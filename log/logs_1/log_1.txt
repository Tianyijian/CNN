nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['Yeah', ',', 'I', 'wouldn', '?', 't', 'know', 'about', 'that', '.']   0
['Bloomingdale', '?', 's']   0

-------dev--------
1109 1109
['I', '?', 'm', 'an', 'idiot', '.']   5
['Ow', '!']   4

-------test--------
2610 2610
['Hey', '!']   1
['Actually', ',', 'nectarines', ',', 'but', 'basically', '...']   0
====================INFORMATION====================
MODEL: non-static
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 50
LEARNING_RATE: 1
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
loading word2vec...
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
write glove vector to glove.txt
global_step: 1, epoch: 1, loss: 1.925885
global_step: 2, epoch: 1, loss: 1.814245
global_step: 3, epoch: 1, loss: 1.661364
global_step: 4, epoch: 1, loss: 1.640390
global_step: 5, epoch: 1, loss: 1.607316
global_step: 6, epoch: 1, loss: 1.577616
global_step: 7, epoch: 1, loss: 1.512019
global_step: 8, epoch: 1, loss: 1.619179
global_step: 9, epoch: 1, loss: 1.570912
global_step: 10, epoch: 1, loss: 1.580727
global_step: 11, epoch: 1, loss: 1.564247
global_step: 12, epoch: 1, loss: 1.492264
global_step: 13, epoch: 1, loss: 1.447052
global_step: 14, epoch: 1, loss: 1.543125
global_step: 15, epoch: 1, loss: 1.525150
global_step: 16, epoch: 1, loss: 1.425918
global_step: 17, epoch: 1, loss: 1.497123
global_step: 18, epoch: 1, loss: 1.421763
global_step: 19, epoch: 1, loss: 1.480063
global_step: 20, epoch: 1, loss: 1.294761
global_step: 21, epoch: 1, loss: 1.364284
global_step: 22, epoch: 1, loss: 1.270151
global_step: 23, epoch: 1, loss: 1.448864
global_step: 24, epoch: 1, loss: 1.472117
global_step: 25, epoch: 1, loss: 1.451946
global_step: 26, epoch: 1, loss: 1.455448
global_step: 27, epoch: 1, loss: 1.606375
global_step: 28, epoch: 1, loss: 1.475089
global_step: 29, epoch: 1, loss: 1.368214
global_step: 30, epoch: 1, loss: 1.273715
global_step: 31, epoch: 1, loss: 1.285432
global_step: 32, epoch: 1, loss: 1.408627
global_step: 33, epoch: 1, loss: 1.427732
global_step: 34, epoch: 1, loss: 1.350574
global_step: 35, epoch: 1, loss: 1.399182
global_step: 36, epoch: 1, loss: 1.410560
global_step: 37, epoch: 1, loss: 1.341285
global_step: 38, epoch: 1, loss: 1.381884
global_step: 39, epoch: 1, loss: 1.317855
global_step: 40, epoch: 1, loss: 1.915746
epoch: 1
train	acc: 0.5145	macro: p 0.2751, r 0.1941, f1: 0.1748	micro: p 0.5145, r 0.5145, f1 0.5145	weighted_f1:0.3944
dev	acc: 0.4770	macro: p 0.2480, r 0.2004, f1: 0.1711	micro: p 0.4770, r 0.4770, f1 0.4770	weighted_f1:0.3505
test	acc: 0.5195	macro: p 0.2437, r 0.1927, f1: 0.1678	micro: p 0.5195, r 0.5195, f1 0.5195	weighted_f1:0.3929
New best model!
global_step: 41, epoch: 2, loss: 1.438367
global_step: 42, epoch: 2, loss: 1.375552
global_step: 43, epoch: 2, loss: 1.242846
global_step: 44, epoch: 2, loss: 1.351354
global_step: 45, epoch: 2, loss: 1.375814
global_step: 46, epoch: 2, loss: 1.281551
global_step: 47, epoch: 2, loss: 1.353832
global_step: 48, epoch: 2, loss: 1.343140
global_step: 49, epoch: 2, loss: 1.361727
global_step: 50, epoch: 2, loss: 1.415806
global_step: 51, epoch: 2, loss: 1.417599
global_step: 52, epoch: 2, loss: 1.388763
global_step: 53, epoch: 2, loss: 1.356730
global_step: 54, epoch: 2, loss: 1.426995
global_step: 55, epoch: 2, loss: 1.364110
global_step: 56, epoch: 2, loss: 1.306851
global_step: 57, epoch: 2, loss: 1.243214
global_step: 58, epoch: 2, loss: 1.307865
global_step: 59, epoch: 2, loss: 1.311754
global_step: 60, epoch: 2, loss: 1.321902
global_step: 61, epoch: 2, loss: 1.334162
global_step: 62, epoch: 2, loss: 1.448448
global_step: 63, epoch: 2, loss: 1.400765
global_step: 64, epoch: 2, loss: 1.324787
global_step: 65, epoch: 2, loss: 1.291638
global_step: 66, epoch: 2, loss: 1.297385
global_step: 67, epoch: 2, loss: 1.349134
global_step: 68, epoch: 2, loss: 1.358981
global_step: 69, epoch: 2, loss: 1.246238
global_step: 70, epoch: 2, loss: 1.304929
global_step: 71, epoch: 2, loss: 1.274857
global_step: 72, epoch: 2, loss: 1.322632
global_step: 73, epoch: 2, loss: 1.253462
global_step: 74, epoch: 2, loss: 1.276577
global_step: 75, epoch: 2, loss: 1.228969
global_step: 76, epoch: 2, loss: 1.207738
global_step: 77, epoch: 2, loss: 1.248411
global_step: 78, epoch: 2, loss: 1.259916
global_step: 79, epoch: 2, loss: 1.393228
global_step: 80, epoch: 2, loss: 0.977964
epoch: 2
train	acc: 0.5596	macro: p 0.3098, r 0.2344, f1: 0.2009	micro: p 0.5596, r 0.5596, f1 0.5596	weighted_f1:0.4578
dev	acc: 0.5131	macro: p 0.4066, r 0.2425, f1: 0.1955	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.3986
test	acc: 0.5621	macro: p 0.2639, r 0.2412, f1: 0.2054	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.4603
New best model!
global_step: 81, epoch: 3, loss: 1.564034
global_step: 82, epoch: 3, loss: 1.388856
global_step: 83, epoch: 3, loss: 1.300968
global_step: 84, epoch: 3, loss: 1.265306
global_step: 85, epoch: 3, loss: 1.147084
global_step: 86, epoch: 3, loss: 1.373590
global_step: 87, epoch: 3, loss: 1.337645
global_step: 88, epoch: 3, loss: 1.314807
global_step: 89, epoch: 3, loss: 1.243066
global_step: 90, epoch: 3, loss: 1.329394
global_step: 91, epoch: 3, loss: 1.228899
global_step: 92, epoch: 3, loss: 1.333880
global_step: 93, epoch: 3, loss: 1.264467
global_step: 94, epoch: 3, loss: 1.259669
global_step: 95, epoch: 3, loss: 1.162825
global_step: 96, epoch: 3, loss: 1.233952
global_step: 97, epoch: 3, loss: 1.334343
global_step: 98, epoch: 3, loss: 1.327673
global_step: 99, epoch: 3, loss: 1.209939
global_step: 100, epoch: 3, loss: 1.203302
global_step: 101, epoch: 3, loss: 1.465596
global_step: 102, epoch: 3, loss: 1.392808
global_step: 103, epoch: 3, loss: 1.331257
global_step: 104, epoch: 3, loss: 1.339354
global_step: 105, epoch: 3, loss: 1.145412
global_step: 106, epoch: 3, loss: 1.355252
global_step: 107, epoch: 3, loss: 1.244187
global_step: 108, epoch: 3, loss: 1.179987
global_step: 109, epoch: 3, loss: 1.208301
global_step: 110, epoch: 3, loss: 1.291501
global_step: 111, epoch: 3, loss: 1.286846
global_step: 112, epoch: 3, loss: 1.259937
global_step: 113, epoch: 3, loss: 1.225593
global_step: 114, epoch: 3, loss: 1.256664
global_step: 115, epoch: 3, loss: 1.341221
global_step: 116, epoch: 3, loss: 1.210017
global_step: 117, epoch: 3, loss: 1.339567
global_step: 118, epoch: 3, loss: 1.238460
global_step: 119, epoch: 3, loss: 1.176351
global_step: 120, epoch: 3, loss: 1.146356
epoch: 3
train	acc: 0.5904	macro: p 0.3320, r 0.2748, f1: 0.2706	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5174
dev	acc: 0.5338	macro: p 0.2920, r 0.2656, f1: 0.2444	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4459
test	acc: 0.5927	macro: p 0.3228, r 0.2779, f1: 0.2695	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5185
New best model!
global_step: 121, epoch: 4, loss: 1.319653
global_step: 122, epoch: 4, loss: 1.345133
global_step: 123, epoch: 4, loss: 1.210122
global_step: 124, epoch: 4, loss: 1.260031
global_step: 125, epoch: 4, loss: 1.242427
global_step: 126, epoch: 4, loss: 1.287401
global_step: 127, epoch: 4, loss: 1.195587
global_step: 128, epoch: 4, loss: 1.247289
global_step: 129, epoch: 4, loss: 1.242123
global_step: 130, epoch: 4, loss: 1.136763
global_step: 131, epoch: 4, loss: 1.252515
global_step: 132, epoch: 4, loss: 1.218986
global_step: 133, epoch: 4, loss: 1.186219
global_step: 134, epoch: 4, loss: 1.254280
global_step: 135, epoch: 4, loss: 1.360542
global_step: 136, epoch: 4, loss: 1.366318
global_step: 137, epoch: 4, loss: 1.299081
global_step: 138, epoch: 4, loss: 1.215240
global_step: 139, epoch: 4, loss: 1.183682
global_step: 140, epoch: 4, loss: 1.118333
global_step: 141, epoch: 4, loss: 1.303733
global_step: 142, epoch: 4, loss: 1.164841
global_step: 143, epoch: 4, loss: 1.234145
global_step: 144, epoch: 4, loss: 1.316408
global_step: 145, epoch: 4, loss: 1.249195
global_step: 146, epoch: 4, loss: 1.212332
global_step: 147, epoch: 4, loss: 1.264330
global_step: 148, epoch: 4, loss: 1.202774
global_step: 149, epoch: 4, loss: 1.126867
global_step: 150, epoch: 4, loss: 1.166937
global_step: 151, epoch: 4, loss: 1.213541
global_step: 152, epoch: 4, loss: 1.215849
global_step: 153, epoch: 4, loss: 1.161335
global_step: 154, epoch: 4, loss: 1.256880
global_step: 155, epoch: 4, loss: 1.251014
global_step: 156, epoch: 4, loss: 1.164185
global_step: 157, epoch: 4, loss: 1.228342
global_step: 158, epoch: 4, loss: 1.243358
global_step: 159, epoch: 4, loss: 1.170957
global_step: 160, epoch: 4, loss: 0.871216
epoch: 4
train	acc: 0.5793	macro: p 0.3597, r 0.2552, f1: 0.2292	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.4864
dev	acc: 0.5203	macro: p 0.3084, r 0.2527, f1: 0.2122	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4146
test	acc: 0.5728	macro: p 0.3729, r 0.2557, f1: 0.2250	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.4774
global_step: 161, epoch: 5, loss: 1.524624
global_step: 162, epoch: 5, loss: 1.246309
global_step: 163, epoch: 5, loss: 1.182183
global_step: 164, epoch: 5, loss: 1.253198
global_step: 165, epoch: 5, loss: 1.205996
global_step: 166, epoch: 5, loss: 1.148989
global_step: 167, epoch: 5, loss: 1.174084
global_step: 168, epoch: 5, loss: 1.231103
global_step: 169, epoch: 5, loss: 1.152673
global_step: 170, epoch: 5, loss: 1.026455
global_step: 171, epoch: 5, loss: 1.208500
global_step: 172, epoch: 5, loss: 1.254491
global_step: 173, epoch: 5, loss: 1.194150
global_step: 174, epoch: 5, loss: 1.133166
global_step: 175, epoch: 5, loss: 1.150478
global_step: 176, epoch: 5, loss: 1.230788
global_step: 177, epoch: 5, loss: 1.108944
global_step: 178, epoch: 5, loss: 1.255342
global_step: 179, epoch: 5, loss: 1.261822
global_step: 180, epoch: 5, loss: 1.289275
global_step: 181, epoch: 5, loss: 1.096979
global_step: 182, epoch: 5, loss: 1.112849
global_step: 183, epoch: 5, loss: 1.247638
global_step: 184, epoch: 5, loss: 1.154680
global_step: 185, epoch: 5, loss: 1.214734
global_step: 186, epoch: 5, loss: 1.208609
global_step: 187, epoch: 5, loss: 1.284815
global_step: 188, epoch: 5, loss: 1.186730
global_step: 189, epoch: 5, loss: 1.217601
global_step: 190, epoch: 5, loss: 1.205148
global_step: 191, epoch: 5, loss: 1.052691
global_step: 192, epoch: 5, loss: 1.243214
global_step: 193, epoch: 5, loss: 1.226407
global_step: 194, epoch: 5, loss: 1.271443
global_step: 195, epoch: 5, loss: 1.176071
global_step: 196, epoch: 5, loss: 1.306956
global_step: 197, epoch: 5, loss: 1.180073
global_step: 198, epoch: 5, loss: 1.268388
global_step: 199, epoch: 5, loss: 1.256869
global_step: 200, epoch: 5, loss: 0.471471
epoch: 5
train	acc: 0.5716	macro: p 0.3705, r 0.2688, f1: 0.2341	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.4925
dev	acc: 0.5014	macro: p 0.2812, r 0.2596, f1: 0.2108	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4119
test	acc: 0.5529	macro: p 0.3964, r 0.2666, f1: 0.2274	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.4750
global_step: 201, epoch: 6, loss: 1.408497
global_step: 202, epoch: 6, loss: 1.278885
global_step: 203, epoch: 6, loss: 1.155172
global_step: 204, epoch: 6, loss: 1.129576
global_step: 205, epoch: 6, loss: 1.137735
global_step: 206, epoch: 6, loss: 1.230490
global_step: 207, epoch: 6, loss: 1.149054
global_step: 208, epoch: 6, loss: 1.114244
global_step: 209, epoch: 6, loss: 1.165603
global_step: 210, epoch: 6, loss: 0.992447
global_step: 211, epoch: 6, loss: 1.211633
global_step: 212, epoch: 6, loss: 1.183288
global_step: 213, epoch: 6, loss: 1.190655
global_step: 214, epoch: 6, loss: 1.235279
global_step: 215, epoch: 6, loss: 1.060737
global_step: 216, epoch: 6, loss: 1.241411
global_step: 217, epoch: 6, loss: 1.227141
global_step: 218, epoch: 6, loss: 1.052914
global_step: 219, epoch: 6, loss: 1.053818
global_step: 220, epoch: 6, loss: 1.286363
global_step: 221, epoch: 6, loss: 1.060000
global_step: 222, epoch: 6, loss: 1.120255
global_step: 223, epoch: 6, loss: 1.127426
global_step: 224, epoch: 6, loss: 1.224871
global_step: 225, epoch: 6, loss: 1.174985
global_step: 226, epoch: 6, loss: 1.314264
global_step: 227, epoch: 6, loss: 1.136258
global_step: 228, epoch: 6, loss: 1.132597
global_step: 229, epoch: 6, loss: 1.129926
global_step: 230, epoch: 6, loss: 1.168692
global_step: 231, epoch: 6, loss: 1.169275
global_step: 232, epoch: 6, loss: 1.269654
global_step: 233, epoch: 6, loss: 1.094176
global_step: 234, epoch: 6, loss: 1.257813
global_step: 235, epoch: 6, loss: 1.229568
global_step: 236, epoch: 6, loss: 1.120583
global_step: 237, epoch: 6, loss: 1.148551
global_step: 238, epoch: 6, loss: 1.193607
global_step: 239, epoch: 6, loss: 1.224937
global_step: 240, epoch: 6, loss: 0.459870
epoch: 6
train	acc: 0.5847	macro: p 0.3545, r 0.2953, f1: 0.2735	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5040
dev	acc: 0.5347	macro: p 0.3242, r 0.2738, f1: 0.2498	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4467
test	acc: 0.5785	macro: p 0.3250, r 0.2777, f1: 0.2598	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.4983
New best model!
global_step: 241, epoch: 7, loss: 1.374287
global_step: 242, epoch: 7, loss: 1.167677
global_step: 243, epoch: 7, loss: 1.105443
global_step: 244, epoch: 7, loss: 1.122126
global_step: 245, epoch: 7, loss: 1.275452
global_step: 246, epoch: 7, loss: 1.181804
global_step: 247, epoch: 7, loss: 1.093633
global_step: 248, epoch: 7, loss: 1.065767
global_step: 249, epoch: 7, loss: 1.165025
global_step: 250, epoch: 7, loss: 1.179961
global_step: 251, epoch: 7, loss: 1.137324
global_step: 252, epoch: 7, loss: 1.057187
global_step: 253, epoch: 7, loss: 1.126202
global_step: 254, epoch: 7, loss: 1.177543
global_step: 255, epoch: 7, loss: 1.151698
global_step: 256, epoch: 7, loss: 1.185144
global_step: 257, epoch: 7, loss: 1.061737
global_step: 258, epoch: 7, loss: 1.286049
global_step: 259, epoch: 7, loss: 1.027191
global_step: 260, epoch: 7, loss: 1.064901
global_step: 261, epoch: 7, loss: 1.092815
global_step: 262, epoch: 7, loss: 1.137478
global_step: 263, epoch: 7, loss: 1.322092
global_step: 264, epoch: 7, loss: 1.182300
global_step: 265, epoch: 7, loss: 1.096635
global_step: 266, epoch: 7, loss: 1.026775
global_step: 267, epoch: 7, loss: 1.243006
global_step: 268, epoch: 7, loss: 1.231911
global_step: 269, epoch: 7, loss: 1.009116
global_step: 270, epoch: 7, loss: 1.137091
global_step: 271, epoch: 7, loss: 1.006209
global_step: 272, epoch: 7, loss: 1.180094
global_step: 273, epoch: 7, loss: 1.051714
global_step: 274, epoch: 7, loss: 1.221591
global_step: 275, epoch: 7, loss: 1.242661
global_step: 276, epoch: 7, loss: 1.135623
global_step: 277, epoch: 7, loss: 1.127820
global_step: 278, epoch: 7, loss: 1.082934
global_step: 279, epoch: 7, loss: 1.018084
global_step: 280, epoch: 7, loss: 0.734120
epoch: 7
train	acc: 0.6294	macro: p 0.4137, r 0.3523, f1: 0.3314	micro: p 0.6294, r 0.6294, f1 0.6294	weighted_f1:0.5757
dev	acc: 0.5537	macro: p 0.3702, r 0.3059, f1: 0.2868	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4876
test	acc: 0.5981	macro: p 0.4175, r 0.3205, f1: 0.3040	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5464
New best model!
global_step: 281, epoch: 8, loss: 1.215206
global_step: 282, epoch: 8, loss: 1.162792
global_step: 283, epoch: 8, loss: 1.187331
global_step: 284, epoch: 8, loss: 0.947270
global_step: 285, epoch: 8, loss: 1.065966
global_step: 286, epoch: 8, loss: 1.142783
global_step: 287, epoch: 8, loss: 1.042919
global_step: 288, epoch: 8, loss: 1.150403
global_step: 289, epoch: 8, loss: 1.093232
global_step: 290, epoch: 8, loss: 1.020443
global_step: 291, epoch: 8, loss: 1.171092
global_step: 292, epoch: 8, loss: 1.103365
global_step: 293, epoch: 8, loss: 1.134181
global_step: 294, epoch: 8, loss: 1.166902
global_step: 295, epoch: 8, loss: 1.146661
global_step: 296, epoch: 8, loss: 1.070363
global_step: 297, epoch: 8, loss: 1.069954
global_step: 298, epoch: 8, loss: 1.101840
global_step: 299, epoch: 8, loss: 1.065241
global_step: 300, epoch: 8, loss: 1.037137
global_step: 301, epoch: 8, loss: 1.226509
global_step: 302, epoch: 8, loss: 1.234554
global_step: 303, epoch: 8, loss: 1.060687
global_step: 304, epoch: 8, loss: 1.106142
global_step: 305, epoch: 8, loss: 1.179574
global_step: 306, epoch: 8, loss: 1.065059
global_step: 307, epoch: 8, loss: 1.141817
global_step: 308, epoch: 8, loss: 1.066234
global_step: 309, epoch: 8, loss: 1.086160
global_step: 310, epoch: 8, loss: 1.091699
global_step: 311, epoch: 8, loss: 1.136190
global_step: 312, epoch: 8, loss: 1.137689
global_step: 313, epoch: 8, loss: 1.007850
global_step: 314, epoch: 8, loss: 1.094600
global_step: 315, epoch: 8, loss: 1.165471
global_step: 316, epoch: 8, loss: 1.032650
global_step: 317, epoch: 8, loss: 1.168693
global_step: 318, epoch: 8, loss: 1.009466
global_step: 319, epoch: 8, loss: 1.231485
global_step: 320, epoch: 8, loss: 1.744946
epoch: 8
train	acc: 0.5481	macro: p 0.4658, r 0.4408, f1: 0.3792	micro: p 0.5481, r 0.5481, f1 0.5481	weighted_f1:0.5594
dev	acc: 0.4653	macro: p 0.3228, r 0.3631, f1: 0.3249	micro: p 0.4653, r 0.4653, f1 0.4653	weighted_f1:0.4704
test	acc: 0.4720	macro: p 0.3221, r 0.3731, f1: 0.3231	micro: p 0.4720, r 0.4720, f1 0.4720	weighted_f1:0.4868
global_step: 321, epoch: 9, loss: 1.331966
global_step: 322, epoch: 9, loss: 0.948504
global_step: 323, epoch: 9, loss: 1.010804
global_step: 324, epoch: 9, loss: 1.092900
global_step: 325, epoch: 9, loss: 1.133491
global_step: 326, epoch: 9, loss: 1.144937
global_step: 327, epoch: 9, loss: 0.923407
global_step: 328, epoch: 9, loss: 1.152190
global_step: 329, epoch: 9, loss: 1.179847
global_step: 330, epoch: 9, loss: 1.050101
global_step: 331, epoch: 9, loss: 1.078633
global_step: 332, epoch: 9, loss: 0.993786
global_step: 333, epoch: 9, loss: 1.135864
global_step: 334, epoch: 9, loss: 1.135667
global_step: 335, epoch: 9, loss: 0.973613
global_step: 336, epoch: 9, loss: 1.102148
global_step: 337, epoch: 9, loss: 1.001696
global_step: 338, epoch: 9, loss: 1.011933
global_step: 339, epoch: 9, loss: 1.068640
global_step: 340, epoch: 9, loss: 0.998514
global_step: 341, epoch: 9, loss: 1.018644
global_step: 342, epoch: 9, loss: 1.031556
global_step: 343, epoch: 9, loss: 0.962568
global_step: 344, epoch: 9, loss: 1.098474
global_step: 345, epoch: 9, loss: 1.057217
global_step: 346, epoch: 9, loss: 1.087013
global_step: 347, epoch: 9, loss: 1.003820
global_step: 348, epoch: 9, loss: 1.197555
global_step: 349, epoch: 9, loss: 1.093526
global_step: 350, epoch: 9, loss: 1.092505
global_step: 351, epoch: 9, loss: 1.059440
global_step: 352, epoch: 9, loss: 1.121738
global_step: 353, epoch: 9, loss: 1.151554
global_step: 354, epoch: 9, loss: 1.227660
global_step: 355, epoch: 9, loss: 1.104805
global_step: 356, epoch: 9, loss: 1.107064
global_step: 357, epoch: 9, loss: 0.936791
global_step: 358, epoch: 9, loss: 1.082963
global_step: 359, epoch: 9, loss: 0.996997
global_step: 360, epoch: 9, loss: 1.637301
epoch: 9
train	acc: 0.6619	macro: p 0.5381, r 0.3786, f1: 0.3885	micro: p 0.6619, r 0.6619, f1 0.6619	weighted_f1:0.6199
dev	acc: 0.5681	macro: p 0.4056, r 0.3155, f1: 0.3091	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5092
test	acc: 0.6161	macro: p 0.4174, r 0.3258, f1: 0.3303	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5687
New best model!
global_step: 361, epoch: 10, loss: 1.017027
global_step: 362, epoch: 10, loss: 0.928663
global_step: 363, epoch: 10, loss: 1.091764
global_step: 364, epoch: 10, loss: 0.946967
global_step: 365, epoch: 10, loss: 1.101635
global_step: 366, epoch: 10, loss: 1.186674
global_step: 367, epoch: 10, loss: 0.959571
global_step: 368, epoch: 10, loss: 0.960372
global_step: 369, epoch: 10, loss: 0.892742
global_step: 370, epoch: 10, loss: 1.036081
global_step: 371, epoch: 10, loss: 0.872479
global_step: 372, epoch: 10, loss: 1.076421
global_step: 373, epoch: 10, loss: 1.156286
global_step: 374, epoch: 10, loss: 1.027537
global_step: 375, epoch: 10, loss: 0.982213
global_step: 376, epoch: 10, loss: 1.022089
global_step: 377, epoch: 10, loss: 1.030648
global_step: 378, epoch: 10, loss: 0.972814
global_step: 379, epoch: 10, loss: 0.984519
global_step: 380, epoch: 10, loss: 0.975254
global_step: 381, epoch: 10, loss: 1.091151
global_step: 382, epoch: 10, loss: 1.093757
global_step: 383, epoch: 10, loss: 1.027984
global_step: 384, epoch: 10, loss: 1.127827
global_step: 385, epoch: 10, loss: 1.120435
global_step: 386, epoch: 10, loss: 0.894957
global_step: 387, epoch: 10, loss: 1.060454
global_step: 388, epoch: 10, loss: 1.014810
global_step: 389, epoch: 10, loss: 1.014059
global_step: 390, epoch: 10, loss: 0.956137
global_step: 391, epoch: 10, loss: 0.904164
global_step: 392, epoch: 10, loss: 1.071531
global_step: 393, epoch: 10, loss: 0.993722
global_step: 394, epoch: 10, loss: 1.059307
global_step: 395, epoch: 10, loss: 1.114602
global_step: 396, epoch: 10, loss: 1.085858
global_step: 397, epoch: 10, loss: 0.966842
global_step: 398, epoch: 10, loss: 1.040597
global_step: 399, epoch: 10, loss: 1.133629
global_step: 400, epoch: 10, loss: 0.419489
epoch: 10
train	acc: 0.6574	macro: p 0.6016, r 0.3528, f1: 0.3492	micro: p 0.6574, r 0.6574, f1 0.6574	weighted_f1:0.5983
dev	acc: 0.5609	macro: p 0.4318, r 0.3088, f1: 0.2874	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.4878
test	acc: 0.5923	macro: p 0.3880, r 0.3012, f1: 0.2822	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5256
global_step: 401, epoch: 11, loss: 1.077359
global_step: 402, epoch: 11, loss: 1.014428
global_step: 403, epoch: 11, loss: 1.009646
global_step: 404, epoch: 11, loss: 0.958333
global_step: 405, epoch: 11, loss: 1.013311
global_step: 406, epoch: 11, loss: 1.085124
global_step: 407, epoch: 11, loss: 1.016999
global_step: 408, epoch: 11, loss: 1.044311
global_step: 409, epoch: 11, loss: 1.102411
global_step: 410, epoch: 11, loss: 1.075900
global_step: 411, epoch: 11, loss: 0.946019
global_step: 412, epoch: 11, loss: 0.967404
global_step: 413, epoch: 11, loss: 0.988318
global_step: 414, epoch: 11, loss: 0.993095
global_step: 415, epoch: 11, loss: 1.184948
global_step: 416, epoch: 11, loss: 1.011872
global_step: 417, epoch: 11, loss: 1.039990
global_step: 418, epoch: 11, loss: 0.891872
global_step: 419, epoch: 11, loss: 0.949773
global_step: 420, epoch: 11, loss: 1.003273
global_step: 421, epoch: 11, loss: 0.985797
global_step: 422, epoch: 11, loss: 1.055254
global_step: 423, epoch: 11, loss: 1.001842
global_step: 424, epoch: 11, loss: 1.125040
global_step: 425, epoch: 11, loss: 0.927915
global_step: 426, epoch: 11, loss: 1.034686
global_step: 427, epoch: 11, loss: 0.981290
global_step: 428, epoch: 11, loss: 0.973149
global_step: 429, epoch: 11, loss: 1.088874
global_step: 430, epoch: 11, loss: 0.997063
global_step: 431, epoch: 11, loss: 0.950217
global_step: 432, epoch: 11, loss: 0.927613
global_step: 433, epoch: 11, loss: 1.011268
global_step: 434, epoch: 11, loss: 0.980071
global_step: 435, epoch: 11, loss: 0.937827
global_step: 436, epoch: 11, loss: 0.962227
global_step: 437, epoch: 11, loss: 1.113207
global_step: 438, epoch: 11, loss: 1.066093
global_step: 439, epoch: 11, loss: 1.035065
global_step: 440, epoch: 11, loss: 1.018322
epoch: 11
train	acc: 0.6298	macro: p 0.5716, r 0.3884, f1: 0.3700	micro: p 0.6298, r 0.6298, f1 0.6298	weighted_f1:0.5990
dev	acc: 0.5131	macro: p 0.3975, r 0.3205, f1: 0.2892	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4747
test	acc: 0.5291	macro: p 0.3734, r 0.3194, f1: 0.2829	micro: p 0.5291, r 0.5291, f1 0.5291	weighted_f1:0.4980
global_step: 441, epoch: 12, loss: 1.104522
global_step: 442, epoch: 12, loss: 1.054390
global_step: 443, epoch: 12, loss: 0.931165
global_step: 444, epoch: 12, loss: 0.948393
global_step: 445, epoch: 12, loss: 0.910935
global_step: 446, epoch: 12, loss: 0.999193
global_step: 447, epoch: 12, loss: 1.035115
global_step: 448, epoch: 12, loss: 0.863654
global_step: 449, epoch: 12, loss: 0.876766
global_step: 450, epoch: 12, loss: 0.988571
global_step: 451, epoch: 12, loss: 0.935639
global_step: 452, epoch: 12, loss: 0.922862
global_step: 453, epoch: 12, loss: 0.938113
global_step: 454, epoch: 12, loss: 0.902134
global_step: 455, epoch: 12, loss: 0.933367
global_step: 456, epoch: 12, loss: 0.901908
global_step: 457, epoch: 12, loss: 0.953200
global_step: 458, epoch: 12, loss: 0.925443
global_step: 459, epoch: 12, loss: 1.007808
global_step: 460, epoch: 12, loss: 1.174899
global_step: 461, epoch: 12, loss: 1.157372
global_step: 462, epoch: 12, loss: 0.978803
global_step: 463, epoch: 12, loss: 0.966254
global_step: 464, epoch: 12, loss: 1.023326
global_step: 465, epoch: 12, loss: 1.007478
global_step: 466, epoch: 12, loss: 0.881646
global_step: 467, epoch: 12, loss: 0.992460
global_step: 468, epoch: 12, loss: 0.962379
global_step: 469, epoch: 12, loss: 0.939839
global_step: 470, epoch: 12, loss: 0.944276
global_step: 471, epoch: 12, loss: 0.938172
global_step: 472, epoch: 12, loss: 1.003654
global_step: 473, epoch: 12, loss: 1.038822
global_step: 474, epoch: 12, loss: 0.943297
global_step: 475, epoch: 12, loss: 0.994510
global_step: 476, epoch: 12, loss: 0.874384
global_step: 477, epoch: 12, loss: 0.912134
global_step: 478, epoch: 12, loss: 0.799465
global_step: 479, epoch: 12, loss: 1.018812
global_step: 480, epoch: 12, loss: 0.246679
epoch: 12
train	acc: 0.5771	macro: p 0.6250, r 0.3155, f1: 0.3018	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5448
dev	acc: 0.4698	macro: p 0.4471, r 0.2715, f1: 0.2398	micro: p 0.4698, r 0.4698, f1 0.4698	weighted_f1:0.4279
test	acc: 0.4981	macro: p 0.3822, r 0.2707, f1: 0.2396	micro: p 0.4981, r 0.4981, f1 0.4981	weighted_f1:0.4664
global_step: 481, epoch: 13, loss: 1.341185
global_step: 482, epoch: 13, loss: 1.052063
global_step: 483, epoch: 13, loss: 0.808990
global_step: 484, epoch: 13, loss: 0.907044
global_step: 485, epoch: 13, loss: 0.914936
global_step: 486, epoch: 13, loss: 0.850401
global_step: 487, epoch: 13, loss: 0.875607
global_step: 488, epoch: 13, loss: 0.879432
global_step: 489, epoch: 13, loss: 0.910791
global_step: 490, epoch: 13, loss: 0.921116
global_step: 491, epoch: 13, loss: 0.856568
global_step: 492, epoch: 13, loss: 0.953820
global_step: 493, epoch: 13, loss: 1.006449
global_step: 494, epoch: 13, loss: 0.953568
global_step: 495, epoch: 13, loss: 0.850755
global_step: 496, epoch: 13, loss: 0.844318
global_step: 497, epoch: 13, loss: 0.929462
global_step: 498, epoch: 13, loss: 0.879036
global_step: 499, epoch: 13, loss: 0.920293
global_step: 500, epoch: 13, loss: 0.821960
global_step: 501, epoch: 13, loss: 0.855701
global_step: 502, epoch: 13, loss: 1.019667
global_step: 503, epoch: 13, loss: 0.868468
global_step: 504, epoch: 13, loss: 0.918979
global_step: 505, epoch: 13, loss: 0.964896
global_step: 506, epoch: 13, loss: 1.008852
global_step: 507, epoch: 13, loss: 0.926979
global_step: 508, epoch: 13, loss: 0.820594
global_step: 509, epoch: 13, loss: 0.971297
global_step: 510, epoch: 13, loss: 1.010920
global_step: 511, epoch: 13, loss: 0.952781
global_step: 512, epoch: 13, loss: 0.992302
global_step: 513, epoch: 13, loss: 0.870625
global_step: 514, epoch: 13, loss: 1.045918
global_step: 515, epoch: 13, loss: 1.111002
global_step: 516, epoch: 13, loss: 1.050355
global_step: 517, epoch: 13, loss: 1.055632
global_step: 518, epoch: 13, loss: 0.868674
global_step: 519, epoch: 13, loss: 0.911884
global_step: 520, epoch: 13, loss: 1.182795
epoch: 13
train	acc: 0.6385	macro: p 0.6765, r 0.3490, f1: 0.3892	micro: p 0.6385, r 0.6385, f1 0.6385	weighted_f1:0.5903
dev	acc: 0.5365	macro: p 0.5078, r 0.2805, f1: 0.2956	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4668
test	acc: 0.5808	macro: p 0.5198, r 0.2732, f1: 0.2918	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5130
global_step: 521, epoch: 14, loss: 1.244530
global_step: 522, epoch: 14, loss: 0.971271
global_step: 523, epoch: 14, loss: 0.920026
global_step: 524, epoch: 14, loss: 0.882514
global_step: 525, epoch: 14, loss: 0.869311
global_step: 526, epoch: 14, loss: 0.896926
global_step: 527, epoch: 14, loss: 0.906965
global_step: 528, epoch: 14, loss: 0.892087
global_step: 529, epoch: 14, loss: 0.835201
global_step: 530, epoch: 14, loss: 0.922636
global_step: 531, epoch: 14, loss: 0.789007
global_step: 532, epoch: 14, loss: 0.983826
global_step: 533, epoch: 14, loss: 0.743674
global_step: 534, epoch: 14, loss: 0.931392
global_step: 535, epoch: 14, loss: 0.901669
global_step: 536, epoch: 14, loss: 0.805549
global_step: 537, epoch: 14, loss: 0.851169
global_step: 538, epoch: 14, loss: 0.810786
global_step: 539, epoch: 14, loss: 0.839964
global_step: 540, epoch: 14, loss: 0.908127
global_step: 541, epoch: 14, loss: 0.892558
global_step: 542, epoch: 14, loss: 1.007310
global_step: 543, epoch: 14, loss: 1.031927
global_step: 544, epoch: 14, loss: 0.908912
global_step: 545, epoch: 14, loss: 0.993133
global_step: 546, epoch: 14, loss: 0.846279
global_step: 547, epoch: 14, loss: 0.842251
global_step: 548, epoch: 14, loss: 0.833771
global_step: 549, epoch: 14, loss: 0.784084
global_step: 550, epoch: 14, loss: 0.909307
global_step: 551, epoch: 14, loss: 0.926245
global_step: 552, epoch: 14, loss: 0.849581
global_step: 553, epoch: 14, loss: 0.851177
global_step: 554, epoch: 14, loss: 0.962976
global_step: 555, epoch: 14, loss: 0.960699
global_step: 556, epoch: 14, loss: 0.899925
global_step: 557, epoch: 14, loss: 0.914373
global_step: 558, epoch: 14, loss: 0.917602
global_step: 559, epoch: 14, loss: 0.813372
global_step: 560, epoch: 14, loss: 0.613091
epoch: 14
train	acc: 0.7503	macro: p 0.7698, r 0.5286, f1: 0.5570	micro: p 0.7503, r 0.7503, f1 0.7503	weighted_f1:0.7282
dev	acc: 0.5699	macro: p 0.3989, r 0.3364, f1: 0.3379	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5233
test	acc: 0.6169	macro: p 0.4240, r 0.3480, f1: 0.3579	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5808
New best model!
global_step: 561, epoch: 15, loss: 0.809180
global_step: 562, epoch: 15, loss: 0.797625
global_step: 563, epoch: 15, loss: 0.905304
global_step: 564, epoch: 15, loss: 0.854573
global_step: 565, epoch: 15, loss: 0.893751
global_step: 566, epoch: 15, loss: 0.905375
global_step: 567, epoch: 15, loss: 0.843490
global_step: 568, epoch: 15, loss: 0.923128
global_step: 569, epoch: 15, loss: 0.749299
global_step: 570, epoch: 15, loss: 0.743067
global_step: 571, epoch: 15, loss: 0.764702
global_step: 572, epoch: 15, loss: 0.843652
global_step: 573, epoch: 15, loss: 0.776168
global_step: 574, epoch: 15, loss: 0.811543
global_step: 575, epoch: 15, loss: 0.807165
global_step: 576, epoch: 15, loss: 0.863965
global_step: 577, epoch: 15, loss: 0.967529
global_step: 578, epoch: 15, loss: 0.884524
global_step: 579, epoch: 15, loss: 0.894116
global_step: 580, epoch: 15, loss: 0.911778
global_step: 581, epoch: 15, loss: 0.834720
global_step: 582, epoch: 15, loss: 0.897010
global_step: 583, epoch: 15, loss: 0.755352
global_step: 584, epoch: 15, loss: 0.964733
global_step: 585, epoch: 15, loss: 1.119792
global_step: 586, epoch: 15, loss: 0.847841
global_step: 587, epoch: 15, loss: 0.911123
global_step: 588, epoch: 15, loss: 0.933184
global_step: 589, epoch: 15, loss: 0.808737
global_step: 590, epoch: 15, loss: 0.922265
global_step: 591, epoch: 15, loss: 0.893550
global_step: 592, epoch: 15, loss: 0.795201
global_step: 593, epoch: 15, loss: 0.754799
global_step: 594, epoch: 15, loss: 0.920035
global_step: 595, epoch: 15, loss: 0.846641
global_step: 596, epoch: 15, loss: 0.881693
global_step: 597, epoch: 15, loss: 0.797547
global_step: 598, epoch: 15, loss: 0.979414
global_step: 599, epoch: 15, loss: 0.901975
global_step: 600, epoch: 15, loss: 0.926468
epoch: 15
train	acc: 0.7135	macro: p 0.7705, r 0.4733, f1: 0.5030	micro: p 0.7135, r 0.7135, f1 0.7135	weighted_f1:0.6839
dev	acc: 0.5455	macro: p 0.4016, r 0.3120, f1: 0.2981	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4845
test	acc: 0.5851	macro: p 0.4139, r 0.3135, f1: 0.3078	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5348
global_step: 601, epoch: 16, loss: 0.942721
global_step: 602, epoch: 16, loss: 0.936313
global_step: 603, epoch: 16, loss: 0.786397
global_step: 604, epoch: 16, loss: 0.861551
global_step: 605, epoch: 16, loss: 0.712931
global_step: 606, epoch: 16, loss: 0.753458
global_step: 607, epoch: 16, loss: 0.890525
global_step: 608, epoch: 16, loss: 0.853692
global_step: 609, epoch: 16, loss: 0.764533
global_step: 610, epoch: 16, loss: 0.853739
global_step: 611, epoch: 16, loss: 0.923240
global_step: 612, epoch: 16, loss: 0.755032
global_step: 613, epoch: 16, loss: 0.702915
global_step: 614, epoch: 16, loss: 0.838197
global_step: 615, epoch: 16, loss: 0.697844
global_step: 616, epoch: 16, loss: 0.994972
global_step: 617, epoch: 16, loss: 0.875883
global_step: 618, epoch: 16, loss: 0.730651
global_step: 619, epoch: 16, loss: 0.829809
global_step: 620, epoch: 16, loss: 0.803976
global_step: 621, epoch: 16, loss: 0.790123
global_step: 622, epoch: 16, loss: 0.858952
global_step: 623, epoch: 16, loss: 0.830627
global_step: 624, epoch: 16, loss: 0.871034
global_step: 625, epoch: 16, loss: 0.837918
global_step: 626, epoch: 16, loss: 0.880363
global_step: 627, epoch: 16, loss: 0.766368
global_step: 628, epoch: 16, loss: 0.779030
global_step: 629, epoch: 16, loss: 0.848278
global_step: 630, epoch: 16, loss: 0.819168
global_step: 631, epoch: 16, loss: 0.850535
global_step: 632, epoch: 16, loss: 0.980956
global_step: 633, epoch: 16, loss: 0.944613
global_step: 634, epoch: 16, loss: 0.902353
global_step: 635, epoch: 16, loss: 0.877848
global_step: 636, epoch: 16, loss: 0.793524
global_step: 637, epoch: 16, loss: 0.913974
global_step: 638, epoch: 16, loss: 0.919396
global_step: 639, epoch: 16, loss: 0.911093
global_step: 640, epoch: 16, loss: 1.421601
epoch: 16
train	acc: 0.7420	macro: p 0.7715, r 0.5687, f1: 0.5781	micro: p 0.7420, r 0.7420, f1 0.7420	weighted_f1:0.7377
dev	acc: 0.5239	macro: p 0.3988, r 0.3437, f1: 0.3324	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4989
test	acc: 0.5395	macro: p 0.5347, r 0.3420, f1: 0.3324	micro: p 0.5395, r 0.5395, f1 0.5395	weighted_f1:0.5280
global_step: 641, epoch: 17, loss: 0.909800
global_step: 642, epoch: 17, loss: 0.726453
global_step: 643, epoch: 17, loss: 0.777953
global_step: 644, epoch: 17, loss: 0.690019
global_step: 645, epoch: 17, loss: 0.791454
global_step: 646, epoch: 17, loss: 0.841347
global_step: 647, epoch: 17, loss: 0.754127
global_step: 648, epoch: 17, loss: 0.855159
global_step: 649, epoch: 17, loss: 0.786239
global_step: 650, epoch: 17, loss: 0.714737
global_step: 651, epoch: 17, loss: 0.724838
global_step: 652, epoch: 17, loss: 0.736835
global_step: 653, epoch: 17, loss: 0.687020
global_step: 654, epoch: 17, loss: 0.718277
global_step: 655, epoch: 17, loss: 0.730744
global_step: 656, epoch: 17, loss: 0.895956
global_step: 657, epoch: 17, loss: 0.864782
global_step: 658, epoch: 17, loss: 0.724366
global_step: 659, epoch: 17, loss: 0.741866
global_step: 660, epoch: 17, loss: 0.822763
global_step: 661, epoch: 17, loss: 0.782628
global_step: 662, epoch: 17, loss: 0.726069
global_step: 663, epoch: 17, loss: 0.756043
global_step: 664, epoch: 17, loss: 0.816786
global_step: 665, epoch: 17, loss: 0.774196
global_step: 666, epoch: 17, loss: 0.812930
global_step: 667, epoch: 17, loss: 0.766637
global_step: 668, epoch: 17, loss: 0.824266
global_step: 669, epoch: 17, loss: 0.754905
global_step: 670, epoch: 17, loss: 0.739097
global_step: 671, epoch: 17, loss: 0.770990
global_step: 672, epoch: 17, loss: 0.811320
global_step: 673, epoch: 17, loss: 0.733728
global_step: 674, epoch: 17, loss: 0.878177
global_step: 675, epoch: 17, loss: 0.790005
global_step: 676, epoch: 17, loss: 0.773526
global_step: 677, epoch: 17, loss: 0.832907
global_step: 678, epoch: 17, loss: 0.815313
global_step: 679, epoch: 17, loss: 0.818821
global_step: 680, epoch: 17, loss: 1.298652
epoch: 17
train	acc: 0.7410	macro: p 0.7957, r 0.5907, f1: 0.6239	micro: p 0.7410, r 0.7410, f1 0.7410	weighted_f1:0.7415
dev	acc: 0.4932	macro: p 0.3523, r 0.3126, f1: 0.2949	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.4697
test	acc: 0.5215	macro: p 0.4489, r 0.3311, f1: 0.3177	micro: p 0.5215, r 0.5215, f1 0.5215	weighted_f1:0.5101
global_step: 681, epoch: 18, loss: 0.931134
global_step: 682, epoch: 18, loss: 0.730930
global_step: 683, epoch: 18, loss: 0.664373
global_step: 684, epoch: 18, loss: 0.817927
global_step: 685, epoch: 18, loss: 0.691045
global_step: 686, epoch: 18, loss: 0.726390
global_step: 687, epoch: 18, loss: 0.623713
global_step: 688, epoch: 18, loss: 0.686306
global_step: 689, epoch: 18, loss: 0.725844
global_step: 690, epoch: 18, loss: 0.648700
global_step: 691, epoch: 18, loss: 0.655909
global_step: 692, epoch: 18, loss: 0.788263
global_step: 693, epoch: 18, loss: 0.750620
global_step: 694, epoch: 18, loss: 0.676944
global_step: 695, epoch: 18, loss: 0.673632
global_step: 696, epoch: 18, loss: 0.773902
global_step: 697, epoch: 18, loss: 0.658510
global_step: 698, epoch: 18, loss: 0.878916
global_step: 699, epoch: 18, loss: 0.695959
global_step: 700, epoch: 18, loss: 0.776694
global_step: 701, epoch: 18, loss: 0.753272
global_step: 702, epoch: 18, loss: 0.721228
global_step: 703, epoch: 18, loss: 0.832663
global_step: 704, epoch: 18, loss: 0.770235
global_step: 705, epoch: 18, loss: 0.776513
global_step: 706, epoch: 18, loss: 0.753306
global_step: 707, epoch: 18, loss: 0.774178
global_step: 708, epoch: 18, loss: 0.726692
global_step: 709, epoch: 18, loss: 0.675204
global_step: 710, epoch: 18, loss: 0.838576
global_step: 711, epoch: 18, loss: 0.723011
global_step: 712, epoch: 18, loss: 0.661558
global_step: 713, epoch: 18, loss: 0.728727
global_step: 714, epoch: 18, loss: 0.737302
global_step: 715, epoch: 18, loss: 0.808456
global_step: 716, epoch: 18, loss: 0.964287
global_step: 717, epoch: 18, loss: 0.842378
global_step: 718, epoch: 18, loss: 0.863557
global_step: 719, epoch: 18, loss: 0.869658
global_step: 720, epoch: 18, loss: 2.134730
epoch: 18
train	acc: 0.7463	macro: p 0.7702, r 0.6212, f1: 0.6574	micro: p 0.7463, r 0.7463, f1 0.7463	weighted_f1:0.7485
dev	acc: 0.5023	macro: p 0.4732, r 0.3349, f1: 0.3285	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4828
test	acc: 0.5337	macro: p 0.4272, r 0.3413, f1: 0.3397	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.5230
global_step: 721, epoch: 19, loss: 0.927382
global_step: 722, epoch: 19, loss: 0.720319
global_step: 723, epoch: 19, loss: 0.700163
global_step: 724, epoch: 19, loss: 0.653195
global_step: 725, epoch: 19, loss: 0.633852
global_step: 726, epoch: 19, loss: 0.813786
global_step: 727, epoch: 19, loss: 0.684513
global_step: 728, epoch: 19, loss: 0.722371
global_step: 729, epoch: 19, loss: 0.693219
global_step: 730, epoch: 19, loss: 0.744138
global_step: 731, epoch: 19, loss: 0.700259
global_step: 732, epoch: 19, loss: 0.654213
global_step: 733, epoch: 19, loss: 0.715372
global_step: 734, epoch: 19, loss: 0.654474
global_step: 735, epoch: 19, loss: 0.785773
global_step: 736, epoch: 19, loss: 0.704237
global_step: 737, epoch: 19, loss: 0.688857
global_step: 738, epoch: 19, loss: 0.766057
global_step: 739, epoch: 19, loss: 0.829391
global_step: 740, epoch: 19, loss: 0.715039
global_step: 741, epoch: 19, loss: 0.887584
global_step: 742, epoch: 19, loss: 0.697906
global_step: 743, epoch: 19, loss: 0.748980
global_step: 744, epoch: 19, loss: 0.654398
global_step: 745, epoch: 19, loss: 0.660879
global_step: 746, epoch: 19, loss: 0.714882
global_step: 747, epoch: 19, loss: 0.829083
global_step: 748, epoch: 19, loss: 0.849573
global_step: 749, epoch: 19, loss: 0.700604
global_step: 750, epoch: 19, loss: 0.672338
global_step: 751, epoch: 19, loss: 0.842815
global_step: 752, epoch: 19, loss: 0.731430
global_step: 753, epoch: 19, loss: 0.687732
global_step: 754, epoch: 19, loss: 0.826308
global_step: 755, epoch: 19, loss: 0.648466
global_step: 756, epoch: 19, loss: 0.706624
global_step: 757, epoch: 19, loss: 0.786881
global_step: 758, epoch: 19, loss: 0.704111
global_step: 759, epoch: 19, loss: 0.777610
global_step: 760, epoch: 19, loss: 1.493281
epoch: 19
train	acc: 0.7848	macro: p 0.7509, r 0.6558, f1: 0.6736	micro: p 0.7848, r 0.7848, f1 0.7848	weighted_f1:0.7847
dev	acc: 0.5230	macro: p 0.3834, r 0.3378, f1: 0.3339	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4997
test	acc: 0.5552	macro: p 0.4242, r 0.3535, f1: 0.3587	micro: p 0.5552, r 0.5552, f1 0.5552	weighted_f1:0.5512
global_step: 761, epoch: 20, loss: 0.864292
global_step: 762, epoch: 20, loss: 0.832613
global_step: 763, epoch: 20, loss: 0.821970
global_step: 764, epoch: 20, loss: 0.780553
global_step: 765, epoch: 20, loss: 0.637497
global_step: 766, epoch: 20, loss: 0.699192
global_step: 767, epoch: 20, loss: 0.724368
global_step: 768, epoch: 20, loss: 0.618638
global_step: 769, epoch: 20, loss: 0.601087
global_step: 770, epoch: 20, loss: 0.640546
global_step: 771, epoch: 20, loss: 0.670041
global_step: 772, epoch: 20, loss: 0.606551
global_step: 773, epoch: 20, loss: 0.641715
global_step: 774, epoch: 20, loss: 0.630454
global_step: 775, epoch: 20, loss: 0.592374
global_step: 776, epoch: 20, loss: 0.670566
global_step: 777, epoch: 20, loss: 0.607689
global_step: 778, epoch: 20, loss: 0.624608
global_step: 779, epoch: 20, loss: 0.549100
global_step: 780, epoch: 20, loss: 0.721373
global_step: 781, epoch: 20, loss: 0.750628
global_step: 782, epoch: 20, loss: 0.757624
global_step: 783, epoch: 20, loss: 0.679762
global_step: 784, epoch: 20, loss: 0.715865
global_step: 785, epoch: 20, loss: 0.677998
global_step: 786, epoch: 20, loss: 0.718656
global_step: 787, epoch: 20, loss: 0.679794
global_step: 788, epoch: 20, loss: 0.709530
global_step: 789, epoch: 20, loss: 0.724330
global_step: 790, epoch: 20, loss: 0.846249
global_step: 791, epoch: 20, loss: 0.693346
global_step: 792, epoch: 20, loss: 0.652477
global_step: 793, epoch: 20, loss: 0.744009
global_step: 794, epoch: 20, loss: 0.663991
global_step: 795, epoch: 20, loss: 0.757259
global_step: 796, epoch: 20, loss: 0.694378
global_step: 797, epoch: 20, loss: 0.630646
global_step: 798, epoch: 20, loss: 0.645632
global_step: 799, epoch: 20, loss: 0.662388
global_step: 800, epoch: 20, loss: 1.659788
epoch: 20
train	acc: 0.7902	macro: p 0.8478, r 0.5514, f1: 0.5960	micro: p 0.7902, r 0.7902, f1 0.7902	weighted_f1:0.7677
dev	acc: 0.5645	macro: p 0.4629, r 0.3323, f1: 0.3253	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5072
test	acc: 0.5958	macro: p 0.5663, r 0.3224, f1: 0.3181	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5462
global_step: 801, epoch: 21, loss: 0.759429
global_step: 802, epoch: 21, loss: 0.649390
global_step: 803, epoch: 21, loss: 0.598720
global_step: 804, epoch: 21, loss: 0.565329
global_step: 805, epoch: 21, loss: 0.548682
global_step: 806, epoch: 21, loss: 0.670754
global_step: 807, epoch: 21, loss: 0.635692
global_step: 808, epoch: 21, loss: 0.621755
global_step: 809, epoch: 21, loss: 0.656244
global_step: 810, epoch: 21, loss: 0.632318
global_step: 811, epoch: 21, loss: 0.739885
global_step: 812, epoch: 21, loss: 0.623783
global_step: 813, epoch: 21, loss: 0.655399
global_step: 814, epoch: 21, loss: 0.744271
global_step: 815, epoch: 21, loss: 0.656157
global_step: 816, epoch: 21, loss: 0.650344
global_step: 817, epoch: 21, loss: 0.639875
global_step: 818, epoch: 21, loss: 0.564600
global_step: 819, epoch: 21, loss: 0.623796
global_step: 820, epoch: 21, loss: 0.681295
global_step: 821, epoch: 21, loss: 0.605072
global_step: 822, epoch: 21, loss: 0.637724
global_step: 823, epoch: 21, loss: 0.688948
global_step: 824, epoch: 21, loss: 0.599042
global_step: 825, epoch: 21, loss: 0.667491
global_step: 826, epoch: 21, loss: 0.661961
global_step: 827, epoch: 21, loss: 0.630920
global_step: 828, epoch: 21, loss: 0.763713
global_step: 829, epoch: 21, loss: 0.702536
global_step: 830, epoch: 21, loss: 0.608545
global_step: 831, epoch: 21, loss: 0.747811
global_step: 832, epoch: 21, loss: 0.910360
global_step: 833, epoch: 21, loss: 0.804450
global_step: 834, epoch: 21, loss: 0.785190
global_step: 835, epoch: 21, loss: 0.716099
global_step: 836, epoch: 21, loss: 0.658136
global_step: 837, epoch: 21, loss: 0.770589
global_step: 838, epoch: 21, loss: 0.672758
global_step: 839, epoch: 21, loss: 0.456343
global_step: 840, epoch: 21, loss: 0.860128
epoch: 21
train	acc: 0.8104	macro: p 0.8463, r 0.6102, f1: 0.6494	micro: p 0.8104, r 0.8104, f1 0.8104	weighted_f1:0.7924
dev	acc: 0.5744	macro: p 0.5349, r 0.3503, f1: 0.3520	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5280
test	acc: 0.6084	macro: p 0.4910, r 0.3483, f1: 0.3468	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5715
New best model!
global_step: 841, epoch: 22, loss: 0.790646
global_step: 842, epoch: 22, loss: 0.668092
global_step: 843, epoch: 22, loss: 0.645558
global_step: 844, epoch: 22, loss: 0.711558
global_step: 845, epoch: 22, loss: 0.593134
global_step: 846, epoch: 22, loss: 0.612993
global_step: 847, epoch: 22, loss: 0.635416
global_step: 848, epoch: 22, loss: 0.660936
global_step: 849, epoch: 22, loss: 0.675098
global_step: 850, epoch: 22, loss: 0.584833
global_step: 851, epoch: 22, loss: 0.745927
global_step: 852, epoch: 22, loss: 0.558427
global_step: 853, epoch: 22, loss: 0.696765
global_step: 854, epoch: 22, loss: 0.527216
global_step: 855, epoch: 22, loss: 0.670093
global_step: 856, epoch: 22, loss: 0.538570
global_step: 857, epoch: 22, loss: 0.623361
global_step: 858, epoch: 22, loss: 0.564856
global_step: 859, epoch: 22, loss: 0.666776
global_step: 860, epoch: 22, loss: 0.667052
global_step: 861, epoch: 22, loss: 0.578089
global_step: 862, epoch: 22, loss: 0.646767
global_step: 863, epoch: 22, loss: 0.735927
global_step: 864, epoch: 22, loss: 0.706796
global_step: 865, epoch: 22, loss: 0.628221
global_step: 866, epoch: 22, loss: 0.779951
global_step: 867, epoch: 22, loss: 0.775729
global_step: 868, epoch: 22, loss: 0.666804
global_step: 869, epoch: 22, loss: 0.742442
global_step: 870, epoch: 22, loss: 0.604086
global_step: 871, epoch: 22, loss: 0.691713
global_step: 872, epoch: 22, loss: 0.596382
global_step: 873, epoch: 22, loss: 0.632859
global_step: 874, epoch: 22, loss: 0.706479
global_step: 875, epoch: 22, loss: 0.599226
global_step: 876, epoch: 22, loss: 0.722668
global_step: 877, epoch: 22, loss: 0.693213
global_step: 878, epoch: 22, loss: 0.682113
global_step: 879, epoch: 22, loss: 0.708985
global_step: 880, epoch: 22, loss: 0.945381
epoch: 22
train	acc: 0.6570	macro: p 0.7147, r 0.6607, f1: 0.6296	micro: p 0.6570, r 0.6570, f1 0.6570	weighted_f1:0.7058
dev	acc: 0.4256	macro: p 0.3977, r 0.3546, f1: 0.3279	micro: p 0.4256, r 0.4256, f1 0.4256	weighted_f1:0.4482
test	acc: 0.4245	macro: p 0.4223, r 0.3565, f1: 0.3300	micro: p 0.4245, r 0.4245, f1 0.4245	weighted_f1:0.4723
global_step: 881, epoch: 23, loss: 1.111848
global_step: 882, epoch: 23, loss: 0.585920
global_step: 883, epoch: 23, loss: 0.654823
global_step: 884, epoch: 23, loss: 0.603140
global_step: 885, epoch: 23, loss: 0.697461
global_step: 886, epoch: 23, loss: 0.592418
global_step: 887, epoch: 23, loss: 0.600788
global_step: 888, epoch: 23, loss: 0.623861
global_step: 889, epoch: 23, loss: 0.587095
global_step: 890, epoch: 23, loss: 0.515477
global_step: 891, epoch: 23, loss: 0.703539
global_step: 892, epoch: 23, loss: 0.561020
global_step: 893, epoch: 23, loss: 0.554742
global_step: 894, epoch: 23, loss: 0.622132
global_step: 895, epoch: 23, loss: 0.588111
global_step: 896, epoch: 23, loss: 0.555677
global_step: 897, epoch: 23, loss: 0.560753
global_step: 898, epoch: 23, loss: 0.660337
global_step: 899, epoch: 23, loss: 0.469722
global_step: 900, epoch: 23, loss: 0.575633
global_step: 901, epoch: 23, loss: 0.525208
global_step: 902, epoch: 23, loss: 0.586979
global_step: 903, epoch: 23, loss: 0.475005
global_step: 904, epoch: 23, loss: 0.644013
global_step: 905, epoch: 23, loss: 0.608440
global_step: 906, epoch: 23, loss: 0.656940
global_step: 907, epoch: 23, loss: 0.652288
global_step: 908, epoch: 23, loss: 0.521739
global_step: 909, epoch: 23, loss: 0.635215
global_step: 910, epoch: 23, loss: 0.670217
global_step: 911, epoch: 23, loss: 0.685418
global_step: 912, epoch: 23, loss: 0.575374
global_step: 913, epoch: 23, loss: 0.587177
global_step: 914, epoch: 23, loss: 0.696042
global_step: 915, epoch: 23, loss: 0.601014
global_step: 916, epoch: 23, loss: 0.761414
global_step: 917, epoch: 23, loss: 0.730555
global_step: 918, epoch: 23, loss: 0.664294
global_step: 919, epoch: 23, loss: 0.570404
global_step: 920, epoch: 23, loss: 1.126648
epoch: 23
train	acc: 0.8418	macro: p 0.8896, r 0.6819, f1: 0.7347	micro: p 0.8418, r 0.8418, f1 0.8418	weighted_f1:0.8273
dev	acc: 0.5645	macro: p 0.4675, r 0.3314, f1: 0.3283	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5080
test	acc: 0.6088	macro: p 0.4779, r 0.3359, f1: 0.3395	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5611
global_step: 921, epoch: 24, loss: 0.689394
global_step: 922, epoch: 24, loss: 0.585961
global_step: 923, epoch: 24, loss: 0.615262
global_step: 924, epoch: 24, loss: 0.676339
global_step: 925, epoch: 24, loss: 0.641968
global_step: 926, epoch: 24, loss: 0.683880
global_step: 927, epoch: 24, loss: 0.512580
global_step: 928, epoch: 24, loss: 0.565424
global_step: 929, epoch: 24, loss: 0.620850
global_step: 930, epoch: 24, loss: 0.534527
global_step: 931, epoch: 24, loss: 0.639797
global_step: 932, epoch: 24, loss: 0.531402
global_step: 933, epoch: 24, loss: 0.514714
global_step: 934, epoch: 24, loss: 0.549437
global_step: 935, epoch: 24, loss: 0.573037
global_step: 936, epoch: 24, loss: 0.646326
global_step: 937, epoch: 24, loss: 0.670050
global_step: 938, epoch: 24, loss: 0.670626
global_step: 939, epoch: 24, loss: 0.556581
global_step: 940, epoch: 24, loss: 0.510785
global_step: 941, epoch: 24, loss: 0.579656
global_step: 942, epoch: 24, loss: 0.700091
global_step: 943, epoch: 24, loss: 0.628569
global_step: 944, epoch: 24, loss: 0.549112
global_step: 945, epoch: 24, loss: 0.677287
global_step: 946, epoch: 24, loss: 0.686784
global_step: 947, epoch: 24, loss: 0.699294
global_step: 948, epoch: 24, loss: 0.553935
global_step: 949, epoch: 24, loss: 0.561490
global_step: 950, epoch: 24, loss: 0.496243
global_step: 951, epoch: 24, loss: 0.660578
global_step: 952, epoch: 24, loss: 0.604770
global_step: 953, epoch: 24, loss: 0.828120
global_step: 954, epoch: 24, loss: 0.611331
global_step: 955, epoch: 24, loss: 0.689965
global_step: 956, epoch: 24, loss: 0.634685
global_step: 957, epoch: 24, loss: 0.692905
global_step: 958, epoch: 24, loss: 0.590657
global_step: 959, epoch: 24, loss: 0.622133
global_step: 960, epoch: 24, loss: 0.629310
epoch: 24
train	acc: 0.7971	macro: p 0.8850, r 0.5972, f1: 0.6727	micro: p 0.7971, r 0.7971, f1 0.7971	weighted_f1:0.7799
dev	acc: 0.5509	macro: p 0.4594, r 0.3077, f1: 0.3019	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4757
test	acc: 0.6008	macro: p 0.5388, r 0.3121, f1: 0.3177	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5353
global_step: 961, epoch: 25, loss: 0.995936
global_step: 962, epoch: 25, loss: 0.819846
global_step: 963, epoch: 25, loss: 0.584897
global_step: 964, epoch: 25, loss: 0.530765
global_step: 965, epoch: 25, loss: 0.516491
global_step: 966, epoch: 25, loss: 0.476326
global_step: 967, epoch: 25, loss: 0.614332
global_step: 968, epoch: 25, loss: 0.647639
global_step: 969, epoch: 25, loss: 0.542147
global_step: 970, epoch: 25, loss: 0.629266
global_step: 971, epoch: 25, loss: 0.665283
global_step: 972, epoch: 25, loss: 0.558493
global_step: 973, epoch: 25, loss: 0.587312
global_step: 974, epoch: 25, loss: 0.491508
global_step: 975, epoch: 25, loss: 0.585209
global_step: 976, epoch: 25, loss: 0.651562
global_step: 977, epoch: 25, loss: 0.562727
global_step: 978, epoch: 25, loss: 0.601294
global_step: 979, epoch: 25, loss: 0.447014
global_step: 980, epoch: 25, loss: 0.666662
global_step: 981, epoch: 25, loss: 0.567458
global_step: 982, epoch: 25, loss: 0.493732
global_step: 983, epoch: 25, loss: 0.444016
global_step: 984, epoch: 25, loss: 0.545197
global_step: 985, epoch: 25, loss: 0.572552
global_step: 986, epoch: 25, loss: 0.602537
global_step: 987, epoch: 25, loss: 0.633348
global_step: 988, epoch: 25, loss: 0.512311
global_step: 989, epoch: 25, loss: 0.559041
global_step: 990, epoch: 25, loss: 0.559526
global_step: 991, epoch: 25, loss: 0.587180
global_step: 992, epoch: 25, loss: 0.484120
global_step: 993, epoch: 25, loss: 0.692010
global_step: 994, epoch: 25, loss: 0.577547
global_step: 995, epoch: 25, loss: 0.544783
global_step: 996, epoch: 25, loss: 0.694175
global_step: 997, epoch: 25, loss: 0.688748
global_step: 998, epoch: 25, loss: 0.632089
global_step: 999, epoch: 25, loss: 0.527768
global_step: 1000, epoch: 25, loss: 1.572481
epoch: 25
train	acc: 0.8721	macro: p 0.9048, r 0.7536, f1: 0.8116	micro: p 0.8721, r 0.8721, f1 0.8721	weighted_f1:0.8681
dev	acc: 0.5591	macro: p 0.5055, r 0.3385, f1: 0.3479	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5108
test	acc: 0.5897	macro: p 0.4457, r 0.3297, f1: 0.3413	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5485
global_step: 1001, epoch: 26, loss: 0.545000
global_step: 1002, epoch: 26, loss: 0.533306
global_step: 1003, epoch: 26, loss: 0.583859
global_step: 1004, epoch: 26, loss: 0.541397
global_step: 1005, epoch: 26, loss: 0.563859
global_step: 1006, epoch: 26, loss: 0.468017
global_step: 1007, epoch: 26, loss: 0.529160
global_step: 1008, epoch: 26, loss: 0.564110
global_step: 1009, epoch: 26, loss: 0.602241
global_step: 1010, epoch: 26, loss: 0.484118
global_step: 1011, epoch: 26, loss: 0.575121
global_step: 1012, epoch: 26, loss: 0.641599
global_step: 1013, epoch: 26, loss: 0.522273
global_step: 1014, epoch: 26, loss: 0.505437
global_step: 1015, epoch: 26, loss: 0.568690
global_step: 1016, epoch: 26, loss: 0.590504
global_step: 1017, epoch: 26, loss: 0.508365
global_step: 1018, epoch: 26, loss: 0.516835
global_step: 1019, epoch: 26, loss: 0.647069
global_step: 1020, epoch: 26, loss: 0.519674
global_step: 1021, epoch: 26, loss: 0.567536
global_step: 1022, epoch: 26, loss: 0.589234
global_step: 1023, epoch: 26, loss: 0.639253
global_step: 1024, epoch: 26, loss: 0.640829
global_step: 1025, epoch: 26, loss: 0.548868
global_step: 1026, epoch: 26, loss: 0.579853
global_step: 1027, epoch: 26, loss: 0.502963
global_step: 1028, epoch: 26, loss: 0.503140
global_step: 1029, epoch: 26, loss: 0.520823
global_step: 1030, epoch: 26, loss: 0.653262
global_step: 1031, epoch: 26, loss: 0.670852
global_step: 1032, epoch: 26, loss: 0.621643
global_step: 1033, epoch: 26, loss: 0.641931
global_step: 1034, epoch: 26, loss: 0.572493
global_step: 1035, epoch: 26, loss: 0.570625
global_step: 1036, epoch: 26, loss: 0.546925
global_step: 1037, epoch: 26, loss: 0.667574
global_step: 1038, epoch: 26, loss: 0.497436
global_step: 1039, epoch: 26, loss: 0.535911
global_step: 1040, epoch: 26, loss: 1.462814
epoch: 26
train	acc: 0.8663	macro: p 0.8926, r 0.7624, f1: 0.8075	micro: p 0.8663, r 0.8663, f1 0.8663	weighted_f1:0.8634
dev	acc: 0.5690	macro: p 0.4645, r 0.3523, f1: 0.3623	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5263
test	acc: 0.6023	macro: p 0.4326, r 0.3466, f1: 0.3561	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5691
global_step: 1041, epoch: 27, loss: 0.576478
global_step: 1042, epoch: 27, loss: 0.534091
global_step: 1043, epoch: 27, loss: 0.560630
global_step: 1044, epoch: 27, loss: 0.535618
global_step: 1045, epoch: 27, loss: 0.489770
global_step: 1046, epoch: 27, loss: 0.489216
global_step: 1047, epoch: 27, loss: 0.620088
global_step: 1048, epoch: 27, loss: 0.551281
global_step: 1049, epoch: 27, loss: 0.539153
global_step: 1050, epoch: 27, loss: 0.510724
global_step: 1051, epoch: 27, loss: 0.434073
global_step: 1052, epoch: 27, loss: 0.492834
global_step: 1053, epoch: 27, loss: 0.444103
global_step: 1054, epoch: 27, loss: 0.471949
global_step: 1055, epoch: 27, loss: 0.616154
global_step: 1056, epoch: 27, loss: 0.455660
global_step: 1057, epoch: 27, loss: 0.616161
global_step: 1058, epoch: 27, loss: 0.799147
global_step: 1059, epoch: 27, loss: 0.473425
global_step: 1060, epoch: 27, loss: 0.535293
global_step: 1061, epoch: 27, loss: 0.444560
global_step: 1062, epoch: 27, loss: 0.468647
global_step: 1063, epoch: 27, loss: 0.609052
global_step: 1064, epoch: 27, loss: 0.554750
global_step: 1065, epoch: 27, loss: 0.525060
global_step: 1066, epoch: 27, loss: 0.548760
global_step: 1067, epoch: 27, loss: 0.516585
global_step: 1068, epoch: 27, loss: 0.509433
global_step: 1069, epoch: 27, loss: 0.598970
global_step: 1070, epoch: 27, loss: 0.489328
global_step: 1071, epoch: 27, loss: 0.641093
global_step: 1072, epoch: 27, loss: 0.610115
global_step: 1073, epoch: 27, loss: 0.575450
global_step: 1074, epoch: 27, loss: 0.594992
global_step: 1075, epoch: 27, loss: 0.446751
global_step: 1076, epoch: 27, loss: 0.725196
global_step: 1077, epoch: 27, loss: 0.633321
global_step: 1078, epoch: 27, loss: 0.607081
global_step: 1079, epoch: 27, loss: 0.533770
global_step: 1080, epoch: 27, loss: 0.130011
epoch: 27
train	acc: 0.8557	macro: p 0.8917, r 0.7297, f1: 0.7762	micro: p 0.8557, r 0.8557, f1 0.8557	weighted_f1:0.8520
dev	acc: 0.5609	macro: p 0.5201, r 0.3508, f1: 0.3484	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5133
test	acc: 0.5805	macro: p 0.4411, r 0.3365, f1: 0.3281	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5449
global_step: 1081, epoch: 28, loss: 0.614056
global_step: 1082, epoch: 28, loss: 0.666255
global_step: 1083, epoch: 28, loss: 0.552636
global_step: 1084, epoch: 28, loss: 0.481344
global_step: 1085, epoch: 28, loss: 0.440756
global_step: 1086, epoch: 28, loss: 0.481054
global_step: 1087, epoch: 28, loss: 0.460819
global_step: 1088, epoch: 28, loss: 0.492780
global_step: 1089, epoch: 28, loss: 0.432012
global_step: 1090, epoch: 28, loss: 0.541282
global_step: 1091, epoch: 28, loss: 0.662041
global_step: 1092, epoch: 28, loss: 0.492625
global_step: 1093, epoch: 28, loss: 0.535863
global_step: 1094, epoch: 28, loss: 0.502430
global_step: 1095, epoch: 28, loss: 0.643668
global_step: 1096, epoch: 28, loss: 0.541453
global_step: 1097, epoch: 28, loss: 0.543778
global_step: 1098, epoch: 28, loss: 0.563151
global_step: 1099, epoch: 28, loss: 0.473836
global_step: 1100, epoch: 28, loss: 0.475477
global_step: 1101, epoch: 28, loss: 0.652619
global_step: 1102, epoch: 28, loss: 0.483231
global_step: 1103, epoch: 28, loss: 0.514680
global_step: 1104, epoch: 28, loss: 0.542199
global_step: 1105, epoch: 28, loss: 0.661007
global_step: 1106, epoch: 28, loss: 0.482832
global_step: 1107, epoch: 28, loss: 0.504114
global_step: 1108, epoch: 28, loss: 0.510579
global_step: 1109, epoch: 28, loss: 0.514306
global_step: 1110, epoch: 28, loss: 0.562930
global_step: 1111, epoch: 28, loss: 0.583853
global_step: 1112, epoch: 28, loss: 0.579718
global_step: 1113, epoch: 28, loss: 0.478491
global_step: 1114, epoch: 28, loss: 0.566780
global_step: 1115, epoch: 28, loss: 0.639289
global_step: 1116, epoch: 28, loss: 0.589231
global_step: 1117, epoch: 28, loss: 0.550653
global_step: 1118, epoch: 28, loss: 0.488805
global_step: 1119, epoch: 28, loss: 0.446602
global_step: 1120, epoch: 28, loss: 0.960578
epoch: 28
train	acc: 0.8762	macro: p 0.9060, r 0.7761, f1: 0.8285	micro: p 0.8762, r 0.8762, f1 0.8762	weighted_f1:0.8731
dev	acc: 0.5735	macro: p 0.4470, r 0.3407, f1: 0.3551	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5281
test	acc: 0.6069	macro: p 0.4642, r 0.3448, f1: 0.3673	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5689
New best model!
global_step: 1121, epoch: 29, loss: 0.541780
global_step: 1122, epoch: 29, loss: 0.485998
global_step: 1123, epoch: 29, loss: 0.492508
global_step: 1124, epoch: 29, loss: 0.695609
global_step: 1125, epoch: 29, loss: 0.489234
global_step: 1126, epoch: 29, loss: 0.439563
global_step: 1127, epoch: 29, loss: 0.393208
global_step: 1128, epoch: 29, loss: 0.491562
global_step: 1129, epoch: 29, loss: 0.440954
global_step: 1130, epoch: 29, loss: 0.374096
global_step: 1131, epoch: 29, loss: 0.565953
global_step: 1132, epoch: 29, loss: 0.578987
global_step: 1133, epoch: 29, loss: 0.445778
global_step: 1134, epoch: 29, loss: 0.439407
global_step: 1135, epoch: 29, loss: 0.453988
global_step: 1136, epoch: 29, loss: 0.517085
global_step: 1137, epoch: 29, loss: 0.436945
global_step: 1138, epoch: 29, loss: 0.634042
global_step: 1139, epoch: 29, loss: 0.403569
global_step: 1140, epoch: 29, loss: 0.524342
global_step: 1141, epoch: 29, loss: 0.561541
global_step: 1142, epoch: 29, loss: 0.459701
global_step: 1143, epoch: 29, loss: 0.596193
global_step: 1144, epoch: 29, loss: 0.588988
global_step: 1145, epoch: 29, loss: 0.553176
global_step: 1146, epoch: 29, loss: 0.553091
global_step: 1147, epoch: 29, loss: 0.438574
global_step: 1148, epoch: 29, loss: 0.510080
global_step: 1149, epoch: 29, loss: 0.494424
global_step: 1150, epoch: 29, loss: 0.610811
global_step: 1151, epoch: 29, loss: 0.463440
global_step: 1152, epoch: 29, loss: 0.645258
global_step: 1153, epoch: 29, loss: 0.528815
global_step: 1154, epoch: 29, loss: 0.466528
global_step: 1155, epoch: 29, loss: 0.577303
global_step: 1156, epoch: 29, loss: 0.491618
global_step: 1157, epoch: 29, loss: 0.520869
global_step: 1158, epoch: 29, loss: 0.510453
global_step: 1159, epoch: 29, loss: 0.549618
global_step: 1160, epoch: 29, loss: 0.510062
epoch: 29
train	acc: 0.8761	macro: p 0.8724, r 0.8482, f1: 0.8532	micro: p 0.8761, r 0.8761, f1 0.8761	weighted_f1:0.8772
dev	acc: 0.5050	macro: p 0.3893, r 0.3682, f1: 0.3526	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4954
test	acc: 0.5184	macro: p 0.3651, r 0.3737, f1: 0.3530	micro: p 0.5184, r 0.5184, f1 0.5184	weighted_f1:0.5215
global_step: 1161, epoch: 30, loss: 0.657736
global_step: 1162, epoch: 30, loss: 0.515365
global_step: 1163, epoch: 30, loss: 0.331844
global_step: 1164, epoch: 30, loss: 0.468683
global_step: 1165, epoch: 30, loss: 0.418651
global_step: 1166, epoch: 30, loss: 0.388464
global_step: 1167, epoch: 30, loss: 0.447123
global_step: 1168, epoch: 30, loss: 0.497334
global_step: 1169, epoch: 30, loss: 0.494335
global_step: 1170, epoch: 30, loss: 0.492570
global_step: 1171, epoch: 30, loss: 0.508599
global_step: 1172, epoch: 30, loss: 0.546900
global_step: 1173, epoch: 30, loss: 0.544614
global_step: 1174, epoch: 30, loss: 0.439137
global_step: 1175, epoch: 30, loss: 0.450666
global_step: 1176, epoch: 30, loss: 0.489486
global_step: 1177, epoch: 30, loss: 0.595272
global_step: 1178, epoch: 30, loss: 0.510455
global_step: 1179, epoch: 30, loss: 0.527245
global_step: 1180, epoch: 30, loss: 0.492256
global_step: 1181, epoch: 30, loss: 0.533341
global_step: 1182, epoch: 30, loss: 0.571746
global_step: 1183, epoch: 30, loss: 0.574123
global_step: 1184, epoch: 30, loss: 0.465988
global_step: 1185, epoch: 30, loss: 0.611971
global_step: 1186, epoch: 30, loss: 0.462445
global_step: 1187, epoch: 30, loss: 0.477479
global_step: 1188, epoch: 30, loss: 0.558016
global_step: 1189, epoch: 30, loss: 0.465532
global_step: 1190, epoch: 30, loss: 0.479849
global_step: 1191, epoch: 30, loss: 0.555664
global_step: 1192, epoch: 30, loss: 0.519355
global_step: 1193, epoch: 30, loss: 0.498170
global_step: 1194, epoch: 30, loss: 0.490613
global_step: 1195, epoch: 30, loss: 0.486730
global_step: 1196, epoch: 30, loss: 0.462019
global_step: 1197, epoch: 30, loss: 0.437612
global_step: 1198, epoch: 30, loss: 0.515834
global_step: 1199, epoch: 30, loss: 0.528108
global_step: 1200, epoch: 30, loss: 0.123933
epoch: 30
train	acc: 0.8989	macro: p 0.9197, r 0.8180, f1: 0.8573	micro: p 0.8989, r 0.8989, f1 0.8989	weighted_f1:0.8973
dev	acc: 0.5609	macro: p 0.4562, r 0.3427, f1: 0.3474	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5219
test	acc: 0.6011	macro: p 0.4394, r 0.3547, f1: 0.3632	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5731
global_step: 1201, epoch: 31, loss: 0.400759
global_step: 1202, epoch: 31, loss: 0.381641
global_step: 1203, epoch: 31, loss: 0.386052
global_step: 1204, epoch: 31, loss: 0.435313
global_step: 1205, epoch: 31, loss: 0.424539
global_step: 1206, epoch: 31, loss: 0.480771
global_step: 1207, epoch: 31, loss: 0.458364
global_step: 1208, epoch: 31, loss: 0.538640
global_step: 1209, epoch: 31, loss: 0.424193
global_step: 1210, epoch: 31, loss: 0.521765
global_step: 1211, epoch: 31, loss: 0.455877
global_step: 1212, epoch: 31, loss: 0.471292
global_step: 1213, epoch: 31, loss: 0.461218
global_step: 1214, epoch: 31, loss: 0.424566
global_step: 1215, epoch: 31, loss: 0.459053
global_step: 1216, epoch: 31, loss: 0.630305
global_step: 1217, epoch: 31, loss: 0.411547
global_step: 1218, epoch: 31, loss: 0.409891
global_step: 1219, epoch: 31, loss: 0.610719
global_step: 1220, epoch: 31, loss: 0.515269
global_step: 1221, epoch: 31, loss: 0.548586
global_step: 1222, epoch: 31, loss: 0.357996
global_step: 1223, epoch: 31, loss: 0.435748
global_step: 1224, epoch: 31, loss: 0.460155
global_step: 1225, epoch: 31, loss: 0.453367
global_step: 1226, epoch: 31, loss: 0.384269
global_step: 1227, epoch: 31, loss: 0.537055
global_step: 1228, epoch: 31, loss: 0.584416
global_step: 1229, epoch: 31, loss: 0.368909
global_step: 1230, epoch: 31, loss: 0.562305
global_step: 1231, epoch: 31, loss: 0.507047
global_step: 1232, epoch: 31, loss: 0.525965
global_step: 1233, epoch: 31, loss: 0.640973
global_step: 1234, epoch: 31, loss: 0.529553
global_step: 1235, epoch: 31, loss: 0.522374
global_step: 1236, epoch: 31, loss: 0.482176
global_step: 1237, epoch: 31, loss: 0.513379
global_step: 1238, epoch: 31, loss: 0.525147
global_step: 1239, epoch: 31, loss: 0.533322
global_step: 1240, epoch: 31, loss: 0.805718
epoch: 31
train	acc: 0.9127	macro: p 0.9220, r 0.8610, f1: 0.8871	micro: p 0.9127, r 0.9127, f1 0.9127	weighted_f1:0.9124
dev	acc: 0.5401	macro: p 0.3924, r 0.3438, f1: 0.3421	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.5127
test	acc: 0.5774	macro: p 0.4099, r 0.3630, f1: 0.3666	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5610
global_step: 1241, epoch: 32, loss: 0.469645
global_step: 1242, epoch: 32, loss: 0.506292
global_step: 1243, epoch: 32, loss: 0.543107
global_step: 1244, epoch: 32, loss: 0.617240
global_step: 1245, epoch: 32, loss: 0.490676
global_step: 1246, epoch: 32, loss: 0.389919
global_step: 1247, epoch: 32, loss: 0.332747
global_step: 1248, epoch: 32, loss: 0.452782
global_step: 1249, epoch: 32, loss: 0.466550
global_step: 1250, epoch: 32, loss: 0.452135
global_step: 1251, epoch: 32, loss: 0.422662
global_step: 1252, epoch: 32, loss: 0.478262
global_step: 1253, epoch: 32, loss: 0.428128
global_step: 1254, epoch: 32, loss: 0.483035
global_step: 1255, epoch: 32, loss: 0.392907
global_step: 1256, epoch: 32, loss: 0.563357
global_step: 1257, epoch: 32, loss: 0.391256
global_step: 1258, epoch: 32, loss: 0.482944
global_step: 1259, epoch: 32, loss: 0.511414
global_step: 1260, epoch: 32, loss: 0.434591
global_step: 1261, epoch: 32, loss: 0.546460
global_step: 1262, epoch: 32, loss: 0.421823
global_step: 1263, epoch: 32, loss: 0.479406
global_step: 1264, epoch: 32, loss: 0.419838
global_step: 1265, epoch: 32, loss: 0.364594
global_step: 1266, epoch: 32, loss: 0.423131
global_step: 1267, epoch: 32, loss: 0.372226
global_step: 1268, epoch: 32, loss: 0.603816
global_step: 1269, epoch: 32, loss: 0.629528
global_step: 1270, epoch: 32, loss: 0.482408
global_step: 1271, epoch: 32, loss: 0.484111
global_step: 1272, epoch: 32, loss: 0.418952
global_step: 1273, epoch: 32, loss: 0.314681
global_step: 1274, epoch: 32, loss: 0.426512
global_step: 1275, epoch: 32, loss: 0.446403
global_step: 1276, epoch: 32, loss: 0.419900
global_step: 1277, epoch: 32, loss: 0.547162
global_step: 1278, epoch: 32, loss: 0.443867
global_step: 1279, epoch: 32, loss: 0.587112
global_step: 1280, epoch: 32, loss: 0.075883
epoch: 32
train	acc: 0.9202	macro: p 0.9347, r 0.8635, f1: 0.8941	micro: p 0.9202, r 0.9202, f1 0.9202	weighted_f1:0.9195
dev	acc: 0.5717	macro: p 0.4445, r 0.3597, f1: 0.3703	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5337
test	acc: 0.6019	macro: p 0.4127, r 0.3581, f1: 0.3640	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5717
New best model!
global_step: 1281, epoch: 33, loss: 0.455526
global_step: 1282, epoch: 33, loss: 0.399123
global_step: 1283, epoch: 33, loss: 0.448210
global_step: 1284, epoch: 33, loss: 0.468823
global_step: 1285, epoch: 33, loss: 0.478428
global_step: 1286, epoch: 33, loss: 0.374072
global_step: 1287, epoch: 33, loss: 0.318549
global_step: 1288, epoch: 33, loss: 0.386120
global_step: 1289, epoch: 33, loss: 0.412301
global_step: 1290, epoch: 33, loss: 0.384884
global_step: 1291, epoch: 33, loss: 0.439132
global_step: 1292, epoch: 33, loss: 0.503624
global_step: 1293, epoch: 33, loss: 0.350534
global_step: 1294, epoch: 33, loss: 0.536213
global_step: 1295, epoch: 33, loss: 0.467854
global_step: 1296, epoch: 33, loss: 0.469931
global_step: 1297, epoch: 33, loss: 0.443036
global_step: 1298, epoch: 33, loss: 0.537638
global_step: 1299, epoch: 33, loss: 0.486485
global_step: 1300, epoch: 33, loss: 0.382251
global_step: 1301, epoch: 33, loss: 0.373265
global_step: 1302, epoch: 33, loss: 0.475635
global_step: 1303, epoch: 33, loss: 0.439474
global_step: 1304, epoch: 33, loss: 0.482755
global_step: 1305, epoch: 33, loss: 0.421355
global_step: 1306, epoch: 33, loss: 0.393714
global_step: 1307, epoch: 33, loss: 0.409547
global_step: 1308, epoch: 33, loss: 0.358285
global_step: 1309, epoch: 33, loss: 0.519390
global_step: 1310, epoch: 33, loss: 0.447666
global_step: 1311, epoch: 33, loss: 0.413433
global_step: 1312, epoch: 33, loss: 0.440593
global_step: 1313, epoch: 33, loss: 0.395474
global_step: 1314, epoch: 33, loss: 0.507767
global_step: 1315, epoch: 33, loss: 0.460261
global_step: 1316, epoch: 33, loss: 0.508032
global_step: 1317, epoch: 33, loss: 0.495950
global_step: 1318, epoch: 33, loss: 0.474738
global_step: 1319, epoch: 33, loss: 0.457377
global_step: 1320, epoch: 33, loss: 0.138969
epoch: 33
train	acc: 0.9138	macro: p 0.9339, r 0.8502, f1: 0.8859	micro: p 0.9138, r 0.9138, f1 0.9138	weighted_f1:0.9125
dev	acc: 0.5618	macro: p 0.4329, r 0.3456, f1: 0.3503	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5220
test	acc: 0.5958	macro: p 0.4312, r 0.3514, f1: 0.3590	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5657
global_step: 1321, epoch: 34, loss: 0.368143
global_step: 1322, epoch: 34, loss: 0.391389
global_step: 1323, epoch: 34, loss: 0.380802
global_step: 1324, epoch: 34, loss: 0.342630
global_step: 1325, epoch: 34, loss: 0.507354
global_step: 1326, epoch: 34, loss: 0.458639
global_step: 1327, epoch: 34, loss: 0.377822
global_step: 1328, epoch: 34, loss: 0.459784
global_step: 1329, epoch: 34, loss: 0.522188
global_step: 1330, epoch: 34, loss: 0.430017
global_step: 1331, epoch: 34, loss: 0.325571
global_step: 1332, epoch: 34, loss: 0.447775
global_step: 1333, epoch: 34, loss: 0.480207
global_step: 1334, epoch: 34, loss: 0.509816
global_step: 1335, epoch: 34, loss: 0.461096
global_step: 1336, epoch: 34, loss: 0.394844
global_step: 1337, epoch: 34, loss: 0.405782
global_step: 1338, epoch: 34, loss: 0.505434
global_step: 1339, epoch: 34, loss: 0.453168
global_step: 1340, epoch: 34, loss: 0.472019
global_step: 1341, epoch: 34, loss: 0.315450
global_step: 1342, epoch: 34, loss: 0.549815
global_step: 1343, epoch: 34, loss: 0.506756
global_step: 1344, epoch: 34, loss: 0.544327
global_step: 1345, epoch: 34, loss: 0.455563
global_step: 1346, epoch: 34, loss: 0.453729
global_step: 1347, epoch: 34, loss: 0.429583
global_step: 1348, epoch: 34, loss: 0.423813
global_step: 1349, epoch: 34, loss: 0.458940
global_step: 1350, epoch: 34, loss: 0.458636
global_step: 1351, epoch: 34, loss: 0.425946
global_step: 1352, epoch: 34, loss: 0.468466
global_step: 1353, epoch: 34, loss: 0.526533
global_step: 1354, epoch: 34, loss: 0.528233
global_step: 1355, epoch: 34, loss: 0.453811
global_step: 1356, epoch: 34, loss: 0.491236
global_step: 1357, epoch: 34, loss: 0.526038
global_step: 1358, epoch: 34, loss: 0.478097
global_step: 1359, epoch: 34, loss: 0.484921
global_step: 1360, epoch: 34, loss: 0.970498
epoch: 34
train	acc: 0.9053	macro: p 0.8933, r 0.8427, f1: 0.8597	micro: p 0.9053, r 0.9053, f1 0.9053	weighted_f1:0.9044
dev	acc: 0.5528	macro: p 0.4484, r 0.3734, f1: 0.3637	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5252
test	acc: 0.5847	macro: p 0.4130, r 0.3727, f1: 0.3651	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5657
global_step: 1361, epoch: 35, loss: 0.580752
global_step: 1362, epoch: 35, loss: 0.519351
global_step: 1363, epoch: 35, loss: 0.474758
global_step: 1364, epoch: 35, loss: 0.454586
global_step: 1365, epoch: 35, loss: 0.529879
global_step: 1366, epoch: 35, loss: 0.466624
global_step: 1367, epoch: 35, loss: 0.465103
global_step: 1368, epoch: 35, loss: 0.397874
global_step: 1369, epoch: 35, loss: 0.393497
global_step: 1370, epoch: 35, loss: 0.381548
global_step: 1371, epoch: 35, loss: 0.432124
global_step: 1372, epoch: 35, loss: 0.409392
global_step: 1373, epoch: 35, loss: 0.478245
global_step: 1374, epoch: 35, loss: 0.385881
global_step: 1375, epoch: 35, loss: 0.485185
global_step: 1376, epoch: 35, loss: 0.470861
global_step: 1377, epoch: 35, loss: 0.409644
global_step: 1378, epoch: 35, loss: 0.321508
global_step: 1379, epoch: 35, loss: 0.332724
global_step: 1380, epoch: 35, loss: 0.436674
global_step: 1381, epoch: 35, loss: 0.392041
global_step: 1382, epoch: 35, loss: 0.407136
global_step: 1383, epoch: 35, loss: 0.483561
global_step: 1384, epoch: 35, loss: 0.484057
global_step: 1385, epoch: 35, loss: 0.401751
global_step: 1386, epoch: 35, loss: 0.402685
global_step: 1387, epoch: 35, loss: 0.469406
global_step: 1388, epoch: 35, loss: 0.437135
global_step: 1389, epoch: 35, loss: 0.392290
global_step: 1390, epoch: 35, loss: 0.451765
global_step: 1391, epoch: 35, loss: 0.508283
global_step: 1392, epoch: 35, loss: 0.461757
global_step: 1393, epoch: 35, loss: 0.480193
global_step: 1394, epoch: 35, loss: 0.390574
global_step: 1395, epoch: 35, loss: 0.436389
global_step: 1396, epoch: 35, loss: 0.485187
global_step: 1397, epoch: 35, loss: 0.421212
global_step: 1398, epoch: 35, loss: 0.364307
global_step: 1399, epoch: 35, loss: 0.510091
global_step: 1400, epoch: 35, loss: 0.795448
epoch: 35
train	acc: 0.9298	macro: p 0.9368, r 0.8889, f1: 0.9094	micro: p 0.9298, r 0.9298, f1 0.9298	weighted_f1:0.9298
dev	acc: 0.5455	macro: p 0.4276, r 0.3618, f1: 0.3659	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5253
test	acc: 0.5736	macro: p 0.3918, r 0.3653, f1: 0.3655	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5616
global_step: 1401, epoch: 36, loss: 0.468906
global_step: 1402, epoch: 36, loss: 0.303313
global_step: 1403, epoch: 36, loss: 0.327437
global_step: 1404, epoch: 36, loss: 0.498273
global_step: 1405, epoch: 36, loss: 0.391839
global_step: 1406, epoch: 36, loss: 0.433376
global_step: 1407, epoch: 36, loss: 0.399842
global_step: 1408, epoch: 36, loss: 0.349982
global_step: 1409, epoch: 36, loss: 0.396667
global_step: 1410, epoch: 36, loss: 0.407219
global_step: 1411, epoch: 36, loss: 0.379525
global_step: 1412, epoch: 36, loss: 0.439543
global_step: 1413, epoch: 36, loss: 0.357263
global_step: 1414, epoch: 36, loss: 0.410174
global_step: 1415, epoch: 36, loss: 0.497718
global_step: 1416, epoch: 36, loss: 0.348477
global_step: 1417, epoch: 36, loss: 0.386270
global_step: 1418, epoch: 36, loss: 0.461544
global_step: 1419, epoch: 36, loss: 0.375154
global_step: 1420, epoch: 36, loss: 0.456589
global_step: 1421, epoch: 36, loss: 0.412501
global_step: 1422, epoch: 36, loss: 0.404517
global_step: 1423, epoch: 36, loss: 0.341883
global_step: 1424, epoch: 36, loss: 0.386826
global_step: 1425, epoch: 36, loss: 0.467572
global_step: 1426, epoch: 36, loss: 0.489048
global_step: 1427, epoch: 36, loss: 0.428856
global_step: 1428, epoch: 36, loss: 0.354989
global_step: 1429, epoch: 36, loss: 0.435109
global_step: 1430, epoch: 36, loss: 0.469154
global_step: 1431, epoch: 36, loss: 0.433278
global_step: 1432, epoch: 36, loss: 0.366965
global_step: 1433, epoch: 36, loss: 0.334397
global_step: 1434, epoch: 36, loss: 0.500462
global_step: 1435, epoch: 36, loss: 0.515391
global_step: 1436, epoch: 36, loss: 0.489934
global_step: 1437, epoch: 36, loss: 0.372673
global_step: 1438, epoch: 36, loss: 0.429535
global_step: 1439, epoch: 36, loss: 0.340767
global_step: 1440, epoch: 36, loss: 0.301815
epoch: 36
train	acc: 0.9123	macro: p 0.9339, r 0.8389, f1: 0.8775	micro: p 0.9123, r 0.9123, f1 0.9123	weighted_f1:0.9108
dev	acc: 0.5546	macro: p 0.4492, r 0.3347, f1: 0.3391	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5081
test	acc: 0.5946	macro: p 0.4206, r 0.3336, f1: 0.3379	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5533
global_step: 1441, epoch: 37, loss: 0.426086
global_step: 1442, epoch: 37, loss: 0.385132
global_step: 1443, epoch: 37, loss: 0.380758
global_step: 1444, epoch: 37, loss: 0.306681
global_step: 1445, epoch: 37, loss: 0.381016
global_step: 1446, epoch: 37, loss: 0.471651
global_step: 1447, epoch: 37, loss: 0.513603
global_step: 1448, epoch: 37, loss: 0.458940
global_step: 1449, epoch: 37, loss: 0.417001
global_step: 1450, epoch: 37, loss: 0.420320
global_step: 1451, epoch: 37, loss: 0.368960
global_step: 1452, epoch: 37, loss: 0.370577
global_step: 1453, epoch: 37, loss: 0.423425
global_step: 1454, epoch: 37, loss: 0.349655
global_step: 1455, epoch: 37, loss: 0.477748
global_step: 1456, epoch: 37, loss: 0.345359
global_step: 1457, epoch: 37, loss: 0.387448
global_step: 1458, epoch: 37, loss: 0.336175
global_step: 1459, epoch: 37, loss: 0.513059
global_step: 1460, epoch: 37, loss: 0.358669
global_step: 1461, epoch: 37, loss: 0.431832
global_step: 1462, epoch: 37, loss: 0.365169
global_step: 1463, epoch: 37, loss: 0.374172
global_step: 1464, epoch: 37, loss: 0.472608
global_step: 1465, epoch: 37, loss: 0.458893
global_step: 1466, epoch: 37, loss: 0.498775
global_step: 1467, epoch: 37, loss: 0.482201
global_step: 1468, epoch: 37, loss: 0.446007
global_step: 1469, epoch: 37, loss: 0.452255
global_step: 1470, epoch: 37, loss: 0.470177
global_step: 1471, epoch: 37, loss: 0.370173
global_step: 1472, epoch: 37, loss: 0.468753
global_step: 1473, epoch: 37, loss: 0.395195
global_step: 1474, epoch: 37, loss: 0.546281
global_step: 1475, epoch: 37, loss: 0.467113
global_step: 1476, epoch: 37, loss: 0.451702
global_step: 1477, epoch: 37, loss: 0.394112
global_step: 1478, epoch: 37, loss: 0.411547
global_step: 1479, epoch: 37, loss: 0.428732
global_step: 1480, epoch: 37, loss: 0.072857
epoch: 37
train	acc: 0.9184	macro: p 0.9126, r 0.8749, f1: 0.8879	micro: p 0.9184, r 0.9184, f1 0.9184	weighted_f1:0.9192
dev	acc: 0.5401	macro: p 0.4078, r 0.3612, f1: 0.3636	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.5208
test	acc: 0.5648	macro: p 0.4110, r 0.3611, f1: 0.3689	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5580
global_step: 1481, epoch: 38, loss: 0.389232
global_step: 1482, epoch: 38, loss: 0.366151
global_step: 1483, epoch: 38, loss: 0.389116
global_step: 1484, epoch: 38, loss: 0.412949
global_step: 1485, epoch: 38, loss: 0.454604
global_step: 1486, epoch: 38, loss: 0.290590
global_step: 1487, epoch: 38, loss: 0.310274
global_step: 1488, epoch: 38, loss: 0.348177
global_step: 1489, epoch: 38, loss: 0.374284
global_step: 1490, epoch: 38, loss: 0.389639
global_step: 1491, epoch: 38, loss: 0.329205
global_step: 1492, epoch: 38, loss: 0.391659
global_step: 1493, epoch: 38, loss: 0.353169
global_step: 1494, epoch: 38, loss: 0.394320
global_step: 1495, epoch: 38, loss: 0.406700
global_step: 1496, epoch: 38, loss: 0.390769
global_step: 1497, epoch: 38, loss: 0.410119
global_step: 1498, epoch: 38, loss: 0.401371
global_step: 1499, epoch: 38, loss: 0.495751
global_step: 1500, epoch: 38, loss: 0.383554
global_step: 1501, epoch: 38, loss: 0.412739
global_step: 1502, epoch: 38, loss: 0.359110
global_step: 1503, epoch: 38, loss: 0.390026
global_step: 1504, epoch: 38, loss: 0.421622
global_step: 1505, epoch: 38, loss: 0.466866
global_step: 1506, epoch: 38, loss: 0.445179
global_step: 1507, epoch: 38, loss: 0.448338
global_step: 1508, epoch: 38, loss: 0.380050
global_step: 1509, epoch: 38, loss: 0.419413
global_step: 1510, epoch: 38, loss: 0.397204
global_step: 1511, epoch: 38, loss: 0.280359
global_step: 1512, epoch: 38, loss: 0.453967
global_step: 1513, epoch: 38, loss: 0.395854
global_step: 1514, epoch: 38, loss: 0.400094
global_step: 1515, epoch: 38, loss: 0.352374
global_step: 1516, epoch: 38, loss: 0.451348
global_step: 1517, epoch: 38, loss: 0.327098
global_step: 1518, epoch: 38, loss: 0.397765
global_step: 1519, epoch: 38, loss: 0.409391
global_step: 1520, epoch: 38, loss: 0.341052
epoch: 38
train	acc: 0.9312	macro: p 0.9442, r 0.8929, f1: 0.9169	micro: p 0.9312, r 0.9312, f1 0.9312	weighted_f1:0.9307
dev	acc: 0.5663	macro: p 0.4035, r 0.3489, f1: 0.3557	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5265
test	acc: 0.5935	macro: p 0.4131, r 0.3492, f1: 0.3645	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5637
global_step: 1521, epoch: 39, loss: 0.355733
global_step: 1522, epoch: 39, loss: 0.287937
global_step: 1523, epoch: 39, loss: 0.399481
global_step: 1524, epoch: 39, loss: 0.400347
global_step: 1525, epoch: 39, loss: 0.383426
global_step: 1526, epoch: 39, loss: 0.382326
global_step: 1527, epoch: 39, loss: 0.456858
global_step: 1528, epoch: 39, loss: 0.413835
global_step: 1529, epoch: 39, loss: 0.339653
global_step: 1530, epoch: 39, loss: 0.387342
global_step: 1531, epoch: 39, loss: 0.368964
global_step: 1532, epoch: 39, loss: 0.418792
global_step: 1533, epoch: 39, loss: 0.332586
global_step: 1534, epoch: 39, loss: 0.302139
global_step: 1535, epoch: 39, loss: 0.340574
global_step: 1536, epoch: 39, loss: 0.327011
global_step: 1537, epoch: 39, loss: 0.366792
global_step: 1538, epoch: 39, loss: 0.324818
global_step: 1539, epoch: 39, loss: 0.413935
global_step: 1540, epoch: 39, loss: 0.373006
global_step: 1541, epoch: 39, loss: 0.431911
global_step: 1542, epoch: 39, loss: 0.394678
global_step: 1543, epoch: 39, loss: 0.424760
global_step: 1544, epoch: 39, loss: 0.358836
global_step: 1545, epoch: 39, loss: 0.409347
global_step: 1546, epoch: 39, loss: 0.429664
global_step: 1547, epoch: 39, loss: 0.351077
global_step: 1548, epoch: 39, loss: 0.324403
global_step: 1549, epoch: 39, loss: 0.408686
global_step: 1550, epoch: 39, loss: 0.370926
global_step: 1551, epoch: 39, loss: 0.394433
global_step: 1552, epoch: 39, loss: 0.480797
global_step: 1553, epoch: 39, loss: 0.412478
global_step: 1554, epoch: 39, loss: 0.389015
global_step: 1555, epoch: 39, loss: 0.466772
global_step: 1556, epoch: 39, loss: 0.464604
global_step: 1557, epoch: 39, loss: 0.356761
global_step: 1558, epoch: 39, loss: 0.400356
global_step: 1559, epoch: 39, loss: 0.351456
global_step: 1560, epoch: 39, loss: 0.071940
epoch: 39
train	acc: 0.9358	macro: p 0.9484, r 0.8995, f1: 0.9224	micro: p 0.9358, r 0.9358, f1 0.9358	weighted_f1:0.9354
dev	acc: 0.5591	macro: p 0.3902, r 0.3537, f1: 0.3606	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5293
test	acc: 0.5805	macro: p 0.3812, r 0.3474, f1: 0.3547	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5585
global_step: 1561, epoch: 40, loss: 0.310760
global_step: 1562, epoch: 40, loss: 0.278036
global_step: 1563, epoch: 40, loss: 0.309849
global_step: 1564, epoch: 40, loss: 0.371658
global_step: 1565, epoch: 40, loss: 0.394034
global_step: 1566, epoch: 40, loss: 0.355514
global_step: 1567, epoch: 40, loss: 0.321453
global_step: 1568, epoch: 40, loss: 0.392345
global_step: 1569, epoch: 40, loss: 0.471096
global_step: 1570, epoch: 40, loss: 0.451688
global_step: 1571, epoch: 40, loss: 0.447286
global_step: 1572, epoch: 40, loss: 0.369102
global_step: 1573, epoch: 40, loss: 0.389100
global_step: 1574, epoch: 40, loss: 0.393343
global_step: 1575, epoch: 40, loss: 0.429934
global_step: 1576, epoch: 40, loss: 0.409742
global_step: 1577, epoch: 40, loss: 0.308973
global_step: 1578, epoch: 40, loss: 0.392176
global_step: 1579, epoch: 40, loss: 0.387155
global_step: 1580, epoch: 40, loss: 0.337150
global_step: 1581, epoch: 40, loss: 0.388267
global_step: 1582, epoch: 40, loss: 0.399107
global_step: 1583, epoch: 40, loss: 0.372652
global_step: 1584, epoch: 40, loss: 0.364994
global_step: 1585, epoch: 40, loss: 0.452896
global_step: 1586, epoch: 40, loss: 0.289290
global_step: 1587, epoch: 40, loss: 0.472543
global_step: 1588, epoch: 40, loss: 0.451888
global_step: 1589, epoch: 40, loss: 0.485712
global_step: 1590, epoch: 40, loss: 0.341010
global_step: 1591, epoch: 40, loss: 0.339083
global_step: 1592, epoch: 40, loss: 0.427992
global_step: 1593, epoch: 40, loss: 0.391006
global_step: 1594, epoch: 40, loss: 0.432500
global_step: 1595, epoch: 40, loss: 0.348797
global_step: 1596, epoch: 40, loss: 0.403726
global_step: 1597, epoch: 40, loss: 0.474264
global_step: 1598, epoch: 40, loss: 0.465612
global_step: 1599, epoch: 40, loss: 0.394285
global_step: 1600, epoch: 40, loss: 0.039938
epoch: 40
train	acc: 0.9375	macro: p 0.9457, r 0.9031, f1: 0.9226	micro: p 0.9375, r 0.9375, f1 0.9375	weighted_f1:0.9373
dev	acc: 0.5491	macro: p 0.3968, r 0.3452, f1: 0.3548	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5223
test	acc: 0.5877	macro: p 0.3985, r 0.3535, f1: 0.3640	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5691
global_step: 1601, epoch: 41, loss: 0.427003
global_step: 1602, epoch: 41, loss: 0.375687
global_step: 1603, epoch: 41, loss: 0.417073
global_step: 1604, epoch: 41, loss: 0.352684
global_step: 1605, epoch: 41, loss: 0.420677
global_step: 1606, epoch: 41, loss: 0.344980
global_step: 1607, epoch: 41, loss: 0.378474
global_step: 1608, epoch: 41, loss: 0.332982
global_step: 1609, epoch: 41, loss: 0.401854
global_step: 1610, epoch: 41, loss: 0.360908
global_step: 1611, epoch: 41, loss: 0.372867
global_step: 1612, epoch: 41, loss: 0.464670
global_step: 1613, epoch: 41, loss: 0.282162
global_step: 1614, epoch: 41, loss: 0.308418
global_step: 1615, epoch: 41, loss: 0.326271
global_step: 1616, epoch: 41, loss: 0.320580
global_step: 1617, epoch: 41, loss: 0.383171
global_step: 1618, epoch: 41, loss: 0.353169
global_step: 1619, epoch: 41, loss: 0.368239
global_step: 1620, epoch: 41, loss: 0.384802
global_step: 1621, epoch: 41, loss: 0.388577
global_step: 1622, epoch: 41, loss: 0.380686
global_step: 1623, epoch: 41, loss: 0.469693
global_step: 1624, epoch: 41, loss: 0.384414
global_step: 1625, epoch: 41, loss: 0.409365
global_step: 1626, epoch: 41, loss: 0.268933
global_step: 1627, epoch: 41, loss: 0.327429
global_step: 1628, epoch: 41, loss: 0.491371
global_step: 1629, epoch: 41, loss: 0.383251
global_step: 1630, epoch: 41, loss: 0.458570
global_step: 1631, epoch: 41, loss: 0.519054
global_step: 1632, epoch: 41, loss: 0.405928
global_step: 1633, epoch: 41, loss: 0.416138
global_step: 1634, epoch: 41, loss: 0.352568
global_step: 1635, epoch: 41, loss: 0.478045
global_step: 1636, epoch: 41, loss: 0.389163
global_step: 1637, epoch: 41, loss: 0.390578
global_step: 1638, epoch: 41, loss: 0.416632
global_step: 1639, epoch: 41, loss: 0.401193
global_step: 1640, epoch: 41, loss: 1.069049
epoch: 41
train	acc: 0.9366	macro: p 0.9503, r 0.9000, f1: 0.9233	micro: p 0.9366, r 0.9366, f1 0.9366	weighted_f1:0.9363
dev	acc: 0.5681	macro: p 0.4320, r 0.3506, f1: 0.3656	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5312
test	acc: 0.5935	macro: p 0.4120, r 0.3446, f1: 0.3571	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5608
global_step: 1641, epoch: 42, loss: 0.322686
global_step: 1642, epoch: 42, loss: 0.259378
global_step: 1643, epoch: 42, loss: 0.412523
global_step: 1644, epoch: 42, loss: 0.305828
global_step: 1645, epoch: 42, loss: 0.324338
global_step: 1646, epoch: 42, loss: 0.322301
global_step: 1647, epoch: 42, loss: 0.358978
global_step: 1648, epoch: 42, loss: 0.349321
global_step: 1649, epoch: 42, loss: 0.433573
global_step: 1650, epoch: 42, loss: 0.394215
global_step: 1651, epoch: 42, loss: 0.354224
global_step: 1652, epoch: 42, loss: 0.273469
global_step: 1653, epoch: 42, loss: 0.305742
global_step: 1654, epoch: 42, loss: 0.341667
global_step: 1655, epoch: 42, loss: 0.341451
global_step: 1656, epoch: 42, loss: 0.412382
global_step: 1657, epoch: 42, loss: 0.310210
global_step: 1658, epoch: 42, loss: 0.338191
global_step: 1659, epoch: 42, loss: 0.353458
global_step: 1660, epoch: 42, loss: 0.376493
global_step: 1661, epoch: 42, loss: 0.413285
global_step: 1662, epoch: 42, loss: 0.292307
global_step: 1663, epoch: 42, loss: 0.343279
global_step: 1664, epoch: 42, loss: 0.371754
global_step: 1665, epoch: 42, loss: 0.346821
global_step: 1666, epoch: 42, loss: 0.337626
global_step: 1667, epoch: 42, loss: 0.314381
global_step: 1668, epoch: 42, loss: 0.362883
global_step: 1669, epoch: 42, loss: 0.376445
global_step: 1670, epoch: 42, loss: 0.338519
global_step: 1671, epoch: 42, loss: 0.347811
global_step: 1672, epoch: 42, loss: 0.376516
global_step: 1673, epoch: 42, loss: 0.477408
global_step: 1674, epoch: 42, loss: 0.467289
global_step: 1675, epoch: 42, loss: 0.522803
global_step: 1676, epoch: 42, loss: 0.400307
global_step: 1677, epoch: 42, loss: 0.311566
global_step: 1678, epoch: 42, loss: 0.344902
global_step: 1679, epoch: 42, loss: 0.365679
global_step: 1680, epoch: 42, loss: 0.295425
epoch: 42
train	acc: 0.9167	macro: p 0.9416, r 0.8614, f1: 0.8959	micro: p 0.9167, r 0.9167, f1 0.9167	weighted_f1:0.9156
dev	acc: 0.5717	macro: p 0.4637, r 0.3463, f1: 0.3540	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5238
test	acc: 0.5989	macro: p 0.4301, r 0.3373, f1: 0.3439	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5564
global_step: 1681, epoch: 43, loss: 0.401743
global_step: 1682, epoch: 43, loss: 0.339847
global_step: 1683, epoch: 43, loss: 0.405397
global_step: 1684, epoch: 43, loss: 0.361793
global_step: 1685, epoch: 43, loss: 0.390689
global_step: 1686, epoch: 43, loss: 0.377137
global_step: 1687, epoch: 43, loss: 0.429626
global_step: 1688, epoch: 43, loss: 0.418140
global_step: 1689, epoch: 43, loss: 0.329925
global_step: 1690, epoch: 43, loss: 0.337766
global_step: 1691, epoch: 43, loss: 0.349603
global_step: 1692, epoch: 43, loss: 0.242696
global_step: 1693, epoch: 43, loss: 0.493971
global_step: 1694, epoch: 43, loss: 0.303758
global_step: 1695, epoch: 43, loss: 0.372572
global_step: 1696, epoch: 43, loss: 0.324968
global_step: 1697, epoch: 43, loss: 0.299767
global_step: 1698, epoch: 43, loss: 0.336097
global_step: 1699, epoch: 43, loss: 0.474864
global_step: 1700, epoch: 43, loss: 0.391951
global_step: 1701, epoch: 43, loss: 0.331916
global_step: 1702, epoch: 43, loss: 0.346103
global_step: 1703, epoch: 43, loss: 0.366129
global_step: 1704, epoch: 43, loss: 0.307763
global_step: 1705, epoch: 43, loss: 0.347900
global_step: 1706, epoch: 43, loss: 0.290517
global_step: 1707, epoch: 43, loss: 0.328458
global_step: 1708, epoch: 43, loss: 0.265772
global_step: 1709, epoch: 43, loss: 0.344098
global_step: 1710, epoch: 43, loss: 0.394600
global_step: 1711, epoch: 43, loss: 0.377950
global_step: 1712, epoch: 43, loss: 0.429967
global_step: 1713, epoch: 43, loss: 0.358959
global_step: 1714, epoch: 43, loss: 0.411769
global_step: 1715, epoch: 43, loss: 0.450067
global_step: 1716, epoch: 43, loss: 0.316523
global_step: 1717, epoch: 43, loss: 0.480967
global_step: 1718, epoch: 43, loss: 0.453512
global_step: 1719, epoch: 43, loss: 0.361352
global_step: 1720, epoch: 43, loss: 0.132294
epoch: 43
train	acc: 0.9366	macro: p 0.9496, r 0.8992, f1: 0.9221	micro: p 0.9366, r 0.9366, f1 0.9366	weighted_f1:0.9362
dev	acc: 0.5518	macro: p 0.4299, r 0.3396, f1: 0.3491	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5146
test	acc: 0.5904	macro: p 0.4209, r 0.3416, f1: 0.3567	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5620
global_step: 1721, epoch: 44, loss: 0.367211
global_step: 1722, epoch: 44, loss: 0.357480
global_step: 1723, epoch: 44, loss: 0.356336
global_step: 1724, epoch: 44, loss: 0.286945
global_step: 1725, epoch: 44, loss: 0.366084
global_step: 1726, epoch: 44, loss: 0.296545
global_step: 1727, epoch: 44, loss: 0.341645
global_step: 1728, epoch: 44, loss: 0.303655
global_step: 1729, epoch: 44, loss: 0.299187
global_step: 1730, epoch: 44, loss: 0.335671
global_step: 1731, epoch: 44, loss: 0.329656
global_step: 1732, epoch: 44, loss: 0.322255
global_step: 1733, epoch: 44, loss: 0.375540
global_step: 1734, epoch: 44, loss: 0.342227
global_step: 1735, epoch: 44, loss: 0.296679
global_step: 1736, epoch: 44, loss: 0.399218
global_step: 1737, epoch: 44, loss: 0.446678
global_step: 1738, epoch: 44, loss: 0.304166
global_step: 1739, epoch: 44, loss: 0.324611
global_step: 1740, epoch: 44, loss: 0.417025
global_step: 1741, epoch: 44, loss: 0.306266
global_step: 1742, epoch: 44, loss: 0.376910
global_step: 1743, epoch: 44, loss: 0.346455
global_step: 1744, epoch: 44, loss: 0.300095
global_step: 1745, epoch: 44, loss: 0.365449
global_step: 1746, epoch: 44, loss: 0.374913
global_step: 1747, epoch: 44, loss: 0.351121
global_step: 1748, epoch: 44, loss: 0.324425
global_step: 1749, epoch: 44, loss: 0.342805
global_step: 1750, epoch: 44, loss: 0.408924
global_step: 1751, epoch: 44, loss: 0.299450
global_step: 1752, epoch: 44, loss: 0.285616
global_step: 1753, epoch: 44, loss: 0.337371
global_step: 1754, epoch: 44, loss: 0.395916
global_step: 1755, epoch: 44, loss: 0.360809
global_step: 1756, epoch: 44, loss: 0.477553
global_step: 1757, epoch: 44, loss: 0.449635
global_step: 1758, epoch: 44, loss: 0.400191
global_step: 1759, epoch: 44, loss: 0.312872
global_step: 1760, epoch: 44, loss: 0.286623
epoch: 44
train	acc: 0.9348	macro: p 0.9533, r 0.8923, f1: 0.9199	micro: p 0.9348, r 0.9348, f1 0.9348	weighted_f1:0.9343
dev	acc: 0.5654	macro: p 0.4443, r 0.3404, f1: 0.3545	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5254
test	acc: 0.6011	macro: p 0.4455, r 0.3408, f1: 0.3625	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5653
global_step: 1761, epoch: 45, loss: 0.368757
global_step: 1762, epoch: 45, loss: 0.284777
global_step: 1763, epoch: 45, loss: 0.304252
global_step: 1764, epoch: 45, loss: 0.465514
global_step: 1765, epoch: 45, loss: 0.369767
global_step: 1766, epoch: 45, loss: 0.332492
global_step: 1767, epoch: 45, loss: 0.369655
global_step: 1768, epoch: 45, loss: 0.406547
global_step: 1769, epoch: 45, loss: 0.365978
global_step: 1770, epoch: 45, loss: 0.400371
global_step: 1771, epoch: 45, loss: 0.266486
global_step: 1772, epoch: 45, loss: 0.298695
global_step: 1773, epoch: 45, loss: 0.279269
global_step: 1774, epoch: 45, loss: 0.321530
global_step: 1775, epoch: 45, loss: 0.311175
global_step: 1776, epoch: 45, loss: 0.411482
global_step: 1777, epoch: 45, loss: 0.478186
global_step: 1778, epoch: 45, loss: 0.358307
global_step: 1779, epoch: 45, loss: 0.410408
global_step: 1780, epoch: 45, loss: 0.377817
global_step: 1781, epoch: 45, loss: 0.399772
global_step: 1782, epoch: 45, loss: 0.295046
global_step: 1783, epoch: 45, loss: 0.288492
global_step: 1784, epoch: 45, loss: 0.285200
global_step: 1785, epoch: 45, loss: 0.307499
global_step: 1786, epoch: 45, loss: 0.393277
global_step: 1787, epoch: 45, loss: 0.353932
global_step: 1788, epoch: 45, loss: 0.379576
global_step: 1789, epoch: 45, loss: 0.320683
global_step: 1790, epoch: 45, loss: 0.397480
global_step: 1791, epoch: 45, loss: 0.486922
global_step: 1792, epoch: 45, loss: 0.357954
global_step: 1793, epoch: 45, loss: 0.360381
global_step: 1794, epoch: 45, loss: 0.418216
global_step: 1795, epoch: 45, loss: 0.442703
global_step: 1796, epoch: 45, loss: 0.326995
global_step: 1797, epoch: 45, loss: 0.501961
global_step: 1798, epoch: 45, loss: 0.355805
global_step: 1799, epoch: 45, loss: 0.340292
global_step: 1800, epoch: 45, loss: 0.007253
epoch: 45
train	acc: 0.9457	macro: p 0.9529, r 0.9198, f1: 0.9350	micro: p 0.9457, r 0.9457, f1 0.9457	weighted_f1:0.9457
dev	acc: 0.5383	macro: p 0.3867, r 0.3467, f1: 0.3481	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5110
test	acc: 0.5835	macro: p 0.4042, r 0.3646, f1: 0.3688	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5622
global_step: 1801, epoch: 46, loss: 0.319637
global_step: 1802, epoch: 46, loss: 0.303704
global_step: 1803, epoch: 46, loss: 0.302339
global_step: 1804, epoch: 46, loss: 0.245879
global_step: 1805, epoch: 46, loss: 0.289301
global_step: 1806, epoch: 46, loss: 0.273128
global_step: 1807, epoch: 46, loss: 0.257463
global_step: 1808, epoch: 46, loss: 0.349394
global_step: 1809, epoch: 46, loss: 0.307032
global_step: 1810, epoch: 46, loss: 0.455515
global_step: 1811, epoch: 46, loss: 0.315843
global_step: 1812, epoch: 46, loss: 0.402528
global_step: 1813, epoch: 46, loss: 0.366098
global_step: 1814, epoch: 46, loss: 0.388812
global_step: 1815, epoch: 46, loss: 0.314637
global_step: 1816, epoch: 46, loss: 0.291461
global_step: 1817, epoch: 46, loss: 0.306742
global_step: 1818, epoch: 46, loss: 0.299214
global_step: 1819, epoch: 46, loss: 0.334395
global_step: 1820, epoch: 46, loss: 0.330708
global_step: 1821, epoch: 46, loss: 0.337495
global_step: 1822, epoch: 46, loss: 0.339783
global_step: 1823, epoch: 46, loss: 0.417442
global_step: 1824, epoch: 46, loss: 0.333687
global_step: 1825, epoch: 46, loss: 0.287378
global_step: 1826, epoch: 46, loss: 0.340494
global_step: 1827, epoch: 46, loss: 0.339682
global_step: 1828, epoch: 46, loss: 0.389553
global_step: 1829, epoch: 46, loss: 0.382645
global_step: 1830, epoch: 46, loss: 0.344750
global_step: 1831, epoch: 46, loss: 0.361892
global_step: 1832, epoch: 46, loss: 0.374092
global_step: 1833, epoch: 46, loss: 0.426642
global_step: 1834, epoch: 46, loss: 0.379772
global_step: 1835, epoch: 46, loss: 0.352871
global_step: 1836, epoch: 46, loss: 0.433594
global_step: 1837, epoch: 46, loss: 0.319693
global_step: 1838, epoch: 46, loss: 0.247565
global_step: 1839, epoch: 46, loss: 0.351981
global_step: 1840, epoch: 46, loss: 0.722158
epoch: 46
train	acc: 0.9077	macro: p 0.9209, r 0.8713, f1: 0.8874	micro: p 0.9077, r 0.9077, f1 0.9077	weighted_f1:0.9078
dev	acc: 0.5482	macro: p 0.4516, r 0.3590, f1: 0.3487	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5066
test	acc: 0.5467	macro: p 0.3752, r 0.3312, f1: 0.3063	micro: p 0.5467, r 0.5467, f1 0.5467	weighted_f1:0.5129
global_step: 1841, epoch: 47, loss: 0.341830
global_step: 1842, epoch: 47, loss: 0.363691
global_step: 1843, epoch: 47, loss: 0.368587
global_step: 1844, epoch: 47, loss: 0.272057
global_step: 1845, epoch: 47, loss: 0.363070
global_step: 1846, epoch: 47, loss: 0.317528
global_step: 1847, epoch: 47, loss: 0.324291
global_step: 1848, epoch: 47, loss: 0.374006
global_step: 1849, epoch: 47, loss: 0.242389
global_step: 1850, epoch: 47, loss: 0.247647
global_step: 1851, epoch: 47, loss: 0.362296
global_step: 1852, epoch: 47, loss: 0.360297
global_step: 1853, epoch: 47, loss: 0.383049
global_step: 1854, epoch: 47, loss: 0.371648
global_step: 1855, epoch: 47, loss: 0.303830
global_step: 1856, epoch: 47, loss: 0.261188
global_step: 1857, epoch: 47, loss: 0.301371
global_step: 1858, epoch: 47, loss: 0.370468
global_step: 1859, epoch: 47, loss: 0.266919
global_step: 1860, epoch: 47, loss: 0.319300
global_step: 1861, epoch: 47, loss: 0.434456
global_step: 1862, epoch: 47, loss: 0.236442
global_step: 1863, epoch: 47, loss: 0.353071
global_step: 1864, epoch: 47, loss: 0.339044
global_step: 1865, epoch: 47, loss: 0.380102
global_step: 1866, epoch: 47, loss: 0.388300
global_step: 1867, epoch: 47, loss: 0.311778
global_step: 1868, epoch: 47, loss: 0.409186
global_step: 1869, epoch: 47, loss: 0.393900
global_step: 1870, epoch: 47, loss: 0.326638
global_step: 1871, epoch: 47, loss: 0.276670
global_step: 1872, epoch: 47, loss: 0.326515
global_step: 1873, epoch: 47, loss: 0.184597
global_step: 1874, epoch: 47, loss: 0.420770
global_step: 1875, epoch: 47, loss: 0.272826
global_step: 1876, epoch: 47, loss: 0.341701
global_step: 1877, epoch: 47, loss: 0.280719
global_step: 1878, epoch: 47, loss: 0.383413
global_step: 1879, epoch: 47, loss: 0.385001
global_step: 1880, epoch: 47, loss: 0.178960
epoch: 47
train	acc: 0.9478	macro: p 0.9516, r 0.9224, f1: 0.9360	micro: p 0.9478, r 0.9478, f1 0.9478	weighted_f1:0.9478
dev	acc: 0.5491	macro: p 0.4076, r 0.3582, f1: 0.3699	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5224
test	acc: 0.5820	macro: p 0.3824, r 0.3522, f1: 0.3588	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5596
global_step: 1881, epoch: 48, loss: 0.278762
global_step: 1882, epoch: 48, loss: 0.364837
global_step: 1883, epoch: 48, loss: 0.353626
global_step: 1884, epoch: 48, loss: 0.345331
global_step: 1885, epoch: 48, loss: 0.286088
global_step: 1886, epoch: 48, loss: 0.342832
global_step: 1887, epoch: 48, loss: 0.267303
global_step: 1888, epoch: 48, loss: 0.337994
global_step: 1889, epoch: 48, loss: 0.325225
global_step: 1890, epoch: 48, loss: 0.323236
global_step: 1891, epoch: 48, loss: 0.345410
global_step: 1892, epoch: 48, loss: 0.298179
global_step: 1893, epoch: 48, loss: 0.369737
global_step: 1894, epoch: 48, loss: 0.347825
global_step: 1895, epoch: 48, loss: 0.275432
global_step: 1896, epoch: 48, loss: 0.286196
global_step: 1897, epoch: 48, loss: 0.464929
global_step: 1898, epoch: 48, loss: 0.346804
global_step: 1899, epoch: 48, loss: 0.255490
global_step: 1900, epoch: 48, loss: 0.282978
global_step: 1901, epoch: 48, loss: 0.322023
global_step: 1902, epoch: 48, loss: 0.316000
global_step: 1903, epoch: 48, loss: 0.290299
global_step: 1904, epoch: 48, loss: 0.276016
global_step: 1905, epoch: 48, loss: 0.287616
global_step: 1906, epoch: 48, loss: 0.270383
global_step: 1907, epoch: 48, loss: 0.323586
global_step: 1908, epoch: 48, loss: 0.309222
global_step: 1909, epoch: 48, loss: 0.403810
global_step: 1910, epoch: 48, loss: 0.264185
global_step: 1911, epoch: 48, loss: 0.330197
global_step: 1912, epoch: 48, loss: 0.326729
global_step: 1913, epoch: 48, loss: 0.339295
global_step: 1914, epoch: 48, loss: 0.318550
global_step: 1915, epoch: 48, loss: 0.350507
global_step: 1916, epoch: 48, loss: 0.423991
global_step: 1917, epoch: 48, loss: 0.261824
global_step: 1918, epoch: 48, loss: 0.293737
global_step: 1919, epoch: 48, loss: 0.397659
global_step: 1920, epoch: 48, loss: 0.043628
epoch: 48
train	acc: 0.9357	macro: p 0.9508, r 0.8989, f1: 0.9219	micro: p 0.9357, r 0.9357, f1 0.9357	weighted_f1:0.9353
dev	acc: 0.5491	macro: p 0.4419, r 0.3313, f1: 0.3271	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5011
test	acc: 0.5812	macro: p 0.4190, r 0.3325, f1: 0.3306	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5414
global_step: 1921, epoch: 49, loss: 0.327198
global_step: 1922, epoch: 49, loss: 0.346245
global_step: 1923, epoch: 49, loss: 0.338630
global_step: 1924, epoch: 49, loss: 0.397976
global_step: 1925, epoch: 49, loss: 0.275883
global_step: 1926, epoch: 49, loss: 0.278329
global_step: 1927, epoch: 49, loss: 0.280131
global_step: 1928, epoch: 49, loss: 0.357906
global_step: 1929, epoch: 49, loss: 0.313130
global_step: 1930, epoch: 49, loss: 0.350585
global_step: 1931, epoch: 49, loss: 0.387446
global_step: 1932, epoch: 49, loss: 0.313583
global_step: 1933, epoch: 49, loss: 0.285245
global_step: 1934, epoch: 49, loss: 0.351507
global_step: 1935, epoch: 49, loss: 0.287421
global_step: 1936, epoch: 49, loss: 0.282979
global_step: 1937, epoch: 49, loss: 0.284759
global_step: 1938, epoch: 49, loss: 0.304560
global_step: 1939, epoch: 49, loss: 0.264759
global_step: 1940, epoch: 49, loss: 0.302414
global_step: 1941, epoch: 49, loss: 0.306124
global_step: 1942, epoch: 49, loss: 0.329809
global_step: 1943, epoch: 49, loss: 0.405043
global_step: 1944, epoch: 49, loss: 0.297094
global_step: 1945, epoch: 49, loss: 0.300110
global_step: 1946, epoch: 49, loss: 0.254875
global_step: 1947, epoch: 49, loss: 0.302599
global_step: 1948, epoch: 49, loss: 0.321620
global_step: 1949, epoch: 49, loss: 0.469643
global_step: 1950, epoch: 49, loss: 0.319436
global_step: 1951, epoch: 49, loss: 0.416657
global_step: 1952, epoch: 49, loss: 0.324038
global_step: 1953, epoch: 49, loss: 0.271336
global_step: 1954, epoch: 49, loss: 0.272137
global_step: 1955, epoch: 49, loss: 0.409262
global_step: 1956, epoch: 49, loss: 0.417803
global_step: 1957, epoch: 49, loss: 0.374070
global_step: 1958, epoch: 49, loss: 0.363696
global_step: 1959, epoch: 49, loss: 0.369580
global_step: 1960, epoch: 49, loss: 0.564774
epoch: 49
train	acc: 0.9341	macro: p 0.9414, r 0.9138, f1: 0.9258	micro: p 0.9341, r 0.9341, f1 0.9341	weighted_f1:0.9347
dev	acc: 0.5230	macro: p 0.3865, r 0.3518, f1: 0.3493	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.5118
test	acc: 0.5356	macro: p 0.3627, r 0.3455, f1: 0.3429	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.5335
global_step: 1961, epoch: 50, loss: 0.322650
global_step: 1962, epoch: 50, loss: 0.314504
global_step: 1963, epoch: 50, loss: 0.336494
global_step: 1964, epoch: 50, loss: 0.366419
global_step: 1965, epoch: 50, loss: 0.306391
global_step: 1966, epoch: 50, loss: 0.291138
global_step: 1967, epoch: 50, loss: 0.369623
global_step: 1968, epoch: 50, loss: 0.275533
global_step: 1969, epoch: 50, loss: 0.322997
global_step: 1970, epoch: 50, loss: 0.370749
global_step: 1971, epoch: 50, loss: 0.361834
global_step: 1972, epoch: 50, loss: 0.317730
global_step: 1973, epoch: 50, loss: 0.323063
global_step: 1974, epoch: 50, loss: 0.274139
global_step: 1975, epoch: 50, loss: 0.291075
global_step: 1976, epoch: 50, loss: 0.269141
global_step: 1977, epoch: 50, loss: 0.383220
global_step: 1978, epoch: 50, loss: 0.289078
global_step: 1979, epoch: 50, loss: 0.278384
global_step: 1980, epoch: 50, loss: 0.270560
global_step: 1981, epoch: 50, loss: 0.351830
global_step: 1982, epoch: 50, loss: 0.280464
global_step: 1983, epoch: 50, loss: 0.319101
global_step: 1984, epoch: 50, loss: 0.348670
global_step: 1985, epoch: 50, loss: 0.329263
global_step: 1986, epoch: 50, loss: 0.317131
global_step: 1987, epoch: 50, loss: 0.347482
global_step: 1988, epoch: 50, loss: 0.285308
global_step: 1989, epoch: 50, loss: 0.318662
global_step: 1990, epoch: 50, loss: 0.309775
global_step: 1991, epoch: 50, loss: 0.290656
global_step: 1992, epoch: 50, loss: 0.269365
global_step: 1993, epoch: 50, loss: 0.357731
global_step: 1994, epoch: 50, loss: 0.398695
global_step: 1995, epoch: 50, loss: 0.328586
global_step: 1996, epoch: 50, loss: 0.298097
global_step: 1997, epoch: 50, loss: 0.439547
global_step: 1998, epoch: 50, loss: 0.193695
global_step: 1999, epoch: 50, loss: 0.412031
global_step: 2000, epoch: 50, loss: 0.042912
epoch: 50
train	acc: 0.9465	macro: p 0.9584, r 0.9178, f1: 0.9364	micro: p 0.9465, r 0.9465, f1 0.9465	weighted_f1:0.9465
dev	acc: 0.5374	macro: p 0.4044, r 0.3454, f1: 0.3449	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5096
test	acc: 0.5690	macro: p 0.4015, r 0.3403, f1: 0.3442	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5447
BEST MODEL epoch: 32
train	acc: 0.9202 macro_p: 0.9347 macro_r: 0.8635 macro_f1: 0.8941 micro_p: 0.9202 micro_r: 0.9202 micro_f1: 0.9202 weighted_f1: 0.9195
dev	acc: 0.5717 macro_p: 0.4445 macro_r: 0.3597 macro_f1: 0.3703 micro_p: 0.5717 micro_r: 0.5717 micro_f1: 0.5717 weighted_f1: 0.5337
test	acc: 0.6019 macro_p: 0.4127 macro_r: 0.3581 macro_f1: 0.3640 micro_p: 0.6019 micro_r: 0.6019 micro_f1: 0.6019 weighted_f1: 0.5717
==========ROUND 2==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 2001, epoch: 1, loss: 1.904235
global_step: 2002, epoch: 1, loss: 1.773226
global_step: 2003, epoch: 1, loss: 1.624722
global_step: 2004, epoch: 1, loss: 1.715725
global_step: 2005, epoch: 1, loss: 1.636320
global_step: 2006, epoch: 1, loss: 1.487356
global_step: 2007, epoch: 1, loss: 1.582146
global_step: 2008, epoch: 1, loss: 1.420122
global_step: 2009, epoch: 1, loss: 1.514792
global_step: 2010, epoch: 1, loss: 1.547589
global_step: 2011, epoch: 1, loss: 1.512435
global_step: 2012, epoch: 1, loss: 1.505032
global_step: 2013, epoch: 1, loss: 1.558048
global_step: 2014, epoch: 1, loss: 1.519647
global_step: 2015, epoch: 1, loss: 1.396973
global_step: 2016, epoch: 1, loss: 1.437710
global_step: 2017, epoch: 1, loss: 1.494488
global_step: 2018, epoch: 1, loss: 1.465691
global_step: 2019, epoch: 1, loss: 1.473655
global_step: 2020, epoch: 1, loss: 1.357128
global_step: 2021, epoch: 1, loss: 1.472594
global_step: 2022, epoch: 1, loss: 1.506266
global_step: 2023, epoch: 1, loss: 1.525739
global_step: 2024, epoch: 1, loss: 1.547247
global_step: 2025, epoch: 1, loss: 1.451438
global_step: 2026, epoch: 1, loss: 1.443351
global_step: 2027, epoch: 1, loss: 1.383312
global_step: 2028, epoch: 1, loss: 1.460125
global_step: 2029, epoch: 1, loss: 1.440290
global_step: 2030, epoch: 1, loss: 1.458122
global_step: 2031, epoch: 1, loss: 1.386760
global_step: 2032, epoch: 1, loss: 1.232958
global_step: 2033, epoch: 1, loss: 1.481992
global_step: 2034, epoch: 1, loss: 1.428365
global_step: 2035, epoch: 1, loss: 1.196199
global_step: 2036, epoch: 1, loss: 1.439211
global_step: 2037, epoch: 1, loss: 1.315958
global_step: 2038, epoch: 1, loss: 1.450406
global_step: 2039, epoch: 1, loss: 1.333841
global_step: 2040, epoch: 1, loss: 1.266009
epoch: 1
train	acc: 0.5588	macro: p 0.2408, r 0.2354, f1: 0.2073	micro: p 0.5588, r 0.5588, f1 0.5588	weighted_f1:0.4611
dev	acc: 0.5095	macro: p 0.2284, r 0.2419, f1: 0.2009	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4008
test	acc: 0.5651	macro: p 0.2359, r 0.2465, f1: 0.2146	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.4667
New best model!
global_step: 2041, epoch: 2, loss: 1.436351
global_step: 2042, epoch: 2, loss: 1.421175
global_step: 2043, epoch: 2, loss: 1.439530
global_step: 2044, epoch: 2, loss: 1.324648
global_step: 2045, epoch: 2, loss: 1.350426
global_step: 2046, epoch: 2, loss: 1.368735
global_step: 2047, epoch: 2, loss: 1.252367
global_step: 2048, epoch: 2, loss: 1.434834
global_step: 2049, epoch: 2, loss: 1.414111
global_step: 2050, epoch: 2, loss: 1.326676
global_step: 2051, epoch: 2, loss: 1.351616
global_step: 2052, epoch: 2, loss: 1.417295
global_step: 2053, epoch: 2, loss: 1.474018
global_step: 2054, epoch: 2, loss: 1.418831
global_step: 2055, epoch: 2, loss: 1.258477
global_step: 2056, epoch: 2, loss: 1.381604
global_step: 2057, epoch: 2, loss: 1.358813
global_step: 2058, epoch: 2, loss: 1.320505
global_step: 2059, epoch: 2, loss: 1.307794
global_step: 2060, epoch: 2, loss: 1.237996
global_step: 2061, epoch: 2, loss: 1.349660
global_step: 2062, epoch: 2, loss: 1.454849
global_step: 2063, epoch: 2, loss: 1.336368
global_step: 2064, epoch: 2, loss: 1.394209
global_step: 2065, epoch: 2, loss: 1.283284
global_step: 2066, epoch: 2, loss: 1.330196
global_step: 2067, epoch: 2, loss: 1.311152
global_step: 2068, epoch: 2, loss: 1.310035
global_step: 2069, epoch: 2, loss: 1.340665
global_step: 2070, epoch: 2, loss: 1.405910
global_step: 2071, epoch: 2, loss: 1.264488
global_step: 2072, epoch: 2, loss: 1.240918
global_step: 2073, epoch: 2, loss: 1.196343
global_step: 2074, epoch: 2, loss: 1.357328
global_step: 2075, epoch: 2, loss: 1.284406
global_step: 2076, epoch: 2, loss: 1.146905
global_step: 2077, epoch: 2, loss: 1.175640
global_step: 2078, epoch: 2, loss: 1.274016
global_step: 2079, epoch: 2, loss: 1.322758
global_step: 2080, epoch: 2, loss: 0.533873
epoch: 2
train	acc: 0.5477	macro: p 0.2695, r 0.2176, f1: 0.1815	micro: p 0.5477, r 0.5477, f1 0.5477	weighted_f1:0.4360
dev	acc: 0.4968	macro: p 0.2656, r 0.2245, f1: 0.1769	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.3762
test	acc: 0.5556	macro: p 0.2805, r 0.2270, f1: 0.1888	micro: p 0.5556, r 0.5556, f1 0.5556	weighted_f1:0.4438
global_step: 2081, epoch: 3, loss: 1.517344
global_step: 2082, epoch: 3, loss: 1.458421
global_step: 2083, epoch: 3, loss: 1.178482
global_step: 2084, epoch: 3, loss: 1.302708
global_step: 2085, epoch: 3, loss: 1.156915
global_step: 2086, epoch: 3, loss: 1.312989
global_step: 2087, epoch: 3, loss: 1.258772
global_step: 2088, epoch: 3, loss: 1.343614
global_step: 2089, epoch: 3, loss: 1.259326
global_step: 2090, epoch: 3, loss: 1.395267
global_step: 2091, epoch: 3, loss: 1.318488
global_step: 2092, epoch: 3, loss: 1.323782
global_step: 2093, epoch: 3, loss: 1.263695
global_step: 2094, epoch: 3, loss: 1.324758
global_step: 2095, epoch: 3, loss: 1.297322
global_step: 2096, epoch: 3, loss: 1.196044
global_step: 2097, epoch: 3, loss: 1.162589
global_step: 2098, epoch: 3, loss: 1.344013
global_step: 2099, epoch: 3, loss: 1.331951
global_step: 2100, epoch: 3, loss: 1.103419
global_step: 2101, epoch: 3, loss: 1.169410
global_step: 2102, epoch: 3, loss: 1.295612
global_step: 2103, epoch: 3, loss: 1.268260
global_step: 2104, epoch: 3, loss: 1.245026
global_step: 2105, epoch: 3, loss: 1.294224
global_step: 2106, epoch: 3, loss: 1.211733
global_step: 2107, epoch: 3, loss: 1.293643
global_step: 2108, epoch: 3, loss: 1.196145
global_step: 2109, epoch: 3, loss: 1.273476
global_step: 2110, epoch: 3, loss: 1.258609
global_step: 2111, epoch: 3, loss: 1.161400
global_step: 2112, epoch: 3, loss: 1.255582
global_step: 2113, epoch: 3, loss: 1.220531
global_step: 2114, epoch: 3, loss: 1.387048
global_step: 2115, epoch: 3, loss: 1.200386
global_step: 2116, epoch: 3, loss: 1.170857
global_step: 2117, epoch: 3, loss: 1.280349
global_step: 2118, epoch: 3, loss: 1.377148
global_step: 2119, epoch: 3, loss: 1.254725
global_step: 2120, epoch: 3, loss: 0.559267
epoch: 3
train	acc: 0.5906	macro: p 0.3066, r 0.2837, f1: 0.2765	micro: p 0.5906, r 0.5906, f1 0.5906	weighted_f1:0.5189
dev	acc: 0.5401	macro: p 0.2802, r 0.2789, f1: 0.2592	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4562
test	acc: 0.5851	macro: p 0.2866, r 0.2761, f1: 0.2624	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5085
New best model!
global_step: 2121, epoch: 4, loss: 1.462240
global_step: 2122, epoch: 4, loss: 1.274787
global_step: 2123, epoch: 4, loss: 1.272264
global_step: 2124, epoch: 4, loss: 1.244537
global_step: 2125, epoch: 4, loss: 1.042731
global_step: 2126, epoch: 4, loss: 1.088073
global_step: 2127, epoch: 4, loss: 1.263415
global_step: 2128, epoch: 4, loss: 1.242383
global_step: 2129, epoch: 4, loss: 1.359253
global_step: 2130, epoch: 4, loss: 1.168702
global_step: 2131, epoch: 4, loss: 1.146572
global_step: 2132, epoch: 4, loss: 1.199276
global_step: 2133, epoch: 4, loss: 1.293097
global_step: 2134, epoch: 4, loss: 1.119689
global_step: 2135, epoch: 4, loss: 1.163427
global_step: 2136, epoch: 4, loss: 1.292288
global_step: 2137, epoch: 4, loss: 1.126031
global_step: 2138, epoch: 4, loss: 1.405659
global_step: 2139, epoch: 4, loss: 1.367869
global_step: 2140, epoch: 4, loss: 1.227292
global_step: 2141, epoch: 4, loss: 1.253786
global_step: 2142, epoch: 4, loss: 1.199880
global_step: 2143, epoch: 4, loss: 1.146665
global_step: 2144, epoch: 4, loss: 1.186848
global_step: 2145, epoch: 4, loss: 1.186233
global_step: 2146, epoch: 4, loss: 1.385749
global_step: 2147, epoch: 4, loss: 1.344486
global_step: 2148, epoch: 4, loss: 1.256148
global_step: 2149, epoch: 4, loss: 1.170660
global_step: 2150, epoch: 4, loss: 1.147464
global_step: 2151, epoch: 4, loss: 1.346496
global_step: 2152, epoch: 4, loss: 1.148483
global_step: 2153, epoch: 4, loss: 1.151841
global_step: 2154, epoch: 4, loss: 1.152705
global_step: 2155, epoch: 4, loss: 1.255633
global_step: 2156, epoch: 4, loss: 1.169042
global_step: 2157, epoch: 4, loss: 1.234870
global_step: 2158, epoch: 4, loss: 1.252344
global_step: 2159, epoch: 4, loss: 1.379065
global_step: 2160, epoch: 4, loss: 1.153881
epoch: 4
train	acc: 0.5790	macro: p 0.4492, r 0.2943, f1: 0.2688	micro: p 0.5790, r 0.5790, f1 0.5790	weighted_f1:0.5013
dev	acc: 0.5293	macro: p 0.3025, r 0.2722, f1: 0.2438	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4418
test	acc: 0.5701	macro: p 0.3949, r 0.2749, f1: 0.2520	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.4941
global_step: 2161, epoch: 5, loss: 1.316322
global_step: 2162, epoch: 5, loss: 1.116593
global_step: 2163, epoch: 5, loss: 1.233561
global_step: 2164, epoch: 5, loss: 1.159760
global_step: 2165, epoch: 5, loss: 1.144087
global_step: 2166, epoch: 5, loss: 1.115539
global_step: 2167, epoch: 5, loss: 1.172454
global_step: 2168, epoch: 5, loss: 1.170541
global_step: 2169, epoch: 5, loss: 1.127374
global_step: 2170, epoch: 5, loss: 1.096715
global_step: 2171, epoch: 5, loss: 1.281700
global_step: 2172, epoch: 5, loss: 1.140739
global_step: 2173, epoch: 5, loss: 1.239700
global_step: 2174, epoch: 5, loss: 1.223837
global_step: 2175, epoch: 5, loss: 1.226508
global_step: 2176, epoch: 5, loss: 1.190733
global_step: 2177, epoch: 5, loss: 1.256723
global_step: 2178, epoch: 5, loss: 1.237048
global_step: 2179, epoch: 5, loss: 1.216883
global_step: 2180, epoch: 5, loss: 1.181607
global_step: 2181, epoch: 5, loss: 1.208760
global_step: 2182, epoch: 5, loss: 1.188189
global_step: 2183, epoch: 5, loss: 1.294455
global_step: 2184, epoch: 5, loss: 1.170668
global_step: 2185, epoch: 5, loss: 1.186065
global_step: 2186, epoch: 5, loss: 1.177087
global_step: 2187, epoch: 5, loss: 1.113430
global_step: 2188, epoch: 5, loss: 1.094276
global_step: 2189, epoch: 5, loss: 1.292593
global_step: 2190, epoch: 5, loss: 1.183256
global_step: 2191, epoch: 5, loss: 1.167957
global_step: 2192, epoch: 5, loss: 1.222649
global_step: 2193, epoch: 5, loss: 1.032162
global_step: 2194, epoch: 5, loss: 1.147774
global_step: 2195, epoch: 5, loss: 1.148040
global_step: 2196, epoch: 5, loss: 1.199423
global_step: 2197, epoch: 5, loss: 1.133978
global_step: 2198, epoch: 5, loss: 1.196722
global_step: 2199, epoch: 5, loss: 1.177885
global_step: 2200, epoch: 5, loss: 1.349533
epoch: 5
train	acc: 0.5769	macro: p 0.3969, r 0.3249, f1: 0.2747	micro: p 0.5769, r 0.5769, f1 0.5769	weighted_f1:0.5207
dev	acc: 0.5113	macro: p 0.3755, r 0.3051, f1: 0.2518	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4420
test	acc: 0.5337	macro: p 0.4139, r 0.3077, f1: 0.2465	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.4795
global_step: 2201, epoch: 6, loss: 1.335343
global_step: 2202, epoch: 6, loss: 1.101068
global_step: 2203, epoch: 6, loss: 1.258932
global_step: 2204, epoch: 6, loss: 1.185262
global_step: 2205, epoch: 6, loss: 1.211193
global_step: 2206, epoch: 6, loss: 1.106311
global_step: 2207, epoch: 6, loss: 1.125285
global_step: 2208, epoch: 6, loss: 1.165946
global_step: 2209, epoch: 6, loss: 1.147228
global_step: 2210, epoch: 6, loss: 1.166472
global_step: 2211, epoch: 6, loss: 1.154664
global_step: 2212, epoch: 6, loss: 1.141108
global_step: 2213, epoch: 6, loss: 1.120663
global_step: 2214, epoch: 6, loss: 1.212927
global_step: 2215, epoch: 6, loss: 1.125249
global_step: 2216, epoch: 6, loss: 1.128631
global_step: 2217, epoch: 6, loss: 1.018601
global_step: 2218, epoch: 6, loss: 1.195549
global_step: 2219, epoch: 6, loss: 1.092879
global_step: 2220, epoch: 6, loss: 1.115609
global_step: 2221, epoch: 6, loss: 1.153298
global_step: 2222, epoch: 6, loss: 1.183756
global_step: 2223, epoch: 6, loss: 1.217139
global_step: 2224, epoch: 6, loss: 1.106455
global_step: 2225, epoch: 6, loss: 1.166292
global_step: 2226, epoch: 6, loss: 1.103531
global_step: 2227, epoch: 6, loss: 1.214857
global_step: 2228, epoch: 6, loss: 1.157232
global_step: 2229, epoch: 6, loss: 1.142846
global_step: 2230, epoch: 6, loss: 1.212159
global_step: 2231, epoch: 6, loss: 1.199369
global_step: 2232, epoch: 6, loss: 1.137363
global_step: 2233, epoch: 6, loss: 1.166388
global_step: 2234, epoch: 6, loss: 1.118788
global_step: 2235, epoch: 6, loss: 1.242718
global_step: 2236, epoch: 6, loss: 1.288471
global_step: 2237, epoch: 6, loss: 1.289051
global_step: 2238, epoch: 6, loss: 1.292483
global_step: 2239, epoch: 6, loss: 1.182470
global_step: 2240, epoch: 6, loss: 1.886619
epoch: 6
train	acc: 0.6183	macro: p 0.4024, r 0.3420, f1: 0.3221	micro: p 0.6183, r 0.6183, f1 0.6183	weighted_f1:0.5645
dev	acc: 0.5509	macro: p 0.3763, r 0.3184, f1: 0.2833	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4809
test	acc: 0.5866	macro: p 0.3773, r 0.3220, f1: 0.2913	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5284
New best model!
global_step: 2241, epoch: 7, loss: 1.197872
global_step: 2242, epoch: 7, loss: 1.176993
global_step: 2243, epoch: 7, loss: 1.154085
global_step: 2244, epoch: 7, loss: 1.013196
global_step: 2245, epoch: 7, loss: 1.140889
global_step: 2246, epoch: 7, loss: 1.219083
global_step: 2247, epoch: 7, loss: 1.051291
global_step: 2248, epoch: 7, loss: 1.243987
global_step: 2249, epoch: 7, loss: 1.056885
global_step: 2250, epoch: 7, loss: 1.193945
global_step: 2251, epoch: 7, loss: 1.044004
global_step: 2252, epoch: 7, loss: 1.199992
global_step: 2253, epoch: 7, loss: 1.113606
global_step: 2254, epoch: 7, loss: 1.191798
global_step: 2255, epoch: 7, loss: 1.155837
global_step: 2256, epoch: 7, loss: 1.142124
global_step: 2257, epoch: 7, loss: 1.086295
global_step: 2258, epoch: 7, loss: 1.134023
global_step: 2259, epoch: 7, loss: 1.124874
global_step: 2260, epoch: 7, loss: 1.140942
global_step: 2261, epoch: 7, loss: 1.060557
global_step: 2262, epoch: 7, loss: 1.161717
global_step: 2263, epoch: 7, loss: 1.083721
global_step: 2264, epoch: 7, loss: 1.183336
global_step: 2265, epoch: 7, loss: 1.162435
global_step: 2266, epoch: 7, loss: 1.086937
global_step: 2267, epoch: 7, loss: 1.098318
global_step: 2268, epoch: 7, loss: 1.055637
global_step: 2269, epoch: 7, loss: 1.093647
global_step: 2270, epoch: 7, loss: 1.045433
global_step: 2271, epoch: 7, loss: 1.103368
global_step: 2272, epoch: 7, loss: 1.114318
global_step: 2273, epoch: 7, loss: 1.080743
global_step: 2274, epoch: 7, loss: 1.148998
global_step: 2275, epoch: 7, loss: 1.091689
global_step: 2276, epoch: 7, loss: 1.084715
global_step: 2277, epoch: 7, loss: 1.223534
global_step: 2278, epoch: 7, loss: 1.241195
global_step: 2279, epoch: 7, loss: 1.146080
global_step: 2280, epoch: 7, loss: 1.212629
epoch: 7
train	acc: 0.6301	macro: p 0.4531, r 0.3194, f1: 0.3244	micro: p 0.6301, r 0.6301, f1 0.6301	weighted_f1:0.5683
dev	acc: 0.5573	macro: p 0.4572, r 0.2991, f1: 0.2842	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4820
test	acc: 0.6038	macro: p 0.4268, r 0.2960, f1: 0.2902	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5340
New best model!
global_step: 2281, epoch: 8, loss: 1.116663
global_step: 2282, epoch: 8, loss: 1.132948
global_step: 2283, epoch: 8, loss: 1.041404
global_step: 2284, epoch: 8, loss: 1.172429
global_step: 2285, epoch: 8, loss: 1.039365
global_step: 2286, epoch: 8, loss: 1.085873
global_step: 2287, epoch: 8, loss: 1.091602
global_step: 2288, epoch: 8, loss: 1.105808
global_step: 2289, epoch: 8, loss: 1.160646
global_step: 2290, epoch: 8, loss: 1.185571
global_step: 2291, epoch: 8, loss: 1.012356
global_step: 2292, epoch: 8, loss: 1.016447
global_step: 2293, epoch: 8, loss: 1.141153
global_step: 2294, epoch: 8, loss: 1.106899
global_step: 2295, epoch: 8, loss: 1.191682
global_step: 2296, epoch: 8, loss: 1.127608
global_step: 2297, epoch: 8, loss: 1.101817
global_step: 2298, epoch: 8, loss: 1.008158
global_step: 2299, epoch: 8, loss: 1.112444
global_step: 2300, epoch: 8, loss: 1.095663
global_step: 2301, epoch: 8, loss: 1.088268
global_step: 2302, epoch: 8, loss: 1.121456
global_step: 2303, epoch: 8, loss: 1.058911
global_step: 2304, epoch: 8, loss: 1.121905
global_step: 2305, epoch: 8, loss: 1.169167
global_step: 2306, epoch: 8, loss: 1.075553
global_step: 2307, epoch: 8, loss: 1.162409
global_step: 2308, epoch: 8, loss: 0.973968
global_step: 2309, epoch: 8, loss: 1.327567
global_step: 2310, epoch: 8, loss: 1.237353
global_step: 2311, epoch: 8, loss: 1.146114
global_step: 2312, epoch: 8, loss: 1.089450
global_step: 2313, epoch: 8, loss: 1.048560
global_step: 2314, epoch: 8, loss: 1.117936
global_step: 2315, epoch: 8, loss: 1.072409
global_step: 2316, epoch: 8, loss: 1.016747
global_step: 2317, epoch: 8, loss: 1.049087
global_step: 2318, epoch: 8, loss: 1.065463
global_step: 2319, epoch: 8, loss: 1.084001
global_step: 2320, epoch: 8, loss: 1.211553
epoch: 8
train	acc: 0.6164	macro: p 0.4202, r 0.3500, f1: 0.3404	micro: p 0.6164, r 0.6164, f1 0.6164	weighted_f1:0.5589
dev	acc: 0.5392	macro: p 0.3521, r 0.2928, f1: 0.2745	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4664
test	acc: 0.5755	macro: p 0.3705, r 0.3005, f1: 0.2903	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5185
global_step: 2321, epoch: 9, loss: 1.076906
global_step: 2322, epoch: 9, loss: 1.210821
global_step: 2323, epoch: 9, loss: 1.057107
global_step: 2324, epoch: 9, loss: 1.124379
global_step: 2325, epoch: 9, loss: 1.240703
global_step: 2326, epoch: 9, loss: 1.052031
global_step: 2327, epoch: 9, loss: 1.135870
global_step: 2328, epoch: 9, loss: 0.999240
global_step: 2329, epoch: 9, loss: 1.038890
global_step: 2330, epoch: 9, loss: 1.014781
global_step: 2331, epoch: 9, loss: 1.058647
global_step: 2332, epoch: 9, loss: 0.911310
global_step: 2333, epoch: 9, loss: 1.075771
global_step: 2334, epoch: 9, loss: 0.982345
global_step: 2335, epoch: 9, loss: 1.066007
global_step: 2336, epoch: 9, loss: 1.047342
global_step: 2337, epoch: 9, loss: 1.007117
global_step: 2338, epoch: 9, loss: 0.955279
global_step: 2339, epoch: 9, loss: 1.143802
global_step: 2340, epoch: 9, loss: 1.173347
global_step: 2341, epoch: 9, loss: 1.186132
global_step: 2342, epoch: 9, loss: 1.138578
global_step: 2343, epoch: 9, loss: 1.113410
global_step: 2344, epoch: 9, loss: 1.052542
global_step: 2345, epoch: 9, loss: 1.106410
global_step: 2346, epoch: 9, loss: 1.057316
global_step: 2347, epoch: 9, loss: 1.059861
global_step: 2348, epoch: 9, loss: 1.119188
global_step: 2349, epoch: 9, loss: 1.091290
global_step: 2350, epoch: 9, loss: 1.140503
global_step: 2351, epoch: 9, loss: 1.121248
global_step: 2352, epoch: 9, loss: 1.006802
global_step: 2353, epoch: 9, loss: 0.959613
global_step: 2354, epoch: 9, loss: 1.146481
global_step: 2355, epoch: 9, loss: 1.132404
global_step: 2356, epoch: 9, loss: 0.975154
global_step: 2357, epoch: 9, loss: 1.099834
global_step: 2358, epoch: 9, loss: 0.996817
global_step: 2359, epoch: 9, loss: 1.079294
global_step: 2360, epoch: 9, loss: 1.305126
epoch: 9
train	acc: 0.6348	macro: p 0.4617, r 0.3308, f1: 0.3423	micro: p 0.6348, r 0.6348, f1 0.6348	weighted_f1:0.5798
dev	acc: 0.5455	macro: p 0.3922, r 0.2881, f1: 0.2732	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4718
test	acc: 0.6019	macro: p 0.4071, r 0.2979, f1: 0.2943	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5371
global_step: 2361, epoch: 10, loss: 1.040267
global_step: 2362, epoch: 10, loss: 0.914914
global_step: 2363, epoch: 10, loss: 1.017085
global_step: 2364, epoch: 10, loss: 1.056589
global_step: 2365, epoch: 10, loss: 0.990051
global_step: 2366, epoch: 10, loss: 1.060822
global_step: 2367, epoch: 10, loss: 1.120485
global_step: 2368, epoch: 10, loss: 0.991156
global_step: 2369, epoch: 10, loss: 0.974519
global_step: 2370, epoch: 10, loss: 1.057636
global_step: 2371, epoch: 10, loss: 1.070116
global_step: 2372, epoch: 10, loss: 1.127197
global_step: 2373, epoch: 10, loss: 1.010078
global_step: 2374, epoch: 10, loss: 1.009054
global_step: 2375, epoch: 10, loss: 1.027633
global_step: 2376, epoch: 10, loss: 1.062991
global_step: 2377, epoch: 10, loss: 1.116024
global_step: 2378, epoch: 10, loss: 1.064474
global_step: 2379, epoch: 10, loss: 1.050771
global_step: 2380, epoch: 10, loss: 1.025136
global_step: 2381, epoch: 10, loss: 1.013617
global_step: 2382, epoch: 10, loss: 1.176123
global_step: 2383, epoch: 10, loss: 1.015306
global_step: 2384, epoch: 10, loss: 1.030823
global_step: 2385, epoch: 10, loss: 1.048201
global_step: 2386, epoch: 10, loss: 0.970548
global_step: 2387, epoch: 10, loss: 1.083830
global_step: 2388, epoch: 10, loss: 0.899817
global_step: 2389, epoch: 10, loss: 1.073625
global_step: 2390, epoch: 10, loss: 1.127111
global_step: 2391, epoch: 10, loss: 1.032924
global_step: 2392, epoch: 10, loss: 1.064248
global_step: 2393, epoch: 10, loss: 1.026217
global_step: 2394, epoch: 10, loss: 1.154707
global_step: 2395, epoch: 10, loss: 1.034647
global_step: 2396, epoch: 10, loss: 1.069460
global_step: 2397, epoch: 10, loss: 1.043878
global_step: 2398, epoch: 10, loss: 1.125376
global_step: 2399, epoch: 10, loss: 1.203460
global_step: 2400, epoch: 10, loss: 0.965807
epoch: 10
train	acc: 0.6690	macro: p 0.5856, r 0.3760, f1: 0.3926	micro: p 0.6690, r 0.6690, f1 0.6690	weighted_f1:0.6211
dev	acc: 0.5546	macro: p 0.4040, r 0.2986, f1: 0.2910	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4856
test	acc: 0.6172	macro: p 0.4675, r 0.3173, f1: 0.3217	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5590
New best model!
global_step: 2401, epoch: 11, loss: 0.912466
global_step: 2402, epoch: 11, loss: 1.082870
global_step: 2403, epoch: 11, loss: 0.950330
global_step: 2404, epoch: 11, loss: 0.956098
global_step: 2405, epoch: 11, loss: 1.022135
global_step: 2406, epoch: 11, loss: 0.966606
global_step: 2407, epoch: 11, loss: 1.098374
global_step: 2408, epoch: 11, loss: 1.079552
global_step: 2409, epoch: 11, loss: 1.074818
global_step: 2410, epoch: 11, loss: 0.992556
global_step: 2411, epoch: 11, loss: 1.008487
global_step: 2412, epoch: 11, loss: 1.103640
global_step: 2413, epoch: 11, loss: 1.040828
global_step: 2414, epoch: 11, loss: 1.030781
global_step: 2415, epoch: 11, loss: 1.040612
global_step: 2416, epoch: 11, loss: 0.997794
global_step: 2417, epoch: 11, loss: 1.044996
global_step: 2418, epoch: 11, loss: 0.999296
global_step: 2419, epoch: 11, loss: 1.018906
global_step: 2420, epoch: 11, loss: 0.904639
global_step: 2421, epoch: 11, loss: 0.966421
global_step: 2422, epoch: 11, loss: 1.026510
global_step: 2423, epoch: 11, loss: 1.044840
global_step: 2424, epoch: 11, loss: 0.994839
global_step: 2425, epoch: 11, loss: 0.978337
global_step: 2426, epoch: 11, loss: 1.056227
global_step: 2427, epoch: 11, loss: 0.901152
global_step: 2428, epoch: 11, loss: 1.105699
global_step: 2429, epoch: 11, loss: 1.108294
global_step: 2430, epoch: 11, loss: 0.982880
global_step: 2431, epoch: 11, loss: 0.959581
global_step: 2432, epoch: 11, loss: 0.962533
global_step: 2433, epoch: 11, loss: 0.887983
global_step: 2434, epoch: 11, loss: 1.044529
global_step: 2435, epoch: 11, loss: 1.074321
global_step: 2436, epoch: 11, loss: 1.027346
global_step: 2437, epoch: 11, loss: 0.987941
global_step: 2438, epoch: 11, loss: 0.872612
global_step: 2439, epoch: 11, loss: 0.982258
global_step: 2440, epoch: 11, loss: 1.164889
epoch: 11
train	acc: 0.6944	macro: p 0.6073, r 0.4353, f1: 0.4410	micro: p 0.6944, r 0.6944, f1 0.6944	weighted_f1:0.6676
dev	acc: 0.5636	macro: p 0.3632, r 0.3315, f1: 0.3337	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5240
test	acc: 0.6180	macro: p 0.3897, r 0.3481, f1: 0.3574	micro: p 0.6180, r 0.6180, f1 0.6180	weighted_f1:0.5859
New best model!
global_step: 2441, epoch: 12, loss: 1.080257
global_step: 2442, epoch: 12, loss: 0.945327
global_step: 2443, epoch: 12, loss: 0.925161
global_step: 2444, epoch: 12, loss: 0.920338
global_step: 2445, epoch: 12, loss: 0.994243
global_step: 2446, epoch: 12, loss: 0.979534
global_step: 2447, epoch: 12, loss: 1.047048
global_step: 2448, epoch: 12, loss: 0.962702
global_step: 2449, epoch: 12, loss: 1.022788
global_step: 2450, epoch: 12, loss: 1.028295
global_step: 2451, epoch: 12, loss: 1.079460
global_step: 2452, epoch: 12, loss: 0.992731
global_step: 2453, epoch: 12, loss: 0.818511
global_step: 2454, epoch: 12, loss: 1.067200
global_step: 2455, epoch: 12, loss: 0.969342
global_step: 2456, epoch: 12, loss: 0.997716
global_step: 2457, epoch: 12, loss: 0.975390
global_step: 2458, epoch: 12, loss: 0.991770
global_step: 2459, epoch: 12, loss: 0.901577
global_step: 2460, epoch: 12, loss: 1.023608
global_step: 2461, epoch: 12, loss: 1.009629
global_step: 2462, epoch: 12, loss: 0.998016
global_step: 2463, epoch: 12, loss: 1.052296
global_step: 2464, epoch: 12, loss: 0.961960
global_step: 2465, epoch: 12, loss: 0.970016
global_step: 2466, epoch: 12, loss: 0.963281
global_step: 2467, epoch: 12, loss: 0.943208
global_step: 2468, epoch: 12, loss: 0.968178
global_step: 2469, epoch: 12, loss: 0.935595
global_step: 2470, epoch: 12, loss: 0.948579
global_step: 2471, epoch: 12, loss: 0.793385
global_step: 2472, epoch: 12, loss: 0.960539
global_step: 2473, epoch: 12, loss: 1.004005
global_step: 2474, epoch: 12, loss: 1.064989
global_step: 2475, epoch: 12, loss: 0.881279
global_step: 2476, epoch: 12, loss: 1.042672
global_step: 2477, epoch: 12, loss: 0.918303
global_step: 2478, epoch: 12, loss: 1.000877
global_step: 2479, epoch: 12, loss: 1.000897
global_step: 2480, epoch: 12, loss: 0.472176
epoch: 12
train	acc: 0.7043	macro: p 0.4694, r 0.4731, f1: 0.4587	micro: p 0.7043, r 0.7043, f1 0.7043	weighted_f1:0.6844
dev	acc: 0.5482	macro: p 0.3552, r 0.3447, f1: 0.3276	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5159
test	acc: 0.5724	macro: p 0.3525, r 0.3484, f1: 0.3299	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5477
global_step: 2481, epoch: 13, loss: 0.944005
global_step: 2482, epoch: 13, loss: 0.952402
global_step: 2483, epoch: 13, loss: 0.977103
global_step: 2484, epoch: 13, loss: 0.992627
global_step: 2485, epoch: 13, loss: 0.894890
global_step: 2486, epoch: 13, loss: 0.971202
global_step: 2487, epoch: 13, loss: 0.905959
global_step: 2488, epoch: 13, loss: 0.913682
global_step: 2489, epoch: 13, loss: 1.067257
global_step: 2490, epoch: 13, loss: 0.951318
global_step: 2491, epoch: 13, loss: 0.799708
global_step: 2492, epoch: 13, loss: 0.866559
global_step: 2493, epoch: 13, loss: 0.989820
global_step: 2494, epoch: 13, loss: 0.970145
global_step: 2495, epoch: 13, loss: 1.008302
global_step: 2496, epoch: 13, loss: 0.952984
global_step: 2497, epoch: 13, loss: 0.863480
global_step: 2498, epoch: 13, loss: 0.902000
global_step: 2499, epoch: 13, loss: 0.901021
global_step: 2500, epoch: 13, loss: 0.975304
global_step: 2501, epoch: 13, loss: 0.965622
global_step: 2502, epoch: 13, loss: 0.979276
global_step: 2503, epoch: 13, loss: 0.960529
global_step: 2504, epoch: 13, loss: 0.910529
global_step: 2505, epoch: 13, loss: 0.970974
global_step: 2506, epoch: 13, loss: 0.920589
global_step: 2507, epoch: 13, loss: 1.015626
global_step: 2508, epoch: 13, loss: 1.044032
global_step: 2509, epoch: 13, loss: 1.015387
global_step: 2510, epoch: 13, loss: 1.017919
global_step: 2511, epoch: 13, loss: 1.048755
global_step: 2512, epoch: 13, loss: 0.917528
global_step: 2513, epoch: 13, loss: 0.923827
global_step: 2514, epoch: 13, loss: 0.931804
global_step: 2515, epoch: 13, loss: 0.862774
global_step: 2516, epoch: 13, loss: 0.863150
global_step: 2517, epoch: 13, loss: 0.864084
global_step: 2518, epoch: 13, loss: 0.860419
global_step: 2519, epoch: 13, loss: 0.962475
global_step: 2520, epoch: 13, loss: 0.732187
epoch: 13
train	acc: 0.5936	macro: p 0.6756, r 0.2838, f1: 0.3099	micro: p 0.5936, r 0.5936, f1 0.5936	weighted_f1:0.5190
dev	acc: 0.5005	macro: p 0.4721, r 0.2299, f1: 0.2238	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.3998
test	acc: 0.5544	macro: p 0.5072, r 0.2355, f1: 0.2392	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.4551
global_step: 2521, epoch: 14, loss: 1.637182
global_step: 2522, epoch: 14, loss: 1.073853
global_step: 2523, epoch: 14, loss: 0.849191
global_step: 2524, epoch: 14, loss: 0.985267
global_step: 2525, epoch: 14, loss: 0.829719
global_step: 2526, epoch: 14, loss: 0.931810
global_step: 2527, epoch: 14, loss: 0.922199
global_step: 2528, epoch: 14, loss: 0.925899
global_step: 2529, epoch: 14, loss: 0.890715
global_step: 2530, epoch: 14, loss: 0.900602
global_step: 2531, epoch: 14, loss: 0.905674
global_step: 2532, epoch: 14, loss: 0.817623
global_step: 2533, epoch: 14, loss: 0.902930
global_step: 2534, epoch: 14, loss: 0.788101
global_step: 2535, epoch: 14, loss: 0.930768
global_step: 2536, epoch: 14, loss: 0.917150
global_step: 2537, epoch: 14, loss: 0.843724
global_step: 2538, epoch: 14, loss: 0.851909
global_step: 2539, epoch: 14, loss: 0.923399
global_step: 2540, epoch: 14, loss: 0.913425
global_step: 2541, epoch: 14, loss: 0.910588
global_step: 2542, epoch: 14, loss: 1.068804
global_step: 2543, epoch: 14, loss: 0.913067
global_step: 2544, epoch: 14, loss: 0.889241
global_step: 2545, epoch: 14, loss: 0.874114
global_step: 2546, epoch: 14, loss: 0.873918
global_step: 2547, epoch: 14, loss: 0.870300
global_step: 2548, epoch: 14, loss: 0.957262
global_step: 2549, epoch: 14, loss: 0.780721
global_step: 2550, epoch: 14, loss: 0.894287
global_step: 2551, epoch: 14, loss: 1.056728
global_step: 2552, epoch: 14, loss: 0.987638
global_step: 2553, epoch: 14, loss: 0.804893
global_step: 2554, epoch: 14, loss: 1.003851
global_step: 2555, epoch: 14, loss: 0.972542
global_step: 2556, epoch: 14, loss: 0.855721
global_step: 2557, epoch: 14, loss: 0.961487
global_step: 2558, epoch: 14, loss: 0.908294
global_step: 2559, epoch: 14, loss: 0.771354
global_step: 2560, epoch: 14, loss: 0.394246
epoch: 14
train	acc: 0.6829	macro: p 0.6524, r 0.3847, f1: 0.3967	micro: p 0.6829, r 0.6829, f1 0.6829	weighted_f1:0.6309
dev	acc: 0.5537	macro: p 0.5943, r 0.3150, f1: 0.3049	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4829
test	acc: 0.5927	macro: p 0.5193, r 0.3057, f1: 0.2927	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5268
global_step: 2561, epoch: 15, loss: 1.029766
global_step: 2562, epoch: 15, loss: 0.846001
global_step: 2563, epoch: 15, loss: 0.807012
global_step: 2564, epoch: 15, loss: 0.918196
global_step: 2565, epoch: 15, loss: 0.773747
global_step: 2566, epoch: 15, loss: 0.833432
global_step: 2567, epoch: 15, loss: 0.784673
global_step: 2568, epoch: 15, loss: 0.818582
global_step: 2569, epoch: 15, loss: 0.943120
global_step: 2570, epoch: 15, loss: 0.951748
global_step: 2571, epoch: 15, loss: 0.835438
global_step: 2572, epoch: 15, loss: 0.790563
global_step: 2573, epoch: 15, loss: 0.790130
global_step: 2574, epoch: 15, loss: 0.753859
global_step: 2575, epoch: 15, loss: 0.959089
global_step: 2576, epoch: 15, loss: 0.920794
global_step: 2577, epoch: 15, loss: 0.741169
global_step: 2578, epoch: 15, loss: 0.937579
global_step: 2579, epoch: 15, loss: 0.835182
global_step: 2580, epoch: 15, loss: 0.820774
global_step: 2581, epoch: 15, loss: 0.875079
global_step: 2582, epoch: 15, loss: 0.751248
global_step: 2583, epoch: 15, loss: 0.878184
global_step: 2584, epoch: 15, loss: 0.899451
global_step: 2585, epoch: 15, loss: 0.746778
global_step: 2586, epoch: 15, loss: 0.940727
global_step: 2587, epoch: 15, loss: 1.021114
global_step: 2588, epoch: 15, loss: 0.965875
global_step: 2589, epoch: 15, loss: 0.883949
global_step: 2590, epoch: 15, loss: 0.844495
global_step: 2591, epoch: 15, loss: 0.949679
global_step: 2592, epoch: 15, loss: 0.864988
global_step: 2593, epoch: 15, loss: 0.878872
global_step: 2594, epoch: 15, loss: 0.862863
global_step: 2595, epoch: 15, loss: 0.895338
global_step: 2596, epoch: 15, loss: 0.805782
global_step: 2597, epoch: 15, loss: 0.886702
global_step: 2598, epoch: 15, loss: 0.982316
global_step: 2599, epoch: 15, loss: 0.995116
global_step: 2600, epoch: 15, loss: 0.537654
epoch: 15
train	acc: 0.7358	macro: p 0.7611, r 0.4783, f1: 0.5018	micro: p 0.7358, r 0.7358, f1 0.7358	weighted_f1:0.7077
dev	acc: 0.5464	macro: p 0.4474, r 0.3192, f1: 0.3113	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4971
test	acc: 0.5889	macro: p 0.4371, r 0.3249, f1: 0.3197	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5471
global_step: 2601, epoch: 16, loss: 0.845599
global_step: 2602, epoch: 16, loss: 0.891332
global_step: 2603, epoch: 16, loss: 0.865226
global_step: 2604, epoch: 16, loss: 0.858706
global_step: 2605, epoch: 16, loss: 0.844469
global_step: 2606, epoch: 16, loss: 0.788635
global_step: 2607, epoch: 16, loss: 0.838640
global_step: 2608, epoch: 16, loss: 0.741908
global_step: 2609, epoch: 16, loss: 0.882836
global_step: 2610, epoch: 16, loss: 0.768260
global_step: 2611, epoch: 16, loss: 0.710427
global_step: 2612, epoch: 16, loss: 0.866172
global_step: 2613, epoch: 16, loss: 0.844403
global_step: 2614, epoch: 16, loss: 0.664590
global_step: 2615, epoch: 16, loss: 0.908977
global_step: 2616, epoch: 16, loss: 0.970954
global_step: 2617, epoch: 16, loss: 0.825802
global_step: 2618, epoch: 16, loss: 0.917149
global_step: 2619, epoch: 16, loss: 0.864273
global_step: 2620, epoch: 16, loss: 0.800148
global_step: 2621, epoch: 16, loss: 0.856027
global_step: 2622, epoch: 16, loss: 0.842267
global_step: 2623, epoch: 16, loss: 0.731238
global_step: 2624, epoch: 16, loss: 0.994184
global_step: 2625, epoch: 16, loss: 0.974979
global_step: 2626, epoch: 16, loss: 0.816239
global_step: 2627, epoch: 16, loss: 0.778098
global_step: 2628, epoch: 16, loss: 0.807640
global_step: 2629, epoch: 16, loss: 0.766585
global_step: 2630, epoch: 16, loss: 0.891656
global_step: 2631, epoch: 16, loss: 0.898569
global_step: 2632, epoch: 16, loss: 0.826529
global_step: 2633, epoch: 16, loss: 0.845378
global_step: 2634, epoch: 16, loss: 0.909243
global_step: 2635, epoch: 16, loss: 0.895534
global_step: 2636, epoch: 16, loss: 0.792458
global_step: 2637, epoch: 16, loss: 0.868987
global_step: 2638, epoch: 16, loss: 0.859571
global_step: 2639, epoch: 16, loss: 1.045439
global_step: 2640, epoch: 16, loss: 0.416842
epoch: 16
train	acc: 0.7048	macro: p 0.8107, r 0.4241, f1: 0.4685	micro: p 0.7048, r 0.7048, f1 0.7048	weighted_f1:0.6653
dev	acc: 0.5528	macro: p 0.4929, r 0.3034, f1: 0.3101	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4829
test	acc: 0.6057	macro: p 0.6315, r 0.3047, f1: 0.3201	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5415
global_step: 2641, epoch: 17, loss: 1.022174
global_step: 2642, epoch: 17, loss: 0.899792
global_step: 2643, epoch: 17, loss: 0.705928
global_step: 2644, epoch: 17, loss: 0.759654
global_step: 2645, epoch: 17, loss: 0.803515
global_step: 2646, epoch: 17, loss: 0.802841
global_step: 2647, epoch: 17, loss: 0.734756
global_step: 2648, epoch: 17, loss: 0.776314
global_step: 2649, epoch: 17, loss: 0.893088
global_step: 2650, epoch: 17, loss: 0.799728
global_step: 2651, epoch: 17, loss: 0.660888
global_step: 2652, epoch: 17, loss: 0.798910
global_step: 2653, epoch: 17, loss: 0.938542
global_step: 2654, epoch: 17, loss: 0.751820
global_step: 2655, epoch: 17, loss: 0.720654
global_step: 2656, epoch: 17, loss: 0.705553
global_step: 2657, epoch: 17, loss: 0.879470
global_step: 2658, epoch: 17, loss: 0.786643
global_step: 2659, epoch: 17, loss: 0.889057
global_step: 2660, epoch: 17, loss: 0.677549
global_step: 2661, epoch: 17, loss: 0.761865
global_step: 2662, epoch: 17, loss: 0.834388
global_step: 2663, epoch: 17, loss: 0.745100
global_step: 2664, epoch: 17, loss: 0.866130
global_step: 2665, epoch: 17, loss: 0.725143
global_step: 2666, epoch: 17, loss: 0.798908
global_step: 2667, epoch: 17, loss: 0.850015
global_step: 2668, epoch: 17, loss: 0.855952
global_step: 2669, epoch: 17, loss: 0.773948
global_step: 2670, epoch: 17, loss: 0.783588
global_step: 2671, epoch: 17, loss: 0.806866
global_step: 2672, epoch: 17, loss: 0.818865
global_step: 2673, epoch: 17, loss: 0.747336
global_step: 2674, epoch: 17, loss: 0.832061
global_step: 2675, epoch: 17, loss: 0.848477
global_step: 2676, epoch: 17, loss: 0.808426
global_step: 2677, epoch: 17, loss: 0.861182
global_step: 2678, epoch: 17, loss: 0.814975
global_step: 2679, epoch: 17, loss: 0.932975
global_step: 2680, epoch: 17, loss: 0.461689
epoch: 17
train	acc: 0.6931	macro: p 0.7071, r 0.5640, f1: 0.5605	micro: p 0.6931, r 0.6931, f1 0.6931	weighted_f1:0.7058
dev	acc: 0.4869	macro: p 0.5573, r 0.3537, f1: 0.3493	micro: p 0.4869, r 0.4869, f1 0.4869	weighted_f1:0.4911
test	acc: 0.5038	macro: p 0.3747, r 0.3514, f1: 0.3316	micro: p 0.5038, r 0.5038, f1 0.5038	weighted_f1:0.5131
global_step: 2681, epoch: 18, loss: 0.996663
global_step: 2682, epoch: 18, loss: 0.829522
global_step: 2683, epoch: 18, loss: 0.767130
global_step: 2684, epoch: 18, loss: 0.744442
global_step: 2685, epoch: 18, loss: 0.765096
global_step: 2686, epoch: 18, loss: 0.752598
global_step: 2687, epoch: 18, loss: 0.767963
global_step: 2688, epoch: 18, loss: 0.794958
global_step: 2689, epoch: 18, loss: 0.747845
global_step: 2690, epoch: 18, loss: 0.738691
global_step: 2691, epoch: 18, loss: 0.678021
global_step: 2692, epoch: 18, loss: 0.734887
global_step: 2693, epoch: 18, loss: 0.684319
global_step: 2694, epoch: 18, loss: 0.728402
global_step: 2695, epoch: 18, loss: 0.737086
global_step: 2696, epoch: 18, loss: 0.757987
global_step: 2697, epoch: 18, loss: 0.726466
global_step: 2698, epoch: 18, loss: 0.875427
global_step: 2699, epoch: 18, loss: 0.937745
global_step: 2700, epoch: 18, loss: 0.826671
global_step: 2701, epoch: 18, loss: 0.837417
global_step: 2702, epoch: 18, loss: 0.750102
global_step: 2703, epoch: 18, loss: 0.813280
global_step: 2704, epoch: 18, loss: 0.731810
global_step: 2705, epoch: 18, loss: 0.809268
global_step: 2706, epoch: 18, loss: 0.774461
global_step: 2707, epoch: 18, loss: 0.856069
global_step: 2708, epoch: 18, loss: 0.764369
global_step: 2709, epoch: 18, loss: 0.625983
global_step: 2710, epoch: 18, loss: 0.765492
global_step: 2711, epoch: 18, loss: 0.731718
global_step: 2712, epoch: 18, loss: 0.792968
global_step: 2713, epoch: 18, loss: 0.767032
global_step: 2714, epoch: 18, loss: 0.761944
global_step: 2715, epoch: 18, loss: 0.768489
global_step: 2716, epoch: 18, loss: 0.888101
global_step: 2717, epoch: 18, loss: 0.848218
global_step: 2718, epoch: 18, loss: 0.768716
global_step: 2719, epoch: 18, loss: 0.736019
global_step: 2720, epoch: 18, loss: 0.441219
epoch: 18
train	acc: 0.8143	macro: p 0.8307, r 0.6149, f1: 0.6324	micro: p 0.8143, r 0.8143, f1 0.8143	weighted_f1:0.7998
dev	acc: 0.5654	macro: p 0.4021, r 0.3563, f1: 0.3614	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5326
test	acc: 0.6023	macro: p 0.4818, r 0.3614, f1: 0.3706	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5768
New best model!
global_step: 2721, epoch: 19, loss: 0.723872
global_step: 2722, epoch: 19, loss: 0.720284
global_step: 2723, epoch: 19, loss: 0.818856
global_step: 2724, epoch: 19, loss: 0.695173
global_step: 2725, epoch: 19, loss: 0.853560
global_step: 2726, epoch: 19, loss: 0.798472
global_step: 2727, epoch: 19, loss: 0.784116
global_step: 2728, epoch: 19, loss: 0.700653
global_step: 2729, epoch: 19, loss: 0.733431
global_step: 2730, epoch: 19, loss: 0.662152
global_step: 2731, epoch: 19, loss: 0.749236
global_step: 2732, epoch: 19, loss: 0.753262
global_step: 2733, epoch: 19, loss: 0.712708
global_step: 2734, epoch: 19, loss: 0.618885
global_step: 2735, epoch: 19, loss: 0.606014
global_step: 2736, epoch: 19, loss: 0.701277
global_step: 2737, epoch: 19, loss: 0.879023
global_step: 2738, epoch: 19, loss: 0.841850
global_step: 2739, epoch: 19, loss: 0.694404
global_step: 2740, epoch: 19, loss: 0.862904
global_step: 2741, epoch: 19, loss: 0.683921
global_step: 2742, epoch: 19, loss: 0.627046
global_step: 2743, epoch: 19, loss: 0.653790
global_step: 2744, epoch: 19, loss: 0.761304
global_step: 2745, epoch: 19, loss: 0.779753
global_step: 2746, epoch: 19, loss: 0.769674
global_step: 2747, epoch: 19, loss: 0.738447
global_step: 2748, epoch: 19, loss: 0.711051
global_step: 2749, epoch: 19, loss: 0.801026
global_step: 2750, epoch: 19, loss: 0.702044
global_step: 2751, epoch: 19, loss: 0.700847
global_step: 2752, epoch: 19, loss: 0.757294
global_step: 2753, epoch: 19, loss: 0.748344
global_step: 2754, epoch: 19, loss: 0.755173
global_step: 2755, epoch: 19, loss: 0.732630
global_step: 2756, epoch: 19, loss: 0.783458
global_step: 2757, epoch: 19, loss: 0.862478
global_step: 2758, epoch: 19, loss: 0.780903
global_step: 2759, epoch: 19, loss: 0.825400
global_step: 2760, epoch: 19, loss: 0.929801
epoch: 19
train	acc: 0.7936	macro: p 0.8284, r 0.5723, f1: 0.5969	micro: p 0.7936, r 0.7936, f1 0.7936	weighted_f1:0.7720
dev	acc: 0.5555	macro: p 0.4435, r 0.3448, f1: 0.3300	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5110
test	acc: 0.5762	macro: p 0.4417, r 0.3415, f1: 0.3260	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5459
global_step: 2761, epoch: 20, loss: 0.763114
global_step: 2762, epoch: 20, loss: 0.609284
global_step: 2763, epoch: 20, loss: 0.694449
global_step: 2764, epoch: 20, loss: 0.761621
global_step: 2765, epoch: 20, loss: 0.738723
global_step: 2766, epoch: 20, loss: 0.785766
global_step: 2767, epoch: 20, loss: 0.719612
global_step: 2768, epoch: 20, loss: 0.700257
global_step: 2769, epoch: 20, loss: 0.557285
global_step: 2770, epoch: 20, loss: 0.672313
global_step: 2771, epoch: 20, loss: 0.769920
global_step: 2772, epoch: 20, loss: 0.676926
global_step: 2773, epoch: 20, loss: 0.744232
global_step: 2774, epoch: 20, loss: 0.721803
global_step: 2775, epoch: 20, loss: 0.673341
global_step: 2776, epoch: 20, loss: 0.648708
global_step: 2777, epoch: 20, loss: 0.623443
global_step: 2778, epoch: 20, loss: 0.781137
global_step: 2779, epoch: 20, loss: 0.716462
global_step: 2780, epoch: 20, loss: 0.756199
global_step: 2781, epoch: 20, loss: 0.793384
global_step: 2782, epoch: 20, loss: 0.646536
global_step: 2783, epoch: 20, loss: 0.693522
global_step: 2784, epoch: 20, loss: 0.733623
global_step: 2785, epoch: 20, loss: 0.747729
global_step: 2786, epoch: 20, loss: 0.683277
global_step: 2787, epoch: 20, loss: 0.589214
global_step: 2788, epoch: 20, loss: 0.684005
global_step: 2789, epoch: 20, loss: 0.763961
global_step: 2790, epoch: 20, loss: 0.658760
global_step: 2791, epoch: 20, loss: 0.705863
global_step: 2792, epoch: 20, loss: 0.772124
global_step: 2793, epoch: 20, loss: 0.723098
global_step: 2794, epoch: 20, loss: 0.764544
global_step: 2795, epoch: 20, loss: 0.764936
global_step: 2796, epoch: 20, loss: 0.810036
global_step: 2797, epoch: 20, loss: 0.762003
global_step: 2798, epoch: 20, loss: 0.952166
global_step: 2799, epoch: 20, loss: 0.720249
global_step: 2800, epoch: 20, loss: 1.687950
epoch: 20
train	acc: 0.7749	macro: p 0.7837, r 0.5795, f1: 0.6341	micro: p 0.7749, r 0.7749, f1 0.7749	weighted_f1:0.7580
dev	acc: 0.5473	macro: p 0.4581, r 0.3194, f1: 0.3295	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4884
test	acc: 0.5916	macro: p 0.4639, r 0.3195, f1: 0.3314	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5373
global_step: 2801, epoch: 21, loss: 0.789957
global_step: 2802, epoch: 21, loss: 0.698044
global_step: 2803, epoch: 21, loss: 0.622655
global_step: 2804, epoch: 21, loss: 0.697376
global_step: 2805, epoch: 21, loss: 0.744887
global_step: 2806, epoch: 21, loss: 0.738535
global_step: 2807, epoch: 21, loss: 0.585605
global_step: 2808, epoch: 21, loss: 0.606197
global_step: 2809, epoch: 21, loss: 0.730699
global_step: 2810, epoch: 21, loss: 0.556860
global_step: 2811, epoch: 21, loss: 0.593605
global_step: 2812, epoch: 21, loss: 0.691213
global_step: 2813, epoch: 21, loss: 0.602104
global_step: 2814, epoch: 21, loss: 0.696684
global_step: 2815, epoch: 21, loss: 0.633717
global_step: 2816, epoch: 21, loss: 0.641110
global_step: 2817, epoch: 21, loss: 0.752080
global_step: 2818, epoch: 21, loss: 0.644683
global_step: 2819, epoch: 21, loss: 0.675385
global_step: 2820, epoch: 21, loss: 0.694294
global_step: 2821, epoch: 21, loss: 0.621801
global_step: 2822, epoch: 21, loss: 0.646499
global_step: 2823, epoch: 21, loss: 0.565080
global_step: 2824, epoch: 21, loss: 0.557554
global_step: 2825, epoch: 21, loss: 0.559792
global_step: 2826, epoch: 21, loss: 0.646646
global_step: 2827, epoch: 21, loss: 0.624034
global_step: 2828, epoch: 21, loss: 0.677934
global_step: 2829, epoch: 21, loss: 0.676365
global_step: 2830, epoch: 21, loss: 0.733212
global_step: 2831, epoch: 21, loss: 0.660883
global_step: 2832, epoch: 21, loss: 0.869389
global_step: 2833, epoch: 21, loss: 0.783944
global_step: 2834, epoch: 21, loss: 0.869577
global_step: 2835, epoch: 21, loss: 0.759043
global_step: 2836, epoch: 21, loss: 0.608784
global_step: 2837, epoch: 21, loss: 0.762911
global_step: 2838, epoch: 21, loss: 0.645499
global_step: 2839, epoch: 21, loss: 0.763789
global_step: 2840, epoch: 21, loss: 1.421059
epoch: 21
train	acc: 0.8437	macro: p 0.8610, r 0.6994, f1: 0.7551	micro: p 0.8437, r 0.8437, f1 0.8437	weighted_f1:0.8367
dev	acc: 0.5645	macro: p 0.4409, r 0.3409, f1: 0.3550	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5184
test	acc: 0.6084	macro: p 0.4720, r 0.3492, f1: 0.3745	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5712
global_step: 2841, epoch: 22, loss: 0.680840
global_step: 2842, epoch: 22, loss: 0.588702
global_step: 2843, epoch: 22, loss: 0.623556
global_step: 2844, epoch: 22, loss: 0.669113
global_step: 2845, epoch: 22, loss: 0.617096
global_step: 2846, epoch: 22, loss: 0.608060
global_step: 2847, epoch: 22, loss: 0.604932
global_step: 2848, epoch: 22, loss: 0.590333
global_step: 2849, epoch: 22, loss: 0.702483
global_step: 2850, epoch: 22, loss: 0.572129
global_step: 2851, epoch: 22, loss: 0.605037
global_step: 2852, epoch: 22, loss: 0.545493
global_step: 2853, epoch: 22, loss: 0.606887
global_step: 2854, epoch: 22, loss: 0.626550
global_step: 2855, epoch: 22, loss: 0.615961
global_step: 2856, epoch: 22, loss: 0.619696
global_step: 2857, epoch: 22, loss: 0.620265
global_step: 2858, epoch: 22, loss: 0.662897
global_step: 2859, epoch: 22, loss: 0.586057
global_step: 2860, epoch: 22, loss: 0.656377
global_step: 2861, epoch: 22, loss: 0.642342
global_step: 2862, epoch: 22, loss: 0.636465
global_step: 2863, epoch: 22, loss: 0.739025
global_step: 2864, epoch: 22, loss: 0.638775
global_step: 2865, epoch: 22, loss: 0.686714
global_step: 2866, epoch: 22, loss: 0.688271
global_step: 2867, epoch: 22, loss: 0.754356
global_step: 2868, epoch: 22, loss: 0.670233
global_step: 2869, epoch: 22, loss: 0.644968
global_step: 2870, epoch: 22, loss: 0.735455
global_step: 2871, epoch: 22, loss: 0.539376
global_step: 2872, epoch: 22, loss: 0.624676
global_step: 2873, epoch: 22, loss: 0.602300
global_step: 2874, epoch: 22, loss: 0.760446
global_step: 2875, epoch: 22, loss: 0.712813
global_step: 2876, epoch: 22, loss: 0.699674
global_step: 2877, epoch: 22, loss: 0.743439
global_step: 2878, epoch: 22, loss: 0.673713
global_step: 2879, epoch: 22, loss: 0.666956
global_step: 2880, epoch: 22, loss: 0.657691
epoch: 22
train	acc: 0.8557	macro: p 0.8445, r 0.7326, f1: 0.7725	micro: p 0.8557, r 0.8557, f1 0.8557	weighted_f1:0.8514
dev	acc: 0.5681	macro: p 0.4482, r 0.3590, f1: 0.3720	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5291
test	acc: 0.6042	macro: p 0.4465, r 0.3543, f1: 0.3662	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5711
global_step: 2881, epoch: 23, loss: 0.609380
global_step: 2882, epoch: 23, loss: 0.608829
global_step: 2883, epoch: 23, loss: 0.654358
global_step: 2884, epoch: 23, loss: 0.651122
global_step: 2885, epoch: 23, loss: 0.615763
global_step: 2886, epoch: 23, loss: 0.692852
global_step: 2887, epoch: 23, loss: 0.580102
global_step: 2888, epoch: 23, loss: 0.591696
global_step: 2889, epoch: 23, loss: 0.542868
global_step: 2890, epoch: 23, loss: 0.582891
global_step: 2891, epoch: 23, loss: 0.622280
global_step: 2892, epoch: 23, loss: 0.738936
global_step: 2893, epoch: 23, loss: 0.687405
global_step: 2894, epoch: 23, loss: 0.565913
global_step: 2895, epoch: 23, loss: 0.675294
global_step: 2896, epoch: 23, loss: 0.638882
global_step: 2897, epoch: 23, loss: 0.617181
global_step: 2898, epoch: 23, loss: 0.560873
global_step: 2899, epoch: 23, loss: 0.608163
global_step: 2900, epoch: 23, loss: 0.512083
global_step: 2901, epoch: 23, loss: 0.564106
global_step: 2902, epoch: 23, loss: 0.580908
global_step: 2903, epoch: 23, loss: 0.678485
global_step: 2904, epoch: 23, loss: 0.601548
global_step: 2905, epoch: 23, loss: 0.613190
global_step: 2906, epoch: 23, loss: 0.609077
global_step: 2907, epoch: 23, loss: 0.674499
global_step: 2908, epoch: 23, loss: 0.585354
global_step: 2909, epoch: 23, loss: 0.642303
global_step: 2910, epoch: 23, loss: 0.601960
global_step: 2911, epoch: 23, loss: 0.669948
global_step: 2912, epoch: 23, loss: 0.599723
global_step: 2913, epoch: 23, loss: 0.622813
global_step: 2914, epoch: 23, loss: 0.696075
global_step: 2915, epoch: 23, loss: 0.551425
global_step: 2916, epoch: 23, loss: 0.647876
global_step: 2917, epoch: 23, loss: 0.689726
global_step: 2918, epoch: 23, loss: 0.608172
global_step: 2919, epoch: 23, loss: 0.671183
global_step: 2920, epoch: 23, loss: 1.316327
epoch: 23
train	acc: 0.8039	macro: p 0.8492, r 0.6291, f1: 0.6776	micro: p 0.8039, r 0.8039, f1 0.8039	weighted_f1:0.7909
dev	acc: 0.5347	macro: p 0.4884, r 0.3208, f1: 0.3429	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4819
test	acc: 0.5854	macro: p 0.5303, r 0.3256, f1: 0.3529	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5361
global_step: 2921, epoch: 24, loss: 0.642177
global_step: 2922, epoch: 24, loss: 0.604586
global_step: 2923, epoch: 24, loss: 0.760164
global_step: 2924, epoch: 24, loss: 0.745898
global_step: 2925, epoch: 24, loss: 0.577608
global_step: 2926, epoch: 24, loss: 0.609009
global_step: 2927, epoch: 24, loss: 0.670426
global_step: 2928, epoch: 24, loss: 0.573677
global_step: 2929, epoch: 24, loss: 0.689239
global_step: 2930, epoch: 24, loss: 0.589007
global_step: 2931, epoch: 24, loss: 0.602021
global_step: 2932, epoch: 24, loss: 0.574679
global_step: 2933, epoch: 24, loss: 0.663148
global_step: 2934, epoch: 24, loss: 0.564541
global_step: 2935, epoch: 24, loss: 0.528804
global_step: 2936, epoch: 24, loss: 0.509042
global_step: 2937, epoch: 24, loss: 0.615429
global_step: 2938, epoch: 24, loss: 0.563237
global_step: 2939, epoch: 24, loss: 0.563406
global_step: 2940, epoch: 24, loss: 0.513738
global_step: 2941, epoch: 24, loss: 0.590138
global_step: 2942, epoch: 24, loss: 0.693325
global_step: 2943, epoch: 24, loss: 0.586417
global_step: 2944, epoch: 24, loss: 0.618086
global_step: 2945, epoch: 24, loss: 0.550787
global_step: 2946, epoch: 24, loss: 0.729296
global_step: 2947, epoch: 24, loss: 0.602920
global_step: 2948, epoch: 24, loss: 0.640750
global_step: 2949, epoch: 24, loss: 0.578144
global_step: 2950, epoch: 24, loss: 0.648200
global_step: 2951, epoch: 24, loss: 0.614406
global_step: 2952, epoch: 24, loss: 0.549972
global_step: 2953, epoch: 24, loss: 0.478309
global_step: 2954, epoch: 24, loss: 0.585184
global_step: 2955, epoch: 24, loss: 0.683811
global_step: 2956, epoch: 24, loss: 0.495577
global_step: 2957, epoch: 24, loss: 0.699814
global_step: 2958, epoch: 24, loss: 0.732151
global_step: 2959, epoch: 24, loss: 0.615073
global_step: 2960, epoch: 24, loss: 0.911156
epoch: 24
train	acc: 0.8548	macro: p 0.8375, r 0.7178, f1: 0.7473	micro: p 0.8548, r 0.8548, f1 0.8548	weighted_f1:0.8517
dev	acc: 0.5546	macro: p 0.4502, r 0.3610, f1: 0.3682	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5268
test	acc: 0.5797	macro: p 0.4274, r 0.3470, f1: 0.3482	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5556
global_step: 2961, epoch: 25, loss: 0.602179
global_step: 2962, epoch: 25, loss: 0.568780
global_step: 2963, epoch: 25, loss: 0.593152
global_step: 2964, epoch: 25, loss: 0.671153
global_step: 2965, epoch: 25, loss: 0.476537
global_step: 2966, epoch: 25, loss: 0.554356
global_step: 2967, epoch: 25, loss: 0.552706
global_step: 2968, epoch: 25, loss: 0.533822
global_step: 2969, epoch: 25, loss: 0.493633
global_step: 2970, epoch: 25, loss: 0.574153
global_step: 2971, epoch: 25, loss: 0.563679
global_step: 2972, epoch: 25, loss: 0.649447
global_step: 2973, epoch: 25, loss: 0.645863
global_step: 2974, epoch: 25, loss: 0.521816
global_step: 2975, epoch: 25, loss: 0.484324
global_step: 2976, epoch: 25, loss: 0.556056
global_step: 2977, epoch: 25, loss: 0.681716
global_step: 2978, epoch: 25, loss: 0.583434
global_step: 2979, epoch: 25, loss: 0.651470
global_step: 2980, epoch: 25, loss: 0.576429
global_step: 2981, epoch: 25, loss: 0.487666
global_step: 2982, epoch: 25, loss: 0.501508
global_step: 2983, epoch: 25, loss: 0.487638
global_step: 2984, epoch: 25, loss: 0.629894
global_step: 2985, epoch: 25, loss: 0.580362
global_step: 2986, epoch: 25, loss: 0.578798
global_step: 2987, epoch: 25, loss: 0.532973
global_step: 2988, epoch: 25, loss: 0.717028
global_step: 2989, epoch: 25, loss: 0.532097
global_step: 2990, epoch: 25, loss: 0.583929
global_step: 2991, epoch: 25, loss: 0.574636
global_step: 2992, epoch: 25, loss: 0.634029
global_step: 2993, epoch: 25, loss: 0.556924
global_step: 2994, epoch: 25, loss: 0.595003
global_step: 2995, epoch: 25, loss: 0.608403
global_step: 2996, epoch: 25, loss: 0.642264
global_step: 2997, epoch: 25, loss: 0.614897
global_step: 2998, epoch: 25, loss: 0.573838
global_step: 2999, epoch: 25, loss: 0.513548
global_step: 3000, epoch: 25, loss: 1.695653
epoch: 25
train	acc: 0.8562	macro: p 0.8561, r 0.7673, f1: 0.7881	micro: p 0.8562, r 0.8562, f1 0.8562	weighted_f1:0.8561
dev	acc: 0.5257	macro: p 0.4665, r 0.3701, f1: 0.3512	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4997
test	acc: 0.5510	macro: p 0.3688, r 0.3596, f1: 0.3369	micro: p 0.5510, r 0.5510, f1 0.5510	weighted_f1:0.5395
global_step: 3001, epoch: 26, loss: 0.821488
global_step: 3002, epoch: 26, loss: 0.572476
global_step: 3003, epoch: 26, loss: 0.596997
global_step: 3004, epoch: 26, loss: 0.558554
global_step: 3005, epoch: 26, loss: 0.525660
global_step: 3006, epoch: 26, loss: 0.498851
global_step: 3007, epoch: 26, loss: 0.518691
global_step: 3008, epoch: 26, loss: 0.606719
global_step: 3009, epoch: 26, loss: 0.593217
global_step: 3010, epoch: 26, loss: 0.565630
global_step: 3011, epoch: 26, loss: 0.597611
global_step: 3012, epoch: 26, loss: 0.531267
global_step: 3013, epoch: 26, loss: 0.441220
global_step: 3014, epoch: 26, loss: 0.524975
global_step: 3015, epoch: 26, loss: 0.515587
global_step: 3016, epoch: 26, loss: 0.558937
global_step: 3017, epoch: 26, loss: 0.539530
global_step: 3018, epoch: 26, loss: 0.564036
global_step: 3019, epoch: 26, loss: 0.577718
global_step: 3020, epoch: 26, loss: 0.607858
global_step: 3021, epoch: 26, loss: 0.543827
global_step: 3022, epoch: 26, loss: 0.521750
global_step: 3023, epoch: 26, loss: 0.569764
global_step: 3024, epoch: 26, loss: 0.472048
global_step: 3025, epoch: 26, loss: 0.594331
global_step: 3026, epoch: 26, loss: 0.521609
global_step: 3027, epoch: 26, loss: 0.468878
global_step: 3028, epoch: 26, loss: 0.525251
global_step: 3029, epoch: 26, loss: 0.546618
global_step: 3030, epoch: 26, loss: 0.550668
global_step: 3031, epoch: 26, loss: 0.496721
global_step: 3032, epoch: 26, loss: 0.491150
global_step: 3033, epoch: 26, loss: 0.630189
global_step: 3034, epoch: 26, loss: 0.557946
global_step: 3035, epoch: 26, loss: 0.587457
global_step: 3036, epoch: 26, loss: 0.487260
global_step: 3037, epoch: 26, loss: 0.434484
global_step: 3038, epoch: 26, loss: 0.616223
global_step: 3039, epoch: 26, loss: 0.634911
global_step: 3040, epoch: 26, loss: 0.233062
epoch: 26
train	acc: 0.8796	macro: p 0.9046, r 0.7634, f1: 0.8143	micro: p 0.8796, r 0.8796, f1 0.8796	weighted_f1:0.8756
dev	acc: 0.5726	macro: p 0.4915, r 0.3616, f1: 0.3842	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5327
test	acc: 0.6069	macro: p 0.4735, r 0.3548, f1: 0.3753	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5703
New best model!
global_step: 3041, epoch: 27, loss: 0.471286
global_step: 3042, epoch: 27, loss: 0.577158
global_step: 3043, epoch: 27, loss: 0.591168
global_step: 3044, epoch: 27, loss: 0.487780
global_step: 3045, epoch: 27, loss: 0.445523
global_step: 3046, epoch: 27, loss: 0.470981
global_step: 3047, epoch: 27, loss: 0.494492
global_step: 3048, epoch: 27, loss: 0.411581
global_step: 3049, epoch: 27, loss: 0.545419
global_step: 3050, epoch: 27, loss: 0.502914
global_step: 3051, epoch: 27, loss: 0.505733
global_step: 3052, epoch: 27, loss: 0.558051
global_step: 3053, epoch: 27, loss: 0.494293
global_step: 3054, epoch: 27, loss: 0.486090
global_step: 3055, epoch: 27, loss: 0.515550
global_step: 3056, epoch: 27, loss: 0.556063
global_step: 3057, epoch: 27, loss: 0.563031
global_step: 3058, epoch: 27, loss: 0.517501
global_step: 3059, epoch: 27, loss: 0.475459
global_step: 3060, epoch: 27, loss: 0.573449
global_step: 3061, epoch: 27, loss: 0.488499
global_step: 3062, epoch: 27, loss: 0.489539
global_step: 3063, epoch: 27, loss: 0.513407
global_step: 3064, epoch: 27, loss: 0.439777
global_step: 3065, epoch: 27, loss: 0.562499
global_step: 3066, epoch: 27, loss: 0.690632
global_step: 3067, epoch: 27, loss: 0.648229
global_step: 3068, epoch: 27, loss: 0.612550
global_step: 3069, epoch: 27, loss: 0.634309
global_step: 3070, epoch: 27, loss: 0.607541
global_step: 3071, epoch: 27, loss: 0.648164
global_step: 3072, epoch: 27, loss: 0.531324
global_step: 3073, epoch: 27, loss: 0.577281
global_step: 3074, epoch: 27, loss: 0.671404
global_step: 3075, epoch: 27, loss: 0.502476
global_step: 3076, epoch: 27, loss: 0.634924
global_step: 3077, epoch: 27, loss: 0.574141
global_step: 3078, epoch: 27, loss: 0.600144
global_step: 3079, epoch: 27, loss: 0.557479
global_step: 3080, epoch: 27, loss: 0.060357
epoch: 27
train	acc: 0.8792	macro: p 0.9105, r 0.7593, f1: 0.8123	micro: p 0.8792, r 0.8792, f1 0.8792	weighted_f1:0.8751
dev	acc: 0.5663	macro: p 0.5591, r 0.3409, f1: 0.3452	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5149
test	acc: 0.5950	macro: p 0.4103, r 0.3337, f1: 0.3362	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5519
global_step: 3081, epoch: 28, loss: 0.448402
global_step: 3082, epoch: 28, loss: 0.544295
global_step: 3083, epoch: 28, loss: 0.508807
global_step: 3084, epoch: 28, loss: 0.439260
global_step: 3085, epoch: 28, loss: 0.487682
global_step: 3086, epoch: 28, loss: 0.495453
global_step: 3087, epoch: 28, loss: 0.492552
global_step: 3088, epoch: 28, loss: 0.488327
global_step: 3089, epoch: 28, loss: 0.446636
global_step: 3090, epoch: 28, loss: 0.528308
global_step: 3091, epoch: 28, loss: 0.606377
global_step: 3092, epoch: 28, loss: 0.458349
global_step: 3093, epoch: 28, loss: 0.459796
global_step: 3094, epoch: 28, loss: 0.518041
global_step: 3095, epoch: 28, loss: 0.521138
global_step: 3096, epoch: 28, loss: 0.664191
global_step: 3097, epoch: 28, loss: 0.637141
global_step: 3098, epoch: 28, loss: 0.529290
global_step: 3099, epoch: 28, loss: 0.586358
global_step: 3100, epoch: 28, loss: 0.506404
global_step: 3101, epoch: 28, loss: 0.499431
global_step: 3102, epoch: 28, loss: 0.541962
global_step: 3103, epoch: 28, loss: 0.516970
global_step: 3104, epoch: 28, loss: 0.526797
global_step: 3105, epoch: 28, loss: 0.487447
global_step: 3106, epoch: 28, loss: 0.471460
global_step: 3107, epoch: 28, loss: 0.565448
global_step: 3108, epoch: 28, loss: 0.549385
global_step: 3109, epoch: 28, loss: 0.487408
global_step: 3110, epoch: 28, loss: 0.547401
global_step: 3111, epoch: 28, loss: 0.696895
global_step: 3112, epoch: 28, loss: 0.668332
global_step: 3113, epoch: 28, loss: 0.454307
global_step: 3114, epoch: 28, loss: 0.500797
global_step: 3115, epoch: 28, loss: 0.535905
global_step: 3116, epoch: 28, loss: 0.479169
global_step: 3117, epoch: 28, loss: 0.553641
global_step: 3118, epoch: 28, loss: 0.617965
global_step: 3119, epoch: 28, loss: 0.657699
global_step: 3120, epoch: 28, loss: 0.461816
epoch: 28
train	acc: 0.8681	macro: p 0.8979, r 0.7419, f1: 0.7871	micro: p 0.8681, r 0.8681, f1 0.8681	weighted_f1:0.8645
dev	acc: 0.5446	macro: p 0.5645, r 0.3405, f1: 0.3343	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5042
test	acc: 0.5751	macro: p 0.4116, r 0.3445, f1: 0.3286	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5405
global_step: 3121, epoch: 29, loss: 0.679642
global_step: 3122, epoch: 29, loss: 0.437261
global_step: 3123, epoch: 29, loss: 0.456931
global_step: 3124, epoch: 29, loss: 0.496608
global_step: 3125, epoch: 29, loss: 0.451315
global_step: 3126, epoch: 29, loss: 0.472031
global_step: 3127, epoch: 29, loss: 0.466219
global_step: 3128, epoch: 29, loss: 0.617381
global_step: 3129, epoch: 29, loss: 0.552890
global_step: 3130, epoch: 29, loss: 0.500561
global_step: 3131, epoch: 29, loss: 0.456109
global_step: 3132, epoch: 29, loss: 0.523448
global_step: 3133, epoch: 29, loss: 0.489816
global_step: 3134, epoch: 29, loss: 0.495513
global_step: 3135, epoch: 29, loss: 0.553878
global_step: 3136, epoch: 29, loss: 0.572405
global_step: 3137, epoch: 29, loss: 0.476127
global_step: 3138, epoch: 29, loss: 0.390704
global_step: 3139, epoch: 29, loss: 0.638937
global_step: 3140, epoch: 29, loss: 0.530015
global_step: 3141, epoch: 29, loss: 0.422141
global_step: 3142, epoch: 29, loss: 0.522208
global_step: 3143, epoch: 29, loss: 0.566592
global_step: 3144, epoch: 29, loss: 0.632044
global_step: 3145, epoch: 29, loss: 0.489455
global_step: 3146, epoch: 29, loss: 0.538066
global_step: 3147, epoch: 29, loss: 0.505009
global_step: 3148, epoch: 29, loss: 0.494028
global_step: 3149, epoch: 29, loss: 0.535308
global_step: 3150, epoch: 29, loss: 0.521409
global_step: 3151, epoch: 29, loss: 0.451883
global_step: 3152, epoch: 29, loss: 0.577253
global_step: 3153, epoch: 29, loss: 0.534696
global_step: 3154, epoch: 29, loss: 0.563889
global_step: 3155, epoch: 29, loss: 0.497697
global_step: 3156, epoch: 29, loss: 0.538325
global_step: 3157, epoch: 29, loss: 0.525793
global_step: 3158, epoch: 29, loss: 0.418388
global_step: 3159, epoch: 29, loss: 0.474937
global_step: 3160, epoch: 29, loss: 2.760921
epoch: 29
train	acc: 0.8757	macro: p 0.8314, r 0.8294, f1: 0.8181	micro: p 0.8757, r 0.8757, f1 0.8757	weighted_f1:0.8770
dev	acc: 0.5059	macro: p 0.3889, r 0.3853, f1: 0.3561	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.5000
test	acc: 0.5364	macro: p 0.3691, r 0.3757, f1: 0.3545	micro: p 0.5364, r 0.5364, f1 0.5364	weighted_f1:0.5426
global_step: 3161, epoch: 30, loss: 0.862362
global_step: 3162, epoch: 30, loss: 0.591630
global_step: 3163, epoch: 30, loss: 0.544112
global_step: 3164, epoch: 30, loss: 0.454482
global_step: 3165, epoch: 30, loss: 0.530001
global_step: 3166, epoch: 30, loss: 0.618425
global_step: 3167, epoch: 30, loss: 0.503458
global_step: 3168, epoch: 30, loss: 0.438192
global_step: 3169, epoch: 30, loss: 0.512627
global_step: 3170, epoch: 30, loss: 0.417299
global_step: 3171, epoch: 30, loss: 0.435103
global_step: 3172, epoch: 30, loss: 0.391355
global_step: 3173, epoch: 30, loss: 0.426123
global_step: 3174, epoch: 30, loss: 0.601886
global_step: 3175, epoch: 30, loss: 0.410334
global_step: 3176, epoch: 30, loss: 0.581474
global_step: 3177, epoch: 30, loss: 0.511699
global_step: 3178, epoch: 30, loss: 0.481568
global_step: 3179, epoch: 30, loss: 0.446429
global_step: 3180, epoch: 30, loss: 0.546437
global_step: 3181, epoch: 30, loss: 0.437507
global_step: 3182, epoch: 30, loss: 0.451826
global_step: 3183, epoch: 30, loss: 0.557787
global_step: 3184, epoch: 30, loss: 0.518949
global_step: 3185, epoch: 30, loss: 0.502645
global_step: 3186, epoch: 30, loss: 0.505531
global_step: 3187, epoch: 30, loss: 0.488739
global_step: 3188, epoch: 30, loss: 0.465701
global_step: 3189, epoch: 30, loss: 0.602171
global_step: 3190, epoch: 30, loss: 0.481025
global_step: 3191, epoch: 30, loss: 0.427860
global_step: 3192, epoch: 30, loss: 0.556822
global_step: 3193, epoch: 30, loss: 0.460269
global_step: 3194, epoch: 30, loss: 0.478356
global_step: 3195, epoch: 30, loss: 0.472801
global_step: 3196, epoch: 30, loss: 0.483930
global_step: 3197, epoch: 30, loss: 0.571269
global_step: 3198, epoch: 30, loss: 0.581500
global_step: 3199, epoch: 30, loss: 0.509312
global_step: 3200, epoch: 30, loss: 0.156630
epoch: 30
train	acc: 0.9106	macro: p 0.9200, r 0.8469, f1: 0.8754	micro: p 0.9106, r 0.9106, f1 0.9106	weighted_f1:0.9100
dev	acc: 0.5464	macro: p 0.4853, r 0.3644, f1: 0.3744	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5240
test	acc: 0.5713	macro: p 0.4316, r 0.3625, f1: 0.3698	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5554
global_step: 3201, epoch: 31, loss: 0.494510
global_step: 3202, epoch: 31, loss: 0.455697
global_step: 3203, epoch: 31, loss: 0.411216
global_step: 3204, epoch: 31, loss: 0.472108
global_step: 3205, epoch: 31, loss: 0.455429
global_step: 3206, epoch: 31, loss: 0.501100
global_step: 3207, epoch: 31, loss: 0.479710
global_step: 3208, epoch: 31, loss: 0.417139
global_step: 3209, epoch: 31, loss: 0.431756
global_step: 3210, epoch: 31, loss: 0.443117
global_step: 3211, epoch: 31, loss: 0.437130
global_step: 3212, epoch: 31, loss: 0.495973
global_step: 3213, epoch: 31, loss: 0.417898
global_step: 3214, epoch: 31, loss: 0.395229
global_step: 3215, epoch: 31, loss: 0.456948
global_step: 3216, epoch: 31, loss: 0.479584
global_step: 3217, epoch: 31, loss: 0.567702
global_step: 3218, epoch: 31, loss: 0.405194
global_step: 3219, epoch: 31, loss: 0.499005
global_step: 3220, epoch: 31, loss: 0.417189
global_step: 3221, epoch: 31, loss: 0.432909
global_step: 3222, epoch: 31, loss: 0.578232
global_step: 3223, epoch: 31, loss: 0.417913
global_step: 3224, epoch: 31, loss: 0.612825
global_step: 3225, epoch: 31, loss: 0.484729
global_step: 3226, epoch: 31, loss: 0.387640
global_step: 3227, epoch: 31, loss: 0.437723
global_step: 3228, epoch: 31, loss: 0.473120
global_step: 3229, epoch: 31, loss: 0.415876
global_step: 3230, epoch: 31, loss: 0.435739
global_step: 3231, epoch: 31, loss: 0.420309
global_step: 3232, epoch: 31, loss: 0.514557
global_step: 3233, epoch: 31, loss: 0.525110
global_step: 3234, epoch: 31, loss: 0.533371
global_step: 3235, epoch: 31, loss: 0.471530
global_step: 3236, epoch: 31, loss: 0.627876
global_step: 3237, epoch: 31, loss: 0.519113
global_step: 3238, epoch: 31, loss: 0.528383
global_step: 3239, epoch: 31, loss: 0.527030
global_step: 3240, epoch: 31, loss: 0.157176
epoch: 31
train	acc: 0.8825	macro: p 0.9124, r 0.7940, f1: 0.8407	micro: p 0.8825, r 0.8825, f1 0.8825	weighted_f1:0.8799
dev	acc: 0.5582	macro: p 0.4965, r 0.3466, f1: 0.3556	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5049
test	acc: 0.5977	macro: p 0.4232, r 0.3358, f1: 0.3438	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5522
global_step: 3241, epoch: 32, loss: 0.504574
global_step: 3242, epoch: 32, loss: 0.493629
global_step: 3243, epoch: 32, loss: 0.409166
global_step: 3244, epoch: 32, loss: 0.417699
global_step: 3245, epoch: 32, loss: 0.408043
global_step: 3246, epoch: 32, loss: 0.370827
global_step: 3247, epoch: 32, loss: 0.490107
global_step: 3248, epoch: 32, loss: 0.484228
global_step: 3249, epoch: 32, loss: 0.496517
global_step: 3250, epoch: 32, loss: 0.401844
global_step: 3251, epoch: 32, loss: 0.480742
global_step: 3252, epoch: 32, loss: 0.512557
global_step: 3253, epoch: 32, loss: 0.374587
global_step: 3254, epoch: 32, loss: 0.421831
global_step: 3255, epoch: 32, loss: 0.357365
global_step: 3256, epoch: 32, loss: 0.529090
global_step: 3257, epoch: 32, loss: 0.578672
global_step: 3258, epoch: 32, loss: 0.421740
global_step: 3259, epoch: 32, loss: 0.455175
global_step: 3260, epoch: 32, loss: 0.470041
global_step: 3261, epoch: 32, loss: 0.481555
global_step: 3262, epoch: 32, loss: 0.443437
global_step: 3263, epoch: 32, loss: 0.498200
global_step: 3264, epoch: 32, loss: 0.430984
global_step: 3265, epoch: 32, loss: 0.477994
global_step: 3266, epoch: 32, loss: 0.456200
global_step: 3267, epoch: 32, loss: 0.475207
global_step: 3268, epoch: 32, loss: 0.444339
global_step: 3269, epoch: 32, loss: 0.506128
global_step: 3270, epoch: 32, loss: 0.476422
global_step: 3271, epoch: 32, loss: 0.451864
global_step: 3272, epoch: 32, loss: 0.430894
global_step: 3273, epoch: 32, loss: 0.567317
global_step: 3274, epoch: 32, loss: 0.508859
global_step: 3275, epoch: 32, loss: 0.466480
global_step: 3276, epoch: 32, loss: 0.415574
global_step: 3277, epoch: 32, loss: 0.530347
global_step: 3278, epoch: 32, loss: 0.529770
global_step: 3279, epoch: 32, loss: 0.617396
global_step: 3280, epoch: 32, loss: 0.431740
epoch: 32
train	acc: 0.8648	macro: p 0.9016, r 0.7289, f1: 0.7833	micro: p 0.8648, r 0.8648, f1 0.8648	weighted_f1:0.8582
dev	acc: 0.5618	macro: p 0.4556, r 0.3322, f1: 0.3392	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5088
test	acc: 0.5927	macro: p 0.4444, r 0.3233, f1: 0.3324	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5421
global_step: 3281, epoch: 33, loss: 0.615181
global_step: 3282, epoch: 33, loss: 0.496011
global_step: 3283, epoch: 33, loss: 0.504163
global_step: 3284, epoch: 33, loss: 0.411254
global_step: 3285, epoch: 33, loss: 0.461878
global_step: 3286, epoch: 33, loss: 0.538757
global_step: 3287, epoch: 33, loss: 0.523314
global_step: 3288, epoch: 33, loss: 0.412567
global_step: 3289, epoch: 33, loss: 0.466796
global_step: 3290, epoch: 33, loss: 0.429556
global_step: 3291, epoch: 33, loss: 0.412205
global_step: 3292, epoch: 33, loss: 0.428320
global_step: 3293, epoch: 33, loss: 0.441269
global_step: 3294, epoch: 33, loss: 0.443290
global_step: 3295, epoch: 33, loss: 0.366930
global_step: 3296, epoch: 33, loss: 0.435970
global_step: 3297, epoch: 33, loss: 0.372921
global_step: 3298, epoch: 33, loss: 0.467131
global_step: 3299, epoch: 33, loss: 0.499848
global_step: 3300, epoch: 33, loss: 0.418720
global_step: 3301, epoch: 33, loss: 0.406777
global_step: 3302, epoch: 33, loss: 0.516474
global_step: 3303, epoch: 33, loss: 0.474748
global_step: 3304, epoch: 33, loss: 0.512317
global_step: 3305, epoch: 33, loss: 0.428122
global_step: 3306, epoch: 33, loss: 0.439998
global_step: 3307, epoch: 33, loss: 0.424860
global_step: 3308, epoch: 33, loss: 0.452956
global_step: 3309, epoch: 33, loss: 0.427282
global_step: 3310, epoch: 33, loss: 0.643833
global_step: 3311, epoch: 33, loss: 0.597724
global_step: 3312, epoch: 33, loss: 0.536080
global_step: 3313, epoch: 33, loss: 0.614934
global_step: 3314, epoch: 33, loss: 0.537435
global_step: 3315, epoch: 33, loss: 0.547490
global_step: 3316, epoch: 33, loss: 0.468469
global_step: 3317, epoch: 33, loss: 0.507824
global_step: 3318, epoch: 33, loss: 0.608263
global_step: 3319, epoch: 33, loss: 0.551504
global_step: 3320, epoch: 33, loss: 0.999271
epoch: 33
train	acc: 0.8784	macro: p 0.8923, r 0.8348, f1: 0.8525	micro: p 0.8784, r 0.8784, f1 0.8784	weighted_f1:0.8796
dev	acc: 0.5104	macro: p 0.4429, r 0.3616, f1: 0.3638	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.5078
test	acc: 0.5226	macro: p 0.4104, r 0.3609, f1: 0.3576	micro: p 0.5226, r 0.5226, f1 0.5226	weighted_f1:0.5254
global_step: 3321, epoch: 34, loss: 0.616973
global_step: 3322, epoch: 34, loss: 0.426872
global_step: 3323, epoch: 34, loss: 0.571484
global_step: 3324, epoch: 34, loss: 0.522653
global_step: 3325, epoch: 34, loss: 0.415554
global_step: 3326, epoch: 34, loss: 0.370306
global_step: 3327, epoch: 34, loss: 0.503400
global_step: 3328, epoch: 34, loss: 0.442612
global_step: 3329, epoch: 34, loss: 0.395364
global_step: 3330, epoch: 34, loss: 0.365798
global_step: 3331, epoch: 34, loss: 0.482737
global_step: 3332, epoch: 34, loss: 0.357827
global_step: 3333, epoch: 34, loss: 0.359159
global_step: 3334, epoch: 34, loss: 0.407263
global_step: 3335, epoch: 34, loss: 0.349148
global_step: 3336, epoch: 34, loss: 0.403938
global_step: 3337, epoch: 34, loss: 0.389388
global_step: 3338, epoch: 34, loss: 0.385980
global_step: 3339, epoch: 34, loss: 0.410691
global_step: 3340, epoch: 34, loss: 0.489775
global_step: 3341, epoch: 34, loss: 0.461243
global_step: 3342, epoch: 34, loss: 0.434283
global_step: 3343, epoch: 34, loss: 0.415772
global_step: 3344, epoch: 34, loss: 0.504165
global_step: 3345, epoch: 34, loss: 0.433389
global_step: 3346, epoch: 34, loss: 0.456391
global_step: 3347, epoch: 34, loss: 0.537931
global_step: 3348, epoch: 34, loss: 0.475424
global_step: 3349, epoch: 34, loss: 0.466967
global_step: 3350, epoch: 34, loss: 0.461958
global_step: 3351, epoch: 34, loss: 0.377840
global_step: 3352, epoch: 34, loss: 0.445737
global_step: 3353, epoch: 34, loss: 0.497876
global_step: 3354, epoch: 34, loss: 0.434777
global_step: 3355, epoch: 34, loss: 0.503081
global_step: 3356, epoch: 34, loss: 0.502013
global_step: 3357, epoch: 34, loss: 0.374245
global_step: 3358, epoch: 34, loss: 0.458150
global_step: 3359, epoch: 34, loss: 0.461722
global_step: 3360, epoch: 34, loss: 0.281288
epoch: 34
train	acc: 0.9000	macro: p 0.9251, r 0.8330, f1: 0.8725	micro: p 0.9000, r 0.9000, f1 0.9000	weighted_f1:0.8981
dev	acc: 0.5636	macro: p 0.4469, r 0.3429, f1: 0.3588	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5198
test	acc: 0.5943	macro: p 0.4336, r 0.3385, f1: 0.3557	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5542
global_step: 3361, epoch: 35, loss: 0.574270
global_step: 3362, epoch: 35, loss: 0.492744
global_step: 3363, epoch: 35, loss: 0.474036
global_step: 3364, epoch: 35, loss: 0.297516
global_step: 3365, epoch: 35, loss: 0.358620
global_step: 3366, epoch: 35, loss: 0.452628
global_step: 3367, epoch: 35, loss: 0.477339
global_step: 3368, epoch: 35, loss: 0.438640
global_step: 3369, epoch: 35, loss: 0.374490
global_step: 3370, epoch: 35, loss: 0.364341
global_step: 3371, epoch: 35, loss: 0.335873
global_step: 3372, epoch: 35, loss: 0.407726
global_step: 3373, epoch: 35, loss: 0.569751
global_step: 3374, epoch: 35, loss: 0.440352
global_step: 3375, epoch: 35, loss: 0.349695
global_step: 3376, epoch: 35, loss: 0.431527
global_step: 3377, epoch: 35, loss: 0.481332
global_step: 3378, epoch: 35, loss: 0.439838
global_step: 3379, epoch: 35, loss: 0.405149
global_step: 3380, epoch: 35, loss: 0.433591
global_step: 3381, epoch: 35, loss: 0.436246
global_step: 3382, epoch: 35, loss: 0.417054
global_step: 3383, epoch: 35, loss: 0.433517
global_step: 3384, epoch: 35, loss: 0.444445
global_step: 3385, epoch: 35, loss: 0.410844
global_step: 3386, epoch: 35, loss: 0.422498
global_step: 3387, epoch: 35, loss: 0.315157
global_step: 3388, epoch: 35, loss: 0.363046
global_step: 3389, epoch: 35, loss: 0.344634
global_step: 3390, epoch: 35, loss: 0.550164
global_step: 3391, epoch: 35, loss: 0.493572
global_step: 3392, epoch: 35, loss: 0.427785
global_step: 3393, epoch: 35, loss: 0.426554
global_step: 3394, epoch: 35, loss: 0.432521
global_step: 3395, epoch: 35, loss: 0.596555
global_step: 3396, epoch: 35, loss: 0.498809
global_step: 3397, epoch: 35, loss: 0.419913
global_step: 3398, epoch: 35, loss: 0.412993
global_step: 3399, epoch: 35, loss: 0.501130
global_step: 3400, epoch: 35, loss: 0.505789
epoch: 35
train	acc: 0.9154	macro: p 0.9360, r 0.8308, f1: 0.8730	micro: p 0.9154, r 0.9154, f1 0.9154	weighted_f1:0.9137
dev	acc: 0.5735	macro: p 0.4811, r 0.3535, f1: 0.3692	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5298
test	acc: 0.5973	macro: p 0.4287, r 0.3350, f1: 0.3452	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5583
global_step: 3401, epoch: 36, loss: 0.427706
global_step: 3402, epoch: 36, loss: 0.477978
global_step: 3403, epoch: 36, loss: 0.371744
global_step: 3404, epoch: 36, loss: 0.365050
global_step: 3405, epoch: 36, loss: 0.458501
global_step: 3406, epoch: 36, loss: 0.483127
global_step: 3407, epoch: 36, loss: 0.463703
global_step: 3408, epoch: 36, loss: 0.428261
global_step: 3409, epoch: 36, loss: 0.384736
global_step: 3410, epoch: 36, loss: 0.429395
global_step: 3411, epoch: 36, loss: 0.569108
global_step: 3412, epoch: 36, loss: 0.293810
global_step: 3413, epoch: 36, loss: 0.358114
global_step: 3414, epoch: 36, loss: 0.413518
global_step: 3415, epoch: 36, loss: 0.478051
global_step: 3416, epoch: 36, loss: 0.442587
global_step: 3417, epoch: 36, loss: 0.365793
global_step: 3418, epoch: 36, loss: 0.464369
global_step: 3419, epoch: 36, loss: 0.398598
global_step: 3420, epoch: 36, loss: 0.337978
global_step: 3421, epoch: 36, loss: 0.434088
global_step: 3422, epoch: 36, loss: 0.423353
global_step: 3423, epoch: 36, loss: 0.446669
global_step: 3424, epoch: 36, loss: 0.389339
global_step: 3425, epoch: 36, loss: 0.417405
global_step: 3426, epoch: 36, loss: 0.495997
global_step: 3427, epoch: 36, loss: 0.353066
global_step: 3428, epoch: 36, loss: 0.345636
global_step: 3429, epoch: 36, loss: 0.323529
global_step: 3430, epoch: 36, loss: 0.488456
global_step: 3431, epoch: 36, loss: 0.389352
global_step: 3432, epoch: 36, loss: 0.499058
global_step: 3433, epoch: 36, loss: 0.382454
global_step: 3434, epoch: 36, loss: 0.399452
global_step: 3435, epoch: 36, loss: 0.537563
global_step: 3436, epoch: 36, loss: 0.405366
global_step: 3437, epoch: 36, loss: 0.605392
global_step: 3438, epoch: 36, loss: 0.447825
global_step: 3439, epoch: 36, loss: 0.431928
global_step: 3440, epoch: 36, loss: 0.345173
epoch: 36
train	acc: 0.9121	macro: p 0.9106, r 0.8459, f1: 0.8727	micro: p 0.9121, r 0.9121, f1 0.9121	weighted_f1:0.9110
dev	acc: 0.5744	macro: p 0.4580, r 0.3716, f1: 0.3896	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5484
test	acc: 0.5943	macro: p 0.4578, r 0.3575, f1: 0.3759	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5732
New best model!
global_step: 3441, epoch: 37, loss: 0.342840
global_step: 3442, epoch: 37, loss: 0.368524
global_step: 3443, epoch: 37, loss: 0.436972
global_step: 3444, epoch: 37, loss: 0.449165
global_step: 3445, epoch: 37, loss: 0.565172
global_step: 3446, epoch: 37, loss: 0.383251
global_step: 3447, epoch: 37, loss: 0.316035
global_step: 3448, epoch: 37, loss: 0.397507
global_step: 3449, epoch: 37, loss: 0.397337
global_step: 3450, epoch: 37, loss: 0.421502
global_step: 3451, epoch: 37, loss: 0.373944
global_step: 3452, epoch: 37, loss: 0.360827
global_step: 3453, epoch: 37, loss: 0.396828
global_step: 3454, epoch: 37, loss: 0.498660
global_step: 3455, epoch: 37, loss: 0.424033
global_step: 3456, epoch: 37, loss: 0.375273
global_step: 3457, epoch: 37, loss: 0.427770
global_step: 3458, epoch: 37, loss: 0.456175
global_step: 3459, epoch: 37, loss: 0.344364
global_step: 3460, epoch: 37, loss: 0.379889
global_step: 3461, epoch: 37, loss: 0.458169
global_step: 3462, epoch: 37, loss: 0.411639
global_step: 3463, epoch: 37, loss: 0.327493
global_step: 3464, epoch: 37, loss: 0.450864
global_step: 3465, epoch: 37, loss: 0.358294
global_step: 3466, epoch: 37, loss: 0.430763
global_step: 3467, epoch: 37, loss: 0.351915
global_step: 3468, epoch: 37, loss: 0.490078
global_step: 3469, epoch: 37, loss: 0.465801
global_step: 3470, epoch: 37, loss: 0.459911
global_step: 3471, epoch: 37, loss: 0.469609
global_step: 3472, epoch: 37, loss: 0.479025
global_step: 3473, epoch: 37, loss: 0.569973
global_step: 3474, epoch: 37, loss: 0.510724
global_step: 3475, epoch: 37, loss: 0.480425
global_step: 3476, epoch: 37, loss: 0.472565
global_step: 3477, epoch: 37, loss: 0.546079
global_step: 3478, epoch: 37, loss: 0.426516
global_step: 3479, epoch: 37, loss: 0.466291
global_step: 3480, epoch: 37, loss: 0.925459
epoch: 37
train	acc: 0.9267	macro: p 0.9407, r 0.8691, f1: 0.8993	micro: p 0.9267, r 0.9267, f1 0.9267	weighted_f1:0.9258
dev	acc: 0.5726	macro: p 0.5018, r 0.3579, f1: 0.3762	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5357
test	acc: 0.6042	macro: p 0.4371, r 0.3623, f1: 0.3794	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5768
global_step: 3481, epoch: 38, loss: 0.358456
global_step: 3482, epoch: 38, loss: 0.455581
global_step: 3483, epoch: 38, loss: 0.355350
global_step: 3484, epoch: 38, loss: 0.360780
global_step: 3485, epoch: 38, loss: 0.433471
global_step: 3486, epoch: 38, loss: 0.384764
global_step: 3487, epoch: 38, loss: 0.343459
global_step: 3488, epoch: 38, loss: 0.321991
global_step: 3489, epoch: 38, loss: 0.397409
global_step: 3490, epoch: 38, loss: 0.348448
global_step: 3491, epoch: 38, loss: 0.478722
global_step: 3492, epoch: 38, loss: 0.367066
global_step: 3493, epoch: 38, loss: 0.420125
global_step: 3494, epoch: 38, loss: 0.346845
global_step: 3495, epoch: 38, loss: 0.423275
global_step: 3496, epoch: 38, loss: 0.355470
global_step: 3497, epoch: 38, loss: 0.288036
global_step: 3498, epoch: 38, loss: 0.364183
global_step: 3499, epoch: 38, loss: 0.391213
global_step: 3500, epoch: 38, loss: 0.495375
global_step: 3501, epoch: 38, loss: 0.342016
global_step: 3502, epoch: 38, loss: 0.428826
global_step: 3503, epoch: 38, loss: 0.440237
global_step: 3504, epoch: 38, loss: 0.431996
global_step: 3505, epoch: 38, loss: 0.385236
global_step: 3506, epoch: 38, loss: 0.357414
global_step: 3507, epoch: 38, loss: 0.370558
global_step: 3508, epoch: 38, loss: 0.426859
global_step: 3509, epoch: 38, loss: 0.416105
global_step: 3510, epoch: 38, loss: 0.447300
global_step: 3511, epoch: 38, loss: 0.396556
global_step: 3512, epoch: 38, loss: 0.489551
global_step: 3513, epoch: 38, loss: 0.367657
global_step: 3514, epoch: 38, loss: 0.561806
global_step: 3515, epoch: 38, loss: 0.450346
global_step: 3516, epoch: 38, loss: 0.505576
global_step: 3517, epoch: 38, loss: 0.378275
global_step: 3518, epoch: 38, loss: 0.394993
global_step: 3519, epoch: 38, loss: 0.438446
global_step: 3520, epoch: 38, loss: 0.933606
epoch: 38
train	acc: 0.8990	macro: p 0.9090, r 0.8451, f1: 0.8671	micro: p 0.8990, r 0.8990, f1 0.8990	weighted_f1:0.8998
dev	acc: 0.5194	macro: p 0.4164, r 0.3524, f1: 0.3509	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.5112
test	acc: 0.5414	macro: p 0.3948, r 0.3569, f1: 0.3496	micro: p 0.5414, r 0.5414, f1 0.5414	weighted_f1:0.5387
global_step: 3521, epoch: 39, loss: 0.597639
global_step: 3522, epoch: 39, loss: 0.395706
global_step: 3523, epoch: 39, loss: 0.311802
global_step: 3524, epoch: 39, loss: 0.355385
global_step: 3525, epoch: 39, loss: 0.374596
global_step: 3526, epoch: 39, loss: 0.309927
global_step: 3527, epoch: 39, loss: 0.407329
global_step: 3528, epoch: 39, loss: 0.402738
global_step: 3529, epoch: 39, loss: 0.345289
global_step: 3530, epoch: 39, loss: 0.391803
global_step: 3531, epoch: 39, loss: 0.411698
global_step: 3532, epoch: 39, loss: 0.410021
global_step: 3533, epoch: 39, loss: 0.305542
global_step: 3534, epoch: 39, loss: 0.459524
global_step: 3535, epoch: 39, loss: 0.407445
global_step: 3536, epoch: 39, loss: 0.395644
global_step: 3537, epoch: 39, loss: 0.396811
global_step: 3538, epoch: 39, loss: 0.360537
global_step: 3539, epoch: 39, loss: 0.300342
global_step: 3540, epoch: 39, loss: 0.416209
global_step: 3541, epoch: 39, loss: 0.331090
global_step: 3542, epoch: 39, loss: 0.502792
global_step: 3543, epoch: 39, loss: 0.476504
global_step: 3544, epoch: 39, loss: 0.362360
global_step: 3545, epoch: 39, loss: 0.418996
global_step: 3546, epoch: 39, loss: 0.404838
global_step: 3547, epoch: 39, loss: 0.353826
global_step: 3548, epoch: 39, loss: 0.421395
global_step: 3549, epoch: 39, loss: 0.361606
global_step: 3550, epoch: 39, loss: 0.348517
global_step: 3551, epoch: 39, loss: 0.434697
global_step: 3552, epoch: 39, loss: 0.392566
global_step: 3553, epoch: 39, loss: 0.374601
global_step: 3554, epoch: 39, loss: 0.431700
global_step: 3555, epoch: 39, loss: 0.421610
global_step: 3556, epoch: 39, loss: 0.339429
global_step: 3557, epoch: 39, loss: 0.434898
global_step: 3558, epoch: 39, loss: 0.462895
global_step: 3559, epoch: 39, loss: 0.478205
global_step: 3560, epoch: 39, loss: 0.515626
epoch: 39
train	acc: 0.9144	macro: p 0.9343, r 0.8372, f1: 0.8754	micro: p 0.9144, r 0.9144, f1 0.9144	weighted_f1:0.9131
dev	acc: 0.5636	macro: p 0.4802, r 0.3392, f1: 0.3546	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5159
test	acc: 0.6019	macro: p 0.5219, r 0.3442, f1: 0.3631	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5656
global_step: 3561, epoch: 40, loss: 0.403051
global_step: 3562, epoch: 40, loss: 0.454242
global_step: 3563, epoch: 40, loss: 0.402018
global_step: 3564, epoch: 40, loss: 0.465167
global_step: 3565, epoch: 40, loss: 0.409284
global_step: 3566, epoch: 40, loss: 0.444572
global_step: 3567, epoch: 40, loss: 0.401109
global_step: 3568, epoch: 40, loss: 0.439832
global_step: 3569, epoch: 40, loss: 0.448354
global_step: 3570, epoch: 40, loss: 0.374098
global_step: 3571, epoch: 40, loss: 0.368415
global_step: 3572, epoch: 40, loss: 0.377598
global_step: 3573, epoch: 40, loss: 0.399539
global_step: 3574, epoch: 40, loss: 0.384927
global_step: 3575, epoch: 40, loss: 0.370835
global_step: 3576, epoch: 40, loss: 0.294753
global_step: 3577, epoch: 40, loss: 0.339340
global_step: 3578, epoch: 40, loss: 0.438971
global_step: 3579, epoch: 40, loss: 0.336364
global_step: 3580, epoch: 40, loss: 0.276431
global_step: 3581, epoch: 40, loss: 0.389684
global_step: 3582, epoch: 40, loss: 0.388535
global_step: 3583, epoch: 40, loss: 0.336867
global_step: 3584, epoch: 40, loss: 0.321831
global_step: 3585, epoch: 40, loss: 0.405409
global_step: 3586, epoch: 40, loss: 0.394177
global_step: 3587, epoch: 40, loss: 0.391636
global_step: 3588, epoch: 40, loss: 0.400960
global_step: 3589, epoch: 40, loss: 0.415279
global_step: 3590, epoch: 40, loss: 0.387984
global_step: 3591, epoch: 40, loss: 0.408464
global_step: 3592, epoch: 40, loss: 0.337168
global_step: 3593, epoch: 40, loss: 0.344101
global_step: 3594, epoch: 40, loss: 0.438100
global_step: 3595, epoch: 40, loss: 0.439611
global_step: 3596, epoch: 40, loss: 0.366337
global_step: 3597, epoch: 40, loss: 0.409498
global_step: 3598, epoch: 40, loss: 0.361380
global_step: 3599, epoch: 40, loss: 0.355810
global_step: 3600, epoch: 40, loss: 0.235402
epoch: 40
train	acc: 0.9378	macro: p 0.9513, r 0.8970, f1: 0.9216	micro: p 0.9378, r 0.9378, f1 0.9378	weighted_f1:0.9375
dev	acc: 0.5771	macro: p 0.4814, r 0.3662, f1: 0.3844	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5401
test	acc: 0.6054	macro: p 0.4422, r 0.3617, f1: 0.3805	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5767
global_step: 3601, epoch: 41, loss: 0.377709
global_step: 3602, epoch: 41, loss: 0.326545
global_step: 3603, epoch: 41, loss: 0.362021
global_step: 3604, epoch: 41, loss: 0.417560
global_step: 3605, epoch: 41, loss: 0.376672
global_step: 3606, epoch: 41, loss: 0.365747
global_step: 3607, epoch: 41, loss: 0.336294
global_step: 3608, epoch: 41, loss: 0.348530
global_step: 3609, epoch: 41, loss: 0.380479
global_step: 3610, epoch: 41, loss: 0.375242
global_step: 3611, epoch: 41, loss: 0.366126
global_step: 3612, epoch: 41, loss: 0.360403
global_step: 3613, epoch: 41, loss: 0.412791
global_step: 3614, epoch: 41, loss: 0.392008
global_step: 3615, epoch: 41, loss: 0.310473
global_step: 3616, epoch: 41, loss: 0.418274
global_step: 3617, epoch: 41, loss: 0.358059
global_step: 3618, epoch: 41, loss: 0.390751
global_step: 3619, epoch: 41, loss: 0.418650
global_step: 3620, epoch: 41, loss: 0.318391
global_step: 3621, epoch: 41, loss: 0.341564
global_step: 3622, epoch: 41, loss: 0.374275
global_step: 3623, epoch: 41, loss: 0.348945
global_step: 3624, epoch: 41, loss: 0.423234
global_step: 3625, epoch: 41, loss: 0.326247
global_step: 3626, epoch: 41, loss: 0.398084
global_step: 3627, epoch: 41, loss: 0.395610
global_step: 3628, epoch: 41, loss: 0.378742
global_step: 3629, epoch: 41, loss: 0.526594
global_step: 3630, epoch: 41, loss: 0.454837
global_step: 3631, epoch: 41, loss: 0.445215
global_step: 3632, epoch: 41, loss: 0.509761
global_step: 3633, epoch: 41, loss: 0.371309
global_step: 3634, epoch: 41, loss: 0.401693
global_step: 3635, epoch: 41, loss: 0.502113
global_step: 3636, epoch: 41, loss: 0.417108
global_step: 3637, epoch: 41, loss: 0.401850
global_step: 3638, epoch: 41, loss: 0.392240
global_step: 3639, epoch: 41, loss: 0.432182
global_step: 3640, epoch: 41, loss: 0.729360
epoch: 41
train	acc: 0.9337	macro: p 0.9345, r 0.9038, f1: 0.9175	micro: p 0.9337, r 0.9337, f1 0.9337	weighted_f1:0.9339
dev	acc: 0.5446	macro: p 0.4237, r 0.3698, f1: 0.3752	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5265
test	acc: 0.5728	macro: p 0.4191, r 0.3773, f1: 0.3845	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5632
global_step: 3641, epoch: 42, loss: 0.422747
global_step: 3642, epoch: 42, loss: 0.322026
global_step: 3643, epoch: 42, loss: 0.409893
global_step: 3644, epoch: 42, loss: 0.338158
global_step: 3645, epoch: 42, loss: 0.407624
global_step: 3646, epoch: 42, loss: 0.326909
global_step: 3647, epoch: 42, loss: 0.367697
global_step: 3648, epoch: 42, loss: 0.364354
global_step: 3649, epoch: 42, loss: 0.433123
global_step: 3650, epoch: 42, loss: 0.299745
global_step: 3651, epoch: 42, loss: 0.453030
global_step: 3652, epoch: 42, loss: 0.408560
global_step: 3653, epoch: 42, loss: 0.361999
global_step: 3654, epoch: 42, loss: 0.316935
global_step: 3655, epoch: 42, loss: 0.392107
global_step: 3656, epoch: 42, loss: 0.345414
global_step: 3657, epoch: 42, loss: 0.324451
global_step: 3658, epoch: 42, loss: 0.405156
global_step: 3659, epoch: 42, loss: 0.317403
global_step: 3660, epoch: 42, loss: 0.358599
global_step: 3661, epoch: 42, loss: 0.360686
global_step: 3662, epoch: 42, loss: 0.358463
global_step: 3663, epoch: 42, loss: 0.388708
global_step: 3664, epoch: 42, loss: 0.308941
global_step: 3665, epoch: 42, loss: 0.414585
global_step: 3666, epoch: 42, loss: 0.345733
global_step: 3667, epoch: 42, loss: 0.349718
global_step: 3668, epoch: 42, loss: 0.325036
global_step: 3669, epoch: 42, loss: 0.356246
global_step: 3670, epoch: 42, loss: 0.392064
global_step: 3671, epoch: 42, loss: 0.414871
global_step: 3672, epoch: 42, loss: 0.495491
global_step: 3673, epoch: 42, loss: 0.532597
global_step: 3674, epoch: 42, loss: 0.419951
global_step: 3675, epoch: 42, loss: 0.320655
global_step: 3676, epoch: 42, loss: 0.347890
global_step: 3677, epoch: 42, loss: 0.396348
global_step: 3678, epoch: 42, loss: 0.333384
global_step: 3679, epoch: 42, loss: 0.392124
global_step: 3680, epoch: 42, loss: 0.565533
epoch: 42
train	acc: 0.9249	macro: p 0.9392, r 0.8722, f1: 0.8999	micro: p 0.9249, r 0.9249, f1 0.9249	weighted_f1:0.9242
dev	acc: 0.5446	macro: p 0.5267, r 0.3454, f1: 0.3556	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5125
test	acc: 0.5885	macro: p 0.4238, r 0.3550, f1: 0.3676	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5651
global_step: 3681, epoch: 43, loss: 0.453163
global_step: 3682, epoch: 43, loss: 0.407474
global_step: 3683, epoch: 43, loss: 0.377714
global_step: 3684, epoch: 43, loss: 0.340641
global_step: 3685, epoch: 43, loss: 0.421779
global_step: 3686, epoch: 43, loss: 0.339396
global_step: 3687, epoch: 43, loss: 0.359710
global_step: 3688, epoch: 43, loss: 0.290399
global_step: 3689, epoch: 43, loss: 0.362102
global_step: 3690, epoch: 43, loss: 0.391542
global_step: 3691, epoch: 43, loss: 0.378612
global_step: 3692, epoch: 43, loss: 0.344423
global_step: 3693, epoch: 43, loss: 0.388767
global_step: 3694, epoch: 43, loss: 0.340276
global_step: 3695, epoch: 43, loss: 0.297648
global_step: 3696, epoch: 43, loss: 0.367383
global_step: 3697, epoch: 43, loss: 0.360510
global_step: 3698, epoch: 43, loss: 0.397494
global_step: 3699, epoch: 43, loss: 0.373024
global_step: 3700, epoch: 43, loss: 0.318312
global_step: 3701, epoch: 43, loss: 0.296806
global_step: 3702, epoch: 43, loss: 0.306461
global_step: 3703, epoch: 43, loss: 0.316314
global_step: 3704, epoch: 43, loss: 0.363495
global_step: 3705, epoch: 43, loss: 0.284821
global_step: 3706, epoch: 43, loss: 0.378316
global_step: 3707, epoch: 43, loss: 0.381129
global_step: 3708, epoch: 43, loss: 0.423657
global_step: 3709, epoch: 43, loss: 0.422348
global_step: 3710, epoch: 43, loss: 0.363422
global_step: 3711, epoch: 43, loss: 0.338577
global_step: 3712, epoch: 43, loss: 0.364140
global_step: 3713, epoch: 43, loss: 0.361458
global_step: 3714, epoch: 43, loss: 0.460305
global_step: 3715, epoch: 43, loss: 0.461839
global_step: 3716, epoch: 43, loss: 0.481006
global_step: 3717, epoch: 43, loss: 0.349714
global_step: 3718, epoch: 43, loss: 0.361846
global_step: 3719, epoch: 43, loss: 0.446342
global_step: 3720, epoch: 43, loss: 0.762559
epoch: 43
train	acc: 0.9150	macro: p 0.9429, r 0.8413, f1: 0.8829	micro: p 0.9150, r 0.9150, f1 0.9150	weighted_f1:0.9134
dev	acc: 0.5518	macro: p 0.4801, r 0.3381, f1: 0.3439	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5079
test	acc: 0.5720	macro: p 0.4541, r 0.3213, f1: 0.3294	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5336
global_step: 3721, epoch: 44, loss: 0.505136
global_step: 3722, epoch: 44, loss: 0.290323
global_step: 3723, epoch: 44, loss: 0.355788
global_step: 3724, epoch: 44, loss: 0.388227
global_step: 3725, epoch: 44, loss: 0.393826
global_step: 3726, epoch: 44, loss: 0.342841
global_step: 3727, epoch: 44, loss: 0.447759
global_step: 3728, epoch: 44, loss: 0.308226
global_step: 3729, epoch: 44, loss: 0.389860
global_step: 3730, epoch: 44, loss: 0.394952
global_step: 3731, epoch: 44, loss: 0.314606
global_step: 3732, epoch: 44, loss: 0.309428
global_step: 3733, epoch: 44, loss: 0.332609
global_step: 3734, epoch: 44, loss: 0.393776
global_step: 3735, epoch: 44, loss: 0.366660
global_step: 3736, epoch: 44, loss: 0.374467
global_step: 3737, epoch: 44, loss: 0.387076
global_step: 3738, epoch: 44, loss: 0.459254
global_step: 3739, epoch: 44, loss: 0.357627
global_step: 3740, epoch: 44, loss: 0.295040
global_step: 3741, epoch: 44, loss: 0.368082
global_step: 3742, epoch: 44, loss: 0.273153
global_step: 3743, epoch: 44, loss: 0.337178
global_step: 3744, epoch: 44, loss: 0.300424
global_step: 3745, epoch: 44, loss: 0.400401
global_step: 3746, epoch: 44, loss: 0.384102
global_step: 3747, epoch: 44, loss: 0.422319
global_step: 3748, epoch: 44, loss: 0.340651
global_step: 3749, epoch: 44, loss: 0.348198
global_step: 3750, epoch: 44, loss: 0.340617
global_step: 3751, epoch: 44, loss: 0.394877
global_step: 3752, epoch: 44, loss: 0.408328
global_step: 3753, epoch: 44, loss: 0.401542
global_step: 3754, epoch: 44, loss: 0.330441
global_step: 3755, epoch: 44, loss: 0.322475
global_step: 3756, epoch: 44, loss: 0.335012
global_step: 3757, epoch: 44, loss: 0.292121
global_step: 3758, epoch: 44, loss: 0.390951
global_step: 3759, epoch: 44, loss: 0.410667
global_step: 3760, epoch: 44, loss: 0.474036
epoch: 44
train	acc: 0.9335	macro: p 0.9567, r 0.8893, f1: 0.9203	micro: p 0.9335, r 0.9335, f1 0.9335	weighted_f1:0.9329
dev	acc: 0.5573	macro: p 0.4610, r 0.3346, f1: 0.3546	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5064
test	acc: 0.5923	macro: p 0.4039, r 0.3255, f1: 0.3447	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5510
global_step: 3761, epoch: 45, loss: 0.363871
global_step: 3762, epoch: 45, loss: 0.375088
global_step: 3763, epoch: 45, loss: 0.339945
global_step: 3764, epoch: 45, loss: 0.412145
global_step: 3765, epoch: 45, loss: 0.324836
global_step: 3766, epoch: 45, loss: 0.374903
global_step: 3767, epoch: 45, loss: 0.375326
global_step: 3768, epoch: 45, loss: 0.353183
global_step: 3769, epoch: 45, loss: 0.317721
global_step: 3770, epoch: 45, loss: 0.362010
global_step: 3771, epoch: 45, loss: 0.347663
global_step: 3772, epoch: 45, loss: 0.362404
global_step: 3773, epoch: 45, loss: 0.294773
global_step: 3774, epoch: 45, loss: 0.358165
global_step: 3775, epoch: 45, loss: 0.334471
global_step: 3776, epoch: 45, loss: 0.401926
global_step: 3777, epoch: 45, loss: 0.277149
global_step: 3778, epoch: 45, loss: 0.399933
global_step: 3779, epoch: 45, loss: 0.359107
global_step: 3780, epoch: 45, loss: 0.353134
global_step: 3781, epoch: 45, loss: 0.382417
global_step: 3782, epoch: 45, loss: 0.364065
global_step: 3783, epoch: 45, loss: 0.375626
global_step: 3784, epoch: 45, loss: 0.233188
global_step: 3785, epoch: 45, loss: 0.263038
global_step: 3786, epoch: 45, loss: 0.366505
global_step: 3787, epoch: 45, loss: 0.385334
global_step: 3788, epoch: 45, loss: 0.380393
global_step: 3789, epoch: 45, loss: 0.302995
global_step: 3790, epoch: 45, loss: 0.397148
global_step: 3791, epoch: 45, loss: 0.444201
global_step: 3792, epoch: 45, loss: 0.366173
global_step: 3793, epoch: 45, loss: 0.308868
global_step: 3794, epoch: 45, loss: 0.361353
global_step: 3795, epoch: 45, loss: 0.307336
global_step: 3796, epoch: 45, loss: 0.337356
global_step: 3797, epoch: 45, loss: 0.488474
global_step: 3798, epoch: 45, loss: 0.361429
global_step: 3799, epoch: 45, loss: 0.213771
global_step: 3800, epoch: 45, loss: 0.026485
epoch: 45
train	acc: 0.9493	macro: p 0.9585, r 0.9189, f1: 0.9374	micro: p 0.9493, r 0.9493, f1 0.9493	weighted_f1:0.9492
dev	acc: 0.5654	macro: p 0.4604, r 0.3616, f1: 0.3799	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5315
test	acc: 0.5900	macro: p 0.4116, r 0.3482, f1: 0.3627	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5627
global_step: 3801, epoch: 46, loss: 0.219999
global_step: 3802, epoch: 46, loss: 0.273735
global_step: 3803, epoch: 46, loss: 0.289897
global_step: 3804, epoch: 46, loss: 0.285512
global_step: 3805, epoch: 46, loss: 0.310356
global_step: 3806, epoch: 46, loss: 0.343548
global_step: 3807, epoch: 46, loss: 0.383702
global_step: 3808, epoch: 46, loss: 0.330307
global_step: 3809, epoch: 46, loss: 0.266069
global_step: 3810, epoch: 46, loss: 0.300833
global_step: 3811, epoch: 46, loss: 0.338583
global_step: 3812, epoch: 46, loss: 0.310684
global_step: 3813, epoch: 46, loss: 0.351074
global_step: 3814, epoch: 46, loss: 0.302360
global_step: 3815, epoch: 46, loss: 0.300450
global_step: 3816, epoch: 46, loss: 0.435865
global_step: 3817, epoch: 46, loss: 0.258269
global_step: 3818, epoch: 46, loss: 0.481775
global_step: 3819, epoch: 46, loss: 0.332699
global_step: 3820, epoch: 46, loss: 0.263683
global_step: 3821, epoch: 46, loss: 0.297234
global_step: 3822, epoch: 46, loss: 0.381981
global_step: 3823, epoch: 46, loss: 0.307069
global_step: 3824, epoch: 46, loss: 0.334887
global_step: 3825, epoch: 46, loss: 0.371333
global_step: 3826, epoch: 46, loss: 0.363162
global_step: 3827, epoch: 46, loss: 0.334566
global_step: 3828, epoch: 46, loss: 0.285036
global_step: 3829, epoch: 46, loss: 0.356574
global_step: 3830, epoch: 46, loss: 0.432340
global_step: 3831, epoch: 46, loss: 0.374501
global_step: 3832, epoch: 46, loss: 0.354619
global_step: 3833, epoch: 46, loss: 0.375783
global_step: 3834, epoch: 46, loss: 0.406050
global_step: 3835, epoch: 46, loss: 0.316950
global_step: 3836, epoch: 46, loss: 0.353020
global_step: 3837, epoch: 46, loss: 0.391300
global_step: 3838, epoch: 46, loss: 0.433769
global_step: 3839, epoch: 46, loss: 0.266422
global_step: 3840, epoch: 46, loss: 0.441534
epoch: 46
train	acc: 0.9426	macro: p 0.9463, r 0.9226, f1: 0.9331	micro: p 0.9426, r 0.9426, f1 0.9426	weighted_f1:0.9430
dev	acc: 0.5329	macro: p 0.3945, r 0.3540, f1: 0.3594	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.5139
test	acc: 0.5690	macro: p 0.4024, r 0.3701, f1: 0.3755	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5575
global_step: 3841, epoch: 47, loss: 0.354432
global_step: 3842, epoch: 47, loss: 0.334536
global_step: 3843, epoch: 47, loss: 0.328823
global_step: 3844, epoch: 47, loss: 0.363418
global_step: 3845, epoch: 47, loss: 0.315529
global_step: 3846, epoch: 47, loss: 0.304682
global_step: 3847, epoch: 47, loss: 0.393346
global_step: 3848, epoch: 47, loss: 0.275268
global_step: 3849, epoch: 47, loss: 0.293571
global_step: 3850, epoch: 47, loss: 0.385390
global_step: 3851, epoch: 47, loss: 0.310917
global_step: 3852, epoch: 47, loss: 0.374790
global_step: 3853, epoch: 47, loss: 0.402663
global_step: 3854, epoch: 47, loss: 0.368835
global_step: 3855, epoch: 47, loss: 0.260059
global_step: 3856, epoch: 47, loss: 0.374241
global_step: 3857, epoch: 47, loss: 0.328345
global_step: 3858, epoch: 47, loss: 0.403539
global_step: 3859, epoch: 47, loss: 0.279590
global_step: 3860, epoch: 47, loss: 0.330267
global_step: 3861, epoch: 47, loss: 0.323972
global_step: 3862, epoch: 47, loss: 0.380918
global_step: 3863, epoch: 47, loss: 0.279928
global_step: 3864, epoch: 47, loss: 0.300649
global_step: 3865, epoch: 47, loss: 0.246283
global_step: 3866, epoch: 47, loss: 0.313008
global_step: 3867, epoch: 47, loss: 0.310798
global_step: 3868, epoch: 47, loss: 0.329097
global_step: 3869, epoch: 47, loss: 0.332964
global_step: 3870, epoch: 47, loss: 0.331419
global_step: 3871, epoch: 47, loss: 0.323338
global_step: 3872, epoch: 47, loss: 0.438981
global_step: 3873, epoch: 47, loss: 0.262006
global_step: 3874, epoch: 47, loss: 0.398825
global_step: 3875, epoch: 47, loss: 0.350438
global_step: 3876, epoch: 47, loss: 0.373907
global_step: 3877, epoch: 47, loss: 0.276096
global_step: 3878, epoch: 47, loss: 0.379040
global_step: 3879, epoch: 47, loss: 0.369461
global_step: 3880, epoch: 47, loss: 0.545799
epoch: 47
train	acc: 0.9152	macro: p 0.9388, r 0.8692, f1: 0.8984	micro: p 0.9152, r 0.9152, f1 0.9152	weighted_f1:0.9156
dev	acc: 0.5356	macro: p 0.4622, r 0.3301, f1: 0.3334	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.5004
test	acc: 0.5567	macro: p 0.4466, r 0.3222, f1: 0.3275	micro: p 0.5567, r 0.5567, f1 0.5567	weighted_f1:0.5310
global_step: 3881, epoch: 48, loss: 0.482877
global_step: 3882, epoch: 48, loss: 0.362947
global_step: 3883, epoch: 48, loss: 0.318628
global_step: 3884, epoch: 48, loss: 0.331531
global_step: 3885, epoch: 48, loss: 0.358135
global_step: 3886, epoch: 48, loss: 0.334491
global_step: 3887, epoch: 48, loss: 0.339715
global_step: 3888, epoch: 48, loss: 0.309673
global_step: 3889, epoch: 48, loss: 0.335023
global_step: 3890, epoch: 48, loss: 0.251845
global_step: 3891, epoch: 48, loss: 0.362156
global_step: 3892, epoch: 48, loss: 0.315294
global_step: 3893, epoch: 48, loss: 0.362169
global_step: 3894, epoch: 48, loss: 0.269848
global_step: 3895, epoch: 48, loss: 0.369047
global_step: 3896, epoch: 48, loss: 0.360117
global_step: 3897, epoch: 48, loss: 0.249607
global_step: 3898, epoch: 48, loss: 0.259152
global_step: 3899, epoch: 48, loss: 0.452692
global_step: 3900, epoch: 48, loss: 0.440478
global_step: 3901, epoch: 48, loss: 0.378008
global_step: 3902, epoch: 48, loss: 0.440169
global_step: 3903, epoch: 48, loss: 0.438440
global_step: 3904, epoch: 48, loss: 0.374673
global_step: 3905, epoch: 48, loss: 0.328512
global_step: 3906, epoch: 48, loss: 0.359882
global_step: 3907, epoch: 48, loss: 0.383862
global_step: 3908, epoch: 48, loss: 0.360285
global_step: 3909, epoch: 48, loss: 0.369596
global_step: 3910, epoch: 48, loss: 0.469025
global_step: 3911, epoch: 48, loss: 0.376679
global_step: 3912, epoch: 48, loss: 0.355601
global_step: 3913, epoch: 48, loss: 0.309924
global_step: 3914, epoch: 48, loss: 0.349691
global_step: 3915, epoch: 48, loss: 0.480463
global_step: 3916, epoch: 48, loss: 0.235741
global_step: 3917, epoch: 48, loss: 0.377886
global_step: 3918, epoch: 48, loss: 0.298555
global_step: 3919, epoch: 48, loss: 0.333034
global_step: 3920, epoch: 48, loss: 0.270939
epoch: 48
train	acc: 0.9448	macro: p 0.9570, r 0.9134, f1: 0.9332	micro: p 0.9448, r 0.9448, f1 0.9448	weighted_f1:0.9447
dev	acc: 0.5618	macro: p 0.4580, r 0.3563, f1: 0.3684	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5241
test	acc: 0.5935	macro: p 0.4089, r 0.3510, f1: 0.3590	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5610
global_step: 3921, epoch: 49, loss: 0.340955
global_step: 3922, epoch: 49, loss: 0.359296
global_step: 3923, epoch: 49, loss: 0.288845
global_step: 3924, epoch: 49, loss: 0.379833
global_step: 3925, epoch: 49, loss: 0.295730
global_step: 3926, epoch: 49, loss: 0.333121
global_step: 3927, epoch: 49, loss: 0.264964
global_step: 3928, epoch: 49, loss: 0.282043
global_step: 3929, epoch: 49, loss: 0.270038
global_step: 3930, epoch: 49, loss: 0.344702
global_step: 3931, epoch: 49, loss: 0.307142
global_step: 3932, epoch: 49, loss: 0.262379
global_step: 3933, epoch: 49, loss: 0.291707
global_step: 3934, epoch: 49, loss: 0.276336
global_step: 3935, epoch: 49, loss: 0.337189
global_step: 3936, epoch: 49, loss: 0.344452
global_step: 3937, epoch: 49, loss: 0.331991
global_step: 3938, epoch: 49, loss: 0.308317
global_step: 3939, epoch: 49, loss: 0.313819
global_step: 3940, epoch: 49, loss: 0.320483
global_step: 3941, epoch: 49, loss: 0.327202
global_step: 3942, epoch: 49, loss: 0.371973
global_step: 3943, epoch: 49, loss: 0.336397
global_step: 3944, epoch: 49, loss: 0.368206
global_step: 3945, epoch: 49, loss: 0.325113
global_step: 3946, epoch: 49, loss: 0.278839
global_step: 3947, epoch: 49, loss: 0.290841
global_step: 3948, epoch: 49, loss: 0.405106
global_step: 3949, epoch: 49, loss: 0.290126
global_step: 3950, epoch: 49, loss: 0.292300
global_step: 3951, epoch: 49, loss: 0.356444
global_step: 3952, epoch: 49, loss: 0.372819
global_step: 3953, epoch: 49, loss: 0.310523
global_step: 3954, epoch: 49, loss: 0.280282
global_step: 3955, epoch: 49, loss: 0.291167
global_step: 3956, epoch: 49, loss: 0.354563
global_step: 3957, epoch: 49, loss: 0.262911
global_step: 3958, epoch: 49, loss: 0.344651
global_step: 3959, epoch: 49, loss: 0.310934
global_step: 3960, epoch: 49, loss: 0.077687
epoch: 49
train	acc: 0.9407	macro: p 0.9607, r 0.8951, f1: 0.9249	micro: p 0.9407, r 0.9407, f1 0.9407	weighted_f1:0.9402
dev	acc: 0.5690	macro: p 0.4526, r 0.3426, f1: 0.3605	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5226
test	acc: 0.6054	macro: p 0.4672, r 0.3405, f1: 0.3641	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5640
global_step: 3961, epoch: 50, loss: 0.285202
global_step: 3962, epoch: 50, loss: 0.292198
global_step: 3963, epoch: 50, loss: 0.343291
global_step: 3964, epoch: 50, loss: 0.285831
global_step: 3965, epoch: 50, loss: 0.345571
global_step: 3966, epoch: 50, loss: 0.318567
global_step: 3967, epoch: 50, loss: 0.327772
global_step: 3968, epoch: 50, loss: 0.350470
global_step: 3969, epoch: 50, loss: 0.293912
global_step: 3970, epoch: 50, loss: 0.359057
global_step: 3971, epoch: 50, loss: 0.277416
global_step: 3972, epoch: 50, loss: 0.272862
global_step: 3973, epoch: 50, loss: 0.286890
global_step: 3974, epoch: 50, loss: 0.300363
global_step: 3975, epoch: 50, loss: 0.258291
global_step: 3976, epoch: 50, loss: 0.370242
global_step: 3977, epoch: 50, loss: 0.281785
global_step: 3978, epoch: 50, loss: 0.305510
global_step: 3979, epoch: 50, loss: 0.398703
global_step: 3980, epoch: 50, loss: 0.370410
global_step: 3981, epoch: 50, loss: 0.307486
global_step: 3982, epoch: 50, loss: 0.235110
global_step: 3983, epoch: 50, loss: 0.302369
global_step: 3984, epoch: 50, loss: 0.309229
global_step: 3985, epoch: 50, loss: 0.323056
global_step: 3986, epoch: 50, loss: 0.316684
global_step: 3987, epoch: 50, loss: 0.310187
global_step: 3988, epoch: 50, loss: 0.304698
global_step: 3989, epoch: 50, loss: 0.290520
global_step: 3990, epoch: 50, loss: 0.266829
global_step: 3991, epoch: 50, loss: 0.326142
global_step: 3992, epoch: 50, loss: 0.347282
global_step: 3993, epoch: 50, loss: 0.477088
global_step: 3994, epoch: 50, loss: 0.428355
global_step: 3995, epoch: 50, loss: 0.438611
global_step: 3996, epoch: 50, loss: 0.384449
global_step: 3997, epoch: 50, loss: 0.295087
global_step: 3998, epoch: 50, loss: 0.350816
global_step: 3999, epoch: 50, loss: 0.344980
global_step: 4000, epoch: 50, loss: 0.225625
epoch: 50
train	acc: 0.9536	macro: p 0.9621, r 0.9269, f1: 0.9434	micro: p 0.9536, r 0.9536, f1 0.9536	weighted_f1:0.9535
dev	acc: 0.5645	macro: p 0.4302, r 0.3592, f1: 0.3716	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5310
test	acc: 0.5950	macro: p 0.4120, r 0.3569, f1: 0.3689	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5694
BEST MODEL epoch: 36
train	acc: 0.9121 macro_p: 0.9106 macro_r: 0.8459 macro_f1: 0.8727 micro_p: 0.9121 micro_r: 0.9121 micro_f1: 0.9121 weighted_f1: 0.9110
dev	acc: 0.5744 macro_p: 0.4580 macro_r: 0.3716 macro_f1: 0.3896 micro_p: 0.5744 micro_r: 0.5744 micro_f1: 0.5744 weighted_f1: 0.5484
test	acc: 0.5943 macro_p: 0.4578 macro_r: 0.3575 macro_f1: 0.3759 micro_p: 0.5943 micro_r: 0.5943 micro_f1: 0.5943 weighted_f1: 0.5732
==========ROUND 3==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 4001, epoch: 1, loss: 1.962245
global_step: 4002, epoch: 1, loss: 1.864558
global_step: 4003, epoch: 1, loss: 1.777037
global_step: 4004, epoch: 1, loss: 1.602124
global_step: 4005, epoch: 1, loss: 1.651690
global_step: 4006, epoch: 1, loss: 1.592282
global_step: 4007, epoch: 1, loss: 1.625337
global_step: 4008, epoch: 1, loss: 1.529031
global_step: 4009, epoch: 1, loss: 1.635692
global_step: 4010, epoch: 1, loss: 1.570263
global_step: 4011, epoch: 1, loss: 1.500620
global_step: 4012, epoch: 1, loss: 1.512173
global_step: 4013, epoch: 1, loss: 1.544232
global_step: 4014, epoch: 1, loss: 1.336749
global_step: 4015, epoch: 1, loss: 1.490506
global_step: 4016, epoch: 1, loss: 1.451867
global_step: 4017, epoch: 1, loss: 1.517230
global_step: 4018, epoch: 1, loss: 1.456248
global_step: 4019, epoch: 1, loss: 1.492870
global_step: 4020, epoch: 1, loss: 1.442384
global_step: 4021, epoch: 1, loss: 1.444789
global_step: 4022, epoch: 1, loss: 1.500387
global_step: 4023, epoch: 1, loss: 1.478274
global_step: 4024, epoch: 1, loss: 1.469671
global_step: 4025, epoch: 1, loss: 1.408756
global_step: 4026, epoch: 1, loss: 1.402195
global_step: 4027, epoch: 1, loss: 1.398804
global_step: 4028, epoch: 1, loss: 1.371571
global_step: 4029, epoch: 1, loss: 1.419552
global_step: 4030, epoch: 1, loss: 1.405752
global_step: 4031, epoch: 1, loss: 1.265198
global_step: 4032, epoch: 1, loss: 1.332351
global_step: 4033, epoch: 1, loss: 1.424760
global_step: 4034, epoch: 1, loss: 1.410614
global_step: 4035, epoch: 1, loss: 1.302731
global_step: 4036, epoch: 1, loss: 1.276677
global_step: 4037, epoch: 1, loss: 1.319764
global_step: 4038, epoch: 1, loss: 1.334592
global_step: 4039, epoch: 1, loss: 1.388696
global_step: 4040, epoch: 1, loss: 1.176662
epoch: 1
train	acc: 0.5425	macro: p 0.2689, r 0.2153, f1: 0.1766	micro: p 0.5425, r 0.5425, f1 0.5425	weighted_f1:0.4313
dev	acc: 0.4968	macro: p 0.2660, r 0.2249, f1: 0.1745	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.3756
test	acc: 0.5525	macro: p 0.2798, r 0.2270, f1: 0.1867	micro: p 0.5525, r 0.5525, f1 0.5525	weighted_f1:0.4430
New best model!
global_step: 4041, epoch: 2, loss: 1.618555
global_step: 4042, epoch: 2, loss: 1.430496
global_step: 4043, epoch: 2, loss: 1.283857
global_step: 4044, epoch: 2, loss: 1.461252
global_step: 4045, epoch: 2, loss: 1.427603
global_step: 4046, epoch: 2, loss: 1.443045
global_step: 4047, epoch: 2, loss: 1.368286
global_step: 4048, epoch: 2, loss: 1.353172
global_step: 4049, epoch: 2, loss: 1.317547
global_step: 4050, epoch: 2, loss: 1.310576
global_step: 4051, epoch: 2, loss: 1.318391
global_step: 4052, epoch: 2, loss: 1.252157
global_step: 4053, epoch: 2, loss: 1.277703
global_step: 4054, epoch: 2, loss: 1.368228
global_step: 4055, epoch: 2, loss: 1.292019
global_step: 4056, epoch: 2, loss: 1.210525
global_step: 4057, epoch: 2, loss: 1.369345
global_step: 4058, epoch: 2, loss: 1.253837
global_step: 4059, epoch: 2, loss: 1.134231
global_step: 4060, epoch: 2, loss: 1.160923
global_step: 4061, epoch: 2, loss: 1.311689
global_step: 4062, epoch: 2, loss: 1.328281
global_step: 4063, epoch: 2, loss: 1.444622
global_step: 4064, epoch: 2, loss: 1.472410
global_step: 4065, epoch: 2, loss: 1.320740
global_step: 4066, epoch: 2, loss: 1.331607
global_step: 4067, epoch: 2, loss: 1.405642
global_step: 4068, epoch: 2, loss: 1.275437
global_step: 4069, epoch: 2, loss: 1.327329
global_step: 4070, epoch: 2, loss: 1.295693
global_step: 4071, epoch: 2, loss: 1.306492
global_step: 4072, epoch: 2, loss: 1.394313
global_step: 4073, epoch: 2, loss: 1.244889
global_step: 4074, epoch: 2, loss: 1.418222
global_step: 4075, epoch: 2, loss: 1.340231
global_step: 4076, epoch: 2, loss: 1.248904
global_step: 4077, epoch: 2, loss: 1.264260
global_step: 4078, epoch: 2, loss: 1.391032
global_step: 4079, epoch: 2, loss: 1.451439
global_step: 4080, epoch: 2, loss: 1.105131
epoch: 2
train	acc: 0.5654	macro: p 0.3267, r 0.2435, f1: 0.2174	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.4720
dev	acc: 0.5122	macro: p 0.2916, r 0.2448, f1: 0.2023	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4051
test	acc: 0.5693	macro: p 0.3465, r 0.2516, f1: 0.2237	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.4772
New best model!
global_step: 4081, epoch: 3, loss: 1.335485
global_step: 4082, epoch: 3, loss: 1.275442
global_step: 4083, epoch: 3, loss: 1.312732
global_step: 4084, epoch: 3, loss: 1.264450
global_step: 4085, epoch: 3, loss: 1.261268
global_step: 4086, epoch: 3, loss: 1.270978
global_step: 4087, epoch: 3, loss: 1.329513
global_step: 4088, epoch: 3, loss: 1.361712
global_step: 4089, epoch: 3, loss: 1.248170
global_step: 4090, epoch: 3, loss: 1.449249
global_step: 4091, epoch: 3, loss: 1.434985
global_step: 4092, epoch: 3, loss: 1.186541
global_step: 4093, epoch: 3, loss: 1.296151
global_step: 4094, epoch: 3, loss: 1.227757
global_step: 4095, epoch: 3, loss: 1.213853
global_step: 4096, epoch: 3, loss: 1.298911
global_step: 4097, epoch: 3, loss: 1.334324
global_step: 4098, epoch: 3, loss: 1.267275
global_step: 4099, epoch: 3, loss: 1.128527
global_step: 4100, epoch: 3, loss: 1.242358
global_step: 4101, epoch: 3, loss: 1.207176
global_step: 4102, epoch: 3, loss: 1.408617
global_step: 4103, epoch: 3, loss: 1.370874
global_step: 4104, epoch: 3, loss: 1.311422
global_step: 4105, epoch: 3, loss: 1.278773
global_step: 4106, epoch: 3, loss: 1.189111
global_step: 4107, epoch: 3, loss: 1.368125
global_step: 4108, epoch: 3, loss: 1.307639
global_step: 4109, epoch: 3, loss: 1.377183
global_step: 4110, epoch: 3, loss: 1.336124
global_step: 4111, epoch: 3, loss: 1.241721
global_step: 4112, epoch: 3, loss: 1.219860
global_step: 4113, epoch: 3, loss: 1.276756
global_step: 4114, epoch: 3, loss: 1.212984
global_step: 4115, epoch: 3, loss: 1.329229
global_step: 4116, epoch: 3, loss: 1.181493
global_step: 4117, epoch: 3, loss: 1.214117
global_step: 4118, epoch: 3, loss: 1.200062
global_step: 4119, epoch: 3, loss: 1.236468
global_step: 4120, epoch: 3, loss: 1.429050
epoch: 3
train	acc: 0.5825	macro: p 0.3343, r 0.2718, f1: 0.2532	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5047
dev	acc: 0.5221	macro: p 0.2940, r 0.2572, f1: 0.2244	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4280
test	acc: 0.5831	macro: p 0.3515, r 0.2672, f1: 0.2462	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5039
New best model!
global_step: 4121, epoch: 4, loss: 1.286905
global_step: 4122, epoch: 4, loss: 1.345853
global_step: 4123, epoch: 4, loss: 1.221577
global_step: 4124, epoch: 4, loss: 1.290696
global_step: 4125, epoch: 4, loss: 1.233427
global_step: 4126, epoch: 4, loss: 1.141938
global_step: 4127, epoch: 4, loss: 1.179835
global_step: 4128, epoch: 4, loss: 1.171543
global_step: 4129, epoch: 4, loss: 1.230550
global_step: 4130, epoch: 4, loss: 1.283041
global_step: 4131, epoch: 4, loss: 1.360483
global_step: 4132, epoch: 4, loss: 1.322084
global_step: 4133, epoch: 4, loss: 1.373793
global_step: 4134, epoch: 4, loss: 1.315675
global_step: 4135, epoch: 4, loss: 1.210215
global_step: 4136, epoch: 4, loss: 1.264531
global_step: 4137, epoch: 4, loss: 1.227092
global_step: 4138, epoch: 4, loss: 1.188453
global_step: 4139, epoch: 4, loss: 1.281108
global_step: 4140, epoch: 4, loss: 1.158484
global_step: 4141, epoch: 4, loss: 1.200041
global_step: 4142, epoch: 4, loss: 1.209334
global_step: 4143, epoch: 4, loss: 1.137503
global_step: 4144, epoch: 4, loss: 1.240399
global_step: 4145, epoch: 4, loss: 1.185354
global_step: 4146, epoch: 4, loss: 1.335986
global_step: 4147, epoch: 4, loss: 1.147189
global_step: 4148, epoch: 4, loss: 1.262526
global_step: 4149, epoch: 4, loss: 1.261591
global_step: 4150, epoch: 4, loss: 1.135008
global_step: 4151, epoch: 4, loss: 1.299361
global_step: 4152, epoch: 4, loss: 1.198226
global_step: 4153, epoch: 4, loss: 1.172769
global_step: 4154, epoch: 4, loss: 1.426039
global_step: 4155, epoch: 4, loss: 1.170488
global_step: 4156, epoch: 4, loss: 1.250769
global_step: 4157, epoch: 4, loss: 1.221081
global_step: 4158, epoch: 4, loss: 1.137201
global_step: 4159, epoch: 4, loss: 1.210154
global_step: 4160, epoch: 4, loss: 1.856108
epoch: 4
train	acc: 0.5600	macro: p 0.3982, r 0.3015, f1: 0.2853	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5133
dev	acc: 0.5176	macro: p 0.3765, r 0.2787, f1: 0.2687	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4652
test	acc: 0.5667	macro: p 0.3914, r 0.2971, f1: 0.2873	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5205
New best model!
global_step: 4161, epoch: 5, loss: 1.238752
global_step: 4162, epoch: 5, loss: 1.482213
global_step: 4163, epoch: 5, loss: 1.294145
global_step: 4164, epoch: 5, loss: 1.091657
global_step: 4165, epoch: 5, loss: 1.188118
global_step: 4166, epoch: 5, loss: 1.137102
global_step: 4167, epoch: 5, loss: 1.293721
global_step: 4168, epoch: 5, loss: 1.297717
global_step: 4169, epoch: 5, loss: 1.205998
global_step: 4170, epoch: 5, loss: 1.213131
global_step: 4171, epoch: 5, loss: 1.250240
global_step: 4172, epoch: 5, loss: 1.119190
global_step: 4173, epoch: 5, loss: 1.270026
global_step: 4174, epoch: 5, loss: 1.216288
global_step: 4175, epoch: 5, loss: 1.086419
global_step: 4176, epoch: 5, loss: 1.112347
global_step: 4177, epoch: 5, loss: 1.263803
global_step: 4178, epoch: 5, loss: 1.173106
global_step: 4179, epoch: 5, loss: 1.087258
global_step: 4180, epoch: 5, loss: 1.259755
global_step: 4181, epoch: 5, loss: 1.181636
global_step: 4182, epoch: 5, loss: 1.111468
global_step: 4183, epoch: 5, loss: 1.174252
global_step: 4184, epoch: 5, loss: 1.206024
global_step: 4185, epoch: 5, loss: 1.129004
global_step: 4186, epoch: 5, loss: 1.199507
global_step: 4187, epoch: 5, loss: 1.215755
global_step: 4188, epoch: 5, loss: 1.150778
global_step: 4189, epoch: 5, loss: 1.148135
global_step: 4190, epoch: 5, loss: 1.146924
global_step: 4191, epoch: 5, loss: 1.227872
global_step: 4192, epoch: 5, loss: 1.276427
global_step: 4193, epoch: 5, loss: 1.141176
global_step: 4194, epoch: 5, loss: 1.230123
global_step: 4195, epoch: 5, loss: 1.227239
global_step: 4196, epoch: 5, loss: 1.155461
global_step: 4197, epoch: 5, loss: 1.198757
global_step: 4198, epoch: 5, loss: 1.026151
global_step: 4199, epoch: 5, loss: 1.188169
global_step: 4200, epoch: 5, loss: 0.660782
epoch: 5
train	acc: 0.5869	macro: p 0.3494, r 0.2668, f1: 0.2683	micro: p 0.5869, r 0.5869, f1 0.5869	weighted_f1:0.5078
dev	acc: 0.5293	macro: p 0.3035, r 0.2578, f1: 0.2441	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4389
test	acc: 0.5904	macro: p 0.4843, r 0.2676, f1: 0.2681	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5098
global_step: 4201, epoch: 6, loss: 1.574324
global_step: 4202, epoch: 6, loss: 1.212332
global_step: 4203, epoch: 6, loss: 1.144542
global_step: 4204, epoch: 6, loss: 1.156292
global_step: 4205, epoch: 6, loss: 1.163777
global_step: 4206, epoch: 6, loss: 1.158863
global_step: 4207, epoch: 6, loss: 1.124922
global_step: 4208, epoch: 6, loss: 1.089640
global_step: 4209, epoch: 6, loss: 1.108286
global_step: 4210, epoch: 6, loss: 1.124873
global_step: 4211, epoch: 6, loss: 1.140779
global_step: 4212, epoch: 6, loss: 1.216598
global_step: 4213, epoch: 6, loss: 1.059729
global_step: 4214, epoch: 6, loss: 1.203024
global_step: 4215, epoch: 6, loss: 1.208336
global_step: 4216, epoch: 6, loss: 1.134708
global_step: 4217, epoch: 6, loss: 1.048497
global_step: 4218, epoch: 6, loss: 1.152997
global_step: 4219, epoch: 6, loss: 1.129740
global_step: 4220, epoch: 6, loss: 0.997373
global_step: 4221, epoch: 6, loss: 1.185123
global_step: 4222, epoch: 6, loss: 1.092539
global_step: 4223, epoch: 6, loss: 1.216297
global_step: 4224, epoch: 6, loss: 1.171606
global_step: 4225, epoch: 6, loss: 1.077243
global_step: 4226, epoch: 6, loss: 1.219068
global_step: 4227, epoch: 6, loss: 1.109618
global_step: 4228, epoch: 6, loss: 1.229241
global_step: 4229, epoch: 6, loss: 1.271880
global_step: 4230, epoch: 6, loss: 1.044716
global_step: 4231, epoch: 6, loss: 1.232544
global_step: 4232, epoch: 6, loss: 1.180540
global_step: 4233, epoch: 6, loss: 1.199741
global_step: 4234, epoch: 6, loss: 1.092067
global_step: 4235, epoch: 6, loss: 1.230638
global_step: 4236, epoch: 6, loss: 1.186944
global_step: 4237, epoch: 6, loss: 1.199339
global_step: 4238, epoch: 6, loss: 1.066091
global_step: 4239, epoch: 6, loss: 1.122601
global_step: 4240, epoch: 6, loss: 1.573972
epoch: 6
train	acc: 0.6422	macro: p 0.4256, r 0.3479, f1: 0.3559	micro: p 0.6422, r 0.6422, f1 0.6422	weighted_f1:0.5922
dev	acc: 0.5618	macro: p 0.4034, r 0.3068, f1: 0.3037	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.4988
test	acc: 0.6172	macro: p 0.3840, r 0.3200, f1: 0.3230	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5629
New best model!
global_step: 4241, epoch: 7, loss: 1.064631
global_step: 4242, epoch: 7, loss: 1.098655
global_step: 4243, epoch: 7, loss: 1.128633
global_step: 4244, epoch: 7, loss: 1.130649
global_step: 4245, epoch: 7, loss: 1.057834
global_step: 4246, epoch: 7, loss: 1.203947
global_step: 4247, epoch: 7, loss: 1.231904
global_step: 4248, epoch: 7, loss: 1.128736
global_step: 4249, epoch: 7, loss: 1.209116
global_step: 4250, epoch: 7, loss: 1.118567
global_step: 4251, epoch: 7, loss: 1.007937
global_step: 4252, epoch: 7, loss: 1.122427
global_step: 4253, epoch: 7, loss: 1.093231
global_step: 4254, epoch: 7, loss: 1.129056
global_step: 4255, epoch: 7, loss: 1.190571
global_step: 4256, epoch: 7, loss: 1.120285
global_step: 4257, epoch: 7, loss: 1.185403
global_step: 4258, epoch: 7, loss: 1.290184
global_step: 4259, epoch: 7, loss: 1.046416
global_step: 4260, epoch: 7, loss: 1.177678
global_step: 4261, epoch: 7, loss: 1.046727
global_step: 4262, epoch: 7, loss: 1.118353
global_step: 4263, epoch: 7, loss: 1.261568
global_step: 4264, epoch: 7, loss: 1.054281
global_step: 4265, epoch: 7, loss: 1.085605
global_step: 4266, epoch: 7, loss: 1.087742
global_step: 4267, epoch: 7, loss: 1.182017
global_step: 4268, epoch: 7, loss: 1.174602
global_step: 4269, epoch: 7, loss: 1.192103
global_step: 4270, epoch: 7, loss: 1.260643
global_step: 4271, epoch: 7, loss: 1.191406
global_step: 4272, epoch: 7, loss: 1.060611
global_step: 4273, epoch: 7, loss: 1.027893
global_step: 4274, epoch: 7, loss: 1.255876
global_step: 4275, epoch: 7, loss: 1.215326
global_step: 4276, epoch: 7, loss: 1.091953
global_step: 4277, epoch: 7, loss: 1.130589
global_step: 4278, epoch: 7, loss: 1.122738
global_step: 4279, epoch: 7, loss: 1.100014
global_step: 4280, epoch: 7, loss: 1.193868
epoch: 7
train	acc: 0.6312	macro: p 0.4272, r 0.3727, f1: 0.3747	micro: p 0.6312, r 0.6312, f1 0.6312	weighted_f1:0.5988
dev	acc: 0.5564	macro: p 0.3801, r 0.3192, f1: 0.3225	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5139
test	acc: 0.6034	macro: p 0.3787, r 0.3324, f1: 0.3373	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5689
New best model!
global_step: 4281, epoch: 8, loss: 1.267556
global_step: 4282, epoch: 8, loss: 1.024043
global_step: 4283, epoch: 8, loss: 1.078217
global_step: 4284, epoch: 8, loss: 1.060977
global_step: 4285, epoch: 8, loss: 1.212320
global_step: 4286, epoch: 8, loss: 1.047416
global_step: 4287, epoch: 8, loss: 1.081644
global_step: 4288, epoch: 8, loss: 1.176533
global_step: 4289, epoch: 8, loss: 1.124027
global_step: 4290, epoch: 8, loss: 1.050100
global_step: 4291, epoch: 8, loss: 1.061254
global_step: 4292, epoch: 8, loss: 1.198886
global_step: 4293, epoch: 8, loss: 1.086797
global_step: 4294, epoch: 8, loss: 1.110188
global_step: 4295, epoch: 8, loss: 1.188819
global_step: 4296, epoch: 8, loss: 1.126817
global_step: 4297, epoch: 8, loss: 1.141708
global_step: 4298, epoch: 8, loss: 1.095673
global_step: 4299, epoch: 8, loss: 1.147235
global_step: 4300, epoch: 8, loss: 1.074156
global_step: 4301, epoch: 8, loss: 1.013048
global_step: 4302, epoch: 8, loss: 1.109069
global_step: 4303, epoch: 8, loss: 0.995197
global_step: 4304, epoch: 8, loss: 1.001346
global_step: 4305, epoch: 8, loss: 1.204183
global_step: 4306, epoch: 8, loss: 1.099716
global_step: 4307, epoch: 8, loss: 1.010073
global_step: 4308, epoch: 8, loss: 1.199033
global_step: 4309, epoch: 8, loss: 1.199164
global_step: 4310, epoch: 8, loss: 1.031918
global_step: 4311, epoch: 8, loss: 1.070786
global_step: 4312, epoch: 8, loss: 1.265860
global_step: 4313, epoch: 8, loss: 1.197483
global_step: 4314, epoch: 8, loss: 1.032561
global_step: 4315, epoch: 8, loss: 1.212654
global_step: 4316, epoch: 8, loss: 1.148003
global_step: 4317, epoch: 8, loss: 1.009635
global_step: 4318, epoch: 8, loss: 1.042927
global_step: 4319, epoch: 8, loss: 1.093281
global_step: 4320, epoch: 8, loss: 1.067594
epoch: 8
train	acc: 0.6391	macro: p 0.4494, r 0.3452, f1: 0.3447	micro: p 0.6391, r 0.6391, f1 0.6391	weighted_f1:0.5889
dev	acc: 0.5437	macro: p 0.3825, r 0.3013, f1: 0.2803	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4796
test	acc: 0.5927	macro: p 0.4026, r 0.3126, f1: 0.3006	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5389
global_step: 4321, epoch: 9, loss: 1.079511
global_step: 4322, epoch: 9, loss: 1.096251
global_step: 4323, epoch: 9, loss: 0.977728
global_step: 4324, epoch: 9, loss: 1.097766
global_step: 4325, epoch: 9, loss: 1.002738
global_step: 4326, epoch: 9, loss: 1.035186
global_step: 4327, epoch: 9, loss: 1.012306
global_step: 4328, epoch: 9, loss: 1.102546
global_step: 4329, epoch: 9, loss: 1.255219
global_step: 4330, epoch: 9, loss: 1.119878
global_step: 4331, epoch: 9, loss: 1.042674
global_step: 4332, epoch: 9, loss: 1.005839
global_step: 4333, epoch: 9, loss: 0.985581
global_step: 4334, epoch: 9, loss: 1.063521
global_step: 4335, epoch: 9, loss: 0.989286
global_step: 4336, epoch: 9, loss: 1.075894
global_step: 4337, epoch: 9, loss: 1.060766
global_step: 4338, epoch: 9, loss: 1.129391
global_step: 4339, epoch: 9, loss: 1.057384
global_step: 4340, epoch: 9, loss: 1.084322
global_step: 4341, epoch: 9, loss: 0.977503
global_step: 4342, epoch: 9, loss: 1.082330
global_step: 4343, epoch: 9, loss: 0.961908
global_step: 4344, epoch: 9, loss: 1.056956
global_step: 4345, epoch: 9, loss: 0.953375
global_step: 4346, epoch: 9, loss: 0.948655
global_step: 4347, epoch: 9, loss: 1.135202
global_step: 4348, epoch: 9, loss: 1.029419
global_step: 4349, epoch: 9, loss: 0.988323
global_step: 4350, epoch: 9, loss: 0.987663
global_step: 4351, epoch: 9, loss: 1.141629
global_step: 4352, epoch: 9, loss: 1.075639
global_step: 4353, epoch: 9, loss: 0.983546
global_step: 4354, epoch: 9, loss: 1.315093
global_step: 4355, epoch: 9, loss: 1.193015
global_step: 4356, epoch: 9, loss: 1.117797
global_step: 4357, epoch: 9, loss: 1.085678
global_step: 4358, epoch: 9, loss: 1.128342
global_step: 4359, epoch: 9, loss: 1.089461
global_step: 4360, epoch: 9, loss: 1.198487
epoch: 9
train	acc: 0.6098	macro: p 0.4546, r 0.3176, f1: 0.3087	micro: p 0.6098, r 0.6098, f1 0.6098	weighted_f1:0.5355
dev	acc: 0.5311	macro: p 0.4140, r 0.2784, f1: 0.2546	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4425
test	acc: 0.5697	macro: p 0.3876, r 0.2735, f1: 0.2559	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.4871
global_step: 4361, epoch: 10, loss: 1.495081
global_step: 4362, epoch: 10, loss: 1.112205
global_step: 4363, epoch: 10, loss: 0.975456
global_step: 4364, epoch: 10, loss: 0.923566
global_step: 4365, epoch: 10, loss: 0.991352
global_step: 4366, epoch: 10, loss: 0.936976
global_step: 4367, epoch: 10, loss: 1.074211
global_step: 4368, epoch: 10, loss: 0.985546
global_step: 4369, epoch: 10, loss: 1.072553
global_step: 4370, epoch: 10, loss: 1.138573
global_step: 4371, epoch: 10, loss: 1.036781
global_step: 4372, epoch: 10, loss: 1.153969
global_step: 4373, epoch: 10, loss: 0.908804
global_step: 4374, epoch: 10, loss: 0.936373
global_step: 4375, epoch: 10, loss: 1.064064
global_step: 4376, epoch: 10, loss: 1.021165
global_step: 4377, epoch: 10, loss: 0.953096
global_step: 4378, epoch: 10, loss: 1.159979
global_step: 4379, epoch: 10, loss: 1.116305
global_step: 4380, epoch: 10, loss: 0.979869
global_step: 4381, epoch: 10, loss: 1.032610
global_step: 4382, epoch: 10, loss: 1.070953
global_step: 4383, epoch: 10, loss: 1.006603
global_step: 4384, epoch: 10, loss: 1.192630
global_step: 4385, epoch: 10, loss: 1.038793
global_step: 4386, epoch: 10, loss: 1.113694
global_step: 4387, epoch: 10, loss: 1.130630
global_step: 4388, epoch: 10, loss: 1.070273
global_step: 4389, epoch: 10, loss: 0.989625
global_step: 4390, epoch: 10, loss: 0.954633
global_step: 4391, epoch: 10, loss: 0.933025
global_step: 4392, epoch: 10, loss: 1.060497
global_step: 4393, epoch: 10, loss: 0.979660
global_step: 4394, epoch: 10, loss: 0.992754
global_step: 4395, epoch: 10, loss: 0.922844
global_step: 4396, epoch: 10, loss: 0.978376
global_step: 4397, epoch: 10, loss: 1.046108
global_step: 4398, epoch: 10, loss: 1.121084
global_step: 4399, epoch: 10, loss: 1.041283
global_step: 4400, epoch: 10, loss: 0.727400
epoch: 10
train	acc: 0.6449	macro: p 0.4556, r 0.3569, f1: 0.3731	micro: p 0.6449, r 0.6449, f1 0.6449	weighted_f1:0.6004
dev	acc: 0.5446	macro: p 0.3790, r 0.2896, f1: 0.2915	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4843
test	acc: 0.6146	macro: p 0.3959, r 0.3151, f1: 0.3252	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5630
global_step: 4401, epoch: 11, loss: 1.188900
global_step: 4402, epoch: 11, loss: 0.985745
global_step: 4403, epoch: 11, loss: 1.019397
global_step: 4404, epoch: 11, loss: 1.053584
global_step: 4405, epoch: 11, loss: 0.972093
global_step: 4406, epoch: 11, loss: 0.965116
global_step: 4407, epoch: 11, loss: 1.017065
global_step: 4408, epoch: 11, loss: 0.960779
global_step: 4409, epoch: 11, loss: 0.914893
global_step: 4410, epoch: 11, loss: 1.050913
global_step: 4411, epoch: 11, loss: 1.036066
global_step: 4412, epoch: 11, loss: 1.202464
global_step: 4413, epoch: 11, loss: 0.901057
global_step: 4414, epoch: 11, loss: 0.961442
global_step: 4415, epoch: 11, loss: 0.942927
global_step: 4416, epoch: 11, loss: 0.955308
global_step: 4417, epoch: 11, loss: 1.058221
global_step: 4418, epoch: 11, loss: 1.033590
global_step: 4419, epoch: 11, loss: 0.961279
global_step: 4420, epoch: 11, loss: 1.014248
global_step: 4421, epoch: 11, loss: 1.013640
global_step: 4422, epoch: 11, loss: 0.899148
global_step: 4423, epoch: 11, loss: 0.947130
global_step: 4424, epoch: 11, loss: 1.002449
global_step: 4425, epoch: 11, loss: 1.039881
global_step: 4426, epoch: 11, loss: 1.001846
global_step: 4427, epoch: 11, loss: 0.925167
global_step: 4428, epoch: 11, loss: 1.005494
global_step: 4429, epoch: 11, loss: 1.029901
global_step: 4430, epoch: 11, loss: 0.958856
global_step: 4431, epoch: 11, loss: 1.010474
global_step: 4432, epoch: 11, loss: 1.094270
global_step: 4433, epoch: 11, loss: 1.170965
global_step: 4434, epoch: 11, loss: 0.893684
global_step: 4435, epoch: 11, loss: 0.968001
global_step: 4436, epoch: 11, loss: 0.983458
global_step: 4437, epoch: 11, loss: 0.915795
global_step: 4438, epoch: 11, loss: 1.082233
global_step: 4439, epoch: 11, loss: 1.015722
global_step: 4440, epoch: 11, loss: 0.234277
epoch: 11
train	acc: 0.6361	macro: p 0.6288, r 0.3231, f1: 0.3442	micro: p 0.6361, r 0.6361, f1 0.6361	weighted_f1:0.5749
dev	acc: 0.5455	macro: p 0.4364, r 0.2785, f1: 0.2699	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4618
test	acc: 0.6004	macro: p 0.4045, r 0.2819, f1: 0.2820	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5215
global_step: 4441, epoch: 12, loss: 1.183214
global_step: 4442, epoch: 12, loss: 1.042570
global_step: 4443, epoch: 12, loss: 0.950982
global_step: 4444, epoch: 12, loss: 0.944472
global_step: 4445, epoch: 12, loss: 0.901442
global_step: 4446, epoch: 12, loss: 0.879478
global_step: 4447, epoch: 12, loss: 0.965575
global_step: 4448, epoch: 12, loss: 0.985025
global_step: 4449, epoch: 12, loss: 0.921485
global_step: 4450, epoch: 12, loss: 1.006555
global_step: 4451, epoch: 12, loss: 1.088385
global_step: 4452, epoch: 12, loss: 0.963279
global_step: 4453, epoch: 12, loss: 0.935451
global_step: 4454, epoch: 12, loss: 0.985456
global_step: 4455, epoch: 12, loss: 0.925602
global_step: 4456, epoch: 12, loss: 0.970076
global_step: 4457, epoch: 12, loss: 0.994186
global_step: 4458, epoch: 12, loss: 1.045503
global_step: 4459, epoch: 12, loss: 0.898690
global_step: 4460, epoch: 12, loss: 0.896311
global_step: 4461, epoch: 12, loss: 0.938746
global_step: 4462, epoch: 12, loss: 1.049722
global_step: 4463, epoch: 12, loss: 1.084056
global_step: 4464, epoch: 12, loss: 1.060742
global_step: 4465, epoch: 12, loss: 0.940533
global_step: 4466, epoch: 12, loss: 0.935255
global_step: 4467, epoch: 12, loss: 0.985273
global_step: 4468, epoch: 12, loss: 0.969968
global_step: 4469, epoch: 12, loss: 1.147283
global_step: 4470, epoch: 12, loss: 0.958028
global_step: 4471, epoch: 12, loss: 0.982645
global_step: 4472, epoch: 12, loss: 0.937861
global_step: 4473, epoch: 12, loss: 0.986213
global_step: 4474, epoch: 12, loss: 1.057200
global_step: 4475, epoch: 12, loss: 0.957498
global_step: 4476, epoch: 12, loss: 0.818357
global_step: 4477, epoch: 12, loss: 1.061949
global_step: 4478, epoch: 12, loss: 0.995717
global_step: 4479, epoch: 12, loss: 0.934399
global_step: 4480, epoch: 12, loss: 0.743431
epoch: 12
train	acc: 0.6912	macro: p 0.6362, r 0.4318, f1: 0.4251	micro: p 0.6912, r 0.6912, f1 0.6912	weighted_f1:0.6633
dev	acc: 0.5374	macro: p 0.3843, r 0.3223, f1: 0.3063	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5012
test	acc: 0.5705	macro: p 0.3839, r 0.3336, f1: 0.3187	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5443
global_step: 4481, epoch: 13, loss: 1.045783
global_step: 4482, epoch: 13, loss: 0.810434
global_step: 4483, epoch: 13, loss: 1.044926
global_step: 4484, epoch: 13, loss: 0.966679
global_step: 4485, epoch: 13, loss: 0.854134
global_step: 4486, epoch: 13, loss: 1.008389
global_step: 4487, epoch: 13, loss: 0.896859
global_step: 4488, epoch: 13, loss: 1.025977
global_step: 4489, epoch: 13, loss: 0.955467
global_step: 4490, epoch: 13, loss: 0.749861
global_step: 4491, epoch: 13, loss: 0.961650
global_step: 4492, epoch: 13, loss: 0.893715
global_step: 4493, epoch: 13, loss: 0.929693
global_step: 4494, epoch: 13, loss: 0.970283
global_step: 4495, epoch: 13, loss: 0.822193
global_step: 4496, epoch: 13, loss: 0.978679
global_step: 4497, epoch: 13, loss: 0.861614
global_step: 4498, epoch: 13, loss: 0.943146
global_step: 4499, epoch: 13, loss: 0.920453
global_step: 4500, epoch: 13, loss: 1.073252
global_step: 4501, epoch: 13, loss: 1.008129
global_step: 4502, epoch: 13, loss: 0.957928
global_step: 4503, epoch: 13, loss: 1.070412
global_step: 4504, epoch: 13, loss: 0.973456
global_step: 4505, epoch: 13, loss: 1.012690
global_step: 4506, epoch: 13, loss: 0.987606
global_step: 4507, epoch: 13, loss: 0.806987
global_step: 4508, epoch: 13, loss: 0.928521
global_step: 4509, epoch: 13, loss: 0.886242
global_step: 4510, epoch: 13, loss: 0.944326
global_step: 4511, epoch: 13, loss: 0.927551
global_step: 4512, epoch: 13, loss: 1.113183
global_step: 4513, epoch: 13, loss: 1.084966
global_step: 4514, epoch: 13, loss: 0.945382
global_step: 4515, epoch: 13, loss: 0.959457
global_step: 4516, epoch: 13, loss: 0.912333
global_step: 4517, epoch: 13, loss: 0.863033
global_step: 4518, epoch: 13, loss: 0.869927
global_step: 4519, epoch: 13, loss: 0.911315
global_step: 4520, epoch: 13, loss: 1.253358
epoch: 13
train	acc: 0.7361	macro: p 0.6206, r 0.4862, f1: 0.5068	micro: p 0.7361, r 0.7361, f1 0.7361	weighted_f1:0.7094
dev	acc: 0.5573	macro: p 0.4129, r 0.3326, f1: 0.3265	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5090
test	acc: 0.5962	macro: p 0.4178, r 0.3355, f1: 0.3320	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5548
global_step: 4521, epoch: 14, loss: 0.940389
global_step: 4522, epoch: 14, loss: 0.890893
global_step: 4523, epoch: 14, loss: 0.834098
global_step: 4524, epoch: 14, loss: 0.811267
global_step: 4525, epoch: 14, loss: 0.949956
global_step: 4526, epoch: 14, loss: 0.925885
global_step: 4527, epoch: 14, loss: 0.978601
global_step: 4528, epoch: 14, loss: 0.911091
global_step: 4529, epoch: 14, loss: 0.799826
global_step: 4530, epoch: 14, loss: 0.898476
global_step: 4531, epoch: 14, loss: 0.805380
global_step: 4532, epoch: 14, loss: 0.961061
global_step: 4533, epoch: 14, loss: 0.961653
global_step: 4534, epoch: 14, loss: 0.948770
global_step: 4535, epoch: 14, loss: 1.003894
global_step: 4536, epoch: 14, loss: 0.982831
global_step: 4537, epoch: 14, loss: 0.827083
global_step: 4538, epoch: 14, loss: 0.893452
global_step: 4539, epoch: 14, loss: 0.878077
global_step: 4540, epoch: 14, loss: 1.021520
global_step: 4541, epoch: 14, loss: 0.874343
global_step: 4542, epoch: 14, loss: 0.848570
global_step: 4543, epoch: 14, loss: 0.855219
global_step: 4544, epoch: 14, loss: 0.826583
global_step: 4545, epoch: 14, loss: 0.848410
global_step: 4546, epoch: 14, loss: 0.951416
global_step: 4547, epoch: 14, loss: 1.124335
global_step: 4548, epoch: 14, loss: 0.933497
global_step: 4549, epoch: 14, loss: 0.890450
global_step: 4550, epoch: 14, loss: 0.958026
global_step: 4551, epoch: 14, loss: 0.704069
global_step: 4552, epoch: 14, loss: 0.914360
global_step: 4553, epoch: 14, loss: 0.904279
global_step: 4554, epoch: 14, loss: 0.932154
global_step: 4555, epoch: 14, loss: 0.900870
global_step: 4556, epoch: 14, loss: 0.817265
global_step: 4557, epoch: 14, loss: 0.835950
global_step: 4558, epoch: 14, loss: 0.946346
global_step: 4559, epoch: 14, loss: 1.033991
global_step: 4560, epoch: 14, loss: 0.372418
epoch: 14
train	acc: 0.7146	macro: p 0.6936, r 0.4892, f1: 0.4769	micro: p 0.7146, r 0.7146, f1 0.7146	weighted_f1:0.7022
dev	acc: 0.5410	macro: p 0.3630, r 0.3377, f1: 0.3184	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5128
test	acc: 0.5579	macro: p 0.3628, r 0.3489, f1: 0.3265	micro: p 0.5579, r 0.5579, f1 0.5579	weighted_f1:0.5446
global_step: 4561, epoch: 15, loss: 0.987680
global_step: 4562, epoch: 15, loss: 0.868134
global_step: 4563, epoch: 15, loss: 0.812267
global_step: 4564, epoch: 15, loss: 0.955618
global_step: 4565, epoch: 15, loss: 0.810456
global_step: 4566, epoch: 15, loss: 0.867423
global_step: 4567, epoch: 15, loss: 0.964079
global_step: 4568, epoch: 15, loss: 0.855982
global_step: 4569, epoch: 15, loss: 0.888701
global_step: 4570, epoch: 15, loss: 0.842628
global_step: 4571, epoch: 15, loss: 0.869009
global_step: 4572, epoch: 15, loss: 0.884961
global_step: 4573, epoch: 15, loss: 0.828006
global_step: 4574, epoch: 15, loss: 0.835509
global_step: 4575, epoch: 15, loss: 0.818839
global_step: 4576, epoch: 15, loss: 0.922252
global_step: 4577, epoch: 15, loss: 0.974002
global_step: 4578, epoch: 15, loss: 1.002832
global_step: 4579, epoch: 15, loss: 0.845454
global_step: 4580, epoch: 15, loss: 0.999629
global_step: 4581, epoch: 15, loss: 1.006911
global_step: 4582, epoch: 15, loss: 0.922443
global_step: 4583, epoch: 15, loss: 0.877435
global_step: 4584, epoch: 15, loss: 0.978823
global_step: 4585, epoch: 15, loss: 0.854779
global_step: 4586, epoch: 15, loss: 1.001001
global_step: 4587, epoch: 15, loss: 0.891950
global_step: 4588, epoch: 15, loss: 0.928074
global_step: 4589, epoch: 15, loss: 0.811504
global_step: 4590, epoch: 15, loss: 0.866774
global_step: 4591, epoch: 15, loss: 0.867089
global_step: 4592, epoch: 15, loss: 1.075649
global_step: 4593, epoch: 15, loss: 1.033067
global_step: 4594, epoch: 15, loss: 0.836236
global_step: 4595, epoch: 15, loss: 0.900854
global_step: 4596, epoch: 15, loss: 0.785077
global_step: 4597, epoch: 15, loss: 0.941358
global_step: 4598, epoch: 15, loss: 0.971629
global_step: 4599, epoch: 15, loss: 0.837926
global_step: 4600, epoch: 15, loss: 0.278381
epoch: 15
train	acc: 0.7002	macro: p 0.7364, r 0.4325, f1: 0.4675	micro: p 0.7002, r 0.7002, f1 0.7002	weighted_f1:0.6661
dev	acc: 0.5573	macro: p 0.4414, r 0.3108, f1: 0.3202	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5019
test	acc: 0.6188	macro: p 0.4871, r 0.3267, f1: 0.3424	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5684
global_step: 4601, epoch: 16, loss: 0.865642
global_step: 4602, epoch: 16, loss: 0.822534
global_step: 4603, epoch: 16, loss: 0.886724
global_step: 4604, epoch: 16, loss: 0.792010
global_step: 4605, epoch: 16, loss: 0.706053
global_step: 4606, epoch: 16, loss: 0.809300
global_step: 4607, epoch: 16, loss: 0.750008
global_step: 4608, epoch: 16, loss: 0.893938
global_step: 4609, epoch: 16, loss: 0.857709
global_step: 4610, epoch: 16, loss: 0.897310
global_step: 4611, epoch: 16, loss: 0.736676
global_step: 4612, epoch: 16, loss: 0.832096
global_step: 4613, epoch: 16, loss: 0.885015
global_step: 4614, epoch: 16, loss: 0.777957
global_step: 4615, epoch: 16, loss: 0.805451
global_step: 4616, epoch: 16, loss: 0.865477
global_step: 4617, epoch: 16, loss: 0.869773
global_step: 4618, epoch: 16, loss: 0.806749
global_step: 4619, epoch: 16, loss: 0.799001
global_step: 4620, epoch: 16, loss: 0.758936
global_step: 4621, epoch: 16, loss: 0.795921
global_step: 4622, epoch: 16, loss: 0.811099
global_step: 4623, epoch: 16, loss: 0.813524
global_step: 4624, epoch: 16, loss: 0.888424
global_step: 4625, epoch: 16, loss: 0.949955
global_step: 4626, epoch: 16, loss: 0.793777
global_step: 4627, epoch: 16, loss: 0.761100
global_step: 4628, epoch: 16, loss: 0.786315
global_step: 4629, epoch: 16, loss: 0.832464
global_step: 4630, epoch: 16, loss: 0.741738
global_step: 4631, epoch: 16, loss: 0.915094
global_step: 4632, epoch: 16, loss: 0.805310
global_step: 4633, epoch: 16, loss: 0.884169
global_step: 4634, epoch: 16, loss: 0.749944
global_step: 4635, epoch: 16, loss: 0.795177
global_step: 4636, epoch: 16, loss: 0.869981
global_step: 4637, epoch: 16, loss: 0.954797
global_step: 4638, epoch: 16, loss: 0.765015
global_step: 4639, epoch: 16, loss: 0.811470
global_step: 4640, epoch: 16, loss: 1.044778
epoch: 16
train	acc: 0.6624	macro: p 0.7584, r 0.4306, f1: 0.4413	micro: p 0.6624, r 0.6624, f1 0.6624	weighted_f1:0.6444
dev	acc: 0.4950	macro: p 0.4788, r 0.3158, f1: 0.2935	micro: p 0.4950, r 0.4950, f1 0.4950	weighted_f1:0.4616
test	acc: 0.5096	macro: p 0.4464, r 0.3017, f1: 0.2775	micro: p 0.5096, r 0.5096, f1 0.5096	weighted_f1:0.4861
global_step: 4641, epoch: 17, loss: 1.156517
global_step: 4642, epoch: 17, loss: 0.915237
global_step: 4643, epoch: 17, loss: 0.846620
global_step: 4644, epoch: 17, loss: 0.678181
global_step: 4645, epoch: 17, loss: 0.790664
global_step: 4646, epoch: 17, loss: 0.823732
global_step: 4647, epoch: 17, loss: 0.749153
global_step: 4648, epoch: 17, loss: 0.763813
global_step: 4649, epoch: 17, loss: 0.822722
global_step: 4650, epoch: 17, loss: 0.683493
global_step: 4651, epoch: 17, loss: 0.722790
global_step: 4652, epoch: 17, loss: 0.746559
global_step: 4653, epoch: 17, loss: 0.734843
global_step: 4654, epoch: 17, loss: 0.813082
global_step: 4655, epoch: 17, loss: 0.827384
global_step: 4656, epoch: 17, loss: 0.856751
global_step: 4657, epoch: 17, loss: 0.718449
global_step: 4658, epoch: 17, loss: 0.833589
global_step: 4659, epoch: 17, loss: 0.825628
global_step: 4660, epoch: 17, loss: 0.670471
global_step: 4661, epoch: 17, loss: 0.708561
global_step: 4662, epoch: 17, loss: 0.880466
global_step: 4663, epoch: 17, loss: 0.786960
global_step: 4664, epoch: 17, loss: 0.811378
global_step: 4665, epoch: 17, loss: 0.786376
global_step: 4666, epoch: 17, loss: 0.742290
global_step: 4667, epoch: 17, loss: 0.775352
global_step: 4668, epoch: 17, loss: 0.887475
global_step: 4669, epoch: 17, loss: 0.906023
global_step: 4670, epoch: 17, loss: 0.749659
global_step: 4671, epoch: 17, loss: 0.875213
global_step: 4672, epoch: 17, loss: 0.839845
global_step: 4673, epoch: 17, loss: 0.717496
global_step: 4674, epoch: 17, loss: 0.833807
global_step: 4675, epoch: 17, loss: 0.728327
global_step: 4676, epoch: 17, loss: 0.686592
global_step: 4677, epoch: 17, loss: 0.892774
global_step: 4678, epoch: 17, loss: 0.725205
global_step: 4679, epoch: 17, loss: 0.870611
global_step: 4680, epoch: 17, loss: 0.597209
epoch: 17
train	acc: 0.6996	macro: p 0.7003, r 0.5179, f1: 0.5141	micro: p 0.6996, r 0.6996, f1 0.6996	weighted_f1:0.6917
dev	acc: 0.4797	macro: p 0.3815, r 0.3149, f1: 0.2912	micro: p 0.4797, r 0.4797, f1 0.4797	weighted_f1:0.4647
test	acc: 0.5111	macro: p 0.3719, r 0.3282, f1: 0.3026	micro: p 0.5111, r 0.5111, f1 0.5111	weighted_f1:0.5057
global_step: 4681, epoch: 18, loss: 1.100541
global_step: 4682, epoch: 18, loss: 0.775477
global_step: 4683, epoch: 18, loss: 0.718492
global_step: 4684, epoch: 18, loss: 0.713135
global_step: 4685, epoch: 18, loss: 0.604756
global_step: 4686, epoch: 18, loss: 0.734299
global_step: 4687, epoch: 18, loss: 0.752065
global_step: 4688, epoch: 18, loss: 0.676370
global_step: 4689, epoch: 18, loss: 0.661729
global_step: 4690, epoch: 18, loss: 0.710410
global_step: 4691, epoch: 18, loss: 0.734177
global_step: 4692, epoch: 18, loss: 0.723543
global_step: 4693, epoch: 18, loss: 0.617904
global_step: 4694, epoch: 18, loss: 0.735228
global_step: 4695, epoch: 18, loss: 0.741276
global_step: 4696, epoch: 18, loss: 0.771808
global_step: 4697, epoch: 18, loss: 0.707288
global_step: 4698, epoch: 18, loss: 0.734584
global_step: 4699, epoch: 18, loss: 0.818670
global_step: 4700, epoch: 18, loss: 0.673311
global_step: 4701, epoch: 18, loss: 0.895890
global_step: 4702, epoch: 18, loss: 0.644594
global_step: 4703, epoch: 18, loss: 0.703045
global_step: 4704, epoch: 18, loss: 0.801757
global_step: 4705, epoch: 18, loss: 0.706918
global_step: 4706, epoch: 18, loss: 0.743726
global_step: 4707, epoch: 18, loss: 0.857306
global_step: 4708, epoch: 18, loss: 0.746996
global_step: 4709, epoch: 18, loss: 0.731845
global_step: 4710, epoch: 18, loss: 0.746408
global_step: 4711, epoch: 18, loss: 0.841679
global_step: 4712, epoch: 18, loss: 0.858571
global_step: 4713, epoch: 18, loss: 0.751874
global_step: 4714, epoch: 18, loss: 0.714681
global_step: 4715, epoch: 18, loss: 0.853573
global_step: 4716, epoch: 18, loss: 0.793226
global_step: 4717, epoch: 18, loss: 0.656322
global_step: 4718, epoch: 18, loss: 0.769742
global_step: 4719, epoch: 18, loss: 0.832380
global_step: 4720, epoch: 18, loss: 0.386655
epoch: 18
train	acc: 0.7056	macro: p 0.7612, r 0.4285, f1: 0.4592	micro: p 0.7056, r 0.7056, f1 0.7056	weighted_f1:0.6545
dev	acc: 0.5509	macro: p 0.4784, r 0.2998, f1: 0.2771	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4671
test	acc: 0.5962	macro: p 0.5660, r 0.3052, f1: 0.2969	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5215
global_step: 4721, epoch: 19, loss: 1.074539
global_step: 4722, epoch: 19, loss: 0.908463
global_step: 4723, epoch: 19, loss: 0.795212
global_step: 4724, epoch: 19, loss: 0.629310
global_step: 4725, epoch: 19, loss: 0.738087
global_step: 4726, epoch: 19, loss: 0.728119
global_step: 4727, epoch: 19, loss: 0.731108
global_step: 4728, epoch: 19, loss: 0.720623
global_step: 4729, epoch: 19, loss: 0.797396
global_step: 4730, epoch: 19, loss: 0.731451
global_step: 4731, epoch: 19, loss: 0.707864
global_step: 4732, epoch: 19, loss: 0.666557
global_step: 4733, epoch: 19, loss: 0.732678
global_step: 4734, epoch: 19, loss: 0.663916
global_step: 4735, epoch: 19, loss: 0.894366
global_step: 4736, epoch: 19, loss: 0.727399
global_step: 4737, epoch: 19, loss: 0.678737
global_step: 4738, epoch: 19, loss: 0.675331
global_step: 4739, epoch: 19, loss: 0.679702
global_step: 4740, epoch: 19, loss: 0.716532
global_step: 4741, epoch: 19, loss: 0.616834
global_step: 4742, epoch: 19, loss: 0.694025
global_step: 4743, epoch: 19, loss: 0.643746
global_step: 4744, epoch: 19, loss: 0.658284
global_step: 4745, epoch: 19, loss: 0.664619
global_step: 4746, epoch: 19, loss: 0.704977
global_step: 4747, epoch: 19, loss: 0.677954
global_step: 4748, epoch: 19, loss: 0.664870
global_step: 4749, epoch: 19, loss: 0.701811
global_step: 4750, epoch: 19, loss: 0.859665
global_step: 4751, epoch: 19, loss: 0.639723
global_step: 4752, epoch: 19, loss: 0.713850
global_step: 4753, epoch: 19, loss: 0.690416
global_step: 4754, epoch: 19, loss: 0.730473
global_step: 4755, epoch: 19, loss: 0.739017
global_step: 4756, epoch: 19, loss: 0.855193
global_step: 4757, epoch: 19, loss: 0.746923
global_step: 4758, epoch: 19, loss: 0.757907
global_step: 4759, epoch: 19, loss: 0.848567
global_step: 4760, epoch: 19, loss: 0.531521
epoch: 19
train	acc: 0.7805	macro: p 0.8285, r 0.5707, f1: 0.6371	micro: p 0.7805, r 0.7805, f1 0.7805	weighted_f1:0.7629
dev	acc: 0.5482	macro: p 0.4470, r 0.3050, f1: 0.3131	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4856
test	acc: 0.5946	macro: p 0.5127, r 0.3140, f1: 0.3355	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5382
global_step: 4761, epoch: 20, loss: 0.796398
global_step: 4762, epoch: 20, loss: 0.768551
global_step: 4763, epoch: 20, loss: 0.796759
global_step: 4764, epoch: 20, loss: 0.724548
global_step: 4765, epoch: 20, loss: 0.566852
global_step: 4766, epoch: 20, loss: 0.688626
global_step: 4767, epoch: 20, loss: 0.558801
global_step: 4768, epoch: 20, loss: 0.586107
global_step: 4769, epoch: 20, loss: 0.685203
global_step: 4770, epoch: 20, loss: 0.726308
global_step: 4771, epoch: 20, loss: 0.717745
global_step: 4772, epoch: 20, loss: 0.660846
global_step: 4773, epoch: 20, loss: 0.706722
global_step: 4774, epoch: 20, loss: 0.669442
global_step: 4775, epoch: 20, loss: 0.624314
global_step: 4776, epoch: 20, loss: 0.625501
global_step: 4777, epoch: 20, loss: 0.636554
global_step: 4778, epoch: 20, loss: 0.600721
global_step: 4779, epoch: 20, loss: 0.682131
global_step: 4780, epoch: 20, loss: 0.681046
global_step: 4781, epoch: 20, loss: 0.662003
global_step: 4782, epoch: 20, loss: 0.676824
global_step: 4783, epoch: 20, loss: 0.711901
global_step: 4784, epoch: 20, loss: 0.663205
global_step: 4785, epoch: 20, loss: 0.804984
global_step: 4786, epoch: 20, loss: 0.873423
global_step: 4787, epoch: 20, loss: 0.692447
global_step: 4788, epoch: 20, loss: 0.660985
global_step: 4789, epoch: 20, loss: 0.640731
global_step: 4790, epoch: 20, loss: 0.664891
global_step: 4791, epoch: 20, loss: 0.715939
global_step: 4792, epoch: 20, loss: 0.745871
global_step: 4793, epoch: 20, loss: 0.783298
global_step: 4794, epoch: 20, loss: 0.949221
global_step: 4795, epoch: 20, loss: 0.783104
global_step: 4796, epoch: 20, loss: 0.742996
global_step: 4797, epoch: 20, loss: 0.702707
global_step: 4798, epoch: 20, loss: 0.738103
global_step: 4799, epoch: 20, loss: 0.821422
global_step: 4800, epoch: 20, loss: 0.434369
epoch: 20
train	acc: 0.7498	macro: p 0.8255, r 0.4672, f1: 0.4997	micro: p 0.7498, r 0.7498, f1 0.7498	weighted_f1:0.7109
dev	acc: 0.5618	macro: p 0.4975, r 0.3104, f1: 0.2997	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.4894
test	acc: 0.6065	macro: p 0.5938, r 0.3132, f1: 0.3154	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5428
global_step: 4801, epoch: 21, loss: 0.672213
global_step: 4802, epoch: 21, loss: 0.664079
global_step: 4803, epoch: 21, loss: 0.680847
global_step: 4804, epoch: 21, loss: 0.699217
global_step: 4805, epoch: 21, loss: 0.749078
global_step: 4806, epoch: 21, loss: 0.592200
global_step: 4807, epoch: 21, loss: 0.655621
global_step: 4808, epoch: 21, loss: 0.578353
global_step: 4809, epoch: 21, loss: 0.561883
global_step: 4810, epoch: 21, loss: 0.714014
global_step: 4811, epoch: 21, loss: 0.755014
global_step: 4812, epoch: 21, loss: 0.699066
global_step: 4813, epoch: 21, loss: 0.768888
global_step: 4814, epoch: 21, loss: 0.664145
global_step: 4815, epoch: 21, loss: 0.619833
global_step: 4816, epoch: 21, loss: 0.675828
global_step: 4817, epoch: 21, loss: 0.747978
global_step: 4818, epoch: 21, loss: 0.650201
global_step: 4819, epoch: 21, loss: 0.621245
global_step: 4820, epoch: 21, loss: 0.701070
global_step: 4821, epoch: 21, loss: 0.670269
global_step: 4822, epoch: 21, loss: 0.675953
global_step: 4823, epoch: 21, loss: 0.719329
global_step: 4824, epoch: 21, loss: 0.665752
global_step: 4825, epoch: 21, loss: 0.692393
global_step: 4826, epoch: 21, loss: 0.729958
global_step: 4827, epoch: 21, loss: 0.695970
global_step: 4828, epoch: 21, loss: 0.793222
global_step: 4829, epoch: 21, loss: 0.650567
global_step: 4830, epoch: 21, loss: 0.574081
global_step: 4831, epoch: 21, loss: 0.601900
global_step: 4832, epoch: 21, loss: 0.756785
global_step: 4833, epoch: 21, loss: 0.632874
global_step: 4834, epoch: 21, loss: 0.627377
global_step: 4835, epoch: 21, loss: 0.717799
global_step: 4836, epoch: 21, loss: 0.676174
global_step: 4837, epoch: 21, loss: 0.695756
global_step: 4838, epoch: 21, loss: 0.637979
global_step: 4839, epoch: 21, loss: 0.719847
global_step: 4840, epoch: 21, loss: 0.450561
epoch: 21
train	acc: 0.7889	macro: p 0.8086, r 0.6918, f1: 0.7117	micro: p 0.7889, r 0.7889, f1 0.7889	weighted_f1:0.7902
dev	acc: 0.4941	macro: p 0.4709, r 0.3547, f1: 0.3491	micro: p 0.4941, r 0.4941, f1 0.4941	weighted_f1:0.4900
test	acc: 0.5192	macro: p 0.3782, r 0.3530, f1: 0.3318	micro: p 0.5192, r 0.5192, f1 0.5192	weighted_f1:0.5168
global_step: 4841, epoch: 22, loss: 0.867487
global_step: 4842, epoch: 22, loss: 0.654658
global_step: 4843, epoch: 22, loss: 0.665633
global_step: 4844, epoch: 22, loss: 0.595364
global_step: 4845, epoch: 22, loss: 0.727187
global_step: 4846, epoch: 22, loss: 0.740697
global_step: 4847, epoch: 22, loss: 0.595018
global_step: 4848, epoch: 22, loss: 0.543516
global_step: 4849, epoch: 22, loss: 0.653044
global_step: 4850, epoch: 22, loss: 0.638317
global_step: 4851, epoch: 22, loss: 0.615294
global_step: 4852, epoch: 22, loss: 0.665112
global_step: 4853, epoch: 22, loss: 0.679592
global_step: 4854, epoch: 22, loss: 0.572000
global_step: 4855, epoch: 22, loss: 0.680134
global_step: 4856, epoch: 22, loss: 0.583235
global_step: 4857, epoch: 22, loss: 0.692833
global_step: 4858, epoch: 22, loss: 0.568074
global_step: 4859, epoch: 22, loss: 0.628612
global_step: 4860, epoch: 22, loss: 0.685489
global_step: 4861, epoch: 22, loss: 0.676978
global_step: 4862, epoch: 22, loss: 0.575792
global_step: 4863, epoch: 22, loss: 0.713710
global_step: 4864, epoch: 22, loss: 0.577366
global_step: 4865, epoch: 22, loss: 0.634254
global_step: 4866, epoch: 22, loss: 0.665865
global_step: 4867, epoch: 22, loss: 0.572844
global_step: 4868, epoch: 22, loss: 0.631706
global_step: 4869, epoch: 22, loss: 0.502937
global_step: 4870, epoch: 22, loss: 0.713690
global_step: 4871, epoch: 22, loss: 0.737401
global_step: 4872, epoch: 22, loss: 0.675162
global_step: 4873, epoch: 22, loss: 0.717923
global_step: 4874, epoch: 22, loss: 0.639787
global_step: 4875, epoch: 22, loss: 0.681051
global_step: 4876, epoch: 22, loss: 0.707512
global_step: 4877, epoch: 22, loss: 0.719570
global_step: 4878, epoch: 22, loss: 0.740568
global_step: 4879, epoch: 22, loss: 0.642262
global_step: 4880, epoch: 22, loss: 0.736859
epoch: 22
train	acc: 0.8489	macro: p 0.7968, r 0.7583, f1: 0.7621	micro: p 0.8489, r 0.8489, f1 0.8489	weighted_f1:0.8467
dev	acc: 0.5374	macro: p 0.4059, r 0.3548, f1: 0.3445	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5083
test	acc: 0.5759	macro: p 0.4031, r 0.3739, f1: 0.3559	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5536
global_step: 4881, epoch: 23, loss: 0.652224
global_step: 4882, epoch: 23, loss: 0.625465
global_step: 4883, epoch: 23, loss: 0.564479
global_step: 4884, epoch: 23, loss: 0.483766
global_step: 4885, epoch: 23, loss: 0.733479
global_step: 4886, epoch: 23, loss: 0.672582
global_step: 4887, epoch: 23, loss: 0.585669
global_step: 4888, epoch: 23, loss: 0.646337
global_step: 4889, epoch: 23, loss: 0.612574
global_step: 4890, epoch: 23, loss: 0.619900
global_step: 4891, epoch: 23, loss: 0.565645
global_step: 4892, epoch: 23, loss: 0.540155
global_step: 4893, epoch: 23, loss: 0.571092
global_step: 4894, epoch: 23, loss: 0.603285
global_step: 4895, epoch: 23, loss: 0.696792
global_step: 4896, epoch: 23, loss: 0.555119
global_step: 4897, epoch: 23, loss: 0.586789
global_step: 4898, epoch: 23, loss: 0.659005
global_step: 4899, epoch: 23, loss: 0.698964
global_step: 4900, epoch: 23, loss: 0.727243
global_step: 4901, epoch: 23, loss: 0.588407
global_step: 4902, epoch: 23, loss: 0.489811
global_step: 4903, epoch: 23, loss: 0.597111
global_step: 4904, epoch: 23, loss: 0.590937
global_step: 4905, epoch: 23, loss: 0.556627
global_step: 4906, epoch: 23, loss: 0.492053
global_step: 4907, epoch: 23, loss: 0.634196
global_step: 4908, epoch: 23, loss: 0.608242
global_step: 4909, epoch: 23, loss: 0.634397
global_step: 4910, epoch: 23, loss: 0.677410
global_step: 4911, epoch: 23, loss: 0.935591
global_step: 4912, epoch: 23, loss: 0.967813
global_step: 4913, epoch: 23, loss: 0.652644
global_step: 4914, epoch: 23, loss: 0.558702
global_step: 4915, epoch: 23, loss: 0.569049
global_step: 4916, epoch: 23, loss: 0.553395
global_step: 4917, epoch: 23, loss: 0.661481
global_step: 4918, epoch: 23, loss: 0.601736
global_step: 4919, epoch: 23, loss: 0.559737
global_step: 4920, epoch: 23, loss: 0.173574
epoch: 23
train	acc: 0.8235	macro: p 0.8737, r 0.6887, f1: 0.7401	micro: p 0.8235, r 0.8235, f1 0.8235	weighted_f1:0.8203
dev	acc: 0.5347	macro: p 0.5531, r 0.3269, f1: 0.3205	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4931
test	acc: 0.5690	macro: p 0.4706, r 0.3314, f1: 0.3358	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5377
global_step: 4921, epoch: 24, loss: 0.583482
global_step: 4922, epoch: 24, loss: 0.703661
global_step: 4923, epoch: 24, loss: 0.612311
global_step: 4924, epoch: 24, loss: 0.623629
global_step: 4925, epoch: 24, loss: 0.565832
global_step: 4926, epoch: 24, loss: 0.496001
global_step: 4927, epoch: 24, loss: 0.524748
global_step: 4928, epoch: 24, loss: 0.528350
global_step: 4929, epoch: 24, loss: 0.563022
global_step: 4930, epoch: 24, loss: 0.593452
global_step: 4931, epoch: 24, loss: 0.509257
global_step: 4932, epoch: 24, loss: 0.633499
global_step: 4933, epoch: 24, loss: 0.711531
global_step: 4934, epoch: 24, loss: 0.672224
global_step: 4935, epoch: 24, loss: 0.624385
global_step: 4936, epoch: 24, loss: 0.590625
global_step: 4937, epoch: 24, loss: 0.522384
global_step: 4938, epoch: 24, loss: 0.518046
global_step: 4939, epoch: 24, loss: 0.494925
global_step: 4940, epoch: 24, loss: 0.615493
global_step: 4941, epoch: 24, loss: 0.631888
global_step: 4942, epoch: 24, loss: 0.595647
global_step: 4943, epoch: 24, loss: 0.643995
global_step: 4944, epoch: 24, loss: 0.713988
global_step: 4945, epoch: 24, loss: 0.676898
global_step: 4946, epoch: 24, loss: 0.637102
global_step: 4947, epoch: 24, loss: 0.595186
global_step: 4948, epoch: 24, loss: 0.646844
global_step: 4949, epoch: 24, loss: 0.696074
global_step: 4950, epoch: 24, loss: 0.557869
global_step: 4951, epoch: 24, loss: 0.555605
global_step: 4952, epoch: 24, loss: 0.598124
global_step: 4953, epoch: 24, loss: 0.736772
global_step: 4954, epoch: 24, loss: 0.733748
global_step: 4955, epoch: 24, loss: 0.551024
global_step: 4956, epoch: 24, loss: 0.646330
global_step: 4957, epoch: 24, loss: 0.618734
global_step: 4958, epoch: 24, loss: 0.607046
global_step: 4959, epoch: 24, loss: 0.686878
global_step: 4960, epoch: 24, loss: 0.293445
epoch: 24
train	acc: 0.8325	macro: p 0.8470, r 0.7386, f1: 0.7710	micro: p 0.8325, r 0.8325, f1 0.8325	weighted_f1:0.8343
dev	acc: 0.5293	macro: p 0.3896, r 0.3319, f1: 0.3184	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4876
test	acc: 0.5644	macro: p 0.4156, r 0.3499, f1: 0.3379	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5401
global_step: 4961, epoch: 25, loss: 0.679337
global_step: 4962, epoch: 25, loss: 0.578572
global_step: 4963, epoch: 25, loss: 0.549034
global_step: 4964, epoch: 25, loss: 0.620943
global_step: 4965, epoch: 25, loss: 0.603819
global_step: 4966, epoch: 25, loss: 0.603893
global_step: 4967, epoch: 25, loss: 0.589897
global_step: 4968, epoch: 25, loss: 0.577555
global_step: 4969, epoch: 25, loss: 0.596608
global_step: 4970, epoch: 25, loss: 0.496529
global_step: 4971, epoch: 25, loss: 0.559990
global_step: 4972, epoch: 25, loss: 0.611446
global_step: 4973, epoch: 25, loss: 0.643346
global_step: 4974, epoch: 25, loss: 0.661534
global_step: 4975, epoch: 25, loss: 0.557396
global_step: 4976, epoch: 25, loss: 0.691999
global_step: 4977, epoch: 25, loss: 0.568982
global_step: 4978, epoch: 25, loss: 0.681773
global_step: 4979, epoch: 25, loss: 0.557152
global_step: 4980, epoch: 25, loss: 0.522108
global_step: 4981, epoch: 25, loss: 0.648850
global_step: 4982, epoch: 25, loss: 0.567439
global_step: 4983, epoch: 25, loss: 0.605822
global_step: 4984, epoch: 25, loss: 0.591893
global_step: 4985, epoch: 25, loss: 0.592228
global_step: 4986, epoch: 25, loss: 0.605425
global_step: 4987, epoch: 25, loss: 0.548257
global_step: 4988, epoch: 25, loss: 0.548903
global_step: 4989, epoch: 25, loss: 0.493567
global_step: 4990, epoch: 25, loss: 0.542791
global_step: 4991, epoch: 25, loss: 0.499387
global_step: 4992, epoch: 25, loss: 0.639922
global_step: 4993, epoch: 25, loss: 0.628444
global_step: 4994, epoch: 25, loss: 0.604593
global_step: 4995, epoch: 25, loss: 0.589501
global_step: 4996, epoch: 25, loss: 0.609620
global_step: 4997, epoch: 25, loss: 0.633486
global_step: 4998, epoch: 25, loss: 0.699390
global_step: 4999, epoch: 25, loss: 0.660977
global_step: 5000, epoch: 25, loss: 0.313793
epoch: 25
train	acc: 0.8794	macro: p 0.8468, r 0.8219, f1: 0.8301	micro: p 0.8794, r 0.8794, f1 0.8794	weighted_f1:0.8798
dev	acc: 0.5257	macro: p 0.3799, r 0.3665, f1: 0.3661	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.5222
test	acc: 0.5471	macro: p 0.3656, r 0.3697, f1: 0.3645	micro: p 0.5471, r 0.5471, f1 0.5471	weighted_f1:0.5501
New best model!
global_step: 5001, epoch: 26, loss: 0.644839
global_step: 5002, epoch: 26, loss: 0.549882
global_step: 5003, epoch: 26, loss: 0.487642
global_step: 5004, epoch: 26, loss: 0.508088
global_step: 5005, epoch: 26, loss: 0.513781
global_step: 5006, epoch: 26, loss: 0.462767
global_step: 5007, epoch: 26, loss: 0.551297
global_step: 5008, epoch: 26, loss: 0.508970
global_step: 5009, epoch: 26, loss: 0.427708
global_step: 5010, epoch: 26, loss: 0.455054
global_step: 5011, epoch: 26, loss: 0.517897
global_step: 5012, epoch: 26, loss: 0.462273
global_step: 5013, epoch: 26, loss: 0.490269
global_step: 5014, epoch: 26, loss: 0.659526
global_step: 5015, epoch: 26, loss: 0.609710
global_step: 5016, epoch: 26, loss: 0.589821
global_step: 5017, epoch: 26, loss: 0.586884
global_step: 5018, epoch: 26, loss: 0.664118
global_step: 5019, epoch: 26, loss: 0.568995
global_step: 5020, epoch: 26, loss: 0.577126
global_step: 5021, epoch: 26, loss: 0.615223
global_step: 5022, epoch: 26, loss: 0.556553
global_step: 5023, epoch: 26, loss: 0.550113
global_step: 5024, epoch: 26, loss: 0.563922
global_step: 5025, epoch: 26, loss: 0.825192
global_step: 5026, epoch: 26, loss: 0.734582
global_step: 5027, epoch: 26, loss: 0.858727
global_step: 5028, epoch: 26, loss: 0.889407
global_step: 5029, epoch: 26, loss: 0.470820
global_step: 5030, epoch: 26, loss: 0.489605
global_step: 5031, epoch: 26, loss: 0.545139
global_step: 5032, epoch: 26, loss: 0.644977
global_step: 5033, epoch: 26, loss: 0.510172
global_step: 5034, epoch: 26, loss: 0.565093
global_step: 5035, epoch: 26, loss: 0.577996
global_step: 5036, epoch: 26, loss: 0.616750
global_step: 5037, epoch: 26, loss: 0.622971
global_step: 5038, epoch: 26, loss: 0.582007
global_step: 5039, epoch: 26, loss: 0.563391
global_step: 5040, epoch: 26, loss: 0.200227
epoch: 26
train	acc: 0.8887	macro: p 0.8935, r 0.7980, f1: 0.8270	micro: p 0.8887, r 0.8887, f1 0.8887	weighted_f1:0.8865
dev	acc: 0.5383	macro: p 0.4209, r 0.3551, f1: 0.3481	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5128
test	acc: 0.5808	macro: p 0.3933, r 0.3674, f1: 0.3621	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5625
global_step: 5041, epoch: 27, loss: 0.608455
global_step: 5042, epoch: 27, loss: 0.476998
global_step: 5043, epoch: 27, loss: 0.484027
global_step: 5044, epoch: 27, loss: 0.515268
global_step: 5045, epoch: 27, loss: 0.526478
global_step: 5046, epoch: 27, loss: 0.437971
global_step: 5047, epoch: 27, loss: 0.486975
global_step: 5048, epoch: 27, loss: 0.430147
global_step: 5049, epoch: 27, loss: 0.638008
global_step: 5050, epoch: 27, loss: 0.538756
global_step: 5051, epoch: 27, loss: 0.597542
global_step: 5052, epoch: 27, loss: 0.632470
global_step: 5053, epoch: 27, loss: 0.543521
global_step: 5054, epoch: 27, loss: 0.568042
global_step: 5055, epoch: 27, loss: 0.574940
global_step: 5056, epoch: 27, loss: 0.509172
global_step: 5057, epoch: 27, loss: 0.639857
global_step: 5058, epoch: 27, loss: 0.455948
global_step: 5059, epoch: 27, loss: 0.605751
global_step: 5060, epoch: 27, loss: 0.543245
global_step: 5061, epoch: 27, loss: 0.597062
global_step: 5062, epoch: 27, loss: 0.483256
global_step: 5063, epoch: 27, loss: 0.505472
global_step: 5064, epoch: 27, loss: 0.569165
global_step: 5065, epoch: 27, loss: 0.537706
global_step: 5066, epoch: 27, loss: 0.513898
global_step: 5067, epoch: 27, loss: 0.524424
global_step: 5068, epoch: 27, loss: 0.618136
global_step: 5069, epoch: 27, loss: 0.706138
global_step: 5070, epoch: 27, loss: 0.463195
global_step: 5071, epoch: 27, loss: 0.558335
global_step: 5072, epoch: 27, loss: 0.629055
global_step: 5073, epoch: 27, loss: 0.614635
global_step: 5074, epoch: 27, loss: 0.682748
global_step: 5075, epoch: 27, loss: 0.555059
global_step: 5076, epoch: 27, loss: 0.643525
global_step: 5077, epoch: 27, loss: 0.651163
global_step: 5078, epoch: 27, loss: 0.650479
global_step: 5079, epoch: 27, loss: 0.624805
global_step: 5080, epoch: 27, loss: 0.783024
epoch: 27
train	acc: 0.8450	macro: p 0.8697, r 0.7485, f1: 0.7811	micro: p 0.8450, r 0.8450, f1 0.8450	weighted_f1:0.8472
dev	acc: 0.5284	macro: p 0.5152, r 0.3387, f1: 0.3428	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.5048
test	acc: 0.5655	macro: p 0.4326, r 0.3545, f1: 0.3534	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5512
global_step: 5081, epoch: 28, loss: 0.654569
global_step: 5082, epoch: 28, loss: 0.652437
global_step: 5083, epoch: 28, loss: 0.502108
global_step: 5084, epoch: 28, loss: 0.541985
global_step: 5085, epoch: 28, loss: 0.492351
global_step: 5086, epoch: 28, loss: 0.524261
global_step: 5087, epoch: 28, loss: 0.553916
global_step: 5088, epoch: 28, loss: 0.512581
global_step: 5089, epoch: 28, loss: 0.432059
global_step: 5090, epoch: 28, loss: 0.472913
global_step: 5091, epoch: 28, loss: 0.471332
global_step: 5092, epoch: 28, loss: 0.515865
global_step: 5093, epoch: 28, loss: 0.525427
global_step: 5094, epoch: 28, loss: 0.456491
global_step: 5095, epoch: 28, loss: 0.493423
global_step: 5096, epoch: 28, loss: 0.438658
global_step: 5097, epoch: 28, loss: 0.397871
global_step: 5098, epoch: 28, loss: 0.573201
global_step: 5099, epoch: 28, loss: 0.555082
global_step: 5100, epoch: 28, loss: 0.584977
global_step: 5101, epoch: 28, loss: 0.599194
global_step: 5102, epoch: 28, loss: 0.573866
global_step: 5103, epoch: 28, loss: 0.564473
global_step: 5104, epoch: 28, loss: 0.476784
global_step: 5105, epoch: 28, loss: 0.499850
global_step: 5106, epoch: 28, loss: 0.517202
global_step: 5107, epoch: 28, loss: 0.535296
global_step: 5108, epoch: 28, loss: 0.460632
global_step: 5109, epoch: 28, loss: 0.599374
global_step: 5110, epoch: 28, loss: 0.602281
global_step: 5111, epoch: 28, loss: 0.578799
global_step: 5112, epoch: 28, loss: 0.454961
global_step: 5113, epoch: 28, loss: 0.674203
global_step: 5114, epoch: 28, loss: 0.513938
global_step: 5115, epoch: 28, loss: 0.591785
global_step: 5116, epoch: 28, loss: 0.504645
global_step: 5117, epoch: 28, loss: 0.542764
global_step: 5118, epoch: 28, loss: 0.512851
global_step: 5119, epoch: 28, loss: 0.514834
global_step: 5120, epoch: 28, loss: 0.375557
epoch: 28
train	acc: 0.8986	macro: p 0.9180, r 0.8153, f1: 0.8553	micro: p 0.8986, r 0.8986, f1 0.8986	weighted_f1:0.8970
dev	acc: 0.5365	macro: p 0.4130, r 0.3303, f1: 0.3301	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4952
test	acc: 0.5958	macro: p 0.4429, r 0.3598, f1: 0.3695	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5637
global_step: 5121, epoch: 29, loss: 0.546721
global_step: 5122, epoch: 29, loss: 0.469636
global_step: 5123, epoch: 29, loss: 0.531949
global_step: 5124, epoch: 29, loss: 0.499113
global_step: 5125, epoch: 29, loss: 0.440469
global_step: 5126, epoch: 29, loss: 0.398194
global_step: 5127, epoch: 29, loss: 0.437760
global_step: 5128, epoch: 29, loss: 0.460906
global_step: 5129, epoch: 29, loss: 0.448129
global_step: 5130, epoch: 29, loss: 0.565387
global_step: 5131, epoch: 29, loss: 0.595068
global_step: 5132, epoch: 29, loss: 0.565914
global_step: 5133, epoch: 29, loss: 0.513460
global_step: 5134, epoch: 29, loss: 0.467108
global_step: 5135, epoch: 29, loss: 0.499934
global_step: 5136, epoch: 29, loss: 0.450805
global_step: 5137, epoch: 29, loss: 0.533538
global_step: 5138, epoch: 29, loss: 0.439271
global_step: 5139, epoch: 29, loss: 0.464008
global_step: 5140, epoch: 29, loss: 0.452240
global_step: 5141, epoch: 29, loss: 0.539396
global_step: 5142, epoch: 29, loss: 0.578565
global_step: 5143, epoch: 29, loss: 0.487804
global_step: 5144, epoch: 29, loss: 0.516723
global_step: 5145, epoch: 29, loss: 0.483937
global_step: 5146, epoch: 29, loss: 0.505767
global_step: 5147, epoch: 29, loss: 0.475478
global_step: 5148, epoch: 29, loss: 0.441037
global_step: 5149, epoch: 29, loss: 0.518161
global_step: 5150, epoch: 29, loss: 0.496651
global_step: 5151, epoch: 29, loss: 0.508343
global_step: 5152, epoch: 29, loss: 0.613785
global_step: 5153, epoch: 29, loss: 0.709706
global_step: 5154, epoch: 29, loss: 0.568008
global_step: 5155, epoch: 29, loss: 0.547338
global_step: 5156, epoch: 29, loss: 0.598592
global_step: 5157, epoch: 29, loss: 0.616425
global_step: 5158, epoch: 29, loss: 0.582254
global_step: 5159, epoch: 29, loss: 0.537865
global_step: 5160, epoch: 29, loss: 0.844323
epoch: 29
train	acc: 0.8478	macro: p 0.8351, r 0.7917, f1: 0.7933	micro: p 0.8478, r 0.8478, f1 0.8478	weighted_f1:0.8578
dev	acc: 0.5221	macro: p 0.4179, r 0.3679, f1: 0.3622	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.5183
test	acc: 0.5234	macro: p 0.4114, r 0.3683, f1: 0.3667	micro: p 0.5234, r 0.5234, f1 0.5234	weighted_f1:0.5439
global_step: 5161, epoch: 30, loss: 0.771850
global_step: 5162, epoch: 30, loss: 0.651057
global_step: 5163, epoch: 30, loss: 0.479818
global_step: 5164, epoch: 30, loss: 0.404870
global_step: 5165, epoch: 30, loss: 0.481146
global_step: 5166, epoch: 30, loss: 0.494396
global_step: 5167, epoch: 30, loss: 0.534128
global_step: 5168, epoch: 30, loss: 0.547391
global_step: 5169, epoch: 30, loss: 0.522264
global_step: 5170, epoch: 30, loss: 0.438112
global_step: 5171, epoch: 30, loss: 0.463803
global_step: 5172, epoch: 30, loss: 0.482953
global_step: 5173, epoch: 30, loss: 0.467774
global_step: 5174, epoch: 30, loss: 0.467553
global_step: 5175, epoch: 30, loss: 0.446693
global_step: 5176, epoch: 30, loss: 0.519123
global_step: 5177, epoch: 30, loss: 0.414975
global_step: 5178, epoch: 30, loss: 0.616018
global_step: 5179, epoch: 30, loss: 0.630967
global_step: 5180, epoch: 30, loss: 0.523657
global_step: 5181, epoch: 30, loss: 0.455173
global_step: 5182, epoch: 30, loss: 0.493250
global_step: 5183, epoch: 30, loss: 0.459142
global_step: 5184, epoch: 30, loss: 0.482283
global_step: 5185, epoch: 30, loss: 0.394630
global_step: 5186, epoch: 30, loss: 0.453631
global_step: 5187, epoch: 30, loss: 0.406368
global_step: 5188, epoch: 30, loss: 0.496056
global_step: 5189, epoch: 30, loss: 0.521280
global_step: 5190, epoch: 30, loss: 0.554076
global_step: 5191, epoch: 30, loss: 0.484285
global_step: 5192, epoch: 30, loss: 0.505139
global_step: 5193, epoch: 30, loss: 0.461285
global_step: 5194, epoch: 30, loss: 0.492080
global_step: 5195, epoch: 30, loss: 0.559869
global_step: 5196, epoch: 30, loss: 0.463354
global_step: 5197, epoch: 30, loss: 0.541004
global_step: 5198, epoch: 30, loss: 0.592400
global_step: 5199, epoch: 30, loss: 0.616791
global_step: 5200, epoch: 30, loss: 0.457863
epoch: 30
train	acc: 0.9073	macro: p 0.9166, r 0.8558, f1: 0.8814	micro: p 0.9073, r 0.9073, f1 0.9073	weighted_f1:0.9073
dev	acc: 0.5374	macro: p 0.3956, r 0.3481, f1: 0.3493	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5146
test	acc: 0.5801	macro: p 0.4249, r 0.3668, f1: 0.3761	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5641
global_step: 5201, epoch: 31, loss: 0.445624
global_step: 5202, epoch: 31, loss: 0.424593
global_step: 5203, epoch: 31, loss: 0.378419
global_step: 5204, epoch: 31, loss: 0.349687
global_step: 5205, epoch: 31, loss: 0.573474
global_step: 5206, epoch: 31, loss: 0.398951
global_step: 5207, epoch: 31, loss: 0.445609
global_step: 5208, epoch: 31, loss: 0.450544
global_step: 5209, epoch: 31, loss: 0.450434
global_step: 5210, epoch: 31, loss: 0.490863
global_step: 5211, epoch: 31, loss: 0.428742
global_step: 5212, epoch: 31, loss: 0.436794
global_step: 5213, epoch: 31, loss: 0.509912
global_step: 5214, epoch: 31, loss: 0.555184
global_step: 5215, epoch: 31, loss: 0.407140
global_step: 5216, epoch: 31, loss: 0.517337
global_step: 5217, epoch: 31, loss: 0.586487
global_step: 5218, epoch: 31, loss: 0.494066
global_step: 5219, epoch: 31, loss: 0.471961
global_step: 5220, epoch: 31, loss: 0.507541
global_step: 5221, epoch: 31, loss: 0.502592
global_step: 5222, epoch: 31, loss: 0.653974
global_step: 5223, epoch: 31, loss: 0.518551
global_step: 5224, epoch: 31, loss: 0.504718
global_step: 5225, epoch: 31, loss: 0.538916
global_step: 5226, epoch: 31, loss: 0.456136
global_step: 5227, epoch: 31, loss: 0.428136
global_step: 5228, epoch: 31, loss: 0.437847
global_step: 5229, epoch: 31, loss: 0.418801
global_step: 5230, epoch: 31, loss: 0.538130
global_step: 5231, epoch: 31, loss: 0.500995
global_step: 5232, epoch: 31, loss: 0.459874
global_step: 5233, epoch: 31, loss: 0.448151
global_step: 5234, epoch: 31, loss: 0.510303
global_step: 5235, epoch: 31, loss: 0.550699
global_step: 5236, epoch: 31, loss: 0.458182
global_step: 5237, epoch: 31, loss: 0.451666
global_step: 5238, epoch: 31, loss: 0.586861
global_step: 5239, epoch: 31, loss: 0.573792
global_step: 5240, epoch: 31, loss: 1.745368
epoch: 31
train	acc: 0.8646	macro: p 0.8901, r 0.7232, f1: 0.7637	micro: p 0.8646, r 0.8646, f1 0.8646	weighted_f1:0.8620
dev	acc: 0.5437	macro: p 0.4854, r 0.3371, f1: 0.3353	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5170
test	acc: 0.5816	macro: p 0.4554, r 0.3439, f1: 0.3398	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5604
global_step: 5241, epoch: 32, loss: 0.556002
global_step: 5242, epoch: 32, loss: 0.470557
global_step: 5243, epoch: 32, loss: 0.458118
global_step: 5244, epoch: 32, loss: 0.497660
global_step: 5245, epoch: 32, loss: 0.400656
global_step: 5246, epoch: 32, loss: 0.385914
global_step: 5247, epoch: 32, loss: 0.453378
global_step: 5248, epoch: 32, loss: 0.425069
global_step: 5249, epoch: 32, loss: 0.413174
global_step: 5250, epoch: 32, loss: 0.411233
global_step: 5251, epoch: 32, loss: 0.386679
global_step: 5252, epoch: 32, loss: 0.440454
global_step: 5253, epoch: 32, loss: 0.454955
global_step: 5254, epoch: 32, loss: 0.522158
global_step: 5255, epoch: 32, loss: 0.616644
global_step: 5256, epoch: 32, loss: 0.445856
global_step: 5257, epoch: 32, loss: 0.611385
global_step: 5258, epoch: 32, loss: 0.494200
global_step: 5259, epoch: 32, loss: 0.469230
global_step: 5260, epoch: 32, loss: 0.454960
global_step: 5261, epoch: 32, loss: 0.427387
global_step: 5262, epoch: 32, loss: 0.442513
global_step: 5263, epoch: 32, loss: 0.408450
global_step: 5264, epoch: 32, loss: 0.486691
global_step: 5265, epoch: 32, loss: 0.373599
global_step: 5266, epoch: 32, loss: 0.438200
global_step: 5267, epoch: 32, loss: 0.418290
global_step: 5268, epoch: 32, loss: 0.524078
global_step: 5269, epoch: 32, loss: 0.511282
global_step: 5270, epoch: 32, loss: 0.423386
global_step: 5271, epoch: 32, loss: 0.435603
global_step: 5272, epoch: 32, loss: 0.435031
global_step: 5273, epoch: 32, loss: 0.526992
global_step: 5274, epoch: 32, loss: 0.437741
global_step: 5275, epoch: 32, loss: 0.454435
global_step: 5276, epoch: 32, loss: 0.415875
global_step: 5277, epoch: 32, loss: 0.447281
global_step: 5278, epoch: 32, loss: 0.509932
global_step: 5279, epoch: 32, loss: 0.472679
global_step: 5280, epoch: 32, loss: 0.207531
epoch: 32
train	acc: 0.8676	macro: p 0.9057, r 0.7646, f1: 0.8135	micro: p 0.8676, r 0.8676, f1 0.8676	weighted_f1:0.8605
dev	acc: 0.5528	macro: p 0.4474, r 0.3188, f1: 0.3242	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4965
test	acc: 0.6149	macro: p 0.4852, r 0.3410, f1: 0.3540	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5657
global_step: 5281, epoch: 33, loss: 0.636075
global_step: 5282, epoch: 33, loss: 0.552692
global_step: 5283, epoch: 33, loss: 0.476350
global_step: 5284, epoch: 33, loss: 0.436915
global_step: 5285, epoch: 33, loss: 0.404433
global_step: 5286, epoch: 33, loss: 0.341928
global_step: 5287, epoch: 33, loss: 0.485868
global_step: 5288, epoch: 33, loss: 0.408775
global_step: 5289, epoch: 33, loss: 0.478090
global_step: 5290, epoch: 33, loss: 0.541088
global_step: 5291, epoch: 33, loss: 0.513445
global_step: 5292, epoch: 33, loss: 0.453528
global_step: 5293, epoch: 33, loss: 0.465383
global_step: 5294, epoch: 33, loss: 0.465790
global_step: 5295, epoch: 33, loss: 0.492605
global_step: 5296, epoch: 33, loss: 0.470424
global_step: 5297, epoch: 33, loss: 0.399226
global_step: 5298, epoch: 33, loss: 0.394536
global_step: 5299, epoch: 33, loss: 0.375217
global_step: 5300, epoch: 33, loss: 0.350888
global_step: 5301, epoch: 33, loss: 0.579357
global_step: 5302, epoch: 33, loss: 0.404352
global_step: 5303, epoch: 33, loss: 0.471820
global_step: 5304, epoch: 33, loss: 0.479876
global_step: 5305, epoch: 33, loss: 0.511482
global_step: 5306, epoch: 33, loss: 0.444064
global_step: 5307, epoch: 33, loss: 0.478629
global_step: 5308, epoch: 33, loss: 0.439043
global_step: 5309, epoch: 33, loss: 0.436074
global_step: 5310, epoch: 33, loss: 0.508338
global_step: 5311, epoch: 33, loss: 0.549814
global_step: 5312, epoch: 33, loss: 0.479959
global_step: 5313, epoch: 33, loss: 0.573951
global_step: 5314, epoch: 33, loss: 0.447185
global_step: 5315, epoch: 33, loss: 0.315266
global_step: 5316, epoch: 33, loss: 0.450995
global_step: 5317, epoch: 33, loss: 0.449893
global_step: 5318, epoch: 33, loss: 0.370085
global_step: 5319, epoch: 33, loss: 0.429944
global_step: 5320, epoch: 33, loss: 0.450798
epoch: 33
train	acc: 0.8643	macro: p 0.9120, r 0.7823, f1: 0.8279	micro: p 0.8643, r 0.8643, f1 0.8643	weighted_f1:0.8660
dev	acc: 0.5041	macro: p 0.5167, r 0.3107, f1: 0.3005	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4705
test	acc: 0.5567	macro: p 0.4719, r 0.3305, f1: 0.3316	micro: p 0.5567, r 0.5567, f1 0.5567	weighted_f1:0.5314
global_step: 5321, epoch: 34, loss: 0.591393
global_step: 5322, epoch: 34, loss: 0.488807
global_step: 5323, epoch: 34, loss: 0.316509
global_step: 5324, epoch: 34, loss: 0.364507
global_step: 5325, epoch: 34, loss: 0.502478
global_step: 5326, epoch: 34, loss: 0.425444
global_step: 5327, epoch: 34, loss: 0.379013
global_step: 5328, epoch: 34, loss: 0.384669
global_step: 5329, epoch: 34, loss: 0.455070
global_step: 5330, epoch: 34, loss: 0.533553
global_step: 5331, epoch: 34, loss: 0.396198
global_step: 5332, epoch: 34, loss: 0.378854
global_step: 5333, epoch: 34, loss: 0.442850
global_step: 5334, epoch: 34, loss: 0.443509
global_step: 5335, epoch: 34, loss: 0.366086
global_step: 5336, epoch: 34, loss: 0.408703
global_step: 5337, epoch: 34, loss: 0.435498
global_step: 5338, epoch: 34, loss: 0.503170
global_step: 5339, epoch: 34, loss: 0.437398
global_step: 5340, epoch: 34, loss: 0.331547
global_step: 5341, epoch: 34, loss: 0.433375
global_step: 5342, epoch: 34, loss: 0.348859
global_step: 5343, epoch: 34, loss: 0.394898
global_step: 5344, epoch: 34, loss: 0.594177
global_step: 5345, epoch: 34, loss: 0.439792
global_step: 5346, epoch: 34, loss: 0.497280
global_step: 5347, epoch: 34, loss: 0.488373
global_step: 5348, epoch: 34, loss: 0.389790
global_step: 5349, epoch: 34, loss: 0.447173
global_step: 5350, epoch: 34, loss: 0.511043
global_step: 5351, epoch: 34, loss: 0.355529
global_step: 5352, epoch: 34, loss: 0.374051
global_step: 5353, epoch: 34, loss: 0.419295
global_step: 5354, epoch: 34, loss: 0.434527
global_step: 5355, epoch: 34, loss: 0.459483
global_step: 5356, epoch: 34, loss: 0.536034
global_step: 5357, epoch: 34, loss: 0.544148
global_step: 5358, epoch: 34, loss: 0.440110
global_step: 5359, epoch: 34, loss: 0.440715
global_step: 5360, epoch: 34, loss: 0.142653
epoch: 34
train	acc: 0.9281	macro: p 0.9323, r 0.8779, f1: 0.9018	micro: p 0.9281, r 0.9281, f1 0.9281	weighted_f1:0.9276
dev	acc: 0.5419	macro: p 0.3949, r 0.3414, f1: 0.3485	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5114
test	acc: 0.6061	macro: p 0.4171, r 0.3652, f1: 0.3791	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5806
global_step: 5361, epoch: 35, loss: 0.443521
global_step: 5362, epoch: 35, loss: 0.347535
global_step: 5363, epoch: 35, loss: 0.433140
global_step: 5364, epoch: 35, loss: 0.408971
global_step: 5365, epoch: 35, loss: 0.352766
global_step: 5366, epoch: 35, loss: 0.494636
global_step: 5367, epoch: 35, loss: 0.438503
global_step: 5368, epoch: 35, loss: 0.457211
global_step: 5369, epoch: 35, loss: 0.516683
global_step: 5370, epoch: 35, loss: 0.500813
global_step: 5371, epoch: 35, loss: 0.425819
global_step: 5372, epoch: 35, loss: 0.419965
global_step: 5373, epoch: 35, loss: 0.373702
global_step: 5374, epoch: 35, loss: 0.453813
global_step: 5375, epoch: 35, loss: 0.490669
global_step: 5376, epoch: 35, loss: 0.438480
global_step: 5377, epoch: 35, loss: 0.432786
global_step: 5378, epoch: 35, loss: 0.397803
global_step: 5379, epoch: 35, loss: 0.450378
global_step: 5380, epoch: 35, loss: 0.434454
global_step: 5381, epoch: 35, loss: 0.446797
global_step: 5382, epoch: 35, loss: 0.465362
global_step: 5383, epoch: 35, loss: 0.464888
global_step: 5384, epoch: 35, loss: 0.488292
global_step: 5385, epoch: 35, loss: 0.479366
global_step: 5386, epoch: 35, loss: 0.478556
global_step: 5387, epoch: 35, loss: 0.503383
global_step: 5388, epoch: 35, loss: 0.361452
global_step: 5389, epoch: 35, loss: 0.349488
global_step: 5390, epoch: 35, loss: 0.394188
global_step: 5391, epoch: 35, loss: 0.391739
global_step: 5392, epoch: 35, loss: 0.409097
global_step: 5393, epoch: 35, loss: 0.335725
global_step: 5394, epoch: 35, loss: 0.432428
global_step: 5395, epoch: 35, loss: 0.488608
global_step: 5396, epoch: 35, loss: 0.431348
global_step: 5397, epoch: 35, loss: 0.434908
global_step: 5398, epoch: 35, loss: 0.439778
global_step: 5399, epoch: 35, loss: 0.469580
global_step: 5400, epoch: 35, loss: 0.006855
epoch: 35
train	acc: 0.9255	macro: p 0.9406, r 0.8650, f1: 0.8966	micro: p 0.9255, r 0.9255, f1 0.9255	weighted_f1:0.9247
dev	acc: 0.5528	macro: p 0.4395, r 0.3470, f1: 0.3542	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5142
test	acc: 0.6157	macro: p 0.4561, r 0.3643, f1: 0.3749	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5821
global_step: 5401, epoch: 36, loss: 0.353152
global_step: 5402, epoch: 36, loss: 0.509029
global_step: 5403, epoch: 36, loss: 0.400969
global_step: 5404, epoch: 36, loss: 0.430194
global_step: 5405, epoch: 36, loss: 0.303207
global_step: 5406, epoch: 36, loss: 0.522162
global_step: 5407, epoch: 36, loss: 0.483241
global_step: 5408, epoch: 36, loss: 0.392114
global_step: 5409, epoch: 36, loss: 0.318436
global_step: 5410, epoch: 36, loss: 0.458832
global_step: 5411, epoch: 36, loss: 0.322185
global_step: 5412, epoch: 36, loss: 0.472206
global_step: 5413, epoch: 36, loss: 0.448105
global_step: 5414, epoch: 36, loss: 0.392603
global_step: 5415, epoch: 36, loss: 0.516670
global_step: 5416, epoch: 36, loss: 0.471871
global_step: 5417, epoch: 36, loss: 0.472767
global_step: 5418, epoch: 36, loss: 0.394397
global_step: 5419, epoch: 36, loss: 0.341705
global_step: 5420, epoch: 36, loss: 0.443396
global_step: 5421, epoch: 36, loss: 0.500090
global_step: 5422, epoch: 36, loss: 0.422911
global_step: 5423, epoch: 36, loss: 0.501513
global_step: 5424, epoch: 36, loss: 0.498775
global_step: 5425, epoch: 36, loss: 0.521773
global_step: 5426, epoch: 36, loss: 0.467411
global_step: 5427, epoch: 36, loss: 0.379499
global_step: 5428, epoch: 36, loss: 0.417475
global_step: 5429, epoch: 36, loss: 0.526044
global_step: 5430, epoch: 36, loss: 0.457680
global_step: 5431, epoch: 36, loss: 0.452252
global_step: 5432, epoch: 36, loss: 0.351504
global_step: 5433, epoch: 36, loss: 0.402029
global_step: 5434, epoch: 36, loss: 0.413140
global_step: 5435, epoch: 36, loss: 0.500809
global_step: 5436, epoch: 36, loss: 0.478288
global_step: 5437, epoch: 36, loss: 0.517181
global_step: 5438, epoch: 36, loss: 0.418992
global_step: 5439, epoch: 36, loss: 0.453118
global_step: 5440, epoch: 36, loss: 0.074394
epoch: 36
train	acc: 0.9210	macro: p 0.9327, r 0.8612, f1: 0.8929	micro: p 0.9210, r 0.9210, f1 0.9210	weighted_f1:0.9201
dev	acc: 0.5338	macro: p 0.3905, r 0.3184, f1: 0.3229	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4915
test	acc: 0.5973	macro: p 0.4491, r 0.3468, f1: 0.3660	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5609
global_step: 5441, epoch: 37, loss: 0.531274
global_step: 5442, epoch: 37, loss: 0.385169
global_step: 5443, epoch: 37, loss: 0.338591
global_step: 5444, epoch: 37, loss: 0.416546
global_step: 5445, epoch: 37, loss: 0.438921
global_step: 5446, epoch: 37, loss: 0.370092
global_step: 5447, epoch: 37, loss: 0.310011
global_step: 5448, epoch: 37, loss: 0.418267
global_step: 5449, epoch: 37, loss: 0.438052
global_step: 5450, epoch: 37, loss: 0.404528
global_step: 5451, epoch: 37, loss: 0.392958
global_step: 5452, epoch: 37, loss: 0.386333
global_step: 5453, epoch: 37, loss: 0.450041
global_step: 5454, epoch: 37, loss: 0.529762
global_step: 5455, epoch: 37, loss: 0.577441
global_step: 5456, epoch: 37, loss: 0.496721
global_step: 5457, epoch: 37, loss: 0.481232
global_step: 5458, epoch: 37, loss: 0.427269
global_step: 5459, epoch: 37, loss: 0.307149
global_step: 5460, epoch: 37, loss: 0.382335
global_step: 5461, epoch: 37, loss: 0.428268
global_step: 5462, epoch: 37, loss: 0.435614
global_step: 5463, epoch: 37, loss: 0.383226
global_step: 5464, epoch: 37, loss: 0.371231
global_step: 5465, epoch: 37, loss: 0.339534
global_step: 5466, epoch: 37, loss: 0.437209
global_step: 5467, epoch: 37, loss: 0.350723
global_step: 5468, epoch: 37, loss: 0.435578
global_step: 5469, epoch: 37, loss: 0.426024
global_step: 5470, epoch: 37, loss: 0.503018
global_step: 5471, epoch: 37, loss: 0.373812
global_step: 5472, epoch: 37, loss: 0.451250
global_step: 5473, epoch: 37, loss: 0.428440
global_step: 5474, epoch: 37, loss: 0.389630
global_step: 5475, epoch: 37, loss: 0.458410
global_step: 5476, epoch: 37, loss: 0.372108
global_step: 5477, epoch: 37, loss: 0.406001
global_step: 5478, epoch: 37, loss: 0.432581
global_step: 5479, epoch: 37, loss: 0.435038
global_step: 5480, epoch: 37, loss: 2.194824
epoch: 37
train	acc: 0.8876	macro: p 0.9083, r 0.8357, f1: 0.8592	micro: p 0.8876, r 0.8876, f1 0.8876	weighted_f1:0.8912
dev	acc: 0.5086	macro: p 0.4034, r 0.3338, f1: 0.3241	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4785
test	acc: 0.5540	macro: p 0.4135, r 0.3433, f1: 0.3303	micro: p 0.5540, r 0.5540, f1 0.5540	weighted_f1:0.5398
global_step: 5481, epoch: 38, loss: 0.530341
global_step: 5482, epoch: 38, loss: 0.425469
global_step: 5483, epoch: 38, loss: 0.381788
global_step: 5484, epoch: 38, loss: 0.396955
global_step: 5485, epoch: 38, loss: 0.384718
global_step: 5486, epoch: 38, loss: 0.483155
global_step: 5487, epoch: 38, loss: 0.474773
global_step: 5488, epoch: 38, loss: 0.381914
global_step: 5489, epoch: 38, loss: 0.335258
global_step: 5490, epoch: 38, loss: 0.424167
global_step: 5491, epoch: 38, loss: 0.423807
global_step: 5492, epoch: 38, loss: 0.422189
global_step: 5493, epoch: 38, loss: 0.376293
global_step: 5494, epoch: 38, loss: 0.359951
global_step: 5495, epoch: 38, loss: 0.458935
global_step: 5496, epoch: 38, loss: 0.444231
global_step: 5497, epoch: 38, loss: 0.377117
global_step: 5498, epoch: 38, loss: 0.413810
global_step: 5499, epoch: 38, loss: 0.391081
global_step: 5500, epoch: 38, loss: 0.450852
global_step: 5501, epoch: 38, loss: 0.317872
global_step: 5502, epoch: 38, loss: 0.314733
global_step: 5503, epoch: 38, loss: 0.365144
global_step: 5504, epoch: 38, loss: 0.452116
global_step: 5505, epoch: 38, loss: 0.488574
global_step: 5506, epoch: 38, loss: 0.396103
global_step: 5507, epoch: 38, loss: 0.406252
global_step: 5508, epoch: 38, loss: 0.357669
global_step: 5509, epoch: 38, loss: 0.357774
global_step: 5510, epoch: 38, loss: 0.429608
global_step: 5511, epoch: 38, loss: 0.356435
global_step: 5512, epoch: 38, loss: 0.372734
global_step: 5513, epoch: 38, loss: 0.365028
global_step: 5514, epoch: 38, loss: 0.338109
global_step: 5515, epoch: 38, loss: 0.360845
global_step: 5516, epoch: 38, loss: 0.553303
global_step: 5517, epoch: 38, loss: 0.351625
global_step: 5518, epoch: 38, loss: 0.400197
global_step: 5519, epoch: 38, loss: 0.474690
global_step: 5520, epoch: 38, loss: 0.086497
epoch: 38
train	acc: 0.9333	macro: p 0.9441, r 0.8907, f1: 0.9132	micro: p 0.9333, r 0.9333, f1 0.9333	weighted_f1:0.9333
dev	acc: 0.5573	macro: p 0.4036, r 0.3582, f1: 0.3559	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5232
test	acc: 0.5954	macro: p 0.4040, r 0.3633, f1: 0.3633	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5686
New best model!
global_step: 5521, epoch: 39, loss: 0.427103
global_step: 5522, epoch: 39, loss: 0.273660
global_step: 5523, epoch: 39, loss: 0.371916
global_step: 5524, epoch: 39, loss: 0.389528
global_step: 5525, epoch: 39, loss: 0.394682
global_step: 5526, epoch: 39, loss: 0.360388
global_step: 5527, epoch: 39, loss: 0.406251
global_step: 5528, epoch: 39, loss: 0.325104
global_step: 5529, epoch: 39, loss: 0.352133
global_step: 5530, epoch: 39, loss: 0.384602
global_step: 5531, epoch: 39, loss: 0.351031
global_step: 5532, epoch: 39, loss: 0.393979
global_step: 5533, epoch: 39, loss: 0.364898
global_step: 5534, epoch: 39, loss: 0.340816
global_step: 5535, epoch: 39, loss: 0.420722
global_step: 5536, epoch: 39, loss: 0.360329
global_step: 5537, epoch: 39, loss: 0.420090
global_step: 5538, epoch: 39, loss: 0.397923
global_step: 5539, epoch: 39, loss: 0.402955
global_step: 5540, epoch: 39, loss: 0.417096
global_step: 5541, epoch: 39, loss: 0.476429
global_step: 5542, epoch: 39, loss: 0.485345
global_step: 5543, epoch: 39, loss: 0.414165
global_step: 5544, epoch: 39, loss: 0.348642
global_step: 5545, epoch: 39, loss: 0.427039
global_step: 5546, epoch: 39, loss: 0.368271
global_step: 5547, epoch: 39, loss: 0.414880
global_step: 5548, epoch: 39, loss: 0.412379
global_step: 5549, epoch: 39, loss: 0.395239
global_step: 5550, epoch: 39, loss: 0.333332
global_step: 5551, epoch: 39, loss: 0.303742
global_step: 5552, epoch: 39, loss: 0.416295
global_step: 5553, epoch: 39, loss: 0.384744
global_step: 5554, epoch: 39, loss: 0.317238
global_step: 5555, epoch: 39, loss: 0.398786
global_step: 5556, epoch: 39, loss: 0.404610
global_step: 5557, epoch: 39, loss: 0.438285
global_step: 5558, epoch: 39, loss: 0.322955
global_step: 5559, epoch: 39, loss: 0.366294
global_step: 5560, epoch: 39, loss: 0.385492
epoch: 39
train	acc: 0.9324	macro: p 0.9319, r 0.8948, f1: 0.9112	micro: p 0.9324, r 0.9324, f1 0.9324	weighted_f1:0.9322
dev	acc: 0.5528	macro: p 0.4406, r 0.3631, f1: 0.3781	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5297
test	acc: 0.5939	macro: p 0.4405, r 0.3732, f1: 0.3903	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5761
New best model!
global_step: 5561, epoch: 40, loss: 0.446534
global_step: 5562, epoch: 40, loss: 0.400369
global_step: 5563, epoch: 40, loss: 0.330572
global_step: 5564, epoch: 40, loss: 0.373250
global_step: 5565, epoch: 40, loss: 0.445620
global_step: 5566, epoch: 40, loss: 0.426393
global_step: 5567, epoch: 40, loss: 0.327350
global_step: 5568, epoch: 40, loss: 0.418317
global_step: 5569, epoch: 40, loss: 0.377686
global_step: 5570, epoch: 40, loss: 0.382464
global_step: 5571, epoch: 40, loss: 0.340321
global_step: 5572, epoch: 40, loss: 0.339729
global_step: 5573, epoch: 40, loss: 0.476529
global_step: 5574, epoch: 40, loss: 0.383646
global_step: 5575, epoch: 40, loss: 0.338735
global_step: 5576, epoch: 40, loss: 0.305454
global_step: 5577, epoch: 40, loss: 0.378861
global_step: 5578, epoch: 40, loss: 0.409308
global_step: 5579, epoch: 40, loss: 0.390140
global_step: 5580, epoch: 40, loss: 0.350215
global_step: 5581, epoch: 40, loss: 0.336030
global_step: 5582, epoch: 40, loss: 0.356131
global_step: 5583, epoch: 40, loss: 0.465739
global_step: 5584, epoch: 40, loss: 0.437818
global_step: 5585, epoch: 40, loss: 0.427899
global_step: 5586, epoch: 40, loss: 0.356249
global_step: 5587, epoch: 40, loss: 0.344823
global_step: 5588, epoch: 40, loss: 0.397370
global_step: 5589, epoch: 40, loss: 0.461558
global_step: 5590, epoch: 40, loss: 0.482643
global_step: 5591, epoch: 40, loss: 0.342243
global_step: 5592, epoch: 40, loss: 0.385869
global_step: 5593, epoch: 40, loss: 0.348429
global_step: 5594, epoch: 40, loss: 0.420844
global_step: 5595, epoch: 40, loss: 0.549498
global_step: 5596, epoch: 40, loss: 0.437577
global_step: 5597, epoch: 40, loss: 0.416422
global_step: 5598, epoch: 40, loss: 0.378429
global_step: 5599, epoch: 40, loss: 0.385072
global_step: 5600, epoch: 40, loss: 0.177921
epoch: 40
train	acc: 0.9245	macro: p 0.9460, r 0.8760, f1: 0.9079	micro: p 0.9245, r 0.9245, f1 0.9245	weighted_f1:0.9239
dev	acc: 0.5500	macro: p 0.4240, r 0.3234, f1: 0.3368	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5026
test	acc: 0.6061	macro: p 0.4908, r 0.3365, f1: 0.3592	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5636
global_step: 5601, epoch: 41, loss: 0.335481
global_step: 5602, epoch: 41, loss: 0.448393
global_step: 5603, epoch: 41, loss: 0.351746
global_step: 5604, epoch: 41, loss: 0.376221
global_step: 5605, epoch: 41, loss: 0.294423
global_step: 5606, epoch: 41, loss: 0.352923
global_step: 5607, epoch: 41, loss: 0.339487
global_step: 5608, epoch: 41, loss: 0.447988
global_step: 5609, epoch: 41, loss: 0.352065
global_step: 5610, epoch: 41, loss: 0.334208
global_step: 5611, epoch: 41, loss: 0.367243
global_step: 5612, epoch: 41, loss: 0.335146
global_step: 5613, epoch: 41, loss: 0.345425
global_step: 5614, epoch: 41, loss: 0.378675
global_step: 5615, epoch: 41, loss: 0.408353
global_step: 5616, epoch: 41, loss: 0.417590
global_step: 5617, epoch: 41, loss: 0.323256
global_step: 5618, epoch: 41, loss: 0.488432
global_step: 5619, epoch: 41, loss: 0.377884
global_step: 5620, epoch: 41, loss: 0.425274
global_step: 5621, epoch: 41, loss: 0.299565
global_step: 5622, epoch: 41, loss: 0.288830
global_step: 5623, epoch: 41, loss: 0.349125
global_step: 5624, epoch: 41, loss: 0.379591
global_step: 5625, epoch: 41, loss: 0.383954
global_step: 5626, epoch: 41, loss: 0.377977
global_step: 5627, epoch: 41, loss: 0.432944
global_step: 5628, epoch: 41, loss: 0.435534
global_step: 5629, epoch: 41, loss: 0.386028
global_step: 5630, epoch: 41, loss: 0.464591
global_step: 5631, epoch: 41, loss: 0.326227
global_step: 5632, epoch: 41, loss: 0.311413
global_step: 5633, epoch: 41, loss: 0.475881
global_step: 5634, epoch: 41, loss: 0.385403
global_step: 5635, epoch: 41, loss: 0.384872
global_step: 5636, epoch: 41, loss: 0.379717
global_step: 5637, epoch: 41, loss: 0.370317
global_step: 5638, epoch: 41, loss: 0.376698
global_step: 5639, epoch: 41, loss: 0.320522
global_step: 5640, epoch: 41, loss: 0.257430
epoch: 41
train	acc: 0.9205	macro: p 0.9455, r 0.8541, f1: 0.8918	micro: p 0.9205, r 0.9205, f1 0.9205	weighted_f1:0.9194
dev	acc: 0.5437	macro: p 0.4597, r 0.3350, f1: 0.3374	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5014
test	acc: 0.5981	macro: p 0.4461, r 0.3390, f1: 0.3441	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5630
global_step: 5641, epoch: 42, loss: 0.373270
global_step: 5642, epoch: 42, loss: 0.493998
global_step: 5643, epoch: 42, loss: 0.355409
global_step: 5644, epoch: 42, loss: 0.337613
global_step: 5645, epoch: 42, loss: 0.312957
global_step: 5646, epoch: 42, loss: 0.393926
global_step: 5647, epoch: 42, loss: 0.348159
global_step: 5648, epoch: 42, loss: 0.368239
global_step: 5649, epoch: 42, loss: 0.389486
global_step: 5650, epoch: 42, loss: 0.416314
global_step: 5651, epoch: 42, loss: 0.389506
global_step: 5652, epoch: 42, loss: 0.360818
global_step: 5653, epoch: 42, loss: 0.340415
global_step: 5654, epoch: 42, loss: 0.368457
global_step: 5655, epoch: 42, loss: 0.364237
global_step: 5656, epoch: 42, loss: 0.441374
global_step: 5657, epoch: 42, loss: 0.421170
global_step: 5658, epoch: 42, loss: 0.352911
global_step: 5659, epoch: 42, loss: 0.361364
global_step: 5660, epoch: 42, loss: 0.347822
global_step: 5661, epoch: 42, loss: 0.300347
global_step: 5662, epoch: 42, loss: 0.406035
global_step: 5663, epoch: 42, loss: 0.343354
global_step: 5664, epoch: 42, loss: 0.369950
global_step: 5665, epoch: 42, loss: 0.318842
global_step: 5666, epoch: 42, loss: 0.424515
global_step: 5667, epoch: 42, loss: 0.455584
global_step: 5668, epoch: 42, loss: 0.386376
global_step: 5669, epoch: 42, loss: 0.362931
global_step: 5670, epoch: 42, loss: 0.343058
global_step: 5671, epoch: 42, loss: 0.352384
global_step: 5672, epoch: 42, loss: 0.411302
global_step: 5673, epoch: 42, loss: 0.463189
global_step: 5674, epoch: 42, loss: 0.370317
global_step: 5675, epoch: 42, loss: 0.394190
global_step: 5676, epoch: 42, loss: 0.308710
global_step: 5677, epoch: 42, loss: 0.347605
global_step: 5678, epoch: 42, loss: 0.362366
global_step: 5679, epoch: 42, loss: 0.419880
global_step: 5680, epoch: 42, loss: 0.378531
epoch: 42
train	acc: 0.9187	macro: p 0.9195, r 0.8811, f1: 0.8944	micro: p 0.9187, r 0.9187, f1 0.9187	weighted_f1:0.9193
dev	acc: 0.5167	macro: p 0.4097, r 0.3659, f1: 0.3614	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.5117
test	acc: 0.5341	macro: p 0.3719, r 0.3544, f1: 0.3481	micro: p 0.5341, r 0.5341, f1 0.5341	weighted_f1:0.5365
global_step: 5681, epoch: 43, loss: 0.670566
global_step: 5682, epoch: 43, loss: 0.442614
global_step: 5683, epoch: 43, loss: 0.368694
global_step: 5684, epoch: 43, loss: 0.296106
global_step: 5685, epoch: 43, loss: 0.387549
global_step: 5686, epoch: 43, loss: 0.308197
global_step: 5687, epoch: 43, loss: 0.303680
global_step: 5688, epoch: 43, loss: 0.335823
global_step: 5689, epoch: 43, loss: 0.355827
global_step: 5690, epoch: 43, loss: 0.327395
global_step: 5691, epoch: 43, loss: 0.336116
global_step: 5692, epoch: 43, loss: 0.321144
global_step: 5693, epoch: 43, loss: 0.502778
global_step: 5694, epoch: 43, loss: 0.281208
global_step: 5695, epoch: 43, loss: 0.358317
global_step: 5696, epoch: 43, loss: 0.355005
global_step: 5697, epoch: 43, loss: 0.353003
global_step: 5698, epoch: 43, loss: 0.340791
global_step: 5699, epoch: 43, loss: 0.350578
global_step: 5700, epoch: 43, loss: 0.339967
global_step: 5701, epoch: 43, loss: 0.289969
global_step: 5702, epoch: 43, loss: 0.299305
global_step: 5703, epoch: 43, loss: 0.345070
global_step: 5704, epoch: 43, loss: 0.410882
global_step: 5705, epoch: 43, loss: 0.410591
global_step: 5706, epoch: 43, loss: 0.343169
global_step: 5707, epoch: 43, loss: 0.359724
global_step: 5708, epoch: 43, loss: 0.344063
global_step: 5709, epoch: 43, loss: 0.388536
global_step: 5710, epoch: 43, loss: 0.308476
global_step: 5711, epoch: 43, loss: 0.338611
global_step: 5712, epoch: 43, loss: 0.361096
global_step: 5713, epoch: 43, loss: 0.368123
global_step: 5714, epoch: 43, loss: 0.392813
global_step: 5715, epoch: 43, loss: 0.471407
global_step: 5716, epoch: 43, loss: 0.271797
global_step: 5717, epoch: 43, loss: 0.360836
global_step: 5718, epoch: 43, loss: 0.430821
global_step: 5719, epoch: 43, loss: 0.406527
global_step: 5720, epoch: 43, loss: 0.272812
epoch: 43
train	acc: 0.9310	macro: p 0.9508, r 0.8816, f1: 0.9123	micro: p 0.9310, r 0.9310, f1 0.9310	weighted_f1:0.9304
dev	acc: 0.5518	macro: p 0.4667, r 0.3383, f1: 0.3465	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5082
test	acc: 0.6034	macro: p 0.4903, r 0.3472, f1: 0.3658	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5643
global_step: 5721, epoch: 44, loss: 0.280029
global_step: 5722, epoch: 44, loss: 0.400359
global_step: 5723, epoch: 44, loss: 0.303207
global_step: 5724, epoch: 44, loss: 0.448366
global_step: 5725, epoch: 44, loss: 0.373128
global_step: 5726, epoch: 44, loss: 0.382585
global_step: 5727, epoch: 44, loss: 0.304719
global_step: 5728, epoch: 44, loss: 0.298837
global_step: 5729, epoch: 44, loss: 0.410739
global_step: 5730, epoch: 44, loss: 0.342838
global_step: 5731, epoch: 44, loss: 0.324465
global_step: 5732, epoch: 44, loss: 0.377522
global_step: 5733, epoch: 44, loss: 0.419740
global_step: 5734, epoch: 44, loss: 0.323019
global_step: 5735, epoch: 44, loss: 0.416154
global_step: 5736, epoch: 44, loss: 0.297221
global_step: 5737, epoch: 44, loss: 0.329873
global_step: 5738, epoch: 44, loss: 0.340909
global_step: 5739, epoch: 44, loss: 0.328006
global_step: 5740, epoch: 44, loss: 0.426694
global_step: 5741, epoch: 44, loss: 0.397861
global_step: 5742, epoch: 44, loss: 0.344414
global_step: 5743, epoch: 44, loss: 0.356716
global_step: 5744, epoch: 44, loss: 0.401563
global_step: 5745, epoch: 44, loss: 0.383156
global_step: 5746, epoch: 44, loss: 0.351537
global_step: 5747, epoch: 44, loss: 0.318783
global_step: 5748, epoch: 44, loss: 0.356384
global_step: 5749, epoch: 44, loss: 0.362502
global_step: 5750, epoch: 44, loss: 0.445567
global_step: 5751, epoch: 44, loss: 0.422096
global_step: 5752, epoch: 44, loss: 0.423359
global_step: 5753, epoch: 44, loss: 0.393546
global_step: 5754, epoch: 44, loss: 0.321350
global_step: 5755, epoch: 44, loss: 0.409126
global_step: 5756, epoch: 44, loss: 0.300652
global_step: 5757, epoch: 44, loss: 0.469398
global_step: 5758, epoch: 44, loss: 0.362287
global_step: 5759, epoch: 44, loss: 0.420932
global_step: 5760, epoch: 44, loss: 0.103163
epoch: 44
train	acc: 0.9421	macro: p 0.9545, r 0.9060, f1: 0.9281	micro: p 0.9421, r 0.9421, f1 0.9421	weighted_f1:0.9419
dev	acc: 0.5573	macro: p 0.4296, r 0.3498, f1: 0.3626	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5209
test	acc: 0.6023	macro: p 0.4295, r 0.3596, f1: 0.3744	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5723
global_step: 5761, epoch: 45, loss: 0.382009
global_step: 5762, epoch: 45, loss: 0.297715
global_step: 5763, epoch: 45, loss: 0.364902
global_step: 5764, epoch: 45, loss: 0.273409
global_step: 5765, epoch: 45, loss: 0.330316
global_step: 5766, epoch: 45, loss: 0.331217
global_step: 5767, epoch: 45, loss: 0.383044
global_step: 5768, epoch: 45, loss: 0.229725
global_step: 5769, epoch: 45, loss: 0.341388
global_step: 5770, epoch: 45, loss: 0.420484
global_step: 5771, epoch: 45, loss: 0.373820
global_step: 5772, epoch: 45, loss: 0.283368
global_step: 5773, epoch: 45, loss: 0.391175
global_step: 5774, epoch: 45, loss: 0.284515
global_step: 5775, epoch: 45, loss: 0.333961
global_step: 5776, epoch: 45, loss: 0.337094
global_step: 5777, epoch: 45, loss: 0.412123
global_step: 5778, epoch: 45, loss: 0.426520
global_step: 5779, epoch: 45, loss: 0.370932
global_step: 5780, epoch: 45, loss: 0.374845
global_step: 5781, epoch: 45, loss: 0.334054
global_step: 5782, epoch: 45, loss: 0.405290
global_step: 5783, epoch: 45, loss: 0.303187
global_step: 5784, epoch: 45, loss: 0.412586
global_step: 5785, epoch: 45, loss: 0.405284
global_step: 5786, epoch: 45, loss: 0.308972
global_step: 5787, epoch: 45, loss: 0.256487
global_step: 5788, epoch: 45, loss: 0.375533
global_step: 5789, epoch: 45, loss: 0.441154
global_step: 5790, epoch: 45, loss: 0.355998
global_step: 5791, epoch: 45, loss: 0.354340
global_step: 5792, epoch: 45, loss: 0.279234
global_step: 5793, epoch: 45, loss: 0.287049
global_step: 5794, epoch: 45, loss: 0.370260
global_step: 5795, epoch: 45, loss: 0.243763
global_step: 5796, epoch: 45, loss: 0.326675
global_step: 5797, epoch: 45, loss: 0.354653
global_step: 5798, epoch: 45, loss: 0.387979
global_step: 5799, epoch: 45, loss: 0.346325
global_step: 5800, epoch: 45, loss: 0.720182
epoch: 45
train	acc: 0.9208	macro: p 0.9373, r 0.8488, f1: 0.8821	micro: p 0.9208, r 0.9208, f1 0.9208	weighted_f1:0.9203
dev	acc: 0.5437	macro: p 0.4777, r 0.3344, f1: 0.3398	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5096
test	acc: 0.5939	macro: p 0.4424, r 0.3470, f1: 0.3567	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5673
global_step: 5801, epoch: 46, loss: 0.511262
global_step: 5802, epoch: 46, loss: 0.401605
global_step: 5803, epoch: 46, loss: 0.377537
global_step: 5804, epoch: 46, loss: 0.361584
global_step: 5805, epoch: 46, loss: 0.290698
global_step: 5806, epoch: 46, loss: 0.353658
global_step: 5807, epoch: 46, loss: 0.268119
global_step: 5808, epoch: 46, loss: 0.355879
global_step: 5809, epoch: 46, loss: 0.304953
global_step: 5810, epoch: 46, loss: 0.319493
global_step: 5811, epoch: 46, loss: 0.393786
global_step: 5812, epoch: 46, loss: 0.369075
global_step: 5813, epoch: 46, loss: 0.360328
global_step: 5814, epoch: 46, loss: 0.264001
global_step: 5815, epoch: 46, loss: 0.380563
global_step: 5816, epoch: 46, loss: 0.358191
global_step: 5817, epoch: 46, loss: 0.254885
global_step: 5818, epoch: 46, loss: 0.314936
global_step: 5819, epoch: 46, loss: 0.231256
global_step: 5820, epoch: 46, loss: 0.308785
global_step: 5821, epoch: 46, loss: 0.412261
global_step: 5822, epoch: 46, loss: 0.361096
global_step: 5823, epoch: 46, loss: 0.291969
global_step: 5824, epoch: 46, loss: 0.389290
global_step: 5825, epoch: 46, loss: 0.333920
global_step: 5826, epoch: 46, loss: 0.236444
global_step: 5827, epoch: 46, loss: 0.347706
global_step: 5828, epoch: 46, loss: 0.442290
global_step: 5829, epoch: 46, loss: 0.411597
global_step: 5830, epoch: 46, loss: 0.396611
global_step: 5831, epoch: 46, loss: 0.309106
global_step: 5832, epoch: 46, loss: 0.337219
global_step: 5833, epoch: 46, loss: 0.404947
global_step: 5834, epoch: 46, loss: 0.300642
global_step: 5835, epoch: 46, loss: 0.391465
global_step: 5836, epoch: 46, loss: 0.336518
global_step: 5837, epoch: 46, loss: 0.317463
global_step: 5838, epoch: 46, loss: 0.307656
global_step: 5839, epoch: 46, loss: 0.359232
global_step: 5840, epoch: 46, loss: 0.521666
epoch: 46
train	acc: 0.9445	macro: p 0.9487, r 0.9203, f1: 0.9334	micro: p 0.9445, r 0.9445, f1 0.9445	weighted_f1:0.9445
dev	acc: 0.5419	macro: p 0.4028, r 0.3588, f1: 0.3617	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5215
test	acc: 0.5828	macro: p 0.4067, r 0.3674, f1: 0.3766	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5677
global_step: 5841, epoch: 47, loss: 0.431810
global_step: 5842, epoch: 47, loss: 0.340866
global_step: 5843, epoch: 47, loss: 0.301980
global_step: 5844, epoch: 47, loss: 0.350217
global_step: 5845, epoch: 47, loss: 0.333132
global_step: 5846, epoch: 47, loss: 0.298743
global_step: 5847, epoch: 47, loss: 0.435366
global_step: 5848, epoch: 47, loss: 0.409750
global_step: 5849, epoch: 47, loss: 0.269411
global_step: 5850, epoch: 47, loss: 0.284915
global_step: 5851, epoch: 47, loss: 0.417510
global_step: 5852, epoch: 47, loss: 0.360511
global_step: 5853, epoch: 47, loss: 0.336263
global_step: 5854, epoch: 47, loss: 0.298969
global_step: 5855, epoch: 47, loss: 0.311021
global_step: 5856, epoch: 47, loss: 0.226783
global_step: 5857, epoch: 47, loss: 0.372826
global_step: 5858, epoch: 47, loss: 0.330435
global_step: 5859, epoch: 47, loss: 0.355899
global_step: 5860, epoch: 47, loss: 0.350291
global_step: 5861, epoch: 47, loss: 0.363039
global_step: 5862, epoch: 47, loss: 0.383959
global_step: 5863, epoch: 47, loss: 0.350718
global_step: 5864, epoch: 47, loss: 0.254389
global_step: 5865, epoch: 47, loss: 0.302947
global_step: 5866, epoch: 47, loss: 0.284336
global_step: 5867, epoch: 47, loss: 0.359173
global_step: 5868, epoch: 47, loss: 0.301906
global_step: 5869, epoch: 47, loss: 0.371298
global_step: 5870, epoch: 47, loss: 0.305278
global_step: 5871, epoch: 47, loss: 0.336251
global_step: 5872, epoch: 47, loss: 0.320349
global_step: 5873, epoch: 47, loss: 0.331720
global_step: 5874, epoch: 47, loss: 0.352964
global_step: 5875, epoch: 47, loss: 0.415718
global_step: 5876, epoch: 47, loss: 0.304060
global_step: 5877, epoch: 47, loss: 0.382927
global_step: 5878, epoch: 47, loss: 0.387776
global_step: 5879, epoch: 47, loss: 0.373671
global_step: 5880, epoch: 47, loss: 0.210485
epoch: 47
train	acc: 0.9362	macro: p 0.9581, r 0.8889, f1: 0.9197	micro: p 0.9362, r 0.9362, f1 0.9362	weighted_f1:0.9355
dev	acc: 0.5500	macro: p 0.4695, r 0.3253, f1: 0.3360	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4968
test	acc: 0.6000	macro: p 0.4339, r 0.3297, f1: 0.3405	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5532
global_step: 5881, epoch: 48, loss: 0.405016
global_step: 5882, epoch: 48, loss: 0.364474
global_step: 5883, epoch: 48, loss: 0.275902
global_step: 5884, epoch: 48, loss: 0.432179
global_step: 5885, epoch: 48, loss: 0.349259
global_step: 5886, epoch: 48, loss: 0.294417
global_step: 5887, epoch: 48, loss: 0.333308
global_step: 5888, epoch: 48, loss: 0.242556
global_step: 5889, epoch: 48, loss: 0.338797
global_step: 5890, epoch: 48, loss: 0.273655
global_step: 5891, epoch: 48, loss: 0.309677
global_step: 5892, epoch: 48, loss: 0.231978
global_step: 5893, epoch: 48, loss: 0.379805
global_step: 5894, epoch: 48, loss: 0.288364
global_step: 5895, epoch: 48, loss: 0.373086
global_step: 5896, epoch: 48, loss: 0.323643
global_step: 5897, epoch: 48, loss: 0.308039
global_step: 5898, epoch: 48, loss: 0.414467
global_step: 5899, epoch: 48, loss: 0.296096
global_step: 5900, epoch: 48, loss: 0.379409
global_step: 5901, epoch: 48, loss: 0.309675
global_step: 5902, epoch: 48, loss: 0.375093
global_step: 5903, epoch: 48, loss: 0.326384
global_step: 5904, epoch: 48, loss: 0.346095
global_step: 5905, epoch: 48, loss: 0.329730
global_step: 5906, epoch: 48, loss: 0.383922
global_step: 5907, epoch: 48, loss: 0.419614
global_step: 5908, epoch: 48, loss: 0.406395
global_step: 5909, epoch: 48, loss: 0.345714
global_step: 5910, epoch: 48, loss: 0.335626
global_step: 5911, epoch: 48, loss: 0.366969
global_step: 5912, epoch: 48, loss: 0.378666
global_step: 5913, epoch: 48, loss: 0.349767
global_step: 5914, epoch: 48, loss: 0.316005
global_step: 5915, epoch: 48, loss: 0.305128
global_step: 5916, epoch: 48, loss: 0.322721
global_step: 5917, epoch: 48, loss: 0.382037
global_step: 5918, epoch: 48, loss: 0.314369
global_step: 5919, epoch: 48, loss: 0.343702
global_step: 5920, epoch: 48, loss: 0.151589
epoch: 48
train	acc: 0.9445	macro: p 0.9546, r 0.9094, f1: 0.9299	micro: p 0.9445, r 0.9445, f1 0.9445	weighted_f1:0.9443
dev	acc: 0.5491	macro: p 0.4165, r 0.3353, f1: 0.3462	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5116
test	acc: 0.6019	macro: p 0.4463, r 0.3500, f1: 0.3656	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5707
global_step: 5921, epoch: 49, loss: 0.314026
global_step: 5922, epoch: 49, loss: 0.319533
global_step: 5923, epoch: 49, loss: 0.347960
global_step: 5924, epoch: 49, loss: 0.402861
global_step: 5925, epoch: 49, loss: 0.430726
global_step: 5926, epoch: 49, loss: 0.330022
global_step: 5927, epoch: 49, loss: 0.276072
global_step: 5928, epoch: 49, loss: 0.292879
global_step: 5929, epoch: 49, loss: 0.321728
global_step: 5930, epoch: 49, loss: 0.279547
global_step: 5931, epoch: 49, loss: 0.293328
global_step: 5932, epoch: 49, loss: 0.230282
global_step: 5933, epoch: 49, loss: 0.305485
global_step: 5934, epoch: 49, loss: 0.339870
global_step: 5935, epoch: 49, loss: 0.391295
global_step: 5936, epoch: 49, loss: 0.310188
global_step: 5937, epoch: 49, loss: 0.308532
global_step: 5938, epoch: 49, loss: 0.355281
global_step: 5939, epoch: 49, loss: 0.316385
global_step: 5940, epoch: 49, loss: 0.295236
global_step: 5941, epoch: 49, loss: 0.359080
global_step: 5942, epoch: 49, loss: 0.323146
global_step: 5943, epoch: 49, loss: 0.266920
global_step: 5944, epoch: 49, loss: 0.362341
global_step: 5945, epoch: 49, loss: 0.336468
global_step: 5946, epoch: 49, loss: 0.333627
global_step: 5947, epoch: 49, loss: 0.312683
global_step: 5948, epoch: 49, loss: 0.414980
global_step: 5949, epoch: 49, loss: 0.396528
global_step: 5950, epoch: 49, loss: 0.317708
global_step: 5951, epoch: 49, loss: 0.360508
global_step: 5952, epoch: 49, loss: 0.368261
global_step: 5953, epoch: 49, loss: 0.294364
global_step: 5954, epoch: 49, loss: 0.433725
global_step: 5955, epoch: 49, loss: 0.308053
global_step: 5956, epoch: 49, loss: 0.362919
global_step: 5957, epoch: 49, loss: 0.294730
global_step: 5958, epoch: 49, loss: 0.295625
global_step: 5959, epoch: 49, loss: 0.272004
global_step: 5960, epoch: 49, loss: 0.723141
epoch: 49
train	acc: 0.9343	macro: p 0.9584, r 0.8864, f1: 0.9190	micro: p 0.9343, r 0.9343, f1 0.9343	weighted_f1:0.9337
dev	acc: 0.5437	macro: p 0.4783, r 0.3244, f1: 0.3386	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4923
test	acc: 0.5969	macro: p 0.4321, r 0.3226, f1: 0.3352	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5495
global_step: 5961, epoch: 50, loss: 0.461812
global_step: 5962, epoch: 50, loss: 0.287288
global_step: 5963, epoch: 50, loss: 0.282218
global_step: 5964, epoch: 50, loss: 0.386965
global_step: 5965, epoch: 50, loss: 0.323798
global_step: 5966, epoch: 50, loss: 0.282134
global_step: 5967, epoch: 50, loss: 0.335498
global_step: 5968, epoch: 50, loss: 0.357358
global_step: 5969, epoch: 50, loss: 0.318090
global_step: 5970, epoch: 50, loss: 0.277995
global_step: 5971, epoch: 50, loss: 0.365992
global_step: 5972, epoch: 50, loss: 0.379942
global_step: 5973, epoch: 50, loss: 0.336218
global_step: 5974, epoch: 50, loss: 0.338174
global_step: 5975, epoch: 50, loss: 0.286222
global_step: 5976, epoch: 50, loss: 0.342794
global_step: 5977, epoch: 50, loss: 0.339145
global_step: 5978, epoch: 50, loss: 0.198413
global_step: 5979, epoch: 50, loss: 0.391946
global_step: 5980, epoch: 50, loss: 0.385422
global_step: 5981, epoch: 50, loss: 0.365179
global_step: 5982, epoch: 50, loss: 0.268527
global_step: 5983, epoch: 50, loss: 0.347794
global_step: 5984, epoch: 50, loss: 0.399169
global_step: 5985, epoch: 50, loss: 0.361381
global_step: 5986, epoch: 50, loss: 0.325993
global_step: 5987, epoch: 50, loss: 0.194692
global_step: 5988, epoch: 50, loss: 0.313899
global_step: 5989, epoch: 50, loss: 0.352890
global_step: 5990, epoch: 50, loss: 0.304641
global_step: 5991, epoch: 50, loss: 0.406902
global_step: 5992, epoch: 50, loss: 0.320123
global_step: 5993, epoch: 50, loss: 0.261308
global_step: 5994, epoch: 50, loss: 0.343025
global_step: 5995, epoch: 50, loss: 0.257249
global_step: 5996, epoch: 50, loss: 0.272845
global_step: 5997, epoch: 50, loss: 0.279611
global_step: 5998, epoch: 50, loss: 0.349587
global_step: 5999, epoch: 50, loss: 0.337951
global_step: 6000, epoch: 50, loss: 0.118176
epoch: 50
train	acc: 0.9528	macro: p 0.9620, r 0.9252, f1: 0.9425	micro: p 0.9528, r 0.9528, f1 0.9528	weighted_f1:0.9527
dev	acc: 0.5482	macro: p 0.4061, r 0.3397, f1: 0.3507	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5129
test	acc: 0.5943	macro: p 0.4291, r 0.3534, f1: 0.3719	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5670
BEST MODEL epoch: 39
train	acc: 0.9324 macro_p: 0.9319 macro_r: 0.8948 macro_f1: 0.9112 micro_p: 0.9324 micro_r: 0.9324 micro_f1: 0.9324 weighted_f1: 0.9322
dev	acc: 0.5528 macro_p: 0.4406 macro_r: 0.3631 macro_f1: 0.3781 micro_p: 0.5528 micro_r: 0.5528 micro_f1: 0.5528 weighted_f1: 0.5297
test	acc: 0.5939 macro_p: 0.4405 macro_r: 0.3732 macro_f1: 0.3903 micro_p: 0.5939 micro_r: 0.5939 micro_f1: 0.5939 weighted_f1: 0.5761
==========ROUND 4==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 6001, epoch: 1, loss: 1.952567
global_step: 6002, epoch: 1, loss: 1.856709
global_step: 6003, epoch: 1, loss: 1.772272
global_step: 6004, epoch: 1, loss: 1.678595
global_step: 6005, epoch: 1, loss: 1.569631
global_step: 6006, epoch: 1, loss: 1.577139
global_step: 6007, epoch: 1, loss: 1.521476
global_step: 6008, epoch: 1, loss: 1.468249
global_step: 6009, epoch: 1, loss: 1.504638
global_step: 6010, epoch: 1, loss: 1.521722
global_step: 6011, epoch: 1, loss: 1.548741
global_step: 6012, epoch: 1, loss: 1.511779
global_step: 6013, epoch: 1, loss: 1.501974
global_step: 6014, epoch: 1, loss: 1.393254
global_step: 6015, epoch: 1, loss: 1.547987
global_step: 6016, epoch: 1, loss: 1.586343
global_step: 6017, epoch: 1, loss: 1.479938
global_step: 6018, epoch: 1, loss: 1.505992
global_step: 6019, epoch: 1, loss: 1.394263
global_step: 6020, epoch: 1, loss: 1.488150
global_step: 6021, epoch: 1, loss: 1.362850
global_step: 6022, epoch: 1, loss: 1.489355
global_step: 6023, epoch: 1, loss: 1.413035
global_step: 6024, epoch: 1, loss: 1.361038
global_step: 6025, epoch: 1, loss: 1.400247
global_step: 6026, epoch: 1, loss: 1.415413
global_step: 6027, epoch: 1, loss: 1.380996
global_step: 6028, epoch: 1, loss: 1.401713
global_step: 6029, epoch: 1, loss: 1.356569
global_step: 6030, epoch: 1, loss: 1.637905
global_step: 6031, epoch: 1, loss: 1.509420
global_step: 6032, epoch: 1, loss: 1.391314
global_step: 6033, epoch: 1, loss: 1.269564
global_step: 6034, epoch: 1, loss: 1.414509
global_step: 6035, epoch: 1, loss: 1.427024
global_step: 6036, epoch: 1, loss: 1.385597
global_step: 6037, epoch: 1, loss: 1.275111
global_step: 6038, epoch: 1, loss: 1.297367
global_step: 6039, epoch: 1, loss: 1.357913
global_step: 6040, epoch: 1, loss: 1.164421
epoch: 1
train	acc: 0.5080	macro: p 0.1227, r 0.2225, f1: 0.1553	micro: p 0.5080, r 0.5080, f1 0.5080	weighted_f1:0.3912
dev	acc: 0.4716	macro: p 0.1161, r 0.2093, f1: 0.1484	micro: p 0.4716, r 0.4716, f1 0.4716	weighted_f1:0.3496
test	acc: 0.5318	macro: p 0.1310, r 0.2224, f1: 0.1630	micro: p 0.5318, r 0.5318, f1 0.5318	weighted_f1:0.4183
New best model!
global_step: 6041, epoch: 2, loss: 1.375679
global_step: 6042, epoch: 2, loss: 1.302786
global_step: 6043, epoch: 2, loss: 1.433849
global_step: 6044, epoch: 2, loss: 1.369222
global_step: 6045, epoch: 2, loss: 1.451138
global_step: 6046, epoch: 2, loss: 1.406579
global_step: 6047, epoch: 2, loss: 1.335461
global_step: 6048, epoch: 2, loss: 1.396773
global_step: 6049, epoch: 2, loss: 1.231175
global_step: 6050, epoch: 2, loss: 1.247660
global_step: 6051, epoch: 2, loss: 1.325991
global_step: 6052, epoch: 2, loss: 1.349133
global_step: 6053, epoch: 2, loss: 1.359750
global_step: 6054, epoch: 2, loss: 1.286319
global_step: 6055, epoch: 2, loss: 1.294328
global_step: 6056, epoch: 2, loss: 1.418676
global_step: 6057, epoch: 2, loss: 1.393168
global_step: 6058, epoch: 2, loss: 1.294213
global_step: 6059, epoch: 2, loss: 1.330956
global_step: 6060, epoch: 2, loss: 1.298360
global_step: 6061, epoch: 2, loss: 1.378680
global_step: 6062, epoch: 2, loss: 1.285828
global_step: 6063, epoch: 2, loss: 1.271200
global_step: 6064, epoch: 2, loss: 1.190764
global_step: 6065, epoch: 2, loss: 1.353190
global_step: 6066, epoch: 2, loss: 1.297170
global_step: 6067, epoch: 2, loss: 1.358271
global_step: 6068, epoch: 2, loss: 1.307102
global_step: 6069, epoch: 2, loss: 1.424509
global_step: 6070, epoch: 2, loss: 1.254010
global_step: 6071, epoch: 2, loss: 1.306639
global_step: 6072, epoch: 2, loss: 1.265591
global_step: 6073, epoch: 2, loss: 1.295056
global_step: 6074, epoch: 2, loss: 1.318996
global_step: 6075, epoch: 2, loss: 1.325373
global_step: 6076, epoch: 2, loss: 1.373471
global_step: 6077, epoch: 2, loss: 1.317174
global_step: 6078, epoch: 2, loss: 1.320809
global_step: 6079, epoch: 2, loss: 1.361152
global_step: 6080, epoch: 2, loss: 0.878181
epoch: 2
train	acc: 0.5306	macro: p 0.3522, r 0.2369, f1: 0.1883	micro: p 0.5306, r 0.5306, f1 0.5306	weighted_f1:0.4297
dev	acc: 0.4932	macro: p 0.3362, r 0.2274, f1: 0.1834	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.3855
test	acc: 0.5571	macro: p 0.3628, r 0.2428, f1: 0.2052	micro: p 0.5571, r 0.5571, f1 0.5571	weighted_f1:0.4628
New best model!
global_step: 6081, epoch: 3, loss: 1.332554
global_step: 6082, epoch: 3, loss: 1.446819
global_step: 6083, epoch: 3, loss: 1.503239
global_step: 6084, epoch: 3, loss: 1.335445
global_step: 6085, epoch: 3, loss: 1.343196
global_step: 6086, epoch: 3, loss: 1.239612
global_step: 6087, epoch: 3, loss: 1.222918
global_step: 6088, epoch: 3, loss: 1.246149
global_step: 6089, epoch: 3, loss: 1.164724
global_step: 6090, epoch: 3, loss: 1.280882
global_step: 6091, epoch: 3, loss: 1.308698
global_step: 6092, epoch: 3, loss: 1.231418
global_step: 6093, epoch: 3, loss: 1.335519
global_step: 6094, epoch: 3, loss: 1.342406
global_step: 6095, epoch: 3, loss: 1.211032
global_step: 6096, epoch: 3, loss: 1.305744
global_step: 6097, epoch: 3, loss: 1.345881
global_step: 6098, epoch: 3, loss: 1.202303
global_step: 6099, epoch: 3, loss: 1.248806
global_step: 6100, epoch: 3, loss: 1.271859
global_step: 6101, epoch: 3, loss: 1.388835
global_step: 6102, epoch: 3, loss: 1.209576
global_step: 6103, epoch: 3, loss: 1.345931
global_step: 6104, epoch: 3, loss: 1.328350
global_step: 6105, epoch: 3, loss: 1.343911
global_step: 6106, epoch: 3, loss: 1.409560
global_step: 6107, epoch: 3, loss: 1.236156
global_step: 6108, epoch: 3, loss: 1.332317
global_step: 6109, epoch: 3, loss: 1.207084
global_step: 6110, epoch: 3, loss: 1.196027
global_step: 6111, epoch: 3, loss: 1.330423
global_step: 6112, epoch: 3, loss: 1.278490
global_step: 6113, epoch: 3, loss: 1.353823
global_step: 6114, epoch: 3, loss: 1.279112
global_step: 6115, epoch: 3, loss: 1.174436
global_step: 6116, epoch: 3, loss: 1.200655
global_step: 6117, epoch: 3, loss: 1.223341
global_step: 6118, epoch: 3, loss: 1.259257
global_step: 6119, epoch: 3, loss: 1.218882
global_step: 6120, epoch: 3, loss: 0.740625
epoch: 3
train	acc: 0.5735	macro: p 0.3291, r 0.2504, f1: 0.2263	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.4818
dev	acc: 0.5221	macro: p 0.3287, r 0.2535, f1: 0.2138	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4173
test	acc: 0.5720	macro: p 0.3320, r 0.2540, f1: 0.2247	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.4773
New best model!
global_step: 6121, epoch: 4, loss: 1.511897
global_step: 6122, epoch: 4, loss: 1.365563
global_step: 6123, epoch: 4, loss: 1.264426
global_step: 6124, epoch: 4, loss: 1.199191
global_step: 6125, epoch: 4, loss: 1.191075
global_step: 6126, epoch: 4, loss: 1.201938
global_step: 6127, epoch: 4, loss: 1.231795
global_step: 6128, epoch: 4, loss: 1.311797
global_step: 6129, epoch: 4, loss: 1.249373
global_step: 6130, epoch: 4, loss: 1.273562
global_step: 6131, epoch: 4, loss: 1.221822
global_step: 6132, epoch: 4, loss: 1.193018
global_step: 6133, epoch: 4, loss: 1.235777
global_step: 6134, epoch: 4, loss: 1.190674
global_step: 6135, epoch: 4, loss: 1.205026
global_step: 6136, epoch: 4, loss: 1.158217
global_step: 6137, epoch: 4, loss: 1.197566
global_step: 6138, epoch: 4, loss: 1.117601
global_step: 6139, epoch: 4, loss: 1.230470
global_step: 6140, epoch: 4, loss: 1.225077
global_step: 6141, epoch: 4, loss: 1.225159
global_step: 6142, epoch: 4, loss: 1.284499
global_step: 6143, epoch: 4, loss: 1.255628
global_step: 6144, epoch: 4, loss: 1.230918
global_step: 6145, epoch: 4, loss: 1.234963
global_step: 6146, epoch: 4, loss: 1.180618
global_step: 6147, epoch: 4, loss: 1.226435
global_step: 6148, epoch: 4, loss: 1.319022
global_step: 6149, epoch: 4, loss: 1.397045
global_step: 6150, epoch: 4, loss: 1.170767
global_step: 6151, epoch: 4, loss: 1.311850
global_step: 6152, epoch: 4, loss: 1.181071
global_step: 6153, epoch: 4, loss: 1.279126
global_step: 6154, epoch: 4, loss: 1.195410
global_step: 6155, epoch: 4, loss: 1.288119
global_step: 6156, epoch: 4, loss: 1.220854
global_step: 6157, epoch: 4, loss: 1.166115
global_step: 6158, epoch: 4, loss: 1.127678
global_step: 6159, epoch: 4, loss: 1.191152
global_step: 6160, epoch: 4, loss: 0.683693
epoch: 4
train	acc: 0.5674	macro: p 0.3340, r 0.2470, f1: 0.2089	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.4705
dev	acc: 0.5131	macro: p 0.3559, r 0.2518, f1: 0.2026	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4072
test	acc: 0.5575	macro: p 0.3773, r 0.2455, f1: 0.2044	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.4613
global_step: 6161, epoch: 5, loss: 1.549640
global_step: 6162, epoch: 5, loss: 1.144464
global_step: 6163, epoch: 5, loss: 1.222205
global_step: 6164, epoch: 5, loss: 1.292042
global_step: 6165, epoch: 5, loss: 1.239687
global_step: 6166, epoch: 5, loss: 1.266528
global_step: 6167, epoch: 5, loss: 1.116197
global_step: 6168, epoch: 5, loss: 1.086005
global_step: 6169, epoch: 5, loss: 1.098250
global_step: 6170, epoch: 5, loss: 1.252361
global_step: 6171, epoch: 5, loss: 1.234578
global_step: 6172, epoch: 5, loss: 1.199033
global_step: 6173, epoch: 5, loss: 1.107210
global_step: 6174, epoch: 5, loss: 1.214218
global_step: 6175, epoch: 5, loss: 1.220298
global_step: 6176, epoch: 5, loss: 1.109702
global_step: 6177, epoch: 5, loss: 1.152728
global_step: 6178, epoch: 5, loss: 1.168719
global_step: 6179, epoch: 5, loss: 1.198441
global_step: 6180, epoch: 5, loss: 1.185998
global_step: 6181, epoch: 5, loss: 1.284865
global_step: 6182, epoch: 5, loss: 1.188276
global_step: 6183, epoch: 5, loss: 1.176557
global_step: 6184, epoch: 5, loss: 1.180266
global_step: 6185, epoch: 5, loss: 1.103276
global_step: 6186, epoch: 5, loss: 1.212810
global_step: 6187, epoch: 5, loss: 1.249425
global_step: 6188, epoch: 5, loss: 1.180887
global_step: 6189, epoch: 5, loss: 1.138366
global_step: 6190, epoch: 5, loss: 1.190342
global_step: 6191, epoch: 5, loss: 1.229238
global_step: 6192, epoch: 5, loss: 1.257918
global_step: 6193, epoch: 5, loss: 1.299331
global_step: 6194, epoch: 5, loss: 1.213843
global_step: 6195, epoch: 5, loss: 1.213765
global_step: 6196, epoch: 5, loss: 1.244818
global_step: 6197, epoch: 5, loss: 1.183754
global_step: 6198, epoch: 5, loss: 1.263472
global_step: 6199, epoch: 5, loss: 1.124423
global_step: 6200, epoch: 5, loss: 1.451150
epoch: 5
train	acc: 0.5715	macro: p 0.4223, r 0.2893, f1: 0.2683	micro: p 0.5715, r 0.5715, f1 0.5715	weighted_f1:0.5161
dev	acc: 0.4986	macro: p 0.3921, r 0.2684, f1: 0.2307	micro: p 0.4986, r 0.4986, f1 0.4986	weighted_f1:0.4281
test	acc: 0.5429	macro: p 0.3999, r 0.2774, f1: 0.2459	micro: p 0.5429, r 0.5429, f1 0.5429	weighted_f1:0.4867
New best model!
global_step: 6201, epoch: 6, loss: 1.299102
global_step: 6202, epoch: 6, loss: 1.188127
global_step: 6203, epoch: 6, loss: 1.100115
global_step: 6204, epoch: 6, loss: 1.055967
global_step: 6205, epoch: 6, loss: 1.054000
global_step: 6206, epoch: 6, loss: 1.214154
global_step: 6207, epoch: 6, loss: 1.089004
global_step: 6208, epoch: 6, loss: 1.317589
global_step: 6209, epoch: 6, loss: 1.147015
global_step: 6210, epoch: 6, loss: 1.072408
global_step: 6211, epoch: 6, loss: 1.138915
global_step: 6212, epoch: 6, loss: 1.156664
global_step: 6213, epoch: 6, loss: 1.142453
global_step: 6214, epoch: 6, loss: 1.189604
global_step: 6215, epoch: 6, loss: 1.107724
global_step: 6216, epoch: 6, loss: 1.158979
global_step: 6217, epoch: 6, loss: 1.293101
global_step: 6218, epoch: 6, loss: 1.226589
global_step: 6219, epoch: 6, loss: 1.091759
global_step: 6220, epoch: 6, loss: 1.152573
global_step: 6221, epoch: 6, loss: 1.077709
global_step: 6222, epoch: 6, loss: 1.219886
global_step: 6223, epoch: 6, loss: 1.219199
global_step: 6224, epoch: 6, loss: 1.165584
global_step: 6225, epoch: 6, loss: 1.127176
global_step: 6226, epoch: 6, loss: 1.004931
global_step: 6227, epoch: 6, loss: 1.217969
global_step: 6228, epoch: 6, loss: 1.130098
global_step: 6229, epoch: 6, loss: 1.277765
global_step: 6230, epoch: 6, loss: 1.100822
global_step: 6231, epoch: 6, loss: 1.177754
global_step: 6232, epoch: 6, loss: 1.229163
global_step: 6233, epoch: 6, loss: 1.229529
global_step: 6234, epoch: 6, loss: 1.065097
global_step: 6235, epoch: 6, loss: 1.007023
global_step: 6236, epoch: 6, loss: 1.122918
global_step: 6237, epoch: 6, loss: 1.061059
global_step: 6238, epoch: 6, loss: 1.234290
global_step: 6239, epoch: 6, loss: 1.300705
global_step: 6240, epoch: 6, loss: 1.896027
epoch: 6
train	acc: 0.6119	macro: p 0.4188, r 0.3335, f1: 0.3329	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5616
dev	acc: 0.5419	macro: p 0.3701, r 0.2923, f1: 0.2861	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4815
test	acc: 0.5962	macro: p 0.3963, r 0.3056, f1: 0.3097	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5478
New best model!
global_step: 6241, epoch: 7, loss: 1.217062
global_step: 6242, epoch: 7, loss: 1.234081
global_step: 6243, epoch: 7, loss: 1.226197
global_step: 6244, epoch: 7, loss: 1.196545
global_step: 6245, epoch: 7, loss: 1.121268
global_step: 6246, epoch: 7, loss: 1.153386
global_step: 6247, epoch: 7, loss: 1.086971
global_step: 6248, epoch: 7, loss: 1.053250
global_step: 6249, epoch: 7, loss: 1.149482
global_step: 6250, epoch: 7, loss: 1.109865
global_step: 6251, epoch: 7, loss: 1.113023
global_step: 6252, epoch: 7, loss: 1.160183
global_step: 6253, epoch: 7, loss: 1.061656
global_step: 6254, epoch: 7, loss: 1.133334
global_step: 6255, epoch: 7, loss: 1.233778
global_step: 6256, epoch: 7, loss: 1.121146
global_step: 6257, epoch: 7, loss: 1.064636
global_step: 6258, epoch: 7, loss: 1.149973
global_step: 6259, epoch: 7, loss: 1.166042
global_step: 6260, epoch: 7, loss: 1.170040
global_step: 6261, epoch: 7, loss: 1.076001
global_step: 6262, epoch: 7, loss: 1.112280
global_step: 6263, epoch: 7, loss: 1.155306
global_step: 6264, epoch: 7, loss: 1.031696
global_step: 6265, epoch: 7, loss: 1.185868
global_step: 6266, epoch: 7, loss: 1.131544
global_step: 6267, epoch: 7, loss: 1.008172
global_step: 6268, epoch: 7, loss: 1.179212
global_step: 6269, epoch: 7, loss: 1.128532
global_step: 6270, epoch: 7, loss: 1.064154
global_step: 6271, epoch: 7, loss: 1.191936
global_step: 6272, epoch: 7, loss: 1.200028
global_step: 6273, epoch: 7, loss: 1.152550
global_step: 6274, epoch: 7, loss: 1.203723
global_step: 6275, epoch: 7, loss: 1.074642
global_step: 6276, epoch: 7, loss: 1.182183
global_step: 6277, epoch: 7, loss: 1.188020
global_step: 6278, epoch: 7, loss: 1.128706
global_step: 6279, epoch: 7, loss: 1.280508
global_step: 6280, epoch: 7, loss: 1.567669
epoch: 7
train	acc: 0.5576	macro: p 0.4593, r 0.2683, f1: 0.2334	micro: p 0.5576, r 0.5576, f1 0.5576	weighted_f1:0.4881
dev	acc: 0.4869	macro: p 0.4288, r 0.2535, f1: 0.2064	micro: p 0.4869, r 0.4869, f1 0.4869	weighted_f1:0.4071
test	acc: 0.5165	macro: p 0.4233, r 0.2528, f1: 0.2114	micro: p 0.5165, r 0.5165, f1 0.5165	weighted_f1:0.4538
global_step: 6281, epoch: 8, loss: 1.322463
global_step: 6282, epoch: 8, loss: 1.075392
global_step: 6283, epoch: 8, loss: 1.040883
global_step: 6284, epoch: 8, loss: 1.096349
global_step: 6285, epoch: 8, loss: 1.020761
global_step: 6286, epoch: 8, loss: 1.179371
global_step: 6287, epoch: 8, loss: 1.146296
global_step: 6288, epoch: 8, loss: 1.140315
global_step: 6289, epoch: 8, loss: 1.143079
global_step: 6290, epoch: 8, loss: 1.122883
global_step: 6291, epoch: 8, loss: 1.169728
global_step: 6292, epoch: 8, loss: 1.139301
global_step: 6293, epoch: 8, loss: 0.991665
global_step: 6294, epoch: 8, loss: 0.964163
global_step: 6295, epoch: 8, loss: 1.101981
global_step: 6296, epoch: 8, loss: 1.167353
global_step: 6297, epoch: 8, loss: 1.107061
global_step: 6298, epoch: 8, loss: 1.081195
global_step: 6299, epoch: 8, loss: 1.149937
global_step: 6300, epoch: 8, loss: 1.156995
global_step: 6301, epoch: 8, loss: 1.119669
global_step: 6302, epoch: 8, loss: 1.168421
global_step: 6303, epoch: 8, loss: 1.120749
global_step: 6304, epoch: 8, loss: 1.096690
global_step: 6305, epoch: 8, loss: 1.033484
global_step: 6306, epoch: 8, loss: 1.124007
global_step: 6307, epoch: 8, loss: 1.152712
global_step: 6308, epoch: 8, loss: 1.200638
global_step: 6309, epoch: 8, loss: 1.189245
global_step: 6310, epoch: 8, loss: 0.949721
global_step: 6311, epoch: 8, loss: 1.105889
global_step: 6312, epoch: 8, loss: 1.047038
global_step: 6313, epoch: 8, loss: 1.011366
global_step: 6314, epoch: 8, loss: 1.134791
global_step: 6315, epoch: 8, loss: 1.096617
global_step: 6316, epoch: 8, loss: 1.098629
global_step: 6317, epoch: 8, loss: 1.106800
global_step: 6318, epoch: 8, loss: 1.236190
global_step: 6319, epoch: 8, loss: 1.130191
global_step: 6320, epoch: 8, loss: 0.629620
epoch: 8
train	acc: 0.6342	macro: p 0.4559, r 0.3327, f1: 0.3356	micro: p 0.6342, r 0.6342, f1 0.6342	weighted_f1:0.5758
dev	acc: 0.5509	macro: p 0.3953, r 0.3025, f1: 0.2833	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4800
test	acc: 0.5946	macro: p 0.4008, r 0.3026, f1: 0.2906	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5293
global_step: 6321, epoch: 9, loss: 1.176453
global_step: 6322, epoch: 9, loss: 1.074975
global_step: 6323, epoch: 9, loss: 1.113455
global_step: 6324, epoch: 9, loss: 1.095237
global_step: 6325, epoch: 9, loss: 1.239345
global_step: 6326, epoch: 9, loss: 1.163332
global_step: 6327, epoch: 9, loss: 0.928393
global_step: 6328, epoch: 9, loss: 0.999851
global_step: 6329, epoch: 9, loss: 1.089423
global_step: 6330, epoch: 9, loss: 1.011104
global_step: 6331, epoch: 9, loss: 1.053588
global_step: 6332, epoch: 9, loss: 1.294487
global_step: 6333, epoch: 9, loss: 1.054610
global_step: 6334, epoch: 9, loss: 0.901606
global_step: 6335, epoch: 9, loss: 1.044786
global_step: 6336, epoch: 9, loss: 0.960700
global_step: 6337, epoch: 9, loss: 1.239694
global_step: 6338, epoch: 9, loss: 1.110894
global_step: 6339, epoch: 9, loss: 1.115278
global_step: 6340, epoch: 9, loss: 1.157601
global_step: 6341, epoch: 9, loss: 1.121369
global_step: 6342, epoch: 9, loss: 1.001048
global_step: 6343, epoch: 9, loss: 0.998292
global_step: 6344, epoch: 9, loss: 1.066939
global_step: 6345, epoch: 9, loss: 1.064283
global_step: 6346, epoch: 9, loss: 1.056855
global_step: 6347, epoch: 9, loss: 1.017003
global_step: 6348, epoch: 9, loss: 1.023648
global_step: 6349, epoch: 9, loss: 1.132748
global_step: 6350, epoch: 9, loss: 1.104770
global_step: 6351, epoch: 9, loss: 0.994915
global_step: 6352, epoch: 9, loss: 1.155039
global_step: 6353, epoch: 9, loss: 0.965138
global_step: 6354, epoch: 9, loss: 1.229207
global_step: 6355, epoch: 9, loss: 1.220712
global_step: 6356, epoch: 9, loss: 1.044490
global_step: 6357, epoch: 9, loss: 1.088379
global_step: 6358, epoch: 9, loss: 1.040255
global_step: 6359, epoch: 9, loss: 1.150244
global_step: 6360, epoch: 9, loss: 1.779116
epoch: 9
train	acc: 0.6594	macro: p 0.4618, r 0.3636, f1: 0.3689	micro: p 0.6594, r 0.6594, f1 0.6594	weighted_f1:0.6087
dev	acc: 0.5528	macro: p 0.3793, r 0.3058, f1: 0.2879	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4850
test	acc: 0.5958	macro: p 0.3746, r 0.3085, f1: 0.2954	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5349
New best model!
global_step: 6361, epoch: 10, loss: 1.011237
global_step: 6362, epoch: 10, loss: 1.022381
global_step: 6363, epoch: 10, loss: 1.015801
global_step: 6364, epoch: 10, loss: 1.018173
global_step: 6365, epoch: 10, loss: 0.955613
global_step: 6366, epoch: 10, loss: 0.987618
global_step: 6367, epoch: 10, loss: 1.097382
global_step: 6368, epoch: 10, loss: 0.965055
global_step: 6369, epoch: 10, loss: 0.998677
global_step: 6370, epoch: 10, loss: 1.036886
global_step: 6371, epoch: 10, loss: 1.018273
global_step: 6372, epoch: 10, loss: 1.171826
global_step: 6373, epoch: 10, loss: 1.045664
global_step: 6374, epoch: 10, loss: 1.086054
global_step: 6375, epoch: 10, loss: 1.098934
global_step: 6376, epoch: 10, loss: 1.102753
global_step: 6377, epoch: 10, loss: 1.044642
global_step: 6378, epoch: 10, loss: 0.958571
global_step: 6379, epoch: 10, loss: 0.997141
global_step: 6380, epoch: 10, loss: 1.108379
global_step: 6381, epoch: 10, loss: 1.056650
global_step: 6382, epoch: 10, loss: 0.997430
global_step: 6383, epoch: 10, loss: 1.040797
global_step: 6384, epoch: 10, loss: 1.064664
global_step: 6385, epoch: 10, loss: 0.970432
global_step: 6386, epoch: 10, loss: 1.080365
global_step: 6387, epoch: 10, loss: 0.984696
global_step: 6388, epoch: 10, loss: 1.056590
global_step: 6389, epoch: 10, loss: 1.021647
global_step: 6390, epoch: 10, loss: 0.947117
global_step: 6391, epoch: 10, loss: 0.995599
global_step: 6392, epoch: 10, loss: 1.036443
global_step: 6393, epoch: 10, loss: 1.053059
global_step: 6394, epoch: 10, loss: 1.074505
global_step: 6395, epoch: 10, loss: 1.118604
global_step: 6396, epoch: 10, loss: 1.011315
global_step: 6397, epoch: 10, loss: 1.094436
global_step: 6398, epoch: 10, loss: 0.978167
global_step: 6399, epoch: 10, loss: 1.017420
global_step: 6400, epoch: 10, loss: 0.786557
epoch: 10
train	acc: 0.6165	macro: p 0.4910, r 0.3028, f1: 0.3200	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5509
dev	acc: 0.5338	macro: p 0.4492, r 0.2632, f1: 0.2605	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4510
test	acc: 0.5943	macro: p 0.4401, r 0.2733, f1: 0.2808	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5182
global_step: 6401, epoch: 11, loss: 1.396041
global_step: 6402, epoch: 11, loss: 1.147634
global_step: 6403, epoch: 11, loss: 1.019443
global_step: 6404, epoch: 11, loss: 0.939323
global_step: 6405, epoch: 11, loss: 0.926586
global_step: 6406, epoch: 11, loss: 0.875954
global_step: 6407, epoch: 11, loss: 1.032810
global_step: 6408, epoch: 11, loss: 1.031246
global_step: 6409, epoch: 11, loss: 0.862847
global_step: 6410, epoch: 11, loss: 0.963507
global_step: 6411, epoch: 11, loss: 0.921659
global_step: 6412, epoch: 11, loss: 0.987944
global_step: 6413, epoch: 11, loss: 1.038185
global_step: 6414, epoch: 11, loss: 0.899454
global_step: 6415, epoch: 11, loss: 0.947533
global_step: 6416, epoch: 11, loss: 1.084517
global_step: 6417, epoch: 11, loss: 1.021397
global_step: 6418, epoch: 11, loss: 1.105930
global_step: 6419, epoch: 11, loss: 1.026465
global_step: 6420, epoch: 11, loss: 0.932975
global_step: 6421, epoch: 11, loss: 0.990840
global_step: 6422, epoch: 11, loss: 1.090381
global_step: 6423, epoch: 11, loss: 0.977369
global_step: 6424, epoch: 11, loss: 0.979422
global_step: 6425, epoch: 11, loss: 0.976525
global_step: 6426, epoch: 11, loss: 1.027362
global_step: 6427, epoch: 11, loss: 0.888120
global_step: 6428, epoch: 11, loss: 1.145127
global_step: 6429, epoch: 11, loss: 0.944706
global_step: 6430, epoch: 11, loss: 0.936498
global_step: 6431, epoch: 11, loss: 1.052185
global_step: 6432, epoch: 11, loss: 1.078801
global_step: 6433, epoch: 11, loss: 1.034150
global_step: 6434, epoch: 11, loss: 0.952654
global_step: 6435, epoch: 11, loss: 0.942310
global_step: 6436, epoch: 11, loss: 1.119070
global_step: 6437, epoch: 11, loss: 0.947499
global_step: 6438, epoch: 11, loss: 0.947001
global_step: 6439, epoch: 11, loss: 1.120887
global_step: 6440, epoch: 11, loss: 0.635847
epoch: 11
train	acc: 0.6889	macro: p 0.6274, r 0.4161, f1: 0.4179	micro: p 0.6889, r 0.6889, f1 0.6889	weighted_f1:0.6556
dev	acc: 0.5582	macro: p 0.3661, r 0.3205, f1: 0.3141	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5109
test	acc: 0.6161	macro: p 0.4097, r 0.3434, f1: 0.3423	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5790
New best model!
global_step: 6441, epoch: 12, loss: 0.910283
global_step: 6442, epoch: 12, loss: 1.059823
global_step: 6443, epoch: 12, loss: 1.040063
global_step: 6444, epoch: 12, loss: 0.919212
global_step: 6445, epoch: 12, loss: 1.040787
global_step: 6446, epoch: 12, loss: 0.807742
global_step: 6447, epoch: 12, loss: 0.970555
global_step: 6448, epoch: 12, loss: 0.999771
global_step: 6449, epoch: 12, loss: 0.995868
global_step: 6450, epoch: 12, loss: 0.930890
global_step: 6451, epoch: 12, loss: 1.093614
global_step: 6452, epoch: 12, loss: 1.012338
global_step: 6453, epoch: 12, loss: 1.146302
global_step: 6454, epoch: 12, loss: 0.925301
global_step: 6455, epoch: 12, loss: 0.966761
global_step: 6456, epoch: 12, loss: 0.960157
global_step: 6457, epoch: 12, loss: 0.978316
global_step: 6458, epoch: 12, loss: 1.094539
global_step: 6459, epoch: 12, loss: 0.879380
global_step: 6460, epoch: 12, loss: 0.934844
global_step: 6461, epoch: 12, loss: 1.013942
global_step: 6462, epoch: 12, loss: 0.938113
global_step: 6463, epoch: 12, loss: 0.947246
global_step: 6464, epoch: 12, loss: 0.858709
global_step: 6465, epoch: 12, loss: 0.944326
global_step: 6466, epoch: 12, loss: 1.076008
global_step: 6467, epoch: 12, loss: 0.855436
global_step: 6468, epoch: 12, loss: 1.083788
global_step: 6469, epoch: 12, loss: 1.075961
global_step: 6470, epoch: 12, loss: 1.063449
global_step: 6471, epoch: 12, loss: 1.001085
global_step: 6472, epoch: 12, loss: 0.882646
global_step: 6473, epoch: 12, loss: 0.949988
global_step: 6474, epoch: 12, loss: 0.873091
global_step: 6475, epoch: 12, loss: 0.972582
global_step: 6476, epoch: 12, loss: 1.091862
global_step: 6477, epoch: 12, loss: 1.023302
global_step: 6478, epoch: 12, loss: 0.925541
global_step: 6479, epoch: 12, loss: 1.031989
global_step: 6480, epoch: 12, loss: 1.071897
epoch: 12
train	acc: 0.7085	macro: p 0.6012, r 0.4712, f1: 0.4770	micro: p 0.7085, r 0.7085, f1 0.7085	weighted_f1:0.6867
dev	acc: 0.5528	macro: p 0.4333, r 0.3354, f1: 0.3340	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5150
test	acc: 0.5874	macro: p 0.3617, r 0.3301, f1: 0.3275	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5573
New best model!
global_step: 6481, epoch: 13, loss: 0.914987
global_step: 6482, epoch: 13, loss: 0.848587
global_step: 6483, epoch: 13, loss: 0.942438
global_step: 6484, epoch: 13, loss: 1.000773
global_step: 6485, epoch: 13, loss: 0.909502
global_step: 6486, epoch: 13, loss: 0.955506
global_step: 6487, epoch: 13, loss: 0.956765
global_step: 6488, epoch: 13, loss: 0.975386
global_step: 6489, epoch: 13, loss: 0.893716
global_step: 6490, epoch: 13, loss: 1.014753
global_step: 6491, epoch: 13, loss: 0.996288
global_step: 6492, epoch: 13, loss: 0.937087
global_step: 6493, epoch: 13, loss: 1.045865
global_step: 6494, epoch: 13, loss: 1.041665
global_step: 6495, epoch: 13, loss: 0.930825
global_step: 6496, epoch: 13, loss: 1.016947
global_step: 6497, epoch: 13, loss: 0.843875
global_step: 6498, epoch: 13, loss: 0.885844
global_step: 6499, epoch: 13, loss: 0.877855
global_step: 6500, epoch: 13, loss: 0.907112
global_step: 6501, epoch: 13, loss: 0.959360
global_step: 6502, epoch: 13, loss: 1.039905
global_step: 6503, epoch: 13, loss: 0.955127
global_step: 6504, epoch: 13, loss: 0.851130
global_step: 6505, epoch: 13, loss: 0.896819
global_step: 6506, epoch: 13, loss: 0.913160
global_step: 6507, epoch: 13, loss: 0.955735
global_step: 6508, epoch: 13, loss: 0.979634
global_step: 6509, epoch: 13, loss: 0.746722
global_step: 6510, epoch: 13, loss: 0.972516
global_step: 6511, epoch: 13, loss: 0.969630
global_step: 6512, epoch: 13, loss: 1.014384
global_step: 6513, epoch: 13, loss: 0.947014
global_step: 6514, epoch: 13, loss: 0.871357
global_step: 6515, epoch: 13, loss: 0.962300
global_step: 6516, epoch: 13, loss: 1.052929
global_step: 6517, epoch: 13, loss: 0.928574
global_step: 6518, epoch: 13, loss: 0.945149
global_step: 6519, epoch: 13, loss: 0.991724
global_step: 6520, epoch: 13, loss: 0.827207
epoch: 13
train	acc: 0.7035	macro: p 0.6088, r 0.4838, f1: 0.4943	micro: p 0.7035, r 0.7035, f1 0.7035	weighted_f1:0.6861
dev	acc: 0.5518	macro: p 0.3635, r 0.3263, f1: 0.3254	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5112
test	acc: 0.5843	macro: p 0.4004, r 0.3455, f1: 0.3501	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5573
global_step: 6521, epoch: 14, loss: 0.866702
global_step: 6522, epoch: 14, loss: 0.959910
global_step: 6523, epoch: 14, loss: 0.916103
global_step: 6524, epoch: 14, loss: 0.969586
global_step: 6525, epoch: 14, loss: 1.052419
global_step: 6526, epoch: 14, loss: 0.828930
global_step: 6527, epoch: 14, loss: 0.802195
global_step: 6528, epoch: 14, loss: 0.905660
global_step: 6529, epoch: 14, loss: 0.864608
global_step: 6530, epoch: 14, loss: 0.950959
global_step: 6531, epoch: 14, loss: 0.846125
global_step: 6532, epoch: 14, loss: 0.842461
global_step: 6533, epoch: 14, loss: 0.847465
global_step: 6534, epoch: 14, loss: 0.866611
global_step: 6535, epoch: 14, loss: 0.877101
global_step: 6536, epoch: 14, loss: 0.912221
global_step: 6537, epoch: 14, loss: 0.967085
global_step: 6538, epoch: 14, loss: 0.878305
global_step: 6539, epoch: 14, loss: 0.904623
global_step: 6540, epoch: 14, loss: 1.073498
global_step: 6541, epoch: 14, loss: 1.079098
global_step: 6542, epoch: 14, loss: 0.830596
global_step: 6543, epoch: 14, loss: 0.924944
global_step: 6544, epoch: 14, loss: 0.943310
global_step: 6545, epoch: 14, loss: 0.803553
global_step: 6546, epoch: 14, loss: 0.836052
global_step: 6547, epoch: 14, loss: 0.873487
global_step: 6548, epoch: 14, loss: 0.864925
global_step: 6549, epoch: 14, loss: 0.879959
global_step: 6550, epoch: 14, loss: 0.972842
global_step: 6551, epoch: 14, loss: 0.996806
global_step: 6552, epoch: 14, loss: 0.854557
global_step: 6553, epoch: 14, loss: 1.059607
global_step: 6554, epoch: 14, loss: 1.048688
global_step: 6555, epoch: 14, loss: 0.857477
global_step: 6556, epoch: 14, loss: 0.844805
global_step: 6557, epoch: 14, loss: 0.839069
global_step: 6558, epoch: 14, loss: 0.923613
global_step: 6559, epoch: 14, loss: 1.030842
global_step: 6560, epoch: 14, loss: 0.244765
epoch: 14
train	acc: 0.7080	macro: p 0.7848, r 0.4411, f1: 0.4724	micro: p 0.7080, r 0.7080, f1 0.7080	weighted_f1:0.6769
dev	acc: 0.5437	macro: p 0.4282, r 0.3089, f1: 0.2977	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4835
test	acc: 0.5843	macro: p 0.4201, r 0.3089, f1: 0.3037	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5334
global_step: 6561, epoch: 15, loss: 0.882186
global_step: 6562, epoch: 15, loss: 0.875182
global_step: 6563, epoch: 15, loss: 0.863742
global_step: 6564, epoch: 15, loss: 0.960946
global_step: 6565, epoch: 15, loss: 0.894542
global_step: 6566, epoch: 15, loss: 0.952171
global_step: 6567, epoch: 15, loss: 0.987963
global_step: 6568, epoch: 15, loss: 0.894408
global_step: 6569, epoch: 15, loss: 0.789117
global_step: 6570, epoch: 15, loss: 0.849477
global_step: 6571, epoch: 15, loss: 0.773916
global_step: 6572, epoch: 15, loss: 0.770499
global_step: 6573, epoch: 15, loss: 0.856753
global_step: 6574, epoch: 15, loss: 0.932265
global_step: 6575, epoch: 15, loss: 0.876749
global_step: 6576, epoch: 15, loss: 0.871815
global_step: 6577, epoch: 15, loss: 0.832047
global_step: 6578, epoch: 15, loss: 0.872601
global_step: 6579, epoch: 15, loss: 0.882952
global_step: 6580, epoch: 15, loss: 0.827323
global_step: 6581, epoch: 15, loss: 0.853392
global_step: 6582, epoch: 15, loss: 0.874458
global_step: 6583, epoch: 15, loss: 0.909989
global_step: 6584, epoch: 15, loss: 0.866130
global_step: 6585, epoch: 15, loss: 0.807239
global_step: 6586, epoch: 15, loss: 0.928807
global_step: 6587, epoch: 15, loss: 0.921642
global_step: 6588, epoch: 15, loss: 0.829948
global_step: 6589, epoch: 15, loss: 0.873559
global_step: 6590, epoch: 15, loss: 0.858320
global_step: 6591, epoch: 15, loss: 0.886585
global_step: 6592, epoch: 15, loss: 0.950008
global_step: 6593, epoch: 15, loss: 0.816213
global_step: 6594, epoch: 15, loss: 0.947122
global_step: 6595, epoch: 15, loss: 0.980175
global_step: 6596, epoch: 15, loss: 0.926302
global_step: 6597, epoch: 15, loss: 0.808693
global_step: 6598, epoch: 15, loss: 0.829079
global_step: 6599, epoch: 15, loss: 0.836562
global_step: 6600, epoch: 15, loss: 1.232891
epoch: 15
train	acc: 0.7270	macro: p 0.7128, r 0.5403, f1: 0.5492	micro: p 0.7270, r 0.7270, f1 0.7270	weighted_f1:0.7196
dev	acc: 0.5248	macro: p 0.3847, r 0.3466, f1: 0.3295	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4972
test	acc: 0.5517	macro: p 0.3876, r 0.3485, f1: 0.3262	micro: p 0.5517, r 0.5517, f1 0.5517	weighted_f1:0.5393
global_step: 6601, epoch: 16, loss: 0.942003
global_step: 6602, epoch: 16, loss: 0.739611
global_step: 6603, epoch: 16, loss: 0.928952
global_step: 6604, epoch: 16, loss: 0.814321
global_step: 6605, epoch: 16, loss: 0.752391
global_step: 6606, epoch: 16, loss: 0.823342
global_step: 6607, epoch: 16, loss: 0.723666
global_step: 6608, epoch: 16, loss: 0.802314
global_step: 6609, epoch: 16, loss: 0.865235
global_step: 6610, epoch: 16, loss: 0.781122
global_step: 6611, epoch: 16, loss: 0.891060
global_step: 6612, epoch: 16, loss: 0.955078
global_step: 6613, epoch: 16, loss: 0.861588
global_step: 6614, epoch: 16, loss: 0.887858
global_step: 6615, epoch: 16, loss: 0.947674
global_step: 6616, epoch: 16, loss: 0.894839
global_step: 6617, epoch: 16, loss: 0.846882
global_step: 6618, epoch: 16, loss: 0.767154
global_step: 6619, epoch: 16, loss: 0.757263
global_step: 6620, epoch: 16, loss: 0.835154
global_step: 6621, epoch: 16, loss: 0.859247
global_step: 6622, epoch: 16, loss: 0.894716
global_step: 6623, epoch: 16, loss: 0.850302
global_step: 6624, epoch: 16, loss: 0.781657
global_step: 6625, epoch: 16, loss: 0.860749
global_step: 6626, epoch: 16, loss: 0.876029
global_step: 6627, epoch: 16, loss: 0.821112
global_step: 6628, epoch: 16, loss: 0.803400
global_step: 6629, epoch: 16, loss: 0.914772
global_step: 6630, epoch: 16, loss: 0.961747
global_step: 6631, epoch: 16, loss: 0.891976
global_step: 6632, epoch: 16, loss: 0.709041
global_step: 6633, epoch: 16, loss: 0.918704
global_step: 6634, epoch: 16, loss: 0.888345
global_step: 6635, epoch: 16, loss: 0.760866
global_step: 6636, epoch: 16, loss: 0.731935
global_step: 6637, epoch: 16, loss: 0.846478
global_step: 6638, epoch: 16, loss: 0.823846
global_step: 6639, epoch: 16, loss: 0.877378
global_step: 6640, epoch: 16, loss: 0.966179
epoch: 16
train	acc: 0.7734	macro: p 0.8047, r 0.5548, f1: 0.5967	micro: p 0.7734, r 0.7734, f1 0.7734	weighted_f1:0.7547
dev	acc: 0.5537	macro: p 0.3983, r 0.3294, f1: 0.3275	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5051
test	acc: 0.5897	macro: p 0.4153, r 0.3287, f1: 0.3359	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5496
global_step: 6641, epoch: 17, loss: 0.735398
global_step: 6642, epoch: 17, loss: 0.811998
global_step: 6643, epoch: 17, loss: 0.793875
global_step: 6644, epoch: 17, loss: 0.710893
global_step: 6645, epoch: 17, loss: 0.734425
global_step: 6646, epoch: 17, loss: 0.904384
global_step: 6647, epoch: 17, loss: 0.901917
global_step: 6648, epoch: 17, loss: 0.770224
global_step: 6649, epoch: 17, loss: 0.840799
global_step: 6650, epoch: 17, loss: 0.652130
global_step: 6651, epoch: 17, loss: 0.770013
global_step: 6652, epoch: 17, loss: 0.735217
global_step: 6653, epoch: 17, loss: 0.818724
global_step: 6654, epoch: 17, loss: 0.831598
global_step: 6655, epoch: 17, loss: 0.749659
global_step: 6656, epoch: 17, loss: 0.761395
global_step: 6657, epoch: 17, loss: 0.703450
global_step: 6658, epoch: 17, loss: 0.740680
global_step: 6659, epoch: 17, loss: 0.930301
global_step: 6660, epoch: 17, loss: 0.886564
global_step: 6661, epoch: 17, loss: 0.829334
global_step: 6662, epoch: 17, loss: 0.853606
global_step: 6663, epoch: 17, loss: 0.799880
global_step: 6664, epoch: 17, loss: 0.703410
global_step: 6665, epoch: 17, loss: 0.836686
global_step: 6666, epoch: 17, loss: 0.810641
global_step: 6667, epoch: 17, loss: 0.849184
global_step: 6668, epoch: 17, loss: 0.708489
global_step: 6669, epoch: 17, loss: 0.822151
global_step: 6670, epoch: 17, loss: 0.902835
global_step: 6671, epoch: 17, loss: 0.861031
global_step: 6672, epoch: 17, loss: 0.786017
global_step: 6673, epoch: 17, loss: 0.807699
global_step: 6674, epoch: 17, loss: 0.757382
global_step: 6675, epoch: 17, loss: 0.753393
global_step: 6676, epoch: 17, loss: 0.819127
global_step: 6677, epoch: 17, loss: 0.859253
global_step: 6678, epoch: 17, loss: 0.833575
global_step: 6679, epoch: 17, loss: 0.782195
global_step: 6680, epoch: 17, loss: 0.729909
epoch: 17
train	acc: 0.7628	macro: p 0.7748, r 0.5326, f1: 0.5823	micro: p 0.7628, r 0.7628, f1 0.7628	weighted_f1:0.7407
dev	acc: 0.5573	macro: p 0.4096, r 0.3171, f1: 0.3206	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5017
test	acc: 0.6123	macro: p 0.4651, r 0.3339, f1: 0.3458	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5680
global_step: 6681, epoch: 18, loss: 0.907194
global_step: 6682, epoch: 18, loss: 0.717837
global_step: 6683, epoch: 18, loss: 0.782698
global_step: 6684, epoch: 18, loss: 0.770910
global_step: 6685, epoch: 18, loss: 0.674238
global_step: 6686, epoch: 18, loss: 0.750237
global_step: 6687, epoch: 18, loss: 0.803294
global_step: 6688, epoch: 18, loss: 0.723042
global_step: 6689, epoch: 18, loss: 0.766855
global_step: 6690, epoch: 18, loss: 0.706899
global_step: 6691, epoch: 18, loss: 0.796813
global_step: 6692, epoch: 18, loss: 0.752054
global_step: 6693, epoch: 18, loss: 0.750861
global_step: 6694, epoch: 18, loss: 0.812336
global_step: 6695, epoch: 18, loss: 0.770863
global_step: 6696, epoch: 18, loss: 0.941293
global_step: 6697, epoch: 18, loss: 0.898923
global_step: 6698, epoch: 18, loss: 0.814057
global_step: 6699, epoch: 18, loss: 0.814454
global_step: 6700, epoch: 18, loss: 0.711881
global_step: 6701, epoch: 18, loss: 0.760704
global_step: 6702, epoch: 18, loss: 0.735329
global_step: 6703, epoch: 18, loss: 0.913372
global_step: 6704, epoch: 18, loss: 0.924664
global_step: 6705, epoch: 18, loss: 0.802027
global_step: 6706, epoch: 18, loss: 0.694638
global_step: 6707, epoch: 18, loss: 0.711445
global_step: 6708, epoch: 18, loss: 0.785523
global_step: 6709, epoch: 18, loss: 0.768590
global_step: 6710, epoch: 18, loss: 0.790902
global_step: 6711, epoch: 18, loss: 0.746395
global_step: 6712, epoch: 18, loss: 0.803449
global_step: 6713, epoch: 18, loss: 0.743595
global_step: 6714, epoch: 18, loss: 0.772696
global_step: 6715, epoch: 18, loss: 0.836082
global_step: 6716, epoch: 18, loss: 0.775807
global_step: 6717, epoch: 18, loss: 0.746974
global_step: 6718, epoch: 18, loss: 0.832436
global_step: 6719, epoch: 18, loss: 0.866559
global_step: 6720, epoch: 18, loss: 0.987826
epoch: 18
train	acc: 0.7845	macro: p 0.7810, r 0.5739, f1: 0.5875	micro: p 0.7845, r 0.7845, f1 0.7845	weighted_f1:0.7662
dev	acc: 0.5618	macro: p 0.4170, r 0.3551, f1: 0.3441	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5167
test	acc: 0.5766	macro: p 0.3869, r 0.3317, f1: 0.3190	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5427
New best model!
global_step: 6721, epoch: 19, loss: 0.872731
global_step: 6722, epoch: 19, loss: 0.760278
global_step: 6723, epoch: 19, loss: 0.843845
global_step: 6724, epoch: 19, loss: 0.677403
global_step: 6725, epoch: 19, loss: 0.745057
global_step: 6726, epoch: 19, loss: 0.679667
global_step: 6727, epoch: 19, loss: 0.688284
global_step: 6728, epoch: 19, loss: 0.634995
global_step: 6729, epoch: 19, loss: 0.767602
global_step: 6730, epoch: 19, loss: 0.710854
global_step: 6731, epoch: 19, loss: 0.733052
global_step: 6732, epoch: 19, loss: 0.741227
global_step: 6733, epoch: 19, loss: 0.709132
global_step: 6734, epoch: 19, loss: 0.708078
global_step: 6735, epoch: 19, loss: 0.680780
global_step: 6736, epoch: 19, loss: 0.715017
global_step: 6737, epoch: 19, loss: 0.732134
global_step: 6738, epoch: 19, loss: 0.685599
global_step: 6739, epoch: 19, loss: 0.772649
global_step: 6740, epoch: 19, loss: 0.652137
global_step: 6741, epoch: 19, loss: 0.596400
global_step: 6742, epoch: 19, loss: 0.843211
global_step: 6743, epoch: 19, loss: 0.764877
global_step: 6744, epoch: 19, loss: 0.723168
global_step: 6745, epoch: 19, loss: 0.718558
global_step: 6746, epoch: 19, loss: 0.739466
global_step: 6747, epoch: 19, loss: 0.818305
global_step: 6748, epoch: 19, loss: 0.842235
global_step: 6749, epoch: 19, loss: 0.953649
global_step: 6750, epoch: 19, loss: 0.953318
global_step: 6751, epoch: 19, loss: 0.774757
global_step: 6752, epoch: 19, loss: 0.754772
global_step: 6753, epoch: 19, loss: 0.755420
global_step: 6754, epoch: 19, loss: 0.676997
global_step: 6755, epoch: 19, loss: 0.686341
global_step: 6756, epoch: 19, loss: 0.649159
global_step: 6757, epoch: 19, loss: 0.707586
global_step: 6758, epoch: 19, loss: 0.794041
global_step: 6759, epoch: 19, loss: 0.796236
global_step: 6760, epoch: 19, loss: 1.413118
epoch: 19
train	acc: 0.8132	macro: p 0.7158, r 0.7223, f1: 0.7135	micro: p 0.8132, r 0.8132, f1 0.8132	weighted_f1:0.8137
dev	acc: 0.5329	macro: p 0.3769, r 0.3580, f1: 0.3558	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.5236
test	acc: 0.5709	macro: p 0.4010, r 0.3856, f1: 0.3794	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5718
New best model!
global_step: 6761, epoch: 20, loss: 0.803862
global_step: 6762, epoch: 20, loss: 0.733172
global_step: 6763, epoch: 20, loss: 0.667716
global_step: 6764, epoch: 20, loss: 0.595291
global_step: 6765, epoch: 20, loss: 0.622868
global_step: 6766, epoch: 20, loss: 0.804412
global_step: 6767, epoch: 20, loss: 0.653045
global_step: 6768, epoch: 20, loss: 0.736891
global_step: 6769, epoch: 20, loss: 0.728361
global_step: 6770, epoch: 20, loss: 0.739616
global_step: 6771, epoch: 20, loss: 0.719682
global_step: 6772, epoch: 20, loss: 0.653189
global_step: 6773, epoch: 20, loss: 0.619907
global_step: 6774, epoch: 20, loss: 0.746147
global_step: 6775, epoch: 20, loss: 0.717322
global_step: 6776, epoch: 20, loss: 0.693602
global_step: 6777, epoch: 20, loss: 0.683958
global_step: 6778, epoch: 20, loss: 0.729934
global_step: 6779, epoch: 20, loss: 0.659395
global_step: 6780, epoch: 20, loss: 0.594212
global_step: 6781, epoch: 20, loss: 0.538792
global_step: 6782, epoch: 20, loss: 0.697855
global_step: 6783, epoch: 20, loss: 0.676961
global_step: 6784, epoch: 20, loss: 0.778522
global_step: 6785, epoch: 20, loss: 0.659328
global_step: 6786, epoch: 20, loss: 0.672095
global_step: 6787, epoch: 20, loss: 0.720467
global_step: 6788, epoch: 20, loss: 0.620936
global_step: 6789, epoch: 20, loss: 0.668058
global_step: 6790, epoch: 20, loss: 1.016428
global_step: 6791, epoch: 20, loss: 0.817146
global_step: 6792, epoch: 20, loss: 0.763160
global_step: 6793, epoch: 20, loss: 0.593439
global_step: 6794, epoch: 20, loss: 0.773289
global_step: 6795, epoch: 20, loss: 0.646621
global_step: 6796, epoch: 20, loss: 0.768095
global_step: 6797, epoch: 20, loss: 0.709830
global_step: 6798, epoch: 20, loss: 0.660248
global_step: 6799, epoch: 20, loss: 0.744156
global_step: 6800, epoch: 20, loss: 0.532028
epoch: 20
train	acc: 0.7930	macro: p 0.8474, r 0.5757, f1: 0.6278	micro: p 0.7930, r 0.7930, f1 0.7930	weighted_f1:0.7742
dev	acc: 0.5473	macro: p 0.3821, r 0.3125, f1: 0.3067	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4850
test	acc: 0.5966	macro: p 0.4248, r 0.3187, f1: 0.3197	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5433
global_step: 6801, epoch: 21, loss: 0.769880
global_step: 6802, epoch: 21, loss: 0.818099
global_step: 6803, epoch: 21, loss: 0.761067
global_step: 6804, epoch: 21, loss: 0.623278
global_step: 6805, epoch: 21, loss: 0.668407
global_step: 6806, epoch: 21, loss: 0.565318
global_step: 6807, epoch: 21, loss: 0.625797
global_step: 6808, epoch: 21, loss: 0.750961
global_step: 6809, epoch: 21, loss: 0.703410
global_step: 6810, epoch: 21, loss: 0.746974
global_step: 6811, epoch: 21, loss: 0.544550
global_step: 6812, epoch: 21, loss: 0.651135
global_step: 6813, epoch: 21, loss: 0.684614
global_step: 6814, epoch: 21, loss: 0.768309
global_step: 6815, epoch: 21, loss: 0.679936
global_step: 6816, epoch: 21, loss: 0.666411
global_step: 6817, epoch: 21, loss: 0.754118
global_step: 6818, epoch: 21, loss: 0.679266
global_step: 6819, epoch: 21, loss: 0.655338
global_step: 6820, epoch: 21, loss: 0.547006
global_step: 6821, epoch: 21, loss: 0.569086
global_step: 6822, epoch: 21, loss: 0.596896
global_step: 6823, epoch: 21, loss: 0.759317
global_step: 6824, epoch: 21, loss: 0.707619
global_step: 6825, epoch: 21, loss: 0.652963
global_step: 6826, epoch: 21, loss: 0.768164
global_step: 6827, epoch: 21, loss: 0.662614
global_step: 6828, epoch: 21, loss: 0.708885
global_step: 6829, epoch: 21, loss: 0.782945
global_step: 6830, epoch: 21, loss: 0.514866
global_step: 6831, epoch: 21, loss: 0.574879
global_step: 6832, epoch: 21, loss: 0.625282
global_step: 6833, epoch: 21, loss: 0.724460
global_step: 6834, epoch: 21, loss: 0.762612
global_step: 6835, epoch: 21, loss: 0.665638
global_step: 6836, epoch: 21, loss: 0.677704
global_step: 6837, epoch: 21, loss: 0.712789
global_step: 6838, epoch: 21, loss: 0.707185
global_step: 6839, epoch: 21, loss: 0.775407
global_step: 6840, epoch: 21, loss: 0.173053
epoch: 21
train	acc: 0.8466	macro: p 0.8402, r 0.7121, f1: 0.7476	micro: p 0.8466, r 0.8466, f1 0.8466	weighted_f1:0.8417
dev	acc: 0.5618	macro: p 0.3746, r 0.3574, f1: 0.3545	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5332
test	acc: 0.5900	macro: p 0.3982, r 0.3600, f1: 0.3627	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5700
New best model!
global_step: 6841, epoch: 22, loss: 0.715559
global_step: 6842, epoch: 22, loss: 0.708024
global_step: 6843, epoch: 22, loss: 0.576818
global_step: 6844, epoch: 22, loss: 0.716199
global_step: 6845, epoch: 22, loss: 0.748986
global_step: 6846, epoch: 22, loss: 0.574642
global_step: 6847, epoch: 22, loss: 0.611258
global_step: 6848, epoch: 22, loss: 0.673744
global_step: 6849, epoch: 22, loss: 0.640398
global_step: 6850, epoch: 22, loss: 0.636810
global_step: 6851, epoch: 22, loss: 0.701972
global_step: 6852, epoch: 22, loss: 0.640692
global_step: 6853, epoch: 22, loss: 0.643560
global_step: 6854, epoch: 22, loss: 0.664783
global_step: 6855, epoch: 22, loss: 0.758257
global_step: 6856, epoch: 22, loss: 0.733782
global_step: 6857, epoch: 22, loss: 0.712886
global_step: 6858, epoch: 22, loss: 0.634320
global_step: 6859, epoch: 22, loss: 0.601870
global_step: 6860, epoch: 22, loss: 0.642327
global_step: 6861, epoch: 22, loss: 0.659150
global_step: 6862, epoch: 22, loss: 0.589950
global_step: 6863, epoch: 22, loss: 0.779149
global_step: 6864, epoch: 22, loss: 0.693984
global_step: 6865, epoch: 22, loss: 0.769171
global_step: 6866, epoch: 22, loss: 0.652470
global_step: 6867, epoch: 22, loss: 0.649673
global_step: 6868, epoch: 22, loss: 0.666882
global_step: 6869, epoch: 22, loss: 0.613079
global_step: 6870, epoch: 22, loss: 0.587263
global_step: 6871, epoch: 22, loss: 0.622795
global_step: 6872, epoch: 22, loss: 0.735271
global_step: 6873, epoch: 22, loss: 0.645713
global_step: 6874, epoch: 22, loss: 0.636238
global_step: 6875, epoch: 22, loss: 0.677459
global_step: 6876, epoch: 22, loss: 0.707743
global_step: 6877, epoch: 22, loss: 0.646787
global_step: 6878, epoch: 22, loss: 0.683522
global_step: 6879, epoch: 22, loss: 0.680361
global_step: 6880, epoch: 22, loss: 0.297103
epoch: 22
train	acc: 0.8021	macro: p 0.8694, r 0.6089, f1: 0.6832	micro: p 0.8021, r 0.8021, f1 0.8021	weighted_f1:0.7891
dev	acc: 0.5564	macro: p 0.5424, r 0.3145, f1: 0.3218	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4946
test	acc: 0.5996	macro: p 0.4205, r 0.3088, f1: 0.3218	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5435
global_step: 6881, epoch: 23, loss: 0.655724
global_step: 6882, epoch: 23, loss: 0.722267
global_step: 6883, epoch: 23, loss: 0.689771
global_step: 6884, epoch: 23, loss: 0.543202
global_step: 6885, epoch: 23, loss: 0.702144
global_step: 6886, epoch: 23, loss: 0.573992
global_step: 6887, epoch: 23, loss: 0.628219
global_step: 6888, epoch: 23, loss: 0.707381
global_step: 6889, epoch: 23, loss: 0.597749
global_step: 6890, epoch: 23, loss: 0.530026
global_step: 6891, epoch: 23, loss: 0.738210
global_step: 6892, epoch: 23, loss: 0.724499
global_step: 6893, epoch: 23, loss: 0.693968
global_step: 6894, epoch: 23, loss: 0.607478
global_step: 6895, epoch: 23, loss: 0.566191
global_step: 6896, epoch: 23, loss: 0.605791
global_step: 6897, epoch: 23, loss: 0.666169
global_step: 6898, epoch: 23, loss: 0.709885
global_step: 6899, epoch: 23, loss: 0.549311
global_step: 6900, epoch: 23, loss: 0.620377
global_step: 6901, epoch: 23, loss: 0.692709
global_step: 6902, epoch: 23, loss: 0.574371
global_step: 6903, epoch: 23, loss: 0.598070
global_step: 6904, epoch: 23, loss: 0.676079
global_step: 6905, epoch: 23, loss: 0.788191
global_step: 6906, epoch: 23, loss: 0.680313
global_step: 6907, epoch: 23, loss: 0.634559
global_step: 6908, epoch: 23, loss: 0.664567
global_step: 6909, epoch: 23, loss: 0.712895
global_step: 6910, epoch: 23, loss: 0.661994
global_step: 6911, epoch: 23, loss: 0.710543
global_step: 6912, epoch: 23, loss: 0.601129
global_step: 6913, epoch: 23, loss: 0.567741
global_step: 6914, epoch: 23, loss: 0.630026
global_step: 6915, epoch: 23, loss: 0.686022
global_step: 6916, epoch: 23, loss: 0.726406
global_step: 6917, epoch: 23, loss: 0.701994
global_step: 6918, epoch: 23, loss: 0.777424
global_step: 6919, epoch: 23, loss: 0.666658
global_step: 6920, epoch: 23, loss: 0.113625
epoch: 23
train	acc: 0.8157	macro: p 0.8305, r 0.6762, f1: 0.7134	micro: p 0.8157, r 0.8157, f1 0.8157	weighted_f1:0.8102
dev	acc: 0.5509	macro: p 0.4870, r 0.3486, f1: 0.3368	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5080
test	acc: 0.5632	macro: p 0.4103, r 0.3318, f1: 0.3183	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.5375
global_step: 6921, epoch: 24, loss: 0.675373
global_step: 6922, epoch: 24, loss: 0.632335
global_step: 6923, epoch: 24, loss: 0.590865
global_step: 6924, epoch: 24, loss: 0.675200
global_step: 6925, epoch: 24, loss: 0.603246
global_step: 6926, epoch: 24, loss: 0.656089
global_step: 6927, epoch: 24, loss: 0.545692
global_step: 6928, epoch: 24, loss: 0.650486
global_step: 6929, epoch: 24, loss: 0.511643
global_step: 6930, epoch: 24, loss: 0.678554
global_step: 6931, epoch: 24, loss: 0.499412
global_step: 6932, epoch: 24, loss: 0.727693
global_step: 6933, epoch: 24, loss: 0.746547
global_step: 6934, epoch: 24, loss: 0.664916
global_step: 6935, epoch: 24, loss: 0.557713
global_step: 6936, epoch: 24, loss: 0.611051
global_step: 6937, epoch: 24, loss: 0.609448
global_step: 6938, epoch: 24, loss: 0.494145
global_step: 6939, epoch: 24, loss: 0.767266
global_step: 6940, epoch: 24, loss: 0.599737
global_step: 6941, epoch: 24, loss: 0.638632
global_step: 6942, epoch: 24, loss: 0.531035
global_step: 6943, epoch: 24, loss: 0.515489
global_step: 6944, epoch: 24, loss: 0.672456
global_step: 6945, epoch: 24, loss: 0.694348
global_step: 6946, epoch: 24, loss: 0.754176
global_step: 6947, epoch: 24, loss: 0.539577
global_step: 6948, epoch: 24, loss: 0.641431
global_step: 6949, epoch: 24, loss: 0.604918
global_step: 6950, epoch: 24, loss: 0.576476
global_step: 6951, epoch: 24, loss: 0.741166
global_step: 6952, epoch: 24, loss: 0.596563
global_step: 6953, epoch: 24, loss: 0.691351
global_step: 6954, epoch: 24, loss: 0.741740
global_step: 6955, epoch: 24, loss: 0.706443
global_step: 6956, epoch: 24, loss: 0.517724
global_step: 6957, epoch: 24, loss: 0.668255
global_step: 6958, epoch: 24, loss: 0.704310
global_step: 6959, epoch: 24, loss: 0.685162
global_step: 6960, epoch: 24, loss: 0.321154
epoch: 24
train	acc: 0.8661	macro: p 0.8798, r 0.7465, f1: 0.7879	micro: p 0.8661, r 0.8661, f1 0.8661	weighted_f1:0.8618
dev	acc: 0.5591	macro: p 0.4191, r 0.3569, f1: 0.3532	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5229
test	acc: 0.5713	macro: p 0.3677, r 0.3343, f1: 0.3293	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5428
global_step: 6961, epoch: 25, loss: 0.558367
global_step: 6962, epoch: 25, loss: 0.534894
global_step: 6963, epoch: 25, loss: 0.509065
global_step: 6964, epoch: 25, loss: 0.515396
global_step: 6965, epoch: 25, loss: 0.589259
global_step: 6966, epoch: 25, loss: 0.662659
global_step: 6967, epoch: 25, loss: 0.577186
global_step: 6968, epoch: 25, loss: 0.567280
global_step: 6969, epoch: 25, loss: 0.755810
global_step: 6970, epoch: 25, loss: 0.675103
global_step: 6971, epoch: 25, loss: 0.614879
global_step: 6972, epoch: 25, loss: 0.595727
global_step: 6973, epoch: 25, loss: 0.597926
global_step: 6974, epoch: 25, loss: 0.626460
global_step: 6975, epoch: 25, loss: 0.553883
global_step: 6976, epoch: 25, loss: 0.542119
global_step: 6977, epoch: 25, loss: 0.568005
global_step: 6978, epoch: 25, loss: 0.591950
global_step: 6979, epoch: 25, loss: 0.538019
global_step: 6980, epoch: 25, loss: 0.575208
global_step: 6981, epoch: 25, loss: 0.638194
global_step: 6982, epoch: 25, loss: 0.619578
global_step: 6983, epoch: 25, loss: 0.561358
global_step: 6984, epoch: 25, loss: 0.698832
global_step: 6985, epoch: 25, loss: 0.692182
global_step: 6986, epoch: 25, loss: 0.586823
global_step: 6987, epoch: 25, loss: 0.562703
global_step: 6988, epoch: 25, loss: 0.725818
global_step: 6989, epoch: 25, loss: 0.651361
global_step: 6990, epoch: 25, loss: 0.705305
global_step: 6991, epoch: 25, loss: 0.571814
global_step: 6992, epoch: 25, loss: 0.577699
global_step: 6993, epoch: 25, loss: 0.615015
global_step: 6994, epoch: 25, loss: 0.580957
global_step: 6995, epoch: 25, loss: 0.578064
global_step: 6996, epoch: 25, loss: 0.539917
global_step: 6997, epoch: 25, loss: 0.545366
global_step: 6998, epoch: 25, loss: 0.563097
global_step: 6999, epoch: 25, loss: 0.703447
global_step: 7000, epoch: 25, loss: 0.884266
epoch: 25
train	acc: 0.8658	macro: p 0.8794, r 0.7604, f1: 0.8065	micro: p 0.8658, r 0.8658, f1 0.8658	weighted_f1:0.8623
dev	acc: 0.5717	macro: p 0.4465, r 0.3611, f1: 0.3644	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5264
test	acc: 0.5908	macro: p 0.4142, r 0.3421, f1: 0.3450	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5548
global_step: 7001, epoch: 26, loss: 0.641003
global_step: 7002, epoch: 26, loss: 0.551021
global_step: 7003, epoch: 26, loss: 0.551339
global_step: 7004, epoch: 26, loss: 0.609231
global_step: 7005, epoch: 26, loss: 0.562036
global_step: 7006, epoch: 26, loss: 0.619895
global_step: 7007, epoch: 26, loss: 0.648957
global_step: 7008, epoch: 26, loss: 0.574863
global_step: 7009, epoch: 26, loss: 0.507204
global_step: 7010, epoch: 26, loss: 0.481003
global_step: 7011, epoch: 26, loss: 0.540126
global_step: 7012, epoch: 26, loss: 0.547818
global_step: 7013, epoch: 26, loss: 0.576749
global_step: 7014, epoch: 26, loss: 0.653103
global_step: 7015, epoch: 26, loss: 0.598397
global_step: 7016, epoch: 26, loss: 0.573798
global_step: 7017, epoch: 26, loss: 0.562945
global_step: 7018, epoch: 26, loss: 0.520595
global_step: 7019, epoch: 26, loss: 0.572162
global_step: 7020, epoch: 26, loss: 0.604174
global_step: 7021, epoch: 26, loss: 0.605886
global_step: 7022, epoch: 26, loss: 0.560425
global_step: 7023, epoch: 26, loss: 0.516456
global_step: 7024, epoch: 26, loss: 0.590022
global_step: 7025, epoch: 26, loss: 0.634165
global_step: 7026, epoch: 26, loss: 0.589846
global_step: 7027, epoch: 26, loss: 0.591128
global_step: 7028, epoch: 26, loss: 0.706862
global_step: 7029, epoch: 26, loss: 0.503651
global_step: 7030, epoch: 26, loss: 0.607227
global_step: 7031, epoch: 26, loss: 0.648288
global_step: 7032, epoch: 26, loss: 0.706768
global_step: 7033, epoch: 26, loss: 0.529195
global_step: 7034, epoch: 26, loss: 0.653694
global_step: 7035, epoch: 26, loss: 0.547813
global_step: 7036, epoch: 26, loss: 0.650142
global_step: 7037, epoch: 26, loss: 0.531452
global_step: 7038, epoch: 26, loss: 0.517693
global_step: 7039, epoch: 26, loss: 0.603387
global_step: 7040, epoch: 26, loss: 0.454829
epoch: 26
train	acc: 0.8699	macro: p 0.8911, r 0.7582, f1: 0.8068	micro: p 0.8699, r 0.8699, f1 0.8699	weighted_f1:0.8667
dev	acc: 0.5636	macro: p 0.4647, r 0.3423, f1: 0.3523	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5223
test	acc: 0.5989	macro: p 0.4184, r 0.3364, f1: 0.3466	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5650
global_step: 7041, epoch: 27, loss: 0.585229
global_step: 7042, epoch: 27, loss: 0.632430
global_step: 7043, epoch: 27, loss: 0.596028
global_step: 7044, epoch: 27, loss: 0.562759
global_step: 7045, epoch: 27, loss: 0.534593
global_step: 7046, epoch: 27, loss: 0.486966
global_step: 7047, epoch: 27, loss: 0.503333
global_step: 7048, epoch: 27, loss: 0.551244
global_step: 7049, epoch: 27, loss: 0.543874
global_step: 7050, epoch: 27, loss: 0.480704
global_step: 7051, epoch: 27, loss: 0.539970
global_step: 7052, epoch: 27, loss: 0.528946
global_step: 7053, epoch: 27, loss: 0.451619
global_step: 7054, epoch: 27, loss: 0.478360
global_step: 7055, epoch: 27, loss: 0.561083
global_step: 7056, epoch: 27, loss: 0.492697
global_step: 7057, epoch: 27, loss: 0.527188
global_step: 7058, epoch: 27, loss: 0.552486
global_step: 7059, epoch: 27, loss: 0.621691
global_step: 7060, epoch: 27, loss: 0.614016
global_step: 7061, epoch: 27, loss: 0.425135
global_step: 7062, epoch: 27, loss: 0.488353
global_step: 7063, epoch: 27, loss: 0.573017
global_step: 7064, epoch: 27, loss: 0.663090
global_step: 7065, epoch: 27, loss: 0.660213
global_step: 7066, epoch: 27, loss: 0.586086
global_step: 7067, epoch: 27, loss: 0.531372
global_step: 7068, epoch: 27, loss: 0.689522
global_step: 7069, epoch: 27, loss: 0.596919
global_step: 7070, epoch: 27, loss: 0.646010
global_step: 7071, epoch: 27, loss: 0.618600
global_step: 7072, epoch: 27, loss: 0.626748
global_step: 7073, epoch: 27, loss: 0.638216
global_step: 7074, epoch: 27, loss: 0.522328
global_step: 7075, epoch: 27, loss: 0.583600
global_step: 7076, epoch: 27, loss: 0.471597
global_step: 7077, epoch: 27, loss: 0.570284
global_step: 7078, epoch: 27, loss: 0.578196
global_step: 7079, epoch: 27, loss: 0.648499
global_step: 7080, epoch: 27, loss: 0.753171
epoch: 27
train	acc: 0.8693	macro: p 0.8688, r 0.8091, f1: 0.8319	micro: p 0.8693, r 0.8693, f1 0.8693	weighted_f1:0.8705
dev	acc: 0.5176	macro: p 0.4090, r 0.3496, f1: 0.3510	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.5024
test	acc: 0.5513	macro: p 0.3905, r 0.3535, f1: 0.3477	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5422
global_step: 7081, epoch: 28, loss: 0.622423
global_step: 7082, epoch: 28, loss: 0.651160
global_step: 7083, epoch: 28, loss: 0.484689
global_step: 7084, epoch: 28, loss: 0.470529
global_step: 7085, epoch: 28, loss: 0.522402
global_step: 7086, epoch: 28, loss: 0.625215
global_step: 7087, epoch: 28, loss: 0.568553
global_step: 7088, epoch: 28, loss: 0.520623
global_step: 7089, epoch: 28, loss: 0.550246
global_step: 7090, epoch: 28, loss: 0.425847
global_step: 7091, epoch: 28, loss: 0.546305
global_step: 7092, epoch: 28, loss: 0.648741
global_step: 7093, epoch: 28, loss: 0.554072
global_step: 7094, epoch: 28, loss: 0.537226
global_step: 7095, epoch: 28, loss: 0.565208
global_step: 7096, epoch: 28, loss: 0.450001
global_step: 7097, epoch: 28, loss: 0.508797
global_step: 7098, epoch: 28, loss: 0.548431
global_step: 7099, epoch: 28, loss: 0.543468
global_step: 7100, epoch: 28, loss: 0.585244
global_step: 7101, epoch: 28, loss: 0.420529
global_step: 7102, epoch: 28, loss: 0.615839
global_step: 7103, epoch: 28, loss: 0.516492
global_step: 7104, epoch: 28, loss: 0.578838
global_step: 7105, epoch: 28, loss: 0.548525
global_step: 7106, epoch: 28, loss: 0.514871
global_step: 7107, epoch: 28, loss: 0.523433
global_step: 7108, epoch: 28, loss: 0.571055
global_step: 7109, epoch: 28, loss: 0.465351
global_step: 7110, epoch: 28, loss: 0.448669
global_step: 7111, epoch: 28, loss: 0.660162
global_step: 7112, epoch: 28, loss: 0.671041
global_step: 7113, epoch: 28, loss: 0.584906
global_step: 7114, epoch: 28, loss: 0.599739
global_step: 7115, epoch: 28, loss: 0.541230
global_step: 7116, epoch: 28, loss: 0.380066
global_step: 7117, epoch: 28, loss: 0.468121
global_step: 7118, epoch: 28, loss: 0.575135
global_step: 7119, epoch: 28, loss: 0.604499
global_step: 7120, epoch: 28, loss: 0.848550
epoch: 28
train	acc: 0.8566	macro: p 0.8770, r 0.7660, f1: 0.8013	micro: p 0.8566, r 0.8566, f1 0.8566	weighted_f1:0.8545
dev	acc: 0.5365	macro: p 0.3905, r 0.3398, f1: 0.3186	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4879
test	acc: 0.5701	macro: p 0.4309, r 0.3503, f1: 0.3361	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5379
global_step: 7121, epoch: 29, loss: 0.611243
global_step: 7122, epoch: 29, loss: 0.523150
global_step: 7123, epoch: 29, loss: 0.526417
global_step: 7124, epoch: 29, loss: 0.469310
global_step: 7125, epoch: 29, loss: 0.451888
global_step: 7126, epoch: 29, loss: 0.573667
global_step: 7127, epoch: 29, loss: 0.510748
global_step: 7128, epoch: 29, loss: 0.512949
global_step: 7129, epoch: 29, loss: 0.519660
global_step: 7130, epoch: 29, loss: 0.433298
global_step: 7131, epoch: 29, loss: 0.514686
global_step: 7132, epoch: 29, loss: 0.486941
global_step: 7133, epoch: 29, loss: 0.517379
global_step: 7134, epoch: 29, loss: 0.470114
global_step: 7135, epoch: 29, loss: 0.474731
global_step: 7136, epoch: 29, loss: 0.526312
global_step: 7137, epoch: 29, loss: 0.602904
global_step: 7138, epoch: 29, loss: 0.533498
global_step: 7139, epoch: 29, loss: 0.533298
global_step: 7140, epoch: 29, loss: 0.514603
global_step: 7141, epoch: 29, loss: 0.528299
global_step: 7142, epoch: 29, loss: 0.506101
global_step: 7143, epoch: 29, loss: 0.628473
global_step: 7144, epoch: 29, loss: 0.615837
global_step: 7145, epoch: 29, loss: 0.510680
global_step: 7146, epoch: 29, loss: 0.610316
global_step: 7147, epoch: 29, loss: 0.499607
global_step: 7148, epoch: 29, loss: 0.483407
global_step: 7149, epoch: 29, loss: 0.529929
global_step: 7150, epoch: 29, loss: 0.493169
global_step: 7151, epoch: 29, loss: 0.494068
global_step: 7152, epoch: 29, loss: 0.605120
global_step: 7153, epoch: 29, loss: 0.583027
global_step: 7154, epoch: 29, loss: 0.606420
global_step: 7155, epoch: 29, loss: 0.601637
global_step: 7156, epoch: 29, loss: 0.571336
global_step: 7157, epoch: 29, loss: 0.541735
global_step: 7158, epoch: 29, loss: 0.442314
global_step: 7159, epoch: 29, loss: 0.541056
global_step: 7160, epoch: 29, loss: 0.459748
epoch: 29
train	acc: 0.8933	macro: p 0.9069, r 0.8106, f1: 0.8484	micro: p 0.8933, r 0.8933, f1 0.8933	weighted_f1:0.8913
dev	acc: 0.5311	macro: p 0.4005, r 0.3309, f1: 0.3253	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4902
test	acc: 0.5881	macro: p 0.4125, r 0.3514, f1: 0.3549	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5562
global_step: 7161, epoch: 30, loss: 0.580128
global_step: 7162, epoch: 30, loss: 0.415230
global_step: 7163, epoch: 30, loss: 0.495797
global_step: 7164, epoch: 30, loss: 0.542391
global_step: 7165, epoch: 30, loss: 0.438106
global_step: 7166, epoch: 30, loss: 0.461197
global_step: 7167, epoch: 30, loss: 0.453678
global_step: 7168, epoch: 30, loss: 0.453853
global_step: 7169, epoch: 30, loss: 0.512515
global_step: 7170, epoch: 30, loss: 0.659597
global_step: 7171, epoch: 30, loss: 0.577588
global_step: 7172, epoch: 30, loss: 0.459275
global_step: 7173, epoch: 30, loss: 0.429875
global_step: 7174, epoch: 30, loss: 0.525170
global_step: 7175, epoch: 30, loss: 0.452269
global_step: 7176, epoch: 30, loss: 0.421028
global_step: 7177, epoch: 30, loss: 0.472303
global_step: 7178, epoch: 30, loss: 0.486240
global_step: 7179, epoch: 30, loss: 0.492736
global_step: 7180, epoch: 30, loss: 0.567656
global_step: 7181, epoch: 30, loss: 0.514451
global_step: 7182, epoch: 30, loss: 0.472790
global_step: 7183, epoch: 30, loss: 0.603146
global_step: 7184, epoch: 30, loss: 0.465403
global_step: 7185, epoch: 30, loss: 0.518579
global_step: 7186, epoch: 30, loss: 0.475484
global_step: 7187, epoch: 30, loss: 0.464806
global_step: 7188, epoch: 30, loss: 0.584856
global_step: 7189, epoch: 30, loss: 0.451167
global_step: 7190, epoch: 30, loss: 0.438343
global_step: 7191, epoch: 30, loss: 0.477334
global_step: 7192, epoch: 30, loss: 0.573714
global_step: 7193, epoch: 30, loss: 0.423821
global_step: 7194, epoch: 30, loss: 0.522779
global_step: 7195, epoch: 30, loss: 0.518258
global_step: 7196, epoch: 30, loss: 0.516380
global_step: 7197, epoch: 30, loss: 0.601808
global_step: 7198, epoch: 30, loss: 0.473203
global_step: 7199, epoch: 30, loss: 0.493981
global_step: 7200, epoch: 30, loss: 0.717374
epoch: 30
train	acc: 0.8695	macro: p 0.9071, r 0.7323, f1: 0.7862	micro: p 0.8695, r 0.8695, f1 0.8695	weighted_f1:0.8613
dev	acc: 0.5410	macro: p 0.4791, r 0.3208, f1: 0.3142	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4901
test	acc: 0.5770	macro: p 0.4387, r 0.3196, f1: 0.3123	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5384
global_step: 7201, epoch: 31, loss: 0.565242
global_step: 7202, epoch: 31, loss: 0.467730
global_step: 7203, epoch: 31, loss: 0.456547
global_step: 7204, epoch: 31, loss: 0.429822
global_step: 7205, epoch: 31, loss: 0.428593
global_step: 7206, epoch: 31, loss: 0.473099
global_step: 7207, epoch: 31, loss: 0.457192
global_step: 7208, epoch: 31, loss: 0.467557
global_step: 7209, epoch: 31, loss: 0.467205
global_step: 7210, epoch: 31, loss: 0.433464
global_step: 7211, epoch: 31, loss: 0.460634
global_step: 7212, epoch: 31, loss: 0.477471
global_step: 7213, epoch: 31, loss: 0.406579
global_step: 7214, epoch: 31, loss: 0.570330
global_step: 7215, epoch: 31, loss: 0.455488
global_step: 7216, epoch: 31, loss: 0.429835
global_step: 7217, epoch: 31, loss: 0.480454
global_step: 7218, epoch: 31, loss: 0.523618
global_step: 7219, epoch: 31, loss: 0.506919
global_step: 7220, epoch: 31, loss: 0.504746
global_step: 7221, epoch: 31, loss: 0.471694
global_step: 7222, epoch: 31, loss: 0.597766
global_step: 7223, epoch: 31, loss: 0.502140
global_step: 7224, epoch: 31, loss: 0.581057
global_step: 7225, epoch: 31, loss: 0.411381
global_step: 7226, epoch: 31, loss: 0.481626
global_step: 7227, epoch: 31, loss: 0.493950
global_step: 7228, epoch: 31, loss: 0.423049
global_step: 7229, epoch: 31, loss: 0.490526
global_step: 7230, epoch: 31, loss: 0.480000
global_step: 7231, epoch: 31, loss: 0.619977
global_step: 7232, epoch: 31, loss: 0.523548
global_step: 7233, epoch: 31, loss: 0.414861
global_step: 7234, epoch: 31, loss: 0.537135
global_step: 7235, epoch: 31, loss: 0.431908
global_step: 7236, epoch: 31, loss: 0.540534
global_step: 7237, epoch: 31, loss: 0.510343
global_step: 7238, epoch: 31, loss: 0.500561
global_step: 7239, epoch: 31, loss: 0.542142
global_step: 7240, epoch: 31, loss: 0.112185
epoch: 31
train	acc: 0.9146	macro: p 0.9222, r 0.8529, f1: 0.8827	micro: p 0.9146, r 0.9146, f1 0.9146	weighted_f1:0.9138
dev	acc: 0.5482	macro: p 0.3970, r 0.3501, f1: 0.3559	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5189
test	acc: 0.5897	macro: p 0.4196, r 0.3636, f1: 0.3774	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5701
global_step: 7241, epoch: 32, loss: 0.409723
global_step: 7242, epoch: 32, loss: 0.484662
global_step: 7243, epoch: 32, loss: 0.344654
global_step: 7244, epoch: 32, loss: 0.456786
global_step: 7245, epoch: 32, loss: 0.464766
global_step: 7246, epoch: 32, loss: 0.420911
global_step: 7247, epoch: 32, loss: 0.387198
global_step: 7248, epoch: 32, loss: 0.495859
global_step: 7249, epoch: 32, loss: 0.448359
global_step: 7250, epoch: 32, loss: 0.461967
global_step: 7251, epoch: 32, loss: 0.463528
global_step: 7252, epoch: 32, loss: 0.508881
global_step: 7253, epoch: 32, loss: 0.460696
global_step: 7254, epoch: 32, loss: 0.499861
global_step: 7255, epoch: 32, loss: 0.504815
global_step: 7256, epoch: 32, loss: 0.388226
global_step: 7257, epoch: 32, loss: 0.496998
global_step: 7258, epoch: 32, loss: 0.372828
global_step: 7259, epoch: 32, loss: 0.447939
global_step: 7260, epoch: 32, loss: 0.469279
global_step: 7261, epoch: 32, loss: 0.513258
global_step: 7262, epoch: 32, loss: 0.540736
global_step: 7263, epoch: 32, loss: 0.468385
global_step: 7264, epoch: 32, loss: 0.544661
global_step: 7265, epoch: 32, loss: 0.480784
global_step: 7266, epoch: 32, loss: 0.562135
global_step: 7267, epoch: 32, loss: 0.458758
global_step: 7268, epoch: 32, loss: 0.586698
global_step: 7269, epoch: 32, loss: 0.475981
global_step: 7270, epoch: 32, loss: 0.517908
global_step: 7271, epoch: 32, loss: 0.446410
global_step: 7272, epoch: 32, loss: 0.457120
global_step: 7273, epoch: 32, loss: 0.445261
global_step: 7274, epoch: 32, loss: 0.427050
global_step: 7275, epoch: 32, loss: 0.568623
global_step: 7276, epoch: 32, loss: 0.459731
global_step: 7277, epoch: 32, loss: 0.466989
global_step: 7278, epoch: 32, loss: 0.478921
global_step: 7279, epoch: 32, loss: 0.571019
global_step: 7280, epoch: 32, loss: 0.662281
epoch: 32
train	acc: 0.8814	macro: p 0.8816, r 0.7567, f1: 0.7846	micro: p 0.8814, r 0.8814, f1 0.8814	weighted_f1:0.8781
dev	acc: 0.5464	macro: p 0.4637, r 0.3526, f1: 0.3581	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5203
test	acc: 0.5820	macro: p 0.4343, r 0.3489, f1: 0.3559	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5648
global_step: 7281, epoch: 33, loss: 0.567186
global_step: 7282, epoch: 33, loss: 0.534808
global_step: 7283, epoch: 33, loss: 0.495687
global_step: 7284, epoch: 33, loss: 0.451799
global_step: 7285, epoch: 33, loss: 0.655594
global_step: 7286, epoch: 33, loss: 0.520784
global_step: 7287, epoch: 33, loss: 0.395265
global_step: 7288, epoch: 33, loss: 0.486742
global_step: 7289, epoch: 33, loss: 0.407355
global_step: 7290, epoch: 33, loss: 0.471376
global_step: 7291, epoch: 33, loss: 0.473205
global_step: 7292, epoch: 33, loss: 0.482095
global_step: 7293, epoch: 33, loss: 0.458491
global_step: 7294, epoch: 33, loss: 0.437793
global_step: 7295, epoch: 33, loss: 0.493152
global_step: 7296, epoch: 33, loss: 0.440153
global_step: 7297, epoch: 33, loss: 0.416859
global_step: 7298, epoch: 33, loss: 0.446900
global_step: 7299, epoch: 33, loss: 0.464941
global_step: 7300, epoch: 33, loss: 0.349737
global_step: 7301, epoch: 33, loss: 0.562466
global_step: 7302, epoch: 33, loss: 0.473710
global_step: 7303, epoch: 33, loss: 0.407110
global_step: 7304, epoch: 33, loss: 0.483915
global_step: 7305, epoch: 33, loss: 0.559298
global_step: 7306, epoch: 33, loss: 0.458601
global_step: 7307, epoch: 33, loss: 0.359379
global_step: 7308, epoch: 33, loss: 0.521809
global_step: 7309, epoch: 33, loss: 0.509454
global_step: 7310, epoch: 33, loss: 0.378868
global_step: 7311, epoch: 33, loss: 0.459018
global_step: 7312, epoch: 33, loss: 0.472738
global_step: 7313, epoch: 33, loss: 0.439762
global_step: 7314, epoch: 33, loss: 0.403789
global_step: 7315, epoch: 33, loss: 0.475721
global_step: 7316, epoch: 33, loss: 0.506033
global_step: 7317, epoch: 33, loss: 0.479591
global_step: 7318, epoch: 33, loss: 0.474849
global_step: 7319, epoch: 33, loss: 0.427691
global_step: 7320, epoch: 33, loss: 1.002383
epoch: 33
train	acc: 0.9162	macro: p 0.9193, r 0.8529, f1: 0.8781	micro: p 0.9162, r 0.9162, f1 0.9162	weighted_f1:0.9154
dev	acc: 0.5564	macro: p 0.4146, r 0.3616, f1: 0.3652	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5283
test	acc: 0.5843	macro: p 0.3968, r 0.3581, f1: 0.3604	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5635
global_step: 7321, epoch: 34, loss: 0.461230
global_step: 7322, epoch: 34, loss: 0.473113
global_step: 7323, epoch: 34, loss: 0.606351
global_step: 7324, epoch: 34, loss: 0.456402
global_step: 7325, epoch: 34, loss: 0.426339
global_step: 7326, epoch: 34, loss: 0.407578
global_step: 7327, epoch: 34, loss: 0.457579
global_step: 7328, epoch: 34, loss: 0.523151
global_step: 7329, epoch: 34, loss: 0.433023
global_step: 7330, epoch: 34, loss: 0.468191
global_step: 7331, epoch: 34, loss: 0.389248
global_step: 7332, epoch: 34, loss: 0.414601
global_step: 7333, epoch: 34, loss: 0.490853
global_step: 7334, epoch: 34, loss: 0.540665
global_step: 7335, epoch: 34, loss: 0.472428
global_step: 7336, epoch: 34, loss: 0.611582
global_step: 7337, epoch: 34, loss: 0.386737
global_step: 7338, epoch: 34, loss: 0.437615
global_step: 7339, epoch: 34, loss: 0.362309
global_step: 7340, epoch: 34, loss: 0.490642
global_step: 7341, epoch: 34, loss: 0.478466
global_step: 7342, epoch: 34, loss: 0.445665
global_step: 7343, epoch: 34, loss: 0.426459
global_step: 7344, epoch: 34, loss: 0.457161
global_step: 7345, epoch: 34, loss: 0.460225
global_step: 7346, epoch: 34, loss: 0.427993
global_step: 7347, epoch: 34, loss: 0.442843
global_step: 7348, epoch: 34, loss: 0.404885
global_step: 7349, epoch: 34, loss: 0.376968
global_step: 7350, epoch: 34, loss: 0.454160
global_step: 7351, epoch: 34, loss: 0.408640
global_step: 7352, epoch: 34, loss: 0.453819
global_step: 7353, epoch: 34, loss: 0.552110
global_step: 7354, epoch: 34, loss: 0.454774
global_step: 7355, epoch: 34, loss: 0.494935
global_step: 7356, epoch: 34, loss: 0.459391
global_step: 7357, epoch: 34, loss: 0.669488
global_step: 7358, epoch: 34, loss: 0.478447
global_step: 7359, epoch: 34, loss: 0.394922
global_step: 7360, epoch: 34, loss: 0.278335
epoch: 34
train	acc: 0.9112	macro: p 0.9297, r 0.8385, f1: 0.8752	micro: p 0.9112, r 0.9112, f1 0.9112	weighted_f1:0.9101
dev	acc: 0.5473	macro: p 0.4512, r 0.3346, f1: 0.3324	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5045
test	acc: 0.5885	macro: p 0.4154, r 0.3415, f1: 0.3466	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5551
global_step: 7361, epoch: 35, loss: 0.361096
global_step: 7362, epoch: 35, loss: 0.436167
global_step: 7363, epoch: 35, loss: 0.422358
global_step: 7364, epoch: 35, loss: 0.419893
global_step: 7365, epoch: 35, loss: 0.449664
global_step: 7366, epoch: 35, loss: 0.373255
global_step: 7367, epoch: 35, loss: 0.542286
global_step: 7368, epoch: 35, loss: 0.392667
global_step: 7369, epoch: 35, loss: 0.571076
global_step: 7370, epoch: 35, loss: 0.422293
global_step: 7371, epoch: 35, loss: 0.386964
global_step: 7372, epoch: 35, loss: 0.509082
global_step: 7373, epoch: 35, loss: 0.333028
global_step: 7374, epoch: 35, loss: 0.342917
global_step: 7375, epoch: 35, loss: 0.532502
global_step: 7376, epoch: 35, loss: 0.362672
global_step: 7377, epoch: 35, loss: 0.495071
global_step: 7378, epoch: 35, loss: 0.413882
global_step: 7379, epoch: 35, loss: 0.467890
global_step: 7380, epoch: 35, loss: 0.594399
global_step: 7381, epoch: 35, loss: 0.472438
global_step: 7382, epoch: 35, loss: 0.532159
global_step: 7383, epoch: 35, loss: 0.487687
global_step: 7384, epoch: 35, loss: 0.415884
global_step: 7385, epoch: 35, loss: 0.369187
global_step: 7386, epoch: 35, loss: 0.409639
global_step: 7387, epoch: 35, loss: 0.439990
global_step: 7388, epoch: 35, loss: 0.367798
global_step: 7389, epoch: 35, loss: 0.411420
global_step: 7390, epoch: 35, loss: 0.534988
global_step: 7391, epoch: 35, loss: 0.387944
global_step: 7392, epoch: 35, loss: 0.418640
global_step: 7393, epoch: 35, loss: 0.467015
global_step: 7394, epoch: 35, loss: 0.490293
global_step: 7395, epoch: 35, loss: 0.500536
global_step: 7396, epoch: 35, loss: 0.540438
global_step: 7397, epoch: 35, loss: 0.520985
global_step: 7398, epoch: 35, loss: 0.386804
global_step: 7399, epoch: 35, loss: 0.370612
global_step: 7400, epoch: 35, loss: 0.099546
epoch: 35
train	acc: 0.9188	macro: p 0.9321, r 0.8553, f1: 0.8872	micro: p 0.9188, r 0.9188, f1 0.9188	weighted_f1:0.9181
dev	acc: 0.5546	macro: p 0.5263, r 0.3436, f1: 0.3499	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5177
test	acc: 0.5893	macro: p 0.4121, r 0.3433, f1: 0.3430	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5608
global_step: 7401, epoch: 36, loss: 0.443475
global_step: 7402, epoch: 36, loss: 0.480497
global_step: 7403, epoch: 36, loss: 0.365562
global_step: 7404, epoch: 36, loss: 0.520596
global_step: 7405, epoch: 36, loss: 0.441242
global_step: 7406, epoch: 36, loss: 0.449200
global_step: 7407, epoch: 36, loss: 0.512593
global_step: 7408, epoch: 36, loss: 0.352518
global_step: 7409, epoch: 36, loss: 0.378036
global_step: 7410, epoch: 36, loss: 0.386169
global_step: 7411, epoch: 36, loss: 0.376842
global_step: 7412, epoch: 36, loss: 0.416623
global_step: 7413, epoch: 36, loss: 0.379245
global_step: 7414, epoch: 36, loss: 0.415072
global_step: 7415, epoch: 36, loss: 0.404356
global_step: 7416, epoch: 36, loss: 0.480032
global_step: 7417, epoch: 36, loss: 0.432349
global_step: 7418, epoch: 36, loss: 0.556272
global_step: 7419, epoch: 36, loss: 0.416143
global_step: 7420, epoch: 36, loss: 0.371306
global_step: 7421, epoch: 36, loss: 0.458038
global_step: 7422, epoch: 36, loss: 0.446177
global_step: 7423, epoch: 36, loss: 0.497068
global_step: 7424, epoch: 36, loss: 0.453819
global_step: 7425, epoch: 36, loss: 0.499853
global_step: 7426, epoch: 36, loss: 0.443398
global_step: 7427, epoch: 36, loss: 0.496994
global_step: 7428, epoch: 36, loss: 0.380356
global_step: 7429, epoch: 36, loss: 0.472097
global_step: 7430, epoch: 36, loss: 0.334695
global_step: 7431, epoch: 36, loss: 0.482777
global_step: 7432, epoch: 36, loss: 0.475182
global_step: 7433, epoch: 36, loss: 0.516023
global_step: 7434, epoch: 36, loss: 0.503198
global_step: 7435, epoch: 36, loss: 0.454108
global_step: 7436, epoch: 36, loss: 0.446584
global_step: 7437, epoch: 36, loss: 0.480743
global_step: 7438, epoch: 36, loss: 0.428873
global_step: 7439, epoch: 36, loss: 0.351903
global_step: 7440, epoch: 36, loss: 0.777994
epoch: 36
train	acc: 0.9200	macro: p 0.9166, r 0.8698, f1: 0.8892	micro: p 0.9200, r 0.9200, f1 0.9200	weighted_f1:0.9194
dev	acc: 0.5500	macro: p 0.4208, r 0.3519, f1: 0.3522	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5161
test	acc: 0.5805	macro: p 0.4102, r 0.3515, f1: 0.3536	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5576
global_step: 7441, epoch: 37, loss: 0.452061
global_step: 7442, epoch: 37, loss: 0.493190
global_step: 7443, epoch: 37, loss: 0.356061
global_step: 7444, epoch: 37, loss: 0.406603
global_step: 7445, epoch: 37, loss: 0.395303
global_step: 7446, epoch: 37, loss: 0.491674
global_step: 7447, epoch: 37, loss: 0.553043
global_step: 7448, epoch: 37, loss: 0.532427
global_step: 7449, epoch: 37, loss: 0.398599
global_step: 7450, epoch: 37, loss: 0.427985
global_step: 7451, epoch: 37, loss: 0.478108
global_step: 7452, epoch: 37, loss: 0.420185
global_step: 7453, epoch: 37, loss: 0.445405
global_step: 7454, epoch: 37, loss: 0.491986
global_step: 7455, epoch: 37, loss: 0.405246
global_step: 7456, epoch: 37, loss: 0.475439
global_step: 7457, epoch: 37, loss: 0.523861
global_step: 7458, epoch: 37, loss: 0.448421
global_step: 7459, epoch: 37, loss: 0.389769
global_step: 7460, epoch: 37, loss: 0.399637
global_step: 7461, epoch: 37, loss: 0.409919
global_step: 7462, epoch: 37, loss: 0.386564
global_step: 7463, epoch: 37, loss: 0.386560
global_step: 7464, epoch: 37, loss: 0.465425
global_step: 7465, epoch: 37, loss: 0.428948
global_step: 7466, epoch: 37, loss: 0.402656
global_step: 7467, epoch: 37, loss: 0.330741
global_step: 7468, epoch: 37, loss: 0.328588
global_step: 7469, epoch: 37, loss: 0.437657
global_step: 7470, epoch: 37, loss: 0.377342
global_step: 7471, epoch: 37, loss: 0.413775
global_step: 7472, epoch: 37, loss: 0.387571
global_step: 7473, epoch: 37, loss: 0.396495
global_step: 7474, epoch: 37, loss: 0.386272
global_step: 7475, epoch: 37, loss: 0.371248
global_step: 7476, epoch: 37, loss: 0.403035
global_step: 7477, epoch: 37, loss: 0.417582
global_step: 7478, epoch: 37, loss: 0.501157
global_step: 7479, epoch: 37, loss: 0.463766
global_step: 7480, epoch: 37, loss: 0.337933
epoch: 37
train	acc: 0.9216	macro: p 0.9425, r 0.8650, f1: 0.8987	micro: p 0.9216, r 0.9216, f1 0.9216	weighted_f1:0.9207
dev	acc: 0.5482	macro: p 0.4521, r 0.3327, f1: 0.3382	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4986
test	acc: 0.5935	macro: p 0.4169, r 0.3309, f1: 0.3415	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5535
global_step: 7481, epoch: 38, loss: 0.504176
global_step: 7482, epoch: 38, loss: 0.399038
global_step: 7483, epoch: 38, loss: 0.402792
global_step: 7484, epoch: 38, loss: 0.447783
global_step: 7485, epoch: 38, loss: 0.483423
global_step: 7486, epoch: 38, loss: 0.373520
global_step: 7487, epoch: 38, loss: 0.468033
global_step: 7488, epoch: 38, loss: 0.365682
global_step: 7489, epoch: 38, loss: 0.429829
global_step: 7490, epoch: 38, loss: 0.356646
global_step: 7491, epoch: 38, loss: 0.460193
global_step: 7492, epoch: 38, loss: 0.341285
global_step: 7493, epoch: 38, loss: 0.415278
global_step: 7494, epoch: 38, loss: 0.370616
global_step: 7495, epoch: 38, loss: 0.311145
global_step: 7496, epoch: 38, loss: 0.418143
global_step: 7497, epoch: 38, loss: 0.408785
global_step: 7498, epoch: 38, loss: 0.361026
global_step: 7499, epoch: 38, loss: 0.480596
global_step: 7500, epoch: 38, loss: 0.334351
global_step: 7501, epoch: 38, loss: 0.421706
global_step: 7502, epoch: 38, loss: 0.357697
global_step: 7503, epoch: 38, loss: 0.480802
global_step: 7504, epoch: 38, loss: 0.426137
global_step: 7505, epoch: 38, loss: 0.421743
global_step: 7506, epoch: 38, loss: 0.462624
global_step: 7507, epoch: 38, loss: 0.433239
global_step: 7508, epoch: 38, loss: 0.396993
global_step: 7509, epoch: 38, loss: 0.486622
global_step: 7510, epoch: 38, loss: 0.459820
global_step: 7511, epoch: 38, loss: 0.398913
global_step: 7512, epoch: 38, loss: 0.385758
global_step: 7513, epoch: 38, loss: 0.416633
global_step: 7514, epoch: 38, loss: 0.466319
global_step: 7515, epoch: 38, loss: 0.385893
global_step: 7516, epoch: 38, loss: 0.470311
global_step: 7517, epoch: 38, loss: 0.384554
global_step: 7518, epoch: 38, loss: 0.363070
global_step: 7519, epoch: 38, loss: 0.469483
global_step: 7520, epoch: 38, loss: 0.622261
epoch: 38
train	acc: 0.8903	macro: p 0.9126, r 0.8139, f1: 0.8485	micro: p 0.8903, r 0.8903, f1 0.8903	weighted_f1:0.8911
dev	acc: 0.5446	macro: p 0.4665, r 0.3416, f1: 0.3283	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4975
test	acc: 0.5659	macro: p 0.4076, r 0.3321, f1: 0.3198	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5351
global_step: 7521, epoch: 39, loss: 0.653192
global_step: 7522, epoch: 39, loss: 0.478023
global_step: 7523, epoch: 39, loss: 0.517341
global_step: 7524, epoch: 39, loss: 0.592951
global_step: 7525, epoch: 39, loss: 0.428574
global_step: 7526, epoch: 39, loss: 0.447740
global_step: 7527, epoch: 39, loss: 0.345476
global_step: 7528, epoch: 39, loss: 0.332699
global_step: 7529, epoch: 39, loss: 0.456825
global_step: 7530, epoch: 39, loss: 0.411911
global_step: 7531, epoch: 39, loss: 0.415127
global_step: 7532, epoch: 39, loss: 0.368436
global_step: 7533, epoch: 39, loss: 0.321962
global_step: 7534, epoch: 39, loss: 0.428764
global_step: 7535, epoch: 39, loss: 0.361054
global_step: 7536, epoch: 39, loss: 0.346654
global_step: 7537, epoch: 39, loss: 0.297917
global_step: 7538, epoch: 39, loss: 0.350222
global_step: 7539, epoch: 39, loss: 0.422898
global_step: 7540, epoch: 39, loss: 0.446667
global_step: 7541, epoch: 39, loss: 0.384975
global_step: 7542, epoch: 39, loss: 0.359830
global_step: 7543, epoch: 39, loss: 0.404443
global_step: 7544, epoch: 39, loss: 0.391433
global_step: 7545, epoch: 39, loss: 0.334766
global_step: 7546, epoch: 39, loss: 0.399366
global_step: 7547, epoch: 39, loss: 0.400206
global_step: 7548, epoch: 39, loss: 0.388838
global_step: 7549, epoch: 39, loss: 0.450258
global_step: 7550, epoch: 39, loss: 0.505177
global_step: 7551, epoch: 39, loss: 0.352388
global_step: 7552, epoch: 39, loss: 0.437001
global_step: 7553, epoch: 39, loss: 0.313776
global_step: 7554, epoch: 39, loss: 0.427007
global_step: 7555, epoch: 39, loss: 0.403610
global_step: 7556, epoch: 39, loss: 0.387211
global_step: 7557, epoch: 39, loss: 0.361480
global_step: 7558, epoch: 39, loss: 0.476022
global_step: 7559, epoch: 39, loss: 0.378069
global_step: 7560, epoch: 39, loss: 0.561363
epoch: 39
train	acc: 0.9221	macro: p 0.9507, r 0.8673, f1: 0.9046	micro: p 0.9221, r 0.9221, f1 0.9221	weighted_f1:0.9212
dev	acc: 0.5455	macro: p 0.4123, r 0.3243, f1: 0.3280	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4902
test	acc: 0.5912	macro: p 0.4360, r 0.3311, f1: 0.3443	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5465
global_step: 7561, epoch: 40, loss: 0.386973
global_step: 7562, epoch: 40, loss: 0.466491
global_step: 7563, epoch: 40, loss: 0.426612
global_step: 7564, epoch: 40, loss: 0.398722
global_step: 7565, epoch: 40, loss: 0.339021
global_step: 7566, epoch: 40, loss: 0.423746
global_step: 7567, epoch: 40, loss: 0.347807
global_step: 7568, epoch: 40, loss: 0.328710
global_step: 7569, epoch: 40, loss: 0.368542
global_step: 7570, epoch: 40, loss: 0.357682
global_step: 7571, epoch: 40, loss: 0.336627
global_step: 7572, epoch: 40, loss: 0.447218
global_step: 7573, epoch: 40, loss: 0.376948
global_step: 7574, epoch: 40, loss: 0.334667
global_step: 7575, epoch: 40, loss: 0.354655
global_step: 7576, epoch: 40, loss: 0.310986
global_step: 7577, epoch: 40, loss: 0.473426
global_step: 7578, epoch: 40, loss: 0.314653
global_step: 7579, epoch: 40, loss: 0.380965
global_step: 7580, epoch: 40, loss: 0.466338
global_step: 7581, epoch: 40, loss: 0.426846
global_step: 7582, epoch: 40, loss: 0.332099
global_step: 7583, epoch: 40, loss: 0.380071
global_step: 7584, epoch: 40, loss: 0.502802
global_step: 7585, epoch: 40, loss: 0.376249
global_step: 7586, epoch: 40, loss: 0.368845
global_step: 7587, epoch: 40, loss: 0.425139
global_step: 7588, epoch: 40, loss: 0.386451
global_step: 7589, epoch: 40, loss: 0.374121
global_step: 7590, epoch: 40, loss: 0.462519
global_step: 7591, epoch: 40, loss: 0.425848
global_step: 7592, epoch: 40, loss: 0.370301
global_step: 7593, epoch: 40, loss: 0.431422
global_step: 7594, epoch: 40, loss: 0.473694
global_step: 7595, epoch: 40, loss: 0.386834
global_step: 7596, epoch: 40, loss: 0.434734
global_step: 7597, epoch: 40, loss: 0.502542
global_step: 7598, epoch: 40, loss: 0.333539
global_step: 7599, epoch: 40, loss: 0.397340
global_step: 7600, epoch: 40, loss: 0.604636
epoch: 40
train	acc: 0.9350	macro: p 0.9410, r 0.8982, f1: 0.9166	micro: p 0.9350, r 0.9350, f1 0.9350	weighted_f1:0.9350
dev	acc: 0.5302	macro: p 0.3959, r 0.3522, f1: 0.3537	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.5078
test	acc: 0.5678	macro: p 0.3850, r 0.3601, f1: 0.3594	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5543
global_step: 7601, epoch: 41, loss: 0.404555
global_step: 7602, epoch: 41, loss: 0.351280
global_step: 7603, epoch: 41, loss: 0.377198
global_step: 7604, epoch: 41, loss: 0.353122
global_step: 7605, epoch: 41, loss: 0.310919
global_step: 7606, epoch: 41, loss: 0.347489
global_step: 7607, epoch: 41, loss: 0.347235
global_step: 7608, epoch: 41, loss: 0.500125
global_step: 7609, epoch: 41, loss: 0.323787
global_step: 7610, epoch: 41, loss: 0.324792
global_step: 7611, epoch: 41, loss: 0.312963
global_step: 7612, epoch: 41, loss: 0.338883
global_step: 7613, epoch: 41, loss: 0.325558
global_step: 7614, epoch: 41, loss: 0.457048
global_step: 7615, epoch: 41, loss: 0.297048
global_step: 7616, epoch: 41, loss: 0.425271
global_step: 7617, epoch: 41, loss: 0.367060
global_step: 7618, epoch: 41, loss: 0.377600
global_step: 7619, epoch: 41, loss: 0.391314
global_step: 7620, epoch: 41, loss: 0.418608
global_step: 7621, epoch: 41, loss: 0.416906
global_step: 7622, epoch: 41, loss: 0.327647
global_step: 7623, epoch: 41, loss: 0.461690
global_step: 7624, epoch: 41, loss: 0.423039
global_step: 7625, epoch: 41, loss: 0.394481
global_step: 7626, epoch: 41, loss: 0.280046
global_step: 7627, epoch: 41, loss: 0.324385
global_step: 7628, epoch: 41, loss: 0.435203
global_step: 7629, epoch: 41, loss: 0.406552
global_step: 7630, epoch: 41, loss: 0.336806
global_step: 7631, epoch: 41, loss: 0.461231
global_step: 7632, epoch: 41, loss: 0.379022
global_step: 7633, epoch: 41, loss: 0.431268
global_step: 7634, epoch: 41, loss: 0.440249
global_step: 7635, epoch: 41, loss: 0.391565
global_step: 7636, epoch: 41, loss: 0.415915
global_step: 7637, epoch: 41, loss: 0.406228
global_step: 7638, epoch: 41, loss: 0.372824
global_step: 7639, epoch: 41, loss: 0.485362
global_step: 7640, epoch: 41, loss: 0.155217
epoch: 41
train	acc: 0.9373	macro: p 0.9473, r 0.8981, f1: 0.9207	micro: p 0.9373, r 0.9373, f1 0.9373	weighted_f1:0.9369
dev	acc: 0.5374	macro: p 0.3755, r 0.3378, f1: 0.3411	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4978
test	acc: 0.5831	macro: p 0.3922, r 0.3463, f1: 0.3566	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5550
global_step: 7641, epoch: 42, loss: 0.368224
global_step: 7642, epoch: 42, loss: 0.466787
global_step: 7643, epoch: 42, loss: 0.320714
global_step: 7644, epoch: 42, loss: 0.371175
global_step: 7645, epoch: 42, loss: 0.374105
global_step: 7646, epoch: 42, loss: 0.398224
global_step: 7647, epoch: 42, loss: 0.327371
global_step: 7648, epoch: 42, loss: 0.323937
global_step: 7649, epoch: 42, loss: 0.334211
global_step: 7650, epoch: 42, loss: 0.418859
global_step: 7651, epoch: 42, loss: 0.383722
global_step: 7652, epoch: 42, loss: 0.278769
global_step: 7653, epoch: 42, loss: 0.419181
global_step: 7654, epoch: 42, loss: 0.331985
global_step: 7655, epoch: 42, loss: 0.315835
global_step: 7656, epoch: 42, loss: 0.296935
global_step: 7657, epoch: 42, loss: 0.452062
global_step: 7658, epoch: 42, loss: 0.360150
global_step: 7659, epoch: 42, loss: 0.298161
global_step: 7660, epoch: 42, loss: 0.407957
global_step: 7661, epoch: 42, loss: 0.357422
global_step: 7662, epoch: 42, loss: 0.398591
global_step: 7663, epoch: 42, loss: 0.368865
global_step: 7664, epoch: 42, loss: 0.426215
global_step: 7665, epoch: 42, loss: 0.376681
global_step: 7666, epoch: 42, loss: 0.496334
global_step: 7667, epoch: 42, loss: 0.343652
global_step: 7668, epoch: 42, loss: 0.442188
global_step: 7669, epoch: 42, loss: 0.361987
global_step: 7670, epoch: 42, loss: 0.310086
global_step: 7671, epoch: 42, loss: 0.406946
global_step: 7672, epoch: 42, loss: 0.343457
global_step: 7673, epoch: 42, loss: 0.324303
global_step: 7674, epoch: 42, loss: 0.473047
global_step: 7675, epoch: 42, loss: 0.348799
global_step: 7676, epoch: 42, loss: 0.470346
global_step: 7677, epoch: 42, loss: 0.340131
global_step: 7678, epoch: 42, loss: 0.434450
global_step: 7679, epoch: 42, loss: 0.420742
global_step: 7680, epoch: 42, loss: 0.033184
epoch: 42
train	acc: 0.9188	macro: p 0.9518, r 0.8592, f1: 0.9000	micro: p 0.9188, r 0.9188, f1 0.9188	weighted_f1:0.9178
dev	acc: 0.5419	macro: p 0.4298, r 0.3217, f1: 0.3351	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4887
test	acc: 0.5889	macro: p 0.4585, r 0.3219, f1: 0.3436	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5392
global_step: 7681, epoch: 43, loss: 0.449088
global_step: 7682, epoch: 43, loss: 0.518091
global_step: 7683, epoch: 43, loss: 0.401156
global_step: 7684, epoch: 43, loss: 0.293829
global_step: 7685, epoch: 43, loss: 0.340539
global_step: 7686, epoch: 43, loss: 0.328986
global_step: 7687, epoch: 43, loss: 0.257603
global_step: 7688, epoch: 43, loss: 0.297356
global_step: 7689, epoch: 43, loss: 0.441051
global_step: 7690, epoch: 43, loss: 0.328072
global_step: 7691, epoch: 43, loss: 0.300962
global_step: 7692, epoch: 43, loss: 0.366832
global_step: 7693, epoch: 43, loss: 0.387789
global_step: 7694, epoch: 43, loss: 0.385103
global_step: 7695, epoch: 43, loss: 0.436390
global_step: 7696, epoch: 43, loss: 0.341639
global_step: 7697, epoch: 43, loss: 0.373400
global_step: 7698, epoch: 43, loss: 0.394188
global_step: 7699, epoch: 43, loss: 0.394537
global_step: 7700, epoch: 43, loss: 0.372849
global_step: 7701, epoch: 43, loss: 0.366484
global_step: 7702, epoch: 43, loss: 0.355167
global_step: 7703, epoch: 43, loss: 0.342043
global_step: 7704, epoch: 43, loss: 0.363720
global_step: 7705, epoch: 43, loss: 0.352111
global_step: 7706, epoch: 43, loss: 0.348260
global_step: 7707, epoch: 43, loss: 0.431191
global_step: 7708, epoch: 43, loss: 0.475258
global_step: 7709, epoch: 43, loss: 0.426155
global_step: 7710, epoch: 43, loss: 0.333646
global_step: 7711, epoch: 43, loss: 0.427851
global_step: 7712, epoch: 43, loss: 0.416736
global_step: 7713, epoch: 43, loss: 0.367287
global_step: 7714, epoch: 43, loss: 0.304530
global_step: 7715, epoch: 43, loss: 0.342589
global_step: 7716, epoch: 43, loss: 0.428634
global_step: 7717, epoch: 43, loss: 0.438392
global_step: 7718, epoch: 43, loss: 0.377120
global_step: 7719, epoch: 43, loss: 0.230072
global_step: 7720, epoch: 43, loss: 0.506797
epoch: 43
train	acc: 0.9222	macro: p 0.9282, r 0.8768, f1: 0.8972	micro: p 0.9222, r 0.9222, f1 0.9222	weighted_f1:0.9225
dev	acc: 0.5221	macro: p 0.4150, r 0.3579, f1: 0.3548	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.5025
test	acc: 0.5483	macro: p 0.4104, r 0.3540, f1: 0.3527	micro: p 0.5483, r 0.5483, f1 0.5483	weighted_f1:0.5397
global_step: 7721, epoch: 44, loss: 0.440993
global_step: 7722, epoch: 44, loss: 0.488982
global_step: 7723, epoch: 44, loss: 0.409702
global_step: 7724, epoch: 44, loss: 0.394064
global_step: 7725, epoch: 44, loss: 0.406361
global_step: 7726, epoch: 44, loss: 0.445243
global_step: 7727, epoch: 44, loss: 0.363826
global_step: 7728, epoch: 44, loss: 0.378464
global_step: 7729, epoch: 44, loss: 0.339475
global_step: 7730, epoch: 44, loss: 0.388376
global_step: 7731, epoch: 44, loss: 0.386255
global_step: 7732, epoch: 44, loss: 0.407513
global_step: 7733, epoch: 44, loss: 0.357474
global_step: 7734, epoch: 44, loss: 0.337876
global_step: 7735, epoch: 44, loss: 0.330506
global_step: 7736, epoch: 44, loss: 0.327300
global_step: 7737, epoch: 44, loss: 0.348189
global_step: 7738, epoch: 44, loss: 0.430842
global_step: 7739, epoch: 44, loss: 0.407321
global_step: 7740, epoch: 44, loss: 0.406063
global_step: 7741, epoch: 44, loss: 0.310371
global_step: 7742, epoch: 44, loss: 0.337672
global_step: 7743, epoch: 44, loss: 0.326494
global_step: 7744, epoch: 44, loss: 0.482483
global_step: 7745, epoch: 44, loss: 0.336968
global_step: 7746, epoch: 44, loss: 0.453324
global_step: 7747, epoch: 44, loss: 0.346209
global_step: 7748, epoch: 44, loss: 0.326746
global_step: 7749, epoch: 44, loss: 0.344307
global_step: 7750, epoch: 44, loss: 0.357154
global_step: 7751, epoch: 44, loss: 0.402844
global_step: 7752, epoch: 44, loss: 0.411579
global_step: 7753, epoch: 44, loss: 0.413622
global_step: 7754, epoch: 44, loss: 0.305314
global_step: 7755, epoch: 44, loss: 0.362355
global_step: 7756, epoch: 44, loss: 0.395547
global_step: 7757, epoch: 44, loss: 0.365286
global_step: 7758, epoch: 44, loss: 0.354098
global_step: 7759, epoch: 44, loss: 0.382702
global_step: 7760, epoch: 44, loss: 0.041815
epoch: 44
train	acc: 0.9375	macro: p 0.9480, r 0.8947, f1: 0.9189	micro: p 0.9375, r 0.9375, f1 0.9375	weighted_f1:0.9371
dev	acc: 0.5573	macro: p 0.4467, r 0.3576, f1: 0.3773	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5225
test	acc: 0.5900	macro: p 0.4170, r 0.3381, f1: 0.3558	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5571
global_step: 7761, epoch: 45, loss: 0.402273
global_step: 7762, epoch: 45, loss: 0.286818
global_step: 7763, epoch: 45, loss: 0.303654
global_step: 7764, epoch: 45, loss: 0.393509
global_step: 7765, epoch: 45, loss: 0.332623
global_step: 7766, epoch: 45, loss: 0.374083
global_step: 7767, epoch: 45, loss: 0.413122
global_step: 7768, epoch: 45, loss: 0.299746
global_step: 7769, epoch: 45, loss: 0.331241
global_step: 7770, epoch: 45, loss: 0.328103
global_step: 7771, epoch: 45, loss: 0.386338
global_step: 7772, epoch: 45, loss: 0.355101
global_step: 7773, epoch: 45, loss: 0.382136
global_step: 7774, epoch: 45, loss: 0.285685
global_step: 7775, epoch: 45, loss: 0.320615
global_step: 7776, epoch: 45, loss: 0.344525
global_step: 7777, epoch: 45, loss: 0.312080
global_step: 7778, epoch: 45, loss: 0.397092
global_step: 7779, epoch: 45, loss: 0.303177
global_step: 7780, epoch: 45, loss: 0.420351
global_step: 7781, epoch: 45, loss: 0.321699
global_step: 7782, epoch: 45, loss: 0.298727
global_step: 7783, epoch: 45, loss: 0.351099
global_step: 7784, epoch: 45, loss: 0.384334
global_step: 7785, epoch: 45, loss: 0.411544
global_step: 7786, epoch: 45, loss: 0.396308
global_step: 7787, epoch: 45, loss: 0.329596
global_step: 7788, epoch: 45, loss: 0.308101
global_step: 7789, epoch: 45, loss: 0.243998
global_step: 7790, epoch: 45, loss: 0.329216
global_step: 7791, epoch: 45, loss: 0.360979
global_step: 7792, epoch: 45, loss: 0.403702
global_step: 7793, epoch: 45, loss: 0.367952
global_step: 7794, epoch: 45, loss: 0.373502
global_step: 7795, epoch: 45, loss: 0.351275
global_step: 7796, epoch: 45, loss: 0.418883
global_step: 7797, epoch: 45, loss: 0.382275
global_step: 7798, epoch: 45, loss: 0.428590
global_step: 7799, epoch: 45, loss: 0.413702
global_step: 7800, epoch: 45, loss: 1.230840
epoch: 45
train	acc: 0.9440	macro: p 0.9513, r 0.9113, f1: 0.9300	micro: p 0.9440, r 0.9440, f1 0.9440	weighted_f1:0.9438
dev	acc: 0.5473	macro: p 0.4005, r 0.3456, f1: 0.3575	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5136
test	acc: 0.5885	macro: p 0.4089, r 0.3474, f1: 0.3618	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5609
global_step: 7801, epoch: 46, loss: 0.323242
global_step: 7802, epoch: 46, loss: 0.341137
global_step: 7803, epoch: 46, loss: 0.387674
global_step: 7804, epoch: 46, loss: 0.414582
global_step: 7805, epoch: 46, loss: 0.355429
global_step: 7806, epoch: 46, loss: 0.345721
global_step: 7807, epoch: 46, loss: 0.274808
global_step: 7808, epoch: 46, loss: 0.297883
global_step: 7809, epoch: 46, loss: 0.343554
global_step: 7810, epoch: 46, loss: 0.381774
global_step: 7811, epoch: 46, loss: 0.323058
global_step: 7812, epoch: 46, loss: 0.274896
global_step: 7813, epoch: 46, loss: 0.406901
global_step: 7814, epoch: 46, loss: 0.370275
global_step: 7815, epoch: 46, loss: 0.320036
global_step: 7816, epoch: 46, loss: 0.304028
global_step: 7817, epoch: 46, loss: 0.413249
global_step: 7818, epoch: 46, loss: 0.417570
global_step: 7819, epoch: 46, loss: 0.263706
global_step: 7820, epoch: 46, loss: 0.302642
global_step: 7821, epoch: 46, loss: 0.328281
global_step: 7822, epoch: 46, loss: 0.351810
global_step: 7823, epoch: 46, loss: 0.321789
global_step: 7824, epoch: 46, loss: 0.328022
global_step: 7825, epoch: 46, loss: 0.365929
global_step: 7826, epoch: 46, loss: 0.304608
global_step: 7827, epoch: 46, loss: 0.343359
global_step: 7828, epoch: 46, loss: 0.488545
global_step: 7829, epoch: 46, loss: 0.357111
global_step: 7830, epoch: 46, loss: 0.409104
global_step: 7831, epoch: 46, loss: 0.381120
global_step: 7832, epoch: 46, loss: 0.335314
global_step: 7833, epoch: 46, loss: 0.360727
global_step: 7834, epoch: 46, loss: 0.379931
global_step: 7835, epoch: 46, loss: 0.303596
global_step: 7836, epoch: 46, loss: 0.368863
global_step: 7837, epoch: 46, loss: 0.348695
global_step: 7838, epoch: 46, loss: 0.334006
global_step: 7839, epoch: 46, loss: 0.311321
global_step: 7840, epoch: 46, loss: 0.920376
epoch: 46
train	acc: 0.9324	macro: p 0.9448, r 0.8805, f1: 0.9077	micro: p 0.9324, r 0.9324, f1 0.9324	weighted_f1:0.9318
dev	acc: 0.5455	macro: p 0.4395, r 0.3440, f1: 0.3516	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5122
test	acc: 0.5851	macro: p 0.4317, r 0.3502, f1: 0.3567	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5576
global_step: 7841, epoch: 47, loss: 0.502525
global_step: 7842, epoch: 47, loss: 0.470725
global_step: 7843, epoch: 47, loss: 0.328258
global_step: 7844, epoch: 47, loss: 0.367151
global_step: 7845, epoch: 47, loss: 0.345500
global_step: 7846, epoch: 47, loss: 0.313356
global_step: 7847, epoch: 47, loss: 0.255656
global_step: 7848, epoch: 47, loss: 0.299716
global_step: 7849, epoch: 47, loss: 0.365132
global_step: 7850, epoch: 47, loss: 0.361914
global_step: 7851, epoch: 47, loss: 0.358589
global_step: 7852, epoch: 47, loss: 0.365912
global_step: 7853, epoch: 47, loss: 0.307073
global_step: 7854, epoch: 47, loss: 0.335204
global_step: 7855, epoch: 47, loss: 0.299969
global_step: 7856, epoch: 47, loss: 0.326882
global_step: 7857, epoch: 47, loss: 0.366856
global_step: 7858, epoch: 47, loss: 0.259147
global_step: 7859, epoch: 47, loss: 0.322557
global_step: 7860, epoch: 47, loss: 0.417190
global_step: 7861, epoch: 47, loss: 0.289721
global_step: 7862, epoch: 47, loss: 0.358224
global_step: 7863, epoch: 47, loss: 0.342925
global_step: 7864, epoch: 47, loss: 0.365118
global_step: 7865, epoch: 47, loss: 0.312756
global_step: 7866, epoch: 47, loss: 0.417822
global_step: 7867, epoch: 47, loss: 0.309681
global_step: 7868, epoch: 47, loss: 0.310570
global_step: 7869, epoch: 47, loss: 0.384676
global_step: 7870, epoch: 47, loss: 0.481755
global_step: 7871, epoch: 47, loss: 0.361090
global_step: 7872, epoch: 47, loss: 0.361678
global_step: 7873, epoch: 47, loss: 0.286887
global_step: 7874, epoch: 47, loss: 0.322985
global_step: 7875, epoch: 47, loss: 0.397843
global_step: 7876, epoch: 47, loss: 0.278342
global_step: 7877, epoch: 47, loss: 0.358449
global_step: 7878, epoch: 47, loss: 0.275014
global_step: 7879, epoch: 47, loss: 0.345070
global_step: 7880, epoch: 47, loss: 0.000529
epoch: 47
train	acc: 0.9498	macro: p 0.9565, r 0.9256, f1: 0.9400	micro: p 0.9498, r 0.9498, f1 0.9498	weighted_f1:0.9498
dev	acc: 0.5410	macro: p 0.3744, r 0.3465, f1: 0.3489	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5080
test	acc: 0.5801	macro: p 0.3953, r 0.3576, f1: 0.3659	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5584
global_step: 7881, epoch: 48, loss: 0.271566
global_step: 7882, epoch: 48, loss: 0.285159
global_step: 7883, epoch: 48, loss: 0.327192
global_step: 7884, epoch: 48, loss: 0.434419
global_step: 7885, epoch: 48, loss: 0.298343
global_step: 7886, epoch: 48, loss: 0.343092
global_step: 7887, epoch: 48, loss: 0.258141
global_step: 7888, epoch: 48, loss: 0.242563
global_step: 7889, epoch: 48, loss: 0.306817
global_step: 7890, epoch: 48, loss: 0.396433
global_step: 7891, epoch: 48, loss: 0.274027
global_step: 7892, epoch: 48, loss: 0.296151
global_step: 7893, epoch: 48, loss: 0.372747
global_step: 7894, epoch: 48, loss: 0.288059
global_step: 7895, epoch: 48, loss: 0.314792
global_step: 7896, epoch: 48, loss: 0.318798
global_step: 7897, epoch: 48, loss: 0.354701
global_step: 7898, epoch: 48, loss: 0.384755
global_step: 7899, epoch: 48, loss: 0.312372
global_step: 7900, epoch: 48, loss: 0.380331
global_step: 7901, epoch: 48, loss: 0.372050
global_step: 7902, epoch: 48, loss: 0.310299
global_step: 7903, epoch: 48, loss: 0.336289
global_step: 7904, epoch: 48, loss: 0.374559
global_step: 7905, epoch: 48, loss: 0.350659
global_step: 7906, epoch: 48, loss: 0.362360
global_step: 7907, epoch: 48, loss: 0.355934
global_step: 7908, epoch: 48, loss: 0.421712
global_step: 7909, epoch: 48, loss: 0.333025
global_step: 7910, epoch: 48, loss: 0.325762
global_step: 7911, epoch: 48, loss: 0.448468
global_step: 7912, epoch: 48, loss: 0.350024
global_step: 7913, epoch: 48, loss: 0.378270
global_step: 7914, epoch: 48, loss: 0.417753
global_step: 7915, epoch: 48, loss: 0.402857
global_step: 7916, epoch: 48, loss: 0.388122
global_step: 7917, epoch: 48, loss: 0.313482
global_step: 7918, epoch: 48, loss: 0.373136
global_step: 7919, epoch: 48, loss: 0.455757
global_step: 7920, epoch: 48, loss: 0.296598
epoch: 48
train	acc: 0.9394	macro: p 0.9493, r 0.9020, f1: 0.9235	micro: p 0.9394, r 0.9394, f1 0.9394	weighted_f1:0.9389
dev	acc: 0.5266	macro: p 0.3613, r 0.3193, f1: 0.3185	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4815
test	acc: 0.5782	macro: p 0.3918, r 0.3371, f1: 0.3431	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5439
global_step: 7921, epoch: 49, loss: 0.347225
global_step: 7922, epoch: 49, loss: 0.326391
global_step: 7923, epoch: 49, loss: 0.285658
global_step: 7924, epoch: 49, loss: 0.346657
global_step: 7925, epoch: 49, loss: 0.334425
global_step: 7926, epoch: 49, loss: 0.317245
global_step: 7927, epoch: 49, loss: 0.348353
global_step: 7928, epoch: 49, loss: 0.368531
global_step: 7929, epoch: 49, loss: 0.377974
global_step: 7930, epoch: 49, loss: 0.320433
global_step: 7931, epoch: 49, loss: 0.398987
global_step: 7932, epoch: 49, loss: 0.257660
global_step: 7933, epoch: 49, loss: 0.265957
global_step: 7934, epoch: 49, loss: 0.314325
global_step: 7935, epoch: 49, loss: 0.379624
global_step: 7936, epoch: 49, loss: 0.353839
global_step: 7937, epoch: 49, loss: 0.401708
global_step: 7938, epoch: 49, loss: 0.383831
global_step: 7939, epoch: 49, loss: 0.366396
global_step: 7940, epoch: 49, loss: 0.325844
global_step: 7941, epoch: 49, loss: 0.341166
global_step: 7942, epoch: 49, loss: 0.415820
global_step: 7943, epoch: 49, loss: 0.388631
global_step: 7944, epoch: 49, loss: 0.355048
global_step: 7945, epoch: 49, loss: 0.335220
global_step: 7946, epoch: 49, loss: 0.422851
global_step: 7947, epoch: 49, loss: 0.330565
global_step: 7948, epoch: 49, loss: 0.286448
global_step: 7949, epoch: 49, loss: 0.334315
global_step: 7950, epoch: 49, loss: 0.276045
global_step: 7951, epoch: 49, loss: 0.271529
global_step: 7952, epoch: 49, loss: 0.362906
global_step: 7953, epoch: 49, loss: 0.356004
global_step: 7954, epoch: 49, loss: 0.344711
global_step: 7955, epoch: 49, loss: 0.303194
global_step: 7956, epoch: 49, loss: 0.369487
global_step: 7957, epoch: 49, loss: 0.367478
global_step: 7958, epoch: 49, loss: 0.369747
global_step: 7959, epoch: 49, loss: 0.337632
global_step: 7960, epoch: 49, loss: 0.454982
epoch: 49
train	acc: 0.9412	macro: p 0.9444, r 0.9163, f1: 0.9282	micro: p 0.9412, r 0.9412, f1 0.9412	weighted_f1:0.9416
dev	acc: 0.5338	macro: p 0.4088, r 0.3398, f1: 0.3499	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.5071
test	acc: 0.5716	macro: p 0.4074, r 0.3569, f1: 0.3612	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5556
global_step: 7961, epoch: 50, loss: 0.362995
global_step: 7962, epoch: 50, loss: 0.357289
global_step: 7963, epoch: 50, loss: 0.276872
global_step: 7964, epoch: 50, loss: 0.397695
global_step: 7965, epoch: 50, loss: 0.329508
global_step: 7966, epoch: 50, loss: 0.388585
global_step: 7967, epoch: 50, loss: 0.301056
global_step: 7968, epoch: 50, loss: 0.320025
global_step: 7969, epoch: 50, loss: 0.336104
global_step: 7970, epoch: 50, loss: 0.341453
global_step: 7971, epoch: 50, loss: 0.330997
global_step: 7972, epoch: 50, loss: 0.251416
global_step: 7973, epoch: 50, loss: 0.380722
global_step: 7974, epoch: 50, loss: 0.394708
global_step: 7975, epoch: 50, loss: 0.326165
global_step: 7976, epoch: 50, loss: 0.318292
global_step: 7977, epoch: 50, loss: 0.355046
global_step: 7978, epoch: 50, loss: 0.299607
global_step: 7979, epoch: 50, loss: 0.301888
global_step: 7980, epoch: 50, loss: 0.279724
global_step: 7981, epoch: 50, loss: 0.243615
global_step: 7982, epoch: 50, loss: 0.296434
global_step: 7983, epoch: 50, loss: 0.294806
global_step: 7984, epoch: 50, loss: 0.365749
global_step: 7985, epoch: 50, loss: 0.294290
global_step: 7986, epoch: 50, loss: 0.372106
global_step: 7987, epoch: 50, loss: 0.381482
global_step: 7988, epoch: 50, loss: 0.323050
global_step: 7989, epoch: 50, loss: 0.318852
global_step: 7990, epoch: 50, loss: 0.370980
global_step: 7991, epoch: 50, loss: 0.304846
global_step: 7992, epoch: 50, loss: 0.408084
global_step: 7993, epoch: 50, loss: 0.323935
global_step: 7994, epoch: 50, loss: 0.317084
global_step: 7995, epoch: 50, loss: 0.342040
global_step: 7996, epoch: 50, loss: 0.303950
global_step: 7997, epoch: 50, loss: 0.331676
global_step: 7998, epoch: 50, loss: 0.284614
global_step: 7999, epoch: 50, loss: 0.268586
global_step: 8000, epoch: 50, loss: 0.523917
epoch: 50
train	acc: 0.9499	macro: p 0.9500, r 0.9289, f1: 0.9387	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9500
dev	acc: 0.5293	macro: p 0.3787, r 0.3490, f1: 0.3540	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.5109
test	acc: 0.5628	macro: p 0.3937, r 0.3669, f1: 0.3722	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5536
BEST MODEL epoch: 21
train	acc: 0.8466 macro_p: 0.8402 macro_r: 0.7121 macro_f1: 0.7476 micro_p: 0.8466 micro_r: 0.8466 micro_f1: 0.8466 weighted_f1: 0.8417
dev	acc: 0.5618 macro_p: 0.3746 macro_r: 0.3574 macro_f1: 0.3545 micro_p: 0.5618 micro_r: 0.5618 micro_f1: 0.5618 weighted_f1: 0.5332
test	acc: 0.5900 macro_p: 0.3982 macro_r: 0.3600 macro_f1: 0.3627 micro_p: 0.5900 micro_r: 0.5900 micro_f1: 0.5900 weighted_f1: 0.5700
==========ROUND 5==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 8001, epoch: 1, loss: 1.924595
global_step: 8002, epoch: 1, loss: 1.837153
global_step: 8003, epoch: 1, loss: 1.755246
global_step: 8004, epoch: 1, loss: 1.666389
global_step: 8005, epoch: 1, loss: 1.549112
global_step: 8006, epoch: 1, loss: 1.529584
global_step: 8007, epoch: 1, loss: 1.548561
global_step: 8008, epoch: 1, loss: 1.449201
global_step: 8009, epoch: 1, loss: 1.522429
global_step: 8010, epoch: 1, loss: 1.557612
global_step: 8011, epoch: 1, loss: 1.529912
global_step: 8012, epoch: 1, loss: 1.494570
global_step: 8013, epoch: 1, loss: 1.465192
global_step: 8014, epoch: 1, loss: 1.479069
global_step: 8015, epoch: 1, loss: 1.532982
global_step: 8016, epoch: 1, loss: 1.551205
global_step: 8017, epoch: 1, loss: 1.445523
global_step: 8018, epoch: 1, loss: 1.458588
global_step: 8019, epoch: 1, loss: 1.474660
global_step: 8020, epoch: 1, loss: 1.492510
global_step: 8021, epoch: 1, loss: 1.448466
global_step: 8022, epoch: 1, loss: 1.432971
global_step: 8023, epoch: 1, loss: 1.372535
global_step: 8024, epoch: 1, loss: 1.520296
global_step: 8025, epoch: 1, loss: 1.456924
global_step: 8026, epoch: 1, loss: 1.460130
global_step: 8027, epoch: 1, loss: 1.437490
global_step: 8028, epoch: 1, loss: 1.475928
global_step: 8029, epoch: 1, loss: 1.372912
global_step: 8030, epoch: 1, loss: 1.344684
global_step: 8031, epoch: 1, loss: 1.443062
global_step: 8032, epoch: 1, loss: 1.517807
global_step: 8033, epoch: 1, loss: 1.421579
global_step: 8034, epoch: 1, loss: 1.274667
global_step: 8035, epoch: 1, loss: 1.267977
global_step: 8036, epoch: 1, loss: 1.364518
global_step: 8037, epoch: 1, loss: 1.359794
global_step: 8038, epoch: 1, loss: 1.419578
global_step: 8039, epoch: 1, loss: 1.311102
global_step: 8040, epoch: 1, loss: 1.527047
epoch: 1
train	acc: 0.5376	macro: p 0.3273, r 0.2495, f1: 0.2132	micro: p 0.5376, r 0.5376, f1 0.5376	weighted_f1:0.4512
dev	acc: 0.5023	macro: p 0.3200, r 0.2402, f1: 0.2083	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4087
test	acc: 0.5644	macro: p 0.3412, r 0.2572, f1: 0.2318	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.4823
New best model!
global_step: 8041, epoch: 2, loss: 1.377771
global_step: 8042, epoch: 2, loss: 1.456108
global_step: 8043, epoch: 2, loss: 1.421816
global_step: 8044, epoch: 2, loss: 1.359377
global_step: 8045, epoch: 2, loss: 1.409780
global_step: 8046, epoch: 2, loss: 1.238225
global_step: 8047, epoch: 2, loss: 1.287681
global_step: 8048, epoch: 2, loss: 1.383018
global_step: 8049, epoch: 2, loss: 1.283722
global_step: 8050, epoch: 2, loss: 1.291916
global_step: 8051, epoch: 2, loss: 1.357401
global_step: 8052, epoch: 2, loss: 1.317648
global_step: 8053, epoch: 2, loss: 1.327530
global_step: 8054, epoch: 2, loss: 1.266894
global_step: 8055, epoch: 2, loss: 1.443418
global_step: 8056, epoch: 2, loss: 1.419470
global_step: 8057, epoch: 2, loss: 1.430068
global_step: 8058, epoch: 2, loss: 1.422811
global_step: 8059, epoch: 2, loss: 1.194325
global_step: 8060, epoch: 2, loss: 1.318884
global_step: 8061, epoch: 2, loss: 1.255836
global_step: 8062, epoch: 2, loss: 1.201545
global_step: 8063, epoch: 2, loss: 1.263569
global_step: 8064, epoch: 2, loss: 1.280065
global_step: 8065, epoch: 2, loss: 1.386303
global_step: 8066, epoch: 2, loss: 1.447064
global_step: 8067, epoch: 2, loss: 1.280069
global_step: 8068, epoch: 2, loss: 1.280542
global_step: 8069, epoch: 2, loss: 1.364406
global_step: 8070, epoch: 2, loss: 1.340079
global_step: 8071, epoch: 2, loss: 1.317612
global_step: 8072, epoch: 2, loss: 1.269773
global_step: 8073, epoch: 2, loss: 1.172129
global_step: 8074, epoch: 2, loss: 1.295344
global_step: 8075, epoch: 2, loss: 1.362847
global_step: 8076, epoch: 2, loss: 1.387286
global_step: 8077, epoch: 2, loss: 1.251383
global_step: 8078, epoch: 2, loss: 1.211013
global_step: 8079, epoch: 2, loss: 1.441800
global_step: 8080, epoch: 2, loss: 1.397947
epoch: 2
train	acc: 0.5402	macro: p 0.3099, r 0.2464, f1: 0.2006	micro: p 0.5402, r 0.5402, f1 0.5402	weighted_f1:0.4584
dev	acc: 0.4725	macro: p 0.2084, r 0.2367, f1: 0.1740	micro: p 0.4725, r 0.4725, f1 0.4725	weighted_f1:0.3768
test	acc: 0.5199	macro: p 0.3211, r 0.2436, f1: 0.1917	micro: p 0.5199, r 0.5199, f1 0.5199	weighted_f1:0.4420
global_step: 8081, epoch: 3, loss: 1.410218
global_step: 8082, epoch: 3, loss: 1.252603
global_step: 8083, epoch: 3, loss: 1.298670
global_step: 8084, epoch: 3, loss: 1.433466
global_step: 8085, epoch: 3, loss: 1.422368
global_step: 8086, epoch: 3, loss: 1.247446
global_step: 8087, epoch: 3, loss: 1.212369
global_step: 8088, epoch: 3, loss: 1.186854
global_step: 8089, epoch: 3, loss: 1.173129
global_step: 8090, epoch: 3, loss: 1.200161
global_step: 8091, epoch: 3, loss: 1.411158
global_step: 8092, epoch: 3, loss: 1.293343
global_step: 8093, epoch: 3, loss: 1.370987
global_step: 8094, epoch: 3, loss: 1.361824
global_step: 8095, epoch: 3, loss: 1.415552
global_step: 8096, epoch: 3, loss: 1.198308
global_step: 8097, epoch: 3, loss: 1.337798
global_step: 8098, epoch: 3, loss: 1.321749
global_step: 8099, epoch: 3, loss: 1.286866
global_step: 8100, epoch: 3, loss: 1.307298
global_step: 8101, epoch: 3, loss: 1.189150
global_step: 8102, epoch: 3, loss: 1.187963
global_step: 8103, epoch: 3, loss: 1.192468
global_step: 8104, epoch: 3, loss: 1.211027
global_step: 8105, epoch: 3, loss: 1.171708
global_step: 8106, epoch: 3, loss: 1.290593
global_step: 8107, epoch: 3, loss: 1.251001
global_step: 8108, epoch: 3, loss: 1.253832
global_step: 8109, epoch: 3, loss: 1.265122
global_step: 8110, epoch: 3, loss: 1.225678
global_step: 8111, epoch: 3, loss: 1.255721
global_step: 8112, epoch: 3, loss: 1.340795
global_step: 8113, epoch: 3, loss: 1.324258
global_step: 8114, epoch: 3, loss: 1.345793
global_step: 8115, epoch: 3, loss: 1.243418
global_step: 8116, epoch: 3, loss: 1.201907
global_step: 8117, epoch: 3, loss: 1.242594
global_step: 8118, epoch: 3, loss: 1.251879
global_step: 8119, epoch: 3, loss: 1.280544
global_step: 8120, epoch: 3, loss: 1.005589
epoch: 3
train	acc: 0.5494	macro: p 0.2686, r 0.2429, f1: 0.1940	micro: p 0.5494, r 0.5494, f1 0.5494	weighted_f1:0.4552
dev	acc: 0.4914	macro: p 0.2586, r 0.2414, f1: 0.1800	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.3850
test	acc: 0.5349	macro: p 0.2834, r 0.2406, f1: 0.1867	micro: p 0.5349, r 0.5349, f1 0.5349	weighted_f1:0.4428
global_step: 8121, epoch: 4, loss: 1.396791
global_step: 8122, epoch: 4, loss: 1.151156
global_step: 8123, epoch: 4, loss: 1.262591
global_step: 8124, epoch: 4, loss: 1.151341
global_step: 8125, epoch: 4, loss: 1.339699
global_step: 8126, epoch: 4, loss: 1.192048
global_step: 8127, epoch: 4, loss: 1.219616
global_step: 8128, epoch: 4, loss: 1.109296
global_step: 8129, epoch: 4, loss: 1.442012
global_step: 8130, epoch: 4, loss: 1.260589
global_step: 8131, epoch: 4, loss: 1.208904
global_step: 8132, epoch: 4, loss: 1.075393
global_step: 8133, epoch: 4, loss: 1.336187
global_step: 8134, epoch: 4, loss: 1.240456
global_step: 8135, epoch: 4, loss: 1.272792
global_step: 8136, epoch: 4, loss: 1.248261
global_step: 8137, epoch: 4, loss: 1.212156
global_step: 8138, epoch: 4, loss: 1.134059
global_step: 8139, epoch: 4, loss: 1.135600
global_step: 8140, epoch: 4, loss: 1.191361
global_step: 8141, epoch: 4, loss: 1.283052
global_step: 8142, epoch: 4, loss: 1.214430
global_step: 8143, epoch: 4, loss: 1.214316
global_step: 8144, epoch: 4, loss: 1.283842
global_step: 8145, epoch: 4, loss: 1.353685
global_step: 8146, epoch: 4, loss: 1.320779
global_step: 8147, epoch: 4, loss: 1.250525
global_step: 8148, epoch: 4, loss: 1.285334
global_step: 8149, epoch: 4, loss: 1.116314
global_step: 8150, epoch: 4, loss: 1.156973
global_step: 8151, epoch: 4, loss: 1.218375
global_step: 8152, epoch: 4, loss: 1.307599
global_step: 8153, epoch: 4, loss: 1.204503
global_step: 8154, epoch: 4, loss: 1.252861
global_step: 8155, epoch: 4, loss: 1.243251
global_step: 8156, epoch: 4, loss: 1.088113
global_step: 8157, epoch: 4, loss: 1.198121
global_step: 8158, epoch: 4, loss: 1.337655
global_step: 8159, epoch: 4, loss: 1.285673
global_step: 8160, epoch: 4, loss: 2.894260
epoch: 4
train	acc: 0.5380	macro: p 0.3580, r 0.3387, f1: 0.3085	micro: p 0.5380, r 0.5380, f1 0.5380	weighted_f1:0.5245
dev	acc: 0.4950	macro: p 0.3450, r 0.3159, f1: 0.2895	micro: p 0.4950, r 0.4950, f1 0.4950	weighted_f1:0.4686
test	acc: 0.5034	macro: p 0.3262, r 0.3162, f1: 0.2823	micro: p 0.5034, r 0.5034, f1 0.5034	weighted_f1:0.4946
New best model!
global_step: 8161, epoch: 5, loss: 1.429361
global_step: 8162, epoch: 5, loss: 1.254658
global_step: 8163, epoch: 5, loss: 1.280063
global_step: 8164, epoch: 5, loss: 1.118811
global_step: 8165, epoch: 5, loss: 1.183747
global_step: 8166, epoch: 5, loss: 1.130034
global_step: 8167, epoch: 5, loss: 1.184264
global_step: 8168, epoch: 5, loss: 1.182976
global_step: 8169, epoch: 5, loss: 1.183327
global_step: 8170, epoch: 5, loss: 1.144838
global_step: 8171, epoch: 5, loss: 1.175952
global_step: 8172, epoch: 5, loss: 1.210620
global_step: 8173, epoch: 5, loss: 1.281636
global_step: 8174, epoch: 5, loss: 1.174920
global_step: 8175, epoch: 5, loss: 1.048595
global_step: 8176, epoch: 5, loss: 1.250632
global_step: 8177, epoch: 5, loss: 1.121556
global_step: 8178, epoch: 5, loss: 1.179097
global_step: 8179, epoch: 5, loss: 1.141269
global_step: 8180, epoch: 5, loss: 1.255073
global_step: 8181, epoch: 5, loss: 1.204020
global_step: 8182, epoch: 5, loss: 1.205391
global_step: 8183, epoch: 5, loss: 1.174805
global_step: 8184, epoch: 5, loss: 1.099475
global_step: 8185, epoch: 5, loss: 1.107852
global_step: 8186, epoch: 5, loss: 1.161073
global_step: 8187, epoch: 5, loss: 1.134512
global_step: 8188, epoch: 5, loss: 1.185453
global_step: 8189, epoch: 5, loss: 1.208225
global_step: 8190, epoch: 5, loss: 1.100100
global_step: 8191, epoch: 5, loss: 1.134405
global_step: 8192, epoch: 5, loss: 1.173728
global_step: 8193, epoch: 5, loss: 1.105680
global_step: 8194, epoch: 5, loss: 1.138905
global_step: 8195, epoch: 5, loss: 1.205133
global_step: 8196, epoch: 5, loss: 1.257545
global_step: 8197, epoch: 5, loss: 1.320694
global_step: 8198, epoch: 5, loss: 1.123302
global_step: 8199, epoch: 5, loss: 1.319236
global_step: 8200, epoch: 5, loss: 1.597436
epoch: 5
train	acc: 0.6197	macro: p 0.4097, r 0.3403, f1: 0.3435	micro: p 0.6197, r 0.6197, f1 0.6197	weighted_f1:0.5761
dev	acc: 0.5555	macro: p 0.3626, r 0.3116, f1: 0.3077	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5028
test	acc: 0.6038	macro: p 0.3865, r 0.3200, f1: 0.3228	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5601
New best model!
global_step: 8201, epoch: 6, loss: 1.238390
global_step: 8202, epoch: 6, loss: 1.124517
global_step: 8203, epoch: 6, loss: 1.195727
global_step: 8204, epoch: 6, loss: 1.098461
global_step: 8205, epoch: 6, loss: 1.201452
global_step: 8206, epoch: 6, loss: 1.199818
global_step: 8207, epoch: 6, loss: 1.139017
global_step: 8208, epoch: 6, loss: 1.085119
global_step: 8209, epoch: 6, loss: 1.206589
global_step: 8210, epoch: 6, loss: 1.187254
global_step: 8211, epoch: 6, loss: 1.171724
global_step: 8212, epoch: 6, loss: 1.108890
global_step: 8213, epoch: 6, loss: 1.135115
global_step: 8214, epoch: 6, loss: 1.224435
global_step: 8215, epoch: 6, loss: 1.130018
global_step: 8216, epoch: 6, loss: 1.346714
global_step: 8217, epoch: 6, loss: 0.948868
global_step: 8218, epoch: 6, loss: 1.132979
global_step: 8219, epoch: 6, loss: 1.259952
global_step: 8220, epoch: 6, loss: 1.106376
global_step: 8221, epoch: 6, loss: 1.173993
global_step: 8222, epoch: 6, loss: 1.136943
global_step: 8223, epoch: 6, loss: 1.139885
global_step: 8224, epoch: 6, loss: 1.136973
global_step: 8225, epoch: 6, loss: 1.116676
global_step: 8226, epoch: 6, loss: 1.214297
global_step: 8227, epoch: 6, loss: 1.048259
global_step: 8228, epoch: 6, loss: 1.113474
global_step: 8229, epoch: 6, loss: 1.085450
global_step: 8230, epoch: 6, loss: 1.132911
global_step: 8231, epoch: 6, loss: 1.294879
global_step: 8232, epoch: 6, loss: 1.153346
global_step: 8233, epoch: 6, loss: 1.234783
global_step: 8234, epoch: 6, loss: 1.252813
global_step: 8235, epoch: 6, loss: 1.220858
global_step: 8236, epoch: 6, loss: 1.196551
global_step: 8237, epoch: 6, loss: 1.065223
global_step: 8238, epoch: 6, loss: 1.131331
global_step: 8239, epoch: 6, loss: 1.053647
global_step: 8240, epoch: 6, loss: 1.232587
epoch: 6
train	acc: 0.6228	macro: p 0.4319, r 0.3213, f1: 0.3317	micro: p 0.6228, r 0.6228, f1 0.6228	weighted_f1:0.5654
dev	acc: 0.5528	macro: p 0.4427, r 0.2915, f1: 0.2900	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4844
test	acc: 0.6138	macro: p 0.4012, r 0.3062, f1: 0.3149	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5531
global_step: 8241, epoch: 7, loss: 1.374760
global_step: 8242, epoch: 7, loss: 1.236762
global_step: 8243, epoch: 7, loss: 1.195521
global_step: 8244, epoch: 7, loss: 1.224918
global_step: 8245, epoch: 7, loss: 0.953244
global_step: 8246, epoch: 7, loss: 1.175817
global_step: 8247, epoch: 7, loss: 1.215631
global_step: 8248, epoch: 7, loss: 1.246152
global_step: 8249, epoch: 7, loss: 1.046553
global_step: 8250, epoch: 7, loss: 1.062521
global_step: 8251, epoch: 7, loss: 1.067641
global_step: 8252, epoch: 7, loss: 1.074726
global_step: 8253, epoch: 7, loss: 1.117704
global_step: 8254, epoch: 7, loss: 1.086643
global_step: 8255, epoch: 7, loss: 1.105361
global_step: 8256, epoch: 7, loss: 0.979569
global_step: 8257, epoch: 7, loss: 1.205700
global_step: 8258, epoch: 7, loss: 1.202213
global_step: 8259, epoch: 7, loss: 1.033079
global_step: 8260, epoch: 7, loss: 1.103738
global_step: 8261, epoch: 7, loss: 1.165118
global_step: 8262, epoch: 7, loss: 1.147325
global_step: 8263, epoch: 7, loss: 1.144477
global_step: 8264, epoch: 7, loss: 1.123486
global_step: 8265, epoch: 7, loss: 1.042322
global_step: 8266, epoch: 7, loss: 1.193908
global_step: 8267, epoch: 7, loss: 1.208318
global_step: 8268, epoch: 7, loss: 1.224656
global_step: 8269, epoch: 7, loss: 1.245021
global_step: 8270, epoch: 7, loss: 1.123197
global_step: 8271, epoch: 7, loss: 1.123037
global_step: 8272, epoch: 7, loss: 1.157245
global_step: 8273, epoch: 7, loss: 1.208974
global_step: 8274, epoch: 7, loss: 0.971842
global_step: 8275, epoch: 7, loss: 1.078895
global_step: 8276, epoch: 7, loss: 1.187870
global_step: 8277, epoch: 7, loss: 1.021908
global_step: 8278, epoch: 7, loss: 1.230044
global_step: 8279, epoch: 7, loss: 1.265322
global_step: 8280, epoch: 7, loss: 2.542458
epoch: 7
train	acc: 0.6175	macro: p 0.4412, r 0.3270, f1: 0.3134	micro: p 0.6175, r 0.6175, f1 0.6175	weighted_f1:0.5523
dev	acc: 0.5509	macro: p 0.4041, r 0.3028, f1: 0.2795	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4732
test	acc: 0.5789	macro: p 0.3758, r 0.2935, f1: 0.2682	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5075
global_step: 8281, epoch: 8, loss: 1.150434
global_step: 8282, epoch: 8, loss: 1.090217
global_step: 8283, epoch: 8, loss: 0.980840
global_step: 8284, epoch: 8, loss: 1.185556
global_step: 8285, epoch: 8, loss: 1.109593
global_step: 8286, epoch: 8, loss: 1.120506
global_step: 8287, epoch: 8, loss: 1.147290
global_step: 8288, epoch: 8, loss: 1.166728
global_step: 8289, epoch: 8, loss: 1.165142
global_step: 8290, epoch: 8, loss: 1.152025
global_step: 8291, epoch: 8, loss: 1.032104
global_step: 8292, epoch: 8, loss: 1.182577
global_step: 8293, epoch: 8, loss: 1.025471
global_step: 8294, epoch: 8, loss: 1.041222
global_step: 8295, epoch: 8, loss: 1.122782
global_step: 8296, epoch: 8, loss: 1.156811
global_step: 8297, epoch: 8, loss: 1.054767
global_step: 8298, epoch: 8, loss: 1.006644
global_step: 8299, epoch: 8, loss: 0.995575
global_step: 8300, epoch: 8, loss: 1.122945
global_step: 8301, epoch: 8, loss: 1.171406
global_step: 8302, epoch: 8, loss: 1.070943
global_step: 8303, epoch: 8, loss: 1.012546
global_step: 8304, epoch: 8, loss: 1.188062
global_step: 8305, epoch: 8, loss: 1.099114
global_step: 8306, epoch: 8, loss: 1.169255
global_step: 8307, epoch: 8, loss: 1.001478
global_step: 8308, epoch: 8, loss: 1.033409
global_step: 8309, epoch: 8, loss: 1.164755
global_step: 8310, epoch: 8, loss: 1.039444
global_step: 8311, epoch: 8, loss: 1.121933
global_step: 8312, epoch: 8, loss: 1.119493
global_step: 8313, epoch: 8, loss: 1.339227
global_step: 8314, epoch: 8, loss: 1.211873
global_step: 8315, epoch: 8, loss: 1.117919
global_step: 8316, epoch: 8, loss: 1.057279
global_step: 8317, epoch: 8, loss: 1.197443
global_step: 8318, epoch: 8, loss: 1.108742
global_step: 8319, epoch: 8, loss: 0.910142
global_step: 8320, epoch: 8, loss: 1.758480
epoch: 8
train	acc: 0.6466	macro: p 0.4539, r 0.3767, f1: 0.3740	micro: p 0.6466, r 0.6466, f1 0.6466	weighted_f1:0.6149
dev	acc: 0.5564	macro: p 0.3865, r 0.3186, f1: 0.3161	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5132
test	acc: 0.6080	macro: p 0.4183, r 0.3360, f1: 0.3342	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5714
New best model!
global_step: 8321, epoch: 9, loss: 1.103975
global_step: 8322, epoch: 9, loss: 1.064894
global_step: 8323, epoch: 9, loss: 1.008652
global_step: 8324, epoch: 9, loss: 1.092566
global_step: 8325, epoch: 9, loss: 1.135719
global_step: 8326, epoch: 9, loss: 1.039487
global_step: 8327, epoch: 9, loss: 0.969106
global_step: 8328, epoch: 9, loss: 1.040653
global_step: 8329, epoch: 9, loss: 0.973666
global_step: 8330, epoch: 9, loss: 1.157799
global_step: 8331, epoch: 9, loss: 1.163752
global_step: 8332, epoch: 9, loss: 0.948034
global_step: 8333, epoch: 9, loss: 1.013783
global_step: 8334, epoch: 9, loss: 1.105193
global_step: 8335, epoch: 9, loss: 0.971816
global_step: 8336, epoch: 9, loss: 1.124938
global_step: 8337, epoch: 9, loss: 0.972710
global_step: 8338, epoch: 9, loss: 1.052267
global_step: 8339, epoch: 9, loss: 1.123705
global_step: 8340, epoch: 9, loss: 1.085768
global_step: 8341, epoch: 9, loss: 1.106885
global_step: 8342, epoch: 9, loss: 0.968523
global_step: 8343, epoch: 9, loss: 0.995310
global_step: 8344, epoch: 9, loss: 1.143632
global_step: 8345, epoch: 9, loss: 1.039695
global_step: 8346, epoch: 9, loss: 1.086698
global_step: 8347, epoch: 9, loss: 1.083687
global_step: 8348, epoch: 9, loss: 1.141878
global_step: 8349, epoch: 9, loss: 1.160363
global_step: 8350, epoch: 9, loss: 1.193775
global_step: 8351, epoch: 9, loss: 1.123556
global_step: 8352, epoch: 9, loss: 1.123045
global_step: 8353, epoch: 9, loss: 1.131555
global_step: 8354, epoch: 9, loss: 1.176741
global_step: 8355, epoch: 9, loss: 1.042027
global_step: 8356, epoch: 9, loss: 1.083181
global_step: 8357, epoch: 9, loss: 1.040947
global_step: 8358, epoch: 9, loss: 1.054273
global_step: 8359, epoch: 9, loss: 1.052923
global_step: 8360, epoch: 9, loss: 0.652126
epoch: 9
train	acc: 0.6307	macro: p 0.4792, r 0.3277, f1: 0.3304	micro: p 0.6307, r 0.6307, f1 0.6307	weighted_f1:0.5721
dev	acc: 0.5500	macro: p 0.3173, r 0.2843, f1: 0.2770	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4769
test	acc: 0.6153	macro: p 0.4941, r 0.3048, f1: 0.3074	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5524
global_step: 8361, epoch: 10, loss: 1.184013
global_step: 8362, epoch: 10, loss: 1.059682
global_step: 8363, epoch: 10, loss: 1.117879
global_step: 8364, epoch: 10, loss: 1.095471
global_step: 8365, epoch: 10, loss: 0.986440
global_step: 8366, epoch: 10, loss: 0.974671
global_step: 8367, epoch: 10, loss: 1.131273
global_step: 8368, epoch: 10, loss: 1.086855
global_step: 8369, epoch: 10, loss: 0.987184
global_step: 8370, epoch: 10, loss: 1.072430
global_step: 8371, epoch: 10, loss: 1.098258
global_step: 8372, epoch: 10, loss: 0.927714
global_step: 8373, epoch: 10, loss: 1.009608
global_step: 8374, epoch: 10, loss: 1.071119
global_step: 8375, epoch: 10, loss: 1.063112
global_step: 8376, epoch: 10, loss: 1.029488
global_step: 8377, epoch: 10, loss: 0.983271
global_step: 8378, epoch: 10, loss: 1.076003
global_step: 8379, epoch: 10, loss: 1.013406
global_step: 8380, epoch: 10, loss: 0.914016
global_step: 8381, epoch: 10, loss: 0.983345
global_step: 8382, epoch: 10, loss: 1.030995
global_step: 8383, epoch: 10, loss: 0.889227
global_step: 8384, epoch: 10, loss: 1.014853
global_step: 8385, epoch: 10, loss: 1.028258
global_step: 8386, epoch: 10, loss: 1.069758
global_step: 8387, epoch: 10, loss: 1.055387
global_step: 8388, epoch: 10, loss: 1.047588
global_step: 8389, epoch: 10, loss: 1.104248
global_step: 8390, epoch: 10, loss: 1.095355
global_step: 8391, epoch: 10, loss: 1.167637
global_step: 8392, epoch: 10, loss: 1.123430
global_step: 8393, epoch: 10, loss: 1.133969
global_step: 8394, epoch: 10, loss: 1.013946
global_step: 8395, epoch: 10, loss: 1.076837
global_step: 8396, epoch: 10, loss: 1.080071
global_step: 8397, epoch: 10, loss: 0.986234
global_step: 8398, epoch: 10, loss: 0.995336
global_step: 8399, epoch: 10, loss: 1.022269
global_step: 8400, epoch: 10, loss: 0.899373
epoch: 10
train	acc: 0.6186	macro: p 0.6066, r 0.2955, f1: 0.2884	micro: p 0.6186, r 0.6186, f1 0.6186	weighted_f1:0.5374
dev	acc: 0.5311	macro: p 0.4694, r 0.2664, f1: 0.2373	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4346
test	acc: 0.5912	macro: p 0.5046, r 0.2764, f1: 0.2584	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5026
global_step: 8401, epoch: 11, loss: 1.389984
global_step: 8402, epoch: 11, loss: 1.156529
global_step: 8403, epoch: 11, loss: 1.025040
global_step: 8404, epoch: 11, loss: 0.980236
global_step: 8405, epoch: 11, loss: 0.959018
global_step: 8406, epoch: 11, loss: 1.049914
global_step: 8407, epoch: 11, loss: 1.050148
global_step: 8408, epoch: 11, loss: 1.014038
global_step: 8409, epoch: 11, loss: 1.058309
global_step: 8410, epoch: 11, loss: 0.986580
global_step: 8411, epoch: 11, loss: 1.022332
global_step: 8412, epoch: 11, loss: 0.885856
global_step: 8413, epoch: 11, loss: 1.003254
global_step: 8414, epoch: 11, loss: 1.027396
global_step: 8415, epoch: 11, loss: 1.032965
global_step: 8416, epoch: 11, loss: 1.110918
global_step: 8417, epoch: 11, loss: 1.032078
global_step: 8418, epoch: 11, loss: 0.974326
global_step: 8419, epoch: 11, loss: 0.984467
global_step: 8420, epoch: 11, loss: 1.025332
global_step: 8421, epoch: 11, loss: 0.937968
global_step: 8422, epoch: 11, loss: 0.965505
global_step: 8423, epoch: 11, loss: 1.031130
global_step: 8424, epoch: 11, loss: 0.979674
global_step: 8425, epoch: 11, loss: 1.003831
global_step: 8426, epoch: 11, loss: 1.012267
global_step: 8427, epoch: 11, loss: 0.963536
global_step: 8428, epoch: 11, loss: 1.100303
global_step: 8429, epoch: 11, loss: 1.033099
global_step: 8430, epoch: 11, loss: 1.026553
global_step: 8431, epoch: 11, loss: 0.983457
global_step: 8432, epoch: 11, loss: 0.904601
global_step: 8433, epoch: 11, loss: 1.050331
global_step: 8434, epoch: 11, loss: 1.014389
global_step: 8435, epoch: 11, loss: 1.044931
global_step: 8436, epoch: 11, loss: 0.938491
global_step: 8437, epoch: 11, loss: 0.931597
global_step: 8438, epoch: 11, loss: 1.090640
global_step: 8439, epoch: 11, loss: 0.973800
global_step: 8440, epoch: 11, loss: 0.217805
epoch: 11
train	acc: 0.6524	macro: p 0.6054, r 0.3524, f1: 0.3587	micro: p 0.6524, r 0.6524, f1 0.6524	weighted_f1:0.6008
dev	acc: 0.5383	macro: p 0.3906, r 0.2927, f1: 0.2723	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4714
test	acc: 0.5889	macro: p 0.4740, r 0.3005, f1: 0.2913	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5302
global_step: 8441, epoch: 12, loss: 1.147466
global_step: 8442, epoch: 12, loss: 1.056923
global_step: 8443, epoch: 12, loss: 0.994180
global_step: 8444, epoch: 12, loss: 1.028628
global_step: 8445, epoch: 12, loss: 1.075105
global_step: 8446, epoch: 12, loss: 0.984920
global_step: 8447, epoch: 12, loss: 1.066624
global_step: 8448, epoch: 12, loss: 0.958984
global_step: 8449, epoch: 12, loss: 0.905722
global_step: 8450, epoch: 12, loss: 0.901514
global_step: 8451, epoch: 12, loss: 1.008375
global_step: 8452, epoch: 12, loss: 0.897328
global_step: 8453, epoch: 12, loss: 1.004349
global_step: 8454, epoch: 12, loss: 0.927946
global_step: 8455, epoch: 12, loss: 0.938210
global_step: 8456, epoch: 12, loss: 0.924296
global_step: 8457, epoch: 12, loss: 0.993044
global_step: 8458, epoch: 12, loss: 1.012440
global_step: 8459, epoch: 12, loss: 1.011461
global_step: 8460, epoch: 12, loss: 1.046492
global_step: 8461, epoch: 12, loss: 0.940568
global_step: 8462, epoch: 12, loss: 1.035281
global_step: 8463, epoch: 12, loss: 1.008515
global_step: 8464, epoch: 12, loss: 0.944399
global_step: 8465, epoch: 12, loss: 0.988424
global_step: 8466, epoch: 12, loss: 0.960115
global_step: 8467, epoch: 12, loss: 1.067002
global_step: 8468, epoch: 12, loss: 1.033468
global_step: 8469, epoch: 12, loss: 1.028373
global_step: 8470, epoch: 12, loss: 1.030434
global_step: 8471, epoch: 12, loss: 1.063420
global_step: 8472, epoch: 12, loss: 0.936855
global_step: 8473, epoch: 12, loss: 0.781417
global_step: 8474, epoch: 12, loss: 0.967925
global_step: 8475, epoch: 12, loss: 1.055880
global_step: 8476, epoch: 12, loss: 1.025201
global_step: 8477, epoch: 12, loss: 1.018068
global_step: 8478, epoch: 12, loss: 1.086666
global_step: 8479, epoch: 12, loss: 1.052788
global_step: 8480, epoch: 12, loss: 1.986863
epoch: 12
train	acc: 0.6640	macro: p 0.6063, r 0.4883, f1: 0.4815	micro: p 0.6640, r 0.6640, f1 0.6640	weighted_f1:0.6597
dev	acc: 0.5176	macro: p 0.3728, r 0.3436, f1: 0.3325	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.5042
test	acc: 0.5352	macro: p 0.3906, r 0.3485, f1: 0.3381	micro: p 0.5352, r 0.5352, f1 0.5352	weighted_f1:0.5340
global_step: 8481, epoch: 13, loss: 1.171858
global_step: 8482, epoch: 13, loss: 0.995666
global_step: 8483, epoch: 13, loss: 0.799940
global_step: 8484, epoch: 13, loss: 1.016796
global_step: 8485, epoch: 13, loss: 0.875862
global_step: 8486, epoch: 13, loss: 0.964557
global_step: 8487, epoch: 13, loss: 0.935942
global_step: 8488, epoch: 13, loss: 0.969546
global_step: 8489, epoch: 13, loss: 0.964508
global_step: 8490, epoch: 13, loss: 0.860011
global_step: 8491, epoch: 13, loss: 0.850932
global_step: 8492, epoch: 13, loss: 0.856714
global_step: 8493, epoch: 13, loss: 1.000169
global_step: 8494, epoch: 13, loss: 0.913604
global_step: 8495, epoch: 13, loss: 0.932905
global_step: 8496, epoch: 13, loss: 0.922241
global_step: 8497, epoch: 13, loss: 0.832927
global_step: 8498, epoch: 13, loss: 0.866556
global_step: 8499, epoch: 13, loss: 1.019535
global_step: 8500, epoch: 13, loss: 0.924833
global_step: 8501, epoch: 13, loss: 0.903601
global_step: 8502, epoch: 13, loss: 0.906512
global_step: 8503, epoch: 13, loss: 1.017810
global_step: 8504, epoch: 13, loss: 0.836061
global_step: 8505, epoch: 13, loss: 0.968636
global_step: 8506, epoch: 13, loss: 0.973068
global_step: 8507, epoch: 13, loss: 1.046543
global_step: 8508, epoch: 13, loss: 0.909890
global_step: 8509, epoch: 13, loss: 0.810703
global_step: 8510, epoch: 13, loss: 0.951295
global_step: 8511, epoch: 13, loss: 0.970328
global_step: 8512, epoch: 13, loss: 0.924209
global_step: 8513, epoch: 13, loss: 0.889951
global_step: 8514, epoch: 13, loss: 1.002117
global_step: 8515, epoch: 13, loss: 0.967747
global_step: 8516, epoch: 13, loss: 0.849887
global_step: 8517, epoch: 13, loss: 0.913252
global_step: 8518, epoch: 13, loss: 0.903796
global_step: 8519, epoch: 13, loss: 0.848675
global_step: 8520, epoch: 13, loss: 0.895984
epoch: 13
train	acc: 0.6837	macro: p 0.6009, r 0.4366, f1: 0.4558	micro: p 0.6837, r 0.6837, f1 0.6837	weighted_f1:0.6561
dev	acc: 0.5528	macro: p 0.3617, r 0.3106, f1: 0.3177	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5081
test	acc: 0.5927	macro: p 0.4445, r 0.3164, f1: 0.3334	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5571
global_step: 8521, epoch: 14, loss: 0.933234
global_step: 8522, epoch: 14, loss: 0.982837
global_step: 8523, epoch: 14, loss: 0.986845
global_step: 8524, epoch: 14, loss: 0.848587
global_step: 8525, epoch: 14, loss: 0.948308
global_step: 8526, epoch: 14, loss: 1.008561
global_step: 8527, epoch: 14, loss: 0.916319
global_step: 8528, epoch: 14, loss: 0.853228
global_step: 8529, epoch: 14, loss: 0.917368
global_step: 8530, epoch: 14, loss: 1.029489
global_step: 8531, epoch: 14, loss: 0.977272
global_step: 8532, epoch: 14, loss: 0.897370
global_step: 8533, epoch: 14, loss: 0.866038
global_step: 8534, epoch: 14, loss: 0.899091
global_step: 8535, epoch: 14, loss: 0.938808
global_step: 8536, epoch: 14, loss: 0.901953
global_step: 8537, epoch: 14, loss: 0.749153
global_step: 8538, epoch: 14, loss: 0.840808
global_step: 8539, epoch: 14, loss: 0.860925
global_step: 8540, epoch: 14, loss: 0.934557
global_step: 8541, epoch: 14, loss: 0.901964
global_step: 8542, epoch: 14, loss: 0.938958
global_step: 8543, epoch: 14, loss: 1.012040
global_step: 8544, epoch: 14, loss: 1.039336
global_step: 8545, epoch: 14, loss: 0.990420
global_step: 8546, epoch: 14, loss: 0.786304
global_step: 8547, epoch: 14, loss: 0.983605
global_step: 8548, epoch: 14, loss: 0.947865
global_step: 8549, epoch: 14, loss: 0.957782
global_step: 8550, epoch: 14, loss: 0.909622
global_step: 8551, epoch: 14, loss: 0.927308
global_step: 8552, epoch: 14, loss: 1.072843
global_step: 8553, epoch: 14, loss: 0.888384
global_step: 8554, epoch: 14, loss: 0.804074
global_step: 8555, epoch: 14, loss: 0.929189
global_step: 8556, epoch: 14, loss: 0.948170
global_step: 8557, epoch: 14, loss: 0.927600
global_step: 8558, epoch: 14, loss: 0.855968
global_step: 8559, epoch: 14, loss: 0.858986
global_step: 8560, epoch: 14, loss: 0.322888
epoch: 14
train	acc: 0.7496	macro: p 0.8173, r 0.4922, f1: 0.5043	micro: p 0.7496, r 0.7496, f1 0.7496	weighted_f1:0.7231
dev	acc: 0.5807	macro: p 0.3759, r 0.3408, f1: 0.3316	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5347
test	acc: 0.6096	macro: p 0.3930, r 0.3432, f1: 0.3383	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5737
New best model!
global_step: 8561, epoch: 15, loss: 0.912095
global_step: 8562, epoch: 15, loss: 0.813113
global_step: 8563, epoch: 15, loss: 0.885566
global_step: 8564, epoch: 15, loss: 0.825295
global_step: 8565, epoch: 15, loss: 0.712736
global_step: 8566, epoch: 15, loss: 0.755902
global_step: 8567, epoch: 15, loss: 0.941363
global_step: 8568, epoch: 15, loss: 0.841986
global_step: 8569, epoch: 15, loss: 0.729090
global_step: 8570, epoch: 15, loss: 0.841950
global_step: 8571, epoch: 15, loss: 0.801204
global_step: 8572, epoch: 15, loss: 0.831615
global_step: 8573, epoch: 15, loss: 0.963761
global_step: 8574, epoch: 15, loss: 0.902517
global_step: 8575, epoch: 15, loss: 0.851034
global_step: 8576, epoch: 15, loss: 0.851262
global_step: 8577, epoch: 15, loss: 0.817744
global_step: 8578, epoch: 15, loss: 0.851028
global_step: 8579, epoch: 15, loss: 0.845718
global_step: 8580, epoch: 15, loss: 0.848301
global_step: 8581, epoch: 15, loss: 0.841715
global_step: 8582, epoch: 15, loss: 0.830612
global_step: 8583, epoch: 15, loss: 0.893172
global_step: 8584, epoch: 15, loss: 0.886987
global_step: 8585, epoch: 15, loss: 1.145469
global_step: 8586, epoch: 15, loss: 1.072017
global_step: 8587, epoch: 15, loss: 1.084864
global_step: 8588, epoch: 15, loss: 0.922248
global_step: 8589, epoch: 15, loss: 0.754324
global_step: 8590, epoch: 15, loss: 0.866957
global_step: 8591, epoch: 15, loss: 0.829974
global_step: 8592, epoch: 15, loss: 0.795589
global_step: 8593, epoch: 15, loss: 0.876249
global_step: 8594, epoch: 15, loss: 0.948413
global_step: 8595, epoch: 15, loss: 0.887938
global_step: 8596, epoch: 15, loss: 0.924770
global_step: 8597, epoch: 15, loss: 1.061030
global_step: 8598, epoch: 15, loss: 0.973320
global_step: 8599, epoch: 15, loss: 0.918784
global_step: 8600, epoch: 15, loss: 0.912578
epoch: 15
train	acc: 0.6910	macro: p 0.7245, r 0.4255, f1: 0.4732	micro: p 0.6910, r 0.6910, f1 0.6910	weighted_f1:0.6513
dev	acc: 0.5491	macro: p 0.4256, r 0.3000, f1: 0.2920	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4798
test	acc: 0.5950	macro: p 0.5703, r 0.3134, f1: 0.3224	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5333
global_step: 8601, epoch: 16, loss: 0.960065
global_step: 8602, epoch: 16, loss: 0.846775
global_step: 8603, epoch: 16, loss: 0.874157
global_step: 8604, epoch: 16, loss: 0.803097
global_step: 8605, epoch: 16, loss: 0.650561
global_step: 8606, epoch: 16, loss: 0.812591
global_step: 8607, epoch: 16, loss: 0.929117
global_step: 8608, epoch: 16, loss: 0.742643
global_step: 8609, epoch: 16, loss: 0.720793
global_step: 8610, epoch: 16, loss: 0.841644
global_step: 8611, epoch: 16, loss: 0.955417
global_step: 8612, epoch: 16, loss: 0.874807
global_step: 8613, epoch: 16, loss: 0.779471
global_step: 8614, epoch: 16, loss: 0.815900
global_step: 8615, epoch: 16, loss: 0.875054
global_step: 8616, epoch: 16, loss: 0.743206
global_step: 8617, epoch: 16, loss: 0.734569
global_step: 8618, epoch: 16, loss: 0.842607
global_step: 8619, epoch: 16, loss: 0.707532
global_step: 8620, epoch: 16, loss: 0.774657
global_step: 8621, epoch: 16, loss: 0.745026
global_step: 8622, epoch: 16, loss: 0.827141
global_step: 8623, epoch: 16, loss: 0.812653
global_step: 8624, epoch: 16, loss: 0.903694
global_step: 8625, epoch: 16, loss: 0.738507
global_step: 8626, epoch: 16, loss: 0.812537
global_step: 8627, epoch: 16, loss: 0.887201
global_step: 8628, epoch: 16, loss: 0.813975
global_step: 8629, epoch: 16, loss: 0.947318
global_step: 8630, epoch: 16, loss: 0.915664
global_step: 8631, epoch: 16, loss: 0.829507
global_step: 8632, epoch: 16, loss: 0.811441
global_step: 8633, epoch: 16, loss: 0.736730
global_step: 8634, epoch: 16, loss: 0.877848
global_step: 8635, epoch: 16, loss: 0.937481
global_step: 8636, epoch: 16, loss: 0.896719
global_step: 8637, epoch: 16, loss: 0.918614
global_step: 8638, epoch: 16, loss: 0.912774
global_step: 8639, epoch: 16, loss: 0.887519
global_step: 8640, epoch: 16, loss: 0.365134
epoch: 16
train	acc: 0.7583	macro: p 0.8092, r 0.5191, f1: 0.5582	micro: p 0.7583, r 0.7583, f1 0.7583	weighted_f1:0.7342
dev	acc: 0.5699	macro: p 0.4404, r 0.3350, f1: 0.3401	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5168
test	acc: 0.6126	macro: p 0.5610, r 0.3357, f1: 0.3463	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5685
global_step: 8641, epoch: 17, loss: 0.924892
global_step: 8642, epoch: 17, loss: 0.841859
global_step: 8643, epoch: 17, loss: 0.871891
global_step: 8644, epoch: 17, loss: 0.732715
global_step: 8645, epoch: 17, loss: 0.983588
global_step: 8646, epoch: 17, loss: 0.773599
global_step: 8647, epoch: 17, loss: 0.880864
global_step: 8648, epoch: 17, loss: 0.788213
global_step: 8649, epoch: 17, loss: 0.826337
global_step: 8650, epoch: 17, loss: 0.840467
global_step: 8651, epoch: 17, loss: 0.744890
global_step: 8652, epoch: 17, loss: 0.808632
global_step: 8653, epoch: 17, loss: 0.764062
global_step: 8654, epoch: 17, loss: 0.746638
global_step: 8655, epoch: 17, loss: 0.836152
global_step: 8656, epoch: 17, loss: 0.845362
global_step: 8657, epoch: 17, loss: 0.962322
global_step: 8658, epoch: 17, loss: 0.920364
global_step: 8659, epoch: 17, loss: 0.898248
global_step: 8660, epoch: 17, loss: 0.759992
global_step: 8661, epoch: 17, loss: 0.967842
global_step: 8662, epoch: 17, loss: 0.849242
global_step: 8663, epoch: 17, loss: 0.996739
global_step: 8664, epoch: 17, loss: 0.925937
global_step: 8665, epoch: 17, loss: 0.700177
global_step: 8666, epoch: 17, loss: 0.720870
global_step: 8667, epoch: 17, loss: 0.954995
global_step: 8668, epoch: 17, loss: 0.871010
global_step: 8669, epoch: 17, loss: 0.813946
global_step: 8670, epoch: 17, loss: 0.892786
global_step: 8671, epoch: 17, loss: 0.784792
global_step: 8672, epoch: 17, loss: 0.657243
global_step: 8673, epoch: 17, loss: 0.783618
global_step: 8674, epoch: 17, loss: 0.922169
global_step: 8675, epoch: 17, loss: 0.794111
global_step: 8676, epoch: 17, loss: 0.801133
global_step: 8677, epoch: 17, loss: 0.812895
global_step: 8678, epoch: 17, loss: 0.877934
global_step: 8679, epoch: 17, loss: 0.680672
global_step: 8680, epoch: 17, loss: 0.083563
epoch: 17
train	acc: 0.7541	macro: p 0.7903, r 0.4911, f1: 0.5240	micro: p 0.7541, r 0.7541, f1 0.7541	weighted_f1:0.7206
dev	acc: 0.5726	macro: p 0.4088, r 0.3246, f1: 0.3208	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5113
test	acc: 0.6172	macro: p 0.5426, r 0.3263, f1: 0.3261	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5637
global_step: 8681, epoch: 18, loss: 0.809743
global_step: 8682, epoch: 18, loss: 0.743556
global_step: 8683, epoch: 18, loss: 0.776412
global_step: 8684, epoch: 18, loss: 0.788694
global_step: 8685, epoch: 18, loss: 0.774698
global_step: 8686, epoch: 18, loss: 0.650045
global_step: 8687, epoch: 18, loss: 0.601571
global_step: 8688, epoch: 18, loss: 0.670513
global_step: 8689, epoch: 18, loss: 0.856109
global_step: 8690, epoch: 18, loss: 0.956229
global_step: 8691, epoch: 18, loss: 0.887050
global_step: 8692, epoch: 18, loss: 0.683517
global_step: 8693, epoch: 18, loss: 0.584406
global_step: 8694, epoch: 18, loss: 0.715762
global_step: 8695, epoch: 18, loss: 0.803974
global_step: 8696, epoch: 18, loss: 0.796673
global_step: 8697, epoch: 18, loss: 0.763457
global_step: 8698, epoch: 18, loss: 0.782312
global_step: 8699, epoch: 18, loss: 0.903393
global_step: 8700, epoch: 18, loss: 0.905811
global_step: 8701, epoch: 18, loss: 0.764843
global_step: 8702, epoch: 18, loss: 0.819423
global_step: 8703, epoch: 18, loss: 0.779505
global_step: 8704, epoch: 18, loss: 0.840646
global_step: 8705, epoch: 18, loss: 0.704854
global_step: 8706, epoch: 18, loss: 0.701294
global_step: 8707, epoch: 18, loss: 0.750373
global_step: 8708, epoch: 18, loss: 0.759033
global_step: 8709, epoch: 18, loss: 0.800083
global_step: 8710, epoch: 18, loss: 0.709560
global_step: 8711, epoch: 18, loss: 0.830707
global_step: 8712, epoch: 18, loss: 0.960753
global_step: 8713, epoch: 18, loss: 0.875169
global_step: 8714, epoch: 18, loss: 0.807557
global_step: 8715, epoch: 18, loss: 0.852297
global_step: 8716, epoch: 18, loss: 0.769517
global_step: 8717, epoch: 18, loss: 0.834546
global_step: 8718, epoch: 18, loss: 0.680571
global_step: 8719, epoch: 18, loss: 0.841625
global_step: 8720, epoch: 18, loss: 0.295518
epoch: 18
train	acc: 0.8023	macro: p 0.8228, r 0.6251, f1: 0.6615	micro: p 0.8023, r 0.8023, f1 0.8023	weighted_f1:0.7911
dev	acc: 0.5636	macro: p 0.4087, r 0.3502, f1: 0.3499	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5271
test	acc: 0.5839	macro: p 0.4008, r 0.3453, f1: 0.3450	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5575
global_step: 8721, epoch: 19, loss: 0.738964
global_step: 8722, epoch: 19, loss: 0.848537
global_step: 8723, epoch: 19, loss: 0.757121
global_step: 8724, epoch: 19, loss: 0.831438
global_step: 8725, epoch: 19, loss: 0.764785
global_step: 8726, epoch: 19, loss: 0.720355
global_step: 8727, epoch: 19, loss: 0.829192
global_step: 8728, epoch: 19, loss: 0.711591
global_step: 8729, epoch: 19, loss: 0.883896
global_step: 8730, epoch: 19, loss: 0.764829
global_step: 8731, epoch: 19, loss: 0.820009
global_step: 8732, epoch: 19, loss: 0.716001
global_step: 8733, epoch: 19, loss: 0.819440
global_step: 8734, epoch: 19, loss: 0.774738
global_step: 8735, epoch: 19, loss: 0.620023
global_step: 8736, epoch: 19, loss: 0.643329
global_step: 8737, epoch: 19, loss: 0.740811
global_step: 8738, epoch: 19, loss: 0.722570
global_step: 8739, epoch: 19, loss: 0.661205
global_step: 8740, epoch: 19, loss: 0.708670
global_step: 8741, epoch: 19, loss: 0.680178
global_step: 8742, epoch: 19, loss: 0.781373
global_step: 8743, epoch: 19, loss: 0.879651
global_step: 8744, epoch: 19, loss: 0.697559
global_step: 8745, epoch: 19, loss: 0.857819
global_step: 8746, epoch: 19, loss: 0.804711
global_step: 8747, epoch: 19, loss: 0.819778
global_step: 8748, epoch: 19, loss: 0.776684
global_step: 8749, epoch: 19, loss: 0.738659
global_step: 8750, epoch: 19, loss: 0.750788
global_step: 8751, epoch: 19, loss: 0.669504
global_step: 8752, epoch: 19, loss: 0.780166
global_step: 8753, epoch: 19, loss: 0.803022
global_step: 8754, epoch: 19, loss: 0.822080
global_step: 8755, epoch: 19, loss: 0.785066
global_step: 8756, epoch: 19, loss: 0.768972
global_step: 8757, epoch: 19, loss: 0.782458
global_step: 8758, epoch: 19, loss: 0.791613
global_step: 8759, epoch: 19, loss: 0.742340
global_step: 8760, epoch: 19, loss: 1.480173
epoch: 19
train	acc: 0.7839	macro: p 0.7758, r 0.6272, f1: 0.6799	micro: p 0.7839, r 0.7839, f1 0.7839	weighted_f1:0.7736
dev	acc: 0.5600	macro: p 0.4300, r 0.3253, f1: 0.3425	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5133
test	acc: 0.6092	macro: p 0.4540, r 0.3429, f1: 0.3664	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5681
global_step: 8761, epoch: 20, loss: 0.901468
global_step: 8762, epoch: 20, loss: 0.751867
global_step: 8763, epoch: 20, loss: 0.748517
global_step: 8764, epoch: 20, loss: 0.687262
global_step: 8765, epoch: 20, loss: 0.597674
global_step: 8766, epoch: 20, loss: 0.697228
global_step: 8767, epoch: 20, loss: 0.809621
global_step: 8768, epoch: 20, loss: 0.740167
global_step: 8769, epoch: 20, loss: 0.667123
global_step: 8770, epoch: 20, loss: 0.741327
global_step: 8771, epoch: 20, loss: 0.850669
global_step: 8772, epoch: 20, loss: 0.680773
global_step: 8773, epoch: 20, loss: 0.648835
global_step: 8774, epoch: 20, loss: 0.720884
global_step: 8775, epoch: 20, loss: 0.730034
global_step: 8776, epoch: 20, loss: 0.607449
global_step: 8777, epoch: 20, loss: 0.667747
global_step: 8778, epoch: 20, loss: 0.762711
global_step: 8779, epoch: 20, loss: 0.686390
global_step: 8780, epoch: 20, loss: 0.697133
global_step: 8781, epoch: 20, loss: 0.693135
global_step: 8782, epoch: 20, loss: 0.708167
global_step: 8783, epoch: 20, loss: 0.861453
global_step: 8784, epoch: 20, loss: 0.698297
global_step: 8785, epoch: 20, loss: 0.654494
global_step: 8786, epoch: 20, loss: 0.813961
global_step: 8787, epoch: 20, loss: 0.787719
global_step: 8788, epoch: 20, loss: 0.824702
global_step: 8789, epoch: 20, loss: 0.695420
global_step: 8790, epoch: 20, loss: 0.701907
global_step: 8791, epoch: 20, loss: 0.686886
global_step: 8792, epoch: 20, loss: 0.756404
global_step: 8793, epoch: 20, loss: 0.632584
global_step: 8794, epoch: 20, loss: 0.648870
global_step: 8795, epoch: 20, loss: 0.782162
global_step: 8796, epoch: 20, loss: 0.704739
global_step: 8797, epoch: 20, loss: 0.779232
global_step: 8798, epoch: 20, loss: 0.631794
global_step: 8799, epoch: 20, loss: 0.648998
global_step: 8800, epoch: 20, loss: 0.522021
epoch: 20
train	acc: 0.8273	macro: p 0.8070, r 0.7020, f1: 0.7198	micro: p 0.8273, r 0.8273, f1 0.8273	weighted_f1:0.8242
dev	acc: 0.5564	macro: p 0.4635, r 0.3755, f1: 0.3827	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5350
test	acc: 0.5674	macro: p 0.3987, r 0.3564, f1: 0.3555	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5577
New best model!
global_step: 8801, epoch: 21, loss: 0.727981
global_step: 8802, epoch: 21, loss: 0.694416
global_step: 8803, epoch: 21, loss: 0.661982
global_step: 8804, epoch: 21, loss: 0.722288
global_step: 8805, epoch: 21, loss: 0.667836
global_step: 8806, epoch: 21, loss: 0.664793
global_step: 8807, epoch: 21, loss: 0.673700
global_step: 8808, epoch: 21, loss: 0.723179
global_step: 8809, epoch: 21, loss: 0.685627
global_step: 8810, epoch: 21, loss: 0.696275
global_step: 8811, epoch: 21, loss: 0.636812
global_step: 8812, epoch: 21, loss: 0.745267
global_step: 8813, epoch: 21, loss: 0.746340
global_step: 8814, epoch: 21, loss: 0.664307
global_step: 8815, epoch: 21, loss: 0.656426
global_step: 8816, epoch: 21, loss: 0.578900
global_step: 8817, epoch: 21, loss: 0.630660
global_step: 8818, epoch: 21, loss: 0.723268
global_step: 8819, epoch: 21, loss: 0.680083
global_step: 8820, epoch: 21, loss: 0.646001
global_step: 8821, epoch: 21, loss: 0.724508
global_step: 8822, epoch: 21, loss: 0.594184
global_step: 8823, epoch: 21, loss: 0.677537
global_step: 8824, epoch: 21, loss: 0.716897
global_step: 8825, epoch: 21, loss: 0.787632
global_step: 8826, epoch: 21, loss: 0.646286
global_step: 8827, epoch: 21, loss: 0.611572
global_step: 8828, epoch: 21, loss: 0.602366
global_step: 8829, epoch: 21, loss: 0.677719
global_step: 8830, epoch: 21, loss: 0.735383
global_step: 8831, epoch: 21, loss: 0.614163
global_step: 8832, epoch: 21, loss: 0.626285
global_step: 8833, epoch: 21, loss: 0.714245
global_step: 8834, epoch: 21, loss: 0.606090
global_step: 8835, epoch: 21, loss: 0.789026
global_step: 8836, epoch: 21, loss: 0.685135
global_step: 8837, epoch: 21, loss: 0.688964
global_step: 8838, epoch: 21, loss: 0.719072
global_step: 8839, epoch: 21, loss: 0.676842
global_step: 8840, epoch: 21, loss: 0.998076
epoch: 21
train	acc: 0.8337	macro: p 0.8385, r 0.6920, f1: 0.7454	micro: p 0.8337, r 0.8337, f1 0.8337	weighted_f1:0.8277
dev	acc: 0.5654	macro: p 0.4696, r 0.3425, f1: 0.3581	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5253
test	acc: 0.6038	macro: p 0.4502, r 0.3538, f1: 0.3747	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5732
global_step: 8841, epoch: 22, loss: 0.688698
global_step: 8842, epoch: 22, loss: 0.701276
global_step: 8843, epoch: 22, loss: 0.518468
global_step: 8844, epoch: 22, loss: 0.627985
global_step: 8845, epoch: 22, loss: 0.617125
global_step: 8846, epoch: 22, loss: 0.731315
global_step: 8847, epoch: 22, loss: 0.648744
global_step: 8848, epoch: 22, loss: 0.641066
global_step: 8849, epoch: 22, loss: 0.578167
global_step: 8850, epoch: 22, loss: 0.763496
global_step: 8851, epoch: 22, loss: 0.715291
global_step: 8852, epoch: 22, loss: 0.626741
global_step: 8853, epoch: 22, loss: 0.631071
global_step: 8854, epoch: 22, loss: 0.652442
global_step: 8855, epoch: 22, loss: 0.613864
global_step: 8856, epoch: 22, loss: 0.632083
global_step: 8857, epoch: 22, loss: 0.638192
global_step: 8858, epoch: 22, loss: 0.773144
global_step: 8859, epoch: 22, loss: 0.500877
global_step: 8860, epoch: 22, loss: 0.503005
global_step: 8861, epoch: 22, loss: 0.625401
global_step: 8862, epoch: 22, loss: 0.594495
global_step: 8863, epoch: 22, loss: 0.616461
global_step: 8864, epoch: 22, loss: 0.597103
global_step: 8865, epoch: 22, loss: 0.726185
global_step: 8866, epoch: 22, loss: 0.718739
global_step: 8867, epoch: 22, loss: 0.793519
global_step: 8868, epoch: 22, loss: 0.708419
global_step: 8869, epoch: 22, loss: 0.758869
global_step: 8870, epoch: 22, loss: 0.700226
global_step: 8871, epoch: 22, loss: 0.670640
global_step: 8872, epoch: 22, loss: 0.752438
global_step: 8873, epoch: 22, loss: 0.571990
global_step: 8874, epoch: 22, loss: 0.750785
global_step: 8875, epoch: 22, loss: 0.810967
global_step: 8876, epoch: 22, loss: 0.760852
global_step: 8877, epoch: 22, loss: 0.614117
global_step: 8878, epoch: 22, loss: 0.646655
global_step: 8879, epoch: 22, loss: 0.646416
global_step: 8880, epoch: 22, loss: 2.357939
epoch: 22
train	acc: 0.8281	macro: p 0.7615, r 0.7724, f1: 0.7595	micro: p 0.8281, r 0.8281, f1 0.8281	weighted_f1:0.8317
dev	acc: 0.5275	macro: p 0.3940, r 0.3817, f1: 0.3773	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.5257
test	acc: 0.5276	macro: p 0.3710, r 0.3773, f1: 0.3627	micro: p 0.5276, r 0.5276, f1 0.5276	weighted_f1:0.5359
global_step: 8881, epoch: 23, loss: 0.875825
global_step: 8882, epoch: 23, loss: 0.593800
global_step: 8883, epoch: 23, loss: 0.766321
global_step: 8884, epoch: 23, loss: 0.729220
global_step: 8885, epoch: 23, loss: 0.644753
global_step: 8886, epoch: 23, loss: 0.608290
global_step: 8887, epoch: 23, loss: 0.657756
global_step: 8888, epoch: 23, loss: 0.582035
global_step: 8889, epoch: 23, loss: 0.558590
global_step: 8890, epoch: 23, loss: 0.564557
global_step: 8891, epoch: 23, loss: 0.640727
global_step: 8892, epoch: 23, loss: 0.657238
global_step: 8893, epoch: 23, loss: 0.566551
global_step: 8894, epoch: 23, loss: 0.552788
global_step: 8895, epoch: 23, loss: 0.602044
global_step: 8896, epoch: 23, loss: 0.616225
global_step: 8897, epoch: 23, loss: 0.593320
global_step: 8898, epoch: 23, loss: 0.600635
global_step: 8899, epoch: 23, loss: 0.659129
global_step: 8900, epoch: 23, loss: 0.707966
global_step: 8901, epoch: 23, loss: 0.588398
global_step: 8902, epoch: 23, loss: 0.644353
global_step: 8903, epoch: 23, loss: 0.597764
global_step: 8904, epoch: 23, loss: 0.661694
global_step: 8905, epoch: 23, loss: 0.597343
global_step: 8906, epoch: 23, loss: 0.625291
global_step: 8907, epoch: 23, loss: 0.592933
global_step: 8908, epoch: 23, loss: 0.620584
global_step: 8909, epoch: 23, loss: 0.589811
global_step: 8910, epoch: 23, loss: 0.549427
global_step: 8911, epoch: 23, loss: 0.649860
global_step: 8912, epoch: 23, loss: 0.589038
global_step: 8913, epoch: 23, loss: 0.623639
global_step: 8914, epoch: 23, loss: 0.482906
global_step: 8915, epoch: 23, loss: 0.666538
global_step: 8916, epoch: 23, loss: 0.704614
global_step: 8917, epoch: 23, loss: 0.680005
global_step: 8918, epoch: 23, loss: 0.599760
global_step: 8919, epoch: 23, loss: 0.775342
global_step: 8920, epoch: 23, loss: 0.127767
epoch: 23
train	acc: 0.8773	macro: p 0.8701, r 0.7749, f1: 0.8065	micro: p 0.8773, r 0.8773, f1 0.8773	weighted_f1:0.8746
dev	acc: 0.5708	macro: p 0.4582, r 0.3774, f1: 0.3835	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5473
test	acc: 0.5843	macro: p 0.4307, r 0.3668, f1: 0.3737	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5683
New best model!
global_step: 8921, epoch: 24, loss: 0.598254
global_step: 8922, epoch: 24, loss: 0.582816
global_step: 8923, epoch: 24, loss: 0.596644
global_step: 8924, epoch: 24, loss: 0.605999
global_step: 8925, epoch: 24, loss: 0.584701
global_step: 8926, epoch: 24, loss: 0.517772
global_step: 8927, epoch: 24, loss: 0.657378
global_step: 8928, epoch: 24, loss: 0.567236
global_step: 8929, epoch: 24, loss: 0.607487
global_step: 8930, epoch: 24, loss: 0.490234
global_step: 8931, epoch: 24, loss: 0.620563
global_step: 8932, epoch: 24, loss: 0.479333
global_step: 8933, epoch: 24, loss: 0.509230
global_step: 8934, epoch: 24, loss: 0.497248
global_step: 8935, epoch: 24, loss: 0.571043
global_step: 8936, epoch: 24, loss: 0.523485
global_step: 8937, epoch: 24, loss: 0.550839
global_step: 8938, epoch: 24, loss: 0.548139
global_step: 8939, epoch: 24, loss: 0.460616
global_step: 8940, epoch: 24, loss: 0.671235
global_step: 8941, epoch: 24, loss: 0.631019
global_step: 8942, epoch: 24, loss: 0.681851
global_step: 8943, epoch: 24, loss: 0.783435
global_step: 8944, epoch: 24, loss: 0.766226
global_step: 8945, epoch: 24, loss: 0.626662
global_step: 8946, epoch: 24, loss: 0.623399
global_step: 8947, epoch: 24, loss: 0.687961
global_step: 8948, epoch: 24, loss: 0.584327
global_step: 8949, epoch: 24, loss: 0.675202
global_step: 8950, epoch: 24, loss: 0.604107
global_step: 8951, epoch: 24, loss: 0.656266
global_step: 8952, epoch: 24, loss: 0.613751
global_step: 8953, epoch: 24, loss: 0.646477
global_step: 8954, epoch: 24, loss: 0.749223
global_step: 8955, epoch: 24, loss: 0.666983
global_step: 8956, epoch: 24, loss: 0.704510
global_step: 8957, epoch: 24, loss: 0.643270
global_step: 8958, epoch: 24, loss: 0.601734
global_step: 8959, epoch: 24, loss: 0.588986
global_step: 8960, epoch: 24, loss: 0.056802
epoch: 24
train	acc: 0.8594	macro: p 0.8945, r 0.7202, f1: 0.7668	micro: p 0.8594, r 0.8594, f1 0.8594	weighted_f1:0.8517
dev	acc: 0.5618	macro: p 0.5444, r 0.3389, f1: 0.3428	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5156
test	acc: 0.5996	macro: p 0.4081, r 0.3421, f1: 0.3473	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5632
global_step: 8961, epoch: 25, loss: 0.570958
global_step: 8962, epoch: 25, loss: 0.531401
global_step: 8963, epoch: 25, loss: 0.638184
global_step: 8964, epoch: 25, loss: 0.463100
global_step: 8965, epoch: 25, loss: 0.542735
global_step: 8966, epoch: 25, loss: 0.611416
global_step: 8967, epoch: 25, loss: 0.527674
global_step: 8968, epoch: 25, loss: 0.594215
global_step: 8969, epoch: 25, loss: 0.477109
global_step: 8970, epoch: 25, loss: 0.518566
global_step: 8971, epoch: 25, loss: 0.447280
global_step: 8972, epoch: 25, loss: 0.522042
global_step: 8973, epoch: 25, loss: 0.574657
global_step: 8974, epoch: 25, loss: 0.647203
global_step: 8975, epoch: 25, loss: 0.586307
global_step: 8976, epoch: 25, loss: 0.563208
global_step: 8977, epoch: 25, loss: 0.660027
global_step: 8978, epoch: 25, loss: 0.584467
global_step: 8979, epoch: 25, loss: 0.598459
global_step: 8980, epoch: 25, loss: 0.561546
global_step: 8981, epoch: 25, loss: 0.503588
global_step: 8982, epoch: 25, loss: 0.588666
global_step: 8983, epoch: 25, loss: 0.579258
global_step: 8984, epoch: 25, loss: 0.810810
global_step: 8985, epoch: 25, loss: 0.641798
global_step: 8986, epoch: 25, loss: 0.582302
global_step: 8987, epoch: 25, loss: 0.667618
global_step: 8988, epoch: 25, loss: 0.619696
global_step: 8989, epoch: 25, loss: 0.547536
global_step: 8990, epoch: 25, loss: 0.573889
global_step: 8991, epoch: 25, loss: 0.629578
global_step: 8992, epoch: 25, loss: 0.528640
global_step: 8993, epoch: 25, loss: 0.624871
global_step: 8994, epoch: 25, loss: 0.564216
global_step: 8995, epoch: 25, loss: 0.565154
global_step: 8996, epoch: 25, loss: 0.576193
global_step: 8997, epoch: 25, loss: 0.666592
global_step: 8998, epoch: 25, loss: 0.585584
global_step: 8999, epoch: 25, loss: 0.662091
global_step: 9000, epoch: 25, loss: 0.340004
epoch: 25
train	acc: 0.8559	macro: p 0.8866, r 0.7568, f1: 0.8027	micro: p 0.8559, r 0.8559, f1 0.8559	weighted_f1:0.8500
dev	acc: 0.5482	macro: p 0.4288, r 0.3313, f1: 0.3370	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4993
test	acc: 0.5774	macro: p 0.4130, r 0.3271, f1: 0.3417	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5355
global_step: 9001, epoch: 26, loss: 0.651423
global_step: 9002, epoch: 26, loss: 0.648700
global_step: 9003, epoch: 26, loss: 0.581158
global_step: 9004, epoch: 26, loss: 0.557864
global_step: 9005, epoch: 26, loss: 0.651491
global_step: 9006, epoch: 26, loss: 0.641171
global_step: 9007, epoch: 26, loss: 0.534592
global_step: 9008, epoch: 26, loss: 0.613150
global_step: 9009, epoch: 26, loss: 0.532685
global_step: 9010, epoch: 26, loss: 0.503904
global_step: 9011, epoch: 26, loss: 0.659265
global_step: 9012, epoch: 26, loss: 0.477620
global_step: 9013, epoch: 26, loss: 0.431322
global_step: 9014, epoch: 26, loss: 0.412644
global_step: 9015, epoch: 26, loss: 0.619911
global_step: 9016, epoch: 26, loss: 0.659237
global_step: 9017, epoch: 26, loss: 0.616486
global_step: 9018, epoch: 26, loss: 0.686518
global_step: 9019, epoch: 26, loss: 0.679538
global_step: 9020, epoch: 26, loss: 0.565860
global_step: 9021, epoch: 26, loss: 0.559153
global_step: 9022, epoch: 26, loss: 0.504800
global_step: 9023, epoch: 26, loss: 0.538420
global_step: 9024, epoch: 26, loss: 0.725567
global_step: 9025, epoch: 26, loss: 0.694680
global_step: 9026, epoch: 26, loss: 0.600256
global_step: 9027, epoch: 26, loss: 0.687216
global_step: 9028, epoch: 26, loss: 0.476529
global_step: 9029, epoch: 26, loss: 0.528223
global_step: 9030, epoch: 26, loss: 0.575389
global_step: 9031, epoch: 26, loss: 0.535723
global_step: 9032, epoch: 26, loss: 0.593907
global_step: 9033, epoch: 26, loss: 0.459863
global_step: 9034, epoch: 26, loss: 0.514219
global_step: 9035, epoch: 26, loss: 0.568188
global_step: 9036, epoch: 26, loss: 0.510761
global_step: 9037, epoch: 26, loss: 0.555728
global_step: 9038, epoch: 26, loss: 0.535868
global_step: 9039, epoch: 26, loss: 0.553316
global_step: 9040, epoch: 26, loss: 0.138696
epoch: 26
train	acc: 0.8599	macro: p 0.8725, r 0.7568, f1: 0.7947	micro: p 0.8599, r 0.8599, f1 0.8599	weighted_f1:0.8601
dev	acc: 0.5555	macro: p 0.4326, r 0.3476, f1: 0.3545	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5268
test	acc: 0.5900	macro: p 0.4476, r 0.3627, f1: 0.3706	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5683
global_step: 9041, epoch: 27, loss: 0.667145
global_step: 9042, epoch: 27, loss: 0.575747
global_step: 9043, epoch: 27, loss: 0.520616
global_step: 9044, epoch: 27, loss: 0.540537
global_step: 9045, epoch: 27, loss: 0.457532
global_step: 9046, epoch: 27, loss: 0.547629
global_step: 9047, epoch: 27, loss: 0.572506
global_step: 9048, epoch: 27, loss: 0.548044
global_step: 9049, epoch: 27, loss: 0.571781
global_step: 9050, epoch: 27, loss: 0.565517
global_step: 9051, epoch: 27, loss: 0.501374
global_step: 9052, epoch: 27, loss: 0.457203
global_step: 9053, epoch: 27, loss: 0.526867
global_step: 9054, epoch: 27, loss: 0.684711
global_step: 9055, epoch: 27, loss: 0.560841
global_step: 9056, epoch: 27, loss: 0.551306
global_step: 9057, epoch: 27, loss: 0.547403
global_step: 9058, epoch: 27, loss: 0.606007
global_step: 9059, epoch: 27, loss: 0.740439
global_step: 9060, epoch: 27, loss: 0.670526
global_step: 9061, epoch: 27, loss: 0.592456
global_step: 9062, epoch: 27, loss: 0.559287
global_step: 9063, epoch: 27, loss: 0.738440
global_step: 9064, epoch: 27, loss: 0.612308
global_step: 9065, epoch: 27, loss: 0.511329
global_step: 9066, epoch: 27, loss: 0.463492
global_step: 9067, epoch: 27, loss: 0.586689
global_step: 9068, epoch: 27, loss: 0.588973
global_step: 9069, epoch: 27, loss: 0.589940
global_step: 9070, epoch: 27, loss: 0.572550
global_step: 9071, epoch: 27, loss: 0.535781
global_step: 9072, epoch: 27, loss: 0.509444
global_step: 9073, epoch: 27, loss: 0.442657
global_step: 9074, epoch: 27, loss: 0.621124
global_step: 9075, epoch: 27, loss: 0.552692
global_step: 9076, epoch: 27, loss: 0.430726
global_step: 9077, epoch: 27, loss: 0.615401
global_step: 9078, epoch: 27, loss: 0.592953
global_step: 9079, epoch: 27, loss: 0.590249
global_step: 9080, epoch: 27, loss: 1.343308
epoch: 27
train	acc: 0.8182	macro: p 0.8562, r 0.6791, f1: 0.7185	micro: p 0.8182, r 0.8182, f1 0.8182	weighted_f1:0.8141
dev	acc: 0.5284	macro: p 0.5804, r 0.3314, f1: 0.3251	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4898
test	acc: 0.5475	macro: p 0.4538, r 0.3182, f1: 0.3099	micro: p 0.5475, r 0.5475, f1 0.5475	weighted_f1:0.5168
global_step: 9081, epoch: 28, loss: 0.616019
global_step: 9082, epoch: 28, loss: 0.617025
global_step: 9083, epoch: 28, loss: 0.456103
global_step: 9084, epoch: 28, loss: 0.510357
global_step: 9085, epoch: 28, loss: 0.577107
global_step: 9086, epoch: 28, loss: 0.535613
global_step: 9087, epoch: 28, loss: 0.524082
global_step: 9088, epoch: 28, loss: 0.504995
global_step: 9089, epoch: 28, loss: 0.479180
global_step: 9090, epoch: 28, loss: 0.562716
global_step: 9091, epoch: 28, loss: 0.557431
global_step: 9092, epoch: 28, loss: 0.438652
global_step: 9093, epoch: 28, loss: 0.571806
global_step: 9094, epoch: 28, loss: 0.517158
global_step: 9095, epoch: 28, loss: 0.491901
global_step: 9096, epoch: 28, loss: 0.506251
global_step: 9097, epoch: 28, loss: 0.530887
global_step: 9098, epoch: 28, loss: 0.492928
global_step: 9099, epoch: 28, loss: 0.498481
global_step: 9100, epoch: 28, loss: 0.535804
global_step: 9101, epoch: 28, loss: 0.545650
global_step: 9102, epoch: 28, loss: 0.499876
global_step: 9103, epoch: 28, loss: 0.630867
global_step: 9104, epoch: 28, loss: 0.477675
global_step: 9105, epoch: 28, loss: 0.618493
global_step: 9106, epoch: 28, loss: 0.445982
global_step: 9107, epoch: 28, loss: 0.537530
global_step: 9108, epoch: 28, loss: 0.487024
global_step: 9109, epoch: 28, loss: 0.471018
global_step: 9110, epoch: 28, loss: 0.534763
global_step: 9111, epoch: 28, loss: 0.428816
global_step: 9112, epoch: 28, loss: 0.573232
global_step: 9113, epoch: 28, loss: 0.618446
global_step: 9114, epoch: 28, loss: 0.591357
global_step: 9115, epoch: 28, loss: 0.548478
global_step: 9116, epoch: 28, loss: 0.534921
global_step: 9117, epoch: 28, loss: 0.517805
global_step: 9118, epoch: 28, loss: 0.578682
global_step: 9119, epoch: 28, loss: 0.547933
global_step: 9120, epoch: 28, loss: 0.735094
epoch: 28
train	acc: 0.8708	macro: p 0.9166, r 0.7614, f1: 0.8218	micro: p 0.8708, r 0.8708, f1 0.8708	weighted_f1:0.8669
dev	acc: 0.5681	macro: p 0.5086, r 0.3344, f1: 0.3526	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5192
test	acc: 0.5977	macro: p 0.4677, r 0.3262, f1: 0.3451	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5522
global_step: 9121, epoch: 29, loss: 0.576637
global_step: 9122, epoch: 29, loss: 0.510582
global_step: 9123, epoch: 29, loss: 0.460520
global_step: 9124, epoch: 29, loss: 0.517048
global_step: 9125, epoch: 29, loss: 0.493592
global_step: 9126, epoch: 29, loss: 0.477998
global_step: 9127, epoch: 29, loss: 0.421760
global_step: 9128, epoch: 29, loss: 0.524397
global_step: 9129, epoch: 29, loss: 0.429956
global_step: 9130, epoch: 29, loss: 0.549795
global_step: 9131, epoch: 29, loss: 0.460734
global_step: 9132, epoch: 29, loss: 0.624843
global_step: 9133, epoch: 29, loss: 0.520870
global_step: 9134, epoch: 29, loss: 0.435745
global_step: 9135, epoch: 29, loss: 0.596965
global_step: 9136, epoch: 29, loss: 0.501893
global_step: 9137, epoch: 29, loss: 0.466335
global_step: 9138, epoch: 29, loss: 0.529652
global_step: 9139, epoch: 29, loss: 0.423169
global_step: 9140, epoch: 29, loss: 0.401077
global_step: 9141, epoch: 29, loss: 0.543068
global_step: 9142, epoch: 29, loss: 0.493209
global_step: 9143, epoch: 29, loss: 0.566537
global_step: 9144, epoch: 29, loss: 0.474530
global_step: 9145, epoch: 29, loss: 0.470541
global_step: 9146, epoch: 29, loss: 0.713681
global_step: 9147, epoch: 29, loss: 0.666476
global_step: 9148, epoch: 29, loss: 0.451387
global_step: 9149, epoch: 29, loss: 0.624685
global_step: 9150, epoch: 29, loss: 0.545658
global_step: 9151, epoch: 29, loss: 0.588544
global_step: 9152, epoch: 29, loss: 0.537757
global_step: 9153, epoch: 29, loss: 0.534953
global_step: 9154, epoch: 29, loss: 0.472148
global_step: 9155, epoch: 29, loss: 0.515128
global_step: 9156, epoch: 29, loss: 0.612529
global_step: 9157, epoch: 29, loss: 0.510566
global_step: 9158, epoch: 29, loss: 0.526384
global_step: 9159, epoch: 29, loss: 0.667368
global_step: 9160, epoch: 29, loss: 0.715994
epoch: 29
train	acc: 0.8748	macro: p 0.8859, r 0.8082, f1: 0.8359	micro: p 0.8748, r 0.8748, f1 0.8748	weighted_f1:0.8729
dev	acc: 0.5473	macro: p 0.4372, r 0.3597, f1: 0.3575	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5036
test	acc: 0.5644	macro: p 0.3725, r 0.3357, f1: 0.3291	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5311
global_step: 9161, epoch: 30, loss: 0.581113
global_step: 9162, epoch: 30, loss: 0.502124
global_step: 9163, epoch: 30, loss: 0.526449
global_step: 9164, epoch: 30, loss: 0.457937
global_step: 9165, epoch: 30, loss: 0.387182
global_step: 9166, epoch: 30, loss: 0.416992
global_step: 9167, epoch: 30, loss: 0.501489
global_step: 9168, epoch: 30, loss: 0.419757
global_step: 9169, epoch: 30, loss: 0.521399
global_step: 9170, epoch: 30, loss: 0.488970
global_step: 9171, epoch: 30, loss: 0.539035
global_step: 9172, epoch: 30, loss: 0.448208
global_step: 9173, epoch: 30, loss: 0.532843
global_step: 9174, epoch: 30, loss: 0.449534
global_step: 9175, epoch: 30, loss: 0.445690
global_step: 9176, epoch: 30, loss: 0.397618
global_step: 9177, epoch: 30, loss: 0.457453
global_step: 9178, epoch: 30, loss: 0.511298
global_step: 9179, epoch: 30, loss: 0.465708
global_step: 9180, epoch: 30, loss: 0.516702
global_step: 9181, epoch: 30, loss: 0.496831
global_step: 9182, epoch: 30, loss: 0.487018
global_step: 9183, epoch: 30, loss: 0.503360
global_step: 9184, epoch: 30, loss: 0.505975
global_step: 9185, epoch: 30, loss: 0.386504
global_step: 9186, epoch: 30, loss: 0.605640
global_step: 9187, epoch: 30, loss: 0.547992
global_step: 9188, epoch: 30, loss: 0.435570
global_step: 9189, epoch: 30, loss: 0.385485
global_step: 9190, epoch: 30, loss: 0.484197
global_step: 9191, epoch: 30, loss: 0.469090
global_step: 9192, epoch: 30, loss: 0.515181
global_step: 9193, epoch: 30, loss: 0.500994
global_step: 9194, epoch: 30, loss: 0.544458
global_step: 9195, epoch: 30, loss: 0.522708
global_step: 9196, epoch: 30, loss: 0.527841
global_step: 9197, epoch: 30, loss: 0.465410
global_step: 9198, epoch: 30, loss: 0.559936
global_step: 9199, epoch: 30, loss: 0.551339
global_step: 9200, epoch: 30, loss: 0.648102
epoch: 30
train	acc: 0.9068	macro: p 0.9040, r 0.8516, f1: 0.8731	micro: p 0.9068, r 0.9068, f1 0.9068	weighted_f1:0.9060
dev	acc: 0.5564	macro: p 0.4156, r 0.3606, f1: 0.3626	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5260
test	acc: 0.5839	macro: p 0.3867, r 0.3612, f1: 0.3620	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5624
global_step: 9201, epoch: 31, loss: 0.598638
global_step: 9202, epoch: 31, loss: 0.461168
global_step: 9203, epoch: 31, loss: 0.431636
global_step: 9204, epoch: 31, loss: 0.600874
global_step: 9205, epoch: 31, loss: 0.415848
global_step: 9206, epoch: 31, loss: 0.475818
global_step: 9207, epoch: 31, loss: 0.479271
global_step: 9208, epoch: 31, loss: 0.616139
global_step: 9209, epoch: 31, loss: 0.504386
global_step: 9210, epoch: 31, loss: 0.500639
global_step: 9211, epoch: 31, loss: 0.424157
global_step: 9212, epoch: 31, loss: 0.425504
global_step: 9213, epoch: 31, loss: 0.408689
global_step: 9214, epoch: 31, loss: 0.483611
global_step: 9215, epoch: 31, loss: 0.489817
global_step: 9216, epoch: 31, loss: 0.495097
global_step: 9217, epoch: 31, loss: 0.502566
global_step: 9218, epoch: 31, loss: 0.477288
global_step: 9219, epoch: 31, loss: 0.471798
global_step: 9220, epoch: 31, loss: 0.434056
global_step: 9221, epoch: 31, loss: 0.454780
global_step: 9222, epoch: 31, loss: 0.437498
global_step: 9223, epoch: 31, loss: 0.453238
global_step: 9224, epoch: 31, loss: 0.521638
global_step: 9225, epoch: 31, loss: 0.401803
global_step: 9226, epoch: 31, loss: 0.483013
global_step: 9227, epoch: 31, loss: 0.528311
global_step: 9228, epoch: 31, loss: 0.507370
global_step: 9229, epoch: 31, loss: 0.432486
global_step: 9230, epoch: 31, loss: 0.469467
global_step: 9231, epoch: 31, loss: 0.546254
global_step: 9232, epoch: 31, loss: 0.473147
global_step: 9233, epoch: 31, loss: 0.459614
global_step: 9234, epoch: 31, loss: 0.403063
global_step: 9235, epoch: 31, loss: 0.403132
global_step: 9236, epoch: 31, loss: 0.452262
global_step: 9237, epoch: 31, loss: 0.618766
global_step: 9238, epoch: 31, loss: 0.445913
global_step: 9239, epoch: 31, loss: 0.528044
global_step: 9240, epoch: 31, loss: 0.046165
epoch: 31
train	acc: 0.9092	macro: p 0.9241, r 0.8380, f1: 0.8747	micro: p 0.9092, r 0.9092, f1 0.9092	weighted_f1:0.9077
dev	acc: 0.5681	macro: p 0.4814, r 0.3476, f1: 0.3651	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5240
test	acc: 0.5981	macro: p 0.4306, r 0.3419, f1: 0.3611	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5616
global_step: 9241, epoch: 32, loss: 0.499217
global_step: 9242, epoch: 32, loss: 0.374199
global_step: 9243, epoch: 32, loss: 0.421635
global_step: 9244, epoch: 32, loss: 0.489562
global_step: 9245, epoch: 32, loss: 0.410290
global_step: 9246, epoch: 32, loss: 0.476973
global_step: 9247, epoch: 32, loss: 0.458520
global_step: 9248, epoch: 32, loss: 0.413989
global_step: 9249, epoch: 32, loss: 0.566461
global_step: 9250, epoch: 32, loss: 0.457096
global_step: 9251, epoch: 32, loss: 0.420010
global_step: 9252, epoch: 32, loss: 0.412169
global_step: 9253, epoch: 32, loss: 0.441307
global_step: 9254, epoch: 32, loss: 0.362956
global_step: 9255, epoch: 32, loss: 0.361901
global_step: 9256, epoch: 32, loss: 0.415899
global_step: 9257, epoch: 32, loss: 0.408901
global_step: 9258, epoch: 32, loss: 0.522355
global_step: 9259, epoch: 32, loss: 0.538622
global_step: 9260, epoch: 32, loss: 0.558643
global_step: 9261, epoch: 32, loss: 0.478606
global_step: 9262, epoch: 32, loss: 0.470252
global_step: 9263, epoch: 32, loss: 0.475523
global_step: 9264, epoch: 32, loss: 0.509743
global_step: 9265, epoch: 32, loss: 0.542692
global_step: 9266, epoch: 32, loss: 0.363795
global_step: 9267, epoch: 32, loss: 0.483703
global_step: 9268, epoch: 32, loss: 0.531139
global_step: 9269, epoch: 32, loss: 0.535864
global_step: 9270, epoch: 32, loss: 0.484196
global_step: 9271, epoch: 32, loss: 0.595176
global_step: 9272, epoch: 32, loss: 0.515927
global_step: 9273, epoch: 32, loss: 0.618818
global_step: 9274, epoch: 32, loss: 0.532584
global_step: 9275, epoch: 32, loss: 0.550336
global_step: 9276, epoch: 32, loss: 0.543465
global_step: 9277, epoch: 32, loss: 0.457696
global_step: 9278, epoch: 32, loss: 0.523423
global_step: 9279, epoch: 32, loss: 0.613802
global_step: 9280, epoch: 32, loss: 0.122918
epoch: 32
train	acc: 0.9069	macro: p 0.9145, r 0.8438, f1: 0.8728	micro: p 0.9069, r 0.9069, f1 0.9069	weighted_f1:0.9063
dev	acc: 0.5455	macro: p 0.4121, r 0.3534, f1: 0.3401	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5043
test	acc: 0.5632	macro: p 0.3992, r 0.3373, f1: 0.3270	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.5330
global_step: 9281, epoch: 33, loss: 0.425397
global_step: 9282, epoch: 33, loss: 0.460746
global_step: 9283, epoch: 33, loss: 0.400747
global_step: 9284, epoch: 33, loss: 0.380739
global_step: 9285, epoch: 33, loss: 0.426553
global_step: 9286, epoch: 33, loss: 0.507247
global_step: 9287, epoch: 33, loss: 0.363116
global_step: 9288, epoch: 33, loss: 0.414453
global_step: 9289, epoch: 33, loss: 0.382751
global_step: 9290, epoch: 33, loss: 0.459463
global_step: 9291, epoch: 33, loss: 0.513087
global_step: 9292, epoch: 33, loss: 0.452433
global_step: 9293, epoch: 33, loss: 0.393363
global_step: 9294, epoch: 33, loss: 0.435693
global_step: 9295, epoch: 33, loss: 0.476528
global_step: 9296, epoch: 33, loss: 0.582059
global_step: 9297, epoch: 33, loss: 0.522427
global_step: 9298, epoch: 33, loss: 0.515140
global_step: 9299, epoch: 33, loss: 0.392358
global_step: 9300, epoch: 33, loss: 0.477958
global_step: 9301, epoch: 33, loss: 0.429161
global_step: 9302, epoch: 33, loss: 0.414755
global_step: 9303, epoch: 33, loss: 0.537601
global_step: 9304, epoch: 33, loss: 0.428491
global_step: 9305, epoch: 33, loss: 0.534567
global_step: 9306, epoch: 33, loss: 0.397515
global_step: 9307, epoch: 33, loss: 0.484351
global_step: 9308, epoch: 33, loss: 0.619987
global_step: 9309, epoch: 33, loss: 0.416200
global_step: 9310, epoch: 33, loss: 0.409099
global_step: 9311, epoch: 33, loss: 0.468242
global_step: 9312, epoch: 33, loss: 0.535909
global_step: 9313, epoch: 33, loss: 0.440398
global_step: 9314, epoch: 33, loss: 0.386434
global_step: 9315, epoch: 33, loss: 0.569740
global_step: 9316, epoch: 33, loss: 0.351432
global_step: 9317, epoch: 33, loss: 0.498788
global_step: 9318, epoch: 33, loss: 0.474517
global_step: 9319, epoch: 33, loss: 0.473073
global_step: 9320, epoch: 33, loss: 0.180501
epoch: 33
train	acc: 0.8749	macro: p 0.9299, r 0.7494, f1: 0.8153	micro: p 0.8749, r 0.8749, f1 0.8749	weighted_f1:0.8695
dev	acc: 0.5482	macro: p 0.4680, r 0.3121, f1: 0.3168	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4859
test	acc: 0.5977	macro: p 0.4389, r 0.3143, f1: 0.3202	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5401
global_step: 9321, epoch: 34, loss: 0.542903
global_step: 9322, epoch: 34, loss: 0.478983
global_step: 9323, epoch: 34, loss: 0.559950
global_step: 9324, epoch: 34, loss: 0.488761
global_step: 9325, epoch: 34, loss: 0.385377
global_step: 9326, epoch: 34, loss: 0.428574
global_step: 9327, epoch: 34, loss: 0.452811
global_step: 9328, epoch: 34, loss: 0.452260
global_step: 9329, epoch: 34, loss: 0.480264
global_step: 9330, epoch: 34, loss: 0.557449
global_step: 9331, epoch: 34, loss: 0.517634
global_step: 9332, epoch: 34, loss: 0.468585
global_step: 9333, epoch: 34, loss: 0.529479
global_step: 9334, epoch: 34, loss: 0.472999
global_step: 9335, epoch: 34, loss: 0.421507
global_step: 9336, epoch: 34, loss: 0.466388
global_step: 9337, epoch: 34, loss: 0.413207
global_step: 9338, epoch: 34, loss: 0.417428
global_step: 9339, epoch: 34, loss: 0.486387
global_step: 9340, epoch: 34, loss: 0.415097
global_step: 9341, epoch: 34, loss: 0.459610
global_step: 9342, epoch: 34, loss: 0.443567
global_step: 9343, epoch: 34, loss: 0.475714
global_step: 9344, epoch: 34, loss: 0.451087
global_step: 9345, epoch: 34, loss: 0.432912
global_step: 9346, epoch: 34, loss: 0.467202
global_step: 9347, epoch: 34, loss: 0.418458
global_step: 9348, epoch: 34, loss: 0.366017
global_step: 9349, epoch: 34, loss: 0.433750
global_step: 9350, epoch: 34, loss: 0.482119
global_step: 9351, epoch: 34, loss: 0.397600
global_step: 9352, epoch: 34, loss: 0.411412
global_step: 9353, epoch: 34, loss: 0.539534
global_step: 9354, epoch: 34, loss: 0.433405
global_step: 9355, epoch: 34, loss: 0.404406
global_step: 9356, epoch: 34, loss: 0.539272
global_step: 9357, epoch: 34, loss: 0.618661
global_step: 9358, epoch: 34, loss: 0.614126
global_step: 9359, epoch: 34, loss: 0.464241
global_step: 9360, epoch: 34, loss: 0.322625
epoch: 34
train	acc: 0.8567	macro: p 0.9222, r 0.7755, f1: 0.8351	micro: p 0.8567, r 0.8567, f1 0.8567	weighted_f1:0.8529
dev	acc: 0.5437	macro: p 0.4384, r 0.2916, f1: 0.3079	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4766
test	acc: 0.5943	macro: p 0.4892, r 0.3125, f1: 0.3464	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5368
global_step: 9361, epoch: 35, loss: 0.658468
global_step: 9362, epoch: 35, loss: 0.551298
global_step: 9363, epoch: 35, loss: 0.461798
global_step: 9364, epoch: 35, loss: 0.531982
global_step: 9365, epoch: 35, loss: 0.460209
global_step: 9366, epoch: 35, loss: 0.432882
global_step: 9367, epoch: 35, loss: 0.428811
global_step: 9368, epoch: 35, loss: 0.358841
global_step: 9369, epoch: 35, loss: 0.394695
global_step: 9370, epoch: 35, loss: 0.432990
global_step: 9371, epoch: 35, loss: 0.480496
global_step: 9372, epoch: 35, loss: 0.410238
global_step: 9373, epoch: 35, loss: 0.401917
global_step: 9374, epoch: 35, loss: 0.490508
global_step: 9375, epoch: 35, loss: 0.430452
global_step: 9376, epoch: 35, loss: 0.566770
global_step: 9377, epoch: 35, loss: 0.372952
global_step: 9378, epoch: 35, loss: 0.478784
global_step: 9379, epoch: 35, loss: 0.375324
global_step: 9380, epoch: 35, loss: 0.467926
global_step: 9381, epoch: 35, loss: 0.359297
global_step: 9382, epoch: 35, loss: 0.391223
global_step: 9383, epoch: 35, loss: 0.400751
global_step: 9384, epoch: 35, loss: 0.306233
global_step: 9385, epoch: 35, loss: 0.404873
global_step: 9386, epoch: 35, loss: 0.500356
global_step: 9387, epoch: 35, loss: 0.537610
global_step: 9388, epoch: 35, loss: 0.541495
global_step: 9389, epoch: 35, loss: 0.358515
global_step: 9390, epoch: 35, loss: 0.439229
global_step: 9391, epoch: 35, loss: 0.384085
global_step: 9392, epoch: 35, loss: 0.361444
global_step: 9393, epoch: 35, loss: 0.442058
global_step: 9394, epoch: 35, loss: 0.499374
global_step: 9395, epoch: 35, loss: 0.517745
global_step: 9396, epoch: 35, loss: 0.433171
global_step: 9397, epoch: 35, loss: 0.517590
global_step: 9398, epoch: 35, loss: 0.477722
global_step: 9399, epoch: 35, loss: 0.443376
global_step: 9400, epoch: 35, loss: 1.260862
epoch: 35
train	acc: 0.9123	macro: p 0.9202, r 0.8501, f1: 0.8813	micro: p 0.9123, r 0.9123, f1 0.9123	weighted_f1:0.9112
dev	acc: 0.5528	macro: p 0.4534, r 0.3438, f1: 0.3607	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5127
test	acc: 0.5816	macro: p 0.3996, r 0.3340, f1: 0.3470	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5484
global_step: 9401, epoch: 36, loss: 0.500756
global_step: 9402, epoch: 36, loss: 0.401703
global_step: 9403, epoch: 36, loss: 0.430418
global_step: 9404, epoch: 36, loss: 0.451276
global_step: 9405, epoch: 36, loss: 0.467557
global_step: 9406, epoch: 36, loss: 0.430085
global_step: 9407, epoch: 36, loss: 0.419769
global_step: 9408, epoch: 36, loss: 0.374892
global_step: 9409, epoch: 36, loss: 0.356548
global_step: 9410, epoch: 36, loss: 0.457738
global_step: 9411, epoch: 36, loss: 0.429399
global_step: 9412, epoch: 36, loss: 0.354202
global_step: 9413, epoch: 36, loss: 0.438593
global_step: 9414, epoch: 36, loss: 0.445814
global_step: 9415, epoch: 36, loss: 0.400725
global_step: 9416, epoch: 36, loss: 0.494523
global_step: 9417, epoch: 36, loss: 0.433578
global_step: 9418, epoch: 36, loss: 0.456324
global_step: 9419, epoch: 36, loss: 0.432871
global_step: 9420, epoch: 36, loss: 0.427740
global_step: 9421, epoch: 36, loss: 0.452933
global_step: 9422, epoch: 36, loss: 0.421822
global_step: 9423, epoch: 36, loss: 0.394925
global_step: 9424, epoch: 36, loss: 0.317504
global_step: 9425, epoch: 36, loss: 0.400897
global_step: 9426, epoch: 36, loss: 0.416354
global_step: 9427, epoch: 36, loss: 0.463806
global_step: 9428, epoch: 36, loss: 0.388406
global_step: 9429, epoch: 36, loss: 0.530015
global_step: 9430, epoch: 36, loss: 0.480816
global_step: 9431, epoch: 36, loss: 0.465755
global_step: 9432, epoch: 36, loss: 0.448675
global_step: 9433, epoch: 36, loss: 0.464066
global_step: 9434, epoch: 36, loss: 0.538700
global_step: 9435, epoch: 36, loss: 0.432424
global_step: 9436, epoch: 36, loss: 0.441074
global_step: 9437, epoch: 36, loss: 0.394653
global_step: 9438, epoch: 36, loss: 0.407331
global_step: 9439, epoch: 36, loss: 0.378934
global_step: 9440, epoch: 36, loss: 0.184862
epoch: 36
train	acc: 0.9234	macro: p 0.9359, r 0.8739, f1: 0.9007	micro: p 0.9234, r 0.9234, f1 0.9234	weighted_f1:0.9225
dev	acc: 0.5564	macro: p 0.4433, r 0.3350, f1: 0.3411	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5155
test	acc: 0.5992	macro: p 0.4329, r 0.3487, f1: 0.3620	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5646
global_step: 9441, epoch: 37, loss: 0.309209
global_step: 9442, epoch: 37, loss: 0.355691
global_step: 9443, epoch: 37, loss: 0.394732
global_step: 9444, epoch: 37, loss: 0.345890
global_step: 9445, epoch: 37, loss: 0.374592
global_step: 9446, epoch: 37, loss: 0.515988
global_step: 9447, epoch: 37, loss: 0.353919
global_step: 9448, epoch: 37, loss: 0.366935
global_step: 9449, epoch: 37, loss: 0.340561
global_step: 9450, epoch: 37, loss: 0.361099
global_step: 9451, epoch: 37, loss: 0.439738
global_step: 9452, epoch: 37, loss: 0.295357
global_step: 9453, epoch: 37, loss: 0.449405
global_step: 9454, epoch: 37, loss: 0.412373
global_step: 9455, epoch: 37, loss: 0.409779
global_step: 9456, epoch: 37, loss: 0.463163
global_step: 9457, epoch: 37, loss: 0.348672
global_step: 9458, epoch: 37, loss: 0.374463
global_step: 9459, epoch: 37, loss: 0.378657
global_step: 9460, epoch: 37, loss: 0.421478
global_step: 9461, epoch: 37, loss: 0.392367
global_step: 9462, epoch: 37, loss: 0.425819
global_step: 9463, epoch: 37, loss: 0.436124
global_step: 9464, epoch: 37, loss: 0.377997
global_step: 9465, epoch: 37, loss: 0.430035
global_step: 9466, epoch: 37, loss: 0.388810
global_step: 9467, epoch: 37, loss: 0.527027
global_step: 9468, epoch: 37, loss: 0.429649
global_step: 9469, epoch: 37, loss: 0.452967
global_step: 9470, epoch: 37, loss: 0.461773
global_step: 9471, epoch: 37, loss: 0.460262
global_step: 9472, epoch: 37, loss: 0.421485
global_step: 9473, epoch: 37, loss: 0.406348
global_step: 9474, epoch: 37, loss: 0.419927
global_step: 9475, epoch: 37, loss: 0.407756
global_step: 9476, epoch: 37, loss: 0.384327
global_step: 9477, epoch: 37, loss: 0.405119
global_step: 9478, epoch: 37, loss: 0.360173
global_step: 9479, epoch: 37, loss: 0.404742
global_step: 9480, epoch: 37, loss: 0.653345
epoch: 37
train	acc: 0.9332	macro: p 0.9415, r 0.8972, f1: 0.9174	micro: p 0.9332, r 0.9332, f1 0.9332	weighted_f1:0.9331
dev	acc: 0.5555	macro: p 0.4080, r 0.3538, f1: 0.3555	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5205
test	acc: 0.5923	macro: p 0.4220, r 0.3616, f1: 0.3685	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5644
global_step: 9481, epoch: 38, loss: 0.341074
global_step: 9482, epoch: 38, loss: 0.395638
global_step: 9483, epoch: 38, loss: 0.440870
global_step: 9484, epoch: 38, loss: 0.308159
global_step: 9485, epoch: 38, loss: 0.343927
global_step: 9486, epoch: 38, loss: 0.387835
global_step: 9487, epoch: 38, loss: 0.414489
global_step: 9488, epoch: 38, loss: 0.311732
global_step: 9489, epoch: 38, loss: 0.384099
global_step: 9490, epoch: 38, loss: 0.377829
global_step: 9491, epoch: 38, loss: 0.443251
global_step: 9492, epoch: 38, loss: 0.417895
global_step: 9493, epoch: 38, loss: 0.318555
global_step: 9494, epoch: 38, loss: 0.309817
global_step: 9495, epoch: 38, loss: 0.393237
global_step: 9496, epoch: 38, loss: 0.372502
global_step: 9497, epoch: 38, loss: 0.386512
global_step: 9498, epoch: 38, loss: 0.382557
global_step: 9499, epoch: 38, loss: 0.447882
global_step: 9500, epoch: 38, loss: 0.351099
global_step: 9501, epoch: 38, loss: 0.476521
global_step: 9502, epoch: 38, loss: 0.320568
global_step: 9503, epoch: 38, loss: 0.396545
global_step: 9504, epoch: 38, loss: 0.466259
global_step: 9505, epoch: 38, loss: 0.417879
global_step: 9506, epoch: 38, loss: 0.342958
global_step: 9507, epoch: 38, loss: 0.398303
global_step: 9508, epoch: 38, loss: 0.354138
global_step: 9509, epoch: 38, loss: 0.298411
global_step: 9510, epoch: 38, loss: 0.290016
global_step: 9511, epoch: 38, loss: 0.367535
global_step: 9512, epoch: 38, loss: 0.417927
global_step: 9513, epoch: 38, loss: 0.382286
global_step: 9514, epoch: 38, loss: 0.470952
global_step: 9515, epoch: 38, loss: 0.457301
global_step: 9516, epoch: 38, loss: 0.473488
global_step: 9517, epoch: 38, loss: 0.359962
global_step: 9518, epoch: 38, loss: 0.457143
global_step: 9519, epoch: 38, loss: 0.367368
global_step: 9520, epoch: 38, loss: 0.886852
epoch: 38
train	acc: 0.9200	macro: p 0.9248, r 0.8692, f1: 0.8920	micro: p 0.9200, r 0.9200, f1 0.9200	weighted_f1:0.9200
dev	acc: 0.5392	macro: p 0.4330, r 0.3486, f1: 0.3555	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5185
test	acc: 0.5728	macro: p 0.3983, r 0.3539, f1: 0.3570	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5593
global_step: 9521, epoch: 39, loss: 0.390281
global_step: 9522, epoch: 39, loss: 0.457123
global_step: 9523, epoch: 39, loss: 0.448168
global_step: 9524, epoch: 39, loss: 0.394894
global_step: 9525, epoch: 39, loss: 0.288615
global_step: 9526, epoch: 39, loss: 0.457031
global_step: 9527, epoch: 39, loss: 0.408554
global_step: 9528, epoch: 39, loss: 0.374114
global_step: 9529, epoch: 39, loss: 0.385002
global_step: 9530, epoch: 39, loss: 0.321653
global_step: 9531, epoch: 39, loss: 0.411761
global_step: 9532, epoch: 39, loss: 0.332609
global_step: 9533, epoch: 39, loss: 0.353615
global_step: 9534, epoch: 39, loss: 0.309248
global_step: 9535, epoch: 39, loss: 0.396803
global_step: 9536, epoch: 39, loss: 0.364041
global_step: 9537, epoch: 39, loss: 0.406634
global_step: 9538, epoch: 39, loss: 0.443203
global_step: 9539, epoch: 39, loss: 0.406878
global_step: 9540, epoch: 39, loss: 0.370597
global_step: 9541, epoch: 39, loss: 0.415903
global_step: 9542, epoch: 39, loss: 0.483191
global_step: 9543, epoch: 39, loss: 0.343619
global_step: 9544, epoch: 39, loss: 0.454888
global_step: 9545, epoch: 39, loss: 0.364280
global_step: 9546, epoch: 39, loss: 0.394155
global_step: 9547, epoch: 39, loss: 0.428866
global_step: 9548, epoch: 39, loss: 0.382971
global_step: 9549, epoch: 39, loss: 0.433387
global_step: 9550, epoch: 39, loss: 0.457570
global_step: 9551, epoch: 39, loss: 0.413736
global_step: 9552, epoch: 39, loss: 0.403112
global_step: 9553, epoch: 39, loss: 0.402051
global_step: 9554, epoch: 39, loss: 0.447240
global_step: 9555, epoch: 39, loss: 0.463115
global_step: 9556, epoch: 39, loss: 0.520614
global_step: 9557, epoch: 39, loss: 0.429924
global_step: 9558, epoch: 39, loss: 0.369202
global_step: 9559, epoch: 39, loss: 0.397817
global_step: 9560, epoch: 39, loss: 0.541340
epoch: 39
train	acc: 0.9007	macro: p 0.9315, r 0.8196, f1: 0.8647	micro: p 0.9007, r 0.9007, f1 0.9007	weighted_f1:0.8978
dev	acc: 0.5555	macro: p 0.4397, r 0.3225, f1: 0.3296	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5015
test	acc: 0.6073	macro: p 0.4597, r 0.3377, f1: 0.3509	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5617
global_step: 9561, epoch: 40, loss: 0.535345
global_step: 9562, epoch: 40, loss: 0.422801
global_step: 9563, epoch: 40, loss: 0.390785
global_step: 9564, epoch: 40, loss: 0.458559
global_step: 9565, epoch: 40, loss: 0.330214
global_step: 9566, epoch: 40, loss: 0.449036
global_step: 9567, epoch: 40, loss: 0.379820
global_step: 9568, epoch: 40, loss: 0.351505
global_step: 9569, epoch: 40, loss: 0.374496
global_step: 9570, epoch: 40, loss: 0.442153
global_step: 9571, epoch: 40, loss: 0.359917
global_step: 9572, epoch: 40, loss: 0.375094
global_step: 9573, epoch: 40, loss: 0.385178
global_step: 9574, epoch: 40, loss: 0.386696
global_step: 9575, epoch: 40, loss: 0.342712
global_step: 9576, epoch: 40, loss: 0.342410
global_step: 9577, epoch: 40, loss: 0.442677
global_step: 9578, epoch: 40, loss: 0.369582
global_step: 9579, epoch: 40, loss: 0.404304
global_step: 9580, epoch: 40, loss: 0.321425
global_step: 9581, epoch: 40, loss: 0.392549
global_step: 9582, epoch: 40, loss: 0.414002
global_step: 9583, epoch: 40, loss: 0.462441
global_step: 9584, epoch: 40, loss: 0.393296
global_step: 9585, epoch: 40, loss: 0.375477
global_step: 9586, epoch: 40, loss: 0.455094
global_step: 9587, epoch: 40, loss: 0.429350
global_step: 9588, epoch: 40, loss: 0.414009
global_step: 9589, epoch: 40, loss: 0.347797
global_step: 9590, epoch: 40, loss: 0.471721
global_step: 9591, epoch: 40, loss: 0.348457
global_step: 9592, epoch: 40, loss: 0.434604
global_step: 9593, epoch: 40, loss: 0.360796
global_step: 9594, epoch: 40, loss: 0.428828
global_step: 9595, epoch: 40, loss: 0.391534
global_step: 9596, epoch: 40, loss: 0.418609
global_step: 9597, epoch: 40, loss: 0.388323
global_step: 9598, epoch: 40, loss: 0.319376
global_step: 9599, epoch: 40, loss: 0.419941
global_step: 9600, epoch: 40, loss: 0.032030
epoch: 40
train	acc: 0.9394	macro: p 0.9447, r 0.9048, f1: 0.9232	micro: p 0.9394, r 0.9394, f1 0.9394	weighted_f1:0.9392
dev	acc: 0.5591	macro: p 0.4158, r 0.3583, f1: 0.3642	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5263
test	acc: 0.5831	macro: p 0.4042, r 0.3579, f1: 0.3628	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5597
global_step: 9601, epoch: 41, loss: 0.383356
global_step: 9602, epoch: 41, loss: 0.338223
global_step: 9603, epoch: 41, loss: 0.339272
global_step: 9604, epoch: 41, loss: 0.287800
global_step: 9605, epoch: 41, loss: 0.420885
global_step: 9606, epoch: 41, loss: 0.350425
global_step: 9607, epoch: 41, loss: 0.362075
global_step: 9608, epoch: 41, loss: 0.293140
global_step: 9609, epoch: 41, loss: 0.366038
global_step: 9610, epoch: 41, loss: 0.378801
global_step: 9611, epoch: 41, loss: 0.305786
global_step: 9612, epoch: 41, loss: 0.355890
global_step: 9613, epoch: 41, loss: 0.322402
global_step: 9614, epoch: 41, loss: 0.395157
global_step: 9615, epoch: 41, loss: 0.351839
global_step: 9616, epoch: 41, loss: 0.347454
global_step: 9617, epoch: 41, loss: 0.394442
global_step: 9618, epoch: 41, loss: 0.380704
global_step: 9619, epoch: 41, loss: 0.373973
global_step: 9620, epoch: 41, loss: 0.402753
global_step: 9621, epoch: 41, loss: 0.436554
global_step: 9622, epoch: 41, loss: 0.412500
global_step: 9623, epoch: 41, loss: 0.350067
global_step: 9624, epoch: 41, loss: 0.357888
global_step: 9625, epoch: 41, loss: 0.469316
global_step: 9626, epoch: 41, loss: 0.396839
global_step: 9627, epoch: 41, loss: 0.423645
global_step: 9628, epoch: 41, loss: 0.366629
global_step: 9629, epoch: 41, loss: 0.480148
global_step: 9630, epoch: 41, loss: 0.292508
global_step: 9631, epoch: 41, loss: 0.429112
global_step: 9632, epoch: 41, loss: 0.393974
global_step: 9633, epoch: 41, loss: 0.314175
global_step: 9634, epoch: 41, loss: 0.368822
global_step: 9635, epoch: 41, loss: 0.372380
global_step: 9636, epoch: 41, loss: 0.404847
global_step: 9637, epoch: 41, loss: 0.334531
global_step: 9638, epoch: 41, loss: 0.513748
global_step: 9639, epoch: 41, loss: 0.445535
global_step: 9640, epoch: 41, loss: 1.260833
epoch: 41
train	acc: 0.9334	macro: p 0.9278, r 0.9055, f1: 0.9147	micro: p 0.9334, r 0.9334, f1 0.9334	weighted_f1:0.9335
dev	acc: 0.5410	macro: p 0.3881, r 0.3659, f1: 0.3654	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5281
test	acc: 0.5513	macro: p 0.3809, r 0.3667, f1: 0.3675	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5468
global_step: 9641, epoch: 42, loss: 0.435372
global_step: 9642, epoch: 42, loss: 0.442182
global_step: 9643, epoch: 42, loss: 0.272226
global_step: 9644, epoch: 42, loss: 0.380729
global_step: 9645, epoch: 42, loss: 0.379742
global_step: 9646, epoch: 42, loss: 0.358911
global_step: 9647, epoch: 42, loss: 0.312748run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

global_step: 9648, epoch: 42, loss: 0.310210
global_step: 9649, epoch: 42, loss: 0.421567
global_step: 9650, epoch: 42, loss: 0.363066
global_step: 9651, epoch: 42, loss: 0.365116
global_step: 9652, epoch: 42, loss: 0.317301
global_step: 9653, epoch: 42, loss: 0.378531
global_step: 9654, epoch: 42, loss: 0.347317
global_step: 9655, epoch: 42, loss: 0.336873
global_step: 9656, epoch: 42, loss: 0.292001
global_step: 9657, epoch: 42, loss: 0.450324
global_step: 9658, epoch: 42, loss: 0.414294
global_step: 9659, epoch: 42, loss: 0.456720
global_step: 9660, epoch: 42, loss: 0.364790
global_step: 9661, epoch: 42, loss: 0.373670
global_step: 9662, epoch: 42, loss: 0.341413
global_step: 9663, epoch: 42, loss: 0.403418
global_step: 9664, epoch: 42, loss: 0.305392
global_step: 9665, epoch: 42, loss: 0.327943
global_step: 9666, epoch: 42, loss: 0.309833
global_step: 9667, epoch: 42, loss: 0.489114
global_step: 9668, epoch: 42, loss: 0.363857
global_step: 9669, epoch: 42, loss: 0.323693
global_step: 9670, epoch: 42, loss: 0.387460
global_step: 9671, epoch: 42, loss: 0.398299
global_step: 9672, epoch: 42, loss: 0.406072
global_step: 9673, epoch: 42, loss: 0.374824
global_step: 9674, epoch: 42, loss: 0.350433
global_step: 9675, epoch: 42, loss: 0.444431
global_step: 9676, epoch: 42, loss: 0.299684
global_step: 9677, epoch: 42, loss: 0.441887
global_step: 9678, epoch: 42, loss: 0.371937
global_step: 9679, epoch: 42, loss: 0.404849
global_step: 9680, epoch: 42, loss: 0.003507
epoch: 42
train	acc: 0.9413	macro: p 0.9441, r 0.9109, f1: 0.9261	micro: p 0.9413, r 0.9413, f1 0.9413	weighted_f1:0.9412
dev	acc: 0.5537	macro: p 0.4170, r 0.3525, f1: 0.3600	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5229
test	acc: 0.5843	macro: p 0.4150, r 0.3584, f1: 0.3670	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5625
global_step: 9681, epoch: 43, loss: 0.394181
global_step: 9682, epoch: 43, loss: 0.314491
global_step: 9683, epoch: 43, loss: 0.401772
global_step: 9684, epoch: 43, loss: 0.325521
global_step: 9685, epoch: 43, loss: 0.408060
global_step: 9686, epoch: 43, loss: 0.344470
global_step: 9687, epoch: 43, loss: 0.371853
global_step: 9688, epoch: 43, loss: 0.242771
global_step: 9689, epoch: 43, loss: 0.270716
global_step: 9690, epoch: 43, loss: 0.385526
global_step: 9691, epoch: 43, loss: 0.326317
global_step: 9692, epoch: 43, loss: 0.351110
global_step: 9693, epoch: 43, loss: 0.378180
global_step: 9694, epoch: 43, loss: 0.368124
global_step: 9695, epoch: 43, loss: 0.281300
global_step: 9696, epoch: 43, loss: 0.280089
global_step: 9697, epoch: 43, loss: 0.409947
global_step: 9698, epoch: 43, loss: 0.347718
global_step: 9699, epoch: 43, loss: 0.324851
global_step: 9700, epoch: 43, loss: 0.370954
global_step: 9701, epoch: 43, loss: 0.311233
global_step: 9702, epoch: 43, loss: 0.409423
global_step: 9703, epoch: 43, loss: 0.361385
global_step: 9704, epoch: 43, loss: 0.328848
global_step: 9705, epoch: 43, loss: 0.379455
global_step: 9706, epoch: 43, loss: 0.348346
global_step: 9707, epoch: 43, loss: 0.510102
global_step: 9708, epoch: 43, loss: 0.346610
global_step: 9709, epoch: 43, loss: 0.269527
global_step: 9710, epoch: 43, loss: 0.364773
global_step: 9711, epoch: 43, loss: 0.308583
global_step: 9712, epoch: 43, loss: 0.485332
global_step: 9713, epoch: 43, loss: 0.472330
global_step: 9714, epoch: 43, loss: 0.409490
global_step: 9715, epoch: 43, loss: 0.378440
global_step: 9716, epoch: 43, loss: 0.406410
global_step: 9717, epoch: 43, loss: 0.295898
global_step: 9718, epoch: 43, loss: 0.432184
global_step: 9719, epoch: 43, loss: 0.477140
global_step: 9720, epoch: 43, loss: 0.705595
epoch: 43
train	acc: 0.9345	macro: p 0.9488, r 0.8916, f1: 0.9173	micro: p 0.9345, r 0.9345, f1 0.9345	weighted_f1:0.9340
dev	acc: 0.5564	macro: p 0.4444, r 0.3373, f1: 0.3492	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5188
test	acc: 0.5946	macro: p 0.4548, r 0.3565, f1: 0.3773	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5666
global_step: 9721, epoch: 44, loss: 0.399981
global_step: 9722, epoch: 44, loss: 0.295907
global_step: 9723, epoch: 44, loss: 0.311379
global_step: 9724, epoch: 44, loss: 0.368256
global_step: 9725, epoch: 44, loss: 0.291231
global_step: 9726, epoch: 44, loss: 0.336350
global_step: 9727, epoch: 44, loss: 0.293180
global_step: 9728, epoch: 44, loss: 0.301237
global_step: 9729, epoch: 44, loss: 0.365446
global_step: 9730, epoch: 44, loss: 0.317962
global_step: 9731, epoch: 44, loss: 0.341759
global_step: 9732, epoch: 44, loss: 0.319888
global_step: 9733, epoch: 44, loss: 0.274778
global_step: 9734, epoch: 44, loss: 0.356040
global_step: 9735, epoch: 44, loss: 0.439798
global_step: 9736, epoch: 44, loss: 0.388744
global_step: 9737, epoch: 44, loss: 0.330667
global_step: 9738, epoch: 44, loss: 0.361909
global_step: 9739, epoch: 44, loss: 0.344097
global_step: 9740, epoch: 44, loss: 0.508534
global_step: 9741, epoch: 44, loss: 0.352051
global_step: 9742, epoch: 44, loss: 0.320594
global_step: 9743, epoch: 44, loss: 0.227602
global_step: 9744, epoch: 44, loss: 0.356963
global_step: 9745, epoch: 44, loss: 0.364171
global_step: 9746, epoch: 44, loss: 0.351137
global_step: 9747, epoch: 44, loss: 0.261892
global_step: 9748, epoch: 44, loss: 0.376634
global_step: 9749, epoch: 44, loss: 0.454990
global_step: 9750, epoch: 44, loss: 0.375700
global_step: 9751, epoch: 44, loss: 0.371449
global_step: 9752, epoch: 44, loss: 0.328502
global_step: 9753, epoch: 44, loss: 0.403749
global_step: 9754, epoch: 44, loss: 0.354138
global_step: 9755, epoch: 44, loss: 0.355428
global_step: 9756, epoch: 44, loss: 0.460961
global_step: 9757, epoch: 44, loss: 0.445779
global_step: 9758, epoch: 44, loss: 0.364238
global_step: 9759, epoch: 44, loss: 0.369026
global_step: 9760, epoch: 44, loss: 0.143859
epoch: 44
train	acc: 0.9365	macro: p 0.9145, r 0.9168, f1: 0.9143	micro: p 0.9365, r 0.9365, f1 0.9365	weighted_f1:0.9368
dev	acc: 0.5194	macro: p 0.3628, r 0.3714, f1: 0.3488	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.5031
test	acc: 0.5387	macro: p 0.3648, r 0.3763, f1: 0.3597	micro: p 0.5387, r 0.5387, f1 0.5387	weighted_f1:0.5362
global_step: 9761, epoch: 45, loss: 0.454866
global_step: 9762, epoch: 45, loss: 0.288492
global_step: 9763, epoch: 45, loss: 0.584283
global_step: 9764, epoch: 45, loss: 0.420495
global_step: 9765, epoch: 45, loss: 0.354556
global_step: 9766, epoch: 45, loss: 0.304918
global_step: 9767, epoch: 45, loss: 0.332241
global_step: 9768, epoch: 45, loss: 0.455945
global_step: 9769, epoch: 45, loss: 0.343196
global_step: 9770, epoch: 45, loss: 0.334965
global_step: 9771, epoch: 45, loss: 0.353293
global_step: 9772, epoch: 45, loss: 0.362483
global_step: 9773, epoch: 45, loss: 0.304540
global_step: 9774, epoch: 45, loss: 0.384143
global_step: 9775, epoch: 45, loss: 0.307085
global_step: 9776, epoch: 45, loss: 0.361408
global_step: 9777, epoch: 45, loss: 0.347644
global_step: 9778, epoch: 45, loss: 0.401390
global_step: 9779, epoch: 45, loss: 0.362404
global_step: 9780, epoch: 45, loss: 0.357706
global_step: 9781, epoch: 45, loss: 0.364250
global_step: 9782, epoch: 45, loss: 0.383278
global_step: 9783, epoch: 45, loss: 0.347580
global_step: 9784, epoch: 45, loss: 0.318255
global_step: 9785, epoch: 45, loss: 0.463736
global_step: 9786, epoch: 45, loss: 0.456993
global_step: 9787, epoch: 45, loss: 0.377924
global_step: 9788, epoch: 45, loss: 0.383236
global_step: 9789, epoch: 45, loss: 0.350550
global_step: 9790, epoch: 45, loss: 0.375504
global_step: 9791, epoch: 45, loss: 0.337969
global_step: 9792, epoch: 45, loss: 0.312249
global_step: 9793, epoch: 45, loss: 0.399189
global_step: 9794, epoch: 45, loss: 0.377947
global_step: 9795, epoch: 45, loss: 0.474496
global_step: 9796, epoch: 45, loss: 0.316627
global_step: 9797, epoch: 45, loss: 0.382921
global_step: 9798, epoch: 45, loss: 0.317806
global_step: 9799, epoch: 45, loss: 0.353967
global_step: 9800, epoch: 45, loss: 0.053135
epoch: 45
train	acc: 0.9384	macro: p 0.9560, r 0.8961, f1: 0.9234	micro: p 0.9384, r 0.9384, f1 0.9384	weighted_f1:0.9379
dev	acc: 0.5528	macro: p 0.5540, r 0.3271, f1: 0.3391	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5089
test	acc: 0.5966	macro: p 0.4497, r 0.3420, f1: 0.3608	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5622
global_step: 9801, epoch: 46, loss: 0.295344
global_step: 9802, epoch: 46, loss: 0.247979
global_step: 9803, epoch: 46, loss: 0.330669
global_step: 9804, epoch: 46, loss: 0.368651
global_step: 9805, epoch: 46, loss: 0.364898
global_step: 9806, epoch: 46, loss: 0.387486
global_step: 9807, epoch: 46, loss: 0.358863
global_step: 9808, epoch: 46, loss: 0.367214
global_step: 9809, epoch: 46, loss: 0.387226
global_step: 9810, epoch: 46, loss: 0.329839
global_step: 9811, epoch: 46, loss: 0.346970
global_step: 9812, epoch: 46, loss: 0.277991
global_step: 9813, epoch: 46, loss: 0.370710
global_step: 9814, epoch: 46, loss: 0.283008
global_step: 9815, epoch: 46, loss: 0.337106
global_step: 9816, epoch: 46, loss: 0.311794
global_step: 9817, epoch: 46, loss: 0.358600
global_step: 9818, epoch: 46, loss: 0.267409
global_step: 9819, epoch: 46, loss: 0.337469
global_step: 9820, epoch: 46, loss: 0.269680
global_step: 9821, epoch: 46, loss: 0.301501
global_step: 9822, epoch: 46, loss: 0.275257
global_step: 9823, epoch: 46, loss: 0.333117
global_step: 9824, epoch: 46, loss: 0.396273
global_step: 9825, epoch: 46, loss: 0.333109
global_step: 9826, epoch: 46, loss: 0.307150
global_step: 9827, epoch: 46, loss: 0.388535
global_step: 9828, epoch: 46, loss: 0.359165
global_step: 9829, epoch: 46, loss: 0.269522
global_step: 9830, epoch: 46, loss: 0.338115
global_step: 9831, epoch: 46, loss: 0.420752
global_step: 9832, epoch: 46, loss: 0.331364
global_step: 9833, epoch: 46, loss: 0.361308
global_step: 9834, epoch: 46, loss: 0.419938
global_step: 9835, epoch: 46, loss: 0.312884
global_step: 9836, epoch: 46, loss: 0.292049
global_step: 9837, epoch: 46, loss: 0.395392
global_step: 9838, epoch: 46, loss: 0.274860
global_step: 9839, epoch: 46, loss: 0.355776
global_step: 9840, epoch: 46, loss: 0.040725
epoch: 46
train	acc: 0.9481	macro: p 0.9557, r 0.9194, f1: 0.9364	micro: p 0.9481, r 0.9481, f1 0.9481	weighted_f1:0.9480
dev	acc: 0.5636	macro: p 0.4252, r 0.3573, f1: 0.3687	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5297
test	acc: 0.5877	macro: p 0.4190, r 0.3543, f1: 0.3685	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5608
global_step: 9841, epoch: 47, loss: 0.336295
global_step: 9842, epoch: 47, loss: 0.307632
global_step: 9843, epoch: 47, loss: 0.258111
global_step: 9844, epoch: 47, loss: 0.327725
global_step: 9845, epoch: 47, loss: 0.341806
global_step: 9846, epoch: 47, loss: 0.336438
global_step: 9847, epoch: 47, loss: 0.306419
global_step: 9848, epoch: 47, loss: 0.280205
global_step: 9849, epoch: 47, loss: 0.318204
global_step: 9850, epoch: 47, loss: 0.260078
global_step: 9851, epoch: 47, loss: 0.254461
global_step: 9852, epoch: 47, loss: 0.424492
global_step: 9853, epoch: 47, loss: 0.336796
global_step: 9854, epoch: 47, loss: 0.295428
global_step: 9855, epoch: 47, loss: 0.253583
global_step: 9856, epoch: 47, loss: 0.333488
global_step: 9857, epoch: 47, loss: 0.230562
global_step: 9858, epoch: 47, loss: 0.309199
global_step: 9859, epoch: 47, loss: 0.328366
global_step: 9860, epoch: 47, loss: 0.338628
global_step: 9861, epoch: 47, loss: 0.333764
global_step: 9862, epoch: 47, loss: 0.380710
global_step: 9863, epoch: 47, loss: 0.313817
global_step: 9864, epoch: 47, loss: 0.326980
global_step: 9865, epoch: 47, loss: 0.358917
global_step: 9866, epoch: 47, loss: 0.449886
global_step: 9867, epoch: 47, loss: 0.349645
global_step: 9868, epoch: 47, loss: 0.370208
global_step: 9869, epoch: 47, loss: 0.377716
global_step: 9870, epoch: 47, loss: 0.285415
global_step: 9871, epoch: 47, loss: 0.379958
global_step: 9872, epoch: 47, loss: 0.389805
global_step: 9873, epoch: 47, loss: 0.348516
global_step: 9874, epoch: 47, loss: 0.343908
global_step: 9875, epoch: 47, loss: 0.311839
global_step: 9876, epoch: 47, loss: 0.437328
global_step: 9877, epoch: 47, loss: 0.294272
global_step: 9878, epoch: 47, loss: 0.443811
global_step: 9879, epoch: 47, loss: 0.426565
global_step: 9880, epoch: 47, loss: 0.067897
epoch: 47
train	acc: 0.9452	macro: p 0.9558, r 0.9148, f1: 0.9340	micro: p 0.9452, r 0.9452, f1 0.9452	weighted_f1:0.9450
dev	acc: 0.5528	macro: p 0.4242, r 0.3470, f1: 0.3606	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5211
test	acc: 0.5874	macro: p 0.4186, r 0.3442, f1: 0.3613	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5611
global_step: 9881, epoch: 48, loss: 0.323333
global_step: 9882, epoch: 48, loss: 0.427524
global_step: 9883, epoch: 48, loss: 0.316699
global_step: 9884, epoch: 48, loss: 0.353940
global_step: 9885, epoch: 48, loss: 0.225334
global_step: 9886, epoch: 48, loss: 0.306852
global_step: 9887, epoch: 48, loss: 0.378154
global_step: 9888, epoch: 48, loss: 0.305371
global_step: 9889, epoch: 48, loss: 0.357990
global_step: 9890, epoch: 48, loss: 0.301863
global_step: 9891, epoch: 48, loss: 0.383242
global_step: 9892, epoch: 48, loss: 0.316924
global_step: 9893, epoch: 48, loss: 0.358237
global_step: 9894, epoch: 48, loss: 0.268712
global_step: 9895, epoch: 48, loss: 0.374196
global_step: 9896, epoch: 48, loss: 0.298696
global_step: 9897, epoch: 48, loss: 0.358758
global_step: 9898, epoch: 48, loss: 0.307429
global_step: 9899, epoch: 48, loss: 0.347943
global_step: 9900, epoch: 48, loss: 0.328214
global_step: 9901, epoch: 48, loss: 0.344391
global_step: 9902, epoch: 48, loss: 0.368088
global_step: 9903, epoch: 48, loss: 0.316845
global_step: 9904, epoch: 48, loss: 0.320451
global_step: 9905, epoch: 48, loss: 0.263639
global_step: 9906, epoch: 48, loss: 0.289740
global_step: 9907, epoch: 48, loss: 0.300356
global_step: 9908, epoch: 48, loss: 0.363534
global_step: 9909, epoch: 48, loss: 0.360558
global_step: 9910, epoch: 48, loss: 0.383403
global_step: 9911, epoch: 48, loss: 0.352259
global_step: 9912, epoch: 48, loss: 0.388466
global_step: 9913, epoch: 48, loss: 0.316756
global_step: 9914, epoch: 48, loss: 0.279107
global_step: 9915, epoch: 48, loss: 0.445795
global_step: 9916, epoch: 48, loss: 0.304203
global_step: 9917, epoch: 48, loss: 0.341627
global_step: 9918, epoch: 48, loss: 0.404422
global_step: 9919, epoch: 48, loss: 0.348342
global_step: 9920, epoch: 48, loss: 0.257750
epoch: 48
train	acc: 0.9462	macro: p 0.9516, r 0.9159, f1: 0.9318	micro: p 0.9462, r 0.9462, f1 0.9462	weighted_f1:0.9463
dev	acc: 0.5609	macro: p 0.4201, r 0.3713, f1: 0.3741	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5333
test	acc: 0.5594	macro: p 0.3702, r 0.3474, f1: 0.3446	micro: p 0.5594, r 0.5594, f1 0.5594	weighted_f1:0.5450
global_step: 9921, epoch: 49, loss: 0.350494
global_step: 9922, epoch: 49, loss: 0.270770
global_step: 9923, epoch: 49, loss: 0.332270
global_step: 9924, epoch: 49, loss: 0.260998
global_step: 9925, epoch: 49, loss: 0.328328
global_step: 9926, epoch: 49, loss: 0.208576
global_step: 9927, epoch: 49, loss: 0.326579
global_step: 9928, epoch: 49, loss: 0.355702
global_step: 9929, epoch: 49, loss: 0.321206
global_step: 9930, epoch: 49, loss: 0.315191
global_step: 9931, epoch: 49, loss: 0.278385
global_step: 9932, epoch: 49, loss: 0.304970
global_step: 9933, epoch: 49, loss: 0.314667
global_step: 9934, epoch: 49, loss: 0.352365
global_step: 9935, epoch: 49, loss: 0.276252
global_step: 9936, epoch: 49, loss: 0.325947
global_step: 9937, epoch: 49, loss: 0.321080
global_step: 9938, epoch: 49, loss: 0.316304
global_step: 9939, epoch: 49, loss: 0.401747
global_step: 9940, epoch: 49, loss: 0.335061
global_step: 9941, epoch: 49, loss: 0.334569
global_step: 9942, epoch: 49, loss: 0.279390
global_step: 9943, epoch: 49, loss: 0.310500
global_step: 9944, epoch: 49, loss: 0.262006
global_step: 9945, epoch: 49, loss: 0.381628
global_step: 9946, epoch: 49, loss: 0.350002
global_step: 9947, epoch: 49, loss: 0.283874
global_step: 9948, epoch: 49, loss: 0.338378
global_step: 9949, epoch: 49, loss: 0.280031
global_step: 9950, epoch: 49, loss: 0.385455
global_step: 9951, epoch: 49, loss: 0.359033
global_step: 9952, epoch: 49, loss: 0.299835
global_step: 9953, epoch: 49, loss: 0.286736
global_step: 9954, epoch: 49, loss: 0.272656
global_step: 9955, epoch: 49, loss: 0.359682
global_step: 9956, epoch: 49, loss: 0.388461
global_step: 9957, epoch: 49, loss: 0.432614
global_step: 9958, epoch: 49, loss: 0.367042
global_step: 9959, epoch: 49, loss: 0.312974
global_step: 9960, epoch: 49, loss: 0.113506
epoch: 49
train	acc: 0.9465	macro: p 0.9495, r 0.9266, f1: 0.9371	micro: p 0.9465, r 0.9465, f1 0.9465	weighted_f1:0.9467
dev	acc: 0.5383	macro: p 0.3891, r 0.3597, f1: 0.3573	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5217
test	acc: 0.5391	macro: p 0.3905, r 0.3589, f1: 0.3601	micro: p 0.5391, r 0.5391, f1 0.5391	weighted_f1:0.5347
global_step: 9961, epoch: 50, loss: 0.369330
global_step: 9962, epoch: 50, loss: 0.252888
global_step: 9963, epoch: 50, loss: 0.281978
global_step: 9964, epoch: 50, loss: 0.302391
global_step: 9965, epoch: 50, loss: 0.293812
global_step: 9966, epoch: 50, loss: 0.347038
global_step: 9967, epoch: 50, loss: 0.195692
global_step: 9968, epoch: 50, loss: 0.316409
global_step: 9969, epoch: 50, loss: 0.283942
global_step: 9970, epoch: 50, loss: 0.373282
global_step: 9971, epoch: 50, loss: 0.248078
global_step: 9972, epoch: 50, loss: 0.272795
global_step: 9973, epoch: 50, loss: 0.274294
global_step: 9974, epoch: 50, loss: 0.327760
global_step: 9975, epoch: 50, loss: 0.335271
global_step: 9976, epoch: 50, loss: 0.278919
global_step: 9977, epoch: 50, loss: 0.295220
global_step: 9978, epoch: 50, loss: 0.316564
global_step: 9979, epoch: 50, loss: 0.287092
global_step: 9980, epoch: 50, loss: 0.275211
global_step: 9981, epoch: 50, loss: 0.337244
global_step: 9982, epoch: 50, loss: 0.356549
global_step: 9983, epoch: 50, loss: 0.334998
global_step: 9984, epoch: 50, loss: 0.308986
global_step: 9985, epoch: 50, loss: 0.395758
global_step: 9986, epoch: 50, loss: 0.321727
global_step: 9987, epoch: 50, loss: 0.367220
global_step: 9988, epoch: 50, loss: 0.306309
global_step: 9989, epoch: 50, loss: 0.338912
global_step: 9990, epoch: 50, loss: 0.323066
global_step: 9991, epoch: 50, loss: 0.309393
global_step: 9992, epoch: 50, loss: 0.320842
global_step: 9993, epoch: 50, loss: 0.200280
global_step: 9994, epoch: 50, loss: 0.269107
global_step: 9995, epoch: 50, loss: 0.264586
global_step: 9996, epoch: 50, loss: 0.285973
global_step: 9997, epoch: 50, loss: 0.404469
global_step: 9998, epoch: 50, loss: 0.324562
global_step: 9999, epoch: 50, loss: 0.310493
global_step: 10000, epoch: 50, loss: 0.820149
epoch: 50
train	acc: 0.9474	macro: p 0.9566, r 0.9178, f1: 0.9355	micro: p 0.9474, r 0.9474, f1 0.9474	weighted_f1:0.9474
dev	acc: 0.5509	macro: p 0.4219, r 0.3468, f1: 0.3467	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5164
test	acc: 0.5728	macro: p 0.4468, r 0.3508, f1: 0.3646	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5492
BEST MODEL epoch: 23
train	acc: 0.8773 macro_p: 0.8701 macro_r: 0.7749 macro_f1: 0.8065 micro_p: 0.8773 micro_r: 0.8773 micro_f1: 0.8773 weighted_f1: 0.8746
dev	acc: 0.5708 macro_p: 0.4582 macro_r: 0.3774 macro_f1: 0.3835 micro_p: 0.5708 micro_r: 0.5708 micro_f1: 0.5708 weighted_f1: 0.5473
test	acc: 0.5843 macro_p: 0.4307 macro_r: 0.3668 macro_f1: 0.3737 micro_p: 0.5843 micro_r: 0.5843 micro_f1: 0.5843 weighted_f1: 0.5683
====================TRAINING FINISHED====================
best epoch: [32, 36, 39, 21, 23], avg test weighted f1: 0.571850
