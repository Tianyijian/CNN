nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['This', 'one', '?', 's', 'from', 'me', '.']   0
['No', '!']   4

-------dev--------
1109 1109
['Come', 'on', 'in', '.']   0
['Oh', '!', '!']   2

-------test--------
2610 2610
['Yeah', '!']   1
['Yeah', '.']   0
====================INFORMATION====================
MODEL: non-static
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 200
LEARNING_RATE: 0.1
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 1, epoch: 1, loss: 2.009419
global_step: 2, epoch: 1, loss: 1.979926
global_step: 3, epoch: 1, loss: 1.966395
global_step: 4, epoch: 1, loss: 1.936884
global_step: 5, epoch: 1, loss: 1.937572
global_step: 6, epoch: 1, loss: 1.945514
global_step: 7, epoch: 1, loss: 1.907134
global_step: 8, epoch: 1, loss: 1.900986
global_step: 9, epoch: 1, loss: 1.875783
global_step: 10, epoch: 1, loss: 1.871990
global_step: 11, epoch: 1, loss: 1.842644
global_step: 12, epoch: 1, loss: 1.830249
global_step: 13, epoch: 1, loss: 1.808084
global_step: 14, epoch: 1, loss: 1.801197
global_step: 15, epoch: 1, loss: 1.811387
global_step: 16, epoch: 1, loss: 1.795177
global_step: 17, epoch: 1, loss: 1.752760
global_step: 18, epoch: 1, loss: 1.733062
global_step: 19, epoch: 1, loss: 1.728833
global_step: 20, epoch: 1, loss: 1.713075
global_step: 21, epoch: 1, loss: 1.685878
global_step: 22, epoch: 1, loss: 1.678888
global_step: 23, epoch: 1, loss: 1.637500
global_step: 24, epoch: 1, loss: 1.641243
global_step: 25, epoch: 1, loss: 1.617935
global_step: 26, epoch: 1, loss: 1.601063
global_step: 27, epoch: 1, loss: 1.702605
global_step: 28, epoch: 1, loss: 1.690739
global_step: 29, epoch: 1, loss: 1.677965
global_step: 30, epoch: 1, loss: 1.595047
global_step: 31, epoch: 1, loss: 1.644705
global_step: 32, epoch: 1, loss: 1.711672
global_step: 33, epoch: 1, loss: 1.611351
global_step: 34, epoch: 1, loss: 1.554906
global_step: 35, epoch: 1, loss: 1.673382
global_step: 36, epoch: 1, loss: 1.554190
global_step: 37, epoch: 1, loss: 1.522441
global_step: 38, epoch: 1, loss: 1.677951
global_step: 39, epoch: 1, loss: 1.645619
global_step: 40, epoch: 1, loss: 1.058447
epoch: 1
train	acc: 0.4706	macro: p 0.0775, r 0.1427, f1: 0.0917	micro: p 0.4706, r 0.4706, f1 0.4706	weighted_f1:0.3020
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
New best model!
global_step: 41, epoch: 2, loss: 1.431933
global_step: 42, epoch: 2, loss: 1.577401
global_step: 43, epoch: 2, loss: 1.711689
global_step: 44, epoch: 2, loss: 1.597773
global_step: 45, epoch: 2, loss: 1.593070
global_step: 46, epoch: 2, loss: 1.524374
global_step: 47, epoch: 2, loss: 1.573440
global_step: 48, epoch: 2, loss: 1.575413
global_step: 49, epoch: 2, loss: 1.520992
global_step: 50, epoch: 2, loss: 1.473506
global_step: 51, epoch: 2, loss: 1.641109
global_step: 52, epoch: 2, loss: 1.615009
global_step: 53, epoch: 2, loss: 1.540549
global_step: 54, epoch: 2, loss: 1.636349
global_step: 55, epoch: 2, loss: 1.612808
global_step: 56, epoch: 2, loss: 1.508250
global_step: 57, epoch: 2, loss: 1.541818
global_step: 58, epoch: 2, loss: 1.453946
global_step: 59, epoch: 2, loss: 1.546681
global_step: 60, epoch: 2, loss: 1.596807
global_step: 61, epoch: 2, loss: 1.614027
global_step: 62, epoch: 2, loss: 1.538925
global_step: 63, epoch: 2, loss: 1.575725
global_step: 64, epoch: 2, loss: 1.486985
global_step: 65, epoch: 2, loss: 1.550584
global_step: 66, epoch: 2, loss: 1.511643
global_step: 67, epoch: 2, loss: 1.471447
global_step: 68, epoch: 2, loss: 1.475464
global_step: 69, epoch: 2, loss: 1.517033
global_step: 70, epoch: 2, loss: 1.522253
global_step: 71, epoch: 2, loss: 1.525993
global_step: 72, epoch: 2, loss: 1.498623
global_step: 73, epoch: 2, loss: 1.555682
global_step: 74, epoch: 2, loss: 1.472690
global_step: 75, epoch: 2, loss: 1.569864
global_step: 76, epoch: 2, loss: 1.455110
global_step: 77, epoch: 2, loss: 1.498193
global_step: 78, epoch: 2, loss: 1.519793
global_step: 79, epoch: 2, loss: 1.517661
global_step: 80, epoch: 2, loss: 2.039546
epoch: 2
train	acc: 0.4802	macro: p 0.1235, r 0.1514, f1: 0.1089	micro: p 0.4802, r 0.4802, f1 0.4802	weighted_f1:0.3262
dev	acc: 0.4310	macro: p 0.0934, r 0.1504, f1: 0.0997	micro: p 0.4310, r 0.4310, f1 0.4310	weighted_f1:0.2715
test	acc: 0.4900	macro: p 0.1230, r 0.1525, f1: 0.1115	micro: p 0.4900, r 0.4900, f1 0.4900	weighted_f1:0.3363
New best model!
global_step: 81, epoch: 3, loss: 1.421583
global_step: 82, epoch: 3, loss: 1.477405
global_step: 83, epoch: 3, loss: 1.636626
global_step: 84, epoch: 3, loss: 1.456141
global_step: 85, epoch: 3, loss: 1.596093
global_step: 86, epoch: 3, loss: 1.563892
global_step: 87, epoch: 3, loss: 1.488750
global_step: 88, epoch: 3, loss: 1.460727
global_step: 89, epoch: 3, loss: 1.566991
global_step: 90, epoch: 3, loss: 1.534224
global_step: 91, epoch: 3, loss: 1.493767
global_step: 92, epoch: 3, loss: 1.520757
global_step: 93, epoch: 3, loss: 1.492288
global_step: 94, epoch: 3, loss: 1.368461
global_step: 95, epoch: 3, loss: 1.419074
global_step: 96, epoch: 3, loss: 1.392943
global_step: 97, epoch: 3, loss: 1.478006
global_step: 98, epoch: 3, loss: 1.500453
global_step: 99, epoch: 3, loss: 1.433887
global_step: 100, epoch: 3, loss: 1.535874
global_step: 101, epoch: 3, loss: 1.478998
global_step: 102, epoch: 3, loss: 1.457587
global_step: 103, epoch: 3, loss: 1.468840
global_step: 104, epoch: 3, loss: 1.427829
global_step: 105, epoch: 3, loss: 1.461641
global_step: 106, epoch: 3, loss: 1.434504
global_step: 107, epoch: 3, loss: 1.474370
global_step: 108, epoch: 3, loss: 1.525673
global_step: 109, epoch: 3, loss: 1.443509
global_step: 110, epoch: 3, loss: 1.507866
global_step: 111, epoch: 3, loss: 1.445368
global_step: 112, epoch: 3, loss: 1.538959
global_step: 113, epoch: 3, loss: 1.447886
global_step: 114, epoch: 3, loss: 1.477893
global_step: 115, epoch: 3, loss: 1.405189
global_step: 116, epoch: 3, loss: 1.377823
global_step: 117, epoch: 3, loss: 1.442453
global_step: 118, epoch: 3, loss: 1.424972
global_step: 119, epoch: 3, loss: 1.430600
global_step: 120, epoch: 3, loss: 0.839448
epoch: 3
train	acc: 0.5226	macro: p 0.1327, r 0.1910, f1: 0.1535	micro: p 0.5226, r 0.5226, f1 0.5226	weighted_f1:0.3968
dev	acc: 0.4608	macro: p 0.1101, r 0.1857, f1: 0.1367	micro: p 0.4608, r 0.4608, f1 0.4608	weighted_f1:0.3243
test	acc: 0.5261	macro: p 0.1285, r 0.1912, f1: 0.1518	micro: p 0.5261, r 0.5261, f1 0.5261	weighted_f1:0.3977
New best model!
global_step: 121, epoch: 4, loss: 1.465408
global_step: 122, epoch: 4, loss: 1.551021
global_step: 123, epoch: 4, loss: 1.427474
global_step: 124, epoch: 4, loss: 1.478703
global_step: 125, epoch: 4, loss: 1.435953
global_step: 126, epoch: 4, loss: 1.363590
global_step: 127, epoch: 4, loss: 1.425610
global_step: 128, epoch: 4, loss: 1.419543
global_step: 129, epoch: 4, loss: 1.458225
global_step: 130, epoch: 4, loss: 1.395822
global_step: 131, epoch: 4, loss: 1.296648
global_step: 132, epoch: 4, loss: 1.409338
global_step: 133, epoch: 4, loss: 1.438810
global_step: 134, epoch: 4, loss: 1.366727
global_step: 135, epoch: 4, loss: 1.447354
global_step: 136, epoch: 4, loss: 1.460504
global_step: 137, epoch: 4, loss: 1.436412
global_step: 138, epoch: 4, loss: 1.432649
global_step: 139, epoch: 4, loss: 1.478860
global_step: 140, epoch: 4, loss: 1.327745
global_step: 141, epoch: 4, loss: 1.370145
global_step: 142, epoch: 4, loss: 1.415309
global_step: 143, epoch: 4, loss: 1.517228
global_step: 144, epoch: 4, loss: 1.450441
global_step: 145, epoch: 4, loss: 1.320636
global_step: 146, epoch: 4, loss: 1.462550
global_step: 147, epoch: 4, loss: 1.346648
global_step: 148, epoch: 4, loss: 1.322898
global_step: 149, epoch: 4, loss: 1.369727
global_step: 150, epoch: 4, loss: 1.385777
global_step: 151, epoch: 4, loss: 1.320995
global_step: 152, epoch: 4, loss: 1.474319
global_step: 153, epoch: 4, loss: 1.353403
global_step: 154, epoch: 4, loss: 1.479563
global_step: 155, epoch: 4, loss: 1.459743
global_step: 156, epoch: 4, loss: 1.476061
global_step: 157, epoch: 4, loss: 1.402247
global_step: 158, epoch: 4, loss: 1.325541
global_step: 159, epoch: 4, loss: 1.572654
global_step: 160, epoch: 4, loss: 2.120522
epoch: 4
train	acc: 0.5425	macro: p 0.1385, r 0.2168, f1: 0.1689	micro: p 0.5425, r 0.5425, f1 0.5425	weighted_f1:0.4293
dev	acc: 0.4896	macro: p 0.1236, r 0.2206, f1: 0.1579	micro: p 0.4896, r 0.4896, f1 0.4896	weighted_f1:0.3618
test	acc: 0.5467	macro: p 0.1377, r 0.2230, f1: 0.1694	micro: p 0.5467, r 0.5467, f1 0.5467	weighted_f1:0.4330
New best model!
global_step: 161, epoch: 5, loss: 1.485290
global_step: 162, epoch: 5, loss: 1.317328
global_step: 163, epoch: 5, loss: 1.427437
global_step: 164, epoch: 5, loss: 1.413073
global_step: 165, epoch: 5, loss: 1.450237
global_step: 166, epoch: 5, loss: 1.354725
global_step: 167, epoch: 5, loss: 1.467312
global_step: 168, epoch: 5, loss: 1.368502
global_step: 169, epoch: 5, loss: 1.330781
global_step: 170, epoch: 5, loss: 1.434230
global_step: 171, epoch: 5, loss: 1.330955
global_step: 172, epoch: 5, loss: 1.382776
global_step: 173, epoch: 5, loss: 1.437575
global_step: 174, epoch: 5, loss: 1.384507
global_step: 175, epoch: 5, loss: 1.379535
global_step: 176, epoch: 5, loss: 1.385709
global_step: 177, epoch: 5, loss: 1.341864
global_step: 178, epoch: 5, loss: 1.466789
global_step: 179, epoch: 5, loss: 1.361119
global_step: 180, epoch: 5, loss: 1.321730
global_step: 181, epoch: 5, loss: 1.375418
global_step: 182, epoch: 5, loss: 1.333521
global_step: 183, epoch: 5, loss: 1.460418
global_step: 184, epoch: 5, loss: 1.328551
global_step: 185, epoch: 5, loss: 1.438110
global_step: 186, epoch: 5, loss: 1.433929
global_step: 187, epoch: 5, loss: 1.441453
global_step: 188, epoch: 5, loss: 1.258218
global_step: 189, epoch: 5, loss: 1.441580
global_step: 190, epoch: 5, loss: 1.425608
global_step: 191, epoch: 5, loss: 1.412974
global_step: 192, epoch: 5, loss: 1.485669
global_step: 193, epoch: 5, loss: 1.353735
global_step: 194, epoch: 5, loss: 1.390464
global_step: 195, epoch: 5, loss: 1.333085
global_step: 196, epoch: 5, loss: 1.325090
global_step: 197, epoch: 5, loss: 1.338382
global_step: 198, epoch: 5, loss: 1.319476
global_step: 199, epoch: 5, loss: 1.334939
global_step: 200, epoch: 5, loss: 1.280330
epoch: 5
train	acc: 0.5406	macro: p 0.1372, r 0.2135, f1: 0.1670	micro: p 0.5406, r 0.5406, f1 0.5406	weighted_f1:0.4257
dev	acc: 0.4851	macro: p 0.1216, r 0.2162, f1: 0.1554	micro: p 0.4851, r 0.4851, f1 0.4851	weighted_f1:0.3574
test	acc: 0.5444	macro: p 0.1360, r 0.2189, f1: 0.1673	micro: p 0.5444, r 0.5444, f1 0.5444	weighted_f1:0.4294
global_step: 201, epoch: 6, loss: 1.295058
global_step: 202, epoch: 6, loss: 1.421033
global_step: 203, epoch: 6, loss: 1.382710
global_step: 204, epoch: 6, loss: 1.394824
global_step: 205, epoch: 6, loss: 1.378600
global_step: 206, epoch: 6, loss: 1.433245
global_step: 207, epoch: 6, loss: 1.422085
global_step: 208, epoch: 6, loss: 1.414785
global_step: 209, epoch: 6, loss: 1.298201
global_step: 210, epoch: 6, loss: 1.295994
global_step: 211, epoch: 6, loss: 1.392041
global_step: 212, epoch: 6, loss: 1.422796
global_step: 213, epoch: 6, loss: 1.352260
global_step: 214, epoch: 6, loss: 1.440305
global_step: 215, epoch: 6, loss: 1.375185
global_step: 216, epoch: 6, loss: 1.196637
global_step: 217, epoch: 6, loss: 1.324248
global_step: 218, epoch: 6, loss: 1.392844
global_step: 219, epoch: 6, loss: 1.429660
global_step: 220, epoch: 6, loss: 1.350604
global_step: 221, epoch: 6, loss: 1.382462
global_step: 222, epoch: 6, loss: 1.273552
global_step: 223, epoch: 6, loss: 1.386729
global_step: 224, epoch: 6, loss: 1.369792
global_step: 225, epoch: 6, loss: 1.313893
global_step: 226, epoch: 6, loss: 1.374843
global_step: 227, epoch: 6, loss: 1.289031
global_step: 228, epoch: 6, loss: 1.245903
global_step: 229, epoch: 6, loss: 1.374581
global_step: 230, epoch: 6, loss: 1.387011
global_step: 231, epoch: 6, loss: 1.457028
global_step: 232, epoch: 6, loss: 1.394309
global_step: 233, epoch: 6, loss: 1.319788
global_step: 234, epoch: 6, loss: 1.416097
global_step: 235, epoch: 6, loss: 1.389902
global_step: 236, epoch: 6, loss: 1.313715
global_step: 237, epoch: 6, loss: 1.317539
global_step: 238, epoch: 6, loss: 1.396903
global_step: 239, epoch: 6, loss: 1.385603
global_step: 240, epoch: 6, loss: 0.732545
epoch: 6
train	acc: 0.5503	macro: p 0.2587, r 0.2266, f1: 0.1883	micro: p 0.5503, r 0.5503, f1 0.5503	weighted_f1:0.4460
dev	acc: 0.5059	macro: p 0.2538, r 0.2376, f1: 0.1884	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.3912
test	acc: 0.5579	macro: p 0.2696, r 0.2380, f1: 0.1988	micro: p 0.5579, r 0.5579, f1 0.5579	weighted_f1:0.4555
New best model!
global_step: 241, epoch: 7, loss: 1.306389
global_step: 242, epoch: 7, loss: 1.417730
global_step: 243, epoch: 7, loss: 1.395499
global_step: 244, epoch: 7, loss: 1.391570
global_step: 245, epoch: 7, loss: 1.419037
global_step: 246, epoch: 7, loss: 1.421613
global_step: 247, epoch: 7, loss: 1.371531
global_step: 248, epoch: 7, loss: 1.398746
global_step: 249, epoch: 7, loss: 1.320735
global_step: 250, epoch: 7, loss: 1.420595
global_step: 251, epoch: 7, loss: 1.301582
global_step: 252, epoch: 7, loss: 1.294935
global_step: 253, epoch: 7, loss: 1.330091
global_step: 254, epoch: 7, loss: 1.351890
global_step: 255, epoch: 7, loss: 1.325353
global_step: 256, epoch: 7, loss: 1.452045
global_step: 257, epoch: 7, loss: 1.247923
global_step: 258, epoch: 7, loss: 1.344399
global_step: 259, epoch: 7, loss: 1.473603
global_step: 260, epoch: 7, loss: 1.396281
global_step: 261, epoch: 7, loss: 1.316852
global_step: 262, epoch: 7, loss: 1.312475
global_step: 263, epoch: 7, loss: 1.312511
global_step: 264, epoch: 7, loss: 1.343246
global_step: 265, epoch: 7, loss: 1.296187
global_step: 266, epoch: 7, loss: 1.298686
global_step: 267, epoch: 7, loss: 1.397364
global_step: 268, epoch: 7, loss: 1.446466
global_step: 269, epoch: 7, loss: 1.338328
global_step: 270, epoch: 7, loss: 1.264648
global_step: 271, epoch: 7, loss: 1.266500
global_step: 272, epoch: 7, loss: 1.357124
global_step: 273, epoch: 7, loss: 1.338116
global_step: 274, epoch: 7, loss: 1.316918
global_step: 275, epoch: 7, loss: 1.359926
global_step: 276, epoch: 7, loss: 1.309370
global_step: 277, epoch: 7, loss: 1.393932
global_step: 278, epoch: 7, loss: 1.332246
global_step: 279, epoch: 7, loss: 1.334092
global_step: 280, epoch: 7, loss: 0.632063
epoch: 7
train	acc: 0.5468	macro: p 0.2709, r 0.2230, f1: 0.1803	micro: p 0.5468, r 0.5468, f1 0.5468	weighted_f1:0.4392
dev	acc: 0.4995	macro: p 0.2685, r 0.2315, f1: 0.1764	micro: p 0.4995, r 0.4995, f1 0.4995	weighted_f1:0.3801
test	acc: 0.5529	macro: p 0.2815, r 0.2321, f1: 0.1873	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.4469
global_step: 281, epoch: 8, loss: 1.435735
global_step: 282, epoch: 8, loss: 1.367526
global_step: 283, epoch: 8, loss: 1.268784
global_step: 284, epoch: 8, loss: 1.310794
global_step: 285, epoch: 8, loss: 1.396310
global_step: 286, epoch: 8, loss: 1.308802
global_step: 287, epoch: 8, loss: 1.348712
global_step: 288, epoch: 8, loss: 1.356668
global_step: 289, epoch: 8, loss: 1.467131
global_step: 290, epoch: 8, loss: 1.288012
global_step: 291, epoch: 8, loss: 1.293577
global_step: 292, epoch: 8, loss: 1.345333
global_step: 293, epoch: 8, loss: 1.362156
global_step: 294, epoch: 8, loss: 1.300732
global_step: 295, epoch: 8, loss: 1.387653
global_step: 296, epoch: 8, loss: 1.401001
global_step: 297, epoch: 8, loss: 1.332098
global_step: 298, epoch: 8, loss: 1.245263
global_step: 299, epoch: 8, loss: 1.298204
global_step: 300, epoch: 8, loss: 1.400067
global_step: 301, epoch: 8, loss: 1.271291
global_step: 302, epoch: 8, loss: 1.318865
global_step: 303, epoch: 8, loss: 1.275339
global_step: 304, epoch: 8, loss: 1.307873
global_step: 305, epoch: 8, loss: 1.351739
global_step: 306, epoch: 8, loss: 1.249274
global_step: 307, epoch: 8, loss: 1.328977
global_step: 308, epoch: 8, loss: 1.269028
global_step: 309, epoch: 8, loss: 1.312128
global_step: 310, epoch: 8, loss: 1.352188
global_step: 311, epoch: 8, loss: 1.387262
global_step: 312, epoch: 8, loss: 1.399812
global_step: 313, epoch: 8, loss: 1.315288
global_step: 314, epoch: 8, loss: 1.384392
global_step: 315, epoch: 8, loss: 1.433474
global_step: 316, epoch: 8, loss: 1.335596
global_step: 317, epoch: 8, loss: 1.199675
global_step: 318, epoch: 8, loss: 1.340036
global_step: 319, epoch: 8, loss: 1.281786
global_step: 320, epoch: 8, loss: 2.275672
epoch: 8
train	acc: 0.5568	macro: p 0.3338, r 0.2361, f1: 0.2063	micro: p 0.5568, r 0.5568, f1 0.5568	weighted_f1:0.4612
dev	acc: 0.5095	macro: p 0.2880, r 0.2425, f1: 0.1977	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4003
test	acc: 0.5613	macro: p 0.3314, r 0.2431, f1: 0.2087	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.4645
New best model!
global_step: 321, epoch: 9, loss: 1.290554
global_step: 322, epoch: 9, loss: 1.275465
global_step: 323, epoch: 9, loss: 1.270392
global_step: 324, epoch: 9, loss: 1.325256
global_step: 325, epoch: 9, loss: 1.319543
global_step: 326, epoch: 9, loss: 1.383573
global_step: 327, epoch: 9, loss: 1.224545
global_step: 328, epoch: 9, loss: 1.348776
global_step: 329, epoch: 9, loss: 1.265867
global_step: 330, epoch: 9, loss: 1.380106
global_step: 331, epoch: 9, loss: 1.359728
global_step: 332, epoch: 9, loss: 1.455890
global_step: 333, epoch: 9, loss: 1.318690
global_step: 334, epoch: 9, loss: 1.398983
global_step: 335, epoch: 9, loss: 1.256677
global_step: 336, epoch: 9, loss: 1.433082
global_step: 337, epoch: 9, loss: 1.260672
global_step: 338, epoch: 9, loss: 1.333434
global_step: 339, epoch: 9, loss: 1.249510
global_step: 340, epoch: 9, loss: 1.405293
global_step: 341, epoch: 9, loss: 1.336893
global_step: 342, epoch: 9, loss: 1.333291
global_step: 343, epoch: 9, loss: 1.263801
global_step: 344, epoch: 9, loss: 1.372330
global_step: 345, epoch: 9, loss: 1.291973
global_step: 346, epoch: 9, loss: 1.250989
global_step: 347, epoch: 9, loss: 1.306441
global_step: 348, epoch: 9, loss: 1.186085
global_step: 349, epoch: 9, loss: 1.389492
global_step: 350, epoch: 9, loss: 1.400714
global_step: 351, epoch: 9, loss: 1.222742
global_step: 352, epoch: 9, loss: 1.313194
global_step: 353, epoch: 9, loss: 1.335810
global_step: 354, epoch: 9, loss: 1.310378
global_step: 355, epoch: 9, loss: 1.411050
global_step: 356, epoch: 9, loss: 1.315473
global_step: 357, epoch: 9, loss: 1.380439
global_step: 358, epoch: 9, loss: 1.358943
global_step: 359, epoch: 9, loss: 1.260341
global_step: 360, epoch: 9, loss: 1.412423
epoch: 9
train	acc: 0.5606	macro: p 0.3295, r 0.2396, f1: 0.2116	micro: p 0.5606, r 0.5606, f1 0.5606	weighted_f1:0.4664
dev	acc: 0.5131	macro: p 0.3182, r 0.2457, f1: 0.2022	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4049
test	acc: 0.5621	macro: p 0.3108, r 0.2451, f1: 0.2126	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.4669
New best model!
global_step: 361, epoch: 10, loss: 1.201965
global_step: 362, epoch: 10, loss: 1.359334
global_step: 363, epoch: 10, loss: 1.311569
global_step: 364, epoch: 10, loss: 1.222885
global_step: 365, epoch: 10, loss: 1.185792
global_step: 366, epoch: 10, loss: 1.265958
global_step: 367, epoch: 10, loss: 1.331896
global_step: 368, epoch: 10, loss: 1.342659
global_step: 369, epoch: 10, loss: 1.397998
global_step: 370, epoch: 10, loss: 1.372455
global_step: 371, epoch: 10, loss: 1.342041
global_step: 372, epoch: 10, loss: 1.255700
global_step: 373, epoch: 10, loss: 1.306149
global_step: 374, epoch: 10, loss: 1.374551
global_step: 375, epoch: 10, loss: 1.307472
global_step: 376, epoch: 10, loss: 1.327721
global_step: 377, epoch: 10, loss: 1.265335
global_step: 378, epoch: 10, loss: 1.246057
global_step: 379, epoch: 10, loss: 1.280029
global_step: 380, epoch: 10, loss: 1.286663
global_step: 381, epoch: 10, loss: 1.322692
global_step: 382, epoch: 10, loss: 1.379993
global_step: 383, epoch: 10, loss: 1.314318
global_step: 384, epoch: 10, loss: 1.387769
global_step: 385, epoch: 10, loss: 1.395656
global_step: 386, epoch: 10, loss: 1.309536
global_step: 387, epoch: 10, loss: 1.349163
global_step: 388, epoch: 10, loss: 1.227108
global_step: 389, epoch: 10, loss: 1.360905
global_step: 390, epoch: 10, loss: 1.377170
global_step: 391, epoch: 10, loss: 1.339595
global_step: 392, epoch: 10, loss: 1.227551
global_step: 393, epoch: 10, loss: 1.186968
global_step: 394, epoch: 10, loss: 1.312180
global_step: 395, epoch: 10, loss: 1.359315
global_step: 396, epoch: 10, loss: 1.319167
global_step: 397, epoch: 10, loss: 1.259288
global_step: 398, epoch: 10, loss: 1.277378
global_step: 399, epoch: 10, loss: 1.364626
global_step: 400, epoch: 10, loss: 1.250432
epoch: 10
train	acc: 0.5702	macro: p 0.3217, r 0.2530, f1: 0.2372	micro: p 0.5702, r 0.5702, f1 0.5702	weighted_f1:0.4875
dev	acc: 0.5257	macro: p 0.3040, r 0.2590, f1: 0.2267	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4288
test	acc: 0.5755	macro: p 0.3200, r 0.2600, f1: 0.2407	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.4928
New best model!
global_step: 401, epoch: 11, loss: 1.238979
global_step: 402, epoch: 11, loss: 1.367175
global_step: 403, epoch: 11, loss: 1.285881
global_step: 404, epoch: 11, loss: 1.303759
global_step: 405, epoch: 11, loss: 1.239856
global_step: 406, epoch: 11, loss: 1.254297
global_step: 407, epoch: 11, loss: 1.185712
global_step: 408, epoch: 11, loss: 1.235154
global_step: 409, epoch: 11, loss: 1.365006
global_step: 410, epoch: 11, loss: 1.375776
global_step: 411, epoch: 11, loss: 1.175972
global_step: 412, epoch: 11, loss: 1.365716
global_step: 413, epoch: 11, loss: 1.275782
global_step: 414, epoch: 11, loss: 1.412420
global_step: 415, epoch: 11, loss: 1.367765
global_step: 416, epoch: 11, loss: 1.394301
global_step: 417, epoch: 11, loss: 1.178917
global_step: 418, epoch: 11, loss: 1.321249
global_step: 419, epoch: 11, loss: 1.355747
global_step: 420, epoch: 11, loss: 1.269582
global_step: 421, epoch: 11, loss: 1.223989
global_step: 422, epoch: 11, loss: 1.228843
global_step: 423, epoch: 11, loss: 1.306354
global_step: 424, epoch: 11, loss: 1.260318
global_step: 425, epoch: 11, loss: 1.358642
global_step: 426, epoch: 11, loss: 1.228420
global_step: 427, epoch: 11, loss: 1.328587
global_step: 428, epoch: 11, loss: 1.269373
global_step: 429, epoch: 11, loss: 1.364651
global_step: 430, epoch: 11, loss: 1.292202
global_step: 431, epoch: 11, loss: 1.281362
global_step: 432, epoch: 11, loss: 1.390928
global_step: 433, epoch: 11, loss: 1.319708
global_step: 434, epoch: 11, loss: 1.287480
global_step: 435, epoch: 11, loss: 1.258183
global_step: 436, epoch: 11, loss: 1.291354
global_step: 437, epoch: 11, loss: 1.289411
global_step: 438, epoch: 11, loss: 1.381910
global_step: 439, epoch: 11, loss: 1.331921
global_step: 440, epoch: 11, loss: 2.082100
epoch: 11
train	acc: 0.5849	macro: p 0.3052, r 0.2810, f1: 0.2759	micro: p 0.5849, r 0.5849, f1 0.5849	weighted_f1:0.5200
dev	acc: 0.5347	macro: p 0.2860, r 0.2712, f1: 0.2572	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4585
test	acc: 0.5851	macro: p 0.2933, r 0.2767, f1: 0.2713	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5199
New best model!
global_step: 441, epoch: 12, loss: 1.368752
global_step: 442, epoch: 12, loss: 1.303556
global_step: 443, epoch: 12, loss: 1.340499
global_step: 444, epoch: 12, loss: 1.338042
global_step: 445, epoch: 12, loss: 1.212765
global_step: 446, epoch: 12, loss: 1.315644
global_step: 447, epoch: 12, loss: 1.303795
global_step: 448, epoch: 12, loss: 1.318994
global_step: 449, epoch: 12, loss: 1.324037
global_step: 450, epoch: 12, loss: 1.214830
global_step: 451, epoch: 12, loss: 1.339515
global_step: 452, epoch: 12, loss: 1.279815
global_step: 453, epoch: 12, loss: 1.216317
global_step: 454, epoch: 12, loss: 1.339592
global_step: 455, epoch: 12, loss: 1.254772
global_step: 456, epoch: 12, loss: 1.253224
global_step: 457, epoch: 12, loss: 1.311760
global_step: 458, epoch: 12, loss: 1.211432
global_step: 459, epoch: 12, loss: 1.309867
global_step: 460, epoch: 12, loss: 1.383490
global_step: 461, epoch: 12, loss: 1.321714
global_step: 462, epoch: 12, loss: 1.263727
global_step: 463, epoch: 12, loss: 1.266962
global_step: 464, epoch: 12, loss: 1.283644
global_step: 465, epoch: 12, loss: 1.159879
global_step: 466, epoch: 12, loss: 1.305343
global_step: 467, epoch: 12, loss: 1.260688
global_step: 468, epoch: 12, loss: 1.293234
global_step: 469, epoch: 12, loss: 1.207169
global_step: 470, epoch: 12, loss: 1.223236
global_step: 471, epoch: 12, loss: 1.203659
global_step: 472, epoch: 12, loss: 1.352643
global_step: 473, epoch: 12, loss: 1.195525
global_step: 474, epoch: 12, loss: 1.196165
global_step: 475, epoch: 12, loss: 1.353051
global_step: 476, epoch: 12, loss: 1.146409
global_step: 477, epoch: 12, loss: 1.322934
global_step: 478, epoch: 12, loss: 1.338958
global_step: 479, epoch: 12, loss: 1.357008
global_step: 480, epoch: 12, loss: 1.372215
epoch: 12
train	acc: 0.5885	macro: p 0.3100, r 0.2820, f1: 0.2772	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5227
dev	acc: 0.5374	macro: p 0.2905, r 0.2739, f1: 0.2565	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4582
test	acc: 0.5897	macro: p 0.3006, r 0.2815, f1: 0.2749	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5237
global_step: 481, epoch: 13, loss: 1.382485
global_step: 482, epoch: 13, loss: 1.223003
global_step: 483, epoch: 13, loss: 1.159103
global_step: 484, epoch: 13, loss: 1.245193
global_step: 485, epoch: 13, loss: 1.283695
global_step: 486, epoch: 13, loss: 1.309205
global_step: 487, epoch: 13, loss: 1.276622
global_step: 488, epoch: 13, loss: 1.397241
global_step: 489, epoch: 13, loss: 1.181108
global_step: 490, epoch: 13, loss: 1.377298
global_step: 491, epoch: 13, loss: 1.286770
global_step: 492, epoch: 13, loss: 1.296449
global_step: 493, epoch: 13, loss: 1.246220
global_step: 494, epoch: 13, loss: 1.192070
global_step: 495, epoch: 13, loss: 1.387371
global_step: 496, epoch: 13, loss: 1.223512
global_step: 497, epoch: 13, loss: 1.322384
global_step: 498, epoch: 13, loss: 1.153478
global_step: 499, epoch: 13, loss: 1.138660
global_step: 500, epoch: 13, loss: 1.274779
global_step: 501, epoch: 13, loss: 1.263549
global_step: 502, epoch: 13, loss: 1.373935
global_step: 503, epoch: 13, loss: 1.197456
global_step: 504, epoch: 13, loss: 1.285321
global_step: 505, epoch: 13, loss: 1.199340
global_step: 506, epoch: 13, loss: 1.258050
global_step: 507, epoch: 13, loss: 1.220011
global_step: 508, epoch: 13, loss: 1.278509
global_step: 509, epoch: 13, loss: 1.240246
global_step: 510, epoch: 13, loss: 1.531296
global_step: 511, epoch: 13, loss: 1.252549
global_step: 512, epoch: 13, loss: 1.235504
global_step: 513, epoch: 13, loss: 1.269783
global_step: 514, epoch: 13, loss: 1.176144
global_step: 515, epoch: 13, loss: 1.312102
global_step: 516, epoch: 13, loss: 1.194108
global_step: 517, epoch: 13, loss: 1.312149
global_step: 518, epoch: 13, loss: 1.340023
global_step: 519, epoch: 13, loss: 1.254794
global_step: 520, epoch: 13, loss: 0.892073
epoch: 13
train	acc: 0.5791	macro: p 0.3294, r 0.2615, f1: 0.2472	micro: p 0.5791, r 0.5791, f1 0.5791	weighted_f1:0.4987
dev	acc: 0.5320	macro: p 0.3058, r 0.2661, f1: 0.2349	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4375
test	acc: 0.5774	macro: p 0.3131, r 0.2629, f1: 0.2422	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.4940
global_step: 521, epoch: 14, loss: 1.195242
global_step: 522, epoch: 14, loss: 1.183469
global_step: 523, epoch: 14, loss: 1.331691
global_step: 524, epoch: 14, loss: 1.280643
global_step: 525, epoch: 14, loss: 1.256101
global_step: 526, epoch: 14, loss: 1.171584
global_step: 527, epoch: 14, loss: 1.265101
global_step: 528, epoch: 14, loss: 1.245570
global_step: 529, epoch: 14, loss: 1.270081
global_step: 530, epoch: 14, loss: 1.249957
global_step: 531, epoch: 14, loss: 1.280551
global_step: 532, epoch: 14, loss: 1.306249
global_step: 533, epoch: 14, loss: 1.226073
global_step: 534, epoch: 14, loss: 1.286441
global_step: 535, epoch: 14, loss: 1.188935
global_step: 536, epoch: 14, loss: 1.177010
global_step: 537, epoch: 14, loss: 1.237555
global_step: 538, epoch: 14, loss: 1.272181
global_step: 539, epoch: 14, loss: 1.347407
global_step: 540, epoch: 14, loss: 1.354809
global_step: 541, epoch: 14, loss: 1.248828
global_step: 542, epoch: 14, loss: 1.267689
global_step: 543, epoch: 14, loss: 1.177715
global_step: 544, epoch: 14, loss: 1.321999
global_step: 545, epoch: 14, loss: 1.350353
global_step: 546, epoch: 14, loss: 1.247454
global_step: 547, epoch: 14, loss: 1.231903
global_step: 548, epoch: 14, loss: 1.196253
global_step: 549, epoch: 14, loss: 1.259150
global_step: 550, epoch: 14, loss: 1.249854
global_step: 551, epoch: 14, loss: 1.237515
global_step: 552, epoch: 14, loss: 1.232505
global_step: 553, epoch: 14, loss: 1.318618
global_step: 554, epoch: 14, loss: 1.147787
global_step: 555, epoch: 14, loss: 1.230268
global_step: 556, epoch: 14, loss: 1.282804
global_step: 557, epoch: 14, loss: 1.348439
global_step: 558, epoch: 14, loss: 1.268514
global_step: 559, epoch: 14, loss: 1.340248
global_step: 560, epoch: 14, loss: 1.292068
epoch: 14
train	acc: 0.5921	macro: p 0.3118, r 0.2885, f1: 0.2846	micro: p 0.5921, r 0.5921, f1 0.5921	weighted_f1:0.5292
dev	acc: 0.5338	macro: p 0.2823, r 0.2738, f1: 0.2585	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4590
test	acc: 0.5920	macro: p 0.3017, r 0.2867, f1: 0.2814	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5289
New best model!
global_step: 561, epoch: 15, loss: 1.153862
global_step: 562, epoch: 15, loss: 1.243221
global_step: 563, epoch: 15, loss: 1.275182
global_step: 564, epoch: 15, loss: 1.256340
global_step: 565, epoch: 15, loss: 1.277256
global_step: 566, epoch: 15, loss: 1.280690
global_step: 567, epoch: 15, loss: 1.320237
global_step: 568, epoch: 15, loss: 1.230409
global_step: 569, epoch: 15, loss: 1.155919
global_step: 570, epoch: 15, loss: 1.138099
global_step: 571, epoch: 15, loss: 1.230118
global_step: 572, epoch: 15, loss: 1.267732
global_step: 573, epoch: 15, loss: 1.233493
global_step: 574, epoch: 15, loss: 1.279628
global_step: 575, epoch: 15, loss: 1.141029
global_step: 576, epoch: 15, loss: 1.299610
global_step: 577, epoch: 15, loss: 1.185440
global_step: 578, epoch: 15, loss: 1.174151
global_step: 579, epoch: 15, loss: 1.276115
global_step: 580, epoch: 15, loss: 1.176919
global_step: 581, epoch: 15, loss: 1.410585
global_step: 582, epoch: 15, loss: 1.297316
global_step: 583, epoch: 15, loss: 1.249044
global_step: 584, epoch: 15, loss: 1.173176
global_step: 585, epoch: 15, loss: 1.270386
global_step: 586, epoch: 15, loss: 1.299421
global_step: 587, epoch: 15, loss: 1.295785
global_step: 588, epoch: 15, loss: 1.415745
global_step: 589, epoch: 15, loss: 1.256400
global_step: 590, epoch: 15, loss: 1.176011
global_step: 591, epoch: 15, loss: 1.355256
global_step: 592, epoch: 15, loss: 1.223862
global_step: 593, epoch: 15, loss: 1.330594
global_step: 594, epoch: 15, loss: 1.219921
global_step: 595, epoch: 15, loss: 1.239331
global_step: 596, epoch: 15, loss: 1.206608
global_step: 597, epoch: 15, loss: 1.218866
global_step: 598, epoch: 15, loss: 1.204493
global_step: 599, epoch: 15, loss: 1.231552
global_step: 600, epoch: 15, loss: 1.601623
epoch: 15
train	acc: 0.5954	macro: p 0.3099, r 0.2886, f1: 0.2843	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5307
dev	acc: 0.5392	macro: p 0.2859, r 0.2785, f1: 0.2617	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4619
test	acc: 0.5958	macro: p 0.3050, r 0.2901, f1: 0.2817	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5293
New best model!
global_step: 601, epoch: 16, loss: 1.367072
global_step: 602, epoch: 16, loss: 1.184422
global_step: 603, epoch: 16, loss: 1.228359
global_step: 604, epoch: 16, loss: 1.343108
global_step: 605, epoch: 16, loss: 1.273913
global_step: 606, epoch: 16, loss: 1.225495
global_step: 607, epoch: 16, loss: 1.301737
global_step: 608, epoch: 16, loss: 1.306123
global_step: 609, epoch: 16, loss: 1.261315
global_step: 610, epoch: 16, loss: 1.288257
global_step: 611, epoch: 16, loss: 1.181171
global_step: 612, epoch: 16, loss: 1.303702
global_step: 613, epoch: 16, loss: 1.163167
global_step: 614, epoch: 16, loss: 1.213653
global_step: 615, epoch: 16, loss: 1.231642
global_step: 616, epoch: 16, loss: 1.234255
global_step: 617, epoch: 16, loss: 1.242360
global_step: 618, epoch: 16, loss: 1.214857
global_step: 619, epoch: 16, loss: 1.166536
global_step: 620, epoch: 16, loss: 1.160700
global_step: 621, epoch: 16, loss: 1.237592
global_step: 622, epoch: 16, loss: 1.262964
global_step: 623, epoch: 16, loss: 1.268065
global_step: 624, epoch: 16, loss: 1.273289
global_step: 625, epoch: 16, loss: 1.291440
global_step: 626, epoch: 16, loss: 1.225035
global_step: 627, epoch: 16, loss: 1.337731
global_step: 628, epoch: 16, loss: 1.251035
global_step: 629, epoch: 16, loss: 1.255371
global_step: 630, epoch: 16, loss: 1.252329
global_step: 631, epoch: 16, loss: 1.235928
global_step: 632, epoch: 16, loss: 1.275123
global_step: 633, epoch: 16, loss: 1.172144
global_step: 634, epoch: 16, loss: 1.190355
global_step: 635, epoch: 16, loss: 1.166787
global_step: 636, epoch: 16, loss: 1.247744
global_step: 637, epoch: 16, loss: 1.164946
global_step: 638, epoch: 16, loss: 1.213537
global_step: 639, epoch: 16, loss: 1.134573
global_step: 640, epoch: 16, loss: 1.242085
epoch: 16
train	acc: 0.5921	macro: p 0.3127, r 0.2821, f1: 0.2741	micro: p 0.5921, r 0.5921, f1 0.5921	weighted_f1:0.5229
dev	acc: 0.5383	macro: p 0.2904, r 0.2777, f1: 0.2545	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4552
test	acc: 0.5931	macro: p 0.3065, r 0.2863, f1: 0.2732	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5222
global_step: 641, epoch: 17, loss: 1.273086
global_step: 642, epoch: 17, loss: 1.240804
global_step: 643, epoch: 17, loss: 1.238169
global_step: 644, epoch: 17, loss: 1.170442
global_step: 645, epoch: 17, loss: 1.184289
global_step: 646, epoch: 17, loss: 1.258479
global_step: 647, epoch: 17, loss: 1.252948
global_step: 648, epoch: 17, loss: 1.334740
global_step: 649, epoch: 17, loss: 1.205456
global_step: 650, epoch: 17, loss: 1.208217
global_step: 651, epoch: 17, loss: 1.239698
global_step: 652, epoch: 17, loss: 1.255140
global_step: 653, epoch: 17, loss: 1.245002
global_step: 654, epoch: 17, loss: 1.220509
global_step: 655, epoch: 17, loss: 1.386240
global_step: 656, epoch: 17, loss: 1.222567
global_step: 657, epoch: 17, loss: 1.125644
global_step: 658, epoch: 17, loss: 1.222736
global_step: 659, epoch: 17, loss: 1.207845
global_step: 660, epoch: 17, loss: 1.210866
global_step: 661, epoch: 17, loss: 1.295958
global_step: 662, epoch: 17, loss: 1.094135
global_step: 663, epoch: 17, loss: 1.262990
global_step: 664, epoch: 17, loss: 1.155344
global_step: 665, epoch: 17, loss: 1.242251
global_step: 666, epoch: 17, loss: 1.268740
global_step: 667, epoch: 17, loss: 1.189818
global_step: 668, epoch: 17, loss: 1.266171
global_step: 669, epoch: 17, loss: 1.245361
global_step: 670, epoch: 17, loss: 1.223740
global_step: 671, epoch: 17, loss: 1.199361
global_step: 672, epoch: 17, loss: 1.223102
global_step: 673, epoch: 17, loss: 1.268390
global_step: 674, epoch: 17, loss: 1.183059
global_step: 675, epoch: 17, loss: 1.122856
global_step: 676, epoch: 17, loss: 1.245026
global_step: 677, epoch: 17, loss: 1.301084
global_step: 678, epoch: 17, loss: 1.283322
global_step: 679, epoch: 17, loss: 1.255256
global_step: 680, epoch: 17, loss: 0.385023
epoch: 17
train	acc: 0.5956	macro: p 0.3120, r 0.2867, f1: 0.2818	micro: p 0.5956, r 0.5956, f1 0.5956	weighted_f1:0.5289
dev	acc: 0.5428	macro: p 0.2875, r 0.2801, f1: 0.2602	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4618
test	acc: 0.5958	macro: p 0.3041, r 0.2889, f1: 0.2794	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5274
global_step: 681, epoch: 18, loss: 1.312305
global_step: 682, epoch: 18, loss: 1.172001
global_step: 683, epoch: 18, loss: 1.150552
global_step: 684, epoch: 18, loss: 1.196700
global_step: 685, epoch: 18, loss: 1.202183
global_step: 686, epoch: 18, loss: 1.318427
global_step: 687, epoch: 18, loss: 1.179764
global_step: 688, epoch: 18, loss: 1.235094
global_step: 689, epoch: 18, loss: 1.219190
global_step: 690, epoch: 18, loss: 1.211221
global_step: 691, epoch: 18, loss: 1.172045
global_step: 692, epoch: 18, loss: 1.180612
global_step: 693, epoch: 18, loss: 1.232883
global_step: 694, epoch: 18, loss: 1.167233
global_step: 695, epoch: 18, loss: 1.299232
global_step: 696, epoch: 18, loss: 1.198856
global_step: 697, epoch: 18, loss: 1.339774
global_step: 698, epoch: 18, loss: 1.225437
global_step: 699, epoch: 18, loss: 1.165678
global_step: 700, epoch: 18, loss: 1.300117
global_step: 701, epoch: 18, loss: 1.265540
global_step: 702, epoch: 18, loss: 1.165651
global_step: 703, epoch: 18, loss: 1.219247
global_step: 704, epoch: 18, loss: 1.207190
global_step: 705, epoch: 18, loss: 1.316543
global_step: 706, epoch: 18, loss: 1.113458
global_step: 707, epoch: 18, loss: 1.261533
global_step: 708, epoch: 18, loss: 1.185568
global_step: 709, epoch: 18, loss: 1.203601
global_step: 710, epoch: 18, loss: 1.174359
global_step: 711, epoch: 18, loss: 1.346869
global_step: 712, epoch: 18, loss: 1.238665
global_step: 713, epoch: 18, loss: 1.134793
global_step: 714, epoch: 18, loss: 1.195794
global_step: 715, epoch: 18, loss: 1.254910
global_step: 716, epoch: 18, loss: 1.274386
global_step: 717, epoch: 18, loss: 1.197368
global_step: 718, epoch: 18, loss: 1.247577
global_step: 719, epoch: 18, loss: 1.264400
global_step: 720, epoch: 18, loss: 1.841988
epoch: 18
train	acc: 0.6043	macro: p 0.3843, r 0.2993, f1: 0.2971	micro: p 0.6043, r 0.6043, f1 0.6043	weighted_f1:0.5423
dev	acc: 0.5473	macro: p 0.2849, r 0.2862, f1: 0.2725	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4725
test	acc: 0.6015	macro: p 0.3749, r 0.2973, f1: 0.2921	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5382
New best model!
global_step: 721, epoch: 19, loss: 1.265996
global_step: 722, epoch: 19, loss: 1.151362
global_step: 723, epoch: 19, loss: 1.287120
global_step: 724, epoch: 19, loss: 1.222409
global_step: 725, epoch: 19, loss: 1.216302
global_step: 726, epoch: 19, loss: 1.352024
global_step: 727, epoch: 19, loss: 1.300299
global_step: 728, epoch: 19, loss: 1.124022
global_step: 729, epoch: 19, loss: 1.218155
global_step: 730, epoch: 19, loss: 1.174568
global_step: 731, epoch: 19, loss: 1.229002
global_step: 732, epoch: 19, loss: 1.276609
global_step: 733, epoch: 19, loss: 1.174397
global_step: 734, epoch: 19, loss: 1.263454
global_step: 735, epoch: 19, loss: 1.192981
global_step: 736, epoch: 19, loss: 1.233125
global_step: 737, epoch: 19, loss: 1.172873
global_step: 738, epoch: 19, loss: 1.182880
global_step: 739, epoch: 19, loss: 1.253804
global_step: 740, epoch: 19, loss: 1.240871
global_step: 741, epoch: 19, loss: 1.279406
global_step: 742, epoch: 19, loss: 1.241973
global_step: 743, epoch: 19, loss: 1.170869
global_step: 744, epoch: 19, loss: 1.151854
global_step: 745, epoch: 19, loss: 1.251397
global_step: 746, epoch: 19, loss: 1.141092
global_step: 747, epoch: 19, loss: 1.260137
global_step: 748, epoch: 19, loss: 1.218818
global_step: 749, epoch: 19, loss: 1.253213
global_step: 750, epoch: 19, loss: 1.272340
global_step: 751, epoch: 19, loss: 1.173361
global_step: 752, epoch: 19, loss: 1.243243
global_step: 753, epoch: 19, loss: 1.117417
global_step: 754, epoch: 19, loss: 1.150456
global_step: 755, epoch: 19, loss: 1.155479
global_step: 756, epoch: 19, loss: 1.097697
global_step: 757, epoch: 19, loss: 1.212141
global_step: 758, epoch: 19, loss: 1.143687
global_step: 759, epoch: 19, loss: 1.212626
global_step: 760, epoch: 19, loss: 1.089936
epoch: 19
train	acc: 0.6051	macro: p 0.3934, r 0.3004, f1: 0.2964	micro: p 0.6051, r 0.6051, f1 0.6051	weighted_f1:0.5436
dev	acc: 0.5410	macro: p 0.2875, r 0.2807, f1: 0.2633	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4648
test	acc: 0.6015	macro: p 0.3843, r 0.2976, f1: 0.2918	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5394
global_step: 761, epoch: 20, loss: 1.198581
global_step: 762, epoch: 20, loss: 1.213495
global_step: 763, epoch: 20, loss: 1.157490
global_step: 764, epoch: 20, loss: 1.083585
global_step: 765, epoch: 20, loss: 1.263049
global_step: 766, epoch: 20, loss: 1.191928
global_step: 767, epoch: 20, loss: 1.225053
global_step: 768, epoch: 20, loss: 1.151254
global_step: 769, epoch: 20, loss: 1.150331
global_step: 770, epoch: 20, loss: 1.208530
global_step: 771, epoch: 20, loss: 1.162447
global_step: 772, epoch: 20, loss: 1.105604
global_step: 773, epoch: 20, loss: 1.248594
global_step: 774, epoch: 20, loss: 1.223640
global_step: 775, epoch: 20, loss: 1.320577
global_step: 776, epoch: 20, loss: 1.285895
global_step: 777, epoch: 20, loss: 1.264960
global_step: 778, epoch: 20, loss: 1.213872
global_step: 779, epoch: 20, loss: 1.231968
global_step: 780, epoch: 20, loss: 1.178654
global_step: 781, epoch: 20, loss: 1.132308
global_step: 782, epoch: 20, loss: 1.219554
global_step: 783, epoch: 20, loss: 1.121374
global_step: 784, epoch: 20, loss: 1.261225
global_step: 785, epoch: 20, loss: 1.231832
global_step: 786, epoch: 20, loss: 1.201910
global_step: 787, epoch: 20, loss: 1.231802
global_step: 788, epoch: 20, loss: 1.213831
global_step: 789, epoch: 20, loss: 1.164567
global_step: 790, epoch: 20, loss: 1.344441
global_step: 791, epoch: 20, loss: 1.076516
global_step: 792, epoch: 20, loss: 1.214700
global_step: 793, epoch: 20, loss: 1.273748
global_step: 794, epoch: 20, loss: 1.248772
global_step: 795, epoch: 20, loss: 1.282901
global_step: 796, epoch: 20, loss: 1.199144
global_step: 797, epoch: 20, loss: 1.162476
global_step: 798, epoch: 20, loss: 1.258596
global_step: 799, epoch: 20, loss: 1.145743
global_step: 800, epoch: 20, loss: 0.800328
epoch: 20
train	acc: 0.5988	macro: p 0.3990, r 0.2871, f1: 0.2741	micro: p 0.5988, r 0.5988, f1 0.5988	weighted_f1:0.5275
dev	acc: 0.5428	macro: p 0.2991, r 0.2828, f1: 0.2527	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4566
test	acc: 0.5923	macro: p 0.3132, r 0.2874, f1: 0.2678	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5184
global_step: 801, epoch: 21, loss: 1.226313
global_step: 802, epoch: 21, loss: 1.235905
global_step: 803, epoch: 21, loss: 1.178601
global_step: 804, epoch: 21, loss: 1.134820
global_step: 805, epoch: 21, loss: 1.067712
global_step: 806, epoch: 21, loss: 1.187090
global_step: 807, epoch: 21, loss: 1.193788
global_step: 808, epoch: 21, loss: 1.293245
global_step: 809, epoch: 21, loss: 1.165808
global_step: 810, epoch: 21, loss: 1.132773
global_step: 811, epoch: 21, loss: 1.255921
global_step: 812, epoch: 21, loss: 1.154898
global_step: 813, epoch: 21, loss: 1.153767
global_step: 814, epoch: 21, loss: 1.021679
global_step: 815, epoch: 21, loss: 1.205220
global_step: 816, epoch: 21, loss: 1.260905
global_step: 817, epoch: 21, loss: 1.159085
global_step: 818, epoch: 21, loss: 1.142094
global_step: 819, epoch: 21, loss: 1.254852
global_step: 820, epoch: 21, loss: 1.255115
global_step: 821, epoch: 21, loss: 1.200127
global_step: 822, epoch: 21, loss: 1.181541
global_step: 823, epoch: 21, loss: 1.197104
global_step: 824, epoch: 21, loss: 1.216079
global_step: 825, epoch: 21, loss: 1.256306
global_step: 826, epoch: 21, loss: 1.260658
global_step: 827, epoch: 21, loss: 1.267381
global_step: 828, epoch: 21, loss: 1.278243
global_step: 829, epoch: 21, loss: 1.196137
global_step: 830, epoch: 21, loss: 1.170444
global_step: 831, epoch: 21, loss: 1.171640
global_step: 832, epoch: 21, loss: 1.165731
global_step: 833, epoch: 21, loss: 1.204533
global_step: 834, epoch: 21, loss: 1.172310
global_step: 835, epoch: 21, loss: 1.294580
global_step: 836, epoch: 21, loss: 1.133886
global_step: 837, epoch: 21, loss: 1.118141
global_step: 838, epoch: 21, loss: 1.273708
global_step: 839, epoch: 21, loss: 1.214417
global_step: 840, epoch: 21, loss: 1.357591
epoch: 21
train	acc: 0.6172	macro: p 0.3959, r 0.3223, f1: 0.3190	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5648
dev	acc: 0.5500	macro: p 0.3174, r 0.2976, f1: 0.2771	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4807
test	acc: 0.5989	macro: p 0.3797, r 0.3104, f1: 0.3000	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5442
New best model!
global_step: 841, epoch: 22, loss: 1.094582
global_step: 842, epoch: 22, loss: 1.129139
global_step: 843, epoch: 22, loss: 1.109347
global_step: 844, epoch: 22, loss: 1.235343
global_step: 845, epoch: 22, loss: 1.192153
global_step: 846, epoch: 22, loss: 1.200582
global_step: 847, epoch: 22, loss: 1.163158
global_step: 848, epoch: 22, loss: 1.157764
global_step: 849, epoch: 22, loss: 1.140819
global_step: 850, epoch: 22, loss: 1.178382
global_step: 851, epoch: 22, loss: 1.206116
global_step: 852, epoch: 22, loss: 1.255038
global_step: 853, epoch: 22, loss: 1.115693
global_step: 854, epoch: 22, loss: 1.112808
global_step: 855, epoch: 22, loss: 1.270479
global_step: 856, epoch: 22, loss: 1.251029
global_step: 857, epoch: 22, loss: 1.201581
global_step: 858, epoch: 22, loss: 1.316886
global_step: 859, epoch: 22, loss: 1.136662
global_step: 860, epoch: 22, loss: 1.250765
global_step: 861, epoch: 22, loss: 1.075040
global_step: 862, epoch: 22, loss: 1.215278
global_step: 863, epoch: 22, loss: 1.131373
global_step: 864, epoch: 22, loss: 1.099708
global_step: 865, epoch: 22, loss: 1.233822
global_step: 866, epoch: 22, loss: 1.222406
global_step: 867, epoch: 22, loss: 1.211163
global_step: 868, epoch: 22, loss: 1.331242
global_step: 869, epoch: 22, loss: 1.219022
global_step: 870, epoch: 22, loss: 1.256768
global_step: 871, epoch: 22, loss: 1.101177
global_step: 872, epoch: 22, loss: 1.227215
global_step: 873, epoch: 22, loss: 1.227581
global_step: 874, epoch: 22, loss: 1.086967
global_step: 875, epoch: 22, loss: 1.194756
global_step: 876, epoch: 22, loss: 1.223837
global_step: 877, epoch: 22, loss: 1.085613
global_step: 878, epoch: 22, loss: 1.136169
global_step: 879, epoch: 22, loss: 1.204661
global_step: 880, epoch: 22, loss: 1.120789
epoch: 22
train	acc: 0.6125	macro: p 0.3970, r 0.3056, f1: 0.3013	micro: p 0.6125, r 0.6125, f1 0.6125	weighted_f1:0.5501
dev	acc: 0.5491	macro: p 0.2879, r 0.2895, f1: 0.2675	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4701
test	acc: 0.6046	macro: p 0.4068, r 0.3013, f1: 0.2920	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5392
global_step: 881, epoch: 23, loss: 1.133923
global_step: 882, epoch: 23, loss: 1.091553
global_step: 883, epoch: 23, loss: 1.178062
global_step: 884, epoch: 23, loss: 1.129668
global_step: 885, epoch: 23, loss: 1.172923
global_step: 886, epoch: 23, loss: 1.135109
global_step: 887, epoch: 23, loss: 1.170700
global_step: 888, epoch: 23, loss: 1.212729
global_step: 889, epoch: 23, loss: 1.235312
global_step: 890, epoch: 23, loss: 1.297244
global_step: 891, epoch: 23, loss: 1.298450
global_step: 892, epoch: 23, loss: 1.160305
global_step: 893, epoch: 23, loss: 1.197966
global_step: 894, epoch: 23, loss: 1.182123
global_step: 895, epoch: 23, loss: 1.063328
global_step: 896, epoch: 23, loss: 1.130273
global_step: 897, epoch: 23, loss: 1.149759
global_step: 898, epoch: 23, loss: 1.212078
global_step: 899, epoch: 23, loss: 1.200155
global_step: 900, epoch: 23, loss: 1.337323
global_step: 901, epoch: 23, loss: 1.104651
global_step: 902, epoch: 23, loss: 1.202605
global_step: 903, epoch: 23, loss: 1.163270
global_step: 904, epoch: 23, loss: 1.196707
global_step: 905, epoch: 23, loss: 1.108851
global_step: 906, epoch: 23, loss: 1.294174
global_step: 907, epoch: 23, loss: 1.131623
global_step: 908, epoch: 23, loss: 1.169831
global_step: 909, epoch: 23, loss: 1.118487
global_step: 910, epoch: 23, loss: 1.153198
global_step: 911, epoch: 23, loss: 1.213575
global_step: 912, epoch: 23, loss: 1.180477
global_step: 913, epoch: 23, loss: 1.309695
global_step: 914, epoch: 23, loss: 1.076525
global_step: 915, epoch: 23, loss: 1.140504
global_step: 916, epoch: 23, loss: 1.144465
global_step: 917, epoch: 23, loss: 1.117981
global_step: 918, epoch: 23, loss: 1.152349
global_step: 919, epoch: 23, loss: 1.289152
global_step: 920, epoch: 23, loss: 1.188995
epoch: 23
train	acc: 0.6130	macro: p 0.3967, r 0.3065, f1: 0.3008	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5508
dev	acc: 0.5491	macro: p 0.2892, r 0.2910, f1: 0.2661	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4689
test	acc: 0.6015	macro: p 0.4251, r 0.3004, f1: 0.2895	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5367
global_step: 921, epoch: 24, loss: 1.070497
global_step: 922, epoch: 24, loss: 1.126119
global_step: 923, epoch: 24, loss: 1.151514
global_step: 924, epoch: 24, loss: 1.065971
global_step: 925, epoch: 24, loss: 1.128238
global_step: 926, epoch: 24, loss: 1.195691
global_step: 927, epoch: 24, loss: 1.256963
global_step: 928, epoch: 24, loss: 1.068190
global_step: 929, epoch: 24, loss: 1.149564
global_step: 930, epoch: 24, loss: 1.135775
global_step: 931, epoch: 24, loss: 1.205709
global_step: 932, epoch: 24, loss: 1.150017
global_step: 933, epoch: 24, loss: 1.171188
global_step: 934, epoch: 24, loss: 1.314183
global_step: 935, epoch: 24, loss: 1.145495
global_step: 936, epoch: 24, loss: 1.083352
global_step: 937, epoch: 24, loss: 1.127969
global_step: 938, epoch: 24, loss: 1.184581
global_step: 939, epoch: 24, loss: 1.172968
global_step: 940, epoch: 24, loss: 1.221315
global_step: 941, epoch: 24, loss: 1.169778
global_step: 942, epoch: 24, loss: 1.118925
global_step: 943, epoch: 24, loss: 1.068183
global_step: 944, epoch: 24, loss: 1.193318
global_step: 945, epoch: 24, loss: 1.140992
global_step: 946, epoch: 24, loss: 1.094766
global_step: 947, epoch: 24, loss: 1.252509
global_step: 948, epoch: 24, loss: 1.219975
global_step: 949, epoch: 24, loss: 1.097970
global_step: 950, epoch: 24, loss: 1.157021
global_step: 951, epoch: 24, loss: 1.183150
global_step: 952, epoch: 24, loss: 1.186960
global_step: 953, epoch: 24, loss: 1.238388
global_step: 954, epoch: 24, loss: 1.247197
global_step: 955, epoch: 24, loss: 1.167231
global_step: 956, epoch: 24, loss: 1.176456
global_step: 957, epoch: 24, loss: 1.266222
global_step: 958, epoch: 24, loss: 1.199079
global_step: 959, epoch: 24, loss: 1.237002
global_step: 960, epoch: 24, loss: 0.416342
epoch: 24
train	acc: 0.6150	macro: p 0.4238, r 0.3068, f1: 0.3041	micro: p 0.6150, r 0.6150, f1 0.6150	weighted_f1:0.5526
dev	acc: 0.5437	macro: p 0.3562, r 0.2837, f1: 0.2647	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4657
test	acc: 0.6034	macro: p 0.4171, r 0.2991, f1: 0.2922	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5388
global_step: 961, epoch: 25, loss: 1.195093
global_step: 962, epoch: 25, loss: 1.139304
global_step: 963, epoch: 25, loss: 1.189615
global_step: 964, epoch: 25, loss: 1.155991
global_step: 965, epoch: 25, loss: 1.156335
global_step: 966, epoch: 25, loss: 1.202517
global_step: 967, epoch: 25, loss: 1.134638
global_step: 968, epoch: 25, loss: 1.160056
global_step: 969, epoch: 25, loss: 1.167982
global_step: 970, epoch: 25, loss: 1.120108
global_step: 971, epoch: 25, loss: 1.230442
global_step: 972, epoch: 25, loss: 1.106247
global_step: 973, epoch: 25, loss: 1.262157
global_step: 974, epoch: 25, loss: 1.082998
global_step: 975, epoch: 25, loss: 1.192716
global_step: 976, epoch: 25, loss: 1.199931
global_step: 977, epoch: 25, loss: 1.218947
global_step: 978, epoch: 25, loss: 1.164561
global_step: 979, epoch: 25, loss: 1.199244
global_step: 980, epoch: 25, loss: 1.248341
global_step: 981, epoch: 25, loss: 1.073836
global_step: 982, epoch: 25, loss: 1.194578
global_step: 983, epoch: 25, loss: 1.314112
global_step: 984, epoch: 25, loss: 1.075691
global_step: 985, epoch: 25, loss: 1.122566
global_step: 986, epoch: 25, loss: 1.146732
global_step: 987, epoch: 25, loss: 1.300068
global_step: 988, epoch: 25, loss: 1.175734
global_step: 989, epoch: 25, loss: 1.175778
global_step: 990, epoch: 25, loss: 1.073338
global_step: 991, epoch: 25, loss: 1.151237
global_step: 992, epoch: 25, loss: 0.993475
global_step: 993, epoch: 25, loss: 1.065810
global_step: 994, epoch: 25, loss: 1.080501
global_step: 995, epoch: 25, loss: 1.145421
global_step: 996, epoch: 25, loss: 1.171699
global_step: 997, epoch: 25, loss: 1.197459
global_step: 998, epoch: 25, loss: 1.219899
global_step: 999, epoch: 25, loss: 1.198677
global_step: 1000, epoch: 25, loss: 1.484601
epoch: 25
train	acc: 0.6246	macro: p 0.4184, r 0.3231, f1: 0.3227	micro: p 0.6246, r 0.6246, f1 0.6246	weighted_f1:0.5687
dev	acc: 0.5509	macro: p 0.3809, r 0.2964, f1: 0.2784	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4787
test	acc: 0.6027	macro: p 0.3985, r 0.3074, f1: 0.3011	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5446
global_step: 1001, epoch: 26, loss: 1.149855
global_step: 1002, epoch: 26, loss: 1.073140
global_step: 1003, epoch: 26, loss: 1.111672
global_step: 1004, epoch: 26, loss: 1.235082
global_step: 1005, epoch: 26, loss: 1.165060
global_step: 1006, epoch: 26, loss: 1.097330
global_step: 1007, epoch: 26, loss: 1.151475
global_step: 1008, epoch: 26, loss: 1.172332
global_step: 1009, epoch: 26, loss: 1.270596
global_step: 1010, epoch: 26, loss: 1.142241
global_step: 1011, epoch: 26, loss: 1.193501
global_step: 1012, epoch: 26, loss: 1.141123
global_step: 1013, epoch: 26, loss: 1.174471
global_step: 1014, epoch: 26, loss: 1.125851
global_step: 1015, epoch: 26, loss: 1.240888
global_step: 1016, epoch: 26, loss: 1.106482
global_step: 1017, epoch: 26, loss: 1.090338
global_step: 1018, epoch: 26, loss: 0.972254
global_step: 1019, epoch: 26, loss: 1.212623
global_step: 1020, epoch: 26, loss: 1.162150
global_step: 1021, epoch: 26, loss: 1.130580
global_step: 1022, epoch: 26, loss: 0.927339
global_step: 1023, epoch: 26, loss: 1.077287
global_step: 1024, epoch: 26, loss: 1.107428
global_step: 1025, epoch: 26, loss: 1.115417
global_step: 1026, epoch: 26, loss: 1.106302
global_step: 1027, epoch: 26, loss: 1.167768
global_step: 1028, epoch: 26, loss: 1.092676
global_step: 1029, epoch: 26, loss: 1.145964
global_step: 1030, epoch: 26, loss: 1.200381
global_step: 1031, epoch: 26, loss: 1.228536
global_step: 1032, epoch: 26, loss: 1.203984
global_step: 1033, epoch: 26, loss: 1.130352
global_step: 1034, epoch: 26, loss: 1.134263
global_step: 1035, epoch: 26, loss: 1.189587
global_step: 1036, epoch: 26, loss: 1.203734
global_step: 1037, epoch: 26, loss: 1.108314
global_step: 1038, epoch: 26, loss: 1.229411
global_step: 1039, epoch: 26, loss: 1.191195
global_step: 1040, epoch: 26, loss: 1.550173
epoch: 26
train	acc: 0.6285	macro: p 0.3988, r 0.3293, f1: 0.3338	micro: p 0.6285, r 0.6285, f1 0.6285	weighted_f1:0.5763
dev	acc: 0.5591	macro: p 0.3611, r 0.3021, f1: 0.2926	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.4927
test	acc: 0.6088	macro: p 0.3805, r 0.3097, f1: 0.3085	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5519
New best model!
global_step: 1041, epoch: 27, loss: 1.299226
global_step: 1042, epoch: 27, loss: 1.103263
global_step: 1043, epoch: 27, loss: 1.135689
global_step: 1044, epoch: 27, loss: 1.096841
global_step: 1045, epoch: 27, loss: 1.175895
global_step: 1046, epoch: 27, loss: 1.176648
global_step: 1047, epoch: 27, loss: 1.106614
global_step: 1048, epoch: 27, loss: 1.183028
global_step: 1049, epoch: 27, loss: 1.150504
global_step: 1050, epoch: 27, loss: 1.097900
global_step: 1051, epoch: 27, loss: 1.086945
global_step: 1052, epoch: 27, loss: 1.054274
global_step: 1053, epoch: 27, loss: 1.081329
global_step: 1054, epoch: 27, loss: 1.063257
global_step: 1055, epoch: 27, loss: 1.188066
global_step: 1056, epoch: 27, loss: 1.195964
global_step: 1057, epoch: 27, loss: 1.096045
global_step: 1058, epoch: 27, loss: 1.179881
global_step: 1059, epoch: 27, loss: 1.123784
global_step: 1060, epoch: 27, loss: 1.133855
global_step: 1061, epoch: 27, loss: 1.126723
global_step: 1062, epoch: 27, loss: 1.148239
global_step: 1063, epoch: 27, loss: 1.157498
global_step: 1064, epoch: 27, loss: 1.103404
global_step: 1065, epoch: 27, loss: 1.100338
global_step: 1066, epoch: 27, loss: 1.179599
global_step: 1067, epoch: 27, loss: 1.060384
global_step: 1068, epoch: 27, loss: 1.206544
global_step: 1069, epoch: 27, loss: 1.282946
global_step: 1070, epoch: 27, loss: 1.043570
global_step: 1071, epoch: 27, loss: 1.136966
global_step: 1072, epoch: 27, loss: 1.247307
global_step: 1073, epoch: 27, loss: 1.126993
global_step: 1074, epoch: 27, loss: 1.165834
global_step: 1075, epoch: 27, loss: 1.096843
global_step: 1076, epoch: 27, loss: 1.159878
global_step: 1077, epoch: 27, loss: 1.228844
global_step: 1078, epoch: 27, loss: 1.129881
global_step: 1079, epoch: 27, loss: 1.047262
global_step: 1080, epoch: 27, loss: 1.088525
epoch: 27
train	acc: 0.6387	macro: p 0.3993, r 0.3477, f1: 0.3512	micro: p 0.6387, r 0.6387, f1 0.6387	weighted_f1:0.5926
dev	acc: 0.5690	macro: p 0.3578, r 0.3157, f1: 0.3071	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5084
test	acc: 0.6100	macro: p 0.3907, r 0.3231, f1: 0.3220	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5605
New best model!
global_step: 1081, epoch: 28, loss: 1.057986
global_step: 1082, epoch: 28, loss: 1.056213
global_step: 1083, epoch: 28, loss: 1.250036
global_step: 1084, epoch: 28, loss: 1.216030
global_step: 1085, epoch: 28, loss: 1.004003
global_step: 1086, epoch: 28, loss: 1.209851
global_step: 1087, epoch: 28, loss: 1.111031
global_step: 1088, epoch: 28, loss: 1.164864
global_step: 1089, epoch: 28, loss: 1.191487
global_step: 1090, epoch: 28, loss: 1.131933
global_step: 1091, epoch: 28, loss: 1.104492
global_step: 1092, epoch: 28, loss: 1.151929
global_step: 1093, epoch: 28, loss: 1.026000
global_step: 1094, epoch: 28, loss: 1.049789
global_step: 1095, epoch: 28, loss: 1.119968
global_step: 1096, epoch: 28, loss: 1.164030
global_step: 1097, epoch: 28, loss: 1.011745
global_step: 1098, epoch: 28, loss: 1.182098
global_step: 1099, epoch: 28, loss: 1.125270
global_step: 1100, epoch: 28, loss: 1.024528
global_step: 1101, epoch: 28, loss: 1.114897
global_step: 1102, epoch: 28, loss: 1.134240
global_step: 1103, epoch: 28, loss: 1.201797
global_step: 1104, epoch: 28, loss: 1.129702
global_step: 1105, epoch: 28, loss: 1.110378
global_step: 1106, epoch: 28, loss: 1.316295
global_step: 1107, epoch: 28, loss: 1.130046
global_step: 1108, epoch: 28, loss: 1.145007
global_step: 1109, epoch: 28, loss: 1.177903
global_step: 1110, epoch: 28, loss: 1.155195
global_step: 1111, epoch: 28, loss: 1.192287
global_step: 1112, epoch: 28, loss: 1.243435
global_step: 1113, epoch: 28, loss: 1.091425
global_step: 1114, epoch: 28, loss: 1.106375
global_step: 1115, epoch: 28, loss: 1.165785
global_step: 1116, epoch: 28, loss: 1.192655
global_step: 1117, epoch: 28, loss: 1.188017
global_step: 1118, epoch: 28, loss: 0.990417
global_step: 1119, epoch: 28, loss: 1.105327
global_step: 1120, epoch: 28, loss: 2.275826
epoch: 28
train	acc: 0.6360	macro: p 0.4060, r 0.3370, f1: 0.3410	micro: p 0.6360, r 0.6360, f1 0.6360	weighted_f1:0.5845
dev	acc: 0.5582	macro: p 0.3523, r 0.3038, f1: 0.2921	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4922
test	acc: 0.6073	macro: p 0.3919, r 0.3123, f1: 0.3093	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5509
global_step: 1121, epoch: 29, loss: 1.020975
global_step: 1122, epoch: 29, loss: 1.125415
global_step: 1123, epoch: 29, loss: 1.124255
global_step: 1124, epoch: 29, loss: 1.161844
global_step: 1125, epoch: 29, loss: 1.038843
global_step: 1126, epoch: 29, loss: 1.150654
global_step: 1127, epoch: 29, loss: 1.124080
global_step: 1128, epoch: 29, loss: 1.109197
global_step: 1129, epoch: 29, loss: 1.175835
global_step: 1130, epoch: 29, loss: 1.113127
global_step: 1131, epoch: 29, loss: 1.154205
global_step: 1132, epoch: 29, loss: 1.127887
global_step: 1133, epoch: 29, loss: 1.099075
global_step: 1134, epoch: 29, loss: 1.126636
global_step: 1135, epoch: 29, loss: 1.195636
global_step: 1136, epoch: 29, loss: 1.148377
global_step: 1137, epoch: 29, loss: 1.118524
global_step: 1138, epoch: 29, loss: 1.118447
global_step: 1139, epoch: 29, loss: 1.110859
global_step: 1140, epoch: 29, loss: 1.197251
global_step: 1141, epoch: 29, loss: 1.086515
global_step: 1142, epoch: 29, loss: 1.069530
global_step: 1143, epoch: 29, loss: 1.209809
global_step: 1144, epoch: 29, loss: 1.173193
global_step: 1145, epoch: 29, loss: 1.133877
global_step: 1146, epoch: 29, loss: 1.076236
global_step: 1147, epoch: 29, loss: 1.089772
global_step: 1148, epoch: 29, loss: 1.118649
global_step: 1149, epoch: 29, loss: 1.027410
global_step: 1150, epoch: 29, loss: 1.123149
global_step: 1151, epoch: 29, loss: 1.123419
global_step: 1152, epoch: 29, loss: 1.156960
global_step: 1153, epoch: 29, loss: 1.007781
global_step: 1154, epoch: 29, loss: 1.171302
global_step: 1155, epoch: 29, loss: 1.082172
global_step: 1156, epoch: 29, loss: 1.191843
global_step: 1157, epoch: 29, loss: 1.086146
global_step: 1158, epoch: 29, loss: 1.044124
global_step: 1159, epoch: 29, loss: 1.191529
global_step: 1160, epoch: 29, loss: 1.608246
epoch: 29
train	acc: 0.6463	macro: p 0.4133, r 0.3585, f1: 0.3614	micro: p 0.6463, r 0.6463, f1 0.6463	weighted_f1:0.6030
dev	acc: 0.5717	macro: p 0.3695, r 0.3231, f1: 0.3150	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5150
test	acc: 0.6123	macro: p 0.3896, r 0.3286, f1: 0.3275	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5660
New best model!
global_step: 1161, epoch: 30, loss: 1.071109
global_step: 1162, epoch: 30, loss: 1.040350
global_step: 1163, epoch: 30, loss: 1.180492
global_step: 1164, epoch: 30, loss: 1.151186
global_step: 1165, epoch: 30, loss: 1.208464
global_step: 1166, epoch: 30, loss: 1.192524
global_step: 1167, epoch: 30, loss: 1.181748
global_step: 1168, epoch: 30, loss: 1.135415
global_step: 1169, epoch: 30, loss: 1.186812
global_step: 1170, epoch: 30, loss: 1.207139
global_step: 1171, epoch: 30, loss: 1.094879
global_step: 1172, epoch: 30, loss: 1.049193
global_step: 1173, epoch: 30, loss: 1.098502
global_step: 1174, epoch: 30, loss: 1.058537
global_step: 1175, epoch: 30, loss: 1.043711
global_step: 1176, epoch: 30, loss: 0.981186
global_step: 1177, epoch: 30, loss: 1.035354
global_step: 1178, epoch: 30, loss: 1.173337
global_step: 1179, epoch: 30, loss: 1.211439
global_step: 1180, epoch: 30, loss: 1.173593
global_step: 1181, epoch: 30, loss: 1.031075
global_step: 1182, epoch: 30, loss: 1.183503
global_step: 1183, epoch: 30, loss: 1.077348
global_step: 1184, epoch: 30, loss: 1.029272
global_step: 1185, epoch: 30, loss: 1.120820
global_step: 1186, epoch: 30, loss: 1.248324
global_step: 1187, epoch: 30, loss: 1.142511
global_step: 1188, epoch: 30, loss: 1.195990
global_step: 1189, epoch: 30, loss: 1.189675
global_step: 1190, epoch: 30, loss: 1.044173
global_step: 1191, epoch: 30, loss: 1.021983
global_step: 1192, epoch: 30, loss: 1.087220
global_step: 1193, epoch: 30, loss: 1.082736
global_step: 1194, epoch: 30, loss: 0.924793
global_step: 1195, epoch: 30, loss: 1.128830
global_step: 1196, epoch: 30, loss: 1.137519
global_step: 1197, epoch: 30, loss: 1.132349
global_step: 1198, epoch: 30, loss: 1.198402
global_step: 1199, epoch: 30, loss: 1.134461
global_step: 1200, epoch: 30, loss: 2.410983
epoch: 30
train	acc: 0.6465	macro: p 0.4145, r 0.3652, f1: 0.3683	micro: p 0.6465, r 0.6465, f1 0.6465	weighted_f1:0.6076
dev	acc: 0.5789	macro: p 0.3856, r 0.3335, f1: 0.3348	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5317
test	acc: 0.6126	macro: p 0.3816, r 0.3346, f1: 0.3364	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5726
New best model!
global_step: 1201, epoch: 31, loss: 1.098317
global_step: 1202, epoch: 31, loss: 1.077979
global_step: 1203, epoch: 31, loss: 0.996579
global_step: 1204, epoch: 31, loss: 1.174344
global_step: 1205, epoch: 31, loss: 1.111311
global_step: 1206, epoch: 31, loss: 1.198986
global_step: 1207, epoch: 31, loss: 1.102642
global_step: 1208, epoch: 31, loss: 1.152534
global_step: 1209, epoch: 31, loss: 1.082947
global_step: 1210, epoch: 31, loss: 1.125413
global_step: 1211, epoch: 31, loss: 1.109835
global_step: 1212, epoch: 31, loss: 1.146212
global_step: 1213, epoch: 31, loss: 1.127814
global_step: 1214, epoch: 31, loss: 1.117773
global_step: 1215, epoch: 31, loss: 1.142280
global_step: 1216, epoch: 31, loss: 1.033198
global_step: 1217, epoch: 31, loss: 1.141832
global_step: 1218, epoch: 31, loss: 1.143651
global_step: 1219, epoch: 31, loss: 1.038920
global_step: 1220, epoch: 31, loss: 1.100089
global_step: 1221, epoch: 31, loss: 1.031601
global_step: 1222, epoch: 31, loss: 1.176239
global_step: 1223, epoch: 31, loss: 1.165674
global_step: 1224, epoch: 31, loss: 1.062797
global_step: 1225, epoch: 31, loss: 1.089777
global_step: 1226, epoch: 31, loss: 1.121851
global_step: 1227, epoch: 31, loss: 1.145616
global_step: 1228, epoch: 31, loss: 1.181545
global_step: 1229, epoch: 31, loss: 1.139842
global_step: 1230, epoch: 31, loss: 1.014231
global_step: 1231, epoch: 31, loss: 1.202966
global_step: 1232, epoch: 31, loss: 1.034449
global_step: 1233, epoch: 31, loss: 1.187846
global_step: 1234, epoch: 31, loss: 1.117163
global_step: 1235, epoch: 31, loss: 1.015608
global_step: 1236, epoch: 31, loss: 1.032884
global_step: 1237, epoch: 31, loss: 1.007630
global_step: 1238, epoch: 31, loss: 1.076806
global_step: 1239, epoch: 31, loss: 1.029473
global_step: 1240, epoch: 31, loss: 1.021444
epoch: 31
train	acc: 0.6440	macro: p 0.4154, r 0.3558, f1: 0.3581	micro: p 0.6440, r 0.6440, f1 0.6440	weighted_f1:0.5999
dev	acc: 0.5663	macro: p 0.3805, r 0.3218, f1: 0.3110	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5097
test	acc: 0.6023	macro: p 0.3880, r 0.3240, f1: 0.3176	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5551
global_step: 1241, epoch: 32, loss: 1.103777
global_step: 1242, epoch: 32, loss: 1.164627
global_step: 1243, epoch: 32, loss: 1.057544
global_step: 1244, epoch: 32, loss: 1.139592
global_step: 1245, epoch: 32, loss: 1.049889
global_step: 1246, epoch: 32, loss: 1.138134
global_step: 1247, epoch: 32, loss: 1.098333
global_step: 1248, epoch: 32, loss: 0.977498
global_step: 1249, epoch: 32, loss: 1.041323
global_step: 1250, epoch: 32, loss: 1.091099
global_step: 1251, epoch: 32, loss: 1.151581
global_step: 1252, epoch: 32, loss: 1.060423
global_step: 1253, epoch: 32, loss: 1.138164
global_step: 1254, epoch: 32, loss: 1.116669
global_step: 1255, epoch: 32, loss: 1.133301
global_step: 1256, epoch: 32, loss: 1.141198
global_step: 1257, epoch: 32, loss: 1.127680
global_step: 1258, epoch: 32, loss: 1.173331
global_step: 1259, epoch: 32, loss: 1.062328
global_step: 1260, epoch: 32, loss: 1.011312
global_step: 1261, epoch: 32, loss: 1.081987
global_step: 1262, epoch: 32, loss: 1.100032
global_step: 1263, epoch: 32, loss: 1.087574
global_step: 1264, epoch: 32, loss: 1.184205
global_step: 1265, epoch: 32, loss: 1.106731
global_step: 1266, epoch: 32, loss: 1.104089
global_step: 1267, epoch: 32, loss: 1.017870
global_step: 1268, epoch: 32, loss: 1.179627
global_step: 1269, epoch: 32, loss: 1.076635
global_step: 1270, epoch: 32, loss: 1.039513
global_step: 1271, epoch: 32, loss: 1.060930
global_step: 1272, epoch: 32, loss: 1.035863
global_step: 1273, epoch: 32, loss: 1.190398
global_step: 1274, epoch: 32, loss: 1.181153
global_step: 1275, epoch: 32, loss: 1.022842
global_step: 1276, epoch: 32, loss: 1.060764
global_step: 1277, epoch: 32, loss: 1.099334
global_step: 1278, epoch: 32, loss: 1.168193
global_step: 1279, epoch: 32, loss: 1.053389
global_step: 1280, epoch: 32, loss: 0.839505
epoch: 32
train	acc: 0.6531	macro: p 0.4257, r 0.3639, f1: 0.3662	micro: p 0.6531, r 0.6531, f1 0.6531	weighted_f1:0.6091
dev	acc: 0.5771	macro: p 0.3802, r 0.3267, f1: 0.3219	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5218
test	acc: 0.6169	macro: p 0.3921, r 0.3314, f1: 0.3293	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5693
global_step: 1281, epoch: 33, loss: 1.106402
global_step: 1282, epoch: 33, loss: 1.138864
global_step: 1283, epoch: 33, loss: 1.168100
global_step: 1284, epoch: 33, loss: 0.968748
global_step: 1285, epoch: 33, loss: 1.122276
global_step: 1286, epoch: 33, loss: 0.972450
global_step: 1287, epoch: 33, loss: 1.091309
global_step: 1288, epoch: 33, loss: 1.060253
global_step: 1289, epoch: 33, loss: 1.135848
global_step: 1290, epoch: 33, loss: 1.124695
global_step: 1291, epoch: 33, loss: 1.084162
global_step: 1292, epoch: 33, loss: 1.015019
global_step: 1293, epoch: 33, loss: 0.994425
global_step: 1294, epoch: 33, loss: 1.041759
global_step: 1295, epoch: 33, loss: 1.158871
global_step: 1296, epoch: 33, loss: 1.139726
global_step: 1297, epoch: 33, loss: 1.114261
global_step: 1298, epoch: 33, loss: 1.053013
global_step: 1299, epoch: 33, loss: 1.133968
global_step: 1300, epoch: 33, loss: 1.160670
global_step: 1301, epoch: 33, loss: 1.171511
global_step: 1302, epoch: 33, loss: 1.051046
global_step: 1303, epoch: 33, loss: 1.034635
global_step: 1304, epoch: 33, loss: 1.007629
global_step: 1305, epoch: 33, loss: 1.046726
global_step: 1306, epoch: 33, loss: 1.135436
global_step: 1307, epoch: 33, loss: 1.149877
global_step: 1308, epoch: 33, loss: 1.080173
global_step: 1309, epoch: 33, loss: 1.081736
global_step: 1310, epoch: 33, loss: 1.045472
global_step: 1311, epoch: 33, loss: 1.107697
global_step: 1312, epoch: 33, loss: 1.101100
global_step: 1313, epoch: 33, loss: 1.148528
global_step: 1314, epoch: 33, loss: 1.107608
global_step: 1315, epoch: 33, loss: 1.132671
global_step: 1316, epoch: 33, loss: 1.138912
global_step: 1317, epoch: 33, loss: 1.082586
global_step: 1318, epoch: 33, loss: 1.100265
global_step: 1319, epoch: 33, loss: 1.059752
global_step: 1320, epoch: 33, loss: 1.696773
epoch: 33
train	acc: 0.6585	macro: p 0.4208, r 0.3792, f1: 0.3831	micro: p 0.6585, r 0.6585, f1 0.6585	weighted_f1:0.6219
dev	acc: 0.5807	macro: p 0.3819, r 0.3374, f1: 0.3385	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5351
test	acc: 0.6123	macro: p 0.3678, r 0.3388, f1: 0.3390	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5742
New best model!
global_step: 1321, epoch: 34, loss: 1.059219
global_step: 1322, epoch: 34, loss: 1.080396
global_step: 1323, epoch: 34, loss: 1.094398
global_step: 1324, epoch: 34, loss: 1.024015
global_step: 1325, epoch: 34, loss: 1.096938
global_step: 1326, epoch: 34, loss: 1.117925
global_step: 1327, epoch: 34, loss: 1.231083
global_step: 1328, epoch: 34, loss: 1.114903
global_step: 1329, epoch: 34, loss: 1.049574
global_step: 1330, epoch: 34, loss: 1.055601
global_step: 1331, epoch: 34, loss: 1.049040
global_step: 1332, epoch: 34, loss: 1.124019
global_step: 1333, epoch: 34, loss: 1.101788
global_step: 1334, epoch: 34, loss: 1.048624
global_step: 1335, epoch: 34, loss: 0.946176
global_step: 1336, epoch: 34, loss: 1.120639
global_step: 1337, epoch: 34, loss: 0.997960
global_step: 1338, epoch: 34, loss: 1.138306
global_step: 1339, epoch: 34, loss: 1.156387
global_step: 1340, epoch: 34, loss: 1.197270
global_step: 1341, epoch: 34, loss: 1.062308
global_step: 1342, epoch: 34, loss: 1.044792
global_step: 1343, epoch: 34, loss: 1.072147
global_step: 1344, epoch: 34, loss: 1.050852
global_step: 1345, epoch: 34, loss: 1.091329
global_step: 1346, epoch: 34, loss: 1.052080
global_step: 1347, epoch: 34, loss: 1.086603
global_step: 1348, epoch: 34, loss: 0.961970
global_step: 1349, epoch: 34, loss: 1.140106
global_step: 1350, epoch: 34, loss: 1.106183
global_step: 1351, epoch: 34, loss: 1.062901
global_step: 1352, epoch: 34, loss: 1.053340
global_step: 1353, epoch: 34, loss: 1.128725
global_step: 1354, epoch: 34, loss: 1.131168
global_step: 1355, epoch: 34, loss: 1.129260
global_step: 1356, epoch: 34, loss: 1.113443
global_step: 1357, epoch: 34, loss: 1.067479
global_step: 1358, epoch: 34, loss: 1.026059
global_step: 1359, epoch: 34, loss: 1.133359
global_step: 1360, epoch: 34, loss: 1.136081
epoch: 34
train	acc: 0.6564	macro: p 0.4307, r 0.3630, f1: 0.3689	micro: p 0.6564, r 0.6564, f1 0.6564	weighted_f1:0.6111
dev	acc: 0.5708	macro: p 0.3695, r 0.3197, f1: 0.3134	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5128
test	acc: 0.6184	macro: p 0.3946, r 0.3279, f1: 0.3285	micro: p 0.6184, r 0.6184, f1 0.6184	weighted_f1:0.5685
global_step: 1361, epoch: 35, loss: 1.037369
global_step: 1362, epoch: 35, loss: 1.068064
global_step: 1363, epoch: 35, loss: 1.100123
global_step: 1364, epoch: 35, loss: 1.050279
global_step: 1365, epoch: 35, loss: 1.056929
global_step: 1366, epoch: 35, loss: 1.146991
global_step: 1367, epoch: 35, loss: 1.111665
global_step: 1368, epoch: 35, loss: 1.058821
global_step: 1369, epoch: 35, loss: 1.089952
global_step: 1370, epoch: 35, loss: 1.075487
global_step: 1371, epoch: 35, loss: 1.130890
global_step: 1372, epoch: 35, loss: 1.037449
global_step: 1373, epoch: 35, loss: 1.098357
global_step: 1374, epoch: 35, loss: 1.099528
global_step: 1375, epoch: 35, loss: 1.110446
global_step: 1376, epoch: 35, loss: 1.087855
global_step: 1377, epoch: 35, loss: 1.182753
global_step: 1378, epoch: 35, loss: 1.106696
global_step: 1379, epoch: 35, loss: 1.076968
global_step: 1380, epoch: 35, loss: 1.195638
global_step: 1381, epoch: 35, loss: 1.082281
global_step: 1382, epoch: 35, loss: 1.008665
global_step: 1383, epoch: 35, loss: 1.042189
global_step: 1384, epoch: 35, loss: 1.055107
global_step: 1385, epoch: 35, loss: 1.026322
global_step: 1386, epoch: 35, loss: 1.017115
global_step: 1387, epoch: 35, loss: 1.041166
global_step: 1388, epoch: 35, loss: 0.945057
global_step: 1389, epoch: 35, loss: 1.132298
global_step: 1390, epoch: 35, loss: 1.059494
global_step: 1391, epoch: 35, loss: 1.010429
global_step: 1392, epoch: 35, loss: 1.125709
global_step: 1393, epoch: 35, loss: 1.004412
global_step: 1394, epoch: 35, loss: 1.068757
global_step: 1395, epoch: 35, loss: 1.044648
global_step: 1396, epoch: 35, loss: 1.095178
global_step: 1397, epoch: 35, loss: 0.953086
global_step: 1398, epoch: 35, loss: 1.111624
global_step: 1399, epoch: 35, loss: 1.121273
global_step: 1400, epoch: 35, loss: 0.816466
epoch: 35
train	acc: 0.6575	macro: p 0.4240, r 0.3656, f1: 0.3710	micro: p 0.6575, r 0.6575, f1 0.6575	weighted_f1:0.6130
dev	acc: 0.5780	macro: p 0.3855, r 0.3303, f1: 0.3249	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5227
test	acc: 0.6088	macro: p 0.3851, r 0.3255, f1: 0.3243	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5608
global_step: 1401, epoch: 36, loss: 0.975335
global_step: 1402, epoch: 36, loss: 1.010212
global_step: 1403, epoch: 36, loss: 1.050195
global_step: 1404, epoch: 36, loss: 1.100837
global_step: 1405, epoch: 36, loss: 1.086581
global_step: 1406, epoch: 36, loss: 1.053381
global_step: 1407, epoch: 36, loss: 0.916610
global_step: 1408, epoch: 36, loss: 1.031528
global_step: 1409, epoch: 36, loss: 1.055137
global_step: 1410, epoch: 36, loss: 1.070442
global_step: 1411, epoch: 36, loss: 1.056428
global_step: 1412, epoch: 36, loss: 1.029678
global_step: 1413, epoch: 36, loss: 1.081338
global_step: 1414, epoch: 36, loss: 1.144789
global_step: 1415, epoch: 36, loss: 0.989573
global_step: 1416, epoch: 36, loss: 0.981786
global_step: 1417, epoch: 36, loss: 1.225567
global_step: 1418, epoch: 36, loss: 1.195180
global_step: 1419, epoch: 36, loss: 1.147051
global_step: 1420, epoch: 36, loss: 1.060111
global_step: 1421, epoch: 36, loss: 1.034575
global_step: 1422, epoch: 36, loss: 1.067100
global_step: 1423, epoch: 36, loss: 1.219126
global_step: 1424, epoch: 36, loss: 1.052293
global_step: 1425, epoch: 36, loss: 1.051298
global_step: 1426, epoch: 36, loss: 1.071050
global_step: 1427, epoch: 36, loss: 0.996908
global_step: 1428, epoch: 36, loss: 1.118341
global_step: 1429, epoch: 36, loss: 1.040160
global_step: 1430, epoch: 36, loss: 1.123158
global_step: 1431, epoch: 36, loss: 1.154096
global_step: 1432, epoch: 36, loss: 1.012505
global_step: 1433, epoch: 36, loss: 0.988205
global_step: 1434, epoch: 36, loss: 1.111799
global_step: 1435, epoch: 36, loss: 0.991009
global_step: 1436, epoch: 36, loss: 1.106024
global_step: 1437, epoch: 36, loss: 1.069087
global_step: 1438, epoch: 36, loss: 1.064788
global_step: 1439, epoch: 36, loss: 1.020057
global_step: 1440, epoch: 36, loss: 0.614691
epoch: 36
train	acc: 0.6439	macro: p 0.4330, r 0.3364, f1: 0.3444	micro: p 0.6439, r 0.6439, f1 0.6439	weighted_f1:0.5878
dev	acc: 0.5591	macro: p 0.3878, r 0.3007, f1: 0.2923	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.4895
test	acc: 0.6134	macro: p 0.3981, r 0.3078, f1: 0.3072	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5512
global_step: 1441, epoch: 37, loss: 1.056018
global_step: 1442, epoch: 37, loss: 1.008282
global_step: 1443, epoch: 37, loss: 1.218231
global_step: 1444, epoch: 37, loss: 1.131416
global_step: 1445, epoch: 37, loss: 1.024942
global_step: 1446, epoch: 37, loss: 1.119889
global_step: 1447, epoch: 37, loss: 1.084053
global_step: 1448, epoch: 37, loss: 1.021816
global_step: 1449, epoch: 37, loss: 0.923508
global_step: 1450, epoch: 37, loss: 0.988294
global_step: 1451, epoch: 37, loss: 1.098248
global_step: 1452, epoch: 37, loss: 1.008688
global_step: 1453, epoch: 37, loss: 1.049341
global_step: 1454, epoch: 37, loss: 1.037125
global_step: 1455, epoch: 37, loss: 1.054940
global_step: 1456, epoch: 37, loss: 1.147942
global_step: 1457, epoch: 37, loss: 1.001117
global_step: 1458, epoch: 37, loss: 1.010562
global_step: 1459, epoch: 37, loss: 1.120022
global_step: 1460, epoch: 37, loss: 1.106860
global_step: 1461, epoch: 37, loss: 1.126765
global_step: 1462, epoch: 37, loss: 1.106940
global_step: 1463, epoch: 37, loss: 0.980008
global_step: 1464, epoch: 37, loss: 1.064750
global_step: 1465, epoch: 37, loss: 0.958336
global_step: 1466, epoch: 37, loss: 1.006634
global_step: 1467, epoch: 37, loss: 1.036174
global_step: 1468, epoch: 37, loss: 0.988381
global_step: 1469, epoch: 37, loss: 1.026127
global_step: 1470, epoch: 37, loss: 0.971005
global_step: 1471, epoch: 37, loss: 1.069159
global_step: 1472, epoch: 37, loss: 0.953188
global_step: 1473, epoch: 37, loss: 1.043867
global_step: 1474, epoch: 37, loss: 1.087332
global_step: 1475, epoch: 37, loss: 1.080093
global_step: 1476, epoch: 37, loss: 1.050338
global_step: 1477, epoch: 37, loss: 0.958231
global_step: 1478, epoch: 37, loss: 1.076772
global_step: 1479, epoch: 37, loss: 1.125378
global_step: 1480, epoch: 37, loss: 1.334789
epoch: 37
train	acc: 0.6699	macro: p 0.4308, r 0.3845, f1: 0.3927	micro: p 0.6699, r 0.6699, f1 0.6699	weighted_f1:0.6313
dev	acc: 0.5816	macro: p 0.3957, r 0.3369, f1: 0.3400	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5341
test	acc: 0.6161	macro: p 0.3718, r 0.3334, f1: 0.3372	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5735
global_step: 1481, epoch: 38, loss: 1.068669
global_step: 1482, epoch: 38, loss: 1.117915
global_step: 1483, epoch: 38, loss: 1.034089
global_step: 1484, epoch: 38, loss: 1.032928
global_step: 1485, epoch: 38, loss: 0.978621
global_step: 1486, epoch: 38, loss: 1.031038
global_step: 1487, epoch: 38, loss: 1.029638
global_step: 1488, epoch: 38, loss: 1.013403
global_step: 1489, epoch: 38, loss: 1.062325
global_step: 1490, epoch: 38, loss: 1.000148
global_step: 1491, epoch: 38, loss: 1.026224
global_step: 1492, epoch: 38, loss: 0.995271
global_step: 1493, epoch: 38, loss: 0.996936
global_step: 1494, epoch: 38, loss: 1.030003
global_step: 1495, epoch: 38, loss: 1.067580
global_step: 1496, epoch: 38, loss: 0.955662
global_step: 1497, epoch: 38, loss: 1.059086
global_step: 1498, epoch: 38, loss: 1.132045
global_step: 1499, epoch: 38, loss: 1.043559
global_step: 1500, epoch: 38, loss: 1.138112
global_step: 1501, epoch: 38, loss: 1.071705
global_step: 1502, epoch: 38, loss: 1.085339
global_step: 1503, epoch: 38, loss: 1.073480
global_step: 1504, epoch: 38, loss: 0.962134
global_step: 1505, epoch: 38, loss: 1.087743
global_step: 1506, epoch: 38, loss: 1.135188
global_step: 1507, epoch: 38, loss: 1.030325
global_step: 1508, epoch: 38, loss: 1.179565
global_step: 1509, epoch: 38, loss: 0.977906
global_step: 1510, epoch: 38, loss: 0.953978
global_step: 1511, epoch: 38, loss: 1.146403
global_step: 1512, epoch: 38, loss: 1.016784
global_step: 1513, epoch: 38, loss: 1.035492
global_step: 1514, epoch: 38, loss: 1.114732
global_step: 1515, epoch: 38, loss: 1.024891
global_step: 1516, epoch: 38, loss: 1.053391
global_step: 1517, epoch: 38, loss: 1.014129
global_step: 1518, epoch: 38, loss: 1.066523
global_step: 1519, epoch: 38, loss: 0.954924
global_step: 1520, epoch: 38, loss: 0.492759
epoch: 38
train	acc: 0.6691	macro: p 0.4323, r 0.3797, f1: 0.3853	micro: p 0.6691, r 0.6691, f1 0.6691	weighted_f1:0.6260
dev	acc: 0.5771	macro: p 0.3780, r 0.3268, f1: 0.3239	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5223
test	acc: 0.6149	macro: p 0.3808, r 0.3294, f1: 0.3297	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5676
global_step: 1521, epoch: 39, loss: 1.013991
global_step: 1522, epoch: 39, loss: 1.116493
global_step: 1523, epoch: 39, loss: 1.111466
global_step: 1524, epoch: 39, loss: 1.079561
global_step: 1525, epoch: 39, loss: 1.064976
global_step: 1526, epoch: 39, loss: 1.117634
global_step: 1527, epoch: 39, loss: 1.027365
global_step: 1528, epoch: 39, loss: 1.113588
global_step: 1529, epoch: 39, loss: 1.087104
global_step: 1530, epoch: 39, loss: 0.956377
global_step: 1531, epoch: 39, loss: 1.060246
global_step: 1532, epoch: 39, loss: 1.083279
global_step: 1533, epoch: 39, loss: 1.082084
global_step: 1534, epoch: 39, loss: 0.981254
global_step: 1535, epoch: 39, loss: 1.057065
global_step: 1536, epoch: 39, loss: 1.010165
global_step: 1537, epoch: 39, loss: 1.091298
global_step: 1538, epoch: 39, loss: 0.976812
global_step: 1539, epoch: 39, loss: 1.010798
global_step: 1540, epoch: 39, loss: 1.028152
global_step: 1541, epoch: 39, loss: 0.960368
global_step: 1542, epoch: 39, loss: 1.045154
global_step: 1543, epoch: 39, loss: 1.163993
global_step: 1544, epoch: 39, loss: 1.005187
global_step: 1545, epoch: 39, loss: 1.062233
global_step: 1546, epoch: 39, loss: 1.058214
global_step: 1547, epoch: 39, loss: 1.050434
global_step: 1548, epoch: 39, loss: 0.997338
global_step: 1549, epoch: 39, loss: 0.943817
global_step: 1550, epoch: 39, loss: 1.058447
global_step: 1551, epoch: 39, loss: 1.056204
global_step: 1552, epoch: 39, loss: 0.973024
global_step: 1553, epoch: 39, loss: 1.035769
global_step: 1554, epoch: 39, loss: 1.145468
global_step: 1555, epoch: 39, loss: 0.967610
global_step: 1556, epoch: 39, loss: 1.002565
global_step: 1557, epoch: 39, loss: 0.974466
global_step: 1558, epoch: 39, loss: 0.979934
global_step: 1559, epoch: 39, loss: 1.116942
global_step: 1560, epoch: 39, loss: 0.385586
epoch: 39
train	acc: 0.6665	macro: p 0.4411, r 0.3697, f1: 0.3783	micro: p 0.6665, r 0.6665, f1 0.6665	weighted_f1:0.6206
dev	acc: 0.5708	macro: p 0.3720, r 0.3185, f1: 0.3126	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5114
test	acc: 0.6157	macro: p 0.3966, r 0.3249, f1: 0.3273	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5648
global_step: 1561, epoch: 40, loss: 1.133652
global_step: 1562, epoch: 40, loss: 1.069185
global_step: 1563, epoch: 40, loss: 0.912787
global_step: 1564, epoch: 40, loss: 1.055948
global_step: 1565, epoch: 40, loss: 1.124837
global_step: 1566, epoch: 40, loss: 0.952188
global_step: 1567, epoch: 40, loss: 1.053868
global_step: 1568, epoch: 40, loss: 0.965049
global_step: 1569, epoch: 40, loss: 0.885750
global_step: 1570, epoch: 40, loss: 1.003604
global_step: 1571, epoch: 40, loss: 0.974478
global_step: 1572, epoch: 40, loss: 1.003837
global_step: 1573, epoch: 40, loss: 0.961129
global_step: 1574, epoch: 40, loss: 1.065871
global_step: 1575, epoch: 40, loss: 1.051520
global_step: 1576, epoch: 40, loss: 1.091240
global_step: 1577, epoch: 40, loss: 0.989419
global_step: 1578, epoch: 40, loss: 1.086606
global_step: 1579, epoch: 40, loss: 1.074174
global_step: 1580, epoch: 40, loss: 1.142631
global_step: 1581, epoch: 40, loss: 0.978307
global_step: 1582, epoch: 40, loss: 0.981954
global_step: 1583, epoch: 40, loss: 1.041503
global_step: 1584, epoch: 40, loss: 0.877051
global_step: 1585, epoch: 40, loss: 0.915717
global_step: 1586, epoch: 40, loss: 1.066185
global_step: 1587, epoch: 40, loss: 1.001990
global_step: 1588, epoch: 40, loss: 1.032407
global_step: 1589, epoch: 40, loss: 1.032715
global_step: 1590, epoch: 40, loss: 1.037337
global_step: 1591, epoch: 40, loss: 1.006595
global_step: 1592, epoch: 40, loss: 1.034196
global_step: 1593, epoch: 40, loss: 1.072647
global_step: 1594, epoch: 40, loss: 1.151332
global_step: 1595, epoch: 40, loss: 1.052753
global_step: 1596, epoch: 40, loss: 1.021049
global_step: 1597, epoch: 40, loss: 0.941381
global_step: 1598, epoch: 40, loss: 1.084037
global_step: 1599, epoch: 40, loss: 1.107003
global_step: 1600, epoch: 40, loss: 2.194945
epoch: 40
train	acc: 0.6778	macro: p 0.4372, r 0.3880, f1: 0.3958	micro: p 0.6778, r 0.6778, f1 0.6778	weighted_f1:0.6368
dev	acc: 0.5789	macro: p 0.3890, r 0.3335, f1: 0.3321	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5273
test	acc: 0.6115	macro: p 0.3666, r 0.3297, f1: 0.3292	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5657
global_step: 1601, epoch: 41, loss: 0.995254
global_step: 1602, epoch: 41, loss: 0.998811
global_step: 1603, epoch: 41, loss: 1.044525
global_step: 1604, epoch: 41, loss: 1.073212
global_step: 1605, epoch: 41, loss: 0.975274
global_step: 1606, epoch: 41, loss: 1.063615
global_step: 1607, epoch: 41, loss: 0.944152
global_step: 1608, epoch: 41, loss: 0.978296
global_step: 1609, epoch: 41, loss: 0.978393
global_step: 1610, epoch: 41, loss: 1.074110
global_step: 1611, epoch: 41, loss: 1.067898
global_step: 1612, epoch: 41, loss: 1.169388
global_step: 1613, epoch: 41, loss: 1.047044
global_step: 1614, epoch: 41, loss: 1.046412
global_step: 1615, epoch: 41, loss: 1.067495
global_step: 1616, epoch: 41, loss: 1.000648
global_step: 1617, epoch: 41, loss: 1.054226
global_step: 1618, epoch: 41, loss: 1.055867
global_step: 1619, epoch: 41, loss: 1.008170
global_step: 1620, epoch: 41, loss: 0.971022
global_step: 1621, epoch: 41, loss: 1.032516
global_step: 1622, epoch: 41, loss: 1.066310
global_step: 1623, epoch: 41, loss: 1.057415
global_step: 1624, epoch: 41, loss: 1.089350
global_step: 1625, epoch: 41, loss: 1.029494
global_step: 1626, epoch: 41, loss: 1.013231
global_step: 1627, epoch: 41, loss: 0.953756
global_step: 1628, epoch: 41, loss: 1.038194
global_step: 1629, epoch: 41, loss: 1.049457
global_step: 1630, epoch: 41, loss: 0.923921
global_step: 1631, epoch: 41, loss: 1.016340
global_step: 1632, epoch: 41, loss: 0.973059
global_step: 1633, epoch: 41, loss: 1.054691
global_step: 1634, epoch: 41, loss: 0.969835
global_step: 1635, epoch: 41, loss: 1.110322
global_step: 1636, epoch: 41, loss: 0.895187
global_step: 1637, epoch: 41, loss: 0.886393
global_step: 1638, epoch: 41, loss: 1.048516
global_step: 1639, epoch: 41, loss: 0.974867
global_step: 1640, epoch: 41, loss: 0.447582
epoch: 41
train	acc: 0.6834	macro: p 0.4406, r 0.3937, f1: 0.3977	micro: p 0.6834, r 0.6834, f1 0.6834	weighted_f1:0.6419
dev	acc: 0.5807	macro: p 0.3905, r 0.3344, f1: 0.3297	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5275
test	acc: 0.6073	macro: p 0.3694, r 0.3295, f1: 0.3264	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5621
global_step: 1641, epoch: 42, loss: 0.984476
global_step: 1642, epoch: 42, loss: 0.952532
global_step: 1643, epoch: 42, loss: 1.029544
global_step: 1644, epoch: 42, loss: 1.083417
global_step: 1645, epoch: 42, loss: 1.107212
global_step: 1646, epoch: 42, loss: 0.940121
global_step: 1647, epoch: 42, loss: 1.089110
global_step: 1648, epoch: 42, loss: 1.038379
global_step: 1649, epoch: 42, loss: 0.975917
global_step: 1650, epoch: 42, loss: 1.052922
global_step: 1651, epoch: 42, loss: 1.013236
global_step: 1652, epoch: 42, loss: 1.010804
global_step: 1653, epoch: 42, loss: 0.886638
global_step: 1654, epoch: 42, loss: 0.872533
global_step: 1655, epoch: 42, loss: 1.082865
global_step: 1656, epoch: 42, loss: 0.937779
global_step: 1657, epoch: 42, loss: 1.011107
global_step: 1658, epoch: 42, loss: 1.017980
global_step: 1659, epoch: 42, loss: 0.918239
global_step: 1660, epoch: 42, loss: 1.102587
global_step: 1661, epoch: 42, loss: 1.162732
global_step: 1662, epoch: 42, loss: 1.012545
global_step: 1663, epoch: 42, loss: 1.035609
global_step: 1664, epoch: 42, loss: 0.986498
global_step: 1665, epoch: 42, loss: 1.026897
global_step: 1666, epoch: 42, loss: 0.945573
global_step: 1667, epoch: 42, loss: 0.986340
global_step: 1668, epoch: 42, loss: 1.012297
global_step: 1669, epoch: 42, loss: 1.089575
global_step: 1670, epoch: 42, loss: 1.020496
global_step: 1671, epoch: 42, loss: 0.969418
global_step: 1672, epoch: 42, loss: 0.995503
global_step: 1673, epoch: 42, loss: 0.959697
global_step: 1674, epoch: 42, loss: 0.986087
global_step: 1675, epoch: 42, loss: 0.968574
global_step: 1676, epoch: 42, loss: 1.129331
global_step: 1677, epoch: 42, loss: 0.883929
global_step: 1678, epoch: 42, loss: 1.091347
global_step: 1679, epoch: 42, loss: 1.021606
global_step: 1680, epoch: 42, loss: 1.190184
epoch: 42
train	acc: 0.6837	macro: p 0.4435, r 0.3953, f1: 0.4053	micro: p 0.6837, r 0.6837, f1 0.6837	weighted_f1:0.6450
dev	acc: 0.5780	macro: p 0.3816, r 0.3328, f1: 0.3337	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5284
test	acc: 0.6134	macro: p 0.3664, r 0.3293, f1: 0.3325	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5691
global_step: 1681, epoch: 43, loss: 0.956183
global_step: 1682, epoch: 43, loss: 0.973600
global_step: 1683, epoch: 43, loss: 0.901236
global_step: 1684, epoch: 43, loss: 0.905311
global_step: 1685, epoch: 43, loss: 1.102877
global_step: 1686, epoch: 43, loss: 1.055194
global_step: 1687, epoch: 43, loss: 1.029117
global_step: 1688, epoch: 43, loss: 0.997828
global_step: 1689, epoch: 43, loss: 0.943160
global_step: 1690, epoch: 43, loss: 0.940615
global_step: 1691, epoch: 43, loss: 0.878458
global_step: 1692, epoch: 43, loss: 0.917064
global_step: 1693, epoch: 43, loss: 1.009167
global_step: 1694, epoch: 43, loss: 0.860631
global_step: 1695, epoch: 43, loss: 0.990837
global_step: 1696, epoch: 43, loss: 1.079121
global_step: 1697, epoch: 43, loss: 1.011994
global_step: 1698, epoch: 43, loss: 1.003135
global_step: 1699, epoch: 43, loss: 0.987818
global_step: 1700, epoch: 43, loss: 1.001214
global_step: 1701, epoch: 43, loss: 1.192751
global_step: 1702, epoch: 43, loss: 0.982648
global_step: 1703, epoch: 43, loss: 1.083141
global_step: 1704, epoch: 43, loss: 0.993884
global_step: 1705, epoch: 43, loss: 1.072626
global_step: 1706, epoch: 43, loss: 0.967518
global_step: 1707, epoch: 43, loss: 0.970443
global_step: 1708, epoch: 43, loss: 0.948842
global_step: 1709, epoch: 43, loss: 1.060286
global_step: 1710, epoch: 43, loss: 1.050775
global_step: 1711, epoch: 43, loss: 0.958568
global_step: 1712, epoch: 43, loss: 0.942724
global_step: 1713, epoch: 43, loss: 1.114756
global_step: 1714, epoch: 43, loss: 0.965073
global_step: 1715, epoch: 43, loss: 0.934123
global_step: 1716, epoch: 43, loss: 1.080031
global_step: 1717, epoch: 43, loss: 1.102855
global_step: 1718, epoch: 43, loss: 0.981505
global_step: 1719, epoch: 43, loss: 1.025323
global_step: 1720, epoch: 43, loss: 0.581499
epoch: 43
train	acc: 0.6696	macro: p 0.4456, r 0.3714, f1: 0.3855	micro: p 0.6696, r 0.6696, f1 0.6696	weighted_f1:0.6230
dev	acc: 0.5726	macro: p 0.3872, r 0.3191, f1: 0.3197	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5134
test	acc: 0.6211	macro: p 0.3976, r 0.3247, f1: 0.3305	micro: p 0.6211, r 0.6211, f1 0.6211	weighted_f1:0.5673
global_step: 1721, epoch: 44, loss: 0.938120
global_step: 1722, epoch: 44, loss: 1.088631
global_step: 1723, epoch: 44, loss: 1.022940
global_step: 1724, epoch: 44, loss: 1.013765
global_step: 1725, epoch: 44, loss: 0.928993
global_step: 1726, epoch: 44, loss: 0.981851
global_step: 1727, epoch: 44, loss: 1.007015
global_step: 1728, epoch: 44, loss: 1.079271
global_step: 1729, epoch: 44, loss: 1.003516
global_step: 1730, epoch: 44, loss: 1.053961
global_step: 1731, epoch: 44, loss: 0.939287
global_step: 1732, epoch: 44, loss: 0.911740
global_step: 1733, epoch: 44, loss: 1.034793
global_step: 1734, epoch: 44, loss: 1.058566
global_step: 1735, epoch: 44, loss: 0.905150
global_step: 1736, epoch: 44, loss: 0.961171
global_step: 1737, epoch: 44, loss: 1.031845
global_step: 1738, epoch: 44, loss: 0.929429
global_step: 1739, epoch: 44, loss: 1.068648
global_step: 1740, epoch: 44, loss: 0.982235
global_step: 1741, epoch: 44, loss: 0.884713
global_step: 1742, epoch: 44, loss: 1.030607
global_step: 1743, epoch: 44, loss: 0.984833
global_step: 1744, epoch: 44, loss: 0.955418
global_step: 1745, epoch: 44, loss: 0.932480
global_step: 1746, epoch: 44, loss: 0.957927
global_step: 1747, epoch: 44, loss: 0.979923
global_step: 1748, epoch: 44, loss: 0.948608
global_step: 1749, epoch: 44, loss: 1.045632
global_step: 1750, epoch: 44, loss: 1.041247
global_step: 1751, epoch: 44, loss: 0.945062
global_step: 1752, epoch: 44, loss: 1.035147
global_step: 1753, epoch: 44, loss: 0.937192
global_step: 1754, epoch: 44, loss: 0.962761
global_step: 1755, epoch: 44, loss: 1.070159
global_step: 1756, epoch: 44, loss: 0.987575
global_step: 1757, epoch: 44, loss: 0.973889
global_step: 1758, epoch: 44, loss: 0.939985
global_step: 1759, epoch: 44, loss: 0.991477
global_step: 1760, epoch: 44, loss: 0.669097
epoch: 44
train	acc: 0.6751	macro: p 0.4481, r 0.3779, f1: 0.3878	micro: p 0.6751, r 0.6751, f1 0.6751	weighted_f1:0.6306
dev	acc: 0.5654	macro: p 0.3823, r 0.3158, f1: 0.3111	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5076
test	acc: 0.6100	macro: p 0.3838, r 0.3213, f1: 0.3223	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5595
global_step: 1761, epoch: 45, loss: 0.922428
global_step: 1762, epoch: 45, loss: 1.136584
global_step: 1763, epoch: 45, loss: 0.916630
global_step: 1764, epoch: 45, loss: 0.888839
global_step: 1765, epoch: 45, loss: 0.916162
global_step: 1766, epoch: 45, loss: 0.927890
global_step: 1767, epoch: 45, loss: 1.037961
global_step: 1768, epoch: 45, loss: 1.054309
global_step: 1769, epoch: 45, loss: 1.050211
global_step: 1770, epoch: 45, loss: 1.142503
global_step: 1771, epoch: 45, loss: 1.067383
global_step: 1772, epoch: 45, loss: 0.941688
global_step: 1773, epoch: 45, loss: 0.817312
global_step: 1774, epoch: 45, loss: 1.052528
global_step: 1775, epoch: 45, loss: 0.929851
global_step: 1776, epoch: 45, loss: 0.948700
global_step: 1777, epoch: 45, loss: 1.023844
global_step: 1778, epoch: 45, loss: 1.014448
global_step: 1779, epoch: 45, loss: 0.993946
global_step: 1780, epoch: 45, loss: 0.933574
global_step: 1781, epoch: 45, loss: 0.859372
global_step: 1782, epoch: 45, loss: 0.876400
global_step: 1783, epoch: 45, loss: 1.066972
global_step: 1784, epoch: 45, loss: 0.953708
global_step: 1785, epoch: 45, loss: 0.873785
global_step: 1786, epoch: 45, loss: 0.919757
global_step: 1787, epoch: 45, loss: 0.962096
global_step: 1788, epoch: 45, loss: 1.043742
global_step: 1789, epoch: 45, loss: 1.027928
global_step: 1790, epoch: 45, loss: 0.864963
global_step: 1791, epoch: 45, loss: 1.054081
global_step: 1792, epoch: 45, loss: 0.937886
global_step: 1793, epoch: 45, loss: 0.848542
global_step: 1794, epoch: 45, loss: 1.041917
global_step: 1795, epoch: 45, loss: 1.062984
global_step: 1796, epoch: 45, loss: 1.033920
global_step: 1797, epoch: 45, loss: 0.962520
global_step: 1798, epoch: 45, loss: 1.049972
global_step: 1799, epoch: 45, loss: 1.075542
global_step: 1800, epoch: 45, loss: 1.634254
epoch: 45
train	acc: 0.7007	macro: p 0.4561, r 0.4202, f1: 0.4258	micro: p 0.7007, r 0.7007, f1 0.7007	weighted_f1:0.6667
dev	acc: 0.5843	macro: p 0.3849, r 0.3413, f1: 0.3420	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5384
test	acc: 0.6184	macro: p 0.3788, r 0.3431, f1: 0.3466	micro: p 0.6184, r 0.6184, f1 0.6184	weighted_f1:0.5803
New best model!
global_step: 1801, epoch: 46, loss: 1.031186
global_step: 1802, epoch: 46, loss: 0.950708
global_step: 1803, epoch: 46, loss: 0.976427
global_step: 1804, epoch: 46, loss: 1.050846
global_step: 1805, epoch: 46, loss: 1.025263
global_step: 1806, epoch: 46, loss: 1.018439
global_step: 1807, epoch: 46, loss: 0.901265
global_step: 1808, epoch: 46, loss: 0.963456
global_step: 1809, epoch: 46, loss: 1.036077
global_step: 1810, epoch: 46, loss: 1.016017
global_step: 1811, epoch: 46, loss: 0.961845
global_step: 1812, epoch: 46, loss: 0.972137
global_step: 1813, epoch: 46, loss: 1.034253
global_step: 1814, epoch: 46, loss: 0.905180
global_step: 1815, epoch: 46, loss: 1.087674
global_step: 1816, epoch: 46, loss: 0.913550
global_step: 1817, epoch: 46, loss: 0.958570
global_step: 1818, epoch: 46, loss: 0.972271
global_step: 1819, epoch: 46, loss: 0.979060
global_step: 1820, epoch: 46, loss: 0.917162
global_step: 1821, epoch: 46, loss: 0.979914
global_step: 1822, epoch: 46, loss: 0.982898
global_step: 1823, epoch: 46, loss: 0.988153
global_step: 1824, epoch: 46, loss: 0.882157
global_step: 1825, epoch: 46, loss: 0.914070
global_step: 1826, epoch: 46, loss: 1.071453
global_step: 1827, epoch: 46, loss: 0.904034
global_step: 1828, epoch: 46, loss: 1.004766
global_step: 1829, epoch: 46, loss: 0.963259
global_step: 1830, epoch: 46, loss: 0.944855
global_step: 1831, epoch: 46, loss: 0.875400
global_step: 1832, epoch: 46, loss: 0.836304
global_step: 1833, epoch: 46, loss: 1.033774
global_step: 1834, epoch: 46, loss: 1.018905
global_step: 1835, epoch: 46, loss: 0.995646
global_step: 1836, epoch: 46, loss: 0.958481
global_step: 1837, epoch: 46, loss: 1.017858
global_step: 1838, epoch: 46, loss: 0.920640
global_step: 1839, epoch: 46, loss: 1.019068
global_step: 1840, epoch: 46, loss: 0.723335
epoch: 46
train	acc: 0.7061	macro: p 0.4619, r 0.4253, f1: 0.4277	micro: p 0.7061, r 0.7061, f1 0.7061	weighted_f1:0.6714
dev	acc: 0.5798	macro: p 0.3822, r 0.3382, f1: 0.3391	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5347
test	acc: 0.6169	macro: p 0.3770, r 0.3426, f1: 0.3438	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5784
global_step: 1841, epoch: 47, loss: 0.895804
global_step: 1842, epoch: 47, loss: 0.989915
global_step: 1843, epoch: 47, loss: 0.851197
global_step: 1844, epoch: 47, loss: 0.972085
global_step: 1845, epoch: 47, loss: 0.953205
global_step: 1846, epoch: 47, loss: 0.865377
global_step: 1847, epoch: 47, loss: 0.906565
global_step: 1848, epoch: 47, loss: 1.007359
global_step: 1849, epoch: 47, loss: 0.944710
global_step: 1850, epoch: 47, loss: 0.968797
global_step: 1851, epoch: 47, loss: 1.031484
global_step: 1852, epoch: 47, loss: 0.958026
global_step: 1853, epoch: 47, loss: 0.909590
global_step: 1854, epoch: 47, loss: 0.996438
global_step: 1855, epoch: 47, loss: 0.950062
global_step: 1856, epoch: 47, loss: 1.036567
global_step: 1857, epoch: 47, loss: 0.875630
global_step: 1858, epoch: 47, loss: 0.933460
global_step: 1859, epoch: 47, loss: 0.926499
global_step: 1860, epoch: 47, loss: 1.043143
global_step: 1861, epoch: 47, loss: 0.816441
global_step: 1862, epoch: 47, loss: 0.991870
global_step: 1863, epoch: 47, loss: 1.013139
global_step: 1864, epoch: 47, loss: 0.944984
global_step: 1865, epoch: 47, loss: 0.863305
global_step: 1866, epoch: 47, loss: 0.905081
global_step: 1867, epoch: 47, loss: 1.008490
global_step: 1868, epoch: 47, loss: 1.007074
global_step: 1869, epoch: 47, loss: 0.956348
global_step: 1870, epoch: 47, loss: 0.989748
global_step: 1871, epoch: 47, loss: 1.010966
global_step: 1872, epoch: 47, loss: 0.953203
global_step: 1873, epoch: 47, loss: 1.093591
global_step: 1874, epoch: 47, loss: 0.955733
global_step: 1875, epoch: 47, loss: 0.863720
global_step: 1876, epoch: 47, loss: 0.976169
global_step: 1877, epoch: 47, loss: 0.941529
global_step: 1878, epoch: 47, loss: 0.959871
global_step: 1879, epoch: 47, loss: 1.048444
global_step: 1880, epoch: 47, loss: 0.992569
epoch: 47
train	acc: 0.7040	macro: p 0.4598, r 0.4149, f1: 0.4202	micro: p 0.7040, r 0.7040, f1 0.7040	weighted_f1:0.6637
dev	acc: 0.5834	macro: p 0.3897, r 0.3372, f1: 0.3343	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5303
test	acc: 0.6111	macro: p 0.3724, r 0.3315, f1: 0.3312	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5660
global_step: 1881, epoch: 48, loss: 0.919935
global_step: 1882, epoch: 48, loss: 0.976315
global_step: 1883, epoch: 48, loss: 0.912600
global_step: 1884, epoch: 48, loss: 1.016004
global_step: 1885, epoch: 48, loss: 0.923440
global_step: 1886, epoch: 48, loss: 0.976777
global_step: 1887, epoch: 48, loss: 0.954345
global_step: 1888, epoch: 48, loss: 1.004706
global_step: 1889, epoch: 48, loss: 1.046828
global_step: 1890, epoch: 48, loss: 0.958084
global_step: 1891, epoch: 48, loss: 1.016093
global_step: 1892, epoch: 48, loss: 0.977970
global_step: 1893, epoch: 48, loss: 1.032457
global_step: 1894, epoch: 48, loss: 0.877570
global_step: 1895, epoch: 48, loss: 0.987018
global_step: 1896, epoch: 48, loss: 0.899781
global_step: 1897, epoch: 48, loss: 0.969186
global_step: 1898, epoch: 48, loss: 0.876358
global_step: 1899, epoch: 48, loss: 0.883417
global_step: 1900, epoch: 48, loss: 0.919650
global_step: 1901, epoch: 48, loss: 0.889587
global_step: 1902, epoch: 48, loss: 0.862704
global_step: 1903, epoch: 48, loss: 0.896553
global_step: 1904, epoch: 48, loss: 0.952689
global_step: 1905, epoch: 48, loss: 0.924503
global_step: 1906, epoch: 48, loss: 0.872208
global_step: 1907, epoch: 48, loss: 1.009114
global_step: 1908, epoch: 48, loss: 0.998622
global_step: 1909, epoch: 48, loss: 0.918351
global_step: 1910, epoch: 48, loss: 0.995598
global_step: 1911, epoch: 48, loss: 0.939474
global_step: 1912, epoch: 48, loss: 1.005845
global_step: 1913, epoch: 48, loss: 0.953797
global_step: 1914, epoch: 48, loss: 0.894506
global_step: 1915, epoch: 48, loss: 0.924563
global_step: 1916, epoch: 48, loss: 0.842226
global_step: 1917, epoch: 48, loss: 0.886410
global_step: 1918, epoch: 48, loss: 0.919042
global_step: 1919, epoch: 48, loss: 1.067793
global_step: 1920, epoch: 48, loss: 0.599131
epoch: 48
train	acc: 0.7052	macro: p 0.4652, r 0.4185, f1: 0.4268	micro: p 0.7052, r 0.7052, f1 0.7052	weighted_f1:0.6682
dev	acc: 0.5807	macro: p 0.3753, r 0.3338, f1: 0.3333	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5308
test	acc: 0.6149	macro: p 0.3726, r 0.3348, f1: 0.3384	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5724
global_step: 1921, epoch: 49, loss: 0.925502
global_step: 1922, epoch: 49, loss: 0.829019
global_step: 1923, epoch: 49, loss: 0.950828
global_step: 1924, epoch: 49, loss: 0.850261
global_step: 1925, epoch: 49, loss: 0.955398
global_step: 1926, epoch: 49, loss: 0.892698
global_step: 1927, epoch: 49, loss: 0.919684
global_step: 1928, epoch: 49, loss: 0.981555
global_step: 1929, epoch: 49, loss: 0.967752
global_step: 1930, epoch: 49, loss: 0.837845
global_step: 1931, epoch: 49, loss: 0.819890
global_step: 1932, epoch: 49, loss: 0.918594
global_step: 1933, epoch: 49, loss: 0.870737
global_step: 1934, epoch: 49, loss: 0.963417
global_step: 1935, epoch: 49, loss: 1.013137
global_step: 1936, epoch: 49, loss: 0.896417
global_step: 1937, epoch: 49, loss: 0.984868
global_step: 1938, epoch: 49, loss: 0.912262
global_step: 1939, epoch: 49, loss: 0.928062
global_step: 1940, epoch: 49, loss: 0.946679
global_step: 1941, epoch: 49, loss: 0.962278
global_step: 1942, epoch: 49, loss: 0.974105
global_step: 1943, epoch: 49, loss: 0.857101
global_step: 1944, epoch: 49, loss: 0.956939
global_step: 1945, epoch: 49, loss: 0.913308
global_step: 1946, epoch: 49, loss: 1.027826
global_step: 1947, epoch: 49, loss: 0.880154
global_step: 1948, epoch: 49, loss: 0.895032
global_step: 1949, epoch: 49, loss: 0.971423
global_step: 1950, epoch: 49, loss: 0.930421
global_step: 1951, epoch: 49, loss: 0.939916
global_step: 1952, epoch: 49, loss: 0.961862
global_step: 1953, epoch: 49, loss: 0.906649
global_step: 1954, epoch: 49, loss: 0.964721
global_step: 1955, epoch: 49, loss: 0.979910
global_step: 1956, epoch: 49, loss: 1.177425
global_step: 1957, epoch: 49, loss: 0.940254
global_step: 1958, epoch: 49, loss: 0.859513
global_step: 1959, epoch: 49, loss: 1.072691
global_step: 1960, epoch: 49, loss: 0.971852
epoch: 49
train	acc: 0.7257	macro: p 0.4683, r 0.4484, f1: 0.4489	micro: p 0.7257, r 0.7257, f1 0.7257	weighted_f1:0.6937
dev	acc: 0.5816	macro: p 0.3717, r 0.3456, f1: 0.3430	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5380
test	acc: 0.6134	macro: p 0.3714, r 0.3443, f1: 0.3443	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5768
global_step: 1961, epoch: 50, loss: 0.982047
global_step: 1962, epoch: 50, loss: 0.981392
global_step: 1963, epoch: 50, loss: 0.821133
global_step: 1964, epoch: 50, loss: 0.952076
global_step: 1965, epoch: 50, loss: 0.929575
global_step: 1966, epoch: 50, loss: 0.947670
global_step: 1967, epoch: 50, loss: 0.913608
global_step: 1968, epoch: 50, loss: 0.984307
global_step: 1969, epoch: 50, loss: 0.926930
global_step: 1970, epoch: 50, loss: 0.905848
global_step: 1971, epoch: 50, loss: 0.920486
global_step: 1972, epoch: 50, loss: 0.859839
global_step: 1973, epoch: 50, loss: 0.853547
global_step: 1974, epoch: 50, loss: 0.905657
global_step: 1975, epoch: 50, loss: 0.832571
global_step: 1976, epoch: 50, loss: 1.015342
global_step: 1977, epoch: 50, loss: 0.833221
global_step: 1978, epoch: 50, loss: 0.940014
global_step: 1979, epoch: 50, loss: 0.956099
global_step: 1980, epoch: 50, loss: 0.979200
global_step: 1981, epoch: 50, loss: 0.989349
global_step: 1982, epoch: 50, loss: 0.999103
global_step: 1983, epoch: 50, loss: 0.981211
global_step: 1984, epoch: 50, loss: 0.888007
global_step: 1985, epoch: 50, loss: 1.008574
global_step: 1986, epoch: 50, loss: 0.872063
global_step: 1987, epoch: 50, loss: 0.921046
global_step: 1988, epoch: 50, loss: 0.955639
global_step: 1989, epoch: 50, loss: 0.854904
global_step: 1990, epoch: 50, loss: 0.882295
global_step: 1991, epoch: 50, loss: 0.952032
global_step: 1992, epoch: 50, loss: 0.951703
global_step: 1993, epoch: 50, loss: 0.968728
global_step: 1994, epoch: 50, loss: 0.842591
global_step: 1995, epoch: 50, loss: 0.933037
global_step: 1996, epoch: 50, loss: 0.920209
global_step: 1997, epoch: 50, loss: 1.000645
global_step: 1998, epoch: 50, loss: 1.000429
global_step: 1999, epoch: 50, loss: 0.939029
global_step: 2000, epoch: 50, loss: 1.581723
epoch: 50
train	acc: 0.7108	macro: p 0.4720, r 0.4193, f1: 0.4275	micro: p 0.7108, r 0.7108, f1 0.7108	weighted_f1:0.6720
dev	acc: 0.5699	macro: p 0.3733, r 0.3229, f1: 0.3180	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5151
test	acc: 0.6092	macro: p 0.3735, r 0.3288, f1: 0.3274	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5632
global_step: 2001, epoch: 51, loss: 0.955814
global_step: 2002, epoch: 51, loss: 0.900629
global_step: 2003, epoch: 51, loss: 0.912791
global_step: 2004, epoch: 51, loss: 0.921614
global_step: 2005, epoch: 51, loss: 0.889206
global_step: 2006, epoch: 51, loss: 1.031182
global_step: 2007, epoch: 51, loss: 0.925868
global_step: 2008, epoch: 51, loss: 0.844166
global_step: 2009, epoch: 51, loss: 1.053094
global_step: 2010, epoch: 51, loss: 0.865280
global_step: 2011, epoch: 51, loss: 0.903889
global_step: 2012, epoch: 51, loss: 0.825425
global_step: 2013, epoch: 51, loss: 0.878771
global_step: 2014, epoch: 51, loss: 0.913478
global_step: 2015, epoch: 51, loss: 1.059841
global_step: 2016, epoch: 51, loss: 0.995329
global_step: 2017, epoch: 51, loss: 0.872363
global_step: 2018, epoch: 51, loss: 0.920827
global_step: 2019, epoch: 51, loss: 0.914214
global_step: 2020, epoch: 51, loss: 0.872875
global_step: 2021, epoch: 51, loss: 0.809538
global_step: 2022, epoch: 51, loss: 0.921291
global_step: 2023, epoch: 51, loss: 0.850411
global_step: 2024, epoch: 51, loss: 0.879373
global_step: 2025, epoch: 51, loss: 0.966283
global_step: 2026, epoch: 51, loss: 0.915131
global_step: 2027, epoch: 51, loss: 0.910103
global_step: 2028, epoch: 51, loss: 0.989222
global_step: 2029, epoch: 51, loss: 0.926939
global_step: 2030, epoch: 51, loss: 0.848868
global_step: 2031, epoch: 51, loss: 0.937077
global_step: 2032, epoch: 51, loss: 0.927150
global_step: 2033, epoch: 51, loss: 0.886229
global_step: 2034, epoch: 51, loss: 0.990067
global_step: 2035, epoch: 51, loss: 0.924799
global_step: 2036, epoch: 51, loss: 0.879649
global_step: 2037, epoch: 51, loss: 0.943730
global_step: 2038, epoch: 51, loss: 0.867093
global_step: 2039, epoch: 51, loss: 1.051137
global_step: 2040, epoch: 51, loss: 1.842000
epoch: 51
train	acc: 0.7337	macro: p 0.4700, r 0.4720, f1: 0.4696	micro: p 0.7337, r 0.7337, f1 0.7337	weighted_f1:0.7092
dev	acc: 0.5807	macro: p 0.3618, r 0.3504, f1: 0.3510	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5446
test	acc: 0.6057	macro: p 0.3532, r 0.3456, f1: 0.3465	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5766
New best model!
global_step: 2041, epoch: 52, loss: 0.934345
global_step: 2042, epoch: 52, loss: 0.920970
global_step: 2043, epoch: 52, loss: 0.842621
global_step: 2044, epoch: 52, loss: 0.906524
global_step: 2045, epoch: 52, loss: 0.870041
global_step: 2046, epoch: 52, loss: 0.836814
global_step: 2047, epoch: 52, loss: 0.874161
global_step: 2048, epoch: 52, loss: 0.945303
global_step: 2049, epoch: 52, loss: 0.905429
global_step: 2050, epoch: 52, loss: 0.926377
global_step: 2051, epoch: 52, loss: 0.939600
global_step: 2052, epoch: 52, loss: 0.868439
global_step: 2053, epoch: 52, loss: 0.927467
global_step: 2054, epoch: 52, loss: 0.991722
global_step: 2055, epoch: 52, loss: 0.969000
global_step: 2056, epoch: 52, loss: 0.930508
global_step: 2057, epoch: 52, loss: 0.993119
global_step: 2058, epoch: 52, loss: 1.089497
global_step: 2059, epoch: 52, loss: 0.885784
global_step: 2060, epoch: 52, loss: 0.869832
global_step: 2061, epoch: 52, loss: 0.987372
global_step: 2062, epoch: 52, loss: 0.905891
global_step: 2063, epoch: 52, loss: 0.851951
global_step: 2064, epoch: 52, loss: 0.913827
global_step: 2065, epoch: 52, loss: 0.799336
global_step: 2066, epoch: 52, loss: 0.969114
global_step: 2067, epoch: 52, loss: 0.972271
global_step: 2068, epoch: 52, loss: 0.936205
global_step: 2069, epoch: 52, loss: 0.980471
global_step: 2070, epoch: 52, loss: 0.823757
global_step: 2071, epoch: 52, loss: 0.861004
global_step: 2072, epoch: 52, loss: 0.917922
global_step: 2073, epoch: 52, loss: 0.884267
global_step: 2074, epoch: 52, loss: 0.985377
global_step: 2075, epoch: 52, loss: 0.817023
global_step: 2076, epoch: 52, loss: 0.893048
global_step: 2077, epoch: 52, loss: 0.868941
global_step: 2078, epoch: 52, loss: 0.884525
global_step: 2079, epoch: 52, loss: 1.002437
global_step: 2080, epoch: 52, loss: 1.114298
epoch: 52
train	acc: 0.7348	macro: p 0.4788, r 0.4664, f1: 0.4651	micro: p 0.7348, r 0.7348, f1 0.7348	weighted_f1:0.7072
dev	acc: 0.5798	macro: p 0.3632, r 0.3475, f1: 0.3462	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5405
test	acc: 0.6092	macro: p 0.3612, r 0.3426, f1: 0.3424	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5758
global_step: 2081, epoch: 53, loss: 0.857537
global_step: 2082, epoch: 53, loss: 0.949948
global_step: 2083, epoch: 53, loss: 0.890172
global_step: 2084, epoch: 53, loss: 0.948042
global_step: 2085, epoch: 53, loss: 0.933672
global_step: 2086, epoch: 53, loss: 0.942695
global_step: 2087, epoch: 53, loss: 0.888766
global_step: 2088, epoch: 53, loss: 0.865738
global_step: 2089, epoch: 53, loss: 0.840515
global_step: 2090, epoch: 53, loss: 0.992712
global_step: 2091, epoch: 53, loss: 0.924804
global_step: 2092, epoch: 53, loss: 0.930327
global_step: 2093, epoch: 53, loss: 0.883870
global_step: 2094, epoch: 53, loss: 0.939451
global_step: 2095, epoch: 53, loss: 0.940010
global_step: 2096, epoch: 53, loss: 1.012354
global_step: 2097, epoch: 53, loss: 0.814729
global_step: 2098, epoch: 53, loss: 0.863005
global_step: 2099, epoch: 53, loss: 0.864210
global_step: 2100, epoch: 53, loss: 0.880836
global_step: 2101, epoch: 53, loss: 0.770724
global_step: 2102, epoch: 53, loss: 0.928246
global_step: 2103, epoch: 53, loss: 0.973855
global_step: 2104, epoch: 53, loss: 0.926939
global_step: 2105, epoch: 53, loss: 0.838215
global_step: 2106, epoch: 53, loss: 0.800771
global_step: 2107, epoch: 53, loss: 0.914429
global_step: 2108, epoch: 53, loss: 0.968488
global_step: 2109, epoch: 53, loss: 0.887129
global_step: 2110, epoch: 53, loss: 0.872887
global_step: 2111, epoch: 53, loss: 0.851374
global_step: 2112, epoch: 53, loss: 0.992525
global_step: 2113, epoch: 53, loss: 1.024103
global_step: 2114, epoch: 53, loss: 0.863033
global_step: 2115, epoch: 53, loss: 1.005986
global_step: 2116, epoch: 53, loss: 0.909898
global_step: 2117, epoch: 53, loss: 1.004922
global_step: 2118, epoch: 53, loss: 0.807238
global_step: 2119, epoch: 53, loss: 0.842731
global_step: 2120, epoch: 53, loss: 1.830543
epoch: 53
train	acc: 0.7487	macro: p 0.4788, r 0.4913, f1: 0.4833	micro: p 0.7487, r 0.7487, f1 0.7487	weighted_f1:0.7256
dev	acc: 0.5735	macro: p 0.3522, r 0.3518, f1: 0.3470	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5409
test	acc: 0.6073	macro: p 0.3571, r 0.3590, f1: 0.3542	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5821
global_step: 2121, epoch: 54, loss: 0.961433
global_step: 2122, epoch: 54, loss: 0.844982
global_step: 2123, epoch: 54, loss: 0.833289
global_step: 2124, epoch: 54, loss: 0.952630
global_step: 2125, epoch: 54, loss: 0.969977
global_step: 2126, epoch: 54, loss: 0.850998
global_step: 2127, epoch: 54, loss: 0.892164
global_step: 2128, epoch: 54, loss: 0.925915
global_step: 2129, epoch: 54, loss: 0.810822
global_step: 2130, epoch: 54, loss: 0.764373
global_step: 2131, epoch: 54, loss: 0.965123
global_step: 2132, epoch: 54, loss: 0.813099
global_step: 2133, epoch: 54, loss: 0.875737
global_step: 2134, epoch: 54, loss: 0.946341
global_step: 2135, epoch: 54, loss: 0.900345
global_step: 2136, epoch: 54, loss: 0.949817
global_step: 2137, epoch: 54, loss: 0.949344
global_step: 2138, epoch: 54, loss: 0.965684
global_step: 2139, epoch: 54, loss: 0.875813
global_step: 2140, epoch: 54, loss: 0.830046
global_step: 2141, epoch: 54, loss: 0.958336
global_step: 2142, epoch: 54, loss: 0.827475
global_step: 2143, epoch: 54, loss: 0.901722
global_step: 2144, epoch: 54, loss: 0.856402
global_step: 2145, epoch: 54, loss: 0.892853
global_step: 2146, epoch: 54, loss: 0.910897
global_step: 2147, epoch: 54, loss: 0.868763
global_step: 2148, epoch: 54, loss: 0.872551
global_step: 2149, epoch: 54, loss: 0.906447
global_step: 2150, epoch: 54, loss: 0.928113
global_step: 2151, epoch: 54, loss: 0.950442
global_step: 2152, epoch: 54, loss: 0.940775
global_step: 2153, epoch: 54, loss: 0.857360
global_step: 2154, epoch: 54, loss: 0.850557
global_step: 2155, epoch: 54, loss: 0.807505
global_step: 2156, epoch: 54, loss: 0.839475
global_step: 2157, epoch: 54, loss: 0.890599
global_step: 2158, epoch: 54, loss: 0.927815
global_step: 2159, epoch: 54, loss: 0.915542
global_step: 2160, epoch: 54, loss: 0.537180
epoch: 54
train	acc: 0.7415	macro: p 0.4864, r 0.4642, f1: 0.4660	micro: p 0.7415, r 0.7415, f1 0.7415	weighted_f1:0.7100
dev	acc: 0.5681	macro: p 0.3619, r 0.3364, f1: 0.3292	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5228
test	acc: 0.6092	macro: p 0.3714, r 0.3435, f1: 0.3383	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5705
global_step: 2161, epoch: 55, loss: 0.840254
global_step: 2162, epoch: 55, loss: 0.926002
global_step: 2163, epoch: 55, loss: 0.809245
global_step: 2164, epoch: 55, loss: 0.801914
global_step: 2165, epoch: 55, loss: 0.861456
global_step: 2166, epoch: 55, loss: 0.974519
global_step: 2167, epoch: 55, loss: 0.881267
global_step: 2168, epoch: 55, loss: 0.813176
global_step: 2169, epoch: 55, loss: 0.817567
global_step: 2170, epoch: 55, loss: 0.864916
global_step: 2171, epoch: 55, loss: 0.989164
global_step: 2172, epoch: 55, loss: 0.944952
global_step: 2173, epoch: 55, loss: 0.847794
global_step: 2174, epoch: 55, loss: 0.865756
global_step: 2175, epoch: 55, loss: 0.892698
global_step: 2176, epoch: 55, loss: 0.898246
global_step: 2177, epoch: 55, loss: 0.812795
global_step: 2178, epoch: 55, loss: 0.995647
global_step: 2179, epoch: 55, loss: 0.823726
global_step: 2180, epoch: 55, loss: 0.932521
global_step: 2181, epoch: 55, loss: 0.930907
global_step: 2182, epoch: 55, loss: 0.851701
global_step: 2183, epoch: 55, loss: 0.888508
global_step: 2184, epoch: 55, loss: 0.916447
global_step: 2185, epoch: 55, loss: 0.911855
global_step: 2186, epoch: 55, loss: 0.886213
global_step: 2187, epoch: 55, loss: 0.921133
global_step: 2188, epoch: 55, loss: 0.905152
global_step: 2189, epoch: 55, loss: 0.793491
global_step: 2190, epoch: 55, loss: 0.941128
global_step: 2191, epoch: 55, loss: 0.909843
global_step: 2192, epoch: 55, loss: 0.886298
global_step: 2193, epoch: 55, loss: 0.907498
global_step: 2194, epoch: 55, loss: 0.801482
global_step: 2195, epoch: 55, loss: 0.770344
global_step: 2196, epoch: 55, loss: 0.910810
global_step: 2197, epoch: 55, loss: 0.839302
global_step: 2198, epoch: 55, loss: 0.983181
global_step: 2199, epoch: 55, loss: 0.961589
global_step: 2200, epoch: 55, loss: 0.711521
epoch: 55
train	acc: 0.7274	macro: p 0.4917, r 0.4358, f1: 0.4467	micro: p 0.7274, r 0.7274, f1 0.7274	weighted_f1:0.6894
dev	acc: 0.5816	macro: p 0.3929, r 0.3320, f1: 0.3313	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5270
test	acc: 0.6123	macro: p 0.3772, r 0.3257, f1: 0.3273	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5634
global_step: 2201, epoch: 56, loss: 0.831154
global_step: 2202, epoch: 56, loss: 0.994977
global_step: 2203, epoch: 56, loss: 0.939089
global_step: 2204, epoch: 56, loss: 0.946383
global_step: 2205, epoch: 56, loss: 1.021799
global_step: 2206, epoch: 56, loss: 0.807033
global_step: 2207, epoch: 56, loss: 0.829746
global_step: 2208, epoch: 56, loss: 0.843681
global_step: 2209, epoch: 56, loss: 0.975297
global_step: 2210, epoch: 56, loss: 0.829523
global_step: 2211, epoch: 56, loss: 0.936127
global_step: 2212, epoch: 56, loss: 0.978240
global_step: 2213, epoch: 56, loss: 0.842274
global_step: 2214, epoch: 56, loss: 0.832786
global_step: 2215, epoch: 56, loss: 0.830268
global_step: 2216, epoch: 56, loss: 0.909591
global_step: 2217, epoch: 56, loss: 0.935618
global_step: 2218, epoch: 56, loss: 0.956700
global_step: 2219, epoch: 56, loss: 0.846329
global_step: 2220, epoch: 56, loss: 0.909149
global_step: 2221, epoch: 56, loss: 0.799195
global_step: 2222, epoch: 56, loss: 0.898444
global_step: 2223, epoch: 56, loss: 0.847415
global_step: 2224, epoch: 56, loss: 0.704682
global_step: 2225, epoch: 56, loss: 0.938411
global_step: 2226, epoch: 56, loss: 0.784430
global_step: 2227, epoch: 56, loss: 0.783448
global_step: 2228, epoch: 56, loss: 0.867543
global_step: 2229, epoch: 56, loss: 0.876969
global_step: 2230, epoch: 56, loss: 0.934778
global_step: 2231, epoch: 56, loss: 0.956838
global_step: 2232, epoch: 56, loss: 0.905916
global_step: 2233, epoch: 56, loss: 0.820762
global_step: 2234, epoch: 56, loss: 0.886844
global_step: 2235, epoch: 56, loss: 0.883831
global_step: 2236, epoch: 56, loss: 0.894585
global_step: 2237, epoch: 56, loss: 0.782876
global_step: 2238, epoch: 56, loss: 0.932579
global_step: 2239, epoch: 56, loss: 0.987857
global_step: 2240, epoch: 56, loss: 0.728104
epoch: 56
train	acc: 0.7569	macro: p 0.4941, r 0.4857, f1: 0.4855	micro: p 0.7569, r 0.7569, f1 0.7569	weighted_f1:0.7288
dev	acc: 0.5771	macro: p 0.3684, r 0.3461, f1: 0.3443	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5365
test	acc: 0.6134	macro: p 0.3681, r 0.3478, f1: 0.3464	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5788
global_step: 2241, epoch: 57, loss: 0.793757
global_step: 2242, epoch: 57, loss: 0.779932
global_step: 2243, epoch: 57, loss: 0.873994
global_step: 2244, epoch: 57, loss: 0.917819
global_step: 2245, epoch: 57, loss: 1.019532
global_step: 2246, epoch: 57, loss: 0.906393
global_step: 2247, epoch: 57, loss: 0.854717
global_step: 2248, epoch: 57, loss: 0.856390
global_step: 2249, epoch: 57, loss: 0.944878
global_step: 2250, epoch: 57, loss: 0.832720
global_step: 2251, epoch: 57, loss: 0.845015
global_step: 2252, epoch: 57, loss: 0.838824
global_step: 2253, epoch: 57, loss: 0.843876
global_step: 2254, epoch: 57, loss: 0.876709
global_step: 2255, epoch: 57, loss: 0.807290
global_step: 2256, epoch: 57, loss: 0.832507
global_step: 2257, epoch: 57, loss: 0.830889
global_step: 2258, epoch: 57, loss: 0.874108
global_step: 2259, epoch: 57, loss: 0.834509
global_step: 2260, epoch: 57, loss: 0.917314
global_step: 2261, epoch: 57, loss: 0.850658
global_step: 2262, epoch: 57, loss: 0.803176
global_step: 2263, epoch: 57, loss: 0.892233
global_step: 2264, epoch: 57, loss: 0.964616
global_step: 2265, epoch: 57, loss: 0.808942
global_step: 2266, epoch: 57, loss: 0.871545
global_step: 2267, epoch: 57, loss: 0.953074
global_step: 2268, epoch: 57, loss: 0.864730
global_step: 2269, epoch: 57, loss: 0.878930
global_step: 2270, epoch: 57, loss: 0.973021
global_step: 2271, epoch: 57, loss: 0.937795
global_step: 2272, epoch: 57, loss: 0.808647
global_step: 2273, epoch: 57, loss: 0.944064
global_step: 2274, epoch: 57, loss: 0.867596
global_step: 2275, epoch: 57, loss: 0.897440
global_step: 2276, epoch: 57, loss: 0.859566
global_step: 2277, epoch: 57, loss: 0.854859
global_step: 2278, epoch: 57, loss: 0.783736
global_step: 2279, epoch: 57, loss: 0.764908
global_step: 2280, epoch: 57, loss: 1.058372
epoch: 57
train	acc: 0.7609	macro: p 0.4937, r 0.4953, f1: 0.4892	micro: p 0.7609, r 0.7609, f1 0.7609	weighted_f1:0.7348
dev	acc: 0.5546	macro: p 0.3514, r 0.3403, f1: 0.3299	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5191
test	acc: 0.5958	macro: p 0.3559, r 0.3476, f1: 0.3379	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5653
global_step: 2281, epoch: 58, loss: 0.941279
global_step: 2282, epoch: 58, loss: 0.778302
global_step: 2283, epoch: 58, loss: 0.923910
global_step: 2284, epoch: 58, loss: 0.881613
global_step: 2285, epoch: 58, loss: 0.740749
global_step: 2286, epoch: 58, loss: 0.916050
global_step: 2287, epoch: 58, loss: 0.961769
global_step: 2288, epoch: 58, loss: 0.858046
global_step: 2289, epoch: 58, loss: 0.851266
global_step: 2290, epoch: 58, loss: 0.886872
global_step: 2291, epoch: 58, loss: 0.861195
global_step: 2292, epoch: 58, loss: 0.758499
global_step: 2293, epoch: 58, loss: 0.769487
global_step: 2294, epoch: 58, loss: 0.855940
global_step: 2295, epoch: 58, loss: 0.879338
global_step: 2296, epoch: 58, loss: 0.838193
global_step: 2297, epoch: 58, loss: 0.840990
global_step: 2298, epoch: 58, loss: 0.864975
global_step: 2299, epoch: 58, loss: 0.835251
global_step: 2300, epoch: 58, loss: 0.831995
global_step: 2301, epoch: 58, loss: 0.864095
global_step: 2302, epoch: 58, loss: 0.887896
global_step: 2303, epoch: 58, loss: 0.920016
global_step: 2304, epoch: 58, loss: 0.910533
global_step: 2305, epoch: 58, loss: 0.892212
global_step: 2306, epoch: 58, loss: 0.775722
global_step: 2307, epoch: 58, loss: 0.825454
global_step: 2308, epoch: 58, loss: 0.823794
global_step: 2309, epoch: 58, loss: 1.005946
global_step: 2310, epoch: 58, loss: 0.929206
global_step: 2311, epoch: 58, loss: 0.845407
global_step: 2312, epoch: 58, loss: 0.820581
global_step: 2313, epoch: 58, loss: 0.812560
global_step: 2314, epoch: 58, loss: 0.823147
global_step: 2315, epoch: 58, loss: 0.833601
global_step: 2316, epoch: 58, loss: 0.892606
global_step: 2317, epoch: 58, loss: 0.880419
global_step: 2318, epoch: 58, loss: 0.855777
global_step: 2319, epoch: 58, loss: 0.813983
global_step: 2320, epoch: 58, loss: 0.233438
epoch: 58
train	acc: 0.7311	macro: p 0.5020, r 0.4440, f1: 0.4569	micro: p 0.7311, r 0.7311, f1 0.7311	weighted_f1:0.6956
dev	acc: 0.5780	macro: p 0.3960, r 0.3278, f1: 0.3331	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5260
test	acc: 0.6149	macro: p 0.3767, r 0.3262, f1: 0.3338	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5684
global_step: 2321, epoch: 59, loss: 0.845932
global_step: 2322, epoch: 59, loss: 0.843802
global_step: 2323, epoch: 59, loss: 0.879559
global_step: 2324, epoch: 59, loss: 0.767206
global_step: 2325, epoch: 59, loss: 0.866160
global_step: 2326, epoch: 59, loss: 0.765051
global_step: 2327, epoch: 59, loss: 0.947591
global_step: 2328, epoch: 59, loss: 0.835747
global_step: 2329, epoch: 59, loss: 0.906313
global_step: 2330, epoch: 59, loss: 0.825253
global_step: 2331, epoch: 59, loss: 0.859320
global_step: 2332, epoch: 59, loss: 0.879476
global_step: 2333, epoch: 59, loss: 0.894009
global_step: 2334, epoch: 59, loss: 0.780420
global_step: 2335, epoch: 59, loss: 0.958515
global_step: 2336, epoch: 59, loss: 0.926821
global_step: 2337, epoch: 59, loss: 0.831036
global_step: 2338, epoch: 59, loss: 0.869413
global_step: 2339, epoch: 59, loss: 0.848624
global_step: 2340, epoch: 59, loss: 0.789510
global_step: 2341, epoch: 59, loss: 0.814957
global_step: 2342, epoch: 59, loss: 0.925976
global_step: 2343, epoch: 59, loss: 0.916647
global_step: 2344, epoch: 59, loss: 0.846780
global_step: 2345, epoch: 59, loss: 0.767011
global_step: 2346, epoch: 59, loss: 0.909139
global_step: 2347, epoch: 59, loss: 0.790759
global_step: 2348, epoch: 59, loss: 0.877262
global_step: 2349, epoch: 59, loss: 0.751585
global_step: 2350, epoch: 59, loss: 0.933287
global_step: 2351, epoch: 59, loss: 0.845580
global_step: 2352, epoch: 59, loss: 0.822865
global_step: 2353, epoch: 59, loss: 0.825163
global_step: 2354, epoch: 59, loss: 0.927554
global_step: 2355, epoch: 59, loss: 0.828548
global_step: 2356, epoch: 59, loss: 0.744523
global_step: 2357, epoch: 59, loss: 0.913241
global_step: 2358, epoch: 59, loss: 0.802569
global_step: 2359, epoch: 59, loss: 0.801248
global_step: 2360, epoch: 59, loss: 1.197364
epoch: 59
train	acc: 0.7648	macro: p 0.5039, r 0.4924, f1: 0.4928	micro: p 0.7648, r 0.7648, f1 0.7648	weighted_f1:0.7352
dev	acc: 0.5915	macro: p 0.3791, r 0.3530, f1: 0.3516	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5467
test	acc: 0.6115	macro: p 0.3629, r 0.3418, f1: 0.3414	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5747
New best model!
global_step: 2361, epoch: 60, loss: 0.917858
global_step: 2362, epoch: 60, loss: 0.827404
global_step: 2363, epoch: 60, loss: 0.811310
global_step: 2364, epoch: 60, loss: 0.812705
global_step: 2365, epoch: 60, loss: 0.914871
global_step: 2366, epoch: 60, loss: 0.900621
global_step: 2367, epoch: 60, loss: 0.845309
global_step: 2368, epoch: 60, loss: 0.783607
global_step: 2369, epoch: 60, loss: 0.875940
global_step: 2370, epoch: 60, loss: 0.867555
global_step: 2371, epoch: 60, loss: 0.735259
global_step: 2372, epoch: 60, loss: 0.945355
global_step: 2373, epoch: 60, loss: 0.745695
global_step: 2374, epoch: 60, loss: 0.770457
global_step: 2375, epoch: 60, loss: 0.746616
global_step: 2376, epoch: 60, loss: 0.735049
global_step: 2377, epoch: 60, loss: 0.876497
global_step: 2378, epoch: 60, loss: 0.872680
global_step: 2379, epoch: 60, loss: 0.832717
global_step: 2380, epoch: 60, loss: 0.933629
global_step: 2381, epoch: 60, loss: 0.851595
global_step: 2382, epoch: 60, loss: 0.908172
global_step: 2383, epoch: 60, loss: 0.766625
global_step: 2384, epoch: 60, loss: 0.837773
global_step: 2385, epoch: 60, loss: 0.857770
global_step: 2386, epoch: 60, loss: 0.787354
global_step: 2387, epoch: 60, loss: 0.885822
global_step: 2388, epoch: 60, loss: 0.878322
global_step: 2389, epoch: 60, loss: 0.763130
global_step: 2390, epoch: 60, loss: 0.889364
global_step: 2391, epoch: 60, loss: 0.945523
global_step: 2392, epoch: 60, loss: 0.859360
global_step: 2393, epoch: 60, loss: 0.891851
global_step: 2394, epoch: 60, loss: 0.742699
global_step: 2395, epoch: 60, loss: 0.840760
global_step: 2396, epoch: 60, loss: 0.763748
global_step: 2397, epoch: 60, loss: 0.835137
global_step: 2398, epoch: 60, loss: 0.909386
global_step: 2399, epoch: 60, loss: 0.802398
global_step: 2400, epoch: 60, loss: 0.913693
epoch: 60
train	acc: 0.7462	macro: p 0.5073, r 0.4612, f1: 0.4737	micro: p 0.7462, r 0.7462, f1 0.7462	weighted_f1:0.7122
dev	acc: 0.5744	macro: p 0.3801, r 0.3256, f1: 0.3267	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5209
test	acc: 0.6111	macro: p 0.3728, r 0.3260, f1: 0.3301	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5639
global_step: 2401, epoch: 61, loss: 0.796920
global_step: 2402, epoch: 61, loss: 0.750441
global_step: 2403, epoch: 61, loss: 0.914209
global_step: 2404, epoch: 61, loss: 0.754112
global_step: 2405, epoch: 61, loss: 0.765370
global_step: 2406, epoch: 61, loss: 0.800818
global_step: 2407, epoch: 61, loss: 0.951734
global_step: 2408, epoch: 61, loss: 0.637656
global_step: 2409, epoch: 61, loss: 0.854278
global_step: 2410, epoch: 61, loss: 0.883180
global_step: 2411, epoch: 61, loss: 0.867673
global_step: 2412, epoch: 61, loss: 0.816221
global_step: 2413, epoch: 61, loss: 0.883743
global_step: 2414, epoch: 61, loss: 0.902744
global_step: 2415, epoch: 61, loss: 0.834030
global_step: 2416, epoch: 61, loss: 0.756289
global_step: 2417, epoch: 61, loss: 0.833386
global_step: 2418, epoch: 61, loss: 0.803787
global_step: 2419, epoch: 61, loss: 0.853273
global_step: 2420, epoch: 61, loss: 0.901173
global_step: 2421, epoch: 61, loss: 0.778915
global_step: 2422, epoch: 61, loss: 0.859278
global_step: 2423, epoch: 61, loss: 0.862903
global_step: 2424, epoch: 61, loss: 0.844535
global_step: 2425, epoch: 61, loss: 0.822564
global_step: 2426, epoch: 61, loss: 0.883660
global_step: 2427, epoch: 61, loss: 0.823394
global_step: 2428, epoch: 61, loss: 0.855771
global_step: 2429, epoch: 61, loss: 0.783683
global_step: 2430, epoch: 61, loss: 0.835793
global_step: 2431, epoch: 61, loss: 0.830995
global_step: 2432, epoch: 61, loss: 0.787269
global_step: 2433, epoch: 61, loss: 0.826992
global_step: 2434, epoch: 61, loss: 1.018195
global_step: 2435, epoch: 61, loss: 0.744542
global_step: 2436, epoch: 61, loss: 0.878637
global_step: 2437, epoch: 61, loss: 0.794999
global_step: 2438, epoch: 61, loss: 0.959159
global_step: 2439, epoch: 61, loss: 0.925600
global_step: 2440, epoch: 61, loss: 1.032222
epoch: 61
train	acc: 0.7582	macro: p 0.5129, r 0.4790, f1: 0.4878	micro: p 0.7582, r 0.7582, f1 0.7582	weighted_f1:0.7271
dev	acc: 0.5852	macro: p 0.3876, r 0.3386, f1: 0.3408	micro: p 0.5852, r 0.5852, f1 0.5852	weighted_f1:0.5355
test	acc: 0.6126	macro: p 0.3717, r 0.3318, f1: 0.3372	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5702
global_step: 2441, epoch: 62, loss: 0.770354
global_step: 2442, epoch: 62, loss: 0.860684
global_step: 2443, epoch: 62, loss: 0.792585
global_step: 2444, epoch: 62, loss: 0.853749
global_step: 2445, epoch: 62, loss: 0.962495
global_step: 2446, epoch: 62, loss: 0.783323
global_step: 2447, epoch: 62, loss: 0.800307
global_step: 2448, epoch: 62, loss: 0.886542
global_step: 2449, epoch: 62, loss: 0.865352
global_step: 2450, epoch: 62, loss: 0.881050
global_step: 2451, epoch: 62, loss: 0.898665
global_step: 2452, epoch: 62, loss: 0.814023
global_step: 2453, epoch: 62, loss: 0.807713
global_step: 2454, epoch: 62, loss: 0.786538
global_step: 2455, epoch: 62, loss: 0.885090
global_step: 2456, epoch: 62, loss: 0.748756
global_step: 2457, epoch: 62, loss: 0.850156
global_step: 2458, epoch: 62, loss: 0.808441
global_step: 2459, epoch: 62, loss: 0.858814
global_step: 2460, epoch: 62, loss: 0.772204
global_step: 2461, epoch: 62, loss: 0.874887
global_step: 2462, epoch: 62, loss: 0.769522
global_step: 2463, epoch: 62, loss: 0.857115
global_step: 2464, epoch: 62, loss: 0.735079
global_step: 2465, epoch: 62, loss: 0.835433
global_step: 2466, epoch: 62, loss: 0.894576
global_step: 2467, epoch: 62, loss: 0.895375
global_step: 2468, epoch: 62, loss: 0.775685
global_step: 2469, epoch: 62, loss: 0.761978
global_step: 2470, epoch: 62, loss: 0.844047
global_step: 2471, epoch: 62, loss: 0.849266
global_step: 2472, epoch: 62, loss: 0.863274
global_step: 2473, epoch: 62, loss: 0.716344
global_step: 2474, epoch: 62, loss: 0.873540
global_step: 2475, epoch: 62, loss: 0.702203
global_step: 2476, epoch: 62, loss: 0.789122
global_step: 2477, epoch: 62, loss: 0.772614
global_step: 2478, epoch: 62, loss: 0.758570
global_step: 2479, epoch: 62, loss: 0.748435
global_step: 2480, epoch: 62, loss: 0.799842
epoch: 62
train	acc: 0.7781	macro: p 0.5200, r 0.5106, f1: 0.5088	micro: p 0.7781, r 0.7781, f1 0.7781	weighted_f1:0.7517
dev	acc: 0.5807	macro: p 0.3705, r 0.3480, f1: 0.3495	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5417
test	acc: 0.6172	macro: p 0.3671, r 0.3487, f1: 0.3493	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5830
global_step: 2481, epoch: 63, loss: 0.911181
global_step: 2482, epoch: 63, loss: 0.804564
global_step: 2483, epoch: 63, loss: 0.850475
global_step: 2484, epoch: 63, loss: 0.772483
global_step: 2485, epoch: 63, loss: 0.718574
global_step: 2486, epoch: 63, loss: 0.804558
global_step: 2487, epoch: 63, loss: 0.887610
global_step: 2488, epoch: 63, loss: 0.787871
global_step: 2489, epoch: 63, loss: 0.725992
global_step: 2490, epoch: 63, loss: 0.785945
global_step: 2491, epoch: 63, loss: 0.754034
global_step: 2492, epoch: 63, loss: 0.828207
global_step: 2493, epoch: 63, loss: 0.842474
global_step: 2494, epoch: 63, loss: 0.853176
global_step: 2495, epoch: 63, loss: 0.852016
global_step: 2496, epoch: 63, loss: 0.805881
global_step: 2497, epoch: 63, loss: 0.873532
global_step: 2498, epoch: 63, loss: 0.861985
global_step: 2499, epoch: 63, loss: 0.767669
global_step: 2500, epoch: 63, loss: 0.834154
global_step: 2501, epoch: 63, loss: 0.860504
global_step: 2502, epoch: 63, loss: 0.828688
global_step: 2503, epoch: 63, loss: 0.714972
global_step: 2504, epoch: 63, loss: 0.897986
global_step: 2505, epoch: 63, loss: 0.794858
global_step: 2506, epoch: 63, loss: 0.897776
global_step: 2507, epoch: 63, loss: 0.690371
global_step: 2508, epoch: 63, loss: 0.849146
global_step: 2509, epoch: 63, loss: 0.763477
global_step: 2510, epoch: 63, loss: 0.733476
global_step: 2511, epoch: 63, loss: 0.796223
global_step: 2512, epoch: 63, loss: 0.689928
global_step: 2513, epoch: 63, loss: 0.739571
global_step: 2514, epoch: 63, loss: 0.838772
global_step: 2515, epoch: 63, loss: 0.960415
global_step: 2516, epoch: 63, loss: 0.913724
global_step: 2517, epoch: 63, loss: 0.788055
global_step: 2518, epoch: 63, loss: 0.799834
global_step: 2519, epoch: 63, loss: 0.796035
global_step: 2520, epoch: 63, loss: 0.686487
epoch: 63
train	acc: 0.7892	macro: p 0.5185, r 0.5275, f1: 0.5207	micro: p 0.7892, r 0.7892, f1 0.7892	weighted_f1:0.7649
dev	acc: 0.5762	macro: p 0.3626, r 0.3522, f1: 0.3502	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5408
test	acc: 0.6138	macro: p 0.3636, r 0.3559, f1: 0.3549	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5849
global_step: 2521, epoch: 64, loss: 0.822455
global_step: 2522, epoch: 64, loss: 0.886877
global_step: 2523, epoch: 64, loss: 0.864924
global_step: 2524, epoch: 64, loss: 0.798434
global_step: 2525, epoch: 64, loss: 0.803160
global_step: 2526, epoch: 64, loss: 0.759971
global_step: 2527, epoch: 64, loss: 0.917505
global_step: 2528, epoch: 64, loss: 0.794714
global_step: 2529, epoch: 64, loss: 0.845613
global_step: 2530, epoch: 64, loss: 0.716274
global_step: 2531, epoch: 64, loss: 0.780833
global_step: 2532, epoch: 64, loss: 0.680528
global_step: 2533, epoch: 64, loss: 0.726873
global_step: 2534, epoch: 64, loss: 0.731166
global_step: 2535, epoch: 64, loss: 0.694925
global_step: 2536, epoch: 64, loss: 0.771910
global_step: 2537, epoch: 64, loss: 0.828842
global_step: 2538, epoch: 64, loss: 0.886090
global_step: 2539, epoch: 64, loss: 0.809187
global_step: 2540, epoch: 64, loss: 0.737384
global_step: 2541, epoch: 64, loss: 0.920084
global_step: 2542, epoch: 64, loss: 0.769460
global_step: 2543, epoch: 64, loss: 0.838331
global_step: 2544, epoch: 64, loss: 0.766611
global_step: 2545, epoch: 64, loss: 0.945563
global_step: 2546, epoch: 64, loss: 0.851827
global_step: 2547, epoch: 64, loss: 0.913677
global_step: 2548, epoch: 64, loss: 0.839804
global_step: 2549, epoch: 64, loss: 0.795376
global_step: 2550, epoch: 64, loss: 0.750530
global_step: 2551, epoch: 64, loss: 0.834798
global_step: 2552, epoch: 64, loss: 0.778229
global_step: 2553, epoch: 64, loss: 0.836620
global_step: 2554, epoch: 64, loss: 0.756885
global_step: 2555, epoch: 64, loss: 0.829701
global_step: 2556, epoch: 64, loss: 0.699598
global_step: 2557, epoch: 64, loss: 0.773499
global_step: 2558, epoch: 64, loss: 0.882966
global_step: 2559, epoch: 64, loss: 0.780357
global_step: 2560, epoch: 64, loss: 1.082605
epoch: 64
train	acc: 0.7851	macro: p 0.5206, r 0.5154, f1: 0.5145	micro: p 0.7851, r 0.7851, f1 0.7851	weighted_f1:0.7573
dev	acc: 0.5771	macro: p 0.3595, r 0.3422, f1: 0.3394	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5332
test	acc: 0.6142	macro: p 0.3674, r 0.3428, f1: 0.3447	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5768
global_step: 2561, epoch: 65, loss: 0.766357
global_step: 2562, epoch: 65, loss: 0.759747
global_step: 2563, epoch: 65, loss: 0.612888
global_step: 2564, epoch: 65, loss: 0.847428
global_step: 2565, epoch: 65, loss: 0.890546
global_step: 2566, epoch: 65, loss: 0.788816
global_step: 2567, epoch: 65, loss: 0.803447
global_step: 2568, epoch: 65, loss: 0.876797
global_step: 2569, epoch: 65, loss: 0.729997
global_step: 2570, epoch: 65, loss: 0.749628
global_step: 2571, epoch: 65, loss: 0.741029
global_step: 2572, epoch: 65, loss: 0.846001
global_step: 2573, epoch: 65, loss: 0.882904
global_step: 2574, epoch: 65, loss: 0.692546
global_step: 2575, epoch: 65, loss: 0.792084
global_step: 2576, epoch: 65, loss: 0.773988
global_step: 2577, epoch: 65, loss: 0.929370
global_step: 2578, epoch: 65, loss: 0.756759
global_step: 2579, epoch: 65, loss: 0.781401
global_step: 2580, epoch: 65, loss: 0.752963
global_step: 2581, epoch: 65, loss: 0.745747
global_step: 2582, epoch: 65, loss: 0.758211
global_step: 2583, epoch: 65, loss: 0.842531
global_step: 2584, epoch: 65, loss: 0.856506
global_step: 2585, epoch: 65, loss: 0.880386
global_step: 2586, epoch: 65, loss: 0.898986
global_step: 2587, epoch: 65, loss: 0.860440
global_step: 2588, epoch: 65, loss: 0.902621
global_step: 2589, epoch: 65, loss: 0.748042
global_step: 2590, epoch: 65, loss: 0.741030
global_step: 2591, epoch: 65, loss: 0.853806
global_step: 2592, epoch: 65, loss: 0.856895
global_step: 2593, epoch: 65, loss: 0.788351
global_step: 2594, epoch: 65, loss: 0.847495
global_step: 2595, epoch: 65, loss: 0.798279
global_step: 2596, epoch: 65, loss: 0.707551
global_step: 2597, epoch: 65, loss: 0.852984
global_step: 2598, epoch: 65, loss: 0.750480
global_step: 2599, epoch: 65, loss: 0.804571
global_step: 2600, epoch: 65, loss: 0.488928
epoch: 65
train	acc: 0.7638	macro: p 0.5223, r 0.4777, f1: 0.4873	micro: p 0.7638, r 0.7638, f1 0.7638	weighted_f1:0.7294
dev	acc: 0.5762	macro: p 0.3945, r 0.3286, f1: 0.3280	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5218
test	acc: 0.6115	macro: p 0.3740, r 0.3270, f1: 0.3294	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5641
global_step: 2601, epoch: 66, loss: 0.748967
global_step: 2602, epoch: 66, loss: 0.952772
global_step: 2603, epoch: 66, loss: 0.789279
global_step: 2604, epoch: 66, loss: 0.780610
global_step: 2605, epoch: 66, loss: 0.817824
global_step: 2606, epoch: 66, loss: 0.776965
global_step: 2607, epoch: 66, loss: 0.810596
global_step: 2608, epoch: 66, loss: 0.856520
global_step: 2609, epoch: 66, loss: 0.763809
global_step: 2610, epoch: 66, loss: 0.849949
global_step: 2611, epoch: 66, loss: 0.838655
global_step: 2612, epoch: 66, loss: 0.771754
global_step: 2613, epoch: 66, loss: 0.610184
global_step: 2614, epoch: 66, loss: 0.864021
global_step: 2615, epoch: 66, loss: 0.789746
global_step: 2616, epoch: 66, loss: 0.878507
global_step: 2617, epoch: 66, loss: 0.827058
global_step: 2618, epoch: 66, loss: 0.831775
global_step: 2619, epoch: 66, loss: 0.688696
global_step: 2620, epoch: 66, loss: 0.776531
global_step: 2621, epoch: 66, loss: 0.747871
global_step: 2622, epoch: 66, loss: 0.782317
global_step: 2623, epoch: 66, loss: 0.798334
global_step: 2624, epoch: 66, loss: 0.701162
global_step: 2625, epoch: 66, loss: 0.845780
global_step: 2626, epoch: 66, loss: 0.734870
global_step: 2627, epoch: 66, loss: 0.883896
global_step: 2628, epoch: 66, loss: 0.766728
global_step: 2629, epoch: 66, loss: 0.667473
global_step: 2630, epoch: 66, loss: 0.770616
global_step: 2631, epoch: 66, loss: 0.823046
global_step: 2632, epoch: 66, loss: 0.775716
global_step: 2633, epoch: 66, loss: 0.840954
global_step: 2634, epoch: 66, loss: 0.676068
global_step: 2635, epoch: 66, loss: 0.769719
global_step: 2636, epoch: 66, loss: 0.680814
global_step: 2637, epoch: 66, loss: 0.793932
global_step: 2638, epoch: 66, loss: 0.776295
global_step: 2639, epoch: 66, loss: 0.745382
global_step: 2640, epoch: 66, loss: 0.792992
epoch: 66
train	acc: 0.7654	macro: p 0.5194, r 0.4835, f1: 0.4923	micro: p 0.7654, r 0.7654, f1 0.7654	weighted_f1:0.7338
dev	acc: 0.5690	macro: p 0.3786, r 0.3223, f1: 0.3195	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5156
test	acc: 0.6111	macro: p 0.3807, r 0.3302, f1: 0.3321	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5658
global_step: 2641, epoch: 67, loss: 0.822397
global_step: 2642, epoch: 67, loss: 0.721187
global_step: 2643, epoch: 67, loss: 0.884447
global_step: 2644, epoch: 67, loss: 0.725024
global_step: 2645, epoch: 67, loss: 0.732612
global_step: 2646, epoch: 67, loss: 0.762322
global_step: 2647, epoch: 67, loss: 0.774878
global_step: 2648, epoch: 67, loss: 0.713417
global_step: 2649, epoch: 67, loss: 0.628144
global_step: 2650, epoch: 67, loss: 0.800322
global_step: 2651, epoch: 67, loss: 0.801196
global_step: 2652, epoch: 67, loss: 0.765604
global_step: 2653, epoch: 67, loss: 0.679492
global_step: 2654, epoch: 67, loss: 0.824190
global_step: 2655, epoch: 67, loss: 0.758700
global_step: 2656, epoch: 67, loss: 0.743917
global_step: 2657, epoch: 67, loss: 0.739384
global_step: 2658, epoch: 67, loss: 0.778442
global_step: 2659, epoch: 67, loss: 0.807292
global_step: 2660, epoch: 67, loss: 0.764305
global_step: 2661, epoch: 67, loss: 0.734092
global_step: 2662, epoch: 67, loss: 0.748883
global_step: 2663, epoch: 67, loss: 0.776242
global_step: 2664, epoch: 67, loss: 0.717317
global_step: 2665, epoch: 67, loss: 0.757305
global_step: 2666, epoch: 67, loss: 0.751150
global_step: 2667, epoch: 67, loss: 0.782580
global_step: 2668, epoch: 67, loss: 0.836693
global_step: 2669, epoch: 67, loss: 0.808807
global_step: 2670, epoch: 67, loss: 0.712069
global_step: 2671, epoch: 67, loss: 0.803668
global_step: 2672, epoch: 67, loss: 0.767678
global_step: 2673, epoch: 67, loss: 0.803535
global_step: 2674, epoch: 67, loss: 0.781415
global_step: 2675, epoch: 67, loss: 0.763239
global_step: 2676, epoch: 67, loss: 0.881035
global_step: 2677, epoch: 67, loss: 0.806932
global_step: 2678, epoch: 67, loss: 0.856491
global_step: 2679, epoch: 67, loss: 0.779315
global_step: 2680, epoch: 67, loss: 0.392317
epoch: 67
train	acc: 0.7896	macro: p 0.5269, r 0.5153, f1: 0.5141	micro: p 0.7896, r 0.7896, f1 0.7896	weighted_f1:0.7594
dev	acc: 0.5744	macro: p 0.3673, r 0.3387, f1: 0.3314	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5250
test	acc: 0.6042	macro: p 0.3627, r 0.3345, f1: 0.3312	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5639
global_step: 2681, epoch: 68, loss: 0.876282
global_step: 2682, epoch: 68, loss: 0.820582
global_step: 2683, epoch: 68, loss: 0.744658
global_step: 2684, epoch: 68, loss: 0.793830
global_step: 2685, epoch: 68, loss: 0.861862
global_step: 2686, epoch: 68, loss: 0.816783
global_step: 2687, epoch: 68, loss: 0.746111
global_step: 2688, epoch: 68, loss: 0.738559
global_step: 2689, epoch: 68, loss: 0.793667
global_step: 2690, epoch: 68, loss: 0.748158
global_step: 2691, epoch: 68, loss: 0.803714
global_step: 2692, epoch: 68, loss: 0.665088
global_step: 2693, epoch: 68, loss: 0.818891
global_step: 2694, epoch: 68, loss: 0.717940
global_step: 2695, epoch: 68, loss: 0.751997
global_step: 2696, epoch: 68, loss: 0.769925
global_step: 2697, epoch: 68, loss: 0.782099
global_step: 2698, epoch: 68, loss: 0.778786
global_step: 2699, epoch: 68, loss: 0.599871
global_step: 2700, epoch: 68, loss: 0.853307
global_step: 2701, epoch: 68, loss: 0.809167
global_step: 2702, epoch: 68, loss: 0.771163
global_step: 2703, epoch: 68, loss: 0.724228
global_step: 2704, epoch: 68, loss: 0.648431
global_step: 2705, epoch: 68, loss: 0.691779
global_step: 2706, epoch: 68, loss: 0.870462
global_step: 2707, epoch: 68, loss: 0.801881
global_step: 2708, epoch: 68, loss: 0.777360
global_step: 2709, epoch: 68, loss: 0.803312
global_step: 2710, epoch: 68, loss: 0.836498
global_step: 2711, epoch: 68, loss: 0.897871
global_step: 2712, epoch: 68, loss: 0.802810
global_step: 2713, epoch: 68, loss: 0.805451
global_step: 2714, epoch: 68, loss: 0.734376
global_step: 2715, epoch: 68, loss: 0.668535
global_step: 2716, epoch: 68, loss: 0.740933
global_step: 2717, epoch: 68, loss: 0.818196
global_step: 2718, epoch: 68, loss: 0.820288
global_step: 2719, epoch: 68, loss: 0.802231
global_step: 2720, epoch: 68, loss: 1.513599
epoch: 68
train	acc: 0.8004	macro: p 0.6762, r 0.5409, f1: 0.5361	micro: p 0.8004, r 0.8004, f1 0.8004	weighted_f1:0.7764
dev	acc: 0.5825	macro: p 0.3670, r 0.3460, f1: 0.3488	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5431
test	acc: 0.6111	macro: p 0.3653, r 0.3458, f1: 0.3498	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5787
global_step: 2721, epoch: 69, loss: 0.823021
global_step: 2722, epoch: 69, loss: 0.730075
global_step: 2723, epoch: 69, loss: 0.736232
global_step: 2724, epoch: 69, loss: 0.663269
global_step: 2725, epoch: 69, loss: 0.722153
global_step: 2726, epoch: 69, loss: 0.717921
global_step: 2727, epoch: 69, loss: 0.823269
global_step: 2728, epoch: 69, loss: 0.806516
global_step: 2729, epoch: 69, loss: 0.807063
global_step: 2730, epoch: 69, loss: 0.796256
global_step: 2731, epoch: 69, loss: 0.789528
global_step: 2732, epoch: 69, loss: 0.743606
global_step: 2733, epoch: 69, loss: 0.746527
global_step: 2734, epoch: 69, loss: 0.820215
global_step: 2735, epoch: 69, loss: 0.790678
global_step: 2736, epoch: 69, loss: 0.753374
global_step: 2737, epoch: 69, loss: 0.757985
global_step: 2738, epoch: 69, loss: 0.683063
global_step: 2739, epoch: 69, loss: 0.683790
global_step: 2740, epoch: 69, loss: 0.671967
global_step: 2741, epoch: 69, loss: 0.731073
global_step: 2742, epoch: 69, loss: 0.736246
global_step: 2743, epoch: 69, loss: 0.719095
global_step: 2744, epoch: 69, loss: 0.737408
global_step: 2745, epoch: 69, loss: 0.802790
global_step: 2746, epoch: 69, loss: 0.696986
global_step: 2747, epoch: 69, loss: 0.828491
global_step: 2748, epoch: 69, loss: 0.746472
global_step: 2749, epoch: 69, loss: 0.820442
global_step: 2750, epoch: 69, loss: 0.740096
global_step: 2751, epoch: 69, loss: 0.760139
global_step: 2752, epoch: 69, loss: 0.798354
global_step: 2753, epoch: 69, loss: 0.733595
global_step: 2754, epoch: 69, loss: 0.771934
global_step: 2755, epoch: 69, loss: 0.730500
global_step: 2756, epoch: 69, loss: 0.781704
global_step: 2757, epoch: 69, loss: 0.769056
global_step: 2758, epoch: 69, loss: 0.776551
global_step: 2759, epoch: 69, loss: 0.793481
global_step: 2760, epoch: 69, loss: 0.464292
epoch: 69
train	acc: 0.8111	macro: p 0.5311, r 0.5531, f1: 0.5403	micro: p 0.8111, r 0.8111, f1 0.8111	weighted_f1:0.7867
dev	acc: 0.5735	macro: p 0.3566, r 0.3523, f1: 0.3460	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5373
test	acc: 0.6031	macro: p 0.3548, r 0.3503, f1: 0.3442	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5735
global_step: 2761, epoch: 70, loss: 0.784600
global_step: 2762, epoch: 70, loss: 0.727901
global_step: 2763, epoch: 70, loss: 0.734432
global_step: 2764, epoch: 70, loss: 0.632830
global_step: 2765, epoch: 70, loss: 0.745477
global_step: 2766, epoch: 70, loss: 0.765822
global_step: 2767, epoch: 70, loss: 0.849823
global_step: 2768, epoch: 70, loss: 0.787287
global_step: 2769, epoch: 70, loss: 0.750764
global_step: 2770, epoch: 70, loss: 0.691562
global_step: 2771, epoch: 70, loss: 0.702357
global_step: 2772, epoch: 70, loss: 0.823397
global_step: 2773, epoch: 70, loss: 0.840761
global_step: 2774, epoch: 70, loss: 0.681955
global_step: 2775, epoch: 70, loss: 0.762924
global_step: 2776, epoch: 70, loss: 0.686357
global_step: 2777, epoch: 70, loss: 0.766243
global_step: 2778, epoch: 70, loss: 0.703849
global_step: 2779, epoch: 70, loss: 0.759279
global_step: 2780, epoch: 70, loss: 0.805562
global_step: 2781, epoch: 70, loss: 0.791654
global_step: 2782, epoch: 70, loss: 0.787101
global_step: 2783, epoch: 70, loss: 0.703969
global_step: 2784, epoch: 70, loss: 0.752851
global_step: 2785, epoch: 70, loss: 0.780763
global_step: 2786, epoch: 70, loss: 0.741005
global_step: 2787, epoch: 70, loss: 0.818648
global_step: 2788, epoch: 70, loss: 0.681215
global_step: 2789, epoch: 70, loss: 0.583699
global_step: 2790, epoch: 70, loss: 0.809558
global_step: 2791, epoch: 70, loss: 0.822407
global_step: 2792, epoch: 70, loss: 0.814946
global_step: 2793, epoch: 70, loss: 0.628689
global_step: 2794, epoch: 70, loss: 0.866334
global_step: 2795, epoch: 70, loss: 0.735136
global_step: 2796, epoch: 70, loss: 0.753796
global_step: 2797, epoch: 70, loss: 0.808928
global_step: 2798, epoch: 70, loss: 0.705200
global_step: 2799, epoch: 70, loss: 0.675260
global_step: 2800, epoch: 70, loss: 1.388318
epoch: 70
train	acc: 0.8170	macro: p 0.5376, r 0.5628, f1: 0.5497	micro: p 0.8170, r 0.8170, f1 0.8170	weighted_f1:0.7941
dev	acc: 0.5690	macro: p 0.3528, r 0.3476, f1: 0.3447	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5356
test	acc: 0.6061	macro: p 0.3549, r 0.3521, f1: 0.3504	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5788
global_step: 2801, epoch: 71, loss: 0.609524
global_step: 2802, epoch: 71, loss: 0.713572
global_step: 2803, epoch: 71, loss: 0.700983
global_step: 2804, epoch: 71, loss: 0.755444
global_step: 2805, epoch: 71, loss: 0.773164
global_step: 2806, epoch: 71, loss: 0.768916
global_step: 2807, epoch: 71, loss: 0.770670
global_step: 2808, epoch: 71, loss: 0.691324
global_step: 2809, epoch: 71, loss: 0.825695
global_step: 2810, epoch: 71, loss: 0.707119
global_step: 2811, epoch: 71, loss: 0.832359
global_step: 2812, epoch: 71, loss: 0.728922
global_step: 2813, epoch: 71, loss: 0.755532
global_step: 2814, epoch: 71, loss: 0.736731
global_step: 2815, epoch: 71, loss: 0.650533
global_step: 2816, epoch: 71, loss: 0.698293
global_step: 2817, epoch: 71, loss: 0.744458
global_step: 2818, epoch: 71, loss: 0.720421
global_step: 2819, epoch: 71, loss: 0.740104
global_step: 2820, epoch: 71, loss: 0.687820
global_step: 2821, epoch: 71, loss: 0.718958
global_step: 2822, epoch: 71, loss: 0.806609
global_step: 2823, epoch: 71, loss: 0.740674
global_step: 2824, epoch: 71, loss: 0.665990
global_step: 2825, epoch: 71, loss: 0.775294
global_step: 2826, epoch: 71, loss: 0.790847
global_step: 2827, epoch: 71, loss: 0.713191
global_step: 2828, epoch: 71, loss: 0.758986
global_step: 2829, epoch: 71, loss: 0.792114
global_step: 2830, epoch: 71, loss: 0.808817
global_step: 2831, epoch: 71, loss: 0.846584
global_step: 2832, epoch: 71, loss: 0.640007
global_step: 2833, epoch: 71, loss: 0.796380
global_step: 2834, epoch: 71, loss: 0.744154
global_step: 2835, epoch: 71, loss: 0.669688
global_step: 2836, epoch: 71, loss: 0.791959
global_step: 2837, epoch: 71, loss: 0.825031
global_step: 2838, epoch: 71, loss: 0.829424
global_step: 2839, epoch: 71, loss: 0.769958
global_step: 2840, epoch: 71, loss: 0.458936
epoch: 71
train	acc: 0.8189	macro: p 0.6822, r 0.5645, f1: 0.5522	micro: p 0.8189, r 0.8189, f1 0.8189	weighted_f1:0.7953
dev	acc: 0.5807	macro: p 0.3632, r 0.3540, f1: 0.3510	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5432
test	acc: 0.6050	macro: p 0.3534, r 0.3471, f1: 0.3450	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5741
global_step: 2841, epoch: 72, loss: 0.671035
global_step: 2842, epoch: 72, loss: 0.739270
global_step: 2843, epoch: 72, loss: 0.757393
global_step: 2844, epoch: 72, loss: 0.711387
global_step: 2845, epoch: 72, loss: 0.786512
global_step: 2846, epoch: 72, loss: 0.706823
global_step: 2847, epoch: 72, loss: 0.734685
global_step: 2848, epoch: 72, loss: 0.669689
global_step: 2849, epoch: 72, loss: 0.850584
global_step: 2850, epoch: 72, loss: 0.768385
global_step: 2851, epoch: 72, loss: 0.681926
global_step: 2852, epoch: 72, loss: 0.669684
global_step: 2853, epoch: 72, loss: 0.693345
global_step: 2854, epoch: 72, loss: 0.945256
global_step: 2855, epoch: 72, loss: 0.780277
global_step: 2856, epoch: 72, loss: 0.744555
global_step: 2857, epoch: 72, loss: 0.719421
global_step: 2858, epoch: 72, loss: 0.765959
global_step: 2859, epoch: 72, loss: 0.751975
global_step: 2860, epoch: 72, loss: 0.643593
global_step: 2861, epoch: 72, loss: 0.727020
global_step: 2862, epoch: 72, loss: 0.679035
global_step: 2863, epoch: 72, loss: 0.777415
global_step: 2864, epoch: 72, loss: 0.756110
global_step: 2865, epoch: 72, loss: 0.871032
global_step: 2866, epoch: 72, loss: 0.694815
global_step: 2867, epoch: 72, loss: 0.736124
global_step: 2868, epoch: 72, loss: 0.681961
global_step: 2869, epoch: 72, loss: 0.742987
global_step: 2870, epoch: 72, loss: 0.757219
global_step: 2871, epoch: 72, loss: 0.791075
global_step: 2872, epoch: 72, loss: 0.777951
global_step: 2873, epoch: 72, loss: 0.717257
global_step: 2874, epoch: 72, loss: 0.713251
global_step: 2875, epoch: 72, loss: 0.652429
global_step: 2876, epoch: 72, loss: 0.700408
global_step: 2877, epoch: 72, loss: 0.673630
global_step: 2878, epoch: 72, loss: 0.775430
global_step: 2879, epoch: 72, loss: 0.790314
global_step: 2880, epoch: 72, loss: 0.811877
epoch: 72
train	acc: 0.8184	macro: p 0.5414, r 0.5625, f1: 0.5515	micro: p 0.8184, r 0.8184, f1 0.8184	weighted_f1:0.7947
dev	acc: 0.5681	macro: p 0.3547, r 0.3429, f1: 0.3395	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5306
test	acc: 0.6119	macro: p 0.3630, r 0.3525, f1: 0.3513	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5807
global_step: 2881, epoch: 73, loss: 0.739211
global_step: 2882, epoch: 73, loss: 0.798644
global_step: 2883, epoch: 73, loss: 0.753452
global_step: 2884, epoch: 73, loss: 0.694327
global_step: 2885, epoch: 73, loss: 0.895945
global_step: 2886, epoch: 73, loss: 0.767849
global_step: 2887, epoch: 73, loss: 0.708187
global_step: 2888, epoch: 73, loss: 0.783160
global_step: 2889, epoch: 73, loss: 0.730847
global_step: 2890, epoch: 73, loss: 0.666287
global_step: 2891, epoch: 73, loss: 0.672976
global_step: 2892, epoch: 73, loss: 0.758794
global_step: 2893, epoch: 73, loss: 0.617031
global_step: 2894, epoch: 73, loss: 0.718713
global_step: 2895, epoch: 73, loss: 0.768418
global_step: 2896, epoch: 73, loss: 0.667585
global_step: 2897, epoch: 73, loss: 0.706566
global_step: 2898, epoch: 73, loss: 0.739351
global_step: 2899, epoch: 73, loss: 0.735076
global_step: 2900, epoch: 73, loss: 0.658139
global_step: 2901, epoch: 73, loss: 0.774571
global_step: 2902, epoch: 73, loss: 0.739364
global_step: 2903, epoch: 73, loss: 0.638012
global_step: 2904, epoch: 73, loss: 0.659265
global_step: 2905, epoch: 73, loss: 0.740040
global_step: 2906, epoch: 73, loss: 0.749714
global_step: 2907, epoch: 73, loss: 0.753603
global_step: 2908, epoch: 73, loss: 0.595750
global_step: 2909, epoch: 73, loss: 0.647943
global_step: 2910, epoch: 73, loss: 0.675674
global_step: 2911, epoch: 73, loss: 0.882265
global_step: 2912, epoch: 73, loss: 0.768780
global_step: 2913, epoch: 73, loss: 0.711463
global_step: 2914, epoch: 73, loss: 0.786534
global_step: 2915, epoch: 73, loss: 0.754678
global_step: 2916, epoch: 73, loss: 0.721695
global_step: 2917, epoch: 73, loss: 0.746376
global_step: 2918, epoch: 73, loss: 0.657626
global_step: 2919, epoch: 73, loss: 0.741674
global_step: 2920, epoch: 73, loss: 0.265238
epoch: 73
train	acc: 0.8218	macro: p 0.6901, r 0.5612, f1: 0.5534	micro: p 0.8218, r 0.8218, f1 0.8218	weighted_f1:0.7967
dev	acc: 0.5609	macro: p 0.3524, r 0.3397, f1: 0.3315	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5219
test	acc: 0.6011	macro: p 0.3591, r 0.3464, f1: 0.3403	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5680
global_step: 2921, epoch: 74, loss: 0.775431
global_step: 2922, epoch: 74, loss: 0.719912
global_step: 2923, epoch: 74, loss: 0.734463
global_step: 2924, epoch: 74, loss: 0.724087
global_step: 2925, epoch: 74, loss: 0.792374
global_step: 2926, epoch: 74, loss: 0.642496
global_step: 2927, epoch: 74, loss: 0.737397
global_step: 2928, epoch: 74, loss: 0.766117
global_step: 2929, epoch: 74, loss: 0.752283
global_step: 2930, epoch: 74, loss: 0.808632
global_step: 2931, epoch: 74, loss: 0.735012
global_step: 2932, epoch: 74, loss: 0.771342
global_step: 2933, epoch: 74, loss: 0.619841
global_step: 2934, epoch: 74, loss: 0.671491
global_step: 2935, epoch: 74, loss: 0.637838
global_step: 2936, epoch: 74, loss: 0.652475
global_step: 2937, epoch: 74, loss: 0.754107
global_step: 2938, epoch: 74, loss: 0.650197
global_step: 2939, epoch: 74, loss: 0.660443
global_step: 2940, epoch: 74, loss: 0.783839
global_step: 2941, epoch: 74, loss: 0.743254
global_step: 2942, epoch: 74, loss: 0.665178
global_step: 2943, epoch: 74, loss: 0.649448
global_step: 2944, epoch: 74, loss: 0.697574
global_step: 2945, epoch: 74, loss: 0.681467
global_step: 2946, epoch: 74, loss: 0.785210
global_step: 2947, epoch: 74, loss: 0.828381
global_step: 2948, epoch: 74, loss: 0.624192
global_step: 2949, epoch: 74, loss: 0.726709
global_step: 2950, epoch: 74, loss: 0.707080
global_step: 2951, epoch: 74, loss: 0.799666
global_step: 2952, epoch: 74, loss: 0.720180
global_step: 2953, epoch: 74, loss: 0.792086
global_step: 2954, epoch: 74, loss: 0.752023
global_step: 2955, epoch: 74, loss: 0.782104
global_step: 2956, epoch: 74, loss: 0.647679
global_step: 2957, epoch: 74, loss: 0.741933
global_step: 2958, epoch: 74, loss: 0.758634
global_step: 2959, epoch: 74, loss: 0.744713
global_step: 2960, epoch: 74, loss: 0.620578
epoch: 74
train	acc: 0.8258	macro: p 0.6906, r 0.5729, f1: 0.5624	micro: p 0.8258, r 0.8258, f1 0.8258	weighted_f1:0.8026
dev	acc: 0.5618	macro: p 0.3514, r 0.3514, f1: 0.3407	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5292
test	acc: 0.5992	macro: p 0.3536, r 0.3544, f1: 0.3447	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5730
global_step: 2961, epoch: 75, loss: 0.811371
global_step: 2962, epoch: 75, loss: 0.790298
global_step: 2963, epoch: 75, loss: 0.685458
global_step: 2964, epoch: 75, loss: 0.653627
global_step: 2965, epoch: 75, loss: 0.655347
global_step: 2966, epoch: 75, loss: 0.689400
global_step: 2967, epoch: 75, loss: 0.736706
global_step: 2968, epoch: 75, loss: 0.765182
global_step: 2969, epoch: 75, loss: 0.660674
global_step: 2970, epoch: 75, loss: 0.721355
global_step: 2971, epoch: 75, loss: 0.645937
global_step: 2972, epoch: 75, loss: 0.767636
global_step: 2973, epoch: 75, loss: 0.747797
global_step: 2974, epoch: 75, loss: 0.614138
global_step: 2975, epoch: 75, loss: 0.747384
global_step: 2976, epoch: 75, loss: 0.678765
global_step: 2977, epoch: 75, loss: 0.703583
global_step: 2978, epoch: 75, loss: 0.681579
global_step: 2979, epoch: 75, loss: 0.754739
global_step: 2980, epoch: 75, loss: 0.640145
global_step: 2981, epoch: 75, loss: 0.637989
global_step: 2982, epoch: 75, loss: 0.652539
global_step: 2983, epoch: 75, loss: 0.782862
global_step: 2984, epoch: 75, loss: 0.762359
global_step: 2985, epoch: 75, loss: 0.761005
global_step: 2986, epoch: 75, loss: 0.751243
global_step: 2987, epoch: 75, loss: 0.713015
global_step: 2988, epoch: 75, loss: 0.693510
global_step: 2989, epoch: 75, loss: 0.600922
global_step: 2990, epoch: 75, loss: 0.646367
global_step: 2991, epoch: 75, loss: 0.810719
global_step: 2992, epoch: 75, loss: 0.646541
global_step: 2993, epoch: 75, loss: 0.795275
global_step: 2994, epoch: 75, loss: 0.763912
global_step: 2995, epoch: 75, loss: 0.646906
global_step: 2996, epoch: 75, loss: 0.788741
global_step: 2997, epoch: 75, loss: 0.697248
global_step: 2998, epoch: 75, loss: 0.683391
global_step: 2999, epoch: 75, loss: 0.698762
global_step: 3000, epoch: 75, loss: 0.977208
epoch: 75
train	acc: 0.8235	macro: p 0.6924, r 0.5658, f1: 0.5583	micro: p 0.8235, r 0.8235, f1 0.8235	weighted_f1:0.7985
dev	acc: 0.5672	macro: p 0.3520, r 0.3358, f1: 0.3312	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5217
test	acc: 0.6023	macro: p 0.3511, r 0.3351, f1: 0.3331	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5640
global_step: 3001, epoch: 76, loss: 0.757640
global_step: 3002, epoch: 76, loss: 0.754899
global_step: 3003, epoch: 76, loss: 0.769215
global_step: 3004, epoch: 76, loss: 0.688607
global_step: 3005, epoch: 76, loss: 0.791482
global_step: 3006, epoch: 76, loss: 0.735394
global_step: 3007, epoch: 76, loss: 0.594000
global_step: 3008, epoch: 76, loss: 0.714640
global_step: 3009, epoch: 76, loss: 0.723287
global_step: 3010, epoch: 76, loss: 0.720701
global_step: 3011, epoch: 76, loss: 0.635999
global_step: 3012, epoch: 76, loss: 0.793392
global_step: 3013, epoch: 76, loss: 0.684620
global_step: 3014, epoch: 76, loss: 0.595042
global_step: 3015, epoch: 76, loss: 0.650366
global_step: 3016, epoch: 76, loss: 0.699915
global_step: 3017, epoch: 76, loss: 0.671131
global_step: 3018, epoch: 76, loss: 0.734819
global_step: 3019, epoch: 76, loss: 0.725985
global_step: 3020, epoch: 76, loss: 0.696443
global_step: 3021, epoch: 76, loss: 0.687624
global_step: 3022, epoch: 76, loss: 0.633930
global_step: 3023, epoch: 76, loss: 0.640838
global_step: 3024, epoch: 76, loss: 0.736725
global_step: 3025, epoch: 76, loss: 0.671164
global_step: 3026, epoch: 76, loss: 0.708504
global_step: 3027, epoch: 76, loss: 0.684682
global_step: 3028, epoch: 76, loss: 0.701156
global_step: 3029, epoch: 76, loss: 0.709984
global_step: 3030, epoch: 76, loss: 0.657957
global_step: 3031, epoch: 76, loss: 0.733390
global_step: 3032, epoch: 76, loss: 0.659891
global_step: 3033, epoch: 76, loss: 0.689423
global_step: 3034, epoch: 76, loss: 0.761776
global_step: 3035, epoch: 76, loss: 0.767857
global_step: 3036, epoch: 76, loss: 0.688134
global_step: 3037, epoch: 76, loss: 0.811985
global_step: 3038, epoch: 76, loss: 0.656103
global_step: 3039, epoch: 76, loss: 0.688660
global_step: 3040, epoch: 76, loss: 0.457892
epoch: 76
train	acc: 0.8215	macro: p 0.6948, r 0.5642, f1: 0.5590	micro: p 0.8215, r 0.8215, f1 0.8215	weighted_f1:0.7969
dev	acc: 0.5690	macro: p 0.3555, r 0.3317, f1: 0.3307	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5243
test	acc: 0.6069	macro: p 0.3598, r 0.3364, f1: 0.3388	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5690
global_step: 3041, epoch: 77, loss: 0.717528
global_step: 3042, epoch: 77, loss: 0.677021
global_step: 3043, epoch: 77, loss: 0.672052
global_step: 3044, epoch: 77, loss: 0.745811
global_step: 3045, epoch: 77, loss: 0.670654
global_step: 3046, epoch: 77, loss: 0.669779
global_step: 3047, epoch: 77, loss: 0.609752
global_step: 3048, epoch: 77, loss: 0.733420
global_step: 3049, epoch: 77, loss: 0.668033
global_step: 3050, epoch: 77, loss: 0.588028
global_step: 3051, epoch: 77, loss: 0.637051
global_step: 3052, epoch: 77, loss: 0.692583
global_step: 3053, epoch: 77, loss: 0.665557
global_step: 3054, epoch: 77, loss: 0.665905
global_step: 3055, epoch: 77, loss: 0.668334
global_step: 3056, epoch: 77, loss: 0.707491
global_step: 3057, epoch: 77, loss: 0.606289
global_step: 3058, epoch: 77, loss: 0.675426
global_step: 3059, epoch: 77, loss: 0.728516
global_step: 3060, epoch: 77, loss: 0.632229
global_step: 3061, epoch: 77, loss: 0.659798
global_step: 3062, epoch: 77, loss: 0.676198
global_step: 3063, epoch: 77, loss: 0.716145
global_step: 3064, epoch: 77, loss: 0.688540
global_step: 3065, epoch: 77, loss: 0.659997
global_step: 3066, epoch: 77, loss: 0.706583
global_step: 3067, epoch: 77, loss: 0.787466
global_step: 3068, epoch: 77, loss: 0.766672
global_step: 3069, epoch: 77, loss: 0.640553
global_step: 3070, epoch: 77, loss: 0.807564
global_step: 3071, epoch: 77, loss: 0.622782
global_step: 3072, epoch: 77, loss: 0.672954
global_step: 3073, epoch: 77, loss: 0.668938
global_step: 3074, epoch: 77, loss: 0.740355
global_step: 3075, epoch: 77, loss: 0.671394
global_step: 3076, epoch: 77, loss: 0.762456
global_step: 3077, epoch: 77, loss: 0.685740
global_step: 3078, epoch: 77, loss: 0.798457
global_step: 3079, epoch: 77, loss: 0.694948
global_step: 3080, epoch: 77, loss: 0.845040
epoch: 77
train	acc: 0.8355	macro: p 0.6991, r 0.5863, f1: 0.5763	micro: p 0.8355, r 0.8355, f1 0.8355	weighted_f1:0.8139
dev	acc: 0.5681	macro: p 0.3583, r 0.3565, f1: 0.3473	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5364
test	acc: 0.6038	macro: p 0.3612, r 0.3603, f1: 0.3517	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5787
global_step: 3081, epoch: 78, loss: 0.712055
global_step: 3082, epoch: 78, loss: 0.675394
global_step: 3083, epoch: 78, loss: 0.695175
global_step: 3084, epoch: 78, loss: 0.796109
global_step: 3085, epoch: 78, loss: 0.654217
global_step: 3086, epoch: 78, loss: 0.746297
global_step: 3087, epoch: 78, loss: 0.560634
global_step: 3088, epoch: 78, loss: 0.737449
global_step: 3089, epoch: 78, loss: 0.615509
global_step: 3090, epoch: 78, loss: 0.743755
global_step: 3091, epoch: 78, loss: 0.590142
global_step: 3092, epoch: 78, loss: 0.799656
global_step: 3093, epoch: 78, loss: 0.677166
global_step: 3094, epoch: 78, loss: 0.657647
global_step: 3095, epoch: 78, loss: 0.616866
global_step: 3096, epoch: 78, loss: 0.572523
global_step: 3097, epoch: 78, loss: 0.696951
global_step: 3098, epoch: 78, loss: 0.840203
global_step: 3099, epoch: 78, loss: 0.828038
global_step: 3100, epoch: 78, loss: 0.699268
global_step: 3101, epoch: 78, loss: 0.693432
global_step: 3102, epoch: 78, loss: 0.705081
global_step: 3103, epoch: 78, loss: 0.674572
global_step: 3104, epoch: 78, loss: 0.736424
global_step: 3105, epoch: 78, loss: 0.620986
global_step: 3106, epoch: 78, loss: 0.685927
global_step: 3107, epoch: 78, loss: 0.726834
global_step: 3108, epoch: 78, loss: 0.602049
global_step: 3109, epoch: 78, loss: 0.814378
global_step: 3110, epoch: 78, loss: 0.703356
global_step: 3111, epoch: 78, loss: 0.751345
global_step: 3112, epoch: 78, loss: 0.596455
global_step: 3113, epoch: 78, loss: 0.683831
global_step: 3114, epoch: 78, loss: 0.722765
global_step: 3115, epoch: 78, loss: 0.705789
global_step: 3116, epoch: 78, loss: 0.640059
global_step: 3117, epoch: 78, loss: 0.644692
global_step: 3118, epoch: 78, loss: 0.668096
global_step: 3119, epoch: 78, loss: 0.621286
global_step: 3120, epoch: 78, loss: 0.107336
epoch: 78
train	acc: 0.8347	macro: p 0.7035, r 0.5822, f1: 0.5740	micro: p 0.8347, r 0.8347, f1 0.8347	weighted_f1:0.8122
dev	acc: 0.5708	macro: p 0.3631, r 0.3473, f1: 0.3445	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5344
test	acc: 0.6146	macro: p 0.3665, r 0.3570, f1: 0.3554	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5855
global_step: 3121, epoch: 79, loss: 0.646564
global_step: 3122, epoch: 79, loss: 0.651276
global_step: 3123, epoch: 79, loss: 0.742833
global_step: 3124, epoch: 79, loss: 0.671426
global_step: 3125, epoch: 79, loss: 0.786610
global_step: 3126, epoch: 79, loss: 0.691798
global_step: 3127, epoch: 79, loss: 0.657446
global_step: 3128, epoch: 79, loss: 0.696395
global_step: 3129, epoch: 79, loss: 0.621790
global_step: 3130, epoch: 79, loss: 0.606708
global_step: 3131, epoch: 79, loss: 0.675421
global_step: 3132, epoch: 79, loss: 0.661533
global_step: 3133, epoch: 79, loss: 0.727570
global_step: 3134, epoch: 79, loss: 0.598113
global_step: 3135, epoch: 79, loss: 0.758874
global_step: 3136, epoch: 79, loss: 0.700606
global_step: 3137, epoch: 79, loss: 0.692682
global_step: 3138, epoch: 79, loss: 0.676633
global_step: 3139, epoch: 79, loss: 0.697287
global_step: 3140, epoch: 79, loss: 0.649233
global_step: 3141, epoch: 79, loss: 0.748986
global_step: 3142, epoch: 79, loss: 0.655356
global_step: 3143, epoch: 79, loss: 0.681604
global_step: 3144, epoch: 79, loss: 0.601943
global_step: 3145, epoch: 79, loss: 0.703883
global_step: 3146, epoch: 79, loss: 0.674204
global_step: 3147, epoch: 79, loss: 0.639087
global_step: 3148, epoch: 79, loss: 0.746803
global_step: 3149, epoch: 79, loss: 0.663644
global_step: 3150, epoch: 79, loss: 0.617856
global_step: 3151, epoch: 79, loss: 0.760380
global_step: 3152, epoch: 79, loss: 0.700277
global_step: 3153, epoch: 79, loss: 0.726314
global_step: 3154, epoch: 79, loss: 0.759311
global_step: 3155, epoch: 79, loss: 0.685538
global_step: 3156, epoch: 79, loss: 0.676254
global_step: 3157, epoch: 79, loss: 0.716218
global_step: 3158, epoch: 79, loss: 0.667059
global_step: 3159, epoch: 79, loss: 0.792606
global_step: 3160, epoch: 79, loss: 0.464842
epoch: 79
train	acc: 0.8258	macro: p 0.7063, r 0.5689, f1: 0.5762	micro: p 0.8258, r 0.8258, f1 0.8258	weighted_f1:0.8016
dev	acc: 0.5690	macro: p 0.3610, r 0.3295, f1: 0.3308	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5227
test	acc: 0.6065	macro: p 0.3675, r 0.3304, f1: 0.3347	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5655
global_step: 3161, epoch: 80, loss: 0.618575
global_step: 3162, epoch: 80, loss: 0.801086
global_step: 3163, epoch: 80, loss: 0.619276
global_step: 3164, epoch: 80, loss: 0.540360
global_step: 3165, epoch: 80, loss: 0.605537
global_step: 3166, epoch: 80, loss: 0.678861
global_step: 3167, epoch: 80, loss: 0.554191
global_step: 3168, epoch: 80, loss: 0.673635
global_step: 3169, epoch: 80, loss: 0.626149
global_step: 3170, epoch: 80, loss: 0.716423
global_step: 3171, epoch: 80, loss: 0.702827
global_step: 3172, epoch: 80, loss: 0.692514
global_step: 3173, epoch: 80, loss: 0.561227
global_step: 3174, epoch: 80, loss: 0.708764
global_step: 3175, epoch: 80, loss: 0.590167
global_step: 3176, epoch: 80, loss: 0.687215
global_step: 3177, epoch: 80, loss: 0.652767
global_step: 3178, epoch: 80, loss: 0.680018
global_step: 3179, epoch: 80, loss: 0.645079
global_step: 3180, epoch: 80, loss: 0.685103
global_step: 3181, epoch: 80, loss: 0.644337
global_step: 3182, epoch: 80, loss: 0.639208
global_step: 3183, epoch: 80, loss: 0.599635
global_step: 3184, epoch: 80, loss: 0.752030
global_step: 3185, epoch: 80, loss: 0.651276
global_step: 3186, epoch: 80, loss: 0.625606
global_step: 3187, epoch: 80, loss: 0.700912
global_step: 3188, epoch: 80, loss: 0.669656
global_step: 3189, epoch: 80, loss: 0.747260
global_step: 3190, epoch: 80, loss: 0.726079
global_step: 3191, epoch: 80, loss: 0.775951
global_step: 3192, epoch: 80, loss: 0.613214
global_step: 3193, epoch: 80, loss: 0.713324
global_step: 3194, epoch: 80, loss: 0.712972
global_step: 3195, epoch: 80, loss: 0.767139
global_step: 3196, epoch: 80, loss: 0.678428
global_step: 3197, epoch: 80, loss: 0.711592
global_step: 3198, epoch: 80, loss: 0.691794
global_step: 3199, epoch: 80, loss: 0.741158
global_step: 3200, epoch: 80, loss: 1.710738
epoch: 80
train	acc: 0.8299	macro: p 0.7048, r 0.5801, f1: 0.5796	micro: p 0.8299, r 0.8299, f1 0.8299	weighted_f1:0.8076
dev	acc: 0.5663	macro: p 0.3545, r 0.3284, f1: 0.3301	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5218
test	acc: 0.6034	macro: p 0.3589, r 0.3287, f1: 0.3354	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5657
global_step: 3201, epoch: 81, loss: 0.551771
global_step: 3202, epoch: 81, loss: 0.640072
global_step: 3203, epoch: 81, loss: 0.710541
global_step: 3204, epoch: 81, loss: 0.665726
global_step: 3205, epoch: 81, loss: 0.667565
global_step: 3206, epoch: 81, loss: 0.668688
global_step: 3207, epoch: 81, loss: 0.807667
global_step: 3208, epoch: 81, loss: 0.684236
global_step: 3209, epoch: 81, loss: 0.627555
global_step: 3210, epoch: 81, loss: 0.701594
global_step: 3211, epoch: 81, loss: 0.687408
global_step: 3212, epoch: 81, loss: 0.624265
global_step: 3213, epoch: 81, loss: 0.741273
global_step: 3214, epoch: 81, loss: 0.730942
global_step: 3215, epoch: 81, loss: 0.643666
global_step: 3216, epoch: 81, loss: 0.601602
global_step: 3217, epoch: 81, loss: 0.649767
global_step: 3218, epoch: 81, loss: 0.656778
global_step: 3219, epoch: 81, loss: 0.761443
global_step: 3220, epoch: 81, loss: 0.648241
global_step: 3221, epoch: 81, loss: 0.660842
global_step: 3222, epoch: 81, loss: 0.757515
global_step: 3223, epoch: 81, loss: 0.556011
global_step: 3224, epoch: 81, loss: 0.621359
global_step: 3225, epoch: 81, loss: 0.773746
global_step: 3226, epoch: 81, loss: 0.779545
global_step: 3227, epoch: 81, loss: 0.623716
global_step: 3228, epoch: 81, loss: 0.660790
global_step: 3229, epoch: 81, loss: 0.606275
global_step: 3230, epoch: 81, loss: 0.594288
global_step: 3231, epoch: 81, loss: 0.605326
global_step: 3232, epoch: 81, loss: 0.660674
global_step: 3233, epoch: 81, loss: 0.695098
global_step: 3234, epoch: 81, loss: 0.613017
global_step: 3235, epoch: 81, loss: 0.568131
global_step: 3236, epoch: 81, loss: 0.697349
global_step: 3237, epoch: 81, loss: 0.616162
global_step: 3238, epoch: 81, loss: 0.681238
global_step: 3239, epoch: 81, loss: 0.671787
global_step: 3240, epoch: 81, loss: 0.608596
epoch: 81
train	acc: 0.8453	macro: p 0.7130, r 0.6040, f1: 0.6055	micro: p 0.8453, r 0.8453, f1 0.8453	weighted_f1:0.8246
dev	acc: 0.5681	macro: p 0.3549, r 0.3422, f1: 0.3389	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5293
test	acc: 0.6100	macro: p 0.3675, r 0.3485, f1: 0.3493	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5778
global_step: 3241, epoch: 82, loss: 0.706478
global_step: 3242, epoch: 82, loss: 0.706416
global_step: 3243, epoch: 82, loss: 0.639644
global_step: 3244, epoch: 82, loss: 0.563800
global_step: 3245, epoch: 82, loss: 0.576942
global_step: 3246, epoch: 82, loss: 0.650236
global_step: 3247, epoch: 82, loss: 0.655507
global_step: 3248, epoch: 82, loss: 0.598249
global_step: 3249, epoch: 82, loss: 0.614179
global_step: 3250, epoch: 82, loss: 0.648183
global_step: 3251, epoch: 82, loss: 0.634505
global_step: 3252, epoch: 82, loss: 0.661720
global_step: 3253, epoch: 82, loss: 0.623268
global_step: 3254, epoch: 82, loss: 0.628820
global_step: 3255, epoch: 82, loss: 0.742237
global_step: 3256, epoch: 82, loss: 0.618473
global_step: 3257, epoch: 82, loss: 0.702981
global_step: 3258, epoch: 82, loss: 0.586691
global_step: 3259, epoch: 82, loss: 0.644027
global_step: 3260, epoch: 82, loss: 0.660888
global_step: 3261, epoch: 82, loss: 0.683208
global_step: 3262, epoch: 82, loss: 0.686446
global_step: 3263, epoch: 82, loss: 0.713226
global_step: 3264, epoch: 82, loss: 0.561137
global_step: 3265, epoch: 82, loss: 0.619724
global_step: 3266, epoch: 82, loss: 0.636420
global_step: 3267, epoch: 82, loss: 0.687145
global_step: 3268, epoch: 82, loss: 0.627221
global_step: 3269, epoch: 82, loss: 0.710201
global_step: 3270, epoch: 82, loss: 0.631520
global_step: 3271, epoch: 82, loss: 0.644846
global_step: 3272, epoch: 82, loss: 0.728903
global_step: 3273, epoch: 82, loss: 0.605240
global_step: 3274, epoch: 82, loss: 0.754692
global_step: 3275, epoch: 82, loss: 0.690023
global_step: 3276, epoch: 82, loss: 0.602094
global_step: 3277, epoch: 82, loss: 0.689444
global_step: 3278, epoch: 82, loss: 0.590981
global_step: 3279, epoch: 82, loss: 0.709775
global_step: 3280, epoch: 82, loss: 1.585427
epoch: 82
train	acc: 0.8338	macro: p 0.7118, r 0.5816, f1: 0.5895	micro: p 0.8338, r 0.8338, f1 0.8338	weighted_f1:0.8107
dev	acc: 0.5708	macro: p 0.3679, r 0.3319, f1: 0.3316	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5239
test	acc: 0.6038	macro: p 0.4337, r 0.3280, f1: 0.3335	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5620
global_step: 3281, epoch: 83, loss: 0.705663
global_step: 3282, epoch: 83, loss: 0.636405
global_step: 3283, epoch: 83, loss: 0.706872
global_step: 3284, epoch: 83, loss: 0.709078
global_step: 3285, epoch: 83, loss: 0.631063
global_step: 3286, epoch: 83, loss: 0.712295
global_step: 3287, epoch: 83, loss: 0.631862
global_step: 3288, epoch: 83, loss: 0.629009
global_step: 3289, epoch: 83, loss: 0.690462
global_step: 3290, epoch: 83, loss: 0.706236
global_step: 3291, epoch: 83, loss: 0.654687
global_step: 3292, epoch: 83, loss: 0.551674
global_step: 3293, epoch: 83, loss: 0.604216
global_step: 3294, epoch: 83, loss: 0.678955
global_step: 3295, epoch: 83, loss: 0.566049
global_step: 3296, epoch: 83, loss: 0.702377
global_step: 3297, epoch: 83, loss: 0.643677
global_step: 3298, epoch: 83, loss: 0.596363
global_step: 3299, epoch: 83, loss: 0.695544
global_step: 3300, epoch: 83, loss: 0.600131
global_step: 3301, epoch: 83, loss: 0.631279
global_step: 3302, epoch: 83, loss: 0.662595
global_step: 3303, epoch: 83, loss: 0.739921
global_step: 3304, epoch: 83, loss: 0.664472
global_step: 3305, epoch: 83, loss: 0.671478
global_step: 3306, epoch: 83, loss: 0.658340
global_step: 3307, epoch: 83, loss: 0.578106
global_step: 3308, epoch: 83, loss: 0.723742
global_step: 3309, epoch: 83, loss: 0.599865
global_step: 3310, epoch: 83, loss: 0.682358
global_step: 3311, epoch: 83, loss: 0.532214
global_step: 3312, epoch: 83, loss: 0.666856
global_step: 3313, epoch: 83, loss: 0.615609
global_step: 3314, epoch: 83, loss: 0.644850
global_step: 3315, epoch: 83, loss: 0.691194
global_step: 3316, epoch: 83, loss: 0.622405
global_step: 3317, epoch: 83, loss: 0.680172
global_step: 3318, epoch: 83, loss: 0.650780
global_step: 3319, epoch: 83, loss: 0.651870
global_step: 3320, epoch: 83, loss: 0.195423
epoch: 83
train	acc: 0.8372	macro: p 0.7055, r 0.5877, f1: 0.5939	micro: p 0.8372, r 0.8372, f1 0.8372	weighted_f1:0.8142
dev	acc: 0.5591	macro: p 0.3503, r 0.3282, f1: 0.3207	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5110
test	acc: 0.6019	macro: p 0.5039, r 0.3305, f1: 0.3307	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5597
global_step: 3321, epoch: 84, loss: 0.729822
global_step: 3322, epoch: 84, loss: 0.571258
global_step: 3323, epoch: 84, loss: 0.490721
global_step: 3324, epoch: 84, loss: 0.497483
global_step: 3325, epoch: 84, loss: 0.606703
global_step: 3326, epoch: 84, loss: 0.710357
global_step: 3327, epoch: 84, loss: 0.545395
global_step: 3328, epoch: 84, loss: 0.748438
global_step: 3329, epoch: 84, loss: 0.512988
global_step: 3330, epoch: 84, loss: 0.587252
global_step: 3331, epoch: 84, loss: 0.663363
global_step: 3332, epoch: 84, loss: 0.605571
global_step: 3333, epoch: 84, loss: 0.663215
global_step: 3334, epoch: 84, loss: 0.674362
global_step: 3335, epoch: 84, loss: 0.612866
global_step: 3336, epoch: 84, loss: 0.676434
global_step: 3337, epoch: 84, loss: 0.570857
global_step: 3338, epoch: 84, loss: 0.647029
global_step: 3339, epoch: 84, loss: 0.702735
global_step: 3340, epoch: 84, loss: 0.588302
global_step: 3341, epoch: 84, loss: 0.643966
global_step: 3342, epoch: 84, loss: 0.645398
global_step: 3343, epoch: 84, loss: 0.609793
global_step: 3344, epoch: 84, loss: 0.647262
global_step: 3345, epoch: 84, loss: 0.719769
global_step: 3346, epoch: 84, loss: 0.851624
global_step: 3347, epoch: 84, loss: 0.618223
global_step: 3348, epoch: 84, loss: 0.685861
global_step: 3349, epoch: 84, loss: 0.588850
global_step: 3350, epoch: 84, loss: 0.640558
global_step: 3351, epoch: 84, loss: 0.576734
global_step: 3352, epoch: 84, loss: 0.686063
global_step: 3353, epoch: 84, loss: 0.586373
global_step: 3354, epoch: 84, loss: 0.638543
global_step: 3355, epoch: 84, loss: 0.775057
global_step: 3356, epoch: 84, loss: 0.662108
global_step: 3357, epoch: 84, loss: 0.645119
global_step: 3358, epoch: 84, loss: 0.581549
global_step: 3359, epoch: 84, loss: 0.582282
global_step: 3360, epoch: 84, loss: 1.050858
epoch: 84
train	acc: 0.8206	macro: p 0.7160, r 0.5602, f1: 0.5727	micro: p 0.8206, r 0.8206, f1 0.8206	weighted_f1:0.7954
dev	acc: 0.5690	macro: p 0.3723, r 0.3229, f1: 0.3284	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5179
test	acc: 0.6065	macro: p 0.3643, r 0.3175, f1: 0.3254	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5584
global_step: 3361, epoch: 85, loss: 0.691222
global_step: 3362, epoch: 85, loss: 0.583057
global_step: 3363, epoch: 85, loss: 0.578071
global_step: 3364, epoch: 85, loss: 0.600456
global_step: 3365, epoch: 85, loss: 0.574479
global_step: 3366, epoch: 85, loss: 0.574341
global_step: 3367, epoch: 85, loss: 0.557027
global_step: 3368, epoch: 85, loss: 0.659272
global_step: 3369, epoch: 85, loss: 0.630628
global_step: 3370, epoch: 85, loss: 0.566661
global_step: 3371, epoch: 85, loss: 0.601670
global_step: 3372, epoch: 85, loss: 0.641242
global_step: 3373, epoch: 85, loss: 0.730801
global_step: 3374, epoch: 85, loss: 0.663764
global_step: 3375, epoch: 85, loss: 0.633051
global_step: 3376, epoch: 85, loss: 0.707378
global_step: 3377, epoch: 85, loss: 0.612778
global_step: 3378, epoch: 85, loss: 0.653039
global_step: 3379, epoch: 85, loss: 0.727764
global_step: 3380, epoch: 85, loss: 0.668375
global_step: 3381, epoch: 85, loss: 0.636720
global_step: 3382, epoch: 85, loss: 0.680905
global_step: 3383, epoch: 85, loss: 0.568672
global_step: 3384, epoch: 85, loss: 0.568814
global_step: 3385, epoch: 85, loss: 0.589445
global_step: 3386, epoch: 85, loss: 0.579268
global_step: 3387, epoch: 85, loss: 0.662556
global_step: 3388, epoch: 85, loss: 0.633932
global_step: 3389, epoch: 85, loss: 0.533450
global_step: 3390, epoch: 85, loss: 0.682294
global_step: 3391, epoch: 85, loss: 0.577358
global_step: 3392, epoch: 85, loss: 0.646352
global_step: 3393, epoch: 85, loss: 0.711664
global_step: 3394, epoch: 85, loss: 0.679118
global_step: 3395, epoch: 85, loss: 0.603068
global_step: 3396, epoch: 85, loss: 0.652116
global_step: 3397, epoch: 85, loss: 0.693787
global_step: 3398, epoch: 85, loss: 0.690131
global_step: 3399, epoch: 85, loss: 0.780860
global_step: 3400, epoch: 85, loss: 0.392130
epoch: 85
train	acc: 0.8457	macro: p 0.8622, r 0.6001, f1: 0.5976	micro: p 0.8457, r 0.8457, f1 0.8457	weighted_f1:0.8257
dev	acc: 0.5735	macro: p 0.3689, r 0.3450, f1: 0.3440	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5355
test	acc: 0.6057	macro: p 0.3645, r 0.3452, f1: 0.3453	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5753
global_step: 3401, epoch: 86, loss: 0.631079
global_step: 3402, epoch: 86, loss: 0.574234
global_step: 3403, epoch: 86, loss: 0.698023
global_step: 3404, epoch: 86, loss: 0.592972
global_step: 3405, epoch: 86, loss: 0.625411
global_step: 3406, epoch: 86, loss: 0.688868
global_step: 3407, epoch: 86, loss: 0.664539
global_step: 3408, epoch: 86, loss: 0.613366
global_step: 3409, epoch: 86, loss: 0.700255
global_step: 3410, epoch: 86, loss: 0.647652
global_step: 3411, epoch: 86, loss: 0.615840
global_step: 3412, epoch: 86, loss: 0.583253
global_step: 3413, epoch: 86, loss: 0.583294
global_step: 3414, epoch: 86, loss: 0.607485
global_step: 3415, epoch: 86, loss: 0.655250
global_step: 3416, epoch: 86, loss: 0.648968
global_step: 3417, epoch: 86, loss: 0.551169
global_step: 3418, epoch: 86, loss: 0.646497
global_step: 3419, epoch: 86, loss: 0.622910
global_step: 3420, epoch: 86, loss: 0.612454
global_step: 3421, epoch: 86, loss: 0.739589
global_step: 3422, epoch: 86, loss: 0.613177
global_step: 3423, epoch: 86, loss: 0.703041
global_step: 3424, epoch: 86, loss: 0.663482
global_step: 3425, epoch: 86, loss: 0.624604
global_step: 3426, epoch: 86, loss: 0.631535
global_step: 3427, epoch: 86, loss: 0.650814
global_step: 3428, epoch: 86, loss: 0.585993
global_step: 3429, epoch: 86, loss: 0.602600
global_step: 3430, epoch: 86, loss: 0.607227
global_step: 3431, epoch: 86, loss: 0.490224
global_step: 3432, epoch: 86, loss: 0.585954
global_step: 3433, epoch: 86, loss: 0.653081
global_step: 3434, epoch: 86, loss: 0.602003
global_step: 3435, epoch: 86, loss: 0.650754
global_step: 3436, epoch: 86, loss: 0.581983
global_step: 3437, epoch: 86, loss: 0.550139
global_step: 3438, epoch: 86, loss: 0.575264
global_step: 3439, epoch: 86, loss: 0.672940
global_step: 3440, epoch: 86, loss: 0.676513
epoch: 86
train	acc: 0.8501	macro: p 0.8576, r 0.6148, f1: 0.6269	micro: p 0.8501, r 0.8501, f1 0.8501	weighted_f1:0.8303
dev	acc: 0.5672	macro: p 0.3596, r 0.3323, f1: 0.3310	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5211
test	acc: 0.6046	macro: p 0.4085, r 0.3328, f1: 0.3375	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5649
global_step: 3441, epoch: 87, loss: 0.563665
global_step: 3442, epoch: 87, loss: 0.533700
global_step: 3443, epoch: 87, loss: 0.630652
global_step: 3444, epoch: 87, loss: 0.625710
global_step: 3445, epoch: 87, loss: 0.579308
global_step: 3446, epoch: 87, loss: 0.552353
global_step: 3447, epoch: 87, loss: 0.567891
global_step: 3448, epoch: 87, loss: 0.555814
global_step: 3449, epoch: 87, loss: 0.538056
global_step: 3450, epoch: 87, loss: 0.635683
global_step: 3451, epoch: 87, loss: 0.618829
global_step: 3452, epoch: 87, loss: 0.637663
global_step: 3453, epoch: 87, loss: 0.641377
global_step: 3454, epoch: 87, loss: 0.511023
global_step: 3455, epoch: 87, loss: 0.612413
global_step: 3456, epoch: 87, loss: 0.731713
global_step: 3457, epoch: 87, loss: 0.551189
global_step: 3458, epoch: 87, loss: 0.567215
global_step: 3459, epoch: 87, loss: 0.500820
global_step: 3460, epoch: 87, loss: 0.659919
global_step: 3461, epoch: 87, loss: 0.589157
global_step: 3462, epoch: 87, loss: 0.547119
global_step: 3463, epoch: 87, loss: 0.679381
global_step: 3464, epoch: 87, loss: 0.666499
global_step: 3465, epoch: 87, loss: 0.734344
global_step: 3466, epoch: 87, loss: 0.698948
global_step: 3467, epoch: 87, loss: 0.690484
global_step: 3468, epoch: 87, loss: 0.666190
global_step: 3469, epoch: 87, loss: 0.639029
global_step: 3470, epoch: 87, loss: 0.617216
global_step: 3471, epoch: 87, loss: 0.579585
global_step: 3472, epoch: 87, loss: 0.601473
global_step: 3473, epoch: 87, loss: 0.637909
global_step: 3474, epoch: 87, loss: 0.699486
global_step: 3475, epoch: 87, loss: 0.535685
global_step: 3476, epoch: 87, loss: 0.673633
global_step: 3477, epoch: 87, loss: 0.661964
global_step: 3478, epoch: 87, loss: 0.588915
global_step: 3479, epoch: 87, loss: 0.637226
global_step: 3480, epoch: 87, loss: 0.618701
epoch: 87
train	acc: 0.8481	macro: p 0.8599, r 0.6139, f1: 0.6293	micro: p 0.8481, r 0.8481, f1 0.8481	weighted_f1:0.8284
dev	acc: 0.5672	macro: p 0.3599, r 0.3284, f1: 0.3281	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5179
test	acc: 0.5992	macro: p 0.3986, r 0.3244, f1: 0.3286	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5557
global_step: 3481, epoch: 88, loss: 0.581653
global_step: 3482, epoch: 88, loss: 0.667371
global_step: 3483, epoch: 88, loss: 0.549805
global_step: 3484, epoch: 88, loss: 0.603407
global_step: 3485, epoch: 88, loss: 0.512012
global_step: 3486, epoch: 88, loss: 0.460064
global_step: 3487, epoch: 88, loss: 0.649245
global_step: 3488, epoch: 88, loss: 0.707126
global_step: 3489, epoch: 88, loss: 0.628100
global_step: 3490, epoch: 88, loss: 0.625164
global_step: 3491, epoch: 88, loss: 0.601605
global_step: 3492, epoch: 88, loss: 0.757435
global_step: 3493, epoch: 88, loss: 0.645372
global_step: 3494, epoch: 88, loss: 0.568325
global_step: 3495, epoch: 88, loss: 0.623535
global_step: 3496, epoch: 88, loss: 0.611926
global_step: 3497, epoch: 88, loss: 0.636798
global_step: 3498, epoch: 88, loss: 0.643688
global_step: 3499, epoch: 88, loss: 0.590540
global_step: 3500, epoch: 88, loss: 0.621890
global_step: 3501, epoch: 88, loss: 0.555115
global_step: 3502, epoch: 88, loss: 0.682876
global_step: 3503, epoch: 88, loss: 0.591743
global_step: 3504, epoch: 88, loss: 0.536610
global_step: 3505, epoch: 88, loss: 0.590122
global_step: 3506, epoch: 88, loss: 0.630526
global_step: 3507, epoch: 88, loss: 0.591834
global_step: 3508, epoch: 88, loss: 0.531880
global_step: 3509, epoch: 88, loss: 0.700836
global_step: 3510, epoch: 88, loss: 0.677800
global_step: 3511, epoch: 88, loss: 0.673084
global_step: 3512, epoch: 88, loss: 0.691147
global_step: 3513, epoch: 88, loss: 0.616319
global_step: 3514, epoch: 88, loss: 0.658622
global_step: 3515, epoch: 88, loss: 0.619231
global_step: 3516, epoch: 88, loss: 0.685303
global_step: 3517, epoch: 88, loss: 0.631308
global_step: 3518, epoch: 88, loss: 0.502636
global_step: 3519, epoch: 88, loss: 0.677639
global_step: 3520, epoch: 88, loss: 0.049417
epoch: 88
train	acc: 0.8542	macro: p 0.8633, r 0.6171, f1: 0.6242	micro: p 0.8542, r 0.8542, f1 0.8542	weighted_f1:0.8344
dev	acc: 0.5663	macro: p 0.3656, r 0.3378, f1: 0.3366	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5257
test	acc: 0.6050	macro: p 0.4085, r 0.3362, f1: 0.3393	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5677
global_step: 3521, epoch: 89, loss: 0.551244
global_step: 3522, epoch: 89, loss: 0.592205
global_step: 3523, epoch: 89, loss: 0.561592
global_step: 3524, epoch: 89, loss: 0.586610
global_step: 3525, epoch: 89, loss: 0.755163
global_step: 3526, epoch: 89, loss: 0.680802
global_step: 3527, epoch: 89, loss: 0.569484
global_step: 3528, epoch: 89, loss: 0.661921
global_step: 3529, epoch: 89, loss: 0.621590
global_step: 3530, epoch: 89, loss: 0.526416
global_step: 3531, epoch: 89, loss: 0.565907
global_step: 3532, epoch: 89, loss: 0.547130
global_step: 3533, epoch: 89, loss: 0.561216
global_step: 3534, epoch: 89, loss: 0.709409
global_step: 3535, epoch: 89, loss: 0.683685
global_step: 3536, epoch: 89, loss: 0.580885
global_step: 3537, epoch: 89, loss: 0.620843
global_step: 3538, epoch: 89, loss: 0.610545
global_step: 3539, epoch: 89, loss: 0.628624
global_step: 3540, epoch: 89, loss: 0.724921
global_step: 3541, epoch: 89, loss: 0.571076
global_step: 3542, epoch: 89, loss: 0.629682
global_step: 3543, epoch: 89, loss: 0.687075
global_step: 3544, epoch: 89, loss: 0.700891
global_step: 3545, epoch: 89, loss: 0.755929
global_step: 3546, epoch: 89, loss: 0.616504
global_step: 3547, epoch: 89, loss: 0.535304
global_step: 3548, epoch: 89, loss: 0.635813
global_step: 3549, epoch: 89, loss: 0.580843
global_step: 3550, epoch: 89, loss: 0.600940
global_step: 3551, epoch: 89, loss: 0.530638
global_step: 3552, epoch: 89, loss: 0.603700
global_step: 3553, epoch: 89, loss: 0.642304
global_step: 3554, epoch: 89, loss: 0.498825
global_step: 3555, epoch: 89, loss: 0.621786
global_step: 3556, epoch: 89, loss: 0.692530
global_step: 3557, epoch: 89, loss: 0.509303
global_step: 3558, epoch: 89, loss: 0.467952
global_step: 3559, epoch: 89, loss: 0.572657
global_step: 3560, epoch: 89, loss: 0.442131
epoch: 89
train	acc: 0.8583	macro: p 0.8676, r 0.6249, f1: 0.6347	micro: p 0.8583, r 0.8583, f1 0.8583	weighted_f1:0.8391
dev	acc: 0.5555	macro: p 0.3492, r 0.3271, f1: 0.3223	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5130
test	acc: 0.6061	macro: p 0.4100, r 0.3379, f1: 0.3397	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5690
global_step: 3561, epoch: 90, loss: 0.517938
global_step: 3562, epoch: 90, loss: 0.619926
global_step: 3563, epoch: 90, loss: 0.619995
global_step: 3564, epoch: 90, loss: 0.516685
global_step: 3565, epoch: 90, loss: 0.619795
global_step: 3566, epoch: 90, loss: 0.571823
global_step: 3567, epoch: 90, loss: 0.562213
global_step: 3568, epoch: 90, loss: 0.668503
global_step: 3569, epoch: 90, loss: 0.637921
global_step: 3570, epoch: 90, loss: 0.556163
global_step: 3571, epoch: 90, loss: 0.588104
global_step: 3572, epoch: 90, loss: 0.618775
global_step: 3573, epoch: 90, loss: 0.674162
global_step: 3574, epoch: 90, loss: 0.580138
global_step: 3575, epoch: 90, loss: 0.605947
global_step: 3576, epoch: 90, loss: 0.615103
global_step: 3577, epoch: 90, loss: 0.523786
global_step: 3578, epoch: 90, loss: 0.477526
global_step: 3579, epoch: 90, loss: 0.726538
global_step: 3580, epoch: 90, loss: 0.625584
global_step: 3581, epoch: 90, loss: 0.670566
global_step: 3582, epoch: 90, loss: 0.634648
global_step: 3583, epoch: 90, loss: 0.563455
global_step: 3584, epoch: 90, loss: 0.634335
global_step: 3585, epoch: 90, loss: 0.699704
global_step: 3586, epoch: 90, loss: 0.640626
global_step: 3587, epoch: 90, loss: 0.511504
global_step: 3588, epoch: 90, loss: 0.549487
global_step: 3589, epoch: 90, loss: 0.643491
global_step: 3590, epoch: 90, loss: 0.674350
global_step: 3591, epoch: 90, loss: 0.677533
global_step: 3592, epoch: 90, loss: 0.549483
global_step: 3593, epoch: 90, loss: 0.587126
global_step: 3594, epoch: 90, loss: 0.600637
global_step: 3595, epoch: 90, loss: 0.653082
global_step: 3596, epoch: 90, loss: 0.679999
global_step: 3597, epoch: 90, loss: 0.553570
global_step: 3598, epoch: 90, loss: 0.599781
global_step: 3599, epoch: 90, loss: 0.572570
global_step: 3600, epoch: 90, loss: 0.387302
epoch: 90
train	acc: 0.8681	macro: p 0.8631, r 0.6442, f1: 0.6423	micro: p 0.8681, r 0.8681, f1 0.8681	weighted_f1:0.8513
dev	acc: 0.5482	macro: p 0.3400, r 0.3453, f1: 0.3366	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5219
test	acc: 0.5946	macro: p 0.3486, r 0.3609, f1: 0.3510	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5764
global_step: 3601, epoch: 91, loss: 0.565934
global_step: 3602, epoch: 91, loss: 0.574002
global_step: 3603, epoch: 91, loss: 0.467562
global_step: 3604, epoch: 91, loss: 0.656577
global_step: 3605, epoch: 91, loss: 0.626893
global_step: 3606, epoch: 91, loss: 0.616027
global_step: 3607, epoch: 91, loss: 0.620757
global_step: 3608, epoch: 91, loss: 0.606964
global_step: 3609, epoch: 91, loss: 0.615172
global_step: 3610, epoch: 91, loss: 0.612515
global_step: 3611, epoch: 91, loss: 0.501767
global_step: 3612, epoch: 91, loss: 0.554016
global_step: 3613, epoch: 91, loss: 0.649188
global_step: 3614, epoch: 91, loss: 0.587807
global_step: 3615, epoch: 91, loss: 0.533855
global_step: 3616, epoch: 91, loss: 0.595423
global_step: 3617, epoch: 91, loss: 0.645161
global_step: 3618, epoch: 91, loss: 0.654229
global_step: 3619, epoch: 91, loss: 0.506387
global_step: 3620, epoch: 91, loss: 0.668773
global_step: 3621, epoch: 91, loss: 0.692175
global_step: 3622, epoch: 91, loss: 0.507199
global_step: 3623, epoch: 91, loss: 0.590136
global_step: 3624, epoch: 91, loss: 0.641620
global_step: 3625, epoch: 91, loss: 0.634786
global_step: 3626, epoch: 91, loss: 0.533737
global_step: 3627, epoch: 91, loss: 0.633476
global_step: 3628, epoch: 91, loss: 0.570030
global_step: 3629, epoch: 91, loss: 0.707288
global_step: 3630, epoch: 91, loss: 0.623711
global_step: 3631, epoch: 91, loss: 0.600597
global_step: 3632, epoch: 91, loss: 0.673863
global_step: 3633, epoch: 91, loss: 0.690705
global_step: 3634, epoch: 91, loss: 0.592670
global_step: 3635, epoch: 91, loss: 0.489939
global_step: 3636, epoch: 91, loss: 0.459463
global_step: 3637, epoch: 91, loss: 0.563788
global_step: 3638, epoch: 91, loss: 0.616606
global_step: 3639, epoch: 91, loss: 0.535298
global_step: 3640, epoch: 91, loss: 0.324333
epoch: 91
train	acc: 0.8721	macro: p 0.8649, r 0.6542, f1: 0.6559	micro: p 0.8721, r 0.8721, f1 0.8721	weighted_f1:0.8551
dev	acc: 0.5681	macro: p 0.3538, r 0.3455, f1: 0.3440	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5332
test	acc: 0.6073	macro: p 0.4045, r 0.3510, f1: 0.3536	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5789
global_step: 3641, epoch: 92, loss: 0.584813
global_step: 3642, epoch: 92, loss: 0.631652
global_step: 3643, epoch: 92, loss: 0.577009
global_step: 3644, epoch: 92, loss: 0.540126
global_step: 3645, epoch: 92, loss: 0.524270
global_step: 3646, epoch: 92, loss: 0.558356
global_step: 3647, epoch: 92, loss: 0.662163
global_step: 3648, epoch: 92, loss: 0.578805
global_step: 3649, epoch: 92, loss: 0.535372
global_step: 3650, epoch: 92, loss: 0.566163
global_step: 3651, epoch: 92, loss: 0.639386
global_step: 3652, epoch: 92, loss: 0.615847
global_step: 3653, epoch: 92, loss: 0.627551
global_step: 3654, epoch: 92, loss: 0.624069
global_step: 3655, epoch: 92, loss: 0.567502
global_step: 3656, epoch: 92, loss: 0.577358
global_step: 3657, epoch: 92, loss: 0.502940
global_step: 3658, epoch: 92, loss: 0.586244
global_step: 3659, epoch: 92, loss: 0.517357
global_step: 3660, epoch: 92, loss: 0.574946
global_step: 3661, epoch: 92, loss: 0.564211
global_step: 3662, epoch: 92, loss: 0.621679
global_step: 3663, epoch: 92, loss: 0.688727
global_step: 3664, epoch: 92, loss: 0.597829
global_step: 3665, epoch: 92, loss: 0.563902
global_step: 3666, epoch: 92, loss: 0.651392
global_step: 3667, epoch: 92, loss: 0.651198
global_step: 3668, epoch: 92, loss: 0.606454
global_step: 3669, epoch: 92, loss: 0.692419
global_step: 3670, epoch: 92, loss: 0.597380
global_step: 3671, epoch: 92, loss: 0.641921
global_step: 3672, epoch: 92, loss: 0.497661
global_step: 3673, epoch: 92, loss: 0.624812
global_step: 3674, epoch: 92, loss: 0.631818
global_step: 3675, epoch: 92, loss: 0.570498
global_step: 3676, epoch: 92, loss: 0.524857
global_step: 3677, epoch: 92, loss: 0.548410
global_step: 3678, epoch: 92, loss: 0.578656
global_step: 3679, epoch: 92, loss: 0.648079
global_step: 3680, epoch: 92, loss: 0.802859
epoch: 92
train	acc: 0.8748	macro: p 0.8685, r 0.6576, f1: 0.6614	micro: p 0.8748, r 0.8748, f1 0.8748	weighted_f1:0.8581
dev	acc: 0.5564	macro: p 0.4894, r 0.3416, f1: 0.3444	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5218
test	acc: 0.5989	macro: p 0.4213, r 0.3434, f1: 0.3442	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5687
global_step: 3681, epoch: 93, loss: 0.618825
global_step: 3682, epoch: 93, loss: 0.616287
global_step: 3683, epoch: 93, loss: 0.629217
global_step: 3684, epoch: 93, loss: 0.538979
global_step: 3685, epoch: 93, loss: 0.510657
global_step: 3686, epoch: 93, loss: 0.624324
global_step: 3687, epoch: 93, loss: 0.606118
global_step: 3688, epoch: 93, loss: 0.542608
global_step: 3689, epoch: 93, loss: 0.539420
global_step: 3690, epoch: 93, loss: 0.587484
global_step: 3691, epoch: 93, loss: 0.528565
global_step: 3692, epoch: 93, loss: 0.581114
global_step: 3693, epoch: 93, loss: 0.620716
global_step: 3694, epoch: 93, loss: 0.635058
global_step: 3695, epoch: 93, loss: 0.557476
global_step: 3696, epoch: 93, loss: 0.605909
global_step: 3697, epoch: 93, loss: 0.586196
global_step: 3698, epoch: 93, loss: 0.569231
global_step: 3699, epoch: 93, loss: 0.625248
global_step: 3700, epoch: 93, loss: 0.668960
global_step: 3701, epoch: 93, loss: 0.742873
global_step: 3702, epoch: 93, loss: 0.560876
global_step: 3703, epoch: 93, loss: 0.537039
global_step: 3704, epoch: 93, loss: 0.570022
global_step: 3705, epoch: 93, loss: 0.569962
global_step: 3706, epoch: 93, loss: 0.547006
global_step: 3707, epoch: 93, loss: 0.625441
global_step: 3708, epoch: 93, loss: 0.575139
global_step: 3709, epoch: 93, loss: 0.565802
global_step: 3710, epoch: 93, loss: 0.560031
global_step: 3711, epoch: 93, loss: 0.574087
global_step: 3712, epoch: 93, loss: 0.576697
global_step: 3713, epoch: 93, loss: 0.538455
global_step: 3714, epoch: 93, loss: 0.560731
global_step: 3715, epoch: 93, loss: 0.522914
global_step: 3716, epoch: 93, loss: 0.599203
global_step: 3717, epoch: 93, loss: 0.661176
global_step: 3718, epoch: 93, loss: 0.544383
global_step: 3719, epoch: 93, loss: 0.576315
global_step: 3720, epoch: 93, loss: 0.495892
epoch: 93
train	acc: 0.8637	macro: p 0.8683, r 0.6370, f1: 0.6464	micro: p 0.8637, r 0.8637, f1 0.8637	weighted_f1:0.8452
dev	acc: 0.5672	macro: p 0.3578, r 0.3302, f1: 0.3319	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5228
test	acc: 0.6061	macro: p 0.4338, r 0.3330, f1: 0.3398	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5667
global_step: 3721, epoch: 94, loss: 0.591036
global_step: 3722, epoch: 94, loss: 0.549876
global_step: 3723, epoch: 94, loss: 0.537867
global_step: 3724, epoch: 94, loss: 0.496823
global_step: 3725, epoch: 94, loss: 0.616451
global_step: 3726, epoch: 94, loss: 0.601527
global_step: 3727, epoch: 94, loss: 0.583821
global_step: 3728, epoch: 94, loss: 0.502465
global_step: 3729, epoch: 94, loss: 0.587146
global_step: 3730, epoch: 94, loss: 0.572644
global_step: 3731, epoch: 94, loss: 0.663431
global_step: 3732, epoch: 94, loss: 0.679228
global_step: 3733, epoch: 94, loss: 0.590660
global_step: 3734, epoch: 94, loss: 0.544244
global_step: 3735, epoch: 94, loss: 0.551026
global_step: 3736, epoch: 94, loss: 0.627446
global_step: 3737, epoch: 94, loss: 0.524482
global_step: 3738, epoch: 94, loss: 0.536042
global_step: 3739, epoch: 94, loss: 0.584143
global_step: 3740, epoch: 94, loss: 0.549225
global_step: 3741, epoch: 94, loss: 0.503136
global_step: 3742, epoch: 94, loss: 0.601706
global_step: 3743, epoch: 94, loss: 0.539171
global_step: 3744, epoch: 94, loss: 0.601894
global_step: 3745, epoch: 94, loss: 0.622297
global_step: 3746, epoch: 94, loss: 0.569093
global_step: 3747, epoch: 94, loss: 0.569678
global_step: 3748, epoch: 94, loss: 0.641473
global_step: 3749, epoch: 94, loss: 0.529683
global_step: 3750, epoch: 94, loss: 0.592966
global_step: 3751, epoch: 94, loss: 0.561775
global_step: 3752, epoch: 94, loss: 0.491959
global_step: 3753, epoch: 94, loss: 0.572166
global_step: 3754, epoch: 94, loss: 0.639621
global_step: 3755, epoch: 94, loss: 0.572070
global_step: 3756, epoch: 94, loss: 0.552930
global_step: 3757, epoch: 94, loss: 0.617633
global_step: 3758, epoch: 94, loss: 0.594163
global_step: 3759, epoch: 94, loss: 0.473655
global_step: 3760, epoch: 94, loss: 0.446729
epoch: 94
train	acc: 0.8766	macro: p 0.8690, r 0.6652, f1: 0.6658	micro: p 0.8766, r 0.8766, f1 0.8766	weighted_f1:0.8610
dev	acc: 0.5600	macro: p 0.3472, r 0.3508, f1: 0.3448	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5323
test	acc: 0.5989	macro: p 0.3839, r 0.3612, f1: 0.3558	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5797
global_step: 3761, epoch: 95, loss: 0.658040
global_step: 3762, epoch: 95, loss: 0.466370
global_step: 3763, epoch: 95, loss: 0.522405
global_step: 3764, epoch: 95, loss: 0.544743
global_step: 3765, epoch: 95, loss: 0.539389
global_step: 3766, epoch: 95, loss: 0.518652
global_step: 3767, epoch: 95, loss: 0.493544
global_step: 3768, epoch: 95, loss: 0.498092
global_step: 3769, epoch: 95, loss: 0.621919
global_step: 3770, epoch: 95, loss: 0.603984
global_step: 3771, epoch: 95, loss: 0.572126
global_step: 3772, epoch: 95, loss: 0.526266
global_step: 3773, epoch: 95, loss: 0.557259
global_step: 3774, epoch: 95, loss: 0.661781
global_step: 3775, epoch: 95, loss: 0.578937
global_step: 3776, epoch: 95, loss: 0.458547
global_step: 3777, epoch: 95, loss: 0.538670
global_step: 3778, epoch: 95, loss: 0.459260
global_step: 3779, epoch: 95, loss: 0.717108
global_step: 3780, epoch: 95, loss: 0.587371
global_step: 3781, epoch: 95, loss: 0.556762
global_step: 3782, epoch: 95, loss: 0.585412
global_step: 3783, epoch: 95, loss: 0.549626
global_step: 3784, epoch: 95, loss: 0.577878
global_step: 3785, epoch: 95, loss: 0.513344
global_step: 3786, epoch: 95, loss: 0.590870
global_step: 3787, epoch: 95, loss: 0.513478
global_step: 3788, epoch: 95, loss: 0.584977
global_step: 3789, epoch: 95, loss: 0.653320
global_step: 3790, epoch: 95, loss: 0.580434
global_step: 3791, epoch: 95, loss: 0.495458
global_step: 3792, epoch: 95, loss: 0.604956
global_step: 3793, epoch: 95, loss: 0.577019
global_step: 3794, epoch: 95, loss: 0.566120
global_step: 3795, epoch: 95, loss: 0.664829
global_step: 3796, epoch: 95, loss: 0.602379
global_step: 3797, epoch: 95, loss: 0.554416
global_step: 3798, epoch: 95, loss: 0.511179
global_step: 3799, epoch: 95, loss: 0.495236
global_step: 3800, epoch: 95, loss: 1.314567
epoch: 95
train	acc: 0.8837	macro: p 0.8450, r 0.6842, f1: 0.6908	micro: p 0.8837, r 0.8837, f1 0.8837	weighted_f1:0.8697
dev	acc: 0.5573	macro: p 0.4181, r 0.3471, f1: 0.3485	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5251
test	acc: 0.5950	macro: p 0.3879, r 0.3462, f1: 0.3478	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5676
global_step: 3801, epoch: 96, loss: 0.565698
global_step: 3802, epoch: 96, loss: 0.508819
global_step: 3803, epoch: 96, loss: 0.501418
global_step: 3804, epoch: 96, loss: 0.441874
global_step: 3805, epoch: 96, loss: 0.522376
global_step: 3806, epoch: 96, loss: 0.545360
global_step: 3807, epoch: 96, loss: 0.516509
global_step: 3808, epoch: 96, loss: 0.519206
global_step: 3809, epoch: 96, loss: 0.558973
global_step: 3810, epoch: 96, loss: 0.554391
global_step: 3811, epoch: 96, loss: 0.591108
global_step: 3812, epoch: 96, loss: 0.444509
global_step: 3813, epoch: 96, loss: 0.535556
global_step: 3814, epoch: 96, loss: 0.615373
global_step: 3815, epoch: 96, loss: 0.617739
global_step: 3816, epoch: 96, loss: 0.590535
global_step: 3817, epoch: 96, loss: 0.630483
global_step: 3818, epoch: 96, loss: 0.577738
global_step: 3819, epoch: 96, loss: 0.516385
global_step: 3820, epoch: 96, loss: 0.627270
global_step: 3821, epoch: 96, loss: 0.551913
global_step: 3822, epoch: 96, loss: 0.493823
global_step: 3823, epoch: 96, loss: 0.608174
global_step: 3824, epoch: 96, loss: 0.605527
global_step: 3825, epoch: 96, loss: 0.537703
global_step: 3826, epoch: 96, loss: 0.528889
global_step: 3827, epoch: 96, loss: 0.602401
global_step: 3828, epoch: 96, loss: 0.525017
global_step: 3829, epoch: 96, loss: 0.625644
global_step: 3830, epoch: 96, loss: 0.487653
global_step: 3831, epoch: 96, loss: 0.583022
global_step: 3832, epoch: 96, loss: 0.604754
global_step: 3833, epoch: 96, loss: 0.600415
global_step: 3834, epoch: 96, loss: 0.565285
global_step: 3835, epoch: 96, loss: 0.593422
global_step: 3836, epoch: 96, loss: 0.556469
global_step: 3837, epoch: 96, loss: 0.594464
global_step: 3838, epoch: 96, loss: 0.638056
global_step: 3839, epoch: 96, loss: 0.551018
global_step: 3840, epoch: 96, loss: 0.984684
epoch: 96
train	acc: 0.8797	macro: p 0.8413, r 0.6809, f1: 0.6900	micro: p 0.8797, r 0.8797, f1 0.8797	weighted_f1:0.8658
dev	acc: 0.5437	macro: p 0.4141, r 0.3360, f1: 0.3324	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5102
test	acc: 0.5851	macro: p 0.3750, r 0.3396, f1: 0.3350	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5559
global_step: 3841, epoch: 97, loss: 0.594025
global_step: 3842, epoch: 97, loss: 0.484229
global_step: 3843, epoch: 97, loss: 0.556805
global_step: 3844, epoch: 97, loss: 0.557510
global_step: 3845, epoch: 97, loss: 0.526200
global_step: 3846, epoch: 97, loss: 0.524165
global_step: 3847, epoch: 97, loss: 0.478567
global_step: 3848, epoch: 97, loss: 0.566651
global_step: 3849, epoch: 97, loss: 0.485576
global_step: 3850, epoch: 97, loss: 0.510620
global_step: 3851, epoch: 97, loss: 0.559719
global_step: 3852, epoch: 97, loss: 0.571784
global_step: 3853, epoch: 97, loss: 0.498702
global_step: 3854, epoch: 97, loss: 0.488271
global_step: 3855, epoch: 97, loss: 0.530858
global_step: 3856, epoch: 97, loss: 0.585033
global_step: 3857, epoch: 97, loss: 0.525277
global_step: 3858, epoch: 97, loss: 0.557585
global_step: 3859, epoch: 97, loss: 0.534503
global_step: 3860, epoch: 97, loss: 0.543862
global_step: 3861, epoch: 97, loss: 0.663746
global_step: 3862, epoch: 97, loss: 0.520263
global_step: 3863, epoch: 97, loss: 0.547623
global_step: 3864, epoch: 97, loss: 0.545476
global_step: 3865, epoch: 97, loss: 0.550124
global_step: 3866, epoch: 97, loss: 0.518404
global_step: 3867, epoch: 97, loss: 0.620497
global_step: 3868, epoch: 97, loss: 0.619125
global_step: 3869, epoch: 97, loss: 0.625596
global_step: 3870, epoch: 97, loss: 0.475458
global_step: 3871, epoch: 97, loss: 0.545277
global_step: 3872, epoch: 97, loss: 0.647110
global_step: 3873, epoch: 97, loss: 0.641466
global_step: 3874, epoch: 97, loss: 0.527145
global_step: 3875, epoch: 97, loss: 0.567204
global_step: 3876, epoch: 97, loss: 0.554966
global_step: 3877, epoch: 97, loss: 0.572514
global_step: 3878, epoch: 97, loss: 0.555131
global_step: 3879, epoch: 97, loss: 0.504116
global_step: 3880, epoch: 97, loss: 0.075390
epoch: 97
train	acc: 0.8630	macro: p 0.8423, r 0.6465, f1: 0.6705	micro: p 0.8630, r 0.8630, f1 0.8630	weighted_f1:0.8463
dev	acc: 0.5636	macro: p 0.5120, r 0.3252, f1: 0.3346	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5123
test	acc: 0.5954	macro: p 0.4264, r 0.3147, f1: 0.3224	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5482
global_step: 3881, epoch: 98, loss: 0.555084
global_step: 3882, epoch: 98, loss: 0.579366
global_step: 3883, epoch: 98, loss: 0.507843
global_step: 3884, epoch: 98, loss: 0.551374
global_step: 3885, epoch: 98, loss: 0.513664
global_step: 3886, epoch: 98, loss: 0.579457
global_step: 3887, epoch: 98, loss: 0.505107
global_step: 3888, epoch: 98, loss: 0.558958
global_step: 3889, epoch: 98, loss: 0.411566
global_step: 3890, epoch: 98, loss: 0.507960
global_step: 3891, epoch: 98, loss: 0.403525
global_step: 3892, epoch: 98, loss: 0.614931
global_step: 3893, epoch: 98, loss: 0.530302
global_step: 3894, epoch: 98, loss: 0.413277
global_step: 3895, epoch: 98, loss: 0.576635
global_step: 3896, epoch: 98, loss: 0.558810
global_step: 3897, epoch: 98, loss: 0.622748
global_step: 3898, epoch: 98, loss: 0.478154
global_step: 3899, epoch: 98, loss: 0.607573
global_step: 3900, epoch: 98, loss: 0.608415
global_step: 3901, epoch: 98, loss: 0.556699
global_step: 3902, epoch: 98, loss: 0.595455
global_step: 3903, epoch: 98, loss: 0.545015
global_step: 3904, epoch: 98, loss: 0.590233
global_step: 3905, epoch: 98, loss: 0.448962
global_step: 3906, epoch: 98, loss: 0.516933
global_step: 3907, epoch: 98, loss: 0.580934
global_step: 3908, epoch: 98, loss: 0.502216
global_step: 3909, epoch: 98, loss: 0.628870
global_step: 3910, epoch: 98, loss: 0.517709
global_step: 3911, epoch: 98, loss: 0.577142
global_step: 3912, epoch: 98, loss: 0.512853
global_step: 3913, epoch: 98, loss: 0.505862
global_step: 3914, epoch: 98, loss: 0.535311
global_step: 3915, epoch: 98, loss: 0.616571
global_step: 3916, epoch: 98, loss: 0.614095
global_step: 3917, epoch: 98, loss: 0.559664
global_step: 3918, epoch: 98, loss: 0.683455
global_step: 3919, epoch: 98, loss: 0.548838
global_step: 3920, epoch: 98, loss: 1.371517
epoch: 98
train	acc: 0.8798	macro: p 0.8652, r 0.6824, f1: 0.6980	micro: p 0.8798, r 0.8798, f1 0.8798	weighted_f1:0.8658
dev	acc: 0.5699	macro: p 0.4331, r 0.3470, f1: 0.3530	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5305
test	acc: 0.6031	macro: p 0.3839, r 0.3390, f1: 0.3422	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5686
global_step: 3921, epoch: 99, loss: 0.577923
global_step: 3922, epoch: 99, loss: 0.548817
global_step: 3923, epoch: 99, loss: 0.592839
global_step: 3924, epoch: 99, loss: 0.527258
global_step: 3925, epoch: 99, loss: 0.580907
global_step: 3926, epoch: 99, loss: 0.535260
global_step: 3927, epoch: 99, loss: 0.479562
global_step: 3928, epoch: 99, loss: 0.536282
global_step: 3929, epoch: 99, loss: 0.594740
global_step: 3930, epoch: 99, loss: 0.537916
global_step: 3931, epoch: 99, loss: 0.486690
global_step: 3932, epoch: 99, loss: 0.556798
global_step: 3933, epoch: 99, loss: 0.542904
global_step: 3934, epoch: 99, loss: 0.498779
global_step: 3935, epoch: 99, loss: 0.550029
global_step: 3936, epoch: 99, loss: 0.482061
global_step: 3937, epoch: 99, loss: 0.529367
global_step: 3938, epoch: 99, loss: 0.594418
global_step: 3939, epoch: 99, loss: 0.473893
global_step: 3940, epoch: 99, loss: 0.522742
global_step: 3941, epoch: 99, loss: 0.597082
global_step: 3942, epoch: 99, loss: 0.458290
global_step: 3943, epoch: 99, loss: 0.577810
global_step: 3944, epoch: 99, loss: 0.643969
global_step: 3945, epoch: 99, loss: 0.458136
global_step: 3946, epoch: 99, loss: 0.443093
global_step: 3947, epoch: 99, loss: 0.541597
global_step: 3948, epoch: 99, loss: 0.474694
global_step: 3949, epoch: 99, loss: 0.530240
global_step: 3950, epoch: 99, loss: 0.588473
global_step: 3951, epoch: 99, loss: 0.492673
global_step: 3952, epoch: 99, loss: 0.576160
global_step: 3953, epoch: 99, loss: 0.488299
global_step: 3954, epoch: 99, loss: 0.583307
global_step: 3955, epoch: 99, loss: 0.478104
global_step: 3956, epoch: 99, loss: 0.635942
global_step: 3957, epoch: 99, loss: 0.605047
global_step: 3958, epoch: 99, loss: 0.554144
global_step: 3959, epoch: 99, loss: 0.536696
global_step: 3960, epoch: 99, loss: 0.174353
epoch: 99
train	acc: 0.8740	macro: p 0.8783, r 0.6662, f1: 0.6874	micro: p 0.8740, r 0.8740, f1 0.8740	weighted_f1:0.8585
dev	acc: 0.5690	macro: p 0.4425, r 0.3372, f1: 0.3438	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5232
test	acc: 0.5977	macro: p 0.4234, r 0.3226, f1: 0.3294	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5547
global_step: 3961, epoch: 100, loss: 0.704958
global_step: 3962, epoch: 100, loss: 0.479378
global_step: 3963, epoch: 100, loss: 0.506310
global_step: 3964, epoch: 100, loss: 0.490600
global_step: 3965, epoch: 100, loss: 0.574971
global_step: 3966, epoch: 100, loss: 0.612756
global_step: 3967, epoch: 100, loss: 0.530225
global_step: 3968, epoch: 100, loss: 0.577303
global_step: 3969, epoch: 100, loss: 0.502500
global_step: 3970, epoch: 100, loss: 0.527486
global_step: 3971, epoch: 100, loss: 0.587085
global_step: 3972, epoch: 100, loss: 0.507461
global_step: 3973, epoch: 100, loss: 0.468005
global_step: 3974, epoch: 100, loss: 0.520726
global_step: 3975, epoch: 100, loss: 0.514336
global_step: 3976, epoch: 100, loss: 0.567933
global_step: 3977, epoch: 100, loss: 0.604665
global_step: 3978, epoch: 100, loss: 0.462454
global_step: 3979, epoch: 100, loss: 0.573059
global_step: 3980, epoch: 100, loss: 0.463655
global_step: 3981, epoch: 100, loss: 0.563761
global_step: 3982, epoch: 100, loss: 0.512721
global_step: 3983, epoch: 100, loss: 0.434128
global_step: 3984, epoch: 100, loss: 0.543727
global_step: 3985, epoch: 100, loss: 0.564582
global_step: 3986, epoch: 100, loss: 0.547241
global_step: 3987, epoch: 100, loss: 0.535765
global_step: 3988, epoch: 100, loss: 0.451750
global_step: 3989, epoch: 100, loss: 0.549110
global_step: 3990, epoch: 100, loss: 0.578090
global_step: 3991, epoch: 100, loss: 0.564969
global_step: 3992, epoch: 100, loss: 0.552965
global_step: 3993, epoch: 100, loss: 0.563818
global_step: 3994, epoch: 100, loss: 0.419154
global_step: 3995, epoch: 100, loss: 0.615312
global_step: 3996, epoch: 100, loss: 0.614252
global_step: 3997, epoch: 100, loss: 0.634040
global_step: 3998, epoch: 100, loss: 0.589629
global_step: 3999, epoch: 100, loss: 0.482268
global_step: 4000, epoch: 100, loss: 0.839658
epoch: 100
train	acc: 0.8776	macro: p 0.8641, r 0.6793, f1: 0.6962	micro: p 0.8776, r 0.8776, f1 0.8776	weighted_f1:0.8636
dev	acc: 0.5726	macro: p 0.4159, r 0.3418, f1: 0.3499	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5318
test	acc: 0.6027	macro: p 0.4032, r 0.3341, f1: 0.3422	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5667
global_step: 4001, epoch: 101, loss: 0.597501
global_step: 4002, epoch: 101, loss: 0.568511
global_step: 4003, epoch: 101, loss: 0.590379
global_step: 4004, epoch: 101, loss: 0.511696
global_step: 4005, epoch: 101, loss: 0.423277
global_step: 4006, epoch: 101, loss: 0.538339
global_step: 4007, epoch: 101, loss: 0.474138
global_step: 4008, epoch: 101, loss: 0.493479
global_step: 4009, epoch: 101, loss: 0.520463
global_step: 4010, epoch: 101, loss: 0.529227
global_step: 4011, epoch: 101, loss: 0.579301
global_step: 4012, epoch: 101, loss: 0.498867
global_step: 4013, epoch: 101, loss: 0.505925
global_step: 4014, epoch: 101, loss: 0.458359
global_step: 4015, epoch: 101, loss: 0.547001
global_step: 4016, epoch: 101, loss: 0.570256
global_step: 4017, epoch: 101, loss: 0.551879
global_step: 4018, epoch: 101, loss: 0.588756
global_step: 4019, epoch: 101, loss: 0.562392
global_step: 4020, epoch: 101, loss: 0.519569
global_step: 4021, epoch: 101, loss: 0.484181
global_step: 4022, epoch: 101, loss: 0.569370
global_step: 4023, epoch: 101, loss: 0.491138
global_step: 4024, epoch: 101, loss: 0.428005
global_step: 4025, epoch: 101, loss: 0.535187
global_step: 4026, epoch: 101, loss: 0.521184
global_step: 4027, epoch: 101, loss: 0.485715
global_step: 4028, epoch: 101, loss: 0.638026
global_step: 4029, epoch: 101, loss: 0.575729
global_step: 4030, epoch: 101, loss: 0.569216
global_step: 4031, epoch: 101, loss: 0.561029
global_step: 4032, epoch: 101, loss: 0.527300
global_step: 4033, epoch: 101, loss: 0.503277
global_step: 4034, epoch: 101, loss: 0.568123
global_step: 4035, epoch: 101, loss: 0.525642
global_step: 4036, epoch: 101, loss: 0.512350
global_step: 4037, epoch: 101, loss: 0.517943
global_step: 4038, epoch: 101, loss: 0.481084
global_step: 4039, epoch: 101, loss: 0.523182
global_step: 4040, epoch: 101, loss: 0.109979
epoch: 101
train	acc: 0.8891	macro: p 0.8823, r 0.6872, f1: 0.6984	micro: p 0.8891, r 0.8891, f1 0.8891	weighted_f1:0.8752
dev	acc: 0.5509	macro: p 0.5184, r 0.3442, f1: 0.3451	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5196
test	acc: 0.5989	macro: p 0.3800, r 0.3510, f1: 0.3487	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5730
global_step: 4041, epoch: 102, loss: 0.423858
global_step: 4042, epoch: 102, loss: 0.432481
global_step: 4043, epoch: 102, loss: 0.554215
global_step: 4044, epoch: 102, loss: 0.608027
global_step: 4045, epoch: 102, loss: 0.487572
global_step: 4046, epoch: 102, loss: 0.454807
global_step: 4047, epoch: 102, loss: 0.518638
global_step: 4048, epoch: 102, loss: 0.463268
global_step: 4049, epoch: 102, loss: 0.544213
global_step: 4050, epoch: 102, loss: 0.456770
global_step: 4051, epoch: 102, loss: 0.496206
global_step: 4052, epoch: 102, loss: 0.504267
global_step: 4053, epoch: 102, loss: 0.549153
global_step: 4054, epoch: 102, loss: 0.577369
global_step: 4055, epoch: 102, loss: 0.498530
global_step: 4056, epoch: 102, loss: 0.501711
global_step: 4057, epoch: 102, loss: 0.592570
global_step: 4058, epoch: 102, loss: 0.580549
global_step: 4059, epoch: 102, loss: 0.505398
global_step: 4060, epoch: 102, loss: 0.495209
global_step: 4061, epoch: 102, loss: 0.651411
global_step: 4062, epoch: 102, loss: 0.560570
global_step: 4063, epoch: 102, loss: 0.595366
global_step: 4064, epoch: 102, loss: 0.449010
global_step: 4065, epoch: 102, loss: 0.501898
global_step: 4066, epoch: 102, loss: 0.597839
global_step: 4067, epoch: 102, loss: 0.625849
global_step: 4068, epoch: 102, loss: 0.501011
global_step: 4069, epoch: 102, loss: 0.517339
global_step: 4070, epoch: 102, loss: 0.546167
global_step: 4071, epoch: 102, loss: 0.641143
global_step: 4072, epoch: 102, loss: 0.566605
global_step: 4073, epoch: 102, loss: 0.532411
global_step: 4074, epoch: 102, loss: 0.506065
global_step: 4075, epoch: 102, loss: 0.605448
global_step: 4076, epoch: 102, loss: 0.530700
global_step: 4077, epoch: 102, loss: 0.592747
global_step: 4078, epoch: 102, loss: 0.516917
global_step: 4079, epoch: 102, loss: 0.526229
global_step: 4080, epoch: 102, loss: 0.324268
epoch: 102
train	acc: 0.8865	macro: p 0.8760, r 0.6894, f1: 0.7009	micro: p 0.8865, r 0.8865, f1 0.8865	weighted_f1:0.8724
dev	acc: 0.5473	macro: p 0.4393, r 0.3437, f1: 0.3433	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5122
test	acc: 0.5885	macro: p 0.3678, r 0.3385, f1: 0.3313	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5571
global_step: 4081, epoch: 103, loss: 0.559531
global_step: 4082, epoch: 103, loss: 0.538364
global_step: 4083, epoch: 103, loss: 0.550632
global_step: 4084, epoch: 103, loss: 0.492384
global_step: 4085, epoch: 103, loss: 0.449893
global_step: 4086, epoch: 103, loss: 0.533643
global_step: 4087, epoch: 103, loss: 0.474135
global_step: 4088, epoch: 103, loss: 0.515239
global_step: 4089, epoch: 103, loss: 0.569498
global_step: 4090, epoch: 103, loss: 0.477371
global_step: 4091, epoch: 103, loss: 0.519873
global_step: 4092, epoch: 103, loss: 0.512607
global_step: 4093, epoch: 103, loss: 0.599135
global_step: 4094, epoch: 103, loss: 0.574634
global_step: 4095, epoch: 103, loss: 0.525010
global_step: 4096, epoch: 103, loss: 0.501970
global_step: 4097, epoch: 103, loss: 0.558652
global_step: 4098, epoch: 103, loss: 0.415023
global_step: 4099, epoch: 103, loss: 0.517261
global_step: 4100, epoch: 103, loss: 0.507514
global_step: 4101, epoch: 103, loss: 0.523046
global_step: 4102, epoch: 103, loss: 0.529096
global_step: 4103, epoch: 103, loss: 0.571430
global_step: 4104, epoch: 103, loss: 0.473197
global_step: 4105, epoch: 103, loss: 0.550278
global_step: 4106, epoch: 103, loss: 0.566322
global_step: 4107, epoch: 103, loss: 0.460096
global_step: 4108, epoch: 103, loss: 0.500915
global_step: 4109, epoch: 103, loss: 0.475660
global_step: 4110, epoch: 103, loss: 0.475453
global_step: 4111, epoch: 103, loss: 0.491893
global_step: 4112, epoch: 103, loss: 0.564230
global_step: 4113, epoch: 103, loss: 0.439024
global_step: 4114, epoch: 103, loss: 0.504939
global_step: 4115, epoch: 103, loss: 0.505542
global_step: 4116, epoch: 103, loss: 0.611446
global_step: 4117, epoch: 103, loss: 0.518447
global_step: 4118, epoch: 103, loss: 0.577714
global_step: 4119, epoch: 103, loss: 0.568761
global_step: 4120, epoch: 103, loss: 0.774114
epoch: 103
train	acc: 0.8865	macro: p 0.8699, r 0.6918, f1: 0.7091	micro: p 0.8865, r 0.8865, f1 0.8865	weighted_f1:0.8727
dev	acc: 0.5663	macro: p 0.4368, r 0.3374, f1: 0.3439	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5232
test	acc: 0.5992	macro: p 0.3957, r 0.3289, f1: 0.3364	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5600
global_step: 4121, epoch: 104, loss: 0.577421
global_step: 4122, epoch: 104, loss: 0.443060
global_step: 4123, epoch: 104, loss: 0.506685
global_step: 4124, epoch: 104, loss: 0.586025
global_step: 4125, epoch: 104, loss: 0.540907
global_step: 4126, epoch: 104, loss: 0.537625
global_step: 4127, epoch: 104, loss: 0.574536
global_step: 4128, epoch: 104, loss: 0.576052
global_step: 4129, epoch: 104, loss: 0.403470
global_step: 4130, epoch: 104, loss: 0.561221
global_step: 4131, epoch: 104, loss: 0.519227
global_step: 4132, epoch: 104, loss: 0.524132
global_step: 4133, epoch: 104, loss: 0.513150
global_step: 4134, epoch: 104, loss: 0.511899
global_step: 4135, epoch: 104, loss: 0.501391
global_step: 4136, epoch: 104, loss: 0.459098
global_step: 4137, epoch: 104, loss: 0.573884
global_step: 4138, epoch: 104, loss: 0.551053
global_step: 4139, epoch: 104, loss: 0.404861
global_step: 4140, epoch: 104, loss: 0.497601
global_step: 4141, epoch: 104, loss: 0.521210
global_step: 4142, epoch: 104, loss: 0.574012
global_step: 4143, epoch: 104, loss: 0.506503
global_step: 4144, epoch: 104, loss: 0.504175
global_step: 4145, epoch: 104, loss: 0.438458
global_step: 4146, epoch: 104, loss: 0.486692
global_step: 4147, epoch: 104, loss: 0.516590
global_step: 4148, epoch: 104, loss: 0.537977
global_step: 4149, epoch: 104, loss: 0.478836
global_step: 4150, epoch: 104, loss: 0.489255
global_step: 4151, epoch: 104, loss: 0.441911
global_step: 4152, epoch: 104, loss: 0.494507
global_step: 4153, epoch: 104, loss: 0.601755
global_step: 4154, epoch: 104, loss: 0.584740
global_step: 4155, epoch: 104, loss: 0.450080
global_step: 4156, epoch: 104, loss: 0.427571
global_step: 4157, epoch: 104, loss: 0.539384
global_step: 4158, epoch: 104, loss: 0.548865
global_step: 4159, epoch: 104, loss: 0.567365
global_step: 4160, epoch: 104, loss: 0.757393
epoch: 104
train	acc: 0.8988	macro: p 0.8770, r 0.7322, f1: 0.7515	micro: p 0.8988, r 0.8988, f1 0.8988	weighted_f1:0.8900
dev	acc: 0.5609	macro: p 0.5616, r 0.3799, f1: 0.3923	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5359
test	acc: 0.5916	macro: p 0.3572, r 0.3517, f1: 0.3463	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5701
global_step: 4161, epoch: 105, loss: 0.527743
global_step: 4162, epoch: 105, loss: 0.537179
global_step: 4163, epoch: 105, loss: 0.515200
global_step: 4164, epoch: 105, loss: 0.463642
global_step: 4165, epoch: 105, loss: 0.533299
global_step: 4166, epoch: 105, loss: 0.472630
global_step: 4167, epoch: 105, loss: 0.484264
global_step: 4168, epoch: 105, loss: 0.450402
global_step: 4169, epoch: 105, loss: 0.507417
global_step: 4170, epoch: 105, loss: 0.588754
global_step: 4171, epoch: 105, loss: 0.543321
global_step: 4172, epoch: 105, loss: 0.504700
global_step: 4173, epoch: 105, loss: 0.535126
global_step: 4174, epoch: 105, loss: 0.427243
global_step: 4175, epoch: 105, loss: 0.489611
global_step: 4176, epoch: 105, loss: 0.551375
global_step: 4177, epoch: 105, loss: 0.489769
global_step: 4178, epoch: 105, loss: 0.488935
global_step: 4179, epoch: 105, loss: 0.527891
global_step: 4180, epoch: 105, loss: 0.485544
global_step: 4181, epoch: 105, loss: 0.507024
global_step: 4182, epoch: 105, loss: 0.546280
global_step: 4183, epoch: 105, loss: 0.501371
global_step: 4184, epoch: 105, loss: 0.541949
global_step: 4185, epoch: 105, loss: 0.504328
global_step: 4186, epoch: 105, loss: 0.389339
global_step: 4187, epoch: 105, loss: 0.507550
global_step: 4188, epoch: 105, loss: 0.562349
global_step: 4189, epoch: 105, loss: 0.539129
global_step: 4190, epoch: 105, loss: 0.492393
global_step: 4191, epoch: 105, loss: 0.519400
global_step: 4192, epoch: 105, loss: 0.558878
global_step: 4193, epoch: 105, loss: 0.497842
global_step: 4194, epoch: 105, loss: 0.599152
global_step: 4195, epoch: 105, loss: 0.473689
global_step: 4196, epoch: 105, loss: 0.501050
global_step: 4197, epoch: 105, loss: 0.512170
global_step: 4198, epoch: 105, loss: 0.539269
global_step: 4199, epoch: 105, loss: 0.442240
global_step: 4200, epoch: 105, loss: 0.339809
epoch: 105
train	acc: 0.8922	macro: p 0.8810, r 0.7067, f1: 0.7298	micro: p 0.8922, r 0.8922, f1 0.8922	weighted_f1:0.8800
dev	acc: 0.5636	macro: p 0.4299, r 0.3432, f1: 0.3472	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5192
test	acc: 0.5939	macro: p 0.3821, r 0.3277, f1: 0.3270	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5540
global_step: 4201, epoch: 106, loss: 0.478294
global_step: 4202, epoch: 106, loss: 0.573794
global_step: 4203, epoch: 106, loss: 0.543231
global_step: 4204, epoch: 106, loss: 0.465822
global_step: 4205, epoch: 106, loss: 0.533383
global_step: 4206, epoch: 106, loss: 0.531913
global_step: 4207, epoch: 106, loss: 0.527486
global_step: 4208, epoch: 106, loss: 0.485931
global_step: 4209, epoch: 106, loss: 0.476315
global_step: 4210, epoch: 106, loss: 0.575214
global_step: 4211, epoch: 106, loss: 0.396361
global_step: 4212, epoch: 106, loss: 0.494513
global_step: 4213, epoch: 106, loss: 0.601416
global_step: 4214, epoch: 106, loss: 0.520313
global_step: 4215, epoch: 106, loss: 0.456078
global_step: 4216, epoch: 106, loss: 0.529015
global_step: 4217, epoch: 106, loss: 0.572848
global_step: 4218, epoch: 106, loss: 0.537984
global_step: 4219, epoch: 106, loss: 0.486517
global_step: 4220, epoch: 106, loss: 0.388691
global_step: 4221, epoch: 106, loss: 0.439949
global_step: 4222, epoch: 106, loss: 0.568841
global_step: 4223, epoch: 106, loss: 0.418605
global_step: 4224, epoch: 106, loss: 0.487075
global_step: 4225, epoch: 106, loss: 0.533592
global_step: 4226, epoch: 106, loss: 0.450396
global_step: 4227, epoch: 106, loss: 0.513278
global_step: 4228, epoch: 106, loss: 0.465493
global_step: 4229, epoch: 106, loss: 0.494524
global_step: 4230, epoch: 106, loss: 0.520525
global_step: 4231, epoch: 106, loss: 0.468116
global_step: 4232, epoch: 106, loss: 0.498869
global_step: 4233, epoch: 106, loss: 0.617240
global_step: 4234, epoch: 106, loss: 0.535272
global_step: 4235, epoch: 106, loss: 0.452930
global_step: 4236, epoch: 106, loss: 0.472640
global_step: 4237, epoch: 106, loss: 0.569256
global_step: 4238, epoch: 106, loss: 0.543327
global_step: 4239, epoch: 106, loss: 0.535633
global_step: 4240, epoch: 106, loss: 0.288967
epoch: 106
train	acc: 0.8739	macro: p 0.8790, r 0.6757, f1: 0.7078	micro: p 0.8739, r 0.8739, f1 0.8739	weighted_f1:0.8600
dev	acc: 0.5681	macro: p 0.5615, r 0.3319, f1: 0.3416	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5179
test	acc: 0.5973	macro: p 0.3953, r 0.3164, f1: 0.3216	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5494
global_step: 4241, epoch: 107, loss: 0.518219
global_step: 4242, epoch: 107, loss: 0.550563
global_step: 4243, epoch: 107, loss: 0.508759
global_step: 4244, epoch: 107, loss: 0.469541
global_step: 4245, epoch: 107, loss: 0.586332
global_step: 4246, epoch: 107, loss: 0.524119
global_step: 4247, epoch: 107, loss: 0.458186
global_step: 4248, epoch: 107, loss: 0.460052
global_step: 4249, epoch: 107, loss: 0.421313
global_step: 4250, epoch: 107, loss: 0.564379
global_step: 4251, epoch: 107, loss: 0.552994
global_step: 4252, epoch: 107, loss: 0.503617
global_step: 4253, epoch: 107, loss: 0.458211
global_step: 4254, epoch: 107, loss: 0.436872
global_step: 4255, epoch: 107, loss: 0.486024
global_step: 4256, epoch: 107, loss: 0.463621
global_step: 4257, epoch: 107, loss: 0.571696
global_step: 4258, epoch: 107, loss: 0.457600
global_step: 4259, epoch: 107, loss: 0.529214
global_step: 4260, epoch: 107, loss: 0.450820
global_step: 4261, epoch: 107, loss: 0.454068
global_step: 4262, epoch: 107, loss: 0.582436
global_step: 4263, epoch: 107, loss: 0.527786
global_step: 4264, epoch: 107, loss: 0.495957
global_step: 4265, epoch: 107, loss: 0.534048
global_step: 4266, epoch: 107, loss: 0.481609
global_step: 4267, epoch: 107, loss: 0.479097
global_step: 4268, epoch: 107, loss: 0.470522
global_step: 4269, epoch: 107, loss: 0.466869
global_step: 4270, epoch: 107, loss: 0.481502
global_step: 4271, epoch: 107, loss: 0.418693
global_step: 4272, epoch: 107, loss: 0.482831
global_step: 4273, epoch: 107, loss: 0.572747
global_step: 4274, epoch: 107, loss: 0.461349
global_step: 4275, epoch: 107, loss: 0.445528
global_step: 4276, epoch: 107, loss: 0.427118
global_step: 4277, epoch: 107, loss: 0.448908
global_step: 4278, epoch: 107, loss: 0.505196
global_step: 4279, epoch: 107, loss: 0.424548
global_step: 4280, epoch: 107, loss: 0.821931
epoch: 107
train	acc: 0.8902	macro: p 0.8677, r 0.7031, f1: 0.7153	micro: p 0.8902, r 0.8902, f1 0.8902	weighted_f1:0.8773
dev	acc: 0.5518	macro: p 0.4071, r 0.3372, f1: 0.3358	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5148
test	acc: 0.5900	macro: p 0.3839, r 0.3336, f1: 0.3316	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5554
global_step: 4281, epoch: 108, loss: 0.451483
global_step: 4282, epoch: 108, loss: 0.480503
global_step: 4283, epoch: 108, loss: 0.540495
global_step: 4284, epoch: 108, loss: 0.509917
global_step: 4285, epoch: 108, loss: 0.455185
global_step: 4286, epoch: 108, loss: 0.444666
global_step: 4287, epoch: 108, loss: 0.492489
global_step: 4288, epoch: 108, loss: 0.485420
global_step: 4289, epoch: 108, loss: 0.487575
global_step: 4290, epoch: 108, loss: 0.620600
global_step: 4291, epoch: 108, loss: 0.516730
global_step: 4292, epoch: 108, loss: 0.500628
global_step: 4293, epoch: 108, loss: 0.496650
global_step: 4294, epoch: 108, loss: 0.563549
global_step: 4295, epoch: 108, loss: 0.585492
global_step: 4296, epoch: 108, loss: 0.516743
global_step: 4297, epoch: 108, loss: 0.511724
global_step: 4298, epoch: 108, loss: 0.478691
global_step: 4299, epoch: 108, loss: 0.538931
global_step: 4300, epoch: 108, loss: 0.456508
global_step: 4301, epoch: 108, loss: 0.474602
global_step: 4302, epoch: 108, loss: 0.488147
global_step: 4303, epoch: 108, loss: 0.451692
global_step: 4304, epoch: 108, loss: 0.517990
global_step: 4305, epoch: 108, loss: 0.586584
global_step: 4306, epoch: 108, loss: 0.486596
global_step: 4307, epoch: 108, loss: 0.485879
global_step: 4308, epoch: 108, loss: 0.432915
global_step: 4309, epoch: 108, loss: 0.449339
global_step: 4310, epoch: 108, loss: 0.479677
global_step: 4311, epoch: 108, loss: 0.525559
global_step: 4312, epoch: 108, loss: 0.576724
global_step: 4313, epoch: 108, loss: 0.480155
global_step: 4314, epoch: 108, loss: 0.487649
global_step: 4315, epoch: 108, loss: 0.439584
global_step: 4316, epoch: 108, loss: 0.488865
global_step: 4317, epoch: 108, loss: 0.464904
global_step: 4318, epoch: 108, loss: 0.487300
global_step: 4319, epoch: 108, loss: 0.499283
global_step: 4320, epoch: 108, loss: 0.977572
epoch: 108
train	acc: 0.9003	macro: p 0.8814, r 0.7244, f1: 0.7377	micro: p 0.9003, r 0.9003, f1 0.9003	weighted_f1:0.8890
dev	acc: 0.5528	macro: p 0.5119, r 0.3444, f1: 0.3496	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5237
test	acc: 0.6011	macro: p 0.3910, r 0.3480, f1: 0.3532	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5745
global_step: 4321, epoch: 109, loss: 0.419014
global_step: 4322, epoch: 109, loss: 0.429683
global_step: 4323, epoch: 109, loss: 0.471871
global_step: 4324, epoch: 109, loss: 0.509561
global_step: 4325, epoch: 109, loss: 0.518884
global_step: 4326, epoch: 109, loss: 0.525580
global_step: 4327, epoch: 109, loss: 0.574268
global_step: 4328, epoch: 109, loss: 0.402376
global_step: 4329, epoch: 109, loss: 0.490787
global_step: 4330, epoch: 109, loss: 0.511953
global_step: 4331, epoch: 109, loss: 0.412657
global_step: 4332, epoch: 109, loss: 0.477001
global_step: 4333, epoch: 109, loss: 0.419982
global_step: 4334, epoch: 109, loss: 0.513691
global_step: 4335, epoch: 109, loss: 0.535693
global_step: 4336, epoch: 109, loss: 0.454107
global_step: 4337, epoch: 109, loss: 0.593428
global_step: 4338, epoch: 109, loss: 0.505657
global_step: 4339, epoch: 109, loss: 0.463054
global_step: 4340, epoch: 109, loss: 0.537163
global_step: 4341, epoch: 109, loss: 0.481238
global_step: 4342, epoch: 109, loss: 0.467525
global_step: 4343, epoch: 109, loss: 0.396032
global_step: 4344, epoch: 109, loss: 0.440540
global_step: 4345, epoch: 109, loss: 0.511372
global_step: 4346, epoch: 109, loss: 0.559017
global_step: 4347, epoch: 109, loss: 0.523344
global_step: 4348, epoch: 109, loss: 0.456879
global_step: 4349, epoch: 109, loss: 0.556536
global_step: 4350, epoch: 109, loss: 0.561743
global_step: 4351, epoch: 109, loss: 0.482474
global_step: 4352, epoch: 109, loss: 0.435839
global_step: 4353, epoch: 109, loss: 0.495056
global_step: 4354, epoch: 109, loss: 0.564780
global_step: 4355, epoch: 109, loss: 0.542328
global_step: 4356, epoch: 109, loss: 0.525007
global_step: 4357, epoch: 109, loss: 0.422898
global_step: 4358, epoch: 109, loss: 0.489775
global_step: 4359, epoch: 109, loss: 0.411237
global_step: 4360, epoch: 109, loss: 0.235950
epoch: 109
train	acc: 0.8946	macro: p 0.8723, r 0.7129, f1: 0.7309	micro: p 0.8946, r 0.8946, f1 0.8946	weighted_f1:0.8826
dev	acc: 0.5645	macro: p 0.4080, r 0.3373, f1: 0.3411	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5214
test	acc: 0.5992	macro: p 0.4085, r 0.3290, f1: 0.3341	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5590
global_step: 4361, epoch: 110, loss: 0.515590
global_step: 4362, epoch: 110, loss: 0.512144
global_step: 4363, epoch: 110, loss: 0.432402
global_step: 4364, epoch: 110, loss: 0.592328
global_step: 4365, epoch: 110, loss: 0.430283
global_step: 4366, epoch: 110, loss: 0.488418
global_step: 4367, epoch: 110, loss: 0.514857
global_step: 4368, epoch: 110, loss: 0.528631
global_step: 4369, epoch: 110, loss: 0.466495
global_step: 4370, epoch: 110, loss: 0.455267
global_step: 4371, epoch: 110, loss: 0.505352
global_step: 4372, epoch: 110, loss: 0.468709
global_step: 4373, epoch: 110, loss: 0.479943
global_step: 4374, epoch: 110, loss: 0.463219
global_step: 4375, epoch: 110, loss: 0.490399
global_step: 4376, epoch: 110, loss: 0.546451
global_step: 4377, epoch: 110, loss: 0.555319
global_step: 4378, epoch: 110, loss: 0.428175
global_step: 4379, epoch: 110, loss: 0.409526
global_step: 4380, epoch: 110, loss: 0.468404
global_step: 4381, epoch: 110, loss: 0.492923
global_step: 4382, epoch: 110, loss: 0.555568
global_step: 4383, epoch: 110, loss: 0.505540
global_step: 4384, epoch: 110, loss: 0.433799
global_step: 4385, epoch: 110, loss: 0.495175
global_step: 4386, epoch: 110, loss: 0.514723
global_step: 4387, epoch: 110, loss: 0.454618
global_step: 4388, epoch: 110, loss: 0.372858
global_step: 4389, epoch: 110, loss: 0.477740
global_step: 4390, epoch: 110, loss: 0.544939
global_step: 4391, epoch: 110, loss: 0.536699
global_step: 4392, epoch: 110, loss: 0.445264
global_step: 4393, epoch: 110, loss: 0.483745
global_step: 4394, epoch: 110, loss: 0.510374
global_step: 4395, epoch: 110, loss: 0.520554
global_step: 4396, epoch: 110, loss: 0.531543
global_step: 4397, epoch: 110, loss: 0.492115
global_step: 4398, epoch: 110, loss: 0.479557
global_step: 4399, epoch: 110, loss: 0.595341
global_step: 4400, epoch: 110, loss: 0.460471
epoch: 110
train	acc: 0.9046	macro: p 0.8790, r 0.7466, f1: 0.7576	micro: p 0.9046, r 0.9046, f1 0.9046	weighted_f1:0.8951
dev	acc: 0.5410	macro: p 0.3924, r 0.3614, f1: 0.3621	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5152
test	acc: 0.5893	macro: p 0.3757, r 0.3603, f1: 0.3561	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5699
global_step: 4401, epoch: 111, loss: 0.473928
global_step: 4402, epoch: 111, loss: 0.550984
global_step: 4403, epoch: 111, loss: 0.470979
global_step: 4404, epoch: 111, loss: 0.399475
global_step: 4405, epoch: 111, loss: 0.488646
global_step: 4406, epoch: 111, loss: 0.472858
global_step: 4407, epoch: 111, loss: 0.435669
global_step: 4408, epoch: 111, loss: 0.512505
global_step: 4409, epoch: 111, loss: 0.464870
global_step: 4410, epoch: 111, loss: 0.449337
global_step: 4411, epoch: 111, loss: 0.464970
global_step: 4412, epoch: 111, loss: 0.455852
global_step: 4413, epoch: 111, loss: 0.467694
global_step: 4414, epoch: 111, loss: 0.443642
global_step: 4415, epoch: 111, loss: 0.443855
global_step: 4416, epoch: 111, loss: 0.459574
global_step: 4417, epoch: 111, loss: 0.570608
global_step: 4418, epoch: 111, loss: 0.480690
global_step: 4419, epoch: 111, loss: 0.489311
global_step: 4420, epoch: 111, loss: 0.472101
global_step: 4421, epoch: 111, loss: 0.416639
global_step: 4422, epoch: 111, loss: 0.509006
global_step: 4423, epoch: 111, loss: 0.492673
global_step: 4424, epoch: 111, loss: 0.441048
global_step: 4425, epoch: 111, loss: 0.604446
global_step: 4426, epoch: 111, loss: 0.458314
global_step: 4427, epoch: 111, loss: 0.490443
global_step: 4428, epoch: 111, loss: 0.408140
global_step: 4429, epoch: 111, loss: 0.481832
global_step: 4430, epoch: 111, loss: 0.472775
global_step: 4431, epoch: 111, loss: 0.374512
global_step: 4432, epoch: 111, loss: 0.523840
global_step: 4433, epoch: 111, loss: 0.414423
global_step: 4434, epoch: 111, loss: 0.476581
global_step: 4435, epoch: 111, loss: 0.548560
global_step: 4436, epoch: 111, loss: 0.508572
global_step: 4437, epoch: 111, loss: 0.534982
global_step: 4438, epoch: 111, loss: 0.435444
global_step: 4439, epoch: 111, loss: 0.476836
global_step: 4440, epoch: 111, loss: 0.222899
epoch: 111
train	acc: 0.9053	macro: p 0.8867, r 0.7404, f1: 0.7605	micro: p 0.9053, r 0.9053, f1 0.9053	weighted_f1:0.8961
dev	acc: 0.5591	macro: p 0.5771, r 0.3739, f1: 0.3857	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5325
test	acc: 0.5939	macro: p 0.3760, r 0.3518, f1: 0.3481	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5699
global_step: 4441, epoch: 112, loss: 0.415017
global_step: 4442, epoch: 112, loss: 0.427162
global_step: 4443, epoch: 112, loss: 0.456913
global_step: 4444, epoch: 112, loss: 0.496073
global_step: 4445, epoch: 112, loss: 0.417138
global_step: 4446, epoch: 112, loss: 0.492465
global_step: 4447, epoch: 112, loss: 0.457659
global_step: 4448, epoch: 112, loss: 0.483883
global_step: 4449, epoch: 112, loss: 0.469279
global_step: 4450, epoch: 112, loss: 0.466722
global_step: 4451, epoch: 112, loss: 0.498715
global_step: 4452, epoch: 112, loss: 0.470183
global_step: 4453, epoch: 112, loss: 0.548256
global_step: 4454, epoch: 112, loss: 0.591653
global_step: 4455, epoch: 112, loss: 0.542504
global_step: 4456, epoch: 112, loss: 0.491198
global_step: 4457, epoch: 112, loss: 0.429307
global_step: 4458, epoch: 112, loss: 0.477861
global_step: 4459, epoch: 112, loss: 0.300674
global_step: 4460, epoch: 112, loss: 0.418120
global_step: 4461, epoch: 112, loss: 0.530429
global_step: 4462, epoch: 112, loss: 0.415441
global_step: 4463, epoch: 112, loss: 0.518180
global_step: 4464, epoch: 112, loss: 0.446579
global_step: 4465, epoch: 112, loss: 0.445533
global_step: 4466, epoch: 112, loss: 0.375024
global_step: 4467, epoch: 112, loss: 0.489163
global_step: 4468, epoch: 112, loss: 0.461458
global_step: 4469, epoch: 112, loss: 0.548075
global_step: 4470, epoch: 112, loss: 0.525388
global_step: 4471, epoch: 112, loss: 0.426923
global_step: 4472, epoch: 112, loss: 0.572940
global_step: 4473, epoch: 112, loss: 0.540661
global_step: 4474, epoch: 112, loss: 0.554656
global_step: 4475, epoch: 112, loss: 0.476252
global_step: 4476, epoch: 112, loss: 0.453365
global_step: 4477, epoch: 112, loss: 0.420849
global_step: 4478, epoch: 112, loss: 0.506827
global_step: 4479, epoch: 112, loss: 0.498917
global_step: 4480, epoch: 112, loss: 0.214657
epoch: 112
train	acc: 0.9027	macro: p 0.8857, r 0.7362, f1: 0.7541	micro: p 0.9027, r 0.9027, f1 0.9027	weighted_f1:0.8929
dev	acc: 0.5717	macro: p 0.5570, r 0.3595, f1: 0.3704	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5368
test	acc: 0.5973	macro: p 0.3755, r 0.3358, f1: 0.3400	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5638
global_step: 4481, epoch: 113, loss: 0.461610
global_step: 4482, epoch: 113, loss: 0.490216
global_step: 4483, epoch: 113, loss: 0.489072
global_step: 4484, epoch: 113, loss: 0.470984
global_step: 4485, epoch: 113, loss: 0.369602
global_step: 4486, epoch: 113, loss: 0.501392
global_step: 4487, epoch: 113, loss: 0.486044
global_step: 4488, epoch: 113, loss: 0.460364
global_step: 4489, epoch: 113, loss: 0.431524
global_step: 4490, epoch: 113, loss: 0.489058
global_step: 4491, epoch: 113, loss: 0.494783
global_step: 4492, epoch: 113, loss: 0.421122
global_step: 4493, epoch: 113, loss: 0.499989
global_step: 4494, epoch: 113, loss: 0.401655
global_step: 4495, epoch: 113, loss: 0.578211
global_step: 4496, epoch: 113, loss: 0.444518
global_step: 4497, epoch: 113, loss: 0.514199
global_step: 4498, epoch: 113, loss: 0.457707
global_step: 4499, epoch: 113, loss: 0.378770
global_step: 4500, epoch: 113, loss: 0.444462
global_step: 4501, epoch: 113, loss: 0.509212
global_step: 4502, epoch: 113, loss: 0.448900
global_step: 4503, epoch: 113, loss: 0.515576
global_step: 4504, epoch: 113, loss: 0.522099
global_step: 4505, epoch: 113, loss: 0.458023
global_step: 4506, epoch: 113, loss: 0.460914
global_step: 4507, epoch: 113, loss: 0.472718
global_step: 4508, epoch: 113, loss: 0.504834
global_step: 4509, epoch: 113, loss: 0.443375
global_step: 4510, epoch: 113, loss: 0.427655
global_step: 4511, epoch: 113, loss: 0.475844
global_step: 4512, epoch: 113, loss: 0.501184
global_step: 4513, epoch: 113, loss: 0.544358
global_step: 4514, epoch: 113, loss: 0.523468
global_step: 4515, epoch: 113, loss: 0.429203
global_step: 4516, epoch: 113, loss: 0.426290
global_step: 4517, epoch: 113, loss: 0.507242
global_step: 4518, epoch: 113, loss: 0.454690
global_step: 4519, epoch: 113, loss: 0.443537
global_step: 4520, epoch: 113, loss: 0.031127
epoch: 113
train	acc: 0.9074	macro: p 0.8903, r 0.7409, f1: 0.7574	micro: p 0.9074, r 0.9074, f1 0.9074	weighted_f1:0.8972
dev	acc: 0.5591	macro: p 0.5567, r 0.3638, f1: 0.3773	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5300
test	acc: 0.5912	macro: p 0.3880, r 0.3425, f1: 0.3453	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5646
global_step: 4521, epoch: 114, loss: 0.528369
global_step: 4522, epoch: 114, loss: 0.469053
global_step: 4523, epoch: 114, loss: 0.396923
global_step: 4524, epoch: 114, loss: 0.502355
global_step: 4525, epoch: 114, loss: 0.415648
global_step: 4526, epoch: 114, loss: 0.509520
global_step: 4527, epoch: 114, loss: 0.475956
global_step: 4528, epoch: 114, loss: 0.449047
global_step: 4529, epoch: 114, loss: 0.371419
global_step: 4530, epoch: 114, loss: 0.613781
global_step: 4531, epoch: 114, loss: 0.508983
global_step: 4532, epoch: 114, loss: 0.456594
global_step: 4533, epoch: 114, loss: 0.465330
global_step: 4534, epoch: 114, loss: 0.426934
global_step: 4535, epoch: 114, loss: 0.538789
global_step: 4536, epoch: 114, loss: 0.516892
global_step: 4537, epoch: 114, loss: 0.383900
global_step: 4538, epoch: 114, loss: 0.440352
global_step: 4539, epoch: 114, loss: 0.486116
global_step: 4540, epoch: 114, loss: 0.496185
global_step: 4541, epoch: 114, loss: 0.431084
global_step: 4542, epoch: 114, loss: 0.517380
global_step: 4543, epoch: 114, loss: 0.446328
global_step: 4544, epoch: 114, loss: 0.420303
global_step: 4545, epoch: 114, loss: 0.446131
global_step: 4546, epoch: 114, loss: 0.478179
global_step: 4547, epoch: 114, loss: 0.518987
global_step: 4548, epoch: 114, loss: 0.445211
global_step: 4549, epoch: 114, loss: 0.466659
global_step: 4550, epoch: 114, loss: 0.490324
global_step: 4551, epoch: 114, loss: 0.347478
global_step: 4552, epoch: 114, loss: 0.494641
global_step: 4553, epoch: 114, loss: 0.486602
global_step: 4554, epoch: 114, loss: 0.461116
global_step: 4555, epoch: 114, loss: 0.457524
global_step: 4556, epoch: 114, loss: 0.430186
global_step: 4557, epoch: 114, loss: 0.415294
global_step: 4558, epoch: 114, loss: 0.526362
global_step: 4559, epoch: 114, loss: 0.565686
global_step: 4560, epoch: 114, loss: 0.190877
epoch: 114
train	acc: 0.9098	macro: p 0.8931, r 0.7647, f1: 0.7892	micro: p 0.9098, r 0.9098, f1 0.9098	weighted_f1:0.9027
dev	acc: 0.5654	macro: p 0.5592, r 0.3683, f1: 0.3796	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5323
test	acc: 0.5954	macro: p 0.3795, r 0.3446, f1: 0.3472	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5650
global_step: 4561, epoch: 115, loss: 0.438449
global_step: 4562, epoch: 115, loss: 0.452957
global_step: 4563, epoch: 115, loss: 0.441742
global_step: 4564, epoch: 115, loss: 0.401145
global_step: 4565, epoch: 115, loss: 0.428363
global_step: 4566, epoch: 115, loss: 0.562391
global_step: 4567, epoch: 115, loss: 0.532606
global_step: 4568, epoch: 115, loss: 0.432198
global_step: 4569, epoch: 115, loss: 0.484766
global_step: 4570, epoch: 115, loss: 0.463304
global_step: 4571, epoch: 115, loss: 0.459894
global_step: 4572, epoch: 115, loss: 0.543010
global_step: 4573, epoch: 115, loss: 0.446663
global_step: 4574, epoch: 115, loss: 0.404231
global_step: 4575, epoch: 115, loss: 0.499564
global_step: 4576, epoch: 115, loss: 0.475584
global_step: 4577, epoch: 115, loss: 0.433226
global_step: 4578, epoch: 115, loss: 0.465840
global_step: 4579, epoch: 115, loss: 0.496066
global_step: 4580, epoch: 115, loss: 0.438105
global_step: 4581, epoch: 115, loss: 0.446628
global_step: 4582, epoch: 115, loss: 0.451398
global_step: 4583, epoch: 115, loss: 0.427399
global_step: 4584, epoch: 115, loss: 0.399941
global_step: 4585, epoch: 115, loss: 0.542493
global_step: 4586, epoch: 115, loss: 0.448342
global_step: 4587, epoch: 115, loss: 0.451477
global_step: 4588, epoch: 115, loss: 0.432894
global_step: 4589, epoch: 115, loss: 0.373210
global_step: 4590, epoch: 115, loss: 0.406742
global_step: 4591, epoch: 115, loss: 0.461311
global_step: 4592, epoch: 115, loss: 0.434176
global_step: 4593, epoch: 115, loss: 0.416990
global_step: 4594, epoch: 115, loss: 0.506057
global_step: 4595, epoch: 115, loss: 0.518479
global_step: 4596, epoch: 115, loss: 0.601719
global_step: 4597, epoch: 115, loss: 0.455335
global_step: 4598, epoch: 115, loss: 0.523407
global_step: 4599, epoch: 115, loss: 0.365791
global_step: 4600, epoch: 115, loss: 0.908923
epoch: 115
train	acc: 0.9002	macro: p 0.8883, r 0.7256, f1: 0.7424	micro: p 0.9002, r 0.9002, f1 0.9002	weighted_f1:0.8889
dev	acc: 0.5609	macro: p 0.3936, r 0.3374, f1: 0.3395	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5204
test	acc: 0.5920	macro: p 0.4054, r 0.3269, f1: 0.3322	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5549
global_step: 4601, epoch: 116, loss: 0.422755
global_step: 4602, epoch: 116, loss: 0.446752
global_step: 4603, epoch: 116, loss: 0.502250
global_step: 4604, epoch: 116, loss: 0.455983
global_step: 4605, epoch: 116, loss: 0.497241
global_step: 4606, epoch: 116, loss: 0.375005
global_step: 4607, epoch: 116, loss: 0.426765
global_step: 4608, epoch: 116, loss: 0.481391
global_step: 4609, epoch: 116, loss: 0.488605
global_step: 4610, epoch: 116, loss: 0.440213
global_step: 4611, epoch: 116, loss: 0.482006
global_step: 4612, epoch: 116, loss: 0.415576
global_step: 4613, epoch: 116, loss: 0.405791
global_step: 4614, epoch: 116, loss: 0.407079
global_step: 4615, epoch: 116, loss: 0.464690
global_step: 4616, epoch: 116, loss: 0.488527
global_step: 4617, epoch: 116, loss: 0.535652
global_step: 4618, epoch: 116, loss: 0.422322
global_step: 4619, epoch: 116, loss: 0.363979
global_step: 4620, epoch: 116, loss: 0.460382
global_step: 4621, epoch: 116, loss: 0.496425
global_step: 4622, epoch: 116, loss: 0.540893
global_step: 4623, epoch: 116, loss: 0.525631
global_step: 4624, epoch: 116, loss: 0.412319
global_step: 4625, epoch: 116, loss: 0.486666
global_step: 4626, epoch: 116, loss: 0.436118
global_step: 4627, epoch: 116, loss: 0.531681
global_step: 4628, epoch: 116, loss: 0.504658
global_step: 4629, epoch: 116, loss: 0.479519
global_step: 4630, epoch: 116, loss: 0.494007
global_step: 4631, epoch: 116, loss: 0.434966
global_step: 4632, epoch: 116, loss: 0.478327
global_step: 4633, epoch: 116, loss: 0.457678
global_step: 4634, epoch: 116, loss: 0.514898
global_step: 4635, epoch: 116, loss: 0.414266
global_step: 4636, epoch: 116, loss: 0.532459
global_step: 4637, epoch: 116, loss: 0.483315
global_step: 4638, epoch: 116, loss: 0.437948
global_step: 4639, epoch: 116, loss: 0.423190
global_step: 4640, epoch: 116, loss: 1.198344
epoch: 116
train	acc: 0.9102	macro: p 0.8917, r 0.7576, f1: 0.7758	micro: p 0.9102, r 0.9102, f1 0.9102	weighted_f1:0.9017
dev	acc: 0.5537	macro: p 0.5496, r 0.3561, f1: 0.3640	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5220
test	acc: 0.5908	macro: p 0.3771, r 0.3439, f1: 0.3430	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5626
global_step: 4641, epoch: 117, loss: 0.438491
global_step: 4642, epoch: 117, loss: 0.478748
global_step: 4643, epoch: 117, loss: 0.439793
global_step: 4644, epoch: 117, loss: 0.409921
global_step: 4645, epoch: 117, loss: 0.440976
global_step: 4646, epoch: 117, loss: 0.410290
global_step: 4647, epoch: 117, loss: 0.442899
global_step: 4648, epoch: 117, loss: 0.427518
global_step: 4649, epoch: 117, loss: 0.410271
global_step: 4650, epoch: 117, loss: 0.435138
global_step: 4651, epoch: 117, loss: 0.517126
global_step: 4652, epoch: 117, loss: 0.379767
global_step: 4653, epoch: 117, loss: 0.466573
global_step: 4654, epoch: 117, loss: 0.473247
global_step: 4655, epoch: 117, loss: 0.424882
global_step: 4656, epoch: 117, loss: 0.402913
global_step: 4657, epoch: 117, loss: 0.497426
global_step: 4658, epoch: 117, loss: 0.432604
global_step: 4659, epoch: 117, loss: 0.396005
global_step: 4660, epoch: 117, loss: 0.436435
global_step: 4661, epoch: 117, loss: 0.443617
global_step: 4662, epoch: 117, loss: 0.476316
global_step: 4663, epoch: 117, loss: 0.443096
global_step: 4664, epoch: 117, loss: 0.483168
global_step: 4665, epoch: 117, loss: 0.400721
global_step: 4666, epoch: 117, loss: 0.536640
global_step: 4667, epoch: 117, loss: 0.466615
global_step: 4668, epoch: 117, loss: 0.548028
global_step: 4669, epoch: 117, loss: 0.531605
global_step: 4670, epoch: 117, loss: 0.493885
global_step: 4671, epoch: 117, loss: 0.412517
global_step: 4672, epoch: 117, loss: 0.443595
global_step: 4673, epoch: 117, loss: 0.454988
global_step: 4674, epoch: 117, loss: 0.518129
global_step: 4675, epoch: 117, loss: 0.429664
global_step: 4676, epoch: 117, loss: 0.420359
global_step: 4677, epoch: 117, loss: 0.496876
global_step: 4678, epoch: 117, loss: 0.515432
global_step: 4679, epoch: 117, loss: 0.434862
global_step: 4680, epoch: 117, loss: 0.215356
epoch: 117
train	acc: 0.9169	macro: p 0.8973, r 0.7718, f1: 0.7963	micro: p 0.9169, r 0.9169, f1 0.9169	weighted_f1:0.9100
dev	acc: 0.5600	macro: p 0.5645, r 0.3596, f1: 0.3697	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5266
test	acc: 0.5935	macro: p 0.3771, r 0.3433, f1: 0.3445	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5642
global_step: 4681, epoch: 118, loss: 0.482895
global_step: 4682, epoch: 118, loss: 0.425037
global_step: 4683, epoch: 118, loss: 0.417897
global_step: 4684, epoch: 118, loss: 0.478928
global_step: 4685, epoch: 118, loss: 0.413577
global_step: 4686, epoch: 118, loss: 0.518549
global_step: 4687, epoch: 118, loss: 0.424663
global_step: 4688, epoch: 118, loss: 0.439515
global_step: 4689, epoch: 118, loss: 0.426500
global_step: 4690, epoch: 118, loss: 0.517497
global_step: 4691, epoch: 118, loss: 0.352105
global_step: 4692, epoch: 118, loss: 0.528792
global_step: 4693, epoch: 118, loss: 0.528602
global_step: 4694, epoch: 118, loss: 0.411704
global_step: 4695, epoch: 118, loss: 0.443521
global_step: 4696, epoch: 118, loss: 0.475179
global_step: 4697, epoch: 118, loss: 0.524243
global_step: 4698, epoch: 118, loss: 0.441682
global_step: 4699, epoch: 118, loss: 0.470764
global_step: 4700, epoch: 118, loss: 0.389273
global_step: 4701, epoch: 118, loss: 0.463087
global_step: 4702, epoch: 118, loss: 0.501331
global_step: 4703, epoch: 118, loss: 0.540552
global_step: 4704, epoch: 118, loss: 0.399534
global_step: 4705, epoch: 118, loss: 0.404083
global_step: 4706, epoch: 118, loss: 0.435240
global_step: 4707, epoch: 118, loss: 0.435516
global_step: 4708, epoch: 118, loss: 0.467244
global_step: 4709, epoch: 118, loss: 0.492313
global_step: 4710, epoch: 118, loss: 0.588695
global_step: 4711, epoch: 118, loss: 0.552895
global_step: 4712, epoch: 118, loss: 0.392774
global_step: 4713, epoch: 118, loss: 0.543106
global_step: 4714, epoch: 118, loss: 0.470496
global_step: 4715, epoch: 118, loss: 0.434683
global_step: 4716, epoch: 118, loss: 0.421949
global_step: 4717, epoch: 118, loss: 0.432668
global_step: 4718, epoch: 118, loss: 0.376274
global_step: 4719, epoch: 118, loss: 0.406021
global_step: 4720, epoch: 118, loss: 0.432031
epoch: 118
train	acc: 0.9041	macro: p 0.8948, r 0.7387, f1: 0.7637	micro: p 0.9041, r 0.9041, f1 0.9041	weighted_f1:0.8943
dev	acc: 0.5582	macro: p 0.5788, r 0.3448, f1: 0.3507	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5168
test	acc: 0.5946	macro: p 0.4054, r 0.3305, f1: 0.3310	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5548
global_step: 4721, epoch: 119, loss: 0.459745
global_step: 4722, epoch: 119, loss: 0.430783
global_step: 4723, epoch: 119, loss: 0.488458
global_step: 4724, epoch: 119, loss: 0.437077
global_step: 4725, epoch: 119, loss: 0.450733
global_step: 4726, epoch: 119, loss: 0.451299
global_step: 4727, epoch: 119, loss: 0.517594
global_step: 4728, epoch: 119, loss: 0.415653
global_step: 4729, epoch: 119, loss: 0.377085
global_step: 4730, epoch: 119, loss: 0.495355
global_step: 4731, epoch: 119, loss: 0.496011
global_step: 4732, epoch: 119, loss: 0.395060
global_step: 4733, epoch: 119, loss: 0.410475
global_step: 4734, epoch: 119, loss: 0.564217
global_step: 4735, epoch: 119, loss: 0.439458
global_step: 4736, epoch: 119, loss: 0.395524
global_step: 4737, epoch: 119, loss: 0.430821
global_step: 4738, epoch: 119, loss: 0.358443
global_step: 4739, epoch: 119, loss: 0.468437
global_step: 4740, epoch: 119, loss: 0.446233
global_step: 4741, epoch: 119, loss: 0.464724
global_step: 4742, epoch: 119, loss: 0.467161
global_step: 4743, epoch: 119, loss: 0.399427
global_step: 4744, epoch: 119, loss: 0.445454
global_step: 4745, epoch: 119, loss: 0.457890
global_step: 4746, epoch: 119, loss: 0.443794
global_step: 4747, epoch: 119, loss: 0.447553
global_step: 4748, epoch: 119, loss: 0.457192
global_step: 4749, epoch: 119, loss: 0.524045
global_step: 4750, epoch: 119, loss: 0.455667
global_step: 4751, epoch: 119, loss: 0.483402
global_step: 4752, epoch: 119, loss: 0.483103
global_step: 4753, epoch: 119, loss: 0.475291
global_step: 4754, epoch: 119, loss: 0.421465
global_step: 4755, epoch: 119, loss: 0.431955
global_step: 4756, epoch: 119, loss: 0.474545
global_step: 4757, epoch: 119, loss: 0.458287
global_step: 4758, epoch: 119, loss: 0.488447
global_step: 4759, epoch: 119, loss: 0.393017
global_step: 4760, epoch: 119, loss: 0.564980
epoch: 119
train	acc: 0.9045	macro: p 0.9004, r 0.7402, f1: 0.7710	micro: p 0.9045, r 0.9045, f1 0.9045	weighted_f1:0.8953
dev	acc: 0.5573	macro: p 0.5729, r 0.3422, f1: 0.3506	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5162
test	acc: 0.6031	macro: p 0.4157, r 0.3344, f1: 0.3384	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5635
global_step: 4761, epoch: 120, loss: 0.512090
global_step: 4762, epoch: 120, loss: 0.455990
global_step: 4763, epoch: 120, loss: 0.450652
global_step: 4764, epoch: 120, loss: 0.371207
global_step: 4765, epoch: 120, loss: 0.514739
global_step: 4766, epoch: 120, loss: 0.436583
global_step: 4767, epoch: 120, loss: 0.427516
global_step: 4768, epoch: 120, loss: 0.381660
global_step: 4769, epoch: 120, loss: 0.423706
global_step: 4770, epoch: 120, loss: 0.501264
global_step: 4771, epoch: 120, loss: 0.377905
global_step: 4772, epoch: 120, loss: 0.409140
global_step: 4773, epoch: 120, loss: 0.485585
global_step: 4774, epoch: 120, loss: 0.500945
global_step: 4775, epoch: 120, loss: 0.426508
global_step: 4776, epoch: 120, loss: 0.460710
global_step: 4777, epoch: 120, loss: 0.363110
global_step: 4778, epoch: 120, loss: 0.497814
global_step: 4779, epoch: 120, loss: 0.446729
global_step: 4780, epoch: 120, loss: 0.438710
global_step: 4781, epoch: 120, loss: 0.357544
global_step: 4782, epoch: 120, loss: 0.466581
global_step: 4783, epoch: 120, loss: 0.390700
global_step: 4784, epoch: 120, loss: 0.378654
global_step: 4785, epoch: 120, loss: 0.442409
global_step: 4786, epoch: 120, loss: 0.423511
global_step: 4787, epoch: 120, loss: 0.410299
global_step: 4788, epoch: 120, loss: 0.460345
global_step: 4789, epoch: 120, loss: 0.442478
global_step: 4790, epoch: 120, loss: 0.594727
global_step: 4791, epoch: 120, loss: 0.390468
global_step: 4792, epoch: 120, loss: 0.463928
global_step: 4793, epoch: 120, loss: 0.429976
global_step: 4794, epoch: 120, loss: 0.390885
global_step: 4795, epoch: 120, loss: 0.477125
global_step: 4796, epoch: 120, loss: 0.405262
global_step: 4797, epoch: 120, loss: 0.355749
global_step: 4798, epoch: 120, loss: 0.513847
global_step: 4799, epoch: 120, loss: 0.467358
global_step: 4800, epoch: 120, loss: 0.275626
epoch: 120
train	acc: 0.9159	macro: p 0.8991, r 0.7698, f1: 0.7907	micro: p 0.9159, r 0.9159, f1 0.9159	weighted_f1:0.9085
dev	acc: 0.5537	macro: p 0.5489, r 0.3645, f1: 0.3772	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5231
test	acc: 0.5958	macro: p 0.3803, r 0.3446, f1: 0.3473	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5684
global_step: 4801, epoch: 121, loss: 0.460230
global_step: 4802, epoch: 121, loss: 0.427290
global_step: 4803, epoch: 121, loss: 0.382761
global_step: 4804, epoch: 121, loss: 0.402695
global_step: 4805, epoch: 121, loss: 0.455307
global_step: 4806, epoch: 121, loss: 0.449482
global_step: 4807, epoch: 121, loss: 0.398175
global_step: 4808, epoch: 121, loss: 0.421199
global_step: 4809, epoch: 121, loss: 0.333154
global_step: 4810, epoch: 121, loss: 0.487610
global_step: 4811, epoch: 121, loss: 0.473311
global_step: 4812, epoch: 121, loss: 0.432090
global_step: 4813, epoch: 121, loss: 0.425788
global_step: 4814, epoch: 121, loss: 0.430400
global_step: 4815, epoch: 121, loss: 0.460197
global_step: 4816, epoch: 121, loss: 0.404870
global_step: 4817, epoch: 121, loss: 0.426952
global_step: 4818, epoch: 121, loss: 0.431787
global_step: 4819, epoch: 121, loss: 0.400303
global_step: 4820, epoch: 121, loss: 0.414932
global_step: 4821, epoch: 121, loss: 0.454294
global_step: 4822, epoch: 121, loss: 0.500454
global_step: 4823, epoch: 121, loss: 0.377042
global_step: 4824, epoch: 121, loss: 0.395409
global_step: 4825, epoch: 121, loss: 0.436806
global_step: 4826, epoch: 121, loss: 0.393927
global_step: 4827, epoch: 121, loss: 0.468183
global_step: 4828, epoch: 121, loss: 0.421829
global_step: 4829, epoch: 121, loss: 0.393184
global_step: 4830, epoch: 121, loss: 0.502924
global_step: 4831, epoch: 121, loss: 0.448420
global_step: 4832, epoch: 121, loss: 0.481349
global_step: 4833, epoch: 121, loss: 0.395042
global_step: 4834, epoch: 121, loss: 0.387255
global_step: 4835, epoch: 121, loss: 0.471060
global_step: 4836, epoch: 121, loss: 0.500868
global_step: 4837, epoch: 121, loss: 0.412526
global_step: 4838, epoch: 121, loss: 0.426238
global_step: 4839, epoch: 121, loss: 0.511253
global_step: 4840, epoch: 121, loss: 0.048585
epoch: 121
train	acc: 0.9153	macro: p 0.9034, r 0.7711, f1: 0.8010	micro: p 0.9153, r 0.9153, f1 0.9153	weighted_f1:0.9089
dev	acc: 0.5591	macro: p 0.5630, r 0.3625, f1: 0.3792	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5263
test	acc: 0.6000	macro: p 0.3921, r 0.3399, f1: 0.3459	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5682
global_step: 4841, epoch: 122, loss: 0.449476
global_step: 4842, epoch: 122, loss: 0.420983
global_step: 4843, epoch: 122, loss: 0.409000
global_step: 4844, epoch: 122, loss: 0.379393
global_step: 4845, epoch: 122, loss: 0.399774
global_step: 4846, epoch: 122, loss: 0.461741
global_step: 4847, epoch: 122, loss: 0.432410
global_step: 4848, epoch: 122, loss: 0.427138
global_step: 4849, epoch: 122, loss: 0.393355
global_step: 4850, epoch: 122, loss: 0.466632
global_step: 4851, epoch: 122, loss: 0.414841
global_step: 4852, epoch: 122, loss: 0.384513
global_step: 4853, epoch: 122, loss: 0.476473
global_step: 4854, epoch: 122, loss: 0.444430
global_step: 4855, epoch: 122, loss: 0.429379
global_step: 4856, epoch: 122, loss: 0.505787
global_step: 4857, epoch: 122, loss: 0.409454
global_step: 4858, epoch: 122, loss: 0.388231
global_step: 4859, epoch: 122, loss: 0.401736
global_step: 4860, epoch: 122, loss: 0.441365
global_step: 4861, epoch: 122, loss: 0.443573
global_step: 4862, epoch: 122, loss: 0.437172
global_step: 4863, epoch: 122, loss: 0.397236
global_step: 4864, epoch: 122, loss: 0.440257
global_step: 4865, epoch: 122, loss: 0.467024
global_step: 4866, epoch: 122, loss: 0.399040
global_step: 4867, epoch: 122, loss: 0.423011
global_step: 4868, epoch: 122, loss: 0.391691
global_step: 4869, epoch: 122, loss: 0.404893
global_step: 4870, epoch: 122, loss: 0.476267
global_step: 4871, epoch: 122, loss: 0.442544
global_step: 4872, epoch: 122, loss: 0.419611
global_step: 4873, epoch: 122, loss: 0.425067
global_step: 4874, epoch: 122, loss: 0.454371
global_step: 4875, epoch: 122, loss: 0.412906
global_step: 4876, epoch: 122, loss: 0.421095
global_step: 4877, epoch: 122, loss: 0.489696
global_step: 4878, epoch: 122, loss: 0.425838
global_step: 4879, epoch: 122, loss: 0.484361
global_step: 4880, epoch: 122, loss: 0.668589
epoch: 122
train	acc: 0.9133	macro: p 0.9072, r 0.7664, f1: 0.7963	micro: p 0.9133, r 0.9133, f1 0.9133	weighted_f1:0.9060
dev	acc: 0.5663	macro: p 0.5670, r 0.3533, f1: 0.3693	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5285
test	acc: 0.5969	macro: p 0.3880, r 0.3272, f1: 0.3356	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5598
global_step: 4881, epoch: 123, loss: 0.398173
global_step: 4882, epoch: 123, loss: 0.435473
global_step: 4883, epoch: 123, loss: 0.479533
global_step: 4884, epoch: 123, loss: 0.399232
global_step: 4885, epoch: 123, loss: 0.505130
global_step: 4886, epoch: 123, loss: 0.406082
global_step: 4887, epoch: 123, loss: 0.388057
global_step: 4888, epoch: 123, loss: 0.457648
global_step: 4889, epoch: 123, loss: 0.420819
global_step: 4890, epoch: 123, loss: 0.463372
global_step: 4891, epoch: 123, loss: 0.431757
global_step: 4892, epoch: 123, loss: 0.412677
global_step: 4893, epoch: 123, loss: 0.360704
global_step: 4894, epoch: 123, loss: 0.394845
global_step: 4895, epoch: 123, loss: 0.364607
global_step: 4896, epoch: 123, loss: 0.378521
global_step: 4897, epoch: 123, loss: 0.465046
global_step: 4898, epoch: 123, loss: 0.464118
global_step: 4899, epoch: 123, loss: 0.458471
global_step: 4900, epoch: 123, loss: 0.458675
global_step: 4901, epoch: 123, loss: 0.480192
global_step: 4902, epoch: 123, loss: 0.361159
global_step: 4903, epoch: 123, loss: 0.422561
global_step: 4904, epoch: 123, loss: 0.378876
global_step: 4905, epoch: 123, loss: 0.451973
global_step: 4906, epoch: 123, loss: 0.407771
global_step: 4907, epoch: 123, loss: 0.506700
global_step: 4908, epoch: 123, loss: 0.425806
global_step: 4909, epoch: 123, loss: 0.425692
global_step: 4910, epoch: 123, loss: 0.387523
global_step: 4911, epoch: 123, loss: 0.412704
global_step: 4912, epoch: 123, loss: 0.436740
global_step: 4913, epoch: 123, loss: 0.475356
global_step: 4914, epoch: 123, loss: 0.416268
global_step: 4915, epoch: 123, loss: 0.477356
global_step: 4916, epoch: 123, loss: 0.405943
global_step: 4917, epoch: 123, loss: 0.425981
global_step: 4918, epoch: 123, loss: 0.432268
global_step: 4919, epoch: 123, loss: 0.440318
global_step: 4920, epoch: 123, loss: 0.807636
epoch: 123
train	acc: 0.9113	macro: p 0.9006, r 0.7704, f1: 0.8031	micro: p 0.9113, r 0.9113, f1 0.9113	weighted_f1:0.9056
dev	acc: 0.5591	macro: p 0.4797, r 0.3378, f1: 0.3541	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5194
test	acc: 0.5989	macro: p 0.4150, r 0.3301, f1: 0.3441	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5624
global_step: 4921, epoch: 124, loss: 0.393692
global_step: 4922, epoch: 124, loss: 0.337837
global_step: 4923, epoch: 124, loss: 0.361652
global_step: 4924, epoch: 124, loss: 0.342679
global_step: 4925, epoch: 124, loss: 0.562798
global_step: 4926, epoch: 124, loss: 0.411273
global_step: 4927, epoch: 124, loss: 0.364426
global_step: 4928, epoch: 124, loss: 0.494713
global_step: 4929, epoch: 124, loss: 0.462753
global_step: 4930, epoch: 124, loss: 0.464640
global_step: 4931, epoch: 124, loss: 0.363992
global_step: 4932, epoch: 124, loss: 0.322126
global_step: 4933, epoch: 124, loss: 0.516228
global_step: 4934, epoch: 124, loss: 0.387576
global_step: 4935, epoch: 124, loss: 0.474196
global_step: 4936, epoch: 124, loss: 0.340534
global_step: 4937, epoch: 124, loss: 0.483440
global_step: 4938, epoch: 124, loss: 0.401652
global_step: 4939, epoch: 124, loss: 0.567378
global_step: 4940, epoch: 124, loss: 0.388432
global_step: 4941, epoch: 124, loss: 0.411233
global_step: 4942, epoch: 124, loss: 0.457850
global_step: 4943, epoch: 124, loss: 0.461945
global_step: 4944, epoch: 124, loss: 0.440816
global_step: 4945, epoch: 124, loss: 0.416458
global_step: 4946, epoch: 124, loss: 0.452403
global_step: 4947, epoch: 124, loss: 0.434143
global_step: 4948, epoch: 124, loss: 0.316683
global_step: 4949, epoch: 124, loss: 0.408999
global_step: 4950, epoch: 124, loss: 0.403681
global_step: 4951, epoch: 124, loss: 0.480168
global_step: 4952, epoch: 124, loss: 0.363550
global_step: 4953, epoch: 124, loss: 0.372609
global_step: 4954, epoch: 124, loss: 0.429901
global_step: 4955, epoch: 124, loss: 0.316868
global_step: 4956, epoch: 124, loss: 0.448716
global_step: 4957, epoch: 124, loss: 0.401486
global_step: 4958, epoch: 124, loss: 0.485574
global_step: 4959, epoch: 124, loss: 0.387246
global_step: 4960, epoch: 124, loss: 0.647080
epoch: 124
train	acc: 0.9237	macro: p 0.9050, r 0.8055, f1: 0.8317	micro: p 0.9237, r 0.9237, f1 0.9237	weighted_f1:0.9195
dev	acc: 0.5618	macro: p 0.4811, r 0.3598, f1: 0.3730	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5302
test	acc: 0.5958	macro: p 0.3836, r 0.3457, f1: 0.3551	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5677
global_step: 4961, epoch: 125, loss: 0.426879
global_step: 4962, epoch: 125, loss: 0.412638
global_step: 4963, epoch: 125, loss: 0.398827
global_step: 4964, epoch: 125, loss: 0.395457
global_step: 4965, epoch: 125, loss: 0.494321
global_step: 4966, epoch: 125, loss: 0.324577
global_step: 4967, epoch: 125, loss: 0.366523
global_step: 4968, epoch: 125, loss: 0.466984
global_step: 4969, epoch: 125, loss: 0.370537
global_step: 4970, epoch: 125, loss: 0.449243
global_step: 4971, epoch: 125, loss: 0.407893
global_step: 4972, epoch: 125, loss: 0.494638
global_step: 4973, epoch: 125, loss: 0.398710
global_step: 4974, epoch: 125, loss: 0.399105
global_step: 4975, epoch: 125, loss: 0.449777
global_step: 4976, epoch: 125, loss: 0.406399
global_step: 4977, epoch: 125, loss: 0.482660
global_step: 4978, epoch: 125, loss: 0.416658
global_step: 4979, epoch: 125, loss: 0.378773
global_step: 4980, epoch: 125, loss: 0.474645
global_step: 4981, epoch: 125, loss: 0.520925
global_step: 4982, epoch: 125, loss: 0.494617
global_step: 4983, epoch: 125, loss: 0.366234
global_step: 4984, epoch: 125, loss: 0.422013
global_step: 4985, epoch: 125, loss: 0.456016
global_step: 4986, epoch: 125, loss: 0.449887
global_step: 4987, epoch: 125, loss: 0.481695
global_step: 4988, epoch: 125, loss: 0.395505
global_step: 4989, epoch: 125, loss: 0.354095
global_step: 4990, epoch: 125, loss: 0.397141
global_step: 4991, epoch: 125, loss: 0.421137
global_step: 4992, epoch: 125, loss: 0.467433
global_step: 4993, epoch: 125, loss: 0.456086
global_step: 4994, epoch: 125, loss: 0.393935
global_step: 4995, epoch: 125, loss: 0.500868
global_step: 4996, epoch: 125, loss: 0.405792
global_step: 4997, epoch: 125, loss: 0.403724
global_step: 4998, epoch: 125, loss: 0.384561
global_step: 4999, epoch: 125, loss: 0.480135
global_step: 5000, epoch: 125, loss: 0.401902
epoch: 125
train	acc: 0.9237	macro: p 0.9180, r 0.8114, f1: 0.8468	micro: p 0.9237, r 0.9237, f1 0.9237	weighted_f1:0.9202
dev	acc: 0.5636	macro: p 0.4477, r 0.3535, f1: 0.3670	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5261
test	acc: 0.5939	macro: p 0.3908, r 0.3348, f1: 0.3454	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5582
global_step: 5001, epoch: 126, loss: 0.318945
global_step: 5002, epoch: 126, loss: 0.504940
global_step: 5003, epoch: 126, loss: 0.352635
global_step: 5004, epoch: 126, loss: 0.392129
global_step: 5005, epoch: 126, loss: 0.467078
global_step: 5006, epoch: 126, loss: 0.451765
global_step: 5007, epoch: 126, loss: 0.422941
global_step: 5008, epoch: 126, loss: 0.462603
global_step: 5009, epoch: 126, loss: 0.455178
global_step: 5010, epoch: 126, loss: 0.509829
global_step: 5011, epoch: 126, loss: 0.345393
global_step: 5012, epoch: 126, loss: 0.515462
global_step: 5013, epoch: 126, loss: 0.435914
global_step: 5014, epoch: 126, loss: 0.444775
global_step: 5015, epoch: 126, loss: 0.425743
global_step: 5016, epoch: 126, loss: 0.449287
global_step: 5017, epoch: 126, loss: 0.438102
global_step: 5018, epoch: 126, loss: 0.391103
global_step: 5019, epoch: 126, loss: 0.387420
global_step: 5020, epoch: 126, loss: 0.390562
global_step: 5021, epoch: 126, loss: 0.434576
global_step: 5022, epoch: 126, loss: 0.456684
global_step: 5023, epoch: 126, loss: 0.401493
global_step: 5024, epoch: 126, loss: 0.418580
global_step: 5025, epoch: 126, loss: 0.436747
global_step: 5026, epoch: 126, loss: 0.382516
global_step: 5027, epoch: 126, loss: 0.417574
global_step: 5028, epoch: 126, loss: 0.483693
global_step: 5029, epoch: 126, loss: 0.409959
global_step: 5030, epoch: 126, loss: 0.337839
global_step: 5031, epoch: 126, loss: 0.385244
global_step: 5032, epoch: 126, loss: 0.390324
global_step: 5033, epoch: 126, loss: 0.413337
global_step: 5034, epoch: 126, loss: 0.375721
global_step: 5035, epoch: 126, loss: 0.432897
global_step: 5036, epoch: 126, loss: 0.419457
global_step: 5037, epoch: 126, loss: 0.404110
global_step: 5038, epoch: 126, loss: 0.452123
global_step: 5039, epoch: 126, loss: 0.404562
global_step: 5040, epoch: 126, loss: 0.321210
epoch: 126
train	acc: 0.9221	macro: p 0.9042, r 0.7900, f1: 0.8160	micro: p 0.9221, r 0.9221, f1 0.9221	weighted_f1:0.9167
dev	acc: 0.5582	macro: p 0.4928, r 0.3666, f1: 0.3802	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5300
test	acc: 0.6011	macro: p 0.3982, r 0.3549, f1: 0.3612	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5771
global_step: 5041, epoch: 127, loss: 0.356075
global_step: 5042, epoch: 127, loss: 0.407970
global_step: 5043, epoch: 127, loss: 0.405947
global_step: 5044, epoch: 127, loss: 0.398193
global_step: 5045, epoch: 127, loss: 0.447385
global_step: 5046, epoch: 127, loss: 0.408965
global_step: 5047, epoch: 127, loss: 0.495973
global_step: 5048, epoch: 127, loss: 0.409061
global_step: 5049, epoch: 127, loss: 0.458186
global_step: 5050, epoch: 127, loss: 0.418823
global_step: 5051, epoch: 127, loss: 0.438240
global_step: 5052, epoch: 127, loss: 0.355955
global_step: 5053, epoch: 127, loss: 0.434084
global_step: 5054, epoch: 127, loss: 0.392673
global_step: 5055, epoch: 127, loss: 0.442507
global_step: 5056, epoch: 127, loss: 0.374858
global_step: 5057, epoch: 127, loss: 0.323785
global_step: 5058, epoch: 127, loss: 0.416224
global_step: 5059, epoch: 127, loss: 0.396737
global_step: 5060, epoch: 127, loss: 0.513515
global_step: 5061, epoch: 127, loss: 0.467903
global_step: 5062, epoch: 127, loss: 0.428724
global_step: 5063, epoch: 127, loss: 0.452854
global_step: 5064, epoch: 127, loss: 0.294630
global_step: 5065, epoch: 127, loss: 0.464557
global_step: 5066, epoch: 127, loss: 0.447722
global_step: 5067, epoch: 127, loss: 0.377632
global_step: 5068, epoch: 127, loss: 0.420557
global_step: 5069, epoch: 127, loss: 0.419490
global_step: 5070, epoch: 127, loss: 0.404800
global_step: 5071, epoch: 127, loss: 0.417205
global_step: 5072, epoch: 127, loss: 0.376701
global_step: 5073, epoch: 127, loss: 0.395009
global_step: 5074, epoch: 127, loss: 0.351634
global_step: 5075, epoch: 127, loss: 0.402135
global_step: 5076, epoch: 127, loss: 0.386564
global_step: 5077, epoch: 127, loss: 0.365564
global_step: 5078, epoch: 127, loss: 0.427348
global_step: 5079, epoch: 127, loss: 0.330568
global_step: 5080, epoch: 127, loss: 0.071790
epoch: 127
train	acc: 0.9178	macro: p 0.9160, r 0.7884, f1: 0.8240	micro: p 0.9178, r 0.9178, f1 0.9178	weighted_f1:0.9125
dev	acc: 0.5663	macro: p 0.4912, r 0.3501, f1: 0.3642	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5254
test	acc: 0.5973	macro: p 0.3957, r 0.3316, f1: 0.3414	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5583
global_step: 5081, epoch: 128, loss: 0.375021
global_step: 5082, epoch: 128, loss: 0.413756
global_step: 5083, epoch: 128, loss: 0.406262
global_step: 5084, epoch: 128, loss: 0.351563
global_step: 5085, epoch: 128, loss: 0.409507
global_step: 5086, epoch: 128, loss: 0.424474
global_step: 5087, epoch: 128, loss: 0.380864
global_step: 5088, epoch: 128, loss: 0.466368
global_step: 5089, epoch: 128, loss: 0.397487
global_step: 5090, epoch: 128, loss: 0.424321
global_step: 5091, epoch: 128, loss: 0.431579
global_step: 5092, epoch: 128, loss: 0.413668
global_step: 5093, epoch: 128, loss: 0.383101
global_step: 5094, epoch: 128, loss: 0.392747
global_step: 5095, epoch: 128, loss: 0.439468
global_step: 5096, epoch: 128, loss: 0.505041
global_step: 5097, epoch: 128, loss: 0.467194
global_step: 5098, epoch: 128, loss: 0.372565
global_step: 5099, epoch: 128, loss: 0.316562
global_step: 5100, epoch: 128, loss: 0.378664
global_step: 5101, epoch: 128, loss: 0.523563
global_step: 5102, epoch: 128, loss: 0.506129
global_step: 5103, epoch: 128, loss: 0.432083
global_step: 5104, epoch: 128, loss: 0.355563
global_step: 5105, epoch: 128, loss: 0.354962
global_step: 5106, epoch: 128, loss: 0.442469
global_step: 5107, epoch: 128, loss: 0.436056
global_step: 5108, epoch: 128, loss: 0.436800
global_step: 5109, epoch: 128, loss: 0.459005
global_step: 5110, epoch: 128, loss: 0.410874
global_step: 5111, epoch: 128, loss: 0.358621
global_step: 5112, epoch: 128, loss: 0.428347
global_step: 5113, epoch: 128, loss: 0.478012
global_step: 5114, epoch: 128, loss: 0.319405
global_step: 5115, epoch: 128, loss: 0.364720
global_step: 5116, epoch: 128, loss: 0.426111
global_step: 5117, epoch: 128, loss: 0.292401
global_step: 5118, epoch: 128, loss: 0.380129
global_step: 5119, epoch: 128, loss: 0.458016
global_step: 5120, epoch: 128, loss: 0.196276
epoch: 128
train	acc: 0.9195	macro: p 0.9186, r 0.7921, f1: 0.8294	micro: p 0.9195, r 0.9195, f1 0.9195	weighted_f1:0.9147
dev	acc: 0.5618	macro: p 0.5648, r 0.3358, f1: 0.3521	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5169
test	acc: 0.5900	macro: p 0.3908, r 0.3185, f1: 0.3305	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5476
global_step: 5121, epoch: 129, loss: 0.345049
global_step: 5122, epoch: 129, loss: 0.333416
global_step: 5123, epoch: 129, loss: 0.449116
global_step: 5124, epoch: 129, loss: 0.344388
global_step: 5125, epoch: 129, loss: 0.355093
global_step: 5126, epoch: 129, loss: 0.344908
global_step: 5127, epoch: 129, loss: 0.463059
global_step: 5128, epoch: 129, loss: 0.336388
global_step: 5129, epoch: 129, loss: 0.438978
global_step: 5130, epoch: 129, loss: 0.395247
global_step: 5131, epoch: 129, loss: 0.454344
global_step: 5132, epoch: 129, loss: 0.416686
global_step: 5133, epoch: 129, loss: 0.363718
global_step: 5134, epoch: 129, loss: 0.455855
global_step: 5135, epoch: 129, loss: 0.336443
global_step: 5136, epoch: 129, loss: 0.502979
global_step: 5137, epoch: 129, loss: 0.343526
global_step: 5138, epoch: 129, loss: 0.395116
global_step: 5139, epoch: 129, loss: 0.362969
global_step: 5140, epoch: 129, loss: 0.427945
global_step: 5141, epoch: 129, loss: 0.406608
global_step: 5142, epoch: 129, loss: 0.461370
global_step: 5143, epoch: 129, loss: 0.429390
global_step: 5144, epoch: 129, loss: 0.452935
global_step: 5145, epoch: 129, loss: 0.462093
global_step: 5146, epoch: 129, loss: 0.417770
global_step: 5147, epoch: 129, loss: 0.356295
global_step: 5148, epoch: 129, loss: 0.306349
global_step: 5149, epoch: 129, loss: 0.418225
global_step: 5150, epoch: 129, loss: 0.472936
global_step: 5151, epoch: 129, loss: 0.407025
global_step: 5152, epoch: 129, loss: 0.348651
global_step: 5153, epoch: 129, loss: 0.404632
global_step: 5154, epoch: 129, loss: 0.330537
global_step: 5155, epoch: 129, loss: 0.433056
global_step: 5156, epoch: 129, loss: 0.372267
global_step: 5157, epoch: 129, loss: 0.354512
global_step: 5158, epoch: 129, loss: 0.391581
global_step: 5159, epoch: 129, loss: 0.382854
global_step: 5160, epoch: 129, loss: 0.411459
epoch: 129
train	acc: 0.9277	macro: p 0.9193, r 0.8142, f1: 0.8429	micro: p 0.9277, r 0.9277, f1 0.9277	weighted_f1:0.9240
dev	acc: 0.5537	macro: p 0.4811, r 0.3581, f1: 0.3649	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5244
test	acc: 0.5870	macro: p 0.3795, r 0.3494, f1: 0.3484	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5627
global_step: 5161, epoch: 130, loss: 0.357594
global_step: 5162, epoch: 130, loss: 0.389910
global_step: 5163, epoch: 130, loss: 0.435156
global_step: 5164, epoch: 130, loss: 0.359757
global_step: 5165, epoch: 130, loss: 0.407079
global_step: 5166, epoch: 130, loss: 0.353334
global_step: 5167, epoch: 130, loss: 0.371257
global_step: 5168, epoch: 130, loss: 0.439012
global_step: 5169, epoch: 130, loss: 0.349787
global_step: 5170, epoch: 130, loss: 0.342041
global_step: 5171, epoch: 130, loss: 0.376302
global_step: 5172, epoch: 130, loss: 0.307403
global_step: 5173, epoch: 130, loss: 0.406618
global_step: 5174, epoch: 130, loss: 0.379598
global_step: 5175, epoch: 130, loss: 0.347874
global_step: 5176, epoch: 130, loss: 0.387189
global_step: 5177, epoch: 130, loss: 0.418920
global_step: 5178, epoch: 130, loss: 0.485668
global_step: 5179, epoch: 130, loss: 0.434885
global_step: 5180, epoch: 130, loss: 0.402229
global_step: 5181, epoch: 130, loss: 0.366826
global_step: 5182, epoch: 130, loss: 0.442892
global_step: 5183, epoch: 130, loss: 0.367956
global_step: 5184, epoch: 130, loss: 0.400248
global_step: 5185, epoch: 130, loss: 0.445522
global_step: 5186, epoch: 130, loss: 0.516186
global_step: 5187, epoch: 130, loss: 0.344700
global_step: 5188, epoch: 130, loss: 0.430844
global_step: 5189, epoch: 130, loss: 0.354547
global_step: 5190, epoch: 130, loss: 0.392540
global_step: 5191, epoch: 130, loss: 0.459460
global_step: 5192, epoch: 130, loss: 0.316467
global_step: 5193, epoch: 130, loss: 0.391258
global_step: 5194, epoch: 130, loss: 0.291753
global_step: 5195, epoch: 130, loss: 0.446752
global_step: 5196, epoch: 130, loss: 0.410636
global_step: 5197, epoch: 130, loss: 0.401179
global_step: 5198, epoch: 130, loss: 0.449940
global_step: 5199, epoch: 130, loss: 0.488959
global_step: 5200, epoch: 130, loss: 0.525007
epoch: 130
train	acc: 0.9274	macro: p 0.9160, r 0.8134, f1: 0.8421	micro: p 0.9274, r 0.9274, f1 0.9274	weighted_f1:0.9236
dev	acc: 0.5491	macro: p 0.5492, r 0.3654, f1: 0.3781	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5220
test	acc: 0.5885	macro: p 0.3733, r 0.3443, f1: 0.3453	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5642
global_step: 5201, epoch: 131, loss: 0.502192
global_step: 5202, epoch: 131, loss: 0.347819
global_step: 5203, epoch: 131, loss: 0.392237
global_step: 5204, epoch: 131, loss: 0.402947
global_step: 5205, epoch: 131, loss: 0.390306
global_step: 5206, epoch: 131, loss: 0.524956
global_step: 5207, epoch: 131, loss: 0.340998
global_step: 5208, epoch: 131, loss: 0.429574
global_step: 5209, epoch: 131, loss: 0.355223
global_step: 5210, epoch: 131, loss: 0.389732
global_step: 5211, epoch: 131, loss: 0.440547
global_step: 5212, epoch: 131, loss: 0.394386
global_step: 5213, epoch: 131, loss: 0.389483
global_step: 5214, epoch: 131, loss: 0.347333
global_step: 5215, epoch: 131, loss: 0.453491
global_step: 5216, epoch: 131, loss: 0.451580
global_step: 5217, epoch: 131, loss: 0.419951
global_step: 5218, epoch: 131, loss: 0.394137
global_step: 5219, epoch: 131, loss: 0.398453
global_step: 5220, epoch: 131, loss: 0.364146
global_step: 5221, epoch: 131, loss: 0.378811
global_step: 5222, epoch: 131, loss: 0.358233
global_step: 5223, epoch: 131, loss: 0.385440
global_step: 5224, epoch: 131, loss: 0.383179
global_step: 5225, epoch: 131, loss: 0.421484
global_step: 5226, epoch: 131, loss: 0.379829
global_step: 5227, epoch: 131, loss: 0.395097
global_step: 5228, epoch: 131, loss: 0.380023
global_step: 5229, epoch: 131, loss: 0.418741
global_step: 5230, epoch: 131, loss: 0.428087
global_step: 5231, epoch: 131, loss: 0.394660
global_step: 5232, epoch: 131, loss: 0.361116
global_step: 5233, epoch: 131, loss: 0.420294
global_step: 5234, epoch: 131, loss: 0.355001
global_step: 5235, epoch: 131, loss: 0.542790
global_step: 5236, epoch: 131, loss: 0.401789
global_step: 5237, epoch: 131, loss: 0.431365
global_step: 5238, epoch: 131, loss: 0.339711
global_step: 5239, epoch: 131, loss: 0.441552
global_step: 5240, epoch: 131, loss: 0.075462
epoch: 131
train	acc: 0.9288	macro: p 0.9254, r 0.8214, f1: 0.8538	micro: p 0.9288, r 0.9288, f1 0.9288	weighted_f1:0.9253
dev	acc: 0.5564	macro: p 0.4546, r 0.3494, f1: 0.3612	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5191
test	acc: 0.5946	macro: p 0.3929, r 0.3356, f1: 0.3442	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5599
global_step: 5241, epoch: 132, loss: 0.482574
global_step: 5242, epoch: 132, loss: 0.438377
global_step: 5243, epoch: 132, loss: 0.355585
global_step: 5244, epoch: 132, loss: 0.383434
global_step: 5245, epoch: 132, loss: 0.361349
global_step: 5246, epoch: 132, loss: 0.352077
global_step: 5247, epoch: 132, loss: 0.415435
global_step: 5248, epoch: 132, loss: 0.377624
global_step: 5249, epoch: 132, loss: 0.425138
global_step: 5250, epoch: 132, loss: 0.415364
global_step: 5251, epoch: 132, loss: 0.322576
global_step: 5252, epoch: 132, loss: 0.313607
global_step: 5253, epoch: 132, loss: 0.394364
global_step: 5254, epoch: 132, loss: 0.474120
global_step: 5255, epoch: 132, loss: 0.356298
global_step: 5256, epoch: 132, loss: 0.378670
global_step: 5257, epoch: 132, loss: 0.334012
global_step: 5258, epoch: 132, loss: 0.432976
global_step: 5259, epoch: 132, loss: 0.384626
global_step: 5260, epoch: 132, loss: 0.442191
global_step: 5261, epoch: 132, loss: 0.293158
global_step: 5262, epoch: 132, loss: 0.373116
global_step: 5263, epoch: 132, loss: 0.452694
global_step: 5264, epoch: 132, loss: 0.382856
global_step: 5265, epoch: 132, loss: 0.400787
global_step: 5266, epoch: 132, loss: 0.353004
global_step: 5267, epoch: 132, loss: 0.408760
global_step: 5268, epoch: 132, loss: 0.393837
global_step: 5269, epoch: 132, loss: 0.411316
global_step: 5270, epoch: 132, loss: 0.351825
global_step: 5271, epoch: 132, loss: 0.437616
global_step: 5272, epoch: 132, loss: 0.485679
global_step: 5273, epoch: 132, loss: 0.320627
global_step: 5274, epoch: 132, loss: 0.369006
global_step: 5275, epoch: 132, loss: 0.436357
global_step: 5276, epoch: 132, loss: 0.471862
global_step: 5277, epoch: 132, loss: 0.378671
global_step: 5278, epoch: 132, loss: 0.390479
global_step: 5279, epoch: 132, loss: 0.405155
global_step: 5280, epoch: 132, loss: 0.099070
epoch: 132
train	acc: 0.9305	macro: p 0.9216, r 0.8215, f1: 0.8506	micro: p 0.9305, r 0.9305, f1 0.9305	weighted_f1:0.9271
dev	acc: 0.5528	macro: p 0.4926, r 0.3548, f1: 0.3702	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5228
test	acc: 0.5950	macro: p 0.3778, r 0.3421, f1: 0.3473	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5684
global_step: 5281, epoch: 133, loss: 0.337059
global_step: 5282, epoch: 133, loss: 0.378398
global_step: 5283, epoch: 133, loss: 0.379474
global_step: 5284, epoch: 133, loss: 0.337874
global_step: 5285, epoch: 133, loss: 0.268084
global_step: 5286, epoch: 133, loss: 0.397790
global_step: 5287, epoch: 133, loss: 0.418259
global_step: 5288, epoch: 133, loss: 0.325316
global_step: 5289, epoch: 133, loss: 0.438324
global_step: 5290, epoch: 133, loss: 0.264175
global_step: 5291, epoch: 133, loss: 0.454845
global_step: 5292, epoch: 133, loss: 0.347505
global_step: 5293, epoch: 133, loss: 0.380918
global_step: 5294, epoch: 133, loss: 0.371221
global_step: 5295, epoch: 133, loss: 0.487659
global_step: 5296, epoch: 133, loss: 0.351285
global_step: 5297, epoch: 133, loss: 0.461467
global_step: 5298, epoch: 133, loss: 0.416092
global_step: 5299, epoch: 133, loss: 0.304584
global_step: 5300, epoch: 133, loss: 0.294126
global_step: 5301, epoch: 133, loss: 0.432309
global_step: 5302, epoch: 133, loss: 0.444966
global_step: 5303, epoch: 133, loss: 0.463723
global_step: 5304, epoch: 133, loss: 0.414780
global_step: 5305, epoch: 133, loss: 0.430275
global_step: 5306, epoch: 133, loss: 0.425068
global_step: 5307, epoch: 133, loss: 0.424406
global_step: 5308, epoch: 133, loss: 0.389153
global_step: 5309, epoch: 133, loss: 0.431163
global_step: 5310, epoch: 133, loss: 0.447372
global_step: 5311, epoch: 133, loss: 0.385375
global_step: 5312, epoch: 133, loss: 0.315343
global_step: 5313, epoch: 133, loss: 0.384757
global_step: 5314, epoch: 133, loss: 0.454929
global_step: 5315, epoch: 133, loss: 0.409845
global_step: 5316, epoch: 133, loss: 0.429362
global_step: 5317, epoch: 133, loss: 0.377918
global_step: 5318, epoch: 133, loss: 0.406289
global_step: 5319, epoch: 133, loss: 0.388366
global_step: 5320, epoch: 133, loss: 0.207406
epoch: 133
train	acc: 0.9286	macro: p 0.9230, r 0.8223, f1: 0.8547	micro: p 0.9286, r 0.9286, f1 0.9286	weighted_f1:0.9255
dev	acc: 0.5609	macro: p 0.4632, r 0.3553, f1: 0.3707	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5249
test	acc: 0.5946	macro: p 0.4003, r 0.3360, f1: 0.3447	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5608
global_step: 5321, epoch: 134, loss: 0.379202
global_step: 5322, epoch: 134, loss: 0.396984
global_step: 5323, epoch: 134, loss: 0.390313
global_step: 5324, epoch: 134, loss: 0.367548
global_step: 5325, epoch: 134, loss: 0.417058
global_step: 5326, epoch: 134, loss: 0.393427
global_step: 5327, epoch: 134, loss: 0.326542
global_step: 5328, epoch: 134, loss: 0.408881
global_step: 5329, epoch: 134, loss: 0.357553
global_step: 5330, epoch: 134, loss: 0.337383
global_step: 5331, epoch: 134, loss: 0.327897
global_step: 5332, epoch: 134, loss: 0.413306
global_step: 5333, epoch: 134, loss: 0.308356
global_step: 5334, epoch: 134, loss: 0.358900
global_step: 5335, epoch: 134, loss: 0.341833
global_step: 5336, epoch: 134, loss: 0.353986
global_step: 5337, epoch: 134, loss: 0.380626
global_step: 5338, epoch: 134, loss: 0.451254
global_step: 5339, epoch: 134, loss: 0.349815
global_step: 5340, epoch: 134, loss: 0.369310
global_step: 5341, epoch: 134, loss: 0.332949
global_step: 5342, epoch: 134, loss: 0.432097
global_step: 5343, epoch: 134, loss: 0.325383
global_step: 5344, epoch: 134, loss: 0.382412
global_step: 5345, epoch: 134, loss: 0.404079
global_step: 5346, epoch: 134, loss: 0.447879
global_step: 5347, epoch: 134, loss: 0.433598
global_step: 5348, epoch: 134, loss: 0.372168
global_step: 5349, epoch: 134, loss: 0.389627
global_step: 5350, epoch: 134, loss: 0.397988
global_step: 5351, epoch: 134, loss: 0.421494
global_step: 5352, epoch: 134, loss: 0.319019
global_step: 5353, epoch: 134, loss: 0.387519
global_step: 5354, epoch: 134, loss: 0.375189
global_step: 5355, epoch: 134, loss: 0.341858
global_step: 5356, epoch: 134, loss: 0.397301
global_step: 5357, epoch: 134, loss: 0.455372
global_step: 5358, epoch: 134, loss: 0.441594
global_step: 5359, epoch: 134, loss: 0.399213
global_step: 5360, epoch: 134, loss: 0.695492
epoch: 134
train	acc: 0.9337	macro: p 0.9265, r 0.8361, f1: 0.8652	micro: p 0.9337, r 0.9337, f1 0.9337	weighted_f1:0.9310
dev	acc: 0.5528	macro: p 0.4594, r 0.3566, f1: 0.3674	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5208
test	acc: 0.5904	macro: p 0.3891, r 0.3426, f1: 0.3491	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5610
global_step: 5361, epoch: 135, loss: 0.383273
global_step: 5362, epoch: 135, loss: 0.403455
global_step: 5363, epoch: 135, loss: 0.318206
global_step: 5364, epoch: 135, loss: 0.313168
global_step: 5365, epoch: 135, loss: 0.456072
global_step: 5366, epoch: 135, loss: 0.307739
global_step: 5367, epoch: 135, loss: 0.449971
global_step: 5368, epoch: 135, loss: 0.422307
global_step: 5369, epoch: 135, loss: 0.303813
global_step: 5370, epoch: 135, loss: 0.346794
global_step: 5371, epoch: 135, loss: 0.479475
global_step: 5372, epoch: 135, loss: 0.425323
global_step: 5373, epoch: 135, loss: 0.447111
global_step: 5374, epoch: 135, loss: 0.404207
global_step: 5375, epoch: 135, loss: 0.426047
global_step: 5376, epoch: 135, loss: 0.322033
global_step: 5377, epoch: 135, loss: 0.386570
global_step: 5378, epoch: 135, loss: 0.361053
global_step: 5379, epoch: 135, loss: 0.376551
global_step: 5380, epoch: 135, loss: 0.464750
global_step: 5381, epoch: 135, loss: 0.381423
global_step: 5382, epoch: 135, loss: 0.382086
global_step: 5383, epoch: 135, loss: 0.445271
global_step: 5384, epoch: 135, loss: 0.416022
global_step: 5385, epoch: 135, loss: 0.318754
global_step: 5386, epoch: 135, loss: 0.400437
global_step: 5387, epoch: 135, loss: 0.374690
global_step: 5388, epoch: 135, loss: 0.444880
global_step: 5389, epoch: 135, loss: 0.382341
global_step: 5390, epoch: 135, loss: 0.415359
global_step: 5391, epoch: 135, loss: 0.393405
global_step: 5392, epoch: 135, loss: 0.361673
global_step: 5393, epoch: 135, loss: 0.361083
global_step: 5394, epoch: 135, loss: 0.412053
global_step: 5395, epoch: 135, loss: 0.448764
global_step: 5396, epoch: 135, loss: 0.379688
global_step: 5397, epoch: 135, loss: 0.352183
global_step: 5398, epoch: 135, loss: 0.362430
global_step: 5399, epoch: 135, loss: 0.375875
global_step: 5400, epoch: 135, loss: 0.948614
epoch: 135
train	acc: 0.9347	macro: p 0.9278, r 0.8441, f1: 0.8740	micro: p 0.9347, r 0.9347, f1 0.9347	weighted_f1:0.9329
dev	acc: 0.5528	macro: p 0.4211, r 0.3535, f1: 0.3670	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5209
test	acc: 0.5801	macro: p 0.3955, r 0.3359, f1: 0.3475	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5514
global_step: 5401, epoch: 136, loss: 0.392989
global_step: 5402, epoch: 136, loss: 0.341856
global_step: 5403, epoch: 136, loss: 0.416654
global_step: 5404, epoch: 136, loss: 0.431317
global_step: 5405, epoch: 136, loss: 0.391519
global_step: 5406, epoch: 136, loss: 0.386819
global_step: 5407, epoch: 136, loss: 0.359187
global_step: 5408, epoch: 136, loss: 0.431130
global_step: 5409, epoch: 136, loss: 0.415474
global_step: 5410, epoch: 136, loss: 0.333446
global_step: 5411, epoch: 136, loss: 0.355682
global_step: 5412, epoch: 136, loss: 0.387296
global_step: 5413, epoch: 136, loss: 0.444750
global_step: 5414, epoch: 136, loss: 0.395156
global_step: 5415, epoch: 136, loss: 0.391157
global_step: 5416, epoch: 136, loss: 0.405080
global_step: 5417, epoch: 136, loss: 0.365179
global_step: 5418, epoch: 136, loss: 0.387038
global_step: 5419, epoch: 136, loss: 0.350235
global_step: 5420, epoch: 136, loss: 0.303899
global_step: 5421, epoch: 136, loss: 0.342443
global_step: 5422, epoch: 136, loss: 0.424698
global_step: 5423, epoch: 136, loss: 0.422363
global_step: 5424, epoch: 136, loss: 0.417364
global_step: 5425, epoch: 136, loss: 0.412648
global_step: 5426, epoch: 136, loss: 0.340756
global_step: 5427, epoch: 136, loss: 0.430169
global_step: 5428, epoch: 136, loss: 0.396146
global_step: 5429, epoch: 136, loss: 0.315877
global_step: 5430, epoch: 136, loss: 0.337197
global_step: 5431, epoch: 136, loss: 0.425104
global_step: 5432, epoch: 136, loss: 0.381418
global_step: 5433, epoch: 136, loss: 0.353432
global_step: 5434, epoch: 136, loss: 0.384897
global_step: 5435, epoch: 136, loss: 0.451019
global_step: 5436, epoch: 136, loss: 0.382882
global_step: 5437, epoch: 136, loss: 0.308285
global_step: 5438, epoch: 136, loss: 0.302180
global_step: 5439, epoch: 136, loss: 0.374600
global_step: 5440, epoch: 136, loss: 0.154657
epoch: 136
train	acc: 0.9331	macro: p 0.9330, r 0.8362, f1: 0.8697	micro: p 0.9331, r 0.9331, f1 0.9331	weighted_f1:0.9306
dev	acc: 0.5546	macro: p 0.4732, r 0.3500, f1: 0.3599	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5193
test	acc: 0.5904	macro: p 0.3850, r 0.3347, f1: 0.3404	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5586
global_step: 5441, epoch: 137, loss: 0.382401
global_step: 5442, epoch: 137, loss: 0.302711
global_step: 5443, epoch: 137, loss: 0.405819
global_step: 5444, epoch: 137, loss: 0.402278
global_step: 5445, epoch: 137, loss: 0.430352
global_step: 5446, epoch: 137, loss: 0.437309
global_step: 5447, epoch: 137, loss: 0.318303
global_step: 5448, epoch: 137, loss: 0.403974
global_step: 5449, epoch: 137, loss: 0.328803
global_step: 5450, epoch: 137, loss: 0.348227
global_step: 5451, epoch: 137, loss: 0.290590
global_step: 5452, epoch: 137, loss: 0.320262
global_step: 5453, epoch: 137, loss: 0.440234
global_step: 5454, epoch: 137, loss: 0.352664
global_step: 5455, epoch: 137, loss: 0.409834
global_step: 5456, epoch: 137, loss: 0.310307
global_step: 5457, epoch: 137, loss: 0.403198
global_step: 5458, epoch: 137, loss: 0.381267
global_step: 5459, epoch: 137, loss: 0.378668
global_step: 5460, epoch: 137, loss: 0.364377
global_step: 5461, epoch: 137, loss: 0.418870
global_step: 5462, epoch: 137, loss: 0.437532
global_step: 5463, epoch: 137, loss: 0.375761
global_step: 5464, epoch: 137, loss: 0.334655
global_step: 5465, epoch: 137, loss: 0.457214
global_step: 5466, epoch: 137, loss: 0.371561
global_step: 5467, epoch: 137, loss: 0.334488
global_step: 5468, epoch: 137, loss: 0.303878
global_step: 5469, epoch: 137, loss: 0.375059
global_step: 5470, epoch: 137, loss: 0.429653
global_step: 5471, epoch: 137, loss: 0.315090
global_step: 5472, epoch: 137, loss: 0.320138
global_step: 5473, epoch: 137, loss: 0.365038
global_step: 5474, epoch: 137, loss: 0.340161
global_step: 5475, epoch: 137, loss: 0.394058
global_step: 5476, epoch: 137, loss: 0.331928
global_step: 5477, epoch: 137, loss: 0.386931
global_step: 5478, epoch: 137, loss: 0.383308
global_step: 5479, epoch: 137, loss: 0.465486
global_step: 5480, epoch: 137, loss: 0.397229
epoch: 137
train	acc: 0.9407	macro: p 0.9268, r 0.8675, f1: 0.8899	micro: p 0.9407, r 0.9407, f1 0.9407	weighted_f1:0.9396
dev	acc: 0.5383	macro: p 0.4200, r 0.3772, f1: 0.3842	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5235
test	acc: 0.5793	macro: p 0.3806, r 0.3706, f1: 0.3724	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5723
global_step: 5481, epoch: 138, loss: 0.294476
global_step: 5482, epoch: 138, loss: 0.323308
global_step: 5483, epoch: 138, loss: 0.292647
global_step: 5484, epoch: 138, loss: 0.326002
global_step: 5485, epoch: 138, loss: 0.335910
global_step: 5486, epoch: 138, loss: 0.447296
global_step: 5487, epoch: 138, loss: 0.311545
global_step: 5488, epoch: 138, loss: 0.296798
global_step: 5489, epoch: 138, loss: 0.334888
global_step: 5490, epoch: 138, loss: 0.378416
global_step: 5491, epoch: 138, loss: 0.419928
global_step: 5492, epoch: 138, loss: 0.442489
global_step: 5493, epoch: 138, loss: 0.360090
global_step: 5494, epoch: 138, loss: 0.314364
global_step: 5495, epoch: 138, loss: 0.325363
global_step: 5496, epoch: 138, loss: 0.397564
global_step: 5497, epoch: 138, loss: 0.402364
global_step: 5498, epoch: 138, loss: 0.438817
global_step: 5499, epoch: 138, loss: 0.431483
global_step: 5500, epoch: 138, loss: 0.336902
global_step: 5501, epoch: 138, loss: 0.408084
global_step: 5502, epoch: 138, loss: 0.450548
global_step: 5503, epoch: 138, loss: 0.397521
global_step: 5504, epoch: 138, loss: 0.356116
global_step: 5505, epoch: 138, loss: 0.326557
global_step: 5506, epoch: 138, loss: 0.440432
global_step: 5507, epoch: 138, loss: 0.427512
global_step: 5508, epoch: 138, loss: 0.418598
global_step: 5509, epoch: 138, loss: 0.300867
global_step: 5510, epoch: 138, loss: 0.470879
global_step: 5511, epoch: 138, loss: 0.362548
global_step: 5512, epoch: 138, loss: 0.358176
global_step: 5513, epoch: 138, loss: 0.390953
global_step: 5514, epoch: 138, loss: 0.389507
global_step: 5515, epoch: 138, loss: 0.396957
global_step: 5516, epoch: 138, loss: 0.424918
global_step: 5517, epoch: 138, loss: 0.352127
global_step: 5518, epoch: 138, loss: 0.477191
global_step: 5519, epoch: 138, loss: 0.331612
global_step: 5520, epoch: 138, loss: 0.553809
epoch: 138
train	acc: 0.9399	macro: p 0.9333, r 0.8659, f1: 0.8921	micro: p 0.9399, r 0.9399, f1 0.9399	weighted_f1:0.9387
dev	acc: 0.5455	macro: p 0.4125, r 0.3540, f1: 0.3644	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5199
test	acc: 0.5877	macro: p 0.3947, r 0.3532, f1: 0.3621	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5681
global_step: 5521, epoch: 139, loss: 0.358036
global_step: 5522, epoch: 139, loss: 0.363216
global_step: 5523, epoch: 139, loss: 0.367205
global_step: 5524, epoch: 139, loss: 0.453526
global_step: 5525, epoch: 139, loss: 0.358522
global_step: 5526, epoch: 139, loss: 0.314685
global_step: 5527, epoch: 139, loss: 0.390952
global_step: 5528, epoch: 139, loss: 0.361549
global_step: 5529, epoch: 139, loss: 0.360525
global_step: 5530, epoch: 139, loss: 0.389384
global_step: 5531, epoch: 139, loss: 0.350083
global_step: 5532, epoch: 139, loss: 0.328174
global_step: 5533, epoch: 139, loss: 0.376714
global_step: 5534, epoch: 139, loss: 0.345131
global_step: 5535, epoch: 139, loss: 0.390150
global_step: 5536, epoch: 139, loss: 0.388693
global_step: 5537, epoch: 139, loss: 0.428416
global_step: 5538, epoch: 139, loss: 0.392150
global_step: 5539, epoch: 139, loss: 0.383366
global_step: 5540, epoch: 139, loss: 0.374692
global_step: 5541, epoch: 139, loss: 0.381517
global_step: 5542, epoch: 139, loss: 0.399437
global_step: 5543, epoch: 139, loss: 0.300965
global_step: 5544, epoch: 139, loss: 0.380330
global_step: 5545, epoch: 139, loss: 0.339855
global_step: 5546, epoch: 139, loss: 0.310713
global_step: 5547, epoch: 139, loss: 0.283976
global_step: 5548, epoch: 139, loss: 0.324689
global_step: 5549, epoch: 139, loss: 0.370370
global_step: 5550, epoch: 139, loss: 0.353685
global_step: 5551, epoch: 139, loss: 0.379198
global_step: 5552, epoch: 139, loss: 0.451817
global_step: 5553, epoch: 139, loss: 0.283694
global_step: 5554, epoch: 139, loss: 0.386812
global_step: 5555, epoch: 139, loss: 0.317295
global_step: 5556, epoch: 139, loss: 0.377196
global_step: 5557, epoch: 139, loss: 0.385308
global_step: 5558, epoch: 139, loss: 0.466768
global_step: 5559, epoch: 139, loss: 0.323244
global_step: 5560, epoch: 139, loss: 0.872855
epoch: 139
train	acc: 0.9352	macro: p 0.9404, r 0.8532, f1: 0.8885	micro: p 0.9352, r 0.9352, f1 0.9352	weighted_f1:0.9336
dev	acc: 0.5582	macro: p 0.4642, r 0.3459, f1: 0.3661	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5196
test	acc: 0.5908	macro: p 0.4024, r 0.3278, f1: 0.3430	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5550
global_step: 5561, epoch: 140, loss: 0.404708
global_step: 5562, epoch: 140, loss: 0.380321
global_step: 5563, epoch: 140, loss: 0.407084
global_step: 5564, epoch: 140, loss: 0.334973
global_step: 5565, epoch: 140, loss: 0.385514
global_step: 5566, epoch: 140, loss: 0.333168
global_step: 5567, epoch: 140, loss: 0.285299
global_step: 5568, epoch: 140, loss: 0.452164
global_step: 5569, epoch: 140, loss: 0.414397
global_step: 5570, epoch: 140, loss: 0.348236
global_step: 5571, epoch: 140, loss: 0.338130
global_step: 5572, epoch: 140, loss: 0.343230
global_step: 5573, epoch: 140, loss: 0.386711
global_step: 5574, epoch: 140, loss: 0.415149
global_step: 5575, epoch: 140, loss: 0.415339
global_step: 5576, epoch: 140, loss: 0.397470
global_step: 5577, epoch: 140, loss: 0.332025
global_step: 5578, epoch: 140, loss: 0.347499
global_step: 5579, epoch: 140, loss: 0.288540
global_step: 5580, epoch: 140, loss: 0.313851
global_step: 5581, epoch: 140, loss: 0.291635
global_step: 5582, epoch: 140, loss: 0.345755
global_step: 5583, epoch: 140, loss: 0.355286
global_step: 5584, epoch: 140, loss: 0.337229
global_step: 5585, epoch: 140, loss: 0.392001
global_step: 5586, epoch: 140, loss: 0.386198
global_step: 5587, epoch: 140, loss: 0.364361
global_step: 5588, epoch: 140, loss: 0.383855
global_step: 5589, epoch: 140, loss: 0.328723
global_step: 5590, epoch: 140, loss: 0.412949
global_step: 5591, epoch: 140, loss: 0.372100
global_step: 5592, epoch: 140, loss: 0.303368
global_step: 5593, epoch: 140, loss: 0.379772
global_step: 5594, epoch: 140, loss: 0.355070
global_step: 5595, epoch: 140, loss: 0.359464
global_step: 5596, epoch: 140, loss: 0.415308
global_step: 5597, epoch: 140, loss: 0.417736
global_step: 5598, epoch: 140, loss: 0.394371
global_step: 5599, epoch: 140, loss: 0.335272
global_step: 5600, epoch: 140, loss: 0.062444
epoch: 140
train	acc: 0.9338	macro: p 0.9383, r 0.8416, f1: 0.8772	micro: p 0.9338, r 0.9338, f1 0.9338	weighted_f1:0.9315
dev	acc: 0.5645	macro: p 0.4692, r 0.3436, f1: 0.3558	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5198
test	acc: 0.5923	macro: p 0.4088, r 0.3267, f1: 0.3390	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5524
global_step: 5601, epoch: 141, loss: 0.348973
global_step: 5602, epoch: 141, loss: 0.403221
global_step: 5603, epoch: 141, loss: 0.329045
global_step: 5604, epoch: 141, loss: 0.331841
global_step: 5605, epoch: 141, loss: 0.310711
global_step: 5606, epoch: 141, loss: 0.297065
global_step: 5607, epoch: 141, loss: 0.310667
global_step: 5608, epoch: 141, loss: 0.449544
global_step: 5609, epoch: 141, loss: 0.328044
global_step: 5610, epoch: 141, loss: 0.336130
global_step: 5611, epoch: 141, loss: 0.336905
global_step: 5612, epoch: 141, loss: 0.327923
global_step: 5613, epoch: 141, loss: 0.377053
global_step: 5614, epoch: 141, loss: 0.303214
global_step: 5615, epoch: 141, loss: 0.323857
global_step: 5616, epoch: 141, loss: 0.403122
global_step: 5617, epoch: 141, loss: 0.398872
global_step: 5618, epoch: 141, loss: 0.451125
global_step: 5619, epoch: 141, loss: 0.343822
global_step: 5620, epoch: 141, loss: 0.340068
global_step: 5621, epoch: 141, loss: 0.319498
global_step: 5622, epoch: 141, loss: 0.301947
global_step: 5623, epoch: 141, loss: 0.424393
global_step: 5624, epoch: 141, loss: 0.364591
global_step: 5625, epoch: 141, loss: 0.353715
global_step: 5626, epoch: 141, loss: 0.357124
global_step: 5627, epoch: 141, loss: 0.337732
global_step: 5628, epoch: 141, loss: 0.366977
global_step: 5629, epoch: 141, loss: 0.293529
global_step: 5630, epoch: 141, loss: 0.384276
global_step: 5631, epoch: 141, loss: 0.377892
global_step: 5632, epoch: 141, loss: 0.390735
global_step: 5633, epoch: 141, loss: 0.367515
global_step: 5634, epoch: 141, loss: 0.373445
global_step: 5635, epoch: 141, loss: 0.469901
global_step: 5636, epoch: 141, loss: 0.467393
global_step: 5637, epoch: 141, loss: 0.340448
global_step: 5638, epoch: 141, loss: 0.475229
global_step: 5639, epoch: 141, loss: 0.325778
global_step: 5640, epoch: 141, loss: 0.097562
epoch: 141
train	acc: 0.9399	macro: p 0.9409, r 0.8623, f1: 0.8927	micro: p 0.9399, r 0.9399, f1 0.9399	weighted_f1:0.9385
dev	acc: 0.5582	macro: p 0.4677, r 0.3558, f1: 0.3626	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5191
test	acc: 0.5912	macro: p 0.4060, r 0.3440, f1: 0.3513	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5594
global_step: 5641, epoch: 142, loss: 0.354164
global_step: 5642, epoch: 142, loss: 0.369133
global_step: 5643, epoch: 142, loss: 0.356256
global_step: 5644, epoch: 142, loss: 0.390835
global_step: 5645, epoch: 142, loss: 0.397317
global_step: 5646, epoch: 142, loss: 0.365764
global_step: 5647, epoch: 142, loss: 0.355675
global_step: 5648, epoch: 142, loss: 0.343240
global_step: 5649, epoch: 142, loss: 0.344954
global_step: 5650, epoch: 142, loss: 0.339163
global_step: 5651, epoch: 142, loss: 0.294836
global_step: 5652, epoch: 142, loss: 0.379109
global_step: 5653, epoch: 142, loss: 0.349474
global_step: 5654, epoch: 142, loss: 0.293379
global_step: 5655, epoch: 142, loss: 0.427956
global_step: 5656, epoch: 142, loss: 0.337803
global_step: 5657, epoch: 142, loss: 0.302153
global_step: 5658, epoch: 142, loss: 0.287595
global_step: 5659, epoch: 142, loss: 0.357688
global_step: 5660, epoch: 142, loss: 0.421760
global_step: 5661, epoch: 142, loss: 0.339021
global_step: 5662, epoch: 142, loss: 0.368026
global_step: 5663, epoch: 142, loss: 0.269043
global_step: 5664, epoch: 142, loss: 0.319156
global_step: 5665, epoch: 142, loss: 0.359802
global_step: 5666, epoch: 142, loss: 0.346466
global_step: 5667, epoch: 142, loss: 0.382526
global_step: 5668, epoch: 142, loss: 0.368276
global_step: 5669, epoch: 142, loss: 0.359289
global_step: 5670, epoch: 142, loss: 0.462397
global_step: 5671, epoch: 142, loss: 0.387724
global_step: 5672, epoch: 142, loss: 0.312312
global_step: 5673, epoch: 142, loss: 0.383408
global_step: 5674, epoch: 142, loss: 0.361631
global_step: 5675, epoch: 142, loss: 0.405603
global_step: 5676, epoch: 142, loss: 0.437813
global_step: 5677, epoch: 142, loss: 0.371009
global_step: 5678, epoch: 142, loss: 0.386989
global_step: 5679, epoch: 142, loss: 0.346318
global_step: 5680, epoch: 142, loss: 0.630145
epoch: 142
train	acc: 0.9383	macro: p 0.9336, r 0.8541, f1: 0.8817	micro: p 0.9383, r 0.9383, f1 0.9383	weighted_f1:0.9365
dev	acc: 0.5591	macro: p 0.4317, r 0.3494, f1: 0.3618	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5239
test	acc: 0.5889	macro: p 0.4057, r 0.3356, f1: 0.3488	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5563
global_step: 5681, epoch: 143, loss: 0.388950
global_step: 5682, epoch: 143, loss: 0.316427
global_step: 5683, epoch: 143, loss: 0.402956
global_step: 5684, epoch: 143, loss: 0.343081
global_step: 5685, epoch: 143, loss: 0.377083
global_step: 5686, epoch: 143, loss: 0.357426
global_step: 5687, epoch: 143, loss: 0.391529
global_step: 5688, epoch: 143, loss: 0.378172
global_step: 5689, epoch: 143, loss: 0.345521
global_step: 5690, epoch: 143, loss: 0.314002
global_step: 5691, epoch: 143, loss: 0.443365
global_step: 5692, epoch: 143, loss: 0.355551
global_step: 5693, epoch: 143, loss: 0.410127
global_step: 5694, epoch: 143, loss: 0.321842
global_step: 5695, epoch: 143, loss: 0.318111
global_step: 5696, epoch: 143, loss: 0.398047
global_step: 5697, epoch: 143, loss: 0.365824
global_step: 5698, epoch: 143, loss: 0.298638
global_step: 5699, epoch: 143, loss: 0.386257
global_step: 5700, epoch: 143, loss: 0.310651
global_step: 5701, epoch: 143, loss: 0.302685
global_step: 5702, epoch: 143, loss: 0.320137
global_step: 5703, epoch: 143, loss: 0.340677
global_step: 5704, epoch: 143, loss: 0.325483
global_step: 5705, epoch: 143, loss: 0.341874
global_step: 5706, epoch: 143, loss: 0.338695
global_step: 5707, epoch: 143, loss: 0.387298
global_step: 5708, epoch: 143, loss: 0.354043
global_step: 5709, epoch: 143, loss: 0.315021
global_step: 5710, epoch: 143, loss: 0.294471
global_step: 5711, epoch: 143, loss: 0.335569
global_step: 5712, epoch: 143, loss: 0.421261
global_step: 5713, epoch: 143, loss: 0.368469
global_step: 5714, epoch: 143, loss: 0.354801
global_step: 5715, epoch: 143, loss: 0.353314
global_step: 5716, epoch: 143, loss: 0.335051
global_step: 5717, epoch: 143, loss: 0.354501
global_step: 5718, epoch: 143, loss: 0.371694
global_step: 5719, epoch: 143, loss: 0.406329
global_step: 5720, epoch: 143, loss: 0.018928
epoch: 143
train	acc: 0.9442	macro: p 0.9439, r 0.8748, f1: 0.9017	micro: p 0.9442, r 0.9442, f1 0.9442	weighted_f1:0.9431
dev	acc: 0.5582	macro: p 0.4743, r 0.3701, f1: 0.3828	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5297
test	acc: 0.5973	macro: p 0.3901, r 0.3521, f1: 0.3585	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5719
global_step: 5721, epoch: 144, loss: 0.387992
global_step: 5722, epoch: 144, loss: 0.393465
global_step: 5723, epoch: 144, loss: 0.357439
global_step: 5724, epoch: 144, loss: 0.336548
global_step: 5725, epoch: 144, loss: 0.280613
global_step: 5726, epoch: 144, loss: 0.382008
global_step: 5727, epoch: 144, loss: 0.328614
global_step: 5728, epoch: 144, loss: 0.371770
global_step: 5729, epoch: 144, loss: 0.345576
global_step: 5730, epoch: 144, loss: 0.353119
global_step: 5731, epoch: 144, loss: 0.400552
global_step: 5732, epoch: 144, loss: 0.373227
global_step: 5733, epoch: 144, loss: 0.384729
global_step: 5734, epoch: 144, loss: 0.337088
global_step: 5735, epoch: 144, loss: 0.343286
global_step: 5736, epoch: 144, loss: 0.358789
global_step: 5737, epoch: 144, loss: 0.322965
global_step: 5738, epoch: 144, loss: 0.367472
global_step: 5739, epoch: 144, loss: 0.333049
global_step: 5740, epoch: 144, loss: 0.398808
global_step: 5741, epoch: 144, loss: 0.354832
global_step: 5742, epoch: 144, loss: 0.360805
global_step: 5743, epoch: 144, loss: 0.390953
global_step: 5744, epoch: 144, loss: 0.373024
global_step: 5745, epoch: 144, loss: 0.326062
global_step: 5746, epoch: 144, loss: 0.443498
global_step: 5747, epoch: 144, loss: 0.353694
global_step: 5748, epoch: 144, loss: 0.314492
global_step: 5749, epoch: 144, loss: 0.371213
global_step: 5750, epoch: 144, loss: 0.282800
global_step: 5751, epoch: 144, loss: 0.354202
global_step: 5752, epoch: 144, loss: 0.392480
global_step: 5753, epoch: 144, loss: 0.361627
global_step: 5754, epoch: 144, loss: 0.293997
global_step: 5755, epoch: 144, loss: 0.328798
global_step: 5756, epoch: 144, loss: 0.267060
global_step: 5757, epoch: 144, loss: 0.367854
global_step: 5758, epoch: 144, loss: 0.390874
global_step: 5759, epoch: 144, loss: 0.365030
global_step: 5760, epoch: 144, loss: 0.303600
epoch: 144
train	acc: 0.9410	macro: p 0.9435, r 0.8642, f1: 0.8944	micro: p 0.9410, r 0.9410, f1 0.9410	weighted_f1:0.9396
dev	acc: 0.5627	macro: p 0.4897, r 0.3654, f1: 0.3796	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5314
test	acc: 0.5973	macro: p 0.3978, r 0.3482, f1: 0.3533	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5694
global_step: 5761, epoch: 145, loss: 0.318582
global_step: 5762, epoch: 145, loss: 0.318754
global_step: 5763, epoch: 145, loss: 0.312742
global_step: 5764, epoch: 145, loss: 0.212658
global_step: 5765, epoch: 145, loss: 0.345225
global_step: 5766, epoch: 145, loss: 0.442306
global_step: 5767, epoch: 145, loss: 0.308147
global_step: 5768, epoch: 145, loss: 0.315092
global_step: 5769, epoch: 145, loss: 0.276898
global_step: 5770, epoch: 145, loss: 0.295237
global_step: 5771, epoch: 145, loss: 0.296562
global_step: 5772, epoch: 145, loss: 0.443897
global_step: 5773, epoch: 145, loss: 0.322469
global_step: 5774, epoch: 145, loss: 0.319113
global_step: 5775, epoch: 145, loss: 0.345140
global_step: 5776, epoch: 145, loss: 0.409860
global_step: 5777, epoch: 145, loss: 0.376788
global_step: 5778, epoch: 145, loss: 0.383155
global_step: 5779, epoch: 145, loss: 0.387527
global_step: 5780, epoch: 145, loss: 0.338032
global_step: 5781, epoch: 145, loss: 0.319369
global_step: 5782, epoch: 145, loss: 0.449974
global_step: 5783, epoch: 145, loss: 0.322492
global_step: 5784, epoch: 145, loss: 0.367537
global_step: 5785, epoch: 145, loss: 0.461833
global_step: 5786, epoch: 145, loss: 0.307455
global_step: 5787, epoch: 145, loss: 0.369599
global_step: 5788, epoch: 145, loss: 0.298795
global_step: 5789, epoch: 145, loss: 0.351680
global_step: 5790, epoch: 145, loss: 0.391580
global_step: 5791, epoch: 145, loss: 0.371737
global_step: 5792, epoch: 145, loss: 0.352907
global_step: 5793, epoch: 145, loss: 0.410372
global_step: 5794, epoch: 145, loss: 0.285087
global_step: 5795, epoch: 145, loss: 0.393853
global_step: 5796, epoch: 145, loss: 0.284411
global_step: 5797, epoch: 145, loss: 0.378686
global_step: 5798, epoch: 145, loss: 0.411077
global_step: 5799, epoch: 145, loss: 0.413925
global_step: 5800, epoch: 145, loss: 0.065169
epoch: 145
train	acc: 0.9414	macro: p 0.9436, r 0.8667, f1: 0.8973	micro: p 0.9414, r 0.9414, f1 0.9414	weighted_f1:0.9401
dev	acc: 0.5582	macro: p 0.5577, r 0.3525, f1: 0.3670	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5195
test	acc: 0.5954	macro: p 0.4214, r 0.3409, f1: 0.3512	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5610
global_step: 5801, epoch: 146, loss: 0.335546
global_step: 5802, epoch: 146, loss: 0.333395
global_step: 5803, epoch: 146, loss: 0.294337
global_step: 5804, epoch: 146, loss: 0.390650
global_step: 5805, epoch: 146, loss: 0.388490
global_step: 5806, epoch: 146, loss: 0.323696
global_step: 5807, epoch: 146, loss: 0.330920
global_step: 5808, epoch: 146, loss: 0.378717
global_step: 5809, epoch: 146, loss: 0.365439
global_step: 5810, epoch: 146, loss: 0.329933
global_step: 5811, epoch: 146, loss: 0.397532
global_step: 5812, epoch: 146, loss: 0.321488
global_step: 5813, epoch: 146, loss: 0.353614
global_step: 5814, epoch: 146, loss: 0.319397
global_step: 5815, epoch: 146, loss: 0.287765
global_step: 5816, epoch: 146, loss: 0.361236
global_step: 5817, epoch: 146, loss: 0.361407
global_step: 5818, epoch: 146, loss: 0.305810
global_step: 5819, epoch: 146, loss: 0.328909
global_step: 5820, epoch: 146, loss: 0.383510
global_step: 5821, epoch: 146, loss: 0.369275
global_step: 5822, epoch: 146, loss: 0.296497
global_step: 5823, epoch: 146, loss: 0.357907
global_step: 5824, epoch: 146, loss: 0.354095
global_step: 5825, epoch: 146, loss: 0.423585
global_step: 5826, epoch: 146, loss: 0.329453
global_step: 5827, epoch: 146, loss: 0.412721
global_step: 5828, epoch: 146, loss: 0.343410
global_step: 5829, epoch: 146, loss: 0.335094
global_step: 5830, epoch: 146, loss: 0.461088
global_step: 5831, epoch: 146, loss: 0.302893
global_step: 5832, epoch: 146, loss: 0.452810
global_step: 5833, epoch: 146, loss: 0.304956
global_step: 5834, epoch: 146, loss: 0.323242
global_step: 5835, epoch: 146, loss: 0.287958
global_step: 5836, epoch: 146, loss: 0.289389
global_step: 5837, epoch: 146, loss: 0.427641
global_step: 5838, epoch: 146, loss: 0.363180
global_step: 5839, epoch: 146, loss: 0.343242
global_step: 5840, epoch: 146, loss: 0.302127
epoch: 146
train	acc: 0.9366	macro: p 0.9336, r 0.8417, f1: 0.8716	micro: p 0.9366, r 0.9366, f1 0.9366	weighted_f1:0.9342
dev	acc: 0.5573	macro: p 0.4814, r 0.3556, f1: 0.3726	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5253
test	acc: 0.5908	macro: p 0.3877, r 0.3358, f1: 0.3447	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5599
global_step: 5841, epoch: 147, loss: 0.345772
global_step: 5842, epoch: 147, loss: 0.282541
global_step: 5843, epoch: 147, loss: 0.384833
global_step: 5844, epoch: 147, loss: 0.388580
global_step: 5845, epoch: 147, loss: 0.293648
global_step: 5846, epoch: 147, loss: 0.344079
global_step: 5847, epoch: 147, loss: 0.313854
global_step: 5848, epoch: 147, loss: 0.409884
global_step: 5849, epoch: 147, loss: 0.309844
global_step: 5850, epoch: 147, loss: 0.264628
global_step: 5851, epoch: 147, loss: 0.345471
global_step: 5852, epoch: 147, loss: 0.363888
global_step: 5853, epoch: 147, loss: 0.361504
global_step: 5854, epoch: 147, loss: 0.388355
global_step: 5855, epoch: 147, loss: 0.305050
global_step: 5856, epoch: 147, loss: 0.393763
global_step: 5857, epoch: 147, loss: 0.307108
global_step: 5858, epoch: 147, loss: 0.304968
global_step: 5859, epoch: 147, loss: 0.330953
global_step: 5860, epoch: 147, loss: 0.344189
global_step: 5861, epoch: 147, loss: 0.397577
global_step: 5862, epoch: 147, loss: 0.354530
global_step: 5863, epoch: 147, loss: 0.348554
global_step: 5864, epoch: 147, loss: 0.284696
global_step: 5865, epoch: 147, loss: 0.312872
global_step: 5866, epoch: 147, loss: 0.304688
global_step: 5867, epoch: 147, loss: 0.330694
global_step: 5868, epoch: 147, loss: 0.320743
global_step: 5869, epoch: 147, loss: 0.351210
global_step: 5870, epoch: 147, loss: 0.355717
global_step: 5871, epoch: 147, loss: 0.315258
global_step: 5872, epoch: 147, loss: 0.453796
global_step: 5873, epoch: 147, loss: 0.324592
global_step: 5874, epoch: 147, loss: 0.396490
global_step: 5875, epoch: 147, loss: 0.354168
global_step: 5876, epoch: 147, loss: 0.357111
global_step: 5877, epoch: 147, loss: 0.400062
global_step: 5878, epoch: 147, loss: 0.369390
global_step: 5879, epoch: 147, loss: 0.493827
global_step: 5880, epoch: 147, loss: 0.197959
epoch: 147
train	acc: 0.9442	macro: p 0.9436, r 0.8702, f1: 0.8984	micro: p 0.9442, r 0.9442, f1 0.9442	weighted_f1:0.9429
dev	acc: 0.5482	macro: p 0.4463, r 0.3566, f1: 0.3675	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5168
test	acc: 0.5939	macro: p 0.3950, r 0.3459, f1: 0.3536	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5662
global_step: 5881, epoch: 148, loss: 0.339027
global_step: 5882, epoch: 148, loss: 0.336145
global_step: 5883, epoch: 148, loss: 0.379584
global_step: 5884, epoch: 148, loss: 0.411076
global_step: 5885, epoch: 148, loss: 0.358759
global_step: 5886, epoch: 148, loss: 0.300437
global_step: 5887, epoch: 148, loss: 0.299189
global_step: 5888, epoch: 148, loss: 0.301126
global_step: 5889, epoch: 148, loss: 0.306358
global_step: 5890, epoch: 148, loss: 0.331278
global_step: 5891, epoch: 148, loss: 0.367050
global_step: 5892, epoch: 148, loss: 0.444842
global_step: 5893, epoch: 148, loss: 0.333012
global_step: 5894, epoch: 148, loss: 0.374253
global_step: 5895, epoch: 148, loss: 0.360648
global_step: 5896, epoch: 148, loss: 0.354373
global_step: 5897, epoch: 148, loss: 0.300212
global_step: 5898, epoch: 148, loss: 0.444171
global_step: 5899, epoch: 148, loss: 0.306553
global_step: 5900, epoch: 148, loss: 0.403476
global_step: 5901, epoch: 148, loss: 0.320943
global_step: 5902, epoch: 148, loss: 0.314677
global_step: 5903, epoch: 148, loss: 0.297718
global_step: 5904, epoch: 148, loss: 0.271413
global_step: 5905, epoch: 148, loss: 0.342321
global_step: 5906, epoch: 148, loss: 0.252718
global_step: 5907, epoch: 148, loss: 0.283467
global_step: 5908, epoch: 148, loss: 0.365488
global_step: 5909, epoch: 148, loss: 0.417411
global_step: 5910, epoch: 148, loss: 0.374647
global_step: 5911, epoch: 148, loss: 0.344087
global_step: 5912, epoch: 148, loss: 0.377697
global_step: 5913, epoch: 148, loss: 0.296761
global_step: 5914, epoch: 148, loss: 0.351113
global_step: 5915, epoch: 148, loss: 0.403532
global_step: 5916, epoch: 148, loss: 0.355870
global_step: 5917, epoch: 148, loss: 0.385704
global_step: 5918, epoch: 148, loss: 0.308247
global_step: 5919, epoch: 148, loss: 0.401287
global_step: 5920, epoch: 148, loss: 0.005072
epoch: 148
train	acc: 0.9465	macro: p 0.9433, r 0.8825, f1: 0.9071	micro: p 0.9465, r 0.9465, f1 0.9465	weighted_f1:0.9457
dev	acc: 0.5491	macro: p 0.4352, r 0.3674, f1: 0.3787	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5223
test	acc: 0.5946	macro: p 0.4073, r 0.3600, f1: 0.3694	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5730
global_step: 5921, epoch: 149, loss: 0.316629
global_step: 5922, epoch: 149, loss: 0.312624
global_step: 5923, epoch: 149, loss: 0.337422
global_step: 5924, epoch: 149, loss: 0.336507
global_step: 5925, epoch: 149, loss: 0.355491
global_step: 5926, epoch: 149, loss: 0.383087
global_step: 5927, epoch: 149, loss: 0.326210
global_step: 5928, epoch: 149, loss: 0.330432
global_step: 5929, epoch: 149, loss: 0.359587
global_step: 5930, epoch: 149, loss: 0.324534
global_step: 5931, epoch: 149, loss: 0.401888
global_step: 5932, epoch: 149, loss: 0.356153
global_step: 5933, epoch: 149, loss: 0.319058
global_step: 5934, epoch: 149, loss: 0.295490
global_step: 5935, epoch: 149, loss: 0.383201
global_step: 5936, epoch: 149, loss: 0.339682
global_step: 5937, epoch: 149, loss: 0.383994
global_step: 5938, epoch: 149, loss: 0.339961
global_step: 5939, epoch: 149, loss: 0.395818
global_step: 5940, epoch: 149, loss: 0.348308
global_step: 5941, epoch: 149, loss: 0.326419
global_step: 5942, epoch: 149, loss: 0.394992
global_step: 5943, epoch: 149, loss: 0.327947
global_step: 5944, epoch: 149, loss: 0.307196
global_step: 5945, epoch: 149, loss: 0.430665
global_step: 5946, epoch: 149, loss: 0.396471
global_step: 5947, epoch: 149, loss: 0.272080
global_step: 5948, epoch: 149, loss: 0.324005
global_step: 5949, epoch: 149, loss: 0.282453
global_step: 5950, epoch: 149, loss: 0.300155
global_step: 5951, epoch: 149, loss: 0.336645
global_step: 5952, epoch: 149, loss: 0.338590
global_step: 5953, epoch: 149, loss: 0.351237
global_step: 5954, epoch: 149, loss: 0.380186
global_step: 5955, epoch: 149, loss: 0.410711
global_step: 5956, epoch: 149, loss: 0.303593
global_step: 5957, epoch: 149, loss: 0.398442
global_step: 5958, epoch: 149, loss: 0.291730
global_step: 5959, epoch: 149, loss: 0.312921
global_step: 5960, epoch: 149, loss: 0.683847
epoch: 149
train	acc: 0.9482	macro: p 0.9463, r 0.8905, f1: 0.9142	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9475
dev	acc: 0.5464	macro: p 0.4251, r 0.3627, f1: 0.3705	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5157
test	acc: 0.5916	macro: p 0.3961, r 0.3547, f1: 0.3624	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5667
global_step: 5961, epoch: 150, loss: 0.268753
global_step: 5962, epoch: 150, loss: 0.292419
global_step: 5963, epoch: 150, loss: 0.278902
global_step: 5964, epoch: 150, loss: 0.287953
global_step: 5965, epoch: 150, loss: 0.348641
global_step: 5966, epoch: 150, loss: 0.316874
global_step: 5967, epoch: 150, loss: 0.317715
global_step: 5968, epoch: 150, loss: 0.301881
global_step: 5969, epoch: 150, loss: 0.351901
global_step: 5970, epoch: 150, loss: 0.385952
global_step: 5971, epoch: 150, loss: 0.331817
global_step: 5972, epoch: 150, loss: 0.340206
global_step: 5973, epoch: 150, loss: 0.295777
global_step: 5974, epoch: 150, loss: 0.308126
global_step: 5975, epoch: 150, loss: 0.338413
global_step: 5976, epoch: 150, loss: 0.353605
global_step: 5977, epoch: 150, loss: 0.371134
global_step: 5978, epoch: 150, loss: 0.390461
global_step: 5979, epoch: 150, loss: 0.351010
global_step: 5980, epoch: 150, loss: 0.262135
global_step: 5981, epoch: 150, loss: 0.401627
global_step: 5982, epoch: 150, loss: 0.341906
global_step: 5983, epoch: 150, loss: 0.375961
global_step: 5984, epoch: 150, loss: 0.304100
global_step: 5985, epoch: 150, loss: 0.382444
global_step: 5986, epoch: 150, loss: 0.379842
global_step: 5987, epoch: 150, loss: 0.382255
global_step: 5988, epoch: 150, loss: 0.361590
global_step: 5989, epoch: 150, loss: 0.381420
global_step: 5990, epoch: 150, loss: 0.346386
global_step: 5991, epoch: 150, loss: 0.353334
global_step: 5992, epoch: 150, loss: 0.322874
global_step: 5993, epoch: 150, loss: 0.277085
global_step: 5994, epoch: 150, loss: 0.345092
global_step: 5995, epoch: 150, loss: 0.337794
global_step: 5996, epoch: 150, loss: 0.381113
global_step: 5997, epoch: 150, loss: 0.317861
global_step: 5998, epoch: 150, loss: 0.344361
global_step: 5999, epoch: 150, loss: 0.381195
global_step: 6000, epoch: 150, loss: 0.204494
epoch: 150
train	acc: 0.9430	macro: p 0.9443, r 0.8761, f1: 0.9051	micro: p 0.9430, r 0.9430, f1 0.9430	weighted_f1:0.9420
dev	acc: 0.5618	macro: p 0.4746, r 0.3578, f1: 0.3810	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5271
test	acc: 0.5900	macro: p 0.4010, r 0.3320, f1: 0.3489	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5582
global_step: 6001, epoch: 151, loss: 0.367698
global_step: 6002, epoch: 151, loss: 0.295167
global_step: 6003, epoch: 151, loss: 0.308907
global_step: 6004, epoch: 151, loss: 0.272922
global_step: 6005, epoch: 151, loss: 0.386454
global_step: 6006, epoch: 151, loss: 0.339417
global_step: 6007, epoch: 151, loss: 0.347229
global_step: 6008, epoch: 151, loss: 0.294201
global_step: 6009, epoch: 151, loss: 0.385594
global_step: 6010, epoch: 151, loss: 0.336922
global_step: 6011, epoch: 151, loss: 0.360270
global_step: 6012, epoch: 151, loss: 0.314930
global_step: 6013, epoch: 151, loss: 0.366187
global_step: 6014, epoch: 151, loss: 0.326517
global_step: 6015, epoch: 151, loss: 0.348078
global_step: 6016, epoch: 151, loss: 0.314417
global_step: 6017, epoch: 151, loss: 0.344435
global_step: 6018, epoch: 151, loss: 0.344543
global_step: 6019, epoch: 151, loss: 0.357013
global_step: 6020, epoch: 151, loss: 0.362383
global_step: 6021, epoch: 151, loss: 0.307546
global_step: 6022, epoch: 151, loss: 0.316552
global_step: 6023, epoch: 151, loss: 0.345223
global_step: 6024, epoch: 151, loss: 0.400326
global_step: 6025, epoch: 151, loss: 0.225018
global_step: 6026, epoch: 151, loss: 0.377065
global_step: 6027, epoch: 151, loss: 0.348910
global_step: 6028, epoch: 151, loss: 0.425545
global_step: 6029, epoch: 151, loss: 0.330528
global_step: 6030, epoch: 151, loss: 0.394840
global_step: 6031, epoch: 151, loss: 0.421682
global_step: 6032, epoch: 151, loss: 0.389547
global_step: 6033, epoch: 151, loss: 0.401610
global_step: 6034, epoch: 151, loss: 0.338271
global_step: 6035, epoch: 151, loss: 0.335343
global_step: 6036, epoch: 151, loss: 0.271236
global_step: 6037, epoch: 151, loss: 0.354711
global_step: 6038, epoch: 151, loss: 0.275501
global_step: 6039, epoch: 151, loss: 0.341028
global_step: 6040, epoch: 151, loss: 0.282030
epoch: 151
train	acc: 0.9440	macro: p 0.9522, r 0.8836, f1: 0.9129	micro: p 0.9440, r 0.9440, f1 0.9440	weighted_f1:0.9433
dev	acc: 0.5618	macro: p 0.4419, r 0.3442, f1: 0.3483	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5137
test	acc: 0.5939	macro: p 0.4195, r 0.3358, f1: 0.3471	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5540
global_step: 6041, epoch: 152, loss: 0.476833
global_step: 6042, epoch: 152, loss: 0.351110
global_step: 6043, epoch: 152, loss: 0.353740
global_step: 6044, epoch: 152, loss: 0.414687
global_step: 6045, epoch: 152, loss: 0.322674
global_step: 6046, epoch: 152, loss: 0.312701
global_step: 6047, epoch: 152, loss: 0.281135
global_step: 6048, epoch: 152, loss: 0.349072
global_step: 6049, epoch: 152, loss: 0.325756
global_step: 6050, epoch: 152, loss: 0.318132
global_step: 6051, epoch: 152, loss: 0.356600
global_step: 6052, epoch: 152, loss: 0.286189
global_step: 6053, epoch: 152, loss: 0.366408
global_step: 6054, epoch: 152, loss: 0.355366
global_step: 6055, epoch: 152, loss: 0.297095
global_step: 6056, epoch: 152, loss: 0.360958
global_step: 6057, epoch: 152, loss: 0.331590
global_step: 6058, epoch: 152, loss: 0.371374
global_step: 6059, epoch: 152, loss: 0.320725
global_step: 6060, epoch: 152, loss: 0.371784
global_step: 6061, epoch: 152, loss: 0.332326
global_step: 6062, epoch: 152, loss: 0.348967
global_step: 6063, epoch: 152, loss: 0.277041
global_step: 6064, epoch: 152, loss: 0.340349
global_step: 6065, epoch: 152, loss: 0.279785
global_step: 6066, epoch: 152, loss: 0.290354
global_step: 6067, epoch: 152, loss: 0.226727
global_step: 6068, epoch: 152, loss: 0.294012
global_step: 6069, epoch: 152, loss: 0.241445
global_step: 6070, epoch: 152, loss: 0.299362
global_step: 6071, epoch: 152, loss: 0.433083
global_step: 6072, epoch: 152, loss: 0.292544
global_step: 6073, epoch: 152, loss: 0.291261
global_step: 6074, epoch: 152, loss: 0.307748
global_step: 6075, epoch: 152, loss: 0.322463
global_step: 6076, epoch: 152, loss: 0.359636
global_step: 6077, epoch: 152, loss: 0.290973
global_step: 6078, epoch: 152, loss: 0.388054
global_step: 6079, epoch: 152, loss: 0.364626
global_step: 6080, epoch: 152, loss: 0.349776
epoch: 152
train	acc: 0.9455	macro: p 0.9427, r 0.8779, f1: 0.9037	micro: p 0.9455, r 0.9455, f1 0.9455	weighted_f1:0.9446
dev	acc: 0.5518	macro: p 0.4603, r 0.3613, f1: 0.3788	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5248
test	acc: 0.5954	macro: p 0.3975, r 0.3481, f1: 0.3578	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5719
global_step: 6081, epoch: 153, loss: 0.381184
global_step: 6082, epoch: 153, loss: 0.372649
global_step: 6083, epoch: 153, loss: 0.345324
global_step: 6084, epoch: 153, loss: 0.310258
global_step: 6085, epoch: 153, loss: 0.328105
global_step: 6086, epoch: 153, loss: 0.269203
global_step: 6087, epoch: 153, loss: 0.242777
global_step: 6088, epoch: 153, loss: 0.341551
global_step: 6089, epoch: 153, loss: 0.271848
global_step: 6090, epoch: 153, loss: 0.294340
global_step: 6091, epoch: 153, loss: 0.356464
global_step: 6092, epoch: 153, loss: 0.313767
global_step: 6093, epoch: 153, loss: 0.322264
global_step: 6094, epoch: 153, loss: 0.337427
global_step: 6095, epoch: 153, loss: 0.406698
global_step: 6096, epoch: 153, loss: 0.287732
global_step: 6097, epoch: 153, loss: 0.302111
global_step: 6098, epoch: 153, loss: 0.345103
global_step: 6099, epoch: 153, loss: 0.340801
global_step: 6100, epoch: 153, loss: 0.344423
global_step: 6101, epoch: 153, loss: 0.289695
global_step: 6102, epoch: 153, loss: 0.308674
global_step: 6103, epoch: 153, loss: 0.404984
global_step: 6104, epoch: 153, loss: 0.395697
global_step: 6105, epoch: 153, loss: 0.251215
global_step: 6106, epoch: 153, loss: 0.307292
global_step: 6107, epoch: 153, loss: 0.412449
global_step: 6108, epoch: 153, loss: 0.273466
global_step: 6109, epoch: 153, loss: 0.374055
global_step: 6110, epoch: 153, loss: 0.355090
global_step: 6111, epoch: 153, loss: 0.329251
global_step: 6112, epoch: 153, loss: 0.448816
global_step: 6113, epoch: 153, loss: 0.277436
global_step: 6114, epoch: 153, loss: 0.316829
global_step: 6115, epoch: 153, loss: 0.309657
global_step: 6116, epoch: 153, loss: 0.346933
global_step: 6117, epoch: 153, loss: 0.329892
global_step: 6118, epoch: 153, loss: 0.402623
global_step: 6119, epoch: 153, loss: 0.315885
global_step: 6120, epoch: 153, loss: 0.360070
epoch: 153
train	acc: 0.9494	macro: p 0.9516, r 0.8896, f1: 0.9157	micro: p 0.9494, r 0.9494, f1 0.9494	weighted_f1:0.9487
dev	acc: 0.5609	macro: p 0.4515, r 0.3585, f1: 0.3738	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5251
test	acc: 0.5900	macro: p 0.3972, r 0.3384, f1: 0.3500	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5583
global_step: 6121, epoch: 154, loss: 0.335285
global_step: 6122, epoch: 154, loss: 0.335557
global_step: 6123, epoch: 154, loss: 0.316786
global_step: 6124, epoch: 154, loss: 0.279639
global_step: 6125, epoch: 154, loss: 0.274998
global_step: 6126, epoch: 154, loss: 0.376971
global_step: 6127, epoch: 154, loss: 0.295613
global_step: 6128, epoch: 154, loss: 0.298702
global_step: 6129, epoch: 154, loss: 0.324786
global_step: 6130, epoch: 154, loss: 0.370700
global_step: 6131, epoch: 154, loss: 0.325438
global_step: 6132, epoch: 154, loss: 0.334691
global_step: 6133, epoch: 154, loss: 0.381761
global_step: 6134, epoch: 154, loss: 0.348575
global_step: 6135, epoch: 154, loss: 0.315431
global_step: 6136, epoch: 154, loss: 0.284174
global_step: 6137, epoch: 154, loss: 0.267615
global_step: 6138, epoch: 154, loss: 0.317290
global_step: 6139, epoch: 154, loss: 0.289054
global_step: 6140, epoch: 154, loss: 0.285679
global_step: 6141, epoch: 154, loss: 0.396045
global_step: 6142, epoch: 154, loss: 0.216568
global_step: 6143, epoch: 154, loss: 0.334182
global_step: 6144, epoch: 154, loss: 0.367432
global_step: 6145, epoch: 154, loss: 0.351855
global_step: 6146, epoch: 154, loss: 0.320791
global_step: 6147, epoch: 154, loss: 0.297762
global_step: 6148, epoch: 154, loss: 0.322591
global_step: 6149, epoch: 154, loss: 0.323676
global_step: 6150, epoch: 154, loss: 0.273804
global_step: 6151, epoch: 154, loss: 0.262907
global_step: 6152, epoch: 154, loss: 0.354699
global_step: 6153, epoch: 154, loss: 0.310274
global_step: 6154, epoch: 154, loss: 0.380893
global_step: 6155, epoch: 154, loss: 0.408364
global_step: 6156, epoch: 154, loss: 0.343383
global_step: 6157, epoch: 154, loss: 0.317719
global_step: 6158, epoch: 154, loss: 0.354692
global_step: 6159, epoch: 154, loss: 0.337091
global_step: 6160, epoch: 154, loss: 0.123793
epoch: 154
train	acc: 0.9442	macro: p 0.9423, r 0.8717, f1: 0.8989	micro: p 0.9442, r 0.9442, f1 0.9442	weighted_f1:0.9430
dev	acc: 0.5518	macro: p 0.4716, r 0.3520, f1: 0.3663	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5172
test	acc: 0.5950	macro: p 0.3942, r 0.3388, f1: 0.3468	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5641
global_step: 6161, epoch: 155, loss: 0.324291
global_step: 6162, epoch: 155, loss: 0.366020
global_step: 6163, epoch: 155, loss: 0.353838
global_step: 6164, epoch: 155, loss: 0.258862
global_step: 6165, epoch: 155, loss: 0.321137
global_step: 6166, epoch: 155, loss: 0.397143
global_step: 6167, epoch: 155, loss: 0.268658
global_step: 6168, epoch: 155, loss: 0.320084
global_step: 6169, epoch: 155, loss: 0.327211
global_step: 6170, epoch: 155, loss: 0.376531
global_step: 6171, epoch: 155, loss: 0.275860
global_step: 6172, epoch: 155, loss: 0.289624
global_step: 6173, epoch: 155, loss: 0.312592
global_step: 6174, epoch: 155, loss: 0.379601
global_step: 6175, epoch: 155, loss: 0.309330
global_step: 6176, epoch: 155, loss: 0.331608
global_step: 6177, epoch: 155, loss: 0.304973
global_step: 6178, epoch: 155, loss: 0.261955
global_step: 6179, epoch: 155, loss: 0.367545
global_step: 6180, epoch: 155, loss: 0.365615
global_step: 6181, epoch: 155, loss: 0.359950
global_step: 6182, epoch: 155, loss: 0.321813
global_step: 6183, epoch: 155, loss: 0.303480
global_step: 6184, epoch: 155, loss: 0.347010
global_step: 6185, epoch: 155, loss: 0.322784
global_step: 6186, epoch: 155, loss: 0.328460
global_step: 6187, epoch: 155, loss: 0.346444
global_step: 6188, epoch: 155, loss: 0.311236
global_step: 6189, epoch: 155, loss: 0.303990
global_step: 6190, epoch: 155, loss: 0.324175
global_step: 6191, epoch: 155, loss: 0.281181
global_step: 6192, epoch: 155, loss: 0.328235
global_step: 6193, epoch: 155, loss: 0.349130
global_step: 6194, epoch: 155, loss: 0.317426
global_step: 6195, epoch: 155, loss: 0.257107
global_step: 6196, epoch: 155, loss: 0.254220
global_step: 6197, epoch: 155, loss: 0.316467
global_step: 6198, epoch: 155, loss: 0.426407
global_step: 6199, epoch: 155, loss: 0.390873
global_step: 6200, epoch: 155, loss: 0.019726
epoch: 155
train	acc: 0.9482	macro: p 0.9527, r 0.8909, f1: 0.9174	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9475
dev	acc: 0.5582	macro: p 0.4917, r 0.3542, f1: 0.3683	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5200
test	acc: 0.5900	macro: p 0.4038, r 0.3359, f1: 0.3468	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5553
global_step: 6201, epoch: 156, loss: 0.272813
global_step: 6202, epoch: 156, loss: 0.356527
global_step: 6203, epoch: 156, loss: 0.327377
global_step: 6204, epoch: 156, loss: 0.271529
global_step: 6205, epoch: 156, loss: 0.304356
global_step: 6206, epoch: 156, loss: 0.347615
global_step: 6207, epoch: 156, loss: 0.316849
global_step: 6208, epoch: 156, loss: 0.320892
global_step: 6209, epoch: 156, loss: 0.275150
global_step: 6210, epoch: 156, loss: 0.287444
global_step: 6211, epoch: 156, loss: 0.337953
global_step: 6212, epoch: 156, loss: 0.352559
global_step: 6213, epoch: 156, loss: 0.238443
global_step: 6214, epoch: 156, loss: 0.345010
global_step: 6215, epoch: 156, loss: 0.307679
global_step: 6216, epoch: 156, loss: 0.387482
global_step: 6217, epoch: 156, loss: 0.299516
global_step: 6218, epoch: 156, loss: 0.251808
global_step: 6219, epoch: 156, loss: 0.274367
global_step: 6220, epoch: 156, loss: 0.303709
global_step: 6221, epoch: 156, loss: 0.287800
global_step: 6222, epoch: 156, loss: 0.390347
global_step: 6223, epoch: 156, loss: 0.326803
global_step: 6224, epoch: 156, loss: 0.288332
global_step: 6225, epoch: 156, loss: 0.280471
global_step: 6226, epoch: 156, loss: 0.260174
global_step: 6227, epoch: 156, loss: 0.326295
global_step: 6228, epoch: 156, loss: 0.351879
global_step: 6229, epoch: 156, loss: 0.301885
global_step: 6230, epoch: 156, loss: 0.313355
global_step: 6231, epoch: 156, loss: 0.321089
global_step: 6232, epoch: 156, loss: 0.383709
global_step: 6233, epoch: 156, loss: 0.305048
global_step: 6234, epoch: 156, loss: 0.358685
global_step: 6235, epoch: 156, loss: 0.346451
global_step: 6236, epoch: 156, loss: 0.293255
global_step: 6237, epoch: 156, loss: 0.321221
global_step: 6238, epoch: 156, loss: 0.348304
global_step: 6239, epoch: 156, loss: 0.303443
global_step: 6240, epoch: 156, loss: 0.884095
epoch: 156
train	acc: 0.9514	macro: p 0.9524, r 0.8999, f1: 0.9224	micro: p 0.9514, r 0.9514, f1 0.9514	weighted_f1:0.9510
dev	acc: 0.5482	macro: p 0.4279, r 0.3629, f1: 0.3706	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5210
test	acc: 0.5866	macro: p 0.3772, r 0.3476, f1: 0.3509	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5648
global_step: 6241, epoch: 157, loss: 0.296283
global_step: 6242, epoch: 157, loss: 0.366876
global_step: 6243, epoch: 157, loss: 0.266153
global_step: 6244, epoch: 157, loss: 0.307045
global_step: 6245, epoch: 157, loss: 0.219782
global_step: 6246, epoch: 157, loss: 0.382952
global_step: 6247, epoch: 157, loss: 0.317415
global_step: 6248, epoch: 157, loss: 0.273025
global_step: 6249, epoch: 157, loss: 0.332003
global_step: 6250, epoch: 157, loss: 0.299064
global_step: 6251, epoch: 157, loss: 0.265550
global_step: 6252, epoch: 157, loss: 0.331754
global_step: 6253, epoch: 157, loss: 0.327819
global_step: 6254, epoch: 157, loss: 0.337890
global_step: 6255, epoch: 157, loss: 0.267520
global_step: 6256, epoch: 157, loss: 0.403184
global_step: 6257, epoch: 157, loss: 0.390427
global_step: 6258, epoch: 157, loss: 0.345748
global_step: 6259, epoch: 157, loss: 0.404094
global_step: 6260, epoch: 157, loss: 0.245912
global_step: 6261, epoch: 157, loss: 0.257406
global_step: 6262, epoch: 157, loss: 0.313999
global_step: 6263, epoch: 157, loss: 0.350058
global_step: 6264, epoch: 157, loss: 0.253266
global_step: 6265, epoch: 157, loss: 0.366584
global_step: 6266, epoch: 157, loss: 0.267606
global_step: 6267, epoch: 157, loss: 0.345495
global_step: 6268, epoch: 157, loss: 0.330651
global_step: 6269, epoch: 157, loss: 0.293145
global_step: 6270, epoch: 157, loss: 0.309808
global_step: 6271, epoch: 157, loss: 0.356090
global_step: 6272, epoch: 157, loss: 0.256707
global_step: 6273, epoch: 157, loss: 0.323327
global_step: 6274, epoch: 157, loss: 0.350513
global_step: 6275, epoch: 157, loss: 0.351296
global_step: 6276, epoch: 157, loss: 0.235834
global_step: 6277, epoch: 157, loss: 0.301075
global_step: 6278, epoch: 157, loss: 0.330669
global_step: 6279, epoch: 157, loss: 0.336528
global_step: 6280, epoch: 157, loss: 0.181545
epoch: 157
train	acc: 0.9514	macro: p 0.9492, r 0.9042, f1: 0.9233	micro: p 0.9514, r 0.9514, f1 0.9514	weighted_f1:0.9510
dev	acc: 0.5491	macro: p 0.4271, r 0.3638, f1: 0.3680	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5228
test	acc: 0.5877	macro: p 0.3950, r 0.3622, f1: 0.3700	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5682
global_step: 6281, epoch: 158, loss: 0.326732
global_step: 6282, epoch: 158, loss: 0.320972
global_step: 6283, epoch: 158, loss: 0.358574
global_step: 6284, epoch: 158, loss: 0.411524
global_step: 6285, epoch: 158, loss: 0.307083
global_step: 6286, epoch: 158, loss: 0.351186
global_step: 6287, epoch: 158, loss: 0.366281
global_step: 6288, epoch: 158, loss: 0.284840
global_step: 6289, epoch: 158, loss: 0.345095
global_step: 6290, epoch: 158, loss: 0.308394
global_step: 6291, epoch: 158, loss: 0.352689
global_step: 6292, epoch: 158, loss: 0.329109
global_step: 6293, epoch: 158, loss: 0.358805
global_step: 6294, epoch: 158, loss: 0.276437
global_step: 6295, epoch: 158, loss: 0.239348
global_step: 6296, epoch: 158, loss: 0.291442
global_step: 6297, epoch: 158, loss: 0.292750
global_step: 6298, epoch: 158, loss: 0.292202
global_step: 6299, epoch: 158, loss: 0.304454
global_step: 6300, epoch: 158, loss: 0.318456
global_step: 6301, epoch: 158, loss: 0.327820
global_step: 6302, epoch: 158, loss: 0.361022
global_step: 6303, epoch: 158, loss: 0.322939
global_step: 6304, epoch: 158, loss: 0.312029
global_step: 6305, epoch: 158, loss: 0.314597
global_step: 6306, epoch: 158, loss: 0.332211
global_step: 6307, epoch: 158, loss: 0.376982
global_step: 6308, epoch: 158, loss: 0.262015
global_step: 6309, epoch: 158, loss: 0.392546
global_step: 6310, epoch: 158, loss: 0.282057
global_step: 6311, epoch: 158, loss: 0.288145
global_step: 6312, epoch: 158, loss: 0.403404
global_step: 6313, epoch: 158, loss: 0.335146
global_step: 6314, epoch: 158, loss: 0.342129
global_step: 6315, epoch: 158, loss: 0.316232
global_step: 6316, epoch: 158, loss: 0.376613
global_step: 6317, epoch: 158, loss: 0.318781
global_step: 6318, epoch: 158, loss: 0.244108
global_step: 6319, epoch: 158, loss: 0.328876
global_step: 6320, epoch: 158, loss: 0.013671
epoch: 158
train	acc: 0.9510	macro: p 0.9547, r 0.8986, f1: 0.9227	micro: p 0.9510, r 0.9510, f1 0.9510	weighted_f1:0.9505
dev	acc: 0.5600	macro: p 0.4659, r 0.3594, f1: 0.3695	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5230
test	acc: 0.5989	macro: p 0.4076, r 0.3491, f1: 0.3575	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5660
global_step: 6321, epoch: 159, loss: 0.273260
global_step: 6322, epoch: 159, loss: 0.305956
global_step: 6323, epoch: 159, loss: 0.334220
global_step: 6324, epoch: 159, loss: 0.314182
global_step: 6325, epoch: 159, loss: 0.319530
global_step: 6326, epoch: 159, loss: 0.230151
global_step: 6327, epoch: 159, loss: 0.294320
global_step: 6328, epoch: 159, loss: 0.308492
global_step: 6329, epoch: 159, loss: 0.386566
global_step: 6330, epoch: 159, loss: 0.305823
global_step: 6331, epoch: 159, loss: 0.283026
global_step: 6332, epoch: 159, loss: 0.280356
global_step: 6333, epoch: 159, loss: 0.305966
global_step: 6334, epoch: 159, loss: 0.263215
global_step: 6335, epoch: 159, loss: 0.320545
global_step: 6336, epoch: 159, loss: 0.381614
global_step: 6337, epoch: 159, loss: 0.255836
global_step: 6338, epoch: 159, loss: 0.302431
global_step: 6339, epoch: 159, loss: 0.295450
global_step: 6340, epoch: 159, loss: 0.324656
global_step: 6341, epoch: 159, loss: 0.323195
global_step: 6342, epoch: 159, loss: 0.349784
global_step: 6343, epoch: 159, loss: 0.357199
global_step: 6344, epoch: 159, loss: 0.288443
global_step: 6345, epoch: 159, loss: 0.277334
global_step: 6346, epoch: 159, loss: 0.300026
global_step: 6347, epoch: 159, loss: 0.344360
global_step: 6348, epoch: 159, loss: 0.343587
global_step: 6349, epoch: 159, loss: 0.279133
global_step: 6350, epoch: 159, loss: 0.249544
global_step: 6351, epoch: 159, loss: 0.372767
global_step: 6352, epoch: 159, loss: 0.247875
global_step: 6353, epoch: 159, loss: 0.384788
global_step: 6354, epoch: 159, loss: 0.331581
global_step: 6355, epoch: 159, loss: 0.245332
global_step: 6356, epoch: 159, loss: 0.340225
global_step: 6357, epoch: 159, loss: 0.369298
global_step: 6358, epoch: 159, loss: 0.368142
global_step: 6359, epoch: 159, loss: 0.289676
global_step: 6360, epoch: 159, loss: 0.946239
epoch: 159
train	acc: 0.9548	macro: p 0.9557, r 0.9120, f1: 0.9312	micro: p 0.9548, r 0.9548, f1 0.9548	weighted_f1:0.9544
dev	acc: 0.5428	macro: p 0.4063, r 0.3597, f1: 0.3701	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5155
test	acc: 0.5885	macro: p 0.4035, r 0.3546, f1: 0.3664	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5665
global_step: 6361, epoch: 160, loss: 0.320199
global_step: 6362, epoch: 160, loss: 0.266847
global_step: 6363, epoch: 160, loss: 0.263902
global_step: 6364, epoch: 160, loss: 0.290487
global_step: 6365, epoch: 160, loss: 0.322218
global_step: 6366, epoch: 160, loss: 0.298852
global_step: 6367, epoch: 160, loss: 0.295671
global_step: 6368, epoch: 160, loss: 0.300630
global_step: 6369, epoch: 160, loss: 0.313671
global_step: 6370, epoch: 160, loss: 0.366086
global_step: 6371, epoch: 160, loss: 0.346692
global_step: 6372, epoch: 160, loss: 0.430589
global_step: 6373, epoch: 160, loss: 0.321004
global_step: 6374, epoch: 160, loss: 0.362058
global_step: 6375, epoch: 160, loss: 0.327080
global_step: 6376, epoch: 160, loss: 0.304794
global_step: 6377, epoch: 160, loss: 0.329102
global_step: 6378, epoch: 160, loss: 0.309711
global_step: 6379, epoch: 160, loss: 0.288125
global_step: 6380, epoch: 160, loss: 0.246669
global_step: 6381, epoch: 160, loss: 0.310952
global_step: 6382, epoch: 160, loss: 0.249425
global_step: 6383, epoch: 160, loss: 0.275045
global_step: 6384, epoch: 160, loss: 0.257619
global_step: 6385, epoch: 160, loss: 0.273778
global_step: 6386, epoch: 160, loss: 0.265871
global_step: 6387, epoch: 160, loss: 0.276966
global_step: 6388, epoch: 160, loss: 0.338737
global_step: 6389, epoch: 160, loss: 0.345843
global_step: 6390, epoch: 160, loss: 0.273151
global_step: 6391, epoch: 160, loss: 0.294485
global_step: 6392, epoch: 160, loss: 0.281276
global_step: 6393, epoch: 160, loss: 0.292663
global_step: 6394, epoch: 160, loss: 0.317128
global_step: 6395, epoch: 160, loss: 0.328491
global_step: 6396, epoch: 160, loss: 0.299968
global_step: 6397, epoch: 160, loss: 0.341454
global_step: 6398, epoch: 160, loss: 0.367997
global_step: 6399, epoch: 160, loss: 0.362093
global_step: 6400, epoch: 160, loss: 0.070468
epoch: 160
train	acc: 0.9527	macro: p 0.9552, r 0.9060, f1: 0.9273	micro: p 0.9527, r 0.9527, f1 0.9527	weighted_f1:0.9523
dev	acc: 0.5437	macro: p 0.4129, r 0.3530, f1: 0.3579	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5128
test	acc: 0.5874	macro: p 0.4007, r 0.3485, f1: 0.3584	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5626
global_step: 6401, epoch: 161, loss: 0.303051
global_step: 6402, epoch: 161, loss: 0.319944
global_step: 6403, epoch: 161, loss: 0.278533
global_step: 6404, epoch: 161, loss: 0.283614
global_step: 6405, epoch: 161, loss: 0.329145
global_step: 6406, epoch: 161, loss: 0.256014
global_step: 6407, epoch: 161, loss: 0.303456
global_step: 6408, epoch: 161, loss: 0.287750
global_step: 6409, epoch: 161, loss: 0.299634
global_step: 6410, epoch: 161, loss: 0.322855
global_step: 6411, epoch: 161, loss: 0.254846
global_step: 6412, epoch: 161, loss: 0.315538
global_step: 6413, epoch: 161, loss: 0.307615
global_step: 6414, epoch: 161, loss: 0.379977
global_step: 6415, epoch: 161, loss: 0.298493
global_step: 6416, epoch: 161, loss: 0.311272
global_step: 6417, epoch: 161, loss: 0.285712
global_step: 6418, epoch: 161, loss: 0.337701
global_step: 6419, epoch: 161, loss: 0.345360
global_step: 6420, epoch: 161, loss: 0.340783
global_step: 6421, epoch: 161, loss: 0.295599
global_step: 6422, epoch: 161, loss: 0.270576
global_step: 6423, epoch: 161, loss: 0.376741
global_step: 6424, epoch: 161, loss: 0.351273
global_step: 6425, epoch: 161, loss: 0.375795
global_step: 6426, epoch: 161, loss: 0.341078
global_step: 6427, epoch: 161, loss: 0.259287
global_step: 6428, epoch: 161, loss: 0.287025
global_step: 6429, epoch: 161, loss: 0.330896
global_step: 6430, epoch: 161, loss: 0.311124
global_step: 6431, epoch: 161, loss: 0.306778
global_step: 6432, epoch: 161, loss: 0.328289
global_step: 6433, epoch: 161, loss: 0.261158
global_step: 6434, epoch: 161, loss: 0.266633
global_step: 6435, epoch: 161, loss: 0.274205
global_step: 6436, epoch: 161, loss: 0.312892
global_step: 6437, epoch: 161, loss: 0.344056
global_step: 6438, epoch: 161, loss: 0.282734
global_step: 6439, epoch: 161, loss: 0.221042
global_step: 6440, epoch: 161, loss: 0.011892
epoch: 161
train	acc: 0.9509	macro: p 0.9592, r 0.8996, f1: 0.9261	micro: p 0.9509, r 0.9509, f1 0.9509	weighted_f1:0.9504
dev	acc: 0.5618	macro: p 0.4597, r 0.3382, f1: 0.3508	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5169
test	acc: 0.5977	macro: p 0.4139, r 0.3312, f1: 0.3448	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5581
global_step: 6441, epoch: 162, loss: 0.316104
global_step: 6442, epoch: 162, loss: 0.414025
global_step: 6443, epoch: 162, loss: 0.259221
global_step: 6444, epoch: 162, loss: 0.290577
global_step: 6445, epoch: 162, loss: 0.293293
global_step: 6446, epoch: 162, loss: 0.260148
global_step: 6447, epoch: 162, loss: 0.297606
global_step: 6448, epoch: 162, loss: 0.346442
global_step: 6449, epoch: 162, loss: 0.290556
global_step: 6450, epoch: 162, loss: 0.315950
global_step: 6451, epoch: 162, loss: 0.289942
global_step: 6452, epoch: 162, loss: 0.377673
global_step: 6453, epoch: 162, loss: 0.314745
global_step: 6454, epoch: 162, loss: 0.297028
global_step: 6455, epoch: 162, loss: 0.338812
global_step: 6456, epoch: 162, loss: 0.354503
global_step: 6457, epoch: 162, loss: 0.304583
global_step: 6458, epoch: 162, loss: 0.264187
global_step: 6459, epoch: 162, loss: 0.408456
global_step: 6460, epoch: 162, loss: 0.240742
global_step: 6461, epoch: 162, loss: 0.284688
global_step: 6462, epoch: 162, loss: 0.337436
global_step: 6463, epoch: 162, loss: 0.300332
global_step: 6464, epoch: 162, loss: 0.293937
global_step: 6465, epoch: 162, loss: 0.260886
global_step: 6466, epoch: 162, loss: 0.248728
global_step: 6467, epoch: 162, loss: 0.333871
global_step: 6468, epoch: 162, loss: 0.247828
global_step: 6469, epoch: 162, loss: 0.262952
global_step: 6470, epoch: 162, loss: 0.289759
global_step: 6471, epoch: 162, loss: 0.326369
global_step: 6472, epoch: 162, loss: 0.296175
global_step: 6473, epoch: 162, loss: 0.406708
global_step: 6474, epoch: 162, loss: 0.302177
global_step: 6475, epoch: 162, loss: 0.328158
global_step: 6476, epoch: 162, loss: 0.282148
global_step: 6477, epoch: 162, loss: 0.303633
global_step: 6478, epoch: 162, loss: 0.313968
global_step: 6479, epoch: 162, loss: 0.313620
global_step: 6480, epoch: 162, loss: 0.180690
epoch: 162
train	acc: 0.9524	macro: p 0.9542, r 0.9030, f1: 0.9254	micro: p 0.9524, r 0.9524, f1 0.9524	weighted_f1:0.9519
dev	acc: 0.5555	macro: p 0.4354, r 0.3667, f1: 0.3789	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5230
test	acc: 0.5893	macro: p 0.4049, r 0.3410, f1: 0.3542	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5587
global_step: 6481, epoch: 163, loss: 0.254650
global_step: 6482, epoch: 163, loss: 0.292017
global_step: 6483, epoch: 163, loss: 0.330383
global_step: 6484, epoch: 163, loss: 0.336930
global_step: 6485, epoch: 163, loss: 0.283357
global_step: 6486, epoch: 163, loss: 0.291194
global_step: 6487, epoch: 163, loss: 0.319527
global_step: 6488, epoch: 163, loss: 0.280870
global_step: 6489, epoch: 163, loss: 0.261030
global_step: 6490, epoch: 163, loss: 0.223894
global_step: 6491, epoch: 163, loss: 0.253720
global_step: 6492, epoch: 163, loss: 0.309596
global_step: 6493, epoch: 163, loss: 0.336960
global_step: 6494, epoch: 163, loss: 0.306754
global_step: 6495, epoch: 163, loss: 0.273258
global_step: 6496, epoch: 163, loss: 0.226205
global_step: 6497, epoch: 163, loss: 0.286583
global_step: 6498, epoch: 163, loss: 0.291833
global_step: 6499, epoch: 163, loss: 0.250781
global_step: 6500, epoch: 163, loss: 0.295073
global_step: 6501, epoch: 163, loss: 0.336111
global_step: 6502, epoch: 163, loss: 0.336750
global_step: 6503, epoch: 163, loss: 0.310611
global_step: 6504, epoch: 163, loss: 0.312447
global_step: 6505, epoch: 163, loss: 0.354926
global_step: 6506, epoch: 163, loss: 0.363794
global_step: 6507, epoch: 163, loss: 0.374808
global_step: 6508, epoch: 163, loss: 0.300986
global_step: 6509, epoch: 163, loss: 0.350683
global_step: 6510, epoch: 163, loss: 0.327544
global_step: 6511, epoch: 163, loss: 0.299001
global_step: 6512, epoch: 163, loss: 0.274699
global_step: 6513, epoch: 163, loss: 0.294904
global_step: 6514, epoch: 163, loss: 0.312647
global_step: 6515, epoch: 163, loss: 0.275540
global_step: 6516, epoch: 163, loss: 0.398413
global_step: 6517, epoch: 163, loss: 0.312289
global_step: 6518, epoch: 163, loss: 0.371994
global_step: 6519, epoch: 163, loss: 0.270874
global_step: 6520, epoch: 163, loss: 0.462232
epoch: 163
train	acc: 0.9554	macro: p 0.9590, r 0.9150, f1: 0.9349	micro: p 0.9554, r 0.9554, f1 0.9554	weighted_f1:0.9550
dev	acc: 0.5627	macro: p 0.4315, r 0.3636, f1: 0.3778	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5301
test	acc: 0.5966	macro: p 0.3957, r 0.3423, f1: 0.3546	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5651
global_step: 6521, epoch: 164, loss: 0.325775
global_step: 6522, epoch: 164, loss: 0.338221
global_step: 6523, epoch: 164, loss: 0.309292
global_step: 6524, epoch: 164, loss: 0.314813
global_step: 6525, epoch: 164, loss: 0.370975
global_step: 6526, epoch: 164, loss: 0.272336
global_step: 6527, epoch: 164, loss: 0.258677
global_step: 6528, epoch: 164, loss: 0.307066
global_step: 6529, epoch: 164, loss: 0.311222
global_step: 6530, epoch: 164, loss: 0.336467
global_step: 6531, epoch: 164, loss: 0.279694
global_step: 6532, epoch: 164, loss: 0.276665
global_step: 6533, epoch: 164, loss: 0.282805
global_step: 6534, epoch: 164, loss: 0.276135
global_step: 6535, epoch: 164, loss: 0.320967
global_step: 6536, epoch: 164, loss: 0.222819
global_step: 6537, epoch: 164, loss: 0.256934
global_step: 6538, epoch: 164, loss: 0.287005
global_step: 6539, epoch: 164, loss: 0.331722
global_step: 6540, epoch: 164, loss: 0.337051
global_step: 6541, epoch: 164, loss: 0.296562
global_step: 6542, epoch: 164, loss: 0.283597
global_step: 6543, epoch: 164, loss: 0.287122
global_step: 6544, epoch: 164, loss: 0.387902
global_step: 6545, epoch: 164, loss: 0.245744
global_step: 6546, epoch: 164, loss: 0.260579
global_step: 6547, epoch: 164, loss: 0.307283
global_step: 6548, epoch: 164, loss: 0.283104
global_step: 6549, epoch: 164, loss: 0.269895
global_step: 6550, epoch: 164, loss: 0.326084
global_step: 6551, epoch: 164, loss: 0.334090
global_step: 6552, epoch: 164, loss: 0.304441
global_step: 6553, epoch: 164, loss: 0.303782
global_step: 6554, epoch: 164, loss: 0.193485
global_step: 6555, epoch: 164, loss: 0.304173
global_step: 6556, epoch: 164, loss: 0.347292
global_step: 6557, epoch: 164, loss: 0.369068
global_step: 6558, epoch: 164, loss: 0.338053
global_step: 6559, epoch: 164, loss: 0.291363
global_step: 6560, epoch: 164, loss: 0.762488
epoch: 164
train	acc: 0.9540	macro: p 0.9564, r 0.9094, f1: 0.9301	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9536
dev	acc: 0.5546	macro: p 0.4482, r 0.3585, f1: 0.3693	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5178
test	acc: 0.5866	macro: p 0.3950, r 0.3409, f1: 0.3538	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5563
global_step: 6561, epoch: 165, loss: 0.215586
global_step: 6562, epoch: 165, loss: 0.277702
global_step: 6563, epoch: 165, loss: 0.328153
global_step: 6564, epoch: 165, loss: 0.333340
global_step: 6565, epoch: 165, loss: 0.341212
global_step: 6566, epoch: 165, loss: 0.340921
global_step: 6567, epoch: 165, loss: 0.318291
global_step: 6568, epoch: 165, loss: 0.313017
global_step: 6569, epoch: 165, loss: 0.275629
global_step: 6570, epoch: 165, loss: 0.260026
global_step: 6571, epoch: 165, loss: 0.339024
global_step: 6572, epoch: 165, loss: 0.262958
global_step: 6573, epoch: 165, loss: 0.231874
global_step: 6574, epoch: 165, loss: 0.322278
global_step: 6575, epoch: 165, loss: 0.218470
global_step: 6576, epoch: 165, loss: 0.361201
global_step: 6577, epoch: 165, loss: 0.309513
global_step: 6578, epoch: 165, loss: 0.251107
global_step: 6579, epoch: 165, loss: 0.290950
global_step: 6580, epoch: 165, loss: 0.361348
global_step: 6581, epoch: 165, loss: 0.295493
global_step: 6582, epoch: 165, loss: 0.292405
global_step: 6583, epoch: 165, loss: 0.288533
global_step: 6584, epoch: 165, loss: 0.324791
global_step: 6585, epoch: 165, loss: 0.250527
global_step: 6586, epoch: 165, loss: 0.280062
global_step: 6587, epoch: 165, loss: 0.272126
global_step: 6588, epoch: 165, loss: 0.389144
global_step: 6589, epoch: 165, loss: 0.223875
global_step: 6590, epoch: 165, loss: 0.249020
global_step: 6591, epoch: 165, loss: 0.267405
global_step: 6592, epoch: 165, loss: 0.389525
global_step: 6593, epoch: 165, loss: 0.251822
global_step: 6594, epoch: 165, loss: 0.324967
global_step: 6595, epoch: 165, loss: 0.313018
global_step: 6596, epoch: 165, loss: 0.269044
global_step: 6597, epoch: 165, loss: 0.330084
global_step: 6598, epoch: 165, loss: 0.305597
global_step: 6599, epoch: 165, loss: 0.262818
global_step: 6600, epoch: 165, loss: 0.373568
epoch: 165
train	acc: 0.9535	macro: p 0.9568, r 0.9088, f1: 0.9298	micro: p 0.9535, r 0.9535, f1 0.9535	weighted_f1:0.9531
dev	acc: 0.5491	macro: p 0.4269, r 0.3510, f1: 0.3590	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5131
test	acc: 0.5877	macro: p 0.4009, r 0.3427, f1: 0.3529	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5584
global_step: 6601, epoch: 166, loss: 0.317117
global_step: 6602, epoch: 166, loss: 0.290201
global_step: 6603, epoch: 166, loss: 0.313764
global_step: 6604, epoch: 166, loss: 0.327141
global_step: 6605, epoch: 166, loss: 0.257093
global_step: 6606, epoch: 166, loss: 0.288429
global_step: 6607, epoch: 166, loss: 0.255169
global_step: 6608, epoch: 166, loss: 0.320915
global_step: 6609, epoch: 166, loss: 0.244139
global_step: 6610, epoch: 166, loss: 0.334689
global_step: 6611, epoch: 166, loss: 0.259903
global_step: 6612, epoch: 166, loss: 0.338101
global_step: 6613, epoch: 166, loss: 0.340824
global_step: 6614, epoch: 166, loss: 0.286765
global_step: 6615, epoch: 166, loss: 0.311219
global_step: 6616, epoch: 166, loss: 0.237533
global_step: 6617, epoch: 166, loss: 0.331362
global_step: 6618, epoch: 166, loss: 0.296753
global_step: 6619, epoch: 166, loss: 0.309577
global_step: 6620, epoch: 166, loss: 0.361687
global_step: 6621, epoch: 166, loss: 0.258567
global_step: 6622, epoch: 166, loss: 0.328140
global_step: 6623, epoch: 166, loss: 0.378117
global_step: 6624, epoch: 166, loss: 0.324069
global_step: 6625, epoch: 166, loss: 0.227352
global_step: 6626, epoch: 166, loss: 0.239583
global_step: 6627, epoch: 166, loss: 0.310304
global_step: 6628, epoch: 166, loss: 0.287303
global_step: 6629, epoch: 166, loss: 0.286908
global_step: 6630, epoch: 166, loss: 0.330954
global_step: 6631, epoch: 166, loss: 0.306313
global_step: 6632, epoch: 166, loss: 0.222963
global_step: 6633, epoch: 166, loss: 0.350547
global_step: 6634, epoch: 166, loss: 0.232680
global_step: 6635, epoch: 166, loss: 0.416383
global_step: 6636, epoch: 166, loss: 0.304648
global_step: 6637, epoch: 166, loss: 0.294321
global_step: 6638, epoch: 166, loss: 0.275285
global_step: 6639, epoch: 166, loss: 0.291188
global_step: 6640, epoch: 166, loss: 0.090117
epoch: 166
train	acc: 0.9559	macro: p 0.9571, r 0.9118, f1: 0.9317	micro: p 0.9559, r 0.9559, f1 0.9559	weighted_f1:0.9555
dev	acc: 0.5446	macro: p 0.4424, r 0.3530, f1: 0.3639	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5128
test	acc: 0.5885	macro: p 0.4065, r 0.3429, f1: 0.3530	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5600
global_step: 6641, epoch: 167, loss: 0.427003
global_step: 6642, epoch: 167, loss: 0.316507
global_step: 6643, epoch: 167, loss: 0.242897
global_step: 6644, epoch: 167, loss: 0.371362
global_step: 6645, epoch: 167, loss: 0.304707
global_step: 6646, epoch: 167, loss: 0.254868
global_step: 6647, epoch: 167, loss: 0.327508
global_step: 6648, epoch: 167, loss: 0.252184
global_step: 6649, epoch: 167, loss: 0.340211
global_step: 6650, epoch: 167, loss: 0.350276
global_step: 6651, epoch: 167, loss: 0.214075
global_step: 6652, epoch: 167, loss: 0.278934
global_step: 6653, epoch: 167, loss: 0.263519
global_step: 6654, epoch: 167, loss: 0.269323
global_step: 6655, epoch: 167, loss: 0.263343
global_step: 6656, epoch: 167, loss: 0.322656
global_step: 6657, epoch: 167, loss: 0.200419
global_step: 6658, epoch: 167, loss: 0.248151
global_step: 6659, epoch: 167, loss: 0.301243
global_step: 6660, epoch: 167, loss: 0.321575
global_step: 6661, epoch: 167, loss: 0.238925
global_step: 6662, epoch: 167, loss: 0.260221
global_step: 6663, epoch: 167, loss: 0.266158
global_step: 6664, epoch: 167, loss: 0.291858
global_step: 6665, epoch: 167, loss: 0.241871
global_step: 6666, epoch: 167, loss: 0.335302
global_step: 6667, epoch: 167, loss: 0.254484
global_step: 6668, epoch: 167, loss: 0.346551
global_step: 6669, epoch: 167, loss: 0.322773
global_step: 6670, epoch: 167, loss: 0.358592
global_step: 6671, epoch: 167, loss: 0.375220
global_step: 6672, epoch: 167, loss: 0.322133
global_step: 6673, epoch: 167, loss: 0.282294
global_step: 6674, epoch: 167, loss: 0.293100
global_step: 6675, epoch: 167, loss: 0.278172
global_step: 6676, epoch: 167, loss: 0.291700
global_step: 6677, epoch: 167, loss: 0.309355
global_step: 6678, epoch: 167, loss: 0.311796
global_step: 6679, epoch: 167, loss: 0.212156
global_step: 6680, epoch: 167, loss: 0.218623
epoch: 167
train	acc: 0.9531	macro: p 0.9574, r 0.9020, f1: 0.9265	micro: p 0.9531, r 0.9531, f1 0.9531	weighted_f1:0.9526
dev	acc: 0.5573	macro: p 0.4573, r 0.3406, f1: 0.3571	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5184
test	acc: 0.5939	macro: p 0.4115, r 0.3355, f1: 0.3519	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5603
global_step: 6681, epoch: 168, loss: 0.286069
global_step: 6682, epoch: 168, loss: 0.309439
global_step: 6683, epoch: 168, loss: 0.313242
global_step: 6684, epoch: 168, loss: 0.224884
global_step: 6685, epoch: 168, loss: 0.316843
global_step: 6686, epoch: 168, loss: 0.300074
global_step: 6687, epoch: 168, loss: 0.289381
global_step: 6688, epoch: 168, loss: 0.292396
global_step: 6689, epoch: 168, loss: 0.274930
global_step: 6690, epoch: 168, loss: 0.301482
global_step: 6691, epoch: 168, loss: 0.329307
global_step: 6692, epoch: 168, loss: 0.286190
global_step: 6693, epoch: 168, loss: 0.247790
global_step: 6694, epoch: 168, loss: 0.274379
global_step: 6695, epoch: 168, loss: 0.331872
global_step: 6696, epoch: 168, loss: 0.269919
global_step: 6697, epoch: 168, loss: 0.269532
global_step: 6698, epoch: 168, loss: 0.354732
global_step: 6699, epoch: 168, loss: 0.293370
global_step: 6700, epoch: 168, loss: 0.335342
global_step: 6701, epoch: 168, loss: 0.296674
global_step: 6702, epoch: 168, loss: 0.293144
global_step: 6703, epoch: 168, loss: 0.263500
global_step: 6704, epoch: 168, loss: 0.271492
global_step: 6705, epoch: 168, loss: 0.321582
global_step: 6706, epoch: 168, loss: 0.248223
global_step: 6707, epoch: 168, loss: 0.311978
global_step: 6708, epoch: 168, loss: 0.301677
global_step: 6709, epoch: 168, loss: 0.277676
global_step: 6710, epoch: 168, loss: 0.283419
global_step: 6711, epoch: 168, loss: 0.339130
global_step: 6712, epoch: 168, loss: 0.308842
global_step: 6713, epoch: 168, loss: 0.271842
global_step: 6714, epoch: 168, loss: 0.247700
global_step: 6715, epoch: 168, loss: 0.323599
global_step: 6716, epoch: 168, loss: 0.356082
global_step: 6717, epoch: 168, loss: 0.298240
global_step: 6718, epoch: 168, loss: 0.255226
global_step: 6719, epoch: 168, loss: 0.307716
global_step: 6720, epoch: 168, loss: 0.315869
epoch: 168
train	acc: 0.9526	macro: p 0.9598, r 0.9140, f1: 0.9351	micro: p 0.9526, r 0.9526, f1 0.9526	weighted_f1:0.9523
dev	acc: 0.5636	macro: p 0.4423, r 0.3440, f1: 0.3594	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5234
test	acc: 0.5966	macro: p 0.4076, r 0.3357, f1: 0.3517	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5587
global_step: 6721, epoch: 169, loss: 0.319802
global_step: 6722, epoch: 169, loss: 0.282351
global_step: 6723, epoch: 169, loss: 0.279758
global_step: 6724, epoch: 169, loss: 0.265069
global_step: 6725, epoch: 169, loss: 0.254633
global_step: 6726, epoch: 169, loss: 0.248117
global_step: 6727, epoch: 169, loss: 0.213766
global_step: 6728, epoch: 169, loss: 0.288460
global_step: 6729, epoch: 169, loss: 0.277966
global_step: 6730, epoch: 169, loss: 0.299210
global_step: 6731, epoch: 169, loss: 0.406710
global_step: 6732, epoch: 169, loss: 0.323100
global_step: 6733, epoch: 169, loss: 0.291205
global_step: 6734, epoch: 169, loss: 0.233364
global_step: 6735, epoch: 169, loss: 0.258433
global_step: 6736, epoch: 169, loss: 0.269393
global_step: 6737, epoch: 169, loss: 0.294693
global_step: 6738, epoch: 169, loss: 0.221112
global_step: 6739, epoch: 169, loss: 0.279817
global_step: 6740, epoch: 169, loss: 0.282829
global_step: 6741, epoch: 169, loss: 0.286031
global_step: 6742, epoch: 169, loss: 0.257049
global_step: 6743, epoch: 169, loss: 0.370256
global_step: 6744, epoch: 169, loss: 0.281354
global_step: 6745, epoch: 169, loss: 0.337588
global_step: 6746, epoch: 169, loss: 0.337815
global_step: 6747, epoch: 169, loss: 0.373759
global_step: 6748, epoch: 169, loss: 0.293052
global_step: 6749, epoch: 169, loss: 0.258715
global_step: 6750, epoch: 169, loss: 0.229355
global_step: 6751, epoch: 169, loss: 0.355275
global_step: 6752, epoch: 169, loss: 0.192622
global_step: 6753, epoch: 169, loss: 0.241249
global_step: 6754, epoch: 169, loss: 0.293480
global_step: 6755, epoch: 169, loss: 0.242899
global_step: 6756, epoch: 169, loss: 0.304053
global_step: 6757, epoch: 169, loss: 0.278222
global_step: 6758, epoch: 169, loss: 0.263120
global_step: 6759, epoch: 169, loss: 0.349420
global_step: 6760, epoch: 169, loss: 0.115828
epoch: 169
train	acc: 0.9571	macro: p 0.9570, r 0.9205, f1: 0.9370	micro: p 0.9571, r 0.9571, f1 0.9571	weighted_f1:0.9568
dev	acc: 0.5555	macro: p 0.4170, r 0.3602, f1: 0.3722	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5248
test	acc: 0.5912	macro: p 0.3924, r 0.3514, f1: 0.3626	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5657
global_step: 6761, epoch: 170, loss: 0.290390
global_step: 6762, epoch: 170, loss: 0.243843
global_step: 6763, epoch: 170, loss: 0.294986
global_step: 6764, epoch: 170, loss: 0.331908
global_step: 6765, epoch: 170, loss: 0.319604
global_step: 6766, epoch: 170, loss: 0.260679
global_step: 6767, epoch: 170, loss: 0.290020
global_step: 6768, epoch: 170, loss: 0.305365
global_step: 6769, epoch: 170, loss: 0.336538
global_step: 6770, epoch: 170, loss: 0.274080
global_step: 6771, epoch: 170, loss: 0.226263
global_step: 6772, epoch: 170, loss: 0.292453
global_step: 6773, epoch: 170, loss: 0.229646
global_step: 6774, epoch: 170, loss: 0.259424
global_step: 6775, epoch: 170, loss: 0.273646
global_step: 6776, epoch: 170, loss: 0.346878
global_step: 6777, epoch: 170, loss: 0.277665
global_step: 6778, epoch: 170, loss: 0.236056
global_step: 6779, epoch: 170, loss: 0.316650
global_step: 6780, epoch: 170, loss: 0.279150
global_step: 6781, epoch: 170, loss: 0.254449
global_step: 6782, epoch: 170, loss: 0.274264
global_step: 6783, epoch: 170, loss: 0.316783
global_step: 6784, epoch: 170, loss: 0.362534
global_step: 6785, epoch: 170, loss: 0.314332
global_step: 6786, epoch: 170, loss: 0.224489
global_step: 6787, epoch: 170, loss: 0.258703
global_step: 6788, epoch: 170, loss: 0.238684
global_step: 6789, epoch: 170, loss: 0.284153
global_step: 6790, epoch: 170, loss: 0.287805
global_step: 6791, epoch: 170, loss: 0.369575
global_step: 6792, epoch: 170, loss: 0.370024
global_step: 6793, epoch: 170, loss: 0.345824
global_step: 6794, epoch: 170, loss: 0.358261
global_step: 6795, epoch: 170, loss: 0.238580
global_step: 6796, epoch: 170, loss: 0.283831
global_step: 6797, epoch: 170, loss: 0.337223
global_step: 6798, epoch: 170, loss: 0.267745
global_step: 6799, epoch: 170, loss: 0.281088
global_step: 6800, epoch: 170, loss: 0.903090
epoch: 170
train	acc: 0.9577	macro: p 0.9575, r 0.9224, f1: 0.9385	micro: p 0.9577, r 0.9577, f1 0.9577	weighted_f1:0.9575
dev	acc: 0.5464	macro: p 0.4128, r 0.3571, f1: 0.3673	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5190
test	acc: 0.5851	macro: p 0.3882, r 0.3461, f1: 0.3560	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5636
global_step: 6801, epoch: 171, loss: 0.268257
global_step: 6802, epoch: 171, loss: 0.250369
global_step: 6803, epoch: 171, loss: 0.304535
global_step: 6804, epoch: 171, loss: 0.379283
global_step: 6805, epoch: 171, loss: 0.279253
global_step: 6806, epoch: 171, loss: 0.325847
global_step: 6807, epoch: 171, loss: 0.263171
global_step: 6808, epoch: 171, loss: 0.273802
global_step: 6809, epoch: 171, loss: 0.300676
global_step: 6810, epoch: 171, loss: 0.296281
global_step: 6811, epoch: 171, loss: 0.225133
global_step: 6812, epoch: 171, loss: 0.281614
global_step: 6813, epoch: 171, loss: 0.364390
global_step: 6814, epoch: 171, loss: 0.292612
global_step: 6815, epoch: 171, loss: 0.281973
global_step: 6816, epoch: 171, loss: 0.248958
global_step: 6817, epoch: 171, loss: 0.279098
global_step: 6818, epoch: 171, loss: 0.271745
global_step: 6819, epoch: 171, loss: 0.349620
global_step: 6820, epoch: 171, loss: 0.292055
global_step: 6821, epoch: 171, loss: 0.238202
global_step: 6822, epoch: 171, loss: 0.250041
global_step: 6823, epoch: 171, loss: 0.284377
global_step: 6824, epoch: 171, loss: 0.290374
global_step: 6825, epoch: 171, loss: 0.297129
global_step: 6826, epoch: 171, loss: 0.259282
global_step: 6827, epoch: 171, loss: 0.265559
global_step: 6828, epoch: 171, loss: 0.276014
global_step: 6829, epoch: 171, loss: 0.399042
global_step: 6830, epoch: 171, loss: 0.227559
global_step: 6831, epoch: 171, loss: 0.266332
global_step: 6832, epoch: 171, loss: 0.314839
global_step: 6833, epoch: 171, loss: 0.333945
global_step: 6834, epoch: 171, loss: 0.256787
global_step: 6835, epoch: 171, loss: 0.267004
global_step: 6836, epoch: 171, loss: 0.317817
global_step: 6837, epoch: 171, loss: 0.324772
global_step: 6838, epoch: 171, loss: 0.277400
global_step: 6839, epoch: 171, loss: 0.295875
global_step: 6840, epoch: 171, loss: 0.017653
epoch: 171
train	acc: 0.9580	macro: p 0.9613, r 0.9203, f1: 0.9388	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9577
dev	acc: 0.5455	macro: p 0.4170, r 0.3530, f1: 0.3613	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5140
test	acc: 0.5885	macro: p 0.3811, r 0.3418, f1: 0.3484	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5618
global_step: 6841, epoch: 172, loss: 0.258701
global_step: 6842, epoch: 172, loss: 0.326808
global_step: 6843, epoch: 172, loss: 0.289324
global_step: 6844, epoch: 172, loss: 0.274805
global_step: 6845, epoch: 172, loss: 0.253065
global_step: 6846, epoch: 172, loss: 0.316577
global_step: 6847, epoch: 172, loss: 0.243519
global_step: 6848, epoch: 172, loss: 0.304456
global_step: 6849, epoch: 172, loss: 0.310219
global_step: 6850, epoch: 172, loss: 0.268466
global_step: 6851, epoch: 172, loss: 0.248759
global_step: 6852, epoch: 172, loss: 0.250797
global_step: 6853, epoch: 172, loss: 0.245548
global_step: 6854, epoch: 172, loss: 0.286668
global_step: 6855, epoch: 172, loss: 0.349200
global_step: 6856, epoch: 172, loss: 0.293050
global_step: 6857, epoch: 172, loss: 0.337134
global_step: 6858, epoch: 172, loss: 0.323245
global_step: 6859, epoch: 172, loss: 0.252614
global_step: 6860, epoch: 172, loss: 0.280757
global_step: 6861, epoch: 172, loss: 0.253301
global_step: 6862, epoch: 172, loss: 0.296583
global_step: 6863, epoch: 172, loss: 0.214343
global_step: 6864, epoch: 172, loss: 0.307668
global_step: 6865, epoch: 172, loss: 0.291903
global_step: 6866, epoch: 172, loss: 0.298402
global_step: 6867, epoch: 172, loss: 0.322806
global_step: 6868, epoch: 172, loss: 0.327144
global_step: 6869, epoch: 172, loss: 0.278956
global_step: 6870, epoch: 172, loss: 0.246855
global_step: 6871, epoch: 172, loss: 0.247424
global_step: 6872, epoch: 172, loss: 0.329791
global_step: 6873, epoch: 172, loss: 0.342478
global_step: 6874, epoch: 172, loss: 0.280540
global_step: 6875, epoch: 172, loss: 0.281229
global_step: 6876, epoch: 172, loss: 0.208143
global_step: 6877, epoch: 172, loss: 0.236566
global_step: 6878, epoch: 172, loss: 0.232401
global_step: 6879, epoch: 172, loss: 0.276604
global_step: 6880, epoch: 172, loss: 0.741395
epoch: 172
train	acc: 0.9560	macro: p 0.9578, r 0.9159, f1: 0.9347	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9557
dev	acc: 0.5500	macro: p 0.4360, r 0.3674, f1: 0.3781	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5222
test	acc: 0.5908	macro: p 0.4130, r 0.3544, f1: 0.3650	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5678
global_step: 6881, epoch: 173, loss: 0.282777
global_step: 6882, epoch: 173, loss: 0.240399
global_step: 6883, epoch: 173, loss: 0.288935
global_step: 6884, epoch: 173, loss: 0.257809
global_step: 6885, epoch: 173, loss: 0.254214
global_step: 6886, epoch: 173, loss: 0.303631
global_step: 6887, epoch: 173, loss: 0.262813
global_step: 6888, epoch: 173, loss: 0.279818
global_step: 6889, epoch: 173, loss: 0.292653
global_step: 6890, epoch: 173, loss: 0.354872
global_step: 6891, epoch: 173, loss: 0.244644
global_step: 6892, epoch: 173, loss: 0.315272
global_step: 6893, epoch: 173, loss: 0.249900
global_step: 6894, epoch: 173, loss: 0.293164
global_step: 6895, epoch: 173, loss: 0.275150
global_step: 6896, epoch: 173, loss: 0.270809
global_step: 6897, epoch: 173, loss: 0.261930
global_step: 6898, epoch: 173, loss: 0.287568
global_step: 6899, epoch: 173, loss: 0.294442
global_step: 6900, epoch: 173, loss: 0.297429
global_step: 6901, epoch: 173, loss: 0.237322
global_step: 6902, epoch: 173, loss: 0.323661
global_step: 6903, epoch: 173, loss: 0.272552
global_step: 6904, epoch: 173, loss: 0.318127
global_step: 6905, epoch: 173, loss: 0.272227
global_step: 6906, epoch: 173, loss: 0.323787
global_step: 6907, epoch: 173, loss: 0.316889
global_step: 6908, epoch: 173, loss: 0.256307
global_step: 6909, epoch: 173, loss: 0.299548
global_step: 6910, epoch: 173, loss: 0.243078
global_step: 6911, epoch: 173, loss: 0.255564
global_step: 6912, epoch: 173, loss: 0.296304
global_step: 6913, epoch: 173, loss: 0.265031
global_step: 6914, epoch: 173, loss: 0.246073
global_step: 6915, epoch: 173, loss: 0.274813
global_step: 6916, epoch: 173, loss: 0.253192
global_step: 6917, epoch: 173, loss: 0.329574
global_step: 6918, epoch: 173, loss: 0.218161
global_step: 6919, epoch: 173, loss: 0.309593
global_step: 6920, epoch: 173, loss: 0.003439
epoch: 173
train	acc: 0.9597	macro: p 0.9640, r 0.9259, f1: 0.9433	micro: p 0.9597, r 0.9597, f1 0.9597	weighted_f1:0.9595
dev	acc: 0.5455	macro: p 0.4052, r 0.3606, f1: 0.3657	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5153
test	acc: 0.5820	macro: p 0.3799, r 0.3457, f1: 0.3520	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5576
global_step: 6921, epoch: 174, loss: 0.310938
global_step: 6922, epoch: 174, loss: 0.280711
global_step: 6923, epoch: 174, loss: 0.250747
global_step: 6924, epoch: 174, loss: 0.285851
global_step: 6925, epoch: 174, loss: 0.284626
global_step: 6926, epoch: 174, loss: 0.239403
global_step: 6927, epoch: 174, loss: 0.260790
global_step: 6928, epoch: 174, loss: 0.194179
global_step: 6929, epoch: 174, loss: 0.267191
global_step: 6930, epoch: 174, loss: 0.303085
global_step: 6931, epoch: 174, loss: 0.352585
global_step: 6932, epoch: 174, loss: 0.331730
global_step: 6933, epoch: 174, loss: 0.246239
global_step: 6934, epoch: 174, loss: 0.276962
global_step: 6935, epoch: 174, loss: 0.245720
global_step: 6936, epoch: 174, loss: 0.263585
global_step: 6937, epoch: 174, loss: 0.338960
global_step: 6938, epoch: 174, loss: 0.253363
global_step: 6939, epoch: 174, loss: 0.278921
global_step: 6940, epoch: 174, loss: 0.262949
global_step: 6941, epoch: 174, loss: 0.174444
global_step: 6942, epoch: 174, loss: 0.237821
global_step: 6943, epoch: 174, loss: 0.291968
global_step: 6944, epoch: 174, loss: 0.283708
global_step: 6945, epoch: 174, loss: 0.261031
global_step: 6946, epoch: 174, loss: 0.330506
global_step: 6947, epoch: 174, loss: 0.324262
global_step: 6948, epoch: 174, loss: 0.298132
global_step: 6949, epoch: 174, loss: 0.265690
global_step: 6950, epoch: 174, loss: 0.388576
global_step: 6951, epoch: 174, loss: 0.311790
global_step: 6952, epoch: 174, loss: 0.288539
global_step: 6953, epoch: 174, loss: 0.330521
global_step: 6954, epoch: 174, loss: 0.277325
global_step: 6955, epoch: 174, loss: 0.368689
global_step: 6956, epoch: 174, loss: 0.321045
global_step: 6957, epoch: 174, loss: 0.263183
global_step: 6958, epoch: 174, loss: 0.265478
global_step: 6959, epoch: 174, loss: 0.288966
global_step: 6960, epoch: 174, loss: 0.027349
epoch: 174
train	acc: 0.9571	macro: p 0.9615, r 0.9226, f1: 0.9404	micro: p 0.9571, r 0.9571, f1 0.9571	weighted_f1:0.9568
dev	acc: 0.5555	macro: p 0.4303, r 0.3582, f1: 0.3715	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5195
test	acc: 0.5824	macro: p 0.3872, r 0.3336, f1: 0.3474	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5504
global_step: 6961, epoch: 175, loss: 0.280303
global_step: 6962, epoch: 175, loss: 0.246058
global_step: 6963, epoch: 175, loss: 0.322389
global_step: 6964, epoch: 175, loss: 0.220115
global_step: 6965, epoch: 175, loss: 0.355259
global_step: 6966, epoch: 175, loss: 0.279058
global_step: 6967, epoch: 175, loss: 0.243426
global_step: 6968, epoch: 175, loss: 0.266630
global_step: 6969, epoch: 175, loss: 0.245242
global_step: 6970, epoch: 175, loss: 0.317906
global_step: 6971, epoch: 175, loss: 0.209475
global_step: 6972, epoch: 175, loss: 0.265347
global_step: 6973, epoch: 175, loss: 0.323694
global_step: 6974, epoch: 175, loss: 0.319523
global_step: 6975, epoch: 175, loss: 0.276690
global_step: 6976, epoch: 175, loss: 0.338859
global_step: 6977, epoch: 175, loss: 0.290157
global_step: 6978, epoch: 175, loss: 0.357969
global_step: 6979, epoch: 175, loss: 0.271870
global_step: 6980, epoch: 175, loss: 0.288427
global_step: 6981, epoch: 175, loss: 0.330059
global_step: 6982, epoch: 175, loss: 0.224036
global_step: 6983, epoch: 175, loss: 0.206007
global_step: 6984, epoch: 175, loss: 0.296746
global_step: 6985, epoch: 175, loss: 0.323574
global_step: 6986, epoch: 175, loss: 0.203620
global_step: 6987, epoch: 175, loss: 0.258133
global_step: 6988, epoch: 175, loss: 0.305915
global_step: 6989, epoch: 175, loss: 0.282231
global_step: 6990, epoch: 175, loss: 0.262444
global_step: 6991, epoch: 175, loss: 0.281180
global_step: 6992, epoch: 175, loss: 0.205479
global_step: 6993, epoch: 175, loss: 0.303874
global_step: 6994, epoch: 175, loss: 0.271293
global_step: 6995, epoch: 175, loss: 0.255485
global_step: 6996, epoch: 175, loss: 0.275327
global_step: 6997, epoch: 175, loss: 0.227728
global_step: 6998, epoch: 175, loss: 0.240534
global_step: 6999, epoch: 175, loss: 0.298215
global_step: 7000, epoch: 175, loss: 0.008781
epoch: 175
train	acc: 0.9603	macro: p 0.9615, r 0.9307, f1: 0.9450	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9602
dev	acc: 0.5428	macro: p 0.3851, r 0.3590, f1: 0.3611	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5151
test	acc: 0.5831	macro: p 0.3931, r 0.3628, f1: 0.3703	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5628
global_step: 7001, epoch: 176, loss: 0.187209
global_step: 7002, epoch: 176, loss: 0.255429
global_step: 7003, epoch: 176, loss: 0.260448
global_step: 7004, epoch: 176, loss: 0.204938
global_step: 7005, epoch: 176, loss: 0.300345
global_step: 7006, epoch: 176, loss: 0.273216
global_step: 7007, epoch: 176, loss: 0.268654
global_step: 7008, epoch: 176, loss: 0.219126
global_step: 7009, epoch: 176, loss: 0.298847
global_step: 7010, epoch: 176, loss: 0.280004
global_step: 7011, epoch: 176, loss: 0.233031
global_step: 7012, epoch: 176, loss: 0.288680
global_step: 7013, epoch: 176, loss: 0.286329
global_step: 7014, epoch: 176, loss: 0.292864
global_step: 7015, epoch: 176, loss: 0.337060
global_step: 7016, epoch: 176, loss: 0.277958
global_step: 7017, epoch: 176, loss: 0.279284
global_step: 7018, epoch: 176, loss: 0.267403
global_step: 7019, epoch: 176, loss: 0.214421
global_step: 7020, epoch: 176, loss: 0.328451
global_step: 7021, epoch: 176, loss: 0.252994
global_step: 7022, epoch: 176, loss: 0.322173
global_step: 7023, epoch: 176, loss: 0.276424
global_step: 7024, epoch: 176, loss: 0.329997
global_step: 7025, epoch: 176, loss: 0.372018
global_step: 7026, epoch: 176, loss: 0.254353
global_step: 7027, epoch: 176, loss: 0.288942
global_step: 7028, epoch: 176, loss: 0.316469
global_step: 7029, epoch: 176, loss: 0.276940
global_step: 7030, epoch: 176, loss: 0.285436
global_step: 7031, epoch: 176, loss: 0.260528
global_step: 7032, epoch: 176, loss: 0.272074
global_step: 7033, epoch: 176, loss: 0.286560
global_step: 7034, epoch: 176, loss: 0.261061
global_step: 7035, epoch: 176, loss: 0.246421
global_step: 7036, epoch: 176, loss: 0.323759
global_step: 7037, epoch: 176, loss: 0.398075
global_step: 7038, epoch: 176, loss: 0.231326
global_step: 7039, epoch: 176, loss: 0.328001
global_step: 7040, epoch: 176, loss: 0.465633
epoch: 176
train	acc: 0.9560	macro: p 0.9624, r 0.9180, f1: 0.9382	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9557
dev	acc: 0.5564	macro: p 0.4233, r 0.3552, f1: 0.3636	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5204
test	acc: 0.5916	macro: p 0.3952, r 0.3402, f1: 0.3485	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5617
global_step: 7041, epoch: 177, loss: 0.242840
global_step: 7042, epoch: 177, loss: 0.297150
global_step: 7043, epoch: 177, loss: 0.329108
global_step: 7044, epoch: 177, loss: 0.345284
global_step: 7045, epoch: 177, loss: 0.276336
global_step: 7046, epoch: 177, loss: 0.294973
global_step: 7047, epoch: 177, loss: 0.347929
global_step: 7048, epoch: 177, loss: 0.257803
global_step: 7049, epoch: 177, loss: 0.333170
global_step: 7050, epoch: 177, loss: 0.239232
global_step: 7051, epoch: 177, loss: 0.318083
global_step: 7052, epoch: 177, loss: 0.286673
global_step: 7053, epoch: 177, loss: 0.269421
global_step: 7054, epoch: 177, loss: 0.308497
global_step: 7055, epoch: 177, loss: 0.278530
global_step: 7056, epoch: 177, loss: 0.287191
global_step: 7057, epoch: 177, loss: 0.278990
global_step: 7058, epoch: 177, loss: 0.230907
global_step: 7059, epoch: 177, loss: 0.256105
global_step: 7060, epoch: 177, loss: 0.274867
global_step: 7061, epoch: 177, loss: 0.233824
global_step: 7062, epoch: 177, loss: 0.202230
global_step: 7063, epoch: 177, loss: 0.246477
global_step: 7064, epoch: 177, loss: 0.283205
global_step: 7065, epoch: 177, loss: 0.322115
global_step: 7066, epoch: 177, loss: 0.290112
global_step: 7067, epoch: 177, loss: 0.268094
global_step: 7068, epoch: 177, loss: 0.269238
global_step: 7069, epoch: 177, loss: 0.288610
global_step: 7070, epoch: 177, loss: 0.278603
global_step: 7071, epoch: 177, loss: 0.277366
global_step: 7072, epoch: 177, loss: 0.269232
global_step: 7073, epoch: 177, loss: 0.265148
global_step: 7074, epoch: 177, loss: 0.244177
global_step: 7075, epoch: 177, loss: 0.265315
global_step: 7076, epoch: 177, loss: 0.286404
global_step: 7077, epoch: 177, loss: 0.327169
global_step: 7078, epoch: 177, loss: 0.246758
global_step: 7079, epoch: 177, loss: 0.309825
global_step: 7080, epoch: 177, loss: 0.384391
epoch: 177
train	acc: 0.9549	macro: p 0.9609, r 0.9125, f1: 0.9341	micro: p 0.9549, r 0.9549, f1 0.9549	weighted_f1:0.9546
dev	acc: 0.5564	macro: p 0.4151, r 0.3526, f1: 0.3553	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5188
test	acc: 0.5831	macro: p 0.4006, r 0.3341, f1: 0.3378	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5497
global_step: 7081, epoch: 178, loss: 0.244802
global_step: 7082, epoch: 178, loss: 0.326259
global_step: 7083, epoch: 178, loss: 0.304407
global_step: 7084, epoch: 178, loss: 0.231780
global_step: 7085, epoch: 178, loss: 0.278884
global_step: 7086, epoch: 178, loss: 0.273865
global_step: 7087, epoch: 178, loss: 0.303981
global_step: 7088, epoch: 178, loss: 0.251808
global_step: 7089, epoch: 178, loss: 0.302865
global_step: 7090, epoch: 178, loss: 0.251952
global_step: 7091, epoch: 178, loss: 0.242716
global_step: 7092, epoch: 178, loss: 0.264433
global_step: 7093, epoch: 178, loss: 0.270456
global_step: 7094, epoch: 178, loss: 0.275768
global_step: 7095, epoch: 178, loss: 0.318660
global_step: 7096, epoch: 178, loss: 0.259498
global_step: 7097, epoch: 178, loss: 0.231930
global_step: 7098, epoch: 178, loss: 0.268196
global_step: 7099, epoch: 178, loss: 0.261966
global_step: 7100, epoch: 178, loss: 0.272357
global_step: 7101, epoch: 178, loss: 0.262729
global_step: 7102, epoch: 178, loss: 0.274895
global_step: 7103, epoch: 178, loss: 0.342681
global_step: 7104, epoch: 178, loss: 0.335237
global_step: 7105, epoch: 178, loss: 0.304560
global_step: 7106, epoch: 178, loss: 0.281209
global_step: 7107, epoch: 178, loss: 0.275618
global_step: 7108, epoch: 178, loss: 0.261478
global_step: 7109, epoch: 178, loss: 0.196628
global_step: 7110, epoch: 178, loss: 0.253926
global_step: 7111, epoch: 178, loss: 0.250886
global_step: 7112, epoch: 178, loss: 0.273398
global_step: 7113, epoch: 178, loss: 0.308447
global_step: 7114, epoch: 178, loss: 0.305937
global_step: 7115, epoch: 178, loss: 0.318487
global_step: 7116, epoch: 178, loss: 0.243886
global_step: 7117, epoch: 178, loss: 0.376086
global_step: 7118, epoch: 178, loss: 0.269651
global_step: 7119, epoch: 178, loss: 0.274659
global_step: 7120, epoch: 178, loss: 0.100524
epoch: 178
train	acc: 0.9594	macro: p 0.9617, r 0.9225, f1: 0.9400	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9591
dev	acc: 0.5383	macro: p 0.4037, r 0.3541, f1: 0.3619	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5132
test	acc: 0.5820	macro: p 0.3980, r 0.3535, f1: 0.3647	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5613
global_step: 7121, epoch: 179, loss: 0.301874
global_step: 7122, epoch: 179, loss: 0.215707
global_step: 7123, epoch: 179, loss: 0.220412
global_step: 7124, epoch: 179, loss: 0.248889
global_step: 7125, epoch: 179, loss: 0.261779
global_step: 7126, epoch: 179, loss: 0.232680
global_step: 7127, epoch: 179, loss: 0.226004
global_step: 7128, epoch: 179, loss: 0.349431
global_step: 7129, epoch: 179, loss: 0.264557
global_step: 7130, epoch: 179, loss: 0.276687
global_step: 7131, epoch: 179, loss: 0.292933
global_step: 7132, epoch: 179, loss: 0.261249
global_step: 7133, epoch: 179, loss: 0.296911
global_step: 7134, epoch: 179, loss: 0.366762
global_step: 7135, epoch: 179, loss: 0.299690
global_step: 7136, epoch: 179, loss: 0.274185
global_step: 7137, epoch: 179, loss: 0.237461
global_step: 7138, epoch: 179, loss: 0.300937
global_step: 7139, epoch: 179, loss: 0.266365
global_step: 7140, epoch: 179, loss: 0.230998
global_step: 7141, epoch: 179, loss: 0.232497
global_step: 7142, epoch: 179, loss: 0.272513
global_step: 7143, epoch: 179, loss: 0.289541
global_step: 7144, epoch: 179, loss: 0.234994
global_step: 7145, epoch: 179, loss: 0.316160
global_step: 7146, epoch: 179, loss: 0.298316
global_step: 7147, epoch: 179, loss: 0.333934
global_step: 7148, epoch: 179, loss: 0.325243
global_step: 7149, epoch: 179, loss: 0.301140
global_step: 7150, epoch: 179, loss: 0.209554
global_step: 7151, epoch: 179, loss: 0.237172
global_step: 7152, epoch: 179, loss: 0.248194
global_step: 7153, epoch: 179, loss: 0.271692
global_step: 7154, epoch: 179, loss: 0.297151
global_step: 7155, epoch: 179, loss: 0.300612
global_step: 7156, epoch: 179, loss: 0.261552
global_step: 7157, epoch: 179, loss: 0.258458
global_step: 7158, epoch: 179, loss: 0.315029
global_step: 7159, epoch: 179, loss: 0.176213
global_step: 7160, epoch: 179, loss: 0.329096
epoch: 179
train	acc: 0.9580	macro: p 0.9623, r 0.9207, f1: 0.9397	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9577
dev	acc: 0.5573	macro: p 0.4637, r 0.3555, f1: 0.3724	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5226
test	acc: 0.5897	macro: p 0.4233, r 0.3411, f1: 0.3561	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5600
global_step: 7161, epoch: 180, loss: 0.238105
global_step: 7162, epoch: 180, loss: 0.301147
global_step: 7163, epoch: 180, loss: 0.326497
global_step: 7164, epoch: 180, loss: 0.309990
global_step: 7165, epoch: 180, loss: 0.177094
global_step: 7166, epoch: 180, loss: 0.260054
global_step: 7167, epoch: 180, loss: 0.221852
global_step: 7168, epoch: 180, loss: 0.273808
global_step: 7169, epoch: 180, loss: 0.226385
global_step: 7170, epoch: 180, loss: 0.205410
global_step: 7171, epoch: 180, loss: 0.281123
global_step: 7172, epoch: 180, loss: 0.275643
global_step: 7173, epoch: 180, loss: 0.220582
global_step: 7174, epoch: 180, loss: 0.264542
global_step: 7175, epoch: 180, loss: 0.289085
global_step: 7176, epoch: 180, loss: 0.271564
global_step: 7177, epoch: 180, loss: 0.254013
global_step: 7178, epoch: 180, loss: 0.245655
global_step: 7179, epoch: 180, loss: 0.259044
global_step: 7180, epoch: 180, loss: 0.292035
global_step: 7181, epoch: 180, loss: 0.317673
global_step: 7182, epoch: 180, loss: 0.323570
global_step: 7183, epoch: 180, loss: 0.392964
global_step: 7184, epoch: 180, loss: 0.356561
global_step: 7185, epoch: 180, loss: 0.196078
global_step: 7186, epoch: 180, loss: 0.284966
global_step: 7187, epoch: 180, loss: 0.270301
global_step: 7188, epoch: 180, loss: 0.300242
global_step: 7189, epoch: 180, loss: 0.203169
global_step: 7190, epoch: 180, loss: 0.221565
global_step: 7191, epoch: 180, loss: 0.266231
global_step: 7192, epoch: 180, loss: 0.290326
global_step: 7193, epoch: 180, loss: 0.220874
global_step: 7194, epoch: 180, loss: 0.270517
global_step: 7195, epoch: 180, loss: 0.332455
global_step: 7196, epoch: 180, loss: 0.351918
global_step: 7197, epoch: 180, loss: 0.297015
global_step: 7198, epoch: 180, loss: 0.270760
global_step: 7199, epoch: 180, loss: 0.245429
global_step: 7200, epoch: 180, loss: 0.194372
epoch: 180
train	acc: 0.9601	macro: p 0.9626, r 0.9294, f1: 0.9448	micro: p 0.9601, r 0.9601, f1 0.9601	weighted_f1:0.9599
dev	acc: 0.5491	macro: p 0.3948, r 0.3547, f1: 0.3604	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5149
test	acc: 0.5835	macro: p 0.3889, r 0.3514, f1: 0.3614	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5579
global_step: 7201, epoch: 181, loss: 0.309930
global_step: 7202, epoch: 181, loss: 0.323415
global_step: 7203, epoch: 181, loss: 0.212920
global_step: 7204, epoch: 181, loss: 0.276115
global_step: 7205, epoch: 181, loss: 0.265995
global_step: 7206, epoch: 181, loss: 0.250401
global_step: 7207, epoch: 181, loss: 0.251280
global_step: 7208, epoch: 181, loss: 0.286607
global_step: 7209, epoch: 181, loss: 0.265398
global_step: 7210, epoch: 181, loss: 0.235994
global_step: 7211, epoch: 181, loss: 0.274994
global_step: 7212, epoch: 181, loss: 0.284865
global_step: 7213, epoch: 181, loss: 0.233409
global_step: 7214, epoch: 181, loss: 0.217812
global_step: 7215, epoch: 181, loss: 0.257713
global_step: 7216, epoch: 181, loss: 0.225554
global_step: 7217, epoch: 181, loss: 0.212288
global_step: 7218, epoch: 181, loss: 0.258487
global_step: 7219, epoch: 181, loss: 0.292308
global_step: 7220, epoch: 181, loss: 0.262088
global_step: 7221, epoch: 181, loss: 0.269995
global_step: 7222, epoch: 181, loss: 0.262574
global_step: 7223, epoch: 181, loss: 0.260759
global_step: 7224, epoch: 181, loss: 0.201416
global_step: 7225, epoch: 181, loss: 0.336191
global_step: 7226, epoch: 181, loss: 0.288369
global_step: 7227, epoch: 181, loss: 0.312161
global_step: 7228, epoch: 181, loss: 0.256515
global_step: 7229, epoch: 181, loss: 0.318857
global_step: 7230, epoch: 181, loss: 0.270328
global_step: 7231, epoch: 181, loss: 0.298967
global_step: 7232, epoch: 181, loss: 0.215482
global_step: 7233, epoch: 181, loss: 0.326600
global_step: 7234, epoch: 181, loss: 0.285028
global_step: 7235, epoch: 181, loss: 0.303534
global_step: 7236, epoch: 181, loss: 0.267698
global_step: 7237, epoch: 181, loss: 0.236521
global_step: 7238, epoch: 181, loss: 0.216154
global_step: 7239, epoch: 181, loss: 0.244196
global_step: 7240, epoch: 181, loss: 0.092346
epoch: 181
train	acc: 0.9598	macro: p 0.9648, r 0.9286, f1: 0.9451	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9597
dev	acc: 0.5437	macro: p 0.4060, r 0.3655, f1: 0.3705	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5180
test	acc: 0.5839	macro: p 0.3882, r 0.3539, f1: 0.3570	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5625
global_step: 7241, epoch: 182, loss: 0.226624
global_step: 7242, epoch: 182, loss: 0.300209
global_step: 7243, epoch: 182, loss: 0.252018
global_step: 7244, epoch: 182, loss: 0.231286
global_step: 7245, epoch: 182, loss: 0.278008
global_step: 7246, epoch: 182, loss: 0.317613
global_step: 7247, epoch: 182, loss: 0.213319
global_step: 7248, epoch: 182, loss: 0.215933
global_step: 7249, epoch: 182, loss: 0.259224
global_step: 7250, epoch: 182, loss: 0.190117
global_step: 7251, epoch: 182, loss: 0.265353
global_step: 7252, epoch: 182, loss: 0.264581
global_step: 7253, epoch: 182, loss: 0.246784
global_step: 7254, epoch: 182, loss: 0.245339
global_step: 7255, epoch: 182, loss: 0.292147
global_step: 7256, epoch: 182, loss: 0.249788
global_step: 7257, epoch: 182, loss: 0.255218
global_step: 7258, epoch: 182, loss: 0.246894
global_step: 7259, epoch: 182, loss: 0.286321
global_step: 7260, epoch: 182, loss: 0.239134
global_step: 7261, epoch: 182, loss: 0.192118
global_step: 7262, epoch: 182, loss: 0.308739
global_step: 7263, epoch: 182, loss: 0.237972
global_step: 7264, epoch: 182, loss: 0.228594
global_step: 7265, epoch: 182, loss: 0.346770
global_step: 7266, epoch: 182, loss: 0.226934
global_step: 7267, epoch: 182, loss: 0.273057
global_step: 7268, epoch: 182, loss: 0.284303
global_step: 7269, epoch: 182, loss: 0.354460
global_step: 7270, epoch: 182, loss: 0.240733
global_step: 7271, epoch: 182, loss: 0.265021
global_step: 7272, epoch: 182, loss: 0.298036
global_step: 7273, epoch: 182, loss: 0.306794
global_step: 7274, epoch: 182, loss: 0.318063
global_step: 7275, epoch: 182, loss: 0.250121
global_step: 7276, epoch: 182, loss: 0.362723
global_step: 7277, epoch: 182, loss: 0.294023
global_step: 7278, epoch: 182, loss: 0.311093
global_step: 7279, epoch: 182, loss: 0.273067
global_step: 7280, epoch: 182, loss: 0.880060
epoch: 182
train	acc: 0.9590	macro: p 0.9656, r 0.9262, f1: 0.9445	micro: p 0.9590, r 0.9590, f1 0.9590	weighted_f1:0.9587
dev	acc: 0.5365	macro: p 0.3985, r 0.3456, f1: 0.3558	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.5082
test	acc: 0.5816	macro: p 0.3910, r 0.3482, f1: 0.3584	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5616
global_step: 7281, epoch: 183, loss: 0.264505
global_step: 7282, epoch: 183, loss: 0.337885
global_step: 7283, epoch: 183, loss: 0.284471
global_step: 7284, epoch: 183, loss: 0.265965
global_step: 7285, epoch: 183, loss: 0.259900
global_step: 7286, epoch: 183, loss: 0.277278
global_step: 7287, epoch: 183, loss: 0.354915
global_step: 7288, epoch: 183, loss: 0.306878
global_step: 7289, epoch: 183, loss: 0.305941
global_step: 7290, epoch: 183, loss: 0.309304
global_step: 7291, epoch: 183, loss: 0.217664
global_step: 7292, epoch: 183, loss: 0.291255
global_step: 7293, epoch: 183, loss: 0.277854
global_step: 7294, epoch: 183, loss: 0.230133
global_step: 7295, epoch: 183, loss: 0.204820
global_step: 7296, epoch: 183, loss: 0.249179
global_step: 7297, epoch: 183, loss: 0.297051
global_step: 7298, epoch: 183, loss: 0.254489
global_step: 7299, epoch: 183, loss: 0.238280
global_step: 7300, epoch: 183, loss: 0.237315
global_step: 7301, epoch: 183, loss: 0.261287
global_step: 7302, epoch: 183, loss: 0.296571
global_step: 7303, epoch: 183, loss: 0.210525
global_step: 7304, epoch: 183, loss: 0.271262
global_step: 7305, epoch: 183, loss: 0.328307
global_step: 7306, epoch: 183, loss: 0.281476
global_step: 7307, epoch: 183, loss: 0.223672
global_step: 7308, epoch: 183, loss: 0.264006
global_step: 7309, epoch: 183, loss: 0.223844
global_step: 7310, epoch: 183, loss: 0.286050
global_step: 7311, epoch: 183, loss: 0.288337
global_step: 7312, epoch: 183, loss: 0.257401
global_step: 7313, epoch: 183, loss: 0.256893
global_step: 7314, epoch: 183, loss: 0.292859
global_step: 7315, epoch: 183, loss: 0.235801
global_step: 7316, epoch: 183, loss: 0.280944
global_step: 7317, epoch: 183, loss: 0.244077
global_step: 7318, epoch: 183, loss: 0.289671
global_step: 7319, epoch: 183, loss: 0.250041
global_step: 7320, epoch: 183, loss: 0.516461
epoch: 183
train	acc: 0.9561	macro: p 0.9603, r 0.9155, f1: 0.9357	micro: p 0.9561, r 0.9561, f1 0.9561	weighted_f1:0.9558
dev	acc: 0.5464	macro: p 0.4430, r 0.3432, f1: 0.3538	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5111
test	acc: 0.5962	macro: p 0.4162, r 0.3467, f1: 0.3559	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5667
global_step: 7321, epoch: 184, loss: 0.248759
global_step: 7322, epoch: 184, loss: 0.219466
global_step: 7323, epoch: 184, loss: 0.169536
global_step: 7324, epoch: 184, loss: 0.304367
global_step: 7325, epoch: 184, loss: 0.271070
global_step: 7326, epoch: 184, loss: 0.290797
global_step: 7327, epoch: 184, loss: 0.266958
global_step: 7328, epoch: 184, loss: 0.277615
global_step: 7329, epoch: 184, loss: 0.261922
global_step: 7330, epoch: 184, loss: 0.308342
global_step: 7331, epoch: 184, loss: 0.258840
global_step: 7332, epoch: 184, loss: 0.248381
global_step: 7333, epoch: 184, loss: 0.286428
global_step: 7334, epoch: 184, loss: 0.264881
global_step: 7335, epoch: 184, loss: 0.239866
global_step: 7336, epoch: 184, loss: 0.230260
global_step: 7337, epoch: 184, loss: 0.231701
global_step: 7338, epoch: 184, loss: 0.275383
global_step: 7339, epoch: 184, loss: 0.238506
global_step: 7340, epoch: 184, loss: 0.323219
global_step: 7341, epoch: 184, loss: 0.283669
global_step: 7342, epoch: 184, loss: 0.267462
global_step: 7343, epoch: 184, loss: 0.280441
global_step: 7344, epoch: 184, loss: 0.248784
global_step: 7345, epoch: 184, loss: 0.279508
global_step: 7346, epoch: 184, loss: 0.199156
global_step: 7347, epoch: 184, loss: 0.201036
global_step: 7348, epoch: 184, loss: 0.220544
global_step: 7349, epoch: 184, loss: 0.238167
global_step: 7350, epoch: 184, loss: 0.224114
global_step: 7351, epoch: 184, loss: 0.237274
global_step: 7352, epoch: 184, loss: 0.303361
global_step: 7353, epoch: 184, loss: 0.234443
global_step: 7354, epoch: 184, loss: 0.226904
global_step: 7355, epoch: 184, loss: 0.279837
global_step: 7356, epoch: 184, loss: 0.211107
global_step: 7357, epoch: 184, loss: 0.270907
global_step: 7358, epoch: 184, loss: 0.284570
global_step: 7359, epoch: 184, loss: 0.283468
global_step: 7360, epoch: 184, loss: 0.032793
epoch: 184
train	acc: 0.9601	macro: p 0.9666, r 0.9292, f1: 0.9466	micro: p 0.9601, r 0.9601, f1 0.9601	weighted_f1:0.9599
dev	acc: 0.5546	macro: p 0.4307, r 0.3446, f1: 0.3601	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5171
test	acc: 0.5946	macro: p 0.4212, r 0.3438, f1: 0.3590	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5622
global_step: 7361, epoch: 185, loss: 0.208748
global_step: 7362, epoch: 185, loss: 0.270692
global_step: 7363, epoch: 185, loss: 0.246912
global_step: 7364, epoch: 185, loss: 0.303265
global_step: 7365, epoch: 185, loss: 0.254450
global_step: 7366, epoch: 185, loss: 0.217482
global_step: 7367, epoch: 185, loss: 0.201308
global_step: 7368, epoch: 185, loss: 0.287195
global_step: 7369, epoch: 185, loss: 0.245374
global_step: 7370, epoch: 185, loss: 0.234947
global_step: 7371, epoch: 185, loss: 0.264349
global_step: 7372, epoch: 185, loss: 0.212879
global_step: 7373, epoch: 185, loss: 0.272965
global_step: 7374, epoch: 185, loss: 0.244573
global_step: 7375, epoch: 185, loss: 0.286812
global_step: 7376, epoch: 185, loss: 0.251273
global_step: 7377, epoch: 185, loss: 0.280727
global_step: 7378, epoch: 185, loss: 0.286079
global_step: 7379, epoch: 185, loss: 0.301433
global_step: 7380, epoch: 185, loss: 0.284382
global_step: 7381, epoch: 185, loss: 0.241666
global_step: 7382, epoch: 185, loss: 0.287259
global_step: 7383, epoch: 185, loss: 0.223176
global_step: 7384, epoch: 185, loss: 0.211639
global_step: 7385, epoch: 185, loss: 0.244110
global_step: 7386, epoch: 185, loss: 0.311987
global_step: 7387, epoch: 185, loss: 0.278427
global_step: 7388, epoch: 185, loss: 0.368893
global_step: 7389, epoch: 185, loss: 0.259793
global_step: 7390, epoch: 185, loss: 0.227436
global_step: 7391, epoch: 185, loss: 0.232025
global_step: 7392, epoch: 185, loss: 0.263768
global_step: 7393, epoch: 185, loss: 0.240546
global_step: 7394, epoch: 185, loss: 0.218501
global_step: 7395, epoch: 185, loss: 0.306876
global_step: 7396, epoch: 185, loss: 0.224818
global_step: 7397, epoch: 185, loss: 0.342473
global_step: 7398, epoch: 185, loss: 0.269036
global_step: 7399, epoch: 185, loss: 0.275050
global_step: 7400, epoch: 185, loss: 0.025986
epoch: 185
train	acc: 0.9599	macro: p 0.9644, r 0.9272, f1: 0.9442	micro: p 0.9599, r 0.9599, f1 0.9599	weighted_f1:0.9597
dev	acc: 0.5365	macro: p 0.3944, r 0.3464, f1: 0.3526	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.5046
test	acc: 0.5866	macro: p 0.3974, r 0.3449, f1: 0.3546	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5583
global_step: 7401, epoch: 186, loss: 0.262478
global_step: 7402, epoch: 186, loss: 0.226260
global_step: 7403, epoch: 186, loss: 0.248545
global_step: 7404, epoch: 186, loss: 0.285785
global_step: 7405, epoch: 186, loss: 0.266053
global_step: 7406, epoch: 186, loss: 0.201389
global_step: 7407, epoch: 186, loss: 0.278103
global_step: 7408, epoch: 186, loss: 0.290988
global_step: 7409, epoch: 186, loss: 0.368444
global_step: 7410, epoch: 186, loss: 0.225481
global_step: 7411, epoch: 186, loss: 0.283497
global_step: 7412, epoch: 186, loss: 0.248178
global_step: 7413, epoch: 186, loss: 0.204707
global_step: 7414, epoch: 186, loss: 0.240837
global_step: 7415, epoch: 186, loss: 0.328416
global_step: 7416, epoch: 186, loss: 0.240758
global_step: 7417, epoch: 186, loss: 0.287985
global_step: 7418, epoch: 186, loss: 0.270404
global_step: 7419, epoch: 186, loss: 0.276242
global_step: 7420, epoch: 186, loss: 0.227038
global_step: 7421, epoch: 186, loss: 0.231038
global_step: 7422, epoch: 186, loss: 0.216953
global_step: 7423, epoch: 186, loss: 0.301900
global_step: 7424, epoch: 186, loss: 0.291591
global_step: 7425, epoch: 186, loss: 0.244318
global_step: 7426, epoch: 186, loss: 0.230295
global_step: 7427, epoch: 186, loss: 0.205267
global_step: 7428, epoch: 186, loss: 0.307803
global_step: 7429, epoch: 186, loss: 0.248073
global_step: 7430, epoch: 186, loss: 0.278838
global_step: 7431, epoch: 186, loss: 0.230319
global_step: 7432, epoch: 186, loss: 0.284088
global_step: 7433, epoch: 186, loss: 0.244192
global_step: 7434, epoch: 186, loss: 0.195372
global_step: 7435, epoch: 186, loss: 0.247796
global_step: 7436, epoch: 186, loss: 0.233738
global_step: 7437, epoch: 186, loss: 0.252964
global_step: 7438, epoch: 186, loss: 0.317965
global_step: 7439, epoch: 186, loss: 0.262626
global_step: 7440, epoch: 186, loss: 0.002815
epoch: 186
train	acc: 0.9616	macro: p 0.9644, r 0.9313, f1: 0.9467	micro: p 0.9616, r 0.9616, f1 0.9616	weighted_f1:0.9614
dev	acc: 0.5419	macro: p 0.3935, r 0.3502, f1: 0.3605	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5135
test	acc: 0.5843	macro: p 0.3892, r 0.3512, f1: 0.3622	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5620
global_step: 7441, epoch: 187, loss: 0.252862
global_step: 7442, epoch: 187, loss: 0.255748
global_step: 7443, epoch: 187, loss: 0.269380
global_step: 7444, epoch: 187, loss: 0.237092
global_step: 7445, epoch: 187, loss: 0.305113
global_step: 7446, epoch: 187, loss: 0.338455
global_step: 7447, epoch: 187, loss: 0.332728
global_step: 7448, epoch: 187, loss: 0.255970
global_step: 7449, epoch: 187, loss: 0.265630
global_step: 7450, epoch: 187, loss: 0.273629
global_step: 7451, epoch: 187, loss: 0.256328
global_step: 7452, epoch: 187, loss: 0.195951
global_step: 7453, epoch: 187, loss: 0.260103
global_step: 7454, epoch: 187, loss: 0.286480
global_step: 7455, epoch: 187, loss: 0.285068
global_step: 7456, epoch: 187, loss: 0.268353
global_step: 7457, epoch: 187, loss: 0.299180
global_step: 7458, epoch: 187, loss: 0.276266
global_step: 7459, epoch: 187, loss: 0.293424
global_step: 7460, epoch: 187, loss: 0.267450
global_step: 7461, epoch: 187, loss: 0.231101
global_step: 7462, epoch: 187, loss: 0.236503
global_step: 7463, epoch: 187, loss: 0.270915
global_step: 7464, epoch: 187, loss: 0.251405
global_step: 7465, epoch: 187, loss: 0.232319
global_step: 7466, epoch: 187, loss: 0.268512
global_step: 7467, epoch: 187, loss: 0.335552
global_step: 7468, epoch: 187, loss: 0.264255
global_step: 7469, epoch: 187, loss: 0.245512
global_step: 7470, epoch: 187, loss: 0.259675
global_step: 7471, epoch: 187, loss: 0.270910
global_step: 7472, epoch: 187, loss: 0.196057
global_step: 7473, epoch: 187, loss: 0.292571
global_step: 7474, epoch: 187, loss: 0.279174
global_step: 7475, epoch: 187, loss: 0.266030
global_step: 7476, epoch: 187, loss: 0.213477
global_step: 7477, epoch: 187, loss: 0.301721
global_step: 7478, epoch: 187, loss: 0.271543
global_step: 7479, epoch: 187, loss: 0.232967
global_step: 7480, epoch: 187, loss: 0.030972
epoch: 187
train	acc: 0.9600	macro: p 0.9665, r 0.9274, f1: 0.9453	micro: p 0.9600, r 0.9600, f1 0.9600	weighted_f1:0.9598
dev	acc: 0.5491	macro: p 0.4315, r 0.3491, f1: 0.3603	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5126
test	acc: 0.5881	macro: p 0.3996, r 0.3401, f1: 0.3519	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5562
global_step: 7481, epoch: 188, loss: 0.241080
global_step: 7482, epoch: 188, loss: 0.217436
global_step: 7483, epoch: 188, loss: 0.266845
global_step: 7484, epoch: 188, loss: 0.214000
global_step: 7485, epoch: 188, loss: 0.270047
global_step: 7486, epoch: 188, loss: 0.266464
global_step: 7487, epoch: 188, loss: 0.277628
global_step: 7488, epoch: 188, loss: 0.339921
global_step: 7489, epoch: 188, loss: 0.295405
global_step: 7490, epoch: 188, loss: 0.252639
global_step: 7491, epoch: 188, loss: 0.223089
global_step: 7492, epoch: 188, loss: 0.260040
global_step: 7493, epoch: 188, loss: 0.221950
global_step: 7494, epoch: 188, loss: 0.266271
global_step: 7495, epoch: 188, loss: 0.266195
global_step: 7496, epoch: 188, loss: 0.255201
global_step: 7497, epoch: 188, loss: 0.253246
global_step: 7498, epoch: 188, loss: 0.264947
global_step: 7499, epoch: 188, loss: 0.218235
global_step: 7500, epoch: 188, loss: 0.278910
global_step: 7501, epoch: 188, loss: 0.175267
global_step: 7502, epoch: 188, loss: 0.345637
global_step: 7503, epoch: 188, loss: 0.233125
global_step: 7504, epoch: 188, loss: 0.225624
global_step: 7505, epoch: 188, loss: 0.271324
global_step: 7506, epoch: 188, loss: 0.296093
global_step: 7507, epoch: 188, loss: 0.241624
global_step: 7508, epoch: 188, loss: 0.241144
global_step: 7509, epoch: 188, loss: 0.338128
global_step: 7510, epoch: 188, loss: 0.247620
global_step: 7511, epoch: 188, loss: 0.237460
global_step: 7512, epoch: 188, loss: 0.288261
global_step: 7513, epoch: 188, loss: 0.274049
global_step: 7514, epoch: 188, loss: 0.297002
global_step: 7515, epoch: 188, loss: 0.243676
global_step: 7516, epoch: 188, loss: 0.249254
global_step: 7517, epoch: 188, loss: 0.261471
global_step: 7518, epoch: 188, loss: 0.278544
global_step: 7519, epoch: 188, loss: 0.197251
global_step: 7520, epoch: 188, loss: 0.024516
epoch: 188
train	acc: 0.9601	macro: p 0.9655, r 0.9294, f1: 0.9461	micro: p 0.9601, r 0.9601, f1 0.9601	weighted_f1:0.9599
dev	acc: 0.5528	macro: p 0.4494, r 0.3559, f1: 0.3704	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5189
test	acc: 0.5931	macro: p 0.4089, r 0.3448, f1: 0.3552	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5629
global_step: 7521, epoch: 189, loss: 0.233010
global_step: 7522, epoch: 189, loss: 0.207526
global_step: 7523, epoch: 189, loss: 0.292227
global_step: 7524, epoch: 189, loss: 0.254096
global_step: 7525, epoch: 189, loss: 0.247048
global_step: 7526, epoch: 189, loss: 0.294644
global_step: 7527, epoch: 189, loss: 0.250346
global_step: 7528, epoch: 189, loss: 0.241061
global_step: 7529, epoch: 189, loss: 0.277654
global_step: 7530, epoch: 189, loss: 0.232512
global_step: 7531, epoch: 189, loss: 0.201995
global_step: 7532, epoch: 189, loss: 0.217574
global_step: 7533, epoch: 189, loss: 0.227610
global_step: 7534, epoch: 189, loss: 0.214497
global_step: 7535, epoch: 189, loss: 0.292461
global_step: 7536, epoch: 189, loss: 0.239366
global_step: 7537, epoch: 189, loss: 0.248742
global_step: 7538, epoch: 189, loss: 0.221207
global_step: 7539, epoch: 189, loss: 0.287530
global_step: 7540, epoch: 189, loss: 0.271984
global_step: 7541, epoch: 189, loss: 0.279416
global_step: 7542, epoch: 189, loss: 0.225300
global_step: 7543, epoch: 189, loss: 0.257164
global_step: 7544, epoch: 189, loss: 0.262060
global_step: 7545, epoch: 189, loss: 0.247725
global_step: 7546, epoch: 189, loss: 0.260538
global_step: 7547, epoch: 189, loss: 0.272931
global_step: 7548, epoch: 189, loss: 0.219947
global_step: 7549, epoch: 189, loss: 0.278106
global_step: 7550, epoch: 189, loss: 0.318923
global_step: 7551, epoch: 189, loss: 0.248180
global_step: 7552, epoch: 189, loss: 0.294732
global_step: 7553, epoch: 189, loss: 0.258457
global_step: 7554, epoch: 189, loss: 0.308556
global_step: 7555, epoch: 189, loss: 0.238599
global_step: 7556, epoch: 189, loss: 0.226526
global_step: 7557, epoch: 189, loss: 0.282373
global_step: 7558, epoch: 189, loss: 0.232902
global_step: 7559, epoch: 189, loss: 0.251713
global_step: 7560, epoch: 189, loss: 0.094515
epoch: 189
train	acc: 0.9593	macro: p 0.9676, r 0.9277, f1: 0.9463	micro: p 0.9593, r 0.9593, f1 0.9593	weighted_f1:0.9591
dev	acc: 0.5518	macro: p 0.4115, r 0.3379, f1: 0.3475	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5108
test	acc: 0.5916	macro: p 0.4108, r 0.3357, f1: 0.3485	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5547
global_step: 7561, epoch: 190, loss: 0.292501
global_step: 7562, epoch: 190, loss: 0.269214
global_step: 7563, epoch: 190, loss: 0.254966
global_step: 7564, epoch: 190, loss: 0.216932
global_step: 7565, epoch: 190, loss: 0.231319
global_step: 7566, epoch: 190, loss: 0.230760
global_step: 7567, epoch: 190, loss: 0.232661
global_step: 7568, epoch: 190, loss: 0.339147
global_step: 7569, epoch: 190, loss: 0.269152
global_step: 7570, epoch: 190, loss: 0.285967
global_step: 7571, epoch: 190, loss: 0.265253
global_step: 7572, epoch: 190, loss: 0.211045
global_step: 7573, epoch: 190, loss: 0.227468
global_step: 7574, epoch: 190, loss: 0.255953
global_step: 7575, epoch: 190, loss: 0.274724
global_step: 7576, epoch: 190, loss: 0.284808
global_step: 7577, epoch: 190, loss: 0.241186
global_step: 7578, epoch: 190, loss: 0.211094
global_step: 7579, epoch: 190, loss: 0.247640
global_step: 7580, epoch: 190, loss: 0.287352
global_step: 7581, epoch: 190, loss: 0.243279
global_step: 7582, epoch: 190, loss: 0.228718
global_step: 7583, epoch: 190, loss: 0.251732
global_step: 7584, epoch: 190, loss: 0.266207
global_step: 7585, epoch: 190, loss: 0.189361
global_step: 7586, epoch: 190, loss: 0.270750
global_step: 7587, epoch: 190, loss: 0.260283
global_step: 7588, epoch: 190, loss: 0.282139
global_step: 7589, epoch: 190, loss: 0.230411
global_step: 7590, epoch: 190, loss: 0.263667
global_step: 7591, epoch: 190, loss: 0.300726
global_step: 7592, epoch: 190, loss: 0.261125
global_step: 7593, epoch: 190, loss: 0.242129
global_step: 7594, epoch: 190, loss: 0.257226
global_step: 7595, epoch: 190, loss: 0.263173
global_step: 7596, epoch: 190, loss: 0.296473
global_step: 7597, epoch: 190, loss: 0.231892
global_step: 7598, epoch: 190, loss: 0.240031
global_step: 7599, epoch: 190, loss: 0.257421
global_step: 7600, epoch: 190, loss: 0.029043
epoch: 190
train	acc: 0.9598	macro: p 0.9642, r 0.9297, f1: 0.9457	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9596
dev	acc: 0.5645	macro: p 0.4358, r 0.3647, f1: 0.3800	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5324
test	acc: 0.5851	macro: p 0.3929, r 0.3383, f1: 0.3514	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5561
global_step: 7601, epoch: 191, loss: 0.235333
global_step: 7602, epoch: 191, loss: 0.171879
global_step: 7603, epoch: 191, loss: 0.221042
global_step: 7604, epoch: 191, loss: 0.240538
global_step: 7605, epoch: 191, loss: 0.332647
global_step: 7606, epoch: 191, loss: 0.207077
global_step: 7607, epoch: 191, loss: 0.267052
global_step: 7608, epoch: 191, loss: 0.176349
global_step: 7609, epoch: 191, loss: 0.167209
global_step: 7610, epoch: 191, loss: 0.252574
global_step: 7611, epoch: 191, loss: 0.295415
global_step: 7612, epoch: 191, loss: 0.289309
global_step: 7613, epoch: 191, loss: 0.216913
global_step: 7614, epoch: 191, loss: 0.233569
global_step: 7615, epoch: 191, loss: 0.325079
global_step: 7616, epoch: 191, loss: 0.279706
global_step: 7617, epoch: 191, loss: 0.241477
global_step: 7618, epoch: 191, loss: 0.316778
global_step: 7619, epoch: 191, loss: 0.184798
global_step: 7620, epoch: 191, loss: 0.293478
global_step: 7621, epoch: 191, loss: 0.318766
global_step: 7622, epoch: 191, loss: 0.201368
global_step: 7623, epoch: 191, loss: 0.233897
global_step: 7624, epoch: 191, loss: 0.219081
global_step: 7625, epoch: 191, loss: 0.297940
global_step: 7626, epoch: 191, loss: 0.290620
global_step: 7627, epoch: 191, loss: 0.229709
global_step: 7628, epoch: 191, loss: 0.270199
global_step: 7629, epoch: 191, loss: 0.187588
global_step: 7630, epoch: 191, loss: 0.265029
global_step: 7631, epoch: 191, loss: 0.297455
global_step: 7632, epoch: 191, loss: 0.239360
global_step: 7633, epoch: 191, loss: 0.260621
global_step: 7634, epoch: 191, loss: 0.267641
global_step: 7635, epoch: 191, loss: 0.286193
global_step: 7636, epoch: 191, loss: 0.212576
global_step: 7637, epoch: 191, loss: 0.294480
global_step: 7638, epoch: 191, loss: 0.270882
global_step: 7639, epoch: 191, loss: 0.256563
global_step: 7640, epoch: 191, loss: 0.685624
epoch: 191
train	acc: 0.9609	macro: p 0.9654, r 0.9335, f1: 0.9482	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9608
dev	acc: 0.5374	macro: p 0.4228, r 0.3557, f1: 0.3676	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5087
test	acc: 0.5831	macro: p 0.3979, r 0.3505, f1: 0.3619	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5608
global_step: 7641, epoch: 192, loss: 0.249123
global_step: 7642, epoch: 192, loss: 0.194274
global_step: 7643, epoch: 192, loss: 0.277667
global_step: 7644, epoch: 192, loss: 0.281080
global_step: 7645, epoch: 192, loss: 0.273115
global_step: 7646, epoch: 192, loss: 0.241195
global_step: 7647, epoch: 192, loss: 0.254360
global_step: 7648, epoch: 192, loss: 0.242093
global_step: 7649, epoch: 192, loss: 0.225086
global_step: 7650, epoch: 192, loss: 0.240505
global_step: 7651, epoch: 192, loss: 0.265734
global_step: 7652, epoch: 192, loss: 0.255622
global_step: 7653, epoch: 192, loss: 0.301686
global_step: 7654, epoch: 192, loss: 0.203154
global_step: 7655, epoch: 192, loss: 0.270941
global_step: 7656, epoch: 192, loss: 0.266959
global_step: 7657, epoch: 192, loss: 0.257591
global_step: 7658, epoch: 192, loss: 0.217973
global_step: 7659, epoch: 192, loss: 0.325628
global_step: 7660, epoch: 192, loss: 0.277692
global_step: 7661, epoch: 192, loss: 0.249060
global_step: 7662, epoch: 192, loss: 0.266337
global_step: 7663, epoch: 192, loss: 0.260912
global_step: 7664, epoch: 192, loss: 0.252906
global_step: 7665, epoch: 192, loss: 0.231956
global_step: 7666, epoch: 192, loss: 0.274722
global_step: 7667, epoch: 192, loss: 0.240498
global_step: 7668, epoch: 192, loss: 0.215393
global_step: 7669, epoch: 192, loss: 0.298873
global_step: 7670, epoch: 192, loss: 0.272368
global_step: 7671, epoch: 192, loss: 0.240394
global_step: 7672, epoch: 192, loss: 0.180724
global_step: 7673, epoch: 192, loss: 0.257871
global_step: 7674, epoch: 192, loss: 0.210152
global_step: 7675, epoch: 192, loss: 0.228693
global_step: 7676, epoch: 192, loss: 0.299210
global_step: 7677, epoch: 192, loss: 0.242436
global_step: 7678, epoch: 192, loss: 0.276708
global_step: 7679, epoch: 192, loss: 0.243597
global_step: 7680, epoch: 192, loss: 0.449538
epoch: 192
train	acc: 0.9576	macro: p 0.9637, r 0.9263, f1: 0.9436	micro: p 0.9576, r 0.9576, f1 0.9576	weighted_f1:0.9574
dev	acc: 0.5392	macro: p 0.4052, r 0.3518, f1: 0.3604	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5073
test	acc: 0.5678	macro: p 0.3838, r 0.3395, f1: 0.3459	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5422
global_step: 7681, epoch: 193, loss: 0.228942
global_step: 7682, epoch: 193, loss: 0.249490
global_step: 7683, epoch: 193, loss: 0.237900
global_step: 7684, epoch: 193, loss: 0.242204
global_step: 7685, epoch: 193, loss: 0.217887
global_step: 7686, epoch: 193, loss: 0.250879
global_step: 7687, epoch: 193, loss: 0.249432
global_step: 7688, epoch: 193, loss: 0.209487
global_step: 7689, epoch: 193, loss: 0.205862
global_step: 7690, epoch: 193, loss: 0.248809
global_step: 7691, epoch: 193, loss: 0.246401
global_step: 7692, epoch: 193, loss: 0.251776
global_step: 7693, epoch: 193, loss: 0.349207
global_step: 7694, epoch: 193, loss: 0.252602
global_step: 7695, epoch: 193, loss: 0.276709
global_step: 7696, epoch: 193, loss: 0.183266
global_step: 7697, epoch: 193, loss: 0.202821
global_step: 7698, epoch: 193, loss: 0.284141
global_step: 7699, epoch: 193, loss: 0.246152
global_step: 7700, epoch: 193, loss: 0.295162
global_step: 7701, epoch: 193, loss: 0.287598
global_step: 7702, epoch: 193, loss: 0.227430
global_step: 7703, epoch: 193, loss: 0.277549
global_step: 7704, epoch: 193, loss: 0.246895
global_step: 7705, epoch: 193, loss: 0.248993
global_step: 7706, epoch: 193, loss: 0.247745
global_step: 7707, epoch: 193, loss: 0.331076
global_step: 7708, epoch: 193, loss: 0.234924
global_step: 7709, epoch: 193, loss: 0.220479
global_step: 7710, epoch: 193, loss: 0.260297
global_step: 7711, epoch: 193, loss: 0.185663
global_step: 7712, epoch: 193, loss: 0.299035
global_step: 7713, epoch: 193, loss: 0.256509
global_step: 7714, epoch: 193, loss: 0.274495
global_step: 7715, epoch: 193, loss: 0.287994
global_step: 7716, epoch: 193, loss: 0.197076
global_step: 7717, epoch: 193, loss: 0.176885
global_step: 7718, epoch: 193, loss: 0.216096
global_step: 7719, epoch: 193, loss: 0.215542
global_step: 7720, epoch: 193, loss: 0.298559
epoch: 193
train	acc: 0.9569	macro: p 0.9657, r 0.9205, f1: 0.9414	micro: p 0.9569, r 0.9569, f1 0.9569	weighted_f1:0.9565
dev	acc: 0.5537	macro: p 0.4313, r 0.3274, f1: 0.3403	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5073
test	acc: 0.5900	macro: p 0.4272, r 0.3223, f1: 0.3394	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5486
global_step: 7721, epoch: 194, loss: 0.283446
global_step: 7722, epoch: 194, loss: 0.236005
global_step: 7723, epoch: 194, loss: 0.240083
global_step: 7724, epoch: 194, loss: 0.297763
global_step: 7725, epoch: 194, loss: 0.300346
global_step: 7726, epoch: 194, loss: 0.293839
global_step: 7727, epoch: 194, loss: 0.258867
global_step: 7728, epoch: 194, loss: 0.240423
global_step: 7729, epoch: 194, loss: 0.193071
global_step: 7730, epoch: 194, loss: 0.257952
global_step: 7731, epoch: 194, loss: 0.165561
global_step: 7732, epoch: 194, loss: 0.313367
global_step: 7733, epoch: 194, loss: 0.277170
global_step: 7734, epoch: 194, loss: 0.211902
global_step: 7735, epoch: 194, loss: 0.223071
global_step: 7736, epoch: 194, loss: 0.266737
global_step: 7737, epoch: 194, loss: 0.318962
global_step: 7738, epoch: 194, loss: 0.241577
global_step: 7739, epoch: 194, loss: 0.206748
global_step: 7740, epoch: 194, loss: 0.276764
global_step: 7741, epoch: 194, loss: 0.328520
global_step: 7742, epoch: 194, loss: 0.186967
global_step: 7743, epoch: 194, loss: 0.273831
global_step: 7744, epoch: 194, loss: 0.271227
global_step: 7745, epoch: 194, loss: 0.270876
global_step: 7746, epoch: 194, loss: 0.245689
global_step: 7747, epoch: 194, loss: 0.231328
global_step: 7748, epoch: 194, loss: 0.214270
global_step: 7749, epoch: 194, loss: 0.307683
global_step: 7750, epoch: 194, loss: 0.213030
global_step: 7751, epoch: 194, loss: 0.200079
global_step: 7752, epoch: 194, loss: 0.251260
global_step: 7753, epoch: 194, loss: 0.211501
global_step: 7754, epoch: 194, loss: 0.270381
global_step: 7755, epoch: 194, loss: 0.212322
global_step: 7756, epoch: 194, loss: 0.242987
global_step: 7757, epoch: 194, loss: 0.271104
global_step: 7758, epoch: 194, loss: 0.251107
global_step: 7759, epoch: 194, loss: 0.199846
global_step: 7760, epoch: 194, loss: 0.654385
epoch: 194
train	acc: 0.9625	macro: p 0.9678, r 0.9353, f1: 0.9504	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9624
dev	acc: 0.5464	macro: p 0.4203, r 0.3596, f1: 0.3699	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5158
test	acc: 0.5812	macro: p 0.3888, r 0.3417, f1: 0.3532	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5552
global_step: 7761, epoch: 195, loss: 0.254373
global_step: 7762, epoch: 195, loss: 0.269259
global_step: 7763, epoch: 195, loss: 0.222497
global_step: 7764, epoch: 195, loss: 0.241126
global_step: 7765, epoch: 195, loss: 0.198664
global_step: 7766, epoch: 195, loss: 0.273820
global_step: 7767, epoch: 195, loss: 0.251833
global_step: 7768, epoch: 195, loss: 0.177340
global_step: 7769, epoch: 195, loss: 0.421143
global_step: 7770, epoch: 195, loss: 0.314643
global_step: 7771, epoch: 195, loss: 0.188876
global_step: 7772, epoch: 195, loss: 0.222179
global_step: 7773, epoch: 195, loss: 0.249814
global_step: 7774, epoch: 195, loss: 0.379953
global_step: 7775, epoch: 195, loss: 0.307169
global_step: 7776, epoch: 195, loss: 0.217319
global_step: 7777, epoch: 195, loss: 0.213744
global_step: 7778, epoch: 195, loss: 0.243366
global_step: 7779, epoch: 195, loss: 0.278040
global_step: 7780, epoch: 195, loss: 0.167998
global_step: 7781, epoch: 195, loss: 0.236487
global_step: 7782, epoch: 195, loss: 0.265818
global_step: 7783, epoch: 195, loss: 0.216807
global_step: 7784, epoch: 195, loss: 0.264961
global_step: 7785, epoch: 195, loss: 0.243945
global_step: 7786, epoch: 195, loss: 0.277985
global_step: 7787, epoch: 195, loss: 0.214783
global_step: 7788, epoch: 195, loss: 0.294327
global_step: 7789, epoch: 195, loss: 0.181798
global_step: 7790, epoch: 195, loss: 0.273690
global_step: 7791, epoch: 195, loss: 0.227442
global_step: 7792, epoch: 195, loss: 0.199373
global_step: 7793, epoch: 195, loss: 0.276106
global_step: 7794, epoch: 195, loss: 0.223597
global_step: 7795, epoch: 195, loss: 0.348609
global_step: 7796, epoch: 195, loss: 0.299932
global_step: 7797, epoch: 195, loss: 0.247192
global_step: 7798, epoch: 195, loss: 0.238606
global_step: 7799, epoch: 195, loss: 0.268336
global_step: 7800, epoch: 195, loss: 0.360123
epoch: 195
train	acc: 0.9627	macro: p 0.9662, r 0.9341, f1: 0.9489	micro: p 0.9627, r 0.9627, f1 0.9627	weighted_f1:0.9626
dev	acc: 0.5383	macro: p 0.4030, r 0.3585, f1: 0.3587	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5109
test	acc: 0.5778	macro: p 0.3812, r 0.3544, f1: 0.3593	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5582
global_step: 7801, epoch: 196, loss: 0.246092
global_step: 7802, epoch: 196, loss: 0.236013
global_step: 7803, epoch: 196, loss: 0.225846
global_step: 7804, epoch: 196, loss: 0.210550
global_step: 7805, epoch: 196, loss: 0.272515
global_step: 7806, epoch: 196, loss: 0.257449
global_step: 7807, epoch: 196, loss: 0.239001
global_step: 7808, epoch: 196, loss: 0.233845
global_step: 7809, epoch: 196, loss: 0.222451
global_step: 7810, epoch: 196, loss: 0.185771
global_step: 7811, epoch: 196, loss: 0.264492
global_step: 7812, epoch: 196, loss: 0.219748
global_step: 7813, epoch: 196, loss: 0.244925
global_step: 7814, epoch: 196, loss: 0.200330
global_step: 7815, epoch: 196, loss: 0.275602
global_step: 7816, epoch: 196, loss: 0.279782
global_step: 7817, epoch: 196, loss: 0.261341
global_step: 7818, epoch: 196, loss: 0.302746
global_step: 7819, epoch: 196, loss: 0.303499
global_step: 7820, epoch: 196, loss: 0.260994
global_step: 7821, epoch: 196, loss: 0.310978
global_step: 7822, epoch: 196, loss: 0.281850
global_step: 7823, epoch: 196, loss: 0.271329
global_step: 7824, epoch: 196, loss: 0.212454
global_step: 7825, epoch: 196, loss: 0.241881
global_step: 7826, epoch: 196, loss: 0.226862
global_step: 7827, epoch: 196, loss: 0.263564
global_step: 7828, epoch: 196, loss: 0.293149
global_step: 7829, epoch: 196, loss: 0.223706
global_step: 7830, epoch: 196, loss: 0.259348
global_step: 7831, epoch: 196, loss: 0.209424
global_step: 7832, epoch: 196, loss: 0.254920
global_step: 7833, epoch: 196, loss: 0.215477
global_step: 7834, epoch: 196, loss: 0.249434
global_step: 7835, epoch: 196, loss: 0.222030
global_step: 7836, epoch: 196, loss: 0.310910
global_step: 7837, epoch: 196, loss: 0.235985
global_step: 7838, epoch: 196, loss: 0.239334
global_step: 7839, epoch: 196, loss: 0.285687
global_step: 7840, epoch: 196, loss: 0.455912
epoch: 196
train	acc: 0.9626	macro: p 0.9671, r 0.9353, f1: 0.9500	micro: p 0.9626, r 0.9626, f1 0.9626	weighted_f1:0.9625
dev	acc: 0.5582	macro: p 0.4346, r 0.3635, f1: 0.3682	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5247
test	acc: 0.5778	macro: p 0.3690, r 0.3365, f1: 0.3389	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5511
global_step: 7841, epoch: 197, loss: 0.244514
global_step: 7842, epoch: 197, loss: 0.293241
global_step: 7843, epoch: 197, loss: 0.315419
global_step: 7844, epoch: 197, loss: 0.225867
global_step: 7845, epoch: 197, loss: 0.235776
global_step: 7846, epoch: 197, loss: 0.252293
global_step: 7847, epoch: 197, loss: 0.240226
global_step: 7848, epoch: 197, loss: 0.254522
global_step: 7849, epoch: 197, loss: 0.226166
global_step: 7850, epoch: 197, loss: 0.226627
global_step: 7851, epoch: 197, loss: 0.214907
global_step: 7852, epoch: 197, loss: 0.212212
global_step: 7853, epoch: 197, loss: 0.168803
global_step: 7854, epoch: 197, loss: 0.264398
global_step: 7855, epoch: 197, loss: 0.194533
global_step: 7856, epoch: 197, loss: 0.305716
global_step: 7857, epoch: 197, loss: 0.260761
global_step: 7858, epoch: 197, loss: 0.250628
global_step: 7859, epoch: 197, loss: 0.249187
global_step: 7860, epoch: 197, loss: 0.249739
global_step: 7861, epoch: 197, loss: 0.236569
global_step: 7862, epoch: 197, loss: 0.256637
global_step: 7863, epoch: 197, loss: 0.236460
global_step: 7864, epoch: 197, loss: 0.248815
global_step: 7865, epoch: 197, loss: 0.251809
global_step: 7866, epoch: 197, loss: 0.242152
global_step: 7867, epoch: 197, loss: 0.145503
global_step: 7868, epoch: 197, loss: 0.167478
global_step: 7869, epoch: 197, loss: 0.256476
global_step: 7870, epoch: 197, loss: 0.235454
global_step: 7871, epoch: 197, loss: 0.276851
global_step: 7872, epoch: 197, loss: 0.246325
global_step: 7873, epoch: 197, loss: 0.269336
global_step: 7874, epoch: 197, loss: 0.299405
global_step: 7875, epoch: 197, loss: 0.207244
global_step: 7876, epoch: 197, loss: 0.197064
global_step: 7877, epoch: 197, loss: 0.338743
global_step: 7878, epoch: 197, loss: 0.267576
global_step: 7879, epoch: 197, loss: 0.260249
global_step: 7880, epoch: 197, loss: 0.003870
epoch: 197
train	acc: 0.9643	macro: p 0.9697, r 0.9390, f1: 0.9533	micro: p 0.9643, r 0.9643, f1 0.9643	weighted_f1:0.9642
dev	acc: 0.5482	macro: p 0.4155, r 0.3577, f1: 0.3652	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5154
test	acc: 0.5805	macro: p 0.3767, r 0.3356, f1: 0.3441	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5518
global_step: 7881, epoch: 198, loss: 0.260913
global_step: 7882, epoch: 198, loss: 0.301523
global_step: 7883, epoch: 198, loss: 0.270241
global_step: 7884, epoch: 198, loss: 0.203437
global_step: 7885, epoch: 198, loss: 0.204206
global_step: 7886, epoch: 198, loss: 0.251941
global_step: 7887, epoch: 198, loss: 0.221316
global_step: 7888, epoch: 198, loss: 0.184200
global_step: 7889, epoch: 198, loss: 0.216552
global_step: 7890, epoch: 198, loss: 0.201538
global_step: 7891, epoch: 198, loss: 0.243067
global_step: 7892, epoch: 198, loss: 0.283555
global_step: 7893, epoch: 198, loss: 0.255752
global_step: 7894, epoch: 198, loss: 0.225266
global_step: 7895, epoch: 198, loss: 0.255093
global_step: 7896, epoch: 198, loss: 0.209439
global_step: 7897, epoch: 198, loss: 0.219531
global_step: 7898, epoch: 198, loss: 0.232942
global_step: 7899, epoch: 198, loss: 0.206775
global_step: 7900, epoch: 198, loss: 0.199296
global_step: 7901, epoch: 198, loss: 0.235450
global_step: 7902, epoch: 198, loss: 0.210359
global_step: 7903, epoch: 198, loss: 0.232353
global_step: 7904, epoch: 198, loss: 0.243097
global_step: 7905, epoch: 198, loss: 0.243604
global_step: 7906, epoch: 198, loss: 0.226733
global_step: 7907, epoch: 198, loss: 0.210580
global_step: 7908, epoch: 198, loss: 0.252508
global_step: 7909, epoch: 198, loss: 0.274216
global_step: 7910, epoch: 198, loss: 0.262002
global_step: 7911, epoch: 198, loss: 0.244997
global_step: 7912, epoch: 198, loss: 0.264954
global_step: 7913, epoch: 198, loss: 0.256083
global_step: 7914, epoch: 198, loss: 0.245065
global_step: 7915, epoch: 198, loss: 0.254934
global_step: 7916, epoch: 198, loss: 0.254980
global_step: 7917, epoch: 198, loss: 0.326709
global_step: 7918, epoch: 198, loss: 0.241183
global_step: 7919, epoch: 198, loss: 0.316657
global_step: 7920, epoch: 198, loss: 0.185821
epoch: 198
train	acc: 0.9636	macro: p 0.9701, r 0.9375, f1: 0.9527	micro: p 0.9636, r 0.9636, f1 0.9636	weighted_f1:0.9635
dev	acc: 0.5392	macro: p 0.4092, r 0.3525, f1: 0.3581	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5065
test	acc: 0.5816	macro: p 0.3921, r 0.3449, f1: 0.3517	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5545
global_step: 7921, epoch: 199, loss: 0.252691
global_step: 7922, epoch: 199, loss: 0.232972
global_step: 7923, epoch: 199, loss: 0.221182
global_step: 7924, epoch: 199, loss: 0.223853
global_step: 7925, epoch: 199, loss: 0.206778
global_step: 7926, epoch: 199, loss: 0.208099
global_step: 7927, epoch: 199, loss: 0.213746
global_step: 7928, epoch: 199, loss: 0.261553
global_step: 7929, epoch: 199, loss: 0.279993
global_step: 7930, epoch: 199, loss: 0.217223
global_step: 7931, epoch: 199, loss: 0.236143
global_step: 7932, epoch: 199, loss: 0.287695
global_step: 7933, epoch: 199, loss: 0.202470
global_step: 7934, epoch: 199, loss: 0.253630
global_step: 7935, epoch: 199, loss: 0.217203
global_step: 7936, epoch: 199, loss: 0.241403
global_step: 7937, epoch: 199, loss: 0.248245
global_step: 7938, epoch: 199, loss: 0.196489
global_step: 7939, epoch: 199, loss: 0.288450
global_step: 7940, epoch: 199, loss: 0.251156
global_step: 7941, epoch: 199, loss: 0.299811
global_step: 7942, epoch: 199, loss: 0.278154
global_step: 7943, epoch: 199, loss: 0.162851
global_step: 7944, epoch: 199, loss: 0.218314
global_step: 7945, epoch: 199, loss: 0.259635
global_step: 7946, epoch: 199, loss: 0.284636
global_step: 7947, epoch: 199, loss: 0.240324
global_step: 7948, epoch: 199, loss: 0.202227
global_step: 7949, epoch: 199, loss: 0.274570
global_step: 7950, epoch: 199, loss: 0.275493
global_step: 7951, epoch: 199, loss: 0.244912
global_step: 7952, epoch: 199, loss: 0.189920
global_step: 7953, epoch: 199, loss: 0.284901
global_step: 7954, epoch: 199, loss: 0.193184
global_step: 7955, epoch: 199, loss: 0.238282
global_step: 7956, epoch: 199, loss: 0.315798
global_step: 7957, epoch: 199, loss: 0.203521
global_step: 7958, epoch: 199, loss: 0.280211
global_step: 7959, epoch: 199, loss: 0.226194
global_step: 7960, epoch: 199, loss: 0.268386
epoch: 199
train	acc: 0.9612	macro: p 0.9689, r 0.9339, f1: 0.9503	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9610
dev	acc: 0.5518	macro: p 0.4192, r 0.3558, f1: 0.3642	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5169
test	acc: 0.5935	macro: p 0.3977, r 0.3419, f1: 0.3541	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5620
global_step: 7961, epoch: 200, loss: 0.221197
global_step: 7962, epoch: 200, loss: 0.234211
global_step: 7963, epoch: 200, loss: 0.238717
global_step: 7964, epoch: 200, loss: 0.245678
global_step: 7965, epoch: 200, loss: 0.216626
global_step: 7966, epoch: 200, loss: 0.225087
global_step: 7967, epoch: 200, loss: 0.232199
global_step: 7968, epoch: 200, loss: 0.239044
global_step: 7969, epoch: 200, loss: 0.237569
global_step: 7970, epoch: 200, loss: 0.219233
global_step: 7971, epoch: 200, loss: 0.260485
global_step: 7972, epoch: 200, loss: 0.288158
global_step: 7973, epoch: 200, loss: 0.264181
global_step: 7974, epoch: 200, loss: 0.231722
global_step: 7975, epoch: 200, loss: 0.236141
global_step: 7976, epoch: 200, loss: 0.256236
global_step: 7977, epoch: 200, loss: 0.227694
global_step: 7978, epoch: 200, loss: 0.190824
global_step: 7979, epoch: 200, loss: 0.257112
global_step: 7980, epoch: 200, loss: 0.202201
global_step: 7981, epoch: 200, loss: 0.255867
global_step: 7982, epoch: 200, loss: 0.187383
global_step: 7983, epoch: 200, loss: 0.248705
global_step: 7984, epoch: 200, loss: 0.253020
global_step: 7985, epoch: 200, loss: 0.189396
global_step: 7986, epoch: 200, loss: 0.224904
global_step: 7987, epoch: 200, loss: 0.280337
global_step: 7988, epoch: 200, loss: 0.215067
global_step: 7989, epoch: 200, loss: 0.279563
global_step: 7990, epoch: 200, loss: 0.236956
global_step: 7991, epoch: 200, loss: 0.233686
global_step: 7992, epoch: 200, loss: 0.347888
global_step: 7993, epoch: 200, loss: 0.263940
global_step: 7994, epoch: 200, loss: 0.248112
global_step: 7995, epoch: 200, loss: 0.219385
global_step: 7996, epoch: 200, loss: 0.264494
global_step: 7997, epoch: 200, loss: 0.209954
global_step: 7998, epoch: 200, loss: 0.223297
global_step: 7999, epoch: 200, loss: 0.262153
global_step: 8000, epoch: 200, loss: 0.013439
epoch: 200
train	acc: 0.9630	macro: p 0.9703, r 0.9352, f1: 0.9516	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9628
dev	acc: 0.5500	macro: p 0.4396, r 0.3561, f1: 0.3684	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5138
test	acc: 0.5954	macro: p 0.4106, r 0.3394, f1: 0.3511	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5610
BEST MODEL epoch: 59
train	acc: 0.7648 macro_p: 0.5039 macro_r: 0.4924 macro_f1: 0.4928 micro_p: 0.7648 micro_r: 0.7648 micro_f1: 0.7648 weighted_f1: 0.7352
dev	acc: 0.5915 macro_p: 0.3791 macro_r: 0.3530 macro_f1: 0.3516 micro_p: 0.5915 micro_r: 0.5915 micro_f1: 0.5915 weighted_f1: 0.5467
test	acc: 0.6115 macro_p: 0.3629 macro_r: 0.3418 macro_f1: 0.3414 micro_p: 0.6115 micro_r: 0.6115 micro_f1: 0.6115 weighted_f1: 0.5747
==========ROUND 2==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 8001, epoch: 1, loss: 1.966953
global_step: 8002, epoch: 1, loss: 1.950186
global_step: 8003, epoch: 1, loss: 1.934688
global_step: 8004, epoch: 1, loss: 1.935801
global_step: 8005, epoch: 1, loss: 1.915838
global_step: 8006, epoch: 1, loss: 1.924395
global_step: 8007, epoch: 1, loss: 1.894503
global_step: 8008, epoch: 1, loss: 1.874030
global_step: 8009, epoch: 1, loss: 1.848891
global_step: 8010, epoch: 1, loss: 1.868614
global_step: 8011, epoch: 1, loss: 1.854080
global_step: 8012, epoch: 1, loss: 1.801870
global_step: 8013, epoch: 1, loss: 1.824803
global_step: 8014, epoch: 1, loss: 1.782125
global_step: 8015, epoch: 1, loss: 1.787919
global_step: 8016, epoch: 1, loss: 1.774486
global_step: 8017, epoch: 1, loss: 1.727190
global_step: 8018, epoch: 1, loss: 1.706539
global_step: 8019, epoch: 1, loss: 1.757679
global_step: 8020, epoch: 1, loss: 1.676502
global_step: 8021, epoch: 1, loss: 1.715496
global_step: 8022, epoch: 1, loss: 1.694012
global_step: 8023, epoch: 1, loss: 1.666699
global_step: 8024, epoch: 1, loss: 1.657736
global_step: 8025, epoch: 1, loss: 1.608504
global_step: 8026, epoch: 1, loss: 1.656525
global_step: 8027, epoch: 1, loss: 1.672132
global_step: 8028, epoch: 1, loss: 1.612487
global_step: 8029, epoch: 1, loss: 1.626351
global_step: 8030, epoch: 1, loss: 1.582829
global_step: 8031, epoch: 1, loss: 1.585577
global_step: 8032, epoch: 1, loss: 1.592949
global_step: 8033, epoch: 1, loss: 1.648141
global_step: 8034, epoch: 1, loss: 1.654627
global_step: 8035, epoch: 1, loss: 1.581233
global_step: 8036, epoch: 1, loss: 1.570225
global_step: 8037, epoch: 1, loss: 1.596634
global_step: 8038, epoch: 1, loss: 1.605105
global_step: 8039, epoch: 1, loss: 1.474679
global_step: 8040, epoch: 1, loss: 1.490045
epoch: 1
train	acc: 0.4706	macro: p 0.0775, r 0.1427, f1: 0.0917	micro: p 0.4706, r 0.4706, f1 0.4706	weighted_f1:0.3020
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
New best model!
global_step: 8041, epoch: 2, loss: 1.685801
global_step: 8042, epoch: 2, loss: 1.605268
global_step: 8043, epoch: 2, loss: 1.568780
global_step: 8044, epoch: 2, loss: 1.578505
global_step: 8045, epoch: 2, loss: 1.523472
global_step: 8046, epoch: 2, loss: 1.556035
global_step: 8047, epoch: 2, loss: 1.612879
global_step: 8048, epoch: 2, loss: 1.610223
global_step: 8049, epoch: 2, loss: 1.537742
global_step: 8050, epoch: 2, loss: 1.540479
global_step: 8051, epoch: 2, loss: 1.588386
global_step: 8052, epoch: 2, loss: 1.516425
global_step: 8053, epoch: 2, loss: 1.483795
global_step: 8054, epoch: 2, loss: 1.574875
global_step: 8055, epoch: 2, loss: 1.568692
global_step: 8056, epoch: 2, loss: 1.551932
global_step: 8057, epoch: 2, loss: 1.598292
global_step: 8058, epoch: 2, loss: 1.564684
global_step: 8059, epoch: 2, loss: 1.539418
global_step: 8060, epoch: 2, loss: 1.630975
global_step: 8061, epoch: 2, loss: 1.556579
global_step: 8062, epoch: 2, loss: 1.576807
global_step: 8063, epoch: 2, loss: 1.532323
global_step: 8064, epoch: 2, loss: 1.542538
global_step: 8065, epoch: 2, loss: 1.586691
global_step: 8066, epoch: 2, loss: 1.543241
global_step: 8067, epoch: 2, loss: 1.539207
global_step: 8068, epoch: 2, loss: 1.545808
global_step: 8069, epoch: 2, loss: 1.487718
global_step: 8070, epoch: 2, loss: 1.591963
global_step: 8071, epoch: 2, loss: 1.504866
global_step: 8072, epoch: 2, loss: 1.446966
global_step: 8073, epoch: 2, loss: 1.480740
global_step: 8074, epoch: 2, loss: 1.548256
global_step: 8075, epoch: 2, loss: 1.569535
global_step: 8076, epoch: 2, loss: 1.627331
global_step: 8077, epoch: 2, loss: 1.466133
global_step: 8078, epoch: 2, loss: 1.506804
global_step: 8079, epoch: 2, loss: 1.539838
global_step: 8080, epoch: 2, loss: 0.986097
epoch: 2
train	acc: 0.4715	macro: p 0.0674, r 0.1429, f1: 0.0916	micro: p 0.4715, r 0.4715, f1 0.4715	weighted_f1:0.3022
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
global_step: 8081, epoch: 3, loss: 1.649423
global_step: 8082, epoch: 3, loss: 1.500640
global_step: 8083, epoch: 3, loss: 1.520669
global_step: 8084, epoch: 3, loss: 1.483116
global_step: 8085, epoch: 3, loss: 1.479800
global_step: 8086, epoch: 3, loss: 1.589463
global_step: 8087, epoch: 3, loss: 1.521124
global_step: 8088, epoch: 3, loss: 1.475035
global_step: 8089, epoch: 3, loss: 1.512559
global_step: 8090, epoch: 3, loss: 1.523553
global_step: 8091, epoch: 3, loss: 1.457194
global_step: 8092, epoch: 3, loss: 1.648618
global_step: 8093, epoch: 3, loss: 1.439095
global_step: 8094, epoch: 3, loss: 1.542520
global_step: 8095, epoch: 3, loss: 1.568117
global_step: 8096, epoch: 3, loss: 1.492906
global_step: 8097, epoch: 3, loss: 1.399335
global_step: 8098, epoch: 3, loss: 1.513033
global_step: 8099, epoch: 3, loss: 1.599021
global_step: 8100, epoch: 3, loss: 1.559209
global_step: 8101, epoch: 3, loss: 1.519461
global_step: 8102, epoch: 3, loss: 1.569528
global_step: 8103, epoch: 3, loss: 1.506119
global_step: 8104, epoch: 3, loss: 1.392712
global_step: 8105, epoch: 3, loss: 1.465318
global_step: 8106, epoch: 3, loss: 1.435985
global_step: 8107, epoch: 3, loss: 1.527877
global_step: 8108, epoch: 3, loss: 1.376836
global_step: 8109, epoch: 3, loss: 1.523214
global_step: 8110, epoch: 3, loss: 1.559911
global_step: 8111, epoch: 3, loss: 1.480738
global_step: 8112, epoch: 3, loss: 1.569520
global_step: 8113, epoch: 3, loss: 1.485200
global_step: 8114, epoch: 3, loss: 1.498626
global_step: 8115, epoch: 3, loss: 1.364563
global_step: 8116, epoch: 3, loss: 1.497447
global_step: 8117, epoch: 3, loss: 1.493061
global_step: 8118, epoch: 3, loss: 1.562375
global_step: 8119, epoch: 3, loss: 1.332351
global_step: 8120, epoch: 3, loss: 0.931963
epoch: 3
train	acc: 0.4764	macro: p 0.1297, r 0.1472, f1: 0.1008	micro: p 0.4764, r 0.4764, f1 0.4764	weighted_f1:0.3149
dev	acc: 0.4310	macro: p 0.1113, r 0.1504, f1: 0.0999	micro: p 0.4310, r 0.4310, f1 0.4310	weighted_f1:0.2700
test	acc: 0.4847	macro: p 0.1236, r 0.1465, f1: 0.1007	micro: p 0.4847, r 0.4847, f1 0.4847	weighted_f1:0.3224
New best model!
global_step: 8121, epoch: 4, loss: 1.448355
global_step: 8122, epoch: 4, loss: 1.472674
global_step: 8123, epoch: 4, loss: 1.440574
global_step: 8124, epoch: 4, loss: 1.359074
global_step: 8125, epoch: 4, loss: 1.514828
global_step: 8126, epoch: 4, loss: 1.504391
global_step: 8127, epoch: 4, loss: 1.468221
global_step: 8128, epoch: 4, loss: 1.437837
global_step: 8129, epoch: 4, loss: 1.472011
global_step: 8130, epoch: 4, loss: 1.439185
global_step: 8131, epoch: 4, loss: 1.531160
global_step: 8132, epoch: 4, loss: 1.456231
global_step: 8133, epoch: 4, loss: 1.349984
global_step: 8134, epoch: 4, loss: 1.438549
global_step: 8135, epoch: 4, loss: 1.365831
global_step: 8136, epoch: 4, loss: 1.554929
global_step: 8137, epoch: 4, loss: 1.454424
global_step: 8138, epoch: 4, loss: 1.523773
global_step: 8139, epoch: 4, loss: 1.498237
global_step: 8140, epoch: 4, loss: 1.376019
global_step: 8141, epoch: 4, loss: 1.463174
global_step: 8142, epoch: 4, loss: 1.424961
global_step: 8143, epoch: 4, loss: 1.481828
global_step: 8144, epoch: 4, loss: 1.417367
global_step: 8145, epoch: 4, loss: 1.472478
global_step: 8146, epoch: 4, loss: 1.371848
global_step: 8147, epoch: 4, loss: 1.424600
global_step: 8148, epoch: 4, loss: 1.438124
global_step: 8149, epoch: 4, loss: 1.459706
global_step: 8150, epoch: 4, loss: 1.366439
global_step: 8151, epoch: 4, loss: 1.489131
global_step: 8152, epoch: 4, loss: 1.535851
global_step: 8153, epoch: 4, loss: 1.424950
global_step: 8154, epoch: 4, loss: 1.458272
global_step: 8155, epoch: 4, loss: 1.434804
global_step: 8156, epoch: 4, loss: 1.365670
global_step: 8157, epoch: 4, loss: 1.450485
global_step: 8158, epoch: 4, loss: 1.385161
global_step: 8159, epoch: 4, loss: 1.356828
global_step: 8160, epoch: 4, loss: 1.388639
epoch: 4
train	acc: 0.5300	macro: p 0.1331, r 0.1986, f1: 0.1583	micro: p 0.5300, r 0.5300, f1 0.5300	weighted_f1:0.4077
dev	acc: 0.4689	macro: p 0.1136, r 0.1958, f1: 0.1435	micro: p 0.4689, r 0.4689, f1 0.4689	weighted_f1:0.3359
test	acc: 0.5352	macro: p 0.1305, r 0.2017, f1: 0.1582	micro: p 0.5352, r 0.5352, f1 0.5352	weighted_f1:0.4114
New best model!
global_step: 8161, epoch: 5, loss: 1.379486
global_step: 8162, epoch: 5, loss: 1.326828
global_step: 8163, epoch: 5, loss: 1.339249
global_step: 8164, epoch: 5, loss: 1.423715
global_step: 8165, epoch: 5, loss: 1.407327
global_step: 8166, epoch: 5, loss: 1.410857
global_step: 8167, epoch: 5, loss: 1.425663
global_step: 8168, epoch: 5, loss: 1.516725
global_step: 8169, epoch: 5, loss: 1.392441
global_step: 8170, epoch: 5, loss: 1.448436
global_step: 8171, epoch: 5, loss: 1.431602
global_step: 8172, epoch: 5, loss: 1.368113
global_step: 8173, epoch: 5, loss: 1.266647
global_step: 8174, epoch: 5, loss: 1.352928
global_step: 8175, epoch: 5, loss: 1.369876
global_step: 8176, epoch: 5, loss: 1.363870
global_step: 8177, epoch: 5, loss: 1.269394
global_step: 8178, epoch: 5, loss: 1.446636
global_step: 8179, epoch: 5, loss: 1.421968
global_step: 8180, epoch: 5, loss: 1.501036
global_step: 8181, epoch: 5, loss: 1.456913
global_step: 8182, epoch: 5, loss: 1.414080
global_step: 8183, epoch: 5, loss: 1.408910
global_step: 8184, epoch: 5, loss: 1.400706
global_step: 8185, epoch: 5, loss: 1.317952
global_step: 8186, epoch: 5, loss: 1.401983
global_step: 8187, epoch: 5, loss: 1.414801
global_step: 8188, epoch: 5, loss: 1.477248
global_step: 8189, epoch: 5, loss: 1.370590
global_step: 8190, epoch: 5, loss: 1.412184
global_step: 8191, epoch: 5, loss: 1.418146
global_step: 8192, epoch: 5, loss: 1.438527
global_step: 8193, epoch: 5, loss: 1.443704
global_step: 8194, epoch: 5, loss: 1.353447
global_step: 8195, epoch: 5, loss: 1.457460
global_step: 8196, epoch: 5, loss: 1.481958
global_step: 8197, epoch: 5, loss: 1.279806
global_step: 8198, epoch: 5, loss: 1.429758
global_step: 8199, epoch: 5, loss: 1.519407
global_step: 8200, epoch: 5, loss: 1.259185
epoch: 5
train	acc: 0.5388	macro: p 0.2791, r 0.2114, f1: 0.1667	micro: p 0.5388, r 0.5388, f1 0.5388	weighted_f1:0.4239
dev	acc: 0.4842	macro: p 0.4064, r 0.2155, f1: 0.1578	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.3585
test	acc: 0.5471	macro: p 0.3506, r 0.2200, f1: 0.1709	micro: p 0.5471, r 0.5471, f1 0.5471	weighted_f1:0.4326
New best model!
global_step: 8201, epoch: 6, loss: 1.361409
global_step: 8202, epoch: 6, loss: 1.449826
global_step: 8203, epoch: 6, loss: 1.418228
global_step: 8204, epoch: 6, loss: 1.390722
global_step: 8205, epoch: 6, loss: 1.349090
global_step: 8206, epoch: 6, loss: 1.397905
global_step: 8207, epoch: 6, loss: 1.448307
global_step: 8208, epoch: 6, loss: 1.487569
global_step: 8209, epoch: 6, loss: 1.288835
global_step: 8210, epoch: 6, loss: 1.388011
global_step: 8211, epoch: 6, loss: 1.450307
global_step: 8212, epoch: 6, loss: 1.431955
global_step: 8213, epoch: 6, loss: 1.343656
global_step: 8214, epoch: 6, loss: 1.316827
global_step: 8215, epoch: 6, loss: 1.439690
global_step: 8216, epoch: 6, loss: 1.355141
global_step: 8217, epoch: 6, loss: 1.433668
global_step: 8218, epoch: 6, loss: 1.478185
global_step: 8219, epoch: 6, loss: 1.379706
global_step: 8220, epoch: 6, loss: 1.341197
global_step: 8221, epoch: 6, loss: 1.341723
global_step: 8222, epoch: 6, loss: 1.321680
global_step: 8223, epoch: 6, loss: 1.395744
global_step: 8224, epoch: 6, loss: 1.325687
global_step: 8225, epoch: 6, loss: 1.417104
global_step: 8226, epoch: 6, loss: 1.370768
global_step: 8227, epoch: 6, loss: 1.356351
global_step: 8228, epoch: 6, loss: 1.329024
global_step: 8229, epoch: 6, loss: 1.339767
global_step: 8230, epoch: 6, loss: 1.366026
global_step: 8231, epoch: 6, loss: 1.305515
global_step: 8232, epoch: 6, loss: 1.231628
global_step: 8233, epoch: 6, loss: 1.478785
global_step: 8234, epoch: 6, loss: 1.361690
global_step: 8235, epoch: 6, loss: 1.299039
global_step: 8236, epoch: 6, loss: 1.358053
global_step: 8237, epoch: 6, loss: 1.343866
global_step: 8238, epoch: 6, loss: 1.454379
global_step: 8239, epoch: 6, loss: 1.348248
global_step: 8240, epoch: 6, loss: 2.113821
epoch: 6
train	acc: 0.5490	macro: p 0.2564, r 0.2251, f1: 0.1848	micro: p 0.5490, r 0.5490, f1 0.5490	weighted_f1:0.4431
dev	acc: 0.5032	macro: p 0.2688, r 0.2354, f1: 0.1846	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.3878
test	acc: 0.5552	macro: p 0.4083, r 0.2348, f1: 0.1927	micro: p 0.5552, r 0.5552, f1 0.5552	weighted_f1:0.4510
New best model!
global_step: 8241, epoch: 7, loss: 1.330014
global_step: 8242, epoch: 7, loss: 1.472887
global_step: 8243, epoch: 7, loss: 1.370543
global_step: 8244, epoch: 7, loss: 1.330755
global_step: 8245, epoch: 7, loss: 1.339534
global_step: 8246, epoch: 7, loss: 1.338470
global_step: 8247, epoch: 7, loss: 1.432186
global_step: 8248, epoch: 7, loss: 1.298686
global_step: 8249, epoch: 7, loss: 1.429659
global_step: 8250, epoch: 7, loss: 1.435792
global_step: 8251, epoch: 7, loss: 1.391618
global_step: 8252, epoch: 7, loss: 1.429230
global_step: 8253, epoch: 7, loss: 1.400636
global_step: 8254, epoch: 7, loss: 1.302122
global_step: 8255, epoch: 7, loss: 1.408602
global_step: 8256, epoch: 7, loss: 1.332941
global_step: 8257, epoch: 7, loss: 1.284793
global_step: 8258, epoch: 7, loss: 1.416156
global_step: 8259, epoch: 7, loss: 1.408275
global_step: 8260, epoch: 7, loss: 1.278859
global_step: 8261, epoch: 7, loss: 1.372327
global_step: 8262, epoch: 7, loss: 1.340663
global_step: 8263, epoch: 7, loss: 1.335461
global_step: 8264, epoch: 7, loss: 1.331034
global_step: 8265, epoch: 7, loss: 1.345866
global_step: 8266, epoch: 7, loss: 1.323528
global_step: 8267, epoch: 7, loss: 1.343804
global_step: 8268, epoch: 7, loss: 1.243606
global_step: 8269, epoch: 7, loss: 1.410627
global_step: 8270, epoch: 7, loss: 1.337911
global_step: 8271, epoch: 7, loss: 1.379267
global_step: 8272, epoch: 7, loss: 1.411083
global_step: 8273, epoch: 7, loss: 1.363700
global_step: 8274, epoch: 7, loss: 1.404638
global_step: 8275, epoch: 7, loss: 1.420310
global_step: 8276, epoch: 7, loss: 1.327867
global_step: 8277, epoch: 7, loss: 1.339655
global_step: 8278, epoch: 7, loss: 1.290030
global_step: 8279, epoch: 7, loss: 1.381988
global_step: 8280, epoch: 7, loss: 1.322906
epoch: 7
train	acc: 0.5532	macro: p 0.3247, r 0.2309, f1: 0.1971	micro: p 0.5532, r 0.5532, f1 0.5532	weighted_f1:0.4533
dev	acc: 0.5077	macro: p 0.3331, r 0.2400, f1: 0.1926	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.3957
test	acc: 0.5594	macro: p 0.3259, r 0.2401, f1: 0.2040	micro: p 0.5594, r 0.5594, f1 0.5594	weighted_f1:0.4610
New best model!
global_step: 8281, epoch: 8, loss: 1.248594
global_step: 8282, epoch: 8, loss: 1.347477
global_step: 8283, epoch: 8, loss: 1.270220
global_step: 8284, epoch: 8, loss: 1.372630
global_step: 8285, epoch: 8, loss: 1.271155
global_step: 8286, epoch: 8, loss: 1.358957
global_step: 8287, epoch: 8, loss: 1.345401
global_step: 8288, epoch: 8, loss: 1.223189
global_step: 8289, epoch: 8, loss: 1.320920
global_step: 8290, epoch: 8, loss: 1.318350
global_step: 8291, epoch: 8, loss: 1.525049
global_step: 8292, epoch: 8, loss: 1.368749
global_step: 8293, epoch: 8, loss: 1.341764
global_step: 8294, epoch: 8, loss: 1.428943
global_step: 8295, epoch: 8, loss: 1.454210
global_step: 8296, epoch: 8, loss: 1.426674
global_step: 8297, epoch: 8, loss: 1.368738
global_step: 8298, epoch: 8, loss: 1.329268
global_step: 8299, epoch: 8, loss: 1.373292
global_step: 8300, epoch: 8, loss: 1.355492
global_step: 8301, epoch: 8, loss: 1.337094
global_step: 8302, epoch: 8, loss: 1.318683
global_step: 8303, epoch: 8, loss: 1.369916
global_step: 8304, epoch: 8, loss: 1.336747
global_step: 8305, epoch: 8, loss: 1.324830
global_step: 8306, epoch: 8, loss: 1.362885
global_step: 8307, epoch: 8, loss: 1.168362
global_step: 8308, epoch: 8, loss: 1.439993
global_step: 8309, epoch: 8, loss: 1.383416
global_step: 8310, epoch: 8, loss: 1.355062
global_step: 8311, epoch: 8, loss: 1.494190
global_step: 8312, epoch: 8, loss: 1.348122
global_step: 8313, epoch: 8, loss: 1.246100
global_step: 8314, epoch: 8, loss: 1.384001
global_step: 8315, epoch: 8, loss: 1.303319
global_step: 8316, epoch: 8, loss: 1.369880
global_step: 8317, epoch: 8, loss: 1.298971
global_step: 8318, epoch: 8, loss: 1.251862
global_step: 8319, epoch: 8, loss: 1.320259
global_step: 8320, epoch: 8, loss: 1.150208
epoch: 8
train	acc: 0.5503	macro: p 0.2562, r 0.2268, f1: 0.1882	micro: p 0.5503, r 0.5503, f1 0.5503	weighted_f1:0.4461
dev	acc: 0.5050	macro: p 0.2608, r 0.2373, f1: 0.1880	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.3910
test	acc: 0.5559	macro: p 0.4054, r 0.2361, f1: 0.1946	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.4525
global_step: 8321, epoch: 9, loss: 1.306496
global_step: 8322, epoch: 9, loss: 1.389629
global_step: 8323, epoch: 9, loss: 1.247704
global_step: 8324, epoch: 9, loss: 1.208594
global_step: 8325, epoch: 9, loss: 1.488642
global_step: 8326, epoch: 9, loss: 1.406768
global_step: 8327, epoch: 9, loss: 1.454808
global_step: 8328, epoch: 9, loss: 1.334048
global_step: 8329, epoch: 9, loss: 1.383077
global_step: 8330, epoch: 9, loss: 1.378591
global_step: 8331, epoch: 9, loss: 1.401297
global_step: 8332, epoch: 9, loss: 1.359555
global_step: 8333, epoch: 9, loss: 1.365714
global_step: 8334, epoch: 9, loss: 1.329829
global_step: 8335, epoch: 9, loss: 1.332375
global_step: 8336, epoch: 9, loss: 1.336141
global_step: 8337, epoch: 9, loss: 1.281329
global_step: 8338, epoch: 9, loss: 1.380443
global_step: 8339, epoch: 9, loss: 1.327430
global_step: 8340, epoch: 9, loss: 1.370138
global_step: 8341, epoch: 9, loss: 1.089279
global_step: 8342, epoch: 9, loss: 1.401599
global_step: 8343, epoch: 9, loss: 1.223364
global_step: 8344, epoch: 9, loss: 1.365398
global_step: 8345, epoch: 9, loss: 1.377974
global_step: 8346, epoch: 9, loss: 1.346862
global_step: 8347, epoch: 9, loss: 1.325716
global_step: 8348, epoch: 9, loss: 1.319163
global_step: 8349, epoch: 9, loss: 1.330881
global_step: 8350, epoch: 9, loss: 1.234119
global_step: 8351, epoch: 9, loss: 1.297797
global_step: 8352, epoch: 9, loss: 1.374967
global_step: 8353, epoch: 9, loss: 1.215481
global_step: 8354, epoch: 9, loss: 1.191835
global_step: 8355, epoch: 9, loss: 1.220878
global_step: 8356, epoch: 9, loss: 1.368568
global_step: 8357, epoch: 9, loss: 1.443106
global_step: 8358, epoch: 9, loss: 1.393839
global_step: 8359, epoch: 9, loss: 1.306890
global_step: 8360, epoch: 9, loss: 1.039560
epoch: 9
train	acc: 0.5605	macro: p 0.3305, r 0.2402, f1: 0.2135	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.4677
dev	acc: 0.5176	macro: p 0.3332, r 0.2504, f1: 0.2107	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4132
test	acc: 0.5613	macro: p 0.2907, r 0.2435, f1: 0.2107	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.4663
New best model!
global_step: 8361, epoch: 10, loss: 1.423696
global_step: 8362, epoch: 10, loss: 1.327608
global_step: 8363, epoch: 10, loss: 1.225510
global_step: 8364, epoch: 10, loss: 1.413949
global_step: 8365, epoch: 10, loss: 1.311724
global_step: 8366, epoch: 10, loss: 1.309772
global_step: 8367, epoch: 10, loss: 1.319421
global_step: 8368, epoch: 10, loss: 1.314529
global_step: 8369, epoch: 10, loss: 1.297227
global_step: 8370, epoch: 10, loss: 1.456150
global_step: 8371, epoch: 10, loss: 1.392207
global_step: 8372, epoch: 10, loss: 1.177333
global_step: 8373, epoch: 10, loss: 1.436112
global_step: 8374, epoch: 10, loss: 1.363638
global_step: 8375, epoch: 10, loss: 1.234460
global_step: 8376, epoch: 10, loss: 1.383674
global_step: 8377, epoch: 10, loss: 1.425506
global_step: 8378, epoch: 10, loss: 1.282380
global_step: 8379, epoch: 10, loss: 1.245908
global_step: 8380, epoch: 10, loss: 1.233044
global_step: 8381, epoch: 10, loss: 1.332014
global_step: 8382, epoch: 10, loss: 1.277921
global_step: 8383, epoch: 10, loss: 1.377930
global_step: 8384, epoch: 10, loss: 1.317521
global_step: 8385, epoch: 10, loss: 1.317603
global_step: 8386, epoch: 10, loss: 1.287733
global_step: 8387, epoch: 10, loss: 1.317045
global_step: 8388, epoch: 10, loss: 1.276191
global_step: 8389, epoch: 10, loss: 1.222689
global_step: 8390, epoch: 10, loss: 1.360746
global_step: 8391, epoch: 10, loss: 1.253490
global_step: 8392, epoch: 10, loss: 1.298291
global_step: 8393, epoch: 10, loss: 1.268562
global_step: 8394, epoch: 10, loss: 1.222893
global_step: 8395, epoch: 10, loss: 1.361881
global_step: 8396, epoch: 10, loss: 1.300139
global_step: 8397, epoch: 10, loss: 1.423209
global_step: 8398, epoch: 10, loss: 1.297347
global_step: 8399, epoch: 10, loss: 1.341326
global_step: 8400, epoch: 10, loss: 1.589199
epoch: 10
train	acc: 0.5718	macro: p 0.3132, r 0.2549, f1: 0.2385	micro: p 0.5718, r 0.5718, f1 0.5718	weighted_f1:0.4899
dev	acc: 0.5221	macro: p 0.2856, r 0.2556, f1: 0.2215	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4239
test	acc: 0.5701	macro: p 0.2977, r 0.2559, f1: 0.2328	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.4849
New best model!
global_step: 8401, epoch: 11, loss: 1.280439
global_step: 8402, epoch: 11, loss: 1.308507
global_step: 8403, epoch: 11, loss: 1.409603
global_step: 8404, epoch: 11, loss: 1.297231
global_step: 8405, epoch: 11, loss: 1.301463
global_step: 8406, epoch: 11, loss: 1.395516
global_step: 8407, epoch: 11, loss: 1.287002
global_step: 8408, epoch: 11, loss: 1.217459
global_step: 8409, epoch: 11, loss: 1.330947
global_step: 8410, epoch: 11, loss: 1.280748
global_step: 8411, epoch: 11, loss: 1.350540
global_step: 8412, epoch: 11, loss: 1.254075
global_step: 8413, epoch: 11, loss: 1.353361
global_step: 8414, epoch: 11, loss: 1.271020
global_step: 8415, epoch: 11, loss: 1.334026
global_step: 8416, epoch: 11, loss: 1.383322
global_step: 8417, epoch: 11, loss: 1.302056
global_step: 8418, epoch: 11, loss: 1.264949
global_step: 8419, epoch: 11, loss: 1.258334
global_step: 8420, epoch: 11, loss: 1.250391
global_step: 8421, epoch: 11, loss: 1.401837
global_step: 8422, epoch: 11, loss: 1.416905
global_step: 8423, epoch: 11, loss: 1.376703
global_step: 8424, epoch: 11, loss: 1.362072
global_step: 8425, epoch: 11, loss: 1.426211
global_step: 8426, epoch: 11, loss: 1.226104
global_step: 8427, epoch: 11, loss: 1.365890
global_step: 8428, epoch: 11, loss: 1.299787
global_step: 8429, epoch: 11, loss: 1.277773
global_step: 8430, epoch: 11, loss: 1.248773
global_step: 8431, epoch: 11, loss: 1.275733
global_step: 8432, epoch: 11, loss: 1.359565
global_step: 8433, epoch: 11, loss: 1.310697
global_step: 8434, epoch: 11, loss: 1.239990
global_step: 8435, epoch: 11, loss: 1.219050
global_step: 8436, epoch: 11, loss: 1.235268
global_step: 8437, epoch: 11, loss: 1.281708
global_step: 8438, epoch: 11, loss: 1.291552
global_step: 8439, epoch: 11, loss: 1.165923
global_step: 8440, epoch: 11, loss: 1.382136
epoch: 11
train	acc: 0.5694	macro: p 0.3275, r 0.2516, f1: 0.2346	micro: p 0.5694, r 0.5694, f1 0.5694	weighted_f1:0.4853
dev	acc: 0.5203	macro: p 0.2965, r 0.2534, f1: 0.2200	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4227
test	acc: 0.5697	macro: p 0.3046, r 0.2528, f1: 0.2305	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.4844
global_step: 8441, epoch: 12, loss: 1.367771
global_step: 8442, epoch: 12, loss: 1.183893
global_step: 8443, epoch: 12, loss: 1.286332
global_step: 8444, epoch: 12, loss: 1.425336
global_step: 8445, epoch: 12, loss: 1.336014
global_step: 8446, epoch: 12, loss: 1.335679
global_step: 8447, epoch: 12, loss: 1.189857
global_step: 8448, epoch: 12, loss: 1.366797
global_step: 8449, epoch: 12, loss: 1.379068
global_step: 8450, epoch: 12, loss: 1.289608
global_step: 8451, epoch: 12, loss: 1.280620
global_step: 8452, epoch: 12, loss: 1.293142
global_step: 8453, epoch: 12, loss: 1.446920
global_step: 8454, epoch: 12, loss: 1.275353
global_step: 8455, epoch: 12, loss: 1.241198
global_step: 8456, epoch: 12, loss: 1.300452
global_step: 8457, epoch: 12, loss: 1.319286
global_step: 8458, epoch: 12, loss: 1.238602
global_step: 8459, epoch: 12, loss: 1.330123
global_step: 8460, epoch: 12, loss: 1.295445
global_step: 8461, epoch: 12, loss: 1.292910
global_step: 8462, epoch: 12, loss: 1.233952
global_step: 8463, epoch: 12, loss: 1.402725
global_step: 8464, epoch: 12, loss: 1.331060
global_step: 8465, epoch: 12, loss: 1.327716
global_step: 8466, epoch: 12, loss: 1.274662
global_step: 8467, epoch: 12, loss: 1.239663
global_step: 8468, epoch: 12, loss: 1.270381
global_step: 8469, epoch: 12, loss: 1.222673
global_step: 8470, epoch: 12, loss: 1.186238
global_step: 8471, epoch: 12, loss: 1.296701
global_step: 8472, epoch: 12, loss: 1.240319
global_step: 8473, epoch: 12, loss: 1.246225
global_step: 8474, epoch: 12, loss: 1.224445
global_step: 8475, epoch: 12, loss: 1.233956
global_step: 8476, epoch: 12, loss: 1.270497
global_step: 8477, epoch: 12, loss: 1.329515
global_step: 8478, epoch: 12, loss: 1.292269
global_step: 8479, epoch: 12, loss: 1.211794
global_step: 8480, epoch: 12, loss: 1.204891
epoch: 12
train	acc: 0.5718	macro: p 0.3254, r 0.2526, f1: 0.2341	micro: p 0.5718, r 0.5718, f1 0.5718	weighted_f1:0.4869
dev	acc: 0.5230	macro: p 0.2967, r 0.2556, f1: 0.2197	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4228
test	acc: 0.5705	macro: p 0.3084, r 0.2537, f1: 0.2293	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.4831
global_step: 8481, epoch: 13, loss: 1.307213
global_step: 8482, epoch: 13, loss: 1.278167
global_step: 8483, epoch: 13, loss: 1.270008
global_step: 8484, epoch: 13, loss: 1.228710
global_step: 8485, epoch: 13, loss: 1.437744
global_step: 8486, epoch: 13, loss: 1.325005
global_step: 8487, epoch: 13, loss: 1.366863
global_step: 8488, epoch: 13, loss: 1.253300
global_step: 8489, epoch: 13, loss: 1.273938
global_step: 8490, epoch: 13, loss: 1.229833
global_step: 8491, epoch: 13, loss: 1.382635
global_step: 8492, epoch: 13, loss: 1.328945
global_step: 8493, epoch: 13, loss: 1.245200
global_step: 8494, epoch: 13, loss: 1.263318
global_step: 8495, epoch: 13, loss: 1.233833
global_step: 8496, epoch: 13, loss: 1.233268
global_step: 8497, epoch: 13, loss: 1.269861
global_step: 8498, epoch: 13, loss: 1.221062
global_step: 8499, epoch: 13, loss: 1.251470
global_step: 8500, epoch: 13, loss: 1.341945
global_step: 8501, epoch: 13, loss: 1.336314
global_step: 8502, epoch: 13, loss: 1.189071
global_step: 8503, epoch: 13, loss: 1.275518
global_step: 8504, epoch: 13, loss: 1.271837
global_step: 8505, epoch: 13, loss: 1.229526
global_step: 8506, epoch: 13, loss: 1.305606
global_step: 8507, epoch: 13, loss: 1.278954
global_step: 8508, epoch: 13, loss: 1.254600
global_step: 8509, epoch: 13, loss: 1.277410
global_step: 8510, epoch: 13, loss: 1.300963
global_step: 8511, epoch: 13, loss: 1.274761
global_step: 8512, epoch: 13, loss: 1.209044
global_step: 8513, epoch: 13, loss: 1.287163
global_step: 8514, epoch: 13, loss: 1.309884
global_step: 8515, epoch: 13, loss: 1.265630
global_step: 8516, epoch: 13, loss: 1.240679
global_step: 8517, epoch: 13, loss: 1.312913
global_step: 8518, epoch: 13, loss: 1.228134
global_step: 8519, epoch: 13, loss: 1.312681
global_step: 8520, epoch: 13, loss: 1.774863
epoch: 13
train	acc: 0.5886	macro: p 0.3090, r 0.2809, f1: 0.2755	micro: p 0.5886, r 0.5886, f1 0.5886	weighted_f1:0.5214
dev	acc: 0.5428	macro: p 0.3022, r 0.2780, f1: 0.2642	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4656
test	acc: 0.5923	macro: p 0.3042, r 0.2815, f1: 0.2755	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5253
New best model!
global_step: 8521, epoch: 14, loss: 1.245278
global_step: 8522, epoch: 14, loss: 1.217149
global_step: 8523, epoch: 14, loss: 1.351451
global_step: 8524, epoch: 14, loss: 1.339459
global_step: 8525, epoch: 14, loss: 1.253349
global_step: 8526, epoch: 14, loss: 1.308008
global_step: 8527, epoch: 14, loss: 1.175968
global_step: 8528, epoch: 14, loss: 1.283770
global_step: 8529, epoch: 14, loss: 1.355113
global_step: 8530, epoch: 14, loss: 1.333363
global_step: 8531, epoch: 14, loss: 1.323069
global_step: 8532, epoch: 14, loss: 1.350573
global_step: 8533, epoch: 14, loss: 1.323088
global_step: 8534, epoch: 14, loss: 1.188391
global_step: 8535, epoch: 14, loss: 1.294593
global_step: 8536, epoch: 14, loss: 1.248531
global_step: 8537, epoch: 14, loss: 1.147816
global_step: 8538, epoch: 14, loss: 1.246855
global_step: 8539, epoch: 14, loss: 1.174461
global_step: 8540, epoch: 14, loss: 1.223548
global_step: 8541, epoch: 14, loss: 1.158023
global_step: 8542, epoch: 14, loss: 1.324532
global_step: 8543, epoch: 14, loss: 1.271624
global_step: 8544, epoch: 14, loss: 1.282266
global_step: 8545, epoch: 14, loss: 1.359020
global_step: 8546, epoch: 14, loss: 1.221792
global_step: 8547, epoch: 14, loss: 1.251469
global_step: 8548, epoch: 14, loss: 1.166905
global_step: 8549, epoch: 14, loss: 1.310105
global_step: 8550, epoch: 14, loss: 1.309116
global_step: 8551, epoch: 14, loss: 1.288481
global_step: 8552, epoch: 14, loss: 1.274565
global_step: 8553, epoch: 14, loss: 1.284215
global_step: 8554, epoch: 14, loss: 1.361036
global_step: 8555, epoch: 14, loss: 1.316006
global_step: 8556, epoch: 14, loss: 1.203147
global_step: 8557, epoch: 14, loss: 1.193139
global_step: 8558, epoch: 14, loss: 1.283475
global_step: 8559, epoch: 14, loss: 1.244038
global_step: 8560, epoch: 14, loss: 2.208817
epoch: 14
train	acc: 0.5893	macro: p 0.3149, r 0.2815, f1: 0.2754	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5221
dev	acc: 0.5383	macro: p 0.2971, r 0.2741, f1: 0.2558	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4583
test	acc: 0.5920	macro: p 0.3056, r 0.2825, f1: 0.2750	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5252
global_step: 8561, epoch: 15, loss: 1.208126
global_step: 8562, epoch: 15, loss: 1.272876
global_step: 8563, epoch: 15, loss: 1.291697
global_step: 8564, epoch: 15, loss: 1.168349
global_step: 8565, epoch: 15, loss: 1.261957
global_step: 8566, epoch: 15, loss: 1.219939
global_step: 8567, epoch: 15, loss: 1.329358
global_step: 8568, epoch: 15, loss: 1.314152
global_step: 8569, epoch: 15, loss: 1.520173
global_step: 8570, epoch: 15, loss: 1.222224
global_step: 8571, epoch: 15, loss: 1.250681
global_step: 8572, epoch: 15, loss: 1.214054
global_step: 8573, epoch: 15, loss: 1.291936
global_step: 8574, epoch: 15, loss: 1.312708
global_step: 8575, epoch: 15, loss: 1.148176
global_step: 8576, epoch: 15, loss: 1.220665
global_step: 8577, epoch: 15, loss: 1.217489
global_step: 8578, epoch: 15, loss: 1.188429
global_step: 8579, epoch: 15, loss: 1.188087
global_step: 8580, epoch: 15, loss: 1.286024
global_step: 8581, epoch: 15, loss: 1.290774
global_step: 8582, epoch: 15, loss: 1.256043
global_step: 8583, epoch: 15, loss: 1.235711
global_step: 8584, epoch: 15, loss: 1.171536
global_step: 8585, epoch: 15, loss: 1.242854
global_step: 8586, epoch: 15, loss: 1.315576
global_step: 8587, epoch: 15, loss: 1.289651
global_step: 8588, epoch: 15, loss: 1.227854
global_step: 8589, epoch: 15, loss: 1.354910
global_step: 8590, epoch: 15, loss: 1.322737
global_step: 8591, epoch: 15, loss: 1.296519
global_step: 8592, epoch: 15, loss: 1.200203
global_step: 8593, epoch: 15, loss: 1.433878
global_step: 8594, epoch: 15, loss: 1.209657
global_step: 8595, epoch: 15, loss: 1.321625
global_step: 8596, epoch: 15, loss: 1.219312
global_step: 8597, epoch: 15, loss: 1.162842
global_step: 8598, epoch: 15, loss: 1.315133
global_step: 8599, epoch: 15, loss: 1.320149
global_step: 8600, epoch: 15, loss: 1.749359
epoch: 15
train	acc: 0.5848	macro: p 0.3216, r 0.2680, f1: 0.2583	micro: p 0.5848, r 0.5848, f1 0.5848	weighted_f1:0.5083
dev	acc: 0.5338	macro: p 0.3081, r 0.2672, f1: 0.2426	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4447
test	acc: 0.5839	macro: p 0.3106, r 0.2685, f1: 0.2534	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5048
global_step: 8601, epoch: 16, loss: 1.261659
global_step: 8602, epoch: 16, loss: 1.236879
global_step: 8603, epoch: 16, loss: 1.282461
global_step: 8604, epoch: 16, loss: 1.246934
global_step: 8605, epoch: 16, loss: 1.244807
global_step: 8606, epoch: 16, loss: 1.307649
global_step: 8607, epoch: 16, loss: 1.274929
global_step: 8608, epoch: 16, loss: 1.191985
global_step: 8609, epoch: 16, loss: 1.125094
global_step: 8610, epoch: 16, loss: 1.358671
global_step: 8611, epoch: 16, loss: 1.251749
global_step: 8612, epoch: 16, loss: 1.169570
global_step: 8613, epoch: 16, loss: 1.168077
global_step: 8614, epoch: 16, loss: 1.184549
global_step: 8615, epoch: 16, loss: 1.276193
global_step: 8616, epoch: 16, loss: 1.287372
global_step: 8617, epoch: 16, loss: 1.106043
global_step: 8618, epoch: 16, loss: 1.321796
global_step: 8619, epoch: 16, loss: 1.235066
global_step: 8620, epoch: 16, loss: 1.368376
global_step: 8621, epoch: 16, loss: 1.203283
global_step: 8622, epoch: 16, loss: 1.221986
global_step: 8623, epoch: 16, loss: 1.240188
global_step: 8624, epoch: 16, loss: 1.192570
global_step: 8625, epoch: 16, loss: 1.193839
global_step: 8626, epoch: 16, loss: 1.310291
global_step: 8627, epoch: 16, loss: 1.274487
global_step: 8628, epoch: 16, loss: 1.455647
global_step: 8629, epoch: 16, loss: 1.413555
global_step: 8630, epoch: 16, loss: 1.251879
global_step: 8631, epoch: 16, loss: 1.240281
global_step: 8632, epoch: 16, loss: 1.170851
global_step: 8633, epoch: 16, loss: 1.341232
global_step: 8634, epoch: 16, loss: 1.212027
global_step: 8635, epoch: 16, loss: 1.185093
global_step: 8636, epoch: 16, loss: 1.272729
global_step: 8637, epoch: 16, loss: 1.216792
global_step: 8638, epoch: 16, loss: 1.248313
global_step: 8639, epoch: 16, loss: 1.142619
global_step: 8640, epoch: 16, loss: 1.972716
epoch: 16
train	acc: 0.5890	macro: p 0.3209, r 0.2749, f1: 0.2679	micro: p 0.5890, r 0.5890, f1 0.5890	weighted_f1:0.5166
dev	acc: 0.5419	macro: p 0.3167, r 0.2756, f1: 0.2553	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4577
test	acc: 0.5904	macro: p 0.3166, r 0.2767, f1: 0.2658	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5163
global_step: 8641, epoch: 17, loss: 1.304208
global_step: 8642, epoch: 17, loss: 1.312504
global_step: 8643, epoch: 17, loss: 1.172040
global_step: 8644, epoch: 17, loss: 1.259256
global_step: 8645, epoch: 17, loss: 1.408585
global_step: 8646, epoch: 17, loss: 1.211661
global_step: 8647, epoch: 17, loss: 1.193179
global_step: 8648, epoch: 17, loss: 1.165771
global_step: 8649, epoch: 17, loss: 1.237368
global_step: 8650, epoch: 17, loss: 1.236016
global_step: 8651, epoch: 17, loss: 1.247437
global_step: 8652, epoch: 17, loss: 1.197171
global_step: 8653, epoch: 17, loss: 1.319305
global_step: 8654, epoch: 17, loss: 1.175123
global_step: 8655, epoch: 17, loss: 1.209024
global_step: 8656, epoch: 17, loss: 1.449468
global_step: 8657, epoch: 17, loss: 1.167334
global_step: 8658, epoch: 17, loss: 1.206198
global_step: 8659, epoch: 17, loss: 1.242202
global_step: 8660, epoch: 17, loss: 1.170495
global_step: 8661, epoch: 17, loss: 1.391196
global_step: 8662, epoch: 17, loss: 1.240902
global_step: 8663, epoch: 17, loss: 1.244865
global_step: 8664, epoch: 17, loss: 1.210313
global_step: 8665, epoch: 17, loss: 1.139529
global_step: 8666, epoch: 17, loss: 1.338929
global_step: 8667, epoch: 17, loss: 1.223766
global_step: 8668, epoch: 17, loss: 1.293525
global_step: 8669, epoch: 17, loss: 1.248041
global_step: 8670, epoch: 17, loss: 1.186156
global_step: 8671, epoch: 17, loss: 1.329494
global_step: 8672, epoch: 17, loss: 1.275288
global_step: 8673, epoch: 17, loss: 1.201544
global_step: 8674, epoch: 17, loss: 1.117280
global_step: 8675, epoch: 17, loss: 1.214756
global_step: 8676, epoch: 17, loss: 1.135327
global_step: 8677, epoch: 17, loss: 1.181749
global_step: 8678, epoch: 17, loss: 1.303888
global_step: 8679, epoch: 17, loss: 1.157870
global_step: 8680, epoch: 17, loss: 1.212938
epoch: 17
train	acc: 0.5971	macro: p 0.3142, r 0.2885, f1: 0.2825	micro: p 0.5971, r 0.5971, f1 0.5971	weighted_f1:0.5308
dev	acc: 0.5383	macro: p 0.2901, r 0.2773, f1: 0.2569	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4586
test	acc: 0.5927	macro: p 0.3034, r 0.2870, f1: 0.2752	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5240
global_step: 8681, epoch: 18, loss: 1.256594
global_step: 8682, epoch: 18, loss: 1.211432
global_step: 8683, epoch: 18, loss: 1.220021
global_step: 8684, epoch: 18, loss: 1.251489
global_step: 8685, epoch: 18, loss: 1.251085
global_step: 8686, epoch: 18, loss: 1.141256
global_step: 8687, epoch: 18, loss: 1.144006
global_step: 8688, epoch: 18, loss: 1.051044
global_step: 8689, epoch: 18, loss: 1.202366
global_step: 8690, epoch: 18, loss: 1.268883
global_step: 8691, epoch: 18, loss: 1.286821
global_step: 8692, epoch: 18, loss: 1.209244
global_step: 8693, epoch: 18, loss: 1.248427
global_step: 8694, epoch: 18, loss: 1.242311
global_step: 8695, epoch: 18, loss: 1.166346
global_step: 8696, epoch: 18, loss: 1.218027
global_step: 8697, epoch: 18, loss: 1.117380
global_step: 8698, epoch: 18, loss: 1.200924
global_step: 8699, epoch: 18, loss: 1.221475
global_step: 8700, epoch: 18, loss: 1.220881
global_step: 8701, epoch: 18, loss: 1.256195
global_step: 8702, epoch: 18, loss: 1.293184
global_step: 8703, epoch: 18, loss: 1.206083
global_step: 8704, epoch: 18, loss: 1.295180
global_step: 8705, epoch: 18, loss: 1.378289
global_step: 8706, epoch: 18, loss: 1.170767
global_step: 8707, epoch: 18, loss: 1.282569
global_step: 8708, epoch: 18, loss: 1.219872
global_step: 8709, epoch: 18, loss: 1.395991
global_step: 8710, epoch: 18, loss: 1.181933
global_step: 8711, epoch: 18, loss: 1.296794
global_step: 8712, epoch: 18, loss: 1.248644
global_step: 8713, epoch: 18, loss: 1.281574
global_step: 8714, epoch: 18, loss: 1.311715
global_step: 8715, epoch: 18, loss: 1.193479
global_step: 8716, epoch: 18, loss: 1.251309
global_step: 8717, epoch: 18, loss: 1.118817
global_step: 8718, epoch: 18, loss: 1.138610
global_step: 8719, epoch: 18, loss: 1.308238
global_step: 8720, epoch: 18, loss: 0.511176
epoch: 18
train	acc: 0.5937	macro: p 0.3209, r 0.2811, f1: 0.2735	micro: p 0.5937, r 0.5937, f1 0.5937	weighted_f1:0.5232
dev	acc: 0.5383	macro: p 0.3022, r 0.2764, f1: 0.2547	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4563
test	acc: 0.5900	macro: p 0.3089, r 0.2813, f1: 0.2684	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5176
global_step: 8721, epoch: 19, loss: 1.320943
global_step: 8722, epoch: 19, loss: 1.211901
global_step: 8723, epoch: 19, loss: 1.314630
global_step: 8724, epoch: 19, loss: 1.113105
global_step: 8725, epoch: 19, loss: 1.232803
global_step: 8726, epoch: 19, loss: 1.224955
global_step: 8727, epoch: 19, loss: 1.263546
global_step: 8728, epoch: 19, loss: 1.253091
global_step: 8729, epoch: 19, loss: 1.251545
global_step: 8730, epoch: 19, loss: 1.145856
global_step: 8731, epoch: 19, loss: 1.225585
global_step: 8732, epoch: 19, loss: 1.299445
global_step: 8733, epoch: 19, loss: 1.133445
global_step: 8734, epoch: 19, loss: 1.155219
global_step: 8735, epoch: 19, loss: 1.155018
global_step: 8736, epoch: 19, loss: 1.292463
global_step: 8737, epoch: 19, loss: 1.280852
global_step: 8738, epoch: 19, loss: 1.190491
global_step: 8739, epoch: 19, loss: 1.236699
global_step: 8740, epoch: 19, loss: 1.275513
global_step: 8741, epoch: 19, loss: 1.140357
global_step: 8742, epoch: 19, loss: 1.224102
global_step: 8743, epoch: 19, loss: 1.237643
global_step: 8744, epoch: 19, loss: 1.165949
global_step: 8745, epoch: 19, loss: 1.141888
global_step: 8746, epoch: 19, loss: 1.261417
global_step: 8747, epoch: 19, loss: 1.143481
global_step: 8748, epoch: 19, loss: 1.191358
global_step: 8749, epoch: 19, loss: 1.156667
global_step: 8750, epoch: 19, loss: 1.211010
global_step: 8751, epoch: 19, loss: 1.254284
global_step: 8752, epoch: 19, loss: 1.193212
global_step: 8753, epoch: 19, loss: 1.148155
global_step: 8754, epoch: 19, loss: 1.177719
global_step: 8755, epoch: 19, loss: 1.209941
global_step: 8756, epoch: 19, loss: 1.318747
global_step: 8757, epoch: 19, loss: 1.200533
global_step: 8758, epoch: 19, loss: 1.218023
global_step: 8759, epoch: 19, loss: 1.279029
global_step: 8760, epoch: 19, loss: 1.131414
epoch: 19
train	acc: 0.6032	macro: p 0.3155, r 0.2998, f1: 0.2904	micro: p 0.6032, r 0.6032, f1 0.6032	weighted_f1:0.5410
dev	acc: 0.5473	macro: p 0.3015, r 0.2922, f1: 0.2684	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4722
test	acc: 0.5943	macro: p 0.3057, r 0.2966, f1: 0.2819	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5303
New best model!
global_step: 8761, epoch: 20, loss: 1.209027
global_step: 8762, epoch: 20, loss: 1.111872
global_step: 8763, epoch: 20, loss: 1.180256
global_step: 8764, epoch: 20, loss: 1.232560
global_step: 8765, epoch: 20, loss: 1.156502
global_step: 8766, epoch: 20, loss: 1.274200
global_step: 8767, epoch: 20, loss: 1.237360
global_step: 8768, epoch: 20, loss: 1.257537
global_step: 8769, epoch: 20, loss: 1.306153
global_step: 8770, epoch: 20, loss: 1.125713
global_step: 8771, epoch: 20, loss: 1.232669
global_step: 8772, epoch: 20, loss: 1.273207
global_step: 8773, epoch: 20, loss: 1.307520
global_step: 8774, epoch: 20, loss: 1.175243
global_step: 8775, epoch: 20, loss: 1.178130
global_step: 8776, epoch: 20, loss: 1.232931
global_step: 8777, epoch: 20, loss: 1.187670
global_step: 8778, epoch: 20, loss: 1.211146
global_step: 8779, epoch: 20, loss: 1.158692
global_step: 8780, epoch: 20, loss: 1.210827
global_step: 8781, epoch: 20, loss: 1.186061
global_step: 8782, epoch: 20, loss: 1.241622
global_step: 8783, epoch: 20, loss: 1.234680
global_step: 8784, epoch: 20, loss: 1.209671
global_step: 8785, epoch: 20, loss: 1.237732
global_step: 8786, epoch: 20, loss: 1.229339
global_step: 8787, epoch: 20, loss: 1.210743
global_step: 8788, epoch: 20, loss: 1.116952
global_step: 8789, epoch: 20, loss: 1.295252
global_step: 8790, epoch: 20, loss: 1.238666
global_step: 8791, epoch: 20, loss: 1.140349
global_step: 8792, epoch: 20, loss: 1.177400
global_step: 8793, epoch: 20, loss: 1.240609
global_step: 8794, epoch: 20, loss: 1.175930
global_step: 8795, epoch: 20, loss: 1.291977
global_step: 8796, epoch: 20, loss: 1.219754
global_step: 8797, epoch: 20, loss: 1.145710
global_step: 8798, epoch: 20, loss: 1.126497
global_step: 8799, epoch: 20, loss: 1.273785
global_step: 8800, epoch: 20, loss: 0.741454
epoch: 20
train	acc: 0.6067	macro: p 0.3266, r 0.3009, f1: 0.2981	micro: p 0.6067, r 0.6067, f1 0.6067	weighted_f1:0.5446
dev	acc: 0.5437	macro: p 0.2937, r 0.2826, f1: 0.2683	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4690
test	acc: 0.5989	macro: p 0.3096, r 0.2922, f1: 0.2876	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5356
global_step: 8801, epoch: 21, loss: 1.138247
global_step: 8802, epoch: 21, loss: 1.185875
global_step: 8803, epoch: 21, loss: 1.190330
global_step: 8804, epoch: 21, loss: 1.166412
global_step: 8805, epoch: 21, loss: 1.170568
global_step: 8806, epoch: 21, loss: 1.297083
global_step: 8807, epoch: 21, loss: 1.236438
global_step: 8808, epoch: 21, loss: 1.154516
global_step: 8809, epoch: 21, loss: 1.111022
global_step: 8810, epoch: 21, loss: 1.162563
global_step: 8811, epoch: 21, loss: 1.167085
global_step: 8812, epoch: 21, loss: 1.302976
global_step: 8813, epoch: 21, loss: 1.132254
global_step: 8814, epoch: 21, loss: 1.129244
global_step: 8815, epoch: 21, loss: 1.234612
global_step: 8816, epoch: 21, loss: 1.200928
global_step: 8817, epoch: 21, loss: 1.159415
global_step: 8818, epoch: 21, loss: 1.236638
global_step: 8819, epoch: 21, loss: 1.163669
global_step: 8820, epoch: 21, loss: 1.109133
global_step: 8821, epoch: 21, loss: 1.209422
global_step: 8822, epoch: 21, loss: 1.277093
global_step: 8823, epoch: 21, loss: 1.144832
global_step: 8824, epoch: 21, loss: 1.228139
global_step: 8825, epoch: 21, loss: 1.196180
global_step: 8826, epoch: 21, loss: 1.289608
global_step: 8827, epoch: 21, loss: 1.210813
global_step: 8828, epoch: 21, loss: 1.306945
global_step: 8829, epoch: 21, loss: 1.222581
global_step: 8830, epoch: 21, loss: 1.208783
global_step: 8831, epoch: 21, loss: 1.187413
global_step: 8832, epoch: 21, loss: 1.197927
global_step: 8833, epoch: 21, loss: 1.193715
global_step: 8834, epoch: 21, loss: 1.094365
global_step: 8835, epoch: 21, loss: 1.119052
global_step: 8836, epoch: 21, loss: 1.225596
global_step: 8837, epoch: 21, loss: 1.276632
global_step: 8838, epoch: 21, loss: 1.311608
global_step: 8839, epoch: 21, loss: 1.177652
global_step: 8840, epoch: 21, loss: 0.853690
epoch: 21
train	acc: 0.6049	macro: p 0.3980, r 0.2940, f1: 0.2929	micro: p 0.6049, r 0.6049, f1 0.6049	weighted_f1:0.5390
dev	acc: 0.5500	macro: p 0.4459, r 0.2868, f1: 0.2731	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4732
test	acc: 0.6000	macro: p 0.4568, r 0.2890, f1: 0.2845	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5317
New best model!
global_step: 8841, epoch: 22, loss: 1.242866
global_step: 8842, epoch: 22, loss: 1.142041
global_step: 8843, epoch: 22, loss: 1.196212
global_step: 8844, epoch: 22, loss: 1.305125
global_step: 8845, epoch: 22, loss: 1.278150
global_step: 8846, epoch: 22, loss: 1.190969
global_step: 8847, epoch: 22, loss: 1.113337
global_step: 8848, epoch: 22, loss: 1.169011
global_step: 8849, epoch: 22, loss: 1.180897
global_step: 8850, epoch: 22, loss: 1.139741
global_step: 8851, epoch: 22, loss: 1.213398
global_step: 8852, epoch: 22, loss: 1.129993
global_step: 8853, epoch: 22, loss: 1.323064
global_step: 8854, epoch: 22, loss: 1.261416
global_step: 8855, epoch: 22, loss: 1.118782
global_step: 8856, epoch: 22, loss: 1.157813
global_step: 8857, epoch: 22, loss: 1.194291
global_step: 8858, epoch: 22, loss: 1.083658
global_step: 8859, epoch: 22, loss: 1.282323
global_step: 8860, epoch: 22, loss: 1.132371
global_step: 8861, epoch: 22, loss: 1.129776
global_step: 8862, epoch: 22, loss: 1.099482
global_step: 8863, epoch: 22, loss: 1.175049
global_step: 8864, epoch: 22, loss: 1.190221
global_step: 8865, epoch: 22, loss: 1.195322
global_step: 8866, epoch: 22, loss: 1.189260
global_step: 8867, epoch: 22, loss: 1.227039
global_step: 8868, epoch: 22, loss: 1.138304
global_step: 8869, epoch: 22, loss: 1.073823
global_step: 8870, epoch: 22, loss: 1.106105
global_step: 8871, epoch: 22, loss: 1.226287
global_step: 8872, epoch: 22, loss: 1.265646
global_step: 8873, epoch: 22, loss: 1.273725
global_step: 8874, epoch: 22, loss: 1.152853
global_step: 8875, epoch: 22, loss: 1.194595
global_step: 8876, epoch: 22, loss: 1.237771
global_step: 8877, epoch: 22, loss: 1.259757
global_step: 8878, epoch: 22, loss: 1.164745
global_step: 8879, epoch: 22, loss: 1.252842
global_step: 8880, epoch: 22, loss: 0.903071
epoch: 22
train	acc: 0.6134	macro: p 0.4001, r 0.3091, f1: 0.3060	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5537
dev	acc: 0.5537	macro: p 0.3715, r 0.2962, f1: 0.2812	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4819
test	acc: 0.5981	macro: p 0.3903, r 0.2984, f1: 0.2914	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5373
New best model!
global_step: 8881, epoch: 23, loss: 1.230726
global_step: 8882, epoch: 23, loss: 1.182377
global_step: 8883, epoch: 23, loss: 1.212690
global_step: 8884, epoch: 23, loss: 1.185276
global_step: 8885, epoch: 23, loss: 1.265611
global_step: 8886, epoch: 23, loss: 1.129465
global_step: 8887, epoch: 23, loss: 1.236133
global_step: 8888, epoch: 23, loss: 1.115052
global_step: 8889, epoch: 23, loss: 1.077202
global_step: 8890, epoch: 23, loss: 1.243498
global_step: 8891, epoch: 23, loss: 1.108096
global_step: 8892, epoch: 23, loss: 1.213663
global_step: 8893, epoch: 23, loss: 1.198323
global_step: 8894, epoch: 23, loss: 1.133289
global_step: 8895, epoch: 23, loss: 1.204528
global_step: 8896, epoch: 23, loss: 1.201200
global_step: 8897, epoch: 23, loss: 1.169228
global_step: 8898, epoch: 23, loss: 1.155722
global_step: 8899, epoch: 23, loss: 1.237266
global_step: 8900, epoch: 23, loss: 1.277483
global_step: 8901, epoch: 23, loss: 1.064902
global_step: 8902, epoch: 23, loss: 1.156499
global_step: 8903, epoch: 23, loss: 1.170305
global_step: 8904, epoch: 23, loss: 1.177646
global_step: 8905, epoch: 23, loss: 1.260858
global_step: 8906, epoch: 23, loss: 1.170361
global_step: 8907, epoch: 23, loss: 1.149659
global_step: 8908, epoch: 23, loss: 1.224199
global_step: 8909, epoch: 23, loss: 1.174046
global_step: 8910, epoch: 23, loss: 1.259732
global_step: 8911, epoch: 23, loss: 1.162807
global_step: 8912, epoch: 23, loss: 1.259054
global_step: 8913, epoch: 23, loss: 1.112658
global_step: 8914, epoch: 23, loss: 1.102006
global_step: 8915, epoch: 23, loss: 1.143158
global_step: 8916, epoch: 23, loss: 1.166460
global_step: 8917, epoch: 23, loss: 1.273090
global_step: 8918, epoch: 23, loss: 1.164157
global_step: 8919, epoch: 23, loss: 1.195329
global_step: 8920, epoch: 23, loss: 1.315451
epoch: 23
train	acc: 0.6143	macro: p 0.3736, r 0.3070, f1: 0.3036	micro: p 0.6143, r 0.6143, f1 0.6143	weighted_f1:0.5522
dev	acc: 0.5473	macro: p 0.4320, r 0.2875, f1: 0.2690	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4704
test	acc: 0.6031	macro: p 0.3804, r 0.2986, f1: 0.2905	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5386
global_step: 8921, epoch: 24, loss: 1.137587
global_step: 8922, epoch: 24, loss: 1.240066
global_step: 8923, epoch: 24, loss: 1.288263
global_step: 8924, epoch: 24, loss: 1.098420
global_step: 8925, epoch: 24, loss: 1.056005
global_step: 8926, epoch: 24, loss: 1.239732
global_step: 8927, epoch: 24, loss: 1.155522
global_step: 8928, epoch: 24, loss: 1.052678
global_step: 8929, epoch: 24, loss: 1.280507
global_step: 8930, epoch: 24, loss: 1.142820
global_step: 8931, epoch: 24, loss: 1.346221
global_step: 8932, epoch: 24, loss: 1.167524
global_step: 8933, epoch: 24, loss: 1.223708
global_step: 8934, epoch: 24, loss: 1.086109
global_step: 8935, epoch: 24, loss: 1.038812
global_step: 8936, epoch: 24, loss: 1.142893
global_step: 8937, epoch: 24, loss: 1.114018
global_step: 8938, epoch: 24, loss: 1.198173
global_step: 8939, epoch: 24, loss: 1.210827
global_step: 8940, epoch: 24, loss: 1.173306
global_step: 8941, epoch: 24, loss: 1.092517
global_step: 8942, epoch: 24, loss: 1.148485
global_step: 8943, epoch: 24, loss: 1.191879
global_step: 8944, epoch: 24, loss: 1.255012
global_step: 8945, epoch: 24, loss: 1.188087
global_step: 8946, epoch: 24, loss: 1.214453
global_step: 8947, epoch: 24, loss: 1.183653
global_step: 8948, epoch: 24, loss: 1.135065
global_step: 8949, epoch: 24, loss: 1.111763
global_step: 8950, epoch: 24, loss: 1.201875
global_step: 8951, epoch: 24, loss: 1.239475
global_step: 8952, epoch: 24, loss: 1.130412
global_step: 8953, epoch: 24, loss: 1.215056
global_step: 8954, epoch: 24, loss: 1.226329
global_step: 8955, epoch: 24, loss: 1.154328
global_step: 8956, epoch: 24, loss: 1.230021
global_step: 8957, epoch: 24, loss: 1.222340
global_step: 8958, epoch: 24, loss: 1.083228
global_step: 8959, epoch: 24, loss: 1.147927
global_step: 8960, epoch: 24, loss: 0.889952
epoch: 24
train	acc: 0.6159	macro: p 0.4035, r 0.3074, f1: 0.3052	micro: p 0.6159, r 0.6159, f1 0.6159	weighted_f1:0.5535
dev	acc: 0.5482	macro: p 0.4401, r 0.2878, f1: 0.2717	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4721
test	acc: 0.6046	macro: p 0.4574, r 0.2977, f1: 0.2912	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5397
global_step: 8961, epoch: 25, loss: 1.197180
global_step: 8962, epoch: 25, loss: 1.127111
global_step: 8963, epoch: 25, loss: 1.108946
global_step: 8964, epoch: 25, loss: 1.035520
global_step: 8965, epoch: 25, loss: 1.300853
global_step: 8966, epoch: 25, loss: 1.170593
global_step: 8967, epoch: 25, loss: 1.078228
global_step: 8968, epoch: 25, loss: 1.194871
global_step: 8969, epoch: 25, loss: 1.223196
global_step: 8970, epoch: 25, loss: 1.136881
global_step: 8971, epoch: 25, loss: 1.142200
global_step: 8972, epoch: 25, loss: 1.191274
global_step: 8973, epoch: 25, loss: 1.205332
global_step: 8974, epoch: 25, loss: 1.134222
global_step: 8975, epoch: 25, loss: 1.120594
global_step: 8976, epoch: 25, loss: 1.185944
global_step: 8977, epoch: 25, loss: 1.210855
global_step: 8978, epoch: 25, loss: 1.121021
global_step: 8979, epoch: 25, loss: 1.153270
global_step: 8980, epoch: 25, loss: 1.172789
global_step: 8981, epoch: 25, loss: 1.222667
global_step: 8982, epoch: 25, loss: 1.215152
global_step: 8983, epoch: 25, loss: 1.223467
global_step: 8984, epoch: 25, loss: 1.144256
global_step: 8985, epoch: 25, loss: 1.120387
global_step: 8986, epoch: 25, loss: 1.029987
global_step: 8987, epoch: 25, loss: 1.268674
global_step: 8988, epoch: 25, loss: 1.153030
global_step: 8989, epoch: 25, loss: 1.184150
global_step: 8990, epoch: 25, loss: 1.084901
global_step: 8991, epoch: 25, loss: 1.086061
global_step: 8992, epoch: 25, loss: 1.229182
global_step: 8993, epoch: 25, loss: 1.185811
global_step: 8994, epoch: 25, loss: 1.112017
global_step: 8995, epoch: 25, loss: 1.099057
global_step: 8996, epoch: 25, loss: 1.228113
global_step: 8997, epoch: 25, loss: 1.244268
global_step: 8998, epoch: 25, loss: 1.265170
global_step: 8999, epoch: 25, loss: 1.120820
global_step: 9000, epoch: 25, loss: 0.510462
epoch: 25
train	acc: 0.6153	macro: p 0.3939, r 0.3040, f1: 0.3017	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5506
dev	acc: 0.5473	macro: p 0.3674, r 0.2854, f1: 0.2666	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4682
test	acc: 0.6038	macro: p 0.4113, r 0.2956, f1: 0.2878	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5361
global_step: 9001, epoch: 26, loss: 1.153440
global_step: 9002, epoch: 26, loss: 1.235213
global_step: 9003, epoch: 26, loss: 1.102171
global_step: 9004, epoch: 26, loss: 1.175002
global_step: 9005, epoch: 26, loss: 1.154519
global_step: 9006, epoch: 26, loss: 1.044908
global_step: 9007, epoch: 26, loss: 1.199305
global_step: 9008, epoch: 26, loss: 1.120773
global_step: 9009, epoch: 26, loss: 1.206772
global_step: 9010, epoch: 26, loss: 1.170158
global_step: 9011, epoch: 26, loss: 1.216588
global_step: 9012, epoch: 26, loss: 1.224234
global_step: 9013, epoch: 26, loss: 1.139868
global_step: 9014, epoch: 26, loss: 1.116355
global_step: 9015, epoch: 26, loss: 0.973561
global_step: 9016, epoch: 26, loss: 1.108754
global_step: 9017, epoch: 26, loss: 1.175084
global_step: 9018, epoch: 26, loss: 1.129023
global_step: 9019, epoch: 26, loss: 1.180133
global_step: 9020, epoch: 26, loss: 1.083637
global_step: 9021, epoch: 26, loss: 1.185779
global_step: 9022, epoch: 26, loss: 1.122915
global_step: 9023, epoch: 26, loss: 1.120841
global_step: 9024, epoch: 26, loss: 1.184787
global_step: 9025, epoch: 26, loss: 1.133434
global_step: 9026, epoch: 26, loss: 1.116664
global_step: 9027, epoch: 26, loss: 1.111373
global_step: 9028, epoch: 26, loss: 1.101799
global_step: 9029, epoch: 26, loss: 1.217241
global_step: 9030, epoch: 26, loss: 1.209764
global_step: 9031, epoch: 26, loss: 1.141294
global_step: 9032, epoch: 26, loss: 1.244274
global_step: 9033, epoch: 26, loss: 1.142471
global_step: 9034, epoch: 26, loss: 1.145379
global_step: 9035, epoch: 26, loss: 1.120171
global_step: 9036, epoch: 26, loss: 1.225954
global_step: 9037, epoch: 26, loss: 1.213196
global_step: 9038, epoch: 26, loss: 1.130089
global_step: 9039, epoch: 26, loss: 1.171429
global_step: 9040, epoch: 26, loss: 0.924873
epoch: 26
train	acc: 0.6232	macro: p 0.4086, r 0.3225, f1: 0.3224	micro: p 0.6232, r 0.6232, f1 0.6232	weighted_f1:0.5675
dev	acc: 0.5491	macro: p 0.3211, r 0.2911, f1: 0.2806	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4811
test	acc: 0.6111	macro: p 0.4160, r 0.3101, f1: 0.3097	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5539
global_step: 9041, epoch: 27, loss: 1.163484
global_step: 9042, epoch: 27, loss: 1.107934
global_step: 9043, epoch: 27, loss: 1.117512
global_step: 9044, epoch: 27, loss: 1.169347
global_step: 9045, epoch: 27, loss: 1.230566
global_step: 9046, epoch: 27, loss: 1.231403
global_step: 9047, epoch: 27, loss: 1.169008
global_step: 9048, epoch: 27, loss: 1.143341
global_step: 9049, epoch: 27, loss: 1.194454
global_step: 9050, epoch: 27, loss: 1.186910
global_step: 9051, epoch: 27, loss: 1.173324
global_step: 9052, epoch: 27, loss: 1.084279
global_step: 9053, epoch: 27, loss: 1.147990
global_step: 9054, epoch: 27, loss: 1.072559
global_step: 9055, epoch: 27, loss: 1.171797
global_step: 9056, epoch: 27, loss: 1.011212
global_step: 9057, epoch: 27, loss: 1.043691
global_step: 9058, epoch: 27, loss: 1.075005
global_step: 9059, epoch: 27, loss: 1.243154
global_step: 9060, epoch: 27, loss: 1.142494
global_step: 9061, epoch: 27, loss: 1.150975
global_step: 9062, epoch: 27, loss: 1.103868
global_step: 9063, epoch: 27, loss: 1.115932
global_step: 9064, epoch: 27, loss: 1.188806
global_step: 9065, epoch: 27, loss: 1.197276
global_step: 9066, epoch: 27, loss: 1.165763
global_step: 9067, epoch: 27, loss: 1.228634
global_step: 9068, epoch: 27, loss: 1.062193
global_step: 9069, epoch: 27, loss: 1.107903
global_step: 9070, epoch: 27, loss: 1.193600
global_step: 9071, epoch: 27, loss: 1.107100
global_step: 9072, epoch: 27, loss: 0.992501
global_step: 9073, epoch: 27, loss: 1.116524
global_step: 9074, epoch: 27, loss: 1.008492
global_step: 9075, epoch: 27, loss: 1.152741
global_step: 9076, epoch: 27, loss: 1.205563
global_step: 9077, epoch: 27, loss: 1.184187
global_step: 9078, epoch: 27, loss: 1.114915
global_step: 9079, epoch: 27, loss: 1.204985
global_step: 9080, epoch: 27, loss: 1.194267
epoch: 27
train	acc: 0.6352	macro: p 0.4158, r 0.3420, f1: 0.3415	micro: p 0.6352, r 0.6352, f1 0.6352	weighted_f1:0.5862
dev	acc: 0.5654	macro: p 0.3544, r 0.3120, f1: 0.3016	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5029
test	acc: 0.6073	macro: p 0.3963, r 0.3153, f1: 0.3104	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5542
New best model!
global_step: 9081, epoch: 28, loss: 1.205419
global_step: 9082, epoch: 28, loss: 1.174778
global_step: 9083, epoch: 28, loss: 1.167927
global_step: 9084, epoch: 28, loss: 1.140180
global_step: 9085, epoch: 28, loss: 0.994337
global_step: 9086, epoch: 28, loss: 1.095034
global_step: 9087, epoch: 28, loss: 1.026088
global_step: 9088, epoch: 28, loss: 1.128313
global_step: 9089, epoch: 28, loss: 1.118587
global_step: 9090, epoch: 28, loss: 1.125817
global_step: 9091, epoch: 28, loss: 1.147567
global_step: 9092, epoch: 28, loss: 1.257504
global_step: 9093, epoch: 28, loss: 1.193908
global_step: 9094, epoch: 28, loss: 1.072711
global_step: 9095, epoch: 28, loss: 1.087819
global_step: 9096, epoch: 28, loss: 1.081779
global_step: 9097, epoch: 28, loss: 1.231454
global_step: 9098, epoch: 28, loss: 1.139958
global_step: 9099, epoch: 28, loss: 1.110744
global_step: 9100, epoch: 28, loss: 1.139883
global_step: 9101, epoch: 28, loss: 1.143428
global_step: 9102, epoch: 28, loss: 1.173661
global_step: 9103, epoch: 28, loss: 1.155087
global_step: 9104, epoch: 28, loss: 1.158219
global_step: 9105, epoch: 28, loss: 1.237679
global_step: 9106, epoch: 28, loss: 1.062682
global_step: 9107, epoch: 28, loss: 1.232874
global_step: 9108, epoch: 28, loss: 1.184238
global_step: 9109, epoch: 28, loss: 1.065914
global_step: 9110, epoch: 28, loss: 1.127908
global_step: 9111, epoch: 28, loss: 1.100291
global_step: 9112, epoch: 28, loss: 1.036257
global_step: 9113, epoch: 28, loss: 1.143410
global_step: 9114, epoch: 28, loss: 1.159305
global_step: 9115, epoch: 28, loss: 1.129092
global_step: 9116, epoch: 28, loss: 1.168240
global_step: 9117, epoch: 28, loss: 1.166446
global_step: 9118, epoch: 28, loss: 1.064424
global_step: 9119, epoch: 28, loss: 1.076906
global_step: 9120, epoch: 28, loss: 1.082527
epoch: 28
train	acc: 0.6318	macro: p 0.4242, r 0.3306, f1: 0.3333	micro: p 0.6318, r 0.6318, f1 0.6318	weighted_f1:0.5777
dev	acc: 0.5654	macro: p 0.3666, r 0.3098, f1: 0.2999	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5002
test	acc: 0.6107	macro: p 0.4046, r 0.3122, f1: 0.3108	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5543
global_step: 9121, epoch: 29, loss: 1.260793
global_step: 9122, epoch: 29, loss: 1.069753
global_step: 9123, epoch: 29, loss: 1.124946
global_step: 9124, epoch: 29, loss: 1.078171
global_step: 9125, epoch: 29, loss: 1.115232
global_step: 9126, epoch: 29, loss: 1.058745
global_step: 9127, epoch: 29, loss: 1.146533
global_step: 9128, epoch: 29, loss: 1.116298
global_step: 9129, epoch: 29, loss: 1.076955
global_step: 9130, epoch: 29, loss: 1.154054
global_step: 9131, epoch: 29, loss: 0.996584
global_step: 9132, epoch: 29, loss: 1.074396
global_step: 9133, epoch: 29, loss: 1.084314
global_step: 9134, epoch: 29, loss: 0.995727
global_step: 9135, epoch: 29, loss: 1.068244
global_step: 9136, epoch: 29, loss: 1.136593
global_step: 9137, epoch: 29, loss: 1.207963
global_step: 9138, epoch: 29, loss: 1.092344
global_step: 9139, epoch: 29, loss: 1.142842
global_step: 9140, epoch: 29, loss: 1.084814
global_step: 9141, epoch: 29, loss: 1.113559
global_step: 9142, epoch: 29, loss: 1.189751
global_step: 9143, epoch: 29, loss: 1.166296
global_step: 9144, epoch: 29, loss: 1.143419
global_step: 9145, epoch: 29, loss: 1.176234
global_step: 9146, epoch: 29, loss: 1.160122
global_step: 9147, epoch: 29, loss: 1.209005
global_step: 9148, epoch: 29, loss: 1.164941
global_step: 9149, epoch: 29, loss: 1.146720
global_step: 9150, epoch: 29, loss: 1.155176
global_step: 9151, epoch: 29, loss: 1.093826
global_step: 9152, epoch: 29, loss: 1.033134
global_step: 9153, epoch: 29, loss: 1.106892
global_step: 9154, epoch: 29, loss: 1.167350
global_step: 9155, epoch: 29, loss: 1.139175
global_step: 9156, epoch: 29, loss: 1.189768
global_step: 9157, epoch: 29, loss: 1.119604
global_step: 9158, epoch: 29, loss: 1.157700
global_step: 9159, epoch: 29, loss: 1.064325
global_step: 9160, epoch: 29, loss: 1.938607
epoch: 29
train	acc: 0.6360	macro: p 0.4118, r 0.3363, f1: 0.3390	micro: p 0.6360, r 0.6360, f1 0.6360	weighted_f1:0.5839
dev	acc: 0.5645	macro: p 0.3730, r 0.3117, f1: 0.3014	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5015
test	acc: 0.6088	macro: p 0.3984, r 0.3134, f1: 0.3102	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5535
global_step: 9161, epoch: 30, loss: 1.051236
global_step: 9162, epoch: 30, loss: 1.179404
global_step: 9163, epoch: 30, loss: 1.223626
global_step: 9164, epoch: 30, loss: 1.109378
global_step: 9165, epoch: 30, loss: 1.230284
global_step: 9166, epoch: 30, loss: 0.985707
global_step: 9167, epoch: 30, loss: 1.165799
global_step: 9168, epoch: 30, loss: 1.093792
global_step: 9169, epoch: 30, loss: 1.137180
global_step: 9170, epoch: 30, loss: 1.113156
global_step: 9171, epoch: 30, loss: 1.103894
global_step: 9172, epoch: 30, loss: 1.046615
global_step: 9173, epoch: 30, loss: 1.172979
global_step: 9174, epoch: 30, loss: 1.197539
global_step: 9175, epoch: 30, loss: 1.061928
global_step: 9176, epoch: 30, loss: 1.159719
global_step: 9177, epoch: 30, loss: 1.141123
global_step: 9178, epoch: 30, loss: 1.091534
global_step: 9179, epoch: 30, loss: 1.138997
global_step: 9180, epoch: 30, loss: 1.217374
global_step: 9181, epoch: 30, loss: 1.090391
global_step: 9182, epoch: 30, loss: 1.154287
global_step: 9183, epoch: 30, loss: 1.051388
global_step: 9184, epoch: 30, loss: 1.101252
global_step: 9185, epoch: 30, loss: 1.069850
global_step: 9186, epoch: 30, loss: 1.168921
global_step: 9187, epoch: 30, loss: 1.142049
global_step: 9188, epoch: 30, loss: 1.071859
global_step: 9189, epoch: 30, loss: 0.965448
global_step: 9190, epoch: 30, loss: 1.049876
global_step: 9191, epoch: 30, loss: 1.103124
global_step: 9192, epoch: 30, loss: 1.077634
global_step: 9193, epoch: 30, loss: 1.076009
global_step: 9194, epoch: 30, loss: 1.178990
global_step: 9195, epoch: 30, loss: 1.049602
global_step: 9196, epoch: 30, loss: 1.107448
global_step: 9197, epoch: 30, loss: 1.191760
global_step: 9198, epoch: 30, loss: 1.147778
global_step: 9199, epoch: 30, loss: 0.996586
global_step: 9200, epoch: 30, loss: 0.385558
epoch: 30
train	acc: 0.6303	macro: p 0.4228, r 0.3218, f1: 0.3235	micro: p 0.6303, r 0.6303, f1 0.6303	weighted_f1:0.5708
dev	acc: 0.5555	macro: p 0.3603, r 0.2955, f1: 0.2810	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4816
test	acc: 0.6069	macro: p 0.4024, r 0.3028, f1: 0.2979	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5433
global_step: 9201, epoch: 31, loss: 1.093405
global_step: 9202, epoch: 31, loss: 1.088037
global_step: 9203, epoch: 31, loss: 1.192342
global_step: 9204, epoch: 31, loss: 1.045708
global_step: 9205, epoch: 31, loss: 1.156198
global_step: 9206, epoch: 31, loss: 1.004304
global_step: 9207, epoch: 31, loss: 1.183155
global_step: 9208, epoch: 31, loss: 1.139753
global_step: 9209, epoch: 31, loss: 1.174157
global_step: 9210, epoch: 31, loss: 1.031460
global_step: 9211, epoch: 31, loss: 1.108327
global_step: 9212, epoch: 31, loss: 1.085837
global_step: 9213, epoch: 31, loss: 1.035656
global_step: 9214, epoch: 31, loss: 1.063673
global_step: 9215, epoch: 31, loss: 1.145750
global_step: 9216, epoch: 31, loss: 1.168916
global_step: 9217, epoch: 31, loss: 1.042875
global_step: 9218, epoch: 31, loss: 1.091513
global_step: 9219, epoch: 31, loss: 1.053394
global_step: 9220, epoch: 31, loss: 1.153273
global_step: 9221, epoch: 31, loss: 1.042520
global_step: 9222, epoch: 31, loss: 1.045623
global_step: 9223, epoch: 31, loss: 1.063725
global_step: 9224, epoch: 31, loss: 1.124923
global_step: 9225, epoch: 31, loss: 1.169495
global_step: 9226, epoch: 31, loss: 1.071903
global_step: 9227, epoch: 31, loss: 1.103462
global_step: 9228, epoch: 31, loss: 1.045709
global_step: 9229, epoch: 31, loss: 1.152166
global_step: 9230, epoch: 31, loss: 1.122369
global_step: 9231, epoch: 31, loss: 1.188887
global_step: 9232, epoch: 31, loss: 1.176809
global_step: 9233, epoch: 31, loss: 1.144358
global_step: 9234, epoch: 31, loss: 1.086852
global_step: 9235, epoch: 31, loss: 1.117320
global_step: 9236, epoch: 31, loss: 1.094036
global_step: 9237, epoch: 31, loss: 1.072570
global_step: 9238, epoch: 31, loss: 1.103165
global_step: 9239, epoch: 31, loss: 1.144579
global_step: 9240, epoch: 31, loss: 0.929430
epoch: 31
train	acc: 0.6477	macro: p 0.4103, r 0.3519, f1: 0.3540	micro: p 0.6477, r 0.6477, f1 0.6477	weighted_f1:0.5985
dev	acc: 0.5780	macro: p 0.3912, r 0.3265, f1: 0.3196	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5186
test	acc: 0.6115	macro: p 0.4031, r 0.3219, f1: 0.3180	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5588
New best model!
global_step: 9241, epoch: 32, loss: 1.147661
global_step: 9242, epoch: 32, loss: 1.106220
global_step: 9243, epoch: 32, loss: 1.077275
global_step: 9244, epoch: 32, loss: 1.056625
global_step: 9245, epoch: 32, loss: 1.048862
global_step: 9246, epoch: 32, loss: 1.161754
global_step: 9247, epoch: 32, loss: 1.106732
global_step: 9248, epoch: 32, loss: 1.025637
global_step: 9249, epoch: 32, loss: 1.147191
global_step: 9250, epoch: 32, loss: 1.051613
global_step: 9251, epoch: 32, loss: 1.019489
global_step: 9252, epoch: 32, loss: 1.016504
global_step: 9253, epoch: 32, loss: 1.222278
global_step: 9254, epoch: 32, loss: 1.085430
global_step: 9255, epoch: 32, loss: 1.152716
global_step: 9256, epoch: 32, loss: 1.144379
global_step: 9257, epoch: 32, loss: 1.114172
global_step: 9258, epoch: 32, loss: 1.131233
global_step: 9259, epoch: 32, loss: 1.102046
global_step: 9260, epoch: 32, loss: 1.122288
global_step: 9261, epoch: 32, loss: 1.031758
global_step: 9262, epoch: 32, loss: 1.142274
global_step: 9263, epoch: 32, loss: 1.073559
global_step: 9264, epoch: 32, loss: 1.110759
global_step: 9265, epoch: 32, loss: 1.124548
global_step: 9266, epoch: 32, loss: 1.072046
global_step: 9267, epoch: 32, loss: 1.067334
global_step: 9268, epoch: 32, loss: 0.964376
global_step: 9269, epoch: 32, loss: 1.131958
global_step: 9270, epoch: 32, loss: 1.110927
global_step: 9271, epoch: 32, loss: 1.066451
global_step: 9272, epoch: 32, loss: 1.092147
global_step: 9273, epoch: 32, loss: 1.105079
global_step: 9274, epoch: 32, loss: 1.196550
global_step: 9275, epoch: 32, loss: 1.083655
global_step: 9276, epoch: 32, loss: 1.079607
global_step: 9277, epoch: 32, loss: 1.014020
global_step: 9278, epoch: 32, loss: 1.147679
global_step: 9279, epoch: 32, loss: 1.065496
global_step: 9280, epoch: 32, loss: 1.797423
epoch: 32
train	acc: 0.6537	macro: p 0.4170, r 0.3643, f1: 0.3677	micro: p 0.6537, r 0.6537, f1 0.6537	weighted_f1:0.6101
dev	acc: 0.5816	macro: p 0.3980, r 0.3324, f1: 0.3291	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5280
test	acc: 0.6103	macro: p 0.3766, r 0.3247, f1: 0.3226	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5626
New best model!
global_step: 9281, epoch: 33, loss: 1.097216
global_step: 9282, epoch: 33, loss: 1.091780
global_step: 9283, epoch: 33, loss: 1.055328
global_step: 9284, epoch: 33, loss: 1.134573
global_step: 9285, epoch: 33, loss: 1.024063
global_step: 9286, epoch: 33, loss: 1.132113
global_step: 9287, epoch: 33, loss: 1.133035
global_step: 9288, epoch: 33, loss: 1.001847
global_step: 9289, epoch: 33, loss: 1.095038
global_step: 9290, epoch: 33, loss: 0.948342
global_step: 9291, epoch: 33, loss: 1.067488
global_step: 9292, epoch: 33, loss: 1.072902
global_step: 9293, epoch: 33, loss: 1.055491
global_step: 9294, epoch: 33, loss: 1.067482
global_step: 9295, epoch: 33, loss: 0.939419
global_step: 9296, epoch: 33, loss: 0.962204
global_step: 9297, epoch: 33, loss: 1.259525
global_step: 9298, epoch: 33, loss: 1.122847
global_step: 9299, epoch: 33, loss: 1.098507
global_step: 9300, epoch: 33, loss: 1.007699
global_step: 9301, epoch: 33, loss: 1.182302
global_step: 9302, epoch: 33, loss: 1.121912
global_step: 9303, epoch: 33, loss: 1.030711
global_step: 9304, epoch: 33, loss: 1.050961
global_step: 9305, epoch: 33, loss: 1.167484
global_step: 9306, epoch: 33, loss: 1.150005
global_step: 9307, epoch: 33, loss: 1.180145
global_step: 9308, epoch: 33, loss: 1.156326
global_step: 9309, epoch: 33, loss: 1.132811
global_step: 9310, epoch: 33, loss: 1.046486
global_step: 9311, epoch: 33, loss: 1.100055
global_step: 9312, epoch: 33, loss: 1.156869
global_step: 9313, epoch: 33, loss: 1.126248
global_step: 9314, epoch: 33, loss: 1.115773
global_step: 9315, epoch: 33, loss: 1.171404
global_step: 9316, epoch: 33, loss: 1.128978
global_step: 9317, epoch: 33, loss: 1.142430
global_step: 9318, epoch: 33, loss: 1.063962
global_step: 9319, epoch: 33, loss: 1.114950
global_step: 9320, epoch: 33, loss: 1.432469
epoch: 33
train	acc: 0.6436	macro: p 0.4326, r 0.3407, f1: 0.3475	micro: p 0.6436, r 0.6436, f1 0.6436	weighted_f1:0.5904
dev	acc: 0.5735	macro: p 0.4018, r 0.3167, f1: 0.3145	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5116
test	acc: 0.6130	macro: p 0.3963, r 0.3117, f1: 0.3127	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5553
global_step: 9321, epoch: 34, loss: 1.094192
global_step: 9322, epoch: 34, loss: 1.130152
global_step: 9323, epoch: 34, loss: 1.046224
global_step: 9324, epoch: 34, loss: 1.074964
global_step: 9325, epoch: 34, loss: 1.106746
global_step: 9326, epoch: 34, loss: 1.069328
global_step: 9327, epoch: 34, loss: 1.172115
global_step: 9328, epoch: 34, loss: 0.944917
global_step: 9329, epoch: 34, loss: 1.089605
global_step: 9330, epoch: 34, loss: 0.968354
global_step: 9331, epoch: 34, loss: 1.055780
global_step: 9332, epoch: 34, loss: 1.070671
global_step: 9333, epoch: 34, loss: 1.042495
global_step: 9334, epoch: 34, loss: 1.097013
global_step: 9335, epoch: 34, loss: 1.034695
global_step: 9336, epoch: 34, loss: 1.027692
global_step: 9337, epoch: 34, loss: 1.079762
global_step: 9338, epoch: 34, loss: 0.975332
global_step: 9339, epoch: 34, loss: 0.962882
global_step: 9340, epoch: 34, loss: 1.152810
global_step: 9341, epoch: 34, loss: 1.161563
global_step: 9342, epoch: 34, loss: 1.063881
global_step: 9343, epoch: 34, loss: 1.147949
global_step: 9344, epoch: 34, loss: 1.069782
global_step: 9345, epoch: 34, loss: 1.203117
global_step: 9346, epoch: 34, loss: 1.047725
global_step: 9347, epoch: 34, loss: 1.125250
global_step: 9348, epoch: 34, loss: 1.201491
global_step: 9349, epoch: 34, loss: 1.073102
global_step: 9350, epoch: 34, loss: 1.052426
global_step: 9351, epoch: 34, loss: 1.201044
global_step: 9352, epoch: 34, loss: 1.102415
global_step: 9353, epoch: 34, loss: 1.062461
global_step: 9354, epoch: 34, loss: 1.080271
global_step: 9355, epoch: 34, loss: 1.082249
global_step: 9356, epoch: 34, loss: 1.038334
global_step: 9357, epoch: 34, loss: 1.039596
global_step: 9358, epoch: 34, loss: 1.036637
global_step: 9359, epoch: 34, loss: 1.101277
global_step: 9360, epoch: 34, loss: 0.948342
epoch: 34
train	acc: 0.6489	macro: p 0.4155, r 0.3476, f1: 0.3550	micro: p 0.6489, r 0.6489, f1 0.6489	weighted_f1:0.5983
dev	acc: 0.5735	macro: p 0.3918, r 0.3190, f1: 0.3158	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5133
test	acc: 0.6134	macro: p 0.3876, r 0.3163, f1: 0.3182	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5590
global_step: 9361, epoch: 35, loss: 1.127003
global_step: 9362, epoch: 35, loss: 1.055288
global_step: 9363, epoch: 35, loss: 1.057621
global_step: 9364, epoch: 35, loss: 1.164037
global_step: 9365, epoch: 35, loss: 1.105419
global_step: 9366, epoch: 35, loss: 1.044196
global_step: 9367, epoch: 35, loss: 1.018709
global_step: 9368, epoch: 35, loss: 1.060184
global_step: 9369, epoch: 35, loss: 1.089838
global_step: 9370, epoch: 35, loss: 1.096984
global_step: 9371, epoch: 35, loss: 1.065387
global_step: 9372, epoch: 35, loss: 1.005146
global_step: 9373, epoch: 35, loss: 1.001581
global_step: 9374, epoch: 35, loss: 1.049850
global_step: 9375, epoch: 35, loss: 1.221608
global_step: 9376, epoch: 35, loss: 1.151548
global_step: 9377, epoch: 35, loss: 1.010324
global_step: 9378, epoch: 35, loss: 1.071270
global_step: 9379, epoch: 35, loss: 1.005125
global_step: 9380, epoch: 35, loss: 1.021373
global_step: 9381, epoch: 35, loss: 1.099553
global_step: 9382, epoch: 35, loss: 0.982893
global_step: 9383, epoch: 35, loss: 1.097759
global_step: 9384, epoch: 35, loss: 1.047006
global_step: 9385, epoch: 35, loss: 1.043027
global_step: 9386, epoch: 35, loss: 1.170446
global_step: 9387, epoch: 35, loss: 1.047236
global_step: 9388, epoch: 35, loss: 1.004404
global_step: 9389, epoch: 35, loss: 1.043898
global_step: 9390, epoch: 35, loss: 1.058343
global_step: 9391, epoch: 35, loss: 1.119040
global_step: 9392, epoch: 35, loss: 0.980737
global_step: 9393, epoch: 35, loss: 1.157654
global_step: 9394, epoch: 35, loss: 1.070828
global_step: 9395, epoch: 35, loss: 1.115425
global_step: 9396, epoch: 35, loss: 1.139685
global_step: 9397, epoch: 35, loss: 1.030333
global_step: 9398, epoch: 35, loss: 1.055973
global_step: 9399, epoch: 35, loss: 1.060274
global_step: 9400, epoch: 35, loss: 0.609084
epoch: 35
train	acc: 0.6510	macro: p 0.4249, r 0.3488, f1: 0.3563	micro: p 0.6510, r 0.6510, f1 0.6510	weighted_f1:0.5989
dev	acc: 0.5699	macro: p 0.3906, r 0.3147, f1: 0.3099	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5066
test	acc: 0.6126	macro: p 0.3943, r 0.3143, f1: 0.3135	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5550
global_step: 9401, epoch: 36, loss: 1.078227
global_step: 9402, epoch: 36, loss: 1.056371
global_step: 9403, epoch: 36, loss: 1.102888
global_step: 9404, epoch: 36, loss: 1.028689
global_step: 9405, epoch: 36, loss: 1.056109
global_step: 9406, epoch: 36, loss: 1.013647
global_step: 9407, epoch: 36, loss: 1.045034
global_step: 9408, epoch: 36, loss: 0.974008
global_step: 9409, epoch: 36, loss: 1.049511
global_step: 9410, epoch: 36, loss: 0.993317
global_step: 9411, epoch: 36, loss: 1.048457
global_step: 9412, epoch: 36, loss: 1.143233
global_step: 9413, epoch: 36, loss: 0.947110
global_step: 9414, epoch: 36, loss: 1.074041
global_step: 9415, epoch: 36, loss: 1.075882
global_step: 9416, epoch: 36, loss: 1.087253
global_step: 9417, epoch: 36, loss: 0.997271
global_step: 9418, epoch: 36, loss: 1.242270
global_step: 9419, epoch: 36, loss: 1.043216
global_step: 9420, epoch: 36, loss: 1.060605
global_step: 9421, epoch: 36, loss: 0.991917
global_step: 9422, epoch: 36, loss: 1.035784
global_step: 9423, epoch: 36, loss: 0.979381
global_step: 9424, epoch: 36, loss: 1.097273
global_step: 9425, epoch: 36, loss: 1.115142
global_step: 9426, epoch: 36, loss: 1.050541
global_step: 9427, epoch: 36, loss: 1.066025
global_step: 9428, epoch: 36, loss: 1.048671
global_step: 9429, epoch: 36, loss: 1.087670
global_step: 9430, epoch: 36, loss: 1.079537
global_step: 9431, epoch: 36, loss: 1.110839
global_step: 9432, epoch: 36, loss: 1.129475
global_step: 9433, epoch: 36, loss: 0.995822
global_step: 9434, epoch: 36, loss: 1.044018
global_step: 9435, epoch: 36, loss: 1.115335
global_step: 9436, epoch: 36, loss: 1.063380
global_step: 9437, epoch: 36, loss: 1.041978
global_step: 9438, epoch: 36, loss: 1.021894
global_step: 9439, epoch: 36, loss: 1.035739
global_step: 9440, epoch: 36, loss: 1.897455
epoch: 36
train	acc: 0.6682	macro: p 0.4244, r 0.3829, f1: 0.3905	micro: p 0.6682, r 0.6682, f1 0.6682	weighted_f1:0.6300
dev	acc: 0.5816	macro: p 0.3797, r 0.3361, f1: 0.3343	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5321
test	acc: 0.6130	macro: p 0.3641, r 0.3328, f1: 0.3341	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5708
New best model!
global_step: 9441, epoch: 37, loss: 0.982695
global_step: 9442, epoch: 37, loss: 1.042856
global_step: 9443, epoch: 37, loss: 1.201372
global_step: 9444, epoch: 37, loss: 0.989383
global_step: 9445, epoch: 37, loss: 1.143101
global_step: 9446, epoch: 37, loss: 1.121389
global_step: 9447, epoch: 37, loss: 1.084159
global_step: 9448, epoch: 37, loss: 1.168756
global_step: 9449, epoch: 37, loss: 1.038753
global_step: 9450, epoch: 37, loss: 1.020497
global_step: 9451, epoch: 37, loss: 1.037865
global_step: 9452, epoch: 37, loss: 0.934122
global_step: 9453, epoch: 37, loss: 0.997140
global_step: 9454, epoch: 37, loss: 0.881435
global_step: 9455, epoch: 37, loss: 0.971517
global_step: 9456, epoch: 37, loss: 1.120273
global_step: 9457, epoch: 37, loss: 0.960920
global_step: 9458, epoch: 37, loss: 1.022227
global_step: 9459, epoch: 37, loss: 1.094334
global_step: 9460, epoch: 37, loss: 1.063598
global_step: 9461, epoch: 37, loss: 1.062667
global_step: 9462, epoch: 37, loss: 1.032280
global_step: 9463, epoch: 37, loss: 0.999679
global_step: 9464, epoch: 37, loss: 1.137558
global_step: 9465, epoch: 37, loss: 0.978519
global_step: 9466, epoch: 37, loss: 0.998072
global_step: 9467, epoch: 37, loss: 1.078988
global_step: 9468, epoch: 37, loss: 0.931134
global_step: 9469, epoch: 37, loss: 1.083477
global_step: 9470, epoch: 37, loss: 1.052548
global_step: 9471, epoch: 37, loss: 1.052325
global_step: 9472, epoch: 37, loss: 1.043725
global_step: 9473, epoch: 37, loss: 1.092807
global_step: 9474, epoch: 37, loss: 1.113884
global_step: 9475, epoch: 37, loss: 1.119119
global_step: 9476, epoch: 37, loss: 1.203823
global_step: 9477, epoch: 37, loss: 1.071919
global_step: 9478, epoch: 37, loss: 1.025318
global_step: 9479, epoch: 37, loss: 1.099441
global_step: 9480, epoch: 37, loss: 0.907532
epoch: 37
train	acc: 0.6562	macro: p 0.4265, r 0.3570, f1: 0.3657	micro: p 0.6562, r 0.6562, f1 0.6562	weighted_f1:0.6082
dev	acc: 0.5690	macro: p 0.3976, r 0.3149, f1: 0.3099	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5078
test	acc: 0.6115	macro: p 0.3720, r 0.3181, f1: 0.3183	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5582
global_step: 9481, epoch: 38, loss: 0.965290
global_step: 9482, epoch: 38, loss: 1.008601
global_step: 9483, epoch: 38, loss: 1.039159
global_step: 9484, epoch: 38, loss: 1.130627
global_step: 9485, epoch: 38, loss: 0.983408
global_step: 9486, epoch: 38, loss: 1.121890
global_step: 9487, epoch: 38, loss: 1.069304
global_step: 9488, epoch: 38, loss: 0.999238
global_step: 9489, epoch: 38, loss: 1.074644
global_step: 9490, epoch: 38, loss: 1.097427
global_step: 9491, epoch: 38, loss: 1.058036
global_step: 9492, epoch: 38, loss: 1.037665
global_step: 9493, epoch: 38, loss: 0.996002
global_step: 9494, epoch: 38, loss: 1.086006
global_step: 9495, epoch: 38, loss: 0.945408
global_step: 9496, epoch: 38, loss: 1.036897
global_step: 9497, epoch: 38, loss: 0.965594
global_step: 9498, epoch: 38, loss: 1.107122
global_step: 9499, epoch: 38, loss: 0.923003
global_step: 9500, epoch: 38, loss: 1.086198
global_step: 9501, epoch: 38, loss: 1.019470
global_step: 9502, epoch: 38, loss: 1.105676
global_step: 9503, epoch: 38, loss: 1.095109
global_step: 9504, epoch: 38, loss: 1.067421
global_step: 9505, epoch: 38, loss: 0.981856
global_step: 9506, epoch: 38, loss: 1.039833
global_step: 9507, epoch: 38, loss: 1.004550
global_step: 9508, epoch: 38, loss: 1.070111
global_step: 9509, epoch: 38, loss: 1.083680
global_step: 9510, epoch: 38, loss: 1.045506
global_step: 9511, epoch: 38, loss: 1.012409
global_step: 9512, epoch: 38, loss: 1.015601
global_step: 9513, epoch: 38, loss: 0.952318
global_step: 9514, epoch: 38, loss: 1.010715
global_step: 9515, epoch: 38, loss: 1.135963
global_step: 9516, epoch: 38, loss: 1.048081
global_step: 9517, epoch: 38, loss: 1.120691
global_step: 9518, epoch: 38, loss: 1.026854
global_step: 9519, epoch: 38, loss: 1.039197
global_step: 9520, epoch: 38, loss: 0.990061
epoch: 38
train	acc: 0.6727	macro: p 0.4320, r 0.3849, f1: 0.3890	micro: p 0.6727, r 0.6727, f1 0.6727	weighted_f1:0.6310
dev	acc: 0.5906	macro: p 0.4065, r 0.3413, f1: 0.3398	micro: p 0.5906, r 0.5906, f1 0.5906	weighted_f1:0.5380
test	acc: 0.6100	macro: p 0.3627, r 0.3274, f1: 0.3254	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5643
New best model!
global_step: 9521, epoch: 39, loss: 0.939397
global_step: 9522, epoch: 39, loss: 1.109308
global_step: 9523, epoch: 39, loss: 0.940757
global_step: 9524, epoch: 39, loss: 1.103435
global_step: 9525, epoch: 39, loss: 1.115378
global_step: 9526, epoch: 39, loss: 1.096319
global_step: 9527, epoch: 39, loss: 1.054848
global_step: 9528, epoch: 39, loss: 1.034360
global_step: 9529, epoch: 39, loss: 1.045166
global_step: 9530, epoch: 39, loss: 0.936758
global_step: 9531, epoch: 39, loss: 1.053006
global_step: 9532, epoch: 39, loss: 1.088240
global_step: 9533, epoch: 39, loss: 0.997739
global_step: 9534, epoch: 39, loss: 1.002574
global_step: 9535, epoch: 39, loss: 1.040083
global_step: 9536, epoch: 39, loss: 1.007829
global_step: 9537, epoch: 39, loss: 0.988026
global_step: 9538, epoch: 39, loss: 0.916997
global_step: 9539, epoch: 39, loss: 1.074487
global_step: 9540, epoch: 39, loss: 0.959447
global_step: 9541, epoch: 39, loss: 1.028191
global_step: 9542, epoch: 39, loss: 1.031723
global_step: 9543, epoch: 39, loss: 0.971144
global_step: 9544, epoch: 39, loss: 1.070817
global_step: 9545, epoch: 39, loss: 1.074219
global_step: 9546, epoch: 39, loss: 0.924743
global_step: 9547, epoch: 39, loss: 1.039419
global_step: 9548, epoch: 39, loss: 1.118759
global_step: 9549, epoch: 39, loss: 0.968647
global_step: 9550, epoch: 39, loss: 1.138049
global_step: 9551, epoch: 39, loss: 1.030436
global_step: 9552, epoch: 39, loss: 1.131548
global_step: 9553, epoch: 39, loss: 1.123204
global_step: 9554, epoch: 39, loss: 1.041439
global_step: 9555, epoch: 39, loss: 1.014156
global_step: 9556, epoch: 39, loss: 0.973860
global_step: 9557, epoch: 39, loss: 1.065879
global_step: 9558, epoch: 39, loss: 1.079588
global_step: 9559, epoch: 39, loss: 0.981487
global_step: 9560, epoch: 39, loss: 0.387438
epoch: 39
train	acc: 0.6767	macro: p 0.4398, r 0.3886, f1: 0.3950	micro: p 0.6767, r 0.6767, f1 0.6767	weighted_f1:0.6367
dev	acc: 0.5870	macro: p 0.4041, r 0.3398, f1: 0.3390	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5363
test	acc: 0.6153	macro: p 0.3724, r 0.3320, f1: 0.3325	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5703
global_step: 9561, epoch: 40, loss: 0.941964
global_step: 9562, epoch: 40, loss: 1.019864
global_step: 9563, epoch: 40, loss: 0.997842
global_step: 9564, epoch: 40, loss: 1.078957
global_step: 9565, epoch: 40, loss: 0.962944
global_step: 9566, epoch: 40, loss: 0.963299
global_step: 9567, epoch: 40, loss: 1.038380
global_step: 9568, epoch: 40, loss: 1.087338
global_step: 9569, epoch: 40, loss: 1.060176
global_step: 9570, epoch: 40, loss: 1.108009
global_step: 9571, epoch: 40, loss: 1.023132
global_step: 9572, epoch: 40, loss: 1.027142
global_step: 9573, epoch: 40, loss: 0.921126
global_step: 9574, epoch: 40, loss: 1.039016
global_step: 9575, epoch: 40, loss: 0.982587
global_step: 9576, epoch: 40, loss: 1.087392
global_step: 9577, epoch: 40, loss: 1.041433
global_step: 9578, epoch: 40, loss: 1.027274
global_step: 9579, epoch: 40, loss: 0.946570
global_step: 9580, epoch: 40, loss: 1.128596
global_step: 9581, epoch: 40, loss: 0.902943
global_step: 9582, epoch: 40, loss: 1.022841
global_step: 9583, epoch: 40, loss: 1.020372
global_step: 9584, epoch: 40, loss: 1.072995
global_step: 9585, epoch: 40, loss: 0.886526
global_step: 9586, epoch: 40, loss: 1.053046
global_step: 9587, epoch: 40, loss: 1.001459
global_step: 9588, epoch: 40, loss: 1.024187
global_step: 9589, epoch: 40, loss: 1.066702
global_step: 9590, epoch: 40, loss: 1.007103
global_step: 9591, epoch: 40, loss: 1.093788
global_step: 9592, epoch: 40, loss: 1.133491
global_step: 9593, epoch: 40, loss: 0.987643
global_step: 9594, epoch: 40, loss: 1.014921
global_step: 9595, epoch: 40, loss: 1.002256
global_step: 9596, epoch: 40, loss: 0.999517
global_step: 9597, epoch: 40, loss: 1.023684
global_step: 9598, epoch: 40, loss: 1.059747
global_step: 9599, epoch: 40, loss: 1.102327
global_step: 9600, epoch: 40, loss: 1.058206
epoch: 40
train	acc: 0.6810	macro: p 0.4405, r 0.3893, f1: 0.3945	micro: p 0.6810, r 0.6810, f1 0.6810	weighted_f1:0.6387
dev	acc: 0.5834	macro: p 0.4020, r 0.3378, f1: 0.3341	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5310
test	acc: 0.6107	macro: p 0.3680, r 0.3262, f1: 0.3238	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5625
global_step: 9601, epoch: 41, loss: 0.980399
global_step: 9602, epoch: 41, loss: 1.092103
global_step: 9603, epoch: 41, loss: 1.046730
global_step: 9604, epoch: 41, loss: 0.977475
global_step: 9605, epoch: 41, loss: 0.964564
global_step: 9606, epoch: 41, loss: 1.089292
global_step: 9607, epoch: 41, loss: 0.964520
global_step: 9608, epoch: 41, loss: 1.033255
global_step: 9609, epoch: 41, loss: 1.049630
global_step: 9610, epoch: 41, loss: 1.011780
global_step: 9611, epoch: 41, loss: 0.928940
global_step: 9612, epoch: 41, loss: 1.086502
global_step: 9613, epoch: 41, loss: 1.074320
global_step: 9614, epoch: 41, loss: 1.031364
global_step: 9615, epoch: 41, loss: 1.040353
global_step: 9616, epoch: 41, loss: 1.079652
global_step: 9617, epoch: 41, loss: 0.955489
global_step: 9618, epoch: 41, loss: 1.054378
global_step: 9619, epoch: 41, loss: 0.993948
global_step: 9620, epoch: 41, loss: 1.019682
global_step: 9621, epoch: 41, loss: 1.218333
global_step: 9622, epoch: 41, loss: 0.950464
global_step: 9623, epoch: 41, loss: 0.975307
global_step: 9624, epoch: 41, loss: 1.034847
global_step: 9625, epoch: 41, loss: 0.948283
global_step: 9626, epoch: 41, loss: 1.070117
global_step: 9627, epoch: 41, loss: 1.034530
global_step: 9628, epoch: 41, loss: 0.941744
global_step: 9629, epoch: 41, loss: 0.955541
global_step: 9630, epoch: 41, loss: 1.031138
global_step: 9631, epoch: 41, loss: 0.948965
global_step: 9632, epoch: 41, loss: 0.978621
global_step: 9633, epoch: 41, loss: 0.937798
global_step: 9634, epoch: 41, loss: 0.980670
global_step: 9635, epoch: 41, loss: 1.034111
global_step: 9636, epoch: 41, loss: 1.053010
global_step: 9637, epoch: 41, loss: 1.036781
global_step: 9638, epoch: 41, loss: 1.040648
global_step: 9639, epoch: 41, loss: 0.909840
global_step: 9640, epoch: 41, loss: 0.960383
epoch: 41
train	acc: 0.6887	macro: p 0.4418, r 0.3999, f1: 0.4037	micro: p 0.6887, r 0.6887, f1 0.6887	weighted_f1:0.6482
dev	acc: 0.5816	macro: p 0.3861, r 0.3394, f1: 0.3328	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5304
test	acc: 0.6096	macro: p 0.3629, r 0.3324, f1: 0.3276	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5650
global_step: 9641, epoch: 42, loss: 1.013185
global_step: 9642, epoch: 42, loss: 1.048935
global_step: 9643, epoch: 42, loss: 0.978463
global_step: 9644, epoch: 42, loss: 1.032795
global_step: 9645, epoch: 42, loss: 1.172361
global_step: 9646, epoch: 42, loss: 1.077294
global_step: 9647, epoch: 42, loss: 0.968189
global_step: 9648, epoch: 42, loss: 0.951956
global_step: 9649, epoch: 42, loss: 0.959564
global_step: 9650, epoch: 42, loss: 0.921321
global_step: 9651, epoch: 42, loss: 0.831496
global_step: 9652, epoch: 42, loss: 1.240747
global_step: 9653, epoch: 42, loss: 0.913899
global_step: 9654, epoch: 42, loss: 1.007406
global_step: 9655, epoch: 42, loss: 0.896136
global_step: 9656, epoch: 42, loss: 0.963560
global_step: 9657, epoch: 42, loss: 1.086659
global_step: 9658, epoch: 42, loss: 1.004252
global_step: 9659, epoch: 42, loss: 0.969229
global_step: 9660, epoch: 42, loss: 0.839744
global_step: 9661, epoch: 42, loss: 1.054857
global_step: 9662, epoch: 42, loss: 0.910267
global_step: 9663, epoch: 42, loss: 1.010147
global_step: 9664, epoch: 42, loss: 1.059963
global_step: 9665, epoch: 42, loss: 1.017394
global_step: 9666, epoch: 42, loss: 1.085284
global_step: 9667, epoch: 42, loss: 1.012501
global_step: 9668, epoch: 42, loss: 1.034084
global_step: 9669, epoch: 42, loss: 0.967703
global_step: 9670, epoch: 42, loss: 1.040614
global_step: 9671, epoch: 42, loss: 0.980510
global_step: 9672, epoch: 42, loss: 1.012653
global_step: 9673, epoch: 42, loss: 0.933671
global_step: 9674, epoch: 42, loss: 1.088737
global_step: 9675, epoch: 42, loss: 1.000888
global_step: 9676, epoch: 42, loss: 1.018401
global_step: 9677, epoch: 42, loss: 1.124161
global_step: 9678, epoch: 42, loss: 0.966147
global_step: 9679, epoch: 42, loss: 1.024377
global_step: 9680, epoch: 42, loss: 0.845816
epoch: 42
train	acc: 0.6864	macro: p 0.4445, r 0.3983, f1: 0.4071	micro: p 0.6864, r 0.6864, f1 0.6864	weighted_f1:0.6476
dev	acc: 0.5843	macro: p 0.3795, r 0.3375, f1: 0.3370	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5347
test	acc: 0.6157	macro: p 0.3684, r 0.3335, f1: 0.3368	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5725
global_step: 9681, epoch: 43, loss: 1.036021
global_step: 9682, epoch: 43, loss: 0.969968
global_step: 9683, epoch: 43, loss: 0.904597
global_step: 9684, epoch: 43, loss: 1.017360
global_step: 9685, epoch: 43, loss: 0.989797
global_step: 9686, epoch: 43, loss: 0.949351
global_step: 9687, epoch: 43, loss: 1.006691
global_step: 9688, epoch: 43, loss: 1.094211
global_step: 9689, epoch: 43, loss: 1.078073
global_step: 9690, epoch: 43, loss: 1.006584
global_step: 9691, epoch: 43, loss: 0.896079
global_step: 9692, epoch: 43, loss: 0.889179
global_step: 9693, epoch: 43, loss: 0.829866
global_step: 9694, epoch: 43, loss: 0.925434
global_step: 9695, epoch: 43, loss: 1.051849
global_step: 9696, epoch: 43, loss: 1.048787
global_step: 9697, epoch: 43, loss: 1.056561
global_step: 9698, epoch: 43, loss: 1.028434
global_step: 9699, epoch: 43, loss: 1.051432
global_step: 9700, epoch: 43, loss: 0.959467
global_step: 9701, epoch: 43, loss: 0.959500
global_step: 9702, epoch: 43, loss: 0.987465
global_step: 9703, epoch: 43, loss: 1.032080
global_step: 9704, epoch: 43, loss: 1.080607
global_step: 9705, epoch: 43, loss: 1.059987
global_step: 9706, epoch: 43, loss: 1.051329
global_step: 9707, epoch: 43, loss: 0.953606
global_step: 9708, epoch: 43, loss: 0.949528
global_step: 9709, epoch: 43, loss: 1.011207
global_step: 9710, epoch: 43, loss: 0.947385
global_step: 9711, epoch: 43, loss: 0.933046
global_step: 9712, epoch: 43, loss: 1.095690
global_step: 9713, epoch: 43, loss: 1.113841
global_step: 9714, epoch: 43, loss: 1.066787
global_step: 9715, epoch: 43, loss: 0.898072
global_step: 9716, epoch: 43, loss: 0.986504
global_step: 9717, epoch: 43, loss: 0.976633
global_step: 9718, epoch: 43, loss: 1.022086
global_step: 9719, epoch: 43, loss: 1.043440
global_step: 9720, epoch: 43, loss: 0.867491
epoch: 43
train	acc: 0.6967	macro: p 0.4384, r 0.4245, f1: 0.4240	micro: p 0.6967, r 0.6967, f1 0.6967	weighted_f1:0.6666
dev	acc: 0.5753	macro: p 0.3643, r 0.3468, f1: 0.3397	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5352
test	acc: 0.6042	macro: p 0.3609, r 0.3464, f1: 0.3410	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5716
global_step: 9721, epoch: 44, loss: 0.956191
global_step: 9722, epoch: 44, loss: 1.019395
global_step: 9723, epoch: 44, loss: 1.085732
global_step: 9724, epoch: 44, loss: 0.923463
global_step: 9725, epoch: 44, loss: 0.943022
global_step: 9726, epoch: 44, loss: 1.036681
global_step: 9727, epoch: 44, loss: 0.981988
global_step: 9728, epoch: 44, loss: 0.989868
global_step: 9729, epoch: 44, loss: 0.971725
global_step: 9730, epoch: 44, loss: 0.923403
global_step: 9731, epoch: 44, loss: 1.048862
global_step: 9732, epoch: 44, loss: 0.979002
global_step: 9733, epoch: 44, loss: 1.074140
global_step: 9734, epoch: 44, loss: 1.035231
global_step: 9735, epoch: 44, loss: 1.015430
global_step: 9736, epoch: 44, loss: 0.969326
global_step: 9737, epoch: 44, loss: 1.038547
global_step: 9738, epoch: 44, loss: 0.980361
global_step: 9739, epoch: 44, loss: 0.960728
global_step: 9740, epoch: 44, loss: 0.987533
global_step: 9741, epoch: 44, loss: 1.012244
global_step: 9742, epoch: 44, loss: 0.970607
global_step: 9743, epoch: 44, loss: 1.013980
global_step: 9744, epoch: 44, loss: 1.058300
global_step: 9745, epoch: 44, loss: 0.998614
global_step: 9746, epoch: 44, loss: 0.939733
global_step: 9747, epoch: 44, loss: 0.940499
global_step: 9748, epoch: 44, loss: 0.967200
global_step: 9749, epoch: 44, loss: 0.995242
global_step: 9750, epoch: 44, loss: 0.964992
global_step: 9751, epoch: 44, loss: 0.972442
global_step: 9752, epoch: 44, loss: 0.986425
global_step: 9753, epoch: 44, loss: 0.946864
global_step: 9754, epoch: 44, loss: 1.002555
global_step: 9755, epoch: 44, loss: 1.030458
global_step: 9756, epoch: 44, loss: 0.998555
global_step: 9757, epoch: 44, loss: 1.058237
global_step: 9758, epoch: 44, loss: 0.901329
global_step: 9759, epoch: 44, loss: 0.981438
global_step: 9760, epoch: 44, loss: 1.060401
epoch: 44
train	acc: 0.6829	macro: p 0.4519, r 0.3875, f1: 0.4005	micro: p 0.6829, r 0.6829, f1 0.6829	weighted_f1:0.6406
dev	acc: 0.5807	macro: p 0.3913, r 0.3299, f1: 0.3307	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5266
test	acc: 0.6153	macro: p 0.3748, r 0.3243, f1: 0.3294	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5666
global_step: 9761, epoch: 45, loss: 0.948665
global_step: 9762, epoch: 45, loss: 0.978749
global_step: 9763, epoch: 45, loss: 0.925253
global_step: 9764, epoch: 45, loss: 1.114550
global_step: 9765, epoch: 45, loss: 1.091706
global_step: 9766, epoch: 45, loss: 0.928848
global_step: 9767, epoch: 45, loss: 1.047364
global_step: 9768, epoch: 45, loss: 0.992634
global_step: 9769, epoch: 45, loss: 1.009511
global_step: 9770, epoch: 45, loss: 0.949861
global_step: 9771, epoch: 45, loss: 0.964235
global_step: 9772, epoch: 45, loss: 0.961120
global_step: 9773, epoch: 45, loss: 0.907903
global_step: 9774, epoch: 45, loss: 1.007664
global_step: 9775, epoch: 45, loss: 0.927680
global_step: 9776, epoch: 45, loss: 1.045246
global_step: 9777, epoch: 45, loss: 0.957197
global_step: 9778, epoch: 45, loss: 0.945779
global_step: 9779, epoch: 45, loss: 0.904321
global_step: 9780, epoch: 45, loss: 1.023586
global_step: 9781, epoch: 45, loss: 1.056857
global_step: 9782, epoch: 45, loss: 0.961922
global_step: 9783, epoch: 45, loss: 1.059006
global_step: 9784, epoch: 45, loss: 0.923673
global_step: 9785, epoch: 45, loss: 0.906426
global_step: 9786, epoch: 45, loss: 0.946650
global_step: 9787, epoch: 45, loss: 0.981157
global_step: 9788, epoch: 45, loss: 0.962623
global_step: 9789, epoch: 45, loss: 1.006540
global_step: 9790, epoch: 45, loss: 0.982092
global_step: 9791, epoch: 45, loss: 1.015743
global_step: 9792, epoch: 45, loss: 0.901729
global_step: 9793, epoch: 45, loss: 0.977135
global_step: 9794, epoch: 45, loss: 1.005068
global_step: 9795, epoch: 45, loss: 1.027825
global_step: 9796, epoch: 45, loss: 0.913357
global_step: 9797, epoch: 45, loss: 0.925191
global_step: 9798, epoch: 45, loss: 0.869730
global_step: 9799, epoch: 45, loss: 1.103942
global_step: 9800, epoch: 45, loss: 1.616997
epoch: 45
train	acc: 0.6989	macro: p 0.4589, r 0.4102, f1: 0.4196	micro: p 0.6989, r 0.6989, f1 0.6989	weighted_f1:0.6612
dev	acc: 0.5834	macro: p 0.3832, r 0.3390, f1: 0.3373	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5344
test	acc: 0.6165	macro: p 0.3728, r 0.3335, f1: 0.3361	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5723
global_step: 9801, epoch: 46, loss: 1.017503
global_step: 9802, epoch: 46, loss: 0.909823
global_step: 9803, epoch: 46, loss: 0.946029
global_step: 9804, epoch: 46, loss: 0.963854
global_step: 9805, epoch: 46, loss: 0.887820
global_step: 9806, epoch: 46, loss: 1.055464
global_step: 9807, epoch: 46, loss: 0.940392
global_step: 9808, epoch: 46, loss: 0.941022
global_step: 9809, epoch: 46, loss: 0.931536
global_step: 9810, epoch: 46, loss: 1.055271
global_step: 9811, epoch: 46, loss: 0.923300
global_step: 9812, epoch: 46, loss: 1.043030
global_step: 9813, epoch: 46, loss: 0.940709
global_step: 9814, epoch: 46, loss: 1.006955
global_step: 9815, epoch: 46, loss: 0.975263
global_step: 9816, epoch: 46, loss: 1.040007
global_step: 9817, epoch: 46, loss: 0.996776
global_step: 9818, epoch: 46, loss: 0.984981
global_step: 9819, epoch: 46, loss: 0.959155
global_step: 9820, epoch: 46, loss: 0.955755
global_step: 9821, epoch: 46, loss: 0.852235
global_step: 9822, epoch: 46, loss: 0.978094
global_step: 9823, epoch: 46, loss: 1.044205
global_step: 9824, epoch: 46, loss: 0.867290
global_step: 9825, epoch: 46, loss: 0.955762
global_step: 9826, epoch: 46, loss: 0.929356
global_step: 9827, epoch: 46, loss: 0.988737
global_step: 9828, epoch: 46, loss: 1.000442
global_step: 9829, epoch: 46, loss: 0.924152
global_step: 9830, epoch: 46, loss: 0.997228
global_step: 9831, epoch: 46, loss: 0.889243
global_step: 9832, epoch: 46, loss: 1.029275
global_step: 9833, epoch: 46, loss: 0.949985
global_step: 9834, epoch: 46, loss: 1.063364
global_step: 9835, epoch: 46, loss: 0.997932
global_step: 9836, epoch: 46, loss: 1.009715
global_step: 9837, epoch: 46, loss: 1.078460
global_step: 9838, epoch: 46, loss: 0.976049
global_step: 9839, epoch: 46, loss: 0.935721
global_step: 9840, epoch: 46, loss: 2.051266
epoch: 46
train	acc: 0.7048	macro: p 0.4597, r 0.4182, f1: 0.4257	micro: p 0.7048, r 0.7048, f1 0.7048	weighted_f1:0.6670
dev	acc: 0.5843	macro: p 0.3803, r 0.3410, f1: 0.3395	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5354
test	acc: 0.6146	macro: p 0.3632, r 0.3349, f1: 0.3349	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5713
global_step: 9841, epoch: 47, loss: 0.895744
global_step: 9842, epoch: 47, loss: 0.977837
global_step: 9843, epoch: 47, loss: 0.993418
global_step: 9844, epoch: 47, loss: 1.003418
global_step: 9845, epoch: 47, loss: 1.005893
global_step: 9846, epoch: 47, loss: 0.923857
global_step: 9847, epoch: 47, loss: 0.866832
global_step: 9848, epoch: 47, loss: 1.018423
global_step: 9849, epoch: 47, loss: 0.997581
global_step: 9850, epoch: 47, loss: 0.983865
global_step: 9851, epoch: 47, loss: 0.922744
global_step: 9852, epoch: 47, loss: 0.928777
global_step: 9853, epoch: 47, loss: 1.043442
global_step: 9854, epoch: 47, loss: 0.866510
global_step: 9855, epoch: 47, loss: 1.045244
global_step: 9856, epoch: 47, loss: 0.987504
global_step: 9857, epoch: 47, loss: 0.914861
global_step: 9858, epoch: 47, loss: 0.934935
global_step: 9859, epoch: 47, loss: 0.877783
global_step: 9860, epoch: 47, loss: 1.082115
global_step: 9861, epoch: 47, loss: 1.065799
global_step: 9862, epoch: 47, loss: 0.935380
global_step: 9863, epoch: 47, loss: 0.932219
global_step: 9864, epoch: 47, loss: 1.020054
global_step: 9865, epoch: 47, loss: 1.033195
global_step: 9866, epoch: 47, loss: 1.023914
global_step: 9867, epoch: 47, loss: 0.963035
global_step: 9868, epoch: 47, loss: 0.978288
global_step: 9869, epoch: 47, loss: 0.881148
global_step: 9870, epoch: 47, loss: 0.976349
global_step: 9871, epoch: 47, loss: 0.978827
global_step: 9872, epoch: 47, loss: 0.886941
global_step: 9873, epoch: 47, loss: 1.021122
global_step: 9874, epoch: 47, loss: 0.999693
global_step: 9875, epoch: 47, loss: 0.906366
global_step: 9876, epoch: 47, loss: 0.907366
global_step: 9877, epoch: 47, loss: 0.810656
global_step: 9878, epoch: 47, loss: 0.968675
global_step: 9879, epoch: 47, loss: 1.032016
global_step: 9880, epoch: 47, loss: 1.515986
epoch: 47
train	acc: 0.6894	macro: p 0.4670, r 0.3902, f1: 0.4029	micro: p 0.6894, r 0.6894, f1 0.6894	weighted_f1:0.6451
dev	acc: 0.5789	macro: p 0.4014, r 0.3274, f1: 0.3256	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5216
test	acc: 0.6119	macro: p 0.3762, r 0.3182, f1: 0.3209	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5596
global_step: 9881, epoch: 48, loss: 0.954824
global_step: 9882, epoch: 48, loss: 0.947627
global_step: 9883, epoch: 48, loss: 0.965834
global_step: 9884, epoch: 48, loss: 0.840729
global_step: 9885, epoch: 48, loss: 0.926636
global_step: 9886, epoch: 48, loss: 0.883647
global_step: 9887, epoch: 48, loss: 0.985045
global_step: 9888, epoch: 48, loss: 0.894239
global_step: 9889, epoch: 48, loss: 0.908860
global_step: 9890, epoch: 48, loss: 0.940152
global_step: 9891, epoch: 48, loss: 1.010348
global_step: 9892, epoch: 48, loss: 1.062034
global_step: 9893, epoch: 48, loss: 1.046204
global_step: 9894, epoch: 48, loss: 0.949732
global_step: 9895, epoch: 48, loss: 0.997303
global_step: 9896, epoch: 48, loss: 0.932847
global_step: 9897, epoch: 48, loss: 1.065771
global_step: 9898, epoch: 48, loss: 0.941054
global_step: 9899, epoch: 48, loss: 0.873875
global_step: 9900, epoch: 48, loss: 1.026832
global_step: 9901, epoch: 48, loss: 0.960342
global_step: 9902, epoch: 48, loss: 0.912750
global_step: 9903, epoch: 48, loss: 0.966125
global_step: 9904, epoch: 48, loss: 0.962569
global_step: 9905, epoch: 48, loss: 0.951994
global_step: 9906, epoch: 48, loss: 0.937777
global_step: 9907, epoch: 48, loss: 0.970043
global_step: 9908, epoch: 48, loss: 0.931332
global_step: 9909, epoch: 48, loss: 0.845786
global_step: 9910, epoch: 48, loss: 0.891806
global_step: 9911, epoch: 48, loss: 1.060227
global_step: 9912, epoch: 48, loss: 0.884191
global_step: 9913, epoch: 48, loss: 1.058032
global_step: 9914, epoch: 48, loss: 1.046528
global_step: 9915, epoch: 48, loss: 0.911263
global_step: 9916, epoch: 48, loss: 1.021984
global_step: 9917, epoch: 48, loss: 1.054543
global_step: 9918, epoch: 48, loss: 0.875916
global_step: 9919, epoch: 48, loss: 0.968726
global_step: 9920, epoch: 48, loss: 0.770176
epoch: 48
train	acc: 0.7111	macro: p 0.4682, r 0.4224, f1: 0.4288	micro: p 0.7111, r 0.7111, f1 0.7111	weighted_f1:0.6725
dev	acc: 0.5843	macro: p 0.3777, r 0.3382, f1: 0.3353	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5328
test	acc: 0.6180	macro: p 0.3727, r 0.3352, f1: 0.3351	micro: p 0.6180, r 0.6180, f1 0.6180	weighted_f1:0.5725
global_step: 9921, epoch: 49, loss: 0.891382
global_step: 9922, epoch: 49, loss: 0.884044
global_step: 9923, epoch: 49, loss: 1.021673
global_step: 9924, epoch: 49, loss: 0.932493
global_step: 9925, epoch: 49, loss: 0.957332
global_step: 9926, epoch: 49, loss: 0.916393
global_step: 9927, epoch: 49, loss: 0.929116
global_step: 9928, epoch: 49, loss: 0.935617
global_step: 9929, epoch: 49, loss: 0.920905
global_step: 9930, epoch: 49, loss: 0.918214
global_step: 9931, epoch: 49, loss: 0.839685
global_step: 9932, epoch: 49, loss: 0.948845
global_step: 9933, epoch: 49, loss: 0.839482
global_step: 9934, epoch: 49, loss: 0.823153
global_step: 9935, epoch: 49, loss: 0.987789
global_step: 9936, epoch: 49, loss: 0.949322
global_step: 9937, epoch: 49, loss: 0.818185
global_step: 9938, epoch: 49, loss: 0.932605
global_step: 9939, epoch: 49, loss: 0.991225
global_step: 9940, epoch: 49, loss: 0.884200
global_step: 9941, epoch: 49, loss: 0.942519
global_step: 9942, epoch: 49, loss: 0.987106
global_step: 9943, epoch: 49, loss: 0.994883
global_step: 9944, epoch: 49, loss: 0.971104
global_step: 9945, epoch: 49, loss: 0.931859
global_step: 9946, epoch: 49, loss: 0.881978
global_step: 9947, epoch: 49, loss: 0.948194
global_step: 9948, epoch: 49, loss: 0.909978
global_step: 9949, epoch: 49, loss: 1.006652
global_step: 9950, epoch: 49, loss: 1.045218
global_step: 9951, epoch: 49, loss: 0.937052
global_step: 9952, epoch: 49, loss: 0.956381
global_step: 9953, epoch: 49, loss: 0.951991
global_step: 9954, epoch: 49, loss: 0.993385
global_step: 9955, epoch: 49, loss: 0.900420
global_step: 9956, epoch: 49, loss: 0.971325
global_step: 9957, epoch: 49, loss: 0.920250
global_step: 9958, epoch: 49, loss: 1.021422
global_step: 9959, epoch: 49, loss: 0.976727
global_step: 9960, epoch: 49, loss: 1.314913
epoch: 49
train	acc: 0.7250	macro: p 0.4747, r 0.4475, f1: 0.4495	micro: p 0.7250, r 0.7250, f1 0.7250	weighted_f1:0.6939
dev	acc: 0.5879	macro: p 0.3812, r 0.3522, f1: 0.3523	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5473
test	acc: 0.6199	macro: p 0.3778, r 0.3505, f1: 0.3515	micro: p 0.6199, r 0.6199, f1 0.6199	weighted_f1:0.5850
New best model!
global_step: 9961, epoch: 50, loss: 0.929496
global_step: 9962, epoch: 50, loss: 0.843625
global_step: 9963, epoch: 50, loss: 0.926392
global_step: 9964, epoch: 50, loss: 1.058925
global_step: 9965, epoch: 50, loss: 0.854983
global_step: 9966, epoch: 50, loss: 0.848055
global_step: 9967, epoch: 50, loss: 0.932365
global_step: 9968, epoch: 50, loss: 1.032599
global_step: 9969, epoch: 50, loss: 0.943751
global_step: 9970, epoch: 50, loss: 0.958125
global_step: 9971, epoch: 50, loss: 0.961307
global_step: 9972, epoch: 50, loss: 0.867995
global_step: 9973, epoch: 50, loss: 0.980240
global_step: 9974, epoch: 50, loss: 0.895405
global_step: 9975, epoch: 50, loss: 0.926386
global_step: 9976, epoch: 50, loss: 0.864366
global_step: 9977, epoch: 50, loss: 0.945845
global_step: 9978, epoch: 50, loss: 0.897668
global_step: 9979, epoch: 50, loss: 1.048614
global_step: 9980, epoch: 50, loss: 0.845810
global_step: 9981, epoch: 50, loss: 1.074016
global_step: 9982, epoch: 50, loss: 0.953309
global_step: 9983, epoch: 50, loss: 0.931196
global_step: 9984, epoch: 50, loss: 0.939368
global_step: 9985, epoch: 50, loss: 0.940335
global_step: 9986, epoch: 50, loss: 0.851755
global_step: 9987, epoch: 50, loss: 0.954829
global_step: 9988, epoch: 50, loss: 0.912631
global_step: 9989, epoch: 50, loss: 0.899417
global_step: 9990, epoch: 50, loss: 1.000353
global_step: 9991, epoch: 50, loss: 0.979437
global_step: 9992, epoch: 50, loss: 0.860574
global_step: 9993, epoch: 50, loss: 0.899153
global_step: 9994, epoch: 50, loss: 0.917240
global_step: 9995, epoch: 50, loss: 0.988191
global_step: 9996, epoch: 50, loss: 0.907909
global_step: 9997, epoch: 50, loss: 0.924599
global_step: 9998, epoch: 50, loss: 0.914403
global_step: 9999, epoch: 50, loss: 0.944959
global_step: 10000, epoch: 50, loss: 1.078802
epoch: 50
train	acc: 0.7219	macro: p 0.4751, r 0.4372, f1: 0.4452	micro: p 0.7219, r 0.7219, f1 0.7219	weighted_f1:0.6873
dev	acc: 0.5771	macro: p 0.3682, r 0.3357, f1: 0.3325	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5285
test	acc: 0.6169	macro: p 0.3715, r 0.3386, f1: 0.3397	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5754
global_step: 10001, epoch: 51, loss: 0.830988
global_step: 10002, epoch: 51, loss: 0.823700
global_step: 10003, epoch: 51, loss: 0.889679
global_step: 10004, epoch: 51, loss: 0.861483
global_step: 10005, epoch: 51, loss: 0.931871
global_step: 10006, epoch: 51, loss: 0.932794
global_step: 10007, epoch: 51, loss: 0.855187
global_step: 10008, epoch: 51, loss: 0.945985
global_step: 10009, epoch: 51, loss: 0.854550
global_step: 10010, epoch: 51, loss: 0.898270
global_step: 10011, epoch: 51, loss: 0.980775
global_step: 10012, epoch: 51, loss: 0.939274
global_step: 10013, epoch: 51, loss: 0.931557
global_step: 10014, epoch: 51, loss: 0.881640
global_step: 10015, epoch: 51, loss: 0.871373
global_step: 10016, epoch: 51, loss: 0.898448
global_step: 10017, epoch: 51, loss: 0.976296
global_step: 10018, epoch: 51, loss: 0.809417
global_step: 10019, epoch: 51, loss: 1.013660
global_step: 10020, epoch: 51, loss: 1.018699
global_step: 10021, epoch: 51, loss: 0.815586
global_step: 10022, epoch: 51, loss: 0.967317
global_step: 10023, epoch: 51, loss: 0.983419
global_step: 10024, epoch: 51, loss: 1.004151
global_step: 10025, epoch: 51, loss: 0.899033
global_step: 10026, epoch: 51, loss: 1.038823
global_step: 10027, epoch: 51, loss: 0.958333
global_step: 10028, epoch: 51, loss: 0.882754
global_step: 10029, epoch: 51, loss: 1.073004
global_step: 10030, epoch: 51, loss: 0.899662
global_step: 10031, epoch: 51, loss: 0.949771
global_step: 10032, epoch: 51, loss: 0.880863
global_step: 10033, epoch: 51, loss: 0.830306
global_step: 10034, epoch: 51, loss: 0.834706
global_step: 10035, epoch: 51, loss: 0.939810
global_step: 10036, epoch: 51, loss: 0.908805
global_step: 10037, epoch: 51, loss: 1.006514
global_step: 10038, epoch: 51, loss: 0.967814
global_step: 10039, epoch: 51, loss: 1.010948
global_step: 10040, epoch: 51, loss: 1.030688
epoch: 51
train	acc: 0.7129	macro: p 0.4774, r 0.4209, f1: 0.4313	micro: p 0.7129, r 0.7129, f1 0.7129	weighted_f1:0.6735
dev	acc: 0.5879	macro: p 0.4057, r 0.3384, f1: 0.3396	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5350
test	acc: 0.6165	macro: p 0.3726, r 0.3284, f1: 0.3321	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5690
global_step: 10041, epoch: 52, loss: 0.944092
global_step: 10042, epoch: 52, loss: 0.951759
global_step: 10043, epoch: 52, loss: 0.835100
global_step: 10044, epoch: 52, loss: 0.892668
global_step: 10045, epoch: 52, loss: 0.886233
global_step: 10046, epoch: 52, loss: 0.919118
global_step: 10047, epoch: 52, loss: 0.944728
global_step: 10048, epoch: 52, loss: 0.924843
global_step: 10049, epoch: 52, loss: 1.023051
global_step: 10050, epoch: 52, loss: 0.987689
global_step: 10051, epoch: 52, loss: 0.932454
global_step: 10052, epoch: 52, loss: 0.953085
global_step: 10053, epoch: 52, loss: 0.881355
global_step: 10054, epoch: 52, loss: 0.781430
global_step: 10055, epoch: 52, loss: 0.859377
global_step: 10056, epoch: 52, loss: 0.943134
global_step: 10057, epoch: 52, loss: 0.923370
global_step: 10058, epoch: 52, loss: 0.923291
global_step: 10059, epoch: 52, loss: 0.855273
global_step: 10060, epoch: 52, loss: 0.858775
global_step: 10061, epoch: 52, loss: 0.954865
global_step: 10062, epoch: 52, loss: 0.948802
global_step: 10063, epoch: 52, loss: 0.786363
global_step: 10064, epoch: 52, loss: 0.837843
global_step: 10065, epoch: 52, loss: 0.846934
global_step: 10066, epoch: 52, loss: 0.991260
global_step: 10067, epoch: 52, loss: 0.887526
global_step: 10068, epoch: 52, loss: 1.049738
global_step: 10069, epoch: 52, loss: 0.950221
global_step: 10070, epoch: 52, loss: 0.884302
global_step: 10071, epoch: 52, loss: 0.906655
global_step: 10072, epoch: 52, loss: 0.954771
global_step: 10073, epoch: 52, loss: 0.856000
global_step: 10074, epoch: 52, loss: 0.965700
global_step: 10075, epoch: 52, loss: 0.872575
global_step: 10076, epoch: 52, loss: 0.948490
global_step: 10077, epoch: 52, loss: 0.985616
global_step: 10078, epoch: 52, loss: 0.876161
global_step: 10079, epoch: 52, loss: 0.999391
global_step: 10080, epoch: 52, loss: 0.678339
epoch: 52
train	acc: 0.7378	macro: p 0.4824, r 0.4637, f1: 0.4662	micro: p 0.7378, r 0.7378, f1 0.7378	weighted_f1:0.7085
dev	acc: 0.5870	macro: p 0.3805, r 0.3512, f1: 0.3512	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5455
test	acc: 0.6138	macro: p 0.3647, r 0.3446, f1: 0.3452	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5784
global_step: 10081, epoch: 53, loss: 0.929080
global_step: 10082, epoch: 53, loss: 0.873818
global_step: 10083, epoch: 53, loss: 0.837982
global_step: 10084, epoch: 53, loss: 0.927232
global_step: 10085, epoch: 53, loss: 0.945570
global_step: 10086, epoch: 53, loss: 0.898915
global_step: 10087, epoch: 53, loss: 0.941748
global_step: 10088, epoch: 53, loss: 0.916307
global_step: 10089, epoch: 53, loss: 0.964674
global_step: 10090, epoch: 53, loss: 0.869576
global_step: 10091, epoch: 53, loss: 0.929266
global_step: 10092, epoch: 53, loss: 0.852765
global_step: 10093, epoch: 53, loss: 0.828782
global_step: 10094, epoch: 53, loss: 0.882111
global_step: 10095, epoch: 53, loss: 0.926718
global_step: 10096, epoch: 53, loss: 0.975181
global_step: 10097, epoch: 53, loss: 1.088099
global_step: 10098, epoch: 53, loss: 0.877014
global_step: 10099, epoch: 53, loss: 0.858356
global_step: 10100, epoch: 53, loss: 0.875623
global_step: 10101, epoch: 53, loss: 0.889455
global_step: 10102, epoch: 53, loss: 0.863623
global_step: 10103, epoch: 53, loss: 0.955372
global_step: 10104, epoch: 53, loss: 0.905216
global_step: 10105, epoch: 53, loss: 0.846682
global_step: 10106, epoch: 53, loss: 1.017917
global_step: 10107, epoch: 53, loss: 0.900500
global_step: 10108, epoch: 53, loss: 0.845305
global_step: 10109, epoch: 53, loss: 0.855362
global_step: 10110, epoch: 53, loss: 0.769918
global_step: 10111, epoch: 53, loss: 0.982072
global_step: 10112, epoch: 53, loss: 0.900702
global_step: 10113, epoch: 53, loss: 0.866818
global_step: 10114, epoch: 53, loss: 0.820690
global_step: 10115, epoch: 53, loss: 0.871845
global_step: 10116, epoch: 53, loss: 0.953982
global_step: 10117, epoch: 53, loss: 1.023977
global_step: 10118, epoch: 53, loss: 0.925165
global_step: 10119, epoch: 53, loss: 0.879273
global_step: 10120, epoch: 53, loss: 1.330371
epoch: 53
train	acc: 0.7288	macro: p 0.4778, r 0.4479, f1: 0.4562	micro: p 0.7288, r 0.7288, f1 0.7288	weighted_f1:0.6969
dev	acc: 0.5789	macro: p 0.3738, r 0.3373, f1: 0.3384	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5328
test	acc: 0.6188	macro: p 0.3726, r 0.3388, f1: 0.3439	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5786
global_step: 10121, epoch: 54, loss: 0.835238
global_step: 10122, epoch: 54, loss: 0.902858
global_step: 10123, epoch: 54, loss: 0.936912
global_step: 10124, epoch: 54, loss: 0.946391
global_step: 10125, epoch: 54, loss: 0.881523
global_step: 10126, epoch: 54, loss: 0.932100
global_step: 10127, epoch: 54, loss: 0.883547
global_step: 10128, epoch: 54, loss: 0.971686
global_step: 10129, epoch: 54, loss: 0.886554
global_step: 10130, epoch: 54, loss: 0.875192
global_step: 10131, epoch: 54, loss: 0.942106
global_step: 10132, epoch: 54, loss: 0.865269
global_step: 10133, epoch: 54, loss: 0.796137
global_step: 10134, epoch: 54, loss: 0.834441
global_step: 10135, epoch: 54, loss: 1.030962
global_step: 10136, epoch: 54, loss: 0.922625
global_step: 10137, epoch: 54, loss: 0.911181
global_step: 10138, epoch: 54, loss: 1.003301
global_step: 10139, epoch: 54, loss: 0.830582
global_step: 10140, epoch: 54, loss: 0.868537
global_step: 10141, epoch: 54, loss: 0.824082
global_step: 10142, epoch: 54, loss: 0.948557
global_step: 10143, epoch: 54, loss: 0.924494
global_step: 10144, epoch: 54, loss: 0.938366
global_step: 10145, epoch: 54, loss: 0.813211
global_step: 10146, epoch: 54, loss: 0.931691
global_step: 10147, epoch: 54, loss: 0.907249
global_step: 10148, epoch: 54, loss: 0.908553
global_step: 10149, epoch: 54, loss: 0.851580
global_step: 10150, epoch: 54, loss: 0.885862
global_step: 10151, epoch: 54, loss: 0.751063
global_step: 10152, epoch: 54, loss: 0.904801
global_step: 10153, epoch: 54, loss: 0.832307
global_step: 10154, epoch: 54, loss: 0.873368
global_step: 10155, epoch: 54, loss: 0.903103
global_step: 10156, epoch: 54, loss: 0.943638
global_step: 10157, epoch: 54, loss: 0.928896
global_step: 10158, epoch: 54, loss: 0.850764
global_step: 10159, epoch: 54, loss: 0.948053
global_step: 10160, epoch: 54, loss: 1.068865
epoch: 54
train	acc: 0.7438	macro: p 0.4886, r 0.4676, f1: 0.4718	micro: p 0.7438, r 0.7438, f1 0.7438	weighted_f1:0.7134
dev	acc: 0.5879	macro: p 0.3789, r 0.3483, f1: 0.3476	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5433
test	acc: 0.6146	macro: p 0.3645, r 0.3415, f1: 0.3436	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5770
global_step: 10161, epoch: 55, loss: 0.896472
global_step: 10162, epoch: 55, loss: 0.890710
global_step: 10163, epoch: 55, loss: 0.893065
global_step: 10164, epoch: 55, loss: 0.866347
global_step: 10165, epoch: 55, loss: 0.892976
global_step: 10166, epoch: 55, loss: 0.873684
global_step: 10167, epoch: 55, loss: 0.880099
global_step: 10168, epoch: 55, loss: 0.891579
global_step: 10169, epoch: 55, loss: 0.856531
global_step: 10170, epoch: 55, loss: 0.864555
global_step: 10171, epoch: 55, loss: 0.880556
global_step: 10172, epoch: 55, loss: 0.987448
global_step: 10173, epoch: 55, loss: 0.940597
global_step: 10174, epoch: 55, loss: 0.986164
global_step: 10175, epoch: 55, loss: 0.887650
global_step: 10176, epoch: 55, loss: 0.924517
global_step: 10177, epoch: 55, loss: 0.874182
global_step: 10178, epoch: 55, loss: 0.886509
global_step: 10179, epoch: 55, loss: 0.822004
global_step: 10180, epoch: 55, loss: 0.793261
global_step: 10181, epoch: 55, loss: 0.894762
global_step: 10182, epoch: 55, loss: 0.915582
global_step: 10183, epoch: 55, loss: 0.994408
global_step: 10184, epoch: 55, loss: 0.866313
global_step: 10185, epoch: 55, loss: 0.874483
global_step: 10186, epoch: 55, loss: 0.900542
global_step: 10187, epoch: 55, loss: 0.794378
global_step: 10188, epoch: 55, loss: 0.898120
global_step: 10189, epoch: 55, loss: 0.898780
global_step: 10190, epoch: 55, loss: 0.957558
global_step: 10191, epoch: 55, loss: 0.852916
global_step: 10192, epoch: 55, loss: 0.799125
global_step: 10193, epoch: 55, loss: 0.787774
global_step: 10194, epoch: 55, loss: 0.798570
global_step: 10195, epoch: 55, loss: 0.822870
global_step: 10196, epoch: 55, loss: 0.971637
global_step: 10197, epoch: 55, loss: 0.887006
global_step: 10198, epoch: 55, loss: 0.855331
global_step: 10199, epoch: 55, loss: 0.977540
global_step: 10200, epoch: 55, loss: 0.639527
epoch: 55
train	acc: 0.7494	macro: p 0.4853, r 0.4787, f1: 0.4800	micro: p 0.7494, r 0.7494, f1 0.7494	weighted_f1:0.7214
dev	acc: 0.5798	macro: p 0.3698, r 0.3486, f1: 0.3476	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5391
test	acc: 0.6107	macro: p 0.3580, r 0.3424, f1: 0.3428	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5752
global_step: 10201, epoch: 56, loss: 0.839776
global_step: 10202, epoch: 56, loss: 0.830466
global_step: 10203, epoch: 56, loss: 0.875028
global_step: 10204, epoch: 56, loss: 1.018472
global_step: 10205, epoch: 56, loss: 0.826254
global_step: 10206, epoch: 56, loss: 0.834111
global_step: 10207, epoch: 56, loss: 0.725626
global_step: 10208, epoch: 56, loss: 0.914736
global_step: 10209, epoch: 56, loss: 0.917649
global_step: 10210, epoch: 56, loss: 0.844857
global_step: 10211, epoch: 56, loss: 0.914431
global_step: 10212, epoch: 56, loss: 0.862567
global_step: 10213, epoch: 56, loss: 0.911123
global_step: 10214, epoch: 56, loss: 0.771831
global_step: 10215, epoch: 56, loss: 0.856095
global_step: 10216, epoch: 56, loss: 0.886964
global_step: 10217, epoch: 56, loss: 0.993720
global_step: 10218, epoch: 56, loss: 0.798552
global_step: 10219, epoch: 56, loss: 0.840545
global_step: 10220, epoch: 56, loss: 0.838210
global_step: 10221, epoch: 56, loss: 0.805217
global_step: 10222, epoch: 56, loss: 0.802899
global_step: 10223, epoch: 56, loss: 0.940181
global_step: 10224, epoch: 56, loss: 0.871297
global_step: 10225, epoch: 56, loss: 0.778417
global_step: 10226, epoch: 56, loss: 0.940605
global_step: 10227, epoch: 56, loss: 0.854578
global_step: 10228, epoch: 56, loss: 0.956601
global_step: 10229, epoch: 56, loss: 0.918208
global_step: 10230, epoch: 56, loss: 0.903521
global_step: 10231, epoch: 56, loss: 0.934687
global_step: 10232, epoch: 56, loss: 0.832406
global_step: 10233, epoch: 56, loss: 0.838364
global_step: 10234, epoch: 56, loss: 0.894284
global_step: 10235, epoch: 56, loss: 0.901801
global_step: 10236, epoch: 56, loss: 0.899487
global_step: 10237, epoch: 56, loss: 0.823943
global_step: 10238, epoch: 56, loss: 0.865880
global_step: 10239, epoch: 56, loss: 0.871687
global_step: 10240, epoch: 56, loss: 1.398697
epoch: 56
train	acc: 0.7508	macro: p 0.4868, r 0.4841, f1: 0.4829	micro: p 0.7508, r 0.7508, f1 0.7508	weighted_f1:0.7238
dev	acc: 0.5834	macro: p 0.3697, r 0.3500, f1: 0.3499	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5428
test	acc: 0.6134	macro: p 0.3610, r 0.3480, f1: 0.3485	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5802
global_step: 10241, epoch: 57, loss: 0.865158
global_step: 10242, epoch: 57, loss: 0.911093
global_step: 10243, epoch: 57, loss: 0.729393
global_step: 10244, epoch: 57, loss: 0.862144
global_step: 10245, epoch: 57, loss: 0.795637
global_step: 10246, epoch: 57, loss: 0.956014
global_step: 10247, epoch: 57, loss: 0.777744
global_step: 10248, epoch: 57, loss: 0.776954
global_step: 10249, epoch: 57, loss: 0.818333
global_step: 10250, epoch: 57, loss: 0.891808
global_step: 10251, epoch: 57, loss: 0.941247
global_step: 10252, epoch: 57, loss: 0.901991
global_step: 10253, epoch: 57, loss: 0.900311
global_step: 10254, epoch: 57, loss: 0.792692
global_step: 10255, epoch: 57, loss: 0.863421
global_step: 10256, epoch: 57, loss: 0.964057
global_step: 10257, epoch: 57, loss: 0.887603
global_step: 10258, epoch: 57, loss: 0.957089
global_step: 10259, epoch: 57, loss: 0.857411
global_step: 10260, epoch: 57, loss: 0.970248
global_step: 10261, epoch: 57, loss: 0.804784
global_step: 10262, epoch: 57, loss: 0.857810
global_step: 10263, epoch: 57, loss: 0.815862
global_step: 10264, epoch: 57, loss: 0.786898
global_step: 10265, epoch: 57, loss: 0.943702
global_step: 10266, epoch: 57, loss: 0.752516
global_step: 10267, epoch: 57, loss: 0.865659
global_step: 10268, epoch: 57, loss: 0.861399
global_step: 10269, epoch: 57, loss: 0.826311
global_step: 10270, epoch: 57, loss: 0.898530
global_step: 10271, epoch: 57, loss: 0.926735
global_step: 10272, epoch: 57, loss: 0.939444
global_step: 10273, epoch: 57, loss: 0.911207
global_step: 10274, epoch: 57, loss: 0.798087
global_step: 10275, epoch: 57, loss: 0.890065
global_step: 10276, epoch: 57, loss: 0.921475
global_step: 10277, epoch: 57, loss: 0.917486
global_step: 10278, epoch: 57, loss: 0.850050
global_step: 10279, epoch: 57, loss: 0.854641
global_step: 10280, epoch: 57, loss: 0.585520
epoch: 57
train	acc: 0.7505	macro: p 0.6478, r 0.4706, f1: 0.4766	micro: p 0.7505, r 0.7505, f1 0.7505	weighted_f1:0.7185
dev	acc: 0.5843	macro: p 0.3844, r 0.3448, f1: 0.3479	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5401
test	acc: 0.6172	macro: p 0.3711, r 0.3392, f1: 0.3419	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5769
global_step: 10281, epoch: 58, loss: 0.844438
global_step: 10282, epoch: 58, loss: 0.860870
global_step: 10283, epoch: 58, loss: 0.960828
global_step: 10284, epoch: 58, loss: 0.846170
global_step: 10285, epoch: 58, loss: 0.789102
global_step: 10286, epoch: 58, loss: 0.980237
global_step: 10287, epoch: 58, loss: 0.815073
global_step: 10288, epoch: 58, loss: 0.848553
global_step: 10289, epoch: 58, loss: 0.869498
global_step: 10290, epoch: 58, loss: 0.754434
global_step: 10291, epoch: 58, loss: 0.866851
global_step: 10292, epoch: 58, loss: 0.908596
global_step: 10293, epoch: 58, loss: 0.883088
global_step: 10294, epoch: 58, loss: 0.821444
global_step: 10295, epoch: 58, loss: 0.776610
global_step: 10296, epoch: 58, loss: 0.879698
global_step: 10297, epoch: 58, loss: 0.834403
global_step: 10298, epoch: 58, loss: 0.838247
global_step: 10299, epoch: 58, loss: 0.857594
global_step: 10300, epoch: 58, loss: 0.916214
global_step: 10301, epoch: 58, loss: 0.838041
global_step: 10302, epoch: 58, loss: 0.969613
global_step: 10303, epoch: 58, loss: 0.884505
global_step: 10304, epoch: 58, loss: 0.815299
global_step: 10305, epoch: 58, loss: 0.998631
global_step: 10306, epoch: 58, loss: 0.797203
global_step: 10307, epoch: 58, loss: 0.924278
global_step: 10308, epoch: 58, loss: 0.896096
global_step: 10309, epoch: 58, loss: 0.781763
global_step: 10310, epoch: 58, loss: 0.853654
global_step: 10311, epoch: 58, loss: 0.808098
global_step: 10312, epoch: 58, loss: 0.880258
global_step: 10313, epoch: 58, loss: 0.764317
global_step: 10314, epoch: 58, loss: 0.902421
global_step: 10315, epoch: 58, loss: 0.868018
global_step: 10316, epoch: 58, loss: 0.867124
global_step: 10317, epoch: 58, loss: 0.858869
global_step: 10318, epoch: 58, loss: 0.834996
global_step: 10319, epoch: 58, loss: 0.834366
global_step: 10320, epoch: 58, loss: 1.713918
epoch: 58
train	acc: 0.7534	macro: p 0.4947, r 0.4776, f1: 0.4783	micro: p 0.7534, r 0.7534, f1 0.7534	weighted_f1:0.7246
dev	acc: 0.5627	macro: p 0.3624, r 0.3342, f1: 0.3253	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5195
test	acc: 0.5989	macro: p 0.3587, r 0.3364, f1: 0.3304	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5627
global_step: 10321, epoch: 59, loss: 0.899967
global_step: 10322, epoch: 59, loss: 0.808973
global_step: 10323, epoch: 59, loss: 0.860424
global_step: 10324, epoch: 59, loss: 0.908941
global_step: 10325, epoch: 59, loss: 0.827100
global_step: 10326, epoch: 59, loss: 0.717915
global_step: 10327, epoch: 59, loss: 0.856284
global_step: 10328, epoch: 59, loss: 0.768741
global_step: 10329, epoch: 59, loss: 0.762549
global_step: 10330, epoch: 59, loss: 0.787839
global_step: 10331, epoch: 59, loss: 0.912959
global_step: 10332, epoch: 59, loss: 0.817825
global_step: 10333, epoch: 59, loss: 0.852855
global_step: 10334, epoch: 59, loss: 0.896082
global_step: 10335, epoch: 59, loss: 0.933120
global_step: 10336, epoch: 59, loss: 0.826430
global_step: 10337, epoch: 59, loss: 0.818374
global_step: 10338, epoch: 59, loss: 0.890894
global_step: 10339, epoch: 59, loss: 0.853736
global_step: 10340, epoch: 59, loss: 0.855158
global_step: 10341, epoch: 59, loss: 0.927709
global_step: 10342, epoch: 59, loss: 0.841985
global_step: 10343, epoch: 59, loss: 0.765962
global_step: 10344, epoch: 59, loss: 0.833300
global_step: 10345, epoch: 59, loss: 0.789186
global_step: 10346, epoch: 59, loss: 0.691977
global_step: 10347, epoch: 59, loss: 0.854016
global_step: 10348, epoch: 59, loss: 0.970167
global_step: 10349, epoch: 59, loss: 0.859910
global_step: 10350, epoch: 59, loss: 0.797109
global_step: 10351, epoch: 59, loss: 0.792477
global_step: 10352, epoch: 59, loss: 0.886563
global_step: 10353, epoch: 59, loss: 0.843289
global_step: 10354, epoch: 59, loss: 0.834490
global_step: 10355, epoch: 59, loss: 0.771619
global_step: 10356, epoch: 59, loss: 0.918406
global_step: 10357, epoch: 59, loss: 0.798231
global_step: 10358, epoch: 59, loss: 0.880580
global_step: 10359, epoch: 59, loss: 0.777264
global_step: 10360, epoch: 59, loss: 0.964707
epoch: 59
train	acc: 0.7648	macro: p 0.5074, r 0.4910, f1: 0.4931	micro: p 0.7648, r 0.7648, f1 0.7648	weighted_f1:0.7362
dev	acc: 0.5870	macro: p 0.3818, r 0.3496, f1: 0.3512	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5445
test	acc: 0.6153	macro: p 0.3661, r 0.3430, f1: 0.3452	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5784
global_step: 10361, epoch: 60, loss: 0.822681
global_step: 10362, epoch: 60, loss: 0.798525
global_step: 10363, epoch: 60, loss: 0.774800
global_step: 10364, epoch: 60, loss: 0.880311
global_step: 10365, epoch: 60, loss: 0.778466
global_step: 10366, epoch: 60, loss: 0.934121
global_step: 10367, epoch: 60, loss: 0.873254
global_step: 10368, epoch: 60, loss: 0.769137
global_step: 10369, epoch: 60, loss: 0.860053
global_step: 10370, epoch: 60, loss: 0.853913
global_step: 10371, epoch: 60, loss: 0.842181
global_step: 10372, epoch: 60, loss: 0.784721
global_step: 10373, epoch: 60, loss: 0.828660
global_step: 10374, epoch: 60, loss: 0.748484
global_step: 10375, epoch: 60, loss: 0.913388
global_step: 10376, epoch: 60, loss: 0.833017
global_step: 10377, epoch: 60, loss: 0.874717
global_step: 10378, epoch: 60, loss: 0.884192
global_step: 10379, epoch: 60, loss: 0.840849
global_step: 10380, epoch: 60, loss: 0.811264
global_step: 10381, epoch: 60, loss: 0.806364
global_step: 10382, epoch: 60, loss: 0.781660
global_step: 10383, epoch: 60, loss: 0.728550
global_step: 10384, epoch: 60, loss: 0.833183
global_step: 10385, epoch: 60, loss: 0.797584
global_step: 10386, epoch: 60, loss: 0.872917
global_step: 10387, epoch: 60, loss: 0.837514
global_step: 10388, epoch: 60, loss: 0.830637
global_step: 10389, epoch: 60, loss: 0.880740
global_step: 10390, epoch: 60, loss: 0.864597
global_step: 10391, epoch: 60, loss: 0.803769
global_step: 10392, epoch: 60, loss: 0.879901
global_step: 10393, epoch: 60, loss: 0.890644
global_step: 10394, epoch: 60, loss: 0.919072
global_step: 10395, epoch: 60, loss: 0.865260
global_step: 10396, epoch: 60, loss: 0.809698
global_step: 10397, epoch: 60, loss: 0.875211
global_step: 10398, epoch: 60, loss: 0.752047
global_step: 10399, epoch: 60, loss: 0.801257
global_step: 10400, epoch: 60, loss: 0.364122
epoch: 60
train	acc: 0.7350	macro: p 0.5041, r 0.4472, f1: 0.4615	micro: p 0.7350, r 0.7350, f1 0.7350	weighted_f1:0.6986
dev	acc: 0.5789	macro: p 0.3900, r 0.3289, f1: 0.3340	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5260
test	acc: 0.6149	macro: p 0.3740, r 0.3235, f1: 0.3303	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5655
global_step: 10401, epoch: 61, loss: 1.011775
global_step: 10402, epoch: 61, loss: 0.790857
global_step: 10403, epoch: 61, loss: 0.864505
global_step: 10404, epoch: 61, loss: 0.895347
global_step: 10405, epoch: 61, loss: 0.812231
global_step: 10406, epoch: 61, loss: 0.927665
global_step: 10407, epoch: 61, loss: 0.825296
global_step: 10408, epoch: 61, loss: 0.804305
global_step: 10409, epoch: 61, loss: 0.852261
global_step: 10410, epoch: 61, loss: 0.825345
global_step: 10411, epoch: 61, loss: 0.753379
global_step: 10412, epoch: 61, loss: 0.787745
global_step: 10413, epoch: 61, loss: 0.823984
global_step: 10414, epoch: 61, loss: 0.747436
global_step: 10415, epoch: 61, loss: 0.940434
global_step: 10416, epoch: 61, loss: 0.708062
global_step: 10417, epoch: 61, loss: 0.886192
global_step: 10418, epoch: 61, loss: 0.868244
global_step: 10419, epoch: 61, loss: 0.796881
global_step: 10420, epoch: 61, loss: 0.832636
global_step: 10421, epoch: 61, loss: 0.767021
global_step: 10422, epoch: 61, loss: 0.892087
global_step: 10423, epoch: 61, loss: 0.743809
global_step: 10424, epoch: 61, loss: 0.832158
global_step: 10425, epoch: 61, loss: 0.959216
global_step: 10426, epoch: 61, loss: 0.770595
global_step: 10427, epoch: 61, loss: 0.882990
global_step: 10428, epoch: 61, loss: 0.717623
global_step: 10429, epoch: 61, loss: 0.794648
global_step: 10430, epoch: 61, loss: 0.767064
global_step: 10431, epoch: 61, loss: 0.750024
global_step: 10432, epoch: 61, loss: 0.823166
global_step: 10433, epoch: 61, loss: 0.839277
global_step: 10434, epoch: 61, loss: 0.834925
global_step: 10435, epoch: 61, loss: 0.815932
global_step: 10436, epoch: 61, loss: 0.729809
global_step: 10437, epoch: 61, loss: 0.875934
global_step: 10438, epoch: 61, loss: 0.952420
global_step: 10439, epoch: 61, loss: 0.784343
global_step: 10440, epoch: 61, loss: 1.497896
epoch: 61
train	acc: 0.7824	macro: p 0.5074, r 0.5205, f1: 0.5129	micro: p 0.7824, r 0.7824, f1 0.7824	weighted_f1:0.7582
dev	acc: 0.5690	macro: p 0.3542, r 0.3469, f1: 0.3416	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5338
test	acc: 0.6034	macro: p 0.3568, r 0.3532, f1: 0.3495	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5763
global_step: 10441, epoch: 62, loss: 0.803032
global_step: 10442, epoch: 62, loss: 0.702548
global_step: 10443, epoch: 62, loss: 0.887377
global_step: 10444, epoch: 62, loss: 0.748211
global_step: 10445, epoch: 62, loss: 0.855102
global_step: 10446, epoch: 62, loss: 0.874263
global_step: 10447, epoch: 62, loss: 0.735006
global_step: 10448, epoch: 62, loss: 0.809690
global_step: 10449, epoch: 62, loss: 0.825814
global_step: 10450, epoch: 62, loss: 0.929959
global_step: 10451, epoch: 62, loss: 0.859861
global_step: 10452, epoch: 62, loss: 0.862086
global_step: 10453, epoch: 62, loss: 0.782845
global_step: 10454, epoch: 62, loss: 0.816383
global_step: 10455, epoch: 62, loss: 0.840416
global_step: 10456, epoch: 62, loss: 0.764259
global_step: 10457, epoch: 62, loss: 0.789392
global_step: 10458, epoch: 62, loss: 0.810432
global_step: 10459, epoch: 62, loss: 0.827438
global_step: 10460, epoch: 62, loss: 0.796170
global_step: 10461, epoch: 62, loss: 0.812486
global_step: 10462, epoch: 62, loss: 0.807828
global_step: 10463, epoch: 62, loss: 0.832982
global_step: 10464, epoch: 62, loss: 0.894705
global_step: 10465, epoch: 62, loss: 0.874657
global_step: 10466, epoch: 62, loss: 0.855663
global_step: 10467, epoch: 62, loss: 0.847045
global_step: 10468, epoch: 62, loss: 0.828528
global_step: 10469, epoch: 62, loss: 0.857819
global_step: 10470, epoch: 62, loss: 0.742842
global_step: 10471, epoch: 62, loss: 0.847528
global_step: 10472, epoch: 62, loss: 0.813877
global_step: 10473, epoch: 62, loss: 0.913150
global_step: 10474, epoch: 62, loss: 0.948459
global_step: 10475, epoch: 62, loss: 0.818730
global_step: 10476, epoch: 62, loss: 0.816756
global_step: 10477, epoch: 62, loss: 0.744570
global_step: 10478, epoch: 62, loss: 0.783138
global_step: 10479, epoch: 62, loss: 0.825232
global_step: 10480, epoch: 62, loss: 0.881309
epoch: 62
train	acc: 0.7855	macro: p 0.6576, r 0.5245, f1: 0.5189	micro: p 0.7855, r 0.7855, f1 0.7855	weighted_f1:0.7600
dev	acc: 0.5735	macro: p 0.3642, r 0.3496, f1: 0.3479	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5363
test	acc: 0.5977	macro: p 0.3510, r 0.3426, f1: 0.3412	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5668
global_step: 10481, epoch: 63, loss: 0.780379
global_step: 10482, epoch: 63, loss: 0.843503
global_step: 10483, epoch: 63, loss: 0.728366
global_step: 10484, epoch: 63, loss: 0.838073
global_step: 10485, epoch: 63, loss: 0.773940
global_step: 10486, epoch: 63, loss: 0.887565
global_step: 10487, epoch: 63, loss: 0.784441
global_step: 10488, epoch: 63, loss: 0.815717
global_step: 10489, epoch: 63, loss: 0.840118
global_step: 10490, epoch: 63, loss: 0.796694
global_step: 10491, epoch: 63, loss: 0.813266
global_step: 10492, epoch: 63, loss: 0.797467
global_step: 10493, epoch: 63, loss: 0.889956
global_step: 10494, epoch: 63, loss: 0.768267
global_step: 10495, epoch: 63, loss: 0.831034
global_step: 10496, epoch: 63, loss: 0.799230
global_step: 10497, epoch: 63, loss: 0.753104
global_step: 10498, epoch: 63, loss: 0.740842
global_step: 10499, epoch: 63, loss: 0.794914
global_step: 10500, epoch: 63, loss: 0.795660
global_step: 10501, epoch: 63, loss: 0.823665
global_step: 10502, epoch: 63, loss: 0.799680
global_step: 10503, epoch: 63, loss: 0.744846
global_step: 10504, epoch: 63, loss: 0.844182
global_step: 10505, epoch: 63, loss: 0.849851
global_step: 10506, epoch: 63, loss: 0.791152
global_step: 10507, epoch: 63, loss: 0.869567
global_step: 10508, epoch: 63, loss: 0.840258
global_step: 10509, epoch: 63, loss: 0.865230
global_step: 10510, epoch: 63, loss: 0.836667
global_step: 10511, epoch: 63, loss: 0.797484
global_step: 10512, epoch: 63, loss: 0.867509
global_step: 10513, epoch: 63, loss: 0.669522
global_step: 10514, epoch: 63, loss: 0.825540
global_step: 10515, epoch: 63, loss: 0.817809
global_step: 10516, epoch: 63, loss: 0.751995
global_step: 10517, epoch: 63, loss: 0.829922
global_step: 10518, epoch: 63, loss: 0.856402
global_step: 10519, epoch: 63, loss: 0.772895
global_step: 10520, epoch: 63, loss: 0.918070
epoch: 63
train	acc: 0.7405	macro: p 0.6560, r 0.4514, f1: 0.4688	micro: p 0.7405, r 0.7405, f1 0.7405	weighted_f1:0.7052
dev	acc: 0.5717	macro: p 0.3911, r 0.3230, f1: 0.3285	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5191
test	acc: 0.6157	macro: p 0.3748, r 0.3220, f1: 0.3293	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5659
global_step: 10521, epoch: 64, loss: 0.929021
global_step: 10522, epoch: 64, loss: 0.799444
global_step: 10523, epoch: 64, loss: 0.853291
global_step: 10524, epoch: 64, loss: 0.854775
global_step: 10525, epoch: 64, loss: 0.745376
global_step: 10526, epoch: 64, loss: 0.778167
global_step: 10527, epoch: 64, loss: 0.673633
global_step: 10528, epoch: 64, loss: 0.729195
global_step: 10529, epoch: 64, loss: 0.762224
global_step: 10530, epoch: 64, loss: 0.863942
global_step: 10531, epoch: 64, loss: 0.814224
global_step: 10532, epoch: 64, loss: 0.760279
global_step: 10533, epoch: 64, loss: 0.672168
global_step: 10534, epoch: 64, loss: 0.824960
global_step: 10535, epoch: 64, loss: 0.797301
global_step: 10536, epoch: 64, loss: 0.769672
global_step: 10537, epoch: 64, loss: 0.797023
global_step: 10538, epoch: 64, loss: 0.828496
global_step: 10539, epoch: 64, loss: 0.817218
global_step: 10540, epoch: 64, loss: 0.760235
global_step: 10541, epoch: 64, loss: 0.874527
global_step: 10542, epoch: 64, loss: 0.855872
global_step: 10543, epoch: 64, loss: 0.783750
global_step: 10544, epoch: 64, loss: 0.745712
global_step: 10545, epoch: 64, loss: 0.823387
global_step: 10546, epoch: 64, loss: 0.797696
global_step: 10547, epoch: 64, loss: 0.822679
global_step: 10548, epoch: 64, loss: 0.829620
global_step: 10549, epoch: 64, loss: 0.746491
global_step: 10550, epoch: 64, loss: 0.870850
global_step: 10551, epoch: 64, loss: 0.766316
global_step: 10552, epoch: 64, loss: 0.747938
global_step: 10553, epoch: 64, loss: 0.791735
global_step: 10554, epoch: 64, loss: 0.854276
global_step: 10555, epoch: 64, loss: 0.816188
global_step: 10556, epoch: 64, loss: 0.828703
global_step: 10557, epoch: 64, loss: 0.831236
global_step: 10558, epoch: 64, loss: 0.795599
global_step: 10559, epoch: 64, loss: 0.787349
global_step: 10560, epoch: 64, loss: 0.767523
epoch: 64
train	acc: 0.7845	macro: p 0.6648, r 0.5195, f1: 0.5154	micro: p 0.7845, r 0.7845, f1 0.7845	weighted_f1:0.7575
dev	acc: 0.5789	macro: p 0.3753, r 0.3511, f1: 0.3498	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5394
test	acc: 0.6096	macro: p 0.3647, r 0.3474, f1: 0.3449	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5759
global_step: 10561, epoch: 65, loss: 0.821600
global_step: 10562, epoch: 65, loss: 0.751579
global_step: 10563, epoch: 65, loss: 0.697578
global_step: 10564, epoch: 65, loss: 0.730194
global_step: 10565, epoch: 65, loss: 0.805952
global_step: 10566, epoch: 65, loss: 0.759042
global_step: 10567, epoch: 65, loss: 0.744694
global_step: 10568, epoch: 65, loss: 0.843247
global_step: 10569, epoch: 65, loss: 0.870937
global_step: 10570, epoch: 65, loss: 0.756147
global_step: 10571, epoch: 65, loss: 0.848549
global_step: 10572, epoch: 65, loss: 0.803072
global_step: 10573, epoch: 65, loss: 0.828803
global_step: 10574, epoch: 65, loss: 0.865546
global_step: 10575, epoch: 65, loss: 0.690568
global_step: 10576, epoch: 65, loss: 0.721177
global_step: 10577, epoch: 65, loss: 0.586390
global_step: 10578, epoch: 65, loss: 0.780239
global_step: 10579, epoch: 65, loss: 0.734987
global_step: 10580, epoch: 65, loss: 0.826757
global_step: 10581, epoch: 65, loss: 0.771043
global_step: 10582, epoch: 65, loss: 0.743562
global_step: 10583, epoch: 65, loss: 0.823994
global_step: 10584, epoch: 65, loss: 0.767039
global_step: 10585, epoch: 65, loss: 0.779586
global_step: 10586, epoch: 65, loss: 0.808748
global_step: 10587, epoch: 65, loss: 0.781882
global_step: 10588, epoch: 65, loss: 0.883536
global_step: 10589, epoch: 65, loss: 0.707061
global_step: 10590, epoch: 65, loss: 0.792652
global_step: 10591, epoch: 65, loss: 0.782870
global_step: 10592, epoch: 65, loss: 0.769106
global_step: 10593, epoch: 65, loss: 0.745881
global_step: 10594, epoch: 65, loss: 0.909596
global_step: 10595, epoch: 65, loss: 0.917936
global_step: 10596, epoch: 65, loss: 0.752393
global_step: 10597, epoch: 65, loss: 0.708924
global_step: 10598, epoch: 65, loss: 0.884625
global_step: 10599, epoch: 65, loss: 0.887218
global_step: 10600, epoch: 65, loss: 2.785342
epoch: 65
train	acc: 0.7901	macro: p 0.6625, r 0.5242, f1: 0.5191	micro: p 0.7901, r 0.7901, f1 0.7901	weighted_f1:0.7649
dev	acc: 0.5672	macro: p 0.3556, r 0.3428, f1: 0.3342	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5282
test	acc: 0.5996	macro: p 0.3574, r 0.3461, f1: 0.3398	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5689
global_step: 10601, epoch: 66, loss: 0.845804
global_step: 10602, epoch: 66, loss: 0.786516
global_step: 10603, epoch: 66, loss: 0.818976
global_step: 10604, epoch: 66, loss: 0.675982
global_step: 10605, epoch: 66, loss: 0.755053
global_step: 10606, epoch: 66, loss: 0.764635
global_step: 10607, epoch: 66, loss: 0.835662
global_step: 10608, epoch: 66, loss: 0.758810
global_step: 10609, epoch: 66, loss: 0.802817
global_step: 10610, epoch: 66, loss: 0.826913
global_step: 10611, epoch: 66, loss: 0.849429
global_step: 10612, epoch: 66, loss: 0.644609
global_step: 10613, epoch: 66, loss: 0.752722
global_step: 10614, epoch: 66, loss: 0.783063
global_step: 10615, epoch: 66, loss: 0.790905
global_step: 10616, epoch: 66, loss: 0.800613
global_step: 10617, epoch: 66, loss: 0.696775
global_step: 10618, epoch: 66, loss: 0.803528
global_step: 10619, epoch: 66, loss: 0.928461
global_step: 10620, epoch: 66, loss: 0.772362
global_step: 10621, epoch: 66, loss: 0.725039
global_step: 10622, epoch: 66, loss: 0.766881
global_step: 10623, epoch: 66, loss: 0.902022
global_step: 10624, epoch: 66, loss: 0.814454
global_step: 10625, epoch: 66, loss: 0.680560
global_step: 10626, epoch: 66, loss: 0.801072
global_step: 10627, epoch: 66, loss: 0.727582
global_step: 10628, epoch: 66, loss: 0.688891
global_step: 10629, epoch: 66, loss: 0.750054
global_step: 10630, epoch: 66, loss: 0.838654
global_step: 10631, epoch: 66, loss: 0.725807
global_step: 10632, epoch: 66, loss: 0.697838
global_step: 10633, epoch: 66, loss: 0.835650
global_step: 10634, epoch: 66, loss: 0.792760
global_step: 10635, epoch: 66, loss: 0.901273
global_step: 10636, epoch: 66, loss: 0.748005
global_step: 10637, epoch: 66, loss: 0.733380
global_step: 10638, epoch: 66, loss: 0.732721
global_step: 10639, epoch: 66, loss: 0.859874
global_step: 10640, epoch: 66, loss: 0.671444
epoch: 66
train	acc: 0.8029	macro: p 0.6714, r 0.5455, f1: 0.5362	micro: p 0.8029, r 0.8029, f1 0.8029	weighted_f1:0.7795
dev	acc: 0.5744	macro: p 0.3618, r 0.3536, f1: 0.3483	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5397
test	acc: 0.6092	macro: p 0.3643, r 0.3600, f1: 0.3530	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5820
global_step: 10641, epoch: 67, loss: 0.759771
global_step: 10642, epoch: 67, loss: 0.914996
global_step: 10643, epoch: 67, loss: 0.826556
global_step: 10644, epoch: 67, loss: 0.773125
global_step: 10645, epoch: 67, loss: 0.807253
global_step: 10646, epoch: 67, loss: 0.876617
global_step: 10647, epoch: 67, loss: 0.740906
global_step: 10648, epoch: 67, loss: 0.745763
global_step: 10649, epoch: 67, loss: 0.724363
global_step: 10650, epoch: 67, loss: 0.745189
global_step: 10651, epoch: 67, loss: 0.748198
global_step: 10652, epoch: 67, loss: 0.719955
global_step: 10653, epoch: 67, loss: 0.819221
global_step: 10654, epoch: 67, loss: 0.791750
global_step: 10655, epoch: 67, loss: 0.768108
global_step: 10656, epoch: 67, loss: 0.728950
global_step: 10657, epoch: 67, loss: 0.799289
global_step: 10658, epoch: 67, loss: 0.771999
global_step: 10659, epoch: 67, loss: 0.661358
global_step: 10660, epoch: 67, loss: 0.749988
global_step: 10661, epoch: 67, loss: 0.833156
global_step: 10662, epoch: 67, loss: 0.853553
global_step: 10663, epoch: 67, loss: 0.791623
global_step: 10664, epoch: 67, loss: 0.760659
global_step: 10665, epoch: 67, loss: 0.747627
global_step: 10666, epoch: 67, loss: 0.759807
global_step: 10667, epoch: 67, loss: 0.697149
global_step: 10668, epoch: 67, loss: 0.830149
global_step: 10669, epoch: 67, loss: 0.761813
global_step: 10670, epoch: 67, loss: 0.703779
global_step: 10671, epoch: 67, loss: 0.704244
global_step: 10672, epoch: 67, loss: 0.786653
global_step: 10673, epoch: 67, loss: 0.756507
global_step: 10674, epoch: 67, loss: 0.742441
global_step: 10675, epoch: 67, loss: 0.773039
global_step: 10676, epoch: 67, loss: 0.783533
global_step: 10677, epoch: 67, loss: 0.789190
global_step: 10678, epoch: 67, loss: 0.842100
global_step: 10679, epoch: 67, loss: 0.749672
global_step: 10680, epoch: 67, loss: 1.339757
epoch: 67
train	acc: 0.7913	macro: p 0.6796, r 0.5268, f1: 0.5263	micro: p 0.7913, r 0.7913, f1 0.7913	weighted_f1:0.7674
dev	acc: 0.5726	macro: p 0.3696, r 0.3395, f1: 0.3411	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5341
test	acc: 0.6103	macro: p 0.3735, r 0.3425, f1: 0.3460	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5772
global_step: 10681, epoch: 68, loss: 0.772607
global_step: 10682, epoch: 68, loss: 0.751993
global_step: 10683, epoch: 68, loss: 0.803801
global_step: 10684, epoch: 68, loss: 0.828533
global_step: 10685, epoch: 68, loss: 0.789285
global_step: 10686, epoch: 68, loss: 0.723947
global_step: 10687, epoch: 68, loss: 0.788502
global_step: 10688, epoch: 68, loss: 0.694263
global_step: 10689, epoch: 68, loss: 0.716566
global_step: 10690, epoch: 68, loss: 0.788388
global_step: 10691, epoch: 68, loss: 0.760143
global_step: 10692, epoch: 68, loss: 0.864244
global_step: 10693, epoch: 68, loss: 0.888253
global_step: 10694, epoch: 68, loss: 0.633630
global_step: 10695, epoch: 68, loss: 0.813571
global_step: 10696, epoch: 68, loss: 0.799974
global_step: 10697, epoch: 68, loss: 0.932940
global_step: 10698, epoch: 68, loss: 0.690391
global_step: 10699, epoch: 68, loss: 0.697678
global_step: 10700, epoch: 68, loss: 0.712521
global_step: 10701, epoch: 68, loss: 0.709087
global_step: 10702, epoch: 68, loss: 0.753704
global_step: 10703, epoch: 68, loss: 0.819869
global_step: 10704, epoch: 68, loss: 0.839584
global_step: 10705, epoch: 68, loss: 0.826307
global_step: 10706, epoch: 68, loss: 0.772063
global_step: 10707, epoch: 68, loss: 0.822862
global_step: 10708, epoch: 68, loss: 0.786622
global_step: 10709, epoch: 68, loss: 0.796586
global_step: 10710, epoch: 68, loss: 0.799458
global_step: 10711, epoch: 68, loss: 0.702473
global_step: 10712, epoch: 68, loss: 0.675794
global_step: 10713, epoch: 68, loss: 0.674240
global_step: 10714, epoch: 68, loss: 0.681197
global_step: 10715, epoch: 68, loss: 0.851730
global_step: 10716, epoch: 68, loss: 0.723142
global_step: 10717, epoch: 68, loss: 0.889069
global_step: 10718, epoch: 68, loss: 0.707342
global_step: 10719, epoch: 68, loss: 0.763861
global_step: 10720, epoch: 68, loss: 0.845553
epoch: 68
train	acc: 0.8058	macro: p 0.6770, r 0.5438, f1: 0.5379	micro: p 0.8058, r 0.8058, f1 0.8058	weighted_f1:0.7808
dev	acc: 0.5834	macro: p 0.3704, r 0.3528, f1: 0.3522	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5447
test	acc: 0.6126	macro: p 0.3638, r 0.3503, f1: 0.3497	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5803
global_step: 10721, epoch: 69, loss: 0.737147
global_step: 10722, epoch: 69, loss: 0.818845
global_step: 10723, epoch: 69, loss: 0.715540
global_step: 10724, epoch: 69, loss: 0.766351
global_step: 10725, epoch: 69, loss: 0.675127
global_step: 10726, epoch: 69, loss: 0.771845
global_step: 10727, epoch: 69, loss: 0.831331
global_step: 10728, epoch: 69, loss: 0.743824
global_step: 10729, epoch: 69, loss: 0.678673
global_step: 10730, epoch: 69, loss: 0.771680
global_step: 10731, epoch: 69, loss: 0.763972
global_step: 10732, epoch: 69, loss: 0.775271
global_step: 10733, epoch: 69, loss: 0.735793
global_step: 10734, epoch: 69, loss: 0.697343
global_step: 10735, epoch: 69, loss: 0.753908
global_step: 10736, epoch: 69, loss: 0.853574
global_step: 10737, epoch: 69, loss: 0.739624
global_step: 10738, epoch: 69, loss: 0.813017
global_step: 10739, epoch: 69, loss: 0.850184
global_step: 10740, epoch: 69, loss: 0.809811
global_step: 10741, epoch: 69, loss: 0.765355
global_step: 10742, epoch: 69, loss: 0.680734
global_step: 10743, epoch: 69, loss: 0.744278
global_step: 10744, epoch: 69, loss: 0.701444
global_step: 10745, epoch: 69, loss: 0.809980
global_step: 10746, epoch: 69, loss: 0.781822
global_step: 10747, epoch: 69, loss: 0.625758
global_step: 10748, epoch: 69, loss: 0.811930
global_step: 10749, epoch: 69, loss: 0.778310
global_step: 10750, epoch: 69, loss: 0.802209
global_step: 10751, epoch: 69, loss: 0.719492
global_step: 10752, epoch: 69, loss: 0.759832
global_step: 10753, epoch: 69, loss: 0.767438
global_step: 10754, epoch: 69, loss: 0.913040
global_step: 10755, epoch: 69, loss: 0.781412
global_step: 10756, epoch: 69, loss: 0.804618
global_step: 10757, epoch: 69, loss: 0.735102
global_step: 10758, epoch: 69, loss: 0.720449
global_step: 10759, epoch: 69, loss: 0.767811
global_step: 10760, epoch: 69, loss: 1.190786
epoch: 69
train	acc: 0.8111	macro: p 0.6860, r 0.5564, f1: 0.5487	micro: p 0.8111, r 0.8111, f1 0.8111	weighted_f1:0.7908
dev	acc: 0.5699	macro: p 0.3624, r 0.3516, f1: 0.3474	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5407
test	acc: 0.6000	macro: p 0.5053, r 0.3555, f1: 0.3532	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5770
global_step: 10761, epoch: 70, loss: 0.763843
global_step: 10762, epoch: 70, loss: 0.798292
global_step: 10763, epoch: 70, loss: 0.785429
global_step: 10764, epoch: 70, loss: 0.753357
global_step: 10765, epoch: 70, loss: 0.753338
global_step: 10766, epoch: 70, loss: 0.649188
global_step: 10767, epoch: 70, loss: 0.695368
global_step: 10768, epoch: 70, loss: 0.845527
global_step: 10769, epoch: 70, loss: 0.722184
global_step: 10770, epoch: 70, loss: 0.674802
global_step: 10771, epoch: 70, loss: 0.651515
global_step: 10772, epoch: 70, loss: 0.797898
global_step: 10773, epoch: 70, loss: 0.662568
global_step: 10774, epoch: 70, loss: 0.784503
global_step: 10775, epoch: 70, loss: 0.693603
global_step: 10776, epoch: 70, loss: 0.627546
global_step: 10777, epoch: 70, loss: 0.841282
global_step: 10778, epoch: 70, loss: 0.817369
global_step: 10779, epoch: 70, loss: 0.708354
global_step: 10780, epoch: 70, loss: 0.686083
global_step: 10781, epoch: 70, loss: 0.732698
global_step: 10782, epoch: 70, loss: 0.741405
global_step: 10783, epoch: 70, loss: 0.816939
global_step: 10784, epoch: 70, loss: 0.709233
global_step: 10785, epoch: 70, loss: 0.732963
global_step: 10786, epoch: 70, loss: 0.663893
global_step: 10787, epoch: 70, loss: 0.862918
global_step: 10788, epoch: 70, loss: 0.760043
global_step: 10789, epoch: 70, loss: 0.732761
global_step: 10790, epoch: 70, loss: 0.789558
global_step: 10791, epoch: 70, loss: 0.753969
global_step: 10792, epoch: 70, loss: 0.778640
global_step: 10793, epoch: 70, loss: 0.860644
global_step: 10794, epoch: 70, loss: 0.763516
global_step: 10795, epoch: 70, loss: 0.777886
global_step: 10796, epoch: 70, loss: 0.745667
global_step: 10797, epoch: 70, loss: 0.736517
global_step: 10798, epoch: 70, loss: 0.651463
global_step: 10799, epoch: 70, loss: 0.721962
global_step: 10800, epoch: 70, loss: 0.561826
epoch: 70
train	acc: 0.7978	macro: p 0.6826, r 0.5374, f1: 0.5392	micro: p 0.7978, r 0.7978, f1 0.7978	weighted_f1:0.7733
dev	acc: 0.5735	macro: p 0.3672, r 0.3377, f1: 0.3419	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5326
test	acc: 0.6073	macro: p 0.3605, r 0.3333, f1: 0.3391	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5708
global_step: 10801, epoch: 71, loss: 0.719037
global_step: 10802, epoch: 71, loss: 0.781325
global_step: 10803, epoch: 71, loss: 0.782413
global_step: 10804, epoch: 71, loss: 0.835871
global_step: 10805, epoch: 71, loss: 0.727624
global_step: 10806, epoch: 71, loss: 0.782429
global_step: 10807, epoch: 71, loss: 0.639139
global_step: 10808, epoch: 71, loss: 0.680808
global_step: 10809, epoch: 71, loss: 0.842635
global_step: 10810, epoch: 71, loss: 0.767647
global_step: 10811, epoch: 71, loss: 0.722013
global_step: 10812, epoch: 71, loss: 0.738594
global_step: 10813, epoch: 71, loss: 0.659584
global_step: 10814, epoch: 71, loss: 0.809674
global_step: 10815, epoch: 71, loss: 0.931553
global_step: 10816, epoch: 71, loss: 0.684823
global_step: 10817, epoch: 71, loss: 0.738850
global_step: 10818, epoch: 71, loss: 0.796496
global_step: 10819, epoch: 71, loss: 0.689319
global_step: 10820, epoch: 71, loss: 0.749682
global_step: 10821, epoch: 71, loss: 0.626965
global_step: 10822, epoch: 71, loss: 0.743823
global_step: 10823, epoch: 71, loss: 0.632618
global_step: 10824, epoch: 71, loss: 0.762329
global_step: 10825, epoch: 71, loss: 0.707557
global_step: 10826, epoch: 71, loss: 0.681053
global_step: 10827, epoch: 71, loss: 0.757574
global_step: 10828, epoch: 71, loss: 0.693123
global_step: 10829, epoch: 71, loss: 0.756963
global_step: 10830, epoch: 71, loss: 0.780112
global_step: 10831, epoch: 71, loss: 0.780828
global_step: 10832, epoch: 71, loss: 0.713768
global_step: 10833, epoch: 71, loss: 0.736924
global_step: 10834, epoch: 71, loss: 0.859266
global_step: 10835, epoch: 71, loss: 0.717565
global_step: 10836, epoch: 71, loss: 0.789870
global_step: 10837, epoch: 71, loss: 0.745952
global_step: 10838, epoch: 71, loss: 0.714084
global_step: 10839, epoch: 71, loss: 0.709768
global_step: 10840, epoch: 71, loss: 1.979708
epoch: 71
train	acc: 0.8209	macro: p 0.6836, r 0.5720, f1: 0.5595	micro: p 0.8209, r 0.8209, f1 0.8209	weighted_f1:0.7988
dev	acc: 0.5744	macro: p 0.3562, r 0.3518, f1: 0.3489	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5398
test	acc: 0.6050	macro: p 0.3560, r 0.3564, f1: 0.3542	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5800
global_step: 10841, epoch: 72, loss: 0.678801
global_step: 10842, epoch: 72, loss: 0.764709
global_step: 10843, epoch: 72, loss: 0.815327
global_step: 10844, epoch: 72, loss: 0.781907
global_step: 10845, epoch: 72, loss: 0.652662
global_step: 10846, epoch: 72, loss: 0.631339
global_step: 10847, epoch: 72, loss: 0.659675
global_step: 10848, epoch: 72, loss: 0.746571
global_step: 10849, epoch: 72, loss: 0.687543
global_step: 10850, epoch: 72, loss: 0.707368
global_step: 10851, epoch: 72, loss: 0.768650
global_step: 10852, epoch: 72, loss: 0.778479
global_step: 10853, epoch: 72, loss: 0.717743
global_step: 10854, epoch: 72, loss: 0.716740
global_step: 10855, epoch: 72, loss: 0.724792
global_step: 10856, epoch: 72, loss: 0.676910
global_step: 10857, epoch: 72, loss: 0.715626
global_step: 10858, epoch: 72, loss: 0.803937
global_step: 10859, epoch: 72, loss: 0.699023
global_step: 10860, epoch: 72, loss: 0.813137
global_step: 10861, epoch: 72, loss: 0.663075
global_step: 10862, epoch: 72, loss: 0.679678
global_step: 10863, epoch: 72, loss: 0.711993
global_step: 10864, epoch: 72, loss: 0.777467
global_step: 10865, epoch: 72, loss: 0.754602
global_step: 10866, epoch: 72, loss: 0.753038
global_step: 10867, epoch: 72, loss: 0.736132
global_step: 10868, epoch: 72, loss: 0.663562
global_step: 10869, epoch: 72, loss: 0.725707
global_step: 10870, epoch: 72, loss: 0.802940
global_step: 10871, epoch: 72, loss: 0.657468
global_step: 10872, epoch: 72, loss: 0.629533
global_step: 10873, epoch: 72, loss: 0.728416
global_step: 10874, epoch: 72, loss: 0.792017
global_step: 10875, epoch: 72, loss: 0.840359
global_step: 10876, epoch: 72, loss: 0.708539
global_step: 10877, epoch: 72, loss: 0.724068
global_step: 10878, epoch: 72, loss: 0.736180
global_step: 10879, epoch: 72, loss: 0.754763
global_step: 10880, epoch: 72, loss: 0.862185
epoch: 72
train	acc: 0.8167	macro: p 0.6915, r 0.5577, f1: 0.5564	micro: p 0.8167, r 0.8167, f1 0.8167	weighted_f1:0.7926
dev	acc: 0.5780	macro: p 0.3681, r 0.3452, f1: 0.3453	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5373
test	acc: 0.6092	macro: p 0.3649, r 0.3423, f1: 0.3453	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5751
global_step: 10881, epoch: 73, loss: 0.709615
global_step: 10882, epoch: 73, loss: 0.690510
global_step: 10883, epoch: 73, loss: 0.717679
global_step: 10884, epoch: 73, loss: 0.718476
global_step: 10885, epoch: 73, loss: 0.762795
global_step: 10886, epoch: 73, loss: 0.733979
global_step: 10887, epoch: 73, loss: 0.617662
global_step: 10888, epoch: 73, loss: 0.721388
global_step: 10889, epoch: 73, loss: 0.801082
global_step: 10890, epoch: 73, loss: 0.728040
global_step: 10891, epoch: 73, loss: 0.728297
global_step: 10892, epoch: 73, loss: 0.634247
global_step: 10893, epoch: 73, loss: 0.675584
global_step: 10894, epoch: 73, loss: 0.712889
global_step: 10895, epoch: 73, loss: 0.742044
global_step: 10896, epoch: 73, loss: 0.809471
global_step: 10897, epoch: 73, loss: 0.684858
global_step: 10898, epoch: 73, loss: 0.665268
global_step: 10899, epoch: 73, loss: 0.740082
global_step: 10900, epoch: 73, loss: 0.717194
global_step: 10901, epoch: 73, loss: 0.717949
global_step: 10902, epoch: 73, loss: 0.716580
global_step: 10903, epoch: 73, loss: 0.726531
global_step: 10904, epoch: 73, loss: 0.771312
global_step: 10905, epoch: 73, loss: 0.738212
global_step: 10906, epoch: 73, loss: 0.749163
global_step: 10907, epoch: 73, loss: 0.812179
global_step: 10908, epoch: 73, loss: 0.747542
global_step: 10909, epoch: 73, loss: 0.668266
global_step: 10910, epoch: 73, loss: 0.740417
global_step: 10911, epoch: 73, loss: 0.726424
global_step: 10912, epoch: 73, loss: 0.775325
global_step: 10913, epoch: 73, loss: 0.567416
global_step: 10914, epoch: 73, loss: 0.718395
global_step: 10915, epoch: 73, loss: 0.706828
global_step: 10916, epoch: 73, loss: 0.711969
global_step: 10917, epoch: 73, loss: 0.728280
global_step: 10918, epoch: 73, loss: 0.558285
global_step: 10919, epoch: 73, loss: 0.689781
global_step: 10920, epoch: 73, loss: 0.504605
epoch: 73
train	acc: 0.8276	macro: p 0.6834, r 0.5764, f1: 0.5714	micro: p 0.8276, r 0.8276, f1 0.8276	weighted_f1:0.8054
dev	acc: 0.5771	macro: p 0.5040, r 0.3564, f1: 0.3589	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5412
test	acc: 0.6111	macro: p 0.5108, r 0.3574, f1: 0.3580	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5823
global_step: 10921, epoch: 74, loss: 0.719411
global_step: 10922, epoch: 74, loss: 0.743601
global_step: 10923, epoch: 74, loss: 0.797024
global_step: 10924, epoch: 74, loss: 0.624081
global_step: 10925, epoch: 74, loss: 0.667010
global_step: 10926, epoch: 74, loss: 0.716891
global_step: 10927, epoch: 74, loss: 0.691182
global_step: 10928, epoch: 74, loss: 0.774084
global_step: 10929, epoch: 74, loss: 0.688009
global_step: 10930, epoch: 74, loss: 0.624088
global_step: 10931, epoch: 74, loss: 0.723301
global_step: 10932, epoch: 74, loss: 0.723104
global_step: 10933, epoch: 74, loss: 0.678359
global_step: 10934, epoch: 74, loss: 0.743783
global_step: 10935, epoch: 74, loss: 0.684411
global_step: 10936, epoch: 74, loss: 0.736547
global_step: 10937, epoch: 74, loss: 0.748527
global_step: 10938, epoch: 74, loss: 0.724931
global_step: 10939, epoch: 74, loss: 0.692509
global_step: 10940, epoch: 74, loss: 0.693289
global_step: 10941, epoch: 74, loss: 0.775296
global_step: 10942, epoch: 74, loss: 0.643874
global_step: 10943, epoch: 74, loss: 0.669841
global_step: 10944, epoch: 74, loss: 0.755799
global_step: 10945, epoch: 74, loss: 0.709130
global_step: 10946, epoch: 74, loss: 0.769156
global_step: 10947, epoch: 74, loss: 0.672592
global_step: 10948, epoch: 74, loss: 0.716217
global_step: 10949, epoch: 74, loss: 0.750425
global_step: 10950, epoch: 74, loss: 0.652678
global_step: 10951, epoch: 74, loss: 0.736617
global_step: 10952, epoch: 74, loss: 0.711437
global_step: 10953, epoch: 74, loss: 0.729076
global_step: 10954, epoch: 74, loss: 0.901691
global_step: 10955, epoch: 74, loss: 0.746727
global_step: 10956, epoch: 74, loss: 0.698866
global_step: 10957, epoch: 74, loss: 0.659407
global_step: 10958, epoch: 74, loss: 0.697458
global_step: 10959, epoch: 74, loss: 0.735802
global_step: 10960, epoch: 74, loss: 0.736931
epoch: 74
train	acc: 0.8324	macro: p 0.6906, r 0.5908, f1: 0.5758	micro: p 0.8324, r 0.8324, f1 0.8324	weighted_f1:0.8123
dev	acc: 0.5681	macro: p 0.4911, r 0.3582, f1: 0.3597	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5400
test	acc: 0.6038	macro: p 0.3549, r 0.3621, f1: 0.3574	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5830
global_step: 10961, epoch: 75, loss: 0.742602
global_step: 10962, epoch: 75, loss: 0.740243
global_step: 10963, epoch: 75, loss: 0.850449
global_step: 10964, epoch: 75, loss: 0.791532
global_step: 10965, epoch: 75, loss: 0.638007
global_step: 10966, epoch: 75, loss: 0.694748
global_step: 10967, epoch: 75, loss: 0.768808
global_step: 10968, epoch: 75, loss: 0.697600
global_step: 10969, epoch: 75, loss: 0.671624
global_step: 10970, epoch: 75, loss: 0.711985
global_step: 10971, epoch: 75, loss: 0.607683
global_step: 10972, epoch: 75, loss: 0.717125
global_step: 10973, epoch: 75, loss: 0.681222
global_step: 10974, epoch: 75, loss: 0.708488
global_step: 10975, epoch: 75, loss: 0.665239
global_step: 10976, epoch: 75, loss: 0.657210
global_step: 10977, epoch: 75, loss: 0.701735
global_step: 10978, epoch: 75, loss: 0.698997
global_step: 10979, epoch: 75, loss: 0.621216
global_step: 10980, epoch: 75, loss: 0.766074
global_step: 10981, epoch: 75, loss: 0.704154
global_step: 10982, epoch: 75, loss: 0.739051
global_step: 10983, epoch: 75, loss: 0.791380
global_step: 10984, epoch: 75, loss: 0.656768
global_step: 10985, epoch: 75, loss: 0.656549
global_step: 10986, epoch: 75, loss: 0.794373
global_step: 10987, epoch: 75, loss: 0.770427
global_step: 10988, epoch: 75, loss: 0.740902
global_step: 10989, epoch: 75, loss: 0.581738
global_step: 10990, epoch: 75, loss: 0.754521
global_step: 10991, epoch: 75, loss: 0.731148
global_step: 10992, epoch: 75, loss: 0.658082
global_step: 10993, epoch: 75, loss: 0.639786
global_step: 10994, epoch: 75, loss: 0.629999
global_step: 10995, epoch: 75, loss: 0.683169
global_step: 10996, epoch: 75, loss: 0.772006
global_step: 10997, epoch: 75, loss: 0.676002
global_step: 10998, epoch: 75, loss: 0.622795
global_step: 10999, epoch: 75, loss: 0.680456
global_step: 11000, epoch: 75, loss: 0.845732
epoch: 75
train	acc: 0.8005	macro: p 0.6997, r 0.5355, f1: 0.5496	micro: p 0.8005, r 0.8005, f1 0.8005	weighted_f1:0.7740
dev	acc: 0.5717	macro: p 0.5242, r 0.3372, f1: 0.3491	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5259
test	acc: 0.6130	macro: p 0.3668, r 0.3278, f1: 0.3351	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5687
global_step: 11001, epoch: 76, loss: 0.769658
global_step: 11002, epoch: 76, loss: 0.741373
global_step: 11003, epoch: 76, loss: 0.732736
global_step: 11004, epoch: 76, loss: 0.715278
global_step: 11005, epoch: 76, loss: 0.694328
global_step: 11006, epoch: 76, loss: 0.617694
global_step: 11007, epoch: 76, loss: 0.706291
global_step: 11008, epoch: 76, loss: 0.688261
global_step: 11009, epoch: 76, loss: 0.698338
global_step: 11010, epoch: 76, loss: 0.650672
global_step: 11011, epoch: 76, loss: 0.812474
global_step: 11012, epoch: 76, loss: 0.697251
global_step: 11013, epoch: 76, loss: 0.729422
global_step: 11014, epoch: 76, loss: 0.656099
global_step: 11015, epoch: 76, loss: 0.692515
global_step: 11016, epoch: 76, loss: 0.669581
global_step: 11017, epoch: 76, loss: 0.646663
global_step: 11018, epoch: 76, loss: 0.608444
global_step: 11019, epoch: 76, loss: 0.841477
global_step: 11020, epoch: 76, loss: 0.726727
global_step: 11021, epoch: 76, loss: 0.585901
global_step: 11022, epoch: 76, loss: 0.681975
global_step: 11023, epoch: 76, loss: 0.722701
global_step: 11024, epoch: 76, loss: 0.666869
global_step: 11025, epoch: 76, loss: 0.648503
global_step: 11026, epoch: 76, loss: 0.662988
global_step: 11027, epoch: 76, loss: 0.783060
global_step: 11028, epoch: 76, loss: 0.633700
global_step: 11029, epoch: 76, loss: 0.619846
global_step: 11030, epoch: 76, loss: 0.695798
global_step: 11031, epoch: 76, loss: 0.706095
global_step: 11032, epoch: 76, loss: 0.668288
global_step: 11033, epoch: 76, loss: 0.773020
global_step: 11034, epoch: 76, loss: 0.708591
global_step: 11035, epoch: 76, loss: 0.676103
global_step: 11036, epoch: 76, loss: 0.715189
global_step: 11037, epoch: 76, loss: 0.668845
global_step: 11038, epoch: 76, loss: 0.634623
global_step: 11039, epoch: 76, loss: 0.753007
global_step: 11040, epoch: 76, loss: 0.659707
epoch: 76
train	acc: 0.8346	macro: p 0.6938, r 0.5836, f1: 0.5811	micro: p 0.8346, r 0.8346, f1 0.8346	weighted_f1:0.8127
dev	acc: 0.5708	macro: p 0.4957, r 0.3485, f1: 0.3484	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5330
test	acc: 0.6054	macro: p 0.5034, r 0.3501, f1: 0.3489	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5757
global_step: 11041, epoch: 77, loss: 0.683487
global_step: 11042, epoch: 77, loss: 0.662318
global_step: 11043, epoch: 77, loss: 0.662897
global_step: 11044, epoch: 77, loss: 0.669576
global_step: 11045, epoch: 77, loss: 0.648008
global_step: 11046, epoch: 77, loss: 0.712563
global_step: 11047, epoch: 77, loss: 0.683140
global_step: 11048, epoch: 77, loss: 0.680601
global_step: 11049, epoch: 77, loss: 0.670085
global_step: 11050, epoch: 77, loss: 0.634496
global_step: 11051, epoch: 77, loss: 0.603374
global_step: 11052, epoch: 77, loss: 0.709903
global_step: 11053, epoch: 77, loss: 0.642229
global_step: 11054, epoch: 77, loss: 0.704464
global_step: 11055, epoch: 77, loss: 0.664971
global_step: 11056, epoch: 77, loss: 0.753882
global_step: 11057, epoch: 77, loss: 0.616411
global_step: 11058, epoch: 77, loss: 0.707070
global_step: 11059, epoch: 77, loss: 0.744675
global_step: 11060, epoch: 77, loss: 0.615396
global_step: 11061, epoch: 77, loss: 0.660469
global_step: 11062, epoch: 77, loss: 0.801141
global_step: 11063, epoch: 77, loss: 0.820689
global_step: 11064, epoch: 77, loss: 0.748545
global_step: 11065, epoch: 77, loss: 0.843923
global_step: 11066, epoch: 77, loss: 0.772357
global_step: 11067, epoch: 77, loss: 0.641486
global_step: 11068, epoch: 77, loss: 0.636283
global_step: 11069, epoch: 77, loss: 0.674097
global_step: 11070, epoch: 77, loss: 0.808211
global_step: 11071, epoch: 77, loss: 0.701545
global_step: 11072, epoch: 77, loss: 0.779202
global_step: 11073, epoch: 77, loss: 0.669922
global_step: 11074, epoch: 77, loss: 0.659767
global_step: 11075, epoch: 77, loss: 0.742161
global_step: 11076, epoch: 77, loss: 0.652431
global_step: 11077, epoch: 77, loss: 0.660610
global_step: 11078, epoch: 77, loss: 0.808350
global_step: 11079, epoch: 77, loss: 0.603216
global_step: 11080, epoch: 77, loss: 1.591810
epoch: 77
train	acc: 0.8428	macro: p 0.6920, r 0.6133, f1: 0.6076	micro: p 0.8428, r 0.8428, f1 0.8428	weighted_f1:0.8250
dev	acc: 0.5681	macro: p 0.4913, r 0.3590, f1: 0.3593	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5392
test	acc: 0.5954	macro: p 0.4438, r 0.3613, f1: 0.3593	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5760
global_step: 11081, epoch: 78, loss: 0.778550
global_step: 11082, epoch: 78, loss: 0.739655
global_step: 11083, epoch: 78, loss: 0.764284
global_step: 11084, epoch: 78, loss: 0.581553
global_step: 11085, epoch: 78, loss: 0.612334
global_step: 11086, epoch: 78, loss: 0.609177
global_step: 11087, epoch: 78, loss: 0.746300
global_step: 11088, epoch: 78, loss: 0.608525
global_step: 11089, epoch: 78, loss: 0.634504
global_step: 11090, epoch: 78, loss: 0.652473
global_step: 11091, epoch: 78, loss: 0.718187
global_step: 11092, epoch: 78, loss: 0.614678
global_step: 11093, epoch: 78, loss: 0.698589
global_step: 11094, epoch: 78, loss: 0.646717
global_step: 11095, epoch: 78, loss: 0.649629
global_step: 11096, epoch: 78, loss: 0.706654
global_step: 11097, epoch: 78, loss: 0.697254
global_step: 11098, epoch: 78, loss: 0.749255
global_step: 11099, epoch: 78, loss: 0.705723
global_step: 11100, epoch: 78, loss: 0.748282
global_step: 11101, epoch: 78, loss: 0.657295
global_step: 11102, epoch: 78, loss: 0.660409
global_step: 11103, epoch: 78, loss: 0.613317
global_step: 11104, epoch: 78, loss: 0.700896
global_step: 11105, epoch: 78, loss: 0.679637
global_step: 11106, epoch: 78, loss: 0.738560
global_step: 11107, epoch: 78, loss: 0.615862
global_step: 11108, epoch: 78, loss: 0.682114
global_step: 11109, epoch: 78, loss: 0.742924
global_step: 11110, epoch: 78, loss: 0.649834
global_step: 11111, epoch: 78, loss: 0.710253
global_step: 11112, epoch: 78, loss: 0.674702
global_step: 11113, epoch: 78, loss: 0.729200
global_step: 11114, epoch: 78, loss: 0.690268
global_step: 11115, epoch: 78, loss: 0.643540
global_step: 11116, epoch: 78, loss: 0.701230
global_step: 11117, epoch: 78, loss: 0.640603
global_step: 11118, epoch: 78, loss: 0.752304
global_step: 11119, epoch: 78, loss: 0.656000
global_step: 11120, epoch: 78, loss: 0.900324
epoch: 78
train	acc: 0.8308	macro: p 0.6988, r 0.5852, f1: 0.5959	micro: p 0.8308, r 0.8308, f1 0.8308	weighted_f1:0.8091
dev	acc: 0.5717	macro: p 0.5105, r 0.3443, f1: 0.3514	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5299
test	acc: 0.6123	macro: p 0.5079, r 0.3423, f1: 0.3469	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5748
global_step: 11121, epoch: 79, loss: 0.666305
global_step: 11122, epoch: 79, loss: 0.601174
global_step: 11123, epoch: 79, loss: 0.562298
global_step: 11124, epoch: 79, loss: 0.618207
global_step: 11125, epoch: 79, loss: 0.649500
global_step: 11126, epoch: 79, loss: 0.588471
global_step: 11127, epoch: 79, loss: 0.681501
global_step: 11128, epoch: 79, loss: 0.713075
global_step: 11129, epoch: 79, loss: 0.587188
global_step: 11130, epoch: 79, loss: 0.630530
global_step: 11131, epoch: 79, loss: 0.653110
global_step: 11132, epoch: 79, loss: 0.625183
global_step: 11133, epoch: 79, loss: 0.693882
global_step: 11134, epoch: 79, loss: 0.687762
global_step: 11135, epoch: 79, loss: 0.612449
global_step: 11136, epoch: 79, loss: 0.705384
global_step: 11137, epoch: 79, loss: 0.701520
global_step: 11138, epoch: 79, loss: 0.688109
global_step: 11139, epoch: 79, loss: 0.707835
global_step: 11140, epoch: 79, loss: 0.553625
global_step: 11141, epoch: 79, loss: 0.640266
global_step: 11142, epoch: 79, loss: 0.639674
global_step: 11143, epoch: 79, loss: 0.652571
global_step: 11144, epoch: 79, loss: 0.749221
global_step: 11145, epoch: 79, loss: 0.699096
global_step: 11146, epoch: 79, loss: 0.626466
global_step: 11147, epoch: 79, loss: 0.690996
global_step: 11148, epoch: 79, loss: 0.730606
global_step: 11149, epoch: 79, loss: 0.776483
global_step: 11150, epoch: 79, loss: 0.752438
global_step: 11151, epoch: 79, loss: 0.772428
global_step: 11152, epoch: 79, loss: 0.724856
global_step: 11153, epoch: 79, loss: 0.732864
global_step: 11154, epoch: 79, loss: 0.684536
global_step: 11155, epoch: 79, loss: 0.702280
global_step: 11156, epoch: 79, loss: 0.630223
global_step: 11157, epoch: 79, loss: 0.652267
global_step: 11158, epoch: 79, loss: 0.629496
global_step: 11159, epoch: 79, loss: 0.779594
global_step: 11160, epoch: 79, loss: 0.823735
epoch: 79
train	acc: 0.8446	macro: p 0.6936, r 0.6145, f1: 0.6055	micro: p 0.8446, r 0.8446, f1 0.8446	weighted_f1:0.8275
dev	acc: 0.5699	macro: p 0.4943, r 0.3614, f1: 0.3629	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5455
test	acc: 0.5946	macro: p 0.4957, r 0.3620, f1: 0.3587	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5781
global_step: 11161, epoch: 80, loss: 0.632242
global_step: 11162, epoch: 80, loss: 0.594704
global_step: 11163, epoch: 80, loss: 0.681963
global_step: 11164, epoch: 80, loss: 0.645839
global_step: 11165, epoch: 80, loss: 0.723197
global_step: 11166, epoch: 80, loss: 0.687636
global_step: 11167, epoch: 80, loss: 0.617905
global_step: 11168, epoch: 80, loss: 0.703548
global_step: 11169, epoch: 80, loss: 0.738642
global_step: 11170, epoch: 80, loss: 0.743286
global_step: 11171, epoch: 80, loss: 0.673024
global_step: 11172, epoch: 80, loss: 0.572643
global_step: 11173, epoch: 80, loss: 0.554122
global_step: 11174, epoch: 80, loss: 0.675809
global_step: 11175, epoch: 80, loss: 0.749611
global_step: 11176, epoch: 80, loss: 0.719721
global_step: 11177, epoch: 80, loss: 0.650097
global_step: 11178, epoch: 80, loss: 0.692414
global_step: 11179, epoch: 80, loss: 0.676215
global_step: 11180, epoch: 80, loss: 0.564226
global_step: 11181, epoch: 80, loss: 0.573218
global_step: 11182, epoch: 80, loss: 0.674740
global_step: 11183, epoch: 80, loss: 0.634793
global_step: 11184, epoch: 80, loss: 0.603496
global_step: 11185, epoch: 80, loss: 0.665139
global_step: 11186, epoch: 80, loss: 0.675617
global_step: 11187, epoch: 80, loss: 0.615582
global_step: 11188, epoch: 80, loss: 0.659238
global_step: 11189, epoch: 80, loss: 0.719737
global_step: 11190, epoch: 80, loss: 0.760258
global_step: 11191, epoch: 80, loss: 0.688116
global_step: 11192, epoch: 80, loss: 0.783931
global_step: 11193, epoch: 80, loss: 0.715849
global_step: 11194, epoch: 80, loss: 0.630373
global_step: 11195, epoch: 80, loss: 0.642481
global_step: 11196, epoch: 80, loss: 0.726076
global_step: 11197, epoch: 80, loss: 0.802018
global_step: 11198, epoch: 80, loss: 0.692510
global_step: 11199, epoch: 80, loss: 0.653114
global_step: 11200, epoch: 80, loss: 0.366906
epoch: 80
train	acc: 0.8070	macro: p 0.7035, r 0.5415, f1: 0.5577	micro: p 0.8070, r 0.8070, f1 0.8070	weighted_f1:0.7806
dev	acc: 0.5717	macro: p 0.5224, r 0.3344, f1: 0.3447	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5231
test	acc: 0.6138	macro: p 0.3673, r 0.3258, f1: 0.3324	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5675
global_step: 11201, epoch: 81, loss: 0.695879
global_step: 11202, epoch: 81, loss: 0.696245
global_step: 11203, epoch: 81, loss: 0.664157
global_step: 11204, epoch: 81, loss: 0.601455
global_step: 11205, epoch: 81, loss: 0.657055
global_step: 11206, epoch: 81, loss: 0.615998
global_step: 11207, epoch: 81, loss: 0.614318
global_step: 11208, epoch: 81, loss: 0.672124
global_step: 11209, epoch: 81, loss: 0.642995
global_step: 11210, epoch: 81, loss: 0.664935
global_step: 11211, epoch: 81, loss: 0.709450
global_step: 11212, epoch: 81, loss: 0.620665
global_step: 11213, epoch: 81, loss: 0.646098
global_step: 11214, epoch: 81, loss: 0.621952
global_step: 11215, epoch: 81, loss: 0.673638
global_step: 11216, epoch: 81, loss: 0.685867
global_step: 11217, epoch: 81, loss: 0.700814
global_step: 11218, epoch: 81, loss: 0.544441
global_step: 11219, epoch: 81, loss: 0.740632
global_step: 11220, epoch: 81, loss: 0.682569
global_step: 11221, epoch: 81, loss: 0.523959
global_step: 11222, epoch: 81, loss: 0.567298
global_step: 11223, epoch: 81, loss: 0.756243
global_step: 11224, epoch: 81, loss: 0.698695
global_step: 11225, epoch: 81, loss: 0.581195
global_step: 11226, epoch: 81, loss: 0.607148
global_step: 11227, epoch: 81, loss: 0.660465
global_step: 11228, epoch: 81, loss: 0.605545
global_step: 11229, epoch: 81, loss: 0.722897
global_step: 11230, epoch: 81, loss: 0.706149
global_step: 11231, epoch: 81, loss: 0.659540
global_step: 11232, epoch: 81, loss: 0.751346
global_step: 11233, epoch: 81, loss: 0.737164
global_step: 11234, epoch: 81, loss: 0.608165
global_step: 11235, epoch: 81, loss: 0.672686
global_step: 11236, epoch: 81, loss: 0.595436
global_step: 11237, epoch: 81, loss: 0.604463
global_step: 11238, epoch: 81, loss: 0.699977
global_step: 11239, epoch: 81, loss: 0.797841
global_step: 11240, epoch: 81, loss: 0.057680
epoch: 81
train	acc: 0.8335	macro: p 0.7107, r 0.5860, f1: 0.5970	micro: p 0.8335, r 0.8335, f1 0.8335	weighted_f1:0.8111
dev	acc: 0.5735	macro: p 0.4480, r 0.3439, f1: 0.3508	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5278
test	acc: 0.6115	macro: p 0.5023, r 0.3374, f1: 0.3413	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5706
global_step: 11241, epoch: 82, loss: 0.653939
global_step: 11242, epoch: 82, loss: 0.681660
global_step: 11243, epoch: 82, loss: 0.699423
global_step: 11244, epoch: 82, loss: 0.672638
global_step: 11245, epoch: 82, loss: 0.756744
global_step: 11246, epoch: 82, loss: 0.673707
global_step: 11247, epoch: 82, loss: 0.564211
global_step: 11248, epoch: 82, loss: 0.639164
global_step: 11249, epoch: 82, loss: 0.541618
global_step: 11250, epoch: 82, loss: 0.686834
global_step: 11251, epoch: 82, loss: 0.551309
global_step: 11252, epoch: 82, loss: 0.677850
global_step: 11253, epoch: 82, loss: 0.733046
global_step: 11254, epoch: 82, loss: 0.695700
global_step: 11255, epoch: 82, loss: 0.630137
global_step: 11256, epoch: 82, loss: 0.611290
global_step: 11257, epoch: 82, loss: 0.627317
global_step: 11258, epoch: 82, loss: 0.696044
global_step: 11259, epoch: 82, loss: 0.670656
global_step: 11260, epoch: 82, loss: 0.736652
global_step: 11261, epoch: 82, loss: 0.610644
global_step: 11262, epoch: 82, loss: 0.605890
global_step: 11263, epoch: 82, loss: 0.760944
global_step: 11264, epoch: 82, loss: 0.668830
global_step: 11265, epoch: 82, loss: 0.663748
global_step: 11266, epoch: 82, loss: 0.618935
global_step: 11267, epoch: 82, loss: 0.604861
global_step: 11268, epoch: 82, loss: 0.630108
global_step: 11269, epoch: 82, loss: 0.680024
global_step: 11270, epoch: 82, loss: 0.719115
global_step: 11271, epoch: 82, loss: 0.619143
global_step: 11272, epoch: 82, loss: 0.654005
global_step: 11273, epoch: 82, loss: 0.627813
global_step: 11274, epoch: 82, loss: 0.624029
global_step: 11275, epoch: 82, loss: 0.732983
global_step: 11276, epoch: 82, loss: 0.559270
global_step: 11277, epoch: 82, loss: 0.705111
global_step: 11278, epoch: 82, loss: 0.727526
global_step: 11279, epoch: 82, loss: 0.634168
global_step: 11280, epoch: 82, loss: 0.560398
epoch: 82
train	acc: 0.8083	macro: p 0.7116, r 0.5487, f1: 0.5694	micro: p 0.8083, r 0.8083, f1 0.8083	weighted_f1:0.7833
dev	acc: 0.5735	macro: p 0.5287, r 0.3351, f1: 0.3486	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5262
test	acc: 0.6115	macro: p 0.5138, r 0.3232, f1: 0.3342	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5650
global_step: 11281, epoch: 83, loss: 0.713774
global_step: 11282, epoch: 83, loss: 0.645279
global_step: 11283, epoch: 83, loss: 0.599452
global_step: 11284, epoch: 83, loss: 0.582655
global_step: 11285, epoch: 83, loss: 0.625519
global_step: 11286, epoch: 83, loss: 0.717294
global_step: 11287, epoch: 83, loss: 0.705206
global_step: 11288, epoch: 83, loss: 0.738037
global_step: 11289, epoch: 83, loss: 0.631916
global_step: 11290, epoch: 83, loss: 0.662910
global_step: 11291, epoch: 83, loss: 0.597502
global_step: 11292, epoch: 83, loss: 0.582286
global_step: 11293, epoch: 83, loss: 0.680716
global_step: 11294, epoch: 83, loss: 0.535487
global_step: 11295, epoch: 83, loss: 0.721643
global_step: 11296, epoch: 83, loss: 0.578293
global_step: 11297, epoch: 83, loss: 0.691670
global_step: 11298, epoch: 83, loss: 0.715437
global_step: 11299, epoch: 83, loss: 0.685372
global_step: 11300, epoch: 83, loss: 0.740325
global_step: 11301, epoch: 83, loss: 0.660700
global_step: 11302, epoch: 83, loss: 0.596645
global_step: 11303, epoch: 83, loss: 0.593067
global_step: 11304, epoch: 83, loss: 0.649198
global_step: 11305, epoch: 83, loss: 0.706423
global_step: 11306, epoch: 83, loss: 0.610735
global_step: 11307, epoch: 83, loss: 0.672946
global_step: 11308, epoch: 83, loss: 0.705926
global_step: 11309, epoch: 83, loss: 0.568543
global_step: 11310, epoch: 83, loss: 0.717737
global_step: 11311, epoch: 83, loss: 0.680149
global_step: 11312, epoch: 83, loss: 0.775961
global_step: 11313, epoch: 83, loss: 0.612266
global_step: 11314, epoch: 83, loss: 0.650576
global_step: 11315, epoch: 83, loss: 0.548083
global_step: 11316, epoch: 83, loss: 0.592420
global_step: 11317, epoch: 83, loss: 0.601659
global_step: 11318, epoch: 83, loss: 0.688260
global_step: 11319, epoch: 83, loss: 0.564833
global_step: 11320, epoch: 83, loss: 0.161366
epoch: 83
train	acc: 0.8240	macro: p 0.7064, r 0.5693, f1: 0.5874	micro: p 0.8240, r 0.8240, f1 0.8240	weighted_f1:0.8004
dev	acc: 0.5618	macro: p 0.5141, r 0.3279, f1: 0.3341	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5122
test	acc: 0.6107	macro: p 0.3655, r 0.3260, f1: 0.3298	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5653
global_step: 11321, epoch: 84, loss: 0.618563
global_step: 11322, epoch: 84, loss: 0.666453
global_step: 11323, epoch: 84, loss: 0.751626
global_step: 11324, epoch: 84, loss: 0.594965
global_step: 11325, epoch: 84, loss: 0.699468
global_step: 11326, epoch: 84, loss: 0.698144
global_step: 11327, epoch: 84, loss: 0.705461
global_step: 11328, epoch: 84, loss: 0.567079
global_step: 11329, epoch: 84, loss: 0.650746
global_step: 11330, epoch: 84, loss: 0.704508
global_step: 11331, epoch: 84, loss: 0.627523
global_step: 11332, epoch: 84, loss: 0.690891
global_step: 11333, epoch: 84, loss: 0.623304
global_step: 11334, epoch: 84, loss: 0.612642
global_step: 11335, epoch: 84, loss: 0.642851
global_step: 11336, epoch: 84, loss: 0.666124
global_step: 11337, epoch: 84, loss: 0.710711
global_step: 11338, epoch: 84, loss: 0.613896
global_step: 11339, epoch: 84, loss: 0.633631
global_step: 11340, epoch: 84, loss: 0.677306
global_step: 11341, epoch: 84, loss: 0.569952
global_step: 11342, epoch: 84, loss: 0.636172
global_step: 11343, epoch: 84, loss: 0.614473
global_step: 11344, epoch: 84, loss: 0.533533
global_step: 11345, epoch: 84, loss: 0.590635
global_step: 11346, epoch: 84, loss: 0.625277
global_step: 11347, epoch: 84, loss: 0.735565
global_step: 11348, epoch: 84, loss: 0.670956
global_step: 11349, epoch: 84, loss: 0.592207
global_step: 11350, epoch: 84, loss: 0.566839
global_step: 11351, epoch: 84, loss: 0.706248
global_step: 11352, epoch: 84, loss: 0.616612
global_step: 11353, epoch: 84, loss: 0.549220
global_step: 11354, epoch: 84, loss: 0.525545
global_step: 11355, epoch: 84, loss: 0.580473
global_step: 11356, epoch: 84, loss: 0.611849
global_step: 11357, epoch: 84, loss: 0.741108
global_step: 11358, epoch: 84, loss: 0.583372
global_step: 11359, epoch: 84, loss: 0.635821
global_step: 11360, epoch: 84, loss: 0.734188
epoch: 84
train	acc: 0.8460	macro: p 0.7171, r 0.6027, f1: 0.6088	micro: p 0.8460, r 0.8460, f1 0.8460	weighted_f1:0.8252
dev	acc: 0.5798	macro: p 0.5210, r 0.3499, f1: 0.3570	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5380
test	acc: 0.6096	macro: p 0.5034, r 0.3389, f1: 0.3418	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5727
global_step: 11361, epoch: 85, loss: 0.553313
global_step: 11362, epoch: 85, loss: 0.615997
global_step: 11363, epoch: 85, loss: 0.632201
global_step: 11364, epoch: 85, loss: 0.611794
global_step: 11365, epoch: 85, loss: 0.653826
global_step: 11366, epoch: 85, loss: 0.606489
global_step: 11367, epoch: 85, loss: 0.632662
global_step: 11368, epoch: 85, loss: 0.587884
global_step: 11369, epoch: 85, loss: 0.557883
global_step: 11370, epoch: 85, loss: 0.644419
global_step: 11371, epoch: 85, loss: 0.772226
global_step: 11372, epoch: 85, loss: 0.617562
global_step: 11373, epoch: 85, loss: 0.631692
global_step: 11374, epoch: 85, loss: 0.584996
global_step: 11375, epoch: 85, loss: 0.561526
global_step: 11376, epoch: 85, loss: 0.563228
global_step: 11377, epoch: 85, loss: 0.518052
global_step: 11378, epoch: 85, loss: 0.538848
global_step: 11379, epoch: 85, loss: 0.593358
global_step: 11380, epoch: 85, loss: 0.609322
global_step: 11381, epoch: 85, loss: 0.722930
global_step: 11382, epoch: 85, loss: 0.706029
global_step: 11383, epoch: 85, loss: 0.684749
global_step: 11384, epoch: 85, loss: 0.668765
global_step: 11385, epoch: 85, loss: 0.679549
global_step: 11386, epoch: 85, loss: 0.613421
global_step: 11387, epoch: 85, loss: 0.600367
global_step: 11388, epoch: 85, loss: 0.597225
global_step: 11389, epoch: 85, loss: 0.653576
global_step: 11390, epoch: 85, loss: 0.766705
global_step: 11391, epoch: 85, loss: 0.573933
global_step: 11392, epoch: 85, loss: 0.632022
global_step: 11393, epoch: 85, loss: 0.616984
global_step: 11394, epoch: 85, loss: 0.739387
global_step: 11395, epoch: 85, loss: 0.658918
global_step: 11396, epoch: 85, loss: 0.615603
global_step: 11397, epoch: 85, loss: 0.568055
global_step: 11398, epoch: 85, loss: 0.652741
global_step: 11399, epoch: 85, loss: 0.664581
global_step: 11400, epoch: 85, loss: 0.433149
epoch: 85
train	acc: 0.8601	macro: p 0.7147, r 0.6363, f1: 0.6407	micro: p 0.8601, r 0.8601, f1 0.8601	weighted_f1:0.8426
dev	acc: 0.5663	macro: p 0.3855, r 0.3512, f1: 0.3482	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5313
test	acc: 0.5962	macro: p 0.4356, r 0.3566, f1: 0.3551	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5716
global_step: 11401, epoch: 86, loss: 0.671677
global_step: 11402, epoch: 86, loss: 0.537043
global_step: 11403, epoch: 86, loss: 0.601509
global_step: 11404, epoch: 86, loss: 0.603237
global_step: 11405, epoch: 86, loss: 0.602750
global_step: 11406, epoch: 86, loss: 0.693889
global_step: 11407, epoch: 86, loss: 0.618539
global_step: 11408, epoch: 86, loss: 0.622359
global_step: 11409, epoch: 86, loss: 0.634643
global_step: 11410, epoch: 86, loss: 0.524987
global_step: 11411, epoch: 86, loss: 0.628927
global_step: 11412, epoch: 86, loss: 0.677888
global_step: 11413, epoch: 86, loss: 0.561935
global_step: 11414, epoch: 86, loss: 0.604151
global_step: 11415, epoch: 86, loss: 0.583516
global_step: 11416, epoch: 86, loss: 0.685793
global_step: 11417, epoch: 86, loss: 0.696099
global_step: 11418, epoch: 86, loss: 0.601014
global_step: 11419, epoch: 86, loss: 0.659610
global_step: 11420, epoch: 86, loss: 0.659132
global_step: 11421, epoch: 86, loss: 0.628112
global_step: 11422, epoch: 86, loss: 0.574347
global_step: 11423, epoch: 86, loss: 0.632752
global_step: 11424, epoch: 86, loss: 0.655288
global_step: 11425, epoch: 86, loss: 0.645817
global_step: 11426, epoch: 86, loss: 0.665766
global_step: 11427, epoch: 86, loss: 0.553013
global_step: 11428, epoch: 86, loss: 0.585109
global_step: 11429, epoch: 86, loss: 0.586421
global_step: 11430, epoch: 86, loss: 0.607338
global_step: 11431, epoch: 86, loss: 0.531993
global_step: 11432, epoch: 86, loss: 0.613584
global_step: 11433, epoch: 86, loss: 0.701970
global_step: 11434, epoch: 86, loss: 0.611703
global_step: 11435, epoch: 86, loss: 0.578932
global_step: 11436, epoch: 86, loss: 0.500533
global_step: 11437, epoch: 86, loss: 0.617550
global_step: 11438, epoch: 86, loss: 0.633169
global_step: 11439, epoch: 86, loss: 0.661343
global_step: 11440, epoch: 86, loss: 0.621502
epoch: 86
train	acc: 0.8622	macro: p 0.8640, r 0.6378, f1: 0.6451	micro: p 0.8622, r 0.8622, f1 0.8622	weighted_f1:0.8444
dev	acc: 0.5708	macro: p 0.4108, r 0.3524, f1: 0.3547	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5338
test	acc: 0.6042	macro: p 0.4397, r 0.3519, f1: 0.3555	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5747
global_step: 11441, epoch: 87, loss: 0.650666
global_step: 11442, epoch: 87, loss: 0.610364
global_step: 11443, epoch: 87, loss: 0.657430
global_step: 11444, epoch: 87, loss: 0.569954
global_step: 11445, epoch: 87, loss: 0.652031
global_step: 11446, epoch: 87, loss: 0.622602
global_step: 11447, epoch: 87, loss: 0.572994
global_step: 11448, epoch: 87, loss: 0.574282
global_step: 11449, epoch: 87, loss: 0.525388
global_step: 11450, epoch: 87, loss: 0.507255
global_step: 11451, epoch: 87, loss: 0.625375
global_step: 11452, epoch: 87, loss: 0.600133
global_step: 11453, epoch: 87, loss: 0.651813
global_step: 11454, epoch: 87, loss: 0.551991
global_step: 11455, epoch: 87, loss: 0.634614
global_step: 11456, epoch: 87, loss: 0.505246
global_step: 11457, epoch: 87, loss: 0.652692
global_step: 11458, epoch: 87, loss: 0.615901
global_step: 11459, epoch: 87, loss: 0.615405
global_step: 11460, epoch: 87, loss: 0.661392
global_step: 11461, epoch: 87, loss: 0.550580
global_step: 11462, epoch: 87, loss: 0.599854
global_step: 11463, epoch: 87, loss: 0.498594
global_step: 11464, epoch: 87, loss: 0.691303
global_step: 11465, epoch: 87, loss: 0.519411
global_step: 11466, epoch: 87, loss: 0.642503
global_step: 11467, epoch: 87, loss: 0.704453
global_step: 11468, epoch: 87, loss: 0.677843
global_step: 11469, epoch: 87, loss: 0.570622
global_step: 11470, epoch: 87, loss: 0.679983
global_step: 11471, epoch: 87, loss: 0.612708
global_step: 11472, epoch: 87, loss: 0.554243
global_step: 11473, epoch: 87, loss: 0.621971
global_step: 11474, epoch: 87, loss: 0.641123
global_step: 11475, epoch: 87, loss: 0.521926
global_step: 11476, epoch: 87, loss: 0.624469
global_step: 11477, epoch: 87, loss: 0.690355
global_step: 11478, epoch: 87, loss: 0.605225
global_step: 11479, epoch: 87, loss: 0.652640
global_step: 11480, epoch: 87, loss: 0.697277
epoch: 87
train	acc: 0.8306	macro: p 0.7152, r 0.5866, f1: 0.6048	micro: p 0.8306, r 0.8306, f1 0.8306	weighted_f1:0.8094
dev	acc: 0.5645	macro: p 0.5176, r 0.3287, f1: 0.3380	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5166
test	acc: 0.6042	macro: p 0.5026, r 0.3206, f1: 0.3290	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5608
global_step: 11481, epoch: 88, loss: 0.675491
global_step: 11482, epoch: 88, loss: 0.621291
global_step: 11483, epoch: 88, loss: 0.488093
global_step: 11484, epoch: 88, loss: 0.473414
global_step: 11485, epoch: 88, loss: 0.571965
global_step: 11486, epoch: 88, loss: 0.640583
global_step: 11487, epoch: 88, loss: 0.622254
global_step: 11488, epoch: 88, loss: 0.638037
global_step: 11489, epoch: 88, loss: 0.589529
global_step: 11490, epoch: 88, loss: 0.549744
global_step: 11491, epoch: 88, loss: 0.656353
global_step: 11492, epoch: 88, loss: 0.498794
global_step: 11493, epoch: 88, loss: 0.651564
global_step: 11494, epoch: 88, loss: 0.630592
global_step: 11495, epoch: 88, loss: 0.617220
global_step: 11496, epoch: 88, loss: 0.579994
global_step: 11497, epoch: 88, loss: 0.579210
global_step: 11498, epoch: 88, loss: 0.533470
global_step: 11499, epoch: 88, loss: 0.614492
global_step: 11500, epoch: 88, loss: 0.570559
global_step: 11501, epoch: 88, loss: 0.612688
global_step: 11502, epoch: 88, loss: 0.594694
global_step: 11503, epoch: 88, loss: 0.637141
global_step: 11504, epoch: 88, loss: 0.574044
global_step: 11505, epoch: 88, loss: 0.545130
global_step: 11506, epoch: 88, loss: 0.590789
global_step: 11507, epoch: 88, loss: 0.613347
global_step: 11508, epoch: 88, loss: 0.535871
global_step: 11509, epoch: 88, loss: 0.703799
global_step: 11510, epoch: 88, loss: 0.645522
global_step: 11511, epoch: 88, loss: 0.588332
global_step: 11512, epoch: 88, loss: 0.618814
global_step: 11513, epoch: 88, loss: 0.605997
global_step: 11514, epoch: 88, loss: 0.649112
global_step: 11515, epoch: 88, loss: 0.618914
global_step: 11516, epoch: 88, loss: 0.676140
global_step: 11517, epoch: 88, loss: 0.678150
global_step: 11518, epoch: 88, loss: 0.613347
global_step: 11519, epoch: 88, loss: 0.558915
global_step: 11520, epoch: 88, loss: 0.489754
epoch: 88
train	acc: 0.8641	macro: p 0.8600, r 0.6446, f1: 0.6460	micro: p 0.8641, r 0.8641, f1 0.8641	weighted_f1:0.8484
dev	acc: 0.5473	macro: p 0.3727, r 0.3505, f1: 0.3466	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5264
test	acc: 0.5816	macro: p 0.4180, r 0.3578, f1: 0.3523	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5671
global_step: 11521, epoch: 89, loss: 0.572798
global_step: 11522, epoch: 89, loss: 0.578292
global_step: 11523, epoch: 89, loss: 0.677811
global_step: 11524, epoch: 89, loss: 0.552104
global_step: 11525, epoch: 89, loss: 0.545823
global_step: 11526, epoch: 89, loss: 0.608163
global_step: 11527, epoch: 89, loss: 0.663083
global_step: 11528, epoch: 89, loss: 0.536486
global_step: 11529, epoch: 89, loss: 0.671552
global_step: 11530, epoch: 89, loss: 0.575432
global_step: 11531, epoch: 89, loss: 0.501256
global_step: 11532, epoch: 89, loss: 0.753343
global_step: 11533, epoch: 89, loss: 0.608117
global_step: 11534, epoch: 89, loss: 0.570988
global_step: 11535, epoch: 89, loss: 0.581374
global_step: 11536, epoch: 89, loss: 0.648727
global_step: 11537, epoch: 89, loss: 0.573273
global_step: 11538, epoch: 89, loss: 0.518111
global_step: 11539, epoch: 89, loss: 0.591389
global_step: 11540, epoch: 89, loss: 0.642013
global_step: 11541, epoch: 89, loss: 0.558033
global_step: 11542, epoch: 89, loss: 0.615156
global_step: 11543, epoch: 89, loss: 0.510101
global_step: 11544, epoch: 89, loss: 0.557185
global_step: 11545, epoch: 89, loss: 0.675228
global_step: 11546, epoch: 89, loss: 0.559853
global_step: 11547, epoch: 89, loss: 0.519415
global_step: 11548, epoch: 89, loss: 0.513440
global_step: 11549, epoch: 89, loss: 0.640013
global_step: 11550, epoch: 89, loss: 0.733225
global_step: 11551, epoch: 89, loss: 0.648812
global_step: 11552, epoch: 89, loss: 0.535398
global_step: 11553, epoch: 89, loss: 0.540890
global_step: 11554, epoch: 89, loss: 0.613444
global_step: 11555, epoch: 89, loss: 0.614457
global_step: 11556, epoch: 89, loss: 0.624539
global_step: 11557, epoch: 89, loss: 0.587541
global_step: 11558, epoch: 89, loss: 0.692226
global_step: 11559, epoch: 89, loss: 0.695088
global_step: 11560, epoch: 89, loss: 0.378241
epoch: 89
train	acc: 0.8543	macro: p 0.7242, r 0.6260, f1: 0.6355	micro: p 0.8543, r 0.8543, f1 0.8543	weighted_f1:0.8359
dev	acc: 0.5717	macro: p 0.5067, r 0.3402, f1: 0.3491	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5285
test	acc: 0.6069	macro: p 0.4629, r 0.3357, f1: 0.3472	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5703
global_step: 11561, epoch: 90, loss: 0.528069
global_step: 11562, epoch: 90, loss: 0.642008
global_step: 11563, epoch: 90, loss: 0.540302
global_step: 11564, epoch: 90, loss: 0.675208
global_step: 11565, epoch: 90, loss: 0.557833
global_step: 11566, epoch: 90, loss: 0.581289
global_step: 11567, epoch: 90, loss: 0.584120
global_step: 11568, epoch: 90, loss: 0.636099
global_step: 11569, epoch: 90, loss: 0.672527
global_step: 11570, epoch: 90, loss: 0.578339
global_step: 11571, epoch: 90, loss: 0.545897
global_step: 11572, epoch: 90, loss: 0.592591
global_step: 11573, epoch: 90, loss: 0.559073
global_step: 11574, epoch: 90, loss: 0.652426
global_step: 11575, epoch: 90, loss: 0.601210
global_step: 11576, epoch: 90, loss: 0.613601
global_step: 11577, epoch: 90, loss: 0.589823
global_step: 11578, epoch: 90, loss: 0.555468
global_step: 11579, epoch: 90, loss: 0.653685
global_step: 11580, epoch: 90, loss: 0.547904
global_step: 11581, epoch: 90, loss: 0.593104
global_step: 11582, epoch: 90, loss: 0.568026
global_step: 11583, epoch: 90, loss: 0.577022
global_step: 11584, epoch: 90, loss: 0.619910
global_step: 11585, epoch: 90, loss: 0.508639
global_step: 11586, epoch: 90, loss: 0.570893
global_step: 11587, epoch: 90, loss: 0.610302
global_step: 11588, epoch: 90, loss: 0.636907
global_step: 11589, epoch: 90, loss: 0.599619
global_step: 11590, epoch: 90, loss: 0.723600
global_step: 11591, epoch: 90, loss: 0.553019
global_step: 11592, epoch: 90, loss: 0.693584
global_step: 11593, epoch: 90, loss: 0.638424
global_step: 11594, epoch: 90, loss: 0.565550
global_step: 11595, epoch: 90, loss: 0.508406
global_step: 11596, epoch: 90, loss: 0.584467
global_step: 11597, epoch: 90, loss: 0.539277
global_step: 11598, epoch: 90, loss: 0.504411
global_step: 11599, epoch: 90, loss: 0.492611
global_step: 11600, epoch: 90, loss: 0.743152
epoch: 90
train	acc: 0.8588	macro: p 0.7248, r 0.6246, f1: 0.6330	micro: p 0.8588, r 0.8588, f1 0.8588	weighted_f1:0.8391
dev	acc: 0.5663	macro: p 0.3956, r 0.3442, f1: 0.3439	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5258
test	acc: 0.6015	macro: p 0.4599, r 0.3442, f1: 0.3448	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5678
global_step: 11601, epoch: 91, loss: 0.511108
global_step: 11602, epoch: 91, loss: 0.614398
global_step: 11603, epoch: 91, loss: 0.565051
global_step: 11604, epoch: 91, loss: 0.605287
global_step: 11605, epoch: 91, loss: 0.681399
global_step: 11606, epoch: 91, loss: 0.547714
global_step: 11607, epoch: 91, loss: 0.624058
global_step: 11608, epoch: 91, loss: 0.680729
global_step: 11609, epoch: 91, loss: 0.586429
global_step: 11610, epoch: 91, loss: 0.635402
global_step: 11611, epoch: 91, loss: 0.559080
global_step: 11612, epoch: 91, loss: 0.587579
global_step: 11613, epoch: 91, loss: 0.564954
global_step: 11614, epoch: 91, loss: 0.525280
global_step: 11615, epoch: 91, loss: 0.558881
global_step: 11616, epoch: 91, loss: 0.577533
global_step: 11617, epoch: 91, loss: 0.532712
global_step: 11618, epoch: 91, loss: 0.553462
global_step: 11619, epoch: 91, loss: 0.708352
global_step: 11620, epoch: 91, loss: 0.580775
global_step: 11621, epoch: 91, loss: 0.678497
global_step: 11622, epoch: 91, loss: 0.595677
global_step: 11623, epoch: 91, loss: 0.534380
global_step: 11624, epoch: 91, loss: 0.526244
global_step: 11625, epoch: 91, loss: 0.634419
global_step: 11626, epoch: 91, loss: 0.650806
global_step: 11627, epoch: 91, loss: 0.642473
global_step: 11628, epoch: 91, loss: 0.522739
global_step: 11629, epoch: 91, loss: 0.541278
global_step: 11630, epoch: 91, loss: 0.570303
global_step: 11631, epoch: 91, loss: 0.586374
global_step: 11632, epoch: 91, loss: 0.579837
global_step: 11633, epoch: 91, loss: 0.508200
global_step: 11634, epoch: 91, loss: 0.619392
global_step: 11635, epoch: 91, loss: 0.665982
global_step: 11636, epoch: 91, loss: 0.614435
global_step: 11637, epoch: 91, loss: 0.616030
global_step: 11638, epoch: 91, loss: 0.582584
global_step: 11639, epoch: 91, loss: 0.588948
global_step: 11640, epoch: 91, loss: 1.234601
epoch: 91
train	acc: 0.8705	macro: p 0.7250, r 0.6595, f1: 0.6636	micro: p 0.8705, r 0.8705, f1 0.8705	weighted_f1:0.8549
dev	acc: 0.5717	macro: p 0.3846, r 0.3526, f1: 0.3557	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5375
test	acc: 0.6038	macro: p 0.4352, r 0.3530, f1: 0.3613	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5778
global_step: 11641, epoch: 92, loss: 0.597670
global_step: 11642, epoch: 92, loss: 0.536310
global_step: 11643, epoch: 92, loss: 0.575400
global_step: 11644, epoch: 92, loss: 0.603004
global_step: 11645, epoch: 92, loss: 0.605386
global_step: 11646, epoch: 92, loss: 0.591685
global_step: 11647, epoch: 92, loss: 0.573403
global_step: 11648, epoch: 92, loss: 0.640643
global_step: 11649, epoch: 92, loss: 0.537012
global_step: 11650, epoch: 92, loss: 0.575878
global_step: 11651, epoch: 92, loss: 0.511800
global_step: 11652, epoch: 92, loss: 0.596240
global_step: 11653, epoch: 92, loss: 0.598836
global_step: 11654, epoch: 92, loss: 0.628614
global_step: 11655, epoch: 92, loss: 0.572585
global_step: 11656, epoch: 92, loss: 0.606291
global_step: 11657, epoch: 92, loss: 0.617840
global_step: 11658, epoch: 92, loss: 0.597584
global_step: 11659, epoch: 92, loss: 0.518588
global_step: 11660, epoch: 92, loss: 0.547384
global_step: 11661, epoch: 92, loss: 0.581951
global_step: 11662, epoch: 92, loss: 0.671535
global_step: 11663, epoch: 92, loss: 0.659236
global_step: 11664, epoch: 92, loss: 0.589964
global_step: 11665, epoch: 92, loss: 0.550602
global_step: 11666, epoch: 92, loss: 0.479058
global_step: 11667, epoch: 92, loss: 0.565319
global_step: 11668, epoch: 92, loss: 0.577162
global_step: 11669, epoch: 92, loss: 0.602229
global_step: 11670, epoch: 92, loss: 0.617751
global_step: 11671, epoch: 92, loss: 0.519614
global_step: 11672, epoch: 92, loss: 0.491973
global_step: 11673, epoch: 92, loss: 0.645345
global_step: 11674, epoch: 92, loss: 0.609288
global_step: 11675, epoch: 92, loss: 0.576744
global_step: 11676, epoch: 92, loss: 0.635456
global_step: 11677, epoch: 92, loss: 0.570936
global_step: 11678, epoch: 92, loss: 0.538189
global_step: 11679, epoch: 92, loss: 0.506397
global_step: 11680, epoch: 92, loss: 0.525347
epoch: 92
train	acc: 0.8652	macro: p 0.8716, r 0.6416, f1: 0.6537	micro: p 0.8652, r 0.8652, f1 0.8652	weighted_f1:0.8475
dev	acc: 0.5807	macro: p 0.4191, r 0.3538, f1: 0.3580	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5407
test	acc: 0.6077	macro: p 0.4584, r 0.3465, f1: 0.3552	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5739
global_step: 11681, epoch: 93, loss: 0.535966
global_step: 11682, epoch: 93, loss: 0.483275
global_step: 11683, epoch: 93, loss: 0.554778
global_step: 11684, epoch: 93, loss: 0.551802
global_step: 11685, epoch: 93, loss: 0.654159
global_step: 11686, epoch: 93, loss: 0.597551
global_step: 11687, epoch: 93, loss: 0.599725
global_step: 11688, epoch: 93, loss: 0.512522
global_step: 11689, epoch: 93, loss: 0.428833
global_step: 11690, epoch: 93, loss: 0.537135
global_step: 11691, epoch: 93, loss: 0.551917
global_step: 11692, epoch: 93, loss: 0.504419
global_step: 11693, epoch: 93, loss: 0.537318
global_step: 11694, epoch: 93, loss: 0.602790
global_step: 11695, epoch: 93, loss: 0.528110
global_step: 11696, epoch: 93, loss: 0.605218
global_step: 11697, epoch: 93, loss: 0.474335
global_step: 11698, epoch: 93, loss: 0.535648
global_step: 11699, epoch: 93, loss: 0.579382
global_step: 11700, epoch: 93, loss: 0.696013
global_step: 11701, epoch: 93, loss: 0.542878
global_step: 11702, epoch: 93, loss: 0.504876
global_step: 11703, epoch: 93, loss: 0.666394
global_step: 11704, epoch: 93, loss: 0.655966
global_step: 11705, epoch: 93, loss: 0.556091
global_step: 11706, epoch: 93, loss: 0.552871
global_step: 11707, epoch: 93, loss: 0.560977
global_step: 11708, epoch: 93, loss: 0.561436
global_step: 11709, epoch: 93, loss: 0.572334
global_step: 11710, epoch: 93, loss: 0.466190
global_step: 11711, epoch: 93, loss: 0.631651
global_step: 11712, epoch: 93, loss: 0.594766
global_step: 11713, epoch: 93, loss: 0.631518
global_step: 11714, epoch: 93, loss: 0.641870
global_step: 11715, epoch: 93, loss: 0.573878
global_step: 11716, epoch: 93, loss: 0.564037
global_step: 11717, epoch: 93, loss: 0.542422
global_step: 11718, epoch: 93, loss: 0.500829
global_step: 11719, epoch: 93, loss: 0.613076
global_step: 11720, epoch: 93, loss: 1.740674
epoch: 93
train	acc: 0.8789	macro: p 0.8656, r 0.6853, f1: 0.6886	micro: p 0.8789, r 0.8789, f1 0.8789	weighted_f1:0.8653
dev	acc: 0.5573	macro: p 0.3813, r 0.3632, f1: 0.3606	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5315
test	acc: 0.5881	macro: p 0.4012, r 0.3691, f1: 0.3637	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5719
global_step: 11721, epoch: 94, loss: 0.575341
global_step: 11722, epoch: 94, loss: 0.540867
global_step: 11723, epoch: 94, loss: 0.574290
global_step: 11724, epoch: 94, loss: 0.525825
global_step: 11725, epoch: 94, loss: 0.518530
global_step: 11726, epoch: 94, loss: 0.553971
global_step: 11727, epoch: 94, loss: 0.681466
global_step: 11728, epoch: 94, loss: 0.602952
global_step: 11729, epoch: 94, loss: 0.606343
global_step: 11730, epoch: 94, loss: 0.477032
global_step: 11731, epoch: 94, loss: 0.601335
global_step: 11732, epoch: 94, loss: 0.536113
global_step: 11733, epoch: 94, loss: 0.574258
global_step: 11734, epoch: 94, loss: 0.598102
global_step: 11735, epoch: 94, loss: 0.573213
global_step: 11736, epoch: 94, loss: 0.581437
global_step: 11737, epoch: 94, loss: 0.461375
global_step: 11738, epoch: 94, loss: 0.602570
global_step: 11739, epoch: 94, loss: 0.626050
global_step: 11740, epoch: 94, loss: 0.551188
global_step: 11741, epoch: 94, loss: 0.577086
global_step: 11742, epoch: 94, loss: 0.474513
global_step: 11743, epoch: 94, loss: 0.563213
global_step: 11744, epoch: 94, loss: 0.505483
global_step: 11745, epoch: 94, loss: 0.619430
global_step: 11746, epoch: 94, loss: 0.644483
global_step: 11747, epoch: 94, loss: 0.559684
global_step: 11748, epoch: 94, loss: 0.591128
global_step: 11749, epoch: 94, loss: 0.605238
global_step: 11750, epoch: 94, loss: 0.584908
global_step: 11751, epoch: 94, loss: 0.535415
global_step: 11752, epoch: 94, loss: 0.623043
global_step: 11753, epoch: 94, loss: 0.685617
global_step: 11754, epoch: 94, loss: 0.584305
global_step: 11755, epoch: 94, loss: 0.616552
global_step: 11756, epoch: 94, loss: 0.526534
global_step: 11757, epoch: 94, loss: 0.571374
global_step: 11758, epoch: 94, loss: 0.587424
global_step: 11759, epoch: 94, loss: 0.575828
global_step: 11760, epoch: 94, loss: 0.637955
epoch: 94
train	acc: 0.8450	macro: p 0.8732, r 0.6146, f1: 0.6448	micro: p 0.8450, r 0.8450, f1 0.8450	weighted_f1:0.8259
dev	acc: 0.5564	macro: p 0.4277, r 0.3249, f1: 0.3350	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5034
test	acc: 0.6069	macro: p 0.4556, r 0.3246, f1: 0.3370	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5584
global_step: 11761, epoch: 95, loss: 0.669960
global_step: 11762, epoch: 95, loss: 0.567647
global_step: 11763, epoch: 95, loss: 0.599546
global_step: 11764, epoch: 95, loss: 0.566393
global_step: 11765, epoch: 95, loss: 0.574718
global_step: 11766, epoch: 95, loss: 0.521563
global_step: 11767, epoch: 95, loss: 0.610656
global_step: 11768, epoch: 95, loss: 0.576415
global_step: 11769, epoch: 95, loss: 0.602565
global_step: 11770, epoch: 95, loss: 0.581478
global_step: 11771, epoch: 95, loss: 0.535210
global_step: 11772, epoch: 95, loss: 0.652006
global_step: 11773, epoch: 95, loss: 0.548479
global_step: 11774, epoch: 95, loss: 0.546266
global_step: 11775, epoch: 95, loss: 0.490025
global_step: 11776, epoch: 95, loss: 0.575385
global_step: 11777, epoch: 95, loss: 0.544595
global_step: 11778, epoch: 95, loss: 0.532227
global_step: 11779, epoch: 95, loss: 0.625091
global_step: 11780, epoch: 95, loss: 0.501861
global_step: 11781, epoch: 95, loss: 0.557763
global_step: 11782, epoch: 95, loss: 0.523842
global_step: 11783, epoch: 95, loss: 0.536642
global_step: 11784, epoch: 95, loss: 0.537642
global_step: 11785, epoch: 95, loss: 0.581714
global_step: 11786, epoch: 95, loss: 0.624290
global_step: 11787, epoch: 95, loss: 0.450645
global_step: 11788, epoch: 95, loss: 0.572464
global_step: 11789, epoch: 95, loss: 0.549825
global_step: 11790, epoch: 95, loss: 0.549840
global_step: 11791, epoch: 95, loss: 0.565764
global_step: 11792, epoch: 95, loss: 0.598098
global_step: 11793, epoch: 95, loss: 0.556908
global_step: 11794, epoch: 95, loss: 0.542751
global_step: 11795, epoch: 95, loss: 0.507654
global_step: 11796, epoch: 95, loss: 0.591945
global_step: 11797, epoch: 95, loss: 0.581920
global_step: 11798, epoch: 95, loss: 0.606205
global_step: 11799, epoch: 95, loss: 0.555257
global_step: 11800, epoch: 95, loss: 1.088758
epoch: 95
train	acc: 0.8730	macro: p 0.8759, r 0.6705, f1: 0.6848	micro: p 0.8730, r 0.8730, f1 0.8730	weighted_f1:0.8583
dev	acc: 0.5690	macro: p 0.4187, r 0.3557, f1: 0.3602	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5312
test	acc: 0.6004	macro: p 0.4243, r 0.3505, f1: 0.3507	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5701
global_step: 11801, epoch: 96, loss: 0.631159
global_step: 11802, epoch: 96, loss: 0.564125
global_step: 11803, epoch: 96, loss: 0.694115
global_step: 11804, epoch: 96, loss: 0.529594
global_step: 11805, epoch: 96, loss: 0.505966
global_step: 11806, epoch: 96, loss: 0.534877
global_step: 11807, epoch: 96, loss: 0.583908
global_step: 11808, epoch: 96, loss: 0.516405
global_step: 11809, epoch: 96, loss: 0.602776
global_step: 11810, epoch: 96, loss: 0.620558
global_step: 11811, epoch: 96, loss: 0.563864
global_step: 11812, epoch: 96, loss: 0.561938
global_step: 11813, epoch: 96, loss: 0.517919
global_step: 11814, epoch: 96, loss: 0.585746
global_step: 11815, epoch: 96, loss: 0.515140
global_step: 11816, epoch: 96, loss: 0.572060
global_step: 11817, epoch: 96, loss: 0.579273
global_step: 11818, epoch: 96, loss: 0.607110
global_step: 11819, epoch: 96, loss: 0.558241
global_step: 11820, epoch: 96, loss: 0.607120
global_step: 11821, epoch: 96, loss: 0.486777
global_step: 11822, epoch: 96, loss: 0.589371
global_step: 11823, epoch: 96, loss: 0.653856
global_step: 11824, epoch: 96, loss: 0.635683
global_step: 11825, epoch: 96, loss: 0.535796
global_step: 11826, epoch: 96, loss: 0.587408
global_step: 11827, epoch: 96, loss: 0.529555
global_step: 11828, epoch: 96, loss: 0.536683
global_step: 11829, epoch: 96, loss: 0.526305
global_step: 11830, epoch: 96, loss: 0.493212
global_step: 11831, epoch: 96, loss: 0.537066
global_step: 11832, epoch: 96, loss: 0.566980
global_step: 11833, epoch: 96, loss: 0.571206
global_step: 11834, epoch: 96, loss: 0.495850
global_step: 11835, epoch: 96, loss: 0.578897
global_step: 11836, epoch: 96, loss: 0.483903
global_step: 11837, epoch: 96, loss: 0.571236
global_step: 11838, epoch: 96, loss: 0.566633
global_step: 11839, epoch: 96, loss: 0.565612
global_step: 11840, epoch: 96, loss: 0.896463
epoch: 96
train	acc: 0.8818	macro: p 0.8772, r 0.6811, f1: 0.6913	micro: p 0.8818, r 0.8818, f1 0.8818	weighted_f1:0.8677
dev	acc: 0.5591	macro: p 0.3900, r 0.3513, f1: 0.3533	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5281
test	acc: 0.5939	macro: p 0.4074, r 0.3556, f1: 0.3561	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5712
global_step: 11841, epoch: 97, loss: 0.494967
global_step: 11842, epoch: 97, loss: 0.561923
global_step: 11843, epoch: 97, loss: 0.562710
global_step: 11844, epoch: 97, loss: 0.514091
global_step: 11845, epoch: 97, loss: 0.600650
global_step: 11846, epoch: 97, loss: 0.536323
global_step: 11847, epoch: 97, loss: 0.504496
global_step: 11848, epoch: 97, loss: 0.599477
global_step: 11849, epoch: 97, loss: 0.621263
global_step: 11850, epoch: 97, loss: 0.548388
global_step: 11851, epoch: 97, loss: 0.562735
global_step: 11852, epoch: 97, loss: 0.649489
global_step: 11853, epoch: 97, loss: 0.463903
global_step: 11854, epoch: 97, loss: 0.571114
global_step: 11855, epoch: 97, loss: 0.567155
global_step: 11856, epoch: 97, loss: 0.539104
global_step: 11857, epoch: 97, loss: 0.561655
global_step: 11858, epoch: 97, loss: 0.501592
global_step: 11859, epoch: 97, loss: 0.566295
global_step: 11860, epoch: 97, loss: 0.519323
global_step: 11861, epoch: 97, loss: 0.576737
global_step: 11862, epoch: 97, loss: 0.535763
global_step: 11863, epoch: 97, loss: 0.545969
global_step: 11864, epoch: 97, loss: 0.551806
global_step: 11865, epoch: 97, loss: 0.515097
global_step: 11866, epoch: 97, loss: 0.528162
global_step: 11867, epoch: 97, loss: 0.577779
global_step: 11868, epoch: 97, loss: 0.600319
global_step: 11869, epoch: 97, loss: 0.525748
global_step: 11870, epoch: 97, loss: 0.481529
global_step: 11871, epoch: 97, loss: 0.485967
global_step: 11872, epoch: 97, loss: 0.530529
global_step: 11873, epoch: 97, loss: 0.629632
global_step: 11874, epoch: 97, loss: 0.635632
global_step: 11875, epoch: 97, loss: 0.510363
global_step: 11876, epoch: 97, loss: 0.535379
global_step: 11877, epoch: 97, loss: 0.627228
global_step: 11878, epoch: 97, loss: 0.557327
global_step: 11879, epoch: 97, loss: 0.517986
global_step: 11880, epoch: 97, loss: 0.123176
epoch: 97
train	acc: 0.8526	macro: p 0.8782, r 0.6229, f1: 0.6498	micro: p 0.8526, r 0.8526, f1 0.8526	weighted_f1:0.8341
dev	acc: 0.5672	macro: p 0.4405, r 0.3373, f1: 0.3491	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5182
test	acc: 0.6130	macro: p 0.4622, r 0.3299, f1: 0.3437	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5666
global_step: 11881, epoch: 98, loss: 0.566437
global_step: 11882, epoch: 98, loss: 0.510014
global_step: 11883, epoch: 98, loss: 0.577079
global_step: 11884, epoch: 98, loss: 0.558882
global_step: 11885, epoch: 98, loss: 0.511642
global_step: 11886, epoch: 98, loss: 0.662968
global_step: 11887, epoch: 98, loss: 0.434906
global_step: 11888, epoch: 98, loss: 0.515790
global_step: 11889, epoch: 98, loss: 0.679774
global_step: 11890, epoch: 98, loss: 0.447247
global_step: 11891, epoch: 98, loss: 0.524560
global_step: 11892, epoch: 98, loss: 0.483338
global_step: 11893, epoch: 98, loss: 0.508433
global_step: 11894, epoch: 98, loss: 0.538501
global_step: 11895, epoch: 98, loss: 0.564197
global_step: 11896, epoch: 98, loss: 0.588689
global_step: 11897, epoch: 98, loss: 0.498389
global_step: 11898, epoch: 98, loss: 0.534150
global_step: 11899, epoch: 98, loss: 0.477850
global_step: 11900, epoch: 98, loss: 0.551142
global_step: 11901, epoch: 98, loss: 0.570156
global_step: 11902, epoch: 98, loss: 0.638443
global_step: 11903, epoch: 98, loss: 0.623781
global_step: 11904, epoch: 98, loss: 0.525040
global_step: 11905, epoch: 98, loss: 0.517747
global_step: 11906, epoch: 98, loss: 0.556373
global_step: 11907, epoch: 98, loss: 0.558208
global_step: 11908, epoch: 98, loss: 0.618146
global_step: 11909, epoch: 98, loss: 0.555234
global_step: 11910, epoch: 98, loss: 0.586405
global_step: 11911, epoch: 98, loss: 0.619039
global_step: 11912, epoch: 98, loss: 0.541885
global_step: 11913, epoch: 98, loss: 0.579727
global_step: 11914, epoch: 98, loss: 0.559880
global_step: 11915, epoch: 98, loss: 0.540672
global_step: 11916, epoch: 98, loss: 0.545472
global_step: 11917, epoch: 98, loss: 0.627768
global_step: 11918, epoch: 98, loss: 0.552534
global_step: 11919, epoch: 98, loss: 0.588319
global_step: 11920, epoch: 98, loss: 0.289529
epoch: 98
train	acc: 0.8855	macro: p 0.8842, r 0.6960, f1: 0.7067	micro: p 0.8855, r 0.8855, f1 0.8855	weighted_f1:0.8719
dev	acc: 0.5717	macro: p 0.4131, r 0.3605, f1: 0.3688	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5369
test	acc: 0.6050	macro: p 0.4185, r 0.3552, f1: 0.3644	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5785
global_step: 11921, epoch: 99, loss: 0.562727
global_step: 11922, epoch: 99, loss: 0.538146
global_step: 11923, epoch: 99, loss: 0.499462
global_step: 11924, epoch: 99, loss: 0.516061
global_step: 11925, epoch: 99, loss: 0.490740
global_step: 11926, epoch: 99, loss: 0.552702
global_step: 11927, epoch: 99, loss: 0.465358
global_step: 11928, epoch: 99, loss: 0.557182
global_step: 11929, epoch: 99, loss: 0.465262
global_step: 11930, epoch: 99, loss: 0.566138
global_step: 11931, epoch: 99, loss: 0.681290
global_step: 11932, epoch: 99, loss: 0.563419
global_step: 11933, epoch: 99, loss: 0.536551
global_step: 11934, epoch: 99, loss: 0.527155
global_step: 11935, epoch: 99, loss: 0.512321
global_step: 11936, epoch: 99, loss: 0.635807
global_step: 11937, epoch: 99, loss: 0.516561
global_step: 11938, epoch: 99, loss: 0.549236
global_step: 11939, epoch: 99, loss: 0.540641
global_step: 11940, epoch: 99, loss: 0.506666
global_step: 11941, epoch: 99, loss: 0.509101
global_step: 11942, epoch: 99, loss: 0.475897
global_step: 11943, epoch: 99, loss: 0.609041
global_step: 11944, epoch: 99, loss: 0.522768
global_step: 11945, epoch: 99, loss: 0.569380
global_step: 11946, epoch: 99, loss: 0.548169
global_step: 11947, epoch: 99, loss: 0.584352
global_step: 11948, epoch: 99, loss: 0.488114
global_step: 11949, epoch: 99, loss: 0.486722
global_step: 11950, epoch: 99, loss: 0.534725
global_step: 11951, epoch: 99, loss: 0.556959
global_step: 11952, epoch: 99, loss: 0.508642
global_step: 11953, epoch: 99, loss: 0.617902
global_step: 11954, epoch: 99, loss: 0.597808
global_step: 11955, epoch: 99, loss: 0.562666
global_step: 11956, epoch: 99, loss: 0.535339
global_step: 11957, epoch: 99, loss: 0.553685
global_step: 11958, epoch: 99, loss: 0.585654
global_step: 11959, epoch: 99, loss: 0.523332
global_step: 11960, epoch: 99, loss: 1.125586
epoch: 99
train	acc: 0.8872	macro: p 0.8893, r 0.6990, f1: 0.7162	micro: p 0.8872, r 0.8872, f1 0.8872	weighted_f1:0.8745
dev	acc: 0.5663	macro: p 0.5538, r 0.3540, f1: 0.3648	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5305
test	acc: 0.5962	macro: p 0.4009, r 0.3450, f1: 0.3484	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5669
global_step: 11961, epoch: 100, loss: 0.557224
global_step: 11962, epoch: 100, loss: 0.555557
global_step: 11963, epoch: 100, loss: 0.460400
global_step: 11964, epoch: 100, loss: 0.509201
global_step: 11965, epoch: 100, loss: 0.522855
global_step: 11966, epoch: 100, loss: 0.527565
global_step: 11967, epoch: 100, loss: 0.462918
global_step: 11968, epoch: 100, loss: 0.581408
global_step: 11969, epoch: 100, loss: 0.520775
global_step: 11970, epoch: 100, loss: 0.551439
global_step: 11971, epoch: 100, loss: 0.549255
global_step: 11972, epoch: 100, loss: 0.456473
global_step: 11973, epoch: 100, loss: 0.442713
global_step: 11974, epoch: 100, loss: 0.584481
global_step: 11975, epoch: 100, loss: 0.536909
global_step: 11976, epoch: 100, loss: 0.639765
global_step: 11977, epoch: 100, loss: 0.506590
global_step: 11978, epoch: 100, loss: 0.606150
global_step: 11979, epoch: 100, loss: 0.478441
global_step: 11980, epoch: 100, loss: 0.580774
global_step: 11981, epoch: 100, loss: 0.541578
global_step: 11982, epoch: 100, loss: 0.503666
global_step: 11983, epoch: 100, loss: 0.501906
global_step: 11984, epoch: 100, loss: 0.581039
global_step: 11985, epoch: 100, loss: 0.513853
global_step: 11986, epoch: 100, loss: 0.583167
global_step: 11987, epoch: 100, loss: 0.557838
global_step: 11988, epoch: 100, loss: 0.557914
global_step: 11989, epoch: 100, loss: 0.479134
global_step: 11990, epoch: 100, loss: 0.552063
global_step: 11991, epoch: 100, loss: 0.562407
global_step: 11992, epoch: 100, loss: 0.513165
global_step: 11993, epoch: 100, loss: 0.482476
global_step: 11994, epoch: 100, loss: 0.509266
global_step: 11995, epoch: 100, loss: 0.581292
global_step: 11996, epoch: 100, loss: 0.513790
global_step: 11997, epoch: 100, loss: 0.471748
global_step: 11998, epoch: 100, loss: 0.590937
global_step: 11999, epoch: 100, loss: 0.561723
global_step: 12000, epoch: 100, loss: 0.054647
epoch: 100
train	acc: 0.8910	macro: p 0.8862, r 0.7046, f1: 0.7155	micro: p 0.8910, r 0.8910, f1 0.8910	weighted_f1:0.8778
dev	acc: 0.5699	macro: p 0.3966, r 0.3571, f1: 0.3613	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5357
test	acc: 0.6023	macro: p 0.4133, r 0.3518, f1: 0.3589	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5744
global_step: 12001, epoch: 101, loss: 0.521035
global_step: 12002, epoch: 101, loss: 0.470753
global_step: 12003, epoch: 101, loss: 0.498160
global_step: 12004, epoch: 101, loss: 0.492709
global_step: 12005, epoch: 101, loss: 0.498244
global_step: 12006, epoch: 101, loss: 0.528193
global_step: 12007, epoch: 101, loss: 0.472881
global_step: 12008, epoch: 101, loss: 0.501192
global_step: 12009, epoch: 101, loss: 0.493085
global_step: 12010, epoch: 101, loss: 0.555774
global_step: 12011, epoch: 101, loss: 0.602036
global_step: 12012, epoch: 101, loss: 0.547254
global_step: 12013, epoch: 101, loss: 0.492325
global_step: 12014, epoch: 101, loss: 0.581128
global_step: 12015, epoch: 101, loss: 0.497300
global_step: 12016, epoch: 101, loss: 0.565139
global_step: 12017, epoch: 101, loss: 0.547242
global_step: 12018, epoch: 101, loss: 0.512050
global_step: 12019, epoch: 101, loss: 0.558013
global_step: 12020, epoch: 101, loss: 0.467686
global_step: 12021, epoch: 101, loss: 0.527294
global_step: 12022, epoch: 101, loss: 0.547739
global_step: 12023, epoch: 101, loss: 0.475122
global_step: 12024, epoch: 101, loss: 0.553119
global_step: 12025, epoch: 101, loss: 0.520239
global_step: 12026, epoch: 101, loss: 0.577193
global_step: 12027, epoch: 101, loss: 0.532180
global_step: 12028, epoch: 101, loss: 0.490331
global_step: 12029, epoch: 101, loss: 0.532588
global_step: 12030, epoch: 101, loss: 0.578835
global_step: 12031, epoch: 101, loss: 0.599996
global_step: 12032, epoch: 101, loss: 0.443936
global_step: 12033, epoch: 101, loss: 0.483899
global_step: 12034, epoch: 101, loss: 0.601828
global_step: 12035, epoch: 101, loss: 0.519123
global_step: 12036, epoch: 101, loss: 0.545986
global_step: 12037, epoch: 101, loss: 0.635431
global_step: 12038, epoch: 101, loss: 0.533464
global_step: 12039, epoch: 101, loss: 0.525320
global_step: 12040, epoch: 101, loss: 0.672006
epoch: 101
train	acc: 0.8853	macro: p 0.8653, r 0.6906, f1: 0.7030	micro: p 0.8853, r 0.8853, f1 0.8853	weighted_f1:0.8720
dev	acc: 0.5609	macro: p 0.3834, r 0.3570, f1: 0.3516	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5284
test	acc: 0.5874	macro: p 0.4247, r 0.3537, f1: 0.3496	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5651
global_step: 12041, epoch: 102, loss: 0.575222
global_step: 12042, epoch: 102, loss: 0.508739
global_step: 12043, epoch: 102, loss: 0.593380
global_step: 12044, epoch: 102, loss: 0.565781
global_step: 12045, epoch: 102, loss: 0.464023
global_step: 12046, epoch: 102, loss: 0.475083
global_step: 12047, epoch: 102, loss: 0.564959
global_step: 12048, epoch: 102, loss: 0.651139
global_step: 12049, epoch: 102, loss: 0.469518
global_step: 12050, epoch: 102, loss: 0.563636
global_step: 12051, epoch: 102, loss: 0.613680
global_step: 12052, epoch: 102, loss: 0.505156
global_step: 12053, epoch: 102, loss: 0.458443
global_step: 12054, epoch: 102, loss: 0.505349
global_step: 12055, epoch: 102, loss: 0.499675
global_step: 12056, epoch: 102, loss: 0.407850
global_step: 12057, epoch: 102, loss: 0.629269
global_step: 12058, epoch: 102, loss: 0.583870
global_step: 12059, epoch: 102, loss: 0.505874
global_step: 12060, epoch: 102, loss: 0.503143
global_step: 12061, epoch: 102, loss: 0.477647
global_step: 12062, epoch: 102, loss: 0.498077
global_step: 12063, epoch: 102, loss: 0.456305
global_step: 12064, epoch: 102, loss: 0.519256
global_step: 12065, epoch: 102, loss: 0.500821
global_step: 12066, epoch: 102, loss: 0.472793
global_step: 12067, epoch: 102, loss: 0.567449
global_step: 12068, epoch: 102, loss: 0.519834
global_step: 12069, epoch: 102, loss: 0.476700
global_step: 12070, epoch: 102, loss: 0.411594
global_step: 12071, epoch: 102, loss: 0.566494
global_step: 12072, epoch: 102, loss: 0.481290
global_step: 12073, epoch: 102, loss: 0.520361
global_step: 12074, epoch: 102, loss: 0.564852
global_step: 12075, epoch: 102, loss: 0.556705
global_step: 12076, epoch: 102, loss: 0.465004
global_step: 12077, epoch: 102, loss: 0.496343
global_step: 12078, epoch: 102, loss: 0.514347
global_step: 12079, epoch: 102, loss: 0.516408
global_step: 12080, epoch: 102, loss: 1.016956
epoch: 102
train	acc: 0.8906	macro: p 0.8884, r 0.7078, f1: 0.7248	micro: p 0.8906, r 0.8906, f1 0.8906	weighted_f1:0.8782
dev	acc: 0.5690	macro: p 0.4160, r 0.3568, f1: 0.3632	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5323
test	acc: 0.6008	macro: p 0.4090, r 0.3493, f1: 0.3566	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5720
global_step: 12081, epoch: 103, loss: 0.505488
global_step: 12082, epoch: 103, loss: 0.501001
global_step: 12083, epoch: 103, loss: 0.668286
global_step: 12084, epoch: 103, loss: 0.480845
global_step: 12085, epoch: 103, loss: 0.512313
global_step: 12086, epoch: 103, loss: 0.513017
global_step: 12087, epoch: 103, loss: 0.520059
global_step: 12088, epoch: 103, loss: 0.515981
global_step: 12089, epoch: 103, loss: 0.545974
global_step: 12090, epoch: 103, loss: 0.483468
global_step: 12091, epoch: 103, loss: 0.512526
global_step: 12092, epoch: 103, loss: 0.503281
global_step: 12093, epoch: 103, loss: 0.426026
global_step: 12094, epoch: 103, loss: 0.530072
global_step: 12095, epoch: 103, loss: 0.530830
global_step: 12096, epoch: 103, loss: 0.485892
global_step: 12097, epoch: 103, loss: 0.573108
global_step: 12098, epoch: 103, loss: 0.550705
global_step: 12099, epoch: 103, loss: 0.521517
global_step: 12100, epoch: 103, loss: 0.498321
global_step: 12101, epoch: 103, loss: 0.519991
global_step: 12102, epoch: 103, loss: 0.496005
global_step: 12103, epoch: 103, loss: 0.480098
global_step: 12104, epoch: 103, loss: 0.504364
global_step: 12105, epoch: 103, loss: 0.435396
global_step: 12106, epoch: 103, loss: 0.528555
global_step: 12107, epoch: 103, loss: 0.463771
global_step: 12108, epoch: 103, loss: 0.499266
global_step: 12109, epoch: 103, loss: 0.521397
global_step: 12110, epoch: 103, loss: 0.512705
global_step: 12111, epoch: 103, loss: 0.556902
global_step: 12112, epoch: 103, loss: 0.524624
global_step: 12113, epoch: 103, loss: 0.509195
global_step: 12114, epoch: 103, loss: 0.560442
global_step: 12115, epoch: 103, loss: 0.571135
global_step: 12116, epoch: 103, loss: 0.470762
global_step: 12117, epoch: 103, loss: 0.497035
global_step: 12118, epoch: 103, loss: 0.556314
global_step: 12119, epoch: 103, loss: 0.585155
global_step: 12120, epoch: 103, loss: 0.158041
epoch: 103
train	acc: 0.8823	macro: p 0.8903, r 0.6856, f1: 0.7061	micro: p 0.8823, r 0.8823, f1 0.8823	weighted_f1:0.8681
dev	acc: 0.5672	macro: p 0.4047, r 0.3436, f1: 0.3492	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5241
test	acc: 0.6038	macro: p 0.4148, r 0.3370, f1: 0.3463	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5672
global_step: 12121, epoch: 104, loss: 0.444055
global_step: 12122, epoch: 104, loss: 0.563258
global_step: 12123, epoch: 104, loss: 0.528033
global_step: 12124, epoch: 104, loss: 0.492677
global_step: 12125, epoch: 104, loss: 0.516558
global_step: 12126, epoch: 104, loss: 0.456548
global_step: 12127, epoch: 104, loss: 0.531268
global_step: 12128, epoch: 104, loss: 0.532517
global_step: 12129, epoch: 104, loss: 0.488333
global_step: 12130, epoch: 104, loss: 0.483057
global_step: 12131, epoch: 104, loss: 0.506582
global_step: 12132, epoch: 104, loss: 0.518791
global_step: 12133, epoch: 104, loss: 0.536548
global_step: 12134, epoch: 104, loss: 0.494242
global_step: 12135, epoch: 104, loss: 0.559623
global_step: 12136, epoch: 104, loss: 0.530875
global_step: 12137, epoch: 104, loss: 0.637801
global_step: 12138, epoch: 104, loss: 0.460766
global_step: 12139, epoch: 104, loss: 0.509025
global_step: 12140, epoch: 104, loss: 0.569184
global_step: 12141, epoch: 104, loss: 0.479887
global_step: 12142, epoch: 104, loss: 0.557950
global_step: 12143, epoch: 104, loss: 0.441783
global_step: 12144, epoch: 104, loss: 0.527759
global_step: 12145, epoch: 104, loss: 0.449565
global_step: 12146, epoch: 104, loss: 0.465416
global_step: 12147, epoch: 104, loss: 0.564888
global_step: 12148, epoch: 104, loss: 0.425766
global_step: 12149, epoch: 104, loss: 0.445928
global_step: 12150, epoch: 104, loss: 0.487072
global_step: 12151, epoch: 104, loss: 0.569155
global_step: 12152, epoch: 104, loss: 0.474531
global_step: 12153, epoch: 104, loss: 0.521816
global_step: 12154, epoch: 104, loss: 0.482728
global_step: 12155, epoch: 104, loss: 0.486616
global_step: 12156, epoch: 104, loss: 0.497223
global_step: 12157, epoch: 104, loss: 0.483724
global_step: 12158, epoch: 104, loss: 0.441175
global_step: 12159, epoch: 104, loss: 0.499408
global_step: 12160, epoch: 104, loss: 0.021442
epoch: 104
train	acc: 0.8852	macro: p 0.8966, r 0.6899, f1: 0.7146	micro: p 0.8852, r 0.8852, f1 0.8852	weighted_f1:0.8715
dev	acc: 0.5735	macro: p 0.4254, r 0.3510, f1: 0.3577	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5313
test	acc: 0.6065	macro: p 0.4459, r 0.3438, f1: 0.3520	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5696
global_step: 12161, epoch: 105, loss: 0.637698
global_step: 12162, epoch: 105, loss: 0.463481
global_step: 12163, epoch: 105, loss: 0.506794
global_step: 12164, epoch: 105, loss: 0.491210
global_step: 12165, epoch: 105, loss: 0.489668
global_step: 12166, epoch: 105, loss: 0.475817
global_step: 12167, epoch: 105, loss: 0.615211
global_step: 12168, epoch: 105, loss: 0.543746
global_step: 12169, epoch: 105, loss: 0.454128
global_step: 12170, epoch: 105, loss: 0.452892
global_step: 12171, epoch: 105, loss: 0.428628
global_step: 12172, epoch: 105, loss: 0.567948
global_step: 12173, epoch: 105, loss: 0.512194
global_step: 12174, epoch: 105, loss: 0.433479
global_step: 12175, epoch: 105, loss: 0.446580
global_step: 12176, epoch: 105, loss: 0.510281
global_step: 12177, epoch: 105, loss: 0.555833
global_step: 12178, epoch: 105, loss: 0.511535
global_step: 12179, epoch: 105, loss: 0.501749
global_step: 12180, epoch: 105, loss: 0.428894
global_step: 12181, epoch: 105, loss: 0.438230
global_step: 12182, epoch: 105, loss: 0.506930
global_step: 12183, epoch: 105, loss: 0.510566
global_step: 12184, epoch: 105, loss: 0.486490
global_step: 12185, epoch: 105, loss: 0.526951
global_step: 12186, epoch: 105, loss: 0.547492
global_step: 12187, epoch: 105, loss: 0.532971
global_step: 12188, epoch: 105, loss: 0.531215
global_step: 12189, epoch: 105, loss: 0.492741
global_step: 12190, epoch: 105, loss: 0.516645
global_step: 12191, epoch: 105, loss: 0.612565
global_step: 12192, epoch: 105, loss: 0.529431
global_step: 12193, epoch: 105, loss: 0.472746
global_step: 12194, epoch: 105, loss: 0.480772
global_step: 12195, epoch: 105, loss: 0.525813
global_step: 12196, epoch: 105, loss: 0.483274
global_step: 12197, epoch: 105, loss: 0.607445
global_step: 12198, epoch: 105, loss: 0.502155
global_step: 12199, epoch: 105, loss: 0.493652
global_step: 12200, epoch: 105, loss: 0.296342
epoch: 105
train	acc: 0.8795	macro: p 0.8923, r 0.6848, f1: 0.7138	micro: p 0.8795, r 0.8795, f1 0.8795	weighted_f1:0.8662
dev	acc: 0.5843	macro: p 0.5818, r 0.3579, f1: 0.3699	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5410
test	acc: 0.6042	macro: p 0.4324, r 0.3359, f1: 0.3465	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5661
global_step: 12201, epoch: 106, loss: 0.534096
global_step: 12202, epoch: 106, loss: 0.491756
global_step: 12203, epoch: 106, loss: 0.534395
global_step: 12204, epoch: 106, loss: 0.493365
global_step: 12205, epoch: 106, loss: 0.435012
global_step: 12206, epoch: 106, loss: 0.645805
global_step: 12207, epoch: 106, loss: 0.412142
global_step: 12208, epoch: 106, loss: 0.507533
global_step: 12209, epoch: 106, loss: 0.503362
global_step: 12210, epoch: 106, loss: 0.591961
global_step: 12211, epoch: 106, loss: 0.561400
global_step: 12212, epoch: 106, loss: 0.420944
global_step: 12213, epoch: 106, loss: 0.436269
global_step: 12214, epoch: 106, loss: 0.527243
global_step: 12215, epoch: 106, loss: 0.536875
global_step: 12216, epoch: 106, loss: 0.503218
global_step: 12217, epoch: 106, loss: 0.432219
global_step: 12218, epoch: 106, loss: 0.542443
global_step: 12219, epoch: 106, loss: 0.511339
global_step: 12220, epoch: 106, loss: 0.484211
global_step: 12221, epoch: 106, loss: 0.564670
global_step: 12222, epoch: 106, loss: 0.496558
global_step: 12223, epoch: 106, loss: 0.475645
global_step: 12224, epoch: 106, loss: 0.527278
global_step: 12225, epoch: 106, loss: 0.546195
global_step: 12226, epoch: 106, loss: 0.558276
global_step: 12227, epoch: 106, loss: 0.499236
global_step: 12228, epoch: 106, loss: 0.521061
global_step: 12229, epoch: 106, loss: 0.381101
global_step: 12230, epoch: 106, loss: 0.526472
global_step: 12231, epoch: 106, loss: 0.523765
global_step: 12232, epoch: 106, loss: 0.498451
global_step: 12233, epoch: 106, loss: 0.465318
global_step: 12234, epoch: 106, loss: 0.530605
global_step: 12235, epoch: 106, loss: 0.542667
global_step: 12236, epoch: 106, loss: 0.446608
global_step: 12237, epoch: 106, loss: 0.507248
global_step: 12238, epoch: 106, loss: 0.523080
global_step: 12239, epoch: 106, loss: 0.442799
global_step: 12240, epoch: 106, loss: 0.503798
epoch: 106
train	acc: 0.9008	macro: p 0.8937, r 0.7338, f1: 0.7512	micro: p 0.9008, r 0.9008, f1 0.9008	weighted_f1:0.8906
dev	acc: 0.5555	macro: p 0.5220, r 0.3526, f1: 0.3534	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5226
test	acc: 0.5885	macro: p 0.3939, r 0.3494, f1: 0.3517	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5636
global_step: 12241, epoch: 107, loss: 0.442851
global_step: 12242, epoch: 107, loss: 0.509450
global_step: 12243, epoch: 107, loss: 0.653310
global_step: 12244, epoch: 107, loss: 0.451213
global_step: 12245, epoch: 107, loss: 0.496028
global_step: 12246, epoch: 107, loss: 0.437947
global_step: 12247, epoch: 107, loss: 0.501310
global_step: 12248, epoch: 107, loss: 0.503389
global_step: 12249, epoch: 107, loss: 0.481017
global_step: 12250, epoch: 107, loss: 0.487326
global_step: 12251, epoch: 107, loss: 0.396656
global_step: 12252, epoch: 107, loss: 0.523493
global_step: 12253, epoch: 107, loss: 0.507949
global_step: 12254, epoch: 107, loss: 0.494440
global_step: 12255, epoch: 107, loss: 0.489371
global_step: 12256, epoch: 107, loss: 0.422151
global_step: 12257, epoch: 107, loss: 0.454663
global_step: 12258, epoch: 107, loss: 0.591118
global_step: 12259, epoch: 107, loss: 0.444017
global_step: 12260, epoch: 107, loss: 0.617060
global_step: 12261, epoch: 107, loss: 0.526577
global_step: 12262, epoch: 107, loss: 0.469953
global_step: 12263, epoch: 107, loss: 0.492623
global_step: 12264, epoch: 107, loss: 0.446696
global_step: 12265, epoch: 107, loss: 0.484774
global_step: 12266, epoch: 107, loss: 0.403057
global_step: 12267, epoch: 107, loss: 0.570845
global_step: 12268, epoch: 107, loss: 0.513354
global_step: 12269, epoch: 107, loss: 0.523863
global_step: 12270, epoch: 107, loss: 0.521659
global_step: 12271, epoch: 107, loss: 0.451121
global_step: 12272, epoch: 107, loss: 0.485705
global_step: 12273, epoch: 107, loss: 0.541633
global_step: 12274, epoch: 107, loss: 0.478440
global_step: 12275, epoch: 107, loss: 0.481569
global_step: 12276, epoch: 107, loss: 0.424941
global_step: 12277, epoch: 107, loss: 0.422887
global_step: 12278, epoch: 107, loss: 0.543701
global_step: 12279, epoch: 107, loss: 0.490977
global_step: 12280, epoch: 107, loss: 0.093748
epoch: 107
train	acc: 0.8949	macro: p 0.8943, r 0.7197, f1: 0.7473	micro: p 0.8949, r 0.8949, f1 0.8949	weighted_f1:0.8838
dev	acc: 0.5726	macro: p 0.5577, r 0.3563, f1: 0.3642	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5298
test	acc: 0.6000	macro: p 0.4048, r 0.3409, f1: 0.3467	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5640
global_step: 12281, epoch: 108, loss: 0.518955
global_step: 12282, epoch: 108, loss: 0.468746
global_step: 12283, epoch: 108, loss: 0.500608
global_step: 12284, epoch: 108, loss: 0.415881
global_step: 12285, epoch: 108, loss: 0.426272
global_step: 12286, epoch: 108, loss: 0.522822
global_step: 12287, epoch: 108, loss: 0.443090
global_step: 12288, epoch: 108, loss: 0.499674
global_step: 12289, epoch: 108, loss: 0.491656
global_step: 12290, epoch: 108, loss: 0.487579
global_step: 12291, epoch: 108, loss: 0.547454
global_step: 12292, epoch: 108, loss: 0.503255
global_step: 12293, epoch: 108, loss: 0.476804
global_step: 12294, epoch: 108, loss: 0.464493
global_step: 12295, epoch: 108, loss: 0.502379
global_step: 12296, epoch: 108, loss: 0.554224
global_step: 12297, epoch: 108, loss: 0.452511
global_step: 12298, epoch: 108, loss: 0.499253
global_step: 12299, epoch: 108, loss: 0.522168
global_step: 12300, epoch: 108, loss: 0.461404
global_step: 12301, epoch: 108, loss: 0.524214
global_step: 12302, epoch: 108, loss: 0.636093
global_step: 12303, epoch: 108, loss: 0.525743
global_step: 12304, epoch: 108, loss: 0.486067
global_step: 12305, epoch: 108, loss: 0.539598
global_step: 12306, epoch: 108, loss: 0.442598
global_step: 12307, epoch: 108, loss: 0.354585
global_step: 12308, epoch: 108, loss: 0.437607
global_step: 12309, epoch: 108, loss: 0.510969
global_step: 12310, epoch: 108, loss: 0.468636
global_step: 12311, epoch: 108, loss: 0.442109
global_step: 12312, epoch: 108, loss: 0.547563
global_step: 12313, epoch: 108, loss: 0.502841
global_step: 12314, epoch: 108, loss: 0.463741
global_step: 12315, epoch: 108, loss: 0.564798
global_step: 12316, epoch: 108, loss: 0.421501
global_step: 12317, epoch: 108, loss: 0.518301
global_step: 12318, epoch: 108, loss: 0.492277
global_step: 12319, epoch: 108, loss: 0.480931
global_step: 12320, epoch: 108, loss: 0.352352
epoch: 108
train	acc: 0.9016	macro: p 0.9017, r 0.7397, f1: 0.7700	micro: p 0.9016, r 0.9016, f1 0.9016	weighted_f1:0.8931
dev	acc: 0.5672	macro: p 0.5462, r 0.3502, f1: 0.3600	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5278
test	acc: 0.6023	macro: p 0.4642, r 0.3510, f1: 0.3620	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5717
global_step: 12321, epoch: 109, loss: 0.503891
global_step: 12322, epoch: 109, loss: 0.494721
global_step: 12323, epoch: 109, loss: 0.442443
global_step: 12324, epoch: 109, loss: 0.553379
global_step: 12325, epoch: 109, loss: 0.569557
global_step: 12326, epoch: 109, loss: 0.503760
global_step: 12327, epoch: 109, loss: 0.462889
global_step: 12328, epoch: 109, loss: 0.594495
global_step: 12329, epoch: 109, loss: 0.446170
global_step: 12330, epoch: 109, loss: 0.419112
global_step: 12331, epoch: 109, loss: 0.530769
global_step: 12332, epoch: 109, loss: 0.498802
global_step: 12333, epoch: 109, loss: 0.481485
global_step: 12334, epoch: 109, loss: 0.417843
global_step: 12335, epoch: 109, loss: 0.596600
global_step: 12336, epoch: 109, loss: 0.465563
global_step: 12337, epoch: 109, loss: 0.423593
global_step: 12338, epoch: 109, loss: 0.402192
global_step: 12339, epoch: 109, loss: 0.450335
global_step: 12340, epoch: 109, loss: 0.498200
global_step: 12341, epoch: 109, loss: 0.459584
global_step: 12342, epoch: 109, loss: 0.456869
global_step: 12343, epoch: 109, loss: 0.582284
global_step: 12344, epoch: 109, loss: 0.560876
global_step: 12345, epoch: 109, loss: 0.440539
global_step: 12346, epoch: 109, loss: 0.467426
global_step: 12347, epoch: 109, loss: 0.489586
global_step: 12348, epoch: 109, loss: 0.516626
global_step: 12349, epoch: 109, loss: 0.502608
global_step: 12350, epoch: 109, loss: 0.482188
global_step: 12351, epoch: 109, loss: 0.381875
global_step: 12352, epoch: 109, loss: 0.516123
global_step: 12353, epoch: 109, loss: 0.440907
global_step: 12354, epoch: 109, loss: 0.504956
global_step: 12355, epoch: 109, loss: 0.449067
global_step: 12356, epoch: 109, loss: 0.547517
global_step: 12357, epoch: 109, loss: 0.540212
global_step: 12358, epoch: 109, loss: 0.530676
global_step: 12359, epoch: 109, loss: 0.503995
global_step: 12360, epoch: 109, loss: 0.518992
epoch: 109
train	acc: 0.8973	macro: p 0.8989, r 0.7341, f1: 0.7550	micro: p 0.8973, r 0.8973, f1 0.8973	weighted_f1:0.8873
dev	acc: 0.5627	macro: p 0.5393, r 0.3482, f1: 0.3511	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5209
test	acc: 0.5950	macro: p 0.3967, r 0.3410, f1: 0.3470	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5613
global_step: 12361, epoch: 110, loss: 0.505274
global_step: 12362, epoch: 110, loss: 0.441083
global_step: 12363, epoch: 110, loss: 0.478946
global_step: 12364, epoch: 110, loss: 0.493427
global_step: 12365, epoch: 110, loss: 0.487859
global_step: 12366, epoch: 110, loss: 0.551445
global_step: 12367, epoch: 110, loss: 0.467690
global_step: 12368, epoch: 110, loss: 0.523064
global_step: 12369, epoch: 110, loss: 0.482894
global_step: 12370, epoch: 110, loss: 0.465821
global_step: 12371, epoch: 110, loss: 0.453876
global_step: 12372, epoch: 110, loss: 0.460553
global_step: 12373, epoch: 110, loss: 0.419198
global_step: 12374, epoch: 110, loss: 0.400875
global_step: 12375, epoch: 110, loss: 0.451530
global_step: 12376, epoch: 110, loss: 0.488076
global_step: 12377, epoch: 110, loss: 0.517879
global_step: 12378, epoch: 110, loss: 0.448875
global_step: 12379, epoch: 110, loss: 0.471165
global_step: 12380, epoch: 110, loss: 0.441041
global_step: 12381, epoch: 110, loss: 0.555173
global_step: 12382, epoch: 110, loss: 0.570710
global_step: 12383, epoch: 110, loss: 0.503011
global_step: 12384, epoch: 110, loss: 0.379319
global_step: 12385, epoch: 110, loss: 0.519463
global_step: 12386, epoch: 110, loss: 0.505170
global_step: 12387, epoch: 110, loss: 0.418348
global_step: 12388, epoch: 110, loss: 0.534510
global_step: 12389, epoch: 110, loss: 0.436591
global_step: 12390, epoch: 110, loss: 0.497996
global_step: 12391, epoch: 110, loss: 0.462185
global_step: 12392, epoch: 110, loss: 0.475494
global_step: 12393, epoch: 110, loss: 0.466349
global_step: 12394, epoch: 110, loss: 0.477020
global_step: 12395, epoch: 110, loss: 0.494077
global_step: 12396, epoch: 110, loss: 0.437203
global_step: 12397, epoch: 110, loss: 0.466486
global_step: 12398, epoch: 110, loss: 0.457276
global_step: 12399, epoch: 110, loss: 0.478907
global_step: 12400, epoch: 110, loss: 0.082873
epoch: 110
train	acc: 0.9059	macro: p 0.9037, r 0.7565, f1: 0.7848	micro: p 0.9059, r 0.9059, f1 0.9059	weighted_f1:0.8979
dev	acc: 0.5699	macro: p 0.5500, r 0.3600, f1: 0.3703	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5319
test	acc: 0.6027	macro: p 0.4711, r 0.3506, f1: 0.3624	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5723
global_step: 12401, epoch: 111, loss: 0.444597
global_step: 12402, epoch: 111, loss: 0.419522
global_step: 12403, epoch: 111, loss: 0.470630
global_step: 12404, epoch: 111, loss: 0.483936
global_step: 12405, epoch: 111, loss: 0.452502
global_step: 12406, epoch: 111, loss: 0.428585
global_step: 12407, epoch: 111, loss: 0.390634
global_step: 12408, epoch: 111, loss: 0.455485
global_step: 12409, epoch: 111, loss: 0.431006
global_step: 12410, epoch: 111, loss: 0.428572
global_step: 12411, epoch: 111, loss: 0.399046
global_step: 12412, epoch: 111, loss: 0.485800
global_step: 12413, epoch: 111, loss: 0.455670
global_step: 12414, epoch: 111, loss: 0.374842
global_step: 12415, epoch: 111, loss: 0.362821
global_step: 12416, epoch: 111, loss: 0.554572
global_step: 12417, epoch: 111, loss: 0.404889
global_step: 12418, epoch: 111, loss: 0.363083
global_step: 12419, epoch: 111, loss: 0.439826
global_step: 12420, epoch: 111, loss: 0.462367
global_step: 12421, epoch: 111, loss: 0.484365
global_step: 12422, epoch: 111, loss: 0.530901
global_step: 12423, epoch: 111, loss: 0.495871
global_step: 12424, epoch: 111, loss: 0.522693
global_step: 12425, epoch: 111, loss: 0.521729
global_step: 12426, epoch: 111, loss: 0.436412
global_step: 12427, epoch: 111, loss: 0.459419
global_step: 12428, epoch: 111, loss: 0.511239
global_step: 12429, epoch: 111, loss: 0.470031
global_step: 12430, epoch: 111, loss: 0.498825
global_step: 12431, epoch: 111, loss: 0.462720
global_step: 12432, epoch: 111, loss: 0.561545
global_step: 12433, epoch: 111, loss: 0.526199
global_step: 12434, epoch: 111, loss: 0.485543
global_step: 12435, epoch: 111, loss: 0.464725
global_step: 12436, epoch: 111, loss: 0.489721
global_step: 12437, epoch: 111, loss: 0.495506
global_step: 12438, epoch: 111, loss: 0.506956
global_step: 12439, epoch: 111, loss: 0.492131
global_step: 12440, epoch: 111, loss: 0.318364
epoch: 111
train	acc: 0.9159	macro: p 0.9044, r 0.7841, f1: 0.8101	micro: p 0.9159, r 0.9159, f1 0.9159	weighted_f1:0.9101
dev	acc: 0.5627	macro: p 0.4627, r 0.3607, f1: 0.3699	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5323
test	acc: 0.5962	macro: p 0.4181, r 0.3576, f1: 0.3652	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5744
global_step: 12441, epoch: 112, loss: 0.437039
global_step: 12442, epoch: 112, loss: 0.428377
global_step: 12443, epoch: 112, loss: 0.395455
global_step: 12444, epoch: 112, loss: 0.570858
global_step: 12445, epoch: 112, loss: 0.458919
global_step: 12446, epoch: 112, loss: 0.409674
global_step: 12447, epoch: 112, loss: 0.371559
global_step: 12448, epoch: 112, loss: 0.390380
global_step: 12449, epoch: 112, loss: 0.461053
global_step: 12450, epoch: 112, loss: 0.508226
global_step: 12451, epoch: 112, loss: 0.447692
global_step: 12452, epoch: 112, loss: 0.491914
global_step: 12453, epoch: 112, loss: 0.428677
global_step: 12454, epoch: 112, loss: 0.457986
global_step: 12455, epoch: 112, loss: 0.566332
global_step: 12456, epoch: 112, loss: 0.445977
global_step: 12457, epoch: 112, loss: 0.507715
global_step: 12458, epoch: 112, loss: 0.445487
global_step: 12459, epoch: 112, loss: 0.387545
global_step: 12460, epoch: 112, loss: 0.398799
global_step: 12461, epoch: 112, loss: 0.451674
global_step: 12462, epoch: 112, loss: 0.513807
global_step: 12463, epoch: 112, loss: 0.562860
global_step: 12464, epoch: 112, loss: 0.442992
global_step: 12465, epoch: 112, loss: 0.435563
global_step: 12466, epoch: 112, loss: 0.495416
global_step: 12467, epoch: 112, loss: 0.548077
global_step: 12468, epoch: 112, loss: 0.399240
global_step: 12469, epoch: 112, loss: 0.578045
global_step: 12470, epoch: 112, loss: 0.448365
global_step: 12471, epoch: 112, loss: 0.468915
global_step: 12472, epoch: 112, loss: 0.420915
global_step: 12473, epoch: 112, loss: 0.457405
global_step: 12474, epoch: 112, loss: 0.510419
global_step: 12475, epoch: 112, loss: 0.378379
global_step: 12476, epoch: 112, loss: 0.540263
global_step: 12477, epoch: 112, loss: 0.446336
global_step: 12478, epoch: 112, loss: 0.548298
global_step: 12479, epoch: 112, loss: 0.415647
global_step: 12480, epoch: 112, loss: 0.316559
epoch: 112
train	acc: 0.9075	macro: p 0.8949, r 0.7568, f1: 0.7879	micro: p 0.9075, r 0.9075, f1 0.9075	weighted_f1:0.9012
dev	acc: 0.5600	macro: p 0.5399, r 0.3619, f1: 0.3672	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5302
test	acc: 0.5897	macro: p 0.3985, r 0.3525, f1: 0.3528	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5671
global_step: 12481, epoch: 113, loss: 0.433053
global_step: 12482, epoch: 113, loss: 0.459868
global_step: 12483, epoch: 113, loss: 0.455873
global_step: 12484, epoch: 113, loss: 0.410063
global_step: 12485, epoch: 113, loss: 0.384777
global_step: 12486, epoch: 113, loss: 0.581280
global_step: 12487, epoch: 113, loss: 0.511138
global_step: 12488, epoch: 113, loss: 0.400859
global_step: 12489, epoch: 113, loss: 0.411183
global_step: 12490, epoch: 113, loss: 0.539426
global_step: 12491, epoch: 113, loss: 0.392548
global_step: 12492, epoch: 113, loss: 0.426771
global_step: 12493, epoch: 113, loss: 0.458716
global_step: 12494, epoch: 113, loss: 0.511466
global_step: 12495, epoch: 113, loss: 0.447284
global_step: 12496, epoch: 113, loss: 0.530370
global_step: 12497, epoch: 113, loss: 0.452178
global_step: 12498, epoch: 113, loss: 0.445331
global_step: 12499, epoch: 113, loss: 0.499321
global_step: 12500, epoch: 113, loss: 0.496457
global_step: 12501, epoch: 113, loss: 0.431091
global_step: 12502, epoch: 113, loss: 0.383806
global_step: 12503, epoch: 113, loss: 0.565098
global_step: 12504, epoch: 113, loss: 0.467254
global_step: 12505, epoch: 113, loss: 0.464573
global_step: 12506, epoch: 113, loss: 0.426127
global_step: 12507, epoch: 113, loss: 0.452572
global_step: 12508, epoch: 113, loss: 0.451358
global_step: 12509, epoch: 113, loss: 0.489160
global_step: 12510, epoch: 113, loss: 0.447639
global_step: 12511, epoch: 113, loss: 0.523808
global_step: 12512, epoch: 113, loss: 0.516779
global_step: 12513, epoch: 113, loss: 0.424665
global_step: 12514, epoch: 113, loss: 0.453260
global_step: 12515, epoch: 113, loss: 0.428296
global_step: 12516, epoch: 113, loss: 0.535104
global_step: 12517, epoch: 113, loss: 0.497071
global_step: 12518, epoch: 113, loss: 0.451127
global_step: 12519, epoch: 113, loss: 0.387193
global_step: 12520, epoch: 113, loss: 0.602649
epoch: 113
train	acc: 0.9029	macro: p 0.9031, r 0.7363, f1: 0.7667	micro: p 0.9029, r 0.9029, f1 0.9029	weighted_f1:0.8942
dev	acc: 0.5726	macro: p 0.5519, r 0.3575, f1: 0.3661	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5360
test	acc: 0.5992	macro: p 0.4342, r 0.3450, f1: 0.3514	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5697
global_step: 12521, epoch: 114, loss: 0.399518
global_step: 12522, epoch: 114, loss: 0.409432
global_step: 12523, epoch: 114, loss: 0.387271
global_step: 12524, epoch: 114, loss: 0.463705
global_step: 12525, epoch: 114, loss: 0.525383
global_step: 12526, epoch: 114, loss: 0.444844
global_step: 12527, epoch: 114, loss: 0.523898
global_step: 12528, epoch: 114, loss: 0.451483
global_step: 12529, epoch: 114, loss: 0.469270
global_step: 12530, epoch: 114, loss: 0.503286
global_step: 12531, epoch: 114, loss: 0.525146
global_step: 12532, epoch: 114, loss: 0.405838
global_step: 12533, epoch: 114, loss: 0.424785
global_step: 12534, epoch: 114, loss: 0.554909
global_step: 12535, epoch: 114, loss: 0.491409
global_step: 12536, epoch: 114, loss: 0.454771
global_step: 12537, epoch: 114, loss: 0.413582
global_step: 12538, epoch: 114, loss: 0.382262
global_step: 12539, epoch: 114, loss: 0.507444
global_step: 12540, epoch: 114, loss: 0.484288
global_step: 12541, epoch: 114, loss: 0.552808
global_step: 12542, epoch: 114, loss: 0.490247
global_step: 12543, epoch: 114, loss: 0.478753
global_step: 12544, epoch: 114, loss: 0.419850
global_step: 12545, epoch: 114, loss: 0.436002
global_step: 12546, epoch: 114, loss: 0.438226
global_step: 12547, epoch: 114, loss: 0.511895
global_step: 12548, epoch: 114, loss: 0.534709
global_step: 12549, epoch: 114, loss: 0.389947
global_step: 12550, epoch: 114, loss: 0.376684
global_step: 12551, epoch: 114, loss: 0.385084
global_step: 12552, epoch: 114, loss: 0.446732
global_step: 12553, epoch: 114, loss: 0.479883
global_step: 12554, epoch: 114, loss: 0.407141
global_step: 12555, epoch: 114, loss: 0.469337
global_step: 12556, epoch: 114, loss: 0.485937
global_step: 12557, epoch: 114, loss: 0.420344
global_step: 12558, epoch: 114, loss: 0.442685
global_step: 12559, epoch: 114, loss: 0.494051
global_step: 12560, epoch: 114, loss: 0.767297
epoch: 114
train	acc: 0.9046	macro: p 0.9113, r 0.7479, f1: 0.7793	micro: p 0.9046, r 0.9046, f1 0.9046	weighted_f1:0.8960
dev	acc: 0.5762	macro: p 0.4754, r 0.3533, f1: 0.3623	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5336
test	acc: 0.6008	macro: p 0.4768, r 0.3362, f1: 0.3491	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5638
global_step: 12561, epoch: 115, loss: 0.436813
global_step: 12562, epoch: 115, loss: 0.407999
global_step: 12563, epoch: 115, loss: 0.429397
global_step: 12564, epoch: 115, loss: 0.442178
global_step: 12565, epoch: 115, loss: 0.451385
global_step: 12566, epoch: 115, loss: 0.382364
global_step: 12567, epoch: 115, loss: 0.445548
global_step: 12568, epoch: 115, loss: 0.489344
global_step: 12569, epoch: 115, loss: 0.398310
global_step: 12570, epoch: 115, loss: 0.451821
global_step: 12571, epoch: 115, loss: 0.437021
global_step: 12572, epoch: 115, loss: 0.481591
global_step: 12573, epoch: 115, loss: 0.421559
global_step: 12574, epoch: 115, loss: 0.430495
global_step: 12575, epoch: 115, loss: 0.410751
global_step: 12576, epoch: 115, loss: 0.381770
global_step: 12577, epoch: 115, loss: 0.430354
global_step: 12578, epoch: 115, loss: 0.330422
global_step: 12579, epoch: 115, loss: 0.423788
global_step: 12580, epoch: 115, loss: 0.424365
global_step: 12581, epoch: 115, loss: 0.472606
global_step: 12582, epoch: 115, loss: 0.386867
global_step: 12583, epoch: 115, loss: 0.377780
global_step: 12584, epoch: 115, loss: 0.465083
global_step: 12585, epoch: 115, loss: 0.476425
global_step: 12586, epoch: 115, loss: 0.445713
global_step: 12587, epoch: 115, loss: 0.476821
global_step: 12588, epoch: 115, loss: 0.444857
global_step: 12589, epoch: 115, loss: 0.434581
global_step: 12590, epoch: 115, loss: 0.466621
global_step: 12591, epoch: 115, loss: 0.437894
global_step: 12592, epoch: 115, loss: 0.492428
global_step: 12593, epoch: 115, loss: 0.480249
global_step: 12594, epoch: 115, loss: 0.461119
global_step: 12595, epoch: 115, loss: 0.518057
global_step: 12596, epoch: 115, loss: 0.478575
global_step: 12597, epoch: 115, loss: 0.418496
global_step: 12598, epoch: 115, loss: 0.527054
global_step: 12599, epoch: 115, loss: 0.421923
global_step: 12600, epoch: 115, loss: 0.947085
epoch: 115
train	acc: 0.9144	macro: p 0.9097, r 0.7791, f1: 0.8051	micro: p 0.9144, r 0.9144, f1 0.9144	weighted_f1:0.9080
dev	acc: 0.5618	macro: p 0.4667, r 0.3586, f1: 0.3650	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5279
test	acc: 0.5966	macro: p 0.4650, r 0.3546, f1: 0.3633	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5705
global_step: 12601, epoch: 116, loss: 0.398106
global_step: 12602, epoch: 116, loss: 0.450134
global_step: 12603, epoch: 116, loss: 0.438047
global_step: 12604, epoch: 116, loss: 0.437317
global_step: 12605, epoch: 116, loss: 0.385717
global_step: 12606, epoch: 116, loss: 0.396294
global_step: 12607, epoch: 116, loss: 0.431365
global_step: 12608, epoch: 116, loss: 0.441945
global_step: 12609, epoch: 116, loss: 0.444914
global_step: 12610, epoch: 116, loss: 0.408465
global_step: 12611, epoch: 116, loss: 0.434589
global_step: 12612, epoch: 116, loss: 0.411115
global_step: 12613, epoch: 116, loss: 0.428319
global_step: 12614, epoch: 116, loss: 0.464587
global_step: 12615, epoch: 116, loss: 0.455558
global_step: 12616, epoch: 116, loss: 0.352146
global_step: 12617, epoch: 116, loss: 0.436416
global_step: 12618, epoch: 116, loss: 0.529746
global_step: 12619, epoch: 116, loss: 0.409363
global_step: 12620, epoch: 116, loss: 0.485790
global_step: 12621, epoch: 116, loss: 0.432046
global_step: 12622, epoch: 116, loss: 0.436418
global_step: 12623, epoch: 116, loss: 0.558829
global_step: 12624, epoch: 116, loss: 0.437915
global_step: 12625, epoch: 116, loss: 0.460809
global_step: 12626, epoch: 116, loss: 0.530473
global_step: 12627, epoch: 116, loss: 0.422128
global_step: 12628, epoch: 116, loss: 0.556999
global_step: 12629, epoch: 116, loss: 0.562975
global_step: 12630, epoch: 116, loss: 0.357303
global_step: 12631, epoch: 116, loss: 0.369476
global_step: 12632, epoch: 116, loss: 0.443834
global_step: 12633, epoch: 116, loss: 0.454282
global_step: 12634, epoch: 116, loss: 0.486478
global_step: 12635, epoch: 116, loss: 0.547436
global_step: 12636, epoch: 116, loss: 0.387111
global_step: 12637, epoch: 116, loss: 0.528759
global_step: 12638, epoch: 116, loss: 0.450219
global_step: 12639, epoch: 116, loss: 0.474677
global_step: 12640, epoch: 116, loss: 0.498698
epoch: 116
train	acc: 0.9046	macro: p 0.9116, r 0.7531, f1: 0.7952	micro: p 0.9046, r 0.9046, f1 0.9046	weighted_f1:0.8978
dev	acc: 0.5690	macro: p 0.4829, r 0.3431, f1: 0.3542	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5237
test	acc: 0.6046	macro: p 0.4551, r 0.3346, f1: 0.3473	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5646
global_step: 12641, epoch: 117, loss: 0.433597
global_step: 12642, epoch: 117, loss: 0.403526
global_step: 12643, epoch: 117, loss: 0.510985
global_step: 12644, epoch: 117, loss: 0.394454
global_step: 12645, epoch: 117, loss: 0.465822
global_step: 12646, epoch: 117, loss: 0.429856
global_step: 12647, epoch: 117, loss: 0.479619
global_step: 12648, epoch: 117, loss: 0.433857
global_step: 12649, epoch: 117, loss: 0.429895
global_step: 12650, epoch: 117, loss: 0.531407
global_step: 12651, epoch: 117, loss: 0.397978
global_step: 12652, epoch: 117, loss: 0.404030
global_step: 12653, epoch: 117, loss: 0.439907
global_step: 12654, epoch: 117, loss: 0.422165
global_step: 12655, epoch: 117, loss: 0.396771
global_step: 12656, epoch: 117, loss: 0.446534
global_step: 12657, epoch: 117, loss: 0.445733
global_step: 12658, epoch: 117, loss: 0.508237
global_step: 12659, epoch: 117, loss: 0.433409
global_step: 12660, epoch: 117, loss: 0.504463
global_step: 12661, epoch: 117, loss: 0.413856
global_step: 12662, epoch: 117, loss: 0.409512
global_step: 12663, epoch: 117, loss: 0.389595
global_step: 12664, epoch: 117, loss: 0.479617
global_step: 12665, epoch: 117, loss: 0.438223
global_step: 12666, epoch: 117, loss: 0.417549
global_step: 12667, epoch: 117, loss: 0.516361
global_step: 12668, epoch: 117, loss: 0.429001
global_step: 12669, epoch: 117, loss: 0.494210
global_step: 12670, epoch: 117, loss: 0.455029
global_step: 12671, epoch: 117, loss: 0.383712
global_step: 12672, epoch: 117, loss: 0.400752
global_step: 12673, epoch: 117, loss: 0.440695
global_step: 12674, epoch: 117, loss: 0.539073
global_step: 12675, epoch: 117, loss: 0.527913
global_step: 12676, epoch: 117, loss: 0.467563
global_step: 12677, epoch: 117, loss: 0.472132
global_step: 12678, epoch: 117, loss: 0.482363
global_step: 12679, epoch: 117, loss: 0.367048
global_step: 12680, epoch: 117, loss: 0.228217
epoch: 117
train	acc: 0.9116	macro: p 0.9153, r 0.7739, f1: 0.8092	micro: p 0.9116, r 0.9116, f1 0.9116	weighted_f1:0.9055
dev	acc: 0.5708	macro: p 0.4716, r 0.3492, f1: 0.3576	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5286
test	acc: 0.6000	macro: p 0.4392, r 0.3430, f1: 0.3552	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5666
global_step: 12681, epoch: 118, loss: 0.428716
global_step: 12682, epoch: 118, loss: 0.352016
global_step: 12683, epoch: 118, loss: 0.487073
global_step: 12684, epoch: 118, loss: 0.411252
global_step: 12685, epoch: 118, loss: 0.395466
global_step: 12686, epoch: 118, loss: 0.517226
global_step: 12687, epoch: 118, loss: 0.463595
global_step: 12688, epoch: 118, loss: 0.417592
global_step: 12689, epoch: 118, loss: 0.472209
global_step: 12690, epoch: 118, loss: 0.455880
global_step: 12691, epoch: 118, loss: 0.384095
global_step: 12692, epoch: 118, loss: 0.504810
global_step: 12693, epoch: 118, loss: 0.413893
global_step: 12694, epoch: 118, loss: 0.532591
global_step: 12695, epoch: 118, loss: 0.449435
global_step: 12696, epoch: 118, loss: 0.416559
global_step: 12697, epoch: 118, loss: 0.386370
global_step: 12698, epoch: 118, loss: 0.482042
global_step: 12699, epoch: 118, loss: 0.481155
global_step: 12700, epoch: 118, loss: 0.470311
global_step: 12701, epoch: 118, loss: 0.370867
global_step: 12702, epoch: 118, loss: 0.384463
global_step: 12703, epoch: 118, loss: 0.344116
global_step: 12704, epoch: 118, loss: 0.503076
global_step: 12705, epoch: 118, loss: 0.527936
global_step: 12706, epoch: 118, loss: 0.448058
global_step: 12707, epoch: 118, loss: 0.424645
global_step: 12708, epoch: 118, loss: 0.421758
global_step: 12709, epoch: 118, loss: 0.391639
global_step: 12710, epoch: 118, loss: 0.405716
global_step: 12711, epoch: 118, loss: 0.436870
global_step: 12712, epoch: 118, loss: 0.466836
global_step: 12713, epoch: 118, loss: 0.387446
global_step: 12714, epoch: 118, loss: 0.449601
global_step: 12715, epoch: 118, loss: 0.487722
global_step: 12716, epoch: 118, loss: 0.377902
global_step: 12717, epoch: 118, loss: 0.421454
global_step: 12718, epoch: 118, loss: 0.489659
global_step: 12719, epoch: 118, loss: 0.438998
global_step: 12720, epoch: 118, loss: 0.035006
epoch: 118
train	acc: 0.9154	macro: p 0.9170, r 0.7890, f1: 0.8254	micro: p 0.9154, r 0.9154, f1 0.9154	weighted_f1:0.9103
dev	acc: 0.5717	macro: p 0.4719, r 0.3510, f1: 0.3614	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5313
test	acc: 0.6034	macro: p 0.4417, r 0.3472, f1: 0.3631	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5696
global_step: 12721, epoch: 119, loss: 0.520169
global_step: 12722, epoch: 119, loss: 0.369723
global_step: 12723, epoch: 119, loss: 0.349717
global_step: 12724, epoch: 119, loss: 0.475818
global_step: 12725, epoch: 119, loss: 0.491255
global_step: 12726, epoch: 119, loss: 0.412327
global_step: 12727, epoch: 119, loss: 0.413426
global_step: 12728, epoch: 119, loss: 0.447525
global_step: 12729, epoch: 119, loss: 0.374030
global_step: 12730, epoch: 119, loss: 0.462330
global_step: 12731, epoch: 119, loss: 0.424345
global_step: 12732, epoch: 119, loss: 0.394271
global_step: 12733, epoch: 119, loss: 0.496052
global_step: 12734, epoch: 119, loss: 0.430619
global_step: 12735, epoch: 119, loss: 0.441054
global_step: 12736, epoch: 119, loss: 0.450721
global_step: 12737, epoch: 119, loss: 0.440333
global_step: 12738, epoch: 119, loss: 0.363968
global_step: 12739, epoch: 119, loss: 0.452289
global_step: 12740, epoch: 119, loss: 0.551812
global_step: 12741, epoch: 119, loss: 0.461644
global_step: 12742, epoch: 119, loss: 0.394344
global_step: 12743, epoch: 119, loss: 0.397737
global_step: 12744, epoch: 119, loss: 0.515989
global_step: 12745, epoch: 119, loss: 0.396782
global_step: 12746, epoch: 119, loss: 0.468975
global_step: 12747, epoch: 119, loss: 0.445025
global_step: 12748, epoch: 119, loss: 0.411820
global_step: 12749, epoch: 119, loss: 0.364478
global_step: 12750, epoch: 119, loss: 0.475648
global_step: 12751, epoch: 119, loss: 0.387726
global_step: 12752, epoch: 119, loss: 0.375714
global_step: 12753, epoch: 119, loss: 0.446972
global_step: 12754, epoch: 119, loss: 0.396450
global_step: 12755, epoch: 119, loss: 0.398237
global_step: 12756, epoch: 119, loss: 0.431100
global_step: 12757, epoch: 119, loss: 0.495836
global_step: 12758, epoch: 119, loss: 0.503108
global_step: 12759, epoch: 119, loss: 0.453065
global_step: 12760, epoch: 119, loss: 0.719341
epoch: 119
train	acc: 0.9129	macro: p 0.9177, r 0.7906, f1: 0.8288	micro: p 0.9129, r 0.9129, f1 0.9129	weighted_f1:0.9079
dev	acc: 0.5726	macro: p 0.4873, r 0.3533, f1: 0.3692	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5315
test	acc: 0.6046	macro: p 0.4401, r 0.3446, f1: 0.3637	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5698
global_step: 12761, epoch: 120, loss: 0.477430
global_step: 12762, epoch: 120, loss: 0.484412
global_step: 12763, epoch: 120, loss: 0.397072
global_step: 12764, epoch: 120, loss: 0.529410
global_step: 12765, epoch: 120, loss: 0.407920
global_step: 12766, epoch: 120, loss: 0.385688
global_step: 12767, epoch: 120, loss: 0.400602
global_step: 12768, epoch: 120, loss: 0.411884
global_step: 12769, epoch: 120, loss: 0.340369
global_step: 12770, epoch: 120, loss: 0.454873
global_step: 12771, epoch: 120, loss: 0.422848
global_step: 12772, epoch: 120, loss: 0.430748
global_step: 12773, epoch: 120, loss: 0.406592
global_step: 12774, epoch: 120, loss: 0.419105
global_step: 12775, epoch: 120, loss: 0.447875
global_step: 12776, epoch: 120, loss: 0.400927
global_step: 12777, epoch: 120, loss: 0.371248
global_step: 12778, epoch: 120, loss: 0.462082
global_step: 12779, epoch: 120, loss: 0.468130
global_step: 12780, epoch: 120, loss: 0.382425
global_step: 12781, epoch: 120, loss: 0.423780
global_step: 12782, epoch: 120, loss: 0.381581
global_step: 12783, epoch: 120, loss: 0.412829
global_step: 12784, epoch: 120, loss: 0.417962
global_step: 12785, epoch: 120, loss: 0.448382
global_step: 12786, epoch: 120, loss: 0.424089
global_step: 12787, epoch: 120, loss: 0.439006
global_step: 12788, epoch: 120, loss: 0.503731
global_step: 12789, epoch: 120, loss: 0.416191
global_step: 12790, epoch: 120, loss: 0.447411
global_step: 12791, epoch: 120, loss: 0.422346
global_step: 12792, epoch: 120, loss: 0.449177
global_step: 12793, epoch: 120, loss: 0.405777
global_step: 12794, epoch: 120, loss: 0.335483
global_step: 12795, epoch: 120, loss: 0.440227
global_step: 12796, epoch: 120, loss: 0.459138
global_step: 12797, epoch: 120, loss: 0.420714
global_step: 12798, epoch: 120, loss: 0.354090
global_step: 12799, epoch: 120, loss: 0.477151
global_step: 12800, epoch: 120, loss: 0.548917
epoch: 120
train	acc: 0.9184	macro: p 0.9157, r 0.8044, f1: 0.8402	micro: p 0.9184, r 0.9184, f1 0.9184	weighted_f1:0.9150
dev	acc: 0.5627	macro: p 0.4768, r 0.3569, f1: 0.3691	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5250
test	acc: 0.5946	macro: p 0.4016, r 0.3437, f1: 0.3480	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5633
global_step: 12801, epoch: 121, loss: 0.455211
global_step: 12802, epoch: 121, loss: 0.473693
global_step: 12803, epoch: 121, loss: 0.419072
global_step: 12804, epoch: 121, loss: 0.383568
global_step: 12805, epoch: 121, loss: 0.411389
global_step: 12806, epoch: 121, loss: 0.365741
global_step: 12807, epoch: 121, loss: 0.418939
global_step: 12808, epoch: 121, loss: 0.409591
global_step: 12809, epoch: 121, loss: 0.505334
global_step: 12810, epoch: 121, loss: 0.460693
global_step: 12811, epoch: 121, loss: 0.417933
global_step: 12812, epoch: 121, loss: 0.430571
global_step: 12813, epoch: 121, loss: 0.508705
global_step: 12814, epoch: 121, loss: 0.416624
global_step: 12815, epoch: 121, loss: 0.387922
global_step: 12816, epoch: 121, loss: 0.431663
global_step: 12817, epoch: 121, loss: 0.425166
global_step: 12818, epoch: 121, loss: 0.364431
global_step: 12819, epoch: 121, loss: 0.384070
global_step: 12820, epoch: 121, loss: 0.456317
global_step: 12821, epoch: 121, loss: 0.454599
global_step: 12822, epoch: 121, loss: 0.394145
global_step: 12823, epoch: 121, loss: 0.433759
global_step: 12824, epoch: 121, loss: 0.458520
global_step: 12825, epoch: 121, loss: 0.429064
global_step: 12826, epoch: 121, loss: 0.372675
global_step: 12827, epoch: 121, loss: 0.486031
global_step: 12828, epoch: 121, loss: 0.619155
global_step: 12829, epoch: 121, loss: 0.385640
global_step: 12830, epoch: 121, loss: 0.416089
global_step: 12831, epoch: 121, loss: 0.417472
global_step: 12832, epoch: 121, loss: 0.398600
global_step: 12833, epoch: 121, loss: 0.487627
global_step: 12834, epoch: 121, loss: 0.460340
global_step: 12835, epoch: 121, loss: 0.415558
global_step: 12836, epoch: 121, loss: 0.376331
global_step: 12837, epoch: 121, loss: 0.472426
global_step: 12838, epoch: 121, loss: 0.385641
global_step: 12839, epoch: 121, loss: 0.416023
global_step: 12840, epoch: 121, loss: 0.299845
epoch: 121
train	acc: 0.9185	macro: p 0.9223, r 0.7914, f1: 0.8275	micro: p 0.9185, r 0.9185, f1 0.9185	weighted_f1:0.9134
dev	acc: 0.5618	macro: p 0.5446, r 0.3508, f1: 0.3612	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5233
test	acc: 0.5958	macro: p 0.4521, r 0.3448, f1: 0.3581	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5645
global_step: 12841, epoch: 122, loss: 0.392415
global_step: 12842, epoch: 122, loss: 0.343273
global_step: 12843, epoch: 122, loss: 0.391920
global_step: 12844, epoch: 122, loss: 0.372472
global_step: 12845, epoch: 122, loss: 0.394707
global_step: 12846, epoch: 122, loss: 0.484063
global_step: 12847, epoch: 122, loss: 0.444911
global_step: 12848, epoch: 122, loss: 0.408307
global_step: 12849, epoch: 122, loss: 0.525168
global_step: 12850, epoch: 122, loss: 0.493964
global_step: 12851, epoch: 122, loss: 0.372174
global_step: 12852, epoch: 122, loss: 0.459090
global_step: 12853, epoch: 122, loss: 0.453539
global_step: 12854, epoch: 122, loss: 0.434217
global_step: 12855, epoch: 122, loss: 0.422894
global_step: 12856, epoch: 122, loss: 0.335193
global_step: 12857, epoch: 122, loss: 0.419890
global_step: 12858, epoch: 122, loss: 0.422321
global_step: 12859, epoch: 122, loss: 0.473157
global_step: 12860, epoch: 122, loss: 0.502791
global_step: 12861, epoch: 122, loss: 0.484550
global_step: 12862, epoch: 122, loss: 0.378073
global_step: 12863, epoch: 122, loss: 0.347552
global_step: 12864, epoch: 122, loss: 0.409264
global_step: 12865, epoch: 122, loss: 0.389224
global_step: 12866, epoch: 122, loss: 0.379075
global_step: 12867, epoch: 122, loss: 0.386727
global_step: 12868, epoch: 122, loss: 0.499476
global_step: 12869, epoch: 122, loss: 0.465254
global_step: 12870, epoch: 122, loss: 0.379244
global_step: 12871, epoch: 122, loss: 0.529108
global_step: 12872, epoch: 122, loss: 0.380539
global_step: 12873, epoch: 122, loss: 0.475516
global_step: 12874, epoch: 122, loss: 0.493739
global_step: 12875, epoch: 122, loss: 0.450881
global_step: 12876, epoch: 122, loss: 0.363769
global_step: 12877, epoch: 122, loss: 0.430646
global_step: 12878, epoch: 122, loss: 0.544547
global_step: 12879, epoch: 122, loss: 0.494391
global_step: 12880, epoch: 122, loss: 0.160688
epoch: 122
train	acc: 0.9220	macro: p 0.9130, r 0.7985, f1: 0.8168	micro: p 0.9220, r 0.9220, f1 0.9220	weighted_f1:0.9166
dev	acc: 0.5500	macro: p 0.4613, r 0.3623, f1: 0.3646	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5286
test	acc: 0.5766	macro: p 0.4291, r 0.3656, f1: 0.3677	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5640
global_step: 12881, epoch: 123, loss: 0.422756
global_step: 12882, epoch: 123, loss: 0.329005
global_step: 12883, epoch: 123, loss: 0.450119
global_step: 12884, epoch: 123, loss: 0.378239
global_step: 12885, epoch: 123, loss: 0.457087
global_step: 12886, epoch: 123, loss: 0.347064
global_step: 12887, epoch: 123, loss: 0.429842
global_step: 12888, epoch: 123, loss: 0.420833
global_step: 12889, epoch: 123, loss: 0.403626
global_step: 12890, epoch: 123, loss: 0.432916
global_step: 12891, epoch: 123, loss: 0.440015
global_step: 12892, epoch: 123, loss: 0.437198
global_step: 12893, epoch: 123, loss: 0.377015
global_step: 12894, epoch: 123, loss: 0.449641
global_step: 12895, epoch: 123, loss: 0.387791
global_step: 12896, epoch: 123, loss: 0.394906
global_step: 12897, epoch: 123, loss: 0.429589
global_step: 12898, epoch: 123, loss: 0.351834
global_step: 12899, epoch: 123, loss: 0.475870
global_step: 12900, epoch: 123, loss: 0.444263
global_step: 12901, epoch: 123, loss: 0.434486
global_step: 12902, epoch: 123, loss: 0.486444
global_step: 12903, epoch: 123, loss: 0.398108
global_step: 12904, epoch: 123, loss: 0.386294
global_step: 12905, epoch: 123, loss: 0.457713
global_step: 12906, epoch: 123, loss: 0.392438
global_step: 12907, epoch: 123, loss: 0.427655
global_step: 12908, epoch: 123, loss: 0.469514
global_step: 12909, epoch: 123, loss: 0.421759
global_step: 12910, epoch: 123, loss: 0.423165
global_step: 12911, epoch: 123, loss: 0.335186
global_step: 12912, epoch: 123, loss: 0.445195
global_step: 12913, epoch: 123, loss: 0.439463
global_step: 12914, epoch: 123, loss: 0.430170
global_step: 12915, epoch: 123, loss: 0.437011
global_step: 12916, epoch: 123, loss: 0.405493
global_step: 12917, epoch: 123, loss: 0.530115
global_step: 12918, epoch: 123, loss: 0.501265
global_step: 12919, epoch: 123, loss: 0.377005
global_step: 12920, epoch: 123, loss: 0.295398
epoch: 123
train	acc: 0.9196	macro: p 0.9239, r 0.7937, f1: 0.8272	micro: p 0.9196, r 0.9196, f1 0.9196	weighted_f1:0.9145
dev	acc: 0.5681	macro: p 0.4754, r 0.3474, f1: 0.3585	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5282
test	acc: 0.6031	macro: p 0.4341, r 0.3444, f1: 0.3577	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5707
global_step: 12921, epoch: 124, loss: 0.337904
global_step: 12922, epoch: 124, loss: 0.415050
global_step: 12923, epoch: 124, loss: 0.351860
global_step: 12924, epoch: 124, loss: 0.396834
global_step: 12925, epoch: 124, loss: 0.463178
global_step: 12926, epoch: 124, loss: 0.459191
global_step: 12927, epoch: 124, loss: 0.411146
global_step: 12928, epoch: 124, loss: 0.444536
global_step: 12929, epoch: 124, loss: 0.470938
global_step: 12930, epoch: 124, loss: 0.381751
global_step: 12931, epoch: 124, loss: 0.433219
global_step: 12932, epoch: 124, loss: 0.393120
global_step: 12933, epoch: 124, loss: 0.427800
global_step: 12934, epoch: 124, loss: 0.399092
global_step: 12935, epoch: 124, loss: 0.420980
global_step: 12936, epoch: 124, loss: 0.319969
global_step: 12937, epoch: 124, loss: 0.397644
global_step: 12938, epoch: 124, loss: 0.391161
global_step: 12939, epoch: 124, loss: 0.395795
global_step: 12940, epoch: 124, loss: 0.387892
global_step: 12941, epoch: 124, loss: 0.449316
global_step: 12942, epoch: 124, loss: 0.360750
global_step: 12943, epoch: 124, loss: 0.408349
global_step: 12944, epoch: 124, loss: 0.401924
global_step: 12945, epoch: 124, loss: 0.441631
global_step: 12946, epoch: 124, loss: 0.358178
global_step: 12947, epoch: 124, loss: 0.400722
global_step: 12948, epoch: 124, loss: 0.413226
global_step: 12949, epoch: 124, loss: 0.397925
global_step: 12950, epoch: 124, loss: 0.445731
global_step: 12951, epoch: 124, loss: 0.413266
global_step: 12952, epoch: 124, loss: 0.436086
global_step: 12953, epoch: 124, loss: 0.418586
global_step: 12954, epoch: 124, loss: 0.411783
global_step: 12955, epoch: 124, loss: 0.409627
global_step: 12956, epoch: 124, loss: 0.414159
global_step: 12957, epoch: 124, loss: 0.418302
global_step: 12958, epoch: 124, loss: 0.391086
global_step: 12959, epoch: 124, loss: 0.298402
global_step: 12960, epoch: 124, loss: 0.177120
epoch: 124
train	acc: 0.9231	macro: p 0.9243, r 0.8084, f1: 0.8422	micro: p 0.9231, r 0.9231, f1 0.9231	weighted_f1:0.9190
dev	acc: 0.5708	macro: p 0.5546, r 0.3572, f1: 0.3697	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5326
test	acc: 0.5989	macro: p 0.4325, r 0.3462, f1: 0.3584	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5683
global_step: 12961, epoch: 125, loss: 0.433938
global_step: 12962, epoch: 125, loss: 0.377557
global_step: 12963, epoch: 125, loss: 0.347521
global_step: 12964, epoch: 125, loss: 0.427506
global_step: 12965, epoch: 125, loss: 0.379759
global_step: 12966, epoch: 125, loss: 0.445205
global_step: 12967, epoch: 125, loss: 0.395325
global_step: 12968, epoch: 125, loss: 0.474980
global_step: 12969, epoch: 125, loss: 0.347063
global_step: 12970, epoch: 125, loss: 0.446994
global_step: 12971, epoch: 125, loss: 0.410187
global_step: 12972, epoch: 125, loss: 0.419455
global_step: 12973, epoch: 125, loss: 0.344212
global_step: 12974, epoch: 125, loss: 0.393146
global_step: 12975, epoch: 125, loss: 0.418022
global_step: 12976, epoch: 125, loss: 0.393562
global_step: 12977, epoch: 125, loss: 0.444702
global_step: 12978, epoch: 125, loss: 0.457504
global_step: 12979, epoch: 125, loss: 0.374334
global_step: 12980, epoch: 125, loss: 0.420040
global_step: 12981, epoch: 125, loss: 0.441725
global_step: 12982, epoch: 125, loss: 0.393465
global_step: 12983, epoch: 125, loss: 0.393761
global_step: 12984, epoch: 125, loss: 0.359224
global_step: 12985, epoch: 125, loss: 0.398063
global_step: 12986, epoch: 125, loss: 0.322577
global_step: 12987, epoch: 125, loss: 0.519950
global_step: 12988, epoch: 125, loss: 0.374263
global_step: 12989, epoch: 125, loss: 0.454223
global_step: 12990, epoch: 125, loss: 0.357374
global_step: 12991, epoch: 125, loss: 0.377696
global_step: 12992, epoch: 125, loss: 0.428112
global_step: 12993, epoch: 125, loss: 0.418025
global_step: 12994, epoch: 125, loss: 0.366283
global_step: 12995, epoch: 125, loss: 0.518547
global_step: 12996, epoch: 125, loss: 0.419232
global_step: 12997, epoch: 125, loss: 0.444111
global_step: 12998, epoch: 125, loss: 0.465275
global_step: 12999, epoch: 125, loss: 0.397463
global_step: 13000, epoch: 125, loss: 0.062439
epoch: 125
train	acc: 0.9259	macro: p 0.9263, r 0.8205, f1: 0.8560	micro: p 0.9259, r 0.9259, f1 0.9259	weighted_f1:0.9226
dev	acc: 0.5699	macro: p 0.4629, r 0.3479, f1: 0.3564	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5292
test	acc: 0.5996	macro: p 0.4123, r 0.3428, f1: 0.3548	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5665
global_step: 13001, epoch: 126, loss: 0.377011
global_step: 13002, epoch: 126, loss: 0.401108
global_step: 13003, epoch: 126, loss: 0.418969
global_step: 13004, epoch: 126, loss: 0.409006
global_step: 13005, epoch: 126, loss: 0.407495
global_step: 13006, epoch: 126, loss: 0.423543
global_step: 13007, epoch: 126, loss: 0.324021
global_step: 13008, epoch: 126, loss: 0.361033
global_step: 13009, epoch: 126, loss: 0.386830
global_step: 13010, epoch: 126, loss: 0.417380
global_step: 13011, epoch: 126, loss: 0.369196
global_step: 13012, epoch: 126, loss: 0.402278
global_step: 13013, epoch: 126, loss: 0.378363
global_step: 13014, epoch: 126, loss: 0.379191
global_step: 13015, epoch: 126, loss: 0.357171
global_step: 13016, epoch: 126, loss: 0.412346
global_step: 13017, epoch: 126, loss: 0.331377
global_step: 13018, epoch: 126, loss: 0.422656
global_step: 13019, epoch: 126, loss: 0.418611
global_step: 13020, epoch: 126, loss: 0.376330
global_step: 13021, epoch: 126, loss: 0.405001
global_step: 13022, epoch: 126, loss: 0.437893
global_step: 13023, epoch: 126, loss: 0.374297
global_step: 13024, epoch: 126, loss: 0.424907
global_step: 13025, epoch: 126, loss: 0.397518
global_step: 13026, epoch: 126, loss: 0.365299
global_step: 13027, epoch: 126, loss: 0.373562
global_step: 13028, epoch: 126, loss: 0.439258
global_step: 13029, epoch: 126, loss: 0.390370
global_step: 13030, epoch: 126, loss: 0.342999
global_step: 13031, epoch: 126, loss: 0.550808
global_step: 13032, epoch: 126, loss: 0.420649
global_step: 13033, epoch: 126, loss: 0.433484
global_step: 13034, epoch: 126, loss: 0.335790
global_step: 13035, epoch: 126, loss: 0.493662
global_step: 13036, epoch: 126, loss: 0.364640
global_step: 13037, epoch: 126, loss: 0.441423
global_step: 13038, epoch: 126, loss: 0.521035
global_step: 13039, epoch: 126, loss: 0.350661
global_step: 13040, epoch: 126, loss: 0.322519
epoch: 126
train	acc: 0.9159	macro: p 0.9221, r 0.7855, f1: 0.8188	micro: p 0.9159, r 0.9159, f1 0.9159	weighted_f1:0.9101
dev	acc: 0.5600	macro: p 0.4668, r 0.3432, f1: 0.3481	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5215
test	acc: 0.5962	macro: p 0.4454, r 0.3406, f1: 0.3501	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5642
global_step: 13041, epoch: 127, loss: 0.411719
global_step: 13042, epoch: 127, loss: 0.416338
global_step: 13043, epoch: 127, loss: 0.459690
global_step: 13044, epoch: 127, loss: 0.389482
global_step: 13045, epoch: 127, loss: 0.428350
global_step: 13046, epoch: 127, loss: 0.322352
global_step: 13047, epoch: 127, loss: 0.477137
global_step: 13048, epoch: 127, loss: 0.375049
global_step: 13049, epoch: 127, loss: 0.336399
global_step: 13050, epoch: 127, loss: 0.398934
global_step: 13051, epoch: 127, loss: 0.337583
global_step: 13052, epoch: 127, loss: 0.471538
global_step: 13053, epoch: 127, loss: 0.474959
global_step: 13054, epoch: 127, loss: 0.372579
global_step: 13055, epoch: 127, loss: 0.403175
global_step: 13056, epoch: 127, loss: 0.345030
global_step: 13057, epoch: 127, loss: 0.355944
global_step: 13058, epoch: 127, loss: 0.353289
global_step: 13059, epoch: 127, loss: 0.402016
global_step: 13060, epoch: 127, loss: 0.455875
global_step: 13061, epoch: 127, loss: 0.391837
global_step: 13062, epoch: 127, loss: 0.386289
global_step: 13063, epoch: 127, loss: 0.391689
global_step: 13064, epoch: 127, loss: 0.370319
global_step: 13065, epoch: 127, loss: 0.499583
global_step: 13066, epoch: 127, loss: 0.422885
global_step: 13067, epoch: 127, loss: 0.395799
global_step: 13068, epoch: 127, loss: 0.432675
global_step: 13069, epoch: 127, loss: 0.393455
global_step: 13070, epoch: 127, loss: 0.376155
global_step: 13071, epoch: 127, loss: 0.426864
global_step: 13072, epoch: 127, loss: 0.404331
global_step: 13073, epoch: 127, loss: 0.356082
global_step: 13074, epoch: 127, loss: 0.363052
global_step: 13075, epoch: 127, loss: 0.385497
global_step: 13076, epoch: 127, loss: 0.393167
global_step: 13077, epoch: 127, loss: 0.414793
global_step: 13078, epoch: 127, loss: 0.433955
global_step: 13079, epoch: 127, loss: 0.405345
global_step: 13080, epoch: 127, loss: 0.310292
epoch: 127
train	acc: 0.9250	macro: p 0.9285, r 0.8212, f1: 0.8560	micro: p 0.9250, r 0.9250, f1 0.9250	weighted_f1:0.9216
dev	acc: 0.5717	macro: p 0.4376, r 0.3569, f1: 0.3714	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5339
test	acc: 0.5966	macro: p 0.4097, r 0.3405, f1: 0.3550	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5633
global_step: 13081, epoch: 128, loss: 0.375985
global_step: 13082, epoch: 128, loss: 0.357188
global_step: 13083, epoch: 128, loss: 0.317269
global_step: 13084, epoch: 128, loss: 0.491121
global_step: 13085, epoch: 128, loss: 0.414011
global_step: 13086, epoch: 128, loss: 0.337559
global_step: 13087, epoch: 128, loss: 0.316705
global_step: 13088, epoch: 128, loss: 0.444507
global_step: 13089, epoch: 128, loss: 0.383012
global_step: 13090, epoch: 128, loss: 0.305552
global_step: 13091, epoch: 128, loss: 0.357596
global_step: 13092, epoch: 128, loss: 0.395945
global_step: 13093, epoch: 128, loss: 0.318853
global_step: 13094, epoch: 128, loss: 0.438862
global_step: 13095, epoch: 128, loss: 0.421469
global_step: 13096, epoch: 128, loss: 0.380666
global_step: 13097, epoch: 128, loss: 0.432603
global_step: 13098, epoch: 128, loss: 0.475946
global_step: 13099, epoch: 128, loss: 0.352130
global_step: 13100, epoch: 128, loss: 0.358594
global_step: 13101, epoch: 128, loss: 0.386059
global_step: 13102, epoch: 128, loss: 0.467209
global_step: 13103, epoch: 128, loss: 0.402459
global_step: 13104, epoch: 128, loss: 0.407688
global_step: 13105, epoch: 128, loss: 0.410782
global_step: 13106, epoch: 128, loss: 0.458768
global_step: 13107, epoch: 128, loss: 0.416388
global_step: 13108, epoch: 128, loss: 0.426620
global_step: 13109, epoch: 128, loss: 0.427015
global_step: 13110, epoch: 128, loss: 0.363125
global_step: 13111, epoch: 128, loss: 0.501253
global_step: 13112, epoch: 128, loss: 0.376234
global_step: 13113, epoch: 128, loss: 0.346080
global_step: 13114, epoch: 128, loss: 0.352830
global_step: 13115, epoch: 128, loss: 0.387531
global_step: 13116, epoch: 128, loss: 0.315727
global_step: 13117, epoch: 128, loss: 0.441326
global_step: 13118, epoch: 128, loss: 0.361441
global_step: 13119, epoch: 128, loss: 0.354171
global_step: 13120, epoch: 128, loss: 0.409750
epoch: 128
train	acc: 0.9357	macro: p 0.9324, r 0.8498, f1: 0.8815	micro: p 0.9357, r 0.9357, f1 0.9357	weighted_f1:0.9340
dev	acc: 0.5645	macro: p 0.4275, r 0.3586, f1: 0.3688	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5355
test	acc: 0.5958	macro: p 0.4114, r 0.3583, f1: 0.3698	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5739
global_step: 13121, epoch: 129, loss: 0.426448
global_step: 13122, epoch: 129, loss: 0.316041
global_step: 13123, epoch: 129, loss: 0.388097
global_step: 13124, epoch: 129, loss: 0.361807
global_step: 13125, epoch: 129, loss: 0.325373
global_step: 13126, epoch: 129, loss: 0.382259
global_step: 13127, epoch: 129, loss: 0.442960
global_step: 13128, epoch: 129, loss: 0.353209
global_step: 13129, epoch: 129, loss: 0.337467
global_step: 13130, epoch: 129, loss: 0.324352
global_step: 13131, epoch: 129, loss: 0.389886
global_step: 13132, epoch: 129, loss: 0.338944
global_step: 13133, epoch: 129, loss: 0.400858
global_step: 13134, epoch: 129, loss: 0.413026
global_step: 13135, epoch: 129, loss: 0.353749
global_step: 13136, epoch: 129, loss: 0.518261
global_step: 13137, epoch: 129, loss: 0.335248
global_step: 13138, epoch: 129, loss: 0.399999
global_step: 13139, epoch: 129, loss: 0.419398
global_step: 13140, epoch: 129, loss: 0.356963
global_step: 13141, epoch: 129, loss: 0.401114
global_step: 13142, epoch: 129, loss: 0.298862
global_step: 13143, epoch: 129, loss: 0.332377
global_step: 13144, epoch: 129, loss: 0.371171
global_step: 13145, epoch: 129, loss: 0.369079
global_step: 13146, epoch: 129, loss: 0.360321
global_step: 13147, epoch: 129, loss: 0.379933
global_step: 13148, epoch: 129, loss: 0.394870
global_step: 13149, epoch: 129, loss: 0.441353
global_step: 13150, epoch: 129, loss: 0.384974
global_step: 13151, epoch: 129, loss: 0.452924
global_step: 13152, epoch: 129, loss: 0.478565
global_step: 13153, epoch: 129, loss: 0.415762
global_step: 13154, epoch: 129, loss: 0.389685
global_step: 13155, epoch: 129, loss: 0.415643
global_step: 13156, epoch: 129, loss: 0.468701
global_step: 13157, epoch: 129, loss: 0.362862
global_step: 13158, epoch: 129, loss: 0.442208
global_step: 13159, epoch: 129, loss: 0.356757
global_step: 13160, epoch: 129, loss: 0.649396
epoch: 129
train	acc: 0.9284	macro: p 0.9337, r 0.8281, f1: 0.8659	micro: p 0.9284, r 0.9284, f1 0.9284	weighted_f1:0.9257
dev	acc: 0.5708	macro: p 0.4499, r 0.3525, f1: 0.3593	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5298
test	acc: 0.5962	macro: p 0.4297, r 0.3439, f1: 0.3544	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5633
global_step: 13161, epoch: 130, loss: 0.370283
global_step: 13162, epoch: 130, loss: 0.343656
global_step: 13163, epoch: 130, loss: 0.471393
global_step: 13164, epoch: 130, loss: 0.327299
global_step: 13165, epoch: 130, loss: 0.336394
global_step: 13166, epoch: 130, loss: 0.387198
global_step: 13167, epoch: 130, loss: 0.400565
global_step: 13168, epoch: 130, loss: 0.405574
global_step: 13169, epoch: 130, loss: 0.311532
global_step: 13170, epoch: 130, loss: 0.417060
global_step: 13171, epoch: 130, loss: 0.399684
global_step: 13172, epoch: 130, loss: 0.435061
global_step: 13173, epoch: 130, loss: 0.382992
global_step: 13174, epoch: 130, loss: 0.393142
global_step: 13175, epoch: 130, loss: 0.429539
global_step: 13176, epoch: 130, loss: 0.352727
global_step: 13177, epoch: 130, loss: 0.317118
global_step: 13178, epoch: 130, loss: 0.286678
global_step: 13179, epoch: 130, loss: 0.422978
global_step: 13180, epoch: 130, loss: 0.385254
global_step: 13181, epoch: 130, loss: 0.414674
global_step: 13182, epoch: 130, loss: 0.423399
global_step: 13183, epoch: 130, loss: 0.354808
global_step: 13184, epoch: 130, loss: 0.369462
global_step: 13185, epoch: 130, loss: 0.410614
global_step: 13186, epoch: 130, loss: 0.498412
global_step: 13187, epoch: 130, loss: 0.361936
global_step: 13188, epoch: 130, loss: 0.325039
global_step: 13189, epoch: 130, loss: 0.352664
global_step: 13190, epoch: 130, loss: 0.418879
global_step: 13191, epoch: 130, loss: 0.340832
global_step: 13192, epoch: 130, loss: 0.329864
global_step: 13193, epoch: 130, loss: 0.399107
global_step: 13194, epoch: 130, loss: 0.373164
global_step: 13195, epoch: 130, loss: 0.334570
global_step: 13196, epoch: 130, loss: 0.379856
global_step: 13197, epoch: 130, loss: 0.375143
global_step: 13198, epoch: 130, loss: 0.418708
global_step: 13199, epoch: 130, loss: 0.488249
global_step: 13200, epoch: 130, loss: 0.739096
epoch: 130
train	acc: 0.9285	macro: p 0.9250, r 0.8213, f1: 0.8519	micro: p 0.9285, r 0.9285, f1 0.9285	weighted_f1:0.9252
dev	acc: 0.5717	macro: p 0.4876, r 0.3592, f1: 0.3685	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5335
test	acc: 0.5962	macro: p 0.4192, r 0.3487, f1: 0.3602	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5653
global_step: 13201, epoch: 131, loss: 0.362656
global_step: 13202, epoch: 131, loss: 0.418878
global_step: 13203, epoch: 131, loss: 0.379509
global_step: 13204, epoch: 131, loss: 0.391307
global_step: 13205, epoch: 131, loss: 0.397591
global_step: 13206, epoch: 131, loss: 0.351624
global_step: 13207, epoch: 131, loss: 0.321348
global_step: 13208, epoch: 131, loss: 0.364691
global_step: 13209, epoch: 131, loss: 0.405704
global_step: 13210, epoch: 131, loss: 0.318013
global_step: 13211, epoch: 131, loss: 0.354692
global_step: 13212, epoch: 131, loss: 0.406297
global_step: 13213, epoch: 131, loss: 0.310225
global_step: 13214, epoch: 131, loss: 0.380481
global_step: 13215, epoch: 131, loss: 0.352758
global_step: 13216, epoch: 131, loss: 0.397279
global_step: 13217, epoch: 131, loss: 0.358443
global_step: 13218, epoch: 131, loss: 0.388961
global_step: 13219, epoch: 131, loss: 0.435327
global_step: 13220, epoch: 131, loss: 0.460442
global_step: 13221, epoch: 131, loss: 0.373905
global_step: 13222, epoch: 131, loss: 0.379277
global_step: 13223, epoch: 131, loss: 0.339696
global_step: 13224, epoch: 131, loss: 0.407560
global_step: 13225, epoch: 131, loss: 0.383489
global_step: 13226, epoch: 131, loss: 0.391109
global_step: 13227, epoch: 131, loss: 0.393853
global_step: 13228, epoch: 131, loss: 0.375786
global_step: 13229, epoch: 131, loss: 0.306882
global_step: 13230, epoch: 131, loss: 0.400453
global_step: 13231, epoch: 131, loss: 0.381736
global_step: 13232, epoch: 131, loss: 0.378907
global_step: 13233, epoch: 131, loss: 0.379112
global_step: 13234, epoch: 131, loss: 0.347916
global_step: 13235, epoch: 131, loss: 0.422381
global_step: 13236, epoch: 131, loss: 0.396688
global_step: 13237, epoch: 131, loss: 0.389516
global_step: 13238, epoch: 131, loss: 0.460350
global_step: 13239, epoch: 131, loss: 0.380567
global_step: 13240, epoch: 131, loss: 0.077858
epoch: 131
train	acc: 0.9364	macro: p 0.9367, r 0.8567, f1: 0.8882	micro: p 0.9364, r 0.9364, f1 0.9364	weighted_f1:0.9348
dev	acc: 0.5645	macro: p 0.4284, r 0.3541, f1: 0.3632	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5285
test	acc: 0.5958	macro: p 0.4156, r 0.3486, f1: 0.3599	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5652
global_step: 13241, epoch: 132, loss: 0.284644
global_step: 13242, epoch: 132, loss: 0.384891
global_step: 13243, epoch: 132, loss: 0.365306
global_step: 13244, epoch: 132, loss: 0.395607
global_step: 13245, epoch: 132, loss: 0.377652
global_step: 13246, epoch: 132, loss: 0.316925
global_step: 13247, epoch: 132, loss: 0.337285
global_step: 13248, epoch: 132, loss: 0.430759
global_step: 13249, epoch: 132, loss: 0.384160
global_step: 13250, epoch: 132, loss: 0.437801
global_step: 13251, epoch: 132, loss: 0.347235
global_step: 13252, epoch: 132, loss: 0.399918
global_step: 13253, epoch: 132, loss: 0.351854
global_step: 13254, epoch: 132, loss: 0.491512
global_step: 13255, epoch: 132, loss: 0.451366
global_step: 13256, epoch: 132, loss: 0.337038
global_step: 13257, epoch: 132, loss: 0.401980
global_step: 13258, epoch: 132, loss: 0.337321
global_step: 13259, epoch: 132, loss: 0.355408
global_step: 13260, epoch: 132, loss: 0.464132
global_step: 13261, epoch: 132, loss: 0.362480
global_step: 13262, epoch: 132, loss: 0.330117
global_step: 13263, epoch: 132, loss: 0.496950
global_step: 13264, epoch: 132, loss: 0.339288
global_step: 13265, epoch: 132, loss: 0.344436
global_step: 13266, epoch: 132, loss: 0.419123
global_step: 13267, epoch: 132, loss: 0.429824
global_step: 13268, epoch: 132, loss: 0.343882
global_step: 13269, epoch: 132, loss: 0.480817
global_step: 13270, epoch: 132, loss: 0.352539
global_step: 13271, epoch: 132, loss: 0.375787
global_step: 13272, epoch: 132, loss: 0.358583
global_step: 13273, epoch: 132, loss: 0.381189
global_step: 13274, epoch: 132, loss: 0.346662
global_step: 13275, epoch: 132, loss: 0.362299
global_step: 13276, epoch: 132, loss: 0.376347
global_step: 13277, epoch: 132, loss: 0.329266
global_step: 13278, epoch: 132, loss: 0.332932
global_step: 13279, epoch: 132, loss: 0.347934
global_step: 13280, epoch: 132, loss: 0.115776
epoch: 132
train	acc: 0.9371	macro: p 0.9289, r 0.8498, f1: 0.8749	micro: p 0.9371, r 0.9371, f1 0.9371	weighted_f1:0.9350
dev	acc: 0.5636	macro: p 0.4271, r 0.3714, f1: 0.3803	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5438
test	acc: 0.5793	macro: p 0.4023, r 0.3651, f1: 0.3746	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5687
global_step: 13281, epoch: 133, loss: 0.340854
global_step: 13282, epoch: 133, loss: 0.403292
global_step: 13283, epoch: 133, loss: 0.425671
global_step: 13284, epoch: 133, loss: 0.289808
global_step: 13285, epoch: 133, loss: 0.413269
global_step: 13286, epoch: 133, loss: 0.364840
global_step: 13287, epoch: 133, loss: 0.368287
global_step: 13288, epoch: 133, loss: 0.365438
global_step: 13289, epoch: 133, loss: 0.429160
global_step: 13290, epoch: 133, loss: 0.427862
global_step: 13291, epoch: 133, loss: 0.360775
global_step: 13292, epoch: 133, loss: 0.349582
global_step: 13293, epoch: 133, loss: 0.336847
global_step: 13294, epoch: 133, loss: 0.399089
global_step: 13295, epoch: 133, loss: 0.381516
global_step: 13296, epoch: 133, loss: 0.303305
global_step: 13297, epoch: 133, loss: 0.373165
global_step: 13298, epoch: 133, loss: 0.330735
global_step: 13299, epoch: 133, loss: 0.387446
global_step: 13300, epoch: 133, loss: 0.444385
global_step: 13301, epoch: 133, loss: 0.327957
global_step: 13302, epoch: 133, loss: 0.428820
global_step: 13303, epoch: 133, loss: 0.481678
global_step: 13304, epoch: 133, loss: 0.381890
global_step: 13305, epoch: 133, loss: 0.368731
global_step: 13306, epoch: 133, loss: 0.369287
global_step: 13307, epoch: 133, loss: 0.345327
global_step: 13308, epoch: 133, loss: 0.364054
global_step: 13309, epoch: 133, loss: 0.387486
global_step: 13310, epoch: 133, loss: 0.415154
global_step: 13311, epoch: 133, loss: 0.378059
global_step: 13312, epoch: 133, loss: 0.411500
global_step: 13313, epoch: 133, loss: 0.399377
global_step: 13314, epoch: 133, loss: 0.341488
global_step: 13315, epoch: 133, loss: 0.355059
global_step: 13316, epoch: 133, loss: 0.367655
global_step: 13317, epoch: 133, loss: 0.330241
global_step: 13318, epoch: 133, loss: 0.492801
global_step: 13319, epoch: 133, loss: 0.444655
global_step: 13320, epoch: 133, loss: 0.243873
epoch: 133
train	acc: 0.9229	macro: p 0.9335, r 0.8115, f1: 0.8528	micro: p 0.9229, r 0.9229, f1 0.9229	weighted_f1:0.9195
dev	acc: 0.5699	macro: p 0.5571, r 0.3482, f1: 0.3551	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5277
test	acc: 0.5954	macro: p 0.4287, r 0.3349, f1: 0.3441	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5594
global_step: 13321, epoch: 134, loss: 0.399521
global_step: 13322, epoch: 134, loss: 0.406650
global_step: 13323, epoch: 134, loss: 0.384612
global_step: 13324, epoch: 134, loss: 0.303554
global_step: 13325, epoch: 134, loss: 0.398088
global_step: 13326, epoch: 134, loss: 0.403424
global_step: 13327, epoch: 134, loss: 0.394379
global_step: 13328, epoch: 134, loss: 0.344247
global_step: 13329, epoch: 134, loss: 0.419985
global_step: 13330, epoch: 134, loss: 0.360548
global_step: 13331, epoch: 134, loss: 0.375616
global_step: 13332, epoch: 134, loss: 0.252721
global_step: 13333, epoch: 134, loss: 0.434706
global_step: 13334, epoch: 134, loss: 0.375928
global_step: 13335, epoch: 134, loss: 0.347088
global_step: 13336, epoch: 134, loss: 0.394202
global_step: 13337, epoch: 134, loss: 0.443411
global_step: 13338, epoch: 134, loss: 0.345077
global_step: 13339, epoch: 134, loss: 0.372417
global_step: 13340, epoch: 134, loss: 0.346224
global_step: 13341, epoch: 134, loss: 0.318943
global_step: 13342, epoch: 134, loss: 0.277821
global_step: 13343, epoch: 134, loss: 0.392206
global_step: 13344, epoch: 134, loss: 0.354958
global_step: 13345, epoch: 134, loss: 0.419424
global_step: 13346, epoch: 134, loss: 0.384086
global_step: 13347, epoch: 134, loss: 0.411550
global_step: 13348, epoch: 134, loss: 0.413985
global_step: 13349, epoch: 134, loss: 0.428557
global_step: 13350, epoch: 134, loss: 0.363937
global_step: 13351, epoch: 134, loss: 0.326296
global_step: 13352, epoch: 134, loss: 0.435923
global_step: 13353, epoch: 134, loss: 0.299701
global_step: 13354, epoch: 134, loss: 0.312808
global_step: 13355, epoch: 134, loss: 0.393280
global_step: 13356, epoch: 134, loss: 0.274766
global_step: 13357, epoch: 134, loss: 0.387762
global_step: 13358, epoch: 134, loss: 0.440296
global_step: 13359, epoch: 134, loss: 0.402097
global_step: 13360, epoch: 134, loss: 0.840663
epoch: 134
train	acc: 0.9378	macro: p 0.9336, r 0.8531, f1: 0.8814	micro: p 0.9378, r 0.9378, f1 0.9378	weighted_f1:0.9361
dev	acc: 0.5600	macro: p 0.4406, r 0.3683, f1: 0.3744	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5365
test	acc: 0.5808	macro: p 0.4072, r 0.3645, f1: 0.3693	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5670
global_step: 13361, epoch: 135, loss: 0.337286
global_step: 13362, epoch: 135, loss: 0.371317
global_step: 13363, epoch: 135, loss: 0.310565
global_step: 13364, epoch: 135, loss: 0.357212
global_step: 13365, epoch: 135, loss: 0.361809
global_step: 13366, epoch: 135, loss: 0.418737
global_step: 13367, epoch: 135, loss: 0.374927
global_step: 13368, epoch: 135, loss: 0.432689
global_step: 13369, epoch: 135, loss: 0.314869
global_step: 13370, epoch: 135, loss: 0.385554
global_step: 13371, epoch: 135, loss: 0.441507
global_step: 13372, epoch: 135, loss: 0.325316
global_step: 13373, epoch: 135, loss: 0.319815
global_step: 13374, epoch: 135, loss: 0.365945
global_step: 13375, epoch: 135, loss: 0.363243
global_step: 13376, epoch: 135, loss: 0.387147
global_step: 13377, epoch: 135, loss: 0.397895
global_step: 13378, epoch: 135, loss: 0.441868
global_step: 13379, epoch: 135, loss: 0.343501
global_step: 13380, epoch: 135, loss: 0.313532
global_step: 13381, epoch: 135, loss: 0.338966
global_step: 13382, epoch: 135, loss: 0.395138
global_step: 13383, epoch: 135, loss: 0.341469
global_step: 13384, epoch: 135, loss: 0.358339
global_step: 13385, epoch: 135, loss: 0.312039
global_step: 13386, epoch: 135, loss: 0.402339
global_step: 13387, epoch: 135, loss: 0.390967
global_step: 13388, epoch: 135, loss: 0.428017
global_step: 13389, epoch: 135, loss: 0.436742
global_step: 13390, epoch: 135, loss: 0.362909
global_step: 13391, epoch: 135, loss: 0.375369
global_step: 13392, epoch: 135, loss: 0.292588
global_step: 13393, epoch: 135, loss: 0.329574
global_step: 13394, epoch: 135, loss: 0.375514
global_step: 13395, epoch: 135, loss: 0.356197
global_step: 13396, epoch: 135, loss: 0.391739
global_step: 13397, epoch: 135, loss: 0.359636
global_step: 13398, epoch: 135, loss: 0.466597
global_step: 13399, epoch: 135, loss: 0.386790
global_step: 13400, epoch: 135, loss: 0.517857
epoch: 135
train	acc: 0.9376	macro: p 0.9298, r 0.8470, f1: 0.8721	micro: p 0.9376, r 0.9376, f1 0.9376	weighted_f1:0.9353
dev	acc: 0.5681	macro: p 0.4405, r 0.3691, f1: 0.3799	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5447
test	acc: 0.5851	macro: p 0.4128, r 0.3624, f1: 0.3756	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5709
global_step: 13401, epoch: 136, loss: 0.366362
global_step: 13402, epoch: 136, loss: 0.347564
global_step: 13403, epoch: 136, loss: 0.303488
global_step: 13404, epoch: 136, loss: 0.374041
global_step: 13405, epoch: 136, loss: 0.400686
global_step: 13406, epoch: 136, loss: 0.269223
global_step: 13407, epoch: 136, loss: 0.406792
global_step: 13408, epoch: 136, loss: 0.353257
global_step: 13409, epoch: 136, loss: 0.400627
global_step: 13410, epoch: 136, loss: 0.335743
global_step: 13411, epoch: 136, loss: 0.476337
global_step: 13412, epoch: 136, loss: 0.366355
global_step: 13413, epoch: 136, loss: 0.410007
global_step: 13414, epoch: 136, loss: 0.362209
global_step: 13415, epoch: 136, loss: 0.374829
global_step: 13416, epoch: 136, loss: 0.315040
global_step: 13417, epoch: 136, loss: 0.361231
global_step: 13418, epoch: 136, loss: 0.325431
global_step: 13419, epoch: 136, loss: 0.427102
global_step: 13420, epoch: 136, loss: 0.356348
global_step: 13421, epoch: 136, loss: 0.441692
global_step: 13422, epoch: 136, loss: 0.349640
global_step: 13423, epoch: 136, loss: 0.299299
global_step: 13424, epoch: 136, loss: 0.360742
global_step: 13425, epoch: 136, loss: 0.382769
global_step: 13426, epoch: 136, loss: 0.396772
global_step: 13427, epoch: 136, loss: 0.337393
global_step: 13428, epoch: 136, loss: 0.344621
global_step: 13429, epoch: 136, loss: 0.387133
global_step: 13430, epoch: 136, loss: 0.358434
global_step: 13431, epoch: 136, loss: 0.353195
global_step: 13432, epoch: 136, loss: 0.349301
global_step: 13433, epoch: 136, loss: 0.319744
global_step: 13434, epoch: 136, loss: 0.323278
global_step: 13435, epoch: 136, loss: 0.482244
global_step: 13436, epoch: 136, loss: 0.371590
global_step: 13437, epoch: 136, loss: 0.431669
global_step: 13438, epoch: 136, loss: 0.478147
global_step: 13439, epoch: 136, loss: 0.409960
global_step: 13440, epoch: 136, loss: 0.537696
epoch: 136
train	acc: 0.9382	macro: p 0.9376, r 0.8560, f1: 0.8868	micro: p 0.9382, r 0.9382, f1 0.9382	weighted_f1:0.9365
dev	acc: 0.5609	macro: p 0.4018, r 0.3510, f1: 0.3546	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5285
test	acc: 0.5962	macro: p 0.4170, r 0.3591, f1: 0.3678	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5724
global_step: 13441, epoch: 137, loss: 0.336589
global_step: 13442, epoch: 137, loss: 0.387725
global_step: 13443, epoch: 137, loss: 0.413057
global_step: 13444, epoch: 137, loss: 0.424260
global_step: 13445, epoch: 137, loss: 0.400287
global_step: 13446, epoch: 137, loss: 0.367087
global_step: 13447, epoch: 137, loss: 0.348030
global_step: 13448, epoch: 137, loss: 0.336506
global_step: 13449, epoch: 137, loss: 0.365252
global_step: 13450, epoch: 137, loss: 0.357192
global_step: 13451, epoch: 137, loss: 0.390042
global_step: 13452, epoch: 137, loss: 0.285941
global_step: 13453, epoch: 137, loss: 0.389145
global_step: 13454, epoch: 137, loss: 0.357518
global_step: 13455, epoch: 137, loss: 0.309676
global_step: 13456, epoch: 137, loss: 0.440490
global_step: 13457, epoch: 137, loss: 0.349656
global_step: 13458, epoch: 137, loss: 0.345303
global_step: 13459, epoch: 137, loss: 0.340265
global_step: 13460, epoch: 137, loss: 0.259769
global_step: 13461, epoch: 137, loss: 0.345359
global_step: 13462, epoch: 137, loss: 0.306492
global_step: 13463, epoch: 137, loss: 0.497599
global_step: 13464, epoch: 137, loss: 0.311049
global_step: 13465, epoch: 137, loss: 0.460419
global_step: 13466, epoch: 137, loss: 0.397657
global_step: 13467, epoch: 137, loss: 0.321385
global_step: 13468, epoch: 137, loss: 0.366823
global_step: 13469, epoch: 137, loss: 0.303293
global_step: 13470, epoch: 137, loss: 0.391840
global_step: 13471, epoch: 137, loss: 0.368376
global_step: 13472, epoch: 137, loss: 0.376323
global_step: 13473, epoch: 137, loss: 0.361401
global_step: 13474, epoch: 137, loss: 0.419154
global_step: 13475, epoch: 137, loss: 0.349294
global_step: 13476, epoch: 137, loss: 0.373303
global_step: 13477, epoch: 137, loss: 0.371494
global_step: 13478, epoch: 137, loss: 0.388214
global_step: 13479, epoch: 137, loss: 0.426516
global_step: 13480, epoch: 137, loss: 0.391316
epoch: 137
train	acc: 0.9261	macro: p 0.9361, r 0.8305, f1: 0.8688	micro: p 0.9261, r 0.9261, f1 0.9261	weighted_f1:0.9234
dev	acc: 0.5681	macro: p 0.4547, r 0.3422, f1: 0.3588	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5263
test	acc: 0.6042	macro: p 0.4342, r 0.3390, f1: 0.3624	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5662
global_step: 13481, epoch: 138, loss: 0.460382
global_step: 13482, epoch: 138, loss: 0.448498
global_step: 13483, epoch: 138, loss: 0.334133
global_step: 13484, epoch: 138, loss: 0.334787
global_step: 13485, epoch: 138, loss: 0.347025
global_step: 13486, epoch: 138, loss: 0.347222
global_step: 13487, epoch: 138, loss: 0.364280
global_step: 13488, epoch: 138, loss: 0.404150
global_step: 13489, epoch: 138, loss: 0.316165
global_step: 13490, epoch: 138, loss: 0.323610
global_step: 13491, epoch: 138, loss: 0.330472
global_step: 13492, epoch: 138, loss: 0.303118
global_step: 13493, epoch: 138, loss: 0.452801
global_step: 13494, epoch: 138, loss: 0.347726
global_step: 13495, epoch: 138, loss: 0.351552
global_step: 13496, epoch: 138, loss: 0.305692
global_step: 13497, epoch: 138, loss: 0.339580
global_step: 13498, epoch: 138, loss: 0.383782
global_step: 13499, epoch: 138, loss: 0.305631
global_step: 13500, epoch: 138, loss: 0.535749
global_step: 13501, epoch: 138, loss: 0.301336
global_step: 13502, epoch: 138, loss: 0.358664
global_step: 13503, epoch: 138, loss: 0.373723
global_step: 13504, epoch: 138, loss: 0.306697
global_step: 13505, epoch: 138, loss: 0.357125
global_step: 13506, epoch: 138, loss: 0.307645
global_step: 13507, epoch: 138, loss: 0.278058
global_step: 13508, epoch: 138, loss: 0.342367
global_step: 13509, epoch: 138, loss: 0.366847
global_step: 13510, epoch: 138, loss: 0.386835
global_step: 13511, epoch: 138, loss: 0.431169
global_step: 13512, epoch: 138, loss: 0.403266
global_step: 13513, epoch: 138, loss: 0.415329
global_step: 13514, epoch: 138, loss: 0.283287
global_step: 13515, epoch: 138, loss: 0.299224
global_step: 13516, epoch: 138, loss: 0.457363
global_step: 13517, epoch: 138, loss: 0.337077
global_step: 13518, epoch: 138, loss: 0.405946
global_step: 13519, epoch: 138, loss: 0.371221
global_step: 13520, epoch: 138, loss: 0.412605
epoch: 138
train	acc: 0.9438	macro: p 0.9435, r 0.8686, f1: 0.8970	micro: p 0.9438, r 0.9438, f1 0.9438	weighted_f1:0.9424
dev	acc: 0.5609	macro: p 0.4393, r 0.3655, f1: 0.3728	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5349
test	acc: 0.5897	macro: p 0.4218, r 0.3611, f1: 0.3712	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5708
global_step: 13521, epoch: 139, loss: 0.347993
global_step: 13522, epoch: 139, loss: 0.397477
global_step: 13523, epoch: 139, loss: 0.364654
global_step: 13524, epoch: 139, loss: 0.451093
global_step: 13525, epoch: 139, loss: 0.317128
global_step: 13526, epoch: 139, loss: 0.353714
global_step: 13527, epoch: 139, loss: 0.362877
global_step: 13528, epoch: 139, loss: 0.318445
global_step: 13529, epoch: 139, loss: 0.270647
global_step: 13530, epoch: 139, loss: 0.315942
global_step: 13531, epoch: 139, loss: 0.361028
global_step: 13532, epoch: 139, loss: 0.330788
global_step: 13533, epoch: 139, loss: 0.355492
global_step: 13534, epoch: 139, loss: 0.421539
global_step: 13535, epoch: 139, loss: 0.310655
global_step: 13536, epoch: 139, loss: 0.358257
global_step: 13537, epoch: 139, loss: 0.290710
global_step: 13538, epoch: 139, loss: 0.407682
global_step: 13539, epoch: 139, loss: 0.247740
global_step: 13540, epoch: 139, loss: 0.310320
global_step: 13541, epoch: 139, loss: 0.337935
global_step: 13542, epoch: 139, loss: 0.425970
global_step: 13543, epoch: 139, loss: 0.370695
global_step: 13544, epoch: 139, loss: 0.396493
global_step: 13545, epoch: 139, loss: 0.359705
global_step: 13546, epoch: 139, loss: 0.368824
global_step: 13547, epoch: 139, loss: 0.361504
global_step: 13548, epoch: 139, loss: 0.349413
global_step: 13549, epoch: 139, loss: 0.337916
global_step: 13550, epoch: 139, loss: 0.340619
global_step: 13551, epoch: 139, loss: 0.435352
global_step: 13552, epoch: 139, loss: 0.353920
global_step: 13553, epoch: 139, loss: 0.365430
global_step: 13554, epoch: 139, loss: 0.303956
global_step: 13555, epoch: 139, loss: 0.394466
global_step: 13556, epoch: 139, loss: 0.321228
global_step: 13557, epoch: 139, loss: 0.400469
global_step: 13558, epoch: 139, loss: 0.393041
global_step: 13559, epoch: 139, loss: 0.352991
global_step: 13560, epoch: 139, loss: 0.154817
epoch: 139
train	acc: 0.9403	macro: p 0.9403, r 0.8582, f1: 0.8875	micro: p 0.9403, r 0.9403, f1 0.9403	weighted_f1:0.9385
dev	acc: 0.5564	macro: p 0.5133, r 0.3475, f1: 0.3489	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5218
test	acc: 0.5920	macro: p 0.4116, r 0.3548, f1: 0.3620	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5675
global_step: 13561, epoch: 140, loss: 0.329680
global_step: 13562, epoch: 140, loss: 0.293242
global_step: 13563, epoch: 140, loss: 0.456920
global_step: 13564, epoch: 140, loss: 0.391896
global_step: 13565, epoch: 140, loss: 0.290909
global_step: 13566, epoch: 140, loss: 0.325541
global_step: 13567, epoch: 140, loss: 0.332387
global_step: 13568, epoch: 140, loss: 0.317510
global_step: 13569, epoch: 140, loss: 0.344514
global_step: 13570, epoch: 140, loss: 0.412907
global_step: 13571, epoch: 140, loss: 0.320358
global_step: 13572, epoch: 140, loss: 0.314472
global_step: 13573, epoch: 140, loss: 0.364173
global_step: 13574, epoch: 140, loss: 0.363104
global_step: 13575, epoch: 140, loss: 0.347450
global_step: 13576, epoch: 140, loss: 0.387660
global_step: 13577, epoch: 140, loss: 0.386188
global_step: 13578, epoch: 140, loss: 0.356039
global_step: 13579, epoch: 140, loss: 0.406009
global_step: 13580, epoch: 140, loss: 0.404978
global_step: 13581, epoch: 140, loss: 0.431258
global_step: 13582, epoch: 140, loss: 0.352688
global_step: 13583, epoch: 140, loss: 0.318358
global_step: 13584, epoch: 140, loss: 0.352592
global_step: 13585, epoch: 140, loss: 0.367269
global_step: 13586, epoch: 140, loss: 0.286392
global_step: 13587, epoch: 140, loss: 0.383354
global_step: 13588, epoch: 140, loss: 0.385901
global_step: 13589, epoch: 140, loss: 0.277748
global_step: 13590, epoch: 140, loss: 0.341066
global_step: 13591, epoch: 140, loss: 0.379625
global_step: 13592, epoch: 140, loss: 0.390260
global_step: 13593, epoch: 140, loss: 0.363375
global_step: 13594, epoch: 140, loss: 0.415984
global_step: 13595, epoch: 140, loss: 0.357340
global_step: 13596, epoch: 140, loss: 0.331724
global_step: 13597, epoch: 140, loss: 0.330863
global_step: 13598, epoch: 140, loss: 0.382306
global_step: 13599, epoch: 140, loss: 0.363049
global_step: 13600, epoch: 140, loss: 0.187927
epoch: 140
train	acc: 0.9422	macro: p 0.9446, r 0.8733, f1: 0.9027	micro: p 0.9422, r 0.9422, f1 0.9422	weighted_f1:0.9412
dev	acc: 0.5654	macro: p 0.4453, r 0.3540, f1: 0.3655	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5290
test	acc: 0.5950	macro: p 0.4130, r 0.3517, f1: 0.3640	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5659
global_step: 13601, epoch: 141, loss: 0.288965
global_step: 13602, epoch: 141, loss: 0.235792
global_step: 13603, epoch: 141, loss: 0.352904
global_step: 13604, epoch: 141, loss: 0.365630
global_step: 13605, epoch: 141, loss: 0.254465
global_step: 13606, epoch: 141, loss: 0.335154
global_step: 13607, epoch: 141, loss: 0.360367
global_step: 13608, epoch: 141, loss: 0.355140
global_step: 13609, epoch: 141, loss: 0.288508
global_step: 13610, epoch: 141, loss: 0.400963
global_step: 13611, epoch: 141, loss: 0.359560
global_step: 13612, epoch: 141, loss: 0.397585
global_step: 13613, epoch: 141, loss: 0.381381
global_step: 13614, epoch: 141, loss: 0.361205
global_step: 13615, epoch: 141, loss: 0.344861
global_step: 13616, epoch: 141, loss: 0.366229
global_step: 13617, epoch: 141, loss: 0.392579
global_step: 13618, epoch: 141, loss: 0.337453
global_step: 13619, epoch: 141, loss: 0.298106
global_step: 13620, epoch: 141, loss: 0.468354
global_step: 13621, epoch: 141, loss: 0.334715
global_step: 13622, epoch: 141, loss: 0.366185
global_step: 13623, epoch: 141, loss: 0.336070
global_step: 13624, epoch: 141, loss: 0.371604
global_step: 13625, epoch: 141, loss: 0.342264
global_step: 13626, epoch: 141, loss: 0.284413
global_step: 13627, epoch: 141, loss: 0.370576
global_step: 13628, epoch: 141, loss: 0.297359
global_step: 13629, epoch: 141, loss: 0.369439
global_step: 13630, epoch: 141, loss: 0.361876
global_step: 13631, epoch: 141, loss: 0.346878
global_step: 13632, epoch: 141, loss: 0.411384
global_step: 13633, epoch: 141, loss: 0.381304
global_step: 13634, epoch: 141, loss: 0.285440
global_step: 13635, epoch: 141, loss: 0.389852
global_step: 13636, epoch: 141, loss: 0.293981
global_step: 13637, epoch: 141, loss: 0.325920
global_step: 13638, epoch: 141, loss: 0.381454
global_step: 13639, epoch: 141, loss: 0.418456
global_step: 13640, epoch: 141, loss: 0.622615
epoch: 141
train	acc: 0.9414	macro: p 0.9388, r 0.8640, f1: 0.8886	micro: p 0.9414, r 0.9414, f1 0.9414	weighted_f1:0.9395
dev	acc: 0.5627	macro: p 0.5196, r 0.3703, f1: 0.3797	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5366
test	acc: 0.5854	macro: p 0.4029, r 0.3615, f1: 0.3707	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5678
global_step: 13641, epoch: 142, loss: 0.365574
global_step: 13642, epoch: 142, loss: 0.407627
global_step: 13643, epoch: 142, loss: 0.337922
global_step: 13644, epoch: 142, loss: 0.274477
global_step: 13645, epoch: 142, loss: 0.350912
global_step: 13646, epoch: 142, loss: 0.399525
global_step: 13647, epoch: 142, loss: 0.384705
global_step: 13648, epoch: 142, loss: 0.350534
global_step: 13649, epoch: 142, loss: 0.351091
global_step: 13650, epoch: 142, loss: 0.328266
global_step: 13651, epoch: 142, loss: 0.261586
global_step: 13652, epoch: 142, loss: 0.328539
global_step: 13653, epoch: 142, loss: 0.312063
global_step: 13654, epoch: 142, loss: 0.263081
global_step: 13655, epoch: 142, loss: 0.344129
global_step: 13656, epoch: 142, loss: 0.339031
global_step: 13657, epoch: 142, loss: 0.299086
global_step: 13658, epoch: 142, loss: 0.347081
global_step: 13659, epoch: 142, loss: 0.353655
global_step: 13660, epoch: 142, loss: 0.362326
global_step: 13661, epoch: 142, loss: 0.310329
global_step: 13662, epoch: 142, loss: 0.298526
global_step: 13663, epoch: 142, loss: 0.386692
global_step: 13664, epoch: 142, loss: 0.337530
global_step: 13665, epoch: 142, loss: 0.389751
global_step: 13666, epoch: 142, loss: 0.431631
global_step: 13667, epoch: 142, loss: 0.312920
global_step: 13668, epoch: 142, loss: 0.375200
global_step: 13669, epoch: 142, loss: 0.263147
global_step: 13670, epoch: 142, loss: 0.386946
global_step: 13671, epoch: 142, loss: 0.344418
global_step: 13672, epoch: 142, loss: 0.366532
global_step: 13673, epoch: 142, loss: 0.317305
global_step: 13674, epoch: 142, loss: 0.359468
global_step: 13675, epoch: 142, loss: 0.434919
global_step: 13676, epoch: 142, loss: 0.394957
global_step: 13677, epoch: 142, loss: 0.372662
global_step: 13678, epoch: 142, loss: 0.301680
global_step: 13679, epoch: 142, loss: 0.286284
global_step: 13680, epoch: 142, loss: 0.047650
epoch: 142
train	acc: 0.9444	macro: p 0.9462, r 0.8720, f1: 0.9009	micro: p 0.9444, r 0.9444, f1 0.9444	weighted_f1:0.9431
dev	acc: 0.5636	macro: p 0.4400, r 0.3524, f1: 0.3646	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5303
test	acc: 0.5920	macro: p 0.4105, r 0.3502, f1: 0.3645	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5665
global_step: 13681, epoch: 143, loss: 0.345344
global_step: 13682, epoch: 143, loss: 0.361844
global_step: 13683, epoch: 143, loss: 0.277978
global_step: 13684, epoch: 143, loss: 0.284055
global_step: 13685, epoch: 143, loss: 0.295730
global_step: 13686, epoch: 143, loss: 0.381966
global_step: 13687, epoch: 143, loss: 0.294448
global_step: 13688, epoch: 143, loss: 0.284855
global_step: 13689, epoch: 143, loss: 0.289922
global_step: 13690, epoch: 143, loss: 0.270331
global_step: 13691, epoch: 143, loss: 0.385447
global_step: 13692, epoch: 143, loss: 0.373687
global_step: 13693, epoch: 143, loss: 0.344289
global_step: 13694, epoch: 143, loss: 0.319996
global_step: 13695, epoch: 143, loss: 0.274317
global_step: 13696, epoch: 143, loss: 0.320796
global_step: 13697, epoch: 143, loss: 0.367271
global_step: 13698, epoch: 143, loss: 0.329475
global_step: 13699, epoch: 143, loss: 0.402856
global_step: 13700, epoch: 143, loss: 0.363944
global_step: 13701, epoch: 143, loss: 0.372705
global_step: 13702, epoch: 143, loss: 0.366571
global_step: 13703, epoch: 143, loss: 0.350892
global_step: 13704, epoch: 143, loss: 0.336163
global_step: 13705, epoch: 143, loss: 0.352628
global_step: 13706, epoch: 143, loss: 0.349795
global_step: 13707, epoch: 143, loss: 0.317274
global_step: 13708, epoch: 143, loss: 0.316494
global_step: 13709, epoch: 143, loss: 0.308944
global_step: 13710, epoch: 143, loss: 0.342030
global_step: 13711, epoch: 143, loss: 0.319513
global_step: 13712, epoch: 143, loss: 0.388758
global_step: 13713, epoch: 143, loss: 0.372560
global_step: 13714, epoch: 143, loss: 0.355522
global_step: 13715, epoch: 143, loss: 0.329262
global_step: 13716, epoch: 143, loss: 0.402679
global_step: 13717, epoch: 143, loss: 0.328149
global_step: 13718, epoch: 143, loss: 0.384560
global_step: 13719, epoch: 143, loss: 0.364616
global_step: 13720, epoch: 143, loss: 0.114113
epoch: 143
train	acc: 0.9444	macro: p 0.9530, r 0.8804, f1: 0.9108	micro: p 0.9444, r 0.9444, f1 0.9444	weighted_f1:0.9435
dev	acc: 0.5645	macro: p 0.4328, r 0.3519, f1: 0.3638	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5263
test	acc: 0.5946	macro: p 0.4049, r 0.3475, f1: 0.3577	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5632
global_step: 13721, epoch: 144, loss: 0.326710
global_step: 13722, epoch: 144, loss: 0.306400
global_step: 13723, epoch: 144, loss: 0.303103
global_step: 13724, epoch: 144, loss: 0.370126
global_step: 13725, epoch: 144, loss: 0.255925
global_step: 13726, epoch: 144, loss: 0.311330
global_step: 13727, epoch: 144, loss: 0.337784
global_step: 13728, epoch: 144, loss: 0.360077
global_step: 13729, epoch: 144, loss: 0.369060
global_step: 13730, epoch: 144, loss: 0.362968
global_step: 13731, epoch: 144, loss: 0.302275
global_step: 13732, epoch: 144, loss: 0.290846
global_step: 13733, epoch: 144, loss: 0.352818
global_step: 13734, epoch: 144, loss: 0.344117
global_step: 13735, epoch: 144, loss: 0.371962
global_step: 13736, epoch: 144, loss: 0.294650
global_step: 13737, epoch: 144, loss: 0.326138
global_step: 13738, epoch: 144, loss: 0.264396
global_step: 13739, epoch: 144, loss: 0.377775
global_step: 13740, epoch: 144, loss: 0.332177
global_step: 13741, epoch: 144, loss: 0.422087
global_step: 13742, epoch: 144, loss: 0.343043
global_step: 13743, epoch: 144, loss: 0.359860
global_step: 13744, epoch: 144, loss: 0.383881
global_step: 13745, epoch: 144, loss: 0.337975
global_step: 13746, epoch: 144, loss: 0.361629
global_step: 13747, epoch: 144, loss: 0.372410
global_step: 13748, epoch: 144, loss: 0.285163
global_step: 13749, epoch: 144, loss: 0.355118
global_step: 13750, epoch: 144, loss: 0.374367
global_step: 13751, epoch: 144, loss: 0.387522
global_step: 13752, epoch: 144, loss: 0.396231
global_step: 13753, epoch: 144, loss: 0.291787
global_step: 13754, epoch: 144, loss: 0.294001
global_step: 13755, epoch: 144, loss: 0.441477
global_step: 13756, epoch: 144, loss: 0.367323
global_step: 13757, epoch: 144, loss: 0.353032
global_step: 13758, epoch: 144, loss: 0.394197
global_step: 13759, epoch: 144, loss: 0.335196
global_step: 13760, epoch: 144, loss: 0.589700
epoch: 144
train	acc: 0.9438	macro: p 0.9419, r 0.8690, f1: 0.8957	micro: p 0.9438, r 0.9438, f1 0.9438	weighted_f1:0.9423
dev	acc: 0.5591	macro: p 0.4590, r 0.3553, f1: 0.3641	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5281
test	acc: 0.5889	macro: p 0.4183, r 0.3598, f1: 0.3712	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5687
global_step: 13761, epoch: 145, loss: 0.288395
global_step: 13762, epoch: 145, loss: 0.311012
global_step: 13763, epoch: 145, loss: 0.377302
global_step: 13764, epoch: 145, loss: 0.351077
global_step: 13765, epoch: 145, loss: 0.331334
global_step: 13766, epoch: 145, loss: 0.339596
global_step: 13767, epoch: 145, loss: 0.277256
global_step: 13768, epoch: 145, loss: 0.291085
global_step: 13769, epoch: 145, loss: 0.347234
global_step: 13770, epoch: 145, loss: 0.298401
global_step: 13771, epoch: 145, loss: 0.340393
global_step: 13772, epoch: 145, loss: 0.393204
global_step: 13773, epoch: 145, loss: 0.316588
global_step: 13774, epoch: 145, loss: 0.368650
global_step: 13775, epoch: 145, loss: 0.336043
global_step: 13776, epoch: 145, loss: 0.328281
global_step: 13777, epoch: 145, loss: 0.345985
global_step: 13778, epoch: 145, loss: 0.383922
global_step: 13779, epoch: 145, loss: 0.433333
global_step: 13780, epoch: 145, loss: 0.284245
global_step: 13781, epoch: 145, loss: 0.395185
global_step: 13782, epoch: 145, loss: 0.395911
global_step: 13783, epoch: 145, loss: 0.347088
global_step: 13784, epoch: 145, loss: 0.372670
global_step: 13785, epoch: 145, loss: 0.349887
global_step: 13786, epoch: 145, loss: 0.332061
global_step: 13787, epoch: 145, loss: 0.307926
global_step: 13788, epoch: 145, loss: 0.304339
global_step: 13789, epoch: 145, loss: 0.358099
global_step: 13790, epoch: 145, loss: 0.324079
global_step: 13791, epoch: 145, loss: 0.309669
global_step: 13792, epoch: 145, loss: 0.404773
global_step: 13793, epoch: 145, loss: 0.361150
global_step: 13794, epoch: 145, loss: 0.421196
global_step: 13795, epoch: 145, loss: 0.343824
global_step: 13796, epoch: 145, loss: 0.390631
global_step: 13797, epoch: 145, loss: 0.318013
global_step: 13798, epoch: 145, loss: 0.329881
global_step: 13799, epoch: 145, loss: 0.399021
global_step: 13800, epoch: 145, loss: 1.241478
epoch: 145
train	acc: 0.9431	macro: p 0.9453, r 0.8737, f1: 0.9026	micro: p 0.9431, r 0.9431, f1 0.9431	weighted_f1:0.9419
dev	acc: 0.5654	macro: p 0.4269, r 0.3475, f1: 0.3603	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5278
test	acc: 0.5966	macro: p 0.4204, r 0.3421, f1: 0.3612	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5649
global_step: 13801, epoch: 146, loss: 0.340444
global_step: 13802, epoch: 146, loss: 0.259324
global_step: 13803, epoch: 146, loss: 0.444645
global_step: 13804, epoch: 146, loss: 0.324067
global_step: 13805, epoch: 146, loss: 0.323131
global_step: 13806, epoch: 146, loss: 0.350919
global_step: 13807, epoch: 146, loss: 0.346503
global_step: 13808, epoch: 146, loss: 0.311965
global_step: 13809, epoch: 146, loss: 0.317772
global_step: 13810, epoch: 146, loss: 0.256988
global_step: 13811, epoch: 146, loss: 0.332922
global_step: 13812, epoch: 146, loss: 0.418491
global_step: 13813, epoch: 146, loss: 0.323349
global_step: 13814, epoch: 146, loss: 0.348784
global_step: 13815, epoch: 146, loss: 0.345886
global_step: 13816, epoch: 146, loss: 0.355165
global_step: 13817, epoch: 146, loss: 0.328890
global_step: 13818, epoch: 146, loss: 0.370292
global_step: 13819, epoch: 146, loss: 0.334040
global_step: 13820, epoch: 146, loss: 0.386733
global_step: 13821, epoch: 146, loss: 0.348049
global_step: 13822, epoch: 146, loss: 0.328228
global_step: 13823, epoch: 146, loss: 0.279045
global_step: 13824, epoch: 146, loss: 0.346174
global_step: 13825, epoch: 146, loss: 0.373524
global_step: 13826, epoch: 146, loss: 0.294118
global_step: 13827, epoch: 146, loss: 0.395414
global_step: 13828, epoch: 146, loss: 0.341893
global_step: 13829, epoch: 146, loss: 0.392719
global_step: 13830, epoch: 146, loss: 0.331367
global_step: 13831, epoch: 146, loss: 0.272740
global_step: 13832, epoch: 146, loss: 0.332982
global_step: 13833, epoch: 146, loss: 0.290064
global_step: 13834, epoch: 146, loss: 0.343627
global_step: 13835, epoch: 146, loss: 0.263505
global_step: 13836, epoch: 146, loss: 0.361322
global_step: 13837, epoch: 146, loss: 0.376954
global_step: 13838, epoch: 146, loss: 0.359601
global_step: 13839, epoch: 146, loss: 0.340301
global_step: 13840, epoch: 146, loss: 0.584777
epoch: 146
train	acc: 0.9490	macro: p 0.9512, r 0.8916, f1: 0.9168	micro: p 0.9490, r 0.9490, f1 0.9490	weighted_f1:0.9483
dev	acc: 0.5582	macro: p 0.4236, r 0.3626, f1: 0.3747	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5318
test	acc: 0.5939	macro: p 0.4030, r 0.3631, f1: 0.3708	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5724
global_step: 13841, epoch: 147, loss: 0.324213
global_step: 13842, epoch: 147, loss: 0.342789
global_step: 13843, epoch: 147, loss: 0.298088
global_step: 13844, epoch: 147, loss: 0.310922
global_step: 13845, epoch: 147, loss: 0.298980
global_step: 13846, epoch: 147, loss: 0.325543
global_step: 13847, epoch: 147, loss: 0.308891
global_step: 13848, epoch: 147, loss: 0.348889
global_step: 13849, epoch: 147, loss: 0.289171
global_step: 13850, epoch: 147, loss: 0.351844
global_step: 13851, epoch: 147, loss: 0.264356
global_step: 13852, epoch: 147, loss: 0.343591
global_step: 13853, epoch: 147, loss: 0.301697
global_step: 13854, epoch: 147, loss: 0.328374
global_step: 13855, epoch: 147, loss: 0.295566
global_step: 13856, epoch: 147, loss: 0.290880
global_step: 13857, epoch: 147, loss: 0.367449
global_step: 13858, epoch: 147, loss: 0.372304
global_step: 13859, epoch: 147, loss: 0.343926
global_step: 13860, epoch: 147, loss: 0.372028
global_step: 13861, epoch: 147, loss: 0.340868
global_step: 13862, epoch: 147, loss: 0.336090
global_step: 13863, epoch: 147, loss: 0.293212
global_step: 13864, epoch: 147, loss: 0.282453
global_step: 13865, epoch: 147, loss: 0.286455
global_step: 13866, epoch: 147, loss: 0.327968
global_step: 13867, epoch: 147, loss: 0.299978
global_step: 13868, epoch: 147, loss: 0.391835
global_step: 13869, epoch: 147, loss: 0.301051
global_step: 13870, epoch: 147, loss: 0.373721
global_step: 13871, epoch: 147, loss: 0.400497
global_step: 13872, epoch: 147, loss: 0.429716
global_step: 13873, epoch: 147, loss: 0.298113
global_step: 13874, epoch: 147, loss: 0.336904
global_step: 13875, epoch: 147, loss: 0.328669
global_step: 13876, epoch: 147, loss: 0.308130
global_step: 13877, epoch: 147, loss: 0.293676
global_step: 13878, epoch: 147, loss: 0.376034
global_step: 13879, epoch: 147, loss: 0.286392
global_step: 13880, epoch: 147, loss: 0.153437
epoch: 147
train	acc: 0.9470	macro: p 0.9472, r 0.8809, f1: 0.9066	micro: p 0.9470, r 0.9470, f1 0.9470	weighted_f1:0.9459
dev	acc: 0.5636	macro: p 0.5390, r 0.3674, f1: 0.3751	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5337
test	acc: 0.5897	macro: p 0.4146, r 0.3600, f1: 0.3665	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5675
global_step: 13881, epoch: 148, loss: 0.318046
global_step: 13882, epoch: 148, loss: 0.370452
global_step: 13883, epoch: 148, loss: 0.270612
global_step: 13884, epoch: 148, loss: 0.317078
global_step: 13885, epoch: 148, loss: 0.424499
global_step: 13886, epoch: 148, loss: 0.234691
global_step: 13887, epoch: 148, loss: 0.364511
global_step: 13888, epoch: 148, loss: 0.316306
global_step: 13889, epoch: 148, loss: 0.334124
global_step: 13890, epoch: 148, loss: 0.306577
global_step: 13891, epoch: 148, loss: 0.295085
global_step: 13892, epoch: 148, loss: 0.298567
global_step: 13893, epoch: 148, loss: 0.380576
global_step: 13894, epoch: 148, loss: 0.287573
global_step: 13895, epoch: 148, loss: 0.365077
global_step: 13896, epoch: 148, loss: 0.307451
global_step: 13897, epoch: 148, loss: 0.359657
global_step: 13898, epoch: 148, loss: 0.309350
global_step: 13899, epoch: 148, loss: 0.346992
global_step: 13900, epoch: 148, loss: 0.295990
global_step: 13901, epoch: 148, loss: 0.423388
global_step: 13902, epoch: 148, loss: 0.306065
global_step: 13903, epoch: 148, loss: 0.307492
global_step: 13904, epoch: 148, loss: 0.377265
global_step: 13905, epoch: 148, loss: 0.333361
global_step: 13906, epoch: 148, loss: 0.377099
global_step: 13907, epoch: 148, loss: 0.302453
global_step: 13908, epoch: 148, loss: 0.384586
global_step: 13909, epoch: 148, loss: 0.388519
global_step: 13910, epoch: 148, loss: 0.261202
global_step: 13911, epoch: 148, loss: 0.409662
global_step: 13912, epoch: 148, loss: 0.343443
global_step: 13913, epoch: 148, loss: 0.394355
global_step: 13914, epoch: 148, loss: 0.386977
global_step: 13915, epoch: 148, loss: 0.334496
global_step: 13916, epoch: 148, loss: 0.321114
global_step: 13917, epoch: 148, loss: 0.275484
global_step: 13918, epoch: 148, loss: 0.302605
global_step: 13919, epoch: 148, loss: 0.345423
global_step: 13920, epoch: 148, loss: 1.036808
epoch: 148
train	acc: 0.9500	macro: p 0.9492, r 0.8953, f1: 0.9173	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9494
dev	acc: 0.5609	macro: p 0.4196, r 0.3592, f1: 0.3624	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5301
test	acc: 0.5870	macro: p 0.3942, r 0.3578, f1: 0.3644	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5650
global_step: 13921, epoch: 149, loss: 0.341218
global_step: 13922, epoch: 149, loss: 0.352991
global_step: 13923, epoch: 149, loss: 0.360966
global_step: 13924, epoch: 149, loss: 0.289967
global_step: 13925, epoch: 149, loss: 0.313844
global_step: 13926, epoch: 149, loss: 0.364429
global_step: 13927, epoch: 149, loss: 0.379910
global_step: 13928, epoch: 149, loss: 0.326844
global_step: 13929, epoch: 149, loss: 0.390804
global_step: 13930, epoch: 149, loss: 0.308499
global_step: 13931, epoch: 149, loss: 0.319961
global_step: 13932, epoch: 149, loss: 0.298603
global_step: 13933, epoch: 149, loss: 0.343579
global_step: 13934, epoch: 149, loss: 0.340345
global_step: 13935, epoch: 149, loss: 0.304356
global_step: 13936, epoch: 149, loss: 0.314077
global_step: 13937, epoch: 149, loss: 0.322949
global_step: 13938, epoch: 149, loss: 0.257238
global_step: 13939, epoch: 149, loss: 0.387782
global_step: 13940, epoch: 149, loss: 0.274063
global_step: 13941, epoch: 149, loss: 0.308788
global_step: 13942, epoch: 149, loss: 0.365634
global_step: 13943, epoch: 149, loss: 0.322116
global_step: 13944, epoch: 149, loss: 0.205081
global_step: 13945, epoch: 149, loss: 0.345740
global_step: 13946, epoch: 149, loss: 0.323340
global_step: 13947, epoch: 149, loss: 0.335085
global_step: 13948, epoch: 149, loss: 0.279300
global_step: 13949, epoch: 149, loss: 0.362476
global_step: 13950, epoch: 149, loss: 0.258310
global_step: 13951, epoch: 149, loss: 0.336010
global_step: 13952, epoch: 149, loss: 0.247154
global_step: 13953, epoch: 149, loss: 0.304816
global_step: 13954, epoch: 149, loss: 0.388298
global_step: 13955, epoch: 149, loss: 0.341217
global_step: 13956, epoch: 149, loss: 0.294910
global_step: 13957, epoch: 149, loss: 0.345104
global_step: 13958, epoch: 149, loss: 0.371763
global_step: 13959, epoch: 149, loss: 0.336436
global_step: 13960, epoch: 149, loss: 0.181961
epoch: 149
train	acc: 0.9471	macro: p 0.9447, r 0.8800, f1: 0.9049	micro: p 0.9471, r 0.9471, f1 0.9471	weighted_f1:0.9460
dev	acc: 0.5609	macro: p 0.4229, r 0.3511, f1: 0.3592	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5271
test	acc: 0.5943	macro: p 0.4112, r 0.3548, f1: 0.3689	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5698
global_step: 13961, epoch: 150, loss: 0.268271
global_step: 13962, epoch: 150, loss: 0.324001
global_step: 13963, epoch: 150, loss: 0.366090
global_step: 13964, epoch: 150, loss: 0.292857
global_step: 13965, epoch: 150, loss: 0.363944
global_step: 13966, epoch: 150, loss: 0.315623
global_step: 13967, epoch: 150, loss: 0.274962
global_step: 13968, epoch: 150, loss: 0.330984
global_step: 13969, epoch: 150, loss: 0.318717
global_step: 13970, epoch: 150, loss: 0.275322
global_step: 13971, epoch: 150, loss: 0.296579
global_step: 13972, epoch: 150, loss: 0.348881
global_step: 13973, epoch: 150, loss: 0.323907
global_step: 13974, epoch: 150, loss: 0.337003
global_step: 13975, epoch: 150, loss: 0.348265
global_step: 13976, epoch: 150, loss: 0.284214
global_step: 13977, epoch: 150, loss: 0.362249
global_step: 13978, epoch: 150, loss: 0.332858
global_step: 13979, epoch: 150, loss: 0.311345
global_step: 13980, epoch: 150, loss: 0.326688
global_step: 13981, epoch: 150, loss: 0.273765
global_step: 13982, epoch: 150, loss: 0.347239
global_step: 13983, epoch: 150, loss: 0.348316
global_step: 13984, epoch: 150, loss: 0.329672
global_step: 13985, epoch: 150, loss: 0.366521
global_step: 13986, epoch: 150, loss: 0.279929
global_step: 13987, epoch: 150, loss: 0.260999
global_step: 13988, epoch: 150, loss: 0.347307
global_step: 13989, epoch: 150, loss: 0.278978
global_step: 13990, epoch: 150, loss: 0.315796
global_step: 13991, epoch: 150, loss: 0.254571
global_step: 13992, epoch: 150, loss: 0.226331
global_step: 13993, epoch: 150, loss: 0.305182
global_step: 13994, epoch: 150, loss: 0.407821
global_step: 13995, epoch: 150, loss: 0.393345
global_step: 13996, epoch: 150, loss: 0.324100
global_step: 13997, epoch: 150, loss: 0.286919
global_step: 13998, epoch: 150, loss: 0.412603
global_step: 13999, epoch: 150, loss: 0.392133
global_step: 14000, epoch: 150, loss: 0.154844
epoch: 150
train	acc: 0.9513	macro: p 0.9541, r 0.8935, f1: 0.9188	micro: p 0.9513, r 0.9513, f1 0.9513	weighted_f1:0.9506
dev	acc: 0.5690	macro: p 0.4821, r 0.3682, f1: 0.3834	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5390
test	acc: 0.5962	macro: p 0.4089, r 0.3563, f1: 0.3676	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5721
global_step: 14001, epoch: 151, loss: 0.313529
global_step: 14002, epoch: 151, loss: 0.364093
global_step: 14003, epoch: 151, loss: 0.349881
global_step: 14004, epoch: 151, loss: 0.325259
global_step: 14005, epoch: 151, loss: 0.289345
global_step: 14006, epoch: 151, loss: 0.325957
global_step: 14007, epoch: 151, loss: 0.370778
global_step: 14008, epoch: 151, loss: 0.272510
global_step: 14009, epoch: 151, loss: 0.330763
global_step: 14010, epoch: 151, loss: 0.337792
global_step: 14011, epoch: 151, loss: 0.340440
global_step: 14012, epoch: 151, loss: 0.249755
global_step: 14013, epoch: 151, loss: 0.302022
global_step: 14014, epoch: 151, loss: 0.350357
global_step: 14015, epoch: 151, loss: 0.352627
global_step: 14016, epoch: 151, loss: 0.262293
global_step: 14017, epoch: 151, loss: 0.350989
global_step: 14018, epoch: 151, loss: 0.361568
global_step: 14019, epoch: 151, loss: 0.302669
global_step: 14020, epoch: 151, loss: 0.296021
global_step: 14021, epoch: 151, loss: 0.271640
global_step: 14022, epoch: 151, loss: 0.294810
global_step: 14023, epoch: 151, loss: 0.266659
global_step: 14024, epoch: 151, loss: 0.389552
global_step: 14025, epoch: 151, loss: 0.273781
global_step: 14026, epoch: 151, loss: 0.426054
global_step: 14027, epoch: 151, loss: 0.343642
global_step: 14028, epoch: 151, loss: 0.350973
global_step: 14029, epoch: 151, loss: 0.312330
global_step: 14030, epoch: 151, loss: 0.326711
global_step: 14031, epoch: 151, loss: 0.327559
global_step: 14032, epoch: 151, loss: 0.345289
global_step: 14033, epoch: 151, loss: 0.340611
global_step: 14034, epoch: 151, loss: 0.340071
global_step: 14035, epoch: 151, loss: 0.294627
global_step: 14036, epoch: 151, loss: 0.337324
global_step: 14037, epoch: 151, loss: 0.332692
global_step: 14038, epoch: 151, loss: 0.359865
global_step: 14039, epoch: 151, loss: 0.357864
global_step: 14040, epoch: 151, loss: 0.185513
epoch: 151
train	acc: 0.9505	macro: p 0.9533, r 0.8966, f1: 0.9207	micro: p 0.9505, r 0.9505, f1 0.9505	weighted_f1:0.9499
dev	acc: 0.5672	macro: p 0.4463, r 0.3604, f1: 0.3741	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5357
test	acc: 0.5927	macro: p 0.3995, r 0.3495, f1: 0.3620	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5671
global_step: 14041, epoch: 152, loss: 0.330206
global_step: 14042, epoch: 152, loss: 0.341408
global_step: 14043, epoch: 152, loss: 0.297034
global_step: 14044, epoch: 152, loss: 0.284750
global_step: 14045, epoch: 152, loss: 0.298224
global_step: 14046, epoch: 152, loss: 0.304650
global_step: 14047, epoch: 152, loss: 0.282255
global_step: 14048, epoch: 152, loss: 0.396965
global_step: 14049, epoch: 152, loss: 0.304603
global_step: 14050, epoch: 152, loss: 0.349912
global_step: 14051, epoch: 152, loss: 0.338385
global_step: 14052, epoch: 152, loss: 0.304118
global_step: 14053, epoch: 152, loss: 0.280793
global_step: 14054, epoch: 152, loss: 0.280618
global_step: 14055, epoch: 152, loss: 0.264055
global_step: 14056, epoch: 152, loss: 0.379936
global_step: 14057, epoch: 152, loss: 0.341455
global_step: 14058, epoch: 152, loss: 0.353888
global_step: 14059, epoch: 152, loss: 0.374410
global_step: 14060, epoch: 152, loss: 0.317444
global_step: 14061, epoch: 152, loss: 0.321217
global_step: 14062, epoch: 152, loss: 0.276374
global_step: 14063, epoch: 152, loss: 0.321647
global_step: 14064, epoch: 152, loss: 0.267339
global_step: 14065, epoch: 152, loss: 0.324350
global_step: 14066, epoch: 152, loss: 0.385412
global_step: 14067, epoch: 152, loss: 0.295809
global_step: 14068, epoch: 152, loss: 0.299275
global_step: 14069, epoch: 152, loss: 0.349899
global_step: 14070, epoch: 152, loss: 0.319172
global_step: 14071, epoch: 152, loss: 0.321184
global_step: 14072, epoch: 152, loss: 0.361043
global_step: 14073, epoch: 152, loss: 0.288350
global_step: 14074, epoch: 152, loss: 0.356405
global_step: 14075, epoch: 152, loss: 0.385328
global_step: 14076, epoch: 152, loss: 0.310603
global_step: 14077, epoch: 152, loss: 0.317486
global_step: 14078, epoch: 152, loss: 0.255445
global_step: 14079, epoch: 152, loss: 0.309681
global_step: 14080, epoch: 152, loss: 0.357735
epoch: 152
train	acc: 0.9500	macro: p 0.9518, r 0.8929, f1: 0.9177	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9494
dev	acc: 0.5600	macro: p 0.4219, r 0.3589, f1: 0.3639	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5315
test	acc: 0.5835	macro: p 0.4170, r 0.3596, f1: 0.3664	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5628
global_step: 14081, epoch: 153, loss: 0.272254
global_step: 14082, epoch: 153, loss: 0.320488
global_step: 14083, epoch: 153, loss: 0.314680
global_step: 14084, epoch: 153, loss: 0.205379
global_step: 14085, epoch: 153, loss: 0.289946
global_step: 14086, epoch: 153, loss: 0.332006
global_step: 14087, epoch: 153, loss: 0.274354
global_step: 14088, epoch: 153, loss: 0.344037
global_step: 14089, epoch: 153, loss: 0.341782
global_step: 14090, epoch: 153, loss: 0.317658
global_step: 14091, epoch: 153, loss: 0.371088
global_step: 14092, epoch: 153, loss: 0.288432
global_step: 14093, epoch: 153, loss: 0.350911
global_step: 14094, epoch: 153, loss: 0.412468
global_step: 14095, epoch: 153, loss: 0.363165
global_step: 14096, epoch: 153, loss: 0.255776
global_step: 14097, epoch: 153, loss: 0.257002
global_step: 14098, epoch: 153, loss: 0.321338
global_step: 14099, epoch: 153, loss: 0.350919
global_step: 14100, epoch: 153, loss: 0.434983
global_step: 14101, epoch: 153, loss: 0.369094
global_step: 14102, epoch: 153, loss: 0.341325
global_step: 14103, epoch: 153, loss: 0.361916
global_step: 14104, epoch: 153, loss: 0.310877
global_step: 14105, epoch: 153, loss: 0.325145
global_step: 14106, epoch: 153, loss: 0.348918
global_step: 14107, epoch: 153, loss: 0.330920
global_step: 14108, epoch: 153, loss: 0.309433
global_step: 14109, epoch: 153, loss: 0.349746
global_step: 14110, epoch: 153, loss: 0.382084
global_step: 14111, epoch: 153, loss: 0.304605
global_step: 14112, epoch: 153, loss: 0.381852
global_step: 14113, epoch: 153, loss: 0.332403
global_step: 14114, epoch: 153, loss: 0.301349
global_step: 14115, epoch: 153, loss: 0.336729
global_step: 14116, epoch: 153, loss: 0.287903
global_step: 14117, epoch: 153, loss: 0.426276
global_step: 14118, epoch: 153, loss: 0.269850
global_step: 14119, epoch: 153, loss: 0.310719
global_step: 14120, epoch: 153, loss: 0.122580
epoch: 153
train	acc: 0.9526	macro: p 0.9503, r 0.9033, f1: 0.9233	micro: p 0.9526, r 0.9526, f1 0.9526	weighted_f1:0.9521
dev	acc: 0.5636	macro: p 0.4364, r 0.3692, f1: 0.3767	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5387
test	acc: 0.5797	macro: p 0.4057, r 0.3663, f1: 0.3746	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5650
global_step: 14121, epoch: 154, loss: 0.310868
global_step: 14122, epoch: 154, loss: 0.284454
global_step: 14123, epoch: 154, loss: 0.325873
global_step: 14124, epoch: 154, loss: 0.297588
global_step: 14125, epoch: 154, loss: 0.418101
global_step: 14126, epoch: 154, loss: 0.283233
global_step: 14127, epoch: 154, loss: 0.282425
global_step: 14128, epoch: 154, loss: 0.279571
global_step: 14129, epoch: 154, loss: 0.297109
global_step: 14130, epoch: 154, loss: 0.295114
global_step: 14131, epoch: 154, loss: 0.292047
global_step: 14132, epoch: 154, loss: 0.371141
global_step: 14133, epoch: 154, loss: 0.270309
global_step: 14134, epoch: 154, loss: 0.294495
global_step: 14135, epoch: 154, loss: 0.324457
global_step: 14136, epoch: 154, loss: 0.317323
global_step: 14137, epoch: 154, loss: 0.262960
global_step: 14138, epoch: 154, loss: 0.360329
global_step: 14139, epoch: 154, loss: 0.244706
global_step: 14140, epoch: 154, loss: 0.290920
global_step: 14141, epoch: 154, loss: 0.360950
global_step: 14142, epoch: 154, loss: 0.362973
global_step: 14143, epoch: 154, loss: 0.367380
global_step: 14144, epoch: 154, loss: 0.284989
global_step: 14145, epoch: 154, loss: 0.335697
global_step: 14146, epoch: 154, loss: 0.356944
global_step: 14147, epoch: 154, loss: 0.331090
global_step: 14148, epoch: 154, loss: 0.283810
global_step: 14149, epoch: 154, loss: 0.334414
global_step: 14150, epoch: 154, loss: 0.289842
global_step: 14151, epoch: 154, loss: 0.358298
global_step: 14152, epoch: 154, loss: 0.292870
global_step: 14153, epoch: 154, loss: 0.402527
global_step: 14154, epoch: 154, loss: 0.322793
global_step: 14155, epoch: 154, loss: 0.351800
global_step: 14156, epoch: 154, loss: 0.255255
global_step: 14157, epoch: 154, loss: 0.303595
global_step: 14158, epoch: 154, loss: 0.350066
global_step: 14159, epoch: 154, loss: 0.301305
global_step: 14160, epoch: 154, loss: 0.061364
epoch: 154
train	acc: 0.9469	macro: p 0.9547, r 0.8842, f1: 0.9142	micro: p 0.9469, r 0.9469, f1 0.9469	weighted_f1:0.9460
dev	acc: 0.5699	macro: p 0.4438, r 0.3481, f1: 0.3626	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5308
test	acc: 0.6004	macro: p 0.4241, r 0.3438, f1: 0.3615	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5659
global_step: 14161, epoch: 155, loss: 0.341775
global_step: 14162, epoch: 155, loss: 0.326195
global_step: 14163, epoch: 155, loss: 0.309413
global_step: 14164, epoch: 155, loss: 0.240462
global_step: 14165, epoch: 155, loss: 0.311955
global_step: 14166, epoch: 155, loss: 0.337106
global_step: 14167, epoch: 155, loss: 0.239587
global_step: 14168, epoch: 155, loss: 0.356181
global_step: 14169, epoch: 155, loss: 0.296098
global_step: 14170, epoch: 155, loss: 0.317929
global_step: 14171, epoch: 155, loss: 0.227447
global_step: 14172, epoch: 155, loss: 0.259938
global_step: 14173, epoch: 155, loss: 0.318267
global_step: 14174, epoch: 155, loss: 0.238629
global_step: 14175, epoch: 155, loss: 0.318723
global_step: 14176, epoch: 155, loss: 0.332802
global_step: 14177, epoch: 155, loss: 0.350630
global_step: 14178, epoch: 155, loss: 0.352876
global_step: 14179, epoch: 155, loss: 0.279186
global_step: 14180, epoch: 155, loss: 0.298375
global_step: 14181, epoch: 155, loss: 0.396993
global_step: 14182, epoch: 155, loss: 0.353654
global_step: 14183, epoch: 155, loss: 0.245333
global_step: 14184, epoch: 155, loss: 0.347377
global_step: 14185, epoch: 155, loss: 0.352218
global_step: 14186, epoch: 155, loss: 0.281797
global_step: 14187, epoch: 155, loss: 0.279664
global_step: 14188, epoch: 155, loss: 0.388852
global_step: 14189, epoch: 155, loss: 0.339105
global_step: 14190, epoch: 155, loss: 0.353557
global_step: 14191, epoch: 155, loss: 0.276645
global_step: 14192, epoch: 155, loss: 0.236937
global_step: 14193, epoch: 155, loss: 0.263041
global_step: 14194, epoch: 155, loss: 0.307008
global_step: 14195, epoch: 155, loss: 0.291944
global_step: 14196, epoch: 155, loss: 0.319477
global_step: 14197, epoch: 155, loss: 0.303364
global_step: 14198, epoch: 155, loss: 0.312757
global_step: 14199, epoch: 155, loss: 0.289178
global_step: 14200, epoch: 155, loss: 0.281216
epoch: 155
train	acc: 0.9494	macro: p 0.9574, r 0.8953, f1: 0.9222	micro: p 0.9494, r 0.9494, f1 0.9494	weighted_f1:0.9487
dev	acc: 0.5699	macro: p 0.4402, r 0.3486, f1: 0.3597	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5274
test	acc: 0.5977	macro: p 0.4225, r 0.3425, f1: 0.3579	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5603
global_step: 14201, epoch: 156, loss: 0.331860
global_step: 14202, epoch: 156, loss: 0.282900
global_step: 14203, epoch: 156, loss: 0.272668
global_step: 14204, epoch: 156, loss: 0.272795
global_step: 14205, epoch: 156, loss: 0.307118
global_step: 14206, epoch: 156, loss: 0.322946
global_step: 14207, epoch: 156, loss: 0.281302
global_step: 14208, epoch: 156, loss: 0.330222
global_step: 14209, epoch: 156, loss: 0.393899
global_step: 14210, epoch: 156, loss: 0.286987
global_step: 14211, epoch: 156, loss: 0.278735
global_step: 14212, epoch: 156, loss: 0.316742
global_step: 14213, epoch: 156, loss: 0.299140
global_step: 14214, epoch: 156, loss: 0.361926
global_step: 14215, epoch: 156, loss: 0.289293
global_step: 14216, epoch: 156, loss: 0.307419
global_step: 14217, epoch: 156, loss: 0.311823
global_step: 14218, epoch: 156, loss: 0.343133
global_step: 14219, epoch: 156, loss: 0.285790
global_step: 14220, epoch: 156, loss: 0.302064
global_step: 14221, epoch: 156, loss: 0.320996
global_step: 14222, epoch: 156, loss: 0.327170
global_step: 14223, epoch: 156, loss: 0.305070
global_step: 14224, epoch: 156, loss: 0.297016
global_step: 14225, epoch: 156, loss: 0.292804
global_step: 14226, epoch: 156, loss: 0.377689
global_step: 14227, epoch: 156, loss: 0.310410
global_step: 14228, epoch: 156, loss: 0.449181
global_step: 14229, epoch: 156, loss: 0.371692
global_step: 14230, epoch: 156, loss: 0.270503
global_step: 14231, epoch: 156, loss: 0.252036
global_step: 14232, epoch: 156, loss: 0.319361
global_step: 14233, epoch: 156, loss: 0.310195
global_step: 14234, epoch: 156, loss: 0.308599
global_step: 14235, epoch: 156, loss: 0.280633
global_step: 14236, epoch: 156, loss: 0.268343
global_step: 14237, epoch: 156, loss: 0.295557
global_step: 14238, epoch: 156, loss: 0.301079
global_step: 14239, epoch: 156, loss: 0.316003
global_step: 14240, epoch: 156, loss: 0.158923
epoch: 156
train	acc: 0.9513	macro: p 0.9557, r 0.8971, f1: 0.9218	micro: p 0.9513, r 0.9513, f1 0.9513	weighted_f1:0.9507
dev	acc: 0.5672	macro: p 0.4472, r 0.3678, f1: 0.3772	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5384
test	acc: 0.5920	macro: p 0.4078, r 0.3609, f1: 0.3668	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5712
global_step: 14241, epoch: 157, loss: 0.395303
global_step: 14242, epoch: 157, loss: 0.293150
global_step: 14243, epoch: 157, loss: 0.285546
global_step: 14244, epoch: 157, loss: 0.299342
global_step: 14245, epoch: 157, loss: 0.312725
global_step: 14246, epoch: 157, loss: 0.267899
global_step: 14247, epoch: 157, loss: 0.224310
global_step: 14248, epoch: 157, loss: 0.310585
global_step: 14249, epoch: 157, loss: 0.269612
global_step: 14250, epoch: 157, loss: 0.253681
global_step: 14251, epoch: 157, loss: 0.323200
global_step: 14252, epoch: 157, loss: 0.355876
global_step: 14253, epoch: 157, loss: 0.304946
global_step: 14254, epoch: 157, loss: 0.366394
global_step: 14255, epoch: 157, loss: 0.336361
global_step: 14256, epoch: 157, loss: 0.333868
global_step: 14257, epoch: 157, loss: 0.313600
global_step: 14258, epoch: 157, loss: 0.398188
global_step: 14259, epoch: 157, loss: 0.338976
global_step: 14260, epoch: 157, loss: 0.241127
global_step: 14261, epoch: 157, loss: 0.315779
global_step: 14262, epoch: 157, loss: 0.265452
global_step: 14263, epoch: 157, loss: 0.297663
global_step: 14264, epoch: 157, loss: 0.283758
global_step: 14265, epoch: 157, loss: 0.349212
global_step: 14266, epoch: 157, loss: 0.303402
global_step: 14267, epoch: 157, loss: 0.283874
global_step: 14268, epoch: 157, loss: 0.260067
global_step: 14269, epoch: 157, loss: 0.340512
global_step: 14270, epoch: 157, loss: 0.381626
global_step: 14271, epoch: 157, loss: 0.338900
global_step: 14272, epoch: 157, loss: 0.290820
global_step: 14273, epoch: 157, loss: 0.348358
global_step: 14274, epoch: 157, loss: 0.333817
global_step: 14275, epoch: 157, loss: 0.368204
global_step: 14276, epoch: 157, loss: 0.282115
global_step: 14277, epoch: 157, loss: 0.285869
global_step: 14278, epoch: 157, loss: 0.272505
global_step: 14279, epoch: 157, loss: 0.365790
global_step: 14280, epoch: 157, loss: 0.243145
epoch: 157
train	acc: 0.9516	macro: p 0.9543, r 0.8990, f1: 0.9228	micro: p 0.9516, r 0.9516, f1 0.9516	weighted_f1:0.9510
dev	acc: 0.5636	macro: p 0.4434, r 0.3559, f1: 0.3694	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5301
test	acc: 0.5920	macro: p 0.4050, r 0.3515, f1: 0.3646	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5659
global_step: 14281, epoch: 158, loss: 0.262271
global_step: 14282, epoch: 158, loss: 0.332034
global_step: 14283, epoch: 158, loss: 0.357820
global_step: 14284, epoch: 158, loss: 0.224663
global_step: 14285, epoch: 158, loss: 0.301491
global_step: 14286, epoch: 158, loss: 0.314963
global_step: 14287, epoch: 158, loss: 0.195051
global_step: 14288, epoch: 158, loss: 0.326999
global_step: 14289, epoch: 158, loss: 0.282889
global_step: 14290, epoch: 158, loss: 0.250364
global_step: 14291, epoch: 158, loss: 0.307679
global_step: 14292, epoch: 158, loss: 0.392249
global_step: 14293, epoch: 158, loss: 0.367428
global_step: 14294, epoch: 158, loss: 0.332286
global_step: 14295, epoch: 158, loss: 0.289126
global_step: 14296, epoch: 158, loss: 0.292035
global_step: 14297, epoch: 158, loss: 0.312106
global_step: 14298, epoch: 158, loss: 0.269147
global_step: 14299, epoch: 158, loss: 0.288855
global_step: 14300, epoch: 158, loss: 0.260844
global_step: 14301, epoch: 158, loss: 0.368702
global_step: 14302, epoch: 158, loss: 0.235750
global_step: 14303, epoch: 158, loss: 0.296511
global_step: 14304, epoch: 158, loss: 0.400975
global_step: 14305, epoch: 158, loss: 0.378035
global_step: 14306, epoch: 158, loss: 0.279911
global_step: 14307, epoch: 158, loss: 0.326486
global_step: 14308, epoch: 158, loss: 0.393733
global_step: 14309, epoch: 158, loss: 0.333490
global_step: 14310, epoch: 158, loss: 0.310605
global_step: 14311, epoch: 158, loss: 0.273879
global_step: 14312, epoch: 158, loss: 0.322989
global_step: 14313, epoch: 158, loss: 0.323294
global_step: 14314, epoch: 158, loss: 0.292402
global_step: 14315, epoch: 158, loss: 0.362728
global_step: 14316, epoch: 158, loss: 0.291893
global_step: 14317, epoch: 158, loss: 0.330209
global_step: 14318, epoch: 158, loss: 0.301413
global_step: 14319, epoch: 158, loss: 0.249169
global_step: 14320, epoch: 158, loss: 0.041368
epoch: 158
train	acc: 0.9534	macro: p 0.9534, r 0.9028, f1: 0.9242	micro: p 0.9534, r 0.9534, f1 0.9534	weighted_f1:0.9528
dev	acc: 0.5600	macro: p 0.4330, r 0.3591, f1: 0.3677	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5314
test	acc: 0.5927	macro: p 0.4067, r 0.3611, f1: 0.3710	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5712
global_step: 14321, epoch: 159, loss: 0.375840
global_step: 14322, epoch: 159, loss: 0.320226
global_step: 14323, epoch: 159, loss: 0.294918
global_step: 14324, epoch: 159, loss: 0.276258
global_step: 14325, epoch: 159, loss: 0.374115
global_step: 14326, epoch: 159, loss: 0.238733
global_step: 14327, epoch: 159, loss: 0.281000
global_step: 14328, epoch: 159, loss: 0.371928
global_step: 14329, epoch: 159, loss: 0.346528
global_step: 14330, epoch: 159, loss: 0.241200
global_step: 14331, epoch: 159, loss: 0.288316
global_step: 14332, epoch: 159, loss: 0.242656
global_step: 14333, epoch: 159, loss: 0.280111
global_step: 14334, epoch: 159, loss: 0.262958
global_step: 14335, epoch: 159, loss: 0.350469
global_step: 14336, epoch: 159, loss: 0.343994
global_step: 14337, epoch: 159, loss: 0.405777
global_step: 14338, epoch: 159, loss: 0.336799
global_step: 14339, epoch: 159, loss: 0.304867
global_step: 14340, epoch: 159, loss: 0.301863
global_step: 14341, epoch: 159, loss: 0.283069
global_step: 14342, epoch: 159, loss: 0.281775
global_step: 14343, epoch: 159, loss: 0.266722
global_step: 14344, epoch: 159, loss: 0.287050
global_step: 14345, epoch: 159, loss: 0.306642
global_step: 14346, epoch: 159, loss: 0.270916
global_step: 14347, epoch: 159, loss: 0.301324
global_step: 14348, epoch: 159, loss: 0.332333
global_step: 14349, epoch: 159, loss: 0.332548
global_step: 14350, epoch: 159, loss: 0.360135
global_step: 14351, epoch: 159, loss: 0.261709
global_step: 14352, epoch: 159, loss: 0.245377
global_step: 14353, epoch: 159, loss: 0.394095
global_step: 14354, epoch: 159, loss: 0.342763
global_step: 14355, epoch: 159, loss: 0.251295
global_step: 14356, epoch: 159, loss: 0.332466
global_step: 14357, epoch: 159, loss: 0.349833
global_step: 14358, epoch: 159, loss: 0.355504
global_step: 14359, epoch: 159, loss: 0.250203
global_step: 14360, epoch: 159, loss: 0.178697
epoch: 159
train	acc: 0.9542	macro: p 0.9581, r 0.9118, f1: 0.9328	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9539
dev	acc: 0.5699	macro: p 0.4307, r 0.3544, f1: 0.3668	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5335
test	acc: 0.5916	macro: p 0.4069, r 0.3458, f1: 0.3593	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5620
global_step: 14361, epoch: 160, loss: 0.303938
global_step: 14362, epoch: 160, loss: 0.311017
global_step: 14363, epoch: 160, loss: 0.302969
global_step: 14364, epoch: 160, loss: 0.267063
global_step: 14365, epoch: 160, loss: 0.336147
global_step: 14366, epoch: 160, loss: 0.328553
global_step: 14367, epoch: 160, loss: 0.348031
global_step: 14368, epoch: 160, loss: 0.331169
global_step: 14369, epoch: 160, loss: 0.310682
global_step: 14370, epoch: 160, loss: 0.255301
global_step: 14371, epoch: 160, loss: 0.281685
global_step: 14372, epoch: 160, loss: 0.354526
global_step: 14373, epoch: 160, loss: 0.299068
global_step: 14374, epoch: 160, loss: 0.272179
global_step: 14375, epoch: 160, loss: 0.311760
global_step: 14376, epoch: 160, loss: 0.342848
global_step: 14377, epoch: 160, loss: 0.288121
global_step: 14378, epoch: 160, loss: 0.274415
global_step: 14379, epoch: 160, loss: 0.318482
global_step: 14380, epoch: 160, loss: 0.246265
global_step: 14381, epoch: 160, loss: 0.260310
global_step: 14382, epoch: 160, loss: 0.380213
global_step: 14383, epoch: 160, loss: 0.298431
global_step: 14384, epoch: 160, loss: 0.274417
global_step: 14385, epoch: 160, loss: 0.300895
global_step: 14386, epoch: 160, loss: 0.350902
global_step: 14387, epoch: 160, loss: 0.308104
global_step: 14388, epoch: 160, loss: 0.396624
global_step: 14389, epoch: 160, loss: 0.300859
global_step: 14390, epoch: 160, loss: 0.280060
global_step: 14391, epoch: 160, loss: 0.311495
global_step: 14392, epoch: 160, loss: 0.358570
global_step: 14393, epoch: 160, loss: 0.277741
global_step: 14394, epoch: 160, loss: 0.293420
global_step: 14395, epoch: 160, loss: 0.361287
global_step: 14396, epoch: 160, loss: 0.294145
global_step: 14397, epoch: 160, loss: 0.273745
global_step: 14398, epoch: 160, loss: 0.336327
global_step: 14399, epoch: 160, loss: 0.305484
global_step: 14400, epoch: 160, loss: 0.109943
epoch: 160
train	acc: 0.9466	macro: p 0.9507, r 0.8849, f1: 0.9124	micro: p 0.9466, r 0.9466, f1 0.9466	weighted_f1:0.9457
dev	acc: 0.5609	macro: p 0.4264, r 0.3398, f1: 0.3518	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5179
test	acc: 0.5931	macro: p 0.4189, r 0.3358, f1: 0.3529	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5568
global_step: 14401, epoch: 161, loss: 0.320285
global_step: 14402, epoch: 161, loss: 0.317250
global_step: 14403, epoch: 161, loss: 0.258079
global_step: 14404, epoch: 161, loss: 0.330766
global_step: 14405, epoch: 161, loss: 0.279177
global_step: 14406, epoch: 161, loss: 0.286013
global_step: 14407, epoch: 161, loss: 0.346305
global_step: 14408, epoch: 161, loss: 0.296134
global_step: 14409, epoch: 161, loss: 0.299412
global_step: 14410, epoch: 161, loss: 0.270684
global_step: 14411, epoch: 161, loss: 0.311745
global_step: 14412, epoch: 161, loss: 0.323245
global_step: 14413, epoch: 161, loss: 0.348753
global_step: 14414, epoch: 161, loss: 0.264437
global_step: 14415, epoch: 161, loss: 0.292327
global_step: 14416, epoch: 161, loss: 0.292645
global_step: 14417, epoch: 161, loss: 0.373992
global_step: 14418, epoch: 161, loss: 0.287841
global_step: 14419, epoch: 161, loss: 0.282223
global_step: 14420, epoch: 161, loss: 0.389234
global_step: 14421, epoch: 161, loss: 0.240341
global_step: 14422, epoch: 161, loss: 0.290647
global_step: 14423, epoch: 161, loss: 0.319159
global_step: 14424, epoch: 161, loss: 0.299322
global_step: 14425, epoch: 161, loss: 0.273996
global_step: 14426, epoch: 161, loss: 0.251542
global_step: 14427, epoch: 161, loss: 0.303936
global_step: 14428, epoch: 161, loss: 0.317139
global_step: 14429, epoch: 161, loss: 0.261345
global_step: 14430, epoch: 161, loss: 0.261237
global_step: 14431, epoch: 161, loss: 0.394990
global_step: 14432, epoch: 161, loss: 0.286041
global_step: 14433, epoch: 161, loss: 0.302654
global_step: 14434, epoch: 161, loss: 0.308715
global_step: 14435, epoch: 161, loss: 0.304018
global_step: 14436, epoch: 161, loss: 0.265974
global_step: 14437, epoch: 161, loss: 0.326993
global_step: 14438, epoch: 161, loss: 0.336140
global_step: 14439, epoch: 161, loss: 0.324776
global_step: 14440, epoch: 161, loss: 0.267266
epoch: 161
train	acc: 0.9555	macro: p 0.9596, r 0.9125, f1: 0.9335	micro: p 0.9555, r 0.9555, f1 0.9555	weighted_f1:0.9551
dev	acc: 0.5681	macro: p 0.4607, r 0.3604, f1: 0.3748	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5351
test	acc: 0.5977	macro: p 0.4106, r 0.3569, f1: 0.3696	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5713
global_step: 14441, epoch: 162, loss: 0.305533
global_step: 14442, epoch: 162, loss: 0.316133
global_step: 14443, epoch: 162, loss: 0.243843
global_step: 14444, epoch: 162, loss: 0.235017
global_step: 14445, epoch: 162, loss: 0.271432
global_step: 14446, epoch: 162, loss: 0.232637
global_step: 14447, epoch: 162, loss: 0.312429
global_step: 14448, epoch: 162, loss: 0.323357
global_step: 14449, epoch: 162, loss: 0.269135
global_step: 14450, epoch: 162, loss: 0.326956
global_step: 14451, epoch: 162, loss: 0.277659
global_step: 14452, epoch: 162, loss: 0.295997
global_step: 14453, epoch: 162, loss: 0.298418
global_step: 14454, epoch: 162, loss: 0.239638
global_step: 14455, epoch: 162, loss: 0.300544
global_step: 14456, epoch: 162, loss: 0.273142
global_step: 14457, epoch: 162, loss: 0.281986
global_step: 14458, epoch: 162, loss: 0.362977
global_step: 14459, epoch: 162, loss: 0.248044
global_step: 14460, epoch: 162, loss: 0.280231
global_step: 14461, epoch: 162, loss: 0.288147
global_step: 14462, epoch: 162, loss: 0.310321
global_step: 14463, epoch: 162, loss: 0.320411
global_step: 14464, epoch: 162, loss: 0.264575
global_step: 14465, epoch: 162, loss: 0.323999
global_step: 14466, epoch: 162, loss: 0.340092
global_step: 14467, epoch: 162, loss: 0.356959
global_step: 14468, epoch: 162, loss: 0.284824
global_step: 14469, epoch: 162, loss: 0.296664
global_step: 14470, epoch: 162, loss: 0.290906
global_step: 14471, epoch: 162, loss: 0.342394
global_step: 14472, epoch: 162, loss: 0.253194
global_step: 14473, epoch: 162, loss: 0.263745
global_step: 14474, epoch: 162, loss: 0.358158
global_step: 14475, epoch: 162, loss: 0.289384
global_step: 14476, epoch: 162, loss: 0.311736
global_step: 14477, epoch: 162, loss: 0.227397
global_step: 14478, epoch: 162, loss: 0.311725
global_step: 14479, epoch: 162, loss: 0.311522
global_step: 14480, epoch: 162, loss: 0.812448
epoch: 162
train	acc: 0.9529	macro: p 0.9560, r 0.9052, f1: 0.9279	micro: p 0.9529, r 0.9529, f1 0.9529	weighted_f1:0.9525
dev	acc: 0.5636	macro: p 0.4385, r 0.3477, f1: 0.3592	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5252
test	acc: 0.5989	macro: p 0.4219, r 0.3501, f1: 0.3622	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5678
global_step: 14481, epoch: 163, loss: 0.411618
global_step: 14482, epoch: 163, loss: 0.297632
global_step: 14483, epoch: 163, loss: 0.234999
global_step: 14484, epoch: 163, loss: 0.338095
global_step: 14485, epoch: 163, loss: 0.298629
global_step: 14486, epoch: 163, loss: 0.265582
global_step: 14487, epoch: 163, loss: 0.381923
global_step: 14488, epoch: 163, loss: 0.291325
global_step: 14489, epoch: 163, loss: 0.266331
global_step: 14490, epoch: 163, loss: 0.319438
global_step: 14491, epoch: 163, loss: 0.278493
global_step: 14492, epoch: 163, loss: 0.347242
global_step: 14493, epoch: 163, loss: 0.270492
global_step: 14494, epoch: 163, loss: 0.309659
global_step: 14495, epoch: 163, loss: 0.208675
global_step: 14496, epoch: 163, loss: 0.265096
global_step: 14497, epoch: 163, loss: 0.275395
global_step: 14498, epoch: 163, loss: 0.289998
global_step: 14499, epoch: 163, loss: 0.329217
global_step: 14500, epoch: 163, loss: 0.262719
global_step: 14501, epoch: 163, loss: 0.242705
global_step: 14502, epoch: 163, loss: 0.297679
global_step: 14503, epoch: 163, loss: 0.303692
global_step: 14504, epoch: 163, loss: 0.280233
global_step: 14505, epoch: 163, loss: 0.271348
global_step: 14506, epoch: 163, loss: 0.238544
global_step: 14507, epoch: 163, loss: 0.287744
global_step: 14508, epoch: 163, loss: 0.277483
global_step: 14509, epoch: 163, loss: 0.330668
global_step: 14510, epoch: 163, loss: 0.352186
global_step: 14511, epoch: 163, loss: 0.275996
global_step: 14512, epoch: 163, loss: 0.317725
global_step: 14513, epoch: 163, loss: 0.248645
global_step: 14514, epoch: 163, loss: 0.308721
global_step: 14515, epoch: 163, loss: 0.388974
global_step: 14516, epoch: 163, loss: 0.235377
global_step: 14517, epoch: 163, loss: 0.355606
global_step: 14518, epoch: 163, loss: 0.311254
global_step: 14519, epoch: 163, loss: 0.335451
global_step: 14520, epoch: 163, loss: 0.418163
epoch: 163
train	acc: 0.9547	macro: p 0.9582, r 0.9093, f1: 0.9309	micro: p 0.9547, r 0.9547, f1 0.9547	weighted_f1:0.9542
dev	acc: 0.5591	macro: p 0.4238, r 0.3505, f1: 0.3620	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5279
test	acc: 0.5954	macro: p 0.4299, r 0.3628, f1: 0.3790	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5726
global_step: 14521, epoch: 164, loss: 0.327944
global_step: 14522, epoch: 164, loss: 0.211457
global_step: 14523, epoch: 164, loss: 0.355034
global_step: 14524, epoch: 164, loss: 0.343562
global_step: 14525, epoch: 164, loss: 0.378906
global_step: 14526, epoch: 164, loss: 0.273387
global_step: 14527, epoch: 164, loss: 0.333626
global_step: 14528, epoch: 164, loss: 0.227605
global_step: 14529, epoch: 164, loss: 0.232598
global_step: 14530, epoch: 164, loss: 0.279242
global_step: 14531, epoch: 164, loss: 0.243028
global_step: 14532, epoch: 164, loss: 0.272189
global_step: 14533, epoch: 164, loss: 0.302493
global_step: 14534, epoch: 164, loss: 0.294885
global_step: 14535, epoch: 164, loss: 0.306460
global_step: 14536, epoch: 164, loss: 0.313147
global_step: 14537, epoch: 164, loss: 0.289166
global_step: 14538, epoch: 164, loss: 0.335493
global_step: 14539, epoch: 164, loss: 0.322176
global_step: 14540, epoch: 164, loss: 0.334446
global_step: 14541, epoch: 164, loss: 0.241422
global_step: 14542, epoch: 164, loss: 0.234266
global_step: 14543, epoch: 164, loss: 0.267961
global_step: 14544, epoch: 164, loss: 0.276276
global_step: 14545, epoch: 164, loss: 0.344825
global_step: 14546, epoch: 164, loss: 0.285632
global_step: 14547, epoch: 164, loss: 0.259364
global_step: 14548, epoch: 164, loss: 0.281161
global_step: 14549, epoch: 164, loss: 0.268362
global_step: 14550, epoch: 164, loss: 0.255366
global_step: 14551, epoch: 164, loss: 0.306707
global_step: 14552, epoch: 164, loss: 0.294989
global_step: 14553, epoch: 164, loss: 0.244691
global_step: 14554, epoch: 164, loss: 0.263024
global_step: 14555, epoch: 164, loss: 0.337757
global_step: 14556, epoch: 164, loss: 0.254090
global_step: 14557, epoch: 164, loss: 0.317467
global_step: 14558, epoch: 164, loss: 0.341064
global_step: 14559, epoch: 164, loss: 0.394175
global_step: 14560, epoch: 164, loss: 0.346555
epoch: 164
train	acc: 0.9583	macro: p 0.9611, r 0.9210, f1: 0.9393	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9580
dev	acc: 0.5609	macro: p 0.4108, r 0.3498, f1: 0.3589	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5268
test	acc: 0.5946	macro: p 0.4123, r 0.3591, f1: 0.3702	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5694
global_step: 14561, epoch: 165, loss: 0.236921
global_step: 14562, epoch: 165, loss: 0.369225
global_step: 14563, epoch: 165, loss: 0.221818
global_step: 14564, epoch: 165, loss: 0.336696
global_step: 14565, epoch: 165, loss: 0.287623
global_step: 14566, epoch: 165, loss: 0.280799
global_step: 14567, epoch: 165, loss: 0.316027
global_step: 14568, epoch: 165, loss: 0.215764
global_step: 14569, epoch: 165, loss: 0.243272
global_step: 14570, epoch: 165, loss: 0.227513
global_step: 14571, epoch: 165, loss: 0.285223
global_step: 14572, epoch: 165, loss: 0.325793
global_step: 14573, epoch: 165, loss: 0.308247
global_step: 14574, epoch: 165, loss: 0.367839
global_step: 14575, epoch: 165, loss: 0.301027
global_step: 14576, epoch: 165, loss: 0.328463
global_step: 14577, epoch: 165, loss: 0.266844
global_step: 14578, epoch: 165, loss: 0.240666
global_step: 14579, epoch: 165, loss: 0.264416
global_step: 14580, epoch: 165, loss: 0.339102
global_step: 14581, epoch: 165, loss: 0.281243
global_step: 14582, epoch: 165, loss: 0.290921
global_step: 14583, epoch: 165, loss: 0.297389
global_step: 14584, epoch: 165, loss: 0.281891
global_step: 14585, epoch: 165, loss: 0.315699
global_step: 14586, epoch: 165, loss: 0.296092
global_step: 14587, epoch: 165, loss: 0.232905
global_step: 14588, epoch: 165, loss: 0.223065
global_step: 14589, epoch: 165, loss: 0.231401
global_step: 14590, epoch: 165, loss: 0.265440
global_step: 14591, epoch: 165, loss: 0.345068
global_step: 14592, epoch: 165, loss: 0.290921
global_step: 14593, epoch: 165, loss: 0.259429
global_step: 14594, epoch: 165, loss: 0.286688
global_step: 14595, epoch: 165, loss: 0.254922
global_step: 14596, epoch: 165, loss: 0.267899
global_step: 14597, epoch: 165, loss: 0.371762
global_step: 14598, epoch: 165, loss: 0.330781
global_step: 14599, epoch: 165, loss: 0.243273
global_step: 14600, epoch: 165, loss: 0.026031
epoch: 165
train	acc: 0.9563	macro: p 0.9595, r 0.9124, f1: 0.9325	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9558
dev	acc: 0.5546	macro: p 0.4223, r 0.3620, f1: 0.3699	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5289
test	acc: 0.5789	macro: p 0.4015, r 0.3595, f1: 0.3692	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5626
global_step: 14601, epoch: 166, loss: 0.235445
global_step: 14602, epoch: 166, loss: 0.278588
global_step: 14603, epoch: 166, loss: 0.285395
global_step: 14604, epoch: 166, loss: 0.252505
global_step: 14605, epoch: 166, loss: 0.289269
global_step: 14606, epoch: 166, loss: 0.261649
global_step: 14607, epoch: 166, loss: 0.337604
global_step: 14608, epoch: 166, loss: 0.278944
global_step: 14609, epoch: 166, loss: 0.317579
global_step: 14610, epoch: 166, loss: 0.303382
global_step: 14611, epoch: 166, loss: 0.291726
global_step: 14612, epoch: 166, loss: 0.298097
global_step: 14613, epoch: 166, loss: 0.290055
global_step: 14614, epoch: 166, loss: 0.254531
global_step: 14615, epoch: 166, loss: 0.291754
global_step: 14616, epoch: 166, loss: 0.334406
global_step: 14617, epoch: 166, loss: 0.283180
global_step: 14618, epoch: 166, loss: 0.245921
global_step: 14619, epoch: 166, loss: 0.263611
global_step: 14620, epoch: 166, loss: 0.285795
global_step: 14621, epoch: 166, loss: 0.308701
global_step: 14622, epoch: 166, loss: 0.318966
global_step: 14623, epoch: 166, loss: 0.269239
global_step: 14624, epoch: 166, loss: 0.215340
global_step: 14625, epoch: 166, loss: 0.335578
global_step: 14626, epoch: 166, loss: 0.338508
global_step: 14627, epoch: 166, loss: 0.319049
global_step: 14628, epoch: 166, loss: 0.294826
global_step: 14629, epoch: 166, loss: 0.208164
global_step: 14630, epoch: 166, loss: 0.302941
global_step: 14631, epoch: 166, loss: 0.298888
global_step: 14632, epoch: 166, loss: 0.304269
global_step: 14633, epoch: 166, loss: 0.315215
global_step: 14634, epoch: 166, loss: 0.380805
global_step: 14635, epoch: 166, loss: 0.272017
global_step: 14636, epoch: 166, loss: 0.283846
global_step: 14637, epoch: 166, loss: 0.297098
global_step: 14638, epoch: 166, loss: 0.315774
global_step: 14639, epoch: 166, loss: 0.298134
global_step: 14640, epoch: 166, loss: 0.214731
epoch: 166
train	acc: 0.9541	macro: p 0.9605, r 0.9109, f1: 0.9330	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9538
dev	acc: 0.5636	macro: p 0.4269, r 0.3507, f1: 0.3644	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5305
test	acc: 0.5989	macro: p 0.4222, r 0.3591, f1: 0.3742	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5728
global_step: 14641, epoch: 167, loss: 0.330766
global_step: 14642, epoch: 167, loss: 0.256258
global_step: 14643, epoch: 167, loss: 0.343752
global_step: 14644, epoch: 167, loss: 0.267720
global_step: 14645, epoch: 167, loss: 0.287265
global_step: 14646, epoch: 167, loss: 0.248309
global_step: 14647, epoch: 167, loss: 0.325119
global_step: 14648, epoch: 167, loss: 0.293976
global_step: 14649, epoch: 167, loss: 0.306025
global_step: 14650, epoch: 167, loss: 0.246118
global_step: 14651, epoch: 167, loss: 0.201802
global_step: 14652, epoch: 167, loss: 0.295698
global_step: 14653, epoch: 167, loss: 0.302315
global_step: 14654, epoch: 167, loss: 0.246922
global_step: 14655, epoch: 167, loss: 0.295470
global_step: 14656, epoch: 167, loss: 0.289474
global_step: 14657, epoch: 167, loss: 0.297069
global_step: 14658, epoch: 167, loss: 0.287179
global_step: 14659, epoch: 167, loss: 0.264211
global_step: 14660, epoch: 167, loss: 0.253447
global_step: 14661, epoch: 167, loss: 0.286018
global_step: 14662, epoch: 167, loss: 0.329917
global_step: 14663, epoch: 167, loss: 0.274791
global_step: 14664, epoch: 167, loss: 0.335220
global_step: 14665, epoch: 167, loss: 0.186225
global_step: 14666, epoch: 167, loss: 0.345566
global_step: 14667, epoch: 167, loss: 0.244532
global_step: 14668, epoch: 167, loss: 0.246594
global_step: 14669, epoch: 167, loss: 0.336838
global_step: 14670, epoch: 167, loss: 0.307446
global_step: 14671, epoch: 167, loss: 0.255885
global_step: 14672, epoch: 167, loss: 0.209132
global_step: 14673, epoch: 167, loss: 0.303353
global_step: 14674, epoch: 167, loss: 0.282079
global_step: 14675, epoch: 167, loss: 0.310647
global_step: 14676, epoch: 167, loss: 0.251048
global_step: 14677, epoch: 167, loss: 0.252848
global_step: 14678, epoch: 167, loss: 0.355320
global_step: 14679, epoch: 167, loss: 0.299006
global_step: 14680, epoch: 167, loss: 0.010337
epoch: 167
train	acc: 0.9571	macro: p 0.9624, r 0.9147, f1: 0.9358	micro: p 0.9571, r 0.9571, f1 0.9571	weighted_f1:0.9567
dev	acc: 0.5591	macro: p 0.4550, r 0.3526, f1: 0.3639	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5261
test	acc: 0.5962	macro: p 0.4110, r 0.3549, f1: 0.3667	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5705
global_step: 14681, epoch: 168, loss: 0.250967
global_step: 14682, epoch: 168, loss: 0.285283
global_step: 14683, epoch: 168, loss: 0.247201
global_step: 14684, epoch: 168, loss: 0.368875
global_step: 14685, epoch: 168, loss: 0.316285
global_step: 14686, epoch: 168, loss: 0.309085
global_step: 14687, epoch: 168, loss: 0.344422
global_step: 14688, epoch: 168, loss: 0.278049
global_step: 14689, epoch: 168, loss: 0.288537
global_step: 14690, epoch: 168, loss: 0.314195
global_step: 14691, epoch: 168, loss: 0.307659
global_step: 14692, epoch: 168, loss: 0.277588
global_step: 14693, epoch: 168, loss: 0.295702
global_step: 14694, epoch: 168, loss: 0.224484
global_step: 14695, epoch: 168, loss: 0.239809
global_step: 14696, epoch: 168, loss: 0.324869
global_step: 14697, epoch: 168, loss: 0.268417
global_step: 14698, epoch: 168, loss: 0.257930
global_step: 14699, epoch: 168, loss: 0.240094
global_step: 14700, epoch: 168, loss: 0.258048
global_step: 14701, epoch: 168, loss: 0.246250
global_step: 14702, epoch: 168, loss: 0.269137
global_step: 14703, epoch: 168, loss: 0.252250
global_step: 14704, epoch: 168, loss: 0.265358
global_step: 14705, epoch: 168, loss: 0.333663
global_step: 14706, epoch: 168, loss: 0.284729
global_step: 14707, epoch: 168, loss: 0.266019
global_step: 14708, epoch: 168, loss: 0.255008
global_step: 14709, epoch: 168, loss: 0.271229
global_step: 14710, epoch: 168, loss: 0.251032
global_step: 14711, epoch: 168, loss: 0.318513
global_step: 14712, epoch: 168, loss: 0.318037
global_step: 14713, epoch: 168, loss: 0.309522
global_step: 14714, epoch: 168, loss: 0.272100
global_step: 14715, epoch: 168, loss: 0.292842
global_step: 14716, epoch: 168, loss: 0.314620
global_step: 14717, epoch: 168, loss: 0.318523
global_step: 14718, epoch: 168, loss: 0.280479
global_step: 14719, epoch: 168, loss: 0.255310
global_step: 14720, epoch: 168, loss: 0.441346
epoch: 168
train	acc: 0.9547	macro: p 0.9567, r 0.9125, f1: 0.9313	micro: p 0.9547, r 0.9547, f1 0.9547	weighted_f1:0.9543
dev	acc: 0.5528	macro: p 0.4492, r 0.3609, f1: 0.3642	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5271
test	acc: 0.5728	macro: p 0.3963, r 0.3630, f1: 0.3670	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5594
global_step: 14721, epoch: 169, loss: 0.242910
global_step: 14722, epoch: 169, loss: 0.268477
global_step: 14723, epoch: 169, loss: 0.212550
global_step: 14724, epoch: 169, loss: 0.293738
global_step: 14725, epoch: 169, loss: 0.270361
global_step: 14726, epoch: 169, loss: 0.282023
global_step: 14727, epoch: 169, loss: 0.300227
global_step: 14728, epoch: 169, loss: 0.259658
global_step: 14729, epoch: 169, loss: 0.275280
global_step: 14730, epoch: 169, loss: 0.283425
global_step: 14731, epoch: 169, loss: 0.339125
global_step: 14732, epoch: 169, loss: 0.333190
global_step: 14733, epoch: 169, loss: 0.297861
global_step: 14734, epoch: 169, loss: 0.277672
global_step: 14735, epoch: 169, loss: 0.296529
global_step: 14736, epoch: 169, loss: 0.311066
global_step: 14737, epoch: 169, loss: 0.272898
global_step: 14738, epoch: 169, loss: 0.280657
global_step: 14739, epoch: 169, loss: 0.296514
global_step: 14740, epoch: 169, loss: 0.335076
global_step: 14741, epoch: 169, loss: 0.261092
global_step: 14742, epoch: 169, loss: 0.300531
global_step: 14743, epoch: 169, loss: 0.256729
global_step: 14744, epoch: 169, loss: 0.237816
global_step: 14745, epoch: 169, loss: 0.250311
global_step: 14746, epoch: 169, loss: 0.269705
global_step: 14747, epoch: 169, loss: 0.321884
global_step: 14748, epoch: 169, loss: 0.337994
global_step: 14749, epoch: 169, loss: 0.243621
global_step: 14750, epoch: 169, loss: 0.270449
global_step: 14751, epoch: 169, loss: 0.303655
global_step: 14752, epoch: 169, loss: 0.258632
global_step: 14753, epoch: 169, loss: 0.243760
global_step: 14754, epoch: 169, loss: 0.375352
global_step: 14755, epoch: 169, loss: 0.243927
global_step: 14756, epoch: 169, loss: 0.347133
global_step: 14757, epoch: 169, loss: 0.314145
global_step: 14758, epoch: 169, loss: 0.220146
global_step: 14759, epoch: 169, loss: 0.288892
global_step: 14760, epoch: 169, loss: 1.141874
epoch: 169
train	acc: 0.9573	macro: p 0.9624, r 0.9215, f1: 0.9406	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9570
dev	acc: 0.5537	macro: p 0.4149, r 0.3477, f1: 0.3624	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5194
test	acc: 0.5900	macro: p 0.4028, r 0.3480, f1: 0.3644	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5617
global_step: 14761, epoch: 170, loss: 0.300952
global_step: 14762, epoch: 170, loss: 0.239196
global_step: 14763, epoch: 170, loss: 0.271203
global_step: 14764, epoch: 170, loss: 0.262766
global_step: 14765, epoch: 170, loss: 0.215973
global_step: 14766, epoch: 170, loss: 0.247196
global_step: 14767, epoch: 170, loss: 0.296266
global_step: 14768, epoch: 170, loss: 0.348855
global_step: 14769, epoch: 170, loss: 0.262972
global_step: 14770, epoch: 170, loss: 0.277790
global_step: 14771, epoch: 170, loss: 0.259588
global_step: 14772, epoch: 170, loss: 0.265155
global_step: 14773, epoch: 170, loss: 0.285188
global_step: 14774, epoch: 170, loss: 0.289400
global_step: 14775, epoch: 170, loss: 0.264430
global_step: 14776, epoch: 170, loss: 0.236531
global_step: 14777, epoch: 170, loss: 0.271035
global_step: 14778, epoch: 170, loss: 0.272151
global_step: 14779, epoch: 170, loss: 0.242863
global_step: 14780, epoch: 170, loss: 0.310631
global_step: 14781, epoch: 170, loss: 0.327767
global_step: 14782, epoch: 170, loss: 0.265779
global_step: 14783, epoch: 170, loss: 0.283502
global_step: 14784, epoch: 170, loss: 0.239344
global_step: 14785, epoch: 170, loss: 0.280594
global_step: 14786, epoch: 170, loss: 0.259808
global_step: 14787, epoch: 170, loss: 0.277602
global_step: 14788, epoch: 170, loss: 0.342174
global_step: 14789, epoch: 170, loss: 0.289125
global_step: 14790, epoch: 170, loss: 0.240821
global_step: 14791, epoch: 170, loss: 0.215927
global_step: 14792, epoch: 170, loss: 0.304367
global_step: 14793, epoch: 170, loss: 0.251845
global_step: 14794, epoch: 170, loss: 0.311793
global_step: 14795, epoch: 170, loss: 0.300531
global_step: 14796, epoch: 170, loss: 0.282417
global_step: 14797, epoch: 170, loss: 0.232857
global_step: 14798, epoch: 170, loss: 0.333762
global_step: 14799, epoch: 170, loss: 0.276094
global_step: 14800, epoch: 170, loss: 0.224905
epoch: 170
train	acc: 0.9587	macro: p 0.9607, r 0.9256, f1: 0.9417	micro: p 0.9587, r 0.9587, f1 0.9587	weighted_f1:0.9585
dev	acc: 0.5582	macro: p 0.4090, r 0.3678, f1: 0.3778	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5354
test	acc: 0.5847	macro: p 0.4012, r 0.3729, f1: 0.3814	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5709
global_step: 14801, epoch: 171, loss: 0.313312
global_step: 14802, epoch: 171, loss: 0.271569
global_step: 14803, epoch: 171, loss: 0.259183
global_step: 14804, epoch: 171, loss: 0.311200
global_step: 14805, epoch: 171, loss: 0.312673
global_step: 14806, epoch: 171, loss: 0.165668
global_step: 14807, epoch: 171, loss: 0.325341
global_step: 14808, epoch: 171, loss: 0.318968
global_step: 14809, epoch: 171, loss: 0.303091
global_step: 14810, epoch: 171, loss: 0.231184
global_step: 14811, epoch: 171, loss: 0.326657
global_step: 14812, epoch: 171, loss: 0.283225
global_step: 14813, epoch: 171, loss: 0.355228
global_step: 14814, epoch: 171, loss: 0.322441
global_step: 14815, epoch: 171, loss: 0.305434
global_step: 14816, epoch: 171, loss: 0.178890
global_step: 14817, epoch: 171, loss: 0.319079
global_step: 14818, epoch: 171, loss: 0.274120
global_step: 14819, epoch: 171, loss: 0.221914
global_step: 14820, epoch: 171, loss: 0.284501
global_step: 14821, epoch: 171, loss: 0.325058
global_step: 14822, epoch: 171, loss: 0.268850
global_step: 14823, epoch: 171, loss: 0.222364
global_step: 14824, epoch: 171, loss: 0.246066
global_step: 14825, epoch: 171, loss: 0.260883
global_step: 14826, epoch: 171, loss: 0.269658
global_step: 14827, epoch: 171, loss: 0.247745
global_step: 14828, epoch: 171, loss: 0.306405
global_step: 14829, epoch: 171, loss: 0.372943
global_step: 14830, epoch: 171, loss: 0.298846
global_step: 14831, epoch: 171, loss: 0.239302
global_step: 14832, epoch: 171, loss: 0.199328
global_step: 14833, epoch: 171, loss: 0.192516
global_step: 14834, epoch: 171, loss: 0.307074
global_step: 14835, epoch: 171, loss: 0.221578
global_step: 14836, epoch: 171, loss: 0.280807
global_step: 14837, epoch: 171, loss: 0.291299
global_step: 14838, epoch: 171, loss: 0.259270
global_step: 14839, epoch: 171, loss: 0.298046
global_step: 14840, epoch: 171, loss: 0.204963
epoch: 171
train	acc: 0.9594	macro: p 0.9575, r 0.9323, f1: 0.9440	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9593
dev	acc: 0.5591	macro: p 0.4067, r 0.3719, f1: 0.3808	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5368
test	acc: 0.5862	macro: p 0.4114, r 0.3815, f1: 0.3907	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5737
global_step: 14841, epoch: 172, loss: 0.258307
global_step: 14842, epoch: 172, loss: 0.282597
global_step: 14843, epoch: 172, loss: 0.252028
global_step: 14844, epoch: 172, loss: 0.259273
global_step: 14845, epoch: 172, loss: 0.337741
global_step: 14846, epoch: 172, loss: 0.326897
global_step: 14847, epoch: 172, loss: 0.293303
global_step: 14848, epoch: 172, loss: 0.205050
global_step: 14849, epoch: 172, loss: 0.249746
global_step: 14850, epoch: 172, loss: 0.286363
global_step: 14851, epoch: 172, loss: 0.307736
global_step: 14852, epoch: 172, loss: 0.261990
global_step: 14853, epoch: 172, loss: 0.355609
global_step: 14854, epoch: 172, loss: 0.208395
global_step: 14855, epoch: 172, loss: 0.278513
global_step: 14856, epoch: 172, loss: 0.240586
global_step: 14857, epoch: 172, loss: 0.266030
global_step: 14858, epoch: 172, loss: 0.241680
global_step: 14859, epoch: 172, loss: 0.262939
global_step: 14860, epoch: 172, loss: 0.278412
global_step: 14861, epoch: 172, loss: 0.284876
global_step: 14862, epoch: 172, loss: 0.332825
global_step: 14863, epoch: 172, loss: 0.336542
global_step: 14864, epoch: 172, loss: 0.263449
global_step: 14865, epoch: 172, loss: 0.253651
global_step: 14866, epoch: 172, loss: 0.243761
global_step: 14867, epoch: 172, loss: 0.304740
global_step: 14868, epoch: 172, loss: 0.232595
global_step: 14869, epoch: 172, loss: 0.286855
global_step: 14870, epoch: 172, loss: 0.251241
global_step: 14871, epoch: 172, loss: 0.359881
global_step: 14872, epoch: 172, loss: 0.304251
global_step: 14873, epoch: 172, loss: 0.274290
global_step: 14874, epoch: 172, loss: 0.269154
global_step: 14875, epoch: 172, loss: 0.297849
global_step: 14876, epoch: 172, loss: 0.297703
global_step: 14877, epoch: 172, loss: 0.351807
global_step: 14878, epoch: 172, loss: 0.263944
global_step: 14879, epoch: 172, loss: 0.262051
global_step: 14880, epoch: 172, loss: 0.022560
epoch: 172
train	acc: 0.9605	macro: p 0.9625, r 0.9247, f1: 0.9418	micro: p 0.9605, r 0.9605, f1 0.9605	weighted_f1:0.9602
dev	acc: 0.5618	macro: p 0.4327, r 0.3573, f1: 0.3646	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5332
test	acc: 0.5874	macro: p 0.4023, r 0.3612, f1: 0.3708	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5680
global_step: 14881, epoch: 173, loss: 0.211147
global_step: 14882, epoch: 173, loss: 0.244960
global_step: 14883, epoch: 173, loss: 0.327169
global_step: 14884, epoch: 173, loss: 0.240340
global_step: 14885, epoch: 173, loss: 0.175575
global_step: 14886, epoch: 173, loss: 0.243735
global_step: 14887, epoch: 173, loss: 0.293593
global_step: 14888, epoch: 173, loss: 0.254612
global_step: 14889, epoch: 173, loss: 0.293974
global_step: 14890, epoch: 173, loss: 0.305007
global_step: 14891, epoch: 173, loss: 0.280825
global_step: 14892, epoch: 173, loss: 0.284053
global_step: 14893, epoch: 173, loss: 0.268018
global_step: 14894, epoch: 173, loss: 0.233074
global_step: 14895, epoch: 173, loss: 0.273410
global_step: 14896, epoch: 173, loss: 0.328632
global_step: 14897, epoch: 173, loss: 0.297481
global_step: 14898, epoch: 173, loss: 0.211203
global_step: 14899, epoch: 173, loss: 0.280138
global_step: 14900, epoch: 173, loss: 0.307220
global_step: 14901, epoch: 173, loss: 0.287593
global_step: 14902, epoch: 173, loss: 0.278285
global_step: 14903, epoch: 173, loss: 0.250160
global_step: 14904, epoch: 173, loss: 0.269275
global_step: 14905, epoch: 173, loss: 0.317330
global_step: 14906, epoch: 173, loss: 0.338214
global_step: 14907, epoch: 173, loss: 0.303230
global_step: 14908, epoch: 173, loss: 0.312321
global_step: 14909, epoch: 173, loss: 0.322757
global_step: 14910, epoch: 173, loss: 0.254703
global_step: 14911, epoch: 173, loss: 0.253959
global_step: 14912, epoch: 173, loss: 0.326547
global_step: 14913, epoch: 173, loss: 0.281614
global_step: 14914, epoch: 173, loss: 0.236930
global_step: 14915, epoch: 173, loss: 0.245454
global_step: 14916, epoch: 173, loss: 0.278564
global_step: 14917, epoch: 173, loss: 0.274714
global_step: 14918, epoch: 173, loss: 0.269350
global_step: 14919, epoch: 173, loss: 0.286002
global_step: 14920, epoch: 173, loss: 0.029029
epoch: 173
train	acc: 0.9576	macro: p 0.9614, r 0.9161, f1: 0.9361	micro: p 0.9576, r 0.9576, f1 0.9576	weighted_f1:0.9572
dev	acc: 0.5618	macro: p 0.4577, r 0.3513, f1: 0.3579	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5272
test	acc: 0.5897	macro: p 0.4174, r 0.3535, f1: 0.3642	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5646
global_step: 14921, epoch: 174, loss: 0.306354
global_step: 14922, epoch: 174, loss: 0.266695
global_step: 14923, epoch: 174, loss: 0.246922
global_step: 14924, epoch: 174, loss: 0.245099
global_step: 14925, epoch: 174, loss: 0.276769
global_step: 14926, epoch: 174, loss: 0.292287
global_step: 14927, epoch: 174, loss: 0.218574
global_step: 14928, epoch: 174, loss: 0.267390
global_step: 14929, epoch: 174, loss: 0.256969
global_step: 14930, epoch: 174, loss: 0.202690
global_step: 14931, epoch: 174, loss: 0.237809
global_step: 14932, epoch: 174, loss: 0.289392
global_step: 14933, epoch: 174, loss: 0.301313
global_step: 14934, epoch: 174, loss: 0.251903
global_step: 14935, epoch: 174, loss: 0.351101
global_step: 14936, epoch: 174, loss: 0.312466
global_step: 14937, epoch: 174, loss: 0.254415
global_step: 14938, epoch: 174, loss: 0.242907
global_step: 14939, epoch: 174, loss: 0.258997
global_step: 14940, epoch: 174, loss: 0.268804
global_step: 14941, epoch: 174, loss: 0.310778
global_step: 14942, epoch: 174, loss: 0.282430
global_step: 14943, epoch: 174, loss: 0.288564
global_step: 14944, epoch: 174, loss: 0.206136
global_step: 14945, epoch: 174, loss: 0.228169
global_step: 14946, epoch: 174, loss: 0.300254
global_step: 14947, epoch: 174, loss: 0.344624
global_step: 14948, epoch: 174, loss: 0.362960
global_step: 14949, epoch: 174, loss: 0.301016
global_step: 14950, epoch: 174, loss: 0.333676
global_step: 14951, epoch: 174, loss: 0.270070
global_step: 14952, epoch: 174, loss: 0.319454
global_step: 14953, epoch: 174, loss: 0.307849
global_step: 14954, epoch: 174, loss: 0.281691
global_step: 14955, epoch: 174, loss: 0.268553
global_step: 14956, epoch: 174, loss: 0.311539
global_step: 14957, epoch: 174, loss: 0.261132
global_step: 14958, epoch: 174, loss: 0.243461
global_step: 14959, epoch: 174, loss: 0.384405
global_step: 14960, epoch: 174, loss: 0.197959
epoch: 174
train	acc: 0.9612	macro: p 0.9638, r 0.9309, f1: 0.9460	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9610
dev	acc: 0.5600	macro: p 0.4439, r 0.3738, f1: 0.3866	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5368
test	acc: 0.5831	macro: p 0.4064, r 0.3664, f1: 0.3756	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5666
global_step: 14961, epoch: 175, loss: 0.349963
global_step: 14962, epoch: 175, loss: 0.231866
global_step: 14963, epoch: 175, loss: 0.263192
global_step: 14964, epoch: 175, loss: 0.321410
global_step: 14965, epoch: 175, loss: 0.282196
global_step: 14966, epoch: 175, loss: 0.191252
global_step: 14967, epoch: 175, loss: 0.316314
global_step: 14968, epoch: 175, loss: 0.272276
global_step: 14969, epoch: 175, loss: 0.249579
global_step: 14970, epoch: 175, loss: 0.248255
global_step: 14971, epoch: 175, loss: 0.270950
global_step: 14972, epoch: 175, loss: 0.218570
global_step: 14973, epoch: 175, loss: 0.283455
global_step: 14974, epoch: 175, loss: 0.262194
global_step: 14975, epoch: 175, loss: 0.222397
global_step: 14976, epoch: 175, loss: 0.233635
global_step: 14977, epoch: 175, loss: 0.299597
global_step: 14978, epoch: 175, loss: 0.331477
global_step: 14979, epoch: 175, loss: 0.264499
global_step: 14980, epoch: 175, loss: 0.243970
global_step: 14981, epoch: 175, loss: 0.222892
global_step: 14982, epoch: 175, loss: 0.297500
global_step: 14983, epoch: 175, loss: 0.274075
global_step: 14984, epoch: 175, loss: 0.322058
global_step: 14985, epoch: 175, loss: 0.267635
global_step: 14986, epoch: 175, loss: 0.279290
global_step: 14987, epoch: 175, loss: 0.271633
global_step: 14988, epoch: 175, loss: 0.304740
global_step: 14989, epoch: 175, loss: 0.273776
global_step: 14990, epoch: 175, loss: 0.293262
global_step: 14991, epoch: 175, loss: 0.254802
global_step: 14992, epoch: 175, loss: 0.236520
global_step: 14993, epoch: 175, loss: 0.193914
global_step: 14994, epoch: 175, loss: 0.315597
global_step: 14995, epoch: 175, loss: 0.314877
global_step: 14996, epoch: 175, loss: 0.323902
global_step: 14997, epoch: 175, loss: 0.341865
global_step: 14998, epoch: 175, loss: 0.235879
global_step: 14999, epoch: 175, loss: 0.355692
global_step: 15000, epoch: 175, loss: 0.471016
epoch: 175
train	acc: 0.9606	macro: p 0.9627, r 0.9269, f1: 0.9432	micro: p 0.9606, r 0.9606, f1 0.9606	weighted_f1:0.9603
dev	acc: 0.5573	macro: p 0.4240, r 0.3526, f1: 0.3620	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5271
test	acc: 0.5881	macro: p 0.4143, r 0.3577, f1: 0.3710	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5657
global_step: 15001, epoch: 176, loss: 0.229324
global_step: 15002, epoch: 176, loss: 0.234944
global_step: 15003, epoch: 176, loss: 0.281546
global_step: 15004, epoch: 176, loss: 0.286475
global_step: 15005, epoch: 176, loss: 0.267707
global_step: 15006, epoch: 176, loss: 0.288164
global_step: 15007, epoch: 176, loss: 0.256972
global_step: 15008, epoch: 176, loss: 0.219880
global_step: 15009, epoch: 176, loss: 0.328119
global_step: 15010, epoch: 176, loss: 0.264836
global_step: 15011, epoch: 176, loss: 0.267275
global_step: 15012, epoch: 176, loss: 0.266071
global_step: 15013, epoch: 176, loss: 0.247411
global_step: 15014, epoch: 176, loss: 0.345984
global_step: 15015, epoch: 176, loss: 0.224286
global_step: 15016, epoch: 176, loss: 0.281329
global_step: 15017, epoch: 176, loss: 0.198487
global_step: 15018, epoch: 176, loss: 0.232455
global_step: 15019, epoch: 176, loss: 0.309877
global_step: 15020, epoch: 176, loss: 0.215582
global_step: 15021, epoch: 176, loss: 0.300835
global_step: 15022, epoch: 176, loss: 0.273657
global_step: 15023, epoch: 176, loss: 0.303038
global_step: 15024, epoch: 176, loss: 0.333925
global_step: 15025, epoch: 176, loss: 0.207350
global_step: 15026, epoch: 176, loss: 0.295041
global_step: 15027, epoch: 176, loss: 0.302394
global_step: 15028, epoch: 176, loss: 0.237617
global_step: 15029, epoch: 176, loss: 0.217904
global_step: 15030, epoch: 176, loss: 0.229994
global_step: 15031, epoch: 176, loss: 0.288050
global_step: 15032, epoch: 176, loss: 0.234963
global_step: 15033, epoch: 176, loss: 0.221330
global_step: 15034, epoch: 176, loss: 0.262165
global_step: 15035, epoch: 176, loss: 0.284090
global_step: 15036, epoch: 176, loss: 0.278896
global_step: 15037, epoch: 176, loss: 0.304222
global_step: 15038, epoch: 176, loss: 0.232224
global_step: 15039, epoch: 176, loss: 0.335792
global_step: 15040, epoch: 176, loss: 0.323053
epoch: 176
train	acc: 0.9603	macro: p 0.9614, r 0.9326, f1: 0.9463	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9601
dev	acc: 0.5609	macro: p 0.4099, r 0.3579, f1: 0.3716	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5319
test	acc: 0.5870	macro: p 0.4057, r 0.3608, f1: 0.3751	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5657
global_step: 15041, epoch: 177, loss: 0.257692
global_step: 15042, epoch: 177, loss: 0.266111
global_step: 15043, epoch: 177, loss: 0.304002
global_step: 15044, epoch: 177, loss: 0.213368
global_step: 15045, epoch: 177, loss: 0.337467
global_step: 15046, epoch: 177, loss: 0.238268
global_step: 15047, epoch: 177, loss: 0.273219
global_step: 15048, epoch: 177, loss: 0.275524
global_step: 15049, epoch: 177, loss: 0.211620
global_step: 15050, epoch: 177, loss: 0.235591
global_step: 15051, epoch: 177, loss: 0.249109
global_step: 15052, epoch: 177, loss: 0.291634
global_step: 15053, epoch: 177, loss: 0.229045
global_step: 15054, epoch: 177, loss: 0.236813
global_step: 15055, epoch: 177, loss: 0.236077
global_step: 15056, epoch: 177, loss: 0.202902
global_step: 15057, epoch: 177, loss: 0.310663
global_step: 15058, epoch: 177, loss: 0.274732
global_step: 15059, epoch: 177, loss: 0.178424
global_step: 15060, epoch: 177, loss: 0.254250
global_step: 15061, epoch: 177, loss: 0.266261
global_step: 15062, epoch: 177, loss: 0.258475
global_step: 15063, epoch: 177, loss: 0.245044
global_step: 15064, epoch: 177, loss: 0.308428
global_step: 15065, epoch: 177, loss: 0.243463
global_step: 15066, epoch: 177, loss: 0.327228
global_step: 15067, epoch: 177, loss: 0.250763
global_step: 15068, epoch: 177, loss: 0.238946
global_step: 15069, epoch: 177, loss: 0.285361
global_step: 15070, epoch: 177, loss: 0.236237
global_step: 15071, epoch: 177, loss: 0.281169
global_step: 15072, epoch: 177, loss: 0.248076
global_step: 15073, epoch: 177, loss: 0.229219
global_step: 15074, epoch: 177, loss: 0.242821
global_step: 15075, epoch: 177, loss: 0.281921
global_step: 15076, epoch: 177, loss: 0.340649
global_step: 15077, epoch: 177, loss: 0.229965
global_step: 15078, epoch: 177, loss: 0.201726
global_step: 15079, epoch: 177, loss: 0.243116
global_step: 15080, epoch: 177, loss: 0.302175
epoch: 177
train	acc: 0.9590	macro: p 0.9617, r 0.9258, f1: 0.9424	micro: p 0.9590, r 0.9590, f1 0.9590	weighted_f1:0.9588
dev	acc: 0.5672	macro: p 0.4303, r 0.3569, f1: 0.3674	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5318
test	acc: 0.5927	macro: p 0.4153, r 0.3584, f1: 0.3680	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5654
global_step: 15081, epoch: 178, loss: 0.293740
global_step: 15082, epoch: 178, loss: 0.250475
global_step: 15083, epoch: 178, loss: 0.319914
global_step: 15084, epoch: 178, loss: 0.196022
global_step: 15085, epoch: 178, loss: 0.220756
global_step: 15086, epoch: 178, loss: 0.228745
global_step: 15087, epoch: 178, loss: 0.249014
global_step: 15088, epoch: 178, loss: 0.279205
global_step: 15089, epoch: 178, loss: 0.319730
global_step: 15090, epoch: 178, loss: 0.304776
global_step: 15091, epoch: 178, loss: 0.209520
global_step: 15092, epoch: 178, loss: 0.294856
global_step: 15093, epoch: 178, loss: 0.210843
global_step: 15094, epoch: 178, loss: 0.234095
global_step: 15095, epoch: 178, loss: 0.181722
global_step: 15096, epoch: 178, loss: 0.309875
global_step: 15097, epoch: 178, loss: 0.272400
global_step: 15098, epoch: 178, loss: 0.283837
global_step: 15099, epoch: 178, loss: 0.208591
global_step: 15100, epoch: 178, loss: 0.285083
global_step: 15101, epoch: 178, loss: 0.248279
global_step: 15102, epoch: 178, loss: 0.279942
global_step: 15103, epoch: 178, loss: 0.251938
global_step: 15104, epoch: 178, loss: 0.272111
global_step: 15105, epoch: 178, loss: 0.342642
global_step: 15106, epoch: 178, loss: 0.200743
global_step: 15107, epoch: 178, loss: 0.217747
global_step: 15108, epoch: 178, loss: 0.324423
global_step: 15109, epoch: 178, loss: 0.270622
global_step: 15110, epoch: 178, loss: 0.271562
global_step: 15111, epoch: 178, loss: 0.302725
global_step: 15112, epoch: 178, loss: 0.289335
global_step: 15113, epoch: 178, loss: 0.279823
global_step: 15114, epoch: 178, loss: 0.281374
global_step: 15115, epoch: 178, loss: 0.203912
global_step: 15116, epoch: 178, loss: 0.245622
global_step: 15117, epoch: 178, loss: 0.284591
global_step: 15118, epoch: 178, loss: 0.281814
global_step: 15119, epoch: 178, loss: 0.229393
global_step: 15120, epoch: 178, loss: 0.180499
epoch: 178
train	acc: 0.9619	macro: p 0.9624, r 0.9330, f1: 0.9469	micro: p 0.9619, r 0.9619, f1 0.9619	weighted_f1:0.9617
dev	acc: 0.5600	macro: p 0.4076, r 0.3497, f1: 0.3623	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5273
test	acc: 0.5927	macro: p 0.4148, r 0.3602, f1: 0.3755	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5697
global_step: 15121, epoch: 179, loss: 0.252960
global_step: 15122, epoch: 179, loss: 0.225649
global_step: 15123, epoch: 179, loss: 0.264394
global_step: 15124, epoch: 179, loss: 0.173676
global_step: 15125, epoch: 179, loss: 0.253948
global_step: 15126, epoch: 179, loss: 0.310344
global_step: 15127, epoch: 179, loss: 0.259629
global_step: 15128, epoch: 179, loss: 0.273806
global_step: 15129, epoch: 179, loss: 0.267913
global_step: 15130, epoch: 179, loss: 0.274626
global_step: 15131, epoch: 179, loss: 0.269208
global_step: 15132, epoch: 179, loss: 0.262070
global_step: 15133, epoch: 179, loss: 0.247353
global_step: 15134, epoch: 179, loss: 0.286862
global_step: 15135, epoch: 179, loss: 0.213623
global_step: 15136, epoch: 179, loss: 0.318507
global_step: 15137, epoch: 179, loss: 0.235841
global_step: 15138, epoch: 179, loss: 0.233675
global_step: 15139, epoch: 179, loss: 0.299091
global_step: 15140, epoch: 179, loss: 0.277410
global_step: 15141, epoch: 179, loss: 0.237687
global_step: 15142, epoch: 179, loss: 0.236521
global_step: 15143, epoch: 179, loss: 0.227381
global_step: 15144, epoch: 179, loss: 0.312778
global_step: 15145, epoch: 179, loss: 0.262822
global_step: 15146, epoch: 179, loss: 0.304585
global_step: 15147, epoch: 179, loss: 0.332325
global_step: 15148, epoch: 179, loss: 0.246923
global_step: 15149, epoch: 179, loss: 0.232674
global_step: 15150, epoch: 179, loss: 0.306811
global_step: 15151, epoch: 179, loss: 0.306554
global_step: 15152, epoch: 179, loss: 0.268859
global_step: 15153, epoch: 179, loss: 0.240049
global_step: 15154, epoch: 179, loss: 0.224052
global_step: 15155, epoch: 179, loss: 0.294259
global_step: 15156, epoch: 179, loss: 0.206449
global_step: 15157, epoch: 179, loss: 0.202270
global_step: 15158, epoch: 179, loss: 0.326824
global_step: 15159, epoch: 179, loss: 0.328449
global_step: 15160, epoch: 179, loss: 0.191068
epoch: 179
train	acc: 0.9557	macro: p 0.9666, r 0.9163, f1: 0.9393	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9553
dev	acc: 0.5609	macro: p 0.4417, r 0.3404, f1: 0.3559	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5193
test	acc: 0.6011	macro: p 0.4166, r 0.3325, f1: 0.3469	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5599
global_step: 15161, epoch: 180, loss: 0.230134
global_step: 15162, epoch: 180, loss: 0.286313
global_step: 15163, epoch: 180, loss: 0.295507
global_step: 15164, epoch: 180, loss: 0.244965
global_step: 15165, epoch: 180, loss: 0.241855
global_step: 15166, epoch: 180, loss: 0.271376
global_step: 15167, epoch: 180, loss: 0.231376
global_step: 15168, epoch: 180, loss: 0.290346
global_step: 15169, epoch: 180, loss: 0.222573
global_step: 15170, epoch: 180, loss: 0.278364
global_step: 15171, epoch: 180, loss: 0.352629
global_step: 15172, epoch: 180, loss: 0.303092
global_step: 15173, epoch: 180, loss: 0.313109
global_step: 15174, epoch: 180, loss: 0.250115
global_step: 15175, epoch: 180, loss: 0.225644
global_step: 15176, epoch: 180, loss: 0.303088
global_step: 15177, epoch: 180, loss: 0.321052
global_step: 15178, epoch: 180, loss: 0.271114
global_step: 15179, epoch: 180, loss: 0.309705
global_step: 15180, epoch: 180, loss: 0.283861
global_step: 15181, epoch: 180, loss: 0.193363
global_step: 15182, epoch: 180, loss: 0.217267
global_step: 15183, epoch: 180, loss: 0.197113
global_step: 15184, epoch: 180, loss: 0.280891
global_step: 15185, epoch: 180, loss: 0.229852
global_step: 15186, epoch: 180, loss: 0.233097
global_step: 15187, epoch: 180, loss: 0.286899
global_step: 15188, epoch: 180, loss: 0.251693
global_step: 15189, epoch: 180, loss: 0.244606
global_step: 15190, epoch: 180, loss: 0.255009
global_step: 15191, epoch: 180, loss: 0.260264
global_step: 15192, epoch: 180, loss: 0.317340
global_step: 15193, epoch: 180, loss: 0.227148
global_step: 15194, epoch: 180, loss: 0.282316
global_step: 15195, epoch: 180, loss: 0.237962
global_step: 15196, epoch: 180, loss: 0.242796
global_step: 15197, epoch: 180, loss: 0.313444
global_step: 15198, epoch: 180, loss: 0.250669
global_step: 15199, epoch: 180, loss: 0.287809
global_step: 15200, epoch: 180, loss: 0.049108
epoch: 180
train	acc: 0.9589	macro: p 0.9660, r 0.9232, f1: 0.9425	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9586
dev	acc: 0.5708	macro: p 0.4761, r 0.3635, f1: 0.3767	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5359
test	acc: 0.5973	macro: p 0.4282, r 0.3525, f1: 0.3663	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5679
global_step: 15201, epoch: 181, loss: 0.248958
global_step: 15202, epoch: 181, loss: 0.259023
global_step: 15203, epoch: 181, loss: 0.285239
global_step: 15204, epoch: 181, loss: 0.197393
global_step: 15205, epoch: 181, loss: 0.229907
global_step: 15206, epoch: 181, loss: 0.221700
global_step: 15207, epoch: 181, loss: 0.287120
global_step: 15208, epoch: 181, loss: 0.219668
global_step: 15209, epoch: 181, loss: 0.302216
global_step: 15210, epoch: 181, loss: 0.230011
global_step: 15211, epoch: 181, loss: 0.194377
global_step: 15212, epoch: 181, loss: 0.242943
global_step: 15213, epoch: 181, loss: 0.224098
global_step: 15214, epoch: 181, loss: 0.229287
global_step: 15215, epoch: 181, loss: 0.244737
global_step: 15216, epoch: 181, loss: 0.233859
global_step: 15217, epoch: 181, loss: 0.308475
global_step: 15218, epoch: 181, loss: 0.301311
global_step: 15219, epoch: 181, loss: 0.329783
global_step: 15220, epoch: 181, loss: 0.293193
global_step: 15221, epoch: 181, loss: 0.223902
global_step: 15222, epoch: 181, loss: 0.362793
global_step: 15223, epoch: 181, loss: 0.205794
global_step: 15224, epoch: 181, loss: 0.285139
global_step: 15225, epoch: 181, loss: 0.256670
global_step: 15226, epoch: 181, loss: 0.255360
global_step: 15227, epoch: 181, loss: 0.234922
global_step: 15228, epoch: 181, loss: 0.242131
global_step: 15229, epoch: 181, loss: 0.260754
global_step: 15230, epoch: 181, loss: 0.226344
global_step: 15231, epoch: 181, loss: 0.307430
global_step: 15232, epoch: 181, loss: 0.295072
global_step: 15233, epoch: 181, loss: 0.203201
global_step: 15234, epoch: 181, loss: 0.302311
global_step: 15235, epoch: 181, loss: 0.243204
global_step: 15236, epoch: 181, loss: 0.189239
global_step: 15237, epoch: 181, loss: 0.259389
global_step: 15238, epoch: 181, loss: 0.227014
global_step: 15239, epoch: 181, loss: 0.218487
global_step: 15240, epoch: 181, loss: 0.900868
epoch: 181
train	acc: 0.9577	macro: p 0.9675, r 0.9223, f1: 0.9430	micro: p 0.9577, r 0.9577, f1 0.9577	weighted_f1:0.9574
dev	acc: 0.5609	macro: p 0.4382, r 0.3393, f1: 0.3535	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5192
test	acc: 0.6019	macro: p 0.4352, r 0.3411, f1: 0.3619	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5644
global_step: 15241, epoch: 182, loss: 0.269045
global_step: 15242, epoch: 182, loss: 0.237039
global_step: 15243, epoch: 182, loss: 0.293437
global_step: 15244, epoch: 182, loss: 0.225157
global_step: 15245, epoch: 182, loss: 0.236438
global_step: 15246, epoch: 182, loss: 0.291822
global_step: 15247, epoch: 182, loss: 0.240623
global_step: 15248, epoch: 182, loss: 0.219961
global_step: 15249, epoch: 182, loss: 0.283373
global_step: 15250, epoch: 182, loss: 0.202923
global_step: 15251, epoch: 182, loss: 0.233894
global_step: 15252, epoch: 182, loss: 0.244108
global_step: 15253, epoch: 182, loss: 0.294772
global_step: 15254, epoch: 182, loss: 0.289270
global_step: 15255, epoch: 182, loss: 0.295022
global_step: 15256, epoch: 182, loss: 0.243287
global_step: 15257, epoch: 182, loss: 0.194581
global_step: 15258, epoch: 182, loss: 0.190771
global_step: 15259, epoch: 182, loss: 0.277833
global_step: 15260, epoch: 182, loss: 0.290793
global_step: 15261, epoch: 182, loss: 0.246703
global_step: 15262, epoch: 182, loss: 0.229925
global_step: 15263, epoch: 182, loss: 0.306929
global_step: 15264, epoch: 182, loss: 0.269418
global_step: 15265, epoch: 182, loss: 0.282105
global_step: 15266, epoch: 182, loss: 0.290682
global_step: 15267, epoch: 182, loss: 0.303191
global_step: 15268, epoch: 182, loss: 0.241501
global_step: 15269, epoch: 182, loss: 0.214148
global_step: 15270, epoch: 182, loss: 0.298602
global_step: 15271, epoch: 182, loss: 0.289785
global_step: 15272, epoch: 182, loss: 0.192184
global_step: 15273, epoch: 182, loss: 0.274721
global_step: 15274, epoch: 182, loss: 0.278623
global_step: 15275, epoch: 182, loss: 0.369193
global_step: 15276, epoch: 182, loss: 0.227020
global_step: 15277, epoch: 182, loss: 0.252196
global_step: 15278, epoch: 182, loss: 0.166936
global_step: 15279, epoch: 182, loss: 0.268037
global_step: 15280, epoch: 182, loss: 0.845162
epoch: 182
train	acc: 0.9588	macro: p 0.9646, r 0.9213, f1: 0.9409	micro: p 0.9588, r 0.9588, f1 0.9588	weighted_f1:0.9585
dev	acc: 0.5609	macro: p 0.4360, r 0.3461, f1: 0.3536	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5228
test	acc: 0.5969	macro: p 0.4264, r 0.3474, f1: 0.3588	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5647
global_step: 15281, epoch: 183, loss: 0.320735
global_step: 15282, epoch: 183, loss: 0.261807
global_step: 15283, epoch: 183, loss: 0.256122
global_step: 15284, epoch: 183, loss: 0.209953
global_step: 15285, epoch: 183, loss: 0.201628
global_step: 15286, epoch: 183, loss: 0.286339
global_step: 15287, epoch: 183, loss: 0.303281
global_step: 15288, epoch: 183, loss: 0.260202
global_step: 15289, epoch: 183, loss: 0.237921
global_step: 15290, epoch: 183, loss: 0.284969
global_step: 15291, epoch: 183, loss: 0.240134
global_step: 15292, epoch: 183, loss: 0.298222
global_step: 15293, epoch: 183, loss: 0.201984
global_step: 15294, epoch: 183, loss: 0.260387
global_step: 15295, epoch: 183, loss: 0.183208
global_step: 15296, epoch: 183, loss: 0.185375
global_step: 15297, epoch: 183, loss: 0.288587
global_step: 15298, epoch: 183, loss: 0.202023
global_step: 15299, epoch: 183, loss: 0.299506
global_step: 15300, epoch: 183, loss: 0.294628
global_step: 15301, epoch: 183, loss: 0.258594
global_step: 15302, epoch: 183, loss: 0.291937
global_step: 15303, epoch: 183, loss: 0.237928
global_step: 15304, epoch: 183, loss: 0.253245
global_step: 15305, epoch: 183, loss: 0.282941
global_step: 15306, epoch: 183, loss: 0.232138
global_step: 15307, epoch: 183, loss: 0.281372
global_step: 15308, epoch: 183, loss: 0.334223
global_step: 15309, epoch: 183, loss: 0.217364
global_step: 15310, epoch: 183, loss: 0.288614
global_step: 15311, epoch: 183, loss: 0.313086
global_step: 15312, epoch: 183, loss: 0.299658
global_step: 15313, epoch: 183, loss: 0.151610
global_step: 15314, epoch: 183, loss: 0.247709
global_step: 15315, epoch: 183, loss: 0.273128
global_step: 15316, epoch: 183, loss: 0.228929
global_step: 15317, epoch: 183, loss: 0.231800
global_step: 15318, epoch: 183, loss: 0.223718
global_step: 15319, epoch: 183, loss: 0.365233
global_step: 15320, epoch: 183, loss: 0.430299
epoch: 183
train	acc: 0.9621	macro: p 0.9641, r 0.9332, f1: 0.9476	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9619
dev	acc: 0.5600	macro: p 0.4182, r 0.3533, f1: 0.3650	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5276
test	acc: 0.5885	macro: p 0.4149, r 0.3617, f1: 0.3777	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5663
global_step: 15321, epoch: 184, loss: 0.220069
global_step: 15322, epoch: 184, loss: 0.215531
global_step: 15323, epoch: 184, loss: 0.258878
global_step: 15324, epoch: 184, loss: 0.249804
global_step: 15325, epoch: 184, loss: 0.266914
global_step: 15326, epoch: 184, loss: 0.270585
global_step: 15327, epoch: 184, loss: 0.268603
global_step: 15328, epoch: 184, loss: 0.257493
global_step: 15329, epoch: 184, loss: 0.323240
global_step: 15330, epoch: 184, loss: 0.264037
global_step: 15331, epoch: 184, loss: 0.256535
global_step: 15332, epoch: 184, loss: 0.319110
global_step: 15333, epoch: 184, loss: 0.229978
global_step: 15334, epoch: 184, loss: 0.270851
global_step: 15335, epoch: 184, loss: 0.215884
global_step: 15336, epoch: 184, loss: 0.236242
global_step: 15337, epoch: 184, loss: 0.317327
global_step: 15338, epoch: 184, loss: 0.252731
global_step: 15339, epoch: 184, loss: 0.228704
global_step: 15340, epoch: 184, loss: 0.230520
global_step: 15341, epoch: 184, loss: 0.262547
global_step: 15342, epoch: 184, loss: 0.213511
global_step: 15343, epoch: 184, loss: 0.245584
global_step: 15344, epoch: 184, loss: 0.253336
global_step: 15345, epoch: 184, loss: 0.257478
global_step: 15346, epoch: 184, loss: 0.226506
global_step: 15347, epoch: 184, loss: 0.303931
global_step: 15348, epoch: 184, loss: 0.186576
global_step: 15349, epoch: 184, loss: 0.266758
global_step: 15350, epoch: 184, loss: 0.271631
global_step: 15351, epoch: 184, loss: 0.218537
global_step: 15352, epoch: 184, loss: 0.327504
global_step: 15353, epoch: 184, loss: 0.264406
global_step: 15354, epoch: 184, loss: 0.251657
global_step: 15355, epoch: 184, loss: 0.174824
global_step: 15356, epoch: 184, loss: 0.315407
global_step: 15357, epoch: 184, loss: 0.209520
global_step: 15358, epoch: 184, loss: 0.188751
global_step: 15359, epoch: 184, loss: 0.259912
global_step: 15360, epoch: 184, loss: 0.329202
epoch: 184
train	acc: 0.9597	macro: p 0.9647, r 0.9227, f1: 0.9417	micro: p 0.9597, r 0.9597, f1 0.9597	weighted_f1:0.9593
dev	acc: 0.5663	macro: p 0.4519, r 0.3538, f1: 0.3648	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5301
test	acc: 0.5920	macro: p 0.4127, r 0.3508, f1: 0.3646	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5636
global_step: 15361, epoch: 185, loss: 0.226034
global_step: 15362, epoch: 185, loss: 0.219378
global_step: 15363, epoch: 185, loss: 0.250837
global_step: 15364, epoch: 185, loss: 0.268986
global_step: 15365, epoch: 185, loss: 0.274396
global_step: 15366, epoch: 185, loss: 0.189636
global_step: 15367, epoch: 185, loss: 0.169207
global_step: 15368, epoch: 185, loss: 0.269246
global_step: 15369, epoch: 185, loss: 0.281033
global_step: 15370, epoch: 185, loss: 0.259546
global_step: 15371, epoch: 185, loss: 0.264549
global_step: 15372, epoch: 185, loss: 0.210039
global_step: 15373, epoch: 185, loss: 0.318799
global_step: 15374, epoch: 185, loss: 0.217042
global_step: 15375, epoch: 185, loss: 0.302203
global_step: 15376, epoch: 185, loss: 0.219917
global_step: 15377, epoch: 185, loss: 0.300385
global_step: 15378, epoch: 185, loss: 0.215017
global_step: 15379, epoch: 185, loss: 0.246521
global_step: 15380, epoch: 185, loss: 0.241351
global_step: 15381, epoch: 185, loss: 0.278768
global_step: 15382, epoch: 185, loss: 0.269082
global_step: 15383, epoch: 185, loss: 0.259247
global_step: 15384, epoch: 185, loss: 0.288277
global_step: 15385, epoch: 185, loss: 0.186772
global_step: 15386, epoch: 185, loss: 0.248268
global_step: 15387, epoch: 185, loss: 0.225474
global_step: 15388, epoch: 185, loss: 0.346699
global_step: 15389, epoch: 185, loss: 0.232989
global_step: 15390, epoch: 185, loss: 0.217355
global_step: 15391, epoch: 185, loss: 0.264961
global_step: 15392, epoch: 185, loss: 0.292974
global_step: 15393, epoch: 185, loss: 0.309882
global_step: 15394, epoch: 185, loss: 0.165422
global_step: 15395, epoch: 185, loss: 0.222434
global_step: 15396, epoch: 185, loss: 0.247558
global_step: 15397, epoch: 185, loss: 0.221552
global_step: 15398, epoch: 185, loss: 0.268679
global_step: 15399, epoch: 185, loss: 0.213141
global_step: 15400, epoch: 185, loss: 0.146970
epoch: 185
train	acc: 0.9634	macro: p 0.9668, r 0.9380, f1: 0.9516	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9633
dev	acc: 0.5663	macro: p 0.4195, r 0.3531, f1: 0.3643	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5320
test	acc: 0.5950	macro: p 0.4150, r 0.3575, f1: 0.3726	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5687
global_step: 15401, epoch: 186, loss: 0.241350
global_step: 15402, epoch: 186, loss: 0.225140
global_step: 15403, epoch: 186, loss: 0.257669
global_step: 15404, epoch: 186, loss: 0.255187
global_step: 15405, epoch: 186, loss: 0.240228
global_step: 15406, epoch: 186, loss: 0.279446
global_step: 15407, epoch: 186, loss: 0.232885
global_step: 15408, epoch: 186, loss: 0.275346
global_step: 15409, epoch: 186, loss: 0.223070
global_step: 15410, epoch: 186, loss: 0.213873
global_step: 15411, epoch: 186, loss: 0.239094
global_step: 15412, epoch: 186, loss: 0.227611
global_step: 15413, epoch: 186, loss: 0.236369
global_step: 15414, epoch: 186, loss: 0.293234
global_step: 15415, epoch: 186, loss: 0.233275
global_step: 15416, epoch: 186, loss: 0.241106
global_step: 15417, epoch: 186, loss: 0.232729
global_step: 15418, epoch: 186, loss: 0.203084
global_step: 15419, epoch: 186, loss: 0.297451
global_step: 15420, epoch: 186, loss: 0.239599
global_step: 15421, epoch: 186, loss: 0.237543
global_step: 15422, epoch: 186, loss: 0.304049
global_step: 15423, epoch: 186, loss: 0.272001
global_step: 15424, epoch: 186, loss: 0.173925
global_step: 15425, epoch: 186, loss: 0.276212
global_step: 15426, epoch: 186, loss: 0.246395
global_step: 15427, epoch: 186, loss: 0.253317
global_step: 15428, epoch: 186, loss: 0.239325
global_step: 15429, epoch: 186, loss: 0.311358
global_step: 15430, epoch: 186, loss: 0.228341
global_step: 15431, epoch: 186, loss: 0.314911
global_step: 15432, epoch: 186, loss: 0.264139
global_step: 15433, epoch: 186, loss: 0.253877
global_step: 15434, epoch: 186, loss: 0.307828
global_step: 15435, epoch: 186, loss: 0.212481
global_step: 15436, epoch: 186, loss: 0.250084
global_step: 15437, epoch: 186, loss: 0.247330
global_step: 15438, epoch: 186, loss: 0.286314
global_step: 15439, epoch: 186, loss: 0.263193
global_step: 15440, epoch: 186, loss: 0.137526
epoch: 186
train	acc: 0.9635	macro: p 0.9651, r 0.9396, f1: 0.9517	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5654	macro: p 0.4210, r 0.3688, f1: 0.3808	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5378
test	acc: 0.5839	macro: p 0.4060, r 0.3641, f1: 0.3762	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5652
global_step: 15441, epoch: 187, loss: 0.221979
global_step: 15442, epoch: 187, loss: 0.261909
global_step: 15443, epoch: 187, loss: 0.285144
global_step: 15444, epoch: 187, loss: 0.258697
global_step: 15445, epoch: 187, loss: 0.239571
global_step: 15446, epoch: 187, loss: 0.322825
global_step: 15447, epoch: 187, loss: 0.269396
global_step: 15448, epoch: 187, loss: 0.233884
global_step: 15449, epoch: 187, loss: 0.220167
global_step: 15450, epoch: 187, loss: 0.273287
global_step: 15451, epoch: 187, loss: 0.209013
global_step: 15452, epoch: 187, loss: 0.264530
global_step: 15453, epoch: 187, loss: 0.185051
global_step: 15454, epoch: 187, loss: 0.271774
global_step: 15455, epoch: 187, loss: 0.249325
global_step: 15456, epoch: 187, loss: 0.207104
global_step: 15457, epoch: 187, loss: 0.230418
global_step: 15458, epoch: 187, loss: 0.232778
global_step: 15459, epoch: 187, loss: 0.218810
global_step: 15460, epoch: 187, loss: 0.207875
global_step: 15461, epoch: 187, loss: 0.212831
global_step: 15462, epoch: 187, loss: 0.248866
global_step: 15463, epoch: 187, loss: 0.313854
global_step: 15464, epoch: 187, loss: 0.274737
global_step: 15465, epoch: 187, loss: 0.242155
global_step: 15466, epoch: 187, loss: 0.255839
global_step: 15467, epoch: 187, loss: 0.253521
global_step: 15468, epoch: 187, loss: 0.263924
global_step: 15469, epoch: 187, loss: 0.365525
global_step: 15470, epoch: 187, loss: 0.203871
global_step: 15471, epoch: 187, loss: 0.228917
global_step: 15472, epoch: 187, loss: 0.251271
global_step: 15473, epoch: 187, loss: 0.265591
global_step: 15474, epoch: 187, loss: 0.290101
global_step: 15475, epoch: 187, loss: 0.164091
global_step: 15476, epoch: 187, loss: 0.275488
global_step: 15477, epoch: 187, loss: 0.324607
global_step: 15478, epoch: 187, loss: 0.276276
global_step: 15479, epoch: 187, loss: 0.280059
global_step: 15480, epoch: 187, loss: 0.066717
epoch: 187
train	acc: 0.9635	macro: p 0.9667, r 0.9378, f1: 0.9513	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5609	macro: p 0.4215, r 0.3567, f1: 0.3644	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5287
test	acc: 0.5866	macro: p 0.4000, r 0.3552, f1: 0.3660	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5644
global_step: 15481, epoch: 188, loss: 0.216656
global_step: 15482, epoch: 188, loss: 0.233876
global_step: 15483, epoch: 188, loss: 0.267013
global_step: 15484, epoch: 188, loss: 0.271645
global_step: 15485, epoch: 188, loss: 0.222854
global_step: 15486, epoch: 188, loss: 0.226601
global_step: 15487, epoch: 188, loss: 0.230224
global_step: 15488, epoch: 188, loss: 0.316314
global_step: 15489, epoch: 188, loss: 0.193796
global_step: 15490, epoch: 188, loss: 0.181460
global_step: 15491, epoch: 188, loss: 0.245707
global_step: 15492, epoch: 188, loss: 0.195352
global_step: 15493, epoch: 188, loss: 0.221625
global_step: 15494, epoch: 188, loss: 0.337553
global_step: 15495, epoch: 188, loss: 0.248236
global_step: 15496, epoch: 188, loss: 0.287541
global_step: 15497, epoch: 188, loss: 0.248455
global_step: 15498, epoch: 188, loss: 0.255592
global_step: 15499, epoch: 188, loss: 0.188657
global_step: 15500, epoch: 188, loss: 0.226538
global_step: 15501, epoch: 188, loss: 0.229459
global_step: 15502, epoch: 188, loss: 0.232523
global_step: 15503, epoch: 188, loss: 0.215540
global_step: 15504, epoch: 188, loss: 0.216364
global_step: 15505, epoch: 188, loss: 0.244216
global_step: 15506, epoch: 188, loss: 0.224516
global_step: 15507, epoch: 188, loss: 0.328862
global_step: 15508, epoch: 188, loss: 0.263454
global_step: 15509, epoch: 188, loss: 0.232876
global_step: 15510, epoch: 188, loss: 0.256935
global_step: 15511, epoch: 188, loss: 0.248466
global_step: 15512, epoch: 188, loss: 0.218389
global_step: 15513, epoch: 188, loss: 0.265747
global_step: 15514, epoch: 188, loss: 0.276787
global_step: 15515, epoch: 188, loss: 0.248854
global_step: 15516, epoch: 188, loss: 0.288131
global_step: 15517, epoch: 188, loss: 0.269047
global_step: 15518, epoch: 188, loss: 0.239593
global_step: 15519, epoch: 188, loss: 0.217191
global_step: 15520, epoch: 188, loss: 0.837156
epoch: 188
train	acc: 0.9625	macro: p 0.9681, r 0.9317, f1: 0.9485	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9623
dev	acc: 0.5654	macro: p 0.4630, r 0.3541, f1: 0.3668	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5294
test	acc: 0.5927	macro: p 0.4128, r 0.3485, f1: 0.3613	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5629
global_step: 15521, epoch: 189, loss: 0.264644
global_step: 15522, epoch: 189, loss: 0.219163
global_step: 15523, epoch: 189, loss: 0.244626
global_step: 15524, epoch: 189, loss: 0.256408
global_step: 15525, epoch: 189, loss: 0.255033
global_step: 15526, epoch: 189, loss: 0.281202
global_step: 15527, epoch: 189, loss: 0.207758
global_step: 15528, epoch: 189, loss: 0.239490
global_step: 15529, epoch: 189, loss: 0.229080
global_step: 15530, epoch: 189, loss: 0.281326
global_step: 15531, epoch: 189, loss: 0.233875
global_step: 15532, epoch: 189, loss: 0.267934
global_step: 15533, epoch: 189, loss: 0.271279
global_step: 15534, epoch: 189, loss: 0.342415
global_step: 15535, epoch: 189, loss: 0.251926
global_step: 15536, epoch: 189, loss: 0.274613
global_step: 15537, epoch: 189, loss: 0.259546
global_step: 15538, epoch: 189, loss: 0.237844
global_step: 15539, epoch: 189, loss: 0.213841
global_step: 15540, epoch: 189, loss: 0.224731
global_step: 15541, epoch: 189, loss: 0.263171
global_step: 15542, epoch: 189, loss: 0.270562
global_step: 15543, epoch: 189, loss: 0.302631
global_step: 15544, epoch: 189, loss: 0.252281
global_step: 15545, epoch: 189, loss: 0.279714
global_step: 15546, epoch: 189, loss: 0.194839
global_step: 15547, epoch: 189, loss: 0.266128
global_step: 15548, epoch: 189, loss: 0.242331
global_step: 15549, epoch: 189, loss: 0.259901
global_step: 15550, epoch: 189, loss: 0.316107
global_step: 15551, epoch: 189, loss: 0.276718
global_step: 15552, epoch: 189, loss: 0.195703
global_step: 15553, epoch: 189, loss: 0.265013
global_step: 15554, epoch: 189, loss: 0.200818
global_step: 15555, epoch: 189, loss: 0.215827
global_step: 15556, epoch: 189, loss: 0.212033
global_step: 15557, epoch: 189, loss: 0.210385
global_step: 15558, epoch: 189, loss: 0.232316
global_step: 15559, epoch: 189, loss: 0.215609
global_step: 15560, epoch: 189, loss: 0.303118
epoch: 189
train	acc: 0.9621	macro: p 0.9674, r 0.9290, f1: 0.9467	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9619
dev	acc: 0.5681	macro: p 0.4582, r 0.3568, f1: 0.3682	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5318
test	acc: 0.5939	macro: p 0.4200, r 0.3480, f1: 0.3594	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5633
global_step: 15561, epoch: 190, loss: 0.276819
global_step: 15562, epoch: 190, loss: 0.265311
global_step: 15563, epoch: 190, loss: 0.213348
global_step: 15564, epoch: 190, loss: 0.193825
global_step: 15565, epoch: 190, loss: 0.226820
global_step: 15566, epoch: 190, loss: 0.333904
global_step: 15567, epoch: 190, loss: 0.292174
global_step: 15568, epoch: 190, loss: 0.270048
global_step: 15569, epoch: 190, loss: 0.194409
global_step: 15570, epoch: 190, loss: 0.267049
global_step: 15571, epoch: 190, loss: 0.235008
global_step: 15572, epoch: 190, loss: 0.293755
global_step: 15573, epoch: 190, loss: 0.240726
global_step: 15574, epoch: 190, loss: 0.254589
global_step: 15575, epoch: 190, loss: 0.227135
global_step: 15576, epoch: 190, loss: 0.218357
global_step: 15577, epoch: 190, loss: 0.208445
global_step: 15578, epoch: 190, loss: 0.235246
global_step: 15579, epoch: 190, loss: 0.319311
global_step: 15580, epoch: 190, loss: 0.268450
global_step: 15581, epoch: 190, loss: 0.262903
global_step: 15582, epoch: 190, loss: 0.283886
global_step: 15583, epoch: 190, loss: 0.332882
global_step: 15584, epoch: 190, loss: 0.286982
global_step: 15585, epoch: 190, loss: 0.219623
global_step: 15586, epoch: 190, loss: 0.275837
global_step: 15587, epoch: 190, loss: 0.229415
global_step: 15588, epoch: 190, loss: 0.213008
global_step: 15589, epoch: 190, loss: 0.245167
global_step: 15590, epoch: 190, loss: 0.237879
global_step: 15591, epoch: 190, loss: 0.281095
global_step: 15592, epoch: 190, loss: 0.219451
global_step: 15593, epoch: 190, loss: 0.254659
global_step: 15594, epoch: 190, loss: 0.279238
global_step: 15595, epoch: 190, loss: 0.286115
global_step: 15596, epoch: 190, loss: 0.232751
global_step: 15597, epoch: 190, loss: 0.201353
global_step: 15598, epoch: 190, loss: 0.275137
global_step: 15599, epoch: 190, loss: 0.226570
global_step: 15600, epoch: 190, loss: 0.706881
epoch: 190
train	acc: 0.9624	macro: p 0.9660, r 0.9348, f1: 0.9492	micro: p 0.9624, r 0.9624, f1 0.9624	weighted_f1:0.9623
dev	acc: 0.5609	macro: p 0.4318, r 0.3681, f1: 0.3779	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5349
test	acc: 0.5808	macro: p 0.4015, r 0.3616, f1: 0.3712	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5631
global_step: 15601, epoch: 191, loss: 0.202484
global_step: 15602, epoch: 191, loss: 0.255319
global_step: 15603, epoch: 191, loss: 0.240445
global_step: 15604, epoch: 191, loss: 0.237916
global_step: 15605, epoch: 191, loss: 0.250906
global_step: 15606, epoch: 191, loss: 0.327037
global_step: 15607, epoch: 191, loss: 0.236897
global_step: 15608, epoch: 191, loss: 0.211332
global_step: 15609, epoch: 191, loss: 0.284436
global_step: 15610, epoch: 191, loss: 0.298084
global_step: 15611, epoch: 191, loss: 0.230139
global_step: 15612, epoch: 191, loss: 0.270915
global_step: 15613, epoch: 191, loss: 0.197562
global_step: 15614, epoch: 191, loss: 0.259252
global_step: 15615, epoch: 191, loss: 0.191035
global_step: 15616, epoch: 191, loss: 0.217165
global_step: 15617, epoch: 191, loss: 0.225085
global_step: 15618, epoch: 191, loss: 0.211083
global_step: 15619, epoch: 191, loss: 0.267455
global_step: 15620, epoch: 191, loss: 0.232803
global_step: 15621, epoch: 191, loss: 0.218636
global_step: 15622, epoch: 191, loss: 0.343344
global_step: 15623, epoch: 191, loss: 0.232062
global_step: 15624, epoch: 191, loss: 0.275279
global_step: 15625, epoch: 191, loss: 0.152201
global_step: 15626, epoch: 191, loss: 0.316181
global_step: 15627, epoch: 191, loss: 0.259061
global_step: 15628, epoch: 191, loss: 0.212022
global_step: 15629, epoch: 191, loss: 0.260782
global_step: 15630, epoch: 191, loss: 0.237419
global_step: 15631, epoch: 191, loss: 0.216712
global_step: 15632, epoch: 191, loss: 0.300568
global_step: 15633, epoch: 191, loss: 0.284553
global_step: 15634, epoch: 191, loss: 0.294487
global_step: 15635, epoch: 191, loss: 0.266266
global_step: 15636, epoch: 191, loss: 0.258540
global_step: 15637, epoch: 191, loss: 0.205293
global_step: 15638, epoch: 191, loss: 0.250630
global_step: 15639, epoch: 191, loss: 0.228277
global_step: 15640, epoch: 191, loss: 0.082760
epoch: 191
train	acc: 0.9620	macro: p 0.9688, r 0.9330, f1: 0.9497	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9618
dev	acc: 0.5690	macro: p 0.4473, r 0.3530, f1: 0.3685	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5326
test	acc: 0.6000	macro: p 0.4252, r 0.3503, f1: 0.3686	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5683
global_step: 15641, epoch: 192, loss: 0.215226
global_step: 15642, epoch: 192, loss: 0.254595
global_step: 15643, epoch: 192, loss: 0.221135
global_step: 15644, epoch: 192, loss: 0.253205
global_step: 15645, epoch: 192, loss: 0.229413
global_step: 15646, epoch: 192, loss: 0.267770
global_step: 15647, epoch: 192, loss: 0.264326
global_step: 15648, epoch: 192, loss: 0.249749
global_step: 15649, epoch: 192, loss: 0.223436
global_step: 15650, epoch: 192, loss: 0.298537
global_step: 15651, epoch: 192, loss: 0.198981
global_step: 15652, epoch: 192, loss: 0.250180
global_step: 15653, epoch: 192, loss: 0.234598
global_step: 15654, epoch: 192, loss: 0.230826
global_step: 15655, epoch: 192, loss: 0.232707
global_step: 15656, epoch: 192, loss: 0.300010
global_step: 15657, epoch: 192, loss: 0.238691
global_step: 15658, epoch: 192, loss: 0.267233
global_step: 15659, epoch: 192, loss: 0.225627
global_step: 15660, epoch: 192, loss: 0.255837
global_step: 15661, epoch: 192, loss: 0.262952
global_step: 15662, epoch: 192, loss: 0.280256
global_step: 15663, epoch: 192, loss: 0.226441
global_step: 15664, epoch: 192, loss: 0.217649
global_step: 15665, epoch: 192, loss: 0.277008
global_step: 15666, epoch: 192, loss: 0.182777
global_step: 15667, epoch: 192, loss: 0.273621
global_step: 15668, epoch: 192, loss: 0.223288
global_step: 15669, epoch: 192, loss: 0.299942
global_step: 15670, epoch: 192, loss: 0.218475
global_step: 15671, epoch: 192, loss: 0.253093
global_step: 15672, epoch: 192, loss: 0.265672
global_step: 15673, epoch: 192, loss: 0.246988
global_step: 15674, epoch: 192, loss: 0.296661
global_step: 15675, epoch: 192, loss: 0.277404
global_step: 15676, epoch: 192, loss: 0.238396
global_step: 15677, epoch: 192, loss: 0.177088
global_step: 15678, epoch: 192, loss: 0.248277
global_step: 15679, epoch: 192, loss: 0.208626
global_step: 15680, epoch: 192, loss: 0.006791
epoch: 192
train	acc: 0.9646	macro: p 0.9670, r 0.9406, f1: 0.9529	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9645
dev	acc: 0.5600	macro: p 0.4304, r 0.3779, f1: 0.3895	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5370
test	acc: 0.5785	macro: p 0.3941, r 0.3643, f1: 0.3736	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5636
global_step: 15681, epoch: 193, loss: 0.239348
global_step: 15682, epoch: 193, loss: 0.246042
global_step: 15683, epoch: 193, loss: 0.221102
global_step: 15684, epoch: 193, loss: 0.201025
global_step: 15685, epoch: 193, loss: 0.187989
global_step: 15686, epoch: 193, loss: 0.177689
global_step: 15687, epoch: 193, loss: 0.211028
global_step: 15688, epoch: 193, loss: 0.203591
global_step: 15689, epoch: 193, loss: 0.227003
global_step: 15690, epoch: 193, loss: 0.233840
global_step: 15691, epoch: 193, loss: 0.266803
global_step: 15692, epoch: 193, loss: 0.306038
global_step: 15693, epoch: 193, loss: 0.260379
global_step: 15694, epoch: 193, loss: 0.236357
global_step: 15695, epoch: 193, loss: 0.246254
global_step: 15696, epoch: 193, loss: 0.231399
global_step: 15697, epoch: 193, loss: 0.230703
global_step: 15698, epoch: 193, loss: 0.186941
global_step: 15699, epoch: 193, loss: 0.227840
global_step: 15700, epoch: 193, loss: 0.272690
global_step: 15701, epoch: 193, loss: 0.238864
global_step: 15702, epoch: 193, loss: 0.211039
global_step: 15703, epoch: 193, loss: 0.183284
global_step: 15704, epoch: 193, loss: 0.228633
global_step: 15705, epoch: 193, loss: 0.238539
global_step: 15706, epoch: 193, loss: 0.247213
global_step: 15707, epoch: 193, loss: 0.359140
global_step: 15708, epoch: 193, loss: 0.218349
global_step: 15709, epoch: 193, loss: 0.215447
global_step: 15710, epoch: 193, loss: 0.274207
global_step: 15711, epoch: 193, loss: 0.278020
global_step: 15712, epoch: 193, loss: 0.299655
global_step: 15713, epoch: 193, loss: 0.257548
global_step: 15714, epoch: 193, loss: 0.272544
global_step: 15715, epoch: 193, loss: 0.280325
global_step: 15716, epoch: 193, loss: 0.350565
global_step: 15717, epoch: 193, loss: 0.248424
global_step: 15718, epoch: 193, loss: 0.279286
global_step: 15719, epoch: 193, loss: 0.211979
global_step: 15720, epoch: 193, loss: 0.600207
epoch: 193
train	acc: 0.9649	macro: p 0.9667, r 0.9439, f1: 0.9546	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9648
dev	acc: 0.5500	macro: p 0.4019, r 0.3698, f1: 0.3767	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5321
test	acc: 0.5739	macro: p 0.3938, r 0.3711, f1: 0.3767	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5652
global_step: 15721, epoch: 194, loss: 0.212613
global_step: 15722, epoch: 194, loss: 0.306275
global_step: 15723, epoch: 194, loss: 0.186966
global_step: 15724, epoch: 194, loss: 0.188968
global_step: 15725, epoch: 194, loss: 0.210925
global_step: 15726, epoch: 194, loss: 0.241543
global_step: 15727, epoch: 194, loss: 0.265018
global_step: 15728, epoch: 194, loss: 0.247113
global_step: 15729, epoch: 194, loss: 0.249445
global_step: 15730, epoch: 194, loss: 0.260814
global_step: 15731, epoch: 194, loss: 0.217623
global_step: 15732, epoch: 194, loss: 0.255950
global_step: 15733, epoch: 194, loss: 0.291843
global_step: 15734, epoch: 194, loss: 0.252770
global_step: 15735, epoch: 194, loss: 0.205837
global_step: 15736, epoch: 194, loss: 0.306063
global_step: 15737, epoch: 194, loss: 0.238445
global_step: 15738, epoch: 194, loss: 0.286241
global_step: 15739, epoch: 194, loss: 0.186164
global_step: 15740, epoch: 194, loss: 0.222797
global_step: 15741, epoch: 194, loss: 0.190231
global_step: 15742, epoch: 194, loss: 0.239126
global_step: 15743, epoch: 194, loss: 0.200718
global_step: 15744, epoch: 194, loss: 0.255661
global_step: 15745, epoch: 194, loss: 0.264508
global_step: 15746, epoch: 194, loss: 0.332296
global_step: 15747, epoch: 194, loss: 0.248777
global_step: 15748, epoch: 194, loss: 0.178389
global_step: 15749, epoch: 194, loss: 0.259112
global_step: 15750, epoch: 194, loss: 0.216537
global_step: 15751, epoch: 194, loss: 0.297516
global_step: 15752, epoch: 194, loss: 0.292196
global_step: 15753, epoch: 194, loss: 0.217155
global_step: 15754, epoch: 194, loss: 0.254049
global_step: 15755, epoch: 194, loss: 0.255199
global_step: 15756, epoch: 194, loss: 0.260860
global_step: 15757, epoch: 194, loss: 0.229906
global_step: 15758, epoch: 194, loss: 0.235621
global_step: 15759, epoch: 194, loss: 0.215398
global_step: 15760, epoch: 194, loss: 0.024715
epoch: 194
train	acc: 0.9648	macro: p 0.9686, r 0.9395, f1: 0.9530	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9647
dev	acc: 0.5582	macro: p 0.4137, r 0.3623, f1: 0.3703	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5320
test	acc: 0.5808	macro: p 0.3953, r 0.3554, f1: 0.3644	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5611
global_step: 15761, epoch: 195, loss: 0.246376
global_step: 15762, epoch: 195, loss: 0.271215
global_step: 15763, epoch: 195, loss: 0.305714
global_step: 15764, epoch: 195, loss: 0.203274
global_step: 15765, epoch: 195, loss: 0.246632
global_step: 15766, epoch: 195, loss: 0.220271
global_step: 15767, epoch: 195, loss: 0.221776
global_step: 15768, epoch: 195, loss: 0.235910
global_step: 15769, epoch: 195, loss: 0.201893
global_step: 15770, epoch: 195, loss: 0.226712
global_step: 15771, epoch: 195, loss: 0.271086
global_step: 15772, epoch: 195, loss: 0.273337
global_step: 15773, epoch: 195, loss: 0.205130
global_step: 15774, epoch: 195, loss: 0.229567
global_step: 15775, epoch: 195, loss: 0.248974
global_step: 15776, epoch: 195, loss: 0.252565
global_step: 15777, epoch: 195, loss: 0.218667
global_step: 15778, epoch: 195, loss: 0.370637
global_step: 15779, epoch: 195, loss: 0.252268
global_step: 15780, epoch: 195, loss: 0.188872
global_step: 15781, epoch: 195, loss: 0.215748
global_step: 15782, epoch: 195, loss: 0.267717
global_step: 15783, epoch: 195, loss: 0.242122
global_step: 15784, epoch: 195, loss: 0.250573
global_step: 15785, epoch: 195, loss: 0.299628
global_step: 15786, epoch: 195, loss: 0.221259
global_step: 15787, epoch: 195, loss: 0.230499
global_step: 15788, epoch: 195, loss: 0.239777
global_step: 15789, epoch: 195, loss: 0.195840
global_step: 15790, epoch: 195, loss: 0.137555
global_step: 15791, epoch: 195, loss: 0.280046
global_step: 15792, epoch: 195, loss: 0.244146
global_step: 15793, epoch: 195, loss: 0.181528
global_step: 15794, epoch: 195, loss: 0.252746
global_step: 15795, epoch: 195, loss: 0.229303
global_step: 15796, epoch: 195, loss: 0.203040
global_step: 15797, epoch: 195, loss: 0.312659
global_step: 15798, epoch: 195, loss: 0.230976
global_step: 15799, epoch: 195, loss: 0.232083
global_step: 15800, epoch: 195, loss: 0.014765
epoch: 195
train	acc: 0.9643	macro: p 0.9689, r 0.9384, f1: 0.9526	micro: p 0.9643, r 0.9643, f1 0.9643	weighted_f1:0.9642
dev	acc: 0.5663	macro: p 0.4554, r 0.3559, f1: 0.3685	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5324
test	acc: 0.5870	macro: p 0.4051, r 0.3476, f1: 0.3584	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5598
global_step: 15801, epoch: 196, loss: 0.225387
global_step: 15802, epoch: 196, loss: 0.269669
global_step: 15803, epoch: 196, loss: 0.201185
global_step: 15804, epoch: 196, loss: 0.220304
global_step: 15805, epoch: 196, loss: 0.228170
global_step: 15806, epoch: 196, loss: 0.258881
global_step: 15807, epoch: 196, loss: 0.261258
global_step: 15808, epoch: 196, loss: 0.243483
global_step: 15809, epoch: 196, loss: 0.229069
global_step: 15810, epoch: 196, loss: 0.273533
global_step: 15811, epoch: 196, loss: 0.238981
global_step: 15812, epoch: 196, loss: 0.206683
global_step: 15813, epoch: 196, loss: 0.279325
global_step: 15814, epoch: 196, loss: 0.186370
global_step: 15815, epoch: 196, loss: 0.242401
global_step: 15816, epoch: 196, loss: 0.202910
global_step: 15817, epoch: 196, loss: 0.222951
global_step: 15818, epoch: 196, loss: 0.180666
global_step: 15819, epoch: 196, loss: 0.284854
global_step: 15820, epoch: 196, loss: 0.185003
global_step: 15821, epoch: 196, loss: 0.215298
global_step: 15822, epoch: 196, loss: 0.249648
global_step: 15823, epoch: 196, loss: 0.253563
global_step: 15824, epoch: 196, loss: 0.226872
global_step: 15825, epoch: 196, loss: 0.254587
global_step: 15826, epoch: 196, loss: 0.240002
global_step: 15827, epoch: 196, loss: 0.270116
global_step: 15828, epoch: 196, loss: 0.255214
global_step: 15829, epoch: 196, loss: 0.233237
global_step: 15830, epoch: 196, loss: 0.208404
global_step: 15831, epoch: 196, loss: 0.244311
global_step: 15832, epoch: 196, loss: 0.220491
global_step: 15833, epoch: 196, loss: 0.238305
global_step: 15834, epoch: 196, loss: 0.221949
global_step: 15835, epoch: 196, loss: 0.288069
global_step: 15836, epoch: 196, loss: 0.256514
global_step: 15837, epoch: 196, loss: 0.217293
global_step: 15838, epoch: 196, loss: 0.363379
global_step: 15839, epoch: 196, loss: 0.242787
global_step: 15840, epoch: 196, loss: 0.006349
epoch: 196
train	acc: 0.9638	macro: p 0.9700, r 0.9380, f1: 0.9529	micro: p 0.9638, r 0.9638, f1 0.9638	weighted_f1:0.9636
dev	acc: 0.5690	macro: p 0.4461, r 0.3577, f1: 0.3695	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5349
test	acc: 0.5943	macro: p 0.4145, r 0.3530, f1: 0.3659	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5660
global_step: 15841, epoch: 197, loss: 0.199069
global_step: 15842, epoch: 197, loss: 0.270699
global_step: 15843, epoch: 197, loss: 0.236800
global_step: 15844, epoch: 197, loss: 0.204712
global_step: 15845, epoch: 197, loss: 0.154362
global_step: 15846, epoch: 197, loss: 0.258013
global_step: 15847, epoch: 197, loss: 0.180423
global_step: 15848, epoch: 197, loss: 0.184186
global_step: 15849, epoch: 197, loss: 0.262506
global_step: 15850, epoch: 197, loss: 0.202683
global_step: 15851, epoch: 197, loss: 0.219031
global_step: 15852, epoch: 197, loss: 0.279857
global_step: 15853, epoch: 197, loss: 0.207802
global_step: 15854, epoch: 197, loss: 0.326381
global_step: 15855, epoch: 197, loss: 0.267871
global_step: 15856, epoch: 197, loss: 0.259805
global_step: 15857, epoch: 197, loss: 0.208755
global_step: 15858, epoch: 197, loss: 0.269145
global_step: 15859, epoch: 197, loss: 0.246607
global_step: 15860, epoch: 197, loss: 0.220912
global_step: 15861, epoch: 197, loss: 0.251341
global_step: 15862, epoch: 197, loss: 0.263380
global_step: 15863, epoch: 197, loss: 0.209573
global_step: 15864, epoch: 197, loss: 0.189983
global_step: 15865, epoch: 197, loss: 0.231292
global_step: 15866, epoch: 197, loss: 0.222723
global_step: 15867, epoch: 197, loss: 0.262302
global_step: 15868, epoch: 197, loss: 0.203854
global_step: 15869, epoch: 197, loss: 0.272898
global_step: 15870, epoch: 197, loss: 0.210226
global_step: 15871, epoch: 197, loss: 0.321756
global_step: 15872, epoch: 197, loss: 0.249883
global_step: 15873, epoch: 197, loss: 0.227947
global_step: 15874, epoch: 197, loss: 0.251547
global_step: 15875, epoch: 197, loss: 0.218686
global_step: 15876, epoch: 197, loss: 0.226325
global_step: 15877, epoch: 197, loss: 0.204175
global_step: 15878, epoch: 197, loss: 0.316379
global_step: 15879, epoch: 197, loss: 0.226036
global_step: 15880, epoch: 197, loss: 0.198105
epoch: 197
train	acc: 0.9650	macro: p 0.9687, r 0.9430, f1: 0.9551	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9649
dev	acc: 0.5663	macro: p 0.4308, r 0.3614, f1: 0.3721	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5358
test	acc: 0.5862	macro: p 0.4019, r 0.3538, f1: 0.3660	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5623
global_step: 15881, epoch: 198, loss: 0.249245
global_step: 15882, epoch: 198, loss: 0.278245
global_step: 15883, epoch: 198, loss: 0.272291
global_step: 15884, epoch: 198, loss: 0.179704
global_step: 15885, epoch: 198, loss: 0.135104
global_step: 15886, epoch: 198, loss: 0.228732
global_step: 15887, epoch: 198, loss: 0.172497
global_step: 15888, epoch: 198, loss: 0.258452
global_step: 15889, epoch: 198, loss: 0.252838
global_step: 15890, epoch: 198, loss: 0.240861
global_step: 15891, epoch: 198, loss: 0.318599
global_step: 15892, epoch: 198, loss: 0.178558
global_step: 15893, epoch: 198, loss: 0.229300
global_step: 15894, epoch: 198, loss: 0.296613
global_step: 15895, epoch: 198, loss: 0.212683
global_step: 15896, epoch: 198, loss: 0.267884
global_step: 15897, epoch: 198, loss: 0.301683
global_step: 15898, epoch: 198, loss: 0.290859
global_step: 15899, epoch: 198, loss: 0.267556
global_step: 15900, epoch: 198, loss: 0.245160
global_step: 15901, epoch: 198, loss: 0.259380
global_step: 15902, epoch: 198, loss: 0.247224
global_step: 15903, epoch: 198, loss: 0.218494
global_step: 15904, epoch: 198, loss: 0.284274
global_step: 15905, epoch: 198, loss: 0.251521
global_step: 15906, epoch: 198, loss: 0.187678
global_step: 15907, epoch: 198, loss: 0.189827
global_step: 15908, epoch: 198, loss: 0.249428
global_step: 15909, epoch: 198, loss: 0.218642
global_step: 15910, epoch: 198, loss: 0.375355
global_step: 15911, epoch: 198, loss: 0.288912
global_step: 15912, epoch: 198, loss: 0.262299
global_step: 15913, epoch: 198, loss: 0.239250
global_step: 15914, epoch: 198, loss: 0.268590
global_step: 15915, epoch: 198, loss: 0.296939
global_step: 15916, epoch: 198, loss: 0.225356
global_step: 15917, epoch: 198, loss: 0.219078
global_step: 15918, epoch: 198, loss: 0.215177
global_step: 15919, epoch: 198, loss: 0.279726
global_step: 15920, epoch: 198, loss: 0.055227
epoch: 198
train	acc: 0.9662	macro: p 0.9698, r 0.9447, f1: 0.9565	micro: p 0.9662, r 0.9662, f1 0.9662	weighted_f1:0.9661
dev	acc: 0.5591	macro: p 0.4211, r 0.3522, f1: 0.3627	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5250
test	acc: 0.5904	macro: p 0.4035, r 0.3522, f1: 0.3649	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5639
global_step: 15921, epoch: 199, loss: 0.262185
global_step: 15922, epoch: 199, loss: 0.229017
global_step: 15923, epoch: 199, loss: 0.211891
global_step: 15924, epoch: 199, loss: 0.240441
global_step: 15925, epoch: 199, loss: 0.216345
global_step: 15926, epoch: 199, loss: 0.221844
global_step: 15927, epoch: 199, loss: 0.254670
global_step: 15928, epoch: 199, loss: 0.233868
global_step: 15929, epoch: 199, loss: 0.267139
global_step: 15930, epoch: 199, loss: 0.218838
global_step: 15931, epoch: 199, loss: 0.203295
global_step: 15932, epoch: 199, loss: 0.188032
global_step: 15933, epoch: 199, loss: 0.280684
global_step: 15934, epoch: 199, loss: 0.225118
global_step: 15935, epoch: 199, loss: 0.251848
global_step: 15936, epoch: 199, loss: 0.243457
global_step: 15937, epoch: 199, loss: 0.224739
global_step: 15938, epoch: 199, loss: 0.258799
global_step: 15939, epoch: 199, loss: 0.204445
global_step: 15940, epoch: 199, loss: 0.272027
global_step: 15941, epoch: 199, loss: 0.194918
global_step: 15942, epoch: 199, loss: 0.238000
global_step: 15943, epoch: 199, loss: 0.220731
global_step: 15944, epoch: 199, loss: 0.267545
global_step: 15945, epoch: 199, loss: 0.186321
global_step: 15946, epoch: 199, loss: 0.272529
global_step: 15947, epoch: 199, loss: 0.162953
global_step: 15948, epoch: 199, loss: 0.165096
global_step: 15949, epoch: 199, loss: 0.287201
global_step: 15950, epoch: 199, loss: 0.226250
global_step: 15951, epoch: 199, loss: 0.283547
global_step: 15952, epoch: 199, loss: 0.221248
global_step: 15953, epoch: 199, loss: 0.171078
global_step: 15954, epoch: 199, loss: 0.241127
global_step: 15955, epoch: 199, loss: 0.230358
global_step: 15956, epoch: 199, loss: 0.267888
global_step: 15957, epoch: 199, loss: 0.244291
global_step: 15958, epoch: 199, loss: 0.192816
global_step: 15959, epoch: 199, loss: 0.300995
global_step: 15960, epoch: 199, loss: 0.380698
epoch: 199
train	acc: 0.9649	macro: p 0.9696, r 0.9433, f1: 0.9557	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9648
dev	acc: 0.5627	macro: p 0.4093, r 0.3574, f1: 0.3687	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5328
test	acc: 0.5877	macro: p 0.4015, r 0.3552, f1: 0.3690	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5634
global_step: 15961, epoch: 200, loss: 0.185656
global_step: 15962, epoch: 200, loss: 0.258638
global_step: 15963, epoch: 200, loss: 0.242871
global_step: 15964, epoch: 200, loss: 0.229054
global_step: 15965, epoch: 200, loss: 0.270519
global_step: 15966, epoch: 200, loss: 0.219452
global_step: 15967, epoch: 200, loss: 0.214034
global_step: 15968, epoch: 200, loss: 0.242177
global_step: 15969, epoch: 200, loss: 0.252538
global_step: 15970, epoch: 200, loss: 0.200454
global_step: 15971, epoch: 200, loss: 0.201634
global_step: 15972, epoch: 200, loss: 0.269461
global_step: 15973, epoch: 200, loss: 0.248474
global_step: 15974, epoch: 200, loss: 0.201463
global_step: 15975, epoch: 200, loss: 0.216936
global_step: 15976, epoch: 200, loss: 0.211879
global_step: 15977, epoch: 200, loss: 0.171199
global_step: 15978, epoch: 200, loss: 0.161977
global_step: 15979, epoch: 200, loss: 0.278567
global_step: 15980, epoch: 200, loss: 0.207371
global_step: 15981, epoch: 200, loss: 0.239422
global_step: 15982, epoch: 200, loss: 0.224856
global_step: 15983, epoch: 200, loss: 0.212487
global_step: 15984, epoch: 200, loss: 0.213384
global_step: 15985, epoch: 200, loss: 0.222652
global_step: 15986, epoch: 200, loss: 0.180917
global_step: 15987, epoch: 200, loss: 0.261785
global_step: 15988, epoch: 200, loss: 0.216915
global_step: 15989, epoch: 200, loss: 0.305072
global_step: 15990, epoch: 200, loss: 0.247840
global_step: 15991, epoch: 200, loss: 0.283900
global_step: 15992, epoch: 200, loss: 0.214314
global_step: 15993, epoch: 200, loss: 0.224759
global_step: 15994, epoch: 200, loss: 0.225811
global_step: 15995, epoch: 200, loss: 0.190034
global_step: 15996, epoch: 200, loss: 0.279276
global_step: 15997, epoch: 200, loss: 0.223775
global_step: 15998, epoch: 200, loss: 0.234777
global_step: 15999, epoch: 200, loss: 0.208513
global_step: 16000, epoch: 200, loss: 0.612398
epoch: 200
train	acc: 0.9655	macro: p 0.9681, r 0.9436, f1: 0.9550	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5573	macro: p 0.4153, r 0.3672, f1: 0.3750	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5341
test	acc: 0.5739	macro: p 0.3909, r 0.3635, f1: 0.3689	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5593
BEST MODEL epoch: 49
train	acc: 0.7250 macro_p: 0.4747 macro_r: 0.4475 macro_f1: 0.4495 micro_p: 0.7250 micro_r: 0.7250 micro_f1: 0.7250 weighted_f1: 0.6939
dev	acc: 0.5879 macro_p: 0.3812 macro_r: 0.3522 macro_f1: 0.3523 micro_p: 0.5879 micro_r: 0.5879 micro_f1: 0.5879 weighted_f1: 0.5473
test	acc: 0.6199 macro_p: 0.3778 macro_r: 0.3505 macro_f1: 0.3515 micro_p: 0.6199 micro_r: 0.6199 micro_f1: 0.6199 weighted_f1: 0.5850
==========ROUND 3==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 16001, epoch: 1, loss: 1.929996
global_step: 16002, epoch: 1, loss: 1.923470
global_step: 16003, epoch: 1, loss: 1.910179
global_step: 16004, epoch: 1, loss: 1.897455
global_step: 16005, epoch: 1, loss: 1.869427
global_step: 16006, epoch: 1, loss: 1.859725
global_step: 16007, epoch: 1, loss: 1.861200
global_step: 16008, epoch: 1, loss: 1.831156
global_step: 16009, epoch: 1, loss: 1.822216
global_step: 16010, epoch: 1, loss: 1.822780
global_step: 16011, epoch: 1, loss: 1.782612
global_step: 16012, epoch: 1, loss: 1.794597
global_step: 16013, epoch: 1, loss: 1.778410
global_step: 16014, epoch: 1, loss: 1.728635
global_step: 16015, epoch: 1, loss: 1.750932
global_step: 16016, epoch: 1, loss: 1.710595
global_step: 16017, epoch: 1, loss: 1.714608
global_step: 16018, epoch: 1, loss: 1.666599
global_step: 16019, epoch: 1, loss: 1.664135
global_step: 16020, epoch: 1, loss: 1.666076
global_step: 16021, epoch: 1, loss: 1.614709
global_step: 16022, epoch: 1, loss: 1.591620
global_step: 16023, epoch: 1, loss: 1.622248
global_step: 16024, epoch: 1, loss: 1.655050
global_step: 16025, epoch: 1, loss: 1.552989
global_step: 16026, epoch: 1, loss: 1.692936
global_step: 16027, epoch: 1, loss: 1.536927
global_step: 16028, epoch: 1, loss: 1.515979
global_step: 16029, epoch: 1, loss: 1.526448
global_step: 16030, epoch: 1, loss: 1.565422
global_step: 16031, epoch: 1, loss: 1.618219
global_step: 16032, epoch: 1, loss: 1.602249
global_step: 16033, epoch: 1, loss: 1.595186
global_step: 16034, epoch: 1, loss: 1.514151
global_step: 16035, epoch: 1, loss: 1.541954
global_step: 16036, epoch: 1, loss: 1.509368
global_step: 16037, epoch: 1, loss: 1.553731
global_step: 16038, epoch: 1, loss: 1.603813
global_step: 16039, epoch: 1, loss: 1.555037
global_step: 16040, epoch: 1, loss: 1.952925
epoch: 1
train	acc: 0.4715	macro: p 0.0674, r 0.1429, f1: 0.0916	micro: p 0.4715, r 0.4715, f1 0.4715	weighted_f1:0.3022
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
New best model!
global_step: 16041, epoch: 2, loss: 1.566370
global_step: 16042, epoch: 2, loss: 1.615340
global_step: 16043, epoch: 2, loss: 1.491855
global_step: 16044, epoch: 2, loss: 1.524425
global_step: 16045, epoch: 2, loss: 1.590746
global_step: 16046, epoch: 2, loss: 1.506591
global_step: 16047, epoch: 2, loss: 1.561140
global_step: 16048, epoch: 2, loss: 1.541382
global_step: 16049, epoch: 2, loss: 1.527514
global_step: 16050, epoch: 2, loss: 1.614195
global_step: 16051, epoch: 2, loss: 1.632615
global_step: 16052, epoch: 2, loss: 1.439095
global_step: 16053, epoch: 2, loss: 1.477220
global_step: 16054, epoch: 2, loss: 1.540165
global_step: 16055, epoch: 2, loss: 1.518406
global_step: 16056, epoch: 2, loss: 1.566306
global_step: 16057, epoch: 2, loss: 1.596678
global_step: 16058, epoch: 2, loss: 1.617651
global_step: 16059, epoch: 2, loss: 1.555950
global_step: 16060, epoch: 2, loss: 1.518452
global_step: 16061, epoch: 2, loss: 1.428156
global_step: 16062, epoch: 2, loss: 1.566641
global_step: 16063, epoch: 2, loss: 1.544158
global_step: 16064, epoch: 2, loss: 1.512927
global_step: 16065, epoch: 2, loss: 1.545320
global_step: 16066, epoch: 2, loss: 1.528197
global_step: 16067, epoch: 2, loss: 1.567100
global_step: 16068, epoch: 2, loss: 1.515383
global_step: 16069, epoch: 2, loss: 1.660823
global_step: 16070, epoch: 2, loss: 1.543428
global_step: 16071, epoch: 2, loss: 1.527532
global_step: 16072, epoch: 2, loss: 1.476501
global_step: 16073, epoch: 2, loss: 1.535373
global_step: 16074, epoch: 2, loss: 1.607208
global_step: 16075, epoch: 2, loss: 1.479228
global_step: 16076, epoch: 2, loss: 1.404128
global_step: 16077, epoch: 2, loss: 1.542199
global_step: 16078, epoch: 2, loss: 1.535522
global_step: 16079, epoch: 2, loss: 1.499795
global_step: 16080, epoch: 2, loss: 0.882702
epoch: 2
train	acc: 0.4715	macro: p 0.0674, r 0.1429, f1: 0.0916	micro: p 0.4715, r 0.4715, f1 0.4715	weighted_f1:0.3022
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
global_step: 16081, epoch: 3, loss: 1.500833
global_step: 16082, epoch: 3, loss: 1.528720
global_step: 16083, epoch: 3, loss: 1.507918
global_step: 16084, epoch: 3, loss: 1.445679
global_step: 16085, epoch: 3, loss: 1.509754
global_step: 16086, epoch: 3, loss: 1.511368
global_step: 16087, epoch: 3, loss: 1.417900
global_step: 16088, epoch: 3, loss: 1.452366
global_step: 16089, epoch: 3, loss: 1.485080
global_step: 16090, epoch: 3, loss: 1.479726
global_step: 16091, epoch: 3, loss: 1.497239
global_step: 16092, epoch: 3, loss: 1.461488
global_step: 16093, epoch: 3, loss: 1.522877
global_step: 16094, epoch: 3, loss: 1.417251
global_step: 16095, epoch: 3, loss: 1.570521
global_step: 16096, epoch: 3, loss: 1.513817
global_step: 16097, epoch: 3, loss: 1.531932
global_step: 16098, epoch: 3, loss: 1.529859
global_step: 16099, epoch: 3, loss: 1.484751
global_step: 16100, epoch: 3, loss: 1.452686
global_step: 16101, epoch: 3, loss: 1.460880
global_step: 16102, epoch: 3, loss: 1.530709
global_step: 16103, epoch: 3, loss: 1.526186
global_step: 16104, epoch: 3, loss: 1.503618
global_step: 16105, epoch: 3, loss: 1.434703
global_step: 16106, epoch: 3, loss: 1.521025
global_step: 16107, epoch: 3, loss: 1.366170
global_step: 16108, epoch: 3, loss: 1.595820
global_step: 16109, epoch: 3, loss: 1.435315
global_step: 16110, epoch: 3, loss: 1.499578
global_step: 16111, epoch: 3, loss: 1.394690
global_step: 16112, epoch: 3, loss: 1.501908
global_step: 16113, epoch: 3, loss: 1.444315
global_step: 16114, epoch: 3, loss: 1.394018
global_step: 16115, epoch: 3, loss: 1.479241
global_step: 16116, epoch: 3, loss: 1.520811
global_step: 16117, epoch: 3, loss: 1.508282
global_step: 16118, epoch: 3, loss: 1.434096
global_step: 16119, epoch: 3, loss: 1.481323
global_step: 16120, epoch: 3, loss: 0.906102
epoch: 3
train	acc: 0.5052	macro: p 0.1296, r 0.1748, f1: 0.1396	micro: p 0.5052, r 0.5052, f1 0.5052	weighted_f1:0.3723
dev	acc: 0.4572	macro: p 0.1134, r 0.1781, f1: 0.1325	micro: p 0.4572, r 0.4572, f1 0.4572	weighted_f1:0.3142
test	acc: 0.5073	macro: p 0.1206, r 0.1723, f1: 0.1358	micro: p 0.5073, r 0.5073, f1 0.5073	weighted_f1:0.3721
New best model!
global_step: 16121, epoch: 4, loss: 1.498338
global_step: 16122, epoch: 4, loss: 1.440270
global_step: 16123, epoch: 4, loss: 1.475871
global_step: 16124, epoch: 4, loss: 1.353384
global_step: 16125, epoch: 4, loss: 1.468305
global_step: 16126, epoch: 4, loss: 1.467322
global_step: 16127, epoch: 4, loss: 1.482715
global_step: 16128, epoch: 4, loss: 1.470215
global_step: 16129, epoch: 4, loss: 1.485493
global_step: 16130, epoch: 4, loss: 1.395613
global_step: 16131, epoch: 4, loss: 1.470105
global_step: 16132, epoch: 4, loss: 1.448027
global_step: 16133, epoch: 4, loss: 1.398152
global_step: 16134, epoch: 4, loss: 1.298635
global_step: 16135, epoch: 4, loss: 1.397623
global_step: 16136, epoch: 4, loss: 1.351370
global_step: 16137, epoch: 4, loss: 1.493213
global_step: 16138, epoch: 4, loss: 1.374932
global_step: 16139, epoch: 4, loss: 1.494833
global_step: 16140, epoch: 4, loss: 1.412442
global_step: 16141, epoch: 4, loss: 1.447107
global_step: 16142, epoch: 4, loss: 1.384277
global_step: 16143, epoch: 4, loss: 1.409389
global_step: 16144, epoch: 4, loss: 1.494483
global_step: 16145, epoch: 4, loss: 1.313124
global_step: 16146, epoch: 4, loss: 1.445938
global_step: 16147, epoch: 4, loss: 1.445008
global_step: 16148, epoch: 4, loss: 1.448031
global_step: 16149, epoch: 4, loss: 1.374621
global_step: 16150, epoch: 4, loss: 1.439502
global_step: 16151, epoch: 4, loss: 1.426013
global_step: 16152, epoch: 4, loss: 1.450101
global_step: 16153, epoch: 4, loss: 1.445626
global_step: 16154, epoch: 4, loss: 1.422122
global_step: 16155, epoch: 4, loss: 1.355105
global_step: 16156, epoch: 4, loss: 1.369508
global_step: 16157, epoch: 4, loss: 1.339971
global_step: 16158, epoch: 4, loss: 1.367995
global_step: 16159, epoch: 4, loss: 1.435647
global_step: 16160, epoch: 4, loss: 1.239114
epoch: 4
train	acc: 0.5379	macro: p 0.1357, r 0.2097, f1: 0.1648	micro: p 0.5379, r 0.5379, f1 0.5379	weighted_f1:0.4218
dev	acc: 0.4815	macro: p 0.1199, r 0.2121, f1: 0.1530	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.3533
test	acc: 0.5444	macro: p 0.1353, r 0.2165, f1: 0.1663	micro: p 0.5444, r 0.5444, f1 0.5444	weighted_f1:0.4274
New best model!
global_step: 16161, epoch: 5, loss: 1.378647
global_step: 16162, epoch: 5, loss: 1.390673
global_step: 16163, epoch: 5, loss: 1.375930
global_step: 16164, epoch: 5, loss: 1.371904
global_step: 16165, epoch: 5, loss: 1.444098
global_step: 16166, epoch: 5, loss: 1.510360
global_step: 16167, epoch: 5, loss: 1.503537
global_step: 16168, epoch: 5, loss: 1.459060
global_step: 16169, epoch: 5, loss: 1.443525
global_step: 16170, epoch: 5, loss: 1.362667
global_step: 16171, epoch: 5, loss: 1.424031
global_step: 16172, epoch: 5, loss: 1.359845
global_step: 16173, epoch: 5, loss: 1.364502
global_step: 16174, epoch: 5, loss: 1.259058
global_step: 16175, epoch: 5, loss: 1.312843
global_step: 16176, epoch: 5, loss: 1.433099
global_step: 16177, epoch: 5, loss: 1.403879
global_step: 16178, epoch: 5, loss: 1.456976
global_step: 16179, epoch: 5, loss: 1.340242
global_step: 16180, epoch: 5, loss: 1.311955
global_step: 16181, epoch: 5, loss: 1.484100
global_step: 16182, epoch: 5, loss: 1.437047
global_step: 16183, epoch: 5, loss: 1.464926
global_step: 16184, epoch: 5, loss: 1.440249
global_step: 16185, epoch: 5, loss: 1.384947
global_step: 16186, epoch: 5, loss: 1.435847
global_step: 16187, epoch: 5, loss: 1.368904
global_step: 16188, epoch: 5, loss: 1.403017
global_step: 16189, epoch: 5, loss: 1.357683
global_step: 16190, epoch: 5, loss: 1.294805
global_step: 16191, epoch: 5, loss: 1.324443
global_step: 16192, epoch: 5, loss: 1.244207
global_step: 16193, epoch: 5, loss: 1.361238
global_step: 16194, epoch: 5, loss: 1.373792
global_step: 16195, epoch: 5, loss: 1.273719
global_step: 16196, epoch: 5, loss: 1.273400
global_step: 16197, epoch: 5, loss: 1.465407
global_step: 16198, epoch: 5, loss: 1.306781
global_step: 16199, epoch: 5, loss: 1.539120
global_step: 16200, epoch: 5, loss: 0.814710
epoch: 5
train	acc: 0.5414	macro: p 0.1376, r 0.2144, f1: 0.1676	micro: p 0.5414, r 0.5414, f1 0.5414	weighted_f1:0.4267
dev	acc: 0.4851	macro: p 0.1217, r 0.2162, f1: 0.1554	micro: p 0.4851, r 0.4851, f1 0.4851	weighted_f1:0.3571
test	acc: 0.5464	macro: p 0.1369, r 0.2207, f1: 0.1684	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4312
New best model!
global_step: 16201, epoch: 6, loss: 1.369976
global_step: 16202, epoch: 6, loss: 1.338032
global_step: 16203, epoch: 6, loss: 1.398677
global_step: 16204, epoch: 6, loss: 1.342362
global_step: 16205, epoch: 6, loss: 1.423300
global_step: 16206, epoch: 6, loss: 1.326021
global_step: 16207, epoch: 6, loss: 1.320297
global_step: 16208, epoch: 6, loss: 1.447411
global_step: 16209, epoch: 6, loss: 1.387910
global_step: 16210, epoch: 6, loss: 1.253387
global_step: 16211, epoch: 6, loss: 1.416909
global_step: 16212, epoch: 6, loss: 1.330841
global_step: 16213, epoch: 6, loss: 1.377678
global_step: 16214, epoch: 6, loss: 1.314984
global_step: 16215, epoch: 6, loss: 1.362392
global_step: 16216, epoch: 6, loss: 1.395752
global_step: 16217, epoch: 6, loss: 1.445835
global_step: 16218, epoch: 6, loss: 1.394308
global_step: 16219, epoch: 6, loss: 1.388636
global_step: 16220, epoch: 6, loss: 1.293532
global_step: 16221, epoch: 6, loss: 1.345760
global_step: 16222, epoch: 6, loss: 1.290635
global_step: 16223, epoch: 6, loss: 1.449536
global_step: 16224, epoch: 6, loss: 1.285805
global_step: 16225, epoch: 6, loss: 1.312682
global_step: 16226, epoch: 6, loss: 1.420373
global_step: 16227, epoch: 6, loss: 1.388385
global_step: 16228, epoch: 6, loss: 1.431239
global_step: 16229, epoch: 6, loss: 1.397586
global_step: 16230, epoch: 6, loss: 1.398291
global_step: 16231, epoch: 6, loss: 1.348154
global_step: 16232, epoch: 6, loss: 1.308872
global_step: 16233, epoch: 6, loss: 1.422598
global_step: 16234, epoch: 6, loss: 1.383142
global_step: 16235, epoch: 6, loss: 1.355107
global_step: 16236, epoch: 6, loss: 1.364723
global_step: 16237, epoch: 6, loss: 1.286012
global_step: 16238, epoch: 6, loss: 1.314396
global_step: 16239, epoch: 6, loss: 1.330027
global_step: 16240, epoch: 6, loss: 1.971222
epoch: 6
train	acc: 0.5485	macro: p 0.2657, r 0.2252, f1: 0.1849	micro: p 0.5485, r 0.5485, f1 0.5485	weighted_f1:0.4430
dev	acc: 0.5032	macro: p 0.2590, r 0.2353, f1: 0.1835	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.3869
test	acc: 0.5544	macro: p 0.2703, r 0.2343, f1: 0.1917	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.4502
New best model!
global_step: 16241, epoch: 7, loss: 1.317793
global_step: 16242, epoch: 7, loss: 1.442148
global_step: 16243, epoch: 7, loss: 1.285865
global_step: 16244, epoch: 7, loss: 1.413179
global_step: 16245, epoch: 7, loss: 1.359383
global_step: 16246, epoch: 7, loss: 1.293779
global_step: 16247, epoch: 7, loss: 1.454471
global_step: 16248, epoch: 7, loss: 1.395294
global_step: 16249, epoch: 7, loss: 1.423671
global_step: 16250, epoch: 7, loss: 1.335104
global_step: 16251, epoch: 7, loss: 1.355851
global_step: 16252, epoch: 7, loss: 1.258856
global_step: 16253, epoch: 7, loss: 1.502443
global_step: 16254, epoch: 7, loss: 1.404077
global_step: 16255, epoch: 7, loss: 1.414166
global_step: 16256, epoch: 7, loss: 1.233946
global_step: 16257, epoch: 7, loss: 1.348154
global_step: 16258, epoch: 7, loss: 1.305711
global_step: 16259, epoch: 7, loss: 1.283357
global_step: 16260, epoch: 7, loss: 1.285447
global_step: 16261, epoch: 7, loss: 1.224093
global_step: 16262, epoch: 7, loss: 1.439045
global_step: 16263, epoch: 7, loss: 1.352576
global_step: 16264, epoch: 7, loss: 1.372102
global_step: 16265, epoch: 7, loss: 1.412198
global_step: 16266, epoch: 7, loss: 1.300492
global_step: 16267, epoch: 7, loss: 1.297046
global_step: 16268, epoch: 7, loss: 1.376702
global_step: 16269, epoch: 7, loss: 1.327947
global_step: 16270, epoch: 7, loss: 1.222700
global_step: 16271, epoch: 7, loss: 1.301448
global_step: 16272, epoch: 7, loss: 1.341135
global_step: 16273, epoch: 7, loss: 1.367154
global_step: 16274, epoch: 7, loss: 1.471592
global_step: 16275, epoch: 7, loss: 1.321345
global_step: 16276, epoch: 7, loss: 1.303513
global_step: 16277, epoch: 7, loss: 1.399897
global_step: 16278, epoch: 7, loss: 1.375934
global_step: 16279, epoch: 7, loss: 1.313297
global_step: 16280, epoch: 7, loss: 2.426894
epoch: 7
train	acc: 0.5552	macro: p 0.3308, r 0.2329, f1: 0.1994	micro: p 0.5552, r 0.5552, f1 0.5552	weighted_f1:0.4557
dev	acc: 0.5077	macro: p 0.3923, r 0.2401, f1: 0.1932	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.3957
test	acc: 0.5586	macro: p 0.2561, r 0.2401, f1: 0.2019	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.4579
New best model!
global_step: 16281, epoch: 8, loss: 1.319476
global_step: 16282, epoch: 8, loss: 1.285411
global_step: 16283, epoch: 8, loss: 1.287827
global_step: 16284, epoch: 8, loss: 1.373527
global_step: 16285, epoch: 8, loss: 1.477030
global_step: 16286, epoch: 8, loss: 1.359179
global_step: 16287, epoch: 8, loss: 1.407907
global_step: 16288, epoch: 8, loss: 1.295621
global_step: 16289, epoch: 8, loss: 1.342319
global_step: 16290, epoch: 8, loss: 1.482921
global_step: 16291, epoch: 8, loss: 1.281519
global_step: 16292, epoch: 8, loss: 1.408943
global_step: 16293, epoch: 8, loss: 1.393542
global_step: 16294, epoch: 8, loss: 1.252847
global_step: 16295, epoch: 8, loss: 1.394091
global_step: 16296, epoch: 8, loss: 1.351684
global_step: 16297, epoch: 8, loss: 1.269023
global_step: 16298, epoch: 8, loss: 1.384041
global_step: 16299, epoch: 8, loss: 1.316467
global_step: 16300, epoch: 8, loss: 1.286187
global_step: 16301, epoch: 8, loss: 1.304916
global_step: 16302, epoch: 8, loss: 1.379650
global_step: 16303, epoch: 8, loss: 1.378172
global_step: 16304, epoch: 8, loss: 1.381696
global_step: 16305, epoch: 8, loss: 1.348042
global_step: 16306, epoch: 8, loss: 1.249973
global_step: 16307, epoch: 8, loss: 1.249787
global_step: 16308, epoch: 8, loss: 1.237228
global_step: 16309, epoch: 8, loss: 1.323799
global_step: 16310, epoch: 8, loss: 1.304165
global_step: 16311, epoch: 8, loss: 1.456743
global_step: 16312, epoch: 8, loss: 1.368713
global_step: 16313, epoch: 8, loss: 1.251755
global_step: 16314, epoch: 8, loss: 1.397176
global_step: 16315, epoch: 8, loss: 1.224417
global_step: 16316, epoch: 8, loss: 1.236079
global_step: 16317, epoch: 8, loss: 1.294974
global_step: 16318, epoch: 8, loss: 1.350881
global_step: 16319, epoch: 8, loss: 1.359101
global_step: 16320, epoch: 8, loss: 2.488128
epoch: 8
train	acc: 0.5580	macro: p 0.2986, r 0.2369, f1: 0.2057	micro: p 0.5580, r 0.5580, f1 0.5580	weighted_f1:0.4614
dev	acc: 0.5113	macro: p 0.3863, r 0.2438, f1: 0.1983	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4012
test	acc: 0.5621	macro: p 0.3932, r 0.2445, f1: 0.2089	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.4639
New best model!
global_step: 16321, epoch: 9, loss: 1.366968
global_step: 16322, epoch: 9, loss: 1.283861
global_step: 16323, epoch: 9, loss: 1.313500
global_step: 16324, epoch: 9, loss: 1.459148
global_step: 16325, epoch: 9, loss: 1.300242
global_step: 16326, epoch: 9, loss: 1.369430
global_step: 16327, epoch: 9, loss: 1.376176
global_step: 16328, epoch: 9, loss: 1.378068
global_step: 16329, epoch: 9, loss: 1.360988
global_step: 16330, epoch: 9, loss: 1.426293
global_step: 16331, epoch: 9, loss: 1.246465
global_step: 16332, epoch: 9, loss: 1.257028
global_step: 16333, epoch: 9, loss: 1.348547
global_step: 16334, epoch: 9, loss: 1.273099
global_step: 16335, epoch: 9, loss: 1.273021
global_step: 16336, epoch: 9, loss: 1.355529
global_step: 16337, epoch: 9, loss: 1.236120
global_step: 16338, epoch: 9, loss: 1.227135
global_step: 16339, epoch: 9, loss: 1.412342
global_step: 16340, epoch: 9, loss: 1.309760
global_step: 16341, epoch: 9, loss: 1.374431
global_step: 16342, epoch: 9, loss: 1.366385
global_step: 16343, epoch: 9, loss: 1.303106
global_step: 16344, epoch: 9, loss: 1.356134
global_step: 16345, epoch: 9, loss: 1.284889
global_step: 16346, epoch: 9, loss: 1.394903
global_step: 16347, epoch: 9, loss: 1.307045
global_step: 16348, epoch: 9, loss: 1.341814
global_step: 16349, epoch: 9, loss: 1.182549
global_step: 16350, epoch: 9, loss: 1.309518
global_step: 16351, epoch: 9, loss: 1.225204
global_step: 16352, epoch: 9, loss: 1.277922
global_step: 16353, epoch: 9, loss: 1.335952
global_step: 16354, epoch: 9, loss: 1.362046
global_step: 16355, epoch: 9, loss: 1.263358
global_step: 16356, epoch: 9, loss: 1.301774
global_step: 16357, epoch: 9, loss: 1.303379
global_step: 16358, epoch: 9, loss: 1.323986
global_step: 16359, epoch: 9, loss: 1.265622
global_step: 16360, epoch: 9, loss: 1.469040
epoch: 9
train	acc: 0.5599	macro: p 0.3052, r 0.2389, f1: 0.2092	micro: p 0.5599, r 0.5599, f1 0.5599	weighted_f1:0.4645
dev	acc: 0.5140	macro: p 0.3800, r 0.2467, f1: 0.2035	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4063
test	acc: 0.5640	macro: p 0.3214, r 0.2471, f1: 0.2127	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.4670
New best model!
global_step: 16361, epoch: 10, loss: 1.266274
global_step: 16362, epoch: 10, loss: 1.207900
global_step: 16363, epoch: 10, loss: 1.286561
global_step: 16364, epoch: 10, loss: 1.409854
global_step: 16365, epoch: 10, loss: 1.412277
global_step: 16366, epoch: 10, loss: 1.291656
global_step: 16367, epoch: 10, loss: 1.304857
global_step: 16368, epoch: 10, loss: 1.347320
global_step: 16369, epoch: 10, loss: 1.302287
global_step: 16370, epoch: 10, loss: 1.294229
global_step: 16371, epoch: 10, loss: 1.333208
global_step: 16372, epoch: 10, loss: 1.233576
global_step: 16373, epoch: 10, loss: 1.312325
global_step: 16374, epoch: 10, loss: 1.409145
global_step: 16375, epoch: 10, loss: 1.312441
global_step: 16376, epoch: 10, loss: 1.260019
global_step: 16377, epoch: 10, loss: 1.277232
global_step: 16378, epoch: 10, loss: 1.336865
global_step: 16379, epoch: 10, loss: 1.312731
global_step: 16380, epoch: 10, loss: 1.244233
global_step: 16381, epoch: 10, loss: 1.247132
global_step: 16382, epoch: 10, loss: 1.298966
global_step: 16383, epoch: 10, loss: 1.246392
global_step: 16384, epoch: 10, loss: 1.231278
global_step: 16385, epoch: 10, loss: 1.209787
global_step: 16386, epoch: 10, loss: 1.323933
global_step: 16387, epoch: 10, loss: 1.257530
global_step: 16388, epoch: 10, loss: 1.266280
global_step: 16389, epoch: 10, loss: 1.340255
global_step: 16390, epoch: 10, loss: 1.380353
global_step: 16391, epoch: 10, loss: 1.277606
global_step: 16392, epoch: 10, loss: 1.446209
global_step: 16393, epoch: 10, loss: 1.388135
global_step: 16394, epoch: 10, loss: 1.289026
global_step: 16395, epoch: 10, loss: 1.254872
global_step: 16396, epoch: 10, loss: 1.366375
global_step: 16397, epoch: 10, loss: 1.308799
global_step: 16398, epoch: 10, loss: 1.361025
global_step: 16399, epoch: 10, loss: 1.290656
global_step: 16400, epoch: 10, loss: 1.542120
epoch: 10
train	acc: 0.5739	macro: p 0.3291, r 0.2575, f1: 0.2421	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.4930
dev	acc: 0.5221	macro: p 0.2974, r 0.2552, f1: 0.2217	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4244
test	acc: 0.5774	macro: p 0.3281, r 0.2634, f1: 0.2443	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.4958
New best model!
global_step: 16401, epoch: 11, loss: 1.252902
global_step: 16402, epoch: 11, loss: 1.270209
global_step: 16403, epoch: 11, loss: 1.228891
global_step: 16404, epoch: 11, loss: 1.302281
global_step: 16405, epoch: 11, loss: 1.262833
global_step: 16406, epoch: 11, loss: 1.311200
global_step: 16407, epoch: 11, loss: 1.267633
global_step: 16408, epoch: 11, loss: 1.219979
global_step: 16409, epoch: 11, loss: 1.430324
global_step: 16410, epoch: 11, loss: 1.263198
global_step: 16411, epoch: 11, loss: 1.203387
global_step: 16412, epoch: 11, loss: 1.391236
global_step: 16413, epoch: 11, loss: 1.347419
global_step: 16414, epoch: 11, loss: 1.280832
global_step: 16415, epoch: 11, loss: 1.275315
global_step: 16416, epoch: 11, loss: 1.345202
global_step: 16417, epoch: 11, loss: 1.295871
global_step: 16418, epoch: 11, loss: 1.398888
global_step: 16419, epoch: 11, loss: 1.301136
global_step: 16420, epoch: 11, loss: 1.283028
global_step: 16421, epoch: 11, loss: 1.258488
global_step: 16422, epoch: 11, loss: 1.221899
global_step: 16423, epoch: 11, loss: 1.406900
global_step: 16424, epoch: 11, loss: 1.338061
global_step: 16425, epoch: 11, loss: 1.208940
global_step: 16426, epoch: 11, loss: 1.303211
global_step: 16427, epoch: 11, loss: 1.330797
global_step: 16428, epoch: 11, loss: 1.229014
global_step: 16429, epoch: 11, loss: 1.284912
global_step: 16430, epoch: 11, loss: 1.276758
global_step: 16431, epoch: 11, loss: 1.333039
global_step: 16432, epoch: 11, loss: 1.265519
global_step: 16433, epoch: 11, loss: 1.307393
global_step: 16434, epoch: 11, loss: 1.345184
global_step: 16435, epoch: 11, loss: 1.274580
global_step: 16436, epoch: 11, loss: 1.220147
global_step: 16437, epoch: 11, loss: 1.335971
global_step: 16438, epoch: 11, loss: 1.407828
global_step: 16439, epoch: 11, loss: 1.311275
global_step: 16440, epoch: 11, loss: 1.413954
epoch: 11
train	acc: 0.5723	macro: p 0.3241, r 0.2538, f1: 0.2353	micro: p 0.5723, r 0.5723, f1 0.5723	weighted_f1:0.4877
dev	acc: 0.5239	macro: p 0.2937, r 0.2572, f1: 0.2222	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4242
test	acc: 0.5774	macro: p 0.3225, r 0.2622, f1: 0.2394	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.4914
global_step: 16441, epoch: 12, loss: 1.299957
global_step: 16442, epoch: 12, loss: 1.293838
global_step: 16443, epoch: 12, loss: 1.379477
global_step: 16444, epoch: 12, loss: 1.242592
global_step: 16445, epoch: 12, loss: 1.237836
global_step: 16446, epoch: 12, loss: 1.376770
global_step: 16447, epoch: 12, loss: 1.276612
global_step: 16448, epoch: 12, loss: 1.290438
global_step: 16449, epoch: 12, loss: 1.356627
global_step: 16450, epoch: 12, loss: 1.340516
global_step: 16451, epoch: 12, loss: 1.288927
global_step: 16452, epoch: 12, loss: 1.275528
global_step: 16453, epoch: 12, loss: 1.185311
global_step: 16454, epoch: 12, loss: 1.236039
global_step: 16455, epoch: 12, loss: 1.179555
global_step: 16456, epoch: 12, loss: 1.390279
global_step: 16457, epoch: 12, loss: 1.333596
global_step: 16458, epoch: 12, loss: 1.270534
global_step: 16459, epoch: 12, loss: 1.238137
global_step: 16460, epoch: 12, loss: 1.281047
global_step: 16461, epoch: 12, loss: 1.346146
global_step: 16462, epoch: 12, loss: 1.255736
global_step: 16463, epoch: 12, loss: 1.407480
global_step: 16464, epoch: 12, loss: 1.316299
global_step: 16465, epoch: 12, loss: 1.244775
global_step: 16466, epoch: 12, loss: 1.309023
global_step: 16467, epoch: 12, loss: 1.246298
global_step: 16468, epoch: 12, loss: 1.233785
global_step: 16469, epoch: 12, loss: 1.217465
global_step: 16470, epoch: 12, loss: 1.293278
global_step: 16471, epoch: 12, loss: 1.280101
global_step: 16472, epoch: 12, loss: 1.173339
global_step: 16473, epoch: 12, loss: 1.407076
global_step: 16474, epoch: 12, loss: 1.182778
global_step: 16475, epoch: 12, loss: 1.251414
global_step: 16476, epoch: 12, loss: 1.171097
global_step: 16477, epoch: 12, loss: 1.394425
global_step: 16478, epoch: 12, loss: 1.244478
global_step: 16479, epoch: 12, loss: 1.258417
global_step: 16480, epoch: 12, loss: 1.585643
epoch: 12
train	acc: 0.5796	macro: p 0.3159, r 0.2650, f1: 0.2526	micro: p 0.5796, r 0.5796, f1 0.5796	weighted_f1:0.5029
dev	acc: 0.5320	macro: p 0.3101, r 0.2670, f1: 0.2389	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4411
test	acc: 0.5835	macro: p 0.3150, r 0.2718, f1: 0.2547	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5049
New best model!
global_step: 16481, epoch: 13, loss: 1.379102
global_step: 16482, epoch: 13, loss: 1.306526
global_step: 16483, epoch: 13, loss: 1.339775
global_step: 16484, epoch: 13, loss: 1.310266
global_step: 16485, epoch: 13, loss: 1.257696
global_step: 16486, epoch: 13, loss: 1.300700
global_step: 16487, epoch: 13, loss: 1.183079
global_step: 16488, epoch: 13, loss: 1.320427
global_step: 16489, epoch: 13, loss: 1.243873
global_step: 16490, epoch: 13, loss: 1.368013
global_step: 16491, epoch: 13, loss: 1.308973
global_step: 16492, epoch: 13, loss: 1.267071
global_step: 16493, epoch: 13, loss: 1.143276
global_step: 16494, epoch: 13, loss: 1.159170
global_step: 16495, epoch: 13, loss: 1.161519
global_step: 16496, epoch: 13, loss: 1.360313
global_step: 16497, epoch: 13, loss: 1.369494
global_step: 16498, epoch: 13, loss: 1.250657
global_step: 16499, epoch: 13, loss: 1.242741
global_step: 16500, epoch: 13, loss: 1.215353
global_step: 16501, epoch: 13, loss: 1.171115
global_step: 16502, epoch: 13, loss: 1.267164
global_step: 16503, epoch: 13, loss: 1.165063
global_step: 16504, epoch: 13, loss: 1.232466
global_step: 16505, epoch: 13, loss: 1.184836
global_step: 16506, epoch: 13, loss: 1.181544
global_step: 16507, epoch: 13, loss: 1.275781
global_step: 16508, epoch: 13, loss: 1.332376
global_step: 16509, epoch: 13, loss: 1.323150
global_step: 16510, epoch: 13, loss: 1.264865
global_step: 16511, epoch: 13, loss: 1.286312
global_step: 16512, epoch: 13, loss: 1.286433
global_step: 16513, epoch: 13, loss: 1.260644
global_step: 16514, epoch: 13, loss: 1.281953
global_step: 16515, epoch: 13, loss: 1.225600
global_step: 16516, epoch: 13, loss: 1.285159
global_step: 16517, epoch: 13, loss: 1.302338
global_step: 16518, epoch: 13, loss: 1.304651
global_step: 16519, epoch: 13, loss: 1.248445
global_step: 16520, epoch: 13, loss: 0.616456
epoch: 13
train	acc: 0.5742	macro: p 0.3368, r 0.2557, f1: 0.2339	micro: p 0.5742, r 0.5742, f1 0.5742	weighted_f1:0.4880
dev	acc: 0.5239	macro: p 0.3171, r 0.2584, f1: 0.2204	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4232
test	acc: 0.5743	macro: p 0.3217, r 0.2601, f1: 0.2322	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.4845
global_step: 16521, epoch: 14, loss: 1.244414
global_step: 16522, epoch: 14, loss: 1.299359
global_step: 16523, epoch: 14, loss: 1.382025
global_step: 16524, epoch: 14, loss: 1.305398
global_step: 16525, epoch: 14, loss: 1.313037
global_step: 16526, epoch: 14, loss: 1.380023
global_step: 16527, epoch: 14, loss: 1.250750
global_step: 16528, epoch: 14, loss: 1.289183
global_step: 16529, epoch: 14, loss: 1.257024
global_step: 16530, epoch: 14, loss: 1.287599
global_step: 16531, epoch: 14, loss: 1.204003
global_step: 16532, epoch: 14, loss: 1.291410
global_step: 16533, epoch: 14, loss: 1.344945
global_step: 16534, epoch: 14, loss: 1.217029
global_step: 16535, epoch: 14, loss: 1.299308
global_step: 16536, epoch: 14, loss: 1.336904
global_step: 16537, epoch: 14, loss: 1.152091
global_step: 16538, epoch: 14, loss: 1.115285
global_step: 16539, epoch: 14, loss: 1.174285
global_step: 16540, epoch: 14, loss: 1.202968
global_step: 16541, epoch: 14, loss: 1.255304
global_step: 16542, epoch: 14, loss: 1.158406
global_step: 16543, epoch: 14, loss: 1.256795
global_step: 16544, epoch: 14, loss: 1.252523
global_step: 16545, epoch: 14, loss: 1.267837
global_step: 16546, epoch: 14, loss: 1.137396
global_step: 16547, epoch: 14, loss: 1.275357
global_step: 16548, epoch: 14, loss: 1.264356
global_step: 16549, epoch: 14, loss: 1.247687
global_step: 16550, epoch: 14, loss: 1.318706
global_step: 16551, epoch: 14, loss: 1.316684
global_step: 16552, epoch: 14, loss: 1.258997
global_step: 16553, epoch: 14, loss: 1.296733
global_step: 16554, epoch: 14, loss: 1.302011
global_step: 16555, epoch: 14, loss: 1.347056
global_step: 16556, epoch: 14, loss: 1.268457
global_step: 16557, epoch: 14, loss: 1.213632
global_step: 16558, epoch: 14, loss: 1.262657
global_step: 16559, epoch: 14, loss: 1.207753
global_step: 16560, epoch: 14, loss: 1.508988
epoch: 14
train	acc: 0.5873	macro: p 0.3115, r 0.2765, f1: 0.2657	micro: p 0.5873, r 0.5873, f1 0.5873	weighted_f1:0.5154
dev	acc: 0.5338	macro: p 0.2936, r 0.2735, f1: 0.2459	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4468
test	acc: 0.5877	macro: p 0.3048, r 0.2805, f1: 0.2628	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5123
New best model!
global_step: 16561, epoch: 15, loss: 1.249796
global_step: 16562, epoch: 15, loss: 1.228560
global_step: 16563, epoch: 15, loss: 1.204543
global_step: 16564, epoch: 15, loss: 1.370023
global_step: 16565, epoch: 15, loss: 1.282665
global_step: 16566, epoch: 15, loss: 1.149480
global_step: 16567, epoch: 15, loss: 1.313047
global_step: 16568, epoch: 15, loss: 1.298597
global_step: 16569, epoch: 15, loss: 1.122616
global_step: 16570, epoch: 15, loss: 1.161989
global_step: 16571, epoch: 15, loss: 1.248485
global_step: 16572, epoch: 15, loss: 1.247815
global_step: 16573, epoch: 15, loss: 1.250917
global_step: 16574, epoch: 15, loss: 1.100771
global_step: 16575, epoch: 15, loss: 1.325009
global_step: 16576, epoch: 15, loss: 1.293305
global_step: 16577, epoch: 15, loss: 1.311691
global_step: 16578, epoch: 15, loss: 1.284235
global_step: 16579, epoch: 15, loss: 1.292414
global_step: 16580, epoch: 15, loss: 1.266435
global_step: 16581, epoch: 15, loss: 1.258668
global_step: 16582, epoch: 15, loss: 1.301780
global_step: 16583, epoch: 15, loss: 1.283676
global_step: 16584, epoch: 15, loss: 1.275713
global_step: 16585, epoch: 15, loss: 1.219470
global_step: 16586, epoch: 15, loss: 1.197854
global_step: 16587, epoch: 15, loss: 1.425061
global_step: 16588, epoch: 15, loss: 1.284243
global_step: 16589, epoch: 15, loss: 1.232462
global_step: 16590, epoch: 15, loss: 1.296550
global_step: 16591, epoch: 15, loss: 1.191176
global_step: 16592, epoch: 15, loss: 1.284835
global_step: 16593, epoch: 15, loss: 1.200699
global_step: 16594, epoch: 15, loss: 1.183467
global_step: 16595, epoch: 15, loss: 1.304702
global_step: 16596, epoch: 15, loss: 1.263359
global_step: 16597, epoch: 15, loss: 1.165456
global_step: 16598, epoch: 15, loss: 1.121461
global_step: 16599, epoch: 15, loss: 1.129854
global_step: 16600, epoch: 15, loss: 0.774470
epoch: 15
train	acc: 0.5912	macro: p 0.3117, r 0.2809, f1: 0.2744	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5220
dev	acc: 0.5392	macro: p 0.2946, r 0.2775, f1: 0.2563	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4571
test	acc: 0.5904	macro: p 0.3039, r 0.2829, f1: 0.2706	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5188
New best model!
global_step: 16601, epoch: 16, loss: 1.234385
global_step: 16602, epoch: 16, loss: 1.208694
global_step: 16603, epoch: 16, loss: 1.369484
global_step: 16604, epoch: 16, loss: 1.161385
global_step: 16605, epoch: 16, loss: 1.261859
global_step: 16606, epoch: 16, loss: 1.200488
global_step: 16607, epoch: 16, loss: 1.338928
global_step: 16608, epoch: 16, loss: 1.238167
global_step: 16609, epoch: 16, loss: 1.356817
global_step: 16610, epoch: 16, loss: 1.373560
global_step: 16611, epoch: 16, loss: 1.269993
global_step: 16612, epoch: 16, loss: 1.291075
global_step: 16613, epoch: 16, loss: 1.173305
global_step: 16614, epoch: 16, loss: 1.195133
global_step: 16615, epoch: 16, loss: 1.329278
global_step: 16616, epoch: 16, loss: 1.232248
global_step: 16617, epoch: 16, loss: 1.209513
global_step: 16618, epoch: 16, loss: 1.240684
global_step: 16619, epoch: 16, loss: 1.228847
global_step: 16620, epoch: 16, loss: 1.239909
global_step: 16621, epoch: 16, loss: 1.199536
global_step: 16622, epoch: 16, loss: 1.183640
global_step: 16623, epoch: 16, loss: 1.270430
global_step: 16624, epoch: 16, loss: 1.193553
global_step: 16625, epoch: 16, loss: 1.194052
global_step: 16626, epoch: 16, loss: 1.212880
global_step: 16627, epoch: 16, loss: 1.191810
global_step: 16628, epoch: 16, loss: 1.239012
global_step: 16629, epoch: 16, loss: 1.221485
global_step: 16630, epoch: 16, loss: 1.145246
global_step: 16631, epoch: 16, loss: 1.184309
global_step: 16632, epoch: 16, loss: 1.228434
global_step: 16633, epoch: 16, loss: 1.158646
global_step: 16634, epoch: 16, loss: 1.227111
global_step: 16635, epoch: 16, loss: 1.328789
global_step: 16636, epoch: 16, loss: 1.116162
global_step: 16637, epoch: 16, loss: 1.229160
global_step: 16638, epoch: 16, loss: 1.293820
global_step: 16639, epoch: 16, loss: 1.311080
global_step: 16640, epoch: 16, loss: 1.183991
epoch: 16
train	acc: 0.5962	macro: p 0.4301, r 0.2886, f1: 0.2802	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5296
dev	acc: 0.5419	macro: p 0.2917, r 0.2828, f1: 0.2561	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4587
test	acc: 0.5912	macro: p 0.4119, r 0.2890, f1: 0.2761	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5235
New best model!
global_step: 16641, epoch: 17, loss: 1.399047
global_step: 16642, epoch: 17, loss: 1.265916
global_step: 16643, epoch: 17, loss: 1.283955
global_step: 16644, epoch: 17, loss: 1.176238
global_step: 16645, epoch: 17, loss: 1.384947
global_step: 16646, epoch: 17, loss: 1.191693
global_step: 16647, epoch: 17, loss: 1.298225
global_step: 16648, epoch: 17, loss: 1.121384
global_step: 16649, epoch: 17, loss: 1.259049
global_step: 16650, epoch: 17, loss: 1.225756
global_step: 16651, epoch: 17, loss: 1.287920
global_step: 16652, epoch: 17, loss: 1.268259
global_step: 16653, epoch: 17, loss: 1.195378
global_step: 16654, epoch: 17, loss: 1.152172
global_step: 16655, epoch: 17, loss: 1.078201
global_step: 16656, epoch: 17, loss: 1.213793
global_step: 16657, epoch: 17, loss: 1.251121
global_step: 16658, epoch: 17, loss: 1.315273
global_step: 16659, epoch: 17, loss: 1.279710
global_step: 16660, epoch: 17, loss: 1.208513
global_step: 16661, epoch: 17, loss: 1.289370
global_step: 16662, epoch: 17, loss: 1.140428
global_step: 16663, epoch: 17, loss: 1.195256
global_step: 16664, epoch: 17, loss: 1.153394
global_step: 16665, epoch: 17, loss: 1.198776
global_step: 16666, epoch: 17, loss: 1.326931
global_step: 16667, epoch: 17, loss: 1.141014
global_step: 16668, epoch: 17, loss: 1.212203
global_step: 16669, epoch: 17, loss: 1.247717
global_step: 16670, epoch: 17, loss: 1.129590
global_step: 16671, epoch: 17, loss: 1.234399
global_step: 16672, epoch: 17, loss: 1.250043
global_step: 16673, epoch: 17, loss: 1.169029
global_step: 16674, epoch: 17, loss: 1.188227
global_step: 16675, epoch: 17, loss: 1.235611
global_step: 16676, epoch: 17, loss: 1.227275
global_step: 16677, epoch: 17, loss: 1.270253
global_step: 16678, epoch: 17, loss: 1.209442
global_step: 16679, epoch: 17, loss: 1.266737
global_step: 16680, epoch: 17, loss: 1.464880
epoch: 17
train	acc: 0.6028	macro: p 0.4200, r 0.2997, f1: 0.2929	micro: p 0.6028, r 0.6028, f1 0.6028	weighted_f1:0.5410
dev	acc: 0.5473	macro: p 0.2901, r 0.2906, f1: 0.2673	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4692
test	acc: 0.5943	macro: p 0.4058, r 0.2955, f1: 0.2830	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5300
New best model!
global_step: 16681, epoch: 18, loss: 1.170009
global_step: 16682, epoch: 18, loss: 1.123721
global_step: 16683, epoch: 18, loss: 1.168886
global_step: 16684, epoch: 18, loss: 1.256142
global_step: 16685, epoch: 18, loss: 1.267834
global_step: 16686, epoch: 18, loss: 1.214703
global_step: 16687, epoch: 18, loss: 1.154596
global_step: 16688, epoch: 18, loss: 1.178172
global_step: 16689, epoch: 18, loss: 1.236050
global_step: 16690, epoch: 18, loss: 1.172458
global_step: 16691, epoch: 18, loss: 1.242980
global_step: 16692, epoch: 18, loss: 1.163668
global_step: 16693, epoch: 18, loss: 1.142698
global_step: 16694, epoch: 18, loss: 1.289819
global_step: 16695, epoch: 18, loss: 1.193329
global_step: 16696, epoch: 18, loss: 1.151389
global_step: 16697, epoch: 18, loss: 1.248922
global_step: 16698, epoch: 18, loss: 1.188324
global_step: 16699, epoch: 18, loss: 1.152420
global_step: 16700, epoch: 18, loss: 1.184215
global_step: 16701, epoch: 18, loss: 1.135793
global_step: 16702, epoch: 18, loss: 1.254305
global_step: 16703, epoch: 18, loss: 1.276044
global_step: 16704, epoch: 18, loss: 1.221583
global_step: 16705, epoch: 18, loss: 1.253257
global_step: 16706, epoch: 18, loss: 1.209433
global_step: 16707, epoch: 18, loss: 1.239990
global_step: 16708, epoch: 18, loss: 1.119173
global_step: 16709, epoch: 18, loss: 1.266646
global_step: 16710, epoch: 18, loss: 1.231401
global_step: 16711, epoch: 18, loss: 1.282154
global_step: 16712, epoch: 18, loss: 1.165242
global_step: 16713, epoch: 18, loss: 1.109208
global_step: 16714, epoch: 18, loss: 1.225719
global_step: 16715, epoch: 18, loss: 1.245330
global_step: 16716, epoch: 18, loss: 1.381086
global_step: 16717, epoch: 18, loss: 1.328264
global_step: 16718, epoch: 18, loss: 1.317250
global_step: 16719, epoch: 18, loss: 1.299292
global_step: 16720, epoch: 18, loss: 0.996827
epoch: 18
train	acc: 0.6030	macro: p 0.4243, r 0.2957, f1: 0.2897	micro: p 0.6030, r 0.6030, f1 0.6030	weighted_f1:0.5379
dev	acc: 0.5464	macro: p 0.2954, r 0.2882, f1: 0.2640	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4659
test	acc: 0.5973	macro: p 0.4017, r 0.2951, f1: 0.2836	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5310
global_step: 16721, epoch: 19, loss: 1.157618
global_step: 16722, epoch: 19, loss: 1.210771
global_step: 16723, epoch: 19, loss: 1.306552
global_step: 16724, epoch: 19, loss: 1.272268
global_step: 16725, epoch: 19, loss: 1.228563
global_step: 16726, epoch: 19, loss: 1.189105
global_step: 16727, epoch: 19, loss: 1.239827
global_step: 16728, epoch: 19, loss: 1.133713
global_step: 16729, epoch: 19, loss: 1.254447
global_step: 16730, epoch: 19, loss: 1.266072
global_step: 16731, epoch: 19, loss: 1.233536
global_step: 16732, epoch: 19, loss: 1.263500
global_step: 16733, epoch: 19, loss: 1.185497
global_step: 16734, epoch: 19, loss: 1.151008
global_step: 16735, epoch: 19, loss: 1.196226
global_step: 16736, epoch: 19, loss: 1.311383
global_step: 16737, epoch: 19, loss: 1.284166
global_step: 16738, epoch: 19, loss: 1.108912
global_step: 16739, epoch: 19, loss: 1.120898
global_step: 16740, epoch: 19, loss: 1.232262
global_step: 16741, epoch: 19, loss: 1.126771
global_step: 16742, epoch: 19, loss: 1.197047
global_step: 16743, epoch: 19, loss: 1.095247
global_step: 16744, epoch: 19, loss: 1.167385
global_step: 16745, epoch: 19, loss: 1.192771
global_step: 16746, epoch: 19, loss: 1.107255
global_step: 16747, epoch: 19, loss: 1.188692
global_step: 16748, epoch: 19, loss: 1.216885
global_step: 16749, epoch: 19, loss: 1.160653
global_step: 16750, epoch: 19, loss: 1.184302
global_step: 16751, epoch: 19, loss: 1.209107
global_step: 16752, epoch: 19, loss: 1.212035
global_step: 16753, epoch: 19, loss: 1.202380
global_step: 16754, epoch: 19, loss: 1.262410
global_step: 16755, epoch: 19, loss: 1.248971
global_step: 16756, epoch: 19, loss: 1.270587
global_step: 16757, epoch: 19, loss: 1.217699
global_step: 16758, epoch: 19, loss: 1.190759
global_step: 16759, epoch: 19, loss: 1.202191
global_step: 16760, epoch: 19, loss: 0.962114
epoch: 19
train	acc: 0.6095	macro: p 0.4263, r 0.3066, f1: 0.3038	micro: p 0.6095, r 0.6095, f1 0.6095	weighted_f1:0.5501
dev	acc: 0.5473	macro: p 0.2828, r 0.2893, f1: 0.2718	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4731
test	acc: 0.6004	macro: p 0.4136, r 0.2996, f1: 0.2930	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5390
New best model!
global_step: 16761, epoch: 20, loss: 1.270327
global_step: 16762, epoch: 20, loss: 1.056688
global_step: 16763, epoch: 20, loss: 1.052975
global_step: 16764, epoch: 20, loss: 1.057027
global_step: 16765, epoch: 20, loss: 1.146538
global_step: 16766, epoch: 20, loss: 1.276507
global_step: 16767, epoch: 20, loss: 1.140521
global_step: 16768, epoch: 20, loss: 1.216227
global_step: 16769, epoch: 20, loss: 1.070527
global_step: 16770, epoch: 20, loss: 1.218915
global_step: 16771, epoch: 20, loss: 1.201072
global_step: 16772, epoch: 20, loss: 1.274804
global_step: 16773, epoch: 20, loss: 1.182223
global_step: 16774, epoch: 20, loss: 1.180435
global_step: 16775, epoch: 20, loss: 1.227420
global_step: 16776, epoch: 20, loss: 1.236615
global_step: 16777, epoch: 20, loss: 1.099208
global_step: 16778, epoch: 20, loss: 1.334806
global_step: 16779, epoch: 20, loss: 1.192852
global_step: 16780, epoch: 20, loss: 1.335255
global_step: 16781, epoch: 20, loss: 1.217145
global_step: 16782, epoch: 20, loss: 1.186632
global_step: 16783, epoch: 20, loss: 1.190951
global_step: 16784, epoch: 20, loss: 1.182024
global_step: 16785, epoch: 20, loss: 1.243915
global_step: 16786, epoch: 20, loss: 1.121641
global_step: 16787, epoch: 20, loss: 1.231609
global_step: 16788, epoch: 20, loss: 1.286663
global_step: 16789, epoch: 20, loss: 1.268834
global_step: 16790, epoch: 20, loss: 1.257243
global_step: 16791, epoch: 20, loss: 1.232264
global_step: 16792, epoch: 20, loss: 1.157660
global_step: 16793, epoch: 20, loss: 1.323486
global_step: 16794, epoch: 20, loss: 1.223296
global_step: 16795, epoch: 20, loss: 1.172856
global_step: 16796, epoch: 20, loss: 1.191632
global_step: 16797, epoch: 20, loss: 1.115871
global_step: 16798, epoch: 20, loss: 1.182753
global_step: 16799, epoch: 20, loss: 1.108304
global_step: 16800, epoch: 20, loss: 1.882892
epoch: 20
train	acc: 0.6128	macro: p 0.3968, r 0.3108, f1: 0.3103	micro: p 0.6128, r 0.6128, f1 0.6128	weighted_f1:0.5554
dev	acc: 0.5482	macro: p 0.3553, r 0.2912, f1: 0.2742	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4747
test	acc: 0.6027	macro: p 0.3945, r 0.3020, f1: 0.2961	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5425
New best model!
global_step: 16801, epoch: 21, loss: 1.248410
global_step: 16802, epoch: 21, loss: 1.186795
global_step: 16803, epoch: 21, loss: 1.108775
global_step: 16804, epoch: 21, loss: 1.344633
global_step: 16805, epoch: 21, loss: 1.194770
global_step: 16806, epoch: 21, loss: 1.197466
global_step: 16807, epoch: 21, loss: 1.170768
global_step: 16808, epoch: 21, loss: 1.243827
global_step: 16809, epoch: 21, loss: 1.238755
global_step: 16810, epoch: 21, loss: 1.234752
global_step: 16811, epoch: 21, loss: 1.280250
global_step: 16812, epoch: 21, loss: 1.161806
global_step: 16813, epoch: 21, loss: 1.170272
global_step: 16814, epoch: 21, loss: 1.163588
global_step: 16815, epoch: 21, loss: 1.253713
global_step: 16816, epoch: 21, loss: 1.147858
global_step: 16817, epoch: 21, loss: 1.103947
global_step: 16818, epoch: 21, loss: 1.154449
global_step: 16819, epoch: 21, loss: 1.080015
global_step: 16820, epoch: 21, loss: 1.214789
global_step: 16821, epoch: 21, loss: 1.179785
global_step: 16822, epoch: 21, loss: 1.147334
global_step: 16823, epoch: 21, loss: 1.160013
global_step: 16824, epoch: 21, loss: 1.120973
global_step: 16825, epoch: 21, loss: 1.177181
global_step: 16826, epoch: 21, loss: 1.217881
global_step: 16827, epoch: 21, loss: 1.159642
global_step: 16828, epoch: 21, loss: 1.285059
global_step: 16829, epoch: 21, loss: 1.164576
global_step: 16830, epoch: 21, loss: 1.228302
global_step: 16831, epoch: 21, loss: 1.093279
global_step: 16832, epoch: 21, loss: 1.179479
global_step: 16833, epoch: 21, loss: 1.181865
global_step: 16834, epoch: 21, loss: 1.104989
global_step: 16835, epoch: 21, loss: 1.266248
global_step: 16836, epoch: 21, loss: 1.220156
global_step: 16837, epoch: 21, loss: 1.282441
global_step: 16838, epoch: 21, loss: 1.186722
global_step: 16839, epoch: 21, loss: 1.100000
global_step: 16840, epoch: 21, loss: 1.142993
epoch: 21
train	acc: 0.6122	macro: p 0.4139, r 0.3075, f1: 0.3050	micro: p 0.6122, r 0.6122, f1 0.6122	weighted_f1:0.5520
dev	acc: 0.5455	macro: p 0.2831, r 0.2883, f1: 0.2677	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4690
test	acc: 0.6023	macro: p 0.4198, r 0.3003, f1: 0.2934	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5402
global_step: 16841, epoch: 22, loss: 1.196210
global_step: 16842, epoch: 22, loss: 1.235132
global_step: 16843, epoch: 22, loss: 1.129221
global_step: 16844, epoch: 22, loss: 1.202884
global_step: 16845, epoch: 22, loss: 1.186287
global_step: 16846, epoch: 22, loss: 1.131188
global_step: 16847, epoch: 22, loss: 1.169175
global_step: 16848, epoch: 22, loss: 1.134143
global_step: 16849, epoch: 22, loss: 1.169393
global_step: 16850, epoch: 22, loss: 1.155517
global_step: 16851, epoch: 22, loss: 1.282342
global_step: 16852, epoch: 22, loss: 1.215218
global_step: 16853, epoch: 22, loss: 1.105533
global_step: 16854, epoch: 22, loss: 1.051899
global_step: 16855, epoch: 22, loss: 1.191849
global_step: 16856, epoch: 22, loss: 1.193589
global_step: 16857, epoch: 22, loss: 1.088808
global_step: 16858, epoch: 22, loss: 1.084792
global_step: 16859, epoch: 22, loss: 1.197648
global_step: 16860, epoch: 22, loss: 1.071902
global_step: 16861, epoch: 22, loss: 1.172717
global_step: 16862, epoch: 22, loss: 1.260107
global_step: 16863, epoch: 22, loss: 1.340270
global_step: 16864, epoch: 22, loss: 1.180972
global_step: 16865, epoch: 22, loss: 1.058724
global_step: 16866, epoch: 22, loss: 1.130909
global_step: 16867, epoch: 22, loss: 1.301018
global_step: 16868, epoch: 22, loss: 1.146889
global_step: 16869, epoch: 22, loss: 1.303623
global_step: 16870, epoch: 22, loss: 1.138111
global_step: 16871, epoch: 22, loss: 1.184363
global_step: 16872, epoch: 22, loss: 1.244344
global_step: 16873, epoch: 22, loss: 1.161795
global_step: 16874, epoch: 22, loss: 1.193608
global_step: 16875, epoch: 22, loss: 1.211502
global_step: 16876, epoch: 22, loss: 1.186430
global_step: 16877, epoch: 22, loss: 1.181675
global_step: 16878, epoch: 22, loss: 1.240864
global_step: 16879, epoch: 22, loss: 1.133738
global_step: 16880, epoch: 22, loss: 1.282667
epoch: 22
train	acc: 0.6135	macro: p 0.4215, r 0.3078, f1: 0.3058	micro: p 0.6135, r 0.6135, f1 0.6135	weighted_f1:0.5527
dev	acc: 0.5455	macro: p 0.3553, r 0.2867, f1: 0.2665	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4679
test	acc: 0.6023	macro: p 0.4034, r 0.2998, f1: 0.2928	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5391
global_step: 16881, epoch: 23, loss: 1.210790
global_step: 16882, epoch: 23, loss: 1.117867
global_step: 16883, epoch: 23, loss: 1.195538
global_step: 16884, epoch: 23, loss: 1.202471
global_step: 16885, epoch: 23, loss: 1.059691
global_step: 16886, epoch: 23, loss: 1.122133
global_step: 16887, epoch: 23, loss: 1.191142
global_step: 16888, epoch: 23, loss: 1.178133
global_step: 16889, epoch: 23, loss: 1.200632
global_step: 16890, epoch: 23, loss: 1.177531
global_step: 16891, epoch: 23, loss: 1.045387
global_step: 16892, epoch: 23, loss: 1.224352
global_step: 16893, epoch: 23, loss: 1.119519
global_step: 16894, epoch: 23, loss: 1.171121
global_step: 16895, epoch: 23, loss: 1.212326
global_step: 16896, epoch: 23, loss: 1.163691
global_step: 16897, epoch: 23, loss: 1.140504
global_step: 16898, epoch: 23, loss: 1.172314
global_step: 16899, epoch: 23, loss: 1.173868
global_step: 16900, epoch: 23, loss: 1.080685
global_step: 16901, epoch: 23, loss: 1.249815
global_step: 16902, epoch: 23, loss: 1.115212
global_step: 16903, epoch: 23, loss: 1.096691
global_step: 16904, epoch: 23, loss: 1.213416
global_step: 16905, epoch: 23, loss: 1.116010
global_step: 16906, epoch: 23, loss: 1.295524
global_step: 16907, epoch: 23, loss: 1.181190
global_step: 16908, epoch: 23, loss: 1.172870
global_step: 16909, epoch: 23, loss: 1.229973
global_step: 16910, epoch: 23, loss: 1.196120
global_step: 16911, epoch: 23, loss: 1.155977
global_step: 16912, epoch: 23, loss: 1.060595
global_step: 16913, epoch: 23, loss: 1.284677
global_step: 16914, epoch: 23, loss: 1.110457
global_step: 16915, epoch: 23, loss: 1.074591
global_step: 16916, epoch: 23, loss: 1.294552
global_step: 16917, epoch: 23, loss: 1.128492
global_step: 16918, epoch: 23, loss: 1.232111
global_step: 16919, epoch: 23, loss: 1.202890
global_step: 16920, epoch: 23, loss: 1.022418
epoch: 23
train	acc: 0.6158	macro: p 0.4200, r 0.3088, f1: 0.3092	micro: p 0.6158, r 0.6158, f1 0.6158	weighted_f1:0.5544
dev	acc: 0.5491	macro: p 0.3629, r 0.2886, f1: 0.2742	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4731
test	acc: 0.6069	macro: p 0.3980, r 0.3018, f1: 0.2978	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5432
global_step: 16921, epoch: 24, loss: 1.183791
global_step: 16922, epoch: 24, loss: 1.188008
global_step: 16923, epoch: 24, loss: 1.112118
global_step: 16924, epoch: 24, loss: 1.151210
global_step: 16925, epoch: 24, loss: 1.029427
global_step: 16926, epoch: 24, loss: 1.253645
global_step: 16927, epoch: 24, loss: 1.098556
global_step: 16928, epoch: 24, loss: 1.163470
global_step: 16929, epoch: 24, loss: 1.211185
global_step: 16930, epoch: 24, loss: 1.167312
global_step: 16931, epoch: 24, loss: 1.058128
global_step: 16932, epoch: 24, loss: 1.108043
global_step: 16933, epoch: 24, loss: 1.149281
global_step: 16934, epoch: 24, loss: 1.232105
global_step: 16935, epoch: 24, loss: 1.140083
global_step: 16936, epoch: 24, loss: 1.098389
global_step: 16937, epoch: 24, loss: 1.194990
global_step: 16938, epoch: 24, loss: 1.131615
global_step: 16939, epoch: 24, loss: 1.211371
global_step: 16940, epoch: 24, loss: 1.236038
global_step: 16941, epoch: 24, loss: 1.157914
global_step: 16942, epoch: 24, loss: 1.218783
global_step: 16943, epoch: 24, loss: 1.250398
global_step: 16944, epoch: 24, loss: 1.159127
global_step: 16945, epoch: 24, loss: 1.084994
global_step: 16946, epoch: 24, loss: 1.243434
global_step: 16947, epoch: 24, loss: 1.260458
global_step: 16948, epoch: 24, loss: 1.206957
global_step: 16949, epoch: 24, loss: 1.200039
global_step: 16950, epoch: 24, loss: 1.122713
global_step: 16951, epoch: 24, loss: 1.164740
global_step: 16952, epoch: 24, loss: 1.079558
global_step: 16953, epoch: 24, loss: 1.153735
global_step: 16954, epoch: 24, loss: 1.156169
global_step: 16955, epoch: 24, loss: 1.160299
global_step: 16956, epoch: 24, loss: 1.107366
global_step: 16957, epoch: 24, loss: 1.308562
global_step: 16958, epoch: 24, loss: 1.197372
global_step: 16959, epoch: 24, loss: 1.058181
global_step: 16960, epoch: 24, loss: 2.267896
epoch: 24
train	acc: 0.6299	macro: p 0.3953, r 0.3405, f1: 0.3418	micro: p 0.6299, r 0.6299, f1 0.6299	weighted_f1:0.5831
dev	acc: 0.5636	macro: p 0.3544, r 0.3129, f1: 0.3008	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5015
test	acc: 0.6123	macro: p 0.3892, r 0.3249, f1: 0.3212	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5626
New best model!
global_step: 16961, epoch: 25, loss: 1.155507
global_step: 16962, epoch: 25, loss: 1.119118
global_step: 16963, epoch: 25, loss: 1.225709
global_step: 16964, epoch: 25, loss: 1.064611
global_step: 16965, epoch: 25, loss: 1.144482
global_step: 16966, epoch: 25, loss: 1.103351
global_step: 16967, epoch: 25, loss: 1.177843
global_step: 16968, epoch: 25, loss: 1.257512
global_step: 16969, epoch: 25, loss: 1.194206
global_step: 16970, epoch: 25, loss: 1.180619
global_step: 16971, epoch: 25, loss: 1.314741
global_step: 16972, epoch: 25, loss: 1.142833
global_step: 16973, epoch: 25, loss: 1.106456
global_step: 16974, epoch: 25, loss: 1.228550
global_step: 16975, epoch: 25, loss: 1.163553
global_step: 16976, epoch: 25, loss: 1.188428
global_step: 16977, epoch: 25, loss: 1.132847
global_step: 16978, epoch: 25, loss: 1.028168
global_step: 16979, epoch: 25, loss: 1.106490
global_step: 16980, epoch: 25, loss: 1.217235
global_step: 16981, epoch: 25, loss: 1.018962
global_step: 16982, epoch: 25, loss: 1.226014
global_step: 16983, epoch: 25, loss: 0.993389
global_step: 16984, epoch: 25, loss: 1.203529
global_step: 16985, epoch: 25, loss: 1.255404
global_step: 16986, epoch: 25, loss: 1.150726
global_step: 16987, epoch: 25, loss: 1.093810
global_step: 16988, epoch: 25, loss: 1.075153
global_step: 16989, epoch: 25, loss: 1.191926
global_step: 16990, epoch: 25, loss: 1.187500
global_step: 16991, epoch: 25, loss: 1.151587
global_step: 16992, epoch: 25, loss: 1.174640
global_step: 16993, epoch: 25, loss: 1.051808
global_step: 16994, epoch: 25, loss: 1.070040
global_step: 16995, epoch: 25, loss: 1.186115
global_step: 16996, epoch: 25, loss: 1.208040
global_step: 16997, epoch: 25, loss: 1.129790
global_step: 16998, epoch: 25, loss: 1.065636
global_step: 16999, epoch: 25, loss: 1.090029
global_step: 17000, epoch: 25, loss: 1.418665
epoch: 25
train	acc: 0.6294	macro: p 0.4058, r 0.3349, f1: 0.3390	micro: p 0.6294, r 0.6294, f1 0.6294	weighted_f1:0.5803
dev	acc: 0.5654	macro: p 0.3774, r 0.3130, f1: 0.3049	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5045
test	acc: 0.6111	macro: p 0.3911, r 0.3189, f1: 0.3180	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5594
New best model!
global_step: 17001, epoch: 26, loss: 1.240512
global_step: 17002, epoch: 26, loss: 1.157104
global_step: 17003, epoch: 26, loss: 1.056348
global_step: 17004, epoch: 26, loss: 1.170961
global_step: 17005, epoch: 26, loss: 1.083506
global_step: 17006, epoch: 26, loss: 1.188606
global_step: 17007, epoch: 26, loss: 1.017235
global_step: 17008, epoch: 26, loss: 1.120089
global_step: 17009, epoch: 26, loss: 1.209189
global_step: 17010, epoch: 26, loss: 1.204650
global_step: 17011, epoch: 26, loss: 1.101172
global_step: 17012, epoch: 26, loss: 1.085491
global_step: 17013, epoch: 26, loss: 1.071195
global_step: 17014, epoch: 26, loss: 1.208143
global_step: 17015, epoch: 26, loss: 1.159730
global_step: 17016, epoch: 26, loss: 1.100931
global_step: 17017, epoch: 26, loss: 1.081891
global_step: 17018, epoch: 26, loss: 1.088647
global_step: 17019, epoch: 26, loss: 1.192440
global_step: 17020, epoch: 26, loss: 1.284609
global_step: 17021, epoch: 26, loss: 1.165637
global_step: 17022, epoch: 26, loss: 1.221042
global_step: 17023, epoch: 26, loss: 1.063894
global_step: 17024, epoch: 26, loss: 1.122568
global_step: 17025, epoch: 26, loss: 1.044906
global_step: 17026, epoch: 26, loss: 1.162864
global_step: 17027, epoch: 26, loss: 0.989203
global_step: 17028, epoch: 26, loss: 1.184796
global_step: 17029, epoch: 26, loss: 1.153565
global_step: 17030, epoch: 26, loss: 1.159867
global_step: 17031, epoch: 26, loss: 1.233989
global_step: 17032, epoch: 26, loss: 1.156249
global_step: 17033, epoch: 26, loss: 1.222836
global_step: 17034, epoch: 26, loss: 1.213199
global_step: 17035, epoch: 26, loss: 1.191713
global_step: 17036, epoch: 26, loss: 1.045121
global_step: 17037, epoch: 26, loss: 1.145886
global_step: 17038, epoch: 26, loss: 1.087784
global_step: 17039, epoch: 26, loss: 1.143507
global_step: 17040, epoch: 26, loss: 0.867833
epoch: 26
train	acc: 0.6243	macro: p 0.4161, r 0.3250, f1: 0.3284	micro: p 0.6243, r 0.6243, f1 0.6243	weighted_f1:0.5707
dev	acc: 0.5627	macro: p 0.3863, r 0.3055, f1: 0.2998	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.4985
test	acc: 0.6111	macro: p 0.3986, r 0.3109, f1: 0.3115	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5548
global_step: 17041, epoch: 27, loss: 1.123253
global_step: 17042, epoch: 27, loss: 1.097018
global_step: 17043, epoch: 27, loss: 1.157982
global_step: 17044, epoch: 27, loss: 1.160278
global_step: 17045, epoch: 27, loss: 1.121234
global_step: 17046, epoch: 27, loss: 1.110612
global_step: 17047, epoch: 27, loss: 1.088163
global_step: 17048, epoch: 27, loss: 1.097988
global_step: 17049, epoch: 27, loss: 1.063950
global_step: 17050, epoch: 27, loss: 1.038428
global_step: 17051, epoch: 27, loss: 1.080157
global_step: 17052, epoch: 27, loss: 1.220119
global_step: 17053, epoch: 27, loss: 1.150167
global_step: 17054, epoch: 27, loss: 1.056576
global_step: 17055, epoch: 27, loss: 1.159255
global_step: 17056, epoch: 27, loss: 1.184599
global_step: 17057, epoch: 27, loss: 1.129691
global_step: 17058, epoch: 27, loss: 1.075857
global_step: 17059, epoch: 27, loss: 1.195105
global_step: 17060, epoch: 27, loss: 1.052469
global_step: 17061, epoch: 27, loss: 1.093213
global_step: 17062, epoch: 27, loss: 1.171686
global_step: 17063, epoch: 27, loss: 1.234636
global_step: 17064, epoch: 27, loss: 1.115872
global_step: 17065, epoch: 27, loss: 1.206390
global_step: 17066, epoch: 27, loss: 1.108759
global_step: 17067, epoch: 27, loss: 1.225613
global_step: 17068, epoch: 27, loss: 1.088980
global_step: 17069, epoch: 27, loss: 1.282106
global_step: 17070, epoch: 27, loss: 1.112917
global_step: 17071, epoch: 27, loss: 1.123033
global_step: 17072, epoch: 27, loss: 1.130102
global_step: 17073, epoch: 27, loss: 1.080437
global_step: 17074, epoch: 27, loss: 1.096563
global_step: 17075, epoch: 27, loss: 1.110862
global_step: 17076, epoch: 27, loss: 1.140249
global_step: 17077, epoch: 27, loss: 1.118554
global_step: 17078, epoch: 27, loss: 1.229761
global_step: 17079, epoch: 27, loss: 1.190372
global_step: 17080, epoch: 27, loss: 1.192402
epoch: 27
train	acc: 0.6395	macro: p 0.3938, r 0.3584, f1: 0.3580	micro: p 0.6395, r 0.6395, f1 0.6395	weighted_f1:0.5982
dev	acc: 0.5699	macro: p 0.3552, r 0.3280, f1: 0.3182	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5173
test	acc: 0.6031	macro: p 0.3659, r 0.3294, f1: 0.3240	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5606
New best model!
global_step: 17081, epoch: 28, loss: 1.062997
global_step: 17082, epoch: 28, loss: 1.111729
global_step: 17083, epoch: 28, loss: 1.210793
global_step: 17084, epoch: 28, loss: 1.232615
global_step: 17085, epoch: 28, loss: 1.110630
global_step: 17086, epoch: 28, loss: 1.171506
global_step: 17087, epoch: 28, loss: 1.104738
global_step: 17088, epoch: 28, loss: 1.111316
global_step: 17089, epoch: 28, loss: 0.981233
global_step: 17090, epoch: 28, loss: 1.180208
global_step: 17091, epoch: 28, loss: 1.003340
global_step: 17092, epoch: 28, loss: 1.212504
global_step: 17093, epoch: 28, loss: 1.138479
global_step: 17094, epoch: 28, loss: 1.227030
global_step: 17095, epoch: 28, loss: 1.129787
global_step: 17096, epoch: 28, loss: 1.113665
global_step: 17097, epoch: 28, loss: 1.136928
global_step: 17098, epoch: 28, loss: 1.076726
global_step: 17099, epoch: 28, loss: 1.102637
global_step: 17100, epoch: 28, loss: 1.026876
global_step: 17101, epoch: 28, loss: 1.273841
global_step: 17102, epoch: 28, loss: 1.059023
global_step: 17103, epoch: 28, loss: 1.198684
global_step: 17104, epoch: 28, loss: 1.110696
global_step: 17105, epoch: 28, loss: 1.096131
global_step: 17106, epoch: 28, loss: 1.138566
global_step: 17107, epoch: 28, loss: 1.095892
global_step: 17108, epoch: 28, loss: 1.176866
global_step: 17109, epoch: 28, loss: 1.221260
global_step: 17110, epoch: 28, loss: 1.100721
global_step: 17111, epoch: 28, loss: 1.162356
global_step: 17112, epoch: 28, loss: 1.086387
global_step: 17113, epoch: 28, loss: 1.166947
global_step: 17114, epoch: 28, loss: 1.225358
global_step: 17115, epoch: 28, loss: 1.141885
global_step: 17116, epoch: 28, loss: 0.980487
global_step: 17117, epoch: 28, loss: 1.066730
global_step: 17118, epoch: 28, loss: 1.021110
global_step: 17119, epoch: 28, loss: 1.129411
global_step: 17120, epoch: 28, loss: 1.596858
epoch: 28
train	acc: 0.6405	macro: p 0.4076, r 0.3485, f1: 0.3545	micro: p 0.6405, r 0.6405, f1 0.6405	weighted_f1:0.5943
dev	acc: 0.5681	macro: p 0.3790, r 0.3196, f1: 0.3114	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5089
test	acc: 0.6115	macro: p 0.3815, r 0.3239, f1: 0.3245	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5622
global_step: 17121, epoch: 29, loss: 1.075752
global_step: 17122, epoch: 29, loss: 1.061305
global_step: 17123, epoch: 29, loss: 1.140419
global_step: 17124, epoch: 29, loss: 1.247250
global_step: 17125, epoch: 29, loss: 1.128011
global_step: 17126, epoch: 29, loss: 1.131553
global_step: 17127, epoch: 29, loss: 1.203728
global_step: 17128, epoch: 29, loss: 1.172861
global_step: 17129, epoch: 29, loss: 1.076962
global_step: 17130, epoch: 29, loss: 1.136729
global_step: 17131, epoch: 29, loss: 1.058287
global_step: 17132, epoch: 29, loss: 1.219111
global_step: 17133, epoch: 29, loss: 1.065984
global_step: 17134, epoch: 29, loss: 1.138140
global_step: 17135, epoch: 29, loss: 0.973556
global_step: 17136, epoch: 29, loss: 1.144430
global_step: 17137, epoch: 29, loss: 1.125831
global_step: 17138, epoch: 29, loss: 1.149332
global_step: 17139, epoch: 29, loss: 1.138342
global_step: 17140, epoch: 29, loss: 1.067756
global_step: 17141, epoch: 29, loss: 1.116733
global_step: 17142, epoch: 29, loss: 0.988959
global_step: 17143, epoch: 29, loss: 1.022525
global_step: 17144, epoch: 29, loss: 1.125229
global_step: 17145, epoch: 29, loss: 1.102976
global_step: 17146, epoch: 29, loss: 1.109517
global_step: 17147, epoch: 29, loss: 1.176500
global_step: 17148, epoch: 29, loss: 1.033695
global_step: 17149, epoch: 29, loss: 1.198080
global_step: 17150, epoch: 29, loss: 1.196194
global_step: 17151, epoch: 29, loss: 1.073443
global_step: 17152, epoch: 29, loss: 1.146089
global_step: 17153, epoch: 29, loss: 1.140919
global_step: 17154, epoch: 29, loss: 0.979991
global_step: 17155, epoch: 29, loss: 1.057827
global_step: 17156, epoch: 29, loss: 1.107376
global_step: 17157, epoch: 29, loss: 1.201788
global_step: 17158, epoch: 29, loss: 1.161564
global_step: 17159, epoch: 29, loss: 1.029444
global_step: 17160, epoch: 29, loss: 2.223276
epoch: 29
train	acc: 0.6466	macro: p 0.4008, r 0.3717, f1: 0.3721	micro: p 0.6466, r 0.6466, f1 0.6466	weighted_f1:0.6109
dev	acc: 0.5663	macro: p 0.3574, r 0.3333, f1: 0.3268	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5220
test	acc: 0.5977	macro: p 0.3543, r 0.3317, f1: 0.3277	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5611
New best model!
global_step: 17161, epoch: 30, loss: 1.191130
global_step: 17162, epoch: 30, loss: 1.100093
global_step: 17163, epoch: 30, loss: 1.208300
global_step: 17164, epoch: 30, loss: 1.049977
global_step: 17165, epoch: 30, loss: 1.138095
global_step: 17166, epoch: 30, loss: 1.106680
global_step: 17167, epoch: 30, loss: 1.089746
global_step: 17168, epoch: 30, loss: 1.046166
global_step: 17169, epoch: 30, loss: 1.014895
global_step: 17170, epoch: 30, loss: 1.077976
global_step: 17171, epoch: 30, loss: 1.097526
global_step: 17172, epoch: 30, loss: 1.056164
global_step: 17173, epoch: 30, loss: 1.024438
global_step: 17174, epoch: 30, loss: 1.166319
global_step: 17175, epoch: 30, loss: 1.051467
global_step: 17176, epoch: 30, loss: 1.058528
global_step: 17177, epoch: 30, loss: 1.109716
global_step: 17178, epoch: 30, loss: 1.139512
global_step: 17179, epoch: 30, loss: 1.124849
global_step: 17180, epoch: 30, loss: 1.085009
global_step: 17181, epoch: 30, loss: 1.169769
global_step: 17182, epoch: 30, loss: 1.143982
global_step: 17183, epoch: 30, loss: 1.088535
global_step: 17184, epoch: 30, loss: 1.070512
global_step: 17185, epoch: 30, loss: 1.035268
global_step: 17186, epoch: 30, loss: 1.164031
global_step: 17187, epoch: 30, loss: 1.164325
global_step: 17188, epoch: 30, loss: 1.204732
global_step: 17189, epoch: 30, loss: 1.148730
global_step: 17190, epoch: 30, loss: 1.032248
global_step: 17191, epoch: 30, loss: 1.101107
global_step: 17192, epoch: 30, loss: 1.118984
global_step: 17193, epoch: 30, loss: 1.039672
global_step: 17194, epoch: 30, loss: 1.058446
global_step: 17195, epoch: 30, loss: 1.020599
global_step: 17196, epoch: 30, loss: 1.182195
global_step: 17197, epoch: 30, loss: 1.095333
global_step: 17198, epoch: 30, loss: 1.144814
global_step: 17199, epoch: 30, loss: 1.062485
global_step: 17200, epoch: 30, loss: 1.231062
epoch: 30
train	acc: 0.6436	macro: p 0.4128, r 0.3500, f1: 0.3553	micro: p 0.6436, r 0.6436, f1 0.6436	weighted_f1:0.5956
dev	acc: 0.5744	macro: p 0.3834, r 0.3220, f1: 0.3176	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5156
test	acc: 0.6142	macro: p 0.3864, r 0.3211, f1: 0.3214	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5621
global_step: 17201, epoch: 31, loss: 0.976617
global_step: 17202, epoch: 31, loss: 1.266566
global_step: 17203, epoch: 31, loss: 1.139053
global_step: 17204, epoch: 31, loss: 1.012477
global_step: 17205, epoch: 31, loss: 1.111701
global_step: 17206, epoch: 31, loss: 1.082452
global_step: 17207, epoch: 31, loss: 0.972929
global_step: 17208, epoch: 31, loss: 0.976926
global_step: 17209, epoch: 31, loss: 1.183806
global_step: 17210, epoch: 31, loss: 1.098469
global_step: 17211, epoch: 31, loss: 0.942514
global_step: 17212, epoch: 31, loss: 1.180225
global_step: 17213, epoch: 31, loss: 1.292297
global_step: 17214, epoch: 31, loss: 1.090976
global_step: 17215, epoch: 31, loss: 1.083561
global_step: 17216, epoch: 31, loss: 1.007967
global_step: 17217, epoch: 31, loss: 1.174947
global_step: 17218, epoch: 31, loss: 1.135628
global_step: 17219, epoch: 31, loss: 0.982171
global_step: 17220, epoch: 31, loss: 1.138979
global_step: 17221, epoch: 31, loss: 1.132142
global_step: 17222, epoch: 31, loss: 1.092833
global_step: 17223, epoch: 31, loss: 1.078157
global_step: 17224, epoch: 31, loss: 1.003045
global_step: 17225, epoch: 31, loss: 0.927030
global_step: 17226, epoch: 31, loss: 1.077735
global_step: 17227, epoch: 31, loss: 1.098249
global_step: 17228, epoch: 31, loss: 1.157814
global_step: 17229, epoch: 31, loss: 1.215968
global_step: 17230, epoch: 31, loss: 1.043055
global_step: 17231, epoch: 31, loss: 1.069719
global_step: 17232, epoch: 31, loss: 1.124357
global_step: 17233, epoch: 31, loss: 1.210759
global_step: 17234, epoch: 31, loss: 1.225952
global_step: 17235, epoch: 31, loss: 1.189083
global_step: 17236, epoch: 31, loss: 0.911629
global_step: 17237, epoch: 31, loss: 1.068433
global_step: 17238, epoch: 31, loss: 1.112364
global_step: 17239, epoch: 31, loss: 1.091616
global_step: 17240, epoch: 31, loss: 2.097039
epoch: 31
train	acc: 0.6488	macro: p 0.4209, r 0.3568, f1: 0.3648	micro: p 0.6488, r 0.6488, f1 0.6488	weighted_f1:0.6040
dev	acc: 0.5762	macro: p 0.3780, r 0.3256, f1: 0.3224	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5214
test	acc: 0.6130	macro: p 0.3770, r 0.3235, f1: 0.3268	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5650
global_step: 17241, epoch: 32, loss: 0.982770
global_step: 17242, epoch: 32, loss: 1.143863
global_step: 17243, epoch: 32, loss: 0.968751
global_step: 17244, epoch: 32, loss: 1.045323
global_step: 17245, epoch: 32, loss: 1.156736
global_step: 17246, epoch: 32, loss: 1.034479
global_step: 17247, epoch: 32, loss: 1.093699
global_step: 17248, epoch: 32, loss: 1.116187
global_step: 17249, epoch: 32, loss: 1.057246
global_step: 17250, epoch: 32, loss: 1.128197
global_step: 17251, epoch: 32, loss: 1.157738
global_step: 17252, epoch: 32, loss: 1.165100
global_step: 17253, epoch: 32, loss: 1.028485
global_step: 17254, epoch: 32, loss: 1.147684
global_step: 17255, epoch: 32, loss: 1.022702
global_step: 17256, epoch: 32, loss: 1.026016
global_step: 17257, epoch: 32, loss: 1.145774
global_step: 17258, epoch: 32, loss: 1.193974
global_step: 17259, epoch: 32, loss: 1.089520
global_step: 17260, epoch: 32, loss: 1.117902
global_step: 17261, epoch: 32, loss: 1.074325
global_step: 17262, epoch: 32, loss: 0.998133
global_step: 17263, epoch: 32, loss: 1.019524
global_step: 17264, epoch: 32, loss: 1.168457
global_step: 17265, epoch: 32, loss: 1.125433
global_step: 17266, epoch: 32, loss: 1.050402
global_step: 17267, epoch: 32, loss: 1.026148
global_step: 17268, epoch: 32, loss: 1.170779
global_step: 17269, epoch: 32, loss: 1.057663
global_step: 17270, epoch: 32, loss: 1.110381
global_step: 17271, epoch: 32, loss: 1.071715
global_step: 17272, epoch: 32, loss: 1.081844
global_step: 17273, epoch: 32, loss: 1.031894
global_step: 17274, epoch: 32, loss: 1.064422
global_step: 17275, epoch: 32, loss: 1.187172
global_step: 17276, epoch: 32, loss: 1.177695
global_step: 17277, epoch: 32, loss: 1.162405
global_step: 17278, epoch: 32, loss: 1.064093
global_step: 17279, epoch: 32, loss: 1.087385
global_step: 17280, epoch: 32, loss: 1.622371
epoch: 32
train	acc: 0.6524	macro: p 0.4154, r 0.3637, f1: 0.3715	micro: p 0.6524, r 0.6524, f1 0.6524	weighted_f1:0.6104
dev	acc: 0.5789	macro: p 0.3747, r 0.3317, f1: 0.3309	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5287
test	acc: 0.6100	macro: p 0.3704, r 0.3253, f1: 0.3290	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5650
New best model!
global_step: 17281, epoch: 33, loss: 1.101591
global_step: 17282, epoch: 33, loss: 1.016801
global_step: 17283, epoch: 33, loss: 1.109843
global_step: 17284, epoch: 33, loss: 1.060398
global_step: 17285, epoch: 33, loss: 1.048836
global_step: 17286, epoch: 33, loss: 1.092726
global_step: 17287, epoch: 33, loss: 1.088206
global_step: 17288, epoch: 33, loss: 1.208369
global_step: 17289, epoch: 33, loss: 1.108781
global_step: 17290, epoch: 33, loss: 1.029225
global_step: 17291, epoch: 33, loss: 1.025214
global_step: 17292, epoch: 33, loss: 1.055206
global_step: 17293, epoch: 33, loss: 1.180477
global_step: 17294, epoch: 33, loss: 1.109167
global_step: 17295, epoch: 33, loss: 1.036394
global_step: 17296, epoch: 33, loss: 1.001301
global_step: 17297, epoch: 33, loss: 1.130975
global_step: 17298, epoch: 33, loss: 1.116526
global_step: 17299, epoch: 33, loss: 1.083111
global_step: 17300, epoch: 33, loss: 0.947473
global_step: 17301, epoch: 33, loss: 1.131624
global_step: 17302, epoch: 33, loss: 1.165351
global_step: 17303, epoch: 33, loss: 1.094412
global_step: 17304, epoch: 33, loss: 1.111268
global_step: 17305, epoch: 33, loss: 1.151216
global_step: 17306, epoch: 33, loss: 0.971214
global_step: 17307, epoch: 33, loss: 1.067126
global_step: 17308, epoch: 33, loss: 1.081520
global_step: 17309, epoch: 33, loss: 1.067137
global_step: 17310, epoch: 33, loss: 1.096320
global_step: 17311, epoch: 33, loss: 1.009680
global_step: 17312, epoch: 33, loss: 1.086983
global_step: 17313, epoch: 33, loss: 1.085008
global_step: 17314, epoch: 33, loss: 1.145813
global_step: 17315, epoch: 33, loss: 1.110781
global_step: 17316, epoch: 33, loss: 1.105422
global_step: 17317, epoch: 33, loss: 0.936080
global_step: 17318, epoch: 33, loss: 1.082781
global_step: 17319, epoch: 33, loss: 1.110817
global_step: 17320, epoch: 33, loss: 0.304249
epoch: 33
train	acc: 0.6497	macro: p 0.4244, r 0.3506, f1: 0.3579	micro: p 0.6497, r 0.6497, f1 0.6497	weighted_f1:0.5992
dev	acc: 0.5726	macro: p 0.3945, r 0.3172, f1: 0.3104	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5085
test	acc: 0.6130	macro: p 0.3807, r 0.3149, f1: 0.3126	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5551
global_step: 17321, epoch: 34, loss: 1.056630
global_step: 17322, epoch: 34, loss: 1.077363
global_step: 17323, epoch: 34, loss: 1.018522
global_step: 17324, epoch: 34, loss: 1.098783
global_step: 17325, epoch: 34, loss: 1.025573
global_step: 17326, epoch: 34, loss: 0.955948
global_step: 17327, epoch: 34, loss: 1.165793
global_step: 17328, epoch: 34, loss: 0.942466
global_step: 17329, epoch: 34, loss: 1.032534
global_step: 17330, epoch: 34, loss: 1.190828
global_step: 17331, epoch: 34, loss: 1.182553
global_step: 17332, epoch: 34, loss: 1.021502
global_step: 17333, epoch: 34, loss: 1.160205
global_step: 17334, epoch: 34, loss: 1.071015
global_step: 17335, epoch: 34, loss: 1.033486
global_step: 17336, epoch: 34, loss: 1.197664
global_step: 17337, epoch: 34, loss: 1.093904
global_step: 17338, epoch: 34, loss: 1.131801
global_step: 17339, epoch: 34, loss: 1.051689
global_step: 17340, epoch: 34, loss: 0.968520
global_step: 17341, epoch: 34, loss: 1.050704
global_step: 17342, epoch: 34, loss: 1.074834
global_step: 17343, epoch: 34, loss: 1.174762
global_step: 17344, epoch: 34, loss: 0.935216
global_step: 17345, epoch: 34, loss: 1.006475
global_step: 17346, epoch: 34, loss: 1.072341
global_step: 17347, epoch: 34, loss: 1.001256
global_step: 17348, epoch: 34, loss: 1.142485
global_step: 17349, epoch: 34, loss: 1.178491
global_step: 17350, epoch: 34, loss: 0.945875
global_step: 17351, epoch: 34, loss: 1.028852
global_step: 17352, epoch: 34, loss: 1.100448
global_step: 17353, epoch: 34, loss: 1.151697
global_step: 17354, epoch: 34, loss: 1.111513
global_step: 17355, epoch: 34, loss: 0.989559
global_step: 17356, epoch: 34, loss: 1.084244
global_step: 17357, epoch: 34, loss: 1.285974
global_step: 17358, epoch: 34, loss: 1.002177
global_step: 17359, epoch: 34, loss: 1.128846
global_step: 17360, epoch: 34, loss: 0.778638
epoch: 34
train	acc: 0.6526	macro: p 0.4260, r 0.3555, f1: 0.3625	micro: p 0.6526, r 0.6526, f1 0.6526	weighted_f1:0.6035
dev	acc: 0.5780	macro: p 0.4047, r 0.3234, f1: 0.3180	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5164
test	acc: 0.6119	macro: p 0.3775, r 0.3153, f1: 0.3138	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5557
global_step: 17361, epoch: 35, loss: 1.025698
global_step: 17362, epoch: 35, loss: 1.129564
global_step: 17363, epoch: 35, loss: 1.073405
global_step: 17364, epoch: 35, loss: 1.056579
global_step: 17365, epoch: 35, loss: 0.929286
global_step: 17366, epoch: 35, loss: 1.074537
global_step: 17367, epoch: 35, loss: 1.120386
global_step: 17368, epoch: 35, loss: 1.047417
global_step: 17369, epoch: 35, loss: 1.030024
global_step: 17370, epoch: 35, loss: 0.933749
global_step: 17371, epoch: 35, loss: 0.999503
global_step: 17372, epoch: 35, loss: 1.122630
global_step: 17373, epoch: 35, loss: 1.074083
global_step: 17374, epoch: 35, loss: 1.042422
global_step: 17375, epoch: 35, loss: 1.037525
global_step: 17376, epoch: 35, loss: 1.094283
global_step: 17377, epoch: 35, loss: 0.894362
global_step: 17378, epoch: 35, loss: 1.078148
global_step: 17379, epoch: 35, loss: 1.096106
global_step: 17380, epoch: 35, loss: 1.094015
global_step: 17381, epoch: 35, loss: 1.070248
global_step: 17382, epoch: 35, loss: 1.024259
global_step: 17383, epoch: 35, loss: 1.095159
global_step: 17384, epoch: 35, loss: 1.098208
global_step: 17385, epoch: 35, loss: 1.055797
global_step: 17386, epoch: 35, loss: 1.014415
global_step: 17387, epoch: 35, loss: 1.146457
global_step: 17388, epoch: 35, loss: 1.080838
global_step: 17389, epoch: 35, loss: 1.168612
global_step: 17390, epoch: 35, loss: 1.066107
global_step: 17391, epoch: 35, loss: 1.069310
global_step: 17392, epoch: 35, loss: 1.078579
global_step: 17393, epoch: 35, loss: 1.183769
global_step: 17394, epoch: 35, loss: 1.072221
global_step: 17395, epoch: 35, loss: 1.030751
global_step: 17396, epoch: 35, loss: 1.054256
global_step: 17397, epoch: 35, loss: 1.002165
global_step: 17398, epoch: 35, loss: 0.955690
global_step: 17399, epoch: 35, loss: 1.194566
global_step: 17400, epoch: 35, loss: 0.815355
epoch: 35
train	acc: 0.6668	macro: p 0.4173, r 0.3901, f1: 0.3909	micro: p 0.6668, r 0.6668, f1 0.6668	weighted_f1:0.6301
dev	acc: 0.5780	macro: p 0.3721, r 0.3446, f1: 0.3355	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5317
test	acc: 0.6034	macro: p 0.3599, r 0.3394, f1: 0.3322	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5650
New best model!
global_step: 17401, epoch: 36, loss: 1.098856
global_step: 17402, epoch: 36, loss: 1.162688
global_step: 17403, epoch: 36, loss: 1.013147
global_step: 17404, epoch: 36, loss: 1.033671
global_step: 17405, epoch: 36, loss: 1.064642
global_step: 17406, epoch: 36, loss: 1.097043
global_step: 17407, epoch: 36, loss: 1.072195
global_step: 17408, epoch: 36, loss: 1.043605
global_step: 17409, epoch: 36, loss: 1.154017
global_step: 17410, epoch: 36, loss: 1.164263
global_step: 17411, epoch: 36, loss: 1.062790
global_step: 17412, epoch: 36, loss: 1.137647
global_step: 17413, epoch: 36, loss: 0.981601
global_step: 17414, epoch: 36, loss: 1.061585
global_step: 17415, epoch: 36, loss: 1.199554
global_step: 17416, epoch: 36, loss: 1.013023
global_step: 17417, epoch: 36, loss: 1.079809
global_step: 17418, epoch: 36, loss: 1.056320
global_step: 17419, epoch: 36, loss: 0.969969
global_step: 17420, epoch: 36, loss: 1.012859
global_step: 17421, epoch: 36, loss: 1.110650
global_step: 17422, epoch: 36, loss: 0.974708
global_step: 17423, epoch: 36, loss: 1.076932
global_step: 17424, epoch: 36, loss: 0.950397
global_step: 17425, epoch: 36, loss: 0.960015
global_step: 17426, epoch: 36, loss: 1.059283
global_step: 17427, epoch: 36, loss: 1.008067
global_step: 17428, epoch: 36, loss: 1.105144
global_step: 17429, epoch: 36, loss: 1.027559
global_step: 17430, epoch: 36, loss: 1.070977
global_step: 17431, epoch: 36, loss: 1.067719
global_step: 17432, epoch: 36, loss: 1.089423
global_step: 17433, epoch: 36, loss: 0.946838
global_step: 17434, epoch: 36, loss: 0.964431
global_step: 17435, epoch: 36, loss: 1.055638
global_step: 17436, epoch: 36, loss: 1.078015
global_step: 17437, epoch: 36, loss: 1.001131
global_step: 17438, epoch: 36, loss: 1.097124
global_step: 17439, epoch: 36, loss: 0.988983
global_step: 17440, epoch: 36, loss: 0.522200
epoch: 36
train	acc: 0.6682	macro: p 0.4349, r 0.3777, f1: 0.3843	micro: p 0.6682, r 0.6682, f1 0.6682	weighted_f1:0.6253
dev	acc: 0.5825	macro: p 0.3849, r 0.3327, f1: 0.3275	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5272
test	acc: 0.6130	macro: p 0.3705, r 0.3276, f1: 0.3273	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5658
global_step: 17441, epoch: 37, loss: 1.045694
global_step: 17442, epoch: 37, loss: 1.076916
global_step: 17443, epoch: 37, loss: 1.115400
global_step: 17444, epoch: 37, loss: 1.062431
global_step: 17445, epoch: 37, loss: 1.117212
global_step: 17446, epoch: 37, loss: 1.023362
global_step: 17447, epoch: 37, loss: 1.034858
global_step: 17448, epoch: 37, loss: 1.035110
global_step: 17449, epoch: 37, loss: 1.009409
global_step: 17450, epoch: 37, loss: 1.037112
global_step: 17451, epoch: 37, loss: 0.997110
global_step: 17452, epoch: 37, loss: 1.009941
global_step: 17453, epoch: 37, loss: 1.037020
global_step: 17454, epoch: 37, loss: 1.030637
global_step: 17455, epoch: 37, loss: 0.985497
global_step: 17456, epoch: 37, loss: 1.064114
global_step: 17457, epoch: 37, loss: 1.045691
global_step: 17458, epoch: 37, loss: 1.101227
global_step: 17459, epoch: 37, loss: 1.137113
global_step: 17460, epoch: 37, loss: 1.005563
global_step: 17461, epoch: 37, loss: 0.907898
global_step: 17462, epoch: 37, loss: 1.049837
global_step: 17463, epoch: 37, loss: 1.028582
global_step: 17464, epoch: 37, loss: 1.089443
global_step: 17465, epoch: 37, loss: 1.019658
global_step: 17466, epoch: 37, loss: 1.035284
global_step: 17467, epoch: 37, loss: 1.107693
global_step: 17468, epoch: 37, loss: 1.074166
global_step: 17469, epoch: 37, loss: 1.028990
global_step: 17470, epoch: 37, loss: 1.069045
global_step: 17471, epoch: 37, loss: 1.068270
global_step: 17472, epoch: 37, loss: 1.053547
global_step: 17473, epoch: 37, loss: 1.034243
global_step: 17474, epoch: 37, loss: 1.141080
global_step: 17475, epoch: 37, loss: 1.017727
global_step: 17476, epoch: 37, loss: 1.025104
global_step: 17477, epoch: 37, loss: 1.079784
global_step: 17478, epoch: 37, loss: 1.131747
global_step: 17479, epoch: 37, loss: 1.030377
global_step: 17480, epoch: 37, loss: 1.303365
epoch: 37
train	acc: 0.6676	macro: p 0.4373, r 0.3736, f1: 0.3825	micro: p 0.6676, r 0.6676, f1 0.6676	weighted_f1:0.6228
dev	acc: 0.5843	macro: p 0.4027, r 0.3324, f1: 0.3298	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5278
test	acc: 0.6146	macro: p 0.3719, r 0.3235, f1: 0.3240	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5636
global_step: 17481, epoch: 38, loss: 1.003595
global_step: 17482, epoch: 38, loss: 1.000639
global_step: 17483, epoch: 38, loss: 1.065472
global_step: 17484, epoch: 38, loss: 1.079142
global_step: 17485, epoch: 38, loss: 1.194049
global_step: 17486, epoch: 38, loss: 1.160704
global_step: 17487, epoch: 38, loss: 1.060150
global_step: 17488, epoch: 38, loss: 1.061372
global_step: 17489, epoch: 38, loss: 1.013811
global_step: 17490, epoch: 38, loss: 0.970633
global_step: 17491, epoch: 38, loss: 0.979727
global_step: 17492, epoch: 38, loss: 1.091274
global_step: 17493, epoch: 38, loss: 1.144170
global_step: 17494, epoch: 38, loss: 0.996451
global_step: 17495, epoch: 38, loss: 0.987665
global_step: 17496, epoch: 38, loss: 1.090576
global_step: 17497, epoch: 38, loss: 1.148823
global_step: 17498, epoch: 38, loss: 1.056878
global_step: 17499, epoch: 38, loss: 1.030927
global_step: 17500, epoch: 38, loss: 0.951342
global_step: 17501, epoch: 38, loss: 0.902109
global_step: 17502, epoch: 38, loss: 1.087146
global_step: 17503, epoch: 38, loss: 0.937056
global_step: 17504, epoch: 38, loss: 1.041996
global_step: 17505, epoch: 38, loss: 0.950439
global_step: 17506, epoch: 38, loss: 1.051172
global_step: 17507, epoch: 38, loss: 0.973358
global_step: 17508, epoch: 38, loss: 0.997605
global_step: 17509, epoch: 38, loss: 1.001820
global_step: 17510, epoch: 38, loss: 1.041734
global_step: 17511, epoch: 38, loss: 1.048916
global_step: 17512, epoch: 38, loss: 1.113053
global_step: 17513, epoch: 38, loss: 1.018331
global_step: 17514, epoch: 38, loss: 0.917548
global_step: 17515, epoch: 38, loss: 0.999385
global_step: 17516, epoch: 38, loss: 1.060069
global_step: 17517, epoch: 38, loss: 1.058045
global_step: 17518, epoch: 38, loss: 1.018931
global_step: 17519, epoch: 38, loss: 1.058757
global_step: 17520, epoch: 38, loss: 2.122801
epoch: 38
train	acc: 0.6776	macro: p 0.4198, r 0.4222, f1: 0.4188	micro: p 0.6776, r 0.6776, f1 0.6776	weighted_f1:0.6549
dev	acc: 0.5762	macro: p 0.3570, r 0.3519, f1: 0.3491	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5428
test	acc: 0.5950	macro: p 0.3447, r 0.3472, f1: 0.3442	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5716
New best model!
global_step: 17521, epoch: 39, loss: 0.989379
global_step: 17522, epoch: 39, loss: 1.138158
global_step: 17523, epoch: 39, loss: 1.014068
global_step: 17524, epoch: 39, loss: 1.070695
global_step: 17525, epoch: 39, loss: 0.975445
global_step: 17526, epoch: 39, loss: 1.113439
global_step: 17527, epoch: 39, loss: 1.094239
global_step: 17528, epoch: 39, loss: 1.020515
global_step: 17529, epoch: 39, loss: 1.053276
global_step: 17530, epoch: 39, loss: 0.956595
global_step: 17531, epoch: 39, loss: 1.035925
global_step: 17532, epoch: 39, loss: 0.922288
global_step: 17533, epoch: 39, loss: 0.960588
global_step: 17534, epoch: 39, loss: 1.080855
global_step: 17535, epoch: 39, loss: 0.985275
global_step: 17536, epoch: 39, loss: 0.899722
global_step: 17537, epoch: 39, loss: 1.212633
global_step: 17538, epoch: 39, loss: 1.057172
global_step: 17539, epoch: 39, loss: 0.957716
global_step: 17540, epoch: 39, loss: 1.075676
global_step: 17541, epoch: 39, loss: 1.036071
global_step: 17542, epoch: 39, loss: 1.144220
global_step: 17543, epoch: 39, loss: 1.066147
global_step: 17544, epoch: 39, loss: 1.075461
global_step: 17545, epoch: 39, loss: 1.169394
global_step: 17546, epoch: 39, loss: 0.952303
global_step: 17547, epoch: 39, loss: 1.060468
global_step: 17548, epoch: 39, loss: 0.955812
global_step: 17549, epoch: 39, loss: 1.007167
global_step: 17550, epoch: 39, loss: 1.042972
global_step: 17551, epoch: 39, loss: 1.040967
global_step: 17552, epoch: 39, loss: 0.914946
global_step: 17553, epoch: 39, loss: 1.058330
global_step: 17554, epoch: 39, loss: 1.062597
global_step: 17555, epoch: 39, loss: 1.005352
global_step: 17556, epoch: 39, loss: 1.060181
global_step: 17557, epoch: 39, loss: 0.977158
global_step: 17558, epoch: 39, loss: 0.969226
global_step: 17559, epoch: 39, loss: 0.986847
global_step: 17560, epoch: 39, loss: 0.569534
epoch: 39
train	acc: 0.6701	macro: p 0.4395, r 0.3753, f1: 0.3852	micro: p 0.6701, r 0.6701, f1 0.6701	weighted_f1:0.6252
dev	acc: 0.5861	macro: p 0.4051, r 0.3343, f1: 0.3301	micro: p 0.5861, r 0.5861, f1 0.5861	weighted_f1:0.5283
test	acc: 0.6138	macro: p 0.3787, r 0.3233, f1: 0.3231	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5616
global_step: 17561, epoch: 40, loss: 0.977480
global_step: 17562, epoch: 40, loss: 0.994995
global_step: 17563, epoch: 40, loss: 1.093964
global_step: 17564, epoch: 40, loss: 1.067182
global_step: 17565, epoch: 40, loss: 1.087211
global_step: 17566, epoch: 40, loss: 0.897764
global_step: 17567, epoch: 40, loss: 1.024353
global_step: 17568, epoch: 40, loss: 0.975410
global_step: 17569, epoch: 40, loss: 1.068602
global_step: 17570, epoch: 40, loss: 1.012760
global_step: 17571, epoch: 40, loss: 1.023070
global_step: 17572, epoch: 40, loss: 0.965280
global_step: 17573, epoch: 40, loss: 0.852767
global_step: 17574, epoch: 40, loss: 0.983428
global_step: 17575, epoch: 40, loss: 1.108276
global_step: 17576, epoch: 40, loss: 1.059785
global_step: 17577, epoch: 40, loss: 1.066635
global_step: 17578, epoch: 40, loss: 1.013552
global_step: 17579, epoch: 40, loss: 1.017793
global_step: 17580, epoch: 40, loss: 0.954865
global_step: 17581, epoch: 40, loss: 0.998657
global_step: 17582, epoch: 40, loss: 1.066573
global_step: 17583, epoch: 40, loss: 1.016857
global_step: 17584, epoch: 40, loss: 1.035411
global_step: 17585, epoch: 40, loss: 1.078026
global_step: 17586, epoch: 40, loss: 1.056998
global_step: 17587, epoch: 40, loss: 0.959537
global_step: 17588, epoch: 40, loss: 1.038472
global_step: 17589, epoch: 40, loss: 1.070947
global_step: 17590, epoch: 40, loss: 1.066310
global_step: 17591, epoch: 40, loss: 1.002485
global_step: 17592, epoch: 40, loss: 1.015672
global_step: 17593, epoch: 40, loss: 1.026178
global_step: 17594, epoch: 40, loss: 0.983747
global_step: 17595, epoch: 40, loss: 0.930687
global_step: 17596, epoch: 40, loss: 1.043269
global_step: 17597, epoch: 40, loss: 1.029845
global_step: 17598, epoch: 40, loss: 0.986659
global_step: 17599, epoch: 40, loss: 1.011638
global_step: 17600, epoch: 40, loss: 1.763759
epoch: 40
train	acc: 0.6859	macro: p 0.4367, r 0.4113, f1: 0.4141	micro: p 0.6859, r 0.6859, f1 0.6859	weighted_f1:0.6514
dev	acc: 0.5861	macro: p 0.3744, r 0.3502, f1: 0.3459	micro: p 0.5861, r 0.5861, f1 0.5861	weighted_f1:0.5421
test	acc: 0.6077	macro: p 0.3610, r 0.3398, f1: 0.3383	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5705
global_step: 17601, epoch: 41, loss: 1.019009
global_step: 17602, epoch: 41, loss: 0.888366
global_step: 17603, epoch: 41, loss: 0.964756
global_step: 17604, epoch: 41, loss: 1.135186
global_step: 17605, epoch: 41, loss: 1.057916
global_step: 17606, epoch: 41, loss: 0.939922
global_step: 17607, epoch: 41, loss: 1.010054
global_step: 17608, epoch: 41, loss: 0.821772
global_step: 17609, epoch: 41, loss: 1.097711
global_step: 17610, epoch: 41, loss: 0.943340
global_step: 17611, epoch: 41, loss: 0.998687
global_step: 17612, epoch: 41, loss: 1.004006
global_step: 17613, epoch: 41, loss: 1.004554
global_step: 17614, epoch: 41, loss: 1.036279
global_step: 17615, epoch: 41, loss: 0.924908
global_step: 17616, epoch: 41, loss: 1.008720
global_step: 17617, epoch: 41, loss: 1.014569
global_step: 17618, epoch: 41, loss: 1.053768
global_step: 17619, epoch: 41, loss: 0.971563
global_step: 17620, epoch: 41, loss: 0.973815
global_step: 17621, epoch: 41, loss: 1.021404
global_step: 17622, epoch: 41, loss: 0.929691
global_step: 17623, epoch: 41, loss: 1.089135
global_step: 17624, epoch: 41, loss: 1.054834
global_step: 17625, epoch: 41, loss: 1.066493
global_step: 17626, epoch: 41, loss: 0.990156
global_step: 17627, epoch: 41, loss: 0.922264
global_step: 17628, epoch: 41, loss: 0.941385
global_step: 17629, epoch: 41, loss: 0.919218
global_step: 17630, epoch: 41, loss: 0.994184
global_step: 17631, epoch: 41, loss: 1.096624
global_step: 17632, epoch: 41, loss: 1.027181
global_step: 17633, epoch: 41, loss: 1.112993
global_step: 17634, epoch: 41, loss: 1.076096
global_step: 17635, epoch: 41, loss: 1.034301
global_step: 17636, epoch: 41, loss: 1.072564
global_step: 17637, epoch: 41, loss: 1.029991
global_step: 17638, epoch: 41, loss: 1.121448
global_step: 17639, epoch: 41, loss: 0.914126
global_step: 17640, epoch: 41, loss: 1.878382
epoch: 41
train	acc: 0.6845	macro: p 0.4453, r 0.4004, f1: 0.4105	micro: p 0.6845, r 0.6845, f1 0.6845	weighted_f1:0.6467
dev	acc: 0.5924	macro: p 0.3872, r 0.3459, f1: 0.3459	micro: p 0.5924, r 0.5924, f1 0.5924	weighted_f1:0.5433
test	acc: 0.6169	macro: p 0.3737, r 0.3360, f1: 0.3406	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5747
New best model!
global_step: 17641, epoch: 42, loss: 1.013621
global_step: 17642, epoch: 42, loss: 1.066023
global_step: 17643, epoch: 42, loss: 0.949727
global_step: 17644, epoch: 42, loss: 1.000938
global_step: 17645, epoch: 42, loss: 1.028546
global_step: 17646, epoch: 42, loss: 1.048699
global_step: 17647, epoch: 42, loss: 1.072662
global_step: 17648, epoch: 42, loss: 0.939055
global_step: 17649, epoch: 42, loss: 1.022237
global_step: 17650, epoch: 42, loss: 1.015944
global_step: 17651, epoch: 42, loss: 1.047351
global_step: 17652, epoch: 42, loss: 0.972612
global_step: 17653, epoch: 42, loss: 0.952083
global_step: 17654, epoch: 42, loss: 0.947497
global_step: 17655, epoch: 42, loss: 1.026267
global_step: 17656, epoch: 42, loss: 1.023799
global_step: 17657, epoch: 42, loss: 0.996858
global_step: 17658, epoch: 42, loss: 0.918464
global_step: 17659, epoch: 42, loss: 0.951191
global_step: 17660, epoch: 42, loss: 0.979509
global_step: 17661, epoch: 42, loss: 0.992513
global_step: 17662, epoch: 42, loss: 0.984002
global_step: 17663, epoch: 42, loss: 1.078790
global_step: 17664, epoch: 42, loss: 0.900174
global_step: 17665, epoch: 42, loss: 0.992973
global_step: 17666, epoch: 42, loss: 0.974145
global_step: 17667, epoch: 42, loss: 0.983044
global_step: 17668, epoch: 42, loss: 0.916905
global_step: 17669, epoch: 42, loss: 0.996660
global_step: 17670, epoch: 42, loss: 0.893458
global_step: 17671, epoch: 42, loss: 0.990140
global_step: 17672, epoch: 42, loss: 1.050834
global_step: 17673, epoch: 42, loss: 0.992589
global_step: 17674, epoch: 42, loss: 0.983276
global_step: 17675, epoch: 42, loss: 1.072782
global_step: 17676, epoch: 42, loss: 1.064224
global_step: 17677, epoch: 42, loss: 0.917156
global_step: 17678, epoch: 42, loss: 1.076622
global_step: 17679, epoch: 42, loss: 0.911922
global_step: 17680, epoch: 42, loss: 1.738167
epoch: 42
train	acc: 0.6884	macro: p 0.4433, r 0.4078, f1: 0.4135	micro: p 0.6884, r 0.6884, f1 0.6884	weighted_f1:0.6529
dev	acc: 0.5861	macro: p 0.3895, r 0.3487, f1: 0.3432	micro: p 0.5861, r 0.5861, f1 0.5861	weighted_f1:0.5396
test	acc: 0.6065	macro: p 0.3669, r 0.3372, f1: 0.3338	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5666
global_step: 17681, epoch: 43, loss: 1.070571
global_step: 17682, epoch: 43, loss: 1.091445
global_step: 17683, epoch: 43, loss: 1.023293
global_step: 17684, epoch: 43, loss: 1.005601
global_step: 17685, epoch: 43, loss: 0.975285
global_step: 17686, epoch: 43, loss: 1.038645
global_step: 17687, epoch: 43, loss: 0.912123
global_step: 17688, epoch: 43, loss: 0.960494
global_step: 17689, epoch: 43, loss: 0.934035
global_step: 17690, epoch: 43, loss: 0.984744
global_step: 17691, epoch: 43, loss: 0.930516
global_step: 17692, epoch: 43, loss: 1.021640
global_step: 17693, epoch: 43, loss: 1.023314
global_step: 17694, epoch: 43, loss: 0.965518
global_step: 17695, epoch: 43, loss: 1.023993
global_step: 17696, epoch: 43, loss: 0.986250
global_step: 17697, epoch: 43, loss: 0.998407
global_step: 17698, epoch: 43, loss: 1.065176
global_step: 17699, epoch: 43, loss: 1.019628
global_step: 17700, epoch: 43, loss: 1.089005
global_step: 17701, epoch: 43, loss: 0.968447
global_step: 17702, epoch: 43, loss: 0.951232
global_step: 17703, epoch: 43, loss: 0.867305
global_step: 17704, epoch: 43, loss: 0.995822
global_step: 17705, epoch: 43, loss: 1.054791
global_step: 17706, epoch: 43, loss: 0.972541
global_step: 17707, epoch: 43, loss: 0.970986
global_step: 17708, epoch: 43, loss: 1.027910
global_step: 17709, epoch: 43, loss: 1.036290
global_step: 17710, epoch: 43, loss: 0.969830
global_step: 17711, epoch: 43, loss: 0.936860
global_step: 17712, epoch: 43, loss: 0.949717
global_step: 17713, epoch: 43, loss: 0.870207
global_step: 17714, epoch: 43, loss: 1.106894
global_step: 17715, epoch: 43, loss: 1.018586
global_step: 17716, epoch: 43, loss: 0.992583
global_step: 17717, epoch: 43, loss: 1.036126
global_step: 17718, epoch: 43, loss: 0.990391
global_step: 17719, epoch: 43, loss: 0.947054
global_step: 17720, epoch: 43, loss: 0.394073
epoch: 43
train	acc: 0.6844	macro: p 0.4502, r 0.3956, f1: 0.4076	micro: p 0.6844, r 0.6844, f1 0.6844	weighted_f1:0.6442
dev	acc: 0.5933	macro: p 0.3951, r 0.3443, f1: 0.3458	micro: p 0.5933, r 0.5933, f1 0.5933	weighted_f1:0.5426
test	acc: 0.6184	macro: p 0.3784, r 0.3329, f1: 0.3382	micro: p 0.6184, r 0.6184, f1 0.6184	weighted_f1:0.5732
global_step: 17721, epoch: 44, loss: 0.987797
global_step: 17722, epoch: 44, loss: 1.018129
global_step: 17723, epoch: 44, loss: 1.062302
global_step: 17724, epoch: 44, loss: 0.980993
global_step: 17725, epoch: 44, loss: 1.005684
global_step: 17726, epoch: 44, loss: 0.968059
global_step: 17727, epoch: 44, loss: 1.117911
global_step: 17728, epoch: 44, loss: 1.018059
global_step: 17729, epoch: 44, loss: 0.982799
global_step: 17730, epoch: 44, loss: 0.934379
global_step: 17731, epoch: 44, loss: 0.921558
global_step: 17732, epoch: 44, loss: 0.879085
global_step: 17733, epoch: 44, loss: 0.999688
global_step: 17734, epoch: 44, loss: 1.033596
global_step: 17735, epoch: 44, loss: 0.992822
global_step: 17736, epoch: 44, loss: 0.941855
global_step: 17737, epoch: 44, loss: 0.991937
global_step: 17738, epoch: 44, loss: 0.959093
global_step: 17739, epoch: 44, loss: 0.941295
global_step: 17740, epoch: 44, loss: 0.915150
global_step: 17741, epoch: 44, loss: 0.979946
global_step: 17742, epoch: 44, loss: 0.785397
global_step: 17743, epoch: 44, loss: 0.941426
global_step: 17744, epoch: 44, loss: 1.013863
global_step: 17745, epoch: 44, loss: 0.910125
global_step: 17746, epoch: 44, loss: 1.078165
global_step: 17747, epoch: 44, loss: 1.016104
global_step: 17748, epoch: 44, loss: 0.898584
global_step: 17749, epoch: 44, loss: 1.038748
global_step: 17750, epoch: 44, loss: 0.939084
global_step: 17751, epoch: 44, loss: 0.880389
global_step: 17752, epoch: 44, loss: 0.959813
global_step: 17753, epoch: 44, loss: 0.963382
global_step: 17754, epoch: 44, loss: 0.992494
global_step: 17755, epoch: 44, loss: 1.015347
global_step: 17756, epoch: 44, loss: 1.011554
global_step: 17757, epoch: 44, loss: 0.975238
global_step: 17758, epoch: 44, loss: 0.983564
global_step: 17759, epoch: 44, loss: 1.098590
global_step: 17760, epoch: 44, loss: 0.893894
epoch: 44
train	acc: 0.6893	macro: p 0.4539, r 0.4048, f1: 0.4169	micro: p 0.6893, r 0.6893, f1 0.6893	weighted_f1:0.6515
dev	acc: 0.5897	macro: p 0.3919, r 0.3436, f1: 0.3464	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5414
test	acc: 0.6172	macro: p 0.3720, r 0.3331, f1: 0.3389	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5735
global_step: 17761, epoch: 45, loss: 1.014952
global_step: 17762, epoch: 45, loss: 0.976064
global_step: 17763, epoch: 45, loss: 0.926770
global_step: 17764, epoch: 45, loss: 1.035748
global_step: 17765, epoch: 45, loss: 0.981470
global_step: 17766, epoch: 45, loss: 0.996499
global_step: 17767, epoch: 45, loss: 0.914814
global_step: 17768, epoch: 45, loss: 1.024345
global_step: 17769, epoch: 45, loss: 0.915009
global_step: 17770, epoch: 45, loss: 0.868421
global_step: 17771, epoch: 45, loss: 0.978766
global_step: 17772, epoch: 45, loss: 1.060225
global_step: 17773, epoch: 45, loss: 1.074501
global_step: 17774, epoch: 45, loss: 1.036309
global_step: 17775, epoch: 45, loss: 1.011181
global_step: 17776, epoch: 45, loss: 0.943368
global_step: 17777, epoch: 45, loss: 1.078134
global_step: 17778, epoch: 45, loss: 0.999943
global_step: 17779, epoch: 45, loss: 0.971883
global_step: 17780, epoch: 45, loss: 0.909729
global_step: 17781, epoch: 45, loss: 1.021261
global_step: 17782, epoch: 45, loss: 0.913242
global_step: 17783, epoch: 45, loss: 1.016069
global_step: 17784, epoch: 45, loss: 1.020497
global_step: 17785, epoch: 45, loss: 0.824313
global_step: 17786, epoch: 45, loss: 0.871658
global_step: 17787, epoch: 45, loss: 1.013750
global_step: 17788, epoch: 45, loss: 1.003055
global_step: 17789, epoch: 45, loss: 0.996432
global_step: 17790, epoch: 45, loss: 0.973920
global_step: 17791, epoch: 45, loss: 0.873374
global_step: 17792, epoch: 45, loss: 0.985107
global_step: 17793, epoch: 45, loss: 0.952552
global_step: 17794, epoch: 45, loss: 0.907910
global_step: 17795, epoch: 45, loss: 1.053248
global_step: 17796, epoch: 45, loss: 1.003567
global_step: 17797, epoch: 45, loss: 0.955620
global_step: 17798, epoch: 45, loss: 0.960907
global_step: 17799, epoch: 45, loss: 0.907451
global_step: 17800, epoch: 45, loss: 1.031118
epoch: 45
train	acc: 0.7096	macro: p 0.4533, r 0.4369, f1: 0.4404	micro: p 0.7096, r 0.7096, f1 0.7096	weighted_f1:0.6776
dev	acc: 0.5879	macro: p 0.3746, r 0.3541, f1: 0.3516	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5459
test	acc: 0.6146	macro: p 0.3673, r 0.3481, f1: 0.3483	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5791
New best model!
global_step: 17801, epoch: 46, loss: 0.990328
global_step: 17802, epoch: 46, loss: 0.947082
global_step: 17803, epoch: 46, loss: 0.962934
global_step: 17804, epoch: 46, loss: 1.038961
global_step: 17805, epoch: 46, loss: 1.031248
global_step: 17806, epoch: 46, loss: 0.897230
global_step: 17807, epoch: 46, loss: 0.893070
global_step: 17808, epoch: 46, loss: 1.022968
global_step: 17809, epoch: 46, loss: 1.001319
global_step: 17810, epoch: 46, loss: 1.016999
global_step: 17811, epoch: 46, loss: 0.924193
global_step: 17812, epoch: 46, loss: 0.989599
global_step: 17813, epoch: 46, loss: 0.923813
global_step: 17814, epoch: 46, loss: 0.947301
global_step: 17815, epoch: 46, loss: 1.007810
global_step: 17816, epoch: 46, loss: 1.023191
global_step: 17817, epoch: 46, loss: 0.989388
global_step: 17818, epoch: 46, loss: 0.859562
global_step: 17819, epoch: 46, loss: 0.936119
global_step: 17820, epoch: 46, loss: 0.926318
global_step: 17821, epoch: 46, loss: 1.083935
global_step: 17822, epoch: 46, loss: 0.952677
global_step: 17823, epoch: 46, loss: 0.928614
global_step: 17824, epoch: 46, loss: 0.871518
global_step: 17825, epoch: 46, loss: 0.989011
global_step: 17826, epoch: 46, loss: 1.079293
global_step: 17827, epoch: 46, loss: 0.906268
global_step: 17828, epoch: 46, loss: 0.948209
global_step: 17829, epoch: 46, loss: 1.038747
global_step: 17830, epoch: 46, loss: 0.871264
global_step: 17831, epoch: 46, loss: 1.030696
global_step: 17832, epoch: 46, loss: 0.854817
global_step: 17833, epoch: 46, loss: 0.857243
global_step: 17834, epoch: 46, loss: 0.988800
global_step: 17835, epoch: 46, loss: 1.028789
global_step: 17836, epoch: 46, loss: 0.902191
global_step: 17837, epoch: 46, loss: 0.929839
global_step: 17838, epoch: 46, loss: 1.049965
global_step: 17839, epoch: 46, loss: 0.907031
global_step: 17840, epoch: 46, loss: 1.453667
epoch: 46
train	acc: 0.7091	macro: p 0.4590, r 0.4308, f1: 0.4326	micro: p 0.7091, r 0.7091, f1 0.7091	weighted_f1:0.6743
dev	acc: 0.5816	macro: p 0.3816, r 0.3494, f1: 0.3424	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5373
test	acc: 0.6054	macro: p 0.3620, r 0.3388, f1: 0.3306	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5642
global_step: 17841, epoch: 47, loss: 0.850755
global_step: 17842, epoch: 47, loss: 0.876576
global_step: 17843, epoch: 47, loss: 0.963124
global_step: 17844, epoch: 47, loss: 0.867128
global_step: 17845, epoch: 47, loss: 0.887922
global_step: 17846, epoch: 47, loss: 0.941058
global_step: 17847, epoch: 47, loss: 0.965420
global_step: 17848, epoch: 47, loss: 0.883788
global_step: 17849, epoch: 47, loss: 1.016393
global_step: 17850, epoch: 47, loss: 0.902886
global_step: 17851, epoch: 47, loss: 0.824365
global_step: 17852, epoch: 47, loss: 0.939080
global_step: 17853, epoch: 47, loss: 0.910754
global_step: 17854, epoch: 47, loss: 0.966507
global_step: 17855, epoch: 47, loss: 0.902330
global_step: 17856, epoch: 47, loss: 0.822648
global_step: 17857, epoch: 47, loss: 0.990222
global_step: 17858, epoch: 47, loss: 1.014609
global_step: 17859, epoch: 47, loss: 1.001938
global_step: 17860, epoch: 47, loss: 1.020295
global_step: 17861, epoch: 47, loss: 0.934684
global_step: 17862, epoch: 47, loss: 1.044403
global_step: 17863, epoch: 47, loss: 0.986695
global_step: 17864, epoch: 47, loss: 0.921123
global_step: 17865, epoch: 47, loss: 0.920127
global_step: 17866, epoch: 47, loss: 0.979320
global_step: 17867, epoch: 47, loss: 0.873590
global_step: 17868, epoch: 47, loss: 0.967660
global_step: 17869, epoch: 47, loss: 0.858414
global_step: 17870, epoch: 47, loss: 1.022876
global_step: 17871, epoch: 47, loss: 1.023325
global_step: 17872, epoch: 47, loss: 0.922623
global_step: 17873, epoch: 47, loss: 1.048666
global_step: 17874, epoch: 47, loss: 1.005700
global_step: 17875, epoch: 47, loss: 0.936230
global_step: 17876, epoch: 47, loss: 1.109704
global_step: 17877, epoch: 47, loss: 0.901899
global_step: 17878, epoch: 47, loss: 0.938230
global_step: 17879, epoch: 47, loss: 0.908757
global_step: 17880, epoch: 47, loss: 0.782385
epoch: 47
train	acc: 0.7005	macro: p 0.4693, r 0.4155, f1: 0.4292	micro: p 0.7005, r 0.7005, f1 0.7005	weighted_f1:0.6646
dev	acc: 0.5825	macro: p 0.3830, r 0.3364, f1: 0.3398	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5350
test	acc: 0.6192	macro: p 0.3801, r 0.3354, f1: 0.3427	micro: p 0.6192, r 0.6192, f1 0.6192	weighted_f1:0.5765
global_step: 17881, epoch: 48, loss: 0.943270
global_step: 17882, epoch: 48, loss: 0.942419
global_step: 17883, epoch: 48, loss: 0.892452
global_step: 17884, epoch: 48, loss: 0.804792
global_step: 17885, epoch: 48, loss: 0.800679
global_step: 17886, epoch: 48, loss: 0.937284
global_step: 17887, epoch: 48, loss: 0.845450
global_step: 17888, epoch: 48, loss: 0.975724
global_step: 17889, epoch: 48, loss: 0.876684
global_step: 17890, epoch: 48, loss: 0.906003
global_step: 17891, epoch: 48, loss: 0.920797
global_step: 17892, epoch: 48, loss: 0.940790
global_step: 17893, epoch: 48, loss: 0.918827
global_step: 17894, epoch: 48, loss: 0.895458
global_step: 17895, epoch: 48, loss: 1.003817
global_step: 17896, epoch: 48, loss: 0.844581
global_step: 17897, epoch: 48, loss: 1.006737
global_step: 17898, epoch: 48, loss: 0.940051
global_step: 17899, epoch: 48, loss: 1.050199
global_step: 17900, epoch: 48, loss: 0.961554
global_step: 17901, epoch: 48, loss: 1.030291
global_step: 17902, epoch: 48, loss: 0.990796
global_step: 17903, epoch: 48, loss: 0.963547
global_step: 17904, epoch: 48, loss: 0.997864
global_step: 17905, epoch: 48, loss: 0.953457
global_step: 17906, epoch: 48, loss: 0.941597
global_step: 17907, epoch: 48, loss: 0.920001
global_step: 17908, epoch: 48, loss: 0.927148
global_step: 17909, epoch: 48, loss: 0.976173
global_step: 17910, epoch: 48, loss: 0.856134
global_step: 17911, epoch: 48, loss: 1.012183
global_step: 17912, epoch: 48, loss: 0.984025
global_step: 17913, epoch: 48, loss: 0.932162
global_step: 17914, epoch: 48, loss: 0.885311
global_step: 17915, epoch: 48, loss: 0.849394
global_step: 17916, epoch: 48, loss: 0.980786
global_step: 17917, epoch: 48, loss: 1.074004
global_step: 17918, epoch: 48, loss: 0.882707
global_step: 17919, epoch: 48, loss: 0.998859
global_step: 17920, epoch: 48, loss: 0.383367
epoch: 48
train	acc: 0.7034	macro: p 0.4706, r 0.4135, f1: 0.4249	micro: p 0.7034, r 0.7034, f1 0.7034	weighted_f1:0.6634
dev	acc: 0.5915	macro: p 0.4060, r 0.3429, f1: 0.3444	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5396
test	acc: 0.6180	macro: p 0.3775, r 0.3305, f1: 0.3335	micro: p 0.6180, r 0.6180, f1 0.6180	weighted_f1:0.5705
global_step: 17921, epoch: 49, loss: 1.079170
global_step: 17922, epoch: 49, loss: 0.935604
global_step: 17923, epoch: 49, loss: 0.941024
global_step: 17924, epoch: 49, loss: 0.930309
global_step: 17925, epoch: 49, loss: 0.986461
global_step: 17926, epoch: 49, loss: 0.891714
global_step: 17927, epoch: 49, loss: 0.934394
global_step: 17928, epoch: 49, loss: 0.953433
global_step: 17929, epoch: 49, loss: 0.925686
global_step: 17930, epoch: 49, loss: 0.986689
global_step: 17931, epoch: 49, loss: 0.945397
global_step: 17932, epoch: 49, loss: 0.932673
global_step: 17933, epoch: 49, loss: 0.881103
global_step: 17934, epoch: 49, loss: 0.837855
global_step: 17935, epoch: 49, loss: 0.999725
global_step: 17936, epoch: 49, loss: 0.866778
global_step: 17937, epoch: 49, loss: 0.858240
global_step: 17938, epoch: 49, loss: 0.897685
global_step: 17939, epoch: 49, loss: 1.031227
global_step: 17940, epoch: 49, loss: 0.974567
global_step: 17941, epoch: 49, loss: 1.002235
global_step: 17942, epoch: 49, loss: 0.861872
global_step: 17943, epoch: 49, loss: 0.966115
global_step: 17944, epoch: 49, loss: 0.875804
global_step: 17945, epoch: 49, loss: 0.851917
global_step: 17946, epoch: 49, loss: 0.948205
global_step: 17947, epoch: 49, loss: 0.905589
global_step: 17948, epoch: 49, loss: 0.932878
global_step: 17949, epoch: 49, loss: 0.893655
global_step: 17950, epoch: 49, loss: 0.969097
global_step: 17951, epoch: 49, loss: 0.894085
global_step: 17952, epoch: 49, loss: 0.856467
global_step: 17953, epoch: 49, loss: 0.872993
global_step: 17954, epoch: 49, loss: 0.937517
global_step: 17955, epoch: 49, loss: 0.946016
global_step: 17956, epoch: 49, loss: 0.880873
global_step: 17957, epoch: 49, loss: 0.857156
global_step: 17958, epoch: 49, loss: 1.039461
global_step: 17959, epoch: 49, loss: 0.934038
global_step: 17960, epoch: 49, loss: 0.913158
epoch: 49
train	acc: 0.6980	macro: p 0.4758, r 0.4092, f1: 0.4252	micro: p 0.6980, r 0.6980, f1 0.6980	weighted_f1:0.6597
dev	acc: 0.5825	macro: p 0.3990, r 0.3304, f1: 0.3354	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5300
test	acc: 0.6215	macro: p 0.3871, r 0.3291, f1: 0.3380	micro: p 0.6215, r 0.6215, f1 0.6215	weighted_f1:0.5737
global_step: 17961, epoch: 50, loss: 0.898041
global_step: 17962, epoch: 50, loss: 0.932860
global_step: 17963, epoch: 50, loss: 1.009219
global_step: 17964, epoch: 50, loss: 1.004854
global_step: 17965, epoch: 50, loss: 0.899823
global_step: 17966, epoch: 50, loss: 0.901519
global_step: 17967, epoch: 50, loss: 0.871791
global_step: 17968, epoch: 50, loss: 0.925418
global_step: 17969, epoch: 50, loss: 0.878559
global_step: 17970, epoch: 50, loss: 0.901153
global_step: 17971, epoch: 50, loss: 1.020372
global_step: 17972, epoch: 50, loss: 0.951963
global_step: 17973, epoch: 50, loss: 0.978929
global_step: 17974, epoch: 50, loss: 0.883638
global_step: 17975, epoch: 50, loss: 0.889642
global_step: 17976, epoch: 50, loss: 0.871685
global_step: 17977, epoch: 50, loss: 0.806783
global_step: 17978, epoch: 50, loss: 0.884712
global_step: 17979, epoch: 50, loss: 1.052833
global_step: 17980, epoch: 50, loss: 0.909674
global_step: 17981, epoch: 50, loss: 0.901789
global_step: 17982, epoch: 50, loss: 0.833498
global_step: 17983, epoch: 50, loss: 1.033443
global_step: 17984, epoch: 50, loss: 0.865771
global_step: 17985, epoch: 50, loss: 0.924059
global_step: 17986, epoch: 50, loss: 0.862799
global_step: 17987, epoch: 50, loss: 0.958067
global_step: 17988, epoch: 50, loss: 0.922052
global_step: 17989, epoch: 50, loss: 1.078821
global_step: 17990, epoch: 50, loss: 0.903672
global_step: 17991, epoch: 50, loss: 0.787255
global_step: 17992, epoch: 50, loss: 1.002446
global_step: 17993, epoch: 50, loss: 0.810976
global_step: 17994, epoch: 50, loss: 0.921636
global_step: 17995, epoch: 50, loss: 0.917156
global_step: 17996, epoch: 50, loss: 0.897693
global_step: 17997, epoch: 50, loss: 0.938704
global_step: 17998, epoch: 50, loss: 0.875900
global_step: 17999, epoch: 50, loss: 0.930536
global_step: 18000, epoch: 50, loss: 0.231264
epoch: 50
train	acc: 0.7250	macro: p 0.4755, r 0.4490, f1: 0.4568	micro: p 0.7250, r 0.7250, f1 0.7250	weighted_f1:0.6931
dev	acc: 0.5915	macro: p 0.3835, r 0.3522, f1: 0.3522	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5472
test	acc: 0.6142	macro: p 0.3681, r 0.3398, f1: 0.3425	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5746
New best model!
global_step: 18001, epoch: 51, loss: 0.920550
global_step: 18002, epoch: 51, loss: 0.923364
global_step: 18003, epoch: 51, loss: 0.867739
global_step: 18004, epoch: 51, loss: 0.832145
global_step: 18005, epoch: 51, loss: 0.790023
global_step: 18006, epoch: 51, loss: 0.941717
global_step: 18007, epoch: 51, loss: 0.869660
global_step: 18008, epoch: 51, loss: 0.794398
global_step: 18009, epoch: 51, loss: 1.017262
global_step: 18010, epoch: 51, loss: 0.960155
global_step: 18011, epoch: 51, loss: 0.882157
global_step: 18012, epoch: 51, loss: 0.980280
global_step: 18013, epoch: 51, loss: 0.902197
global_step: 18014, epoch: 51, loss: 0.895926
global_step: 18015, epoch: 51, loss: 0.888299
global_step: 18016, epoch: 51, loss: 0.885287
global_step: 18017, epoch: 51, loss: 0.993352
global_step: 18018, epoch: 51, loss: 0.874930
global_step: 18019, epoch: 51, loss: 0.984249
global_step: 18020, epoch: 51, loss: 0.902154
global_step: 18021, epoch: 51, loss: 0.840344
global_step: 18022, epoch: 51, loss: 0.934975
global_step: 18023, epoch: 51, loss: 0.866719
global_step: 18024, epoch: 51, loss: 0.969586
global_step: 18025, epoch: 51, loss: 0.948020
global_step: 18026, epoch: 51, loss: 0.958357
global_step: 18027, epoch: 51, loss: 0.919518
global_step: 18028, epoch: 51, loss: 0.896340
global_step: 18029, epoch: 51, loss: 0.909127
global_step: 18030, epoch: 51, loss: 0.909235
global_step: 18031, epoch: 51, loss: 1.007978
global_step: 18032, epoch: 51, loss: 0.924310
global_step: 18033, epoch: 51, loss: 0.914800
global_step: 18034, epoch: 51, loss: 0.900073
global_step: 18035, epoch: 51, loss: 0.868582
global_step: 18036, epoch: 51, loss: 0.856676
global_step: 18037, epoch: 51, loss: 0.903735
global_step: 18038, epoch: 51, loss: 0.874252
global_step: 18039, epoch: 51, loss: 0.971239
global_step: 18040, epoch: 51, loss: 0.554800
epoch: 51
train	acc: 0.7169	macro: p 0.4833, r 0.4303, f1: 0.4421	micro: p 0.7169, r 0.7169, f1 0.7169	weighted_f1:0.6811
dev	acc: 0.5825	macro: p 0.3898, r 0.3376, f1: 0.3379	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5333
test	acc: 0.6192	macro: p 0.3800, r 0.3348, f1: 0.3387	micro: p 0.6192, r 0.6192, f1 0.6192	weighted_f1:0.5748
global_step: 18041, epoch: 52, loss: 0.952153
global_step: 18042, epoch: 52, loss: 0.987483
global_step: 18043, epoch: 52, loss: 0.885403
global_step: 18044, epoch: 52, loss: 0.788762
global_step: 18045, epoch: 52, loss: 0.914029
global_step: 18046, epoch: 52, loss: 0.812749
global_step: 18047, epoch: 52, loss: 0.797737
global_step: 18048, epoch: 52, loss: 0.956066
global_step: 18049, epoch: 52, loss: 0.959144
global_step: 18050, epoch: 52, loss: 0.754735
global_step: 18051, epoch: 52, loss: 0.874011
global_step: 18052, epoch: 52, loss: 0.894712
global_step: 18053, epoch: 52, loss: 0.853344
global_step: 18054, epoch: 52, loss: 0.989162
global_step: 18055, epoch: 52, loss: 0.792012
global_step: 18056, epoch: 52, loss: 0.796542
global_step: 18057, epoch: 52, loss: 0.894261
global_step: 18058, epoch: 52, loss: 0.855532
global_step: 18059, epoch: 52, loss: 0.821361
global_step: 18060, epoch: 52, loss: 0.942547
global_step: 18061, epoch: 52, loss: 1.061093
global_step: 18062, epoch: 52, loss: 0.986344
global_step: 18063, epoch: 52, loss: 0.867648
global_step: 18064, epoch: 52, loss: 0.949396
global_step: 18065, epoch: 52, loss: 0.964025
global_step: 18066, epoch: 52, loss: 0.858641
global_step: 18067, epoch: 52, loss: 0.987709
global_step: 18068, epoch: 52, loss: 0.904286
global_step: 18069, epoch: 52, loss: 0.905055
global_step: 18070, epoch: 52, loss: 0.890695
global_step: 18071, epoch: 52, loss: 0.983035
global_step: 18072, epoch: 52, loss: 0.782275
global_step: 18073, epoch: 52, loss: 0.801158
global_step: 18074, epoch: 52, loss: 0.939450
global_step: 18075, epoch: 52, loss: 0.866814
global_step: 18076, epoch: 52, loss: 0.893562
global_step: 18077, epoch: 52, loss: 0.909998
global_step: 18078, epoch: 52, loss: 0.906335
global_step: 18079, epoch: 52, loss: 0.829617
global_step: 18080, epoch: 52, loss: 0.802333
epoch: 52
train	acc: 0.7320	macro: p 0.4818, r 0.4611, f1: 0.4668	micro: p 0.7320, r 0.7320, f1 0.7320	weighted_f1:0.7017
dev	acc: 0.5816	macro: p 0.3691, r 0.3442, f1: 0.3446	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5384
test	acc: 0.6115	macro: p 0.3614, r 0.3398, f1: 0.3427	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5743
global_step: 18081, epoch: 53, loss: 0.868700
global_step: 18082, epoch: 53, loss: 0.796054
global_step: 18083, epoch: 53, loss: 0.835665
global_step: 18084, epoch: 53, loss: 0.913729
global_step: 18085, epoch: 53, loss: 0.767483
global_step: 18086, epoch: 53, loss: 0.969853
global_step: 18087, epoch: 53, loss: 0.941603
global_step: 18088, epoch: 53, loss: 0.796863
global_step: 18089, epoch: 53, loss: 0.929050
global_step: 18090, epoch: 53, loss: 0.944533
global_step: 18091, epoch: 53, loss: 0.987861
global_step: 18092, epoch: 53, loss: 0.783715
global_step: 18093, epoch: 53, loss: 0.898137
global_step: 18094, epoch: 53, loss: 0.996476
global_step: 18095, epoch: 53, loss: 0.913339
global_step: 18096, epoch: 53, loss: 0.963771
global_step: 18097, epoch: 53, loss: 0.816765
global_step: 18098, epoch: 53, loss: 0.891084
global_step: 18099, epoch: 53, loss: 0.942976
global_step: 18100, epoch: 53, loss: 0.924460
global_step: 18101, epoch: 53, loss: 0.837272
global_step: 18102, epoch: 53, loss: 0.761159
global_step: 18103, epoch: 53, loss: 1.027199
global_step: 18104, epoch: 53, loss: 0.864004
global_step: 18105, epoch: 53, loss: 0.850592
global_step: 18106, epoch: 53, loss: 0.896319
global_step: 18107, epoch: 53, loss: 0.845873
global_step: 18108, epoch: 53, loss: 0.840746
global_step: 18109, epoch: 53, loss: 0.938492
global_step: 18110, epoch: 53, loss: 0.987363
global_step: 18111, epoch: 53, loss: 0.904080
global_step: 18112, epoch: 53, loss: 0.768453
global_step: 18113, epoch: 53, loss: 0.871746
global_step: 18114, epoch: 53, loss: 0.852569
global_step: 18115, epoch: 53, loss: 0.789155
global_step: 18116, epoch: 53, loss: 0.941532
global_step: 18117, epoch: 53, loss: 0.993391
global_step: 18118, epoch: 53, loss: 0.878395
global_step: 18119, epoch: 53, loss: 0.772575
global_step: 18120, epoch: 53, loss: 0.832349
epoch: 53
train	acc: 0.7313	macro: p 0.6366, r 0.4483, f1: 0.4578	micro: p 0.7313, r 0.7313, f1 0.7313	weighted_f1:0.6960
dev	acc: 0.5915	macro: p 0.5413, r 0.3550, f1: 0.3621	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5455
test	acc: 0.6165	macro: p 0.3721, r 0.3374, f1: 0.3392	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5736
global_step: 18121, epoch: 54, loss: 0.878316
global_step: 18122, epoch: 54, loss: 0.908870
global_step: 18123, epoch: 54, loss: 0.880788
global_step: 18124, epoch: 54, loss: 0.982485
global_step: 18125, epoch: 54, loss: 0.900412
global_step: 18126, epoch: 54, loss: 0.844482
global_step: 18127, epoch: 54, loss: 0.796211
global_step: 18128, epoch: 54, loss: 0.879702
global_step: 18129, epoch: 54, loss: 0.932297
global_step: 18130, epoch: 54, loss: 0.991577
global_step: 18131, epoch: 54, loss: 0.923736
global_step: 18132, epoch: 54, loss: 0.934231
global_step: 18133, epoch: 54, loss: 0.796183
global_step: 18134, epoch: 54, loss: 0.943180
global_step: 18135, epoch: 54, loss: 0.740311
global_step: 18136, epoch: 54, loss: 0.944017
global_step: 18137, epoch: 54, loss: 0.821467
global_step: 18138, epoch: 54, loss: 0.823674
global_step: 18139, epoch: 54, loss: 0.782378
global_step: 18140, epoch: 54, loss: 0.952697
global_step: 18141, epoch: 54, loss: 0.821964
global_step: 18142, epoch: 54, loss: 0.922549
global_step: 18143, epoch: 54, loss: 0.901663
global_step: 18144, epoch: 54, loss: 0.865784
global_step: 18145, epoch: 54, loss: 0.829142
global_step: 18146, epoch: 54, loss: 0.945557
global_step: 18147, epoch: 54, loss: 0.820422
global_step: 18148, epoch: 54, loss: 0.920323
global_step: 18149, epoch: 54, loss: 0.866874
global_step: 18150, epoch: 54, loss: 0.972504
global_step: 18151, epoch: 54, loss: 0.836961
global_step: 18152, epoch: 54, loss: 0.903361
global_step: 18153, epoch: 54, loss: 0.846413
global_step: 18154, epoch: 54, loss: 0.975353
global_step: 18155, epoch: 54, loss: 0.932675
global_step: 18156, epoch: 54, loss: 0.819089
global_step: 18157, epoch: 54, loss: 0.818521
global_step: 18158, epoch: 54, loss: 0.808238
global_step: 18159, epoch: 54, loss: 1.005115
global_step: 18160, epoch: 54, loss: 0.893827
epoch: 54
train	acc: 0.7570	macro: p 0.6348, r 0.4956, f1: 0.4968	micro: p 0.7570, r 0.7570, f1 0.7570	weighted_f1:0.7328
dev	acc: 0.5780	macro: p 0.5074, r 0.3566, f1: 0.3607	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5433
test	acc: 0.6084	macro: p 0.4991, r 0.3530, f1: 0.3523	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5793
global_step: 18161, epoch: 55, loss: 0.843572
global_step: 18162, epoch: 55, loss: 0.864840
global_step: 18163, epoch: 55, loss: 0.926024
global_step: 18164, epoch: 55, loss: 0.843009
global_step: 18165, epoch: 55, loss: 0.953533
global_step: 18166, epoch: 55, loss: 0.920370
global_step: 18167, epoch: 55, loss: 0.809319
global_step: 18168, epoch: 55, loss: 0.882716
global_step: 18169, epoch: 55, loss: 0.799360
global_step: 18170, epoch: 55, loss: 0.860743
global_step: 18171, epoch: 55, loss: 0.852572
global_step: 18172, epoch: 55, loss: 0.915617
global_step: 18173, epoch: 55, loss: 0.931554
global_step: 18174, epoch: 55, loss: 0.868876
global_step: 18175, epoch: 55, loss: 0.850872
global_step: 18176, epoch: 55, loss: 0.861114
global_step: 18177, epoch: 55, loss: 0.868167
global_step: 18178, epoch: 55, loss: 0.939811
global_step: 18179, epoch: 55, loss: 0.901830
global_step: 18180, epoch: 55, loss: 0.891371
global_step: 18181, epoch: 55, loss: 0.933731
global_step: 18182, epoch: 55, loss: 0.856915
global_step: 18183, epoch: 55, loss: 0.879472
global_step: 18184, epoch: 55, loss: 0.949671
global_step: 18185, epoch: 55, loss: 0.884897
global_step: 18186, epoch: 55, loss: 0.902065
global_step: 18187, epoch: 55, loss: 0.923602
global_step: 18188, epoch: 55, loss: 0.777242
global_step: 18189, epoch: 55, loss: 0.865524
global_step: 18190, epoch: 55, loss: 0.853939
global_step: 18191, epoch: 55, loss: 0.798618
global_step: 18192, epoch: 55, loss: 0.855723
global_step: 18193, epoch: 55, loss: 0.784181
global_step: 18194, epoch: 55, loss: 0.886854
global_step: 18195, epoch: 55, loss: 0.861555
global_step: 18196, epoch: 55, loss: 0.816817
global_step: 18197, epoch: 55, loss: 0.947258
global_step: 18198, epoch: 55, loss: 0.956137
global_step: 18199, epoch: 55, loss: 0.876618
global_step: 18200, epoch: 55, loss: 1.075334
epoch: 55
train	acc: 0.7178	macro: p 0.6038, r 0.4310, f1: 0.4519	micro: p 0.7178, r 0.7178, f1 0.7178	weighted_f1:0.6816
dev	acc: 0.5735	macro: p 0.5364, r 0.3281, f1: 0.3377	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5188
test	acc: 0.6165	macro: p 0.3821, r 0.3245, f1: 0.3327	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5671
global_step: 18201, epoch: 56, loss: 0.880545
global_step: 18202, epoch: 56, loss: 0.848810
global_step: 18203, epoch: 56, loss: 0.828678
global_step: 18204, epoch: 56, loss: 0.961672
global_step: 18205, epoch: 56, loss: 0.875440
global_step: 18206, epoch: 56, loss: 0.934210
global_step: 18207, epoch: 56, loss: 0.802423
global_step: 18208, epoch: 56, loss: 0.836916
global_step: 18209, epoch: 56, loss: 0.949164
global_step: 18210, epoch: 56, loss: 0.840235
global_step: 18211, epoch: 56, loss: 0.875003
global_step: 18212, epoch: 56, loss: 0.860852
global_step: 18213, epoch: 56, loss: 0.919454
global_step: 18214, epoch: 56, loss: 0.953253
global_step: 18215, epoch: 56, loss: 0.915993
global_step: 18216, epoch: 56, loss: 0.910073
global_step: 18217, epoch: 56, loss: 0.814268
global_step: 18218, epoch: 56, loss: 0.874147
global_step: 18219, epoch: 56, loss: 0.663364
global_step: 18220, epoch: 56, loss: 0.843053
global_step: 18221, epoch: 56, loss: 0.837848
global_step: 18222, epoch: 56, loss: 0.851281
global_step: 18223, epoch: 56, loss: 0.850124
global_step: 18224, epoch: 56, loss: 0.865908
global_step: 18225, epoch: 56, loss: 0.904267
global_step: 18226, epoch: 56, loss: 0.799892
global_step: 18227, epoch: 56, loss: 0.801610
global_step: 18228, epoch: 56, loss: 0.811718
global_step: 18229, epoch: 56, loss: 0.858716
global_step: 18230, epoch: 56, loss: 0.806034
global_step: 18231, epoch: 56, loss: 0.870596
global_step: 18232, epoch: 56, loss: 0.830596
global_step: 18233, epoch: 56, loss: 0.956477
global_step: 18234, epoch: 56, loss: 1.034169
global_step: 18235, epoch: 56, loss: 0.939473
global_step: 18236, epoch: 56, loss: 0.702156
global_step: 18237, epoch: 56, loss: 0.902987
global_step: 18238, epoch: 56, loss: 0.801830
global_step: 18239, epoch: 56, loss: 0.944245
global_step: 18240, epoch: 56, loss: 1.176693
epoch: 56
train	acc: 0.7250	macro: p 0.6461, r 0.4334, f1: 0.4510	micro: p 0.7250, r 0.7250, f1 0.7250	weighted_f1:0.6858
dev	acc: 0.5780	macro: p 0.5542, r 0.3326, f1: 0.3393	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5217
test	acc: 0.6161	macro: p 0.3787, r 0.3220, f1: 0.3245	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5626
global_step: 18241, epoch: 57, loss: 0.889724
global_step: 18242, epoch: 57, loss: 0.818284
global_step: 18243, epoch: 57, loss: 0.886932
global_step: 18244, epoch: 57, loss: 0.839782
global_step: 18245, epoch: 57, loss: 0.824748
global_step: 18246, epoch: 57, loss: 0.834833
global_step: 18247, epoch: 57, loss: 0.808550
global_step: 18248, epoch: 57, loss: 0.822908
global_step: 18249, epoch: 57, loss: 0.836473
global_step: 18250, epoch: 57, loss: 0.839463
global_step: 18251, epoch: 57, loss: 0.841227
global_step: 18252, epoch: 57, loss: 0.897058
global_step: 18253, epoch: 57, loss: 0.825712
global_step: 18254, epoch: 57, loss: 0.916036
global_step: 18255, epoch: 57, loss: 0.866856
global_step: 18256, epoch: 57, loss: 0.843638
global_step: 18257, epoch: 57, loss: 0.817039
global_step: 18258, epoch: 57, loss: 0.821329
global_step: 18259, epoch: 57, loss: 0.865604
global_step: 18260, epoch: 57, loss: 0.863304
global_step: 18261, epoch: 57, loss: 0.833948
global_step: 18262, epoch: 57, loss: 0.744310
global_step: 18263, epoch: 57, loss: 0.973406
global_step: 18264, epoch: 57, loss: 0.743967
global_step: 18265, epoch: 57, loss: 0.814216
global_step: 18266, epoch: 57, loss: 0.872107
global_step: 18267, epoch: 57, loss: 0.875724
global_step: 18268, epoch: 57, loss: 0.924809
global_step: 18269, epoch: 57, loss: 0.764567
global_step: 18270, epoch: 57, loss: 0.856982
global_step: 18271, epoch: 57, loss: 0.814121
global_step: 18272, epoch: 57, loss: 0.928908
global_step: 18273, epoch: 57, loss: 0.890271
global_step: 18274, epoch: 57, loss: 0.862438
global_step: 18275, epoch: 57, loss: 0.841157
global_step: 18276, epoch: 57, loss: 0.880625
global_step: 18277, epoch: 57, loss: 0.878206
global_step: 18278, epoch: 57, loss: 0.929197
global_step: 18279, epoch: 57, loss: 0.805151
global_step: 18280, epoch: 57, loss: 1.308448
epoch: 57
train	acc: 0.7688	macro: p 0.6281, r 0.5063, f1: 0.5050	micro: p 0.7688, r 0.7688, f1 0.7688	weighted_f1:0.7426
dev	acc: 0.5771	macro: p 0.5059, r 0.3568, f1: 0.3563	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5392
test	acc: 0.6046	macro: p 0.4973, r 0.3503, f1: 0.3455	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5735
global_step: 18281, epoch: 58, loss: 0.793249
global_step: 18282, epoch: 58, loss: 0.819615
global_step: 18283, epoch: 58, loss: 0.770966
global_step: 18284, epoch: 58, loss: 0.921461
global_step: 18285, epoch: 58, loss: 0.838213
global_step: 18286, epoch: 58, loss: 0.791227
global_step: 18287, epoch: 58, loss: 0.851819
global_step: 18288, epoch: 58, loss: 0.837663
global_step: 18289, epoch: 58, loss: 0.830671
global_step: 18290, epoch: 58, loss: 0.825501
global_step: 18291, epoch: 58, loss: 0.782166
global_step: 18292, epoch: 58, loss: 0.805334
global_step: 18293, epoch: 58, loss: 0.914726
global_step: 18294, epoch: 58, loss: 0.833457
global_step: 18295, epoch: 58, loss: 0.797120
global_step: 18296, epoch: 58, loss: 0.866451
global_step: 18297, epoch: 58, loss: 0.912308
global_step: 18298, epoch: 58, loss: 0.754085
global_step: 18299, epoch: 58, loss: 0.765299
global_step: 18300, epoch: 58, loss: 0.828557
global_step: 18301, epoch: 58, loss: 0.837124
global_step: 18302, epoch: 58, loss: 0.881846
global_step: 18303, epoch: 58, loss: 0.782459
global_step: 18304, epoch: 58, loss: 0.869352
global_step: 18305, epoch: 58, loss: 0.819538
global_step: 18306, epoch: 58, loss: 0.869566
global_step: 18307, epoch: 58, loss: 0.837058
global_step: 18308, epoch: 58, loss: 0.828769
global_step: 18309, epoch: 58, loss: 0.852749
global_step: 18310, epoch: 58, loss: 0.773142
global_step: 18311, epoch: 58, loss: 0.951726
global_step: 18312, epoch: 58, loss: 0.914731
global_step: 18313, epoch: 58, loss: 0.878007
global_step: 18314, epoch: 58, loss: 0.874405
global_step: 18315, epoch: 58, loss: 0.928665
global_step: 18316, epoch: 58, loss: 0.865813
global_step: 18317, epoch: 58, loss: 0.845276
global_step: 18318, epoch: 58, loss: 0.780324
global_step: 18319, epoch: 58, loss: 0.725610
global_step: 18320, epoch: 58, loss: 0.728390
epoch: 58
train	acc: 0.7731	macro: p 0.6452, r 0.5143, f1: 0.5112	micro: p 0.7731, r 0.7731, f1 0.7731	weighted_f1:0.7476
dev	acc: 0.5780	macro: p 0.5122, r 0.3607, f1: 0.3611	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5414
test	acc: 0.6065	macro: p 0.3579, r 0.3518, f1: 0.3451	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5755
global_step: 18321, epoch: 59, loss: 0.765328
global_step: 18322, epoch: 59, loss: 0.823436
global_step: 18323, epoch: 59, loss: 0.738349
global_step: 18324, epoch: 59, loss: 0.799750
global_step: 18325, epoch: 59, loss: 0.792882
global_step: 18326, epoch: 59, loss: 0.929956
global_step: 18327, epoch: 59, loss: 0.737471
global_step: 18328, epoch: 59, loss: 0.856758
global_step: 18329, epoch: 59, loss: 0.814201
global_step: 18330, epoch: 59, loss: 0.843351
global_step: 18331, epoch: 59, loss: 0.809982
global_step: 18332, epoch: 59, loss: 0.832497
global_step: 18333, epoch: 59, loss: 0.799526
global_step: 18334, epoch: 59, loss: 0.845935
global_step: 18335, epoch: 59, loss: 0.879658
global_step: 18336, epoch: 59, loss: 0.747622
global_step: 18337, epoch: 59, loss: 0.717976
global_step: 18338, epoch: 59, loss: 0.988557
global_step: 18339, epoch: 59, loss: 0.841519
global_step: 18340, epoch: 59, loss: 0.876777
global_step: 18341, epoch: 59, loss: 0.890419
global_step: 18342, epoch: 59, loss: 0.802949
global_step: 18343, epoch: 59, loss: 0.959859
global_step: 18344, epoch: 59, loss: 0.759053
global_step: 18345, epoch: 59, loss: 0.888106
global_step: 18346, epoch: 59, loss: 0.872661
global_step: 18347, epoch: 59, loss: 0.867257
global_step: 18348, epoch: 59, loss: 0.801625
global_step: 18349, epoch: 59, loss: 0.849147
global_step: 18350, epoch: 59, loss: 0.859846
global_step: 18351, epoch: 59, loss: 0.867823
global_step: 18352, epoch: 59, loss: 0.845352
global_step: 18353, epoch: 59, loss: 0.828248
global_step: 18354, epoch: 59, loss: 0.793828
global_step: 18355, epoch: 59, loss: 0.737144
global_step: 18356, epoch: 59, loss: 0.839469
global_step: 18357, epoch: 59, loss: 0.928644
global_step: 18358, epoch: 59, loss: 0.909493
global_step: 18359, epoch: 59, loss: 0.875319
global_step: 18360, epoch: 59, loss: 0.381508
epoch: 59
train	acc: 0.7419	macro: p 0.6402, r 0.4605, f1: 0.4795	micro: p 0.7419, r 0.7419, f1 0.7419	weighted_f1:0.7077
dev	acc: 0.5852	macro: p 0.5557, r 0.3421, f1: 0.3507	micro: p 0.5852, r 0.5852, f1 0.5852	weighted_f1:0.5324
test	acc: 0.6157	macro: p 0.5211, r 0.3296, f1: 0.3369	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5677
global_step: 18361, epoch: 60, loss: 0.798783
global_step: 18362, epoch: 60, loss: 0.713692
global_step: 18363, epoch: 60, loss: 0.793022
global_step: 18364, epoch: 60, loss: 0.764257
global_step: 18365, epoch: 60, loss: 0.651329
global_step: 18366, epoch: 60, loss: 0.906796
global_step: 18367, epoch: 60, loss: 0.815795
global_step: 18368, epoch: 60, loss: 0.849410
global_step: 18369, epoch: 60, loss: 0.819451
global_step: 18370, epoch: 60, loss: 0.817514
global_step: 18371, epoch: 60, loss: 0.948248
global_step: 18372, epoch: 60, loss: 0.743623
global_step: 18373, epoch: 60, loss: 0.790827
global_step: 18374, epoch: 60, loss: 0.787462
global_step: 18375, epoch: 60, loss: 0.839083
global_step: 18376, epoch: 60, loss: 0.849547
global_step: 18377, epoch: 60, loss: 0.885322
global_step: 18378, epoch: 60, loss: 0.846936
global_step: 18379, epoch: 60, loss: 0.802292
global_step: 18380, epoch: 60, loss: 0.925883
global_step: 18381, epoch: 60, loss: 0.803509
global_step: 18382, epoch: 60, loss: 0.771878
global_step: 18383, epoch: 60, loss: 0.983573
global_step: 18384, epoch: 60, loss: 0.862020
global_step: 18385, epoch: 60, loss: 0.802695
global_step: 18386, epoch: 60, loss: 0.708214
global_step: 18387, epoch: 60, loss: 0.786542
global_step: 18388, epoch: 60, loss: 0.893022
global_step: 18389, epoch: 60, loss: 0.796291
global_step: 18390, epoch: 60, loss: 0.794910
global_step: 18391, epoch: 60, loss: 0.897107
global_step: 18392, epoch: 60, loss: 0.823743
global_step: 18393, epoch: 60, loss: 0.778708
global_step: 18394, epoch: 60, loss: 0.786877
global_step: 18395, epoch: 60, loss: 0.774450
global_step: 18396, epoch: 60, loss: 0.763805
global_step: 18397, epoch: 60, loss: 0.795538
global_step: 18398, epoch: 60, loss: 0.833392
global_step: 18399, epoch: 60, loss: 0.831735
global_step: 18400, epoch: 60, loss: 0.267399
epoch: 60
train	acc: 0.7622	macro: p 0.6444, r 0.4862, f1: 0.4999	micro: p 0.7622, r 0.7622, f1 0.7622	weighted_f1:0.7301
dev	acc: 0.5897	macro: p 0.5396, r 0.3587, f1: 0.3682	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5417
test	acc: 0.6142	macro: p 0.5086, r 0.3360, f1: 0.3368	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5697
global_step: 18401, epoch: 61, loss: 0.857761
global_step: 18402, epoch: 61, loss: 0.857697
global_step: 18403, epoch: 61, loss: 0.760522
global_step: 18404, epoch: 61, loss: 0.844425
global_step: 18405, epoch: 61, loss: 0.795901
global_step: 18406, epoch: 61, loss: 0.728541
global_step: 18407, epoch: 61, loss: 0.867751
global_step: 18408, epoch: 61, loss: 0.800144
global_step: 18409, epoch: 61, loss: 0.840103
global_step: 18410, epoch: 61, loss: 0.816949
global_step: 18411, epoch: 61, loss: 0.796788
global_step: 18412, epoch: 61, loss: 0.872245
global_step: 18413, epoch: 61, loss: 0.809548
global_step: 18414, epoch: 61, loss: 0.777680
global_step: 18415, epoch: 61, loss: 0.858889
global_step: 18416, epoch: 61, loss: 0.774017
global_step: 18417, epoch: 61, loss: 0.804560
global_step: 18418, epoch: 61, loss: 0.864385
global_step: 18419, epoch: 61, loss: 0.759397
global_step: 18420, epoch: 61, loss: 0.801298
global_step: 18421, epoch: 61, loss: 0.729267
global_step: 18422, epoch: 61, loss: 0.817947
global_step: 18423, epoch: 61, loss: 0.768831
global_step: 18424, epoch: 61, loss: 0.936498
global_step: 18425, epoch: 61, loss: 0.801135
global_step: 18426, epoch: 61, loss: 0.813713
global_step: 18427, epoch: 61, loss: 0.883969
global_step: 18428, epoch: 61, loss: 0.804625
global_step: 18429, epoch: 61, loss: 0.878806
global_step: 18430, epoch: 61, loss: 0.850623
global_step: 18431, epoch: 61, loss: 0.782491
global_step: 18432, epoch: 61, loss: 0.807911
global_step: 18433, epoch: 61, loss: 0.787798
global_step: 18434, epoch: 61, loss: 1.019772
global_step: 18435, epoch: 61, loss: 0.818738
global_step: 18436, epoch: 61, loss: 0.742911
global_step: 18437, epoch: 61, loss: 0.790811
global_step: 18438, epoch: 61, loss: 0.707854
global_step: 18439, epoch: 61, loss: 0.984373
global_step: 18440, epoch: 61, loss: 0.651183
epoch: 61
train	acc: 0.7799	macro: p 0.6502, r 0.5188, f1: 0.5276	micro: p 0.7799, r 0.7799, f1 0.7799	weighted_f1:0.7550
dev	acc: 0.5843	macro: p 0.4837, r 0.3651, f1: 0.3722	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5456
test	acc: 0.6100	macro: p 0.5130, r 0.3491, f1: 0.3472	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5757
global_step: 18441, epoch: 62, loss: 0.711896
global_step: 18442, epoch: 62, loss: 0.660739
global_step: 18443, epoch: 62, loss: 0.749202
global_step: 18444, epoch: 62, loss: 0.833658
global_step: 18445, epoch: 62, loss: 0.875864
global_step: 18446, epoch: 62, loss: 0.846060
global_step: 18447, epoch: 62, loss: 0.787242
global_step: 18448, epoch: 62, loss: 0.777999
global_step: 18449, epoch: 62, loss: 0.901140
global_step: 18450, epoch: 62, loss: 0.739703
global_step: 18451, epoch: 62, loss: 0.836001
global_step: 18452, epoch: 62, loss: 0.812170
global_step: 18453, epoch: 62, loss: 0.786214
global_step: 18454, epoch: 62, loss: 0.829930
global_step: 18455, epoch: 62, loss: 0.753673
global_step: 18456, epoch: 62, loss: 0.809040
global_step: 18457, epoch: 62, loss: 0.842439
global_step: 18458, epoch: 62, loss: 0.786953
global_step: 18459, epoch: 62, loss: 0.872113
global_step: 18460, epoch: 62, loss: 0.773098
global_step: 18461, epoch: 62, loss: 0.743494
global_step: 18462, epoch: 62, loss: 0.781265
global_step: 18463, epoch: 62, loss: 0.803567
global_step: 18464, epoch: 62, loss: 0.794057
global_step: 18465, epoch: 62, loss: 0.789074
global_step: 18466, epoch: 62, loss: 0.775088
global_step: 18467, epoch: 62, loss: 0.842772
global_step: 18468, epoch: 62, loss: 0.902774
global_step: 18469, epoch: 62, loss: 0.875009
global_step: 18470, epoch: 62, loss: 0.776587
global_step: 18471, epoch: 62, loss: 0.792929
global_step: 18472, epoch: 62, loss: 0.779923
global_step: 18473, epoch: 62, loss: 0.807290
global_step: 18474, epoch: 62, loss: 0.720481
global_step: 18475, epoch: 62, loss: 0.813814
global_step: 18476, epoch: 62, loss: 0.881841
global_step: 18477, epoch: 62, loss: 0.904587
global_step: 18478, epoch: 62, loss: 0.799936
global_step: 18479, epoch: 62, loss: 0.727803
global_step: 18480, epoch: 62, loss: 0.572965
epoch: 62
train	acc: 0.7782	macro: p 0.6593, r 0.5132, f1: 0.5262	micro: p 0.7782, r 0.7782, f1 0.7782	weighted_f1:0.7510
dev	acc: 0.5870	macro: p 0.5248, r 0.3605, f1: 0.3718	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5446
test	acc: 0.6184	macro: p 0.5150, r 0.3467, f1: 0.3496	micro: p 0.6184, r 0.6184, f1 0.6184	weighted_f1:0.5791
global_step: 18481, epoch: 63, loss: 0.823343
global_step: 18482, epoch: 63, loss: 0.816835
global_step: 18483, epoch: 63, loss: 0.847053
global_step: 18484, epoch: 63, loss: 0.805126
global_step: 18485, epoch: 63, loss: 0.692474
global_step: 18486, epoch: 63, loss: 0.764172
global_step: 18487, epoch: 63, loss: 0.863410
global_step: 18488, epoch: 63, loss: 0.753268
global_step: 18489, epoch: 63, loss: 0.775230
global_step: 18490, epoch: 63, loss: 0.726743
global_step: 18491, epoch: 63, loss: 0.859176
global_step: 18492, epoch: 63, loss: 0.730995
global_step: 18493, epoch: 63, loss: 0.815170
global_step: 18494, epoch: 63, loss: 0.830322
global_step: 18495, epoch: 63, loss: 0.839079
global_step: 18496, epoch: 63, loss: 0.807195
global_step: 18497, epoch: 63, loss: 0.861893
global_step: 18498, epoch: 63, loss: 0.714522
global_step: 18499, epoch: 63, loss: 0.757322
global_step: 18500, epoch: 63, loss: 0.707932
global_step: 18501, epoch: 63, loss: 0.742439
global_step: 18502, epoch: 63, loss: 0.892842
global_step: 18503, epoch: 63, loss: 0.701414
global_step: 18504, epoch: 63, loss: 0.861071
global_step: 18505, epoch: 63, loss: 0.797439
global_step: 18506, epoch: 63, loss: 0.920575
global_step: 18507, epoch: 63, loss: 0.774404
global_step: 18508, epoch: 63, loss: 0.793068
global_step: 18509, epoch: 63, loss: 0.789544
global_step: 18510, epoch: 63, loss: 0.795268
global_step: 18511, epoch: 63, loss: 0.801384
global_step: 18512, epoch: 63, loss: 0.799876
global_step: 18513, epoch: 63, loss: 0.860753
global_step: 18514, epoch: 63, loss: 0.732336
global_step: 18515, epoch: 63, loss: 0.852370
global_step: 18516, epoch: 63, loss: 0.663619
global_step: 18517, epoch: 63, loss: 0.816687
global_step: 18518, epoch: 63, loss: 0.761097
global_step: 18519, epoch: 63, loss: 0.757675
global_step: 18520, epoch: 63, loss: 0.644343
epoch: 63
train	acc: 0.7928	macro: p 0.6580, r 0.5379, f1: 0.5446	micro: p 0.7928, r 0.7928, f1 0.7928	weighted_f1:0.7692
dev	acc: 0.5843	macro: p 0.4789, r 0.3693, f1: 0.3760	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5479
test	acc: 0.6084	macro: p 0.5084, r 0.3520, f1: 0.3488	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5753
New best model!
global_step: 18521, epoch: 64, loss: 0.739546
global_step: 18522, epoch: 64, loss: 0.615076
global_step: 18523, epoch: 64, loss: 0.720410
global_step: 18524, epoch: 64, loss: 0.784315
global_step: 18525, epoch: 64, loss: 0.767829
global_step: 18526, epoch: 64, loss: 0.784089
global_step: 18527, epoch: 64, loss: 0.961619
global_step: 18528, epoch: 64, loss: 0.692481
global_step: 18529, epoch: 64, loss: 0.791774
global_step: 18530, epoch: 64, loss: 0.698020
global_step: 18531, epoch: 64, loss: 0.801981
global_step: 18532, epoch: 64, loss: 0.786385
global_step: 18533, epoch: 64, loss: 0.783968
global_step: 18534, epoch: 64, loss: 0.869761
global_step: 18535, epoch: 64, loss: 0.842356
global_step: 18536, epoch: 64, loss: 0.846595
global_step: 18537, epoch: 64, loss: 0.804879
global_step: 18538, epoch: 64, loss: 0.721974
global_step: 18539, epoch: 64, loss: 0.665050
global_step: 18540, epoch: 64, loss: 0.820874
global_step: 18541, epoch: 64, loss: 0.740139
global_step: 18542, epoch: 64, loss: 0.909267
global_step: 18543, epoch: 64, loss: 0.695985
global_step: 18544, epoch: 64, loss: 0.766176
global_step: 18545, epoch: 64, loss: 0.735236
global_step: 18546, epoch: 64, loss: 0.811480
global_step: 18547, epoch: 64, loss: 0.905639
global_step: 18548, epoch: 64, loss: 0.800721
global_step: 18549, epoch: 64, loss: 0.854473
global_step: 18550, epoch: 64, loss: 0.849455
global_step: 18551, epoch: 64, loss: 0.775593
global_step: 18552, epoch: 64, loss: 0.684223
global_step: 18553, epoch: 64, loss: 0.794526
global_step: 18554, epoch: 64, loss: 0.804272
global_step: 18555, epoch: 64, loss: 0.770475
global_step: 18556, epoch: 64, loss: 0.796476
global_step: 18557, epoch: 64, loss: 0.709542
global_step: 18558, epoch: 64, loss: 0.779967
global_step: 18559, epoch: 64, loss: 0.812491
global_step: 18560, epoch: 64, loss: 0.341940
epoch: 64
train	acc: 0.7800	macro: p 0.6615, r 0.5210, f1: 0.5346	micro: p 0.7800, r 0.7800, f1 0.7800	weighted_f1:0.7544
dev	acc: 0.5825	macro: p 0.5121, r 0.3533, f1: 0.3664	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5391
test	acc: 0.6165	macro: p 0.5150, r 0.3448, f1: 0.3517	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5781
global_step: 18561, epoch: 65, loss: 0.746098
global_step: 18562, epoch: 65, loss: 0.736033
global_step: 18563, epoch: 65, loss: 0.739255
global_step: 18564, epoch: 65, loss: 0.691193
global_step: 18565, epoch: 65, loss: 0.791750
global_step: 18566, epoch: 65, loss: 0.738031
global_step: 18567, epoch: 65, loss: 0.735656
global_step: 18568, epoch: 65, loss: 0.847162
global_step: 18569, epoch: 65, loss: 0.757947
global_step: 18570, epoch: 65, loss: 0.725162
global_step: 18571, epoch: 65, loss: 0.651838
global_step: 18572, epoch: 65, loss: 0.773218
global_step: 18573, epoch: 65, loss: 0.898031
global_step: 18574, epoch: 65, loss: 0.792049
global_step: 18575, epoch: 65, loss: 0.721024
global_step: 18576, epoch: 65, loss: 0.697297
global_step: 18577, epoch: 65, loss: 0.755074
global_step: 18578, epoch: 65, loss: 0.861709
global_step: 18579, epoch: 65, loss: 0.673702
global_step: 18580, epoch: 65, loss: 0.832295
global_step: 18581, epoch: 65, loss: 0.739602
global_step: 18582, epoch: 65, loss: 0.714686
global_step: 18583, epoch: 65, loss: 0.766188
global_step: 18584, epoch: 65, loss: 0.813130
global_step: 18585, epoch: 65, loss: 0.716066
global_step: 18586, epoch: 65, loss: 0.850392
global_step: 18587, epoch: 65, loss: 0.794894
global_step: 18588, epoch: 65, loss: 0.768112
global_step: 18589, epoch: 65, loss: 0.826805
global_step: 18590, epoch: 65, loss: 0.872150
global_step: 18591, epoch: 65, loss: 0.798580
global_step: 18592, epoch: 65, loss: 0.723850
global_step: 18593, epoch: 65, loss: 0.779026
global_step: 18594, epoch: 65, loss: 0.732637
global_step: 18595, epoch: 65, loss: 0.811683
global_step: 18596, epoch: 65, loss: 0.688268
global_step: 18597, epoch: 65, loss: 0.841172
global_step: 18598, epoch: 65, loss: 0.865683
global_step: 18599, epoch: 65, loss: 0.785941
global_step: 18600, epoch: 65, loss: 1.178789
epoch: 65
train	acc: 0.7876	macro: p 0.6714, r 0.5252, f1: 0.5395	micro: p 0.7876, r 0.7876, f1 0.7876	weighted_f1:0.7629
dev	acc: 0.5771	macro: p 0.4742, r 0.3484, f1: 0.3609	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5355
test	acc: 0.6188	macro: p 0.5206, r 0.3443, f1: 0.3509	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5813
global_step: 18601, epoch: 66, loss: 0.675841
global_step: 18602, epoch: 66, loss: 0.781318
global_step: 18603, epoch: 66, loss: 0.720115
global_step: 18604, epoch: 66, loss: 0.769803
global_step: 18605, epoch: 66, loss: 0.664901
global_step: 18606, epoch: 66, loss: 0.807442
global_step: 18607, epoch: 66, loss: 0.735306
global_step: 18608, epoch: 66, loss: 0.723700
global_step: 18609, epoch: 66, loss: 0.784639
global_step: 18610, epoch: 66, loss: 0.809905
global_step: 18611, epoch: 66, loss: 0.696477
global_step: 18612, epoch: 66, loss: 0.668936
global_step: 18613, epoch: 66, loss: 0.803829
global_step: 18614, epoch: 66, loss: 0.869897
global_step: 18615, epoch: 66, loss: 0.747383
global_step: 18616, epoch: 66, loss: 0.773919
global_step: 18617, epoch: 66, loss: 0.762560
global_step: 18618, epoch: 66, loss: 0.720936
global_step: 18619, epoch: 66, loss: 0.786739
global_step: 18620, epoch: 66, loss: 0.756277
global_step: 18621, epoch: 66, loss: 0.750175
global_step: 18622, epoch: 66, loss: 0.723515
global_step: 18623, epoch: 66, loss: 0.756222
global_step: 18624, epoch: 66, loss: 0.717835
global_step: 18625, epoch: 66, loss: 0.716579
global_step: 18626, epoch: 66, loss: 0.748831
global_step: 18627, epoch: 66, loss: 0.744387
global_step: 18628, epoch: 66, loss: 0.732768
global_step: 18629, epoch: 66, loss: 0.818179
global_step: 18630, epoch: 66, loss: 0.706291
global_step: 18631, epoch: 66, loss: 0.776595
global_step: 18632, epoch: 66, loss: 0.823946
global_step: 18633, epoch: 66, loss: 0.828566
global_step: 18634, epoch: 66, loss: 0.804334
global_step: 18635, epoch: 66, loss: 0.815557
global_step: 18636, epoch: 66, loss: 0.775085
global_step: 18637, epoch: 66, loss: 0.801578
global_step: 18638, epoch: 66, loss: 0.772300
global_step: 18639, epoch: 66, loss: 0.700345
global_step: 18640, epoch: 66, loss: 0.728298
epoch: 66
train	acc: 0.7933	macro: p 0.6690, r 0.5422, f1: 0.5513	micro: p 0.7933, r 0.7933, f1 0.7933	weighted_f1:0.7716
dev	acc: 0.5753	macro: p 0.4634, r 0.3523, f1: 0.3664	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5377
test	acc: 0.6115	macro: p 0.5108, r 0.3445, f1: 0.3554	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5786
global_step: 18641, epoch: 67, loss: 0.722832
global_step: 18642, epoch: 67, loss: 0.773089
global_step: 18643, epoch: 67, loss: 0.748084
global_step: 18644, epoch: 67, loss: 0.739456
global_step: 18645, epoch: 67, loss: 0.723141
global_step: 18646, epoch: 67, loss: 0.781196
global_step: 18647, epoch: 67, loss: 0.723412
global_step: 18648, epoch: 67, loss: 0.775197
global_step: 18649, epoch: 67, loss: 0.715667
global_step: 18650, epoch: 67, loss: 0.933875
global_step: 18651, epoch: 67, loss: 0.647577
global_step: 18652, epoch: 67, loss: 0.704825
global_step: 18653, epoch: 67, loss: 0.772813
global_step: 18654, epoch: 67, loss: 0.886186
global_step: 18655, epoch: 67, loss: 0.786960
global_step: 18656, epoch: 67, loss: 0.812659
global_step: 18657, epoch: 67, loss: 0.740820
global_step: 18658, epoch: 67, loss: 0.788649
global_step: 18659, epoch: 67, loss: 0.786421
global_step: 18660, epoch: 67, loss: 0.675120
global_step: 18661, epoch: 67, loss: 0.758254
global_step: 18662, epoch: 67, loss: 0.654706
global_step: 18663, epoch: 67, loss: 0.699747
global_step: 18664, epoch: 67, loss: 0.738056
global_step: 18665, epoch: 67, loss: 0.660923
global_step: 18666, epoch: 67, loss: 0.681103
global_step: 18667, epoch: 67, loss: 0.683829
global_step: 18668, epoch: 67, loss: 0.799180
global_step: 18669, epoch: 67, loss: 0.862402
global_step: 18670, epoch: 67, loss: 0.759433
global_step: 18671, epoch: 67, loss: 0.726411
global_step: 18672, epoch: 67, loss: 0.796834
global_step: 18673, epoch: 67, loss: 0.684608
global_step: 18674, epoch: 67, loss: 0.745198
global_step: 18675, epoch: 67, loss: 0.752638
global_step: 18676, epoch: 67, loss: 0.709995
global_step: 18677, epoch: 67, loss: 0.750572
global_step: 18678, epoch: 67, loss: 0.762125
global_step: 18679, epoch: 67, loss: 0.697924
global_step: 18680, epoch: 67, loss: 0.651439
epoch: 67
train	acc: 0.7976	macro: p 0.6763, r 0.5374, f1: 0.5530	micro: p 0.7976, r 0.7976, f1 0.7976	weighted_f1:0.7722
dev	acc: 0.5816	macro: p 0.4740, r 0.3543, f1: 0.3665	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5389
test	acc: 0.6176	macro: p 0.5163, r 0.3458, f1: 0.3504	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5790
global_step: 18681, epoch: 68, loss: 0.742957
global_step: 18682, epoch: 68, loss: 0.821335
global_step: 18683, epoch: 68, loss: 0.775007
global_step: 18684, epoch: 68, loss: 0.820413
global_step: 18685, epoch: 68, loss: 0.690860
global_step: 18686, epoch: 68, loss: 0.802975
global_step: 18687, epoch: 68, loss: 0.659133
global_step: 18688, epoch: 68, loss: 0.761759
global_step: 18689, epoch: 68, loss: 0.680951
global_step: 18690, epoch: 68, loss: 0.741922
global_step: 18691, epoch: 68, loss: 0.668592
global_step: 18692, epoch: 68, loss: 0.750713
global_step: 18693, epoch: 68, loss: 0.730948
global_step: 18694, epoch: 68, loss: 0.835324
global_step: 18695, epoch: 68, loss: 0.679540
global_step: 18696, epoch: 68, loss: 0.714399
global_step: 18697, epoch: 68, loss: 0.764874
global_step: 18698, epoch: 68, loss: 0.711547
global_step: 18699, epoch: 68, loss: 0.754713
global_step: 18700, epoch: 68, loss: 0.723333
global_step: 18701, epoch: 68, loss: 0.662646
global_step: 18702, epoch: 68, loss: 0.676697
global_step: 18703, epoch: 68, loss: 0.809077
global_step: 18704, epoch: 68, loss: 0.883751
global_step: 18705, epoch: 68, loss: 0.630141
global_step: 18706, epoch: 68, loss: 0.765959
global_step: 18707, epoch: 68, loss: 0.773741
global_step: 18708, epoch: 68, loss: 0.699394
global_step: 18709, epoch: 68, loss: 0.784551
global_step: 18710, epoch: 68, loss: 0.764621
global_step: 18711, epoch: 68, loss: 0.612746
global_step: 18712, epoch: 68, loss: 0.741161
global_step: 18713, epoch: 68, loss: 0.827513
global_step: 18714, epoch: 68, loss: 0.770935
global_step: 18715, epoch: 68, loss: 0.724019
global_step: 18716, epoch: 68, loss: 0.779589
global_step: 18717, epoch: 68, loss: 0.706464
global_step: 18718, epoch: 68, loss: 0.741938
global_step: 18719, epoch: 68, loss: 0.811091
global_step: 18720, epoch: 68, loss: 0.553529
epoch: 68
train	acc: 0.8019	macro: p 0.6748, r 0.5464, f1: 0.5579	micro: p 0.8019, r 0.8019, f1 0.8019	weighted_f1:0.7791
dev	acc: 0.5735	macro: p 0.4678, r 0.3487, f1: 0.3608	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5331
test	acc: 0.6142	macro: p 0.5147, r 0.3459, f1: 0.3544	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5794
global_step: 18721, epoch: 69, loss: 0.782841
global_step: 18722, epoch: 69, loss: 0.769938
global_step: 18723, epoch: 69, loss: 0.709635
global_step: 18724, epoch: 69, loss: 0.800044
global_step: 18725, epoch: 69, loss: 0.862756
global_step: 18726, epoch: 69, loss: 0.740767
global_step: 18727, epoch: 69, loss: 0.689608
global_step: 18728, epoch: 69, loss: 0.716320
global_step: 18729, epoch: 69, loss: 0.708233
global_step: 18730, epoch: 69, loss: 0.729985
global_step: 18731, epoch: 69, loss: 0.735816
global_step: 18732, epoch: 69, loss: 0.775822
global_step: 18733, epoch: 69, loss: 0.718451
global_step: 18734, epoch: 69, loss: 0.737444
global_step: 18735, epoch: 69, loss: 0.828833
global_step: 18736, epoch: 69, loss: 0.667276
global_step: 18737, epoch: 69, loss: 0.688573
global_step: 18738, epoch: 69, loss: 0.776306
global_step: 18739, epoch: 69, loss: 0.701754
global_step: 18740, epoch: 69, loss: 0.685384
global_step: 18741, epoch: 69, loss: 0.631962
global_step: 18742, epoch: 69, loss: 0.810695
global_step: 18743, epoch: 69, loss: 0.862358
global_step: 18744, epoch: 69, loss: 0.771862
global_step: 18745, epoch: 69, loss: 0.660069
global_step: 18746, epoch: 69, loss: 0.694215
global_step: 18747, epoch: 69, loss: 0.807460
global_step: 18748, epoch: 69, loss: 0.725223
global_step: 18749, epoch: 69, loss: 0.652534
global_step: 18750, epoch: 69, loss: 0.732431
global_step: 18751, epoch: 69, loss: 0.792815
global_step: 18752, epoch: 69, loss: 0.772662
global_step: 18753, epoch: 69, loss: 0.768409
global_step: 18754, epoch: 69, loss: 0.706324
global_step: 18755, epoch: 69, loss: 0.721434
global_step: 18756, epoch: 69, loss: 0.740584
global_step: 18757, epoch: 69, loss: 0.744795
global_step: 18758, epoch: 69, loss: 0.683888
global_step: 18759, epoch: 69, loss: 0.622798
global_step: 18760, epoch: 69, loss: 1.089302
epoch: 69
train	acc: 0.7688	macro: p 0.6795, r 0.5073, f1: 0.5384	micro: p 0.7688, r 0.7688, f1 0.7688	weighted_f1:0.7410
dev	acc: 0.5726	macro: p 0.4902, r 0.3352, f1: 0.3531	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5211
test	acc: 0.6153	macro: p 0.5191, r 0.3279, f1: 0.3404	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5666
global_step: 18761, epoch: 70, loss: 0.778225
global_step: 18762, epoch: 70, loss: 0.696427
global_step: 18763, epoch: 70, loss: 0.665226
global_step: 18764, epoch: 70, loss: 0.828117
global_step: 18765, epoch: 70, loss: 0.756185
global_step: 18766, epoch: 70, loss: 0.686534
global_step: 18767, epoch: 70, loss: 0.685536
global_step: 18768, epoch: 70, loss: 0.755813
global_step: 18769, epoch: 70, loss: 0.678808
global_step: 18770, epoch: 70, loss: 0.683741
global_step: 18771, epoch: 70, loss: 0.705462
global_step: 18772, epoch: 70, loss: 0.737478
global_step: 18773, epoch: 70, loss: 0.732428
global_step: 18774, epoch: 70, loss: 0.680975
global_step: 18775, epoch: 70, loss: 0.808612
global_step: 18776, epoch: 70, loss: 0.742484
global_step: 18777, epoch: 70, loss: 0.730715
global_step: 18778, epoch: 70, loss: 0.794282
global_step: 18779, epoch: 70, loss: 0.869584
global_step: 18780, epoch: 70, loss: 0.776666
global_step: 18781, epoch: 70, loss: 0.680294
global_step: 18782, epoch: 70, loss: 0.802374
global_step: 18783, epoch: 70, loss: 0.862270
global_step: 18784, epoch: 70, loss: 0.717987
global_step: 18785, epoch: 70, loss: 0.610427
global_step: 18786, epoch: 70, loss: 0.710254
global_step: 18787, epoch: 70, loss: 0.660085
global_step: 18788, epoch: 70, loss: 0.797443
global_step: 18789, epoch: 70, loss: 0.642991
global_step: 18790, epoch: 70, loss: 0.688195
global_step: 18791, epoch: 70, loss: 0.659294
global_step: 18792, epoch: 70, loss: 0.720033
global_step: 18793, epoch: 70, loss: 0.752350
global_step: 18794, epoch: 70, loss: 0.678414
global_step: 18795, epoch: 70, loss: 0.682672
global_step: 18796, epoch: 70, loss: 0.690448
global_step: 18797, epoch: 70, loss: 0.768905
global_step: 18798, epoch: 70, loss: 0.683354
global_step: 18799, epoch: 70, loss: 0.716414
global_step: 18800, epoch: 70, loss: 0.842126
epoch: 70
train	acc: 0.8208	macro: p 0.6868, r 0.5780, f1: 0.5847	micro: p 0.8208, r 0.8208, f1 0.8208	weighted_f1:0.8012
dev	acc: 0.5744	macro: p 0.4653, r 0.3617, f1: 0.3696	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5424
test	acc: 0.6031	macro: p 0.5040, r 0.3535, f1: 0.3535	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5753
global_step: 18801, epoch: 71, loss: 0.671835
global_step: 18802, epoch: 71, loss: 0.811065
global_step: 18803, epoch: 71, loss: 0.674555
global_step: 18804, epoch: 71, loss: 0.740868
global_step: 18805, epoch: 71, loss: 0.715931
global_step: 18806, epoch: 71, loss: 0.588524
global_step: 18807, epoch: 71, loss: 0.666123
global_step: 18808, epoch: 71, loss: 0.767967
global_step: 18809, epoch: 71, loss: 0.642328
global_step: 18810, epoch: 71, loss: 0.797336
global_step: 18811, epoch: 71, loss: 0.716113
global_step: 18812, epoch: 71, loss: 0.708659
global_step: 18813, epoch: 71, loss: 0.790573
global_step: 18814, epoch: 71, loss: 0.678892
global_step: 18815, epoch: 71, loss: 0.661249
global_step: 18816, epoch: 71, loss: 0.680776
global_step: 18817, epoch: 71, loss: 0.748739
global_step: 18818, epoch: 71, loss: 0.695360
global_step: 18819, epoch: 71, loss: 0.642671
global_step: 18820, epoch: 71, loss: 0.797460
global_step: 18821, epoch: 71, loss: 0.693578
global_step: 18822, epoch: 71, loss: 0.665171
global_step: 18823, epoch: 71, loss: 0.751957
global_step: 18824, epoch: 71, loss: 0.746398
global_step: 18825, epoch: 71, loss: 0.724592
global_step: 18826, epoch: 71, loss: 0.758800
global_step: 18827, epoch: 71, loss: 0.707642
global_step: 18828, epoch: 71, loss: 0.735459
global_step: 18829, epoch: 71, loss: 0.788074
global_step: 18830, epoch: 71, loss: 0.563668
global_step: 18831, epoch: 71, loss: 0.791543
global_step: 18832, epoch: 71, loss: 0.724228
global_step: 18833, epoch: 71, loss: 0.603967
global_step: 18834, epoch: 71, loss: 0.656412
global_step: 18835, epoch: 71, loss: 0.732767
global_step: 18836, epoch: 71, loss: 0.690055
global_step: 18837, epoch: 71, loss: 0.722926
global_step: 18838, epoch: 71, loss: 0.745241
global_step: 18839, epoch: 71, loss: 0.807691
global_step: 18840, epoch: 71, loss: 0.778617
epoch: 71
train	acc: 0.8186	macro: p 0.6961, r 0.5751, f1: 0.5950	micro: p 0.8186, r 0.8186, f1 0.8186	weighted_f1:0.7973
dev	acc: 0.5816	macro: p 0.4312, r 0.3557, f1: 0.3648	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5397
test	acc: 0.6115	macro: p 0.4269, r 0.3442, f1: 0.3505	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5749
global_step: 18841, epoch: 72, loss: 0.733095
global_step: 18842, epoch: 72, loss: 0.701092
global_step: 18843, epoch: 72, loss: 0.691874
global_step: 18844, epoch: 72, loss: 0.727328
global_step: 18845, epoch: 72, loss: 0.712788
global_step: 18846, epoch: 72, loss: 0.640609
global_step: 18847, epoch: 72, loss: 0.749771
global_step: 18848, epoch: 72, loss: 0.684228
global_step: 18849, epoch: 72, loss: 0.729221
global_step: 18850, epoch: 72, loss: 0.660431
global_step: 18851, epoch: 72, loss: 0.725273
global_step: 18852, epoch: 72, loss: 0.847511
global_step: 18853, epoch: 72, loss: 0.649207
global_step: 18854, epoch: 72, loss: 0.691991
global_step: 18855, epoch: 72, loss: 0.666366
global_step: 18856, epoch: 72, loss: 0.655116
global_step: 18857, epoch: 72, loss: 0.649063
global_step: 18858, epoch: 72, loss: 0.672015
global_step: 18859, epoch: 72, loss: 0.698795
global_step: 18860, epoch: 72, loss: 0.697844
global_step: 18861, epoch: 72, loss: 0.640004
global_step: 18862, epoch: 72, loss: 0.721207
global_step: 18863, epoch: 72, loss: 0.716403
global_step: 18864, epoch: 72, loss: 0.828688
global_step: 18865, epoch: 72, loss: 0.566192
global_step: 18866, epoch: 72, loss: 0.590629
global_step: 18867, epoch: 72, loss: 0.618762
global_step: 18868, epoch: 72, loss: 0.848892
global_step: 18869, epoch: 72, loss: 0.695469
global_step: 18870, epoch: 72, loss: 0.616268
global_step: 18871, epoch: 72, loss: 0.726741
global_step: 18872, epoch: 72, loss: 0.784128
global_step: 18873, epoch: 72, loss: 0.730878
global_step: 18874, epoch: 72, loss: 0.690542
global_step: 18875, epoch: 72, loss: 0.762020
global_step: 18876, epoch: 72, loss: 0.749961
global_step: 18877, epoch: 72, loss: 0.734775
global_step: 18878, epoch: 72, loss: 0.754918
global_step: 18879, epoch: 72, loss: 0.688516
global_step: 18880, epoch: 72, loss: 1.885915
epoch: 72
train	acc: 0.8153	macro: p 0.6958, r 0.5724, f1: 0.5981	micro: p 0.8153, r 0.8153, f1 0.8153	weighted_f1:0.7945
dev	acc: 0.5753	macro: p 0.4292, r 0.3440, f1: 0.3536	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5298
test	acc: 0.6172	macro: p 0.4425, r 0.3428, f1: 0.3527	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5783
global_step: 18881, epoch: 73, loss: 0.719942
global_step: 18882, epoch: 73, loss: 0.670294
global_step: 18883, epoch: 73, loss: 0.711577
global_step: 18884, epoch: 73, loss: 0.749298
global_step: 18885, epoch: 73, loss: 0.659207
global_step: 18886, epoch: 73, loss: 0.686150
global_step: 18887, epoch: 73, loss: 0.778845
global_step: 18888, epoch: 73, loss: 0.754974
global_step: 18889, epoch: 73, loss: 0.694969
global_step: 18890, epoch: 73, loss: 0.663475
global_step: 18891, epoch: 73, loss: 0.684159
global_step: 18892, epoch: 73, loss: 0.754740
global_step: 18893, epoch: 73, loss: 0.748863
global_step: 18894, epoch: 73, loss: 0.681983
global_step: 18895, epoch: 73, loss: 0.757477
global_step: 18896, epoch: 73, loss: 0.696413
global_step: 18897, epoch: 73, loss: 0.705347
global_step: 18898, epoch: 73, loss: 0.656592
global_step: 18899, epoch: 73, loss: 0.765469
global_step: 18900, epoch: 73, loss: 0.802251
global_step: 18901, epoch: 73, loss: 0.585540
global_step: 18902, epoch: 73, loss: 0.625473
global_step: 18903, epoch: 73, loss: 0.721233
global_step: 18904, epoch: 73, loss: 0.641772
global_step: 18905, epoch: 73, loss: 0.802641
global_step: 18906, epoch: 73, loss: 0.647815
global_step: 18907, epoch: 73, loss: 0.716353
global_step: 18908, epoch: 73, loss: 0.678319
global_step: 18909, epoch: 73, loss: 0.689395
global_step: 18910, epoch: 73, loss: 0.710130
global_step: 18911, epoch: 73, loss: 0.679291
global_step: 18912, epoch: 73, loss: 0.625618
global_step: 18913, epoch: 73, loss: 0.661206
global_step: 18914, epoch: 73, loss: 0.737192
global_step: 18915, epoch: 73, loss: 0.689351
global_step: 18916, epoch: 73, loss: 0.733255
global_step: 18917, epoch: 73, loss: 0.723310
global_step: 18918, epoch: 73, loss: 0.696421
global_step: 18919, epoch: 73, loss: 0.735448
global_step: 18920, epoch: 73, loss: 0.316103
epoch: 73
train	acc: 0.8353	macro: p 0.6918, r 0.6051, f1: 0.6159	micro: p 0.8353, r 0.8353, f1 0.8353	weighted_f1:0.8166
dev	acc: 0.5816	macro: p 0.4655, r 0.3642, f1: 0.3740	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5447
test	acc: 0.6069	macro: p 0.4518, r 0.3492, f1: 0.3522	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5744
global_step: 18921, epoch: 74, loss: 0.662873
global_step: 18922, epoch: 74, loss: 0.638984
global_step: 18923, epoch: 74, loss: 0.698301
global_step: 18924, epoch: 74, loss: 0.765776
global_step: 18925, epoch: 74, loss: 0.726879
global_step: 18926, epoch: 74, loss: 0.668150
global_step: 18927, epoch: 74, loss: 0.725364
global_step: 18928, epoch: 74, loss: 0.722365
global_step: 18929, epoch: 74, loss: 0.647779
global_step: 18930, epoch: 74, loss: 0.684634
global_step: 18931, epoch: 74, loss: 0.651816
global_step: 18932, epoch: 74, loss: 0.688077
global_step: 18933, epoch: 74, loss: 0.683938
global_step: 18934, epoch: 74, loss: 0.728893
global_step: 18935, epoch: 74, loss: 0.580617
global_step: 18936, epoch: 74, loss: 0.585745
global_step: 18937, epoch: 74, loss: 0.682423
global_step: 18938, epoch: 74, loss: 0.679222
global_step: 18939, epoch: 74, loss: 0.767250
global_step: 18940, epoch: 74, loss: 0.707608
global_step: 18941, epoch: 74, loss: 0.656015
global_step: 18942, epoch: 74, loss: 0.713264
global_step: 18943, epoch: 74, loss: 0.633801
global_step: 18944, epoch: 74, loss: 0.640465
global_step: 18945, epoch: 74, loss: 0.670511
global_step: 18946, epoch: 74, loss: 0.789019
global_step: 18947, epoch: 74, loss: 0.656834
global_step: 18948, epoch: 74, loss: 0.734709
global_step: 18949, epoch: 74, loss: 0.736158
global_step: 18950, epoch: 74, loss: 0.685916
global_step: 18951, epoch: 74, loss: 0.695191
global_step: 18952, epoch: 74, loss: 0.837633
global_step: 18953, epoch: 74, loss: 0.733063
global_step: 18954, epoch: 74, loss: 0.661029
global_step: 18955, epoch: 74, loss: 0.666165
global_step: 18956, epoch: 74, loss: 0.672005
global_step: 18957, epoch: 74, loss: 0.663492
global_step: 18958, epoch: 74, loss: 0.736593
global_step: 18959, epoch: 74, loss: 0.741242
global_step: 18960, epoch: 74, loss: 1.111895
epoch: 74
train	acc: 0.8368	macro: p 0.6923, r 0.6165, f1: 0.6160	micro: p 0.8368, r 0.8368, f1 0.8368	weighted_f1:0.8215
dev	acc: 0.5618	macro: p 0.4513, r 0.3654, f1: 0.3711	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5380
test	acc: 0.5889	macro: p 0.4505, r 0.3577, f1: 0.3571	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5719
global_step: 18961, epoch: 75, loss: 0.722730
global_step: 18962, epoch: 75, loss: 0.731880
global_step: 18963, epoch: 75, loss: 0.725263
global_step: 18964, epoch: 75, loss: 0.669343
global_step: 18965, epoch: 75, loss: 0.662903
global_step: 18966, epoch: 75, loss: 0.685945
global_step: 18967, epoch: 75, loss: 0.593433
global_step: 18968, epoch: 75, loss: 0.633670
global_step: 18969, epoch: 75, loss: 0.719050
global_step: 18970, epoch: 75, loss: 0.711370
global_step: 18971, epoch: 75, loss: 0.748055
global_step: 18972, epoch: 75, loss: 0.635040
global_step: 18973, epoch: 75, loss: 0.697229
global_step: 18974, epoch: 75, loss: 0.753289
global_step: 18975, epoch: 75, loss: 0.667663
global_step: 18976, epoch: 75, loss: 0.688050
global_step: 18977, epoch: 75, loss: 0.727634
global_step: 18978, epoch: 75, loss: 0.747919
global_step: 18979, epoch: 75, loss: 0.675417
global_step: 18980, epoch: 75, loss: 0.721476
global_step: 18981, epoch: 75, loss: 0.603931
global_step: 18982, epoch: 75, loss: 0.683086
global_step: 18983, epoch: 75, loss: 0.680768
global_step: 18984, epoch: 75, loss: 0.692424
global_step: 18985, epoch: 75, loss: 0.624848
global_step: 18986, epoch: 75, loss: 0.665306
global_step: 18987, epoch: 75, loss: 0.759251
global_step: 18988, epoch: 75, loss: 0.669372
global_step: 18989, epoch: 75, loss: 0.646196
global_step: 18990, epoch: 75, loss: 0.709980
global_step: 18991, epoch: 75, loss: 0.676965
global_step: 18992, epoch: 75, loss: 0.693160
global_step: 18993, epoch: 75, loss: 0.626618
global_step: 18994, epoch: 75, loss: 0.646110
global_step: 18995, epoch: 75, loss: 0.660086
global_step: 18996, epoch: 75, loss: 0.699994
global_step: 18997, epoch: 75, loss: 0.649996
global_step: 18998, epoch: 75, loss: 0.728986
global_step: 18999, epoch: 75, loss: 0.561181
global_step: 19000, epoch: 75, loss: 1.140598
epoch: 75
train	acc: 0.8434	macro: p 0.6997, r 0.6235, f1: 0.6364	micro: p 0.8434, r 0.8434, f1 0.8434	weighted_f1:0.8261
dev	acc: 0.5834	macro: p 0.4314, r 0.3669, f1: 0.3757	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5477
test	acc: 0.6073	macro: p 0.4274, r 0.3500, f1: 0.3530	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5756
global_step: 19001, epoch: 76, loss: 0.543754
global_step: 19002, epoch: 76, loss: 0.715131
global_step: 19003, epoch: 76, loss: 0.806475
global_step: 19004, epoch: 76, loss: 0.617282
global_step: 19005, epoch: 76, loss: 0.677204
global_step: 19006, epoch: 76, loss: 0.586018
global_step: 19007, epoch: 76, loss: 0.600001
global_step: 19008, epoch: 76, loss: 0.647581
global_step: 19009, epoch: 76, loss: 0.593843
global_step: 19010, epoch: 76, loss: 0.674719
global_step: 19011, epoch: 76, loss: 0.772194
global_step: 19012, epoch: 76, loss: 0.706886
global_step: 19013, epoch: 76, loss: 0.676861
global_step: 19014, epoch: 76, loss: 0.823411
global_step: 19015, epoch: 76, loss: 0.666370
global_step: 19016, epoch: 76, loss: 0.742878
global_step: 19017, epoch: 76, loss: 0.678324
global_step: 19018, epoch: 76, loss: 0.648536
global_step: 19019, epoch: 76, loss: 0.634204
global_step: 19020, epoch: 76, loss: 0.666052
global_step: 19021, epoch: 76, loss: 0.739130
global_step: 19022, epoch: 76, loss: 0.645242
global_step: 19023, epoch: 76, loss: 0.685176
global_step: 19024, epoch: 76, loss: 0.675286
global_step: 19025, epoch: 76, loss: 0.648201
global_step: 19026, epoch: 76, loss: 0.709855
global_step: 19027, epoch: 76, loss: 0.749153
global_step: 19028, epoch: 76, loss: 0.739811
global_step: 19029, epoch: 76, loss: 0.634937
global_step: 19030, epoch: 76, loss: 0.652194
global_step: 19031, epoch: 76, loss: 0.777838
global_step: 19032, epoch: 76, loss: 0.655741
global_step: 19033, epoch: 76, loss: 0.717473
global_step: 19034, epoch: 76, loss: 0.601605
global_step: 19035, epoch: 76, loss: 0.543957
global_step: 19036, epoch: 76, loss: 0.763958
global_step: 19037, epoch: 76, loss: 0.590821
global_step: 19038, epoch: 76, loss: 0.738956
global_step: 19039, epoch: 76, loss: 0.737235
global_step: 19040, epoch: 76, loss: 0.549686
epoch: 76
train	acc: 0.8427	macro: p 0.6993, r 0.6218, f1: 0.6342	micro: p 0.8427, r 0.8427, f1 0.8427	weighted_f1:0.8254
dev	acc: 0.5726	macro: p 0.4124, r 0.3589, f1: 0.3593	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5340
test	acc: 0.5973	macro: p 0.3919, r 0.3489, f1: 0.3422	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5666
global_step: 19041, epoch: 77, loss: 0.632152
global_step: 19042, epoch: 77, loss: 0.649801
global_step: 19043, epoch: 77, loss: 0.617741
global_step: 19044, epoch: 77, loss: 0.715992
global_step: 19045, epoch: 77, loss: 0.592543
global_step: 19046, epoch: 77, loss: 0.708192
global_step: 19047, epoch: 77, loss: 0.629538
global_step: 19048, epoch: 77, loss: 0.533147
global_step: 19049, epoch: 77, loss: 0.721927
global_step: 19050, epoch: 77, loss: 0.713946
global_step: 19051, epoch: 77, loss: 0.714459
global_step: 19052, epoch: 77, loss: 0.629178
global_step: 19053, epoch: 77, loss: 0.660651
global_step: 19054, epoch: 77, loss: 0.563489
global_step: 19055, epoch: 77, loss: 0.625073
global_step: 19056, epoch: 77, loss: 0.686173
global_step: 19057, epoch: 77, loss: 0.687606
global_step: 19058, epoch: 77, loss: 0.720855
global_step: 19059, epoch: 77, loss: 0.799373
global_step: 19060, epoch: 77, loss: 0.598044
global_step: 19061, epoch: 77, loss: 0.677646
global_step: 19062, epoch: 77, loss: 0.679296
global_step: 19063, epoch: 77, loss: 0.649651
global_step: 19064, epoch: 77, loss: 0.665598
global_step: 19065, epoch: 77, loss: 0.710860
global_step: 19066, epoch: 77, loss: 0.757844
global_step: 19067, epoch: 77, loss: 0.600800
global_step: 19068, epoch: 77, loss: 0.718963
global_step: 19069, epoch: 77, loss: 0.650671
global_step: 19070, epoch: 77, loss: 0.664327
global_step: 19071, epoch: 77, loss: 0.644695
global_step: 19072, epoch: 77, loss: 0.615240
global_step: 19073, epoch: 77, loss: 0.690884
global_step: 19074, epoch: 77, loss: 0.655324
global_step: 19075, epoch: 77, loss: 0.631277
global_step: 19076, epoch: 77, loss: 0.619137
global_step: 19077, epoch: 77, loss: 0.717304
global_step: 19078, epoch: 77, loss: 0.712287
global_step: 19079, epoch: 77, loss: 0.710683
global_step: 19080, epoch: 77, loss: 2.129797
epoch: 77
train	acc: 0.8486	macro: p 0.7037, r 0.6320, f1: 0.6421	micro: p 0.8486, r 0.8486, f1 0.8486	weighted_f1:0.8321
dev	acc: 0.5744	macro: p 0.4167, r 0.3605, f1: 0.3691	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5418
test	acc: 0.6065	macro: p 0.4288, r 0.3522, f1: 0.3558	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5776
global_step: 19081, epoch: 78, loss: 0.764623
global_step: 19082, epoch: 78, loss: 0.645057
global_step: 19083, epoch: 78, loss: 0.706018
global_step: 19084, epoch: 78, loss: 0.665090
global_step: 19085, epoch: 78, loss: 0.676729
global_step: 19086, epoch: 78, loss: 0.640237
global_step: 19087, epoch: 78, loss: 0.667612
global_step: 19088, epoch: 78, loss: 0.585258
global_step: 19089, epoch: 78, loss: 0.608038
global_step: 19090, epoch: 78, loss: 0.681608
global_step: 19091, epoch: 78, loss: 0.691379
global_step: 19092, epoch: 78, loss: 0.587990
global_step: 19093, epoch: 78, loss: 0.652450
global_step: 19094, epoch: 78, loss: 0.685386
global_step: 19095, epoch: 78, loss: 0.605538
global_step: 19096, epoch: 78, loss: 0.640248
global_step: 19097, epoch: 78, loss: 0.775093
global_step: 19098, epoch: 78, loss: 0.659749
global_step: 19099, epoch: 78, loss: 0.688088
global_step: 19100, epoch: 78, loss: 0.652495
global_step: 19101, epoch: 78, loss: 0.702864
global_step: 19102, epoch: 78, loss: 0.690256
global_step: 19103, epoch: 78, loss: 0.773910
global_step: 19104, epoch: 78, loss: 0.648330
global_step: 19105, epoch: 78, loss: 0.657869
global_step: 19106, epoch: 78, loss: 0.589298
global_step: 19107, epoch: 78, loss: 0.643049
global_step: 19108, epoch: 78, loss: 0.630234
global_step: 19109, epoch: 78, loss: 0.581191
global_step: 19110, epoch: 78, loss: 0.646545
global_step: 19111, epoch: 78, loss: 0.657471
global_step: 19112, epoch: 78, loss: 0.750365
global_step: 19113, epoch: 78, loss: 0.688453
global_step: 19114, epoch: 78, loss: 0.664560
global_step: 19115, epoch: 78, loss: 0.577863
global_step: 19116, epoch: 78, loss: 0.658356
global_step: 19117, epoch: 78, loss: 0.741439
global_step: 19118, epoch: 78, loss: 0.585340
global_step: 19119, epoch: 78, loss: 0.705146
global_step: 19120, epoch: 78, loss: 0.411836
epoch: 78
train	acc: 0.8362	macro: p 0.7092, r 0.6113, f1: 0.6324	micro: p 0.8362, r 0.8362, f1 0.8362	weighted_f1:0.8175
dev	acc: 0.5807	macro: p 0.4359, r 0.3538, f1: 0.3664	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5378
test	acc: 0.6146	macro: p 0.4427, r 0.3447, f1: 0.3528	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5758
global_step: 19121, epoch: 79, loss: 0.615475
global_step: 19122, epoch: 79, loss: 0.564575
global_step: 19123, epoch: 79, loss: 0.681785
global_step: 19124, epoch: 79, loss: 0.651371
global_step: 19125, epoch: 79, loss: 0.656116
global_step: 19126, epoch: 79, loss: 0.617128
global_step: 19127, epoch: 79, loss: 0.622504
global_step: 19128, epoch: 79, loss: 0.557168
global_step: 19129, epoch: 79, loss: 0.641931
global_step: 19130, epoch: 79, loss: 0.605915
global_step: 19131, epoch: 79, loss: 0.585488
global_step: 19132, epoch: 79, loss: 0.719850
global_step: 19133, epoch: 79, loss: 0.683032
global_step: 19134, epoch: 79, loss: 0.727223
global_step: 19135, epoch: 79, loss: 0.651231
global_step: 19136, epoch: 79, loss: 0.738002
global_step: 19137, epoch: 79, loss: 0.649926
global_step: 19138, epoch: 79, loss: 0.665703
global_step: 19139, epoch: 79, loss: 0.745466
global_step: 19140, epoch: 79, loss: 0.710042
global_step: 19141, epoch: 79, loss: 0.607543
global_step: 19142, epoch: 79, loss: 0.593827
global_step: 19143, epoch: 79, loss: 0.638919
global_step: 19144, epoch: 79, loss: 0.575907
global_step: 19145, epoch: 79, loss: 0.754974
global_step: 19146, epoch: 79, loss: 0.658320
global_step: 19147, epoch: 79, loss: 0.560437
global_step: 19148, epoch: 79, loss: 0.564438
global_step: 19149, epoch: 79, loss: 0.628328
global_step: 19150, epoch: 79, loss: 0.634347
global_step: 19151, epoch: 79, loss: 0.691381
global_step: 19152, epoch: 79, loss: 0.701218
global_step: 19153, epoch: 79, loss: 0.688778
global_step: 19154, epoch: 79, loss: 0.675331
global_step: 19155, epoch: 79, loss: 0.572191
global_step: 19156, epoch: 79, loss: 0.647856
global_step: 19157, epoch: 79, loss: 0.671249
global_step: 19158, epoch: 79, loss: 0.694152
global_step: 19159, epoch: 79, loss: 0.589764
global_step: 19160, epoch: 79, loss: 1.144133
epoch: 79
train	acc: 0.8601	macro: p 0.7086, r 0.6551, f1: 0.6654	micro: p 0.8601, r 0.8601, f1 0.8601	weighted_f1:0.8452
dev	acc: 0.5744	macro: p 0.4022, r 0.3650, f1: 0.3699	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5438
test	acc: 0.6050	macro: p 0.3921, r 0.3553, f1: 0.3552	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5777
global_step: 19161, epoch: 80, loss: 0.612417
global_step: 19162, epoch: 80, loss: 0.641585
global_step: 19163, epoch: 80, loss: 0.625915
global_step: 19164, epoch: 80, loss: 0.513267
global_step: 19165, epoch: 80, loss: 0.598258
global_step: 19166, epoch: 80, loss: 0.684611
global_step: 19167, epoch: 80, loss: 0.653711
global_step: 19168, epoch: 80, loss: 0.722130
global_step: 19169, epoch: 80, loss: 0.641006
global_step: 19170, epoch: 80, loss: 0.639511
global_step: 19171, epoch: 80, loss: 0.647173
global_step: 19172, epoch: 80, loss: 0.553069
global_step: 19173, epoch: 80, loss: 0.625272
global_step: 19174, epoch: 80, loss: 0.681806
global_step: 19175, epoch: 80, loss: 0.703388
global_step: 19176, epoch: 80, loss: 0.678760
global_step: 19177, epoch: 80, loss: 0.679385
global_step: 19178, epoch: 80, loss: 0.665964
global_step: 19179, epoch: 80, loss: 0.650915
global_step: 19180, epoch: 80, loss: 0.700262
global_step: 19181, epoch: 80, loss: 0.686898
global_step: 19182, epoch: 80, loss: 0.712852
global_step: 19183, epoch: 80, loss: 0.637258
global_step: 19184, epoch: 80, loss: 0.595968
global_step: 19185, epoch: 80, loss: 0.669107
global_step: 19186, epoch: 80, loss: 0.657811
global_step: 19187, epoch: 80, loss: 0.699803
global_step: 19188, epoch: 80, loss: 0.625376
global_step: 19189, epoch: 80, loss: 0.574975
global_step: 19190, epoch: 80, loss: 0.683505
global_step: 19191, epoch: 80, loss: 0.614806
global_step: 19192, epoch: 80, loss: 0.567203
global_step: 19193, epoch: 80, loss: 0.626985
global_step: 19194, epoch: 80, loss: 0.741932
global_step: 19195, epoch: 80, loss: 0.636205
global_step: 19196, epoch: 80, loss: 0.585482
global_step: 19197, epoch: 80, loss: 0.581355
global_step: 19198, epoch: 80, loss: 0.583515
global_step: 19199, epoch: 80, loss: 0.663169
global_step: 19200, epoch: 80, loss: 0.122012
epoch: 80
train	acc: 0.8569	macro: p 0.7131, r 0.6442, f1: 0.6559	micro: p 0.8569, r 0.8569, f1 0.8569	weighted_f1:0.8414
dev	acc: 0.5744	macro: p 0.4159, r 0.3598, f1: 0.3680	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5420
test	acc: 0.6084	macro: p 0.4043, r 0.3560, f1: 0.3582	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5803
global_step: 19201, epoch: 81, loss: 0.685051
global_step: 19202, epoch: 81, loss: 0.657508
global_step: 19203, epoch: 81, loss: 0.684573
global_step: 19204, epoch: 81, loss: 0.695845
global_step: 19205, epoch: 81, loss: 0.667481
global_step: 19206, epoch: 81, loss: 0.675651
global_step: 19207, epoch: 81, loss: 0.566402
global_step: 19208, epoch: 81, loss: 0.632955
global_step: 19209, epoch: 81, loss: 0.660000
global_step: 19210, epoch: 81, loss: 0.618683
global_step: 19211, epoch: 81, loss: 0.635023
global_step: 19212, epoch: 81, loss: 0.620939
global_step: 19213, epoch: 81, loss: 0.686899
global_step: 19214, epoch: 81, loss: 0.588843
global_step: 19215, epoch: 81, loss: 0.667102
global_step: 19216, epoch: 81, loss: 0.602594
global_step: 19217, epoch: 81, loss: 0.631021
global_step: 19218, epoch: 81, loss: 0.654481
global_step: 19219, epoch: 81, loss: 0.627777
global_step: 19220, epoch: 81, loss: 0.665804
global_step: 19221, epoch: 81, loss: 0.574583
global_step: 19222, epoch: 81, loss: 0.600100
global_step: 19223, epoch: 81, loss: 0.581987
global_step: 19224, epoch: 81, loss: 0.728420
global_step: 19225, epoch: 81, loss: 0.679668
global_step: 19226, epoch: 81, loss: 0.653010
global_step: 19227, epoch: 81, loss: 0.592543
global_step: 19228, epoch: 81, loss: 0.658243
global_step: 19229, epoch: 81, loss: 0.662983
global_step: 19230, epoch: 81, loss: 0.629589
global_step: 19231, epoch: 81, loss: 0.615655
global_step: 19232, epoch: 81, loss: 0.628396
global_step: 19233, epoch: 81, loss: 0.641240
global_step: 19234, epoch: 81, loss: 0.594027
global_step: 19235, epoch: 81, loss: 0.598816
global_step: 19236, epoch: 81, loss: 0.589344
global_step: 19237, epoch: 81, loss: 0.737538
global_step: 19238, epoch: 81, loss: 0.598873
global_step: 19239, epoch: 81, loss: 0.553169
global_step: 19240, epoch: 81, loss: 0.529375
epoch: 81
train	acc: 0.8508	macro: p 0.7143, r 0.6278, f1: 0.6446	micro: p 0.8508, r 0.8508, f1 0.8508	weighted_f1:0.8330
dev	acc: 0.5807	macro: p 0.4277, r 0.3630, f1: 0.3667	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5420
test	acc: 0.6054	macro: p 0.4223, r 0.3489, f1: 0.3485	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5723
global_step: 19241, epoch: 82, loss: 0.714141
global_step: 19242, epoch: 82, loss: 0.649351
global_step: 19243, epoch: 82, loss: 0.635089
global_step: 19244, epoch: 82, loss: 0.771632
global_step: 19245, epoch: 82, loss: 0.565505
global_step: 19246, epoch: 82, loss: 0.700905
global_step: 19247, epoch: 82, loss: 0.566175
global_step: 19248, epoch: 82, loss: 0.675444
global_step: 19249, epoch: 82, loss: 0.680698
global_step: 19250, epoch: 82, loss: 0.674397
global_step: 19251, epoch: 82, loss: 0.607091
global_step: 19252, epoch: 82, loss: 0.735769
global_step: 19253, epoch: 82, loss: 0.596096
global_step: 19254, epoch: 82, loss: 0.578405
global_step: 19255, epoch: 82, loss: 0.655581
global_step: 19256, epoch: 82, loss: 0.601180
global_step: 19257, epoch: 82, loss: 0.555705
global_step: 19258, epoch: 82, loss: 0.694156
global_step: 19259, epoch: 82, loss: 0.589133
global_step: 19260, epoch: 82, loss: 0.639766
global_step: 19261, epoch: 82, loss: 0.647813
global_step: 19262, epoch: 82, loss: 0.573665
global_step: 19263, epoch: 82, loss: 0.615587
global_step: 19264, epoch: 82, loss: 0.706825
global_step: 19265, epoch: 82, loss: 0.712500
global_step: 19266, epoch: 82, loss: 0.549208
global_step: 19267, epoch: 82, loss: 0.646203
global_step: 19268, epoch: 82, loss: 0.633809
global_step: 19269, epoch: 82, loss: 0.531335
global_step: 19270, epoch: 82, loss: 0.707157
global_step: 19271, epoch: 82, loss: 0.703455
global_step: 19272, epoch: 82, loss: 0.544110
global_step: 19273, epoch: 82, loss: 0.628007
global_step: 19274, epoch: 82, loss: 0.637913
global_step: 19275, epoch: 82, loss: 0.575079
global_step: 19276, epoch: 82, loss: 0.631935
global_step: 19277, epoch: 82, loss: 0.768249
global_step: 19278, epoch: 82, loss: 0.539947
global_step: 19279, epoch: 82, loss: 0.547388
global_step: 19280, epoch: 82, loss: 0.399098
epoch: 82
train	acc: 0.8490	macro: p 0.7176, r 0.6233, f1: 0.6419	micro: p 0.8490, r 0.8490, f1 0.8490	weighted_f1:0.8306
dev	acc: 0.5726	macro: p 0.4165, r 0.3494, f1: 0.3542	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5300
test	acc: 0.6061	macro: p 0.4197, r 0.3412, f1: 0.3437	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5693
global_step: 19281, epoch: 83, loss: 0.615692
global_step: 19282, epoch: 83, loss: 0.532502
global_step: 19283, epoch: 83, loss: 0.631730
global_step: 19284, epoch: 83, loss: 0.646071
global_step: 19285, epoch: 83, loss: 0.545963
global_step: 19286, epoch: 83, loss: 0.685955
global_step: 19287, epoch: 83, loss: 0.655112
global_step: 19288, epoch: 83, loss: 0.611811
global_step: 19289, epoch: 83, loss: 0.623003
global_step: 19290, epoch: 83, loss: 0.542357
global_step: 19291, epoch: 83, loss: 0.552656
global_step: 19292, epoch: 83, loss: 0.683523
global_step: 19293, epoch: 83, loss: 0.582433
global_step: 19294, epoch: 83, loss: 0.725943
global_step: 19295, epoch: 83, loss: 0.621078
global_step: 19296, epoch: 83, loss: 0.618144
global_step: 19297, epoch: 83, loss: 0.639213
global_step: 19298, epoch: 83, loss: 0.699242
global_step: 19299, epoch: 83, loss: 0.596288
global_step: 19300, epoch: 83, loss: 0.561604
global_step: 19301, epoch: 83, loss: 0.620762
global_step: 19302, epoch: 83, loss: 0.666301
global_step: 19303, epoch: 83, loss: 0.690218
global_step: 19304, epoch: 83, loss: 0.670804
global_step: 19305, epoch: 83, loss: 0.659137
global_step: 19306, epoch: 83, loss: 0.584417
global_step: 19307, epoch: 83, loss: 0.696785
global_step: 19308, epoch: 83, loss: 0.638704
global_step: 19309, epoch: 83, loss: 0.672397
global_step: 19310, epoch: 83, loss: 0.635368
global_step: 19311, epoch: 83, loss: 0.570936
global_step: 19312, epoch: 83, loss: 0.615943
global_step: 19313, epoch: 83, loss: 0.645772
global_step: 19314, epoch: 83, loss: 0.614399
global_step: 19315, epoch: 83, loss: 0.619362
global_step: 19316, epoch: 83, loss: 0.660704
global_step: 19317, epoch: 83, loss: 0.634508
global_step: 19318, epoch: 83, loss: 0.653894
global_step: 19319, epoch: 83, loss: 0.622885
global_step: 19320, epoch: 83, loss: 0.211526
epoch: 83
train	acc: 0.8144	macro: p 0.8644, r 0.5733, f1: 0.6149	micro: p 0.8144, r 0.8144, f1 0.8144	weighted_f1:0.7931
dev	acc: 0.5573	macro: p 0.4375, r 0.3162, f1: 0.3255	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4978
test	acc: 0.6123	macro: p 0.4423, r 0.3198, f1: 0.3321	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5593
global_step: 19321, epoch: 84, loss: 0.741528
global_step: 19322, epoch: 84, loss: 0.598624
global_step: 19323, epoch: 84, loss: 0.701221
global_step: 19324, epoch: 84, loss: 0.524822
global_step: 19325, epoch: 84, loss: 0.610319
global_step: 19326, epoch: 84, loss: 0.623335
global_step: 19327, epoch: 84, loss: 0.630899
global_step: 19328, epoch: 84, loss: 0.606041
global_step: 19329, epoch: 84, loss: 0.621516
global_step: 19330, epoch: 84, loss: 0.724665
global_step: 19331, epoch: 84, loss: 0.655046
global_step: 19332, epoch: 84, loss: 0.592806
global_step: 19333, epoch: 84, loss: 0.700171
global_step: 19334, epoch: 84, loss: 0.609823
global_step: 19335, epoch: 84, loss: 0.670784
global_step: 19336, epoch: 84, loss: 0.616851
global_step: 19337, epoch: 84, loss: 0.577724
global_step: 19338, epoch: 84, loss: 0.603823
global_step: 19339, epoch: 84, loss: 0.571877
global_step: 19340, epoch: 84, loss: 0.636254
global_step: 19341, epoch: 84, loss: 0.633756
global_step: 19342, epoch: 84, loss: 0.706647
global_step: 19343, epoch: 84, loss: 0.495643
global_step: 19344, epoch: 84, loss: 0.659317
global_step: 19345, epoch: 84, loss: 0.585299
global_step: 19346, epoch: 84, loss: 0.596171
global_step: 19347, epoch: 84, loss: 0.641878
global_step: 19348, epoch: 84, loss: 0.675516
global_step: 19349, epoch: 84, loss: 0.587235
global_step: 19350, epoch: 84, loss: 0.620951
global_step: 19351, epoch: 84, loss: 0.656690
global_step: 19352, epoch: 84, loss: 0.585756
global_step: 19353, epoch: 84, loss: 0.620243
global_step: 19354, epoch: 84, loss: 0.663477
global_step: 19355, epoch: 84, loss: 0.611481
global_step: 19356, epoch: 84, loss: 0.526851
global_step: 19357, epoch: 84, loss: 0.634635
global_step: 19358, epoch: 84, loss: 0.652859
global_step: 19359, epoch: 84, loss: 0.523951
global_step: 19360, epoch: 84, loss: 0.354682
epoch: 84
train	acc: 0.8499	macro: p 0.8641, r 0.6383, f1: 0.6593	micro: p 0.8499, r 0.8499, f1 0.8499	weighted_f1:0.8339
dev	acc: 0.5708	macro: p 0.4243, r 0.3431, f1: 0.3560	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5272
test	acc: 0.6149	macro: p 0.4357, r 0.3445, f1: 0.3583	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5780
global_step: 19361, epoch: 85, loss: 0.689986
global_step: 19362, epoch: 85, loss: 0.633401
global_step: 19363, epoch: 85, loss: 0.604192
global_step: 19364, epoch: 85, loss: 0.552598
global_step: 19365, epoch: 85, loss: 0.591259
global_step: 19366, epoch: 85, loss: 0.514444
global_step: 19367, epoch: 85, loss: 0.606584
global_step: 19368, epoch: 85, loss: 0.638086
global_step: 19369, epoch: 85, loss: 0.641472
global_step: 19370, epoch: 85, loss: 0.559954
global_step: 19371, epoch: 85, loss: 0.669692
global_step: 19372, epoch: 85, loss: 0.613457
global_step: 19373, epoch: 85, loss: 0.627705
global_step: 19374, epoch: 85, loss: 0.619151
global_step: 19375, epoch: 85, loss: 0.668206
global_step: 19376, epoch: 85, loss: 0.573427
global_step: 19377, epoch: 85, loss: 0.628107
global_step: 19378, epoch: 85, loss: 0.534843
global_step: 19379, epoch: 85, loss: 0.641364
global_step: 19380, epoch: 85, loss: 0.657716
global_step: 19381, epoch: 85, loss: 0.635277
global_step: 19382, epoch: 85, loss: 0.558681
global_step: 19383, epoch: 85, loss: 0.598878
global_step: 19384, epoch: 85, loss: 0.601939
global_step: 19385, epoch: 85, loss: 0.616703
global_step: 19386, epoch: 85, loss: 0.661900
global_step: 19387, epoch: 85, loss: 0.616320
global_step: 19388, epoch: 85, loss: 0.584983
global_step: 19389, epoch: 85, loss: 0.483301
global_step: 19390, epoch: 85, loss: 0.609988
global_step: 19391, epoch: 85, loss: 0.625241
global_step: 19392, epoch: 85, loss: 0.532749
global_step: 19393, epoch: 85, loss: 0.647376
global_step: 19394, epoch: 85, loss: 0.597026
global_step: 19395, epoch: 85, loss: 0.598078
global_step: 19396, epoch: 85, loss: 0.600976
global_step: 19397, epoch: 85, loss: 0.615289
global_step: 19398, epoch: 85, loss: 0.704010
global_step: 19399, epoch: 85, loss: 0.563526
global_step: 19400, epoch: 85, loss: 0.436078
epoch: 85
train	acc: 0.8682	macro: p 0.8594, r 0.6740, f1: 0.6853	micro: p 0.8682, r 0.8682, f1 0.8682	weighted_f1:0.8540
dev	acc: 0.5708	macro: p 0.3934, r 0.3626, f1: 0.3624	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5360
test	acc: 0.6019	macro: p 0.3875, r 0.3556, f1: 0.3511	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5733
global_step: 19401, epoch: 86, loss: 0.561463
global_step: 19402, epoch: 86, loss: 0.540904
global_step: 19403, epoch: 86, loss: 0.623958
global_step: 19404, epoch: 86, loss: 0.572567
global_step: 19405, epoch: 86, loss: 0.565972
global_step: 19406, epoch: 86, loss: 0.603958
global_step: 19407, epoch: 86, loss: 0.605144
global_step: 19408, epoch: 86, loss: 0.585177
global_step: 19409, epoch: 86, loss: 0.503571
global_step: 19410, epoch: 86, loss: 0.606018
global_step: 19411, epoch: 86, loss: 0.606303
global_step: 19412, epoch: 86, loss: 0.604575
global_step: 19413, epoch: 86, loss: 0.649671
global_step: 19414, epoch: 86, loss: 0.614055
global_step: 19415, epoch: 86, loss: 0.595454
global_step: 19416, epoch: 86, loss: 0.616260
global_step: 19417, epoch: 86, loss: 0.604911
global_step: 19418, epoch: 86, loss: 0.640641
global_step: 19419, epoch: 86, loss: 0.521132
global_step: 19420, epoch: 86, loss: 0.578672
global_step: 19421, epoch: 86, loss: 0.659695
global_step: 19422, epoch: 86, loss: 0.608775
global_step: 19423, epoch: 86, loss: 0.640816
global_step: 19424, epoch: 86, loss: 0.545489
global_step: 19425, epoch: 86, loss: 0.583335
global_step: 19426, epoch: 86, loss: 0.622630
global_step: 19427, epoch: 86, loss: 0.671663
global_step: 19428, epoch: 86, loss: 0.697733
global_step: 19429, epoch: 86, loss: 0.559060
global_step: 19430, epoch: 86, loss: 0.567665
global_step: 19431, epoch: 86, loss: 0.617330
global_step: 19432, epoch: 86, loss: 0.573836
global_step: 19433, epoch: 86, loss: 0.573603
global_step: 19434, epoch: 86, loss: 0.627086
global_step: 19435, epoch: 86, loss: 0.594137
global_step: 19436, epoch: 86, loss: 0.574487
global_step: 19437, epoch: 86, loss: 0.612002
global_step: 19438, epoch: 86, loss: 0.574915
global_step: 19439, epoch: 86, loss: 0.578484
global_step: 19440, epoch: 86, loss: 0.185135
epoch: 86
train	acc: 0.8611	macro: p 0.8462, r 0.6595, f1: 0.6797	micro: p 0.8611, r 0.8611, f1 0.8611	weighted_f1:0.8465
dev	acc: 0.5807	macro: p 0.4401, r 0.3555, f1: 0.3665	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5400
test	acc: 0.6103	macro: p 0.4224, r 0.3473, f1: 0.3573	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5750
global_step: 19441, epoch: 87, loss: 0.620646
global_step: 19442, epoch: 87, loss: 0.542550
global_step: 19443, epoch: 87, loss: 0.547933
global_step: 19444, epoch: 87, loss: 0.595481
global_step: 19445, epoch: 87, loss: 0.571127
global_step: 19446, epoch: 87, loss: 0.517656
global_step: 19447, epoch: 87, loss: 0.566868
global_step: 19448, epoch: 87, loss: 0.639326
global_step: 19449, epoch: 87, loss: 0.606760
global_step: 19450, epoch: 87, loss: 0.519704
global_step: 19451, epoch: 87, loss: 0.597770
global_step: 19452, epoch: 87, loss: 0.677721
global_step: 19453, epoch: 87, loss: 0.599597
global_step: 19454, epoch: 87, loss: 0.579902
global_step: 19455, epoch: 87, loss: 0.568237
global_step: 19456, epoch: 87, loss: 0.605653
global_step: 19457, epoch: 87, loss: 0.602082
global_step: 19458, epoch: 87, loss: 0.575250
global_step: 19459, epoch: 87, loss: 0.494118
global_step: 19460, epoch: 87, loss: 0.471479
global_step: 19461, epoch: 87, loss: 0.626755
global_step: 19462, epoch: 87, loss: 0.624671
global_step: 19463, epoch: 87, loss: 0.649532
global_step: 19464, epoch: 87, loss: 0.628325
global_step: 19465, epoch: 87, loss: 0.621231
global_step: 19466, epoch: 87, loss: 0.647071
global_step: 19467, epoch: 87, loss: 0.596043
global_step: 19468, epoch: 87, loss: 0.629053
global_step: 19469, epoch: 87, loss: 0.629919
global_step: 19470, epoch: 87, loss: 0.677860
global_step: 19471, epoch: 87, loss: 0.628789
global_step: 19472, epoch: 87, loss: 0.558620
global_step: 19473, epoch: 87, loss: 0.606155
global_step: 19474, epoch: 87, loss: 0.633121
global_step: 19475, epoch: 87, loss: 0.665656
global_step: 19476, epoch: 87, loss: 0.517925
global_step: 19477, epoch: 87, loss: 0.596813
global_step: 19478, epoch: 87, loss: 0.618567
global_step: 19479, epoch: 87, loss: 0.681627
global_step: 19480, epoch: 87, loss: 0.686090
epoch: 87
train	acc: 0.8708	macro: p 0.8702, r 0.6704, f1: 0.6865	micro: p 0.8708, r 0.8708, f1 0.8708	weighted_f1:0.8557
dev	acc: 0.5771	macro: p 0.4075, r 0.3571, f1: 0.3623	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5386
test	acc: 0.6004	macro: p 0.4115, r 0.3448, f1: 0.3498	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5681
global_step: 19481, epoch: 88, loss: 0.558070
global_step: 19482, epoch: 88, loss: 0.602433
global_step: 19483, epoch: 88, loss: 0.588578
global_step: 19484, epoch: 88, loss: 0.534629
global_step: 19485, epoch: 88, loss: 0.589869
global_step: 19486, epoch: 88, loss: 0.625143
global_step: 19487, epoch: 88, loss: 0.553123
global_step: 19488, epoch: 88, loss: 0.578685
global_step: 19489, epoch: 88, loss: 0.559641
global_step: 19490, epoch: 88, loss: 0.574879
global_step: 19491, epoch: 88, loss: 0.570631
global_step: 19492, epoch: 88, loss: 0.545852
global_step: 19493, epoch: 88, loss: 0.599341
global_step: 19494, epoch: 88, loss: 0.557186
global_step: 19495, epoch: 88, loss: 0.527544
global_step: 19496, epoch: 88, loss: 0.625264
global_step: 19497, epoch: 88, loss: 0.568376
global_step: 19498, epoch: 88, loss: 0.623784
global_step: 19499, epoch: 88, loss: 0.602054
global_step: 19500, epoch: 88, loss: 0.603831
global_step: 19501, epoch: 88, loss: 0.642769
global_step: 19502, epoch: 88, loss: 0.578626
global_step: 19503, epoch: 88, loss: 0.547251
global_step: 19504, epoch: 88, loss: 0.511111
global_step: 19505, epoch: 88, loss: 0.508988
global_step: 19506, epoch: 88, loss: 0.669981
global_step: 19507, epoch: 88, loss: 0.672337
global_step: 19508, epoch: 88, loss: 0.621681
global_step: 19509, epoch: 88, loss: 0.578327
global_step: 19510, epoch: 88, loss: 0.562566
global_step: 19511, epoch: 88, loss: 0.584964
global_step: 19512, epoch: 88, loss: 0.552293
global_step: 19513, epoch: 88, loss: 0.581609
global_step: 19514, epoch: 88, loss: 0.527245
global_step: 19515, epoch: 88, loss: 0.647974
global_step: 19516, epoch: 88, loss: 0.643765
global_step: 19517, epoch: 88, loss: 0.558019
global_step: 19518, epoch: 88, loss: 0.605335
global_step: 19519, epoch: 88, loss: 0.640996
global_step: 19520, epoch: 88, loss: 1.212098
epoch: 88
train	acc: 0.8753	macro: p 0.8657, r 0.6903, f1: 0.6962	micro: p 0.8753, r 0.8753, f1 0.8753	weighted_f1:0.8631
dev	acc: 0.5636	macro: p 0.3929, r 0.3694, f1: 0.3709	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5414
test	acc: 0.5939	macro: p 0.4016, r 0.3670, f1: 0.3617	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5769
global_step: 19521, epoch: 89, loss: 0.594190
global_step: 19522, epoch: 89, loss: 0.566110
global_step: 19523, epoch: 89, loss: 0.582534
global_step: 19524, epoch: 89, loss: 0.651102
global_step: 19525, epoch: 89, loss: 0.616263
global_step: 19526, epoch: 89, loss: 0.532073
global_step: 19527, epoch: 89, loss: 0.580685
global_step: 19528, epoch: 89, loss: 0.567130
global_step: 19529, epoch: 89, loss: 0.587495
global_step: 19530, epoch: 89, loss: 0.566408
global_step: 19531, epoch: 89, loss: 0.579608
global_step: 19532, epoch: 89, loss: 0.554921
global_step: 19533, epoch: 89, loss: 0.549390
global_step: 19534, epoch: 89, loss: 0.599541
global_step: 19535, epoch: 89, loss: 0.699881
global_step: 19536, epoch: 89, loss: 0.551762
global_step: 19537, epoch: 89, loss: 0.600578
global_step: 19538, epoch: 89, loss: 0.524899
global_step: 19539, epoch: 89, loss: 0.586522
global_step: 19540, epoch: 89, loss: 0.560921
global_step: 19541, epoch: 89, loss: 0.592432
global_step: 19542, epoch: 89, loss: 0.522025
global_step: 19543, epoch: 89, loss: 0.579894
global_step: 19544, epoch: 89, loss: 0.588919
global_step: 19545, epoch: 89, loss: 0.580330
global_step: 19546, epoch: 89, loss: 0.592539
global_step: 19547, epoch: 89, loss: 0.682215
global_step: 19548, epoch: 89, loss: 0.646031
global_step: 19549, epoch: 89, loss: 0.499751
global_step: 19550, epoch: 89, loss: 0.507829
global_step: 19551, epoch: 89, loss: 0.574873
global_step: 19552, epoch: 89, loss: 0.516434
global_step: 19553, epoch: 89, loss: 0.649496
global_step: 19554, epoch: 89, loss: 0.586964
global_step: 19555, epoch: 89, loss: 0.507879
global_step: 19556, epoch: 89, loss: 0.522395
global_step: 19557, epoch: 89, loss: 0.624637
global_step: 19558, epoch: 89, loss: 0.633597
global_step: 19559, epoch: 89, loss: 0.580244
global_step: 19560, epoch: 89, loss: 0.495259
epoch: 89
train	acc: 0.8612	macro: p 0.8441, r 0.6738, f1: 0.6966	micro: p 0.8612, r 0.8612, f1 0.8612	weighted_f1:0.8467
dev	acc: 0.5753	macro: p 0.4143, r 0.3495, f1: 0.3565	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5300
test	acc: 0.6092	macro: p 0.4195, r 0.3425, f1: 0.3517	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5697
global_step: 19561, epoch: 90, loss: 0.674161
global_step: 19562, epoch: 90, loss: 0.558912
global_step: 19563, epoch: 90, loss: 0.691687
global_step: 19564, epoch: 90, loss: 0.548051
global_step: 19565, epoch: 90, loss: 0.612925
global_step: 19566, epoch: 90, loss: 0.539194
global_step: 19567, epoch: 90, loss: 0.625200
global_step: 19568, epoch: 90, loss: 0.605604
global_step: 19569, epoch: 90, loss: 0.605804
global_step: 19570, epoch: 90, loss: 0.507556
global_step: 19571, epoch: 90, loss: 0.561767
global_step: 19572, epoch: 90, loss: 0.649481
global_step: 19573, epoch: 90, loss: 0.626123
global_step: 19574, epoch: 90, loss: 0.535309
global_step: 19575, epoch: 90, loss: 0.650330
global_step: 19576, epoch: 90, loss: 0.585338
global_step: 19577, epoch: 90, loss: 0.505008
global_step: 19578, epoch: 90, loss: 0.621092
global_step: 19579, epoch: 90, loss: 0.471856
global_step: 19580, epoch: 90, loss: 0.610379
global_step: 19581, epoch: 90, loss: 0.508500
global_step: 19582, epoch: 90, loss: 0.658680
global_step: 19583, epoch: 90, loss: 0.511656
global_step: 19584, epoch: 90, loss: 0.560871
global_step: 19585, epoch: 90, loss: 0.535495
global_step: 19586, epoch: 90, loss: 0.552067
global_step: 19587, epoch: 90, loss: 0.478094
global_step: 19588, epoch: 90, loss: 0.533116
global_step: 19589, epoch: 90, loss: 0.573058
global_step: 19590, epoch: 90, loss: 0.580699
global_step: 19591, epoch: 90, loss: 0.538386
global_step: 19592, epoch: 90, loss: 0.648951
global_step: 19593, epoch: 90, loss: 0.523434
global_step: 19594, epoch: 90, loss: 0.493612
global_step: 19595, epoch: 90, loss: 0.587312
global_step: 19596, epoch: 90, loss: 0.502387
global_step: 19597, epoch: 90, loss: 0.508643
global_step: 19598, epoch: 90, loss: 0.509376
global_step: 19599, epoch: 90, loss: 0.624095
global_step: 19600, epoch: 90, loss: 0.768085
epoch: 90
train	acc: 0.8756	macro: p 0.8432, r 0.6870, f1: 0.7017	micro: p 0.8756, r 0.8756, f1 0.8756	weighted_f1:0.8619
dev	acc: 0.5699	macro: p 0.4005, r 0.3568, f1: 0.3602	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5342
test	acc: 0.6069	macro: p 0.4031, r 0.3530, f1: 0.3542	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5757
global_step: 19601, epoch: 91, loss: 0.600165
global_step: 19602, epoch: 91, loss: 0.538301
global_step: 19603, epoch: 91, loss: 0.579177
global_step: 19604, epoch: 91, loss: 0.536330
global_step: 19605, epoch: 91, loss: 0.582349
global_step: 19606, epoch: 91, loss: 0.556215
global_step: 19607, epoch: 91, loss: 0.634396
global_step: 19608, epoch: 91, loss: 0.577550
global_step: 19609, epoch: 91, loss: 0.612409
global_step: 19610, epoch: 91, loss: 0.554963
global_step: 19611, epoch: 91, loss: 0.575093
global_step: 19612, epoch: 91, loss: 0.530259
global_step: 19613, epoch: 91, loss: 0.632742
global_step: 19614, epoch: 91, loss: 0.590359
global_step: 19615, epoch: 91, loss: 0.578924
global_step: 19616, epoch: 91, loss: 0.454396
global_step: 19617, epoch: 91, loss: 0.570347
global_step: 19618, epoch: 91, loss: 0.680198
global_step: 19619, epoch: 91, loss: 0.565897
global_step: 19620, epoch: 91, loss: 0.615984
global_step: 19621, epoch: 91, loss: 0.572037
global_step: 19622, epoch: 91, loss: 0.605414
global_step: 19623, epoch: 91, loss: 0.568949
global_step: 19624, epoch: 91, loss: 0.492245
global_step: 19625, epoch: 91, loss: 0.607791
global_step: 19626, epoch: 91, loss: 0.484275
global_step: 19627, epoch: 91, loss: 0.595229
global_step: 19628, epoch: 91, loss: 0.516272
global_step: 19629, epoch: 91, loss: 0.567292
global_step: 19630, epoch: 91, loss: 0.613365
global_step: 19631, epoch: 91, loss: 0.491786
global_step: 19632, epoch: 91, loss: 0.544893
global_step: 19633, epoch: 91, loss: 0.638690
global_step: 19634, epoch: 91, loss: 0.523623
global_step: 19635, epoch: 91, loss: 0.557754
global_step: 19636, epoch: 91, loss: 0.511811
global_step: 19637, epoch: 91, loss: 0.572395
global_step: 19638, epoch: 91, loss: 0.593233
global_step: 19639, epoch: 91, loss: 0.537043
global_step: 19640, epoch: 91, loss: 1.140760
epoch: 91
train	acc: 0.8788	macro: p 0.8704, r 0.7174, f1: 0.7431	micro: p 0.8788, r 0.8788, f1 0.8788	weighted_f1:0.8691
dev	acc: 0.5816	macro: p 0.5443, r 0.3646, f1: 0.3766	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5464
test	acc: 0.6084	macro: p 0.4040, r 0.3528, f1: 0.3615	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5774
global_step: 19641, epoch: 92, loss: 0.608497
global_step: 19642, epoch: 92, loss: 0.490049
global_step: 19643, epoch: 92, loss: 0.509399
global_step: 19644, epoch: 92, loss: 0.575999
global_step: 19645, epoch: 92, loss: 0.574661
global_step: 19646, epoch: 92, loss: 0.453855
global_step: 19647, epoch: 92, loss: 0.580016
global_step: 19648, epoch: 92, loss: 0.556687
global_step: 19649, epoch: 92, loss: 0.663890
global_step: 19650, epoch: 92, loss: 0.560508
global_step: 19651, epoch: 92, loss: 0.604061
global_step: 19652, epoch: 92, loss: 0.552571
global_step: 19653, epoch: 92, loss: 0.465632
global_step: 19654, epoch: 92, loss: 0.633134
global_step: 19655, epoch: 92, loss: 0.637125
global_step: 19656, epoch: 92, loss: 0.543638
global_step: 19657, epoch: 92, loss: 0.478211
global_step: 19658, epoch: 92, loss: 0.595289
global_step: 19659, epoch: 92, loss: 0.501368
global_step: 19660, epoch: 92, loss: 0.567959
global_step: 19661, epoch: 92, loss: 0.550277
global_step: 19662, epoch: 92, loss: 0.560253
global_step: 19663, epoch: 92, loss: 0.577174
global_step: 19664, epoch: 92, loss: 0.600981
global_step: 19665, epoch: 92, loss: 0.600954
global_step: 19666, epoch: 92, loss: 0.515815
global_step: 19667, epoch: 92, loss: 0.574227
global_step: 19668, epoch: 92, loss: 0.534805
global_step: 19669, epoch: 92, loss: 0.580886
global_step: 19670, epoch: 92, loss: 0.565534
global_step: 19671, epoch: 92, loss: 0.519470
global_step: 19672, epoch: 92, loss: 0.556954
global_step: 19673, epoch: 92, loss: 0.546745
global_step: 19674, epoch: 92, loss: 0.589504
global_step: 19675, epoch: 92, loss: 0.582571
global_step: 19676, epoch: 92, loss: 0.584499
global_step: 19677, epoch: 92, loss: 0.598903
global_step: 19678, epoch: 92, loss: 0.522578
global_step: 19679, epoch: 92, loss: 0.619772
global_step: 19680, epoch: 92, loss: 0.677214
epoch: 92
train	acc: 0.8896	macro: p 0.8709, r 0.7337, f1: 0.7482	micro: p 0.8896, r 0.8896, f1 0.8896	weighted_f1:0.8798
dev	acc: 0.5762	macro: p 0.5442, r 0.3743, f1: 0.3834	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5474
test	acc: 0.5981	macro: p 0.3836, r 0.3524, f1: 0.3548	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5717
global_step: 19681, epoch: 93, loss: 0.499253
global_step: 19682, epoch: 93, loss: 0.658723
global_step: 19683, epoch: 93, loss: 0.536584
global_step: 19684, epoch: 93, loss: 0.533664
global_step: 19685, epoch: 93, loss: 0.544618
global_step: 19686, epoch: 93, loss: 0.525341
global_step: 19687, epoch: 93, loss: 0.550432
global_step: 19688, epoch: 93, loss: 0.539419
global_step: 19689, epoch: 93, loss: 0.526765
global_step: 19690, epoch: 93, loss: 0.518870
global_step: 19691, epoch: 93, loss: 0.600948
global_step: 19692, epoch: 93, loss: 0.574643
global_step: 19693, epoch: 93, loss: 0.605859
global_step: 19694, epoch: 93, loss: 0.568392
global_step: 19695, epoch: 93, loss: 0.553547
global_step: 19696, epoch: 93, loss: 0.583441
global_step: 19697, epoch: 93, loss: 0.517653
global_step: 19698, epoch: 93, loss: 0.516464
global_step: 19699, epoch: 93, loss: 0.600482
global_step: 19700, epoch: 93, loss: 0.597830
global_step: 19701, epoch: 93, loss: 0.597111
global_step: 19702, epoch: 93, loss: 0.570669
global_step: 19703, epoch: 93, loss: 0.488291
global_step: 19704, epoch: 93, loss: 0.540781
global_step: 19705, epoch: 93, loss: 0.543658
global_step: 19706, epoch: 93, loss: 0.562524
global_step: 19707, epoch: 93, loss: 0.541871
global_step: 19708, epoch: 93, loss: 0.523685
global_step: 19709, epoch: 93, loss: 0.558038
global_step: 19710, epoch: 93, loss: 0.503173
global_step: 19711, epoch: 93, loss: 0.625558
global_step: 19712, epoch: 93, loss: 0.654165
global_step: 19713, epoch: 93, loss: 0.521428
global_step: 19714, epoch: 93, loss: 0.531521
global_step: 19715, epoch: 93, loss: 0.566418
global_step: 19716, epoch: 93, loss: 0.506164
global_step: 19717, epoch: 93, loss: 0.535470
global_step: 19718, epoch: 93, loss: 0.531991
global_step: 19719, epoch: 93, loss: 0.589822
global_step: 19720, epoch: 93, loss: 0.758286
epoch: 93
train	acc: 0.8673	macro: p 0.8735, r 0.6824, f1: 0.7166	micro: p 0.8673, r 0.8673, f1 0.8673	weighted_f1:0.8544
dev	acc: 0.5609	macro: p 0.4024, r 0.3313, f1: 0.3438	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5142
test	acc: 0.6034	macro: p 0.4287, r 0.3297, f1: 0.3464	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5611
global_step: 19721, epoch: 94, loss: 0.641450
global_step: 19722, epoch: 94, loss: 0.528424
global_step: 19723, epoch: 94, loss: 0.478511
global_step: 19724, epoch: 94, loss: 0.476115
global_step: 19725, epoch: 94, loss: 0.574528
global_step: 19726, epoch: 94, loss: 0.551253
global_step: 19727, epoch: 94, loss: 0.481263
global_step: 19728, epoch: 94, loss: 0.486856
global_step: 19729, epoch: 94, loss: 0.481606
global_step: 19730, epoch: 94, loss: 0.423716
global_step: 19731, epoch: 94, loss: 0.603252
global_step: 19732, epoch: 94, loss: 0.660399
global_step: 19733, epoch: 94, loss: 0.495150
global_step: 19734, epoch: 94, loss: 0.620470
global_step: 19735, epoch: 94, loss: 0.533975
global_step: 19736, epoch: 94, loss: 0.540349
global_step: 19737, epoch: 94, loss: 0.630167
global_step: 19738, epoch: 94, loss: 0.521681
global_step: 19739, epoch: 94, loss: 0.550433
global_step: 19740, epoch: 94, loss: 0.565470
global_step: 19741, epoch: 94, loss: 0.566206
global_step: 19742, epoch: 94, loss: 0.545100
global_step: 19743, epoch: 94, loss: 0.429479
global_step: 19744, epoch: 94, loss: 0.592784
global_step: 19745, epoch: 94, loss: 0.589140
global_step: 19746, epoch: 94, loss: 0.503566
global_step: 19747, epoch: 94, loss: 0.539637
global_step: 19748, epoch: 94, loss: 0.524411
global_step: 19749, epoch: 94, loss: 0.558933
global_step: 19750, epoch: 94, loss: 0.481806
global_step: 19751, epoch: 94, loss: 0.426239
global_step: 19752, epoch: 94, loss: 0.577679
global_step: 19753, epoch: 94, loss: 0.507396
global_step: 19754, epoch: 94, loss: 0.604692
global_step: 19755, epoch: 94, loss: 0.502338
global_step: 19756, epoch: 94, loss: 0.450242
global_step: 19757, epoch: 94, loss: 0.561324
global_step: 19758, epoch: 94, loss: 0.720174
global_step: 19759, epoch: 94, loss: 0.534663
global_step: 19760, epoch: 94, loss: 0.151306
epoch: 94
train	acc: 0.8872	macro: p 0.8793, r 0.7102, f1: 0.7309	micro: p 0.8872, r 0.8872, f1 0.8872	weighted_f1:0.8753
dev	acc: 0.5744	macro: p 0.4028, r 0.3550, f1: 0.3637	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5375
test	acc: 0.6061	macro: p 0.4088, r 0.3477, f1: 0.3550	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5741
global_step: 19761, epoch: 95, loss: 0.540994
global_step: 19762, epoch: 95, loss: 0.543171
global_step: 19763, epoch: 95, loss: 0.479588
global_step: 19764, epoch: 95, loss: 0.624703
global_step: 19765, epoch: 95, loss: 0.555087
global_step: 19766, epoch: 95, loss: 0.542476
global_step: 19767, epoch: 95, loss: 0.544003
global_step: 19768, epoch: 95, loss: 0.597197
global_step: 19769, epoch: 95, loss: 0.542773
global_step: 19770, epoch: 95, loss: 0.439632
global_step: 19771, epoch: 95, loss: 0.454547
global_step: 19772, epoch: 95, loss: 0.426819
global_step: 19773, epoch: 95, loss: 0.432318
global_step: 19774, epoch: 95, loss: 0.544394
global_step: 19775, epoch: 95, loss: 0.614773
global_step: 19776, epoch: 95, loss: 0.635516
global_step: 19777, epoch: 95, loss: 0.591148
global_step: 19778, epoch: 95, loss: 0.553979
global_step: 19779, epoch: 95, loss: 0.528665
global_step: 19780, epoch: 95, loss: 0.540416
global_step: 19781, epoch: 95, loss: 0.534909
global_step: 19782, epoch: 95, loss: 0.528300
global_step: 19783, epoch: 95, loss: 0.554931
global_step: 19784, epoch: 95, loss: 0.546097
global_step: 19785, epoch: 95, loss: 0.527459
global_step: 19786, epoch: 95, loss: 0.514637
global_step: 19787, epoch: 95, loss: 0.586865
global_step: 19788, epoch: 95, loss: 0.582160
global_step: 19789, epoch: 95, loss: 0.481655
global_step: 19790, epoch: 95, loss: 0.534302
global_step: 19791, epoch: 95, loss: 0.507274
global_step: 19792, epoch: 95, loss: 0.518727
global_step: 19793, epoch: 95, loss: 0.484801
global_step: 19794, epoch: 95, loss: 0.623134
global_step: 19795, epoch: 95, loss: 0.477333
global_step: 19796, epoch: 95, loss: 0.613528
global_step: 19797, epoch: 95, loss: 0.549475
global_step: 19798, epoch: 95, loss: 0.660414
global_step: 19799, epoch: 95, loss: 0.558060
global_step: 19800, epoch: 95, loss: 0.512155
epoch: 95
train	acc: 0.8864	macro: p 0.8716, r 0.7170, f1: 0.7250	micro: p 0.8864, r 0.8864, f1 0.8864	weighted_f1:0.8750
dev	acc: 0.5564	macro: p 0.5387, r 0.3778, f1: 0.3796	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5362
test	acc: 0.5766	macro: p 0.3880, r 0.3591, f1: 0.3497	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5603
global_step: 19801, epoch: 96, loss: 0.619950
global_step: 19802, epoch: 96, loss: 0.516966
global_step: 19803, epoch: 96, loss: 0.478954
global_step: 19804, epoch: 96, loss: 0.553386
global_step: 19805, epoch: 96, loss: 0.520164
global_step: 19806, epoch: 96, loss: 0.427043
global_step: 19807, epoch: 96, loss: 0.522416
global_step: 19808, epoch: 96, loss: 0.538996
global_step: 19809, epoch: 96, loss: 0.552389
global_step: 19810, epoch: 96, loss: 0.631533
global_step: 19811, epoch: 96, loss: 0.563405
global_step: 19812, epoch: 96, loss: 0.456771
global_step: 19813, epoch: 96, loss: 0.566767
global_step: 19814, epoch: 96, loss: 0.528314
global_step: 19815, epoch: 96, loss: 0.569409
global_step: 19816, epoch: 96, loss: 0.465154
global_step: 19817, epoch: 96, loss: 0.603196
global_step: 19818, epoch: 96, loss: 0.475178
global_step: 19819, epoch: 96, loss: 0.484212
global_step: 19820, epoch: 96, loss: 0.428579
global_step: 19821, epoch: 96, loss: 0.581980
global_step: 19822, epoch: 96, loss: 0.512831
global_step: 19823, epoch: 96, loss: 0.554082
global_step: 19824, epoch: 96, loss: 0.578233
global_step: 19825, epoch: 96, loss: 0.456259
global_step: 19826, epoch: 96, loss: 0.562134
global_step: 19827, epoch: 96, loss: 0.512073
global_step: 19828, epoch: 96, loss: 0.695732
global_step: 19829, epoch: 96, loss: 0.520774
global_step: 19830, epoch: 96, loss: 0.655334
global_step: 19831, epoch: 96, loss: 0.599255
global_step: 19832, epoch: 96, loss: 0.555597
global_step: 19833, epoch: 96, loss: 0.516338
global_step: 19834, epoch: 96, loss: 0.459498
global_step: 19835, epoch: 96, loss: 0.545276
global_step: 19836, epoch: 96, loss: 0.514872
global_step: 19837, epoch: 96, loss: 0.526024
global_step: 19838, epoch: 96, loss: 0.604254
global_step: 19839, epoch: 96, loss: 0.516674
global_step: 19840, epoch: 96, loss: 0.203432
epoch: 96
train	acc: 0.8942	macro: p 0.8893, r 0.7296, f1: 0.7488	micro: p 0.8942, r 0.8942, f1 0.8942	weighted_f1:0.8839
dev	acc: 0.5780	macro: p 0.5455, r 0.3718, f1: 0.3797	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5478
test	acc: 0.5973	macro: p 0.3934, r 0.3528, f1: 0.3524	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5705
global_step: 19841, epoch: 97, loss: 0.553143
global_step: 19842, epoch: 97, loss: 0.584040
global_step: 19843, epoch: 97, loss: 0.461576
global_step: 19844, epoch: 97, loss: 0.567677
global_step: 19845, epoch: 97, loss: 0.514257
global_step: 19846, epoch: 97, loss: 0.579928
global_step: 19847, epoch: 97, loss: 0.504116
global_step: 19848, epoch: 97, loss: 0.467158
global_step: 19849, epoch: 97, loss: 0.523978
global_step: 19850, epoch: 97, loss: 0.587792
global_step: 19851, epoch: 97, loss: 0.495264
global_step: 19852, epoch: 97, loss: 0.429495
global_step: 19853, epoch: 97, loss: 0.619172
global_step: 19854, epoch: 97, loss: 0.482097
global_step: 19855, epoch: 97, loss: 0.501162
global_step: 19856, epoch: 97, loss: 0.554884
global_step: 19857, epoch: 97, loss: 0.469041
global_step: 19858, epoch: 97, loss: 0.494240
global_step: 19859, epoch: 97, loss: 0.569629
global_step: 19860, epoch: 97, loss: 0.427823
global_step: 19861, epoch: 97, loss: 0.588408
global_step: 19862, epoch: 97, loss: 0.515148
global_step: 19863, epoch: 97, loss: 0.518920
global_step: 19864, epoch: 97, loss: 0.476751
global_step: 19865, epoch: 97, loss: 0.616782
global_step: 19866, epoch: 97, loss: 0.580671
global_step: 19867, epoch: 97, loss: 0.496560
global_step: 19868, epoch: 97, loss: 0.513695
global_step: 19869, epoch: 97, loss: 0.555330
global_step: 19870, epoch: 97, loss: 0.514644
global_step: 19871, epoch: 97, loss: 0.422188
global_step: 19872, epoch: 97, loss: 0.572909
global_step: 19873, epoch: 97, loss: 0.438630
global_step: 19874, epoch: 97, loss: 0.607397
global_step: 19875, epoch: 97, loss: 0.407555
global_step: 19876, epoch: 97, loss: 0.536832
global_step: 19877, epoch: 97, loss: 0.496281
global_step: 19878, epoch: 97, loss: 0.666496
global_step: 19879, epoch: 97, loss: 0.495541
global_step: 19880, epoch: 97, loss: 0.269417
epoch: 97
train	acc: 0.8817	macro: p 0.8749, r 0.7013, f1: 0.7265	micro: p 0.8817, r 0.8817, f1 0.8817	weighted_f1:0.8694
dev	acc: 0.5789	macro: p 0.4140, r 0.3517, f1: 0.3621	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5362
test	acc: 0.6130	macro: p 0.4205, r 0.3452, f1: 0.3554	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5762
global_step: 19881, epoch: 98, loss: 0.627681
global_step: 19882, epoch: 98, loss: 0.501724
global_step: 19883, epoch: 98, loss: 0.486289
global_step: 19884, epoch: 98, loss: 0.472001
global_step: 19885, epoch: 98, loss: 0.478924
global_step: 19886, epoch: 98, loss: 0.554932
global_step: 19887, epoch: 98, loss: 0.527466
global_step: 19888, epoch: 98, loss: 0.531819
global_step: 19889, epoch: 98, loss: 0.500382
global_step: 19890, epoch: 98, loss: 0.483237
global_step: 19891, epoch: 98, loss: 0.506195
global_step: 19892, epoch: 98, loss: 0.600271
global_step: 19893, epoch: 98, loss: 0.459345
global_step: 19894, epoch: 98, loss: 0.465968
global_step: 19895, epoch: 98, loss: 0.525994
global_step: 19896, epoch: 98, loss: 0.548100
global_step: 19897, epoch: 98, loss: 0.601764
global_step: 19898, epoch: 98, loss: 0.404088
global_step: 19899, epoch: 98, loss: 0.494933
global_step: 19900, epoch: 98, loss: 0.501825
global_step: 19901, epoch: 98, loss: 0.460530
global_step: 19902, epoch: 98, loss: 0.534586
global_step: 19903, epoch: 98, loss: 0.569677
global_step: 19904, epoch: 98, loss: 0.551919
global_step: 19905, epoch: 98, loss: 0.615606
global_step: 19906, epoch: 98, loss: 0.553523
global_step: 19907, epoch: 98, loss: 0.463687
global_step: 19908, epoch: 98, loss: 0.454705
global_step: 19909, epoch: 98, loss: 0.558453
global_step: 19910, epoch: 98, loss: 0.437395
global_step: 19911, epoch: 98, loss: 0.471196
global_step: 19912, epoch: 98, loss: 0.540759
global_step: 19913, epoch: 98, loss: 0.579915
global_step: 19914, epoch: 98, loss: 0.531753
global_step: 19915, epoch: 98, loss: 0.400496
global_step: 19916, epoch: 98, loss: 0.593842
global_step: 19917, epoch: 98, loss: 0.511198
global_step: 19918, epoch: 98, loss: 0.495145
global_step: 19919, epoch: 98, loss: 0.603056
global_step: 19920, epoch: 98, loss: 0.244753
epoch: 98
train	acc: 0.8882	macro: p 0.8931, r 0.7093, f1: 0.7276	micro: p 0.8882, r 0.8882, f1 0.8882	weighted_f1:0.8764
dev	acc: 0.5672	macro: p 0.3962, r 0.3576, f1: 0.3612	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5362
test	acc: 0.5939	macro: p 0.4011, r 0.3476, f1: 0.3472	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5682
global_step: 19921, epoch: 99, loss: 0.649820
global_step: 19922, epoch: 99, loss: 0.447568
global_step: 19923, epoch: 99, loss: 0.501835
global_step: 19924, epoch: 99, loss: 0.476783
global_step: 19925, epoch: 99, loss: 0.486147
global_step: 19926, epoch: 99, loss: 0.462801
global_step: 19927, epoch: 99, loss: 0.475637
global_step: 19928, epoch: 99, loss: 0.498553
global_step: 19929, epoch: 99, loss: 0.484254
global_step: 19930, epoch: 99, loss: 0.494619
global_step: 19931, epoch: 99, loss: 0.533269
global_step: 19932, epoch: 99, loss: 0.522019
global_step: 19933, epoch: 99, loss: 0.499008
global_step: 19934, epoch: 99, loss: 0.457347
global_step: 19935, epoch: 99, loss: 0.433102
global_step: 19936, epoch: 99, loss: 0.511462
global_step: 19937, epoch: 99, loss: 0.422706
global_step: 19938, epoch: 99, loss: 0.504416
global_step: 19939, epoch: 99, loss: 0.477780
global_step: 19940, epoch: 99, loss: 0.459391
global_step: 19941, epoch: 99, loss: 0.589746
global_step: 19942, epoch: 99, loss: 0.471140
global_step: 19943, epoch: 99, loss: 0.536388
global_step: 19944, epoch: 99, loss: 0.484987
global_step: 19945, epoch: 99, loss: 0.678644
global_step: 19946, epoch: 99, loss: 0.536268
global_step: 19947, epoch: 99, loss: 0.549984
global_step: 19948, epoch: 99, loss: 0.563387
global_step: 19949, epoch: 99, loss: 0.458188
global_step: 19950, epoch: 99, loss: 0.580697
global_step: 19951, epoch: 99, loss: 0.575175
global_step: 19952, epoch: 99, loss: 0.572721
global_step: 19953, epoch: 99, loss: 0.514543
global_step: 19954, epoch: 99, loss: 0.443385
global_step: 19955, epoch: 99, loss: 0.491655
global_step: 19956, epoch: 99, loss: 0.500692
global_step: 19957, epoch: 99, loss: 0.519244
global_step: 19958, epoch: 99, loss: 0.595418
global_step: 19959, epoch: 99, loss: 0.550632
global_step: 19960, epoch: 99, loss: 0.122172
epoch: 99
train	acc: 0.8919	macro: p 0.8870, r 0.7255, f1: 0.7472	micro: p 0.8919, r 0.8919, f1 0.8919	weighted_f1:0.8807
dev	acc: 0.5654	macro: p 0.3912, r 0.3475, f1: 0.3495	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5248
test	acc: 0.5958	macro: p 0.3974, r 0.3386, f1: 0.3406	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5614
global_step: 19961, epoch: 100, loss: 0.510392
global_step: 19962, epoch: 100, loss: 0.449934
global_step: 19963, epoch: 100, loss: 0.484655
global_step: 19964, epoch: 100, loss: 0.501250
global_step: 19965, epoch: 100, loss: 0.572288
global_step: 19966, epoch: 100, loss: 0.438595
global_step: 19967, epoch: 100, loss: 0.576126
global_step: 19968, epoch: 100, loss: 0.550022
global_step: 19969, epoch: 100, loss: 0.511981
global_step: 19970, epoch: 100, loss: 0.551109
global_step: 19971, epoch: 100, loss: 0.470731
global_step: 19972, epoch: 100, loss: 0.498191
global_step: 19973, epoch: 100, loss: 0.531435
global_step: 19974, epoch: 100, loss: 0.514683
global_step: 19975, epoch: 100, loss: 0.454994
global_step: 19976, epoch: 100, loss: 0.586635
global_step: 19977, epoch: 100, loss: 0.494167
global_step: 19978, epoch: 100, loss: 0.459040
global_step: 19979, epoch: 100, loss: 0.519356
global_step: 19980, epoch: 100, loss: 0.447626
global_step: 19981, epoch: 100, loss: 0.430566
global_step: 19982, epoch: 100, loss: 0.442950
global_step: 19983, epoch: 100, loss: 0.455539
global_step: 19984, epoch: 100, loss: 0.603497
global_step: 19985, epoch: 100, loss: 0.529154
global_step: 19986, epoch: 100, loss: 0.447942
global_step: 19987, epoch: 100, loss: 0.530299
global_step: 19988, epoch: 100, loss: 0.441859
global_step: 19989, epoch: 100, loss: 0.489790
global_step: 19990, epoch: 100, loss: 0.518809
global_step: 19991, epoch: 100, loss: 0.475980
global_step: 19992, epoch: 100, loss: 0.525110
global_step: 19993, epoch: 100, loss: 0.566133
global_step: 19994, epoch: 100, loss: 0.480943
global_step: 19995, epoch: 100, loss: 0.571674
global_step: 19996, epoch: 100, loss: 0.545039
global_step: 19997, epoch: 100, loss: 0.524590
global_step: 19998, epoch: 100, loss: 0.497757
global_step: 19999, epoch: 100, loss: 0.492802
global_step: 20000, epoch: 100, loss: 0.313425
epoch: 100
train	acc: 0.9042	macro: p 0.8885, r 0.7526, f1: 0.7666	micro: p 0.9042, r 0.9042, f1 0.9042	weighted_f1:0.8948
dev	acc: 0.5744	macro: p 0.5487, r 0.3810, f1: 0.3899	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5498
test	acc: 0.5908	macro: p 0.3909, r 0.3506, f1: 0.3513	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5676
New best model!
global_step: 20001, epoch: 101, loss: 0.519091
global_step: 20002, epoch: 101, loss: 0.510852
global_step: 20003, epoch: 101, loss: 0.502662
global_step: 20004, epoch: 101, loss: 0.499537
global_step: 20005, epoch: 101, loss: 0.450074
global_step: 20006, epoch: 101, loss: 0.450070
global_step: 20007, epoch: 101, loss: 0.477072
global_step: 20008, epoch: 101, loss: 0.531342
global_step: 20009, epoch: 101, loss: 0.427557
global_step: 20010, epoch: 101, loss: 0.550442
global_step: 20011, epoch: 101, loss: 0.465890
global_step: 20012, epoch: 101, loss: 0.429458
global_step: 20013, epoch: 101, loss: 0.501408
global_step: 20014, epoch: 101, loss: 0.525041
global_step: 20015, epoch: 101, loss: 0.531062
global_step: 20016, epoch: 101, loss: 0.486246
global_step: 20017, epoch: 101, loss: 0.544749
global_step: 20018, epoch: 101, loss: 0.477007
global_step: 20019, epoch: 101, loss: 0.520118
global_step: 20020, epoch: 101, loss: 0.631286
global_step: 20021, epoch: 101, loss: 0.540533
global_step: 20022, epoch: 101, loss: 0.496059
global_step: 20023, epoch: 101, loss: 0.533265
global_step: 20024, epoch: 101, loss: 0.544709
global_step: 20025, epoch: 101, loss: 0.420599
global_step: 20026, epoch: 101, loss: 0.538961
global_step: 20027, epoch: 101, loss: 0.449369
global_step: 20028, epoch: 101, loss: 0.541181
global_step: 20029, epoch: 101, loss: 0.521434
global_step: 20030, epoch: 101, loss: 0.451424
global_step: 20031, epoch: 101, loss: 0.482854
global_step: 20032, epoch: 101, loss: 0.523965
global_step: 20033, epoch: 101, loss: 0.503596
global_step: 20034, epoch: 101, loss: 0.529288
global_step: 20035, epoch: 101, loss: 0.517507
global_step: 20036, epoch: 101, loss: 0.466738
global_step: 20037, epoch: 101, loss: 0.533185
global_step: 20038, epoch: 101, loss: 0.574472
global_step: 20039, epoch: 101, loss: 0.481732
global_step: 20040, epoch: 101, loss: 1.741058
epoch: 101
train	acc: 0.8988	macro: p 0.8774, r 0.7505, f1: 0.7588	micro: p 0.8988, r 0.8988, f1 0.8988	weighted_f1:0.8891
dev	acc: 0.5491	macro: p 0.5309, r 0.3672, f1: 0.3683	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5266
test	acc: 0.5751	macro: p 0.3857, r 0.3570, f1: 0.3523	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5589
global_step: 20041, epoch: 102, loss: 0.580016
global_step: 20042, epoch: 102, loss: 0.496675
global_step: 20043, epoch: 102, loss: 0.509616
global_step: 20044, epoch: 102, loss: 0.452841
global_step: 20045, epoch: 102, loss: 0.440010
global_step: 20046, epoch: 102, loss: 0.521449
global_step: 20047, epoch: 102, loss: 0.528168
global_step: 20048, epoch: 102, loss: 0.567793
global_step: 20049, epoch: 102, loss: 0.519565
global_step: 20050, epoch: 102, loss: 0.516564
global_step: 20051, epoch: 102, loss: 0.477272
global_step: 20052, epoch: 102, loss: 0.560642
global_step: 20053, epoch: 102, loss: 0.457813
global_step: 20054, epoch: 102, loss: 0.517373
global_step: 20055, epoch: 102, loss: 0.589162
global_step: 20056, epoch: 102, loss: 0.477285
global_step: 20057, epoch: 102, loss: 0.448544
global_step: 20058, epoch: 102, loss: 0.485677
global_step: 20059, epoch: 102, loss: 0.557914
global_step: 20060, epoch: 102, loss: 0.526091
global_step: 20061, epoch: 102, loss: 0.529197
global_step: 20062, epoch: 102, loss: 0.518873
global_step: 20063, epoch: 102, loss: 0.491198
global_step: 20064, epoch: 102, loss: 0.507346
global_step: 20065, epoch: 102, loss: 0.486535
global_step: 20066, epoch: 102, loss: 0.405704
global_step: 20067, epoch: 102, loss: 0.447897
global_step: 20068, epoch: 102, loss: 0.396990
global_step: 20069, epoch: 102, loss: 0.451619
global_step: 20070, epoch: 102, loss: 0.485931
global_step: 20071, epoch: 102, loss: 0.501519
global_step: 20072, epoch: 102, loss: 0.478010
global_step: 20073, epoch: 102, loss: 0.521474
global_step: 20074, epoch: 102, loss: 0.408340
global_step: 20075, epoch: 102, loss: 0.484910
global_step: 20076, epoch: 102, loss: 0.527377
global_step: 20077, epoch: 102, loss: 0.462087
global_step: 20078, epoch: 102, loss: 0.627957
global_step: 20079, epoch: 102, loss: 0.576435
global_step: 20080, epoch: 102, loss: 0.257529
epoch: 102
train	acc: 0.8974	macro: p 0.8932, r 0.7362, f1: 0.7597	micro: p 0.8974, r 0.8974, f1 0.8974	weighted_f1:0.8872
dev	acc: 0.5690	macro: p 0.5399, r 0.3518, f1: 0.3608	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5298
test	acc: 0.6038	macro: p 0.4034, r 0.3427, f1: 0.3486	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5691
global_step: 20081, epoch: 103, loss: 0.519154
global_step: 20082, epoch: 103, loss: 0.568462
global_step: 20083, epoch: 103, loss: 0.441279
global_step: 20084, epoch: 103, loss: 0.475855
global_step: 20085, epoch: 103, loss: 0.469325
global_step: 20086, epoch: 103, loss: 0.504520
global_step: 20087, epoch: 103, loss: 0.528944
global_step: 20088, epoch: 103, loss: 0.440351
global_step: 20089, epoch: 103, loss: 0.467077
global_step: 20090, epoch: 103, loss: 0.544846
global_step: 20091, epoch: 103, loss: 0.428469
global_step: 20092, epoch: 103, loss: 0.482645
global_step: 20093, epoch: 103, loss: 0.460832
global_step: 20094, epoch: 103, loss: 0.468003
global_step: 20095, epoch: 103, loss: 0.489142
global_step: 20096, epoch: 103, loss: 0.497744
global_step: 20097, epoch: 103, loss: 0.505605
global_step: 20098, epoch: 103, loss: 0.470270
global_step: 20099, epoch: 103, loss: 0.434059
global_step: 20100, epoch: 103, loss: 0.510938
global_step: 20101, epoch: 103, loss: 0.485407
global_step: 20102, epoch: 103, loss: 0.543014
global_step: 20103, epoch: 103, loss: 0.486743
global_step: 20104, epoch: 103, loss: 0.557797
global_step: 20105, epoch: 103, loss: 0.431163
global_step: 20106, epoch: 103, loss: 0.531288
global_step: 20107, epoch: 103, loss: 0.537638
global_step: 20108, epoch: 103, loss: 0.483227
global_step: 20109, epoch: 103, loss: 0.435725
global_step: 20110, epoch: 103, loss: 0.506330
global_step: 20111, epoch: 103, loss: 0.590720
global_step: 20112, epoch: 103, loss: 0.519571
global_step: 20113, epoch: 103, loss: 0.432934
global_step: 20114, epoch: 103, loss: 0.528930
global_step: 20115, epoch: 103, loss: 0.532527
global_step: 20116, epoch: 103, loss: 0.500758
global_step: 20117, epoch: 103, loss: 0.521399
global_step: 20118, epoch: 103, loss: 0.478621
global_step: 20119, epoch: 103, loss: 0.600693
global_step: 20120, epoch: 103, loss: 0.244739
epoch: 103
train	acc: 0.8672	macro: p 0.9031, r 0.6946, f1: 0.7448	micro: p 0.8672, r 0.8672, f1 0.8672	weighted_f1:0.8570
dev	acc: 0.5582	macro: p 0.5710, r 0.3186, f1: 0.3366	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5024
test	acc: 0.6084	macro: p 0.4267, r 0.3197, f1: 0.3387	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5589
global_step: 20121, epoch: 104, loss: 0.456283
global_step: 20122, epoch: 104, loss: 0.506791
global_step: 20123, epoch: 104, loss: 0.499014
global_step: 20124, epoch: 104, loss: 0.465137
global_step: 20125, epoch: 104, loss: 0.454415
global_step: 20126, epoch: 104, loss: 0.429010
global_step: 20127, epoch: 104, loss: 0.542408
global_step: 20128, epoch: 104, loss: 0.522896
global_step: 20129, epoch: 104, loss: 0.471106
global_step: 20130, epoch: 104, loss: 0.579122
global_step: 20131, epoch: 104, loss: 0.431072
global_step: 20132, epoch: 104, loss: 0.464721
global_step: 20133, epoch: 104, loss: 0.542583
global_step: 20134, epoch: 104, loss: 0.487101
global_step: 20135, epoch: 104, loss: 0.459361
global_step: 20136, epoch: 104, loss: 0.445812
global_step: 20137, epoch: 104, loss: 0.517866
global_step: 20138, epoch: 104, loss: 0.526923
global_step: 20139, epoch: 104, loss: 0.416809
global_step: 20140, epoch: 104, loss: 0.477513
global_step: 20141, epoch: 104, loss: 0.558324
global_step: 20142, epoch: 104, loss: 0.441554
global_step: 20143, epoch: 104, loss: 0.518291
global_step: 20144, epoch: 104, loss: 0.472567
global_step: 20145, epoch: 104, loss: 0.493381
global_step: 20146, epoch: 104, loss: 0.569853
global_step: 20147, epoch: 104, loss: 0.468689
global_step: 20148, epoch: 104, loss: 0.571807
global_step: 20149, epoch: 104, loss: 0.388392
global_step: 20150, epoch: 104, loss: 0.486422
global_step: 20151, epoch: 104, loss: 0.466805
global_step: 20152, epoch: 104, loss: 0.485762
global_step: 20153, epoch: 104, loss: 0.486245
global_step: 20154, epoch: 104, loss: 0.465247
global_step: 20155, epoch: 104, loss: 0.531417
global_step: 20156, epoch: 104, loss: 0.489672
global_step: 20157, epoch: 104, loss: 0.415319
global_step: 20158, epoch: 104, loss: 0.525388
global_step: 20159, epoch: 104, loss: 0.456364
global_step: 20160, epoch: 104, loss: 0.119398
epoch: 104
train	acc: 0.9042	macro: p 0.9019, r 0.7561, f1: 0.7787	micro: p 0.9042, r 0.9042, f1 0.9042	weighted_f1:0.8952
dev	acc: 0.5699	macro: p 0.5520, r 0.3644, f1: 0.3740	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5359
test	acc: 0.6057	macro: p 0.4008, r 0.3501, f1: 0.3536	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5752
global_step: 20161, epoch: 105, loss: 0.511804
global_step: 20162, epoch: 105, loss: 0.494043
global_step: 20163, epoch: 105, loss: 0.515645
global_step: 20164, epoch: 105, loss: 0.508427
global_step: 20165, epoch: 105, loss: 0.479624
global_step: 20166, epoch: 105, loss: 0.501620
global_step: 20167, epoch: 105, loss: 0.477734
global_step: 20168, epoch: 105, loss: 0.453005
global_step: 20169, epoch: 105, loss: 0.435418
global_step: 20170, epoch: 105, loss: 0.516443
global_step: 20171, epoch: 105, loss: 0.415344
global_step: 20172, epoch: 105, loss: 0.474994
global_step: 20173, epoch: 105, loss: 0.438496
global_step: 20174, epoch: 105, loss: 0.484025
global_step: 20175, epoch: 105, loss: 0.433794
global_step: 20176, epoch: 105, loss: 0.496279
global_step: 20177, epoch: 105, loss: 0.447604
global_step: 20178, epoch: 105, loss: 0.505867
global_step: 20179, epoch: 105, loss: 0.453411
global_step: 20180, epoch: 105, loss: 0.419150
global_step: 20181, epoch: 105, loss: 0.534353
global_step: 20182, epoch: 105, loss: 0.468090
global_step: 20183, epoch: 105, loss: 0.510798
global_step: 20184, epoch: 105, loss: 0.509210
global_step: 20185, epoch: 105, loss: 0.456030
global_step: 20186, epoch: 105, loss: 0.423725
global_step: 20187, epoch: 105, loss: 0.505496
global_step: 20188, epoch: 105, loss: 0.518617
global_step: 20189, epoch: 105, loss: 0.499487
global_step: 20190, epoch: 105, loss: 0.493031
global_step: 20191, epoch: 105, loss: 0.493365
global_step: 20192, epoch: 105, loss: 0.557417
global_step: 20193, epoch: 105, loss: 0.542723
global_step: 20194, epoch: 105, loss: 0.430873
global_step: 20195, epoch: 105, loss: 0.504728
global_step: 20196, epoch: 105, loss: 0.433628
global_step: 20197, epoch: 105, loss: 0.490627
global_step: 20198, epoch: 105, loss: 0.504810
global_step: 20199, epoch: 105, loss: 0.455459
global_step: 20200, epoch: 105, loss: 0.726954
epoch: 105
train	acc: 0.9042	macro: p 0.8984, r 0.7540, f1: 0.7755	micro: p 0.9042, r 0.9042, f1 0.9042	weighted_f1:0.8953
dev	acc: 0.5609	macro: p 0.3858, r 0.3477, f1: 0.3533	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5252
test	acc: 0.5981	macro: p 0.4030, r 0.3438, f1: 0.3530	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5670
global_step: 20201, epoch: 106, loss: 0.481145
global_step: 20202, epoch: 106, loss: 0.512074
global_step: 20203, epoch: 106, loss: 0.439788
global_step: 20204, epoch: 106, loss: 0.457094
global_step: 20205, epoch: 106, loss: 0.418888
global_step: 20206, epoch: 106, loss: 0.441419
global_step: 20207, epoch: 106, loss: 0.482099
global_step: 20208, epoch: 106, loss: 0.482414
global_step: 20209, epoch: 106, loss: 0.520769
global_step: 20210, epoch: 106, loss: 0.497577
global_step: 20211, epoch: 106, loss: 0.459038
global_step: 20212, epoch: 106, loss: 0.465397
global_step: 20213, epoch: 106, loss: 0.489368
global_step: 20214, epoch: 106, loss: 0.444199
global_step: 20215, epoch: 106, loss: 0.441692
global_step: 20216, epoch: 106, loss: 0.511603
global_step: 20217, epoch: 106, loss: 0.408120
global_step: 20218, epoch: 106, loss: 0.445386
global_step: 20219, epoch: 106, loss: 0.501540
global_step: 20220, epoch: 106, loss: 0.427476
global_step: 20221, epoch: 106, loss: 0.406557
global_step: 20222, epoch: 106, loss: 0.434821
global_step: 20223, epoch: 106, loss: 0.553089
global_step: 20224, epoch: 106, loss: 0.453446
global_step: 20225, epoch: 106, loss: 0.405527
global_step: 20226, epoch: 106, loss: 0.455542
global_step: 20227, epoch: 106, loss: 0.433609
global_step: 20228, epoch: 106, loss: 0.513788
global_step: 20229, epoch: 106, loss: 0.482457
global_step: 20230, epoch: 106, loss: 0.511086
global_step: 20231, epoch: 106, loss: 0.502923
global_step: 20232, epoch: 106, loss: 0.503687
global_step: 20233, epoch: 106, loss: 0.542478
global_step: 20234, epoch: 106, loss: 0.475517
global_step: 20235, epoch: 106, loss: 0.505411
global_step: 20236, epoch: 106, loss: 0.464170
global_step: 20237, epoch: 106, loss: 0.420172
global_step: 20238, epoch: 106, loss: 0.480546
global_step: 20239, epoch: 106, loss: 0.491259
global_step: 20240, epoch: 106, loss: 1.635584
epoch: 106
train	acc: 0.9035	macro: p 0.8912, r 0.7524, f1: 0.7752	micro: p 0.9035, r 0.9035, f1 0.9035	weighted_f1:0.8961
dev	acc: 0.5600	macro: p 0.5519, r 0.3704, f1: 0.3771	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5335
test	acc: 0.5946	macro: p 0.3975, r 0.3582, f1: 0.3550	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5728
global_step: 20241, epoch: 107, loss: 0.470946
global_step: 20242, epoch: 107, loss: 0.475254
global_step: 20243, epoch: 107, loss: 0.504388
global_step: 20244, epoch: 107, loss: 0.494210
global_step: 20245, epoch: 107, loss: 0.475983
global_step: 20246, epoch: 107, loss: 0.461944
global_step: 20247, epoch: 107, loss: 0.493763
global_step: 20248, epoch: 107, loss: 0.500277
global_step: 20249, epoch: 107, loss: 0.448586
global_step: 20250, epoch: 107, loss: 0.490515
global_step: 20251, epoch: 107, loss: 0.465127
global_step: 20252, epoch: 107, loss: 0.545109
global_step: 20253, epoch: 107, loss: 0.428283
global_step: 20254, epoch: 107, loss: 0.498469
global_step: 20255, epoch: 107, loss: 0.505968
global_step: 20256, epoch: 107, loss: 0.434868
global_step: 20257, epoch: 107, loss: 0.443810
global_step: 20258, epoch: 107, loss: 0.448855
global_step: 20259, epoch: 107, loss: 0.480171
global_step: 20260, epoch: 107, loss: 0.521653
global_step: 20261, epoch: 107, loss: 0.393570
global_step: 20262, epoch: 107, loss: 0.536535
global_step: 20263, epoch: 107, loss: 0.478185
global_step: 20264, epoch: 107, loss: 0.445997
global_step: 20265, epoch: 107, loss: 0.436620
global_step: 20266, epoch: 107, loss: 0.610161
global_step: 20267, epoch: 107, loss: 0.418072
global_step: 20268, epoch: 107, loss: 0.371458
global_step: 20269, epoch: 107, loss: 0.500710
global_step: 20270, epoch: 107, loss: 0.455140
global_step: 20271, epoch: 107, loss: 0.438262
global_step: 20272, epoch: 107, loss: 0.571291
global_step: 20273, epoch: 107, loss: 0.464891
global_step: 20274, epoch: 107, loss: 0.488305
global_step: 20275, epoch: 107, loss: 0.475206
global_step: 20276, epoch: 107, loss: 0.526013
global_step: 20277, epoch: 107, loss: 0.439973
global_step: 20278, epoch: 107, loss: 0.508164
global_step: 20279, epoch: 107, loss: 0.478001
global_step: 20280, epoch: 107, loss: 0.285056
epoch: 107
train	acc: 0.9120	macro: p 0.9026, r 0.7757, f1: 0.7998	micro: p 0.9120, r 0.9120, f1 0.9120	weighted_f1:0.9050
dev	acc: 0.5690	macro: p 0.4703, r 0.3645, f1: 0.3760	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5391
test	acc: 0.6011	macro: p 0.4069, r 0.3496, f1: 0.3582	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5736
global_step: 20281, epoch: 108, loss: 0.467045
global_step: 20282, epoch: 108, loss: 0.417615
global_step: 20283, epoch: 108, loss: 0.459234
global_step: 20284, epoch: 108, loss: 0.487979
global_step: 20285, epoch: 108, loss: 0.448002
global_step: 20286, epoch: 108, loss: 0.420597
global_step: 20287, epoch: 108, loss: 0.466867
global_step: 20288, epoch: 108, loss: 0.509476
global_step: 20289, epoch: 108, loss: 0.343318
global_step: 20290, epoch: 108, loss: 0.520620
global_step: 20291, epoch: 108, loss: 0.423713
global_step: 20292, epoch: 108, loss: 0.507612
global_step: 20293, epoch: 108, loss: 0.509273
global_step: 20294, epoch: 108, loss: 0.478956
global_step: 20295, epoch: 108, loss: 0.360035
global_step: 20296, epoch: 108, loss: 0.492440
global_step: 20297, epoch: 108, loss: 0.459371
global_step: 20298, epoch: 108, loss: 0.441287
global_step: 20299, epoch: 108, loss: 0.494563
global_step: 20300, epoch: 108, loss: 0.404652
global_step: 20301, epoch: 108, loss: 0.480590
global_step: 20302, epoch: 108, loss: 0.469669
global_step: 20303, epoch: 108, loss: 0.453684
global_step: 20304, epoch: 108, loss: 0.519765
global_step: 20305, epoch: 108, loss: 0.478582
global_step: 20306, epoch: 108, loss: 0.440175
global_step: 20307, epoch: 108, loss: 0.446061
global_step: 20308, epoch: 108, loss: 0.418116
global_step: 20309, epoch: 108, loss: 0.473078
global_step: 20310, epoch: 108, loss: 0.523590
global_step: 20311, epoch: 108, loss: 0.458725
global_step: 20312, epoch: 108, loss: 0.535807
global_step: 20313, epoch: 108, loss: 0.489345
global_step: 20314, epoch: 108, loss: 0.456742
global_step: 20315, epoch: 108, loss: 0.520767
global_step: 20316, epoch: 108, loss: 0.513543
global_step: 20317, epoch: 108, loss: 0.391662
global_step: 20318, epoch: 108, loss: 0.518144
global_step: 20319, epoch: 108, loss: 0.497868
global_step: 20320, epoch: 108, loss: 1.662810
epoch: 108
train	acc: 0.9042	macro: p 0.9107, r 0.7739, f1: 0.8112	micro: p 0.9042, r 0.9042, f1 0.9042	weighted_f1:0.8982
dev	acc: 0.5699	macro: p 0.4931, r 0.3527, f1: 0.3709	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5299
test	acc: 0.6080	macro: p 0.4170, r 0.3394, f1: 0.3545	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5703
global_step: 20321, epoch: 109, loss: 0.510025
global_step: 20322, epoch: 109, loss: 0.432061
global_step: 20323, epoch: 109, loss: 0.567926
global_step: 20324, epoch: 109, loss: 0.481600
global_step: 20325, epoch: 109, loss: 0.405044
global_step: 20326, epoch: 109, loss: 0.362432
global_step: 20327, epoch: 109, loss: 0.442944
global_step: 20328, epoch: 109, loss: 0.436241
global_step: 20329, epoch: 109, loss: 0.534867
global_step: 20330, epoch: 109, loss: 0.413251
global_step: 20331, epoch: 109, loss: 0.414944
global_step: 20332, epoch: 109, loss: 0.430375
global_step: 20333, epoch: 109, loss: 0.469048
global_step: 20334, epoch: 109, loss: 0.393619
global_step: 20335, epoch: 109, loss: 0.439411
global_step: 20336, epoch: 109, loss: 0.515381
global_step: 20337, epoch: 109, loss: 0.403149
global_step: 20338, epoch: 109, loss: 0.442969
global_step: 20339, epoch: 109, loss: 0.452469
global_step: 20340, epoch: 109, loss: 0.376080
global_step: 20341, epoch: 109, loss: 0.470054
global_step: 20342, epoch: 109, loss: 0.410814
global_step: 20343, epoch: 109, loss: 0.553231
global_step: 20344, epoch: 109, loss: 0.456861
global_step: 20345, epoch: 109, loss: 0.459624
global_step: 20346, epoch: 109, loss: 0.392814
global_step: 20347, epoch: 109, loss: 0.425049
global_step: 20348, epoch: 109, loss: 0.549888
global_step: 20349, epoch: 109, loss: 0.445434
global_step: 20350, epoch: 109, loss: 0.544945
global_step: 20351, epoch: 109, loss: 0.427327
global_step: 20352, epoch: 109, loss: 0.433069
global_step: 20353, epoch: 109, loss: 0.455750
global_step: 20354, epoch: 109, loss: 0.560190
global_step: 20355, epoch: 109, loss: 0.510338
global_step: 20356, epoch: 109, loss: 0.440690
global_step: 20357, epoch: 109, loss: 0.581685
global_step: 20358, epoch: 109, loss: 0.431811
global_step: 20359, epoch: 109, loss: 0.475930
global_step: 20360, epoch: 109, loss: 0.182097
epoch: 109
train	acc: 0.9149	macro: p 0.9088, r 0.7899, f1: 0.8175	micro: p 0.9149, r 0.9149, f1 0.9149	weighted_f1:0.9091
dev	acc: 0.5717	macro: p 0.5481, r 0.3702, f1: 0.3791	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5400
test	acc: 0.5939	macro: p 0.3821, r 0.3457, f1: 0.3487	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5656
global_step: 20361, epoch: 110, loss: 0.499715
global_step: 20362, epoch: 110, loss: 0.416126
global_step: 20363, epoch: 110, loss: 0.391732
global_step: 20364, epoch: 110, loss: 0.403802
global_step: 20365, epoch: 110, loss: 0.439905
global_step: 20366, epoch: 110, loss: 0.351490
global_step: 20367, epoch: 110, loss: 0.459537
global_step: 20368, epoch: 110, loss: 0.513999
global_step: 20369, epoch: 110, loss: 0.510446
global_step: 20370, epoch: 110, loss: 0.507517
global_step: 20371, epoch: 110, loss: 0.474513
global_step: 20372, epoch: 110, loss: 0.511375
global_step: 20373, epoch: 110, loss: 0.489783
global_step: 20374, epoch: 110, loss: 0.430822
global_step: 20375, epoch: 110, loss: 0.482523
global_step: 20376, epoch: 110, loss: 0.426773
global_step: 20377, epoch: 110, loss: 0.477213
global_step: 20378, epoch: 110, loss: 0.548961
global_step: 20379, epoch: 110, loss: 0.500180
global_step: 20380, epoch: 110, loss: 0.503059
global_step: 20381, epoch: 110, loss: 0.392696
global_step: 20382, epoch: 110, loss: 0.361076
global_step: 20383, epoch: 110, loss: 0.475472
global_step: 20384, epoch: 110, loss: 0.525387
global_step: 20385, epoch: 110, loss: 0.417071
global_step: 20386, epoch: 110, loss: 0.433339
global_step: 20387, epoch: 110, loss: 0.476834
global_step: 20388, epoch: 110, loss: 0.482736
global_step: 20389, epoch: 110, loss: 0.430674
global_step: 20390, epoch: 110, loss: 0.444681
global_step: 20391, epoch: 110, loss: 0.506834
global_step: 20392, epoch: 110, loss: 0.398449
global_step: 20393, epoch: 110, loss: 0.419017
global_step: 20394, epoch: 110, loss: 0.428976
global_step: 20395, epoch: 110, loss: 0.419854
global_step: 20396, epoch: 110, loss: 0.616579
global_step: 20397, epoch: 110, loss: 0.510012
global_step: 20398, epoch: 110, loss: 0.429777
global_step: 20399, epoch: 110, loss: 0.468272
global_step: 20400, epoch: 110, loss: 0.757115
epoch: 110
train	acc: 0.9106	macro: p 0.9096, r 0.7842, f1: 0.8091	micro: p 0.9106, r 0.9106, f1 0.9106	weighted_f1:0.9041
dev	acc: 0.5500	macro: p 0.4111, r 0.3441, f1: 0.3541	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5171
test	acc: 0.5870	macro: p 0.3811, r 0.3365, f1: 0.3453	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5567
global_step: 20401, epoch: 111, loss: 0.393036
global_step: 20402, epoch: 111, loss: 0.494416
global_step: 20403, epoch: 111, loss: 0.480971
global_step: 20404, epoch: 111, loss: 0.440869
global_step: 20405, epoch: 111, loss: 0.443947
global_step: 20406, epoch: 111, loss: 0.445596
global_step: 20407, epoch: 111, loss: 0.377199
global_step: 20408, epoch: 111, loss: 0.462837
global_step: 20409, epoch: 111, loss: 0.393295
global_step: 20410, epoch: 111, loss: 0.422229
global_step: 20411, epoch: 111, loss: 0.452235
global_step: 20412, epoch: 111, loss: 0.480408
global_step: 20413, epoch: 111, loss: 0.481506
global_step: 20414, epoch: 111, loss: 0.413732
global_step: 20415, epoch: 111, loss: 0.431240
global_step: 20416, epoch: 111, loss: 0.424181
global_step: 20417, epoch: 111, loss: 0.442939
global_step: 20418, epoch: 111, loss: 0.526033
global_step: 20419, epoch: 111, loss: 0.526241
global_step: 20420, epoch: 111, loss: 0.494728
global_step: 20421, epoch: 111, loss: 0.382752
global_step: 20422, epoch: 111, loss: 0.482122
global_step: 20423, epoch: 111, loss: 0.486882
global_step: 20424, epoch: 111, loss: 0.433404
global_step: 20425, epoch: 111, loss: 0.447869
global_step: 20426, epoch: 111, loss: 0.414788
global_step: 20427, epoch: 111, loss: 0.523790
global_step: 20428, epoch: 111, loss: 0.404717
global_step: 20429, epoch: 111, loss: 0.442454
global_step: 20430, epoch: 111, loss: 0.429456
global_step: 20431, epoch: 111, loss: 0.396142
global_step: 20432, epoch: 111, loss: 0.458473
global_step: 20433, epoch: 111, loss: 0.471160
global_step: 20434, epoch: 111, loss: 0.459774
global_step: 20435, epoch: 111, loss: 0.487967
global_step: 20436, epoch: 111, loss: 0.451761
global_step: 20437, epoch: 111, loss: 0.456936
global_step: 20438, epoch: 111, loss: 0.426287
global_step: 20439, epoch: 111, loss: 0.454994
global_step: 20440, epoch: 111, loss: 0.838986
epoch: 111
train	acc: 0.9156	macro: p 0.9060, r 0.7902, f1: 0.8174	micro: p 0.9156, r 0.9156, f1 0.9156	weighted_f1:0.9099
dev	acc: 0.5762	macro: p 0.4843, r 0.3760, f1: 0.3895	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5483
test	acc: 0.6008	macro: p 0.3989, r 0.3536, f1: 0.3607	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5749
global_step: 20441, epoch: 112, loss: 0.425423
global_step: 20442, epoch: 112, loss: 0.382810
global_step: 20443, epoch: 112, loss: 0.430786
global_step: 20444, epoch: 112, loss: 0.424234
global_step: 20445, epoch: 112, loss: 0.461483
global_step: 20446, epoch: 112, loss: 0.463341
global_step: 20447, epoch: 112, loss: 0.438999
global_step: 20448, epoch: 112, loss: 0.387567
global_step: 20449, epoch: 112, loss: 0.466466
global_step: 20450, epoch: 112, loss: 0.396626
global_step: 20451, epoch: 112, loss: 0.523675
global_step: 20452, epoch: 112, loss: 0.411677
global_step: 20453, epoch: 112, loss: 0.383831
global_step: 20454, epoch: 112, loss: 0.508704
global_step: 20455, epoch: 112, loss: 0.413732
global_step: 20456, epoch: 112, loss: 0.411783
global_step: 20457, epoch: 112, loss: 0.495902
global_step: 20458, epoch: 112, loss: 0.384165
global_step: 20459, epoch: 112, loss: 0.499600
global_step: 20460, epoch: 112, loss: 0.406045
global_step: 20461, epoch: 112, loss: 0.484361
global_step: 20462, epoch: 112, loss: 0.367799
global_step: 20463, epoch: 112, loss: 0.483718
global_step: 20464, epoch: 112, loss: 0.535979
global_step: 20465, epoch: 112, loss: 0.494023
global_step: 20466, epoch: 112, loss: 0.416874
global_step: 20467, epoch: 112, loss: 0.399892
global_step: 20468, epoch: 112, loss: 0.457045
global_step: 20469, epoch: 112, loss: 0.435860
global_step: 20470, epoch: 112, loss: 0.490801
global_step: 20471, epoch: 112, loss: 0.453334
global_step: 20472, epoch: 112, loss: 0.476250
global_step: 20473, epoch: 112, loss: 0.504037
global_step: 20474, epoch: 112, loss: 0.411236
global_step: 20475, epoch: 112, loss: 0.404731
global_step: 20476, epoch: 112, loss: 0.431604
global_step: 20477, epoch: 112, loss: 0.441904
global_step: 20478, epoch: 112, loss: 0.455906
global_step: 20479, epoch: 112, loss: 0.462627
global_step: 20480, epoch: 112, loss: 1.164301
epoch: 112
train	acc: 0.9197	macro: p 0.9035, r 0.8000, f1: 0.8113	micro: p 0.9197, r 0.9197, f1 0.9197	weighted_f1:0.9134
dev	acc: 0.5582	macro: p 0.4595, r 0.3801, f1: 0.3854	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5412
test	acc: 0.5778	macro: p 0.3749, r 0.3615, f1: 0.3619	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5675
global_step: 20481, epoch: 113, loss: 0.453228
global_step: 20482, epoch: 113, loss: 0.375075
global_step: 20483, epoch: 113, loss: 0.447367
global_step: 20484, epoch: 113, loss: 0.550814
global_step: 20485, epoch: 113, loss: 0.406701
global_step: 20486, epoch: 113, loss: 0.399325
global_step: 20487, epoch: 113, loss: 0.393061
global_step: 20488, epoch: 113, loss: 0.505677
global_step: 20489, epoch: 113, loss: 0.327847
global_step: 20490, epoch: 113, loss: 0.468073
global_step: 20491, epoch: 113, loss: 0.394157
global_step: 20492, epoch: 113, loss: 0.452850
global_step: 20493, epoch: 113, loss: 0.464509
global_step: 20494, epoch: 113, loss: 0.416679
global_step: 20495, epoch: 113, loss: 0.486770
global_step: 20496, epoch: 113, loss: 0.485515
global_step: 20497, epoch: 113, loss: 0.527527
global_step: 20498, epoch: 113, loss: 0.435884
global_step: 20499, epoch: 113, loss: 0.354716
global_step: 20500, epoch: 113, loss: 0.487289
global_step: 20501, epoch: 113, loss: 0.504666
global_step: 20502, epoch: 113, loss: 0.431621
global_step: 20503, epoch: 113, loss: 0.461835
global_step: 20504, epoch: 113, loss: 0.514289
global_step: 20505, epoch: 113, loss: 0.498596
global_step: 20506, epoch: 113, loss: 0.417150
global_step: 20507, epoch: 113, loss: 0.478860
global_step: 20508, epoch: 113, loss: 0.525141
global_step: 20509, epoch: 113, loss: 0.478852
global_step: 20510, epoch: 113, loss: 0.368859
global_step: 20511, epoch: 113, loss: 0.388287
global_step: 20512, epoch: 113, loss: 0.443446
global_step: 20513, epoch: 113, loss: 0.401419
global_step: 20514, epoch: 113, loss: 0.504735
global_step: 20515, epoch: 113, loss: 0.447657
global_step: 20516, epoch: 113, loss: 0.439842
global_step: 20517, epoch: 113, loss: 0.440901
global_step: 20518, epoch: 113, loss: 0.381506
global_step: 20519, epoch: 113, loss: 0.459345
global_step: 20520, epoch: 113, loss: 0.144594
epoch: 113
train	acc: 0.9164	macro: p 0.9133, r 0.7922, f1: 0.8182	micro: p 0.9164, r 0.9164, f1 0.9164	weighted_f1:0.9102
dev	acc: 0.5663	macro: p 0.5419, r 0.3639, f1: 0.3743	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5339
test	acc: 0.6042	macro: p 0.4000, r 0.3497, f1: 0.3561	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5736
global_step: 20521, epoch: 114, loss: 0.419611
global_step: 20522, epoch: 114, loss: 0.444570
global_step: 20523, epoch: 114, loss: 0.418894
global_step: 20524, epoch: 114, loss: 0.426784
global_step: 20525, epoch: 114, loss: 0.451052
global_step: 20526, epoch: 114, loss: 0.459630
global_step: 20527, epoch: 114, loss: 0.411710
global_step: 20528, epoch: 114, loss: 0.398507
global_step: 20529, epoch: 114, loss: 0.483812
global_step: 20530, epoch: 114, loss: 0.501605
global_step: 20531, epoch: 114, loss: 0.447330
global_step: 20532, epoch: 114, loss: 0.484974
global_step: 20533, epoch: 114, loss: 0.465855
global_step: 20534, epoch: 114, loss: 0.380769
global_step: 20535, epoch: 114, loss: 0.433558
global_step: 20536, epoch: 114, loss: 0.423179
global_step: 20537, epoch: 114, loss: 0.381843
global_step: 20538, epoch: 114, loss: 0.514355
global_step: 20539, epoch: 114, loss: 0.451256
global_step: 20540, epoch: 114, loss: 0.422591
global_step: 20541, epoch: 114, loss: 0.364319
global_step: 20542, epoch: 114, loss: 0.409695
global_step: 20543, epoch: 114, loss: 0.419195
global_step: 20544, epoch: 114, loss: 0.353284
global_step: 20545, epoch: 114, loss: 0.443233
global_step: 20546, epoch: 114, loss: 0.415009
global_step: 20547, epoch: 114, loss: 0.467035
global_step: 20548, epoch: 114, loss: 0.372030
global_step: 20549, epoch: 114, loss: 0.426753
global_step: 20550, epoch: 114, loss: 0.448754
global_step: 20551, epoch: 114, loss: 0.416818
global_step: 20552, epoch: 114, loss: 0.483656
global_step: 20553, epoch: 114, loss: 0.501742
global_step: 20554, epoch: 114, loss: 0.508290
global_step: 20555, epoch: 114, loss: 0.409069
global_step: 20556, epoch: 114, loss: 0.415079
global_step: 20557, epoch: 114, loss: 0.483381
global_step: 20558, epoch: 114, loss: 0.452804
global_step: 20559, epoch: 114, loss: 0.407929
global_step: 20560, epoch: 114, loss: 0.059542
epoch: 114
train	acc: 0.9123	macro: p 0.9163, r 0.7836, f1: 0.8152	micro: p 0.9123, r 0.9123, f1 0.9123	weighted_f1:0.9057
dev	acc: 0.5672	macro: p 0.4498, r 0.3493, f1: 0.3587	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5231
test	acc: 0.6004	macro: p 0.3989, r 0.3345, f1: 0.3433	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5619
global_step: 20561, epoch: 115, loss: 0.421700
global_step: 20562, epoch: 115, loss: 0.460572
global_step: 20563, epoch: 115, loss: 0.474324
global_step: 20564, epoch: 115, loss: 0.488821
global_step: 20565, epoch: 115, loss: 0.501602
global_step: 20566, epoch: 115, loss: 0.481284
global_step: 20567, epoch: 115, loss: 0.439198
global_step: 20568, epoch: 115, loss: 0.439143
global_step: 20569, epoch: 115, loss: 0.422433
global_step: 20570, epoch: 115, loss: 0.417533
global_step: 20571, epoch: 115, loss: 0.414447
global_step: 20572, epoch: 115, loss: 0.495948
global_step: 20573, epoch: 115, loss: 0.339731
global_step: 20574, epoch: 115, loss: 0.423779
global_step: 20575, epoch: 115, loss: 0.410580
global_step: 20576, epoch: 115, loss: 0.524155
global_step: 20577, epoch: 115, loss: 0.357127
global_step: 20578, epoch: 115, loss: 0.431854
global_step: 20579, epoch: 115, loss: 0.482543
global_step: 20580, epoch: 115, loss: 0.494313
global_step: 20581, epoch: 115, loss: 0.412590
global_step: 20582, epoch: 115, loss: 0.376566
global_step: 20583, epoch: 115, loss: 0.370832
global_step: 20584, epoch: 115, loss: 0.419522
global_step: 20585, epoch: 115, loss: 0.444402
global_step: 20586, epoch: 115, loss: 0.464989
global_step: 20587, epoch: 115, loss: 0.394853
global_step: 20588, epoch: 115, loss: 0.418619
global_step: 20589, epoch: 115, loss: 0.378949
global_step: 20590, epoch: 115, loss: 0.417323
global_step: 20591, epoch: 115, loss: 0.399617
global_step: 20592, epoch: 115, loss: 0.410370
global_step: 20593, epoch: 115, loss: 0.448427
global_step: 20594, epoch: 115, loss: 0.467261
global_step: 20595, epoch: 115, loss: 0.479334
global_step: 20596, epoch: 115, loss: 0.406271
global_step: 20597, epoch: 115, loss: 0.411813
global_step: 20598, epoch: 115, loss: 0.453544
global_step: 20599, epoch: 115, loss: 0.482026
global_step: 20600, epoch: 115, loss: 0.241220
epoch: 115
train	acc: 0.9143	macro: p 0.9154, r 0.7879, f1: 0.8178	micro: p 0.9143, r 0.9143, f1 0.9143	weighted_f1:0.9084
dev	acc: 0.5500	macro: p 0.4585, r 0.3429, f1: 0.3503	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5132
test	acc: 0.5946	macro: p 0.4141, r 0.3348, f1: 0.3430	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5608
global_step: 20601, epoch: 116, loss: 0.470672
global_step: 20602, epoch: 116, loss: 0.364799
global_step: 20603, epoch: 116, loss: 0.359529
global_step: 20604, epoch: 116, loss: 0.454136
global_step: 20605, epoch: 116, loss: 0.529656
global_step: 20606, epoch: 116, loss: 0.512165
global_step: 20607, epoch: 116, loss: 0.376266
global_step: 20608, epoch: 116, loss: 0.421783
global_step: 20609, epoch: 116, loss: 0.481386
global_step: 20610, epoch: 116, loss: 0.406560
global_step: 20611, epoch: 116, loss: 0.368591
global_step: 20612, epoch: 116, loss: 0.351185
global_step: 20613, epoch: 116, loss: 0.423708
global_step: 20614, epoch: 116, loss: 0.392846
global_step: 20615, epoch: 116, loss: 0.389298
global_step: 20616, epoch: 116, loss: 0.410865
global_step: 20617, epoch: 116, loss: 0.352094
global_step: 20618, epoch: 116, loss: 0.441454
global_step: 20619, epoch: 116, loss: 0.440023
global_step: 20620, epoch: 116, loss: 0.365849
global_step: 20621, epoch: 116, loss: 0.554137
global_step: 20622, epoch: 116, loss: 0.460147
global_step: 20623, epoch: 116, loss: 0.437676
global_step: 20624, epoch: 116, loss: 0.454504
global_step: 20625, epoch: 116, loss: 0.387966
global_step: 20626, epoch: 116, loss: 0.392533
global_step: 20627, epoch: 116, loss: 0.509213
global_step: 20628, epoch: 116, loss: 0.443256
global_step: 20629, epoch: 116, loss: 0.398747
global_step: 20630, epoch: 116, loss: 0.480267
global_step: 20631, epoch: 116, loss: 0.496039
global_step: 20632, epoch: 116, loss: 0.473370
global_step: 20633, epoch: 116, loss: 0.414947
global_step: 20634, epoch: 116, loss: 0.421895
global_step: 20635, epoch: 116, loss: 0.435157
global_step: 20636, epoch: 116, loss: 0.426761
global_step: 20637, epoch: 116, loss: 0.408857
global_step: 20638, epoch: 116, loss: 0.437418
global_step: 20639, epoch: 116, loss: 0.482900
global_step: 20640, epoch: 116, loss: 0.364224
epoch: 116
train	acc: 0.9200	macro: p 0.9125, r 0.8075, f1: 0.8308	micro: p 0.9200, r 0.9200, f1 0.9200	weighted_f1:0.9152
dev	acc: 0.5582	macro: p 0.4702, r 0.3727, f1: 0.3756	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5305
test	acc: 0.5831	macro: p 0.3843, r 0.3500, f1: 0.3486	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5603
global_step: 20641, epoch: 117, loss: 0.490802
global_step: 20642, epoch: 117, loss: 0.450873
global_step: 20643, epoch: 117, loss: 0.419014
global_step: 20644, epoch: 117, loss: 0.457641
global_step: 20645, epoch: 117, loss: 0.384719
global_step: 20646, epoch: 117, loss: 0.396848
global_step: 20647, epoch: 117, loss: 0.348278
global_step: 20648, epoch: 117, loss: 0.372888
global_step: 20649, epoch: 117, loss: 0.449758
global_step: 20650, epoch: 117, loss: 0.434545
global_step: 20651, epoch: 117, loss: 0.366025
global_step: 20652, epoch: 117, loss: 0.328397
global_step: 20653, epoch: 117, loss: 0.368054
global_step: 20654, epoch: 117, loss: 0.459923
global_step: 20655, epoch: 117, loss: 0.451638
global_step: 20656, epoch: 117, loss: 0.382695
global_step: 20657, epoch: 117, loss: 0.360476
global_step: 20658, epoch: 117, loss: 0.414099
global_step: 20659, epoch: 117, loss: 0.385942
global_step: 20660, epoch: 117, loss: 0.468060
global_step: 20661, epoch: 117, loss: 0.441510
global_step: 20662, epoch: 117, loss: 0.438065
global_step: 20663, epoch: 117, loss: 0.491316
global_step: 20664, epoch: 117, loss: 0.405117
global_step: 20665, epoch: 117, loss: 0.511988
global_step: 20666, epoch: 117, loss: 0.433626
global_step: 20667, epoch: 117, loss: 0.502503
global_step: 20668, epoch: 117, loss: 0.508635
global_step: 20669, epoch: 117, loss: 0.385677
global_step: 20670, epoch: 117, loss: 0.422721
global_step: 20671, epoch: 117, loss: 0.361951
global_step: 20672, epoch: 117, loss: 0.424925
global_step: 20673, epoch: 117, loss: 0.420216
global_step: 20674, epoch: 117, loss: 0.379423
global_step: 20675, epoch: 117, loss: 0.298446
global_step: 20676, epoch: 117, loss: 0.432849
global_step: 20677, epoch: 117, loss: 0.464651
global_step: 20678, epoch: 117, loss: 0.428802
global_step: 20679, epoch: 117, loss: 0.415887
global_step: 20680, epoch: 117, loss: 0.062628
epoch: 117
train	acc: 0.9235	macro: p 0.9160, r 0.8051, f1: 0.8268	micro: p 0.9235, r 0.9235, f1 0.9235	weighted_f1:0.9178
dev	acc: 0.5600	macro: p 0.4675, r 0.3632, f1: 0.3733	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5320
test	acc: 0.5958	macro: p 0.3991, r 0.3517, f1: 0.3564	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5705
global_step: 20681, epoch: 118, loss: 0.390828
global_step: 20682, epoch: 118, loss: 0.487159
global_step: 20683, epoch: 118, loss: 0.363424
global_step: 20684, epoch: 118, loss: 0.306903
global_step: 20685, epoch: 118, loss: 0.446319
global_step: 20686, epoch: 118, loss: 0.326408
global_step: 20687, epoch: 118, loss: 0.446346
global_step: 20688, epoch: 118, loss: 0.407023
global_step: 20689, epoch: 118, loss: 0.371228
global_step: 20690, epoch: 118, loss: 0.354989
global_step: 20691, epoch: 118, loss: 0.372434
global_step: 20692, epoch: 118, loss: 0.481627
global_step: 20693, epoch: 118, loss: 0.406337
global_step: 20694, epoch: 118, loss: 0.368797
global_step: 20695, epoch: 118, loss: 0.334863
global_step: 20696, epoch: 118, loss: 0.403789
global_step: 20697, epoch: 118, loss: 0.436175
global_step: 20698, epoch: 118, loss: 0.402114
global_step: 20699, epoch: 118, loss: 0.346676
global_step: 20700, epoch: 118, loss: 0.376134
global_step: 20701, epoch: 118, loss: 0.381297
global_step: 20702, epoch: 118, loss: 0.439245
global_step: 20703, epoch: 118, loss: 0.365168
global_step: 20704, epoch: 118, loss: 0.454249
global_step: 20705, epoch: 118, loss: 0.423707
global_step: 20706, epoch: 118, loss: 0.435476
global_step: 20707, epoch: 118, loss: 0.441453
global_step: 20708, epoch: 118, loss: 0.459699
global_step: 20709, epoch: 118, loss: 0.382404
global_step: 20710, epoch: 118, loss: 0.422083
global_step: 20711, epoch: 118, loss: 0.477708
global_step: 20712, epoch: 118, loss: 0.575744
global_step: 20713, epoch: 118, loss: 0.353206
global_step: 20714, epoch: 118, loss: 0.505584
global_step: 20715, epoch: 118, loss: 0.318080
global_step: 20716, epoch: 118, loss: 0.417225
global_step: 20717, epoch: 118, loss: 0.456710
global_step: 20718, epoch: 118, loss: 0.470012
global_step: 20719, epoch: 118, loss: 0.555256
global_step: 20720, epoch: 118, loss: 0.437073
epoch: 118
train	acc: 0.9196	macro: p 0.9208, r 0.8010, f1: 0.8345	micro: p 0.9196, r 0.9196, f1 0.9196	weighted_f1:0.9149
dev	acc: 0.5564	macro: p 0.4482, r 0.3412, f1: 0.3543	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5213
test	acc: 0.6015	macro: p 0.4235, r 0.3433, f1: 0.3554	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5704
global_step: 20721, epoch: 119, loss: 0.444871
global_step: 20722, epoch: 119, loss: 0.492657
global_step: 20723, epoch: 119, loss: 0.382614
global_step: 20724, epoch: 119, loss: 0.407570
global_step: 20725, epoch: 119, loss: 0.421140
global_step: 20726, epoch: 119, loss: 0.416680
global_step: 20727, epoch: 119, loss: 0.419769
global_step: 20728, epoch: 119, loss: 0.403391
global_step: 20729, epoch: 119, loss: 0.416548
global_step: 20730, epoch: 119, loss: 0.407993
global_step: 20731, epoch: 119, loss: 0.475340
global_step: 20732, epoch: 119, loss: 0.442647
global_step: 20733, epoch: 119, loss: 0.372569
global_step: 20734, epoch: 119, loss: 0.399490
global_step: 20735, epoch: 119, loss: 0.389385
global_step: 20736, epoch: 119, loss: 0.497930
global_step: 20737, epoch: 119, loss: 0.404064
global_step: 20738, epoch: 119, loss: 0.449827
global_step: 20739, epoch: 119, loss: 0.354511
global_step: 20740, epoch: 119, loss: 0.396738
global_step: 20741, epoch: 119, loss: 0.453930
global_step: 20742, epoch: 119, loss: 0.483073
global_step: 20743, epoch: 119, loss: 0.453376
global_step: 20744, epoch: 119, loss: 0.475859
global_step: 20745, epoch: 119, loss: 0.340053
global_step: 20746, epoch: 119, loss: 0.430477
global_step: 20747, epoch: 119, loss: 0.396125
global_step: 20748, epoch: 119, loss: 0.457505
global_step: 20749, epoch: 119, loss: 0.394607
global_step: 20750, epoch: 119, loss: 0.378425
global_step: 20751, epoch: 119, loss: 0.395923
global_step: 20752, epoch: 119, loss: 0.426012
global_step: 20753, epoch: 119, loss: 0.359232
global_step: 20754, epoch: 119, loss: 0.432139
global_step: 20755, epoch: 119, loss: 0.397742
global_step: 20756, epoch: 119, loss: 0.432296
global_step: 20757, epoch: 119, loss: 0.383874
global_step: 20758, epoch: 119, loss: 0.394944
global_step: 20759, epoch: 119, loss: 0.409548
global_step: 20760, epoch: 119, loss: 1.380772
epoch: 119
train	acc: 0.9305	macro: p 0.9177, r 0.8398, f1: 0.8619	micro: p 0.9305, r 0.9305, f1 0.9305	weighted_f1:0.9277
dev	acc: 0.5726	macro: p 0.4341, r 0.3863, f1: 0.3963	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5504
test	acc: 0.5954	macro: p 0.3903, r 0.3620, f1: 0.3699	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5772
New best model!
global_step: 20761, epoch: 120, loss: 0.416632
global_step: 20762, epoch: 120, loss: 0.331630
global_step: 20763, epoch: 120, loss: 0.426362
global_step: 20764, epoch: 120, loss: 0.366951
global_step: 20765, epoch: 120, loss: 0.435440
global_step: 20766, epoch: 120, loss: 0.383662
global_step: 20767, epoch: 120, loss: 0.457098
global_step: 20768, epoch: 120, loss: 0.425543
global_step: 20769, epoch: 120, loss: 0.509760
global_step: 20770, epoch: 120, loss: 0.442201
global_step: 20771, epoch: 120, loss: 0.434953
global_step: 20772, epoch: 120, loss: 0.426873
global_step: 20773, epoch: 120, loss: 0.407518
global_step: 20774, epoch: 120, loss: 0.395463
global_step: 20775, epoch: 120, loss: 0.410849
global_step: 20776, epoch: 120, loss: 0.454785
global_step: 20777, epoch: 120, loss: 0.379177
global_step: 20778, epoch: 120, loss: 0.468694
global_step: 20779, epoch: 120, loss: 0.381438
global_step: 20780, epoch: 120, loss: 0.338214
global_step: 20781, epoch: 120, loss: 0.521686
global_step: 20782, epoch: 120, loss: 0.475069
global_step: 20783, epoch: 120, loss: 0.379890
global_step: 20784, epoch: 120, loss: 0.430180
global_step: 20785, epoch: 120, loss: 0.390906
global_step: 20786, epoch: 120, loss: 0.404301
global_step: 20787, epoch: 120, loss: 0.369711
global_step: 20788, epoch: 120, loss: 0.409179
global_step: 20789, epoch: 120, loss: 0.414579
global_step: 20790, epoch: 120, loss: 0.404403
global_step: 20791, epoch: 120, loss: 0.447864
global_step: 20792, epoch: 120, loss: 0.426525
global_step: 20793, epoch: 120, loss: 0.378307
global_step: 20794, epoch: 120, loss: 0.370663
global_step: 20795, epoch: 120, loss: 0.336580
global_step: 20796, epoch: 120, loss: 0.475713
global_step: 20797, epoch: 120, loss: 0.383803
global_step: 20798, epoch: 120, loss: 0.376433
global_step: 20799, epoch: 120, loss: 0.354674
global_step: 20800, epoch: 120, loss: 1.077376
epoch: 120
train	acc: 0.9278	macro: p 0.9246, r 0.8283, f1: 0.8564	micro: p 0.9278, r 0.9278, f1 0.9278	weighted_f1:0.9244
dev	acc: 0.5735	macro: p 0.4471, r 0.3707, f1: 0.3852	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5434
test	acc: 0.5981	macro: p 0.3965, r 0.3446, f1: 0.3562	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5690
global_step: 20801, epoch: 121, loss: 0.414479
global_step: 20802, epoch: 121, loss: 0.431038
global_step: 20803, epoch: 121, loss: 0.388158
global_step: 20804, epoch: 121, loss: 0.368212
global_step: 20805, epoch: 121, loss: 0.478141
global_step: 20806, epoch: 121, loss: 0.416143
global_step: 20807, epoch: 121, loss: 0.447501
global_step: 20808, epoch: 121, loss: 0.432536
global_step: 20809, epoch: 121, loss: 0.466050
global_step: 20810, epoch: 121, loss: 0.482940
global_step: 20811, epoch: 121, loss: 0.374843
global_step: 20812, epoch: 121, loss: 0.394076
global_step: 20813, epoch: 121, loss: 0.432204
global_step: 20814, epoch: 121, loss: 0.389027
global_step: 20815, epoch: 121, loss: 0.317478
global_step: 20816, epoch: 121, loss: 0.372589
global_step: 20817, epoch: 121, loss: 0.387075
global_step: 20818, epoch: 121, loss: 0.370127
global_step: 20819, epoch: 121, loss: 0.367625
global_step: 20820, epoch: 121, loss: 0.446384
global_step: 20821, epoch: 121, loss: 0.417949
global_step: 20822, epoch: 121, loss: 0.340424
global_step: 20823, epoch: 121, loss: 0.527312
global_step: 20824, epoch: 121, loss: 0.432560
global_step: 20825, epoch: 121, loss: 0.377313
global_step: 20826, epoch: 121, loss: 0.415164
global_step: 20827, epoch: 121, loss: 0.341719
global_step: 20828, epoch: 121, loss: 0.401897
global_step: 20829, epoch: 121, loss: 0.362653
global_step: 20830, epoch: 121, loss: 0.417764
global_step: 20831, epoch: 121, loss: 0.463574
global_step: 20832, epoch: 121, loss: 0.475978
global_step: 20833, epoch: 121, loss: 0.437224
global_step: 20834, epoch: 121, loss: 0.372290
global_step: 20835, epoch: 121, loss: 0.411602
global_step: 20836, epoch: 121, loss: 0.374212
global_step: 20837, epoch: 121, loss: 0.462294
global_step: 20838, epoch: 121, loss: 0.415801
global_step: 20839, epoch: 121, loss: 0.310238
global_step: 20840, epoch: 121, loss: 0.353341
epoch: 121
train	acc: 0.9213	macro: p 0.9311, r 0.8173, f1: 0.8525	micro: p 0.9213, r 0.9213, f1 0.9213	weighted_f1:0.9172
dev	acc: 0.5834	macro: p 0.5048, r 0.3651, f1: 0.3788	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5418
test	acc: 0.6011	macro: p 0.3986, r 0.3359, f1: 0.3448	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5620
global_step: 20841, epoch: 122, loss: 0.404991
global_step: 20842, epoch: 122, loss: 0.410679
global_step: 20843, epoch: 122, loss: 0.415227
global_step: 20844, epoch: 122, loss: 0.444235
global_step: 20845, epoch: 122, loss: 0.392998
global_step: 20846, epoch: 122, loss: 0.347542
global_step: 20847, epoch: 122, loss: 0.315635
global_step: 20848, epoch: 122, loss: 0.390957
global_step: 20849, epoch: 122, loss: 0.398459
global_step: 20850, epoch: 122, loss: 0.335262
global_step: 20851, epoch: 122, loss: 0.439133
global_step: 20852, epoch: 122, loss: 0.410419
global_step: 20853, epoch: 122, loss: 0.394941
global_step: 20854, epoch: 122, loss: 0.399092
global_step: 20855, epoch: 122, loss: 0.363794
global_step: 20856, epoch: 122, loss: 0.334804
global_step: 20857, epoch: 122, loss: 0.306967
global_step: 20858, epoch: 122, loss: 0.414344
global_step: 20859, epoch: 122, loss: 0.436195
global_step: 20860, epoch: 122, loss: 0.495424
global_step: 20861, epoch: 122, loss: 0.369532
global_step: 20862, epoch: 122, loss: 0.437418
global_step: 20863, epoch: 122, loss: 0.392763
global_step: 20864, epoch: 122, loss: 0.378628
global_step: 20865, epoch: 122, loss: 0.449847
global_step: 20866, epoch: 122, loss: 0.437332
global_step: 20867, epoch: 122, loss: 0.497507
global_step: 20868, epoch: 122, loss: 0.433641
global_step: 20869, epoch: 122, loss: 0.393095
global_step: 20870, epoch: 122, loss: 0.320576
global_step: 20871, epoch: 122, loss: 0.310129
global_step: 20872, epoch: 122, loss: 0.432534
global_step: 20873, epoch: 122, loss: 0.384115
global_step: 20874, epoch: 122, loss: 0.410139
global_step: 20875, epoch: 122, loss: 0.391484
global_step: 20876, epoch: 122, loss: 0.433776
global_step: 20877, epoch: 122, loss: 0.471406
global_step: 20878, epoch: 122, loss: 0.440315
global_step: 20879, epoch: 122, loss: 0.446840
global_step: 20880, epoch: 122, loss: 1.464753
epoch: 122
train	acc: 0.9337	macro: p 0.9337, r 0.8525, f1: 0.8824	micro: p 0.9337, r 0.9337, f1 0.9337	weighted_f1:0.9316
dev	acc: 0.5672	macro: p 0.4271, r 0.3571, f1: 0.3678	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5323
test	acc: 0.6004	macro: p 0.4025, r 0.3435, f1: 0.3555	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5690
global_step: 20881, epoch: 123, loss: 0.414209
global_step: 20882, epoch: 123, loss: 0.362564
global_step: 20883, epoch: 123, loss: 0.379667
global_step: 20884, epoch: 123, loss: 0.320714
global_step: 20885, epoch: 123, loss: 0.408698
global_step: 20886, epoch: 123, loss: 0.423072
global_step: 20887, epoch: 123, loss: 0.409475
global_step: 20888, epoch: 123, loss: 0.457992
global_step: 20889, epoch: 123, loss: 0.457150
global_step: 20890, epoch: 123, loss: 0.388988
global_step: 20891, epoch: 123, loss: 0.498948
global_step: 20892, epoch: 123, loss: 0.376396
global_step: 20893, epoch: 123, loss: 0.349618
global_step: 20894, epoch: 123, loss: 0.398304
global_step: 20895, epoch: 123, loss: 0.377049
global_step: 20896, epoch: 123, loss: 0.427179
global_step: 20897, epoch: 123, loss: 0.300849
global_step: 20898, epoch: 123, loss: 0.301776
global_step: 20899, epoch: 123, loss: 0.413011
global_step: 20900, epoch: 123, loss: 0.396072
global_step: 20901, epoch: 123, loss: 0.402572
global_step: 20902, epoch: 123, loss: 0.382164
global_step: 20903, epoch: 123, loss: 0.379917
global_step: 20904, epoch: 123, loss: 0.464965
global_step: 20905, epoch: 123, loss: 0.417817
global_step: 20906, epoch: 123, loss: 0.397485
global_step: 20907, epoch: 123, loss: 0.365982
global_step: 20908, epoch: 123, loss: 0.340551
global_step: 20909, epoch: 123, loss: 0.362910
global_step: 20910, epoch: 123, loss: 0.416609
global_step: 20911, epoch: 123, loss: 0.481841
global_step: 20912, epoch: 123, loss: 0.376386
global_step: 20913, epoch: 123, loss: 0.504198
global_step: 20914, epoch: 123, loss: 0.390124
global_step: 20915, epoch: 123, loss: 0.362579
global_step: 20916, epoch: 123, loss: 0.357760
global_step: 20917, epoch: 123, loss: 0.393302
global_step: 20918, epoch: 123, loss: 0.451113
global_step: 20919, epoch: 123, loss: 0.360426
global_step: 20920, epoch: 123, loss: 0.660342
epoch: 123
train	acc: 0.9184	macro: p 0.9320, r 0.8045, f1: 0.8439	micro: p 0.9184, r 0.9184, f1 0.9184	weighted_f1:0.9138
dev	acc: 0.5717	macro: p 0.5006, r 0.3516, f1: 0.3657	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5269
test	acc: 0.6080	macro: p 0.4118, r 0.3339, f1: 0.3430	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5656
global_step: 20921, epoch: 124, loss: 0.407507
global_step: 20922, epoch: 124, loss: 0.331119
global_step: 20923, epoch: 124, loss: 0.407740
global_step: 20924, epoch: 124, loss: 0.377460
global_step: 20925, epoch: 124, loss: 0.328407
global_step: 20926, epoch: 124, loss: 0.418617
global_step: 20927, epoch: 124, loss: 0.341979
global_step: 20928, epoch: 124, loss: 0.329267
global_step: 20929, epoch: 124, loss: 0.444212
global_step: 20930, epoch: 124, loss: 0.383053
global_step: 20931, epoch: 124, loss: 0.435421
global_step: 20932, epoch: 124, loss: 0.338508
global_step: 20933, epoch: 124, loss: 0.433582
global_step: 20934, epoch: 124, loss: 0.407382
global_step: 20935, epoch: 124, loss: 0.425088
global_step: 20936, epoch: 124, loss: 0.338740
global_step: 20937, epoch: 124, loss: 0.327148
global_step: 20938, epoch: 124, loss: 0.447069
global_step: 20939, epoch: 124, loss: 0.386543
global_step: 20940, epoch: 124, loss: 0.411511
global_step: 20941, epoch: 124, loss: 0.411756
global_step: 20942, epoch: 124, loss: 0.363621
global_step: 20943, epoch: 124, loss: 0.380152
global_step: 20944, epoch: 124, loss: 0.382699
global_step: 20945, epoch: 124, loss: 0.380484
global_step: 20946, epoch: 124, loss: 0.367309
global_step: 20947, epoch: 124, loss: 0.386174
global_step: 20948, epoch: 124, loss: 0.488531
global_step: 20949, epoch: 124, loss: 0.427076
global_step: 20950, epoch: 124, loss: 0.415733
global_step: 20951, epoch: 124, loss: 0.349766
global_step: 20952, epoch: 124, loss: 0.468200
global_step: 20953, epoch: 124, loss: 0.319511
global_step: 20954, epoch: 124, loss: 0.431752
global_step: 20955, epoch: 124, loss: 0.355638
global_step: 20956, epoch: 124, loss: 0.528693
global_step: 20957, epoch: 124, loss: 0.431716
global_step: 20958, epoch: 124, loss: 0.330238
global_step: 20959, epoch: 124, loss: 0.356191
global_step: 20960, epoch: 124, loss: 0.308525
epoch: 124
train	acc: 0.9244	macro: p 0.9323, r 0.8203, f1: 0.8543	micro: p 0.9244, r 0.9244, f1 0.9244	weighted_f1:0.9204
dev	acc: 0.5618	macro: p 0.4525, r 0.3496, f1: 0.3574	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5189
test	acc: 0.5969	macro: p 0.4124, r 0.3366, f1: 0.3430	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5581
global_step: 20961, epoch: 125, loss: 0.370366
global_step: 20962, epoch: 125, loss: 0.380583
global_step: 20963, epoch: 125, loss: 0.419943
global_step: 20964, epoch: 125, loss: 0.428878
global_step: 20965, epoch: 125, loss: 0.317644
global_step: 20966, epoch: 125, loss: 0.424044
global_step: 20967, epoch: 125, loss: 0.363468
global_step: 20968, epoch: 125, loss: 0.369776
global_step: 20969, epoch: 125, loss: 0.408821
global_step: 20970, epoch: 125, loss: 0.337920
global_step: 20971, epoch: 125, loss: 0.369378
global_step: 20972, epoch: 125, loss: 0.399901
global_step: 20973, epoch: 125, loss: 0.378778
global_step: 20974, epoch: 125, loss: 0.382067
global_step: 20975, epoch: 125, loss: 0.440354
global_step: 20976, epoch: 125, loss: 0.338810
global_step: 20977, epoch: 125, loss: 0.375283
global_step: 20978, epoch: 125, loss: 0.423290
global_step: 20979, epoch: 125, loss: 0.329123
global_step: 20980, epoch: 125, loss: 0.320658
global_step: 20981, epoch: 125, loss: 0.403792
global_step: 20982, epoch: 125, loss: 0.370592
global_step: 20983, epoch: 125, loss: 0.489199
global_step: 20984, epoch: 125, loss: 0.444223
global_step: 20985, epoch: 125, loss: 0.396353
global_step: 20986, epoch: 125, loss: 0.327363
global_step: 20987, epoch: 125, loss: 0.468983
global_step: 20988, epoch: 125, loss: 0.321701
global_step: 20989, epoch: 125, loss: 0.376401
global_step: 20990, epoch: 125, loss: 0.443174
global_step: 20991, epoch: 125, loss: 0.348604
global_step: 20992, epoch: 125, loss: 0.383693
global_step: 20993, epoch: 125, loss: 0.404835
global_step: 20994, epoch: 125, loss: 0.341233
global_step: 20995, epoch: 125, loss: 0.382743
global_step: 20996, epoch: 125, loss: 0.329532
global_step: 20997, epoch: 125, loss: 0.416879
global_step: 20998, epoch: 125, loss: 0.345840
global_step: 20999, epoch: 125, loss: 0.454604
global_step: 21000, epoch: 125, loss: 0.192721
epoch: 125
train	acc: 0.9308	macro: p 0.9274, r 0.8414, f1: 0.8686	micro: p 0.9308, r 0.9308, f1 0.9308	weighted_f1:0.9281
dev	acc: 0.5546	macro: p 0.4225, r 0.3558, f1: 0.3621	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5226
test	acc: 0.5962	macro: p 0.3959, r 0.3497, f1: 0.3558	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5685
global_step: 21001, epoch: 126, loss: 0.414604
global_step: 21002, epoch: 126, loss: 0.368352
global_step: 21003, epoch: 126, loss: 0.368634
global_step: 21004, epoch: 126, loss: 0.404601
global_step: 21005, epoch: 126, loss: 0.359901
global_step: 21006, epoch: 126, loss: 0.470821
global_step: 21007, epoch: 126, loss: 0.324440
global_step: 21008, epoch: 126, loss: 0.457062
global_step: 21009, epoch: 126, loss: 0.445283
global_step: 21010, epoch: 126, loss: 0.349273
global_step: 21011, epoch: 126, loss: 0.394727
global_step: 21012, epoch: 126, loss: 0.349253
global_step: 21013, epoch: 126, loss: 0.417400
global_step: 21014, epoch: 126, loss: 0.379213
global_step: 21015, epoch: 126, loss: 0.339729
global_step: 21016, epoch: 126, loss: 0.370308
global_step: 21017, epoch: 126, loss: 0.423113
global_step: 21018, epoch: 126, loss: 0.470571
global_step: 21019, epoch: 126, loss: 0.350640
global_step: 21020, epoch: 126, loss: 0.447595
global_step: 21021, epoch: 126, loss: 0.412217
global_step: 21022, epoch: 126, loss: 0.332479
global_step: 21023, epoch: 126, loss: 0.377949
global_step: 21024, epoch: 126, loss: 0.371186
global_step: 21025, epoch: 126, loss: 0.455459
global_step: 21026, epoch: 126, loss: 0.332656
global_step: 21027, epoch: 126, loss: 0.345175
global_step: 21028, epoch: 126, loss: 0.436773
global_step: 21029, epoch: 126, loss: 0.363622
global_step: 21030, epoch: 126, loss: 0.395221
global_step: 21031, epoch: 126, loss: 0.418597
global_step: 21032, epoch: 126, loss: 0.380380
global_step: 21033, epoch: 126, loss: 0.398702
global_step: 21034, epoch: 126, loss: 0.484215
global_step: 21035, epoch: 126, loss: 0.399978
global_step: 21036, epoch: 126, loss: 0.343187
global_step: 21037, epoch: 126, loss: 0.413816
global_step: 21038, epoch: 126, loss: 0.410579
global_step: 21039, epoch: 126, loss: 0.386833
global_step: 21040, epoch: 126, loss: 0.043913
epoch: 126
train	acc: 0.9322	macro: p 0.9373, r 0.8508, f1: 0.8831	micro: p 0.9322, r 0.9322, f1 0.9322	weighted_f1:0.9301
dev	acc: 0.5744	macro: p 0.4478, r 0.3577, f1: 0.3721	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5356
test	acc: 0.6019	macro: p 0.4051, r 0.3389, f1: 0.3525	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5666
global_step: 21041, epoch: 127, loss: 0.311809
global_step: 21042, epoch: 127, loss: 0.424025
global_step: 21043, epoch: 127, loss: 0.439816
global_step: 21044, epoch: 127, loss: 0.338196
global_step: 21045, epoch: 127, loss: 0.447200
global_step: 21046, epoch: 127, loss: 0.337403
global_step: 21047, epoch: 127, loss: 0.406557
global_step: 21048, epoch: 127, loss: 0.319152
global_step: 21049, epoch: 127, loss: 0.437913
global_step: 21050, epoch: 127, loss: 0.335374
global_step: 21051, epoch: 127, loss: 0.461211
global_step: 21052, epoch: 127, loss: 0.398489
global_step: 21053, epoch: 127, loss: 0.421153
global_step: 21054, epoch: 127, loss: 0.377136
global_step: 21055, epoch: 127, loss: 0.395894
global_step: 21056, epoch: 127, loss: 0.421321
global_step: 21057, epoch: 127, loss: 0.334100
global_step: 21058, epoch: 127, loss: 0.395706
global_step: 21059, epoch: 127, loss: 0.316557
global_step: 21060, epoch: 127, loss: 0.310898
global_step: 21061, epoch: 127, loss: 0.427402
global_step: 21062, epoch: 127, loss: 0.410676
global_step: 21063, epoch: 127, loss: 0.368776
global_step: 21064, epoch: 127, loss: 0.441079
global_step: 21065, epoch: 127, loss: 0.411262
global_step: 21066, epoch: 127, loss: 0.404642
global_step: 21067, epoch: 127, loss: 0.388664
global_step: 21068, epoch: 127, loss: 0.415739
global_step: 21069, epoch: 127, loss: 0.337652
global_step: 21070, epoch: 127, loss: 0.375598
global_step: 21071, epoch: 127, loss: 0.331387
global_step: 21072, epoch: 127, loss: 0.321428
global_step: 21073, epoch: 127, loss: 0.351972
global_step: 21074, epoch: 127, loss: 0.364169
global_step: 21075, epoch: 127, loss: 0.405876
global_step: 21076, epoch: 127, loss: 0.425807
global_step: 21077, epoch: 127, loss: 0.374320
global_step: 21078, epoch: 127, loss: 0.418632
global_step: 21079, epoch: 127, loss: 0.423069
global_step: 21080, epoch: 127, loss: 0.425278
epoch: 127
train	acc: 0.9381	macro: p 0.9330, r 0.8602, f1: 0.8838	micro: p 0.9381, r 0.9381, f1 0.9381	weighted_f1:0.9361
dev	acc: 0.5663	macro: p 0.4389, r 0.3833, f1: 0.3901	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5421
test	acc: 0.5847	macro: p 0.3858, r 0.3565, f1: 0.3603	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5651
global_step: 21081, epoch: 128, loss: 0.476995
global_step: 21082, epoch: 128, loss: 0.402171
global_step: 21083, epoch: 128, loss: 0.357524
global_step: 21084, epoch: 128, loss: 0.415937
global_step: 21085, epoch: 128, loss: 0.380226
global_step: 21086, epoch: 128, loss: 0.424994
global_step: 21087, epoch: 128, loss: 0.353688
global_step: 21088, epoch: 128, loss: 0.379708
global_step: 21089, epoch: 128, loss: 0.343943
global_step: 21090, epoch: 128, loss: 0.309052
global_step: 21091, epoch: 128, loss: 0.297940
global_step: 21092, epoch: 128, loss: 0.478338
global_step: 21093, epoch: 128, loss: 0.395338
global_step: 21094, epoch: 128, loss: 0.347578
global_step: 21095, epoch: 128, loss: 0.425916
global_step: 21096, epoch: 128, loss: 0.413967
global_step: 21097, epoch: 128, loss: 0.377701
global_step: 21098, epoch: 128, loss: 0.463957
global_step: 21099, epoch: 128, loss: 0.442086
global_step: 21100, epoch: 128, loss: 0.343275
global_step: 21101, epoch: 128, loss: 0.347549
global_step: 21102, epoch: 128, loss: 0.344301
global_step: 21103, epoch: 128, loss: 0.401658
global_step: 21104, epoch: 128, loss: 0.340416
global_step: 21105, epoch: 128, loss: 0.335753
global_step: 21106, epoch: 128, loss: 0.351528
global_step: 21107, epoch: 128, loss: 0.565719
global_step: 21108, epoch: 128, loss: 0.321205
global_step: 21109, epoch: 128, loss: 0.461097
global_step: 21110, epoch: 128, loss: 0.385894
global_step: 21111, epoch: 128, loss: 0.293577
global_step: 21112, epoch: 128, loss: 0.480627
global_step: 21113, epoch: 128, loss: 0.334200
global_step: 21114, epoch: 128, loss: 0.401170
global_step: 21115, epoch: 128, loss: 0.399126
global_step: 21116, epoch: 128, loss: 0.281655
global_step: 21117, epoch: 128, loss: 0.363361
global_step: 21118, epoch: 128, loss: 0.371902
global_step: 21119, epoch: 128, loss: 0.311652
global_step: 21120, epoch: 128, loss: 0.264620
epoch: 128
train	acc: 0.9362	macro: p 0.9314, r 0.8547, f1: 0.8811	micro: p 0.9362, r 0.9362, f1 0.9362	weighted_f1:0.9342
dev	acc: 0.5663	macro: p 0.4568, r 0.3786, f1: 0.3862	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5402
test	acc: 0.5931	macro: p 0.3827, r 0.3546, f1: 0.3544	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5703
global_step: 21121, epoch: 129, loss: 0.302799
global_step: 21122, epoch: 129, loss: 0.412691
global_step: 21123, epoch: 129, loss: 0.372765
global_step: 21124, epoch: 129, loss: 0.366434
global_step: 21125, epoch: 129, loss: 0.334619
global_step: 21126, epoch: 129, loss: 0.388815
global_step: 21127, epoch: 129, loss: 0.448240
global_step: 21128, epoch: 129, loss: 0.407079
global_step: 21129, epoch: 129, loss: 0.434680
global_step: 21130, epoch: 129, loss: 0.320832
global_step: 21131, epoch: 129, loss: 0.364767
global_step: 21132, epoch: 129, loss: 0.366860
global_step: 21133, epoch: 129, loss: 0.386029
global_step: 21134, epoch: 129, loss: 0.395357
global_step: 21135, epoch: 129, loss: 0.346873
global_step: 21136, epoch: 129, loss: 0.478930
global_step: 21137, epoch: 129, loss: 0.306676
global_step: 21138, epoch: 129, loss: 0.482400
global_step: 21139, epoch: 129, loss: 0.300724
global_step: 21140, epoch: 129, loss: 0.367851
global_step: 21141, epoch: 129, loss: 0.372346
global_step: 21142, epoch: 129, loss: 0.356308
global_step: 21143, epoch: 129, loss: 0.381738
global_step: 21144, epoch: 129, loss: 0.386040
global_step: 21145, epoch: 129, loss: 0.376275
global_step: 21146, epoch: 129, loss: 0.368710
global_step: 21147, epoch: 129, loss: 0.373206
global_step: 21148, epoch: 129, loss: 0.414818
global_step: 21149, epoch: 129, loss: 0.399443
global_step: 21150, epoch: 129, loss: 0.492068
global_step: 21151, epoch: 129, loss: 0.331714
global_step: 21152, epoch: 129, loss: 0.421123
global_step: 21153, epoch: 129, loss: 0.438898
global_step: 21154, epoch: 129, loss: 0.378223
global_step: 21155, epoch: 129, loss: 0.472595
global_step: 21156, epoch: 129, loss: 0.420166
global_step: 21157, epoch: 129, loss: 0.310539
global_step: 21158, epoch: 129, loss: 0.378785
global_step: 21159, epoch: 129, loss: 0.386752
global_step: 21160, epoch: 129, loss: 0.177130
epoch: 129
train	acc: 0.9360	macro: p 0.9315, r 0.8510, f1: 0.8786	micro: p 0.9360, r 0.9360, f1 0.9360	weighted_f1:0.9339
dev	acc: 0.5753	macro: p 0.4830, r 0.3838, f1: 0.3945	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5519
test	acc: 0.5950	macro: p 0.3882, r 0.3555, f1: 0.3601	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5744
New best model!
global_step: 21161, epoch: 130, loss: 0.409744
global_step: 21162, epoch: 130, loss: 0.411847
global_step: 21163, epoch: 130, loss: 0.421135
global_step: 21164, epoch: 130, loss: 0.318788
global_step: 21165, epoch: 130, loss: 0.421418
global_step: 21166, epoch: 130, loss: 0.346963
global_step: 21167, epoch: 130, loss: 0.448927
global_step: 21168, epoch: 130, loss: 0.294996
global_step: 21169, epoch: 130, loss: 0.405535
global_step: 21170, epoch: 130, loss: 0.335484
global_step: 21171, epoch: 130, loss: 0.364791
global_step: 21172, epoch: 130, loss: 0.409570
global_step: 21173, epoch: 130, loss: 0.407753
global_step: 21174, epoch: 130, loss: 0.386628
global_step: 21175, epoch: 130, loss: 0.414895
global_step: 21176, epoch: 130, loss: 0.308345
global_step: 21177, epoch: 130, loss: 0.407051
global_step: 21178, epoch: 130, loss: 0.376325
global_step: 21179, epoch: 130, loss: 0.342777
global_step: 21180, epoch: 130, loss: 0.375883
global_step: 21181, epoch: 130, loss: 0.426082
global_step: 21182, epoch: 130, loss: 0.419944
global_step: 21183, epoch: 130, loss: 0.245512
global_step: 21184, epoch: 130, loss: 0.406990
global_step: 21185, epoch: 130, loss: 0.427209
global_step: 21186, epoch: 130, loss: 0.369015
global_step: 21187, epoch: 130, loss: 0.354304
global_step: 21188, epoch: 130, loss: 0.404119
global_step: 21189, epoch: 130, loss: 0.392373
global_step: 21190, epoch: 130, loss: 0.368618
global_step: 21191, epoch: 130, loss: 0.359202
global_step: 21192, epoch: 130, loss: 0.418847
global_step: 21193, epoch: 130, loss: 0.419497
global_step: 21194, epoch: 130, loss: 0.375471
global_step: 21195, epoch: 130, loss: 0.371880
global_step: 21196, epoch: 130, loss: 0.415137
global_step: 21197, epoch: 130, loss: 0.365420
global_step: 21198, epoch: 130, loss: 0.317502
global_step: 21199, epoch: 130, loss: 0.397177
global_step: 21200, epoch: 130, loss: 0.095400
epoch: 130
train	acc: 0.9395	macro: p 0.9354, r 0.8613, f1: 0.8861	micro: p 0.9395, r 0.9395, f1 0.9395	weighted_f1:0.9375
dev	acc: 0.5690	macro: p 0.4376, r 0.3756, f1: 0.3843	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5437
test	acc: 0.5939	macro: p 0.3904, r 0.3557, f1: 0.3624	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5726
global_step: 21201, epoch: 131, loss: 0.438199
global_step: 21202, epoch: 131, loss: 0.372975
global_step: 21203, epoch: 131, loss: 0.391064
global_step: 21204, epoch: 131, loss: 0.446742
global_step: 21205, epoch: 131, loss: 0.425787
global_step: 21206, epoch: 131, loss: 0.374888
global_step: 21207, epoch: 131, loss: 0.348897
global_step: 21208, epoch: 131, loss: 0.364467
global_step: 21209, epoch: 131, loss: 0.357085
global_step: 21210, epoch: 131, loss: 0.290037
global_step: 21211, epoch: 131, loss: 0.264853
global_step: 21212, epoch: 131, loss: 0.362500
global_step: 21213, epoch: 131, loss: 0.389950
global_step: 21214, epoch: 131, loss: 0.345721
global_step: 21215, epoch: 131, loss: 0.312986
global_step: 21216, epoch: 131, loss: 0.277180
global_step: 21217, epoch: 131, loss: 0.414854
global_step: 21218, epoch: 131, loss: 0.328270
global_step: 21219, epoch: 131, loss: 0.486864
global_step: 21220, epoch: 131, loss: 0.381206
global_step: 21221, epoch: 131, loss: 0.390676
global_step: 21222, epoch: 131, loss: 0.402768
global_step: 21223, epoch: 131, loss: 0.382539
global_step: 21224, epoch: 131, loss: 0.350518
global_step: 21225, epoch: 131, loss: 0.312429
global_step: 21226, epoch: 131, loss: 0.417216
global_step: 21227, epoch: 131, loss: 0.373724
global_step: 21228, epoch: 131, loss: 0.451002
global_step: 21229, epoch: 131, loss: 0.376002
global_step: 21230, epoch: 131, loss: 0.328016
global_step: 21231, epoch: 131, loss: 0.422291
global_step: 21232, epoch: 131, loss: 0.387287
global_step: 21233, epoch: 131, loss: 0.407284
global_step: 21234, epoch: 131, loss: 0.409807
global_step: 21235, epoch: 131, loss: 0.367359
global_step: 21236, epoch: 131, loss: 0.423336
global_step: 21237, epoch: 131, loss: 0.406600
global_step: 21238, epoch: 131, loss: 0.375820
global_step: 21239, epoch: 131, loss: 0.387659
global_step: 21240, epoch: 131, loss: 0.194121
epoch: 131
train	acc: 0.9335	macro: p 0.9385, r 0.8504, f1: 0.8830	micro: p 0.9335, r 0.9335, f1 0.9335	weighted_f1:0.9313
dev	acc: 0.5627	macro: p 0.4605, r 0.3546, f1: 0.3704	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5251
test	acc: 0.6027	macro: p 0.4100, r 0.3383, f1: 0.3523	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5643
global_step: 21241, epoch: 132, loss: 0.366149
global_step: 21242, epoch: 132, loss: 0.337417
global_step: 21243, epoch: 132, loss: 0.382994
global_step: 21244, epoch: 132, loss: 0.383367
global_step: 21245, epoch: 132, loss: 0.474359
global_step: 21246, epoch: 132, loss: 0.439633
global_step: 21247, epoch: 132, loss: 0.415420
global_step: 21248, epoch: 132, loss: 0.395452
global_step: 21249, epoch: 132, loss: 0.412892
global_step: 21250, epoch: 132, loss: 0.349988
global_step: 21251, epoch: 132, loss: 0.452057
global_step: 21252, epoch: 132, loss: 0.316098
global_step: 21253, epoch: 132, loss: 0.310678
global_step: 21254, epoch: 132, loss: 0.408377
global_step: 21255, epoch: 132, loss: 0.363818
global_step: 21256, epoch: 132, loss: 0.375662
global_step: 21257, epoch: 132, loss: 0.414623
global_step: 21258, epoch: 132, loss: 0.363311
global_step: 21259, epoch: 132, loss: 0.314008
global_step: 21260, epoch: 132, loss: 0.365126
global_step: 21261, epoch: 132, loss: 0.381419
global_step: 21262, epoch: 132, loss: 0.358285
global_step: 21263, epoch: 132, loss: 0.350143
global_step: 21264, epoch: 132, loss: 0.314352
global_step: 21265, epoch: 132, loss: 0.368988
global_step: 21266, epoch: 132, loss: 0.303410
global_step: 21267, epoch: 132, loss: 0.322221
global_step: 21268, epoch: 132, loss: 0.342521
global_step: 21269, epoch: 132, loss: 0.379875
global_step: 21270, epoch: 132, loss: 0.371726
global_step: 21271, epoch: 132, loss: 0.343852
global_step: 21272, epoch: 132, loss: 0.419839
global_step: 21273, epoch: 132, loss: 0.371052
global_step: 21274, epoch: 132, loss: 0.465733
global_step: 21275, epoch: 132, loss: 0.386030
global_step: 21276, epoch: 132, loss: 0.339704
global_step: 21277, epoch: 132, loss: 0.446750
global_step: 21278, epoch: 132, loss: 0.275668
global_step: 21279, epoch: 132, loss: 0.425548
global_step: 21280, epoch: 132, loss: 0.229168
epoch: 132
train	acc: 0.9397	macro: p 0.9398, r 0.8697, f1: 0.8960	micro: p 0.9397, r 0.9397, f1 0.9397	weighted_f1:0.9383
dev	acc: 0.5627	macro: p 0.4609, r 0.3589, f1: 0.3649	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5270
test	acc: 0.5958	macro: p 0.3969, r 0.3524, f1: 0.3577	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5660
global_step: 21281, epoch: 133, loss: 0.325070
global_step: 21282, epoch: 133, loss: 0.336605
global_step: 21283, epoch: 133, loss: 0.362278
global_step: 21284, epoch: 133, loss: 0.413263
global_step: 21285, epoch: 133, loss: 0.331198
global_step: 21286, epoch: 133, loss: 0.317673
global_step: 21287, epoch: 133, loss: 0.323673
global_step: 21288, epoch: 133, loss: 0.379620
global_step: 21289, epoch: 133, loss: 0.332059
global_step: 21290, epoch: 133, loss: 0.406033
global_step: 21291, epoch: 133, loss: 0.340951
global_step: 21292, epoch: 133, loss: 0.355623
global_step: 21293, epoch: 133, loss: 0.408741
global_step: 21294, epoch: 133, loss: 0.354981
global_step: 21295, epoch: 133, loss: 0.392696
global_step: 21296, epoch: 133, loss: 0.403250
global_step: 21297, epoch: 133, loss: 0.365646
global_step: 21298, epoch: 133, loss: 0.427225
global_step: 21299, epoch: 133, loss: 0.447102
global_step: 21300, epoch: 133, loss: 0.333262
global_step: 21301, epoch: 133, loss: 0.304631
global_step: 21302, epoch: 133, loss: 0.407210
global_step: 21303, epoch: 133, loss: 0.272302
global_step: 21304, epoch: 133, loss: 0.307365
global_step: 21305, epoch: 133, loss: 0.357972
global_step: 21306, epoch: 133, loss: 0.337190
global_step: 21307, epoch: 133, loss: 0.400621
global_step: 21308, epoch: 133, loss: 0.430052
global_step: 21309, epoch: 133, loss: 0.296730
global_step: 21310, epoch: 133, loss: 0.285880
global_step: 21311, epoch: 133, loss: 0.362897
global_step: 21312, epoch: 133, loss: 0.339267
global_step: 21313, epoch: 133, loss: 0.400340
global_step: 21314, epoch: 133, loss: 0.385306
global_step: 21315, epoch: 133, loss: 0.425917
global_step: 21316, epoch: 133, loss: 0.417919
global_step: 21317, epoch: 133, loss: 0.409753
global_step: 21318, epoch: 133, loss: 0.435453
global_step: 21319, epoch: 133, loss: 0.354910
global_step: 21320, epoch: 133, loss: 0.856610
epoch: 133
train	acc: 0.9381	macro: p 0.9439, r 0.8666, f1: 0.8971	micro: p 0.9381, r 0.9381, f1 0.9381	weighted_f1:0.9366
dev	acc: 0.5636	macro: p 0.4447, r 0.3608, f1: 0.3709	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5296
test	acc: 0.5923	macro: p 0.3941, r 0.3410, f1: 0.3483	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5604
global_step: 21321, epoch: 134, loss: 0.422149
global_step: 21322, epoch: 134, loss: 0.372247
global_step: 21323, epoch: 134, loss: 0.410224
global_step: 21324, epoch: 134, loss: 0.363222
global_step: 21325, epoch: 134, loss: 0.379954
global_step: 21326, epoch: 134, loss: 0.354583
global_step: 21327, epoch: 134, loss: 0.373055
global_step: 21328, epoch: 134, loss: 0.342988
global_step: 21329, epoch: 134, loss: 0.333863
global_step: 21330, epoch: 134, loss: 0.320929
global_step: 21331, epoch: 134, loss: 0.429481
global_step: 21332, epoch: 134, loss: 0.287664
global_step: 21333, epoch: 134, loss: 0.409586
global_step: 21334, epoch: 134, loss: 0.377739
global_step: 21335, epoch: 134, loss: 0.395067
global_step: 21336, epoch: 134, loss: 0.354457
global_step: 21337, epoch: 134, loss: 0.344121
global_step: 21338, epoch: 134, loss: 0.356232
global_step: 21339, epoch: 134, loss: 0.358462
global_step: 21340, epoch: 134, loss: 0.373898
global_step: 21341, epoch: 134, loss: 0.307088
global_step: 21342, epoch: 134, loss: 0.347444
global_step: 21343, epoch: 134, loss: 0.380365
global_step: 21344, epoch: 134, loss: 0.316299
global_step: 21345, epoch: 134, loss: 0.347363
global_step: 21346, epoch: 134, loss: 0.407034
global_step: 21347, epoch: 134, loss: 0.371934
global_step: 21348, epoch: 134, loss: 0.285805
global_step: 21349, epoch: 134, loss: 0.487141
global_step: 21350, epoch: 134, loss: 0.299733
global_step: 21351, epoch: 134, loss: 0.371591
global_step: 21352, epoch: 134, loss: 0.389076
global_step: 21353, epoch: 134, loss: 0.299756
global_step: 21354, epoch: 134, loss: 0.340972
global_step: 21355, epoch: 134, loss: 0.448836
global_step: 21356, epoch: 134, loss: 0.290164
global_step: 21357, epoch: 134, loss: 0.421555
global_step: 21358, epoch: 134, loss: 0.334860
global_step: 21359, epoch: 134, loss: 0.419090
global_step: 21360, epoch: 134, loss: 0.072061
epoch: 134
train	acc: 0.9412	macro: p 0.9405, r 0.8727, f1: 0.8993	micro: p 0.9412, r 0.9412, f1 0.9412	weighted_f1:0.9399
dev	acc: 0.5681	macro: p 0.4489, r 0.3609, f1: 0.3755	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5367
test	acc: 0.6008	macro: p 0.4067, r 0.3465, f1: 0.3564	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5717
global_step: 21361, epoch: 135, loss: 0.343421
global_step: 21362, epoch: 135, loss: 0.416179
global_step: 21363, epoch: 135, loss: 0.353766
global_step: 21364, epoch: 135, loss: 0.356571
global_step: 21365, epoch: 135, loss: 0.316283
global_step: 21366, epoch: 135, loss: 0.415158
global_step: 21367, epoch: 135, loss: 0.359977
global_step: 21368, epoch: 135, loss: 0.336622
global_step: 21369, epoch: 135, loss: 0.356209
global_step: 21370, epoch: 135, loss: 0.340509
global_step: 21371, epoch: 135, loss: 0.370954
global_step: 21372, epoch: 135, loss: 0.463601
global_step: 21373, epoch: 135, loss: 0.537415
global_step: 21374, epoch: 135, loss: 0.376809
global_step: 21375, epoch: 135, loss: 0.355794
global_step: 21376, epoch: 135, loss: 0.350984
global_step: 21377, epoch: 135, loss: 0.373234
global_step: 21378, epoch: 135, loss: 0.289094
global_step: 21379, epoch: 135, loss: 0.351004
global_step: 21380, epoch: 135, loss: 0.328931
global_step: 21381, epoch: 135, loss: 0.391049
global_step: 21382, epoch: 135, loss: 0.372344
global_step: 21383, epoch: 135, loss: 0.295372
global_step: 21384, epoch: 135, loss: 0.335159
global_step: 21385, epoch: 135, loss: 0.381611
global_step: 21386, epoch: 135, loss: 0.277967
global_step: 21387, epoch: 135, loss: 0.306646
global_step: 21388, epoch: 135, loss: 0.262796
global_step: 21389, epoch: 135, loss: 0.385985
global_step: 21390, epoch: 135, loss: 0.379154
global_step: 21391, epoch: 135, loss: 0.373460
global_step: 21392, epoch: 135, loss: 0.331467
global_step: 21393, epoch: 135, loss: 0.338373
global_step: 21394, epoch: 135, loss: 0.310086
global_step: 21395, epoch: 135, loss: 0.300098
global_step: 21396, epoch: 135, loss: 0.367706
global_step: 21397, epoch: 135, loss: 0.278753
global_step: 21398, epoch: 135, loss: 0.371443
global_step: 21399, epoch: 135, loss: 0.343255
global_step: 21400, epoch: 135, loss: 0.144436
epoch: 135
train	acc: 0.9459	macro: p 0.9454, r 0.8861, f1: 0.9101	micro: p 0.9459, r 0.9459, f1 0.9459	weighted_f1:0.9450
dev	acc: 0.5618	macro: p 0.4190, r 0.3605, f1: 0.3692	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5299
test	acc: 0.5958	macro: p 0.3953, r 0.3495, f1: 0.3569	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5684
global_step: 21401, epoch: 136, loss: 0.361790
global_step: 21402, epoch: 136, loss: 0.369538
global_step: 21403, epoch: 136, loss: 0.348344
global_step: 21404, epoch: 136, loss: 0.346387
global_step: 21405, epoch: 136, loss: 0.307522
global_step: 21406, epoch: 136, loss: 0.332121
global_step: 21407, epoch: 136, loss: 0.311693
global_step: 21408, epoch: 136, loss: 0.402236
global_step: 21409, epoch: 136, loss: 0.239236
global_step: 21410, epoch: 136, loss: 0.349304
global_step: 21411, epoch: 136, loss: 0.309633
global_step: 21412, epoch: 136, loss: 0.383892
global_step: 21413, epoch: 136, loss: 0.364587
global_step: 21414, epoch: 136, loss: 0.276541
global_step: 21415, epoch: 136, loss: 0.361878
global_step: 21416, epoch: 136, loss: 0.412105
global_step: 21417, epoch: 136, loss: 0.337527
global_step: 21418, epoch: 136, loss: 0.466151
global_step: 21419, epoch: 136, loss: 0.269491
global_step: 21420, epoch: 136, loss: 0.412363
global_step: 21421, epoch: 136, loss: 0.397561
global_step: 21422, epoch: 136, loss: 0.338350
global_step: 21423, epoch: 136, loss: 0.385954
global_step: 21424, epoch: 136, loss: 0.333912
global_step: 21425, epoch: 136, loss: 0.386721
global_step: 21426, epoch: 136, loss: 0.342151
global_step: 21427, epoch: 136, loss: 0.359497
global_step: 21428, epoch: 136, loss: 0.341257
global_step: 21429, epoch: 136, loss: 0.383188
global_step: 21430, epoch: 136, loss: 0.415140
global_step: 21431, epoch: 136, loss: 0.371228
global_step: 21432, epoch: 136, loss: 0.423824
global_step: 21433, epoch: 136, loss: 0.341918
global_step: 21434, epoch: 136, loss: 0.336782
global_step: 21435, epoch: 136, loss: 0.362430
global_step: 21436, epoch: 136, loss: 0.373960
global_step: 21437, epoch: 136, loss: 0.431905
global_step: 21438, epoch: 136, loss: 0.308855
global_step: 21439, epoch: 136, loss: 0.386956
global_step: 21440, epoch: 136, loss: 0.071968
epoch: 136
train	acc: 0.9411	macro: p 0.9406, r 0.8718, f1: 0.8965	micro: p 0.9411, r 0.9411, f1 0.9411	weighted_f1:0.9396
dev	acc: 0.5645	macro: p 0.4582, r 0.3784, f1: 0.3895	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5370
test	acc: 0.5920	macro: p 0.3804, r 0.3481, f1: 0.3534	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5650
global_step: 21441, epoch: 137, loss: 0.299535
global_step: 21442, epoch: 137, loss: 0.353893
global_step: 21443, epoch: 137, loss: 0.332763
global_step: 21444, epoch: 137, loss: 0.357284
global_step: 21445, epoch: 137, loss: 0.299699
global_step: 21446, epoch: 137, loss: 0.450024
global_step: 21447, epoch: 137, loss: 0.337458
global_step: 21448, epoch: 137, loss: 0.271623
global_step: 21449, epoch: 137, loss: 0.330106
global_step: 21450, epoch: 137, loss: 0.371188
global_step: 21451, epoch: 137, loss: 0.392533
global_step: 21452, epoch: 137, loss: 0.330260
global_step: 21453, epoch: 137, loss: 0.396776
global_step: 21454, epoch: 137, loss: 0.425660
global_step: 21455, epoch: 137, loss: 0.350785
global_step: 21456, epoch: 137, loss: 0.391568
global_step: 21457, epoch: 137, loss: 0.371879
global_step: 21458, epoch: 137, loss: 0.379225
global_step: 21459, epoch: 137, loss: 0.470024
global_step: 21460, epoch: 137, loss: 0.326349
global_step: 21461, epoch: 137, loss: 0.346251
global_step: 21462, epoch: 137, loss: 0.354440
global_step: 21463, epoch: 137, loss: 0.315198
global_step: 21464, epoch: 137, loss: 0.415604
global_step: 21465, epoch: 137, loss: 0.326427
global_step: 21466, epoch: 137, loss: 0.335310
global_step: 21467, epoch: 137, loss: 0.365701
global_step: 21468, epoch: 137, loss: 0.337940
global_step: 21469, epoch: 137, loss: 0.307512
global_step: 21470, epoch: 137, loss: 0.250165
global_step: 21471, epoch: 137, loss: 0.417618
global_step: 21472, epoch: 137, loss: 0.276138
global_step: 21473, epoch: 137, loss: 0.405623
global_step: 21474, epoch: 137, loss: 0.358367
global_step: 21475, epoch: 137, loss: 0.324244
global_step: 21476, epoch: 137, loss: 0.337902
global_step: 21477, epoch: 137, loss: 0.235179
global_step: 21478, epoch: 137, loss: 0.286645
global_step: 21479, epoch: 137, loss: 0.337562
global_step: 21480, epoch: 137, loss: 0.598075
epoch: 137
train	acc: 0.9301	macro: p 0.9458, r 0.8459, f1: 0.8834	micro: p 0.9301, r 0.9301, f1 0.9301	weighted_f1:0.9278
dev	acc: 0.5509	macro: p 0.4545, r 0.3319, f1: 0.3509	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5070
test	acc: 0.5992	macro: p 0.4357, r 0.3267, f1: 0.3476	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5571
global_step: 21481, epoch: 138, loss: 0.369334
global_step: 21482, epoch: 138, loss: 0.353917
global_step: 21483, epoch: 138, loss: 0.343867
global_step: 21484, epoch: 138, loss: 0.275244
global_step: 21485, epoch: 138, loss: 0.376141
global_step: 21486, epoch: 138, loss: 0.377627
global_step: 21487, epoch: 138, loss: 0.280259
global_step: 21488, epoch: 138, loss: 0.356155
global_step: 21489, epoch: 138, loss: 0.431993
global_step: 21490, epoch: 138, loss: 0.286906
global_step: 21491, epoch: 138, loss: 0.336275
global_step: 21492, epoch: 138, loss: 0.303465
global_step: 21493, epoch: 138, loss: 0.304087
global_step: 21494, epoch: 138, loss: 0.280933
global_step: 21495, epoch: 138, loss: 0.393970
global_step: 21496, epoch: 138, loss: 0.392780
global_step: 21497, epoch: 138, loss: 0.324158
global_step: 21498, epoch: 138, loss: 0.327898
global_step: 21499, epoch: 138, loss: 0.335521
global_step: 21500, epoch: 138, loss: 0.334723
global_step: 21501, epoch: 138, loss: 0.344701
global_step: 21502, epoch: 138, loss: 0.330782
global_step: 21503, epoch: 138, loss: 0.396796
global_step: 21504, epoch: 138, loss: 0.363107
global_step: 21505, epoch: 138, loss: 0.451350
global_step: 21506, epoch: 138, loss: 0.358180
global_step: 21507, epoch: 138, loss: 0.322292
global_step: 21508, epoch: 138, loss: 0.367990
global_step: 21509, epoch: 138, loss: 0.303956
global_step: 21510, epoch: 138, loss: 0.346257
global_step: 21511, epoch: 138, loss: 0.424074
global_step: 21512, epoch: 138, loss: 0.348115
global_step: 21513, epoch: 138, loss: 0.286946
global_step: 21514, epoch: 138, loss: 0.385451
global_step: 21515, epoch: 138, loss: 0.367729
global_step: 21516, epoch: 138, loss: 0.440250
global_step: 21517, epoch: 138, loss: 0.358845
global_step: 21518, epoch: 138, loss: 0.292899
global_step: 21519, epoch: 138, loss: 0.367973
global_step: 21520, epoch: 138, loss: 0.468275
epoch: 138
train	acc: 0.9420	macro: p 0.9468, r 0.8816, f1: 0.9096	micro: p 0.9420, r 0.9420, f1 0.9420	weighted_f1:0.9410
dev	acc: 0.5681	macro: p 0.4350, r 0.3556, f1: 0.3702	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5288
test	acc: 0.5996	macro: p 0.4105, r 0.3350, f1: 0.3501	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5615
global_step: 21521, epoch: 139, loss: 0.374696
global_step: 21522, epoch: 139, loss: 0.331098
global_step: 21523, epoch: 139, loss: 0.349121
global_step: 21524, epoch: 139, loss: 0.344082
global_step: 21525, epoch: 139, loss: 0.367198
global_step: 21526, epoch: 139, loss: 0.377624
global_step: 21527, epoch: 139, loss: 0.260708
global_step: 21528, epoch: 139, loss: 0.433494
global_step: 21529, epoch: 139, loss: 0.391551
global_step: 21530, epoch: 139, loss: 0.359273
global_step: 21531, epoch: 139, loss: 0.414067
global_step: 21532, epoch: 139, loss: 0.343312
global_step: 21533, epoch: 139, loss: 0.345981
global_step: 21534, epoch: 139, loss: 0.396841
global_step: 21535, epoch: 139, loss: 0.362189
global_step: 21536, epoch: 139, loss: 0.361944
global_step: 21537, epoch: 139, loss: 0.291161
global_step: 21538, epoch: 139, loss: 0.282401
global_step: 21539, epoch: 139, loss: 0.316270
global_step: 21540, epoch: 139, loss: 0.306055
global_step: 21541, epoch: 139, loss: 0.319092
global_step: 21542, epoch: 139, loss: 0.311317
global_step: 21543, epoch: 139, loss: 0.304593
global_step: 21544, epoch: 139, loss: 0.350684
global_step: 21545, epoch: 139, loss: 0.388127
global_step: 21546, epoch: 139, loss: 0.382698
global_step: 21547, epoch: 139, loss: 0.327900
global_step: 21548, epoch: 139, loss: 0.351214
global_step: 21549, epoch: 139, loss: 0.396812
global_step: 21550, epoch: 139, loss: 0.254646
global_step: 21551, epoch: 139, loss: 0.390453
global_step: 21552, epoch: 139, loss: 0.368559
global_step: 21553, epoch: 139, loss: 0.243199
global_step: 21554, epoch: 139, loss: 0.346006
global_step: 21555, epoch: 139, loss: 0.392255
global_step: 21556, epoch: 139, loss: 0.324454
global_step: 21557, epoch: 139, loss: 0.275410
global_step: 21558, epoch: 139, loss: 0.412127
global_step: 21559, epoch: 139, loss: 0.346939
global_step: 21560, epoch: 139, loss: 1.740029
epoch: 139
train	acc: 0.9459	macro: p 0.9457, r 0.8897, f1: 0.9123	micro: p 0.9459, r 0.9459, f1 0.9459	weighted_f1:0.9451
dev	acc: 0.5591	macro: p 0.4246, r 0.3729, f1: 0.3822	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5343
test	acc: 0.5854	macro: p 0.3766, r 0.3480, f1: 0.3499	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5642
global_step: 21561, epoch: 140, loss: 0.440086
global_step: 21562, epoch: 140, loss: 0.289330
global_step: 21563, epoch: 140, loss: 0.283998
global_step: 21564, epoch: 140, loss: 0.320706
global_step: 21565, epoch: 140, loss: 0.288784
global_step: 21566, epoch: 140, loss: 0.408953
global_step: 21567, epoch: 140, loss: 0.346042
global_step: 21568, epoch: 140, loss: 0.395246
global_step: 21569, epoch: 140, loss: 0.247760
global_step: 21570, epoch: 140, loss: 0.342412
global_step: 21571, epoch: 140, loss: 0.363794
global_step: 21572, epoch: 140, loss: 0.348467
global_step: 21573, epoch: 140, loss: 0.332401
global_step: 21574, epoch: 140, loss: 0.302140
global_step: 21575, epoch: 140, loss: 0.374725
global_step: 21576, epoch: 140, loss: 0.322149
global_step: 21577, epoch: 140, loss: 0.331369
global_step: 21578, epoch: 140, loss: 0.386971
global_step: 21579, epoch: 140, loss: 0.305548
global_step: 21580, epoch: 140, loss: 0.321151
global_step: 21581, epoch: 140, loss: 0.312621
global_step: 21582, epoch: 140, loss: 0.415811
global_step: 21583, epoch: 140, loss: 0.328497
global_step: 21584, epoch: 140, loss: 0.317147
global_step: 21585, epoch: 140, loss: 0.357228
global_step: 21586, epoch: 140, loss: 0.359757
global_step: 21587, epoch: 140, loss: 0.393461
global_step: 21588, epoch: 140, loss: 0.314713
global_step: 21589, epoch: 140, loss: 0.390548
global_step: 21590, epoch: 140, loss: 0.251054
global_step: 21591, epoch: 140, loss: 0.295288
global_step: 21592, epoch: 140, loss: 0.340215
global_step: 21593, epoch: 140, loss: 0.363534
global_step: 21594, epoch: 140, loss: 0.330176
global_step: 21595, epoch: 140, loss: 0.291924
global_step: 21596, epoch: 140, loss: 0.420260
global_step: 21597, epoch: 140, loss: 0.407723
global_step: 21598, epoch: 140, loss: 0.400647
global_step: 21599, epoch: 140, loss: 0.344985
global_step: 21600, epoch: 140, loss: 0.856109
epoch: 140
train	acc: 0.9444	macro: p 0.9418, r 0.8783, f1: 0.9028	micro: p 0.9444, r 0.9444, f1 0.9444	weighted_f1:0.9432
dev	acc: 0.5663	macro: p 0.4459, r 0.3790, f1: 0.3871	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5383
test	acc: 0.5874	macro: p 0.4016, r 0.3545, f1: 0.3587	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5627
global_step: 21601, epoch: 141, loss: 0.379600
global_step: 21602, epoch: 141, loss: 0.306382
global_step: 21603, epoch: 141, loss: 0.258524
global_step: 21604, epoch: 141, loss: 0.289393
global_step: 21605, epoch: 141, loss: 0.327688
global_step: 21606, epoch: 141, loss: 0.331087
global_step: 21607, epoch: 141, loss: 0.417322
global_step: 21608, epoch: 141, loss: 0.363760
global_step: 21609, epoch: 141, loss: 0.312031
global_step: 21610, epoch: 141, loss: 0.264538
global_step: 21611, epoch: 141, loss: 0.381155
global_step: 21612, epoch: 141, loss: 0.367021
global_step: 21613, epoch: 141, loss: 0.392916
global_step: 21614, epoch: 141, loss: 0.339615
global_step: 21615, epoch: 141, loss: 0.334169
global_step: 21616, epoch: 141, loss: 0.353485
global_step: 21617, epoch: 141, loss: 0.304779
global_step: 21618, epoch: 141, loss: 0.314604
global_step: 21619, epoch: 141, loss: 0.344139
global_step: 21620, epoch: 141, loss: 0.292216
global_step: 21621, epoch: 141, loss: 0.372668
global_step: 21622, epoch: 141, loss: 0.306986
global_step: 21623, epoch: 141, loss: 0.349223
global_step: 21624, epoch: 141, loss: 0.322178
global_step: 21625, epoch: 141, loss: 0.378675
global_step: 21626, epoch: 141, loss: 0.323724
global_step: 21627, epoch: 141, loss: 0.366223
global_step: 21628, epoch: 141, loss: 0.348951
global_step: 21629, epoch: 141, loss: 0.351196
global_step: 21630, epoch: 141, loss: 0.343963
global_step: 21631, epoch: 141, loss: 0.333573
global_step: 21632, epoch: 141, loss: 0.428130
global_step: 21633, epoch: 141, loss: 0.376225
global_step: 21634, epoch: 141, loss: 0.309894
global_step: 21635, epoch: 141, loss: 0.338581
global_step: 21636, epoch: 141, loss: 0.336227
global_step: 21637, epoch: 141, loss: 0.309213
global_step: 21638, epoch: 141, loss: 0.264081
global_step: 21639, epoch: 141, loss: 0.330268
global_step: 21640, epoch: 141, loss: 0.008881
epoch: 141
train	acc: 0.9491	macro: p 0.9533, r 0.8973, f1: 0.9215	micro: p 0.9491, r 0.9491, f1 0.9491	weighted_f1:0.9485
dev	acc: 0.5663	macro: p 0.4356, r 0.3668, f1: 0.3775	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5333
test	acc: 0.5954	macro: p 0.4144, r 0.3530, f1: 0.3654	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5672
global_step: 21641, epoch: 142, loss: 0.368897
global_step: 21642, epoch: 142, loss: 0.334733
global_step: 21643, epoch: 142, loss: 0.310484
global_step: 21644, epoch: 142, loss: 0.320048
global_step: 21645, epoch: 142, loss: 0.341284
global_step: 21646, epoch: 142, loss: 0.275006
global_step: 21647, epoch: 142, loss: 0.283920
global_step: 21648, epoch: 142, loss: 0.327333
global_step: 21649, epoch: 142, loss: 0.307107
global_step: 21650, epoch: 142, loss: 0.376461
global_step: 21651, epoch: 142, loss: 0.297078
global_step: 21652, epoch: 142, loss: 0.368312
global_step: 21653, epoch: 142, loss: 0.404626
global_step: 21654, epoch: 142, loss: 0.300311
global_step: 21655, epoch: 142, loss: 0.273518
global_step: 21656, epoch: 142, loss: 0.319837
global_step: 21657, epoch: 142, loss: 0.347953
global_step: 21658, epoch: 142, loss: 0.376725
global_step: 21659, epoch: 142, loss: 0.374879
global_step: 21660, epoch: 142, loss: 0.311387
global_step: 21661, epoch: 142, loss: 0.333524
global_step: 21662, epoch: 142, loss: 0.318971
global_step: 21663, epoch: 142, loss: 0.332227
global_step: 21664, epoch: 142, loss: 0.283761
global_step: 21665, epoch: 142, loss: 0.293262
global_step: 21666, epoch: 142, loss: 0.313362
global_step: 21667, epoch: 142, loss: 0.364569
global_step: 21668, epoch: 142, loss: 0.292315
global_step: 21669, epoch: 142, loss: 0.370129
global_step: 21670, epoch: 142, loss: 0.376331
global_step: 21671, epoch: 142, loss: 0.298999
global_step: 21672, epoch: 142, loss: 0.319665
global_step: 21673, epoch: 142, loss: 0.386217
global_step: 21674, epoch: 142, loss: 0.379669
global_step: 21675, epoch: 142, loss: 0.339366
global_step: 21676, epoch: 142, loss: 0.331650
global_step: 21677, epoch: 142, loss: 0.404458
global_step: 21678, epoch: 142, loss: 0.411551
global_step: 21679, epoch: 142, loss: 0.277426
global_step: 21680, epoch: 142, loss: 0.626794
epoch: 142
train	acc: 0.9492	macro: p 0.9448, r 0.8956, f1: 0.9158	micro: p 0.9492, r 0.9492, f1 0.9492	weighted_f1:0.9484
dev	acc: 0.5627	macro: p 0.4192, r 0.3724, f1: 0.3813	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5372
test	acc: 0.5897	macro: p 0.3933, r 0.3602, f1: 0.3690	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5695
global_step: 21681, epoch: 143, loss: 0.354230
global_step: 21682, epoch: 143, loss: 0.296939
global_step: 21683, epoch: 143, loss: 0.371029
global_step: 21684, epoch: 143, loss: 0.290165
global_step: 21685, epoch: 143, loss: 0.331172
global_step: 21686, epoch: 143, loss: 0.353778
global_step: 21687, epoch: 143, loss: 0.385768
global_step: 21688, epoch: 143, loss: 0.438804
global_step: 21689, epoch: 143, loss: 0.329754
global_step: 21690, epoch: 143, loss: 0.356887
global_step: 21691, epoch: 143, loss: 0.333067
global_step: 21692, epoch: 143, loss: 0.376560
global_step: 21693, epoch: 143, loss: 0.324268
global_step: 21694, epoch: 143, loss: 0.358886
global_step: 21695, epoch: 143, loss: 0.249933
global_step: 21696, epoch: 143, loss: 0.341539
global_step: 21697, epoch: 143, loss: 0.256177
global_step: 21698, epoch: 143, loss: 0.298842
global_step: 21699, epoch: 143, loss: 0.330783
global_step: 21700, epoch: 143, loss: 0.388994
global_step: 21701, epoch: 143, loss: 0.365018
global_step: 21702, epoch: 143, loss: 0.383048
global_step: 21703, epoch: 143, loss: 0.324134
global_step: 21704, epoch: 143, loss: 0.311735
global_step: 21705, epoch: 143, loss: 0.308159
global_step: 21706, epoch: 143, loss: 0.347466
global_step: 21707, epoch: 143, loss: 0.343863
global_step: 21708, epoch: 143, loss: 0.388846
global_step: 21709, epoch: 143, loss: 0.372711
global_step: 21710, epoch: 143, loss: 0.353030
global_step: 21711, epoch: 143, loss: 0.278679
global_step: 21712, epoch: 143, loss: 0.288394
global_step: 21713, epoch: 143, loss: 0.367709
global_step: 21714, epoch: 143, loss: 0.357033
global_step: 21715, epoch: 143, loss: 0.320892
global_step: 21716, epoch: 143, loss: 0.297059
global_step: 21717, epoch: 143, loss: 0.311363
global_step: 21718, epoch: 143, loss: 0.314255
global_step: 21719, epoch: 143, loss: 0.318613
global_step: 21720, epoch: 143, loss: 0.150425
epoch: 143
train	acc: 0.9493	macro: p 0.9503, r 0.8968, f1: 0.9197	micro: p 0.9493, r 0.9493, f1 0.9493	weighted_f1:0.9487
dev	acc: 0.5690	macro: p 0.4335, r 0.3662, f1: 0.3765	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5366
test	acc: 0.6019	macro: p 0.4217, r 0.3563, f1: 0.3669	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5733
global_step: 21721, epoch: 144, loss: 0.414721
global_step: 21722, epoch: 144, loss: 0.369073
global_step: 21723, epoch: 144, loss: 0.310625
global_step: 21724, epoch: 144, loss: 0.307393
global_step: 21725, epoch: 144, loss: 0.269061
global_step: 21726, epoch: 144, loss: 0.317360
global_step: 21727, epoch: 144, loss: 0.325865
global_step: 21728, epoch: 144, loss: 0.385665
global_step: 21729, epoch: 144, loss: 0.319711
global_step: 21730, epoch: 144, loss: 0.319852
global_step: 21731, epoch: 144, loss: 0.303742
global_step: 21732, epoch: 144, loss: 0.330492
global_step: 21733, epoch: 144, loss: 0.269083
global_step: 21734, epoch: 144, loss: 0.273645
global_step: 21735, epoch: 144, loss: 0.308383
global_step: 21736, epoch: 144, loss: 0.284264
global_step: 21737, epoch: 144, loss: 0.300503
global_step: 21738, epoch: 144, loss: 0.355317
global_step: 21739, epoch: 144, loss: 0.367074
global_step: 21740, epoch: 144, loss: 0.311341
global_step: 21741, epoch: 144, loss: 0.291161
global_step: 21742, epoch: 144, loss: 0.312789
global_step: 21743, epoch: 144, loss: 0.289812
global_step: 21744, epoch: 144, loss: 0.395103
global_step: 21745, epoch: 144, loss: 0.313449
global_step: 21746, epoch: 144, loss: 0.347278
global_step: 21747, epoch: 144, loss: 0.323206
global_step: 21748, epoch: 144, loss: 0.250156
global_step: 21749, epoch: 144, loss: 0.334119
global_step: 21750, epoch: 144, loss: 0.369244
global_step: 21751, epoch: 144, loss: 0.298999
global_step: 21752, epoch: 144, loss: 0.370199
global_step: 21753, epoch: 144, loss: 0.318603
global_step: 21754, epoch: 144, loss: 0.360102
global_step: 21755, epoch: 144, loss: 0.289699
global_step: 21756, epoch: 144, loss: 0.357520
global_step: 21757, epoch: 144, loss: 0.286038
global_step: 21758, epoch: 144, loss: 0.415476
global_step: 21759, epoch: 144, loss: 0.354181
global_step: 21760, epoch: 144, loss: 0.023297
epoch: 144
train	acc: 0.9471	macro: p 0.9542, r 0.8944, f1: 0.9205	micro: p 0.9471, r 0.9471, f1 0.9471	weighted_f1:0.9464
dev	acc: 0.5771	macro: p 0.4690, r 0.3649, f1: 0.3800	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5386
test	acc: 0.5996	macro: p 0.4208, r 0.3437, f1: 0.3574	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5642
global_step: 21761, epoch: 145, loss: 0.322717
global_step: 21762, epoch: 145, loss: 0.363988
global_step: 21763, epoch: 145, loss: 0.287328
global_step: 21764, epoch: 145, loss: 0.326576
global_step: 21765, epoch: 145, loss: 0.357947
global_step: 21766, epoch: 145, loss: 0.307494
global_step: 21767, epoch: 145, loss: 0.285555
global_step: 21768, epoch: 145, loss: 0.291222
global_step: 21769, epoch: 145, loss: 0.378439
global_step: 21770, epoch: 145, loss: 0.306561
global_step: 21771, epoch: 145, loss: 0.279564
global_step: 21772, epoch: 145, loss: 0.306106
global_step: 21773, epoch: 145, loss: 0.241415
global_step: 21774, epoch: 145, loss: 0.391084
global_step: 21775, epoch: 145, loss: 0.426271
global_step: 21776, epoch: 145, loss: 0.306417
global_step: 21777, epoch: 145, loss: 0.346055
global_step: 21778, epoch: 145, loss: 0.346695
global_step: 21779, epoch: 145, loss: 0.336172
global_step: 21780, epoch: 145, loss: 0.313626
global_step: 21781, epoch: 145, loss: 0.400058
global_step: 21782, epoch: 145, loss: 0.364319
global_step: 21783, epoch: 145, loss: 0.328010
global_step: 21784, epoch: 145, loss: 0.238147
global_step: 21785, epoch: 145, loss: 0.319615
global_step: 21786, epoch: 145, loss: 0.297014
global_step: 21787, epoch: 145, loss: 0.353293
global_step: 21788, epoch: 145, loss: 0.283019
global_step: 21789, epoch: 145, loss: 0.318387
global_step: 21790, epoch: 145, loss: 0.337305
global_step: 21791, epoch: 145, loss: 0.298031
global_step: 21792, epoch: 145, loss: 0.268534
global_step: 21793, epoch: 145, loss: 0.318897
global_step: 21794, epoch: 145, loss: 0.341087
global_step: 21795, epoch: 145, loss: 0.286186
global_step: 21796, epoch: 145, loss: 0.367077
global_step: 21797, epoch: 145, loss: 0.427568
global_step: 21798, epoch: 145, loss: 0.264838
global_step: 21799, epoch: 145, loss: 0.364828
global_step: 21800, epoch: 145, loss: 0.051864
epoch: 145
train	acc: 0.9487	macro: p 0.9491, r 0.8908, f1: 0.9146	micro: p 0.9487, r 0.9487, f1 0.9487	weighted_f1:0.9479
dev	acc: 0.5726	macro: p 0.4509, r 0.3746, f1: 0.3867	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5456
test	acc: 0.5931	macro: p 0.3890, r 0.3479, f1: 0.3529	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5685
global_step: 21801, epoch: 146, loss: 0.301689
global_step: 21802, epoch: 146, loss: 0.355423
global_step: 21803, epoch: 146, loss: 0.248090
global_step: 21804, epoch: 146, loss: 0.326985
global_step: 21805, epoch: 146, loss: 0.251495
global_step: 21806, epoch: 146, loss: 0.287912
global_step: 21807, epoch: 146, loss: 0.334268
global_step: 21808, epoch: 146, loss: 0.354412
global_step: 21809, epoch: 146, loss: 0.278555
global_step: 21810, epoch: 146, loss: 0.376344
global_step: 21811, epoch: 146, loss: 0.317941
global_step: 21812, epoch: 146, loss: 0.300131
global_step: 21813, epoch: 146, loss: 0.276719
global_step: 21814, epoch: 146, loss: 0.364944
global_step: 21815, epoch: 146, loss: 0.318566
global_step: 21816, epoch: 146, loss: 0.349796
global_step: 21817, epoch: 146, loss: 0.370351
global_step: 21818, epoch: 146, loss: 0.356051
global_step: 21819, epoch: 146, loss: 0.303768
global_step: 21820, epoch: 146, loss: 0.349457
global_step: 21821, epoch: 146, loss: 0.324840
global_step: 21822, epoch: 146, loss: 0.350696
global_step: 21823, epoch: 146, loss: 0.337728
global_step: 21824, epoch: 146, loss: 0.326093
global_step: 21825, epoch: 146, loss: 0.324450
global_step: 21826, epoch: 146, loss: 0.357120
global_step: 21827, epoch: 146, loss: 0.375251
global_step: 21828, epoch: 146, loss: 0.233302
global_step: 21829, epoch: 146, loss: 0.252183
global_step: 21830, epoch: 146, loss: 0.332290
global_step: 21831, epoch: 146, loss: 0.315821
global_step: 21832, epoch: 146, loss: 0.365241
global_step: 21833, epoch: 146, loss: 0.366531
global_step: 21834, epoch: 146, loss: 0.291976
global_step: 21835, epoch: 146, loss: 0.364204
global_step: 21836, epoch: 146, loss: 0.349797
global_step: 21837, epoch: 146, loss: 0.282823
global_step: 21838, epoch: 146, loss: 0.320486
global_step: 21839, epoch: 146, loss: 0.308954
global_step: 21840, epoch: 146, loss: 0.046017
epoch: 146
train	acc: 0.9499	macro: p 0.9472, r 0.9012, f1: 0.9206	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9495
dev	acc: 0.5681	macro: p 0.4311, r 0.3855, f1: 0.3962	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5487
test	acc: 0.5847	macro: p 0.3841, r 0.3582, f1: 0.3602	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5705
global_step: 21841, epoch: 147, loss: 0.275426
global_step: 21842, epoch: 147, loss: 0.324871
global_step: 21843, epoch: 147, loss: 0.306339
global_step: 21844, epoch: 147, loss: 0.302448
global_step: 21845, epoch: 147, loss: 0.298285
global_step: 21846, epoch: 147, loss: 0.277529
global_step: 21847, epoch: 147, loss: 0.327964
global_step: 21848, epoch: 147, loss: 0.356390
global_step: 21849, epoch: 147, loss: 0.305628
global_step: 21850, epoch: 147, loss: 0.336236
global_step: 21851, epoch: 147, loss: 0.293441
global_step: 21852, epoch: 147, loss: 0.344295
global_step: 21853, epoch: 147, loss: 0.301277
global_step: 21854, epoch: 147, loss: 0.263452
global_step: 21855, epoch: 147, loss: 0.380668
global_step: 21856, epoch: 147, loss: 0.339097
global_step: 21857, epoch: 147, loss: 0.443370
global_step: 21858, epoch: 147, loss: 0.295358
global_step: 21859, epoch: 147, loss: 0.294559
global_step: 21860, epoch: 147, loss: 0.321611
global_step: 21861, epoch: 147, loss: 0.332981
global_step: 21862, epoch: 147, loss: 0.262146
global_step: 21863, epoch: 147, loss: 0.317655
global_step: 21864, epoch: 147, loss: 0.328395
global_step: 21865, epoch: 147, loss: 0.262284
global_step: 21866, epoch: 147, loss: 0.299613
global_step: 21867, epoch: 147, loss: 0.296144
global_step: 21868, epoch: 147, loss: 0.380420
global_step: 21869, epoch: 147, loss: 0.338313
global_step: 21870, epoch: 147, loss: 0.333263
global_step: 21871, epoch: 147, loss: 0.347388
global_step: 21872, epoch: 147, loss: 0.328436
global_step: 21873, epoch: 147, loss: 0.416156
global_step: 21874, epoch: 147, loss: 0.396932
global_step: 21875, epoch: 147, loss: 0.363932
global_step: 21876, epoch: 147, loss: 0.257932
global_step: 21877, epoch: 147, loss: 0.378417
global_step: 21878, epoch: 147, loss: 0.321214
global_step: 21879, epoch: 147, loss: 0.258580
global_step: 21880, epoch: 147, loss: 0.039511
epoch: 147
train	acc: 0.9502	macro: p 0.9534, r 0.9034, f1: 0.9256	micro: p 0.9502, r 0.9502, f1 0.9502	weighted_f1:0.9497
dev	acc: 0.5672	macro: p 0.4380, r 0.3650, f1: 0.3787	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5340
test	acc: 0.6004	macro: p 0.4081, r 0.3453, f1: 0.3569	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5700
global_step: 21881, epoch: 148, loss: 0.295789
global_step: 21882, epoch: 148, loss: 0.304521
global_step: 21883, epoch: 148, loss: 0.338636
global_step: 21884, epoch: 148, loss: 0.281054
global_step: 21885, epoch: 148, loss: 0.366482
global_step: 21886, epoch: 148, loss: 0.309840
global_step: 21887, epoch: 148, loss: 0.368378
global_step: 21888, epoch: 148, loss: 0.304581
global_step: 21889, epoch: 148, loss: 0.291798
global_step: 21890, epoch: 148, loss: 0.299229
global_step: 21891, epoch: 148, loss: 0.372227
global_step: 21892, epoch: 148, loss: 0.325150
global_step: 21893, epoch: 148, loss: 0.335654
global_step: 21894, epoch: 148, loss: 0.325590
global_step: 21895, epoch: 148, loss: 0.285218
global_step: 21896, epoch: 148, loss: 0.234438
global_step: 21897, epoch: 148, loss: 0.305359
global_step: 21898, epoch: 148, loss: 0.319557
global_step: 21899, epoch: 148, loss: 0.356900
global_step: 21900, epoch: 148, loss: 0.368894
global_step: 21901, epoch: 148, loss: 0.346623
global_step: 21902, epoch: 148, loss: 0.390359
global_step: 21903, epoch: 148, loss: 0.329033
global_step: 21904, epoch: 148, loss: 0.304384
global_step: 21905, epoch: 148, loss: 0.336309
global_step: 21906, epoch: 148, loss: 0.270314
global_step: 21907, epoch: 148, loss: 0.378293
global_step: 21908, epoch: 148, loss: 0.341850
global_step: 21909, epoch: 148, loss: 0.277424
global_step: 21910, epoch: 148, loss: 0.396527
global_step: 21911, epoch: 148, loss: 0.334982
global_step: 21912, epoch: 148, loss: 0.300754
global_step: 21913, epoch: 148, loss: 0.282798
global_step: 21914, epoch: 148, loss: 0.315676
global_step: 21915, epoch: 148, loss: 0.329976
global_step: 21916, epoch: 148, loss: 0.271950
global_step: 21917, epoch: 148, loss: 0.286573
global_step: 21918, epoch: 148, loss: 0.429290
global_step: 21919, epoch: 148, loss: 0.284580
global_step: 21920, epoch: 148, loss: 1.059908
epoch: 148
train	acc: 0.9523	macro: p 0.9483, r 0.9086, f1: 0.9259	micro: p 0.9523, r 0.9523, f1 0.9523	weighted_f1:0.9519
dev	acc: 0.5726	macro: p 0.4450, r 0.3871, f1: 0.4037	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5493
test	acc: 0.5920	macro: p 0.3989, r 0.3585, f1: 0.3726	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5736
global_step: 21921, epoch: 149, loss: 0.314898
global_step: 21922, epoch: 149, loss: 0.356325
global_step: 21923, epoch: 149, loss: 0.307996
global_step: 21924, epoch: 149, loss: 0.266815
global_step: 21925, epoch: 149, loss: 0.334892
global_step: 21926, epoch: 149, loss: 0.304582
global_step: 21927, epoch: 149, loss: 0.239893
global_step: 21928, epoch: 149, loss: 0.309706
global_step: 21929, epoch: 149, loss: 0.317497
global_step: 21930, epoch: 149, loss: 0.264535
global_step: 21931, epoch: 149, loss: 0.358157
global_step: 21932, epoch: 149, loss: 0.296358
global_step: 21933, epoch: 149, loss: 0.384430
global_step: 21934, epoch: 149, loss: 0.294632
global_step: 21935, epoch: 149, loss: 0.266929
global_step: 21936, epoch: 149, loss: 0.399164
global_step: 21937, epoch: 149, loss: 0.309970
global_step: 21938, epoch: 149, loss: 0.328676
global_step: 21939, epoch: 149, loss: 0.311502
global_step: 21940, epoch: 149, loss: 0.389975
global_step: 21941, epoch: 149, loss: 0.398451
global_step: 21942, epoch: 149, loss: 0.332420
global_step: 21943, epoch: 149, loss: 0.299420
global_step: 21944, epoch: 149, loss: 0.373644
global_step: 21945, epoch: 149, loss: 0.322107
global_step: 21946, epoch: 149, loss: 0.236952
global_step: 21947, epoch: 149, loss: 0.319283
global_step: 21948, epoch: 149, loss: 0.312467
global_step: 21949, epoch: 149, loss: 0.319812
global_step: 21950, epoch: 149, loss: 0.294274
global_step: 21951, epoch: 149, loss: 0.345704
global_step: 21952, epoch: 149, loss: 0.323705
global_step: 21953, epoch: 149, loss: 0.288717
global_step: 21954, epoch: 149, loss: 0.286024
global_step: 21955, epoch: 149, loss: 0.272443
global_step: 21956, epoch: 149, loss: 0.332198
global_step: 21957, epoch: 149, loss: 0.397279
global_step: 21958, epoch: 149, loss: 0.318296
global_step: 21959, epoch: 149, loss: 0.366832
global_step: 21960, epoch: 149, loss: 0.017975
epoch: 149
train	acc: 0.9508	macro: p 0.9554, r 0.9026, f1: 0.9258	micro: p 0.9508, r 0.9508, f1 0.9508	weighted_f1:0.9502
dev	acc: 0.5654	macro: p 0.4210, r 0.3538, f1: 0.3638	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5275
test	acc: 0.6011	macro: p 0.4306, r 0.3497, f1: 0.3666	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5682
global_step: 21961, epoch: 150, loss: 0.290178
global_step: 21962, epoch: 150, loss: 0.328143
global_step: 21963, epoch: 150, loss: 0.357072
global_step: 21964, epoch: 150, loss: 0.251681
global_step: 21965, epoch: 150, loss: 0.361512
global_step: 21966, epoch: 150, loss: 0.281882
global_step: 21967, epoch: 150, loss: 0.343133
global_step: 21968, epoch: 150, loss: 0.229677
global_step: 21969, epoch: 150, loss: 0.303207
global_step: 21970, epoch: 150, loss: 0.318298
global_step: 21971, epoch: 150, loss: 0.321879
global_step: 21972, epoch: 150, loss: 0.284715
global_step: 21973, epoch: 150, loss: 0.277476
global_step: 21974, epoch: 150, loss: 0.304897
global_step: 21975, epoch: 150, loss: 0.338053
global_step: 21976, epoch: 150, loss: 0.351733
global_step: 21977, epoch: 150, loss: 0.281752
global_step: 21978, epoch: 150, loss: 0.315244
global_step: 21979, epoch: 150, loss: 0.299624
global_step: 21980, epoch: 150, loss: 0.291703
global_step: 21981, epoch: 150, loss: 0.278346
global_step: 21982, epoch: 150, loss: 0.310889
global_step: 21983, epoch: 150, loss: 0.261609
global_step: 21984, epoch: 150, loss: 0.373986
global_step: 21985, epoch: 150, loss: 0.332410
global_step: 21986, epoch: 150, loss: 0.315695
global_step: 21987, epoch: 150, loss: 0.306562
global_step: 21988, epoch: 150, loss: 0.260059
global_step: 21989, epoch: 150, loss: 0.325012
global_step: 21990, epoch: 150, loss: 0.277286
global_step: 21991, epoch: 150, loss: 0.375357
global_step: 21992, epoch: 150, loss: 0.293589
global_step: 21993, epoch: 150, loss: 0.304993
global_step: 21994, epoch: 150, loss: 0.266103
global_step: 21995, epoch: 150, loss: 0.326065
global_step: 21996, epoch: 150, loss: 0.357616
global_step: 21997, epoch: 150, loss: 0.367555
global_step: 21998, epoch: 150, loss: 0.305731
global_step: 21999, epoch: 150, loss: 0.376236
global_step: 22000, epoch: 150, loss: 0.132041
epoch: 150
train	acc: 0.9459	macro: p 0.9544, r 0.8850, f1: 0.9132	micro: p 0.9459, r 0.9459, f1 0.9459	weighted_f1:0.9449
dev	acc: 0.5627	macro: p 0.4572, r 0.3527, f1: 0.3615	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5234
test	acc: 0.5969	macro: p 0.3982, r 0.3378, f1: 0.3432	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5611
global_step: 22001, epoch: 151, loss: 0.285671
global_step: 22002, epoch: 151, loss: 0.362412
global_step: 22003, epoch: 151, loss: 0.258590
global_step: 22004, epoch: 151, loss: 0.339324
global_step: 22005, epoch: 151, loss: 0.256116
global_step: 22006, epoch: 151, loss: 0.289674
global_step: 22007, epoch: 151, loss: 0.354184
global_step: 22008, epoch: 151, loss: 0.318300
global_step: 22009, epoch: 151, loss: 0.304623
global_step: 22010, epoch: 151, loss: 0.328027
global_step: 22011, epoch: 151, loss: 0.356266
global_step: 22012, epoch: 151, loss: 0.302134
global_step: 22013, epoch: 151, loss: 0.292093
global_step: 22014, epoch: 151, loss: 0.260065
global_step: 22015, epoch: 151, loss: 0.349870
global_step: 22016, epoch: 151, loss: 0.340036
global_step: 22017, epoch: 151, loss: 0.368328
global_step: 22018, epoch: 151, loss: 0.282170
global_step: 22019, epoch: 151, loss: 0.300830
global_step: 22020, epoch: 151, loss: 0.360586
global_step: 22021, epoch: 151, loss: 0.319045
global_step: 22022, epoch: 151, loss: 0.337248
global_step: 22023, epoch: 151, loss: 0.260887
global_step: 22024, epoch: 151, loss: 0.310072
global_step: 22025, epoch: 151, loss: 0.280092
global_step: 22026, epoch: 151, loss: 0.312709
global_step: 22027, epoch: 151, loss: 0.210807
global_step: 22028, epoch: 151, loss: 0.399152
global_step: 22029, epoch: 151, loss: 0.284314
global_step: 22030, epoch: 151, loss: 0.263525
global_step: 22031, epoch: 151, loss: 0.341071
global_step: 22032, epoch: 151, loss: 0.334081
global_step: 22033, epoch: 151, loss: 0.310613
global_step: 22034, epoch: 151, loss: 0.347833
global_step: 22035, epoch: 151, loss: 0.304033
global_step: 22036, epoch: 151, loss: 0.278335
global_step: 22037, epoch: 151, loss: 0.307417
global_step: 22038, epoch: 151, loss: 0.390962
global_step: 22039, epoch: 151, loss: 0.349264
global_step: 22040, epoch: 151, loss: 0.130225
epoch: 151
train	acc: 0.9520	macro: p 0.9555, r 0.9082, f1: 0.9295	micro: p 0.9520, r 0.9520, f1 0.9520	weighted_f1:0.9516
dev	acc: 0.5654	macro: p 0.4222, r 0.3524, f1: 0.3653	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5266
test	acc: 0.6015	macro: p 0.4164, r 0.3431, f1: 0.3570	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5661
global_step: 22041, epoch: 152, loss: 0.363344
global_step: 22042, epoch: 152, loss: 0.269670
global_step: 22043, epoch: 152, loss: 0.253846
global_step: 22044, epoch: 152, loss: 0.268819
global_step: 22045, epoch: 152, loss: 0.299730
global_step: 22046, epoch: 152, loss: 0.256376
global_step: 22047, epoch: 152, loss: 0.422490
global_step: 22048, epoch: 152, loss: 0.269425
global_step: 22049, epoch: 152, loss: 0.345654
global_step: 22050, epoch: 152, loss: 0.249310
global_step: 22051, epoch: 152, loss: 0.338970
global_step: 22052, epoch: 152, loss: 0.266919
global_step: 22053, epoch: 152, loss: 0.333410
global_step: 22054, epoch: 152, loss: 0.274348
global_step: 22055, epoch: 152, loss: 0.314971
global_step: 22056, epoch: 152, loss: 0.329012
global_step: 22057, epoch: 152, loss: 0.219116
global_step: 22058, epoch: 152, loss: 0.333388
global_step: 22059, epoch: 152, loss: 0.261386
global_step: 22060, epoch: 152, loss: 0.314928
global_step: 22061, epoch: 152, loss: 0.347564
global_step: 22062, epoch: 152, loss: 0.270920
global_step: 22063, epoch: 152, loss: 0.342550
global_step: 22064, epoch: 152, loss: 0.348544
global_step: 22065, epoch: 152, loss: 0.270410
global_step: 22066, epoch: 152, loss: 0.382401
global_step: 22067, epoch: 152, loss: 0.318294
global_step: 22068, epoch: 152, loss: 0.348255
global_step: 22069, epoch: 152, loss: 0.359202
global_step: 22070, epoch: 152, loss: 0.342773
global_step: 22071, epoch: 152, loss: 0.259239
global_step: 22072, epoch: 152, loss: 0.328083
global_step: 22073, epoch: 152, loss: 0.243193
global_step: 22074, epoch: 152, loss: 0.328962
global_step: 22075, epoch: 152, loss: 0.333400
global_step: 22076, epoch: 152, loss: 0.302279
global_step: 22077, epoch: 152, loss: 0.367927
global_step: 22078, epoch: 152, loss: 0.294623
global_step: 22079, epoch: 152, loss: 0.300297
global_step: 22080, epoch: 152, loss: 0.341924
epoch: 152
train	acc: 0.9507	macro: p 0.9515, r 0.8974, f1: 0.9192	micro: p 0.9507, r 0.9507, f1 0.9507	weighted_f1:0.9500
dev	acc: 0.5618	macro: p 0.4385, r 0.3846, f1: 0.3897	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5416
test	acc: 0.5759	macro: p 0.3808, r 0.3606, f1: 0.3594	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5618
global_step: 22081, epoch: 153, loss: 0.390132
global_step: 22082, epoch: 153, loss: 0.359395
global_step: 22083, epoch: 153, loss: 0.322116
global_step: 22084, epoch: 153, loss: 0.303182
global_step: 22085, epoch: 153, loss: 0.310032
global_step: 22086, epoch: 153, loss: 0.326020
global_step: 22087, epoch: 153, loss: 0.319632
global_step: 22088, epoch: 153, loss: 0.370019
global_step: 22089, epoch: 153, loss: 0.350203
global_step: 22090, epoch: 153, loss: 0.369196
global_step: 22091, epoch: 153, loss: 0.329119
global_step: 22092, epoch: 153, loss: 0.262067
global_step: 22093, epoch: 153, loss: 0.332349
global_step: 22094, epoch: 153, loss: 0.256267
global_step: 22095, epoch: 153, loss: 0.262128
global_step: 22096, epoch: 153, loss: 0.250954
global_step: 22097, epoch: 153, loss: 0.328236
global_step: 22098, epoch: 153, loss: 0.274840
global_step: 22099, epoch: 153, loss: 0.364779
global_step: 22100, epoch: 153, loss: 0.353030
global_step: 22101, epoch: 153, loss: 0.247901
global_step: 22102, epoch: 153, loss: 0.278930
global_step: 22103, epoch: 153, loss: 0.320499
global_step: 22104, epoch: 153, loss: 0.333235
global_step: 22105, epoch: 153, loss: 0.320486
global_step: 22106, epoch: 153, loss: 0.353414
global_step: 22107, epoch: 153, loss: 0.321857
global_step: 22108, epoch: 153, loss: 0.314688
global_step: 22109, epoch: 153, loss: 0.303848
global_step: 22110, epoch: 153, loss: 0.317692
global_step: 22111, epoch: 153, loss: 0.331922
global_step: 22112, epoch: 153, loss: 0.338335
global_step: 22113, epoch: 153, loss: 0.344010
global_step: 22114, epoch: 153, loss: 0.287340
global_step: 22115, epoch: 153, loss: 0.269069
global_step: 22116, epoch: 153, loss: 0.336281
global_step: 22117, epoch: 153, loss: 0.354022
global_step: 22118, epoch: 153, loss: 0.305402
global_step: 22119, epoch: 153, loss: 0.254995
global_step: 22120, epoch: 153, loss: 0.045235
epoch: 153
train	acc: 0.9548	macro: p 0.9560, r 0.9128, f1: 0.9322	micro: p 0.9548, r 0.9548, f1 0.9548	weighted_f1:0.9544
dev	acc: 0.5618	macro: p 0.4313, r 0.3672, f1: 0.3798	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5331
test	acc: 0.5946	macro: p 0.4010, r 0.3500, f1: 0.3598	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5695
global_step: 22121, epoch: 154, loss: 0.251490
global_step: 22122, epoch: 154, loss: 0.287949
global_step: 22123, epoch: 154, loss: 0.308920
global_step: 22124, epoch: 154, loss: 0.279340
global_step: 22125, epoch: 154, loss: 0.371925
global_step: 22126, epoch: 154, loss: 0.279664
global_step: 22127, epoch: 154, loss: 0.272916
global_step: 22128, epoch: 154, loss: 0.302850
global_step: 22129, epoch: 154, loss: 0.326775
global_step: 22130, epoch: 154, loss: 0.305393
global_step: 22131, epoch: 154, loss: 0.297818
global_step: 22132, epoch: 154, loss: 0.318650
global_step: 22133, epoch: 154, loss: 0.293631
global_step: 22134, epoch: 154, loss: 0.270755
global_step: 22135, epoch: 154, loss: 0.282177
global_step: 22136, epoch: 154, loss: 0.312012
global_step: 22137, epoch: 154, loss: 0.265547
global_step: 22138, epoch: 154, loss: 0.288870
global_step: 22139, epoch: 154, loss: 0.303494
global_step: 22140, epoch: 154, loss: 0.285326
global_step: 22141, epoch: 154, loss: 0.294422
global_step: 22142, epoch: 154, loss: 0.280234
global_step: 22143, epoch: 154, loss: 0.300289
global_step: 22144, epoch: 154, loss: 0.296139
global_step: 22145, epoch: 154, loss: 0.322062
global_step: 22146, epoch: 154, loss: 0.293732
global_step: 22147, epoch: 154, loss: 0.309996
global_step: 22148, epoch: 154, loss: 0.335708
global_step: 22149, epoch: 154, loss: 0.238431
global_step: 22150, epoch: 154, loss: 0.269899
global_step: 22151, epoch: 154, loss: 0.293880
global_step: 22152, epoch: 154, loss: 0.349623
global_step: 22153, epoch: 154, loss: 0.266771
global_step: 22154, epoch: 154, loss: 0.274853
global_step: 22155, epoch: 154, loss: 0.437335
global_step: 22156, epoch: 154, loss: 0.355044
global_step: 22157, epoch: 154, loss: 0.308277
global_step: 22158, epoch: 154, loss: 0.369469
global_step: 22159, epoch: 154, loss: 0.231600
global_step: 22160, epoch: 154, loss: 0.134628
epoch: 154
train	acc: 0.9523	macro: p 0.9531, r 0.9052, f1: 0.9259	micro: p 0.9523, r 0.9523, f1 0.9523	weighted_f1:0.9518
dev	acc: 0.5609	macro: p 0.4358, r 0.3677, f1: 0.3759	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5298
test	acc: 0.5954	macro: p 0.4051, r 0.3550, f1: 0.3643	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5702
global_step: 22161, epoch: 155, loss: 0.281343
global_step: 22162, epoch: 155, loss: 0.325063
global_step: 22163, epoch: 155, loss: 0.274540
global_step: 22164, epoch: 155, loss: 0.289384
global_step: 22165, epoch: 155, loss: 0.273925
global_step: 22166, epoch: 155, loss: 0.329224
global_step: 22167, epoch: 155, loss: 0.276411
global_step: 22168, epoch: 155, loss: 0.244942
global_step: 22169, epoch: 155, loss: 0.299725
global_step: 22170, epoch: 155, loss: 0.242710
global_step: 22171, epoch: 155, loss: 0.361960
global_step: 22172, epoch: 155, loss: 0.316239
global_step: 22173, epoch: 155, loss: 0.343805
global_step: 22174, epoch: 155, loss: 0.271869
global_step: 22175, epoch: 155, loss: 0.277716
global_step: 22176, epoch: 155, loss: 0.184968
global_step: 22177, epoch: 155, loss: 0.318637
global_step: 22178, epoch: 155, loss: 0.340061
global_step: 22179, epoch: 155, loss: 0.300450
global_step: 22180, epoch: 155, loss: 0.310477
global_step: 22181, epoch: 155, loss: 0.369196
global_step: 22182, epoch: 155, loss: 0.343015
global_step: 22183, epoch: 155, loss: 0.320695
global_step: 22184, epoch: 155, loss: 0.310962
global_step: 22185, epoch: 155, loss: 0.278759
global_step: 22186, epoch: 155, loss: 0.259885
global_step: 22187, epoch: 155, loss: 0.221306
global_step: 22188, epoch: 155, loss: 0.302905
global_step: 22189, epoch: 155, loss: 0.280647
global_step: 22190, epoch: 155, loss: 0.322763
global_step: 22191, epoch: 155, loss: 0.398646
global_step: 22192, epoch: 155, loss: 0.249687
global_step: 22193, epoch: 155, loss: 0.318857
global_step: 22194, epoch: 155, loss: 0.405262
global_step: 22195, epoch: 155, loss: 0.287692
global_step: 22196, epoch: 155, loss: 0.355035
global_step: 22197, epoch: 155, loss: 0.365360
global_step: 22198, epoch: 155, loss: 0.317410
global_step: 22199, epoch: 155, loss: 0.311302
global_step: 22200, epoch: 155, loss: 0.188985
epoch: 155
train	acc: 0.9527	macro: p 0.9569, r 0.9101, f1: 0.9310	micro: p 0.9527, r 0.9527, f1 0.9527	weighted_f1:0.9524
dev	acc: 0.5636	macro: p 0.4345, r 0.3633, f1: 0.3756	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5282
test	acc: 0.5946	macro: p 0.4141, r 0.3458, f1: 0.3554	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5620
global_step: 22201, epoch: 156, loss: 0.265893
global_step: 22202, epoch: 156, loss: 0.295635
global_step: 22203, epoch: 156, loss: 0.310549
global_step: 22204, epoch: 156, loss: 0.336875
global_step: 22205, epoch: 156, loss: 0.324106
global_step: 22206, epoch: 156, loss: 0.281990
global_step: 22207, epoch: 156, loss: 0.317663
global_step: 22208, epoch: 156, loss: 0.379095
global_step: 22209, epoch: 156, loss: 0.306212
global_step: 22210, epoch: 156, loss: 0.300239
global_step: 22211, epoch: 156, loss: 0.295186
global_step: 22212, epoch: 156, loss: 0.264813
global_step: 22213, epoch: 156, loss: 0.253372
global_step: 22214, epoch: 156, loss: 0.309084
global_step: 22215, epoch: 156, loss: 0.270104
global_step: 22216, epoch: 156, loss: 0.337128
global_step: 22217, epoch: 156, loss: 0.348323
global_step: 22218, epoch: 156, loss: 0.317044
global_step: 22219, epoch: 156, loss: 0.349055
global_step: 22220, epoch: 156, loss: 0.318594
global_step: 22221, epoch: 156, loss: 0.223163
global_step: 22222, epoch: 156, loss: 0.253762
global_step: 22223, epoch: 156, loss: 0.271279
global_step: 22224, epoch: 156, loss: 0.310405
global_step: 22225, epoch: 156, loss: 0.273583
global_step: 22226, epoch: 156, loss: 0.338761
global_step: 22227, epoch: 156, loss: 0.275709
global_step: 22228, epoch: 156, loss: 0.302183
global_step: 22229, epoch: 156, loss: 0.318641
global_step: 22230, epoch: 156, loss: 0.296601
global_step: 22231, epoch: 156, loss: 0.312712
global_step: 22232, epoch: 156, loss: 0.316399
global_step: 22233, epoch: 156, loss: 0.338514
global_step: 22234, epoch: 156, loss: 0.320660
global_step: 22235, epoch: 156, loss: 0.319656
global_step: 22236, epoch: 156, loss: 0.315007
global_step: 22237, epoch: 156, loss: 0.293608
global_step: 22238, epoch: 156, loss: 0.379536
global_step: 22239, epoch: 156, loss: 0.349606
global_step: 22240, epoch: 156, loss: 0.146622
epoch: 156
train	acc: 0.9536	macro: p 0.9582, r 0.9116, f1: 0.9326	micro: p 0.9536, r 0.9536, f1 0.9536	weighted_f1:0.9533
dev	acc: 0.5690	macro: p 0.4432, r 0.3592, f1: 0.3707	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5340
test	acc: 0.5920	macro: p 0.4009, r 0.3378, f1: 0.3456	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5596
global_step: 22241, epoch: 157, loss: 0.304562
global_step: 22242, epoch: 157, loss: 0.247602
global_step: 22243, epoch: 157, loss: 0.327631
global_step: 22244, epoch: 157, loss: 0.220341
global_step: 22245, epoch: 157, loss: 0.350535
global_step: 22246, epoch: 157, loss: 0.255311
global_step: 22247, epoch: 157, loss: 0.312924
global_step: 22248, epoch: 157, loss: 0.260545
global_step: 22249, epoch: 157, loss: 0.303327
global_step: 22250, epoch: 157, loss: 0.270554
global_step: 22251, epoch: 157, loss: 0.351732
global_step: 22252, epoch: 157, loss: 0.277905
global_step: 22253, epoch: 157, loss: 0.276820
global_step: 22254, epoch: 157, loss: 0.291828
global_step: 22255, epoch: 157, loss: 0.255725
global_step: 22256, epoch: 157, loss: 0.311471
global_step: 22257, epoch: 157, loss: 0.280312
global_step: 22258, epoch: 157, loss: 0.277602
global_step: 22259, epoch: 157, loss: 0.267073
global_step: 22260, epoch: 157, loss: 0.290095
global_step: 22261, epoch: 157, loss: 0.360556
global_step: 22262, epoch: 157, loss: 0.226987
global_step: 22263, epoch: 157, loss: 0.343136
global_step: 22264, epoch: 157, loss: 0.264362
global_step: 22265, epoch: 157, loss: 0.309116
global_step: 22266, epoch: 157, loss: 0.208043
global_step: 22267, epoch: 157, loss: 0.320971
global_step: 22268, epoch: 157, loss: 0.391504
global_step: 22269, epoch: 157, loss: 0.384046
global_step: 22270, epoch: 157, loss: 0.277031
global_step: 22271, epoch: 157, loss: 0.393960
global_step: 22272, epoch: 157, loss: 0.335558
global_step: 22273, epoch: 157, loss: 0.280451
global_step: 22274, epoch: 157, loss: 0.327932
global_step: 22275, epoch: 157, loss: 0.265963
global_step: 22276, epoch: 157, loss: 0.340853
global_step: 22277, epoch: 157, loss: 0.361685
global_step: 22278, epoch: 157, loss: 0.301779
global_step: 22279, epoch: 157, loss: 0.311336
global_step: 22280, epoch: 157, loss: 0.078497
epoch: 157
train	acc: 0.9532	macro: p 0.9549, r 0.9094, f1: 0.9292	micro: p 0.9532, r 0.9532, f1 0.9532	weighted_f1:0.9529
dev	acc: 0.5735	macro: p 0.4860, r 0.3833, f1: 0.3919	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5460
test	acc: 0.5904	macro: p 0.3997, r 0.3537, f1: 0.3578	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5657
global_step: 22281, epoch: 158, loss: 0.395629
global_step: 22282, epoch: 158, loss: 0.293305
global_step: 22283, epoch: 158, loss: 0.271817
global_step: 22284, epoch: 158, loss: 0.223597
global_step: 22285, epoch: 158, loss: 0.296849
global_step: 22286, epoch: 158, loss: 0.250198
global_step: 22287, epoch: 158, loss: 0.271573
global_step: 22288, epoch: 158, loss: 0.318954
global_step: 22289, epoch: 158, loss: 0.285084
global_step: 22290, epoch: 158, loss: 0.294122
global_step: 22291, epoch: 158, loss: 0.340917
global_step: 22292, epoch: 158, loss: 0.298684
global_step: 22293, epoch: 158, loss: 0.274128
global_step: 22294, epoch: 158, loss: 0.291246
global_step: 22295, epoch: 158, loss: 0.306590
global_step: 22296, epoch: 158, loss: 0.263747
global_step: 22297, epoch: 158, loss: 0.236559
global_step: 22298, epoch: 158, loss: 0.333692
global_step: 22299, epoch: 158, loss: 0.354763
global_step: 22300, epoch: 158, loss: 0.278386
global_step: 22301, epoch: 158, loss: 0.315860
global_step: 22302, epoch: 158, loss: 0.303245
global_step: 22303, epoch: 158, loss: 0.358271
global_step: 22304, epoch: 158, loss: 0.291008
global_step: 22305, epoch: 158, loss: 0.284439
global_step: 22306, epoch: 158, loss: 0.229179
global_step: 22307, epoch: 158, loss: 0.360135
global_step: 22308, epoch: 158, loss: 0.235891
global_step: 22309, epoch: 158, loss: 0.307835
global_step: 22310, epoch: 158, loss: 0.292380
global_step: 22311, epoch: 158, loss: 0.274280
global_step: 22312, epoch: 158, loss: 0.275900
global_step: 22313, epoch: 158, loss: 0.290406
global_step: 22314, epoch: 158, loss: 0.296572
global_step: 22315, epoch: 158, loss: 0.307671
global_step: 22316, epoch: 158, loss: 0.284752
global_step: 22317, epoch: 158, loss: 0.272758
global_step: 22318, epoch: 158, loss: 0.316908
global_step: 22319, epoch: 158, loss: 0.316824
global_step: 22320, epoch: 158, loss: 0.257647
epoch: 158
train	acc: 0.9549	macro: p 0.9526, r 0.9182, f1: 0.9337	micro: p 0.9549, r 0.9549, f1 0.9549	weighted_f1:0.9547
dev	acc: 0.5636	macro: p 0.4385, r 0.3812, f1: 0.3955	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5415
test	acc: 0.5866	macro: p 0.4112, r 0.3611, f1: 0.3714	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5705
global_step: 22321, epoch: 159, loss: 0.288160
global_step: 22322, epoch: 159, loss: 0.308322
global_step: 22323, epoch: 159, loss: 0.261903
global_step: 22324, epoch: 159, loss: 0.211494
global_step: 22325, epoch: 159, loss: 0.354374
global_step: 22326, epoch: 159, loss: 0.262284
global_step: 22327, epoch: 159, loss: 0.298460
global_step: 22328, epoch: 159, loss: 0.248857
global_step: 22329, epoch: 159, loss: 0.353517
global_step: 22330, epoch: 159, loss: 0.223259
global_step: 22331, epoch: 159, loss: 0.277304
global_step: 22332, epoch: 159, loss: 0.316357
global_step: 22333, epoch: 159, loss: 0.295961
global_step: 22334, epoch: 159, loss: 0.261834
global_step: 22335, epoch: 159, loss: 0.339633
global_step: 22336, epoch: 159, loss: 0.347618
global_step: 22337, epoch: 159, loss: 0.317464
global_step: 22338, epoch: 159, loss: 0.334952
global_step: 22339, epoch: 159, loss: 0.344635
global_step: 22340, epoch: 159, loss: 0.286555
global_step: 22341, epoch: 159, loss: 0.315794
global_step: 22342, epoch: 159, loss: 0.251196
global_step: 22343, epoch: 159, loss: 0.332804
global_step: 22344, epoch: 159, loss: 0.301298
global_step: 22345, epoch: 159, loss: 0.292295
global_step: 22346, epoch: 159, loss: 0.230812
global_step: 22347, epoch: 159, loss: 0.219732
global_step: 22348, epoch: 159, loss: 0.295830
global_step: 22349, epoch: 159, loss: 0.335265
global_step: 22350, epoch: 159, loss: 0.380537
global_step: 22351, epoch: 159, loss: 0.342755
global_step: 22352, epoch: 159, loss: 0.323441
global_step: 22353, epoch: 159, loss: 0.313135
global_step: 22354, epoch: 159, loss: 0.255138
global_step: 22355, epoch: 159, loss: 0.310216
global_step: 22356, epoch: 159, loss: 0.228393
global_step: 22357, epoch: 159, loss: 0.231312
global_step: 22358, epoch: 159, loss: 0.337222
global_step: 22359, epoch: 159, loss: 0.337549
global_step: 22360, epoch: 159, loss: 0.344250
epoch: 159
train	acc: 0.9556	macro: p 0.9518, r 0.9129, f1: 0.9293	micro: p 0.9556, r 0.9556, f1 0.9556	weighted_f1:0.9551
dev	acc: 0.5654	macro: p 0.4350, r 0.3877, f1: 0.3939	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5444
test	acc: 0.5778	macro: p 0.3846, r 0.3597, f1: 0.3652	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5650
global_step: 22361, epoch: 160, loss: 0.303637
global_step: 22362, epoch: 160, loss: 0.261592
global_step: 22363, epoch: 160, loss: 0.260946
global_step: 22364, epoch: 160, loss: 0.345745
global_step: 22365, epoch: 160, loss: 0.294230
global_step: 22366, epoch: 160, loss: 0.282971
global_step: 22367, epoch: 160, loss: 0.329470
global_step: 22368, epoch: 160, loss: 0.246494
global_step: 22369, epoch: 160, loss: 0.279412
global_step: 22370, epoch: 160, loss: 0.295428
global_step: 22371, epoch: 160, loss: 0.251915
global_step: 22372, epoch: 160, loss: 0.311858
global_step: 22373, epoch: 160, loss: 0.222171
global_step: 22374, epoch: 160, loss: 0.292642
global_step: 22375, epoch: 160, loss: 0.329197
global_step: 22376, epoch: 160, loss: 0.383234
global_step: 22377, epoch: 160, loss: 0.296011
global_step: 22378, epoch: 160, loss: 0.244045
global_step: 22379, epoch: 160, loss: 0.306151
global_step: 22380, epoch: 160, loss: 0.281996
global_step: 22381, epoch: 160, loss: 0.331083
global_step: 22382, epoch: 160, loss: 0.301411
global_step: 22383, epoch: 160, loss: 0.291351
global_step: 22384, epoch: 160, loss: 0.262803
global_step: 22385, epoch: 160, loss: 0.256144
global_step: 22386, epoch: 160, loss: 0.289683
global_step: 22387, epoch: 160, loss: 0.210821
global_step: 22388, epoch: 160, loss: 0.256070
global_step: 22389, epoch: 160, loss: 0.305005
global_step: 22390, epoch: 160, loss: 0.258184
global_step: 22391, epoch: 160, loss: 0.250395
global_step: 22392, epoch: 160, loss: 0.324981
global_step: 22393, epoch: 160, loss: 0.303059
global_step: 22394, epoch: 160, loss: 0.332478
global_step: 22395, epoch: 160, loss: 0.291720
global_step: 22396, epoch: 160, loss: 0.341184
global_step: 22397, epoch: 160, loss: 0.313157
global_step: 22398, epoch: 160, loss: 0.281905
global_step: 22399, epoch: 160, loss: 0.252286
global_step: 22400, epoch: 160, loss: 0.782010
epoch: 160
train	acc: 0.9557	macro: p 0.9553, r 0.9153, f1: 0.9330	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9554
dev	acc: 0.5636	macro: p 0.4408, r 0.3713, f1: 0.3841	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5360
test	acc: 0.5950	macro: p 0.3963, r 0.3545, f1: 0.3613	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5717
global_step: 22401, epoch: 161, loss: 0.302299
global_step: 22402, epoch: 161, loss: 0.238619
global_step: 22403, epoch: 161, loss: 0.313889
global_step: 22404, epoch: 161, loss: 0.262628
global_step: 22405, epoch: 161, loss: 0.265087
global_step: 22406, epoch: 161, loss: 0.338078
global_step: 22407, epoch: 161, loss: 0.202808
global_step: 22408, epoch: 161, loss: 0.246973
global_step: 22409, epoch: 161, loss: 0.295545
global_step: 22410, epoch: 161, loss: 0.328630
global_step: 22411, epoch: 161, loss: 0.306259
global_step: 22412, epoch: 161, loss: 0.299170
global_step: 22413, epoch: 161, loss: 0.329771
global_step: 22414, epoch: 161, loss: 0.243654
global_step: 22415, epoch: 161, loss: 0.312465
global_step: 22416, epoch: 161, loss: 0.208739
global_step: 22417, epoch: 161, loss: 0.318632
global_step: 22418, epoch: 161, loss: 0.303389
global_step: 22419, epoch: 161, loss: 0.244256
global_step: 22420, epoch: 161, loss: 0.317911
global_step: 22421, epoch: 161, loss: 0.279242
global_step: 22422, epoch: 161, loss: 0.261223
global_step: 22423, epoch: 161, loss: 0.331007
global_step: 22424, epoch: 161, loss: 0.321006
global_step: 22425, epoch: 161, loss: 0.284361
global_step: 22426, epoch: 161, loss: 0.296205
global_step: 22427, epoch: 161, loss: 0.274254
global_step: 22428, epoch: 161, loss: 0.273750
global_step: 22429, epoch: 161, loss: 0.289281
global_step: 22430, epoch: 161, loss: 0.291958
global_step: 22431, epoch: 161, loss: 0.300499
global_step: 22432, epoch: 161, loss: 0.317586
global_step: 22433, epoch: 161, loss: 0.323797
global_step: 22434, epoch: 161, loss: 0.253138
global_step: 22435, epoch: 161, loss: 0.340438
global_step: 22436, epoch: 161, loss: 0.325860
global_step: 22437, epoch: 161, loss: 0.347220
global_step: 22438, epoch: 161, loss: 0.223866
global_step: 22439, epoch: 161, loss: 0.337954
global_step: 22440, epoch: 161, loss: 0.225295
epoch: 161
train	acc: 0.9558	macro: p 0.9581, r 0.9161, f1: 0.9352	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9554
dev	acc: 0.5645	macro: p 0.4502, r 0.3653, f1: 0.3845	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5325
test	acc: 0.5966	macro: p 0.4118, r 0.3463, f1: 0.3621	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5671
global_step: 22441, epoch: 162, loss: 0.305329
global_step: 22442, epoch: 162, loss: 0.270058
global_step: 22443, epoch: 162, loss: 0.276281
global_step: 22444, epoch: 162, loss: 0.230718
global_step: 22445, epoch: 162, loss: 0.255535
global_step: 22446, epoch: 162, loss: 0.269243
global_step: 22447, epoch: 162, loss: 0.245274
global_step: 22448, epoch: 162, loss: 0.305883
global_step: 22449, epoch: 162, loss: 0.298622
global_step: 22450, epoch: 162, loss: 0.254536
global_step: 22451, epoch: 162, loss: 0.321795
global_step: 22452, epoch: 162, loss: 0.278579
global_step: 22453, epoch: 162, loss: 0.295897
global_step: 22454, epoch: 162, loss: 0.250564
global_step: 22455, epoch: 162, loss: 0.199151
global_step: 22456, epoch: 162, loss: 0.278722
global_step: 22457, epoch: 162, loss: 0.267932
global_step: 22458, epoch: 162, loss: 0.295019
global_step: 22459, epoch: 162, loss: 0.308542
global_step: 22460, epoch: 162, loss: 0.248706
global_step: 22461, epoch: 162, loss: 0.262188
global_step: 22462, epoch: 162, loss: 0.340423
global_step: 22463, epoch: 162, loss: 0.320947
global_step: 22464, epoch: 162, loss: 0.300973
global_step: 22465, epoch: 162, loss: 0.288083
global_step: 22466, epoch: 162, loss: 0.271459
global_step: 22467, epoch: 162, loss: 0.333930
global_step: 22468, epoch: 162, loss: 0.344778
global_step: 22469, epoch: 162, loss: 0.279278
global_step: 22470, epoch: 162, loss: 0.335020
global_step: 22471, epoch: 162, loss: 0.304036
global_step: 22472, epoch: 162, loss: 0.281621
global_step: 22473, epoch: 162, loss: 0.334389
global_step: 22474, epoch: 162, loss: 0.248368
global_step: 22475, epoch: 162, loss: 0.272886
global_step: 22476, epoch: 162, loss: 0.321107
global_step: 22477, epoch: 162, loss: 0.262882
global_step: 22478, epoch: 162, loss: 0.304513
global_step: 22479, epoch: 162, loss: 0.251291
global_step: 22480, epoch: 162, loss: 0.170958
epoch: 162
train	acc: 0.9576	macro: p 0.9570, r 0.9212, f1: 0.9373	micro: p 0.9576, r 0.9576, f1 0.9576	weighted_f1:0.9574
dev	acc: 0.5663	macro: p 0.4443, r 0.3833, f1: 0.3966	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5417
test	acc: 0.5843	macro: p 0.3783, r 0.3532, f1: 0.3587	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5659
global_step: 22481, epoch: 163, loss: 0.228165
global_step: 22482, epoch: 163, loss: 0.259847
global_step: 22483, epoch: 163, loss: 0.268508
global_step: 22484, epoch: 163, loss: 0.296118
global_step: 22485, epoch: 163, loss: 0.265266
global_step: 22486, epoch: 163, loss: 0.247245
global_step: 22487, epoch: 163, loss: 0.317605
global_step: 22488, epoch: 163, loss: 0.239091
global_step: 22489, epoch: 163, loss: 0.271623
global_step: 22490, epoch: 163, loss: 0.246472
global_step: 22491, epoch: 163, loss: 0.264044
global_step: 22492, epoch: 163, loss: 0.199022
global_step: 22493, epoch: 163, loss: 0.271918
global_step: 22494, epoch: 163, loss: 0.283901
global_step: 22495, epoch: 163, loss: 0.238715
global_step: 22496, epoch: 163, loss: 0.269884
global_step: 22497, epoch: 163, loss: 0.293565
global_step: 22498, epoch: 163, loss: 0.290250
global_step: 22499, epoch: 163, loss: 0.307434
global_step: 22500, epoch: 163, loss: 0.347987
global_step: 22501, epoch: 163, loss: 0.350765
global_step: 22502, epoch: 163, loss: 0.308814
global_step: 22503, epoch: 163, loss: 0.241192
global_step: 22504, epoch: 163, loss: 0.313549
global_step: 22505, epoch: 163, loss: 0.299677
global_step: 22506, epoch: 163, loss: 0.330914
global_step: 22507, epoch: 163, loss: 0.327056
global_step: 22508, epoch: 163, loss: 0.219244
global_step: 22509, epoch: 163, loss: 0.308301
global_step: 22510, epoch: 163, loss: 0.329921
global_step: 22511, epoch: 163, loss: 0.351957
global_step: 22512, epoch: 163, loss: 0.319163
global_step: 22513, epoch: 163, loss: 0.228921
global_step: 22514, epoch: 163, loss: 0.306045
global_step: 22515, epoch: 163, loss: 0.212160
global_step: 22516, epoch: 163, loss: 0.241632
global_step: 22517, epoch: 163, loss: 0.293028
global_step: 22518, epoch: 163, loss: 0.273646
global_step: 22519, epoch: 163, loss: 0.300398
global_step: 22520, epoch: 163, loss: 0.052746
epoch: 163
train	acc: 0.9540	macro: p 0.9567, r 0.9106, f1: 0.9307	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9536
dev	acc: 0.5627	macro: p 0.4305, r 0.3717, f1: 0.3822	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5348
test	acc: 0.5916	macro: p 0.3933, r 0.3509, f1: 0.3574	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5671
global_step: 22521, epoch: 164, loss: 0.272058
global_step: 22522, epoch: 164, loss: 0.326446
global_step: 22523, epoch: 164, loss: 0.271249
global_step: 22524, epoch: 164, loss: 0.293322
global_step: 22525, epoch: 164, loss: 0.220440
global_step: 22526, epoch: 164, loss: 0.281942
global_step: 22527, epoch: 164, loss: 0.304628
global_step: 22528, epoch: 164, loss: 0.268863
global_step: 22529, epoch: 164, loss: 0.297457
global_step: 22530, epoch: 164, loss: 0.272265
global_step: 22531, epoch: 164, loss: 0.210459
global_step: 22532, epoch: 164, loss: 0.251556
global_step: 22533, epoch: 164, loss: 0.285302
global_step: 22534, epoch: 164, loss: 0.348821
global_step: 22535, epoch: 164, loss: 0.271908
global_step: 22536, epoch: 164, loss: 0.295610
global_step: 22537, epoch: 164, loss: 0.236212
global_step: 22538, epoch: 164, loss: 0.315201
global_step: 22539, epoch: 164, loss: 0.294141
global_step: 22540, epoch: 164, loss: 0.257991
global_step: 22541, epoch: 164, loss: 0.262221
global_step: 22542, epoch: 164, loss: 0.281365
global_step: 22543, epoch: 164, loss: 0.283147
global_step: 22544, epoch: 164, loss: 0.307061
global_step: 22545, epoch: 164, loss: 0.246970
global_step: 22546, epoch: 164, loss: 0.236304
global_step: 22547, epoch: 164, loss: 0.193238
global_step: 22548, epoch: 164, loss: 0.293541
global_step: 22549, epoch: 164, loss: 0.267139
global_step: 22550, epoch: 164, loss: 0.334262
global_step: 22551, epoch: 164, loss: 0.298657
global_step: 22552, epoch: 164, loss: 0.350735
global_step: 22553, epoch: 164, loss: 0.271176
global_step: 22554, epoch: 164, loss: 0.341324
global_step: 22555, epoch: 164, loss: 0.335415
global_step: 22556, epoch: 164, loss: 0.270001
global_step: 22557, epoch: 164, loss: 0.269751
global_step: 22558, epoch: 164, loss: 0.291567
global_step: 22559, epoch: 164, loss: 0.250275
global_step: 22560, epoch: 164, loss: 0.012744
epoch: 164
train	acc: 0.9574	macro: p 0.9597, r 0.9267, f1: 0.9421	micro: p 0.9574, r 0.9574, f1 0.9574	weighted_f1:0.9572
dev	acc: 0.5681	macro: p 0.4339, r 0.3678, f1: 0.3831	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5351
test	acc: 0.5900	macro: p 0.3972, r 0.3444, f1: 0.3578	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5618
global_step: 22561, epoch: 165, loss: 0.222842
global_step: 22562, epoch: 165, loss: 0.201335
global_step: 22563, epoch: 165, loss: 0.177419
global_step: 22564, epoch: 165, loss: 0.298097
global_step: 22565, epoch: 165, loss: 0.301993
global_step: 22566, epoch: 165, loss: 0.265267
global_step: 22567, epoch: 165, loss: 0.273120
global_step: 22568, epoch: 165, loss: 0.334682
global_step: 22569, epoch: 165, loss: 0.279729
global_step: 22570, epoch: 165, loss: 0.291515
global_step: 22571, epoch: 165, loss: 0.301605
global_step: 22572, epoch: 165, loss: 0.262210
global_step: 22573, epoch: 165, loss: 0.300236
global_step: 22574, epoch: 165, loss: 0.241560
global_step: 22575, epoch: 165, loss: 0.218952
global_step: 22576, epoch: 165, loss: 0.300607
global_step: 22577, epoch: 165, loss: 0.370521
global_step: 22578, epoch: 165, loss: 0.302448
global_step: 22579, epoch: 165, loss: 0.306915
global_step: 22580, epoch: 165, loss: 0.312991
global_step: 22581, epoch: 165, loss: 0.329053
global_step: 22582, epoch: 165, loss: 0.312942
global_step: 22583, epoch: 165, loss: 0.293032
global_step: 22584, epoch: 165, loss: 0.265112
global_step: 22585, epoch: 165, loss: 0.190690
global_step: 22586, epoch: 165, loss: 0.218884
global_step: 22587, epoch: 165, loss: 0.255314
global_step: 22588, epoch: 165, loss: 0.294850
global_step: 22589, epoch: 165, loss: 0.261224
global_step: 22590, epoch: 165, loss: 0.326950
global_step: 22591, epoch: 165, loss: 0.318065
global_step: 22592, epoch: 165, loss: 0.294515
global_step: 22593, epoch: 165, loss: 0.313075
global_step: 22594, epoch: 165, loss: 0.262445
global_step: 22595, epoch: 165, loss: 0.372116
global_step: 22596, epoch: 165, loss: 0.304108
global_step: 22597, epoch: 165, loss: 0.289054
global_step: 22598, epoch: 165, loss: 0.315697
global_step: 22599, epoch: 165, loss: 0.266319
global_step: 22600, epoch: 165, loss: 0.187976
epoch: 165
train	acc: 0.9573	macro: p 0.9618, r 0.9242, f1: 0.9417	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9570
dev	acc: 0.5663	macro: p 0.4480, r 0.3661, f1: 0.3835	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5322
test	acc: 0.5939	macro: p 0.4203, r 0.3464, f1: 0.3624	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5637
global_step: 22601, epoch: 166, loss: 0.316494
global_step: 22602, epoch: 166, loss: 0.290783
global_step: 22603, epoch: 166, loss: 0.228526
global_step: 22604, epoch: 166, loss: 0.288429
global_step: 22605, epoch: 166, loss: 0.338179
global_step: 22606, epoch: 166, loss: 0.263499
global_step: 22607, epoch: 166, loss: 0.285833
global_step: 22608, epoch: 166, loss: 0.309046
global_step: 22609, epoch: 166, loss: 0.289515
global_step: 22610, epoch: 166, loss: 0.244730
global_step: 22611, epoch: 166, loss: 0.270315
global_step: 22612, epoch: 166, loss: 0.255400
global_step: 22613, epoch: 166, loss: 0.260719
global_step: 22614, epoch: 166, loss: 0.270123
global_step: 22615, epoch: 166, loss: 0.354597
global_step: 22616, epoch: 166, loss: 0.293944
global_step: 22617, epoch: 166, loss: 0.296808
global_step: 22618, epoch: 166, loss: 0.296603
global_step: 22619, epoch: 166, loss: 0.258016
global_step: 22620, epoch: 166, loss: 0.300990
global_step: 22621, epoch: 166, loss: 0.262909
global_step: 22622, epoch: 166, loss: 0.292163
global_step: 22623, epoch: 166, loss: 0.194379
global_step: 22624, epoch: 166, loss: 0.390051
global_step: 22625, epoch: 166, loss: 0.263630
global_step: 22626, epoch: 166, loss: 0.311109
global_step: 22627, epoch: 166, loss: 0.255181
global_step: 22628, epoch: 166, loss: 0.337812
global_step: 22629, epoch: 166, loss: 0.282173
global_step: 22630, epoch: 166, loss: 0.237290
global_step: 22631, epoch: 166, loss: 0.267147
global_step: 22632, epoch: 166, loss: 0.339058
global_step: 22633, epoch: 166, loss: 0.275743
global_step: 22634, epoch: 166, loss: 0.329860
global_step: 22635, epoch: 166, loss: 0.295916
global_step: 22636, epoch: 166, loss: 0.360737
global_step: 22637, epoch: 166, loss: 0.293695
global_step: 22638, epoch: 166, loss: 0.368825
global_step: 22639, epoch: 166, loss: 0.277860
global_step: 22640, epoch: 166, loss: 0.014850
epoch: 166
train	acc: 0.9562	macro: p 0.9606, r 0.9159, f1: 0.9357	micro: p 0.9562, r 0.9562, f1 0.9562	weighted_f1:0.9558
dev	acc: 0.5672	macro: p 0.4449, r 0.3608, f1: 0.3719	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5314
test	acc: 0.5985	macro: p 0.4115, r 0.3482, f1: 0.3561	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5661
global_step: 22641, epoch: 167, loss: 0.291450
global_step: 22642, epoch: 167, loss: 0.308226
global_step: 22643, epoch: 167, loss: 0.240669
global_step: 22644, epoch: 167, loss: 0.276844
global_step: 22645, epoch: 167, loss: 0.282373
global_step: 22646, epoch: 167, loss: 0.266832
global_step: 22647, epoch: 167, loss: 0.297490
global_step: 22648, epoch: 167, loss: 0.340199
global_step: 22649, epoch: 167, loss: 0.188910
global_step: 22650, epoch: 167, loss: 0.328487
global_step: 22651, epoch: 167, loss: 0.279807
global_step: 22652, epoch: 167, loss: 0.328673
global_step: 22653, epoch: 167, loss: 0.256494
global_step: 22654, epoch: 167, loss: 0.308708
global_step: 22655, epoch: 167, loss: 0.261384
global_step: 22656, epoch: 167, loss: 0.217996
global_step: 22657, epoch: 167, loss: 0.297668
global_step: 22658, epoch: 167, loss: 0.243046
global_step: 22659, epoch: 167, loss: 0.320855
global_step: 22660, epoch: 167, loss: 0.260296
global_step: 22661, epoch: 167, loss: 0.222496
global_step: 22662, epoch: 167, loss: 0.305454
global_step: 22663, epoch: 167, loss: 0.393353
global_step: 22664, epoch: 167, loss: 0.268823
global_step: 22665, epoch: 167, loss: 0.296569
global_step: 22666, epoch: 167, loss: 0.232871
global_step: 22667, epoch: 167, loss: 0.251587
global_step: 22668, epoch: 167, loss: 0.267778
global_step: 22669, epoch: 167, loss: 0.254886
global_step: 22670, epoch: 167, loss: 0.252048
global_step: 22671, epoch: 167, loss: 0.246183
global_step: 22672, epoch: 167, loss: 0.285986
global_step: 22673, epoch: 167, loss: 0.341481
global_step: 22674, epoch: 167, loss: 0.269091
global_step: 22675, epoch: 167, loss: 0.257774
global_step: 22676, epoch: 167, loss: 0.316395
global_step: 22677, epoch: 167, loss: 0.278787
global_step: 22678, epoch: 167, loss: 0.305103
global_step: 22679, epoch: 167, loss: 0.275318
global_step: 22680, epoch: 167, loss: 0.370984
epoch: 167
train	acc: 0.9554	macro: p 0.9615, r 0.9186, f1: 0.9384	micro: p 0.9554, r 0.9554, f1 0.9554	weighted_f1:0.9550
dev	acc: 0.5537	macro: p 0.4272, r 0.3596, f1: 0.3729	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5229
test	acc: 0.5854	macro: p 0.3987, r 0.3437, f1: 0.3558	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5582
global_step: 22681, epoch: 168, loss: 0.372282
global_step: 22682, epoch: 168, loss: 0.334600
global_step: 22683, epoch: 168, loss: 0.274517
global_step: 22684, epoch: 168, loss: 0.236421
global_step: 22685, epoch: 168, loss: 0.334358
global_step: 22686, epoch: 168, loss: 0.214149
global_step: 22687, epoch: 168, loss: 0.202474
global_step: 22688, epoch: 168, loss: 0.277559
global_step: 22689, epoch: 168, loss: 0.280739
global_step: 22690, epoch: 168, loss: 0.284530
global_step: 22691, epoch: 168, loss: 0.327502
global_step: 22692, epoch: 168, loss: 0.316971
global_step: 22693, epoch: 168, loss: 0.301430
global_step: 22694, epoch: 168, loss: 0.335683
global_step: 22695, epoch: 168, loss: 0.349571
global_step: 22696, epoch: 168, loss: 0.201620
global_step: 22697, epoch: 168, loss: 0.342763
global_step: 22698, epoch: 168, loss: 0.256637
global_step: 22699, epoch: 168, loss: 0.263009
global_step: 22700, epoch: 168, loss: 0.267737
global_step: 22701, epoch: 168, loss: 0.236341
global_step: 22702, epoch: 168, loss: 0.225424
global_step: 22703, epoch: 168, loss: 0.314415
global_step: 22704, epoch: 168, loss: 0.298039
global_step: 22705, epoch: 168, loss: 0.277716
global_step: 22706, epoch: 168, loss: 0.237474
global_step: 22707, epoch: 168, loss: 0.179827
global_step: 22708, epoch: 168, loss: 0.303291
global_step: 22709, epoch: 168, loss: 0.281993
global_step: 22710, epoch: 168, loss: 0.261916
global_step: 22711, epoch: 168, loss: 0.302181
global_step: 22712, epoch: 168, loss: 0.299049
global_step: 22713, epoch: 168, loss: 0.287525
global_step: 22714, epoch: 168, loss: 0.296616
global_step: 22715, epoch: 168, loss: 0.239644
global_step: 22716, epoch: 168, loss: 0.285721
global_step: 22717, epoch: 168, loss: 0.283897
global_step: 22718, epoch: 168, loss: 0.254659
global_step: 22719, epoch: 168, loss: 0.295956
global_step: 22720, epoch: 168, loss: 0.496563
epoch: 168
train	acc: 0.9578	macro: p 0.9583, r 0.9255, f1: 0.9405	micro: p 0.9578, r 0.9578, f1 0.9578	weighted_f1:0.9576
dev	acc: 0.5582	macro: p 0.4252, r 0.3763, f1: 0.3885	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5370
test	acc: 0.5854	macro: p 0.3928, r 0.3656, f1: 0.3721	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5723
global_step: 22721, epoch: 169, loss: 0.352676
global_step: 22722, epoch: 169, loss: 0.270138
global_step: 22723, epoch: 169, loss: 0.296734
global_step: 22724, epoch: 169, loss: 0.287582
global_step: 22725, epoch: 169, loss: 0.236748
global_step: 22726, epoch: 169, loss: 0.339828
global_step: 22727, epoch: 169, loss: 0.296123
global_step: 22728, epoch: 169, loss: 0.274569
global_step: 22729, epoch: 169, loss: 0.324955
global_step: 22730, epoch: 169, loss: 0.304880
global_step: 22731, epoch: 169, loss: 0.291801
global_step: 22732, epoch: 169, loss: 0.354438
global_step: 22733, epoch: 169, loss: 0.244153
global_step: 22734, epoch: 169, loss: 0.234039
global_step: 22735, epoch: 169, loss: 0.273791
global_step: 22736, epoch: 169, loss: 0.295639
global_step: 22737, epoch: 169, loss: 0.273507
global_step: 22738, epoch: 169, loss: 0.262988
global_step: 22739, epoch: 169, loss: 0.240439
global_step: 22740, epoch: 169, loss: 0.234775
global_step: 22741, epoch: 169, loss: 0.270453
global_step: 22742, epoch: 169, loss: 0.248631
global_step: 22743, epoch: 169, loss: 0.203098
global_step: 22744, epoch: 169, loss: 0.242929
global_step: 22745, epoch: 169, loss: 0.212903
global_step: 22746, epoch: 169, loss: 0.264592
global_step: 22747, epoch: 169, loss: 0.321927
global_step: 22748, epoch: 169, loss: 0.263057
global_step: 22749, epoch: 169, loss: 0.304641
global_step: 22750, epoch: 169, loss: 0.372249
global_step: 22751, epoch: 169, loss: 0.264350
global_step: 22752, epoch: 169, loss: 0.321284
global_step: 22753, epoch: 169, loss: 0.317785
global_step: 22754, epoch: 169, loss: 0.256889
global_step: 22755, epoch: 169, loss: 0.213656
global_step: 22756, epoch: 169, loss: 0.244124
global_step: 22757, epoch: 169, loss: 0.294055
global_step: 22758, epoch: 169, loss: 0.331662
global_step: 22759, epoch: 169, loss: 0.219702
global_step: 22760, epoch: 169, loss: 0.046683
epoch: 169
train	acc: 0.9538	macro: p 0.9610, r 0.9113, f1: 0.9335	micro: p 0.9538, r 0.9538, f1 0.9538	weighted_f1:0.9533
dev	acc: 0.5591	macro: p 0.4314, r 0.3458, f1: 0.3598	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5210
test	acc: 0.5992	macro: p 0.4232, r 0.3402, f1: 0.3559	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5650
global_step: 22761, epoch: 170, loss: 0.317244
global_step: 22762, epoch: 170, loss: 0.338342
global_step: 22763, epoch: 170, loss: 0.325096
global_step: 22764, epoch: 170, loss: 0.218117
global_step: 22765, epoch: 170, loss: 0.310684
global_step: 22766, epoch: 170, loss: 0.287941
global_step: 22767, epoch: 170, loss: 0.236832
global_step: 22768, epoch: 170, loss: 0.279775
global_step: 22769, epoch: 170, loss: 0.217532
global_step: 22770, epoch: 170, loss: 0.221816
global_step: 22771, epoch: 170, loss: 0.313101
global_step: 22772, epoch: 170, loss: 0.232149
global_step: 22773, epoch: 170, loss: 0.296768
global_step: 22774, epoch: 170, loss: 0.294638
global_step: 22775, epoch: 170, loss: 0.176984
global_step: 22776, epoch: 170, loss: 0.297195
global_step: 22777, epoch: 170, loss: 0.278974
global_step: 22778, epoch: 170, loss: 0.217598
global_step: 22779, epoch: 170, loss: 0.276632
global_step: 22780, epoch: 170, loss: 0.265558
global_step: 22781, epoch: 170, loss: 0.285736
global_step: 22782, epoch: 170, loss: 0.231928
global_step: 22783, epoch: 170, loss: 0.253908
global_step: 22784, epoch: 170, loss: 0.264511
global_step: 22785, epoch: 170, loss: 0.233397
global_step: 22786, epoch: 170, loss: 0.287568
global_step: 22787, epoch: 170, loss: 0.249834
global_step: 22788, epoch: 170, loss: 0.273766
global_step: 22789, epoch: 170, loss: 0.267165
global_step: 22790, epoch: 170, loss: 0.350206
global_step: 22791, epoch: 170, loss: 0.271717
global_step: 22792, epoch: 170, loss: 0.269598
global_step: 22793, epoch: 170, loss: 0.278324
global_step: 22794, epoch: 170, loss: 0.248777
global_step: 22795, epoch: 170, loss: 0.299577
global_step: 22796, epoch: 170, loss: 0.276383
global_step: 22797, epoch: 170, loss: 0.296318
global_step: 22798, epoch: 170, loss: 0.340503
global_step: 22799, epoch: 170, loss: 0.254330
global_step: 22800, epoch: 170, loss: 0.229928
epoch: 170
train	acc: 0.9600	macro: p 0.9610, r 0.9299, f1: 0.9444	micro: p 0.9600, r 0.9600, f1 0.9600	weighted_f1:0.9598
dev	acc: 0.5663	macro: p 0.4404, r 0.3754, f1: 0.3924	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5402
test	acc: 0.5916	macro: p 0.4131, r 0.3588, f1: 0.3727	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5703
global_step: 22801, epoch: 171, loss: 0.182666
global_step: 22802, epoch: 171, loss: 0.252292
global_step: 22803, epoch: 171, loss: 0.306167
global_step: 22804, epoch: 171, loss: 0.286639
global_step: 22805, epoch: 171, loss: 0.276059
global_step: 22806, epoch: 171, loss: 0.223286
global_step: 22807, epoch: 171, loss: 0.277747
global_step: 22808, epoch: 171, loss: 0.291177
global_step: 22809, epoch: 171, loss: 0.245549
global_step: 22810, epoch: 171, loss: 0.280835
global_step: 22811, epoch: 171, loss: 0.302186
global_step: 22812, epoch: 171, loss: 0.282395
global_step: 22813, epoch: 171, loss: 0.229643
global_step: 22814, epoch: 171, loss: 0.201167
global_step: 22815, epoch: 171, loss: 0.239158
global_step: 22816, epoch: 171, loss: 0.313676
global_step: 22817, epoch: 171, loss: 0.287816
global_step: 22818, epoch: 171, loss: 0.263491
global_step: 22819, epoch: 171, loss: 0.244435
global_step: 22820, epoch: 171, loss: 0.204894
global_step: 22821, epoch: 171, loss: 0.206548
global_step: 22822, epoch: 171, loss: 0.337037
global_step: 22823, epoch: 171, loss: 0.303790
global_step: 22824, epoch: 171, loss: 0.243255
global_step: 22825, epoch: 171, loss: 0.254881
global_step: 22826, epoch: 171, loss: 0.310432
global_step: 22827, epoch: 171, loss: 0.359384
global_step: 22828, epoch: 171, loss: 0.244229
global_step: 22829, epoch: 171, loss: 0.285059
global_step: 22830, epoch: 171, loss: 0.270457
global_step: 22831, epoch: 171, loss: 0.327713
global_step: 22832, epoch: 171, loss: 0.316128
global_step: 22833, epoch: 171, loss: 0.296350
global_step: 22834, epoch: 171, loss: 0.274571
global_step: 22835, epoch: 171, loss: 0.245915
global_step: 22836, epoch: 171, loss: 0.256801
global_step: 22837, epoch: 171, loss: 0.238651
global_step: 22838, epoch: 171, loss: 0.299376
global_step: 22839, epoch: 171, loss: 0.241255
global_step: 22840, epoch: 171, loss: 0.319125
epoch: 171
train	acc: 0.9598	macro: p 0.9595, r 0.9298, f1: 0.9436	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9596
dev	acc: 0.5672	macro: p 0.4416, r 0.3809, f1: 0.3969	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5412
test	acc: 0.5877	macro: p 0.3903, r 0.3509, f1: 0.3605	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5659
global_step: 22841, epoch: 172, loss: 0.316788
global_step: 22842, epoch: 172, loss: 0.263316
global_step: 22843, epoch: 172, loss: 0.327718
global_step: 22844, epoch: 172, loss: 0.248140
global_step: 22845, epoch: 172, loss: 0.268803
global_step: 22846, epoch: 172, loss: 0.232900
global_step: 22847, epoch: 172, loss: 0.290443
global_step: 22848, epoch: 172, loss: 0.312597
global_step: 22849, epoch: 172, loss: 0.252267
global_step: 22850, epoch: 172, loss: 0.253942
global_step: 22851, epoch: 172, loss: 0.236021
global_step: 22852, epoch: 172, loss: 0.224041
global_step: 22853, epoch: 172, loss: 0.267973
global_step: 22854, epoch: 172, loss: 0.257723
global_step: 22855, epoch: 172, loss: 0.249680
global_step: 22856, epoch: 172, loss: 0.299549
global_step: 22857, epoch: 172, loss: 0.284630
global_step: 22858, epoch: 172, loss: 0.272665
global_step: 22859, epoch: 172, loss: 0.283798
global_step: 22860, epoch: 172, loss: 0.256885
global_step: 22861, epoch: 172, loss: 0.255027
global_step: 22862, epoch: 172, loss: 0.268043
global_step: 22863, epoch: 172, loss: 0.296147
global_step: 22864, epoch: 172, loss: 0.253420
global_step: 22865, epoch: 172, loss: 0.280611
global_step: 22866, epoch: 172, loss: 0.231855
global_step: 22867, epoch: 172, loss: 0.269191
global_step: 22868, epoch: 172, loss: 0.261436
global_step: 22869, epoch: 172, loss: 0.306395
global_step: 22870, epoch: 172, loss: 0.378211
global_step: 22871, epoch: 172, loss: 0.227342
global_step: 22872, epoch: 172, loss: 0.302809
global_step: 22873, epoch: 172, loss: 0.305049
global_step: 22874, epoch: 172, loss: 0.216834
global_step: 22875, epoch: 172, loss: 0.252460
global_step: 22876, epoch: 172, loss: 0.267707
global_step: 22877, epoch: 172, loss: 0.275622
global_step: 22878, epoch: 172, loss: 0.300535
global_step: 22879, epoch: 172, loss: 0.268389
global_step: 22880, epoch: 172, loss: 0.001570
epoch: 172
train	acc: 0.9607	macro: p 0.9615, r 0.9298, f1: 0.9445	micro: p 0.9607, r 0.9607, f1 0.9607	weighted_f1:0.9605
dev	acc: 0.5609	macro: p 0.4270, r 0.3737, f1: 0.3866	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5356
test	acc: 0.5854	macro: p 0.3912, r 0.3558, f1: 0.3645	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5657
global_step: 22881, epoch: 173, loss: 0.223857
global_step: 22882, epoch: 173, loss: 0.290536
global_step: 22883, epoch: 173, loss: 0.277287
global_step: 22884, epoch: 173, loss: 0.257817
global_step: 22885, epoch: 173, loss: 0.226417
global_step: 22886, epoch: 173, loss: 0.283740
global_step: 22887, epoch: 173, loss: 0.350592
global_step: 22888, epoch: 173, loss: 0.283775
global_step: 22889, epoch: 173, loss: 0.204811
global_step: 22890, epoch: 173, loss: 0.240533
global_step: 22891, epoch: 173, loss: 0.269905
global_step: 22892, epoch: 173, loss: 0.282830
global_step: 22893, epoch: 173, loss: 0.265155
global_step: 22894, epoch: 173, loss: 0.265950
global_step: 22895, epoch: 173, loss: 0.286255
global_step: 22896, epoch: 173, loss: 0.256167
global_step: 22897, epoch: 173, loss: 0.211673
global_step: 22898, epoch: 173, loss: 0.281707
global_step: 22899, epoch: 173, loss: 0.171719
global_step: 22900, epoch: 173, loss: 0.207868
global_step: 22901, epoch: 173, loss: 0.238368
global_step: 22902, epoch: 173, loss: 0.327725
global_step: 22903, epoch: 173, loss: 0.231308
global_step: 22904, epoch: 173, loss: 0.209918
global_step: 22905, epoch: 173, loss: 0.301563
global_step: 22906, epoch: 173, loss: 0.319115
global_step: 22907, epoch: 173, loss: 0.375304
global_step: 22908, epoch: 173, loss: 0.197984
global_step: 22909, epoch: 173, loss: 0.335777
global_step: 22910, epoch: 173, loss: 0.341203
global_step: 22911, epoch: 173, loss: 0.247385
global_step: 22912, epoch: 173, loss: 0.246727
global_step: 22913, epoch: 173, loss: 0.255315
global_step: 22914, epoch: 173, loss: 0.272225
global_step: 22915, epoch: 173, loss: 0.246667
global_step: 22916, epoch: 173, loss: 0.219881
global_step: 22917, epoch: 173, loss: 0.260616
global_step: 22918, epoch: 173, loss: 0.303449
global_step: 22919, epoch: 173, loss: 0.253705
global_step: 22920, epoch: 173, loss: 0.063461
epoch: 173
train	acc: 0.9607	macro: p 0.9647, r 0.9311, f1: 0.9468	micro: p 0.9607, r 0.9607, f1 0.9607	weighted_f1:0.9605
dev	acc: 0.5663	macro: p 0.4285, r 0.3566, f1: 0.3719	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5310
test	acc: 0.5950	macro: p 0.4094, r 0.3422, f1: 0.3589	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5639
global_step: 22921, epoch: 174, loss: 0.257074
global_step: 22922, epoch: 174, loss: 0.311441
global_step: 22923, epoch: 174, loss: 0.251256
global_step: 22924, epoch: 174, loss: 0.232458
global_step: 22925, epoch: 174, loss: 0.241709
global_step: 22926, epoch: 174, loss: 0.232121
global_step: 22927, epoch: 174, loss: 0.286461
global_step: 22928, epoch: 174, loss: 0.242328
global_step: 22929, epoch: 174, loss: 0.256660
global_step: 22930, epoch: 174, loss: 0.252856
global_step: 22931, epoch: 174, loss: 0.278280
global_step: 22932, epoch: 174, loss: 0.318204
global_step: 22933, epoch: 174, loss: 0.258890
global_step: 22934, epoch: 174, loss: 0.306374
global_step: 22935, epoch: 174, loss: 0.241506
global_step: 22936, epoch: 174, loss: 0.289469
global_step: 22937, epoch: 174, loss: 0.287318
global_step: 22938, epoch: 174, loss: 0.300808
global_step: 22939, epoch: 174, loss: 0.236287
global_step: 22940, epoch: 174, loss: 0.226171
global_step: 22941, epoch: 174, loss: 0.227939
global_step: 22942, epoch: 174, loss: 0.213226
global_step: 22943, epoch: 174, loss: 0.220749
global_step: 22944, epoch: 174, loss: 0.313644
global_step: 22945, epoch: 174, loss: 0.242152
global_step: 22946, epoch: 174, loss: 0.283730
global_step: 22947, epoch: 174, loss: 0.278596
global_step: 22948, epoch: 174, loss: 0.274195
global_step: 22949, epoch: 174, loss: 0.264416
global_step: 22950, epoch: 174, loss: 0.256431
global_step: 22951, epoch: 174, loss: 0.216809
global_step: 22952, epoch: 174, loss: 0.165973
global_step: 22953, epoch: 174, loss: 0.296511
global_step: 22954, epoch: 174, loss: 0.287449
global_step: 22955, epoch: 174, loss: 0.244271
global_step: 22956, epoch: 174, loss: 0.295684
global_step: 22957, epoch: 174, loss: 0.301391
global_step: 22958, epoch: 174, loss: 0.232427
global_step: 22959, epoch: 174, loss: 0.323095
global_step: 22960, epoch: 174, loss: 0.178944
epoch: 174
train	acc: 0.9594	macro: p 0.9633, r 0.9274, f1: 0.9439	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9592
dev	acc: 0.5663	macro: p 0.4499, r 0.3664, f1: 0.3824	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5353
test	acc: 0.5946	macro: p 0.3960, r 0.3485, f1: 0.3569	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5677
global_step: 22961, epoch: 175, loss: 0.291830
global_step: 22962, epoch: 175, loss: 0.243020
global_step: 22963, epoch: 175, loss: 0.250899
global_step: 22964, epoch: 175, loss: 0.242349
global_step: 22965, epoch: 175, loss: 0.309082
global_step: 22966, epoch: 175, loss: 0.279681
global_step: 22967, epoch: 175, loss: 0.220616
global_step: 22968, epoch: 175, loss: 0.263683
global_step: 22969, epoch: 175, loss: 0.223996
global_step: 22970, epoch: 175, loss: 0.244566
global_step: 22971, epoch: 175, loss: 0.285326
global_step: 22972, epoch: 175, loss: 0.312457
global_step: 22973, epoch: 175, loss: 0.244489
global_step: 22974, epoch: 175, loss: 0.265430
global_step: 22975, epoch: 175, loss: 0.308345
global_step: 22976, epoch: 175, loss: 0.330463
global_step: 22977, epoch: 175, loss: 0.265482
global_step: 22978, epoch: 175, loss: 0.238775
global_step: 22979, epoch: 175, loss: 0.207094
global_step: 22980, epoch: 175, loss: 0.273608
global_step: 22981, epoch: 175, loss: 0.301551
global_step: 22982, epoch: 175, loss: 0.330394
global_step: 22983, epoch: 175, loss: 0.246794
global_step: 22984, epoch: 175, loss: 0.289016
global_step: 22985, epoch: 175, loss: 0.244368
global_step: 22986, epoch: 175, loss: 0.261935
global_step: 22987, epoch: 175, loss: 0.278824
global_step: 22988, epoch: 175, loss: 0.257697
global_step: 22989, epoch: 175, loss: 0.324046
global_step: 22990, epoch: 175, loss: 0.202132
global_step: 22991, epoch: 175, loss: 0.318455
global_step: 22992, epoch: 175, loss: 0.220248
global_step: 22993, epoch: 175, loss: 0.194432
global_step: 22994, epoch: 175, loss: 0.237497
global_step: 22995, epoch: 175, loss: 0.263271
global_step: 22996, epoch: 175, loss: 0.224387
global_step: 22997, epoch: 175, loss: 0.278501
global_step: 22998, epoch: 175, loss: 0.325593
global_step: 22999, epoch: 175, loss: 0.242375
global_step: 23000, epoch: 175, loss: 0.264201
epoch: 175
train	acc: 0.9614	macro: p 0.9637, r 0.9344, f1: 0.9478	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9613
dev	acc: 0.5537	macro: p 0.4035, r 0.3646, f1: 0.3732	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5287
test	acc: 0.5851	macro: p 0.3904, r 0.3605, f1: 0.3685	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5675
global_step: 23001, epoch: 176, loss: 0.243618
global_step: 23002, epoch: 176, loss: 0.287468
global_step: 23003, epoch: 176, loss: 0.262992
global_step: 23004, epoch: 176, loss: 0.240864
global_step: 23005, epoch: 176, loss: 0.240400
global_step: 23006, epoch: 176, loss: 0.255111
global_step: 23007, epoch: 176, loss: 0.237007
global_step: 23008, epoch: 176, loss: 0.248002
global_step: 23009, epoch: 176, loss: 0.258976
global_step: 23010, epoch: 176, loss: 0.265186
global_step: 23011, epoch: 176, loss: 0.182483
global_step: 23012, epoch: 176, loss: 0.280643
global_step: 23013, epoch: 176, loss: 0.276252
global_step: 23014, epoch: 176, loss: 0.280971
global_step: 23015, epoch: 176, loss: 0.275606
global_step: 23016, epoch: 176, loss: 0.288477
global_step: 23017, epoch: 176, loss: 0.282551
global_step: 23018, epoch: 176, loss: 0.261834
global_step: 23019, epoch: 176, loss: 0.205380
global_step: 23020, epoch: 176, loss: 0.270177
global_step: 23021, epoch: 176, loss: 0.206008
global_step: 23022, epoch: 176, loss: 0.238074
global_step: 23023, epoch: 176, loss: 0.296927
global_step: 23024, epoch: 176, loss: 0.255783
global_step: 23025, epoch: 176, loss: 0.202110
global_step: 23026, epoch: 176, loss: 0.210246
global_step: 23027, epoch: 176, loss: 0.250683
global_step: 23028, epoch: 176, loss: 0.264083
global_step: 23029, epoch: 176, loss: 0.269578
global_step: 23030, epoch: 176, loss: 0.287742
global_step: 23031, epoch: 176, loss: 0.250740
global_step: 23032, epoch: 176, loss: 0.170630
global_step: 23033, epoch: 176, loss: 0.365915
global_step: 23034, epoch: 176, loss: 0.328903
global_step: 23035, epoch: 176, loss: 0.289743
global_step: 23036, epoch: 176, loss: 0.294549
global_step: 23037, epoch: 176, loss: 0.305636
global_step: 23038, epoch: 176, loss: 0.218075
global_step: 23039, epoch: 176, loss: 0.266019
global_step: 23040, epoch: 176, loss: 0.359564
epoch: 176
train	acc: 0.9589	macro: p 0.9637, r 0.9253, f1: 0.9428	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9586
dev	acc: 0.5600	macro: p 0.4347, r 0.3612, f1: 0.3750	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5280
test	acc: 0.5862	macro: p 0.4086, r 0.3415, f1: 0.3556	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5580
global_step: 23041, epoch: 177, loss: 0.211679
global_step: 23042, epoch: 177, loss: 0.215533
global_step: 23043, epoch: 177, loss: 0.249654
global_step: 23044, epoch: 177, loss: 0.202028
global_step: 23045, epoch: 177, loss: 0.272134
global_step: 23046, epoch: 177, loss: 0.275361
global_step: 23047, epoch: 177, loss: 0.274283
global_step: 23048, epoch: 177, loss: 0.265973
global_step: 23049, epoch: 177, loss: 0.236301
global_step: 23050, epoch: 177, loss: 0.262101
global_step: 23051, epoch: 177, loss: 0.299284
global_step: 23052, epoch: 177, loss: 0.220128
global_step: 23053, epoch: 177, loss: 0.246449
global_step: 23054, epoch: 177, loss: 0.239745
global_step: 23055, epoch: 177, loss: 0.287560
global_step: 23056, epoch: 177, loss: 0.275826
global_step: 23057, epoch: 177, loss: 0.256734
global_step: 23058, epoch: 177, loss: 0.314481
global_step: 23059, epoch: 177, loss: 0.213433
global_step: 23060, epoch: 177, loss: 0.295256
global_step: 23061, epoch: 177, loss: 0.280053
global_step: 23062, epoch: 177, loss: 0.208900
global_step: 23063, epoch: 177, loss: 0.273781
global_step: 23064, epoch: 177, loss: 0.245413
global_step: 23065, epoch: 177, loss: 0.262430
global_step: 23066, epoch: 177, loss: 0.276079
global_step: 23067, epoch: 177, loss: 0.227861
global_step: 23068, epoch: 177, loss: 0.290882
global_step: 23069, epoch: 177, loss: 0.295131
global_step: 23070, epoch: 177, loss: 0.238790
global_step: 23071, epoch: 177, loss: 0.281679
global_step: 23072, epoch: 177, loss: 0.195640
global_step: 23073, epoch: 177, loss: 0.262918
global_step: 23074, epoch: 177, loss: 0.255309
global_step: 23075, epoch: 177, loss: 0.262332
global_step: 23076, epoch: 177, loss: 0.225066
global_step: 23077, epoch: 177, loss: 0.246708
global_step: 23078, epoch: 177, loss: 0.220748
global_step: 23079, epoch: 177, loss: 0.244141
global_step: 23080, epoch: 177, loss: 0.207834
epoch: 177
train	acc: 0.9563	macro: p 0.9638, r 0.9236, f1: 0.9422	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9560
dev	acc: 0.5600	macro: p 0.4242, r 0.3406, f1: 0.3560	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5173
test	acc: 0.6034	macro: p 0.4158, r 0.3385, f1: 0.3551	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5635
global_step: 23081, epoch: 178, loss: 0.214512
global_step: 23082, epoch: 178, loss: 0.315264
global_step: 23083, epoch: 178, loss: 0.271099
global_step: 23084, epoch: 178, loss: 0.203780
global_step: 23085, epoch: 178, loss: 0.244220
global_step: 23086, epoch: 178, loss: 0.236618
global_step: 23087, epoch: 178, loss: 0.272015
global_step: 23088, epoch: 178, loss: 0.309303
global_step: 23089, epoch: 178, loss: 0.227331
global_step: 23090, epoch: 178, loss: 0.169346
global_step: 23091, epoch: 178, loss: 0.226556
global_step: 23092, epoch: 178, loss: 0.264811
global_step: 23093, epoch: 178, loss: 0.301420
global_step: 23094, epoch: 178, loss: 0.223924
global_step: 23095, epoch: 178, loss: 0.292167
global_step: 23096, epoch: 178, loss: 0.255941
global_step: 23097, epoch: 178, loss: 0.269558
global_step: 23098, epoch: 178, loss: 0.233274
global_step: 23099, epoch: 178, loss: 0.266323
global_step: 23100, epoch: 178, loss: 0.263503
global_step: 23101, epoch: 178, loss: 0.189455
global_step: 23102, epoch: 178, loss: 0.212822
global_step: 23103, epoch: 178, loss: 0.280273
global_step: 23104, epoch: 178, loss: 0.283895
global_step: 23105, epoch: 178, loss: 0.314843
global_step: 23106, epoch: 178, loss: 0.287687
global_step: 23107, epoch: 178, loss: 0.233400
global_step: 23108, epoch: 178, loss: 0.347904
global_step: 23109, epoch: 178, loss: 0.258967
global_step: 23110, epoch: 178, loss: 0.243422
global_step: 23111, epoch: 178, loss: 0.309520
global_step: 23112, epoch: 178, loss: 0.202196
global_step: 23113, epoch: 178, loss: 0.283189
global_step: 23114, epoch: 178, loss: 0.265028
global_step: 23115, epoch: 178, loss: 0.296169
global_step: 23116, epoch: 178, loss: 0.234198
global_step: 23117, epoch: 178, loss: 0.316945
global_step: 23118, epoch: 178, loss: 0.238359
global_step: 23119, epoch: 178, loss: 0.291048
global_step: 23120, epoch: 178, loss: 0.806986
epoch: 178
train	acc: 0.9620	macro: p 0.9648, r 0.9320, f1: 0.9472	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9618
dev	acc: 0.5500	macro: p 0.4116, r 0.3610, f1: 0.3730	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5267
test	acc: 0.5843	macro: p 0.3912, r 0.3552, f1: 0.3647	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5685
global_step: 23121, epoch: 179, loss: 0.239636
global_step: 23122, epoch: 179, loss: 0.223316
global_step: 23123, epoch: 179, loss: 0.313853
global_step: 23124, epoch: 179, loss: 0.316909
global_step: 23125, epoch: 179, loss: 0.225936
global_step: 23126, epoch: 179, loss: 0.309912
global_step: 23127, epoch: 179, loss: 0.241041
global_step: 23128, epoch: 179, loss: 0.254513
global_step: 23129, epoch: 179, loss: 0.248595
global_step: 23130, epoch: 179, loss: 0.268403
global_step: 23131, epoch: 179, loss: 0.212185
global_step: 23132, epoch: 179, loss: 0.197140
global_step: 23133, epoch: 179, loss: 0.252975
global_step: 23134, epoch: 179, loss: 0.262152
global_step: 23135, epoch: 179, loss: 0.255074
global_step: 23136, epoch: 179, loss: 0.262013
global_step: 23137, epoch: 179, loss: 0.246380
global_step: 23138, epoch: 179, loss: 0.268402
global_step: 23139, epoch: 179, loss: 0.204822
global_step: 23140, epoch: 179, loss: 0.371397
global_step: 23141, epoch: 179, loss: 0.295023
global_step: 23142, epoch: 179, loss: 0.301774
global_step: 23143, epoch: 179, loss: 0.229072
global_step: 23144, epoch: 179, loss: 0.280070
global_step: 23145, epoch: 179, loss: 0.299271
global_step: 23146, epoch: 179, loss: 0.240773
global_step: 23147, epoch: 179, loss: 0.275941
global_step: 23148, epoch: 179, loss: 0.237375
global_step: 23149, epoch: 179, loss: 0.272435
global_step: 23150, epoch: 179, loss: 0.244498
global_step: 23151, epoch: 179, loss: 0.275535
global_step: 23152, epoch: 179, loss: 0.237920
global_step: 23153, epoch: 179, loss: 0.233393
global_step: 23154, epoch: 179, loss: 0.222144
global_step: 23155, epoch: 179, loss: 0.261702
global_step: 23156, epoch: 179, loss: 0.284068
global_step: 23157, epoch: 179, loss: 0.220028
global_step: 23158, epoch: 179, loss: 0.257215
global_step: 23159, epoch: 179, loss: 0.195103
global_step: 23160, epoch: 179, loss: 0.047326
epoch: 179
train	acc: 0.9615	macro: p 0.9662, r 0.9310, f1: 0.9471	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9613
dev	acc: 0.5609	macro: p 0.4510, r 0.3681, f1: 0.3825	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5304
test	acc: 0.5950	macro: p 0.3912, r 0.3457, f1: 0.3514	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5668
global_step: 23161, epoch: 180, loss: 0.220668
global_step: 23162, epoch: 180, loss: 0.263298
global_step: 23163, epoch: 180, loss: 0.246427
global_step: 23164, epoch: 180, loss: 0.221716
global_step: 23165, epoch: 180, loss: 0.249625
global_step: 23166, epoch: 180, loss: 0.251281
global_step: 23167, epoch: 180, loss: 0.305701
global_step: 23168, epoch: 180, loss: 0.353145
global_step: 23169, epoch: 180, loss: 0.266780
global_step: 23170, epoch: 180, loss: 0.234972
global_step: 23171, epoch: 180, loss: 0.257139
global_step: 23172, epoch: 180, loss: 0.237163
global_step: 23173, epoch: 180, loss: 0.215259
global_step: 23174, epoch: 180, loss: 0.274006
global_step: 23175, epoch: 180, loss: 0.262267
global_step: 23176, epoch: 180, loss: 0.227813
global_step: 23177, epoch: 180, loss: 0.261365
global_step: 23178, epoch: 180, loss: 0.247084
global_step: 23179, epoch: 180, loss: 0.219928
global_step: 23180, epoch: 180, loss: 0.247614
global_step: 23181, epoch: 180, loss: 0.318313
global_step: 23182, epoch: 180, loss: 0.221589
global_step: 23183, epoch: 180, loss: 0.245079
global_step: 23184, epoch: 180, loss: 0.305772
global_step: 23185, epoch: 180, loss: 0.208852
global_step: 23186, epoch: 180, loss: 0.278121
global_step: 23187, epoch: 180, loss: 0.224972
global_step: 23188, epoch: 180, loss: 0.228923
global_step: 23189, epoch: 180, loss: 0.222936
global_step: 23190, epoch: 180, loss: 0.281297
global_step: 23191, epoch: 180, loss: 0.288562
global_step: 23192, epoch: 180, loss: 0.303591
global_step: 23193, epoch: 180, loss: 0.296131
global_step: 23194, epoch: 180, loss: 0.244603
global_step: 23195, epoch: 180, loss: 0.182962
global_step: 23196, epoch: 180, loss: 0.297020
global_step: 23197, epoch: 180, loss: 0.237030
global_step: 23198, epoch: 180, loss: 0.292065
global_step: 23199, epoch: 180, loss: 0.331268
global_step: 23200, epoch: 180, loss: 0.892117
epoch: 180
train	acc: 0.9622	macro: p 0.9662, r 0.9355, f1: 0.9498	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9620
dev	acc: 0.5546	macro: p 0.4204, r 0.3547, f1: 0.3704	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5223
test	acc: 0.5900	macro: p 0.4051, r 0.3461, f1: 0.3615	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5615
global_step: 23201, epoch: 181, loss: 0.311052
global_step: 23202, epoch: 181, loss: 0.263702
global_step: 23203, epoch: 181, loss: 0.203755
global_step: 23204, epoch: 181, loss: 0.366838
global_step: 23205, epoch: 181, loss: 0.233666
global_step: 23206, epoch: 181, loss: 0.244930
global_step: 23207, epoch: 181, loss: 0.255262
global_step: 23208, epoch: 181, loss: 0.251881
global_step: 23209, epoch: 181, loss: 0.256876
global_step: 23210, epoch: 181, loss: 0.262919
global_step: 23211, epoch: 181, loss: 0.196828
global_step: 23212, epoch: 181, loss: 0.263943
global_step: 23213, epoch: 181, loss: 0.202783
global_step: 23214, epoch: 181, loss: 0.223556
global_step: 23215, epoch: 181, loss: 0.216139
global_step: 23216, epoch: 181, loss: 0.253134
global_step: 23217, epoch: 181, loss: 0.241329
global_step: 23218, epoch: 181, loss: 0.245871
global_step: 23219, epoch: 181, loss: 0.265227
global_step: 23220, epoch: 181, loss: 0.178533
global_step: 23221, epoch: 181, loss: 0.288736
global_step: 23222, epoch: 181, loss: 0.344873
global_step: 23223, epoch: 181, loss: 0.202823
global_step: 23224, epoch: 181, loss: 0.306644
global_step: 23225, epoch: 181, loss: 0.293997
global_step: 23226, epoch: 181, loss: 0.243793
global_step: 23227, epoch: 181, loss: 0.262903
global_step: 23228, epoch: 181, loss: 0.249937
global_step: 23229, epoch: 181, loss: 0.353487
global_step: 23230, epoch: 181, loss: 0.261584
global_step: 23231, epoch: 181, loss: 0.276569
global_step: 23232, epoch: 181, loss: 0.206949
global_step: 23233, epoch: 181, loss: 0.218406
global_step: 23234, epoch: 181, loss: 0.239952
global_step: 23235, epoch: 181, loss: 0.278815
global_step: 23236, epoch: 181, loss: 0.272571
global_step: 23237, epoch: 181, loss: 0.237627
global_step: 23238, epoch: 181, loss: 0.262389
global_step: 23239, epoch: 181, loss: 0.278737
global_step: 23240, epoch: 181, loss: 1.039955
epoch: 181
train	acc: 0.9610	macro: p 0.9616, r 0.9330, f1: 0.9459	micro: p 0.9610, r 0.9610, f1 0.9610	weighted_f1:0.9609
dev	acc: 0.5591	macro: p 0.4266, r 0.3842, f1: 0.3941	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5381
test	acc: 0.5808	macro: p 0.3781, r 0.3598, f1: 0.3614	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5645
global_step: 23241, epoch: 182, loss: 0.264866
global_step: 23242, epoch: 182, loss: 0.218933
global_step: 23243, epoch: 182, loss: 0.272056
global_step: 23244, epoch: 182, loss: 0.231979
global_step: 23245, epoch: 182, loss: 0.266874
global_step: 23246, epoch: 182, loss: 0.246013
global_step: 23247, epoch: 182, loss: 0.234478
global_step: 23248, epoch: 182, loss: 0.237951
global_step: 23249, epoch: 182, loss: 0.248973
global_step: 23250, epoch: 182, loss: 0.221807
global_step: 23251, epoch: 182, loss: 0.221367
global_step: 23252, epoch: 182, loss: 0.253856
global_step: 23253, epoch: 182, loss: 0.216326
global_step: 23254, epoch: 182, loss: 0.261671
global_step: 23255, epoch: 182, loss: 0.234015
global_step: 23256, epoch: 182, loss: 0.291288
global_step: 23257, epoch: 182, loss: 0.211932
global_step: 23258, epoch: 182, loss: 0.286483
global_step: 23259, epoch: 182, loss: 0.262413
global_step: 23260, epoch: 182, loss: 0.274424
global_step: 23261, epoch: 182, loss: 0.299111
global_step: 23262, epoch: 182, loss: 0.252775
global_step: 23263, epoch: 182, loss: 0.303707
global_step: 23264, epoch: 182, loss: 0.273625
global_step: 23265, epoch: 182, loss: 0.285843
global_step: 23266, epoch: 182, loss: 0.175113
global_step: 23267, epoch: 182, loss: 0.248787
global_step: 23268, epoch: 182, loss: 0.306954
global_step: 23269, epoch: 182, loss: 0.339507
global_step: 23270, epoch: 182, loss: 0.216779
global_step: 23271, epoch: 182, loss: 0.199650
global_step: 23272, epoch: 182, loss: 0.186884
global_step: 23273, epoch: 182, loss: 0.262783
global_step: 23274, epoch: 182, loss: 0.245800
global_step: 23275, epoch: 182, loss: 0.247767
global_step: 23276, epoch: 182, loss: 0.243863
global_step: 23277, epoch: 182, loss: 0.326360
global_step: 23278, epoch: 182, loss: 0.170050
global_step: 23279, epoch: 182, loss: 0.259728
global_step: 23280, epoch: 182, loss: 0.007632
epoch: 182
train	acc: 0.9622	macro: p 0.9664, r 0.9330, f1: 0.9483	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9620
dev	acc: 0.5681	macro: p 0.4447, r 0.3756, f1: 0.3864	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5396
test	acc: 0.5843	macro: p 0.3846, r 0.3446, f1: 0.3497	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5596
global_step: 23281, epoch: 183, loss: 0.245404
global_step: 23282, epoch: 183, loss: 0.214015
global_step: 23283, epoch: 183, loss: 0.204195
global_step: 23284, epoch: 183, loss: 0.196331
global_step: 23285, epoch: 183, loss: 0.228046
global_step: 23286, epoch: 183, loss: 0.238771
global_step: 23287, epoch: 183, loss: 0.233641
global_step: 23288, epoch: 183, loss: 0.272724
global_step: 23289, epoch: 183, loss: 0.230830
global_step: 23290, epoch: 183, loss: 0.274132
global_step: 23291, epoch: 183, loss: 0.190161
global_step: 23292, epoch: 183, loss: 0.198812
global_step: 23293, epoch: 183, loss: 0.249638
global_step: 23294, epoch: 183, loss: 0.306082
global_step: 23295, epoch: 183, loss: 0.272302
global_step: 23296, epoch: 183, loss: 0.254105
global_step: 23297, epoch: 183, loss: 0.284970
global_step: 23298, epoch: 183, loss: 0.242684
global_step: 23299, epoch: 183, loss: 0.187748
global_step: 23300, epoch: 183, loss: 0.234493
global_step: 23301, epoch: 183, loss: 0.247802
global_step: 23302, epoch: 183, loss: 0.178250
global_step: 23303, epoch: 183, loss: 0.217131
global_step: 23304, epoch: 183, loss: 0.225452
global_step: 23305, epoch: 183, loss: 0.300977
global_step: 23306, epoch: 183, loss: 0.312712
global_step: 23307, epoch: 183, loss: 0.225984
global_step: 23308, epoch: 183, loss: 0.254194
global_step: 23309, epoch: 183, loss: 0.227432
global_step: 23310, epoch: 183, loss: 0.283057
global_step: 23311, epoch: 183, loss: 0.360039
global_step: 23312, epoch: 183, loss: 0.300803
global_step: 23313, epoch: 183, loss: 0.291948
global_step: 23314, epoch: 183, loss: 0.215359
global_step: 23315, epoch: 183, loss: 0.278343
global_step: 23316, epoch: 183, loss: 0.307858
global_step: 23317, epoch: 183, loss: 0.236260
global_step: 23318, epoch: 183, loss: 0.211222
global_step: 23319, epoch: 183, loss: 0.263775
global_step: 23320, epoch: 183, loss: 0.231979
epoch: 183
train	acc: 0.9608	macro: p 0.9653, r 0.9286, f1: 0.9455	micro: p 0.9608, r 0.9608, f1 0.9608	weighted_f1:0.9606
dev	acc: 0.5663	macro: p 0.4779, r 0.3675, f1: 0.3826	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5303
test	acc: 0.5939	macro: p 0.3931, r 0.3403, f1: 0.3480	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5607
global_step: 23321, epoch: 184, loss: 0.267863
global_step: 23322, epoch: 184, loss: 0.264343
global_step: 23323, epoch: 184, loss: 0.186367
global_step: 23324, epoch: 184, loss: 0.204197
global_step: 23325, epoch: 184, loss: 0.320334
global_step: 23326, epoch: 184, loss: 0.289389
global_step: 23327, epoch: 184, loss: 0.260040
global_step: 23328, epoch: 184, loss: 0.244434
global_step: 23329, epoch: 184, loss: 0.189224
global_step: 23330, epoch: 184, loss: 0.258952
global_step: 23331, epoch: 184, loss: 0.231844
global_step: 23332, epoch: 184, loss: 0.293708
global_step: 23333, epoch: 184, loss: 0.297273
global_step: 23334, epoch: 184, loss: 0.233426
global_step: 23335, epoch: 184, loss: 0.275818
global_step: 23336, epoch: 184, loss: 0.282008
global_step: 23337, epoch: 184, loss: 0.223886
global_step: 23338, epoch: 184, loss: 0.224784
global_step: 23339, epoch: 184, loss: 0.237369
global_step: 23340, epoch: 184, loss: 0.289275
global_step: 23341, epoch: 184, loss: 0.259544
global_step: 23342, epoch: 184, loss: 0.233334
global_step: 23343, epoch: 184, loss: 0.375026
global_step: 23344, epoch: 184, loss: 0.284112
global_step: 23345, epoch: 184, loss: 0.237506
global_step: 23346, epoch: 184, loss: 0.262239
global_step: 23347, epoch: 184, loss: 0.242470
global_step: 23348, epoch: 184, loss: 0.268330
global_step: 23349, epoch: 184, loss: 0.238462
global_step: 23350, epoch: 184, loss: 0.227398
global_step: 23351, epoch: 184, loss: 0.326352
global_step: 23352, epoch: 184, loss: 0.245033
global_step: 23353, epoch: 184, loss: 0.260662
global_step: 23354, epoch: 184, loss: 0.236540
global_step: 23355, epoch: 184, loss: 0.248449
global_step: 23356, epoch: 184, loss: 0.224544
global_step: 23357, epoch: 184, loss: 0.223119
global_step: 23358, epoch: 184, loss: 0.272691
global_step: 23359, epoch: 184, loss: 0.180614
global_step: 23360, epoch: 184, loss: 0.174803
epoch: 184
train	acc: 0.9621	macro: p 0.9653, r 0.9331, f1: 0.9480	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9620
dev	acc: 0.5618	macro: p 0.4414, r 0.3657, f1: 0.3765	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5306
test	acc: 0.5904	macro: p 0.3857, r 0.3504, f1: 0.3544	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5648
global_step: 23361, epoch: 185, loss: 0.221688
global_step: 23362, epoch: 185, loss: 0.236226
global_step: 23363, epoch: 185, loss: 0.248009
global_step: 23364, epoch: 185, loss: 0.202470
global_step: 23365, epoch: 185, loss: 0.237682
global_step: 23366, epoch: 185, loss: 0.342380
global_step: 23367, epoch: 185, loss: 0.301899
global_step: 23368, epoch: 185, loss: 0.243864
global_step: 23369, epoch: 185, loss: 0.189339
global_step: 23370, epoch: 185, loss: 0.202064
global_step: 23371, epoch: 185, loss: 0.325911
global_step: 23372, epoch: 185, loss: 0.253718
global_step: 23373, epoch: 185, loss: 0.251491
global_step: 23374, epoch: 185, loss: 0.280313
global_step: 23375, epoch: 185, loss: 0.244096
global_step: 23376, epoch: 185, loss: 0.223200
global_step: 23377, epoch: 185, loss: 0.221639
global_step: 23378, epoch: 185, loss: 0.299382
global_step: 23379, epoch: 185, loss: 0.227545
global_step: 23380, epoch: 185, loss: 0.250402
global_step: 23381, epoch: 185, loss: 0.249954
global_step: 23382, epoch: 185, loss: 0.215987
global_step: 23383, epoch: 185, loss: 0.235856
global_step: 23384, epoch: 185, loss: 0.261311
global_step: 23385, epoch: 185, loss: 0.264841
global_step: 23386, epoch: 185, loss: 0.219928
global_step: 23387, epoch: 185, loss: 0.217149
global_step: 23388, epoch: 185, loss: 0.274065
global_step: 23389, epoch: 185, loss: 0.232438
global_step: 23390, epoch: 185, loss: 0.243883
global_step: 23391, epoch: 185, loss: 0.242786
global_step: 23392, epoch: 185, loss: 0.258087
global_step: 23393, epoch: 185, loss: 0.259655
global_step: 23394, epoch: 185, loss: 0.210112
global_step: 23395, epoch: 185, loss: 0.204229
global_step: 23396, epoch: 185, loss: 0.319061
global_step: 23397, epoch: 185, loss: 0.274139
global_step: 23398, epoch: 185, loss: 0.221637
global_step: 23399, epoch: 185, loss: 0.241596
global_step: 23400, epoch: 185, loss: 0.063095
epoch: 185
train	acc: 0.9630	macro: p 0.9658, r 0.9366, f1: 0.9503	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9629
dev	acc: 0.5591	macro: p 0.4462, r 0.3693, f1: 0.3839	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5294
test	acc: 0.5931	macro: p 0.3902, r 0.3504, f1: 0.3590	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5676
global_step: 23401, epoch: 186, loss: 0.249578
global_step: 23402, epoch: 186, loss: 0.294714
global_step: 23403, epoch: 186, loss: 0.242020
global_step: 23404, epoch: 186, loss: 0.205210
global_step: 23405, epoch: 186, loss: 0.210994
global_step: 23406, epoch: 186, loss: 0.255980
global_step: 23407, epoch: 186, loss: 0.219512
global_step: 23408, epoch: 186, loss: 0.224237
global_step: 23409, epoch: 186, loss: 0.252530
global_step: 23410, epoch: 186, loss: 0.304421
global_step: 23411, epoch: 186, loss: 0.209966
global_step: 23412, epoch: 186, loss: 0.297527
global_step: 23413, epoch: 186, loss: 0.276081
global_step: 23414, epoch: 186, loss: 0.278127
global_step: 23415, epoch: 186, loss: 0.210661
global_step: 23416, epoch: 186, loss: 0.253685
global_step: 23417, epoch: 186, loss: 0.288492
global_step: 23418, epoch: 186, loss: 0.274624
global_step: 23419, epoch: 186, loss: 0.244985
global_step: 23420, epoch: 186, loss: 0.276108
global_step: 23421, epoch: 186, loss: 0.175768
global_step: 23422, epoch: 186, loss: 0.275442
global_step: 23423, epoch: 186, loss: 0.195098
global_step: 23424, epoch: 186, loss: 0.279874
global_step: 23425, epoch: 186, loss: 0.235748
global_step: 23426, epoch: 186, loss: 0.247222
global_step: 23427, epoch: 186, loss: 0.237858
global_step: 23428, epoch: 186, loss: 0.190529
global_step: 23429, epoch: 186, loss: 0.235963
global_step: 23430, epoch: 186, loss: 0.293842
global_step: 23431, epoch: 186, loss: 0.258974
global_step: 23432, epoch: 186, loss: 0.303820
global_step: 23433, epoch: 186, loss: 0.238093
global_step: 23434, epoch: 186, loss: 0.203324
global_step: 23435, epoch: 186, loss: 0.314665
global_step: 23436, epoch: 186, loss: 0.289875
global_step: 23437, epoch: 186, loss: 0.259789
global_step: 23438, epoch: 186, loss: 0.260960
global_step: 23439, epoch: 186, loss: 0.192997
global_step: 23440, epoch: 186, loss: 0.065217
epoch: 186
train	acc: 0.9599	macro: p 0.9655, r 0.9316, f1: 0.9475	micro: p 0.9599, r 0.9599, f1 0.9599	weighted_f1:0.9597
dev	acc: 0.5618	macro: p 0.4605, r 0.3696, f1: 0.3849	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5322
test	acc: 0.5870	macro: p 0.3922, r 0.3448, f1: 0.3555	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5612
global_step: 23441, epoch: 187, loss: 0.184705
global_step: 23442, epoch: 187, loss: 0.296013
global_step: 23443, epoch: 187, loss: 0.272199
global_step: 23444, epoch: 187, loss: 0.243716
global_step: 23445, epoch: 187, loss: 0.296668
global_step: 23446, epoch: 187, loss: 0.165992
global_step: 23447, epoch: 187, loss: 0.202691
global_step: 23448, epoch: 187, loss: 0.242225
global_step: 23449, epoch: 187, loss: 0.245249
global_step: 23450, epoch: 187, loss: 0.254938
global_step: 23451, epoch: 187, loss: 0.291828
global_step: 23452, epoch: 187, loss: 0.247042
global_step: 23453, epoch: 187, loss: 0.254079
global_step: 23454, epoch: 187, loss: 0.250741
global_step: 23455, epoch: 187, loss: 0.246681
global_step: 23456, epoch: 187, loss: 0.248994
global_step: 23457, epoch: 187, loss: 0.237079
global_step: 23458, epoch: 187, loss: 0.227033
global_step: 23459, epoch: 187, loss: 0.182988
global_step: 23460, epoch: 187, loss: 0.280332
global_step: 23461, epoch: 187, loss: 0.208316
global_step: 23462, epoch: 187, loss: 0.203727
global_step: 23463, epoch: 187, loss: 0.334044
global_step: 23464, epoch: 187, loss: 0.218740
global_step: 23465, epoch: 187, loss: 0.279623
global_step: 23466, epoch: 187, loss: 0.251942
global_step: 23467, epoch: 187, loss: 0.293360
global_step: 23468, epoch: 187, loss: 0.266532
global_step: 23469, epoch: 187, loss: 0.307943
global_step: 23470, epoch: 187, loss: 0.232941
global_step: 23471, epoch: 187, loss: 0.235787
global_step: 23472, epoch: 187, loss: 0.233480
global_step: 23473, epoch: 187, loss: 0.255032
global_step: 23474, epoch: 187, loss: 0.324441
global_step: 23475, epoch: 187, loss: 0.309479
global_step: 23476, epoch: 187, loss: 0.287878
global_step: 23477, epoch: 187, loss: 0.211032
global_step: 23478, epoch: 187, loss: 0.276022
global_step: 23479, epoch: 187, loss: 0.257411
global_step: 23480, epoch: 187, loss: 0.016645
epoch: 187
train	acc: 0.9627	macro: p 0.9662, r 0.9363, f1: 0.9503	micro: p 0.9627, r 0.9627, f1 0.9627	weighted_f1:0.9626
dev	acc: 0.5744	macro: p 0.4703, r 0.3860, f1: 0.4051	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5452
test	acc: 0.5954	macro: p 0.3980, r 0.3565, f1: 0.3664	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5699
global_step: 23481, epoch: 188, loss: 0.251831
global_step: 23482, epoch: 188, loss: 0.232771
global_step: 23483, epoch: 188, loss: 0.224008
global_step: 23484, epoch: 188, loss: 0.249616
global_step: 23485, epoch: 188, loss: 0.276012
global_step: 23486, epoch: 188, loss: 0.220975
global_step: 23487, epoch: 188, loss: 0.190132
global_step: 23488, epoch: 188, loss: 0.216393
global_step: 23489, epoch: 188, loss: 0.303235
global_step: 23490, epoch: 188, loss: 0.287756
global_step: 23491, epoch: 188, loss: 0.167176
global_step: 23492, epoch: 188, loss: 0.265866
global_step: 23493, epoch: 188, loss: 0.280075
global_step: 23494, epoch: 188, loss: 0.304787
global_step: 23495, epoch: 188, loss: 0.196069
global_step: 23496, epoch: 188, loss: 0.298702
global_step: 23497, epoch: 188, loss: 0.197718
global_step: 23498, epoch: 188, loss: 0.235568
global_step: 23499, epoch: 188, loss: 0.298609
global_step: 23500, epoch: 188, loss: 0.332937
global_step: 23501, epoch: 188, loss: 0.240473
global_step: 23502, epoch: 188, loss: 0.177439
global_step: 23503, epoch: 188, loss: 0.260951
global_step: 23504, epoch: 188, loss: 0.267078
global_step: 23505, epoch: 188, loss: 0.267582
global_step: 23506, epoch: 188, loss: 0.220790
global_step: 23507, epoch: 188, loss: 0.254017
global_step: 23508, epoch: 188, loss: 0.214817
global_step: 23509, epoch: 188, loss: 0.252767
global_step: 23510, epoch: 188, loss: 0.242802
global_step: 23511, epoch: 188, loss: 0.210506
global_step: 23512, epoch: 188, loss: 0.272763
global_step: 23513, epoch: 188, loss: 0.290727
global_step: 23514, epoch: 188, loss: 0.274309
global_step: 23515, epoch: 188, loss: 0.218286
global_step: 23516, epoch: 188, loss: 0.245061
global_step: 23517, epoch: 188, loss: 0.202055
global_step: 23518, epoch: 188, loss: 0.214640
global_step: 23519, epoch: 188, loss: 0.249507
global_step: 23520, epoch: 188, loss: 0.457194
epoch: 188
train	acc: 0.9629	macro: p 0.9667, r 0.9377, f1: 0.9512	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9628
dev	acc: 0.5681	macro: p 0.4660, r 0.3714, f1: 0.3881	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5355
test	acc: 0.5954	macro: p 0.4088, r 0.3540, f1: 0.3674	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5678
global_step: 23521, epoch: 189, loss: 0.241127
global_step: 23522, epoch: 189, loss: 0.200029
global_step: 23523, epoch: 189, loss: 0.234519
global_step: 23524, epoch: 189, loss: 0.197290
global_step: 23525, epoch: 189, loss: 0.216530
global_step: 23526, epoch: 189, loss: 0.209636
global_step: 23527, epoch: 189, loss: 0.209502
global_step: 23528, epoch: 189, loss: 0.282503
global_step: 23529, epoch: 189, loss: 0.251068
global_step: 23530, epoch: 189, loss: 0.205984
global_step: 23531, epoch: 189, loss: 0.286752
global_step: 23532, epoch: 189, loss: 0.260384
global_step: 23533, epoch: 189, loss: 0.182506
global_step: 23534, epoch: 189, loss: 0.290466
global_step: 23535, epoch: 189, loss: 0.224182
global_step: 23536, epoch: 189, loss: 0.223912
global_step: 23537, epoch: 189, loss: 0.234772
global_step: 23538, epoch: 189, loss: 0.234912
global_step: 23539, epoch: 189, loss: 0.284784
global_step: 23540, epoch: 189, loss: 0.236595
global_step: 23541, epoch: 189, loss: 0.201451
global_step: 23542, epoch: 189, loss: 0.220022
global_step: 23543, epoch: 189, loss: 0.285754
global_step: 23544, epoch: 189, loss: 0.226239
global_step: 23545, epoch: 189, loss: 0.242283
global_step: 23546, epoch: 189, loss: 0.299432
global_step: 23547, epoch: 189, loss: 0.229658
global_step: 23548, epoch: 189, loss: 0.280403
global_step: 23549, epoch: 189, loss: 0.237825
global_step: 23550, epoch: 189, loss: 0.240431
global_step: 23551, epoch: 189, loss: 0.237518
global_step: 23552, epoch: 189, loss: 0.268880
global_step: 23553, epoch: 189, loss: 0.282376
global_step: 23554, epoch: 189, loss: 0.242372
global_step: 23555, epoch: 189, loss: 0.247657
global_step: 23556, epoch: 189, loss: 0.250232
global_step: 23557, epoch: 189, loss: 0.187760
global_step: 23558, epoch: 189, loss: 0.298146
global_step: 23559, epoch: 189, loss: 0.275814
global_step: 23560, epoch: 189, loss: 0.008832
epoch: 189
train	acc: 0.9634	macro: p 0.9673, r 0.9385, f1: 0.9520	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9632
dev	acc: 0.5573	macro: p 0.4528, r 0.3622, f1: 0.3731	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5233
test	acc: 0.5847	macro: p 0.3850, r 0.3389, f1: 0.3451	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5545
global_step: 23561, epoch: 190, loss: 0.261539
global_step: 23562, epoch: 190, loss: 0.246855
global_step: 23563, epoch: 190, loss: 0.249232
global_step: 23564, epoch: 190, loss: 0.194451
global_step: 23565, epoch: 190, loss: 0.207196
global_step: 23566, epoch: 190, loss: 0.288143
global_step: 23567, epoch: 190, loss: 0.260871
global_step: 23568, epoch: 190, loss: 0.179118
global_step: 23569, epoch: 190, loss: 0.248024
global_step: 23570, epoch: 190, loss: 0.262143
global_step: 23571, epoch: 190, loss: 0.253438
global_step: 23572, epoch: 190, loss: 0.187799
global_step: 23573, epoch: 190, loss: 0.241316
global_step: 23574, epoch: 190, loss: 0.201758
global_step: 23575, epoch: 190, loss: 0.208610
global_step: 23576, epoch: 190, loss: 0.229087
global_step: 23577, epoch: 190, loss: 0.280167
global_step: 23578, epoch: 190, loss: 0.187671
global_step: 23579, epoch: 190, loss: 0.303720
global_step: 23580, epoch: 190, loss: 0.258268
global_step: 23581, epoch: 190, loss: 0.180645
global_step: 23582, epoch: 190, loss: 0.276074
global_step: 23583, epoch: 190, loss: 0.235653
global_step: 23584, epoch: 190, loss: 0.222823
global_step: 23585, epoch: 190, loss: 0.227719
global_step: 23586, epoch: 190, loss: 0.200070
global_step: 23587, epoch: 190, loss: 0.307839
global_step: 23588, epoch: 190, loss: 0.278515
global_step: 23589, epoch: 190, loss: 0.242436
global_step: 23590, epoch: 190, loss: 0.237813
global_step: 23591, epoch: 190, loss: 0.289928
global_step: 23592, epoch: 190, loss: 0.255060
global_step: 23593, epoch: 190, loss: 0.271331
global_step: 23594, epoch: 190, loss: 0.230228
global_step: 23595, epoch: 190, loss: 0.185267
global_step: 23596, epoch: 190, loss: 0.253005
global_step: 23597, epoch: 190, loss: 0.296148
global_step: 23598, epoch: 190, loss: 0.279575
global_step: 23599, epoch: 190, loss: 0.241355
global_step: 23600, epoch: 190, loss: 0.024950
epoch: 190
train	acc: 0.9629	macro: p 0.9672, r 0.9384, f1: 0.9518	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9628
dev	acc: 0.5618	macro: p 0.4199, r 0.3658, f1: 0.3783	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5322
test	acc: 0.5935	macro: p 0.3961, r 0.3525, f1: 0.3640	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5694
global_step: 23601, epoch: 191, loss: 0.240957
global_step: 23602, epoch: 191, loss: 0.235505
global_step: 23603, epoch: 191, loss: 0.241286
global_step: 23604, epoch: 191, loss: 0.251586
global_step: 23605, epoch: 191, loss: 0.209585
global_step: 23606, epoch: 191, loss: 0.307477
global_step: 23607, epoch: 191, loss: 0.300810
global_step: 23608, epoch: 191, loss: 0.209994
global_step: 23609, epoch: 191, loss: 0.275394
global_step: 23610, epoch: 191, loss: 0.243393
global_step: 23611, epoch: 191, loss: 0.186008
global_step: 23612, epoch: 191, loss: 0.310097
global_step: 23613, epoch: 191, loss: 0.255160
global_step: 23614, epoch: 191, loss: 0.312713
global_step: 23615, epoch: 191, loss: 0.205263
global_step: 23616, epoch: 191, loss: 0.271113
global_step: 23617, epoch: 191, loss: 0.200062
global_step: 23618, epoch: 191, loss: 0.210195
global_step: 23619, epoch: 191, loss: 0.180321
global_step: 23620, epoch: 191, loss: 0.278818
global_step: 23621, epoch: 191, loss: 0.296231
global_step: 23622, epoch: 191, loss: 0.263130
global_step: 23623, epoch: 191, loss: 0.187260
global_step: 23624, epoch: 191, loss: 0.280438
global_step: 23625, epoch: 191, loss: 0.296934
global_step: 23626, epoch: 191, loss: 0.203884
global_step: 23627, epoch: 191, loss: 0.232426
global_step: 23628, epoch: 191, loss: 0.243098
global_step: 23629, epoch: 191, loss: 0.213372
global_step: 23630, epoch: 191, loss: 0.237688
global_step: 23631, epoch: 191, loss: 0.197936
global_step: 23632, epoch: 191, loss: 0.288480
global_step: 23633, epoch: 191, loss: 0.287444
global_step: 23634, epoch: 191, loss: 0.264837
global_step: 23635, epoch: 191, loss: 0.184712
global_step: 23636, epoch: 191, loss: 0.200493
global_step: 23637, epoch: 191, loss: 0.273077
global_step: 23638, epoch: 191, loss: 0.232014
global_step: 23639, epoch: 191, loss: 0.304028
global_step: 23640, epoch: 191, loss: 0.041810
epoch: 191
train	acc: 0.9634	macro: p 0.9663, r 0.9387, f1: 0.9517	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9633
dev	acc: 0.5654	macro: p 0.4310, r 0.3664, f1: 0.3799	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5358
test	acc: 0.5877	macro: p 0.3875, r 0.3549, f1: 0.3634	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5680
global_step: 23641, epoch: 192, loss: 0.270518
global_step: 23642, epoch: 192, loss: 0.250339
global_step: 23643, epoch: 192, loss: 0.222839
global_step: 23644, epoch: 192, loss: 0.313482
global_step: 23645, epoch: 192, loss: 0.283851
global_step: 23646, epoch: 192, loss: 0.255403
global_step: 23647, epoch: 192, loss: 0.274247
global_step: 23648, epoch: 192, loss: 0.210769
global_step: 23649, epoch: 192, loss: 0.256840
global_step: 23650, epoch: 192, loss: 0.228127
global_step: 23651, epoch: 192, loss: 0.194797
global_step: 23652, epoch: 192, loss: 0.259884
global_step: 23653, epoch: 192, loss: 0.304250
global_step: 23654, epoch: 192, loss: 0.204785
global_step: 23655, epoch: 192, loss: 0.226118
global_step: 23656, epoch: 192, loss: 0.214485
global_step: 23657, epoch: 192, loss: 0.228112
global_step: 23658, epoch: 192, loss: 0.221412
global_step: 23659, epoch: 192, loss: 0.257667
global_step: 23660, epoch: 192, loss: 0.323351
global_step: 23661, epoch: 192, loss: 0.207116
global_step: 23662, epoch: 192, loss: 0.285569
global_step: 23663, epoch: 192, loss: 0.207500
global_step: 23664, epoch: 192, loss: 0.281685
global_step: 23665, epoch: 192, loss: 0.216370
global_step: 23666, epoch: 192, loss: 0.270781
global_step: 23667, epoch: 192, loss: 0.227458
global_step: 23668, epoch: 192, loss: 0.189133
global_step: 23669, epoch: 192, loss: 0.268847
global_step: 23670, epoch: 192, loss: 0.228397
global_step: 23671, epoch: 192, loss: 0.269538
global_step: 23672, epoch: 192, loss: 0.188452
global_step: 23673, epoch: 192, loss: 0.296450
global_step: 23674, epoch: 192, loss: 0.254234
global_step: 23675, epoch: 192, loss: 0.255407
global_step: 23676, epoch: 192, loss: 0.242923
global_step: 23677, epoch: 192, loss: 0.249997
global_step: 23678, epoch: 192, loss: 0.232742
global_step: 23679, epoch: 192, loss: 0.166188
global_step: 23680, epoch: 192, loss: 0.153446
epoch: 192
train	acc: 0.9611	macro: p 0.9658, r 0.9344, f1: 0.9491	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9610
dev	acc: 0.5663	macro: p 0.4545, r 0.3612, f1: 0.3770	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5320
test	acc: 0.5958	macro: p 0.4069, r 0.3496, f1: 0.3605	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5649
global_step: 23681, epoch: 193, loss: 0.212057
global_step: 23682, epoch: 193, loss: 0.227393
global_step: 23683, epoch: 193, loss: 0.196057
global_step: 23684, epoch: 193, loss: 0.257674
global_step: 23685, epoch: 193, loss: 0.293966
global_step: 23686, epoch: 193, loss: 0.196316
global_step: 23687, epoch: 193, loss: 0.241055
global_step: 23688, epoch: 193, loss: 0.251678
global_step: 23689, epoch: 193, loss: 0.158847
global_step: 23690, epoch: 193, loss: 0.229421
global_step: 23691, epoch: 193, loss: 0.293570
global_step: 23692, epoch: 193, loss: 0.205652
global_step: 23693, epoch: 193, loss: 0.208328
global_step: 23694, epoch: 193, loss: 0.196647
global_step: 23695, epoch: 193, loss: 0.232196
global_step: 23696, epoch: 193, loss: 0.299591
global_step: 23697, epoch: 193, loss: 0.299841
global_step: 23698, epoch: 193, loss: 0.204897
global_step: 23699, epoch: 193, loss: 0.233718
global_step: 23700, epoch: 193, loss: 0.320222
global_step: 23701, epoch: 193, loss: 0.225296
global_step: 23702, epoch: 193, loss: 0.215861
global_step: 23703, epoch: 193, loss: 0.262655
global_step: 23704, epoch: 193, loss: 0.243204
global_step: 23705, epoch: 193, loss: 0.185790
global_step: 23706, epoch: 193, loss: 0.242573
global_step: 23707, epoch: 193, loss: 0.320790
global_step: 23708, epoch: 193, loss: 0.215763
global_step: 23709, epoch: 193, loss: 0.295517
global_step: 23710, epoch: 193, loss: 0.268926
global_step: 23711, epoch: 193, loss: 0.237523
global_step: 23712, epoch: 193, loss: 0.254211
global_step: 23713, epoch: 193, loss: 0.218702
global_step: 23714, epoch: 193, loss: 0.306023
global_step: 23715, epoch: 193, loss: 0.285653
global_step: 23716, epoch: 193, loss: 0.176795
global_step: 23717, epoch: 193, loss: 0.241419
global_step: 23718, epoch: 193, loss: 0.272529
global_step: 23719, epoch: 193, loss: 0.249325
global_step: 23720, epoch: 193, loss: 0.225480
epoch: 193
train	acc: 0.9622	macro: p 0.9672, r 0.9368, f1: 0.9509	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9621
dev	acc: 0.5636	macro: p 0.4369, r 0.3624, f1: 0.3717	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5331
test	acc: 0.5824	macro: p 0.3994, r 0.3497, f1: 0.3568	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5573
global_step: 23721, epoch: 194, loss: 0.228172
global_step: 23722, epoch: 194, loss: 0.256439
global_step: 23723, epoch: 194, loss: 0.217372
global_step: 23724, epoch: 194, loss: 0.204999
global_step: 23725, epoch: 194, loss: 0.252756
global_step: 23726, epoch: 194, loss: 0.210569
global_step: 23727, epoch: 194, loss: 0.330290
global_step: 23728, epoch: 194, loss: 0.277687
global_step: 23729, epoch: 194, loss: 0.212410
global_step: 23730, epoch: 194, loss: 0.229947
global_step: 23731, epoch: 194, loss: 0.225631
global_step: 23732, epoch: 194, loss: 0.234131
global_step: 23733, epoch: 194, loss: 0.212603
global_step: 23734, epoch: 194, loss: 0.198687
global_step: 23735, epoch: 194, loss: 0.240842
global_step: 23736, epoch: 194, loss: 0.228882
global_step: 23737, epoch: 194, loss: 0.284802
global_step: 23738, epoch: 194, loss: 0.207079
global_step: 23739, epoch: 194, loss: 0.241103
global_step: 23740, epoch: 194, loss: 0.221969
global_step: 23741, epoch: 194, loss: 0.201261
global_step: 23742, epoch: 194, loss: 0.275025
global_step: 23743, epoch: 194, loss: 0.216938
global_step: 23744, epoch: 194, loss: 0.239784
global_step: 23745, epoch: 194, loss: 0.263786
global_step: 23746, epoch: 194, loss: 0.266062
global_step: 23747, epoch: 194, loss: 0.169075
global_step: 23748, epoch: 194, loss: 0.211086
global_step: 23749, epoch: 194, loss: 0.196516
global_step: 23750, epoch: 194, loss: 0.197972
global_step: 23751, epoch: 194, loss: 0.165722
global_step: 23752, epoch: 194, loss: 0.243643
global_step: 23753, epoch: 194, loss: 0.288282
global_step: 23754, epoch: 194, loss: 0.224619
global_step: 23755, epoch: 194, loss: 0.257659
global_step: 23756, epoch: 194, loss: 0.200555
global_step: 23757, epoch: 194, loss: 0.277063
global_step: 23758, epoch: 194, loss: 0.256166
global_step: 23759, epoch: 194, loss: 0.266184
global_step: 23760, epoch: 194, loss: 0.340594
epoch: 194
train	acc: 0.9640	macro: p 0.9653, r 0.9393, f1: 0.9516	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9639
dev	acc: 0.5690	macro: p 0.4418, r 0.3720, f1: 0.3890	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5392
test	acc: 0.5889	macro: p 0.3962, r 0.3511, f1: 0.3648	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5656
global_step: 23761, epoch: 195, loss: 0.213637
global_step: 23762, epoch: 195, loss: 0.339571
global_step: 23763, epoch: 195, loss: 0.260237
global_step: 23764, epoch: 195, loss: 0.216827
global_step: 23765, epoch: 195, loss: 0.188377
global_step: 23766, epoch: 195, loss: 0.283765
global_step: 23767, epoch: 195, loss: 0.235474
global_step: 23768, epoch: 195, loss: 0.231405
global_step: 23769, epoch: 195, loss: 0.252722
global_step: 23770, epoch: 195, loss: 0.179129
global_step: 23771, epoch: 195, loss: 0.218812
global_step: 23772, epoch: 195, loss: 0.225678
global_step: 23773, epoch: 195, loss: 0.207562
global_step: 23774, epoch: 195, loss: 0.244183
global_step: 23775, epoch: 195, loss: 0.270630
global_step: 23776, epoch: 195, loss: 0.228099
global_step: 23777, epoch: 195, loss: 0.219100
global_step: 23778, epoch: 195, loss: 0.213529
global_step: 23779, epoch: 195, loss: 0.241364
global_step: 23780, epoch: 195, loss: 0.232305
global_step: 23781, epoch: 195, loss: 0.172511
global_step: 23782, epoch: 195, loss: 0.258368
global_step: 23783, epoch: 195, loss: 0.233217
global_step: 23784, epoch: 195, loss: 0.217492
global_step: 23785, epoch: 195, loss: 0.198350
global_step: 23786, epoch: 195, loss: 0.241138
global_step: 23787, epoch: 195, loss: 0.165906
global_step: 23788, epoch: 195, loss: 0.251580
global_step: 23789, epoch: 195, loss: 0.195413
global_step: 23790, epoch: 195, loss: 0.228033
global_step: 23791, epoch: 195, loss: 0.272778
global_step: 23792, epoch: 195, loss: 0.181857
global_step: 23793, epoch: 195, loss: 0.203866
global_step: 23794, epoch: 195, loss: 0.269837
global_step: 23795, epoch: 195, loss: 0.318952
global_step: 23796, epoch: 195, loss: 0.273206
global_step: 23797, epoch: 195, loss: 0.284488
global_step: 23798, epoch: 195, loss: 0.274934
global_step: 23799, epoch: 195, loss: 0.213351
global_step: 23800, epoch: 195, loss: 0.036599
epoch: 195
train	acc: 0.9646	macro: p 0.9681, r 0.9408, f1: 0.9536	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9645
dev	acc: 0.5672	macro: p 0.4450, r 0.3716, f1: 0.3880	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5366
test	acc: 0.5862	macro: p 0.3887, r 0.3485, f1: 0.3577	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5604
global_step: 23801, epoch: 196, loss: 0.217718
global_step: 23802, epoch: 196, loss: 0.169055
global_step: 23803, epoch: 196, loss: 0.202673
global_step: 23804, epoch: 196, loss: 0.271458
global_step: 23805, epoch: 196, loss: 0.227843
global_step: 23806, epoch: 196, loss: 0.227515
global_step: 23807, epoch: 196, loss: 0.282892
global_step: 23808, epoch: 196, loss: 0.214699
global_step: 23809, epoch: 196, loss: 0.254271
global_step: 23810, epoch: 196, loss: 0.202071
global_step: 23811, epoch: 196, loss: 0.217132
global_step: 23812, epoch: 196, loss: 0.257320
global_step: 23813, epoch: 196, loss: 0.173690
global_step: 23814, epoch: 196, loss: 0.197897
global_step: 23815, epoch: 196, loss: 0.200863
global_step: 23816, epoch: 196, loss: 0.275918
global_step: 23817, epoch: 196, loss: 0.173311
global_step: 23818, epoch: 196, loss: 0.235792
global_step: 23819, epoch: 196, loss: 0.252969
global_step: 23820, epoch: 196, loss: 0.194156
global_step: 23821, epoch: 196, loss: 0.233043
global_step: 23822, epoch: 196, loss: 0.234199
global_step: 23823, epoch: 196, loss: 0.190149
global_step: 23824, epoch: 196, loss: 0.232124
global_step: 23825, epoch: 196, loss: 0.227842
global_step: 23826, epoch: 196, loss: 0.225864
global_step: 23827, epoch: 196, loss: 0.271545
global_step: 23828, epoch: 196, loss: 0.249869
global_step: 23829, epoch: 196, loss: 0.239949
global_step: 23830, epoch: 196, loss: 0.238832
global_step: 23831, epoch: 196, loss: 0.274266
global_step: 23832, epoch: 196, loss: 0.221568
global_step: 23833, epoch: 196, loss: 0.243448
global_step: 23834, epoch: 196, loss: 0.223356
global_step: 23835, epoch: 196, loss: 0.180989
global_step: 23836, epoch: 196, loss: 0.233877
global_step: 23837, epoch: 196, loss: 0.260083
global_step: 23838, epoch: 196, loss: 0.177879
global_step: 23839, epoch: 196, loss: 0.300225
global_step: 23840, epoch: 196, loss: 0.044750
epoch: 196
train	acc: 0.9639	macro: p 0.9678, r 0.9402, f1: 0.9531	micro: p 0.9639, r 0.9639, f1 0.9639	weighted_f1:0.9638
dev	acc: 0.5582	macro: p 0.4479, r 0.3706, f1: 0.3826	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5295
test	acc: 0.5908	macro: p 0.3976, r 0.3623, f1: 0.3684	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5695
global_step: 23841, epoch: 197, loss: 0.229918
global_step: 23842, epoch: 197, loss: 0.205484
global_step: 23843, epoch: 197, loss: 0.167022
global_step: 23844, epoch: 197, loss: 0.211134
global_step: 23845, epoch: 197, loss: 0.229591
global_step: 23846, epoch: 197, loss: 0.163851
global_step: 23847, epoch: 197, loss: 0.222775
global_step: 23848, epoch: 197, loss: 0.197749
global_step: 23849, epoch: 197, loss: 0.253954
global_step: 23850, epoch: 197, loss: 0.184380
global_step: 23851, epoch: 197, loss: 0.232833
global_step: 23852, epoch: 197, loss: 0.180227
global_step: 23853, epoch: 197, loss: 0.181861
global_step: 23854, epoch: 197, loss: 0.212214
global_step: 23855, epoch: 197, loss: 0.234045
global_step: 23856, epoch: 197, loss: 0.236553
global_step: 23857, epoch: 197, loss: 0.224925
global_step: 23858, epoch: 197, loss: 0.212254
global_step: 23859, epoch: 197, loss: 0.252585
global_step: 23860, epoch: 197, loss: 0.235798
global_step: 23861, epoch: 197, loss: 0.253407
global_step: 23862, epoch: 197, loss: 0.286692
global_step: 23863, epoch: 197, loss: 0.228209
global_step: 23864, epoch: 197, loss: 0.202111
global_step: 23865, epoch: 197, loss: 0.221456
global_step: 23866, epoch: 197, loss: 0.231987
global_step: 23867, epoch: 197, loss: 0.223534
global_step: 23868, epoch: 197, loss: 0.199545
global_step: 23869, epoch: 197, loss: 0.218166
global_step: 23870, epoch: 197, loss: 0.288458
global_step: 23871, epoch: 197, loss: 0.208668
global_step: 23872, epoch: 197, loss: 0.232354
global_step: 23873, epoch: 197, loss: 0.272129
global_step: 23874, epoch: 197, loss: 0.202169
global_step: 23875, epoch: 197, loss: 0.238325
global_step: 23876, epoch: 197, loss: 0.179379
global_step: 23877, epoch: 197, loss: 0.250181
global_step: 23878, epoch: 197, loss: 0.227024
global_step: 23879, epoch: 197, loss: 0.282886
global_step: 23880, epoch: 197, loss: 0.018325
epoch: 197
train	acc: 0.9638	macro: p 0.9672, r 0.9392, f1: 0.9523	micro: p 0.9638, r 0.9638, f1 0.9638	weighted_f1:0.9637
dev	acc: 0.5699	macro: p 0.4723, r 0.3670, f1: 0.3851	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5336
test	acc: 0.5893	macro: p 0.3959, r 0.3383, f1: 0.3484	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5570
global_step: 23881, epoch: 198, loss: 0.167526
global_step: 23882, epoch: 198, loss: 0.170982
global_step: 23883, epoch: 198, loss: 0.171718
global_step: 23884, epoch: 198, loss: 0.206913
global_step: 23885, epoch: 198, loss: 0.183269
global_step: 23886, epoch: 198, loss: 0.239932
global_step: 23887, epoch: 198, loss: 0.242712
global_step: 23888, epoch: 198, loss: 0.203884
global_step: 23889, epoch: 198, loss: 0.186478
global_step: 23890, epoch: 198, loss: 0.211950
global_step: 23891, epoch: 198, loss: 0.288403
global_step: 23892, epoch: 198, loss: 0.166179
global_step: 23893, epoch: 198, loss: 0.201916
global_step: 23894, epoch: 198, loss: 0.289594
global_step: 23895, epoch: 198, loss: 0.275533
global_step: 23896, epoch: 198, loss: 0.220842
global_step: 23897, epoch: 198, loss: 0.245083
global_step: 23898, epoch: 198, loss: 0.221294
global_step: 23899, epoch: 198, loss: 0.291080
global_step: 23900, epoch: 198, loss: 0.242575
global_step: 23901, epoch: 198, loss: 0.255210
global_step: 23902, epoch: 198, loss: 0.221627
global_step: 23903, epoch: 198, loss: 0.226254
global_step: 23904, epoch: 198, loss: 0.265906
global_step: 23905, epoch: 198, loss: 0.346943
global_step: 23906, epoch: 198, loss: 0.252723
global_step: 23907, epoch: 198, loss: 0.208014
global_step: 23908, epoch: 198, loss: 0.177849
global_step: 23909, epoch: 198, loss: 0.191548
global_step: 23910, epoch: 198, loss: 0.252626
global_step: 23911, epoch: 198, loss: 0.295431
global_step: 23912, epoch: 198, loss: 0.236509
global_step: 23913, epoch: 198, loss: 0.246132
global_step: 23914, epoch: 198, loss: 0.221276
global_step: 23915, epoch: 198, loss: 0.278970
global_step: 23916, epoch: 198, loss: 0.221045
global_step: 23917, epoch: 198, loss: 0.307084
global_step: 23918, epoch: 198, loss: 0.228218
global_step: 23919, epoch: 198, loss: 0.177478
global_step: 23920, epoch: 198, loss: 0.231805
epoch: 198
train	acc: 0.9645	macro: p 0.9676, r 0.9402, f1: 0.9529	micro: p 0.9645, r 0.9645, f1 0.9645	weighted_f1:0.9644
dev	acc: 0.5591	macro: p 0.4228, r 0.3731, f1: 0.3815	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5353
test	acc: 0.5824	macro: p 0.3928, r 0.3636, f1: 0.3700	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5673
global_step: 23921, epoch: 199, loss: 0.255988
global_step: 23922, epoch: 199, loss: 0.172857
global_step: 23923, epoch: 199, loss: 0.256626
global_step: 23924, epoch: 199, loss: 0.285383
global_step: 23925, epoch: 199, loss: 0.235101
global_step: 23926, epoch: 199, loss: 0.259593
global_step: 23927, epoch: 199, loss: 0.244581
global_step: 23928, epoch: 199, loss: 0.256914
global_step: 23929, epoch: 199, loss: 0.231342
global_step: 23930, epoch: 199, loss: 0.206440
global_step: 23931, epoch: 199, loss: 0.220538
global_step: 23932, epoch: 199, loss: 0.205066
global_step: 23933, epoch: 199, loss: 0.194836
global_step: 23934, epoch: 199, loss: 0.194426
global_step: 23935, epoch: 199, loss: 0.189773
global_step: 23936, epoch: 199, loss: 0.206908
global_step: 23937, epoch: 199, loss: 0.212595
global_step: 23938, epoch: 199, loss: 0.212547
global_step: 23939, epoch: 199, loss: 0.271379
global_step: 23940, epoch: 199, loss: 0.268169
global_step: 23941, epoch: 199, loss: 0.225971
global_step: 23942, epoch: 199, loss: 0.255002
global_step: 23943, epoch: 199, loss: 0.274609
global_step: 23944, epoch: 199, loss: 0.248035
global_step: 23945, epoch: 199, loss: 0.245374
global_step: 23946, epoch: 199, loss: 0.228471
global_step: 23947, epoch: 199, loss: 0.234077
global_step: 23948, epoch: 199, loss: 0.245830
global_step: 23949, epoch: 199, loss: 0.188836
global_step: 23950, epoch: 199, loss: 0.214477
global_step: 23951, epoch: 199, loss: 0.147923
global_step: 23952, epoch: 199, loss: 0.220920
global_step: 23953, epoch: 199, loss: 0.234052
global_step: 23954, epoch: 199, loss: 0.198778
global_step: 23955, epoch: 199, loss: 0.280965
global_step: 23956, epoch: 199, loss: 0.207216
global_step: 23957, epoch: 199, loss: 0.263360
global_step: 23958, epoch: 199, loss: 0.192290
global_step: 23959, epoch: 199, loss: 0.229018
global_step: 23960, epoch: 199, loss: 0.107160
epoch: 199
train	acc: 0.9646	macro: p 0.9673, r 0.9392, f1: 0.9523	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9645
dev	acc: 0.5518	macro: p 0.4421, r 0.3722, f1: 0.3846	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5316
test	acc: 0.5793	macro: p 0.3977, r 0.3570, f1: 0.3573	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5637
global_step: 23961, epoch: 200, loss: 0.297840
global_step: 23962, epoch: 200, loss: 0.241086
global_step: 23963, epoch: 200, loss: 0.208529
global_step: 23964, epoch: 200, loss: 0.197941
global_step: 23965, epoch: 200, loss: 0.208798
global_step: 23966, epoch: 200, loss: 0.198014
global_step: 23967, epoch: 200, loss: 0.208342
global_step: 23968, epoch: 200, loss: 0.217043
global_step: 23969, epoch: 200, loss: 0.230889
global_step: 23970, epoch: 200, loss: 0.262015
global_step: 23971, epoch: 200, loss: 0.257326
global_step: 23972, epoch: 200, loss: 0.205314
global_step: 23973, epoch: 200, loss: 0.241724
global_step: 23974, epoch: 200, loss: 0.200490
global_step: 23975, epoch: 200, loss: 0.223785
global_step: 23976, epoch: 200, loss: 0.247392
global_step: 23977, epoch: 200, loss: 0.212624
global_step: 23978, epoch: 200, loss: 0.223834
global_step: 23979, epoch: 200, loss: 0.240605
global_step: 23980, epoch: 200, loss: 0.232706
global_step: 23981, epoch: 200, loss: 0.184809
global_step: 23982, epoch: 200, loss: 0.204136
global_step: 23983, epoch: 200, loss: 0.258219
global_step: 23984, epoch: 200, loss: 0.202902
global_step: 23985, epoch: 200, loss: 0.299528
global_step: 23986, epoch: 200, loss: 0.224106
global_step: 23987, epoch: 200, loss: 0.286070
global_step: 23988, epoch: 200, loss: 0.256117
global_step: 23989, epoch: 200, loss: 0.213303
global_step: 23990, epoch: 200, loss: 0.201641
global_step: 23991, epoch: 200, loss: 0.254827
global_step: 23992, epoch: 200, loss: 0.304802
global_step: 23993, epoch: 200, loss: 0.238646
global_step: 23994, epoch: 200, loss: 0.234187
global_step: 23995, epoch: 200, loss: 0.296532
global_step: 23996, epoch: 200, loss: 0.228146
global_step: 23997, epoch: 200, loss: 0.247392
global_step: 23998, epoch: 200, loss: 0.218802
global_step: 23999, epoch: 200, loss: 0.262248
global_step: 24000, epoch: 200, loss: 0.117318
epoch: 200
train	acc: 0.9641	macro: p 0.9708, r 0.9414, f1: 0.9552	micro: p 0.9641, r 0.9641, f1 0.9641	weighted_f1:0.9640
dev	acc: 0.5735	macro: p 0.4722, r 0.3610, f1: 0.3789	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5342
test	acc: 0.5969	macro: p 0.3978, r 0.3377, f1: 0.3479	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5604
BEST MODEL epoch: 129
train	acc: 0.9360 macro_p: 0.9315 macro_r: 0.8510 macro_f1: 0.8786 micro_p: 0.9360 micro_r: 0.9360 micro_f1: 0.9360 weighted_f1: 0.9339
dev	acc: 0.5753 macro_p: 0.4830 macro_r: 0.3838 macro_f1: 0.3945 micro_p: 0.5753 micro_r: 0.5753 micro_f1: 0.5753 weighted_f1: 0.5519
test	acc: 0.5950 macro_p: 0.3882 macro_r: 0.3555 macro_f1: 0.3601 micro_p: 0.5950 micro_r: 0.5950 micro_f1: 0.5950 weighted_f1: 0.5744
==========ROUND 4==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 24001, epoch: 1, loss: 1.935359
global_step: 24002, epoch: 1, loss: 1.923000
global_step: 24003, epoch: 1, loss: 1.913876
global_step: 24004, epoch: 1, loss: 1.905855
global_step: 24005, epoch: 1, loss: 1.896568
global_step: 24006, epoch: 1, loss: 1.900406
global_step: 24007, epoch: 1, loss: 1.877027
global_step: 24008, epoch: 1, loss: 1.863781
global_step: 24009, epoch: 1, loss: 1.863622
global_step: 24010, epoch: 1, loss: 1.857509
global_step: 24011, epoch: 1, loss: 1.839249
global_step: 24012, epoch: 1, loss: 1.817488
global_step: 24013, epoch: 1, loss: 1.805087
global_step: 24014, epoch: 1, loss: 1.782266
global_step: 24015, epoch: 1, loss: 1.806571
global_step: 24016, epoch: 1, loss: 1.771326
global_step: 24017, epoch: 1, loss: 1.751182
global_step: 24018, epoch: 1, loss: 1.786241
global_step: 24019, epoch: 1, loss: 1.704641
global_step: 24020, epoch: 1, loss: 1.728082
global_step: 24021, epoch: 1, loss: 1.694590
global_step: 24022, epoch: 1, loss: 1.717650
global_step: 24023, epoch: 1, loss: 1.664125
global_step: 24024, epoch: 1, loss: 1.624320
global_step: 24025, epoch: 1, loss: 1.672066
global_step: 24026, epoch: 1, loss: 1.641484
global_step: 24027, epoch: 1, loss: 1.622277
global_step: 24028, epoch: 1, loss: 1.639659
global_step: 24029, epoch: 1, loss: 1.648400
global_step: 24030, epoch: 1, loss: 1.629256
global_step: 24031, epoch: 1, loss: 1.606093
global_step: 24032, epoch: 1, loss: 1.566153
global_step: 24033, epoch: 1, loss: 1.570970
global_step: 24034, epoch: 1, loss: 1.584270
global_step: 24035, epoch: 1, loss: 1.506886
global_step: 24036, epoch: 1, loss: 1.592481
global_step: 24037, epoch: 1, loss: 1.656536
global_step: 24038, epoch: 1, loss: 1.580523
global_step: 24039, epoch: 1, loss: 1.583101
global_step: 24040, epoch: 1, loss: 1.458378
epoch: 1
train	acc: 0.4715	macro: p 0.0674, r 0.1429, f1: 0.0916	micro: p 0.4715, r 0.4715, f1 0.4715	weighted_f1:0.3022
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
New best model!
global_step: 24041, epoch: 2, loss: 1.491115
global_step: 24042, epoch: 2, loss: 1.567617
global_step: 24043, epoch: 2, loss: 1.601111
global_step: 24044, epoch: 2, loss: 1.514690
global_step: 24045, epoch: 2, loss: 1.639231
global_step: 24046, epoch: 2, loss: 1.627894
global_step: 24047, epoch: 2, loss: 1.482003
global_step: 24048, epoch: 2, loss: 1.562723
global_step: 24049, epoch: 2, loss: 1.471597
global_step: 24050, epoch: 2, loss: 1.609372
global_step: 24051, epoch: 2, loss: 1.606902
global_step: 24052, epoch: 2, loss: 1.499432
global_step: 24053, epoch: 2, loss: 1.562056
global_step: 24054, epoch: 2, loss: 1.504448
global_step: 24055, epoch: 2, loss: 1.555452
global_step: 24056, epoch: 2, loss: 1.568451
global_step: 24057, epoch: 2, loss: 1.570342
global_step: 24058, epoch: 2, loss: 1.562419
global_step: 24059, epoch: 2, loss: 1.522115
global_step: 24060, epoch: 2, loss: 1.641381
global_step: 24061, epoch: 2, loss: 1.545781
global_step: 24062, epoch: 2, loss: 1.574354
global_step: 24063, epoch: 2, loss: 1.566008
global_step: 24064, epoch: 2, loss: 1.460232
global_step: 24065, epoch: 2, loss: 1.598456
global_step: 24066, epoch: 2, loss: 1.470843
global_step: 24067, epoch: 2, loss: 1.542234
global_step: 24068, epoch: 2, loss: 1.522654
global_step: 24069, epoch: 2, loss: 1.512029
global_step: 24070, epoch: 2, loss: 1.490364
global_step: 24071, epoch: 2, loss: 1.558242
global_step: 24072, epoch: 2, loss: 1.579899
global_step: 24073, epoch: 2, loss: 1.529317
global_step: 24074, epoch: 2, loss: 1.495734
global_step: 24075, epoch: 2, loss: 1.530326
global_step: 24076, epoch: 2, loss: 1.487823
global_step: 24077, epoch: 2, loss: 1.486273
global_step: 24078, epoch: 2, loss: 1.490205
global_step: 24079, epoch: 2, loss: 1.554002
global_step: 24080, epoch: 2, loss: 1.649565
epoch: 2
train	acc: 0.4715	macro: p 0.0674, r 0.1429, f1: 0.0916	micro: p 0.4715, r 0.4715, f1 0.4715	weighted_f1:0.3022
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4820	macro: p 0.1641, r 0.1436, f1: 0.0943	micro: p 0.4820, r 0.4820, f1 0.4820	weighted_f1:0.3144
global_step: 24081, epoch: 3, loss: 1.458982
global_step: 24082, epoch: 3, loss: 1.545893
global_step: 24083, epoch: 3, loss: 1.492227
global_step: 24084, epoch: 3, loss: 1.439523
global_step: 24085, epoch: 3, loss: 1.505764
global_step: 24086, epoch: 3, loss: 1.464411
global_step: 24087, epoch: 3, loss: 1.471666
global_step: 24088, epoch: 3, loss: 1.513036
global_step: 24089, epoch: 3, loss: 1.447680
global_step: 24090, epoch: 3, loss: 1.525356
global_step: 24091, epoch: 3, loss: 1.463443
global_step: 24092, epoch: 3, loss: 1.464107
global_step: 24093, epoch: 3, loss: 1.533121
global_step: 24094, epoch: 3, loss: 1.482494
global_step: 24095, epoch: 3, loss: 1.536529
global_step: 24096, epoch: 3, loss: 1.621185
global_step: 24097, epoch: 3, loss: 1.577513
global_step: 24098, epoch: 3, loss: 1.502922
global_step: 24099, epoch: 3, loss: 1.429923
global_step: 24100, epoch: 3, loss: 1.488246
global_step: 24101, epoch: 3, loss: 1.457568
global_step: 24102, epoch: 3, loss: 1.508590
global_step: 24103, epoch: 3, loss: 1.431949
global_step: 24104, epoch: 3, loss: 1.455012
global_step: 24105, epoch: 3, loss: 1.533648
global_step: 24106, epoch: 3, loss: 1.500599
global_step: 24107, epoch: 3, loss: 1.427496
global_step: 24108, epoch: 3, loss: 1.429533
global_step: 24109, epoch: 3, loss: 1.513449
global_step: 24110, epoch: 3, loss: 1.491921
global_step: 24111, epoch: 3, loss: 1.510250
global_step: 24112, epoch: 3, loss: 1.403768
global_step: 24113, epoch: 3, loss: 1.436452
global_step: 24114, epoch: 3, loss: 1.566229
global_step: 24115, epoch: 3, loss: 1.412405
global_step: 24116, epoch: 3, loss: 1.506095
global_step: 24117, epoch: 3, loss: 1.426168
global_step: 24118, epoch: 3, loss: 1.503357
global_step: 24119, epoch: 3, loss: 1.413442
global_step: 24120, epoch: 3, loss: 1.512377
epoch: 3
train	acc: 0.5108	macro: p 0.1315, r 0.1799, f1: 0.1447	micro: p 0.5108, r 0.5108, f1 0.5108	weighted_f1:0.3804
dev	acc: 0.4581	macro: p 0.1125, r 0.1802, f1: 0.1339	micro: p 0.4581, r 0.4581, f1 0.4581	weighted_f1:0.3167
test	acc: 0.5146	macro: p 0.1252, r 0.1793, f1: 0.1427	micro: p 0.5146, r 0.5146, f1 0.5146	weighted_f1:0.3818
New best model!
global_step: 24121, epoch: 4, loss: 1.514163
global_step: 24122, epoch: 4, loss: 1.539310
global_step: 24123, epoch: 4, loss: 1.469436
global_step: 24124, epoch: 4, loss: 1.455333
global_step: 24125, epoch: 4, loss: 1.364617
global_step: 24126, epoch: 4, loss: 1.440219
global_step: 24127, epoch: 4, loss: 1.441454
global_step: 24128, epoch: 4, loss: 1.489219
global_step: 24129, epoch: 4, loss: 1.397924
global_step: 24130, epoch: 4, loss: 1.434344
global_step: 24131, epoch: 4, loss: 1.353703
global_step: 24132, epoch: 4, loss: 1.522409
global_step: 24133, epoch: 4, loss: 1.462964
global_step: 24134, epoch: 4, loss: 1.466082
global_step: 24135, epoch: 4, loss: 1.483404
global_step: 24136, epoch: 4, loss: 1.379162
global_step: 24137, epoch: 4, loss: 1.420633
global_step: 24138, epoch: 4, loss: 1.411764
global_step: 24139, epoch: 4, loss: 1.409891
global_step: 24140, epoch: 4, loss: 1.404897
global_step: 24141, epoch: 4, loss: 1.339640
global_step: 24142, epoch: 4, loss: 1.557546
global_step: 24143, epoch: 4, loss: 1.483669
global_step: 24144, epoch: 4, loss: 1.366445
global_step: 24145, epoch: 4, loss: 1.342843
global_step: 24146, epoch: 4, loss: 1.442035
global_step: 24147, epoch: 4, loss: 1.407956
global_step: 24148, epoch: 4, loss: 1.418764
global_step: 24149, epoch: 4, loss: 1.381652
global_step: 24150, epoch: 4, loss: 1.436277
global_step: 24151, epoch: 4, loss: 1.430661
global_step: 24152, epoch: 4, loss: 1.393837
global_step: 24153, epoch: 4, loss: 1.423509
global_step: 24154, epoch: 4, loss: 1.418255
global_step: 24155, epoch: 4, loss: 1.365999
global_step: 24156, epoch: 4, loss: 1.274001
global_step: 24157, epoch: 4, loss: 1.355285
global_step: 24158, epoch: 4, loss: 1.503976
global_step: 24159, epoch: 4, loss: 1.522367
global_step: 24160, epoch: 4, loss: 1.612437
epoch: 4
train	acc: 0.5481	macro: p 0.2404, r 0.2230, f1: 0.1946	micro: p 0.5481, r 0.5481, f1 0.5481	weighted_f1:0.4452
dev	acc: 0.4932	macro: p 0.2313, r 0.2242, f1: 0.1812	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.3790
test	acc: 0.5521	macro: p 0.2373, r 0.2302, f1: 0.1997	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.4492
New best model!
global_step: 24161, epoch: 5, loss: 1.532979
global_step: 24162, epoch: 5, loss: 1.409525
global_step: 24163, epoch: 5, loss: 1.327700
global_step: 24164, epoch: 5, loss: 1.450561
global_step: 24165, epoch: 5, loss: 1.516838
global_step: 24166, epoch: 5, loss: 1.375705
global_step: 24167, epoch: 5, loss: 1.452470
global_step: 24168, epoch: 5, loss: 1.395272
global_step: 24169, epoch: 5, loss: 1.437648
global_step: 24170, epoch: 5, loss: 1.373346
global_step: 24171, epoch: 5, loss: 1.327094
global_step: 24172, epoch: 5, loss: 1.408759
global_step: 24173, epoch: 5, loss: 1.437758
global_step: 24174, epoch: 5, loss: 1.458889
global_step: 24175, epoch: 5, loss: 1.296965
global_step: 24176, epoch: 5, loss: 1.458813
global_step: 24177, epoch: 5, loss: 1.357093
global_step: 24178, epoch: 5, loss: 1.475263
global_step: 24179, epoch: 5, loss: 1.402665
global_step: 24180, epoch: 5, loss: 1.479730
global_step: 24181, epoch: 5, loss: 1.402543
global_step: 24182, epoch: 5, loss: 1.387183
global_step: 24183, epoch: 5, loss: 1.375461
global_step: 24184, epoch: 5, loss: 1.342007
global_step: 24185, epoch: 5, loss: 1.308272
global_step: 24186, epoch: 5, loss: 1.218162
global_step: 24187, epoch: 5, loss: 1.345683
global_step: 24188, epoch: 5, loss: 1.433065
global_step: 24189, epoch: 5, loss: 1.407500
global_step: 24190, epoch: 5, loss: 1.443722
global_step: 24191, epoch: 5, loss: 1.371710
global_step: 24192, epoch: 5, loss: 1.321742
global_step: 24193, epoch: 5, loss: 1.361887
global_step: 24194, epoch: 5, loss: 1.252101
global_step: 24195, epoch: 5, loss: 1.387969
global_step: 24196, epoch: 5, loss: 1.406479
global_step: 24197, epoch: 5, loss: 1.401023
global_step: 24198, epoch: 5, loss: 1.435566
global_step: 24199, epoch: 5, loss: 1.407111
global_step: 24200, epoch: 5, loss: 1.229411
epoch: 5
train	acc: 0.5464	macro: p 0.2678, r 0.2213, f1: 0.1778	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4371
dev	acc: 0.4950	macro: p 0.2674, r 0.2269, f1: 0.1699	micro: p 0.4950, r 0.4950, f1 0.4950	weighted_f1:0.3732
test	acc: 0.5506	macro: p 0.2811, r 0.2284, f1: 0.1806	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.4415
global_step: 24201, epoch: 6, loss: 1.391217
global_step: 24202, epoch: 6, loss: 1.426457
global_step: 24203, epoch: 6, loss: 1.342547
global_step: 24204, epoch: 6, loss: 1.247604
global_step: 24205, epoch: 6, loss: 1.326315
global_step: 24206, epoch: 6, loss: 1.369352
global_step: 24207, epoch: 6, loss: 1.316773
global_step: 24208, epoch: 6, loss: 1.312629
global_step: 24209, epoch: 6, loss: 1.441862
global_step: 24210, epoch: 6, loss: 1.307674
global_step: 24211, epoch: 6, loss: 1.307662
global_step: 24212, epoch: 6, loss: 1.273269
global_step: 24213, epoch: 6, loss: 1.371931
global_step: 24214, epoch: 6, loss: 1.390864
global_step: 24215, epoch: 6, loss: 1.354249
global_step: 24216, epoch: 6, loss: 1.518344
global_step: 24217, epoch: 6, loss: 1.357543
global_step: 24218, epoch: 6, loss: 1.467387
global_step: 24219, epoch: 6, loss: 1.379625
global_step: 24220, epoch: 6, loss: 1.302731
global_step: 24221, epoch: 6, loss: 1.388279
global_step: 24222, epoch: 6, loss: 1.327288
global_step: 24223, epoch: 6, loss: 1.407013
global_step: 24224, epoch: 6, loss: 1.399314
global_step: 24225, epoch: 6, loss: 1.426778
global_step: 24226, epoch: 6, loss: 1.390379
global_step: 24227, epoch: 6, loss: 1.434748
global_step: 24228, epoch: 6, loss: 1.286590
global_step: 24229, epoch: 6, loss: 1.321764
global_step: 24230, epoch: 6, loss: 1.330469
global_step: 24231, epoch: 6, loss: 1.392544
global_step: 24232, epoch: 6, loss: 1.420961
global_step: 24233, epoch: 6, loss: 1.359443
global_step: 24234, epoch: 6, loss: 1.302053
global_step: 24235, epoch: 6, loss: 1.365002
global_step: 24236, epoch: 6, loss: 1.378638
global_step: 24237, epoch: 6, loss: 1.370518
global_step: 24238, epoch: 6, loss: 1.371549
global_step: 24239, epoch: 6, loss: 1.405685
global_step: 24240, epoch: 6, loss: 1.392238
epoch: 6
train	acc: 0.5473	macro: p 0.2640, r 0.2238, f1: 0.1820	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4407
dev	acc: 0.5005	macro: p 0.2686, r 0.2331, f1: 0.1797	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.3830
test	acc: 0.5529	macro: p 0.2743, r 0.2323, f1: 0.1880	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.4473
New best model!
global_step: 24241, epoch: 7, loss: 1.313486
global_step: 24242, epoch: 7, loss: 1.364991
global_step: 24243, epoch: 7, loss: 1.315212
global_step: 24244, epoch: 7, loss: 1.412745
global_step: 24245, epoch: 7, loss: 1.447530
global_step: 24246, epoch: 7, loss: 1.367173
global_step: 24247, epoch: 7, loss: 1.388331
global_step: 24248, epoch: 7, loss: 1.322800
global_step: 24249, epoch: 7, loss: 1.496251
global_step: 24250, epoch: 7, loss: 1.363292
global_step: 24251, epoch: 7, loss: 1.408956
global_step: 24252, epoch: 7, loss: 1.395251
global_step: 24253, epoch: 7, loss: 1.476354
global_step: 24254, epoch: 7, loss: 1.346653
global_step: 24255, epoch: 7, loss: 1.352517
global_step: 24256, epoch: 7, loss: 1.349394
global_step: 24257, epoch: 7, loss: 1.323930
global_step: 24258, epoch: 7, loss: 1.288931
global_step: 24259, epoch: 7, loss: 1.308188
global_step: 24260, epoch: 7, loss: 1.348198
global_step: 24261, epoch: 7, loss: 1.349840
global_step: 24262, epoch: 7, loss: 1.312556
global_step: 24263, epoch: 7, loss: 1.330404
global_step: 24264, epoch: 7, loss: 1.280985
global_step: 24265, epoch: 7, loss: 1.193212
global_step: 24266, epoch: 7, loss: 1.266650
global_step: 24267, epoch: 7, loss: 1.358029
global_step: 24268, epoch: 7, loss: 1.279945
global_step: 24269, epoch: 7, loss: 1.342327
global_step: 24270, epoch: 7, loss: 1.333719
global_step: 24271, epoch: 7, loss: 1.403651
global_step: 24272, epoch: 7, loss: 1.339606
global_step: 24273, epoch: 7, loss: 1.325295
global_step: 24274, epoch: 7, loss: 1.326041
global_step: 24275, epoch: 7, loss: 1.359051
global_step: 24276, epoch: 7, loss: 1.206847
global_step: 24277, epoch: 7, loss: 1.442556
global_step: 24278, epoch: 7, loss: 1.389556
global_step: 24279, epoch: 7, loss: 1.366953
global_step: 24280, epoch: 7, loss: 1.272697
epoch: 7
train	acc: 0.5559	macro: p 0.3363, r 0.2345, f1: 0.2017	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.4578
dev	acc: 0.5068	macro: p 0.2503, r 0.2404, f1: 0.1928	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.3952
test	acc: 0.5609	macro: p 0.2529, r 0.2431, f1: 0.2065	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.4619
New best model!
global_step: 24281, epoch: 8, loss: 1.323833
global_step: 24282, epoch: 8, loss: 1.405399
global_step: 24283, epoch: 8, loss: 1.359800
global_step: 24284, epoch: 8, loss: 1.244290
global_step: 24285, epoch: 8, loss: 1.230456
global_step: 24286, epoch: 8, loss: 1.318808
global_step: 24287, epoch: 8, loss: 1.289067
global_step: 24288, epoch: 8, loss: 1.298691
global_step: 24289, epoch: 8, loss: 1.407678
global_step: 24290, epoch: 8, loss: 1.374377
global_step: 24291, epoch: 8, loss: 1.300952
global_step: 24292, epoch: 8, loss: 1.268986
global_step: 24293, epoch: 8, loss: 1.342806
global_step: 24294, epoch: 8, loss: 1.345332
global_step: 24295, epoch: 8, loss: 1.404810
global_step: 24296, epoch: 8, loss: 1.355210
global_step: 24297, epoch: 8, loss: 1.410085
global_step: 24298, epoch: 8, loss: 1.384950
global_step: 24299, epoch: 8, loss: 1.344340
global_step: 24300, epoch: 8, loss: 1.297146
global_step: 24301, epoch: 8, loss: 1.420919
global_step: 24302, epoch: 8, loss: 1.353690
global_step: 24303, epoch: 8, loss: 1.277396
global_step: 24304, epoch: 8, loss: 1.272401
global_step: 24305, epoch: 8, loss: 1.310673
global_step: 24306, epoch: 8, loss: 1.337874
global_step: 24307, epoch: 8, loss: 1.347681
global_step: 24308, epoch: 8, loss: 1.314399
global_step: 24309, epoch: 8, loss: 1.250984
global_step: 24310, epoch: 8, loss: 1.193903
global_step: 24311, epoch: 8, loss: 1.361288
global_step: 24312, epoch: 8, loss: 1.310731
global_step: 24313, epoch: 8, loss: 1.351410
global_step: 24314, epoch: 8, loss: 1.379639
global_step: 24315, epoch: 8, loss: 1.431397
global_step: 24316, epoch: 8, loss: 1.354932
global_step: 24317, epoch: 8, loss: 1.291477
global_step: 24318, epoch: 8, loss: 1.281459
global_step: 24319, epoch: 8, loss: 1.410014
global_step: 24320, epoch: 8, loss: 1.088074
epoch: 8
train	acc: 0.5544	macro: p 0.2555, r 0.2326, f1: 0.1979	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.4547
dev	acc: 0.5068	macro: p 0.2624, r 0.2404, f1: 0.1929	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.3953
test	acc: 0.5609	macro: p 0.2593, r 0.2429, f1: 0.2061	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.4616
New best model!
global_step: 24321, epoch: 9, loss: 1.323144
global_step: 24322, epoch: 9, loss: 1.374032
global_step: 24323, epoch: 9, loss: 1.431487
global_step: 24324, epoch: 9, loss: 1.390594
global_step: 24325, epoch: 9, loss: 1.277941
global_step: 24326, epoch: 9, loss: 1.353839
global_step: 24327, epoch: 9, loss: 1.388809
global_step: 24328, epoch: 9, loss: 1.305939
global_step: 24329, epoch: 9, loss: 1.350638
global_step: 24330, epoch: 9, loss: 1.225519
global_step: 24331, epoch: 9, loss: 1.255096
global_step: 24332, epoch: 9, loss: 1.418803
global_step: 24333, epoch: 9, loss: 1.319977
global_step: 24334, epoch: 9, loss: 1.212400
global_step: 24335, epoch: 9, loss: 1.359367
global_step: 24336, epoch: 9, loss: 1.397089
global_step: 24337, epoch: 9, loss: 1.237890
global_step: 24338, epoch: 9, loss: 1.359936
global_step: 24339, epoch: 9, loss: 1.388054
global_step: 24340, epoch: 9, loss: 1.301366
global_step: 24341, epoch: 9, loss: 1.222418
global_step: 24342, epoch: 9, loss: 1.273509
global_step: 24343, epoch: 9, loss: 1.417029
global_step: 24344, epoch: 9, loss: 1.400495
global_step: 24345, epoch: 9, loss: 1.330598
global_step: 24346, epoch: 9, loss: 1.266300
global_step: 24347, epoch: 9, loss: 1.267686
global_step: 24348, epoch: 9, loss: 1.277112
global_step: 24349, epoch: 9, loss: 1.365834
global_step: 24350, epoch: 9, loss: 1.318023
global_step: 24351, epoch: 9, loss: 1.441318
global_step: 24352, epoch: 9, loss: 1.321510
global_step: 24353, epoch: 9, loss: 1.222790
global_step: 24354, epoch: 9, loss: 1.362584
global_step: 24355, epoch: 9, loss: 1.302135
global_step: 24356, epoch: 9, loss: 1.394631
global_step: 24357, epoch: 9, loss: 1.269953
global_step: 24358, epoch: 9, loss: 1.287396
global_step: 24359, epoch: 9, loss: 1.218698
global_step: 24360, epoch: 9, loss: 1.219256
epoch: 9
train	acc: 0.5610	macro: p 0.3128, r 0.2408, f1: 0.2120	micro: p 0.5610, r 0.5610, f1 0.5610	weighted_f1:0.4670
dev	acc: 0.5149	macro: p 0.3727, r 0.2483, f1: 0.2050	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4073
test	acc: 0.5651	macro: p 0.2362, r 0.2495, f1: 0.2163	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.4695
New best model!
global_step: 24361, epoch: 10, loss: 1.396136
global_step: 24362, epoch: 10, loss: 1.244341
global_step: 24363, epoch: 10, loss: 1.228499
global_step: 24364, epoch: 10, loss: 1.325066
global_step: 24365, epoch: 10, loss: 1.197344
global_step: 24366, epoch: 10, loss: 1.318626
global_step: 24367, epoch: 10, loss: 1.274802
global_step: 24368, epoch: 10, loss: 1.327614
global_step: 24369, epoch: 10, loss: 1.269893
global_step: 24370, epoch: 10, loss: 1.310746
global_step: 24371, epoch: 10, loss: 1.272941
global_step: 24372, epoch: 10, loss: 1.414043
global_step: 24373, epoch: 10, loss: 1.248871
global_step: 24374, epoch: 10, loss: 1.405444
global_step: 24375, epoch: 10, loss: 1.426684
global_step: 24376, epoch: 10, loss: 1.291889
global_step: 24377, epoch: 10, loss: 1.297668
global_step: 24378, epoch: 10, loss: 1.304545
global_step: 24379, epoch: 10, loss: 1.296874
global_step: 24380, epoch: 10, loss: 1.225936
global_step: 24381, epoch: 10, loss: 1.235280
global_step: 24382, epoch: 10, loss: 1.292826
global_step: 24383, epoch: 10, loss: 1.367839
global_step: 24384, epoch: 10, loss: 1.330404
global_step: 24385, epoch: 10, loss: 1.387580
global_step: 24386, epoch: 10, loss: 1.225517
global_step: 24387, epoch: 10, loss: 1.345075
global_step: 24388, epoch: 10, loss: 1.266565
global_step: 24389, epoch: 10, loss: 1.294261
global_step: 24390, epoch: 10, loss: 1.248708
global_step: 24391, epoch: 10, loss: 1.397920
global_step: 24392, epoch: 10, loss: 1.256597
global_step: 24393, epoch: 10, loss: 1.271438
global_step: 24394, epoch: 10, loss: 1.349710
global_step: 24395, epoch: 10, loss: 1.431190
global_step: 24396, epoch: 10, loss: 1.243596
global_step: 24397, epoch: 10, loss: 1.375242
global_step: 24398, epoch: 10, loss: 1.329047
global_step: 24399, epoch: 10, loss: 1.360178
global_step: 24400, epoch: 10, loss: 1.415356
epoch: 10
train	acc: 0.5624	macro: p 0.3033, r 0.2426, f1: 0.2152	micro: p 0.5624, r 0.5624, f1 0.5624	weighted_f1:0.4698
dev	acc: 0.5149	macro: p 0.3675, r 0.2483, f1: 0.2062	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4084
test	acc: 0.5659	macro: p 0.3762, r 0.2503, f1: 0.2179	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.4711
New best model!
global_step: 24401, epoch: 11, loss: 1.243567
global_step: 24402, epoch: 11, loss: 1.313372
global_step: 24403, epoch: 11, loss: 1.222417
global_step: 24404, epoch: 11, loss: 1.349323
global_step: 24405, epoch: 11, loss: 1.344597
global_step: 24406, epoch: 11, loss: 1.221227
global_step: 24407, epoch: 11, loss: 1.392461
global_step: 24408, epoch: 11, loss: 1.276375
global_step: 24409, epoch: 11, loss: 1.312162
global_step: 24410, epoch: 11, loss: 1.178683
global_step: 24411, epoch: 11, loss: 1.271277
global_step: 24412, epoch: 11, loss: 1.439036
global_step: 24413, epoch: 11, loss: 1.290005
global_step: 24414, epoch: 11, loss: 1.281390
global_step: 24415, epoch: 11, loss: 1.282752
global_step: 24416, epoch: 11, loss: 1.327791
global_step: 24417, epoch: 11, loss: 1.248826
global_step: 24418, epoch: 11, loss: 1.231542
global_step: 24419, epoch: 11, loss: 1.290494
global_step: 24420, epoch: 11, loss: 1.367361
global_step: 24421, epoch: 11, loss: 1.272785
global_step: 24422, epoch: 11, loss: 1.264463
global_step: 24423, epoch: 11, loss: 1.450935
global_step: 24424, epoch: 11, loss: 1.233179
global_step: 24425, epoch: 11, loss: 1.348498
global_step: 24426, epoch: 11, loss: 1.269985
global_step: 24427, epoch: 11, loss: 1.157510
global_step: 24428, epoch: 11, loss: 1.270175
global_step: 24429, epoch: 11, loss: 1.301607
global_step: 24430, epoch: 11, loss: 1.308876
global_step: 24431, epoch: 11, loss: 1.339063
global_step: 24432, epoch: 11, loss: 1.242766
global_step: 24433, epoch: 11, loss: 1.281835
global_step: 24434, epoch: 11, loss: 1.290363
global_step: 24435, epoch: 11, loss: 1.278702
global_step: 24436, epoch: 11, loss: 1.325377
global_step: 24437, epoch: 11, loss: 1.191769
global_step: 24438, epoch: 11, loss: 1.308247
global_step: 24439, epoch: 11, loss: 1.395232
global_step: 24440, epoch: 11, loss: 1.295293
epoch: 11
train	acc: 0.5807	macro: p 0.3185, r 0.2673, f1: 0.2575	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5065
dev	acc: 0.5293	macro: p 0.3016, r 0.2647, f1: 0.2381	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4402
test	acc: 0.5835	macro: p 0.3186, r 0.2713, f1: 0.2576	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5082
New best model!
global_step: 24441, epoch: 12, loss: 1.316167
global_step: 24442, epoch: 12, loss: 1.229376
global_step: 24443, epoch: 12, loss: 1.224000
global_step: 24444, epoch: 12, loss: 1.340749
global_step: 24445, epoch: 12, loss: 1.314218
global_step: 24446, epoch: 12, loss: 1.368979
global_step: 24447, epoch: 12, loss: 1.293525
global_step: 24448, epoch: 12, loss: 1.330792
global_step: 24449, epoch: 12, loss: 1.303624
global_step: 24450, epoch: 12, loss: 1.221639
global_step: 24451, epoch: 12, loss: 1.220162
global_step: 24452, epoch: 12, loss: 1.380087
global_step: 24453, epoch: 12, loss: 1.339559
global_step: 24454, epoch: 12, loss: 1.362181
global_step: 24455, epoch: 12, loss: 1.234916
global_step: 24456, epoch: 12, loss: 1.278989
global_step: 24457, epoch: 12, loss: 1.285429
global_step: 24458, epoch: 12, loss: 1.243999
global_step: 24459, epoch: 12, loss: 1.248897
global_step: 24460, epoch: 12, loss: 1.286193
global_step: 24461, epoch: 12, loss: 1.177469
global_step: 24462, epoch: 12, loss: 1.186055
global_step: 24463, epoch: 12, loss: 1.244862
global_step: 24464, epoch: 12, loss: 1.260672
global_step: 24465, epoch: 12, loss: 1.427478
global_step: 24466, epoch: 12, loss: 1.234376
global_step: 24467, epoch: 12, loss: 1.319735
global_step: 24468, epoch: 12, loss: 1.314476
global_step: 24469, epoch: 12, loss: 1.285329
global_step: 24470, epoch: 12, loss: 1.327780
global_step: 24471, epoch: 12, loss: 1.220910
global_step: 24472, epoch: 12, loss: 1.265739
global_step: 24473, epoch: 12, loss: 1.360243
global_step: 24474, epoch: 12, loss: 1.258711
global_step: 24475, epoch: 12, loss: 1.380692
global_step: 24476, epoch: 12, loss: 1.262838
global_step: 24477, epoch: 12, loss: 1.333282
global_step: 24478, epoch: 12, loss: 1.221767
global_step: 24479, epoch: 12, loss: 1.302887
global_step: 24480, epoch: 12, loss: 1.808440
epoch: 12
train	acc: 0.5803	macro: p 0.3087, r 0.2690, f1: 0.2493	micro: p 0.5803, r 0.5803, f1 0.5803	weighted_f1:0.5025
dev	acc: 0.5257	macro: p 0.2504, r 0.2667, f1: 0.2273	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4294
test	acc: 0.5797	macro: p 0.2977, r 0.2741, f1: 0.2475	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.4982
global_step: 24481, epoch: 13, loss: 1.288979
global_step: 24482, epoch: 13, loss: 1.303450
global_step: 24483, epoch: 13, loss: 1.307627
global_step: 24484, epoch: 13, loss: 1.216704
global_step: 24485, epoch: 13, loss: 1.272219
global_step: 24486, epoch: 13, loss: 1.279915
global_step: 24487, epoch: 13, loss: 1.308416
global_step: 24488, epoch: 13, loss: 1.258536
global_step: 24489, epoch: 13, loss: 1.351048
global_step: 24490, epoch: 13, loss: 1.339114
global_step: 24491, epoch: 13, loss: 1.318379
global_step: 24492, epoch: 13, loss: 1.263836
global_step: 24493, epoch: 13, loss: 1.290696
global_step: 24494, epoch: 13, loss: 1.191638
global_step: 24495, epoch: 13, loss: 1.185822
global_step: 24496, epoch: 13, loss: 1.276604
global_step: 24497, epoch: 13, loss: 1.349761
global_step: 24498, epoch: 13, loss: 1.243975
global_step: 24499, epoch: 13, loss: 1.229203
global_step: 24500, epoch: 13, loss: 1.196857
global_step: 24501, epoch: 13, loss: 1.278359
global_step: 24502, epoch: 13, loss: 1.210095
global_step: 24503, epoch: 13, loss: 1.329778
global_step: 24504, epoch: 13, loss: 1.324430
global_step: 24505, epoch: 13, loss: 1.361293
global_step: 24506, epoch: 13, loss: 1.195204
global_step: 24507, epoch: 13, loss: 1.219522
global_step: 24508, epoch: 13, loss: 1.155855
global_step: 24509, epoch: 13, loss: 1.264069
global_step: 24510, epoch: 13, loss: 1.275225
global_step: 24511, epoch: 13, loss: 1.254922
global_step: 24512, epoch: 13, loss: 1.211465
global_step: 24513, epoch: 13, loss: 1.324230
global_step: 24514, epoch: 13, loss: 1.285886
global_step: 24515, epoch: 13, loss: 1.246857
global_step: 24516, epoch: 13, loss: 1.306033
global_step: 24517, epoch: 13, loss: 1.307249
global_step: 24518, epoch: 13, loss: 1.301784
global_step: 24519, epoch: 13, loss: 1.223151
global_step: 24520, epoch: 13, loss: 1.083269
epoch: 13
train	acc: 0.5796	macro: p 0.3075, r 0.2674, f1: 0.2476	micro: p 0.5796, r 0.5796, f1 0.5796	weighted_f1:0.5007
dev	acc: 0.5266	macro: p 0.2557, r 0.2659, f1: 0.2272	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4296
test	acc: 0.5789	macro: p 0.2956, r 0.2731, f1: 0.2461	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.4966
global_step: 24521, epoch: 14, loss: 1.277629
global_step: 24522, epoch: 14, loss: 1.293240
global_step: 24523, epoch: 14, loss: 1.346727
global_step: 24524, epoch: 14, loss: 1.245005
global_step: 24525, epoch: 14, loss: 1.324756
global_step: 24526, epoch: 14, loss: 1.284034
global_step: 24527, epoch: 14, loss: 1.234135
global_step: 24528, epoch: 14, loss: 1.179106
global_step: 24529, epoch: 14, loss: 1.178203
global_step: 24530, epoch: 14, loss: 1.315222
global_step: 24531, epoch: 14, loss: 1.353138
global_step: 24532, epoch: 14, loss: 1.187061
global_step: 24533, epoch: 14, loss: 1.159643
global_step: 24534, epoch: 14, loss: 1.246270
global_step: 24535, epoch: 14, loss: 1.237879
global_step: 24536, epoch: 14, loss: 1.276209
global_step: 24537, epoch: 14, loss: 1.301004
global_step: 24538, epoch: 14, loss: 1.321468
global_step: 24539, epoch: 14, loss: 1.244344
global_step: 24540, epoch: 14, loss: 1.268356
global_step: 24541, epoch: 14, loss: 1.319975
global_step: 24542, epoch: 14, loss: 1.319205
global_step: 24543, epoch: 14, loss: 1.136200
global_step: 24544, epoch: 14, loss: 1.254178
global_step: 24545, epoch: 14, loss: 1.182887
global_step: 24546, epoch: 14, loss: 1.343198
global_step: 24547, epoch: 14, loss: 1.248106
global_step: 24548, epoch: 14, loss: 1.289846
global_step: 24549, epoch: 14, loss: 1.308934
global_step: 24550, epoch: 14, loss: 1.193883
global_step: 24551, epoch: 14, loss: 1.236680
global_step: 24552, epoch: 14, loss: 1.186523
global_step: 24553, epoch: 14, loss: 1.328217
global_step: 24554, epoch: 14, loss: 1.268252
global_step: 24555, epoch: 14, loss: 1.289085
global_step: 24556, epoch: 14, loss: 1.237768
global_step: 24557, epoch: 14, loss: 1.248191
global_step: 24558, epoch: 14, loss: 1.185333
global_step: 24559, epoch: 14, loss: 1.237426
global_step: 24560, epoch: 14, loss: 1.411927
epoch: 14
train	acc: 0.5927	macro: p 0.3075, r 0.2871, f1: 0.2782	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5268
dev	acc: 0.5338	macro: p 0.2733, r 0.2768, f1: 0.2495	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4512
test	acc: 0.5885	macro: p 0.2995, r 0.2874, f1: 0.2717	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5201
New best model!
global_step: 24561, epoch: 15, loss: 1.115963
global_step: 24562, epoch: 15, loss: 1.296474
global_step: 24563, epoch: 15, loss: 1.224290
global_step: 24564, epoch: 15, loss: 1.236483
global_step: 24565, epoch: 15, loss: 1.294129
global_step: 24566, epoch: 15, loss: 1.327469
global_step: 24567, epoch: 15, loss: 1.251535
global_step: 24568, epoch: 15, loss: 1.268396
global_step: 24569, epoch: 15, loss: 1.302787
global_step: 24570, epoch: 15, loss: 1.246977
global_step: 24571, epoch: 15, loss: 1.193539
global_step: 24572, epoch: 15, loss: 1.301296
global_step: 24573, epoch: 15, loss: 1.285493
global_step: 24574, epoch: 15, loss: 1.271425
global_step: 24575, epoch: 15, loss: 1.213330
global_step: 24576, epoch: 15, loss: 1.368121
global_step: 24577, epoch: 15, loss: 1.169691
global_step: 24578, epoch: 15, loss: 1.330174
global_step: 24579, epoch: 15, loss: 1.238076
global_step: 24580, epoch: 15, loss: 1.255562
global_step: 24581, epoch: 15, loss: 1.162336
global_step: 24582, epoch: 15, loss: 1.225750
global_step: 24583, epoch: 15, loss: 1.228740
global_step: 24584, epoch: 15, loss: 1.059842
global_step: 24585, epoch: 15, loss: 1.237034
global_step: 24586, epoch: 15, loss: 1.268409
global_step: 24587, epoch: 15, loss: 1.306690
global_step: 24588, epoch: 15, loss: 1.185578
global_step: 24589, epoch: 15, loss: 1.275088
global_step: 24590, epoch: 15, loss: 1.365929
global_step: 24591, epoch: 15, loss: 1.328531
global_step: 24592, epoch: 15, loss: 1.241346
global_step: 24593, epoch: 15, loss: 1.130648
global_step: 24594, epoch: 15, loss: 1.275704
global_step: 24595, epoch: 15, loss: 1.231789
global_step: 24596, epoch: 15, loss: 1.386359
global_step: 24597, epoch: 15, loss: 1.228158
global_step: 24598, epoch: 15, loss: 1.245650
global_step: 24599, epoch: 15, loss: 1.254970
global_step: 24600, epoch: 15, loss: 0.553028
epoch: 15
train	acc: 0.5894	macro: p 0.3142, r 0.2772, f1: 0.2697	micro: p 0.5894, r 0.5894, f1 0.5894	weighted_f1:0.5182
dev	acc: 0.5302	macro: p 0.2780, r 0.2682, f1: 0.2429	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4440
test	acc: 0.5904	macro: p 0.3116, r 0.2819, f1: 0.2690	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5173
global_step: 24601, epoch: 16, loss: 1.386746
global_step: 24602, epoch: 16, loss: 1.223391
global_step: 24603, epoch: 16, loss: 1.142397
global_step: 24604, epoch: 16, loss: 1.245572
global_step: 24605, epoch: 16, loss: 1.266884
global_step: 24606, epoch: 16, loss: 1.246006
global_step: 24607, epoch: 16, loss: 1.322169
global_step: 24608, epoch: 16, loss: 1.367639
global_step: 24609, epoch: 16, loss: 1.210695
global_step: 24610, epoch: 16, loss: 1.230901
global_step: 24611, epoch: 16, loss: 1.308120
global_step: 24612, epoch: 16, loss: 1.132187
global_step: 24613, epoch: 16, loss: 1.263539
global_step: 24614, epoch: 16, loss: 1.165899
global_step: 24615, epoch: 16, loss: 1.165365
global_step: 24616, epoch: 16, loss: 1.202374
global_step: 24617, epoch: 16, loss: 1.258809
global_step: 24618, epoch: 16, loss: 1.208446
global_step: 24619, epoch: 16, loss: 1.292166
global_step: 24620, epoch: 16, loss: 1.148817
global_step: 24621, epoch: 16, loss: 1.319249
global_step: 24622, epoch: 16, loss: 1.070403
global_step: 24623, epoch: 16, loss: 1.270503
global_step: 24624, epoch: 16, loss: 1.236332
global_step: 24625, epoch: 16, loss: 1.291388
global_step: 24626, epoch: 16, loss: 1.280500
global_step: 24627, epoch: 16, loss: 1.213731
global_step: 24628, epoch: 16, loss: 1.201197
global_step: 24629, epoch: 16, loss: 1.311616
global_step: 24630, epoch: 16, loss: 1.276872
global_step: 24631, epoch: 16, loss: 1.308995
global_step: 24632, epoch: 16, loss: 1.202410
global_step: 24633, epoch: 16, loss: 1.290732
global_step: 24634, epoch: 16, loss: 1.198395
global_step: 24635, epoch: 16, loss: 1.166605
global_step: 24636, epoch: 16, loss: 1.132809
global_step: 24637, epoch: 16, loss: 1.226172
global_step: 24638, epoch: 16, loss: 1.276935
global_step: 24639, epoch: 16, loss: 1.189162
global_step: 24640, epoch: 16, loss: 1.141304
epoch: 16
train	acc: 0.5934	macro: p 0.3103, r 0.2874, f1: 0.2722	micro: p 0.5934, r 0.5934, f1 0.5934	weighted_f1:0.5240
dev	acc: 0.5347	macro: p 0.2685, r 0.2790, f1: 0.2471	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4496
test	acc: 0.5831	macro: p 0.2921, r 0.2846, f1: 0.2609	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5101
global_step: 24641, epoch: 17, loss: 1.196368
global_step: 24642, epoch: 17, loss: 1.169480
global_step: 24643, epoch: 17, loss: 1.207924
global_step: 24644, epoch: 17, loss: 1.309123
global_step: 24645, epoch: 17, loss: 1.141150
global_step: 24646, epoch: 17, loss: 1.248096
global_step: 24647, epoch: 17, loss: 1.305856
global_step: 24648, epoch: 17, loss: 1.190107
global_step: 24649, epoch: 17, loss: 1.318098
global_step: 24650, epoch: 17, loss: 1.345054
global_step: 24651, epoch: 17, loss: 1.241543
global_step: 24652, epoch: 17, loss: 1.174420
global_step: 24653, epoch: 17, loss: 1.136267
global_step: 24654, epoch: 17, loss: 1.202541
global_step: 24655, epoch: 17, loss: 1.302240
global_step: 24656, epoch: 17, loss: 1.261406
global_step: 24657, epoch: 17, loss: 1.210629
global_step: 24658, epoch: 17, loss: 1.258064
global_step: 24659, epoch: 17, loss: 1.225554
global_step: 24660, epoch: 17, loss: 1.234121
global_step: 24661, epoch: 17, loss: 1.232763
global_step: 24662, epoch: 17, loss: 1.247688
global_step: 24663, epoch: 17, loss: 1.162169
global_step: 24664, epoch: 17, loss: 1.245639
global_step: 24665, epoch: 17, loss: 1.202234
global_step: 24666, epoch: 17, loss: 1.193274
global_step: 24667, epoch: 17, loss: 1.301000
global_step: 24668, epoch: 17, loss: 1.199193
global_step: 24669, epoch: 17, loss: 1.339686
global_step: 24670, epoch: 17, loss: 1.252765
global_step: 24671, epoch: 17, loss: 1.221235
global_step: 24672, epoch: 17, loss: 1.147027
global_step: 24673, epoch: 17, loss: 1.176021
global_step: 24674, epoch: 17, loss: 1.124288
global_step: 24675, epoch: 17, loss: 1.162590
global_step: 24676, epoch: 17, loss: 1.238263
global_step: 24677, epoch: 17, loss: 1.324206
global_step: 24678, epoch: 17, loss: 1.243037
global_step: 24679, epoch: 17, loss: 1.232174
global_step: 24680, epoch: 17, loss: 1.410460
epoch: 17
train	acc: 0.6022	macro: p 0.3127, r 0.2989, f1: 0.2931	micro: p 0.6022, r 0.6022, f1 0.6022	weighted_f1:0.5406
dev	acc: 0.5455	macro: p 0.2795, r 0.2867, f1: 0.2658	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4682
test	acc: 0.5985	macro: p 0.3059, r 0.2977, f1: 0.2860	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5340
New best model!
global_step: 24681, epoch: 18, loss: 1.165610
global_step: 24682, epoch: 18, loss: 1.196160
global_step: 24683, epoch: 18, loss: 1.286976
global_step: 24684, epoch: 18, loss: 1.283778
global_step: 24685, epoch: 18, loss: 1.175704
global_step: 24686, epoch: 18, loss: 1.283789
global_step: 24687, epoch: 18, loss: 1.245977
global_step: 24688, epoch: 18, loss: 1.353141
global_step: 24689, epoch: 18, loss: 1.177168
global_step: 24690, epoch: 18, loss: 1.172747
global_step: 24691, epoch: 18, loss: 1.171420
global_step: 24692, epoch: 18, loss: 1.245639
global_step: 24693, epoch: 18, loss: 1.279276
global_step: 24694, epoch: 18, loss: 1.182176
global_step: 24695, epoch: 18, loss: 1.203328
global_step: 24696, epoch: 18, loss: 1.185123
global_step: 24697, epoch: 18, loss: 1.264826
global_step: 24698, epoch: 18, loss: 1.217661
global_step: 24699, epoch: 18, loss: 1.227477
global_step: 24700, epoch: 18, loss: 1.232183
global_step: 24701, epoch: 18, loss: 1.184395
global_step: 24702, epoch: 18, loss: 1.298162
global_step: 24703, epoch: 18, loss: 1.329947
global_step: 24704, epoch: 18, loss: 1.314705
global_step: 24705, epoch: 18, loss: 1.196312
global_step: 24706, epoch: 18, loss: 1.257806
global_step: 24707, epoch: 18, loss: 1.252945
global_step: 24708, epoch: 18, loss: 1.166675
global_step: 24709, epoch: 18, loss: 1.353326
global_step: 24710, epoch: 18, loss: 1.305065
global_step: 24711, epoch: 18, loss: 1.272864
global_step: 24712, epoch: 18, loss: 1.230008
global_step: 24713, epoch: 18, loss: 1.109518
global_step: 24714, epoch: 18, loss: 1.034495
global_step: 24715, epoch: 18, loss: 1.270478
global_step: 24716, epoch: 18, loss: 1.227208
global_step: 24717, epoch: 18, loss: 1.227037
global_step: 24718, epoch: 18, loss: 1.208665
global_step: 24719, epoch: 18, loss: 1.059935
global_step: 24720, epoch: 18, loss: 1.146645
epoch: 18
train	acc: 0.6008	macro: p 0.3177, r 0.2949, f1: 0.2915	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5376
dev	acc: 0.5401	macro: p 0.2754, r 0.2786, f1: 0.2581	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4598
test	acc: 0.5989	macro: p 0.3068, r 0.2933, f1: 0.2841	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5326
global_step: 24721, epoch: 19, loss: 1.256318
global_step: 24722, epoch: 19, loss: 1.196856
global_step: 24723, epoch: 19, loss: 1.269794
global_step: 24724, epoch: 19, loss: 1.106885
global_step: 24725, epoch: 19, loss: 1.134015
global_step: 24726, epoch: 19, loss: 1.169245
global_step: 24727, epoch: 19, loss: 1.279666
global_step: 24728, epoch: 19, loss: 1.073182
global_step: 24729, epoch: 19, loss: 1.103804
global_step: 24730, epoch: 19, loss: 1.098675
global_step: 24731, epoch: 19, loss: 1.192914
global_step: 24732, epoch: 19, loss: 1.241094
global_step: 24733, epoch: 19, loss: 1.285442
global_step: 24734, epoch: 19, loss: 1.210100
global_step: 24735, epoch: 19, loss: 1.314860
global_step: 24736, epoch: 19, loss: 1.219835
global_step: 24737, epoch: 19, loss: 1.168790
global_step: 24738, epoch: 19, loss: 1.318180
global_step: 24739, epoch: 19, loss: 1.210785
global_step: 24740, epoch: 19, loss: 1.249109
global_step: 24741, epoch: 19, loss: 1.167430
global_step: 24742, epoch: 19, loss: 1.118984
global_step: 24743, epoch: 19, loss: 1.240477
global_step: 24744, epoch: 19, loss: 1.178530
global_step: 24745, epoch: 19, loss: 1.247983
global_step: 24746, epoch: 19, loss: 1.307140
global_step: 24747, epoch: 19, loss: 1.376817
global_step: 24748, epoch: 19, loss: 1.193601
global_step: 24749, epoch: 19, loss: 1.173934
global_step: 24750, epoch: 19, loss: 1.322598
global_step: 24751, epoch: 19, loss: 1.234723
global_step: 24752, epoch: 19, loss: 1.213400
global_step: 24753, epoch: 19, loss: 1.277891
global_step: 24754, epoch: 19, loss: 1.182190
global_step: 24755, epoch: 19, loss: 1.226848
global_step: 24756, epoch: 19, loss: 1.133436
global_step: 24757, epoch: 19, loss: 1.293208
global_step: 24758, epoch: 19, loss: 1.227352
global_step: 24759, epoch: 19, loss: 1.179116
global_step: 24760, epoch: 19, loss: 1.727521
epoch: 19
train	acc: 0.6024	macro: p 0.4520, r 0.3000, f1: 0.2865	micro: p 0.6024, r 0.6024, f1 0.6024	weighted_f1:0.5379
dev	acc: 0.5428	macro: p 0.2851, r 0.2901, f1: 0.2609	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4623
test	acc: 0.5912	macro: p 0.4409, r 0.2968, f1: 0.2775	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5247
global_step: 24761, epoch: 20, loss: 1.292599
global_step: 24762, epoch: 20, loss: 1.193581
global_step: 24763, epoch: 20, loss: 1.239498
global_step: 24764, epoch: 20, loss: 1.106537
global_step: 24765, epoch: 20, loss: 1.254238
global_step: 24766, epoch: 20, loss: 1.212175
global_step: 24767, epoch: 20, loss: 1.220662
global_step: 24768, epoch: 20, loss: 1.202926
global_step: 24769, epoch: 20, loss: 1.356783
global_step: 24770, epoch: 20, loss: 1.257495
global_step: 24771, epoch: 20, loss: 1.140529
global_step: 24772, epoch: 20, loss: 1.383102
global_step: 24773, epoch: 20, loss: 1.309186
global_step: 24774, epoch: 20, loss: 1.252909
global_step: 24775, epoch: 20, loss: 1.241100
global_step: 24776, epoch: 20, loss: 1.093728
global_step: 24777, epoch: 20, loss: 1.098954
global_step: 24778, epoch: 20, loss: 1.155753
global_step: 24779, epoch: 20, loss: 1.232806
global_step: 24780, epoch: 20, loss: 1.220699
global_step: 24781, epoch: 20, loss: 1.179782
global_step: 24782, epoch: 20, loss: 1.080055
global_step: 24783, epoch: 20, loss: 1.278426
global_step: 24784, epoch: 20, loss: 1.193446
global_step: 24785, epoch: 20, loss: 1.139243
global_step: 24786, epoch: 20, loss: 1.061470
global_step: 24787, epoch: 20, loss: 1.191539
global_step: 24788, epoch: 20, loss: 1.117909
global_step: 24789, epoch: 20, loss: 1.299203
global_step: 24790, epoch: 20, loss: 1.166567
global_step: 24791, epoch: 20, loss: 1.071982
global_step: 24792, epoch: 20, loss: 1.289763
global_step: 24793, epoch: 20, loss: 1.197537
global_step: 24794, epoch: 20, loss: 1.131252
global_step: 24795, epoch: 20, loss: 1.133922
global_step: 24796, epoch: 20, loss: 1.251765
global_step: 24797, epoch: 20, loss: 1.296420
global_step: 24798, epoch: 20, loss: 1.156322
global_step: 24799, epoch: 20, loss: 1.248138
global_step: 24800, epoch: 20, loss: 1.009669
epoch: 20
train	acc: 0.6038	macro: p 0.3199, r 0.2968, f1: 0.2934	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5401
dev	acc: 0.5410	macro: p 0.2780, r 0.2796, f1: 0.2586	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4603
test	acc: 0.6004	macro: p 0.3094, r 0.2949, f1: 0.2855	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5339
global_step: 24801, epoch: 21, loss: 1.296531
global_step: 24802, epoch: 21, loss: 1.109623
global_step: 24803, epoch: 21, loss: 1.148432
global_step: 24804, epoch: 21, loss: 1.304706
global_step: 24805, epoch: 21, loss: 1.092457
global_step: 24806, epoch: 21, loss: 1.281601
global_step: 24807, epoch: 21, loss: 1.239633
global_step: 24808, epoch: 21, loss: 1.239458
global_step: 24809, epoch: 21, loss: 1.101308
global_step: 24810, epoch: 21, loss: 1.220953
global_step: 24811, epoch: 21, loss: 1.199918
global_step: 24812, epoch: 21, loss: 1.248994
global_step: 24813, epoch: 21, loss: 1.194822
global_step: 24814, epoch: 21, loss: 1.222833
global_step: 24815, epoch: 21, loss: 1.227714
global_step: 24816, epoch: 21, loss: 1.169163
global_step: 24817, epoch: 21, loss: 1.258929
global_step: 24818, epoch: 21, loss: 1.171946
global_step: 24819, epoch: 21, loss: 1.233785
global_step: 24820, epoch: 21, loss: 1.097604
global_step: 24821, epoch: 21, loss: 1.193077
global_step: 24822, epoch: 21, loss: 1.073302
global_step: 24823, epoch: 21, loss: 1.272321
global_step: 24824, epoch: 21, loss: 1.134192
global_step: 24825, epoch: 21, loss: 1.178064
global_step: 24826, epoch: 21, loss: 1.223926
global_step: 24827, epoch: 21, loss: 1.120078
global_step: 24828, epoch: 21, loss: 1.190031
global_step: 24829, epoch: 21, loss: 1.202682
global_step: 24830, epoch: 21, loss: 1.250653
global_step: 24831, epoch: 21, loss: 1.179013
global_step: 24832, epoch: 21, loss: 1.199777
global_step: 24833, epoch: 21, loss: 1.258628
global_step: 24834, epoch: 21, loss: 1.176930
global_step: 24835, epoch: 21, loss: 1.295999
global_step: 24836, epoch: 21, loss: 1.178155
global_step: 24837, epoch: 21, loss: 1.181449
global_step: 24838, epoch: 21, loss: 1.159066
global_step: 24839, epoch: 21, loss: 1.178825
global_step: 24840, epoch: 21, loss: 1.169572
epoch: 21
train	acc: 0.5996	macro: p 0.4703, r 0.2887, f1: 0.2776	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5295
dev	acc: 0.5410	macro: p 0.2897, r 0.2812, f1: 0.2521	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4548
test	acc: 0.5912	macro: p 0.4552, r 0.2858, f1: 0.2691	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5185
global_step: 24841, epoch: 22, loss: 1.198608
global_step: 24842, epoch: 22, loss: 1.212700
global_step: 24843, epoch: 22, loss: 1.162861
global_step: 24844, epoch: 22, loss: 1.294643
global_step: 24845, epoch: 22, loss: 1.193452
global_step: 24846, epoch: 22, loss: 1.203691
global_step: 24847, epoch: 22, loss: 1.286306
global_step: 24848, epoch: 22, loss: 1.269340
global_step: 24849, epoch: 22, loss: 1.115359
global_step: 24850, epoch: 22, loss: 1.280687
global_step: 24851, epoch: 22, loss: 1.141034
global_step: 24852, epoch: 22, loss: 1.145128
global_step: 24853, epoch: 22, loss: 1.202207
global_step: 24854, epoch: 22, loss: 1.237868
global_step: 24855, epoch: 22, loss: 1.112361
global_step: 24856, epoch: 22, loss: 1.161739
global_step: 24857, epoch: 22, loss: 1.058235
global_step: 24858, epoch: 22, loss: 1.181973
global_step: 24859, epoch: 22, loss: 1.214706
global_step: 24860, epoch: 22, loss: 1.162636
global_step: 24861, epoch: 22, loss: 1.332434
global_step: 24862, epoch: 22, loss: 1.189008
global_step: 24863, epoch: 22, loss: 1.069283
global_step: 24864, epoch: 22, loss: 1.118323
global_step: 24865, epoch: 22, loss: 1.101773
global_step: 24866, epoch: 22, loss: 1.122275
global_step: 24867, epoch: 22, loss: 1.079989
global_step: 24868, epoch: 22, loss: 1.336831
global_step: 24869, epoch: 22, loss: 1.190673
global_step: 24870, epoch: 22, loss: 1.082840
global_step: 24871, epoch: 22, loss: 1.211130
global_step: 24872, epoch: 22, loss: 1.185286
global_step: 24873, epoch: 22, loss: 1.229978
global_step: 24874, epoch: 22, loss: 1.102880
global_step: 24875, epoch: 22, loss: 1.202234
global_step: 24876, epoch: 22, loss: 1.217343
global_step: 24877, epoch: 22, loss: 1.208348
global_step: 24878, epoch: 22, loss: 1.268335
global_step: 24879, epoch: 22, loss: 1.187628
global_step: 24880, epoch: 22, loss: 0.991451
epoch: 22
train	acc: 0.6102	macro: p 0.4280, r 0.3052, f1: 0.3023	micro: p 0.6102, r 0.6102, f1 0.6102	weighted_f1:0.5489
dev	acc: 0.5500	macro: p 0.2852, r 0.2906, f1: 0.2690	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4718
test	acc: 0.6023	macro: p 0.4243, r 0.3013, f1: 0.2926	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5389
New best model!
global_step: 24881, epoch: 23, loss: 1.119355
global_step: 24882, epoch: 23, loss: 1.233910
global_step: 24883, epoch: 23, loss: 1.107533
global_step: 24884, epoch: 23, loss: 1.145855
global_step: 24885, epoch: 23, loss: 1.157171
global_step: 24886, epoch: 23, loss: 1.164920
global_step: 24887, epoch: 23, loss: 1.115287
global_step: 24888, epoch: 23, loss: 1.143147
global_step: 24889, epoch: 23, loss: 1.173033
global_step: 24890, epoch: 23, loss: 1.149972
global_step: 24891, epoch: 23, loss: 1.115972
global_step: 24892, epoch: 23, loss: 1.157140
global_step: 24893, epoch: 23, loss: 1.082962
global_step: 24894, epoch: 23, loss: 1.051872
global_step: 24895, epoch: 23, loss: 1.278551
global_step: 24896, epoch: 23, loss: 1.224151
global_step: 24897, epoch: 23, loss: 1.242112
global_step: 24898, epoch: 23, loss: 1.187250
global_step: 24899, epoch: 23, loss: 1.215248
global_step: 24900, epoch: 23, loss: 1.170325
global_step: 24901, epoch: 23, loss: 1.135111
global_step: 24902, epoch: 23, loss: 1.162522
global_step: 24903, epoch: 23, loss: 1.139616
global_step: 24904, epoch: 23, loss: 1.190695
global_step: 24905, epoch: 23, loss: 1.215922
global_step: 24906, epoch: 23, loss: 1.178037
global_step: 24907, epoch: 23, loss: 1.157535
global_step: 24908, epoch: 23, loss: 1.170579
global_step: 24909, epoch: 23, loss: 1.070245
global_step: 24910, epoch: 23, loss: 1.273428
global_step: 24911, epoch: 23, loss: 1.173268
global_step: 24912, epoch: 23, loss: 1.253409
global_step: 24913, epoch: 23, loss: 1.146557
global_step: 24914, epoch: 23, loss: 1.255102
global_step: 24915, epoch: 23, loss: 1.250313
global_step: 24916, epoch: 23, loss: 1.278429
global_step: 24917, epoch: 23, loss: 1.073903
global_step: 24918, epoch: 23, loss: 1.157342
global_step: 24919, epoch: 23, loss: 1.196450
global_step: 24920, epoch: 23, loss: 0.913748
epoch: 23
train	acc: 0.6163	macro: p 0.4193, r 0.3182, f1: 0.3142	micro: p 0.6163, r 0.6163, f1 0.6163	weighted_f1:0.5599
dev	acc: 0.5591	macro: p 0.2865, r 0.3011, f1: 0.2862	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.4885
test	acc: 0.6080	macro: p 0.4221, r 0.3135, f1: 0.3073	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5515
New best model!
global_step: 24921, epoch: 24, loss: 1.149311
global_step: 24922, epoch: 24, loss: 1.202082
global_step: 24923, epoch: 24, loss: 1.210667
global_step: 24924, epoch: 24, loss: 1.302893
global_step: 24925, epoch: 24, loss: 1.126059
global_step: 24926, epoch: 24, loss: 1.213983
global_step: 24927, epoch: 24, loss: 1.054921
global_step: 24928, epoch: 24, loss: 1.205658
global_step: 24929, epoch: 24, loss: 1.134259
global_step: 24930, epoch: 24, loss: 1.236618
global_step: 24931, epoch: 24, loss: 1.226420
global_step: 24932, epoch: 24, loss: 1.151809
global_step: 24933, epoch: 24, loss: 1.085726
global_step: 24934, epoch: 24, loss: 1.146750
global_step: 24935, epoch: 24, loss: 1.168892
global_step: 24936, epoch: 24, loss: 1.114484
global_step: 24937, epoch: 24, loss: 1.124047
global_step: 24938, epoch: 24, loss: 1.086323
global_step: 24939, epoch: 24, loss: 1.238863
global_step: 24940, epoch: 24, loss: 1.149253
global_step: 24941, epoch: 24, loss: 1.148846
global_step: 24942, epoch: 24, loss: 1.128617
global_step: 24943, epoch: 24, loss: 1.128640
global_step: 24944, epoch: 24, loss: 1.167518
global_step: 24945, epoch: 24, loss: 1.112630
global_step: 24946, epoch: 24, loss: 1.168105
global_step: 24947, epoch: 24, loss: 1.141744
global_step: 24948, epoch: 24, loss: 1.176118
global_step: 24949, epoch: 24, loss: 1.268024
global_step: 24950, epoch: 24, loss: 1.157471
global_step: 24951, epoch: 24, loss: 1.239961
global_step: 24952, epoch: 24, loss: 1.142547
global_step: 24953, epoch: 24, loss: 1.095033
global_step: 24954, epoch: 24, loss: 1.248249
global_step: 24955, epoch: 24, loss: 1.238328
global_step: 24956, epoch: 24, loss: 1.071529
global_step: 24957, epoch: 24, loss: 1.194436
global_step: 24958, epoch: 24, loss: 1.234880
global_step: 24959, epoch: 24, loss: 1.259841
global_step: 24960, epoch: 24, loss: 1.244066
epoch: 24
train	acc: 0.6188	macro: p 0.4327, r 0.3141, f1: 0.3121	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5589
dev	acc: 0.5509	macro: p 0.2904, r 0.2935, f1: 0.2724	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4745
test	acc: 0.6046	macro: p 0.4282, r 0.3050, f1: 0.2964	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5420
global_step: 24961, epoch: 25, loss: 1.147756
global_step: 24962, epoch: 25, loss: 1.225790
global_step: 24963, epoch: 25, loss: 1.226083
global_step: 24964, epoch: 25, loss: 1.129099
global_step: 24965, epoch: 25, loss: 1.243794
global_step: 24966, epoch: 25, loss: 1.127380
global_step: 24967, epoch: 25, loss: 1.227201
global_step: 24968, epoch: 25, loss: 1.254673
global_step: 24969, epoch: 25, loss: 1.036677
global_step: 24970, epoch: 25, loss: 1.064834
global_step: 24971, epoch: 25, loss: 1.198782
global_step: 24972, epoch: 25, loss: 1.092482
global_step: 24973, epoch: 25, loss: 1.227650
global_step: 24974, epoch: 25, loss: 1.051077
global_step: 24975, epoch: 25, loss: 1.102413
global_step: 24976, epoch: 25, loss: 1.104295
global_step: 24977, epoch: 25, loss: 1.189745
global_step: 24978, epoch: 25, loss: 1.219564
global_step: 24979, epoch: 25, loss: 1.179295
global_step: 24980, epoch: 25, loss: 1.068043
global_step: 24981, epoch: 25, loss: 1.066912
global_step: 24982, epoch: 25, loss: 1.245058
global_step: 24983, epoch: 25, loss: 1.092914
global_step: 24984, epoch: 25, loss: 1.287025
global_step: 24985, epoch: 25, loss: 1.176582
global_step: 24986, epoch: 25, loss: 1.129506
global_step: 24987, epoch: 25, loss: 1.210483
global_step: 24988, epoch: 25, loss: 1.269649
global_step: 24989, epoch: 25, loss: 1.121434
global_step: 24990, epoch: 25, loss: 1.187094
global_step: 24991, epoch: 25, loss: 1.161385
global_step: 24992, epoch: 25, loss: 1.153177
global_step: 24993, epoch: 25, loss: 1.246585
global_step: 24994, epoch: 25, loss: 1.049526
global_step: 24995, epoch: 25, loss: 1.119752
global_step: 24996, epoch: 25, loss: 1.191629
global_step: 24997, epoch: 25, loss: 1.197324
global_step: 24998, epoch: 25, loss: 1.115676
global_step: 24999, epoch: 25, loss: 1.113745
global_step: 25000, epoch: 25, loss: 1.180512
epoch: 25
train	acc: 0.6183	macro: p 0.4395, r 0.3132, f1: 0.3115	micro: p 0.6183, r 0.6183, f1 0.6183	weighted_f1:0.5588
dev	acc: 0.5464	macro: p 0.2849, r 0.2896, f1: 0.2671	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4698
test	acc: 0.6015	macro: p 0.4260, r 0.3007, f1: 0.2927	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5393
global_step: 25001, epoch: 26, loss: 1.116756
global_step: 25002, epoch: 26, loss: 1.197052
global_step: 25003, epoch: 26, loss: 1.154382
global_step: 25004, epoch: 26, loss: 1.325510
global_step: 25005, epoch: 26, loss: 1.228725
global_step: 25006, epoch: 26, loss: 1.168905
global_step: 25007, epoch: 26, loss: 1.198348
global_step: 25008, epoch: 26, loss: 1.139567
global_step: 25009, epoch: 26, loss: 1.323725
global_step: 25010, epoch: 26, loss: 1.179033
global_step: 25011, epoch: 26, loss: 1.119864
global_step: 25012, epoch: 26, loss: 1.055258
global_step: 25013, epoch: 26, loss: 1.137934
global_step: 25014, epoch: 26, loss: 1.197933
global_step: 25015, epoch: 26, loss: 1.148170
global_step: 25016, epoch: 26, loss: 1.127075
global_step: 25017, epoch: 26, loss: 1.091252
global_step: 25018, epoch: 26, loss: 1.191300
global_step: 25019, epoch: 26, loss: 1.122789
global_step: 25020, epoch: 26, loss: 1.122388
global_step: 25021, epoch: 26, loss: 1.140041
global_step: 25022, epoch: 26, loss: 1.218942
global_step: 25023, epoch: 26, loss: 1.027250
global_step: 25024, epoch: 26, loss: 1.123813
global_step: 25025, epoch: 26, loss: 1.076959
global_step: 25026, epoch: 26, loss: 1.235968
global_step: 25027, epoch: 26, loss: 1.125679
global_step: 25028, epoch: 26, loss: 1.157991
global_step: 25029, epoch: 26, loss: 1.259116
global_step: 25030, epoch: 26, loss: 1.165325
global_step: 25031, epoch: 26, loss: 1.291677
global_step: 25032, epoch: 26, loss: 1.125315
global_step: 25033, epoch: 26, loss: 1.056530
global_step: 25034, epoch: 26, loss: 1.197634
global_step: 25035, epoch: 26, loss: 1.007901
global_step: 25036, epoch: 26, loss: 1.117864
global_step: 25037, epoch: 26, loss: 1.169405
global_step: 25038, epoch: 26, loss: 1.223119
global_step: 25039, epoch: 26, loss: 1.130109
global_step: 25040, epoch: 26, loss: 0.887000
epoch: 26
train	acc: 0.6221	macro: p 0.4412, r 0.3164, f1: 0.3139	micro: p 0.6221, r 0.6221, f1 0.6221	weighted_f1:0.5618
dev	acc: 0.5537	macro: p 0.2894, r 0.2956, f1: 0.2739	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4759
test	acc: 0.6065	macro: p 0.4275, r 0.3060, f1: 0.2979	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5436
global_step: 25041, epoch: 27, loss: 1.056560
global_step: 25042, epoch: 27, loss: 1.185195
global_step: 25043, epoch: 27, loss: 1.167982
global_step: 25044, epoch: 27, loss: 1.177312
global_step: 25045, epoch: 27, loss: 1.173288
global_step: 25046, epoch: 27, loss: 1.144623
global_step: 25047, epoch: 27, loss: 1.226910
global_step: 25048, epoch: 27, loss: 1.163345
global_step: 25049, epoch: 27, loss: 1.145062
global_step: 25050, epoch: 27, loss: 1.100396
global_step: 25051, epoch: 27, loss: 1.092424
global_step: 25052, epoch: 27, loss: 1.101532
global_step: 25053, epoch: 27, loss: 1.172456
global_step: 25054, epoch: 27, loss: 1.089522
global_step: 25055, epoch: 27, loss: 1.098393
global_step: 25056, epoch: 27, loss: 1.237530
global_step: 25057, epoch: 27, loss: 1.084837
global_step: 25058, epoch: 27, loss: 1.143416
global_step: 25059, epoch: 27, loss: 1.135084
global_step: 25060, epoch: 27, loss: 1.315098
global_step: 25061, epoch: 27, loss: 1.143600
global_step: 25062, epoch: 27, loss: 1.113949
global_step: 25063, epoch: 27, loss: 1.036766
global_step: 25064, epoch: 27, loss: 1.119284
global_step: 25065, epoch: 27, loss: 1.136875
global_step: 25066, epoch: 27, loss: 1.109193
global_step: 25067, epoch: 27, loss: 1.192696
global_step: 25068, epoch: 27, loss: 1.116811
global_step: 25069, epoch: 27, loss: 1.033573
global_step: 25070, epoch: 27, loss: 1.267991
global_step: 25071, epoch: 27, loss: 1.077687
global_step: 25072, epoch: 27, loss: 1.063963
global_step: 25073, epoch: 27, loss: 1.082760
global_step: 25074, epoch: 27, loss: 1.078793
global_step: 25075, epoch: 27, loss: 1.184000
global_step: 25076, epoch: 27, loss: 1.150991
global_step: 25077, epoch: 27, loss: 1.273864
global_step: 25078, epoch: 27, loss: 1.270989
global_step: 25079, epoch: 27, loss: 1.155358
global_step: 25080, epoch: 27, loss: 0.588854
epoch: 27
train	acc: 0.6334	macro: p 0.4284, r 0.3383, f1: 0.3380	micro: p 0.6334, r 0.6334, f1 0.6334	weighted_f1:0.5818
dev	acc: 0.5645	macro: p 0.3417, r 0.3116, f1: 0.2923	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.4955
test	acc: 0.6088	macro: p 0.4132, r 0.3200, f1: 0.3133	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5547
New best model!
global_step: 25081, epoch: 28, loss: 1.126891
global_step: 25082, epoch: 28, loss: 1.150932
global_step: 25083, epoch: 28, loss: 1.181951
global_step: 25084, epoch: 28, loss: 1.167097
global_step: 25085, epoch: 28, loss: 1.207953
global_step: 25086, epoch: 28, loss: 1.229158
global_step: 25087, epoch: 28, loss: 1.169240
global_step: 25088, epoch: 28, loss: 1.033950
global_step: 25089, epoch: 28, loss: 1.185466
global_step: 25090, epoch: 28, loss: 1.087460
global_step: 25091, epoch: 28, loss: 1.119715
global_step: 25092, epoch: 28, loss: 1.211522
global_step: 25093, epoch: 28, loss: 1.089806
global_step: 25094, epoch: 28, loss: 0.971962
global_step: 25095, epoch: 28, loss: 1.112494
global_step: 25096, epoch: 28, loss: 1.103795
global_step: 25097, epoch: 28, loss: 1.144759
global_step: 25098, epoch: 28, loss: 0.985589
global_step: 25099, epoch: 28, loss: 1.167953
global_step: 25100, epoch: 28, loss: 1.178707
global_step: 25101, epoch: 28, loss: 1.195445
global_step: 25102, epoch: 28, loss: 1.110691
global_step: 25103, epoch: 28, loss: 1.100403
global_step: 25104, epoch: 28, loss: 1.161023
global_step: 25105, epoch: 28, loss: 1.041690
global_step: 25106, epoch: 28, loss: 1.190509
global_step: 25107, epoch: 28, loss: 1.107382
global_step: 25108, epoch: 28, loss: 1.177002
global_step: 25109, epoch: 28, loss: 1.185317
global_step: 25110, epoch: 28, loss: 1.122526
global_step: 25111, epoch: 28, loss: 1.124742
global_step: 25112, epoch: 28, loss: 1.165423
global_step: 25113, epoch: 28, loss: 1.151357
global_step: 25114, epoch: 28, loss: 1.205105
global_step: 25115, epoch: 28, loss: 1.012970
global_step: 25116, epoch: 28, loss: 1.133642
global_step: 25117, epoch: 28, loss: 1.155262
global_step: 25118, epoch: 28, loss: 1.099676
global_step: 25119, epoch: 28, loss: 1.151652
global_step: 25120, epoch: 28, loss: 2.114393
epoch: 28
train	acc: 0.6388	macro: p 0.4037, r 0.3568, f1: 0.3544	micro: p 0.6388, r 0.6388, f1 0.6388	weighted_f1:0.5963
dev	acc: 0.5672	macro: p 0.3628, r 0.3272, f1: 0.3116	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5113
test	acc: 0.5981	macro: p 0.3704, r 0.3268, f1: 0.3182	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5543
New best model!
global_step: 25121, epoch: 29, loss: 1.222212
global_step: 25122, epoch: 29, loss: 1.052624
global_step: 25123, epoch: 29, loss: 1.065726
global_step: 25124, epoch: 29, loss: 1.102481
global_step: 25125, epoch: 29, loss: 1.180771
global_step: 25126, epoch: 29, loss: 1.179952
global_step: 25127, epoch: 29, loss: 1.096506
global_step: 25128, epoch: 29, loss: 1.152564
global_step: 25129, epoch: 29, loss: 1.298065
global_step: 25130, epoch: 29, loss: 1.057989
global_step: 25131, epoch: 29, loss: 1.090042
global_step: 25132, epoch: 29, loss: 1.129398
global_step: 25133, epoch: 29, loss: 1.159465
global_step: 25134, epoch: 29, loss: 1.077299
global_step: 25135, epoch: 29, loss: 1.110346
global_step: 25136, epoch: 29, loss: 1.160157
global_step: 25137, epoch: 29, loss: 1.051485
global_step: 25138, epoch: 29, loss: 1.120827
global_step: 25139, epoch: 29, loss: 1.091014
global_step: 25140, epoch: 29, loss: 1.172479
global_step: 25141, epoch: 29, loss: 1.018149
global_step: 25142, epoch: 29, loss: 1.061890
global_step: 25143, epoch: 29, loss: 1.230466
global_step: 25144, epoch: 29, loss: 1.133646
global_step: 25145, epoch: 29, loss: 1.124101
global_step: 25146, epoch: 29, loss: 1.108076
global_step: 25147, epoch: 29, loss: 1.131378
global_step: 25148, epoch: 29, loss: 1.113962
global_step: 25149, epoch: 29, loss: 1.058819
global_step: 25150, epoch: 29, loss: 1.177559
global_step: 25151, epoch: 29, loss: 1.088497
global_step: 25152, epoch: 29, loss: 1.167386
global_step: 25153, epoch: 29, loss: 1.173812
global_step: 25154, epoch: 29, loss: 1.263869
global_step: 25155, epoch: 29, loss: 1.098754
global_step: 25156, epoch: 29, loss: 1.052268
global_step: 25157, epoch: 29, loss: 1.131735
global_step: 25158, epoch: 29, loss: 1.152516
global_step: 25159, epoch: 29, loss: 1.152653
global_step: 25160, epoch: 29, loss: 0.995808
epoch: 29
train	acc: 0.6409	macro: p 0.4018, r 0.3497, f1: 0.3501	micro: p 0.6409, r 0.6409, f1 0.6409	weighted_f1:0.5938
dev	acc: 0.5717	macro: p 0.3711, r 0.3242, f1: 0.3124	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5128
test	acc: 0.6077	macro: p 0.3820, r 0.3263, f1: 0.3219	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5601
New best model!
global_step: 25161, epoch: 30, loss: 1.116127
global_step: 25162, epoch: 30, loss: 1.117709
global_step: 25163, epoch: 30, loss: 1.103740
global_step: 25164, epoch: 30, loss: 1.104610
global_step: 25165, epoch: 30, loss: 1.158166
global_step: 25166, epoch: 30, loss: 1.165516
global_step: 25167, epoch: 30, loss: 1.032050
global_step: 25168, epoch: 30, loss: 1.113005
global_step: 25169, epoch: 30, loss: 1.157404
global_step: 25170, epoch: 30, loss: 1.257313
global_step: 25171, epoch: 30, loss: 1.118031
global_step: 25172, epoch: 30, loss: 1.089423
global_step: 25173, epoch: 30, loss: 1.119413
global_step: 25174, epoch: 30, loss: 1.101012
global_step: 25175, epoch: 30, loss: 1.166979
global_step: 25176, epoch: 30, loss: 1.099483
global_step: 25177, epoch: 30, loss: 1.156685
global_step: 25178, epoch: 30, loss: 1.092989
global_step: 25179, epoch: 30, loss: 1.192664
global_step: 25180, epoch: 30, loss: 1.213141
global_step: 25181, epoch: 30, loss: 1.113838
global_step: 25182, epoch: 30, loss: 1.068677
global_step: 25183, epoch: 30, loss: 1.192747
global_step: 25184, epoch: 30, loss: 1.068201
global_step: 25185, epoch: 30, loss: 1.147197
global_step: 25186, epoch: 30, loss: 1.008505
global_step: 25187, epoch: 30, loss: 1.070673
global_step: 25188, epoch: 30, loss: 1.068520
global_step: 25189, epoch: 30, loss: 1.126157
global_step: 25190, epoch: 30, loss: 1.045087
global_step: 25191, epoch: 30, loss: 1.096003
global_step: 25192, epoch: 30, loss: 1.075645
global_step: 25193, epoch: 30, loss: 1.163893
global_step: 25194, epoch: 30, loss: 1.116348
global_step: 25195, epoch: 30, loss: 1.092346
global_step: 25196, epoch: 30, loss: 1.152951
global_step: 25197, epoch: 30, loss: 1.066617
global_step: 25198, epoch: 30, loss: 1.086310
global_step: 25199, epoch: 30, loss: 1.168384
global_step: 25200, epoch: 30, loss: 0.502805
epoch: 30
train	acc: 0.6388	macro: p 0.4172, r 0.3457, f1: 0.3478	micro: p 0.6388, r 0.6388, f1 0.6388	weighted_f1:0.5911
dev	acc: 0.5618	macro: p 0.3650, r 0.3132, f1: 0.2983	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.4991
test	acc: 0.6057	macro: p 0.4026, r 0.3232, f1: 0.3191	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5569
global_step: 25201, epoch: 31, loss: 1.093315
global_step: 25202, epoch: 31, loss: 1.210136
global_step: 25203, epoch: 31, loss: 1.107960
global_step: 25204, epoch: 31, loss: 1.148550
global_step: 25205, epoch: 31, loss: 1.049362
global_step: 25206, epoch: 31, loss: 1.076494
global_step: 25207, epoch: 31, loss: 1.041130
global_step: 25208, epoch: 31, loss: 1.204331
global_step: 25209, epoch: 31, loss: 1.055429
global_step: 25210, epoch: 31, loss: 1.214618
global_step: 25211, epoch: 31, loss: 1.054344
global_step: 25212, epoch: 31, loss: 1.107708
global_step: 25213, epoch: 31, loss: 1.117636
global_step: 25214, epoch: 31, loss: 1.067053
global_step: 25215, epoch: 31, loss: 1.066732
global_step: 25216, epoch: 31, loss: 1.223521
global_step: 25217, epoch: 31, loss: 1.098198
global_step: 25218, epoch: 31, loss: 1.118505
global_step: 25219, epoch: 31, loss: 1.159112
global_step: 25220, epoch: 31, loss: 1.049819
global_step: 25221, epoch: 31, loss: 1.079428
global_step: 25222, epoch: 31, loss: 1.150213
global_step: 25223, epoch: 31, loss: 1.197436
global_step: 25224, epoch: 31, loss: 1.088705
global_step: 25225, epoch: 31, loss: 1.094496
global_step: 25226, epoch: 31, loss: 1.144657
global_step: 25227, epoch: 31, loss: 1.185018
global_step: 25228, epoch: 31, loss: 1.103412
global_step: 25229, epoch: 31, loss: 1.055393
global_step: 25230, epoch: 31, loss: 1.128897
global_step: 25231, epoch: 31, loss: 1.070594
global_step: 25232, epoch: 31, loss: 1.049311
global_step: 25233, epoch: 31, loss: 1.050391
global_step: 25234, epoch: 31, loss: 1.122819
global_step: 25235, epoch: 31, loss: 1.037670
global_step: 25236, epoch: 31, loss: 1.076202
global_step: 25237, epoch: 31, loss: 1.105976
global_step: 25238, epoch: 31, loss: 1.110750
global_step: 25239, epoch: 31, loss: 1.099174
global_step: 25240, epoch: 31, loss: 1.746216
epoch: 31
train	acc: 0.6445	macro: p 0.4286, r 0.3489, f1: 0.3503	micro: p 0.6445, r 0.6445, f1 0.6445	weighted_f1:0.5939
dev	acc: 0.5717	macro: p 0.3623, r 0.3204, f1: 0.3080	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5080
test	acc: 0.6142	macro: p 0.4242, r 0.3248, f1: 0.3210	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5615
global_step: 25241, epoch: 32, loss: 0.989215
global_step: 25242, epoch: 32, loss: 1.174891
global_step: 25243, epoch: 32, loss: 1.063357
global_step: 25244, epoch: 32, loss: 0.980583
global_step: 25245, epoch: 32, loss: 1.050053
global_step: 25246, epoch: 32, loss: 1.032046
global_step: 25247, epoch: 32, loss: 1.088739
global_step: 25248, epoch: 32, loss: 1.155567
global_step: 25249, epoch: 32, loss: 1.190177
global_step: 25250, epoch: 32, loss: 1.078093
global_step: 25251, epoch: 32, loss: 1.082460
global_step: 25252, epoch: 32, loss: 1.115179
global_step: 25253, epoch: 32, loss: 1.034041
global_step: 25254, epoch: 32, loss: 1.124899
global_step: 25255, epoch: 32, loss: 1.129260
global_step: 25256, epoch: 32, loss: 1.212240
global_step: 25257, epoch: 32, loss: 1.112835
global_step: 25258, epoch: 32, loss: 1.059357
global_step: 25259, epoch: 32, loss: 1.114495
global_step: 25260, epoch: 32, loss: 1.124439
global_step: 25261, epoch: 32, loss: 1.175183
global_step: 25262, epoch: 32, loss: 0.990715
global_step: 25263, epoch: 32, loss: 1.166467
global_step: 25264, epoch: 32, loss: 1.085557
global_step: 25265, epoch: 32, loss: 1.267859
global_step: 25266, epoch: 32, loss: 1.152145
global_step: 25267, epoch: 32, loss: 1.013306
global_step: 25268, epoch: 32, loss: 1.119356
global_step: 25269, epoch: 32, loss: 1.147690
global_step: 25270, epoch: 32, loss: 1.098873
global_step: 25271, epoch: 32, loss: 1.130217
global_step: 25272, epoch: 32, loss: 1.045796
global_step: 25273, epoch: 32, loss: 1.083671
global_step: 25274, epoch: 32, loss: 1.100067
global_step: 25275, epoch: 32, loss: 1.146144
global_step: 25276, epoch: 32, loss: 1.101255
global_step: 25277, epoch: 32, loss: 0.968743
global_step: 25278, epoch: 32, loss: 1.185522
global_step: 25279, epoch: 32, loss: 1.109518
global_step: 25280, epoch: 32, loss: 1.006588
epoch: 32
train	acc: 0.6508	macro: p 0.4169, r 0.3681, f1: 0.3705	micro: p 0.6508, r 0.6508, f1 0.6508	weighted_f1:0.6112
dev	acc: 0.5708	macro: p 0.3675, r 0.3288, f1: 0.3195	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5188
test	acc: 0.6069	macro: p 0.3794, r 0.3348, f1: 0.3315	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5661
New best model!
global_step: 25281, epoch: 33, loss: 1.170844
global_step: 25282, epoch: 33, loss: 0.971637
global_step: 25283, epoch: 33, loss: 0.989501
global_step: 25284, epoch: 33, loss: 1.098464
global_step: 25285, epoch: 33, loss: 1.059802
global_step: 25286, epoch: 33, loss: 1.038105
global_step: 25287, epoch: 33, loss: 1.085963
global_step: 25288, epoch: 33, loss: 1.107166
global_step: 25289, epoch: 33, loss: 1.134271
global_step: 25290, epoch: 33, loss: 1.119039
global_step: 25291, epoch: 33, loss: 1.198794
global_step: 25292, epoch: 33, loss: 1.111716
global_step: 25293, epoch: 33, loss: 1.166155
global_step: 25294, epoch: 33, loss: 0.977677
global_step: 25295, epoch: 33, loss: 1.116664
global_step: 25296, epoch: 33, loss: 0.984058
global_step: 25297, epoch: 33, loss: 1.063419
global_step: 25298, epoch: 33, loss: 1.117043
global_step: 25299, epoch: 33, loss: 1.089037
global_step: 25300, epoch: 33, loss: 1.115007
global_step: 25301, epoch: 33, loss: 1.207678
global_step: 25302, epoch: 33, loss: 1.208068
global_step: 25303, epoch: 33, loss: 0.969079
global_step: 25304, epoch: 33, loss: 1.068966
global_step: 25305, epoch: 33, loss: 1.047548
global_step: 25306, epoch: 33, loss: 1.026348
global_step: 25307, epoch: 33, loss: 1.088273
global_step: 25308, epoch: 33, loss: 1.172321
global_step: 25309, epoch: 33, loss: 1.040081
global_step: 25310, epoch: 33, loss: 0.979171
global_step: 25311, epoch: 33, loss: 1.121899
global_step: 25312, epoch: 33, loss: 1.086344
global_step: 25313, epoch: 33, loss: 1.116381
global_step: 25314, epoch: 33, loss: 1.023208
global_step: 25315, epoch: 33, loss: 1.218362
global_step: 25316, epoch: 33, loss: 1.036079
global_step: 25317, epoch: 33, loss: 1.175854
global_step: 25318, epoch: 33, loss: 1.173064
global_step: 25319, epoch: 33, loss: 1.102840
global_step: 25320, epoch: 33, loss: 0.578211
epoch: 33
train	acc: 0.6520	macro: p 0.4362, r 0.3570, f1: 0.3604	micro: p 0.6520, r 0.6520, f1 0.6520	weighted_f1:0.6040
dev	acc: 0.5762	macro: p 0.3813, r 0.3255, f1: 0.3168	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5173
test	acc: 0.6195	macro: p 0.4143, r 0.3328, f1: 0.3325	micro: p 0.6195, r 0.6195, f1 0.6195	weighted_f1:0.5710
global_step: 25321, epoch: 34, loss: 1.087670
global_step: 25322, epoch: 34, loss: 1.047835
global_step: 25323, epoch: 34, loss: 1.072707
global_step: 25324, epoch: 34, loss: 1.047350
global_step: 25325, epoch: 34, loss: 1.045538
global_step: 25326, epoch: 34, loss: 1.100316
global_step: 25327, epoch: 34, loss: 1.056437
global_step: 25328, epoch: 34, loss: 1.013062
global_step: 25329, epoch: 34, loss: 0.995448
global_step: 25330, epoch: 34, loss: 1.121665
global_step: 25331, epoch: 34, loss: 0.989393
global_step: 25332, epoch: 34, loss: 1.057393
global_step: 25333, epoch: 34, loss: 1.234611
global_step: 25334, epoch: 34, loss: 1.069081
global_step: 25335, epoch: 34, loss: 1.126462
global_step: 25336, epoch: 34, loss: 1.196500
global_step: 25337, epoch: 34, loss: 1.109161
global_step: 25338, epoch: 34, loss: 1.161505
global_step: 25339, epoch: 34, loss: 1.178676
global_step: 25340, epoch: 34, loss: 1.028352
global_step: 25341, epoch: 34, loss: 0.993069
global_step: 25342, epoch: 34, loss: 1.128682
global_step: 25343, epoch: 34, loss: 1.045735
global_step: 25344, epoch: 34, loss: 1.011735
global_step: 25345, epoch: 34, loss: 1.108650
global_step: 25346, epoch: 34, loss: 1.155695
global_step: 25347, epoch: 34, loss: 1.100401
global_step: 25348, epoch: 34, loss: 0.951392
global_step: 25349, epoch: 34, loss: 1.105351
global_step: 25350, epoch: 34, loss: 1.058531
global_step: 25351, epoch: 34, loss: 1.138943
global_step: 25352, epoch: 34, loss: 1.225255
global_step: 25353, epoch: 34, loss: 1.147993
global_step: 25354, epoch: 34, loss: 1.016200
global_step: 25355, epoch: 34, loss: 1.030132
global_step: 25356, epoch: 34, loss: 1.015905
global_step: 25357, epoch: 34, loss: 1.085187
global_step: 25358, epoch: 34, loss: 1.118818
global_step: 25359, epoch: 34, loss: 0.989387
global_step: 25360, epoch: 34, loss: 0.827415
epoch: 34
train	acc: 0.6551	macro: p 0.4204, r 0.3664, f1: 0.3744	micro: p 0.6551, r 0.6551, f1 0.6551	weighted_f1:0.6132
dev	acc: 0.5798	macro: p 0.3822, r 0.3329, f1: 0.3307	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5280
test	acc: 0.6180	macro: p 0.3877, r 0.3345, f1: 0.3382	micro: p 0.6180, r 0.6180, f1 0.6180	weighted_f1:0.5738
New best model!
global_step: 25361, epoch: 35, loss: 1.158031
global_step: 25362, epoch: 35, loss: 0.979740
global_step: 25363, epoch: 35, loss: 1.012704
global_step: 25364, epoch: 35, loss: 1.147056
global_step: 25365, epoch: 35, loss: 0.943387
global_step: 25366, epoch: 35, loss: 0.977255
global_step: 25367, epoch: 35, loss: 0.999471
global_step: 25368, epoch: 35, loss: 1.089689
global_step: 25369, epoch: 35, loss: 0.967444
global_step: 25370, epoch: 35, loss: 0.986418
global_step: 25371, epoch: 35, loss: 1.126362
global_step: 25372, epoch: 35, loss: 1.066296
global_step: 25373, epoch: 35, loss: 1.076493
global_step: 25374, epoch: 35, loss: 1.067674
global_step: 25375, epoch: 35, loss: 0.996380
global_step: 25376, epoch: 35, loss: 0.946756
global_step: 25377, epoch: 35, loss: 1.108628
global_step: 25378, epoch: 35, loss: 1.237091
global_step: 25379, epoch: 35, loss: 1.161428
global_step: 25380, epoch: 35, loss: 1.088845
global_step: 25381, epoch: 35, loss: 1.246017
global_step: 25382, epoch: 35, loss: 1.095811
global_step: 25383, epoch: 35, loss: 1.084951
global_step: 25384, epoch: 35, loss: 1.125042
global_step: 25385, epoch: 35, loss: 1.097139
global_step: 25386, epoch: 35, loss: 1.083586
global_step: 25387, epoch: 35, loss: 1.083871
global_step: 25388, epoch: 35, loss: 1.077267
global_step: 25389, epoch: 35, loss: 1.144116
global_step: 25390, epoch: 35, loss: 1.037841
global_step: 25391, epoch: 35, loss: 1.150831
global_step: 25392, epoch: 35, loss: 1.197655
global_step: 25393, epoch: 35, loss: 1.036863
global_step: 25394, epoch: 35, loss: 1.108138
global_step: 25395, epoch: 35, loss: 1.090897
global_step: 25396, epoch: 35, loss: 1.080504
global_step: 25397, epoch: 35, loss: 1.090134
global_step: 25398, epoch: 35, loss: 0.942908
global_step: 25399, epoch: 35, loss: 1.027268
global_step: 25400, epoch: 35, loss: 1.950797
epoch: 35
train	acc: 0.6618	macro: p 0.4212, r 0.3750, f1: 0.3788	micro: p 0.6618, r 0.6618, f1 0.6618	weighted_f1:0.6207
dev	acc: 0.5771	macro: p 0.3673, r 0.3339, f1: 0.3251	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5248
test	acc: 0.6100	macro: p 0.3773, r 0.3340, f1: 0.3310	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5668
global_step: 25401, epoch: 36, loss: 1.144703
global_step: 25402, epoch: 36, loss: 1.092707
global_step: 25403, epoch: 36, loss: 1.089449
global_step: 25404, epoch: 36, loss: 0.974934
global_step: 25405, epoch: 36, loss: 1.055158
global_step: 25406, epoch: 36, loss: 1.059799
global_step: 25407, epoch: 36, loss: 1.017195
global_step: 25408, epoch: 36, loss: 1.000718
global_step: 25409, epoch: 36, loss: 1.047436
global_step: 25410, epoch: 36, loss: 1.331050
global_step: 25411, epoch: 36, loss: 1.016052
global_step: 25412, epoch: 36, loss: 1.094275
global_step: 25413, epoch: 36, loss: 1.013318
global_step: 25414, epoch: 36, loss: 1.124426
global_step: 25415, epoch: 36, loss: 1.047847
global_step: 25416, epoch: 36, loss: 1.164361
global_step: 25417, epoch: 36, loss: 1.084077
global_step: 25418, epoch: 36, loss: 1.063184
global_step: 25419, epoch: 36, loss: 0.961762
global_step: 25420, epoch: 36, loss: 1.041088
global_step: 25421, epoch: 36, loss: 1.050587
global_step: 25422, epoch: 36, loss: 1.096114
global_step: 25423, epoch: 36, loss: 0.961908
global_step: 25424, epoch: 36, loss: 1.103778
global_step: 25425, epoch: 36, loss: 1.108115
global_step: 25426, epoch: 36, loss: 1.170087
global_step: 25427, epoch: 36, loss: 1.045688
global_step: 25428, epoch: 36, loss: 1.049581
global_step: 25429, epoch: 36, loss: 1.083258
global_step: 25430, epoch: 36, loss: 1.057763
global_step: 25431, epoch: 36, loss: 1.008706
global_step: 25432, epoch: 36, loss: 1.033213
global_step: 25433, epoch: 36, loss: 1.011456
global_step: 25434, epoch: 36, loss: 1.076920
global_step: 25435, epoch: 36, loss: 1.007580
global_step: 25436, epoch: 36, loss: 1.174874
global_step: 25437, epoch: 36, loss: 1.047690
global_step: 25438, epoch: 36, loss: 1.158022
global_step: 25439, epoch: 36, loss: 1.031828
global_step: 25440, epoch: 36, loss: 1.238459
epoch: 36
train	acc: 0.6649	macro: p 0.4261, r 0.3810, f1: 0.3876	micro: p 0.6649, r 0.6649, f1 0.6649	weighted_f1:0.6269
dev	acc: 0.5825	macro: p 0.3783, r 0.3393, f1: 0.3374	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5341
test	acc: 0.6184	macro: p 0.3836, r 0.3396, f1: 0.3429	micro: p 0.6184, r 0.6184, f1 0.6184	weighted_f1:0.5781
New best model!
global_step: 25441, epoch: 37, loss: 1.050692
global_step: 25442, epoch: 37, loss: 1.100141
global_step: 25443, epoch: 37, loss: 1.089700
global_step: 25444, epoch: 37, loss: 1.053211
global_step: 25445, epoch: 37, loss: 1.114289
global_step: 25446, epoch: 37, loss: 0.972698
global_step: 25447, epoch: 37, loss: 0.968732
global_step: 25448, epoch: 37, loss: 1.074002
global_step: 25449, epoch: 37, loss: 1.028703
global_step: 25450, epoch: 37, loss: 1.002467
global_step: 25451, epoch: 37, loss: 0.944664
global_step: 25452, epoch: 37, loss: 0.890923
global_step: 25453, epoch: 37, loss: 1.027753
global_step: 25454, epoch: 37, loss: 0.948580
global_step: 25455, epoch: 37, loss: 1.092876
global_step: 25456, epoch: 37, loss: 1.040568
global_step: 25457, epoch: 37, loss: 1.215886
global_step: 25458, epoch: 37, loss: 1.033324
global_step: 25459, epoch: 37, loss: 1.189307
global_step: 25460, epoch: 37, loss: 1.097760
global_step: 25461, epoch: 37, loss: 1.111387
global_step: 25462, epoch: 37, loss: 1.112261
global_step: 25463, epoch: 37, loss: 1.098792
global_step: 25464, epoch: 37, loss: 1.092556
global_step: 25465, epoch: 37, loss: 1.109599
global_step: 25466, epoch: 37, loss: 1.062197
global_step: 25467, epoch: 37, loss: 1.064059
global_step: 25468, epoch: 37, loss: 1.079521
global_step: 25469, epoch: 37, loss: 1.073871
global_step: 25470, epoch: 37, loss: 1.152731
global_step: 25471, epoch: 37, loss: 1.026708
global_step: 25472, epoch: 37, loss: 0.979051
global_step: 25473, epoch: 37, loss: 0.974401
global_step: 25474, epoch: 37, loss: 1.088996
global_step: 25475, epoch: 37, loss: 0.989560
global_step: 25476, epoch: 37, loss: 1.096620
global_step: 25477, epoch: 37, loss: 1.148587
global_step: 25478, epoch: 37, loss: 1.039154
global_step: 25479, epoch: 37, loss: 1.069838
global_step: 25480, epoch: 37, loss: 1.090327
epoch: 37
train	acc: 0.6579	macro: p 0.4290, r 0.3630, f1: 0.3710	micro: p 0.6579, r 0.6579, f1 0.6579	weighted_f1:0.6123
dev	acc: 0.5717	macro: p 0.3802, r 0.3231, f1: 0.3189	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5159
test	acc: 0.6169	macro: p 0.3953, r 0.3294, f1: 0.3302	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5677
global_step: 25481, epoch: 38, loss: 0.991793
global_step: 25482, epoch: 38, loss: 1.015000
global_step: 25483, epoch: 38, loss: 1.109357
global_step: 25484, epoch: 38, loss: 1.016954
global_step: 25485, epoch: 38, loss: 1.103453
global_step: 25486, epoch: 38, loss: 1.030596
global_step: 25487, epoch: 38, loss: 1.031892
global_step: 25488, epoch: 38, loss: 1.182387
global_step: 25489, epoch: 38, loss: 1.284628
global_step: 25490, epoch: 38, loss: 1.032903
global_step: 25491, epoch: 38, loss: 1.018178
global_step: 25492, epoch: 38, loss: 0.976576
global_step: 25493, epoch: 38, loss: 1.119776
global_step: 25494, epoch: 38, loss: 1.032116
global_step: 25495, epoch: 38, loss: 1.118008
global_step: 25496, epoch: 38, loss: 1.052397
global_step: 25497, epoch: 38, loss: 0.949811
global_step: 25498, epoch: 38, loss: 0.895109
global_step: 25499, epoch: 38, loss: 1.014527
global_step: 25500, epoch: 38, loss: 1.062124
global_step: 25501, epoch: 38, loss: 1.036268
global_step: 25502, epoch: 38, loss: 1.050848
global_step: 25503, epoch: 38, loss: 0.994431
global_step: 25504, epoch: 38, loss: 1.049883
global_step: 25505, epoch: 38, loss: 1.077916
global_step: 25506, epoch: 38, loss: 1.135411
global_step: 25507, epoch: 38, loss: 1.040158
global_step: 25508, epoch: 38, loss: 0.951267
global_step: 25509, epoch: 38, loss: 0.996017
global_step: 25510, epoch: 38, loss: 1.039960
global_step: 25511, epoch: 38, loss: 0.957659
global_step: 25512, epoch: 38, loss: 1.060929
global_step: 25513, epoch: 38, loss: 1.055658
global_step: 25514, epoch: 38, loss: 1.016060
global_step: 25515, epoch: 38, loss: 0.979675
global_step: 25516, epoch: 38, loss: 1.184206
global_step: 25517, epoch: 38, loss: 1.015864
global_step: 25518, epoch: 38, loss: 1.109511
global_step: 25519, epoch: 38, loss: 0.942300
global_step: 25520, epoch: 38, loss: 1.320914
epoch: 38
train	acc: 0.6608	macro: p 0.4333, r 0.3636, f1: 0.3662	micro: p 0.6608, r 0.6608, f1 0.6608	weighted_f1:0.6125
dev	acc: 0.5753	macro: p 0.3898, r 0.3266, f1: 0.3147	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5145
test	acc: 0.6111	macro: p 0.3935, r 0.3263, f1: 0.3209	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5598
global_step: 25521, epoch: 39, loss: 0.950621
global_step: 25522, epoch: 39, loss: 1.165204
global_step: 25523, epoch: 39, loss: 1.034873
global_step: 25524, epoch: 39, loss: 1.024756
global_step: 25525, epoch: 39, loss: 0.940071
global_step: 25526, epoch: 39, loss: 0.984527
global_step: 25527, epoch: 39, loss: 1.157529
global_step: 25528, epoch: 39, loss: 1.055425
global_step: 25529, epoch: 39, loss: 1.125459
global_step: 25530, epoch: 39, loss: 1.008605
global_step: 25531, epoch: 39, loss: 0.891090
global_step: 25532, epoch: 39, loss: 1.024712
global_step: 25533, epoch: 39, loss: 1.050994
global_step: 25534, epoch: 39, loss: 1.042744
global_step: 25535, epoch: 39, loss: 1.062899
global_step: 25536, epoch: 39, loss: 1.094469
global_step: 25537, epoch: 39, loss: 0.993128
global_step: 25538, epoch: 39, loss: 1.006298
global_step: 25539, epoch: 39, loss: 1.269675
global_step: 25540, epoch: 39, loss: 0.918021
global_step: 25541, epoch: 39, loss: 0.997709
global_step: 25542, epoch: 39, loss: 1.001661
global_step: 25543, epoch: 39, loss: 1.019371
global_step: 25544, epoch: 39, loss: 1.119573
global_step: 25545, epoch: 39, loss: 1.053622
global_step: 25546, epoch: 39, loss: 0.960994
global_step: 25547, epoch: 39, loss: 1.159567
global_step: 25548, epoch: 39, loss: 0.971179
global_step: 25549, epoch: 39, loss: 0.941213
global_step: 25550, epoch: 39, loss: 0.969120
global_step: 25551, epoch: 39, loss: 1.098569
global_step: 25552, epoch: 39, loss: 1.029660
global_step: 25553, epoch: 39, loss: 1.169713
global_step: 25554, epoch: 39, loss: 1.012480
global_step: 25555, epoch: 39, loss: 1.038261
global_step: 25556, epoch: 39, loss: 0.954030
global_step: 25557, epoch: 39, loss: 1.110887
global_step: 25558, epoch: 39, loss: 1.038388
global_step: 25559, epoch: 39, loss: 1.033271
global_step: 25560, epoch: 39, loss: 1.006677
epoch: 39
train	acc: 0.6707	macro: p 0.4289, r 0.3789, f1: 0.3829	micro: p 0.6707, r 0.6707, f1 0.6707	weighted_f1:0.6260
dev	acc: 0.5843	macro: p 0.3827, r 0.3380, f1: 0.3311	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5287
test	acc: 0.6088	macro: p 0.3795, r 0.3263, f1: 0.3224	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5601
global_step: 25561, epoch: 40, loss: 1.018357
global_step: 25562, epoch: 40, loss: 0.953769
global_step: 25563, epoch: 40, loss: 0.998371
global_step: 25564, epoch: 40, loss: 1.108229
global_step: 25565, epoch: 40, loss: 1.034414
global_step: 25566, epoch: 40, loss: 1.107808
global_step: 25567, epoch: 40, loss: 1.052277
global_step: 25568, epoch: 40, loss: 1.040948
global_step: 25569, epoch: 40, loss: 0.901956
global_step: 25570, epoch: 40, loss: 0.939058
global_step: 25571, epoch: 40, loss: 1.116451
global_step: 25572, epoch: 40, loss: 0.967819
global_step: 25573, epoch: 40, loss: 0.930773
global_step: 25574, epoch: 40, loss: 0.965148
global_step: 25575, epoch: 40, loss: 1.023044
global_step: 25576, epoch: 40, loss: 0.924997
global_step: 25577, epoch: 40, loss: 0.980446
global_step: 25578, epoch: 40, loss: 1.086493
global_step: 25579, epoch: 40, loss: 1.048658
global_step: 25580, epoch: 40, loss: 1.035793
global_step: 25581, epoch: 40, loss: 1.006781
global_step: 25582, epoch: 40, loss: 1.024551
global_step: 25583, epoch: 40, loss: 0.956774
global_step: 25584, epoch: 40, loss: 1.045041
global_step: 25585, epoch: 40, loss: 1.052546
global_step: 25586, epoch: 40, loss: 1.141050
global_step: 25587, epoch: 40, loss: 0.966660
global_step: 25588, epoch: 40, loss: 0.975440
global_step: 25589, epoch: 40, loss: 1.023158
global_step: 25590, epoch: 40, loss: 1.069600
global_step: 25591, epoch: 40, loss: 1.017502
global_step: 25592, epoch: 40, loss: 1.012440
global_step: 25593, epoch: 40, loss: 1.053782
global_step: 25594, epoch: 40, loss: 1.030362
global_step: 25595, epoch: 40, loss: 1.047348
global_step: 25596, epoch: 40, loss: 1.081780
global_step: 25597, epoch: 40, loss: 1.076772
global_step: 25598, epoch: 40, loss: 1.013496
global_step: 25599, epoch: 40, loss: 1.000379
global_step: 25600, epoch: 40, loss: 0.559343
epoch: 40
train	acc: 0.6720	macro: p 0.4373, r 0.3825, f1: 0.3890	micro: p 0.6720, r 0.6720, f1 0.6720	weighted_f1:0.6307
dev	acc: 0.5771	macro: p 0.3760, r 0.3304, f1: 0.3293	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5259
test	acc: 0.6157	macro: p 0.3859, r 0.3303, f1: 0.3335	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5706
global_step: 25601, epoch: 41, loss: 1.037759
global_step: 25602, epoch: 41, loss: 1.073697
global_step: 25603, epoch: 41, loss: 0.946574
global_step: 25604, epoch: 41, loss: 1.098310
global_step: 25605, epoch: 41, loss: 0.983949
global_step: 25606, epoch: 41, loss: 1.040804
global_step: 25607, epoch: 41, loss: 0.927283
global_step: 25608, epoch: 41, loss: 1.081681
global_step: 25609, epoch: 41, loss: 1.019536
global_step: 25610, epoch: 41, loss: 1.069073
global_step: 25611, epoch: 41, loss: 1.102839
global_step: 25612, epoch: 41, loss: 0.990516
global_step: 25613, epoch: 41, loss: 1.097055
global_step: 25614, epoch: 41, loss: 0.997889
global_step: 25615, epoch: 41, loss: 1.007701
global_step: 25616, epoch: 41, loss: 1.107610
global_step: 25617, epoch: 41, loss: 0.931120
global_step: 25618, epoch: 41, loss: 0.940119
global_step: 25619, epoch: 41, loss: 0.964242
global_step: 25620, epoch: 41, loss: 1.097837
global_step: 25621, epoch: 41, loss: 1.101216
global_step: 25622, epoch: 41, loss: 0.908752
global_step: 25623, epoch: 41, loss: 1.020519
global_step: 25624, epoch: 41, loss: 0.944000
global_step: 25625, epoch: 41, loss: 1.125831
global_step: 25626, epoch: 41, loss: 1.012641
global_step: 25627, epoch: 41, loss: 1.024400
global_step: 25628, epoch: 41, loss: 1.097728
global_step: 25629, epoch: 41, loss: 0.937676
global_step: 25630, epoch: 41, loss: 1.052966
global_step: 25631, epoch: 41, loss: 0.992647
global_step: 25632, epoch: 41, loss: 0.939141
global_step: 25633, epoch: 41, loss: 0.994645
global_step: 25634, epoch: 41, loss: 1.008946
global_step: 25635, epoch: 41, loss: 1.028858
global_step: 25636, epoch: 41, loss: 1.151164
global_step: 25637, epoch: 41, loss: 0.958864
global_step: 25638, epoch: 41, loss: 0.973845
global_step: 25639, epoch: 41, loss: 0.973510
global_step: 25640, epoch: 41, loss: 0.540771
epoch: 41
train	acc: 0.6509	macro: p 0.4466, r 0.3485, f1: 0.3603	micro: p 0.6509, r 0.6509, f1 0.6509	weighted_f1:0.5986
dev	acc: 0.5690	macro: p 0.4070, r 0.3095, f1: 0.3075	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5034
test	acc: 0.6126	macro: p 0.4136, r 0.3090, f1: 0.3125	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5527
global_step: 25641, epoch: 42, loss: 1.026923
global_step: 25642, epoch: 42, loss: 1.006558
global_step: 25643, epoch: 42, loss: 1.015381
global_step: 25644, epoch: 42, loss: 0.829350
global_step: 25645, epoch: 42, loss: 0.968222
global_step: 25646, epoch: 42, loss: 1.053857
global_step: 25647, epoch: 42, loss: 1.018040
global_step: 25648, epoch: 42, loss: 0.915504
global_step: 25649, epoch: 42, loss: 0.976216
global_step: 25650, epoch: 42, loss: 0.951190
global_step: 25651, epoch: 42, loss: 1.031610
global_step: 25652, epoch: 42, loss: 0.975188
global_step: 25653, epoch: 42, loss: 0.982953
global_step: 25654, epoch: 42, loss: 1.002927
global_step: 25655, epoch: 42, loss: 1.022051
global_step: 25656, epoch: 42, loss: 0.869013
global_step: 25657, epoch: 42, loss: 0.996437
global_step: 25658, epoch: 42, loss: 1.009883
global_step: 25659, epoch: 42, loss: 0.964058
global_step: 25660, epoch: 42, loss: 0.969952
global_step: 25661, epoch: 42, loss: 1.021954
global_step: 25662, epoch: 42, loss: 0.992070
global_step: 25663, epoch: 42, loss: 1.019972
global_step: 25664, epoch: 42, loss: 1.061856
global_step: 25665, epoch: 42, loss: 1.048331
global_step: 25666, epoch: 42, loss: 0.967590
global_step: 25667, epoch: 42, loss: 1.094861
global_step: 25668, epoch: 42, loss: 1.029863
global_step: 25669, epoch: 42, loss: 1.025126
global_step: 25670, epoch: 42, loss: 0.989327
global_step: 25671, epoch: 42, loss: 1.104013
global_step: 25672, epoch: 42, loss: 0.952629
global_step: 25673, epoch: 42, loss: 1.086586
global_step: 25674, epoch: 42, loss: 1.062531
global_step: 25675, epoch: 42, loss: 1.119672
global_step: 25676, epoch: 42, loss: 1.093811
global_step: 25677, epoch: 42, loss: 0.978264
global_step: 25678, epoch: 42, loss: 1.025869
global_step: 25679, epoch: 42, loss: 0.978279
global_step: 25680, epoch: 42, loss: 1.302656
epoch: 42
train	acc: 0.6882	macro: p 0.4431, r 0.4034, f1: 0.4098	micro: p 0.6882, r 0.6882, f1 0.6882	weighted_f1:0.6505
dev	acc: 0.5915	macro: p 0.3879, r 0.3487, f1: 0.3449	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5419
test	acc: 0.6126	macro: p 0.3771, r 0.3341, f1: 0.3356	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5703
New best model!
global_step: 25681, epoch: 43, loss: 1.014850
global_step: 25682, epoch: 43, loss: 0.984755
global_step: 25683, epoch: 43, loss: 1.011009
global_step: 25684, epoch: 43, loss: 0.923692
global_step: 25685, epoch: 43, loss: 0.915402
global_step: 25686, epoch: 43, loss: 1.074696
global_step: 25687, epoch: 43, loss: 0.860370
global_step: 25688, epoch: 43, loss: 1.042841
global_step: 25689, epoch: 43, loss: 0.983253
global_step: 25690, epoch: 43, loss: 0.950478
global_step: 25691, epoch: 43, loss: 0.922052
global_step: 25692, epoch: 43, loss: 1.005856
global_step: 25693, epoch: 43, loss: 1.047707
global_step: 25694, epoch: 43, loss: 1.010839
global_step: 25695, epoch: 43, loss: 0.973318
global_step: 25696, epoch: 43, loss: 1.076473
global_step: 25697, epoch: 43, loss: 1.222190
global_step: 25698, epoch: 43, loss: 1.064671
global_step: 25699, epoch: 43, loss: 1.007945
global_step: 25700, epoch: 43, loss: 0.969302
global_step: 25701, epoch: 43, loss: 1.042521
global_step: 25702, epoch: 43, loss: 0.908386
global_step: 25703, epoch: 43, loss: 1.010904
global_step: 25704, epoch: 43, loss: 0.969873
global_step: 25705, epoch: 43, loss: 0.950271
global_step: 25706, epoch: 43, loss: 0.918442
global_step: 25707, epoch: 43, loss: 0.993285
global_step: 25708, epoch: 43, loss: 1.039693
global_step: 25709, epoch: 43, loss: 0.923561
global_step: 25710, epoch: 43, loss: 1.027768
global_step: 25711, epoch: 43, loss: 0.971183
global_step: 25712, epoch: 43, loss: 1.007628
global_step: 25713, epoch: 43, loss: 1.083125
global_step: 25714, epoch: 43, loss: 1.017483
global_step: 25715, epoch: 43, loss: 1.113978
global_step: 25716, epoch: 43, loss: 0.995350
global_step: 25717, epoch: 43, loss: 1.089906
global_step: 25718, epoch: 43, loss: 1.021249
global_step: 25719, epoch: 43, loss: 0.856939
global_step: 25720, epoch: 43, loss: 0.754005
epoch: 43
train	acc: 0.6836	macro: p 0.4463, r 0.3967, f1: 0.4027	micro: p 0.6836, r 0.6836, f1 0.6836	weighted_f1:0.6444
dev	acc: 0.5834	macro: p 0.3853, r 0.3362, f1: 0.3365	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5339
test	acc: 0.6169	macro: p 0.3862, r 0.3332, f1: 0.3372	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5733
global_step: 25721, epoch: 44, loss: 1.148335
global_step: 25722, epoch: 44, loss: 1.152551
global_step: 25723, epoch: 44, loss: 0.942517
global_step: 25724, epoch: 44, loss: 1.012715
global_step: 25725, epoch: 44, loss: 0.821297
global_step: 25726, epoch: 44, loss: 1.066911
global_step: 25727, epoch: 44, loss: 1.144627
global_step: 25728, epoch: 44, loss: 0.964527
global_step: 25729, epoch: 44, loss: 0.915983
global_step: 25730, epoch: 44, loss: 0.950405
global_step: 25731, epoch: 44, loss: 1.005725
global_step: 25732, epoch: 44, loss: 0.844214
global_step: 25733, epoch: 44, loss: 0.902066
global_step: 25734, epoch: 44, loss: 0.936422
global_step: 25735, epoch: 44, loss: 0.931735
global_step: 25736, epoch: 44, loss: 1.003785
global_step: 25737, epoch: 44, loss: 0.986663
global_step: 25738, epoch: 44, loss: 1.032522
global_step: 25739, epoch: 44, loss: 0.933139
global_step: 25740, epoch: 44, loss: 0.931417
global_step: 25741, epoch: 44, loss: 0.985820
global_step: 25742, epoch: 44, loss: 1.040450
global_step: 25743, epoch: 44, loss: 0.999936
global_step: 25744, epoch: 44, loss: 0.998345
global_step: 25745, epoch: 44, loss: 1.033172
global_step: 25746, epoch: 44, loss: 0.984837
global_step: 25747, epoch: 44, loss: 0.999996
global_step: 25748, epoch: 44, loss: 1.004668
global_step: 25749, epoch: 44, loss: 0.944684
global_step: 25750, epoch: 44, loss: 0.986117
global_step: 25751, epoch: 44, loss: 0.929127
global_step: 25752, epoch: 44, loss: 1.020505
global_step: 25753, epoch: 44, loss: 1.079447
global_step: 25754, epoch: 44, loss: 0.921749
global_step: 25755, epoch: 44, loss: 1.037438
global_step: 25756, epoch: 44, loss: 1.050300
global_step: 25757, epoch: 44, loss: 0.968397
global_step: 25758, epoch: 44, loss: 1.026658
global_step: 25759, epoch: 44, loss: 1.055503
global_step: 25760, epoch: 44, loss: 1.831601
epoch: 44
train	acc: 0.7020	macro: p 0.4434, r 0.4315, f1: 0.4332	micro: p 0.7020, r 0.7020, f1 0.7020	weighted_f1:0.6733
dev	acc: 0.5879	macro: p 0.3680, r 0.3521, f1: 0.3484	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5465
test	acc: 0.6096	macro: p 0.3664, r 0.3489, f1: 0.3495	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5785
New best model!
global_step: 25761, epoch: 45, loss: 1.044365
global_step: 25762, epoch: 45, loss: 0.926697
global_step: 25763, epoch: 45, loss: 0.886701
global_step: 25764, epoch: 45, loss: 1.020520
global_step: 25765, epoch: 45, loss: 1.056961
global_step: 25766, epoch: 45, loss: 0.943885
global_step: 25767, epoch: 45, loss: 0.982574
global_step: 25768, epoch: 45, loss: 1.105959
global_step: 25769, epoch: 45, loss: 1.003644
global_step: 25770, epoch: 45, loss: 0.999928
global_step: 25771, epoch: 45, loss: 1.041647
global_step: 25772, epoch: 45, loss: 1.067665
global_step: 25773, epoch: 45, loss: 0.867962
global_step: 25774, epoch: 45, loss: 1.057960
global_step: 25775, epoch: 45, loss: 0.928698
global_step: 25776, epoch: 45, loss: 0.951877
global_step: 25777, epoch: 45, loss: 0.955702
global_step: 25778, epoch: 45, loss: 1.009359
global_step: 25779, epoch: 45, loss: 1.027220
global_step: 25780, epoch: 45, loss: 0.885991
global_step: 25781, epoch: 45, loss: 0.925064
global_step: 25782, epoch: 45, loss: 0.954013
global_step: 25783, epoch: 45, loss: 0.941485
global_step: 25784, epoch: 45, loss: 0.925997
global_step: 25785, epoch: 45, loss: 0.961931
global_step: 25786, epoch: 45, loss: 1.009888
global_step: 25787, epoch: 45, loss: 1.037069
global_step: 25788, epoch: 45, loss: 1.019964
global_step: 25789, epoch: 45, loss: 0.877808
global_step: 25790, epoch: 45, loss: 0.961648
global_step: 25791, epoch: 45, loss: 1.063264
global_step: 25792, epoch: 45, loss: 1.031497
global_step: 25793, epoch: 45, loss: 0.907137
global_step: 25794, epoch: 45, loss: 0.919480
global_step: 25795, epoch: 45, loss: 1.018239
global_step: 25796, epoch: 45, loss: 1.014918
global_step: 25797, epoch: 45, loss: 0.996840
global_step: 25798, epoch: 45, loss: 0.988521
global_step: 25799, epoch: 45, loss: 1.028291
global_step: 25800, epoch: 45, loss: 0.595415
epoch: 45
train	acc: 0.6966	macro: p 0.4547, r 0.4102, f1: 0.4153	micro: p 0.6966, r 0.6966, f1 0.6966	weighted_f1:0.6586
dev	acc: 0.5897	macro: p 0.3927, r 0.3458, f1: 0.3434	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5406
test	acc: 0.6176	macro: p 0.3834, r 0.3391, f1: 0.3405	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5758
global_step: 25801, epoch: 46, loss: 0.994627
global_step: 25802, epoch: 46, loss: 0.943619
global_step: 25803, epoch: 46, loss: 0.987320
global_step: 25804, epoch: 46, loss: 0.923394
global_step: 25805, epoch: 46, loss: 1.000253
global_step: 25806, epoch: 46, loss: 1.028257
global_step: 25807, epoch: 46, loss: 0.916116
global_step: 25808, epoch: 46, loss: 0.954792
global_step: 25809, epoch: 46, loss: 1.047338
global_step: 25810, epoch: 46, loss: 1.108597
global_step: 25811, epoch: 46, loss: 0.973969
global_step: 25812, epoch: 46, loss: 1.058335
global_step: 25813, epoch: 46, loss: 0.892484
global_step: 25814, epoch: 46, loss: 0.960438
global_step: 25815, epoch: 46, loss: 0.929510
global_step: 25816, epoch: 46, loss: 0.974766
global_step: 25817, epoch: 46, loss: 0.936307
global_step: 25818, epoch: 46, loss: 1.057508
global_step: 25819, epoch: 46, loss: 0.976695
global_step: 25820, epoch: 46, loss: 0.989345
global_step: 25821, epoch: 46, loss: 0.926899
global_step: 25822, epoch: 46, loss: 0.936646
global_step: 25823, epoch: 46, loss: 0.979931
global_step: 25824, epoch: 46, loss: 1.104969
global_step: 25825, epoch: 46, loss: 0.968771
global_step: 25826, epoch: 46, loss: 0.853222
global_step: 25827, epoch: 46, loss: 1.032633
global_step: 25828, epoch: 46, loss: 1.031466
global_step: 25829, epoch: 46, loss: 1.082858
global_step: 25830, epoch: 46, loss: 0.975395
global_step: 25831, epoch: 46, loss: 0.967355
global_step: 25832, epoch: 46, loss: 0.905519
global_step: 25833, epoch: 46, loss: 0.959489
global_step: 25834, epoch: 46, loss: 1.041300
global_step: 25835, epoch: 46, loss: 0.970706
global_step: 25836, epoch: 46, loss: 0.875181
global_step: 25837, epoch: 46, loss: 0.940803
global_step: 25838, epoch: 46, loss: 1.038377
global_step: 25839, epoch: 46, loss: 0.935779
global_step: 25840, epoch: 46, loss: 0.446919
epoch: 46
train	acc: 0.7014	macro: p 0.4609, r 0.4187, f1: 0.4245	micro: p 0.7014, r 0.7014, f1 0.7014	weighted_f1:0.6663
dev	acc: 0.5843	macro: p 0.3886, r 0.3416, f1: 0.3397	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5365
test	acc: 0.6199	macro: p 0.3889, r 0.3425, f1: 0.3452	micro: p 0.6199, r 0.6199, f1 0.6199	weighted_f1:0.5802
global_step: 25841, epoch: 47, loss: 0.992953
global_step: 25842, epoch: 47, loss: 0.963135
global_step: 25843, epoch: 47, loss: 0.985686
global_step: 25844, epoch: 47, loss: 0.985779
global_step: 25845, epoch: 47, loss: 0.996159
global_step: 25846, epoch: 47, loss: 1.125832
global_step: 25847, epoch: 47, loss: 0.925135
global_step: 25848, epoch: 47, loss: 0.979265
global_step: 25849, epoch: 47, loss: 1.019027
global_step: 25850, epoch: 47, loss: 0.980689
global_step: 25851, epoch: 47, loss: 1.021840
global_step: 25852, epoch: 47, loss: 0.953881
global_step: 25853, epoch: 47, loss: 0.983883
global_step: 25854, epoch: 47, loss: 0.932931
global_step: 25855, epoch: 47, loss: 0.961805
global_step: 25856, epoch: 47, loss: 0.918048
global_step: 25857, epoch: 47, loss: 0.935874
global_step: 25858, epoch: 47, loss: 0.851767
global_step: 25859, epoch: 47, loss: 0.926966
global_step: 25860, epoch: 47, loss: 0.949780
global_step: 25861, epoch: 47, loss: 0.939848
global_step: 25862, epoch: 47, loss: 0.994421
global_step: 25863, epoch: 47, loss: 0.840253
global_step: 25864, epoch: 47, loss: 0.879286
global_step: 25865, epoch: 47, loss: 0.967568
global_step: 25866, epoch: 47, loss: 0.904946
global_step: 25867, epoch: 47, loss: 0.968805
global_step: 25868, epoch: 47, loss: 0.888884
global_step: 25869, epoch: 47, loss: 1.032400
global_step: 25870, epoch: 47, loss: 1.036867
global_step: 25871, epoch: 47, loss: 1.124333
global_step: 25872, epoch: 47, loss: 0.985045
global_step: 25873, epoch: 47, loss: 0.979249
global_step: 25874, epoch: 47, loss: 0.954320
global_step: 25875, epoch: 47, loss: 0.936935
global_step: 25876, epoch: 47, loss: 0.976214
global_step: 25877, epoch: 47, loss: 0.959812
global_step: 25878, epoch: 47, loss: 0.968384
global_step: 25879, epoch: 47, loss: 0.972471
global_step: 25880, epoch: 47, loss: 1.369246
epoch: 47
train	acc: 0.7178	macro: p 0.4526, r 0.4603, f1: 0.4477	micro: p 0.7178, r 0.7178, f1 0.7178	weighted_f1:0.6928
dev	acc: 0.5771	macro: p 0.3599, r 0.3572, f1: 0.3460	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5422
test	acc: 0.6038	macro: p 0.3602, r 0.3645, f1: 0.3527	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5804
global_step: 25881, epoch: 48, loss: 0.980730
global_step: 25882, epoch: 48, loss: 0.941220
global_step: 25883, epoch: 48, loss: 1.054814
global_step: 25884, epoch: 48, loss: 0.946006
global_step: 25885, epoch: 48, loss: 0.920539
global_step: 25886, epoch: 48, loss: 0.900823
global_step: 25887, epoch: 48, loss: 1.017812
global_step: 25888, epoch: 48, loss: 0.938200
global_step: 25889, epoch: 48, loss: 0.915697
global_step: 25890, epoch: 48, loss: 1.011734
global_step: 25891, epoch: 48, loss: 0.899536
global_step: 25892, epoch: 48, loss: 1.059231
global_step: 25893, epoch: 48, loss: 0.942053
global_step: 25894, epoch: 48, loss: 0.921602
global_step: 25895, epoch: 48, loss: 0.952246
global_step: 25896, epoch: 48, loss: 0.904291
global_step: 25897, epoch: 48, loss: 0.840364
global_step: 25898, epoch: 48, loss: 1.022551
global_step: 25899, epoch: 48, loss: 0.959247
global_step: 25900, epoch: 48, loss: 1.058935
global_step: 25901, epoch: 48, loss: 0.940443
global_step: 25902, epoch: 48, loss: 1.038903
global_step: 25903, epoch: 48, loss: 0.828029
global_step: 25904, epoch: 48, loss: 0.955335
global_step: 25905, epoch: 48, loss: 0.931801
global_step: 25906, epoch: 48, loss: 1.032775
global_step: 25907, epoch: 48, loss: 1.053430
global_step: 25908, epoch: 48, loss: 1.065137
global_step: 25909, epoch: 48, loss: 1.125505
global_step: 25910, epoch: 48, loss: 0.994396
global_step: 25911, epoch: 48, loss: 0.956284
global_step: 25912, epoch: 48, loss: 1.021465
global_step: 25913, epoch: 48, loss: 0.944739
global_step: 25914, epoch: 48, loss: 0.965346
global_step: 25915, epoch: 48, loss: 0.926530
global_step: 25916, epoch: 48, loss: 0.997324
global_step: 25917, epoch: 48, loss: 0.840247
global_step: 25918, epoch: 48, loss: 0.958502
global_step: 25919, epoch: 48, loss: 0.975115
global_step: 25920, epoch: 48, loss: 1.531153
epoch: 48
train	acc: 0.7079	macro: p 0.4649, r 0.4255, f1: 0.4321	micro: p 0.7079, r 0.7079, f1 0.7079	weighted_f1:0.6723
dev	acc: 0.5861	macro: p 0.3868, r 0.3429, f1: 0.3445	micro: p 0.5861, r 0.5861, f1 0.5861	weighted_f1:0.5396
test	acc: 0.6176	macro: p 0.3816, r 0.3389, f1: 0.3437	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5769
global_step: 25921, epoch: 49, loss: 0.892505
global_step: 25922, epoch: 49, loss: 0.891284
global_step: 25923, epoch: 49, loss: 0.940420
global_step: 25924, epoch: 49, loss: 1.026203
global_step: 25925, epoch: 49, loss: 0.980710
global_step: 25926, epoch: 49, loss: 0.952091
global_step: 25927, epoch: 49, loss: 0.906821
global_step: 25928, epoch: 49, loss: 0.991698
global_step: 25929, epoch: 49, loss: 0.984398
global_step: 25930, epoch: 49, loss: 0.960535
global_step: 25931, epoch: 49, loss: 0.938942
global_step: 25932, epoch: 49, loss: 0.962907
global_step: 25933, epoch: 49, loss: 1.062575
global_step: 25934, epoch: 49, loss: 1.045945
global_step: 25935, epoch: 49, loss: 0.858981
global_step: 25936, epoch: 49, loss: 0.878508
global_step: 25937, epoch: 49, loss: 0.940345
global_step: 25938, epoch: 49, loss: 0.806006
global_step: 25939, epoch: 49, loss: 1.016978
global_step: 25940, epoch: 49, loss: 0.911409
global_step: 25941, epoch: 49, loss: 1.010823
global_step: 25942, epoch: 49, loss: 0.949883
global_step: 25943, epoch: 49, loss: 0.966647
global_step: 25944, epoch: 49, loss: 0.913655
global_step: 25945, epoch: 49, loss: 0.949695
global_step: 25946, epoch: 49, loss: 0.821570
global_step: 25947, epoch: 49, loss: 0.992158
global_step: 25948, epoch: 49, loss: 0.997778
global_step: 25949, epoch: 49, loss: 0.926139
global_step: 25950, epoch: 49, loss: 0.906489
global_step: 25951, epoch: 49, loss: 0.952932
global_step: 25952, epoch: 49, loss: 0.947067
global_step: 25953, epoch: 49, loss: 0.929506
global_step: 25954, epoch: 49, loss: 0.925504
global_step: 25955, epoch: 49, loss: 0.939408
global_step: 25956, epoch: 49, loss: 0.988807
global_step: 25957, epoch: 49, loss: 0.891388
global_step: 25958, epoch: 49, loss: 0.977012
global_step: 25959, epoch: 49, loss: 0.948102
global_step: 25960, epoch: 49, loss: 0.868892
epoch: 49
train	acc: 0.7120	macro: p 0.4672, r 0.4325, f1: 0.4381	micro: p 0.7120, r 0.7120, f1 0.7120	weighted_f1:0.6796
dev	acc: 0.5771	macro: p 0.3747, r 0.3366, f1: 0.3336	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5301
test	acc: 0.6165	macro: p 0.3851, r 0.3444, f1: 0.3469	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5792
global_step: 25961, epoch: 50, loss: 0.976902
global_step: 25962, epoch: 50, loss: 1.000703
global_step: 25963, epoch: 50, loss: 0.946070
global_step: 25964, epoch: 50, loss: 1.022798
global_step: 25965, epoch: 50, loss: 0.839858
global_step: 25966, epoch: 50, loss: 1.013322
global_step: 25967, epoch: 50, loss: 0.775387
global_step: 25968, epoch: 50, loss: 0.868494
global_step: 25969, epoch: 50, loss: 0.888225
global_step: 25970, epoch: 50, loss: 0.864264
global_step: 25971, epoch: 50, loss: 0.917521
global_step: 25972, epoch: 50, loss: 0.870692
global_step: 25973, epoch: 50, loss: 0.988454
global_step: 25974, epoch: 50, loss: 1.028941
global_step: 25975, epoch: 50, loss: 1.012852
global_step: 25976, epoch: 50, loss: 0.896427
global_step: 25977, epoch: 50, loss: 0.885944
global_step: 25978, epoch: 50, loss: 0.976565
global_step: 25979, epoch: 50, loss: 0.916738
global_step: 25980, epoch: 50, loss: 0.894275
global_step: 25981, epoch: 50, loss: 0.819842
global_step: 25982, epoch: 50, loss: 1.005695
global_step: 25983, epoch: 50, loss: 0.861735
global_step: 25984, epoch: 50, loss: 1.051661
global_step: 25985, epoch: 50, loss: 0.925755
global_step: 25986, epoch: 50, loss: 0.987543
global_step: 25987, epoch: 50, loss: 0.947087
global_step: 25988, epoch: 50, loss: 0.851850
global_step: 25989, epoch: 50, loss: 1.101736
global_step: 25990, epoch: 50, loss: 0.787939
global_step: 25991, epoch: 50, loss: 0.942789
global_step: 25992, epoch: 50, loss: 1.034369
global_step: 25993, epoch: 50, loss: 0.922418
global_step: 25994, epoch: 50, loss: 0.962322
global_step: 25995, epoch: 50, loss: 0.929013
global_step: 25996, epoch: 50, loss: 0.941907
global_step: 25997, epoch: 50, loss: 1.052278
global_step: 25998, epoch: 50, loss: 0.959802
global_step: 25999, epoch: 50, loss: 1.039391
global_step: 26000, epoch: 50, loss: 0.747028
epoch: 50
train	acc: 0.7044	macro: p 0.4657, r 0.4118, f1: 0.4209	micro: p 0.7044, r 0.7044, f1 0.7044	weighted_f1:0.6641
dev	acc: 0.5852	macro: p 0.3960, r 0.3382, f1: 0.3385	micro: p 0.5852, r 0.5852, f1 0.5852	weighted_f1:0.5343
test	acc: 0.6161	macro: p 0.3871, r 0.3320, f1: 0.3356	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5698
global_step: 26001, epoch: 51, loss: 0.921557
global_step: 26002, epoch: 51, loss: 0.860113
global_step: 26003, epoch: 51, loss: 1.009753
global_step: 26004, epoch: 51, loss: 0.866108
global_step: 26005, epoch: 51, loss: 0.916359
global_step: 26006, epoch: 51, loss: 0.924109
global_step: 26007, epoch: 51, loss: 0.866092
global_step: 26008, epoch: 51, loss: 0.983566
global_step: 26009, epoch: 51, loss: 0.940512
global_step: 26010, epoch: 51, loss: 0.933945
global_step: 26011, epoch: 51, loss: 0.888153
global_step: 26012, epoch: 51, loss: 0.853256
global_step: 26013, epoch: 51, loss: 0.972613
global_step: 26014, epoch: 51, loss: 0.860896
global_step: 26015, epoch: 51, loss: 0.977675
global_step: 26016, epoch: 51, loss: 0.974794
global_step: 26017, epoch: 51, loss: 0.954224
global_step: 26018, epoch: 51, loss: 0.899425
global_step: 26019, epoch: 51, loss: 0.933108
global_step: 26020, epoch: 51, loss: 0.936877
global_step: 26021, epoch: 51, loss: 0.901063
global_step: 26022, epoch: 51, loss: 0.963947
global_step: 26023, epoch: 51, loss: 0.893039
global_step: 26024, epoch: 51, loss: 1.242261
global_step: 26025, epoch: 51, loss: 0.922006
global_step: 26026, epoch: 51, loss: 0.909471
global_step: 26027, epoch: 51, loss: 0.882114
global_step: 26028, epoch: 51, loss: 0.888435
global_step: 26029, epoch: 51, loss: 0.967531
global_step: 26030, epoch: 51, loss: 1.057423
global_step: 26031, epoch: 51, loss: 0.876560
global_step: 26032, epoch: 51, loss: 0.994564
global_step: 26033, epoch: 51, loss: 1.042036
global_step: 26034, epoch: 51, loss: 0.877479
global_step: 26035, epoch: 51, loss: 0.969852
global_step: 26036, epoch: 51, loss: 0.970422
global_step: 26037, epoch: 51, loss: 0.826070
global_step: 26038, epoch: 51, loss: 0.994399
global_step: 26039, epoch: 51, loss: 0.867354
global_step: 26040, epoch: 51, loss: 1.018450
epoch: 51
train	acc: 0.7334	macro: p 0.4729, r 0.4594, f1: 0.4537	micro: p 0.7334, r 0.7334, f1 0.7334	weighted_f1:0.7020
dev	acc: 0.5843	macro: p 0.3722, r 0.3537, f1: 0.3453	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5414
test	acc: 0.6123	macro: p 0.3755, r 0.3537, f1: 0.3480	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5793
global_step: 26041, epoch: 52, loss: 0.931586
global_step: 26042, epoch: 52, loss: 0.955985
global_step: 26043, epoch: 52, loss: 0.986751
global_step: 26044, epoch: 52, loss: 0.943487
global_step: 26045, epoch: 52, loss: 0.977900
global_step: 26046, epoch: 52, loss: 0.934448
global_step: 26047, epoch: 52, loss: 0.845376
global_step: 26048, epoch: 52, loss: 0.913026
global_step: 26049, epoch: 52, loss: 0.932198
global_step: 26050, epoch: 52, loss: 1.037039
global_step: 26051, epoch: 52, loss: 0.948174
global_step: 26052, epoch: 52, loss: 0.991624
global_step: 26053, epoch: 52, loss: 0.915651
global_step: 26054, epoch: 52, loss: 0.942443
global_step: 26055, epoch: 52, loss: 0.938984
global_step: 26056, epoch: 52, loss: 0.904662
global_step: 26057, epoch: 52, loss: 0.828854
global_step: 26058, epoch: 52, loss: 0.969769
global_step: 26059, epoch: 52, loss: 0.869798
global_step: 26060, epoch: 52, loss: 0.810405
global_step: 26061, epoch: 52, loss: 0.908787
global_step: 26062, epoch: 52, loss: 0.839955
global_step: 26063, epoch: 52, loss: 0.837410
global_step: 26064, epoch: 52, loss: 0.941711
global_step: 26065, epoch: 52, loss: 0.877563
global_step: 26066, epoch: 52, loss: 0.913578
global_step: 26067, epoch: 52, loss: 0.956131
global_step: 26068, epoch: 52, loss: 0.983577
global_step: 26069, epoch: 52, loss: 0.892323
global_step: 26070, epoch: 52, loss: 0.895248
global_step: 26071, epoch: 52, loss: 0.919646
global_step: 26072, epoch: 52, loss: 0.929218
global_step: 26073, epoch: 52, loss: 1.048483
global_step: 26074, epoch: 52, loss: 0.827919
global_step: 26075, epoch: 52, loss: 0.849491
global_step: 26076, epoch: 52, loss: 0.986748
global_step: 26077, epoch: 52, loss: 0.908525
global_step: 26078, epoch: 52, loss: 0.864247
global_step: 26079, epoch: 52, loss: 0.933433
global_step: 26080, epoch: 52, loss: 0.334459
epoch: 52
train	acc: 0.7268	macro: p 0.4767, r 0.4459, f1: 0.4473	micro: p 0.7268, r 0.7268, f1 0.7268	weighted_f1:0.6937
dev	acc: 0.5861	macro: p 0.3950, r 0.3476, f1: 0.3434	micro: p 0.5861, r 0.5861, f1 0.5861	weighted_f1:0.5394
test	acc: 0.6103	macro: p 0.3804, r 0.3435, f1: 0.3420	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5738
global_step: 26081, epoch: 53, loss: 0.842297
global_step: 26082, epoch: 53, loss: 0.870753
global_step: 26083, epoch: 53, loss: 0.966389
global_step: 26084, epoch: 53, loss: 0.856081
global_step: 26085, epoch: 53, loss: 0.983632
global_step: 26086, epoch: 53, loss: 0.864797
global_step: 26087, epoch: 53, loss: 0.861717
global_step: 26088, epoch: 53, loss: 0.974086
global_step: 26089, epoch: 53, loss: 0.891861
global_step: 26090, epoch: 53, loss: 0.856675
global_step: 26091, epoch: 53, loss: 0.922684
global_step: 26092, epoch: 53, loss: 0.863545
global_step: 26093, epoch: 53, loss: 0.854845
global_step: 26094, epoch: 53, loss: 0.911914
global_step: 26095, epoch: 53, loss: 0.953337
global_step: 26096, epoch: 53, loss: 0.968077
global_step: 26097, epoch: 53, loss: 0.920215
global_step: 26098, epoch: 53, loss: 0.957795
global_step: 26099, epoch: 53, loss: 1.038218
global_step: 26100, epoch: 53, loss: 0.874594
global_step: 26101, epoch: 53, loss: 0.850378
global_step: 26102, epoch: 53, loss: 0.929294
global_step: 26103, epoch: 53, loss: 0.815582
global_step: 26104, epoch: 53, loss: 0.804139
global_step: 26105, epoch: 53, loss: 1.014207
global_step: 26106, epoch: 53, loss: 0.823590
global_step: 26107, epoch: 53, loss: 0.922623
global_step: 26108, epoch: 53, loss: 0.963384
global_step: 26109, epoch: 53, loss: 0.905631
global_step: 26110, epoch: 53, loss: 1.006544
global_step: 26111, epoch: 53, loss: 0.883098
global_step: 26112, epoch: 53, loss: 0.951089
global_step: 26113, epoch: 53, loss: 0.924300
global_step: 26114, epoch: 53, loss: 0.904839
global_step: 26115, epoch: 53, loss: 0.926891
global_step: 26116, epoch: 53, loss: 0.873323
global_step: 26117, epoch: 53, loss: 0.888487
global_step: 26118, epoch: 53, loss: 1.056730
global_step: 26119, epoch: 53, loss: 0.909495
global_step: 26120, epoch: 53, loss: 1.176586
epoch: 53
train	acc: 0.7322	macro: p 0.4819, r 0.4510, f1: 0.4550	micro: p 0.7322, r 0.7322, f1 0.7322	weighted_f1:0.6982
dev	acc: 0.5960	macro: p 0.3942, r 0.3530, f1: 0.3506	micro: p 0.5960, r 0.5960, f1 0.5960	weighted_f1:0.5477
test	acc: 0.6195	macro: p 0.3838, r 0.3453, f1: 0.3471	micro: p 0.6195, r 0.6195, f1 0.6195	weighted_f1:0.5800
New best model!
global_step: 26121, epoch: 54, loss: 0.859478
global_step: 26122, epoch: 54, loss: 0.872951
global_step: 26123, epoch: 54, loss: 0.913142
global_step: 26124, epoch: 54, loss: 0.828511
global_step: 26125, epoch: 54, loss: 0.962897
global_step: 26126, epoch: 54, loss: 0.973398
global_step: 26127, epoch: 54, loss: 0.886441
global_step: 26128, epoch: 54, loss: 0.799568
global_step: 26129, epoch: 54, loss: 0.838135
global_step: 26130, epoch: 54, loss: 1.030406
global_step: 26131, epoch: 54, loss: 0.917822
global_step: 26132, epoch: 54, loss: 0.917287
global_step: 26133, epoch: 54, loss: 0.877575
global_step: 26134, epoch: 54, loss: 0.919961
global_step: 26135, epoch: 54, loss: 0.900430
global_step: 26136, epoch: 54, loss: 0.901621
global_step: 26137, epoch: 54, loss: 0.989470
global_step: 26138, epoch: 54, loss: 0.925999
global_step: 26139, epoch: 54, loss: 0.928443
global_step: 26140, epoch: 54, loss: 0.804528
global_step: 26141, epoch: 54, loss: 0.879734
global_step: 26142, epoch: 54, loss: 0.969250
global_step: 26143, epoch: 54, loss: 0.815179
global_step: 26144, epoch: 54, loss: 0.955763
global_step: 26145, epoch: 54, loss: 0.806125
global_step: 26146, epoch: 54, loss: 0.937672
global_step: 26147, epoch: 54, loss: 0.933259
global_step: 26148, epoch: 54, loss: 0.954050
global_step: 26149, epoch: 54, loss: 0.935698
global_step: 26150, epoch: 54, loss: 0.902323
global_step: 26151, epoch: 54, loss: 0.855838
global_step: 26152, epoch: 54, loss: 0.922615
global_step: 26153, epoch: 54, loss: 0.901585
global_step: 26154, epoch: 54, loss: 0.918521
global_step: 26155, epoch: 54, loss: 0.864848
global_step: 26156, epoch: 54, loss: 1.003913
global_step: 26157, epoch: 54, loss: 0.880691
global_step: 26158, epoch: 54, loss: 0.792533
global_step: 26159, epoch: 54, loss: 0.927150
global_step: 26160, epoch: 54, loss: 0.895704
epoch: 54
train	acc: 0.7232	macro: p 0.4815, r 0.4344, f1: 0.4412	micro: p 0.7232, r 0.7232, f1 0.7232	weighted_f1:0.6841
dev	acc: 0.5915	macro: p 0.3877, r 0.3440, f1: 0.3418	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5393
test	acc: 0.6172	macro: p 0.3781, r 0.3347, f1: 0.3372	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5717
global_step: 26161, epoch: 55, loss: 0.956141
global_step: 26162, epoch: 55, loss: 0.899492
global_step: 26163, epoch: 55, loss: 0.844407
global_step: 26164, epoch: 55, loss: 0.824447
global_step: 26165, epoch: 55, loss: 0.979610
global_step: 26166, epoch: 55, loss: 0.983914
global_step: 26167, epoch: 55, loss: 0.786154
global_step: 26168, epoch: 55, loss: 0.956026
global_step: 26169, epoch: 55, loss: 0.895170
global_step: 26170, epoch: 55, loss: 0.827892
global_step: 26171, epoch: 55, loss: 0.892239
global_step: 26172, epoch: 55, loss: 0.848181
global_step: 26173, epoch: 55, loss: 0.955954
global_step: 26174, epoch: 55, loss: 0.898040
global_step: 26175, epoch: 55, loss: 0.895644
global_step: 26176, epoch: 55, loss: 0.895256
global_step: 26177, epoch: 55, loss: 0.878609
global_step: 26178, epoch: 55, loss: 0.820560
global_step: 26179, epoch: 55, loss: 0.847440
global_step: 26180, epoch: 55, loss: 0.844570
global_step: 26181, epoch: 55, loss: 0.920806
global_step: 26182, epoch: 55, loss: 0.855639
global_step: 26183, epoch: 55, loss: 0.914023
global_step: 26184, epoch: 55, loss: 0.872455
global_step: 26185, epoch: 55, loss: 0.931421
global_step: 26186, epoch: 55, loss: 0.873340
global_step: 26187, epoch: 55, loss: 0.790650
global_step: 26188, epoch: 55, loss: 0.884835
global_step: 26189, epoch: 55, loss: 0.911605
global_step: 26190, epoch: 55, loss: 0.901732
global_step: 26191, epoch: 55, loss: 0.962167
global_step: 26192, epoch: 55, loss: 0.864315
global_step: 26193, epoch: 55, loss: 1.017679
global_step: 26194, epoch: 55, loss: 0.982287
global_step: 26195, epoch: 55, loss: 0.887754
global_step: 26196, epoch: 55, loss: 0.962589
global_step: 26197, epoch: 55, loss: 0.874755
global_step: 26198, epoch: 55, loss: 0.826805
global_step: 26199, epoch: 55, loss: 0.838040
global_step: 26200, epoch: 55, loss: 0.551615
epoch: 55
train	acc: 0.7231	macro: p 0.4859, r 0.4329, f1: 0.4413	micro: p 0.7231, r 0.7231, f1 0.7231	weighted_f1:0.6851
dev	acc: 0.5870	macro: p 0.4000, r 0.3400, f1: 0.3370	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5343
test	acc: 0.6103	macro: p 0.3822, r 0.3287, f1: 0.3290	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5638
global_step: 26201, epoch: 56, loss: 0.868404
global_step: 26202, epoch: 56, loss: 0.881780
global_step: 26203, epoch: 56, loss: 0.946240
global_step: 26204, epoch: 56, loss: 0.883390
global_step: 26205, epoch: 56, loss: 0.784180
global_step: 26206, epoch: 56, loss: 0.835454
global_step: 26207, epoch: 56, loss: 0.851597
global_step: 26208, epoch: 56, loss: 0.891785
global_step: 26209, epoch: 56, loss: 0.894095
global_step: 26210, epoch: 56, loss: 0.941900
global_step: 26211, epoch: 56, loss: 0.781225
global_step: 26212, epoch: 56, loss: 0.843304
global_step: 26213, epoch: 56, loss: 0.903419
global_step: 26214, epoch: 56, loss: 0.887925
global_step: 26215, epoch: 56, loss: 0.941198
global_step: 26216, epoch: 56, loss: 0.977470
global_step: 26217, epoch: 56, loss: 0.849132
global_step: 26218, epoch: 56, loss: 0.807860
global_step: 26219, epoch: 56, loss: 0.897107
global_step: 26220, epoch: 56, loss: 0.856985
global_step: 26221, epoch: 56, loss: 0.761680
global_step: 26222, epoch: 56, loss: 0.859713
global_step: 26223, epoch: 56, loss: 0.936230
global_step: 26224, epoch: 56, loss: 1.005648
global_step: 26225, epoch: 56, loss: 0.827293
global_step: 26226, epoch: 56, loss: 0.926184
global_step: 26227, epoch: 56, loss: 0.900069
global_step: 26228, epoch: 56, loss: 0.918478
global_step: 26229, epoch: 56, loss: 0.966039
global_step: 26230, epoch: 56, loss: 0.856930
global_step: 26231, epoch: 56, loss: 0.839413
global_step: 26232, epoch: 56, loss: 0.948154
global_step: 26233, epoch: 56, loss: 0.843250
global_step: 26234, epoch: 56, loss: 0.813304
global_step: 26235, epoch: 56, loss: 0.892860
global_step: 26236, epoch: 56, loss: 0.903232
global_step: 26237, epoch: 56, loss: 0.925062
global_step: 26238, epoch: 56, loss: 0.861687
global_step: 26239, epoch: 56, loss: 0.828204
global_step: 26240, epoch: 56, loss: 0.537339
epoch: 56
train	acc: 0.7383	macro: p 0.4878, r 0.4605, f1: 0.4611	micro: p 0.7383, r 0.7383, f1 0.7383	weighted_f1:0.7073
dev	acc: 0.5843	macro: p 0.3888, r 0.3504, f1: 0.3435	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5397
test	acc: 0.6126	macro: p 0.3867, r 0.3498, f1: 0.3466	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5779
global_step: 26241, epoch: 57, loss: 0.918480
global_step: 26242, epoch: 57, loss: 0.850611
global_step: 26243, epoch: 57, loss: 0.894330
global_step: 26244, epoch: 57, loss: 0.781997
global_step: 26245, epoch: 57, loss: 1.013372
global_step: 26246, epoch: 57, loss: 0.936415
global_step: 26247, epoch: 57, loss: 0.783829
global_step: 26248, epoch: 57, loss: 0.914077
global_step: 26249, epoch: 57, loss: 0.802737
global_step: 26250, epoch: 57, loss: 0.985448
global_step: 26251, epoch: 57, loss: 0.839610
global_step: 26252, epoch: 57, loss: 0.912780
global_step: 26253, epoch: 57, loss: 0.880132
global_step: 26254, epoch: 57, loss: 0.848997
global_step: 26255, epoch: 57, loss: 0.891777
global_step: 26256, epoch: 57, loss: 0.887315
global_step: 26257, epoch: 57, loss: 0.820426
global_step: 26258, epoch: 57, loss: 0.993213
global_step: 26259, epoch: 57, loss: 0.936957
global_step: 26260, epoch: 57, loss: 0.877970
global_step: 26261, epoch: 57, loss: 0.854569
global_step: 26262, epoch: 57, loss: 0.818279
global_step: 26263, epoch: 57, loss: 0.897462
global_step: 26264, epoch: 57, loss: 0.966685
global_step: 26265, epoch: 57, loss: 0.939401
global_step: 26266, epoch: 57, loss: 0.906063
global_step: 26267, epoch: 57, loss: 0.856203
global_step: 26268, epoch: 57, loss: 0.909988
global_step: 26269, epoch: 57, loss: 0.811109
global_step: 26270, epoch: 57, loss: 0.813665
global_step: 26271, epoch: 57, loss: 0.755554
global_step: 26272, epoch: 57, loss: 0.844285
global_step: 26273, epoch: 57, loss: 0.902094
global_step: 26274, epoch: 57, loss: 0.863620
global_step: 26275, epoch: 57, loss: 0.827579
global_step: 26276, epoch: 57, loss: 0.859656
global_step: 26277, epoch: 57, loss: 0.907663
global_step: 26278, epoch: 57, loss: 0.907498
global_step: 26279, epoch: 57, loss: 0.744866
global_step: 26280, epoch: 57, loss: 0.763241
epoch: 57
train	acc: 0.7391	macro: p 0.4946, r 0.4561, f1: 0.4639	micro: p 0.7391, r 0.7391, f1 0.7391	weighted_f1:0.7062
dev	acc: 0.5879	macro: p 0.3974, r 0.3442, f1: 0.3447	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5405
test	acc: 0.6234	macro: p 0.3904, r 0.3435, f1: 0.3485	micro: p 0.6234, r 0.6234, f1 0.6234	weighted_f1:0.5827
global_step: 26281, epoch: 58, loss: 0.819532
global_step: 26282, epoch: 58, loss: 0.816231
global_step: 26283, epoch: 58, loss: 0.849708
global_step: 26284, epoch: 58, loss: 0.905859
global_step: 26285, epoch: 58, loss: 0.770664
global_step: 26286, epoch: 58, loss: 0.867136
global_step: 26287, epoch: 58, loss: 0.817445
global_step: 26288, epoch: 58, loss: 0.920364
global_step: 26289, epoch: 58, loss: 0.847579
global_step: 26290, epoch: 58, loss: 0.957407
global_step: 26291, epoch: 58, loss: 0.935244
global_step: 26292, epoch: 58, loss: 0.834639
global_step: 26293, epoch: 58, loss: 0.893071
global_step: 26294, epoch: 58, loss: 0.932493
global_step: 26295, epoch: 58, loss: 0.902743
global_step: 26296, epoch: 58, loss: 0.818525
global_step: 26297, epoch: 58, loss: 1.000444
global_step: 26298, epoch: 58, loss: 0.841094
global_step: 26299, epoch: 58, loss: 0.910937
global_step: 26300, epoch: 58, loss: 0.873621
global_step: 26301, epoch: 58, loss: 0.799953
global_step: 26302, epoch: 58, loss: 0.852248
global_step: 26303, epoch: 58, loss: 0.798981
global_step: 26304, epoch: 58, loss: 0.903985
global_step: 26305, epoch: 58, loss: 0.901271
global_step: 26306, epoch: 58, loss: 0.918009
global_step: 26307, epoch: 58, loss: 0.768901
global_step: 26308, epoch: 58, loss: 0.916750
global_step: 26309, epoch: 58, loss: 0.820341
global_step: 26310, epoch: 58, loss: 0.922462
global_step: 26311, epoch: 58, loss: 0.827175
global_step: 26312, epoch: 58, loss: 0.903296
global_step: 26313, epoch: 58, loss: 0.754500
global_step: 26314, epoch: 58, loss: 0.839067
global_step: 26315, epoch: 58, loss: 0.886303
global_step: 26316, epoch: 58, loss: 0.814231
global_step: 26317, epoch: 58, loss: 0.890377
global_step: 26318, epoch: 58, loss: 0.901636
global_step: 26319, epoch: 58, loss: 0.884133
global_step: 26320, epoch: 58, loss: 1.011000
epoch: 58
train	acc: 0.7559	macro: p 0.4975, r 0.4793, f1: 0.4786	micro: p 0.7559, r 0.7559, f1 0.7559	weighted_f1:0.7243
dev	acc: 0.5915	macro: p 0.3876, r 0.3547, f1: 0.3495	micro: p 0.5915, r 0.5915, f1 0.5915	weighted_f1:0.5448
test	acc: 0.6234	macro: p 0.3854, r 0.3544, f1: 0.3543	micro: p 0.6234, r 0.6234, f1 0.6234	weighted_f1:0.5868
global_step: 26321, epoch: 59, loss: 0.888282
global_step: 26322, epoch: 59, loss: 0.848843
global_step: 26323, epoch: 59, loss: 0.863658
global_step: 26324, epoch: 59, loss: 0.845479
global_step: 26325, epoch: 59, loss: 0.895252
global_step: 26326, epoch: 59, loss: 0.802559
global_step: 26327, epoch: 59, loss: 0.791386
global_step: 26328, epoch: 59, loss: 0.854747
global_step: 26329, epoch: 59, loss: 0.892189
global_step: 26330, epoch: 59, loss: 0.898121
global_step: 26331, epoch: 59, loss: 0.828731
global_step: 26332, epoch: 59, loss: 0.855062
global_step: 26333, epoch: 59, loss: 0.924967
global_step: 26334, epoch: 59, loss: 0.810946
global_step: 26335, epoch: 59, loss: 0.737319
global_step: 26336, epoch: 59, loss: 0.907246
global_step: 26337, epoch: 59, loss: 0.881608
global_step: 26338, epoch: 59, loss: 0.928122
global_step: 26339, epoch: 59, loss: 0.832284
global_step: 26340, epoch: 59, loss: 0.829129
global_step: 26341, epoch: 59, loss: 0.814225
global_step: 26342, epoch: 59, loss: 0.773092
global_step: 26343, epoch: 59, loss: 0.887379
global_step: 26344, epoch: 59, loss: 0.769054
global_step: 26345, epoch: 59, loss: 0.904917
global_step: 26346, epoch: 59, loss: 0.854338
global_step: 26347, epoch: 59, loss: 0.805401
global_step: 26348, epoch: 59, loss: 0.889190
global_step: 26349, epoch: 59, loss: 0.758269
global_step: 26350, epoch: 59, loss: 0.918140
global_step: 26351, epoch: 59, loss: 0.888402
global_step: 26352, epoch: 59, loss: 0.826930
global_step: 26353, epoch: 59, loss: 0.834847
global_step: 26354, epoch: 59, loss: 0.911096
global_step: 26355, epoch: 59, loss: 0.756188
global_step: 26356, epoch: 59, loss: 0.926362
global_step: 26357, epoch: 59, loss: 0.797781
global_step: 26358, epoch: 59, loss: 0.965477
global_step: 26359, epoch: 59, loss: 0.790514
global_step: 26360, epoch: 59, loss: 0.981561
epoch: 59
train	acc: 0.7623	macro: p 0.5012, r 0.4912, f1: 0.4886	micro: p 0.7623, r 0.7623, f1 0.7623	weighted_f1:0.7348
dev	acc: 0.5852	macro: p 0.3822, r 0.3536, f1: 0.3481	micro: p 0.5852, r 0.5852, f1 0.5852	weighted_f1:0.5444
test	acc: 0.6126	macro: p 0.3784, r 0.3559, f1: 0.3540	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5824
global_step: 26361, epoch: 60, loss: 0.958786
global_step: 26362, epoch: 60, loss: 0.903494
global_step: 26363, epoch: 60, loss: 0.856631
global_step: 26364, epoch: 60, loss: 0.841895
global_step: 26365, epoch: 60, loss: 0.926174
global_step: 26366, epoch: 60, loss: 0.941079
global_step: 26367, epoch: 60, loss: 0.758826
global_step: 26368, epoch: 60, loss: 0.860509
global_step: 26369, epoch: 60, loss: 0.786409
global_step: 26370, epoch: 60, loss: 0.846644
global_step: 26371, epoch: 60, loss: 0.910063
global_step: 26372, epoch: 60, loss: 0.838681
global_step: 26373, epoch: 60, loss: 0.888717
global_step: 26374, epoch: 60, loss: 0.825026
global_step: 26375, epoch: 60, loss: 0.873171
global_step: 26376, epoch: 60, loss: 0.767908
global_step: 26377, epoch: 60, loss: 0.852668
global_step: 26378, epoch: 60, loss: 0.898981
global_step: 26379, epoch: 60, loss: 0.772802
global_step: 26380, epoch: 60, loss: 0.870715
global_step: 26381, epoch: 60, loss: 0.945963
global_step: 26382, epoch: 60, loss: 0.846272
global_step: 26383, epoch: 60, loss: 0.923461
global_step: 26384, epoch: 60, loss: 0.789418
global_step: 26385, epoch: 60, loss: 0.849946
global_step: 26386, epoch: 60, loss: 0.796053
global_step: 26387, epoch: 60, loss: 0.806639
global_step: 26388, epoch: 60, loss: 0.888325
global_step: 26389, epoch: 60, loss: 0.780829
global_step: 26390, epoch: 60, loss: 0.846841
global_step: 26391, epoch: 60, loss: 0.872698
global_step: 26392, epoch: 60, loss: 0.738022
global_step: 26393, epoch: 60, loss: 0.761151
global_step: 26394, epoch: 60, loss: 0.856901
global_step: 26395, epoch: 60, loss: 0.851549
global_step: 26396, epoch: 60, loss: 0.886806
global_step: 26397, epoch: 60, loss: 0.825815
global_step: 26398, epoch: 60, loss: 0.970175
global_step: 26399, epoch: 60, loss: 0.752511
global_step: 26400, epoch: 60, loss: 0.442579
epoch: 60
train	acc: 0.7709	macro: p 0.5075, r 0.5024, f1: 0.4992	micro: p 0.7709, r 0.7709, f1 0.7709	weighted_f1:0.7446
dev	acc: 0.5852	macro: p 0.3745, r 0.3524, f1: 0.3503	micro: p 0.5852, r 0.5852, f1 0.5852	weighted_f1:0.5456
test	acc: 0.6188	macro: p 0.3769, r 0.3603, f1: 0.3596	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5884
global_step: 26401, epoch: 61, loss: 0.782376
global_step: 26402, epoch: 61, loss: 0.823522
global_step: 26403, epoch: 61, loss: 0.704140
global_step: 26404, epoch: 61, loss: 0.844674
global_step: 26405, epoch: 61, loss: 0.788756
global_step: 26406, epoch: 61, loss: 0.882827
global_step: 26407, epoch: 61, loss: 0.887326
global_step: 26408, epoch: 61, loss: 0.800118
global_step: 26409, epoch: 61, loss: 0.884468
global_step: 26410, epoch: 61, loss: 0.865718
global_step: 26411, epoch: 61, loss: 0.826625
global_step: 26412, epoch: 61, loss: 0.832408
global_step: 26413, epoch: 61, loss: 0.716880
global_step: 26414, epoch: 61, loss: 0.862980
global_step: 26415, epoch: 61, loss: 0.867154
global_step: 26416, epoch: 61, loss: 0.782346
global_step: 26417, epoch: 61, loss: 0.845054
global_step: 26418, epoch: 61, loss: 0.763129
global_step: 26419, epoch: 61, loss: 0.807991
global_step: 26420, epoch: 61, loss: 0.881435
global_step: 26421, epoch: 61, loss: 0.753223
global_step: 26422, epoch: 61, loss: 0.796756
global_step: 26423, epoch: 61, loss: 0.720066
global_step: 26424, epoch: 61, loss: 0.800398
global_step: 26425, epoch: 61, loss: 0.770441
global_step: 26426, epoch: 61, loss: 0.901748
global_step: 26427, epoch: 61, loss: 0.816477
global_step: 26428, epoch: 61, loss: 0.848433
global_step: 26429, epoch: 61, loss: 0.850096
global_step: 26430, epoch: 61, loss: 0.821854
global_step: 26431, epoch: 61, loss: 0.915483
global_step: 26432, epoch: 61, loss: 0.894816
global_step: 26433, epoch: 61, loss: 0.860498
global_step: 26434, epoch: 61, loss: 0.865522
global_step: 26435, epoch: 61, loss: 0.877519
global_step: 26436, epoch: 61, loss: 0.886415
global_step: 26437, epoch: 61, loss: 0.897322
global_step: 26438, epoch: 61, loss: 0.878057
global_step: 26439, epoch: 61, loss: 0.849954
global_step: 26440, epoch: 61, loss: 0.924578
epoch: 61
train	acc: 0.7712	macro: p 0.5066, r 0.5040, f1: 0.5004	micro: p 0.7712, r 0.7712, f1 0.7712	weighted_f1:0.7453
dev	acc: 0.5744	macro: p 0.3721, r 0.3503, f1: 0.3441	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5354
test	acc: 0.6092	macro: p 0.3736, r 0.3541, f1: 0.3517	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5794
global_step: 26441, epoch: 62, loss: 0.794941
global_step: 26442, epoch: 62, loss: 1.013741
global_step: 26443, epoch: 62, loss: 0.720871
global_step: 26444, epoch: 62, loss: 0.874238
global_step: 26445, epoch: 62, loss: 0.852948
global_step: 26446, epoch: 62, loss: 0.805851
global_step: 26447, epoch: 62, loss: 0.709660
global_step: 26448, epoch: 62, loss: 0.792560
global_step: 26449, epoch: 62, loss: 0.839302
global_step: 26450, epoch: 62, loss: 0.757924
global_step: 26451, epoch: 62, loss: 0.756035
global_step: 26452, epoch: 62, loss: 0.782789
global_step: 26453, epoch: 62, loss: 0.888032
global_step: 26454, epoch: 62, loss: 0.778857
global_step: 26455, epoch: 62, loss: 0.823067
global_step: 26456, epoch: 62, loss: 0.899472
global_step: 26457, epoch: 62, loss: 0.899390
global_step: 26458, epoch: 62, loss: 0.845727
global_step: 26459, epoch: 62, loss: 0.942168
global_step: 26460, epoch: 62, loss: 0.872766
global_step: 26461, epoch: 62, loss: 0.807134
global_step: 26462, epoch: 62, loss: 0.767661
global_step: 26463, epoch: 62, loss: 0.733332
global_step: 26464, epoch: 62, loss: 0.880231
global_step: 26465, epoch: 62, loss: 0.864206
global_step: 26466, epoch: 62, loss: 0.784063
global_step: 26467, epoch: 62, loss: 0.980501
global_step: 26468, epoch: 62, loss: 0.758652
global_step: 26469, epoch: 62, loss: 0.770251
global_step: 26470, epoch: 62, loss: 0.907794
global_step: 26471, epoch: 62, loss: 0.766161
global_step: 26472, epoch: 62, loss: 0.769574
global_step: 26473, epoch: 62, loss: 0.903775
global_step: 26474, epoch: 62, loss: 0.839152
global_step: 26475, epoch: 62, loss: 0.898435
global_step: 26476, epoch: 62, loss: 0.796365
global_step: 26477, epoch: 62, loss: 0.801735
global_step: 26478, epoch: 62, loss: 0.795317
global_step: 26479, epoch: 62, loss: 0.929448
global_step: 26480, epoch: 62, loss: 1.124629
epoch: 62
train	acc: 0.7652	macro: p 0.5151, r 0.4867, f1: 0.4901	micro: p 0.7652, r 0.7652, f1 0.7652	weighted_f1:0.7350
dev	acc: 0.5879	macro: p 0.3905, r 0.3461, f1: 0.3445	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5410
test	acc: 0.6199	macro: p 0.3910, r 0.3465, f1: 0.3501	micro: p 0.6199, r 0.6199, f1 0.6199	weighted_f1:0.5820
global_step: 26481, epoch: 63, loss: 0.870767
global_step: 26482, epoch: 63, loss: 0.856525
global_step: 26483, epoch: 63, loss: 0.782326
global_step: 26484, epoch: 63, loss: 0.882666
global_step: 26485, epoch: 63, loss: 0.839368
global_step: 26486, epoch: 63, loss: 0.808106
global_step: 26487, epoch: 63, loss: 0.734290
global_step: 26488, epoch: 63, loss: 0.906765
global_step: 26489, epoch: 63, loss: 0.832678
global_step: 26490, epoch: 63, loss: 0.848786
global_step: 26491, epoch: 63, loss: 0.848265
global_step: 26492, epoch: 63, loss: 0.827233
global_step: 26493, epoch: 63, loss: 0.849030
global_step: 26494, epoch: 63, loss: 0.790693
global_step: 26495, epoch: 63, loss: 0.852971
global_step: 26496, epoch: 63, loss: 0.857735
global_step: 26497, epoch: 63, loss: 0.752912
global_step: 26498, epoch: 63, loss: 0.745960
global_step: 26499, epoch: 63, loss: 0.839182
global_step: 26500, epoch: 63, loss: 0.802310
global_step: 26501, epoch: 63, loss: 0.805933
global_step: 26502, epoch: 63, loss: 0.816265
global_step: 26503, epoch: 63, loss: 0.752398
global_step: 26504, epoch: 63, loss: 0.731169
global_step: 26505, epoch: 63, loss: 0.775355
global_step: 26506, epoch: 63, loss: 0.922673
global_step: 26507, epoch: 63, loss: 0.866324
global_step: 26508, epoch: 63, loss: 0.792346
global_step: 26509, epoch: 63, loss: 0.771506
global_step: 26510, epoch: 63, loss: 0.741152
global_step: 26511, epoch: 63, loss: 0.736664
global_step: 26512, epoch: 63, loss: 0.898824
global_step: 26513, epoch: 63, loss: 0.908902
global_step: 26514, epoch: 63, loss: 0.759756
global_step: 26515, epoch: 63, loss: 0.778367
global_step: 26516, epoch: 63, loss: 0.972628
global_step: 26517, epoch: 63, loss: 0.807843
global_step: 26518, epoch: 63, loss: 0.738591
global_step: 26519, epoch: 63, loss: 0.879845
global_step: 26520, epoch: 63, loss: 0.974747
epoch: 63
train	acc: 0.7724	macro: p 0.5174, r 0.4920, f1: 0.4919	micro: p 0.7724, r 0.7724, f1 0.7724	weighted_f1:0.7401
dev	acc: 0.5924	macro: p 0.3920, r 0.3536, f1: 0.3489	micro: p 0.5924, r 0.5924, f1 0.5924	weighted_f1:0.5452
test	acc: 0.6176	macro: p 0.3908, r 0.3489, f1: 0.3488	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5799
global_step: 26521, epoch: 64, loss: 0.764609
global_step: 26522, epoch: 64, loss: 0.731940
global_step: 26523, epoch: 64, loss: 0.878259
global_step: 26524, epoch: 64, loss: 0.790275
global_step: 26525, epoch: 64, loss: 0.868864
global_step: 26526, epoch: 64, loss: 0.877100
global_step: 26527, epoch: 64, loss: 0.774064
global_step: 26528, epoch: 64, loss: 0.806488
global_step: 26529, epoch: 64, loss: 0.800659
global_step: 26530, epoch: 64, loss: 0.758101
global_step: 26531, epoch: 64, loss: 0.948618
global_step: 26532, epoch: 64, loss: 0.841619
global_step: 26533, epoch: 64, loss: 0.840032
global_step: 26534, epoch: 64, loss: 0.774484
global_step: 26535, epoch: 64, loss: 0.745916
global_step: 26536, epoch: 64, loss: 0.781516
global_step: 26537, epoch: 64, loss: 0.719671
global_step: 26538, epoch: 64, loss: 0.811461
global_step: 26539, epoch: 64, loss: 0.765739
global_step: 26540, epoch: 64, loss: 0.872464
global_step: 26541, epoch: 64, loss: 0.727273
global_step: 26542, epoch: 64, loss: 0.815244
global_step: 26543, epoch: 64, loss: 0.718347
global_step: 26544, epoch: 64, loss: 0.801979
global_step: 26545, epoch: 64, loss: 0.733101
global_step: 26546, epoch: 64, loss: 0.798330
global_step: 26547, epoch: 64, loss: 0.908157
global_step: 26548, epoch: 64, loss: 0.771109
global_step: 26549, epoch: 64, loss: 0.783384
global_step: 26550, epoch: 64, loss: 0.898086
global_step: 26551, epoch: 64, loss: 0.829696
global_step: 26552, epoch: 64, loss: 0.837109
global_step: 26553, epoch: 64, loss: 0.820128
global_step: 26554, epoch: 64, loss: 0.876748
global_step: 26555, epoch: 64, loss: 0.801065
global_step: 26556, epoch: 64, loss: 0.777862
global_step: 26557, epoch: 64, loss: 0.881800
global_step: 26558, epoch: 64, loss: 0.783458
global_step: 26559, epoch: 64, loss: 0.806372
global_step: 26560, epoch: 64, loss: 1.231775
epoch: 64
train	acc: 0.7631	macro: p 0.5166, r 0.4825, f1: 0.4915	micro: p 0.7631, r 0.7631, f1 0.7631	weighted_f1:0.7315
dev	acc: 0.5843	macro: p 0.3902, r 0.3419, f1: 0.3430	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5359
test	acc: 0.6195	macro: p 0.3908, r 0.3398, f1: 0.3468	micro: p 0.6195, r 0.6195, f1 0.6195	weighted_f1:0.5770
global_step: 26561, epoch: 65, loss: 0.734357
global_step: 26562, epoch: 65, loss: 0.752470
global_step: 26563, epoch: 65, loss: 0.795632
global_step: 26564, epoch: 65, loss: 0.808611
global_step: 26565, epoch: 65, loss: 0.779748
global_step: 26566, epoch: 65, loss: 0.722059
global_step: 26567, epoch: 65, loss: 0.738345
global_step: 26568, epoch: 65, loss: 0.818254
global_step: 26569, epoch: 65, loss: 0.759856
global_step: 26570, epoch: 65, loss: 0.862200
global_step: 26571, epoch: 65, loss: 0.806407
global_step: 26572, epoch: 65, loss: 0.825930
global_step: 26573, epoch: 65, loss: 0.788320
global_step: 26574, epoch: 65, loss: 0.907704
global_step: 26575, epoch: 65, loss: 0.744319
global_step: 26576, epoch: 65, loss: 0.819546
global_step: 26577, epoch: 65, loss: 0.877828
global_step: 26578, epoch: 65, loss: 0.777003
global_step: 26579, epoch: 65, loss: 0.836977
global_step: 26580, epoch: 65, loss: 0.798482
global_step: 26581, epoch: 65, loss: 0.928828
global_step: 26582, epoch: 65, loss: 0.798581
global_step: 26583, epoch: 65, loss: 0.791161
global_step: 26584, epoch: 65, loss: 0.873207
global_step: 26585, epoch: 65, loss: 0.759251
global_step: 26586, epoch: 65, loss: 0.889816
global_step: 26587, epoch: 65, loss: 0.737867
global_step: 26588, epoch: 65, loss: 0.928877
global_step: 26589, epoch: 65, loss: 0.779981
global_step: 26590, epoch: 65, loss: 0.782242
global_step: 26591, epoch: 65, loss: 0.817802
global_step: 26592, epoch: 65, loss: 0.824667
global_step: 26593, epoch: 65, loss: 0.843217
global_step: 26594, epoch: 65, loss: 0.773977
global_step: 26595, epoch: 65, loss: 0.857296
global_step: 26596, epoch: 65, loss: 0.826970
global_step: 26597, epoch: 65, loss: 0.761940
global_step: 26598, epoch: 65, loss: 0.737211
global_step: 26599, epoch: 65, loss: 0.776219
global_step: 26600, epoch: 65, loss: 1.306954
epoch: 65
train	acc: 0.7855	macro: p 0.5248, r 0.5200, f1: 0.5178	micro: p 0.7855, r 0.7855, f1 0.7855	weighted_f1:0.7602
dev	acc: 0.5870	macro: p 0.3771, r 0.3511, f1: 0.3517	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5461
test	acc: 0.6249	macro: p 0.3866, r 0.3599, f1: 0.3644	micro: p 0.6249, r 0.6249, f1 0.6249	weighted_f1:0.5932
global_step: 26601, epoch: 66, loss: 0.747946
global_step: 26602, epoch: 66, loss: 0.749161
global_step: 26603, epoch: 66, loss: 0.672252
global_step: 26604, epoch: 66, loss: 0.828152
global_step: 26605, epoch: 66, loss: 0.816039
global_step: 26606, epoch: 66, loss: 0.761934
global_step: 26607, epoch: 66, loss: 0.711453
global_step: 26608, epoch: 66, loss: 0.740108
global_step: 26609, epoch: 66, loss: 0.826596
global_step: 26610, epoch: 66, loss: 0.898399
global_step: 26611, epoch: 66, loss: 0.741426
global_step: 26612, epoch: 66, loss: 0.748016
global_step: 26613, epoch: 66, loss: 0.812431
global_step: 26614, epoch: 66, loss: 0.835564
global_step: 26615, epoch: 66, loss: 0.836155
global_step: 26616, epoch: 66, loss: 0.893210
global_step: 26617, epoch: 66, loss: 0.720217
global_step: 26618, epoch: 66, loss: 0.859653
global_step: 26619, epoch: 66, loss: 0.719783
global_step: 26620, epoch: 66, loss: 0.770628
global_step: 26621, epoch: 66, loss: 0.751892
global_step: 26622, epoch: 66, loss: 0.843898
global_step: 26623, epoch: 66, loss: 0.879271
global_step: 26624, epoch: 66, loss: 0.804004
global_step: 26625, epoch: 66, loss: 0.816387
global_step: 26626, epoch: 66, loss: 0.685026
global_step: 26627, epoch: 66, loss: 0.851015
global_step: 26628, epoch: 66, loss: 0.744362
global_step: 26629, epoch: 66, loss: 0.669328
global_step: 26630, epoch: 66, loss: 0.862794
global_step: 26631, epoch: 66, loss: 0.866443
global_step: 26632, epoch: 66, loss: 0.768339
global_step: 26633, epoch: 66, loss: 0.737969
global_step: 26634, epoch: 66, loss: 0.792949
global_step: 26635, epoch: 66, loss: 0.821194
global_step: 26636, epoch: 66, loss: 0.732390
global_step: 26637, epoch: 66, loss: 0.687707
global_step: 26638, epoch: 66, loss: 0.950623
global_step: 26639, epoch: 66, loss: 0.894312
global_step: 26640, epoch: 66, loss: 0.396655
epoch: 66
train	acc: 0.7805	macro: p 0.5248, r 0.5065, f1: 0.5096	micro: p 0.7805, r 0.7805, f1 0.7805	weighted_f1:0.7507
dev	acc: 0.5879	macro: p 0.3825, r 0.3488, f1: 0.3465	micro: p 0.5879, r 0.5879, f1 0.5879	weighted_f1:0.5412
test	acc: 0.6230	macro: p 0.3881, r 0.3475, f1: 0.3512	micro: p 0.6230, r 0.6230, f1 0.6230	weighted_f1:0.5832
global_step: 26641, epoch: 67, loss: 0.839438
global_step: 26642, epoch: 67, loss: 0.615286
global_step: 26643, epoch: 67, loss: 0.718697
global_step: 26644, epoch: 67, loss: 0.746400
global_step: 26645, epoch: 67, loss: 0.809021
global_step: 26646, epoch: 67, loss: 0.784850
global_step: 26647, epoch: 67, loss: 0.815686
global_step: 26648, epoch: 67, loss: 0.749421
global_step: 26649, epoch: 67, loss: 0.858100
global_step: 26650, epoch: 67, loss: 0.826668
global_step: 26651, epoch: 67, loss: 0.792705
global_step: 26652, epoch: 67, loss: 0.842393
global_step: 26653, epoch: 67, loss: 0.802893
global_step: 26654, epoch: 67, loss: 0.708718
global_step: 26655, epoch: 67, loss: 0.762378
global_step: 26656, epoch: 67, loss: 0.723284
global_step: 26657, epoch: 67, loss: 0.710921
global_step: 26658, epoch: 67, loss: 0.785815
global_step: 26659, epoch: 67, loss: 0.806101
global_step: 26660, epoch: 67, loss: 0.710577
global_step: 26661, epoch: 67, loss: 0.773204
global_step: 26662, epoch: 67, loss: 0.876755
global_step: 26663, epoch: 67, loss: 0.863394
global_step: 26664, epoch: 67, loss: 0.785514
global_step: 26665, epoch: 67, loss: 0.837534
global_step: 26666, epoch: 67, loss: 0.752231
global_step: 26667, epoch: 67, loss: 0.879896
global_step: 26668, epoch: 67, loss: 0.861221
global_step: 26669, epoch: 67, loss: 0.770671
global_step: 26670, epoch: 67, loss: 0.778511
global_step: 26671, epoch: 67, loss: 0.718881
global_step: 26672, epoch: 67, loss: 0.678106
global_step: 26673, epoch: 67, loss: 0.800199
global_step: 26674, epoch: 67, loss: 0.809375
global_step: 26675, epoch: 67, loss: 0.802846
global_step: 26676, epoch: 67, loss: 0.816401
global_step: 26677, epoch: 67, loss: 0.783817
global_step: 26678, epoch: 67, loss: 0.719373
global_step: 26679, epoch: 67, loss: 0.822482
global_step: 26680, epoch: 67, loss: 0.776781
epoch: 67
train	acc: 0.7966	macro: p 0.5220, r 0.5415, f1: 0.5282	micro: p 0.7966, r 0.7966, f1 0.7966	weighted_f1:0.7749
dev	acc: 0.5690	macro: p 0.3526, r 0.3554, f1: 0.3454	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5387
test	acc: 0.6004	macro: p 0.3655, r 0.3629, f1: 0.3563	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5792
global_step: 26681, epoch: 68, loss: 0.694705
global_step: 26682, epoch: 68, loss: 0.697738
global_step: 26683, epoch: 68, loss: 0.891990
global_step: 26684, epoch: 68, loss: 0.788553
global_step: 26685, epoch: 68, loss: 0.720998
global_step: 26686, epoch: 68, loss: 0.752809
global_step: 26687, epoch: 68, loss: 0.665526
global_step: 26688, epoch: 68, loss: 0.835321
global_step: 26689, epoch: 68, loss: 0.805277
global_step: 26690, epoch: 68, loss: 0.703963
global_step: 26691, epoch: 68, loss: 0.848221
global_step: 26692, epoch: 68, loss: 0.737177
global_step: 26693, epoch: 68, loss: 0.714494
global_step: 26694, epoch: 68, loss: 0.779934
global_step: 26695, epoch: 68, loss: 0.801599
global_step: 26696, epoch: 68, loss: 0.694347
global_step: 26697, epoch: 68, loss: 0.784227
global_step: 26698, epoch: 68, loss: 0.670980
global_step: 26699, epoch: 68, loss: 0.904725
global_step: 26700, epoch: 68, loss: 0.802875
global_step: 26701, epoch: 68, loss: 0.844023
global_step: 26702, epoch: 68, loss: 0.805949
global_step: 26703, epoch: 68, loss: 0.754187
global_step: 26704, epoch: 68, loss: 0.754932
global_step: 26705, epoch: 68, loss: 0.775445
global_step: 26706, epoch: 68, loss: 0.794238
global_step: 26707, epoch: 68, loss: 0.837907
global_step: 26708, epoch: 68, loss: 0.813397
global_step: 26709, epoch: 68, loss: 0.868528
global_step: 26710, epoch: 68, loss: 0.857044
global_step: 26711, epoch: 68, loss: 0.738453
global_step: 26712, epoch: 68, loss: 0.835749
global_step: 26713, epoch: 68, loss: 0.843750
global_step: 26714, epoch: 68, loss: 0.856271
global_step: 26715, epoch: 68, loss: 0.690459
global_step: 26716, epoch: 68, loss: 0.782335
global_step: 26717, epoch: 68, loss: 0.872939
global_step: 26718, epoch: 68, loss: 0.747545
global_step: 26719, epoch: 68, loss: 0.736647
global_step: 26720, epoch: 68, loss: 0.343856
epoch: 68
train	acc: 0.7890	macro: p 0.5291, r 0.5142, f1: 0.5145	micro: p 0.7890, r 0.7890, f1 0.7890	weighted_f1:0.7586
dev	acc: 0.5816	macro: p 0.3824, r 0.3463, f1: 0.3410	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5343
test	acc: 0.6169	macro: p 0.3799, r 0.3469, f1: 0.3461	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5782
global_step: 26721, epoch: 69, loss: 0.666208
global_step: 26722, epoch: 69, loss: 0.737074
global_step: 26723, epoch: 69, loss: 0.776701
global_step: 26724, epoch: 69, loss: 0.842574
global_step: 26725, epoch: 69, loss: 0.674534
global_step: 26726, epoch: 69, loss: 0.850864
global_step: 26727, epoch: 69, loss: 0.787914
global_step: 26728, epoch: 69, loss: 0.861227
global_step: 26729, epoch: 69, loss: 0.766011
global_step: 26730, epoch: 69, loss: 0.689134
global_step: 26731, epoch: 69, loss: 0.787493
global_step: 26732, epoch: 69, loss: 0.780041
global_step: 26733, epoch: 69, loss: 0.729937
global_step: 26734, epoch: 69, loss: 0.781011
global_step: 26735, epoch: 69, loss: 0.746869
global_step: 26736, epoch: 69, loss: 0.713487
global_step: 26737, epoch: 69, loss: 0.739709
global_step: 26738, epoch: 69, loss: 0.774109
global_step: 26739, epoch: 69, loss: 0.751128
global_step: 26740, epoch: 69, loss: 0.875243
global_step: 26741, epoch: 69, loss: 0.707062
global_step: 26742, epoch: 69, loss: 0.855524
global_step: 26743, epoch: 69, loss: 0.788667
global_step: 26744, epoch: 69, loss: 0.757930
global_step: 26745, epoch: 69, loss: 0.758229
global_step: 26746, epoch: 69, loss: 0.842284
global_step: 26747, epoch: 69, loss: 0.785360
global_step: 26748, epoch: 69, loss: 0.762053
global_step: 26749, epoch: 69, loss: 0.811978
global_step: 26750, epoch: 69, loss: 0.753115
global_step: 26751, epoch: 69, loss: 0.770684
global_step: 26752, epoch: 69, loss: 0.743809
global_step: 26753, epoch: 69, loss: 0.725457
global_step: 26754, epoch: 69, loss: 0.827303
global_step: 26755, epoch: 69, loss: 0.803560
global_step: 26756, epoch: 69, loss: 0.778043
global_step: 26757, epoch: 69, loss: 0.874981
global_step: 26758, epoch: 69, loss: 0.774162
global_step: 26759, epoch: 69, loss: 0.690562
global_step: 26760, epoch: 69, loss: 0.356878
epoch: 69
train	acc: 0.7726	macro: p 0.6764, r 0.4927, f1: 0.5051	micro: p 0.7726, r 0.7726, f1 0.7726	weighted_f1:0.7415
dev	acc: 0.5807	macro: p 0.3960, r 0.3329, f1: 0.3372	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5298
test	acc: 0.6211	macro: p 0.3924, r 0.3332, f1: 0.3428	micro: p 0.6211, r 0.6211, f1 0.6211	weighted_f1:0.5754
global_step: 26761, epoch: 70, loss: 0.782830
global_step: 26762, epoch: 70, loss: 0.768612
global_step: 26763, epoch: 70, loss: 0.688755
global_step: 26764, epoch: 70, loss: 0.761477
global_step: 26765, epoch: 70, loss: 0.689928
global_step: 26766, epoch: 70, loss: 0.755569
global_step: 26767, epoch: 70, loss: 0.728264
global_step: 26768, epoch: 70, loss: 0.732028
global_step: 26769, epoch: 70, loss: 0.691839
global_step: 26770, epoch: 70, loss: 0.752642
global_step: 26771, epoch: 70, loss: 0.771435
global_step: 26772, epoch: 70, loss: 0.733100
global_step: 26773, epoch: 70, loss: 0.753583
global_step: 26774, epoch: 70, loss: 0.836412
global_step: 26775, epoch: 70, loss: 0.779723
global_step: 26776, epoch: 70, loss: 0.795009
global_step: 26777, epoch: 70, loss: 0.821615
global_step: 26778, epoch: 70, loss: 0.688722
global_step: 26779, epoch: 70, loss: 0.763540
global_step: 26780, epoch: 70, loss: 0.837646
global_step: 26781, epoch: 70, loss: 0.774375
global_step: 26782, epoch: 70, loss: 0.745601
global_step: 26783, epoch: 70, loss: 0.839552
global_step: 26784, epoch: 70, loss: 0.753733
global_step: 26785, epoch: 70, loss: 0.789867
global_step: 26786, epoch: 70, loss: 0.690169
global_step: 26787, epoch: 70, loss: 0.784397
global_step: 26788, epoch: 70, loss: 0.777047
global_step: 26789, epoch: 70, loss: 0.761730
global_step: 26790, epoch: 70, loss: 0.752586
global_step: 26791, epoch: 70, loss: 0.825300
global_step: 26792, epoch: 70, loss: 0.860639
global_step: 26793, epoch: 70, loss: 0.759553
global_step: 26794, epoch: 70, loss: 0.772203
global_step: 26795, epoch: 70, loss: 0.709107
global_step: 26796, epoch: 70, loss: 0.678521
global_step: 26797, epoch: 70, loss: 0.869988
global_step: 26798, epoch: 70, loss: 0.787041
global_step: 26799, epoch: 70, loss: 0.737219
global_step: 26800, epoch: 70, loss: 0.635031
epoch: 70
train	acc: 0.8079	macro: p 0.5301, r 0.5487, f1: 0.5361	micro: p 0.8079, r 0.8079, f1 0.8079	weighted_f1:0.7835
dev	acc: 0.5744	macro: p 0.3652, r 0.3578, f1: 0.3480	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5394
test	acc: 0.6061	macro: p 0.3676, r 0.3661, f1: 0.3571	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5817
global_step: 26801, epoch: 71, loss: 0.856938
global_step: 26802, epoch: 71, loss: 0.750658
global_step: 26803, epoch: 71, loss: 0.703599
global_step: 26804, epoch: 71, loss: 0.786539
global_step: 26805, epoch: 71, loss: 0.730991
global_step: 26806, epoch: 71, loss: 0.678096
global_step: 26807, epoch: 71, loss: 0.682452
global_step: 26808, epoch: 71, loss: 0.833768
global_step: 26809, epoch: 71, loss: 0.803188
global_step: 26810, epoch: 71, loss: 0.781919
global_step: 26811, epoch: 71, loss: 0.822028
global_step: 26812, epoch: 71, loss: 0.763993
global_step: 26813, epoch: 71, loss: 0.753446
global_step: 26814, epoch: 71, loss: 0.662801
global_step: 26815, epoch: 71, loss: 0.749279
global_step: 26816, epoch: 71, loss: 0.690226
global_step: 26817, epoch: 71, loss: 0.841910
global_step: 26818, epoch: 71, loss: 0.874855
global_step: 26819, epoch: 71, loss: 0.799984
global_step: 26820, epoch: 71, loss: 0.661508
global_step: 26821, epoch: 71, loss: 0.786808
global_step: 26822, epoch: 71, loss: 0.710144
global_step: 26823, epoch: 71, loss: 0.671840
global_step: 26824, epoch: 71, loss: 0.762064
global_step: 26825, epoch: 71, loss: 0.768685
global_step: 26826, epoch: 71, loss: 0.773104
global_step: 26827, epoch: 71, loss: 0.764168
global_step: 26828, epoch: 71, loss: 0.722135
global_step: 26829, epoch: 71, loss: 0.847913
global_step: 26830, epoch: 71, loss: 0.626504
global_step: 26831, epoch: 71, loss: 0.702391
global_step: 26832, epoch: 71, loss: 0.655266
global_step: 26833, epoch: 71, loss: 0.762236
global_step: 26834, epoch: 71, loss: 0.811665
global_step: 26835, epoch: 71, loss: 0.910382
global_step: 26836, epoch: 71, loss: 0.730471
global_step: 26837, epoch: 71, loss: 0.778399
global_step: 26838, epoch: 71, loss: 0.750798
global_step: 26839, epoch: 71, loss: 0.791419
global_step: 26840, epoch: 71, loss: 0.671560
epoch: 71
train	acc: 0.8010	macro: p 0.5411, r 0.5319, f1: 0.5310	micro: p 0.8010, r 0.8010, f1 0.8010	weighted_f1:0.7728
dev	acc: 0.5816	macro: p 0.3821, r 0.3468, f1: 0.3477	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5385
test	acc: 0.6272	macro: p 0.3892, r 0.3563, f1: 0.3599	micro: p 0.6272, r 0.6272, f1 0.6272	weighted_f1:0.5906
global_step: 26841, epoch: 72, loss: 0.781069
global_step: 26842, epoch: 72, loss: 0.668164
global_step: 26843, epoch: 72, loss: 0.786048
global_step: 26844, epoch: 72, loss: 0.669478
global_step: 26845, epoch: 72, loss: 0.651478
global_step: 26846, epoch: 72, loss: 0.700951
global_step: 26847, epoch: 72, loss: 0.783193
global_step: 26848, epoch: 72, loss: 0.730561
global_step: 26849, epoch: 72, loss: 0.703976
global_step: 26850, epoch: 72, loss: 0.719251
global_step: 26851, epoch: 72, loss: 0.733923
global_step: 26852, epoch: 72, loss: 0.785118
global_step: 26853, epoch: 72, loss: 0.764340
global_step: 26854, epoch: 72, loss: 0.721736
global_step: 26855, epoch: 72, loss: 0.808095
global_step: 26856, epoch: 72, loss: 0.655899
global_step: 26857, epoch: 72, loss: 0.637764
global_step: 26858, epoch: 72, loss: 0.629542
global_step: 26859, epoch: 72, loss: 0.651962
global_step: 26860, epoch: 72, loss: 0.636729
global_step: 26861, epoch: 72, loss: 0.752758
global_step: 26862, epoch: 72, loss: 0.729034
global_step: 26863, epoch: 72, loss: 0.714102
global_step: 26864, epoch: 72, loss: 0.706958
global_step: 26865, epoch: 72, loss: 0.795243
global_step: 26866, epoch: 72, loss: 0.703867
global_step: 26867, epoch: 72, loss: 0.797923
global_step: 26868, epoch: 72, loss: 0.788473
global_step: 26869, epoch: 72, loss: 0.686809
global_step: 26870, epoch: 72, loss: 0.708334
global_step: 26871, epoch: 72, loss: 0.788945
global_step: 26872, epoch: 72, loss: 0.921033
global_step: 26873, epoch: 72, loss: 0.842562
global_step: 26874, epoch: 72, loss: 0.834420
global_step: 26875, epoch: 72, loss: 0.695682
global_step: 26876, epoch: 72, loss: 0.685139
global_step: 26877, epoch: 72, loss: 0.795063
global_step: 26878, epoch: 72, loss: 0.801810
global_step: 26879, epoch: 72, loss: 0.713513
global_step: 26880, epoch: 72, loss: 0.139592
epoch: 72
train	acc: 0.7715	macro: p 0.5342, r 0.4926, f1: 0.5065	micro: p 0.7715, r 0.7715, f1 0.7715	weighted_f1:0.7408
dev	acc: 0.5726	macro: p 0.3900, r 0.3236, f1: 0.3286	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5194
test	acc: 0.6146	macro: p 0.3859, r 0.3254, f1: 0.3352	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5669
global_step: 26881, epoch: 73, loss: 0.754217
global_step: 26882, epoch: 73, loss: 0.778692
global_step: 26883, epoch: 73, loss: 0.736089
global_step: 26884, epoch: 73, loss: 0.639618
global_step: 26885, epoch: 73, loss: 0.755386
global_step: 26886, epoch: 73, loss: 0.756802
global_step: 26887, epoch: 73, loss: 0.650247
global_step: 26888, epoch: 73, loss: 0.683297
global_step: 26889, epoch: 73, loss: 0.757251
global_step: 26890, epoch: 73, loss: 0.730027
global_step: 26891, epoch: 73, loss: 0.743040
global_step: 26892, epoch: 73, loss: 0.708405
global_step: 26893, epoch: 73, loss: 0.706212
global_step: 26894, epoch: 73, loss: 0.735542
global_step: 26895, epoch: 73, loss: 0.740915
global_step: 26896, epoch: 73, loss: 0.729525
global_step: 26897, epoch: 73, loss: 0.830207
global_step: 26898, epoch: 73, loss: 0.769778
global_step: 26899, epoch: 73, loss: 0.724834
global_step: 26900, epoch: 73, loss: 0.692719
global_step: 26901, epoch: 73, loss: 0.852145
global_step: 26902, epoch: 73, loss: 0.740574
global_step: 26903, epoch: 73, loss: 0.711485
global_step: 26904, epoch: 73, loss: 0.811917
global_step: 26905, epoch: 73, loss: 0.842597
global_step: 26906, epoch: 73, loss: 0.744393
global_step: 26907, epoch: 73, loss: 0.790705
global_step: 26908, epoch: 73, loss: 0.739870
global_step: 26909, epoch: 73, loss: 0.653411
global_step: 26910, epoch: 73, loss: 0.801094
global_step: 26911, epoch: 73, loss: 0.699444
global_step: 26912, epoch: 73, loss: 0.694289
global_step: 26913, epoch: 73, loss: 0.668010
global_step: 26914, epoch: 73, loss: 0.601149
global_step: 26915, epoch: 73, loss: 0.731879
global_step: 26916, epoch: 73, loss: 0.768366
global_step: 26917, epoch: 73, loss: 0.736687
global_step: 26918, epoch: 73, loss: 0.652040
global_step: 26919, epoch: 73, loss: 0.768144
global_step: 26920, epoch: 73, loss: 0.334931
epoch: 73
train	acc: 0.7824	macro: p 0.6885, r 0.4981, f1: 0.5067	micro: p 0.7824, r 0.7824, f1 0.7824	weighted_f1:0.7484
dev	acc: 0.5744	macro: p 0.4003, r 0.3262, f1: 0.3255	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5187
test	acc: 0.6188	macro: p 0.3969, r 0.3308, f1: 0.3353	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5707
global_step: 26921, epoch: 74, loss: 0.703171
global_step: 26922, epoch: 74, loss: 0.764122
global_step: 26923, epoch: 74, loss: 0.655773
global_step: 26924, epoch: 74, loss: 0.745967
global_step: 26925, epoch: 74, loss: 0.782283
global_step: 26926, epoch: 74, loss: 0.722393
global_step: 26927, epoch: 74, loss: 0.704917
global_step: 26928, epoch: 74, loss: 0.667229
global_step: 26929, epoch: 74, loss: 0.688408
global_step: 26930, epoch: 74, loss: 0.615286
global_step: 26931, epoch: 74, loss: 0.766056
global_step: 26932, epoch: 74, loss: 0.678558
global_step: 26933, epoch: 74, loss: 0.699840
global_step: 26934, epoch: 74, loss: 0.814192
global_step: 26935, epoch: 74, loss: 0.734034
global_step: 26936, epoch: 74, loss: 0.650418
global_step: 26937, epoch: 74, loss: 0.695693
global_step: 26938, epoch: 74, loss: 0.628164
global_step: 26939, epoch: 74, loss: 0.841549
global_step: 26940, epoch: 74, loss: 0.604576
global_step: 26941, epoch: 74, loss: 0.734683
global_step: 26942, epoch: 74, loss: 0.776237
global_step: 26943, epoch: 74, loss: 0.805349
global_step: 26944, epoch: 74, loss: 0.695056
global_step: 26945, epoch: 74, loss: 0.868245
global_step: 26946, epoch: 74, loss: 0.736755
global_step: 26947, epoch: 74, loss: 0.687560
global_step: 26948, epoch: 74, loss: 0.681515
global_step: 26949, epoch: 74, loss: 0.686949
global_step: 26950, epoch: 74, loss: 0.816075
global_step: 26951, epoch: 74, loss: 0.706387
global_step: 26952, epoch: 74, loss: 0.703439
global_step: 26953, epoch: 74, loss: 0.737399
global_step: 26954, epoch: 74, loss: 0.748151
global_step: 26955, epoch: 74, loss: 0.715538
global_step: 26956, epoch: 74, loss: 0.621761
global_step: 26957, epoch: 74, loss: 0.685987
global_step: 26958, epoch: 74, loss: 0.728154
global_step: 26959, epoch: 74, loss: 0.839809
global_step: 26960, epoch: 74, loss: 0.393981
epoch: 74
train	acc: 0.8258	macro: p 0.6943, r 0.5732, f1: 0.5598	micro: p 0.8258, r 0.8258, f1 0.8258	weighted_f1:0.8034
dev	acc: 0.5780	macro: p 0.3597, r 0.3568, f1: 0.3492	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5431
test	acc: 0.6149	macro: p 0.3741, r 0.3742, f1: 0.3664	micro: p 0.6149, r 0.6149, f1 0.6149	weighted_f1:0.5918
global_step: 26961, epoch: 75, loss: 0.800559
global_step: 26962, epoch: 75, loss: 0.729286
global_step: 26963, epoch: 75, loss: 0.670129
global_step: 26964, epoch: 75, loss: 0.759309
global_step: 26965, epoch: 75, loss: 0.707260
global_step: 26966, epoch: 75, loss: 0.674650
global_step: 26967, epoch: 75, loss: 0.698672
global_step: 26968, epoch: 75, loss: 0.704277
global_step: 26969, epoch: 75, loss: 0.757898
global_step: 26970, epoch: 75, loss: 0.674385
global_step: 26971, epoch: 75, loss: 0.770471
global_step: 26972, epoch: 75, loss: 0.759055
global_step: 26973, epoch: 75, loss: 0.881749
global_step: 26974, epoch: 75, loss: 0.677392
global_step: 26975, epoch: 75, loss: 0.720891
global_step: 26976, epoch: 75, loss: 0.714531
global_step: 26977, epoch: 75, loss: 0.726248
global_step: 26978, epoch: 75, loss: 0.805274
global_step: 26979, epoch: 75, loss: 0.743896
global_step: 26980, epoch: 75, loss: 0.799157
global_step: 26981, epoch: 75, loss: 0.823790
global_step: 26982, epoch: 75, loss: 0.664720
global_step: 26983, epoch: 75, loss: 0.672054
global_step: 26984, epoch: 75, loss: 0.709954
global_step: 26985, epoch: 75, loss: 0.710654
global_step: 26986, epoch: 75, loss: 0.707968
global_step: 26987, epoch: 75, loss: 0.803061
global_step: 26988, epoch: 75, loss: 0.732889
global_step: 26989, epoch: 75, loss: 0.689835
global_step: 26990, epoch: 75, loss: 0.679986
global_step: 26991, epoch: 75, loss: 0.656105
global_step: 26992, epoch: 75, loss: 0.676234
global_step: 26993, epoch: 75, loss: 0.767411
global_step: 26994, epoch: 75, loss: 0.682094
global_step: 26995, epoch: 75, loss: 0.701260
global_step: 26996, epoch: 75, loss: 0.687388
global_step: 26997, epoch: 75, loss: 0.727721
global_step: 26998, epoch: 75, loss: 0.722006
global_step: 26999, epoch: 75, loss: 0.701273
global_step: 27000, epoch: 75, loss: 0.700148
epoch: 75
train	acc: 0.8159	macro: p 0.6923, r 0.5604, f1: 0.5555	micro: p 0.8159, r 0.8159, f1 0.8159	weighted_f1:0.7921
dev	acc: 0.5780	macro: p 0.3721, r 0.3439, f1: 0.3479	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5384
test	acc: 0.6195	macro: p 0.3774, r 0.3509, f1: 0.3581	micro: p 0.6195, r 0.6195, f1 0.6195	weighted_f1:0.5867
global_step: 27001, epoch: 76, loss: 0.716605
global_step: 27002, epoch: 76, loss: 0.712914
global_step: 27003, epoch: 76, loss: 0.636598
global_step: 27004, epoch: 76, loss: 0.721037
global_step: 27005, epoch: 76, loss: 0.678044
global_step: 27006, epoch: 76, loss: 0.632367
global_step: 27007, epoch: 76, loss: 0.827386
global_step: 27008, epoch: 76, loss: 0.699290
global_step: 27009, epoch: 76, loss: 0.620268
global_step: 27010, epoch: 76, loss: 0.764568
global_step: 27011, epoch: 76, loss: 0.684793
global_step: 27012, epoch: 76, loss: 0.678898
global_step: 27013, epoch: 76, loss: 0.712248
global_step: 27014, epoch: 76, loss: 0.728547
global_step: 27015, epoch: 76, loss: 0.691145
global_step: 27016, epoch: 76, loss: 0.620091
global_step: 27017, epoch: 76, loss: 0.690295
global_step: 27018, epoch: 76, loss: 0.703880
global_step: 27019, epoch: 76, loss: 0.668103
global_step: 27020, epoch: 76, loss: 0.603196
global_step: 27021, epoch: 76, loss: 0.701188
global_step: 27022, epoch: 76, loss: 0.697502
global_step: 27023, epoch: 76, loss: 0.788590
global_step: 27024, epoch: 76, loss: 0.658438
global_step: 27025, epoch: 76, loss: 0.705695
global_step: 27026, epoch: 76, loss: 0.714410
global_step: 27027, epoch: 76, loss: 0.580696
global_step: 27028, epoch: 76, loss: 0.709247
global_step: 27029, epoch: 76, loss: 0.706994
global_step: 27030, epoch: 76, loss: 0.725225
global_step: 27031, epoch: 76, loss: 0.736285
global_step: 27032, epoch: 76, loss: 0.798898
global_step: 27033, epoch: 76, loss: 0.721856
global_step: 27034, epoch: 76, loss: 0.643135
global_step: 27035, epoch: 76, loss: 0.807935
global_step: 27036, epoch: 76, loss: 0.715020
global_step: 27037, epoch: 76, loss: 0.617344
global_step: 27038, epoch: 76, loss: 0.818683
global_step: 27039, epoch: 76, loss: 0.771347
global_step: 27040, epoch: 76, loss: 0.192670
epoch: 76
train	acc: 0.8171	macro: p 0.7031, r 0.5529, f1: 0.5532	micro: p 0.8171, r 0.8171, f1 0.8171	weighted_f1:0.7903
dev	acc: 0.5780	macro: p 0.3839, r 0.3413, f1: 0.3442	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5335
test	acc: 0.6253	macro: p 0.3928, r 0.3535, f1: 0.3586	micro: p 0.6253, r 0.6253, f1 0.6253	weighted_f1:0.5884
global_step: 27041, epoch: 77, loss: 0.681475
global_step: 27042, epoch: 77, loss: 0.707084
global_step: 27043, epoch: 77, loss: 0.772460
global_step: 27044, epoch: 77, loss: 0.734120
global_step: 27045, epoch: 77, loss: 0.767001
global_step: 27046, epoch: 77, loss: 0.698023
global_step: 27047, epoch: 77, loss: 0.707406
global_step: 27048, epoch: 77, loss: 0.742465
global_step: 27049, epoch: 77, loss: 0.692336
global_step: 27050, epoch: 77, loss: 0.717772
global_step: 27051, epoch: 77, loss: 0.736943
global_step: 27052, epoch: 77, loss: 0.632465
global_step: 27053, epoch: 77, loss: 0.743980
global_step: 27054, epoch: 77, loss: 0.657947
global_step: 27055, epoch: 77, loss: 0.719997
global_step: 27056, epoch: 77, loss: 0.664426
global_step: 27057, epoch: 77, loss: 0.631496
global_step: 27058, epoch: 77, loss: 0.641470
global_step: 27059, epoch: 77, loss: 0.580123
global_step: 27060, epoch: 77, loss: 0.625855
global_step: 27061, epoch: 77, loss: 0.670004
global_step: 27062, epoch: 77, loss: 0.695043
global_step: 27063, epoch: 77, loss: 0.725508
global_step: 27064, epoch: 77, loss: 0.705278
global_step: 27065, epoch: 77, loss: 0.629804
global_step: 27066, epoch: 77, loss: 0.765049
global_step: 27067, epoch: 77, loss: 0.701544
global_step: 27068, epoch: 77, loss: 0.779383
global_step: 27069, epoch: 77, loss: 0.772300
global_step: 27070, epoch: 77, loss: 0.689259
global_step: 27071, epoch: 77, loss: 0.722366
global_step: 27072, epoch: 77, loss: 0.776364
global_step: 27073, epoch: 77, loss: 0.702596
global_step: 27074, epoch: 77, loss: 0.643349
global_step: 27075, epoch: 77, loss: 0.685069
global_step: 27076, epoch: 77, loss: 0.669023
global_step: 27077, epoch: 77, loss: 0.739843
global_step: 27078, epoch: 77, loss: 0.547179
global_step: 27079, epoch: 77, loss: 0.673757
global_step: 27080, epoch: 77, loss: 0.755122
epoch: 77
train	acc: 0.8052	macro: p 0.6775, r 0.5368, f1: 0.5454	micro: p 0.8052, r 0.8052, f1 0.8052	weighted_f1:0.7778
dev	acc: 0.5780	macro: p 0.3933, r 0.3368, f1: 0.3420	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5311
test	acc: 0.6215	macro: p 0.3920, r 0.3396, f1: 0.3491	micro: p 0.6215, r 0.6215, f1 0.6215	weighted_f1:0.5794
global_step: 27081, epoch: 78, loss: 0.644374
global_step: 27082, epoch: 78, loss: 0.710664
global_step: 27083, epoch: 78, loss: 0.628982
global_step: 27084, epoch: 78, loss: 0.748555
global_step: 27085, epoch: 78, loss: 0.661871
global_step: 27086, epoch: 78, loss: 0.590981
global_step: 27087, epoch: 78, loss: 0.666289
global_step: 27088, epoch: 78, loss: 0.553885
global_step: 27089, epoch: 78, loss: 0.708041
global_step: 27090, epoch: 78, loss: 0.699210
global_step: 27091, epoch: 78, loss: 0.724261
global_step: 27092, epoch: 78, loss: 0.726962
global_step: 27093, epoch: 78, loss: 0.665654
global_step: 27094, epoch: 78, loss: 0.701787
global_step: 27095, epoch: 78, loss: 0.705367
global_step: 27096, epoch: 78, loss: 0.682741
global_step: 27097, epoch: 78, loss: 0.670432
global_step: 27098, epoch: 78, loss: 0.762251
global_step: 27099, epoch: 78, loss: 0.619577
global_step: 27100, epoch: 78, loss: 0.631552
global_step: 27101, epoch: 78, loss: 0.712981
global_step: 27102, epoch: 78, loss: 0.708594
global_step: 27103, epoch: 78, loss: 0.755323
global_step: 27104, epoch: 78, loss: 0.664591
global_step: 27105, epoch: 78, loss: 0.692279
global_step: 27106, epoch: 78, loss: 0.645703
global_step: 27107, epoch: 78, loss: 0.639493
global_step: 27108, epoch: 78, loss: 0.691552
global_step: 27109, epoch: 78, loss: 0.687943
global_step: 27110, epoch: 78, loss: 0.716888
global_step: 27111, epoch: 78, loss: 0.740548
global_step: 27112, epoch: 78, loss: 0.751086
global_step: 27113, epoch: 78, loss: 0.661866
global_step: 27114, epoch: 78, loss: 0.715153
global_step: 27115, epoch: 78, loss: 0.689140
global_step: 27116, epoch: 78, loss: 0.776252
global_step: 27117, epoch: 78, loss: 0.733038
global_step: 27118, epoch: 78, loss: 0.689460
global_step: 27119, epoch: 78, loss: 0.698599
global_step: 27120, epoch: 78, loss: 1.075218
epoch: 78
train	acc: 0.8246	macro: p 0.6845, r 0.5702, f1: 0.5742	micro: p 0.8246, r 0.8246, f1 0.8246	weighted_f1:0.8006
dev	acc: 0.5762	macro: p 0.3766, r 0.3406, f1: 0.3460	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5331
test	acc: 0.6157	macro: p 0.3793, r 0.3404, f1: 0.3504	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5770
global_step: 27121, epoch: 79, loss: 0.668825
global_step: 27122, epoch: 79, loss: 0.666736
global_step: 27123, epoch: 79, loss: 0.599293
global_step: 27124, epoch: 79, loss: 0.778203
global_step: 27125, epoch: 79, loss: 0.666805
global_step: 27126, epoch: 79, loss: 0.632239
global_step: 27127, epoch: 79, loss: 0.680929
global_step: 27128, epoch: 79, loss: 0.737305
global_step: 27129, epoch: 79, loss: 0.665160
global_step: 27130, epoch: 79, loss: 0.671915
global_step: 27131, epoch: 79, loss: 0.711926
global_step: 27132, epoch: 79, loss: 0.652109
global_step: 27133, epoch: 79, loss: 0.782965
global_step: 27134, epoch: 79, loss: 0.704110
global_step: 27135, epoch: 79, loss: 0.760895
global_step: 27136, epoch: 79, loss: 0.656941
global_step: 27137, epoch: 79, loss: 0.564604
global_step: 27138, epoch: 79, loss: 0.676480
global_step: 27139, epoch: 79, loss: 0.677867
global_step: 27140, epoch: 79, loss: 0.622258
global_step: 27141, epoch: 79, loss: 0.696127
global_step: 27142, epoch: 79, loss: 0.754645
global_step: 27143, epoch: 79, loss: 0.728658
global_step: 27144, epoch: 79, loss: 0.611906
global_step: 27145, epoch: 79, loss: 0.713347
global_step: 27146, epoch: 79, loss: 0.661635
global_step: 27147, epoch: 79, loss: 0.680909
global_step: 27148, epoch: 79, loss: 0.773536
global_step: 27149, epoch: 79, loss: 0.628420
global_step: 27150, epoch: 79, loss: 0.640978
global_step: 27151, epoch: 79, loss: 0.616549
global_step: 27152, epoch: 79, loss: 0.642638
global_step: 27153, epoch: 79, loss: 0.679706
global_step: 27154, epoch: 79, loss: 0.694099
global_step: 27155, epoch: 79, loss: 0.632666
global_step: 27156, epoch: 79, loss: 0.622542
global_step: 27157, epoch: 79, loss: 0.767439
global_step: 27158, epoch: 79, loss: 0.635623
global_step: 27159, epoch: 79, loss: 0.746251
global_step: 27160, epoch: 79, loss: 0.383230
epoch: 79
train	acc: 0.8407	macro: p 0.6884, r 0.5915, f1: 0.5809	micro: p 0.8407, r 0.8407, f1 0.8407	weighted_f1:0.8179
dev	acc: 0.5735	macro: p 0.3559, r 0.3512, f1: 0.3452	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5371
test	acc: 0.6092	macro: p 0.3638, r 0.3629, f1: 0.3579	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5837
global_step: 27161, epoch: 80, loss: 0.604442
global_step: 27162, epoch: 80, loss: 0.577176
global_step: 27163, epoch: 80, loss: 0.670027
global_step: 27164, epoch: 80, loss: 0.572242
global_step: 27165, epoch: 80, loss: 0.671012
global_step: 27166, epoch: 80, loss: 0.640477
global_step: 27167, epoch: 80, loss: 0.702400
global_step: 27168, epoch: 80, loss: 0.649650
global_step: 27169, epoch: 80, loss: 0.809567
global_step: 27170, epoch: 80, loss: 0.690783
global_step: 27171, epoch: 80, loss: 0.703557
global_step: 27172, epoch: 80, loss: 0.605583
global_step: 27173, epoch: 80, loss: 0.732289
global_step: 27174, epoch: 80, loss: 0.662075
global_step: 27175, epoch: 80, loss: 0.744148
global_step: 27176, epoch: 80, loss: 0.729372
global_step: 27177, epoch: 80, loss: 0.618421
global_step: 27178, epoch: 80, loss: 0.690644
global_step: 27179, epoch: 80, loss: 0.587857
global_step: 27180, epoch: 80, loss: 0.623144
global_step: 27181, epoch: 80, loss: 0.685874
global_step: 27182, epoch: 80, loss: 0.761663
global_step: 27183, epoch: 80, loss: 0.798517
global_step: 27184, epoch: 80, loss: 0.596202
global_step: 27185, epoch: 80, loss: 0.632444
global_step: 27186, epoch: 80, loss: 0.715659
global_step: 27187, epoch: 80, loss: 0.702460
global_step: 27188, epoch: 80, loss: 0.650891
global_step: 27189, epoch: 80, loss: 0.647069
global_step: 27190, epoch: 80, loss: 0.682887
global_step: 27191, epoch: 80, loss: 0.629621
global_step: 27192, epoch: 80, loss: 0.716045
global_step: 27193, epoch: 80, loss: 0.716661
global_step: 27194, epoch: 80, loss: 0.694366
global_step: 27195, epoch: 80, loss: 0.682995
global_step: 27196, epoch: 80, loss: 0.593976
global_step: 27197, epoch: 80, loss: 0.760014
global_step: 27198, epoch: 80, loss: 0.830261
global_step: 27199, epoch: 80, loss: 0.622951
global_step: 27200, epoch: 80, loss: 1.416107
epoch: 80
train	acc: 0.8494	macro: p 0.7089, r 0.6082, f1: 0.5921	micro: p 0.8494, r 0.8494, f1 0.8494	weighted_f1:0.8284
dev	acc: 0.5780	macro: p 0.3656, r 0.3617, f1: 0.3590	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5476
test	acc: 0.6115	macro: p 0.3687, r 0.3725, f1: 0.3690	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5914
global_step: 27201, epoch: 81, loss: 0.738982
global_step: 27202, epoch: 81, loss: 0.607989
global_step: 27203, epoch: 81, loss: 0.736283
global_step: 27204, epoch: 81, loss: 0.630720
global_step: 27205, epoch: 81, loss: 0.696853
global_step: 27206, epoch: 81, loss: 0.680464
global_step: 27207, epoch: 81, loss: 0.687945
global_step: 27208, epoch: 81, loss: 0.835099
global_step: 27209, epoch: 81, loss: 0.693094
global_step: 27210, epoch: 81, loss: 0.730611
global_step: 27211, epoch: 81, loss: 0.690499
global_step: 27212, epoch: 81, loss: 0.699604
global_step: 27213, epoch: 81, loss: 0.647889
global_step: 27214, epoch: 81, loss: 0.559974
global_step: 27215, epoch: 81, loss: 0.624042
global_step: 27216, epoch: 81, loss: 0.610714
global_step: 27217, epoch: 81, loss: 0.806924
global_step: 27218, epoch: 81, loss: 0.680165
global_step: 27219, epoch: 81, loss: 0.645627
global_step: 27220, epoch: 81, loss: 0.614872
global_step: 27221, epoch: 81, loss: 0.731069
global_step: 27222, epoch: 81, loss: 0.677425
global_step: 27223, epoch: 81, loss: 0.718187
global_step: 27224, epoch: 81, loss: 0.558993
global_step: 27225, epoch: 81, loss: 0.672395
global_step: 27226, epoch: 81, loss: 0.659590
global_step: 27227, epoch: 81, loss: 0.568991
global_step: 27228, epoch: 81, loss: 0.616561
global_step: 27229, epoch: 81, loss: 0.781849
global_step: 27230, epoch: 81, loss: 0.791413
global_step: 27231, epoch: 81, loss: 0.593798
global_step: 27232, epoch: 81, loss: 0.658464
global_step: 27233, epoch: 81, loss: 0.698183
global_step: 27234, epoch: 81, loss: 0.756171
global_step: 27235, epoch: 81, loss: 0.661430
global_step: 27236, epoch: 81, loss: 0.699390
global_step: 27237, epoch: 81, loss: 0.609038
global_step: 27238, epoch: 81, loss: 0.575024
global_step: 27239, epoch: 81, loss: 0.643865
global_step: 27240, epoch: 81, loss: 0.455728
epoch: 81
train	acc: 0.8161	macro: p 0.6925, r 0.5525, f1: 0.5624	micro: p 0.8161, r 0.8161, f1 0.8161	weighted_f1:0.7900
dev	acc: 0.5681	macro: p 0.3845, r 0.3263, f1: 0.3290	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5175
test	acc: 0.6138	macro: p 0.3836, r 0.3309, f1: 0.3395	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5697
global_step: 27241, epoch: 82, loss: 0.707281
global_step: 27242, epoch: 82, loss: 0.599112
global_step: 27243, epoch: 82, loss: 0.589529
global_step: 27244, epoch: 82, loss: 0.707990
global_step: 27245, epoch: 82, loss: 0.678111
global_step: 27246, epoch: 82, loss: 0.706976
global_step: 27247, epoch: 82, loss: 0.707725
global_step: 27248, epoch: 82, loss: 0.745935
global_step: 27249, epoch: 82, loss: 0.515814
global_step: 27250, epoch: 82, loss: 0.670456
global_step: 27251, epoch: 82, loss: 0.620694
global_step: 27252, epoch: 82, loss: 0.676594
global_step: 27253, epoch: 82, loss: 0.603327
global_step: 27254, epoch: 82, loss: 0.760969
global_step: 27255, epoch: 82, loss: 0.675445
global_step: 27256, epoch: 82, loss: 0.683511
global_step: 27257, epoch: 82, loss: 0.708907
global_step: 27258, epoch: 82, loss: 0.757909
global_step: 27259, epoch: 82, loss: 0.653424
global_step: 27260, epoch: 82, loss: 0.566763
global_step: 27261, epoch: 82, loss: 0.728032
global_step: 27262, epoch: 82, loss: 0.755479
global_step: 27263, epoch: 82, loss: 0.544599
global_step: 27264, epoch: 82, loss: 0.717349
global_step: 27265, epoch: 82, loss: 0.769701
global_step: 27266, epoch: 82, loss: 0.646973
global_step: 27267, epoch: 82, loss: 0.593520
global_step: 27268, epoch: 82, loss: 0.712344
global_step: 27269, epoch: 82, loss: 0.693509
global_step: 27270, epoch: 82, loss: 0.579817
global_step: 27271, epoch: 82, loss: 0.739604
global_step: 27272, epoch: 82, loss: 0.630568
global_step: 27273, epoch: 82, loss: 0.741695
global_step: 27274, epoch: 82, loss: 0.657985
global_step: 27275, epoch: 82, loss: 0.660794
global_step: 27276, epoch: 82, loss: 0.627625
global_step: 27277, epoch: 82, loss: 0.502206
global_step: 27278, epoch: 82, loss: 0.638159
global_step: 27279, epoch: 82, loss: 0.606867
global_step: 27280, epoch: 82, loss: 0.515184
epoch: 82
train	acc: 0.8339	macro: p 0.7004, r 0.5870, f1: 0.5860	micro: p 0.8339, r 0.8339, f1 0.8339	weighted_f1:0.8118
dev	acc: 0.5762	macro: p 0.3841, r 0.3409, f1: 0.3480	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5359
test	acc: 0.6230	macro: p 0.4558, r 0.3515, f1: 0.3623	micro: p 0.6230, r 0.6230, f1 0.6230	weighted_f1:0.5881
global_step: 27281, epoch: 83, loss: 0.594370
global_step: 27282, epoch: 83, loss: 0.656155
global_step: 27283, epoch: 83, loss: 0.637036
global_step: 27284, epoch: 83, loss: 0.589714
global_step: 27285, epoch: 83, loss: 0.662618
global_step: 27286, epoch: 83, loss: 0.619601
global_step: 27287, epoch: 83, loss: 0.762270
global_step: 27288, epoch: 83, loss: 0.620381
global_step: 27289, epoch: 83, loss: 0.648817
global_step: 27290, epoch: 83, loss: 0.575649
global_step: 27291, epoch: 83, loss: 0.541392
global_step: 27292, epoch: 83, loss: 0.642005
global_step: 27293, epoch: 83, loss: 0.663122
global_step: 27294, epoch: 83, loss: 0.638394
global_step: 27295, epoch: 83, loss: 0.637801
global_step: 27296, epoch: 83, loss: 0.727874
global_step: 27297, epoch: 83, loss: 0.749744
global_step: 27298, epoch: 83, loss: 0.726526
global_step: 27299, epoch: 83, loss: 0.633969
global_step: 27300, epoch: 83, loss: 0.611327
global_step: 27301, epoch: 83, loss: 0.603396
global_step: 27302, epoch: 83, loss: 0.707957
global_step: 27303, epoch: 83, loss: 0.651031
global_step: 27304, epoch: 83, loss: 0.743859
global_step: 27305, epoch: 83, loss: 0.671699
global_step: 27306, epoch: 83, loss: 0.703000
global_step: 27307, epoch: 83, loss: 0.650512
global_step: 27308, epoch: 83, loss: 0.653215
global_step: 27309, epoch: 83, loss: 0.634388
global_step: 27310, epoch: 83, loss: 0.604672
global_step: 27311, epoch: 83, loss: 0.706264
global_step: 27312, epoch: 83, loss: 0.598382
global_step: 27313, epoch: 83, loss: 0.730312
global_step: 27314, epoch: 83, loss: 0.622335
global_step: 27315, epoch: 83, loss: 0.614079
global_step: 27316, epoch: 83, loss: 0.727248
global_step: 27317, epoch: 83, loss: 0.574508
global_step: 27318, epoch: 83, loss: 0.669061
global_step: 27319, epoch: 83, loss: 0.713339
global_step: 27320, epoch: 83, loss: 0.875270
epoch: 83
train	acc: 0.8464	macro: p 0.7042, r 0.6041, f1: 0.5971	micro: p 0.8464, r 0.8464, f1 0.8464	weighted_f1:0.8245
dev	acc: 0.5807	macro: p 0.3749, r 0.3528, f1: 0.3551	micro: p 0.5807, r 0.5807, f1 0.5807	weighted_f1:0.5432
test	acc: 0.6123	macro: p 0.3665, r 0.3522, f1: 0.3545	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5818
global_step: 27321, epoch: 84, loss: 0.572593
global_step: 27322, epoch: 84, loss: 0.780076
global_step: 27323, epoch: 84, loss: 0.612303
global_step: 27324, epoch: 84, loss: 0.639448
global_step: 27325, epoch: 84, loss: 0.576036
global_step: 27326, epoch: 84, loss: 0.616764
global_step: 27327, epoch: 84, loss: 0.691852
global_step: 27328, epoch: 84, loss: 0.706215
global_step: 27329, epoch: 84, loss: 0.614199
global_step: 27330, epoch: 84, loss: 0.584841
global_step: 27331, epoch: 84, loss: 0.642927
global_step: 27332, epoch: 84, loss: 0.706920
global_step: 27333, epoch: 84, loss: 0.644173
global_step: 27334, epoch: 84, loss: 0.681147
global_step: 27335, epoch: 84, loss: 0.592225
global_step: 27336, epoch: 84, loss: 0.551478
global_step: 27337, epoch: 84, loss: 0.735990
global_step: 27338, epoch: 84, loss: 0.601674
global_step: 27339, epoch: 84, loss: 0.658574
global_step: 27340, epoch: 84, loss: 0.666956
global_step: 27341, epoch: 84, loss: 0.597360
global_step: 27342, epoch: 84, loss: 0.603469
global_step: 27343, epoch: 84, loss: 0.716373
global_step: 27344, epoch: 84, loss: 0.627299
global_step: 27345, epoch: 84, loss: 0.600864
global_step: 27346, epoch: 84, loss: 0.707712
global_step: 27347, epoch: 84, loss: 0.647504
global_step: 27348, epoch: 84, loss: 0.656642
global_step: 27349, epoch: 84, loss: 0.659588
global_step: 27350, epoch: 84, loss: 0.605619
global_step: 27351, epoch: 84, loss: 0.629739
global_step: 27352, epoch: 84, loss: 0.651064
global_step: 27353, epoch: 84, loss: 0.647651
global_step: 27354, epoch: 84, loss: 0.611601
global_step: 27355, epoch: 84, loss: 0.598298
global_step: 27356, epoch: 84, loss: 0.699262
global_step: 27357, epoch: 84, loss: 0.642550
global_step: 27358, epoch: 84, loss: 0.657968
global_step: 27359, epoch: 84, loss: 0.769792
global_step: 27360, epoch: 84, loss: 0.119671
epoch: 84
train	acc: 0.8552	macro: p 0.8572, r 0.6208, f1: 0.6188	micro: p 0.8552, r 0.8552, f1 0.8552	weighted_f1:0.8353
dev	acc: 0.5816	macro: p 0.3713, r 0.3572, f1: 0.3558	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5455
test	acc: 0.6130	macro: p 0.3644, r 0.3608, f1: 0.3575	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5854
global_step: 27361, epoch: 85, loss: 0.648984
global_step: 27362, epoch: 85, loss: 0.576585
global_step: 27363, epoch: 85, loss: 0.578871
global_step: 27364, epoch: 85, loss: 0.674208
global_step: 27365, epoch: 85, loss: 0.663904
global_step: 27366, epoch: 85, loss: 0.654886
global_step: 27367, epoch: 85, loss: 0.597082
global_step: 27368, epoch: 85, loss: 0.625199
global_step: 27369, epoch: 85, loss: 0.701458
global_step: 27370, epoch: 85, loss: 0.688531
global_step: 27371, epoch: 85, loss: 0.609495
global_step: 27372, epoch: 85, loss: 0.582457
global_step: 27373, epoch: 85, loss: 0.645673
global_step: 27374, epoch: 85, loss: 0.558702
global_step: 27375, epoch: 85, loss: 0.569234
global_step: 27376, epoch: 85, loss: 0.573105
global_step: 27377, epoch: 85, loss: 0.640168
global_step: 27378, epoch: 85, loss: 0.690080
global_step: 27379, epoch: 85, loss: 0.655599
global_step: 27380, epoch: 85, loss: 0.650269
global_step: 27381, epoch: 85, loss: 0.668165
global_step: 27382, epoch: 85, loss: 0.621171
global_step: 27383, epoch: 85, loss: 0.642252
global_step: 27384, epoch: 85, loss: 0.553353
global_step: 27385, epoch: 85, loss: 0.722754
global_step: 27386, epoch: 85, loss: 0.618622
global_step: 27387, epoch: 85, loss: 0.623652
global_step: 27388, epoch: 85, loss: 0.617212
global_step: 27389, epoch: 85, loss: 0.697928
global_step: 27390, epoch: 85, loss: 0.693810
global_step: 27391, epoch: 85, loss: 0.626549
global_step: 27392, epoch: 85, loss: 0.590073
global_step: 27393, epoch: 85, loss: 0.767652
global_step: 27394, epoch: 85, loss: 0.683766
global_step: 27395, epoch: 85, loss: 0.650869
global_step: 27396, epoch: 85, loss: 0.658889
global_step: 27397, epoch: 85, loss: 0.659435
global_step: 27398, epoch: 85, loss: 0.637865
global_step: 27399, epoch: 85, loss: 0.605424
global_step: 27400, epoch: 85, loss: 0.773999
epoch: 85
train	acc: 0.8315	macro: p 0.6944, r 0.5782, f1: 0.5828	micro: p 0.8315, r 0.8315, f1 0.8315	weighted_f1:0.8073
dev	acc: 0.5627	macro: p 0.3641, r 0.3227, f1: 0.3240	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5118
test	acc: 0.6096	macro: p 0.3713, r 0.3323, f1: 0.3372	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5659
global_step: 27401, epoch: 86, loss: 0.589901
global_step: 27402, epoch: 86, loss: 0.501446
global_step: 27403, epoch: 86, loss: 0.600677
global_step: 27404, epoch: 86, loss: 0.710213
global_step: 27405, epoch: 86, loss: 0.552412
global_step: 27406, epoch: 86, loss: 0.556641
global_step: 27407, epoch: 86, loss: 0.728900
global_step: 27408, epoch: 86, loss: 0.604198
global_step: 27409, epoch: 86, loss: 0.587311
global_step: 27410, epoch: 86, loss: 0.660555
global_step: 27411, epoch: 86, loss: 0.596746
global_step: 27412, epoch: 86, loss: 0.624834
global_step: 27413, epoch: 86, loss: 0.630019
global_step: 27414, epoch: 86, loss: 0.704605
global_step: 27415, epoch: 86, loss: 0.514679
global_step: 27416, epoch: 86, loss: 0.632334
global_step: 27417, epoch: 86, loss: 0.668226
global_step: 27418, epoch: 86, loss: 0.629834
global_step: 27419, epoch: 86, loss: 0.639319
global_step: 27420, epoch: 86, loss: 0.644365
global_step: 27421, epoch: 86, loss: 0.663446
global_step: 27422, epoch: 86, loss: 0.576708
global_step: 27423, epoch: 86, loss: 0.671738
global_step: 27424, epoch: 86, loss: 0.535130
global_step: 27425, epoch: 86, loss: 0.663992
global_step: 27426, epoch: 86, loss: 0.570051
global_step: 27427, epoch: 86, loss: 0.601183
global_step: 27428, epoch: 86, loss: 0.709532
global_step: 27429, epoch: 86, loss: 0.686105
global_step: 27430, epoch: 86, loss: 0.718444
global_step: 27431, epoch: 86, loss: 0.605271
global_step: 27432, epoch: 86, loss: 0.621280
global_step: 27433, epoch: 86, loss: 0.662899
global_step: 27434, epoch: 86, loss: 0.738371
global_step: 27435, epoch: 86, loss: 0.586146
global_step: 27436, epoch: 86, loss: 0.632178
global_step: 27437, epoch: 86, loss: 0.592489
global_step: 27438, epoch: 86, loss: 0.743772
global_step: 27439, epoch: 86, loss: 0.764090
global_step: 27440, epoch: 86, loss: 0.344441
epoch: 86
train	acc: 0.8500	macro: p 0.7168, r 0.6028, f1: 0.6049	micro: p 0.8500, r 0.8500, f1 0.8500	weighted_f1:0.8273
dev	acc: 0.5825	macro: p 0.3889, r 0.3491, f1: 0.3501	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5399
test	acc: 0.6176	macro: p 0.3810, r 0.3501, f1: 0.3533	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5825
global_step: 27441, epoch: 87, loss: 0.595405
global_step: 27442, epoch: 87, loss: 0.582892
global_step: 27443, epoch: 87, loss: 0.657890
global_step: 27444, epoch: 87, loss: 0.623763
global_step: 27445, epoch: 87, loss: 0.646894
global_step: 27446, epoch: 87, loss: 0.617519
global_step: 27447, epoch: 87, loss: 0.580371
global_step: 27448, epoch: 87, loss: 0.591913
global_step: 27449, epoch: 87, loss: 0.602230
global_step: 27450, epoch: 87, loss: 0.624036
global_step: 27451, epoch: 87, loss: 0.568555
global_step: 27452, epoch: 87, loss: 0.627339
global_step: 27453, epoch: 87, loss: 0.612358
global_step: 27454, epoch: 87, loss: 0.589191
global_step: 27455, epoch: 87, loss: 0.666641
global_step: 27456, epoch: 87, loss: 0.690504
global_step: 27457, epoch: 87, loss: 0.589597
global_step: 27458, epoch: 87, loss: 0.687577
global_step: 27459, epoch: 87, loss: 0.635398
global_step: 27460, epoch: 87, loss: 0.639911
global_step: 27461, epoch: 87, loss: 0.615281
global_step: 27462, epoch: 87, loss: 0.571559
global_step: 27463, epoch: 87, loss: 0.742980
global_step: 27464, epoch: 87, loss: 0.634732
global_step: 27465, epoch: 87, loss: 0.657363
global_step: 27466, epoch: 87, loss: 0.595762
global_step: 27467, epoch: 87, loss: 0.620885
global_step: 27468, epoch: 87, loss: 0.661935
global_step: 27469, epoch: 87, loss: 0.644555
global_step: 27470, epoch: 87, loss: 0.645008
global_step: 27471, epoch: 87, loss: 0.677011
global_step: 27472, epoch: 87, loss: 0.623273
global_step: 27473, epoch: 87, loss: 0.572180
global_step: 27474, epoch: 87, loss: 0.620611
global_step: 27475, epoch: 87, loss: 0.696311
global_step: 27476, epoch: 87, loss: 0.648273
global_step: 27477, epoch: 87, loss: 0.708955
global_step: 27478, epoch: 87, loss: 0.754990
global_step: 27479, epoch: 87, loss: 0.566802
global_step: 27480, epoch: 87, loss: 0.488797
epoch: 87
train	acc: 0.8399	macro: p 0.7196, r 0.5962, f1: 0.6121	micro: p 0.8399, r 0.8399, f1 0.8399	weighted_f1:0.8182
dev	acc: 0.5780	macro: p 0.3941, r 0.3378, f1: 0.3414	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5302
test	acc: 0.6157	macro: p 0.3791, r 0.3370, f1: 0.3446	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5743
global_step: 27481, epoch: 88, loss: 0.650098
global_step: 27482, epoch: 88, loss: 0.544445
global_step: 27483, epoch: 88, loss: 0.501317
global_step: 27484, epoch: 88, loss: 0.639127
global_step: 27485, epoch: 88, loss: 0.639807
global_step: 27486, epoch: 88, loss: 0.535248
global_step: 27487, epoch: 88, loss: 0.648373
global_step: 27488, epoch: 88, loss: 0.642788
global_step: 27489, epoch: 88, loss: 0.595272
global_step: 27490, epoch: 88, loss: 0.574115
global_step: 27491, epoch: 88, loss: 0.578638
global_step: 27492, epoch: 88, loss: 0.518837
global_step: 27493, epoch: 88, loss: 0.593975
global_step: 27494, epoch: 88, loss: 0.626343
global_step: 27495, epoch: 88, loss: 0.625500
global_step: 27496, epoch: 88, loss: 0.574857
global_step: 27497, epoch: 88, loss: 0.635610
global_step: 27498, epoch: 88, loss: 0.600475
global_step: 27499, epoch: 88, loss: 0.612016
global_step: 27500, epoch: 88, loss: 0.617453
global_step: 27501, epoch: 88, loss: 0.676351
global_step: 27502, epoch: 88, loss: 0.591950
global_step: 27503, epoch: 88, loss: 0.792048
global_step: 27504, epoch: 88, loss: 0.575788
global_step: 27505, epoch: 88, loss: 0.629832
global_step: 27506, epoch: 88, loss: 0.625640
global_step: 27507, epoch: 88, loss: 0.663297
global_step: 27508, epoch: 88, loss: 0.650290
global_step: 27509, epoch: 88, loss: 0.614704
global_step: 27510, epoch: 88, loss: 0.678741
global_step: 27511, epoch: 88, loss: 0.647251
global_step: 27512, epoch: 88, loss: 0.699748
global_step: 27513, epoch: 88, loss: 0.589263
global_step: 27514, epoch: 88, loss: 0.695997
global_step: 27515, epoch: 88, loss: 0.659041
global_step: 27516, epoch: 88, loss: 0.577393
global_step: 27517, epoch: 88, loss: 0.622355
global_step: 27518, epoch: 88, loss: 0.662365
global_step: 27519, epoch: 88, loss: 0.708333
global_step: 27520, epoch: 88, loss: 0.652696
epoch: 88
train	acc: 0.8552	macro: p 0.7182, r 0.6123, f1: 0.6104	micro: p 0.8552, r 0.8552, f1 0.8552	weighted_f1:0.8339
dev	acc: 0.5753	macro: p 0.3745, r 0.3510, f1: 0.3434	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5365
test	acc: 0.6088	macro: p 0.3728, r 0.3562, f1: 0.3523	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5806
global_step: 27521, epoch: 89, loss: 0.602787
global_step: 27522, epoch: 89, loss: 0.631743
global_step: 27523, epoch: 89, loss: 0.563751
global_step: 27524, epoch: 89, loss: 0.653210
global_step: 27525, epoch: 89, loss: 0.600257
global_step: 27526, epoch: 89, loss: 0.496983
global_step: 27527, epoch: 89, loss: 0.691741
global_step: 27528, epoch: 89, loss: 0.633561
global_step: 27529, epoch: 89, loss: 0.653339
global_step: 27530, epoch: 89, loss: 0.622625
global_step: 27531, epoch: 89, loss: 0.695146
global_step: 27532, epoch: 89, loss: 0.583788
global_step: 27533, epoch: 89, loss: 0.564698
global_step: 27534, epoch: 89, loss: 0.576807
global_step: 27535, epoch: 89, loss: 0.683638
global_step: 27536, epoch: 89, loss: 0.524211
global_step: 27537, epoch: 89, loss: 0.634403
global_step: 27538, epoch: 89, loss: 0.522420
global_step: 27539, epoch: 89, loss: 0.618272
global_step: 27540, epoch: 89, loss: 0.566846
global_step: 27541, epoch: 89, loss: 0.630682
global_step: 27542, epoch: 89, loss: 0.572013
global_step: 27543, epoch: 89, loss: 0.609339
global_step: 27544, epoch: 89, loss: 0.578840
global_step: 27545, epoch: 89, loss: 0.557998
global_step: 27546, epoch: 89, loss: 0.605552
global_step: 27547, epoch: 89, loss: 0.628441
global_step: 27548, epoch: 89, loss: 0.620088
global_step: 27549, epoch: 89, loss: 0.598926
global_step: 27550, epoch: 89, loss: 0.644269
global_step: 27551, epoch: 89, loss: 0.578479
global_step: 27552, epoch: 89, loss: 0.501598
global_step: 27553, epoch: 89, loss: 0.632959
global_step: 27554, epoch: 89, loss: 0.644393
global_step: 27555, epoch: 89, loss: 0.606689
global_step: 27556, epoch: 89, loss: 0.606943
global_step: 27557, epoch: 89, loss: 0.667681
global_step: 27558, epoch: 89, loss: 0.590787
global_step: 27559, epoch: 89, loss: 0.593670
global_step: 27560, epoch: 89, loss: 0.933918
epoch: 89
train	acc: 0.8522	macro: p 0.7222, r 0.6076, f1: 0.6154	micro: p 0.8522, r 0.8522, f1 0.8522	weighted_f1:0.8301
dev	acc: 0.5825	macro: p 0.4449, r 0.3544, f1: 0.3579	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5379
test	acc: 0.6103	macro: p 0.3765, r 0.3396, f1: 0.3409	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5705
global_step: 27561, epoch: 90, loss: 0.529490
global_step: 27562, epoch: 90, loss: 0.602066
global_step: 27563, epoch: 90, loss: 0.668884
global_step: 27564, epoch: 90, loss: 0.574326
global_step: 27565, epoch: 90, loss: 0.626658
global_step: 27566, epoch: 90, loss: 0.589368
global_step: 27567, epoch: 90, loss: 0.627959
global_step: 27568, epoch: 90, loss: 0.594335
global_step: 27569, epoch: 90, loss: 0.598558
global_step: 27570, epoch: 90, loss: 0.572513
global_step: 27571, epoch: 90, loss: 0.499343
global_step: 27572, epoch: 90, loss: 0.544770
global_step: 27573, epoch: 90, loss: 0.652278
global_step: 27574, epoch: 90, loss: 0.640114
global_step: 27575, epoch: 90, loss: 0.639176
global_step: 27576, epoch: 90, loss: 0.519897
global_step: 27577, epoch: 90, loss: 0.666966
global_step: 27578, epoch: 90, loss: 0.570889
global_step: 27579, epoch: 90, loss: 0.616294
global_step: 27580, epoch: 90, loss: 0.605748
global_step: 27581, epoch: 90, loss: 0.638810
global_step: 27582, epoch: 90, loss: 0.678030
global_step: 27583, epoch: 90, loss: 0.638982
global_step: 27584, epoch: 90, loss: 0.637865
global_step: 27585, epoch: 90, loss: 0.552751
global_step: 27586, epoch: 90, loss: 0.586897
global_step: 27587, epoch: 90, loss: 0.582880
global_step: 27588, epoch: 90, loss: 0.542835
global_step: 27589, epoch: 90, loss: 0.582978
global_step: 27590, epoch: 90, loss: 0.571299
global_step: 27591, epoch: 90, loss: 0.682973
global_step: 27592, epoch: 90, loss: 0.577350
global_step: 27593, epoch: 90, loss: 0.621266
global_step: 27594, epoch: 90, loss: 0.629144
global_step: 27595, epoch: 90, loss: 0.607738
global_step: 27596, epoch: 90, loss: 0.691764
global_step: 27597, epoch: 90, loss: 0.598407
global_step: 27598, epoch: 90, loss: 0.605922
global_step: 27599, epoch: 90, loss: 0.722539
global_step: 27600, epoch: 90, loss: 0.293118
epoch: 90
train	acc: 0.8499	macro: p 0.7189, r 0.6083, f1: 0.6142	micro: p 0.8499, r 0.8499, f1 0.8499	weighted_f1:0.8290
dev	acc: 0.5708	macro: p 0.3725, r 0.3340, f1: 0.3373	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5247
test	acc: 0.6111	macro: p 0.4182, r 0.3343, f1: 0.3439	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5703
global_step: 27601, epoch: 91, loss: 0.633611
global_step: 27602, epoch: 91, loss: 0.506073
global_step: 27603, epoch: 91, loss: 0.553121
global_step: 27604, epoch: 91, loss: 0.599802
global_step: 27605, epoch: 91, loss: 0.505794
global_step: 27606, epoch: 91, loss: 0.598864
global_step: 27607, epoch: 91, loss: 0.640411
global_step: 27608, epoch: 91, loss: 0.586634
global_step: 27609, epoch: 91, loss: 0.639679
global_step: 27610, epoch: 91, loss: 0.552218
global_step: 27611, epoch: 91, loss: 0.665552
global_step: 27612, epoch: 91, loss: 0.614539
global_step: 27613, epoch: 91, loss: 0.572560
global_step: 27614, epoch: 91, loss: 0.610096
global_step: 27615, epoch: 91, loss: 0.648245
global_step: 27616, epoch: 91, loss: 0.599187
global_step: 27617, epoch: 91, loss: 0.560076
global_step: 27618, epoch: 91, loss: 0.655180
global_step: 27619, epoch: 91, loss: 0.612581
global_step: 27620, epoch: 91, loss: 0.646311
global_step: 27621, epoch: 91, loss: 0.544119
global_step: 27622, epoch: 91, loss: 0.601386
global_step: 27623, epoch: 91, loss: 0.628830
global_step: 27624, epoch: 91, loss: 0.580174
global_step: 27625, epoch: 91, loss: 0.622923
global_step: 27626, epoch: 91, loss: 0.604938
global_step: 27627, epoch: 91, loss: 0.613190
global_step: 27628, epoch: 91, loss: 0.583342
global_step: 27629, epoch: 91, loss: 0.541864
global_step: 27630, epoch: 91, loss: 0.626870
global_step: 27631, epoch: 91, loss: 0.574662
global_step: 27632, epoch: 91, loss: 0.565355
global_step: 27633, epoch: 91, loss: 0.535846
global_step: 27634, epoch: 91, loss: 0.566461
global_step: 27635, epoch: 91, loss: 0.590521
global_step: 27636, epoch: 91, loss: 0.679604
global_step: 27637, epoch: 91, loss: 0.575152
global_step: 27638, epoch: 91, loss: 0.591770
global_step: 27639, epoch: 91, loss: 0.583648
global_step: 27640, epoch: 91, loss: 1.409949
epoch: 91
train	acc: 0.8713	macro: p 0.8561, r 0.6586, f1: 0.6560	micro: p 0.8713, r 0.8713, f1 0.8713	weighted_f1:0.8556
dev	acc: 0.5708	macro: p 0.3794, r 0.3641, f1: 0.3621	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5438
test	acc: 0.6038	macro: p 0.3767, r 0.3757, f1: 0.3686	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5878
global_step: 27641, epoch: 92, loss: 0.565807
global_step: 27642, epoch: 92, loss: 0.606010
global_step: 27643, epoch: 92, loss: 0.630663
global_step: 27644, epoch: 92, loss: 0.646127
global_step: 27645, epoch: 92, loss: 0.570606
global_step: 27646, epoch: 92, loss: 0.733761
global_step: 27647, epoch: 92, loss: 0.532549
global_step: 27648, epoch: 92, loss: 0.509975
global_step: 27649, epoch: 92, loss: 0.682480
global_step: 27650, epoch: 92, loss: 0.636496
global_step: 27651, epoch: 92, loss: 0.602107
global_step: 27652, epoch: 92, loss: 0.517726
global_step: 27653, epoch: 92, loss: 0.483936
global_step: 27654, epoch: 92, loss: 0.573343
global_step: 27655, epoch: 92, loss: 0.581922
global_step: 27656, epoch: 92, loss: 0.571333
global_step: 27657, epoch: 92, loss: 0.564310
global_step: 27658, epoch: 92, loss: 0.585568
global_step: 27659, epoch: 92, loss: 0.464881
global_step: 27660, epoch: 92, loss: 0.665528
global_step: 27661, epoch: 92, loss: 0.550580
global_step: 27662, epoch: 92, loss: 0.650823
global_step: 27663, epoch: 92, loss: 0.641705
global_step: 27664, epoch: 92, loss: 0.549453
global_step: 27665, epoch: 92, loss: 0.588045
global_step: 27666, epoch: 92, loss: 0.589606
global_step: 27667, epoch: 92, loss: 0.590711
global_step: 27668, epoch: 92, loss: 0.671107
global_step: 27669, epoch: 92, loss: 0.520602
global_step: 27670, epoch: 92, loss: 0.620764
global_step: 27671, epoch: 92, loss: 0.615215
global_step: 27672, epoch: 92, loss: 0.576168
global_step: 27673, epoch: 92, loss: 0.614879
global_step: 27674, epoch: 92, loss: 0.503959
global_step: 27675, epoch: 92, loss: 0.633917
global_step: 27676, epoch: 92, loss: 0.554327
global_step: 27677, epoch: 92, loss: 0.582346
global_step: 27678, epoch: 92, loss: 0.598719
global_step: 27679, epoch: 92, loss: 0.511345
global_step: 27680, epoch: 92, loss: 0.229841
epoch: 92
train	acc: 0.8429	macro: p 0.7227, r 0.5988, f1: 0.6179	micro: p 0.8429, r 0.8429, f1 0.8429	weighted_f1:0.8213
dev	acc: 0.5717	macro: p 0.3959, r 0.3287, f1: 0.3356	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5233
test	acc: 0.6146	macro: p 0.4315, r 0.3304, f1: 0.3428	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5703
global_step: 27681, epoch: 93, loss: 0.581473
global_step: 27682, epoch: 93, loss: 0.634826
global_step: 27683, epoch: 93, loss: 0.674185
global_step: 27684, epoch: 93, loss: 0.587363
global_step: 27685, epoch: 93, loss: 0.583408
global_step: 27686, epoch: 93, loss: 0.617020
global_step: 27687, epoch: 93, loss: 0.675272
global_step: 27688, epoch: 93, loss: 0.562839
global_step: 27689, epoch: 93, loss: 0.581155
global_step: 27690, epoch: 93, loss: 0.546440
global_step: 27691, epoch: 93, loss: 0.501350
global_step: 27692, epoch: 93, loss: 0.590471
global_step: 27693, epoch: 93, loss: 0.545120
global_step: 27694, epoch: 93, loss: 0.615083
global_step: 27695, epoch: 93, loss: 0.619270
global_step: 27696, epoch: 93, loss: 0.586121
global_step: 27697, epoch: 93, loss: 0.604224
global_step: 27698, epoch: 93, loss: 0.542574
global_step: 27699, epoch: 93, loss: 0.555581
global_step: 27700, epoch: 93, loss: 0.568348
global_step: 27701, epoch: 93, loss: 0.533288
global_step: 27702, epoch: 93, loss: 0.581324
global_step: 27703, epoch: 93, loss: 0.546891
global_step: 27704, epoch: 93, loss: 0.639950
global_step: 27705, epoch: 93, loss: 0.505313
global_step: 27706, epoch: 93, loss: 0.514889
global_step: 27707, epoch: 93, loss: 0.490560
global_step: 27708, epoch: 93, loss: 0.727064
global_step: 27709, epoch: 93, loss: 0.587937
global_step: 27710, epoch: 93, loss: 0.521052
global_step: 27711, epoch: 93, loss: 0.562452
global_step: 27712, epoch: 93, loss: 0.687845
global_step: 27713, epoch: 93, loss: 0.687803
global_step: 27714, epoch: 93, loss: 0.589480
global_step: 27715, epoch: 93, loss: 0.588249
global_step: 27716, epoch: 93, loss: 0.556769
global_step: 27717, epoch: 93, loss: 0.531010
global_step: 27718, epoch: 93, loss: 0.493335
global_step: 27719, epoch: 93, loss: 0.593616
global_step: 27720, epoch: 93, loss: 0.433527
epoch: 93
train	acc: 0.8666	macro: p 0.7290, r 0.6428, f1: 0.6550	micro: p 0.8666, r 0.8666, f1 0.8666	weighted_f1:0.8483
dev	acc: 0.5735	macro: p 0.4219, r 0.3425, f1: 0.3478	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5289
test	acc: 0.6061	macro: p 0.3867, r 0.3369, f1: 0.3423	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5693
global_step: 27721, epoch: 94, loss: 0.555525
global_step: 27722, epoch: 94, loss: 0.533492
global_step: 27723, epoch: 94, loss: 0.566347
global_step: 27724, epoch: 94, loss: 0.622012
global_step: 27725, epoch: 94, loss: 0.566474
global_step: 27726, epoch: 94, loss: 0.605775
global_step: 27727, epoch: 94, loss: 0.533154
global_step: 27728, epoch: 94, loss: 0.616605
global_step: 27729, epoch: 94, loss: 0.630944
global_step: 27730, epoch: 94, loss: 0.624600
global_step: 27731, epoch: 94, loss: 0.630368
global_step: 27732, epoch: 94, loss: 0.592692
global_step: 27733, epoch: 94, loss: 0.584869
global_step: 27734, epoch: 94, loss: 0.595680
global_step: 27735, epoch: 94, loss: 0.582119
global_step: 27736, epoch: 94, loss: 0.553388
global_step: 27737, epoch: 94, loss: 0.595925
global_step: 27738, epoch: 94, loss: 0.564142
global_step: 27739, epoch: 94, loss: 0.458344
global_step: 27740, epoch: 94, loss: 0.518914
global_step: 27741, epoch: 94, loss: 0.637626
global_step: 27742, epoch: 94, loss: 0.517576
global_step: 27743, epoch: 94, loss: 0.639994
global_step: 27744, epoch: 94, loss: 0.592664
global_step: 27745, epoch: 94, loss: 0.576860
global_step: 27746, epoch: 94, loss: 0.552968
global_step: 27747, epoch: 94, loss: 0.499508
global_step: 27748, epoch: 94, loss: 0.638454
global_step: 27749, epoch: 94, loss: 0.545984
global_step: 27750, epoch: 94, loss: 0.501541
global_step: 27751, epoch: 94, loss: 0.645842
global_step: 27752, epoch: 94, loss: 0.620122
global_step: 27753, epoch: 94, loss: 0.592971
global_step: 27754, epoch: 94, loss: 0.556827
global_step: 27755, epoch: 94, loss: 0.563272
global_step: 27756, epoch: 94, loss: 0.654738
global_step: 27757, epoch: 94, loss: 0.534901
global_step: 27758, epoch: 94, loss: 0.609223
global_step: 27759, epoch: 94, loss: 0.595847
global_step: 27760, epoch: 94, loss: 0.395482
epoch: 94
train	acc: 0.8489	macro: p 0.8722, r 0.6104, f1: 0.6301	micro: p 0.8489, r 0.8489, f1 0.8489	weighted_f1:0.8287
dev	acc: 0.5663	macro: p 0.3828, r 0.3246, f1: 0.3322	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5177
test	acc: 0.6065	macro: p 0.4239, r 0.3237, f1: 0.3376	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5617
global_step: 27761, epoch: 95, loss: 0.621063
global_step: 27762, epoch: 95, loss: 0.559411
global_step: 27763, epoch: 95, loss: 0.482689
global_step: 27764, epoch: 95, loss: 0.551692
global_step: 27765, epoch: 95, loss: 0.584475
global_step: 27766, epoch: 95, loss: 0.562609
global_step: 27767, epoch: 95, loss: 0.539917
global_step: 27768, epoch: 95, loss: 0.510325
global_step: 27769, epoch: 95, loss: 0.695263
global_step: 27770, epoch: 95, loss: 0.576053
global_step: 27771, epoch: 95, loss: 0.660166
global_step: 27772, epoch: 95, loss: 0.640847
global_step: 27773, epoch: 95, loss: 0.603033
global_step: 27774, epoch: 95, loss: 0.596985
global_step: 27775, epoch: 95, loss: 0.570438
global_step: 27776, epoch: 95, loss: 0.554239
global_step: 27777, epoch: 95, loss: 0.540055
global_step: 27778, epoch: 95, loss: 0.549259
global_step: 27779, epoch: 95, loss: 0.565662
global_step: 27780, epoch: 95, loss: 0.519153
global_step: 27781, epoch: 95, loss: 0.536055
global_step: 27782, epoch: 95, loss: 0.615072
global_step: 27783, epoch: 95, loss: 0.648812
global_step: 27784, epoch: 95, loss: 0.498181
global_step: 27785, epoch: 95, loss: 0.541746
global_step: 27786, epoch: 95, loss: 0.594124
global_step: 27787, epoch: 95, loss: 0.561558
global_step: 27788, epoch: 95, loss: 0.617808
global_step: 27789, epoch: 95, loss: 0.547978
global_step: 27790, epoch: 95, loss: 0.562353
global_step: 27791, epoch: 95, loss: 0.597983
global_step: 27792, epoch: 95, loss: 0.587029
global_step: 27793, epoch: 95, loss: 0.511940
global_step: 27794, epoch: 95, loss: 0.571636
global_step: 27795, epoch: 95, loss: 0.543541
global_step: 27796, epoch: 95, loss: 0.546475
global_step: 27797, epoch: 95, loss: 0.491244
global_step: 27798, epoch: 95, loss: 0.583360
global_step: 27799, epoch: 95, loss: 0.604460
global_step: 27800, epoch: 95, loss: 0.588646
epoch: 95
train	acc: 0.8793	macro: p 0.8666, r 0.6707, f1: 0.6749	micro: p 0.8793, r 0.8793, f1 0.8793	weighted_f1:0.8639
dev	acc: 0.5744	macro: p 0.4344, r 0.3578, f1: 0.3640	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5424
test	acc: 0.6111	macro: p 0.3838, r 0.3653, f1: 0.3670	micro: p 0.6111, r 0.6111, f1 0.6111	weighted_f1:0.5894
global_step: 27801, epoch: 96, loss: 0.560004
global_step: 27802, epoch: 96, loss: 0.630126
global_step: 27803, epoch: 96, loss: 0.526392
global_step: 27804, epoch: 96, loss: 0.569337
global_step: 27805, epoch: 96, loss: 0.602312
global_step: 27806, epoch: 96, loss: 0.556626
global_step: 27807, epoch: 96, loss: 0.580839
global_step: 27808, epoch: 96, loss: 0.505602
global_step: 27809, epoch: 96, loss: 0.658774
global_step: 27810, epoch: 96, loss: 0.536558
global_step: 27811, epoch: 96, loss: 0.644621
global_step: 27812, epoch: 96, loss: 0.569399
global_step: 27813, epoch: 96, loss: 0.541353
global_step: 27814, epoch: 96, loss: 0.505676
global_step: 27815, epoch: 96, loss: 0.641759
global_step: 27816, epoch: 96, loss: 0.553581
global_step: 27817, epoch: 96, loss: 0.557293
global_step: 27818, epoch: 96, loss: 0.661881
global_step: 27819, epoch: 96, loss: 0.482714
global_step: 27820, epoch: 96, loss: 0.626046
global_step: 27821, epoch: 96, loss: 0.535195
global_step: 27822, epoch: 96, loss: 0.580082
global_step: 27823, epoch: 96, loss: 0.576272
global_step: 27824, epoch: 96, loss: 0.668501
global_step: 27825, epoch: 96, loss: 0.558227
global_step: 27826, epoch: 96, loss: 0.595467
global_step: 27827, epoch: 96, loss: 0.561886
global_step: 27828, epoch: 96, loss: 0.556913
global_step: 27829, epoch: 96, loss: 0.585922
global_step: 27830, epoch: 96, loss: 0.560266
global_step: 27831, epoch: 96, loss: 0.535337
global_step: 27832, epoch: 96, loss: 0.604456
global_step: 27833, epoch: 96, loss: 0.650801
global_step: 27834, epoch: 96, loss: 0.581174
global_step: 27835, epoch: 96, loss: 0.464259
global_step: 27836, epoch: 96, loss: 0.488131
global_step: 27837, epoch: 96, loss: 0.562604
global_step: 27838, epoch: 96, loss: 0.489207
global_step: 27839, epoch: 96, loss: 0.509489
global_step: 27840, epoch: 96, loss: 0.505091
epoch: 96
train	acc: 0.8654	macro: p 0.8661, r 0.6342, f1: 0.6442	micro: p 0.8654, r 0.8654, f1 0.8654	weighted_f1:0.8466
dev	acc: 0.5780	macro: p 0.4192, r 0.3497, f1: 0.3550	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5378
test	acc: 0.6172	macro: p 0.3783, r 0.3513, f1: 0.3520	micro: p 0.6172, r 0.6172, f1 0.6172	weighted_f1:0.5844
global_step: 27841, epoch: 97, loss: 0.586296
global_step: 27842, epoch: 97, loss: 0.611836
global_step: 27843, epoch: 97, loss: 0.529832
global_step: 27844, epoch: 97, loss: 0.514494
global_step: 27845, epoch: 97, loss: 0.506694
global_step: 27846, epoch: 97, loss: 0.595056
global_step: 27847, epoch: 97, loss: 0.710419
global_step: 27848, epoch: 97, loss: 0.548164
global_step: 27849, epoch: 97, loss: 0.634856
global_step: 27850, epoch: 97, loss: 0.544787
global_step: 27851, epoch: 97, loss: 0.651487
global_step: 27852, epoch: 97, loss: 0.516523
global_step: 27853, epoch: 97, loss: 0.549864
global_step: 27854, epoch: 97, loss: 0.515970
global_step: 27855, epoch: 97, loss: 0.566924
global_step: 27856, epoch: 97, loss: 0.573421
global_step: 27857, epoch: 97, loss: 0.629558
global_step: 27858, epoch: 97, loss: 0.598827
global_step: 27859, epoch: 97, loss: 0.551970
global_step: 27860, epoch: 97, loss: 0.463829
global_step: 27861, epoch: 97, loss: 0.525139
global_step: 27862, epoch: 97, loss: 0.591529
global_step: 27863, epoch: 97, loss: 0.588584
global_step: 27864, epoch: 97, loss: 0.497060
global_step: 27865, epoch: 97, loss: 0.657341
global_step: 27866, epoch: 97, loss: 0.551150
global_step: 27867, epoch: 97, loss: 0.660608
global_step: 27868, epoch: 97, loss: 0.581491
global_step: 27869, epoch: 97, loss: 0.435384
global_step: 27870, epoch: 97, loss: 0.565436
global_step: 27871, epoch: 97, loss: 0.476163
global_step: 27872, epoch: 97, loss: 0.533243
global_step: 27873, epoch: 97, loss: 0.530698
global_step: 27874, epoch: 97, loss: 0.529701
global_step: 27875, epoch: 97, loss: 0.509275
global_step: 27876, epoch: 97, loss: 0.576596
global_step: 27877, epoch: 97, loss: 0.559103
global_step: 27878, epoch: 97, loss: 0.520334
global_step: 27879, epoch: 97, loss: 0.557792
global_step: 27880, epoch: 97, loss: 0.797320
epoch: 97
train	acc: 0.8790	macro: p 0.8782, r 0.6654, f1: 0.6739	micro: p 0.8790, r 0.8790, f1 0.8790	weighted_f1:0.8625
dev	acc: 0.5789	macro: p 0.4105, r 0.3572, f1: 0.3619	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5413
test	acc: 0.6142	macro: p 0.3922, r 0.3588, f1: 0.3606	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5859
global_step: 27881, epoch: 98, loss: 0.578270
global_step: 27882, epoch: 98, loss: 0.525943
global_step: 27883, epoch: 98, loss: 0.678844
global_step: 27884, epoch: 98, loss: 0.479631
global_step: 27885, epoch: 98, loss: 0.504394
global_step: 27886, epoch: 98, loss: 0.493350
global_step: 27887, epoch: 98, loss: 0.491937
global_step: 27888, epoch: 98, loss: 0.528011
global_step: 27889, epoch: 98, loss: 0.587710
global_step: 27890, epoch: 98, loss: 0.570580
global_step: 27891, epoch: 98, loss: 0.580383
global_step: 27892, epoch: 98, loss: 0.645869
global_step: 27893, epoch: 98, loss: 0.452342
global_step: 27894, epoch: 98, loss: 0.544729
global_step: 27895, epoch: 98, loss: 0.548198
global_step: 27896, epoch: 98, loss: 0.583654
global_step: 27897, epoch: 98, loss: 0.560853
global_step: 27898, epoch: 98, loss: 0.523440
global_step: 27899, epoch: 98, loss: 0.628347
global_step: 27900, epoch: 98, loss: 0.510746
global_step: 27901, epoch: 98, loss: 0.604531
global_step: 27902, epoch: 98, loss: 0.551280
global_step: 27903, epoch: 98, loss: 0.548691
global_step: 27904, epoch: 98, loss: 0.469994
global_step: 27905, epoch: 98, loss: 0.492861
global_step: 27906, epoch: 98, loss: 0.530872
global_step: 27907, epoch: 98, loss: 0.602275
global_step: 27908, epoch: 98, loss: 0.578936
global_step: 27909, epoch: 98, loss: 0.576665
global_step: 27910, epoch: 98, loss: 0.527415
global_step: 27911, epoch: 98, loss: 0.663727
global_step: 27912, epoch: 98, loss: 0.575738
global_step: 27913, epoch: 98, loss: 0.556160
global_step: 27914, epoch: 98, loss: 0.569779
global_step: 27915, epoch: 98, loss: 0.516094
global_step: 27916, epoch: 98, loss: 0.610238
global_step: 27917, epoch: 98, loss: 0.574193
global_step: 27918, epoch: 98, loss: 0.473778
global_step: 27919, epoch: 98, loss: 0.490993
global_step: 27920, epoch: 98, loss: 0.372780
epoch: 98
train	acc: 0.8542	macro: p 0.8709, r 0.6287, f1: 0.6455	micro: p 0.8542, r 0.8542, f1 0.8542	weighted_f1:0.8365
dev	acc: 0.5645	macro: p 0.4411, r 0.3285, f1: 0.3395	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5161
test	acc: 0.6069	macro: p 0.4323, r 0.3289, f1: 0.3442	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5629
global_step: 27921, epoch: 99, loss: 0.603385
global_step: 27922, epoch: 99, loss: 0.576684
global_step: 27923, epoch: 99, loss: 0.516039
global_step: 27924, epoch: 99, loss: 0.627447
global_step: 27925, epoch: 99, loss: 0.481515
global_step: 27926, epoch: 99, loss: 0.504597
global_step: 27927, epoch: 99, loss: 0.488602
global_step: 27928, epoch: 99, loss: 0.544151
global_step: 27929, epoch: 99, loss: 0.611859
global_step: 27930, epoch: 99, loss: 0.516623
global_step: 27931, epoch: 99, loss: 0.495651
global_step: 27932, epoch: 99, loss: 0.697192
global_step: 27933, epoch: 99, loss: 0.607947
global_step: 27934, epoch: 99, loss: 0.565368
global_step: 27935, epoch: 99, loss: 0.558995
global_step: 27936, epoch: 99, loss: 0.553100
global_step: 27937, epoch: 99, loss: 0.482528
global_step: 27938, epoch: 99, loss: 0.491716
global_step: 27939, epoch: 99, loss: 0.547544
global_step: 27940, epoch: 99, loss: 0.554162
global_step: 27941, epoch: 99, loss: 0.522937
global_step: 27942, epoch: 99, loss: 0.507211
global_step: 27943, epoch: 99, loss: 0.559197
global_step: 27944, epoch: 99, loss: 0.562754
global_step: 27945, epoch: 99, loss: 0.593437
global_step: 27946, epoch: 99, loss: 0.470658
global_step: 27947, epoch: 99, loss: 0.528063
global_step: 27948, epoch: 99, loss: 0.519352
global_step: 27949, epoch: 99, loss: 0.555712
global_step: 27950, epoch: 99, loss: 0.505219
global_step: 27951, epoch: 99, loss: 0.583386
global_step: 27952, epoch: 99, loss: 0.468066
global_step: 27953, epoch: 99, loss: 0.553671
global_step: 27954, epoch: 99, loss: 0.533273
global_step: 27955, epoch: 99, loss: 0.595260
global_step: 27956, epoch: 99, loss: 0.498866
global_step: 27957, epoch: 99, loss: 0.534878
global_step: 27958, epoch: 99, loss: 0.572165
global_step: 27959, epoch: 99, loss: 0.589736
global_step: 27960, epoch: 99, loss: 0.682798
epoch: 99
train	acc: 0.8791	macro: p 0.8778, r 0.6666, f1: 0.6720	micro: p 0.8791, r 0.8791, f1 0.8791	weighted_f1:0.8632
dev	acc: 0.5618	macro: p 0.3883, r 0.3446, f1: 0.3518	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5304
test	acc: 0.6065	macro: p 0.3913, r 0.3546, f1: 0.3586	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5817
global_step: 27961, epoch: 100, loss: 0.575273
global_step: 27962, epoch: 100, loss: 0.564645
global_step: 27963, epoch: 100, loss: 0.505098
global_step: 27964, epoch: 100, loss: 0.544290
global_step: 27965, epoch: 100, loss: 0.556961
global_step: 27966, epoch: 100, loss: 0.549665
global_step: 27967, epoch: 100, loss: 0.502446
global_step: 27968, epoch: 100, loss: 0.519422
global_step: 27969, epoch: 100, loss: 0.630073
global_step: 27970, epoch: 100, loss: 0.502208
global_step: 27971, epoch: 100, loss: 0.563263
global_step: 27972, epoch: 100, loss: 0.479377
global_step: 27973, epoch: 100, loss: 0.568639
global_step: 27974, epoch: 100, loss: 0.465385
global_step: 27975, epoch: 100, loss: 0.465589
global_step: 27976, epoch: 100, loss: 0.590142
global_step: 27977, epoch: 100, loss: 0.525917
global_step: 27978, epoch: 100, loss: 0.580835
global_step: 27979, epoch: 100, loss: 0.483458
global_step: 27980, epoch: 100, loss: 0.559341
global_step: 27981, epoch: 100, loss: 0.560275
global_step: 27982, epoch: 100, loss: 0.460655
global_step: 27983, epoch: 100, loss: 0.547271
global_step: 27984, epoch: 100, loss: 0.659187
global_step: 27985, epoch: 100, loss: 0.628336
global_step: 27986, epoch: 100, loss: 0.553318
global_step: 27987, epoch: 100, loss: 0.572859
global_step: 27988, epoch: 100, loss: 0.528509
global_step: 27989, epoch: 100, loss: 0.459078
global_step: 27990, epoch: 100, loss: 0.515523
global_step: 27991, epoch: 100, loss: 0.458195
global_step: 27992, epoch: 100, loss: 0.486321
global_step: 27993, epoch: 100, loss: 0.606700
global_step: 27994, epoch: 100, loss: 0.505598
global_step: 27995, epoch: 100, loss: 0.592812
global_step: 27996, epoch: 100, loss: 0.556864
global_step: 27997, epoch: 100, loss: 0.535621
global_step: 27998, epoch: 100, loss: 0.535975
global_step: 27999, epoch: 100, loss: 0.552977
global_step: 28000, epoch: 100, loss: 0.172979
epoch: 100
train	acc: 0.8736	macro: p 0.7860, r 0.6557, f1: 0.6702	micro: p 0.8736, r 0.8736, f1 0.8736	weighted_f1:0.8565
dev	acc: 0.5771	macro: p 0.3887, r 0.3417, f1: 0.3468	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5337
test	acc: 0.6100	macro: p 0.3958, r 0.3357, f1: 0.3445	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5712
global_step: 28001, epoch: 101, loss: 0.533627
global_step: 28002, epoch: 101, loss: 0.515822
global_step: 28003, epoch: 101, loss: 0.488011
global_step: 28004, epoch: 101, loss: 0.508773
global_step: 28005, epoch: 101, loss: 0.605143
global_step: 28006, epoch: 101, loss: 0.617824
global_step: 28007, epoch: 101, loss: 0.552493
global_step: 28008, epoch: 101, loss: 0.487810
global_step: 28009, epoch: 101, loss: 0.529330
global_step: 28010, epoch: 101, loss: 0.533221
global_step: 28011, epoch: 101, loss: 0.567565
global_step: 28012, epoch: 101, loss: 0.552201
global_step: 28013, epoch: 101, loss: 0.512295
global_step: 28014, epoch: 101, loss: 0.562737
global_step: 28015, epoch: 101, loss: 0.494226
global_step: 28016, epoch: 101, loss: 0.498630
global_step: 28017, epoch: 101, loss: 0.555430
global_step: 28018, epoch: 101, loss: 0.615081
global_step: 28019, epoch: 101, loss: 0.527527
global_step: 28020, epoch: 101, loss: 0.524507
global_step: 28021, epoch: 101, loss: 0.541302
global_step: 28022, epoch: 101, loss: 0.516579
global_step: 28023, epoch: 101, loss: 0.521837
global_step: 28024, epoch: 101, loss: 0.556381
global_step: 28025, epoch: 101, loss: 0.550739
global_step: 28026, epoch: 101, loss: 0.631939
global_step: 28027, epoch: 101, loss: 0.437606
global_step: 28028, epoch: 101, loss: 0.529533
global_step: 28029, epoch: 101, loss: 0.550125
global_step: 28030, epoch: 101, loss: 0.525469
global_step: 28031, epoch: 101, loss: 0.490782
global_step: 28032, epoch: 101, loss: 0.491976
global_step: 28033, epoch: 101, loss: 0.603322
global_step: 28034, epoch: 101, loss: 0.512842
global_step: 28035, epoch: 101, loss: 0.494512
global_step: 28036, epoch: 101, loss: 0.548645
global_step: 28037, epoch: 101, loss: 0.509533
global_step: 28038, epoch: 101, loss: 0.593885
global_step: 28039, epoch: 101, loss: 0.527384
global_step: 28040, epoch: 101, loss: 0.274335
epoch: 101
train	acc: 0.8670	macro: p 0.8594, r 0.6402, f1: 0.6618	micro: p 0.8670, r 0.8670, f1 0.8670	weighted_f1:0.8483
dev	acc: 0.5654	macro: p 0.3903, r 0.3287, f1: 0.3288	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5167
test	acc: 0.6069	macro: p 0.4158, r 0.3321, f1: 0.3389	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5643
global_step: 28041, epoch: 102, loss: 0.540695
global_step: 28042, epoch: 102, loss: 0.565807
global_step: 28043, epoch: 102, loss: 0.562050
global_step: 28044, epoch: 102, loss: 0.585039
global_step: 28045, epoch: 102, loss: 0.515302
global_step: 28046, epoch: 102, loss: 0.569131
global_step: 28047, epoch: 102, loss: 0.496395
global_step: 28048, epoch: 102, loss: 0.500048
global_step: 28049, epoch: 102, loss: 0.590328
global_step: 28050, epoch: 102, loss: 0.585949
global_step: 28051, epoch: 102, loss: 0.559490
global_step: 28052, epoch: 102, loss: 0.523971
global_step: 28053, epoch: 102, loss: 0.570474
global_step: 28054, epoch: 102, loss: 0.554267
global_step: 28055, epoch: 102, loss: 0.447280
global_step: 28056, epoch: 102, loss: 0.515466
global_step: 28057, epoch: 102, loss: 0.443318
global_step: 28058, epoch: 102, loss: 0.593674
global_step: 28059, epoch: 102, loss: 0.511595
global_step: 28060, epoch: 102, loss: 0.571881
global_step: 28061, epoch: 102, loss: 0.565739
global_step: 28062, epoch: 102, loss: 0.609979
global_step: 28063, epoch: 102, loss: 0.442730
global_step: 28064, epoch: 102, loss: 0.547812
global_step: 28065, epoch: 102, loss: 0.470934
global_step: 28066, epoch: 102, loss: 0.516029
global_step: 28067, epoch: 102, loss: 0.469151
global_step: 28068, epoch: 102, loss: 0.473514
global_step: 28069, epoch: 102, loss: 0.519231
global_step: 28070, epoch: 102, loss: 0.538454
global_step: 28071, epoch: 102, loss: 0.509365
global_step: 28072, epoch: 102, loss: 0.489801
global_step: 28073, epoch: 102, loss: 0.594141
global_step: 28074, epoch: 102, loss: 0.577814
global_step: 28075, epoch: 102, loss: 0.531406
global_step: 28076, epoch: 102, loss: 0.640225
global_step: 28077, epoch: 102, loss: 0.557445
global_step: 28078, epoch: 102, loss: 0.487910
global_step: 28079, epoch: 102, loss: 0.533272
global_step: 28080, epoch: 102, loss: 1.083680
epoch: 102
train	acc: 0.8800	macro: p 0.8639, r 0.6718, f1: 0.6866	micro: p 0.8800, r 0.8800, f1 0.8800	weighted_f1:0.8648
dev	acc: 0.5672	macro: p 0.3939, r 0.3370, f1: 0.3458	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5268
test	acc: 0.6103	macro: p 0.3964, r 0.3429, f1: 0.3538	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5777
global_step: 28081, epoch: 103, loss: 0.541220
global_step: 28082, epoch: 103, loss: 0.439660
global_step: 28083, epoch: 103, loss: 0.629515
global_step: 28084, epoch: 103, loss: 0.539936
global_step: 28085, epoch: 103, loss: 0.587303
global_step: 28086, epoch: 103, loss: 0.528625
global_step: 28087, epoch: 103, loss: 0.591509
global_step: 28088, epoch: 103, loss: 0.516278
global_step: 28089, epoch: 103, loss: 0.539860
global_step: 28090, epoch: 103, loss: 0.458570
global_step: 28091, epoch: 103, loss: 0.505535
global_step: 28092, epoch: 103, loss: 0.519799
global_step: 28093, epoch: 103, loss: 0.533376
global_step: 28094, epoch: 103, loss: 0.513021
global_step: 28095, epoch: 103, loss: 0.487451
global_step: 28096, epoch: 103, loss: 0.485655
global_step: 28097, epoch: 103, loss: 0.604027
global_step: 28098, epoch: 103, loss: 0.445888
global_step: 28099, epoch: 103, loss: 0.505303
global_step: 28100, epoch: 103, loss: 0.427631
global_step: 28101, epoch: 103, loss: 0.546672
global_step: 28102, epoch: 103, loss: 0.455399
global_step: 28103, epoch: 103, loss: 0.588117
global_step: 28104, epoch: 103, loss: 0.591364
global_step: 28105, epoch: 103, loss: 0.492192
global_step: 28106, epoch: 103, loss: 0.471687
global_step: 28107, epoch: 103, loss: 0.548328
global_step: 28108, epoch: 103, loss: 0.537161
global_step: 28109, epoch: 103, loss: 0.546003
global_step: 28110, epoch: 103, loss: 0.499146
global_step: 28111, epoch: 103, loss: 0.605842
global_step: 28112, epoch: 103, loss: 0.498430
global_step: 28113, epoch: 103, loss: 0.453006
global_step: 28114, epoch: 103, loss: 0.556812
global_step: 28115, epoch: 103, loss: 0.561200
global_step: 28116, epoch: 103, loss: 0.579087
global_step: 28117, epoch: 103, loss: 0.560557
global_step: 28118, epoch: 103, loss: 0.528647
global_step: 28119, epoch: 103, loss: 0.617958
global_step: 28120, epoch: 103, loss: 1.090203
epoch: 103
train	acc: 0.8915	macro: p 0.8686, r 0.6937, f1: 0.7054	micro: p 0.8915, r 0.8915, f1 0.8915	weighted_f1:0.8774
dev	acc: 0.5699	macro: p 0.5489, r 0.3561, f1: 0.3656	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5335
test	acc: 0.6038	macro: p 0.3933, r 0.3514, f1: 0.3579	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5767
global_step: 28121, epoch: 104, loss: 0.526065
global_step: 28122, epoch: 104, loss: 0.531670
global_step: 28123, epoch: 104, loss: 0.507477
global_step: 28124, epoch: 104, loss: 0.443891
global_step: 28125, epoch: 104, loss: 0.484728
global_step: 28126, epoch: 104, loss: 0.580493
global_step: 28127, epoch: 104, loss: 0.480605
global_step: 28128, epoch: 104, loss: 0.527873
global_step: 28129, epoch: 104, loss: 0.566326
global_step: 28130, epoch: 104, loss: 0.604677
global_step: 28131, epoch: 104, loss: 0.544890
global_step: 28132, epoch: 104, loss: 0.567422
global_step: 28133, epoch: 104, loss: 0.472287
global_step: 28134, epoch: 104, loss: 0.475591
global_step: 28135, epoch: 104, loss: 0.466144
global_step: 28136, epoch: 104, loss: 0.572578
global_step: 28137, epoch: 104, loss: 0.409512
global_step: 28138, epoch: 104, loss: 0.559246
global_step: 28139, epoch: 104, loss: 0.567257
global_step: 28140, epoch: 104, loss: 0.660425
global_step: 28141, epoch: 104, loss: 0.553583
global_step: 28142, epoch: 104, loss: 0.516182
global_step: 28143, epoch: 104, loss: 0.522060
global_step: 28144, epoch: 104, loss: 0.511567
global_step: 28145, epoch: 104, loss: 0.605807
global_step: 28146, epoch: 104, loss: 0.536424
global_step: 28147, epoch: 104, loss: 0.534355
global_step: 28148, epoch: 104, loss: 0.526147
global_step: 28149, epoch: 104, loss: 0.488551
global_step: 28150, epoch: 104, loss: 0.482740
global_step: 28151, epoch: 104, loss: 0.481889
global_step: 28152, epoch: 104, loss: 0.442278
global_step: 28153, epoch: 104, loss: 0.534302
global_step: 28154, epoch: 104, loss: 0.477198
global_step: 28155, epoch: 104, loss: 0.532338
global_step: 28156, epoch: 104, loss: 0.525833
global_step: 28157, epoch: 104, loss: 0.456011
global_step: 28158, epoch: 104, loss: 0.540267
global_step: 28159, epoch: 104, loss: 0.574849
global_step: 28160, epoch: 104, loss: 0.033817
epoch: 104
train	acc: 0.8887	macro: p 0.8646, r 0.6893, f1: 0.7002	micro: p 0.8887, r 0.8887, f1 0.8887	weighted_f1:0.8741
dev	acc: 0.5753	macro: p 0.4004, r 0.3533, f1: 0.3575	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5382
test	acc: 0.6088	macro: p 0.3932, r 0.3503, f1: 0.3560	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5802
global_step: 28161, epoch: 105, loss: 0.474091
global_step: 28162, epoch: 105, loss: 0.539354
global_step: 28163, epoch: 105, loss: 0.502033
global_step: 28164, epoch: 105, loss: 0.417568
global_step: 28165, epoch: 105, loss: 0.543873
global_step: 28166, epoch: 105, loss: 0.507150
global_step: 28167, epoch: 105, loss: 0.525945
global_step: 28168, epoch: 105, loss: 0.483775
global_step: 28169, epoch: 105, loss: 0.445069
global_step: 28170, epoch: 105, loss: 0.418808
global_step: 28171, epoch: 105, loss: 0.547155
global_step: 28172, epoch: 105, loss: 0.453383
global_step: 28173, epoch: 105, loss: 0.572700
global_step: 28174, epoch: 105, loss: 0.492515
global_step: 28175, epoch: 105, loss: 0.512081
global_step: 28176, epoch: 105, loss: 0.518869
global_step: 28177, epoch: 105, loss: 0.506530
global_step: 28178, epoch: 105, loss: 0.454758
global_step: 28179, epoch: 105, loss: 0.546472
global_step: 28180, epoch: 105, loss: 0.509608
global_step: 28181, epoch: 105, loss: 0.507616
global_step: 28182, epoch: 105, loss: 0.454074
global_step: 28183, epoch: 105, loss: 0.539192
global_step: 28184, epoch: 105, loss: 0.489764
global_step: 28185, epoch: 105, loss: 0.476026
global_step: 28186, epoch: 105, loss: 0.560327
global_step: 28187, epoch: 105, loss: 0.508582
global_step: 28188, epoch: 105, loss: 0.488660
global_step: 28189, epoch: 105, loss: 0.511668
global_step: 28190, epoch: 105, loss: 0.518244
global_step: 28191, epoch: 105, loss: 0.576461
global_step: 28192, epoch: 105, loss: 0.507612
global_step: 28193, epoch: 105, loss: 0.540791
global_step: 28194, epoch: 105, loss: 0.514177
global_step: 28195, epoch: 105, loss: 0.575365
global_step: 28196, epoch: 105, loss: 0.602232
global_step: 28197, epoch: 105, loss: 0.613724
global_step: 28198, epoch: 105, loss: 0.552645
global_step: 28199, epoch: 105, loss: 0.559156
global_step: 28200, epoch: 105, loss: 0.675938
epoch: 105
train	acc: 0.8934	macro: p 0.8605, r 0.7084, f1: 0.7223	micro: p 0.8934, r 0.8934, f1 0.8934	weighted_f1:0.8813
dev	acc: 0.5834	macro: p 0.5465, r 0.3665, f1: 0.3717	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5488
test	acc: 0.6096	macro: p 0.4394, r 0.3630, f1: 0.3673	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5841
New best model!
global_step: 28201, epoch: 106, loss: 0.542801
global_step: 28202, epoch: 106, loss: 0.576377
global_step: 28203, epoch: 106, loss: 0.499389
global_step: 28204, epoch: 106, loss: 0.520464
global_step: 28205, epoch: 106, loss: 0.506518
global_step: 28206, epoch: 106, loss: 0.447086
global_step: 28207, epoch: 106, loss: 0.497374
global_step: 28208, epoch: 106, loss: 0.492049
global_step: 28209, epoch: 106, loss: 0.511766
global_step: 28210, epoch: 106, loss: 0.588464
global_step: 28211, epoch: 106, loss: 0.472459
global_step: 28212, epoch: 106, loss: 0.505035
global_step: 28213, epoch: 106, loss: 0.533517
global_step: 28214, epoch: 106, loss: 0.503365
global_step: 28215, epoch: 106, loss: 0.546879
global_step: 28216, epoch: 106, loss: 0.511043
global_step: 28217, epoch: 106, loss: 0.598912
global_step: 28218, epoch: 106, loss: 0.473026
global_step: 28219, epoch: 106, loss: 0.514480
global_step: 28220, epoch: 106, loss: 0.504843
global_step: 28221, epoch: 106, loss: 0.527176
global_step: 28222, epoch: 106, loss: 0.463096
global_step: 28223, epoch: 106, loss: 0.587460
global_step: 28224, epoch: 106, loss: 0.490949
global_step: 28225, epoch: 106, loss: 0.484869
global_step: 28226, epoch: 106, loss: 0.552252
global_step: 28227, epoch: 106, loss: 0.528004
global_step: 28228, epoch: 106, loss: 0.569748
global_step: 28229, epoch: 106, loss: 0.425225
global_step: 28230, epoch: 106, loss: 0.521769
global_step: 28231, epoch: 106, loss: 0.567444
global_step: 28232, epoch: 106, loss: 0.531944
global_step: 28233, epoch: 106, loss: 0.632146
global_step: 28234, epoch: 106, loss: 0.552312
global_step: 28235, epoch: 106, loss: 0.444437
global_step: 28236, epoch: 106, loss: 0.450381
global_step: 28237, epoch: 106, loss: 0.577515
global_step: 28238, epoch: 106, loss: 0.444461
global_step: 28239, epoch: 106, loss: 0.440883
global_step: 28240, epoch: 106, loss: 0.736477
epoch: 106
train	acc: 0.8913	macro: p 0.8699, r 0.7088, f1: 0.7269	micro: p 0.8913, r 0.8913, f1 0.8913	weighted_f1:0.8794
dev	acc: 0.5762	macro: p 0.4108, r 0.3572, f1: 0.3655	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5397
test	acc: 0.6080	macro: p 0.3861, r 0.3522, f1: 0.3580	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5796
global_step: 28241, epoch: 107, loss: 0.545408
global_step: 28242, epoch: 107, loss: 0.502754
global_step: 28243, epoch: 107, loss: 0.500257
global_step: 28244, epoch: 107, loss: 0.451801
global_step: 28245, epoch: 107, loss: 0.556879
global_step: 28246, epoch: 107, loss: 0.560295
global_step: 28247, epoch: 107, loss: 0.452714
global_step: 28248, epoch: 107, loss: 0.491929
global_step: 28249, epoch: 107, loss: 0.466311
global_step: 28250, epoch: 107, loss: 0.597896
global_step: 28251, epoch: 107, loss: 0.501797
global_step: 28252, epoch: 107, loss: 0.624978
global_step: 28253, epoch: 107, loss: 0.487903
global_step: 28254, epoch: 107, loss: 0.430379
global_step: 28255, epoch: 107, loss: 0.484322
global_step: 28256, epoch: 107, loss: 0.508322
global_step: 28257, epoch: 107, loss: 0.465606
global_step: 28258, epoch: 107, loss: 0.475676
global_step: 28259, epoch: 107, loss: 0.599567
global_step: 28260, epoch: 107, loss: 0.499907
global_step: 28261, epoch: 107, loss: 0.605818
global_step: 28262, epoch: 107, loss: 0.550560
global_step: 28263, epoch: 107, loss: 0.506310
global_step: 28264, epoch: 107, loss: 0.546524
global_step: 28265, epoch: 107, loss: 0.570078
global_step: 28266, epoch: 107, loss: 0.483752
global_step: 28267, epoch: 107, loss: 0.527429
global_step: 28268, epoch: 107, loss: 0.502325
global_step: 28269, epoch: 107, loss: 0.525864
global_step: 28270, epoch: 107, loss: 0.545277
global_step: 28271, epoch: 107, loss: 0.523163
global_step: 28272, epoch: 107, loss: 0.503223
global_step: 28273, epoch: 107, loss: 0.373049
global_step: 28274, epoch: 107, loss: 0.443650
global_step: 28275, epoch: 107, loss: 0.516184
global_step: 28276, epoch: 107, loss: 0.426321
global_step: 28277, epoch: 107, loss: 0.469034
global_step: 28278, epoch: 107, loss: 0.529196
global_step: 28279, epoch: 107, loss: 0.503391
global_step: 28280, epoch: 107, loss: 0.401468
epoch: 107
train	acc: 0.8989	macro: p 0.8782, r 0.7294, f1: 0.7545	micro: p 0.8989, r 0.8989, f1 0.8989	weighted_f1:0.8893
dev	acc: 0.5762	macro: p 0.4023, r 0.3626, f1: 0.3689	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5414
test	acc: 0.6119	macro: p 0.4215, r 0.3613, f1: 0.3704	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5855
global_step: 28281, epoch: 108, loss: 0.520869
global_step: 28282, epoch: 108, loss: 0.443286
global_step: 28283, epoch: 108, loss: 0.483670
global_step: 28284, epoch: 108, loss: 0.379288
global_step: 28285, epoch: 108, loss: 0.408798
global_step: 28286, epoch: 108, loss: 0.491399
global_step: 28287, epoch: 108, loss: 0.519874
global_step: 28288, epoch: 108, loss: 0.511236
global_step: 28289, epoch: 108, loss: 0.492889
global_step: 28290, epoch: 108, loss: 0.472007
global_step: 28291, epoch: 108, loss: 0.510656
global_step: 28292, epoch: 108, loss: 0.460664
global_step: 28293, epoch: 108, loss: 0.549922
global_step: 28294, epoch: 108, loss: 0.517837
global_step: 28295, epoch: 108, loss: 0.500528
global_step: 28296, epoch: 108, loss: 0.510318
global_step: 28297, epoch: 108, loss: 0.474879
global_step: 28298, epoch: 108, loss: 0.572199
global_step: 28299, epoch: 108, loss: 0.430191
global_step: 28300, epoch: 108, loss: 0.517346
global_step: 28301, epoch: 108, loss: 0.540257
global_step: 28302, epoch: 108, loss: 0.536708
global_step: 28303, epoch: 108, loss: 0.519069
global_step: 28304, epoch: 108, loss: 0.493696
global_step: 28305, epoch: 108, loss: 0.562443
global_step: 28306, epoch: 108, loss: 0.480988
global_step: 28307, epoch: 108, loss: 0.500654
global_step: 28308, epoch: 108, loss: 0.565031
global_step: 28309, epoch: 108, loss: 0.473695
global_step: 28310, epoch: 108, loss: 0.377276
global_step: 28311, epoch: 108, loss: 0.496075
global_step: 28312, epoch: 108, loss: 0.567852
global_step: 28313, epoch: 108, loss: 0.499442
global_step: 28314, epoch: 108, loss: 0.527590
global_step: 28315, epoch: 108, loss: 0.542040
global_step: 28316, epoch: 108, loss: 0.548568
global_step: 28317, epoch: 108, loss: 0.505434
global_step: 28318, epoch: 108, loss: 0.488751
global_step: 28319, epoch: 108, loss: 0.497614
global_step: 28320, epoch: 108, loss: 0.600312
epoch: 108
train	acc: 0.8704	macro: p 0.8762, r 0.6681, f1: 0.7020	micro: p 0.8704, r 0.8704, f1 0.8704	weighted_f1:0.8563
dev	acc: 0.5600	macro: p 0.4032, r 0.3215, f1: 0.3303	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5081
test	acc: 0.6050	macro: p 0.4311, r 0.3233, f1: 0.3393	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5579
global_step: 28321, epoch: 109, loss: 0.535742
global_step: 28322, epoch: 109, loss: 0.554731
global_step: 28323, epoch: 109, loss: 0.479052
global_step: 28324, epoch: 109, loss: 0.535431
global_step: 28325, epoch: 109, loss: 0.396337
global_step: 28326, epoch: 109, loss: 0.568195
global_step: 28327, epoch: 109, loss: 0.432331
global_step: 28328, epoch: 109, loss: 0.559557
global_step: 28329, epoch: 109, loss: 0.474997
global_step: 28330, epoch: 109, loss: 0.522578
global_step: 28331, epoch: 109, loss: 0.392589
global_step: 28332, epoch: 109, loss: 0.409738
global_step: 28333, epoch: 109, loss: 0.567031
global_step: 28334, epoch: 109, loss: 0.481086
global_step: 28335, epoch: 109, loss: 0.532346
global_step: 28336, epoch: 109, loss: 0.456568
global_step: 28337, epoch: 109, loss: 0.484311
global_step: 28338, epoch: 109, loss: 0.537834
global_step: 28339, epoch: 109, loss: 0.520768
global_step: 28340, epoch: 109, loss: 0.456057
global_step: 28341, epoch: 109, loss: 0.507586
global_step: 28342, epoch: 109, loss: 0.429751
global_step: 28343, epoch: 109, loss: 0.639249
global_step: 28344, epoch: 109, loss: 0.451063
global_step: 28345, epoch: 109, loss: 0.454060
global_step: 28346, epoch: 109, loss: 0.543904
global_step: 28347, epoch: 109, loss: 0.459858
global_step: 28348, epoch: 109, loss: 0.532385
global_step: 28349, epoch: 109, loss: 0.499550
global_step: 28350, epoch: 109, loss: 0.464261
global_step: 28351, epoch: 109, loss: 0.401942
global_step: 28352, epoch: 109, loss: 0.510695
global_step: 28353, epoch: 109, loss: 0.586028
global_step: 28354, epoch: 109, loss: 0.538943
global_step: 28355, epoch: 109, loss: 0.527206
global_step: 28356, epoch: 109, loss: 0.489624
global_step: 28357, epoch: 109, loss: 0.496786
global_step: 28358, epoch: 109, loss: 0.515445
global_step: 28359, epoch: 109, loss: 0.439229
global_step: 28360, epoch: 109, loss: 0.410420
epoch: 109
train	acc: 0.8967	macro: p 0.8764, r 0.7132, f1: 0.7315	micro: p 0.8967, r 0.8967, f1 0.8967	weighted_f1:0.8852
dev	acc: 0.5735	macro: p 0.5481, r 0.3583, f1: 0.3702	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5367
test	acc: 0.6092	macro: p 0.4004, r 0.3533, f1: 0.3603	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5803
global_step: 28361, epoch: 110, loss: 0.367389
global_step: 28362, epoch: 110, loss: 0.533649
global_step: 28363, epoch: 110, loss: 0.531301
global_step: 28364, epoch: 110, loss: 0.461990
global_step: 28365, epoch: 110, loss: 0.484262
global_step: 28366, epoch: 110, loss: 0.512555
global_step: 28367, epoch: 110, loss: 0.445370
global_step: 28368, epoch: 110, loss: 0.382776
global_step: 28369, epoch: 110, loss: 0.462222
global_step: 28370, epoch: 110, loss: 0.503034
global_step: 28371, epoch: 110, loss: 0.575482
global_step: 28372, epoch: 110, loss: 0.459527
global_step: 28373, epoch: 110, loss: 0.457761
global_step: 28374, epoch: 110, loss: 0.383797
global_step: 28375, epoch: 110, loss: 0.419973
global_step: 28376, epoch: 110, loss: 0.535708
global_step: 28377, epoch: 110, loss: 0.558422
global_step: 28378, epoch: 110, loss: 0.450788
global_step: 28379, epoch: 110, loss: 0.493465
global_step: 28380, epoch: 110, loss: 0.517932
global_step: 28381, epoch: 110, loss: 0.477763
global_step: 28382, epoch: 110, loss: 0.502466
global_step: 28383, epoch: 110, loss: 0.547996
global_step: 28384, epoch: 110, loss: 0.448957
global_step: 28385, epoch: 110, loss: 0.475319
global_step: 28386, epoch: 110, loss: 0.443950
global_step: 28387, epoch: 110, loss: 0.510831
global_step: 28388, epoch: 110, loss: 0.468961
global_step: 28389, epoch: 110, loss: 0.496072
global_step: 28390, epoch: 110, loss: 0.420122
global_step: 28391, epoch: 110, loss: 0.568807
global_step: 28392, epoch: 110, loss: 0.490518
global_step: 28393, epoch: 110, loss: 0.562017
global_step: 28394, epoch: 110, loss: 0.442416
global_step: 28395, epoch: 110, loss: 0.458305
global_step: 28396, epoch: 110, loss: 0.608803
global_step: 28397, epoch: 110, loss: 0.494603
global_step: 28398, epoch: 110, loss: 0.553515
global_step: 28399, epoch: 110, loss: 0.536380
global_step: 28400, epoch: 110, loss: 0.151167
epoch: 110
train	acc: 0.8931	macro: p 0.8780, r 0.7054, f1: 0.7243	micro: p 0.8931, r 0.8931, f1 0.8931	weighted_f1:0.8810
dev	acc: 0.5573	macro: p 0.5517, r 0.3515, f1: 0.3533	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5220
test	acc: 0.5931	macro: p 0.3957, r 0.3502, f1: 0.3496	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5681
global_step: 28401, epoch: 111, loss: 0.475147
global_step: 28402, epoch: 111, loss: 0.400525
global_step: 28403, epoch: 111, loss: 0.411826
global_step: 28404, epoch: 111, loss: 0.534292
global_step: 28405, epoch: 111, loss: 0.459767
global_step: 28406, epoch: 111, loss: 0.419057
global_step: 28407, epoch: 111, loss: 0.422093
global_step: 28408, epoch: 111, loss: 0.449769
global_step: 28409, epoch: 111, loss: 0.561661
global_step: 28410, epoch: 111, loss: 0.602719
global_step: 28411, epoch: 111, loss: 0.444856
global_step: 28412, epoch: 111, loss: 0.503748
global_step: 28413, epoch: 111, loss: 0.552993
global_step: 28414, epoch: 111, loss: 0.553554
global_step: 28415, epoch: 111, loss: 0.372266
global_step: 28416, epoch: 111, loss: 0.487213
global_step: 28417, epoch: 111, loss: 0.443475
global_step: 28418, epoch: 111, loss: 0.510044
global_step: 28419, epoch: 111, loss: 0.568429
global_step: 28420, epoch: 111, loss: 0.539908
global_step: 28421, epoch: 111, loss: 0.490954
global_step: 28422, epoch: 111, loss: 0.474512
global_step: 28423, epoch: 111, loss: 0.415324
global_step: 28424, epoch: 111, loss: 0.490139
global_step: 28425, epoch: 111, loss: 0.443266
global_step: 28426, epoch: 111, loss: 0.393633
global_step: 28427, epoch: 111, loss: 0.487343
global_step: 28428, epoch: 111, loss: 0.534653
global_step: 28429, epoch: 111, loss: 0.505762
global_step: 28430, epoch: 111, loss: 0.521592
global_step: 28431, epoch: 111, loss: 0.446703
global_step: 28432, epoch: 111, loss: 0.457677
global_step: 28433, epoch: 111, loss: 0.550485
global_step: 28434, epoch: 111, loss: 0.552888
global_step: 28435, epoch: 111, loss: 0.522100
global_step: 28436, epoch: 111, loss: 0.496989
global_step: 28437, epoch: 111, loss: 0.570050
global_step: 28438, epoch: 111, loss: 0.408636
global_step: 28439, epoch: 111, loss: 0.521746
global_step: 28440, epoch: 111, loss: 0.970183
epoch: 111
train	acc: 0.8983	macro: p 0.8936, r 0.7115, f1: 0.7347	micro: p 0.8983, r 0.8983, f1 0.8983	weighted_f1:0.8862
dev	acc: 0.5690	macro: p 0.5535, r 0.3499, f1: 0.3623	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5292
test	acc: 0.6038	macro: p 0.3935, r 0.3394, f1: 0.3498	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5699
global_step: 28441, epoch: 112, loss: 0.469121
global_step: 28442, epoch: 112, loss: 0.469511
global_step: 28443, epoch: 112, loss: 0.499053
global_step: 28444, epoch: 112, loss: 0.405843
global_step: 28445, epoch: 112, loss: 0.485639
global_step: 28446, epoch: 112, loss: 0.427046
global_step: 28447, epoch: 112, loss: 0.390747
global_step: 28448, epoch: 112, loss: 0.461899
global_step: 28449, epoch: 112, loss: 0.548160
global_step: 28450, epoch: 112, loss: 0.409784
global_step: 28451, epoch: 112, loss: 0.465579
global_step: 28452, epoch: 112, loss: 0.498635
global_step: 28453, epoch: 112, loss: 0.510871
global_step: 28454, epoch: 112, loss: 0.442589
global_step: 28455, epoch: 112, loss: 0.445767
global_step: 28456, epoch: 112, loss: 0.448993
global_step: 28457, epoch: 112, loss: 0.492803
global_step: 28458, epoch: 112, loss: 0.495492
global_step: 28459, epoch: 112, loss: 0.464715
global_step: 28460, epoch: 112, loss: 0.494777
global_step: 28461, epoch: 112, loss: 0.454554
global_step: 28462, epoch: 112, loss: 0.379313
global_step: 28463, epoch: 112, loss: 0.458739
global_step: 28464, epoch: 112, loss: 0.495099
global_step: 28465, epoch: 112, loss: 0.503789
global_step: 28466, epoch: 112, loss: 0.488571
global_step: 28467, epoch: 112, loss: 0.577811
global_step: 28468, epoch: 112, loss: 0.472977
global_step: 28469, epoch: 112, loss: 0.475636
global_step: 28470, epoch: 112, loss: 0.477175
global_step: 28471, epoch: 112, loss: 0.496602
global_step: 28472, epoch: 112, loss: 0.395220
global_step: 28473, epoch: 112, loss: 0.449982
global_step: 28474, epoch: 112, loss: 0.488758
global_step: 28475, epoch: 112, loss: 0.476460
global_step: 28476, epoch: 112, loss: 0.465058
global_step: 28477, epoch: 112, loss: 0.519578
global_step: 28478, epoch: 112, loss: 0.457119
global_step: 28479, epoch: 112, loss: 0.529280
global_step: 28480, epoch: 112, loss: 0.143324
epoch: 112
train	acc: 0.9021	macro: p 0.8890, r 0.7296, f1: 0.7509	micro: p 0.9021, r 0.9021, f1 0.9021	weighted_f1:0.8919
dev	acc: 0.5708	macro: p 0.5539, r 0.3587, f1: 0.3672	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5337
test	acc: 0.6038	macro: p 0.3868, r 0.3518, f1: 0.3555	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5762
global_step: 28481, epoch: 113, loss: 0.507426
global_step: 28482, epoch: 113, loss: 0.539647
global_step: 28483, epoch: 113, loss: 0.481823
global_step: 28484, epoch: 113, loss: 0.481261
global_step: 28485, epoch: 113, loss: 0.521158
global_step: 28486, epoch: 113, loss: 0.521908
global_step: 28487, epoch: 113, loss: 0.387784
global_step: 28488, epoch: 113, loss: 0.468670
global_step: 28489, epoch: 113, loss: 0.502204
global_step: 28490, epoch: 113, loss: 0.481647
global_step: 28491, epoch: 113, loss: 0.485458
global_step: 28492, epoch: 113, loss: 0.476526
global_step: 28493, epoch: 113, loss: 0.390889
global_step: 28494, epoch: 113, loss: 0.462528
global_step: 28495, epoch: 113, loss: 0.487264
global_step: 28496, epoch: 113, loss: 0.484597
global_step: 28497, epoch: 113, loss: 0.482643
global_step: 28498, epoch: 113, loss: 0.455937
global_step: 28499, epoch: 113, loss: 0.440033
global_step: 28500, epoch: 113, loss: 0.443593
global_step: 28501, epoch: 113, loss: 0.465832
global_step: 28502, epoch: 113, loss: 0.503162
global_step: 28503, epoch: 113, loss: 0.417753
global_step: 28504, epoch: 113, loss: 0.415188
global_step: 28505, epoch: 113, loss: 0.518765
global_step: 28506, epoch: 113, loss: 0.473890
global_step: 28507, epoch: 113, loss: 0.527734
global_step: 28508, epoch: 113, loss: 0.470188
global_step: 28509, epoch: 113, loss: 0.477207
global_step: 28510, epoch: 113, loss: 0.447446
global_step: 28511, epoch: 113, loss: 0.476396
global_step: 28512, epoch: 113, loss: 0.585508
global_step: 28513, epoch: 113, loss: 0.426217
global_step: 28514, epoch: 113, loss: 0.527520
global_step: 28515, epoch: 113, loss: 0.453665
global_step: 28516, epoch: 113, loss: 0.495754
global_step: 28517, epoch: 113, loss: 0.508021
global_step: 28518, epoch: 113, loss: 0.484906
global_step: 28519, epoch: 113, loss: 0.411851
global_step: 28520, epoch: 113, loss: 0.929031
epoch: 113
train	acc: 0.8879	macro: p 0.9019, r 0.6961, f1: 0.7221	micro: p 0.8879, r 0.8879, f1 0.8879	weighted_f1:0.8749
dev	acc: 0.5636	macro: p 0.5837, r 0.3365, f1: 0.3525	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5171
test	acc: 0.6077	macro: p 0.4234, r 0.3324, f1: 0.3485	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5667
global_step: 28521, epoch: 114, loss: 0.580841
global_step: 28522, epoch: 114, loss: 0.481952
global_step: 28523, epoch: 114, loss: 0.524246
global_step: 28524, epoch: 114, loss: 0.429481
global_step: 28525, epoch: 114, loss: 0.451196
global_step: 28526, epoch: 114, loss: 0.440063
global_step: 28527, epoch: 114, loss: 0.515759
global_step: 28528, epoch: 114, loss: 0.446537
global_step: 28529, epoch: 114, loss: 0.483403
global_step: 28530, epoch: 114, loss: 0.527613
global_step: 28531, epoch: 114, loss: 0.464068
global_step: 28532, epoch: 114, loss: 0.515474
global_step: 28533, epoch: 114, loss: 0.502660
global_step: 28534, epoch: 114, loss: 0.481568
global_step: 28535, epoch: 114, loss: 0.461978
global_step: 28536, epoch: 114, loss: 0.523014
global_step: 28537, epoch: 114, loss: 0.448063
global_step: 28538, epoch: 114, loss: 0.475586
global_step: 28539, epoch: 114, loss: 0.581223
global_step: 28540, epoch: 114, loss: 0.473932
global_step: 28541, epoch: 114, loss: 0.480307
global_step: 28542, epoch: 114, loss: 0.387816
global_step: 28543, epoch: 114, loss: 0.453843
global_step: 28544, epoch: 114, loss: 0.418893
global_step: 28545, epoch: 114, loss: 0.538808
global_step: 28546, epoch: 114, loss: 0.447817
global_step: 28547, epoch: 114, loss: 0.464270
global_step: 28548, epoch: 114, loss: 0.462482
global_step: 28549, epoch: 114, loss: 0.545975
global_step: 28550, epoch: 114, loss: 0.479112
global_step: 28551, epoch: 114, loss: 0.475134
global_step: 28552, epoch: 114, loss: 0.414649
global_step: 28553, epoch: 114, loss: 0.378438
global_step: 28554, epoch: 114, loss: 0.494398
global_step: 28555, epoch: 114, loss: 0.388036
global_step: 28556, epoch: 114, loss: 0.427157
global_step: 28557, epoch: 114, loss: 0.368062
global_step: 28558, epoch: 114, loss: 0.469314
global_step: 28559, epoch: 114, loss: 0.412820
global_step: 28560, epoch: 114, loss: 0.993508
epoch: 114
train	acc: 0.8984	macro: p 0.8805, r 0.7285, f1: 0.7430	micro: p 0.8984, r 0.8984, f1 0.8984	weighted_f1:0.8881
dev	acc: 0.5437	macro: p 0.5308, r 0.3545, f1: 0.3527	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5173
test	acc: 0.5824	macro: p 0.3821, r 0.3608, f1: 0.3550	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5676
global_step: 28561, epoch: 115, loss: 0.471925
global_step: 28562, epoch: 115, loss: 0.495299
global_step: 28563, epoch: 115, loss: 0.488657
global_step: 28564, epoch: 115, loss: 0.422559
global_step: 28565, epoch: 115, loss: 0.463770
global_step: 28566, epoch: 115, loss: 0.525637
global_step: 28567, epoch: 115, loss: 0.455737
global_step: 28568, epoch: 115, loss: 0.444486
global_step: 28569, epoch: 115, loss: 0.498831
global_step: 28570, epoch: 115, loss: 0.408119
global_step: 28571, epoch: 115, loss: 0.460837
global_step: 28572, epoch: 115, loss: 0.460909
global_step: 28573, epoch: 115, loss: 0.512758
global_step: 28574, epoch: 115, loss: 0.395404
global_step: 28575, epoch: 115, loss: 0.389168
global_step: 28576, epoch: 115, loss: 0.507600
global_step: 28577, epoch: 115, loss: 0.457690
global_step: 28578, epoch: 115, loss: 0.427430
global_step: 28579, epoch: 115, loss: 0.485869
global_step: 28580, epoch: 115, loss: 0.488887
global_step: 28581, epoch: 115, loss: 0.484293
global_step: 28582, epoch: 115, loss: 0.584716
global_step: 28583, epoch: 115, loss: 0.426569
global_step: 28584, epoch: 115, loss: 0.480460
global_step: 28585, epoch: 115, loss: 0.424530
global_step: 28586, epoch: 115, loss: 0.381302
global_step: 28587, epoch: 115, loss: 0.451648
global_step: 28588, epoch: 115, loss: 0.451032
global_step: 28589, epoch: 115, loss: 0.468392
global_step: 28590, epoch: 115, loss: 0.537376
global_step: 28591, epoch: 115, loss: 0.532822
global_step: 28592, epoch: 115, loss: 0.422909
global_step: 28593, epoch: 115, loss: 0.421543
global_step: 28594, epoch: 115, loss: 0.470231
global_step: 28595, epoch: 115, loss: 0.455614
global_step: 28596, epoch: 115, loss: 0.499194
global_step: 28597, epoch: 115, loss: 0.451836
global_step: 28598, epoch: 115, loss: 0.405231
global_step: 28599, epoch: 115, loss: 0.451195
global_step: 28600, epoch: 115, loss: 0.127707
epoch: 115
train	acc: 0.9009	macro: p 0.8839, r 0.7276, f1: 0.7510	micro: p 0.9009, r 0.9009, f1 0.9009	weighted_f1:0.8906
dev	acc: 0.5645	macro: p 0.5474, r 0.3458, f1: 0.3566	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5251
test	acc: 0.6019	macro: p 0.3927, r 0.3417, f1: 0.3499	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5711
global_step: 28601, epoch: 116, loss: 0.422452
global_step: 28602, epoch: 116, loss: 0.490013
global_step: 28603, epoch: 116, loss: 0.422408
global_step: 28604, epoch: 116, loss: 0.450990
global_step: 28605, epoch: 116, loss: 0.443557
global_step: 28606, epoch: 116, loss: 0.512176
global_step: 28607, epoch: 116, loss: 0.461634
global_step: 28608, epoch: 116, loss: 0.435633
global_step: 28609, epoch: 116, loss: 0.424824
global_step: 28610, epoch: 116, loss: 0.451384
global_step: 28611, epoch: 116, loss: 0.487116
global_step: 28612, epoch: 116, loss: 0.406915
global_step: 28613, epoch: 116, loss: 0.421828
global_step: 28614, epoch: 116, loss: 0.421179
global_step: 28615, epoch: 116, loss: 0.536012
global_step: 28616, epoch: 116, loss: 0.403268
global_step: 28617, epoch: 116, loss: 0.518968
global_step: 28618, epoch: 116, loss: 0.486140
global_step: 28619, epoch: 116, loss: 0.515582
global_step: 28620, epoch: 116, loss: 0.400061
global_step: 28621, epoch: 116, loss: 0.490296
global_step: 28622, epoch: 116, loss: 0.518053
global_step: 28623, epoch: 116, loss: 0.482447
global_step: 28624, epoch: 116, loss: 0.445289
global_step: 28625, epoch: 116, loss: 0.456571
global_step: 28626, epoch: 116, loss: 0.555907
global_step: 28627, epoch: 116, loss: 0.452707
global_step: 28628, epoch: 116, loss: 0.451896
global_step: 28629, epoch: 116, loss: 0.450467
global_step: 28630, epoch: 116, loss: 0.421109
global_step: 28631, epoch: 116, loss: 0.434540
global_step: 28632, epoch: 116, loss: 0.426846
global_step: 28633, epoch: 116, loss: 0.416802
global_step: 28634, epoch: 116, loss: 0.402017
global_step: 28635, epoch: 116, loss: 0.434310
global_step: 28636, epoch: 116, loss: 0.510280
global_step: 28637, epoch: 116, loss: 0.404324
global_step: 28638, epoch: 116, loss: 0.508986
global_step: 28639, epoch: 116, loss: 0.435812
global_step: 28640, epoch: 116, loss: 0.634793
epoch: 116
train	acc: 0.9076	macro: p 0.8930, r 0.7438, f1: 0.7703	micro: p 0.9076, r 0.9076, f1 0.9076	weighted_f1:0.8993
dev	acc: 0.5654	macro: p 0.5390, r 0.3545, f1: 0.3594	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5317
test	acc: 0.6046	macro: p 0.3986, r 0.3595, f1: 0.3635	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5807
global_step: 28641, epoch: 117, loss: 0.535543
global_step: 28642, epoch: 117, loss: 0.472922
global_step: 28643, epoch: 117, loss: 0.389408
global_step: 28644, epoch: 117, loss: 0.522419
global_step: 28645, epoch: 117, loss: 0.509682
global_step: 28646, epoch: 117, loss: 0.493800
global_step: 28647, epoch: 117, loss: 0.459955
global_step: 28648, epoch: 117, loss: 0.445791
global_step: 28649, epoch: 117, loss: 0.405380
global_step: 28650, epoch: 117, loss: 0.453264
global_step: 28651, epoch: 117, loss: 0.491388
global_step: 28652, epoch: 117, loss: 0.502085
global_step: 28653, epoch: 117, loss: 0.495648
global_step: 28654, epoch: 117, loss: 0.442794
global_step: 28655, epoch: 117, loss: 0.397286
global_step: 28656, epoch: 117, loss: 0.456539
global_step: 28657, epoch: 117, loss: 0.521886
global_step: 28658, epoch: 117, loss: 0.555275
global_step: 28659, epoch: 117, loss: 0.480450
global_step: 28660, epoch: 117, loss: 0.443990
global_step: 28661, epoch: 117, loss: 0.440935
global_step: 28662, epoch: 117, loss: 0.446735
global_step: 28663, epoch: 117, loss: 0.394351
global_step: 28664, epoch: 117, loss: 0.452502
global_step: 28665, epoch: 117, loss: 0.484256
global_step: 28666, epoch: 117, loss: 0.397061
global_step: 28667, epoch: 117, loss: 0.435490
global_step: 28668, epoch: 117, loss: 0.455296
global_step: 28669, epoch: 117, loss: 0.428452
global_step: 28670, epoch: 117, loss: 0.491890
global_step: 28671, epoch: 117, loss: 0.464440
global_step: 28672, epoch: 117, loss: 0.364730
global_step: 28673, epoch: 117, loss: 0.522654
global_step: 28674, epoch: 117, loss: 0.479214
global_step: 28675, epoch: 117, loss: 0.443280
global_step: 28676, epoch: 117, loss: 0.457787
global_step: 28677, epoch: 117, loss: 0.474526
global_step: 28678, epoch: 117, loss: 0.518473
global_step: 28679, epoch: 117, loss: 0.369602
global_step: 28680, epoch: 117, loss: 0.470138
epoch: 117
train	acc: 0.9069	macro: p 0.8938, r 0.7442, f1: 0.7710	micro: p 0.9069, r 0.9069, f1 0.9069	weighted_f1:0.8980
dev	acc: 0.5627	macro: p 0.5387, r 0.3443, f1: 0.3511	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5201
test	acc: 0.6042	macro: p 0.3852, r 0.3464, f1: 0.3514	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5727
global_step: 28681, epoch: 118, loss: 0.360648
global_step: 28682, epoch: 118, loss: 0.368350
global_step: 28683, epoch: 118, loss: 0.477963
global_step: 28684, epoch: 118, loss: 0.515911
global_step: 28685, epoch: 118, loss: 0.420488
global_step: 28686, epoch: 118, loss: 0.443736
global_step: 28687, epoch: 118, loss: 0.364257
global_step: 28688, epoch: 118, loss: 0.494517
global_step: 28689, epoch: 118, loss: 0.394428
global_step: 28690, epoch: 118, loss: 0.393069
global_step: 28691, epoch: 118, loss: 0.432620
global_step: 28692, epoch: 118, loss: 0.554006
global_step: 28693, epoch: 118, loss: 0.473047
global_step: 28694, epoch: 118, loss: 0.429615
global_step: 28695, epoch: 118, loss: 0.414653
global_step: 28696, epoch: 118, loss: 0.451592
global_step: 28697, epoch: 118, loss: 0.436788
global_step: 28698, epoch: 118, loss: 0.489416
global_step: 28699, epoch: 118, loss: 0.547070
global_step: 28700, epoch: 118, loss: 0.399389
global_step: 28701, epoch: 118, loss: 0.550290
global_step: 28702, epoch: 118, loss: 0.412777
global_step: 28703, epoch: 118, loss: 0.445726
global_step: 28704, epoch: 118, loss: 0.566418
global_step: 28705, epoch: 118, loss: 0.478733
global_step: 28706, epoch: 118, loss: 0.450110
global_step: 28707, epoch: 118, loss: 0.522200
global_step: 28708, epoch: 118, loss: 0.449784
global_step: 28709, epoch: 118, loss: 0.448077
global_step: 28710, epoch: 118, loss: 0.426631
global_step: 28711, epoch: 118, loss: 0.454801
global_step: 28712, epoch: 118, loss: 0.423924
global_step: 28713, epoch: 118, loss: 0.553171
global_step: 28714, epoch: 118, loss: 0.385803
global_step: 28715, epoch: 118, loss: 0.521323
global_step: 28716, epoch: 118, loss: 0.515760
global_step: 28717, epoch: 118, loss: 0.436267
global_step: 28718, epoch: 118, loss: 0.419928
global_step: 28719, epoch: 118, loss: 0.479039
global_step: 28720, epoch: 118, loss: 0.559911
epoch: 118
train	acc: 0.8996	macro: p 0.8933, r 0.7239, f1: 0.7392	micro: p 0.8996, r 0.8996, f1 0.8996	weighted_f1:0.8891
dev	acc: 0.5528	macro: p 0.5204, r 0.3396, f1: 0.3472	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5161
test	acc: 0.5954	macro: p 0.3994, r 0.3437, f1: 0.3528	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5685
global_step: 28721, epoch: 119, loss: 0.490680
global_step: 28722, epoch: 119, loss: 0.428686
global_step: 28723, epoch: 119, loss: 0.461792
global_step: 28724, epoch: 119, loss: 0.480539
global_step: 28725, epoch: 119, loss: 0.462430
global_step: 28726, epoch: 119, loss: 0.498145
global_step: 28727, epoch: 119, loss: 0.433805
global_step: 28728, epoch: 119, loss: 0.454789
global_step: 28729, epoch: 119, loss: 0.454288
global_step: 28730, epoch: 119, loss: 0.481035
global_step: 28731, epoch: 119, loss: 0.473268
global_step: 28732, epoch: 119, loss: 0.520943
global_step: 28733, epoch: 119, loss: 0.421979
global_step: 28734, epoch: 119, loss: 0.431753
global_step: 28735, epoch: 119, loss: 0.522264
global_step: 28736, epoch: 119, loss: 0.555836
global_step: 28737, epoch: 119, loss: 0.444853
global_step: 28738, epoch: 119, loss: 0.405660
global_step: 28739, epoch: 119, loss: 0.505938
global_step: 28740, epoch: 119, loss: 0.419456
global_step: 28741, epoch: 119, loss: 0.418860
global_step: 28742, epoch: 119, loss: 0.487455
global_step: 28743, epoch: 119, loss: 0.480408
global_step: 28744, epoch: 119, loss: 0.414288
global_step: 28745, epoch: 119, loss: 0.549309
global_step: 28746, epoch: 119, loss: 0.407585
global_step: 28747, epoch: 119, loss: 0.454818
global_step: 28748, epoch: 119, loss: 0.413274
global_step: 28749, epoch: 119, loss: 0.496732
global_step: 28750, epoch: 119, loss: 0.358579
global_step: 28751, epoch: 119, loss: 0.343801
global_step: 28752, epoch: 119, loss: 0.495078
global_step: 28753, epoch: 119, loss: 0.371597
global_step: 28754, epoch: 119, loss: 0.490241
global_step: 28755, epoch: 119, loss: 0.424873
global_step: 28756, epoch: 119, loss: 0.498480
global_step: 28757, epoch: 119, loss: 0.468656
global_step: 28758, epoch: 119, loss: 0.429557
global_step: 28759, epoch: 119, loss: 0.388685
global_step: 28760, epoch: 119, loss: 0.461820
epoch: 119
train	acc: 0.9101	macro: p 0.8966, r 0.7553, f1: 0.7825	micro: p 0.9101, r 0.9101, f1 0.9101	weighted_f1:0.9020
dev	acc: 0.5672	macro: p 0.5365, r 0.3431, f1: 0.3552	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5248
test	acc: 0.6019	macro: p 0.3811, r 0.3341, f1: 0.3465	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5678
global_step: 28761, epoch: 120, loss: 0.421499
global_step: 28762, epoch: 120, loss: 0.355557
global_step: 28763, epoch: 120, loss: 0.367017
global_step: 28764, epoch: 120, loss: 0.413966
global_step: 28765, epoch: 120, loss: 0.477384
global_step: 28766, epoch: 120, loss: 0.314296
global_step: 28767, epoch: 120, loss: 0.485401
global_step: 28768, epoch: 120, loss: 0.400514
global_step: 28769, epoch: 120, loss: 0.419464
global_step: 28770, epoch: 120, loss: 0.438579
global_step: 28771, epoch: 120, loss: 0.458626
global_step: 28772, epoch: 120, loss: 0.485631
global_step: 28773, epoch: 120, loss: 0.423422
global_step: 28774, epoch: 120, loss: 0.353936
global_step: 28775, epoch: 120, loss: 0.440932
global_step: 28776, epoch: 120, loss: 0.425676
global_step: 28777, epoch: 120, loss: 0.395803
global_step: 28778, epoch: 120, loss: 0.378364
global_step: 28779, epoch: 120, loss: 0.450624
global_step: 28780, epoch: 120, loss: 0.463289
global_step: 28781, epoch: 120, loss: 0.436985
global_step: 28782, epoch: 120, loss: 0.439503
global_step: 28783, epoch: 120, loss: 0.497472
global_step: 28784, epoch: 120, loss: 0.443409
global_step: 28785, epoch: 120, loss: 0.470809
global_step: 28786, epoch: 120, loss: 0.425209
global_step: 28787, epoch: 120, loss: 0.572695
global_step: 28788, epoch: 120, loss: 0.489682
global_step: 28789, epoch: 120, loss: 0.467739
global_step: 28790, epoch: 120, loss: 0.443222
global_step: 28791, epoch: 120, loss: 0.501788
global_step: 28792, epoch: 120, loss: 0.492905
global_step: 28793, epoch: 120, loss: 0.430838
global_step: 28794, epoch: 120, loss: 0.457013
global_step: 28795, epoch: 120, loss: 0.426995
global_step: 28796, epoch: 120, loss: 0.383261
global_step: 28797, epoch: 120, loss: 0.354654
global_step: 28798, epoch: 120, loss: 0.427809
global_step: 28799, epoch: 120, loss: 0.524653
global_step: 28800, epoch: 120, loss: 0.135952
epoch: 120
train	acc: 0.9130	macro: p 0.8995, r 0.7620, f1: 0.7892	micro: p 0.9130, r 0.9130, f1 0.9130	weighted_f1:0.9055
dev	acc: 0.5636	macro: p 0.5331, r 0.3488, f1: 0.3511	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5248
test	acc: 0.5946	macro: p 0.3821, r 0.3507, f1: 0.3524	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5701
global_step: 28801, epoch: 121, loss: 0.416529
global_step: 28802, epoch: 121, loss: 0.393306
global_step: 28803, epoch: 121, loss: 0.400581
global_step: 28804, epoch: 121, loss: 0.397995
global_step: 28805, epoch: 121, loss: 0.420232
global_step: 28806, epoch: 121, loss: 0.466100
global_step: 28807, epoch: 121, loss: 0.422102
global_step: 28808, epoch: 121, loss: 0.388657
global_step: 28809, epoch: 121, loss: 0.414090
global_step: 28810, epoch: 121, loss: 0.444354
global_step: 28811, epoch: 121, loss: 0.348969
global_step: 28812, epoch: 121, loss: 0.474229
global_step: 28813, epoch: 121, loss: 0.370143
global_step: 28814, epoch: 121, loss: 0.446944
global_step: 28815, epoch: 121, loss: 0.398325
global_step: 28816, epoch: 121, loss: 0.434576
global_step: 28817, epoch: 121, loss: 0.431227
global_step: 28818, epoch: 121, loss: 0.480634
global_step: 28819, epoch: 121, loss: 0.492997
global_step: 28820, epoch: 121, loss: 0.460662
global_step: 28821, epoch: 121, loss: 0.430433
global_step: 28822, epoch: 121, loss: 0.357516
global_step: 28823, epoch: 121, loss: 0.453503
global_step: 28824, epoch: 121, loss: 0.426657
global_step: 28825, epoch: 121, loss: 0.367026
global_step: 28826, epoch: 121, loss: 0.471993
global_step: 28827, epoch: 121, loss: 0.494219
global_step: 28828, epoch: 121, loss: 0.420192
global_step: 28829, epoch: 121, loss: 0.436773
global_step: 28830, epoch: 121, loss: 0.419755
global_step: 28831, epoch: 121, loss: 0.450765
global_step: 28832, epoch: 121, loss: 0.415718
global_step: 28833, epoch: 121, loss: 0.362678
global_step: 28834, epoch: 121, loss: 0.535148
global_step: 28835, epoch: 121, loss: 0.535091
global_step: 28836, epoch: 121, loss: 0.413780
global_step: 28837, epoch: 121, loss: 0.493690
global_step: 28838, epoch: 121, loss: 0.468181
global_step: 28839, epoch: 121, loss: 0.478856
global_step: 28840, epoch: 121, loss: 0.024008
epoch: 121
train	acc: 0.9119	macro: p 0.9041, r 0.7546, f1: 0.7851	micro: p 0.9119, r 0.9119, f1 0.9119	weighted_f1:0.9038
dev	acc: 0.5645	macro: p 0.5571, r 0.3412, f1: 0.3533	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5212
test	acc: 0.6061	macro: p 0.3979, r 0.3376, f1: 0.3494	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5713
global_step: 28841, epoch: 122, loss: 0.441726
global_step: 28842, epoch: 122, loss: 0.392015
global_step: 28843, epoch: 122, loss: 0.532307
global_step: 28844, epoch: 122, loss: 0.403162
global_step: 28845, epoch: 122, loss: 0.413426
global_step: 28846, epoch: 122, loss: 0.499949
global_step: 28847, epoch: 122, loss: 0.395965
global_step: 28848, epoch: 122, loss: 0.405475
global_step: 28849, epoch: 122, loss: 0.450592
global_step: 28850, epoch: 122, loss: 0.395315
global_step: 28851, epoch: 122, loss: 0.571812
global_step: 28852, epoch: 122, loss: 0.476266
global_step: 28853, epoch: 122, loss: 0.492684
global_step: 28854, epoch: 122, loss: 0.443733
global_step: 28855, epoch: 122, loss: 0.444233
global_step: 28856, epoch: 122, loss: 0.372861
global_step: 28857, epoch: 122, loss: 0.432521
global_step: 28858, epoch: 122, loss: 0.466109
global_step: 28859, epoch: 122, loss: 0.461336
global_step: 28860, epoch: 122, loss: 0.386974
global_step: 28861, epoch: 122, loss: 0.416656
global_step: 28862, epoch: 122, loss: 0.380207
global_step: 28863, epoch: 122, loss: 0.492018
global_step: 28864, epoch: 122, loss: 0.436977
global_step: 28865, epoch: 122, loss: 0.446668
global_step: 28866, epoch: 122, loss: 0.543990
global_step: 28867, epoch: 122, loss: 0.489876
global_step: 28868, epoch: 122, loss: 0.412045
global_step: 28869, epoch: 122, loss: 0.470759
global_step: 28870, epoch: 122, loss: 0.390897
global_step: 28871, epoch: 122, loss: 0.415315
global_step: 28872, epoch: 122, loss: 0.375172
global_step: 28873, epoch: 122, loss: 0.407262
global_step: 28874, epoch: 122, loss: 0.504273
global_step: 28875, epoch: 122, loss: 0.449253
global_step: 28876, epoch: 122, loss: 0.548834
global_step: 28877, epoch: 122, loss: 0.345006
global_step: 28878, epoch: 122, loss: 0.402718
global_step: 28879, epoch: 122, loss: 0.484483
global_step: 28880, epoch: 122, loss: 0.346415
epoch: 122
train	acc: 0.9125	macro: p 0.9038, r 0.7561, f1: 0.7855	micro: p 0.9125, r 0.9125, f1 0.9125	weighted_f1:0.9046
dev	acc: 0.5645	macro: p 0.4682, r 0.3424, f1: 0.3502	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5219
test	acc: 0.6038	macro: p 0.3906, r 0.3451, f1: 0.3527	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5734
global_step: 28881, epoch: 123, loss: 0.424329
global_step: 28882, epoch: 123, loss: 0.482203
global_step: 28883, epoch: 123, loss: 0.357481
global_step: 28884, epoch: 123, loss: 0.466313
global_step: 28885, epoch: 123, loss: 0.500472
global_step: 28886, epoch: 123, loss: 0.464541
global_step: 28887, epoch: 123, loss: 0.441397
global_step: 28888, epoch: 123, loss: 0.426609
global_step: 28889, epoch: 123, loss: 0.451741
global_step: 28890, epoch: 123, loss: 0.349454
global_step: 28891, epoch: 123, loss: 0.408964
global_step: 28892, epoch: 123, loss: 0.449817
global_step: 28893, epoch: 123, loss: 0.510996
global_step: 28894, epoch: 123, loss: 0.419912
global_step: 28895, epoch: 123, loss: 0.376999
global_step: 28896, epoch: 123, loss: 0.372580
global_step: 28897, epoch: 123, loss: 0.501459
global_step: 28898, epoch: 123, loss: 0.487766
global_step: 28899, epoch: 123, loss: 0.461000
global_step: 28900, epoch: 123, loss: 0.385645
global_step: 28901, epoch: 123, loss: 0.463354
global_step: 28902, epoch: 123, loss: 0.353790
global_step: 28903, epoch: 123, loss: 0.455414
global_step: 28904, epoch: 123, loss: 0.484531
global_step: 28905, epoch: 123, loss: 0.405754
global_step: 28906, epoch: 123, loss: 0.426272
global_step: 28907, epoch: 123, loss: 0.412972
global_step: 28908, epoch: 123, loss: 0.437264
global_step: 28909, epoch: 123, loss: 0.490905
global_step: 28910, epoch: 123, loss: 0.379929
global_step: 28911, epoch: 123, loss: 0.488847
global_step: 28912, epoch: 123, loss: 0.431967
global_step: 28913, epoch: 123, loss: 0.441666
global_step: 28914, epoch: 123, loss: 0.442103
global_step: 28915, epoch: 123, loss: 0.346087
global_step: 28916, epoch: 123, loss: 0.439359
global_step: 28917, epoch: 123, loss: 0.386340
global_step: 28918, epoch: 123, loss: 0.519996
global_step: 28919, epoch: 123, loss: 0.491654
global_step: 28920, epoch: 123, loss: 0.122977
epoch: 123
train	acc: 0.9151	macro: p 0.8990, r 0.7650, f1: 0.7889	micro: p 0.9151, r 0.9151, f1 0.9151	weighted_f1:0.9077
dev	acc: 0.5690	macro: p 0.4639, r 0.3579, f1: 0.3663	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5348
test	acc: 0.6000	macro: p 0.3851, r 0.3550, f1: 0.3610	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5775
global_step: 28921, epoch: 124, loss: 0.360437
global_step: 28922, epoch: 124, loss: 0.545250
global_step: 28923, epoch: 124, loss: 0.501797
global_step: 28924, epoch: 124, loss: 0.426231
global_step: 28925, epoch: 124, loss: 0.445466
global_step: 28926, epoch: 124, loss: 0.480169
global_step: 28927, epoch: 124, loss: 0.421867
global_step: 28928, epoch: 124, loss: 0.402662
global_step: 28929, epoch: 124, loss: 0.400909
global_step: 28930, epoch: 124, loss: 0.392204
global_step: 28931, epoch: 124, loss: 0.404364
global_step: 28932, epoch: 124, loss: 0.436481
global_step: 28933, epoch: 124, loss: 0.448102
global_step: 28934, epoch: 124, loss: 0.419389
global_step: 28935, epoch: 124, loss: 0.438963
global_step: 28936, epoch: 124, loss: 0.504710
global_step: 28937, epoch: 124, loss: 0.489956
global_step: 28938, epoch: 124, loss: 0.426973
global_step: 28939, epoch: 124, loss: 0.456453
global_step: 28940, epoch: 124, loss: 0.394553
global_step: 28941, epoch: 124, loss: 0.444594
global_step: 28942, epoch: 124, loss: 0.576476
global_step: 28943, epoch: 124, loss: 0.361319
global_step: 28944, epoch: 124, loss: 0.395796
global_step: 28945, epoch: 124, loss: 0.444938
global_step: 28946, epoch: 124, loss: 0.365917
global_step: 28947, epoch: 124, loss: 0.416833
global_step: 28948, epoch: 124, loss: 0.436963
global_step: 28949, epoch: 124, loss: 0.422305
global_step: 28950, epoch: 124, loss: 0.471141
global_step: 28951, epoch: 124, loss: 0.433080
global_step: 28952, epoch: 124, loss: 0.439227
global_step: 28953, epoch: 124, loss: 0.404547
global_step: 28954, epoch: 124, loss: 0.406410
global_step: 28955, epoch: 124, loss: 0.363021
global_step: 28956, epoch: 124, loss: 0.492119
global_step: 28957, epoch: 124, loss: 0.378730
global_step: 28958, epoch: 124, loss: 0.449303
global_step: 28959, epoch: 124, loss: 0.435603
global_step: 28960, epoch: 124, loss: 0.251439
epoch: 124
train	acc: 0.9171	macro: p 0.9018, r 0.7661, f1: 0.7916	micro: p 0.9171, r 0.9171, f1 0.9171	weighted_f1:0.9095
dev	acc: 0.5609	macro: p 0.5313, r 0.3428, f1: 0.3534	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5225
test	acc: 0.6069	macro: p 0.3994, r 0.3540, f1: 0.3650	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5798
global_step: 28961, epoch: 125, loss: 0.402147
global_step: 28962, epoch: 125, loss: 0.412598
global_step: 28963, epoch: 125, loss: 0.366739
global_step: 28964, epoch: 125, loss: 0.451098
global_step: 28965, epoch: 125, loss: 0.469723
global_step: 28966, epoch: 125, loss: 0.416689
global_step: 28967, epoch: 125, loss: 0.455144
global_step: 28968, epoch: 125, loss: 0.426905
global_step: 28969, epoch: 125, loss: 0.501331
global_step: 28970, epoch: 125, loss: 0.372095
global_step: 28971, epoch: 125, loss: 0.381312
global_step: 28972, epoch: 125, loss: 0.446470
global_step: 28973, epoch: 125, loss: 0.501239
global_step: 28974, epoch: 125, loss: 0.358680
global_step: 28975, epoch: 125, loss: 0.484900
global_step: 28976, epoch: 125, loss: 0.451425
global_step: 28977, epoch: 125, loss: 0.489316
global_step: 28978, epoch: 125, loss: 0.385730
global_step: 28979, epoch: 125, loss: 0.424783
global_step: 28980, epoch: 125, loss: 0.361782
global_step: 28981, epoch: 125, loss: 0.452674
global_step: 28982, epoch: 125, loss: 0.441556
global_step: 28983, epoch: 125, loss: 0.479730
global_step: 28984, epoch: 125, loss: 0.402835
global_step: 28985, epoch: 125, loss: 0.378172
global_step: 28986, epoch: 125, loss: 0.416405
global_step: 28987, epoch: 125, loss: 0.473674
global_step: 28988, epoch: 125, loss: 0.463369
global_step: 28989, epoch: 125, loss: 0.419778
global_step: 28990, epoch: 125, loss: 0.442070
global_step: 28991, epoch: 125, loss: 0.392366
global_step: 28992, epoch: 125, loss: 0.420281
global_step: 28993, epoch: 125, loss: 0.364140
global_step: 28994, epoch: 125, loss: 0.465994
global_step: 28995, epoch: 125, loss: 0.464881
global_step: 28996, epoch: 125, loss: 0.415218
global_step: 28997, epoch: 125, loss: 0.396590
global_step: 28998, epoch: 125, loss: 0.512685
global_step: 28999, epoch: 125, loss: 0.381843
global_step: 29000, epoch: 125, loss: 0.498779
epoch: 125
train	acc: 0.9190	macro: p 0.9101, r 0.7911, f1: 0.8264	micro: p 0.9190, r 0.9190, f1 0.9190	weighted_f1:0.9142
dev	acc: 0.5627	macro: p 0.4403, r 0.3414, f1: 0.3510	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5200
test	acc: 0.6008	macro: p 0.4085, r 0.3413, f1: 0.3547	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5657
global_step: 29001, epoch: 126, loss: 0.431433
global_step: 29002, epoch: 126, loss: 0.557900
global_step: 29003, epoch: 126, loss: 0.326576
global_step: 29004, epoch: 126, loss: 0.437405
global_step: 29005, epoch: 126, loss: 0.431722
global_step: 29006, epoch: 126, loss: 0.425682
global_step: 29007, epoch: 126, loss: 0.397613
global_step: 29008, epoch: 126, loss: 0.325678
global_step: 29009, epoch: 126, loss: 0.391390
global_step: 29010, epoch: 126, loss: 0.384028
global_step: 29011, epoch: 126, loss: 0.464299
global_step: 29012, epoch: 126, loss: 0.492546
global_step: 29013, epoch: 126, loss: 0.433687
global_step: 29014, epoch: 126, loss: 0.434688
global_step: 29015, epoch: 126, loss: 0.477856
global_step: 29016, epoch: 126, loss: 0.387862
global_step: 29017, epoch: 126, loss: 0.397278
global_step: 29018, epoch: 126, loss: 0.421948
global_step: 29019, epoch: 126, loss: 0.443395
global_step: 29020, epoch: 126, loss: 0.384506
global_step: 29021, epoch: 126, loss: 0.452786
global_step: 29022, epoch: 126, loss: 0.332642
global_step: 29023, epoch: 126, loss: 0.463243
global_step: 29024, epoch: 126, loss: 0.439383
global_step: 29025, epoch: 126, loss: 0.398485
global_step: 29026, epoch: 126, loss: 0.507124
global_step: 29027, epoch: 126, loss: 0.518138
global_step: 29028, epoch: 126, loss: 0.410752
global_step: 29029, epoch: 126, loss: 0.379131
global_step: 29030, epoch: 126, loss: 0.457017
global_step: 29031, epoch: 126, loss: 0.371111
global_step: 29032, epoch: 126, loss: 0.426725
global_step: 29033, epoch: 126, loss: 0.535357
global_step: 29034, epoch: 126, loss: 0.415759
global_step: 29035, epoch: 126, loss: 0.410563
global_step: 29036, epoch: 126, loss: 0.334550
global_step: 29037, epoch: 126, loss: 0.519198
global_step: 29038, epoch: 126, loss: 0.394863
global_step: 29039, epoch: 126, loss: 0.390943
global_step: 29040, epoch: 126, loss: 0.587359
epoch: 126
train	acc: 0.9208	macro: p 0.9083, r 0.7897, f1: 0.8174	micro: p 0.9208, r 0.9208, f1 0.9208	weighted_f1:0.9154
dev	acc: 0.5627	macro: p 0.5252, r 0.3481, f1: 0.3559	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5263
test	acc: 0.5939	macro: p 0.4133, r 0.3527, f1: 0.3663	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5703
global_step: 29041, epoch: 127, loss: 0.473326
global_step: 29042, epoch: 127, loss: 0.411194
global_step: 29043, epoch: 127, loss: 0.395474
global_step: 29044, epoch: 127, loss: 0.391107
global_step: 29045, epoch: 127, loss: 0.442268
global_step: 29046, epoch: 127, loss: 0.424337
global_step: 29047, epoch: 127, loss: 0.419698
global_step: 29048, epoch: 127, loss: 0.359824
global_step: 29049, epoch: 127, loss: 0.445101
global_step: 29050, epoch: 127, loss: 0.417313
global_step: 29051, epoch: 127, loss: 0.475552
global_step: 29052, epoch: 127, loss: 0.433087
global_step: 29053, epoch: 127, loss: 0.462963
global_step: 29054, epoch: 127, loss: 0.407889
global_step: 29055, epoch: 127, loss: 0.417307
global_step: 29056, epoch: 127, loss: 0.460532
global_step: 29057, epoch: 127, loss: 0.343148
global_step: 29058, epoch: 127, loss: 0.475677
global_step: 29059, epoch: 127, loss: 0.428454
global_step: 29060, epoch: 127, loss: 0.458254
global_step: 29061, epoch: 127, loss: 0.411760
global_step: 29062, epoch: 127, loss: 0.391954
global_step: 29063, epoch: 127, loss: 0.317231
global_step: 29064, epoch: 127, loss: 0.419320
global_step: 29065, epoch: 127, loss: 0.450442
global_step: 29066, epoch: 127, loss: 0.349963
global_step: 29067, epoch: 127, loss: 0.463764
global_step: 29068, epoch: 127, loss: 0.361589
global_step: 29069, epoch: 127, loss: 0.461367
global_step: 29070, epoch: 127, loss: 0.375358
global_step: 29071, epoch: 127, loss: 0.492866
global_step: 29072, epoch: 127, loss: 0.416214
global_step: 29073, epoch: 127, loss: 0.430798
global_step: 29074, epoch: 127, loss: 0.394040
global_step: 29075, epoch: 127, loss: 0.430962
global_step: 29076, epoch: 127, loss: 0.377372
global_step: 29077, epoch: 127, loss: 0.443033
global_step: 29078, epoch: 127, loss: 0.423497
global_step: 29079, epoch: 127, loss: 0.415569
global_step: 29080, epoch: 127, loss: 0.035339
epoch: 127
train	acc: 0.9219	macro: p 0.9125, r 0.7869, f1: 0.8153	micro: p 0.9219, r 0.9219, f1 0.9219	weighted_f1:0.9163
dev	acc: 0.5636	macro: p 0.4504, r 0.3576, f1: 0.3629	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5334
test	acc: 0.5985	macro: p 0.4036, r 0.3601, f1: 0.3654	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5785
global_step: 29081, epoch: 128, loss: 0.366066
global_step: 29082, epoch: 128, loss: 0.349780
global_step: 29083, epoch: 128, loss: 0.429846
global_step: 29084, epoch: 128, loss: 0.358437
global_step: 29085, epoch: 128, loss: 0.439550
global_step: 29086, epoch: 128, loss: 0.378924
global_step: 29087, epoch: 128, loss: 0.443678
global_step: 29088, epoch: 128, loss: 0.367346
global_step: 29089, epoch: 128, loss: 0.363323
global_step: 29090, epoch: 128, loss: 0.361536
global_step: 29091, epoch: 128, loss: 0.423238
global_step: 29092, epoch: 128, loss: 0.533476
global_step: 29093, epoch: 128, loss: 0.428152
global_step: 29094, epoch: 128, loss: 0.429077
global_step: 29095, epoch: 128, loss: 0.403661
global_step: 29096, epoch: 128, loss: 0.447210
global_step: 29097, epoch: 128, loss: 0.430660
global_step: 29098, epoch: 128, loss: 0.420587
global_step: 29099, epoch: 128, loss: 0.436319
global_step: 29100, epoch: 128, loss: 0.485550
global_step: 29101, epoch: 128, loss: 0.388288
global_step: 29102, epoch: 128, loss: 0.362256
global_step: 29103, epoch: 128, loss: 0.366105
global_step: 29104, epoch: 128, loss: 0.414282
global_step: 29105, epoch: 128, loss: 0.455898
global_step: 29106, epoch: 128, loss: 0.324302
global_step: 29107, epoch: 128, loss: 0.387209
global_step: 29108, epoch: 128, loss: 0.441755
global_step: 29109, epoch: 128, loss: 0.395088
global_step: 29110, epoch: 128, loss: 0.350670
global_step: 29111, epoch: 128, loss: 0.376694
global_step: 29112, epoch: 128, loss: 0.495415
global_step: 29113, epoch: 128, loss: 0.434440
global_step: 29114, epoch: 128, loss: 0.415875
global_step: 29115, epoch: 128, loss: 0.443805
global_step: 29116, epoch: 128, loss: 0.379306
global_step: 29117, epoch: 128, loss: 0.425281
global_step: 29118, epoch: 128, loss: 0.425932
global_step: 29119, epoch: 128, loss: 0.391299
global_step: 29120, epoch: 128, loss: 0.176284
epoch: 128
train	acc: 0.9173	macro: p 0.9157, r 0.7815, f1: 0.8199	micro: p 0.9173, r 0.9173, f1 0.9173	weighted_f1:0.9121
dev	acc: 0.5663	macro: p 0.5414, r 0.3434, f1: 0.3505	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5232
test	acc: 0.6096	macro: p 0.4360, r 0.3540, f1: 0.3682	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5793
global_step: 29121, epoch: 129, loss: 0.425024
global_step: 29122, epoch: 129, loss: 0.418401
global_step: 29123, epoch: 129, loss: 0.417877
global_step: 29124, epoch: 129, loss: 0.417753
global_step: 29125, epoch: 129, loss: 0.400270
global_step: 29126, epoch: 129, loss: 0.389165
global_step: 29127, epoch: 129, loss: 0.387689
global_step: 29128, epoch: 129, loss: 0.368232
global_step: 29129, epoch: 129, loss: 0.369995
global_step: 29130, epoch: 129, loss: 0.363950
global_step: 29131, epoch: 129, loss: 0.451729
global_step: 29132, epoch: 129, loss: 0.450853
global_step: 29133, epoch: 129, loss: 0.455926
global_step: 29134, epoch: 129, loss: 0.401144
global_step: 29135, epoch: 129, loss: 0.413535
global_step: 29136, epoch: 129, loss: 0.372624
global_step: 29137, epoch: 129, loss: 0.460619
global_step: 29138, epoch: 129, loss: 0.423263
global_step: 29139, epoch: 129, loss: 0.461453
global_step: 29140, epoch: 129, loss: 0.456603
global_step: 29141, epoch: 129, loss: 0.434182
global_step: 29142, epoch: 129, loss: 0.387241
global_step: 29143, epoch: 129, loss: 0.440926
global_step: 29144, epoch: 129, loss: 0.389900
global_step: 29145, epoch: 129, loss: 0.383225
global_step: 29146, epoch: 129, loss: 0.396290
global_step: 29147, epoch: 129, loss: 0.451686
global_step: 29148, epoch: 129, loss: 0.472739
global_step: 29149, epoch: 129, loss: 0.422046
global_step: 29150, epoch: 129, loss: 0.392558
global_step: 29151, epoch: 129, loss: 0.438442
global_step: 29152, epoch: 129, loss: 0.398066
global_step: 29153, epoch: 129, loss: 0.374903
global_step: 29154, epoch: 129, loss: 0.477408
global_step: 29155, epoch: 129, loss: 0.342368
global_step: 29156, epoch: 129, loss: 0.438098
global_step: 29157, epoch: 129, loss: 0.345904
global_step: 29158, epoch: 129, loss: 0.342325
global_step: 29159, epoch: 129, loss: 0.336669
global_step: 29160, epoch: 129, loss: 0.040125
epoch: 129
train	acc: 0.9262	macro: p 0.9206, r 0.8040, f1: 0.8379	micro: p 0.9262, r 0.9262, f1 0.9262	weighted_f1:0.9220
dev	acc: 0.5681	macro: p 0.4616, r 0.3566, f1: 0.3592	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5309
test	acc: 0.6011	macro: p 0.4127, r 0.3583, f1: 0.3651	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5765
global_step: 29161, epoch: 130, loss: 0.385788
global_step: 29162, epoch: 130, loss: 0.436231
global_step: 29163, epoch: 130, loss: 0.343460
global_step: 29164, epoch: 130, loss: 0.359195
global_step: 29165, epoch: 130, loss: 0.391568
global_step: 29166, epoch: 130, loss: 0.395244
global_step: 29167, epoch: 130, loss: 0.472141
global_step: 29168, epoch: 130, loss: 0.397188
global_step: 29169, epoch: 130, loss: 0.417467
global_step: 29170, epoch: 130, loss: 0.336996
global_step: 29171, epoch: 130, loss: 0.366440
global_step: 29172, epoch: 130, loss: 0.427548
global_step: 29173, epoch: 130, loss: 0.400647
global_step: 29174, epoch: 130, loss: 0.441676
global_step: 29175, epoch: 130, loss: 0.398349
global_step: 29176, epoch: 130, loss: 0.452563
global_step: 29177, epoch: 130, loss: 0.464360
global_step: 29178, epoch: 130, loss: 0.381070
global_step: 29179, epoch: 130, loss: 0.402406
global_step: 29180, epoch: 130, loss: 0.600156
global_step: 29181, epoch: 130, loss: 0.466622
global_step: 29182, epoch: 130, loss: 0.392196
global_step: 29183, epoch: 130, loss: 0.408853
global_step: 29184, epoch: 130, loss: 0.420218
global_step: 29185, epoch: 130, loss: 0.453820
global_step: 29186, epoch: 130, loss: 0.431998
global_step: 29187, epoch: 130, loss: 0.397494
global_step: 29188, epoch: 130, loss: 0.374127
global_step: 29189, epoch: 130, loss: 0.447526
global_step: 29190, epoch: 130, loss: 0.348104
global_step: 29191, epoch: 130, loss: 0.362491
global_step: 29192, epoch: 130, loss: 0.315287
global_step: 29193, epoch: 130, loss: 0.475805
global_step: 29194, epoch: 130, loss: 0.425417
global_step: 29195, epoch: 130, loss: 0.345553
global_step: 29196, epoch: 130, loss: 0.457005
global_step: 29197, epoch: 130, loss: 0.471598
global_step: 29198, epoch: 130, loss: 0.366621
global_step: 29199, epoch: 130, loss: 0.435992
global_step: 29200, epoch: 130, loss: 0.677146
epoch: 130
train	acc: 0.9296	macro: p 0.9229, r 0.8258, f1: 0.8576	micro: p 0.9296, r 0.9296, f1 0.9296	weighted_f1:0.9265
dev	acc: 0.5573	macro: p 0.4207, r 0.3397, f1: 0.3479	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5190
test	acc: 0.5935	macro: p 0.3952, r 0.3451, f1: 0.3581	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5666
global_step: 29201, epoch: 131, loss: 0.462368
global_step: 29202, epoch: 131, loss: 0.316517
global_step: 29203, epoch: 131, loss: 0.406052
global_step: 29204, epoch: 131, loss: 0.299441
global_step: 29205, epoch: 131, loss: 0.536015
global_step: 29206, epoch: 131, loss: 0.341703
global_step: 29207, epoch: 131, loss: 0.319956
global_step: 29208, epoch: 131, loss: 0.382095
global_step: 29209, epoch: 131, loss: 0.370698
global_step: 29210, epoch: 131, loss: 0.479559
global_step: 29211, epoch: 131, loss: 0.374171
global_step: 29212, epoch: 131, loss: 0.408058
global_step: 29213, epoch: 131, loss: 0.533711
global_step: 29214, epoch: 131, loss: 0.286019
global_step: 29215, epoch: 131, loss: 0.441029
global_step: 29216, epoch: 131, loss: 0.424006
global_step: 29217, epoch: 131, loss: 0.338696
global_step: 29218, epoch: 131, loss: 0.404316
global_step: 29219, epoch: 131, loss: 0.329088
global_step: 29220, epoch: 131, loss: 0.396795
global_step: 29221, epoch: 131, loss: 0.386887
global_step: 29222, epoch: 131, loss: 0.404491
global_step: 29223, epoch: 131, loss: 0.411798
global_step: 29224, epoch: 131, loss: 0.419540
global_step: 29225, epoch: 131, loss: 0.457977
global_step: 29226, epoch: 131, loss: 0.402480
global_step: 29227, epoch: 131, loss: 0.371837
global_step: 29228, epoch: 131, loss: 0.426926
global_step: 29229, epoch: 131, loss: 0.369518
global_step: 29230, epoch: 131, loss: 0.375867
global_step: 29231, epoch: 131, loss: 0.427901
global_step: 29232, epoch: 131, loss: 0.466143
global_step: 29233, epoch: 131, loss: 0.484966
global_step: 29234, epoch: 131, loss: 0.404070
global_step: 29235, epoch: 131, loss: 0.423146
global_step: 29236, epoch: 131, loss: 0.420306
global_step: 29237, epoch: 131, loss: 0.301584
global_step: 29238, epoch: 131, loss: 0.370659
global_step: 29239, epoch: 131, loss: 0.429323
global_step: 29240, epoch: 131, loss: 0.385788
epoch: 131
train	acc: 0.9259	macro: p 0.9210, r 0.8094, f1: 0.8427	micro: p 0.9259, r 0.9259, f1 0.9259	weighted_f1:0.9218
dev	acc: 0.5591	macro: p 0.5244, r 0.3433, f1: 0.3526	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5218
test	acc: 0.5989	macro: p 0.4020, r 0.3512, f1: 0.3629	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5736
global_step: 29241, epoch: 132, loss: 0.478317
global_step: 29242, epoch: 132, loss: 0.391678
global_step: 29243, epoch: 132, loss: 0.388670
global_step: 29244, epoch: 132, loss: 0.428518
global_step: 29245, epoch: 132, loss: 0.366412
global_step: 29246, epoch: 132, loss: 0.416249
global_step: 29247, epoch: 132, loss: 0.456502
global_step: 29248, epoch: 132, loss: 0.360044
global_step: 29249, epoch: 132, loss: 0.405146
global_step: 29250, epoch: 132, loss: 0.368001
global_step: 29251, epoch: 132, loss: 0.379622
global_step: 29252, epoch: 132, loss: 0.414523
global_step: 29253, epoch: 132, loss: 0.395675
global_step: 29254, epoch: 132, loss: 0.485947
global_step: 29255, epoch: 132, loss: 0.376336
global_step: 29256, epoch: 132, loss: 0.458891
global_step: 29257, epoch: 132, loss: 0.335705
global_step: 29258, epoch: 132, loss: 0.406805
global_step: 29259, epoch: 132, loss: 0.408600
global_step: 29260, epoch: 132, loss: 0.481847
global_step: 29261, epoch: 132, loss: 0.367329
global_step: 29262, epoch: 132, loss: 0.423728
global_step: 29263, epoch: 132, loss: 0.413747
global_step: 29264, epoch: 132, loss: 0.361199
global_step: 29265, epoch: 132, loss: 0.383581
global_step: 29266, epoch: 132, loss: 0.323873
global_step: 29267, epoch: 132, loss: 0.515599
global_step: 29268, epoch: 132, loss: 0.358958
global_step: 29269, epoch: 132, loss: 0.394814
global_step: 29270, epoch: 132, loss: 0.478235
global_step: 29271, epoch: 132, loss: 0.354022
global_step: 29272, epoch: 132, loss: 0.395090
global_step: 29273, epoch: 132, loss: 0.348122
global_step: 29274, epoch: 132, loss: 0.443068
global_step: 29275, epoch: 132, loss: 0.337070
global_step: 29276, epoch: 132, loss: 0.464516
global_step: 29277, epoch: 132, loss: 0.384205
global_step: 29278, epoch: 132, loss: 0.476043
global_step: 29279, epoch: 132, loss: 0.310386
global_step: 29280, epoch: 132, loss: 0.078166
epoch: 132
train	acc: 0.9199	macro: p 0.9157, r 0.7774, f1: 0.8095	micro: p 0.9199, r 0.9199, f1 0.9199	weighted_f1:0.9133
dev	acc: 0.5636	macro: p 0.5324, r 0.3419, f1: 0.3505	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5216
test	acc: 0.6038	macro: p 0.4017, r 0.3456, f1: 0.3564	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5733
global_step: 29281, epoch: 133, loss: 0.360533
global_step: 29282, epoch: 133, loss: 0.412125
global_step: 29283, epoch: 133, loss: 0.306680
global_step: 29284, epoch: 133, loss: 0.403784
global_step: 29285, epoch: 133, loss: 0.305753
global_step: 29286, epoch: 133, loss: 0.345561
global_step: 29287, epoch: 133, loss: 0.333842
global_step: 29288, epoch: 133, loss: 0.346668
global_step: 29289, epoch: 133, loss: 0.342482
global_step: 29290, epoch: 133, loss: 0.425077
global_step: 29291, epoch: 133, loss: 0.356073
global_step: 29292, epoch: 133, loss: 0.420654
global_step: 29293, epoch: 133, loss: 0.346390
global_step: 29294, epoch: 133, loss: 0.444138
global_step: 29295, epoch: 133, loss: 0.414147
global_step: 29296, epoch: 133, loss: 0.405909
global_step: 29297, epoch: 133, loss: 0.380761
global_step: 29298, epoch: 133, loss: 0.425402
global_step: 29299, epoch: 133, loss: 0.351507
global_step: 29300, epoch: 133, loss: 0.452857
global_step: 29301, epoch: 133, loss: 0.427250
global_step: 29302, epoch: 133, loss: 0.416462
global_step: 29303, epoch: 133, loss: 0.345913
global_step: 29304, epoch: 133, loss: 0.376507
global_step: 29305, epoch: 133, loss: 0.439508
global_step: 29306, epoch: 133, loss: 0.489257
global_step: 29307, epoch: 133, loss: 0.337526
global_step: 29308, epoch: 133, loss: 0.383295
global_step: 29309, epoch: 133, loss: 0.389240
global_step: 29310, epoch: 133, loss: 0.389008
global_step: 29311, epoch: 133, loss: 0.357435
global_step: 29312, epoch: 133, loss: 0.487523
global_step: 29313, epoch: 133, loss: 0.419761
global_step: 29314, epoch: 133, loss: 0.494293
global_step: 29315, epoch: 133, loss: 0.387337
global_step: 29316, epoch: 133, loss: 0.331339
global_step: 29317, epoch: 133, loss: 0.416930
global_step: 29318, epoch: 133, loss: 0.452829
global_step: 29319, epoch: 133, loss: 0.446478
global_step: 29320, epoch: 133, loss: 0.578586
epoch: 133
train	acc: 0.9344	macro: p 0.9208, r 0.8442, f1: 0.8699	micro: p 0.9344, r 0.9344, f1 0.9344	weighted_f1:0.9324
dev	acc: 0.5537	macro: p 0.4081, r 0.3582, f1: 0.3599	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5290
test	acc: 0.5904	macro: p 0.3999, r 0.3750, f1: 0.3795	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5787
global_step: 29321, epoch: 134, loss: 0.374573
global_step: 29322, epoch: 134, loss: 0.350424
global_step: 29323, epoch: 134, loss: 0.402980
global_step: 29324, epoch: 134, loss: 0.351323
global_step: 29325, epoch: 134, loss: 0.462494
global_step: 29326, epoch: 134, loss: 0.517528
global_step: 29327, epoch: 134, loss: 0.443459
global_step: 29328, epoch: 134, loss: 0.350634
global_step: 29329, epoch: 134, loss: 0.372815
global_step: 29330, epoch: 134, loss: 0.360502
global_step: 29331, epoch: 134, loss: 0.403279
global_step: 29332, epoch: 134, loss: 0.364678
global_step: 29333, epoch: 134, loss: 0.376692
global_step: 29334, epoch: 134, loss: 0.329633
global_step: 29335, epoch: 134, loss: 0.440613
global_step: 29336, epoch: 134, loss: 0.396155
global_step: 29337, epoch: 134, loss: 0.379649
global_step: 29338, epoch: 134, loss: 0.465306
global_step: 29339, epoch: 134, loss: 0.274835
global_step: 29340, epoch: 134, loss: 0.314211
global_step: 29341, epoch: 134, loss: 0.362256
global_step: 29342, epoch: 134, loss: 0.398565
global_step: 29343, epoch: 134, loss: 0.328870
global_step: 29344, epoch: 134, loss: 0.471429
global_step: 29345, epoch: 134, loss: 0.337655
global_step: 29346, epoch: 134, loss: 0.421937
global_step: 29347, epoch: 134, loss: 0.481978
global_step: 29348, epoch: 134, loss: 0.427081
global_step: 29349, epoch: 134, loss: 0.409983
global_step: 29350, epoch: 134, loss: 0.401836
global_step: 29351, epoch: 134, loss: 0.296946
global_step: 29352, epoch: 134, loss: 0.376082
global_step: 29353, epoch: 134, loss: 0.373742
global_step: 29354, epoch: 134, loss: 0.507301
global_step: 29355, epoch: 134, loss: 0.443331
global_step: 29356, epoch: 134, loss: 0.333076
global_step: 29357, epoch: 134, loss: 0.377986
global_step: 29358, epoch: 134, loss: 0.416188
global_step: 29359, epoch: 134, loss: 0.443550
global_step: 29360, epoch: 134, loss: 0.099297
epoch: 134
train	acc: 0.9247	macro: p 0.9237, r 0.7952, f1: 0.8297	micro: p 0.9247, r 0.9247, f1 0.9247	weighted_f1:0.9195
dev	acc: 0.5609	macro: p 0.5284, r 0.3360, f1: 0.3446	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5164
test	acc: 0.6031	macro: p 0.4336, r 0.3471, f1: 0.3629	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5717
global_step: 29361, epoch: 135, loss: 0.392131
global_step: 29362, epoch: 135, loss: 0.428398
global_step: 29363, epoch: 135, loss: 0.380602
global_step: 29364, epoch: 135, loss: 0.429788
global_step: 29365, epoch: 135, loss: 0.368798
global_step: 29366, epoch: 135, loss: 0.329162
global_step: 29367, epoch: 135, loss: 0.373754
global_step: 29368, epoch: 135, loss: 0.381420
global_step: 29369, epoch: 135, loss: 0.437541
global_step: 29370, epoch: 135, loss: 0.348828
global_step: 29371, epoch: 135, loss: 0.332341
global_step: 29372, epoch: 135, loss: 0.421295
global_step: 29373, epoch: 135, loss: 0.360425
global_step: 29374, epoch: 135, loss: 0.382225
global_step: 29375, epoch: 135, loss: 0.375975
global_step: 29376, epoch: 135, loss: 0.315803
global_step: 29377, epoch: 135, loss: 0.390195
global_step: 29378, epoch: 135, loss: 0.386362
global_step: 29379, epoch: 135, loss: 0.396753
global_step: 29380, epoch: 135, loss: 0.393398
global_step: 29381, epoch: 135, loss: 0.341906
global_step: 29382, epoch: 135, loss: 0.384496
global_step: 29383, epoch: 135, loss: 0.393721
global_step: 29384, epoch: 135, loss: 0.443721
global_step: 29385, epoch: 135, loss: 0.501230
global_step: 29386, epoch: 135, loss: 0.385764
global_step: 29387, epoch: 135, loss: 0.393103
global_step: 29388, epoch: 135, loss: 0.326818
global_step: 29389, epoch: 135, loss: 0.408423
global_step: 29390, epoch: 135, loss: 0.284668
global_step: 29391, epoch: 135, loss: 0.376594
global_step: 29392, epoch: 135, loss: 0.345061
global_step: 29393, epoch: 135, loss: 0.343865
global_step: 29394, epoch: 135, loss: 0.429139
global_step: 29395, epoch: 135, loss: 0.390496
global_step: 29396, epoch: 135, loss: 0.289757
global_step: 29397, epoch: 135, loss: 0.419236
global_step: 29398, epoch: 135, loss: 0.438909
global_step: 29399, epoch: 135, loss: 0.359254
global_step: 29400, epoch: 135, loss: 1.668536
epoch: 135
train	acc: 0.9321	macro: p 0.9301, r 0.8392, f1: 0.8729	micro: p 0.9321, r 0.9321, f1 0.9321	weighted_f1:0.9299
dev	acc: 0.5600	macro: p 0.4366, r 0.3423, f1: 0.3514	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5167
test	acc: 0.6004	macro: p 0.3994, r 0.3456, f1: 0.3585	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5688
global_step: 29401, epoch: 136, loss: 0.399158
global_step: 29402, epoch: 136, loss: 0.444483
global_step: 29403, epoch: 136, loss: 0.355201
global_step: 29404, epoch: 136, loss: 0.450856
global_step: 29405, epoch: 136, loss: 0.349447
global_step: 29406, epoch: 136, loss: 0.385162
global_step: 29407, epoch: 136, loss: 0.331870
global_step: 29408, epoch: 136, loss: 0.380975
global_step: 29409, epoch: 136, loss: 0.354371
global_step: 29410, epoch: 136, loss: 0.299242
global_step: 29411, epoch: 136, loss: 0.378082
global_step: 29412, epoch: 136, loss: 0.416593
global_step: 29413, epoch: 136, loss: 0.383589
global_step: 29414, epoch: 136, loss: 0.379805
global_step: 29415, epoch: 136, loss: 0.314765
global_step: 29416, epoch: 136, loss: 0.330027
global_step: 29417, epoch: 136, loss: 0.368090
global_step: 29418, epoch: 136, loss: 0.373319
global_step: 29419, epoch: 136, loss: 0.386208
global_step: 29420, epoch: 136, loss: 0.371640
global_step: 29421, epoch: 136, loss: 0.411816
global_step: 29422, epoch: 136, loss: 0.338056
global_step: 29423, epoch: 136, loss: 0.447084
global_step: 29424, epoch: 136, loss: 0.441214
global_step: 29425, epoch: 136, loss: 0.314280
global_step: 29426, epoch: 136, loss: 0.335467
global_step: 29427, epoch: 136, loss: 0.421329
global_step: 29428, epoch: 136, loss: 0.483052
global_step: 29429, epoch: 136, loss: 0.324332
global_step: 29430, epoch: 136, loss: 0.372541
global_step: 29431, epoch: 136, loss: 0.471100
global_step: 29432, epoch: 136, loss: 0.437534
global_step: 29433, epoch: 136, loss: 0.500505
global_step: 29434, epoch: 136, loss: 0.350386
global_step: 29435, epoch: 136, loss: 0.375095
global_step: 29436, epoch: 136, loss: 0.363387
global_step: 29437, epoch: 136, loss: 0.404182
global_step: 29438, epoch: 136, loss: 0.416513
global_step: 29439, epoch: 136, loss: 0.381016
global_step: 29440, epoch: 136, loss: 0.266084
epoch: 136
train	acc: 0.9370	macro: p 0.9303, r 0.8522, f1: 0.8816	micro: p 0.9370, r 0.9370, f1 0.9370	weighted_f1:0.9352
dev	acc: 0.5609	macro: p 0.4419, r 0.3442, f1: 0.3508	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5233
test	acc: 0.5981	macro: p 0.4022, r 0.3563, f1: 0.3693	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5735
global_step: 29441, epoch: 137, loss: 0.368266
global_step: 29442, epoch: 137, loss: 0.355135
global_step: 29443, epoch: 137, loss: 0.365346
global_step: 29444, epoch: 137, loss: 0.366159
global_step: 29445, epoch: 137, loss: 0.391779
global_step: 29446, epoch: 137, loss: 0.404975
global_step: 29447, epoch: 137, loss: 0.345940
global_step: 29448, epoch: 137, loss: 0.388284
global_step: 29449, epoch: 137, loss: 0.395229
global_step: 29450, epoch: 137, loss: 0.370702
global_step: 29451, epoch: 137, loss: 0.426787
global_step: 29452, epoch: 137, loss: 0.365154
global_step: 29453, epoch: 137, loss: 0.399439
global_step: 29454, epoch: 137, loss: 0.351215
global_step: 29455, epoch: 137, loss: 0.412488
global_step: 29456, epoch: 137, loss: 0.338005
global_step: 29457, epoch: 137, loss: 0.439789
global_step: 29458, epoch: 137, loss: 0.346425
global_step: 29459, epoch: 137, loss: 0.310999
global_step: 29460, epoch: 137, loss: 0.309888
global_step: 29461, epoch: 137, loss: 0.440135
global_step: 29462, epoch: 137, loss: 0.351874
global_step: 29463, epoch: 137, loss: 0.336547
global_step: 29464, epoch: 137, loss: 0.383888
global_step: 29465, epoch: 137, loss: 0.436629
global_step: 29466, epoch: 137, loss: 0.349989
global_step: 29467, epoch: 137, loss: 0.472234
global_step: 29468, epoch: 137, loss: 0.434894
global_step: 29469, epoch: 137, loss: 0.393351
global_step: 29470, epoch: 137, loss: 0.304933
global_step: 29471, epoch: 137, loss: 0.345768
global_step: 29472, epoch: 137, loss: 0.322698
global_step: 29473, epoch: 137, loss: 0.385293
global_step: 29474, epoch: 137, loss: 0.362909
global_step: 29475, epoch: 137, loss: 0.381412
global_step: 29476, epoch: 137, loss: 0.460815
global_step: 29477, epoch: 137, loss: 0.351780
global_step: 29478, epoch: 137, loss: 0.428282
global_step: 29479, epoch: 137, loss: 0.383090
global_step: 29480, epoch: 137, loss: 0.255894
epoch: 137
train	acc: 0.9372	macro: p 0.9356, r 0.8415, f1: 0.8735	micro: p 0.9372, r 0.9372, f1 0.9372	weighted_f1:0.9347
dev	acc: 0.5537	macro: p 0.4342, r 0.3419, f1: 0.3470	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5179
test	acc: 0.5977	macro: p 0.4006, r 0.3563, f1: 0.3669	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5748
global_step: 29481, epoch: 138, loss: 0.401835
global_step: 29482, epoch: 138, loss: 0.382919
global_step: 29483, epoch: 138, loss: 0.332259
global_step: 29484, epoch: 138, loss: 0.358415
global_step: 29485, epoch: 138, loss: 0.432295
global_step: 29486, epoch: 138, loss: 0.400228
global_step: 29487, epoch: 138, loss: 0.425776
global_step: 29488, epoch: 138, loss: 0.375121
global_step: 29489, epoch: 138, loss: 0.265824
global_step: 29490, epoch: 138, loss: 0.287952
global_step: 29491, epoch: 138, loss: 0.395878
global_step: 29492, epoch: 138, loss: 0.448368
global_step: 29493, epoch: 138, loss: 0.430960
global_step: 29494, epoch: 138, loss: 0.404797
global_step: 29495, epoch: 138, loss: 0.398033
global_step: 29496, epoch: 138, loss: 0.344157
global_step: 29497, epoch: 138, loss: 0.364294
global_step: 29498, epoch: 138, loss: 0.309557
global_step: 29499, epoch: 138, loss: 0.390763
global_step: 29500, epoch: 138, loss: 0.337815
global_step: 29501, epoch: 138, loss: 0.435759
global_step: 29502, epoch: 138, loss: 0.361529
global_step: 29503, epoch: 138, loss: 0.429677
global_step: 29504, epoch: 138, loss: 0.428078
global_step: 29505, epoch: 138, loss: 0.344441
global_step: 29506, epoch: 138, loss: 0.377379
global_step: 29507, epoch: 138, loss: 0.366016
global_step: 29508, epoch: 138, loss: 0.321917
global_step: 29509, epoch: 138, loss: 0.423852
global_step: 29510, epoch: 138, loss: 0.338574
global_step: 29511, epoch: 138, loss: 0.435223
global_step: 29512, epoch: 138, loss: 0.358888
global_step: 29513, epoch: 138, loss: 0.367009
global_step: 29514, epoch: 138, loss: 0.308366
global_step: 29515, epoch: 138, loss: 0.386041
global_step: 29516, epoch: 138, loss: 0.417857
global_step: 29517, epoch: 138, loss: 0.427208
global_step: 29518, epoch: 138, loss: 0.373982
global_step: 29519, epoch: 138, loss: 0.389807
global_step: 29520, epoch: 138, loss: 0.168033
epoch: 138
train	acc: 0.9354	macro: p 0.9318, r 0.8372, f1: 0.8702	micro: p 0.9354, r 0.9354, f1 0.9354	weighted_f1:0.9331
dev	acc: 0.5654	macro: p 0.4267, r 0.3541, f1: 0.3590	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5313
test	acc: 0.6000	macro: p 0.4125, r 0.3644, f1: 0.3721	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5793
global_step: 29521, epoch: 139, loss: 0.331989
global_step: 29522, epoch: 139, loss: 0.335955
global_step: 29523, epoch: 139, loss: 0.342475
global_step: 29524, epoch: 139, loss: 0.291922
global_step: 29525, epoch: 139, loss: 0.447484
global_step: 29526, epoch: 139, loss: 0.322663
global_step: 29527, epoch: 139, loss: 0.407865
global_step: 29528, epoch: 139, loss: 0.368537
global_step: 29529, epoch: 139, loss: 0.293121
global_step: 29530, epoch: 139, loss: 0.418920
global_step: 29531, epoch: 139, loss: 0.322313
global_step: 29532, epoch: 139, loss: 0.267866
global_step: 29533, epoch: 139, loss: 0.377172
global_step: 29534, epoch: 139, loss: 0.458097
global_step: 29535, epoch: 139, loss: 0.441636
global_step: 29536, epoch: 139, loss: 0.363105
global_step: 29537, epoch: 139, loss: 0.463227
global_step: 29538, epoch: 139, loss: 0.402574
global_step: 29539, epoch: 139, loss: 0.382329
global_step: 29540, epoch: 139, loss: 0.452570
global_step: 29541, epoch: 139, loss: 0.336797
global_step: 29542, epoch: 139, loss: 0.376416
global_step: 29543, epoch: 139, loss: 0.424266
global_step: 29544, epoch: 139, loss: 0.353424
global_step: 29545, epoch: 139, loss: 0.381976
global_step: 29546, epoch: 139, loss: 0.317004
global_step: 29547, epoch: 139, loss: 0.443558
global_step: 29548, epoch: 139, loss: 0.417653
global_step: 29549, epoch: 139, loss: 0.328550
global_step: 29550, epoch: 139, loss: 0.501911
global_step: 29551, epoch: 139, loss: 0.427148
global_step: 29552, epoch: 139, loss: 0.352611
global_step: 29553, epoch: 139, loss: 0.437724
global_step: 29554, epoch: 139, loss: 0.379049
global_step: 29555, epoch: 139, loss: 0.393522
global_step: 29556, epoch: 139, loss: 0.410241
global_step: 29557, epoch: 139, loss: 0.310822
global_step: 29558, epoch: 139, loss: 0.435836
global_step: 29559, epoch: 139, loss: 0.362453
global_step: 29560, epoch: 139, loss: 0.222657
epoch: 139
train	acc: 0.9367	macro: p 0.9289, r 0.8420, f1: 0.8716	micro: p 0.9367, r 0.9367, f1 0.9367	weighted_f1:0.9343
dev	acc: 0.5537	macro: p 0.4356, r 0.3439, f1: 0.3488	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5191
test	acc: 0.5977	macro: p 0.4049, r 0.3605, f1: 0.3705	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5770
global_step: 29561, epoch: 140, loss: 0.332082
global_step: 29562, epoch: 140, loss: 0.380294
global_step: 29563, epoch: 140, loss: 0.373209
global_step: 29564, epoch: 140, loss: 0.411171
global_step: 29565, epoch: 140, loss: 0.431558
global_step: 29566, epoch: 140, loss: 0.439767
global_step: 29567, epoch: 140, loss: 0.340272
global_step: 29568, epoch: 140, loss: 0.297687
global_step: 29569, epoch: 140, loss: 0.387288
global_step: 29570, epoch: 140, loss: 0.444178
global_step: 29571, epoch: 140, loss: 0.339801
global_step: 29572, epoch: 140, loss: 0.404336
global_step: 29573, epoch: 140, loss: 0.423747
global_step: 29574, epoch: 140, loss: 0.378914
global_step: 29575, epoch: 140, loss: 0.360458
global_step: 29576, epoch: 140, loss: 0.309800
global_step: 29577, epoch: 140, loss: 0.321305
global_step: 29578, epoch: 140, loss: 0.287442
global_step: 29579, epoch: 140, loss: 0.373569
global_step: 29580, epoch: 140, loss: 0.366634
global_step: 29581, epoch: 140, loss: 0.377053
global_step: 29582, epoch: 140, loss: 0.347708
global_step: 29583, epoch: 140, loss: 0.388255
global_step: 29584, epoch: 140, loss: 0.401544
global_step: 29585, epoch: 140, loss: 0.439017
global_step: 29586, epoch: 140, loss: 0.338579
global_step: 29587, epoch: 140, loss: 0.333551
global_step: 29588, epoch: 140, loss: 0.375409
global_step: 29589, epoch: 140, loss: 0.398316
global_step: 29590, epoch: 140, loss: 0.377449
global_step: 29591, epoch: 140, loss: 0.396643
global_step: 29592, epoch: 140, loss: 0.301595
global_step: 29593, epoch: 140, loss: 0.423503
global_step: 29594, epoch: 140, loss: 0.321674
global_step: 29595, epoch: 140, loss: 0.376389
global_step: 29596, epoch: 140, loss: 0.407441
global_step: 29597, epoch: 140, loss: 0.321980
global_step: 29598, epoch: 140, loss: 0.390821
global_step: 29599, epoch: 140, loss: 0.340074
global_step: 29600, epoch: 140, loss: 0.343984
epoch: 140
train	acc: 0.9110	macro: p 0.9308, r 0.7972, f1: 0.8456	micro: p 0.9110, r 0.9110, f1 0.9110	weighted_f1:0.9072
dev	acc: 0.5500	macro: p 0.4657, r 0.3171, f1: 0.3273	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4947
test	acc: 0.6042	macro: p 0.4713, r 0.3261, f1: 0.3514	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5555
global_step: 29601, epoch: 141, loss: 0.394166
global_step: 29602, epoch: 141, loss: 0.346716
global_step: 29603, epoch: 141, loss: 0.366412
global_step: 29604, epoch: 141, loss: 0.364077
global_step: 29605, epoch: 141, loss: 0.402349
global_step: 29606, epoch: 141, loss: 0.360853
global_step: 29607, epoch: 141, loss: 0.359205
global_step: 29608, epoch: 141, loss: 0.395085
global_step: 29609, epoch: 141, loss: 0.300508
global_step: 29610, epoch: 141, loss: 0.347439
global_step: 29611, epoch: 141, loss: 0.351647
global_step: 29612, epoch: 141, loss: 0.353438
global_step: 29613, epoch: 141, loss: 0.363315
global_step: 29614, epoch: 141, loss: 0.418131
global_step: 29615, epoch: 141, loss: 0.360389
global_step: 29616, epoch: 141, loss: 0.398879
global_step: 29617, epoch: 141, loss: 0.339780
global_step: 29618, epoch: 141, loss: 0.352802
global_step: 29619, epoch: 141, loss: 0.469306
global_step: 29620, epoch: 141, loss: 0.441379
global_step: 29621, epoch: 141, loss: 0.359938
global_step: 29622, epoch: 141, loss: 0.380961
global_step: 29623, epoch: 141, loss: 0.358754
global_step: 29624, epoch: 141, loss: 0.383303
global_step: 29625, epoch: 141, loss: 0.366105
global_step: 29626, epoch: 141, loss: 0.320973
global_step: 29627, epoch: 141, loss: 0.404885
global_step: 29628, epoch: 141, loss: 0.444872
global_step: 29629, epoch: 141, loss: 0.340876
global_step: 29630, epoch: 141, loss: 0.428193
global_step: 29631, epoch: 141, loss: 0.333057
global_step: 29632, epoch: 141, loss: 0.268884
global_step: 29633, epoch: 141, loss: 0.345530
global_step: 29634, epoch: 141, loss: 0.453124
global_step: 29635, epoch: 141, loss: 0.387897
global_step: 29636, epoch: 141, loss: 0.376491
global_step: 29637, epoch: 141, loss: 0.346409
global_step: 29638, epoch: 141, loss: 0.363677
global_step: 29639, epoch: 141, loss: 0.347174
global_step: 29640, epoch: 141, loss: 0.041527
epoch: 141
train	acc: 0.9395	macro: p 0.9374, r 0.8600, f1: 0.8897	micro: p 0.9395, r 0.9395, f1 0.9395	weighted_f1:0.9380
dev	acc: 0.5663	macro: p 0.4449, r 0.3529, f1: 0.3571	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5296
test	acc: 0.5943	macro: p 0.3941, r 0.3564, f1: 0.3657	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5715
global_step: 29641, epoch: 142, loss: 0.348427
global_step: 29642, epoch: 142, loss: 0.327429
global_step: 29643, epoch: 142, loss: 0.380503
global_step: 29644, epoch: 142, loss: 0.296340
global_step: 29645, epoch: 142, loss: 0.277691
global_step: 29646, epoch: 142, loss: 0.401184
global_step: 29647, epoch: 142, loss: 0.322484
global_step: 29648, epoch: 142, loss: 0.377585
global_step: 29649, epoch: 142, loss: 0.309165
global_step: 29650, epoch: 142, loss: 0.419800
global_step: 29651, epoch: 142, loss: 0.343139
global_step: 29652, epoch: 142, loss: 0.358388
global_step: 29653, epoch: 142, loss: 0.324430
global_step: 29654, epoch: 142, loss: 0.317325
global_step: 29655, epoch: 142, loss: 0.346662
global_step: 29656, epoch: 142, loss: 0.393322
global_step: 29657, epoch: 142, loss: 0.319790
global_step: 29658, epoch: 142, loss: 0.404331
global_step: 29659, epoch: 142, loss: 0.377148
global_step: 29660, epoch: 142, loss: 0.362597
global_step: 29661, epoch: 142, loss: 0.338220
global_step: 29662, epoch: 142, loss: 0.370319
global_step: 29663, epoch: 142, loss: 0.301704
global_step: 29664, epoch: 142, loss: 0.302500
global_step: 29665, epoch: 142, loss: 0.429881
global_step: 29666, epoch: 142, loss: 0.411688
global_step: 29667, epoch: 142, loss: 0.406775
global_step: 29668, epoch: 142, loss: 0.327268
global_step: 29669, epoch: 142, loss: 0.325834
global_step: 29670, epoch: 142, loss: 0.318919
global_step: 29671, epoch: 142, loss: 0.441744
global_step: 29672, epoch: 142, loss: 0.302655
global_step: 29673, epoch: 142, loss: 0.403260
global_step: 29674, epoch: 142, loss: 0.368991
global_step: 29675, epoch: 142, loss: 0.395557
global_step: 29676, epoch: 142, loss: 0.411848
global_step: 29677, epoch: 142, loss: 0.422235
global_step: 29678, epoch: 142, loss: 0.330096
global_step: 29679, epoch: 142, loss: 0.395567
global_step: 29680, epoch: 142, loss: 0.246144
epoch: 142
train	acc: 0.9339	macro: p 0.9386, r 0.8376, f1: 0.8744	micro: p 0.9339, r 0.9339, f1 0.9339	weighted_f1:0.9315
dev	acc: 0.5645	macro: p 0.5441, r 0.3411, f1: 0.3491	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5194
test	acc: 0.6065	macro: p 0.4353, r 0.3470, f1: 0.3621	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5734
global_step: 29681, epoch: 143, loss: 0.353871
global_step: 29682, epoch: 143, loss: 0.315473
global_step: 29683, epoch: 143, loss: 0.362828
global_step: 29684, epoch: 143, loss: 0.331875
global_step: 29685, epoch: 143, loss: 0.385644
global_step: 29686, epoch: 143, loss: 0.489598
global_step: 29687, epoch: 143, loss: 0.270538
global_step: 29688, epoch: 143, loss: 0.284314
global_step: 29689, epoch: 143, loss: 0.328713
global_step: 29690, epoch: 143, loss: 0.290487
global_step: 29691, epoch: 143, loss: 0.382805
global_step: 29692, epoch: 143, loss: 0.339476
global_step: 29693, epoch: 143, loss: 0.422786
global_step: 29694, epoch: 143, loss: 0.427555
global_step: 29695, epoch: 143, loss: 0.254301
global_step: 29696, epoch: 143, loss: 0.303728
global_step: 29697, epoch: 143, loss: 0.436609
global_step: 29698, epoch: 143, loss: 0.438530
global_step: 29699, epoch: 143, loss: 0.332918
global_step: 29700, epoch: 143, loss: 0.331161
global_step: 29701, epoch: 143, loss: 0.349684
global_step: 29702, epoch: 143, loss: 0.336873
global_step: 29703, epoch: 143, loss: 0.383365
global_step: 29704, epoch: 143, loss: 0.356245
global_step: 29705, epoch: 143, loss: 0.327822
global_step: 29706, epoch: 143, loss: 0.382915
global_step: 29707, epoch: 143, loss: 0.393598
global_step: 29708, epoch: 143, loss: 0.429289
global_step: 29709, epoch: 143, loss: 0.329896
global_step: 29710, epoch: 143, loss: 0.358900
global_step: 29711, epoch: 143, loss: 0.359908
global_step: 29712, epoch: 143, loss: 0.314395
global_step: 29713, epoch: 143, loss: 0.424607
global_step: 29714, epoch: 143, loss: 0.406968
global_step: 29715, epoch: 143, loss: 0.374407
global_step: 29716, epoch: 143, loss: 0.437571
global_step: 29717, epoch: 143, loss: 0.396871
global_step: 29718, epoch: 143, loss: 0.384758
global_step: 29719, epoch: 143, loss: 0.393520
global_step: 29720, epoch: 143, loss: 0.113286
epoch: 143
train	acc: 0.9363	macro: p 0.9362, r 0.8397, f1: 0.8729	micro: p 0.9363, r 0.9363, f1 0.9363	weighted_f1:0.9338
dev	acc: 0.5573	macro: p 0.4208, r 0.3412, f1: 0.3481	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5188
test	acc: 0.5977	macro: p 0.4127, r 0.3497, f1: 0.3645	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5711
global_step: 29721, epoch: 144, loss: 0.343620
global_step: 29722, epoch: 144, loss: 0.324018
global_step: 29723, epoch: 144, loss: 0.329103
global_step: 29724, epoch: 144, loss: 0.389007
global_step: 29725, epoch: 144, loss: 0.366700
global_step: 29726, epoch: 144, loss: 0.317401
global_step: 29727, epoch: 144, loss: 0.345562
global_step: 29728, epoch: 144, loss: 0.388897
global_step: 29729, epoch: 144, loss: 0.347532
global_step: 29730, epoch: 144, loss: 0.383600
global_step: 29731, epoch: 144, loss: 0.395998
global_step: 29732, epoch: 144, loss: 0.289978
global_step: 29733, epoch: 144, loss: 0.293016
global_step: 29734, epoch: 144, loss: 0.312955
global_step: 29735, epoch: 144, loss: 0.401257
global_step: 29736, epoch: 144, loss: 0.371927
global_step: 29737, epoch: 144, loss: 0.364522
global_step: 29738, epoch: 144, loss: 0.397569
global_step: 29739, epoch: 144, loss: 0.374244
global_step: 29740, epoch: 144, loss: 0.334966
global_step: 29741, epoch: 144, loss: 0.324337
global_step: 29742, epoch: 144, loss: 0.368324
global_step: 29743, epoch: 144, loss: 0.396743
global_step: 29744, epoch: 144, loss: 0.332821
global_step: 29745, epoch: 144, loss: 0.348246
global_step: 29746, epoch: 144, loss: 0.417423
global_step: 29747, epoch: 144, loss: 0.356701
global_step: 29748, epoch: 144, loss: 0.347828
global_step: 29749, epoch: 144, loss: 0.368827
global_step: 29750, epoch: 144, loss: 0.313705
global_step: 29751, epoch: 144, loss: 0.329503
global_step: 29752, epoch: 144, loss: 0.396471
global_step: 29753, epoch: 144, loss: 0.365082
global_step: 29754, epoch: 144, loss: 0.365977
global_step: 29755, epoch: 144, loss: 0.403867
global_step: 29756, epoch: 144, loss: 0.324627
global_step: 29757, epoch: 144, loss: 0.340827
global_step: 29758, epoch: 144, loss: 0.330188
global_step: 29759, epoch: 144, loss: 0.348390
global_step: 29760, epoch: 144, loss: 0.764671
epoch: 144
train	acc: 0.9424	macro: p 0.9410, r 0.8670, f1: 0.8958	micro: p 0.9424, r 0.9424, f1 0.9424	weighted_f1:0.9410
dev	acc: 0.5573	macro: p 0.4172, r 0.3431, f1: 0.3478	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5203
test	acc: 0.5927	macro: p 0.4089, r 0.3579, f1: 0.3708	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5711
global_step: 29761, epoch: 145, loss: 0.427692
global_step: 29762, epoch: 145, loss: 0.353963
global_step: 29763, epoch: 145, loss: 0.329114
global_step: 29764, epoch: 145, loss: 0.338420
global_step: 29765, epoch: 145, loss: 0.409324
global_step: 29766, epoch: 145, loss: 0.342934
global_step: 29767, epoch: 145, loss: 0.361737
global_step: 29768, epoch: 145, loss: 0.346206
global_step: 29769, epoch: 145, loss: 0.330789
global_step: 29770, epoch: 145, loss: 0.338116
global_step: 29771, epoch: 145, loss: 0.385002
global_step: 29772, epoch: 145, loss: 0.351667
global_step: 29773, epoch: 145, loss: 0.342685
global_step: 29774, epoch: 145, loss: 0.334555
global_step: 29775, epoch: 145, loss: 0.357675
global_step: 29776, epoch: 145, loss: 0.375167
global_step: 29777, epoch: 145, loss: 0.320189
global_step: 29778, epoch: 145, loss: 0.372357
global_step: 29779, epoch: 145, loss: 0.380692
global_step: 29780, epoch: 145, loss: 0.384465
global_step: 29781, epoch: 145, loss: 0.307809
global_step: 29782, epoch: 145, loss: 0.332005
global_step: 29783, epoch: 145, loss: 0.379940
global_step: 29784, epoch: 145, loss: 0.323497
global_step: 29785, epoch: 145, loss: 0.350837
global_step: 29786, epoch: 145, loss: 0.291792
global_step: 29787, epoch: 145, loss: 0.313936
global_step: 29788, epoch: 145, loss: 0.349423
global_step: 29789, epoch: 145, loss: 0.382419
global_step: 29790, epoch: 145, loss: 0.397140
global_step: 29791, epoch: 145, loss: 0.330059
global_step: 29792, epoch: 145, loss: 0.348723
global_step: 29793, epoch: 145, loss: 0.381875
global_step: 29794, epoch: 145, loss: 0.357908
global_step: 29795, epoch: 145, loss: 0.429286
global_step: 29796, epoch: 145, loss: 0.283413
global_step: 29797, epoch: 145, loss: 0.359919
global_step: 29798, epoch: 145, loss: 0.319582
global_step: 29799, epoch: 145, loss: 0.337914
global_step: 29800, epoch: 145, loss: 0.084556
epoch: 145
train	acc: 0.9371	macro: p 0.9346, r 0.8438, f1: 0.8760	micro: p 0.9371, r 0.9371, f1 0.9371	weighted_f1:0.9351
dev	acc: 0.5627	macro: p 0.4543, r 0.3511, f1: 0.3554	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5277
test	acc: 0.6011	macro: p 0.4183, r 0.3659, f1: 0.3741	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5806
global_step: 29801, epoch: 146, loss: 0.307153
global_step: 29802, epoch: 146, loss: 0.405525
global_step: 29803, epoch: 146, loss: 0.433196
global_step: 29804, epoch: 146, loss: 0.390572
global_step: 29805, epoch: 146, loss: 0.331070
global_step: 29806, epoch: 146, loss: 0.291787
global_step: 29807, epoch: 146, loss: 0.408571
global_step: 29808, epoch: 146, loss: 0.350961
global_step: 29809, epoch: 146, loss: 0.345135
global_step: 29810, epoch: 146, loss: 0.291978
global_step: 29811, epoch: 146, loss: 0.385784
global_step: 29812, epoch: 146, loss: 0.392214
global_step: 29813, epoch: 146, loss: 0.465487
global_step: 29814, epoch: 146, loss: 0.380862
global_step: 29815, epoch: 146, loss: 0.391100
global_step: 29816, epoch: 146, loss: 0.328996
global_step: 29817, epoch: 146, loss: 0.374320
global_step: 29818, epoch: 146, loss: 0.320823
global_step: 29819, epoch: 146, loss: 0.360182
global_step: 29820, epoch: 146, loss: 0.305732
global_step: 29821, epoch: 146, loss: 0.291835
global_step: 29822, epoch: 146, loss: 0.377485
global_step: 29823, epoch: 146, loss: 0.365525
global_step: 29824, epoch: 146, loss: 0.368522
global_step: 29825, epoch: 146, loss: 0.236190
global_step: 29826, epoch: 146, loss: 0.419074
global_step: 29827, epoch: 146, loss: 0.380368
global_step: 29828, epoch: 146, loss: 0.396361
global_step: 29829, epoch: 146, loss: 0.342002
global_step: 29830, epoch: 146, loss: 0.279454
global_step: 29831, epoch: 146, loss: 0.330663
global_step: 29832, epoch: 146, loss: 0.334039
global_step: 29833, epoch: 146, loss: 0.344669
global_step: 29834, epoch: 146, loss: 0.325841
global_step: 29835, epoch: 146, loss: 0.349229
global_step: 29836, epoch: 146, loss: 0.394789
global_step: 29837, epoch: 146, loss: 0.288372
global_step: 29838, epoch: 146, loss: 0.308499
global_step: 29839, epoch: 146, loss: 0.265829
global_step: 29840, epoch: 146, loss: 0.029055
epoch: 146
train	acc: 0.9407	macro: p 0.9428, r 0.8615, f1: 0.8933	micro: p 0.9407, r 0.9407, f1 0.9407	weighted_f1:0.9392
dev	acc: 0.5627	macro: p 0.4533, r 0.3440, f1: 0.3492	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5207
test	acc: 0.6015	macro: p 0.4160, r 0.3550, f1: 0.3693	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5737
global_step: 29841, epoch: 147, loss: 0.310506
global_step: 29842, epoch: 147, loss: 0.382496
global_step: 29843, epoch: 147, loss: 0.288313
global_step: 29844, epoch: 147, loss: 0.371215
global_step: 29845, epoch: 147, loss: 0.230969
global_step: 29846, epoch: 147, loss: 0.312488
global_step: 29847, epoch: 147, loss: 0.306541
global_step: 29848, epoch: 147, loss: 0.335131
global_step: 29849, epoch: 147, loss: 0.312182
global_step: 29850, epoch: 147, loss: 0.429703
global_step: 29851, epoch: 147, loss: 0.373133
global_step: 29852, epoch: 147, loss: 0.353973
global_step: 29853, epoch: 147, loss: 0.300111
global_step: 29854, epoch: 147, loss: 0.400675
global_step: 29855, epoch: 147, loss: 0.333488
global_step: 29856, epoch: 147, loss: 0.351730
global_step: 29857, epoch: 147, loss: 0.394392
global_step: 29858, epoch: 147, loss: 0.312858
global_step: 29859, epoch: 147, loss: 0.352311
global_step: 29860, epoch: 147, loss: 0.348793
global_step: 29861, epoch: 147, loss: 0.407393
global_step: 29862, epoch: 147, loss: 0.308596
global_step: 29863, epoch: 147, loss: 0.321605
global_step: 29864, epoch: 147, loss: 0.346364
global_step: 29865, epoch: 147, loss: 0.271976
global_step: 29866, epoch: 147, loss: 0.417751
global_step: 29867, epoch: 147, loss: 0.435797
global_step: 29868, epoch: 147, loss: 0.358127
global_step: 29869, epoch: 147, loss: 0.393345
global_step: 29870, epoch: 147, loss: 0.366524
global_step: 29871, epoch: 147, loss: 0.325124
global_step: 29872, epoch: 147, loss: 0.329557
global_step: 29873, epoch: 147, loss: 0.376849
global_step: 29874, epoch: 147, loss: 0.310766
global_step: 29875, epoch: 147, loss: 0.438736
global_step: 29876, epoch: 147, loss: 0.422981
global_step: 29877, epoch: 147, loss: 0.329363
global_step: 29878, epoch: 147, loss: 0.367877
global_step: 29879, epoch: 147, loss: 0.321384
global_step: 29880, epoch: 147, loss: 0.056550
epoch: 147
train	acc: 0.9426	macro: p 0.9424, r 0.8665, f1: 0.8958	micro: p 0.9426, r 0.9426, f1 0.9426	weighted_f1:0.9412
dev	acc: 0.5582	macro: p 0.4186, r 0.3460, f1: 0.3507	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5217
test	acc: 0.5935	macro: p 0.3959, r 0.3535, f1: 0.3638	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5708
global_step: 29881, epoch: 148, loss: 0.412596
global_step: 29882, epoch: 148, loss: 0.335503
global_step: 29883, epoch: 148, loss: 0.437990
global_step: 29884, epoch: 148, loss: 0.334531
global_step: 29885, epoch: 148, loss: 0.231723
global_step: 29886, epoch: 148, loss: 0.366847
global_step: 29887, epoch: 148, loss: 0.361826
global_step: 29888, epoch: 148, loss: 0.363681
global_step: 29889, epoch: 148, loss: 0.322445
global_step: 29890, epoch: 148, loss: 0.230481
global_step: 29891, epoch: 148, loss: 0.355862
global_step: 29892, epoch: 148, loss: 0.423771
global_step: 29893, epoch: 148, loss: 0.302679
global_step: 29894, epoch: 148, loss: 0.345230
global_step: 29895, epoch: 148, loss: 0.432280
global_step: 29896, epoch: 148, loss: 0.398713
global_step: 29897, epoch: 148, loss: 0.324244
global_step: 29898, epoch: 148, loss: 0.326408
global_step: 29899, epoch: 148, loss: 0.326405
global_step: 29900, epoch: 148, loss: 0.369918
global_step: 29901, epoch: 148, loss: 0.469654
global_step: 29902, epoch: 148, loss: 0.345819
global_step: 29903, epoch: 148, loss: 0.307087
global_step: 29904, epoch: 148, loss: 0.349644
global_step: 29905, epoch: 148, loss: 0.275207
global_step: 29906, epoch: 148, loss: 0.325865
global_step: 29907, epoch: 148, loss: 0.337895
global_step: 29908, epoch: 148, loss: 0.351637
global_step: 29909, epoch: 148, loss: 0.406773
global_step: 29910, epoch: 148, loss: 0.342180
global_step: 29911, epoch: 148, loss: 0.335476
global_step: 29912, epoch: 148, loss: 0.304967
global_step: 29913, epoch: 148, loss: 0.313018
global_step: 29914, epoch: 148, loss: 0.309422
global_step: 29915, epoch: 148, loss: 0.390398
global_step: 29916, epoch: 148, loss: 0.361804
global_step: 29917, epoch: 148, loss: 0.402868
global_step: 29918, epoch: 148, loss: 0.304009
global_step: 29919, epoch: 148, loss: 0.357263
global_step: 29920, epoch: 148, loss: 0.051132
epoch: 148
train	acc: 0.9412	macro: p 0.9374, r 0.8560, f1: 0.8845	micro: p 0.9412, r 0.9412, f1 0.9412	weighted_f1:0.9394
dev	acc: 0.5627	macro: p 0.4474, r 0.3533, f1: 0.3585	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5278
test	acc: 0.5935	macro: p 0.4071, r 0.3612, f1: 0.3725	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5734
global_step: 29921, epoch: 149, loss: 0.342091
global_step: 29922, epoch: 149, loss: 0.311411
global_step: 29923, epoch: 149, loss: 0.368440
global_step: 29924, epoch: 149, loss: 0.380256
global_step: 29925, epoch: 149, loss: 0.299092
global_step: 29926, epoch: 149, loss: 0.340979
global_step: 29927, epoch: 149, loss: 0.421437
global_step: 29928, epoch: 149, loss: 0.308919
global_step: 29929, epoch: 149, loss: 0.400286
global_step: 29930, epoch: 149, loss: 0.351530
global_step: 29931, epoch: 149, loss: 0.280374
global_step: 29932, epoch: 149, loss: 0.349859
global_step: 29933, epoch: 149, loss: 0.381555
global_step: 29934, epoch: 149, loss: 0.382791
global_step: 29935, epoch: 149, loss: 0.331803
global_step: 29936, epoch: 149, loss: 0.361883
global_step: 29937, epoch: 149, loss: 0.273436
global_step: 29938, epoch: 149, loss: 0.324362
global_step: 29939, epoch: 149, loss: 0.325431
global_step: 29940, epoch: 149, loss: 0.284417
global_step: 29941, epoch: 149, loss: 0.289177
global_step: 29942, epoch: 149, loss: 0.399620
global_step: 29943, epoch: 149, loss: 0.381811
global_step: 29944, epoch: 149, loss: 0.368961
global_step: 29945, epoch: 149, loss: 0.327050
global_step: 29946, epoch: 149, loss: 0.265923
global_step: 29947, epoch: 149, loss: 0.329321
global_step: 29948, epoch: 149, loss: 0.358770
global_step: 29949, epoch: 149, loss: 0.244058
global_step: 29950, epoch: 149, loss: 0.312253
global_step: 29951, epoch: 149, loss: 0.344445
global_step: 29952, epoch: 149, loss: 0.362940
global_step: 29953, epoch: 149, loss: 0.382230
global_step: 29954, epoch: 149, loss: 0.360991
global_step: 29955, epoch: 149, loss: 0.349202
global_step: 29956, epoch: 149, loss: 0.385414
global_step: 29957, epoch: 149, loss: 0.273483
global_step: 29958, epoch: 149, loss: 0.315611
global_step: 29959, epoch: 149, loss: 0.349545
global_step: 29960, epoch: 149, loss: 0.627120
epoch: 149
train	acc: 0.9463	macro: p 0.9450, r 0.8772, f1: 0.9042	micro: p 0.9463, r 0.9463, f1 0.9463	weighted_f1:0.9452
dev	acc: 0.5690	macro: p 0.4460, r 0.3555, f1: 0.3586	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5328
test	acc: 0.5920	macro: p 0.3876, r 0.3558, f1: 0.3611	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5712
global_step: 29961, epoch: 150, loss: 0.344381
global_step: 29962, epoch: 150, loss: 0.341643
global_step: 29963, epoch: 150, loss: 0.264803
global_step: 29964, epoch: 150, loss: 0.396460
global_step: 29965, epoch: 150, loss: 0.345405
global_step: 29966, epoch: 150, loss: 0.322317
global_step: 29967, epoch: 150, loss: 0.359926
global_step: 29968, epoch: 150, loss: 0.323920
global_step: 29969, epoch: 150, loss: 0.336180
global_step: 29970, epoch: 150, loss: 0.352511
global_step: 29971, epoch: 150, loss: 0.302207
global_step: 29972, epoch: 150, loss: 0.368813
global_step: 29973, epoch: 150, loss: 0.298480
global_step: 29974, epoch: 150, loss: 0.323397
global_step: 29975, epoch: 150, loss: 0.347440
global_step: 29976, epoch: 150, loss: 0.306247
global_step: 29977, epoch: 150, loss: 0.302505
global_step: 29978, epoch: 150, loss: 0.331832
global_step: 29979, epoch: 150, loss: 0.328809
global_step: 29980, epoch: 150, loss: 0.346678
global_step: 29981, epoch: 150, loss: 0.229323
global_step: 29982, epoch: 150, loss: 0.348626
global_step: 29983, epoch: 150, loss: 0.487452
global_step: 29984, epoch: 150, loss: 0.346960
global_step: 29985, epoch: 150, loss: 0.263303
global_step: 29986, epoch: 150, loss: 0.342592
global_step: 29987, epoch: 150, loss: 0.293150
global_step: 29988, epoch: 150, loss: 0.368493
global_step: 29989, epoch: 150, loss: 0.380282
global_step: 29990, epoch: 150, loss: 0.361928
global_step: 29991, epoch: 150, loss: 0.285182
global_step: 29992, epoch: 150, loss: 0.315152
global_step: 29993, epoch: 150, loss: 0.437337
global_step: 29994, epoch: 150, loss: 0.441966
global_step: 29995, epoch: 150, loss: 0.407716
global_step: 29996, epoch: 150, loss: 0.394142
global_step: 29997, epoch: 150, loss: 0.310398
global_step: 29998, epoch: 150, loss: 0.352606
global_step: 29999, epoch: 150, loss: 0.272843
global_step: 30000, epoch: 150, loss: 0.254213
epoch: 150
train	acc: 0.9433	macro: p 0.9428, r 0.8659, f1: 0.8955	micro: p 0.9433, r 0.9433, f1 0.9433	weighted_f1:0.9419
dev	acc: 0.5555	macro: p 0.4396, r 0.3386, f1: 0.3417	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5151
test	acc: 0.5966	macro: p 0.4207, r 0.3589, f1: 0.3724	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5724
global_step: 30001, epoch: 151, loss: 0.309042
global_step: 30002, epoch: 151, loss: 0.296537
global_step: 30003, epoch: 151, loss: 0.364755
global_step: 30004, epoch: 151, loss: 0.335416
global_step: 30005, epoch: 151, loss: 0.341727
global_step: 30006, epoch: 151, loss: 0.344256
global_step: 30007, epoch: 151, loss: 0.361268
global_step: 30008, epoch: 151, loss: 0.238864
global_step: 30009, epoch: 151, loss: 0.311691
global_step: 30010, epoch: 151, loss: 0.263176
global_step: 30011, epoch: 151, loss: 0.325129
global_step: 30012, epoch: 151, loss: 0.315840
global_step: 30013, epoch: 151, loss: 0.336795
global_step: 30014, epoch: 151, loss: 0.309587
global_step: 30015, epoch: 151, loss: 0.473704
global_step: 30016, epoch: 151, loss: 0.306636
global_step: 30017, epoch: 151, loss: 0.334311
global_step: 30018, epoch: 151, loss: 0.350339
global_step: 30019, epoch: 151, loss: 0.374126
global_step: 30020, epoch: 151, loss: 0.285103
global_step: 30021, epoch: 151, loss: 0.261187
global_step: 30022, epoch: 151, loss: 0.323544
global_step: 30023, epoch: 151, loss: 0.363832
global_step: 30024, epoch: 151, loss: 0.415912
global_step: 30025, epoch: 151, loss: 0.392069
global_step: 30026, epoch: 151, loss: 0.323059
global_step: 30027, epoch: 151, loss: 0.386004
global_step: 30028, epoch: 151, loss: 0.301405
global_step: 30029, epoch: 151, loss: 0.350875
global_step: 30030, epoch: 151, loss: 0.305211
global_step: 30031, epoch: 151, loss: 0.398406
global_step: 30032, epoch: 151, loss: 0.335639
global_step: 30033, epoch: 151, loss: 0.370540
global_step: 30034, epoch: 151, loss: 0.366509
global_step: 30035, epoch: 151, loss: 0.365337
global_step: 30036, epoch: 151, loss: 0.318634
global_step: 30037, epoch: 151, loss: 0.342676
global_step: 30038, epoch: 151, loss: 0.381329
global_step: 30039, epoch: 151, loss: 0.280097
global_step: 30040, epoch: 151, loss: 1.454693
epoch: 151
train	acc: 0.9459	macro: p 0.9443, r 0.8785, f1: 0.9039	micro: p 0.9459, r 0.9459, f1 0.9459	weighted_f1:0.9449
dev	acc: 0.5392	macro: p 0.4147, r 0.3526, f1: 0.3565	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5195
test	acc: 0.5805	macro: p 0.4102, r 0.3748, f1: 0.3821	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5720
global_step: 30041, epoch: 152, loss: 0.383836
global_step: 30042, epoch: 152, loss: 0.342553
global_step: 30043, epoch: 152, loss: 0.360414
global_step: 30044, epoch: 152, loss: 0.296210
global_step: 30045, epoch: 152, loss: 0.309765
global_step: 30046, epoch: 152, loss: 0.336699
global_step: 30047, epoch: 152, loss: 0.297792
global_step: 30048, epoch: 152, loss: 0.298100
global_step: 30049, epoch: 152, loss: 0.302334
global_step: 30050, epoch: 152, loss: 0.339934
global_step: 30051, epoch: 152, loss: 0.302104
global_step: 30052, epoch: 152, loss: 0.390792
global_step: 30053, epoch: 152, loss: 0.300526
global_step: 30054, epoch: 152, loss: 0.384398
global_step: 30055, epoch: 152, loss: 0.287915
global_step: 30056, epoch: 152, loss: 0.271700
global_step: 30057, epoch: 152, loss: 0.306145
global_step: 30058, epoch: 152, loss: 0.363038
global_step: 30059, epoch: 152, loss: 0.292235
global_step: 30060, epoch: 152, loss: 0.312148
global_step: 30061, epoch: 152, loss: 0.334896
global_step: 30062, epoch: 152, loss: 0.313715
global_step: 30063, epoch: 152, loss: 0.362767
global_step: 30064, epoch: 152, loss: 0.345495
global_step: 30065, epoch: 152, loss: 0.342235
global_step: 30066, epoch: 152, loss: 0.273068
global_step: 30067, epoch: 152, loss: 0.351805
global_step: 30068, epoch: 152, loss: 0.326650
global_step: 30069, epoch: 152, loss: 0.273427
global_step: 30070, epoch: 152, loss: 0.310199
global_step: 30071, epoch: 152, loss: 0.347329
global_step: 30072, epoch: 152, loss: 0.370750
global_step: 30073, epoch: 152, loss: 0.354024
global_step: 30074, epoch: 152, loss: 0.406962
global_step: 30075, epoch: 152, loss: 0.350777
global_step: 30076, epoch: 152, loss: 0.387345
global_step: 30077, epoch: 152, loss: 0.367418
global_step: 30078, epoch: 152, loss: 0.383888
global_step: 30079, epoch: 152, loss: 0.352001
global_step: 30080, epoch: 152, loss: 0.181310
epoch: 152
train	acc: 0.9465	macro: p 0.9482, r 0.8799, f1: 0.9082	micro: p 0.9465, r 0.9465, f1 0.9465	weighted_f1:0.9456
dev	acc: 0.5582	macro: p 0.4509, r 0.3479, f1: 0.3552	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5248
test	acc: 0.5958	macro: p 0.4050, r 0.3588, f1: 0.3708	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5753
global_step: 30081, epoch: 153, loss: 0.294384
global_step: 30082, epoch: 153, loss: 0.365939
global_step: 30083, epoch: 153, loss: 0.325212
global_step: 30084, epoch: 153, loss: 0.316697
global_step: 30085, epoch: 153, loss: 0.324628
global_step: 30086, epoch: 153, loss: 0.345255
global_step: 30087, epoch: 153, loss: 0.293131
global_step: 30088, epoch: 153, loss: 0.372171
global_step: 30089, epoch: 153, loss: 0.398037
global_step: 30090, epoch: 153, loss: 0.392073
global_step: 30091, epoch: 153, loss: 0.397290
global_step: 30092, epoch: 153, loss: 0.274998
global_step: 30093, epoch: 153, loss: 0.357429
global_step: 30094, epoch: 153, loss: 0.233203
global_step: 30095, epoch: 153, loss: 0.325233
global_step: 30096, epoch: 153, loss: 0.310669
global_step: 30097, epoch: 153, loss: 0.333609
global_step: 30098, epoch: 153, loss: 0.382316
global_step: 30099, epoch: 153, loss: 0.332689
global_step: 30100, epoch: 153, loss: 0.322329
global_step: 30101, epoch: 153, loss: 0.271000
global_step: 30102, epoch: 153, loss: 0.322225
global_step: 30103, epoch: 153, loss: 0.286928
global_step: 30104, epoch: 153, loss: 0.387962
global_step: 30105, epoch: 153, loss: 0.343321
global_step: 30106, epoch: 153, loss: 0.348071
global_step: 30107, epoch: 153, loss: 0.328574
global_step: 30108, epoch: 153, loss: 0.370241
global_step: 30109, epoch: 153, loss: 0.355318
global_step: 30110, epoch: 153, loss: 0.322864
global_step: 30111, epoch: 153, loss: 0.310658
global_step: 30112, epoch: 153, loss: 0.336474
global_step: 30113, epoch: 153, loss: 0.317353
global_step: 30114, epoch: 153, loss: 0.332234
global_step: 30115, epoch: 153, loss: 0.326818
global_step: 30116, epoch: 153, loss: 0.346561
global_step: 30117, epoch: 153, loss: 0.391892
global_step: 30118, epoch: 153, loss: 0.300754
global_step: 30119, epoch: 153, loss: 0.351618
global_step: 30120, epoch: 153, loss: 0.047678
epoch: 153
train	acc: 0.9495	macro: p 0.9538, r 0.8945, f1: 0.9204	micro: p 0.9495, r 0.9495, f1 0.9495	weighted_f1:0.9489
dev	acc: 0.5573	macro: p 0.4117, r 0.3501, f1: 0.3564	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5220
test	acc: 0.5923	macro: p 0.4051, r 0.3560, f1: 0.3698	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5694
global_step: 30121, epoch: 154, loss: 0.305508
global_step: 30122, epoch: 154, loss: 0.324582
global_step: 30123, epoch: 154, loss: 0.342938
global_step: 30124, epoch: 154, loss: 0.295190
global_step: 30125, epoch: 154, loss: 0.310779
global_step: 30126, epoch: 154, loss: 0.358555
global_step: 30127, epoch: 154, loss: 0.366205
global_step: 30128, epoch: 154, loss: 0.308102
global_step: 30129, epoch: 154, loss: 0.304592
global_step: 30130, epoch: 154, loss: 0.325730
global_step: 30131, epoch: 154, loss: 0.323951
global_step: 30132, epoch: 154, loss: 0.341833
global_step: 30133, epoch: 154, loss: 0.277384
global_step: 30134, epoch: 154, loss: 0.322811
global_step: 30135, epoch: 154, loss: 0.326175
global_step: 30136, epoch: 154, loss: 0.321654
global_step: 30137, epoch: 154, loss: 0.331029
global_step: 30138, epoch: 154, loss: 0.328924
global_step: 30139, epoch: 154, loss: 0.268966
global_step: 30140, epoch: 154, loss: 0.347513
global_step: 30141, epoch: 154, loss: 0.376544
global_step: 30142, epoch: 154, loss: 0.329646
global_step: 30143, epoch: 154, loss: 0.282185
global_step: 30144, epoch: 154, loss: 0.301858
global_step: 30145, epoch: 154, loss: 0.373448
global_step: 30146, epoch: 154, loss: 0.440987
global_step: 30147, epoch: 154, loss: 0.325891
global_step: 30148, epoch: 154, loss: 0.293030
global_step: 30149, epoch: 154, loss: 0.324762
global_step: 30150, epoch: 154, loss: 0.295941
global_step: 30151, epoch: 154, loss: 0.370319
global_step: 30152, epoch: 154, loss: 0.306104
global_step: 30153, epoch: 154, loss: 0.338759
global_step: 30154, epoch: 154, loss: 0.321298
global_step: 30155, epoch: 154, loss: 0.312594
global_step: 30156, epoch: 154, loss: 0.308507
global_step: 30157, epoch: 154, loss: 0.378004
global_step: 30158, epoch: 154, loss: 0.441878
global_step: 30159, epoch: 154, loss: 0.336870
global_step: 30160, epoch: 154, loss: 0.939582
epoch: 154
train	acc: 0.9433	macro: p 0.9502, r 0.8847, f1: 0.9127	micro: p 0.9433, r 0.9433, f1 0.9433	weighted_f1:0.9426
dev	acc: 0.5546	macro: p 0.4457, r 0.3416, f1: 0.3489	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5120
test	acc: 0.5866	macro: p 0.3873, r 0.3364, f1: 0.3451	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5541
global_step: 30161, epoch: 155, loss: 0.360402
global_step: 30162, epoch: 155, loss: 0.357320
global_step: 30163, epoch: 155, loss: 0.330969
global_step: 30164, epoch: 155, loss: 0.248343
global_step: 30165, epoch: 155, loss: 0.342698
global_step: 30166, epoch: 155, loss: 0.406182
global_step: 30167, epoch: 155, loss: 0.310081
global_step: 30168, epoch: 155, loss: 0.328115
global_step: 30169, epoch: 155, loss: 0.301128
global_step: 30170, epoch: 155, loss: 0.258436
global_step: 30171, epoch: 155, loss: 0.293911
global_step: 30172, epoch: 155, loss: 0.333936
global_step: 30173, epoch: 155, loss: 0.236321
global_step: 30174, epoch: 155, loss: 0.416660
global_step: 30175, epoch: 155, loss: 0.288426
global_step: 30176, epoch: 155, loss: 0.329560
global_step: 30177, epoch: 155, loss: 0.352499
global_step: 30178, epoch: 155, loss: 0.355380
global_step: 30179, epoch: 155, loss: 0.282654
global_step: 30180, epoch: 155, loss: 0.329248
global_step: 30181, epoch: 155, loss: 0.301442
global_step: 30182, epoch: 155, loss: 0.278764
global_step: 30183, epoch: 155, loss: 0.339588
global_step: 30184, epoch: 155, loss: 0.415148
global_step: 30185, epoch: 155, loss: 0.363895
global_step: 30186, epoch: 155, loss: 0.260571
global_step: 30187, epoch: 155, loss: 0.291430
global_step: 30188, epoch: 155, loss: 0.304674
global_step: 30189, epoch: 155, loss: 0.328878
global_step: 30190, epoch: 155, loss: 0.288098
global_step: 30191, epoch: 155, loss: 0.232456
global_step: 30192, epoch: 155, loss: 0.260784
global_step: 30193, epoch: 155, loss: 0.369795
global_step: 30194, epoch: 155, loss: 0.393831
global_step: 30195, epoch: 155, loss: 0.286242
global_step: 30196, epoch: 155, loss: 0.346056
global_step: 30197, epoch: 155, loss: 0.325070
global_step: 30198, epoch: 155, loss: 0.308752
global_step: 30199, epoch: 155, loss: 0.323076
global_step: 30200, epoch: 155, loss: 0.550850
epoch: 155
train	acc: 0.9512	macro: p 0.9493, r 0.9037, f1: 0.9243	micro: p 0.9512, r 0.9512, f1 0.9512	weighted_f1:0.9508
dev	acc: 0.5609	macro: p 0.3953, r 0.3468, f1: 0.3531	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5243
test	acc: 0.5966	macro: p 0.4083, r 0.3634, f1: 0.3735	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5758
global_step: 30201, epoch: 156, loss: 0.288970
global_step: 30202, epoch: 156, loss: 0.332607
global_step: 30203, epoch: 156, loss: 0.332336
global_step: 30204, epoch: 156, loss: 0.330125
global_step: 30205, epoch: 156, loss: 0.265004
global_step: 30206, epoch: 156, loss: 0.301941
global_step: 30207, epoch: 156, loss: 0.331202
global_step: 30208, epoch: 156, loss: 0.362293
global_step: 30209, epoch: 156, loss: 0.353874
global_step: 30210, epoch: 156, loss: 0.241852
global_step: 30211, epoch: 156, loss: 0.272185
global_step: 30212, epoch: 156, loss: 0.390406
global_step: 30213, epoch: 156, loss: 0.275515
global_step: 30214, epoch: 156, loss: 0.245905
global_step: 30215, epoch: 156, loss: 0.288328
global_step: 30216, epoch: 156, loss: 0.282141
global_step: 30217, epoch: 156, loss: 0.348183
global_step: 30218, epoch: 156, loss: 0.331822
global_step: 30219, epoch: 156, loss: 0.266542
global_step: 30220, epoch: 156, loss: 0.350231
global_step: 30221, epoch: 156, loss: 0.320385
global_step: 30222, epoch: 156, loss: 0.357821
global_step: 30223, epoch: 156, loss: 0.338365
global_step: 30224, epoch: 156, loss: 0.286991
global_step: 30225, epoch: 156, loss: 0.318434
global_step: 30226, epoch: 156, loss: 0.328812
global_step: 30227, epoch: 156, loss: 0.338875
global_step: 30228, epoch: 156, loss: 0.359768
global_step: 30229, epoch: 156, loss: 0.305449
global_step: 30230, epoch: 156, loss: 0.347837
global_step: 30231, epoch: 156, loss: 0.284266
global_step: 30232, epoch: 156, loss: 0.371827
global_step: 30233, epoch: 156, loss: 0.339424
global_step: 30234, epoch: 156, loss: 0.337610
global_step: 30235, epoch: 156, loss: 0.347817
global_step: 30236, epoch: 156, loss: 0.357167
global_step: 30237, epoch: 156, loss: 0.309271
global_step: 30238, epoch: 156, loss: 0.371116
global_step: 30239, epoch: 156, loss: 0.356242
global_step: 30240, epoch: 156, loss: 0.926982
epoch: 156
train	acc: 0.9442	macro: p 0.9468, r 0.8781, f1: 0.9065	micro: p 0.9442, r 0.9442, f1 0.9442	weighted_f1:0.9434
dev	acc: 0.5636	macro: p 0.4151, r 0.3427, f1: 0.3488	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5240
test	acc: 0.6042	macro: p 0.4267, r 0.3582, f1: 0.3711	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5784
global_step: 30241, epoch: 157, loss: 0.328731
global_step: 30242, epoch: 157, loss: 0.335534
global_step: 30243, epoch: 157, loss: 0.308195
global_step: 30244, epoch: 157, loss: 0.407924
global_step: 30245, epoch: 157, loss: 0.309333
global_step: 30246, epoch: 157, loss: 0.320341
global_step: 30247, epoch: 157, loss: 0.309429
global_step: 30248, epoch: 157, loss: 0.348843
global_step: 30249, epoch: 157, loss: 0.362442
global_step: 30250, epoch: 157, loss: 0.388787
global_step: 30251, epoch: 157, loss: 0.287327
global_step: 30252, epoch: 157, loss: 0.306411
global_step: 30253, epoch: 157, loss: 0.300960
global_step: 30254, epoch: 157, loss: 0.256200
global_step: 30255, epoch: 157, loss: 0.288962
global_step: 30256, epoch: 157, loss: 0.312821
global_step: 30257, epoch: 157, loss: 0.269965
global_step: 30258, epoch: 157, loss: 0.282706
global_step: 30259, epoch: 157, loss: 0.309419
global_step: 30260, epoch: 157, loss: 0.337763
global_step: 30261, epoch: 157, loss: 0.368051
global_step: 30262, epoch: 157, loss: 0.358396
global_step: 30263, epoch: 157, loss: 0.323007
global_step: 30264, epoch: 157, loss: 0.269466
global_step: 30265, epoch: 157, loss: 0.308276
global_step: 30266, epoch: 157, loss: 0.243807
global_step: 30267, epoch: 157, loss: 0.306948
global_step: 30268, epoch: 157, loss: 0.258036
global_step: 30269, epoch: 157, loss: 0.367221
global_step: 30270, epoch: 157, loss: 0.320614
global_step: 30271, epoch: 157, loss: 0.317069
global_step: 30272, epoch: 157, loss: 0.342463
global_step: 30273, epoch: 157, loss: 0.312949
global_step: 30274, epoch: 157, loss: 0.276929
global_step: 30275, epoch: 157, loss: 0.313459
global_step: 30276, epoch: 157, loss: 0.423534
global_step: 30277, epoch: 157, loss: 0.329924
global_step: 30278, epoch: 157, loss: 0.290707
global_step: 30279, epoch: 157, loss: 0.314164
global_step: 30280, epoch: 157, loss: 0.346279
epoch: 157
train	acc: 0.9485	macro: p 0.9467, r 0.8823, f1: 0.9080	micro: p 0.9485, r 0.9485, f1 0.9485	weighted_f1:0.9475
dev	acc: 0.5600	macro: p 0.4112, r 0.3530, f1: 0.3562	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5275
test	acc: 0.5870	macro: p 0.4106, r 0.3677, f1: 0.3778	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5712
global_step: 30281, epoch: 158, loss: 0.307740
global_step: 30282, epoch: 158, loss: 0.286031
global_step: 30283, epoch: 158, loss: 0.349994
global_step: 30284, epoch: 158, loss: 0.346943
global_step: 30285, epoch: 158, loss: 0.336384
global_step: 30286, epoch: 158, loss: 0.248814
global_step: 30287, epoch: 158, loss: 0.295329
global_step: 30288, epoch: 158, loss: 0.323862
global_step: 30289, epoch: 158, loss: 0.300866
global_step: 30290, epoch: 158, loss: 0.353231
global_step: 30291, epoch: 158, loss: 0.291975
global_step: 30292, epoch: 158, loss: 0.284200
global_step: 30293, epoch: 158, loss: 0.356220
global_step: 30294, epoch: 158, loss: 0.340142
global_step: 30295, epoch: 158, loss: 0.373137
global_step: 30296, epoch: 158, loss: 0.352503
global_step: 30297, epoch: 158, loss: 0.296042
global_step: 30298, epoch: 158, loss: 0.319544
global_step: 30299, epoch: 158, loss: 0.341110
global_step: 30300, epoch: 158, loss: 0.399104
global_step: 30301, epoch: 158, loss: 0.293805
global_step: 30302, epoch: 158, loss: 0.249782
global_step: 30303, epoch: 158, loss: 0.258036
global_step: 30304, epoch: 158, loss: 0.316430
global_step: 30305, epoch: 158, loss: 0.278044
global_step: 30306, epoch: 158, loss: 0.443433
global_step: 30307, epoch: 158, loss: 0.307302
global_step: 30308, epoch: 158, loss: 0.381330
global_step: 30309, epoch: 158, loss: 0.360102
global_step: 30310, epoch: 158, loss: 0.303402
global_step: 30311, epoch: 158, loss: 0.314686
global_step: 30312, epoch: 158, loss: 0.301392
global_step: 30313, epoch: 158, loss: 0.213156
global_step: 30314, epoch: 158, loss: 0.273179
global_step: 30315, epoch: 158, loss: 0.256564
global_step: 30316, epoch: 158, loss: 0.256144
global_step: 30317, epoch: 158, loss: 0.240562
global_step: 30318, epoch: 158, loss: 0.292792
global_step: 30319, epoch: 158, loss: 0.307772
global_step: 30320, epoch: 158, loss: 0.455118
epoch: 158
train	acc: 0.9493	macro: p 0.9527, r 0.8892, f1: 0.9160	micro: p 0.9493, r 0.9493, f1 0.9493	weighted_f1:0.9485
dev	acc: 0.5528	macro: p 0.5028, r 0.3338, f1: 0.3393	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5112
test	acc: 0.5870	macro: p 0.3928, r 0.3426, f1: 0.3554	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5591
global_step: 30321, epoch: 159, loss: 0.275879
global_step: 30322, epoch: 159, loss: 0.378835
global_step: 30323, epoch: 159, loss: 0.339411
global_step: 30324, epoch: 159, loss: 0.321504
global_step: 30325, epoch: 159, loss: 0.365263
global_step: 30326, epoch: 159, loss: 0.297371
global_step: 30327, epoch: 159, loss: 0.314138
global_step: 30328, epoch: 159, loss: 0.281234
global_step: 30329, epoch: 159, loss: 0.344839
global_step: 30330, epoch: 159, loss: 0.271320
global_step: 30331, epoch: 159, loss: 0.288255
global_step: 30332, epoch: 159, loss: 0.328248
global_step: 30333, epoch: 159, loss: 0.311033
global_step: 30334, epoch: 159, loss: 0.406991
global_step: 30335, epoch: 159, loss: 0.343035
global_step: 30336, epoch: 159, loss: 0.293116
global_step: 30337, epoch: 159, loss: 0.312186
global_step: 30338, epoch: 159, loss: 0.285961
global_step: 30339, epoch: 159, loss: 0.296868
global_step: 30340, epoch: 159, loss: 0.320211
global_step: 30341, epoch: 159, loss: 0.313163
global_step: 30342, epoch: 159, loss: 0.266823
global_step: 30343, epoch: 159, loss: 0.330116
global_step: 30344, epoch: 159, loss: 0.280235
global_step: 30345, epoch: 159, loss: 0.281324
global_step: 30346, epoch: 159, loss: 0.359413
global_step: 30347, epoch: 159, loss: 0.312545
global_step: 30348, epoch: 159, loss: 0.325529
global_step: 30349, epoch: 159, loss: 0.371948
global_step: 30350, epoch: 159, loss: 0.334236
global_step: 30351, epoch: 159, loss: 0.293651
global_step: 30352, epoch: 159, loss: 0.371554
global_step: 30353, epoch: 159, loss: 0.360200
global_step: 30354, epoch: 159, loss: 0.252134
global_step: 30355, epoch: 159, loss: 0.387780
global_step: 30356, epoch: 159, loss: 0.347099
global_step: 30357, epoch: 159, loss: 0.394889
global_step: 30358, epoch: 159, loss: 0.348423
global_step: 30359, epoch: 159, loss: 0.267478
global_step: 30360, epoch: 159, loss: 0.904788
epoch: 159
train	acc: 0.9535	macro: p 0.9553, r 0.9094, f1: 0.9304	micro: p 0.9535, r 0.9535, f1 0.9535	weighted_f1:0.9531
dev	acc: 0.5582	macro: p 0.3881, r 0.3469, f1: 0.3567	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5255
test	acc: 0.5958	macro: p 0.4155, r 0.3638, f1: 0.3813	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5733
global_step: 30361, epoch: 160, loss: 0.412970
global_step: 30362, epoch: 160, loss: 0.291718
global_step: 30363, epoch: 160, loss: 0.310932
global_step: 30364, epoch: 160, loss: 0.285554
global_step: 30365, epoch: 160, loss: 0.313121
global_step: 30366, epoch: 160, loss: 0.385712
global_step: 30367, epoch: 160, loss: 0.295707
global_step: 30368, epoch: 160, loss: 0.263301
global_step: 30369, epoch: 160, loss: 0.322929
global_step: 30370, epoch: 160, loss: 0.295841
global_step: 30371, epoch: 160, loss: 0.349959
global_step: 30372, epoch: 160, loss: 0.361686
global_step: 30373, epoch: 160, loss: 0.262396
global_step: 30374, epoch: 160, loss: 0.301574
global_step: 30375, epoch: 160, loss: 0.272229
global_step: 30376, epoch: 160, loss: 0.345697
global_step: 30377, epoch: 160, loss: 0.338832
global_step: 30378, epoch: 160, loss: 0.316731
global_step: 30379, epoch: 160, loss: 0.316860
global_step: 30380, epoch: 160, loss: 0.345310
global_step: 30381, epoch: 160, loss: 0.221238
global_step: 30382, epoch: 160, loss: 0.313967
global_step: 30383, epoch: 160, loss: 0.331560
global_step: 30384, epoch: 160, loss: 0.294453
global_step: 30385, epoch: 160, loss: 0.380024
global_step: 30386, epoch: 160, loss: 0.389046
global_step: 30387, epoch: 160, loss: 0.309691
global_step: 30388, epoch: 160, loss: 0.308803
global_step: 30389, epoch: 160, loss: 0.373779
global_step: 30390, epoch: 160, loss: 0.322101
global_step: 30391, epoch: 160, loss: 0.298854
global_step: 30392, epoch: 160, loss: 0.302732
global_step: 30393, epoch: 160, loss: 0.321037
global_step: 30394, epoch: 160, loss: 0.292386
global_step: 30395, epoch: 160, loss: 0.257839
global_step: 30396, epoch: 160, loss: 0.288393
global_step: 30397, epoch: 160, loss: 0.281038
global_step: 30398, epoch: 160, loss: 0.350540
global_step: 30399, epoch: 160, loss: 0.309700
global_step: 30400, epoch: 160, loss: 0.060246
epoch: 160
train	acc: 0.9528	macro: p 0.9513, r 0.9016, f1: 0.9226	micro: p 0.9528, r 0.9528, f1 0.9528	weighted_f1:0.9522
dev	acc: 0.5564	macro: p 0.3820, r 0.3538, f1: 0.3574	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5299
test	acc: 0.5862	macro: p 0.3870, r 0.3598, f1: 0.3685	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5720
global_step: 30401, epoch: 161, loss: 0.354707
global_step: 30402, epoch: 161, loss: 0.323613
global_step: 30403, epoch: 161, loss: 0.276881
global_step: 30404, epoch: 161, loss: 0.240372
global_step: 30405, epoch: 161, loss: 0.326607
global_step: 30406, epoch: 161, loss: 0.313503
global_step: 30407, epoch: 161, loss: 0.290283
global_step: 30408, epoch: 161, loss: 0.278667
global_step: 30409, epoch: 161, loss: 0.342998
global_step: 30410, epoch: 161, loss: 0.346723
global_step: 30411, epoch: 161, loss: 0.268119
global_step: 30412, epoch: 161, loss: 0.301818
global_step: 30413, epoch: 161, loss: 0.335964
global_step: 30414, epoch: 161, loss: 0.260586
global_step: 30415, epoch: 161, loss: 0.341161
global_step: 30416, epoch: 161, loss: 0.260970
global_step: 30417, epoch: 161, loss: 0.338866
global_step: 30418, epoch: 161, loss: 0.348733
global_step: 30419, epoch: 161, loss: 0.402166
global_step: 30420, epoch: 161, loss: 0.328058
global_step: 30421, epoch: 161, loss: 0.259925
global_step: 30422, epoch: 161, loss: 0.300856
global_step: 30423, epoch: 161, loss: 0.316792
global_step: 30424, epoch: 161, loss: 0.311546
global_step: 30425, epoch: 161, loss: 0.319318
global_step: 30426, epoch: 161, loss: 0.317508
global_step: 30427, epoch: 161, loss: 0.450803
global_step: 30428, epoch: 161, loss: 0.329620
global_step: 30429, epoch: 161, loss: 0.333962
global_step: 30430, epoch: 161, loss: 0.312732
global_step: 30431, epoch: 161, loss: 0.277103
global_step: 30432, epoch: 161, loss: 0.323996
global_step: 30433, epoch: 161, loss: 0.321155
global_step: 30434, epoch: 161, loss: 0.318560
global_step: 30435, epoch: 161, loss: 0.275364
global_step: 30436, epoch: 161, loss: 0.368745
global_step: 30437, epoch: 161, loss: 0.290109
global_step: 30438, epoch: 161, loss: 0.247615
global_step: 30439, epoch: 161, loss: 0.272278
global_step: 30440, epoch: 161, loss: 0.216628
epoch: 161
train	acc: 0.9533	macro: p 0.9551, r 0.9059, f1: 0.9274	micro: p 0.9533, r 0.9533, f1 0.9533	weighted_f1:0.9529
dev	acc: 0.5591	macro: p 0.4106, r 0.3587, f1: 0.3647	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5289
test	acc: 0.5943	macro: p 0.3981, r 0.3631, f1: 0.3710	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5761
global_step: 30441, epoch: 162, loss: 0.244563
global_step: 30442, epoch: 162, loss: 0.344397
global_step: 30443, epoch: 162, loss: 0.195336
global_step: 30444, epoch: 162, loss: 0.232262
global_step: 30445, epoch: 162, loss: 0.290452
global_step: 30446, epoch: 162, loss: 0.329116
global_step: 30447, epoch: 162, loss: 0.274891
global_step: 30448, epoch: 162, loss: 0.284524
global_step: 30449, epoch: 162, loss: 0.343987
global_step: 30450, epoch: 162, loss: 0.346970
global_step: 30451, epoch: 162, loss: 0.347067
global_step: 30452, epoch: 162, loss: 0.331553
global_step: 30453, epoch: 162, loss: 0.295933
global_step: 30454, epoch: 162, loss: 0.301118
global_step: 30455, epoch: 162, loss: 0.304494
global_step: 30456, epoch: 162, loss: 0.295323
global_step: 30457, epoch: 162, loss: 0.268794
global_step: 30458, epoch: 162, loss: 0.291785
global_step: 30459, epoch: 162, loss: 0.301126
global_step: 30460, epoch: 162, loss: 0.278839
global_step: 30461, epoch: 162, loss: 0.338703
global_step: 30462, epoch: 162, loss: 0.321419
global_step: 30463, epoch: 162, loss: 0.326560
global_step: 30464, epoch: 162, loss: 0.368155
global_step: 30465, epoch: 162, loss: 0.348698
global_step: 30466, epoch: 162, loss: 0.327943
global_step: 30467, epoch: 162, loss: 0.336893
global_step: 30468, epoch: 162, loss: 0.370938
global_step: 30469, epoch: 162, loss: 0.294905
global_step: 30470, epoch: 162, loss: 0.262498
global_step: 30471, epoch: 162, loss: 0.331851
global_step: 30472, epoch: 162, loss: 0.314418
global_step: 30473, epoch: 162, loss: 0.291936
global_step: 30474, epoch: 162, loss: 0.295689
global_step: 30475, epoch: 162, loss: 0.299776
global_step: 30476, epoch: 162, loss: 0.368822
global_step: 30477, epoch: 162, loss: 0.310143
global_step: 30478, epoch: 162, loss: 0.349201
global_step: 30479, epoch: 162, loss: 0.287319
global_step: 30480, epoch: 162, loss: 0.625877
epoch: 162
train	acc: 0.9499	macro: p 0.9547, r 0.8917, f1: 0.9186	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9492
dev	acc: 0.5546	macro: p 0.4520, r 0.3322, f1: 0.3369	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5096
test	acc: 0.5969	macro: p 0.4213, r 0.3496, f1: 0.3645	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5676
global_step: 30481, epoch: 163, loss: 0.328647
global_step: 30482, epoch: 163, loss: 0.349900
global_step: 30483, epoch: 163, loss: 0.277665
global_step: 30484, epoch: 163, loss: 0.326722
global_step: 30485, epoch: 163, loss: 0.240440
global_step: 30486, epoch: 163, loss: 0.321130
global_step: 30487, epoch: 163, loss: 0.284472
global_step: 30488, epoch: 163, loss: 0.248969
global_step: 30489, epoch: 163, loss: 0.296640
global_step: 30490, epoch: 163, loss: 0.307418
global_step: 30491, epoch: 163, loss: 0.251828
global_step: 30492, epoch: 163, loss: 0.332752
global_step: 30493, epoch: 163, loss: 0.312222
global_step: 30494, epoch: 163, loss: 0.285533
global_step: 30495, epoch: 163, loss: 0.304657
global_step: 30496, epoch: 163, loss: 0.292696
global_step: 30497, epoch: 163, loss: 0.349527
global_step: 30498, epoch: 163, loss: 0.357538
global_step: 30499, epoch: 163, loss: 0.323540
global_step: 30500, epoch: 163, loss: 0.289026
global_step: 30501, epoch: 163, loss: 0.216048
global_step: 30502, epoch: 163, loss: 0.267779
global_step: 30503, epoch: 163, loss: 0.387112
global_step: 30504, epoch: 163, loss: 0.301644
global_step: 30505, epoch: 163, loss: 0.347653
global_step: 30506, epoch: 163, loss: 0.263431
global_step: 30507, epoch: 163, loss: 0.331936
global_step: 30508, epoch: 163, loss: 0.305506
global_step: 30509, epoch: 163, loss: 0.273340
global_step: 30510, epoch: 163, loss: 0.407051
global_step: 30511, epoch: 163, loss: 0.247115
global_step: 30512, epoch: 163, loss: 0.289810
global_step: 30513, epoch: 163, loss: 0.312038
global_step: 30514, epoch: 163, loss: 0.271729
global_step: 30515, epoch: 163, loss: 0.328394
global_step: 30516, epoch: 163, loss: 0.417995
global_step: 30517, epoch: 163, loss: 0.276754
global_step: 30518, epoch: 163, loss: 0.316914
global_step: 30519, epoch: 163, loss: 0.313300
global_step: 30520, epoch: 163, loss: 0.053343
epoch: 163
train	acc: 0.9560	macro: p 0.9584, r 0.9118, f1: 0.9326	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9556
dev	acc: 0.5528	macro: p 0.3824, r 0.3419, f1: 0.3459	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5194
test	acc: 0.5920	macro: p 0.4056, r 0.3680, f1: 0.3786	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5755
global_step: 30521, epoch: 164, loss: 0.282504
global_step: 30522, epoch: 164, loss: 0.349678
global_step: 30523, epoch: 164, loss: 0.329121
global_step: 30524, epoch: 164, loss: 0.261154
global_step: 30525, epoch: 164, loss: 0.299176
global_step: 30526, epoch: 164, loss: 0.301258
global_step: 30527, epoch: 164, loss: 0.306905
global_step: 30528, epoch: 164, loss: 0.311488
global_step: 30529, epoch: 164, loss: 0.316330
global_step: 30530, epoch: 164, loss: 0.294646
global_step: 30531, epoch: 164, loss: 0.289740
global_step: 30532, epoch: 164, loss: 0.294919
global_step: 30533, epoch: 164, loss: 0.261389
global_step: 30534, epoch: 164, loss: 0.337582
global_step: 30535, epoch: 164, loss: 0.319028
global_step: 30536, epoch: 164, loss: 0.298988
global_step: 30537, epoch: 164, loss: 0.283345
global_step: 30538, epoch: 164, loss: 0.365227
global_step: 30539, epoch: 164, loss: 0.312234
global_step: 30540, epoch: 164, loss: 0.312971
global_step: 30541, epoch: 164, loss: 0.363206
global_step: 30542, epoch: 164, loss: 0.298988
global_step: 30543, epoch: 164, loss: 0.319078
global_step: 30544, epoch: 164, loss: 0.287741
global_step: 30545, epoch: 164, loss: 0.332459
global_step: 30546, epoch: 164, loss: 0.287495
global_step: 30547, epoch: 164, loss: 0.312616
global_step: 30548, epoch: 164, loss: 0.353209
global_step: 30549, epoch: 164, loss: 0.273643
global_step: 30550, epoch: 164, loss: 0.316756
global_step: 30551, epoch: 164, loss: 0.311875
global_step: 30552, epoch: 164, loss: 0.299599
global_step: 30553, epoch: 164, loss: 0.309037
global_step: 30554, epoch: 164, loss: 0.288594
global_step: 30555, epoch: 164, loss: 0.329114
global_step: 30556, epoch: 164, loss: 0.260691
global_step: 30557, epoch: 164, loss: 0.290009
global_step: 30558, epoch: 164, loss: 0.393785
global_step: 30559, epoch: 164, loss: 0.307388
global_step: 30560, epoch: 164, loss: 0.015424
epoch: 164
train	acc: 0.9547	macro: p 0.9589, r 0.9074, f1: 0.9301	micro: p 0.9547, r 0.9547, f1 0.9547	weighted_f1:0.9542
dev	acc: 0.5546	macro: p 0.3992, r 0.3398, f1: 0.3434	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5159
test	acc: 0.5904	macro: p 0.3868, r 0.3489, f1: 0.3573	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5661
global_step: 30561, epoch: 165, loss: 0.366378
global_step: 30562, epoch: 165, loss: 0.343752
global_step: 30563, epoch: 165, loss: 0.347196
global_step: 30564, epoch: 165, loss: 0.280227
global_step: 30565, epoch: 165, loss: 0.248203
global_step: 30566, epoch: 165, loss: 0.369244
global_step: 30567, epoch: 165, loss: 0.310873
global_step: 30568, epoch: 165, loss: 0.271179
global_step: 30569, epoch: 165, loss: 0.280399
global_step: 30570, epoch: 165, loss: 0.311247
global_step: 30571, epoch: 165, loss: 0.314432
global_step: 30572, epoch: 165, loss: 0.268476
global_step: 30573, epoch: 165, loss: 0.254440
global_step: 30574, epoch: 165, loss: 0.244561
global_step: 30575, epoch: 165, loss: 0.259880
global_step: 30576, epoch: 165, loss: 0.257330
global_step: 30577, epoch: 165, loss: 0.334364
global_step: 30578, epoch: 165, loss: 0.357845
global_step: 30579, epoch: 165, loss: 0.229017
global_step: 30580, epoch: 165, loss: 0.278635
global_step: 30581, epoch: 165, loss: 0.331004
global_step: 30582, epoch: 165, loss: 0.292418
global_step: 30583, epoch: 165, loss: 0.410752
global_step: 30584, epoch: 165, loss: 0.292354
global_step: 30585, epoch: 165, loss: 0.342947
global_step: 30586, epoch: 165, loss: 0.304958
global_step: 30587, epoch: 165, loss: 0.271036
global_step: 30588, epoch: 165, loss: 0.286220
global_step: 30589, epoch: 165, loss: 0.336284
global_step: 30590, epoch: 165, loss: 0.360042
global_step: 30591, epoch: 165, loss: 0.282639
global_step: 30592, epoch: 165, loss: 0.370688
global_step: 30593, epoch: 165, loss: 0.249653
global_step: 30594, epoch: 165, loss: 0.289170
global_step: 30595, epoch: 165, loss: 0.327852
global_step: 30596, epoch: 165, loss: 0.265613
global_step: 30597, epoch: 165, loss: 0.297840
global_step: 30598, epoch: 165, loss: 0.339833
global_step: 30599, epoch: 165, loss: 0.320485
global_step: 30600, epoch: 165, loss: 0.291344
epoch: 165
train	acc: 0.9487	macro: p 0.9554, r 0.8945, f1: 0.9209	micro: p 0.9487, r 0.9487, f1 0.9487	weighted_f1:0.9481
dev	acc: 0.5573	macro: p 0.3933, r 0.3391, f1: 0.3459	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5182
test	acc: 0.5996	macro: p 0.4235, r 0.3535, f1: 0.3712	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5722
global_step: 30601, epoch: 166, loss: 0.403719
global_step: 30602, epoch: 166, loss: 0.301006
global_step: 30603, epoch: 166, loss: 0.288527
global_step: 30604, epoch: 166, loss: 0.377904
global_step: 30605, epoch: 166, loss: 0.341359
global_step: 30606, epoch: 166, loss: 0.326092
global_step: 30607, epoch: 166, loss: 0.332724
global_step: 30608, epoch: 166, loss: 0.287633
global_step: 30609, epoch: 166, loss: 0.253471
global_step: 30610, epoch: 166, loss: 0.318137
global_step: 30611, epoch: 166, loss: 0.276874
global_step: 30612, epoch: 166, loss: 0.256300
global_step: 30613, epoch: 166, loss: 0.237261
global_step: 30614, epoch: 166, loss: 0.405218
global_step: 30615, epoch: 166, loss: 0.267503
global_step: 30616, epoch: 166, loss: 0.246241
global_step: 30617, epoch: 166, loss: 0.353021
global_step: 30618, epoch: 166, loss: 0.272287
global_step: 30619, epoch: 166, loss: 0.305027
global_step: 30620, epoch: 166, loss: 0.342870
global_step: 30621, epoch: 166, loss: 0.392147
global_step: 30622, epoch: 166, loss: 0.293971
global_step: 30623, epoch: 166, loss: 0.254493
global_step: 30624, epoch: 166, loss: 0.278637
global_step: 30625, epoch: 166, loss: 0.269381
global_step: 30626, epoch: 166, loss: 0.310679
global_step: 30627, epoch: 166, loss: 0.374484
global_step: 30628, epoch: 166, loss: 0.276473
global_step: 30629, epoch: 166, loss: 0.266719
global_step: 30630, epoch: 166, loss: 0.242909
global_step: 30631, epoch: 166, loss: 0.220696
global_step: 30632, epoch: 166, loss: 0.337827
global_step: 30633, epoch: 166, loss: 0.356173
global_step: 30634, epoch: 166, loss: 0.356797
global_step: 30635, epoch: 166, loss: 0.369126
global_step: 30636, epoch: 166, loss: 0.281358
global_step: 30637, epoch: 166, loss: 0.233367
global_step: 30638, epoch: 166, loss: 0.316841
global_step: 30639, epoch: 166, loss: 0.354323
global_step: 30640, epoch: 166, loss: 0.040035
epoch: 166
train	acc: 0.9540	macro: p 0.9562, r 0.9037, f1: 0.9260	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9535
dev	acc: 0.5555	macro: p 0.4134, r 0.3526, f1: 0.3566	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5288
test	acc: 0.5889	macro: p 0.4010, r 0.3662, f1: 0.3738	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5746
global_step: 30641, epoch: 167, loss: 0.285309
global_step: 30642, epoch: 167, loss: 0.298979
global_step: 30643, epoch: 167, loss: 0.368266
global_step: 30644, epoch: 167, loss: 0.234754
global_step: 30645, epoch: 167, loss: 0.294924
global_step: 30646, epoch: 167, loss: 0.270301
global_step: 30647, epoch: 167, loss: 0.273421
global_step: 30648, epoch: 167, loss: 0.361825
global_step: 30649, epoch: 167, loss: 0.289709
global_step: 30650, epoch: 167, loss: 0.399058
global_step: 30651, epoch: 167, loss: 0.261865
global_step: 30652, epoch: 167, loss: 0.329326
global_step: 30653, epoch: 167, loss: 0.311151
global_step: 30654, epoch: 167, loss: 0.300112
global_step: 30655, epoch: 167, loss: 0.286904
global_step: 30656, epoch: 167, loss: 0.289365
global_step: 30657, epoch: 167, loss: 0.304350
global_step: 30658, epoch: 167, loss: 0.220005
global_step: 30659, epoch: 167, loss: 0.262335
global_step: 30660, epoch: 167, loss: 0.278357
global_step: 30661, epoch: 167, loss: 0.269202
global_step: 30662, epoch: 167, loss: 0.299238
global_step: 30663, epoch: 167, loss: 0.233750
global_step: 30664, epoch: 167, loss: 0.320955
global_step: 30665, epoch: 167, loss: 0.356481
global_step: 30666, epoch: 167, loss: 0.332954
global_step: 30667, epoch: 167, loss: 0.308687
global_step: 30668, epoch: 167, loss: 0.371959
global_step: 30669, epoch: 167, loss: 0.240732
global_step: 30670, epoch: 167, loss: 0.239070
global_step: 30671, epoch: 167, loss: 0.301043
global_step: 30672, epoch: 167, loss: 0.303627
global_step: 30673, epoch: 167, loss: 0.311051
global_step: 30674, epoch: 167, loss: 0.277671
global_step: 30675, epoch: 167, loss: 0.294471
global_step: 30676, epoch: 167, loss: 0.324051
global_step: 30677, epoch: 167, loss: 0.329320
global_step: 30678, epoch: 167, loss: 0.352104
global_step: 30679, epoch: 167, loss: 0.301769
global_step: 30680, epoch: 167, loss: 0.072347
epoch: 167
train	acc: 0.9559	macro: p 0.9599, r 0.9135, f1: 0.9344	micro: p 0.9559, r 0.9559, f1 0.9559	weighted_f1:0.9555
dev	acc: 0.5564	macro: p 0.4100, r 0.3387, f1: 0.3434	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5171
test	acc: 0.5927	macro: p 0.3911, r 0.3476, f1: 0.3585	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5667
global_step: 30681, epoch: 168, loss: 0.279094
global_step: 30682, epoch: 168, loss: 0.315901
global_step: 30683, epoch: 168, loss: 0.321366
global_step: 30684, epoch: 168, loss: 0.320256
global_step: 30685, epoch: 168, loss: 0.317945
global_step: 30686, epoch: 168, loss: 0.267575
global_step: 30687, epoch: 168, loss: 0.266640
global_step: 30688, epoch: 168, loss: 0.274421
global_step: 30689, epoch: 168, loss: 0.328030
global_step: 30690, epoch: 168, loss: 0.276702
global_step: 30691, epoch: 168, loss: 0.295142
global_step: 30692, epoch: 168, loss: 0.267562
global_step: 30693, epoch: 168, loss: 0.257122
global_step: 30694, epoch: 168, loss: 0.327157
global_step: 30695, epoch: 168, loss: 0.235020
global_step: 30696, epoch: 168, loss: 0.314247
global_step: 30697, epoch: 168, loss: 0.273466
global_step: 30698, epoch: 168, loss: 0.345453
global_step: 30699, epoch: 168, loss: 0.244964
global_step: 30700, epoch: 168, loss: 0.307534
global_step: 30701, epoch: 168, loss: 0.263505
global_step: 30702, epoch: 168, loss: 0.310189
global_step: 30703, epoch: 168, loss: 0.249544
global_step: 30704, epoch: 168, loss: 0.339779
global_step: 30705, epoch: 168, loss: 0.307974
global_step: 30706, epoch: 168, loss: 0.355602
global_step: 30707, epoch: 168, loss: 0.255627
global_step: 30708, epoch: 168, loss: 0.234948
global_step: 30709, epoch: 168, loss: 0.276604
global_step: 30710, epoch: 168, loss: 0.311477
global_step: 30711, epoch: 168, loss: 0.326920
global_step: 30712, epoch: 168, loss: 0.275783
global_step: 30713, epoch: 168, loss: 0.333729
global_step: 30714, epoch: 168, loss: 0.286847
global_step: 30715, epoch: 168, loss: 0.372934
global_step: 30716, epoch: 168, loss: 0.249178
global_step: 30717, epoch: 168, loss: 0.290117
global_step: 30718, epoch: 168, loss: 0.289606
global_step: 30719, epoch: 168, loss: 0.265249
global_step: 30720, epoch: 168, loss: 0.528302
epoch: 168
train	acc: 0.9523	macro: p 0.9564, r 0.8998, f1: 0.9241	micro: p 0.9523, r 0.9523, f1 0.9523	weighted_f1:0.9517
dev	acc: 0.5528	macro: p 0.4371, r 0.3355, f1: 0.3407	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5121
test	acc: 0.5889	macro: p 0.3961, r 0.3477, f1: 0.3594	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5645
global_step: 30721, epoch: 169, loss: 0.330903
global_step: 30722, epoch: 169, loss: 0.407740
global_step: 30723, epoch: 169, loss: 0.225586
global_step: 30724, epoch: 169, loss: 0.286926
global_step: 30725, epoch: 169, loss: 0.291985
global_step: 30726, epoch: 169, loss: 0.342976
global_step: 30727, epoch: 169, loss: 0.234625
global_step: 30728, epoch: 169, loss: 0.324381
global_step: 30729, epoch: 169, loss: 0.217106
global_step: 30730, epoch: 169, loss: 0.371779
global_step: 30731, epoch: 169, loss: 0.359061
global_step: 30732, epoch: 169, loss: 0.327041
global_step: 30733, epoch: 169, loss: 0.250074
global_step: 30734, epoch: 169, loss: 0.296688
global_step: 30735, epoch: 169, loss: 0.278507
global_step: 30736, epoch: 169, loss: 0.305017
global_step: 30737, epoch: 169, loss: 0.292680
global_step: 30738, epoch: 169, loss: 0.249447
global_step: 30739, epoch: 169, loss: 0.311858
global_step: 30740, epoch: 169, loss: 0.295031
global_step: 30741, epoch: 169, loss: 0.364008
global_step: 30742, epoch: 169, loss: 0.270076
global_step: 30743, epoch: 169, loss: 0.306169
global_step: 30744, epoch: 169, loss: 0.303679
global_step: 30745, epoch: 169, loss: 0.309066
global_step: 30746, epoch: 169, loss: 0.327901
global_step: 30747, epoch: 169, loss: 0.326088
global_step: 30748, epoch: 169, loss: 0.239110
global_step: 30749, epoch: 169, loss: 0.235400
global_step: 30750, epoch: 169, loss: 0.265075
global_step: 30751, epoch: 169, loss: 0.299786
global_step: 30752, epoch: 169, loss: 0.341181
global_step: 30753, epoch: 169, loss: 0.303861
global_step: 30754, epoch: 169, loss: 0.284802
global_step: 30755, epoch: 169, loss: 0.309935
global_step: 30756, epoch: 169, loss: 0.284821
global_step: 30757, epoch: 169, loss: 0.273700
global_step: 30758, epoch: 169, loss: 0.255461
global_step: 30759, epoch: 169, loss: 0.311421
global_step: 30760, epoch: 169, loss: 0.093549
epoch: 169
train	acc: 0.9561	macro: p 0.9592, r 0.9152, f1: 0.9350	micro: p 0.9561, r 0.9561, f1 0.9561	weighted_f1:0.9557
dev	acc: 0.5591	macro: p 0.4112, r 0.3506, f1: 0.3606	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5253
test	acc: 0.5881	macro: p 0.3937, r 0.3514, f1: 0.3630	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5668
global_step: 30761, epoch: 170, loss: 0.280066
global_step: 30762, epoch: 170, loss: 0.291156
global_step: 30763, epoch: 170, loss: 0.287964
global_step: 30764, epoch: 170, loss: 0.303679
global_step: 30765, epoch: 170, loss: 0.277384
global_step: 30766, epoch: 170, loss: 0.286717
global_step: 30767, epoch: 170, loss: 0.256095
global_step: 30768, epoch: 170, loss: 0.229727
global_step: 30769, epoch: 170, loss: 0.335887
global_step: 30770, epoch: 170, loss: 0.234939
global_step: 30771, epoch: 170, loss: 0.280520
global_step: 30772, epoch: 170, loss: 0.288754
global_step: 30773, epoch: 170, loss: 0.268948
global_step: 30774, epoch: 170, loss: 0.289181
global_step: 30775, epoch: 170, loss: 0.280427
global_step: 30776, epoch: 170, loss: 0.268012
global_step: 30777, epoch: 170, loss: 0.282666
global_step: 30778, epoch: 170, loss: 0.305859
global_step: 30779, epoch: 170, loss: 0.308952
global_step: 30780, epoch: 170, loss: 0.267967
global_step: 30781, epoch: 170, loss: 0.360427
global_step: 30782, epoch: 170, loss: 0.256161
global_step: 30783, epoch: 170, loss: 0.290500
global_step: 30784, epoch: 170, loss: 0.372743
global_step: 30785, epoch: 170, loss: 0.295513
global_step: 30786, epoch: 170, loss: 0.322435
global_step: 30787, epoch: 170, loss: 0.253412
global_step: 30788, epoch: 170, loss: 0.295094
global_step: 30789, epoch: 170, loss: 0.279378
global_step: 30790, epoch: 170, loss: 0.323192
global_step: 30791, epoch: 170, loss: 0.240812
global_step: 30792, epoch: 170, loss: 0.217665
global_step: 30793, epoch: 170, loss: 0.270142
global_step: 30794, epoch: 170, loss: 0.289198
global_step: 30795, epoch: 170, loss: 0.325785
global_step: 30796, epoch: 170, loss: 0.285836
global_step: 30797, epoch: 170, loss: 0.285372
global_step: 30798, epoch: 170, loss: 0.319329
global_step: 30799, epoch: 170, loss: 0.326859
global_step: 30800, epoch: 170, loss: 0.181339
epoch: 170
train	acc: 0.9573	macro: p 0.9586, r 0.9152, f1: 0.9342	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9569
dev	acc: 0.5609	macro: p 0.4376, r 0.3616, f1: 0.3639	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5309
test	acc: 0.5839	macro: p 0.3905, r 0.3604, f1: 0.3653	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5673
global_step: 30801, epoch: 171, loss: 0.250021
global_step: 30802, epoch: 171, loss: 0.345442
global_step: 30803, epoch: 171, loss: 0.364914
global_step: 30804, epoch: 171, loss: 0.298293
global_step: 30805, epoch: 171, loss: 0.221467
global_step: 30806, epoch: 171, loss: 0.234580
global_step: 30807, epoch: 171, loss: 0.311258
global_step: 30808, epoch: 171, loss: 0.283232
global_step: 30809, epoch: 171, loss: 0.295847
global_step: 30810, epoch: 171, loss: 0.297429
global_step: 30811, epoch: 171, loss: 0.318101
global_step: 30812, epoch: 171, loss: 0.262872
global_step: 30813, epoch: 171, loss: 0.295018
global_step: 30814, epoch: 171, loss: 0.268723
global_step: 30815, epoch: 171, loss: 0.282761
global_step: 30816, epoch: 171, loss: 0.253412
global_step: 30817, epoch: 171, loss: 0.265377
global_step: 30818, epoch: 171, loss: 0.329241
global_step: 30819, epoch: 171, loss: 0.316589
global_step: 30820, epoch: 171, loss: 0.291233
global_step: 30821, epoch: 171, loss: 0.300154
global_step: 30822, epoch: 171, loss: 0.300780
global_step: 30823, epoch: 171, loss: 0.321020
global_step: 30824, epoch: 171, loss: 0.222000
global_step: 30825, epoch: 171, loss: 0.236465
global_step: 30826, epoch: 171, loss: 0.260919
global_step: 30827, epoch: 171, loss: 0.283288
global_step: 30828, epoch: 171, loss: 0.386446
global_step: 30829, epoch: 171, loss: 0.248033
global_step: 30830, epoch: 171, loss: 0.373305
global_step: 30831, epoch: 171, loss: 0.275031
global_step: 30832, epoch: 171, loss: 0.281596
global_step: 30833, epoch: 171, loss: 0.275590
global_step: 30834, epoch: 171, loss: 0.280444
global_step: 30835, epoch: 171, loss: 0.304756
global_step: 30836, epoch: 171, loss: 0.285605
global_step: 30837, epoch: 171, loss: 0.306221
global_step: 30838, epoch: 171, loss: 0.247504
global_step: 30839, epoch: 171, loss: 0.262065
global_step: 30840, epoch: 171, loss: 0.258989
epoch: 171
train	acc: 0.9453	macro: p 0.9605, r 0.8848, f1: 0.9170	micro: p 0.9453, r 0.9453, f1 0.9453	weighted_f1:0.9443
dev	acc: 0.5564	macro: p 0.5611, r 0.3281, f1: 0.3379	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5069
test	acc: 0.6027	macro: p 0.4313, r 0.3299, f1: 0.3468	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5594
global_step: 30841, epoch: 172, loss: 0.302574
global_step: 30842, epoch: 172, loss: 0.225681
global_step: 30843, epoch: 172, loss: 0.251207
global_step: 30844, epoch: 172, loss: 0.285878
global_step: 30845, epoch: 172, loss: 0.294092
global_step: 30846, epoch: 172, loss: 0.220033
global_step: 30847, epoch: 172, loss: 0.230235
global_step: 30848, epoch: 172, loss: 0.408054
global_step: 30849, epoch: 172, loss: 0.198469
global_step: 30850, epoch: 172, loss: 0.297332
global_step: 30851, epoch: 172, loss: 0.305114
global_step: 30852, epoch: 172, loss: 0.225921
global_step: 30853, epoch: 172, loss: 0.315945
global_step: 30854, epoch: 172, loss: 0.232103
global_step: 30855, epoch: 172, loss: 0.272612
global_step: 30856, epoch: 172, loss: 0.313774
global_step: 30857, epoch: 172, loss: 0.277348
global_step: 30858, epoch: 172, loss: 0.311124
global_step: 30859, epoch: 172, loss: 0.324546
global_step: 30860, epoch: 172, loss: 0.268830
global_step: 30861, epoch: 172, loss: 0.198666
global_step: 30862, epoch: 172, loss: 0.256996
global_step: 30863, epoch: 172, loss: 0.249806
global_step: 30864, epoch: 172, loss: 0.270388
global_step: 30865, epoch: 172, loss: 0.403077
global_step: 30866, epoch: 172, loss: 0.329551
global_step: 30867, epoch: 172, loss: 0.247316
global_step: 30868, epoch: 172, loss: 0.244817
global_step: 30869, epoch: 172, loss: 0.238508
global_step: 30870, epoch: 172, loss: 0.314170
global_step: 30871, epoch: 172, loss: 0.250108
global_step: 30872, epoch: 172, loss: 0.273973
global_step: 30873, epoch: 172, loss: 0.336561
global_step: 30874, epoch: 172, loss: 0.388401
global_step: 30875, epoch: 172, loss: 0.285115
global_step: 30876, epoch: 172, loss: 0.310847
global_step: 30877, epoch: 172, loss: 0.306213
global_step: 30878, epoch: 172, loss: 0.310093
global_step: 30879, epoch: 172, loss: 0.326152
global_step: 30880, epoch: 172, loss: 1.528071
epoch: 172
train	acc: 0.9584	macro: p 0.9598, r 0.9181, f1: 0.9368	micro: p 0.9584, r 0.9584, f1 0.9584	weighted_f1:0.9580
dev	acc: 0.5500	macro: p 0.3833, r 0.3364, f1: 0.3379	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5131
test	acc: 0.5897	macro: p 0.4020, r 0.3594, f1: 0.3703	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5693
global_step: 30881, epoch: 173, loss: 0.329392
global_step: 30882, epoch: 173, loss: 0.249392
global_step: 30883, epoch: 173, loss: 0.239483
global_step: 30884, epoch: 173, loss: 0.230694
global_step: 30885, epoch: 173, loss: 0.224031
global_step: 30886, epoch: 173, loss: 0.230618
global_step: 30887, epoch: 173, loss: 0.298255
global_step: 30888, epoch: 173, loss: 0.231872
global_step: 30889, epoch: 173, loss: 0.283445
global_step: 30890, epoch: 173, loss: 0.252304
global_step: 30891, epoch: 173, loss: 0.259943
global_step: 30892, epoch: 173, loss: 0.276697
global_step: 30893, epoch: 173, loss: 0.281320
global_step: 30894, epoch: 173, loss: 0.294125
global_step: 30895, epoch: 173, loss: 0.273379
global_step: 30896, epoch: 173, loss: 0.280099
global_step: 30897, epoch: 173, loss: 0.281438
global_step: 30898, epoch: 173, loss: 0.273373
global_step: 30899, epoch: 173, loss: 0.244940
global_step: 30900, epoch: 173, loss: 0.386167
global_step: 30901, epoch: 173, loss: 0.261572
global_step: 30902, epoch: 173, loss: 0.293079
global_step: 30903, epoch: 173, loss: 0.254993
global_step: 30904, epoch: 173, loss: 0.255065
global_step: 30905, epoch: 173, loss: 0.254875
global_step: 30906, epoch: 173, loss: 0.275649
global_step: 30907, epoch: 173, loss: 0.305945
global_step: 30908, epoch: 173, loss: 0.205919
global_step: 30909, epoch: 173, loss: 0.238621
global_step: 30910, epoch: 173, loss: 0.253921
global_step: 30911, epoch: 173, loss: 0.308510
global_step: 30912, epoch: 173, loss: 0.235629
global_step: 30913, epoch: 173, loss: 0.290871
global_step: 30914, epoch: 173, loss: 0.250483
global_step: 30915, epoch: 173, loss: 0.304906
global_step: 30916, epoch: 173, loss: 0.339305
global_step: 30917, epoch: 173, loss: 0.312747
global_step: 30918, epoch: 173, loss: 0.375856
global_step: 30919, epoch: 173, loss: 0.275278
global_step: 30920, epoch: 173, loss: 0.131668
epoch: 173
train	acc: 0.9558	macro: p 0.9577, r 0.9106, f1: 0.9314	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9553
dev	acc: 0.5500	macro: p 0.4346, r 0.3355, f1: 0.3419	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5114
test	acc: 0.5912	macro: p 0.4037, r 0.3506, f1: 0.3647	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5656
global_step: 30921, epoch: 174, loss: 0.249991
global_step: 30922, epoch: 174, loss: 0.310878
global_step: 30923, epoch: 174, loss: 0.288266
global_step: 30924, epoch: 174, loss: 0.258190
global_step: 30925, epoch: 174, loss: 0.295610
global_step: 30926, epoch: 174, loss: 0.230889
global_step: 30927, epoch: 174, loss: 0.248430
global_step: 30928, epoch: 174, loss: 0.277519
global_step: 30929, epoch: 174, loss: 0.290215
global_step: 30930, epoch: 174, loss: 0.319007
global_step: 30931, epoch: 174, loss: 0.360161
global_step: 30932, epoch: 174, loss: 0.219594
global_step: 30933, epoch: 174, loss: 0.306537
global_step: 30934, epoch: 174, loss: 0.295479
global_step: 30935, epoch: 174, loss: 0.286483
global_step: 30936, epoch: 174, loss: 0.265046
global_step: 30937, epoch: 174, loss: 0.263169
global_step: 30938, epoch: 174, loss: 0.221147
global_step: 30939, epoch: 174, loss: 0.268727
global_step: 30940, epoch: 174, loss: 0.247745
global_step: 30941, epoch: 174, loss: 0.269160
global_step: 30942, epoch: 174, loss: 0.262333
global_step: 30943, epoch: 174, loss: 0.275396
global_step: 30944, epoch: 174, loss: 0.254039
global_step: 30945, epoch: 174, loss: 0.306007
global_step: 30946, epoch: 174, loss: 0.301488
global_step: 30947, epoch: 174, loss: 0.296133
global_step: 30948, epoch: 174, loss: 0.321842
global_step: 30949, epoch: 174, loss: 0.369242
global_step: 30950, epoch: 174, loss: 0.265614
global_step: 30951, epoch: 174, loss: 0.277129
global_step: 30952, epoch: 174, loss: 0.309736
global_step: 30953, epoch: 174, loss: 0.402984
global_step: 30954, epoch: 174, loss: 0.240685
global_step: 30955, epoch: 174, loss: 0.306889
global_step: 30956, epoch: 174, loss: 0.269560
global_step: 30957, epoch: 174, loss: 0.315497
global_step: 30958, epoch: 174, loss: 0.303247
global_step: 30959, epoch: 174, loss: 0.255583
global_step: 30960, epoch: 174, loss: 0.125963
epoch: 174
train	acc: 0.9589	macro: p 0.9606, r 0.9194, f1: 0.9380	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9586
dev	acc: 0.5546	macro: p 0.3912, r 0.3479, f1: 0.3533	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5216
test	acc: 0.5824	macro: p 0.3916, r 0.3535, f1: 0.3635	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5631
global_step: 30961, epoch: 175, loss: 0.319693
global_step: 30962, epoch: 175, loss: 0.306274
global_step: 30963, epoch: 175, loss: 0.249628
global_step: 30964, epoch: 175, loss: 0.283484
global_step: 30965, epoch: 175, loss: 0.235308
global_step: 30966, epoch: 175, loss: 0.297003
global_step: 30967, epoch: 175, loss: 0.205083
global_step: 30968, epoch: 175, loss: 0.219053
global_step: 30969, epoch: 175, loss: 0.297970
global_step: 30970, epoch: 175, loss: 0.333011
global_step: 30971, epoch: 175, loss: 0.261837
global_step: 30972, epoch: 175, loss: 0.339972
global_step: 30973, epoch: 175, loss: 0.219641
global_step: 30974, epoch: 175, loss: 0.269979
global_step: 30975, epoch: 175, loss: 0.246230
global_step: 30976, epoch: 175, loss: 0.313362
global_step: 30977, epoch: 175, loss: 0.292191
global_step: 30978, epoch: 175, loss: 0.280932
global_step: 30979, epoch: 175, loss: 0.246260
global_step: 30980, epoch: 175, loss: 0.318816
global_step: 30981, epoch: 175, loss: 0.323555
global_step: 30982, epoch: 175, loss: 0.347374
global_step: 30983, epoch: 175, loss: 0.270799
global_step: 30984, epoch: 175, loss: 0.254205
global_step: 30985, epoch: 175, loss: 0.311928
global_step: 30986, epoch: 175, loss: 0.246394
global_step: 30987, epoch: 175, loss: 0.310335
global_step: 30988, epoch: 175, loss: 0.294144
global_step: 30989, epoch: 175, loss: 0.363256
global_step: 30990, epoch: 175, loss: 0.295317
global_step: 30991, epoch: 175, loss: 0.382375
global_step: 30992, epoch: 175, loss: 0.302089
global_step: 30993, epoch: 175, loss: 0.261139
global_step: 30994, epoch: 175, loss: 0.277261
global_step: 30995, epoch: 175, loss: 0.238806
global_step: 30996, epoch: 175, loss: 0.329103
global_step: 30997, epoch: 175, loss: 0.309943
global_step: 30998, epoch: 175, loss: 0.211631
global_step: 30999, epoch: 175, loss: 0.263501
global_step: 31000, epoch: 175, loss: 0.230360
epoch: 175
train	acc: 0.9564	macro: p 0.9590, r 0.9089, f1: 0.9309	micro: p 0.9564, r 0.9564, f1 0.9564	weighted_f1:0.9559
dev	acc: 0.5546	macro: p 0.4002, r 0.3445, f1: 0.3502	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5187
test	acc: 0.5847	macro: p 0.3874, r 0.3479, f1: 0.3562	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5621
global_step: 31001, epoch: 176, loss: 0.241359
global_step: 31002, epoch: 176, loss: 0.317497
global_step: 31003, epoch: 176, loss: 0.221417
global_step: 31004, epoch: 176, loss: 0.234614
global_step: 31005, epoch: 176, loss: 0.294819
global_step: 31006, epoch: 176, loss: 0.311434
global_step: 31007, epoch: 176, loss: 0.251050
global_step: 31008, epoch: 176, loss: 0.316047
global_step: 31009, epoch: 176, loss: 0.271568
global_step: 31010, epoch: 176, loss: 0.263393
global_step: 31011, epoch: 176, loss: 0.251067
global_step: 31012, epoch: 176, loss: 0.319406
global_step: 31013, epoch: 176, loss: 0.244958
global_step: 31014, epoch: 176, loss: 0.292165
global_step: 31015, epoch: 176, loss: 0.324699
global_step: 31016, epoch: 176, loss: 0.279707
global_step: 31017, epoch: 176, loss: 0.302134
global_step: 31018, epoch: 176, loss: 0.337393
global_step: 31019, epoch: 176, loss: 0.224180
global_step: 31020, epoch: 176, loss: 0.285035
global_step: 31021, epoch: 176, loss: 0.279159
global_step: 31022, epoch: 176, loss: 0.287503
global_step: 31023, epoch: 176, loss: 0.345215
global_step: 31024, epoch: 176, loss: 0.268227
global_step: 31025, epoch: 176, loss: 0.276585
global_step: 31026, epoch: 176, loss: 0.209853
global_step: 31027, epoch: 176, loss: 0.240824
global_step: 31028, epoch: 176, loss: 0.343033
global_step: 31029, epoch: 176, loss: 0.293183
global_step: 31030, epoch: 176, loss: 0.269855
global_step: 31031, epoch: 176, loss: 0.287110
global_step: 31032, epoch: 176, loss: 0.292216
global_step: 31033, epoch: 176, loss: 0.331303
global_step: 31034, epoch: 176, loss: 0.267776
global_step: 31035, epoch: 176, loss: 0.331852
global_step: 31036, epoch: 176, loss: 0.279255
global_step: 31037, epoch: 176, loss: 0.258050
global_step: 31038, epoch: 176, loss: 0.233007
global_step: 31039, epoch: 176, loss: 0.334301
global_step: 31040, epoch: 176, loss: 0.852880
epoch: 176
train	acc: 0.9603	macro: p 0.9616, r 0.9299, f1: 0.9445	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9602
dev	acc: 0.5446	macro: p 0.3767, r 0.3521, f1: 0.3560	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5199
test	acc: 0.5820	macro: p 0.3892, r 0.3708, f1: 0.3752	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5707
global_step: 31041, epoch: 177, loss: 0.298968
global_step: 31042, epoch: 177, loss: 0.309857
global_step: 31043, epoch: 177, loss: 0.250298
global_step: 31044, epoch: 177, loss: 0.261581
global_step: 31045, epoch: 177, loss: 0.334067
global_step: 31046, epoch: 177, loss: 0.309086
global_step: 31047, epoch: 177, loss: 0.246983
global_step: 31048, epoch: 177, loss: 0.212804
global_step: 31049, epoch: 177, loss: 0.289093
global_step: 31050, epoch: 177, loss: 0.262689
global_step: 31051, epoch: 177, loss: 0.300645
global_step: 31052, epoch: 177, loss: 0.273916
global_step: 31053, epoch: 177, loss: 0.252841
global_step: 31054, epoch: 177, loss: 0.249317
global_step: 31055, epoch: 177, loss: 0.311272
global_step: 31056, epoch: 177, loss: 0.344784
global_step: 31057, epoch: 177, loss: 0.245180
global_step: 31058, epoch: 177, loss: 0.311574
global_step: 31059, epoch: 177, loss: 0.198654
global_step: 31060, epoch: 177, loss: 0.328711
global_step: 31061, epoch: 177, loss: 0.308336
global_step: 31062, epoch: 177, loss: 0.253468
global_step: 31063, epoch: 177, loss: 0.261047
global_step: 31064, epoch: 177, loss: 0.273629
global_step: 31065, epoch: 177, loss: 0.293157
global_step: 31066, epoch: 177, loss: 0.252345
global_step: 31067, epoch: 177, loss: 0.256988
global_step: 31068, epoch: 177, loss: 0.290246
global_step: 31069, epoch: 177, loss: 0.273392
global_step: 31070, epoch: 177, loss: 0.298313
global_step: 31071, epoch: 177, loss: 0.286750
global_step: 31072, epoch: 177, loss: 0.279067
global_step: 31073, epoch: 177, loss: 0.261652
global_step: 31074, epoch: 177, loss: 0.263150
global_step: 31075, epoch: 177, loss: 0.337473
global_step: 31076, epoch: 177, loss: 0.275361
global_step: 31077, epoch: 177, loss: 0.218895
global_step: 31078, epoch: 177, loss: 0.315727
global_step: 31079, epoch: 177, loss: 0.348609
global_step: 31080, epoch: 177, loss: 0.317879
epoch: 177
train	acc: 0.9593	macro: p 0.9609, r 0.9217, f1: 0.9393	micro: p 0.9593, r 0.9593, f1 0.9593	weighted_f1:0.9590
dev	acc: 0.5573	macro: p 0.4183, r 0.3555, f1: 0.3607	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5263
test	acc: 0.5824	macro: p 0.3840, r 0.3526, f1: 0.3566	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5628
global_step: 31081, epoch: 178, loss: 0.300077
global_step: 31082, epoch: 178, loss: 0.244763
global_step: 31083, epoch: 178, loss: 0.280068
global_step: 31084, epoch: 178, loss: 0.333539
global_step: 31085, epoch: 178, loss: 0.247003
global_step: 31086, epoch: 178, loss: 0.263438
global_step: 31087, epoch: 178, loss: 0.277278
global_step: 31088, epoch: 178, loss: 0.262196
global_step: 31089, epoch: 178, loss: 0.293615
global_step: 31090, epoch: 178, loss: 0.289252
global_step: 31091, epoch: 178, loss: 0.269590
global_step: 31092, epoch: 178, loss: 0.253360
global_step: 31093, epoch: 178, loss: 0.298140
global_step: 31094, epoch: 178, loss: 0.345948
global_step: 31095, epoch: 178, loss: 0.326385
global_step: 31096, epoch: 178, loss: 0.315317
global_step: 31097, epoch: 178, loss: 0.301175
global_step: 31098, epoch: 178, loss: 0.212687
global_step: 31099, epoch: 178, loss: 0.289195
global_step: 31100, epoch: 178, loss: 0.279057
global_step: 31101, epoch: 178, loss: 0.255799
global_step: 31102, epoch: 178, loss: 0.274923
global_step: 31103, epoch: 178, loss: 0.300450
global_step: 31104, epoch: 178, loss: 0.267677
global_step: 31105, epoch: 178, loss: 0.258592
global_step: 31106, epoch: 178, loss: 0.219746
global_step: 31107, epoch: 178, loss: 0.204009
global_step: 31108, epoch: 178, loss: 0.244417
global_step: 31109, epoch: 178, loss: 0.260616
global_step: 31110, epoch: 178, loss: 0.326239
global_step: 31111, epoch: 178, loss: 0.300857
global_step: 31112, epoch: 178, loss: 0.239861
global_step: 31113, epoch: 178, loss: 0.360519
global_step: 31114, epoch: 178, loss: 0.265262
global_step: 31115, epoch: 178, loss: 0.297990
global_step: 31116, epoch: 178, loss: 0.277655
global_step: 31117, epoch: 178, loss: 0.262083
global_step: 31118, epoch: 178, loss: 0.224925
global_step: 31119, epoch: 178, loss: 0.283372
global_step: 31120, epoch: 178, loss: 0.047509
epoch: 178
train	acc: 0.9551	macro: p 0.9608, r 0.9109, f1: 0.9333	micro: p 0.9551, r 0.9551, f1 0.9551	weighted_f1:0.9546
dev	acc: 0.5609	macro: p 0.4443, r 0.3458, f1: 0.3591	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5230
test	acc: 0.5981	macro: p 0.4186, r 0.3530, f1: 0.3703	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5709
global_step: 31121, epoch: 179, loss: 0.282112
global_step: 31122, epoch: 179, loss: 0.308968
global_step: 31123, epoch: 179, loss: 0.266750
global_step: 31124, epoch: 179, loss: 0.305381
global_step: 31125, epoch: 179, loss: 0.294123
global_step: 31126, epoch: 179, loss: 0.202386
global_step: 31127, epoch: 179, loss: 0.302959
global_step: 31128, epoch: 179, loss: 0.295909
global_step: 31129, epoch: 179, loss: 0.185030
global_step: 31130, epoch: 179, loss: 0.248702
global_step: 31131, epoch: 179, loss: 0.331005
global_step: 31132, epoch: 179, loss: 0.307306
global_step: 31133, epoch: 179, loss: 0.250179
global_step: 31134, epoch: 179, loss: 0.355269
global_step: 31135, epoch: 179, loss: 0.292170
global_step: 31136, epoch: 179, loss: 0.223080
global_step: 31137, epoch: 179, loss: 0.247699
global_step: 31138, epoch: 179, loss: 0.268479
global_step: 31139, epoch: 179, loss: 0.279962
global_step: 31140, epoch: 179, loss: 0.247813
global_step: 31141, epoch: 179, loss: 0.194798
global_step: 31142, epoch: 179, loss: 0.283193
global_step: 31143, epoch: 179, loss: 0.235444
global_step: 31144, epoch: 179, loss: 0.313012
global_step: 31145, epoch: 179, loss: 0.275685
global_step: 31146, epoch: 179, loss: 0.280479
global_step: 31147, epoch: 179, loss: 0.236593
global_step: 31148, epoch: 179, loss: 0.312673
global_step: 31149, epoch: 179, loss: 0.256478
global_step: 31150, epoch: 179, loss: 0.201759
global_step: 31151, epoch: 179, loss: 0.266265
global_step: 31152, epoch: 179, loss: 0.323174
global_step: 31153, epoch: 179, loss: 0.344751
global_step: 31154, epoch: 179, loss: 0.241364
global_step: 31155, epoch: 179, loss: 0.312732
global_step: 31156, epoch: 179, loss: 0.393286
global_step: 31157, epoch: 179, loss: 0.303433
global_step: 31158, epoch: 179, loss: 0.245024
global_step: 31159, epoch: 179, loss: 0.315961
global_step: 31160, epoch: 179, loss: 0.319753
epoch: 179
train	acc: 0.9620	macro: p 0.9616, r 0.9323, f1: 0.9460	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9619
dev	acc: 0.5473	macro: p 0.3763, r 0.3507, f1: 0.3562	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5230
test	acc: 0.5793	macro: p 0.3917, r 0.3685, f1: 0.3744	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5674
global_step: 31161, epoch: 180, loss: 0.271997
global_step: 31162, epoch: 180, loss: 0.303222
global_step: 31163, epoch: 180, loss: 0.239947
global_step: 31164, epoch: 180, loss: 0.287290
global_step: 31165, epoch: 180, loss: 0.235571
global_step: 31166, epoch: 180, loss: 0.268872
global_step: 31167, epoch: 180, loss: 0.243895
global_step: 31168, epoch: 180, loss: 0.328591
global_step: 31169, epoch: 180, loss: 0.279115
global_step: 31170, epoch: 180, loss: 0.369548
global_step: 31171, epoch: 180, loss: 0.298550
global_step: 31172, epoch: 180, loss: 0.258826
global_step: 31173, epoch: 180, loss: 0.263196
global_step: 31174, epoch: 180, loss: 0.248080
global_step: 31175, epoch: 180, loss: 0.237272
global_step: 31176, epoch: 180, loss: 0.328588
global_step: 31177, epoch: 180, loss: 0.216846
global_step: 31178, epoch: 180, loss: 0.259965
global_step: 31179, epoch: 180, loss: 0.306437
global_step: 31180, epoch: 180, loss: 0.292388
global_step: 31181, epoch: 180, loss: 0.233242
global_step: 31182, epoch: 180, loss: 0.280922
global_step: 31183, epoch: 180, loss: 0.254028
global_step: 31184, epoch: 180, loss: 0.295992
global_step: 31185, epoch: 180, loss: 0.255488
global_step: 31186, epoch: 180, loss: 0.305896
global_step: 31187, epoch: 180, loss: 0.261623
global_step: 31188, epoch: 180, loss: 0.251135
global_step: 31189, epoch: 180, loss: 0.371317
global_step: 31190, epoch: 180, loss: 0.232377
global_step: 31191, epoch: 180, loss: 0.337551
global_step: 31192, epoch: 180, loss: 0.262229
global_step: 31193, epoch: 180, loss: 0.291385
global_step: 31194, epoch: 180, loss: 0.357860
global_step: 31195, epoch: 180, loss: 0.269626
global_step: 31196, epoch: 180, loss: 0.211190
global_step: 31197, epoch: 180, loss: 0.232697
global_step: 31198, epoch: 180, loss: 0.288433
global_step: 31199, epoch: 180, loss: 0.256728
global_step: 31200, epoch: 180, loss: 0.594459
epoch: 180
train	acc: 0.9589	macro: p 0.9631, r 0.9232, f1: 0.9414	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9587
dev	acc: 0.5537	macro: p 0.3933, r 0.3496, f1: 0.3492	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5161
test	acc: 0.5877	macro: p 0.3795, r 0.3492, f1: 0.3538	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5657
global_step: 31201, epoch: 181, loss: 0.158563
global_step: 31202, epoch: 181, loss: 0.259708
global_step: 31203, epoch: 181, loss: 0.341575
global_step: 31204, epoch: 181, loss: 0.190517
global_step: 31205, epoch: 181, loss: 0.225249
global_step: 31206, epoch: 181, loss: 0.285976
global_step: 31207, epoch: 181, loss: 0.250746
global_step: 31208, epoch: 181, loss: 0.244201
global_step: 31209, epoch: 181, loss: 0.217650
global_step: 31210, epoch: 181, loss: 0.276729
global_step: 31211, epoch: 181, loss: 0.259836
global_step: 31212, epoch: 181, loss: 0.384574
global_step: 31213, epoch: 181, loss: 0.302264
global_step: 31214, epoch: 181, loss: 0.232690
global_step: 31215, epoch: 181, loss: 0.327790
global_step: 31216, epoch: 181, loss: 0.275093
global_step: 31217, epoch: 181, loss: 0.258543
global_step: 31218, epoch: 181, loss: 0.260725
global_step: 31219, epoch: 181, loss: 0.254379
global_step: 31220, epoch: 181, loss: 0.335343
global_step: 31221, epoch: 181, loss: 0.214448
global_step: 31222, epoch: 181, loss: 0.326900
global_step: 31223, epoch: 181, loss: 0.171213
global_step: 31224, epoch: 181, loss: 0.339555
global_step: 31225, epoch: 181, loss: 0.223385
global_step: 31226, epoch: 181, loss: 0.245860
global_step: 31227, epoch: 181, loss: 0.237248
global_step: 31228, epoch: 181, loss: 0.241596
global_step: 31229, epoch: 181, loss: 0.247768
global_step: 31230, epoch: 181, loss: 0.283932
global_step: 31231, epoch: 181, loss: 0.229284
global_step: 31232, epoch: 181, loss: 0.369816
global_step: 31233, epoch: 181, loss: 0.291540
global_step: 31234, epoch: 181, loss: 0.282533
global_step: 31235, epoch: 181, loss: 0.299300
global_step: 31236, epoch: 181, loss: 0.226624
global_step: 31237, epoch: 181, loss: 0.277621
global_step: 31238, epoch: 181, loss: 0.251592
global_step: 31239, epoch: 181, loss: 0.287872
global_step: 31240, epoch: 181, loss: 0.082258
epoch: 181
train	acc: 0.9599	macro: p 0.9650, r 0.9270, f1: 0.9446	micro: p 0.9599, r 0.9599, f1 0.9599	weighted_f1:0.9597
dev	acc: 0.5537	macro: p 0.4043, r 0.3413, f1: 0.3464	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5162
test	acc: 0.5950	macro: p 0.4109, r 0.3589, f1: 0.3730	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5709
global_step: 31241, epoch: 182, loss: 0.296162
global_step: 31242, epoch: 182, loss: 0.240464
global_step: 31243, epoch: 182, loss: 0.235497
global_step: 31244, epoch: 182, loss: 0.294600
global_step: 31245, epoch: 182, loss: 0.279553
global_step: 31246, epoch: 182, loss: 0.305750
global_step: 31247, epoch: 182, loss: 0.288287
global_step: 31248, epoch: 182, loss: 0.200283
global_step: 31249, epoch: 182, loss: 0.229367
global_step: 31250, epoch: 182, loss: 0.251867
global_step: 31251, epoch: 182, loss: 0.249931
global_step: 31252, epoch: 182, loss: 0.226840
global_step: 31253, epoch: 182, loss: 0.158435
global_step: 31254, epoch: 182, loss: 0.250260
global_step: 31255, epoch: 182, loss: 0.276252
global_step: 31256, epoch: 182, loss: 0.301186
global_step: 31257, epoch: 182, loss: 0.279616
global_step: 31258, epoch: 182, loss: 0.287113
global_step: 31259, epoch: 182, loss: 0.315055
global_step: 31260, epoch: 182, loss: 0.274405
global_step: 31261, epoch: 182, loss: 0.297074
global_step: 31262, epoch: 182, loss: 0.349660
global_step: 31263, epoch: 182, loss: 0.308215
global_step: 31264, epoch: 182, loss: 0.269343
global_step: 31265, epoch: 182, loss: 0.355957
global_step: 31266, epoch: 182, loss: 0.291441
global_step: 31267, epoch: 182, loss: 0.318329
global_step: 31268, epoch: 182, loss: 0.269476
global_step: 31269, epoch: 182, loss: 0.337078
global_step: 31270, epoch: 182, loss: 0.251502
global_step: 31271, epoch: 182, loss: 0.185763
global_step: 31272, epoch: 182, loss: 0.259785
global_step: 31273, epoch: 182, loss: 0.258104
global_step: 31274, epoch: 182, loss: 0.247513
global_step: 31275, epoch: 182, loss: 0.325529
global_step: 31276, epoch: 182, loss: 0.223799
global_step: 31277, epoch: 182, loss: 0.211745
global_step: 31278, epoch: 182, loss: 0.237150
global_step: 31279, epoch: 182, loss: 0.282700
global_step: 31280, epoch: 182, loss: 0.362888
epoch: 182
train	acc: 0.9559	macro: p 0.9657, r 0.9242, f1: 0.9435	micro: p 0.9559, r 0.9559, f1 0.9559	weighted_f1:0.9556
dev	acc: 0.5537	macro: p 0.4081, r 0.3394, f1: 0.3506	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5144
test	acc: 0.5916	macro: p 0.4013, r 0.3449, f1: 0.3595	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5609
global_step: 31281, epoch: 183, loss: 0.232967
global_step: 31282, epoch: 183, loss: 0.288569
global_step: 31283, epoch: 183, loss: 0.305252
global_step: 31284, epoch: 183, loss: 0.185850
global_step: 31285, epoch: 183, loss: 0.229427
global_step: 31286, epoch: 183, loss: 0.183216
global_step: 31287, epoch: 183, loss: 0.219348
global_step: 31288, epoch: 183, loss: 0.311665
global_step: 31289, epoch: 183, loss: 0.257707
global_step: 31290, epoch: 183, loss: 0.258608
global_step: 31291, epoch: 183, loss: 0.235634
global_step: 31292, epoch: 183, loss: 0.210722
global_step: 31293, epoch: 183, loss: 0.246010
global_step: 31294, epoch: 183, loss: 0.366726
global_step: 31295, epoch: 183, loss: 0.240886
global_step: 31296, epoch: 183, loss: 0.201148
global_step: 31297, epoch: 183, loss: 0.293130
global_step: 31298, epoch: 183, loss: 0.346254
global_step: 31299, epoch: 183, loss: 0.273768
global_step: 31300, epoch: 183, loss: 0.302211
global_step: 31301, epoch: 183, loss: 0.293082
global_step: 31302, epoch: 183, loss: 0.233354
global_step: 31303, epoch: 183, loss: 0.281146
global_step: 31304, epoch: 183, loss: 0.297454
global_step: 31305, epoch: 183, loss: 0.262300
global_step: 31306, epoch: 183, loss: 0.289841
global_step: 31307, epoch: 183, loss: 0.324861
global_step: 31308, epoch: 183, loss: 0.194077
global_step: 31309, epoch: 183, loss: 0.247294
global_step: 31310, epoch: 183, loss: 0.275560
global_step: 31311, epoch: 183, loss: 0.256272
global_step: 31312, epoch: 183, loss: 0.279682
global_step: 31313, epoch: 183, loss: 0.240876
global_step: 31314, epoch: 183, loss: 0.237877
global_step: 31315, epoch: 183, loss: 0.214532
global_step: 31316, epoch: 183, loss: 0.252992
global_step: 31317, epoch: 183, loss: 0.252921
global_step: 31318, epoch: 183, loss: 0.260145
global_step: 31319, epoch: 183, loss: 0.348527
global_step: 31320, epoch: 183, loss: 0.088719
epoch: 183
train	acc: 0.9598	macro: p 0.9622, r 0.9254, f1: 0.9422	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9596
dev	acc: 0.5509	macro: p 0.4052, r 0.3486, f1: 0.3519	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5147
test	acc: 0.5824	macro: p 0.3924, r 0.3577, f1: 0.3648	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5610
global_step: 31321, epoch: 184, loss: 0.303699
global_step: 31322, epoch: 184, loss: 0.222308
global_step: 31323, epoch: 184, loss: 0.309790
global_step: 31324, epoch: 184, loss: 0.234791
global_step: 31325, epoch: 184, loss: 0.249915
global_step: 31326, epoch: 184, loss: 0.254638
global_step: 31327, epoch: 184, loss: 0.237840
global_step: 31328, epoch: 184, loss: 0.257143
global_step: 31329, epoch: 184, loss: 0.288707
global_step: 31330, epoch: 184, loss: 0.282695
global_step: 31331, epoch: 184, loss: 0.223783
global_step: 31332, epoch: 184, loss: 0.221120
global_step: 31333, epoch: 184, loss: 0.270570
global_step: 31334, epoch: 184, loss: 0.208529
global_step: 31335, epoch: 184, loss: 0.290038
global_step: 31336, epoch: 184, loss: 0.322693
global_step: 31337, epoch: 184, loss: 0.256872
global_step: 31338, epoch: 184, loss: 0.229953
global_step: 31339, epoch: 184, loss: 0.292062
global_step: 31340, epoch: 184, loss: 0.284761
global_step: 31341, epoch: 184, loss: 0.307645
global_step: 31342, epoch: 184, loss: 0.315651
global_step: 31343, epoch: 184, loss: 0.282699
global_step: 31344, epoch: 184, loss: 0.294299
global_step: 31345, epoch: 184, loss: 0.315562
global_step: 31346, epoch: 184, loss: 0.238360
global_step: 31347, epoch: 184, loss: 0.301278
global_step: 31348, epoch: 184, loss: 0.359282
global_step: 31349, epoch: 184, loss: 0.182307
global_step: 31350, epoch: 184, loss: 0.284450
global_step: 31351, epoch: 184, loss: 0.262279
global_step: 31352, epoch: 184, loss: 0.281301
global_step: 31353, epoch: 184, loss: 0.276163
global_step: 31354, epoch: 184, loss: 0.253390
global_step: 31355, epoch: 184, loss: 0.292033
global_step: 31356, epoch: 184, loss: 0.304928
global_step: 31357, epoch: 184, loss: 0.226035
global_step: 31358, epoch: 184, loss: 0.282600
global_step: 31359, epoch: 184, loss: 0.306462
global_step: 31360, epoch: 184, loss: 0.229996
epoch: 184
train	acc: 0.9612	macro: p 0.9619, r 0.9321, f1: 0.9460	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9611
dev	acc: 0.5600	macro: p 0.4365, r 0.3647, f1: 0.3752	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5290
test	acc: 0.5759	macro: p 0.3709, r 0.3450, f1: 0.3508	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5546
global_step: 31361, epoch: 185, loss: 0.206042
global_step: 31362, epoch: 185, loss: 0.247971
global_step: 31363, epoch: 185, loss: 0.306708
global_step: 31364, epoch: 185, loss: 0.259440
global_step: 31365, epoch: 185, loss: 0.215066
global_step: 31366, epoch: 185, loss: 0.229255
global_step: 31367, epoch: 185, loss: 0.320170
global_step: 31368, epoch: 185, loss: 0.249710
global_step: 31369, epoch: 185, loss: 0.314944
global_step: 31370, epoch: 185, loss: 0.242482
global_step: 31371, epoch: 185, loss: 0.257685
global_step: 31372, epoch: 185, loss: 0.262073
global_step: 31373, epoch: 185, loss: 0.286037
global_step: 31374, epoch: 185, loss: 0.269597
global_step: 31375, epoch: 185, loss: 0.243960
global_step: 31376, epoch: 185, loss: 0.258632
global_step: 31377, epoch: 185, loss: 0.260005
global_step: 31378, epoch: 185, loss: 0.306904
global_step: 31379, epoch: 185, loss: 0.213615
global_step: 31380, epoch: 185, loss: 0.274180
global_step: 31381, epoch: 185, loss: 0.299019
global_step: 31382, epoch: 185, loss: 0.261871
global_step: 31383, epoch: 185, loss: 0.291714
global_step: 31384, epoch: 185, loss: 0.313652
global_step: 31385, epoch: 185, loss: 0.238515
global_step: 31386, epoch: 185, loss: 0.225021
global_step: 31387, epoch: 185, loss: 0.232138
global_step: 31388, epoch: 185, loss: 0.271251
global_step: 31389, epoch: 185, loss: 0.279935
global_step: 31390, epoch: 185, loss: 0.255235
global_step: 31391, epoch: 185, loss: 0.185661
global_step: 31392, epoch: 185, loss: 0.273919
global_step: 31393, epoch: 185, loss: 0.230092
global_step: 31394, epoch: 185, loss: 0.280359
global_step: 31395, epoch: 185, loss: 0.232416
global_step: 31396, epoch: 185, loss: 0.215228
global_step: 31397, epoch: 185, loss: 0.316633
global_step: 31398, epoch: 185, loss: 0.274043
global_step: 31399, epoch: 185, loss: 0.279738
global_step: 31400, epoch: 185, loss: 0.476707
epoch: 185
train	acc: 0.9616	macro: p 0.9634, r 0.9324, f1: 0.9469	micro: p 0.9616, r 0.9616, f1 0.9616	weighted_f1:0.9614
dev	acc: 0.5555	macro: p 0.4015, r 0.3562, f1: 0.3669	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5255
test	acc: 0.5828	macro: p 0.3897, r 0.3545, f1: 0.3657	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5633
global_step: 31401, epoch: 186, loss: 0.248450
global_step: 31402, epoch: 186, loss: 0.228766
global_step: 31403, epoch: 186, loss: 0.295498
global_step: 31404, epoch: 186, loss: 0.299456
global_step: 31405, epoch: 186, loss: 0.239910
global_step: 31406, epoch: 186, loss: 0.270060
global_step: 31407, epoch: 186, loss: 0.294526
global_step: 31408, epoch: 186, loss: 0.244451
global_step: 31409, epoch: 186, loss: 0.225848
global_step: 31410, epoch: 186, loss: 0.276715
global_step: 31411, epoch: 186, loss: 0.259144
global_step: 31412, epoch: 186, loss: 0.283536
global_step: 31413, epoch: 186, loss: 0.302531
global_step: 31414, epoch: 186, loss: 0.266653
global_step: 31415, epoch: 186, loss: 0.183358
global_step: 31416, epoch: 186, loss: 0.269889
global_step: 31417, epoch: 186, loss: 0.281461
global_step: 31418, epoch: 186, loss: 0.245704
global_step: 31419, epoch: 186, loss: 0.238576
global_step: 31420, epoch: 186, loss: 0.300187
global_step: 31421, epoch: 186, loss: 0.267087
global_step: 31422, epoch: 186, loss: 0.302344
global_step: 31423, epoch: 186, loss: 0.328654
global_step: 31424, epoch: 186, loss: 0.271924
global_step: 31425, epoch: 186, loss: 0.242313
global_step: 31426, epoch: 186, loss: 0.236350
global_step: 31427, epoch: 186, loss: 0.213705
global_step: 31428, epoch: 186, loss: 0.250192
global_step: 31429, epoch: 186, loss: 0.284924
global_step: 31430, epoch: 186, loss: 0.310389
global_step: 31431, epoch: 186, loss: 0.266293
global_step: 31432, epoch: 186, loss: 0.301771
global_step: 31433, epoch: 186, loss: 0.232768
global_step: 31434, epoch: 186, loss: 0.277969
global_step: 31435, epoch: 186, loss: 0.240783
global_step: 31436, epoch: 186, loss: 0.260088
global_step: 31437, epoch: 186, loss: 0.264273
global_step: 31438, epoch: 186, loss: 0.311174
global_step: 31439, epoch: 186, loss: 0.304314
global_step: 31440, epoch: 186, loss: 0.283788
epoch: 186
train	acc: 0.9605	macro: p 0.9630, r 0.9236, f1: 0.9417	micro: p 0.9605, r 0.9605, f1 0.9605	weighted_f1:0.9602
dev	acc: 0.5518	macro: p 0.3880, r 0.3360, f1: 0.3408	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5128
test	acc: 0.5862	macro: p 0.3917, r 0.3445, f1: 0.3546	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5619
global_step: 31441, epoch: 187, loss: 0.215045
global_step: 31442, epoch: 187, loss: 0.253889
global_step: 31443, epoch: 187, loss: 0.218259
global_step: 31444, epoch: 187, loss: 0.205237
global_step: 31445, epoch: 187, loss: 0.265621
global_step: 31446, epoch: 187, loss: 0.299758
global_step: 31447, epoch: 187, loss: 0.190682
global_step: 31448, epoch: 187, loss: 0.244877
global_step: 31449, epoch: 187, loss: 0.273589
global_step: 31450, epoch: 187, loss: 0.258119
global_step: 31451, epoch: 187, loss: 0.251693
global_step: 31452, epoch: 187, loss: 0.266902
global_step: 31453, epoch: 187, loss: 0.206048
global_step: 31454, epoch: 187, loss: 0.250726
global_step: 31455, epoch: 187, loss: 0.244093
global_step: 31456, epoch: 187, loss: 0.229480
global_step: 31457, epoch: 187, loss: 0.225399
global_step: 31458, epoch: 187, loss: 0.255964
global_step: 31459, epoch: 187, loss: 0.320838
global_step: 31460, epoch: 187, loss: 0.233890
global_step: 31461, epoch: 187, loss: 0.285615
global_step: 31462, epoch: 187, loss: 0.312084
global_step: 31463, epoch: 187, loss: 0.231025
global_step: 31464, epoch: 187, loss: 0.237652
global_step: 31465, epoch: 187, loss: 0.322826
global_step: 31466, epoch: 187, loss: 0.267233
global_step: 31467, epoch: 187, loss: 0.213351
global_step: 31468, epoch: 187, loss: 0.265363
global_step: 31469, epoch: 187, loss: 0.353165
global_step: 31470, epoch: 187, loss: 0.281153
global_step: 31471, epoch: 187, loss: 0.312011
global_step: 31472, epoch: 187, loss: 0.268801
global_step: 31473, epoch: 187, loss: 0.257132
global_step: 31474, epoch: 187, loss: 0.297146
global_step: 31475, epoch: 187, loss: 0.320846
global_step: 31476, epoch: 187, loss: 0.293998
global_step: 31477, epoch: 187, loss: 0.290480
global_step: 31478, epoch: 187, loss: 0.342927
global_step: 31479, epoch: 187, loss: 0.248921
global_step: 31480, epoch: 187, loss: 0.095838
epoch: 187
train	acc: 0.9600	macro: p 0.9619, r 0.9316, f1: 0.9454	micro: p 0.9600, r 0.9600, f1 0.9600	weighted_f1:0.9600
dev	acc: 0.5528	macro: p 0.3998, r 0.3636, f1: 0.3619	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5256
test	acc: 0.5797	macro: p 0.3735, r 0.3587, f1: 0.3573	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5642
global_step: 31481, epoch: 188, loss: 0.228550
global_step: 31482, epoch: 188, loss: 0.255641
global_step: 31483, epoch: 188, loss: 0.221522
global_step: 31484, epoch: 188, loss: 0.263108
global_step: 31485, epoch: 188, loss: 0.210404
global_step: 31486, epoch: 188, loss: 0.302715
global_step: 31487, epoch: 188, loss: 0.254730
global_step: 31488, epoch: 188, loss: 0.258980
global_step: 31489, epoch: 188, loss: 0.442435
global_step: 31490, epoch: 188, loss: 0.232091
global_step: 31491, epoch: 188, loss: 0.236342
global_step: 31492, epoch: 188, loss: 0.279511
global_step: 31493, epoch: 188, loss: 0.273232
global_step: 31494, epoch: 188, loss: 0.284496
global_step: 31495, epoch: 188, loss: 0.283406
global_step: 31496, epoch: 188, loss: 0.282280
global_step: 31497, epoch: 188, loss: 0.272791
global_step: 31498, epoch: 188, loss: 0.212151
global_step: 31499, epoch: 188, loss: 0.270664
global_step: 31500, epoch: 188, loss: 0.326574
global_step: 31501, epoch: 188, loss: 0.324692
global_step: 31502, epoch: 188, loss: 0.283371
global_step: 31503, epoch: 188, loss: 0.265242
global_step: 31504, epoch: 188, loss: 0.282457
global_step: 31505, epoch: 188, loss: 0.249976
global_step: 31506, epoch: 188, loss: 0.221475
global_step: 31507, epoch: 188, loss: 0.208630
global_step: 31508, epoch: 188, loss: 0.198503
global_step: 31509, epoch: 188, loss: 0.223398
global_step: 31510, epoch: 188, loss: 0.261296
global_step: 31511, epoch: 188, loss: 0.264106
global_step: 31512, epoch: 188, loss: 0.330769
global_step: 31513, epoch: 188, loss: 0.264777
global_step: 31514, epoch: 188, loss: 0.311756
global_step: 31515, epoch: 188, loss: 0.271578
global_step: 31516, epoch: 188, loss: 0.278204
global_step: 31517, epoch: 188, loss: 0.220177
global_step: 31518, epoch: 188, loss: 0.223225
global_step: 31519, epoch: 188, loss: 0.269663
global_step: 31520, epoch: 188, loss: 0.044718
epoch: 188
train	acc: 0.9638	macro: p 0.9644, r 0.9372, f1: 0.9498	micro: p 0.9638, r 0.9638, f1 0.9638	weighted_f1:0.9637
dev	acc: 0.5509	macro: p 0.3885, r 0.3605, f1: 0.3679	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5287
test	acc: 0.5778	macro: p 0.3804, r 0.3612, f1: 0.3669	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5654
global_step: 31521, epoch: 189, loss: 0.217828
global_step: 31522, epoch: 189, loss: 0.206047
global_step: 31523, epoch: 189, loss: 0.230854
global_step: 31524, epoch: 189, loss: 0.243549
global_step: 31525, epoch: 189, loss: 0.200341
global_step: 31526, epoch: 189, loss: 0.284652
global_step: 31527, epoch: 189, loss: 0.279066
global_step: 31528, epoch: 189, loss: 0.245518
global_step: 31529, epoch: 189, loss: 0.272888
global_step: 31530, epoch: 189, loss: 0.232384
global_step: 31531, epoch: 189, loss: 0.240642
global_step: 31532, epoch: 189, loss: 0.222488
global_step: 31533, epoch: 189, loss: 0.300667
global_step: 31534, epoch: 189, loss: 0.223179
global_step: 31535, epoch: 189, loss: 0.294185
global_step: 31536, epoch: 189, loss: 0.262177
global_step: 31537, epoch: 189, loss: 0.303402
global_step: 31538, epoch: 189, loss: 0.284726
global_step: 31539, epoch: 189, loss: 0.314842
global_step: 31540, epoch: 189, loss: 0.253586
global_step: 31541, epoch: 189, loss: 0.287012
global_step: 31542, epoch: 189, loss: 0.296216
global_step: 31543, epoch: 189, loss: 0.269063
global_step: 31544, epoch: 189, loss: 0.236398
global_step: 31545, epoch: 189, loss: 0.168827
global_step: 31546, epoch: 189, loss: 0.322876
global_step: 31547, epoch: 189, loss: 0.230532
global_step: 31548, epoch: 189, loss: 0.236034
global_step: 31549, epoch: 189, loss: 0.223317
global_step: 31550, epoch: 189, loss: 0.237987
global_step: 31551, epoch: 189, loss: 0.237166
global_step: 31552, epoch: 189, loss: 0.246995
global_step: 31553, epoch: 189, loss: 0.307425
global_step: 31554, epoch: 189, loss: 0.186116
global_step: 31555, epoch: 189, loss: 0.230545
global_step: 31556, epoch: 189, loss: 0.265855
global_step: 31557, epoch: 189, loss: 0.220677
global_step: 31558, epoch: 189, loss: 0.211573
global_step: 31559, epoch: 189, loss: 0.310124
global_step: 31560, epoch: 189, loss: 0.564585
epoch: 189
train	acc: 0.9618	macro: p 0.9653, r 0.9288, f1: 0.9457	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9616
dev	acc: 0.5518	macro: p 0.3976, r 0.3416, f1: 0.3441	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5124
test	acc: 0.5854	macro: p 0.3995, r 0.3557, f1: 0.3621	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5633
global_step: 31561, epoch: 190, loss: 0.256562
global_step: 31562, epoch: 190, loss: 0.267203
global_step: 31563, epoch: 190, loss: 0.238678
global_step: 31564, epoch: 190, loss: 0.276988
global_step: 31565, epoch: 190, loss: 0.201718
global_step: 31566, epoch: 190, loss: 0.248952
global_step: 31567, epoch: 190, loss: 0.194071
global_step: 31568, epoch: 190, loss: 0.223425
global_step: 31569, epoch: 190, loss: 0.215682
global_step: 31570, epoch: 190, loss: 0.180850
global_step: 31571, epoch: 190, loss: 0.246382
global_step: 31572, epoch: 190, loss: 0.274043
global_step: 31573, epoch: 190, loss: 0.307926
global_step: 31574, epoch: 190, loss: 0.174717
global_step: 31575, epoch: 190, loss: 0.318837
global_step: 31576, epoch: 190, loss: 0.240958
global_step: 31577, epoch: 190, loss: 0.264019
global_step: 31578, epoch: 190, loss: 0.257205
global_step: 31579, epoch: 190, loss: 0.300869
global_step: 31580, epoch: 190, loss: 0.327635
global_step: 31581, epoch: 190, loss: 0.240191
global_step: 31582, epoch: 190, loss: 0.231145
global_step: 31583, epoch: 190, loss: 0.281619
global_step: 31584, epoch: 190, loss: 0.262863
global_step: 31585, epoch: 190, loss: 0.405347
global_step: 31586, epoch: 190, loss: 0.273456
global_step: 31587, epoch: 190, loss: 0.178312
global_step: 31588, epoch: 190, loss: 0.206636
global_step: 31589, epoch: 190, loss: 0.288377
global_step: 31590, epoch: 190, loss: 0.206492
global_step: 31591, epoch: 190, loss: 0.218553
global_step: 31592, epoch: 190, loss: 0.315567
global_step: 31593, epoch: 190, loss: 0.281776
global_step: 31594, epoch: 190, loss: 0.281444
global_step: 31595, epoch: 190, loss: 0.202577
global_step: 31596, epoch: 190, loss: 0.305581
global_step: 31597, epoch: 190, loss: 0.194257
global_step: 31598, epoch: 190, loss: 0.266088
global_step: 31599, epoch: 190, loss: 0.260998
global_step: 31600, epoch: 190, loss: 0.113079
epoch: 190
train	acc: 0.9644	macro: p 0.9665, r 0.9393, f1: 0.9521	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9643
dev	acc: 0.5446	macro: p 0.3759, r 0.3425, f1: 0.3511	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5182
test	acc: 0.5862	macro: p 0.3927, r 0.3633, f1: 0.3738	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5708
global_step: 31601, epoch: 191, loss: 0.282633
global_step: 31602, epoch: 191, loss: 0.250885
global_step: 31603, epoch: 191, loss: 0.226472
global_step: 31604, epoch: 191, loss: 0.277471
global_step: 31605, epoch: 191, loss: 0.300527
global_step: 31606, epoch: 191, loss: 0.275513
global_step: 31607, epoch: 191, loss: 0.334159
global_step: 31608, epoch: 191, loss: 0.216088
global_step: 31609, epoch: 191, loss: 0.275428
global_step: 31610, epoch: 191, loss: 0.214955
global_step: 31611, epoch: 191, loss: 0.288786
global_step: 31612, epoch: 191, loss: 0.252354
global_step: 31613, epoch: 191, loss: 0.282455
global_step: 31614, epoch: 191, loss: 0.221848
global_step: 31615, epoch: 191, loss: 0.268625
global_step: 31616, epoch: 191, loss: 0.249642
global_step: 31617, epoch: 191, loss: 0.201106
global_step: 31618, epoch: 191, loss: 0.302000
global_step: 31619, epoch: 191, loss: 0.258266
global_step: 31620, epoch: 191, loss: 0.189650
global_step: 31621, epoch: 191, loss: 0.235865
global_step: 31622, epoch: 191, loss: 0.217775
global_step: 31623, epoch: 191, loss: 0.252567
global_step: 31624, epoch: 191, loss: 0.238723
global_step: 31625, epoch: 191, loss: 0.254090
global_step: 31626, epoch: 191, loss: 0.178721
global_step: 31627, epoch: 191, loss: 0.318474
global_step: 31628, epoch: 191, loss: 0.248461
global_step: 31629, epoch: 191, loss: 0.278164
global_step: 31630, epoch: 191, loss: 0.288244
global_step: 31631, epoch: 191, loss: 0.261462
global_step: 31632, epoch: 191, loss: 0.210312
global_step: 31633, epoch: 191, loss: 0.308614
global_step: 31634, epoch: 191, loss: 0.285875
global_step: 31635, epoch: 191, loss: 0.271811
global_step: 31636, epoch: 191, loss: 0.255183
global_step: 31637, epoch: 191, loss: 0.236540
global_step: 31638, epoch: 191, loss: 0.262455
global_step: 31639, epoch: 191, loss: 0.246414
global_step: 31640, epoch: 191, loss: 0.162209
epoch: 191
train	acc: 0.9611	macro: p 0.9669, r 0.9259, f1: 0.9446	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9608
dev	acc: 0.5473	macro: p 0.4023, r 0.3315, f1: 0.3373	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5072
test	acc: 0.5897	macro: p 0.4070, r 0.3469, f1: 0.3609	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5626
global_step: 31641, epoch: 192, loss: 0.226766
global_step: 31642, epoch: 192, loss: 0.214645
global_step: 31643, epoch: 192, loss: 0.304396
global_step: 31644, epoch: 192, loss: 0.305770
global_step: 31645, epoch: 192, loss: 0.291423
global_step: 31646, epoch: 192, loss: 0.263361
global_step: 31647, epoch: 192, loss: 0.261701
global_step: 31648, epoch: 192, loss: 0.228688
global_step: 31649, epoch: 192, loss: 0.192543
global_step: 31650, epoch: 192, loss: 0.230483
global_step: 31651, epoch: 192, loss: 0.268526
global_step: 31652, epoch: 192, loss: 0.331994
global_step: 31653, epoch: 192, loss: 0.268459
global_step: 31654, epoch: 192, loss: 0.252976
global_step: 31655, epoch: 192, loss: 0.235888
global_step: 31656, epoch: 192, loss: 0.241521
global_step: 31657, epoch: 192, loss: 0.257215
global_step: 31658, epoch: 192, loss: 0.259518
global_step: 31659, epoch: 192, loss: 0.293274
global_step: 31660, epoch: 192, loss: 0.225878
global_step: 31661, epoch: 192, loss: 0.346530
global_step: 31662, epoch: 192, loss: 0.247561
global_step: 31663, epoch: 192, loss: 0.219696
global_step: 31664, epoch: 192, loss: 0.210810
global_step: 31665, epoch: 192, loss: 0.233145
global_step: 31666, epoch: 192, loss: 0.240684
global_step: 31667, epoch: 192, loss: 0.280194
global_step: 31668, epoch: 192, loss: 0.244752
global_step: 31669, epoch: 192, loss: 0.229277
global_step: 31670, epoch: 192, loss: 0.200135
global_step: 31671, epoch: 192, loss: 0.209127
global_step: 31672, epoch: 192, loss: 0.248174
global_step: 31673, epoch: 192, loss: 0.261477
global_step: 31674, epoch: 192, loss: 0.198025
global_step: 31675, epoch: 192, loss: 0.283165
global_step: 31676, epoch: 192, loss: 0.276945
global_step: 31677, epoch: 192, loss: 0.268216
global_step: 31678, epoch: 192, loss: 0.277204
global_step: 31679, epoch: 192, loss: 0.252205
global_step: 31680, epoch: 192, loss: 0.495924
epoch: 192
train	acc: 0.9552	macro: p 0.9691, r 0.9228, f1: 0.9444	micro: p 0.9552, r 0.9552, f1 0.9552	weighted_f1:0.9548
dev	acc: 0.5383	macro: p 0.4059, r 0.3206, f1: 0.3303	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4905
test	acc: 0.5874	macro: p 0.4006, r 0.3265, f1: 0.3442	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5465
global_step: 31681, epoch: 193, loss: 0.365470
global_step: 31682, epoch: 193, loss: 0.234845
global_step: 31683, epoch: 193, loss: 0.195398
global_step: 31684, epoch: 193, loss: 0.214135
global_step: 31685, epoch: 193, loss: 0.257718
global_step: 31686, epoch: 193, loss: 0.235027
global_step: 31687, epoch: 193, loss: 0.243260
global_step: 31688, epoch: 193, loss: 0.230760
global_step: 31689, epoch: 193, loss: 0.219529
global_step: 31690, epoch: 193, loss: 0.241833
global_step: 31691, epoch: 193, loss: 0.215650
global_step: 31692, epoch: 193, loss: 0.191243
global_step: 31693, epoch: 193, loss: 0.253425
global_step: 31694, epoch: 193, loss: 0.266091
global_step: 31695, epoch: 193, loss: 0.279564
global_step: 31696, epoch: 193, loss: 0.236616
global_step: 31697, epoch: 193, loss: 0.203543
global_step: 31698, epoch: 193, loss: 0.243149
global_step: 31699, epoch: 193, loss: 0.245462
global_step: 31700, epoch: 193, loss: 0.282926
global_step: 31701, epoch: 193, loss: 0.226913
global_step: 31702, epoch: 193, loss: 0.290541
global_step: 31703, epoch: 193, loss: 0.241358
global_step: 31704, epoch: 193, loss: 0.193528
global_step: 31705, epoch: 193, loss: 0.244641
global_step: 31706, epoch: 193, loss: 0.203719
global_step: 31707, epoch: 193, loss: 0.212876
global_step: 31708, epoch: 193, loss: 0.199580
global_step: 31709, epoch: 193, loss: 0.251678
global_step: 31710, epoch: 193, loss: 0.238844
global_step: 31711, epoch: 193, loss: 0.289526
global_step: 31712, epoch: 193, loss: 0.221532
global_step: 31713, epoch: 193, loss: 0.308630
global_step: 31714, epoch: 193, loss: 0.271192
global_step: 31715, epoch: 193, loss: 0.293220
global_step: 31716, epoch: 193, loss: 0.277924
global_step: 31717, epoch: 193, loss: 0.226495
global_step: 31718, epoch: 193, loss: 0.306865
global_step: 31719, epoch: 193, loss: 0.231010
global_step: 31720, epoch: 193, loss: 0.074938
epoch: 193
train	acc: 0.9628	macro: p 0.9663, r 0.9314, f1: 0.9475	micro: p 0.9628, r 0.9628, f1 0.9628	weighted_f1:0.9626
dev	acc: 0.5455	macro: p 0.3883, r 0.3391, f1: 0.3442	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5114
test	acc: 0.5851	macro: p 0.3882, r 0.3454, f1: 0.3544	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5610
global_step: 31721, epoch: 194, loss: 0.225464
global_step: 31722, epoch: 194, loss: 0.238109
global_step: 31723, epoch: 194, loss: 0.191903
global_step: 31724, epoch: 194, loss: 0.229739
global_step: 31725, epoch: 194, loss: 0.223262
global_step: 31726, epoch: 194, loss: 0.253791
global_step: 31727, epoch: 194, loss: 0.229776
global_step: 31728, epoch: 194, loss: 0.272465
global_step: 31729, epoch: 194, loss: 0.249570
global_step: 31730, epoch: 194, loss: 0.213093
global_step: 31731, epoch: 194, loss: 0.259849
global_step: 31732, epoch: 194, loss: 0.271673
global_step: 31733, epoch: 194, loss: 0.323435
global_step: 31734, epoch: 194, loss: 0.248308
global_step: 31735, epoch: 194, loss: 0.273310
global_step: 31736, epoch: 194, loss: 0.286386
global_step: 31737, epoch: 194, loss: 0.269864
global_step: 31738, epoch: 194, loss: 0.247251
global_step: 31739, epoch: 194, loss: 0.218458
global_step: 31740, epoch: 194, loss: 0.260372
global_step: 31741, epoch: 194, loss: 0.269806
global_step: 31742, epoch: 194, loss: 0.210963
global_step: 31743, epoch: 194, loss: 0.226391
global_step: 31744, epoch: 194, loss: 0.277168
global_step: 31745, epoch: 194, loss: 0.237754
global_step: 31746, epoch: 194, loss: 0.259500
global_step: 31747, epoch: 194, loss: 0.230735
global_step: 31748, epoch: 194, loss: 0.253875
global_step: 31749, epoch: 194, loss: 0.327630
global_step: 31750, epoch: 194, loss: 0.238858
global_step: 31751, epoch: 194, loss: 0.204162
global_step: 31752, epoch: 194, loss: 0.272402
global_step: 31753, epoch: 194, loss: 0.235095
global_step: 31754, epoch: 194, loss: 0.284907
global_step: 31755, epoch: 194, loss: 0.244142
global_step: 31756, epoch: 194, loss: 0.223695
global_step: 31757, epoch: 194, loss: 0.198917
global_step: 31758, epoch: 194, loss: 0.215044
global_step: 31759, epoch: 194, loss: 0.284876
global_step: 31760, epoch: 194, loss: 0.085162
epoch: 194
train	acc: 0.9630	macro: p 0.9661, r 0.9357, f1: 0.9500	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9628
dev	acc: 0.5491	macro: p 0.4030, r 0.3398, f1: 0.3493	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5125
test	acc: 0.5954	macro: p 0.4006, r 0.3477, f1: 0.3618	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5668
global_step: 31761, epoch: 195, loss: 0.233056
global_step: 31762, epoch: 195, loss: 0.190709
global_step: 31763, epoch: 195, loss: 0.258453
global_step: 31764, epoch: 195, loss: 0.173060
global_step: 31765, epoch: 195, loss: 0.278848
global_step: 31766, epoch: 195, loss: 0.285373
global_step: 31767, epoch: 195, loss: 0.210521
global_step: 31768, epoch: 195, loss: 0.254213
global_step: 31769, epoch: 195, loss: 0.283001
global_step: 31770, epoch: 195, loss: 0.226716
global_step: 31771, epoch: 195, loss: 0.249460
global_step: 31772, epoch: 195, loss: 0.188276
global_step: 31773, epoch: 195, loss: 0.220174
global_step: 31774, epoch: 195, loss: 0.247876
global_step: 31775, epoch: 195, loss: 0.287612
global_step: 31776, epoch: 195, loss: 0.218445
global_step: 31777, epoch: 195, loss: 0.252952
global_step: 31778, epoch: 195, loss: 0.254612
global_step: 31779, epoch: 195, loss: 0.252026
global_step: 31780, epoch: 195, loss: 0.267326
global_step: 31781, epoch: 195, loss: 0.241098
global_step: 31782, epoch: 195, loss: 0.226136
global_step: 31783, epoch: 195, loss: 0.258801
global_step: 31784, epoch: 195, loss: 0.271883
global_step: 31785, epoch: 195, loss: 0.266446
global_step: 31786, epoch: 195, loss: 0.280629
global_step: 31787, epoch: 195, loss: 0.274807
global_step: 31788, epoch: 195, loss: 0.220893
global_step: 31789, epoch: 195, loss: 0.285755
global_step: 31790, epoch: 195, loss: 0.286744
global_step: 31791, epoch: 195, loss: 0.257618
global_step: 31792, epoch: 195, loss: 0.277673
global_step: 31793, epoch: 195, loss: 0.277442
global_step: 31794, epoch: 195, loss: 0.307319
global_step: 31795, epoch: 195, loss: 0.345865
global_step: 31796, epoch: 195, loss: 0.247090
global_step: 31797, epoch: 195, loss: 0.257433
global_step: 31798, epoch: 195, loss: 0.308503
global_step: 31799, epoch: 195, loss: 0.194027
global_step: 31800, epoch: 195, loss: 0.221403
epoch: 195
train	acc: 0.9634	macro: p 0.9653, r 0.9407, f1: 0.9522	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9634
dev	acc: 0.5410	macro: p 0.4083, r 0.3537, f1: 0.3571	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5177
test	acc: 0.5789	macro: p 0.3894, r 0.3681, f1: 0.3706	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5675
global_step: 31801, epoch: 196, loss: 0.255323
global_step: 31802, epoch: 196, loss: 0.217424
global_step: 31803, epoch: 196, loss: 0.271117
global_step: 31804, epoch: 196, loss: 0.262954
global_step: 31805, epoch: 196, loss: 0.268264
global_step: 31806, epoch: 196, loss: 0.270057
global_step: 31807, epoch: 196, loss: 0.225200
global_step: 31808, epoch: 196, loss: 0.296941
global_step: 31809, epoch: 196, loss: 0.218661
global_step: 31810, epoch: 196, loss: 0.279418
global_step: 31811, epoch: 196, loss: 0.243169
global_step: 31812, epoch: 196, loss: 0.269768
global_step: 31813, epoch: 196, loss: 0.285895
global_step: 31814, epoch: 196, loss: 0.217776
global_step: 31815, epoch: 196, loss: 0.210336
global_step: 31816, epoch: 196, loss: 0.214428
global_step: 31817, epoch: 196, loss: 0.242637
global_step: 31818, epoch: 196, loss: 0.282287
global_step: 31819, epoch: 196, loss: 0.305161
global_step: 31820, epoch: 196, loss: 0.307827
global_step: 31821, epoch: 196, loss: 0.239687
global_step: 31822, epoch: 196, loss: 0.217952
global_step: 31823, epoch: 196, loss: 0.276287
global_step: 31824, epoch: 196, loss: 0.247862
global_step: 31825, epoch: 196, loss: 0.181066
global_step: 31826, epoch: 196, loss: 0.193451
global_step: 31827, epoch: 196, loss: 0.293386
global_step: 31828, epoch: 196, loss: 0.218387
global_step: 31829, epoch: 196, loss: 0.257267
global_step: 31830, epoch: 196, loss: 0.270634
global_step: 31831, epoch: 196, loss: 0.207398
global_step: 31832, epoch: 196, loss: 0.277810
global_step: 31833, epoch: 196, loss: 0.211786
global_step: 31834, epoch: 196, loss: 0.218562
global_step: 31835, epoch: 196, loss: 0.286587
global_step: 31836, epoch: 196, loss: 0.235906
global_step: 31837, epoch: 196, loss: 0.276753
global_step: 31838, epoch: 196, loss: 0.282401
global_step: 31839, epoch: 196, loss: 0.182803
global_step: 31840, epoch: 196, loss: 0.171826
epoch: 196
train	acc: 0.9621	macro: p 0.9653, r 0.9361, f1: 0.9499	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9620
dev	acc: 0.5437	macro: p 0.4016, r 0.3424, f1: 0.3510	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5052
test	acc: 0.5908	macro: p 0.4029, r 0.3515, f1: 0.3631	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5621
global_step: 31841, epoch: 197, loss: 0.226341
global_step: 31842, epoch: 197, loss: 0.231414
global_step: 31843, epoch: 197, loss: 0.216784
global_step: 31844, epoch: 197, loss: 0.250266
global_step: 31845, epoch: 197, loss: 0.243073
global_step: 31846, epoch: 197, loss: 0.205589
global_step: 31847, epoch: 197, loss: 0.221290
global_step: 31848, epoch: 197, loss: 0.195218
global_step: 31849, epoch: 197, loss: 0.238573
global_step: 31850, epoch: 197, loss: 0.269350
global_step: 31851, epoch: 197, loss: 0.277756
global_step: 31852, epoch: 197, loss: 0.290268
global_step: 31853, epoch: 197, loss: 0.277028
global_step: 31854, epoch: 197, loss: 0.263663
global_step: 31855, epoch: 197, loss: 0.257317
global_step: 31856, epoch: 197, loss: 0.211532
global_step: 31857, epoch: 197, loss: 0.193929
global_step: 31858, epoch: 197, loss: 0.273212
global_step: 31859, epoch: 197, loss: 0.247669
global_step: 31860, epoch: 197, loss: 0.228200
global_step: 31861, epoch: 197, loss: 0.269253
global_step: 31862, epoch: 197, loss: 0.283815
global_step: 31863, epoch: 197, loss: 0.246358
global_step: 31864, epoch: 197, loss: 0.197853
global_step: 31865, epoch: 197, loss: 0.250029
global_step: 31866, epoch: 197, loss: 0.222016
global_step: 31867, epoch: 197, loss: 0.198104
global_step: 31868, epoch: 197, loss: 0.238573
global_step: 31869, epoch: 197, loss: 0.257361
global_step: 31870, epoch: 197, loss: 0.305080
global_step: 31871, epoch: 197, loss: 0.273499
global_step: 31872, epoch: 197, loss: 0.266231
global_step: 31873, epoch: 197, loss: 0.266235
global_step: 31874, epoch: 197, loss: 0.249751
global_step: 31875, epoch: 197, loss: 0.254022
global_step: 31876, epoch: 197, loss: 0.210682
global_step: 31877, epoch: 197, loss: 0.262497
global_step: 31878, epoch: 197, loss: 0.228580
global_step: 31879, epoch: 197, loss: 0.261209
global_step: 31880, epoch: 197, loss: 0.234483
epoch: 197
train	acc: 0.9641	macro: p 0.9675, r 0.9369, f1: 0.9512	micro: p 0.9641, r 0.9641, f1 0.9641	weighted_f1:0.9640
dev	acc: 0.5537	macro: p 0.4056, r 0.3517, f1: 0.3577	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5206
test	acc: 0.5912	macro: p 0.3937, r 0.3538, f1: 0.3633	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5683
global_step: 31881, epoch: 198, loss: 0.239517
global_step: 31882, epoch: 198, loss: 0.248628
global_step: 31883, epoch: 198, loss: 0.255906
global_step: 31884, epoch: 198, loss: 0.221681
global_step: 31885, epoch: 198, loss: 0.235873
global_step: 31886, epoch: 198, loss: 0.176178
global_step: 31887, epoch: 198, loss: 0.165710
global_step: 31888, epoch: 198, loss: 0.237183
global_step: 31889, epoch: 198, loss: 0.262119
global_step: 31890, epoch: 198, loss: 0.195800
global_step: 31891, epoch: 198, loss: 0.242335
global_step: 31892, epoch: 198, loss: 0.278327
global_step: 31893, epoch: 198, loss: 0.291419
global_step: 31894, epoch: 198, loss: 0.241691
global_step: 31895, epoch: 198, loss: 0.253541
global_step: 31896, epoch: 198, loss: 0.231697
global_step: 31897, epoch: 198, loss: 0.302072
global_step: 31898, epoch: 198, loss: 0.225809
global_step: 31899, epoch: 198, loss: 0.322718
global_step: 31900, epoch: 198, loss: 0.256400
global_step: 31901, epoch: 198, loss: 0.222382
global_step: 31902, epoch: 198, loss: 0.243959
global_step: 31903, epoch: 198, loss: 0.218979
global_step: 31904, epoch: 198, loss: 0.204469
global_step: 31905, epoch: 198, loss: 0.231909
global_step: 31906, epoch: 198, loss: 0.313021
global_step: 31907, epoch: 198, loss: 0.232874
global_step: 31908, epoch: 198, loss: 0.309987
global_step: 31909, epoch: 198, loss: 0.301325
global_step: 31910, epoch: 198, loss: 0.266038
global_step: 31911, epoch: 198, loss: 0.286334
global_step: 31912, epoch: 198, loss: 0.231942
global_step: 31913, epoch: 198, loss: 0.264767
global_step: 31914, epoch: 198, loss: 0.248601
global_step: 31915, epoch: 198, loss: 0.217669
global_step: 31916, epoch: 198, loss: 0.223492
global_step: 31917, epoch: 198, loss: 0.225286
global_step: 31918, epoch: 198, loss: 0.271785
global_step: 31919, epoch: 198, loss: 0.241404
global_step: 31920, epoch: 198, loss: 0.360062
epoch: 198
train	acc: 0.9642	macro: p 0.9657, r 0.9407, f1: 0.9524	micro: p 0.9642, r 0.9642, f1 0.9642	weighted_f1:0.9641
dev	acc: 0.5500	macro: p 0.3895, r 0.3417, f1: 0.3462	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5166
test	acc: 0.5931	macro: p 0.3945, r 0.3578, f1: 0.3683	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5718
global_step: 31921, epoch: 199, loss: 0.223651
global_step: 31922, epoch: 199, loss: 0.260514
global_step: 31923, epoch: 199, loss: 0.215083
global_step: 31924, epoch: 199, loss: 0.161823
global_step: 31925, epoch: 199, loss: 0.225803
global_step: 31926, epoch: 199, loss: 0.270348
global_step: 31927, epoch: 199, loss: 0.216413
global_step: 31928, epoch: 199, loss: 0.172907
global_step: 31929, epoch: 199, loss: 0.203627
global_step: 31930, epoch: 199, loss: 0.249961
global_step: 31931, epoch: 199, loss: 0.228047
global_step: 31932, epoch: 199, loss: 0.271327
global_step: 31933, epoch: 199, loss: 0.212143
global_step: 31934, epoch: 199, loss: 0.235976
global_step: 31935, epoch: 199, loss: 0.248482
global_step: 31936, epoch: 199, loss: 0.275141
global_step: 31937, epoch: 199, loss: 0.266454
global_step: 31938, epoch: 199, loss: 0.249183
global_step: 31939, epoch: 199, loss: 0.283452
global_step: 31940, epoch: 199, loss: 0.224261
global_step: 31941, epoch: 199, loss: 0.202363
global_step: 31942, epoch: 199, loss: 0.247037
global_step: 31943, epoch: 199, loss: 0.179413
global_step: 31944, epoch: 199, loss: 0.187605
global_step: 31945, epoch: 199, loss: 0.243997
global_step: 31946, epoch: 199, loss: 0.256192
global_step: 31947, epoch: 199, loss: 0.268270
global_step: 31948, epoch: 199, loss: 0.219778
global_step: 31949, epoch: 199, loss: 0.277294
global_step: 31950, epoch: 199, loss: 0.209191
global_step: 31951, epoch: 199, loss: 0.235768
global_step: 31952, epoch: 199, loss: 0.240938
global_step: 31953, epoch: 199, loss: 0.251827
global_step: 31954, epoch: 199, loss: 0.293830
global_step: 31955, epoch: 199, loss: 0.227109
global_step: 31956, epoch: 199, loss: 0.257271
global_step: 31957, epoch: 199, loss: 0.259417
global_step: 31958, epoch: 199, loss: 0.249424
global_step: 31959, epoch: 199, loss: 0.236020
global_step: 31960, epoch: 199, loss: 0.194364
epoch: 199
train	acc: 0.9635	macro: p 0.9658, r 0.9396, f1: 0.9519	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5528	macro: p 0.3879, r 0.3499, f1: 0.3601	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5265
test	acc: 0.5874	macro: p 0.3980, r 0.3643, f1: 0.3761	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5708
global_step: 31961, epoch: 200, loss: 0.273731
global_step: 31962, epoch: 200, loss: 0.231451
global_step: 31963, epoch: 200, loss: 0.222572
global_step: 31964, epoch: 200, loss: 0.207017
global_step: 31965, epoch: 200, loss: 0.186191
global_step: 31966, epoch: 200, loss: 0.300145
global_step: 31967, epoch: 200, loss: 0.283167
global_step: 31968, epoch: 200, loss: 0.245761
global_step: 31969, epoch: 200, loss: 0.280086
global_step: 31970, epoch: 200, loss: 0.182880
global_step: 31971, epoch: 200, loss: 0.243176
global_step: 31972, epoch: 200, loss: 0.296630
global_step: 31973, epoch: 200, loss: 0.222016
global_step: 31974, epoch: 200, loss: 0.229299
global_step: 31975, epoch: 200, loss: 0.221627
global_step: 31976, epoch: 200, loss: 0.232539
global_step: 31977, epoch: 200, loss: 0.217957
global_step: 31978, epoch: 200, loss: 0.301631
global_step: 31979, epoch: 200, loss: 0.273685
global_step: 31980, epoch: 200, loss: 0.196351
global_step: 31981, epoch: 200, loss: 0.278348
global_step: 31982, epoch: 200, loss: 0.254377
global_step: 31983, epoch: 200, loss: 0.197363
global_step: 31984, epoch: 200, loss: 0.175638
global_step: 31985, epoch: 200, loss: 0.252736
global_step: 31986, epoch: 200, loss: 0.217199
global_step: 31987, epoch: 200, loss: 0.310704
global_step: 31988, epoch: 200, loss: 0.301624
global_step: 31989, epoch: 200, loss: 0.197521
global_step: 31990, epoch: 200, loss: 0.202080
global_step: 31991, epoch: 200, loss: 0.213358
global_step: 31992, epoch: 200, loss: 0.250719
global_step: 31993, epoch: 200, loss: 0.239647
global_step: 31994, epoch: 200, loss: 0.306800
global_step: 31995, epoch: 200, loss: 0.223202
global_step: 31996, epoch: 200, loss: 0.222679
global_step: 31997, epoch: 200, loss: 0.228460
global_step: 31998, epoch: 200, loss: 0.329522
global_step: 31999, epoch: 200, loss: 0.243321
global_step: 32000, epoch: 200, loss: 0.013736
epoch: 200
train	acc: 0.9655	macro: p 0.9697, r 0.9428, f1: 0.9555	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9654
dev	acc: 0.5473	macro: p 0.3836, r 0.3395, f1: 0.3467	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5147
test	acc: 0.5893	macro: p 0.3986, r 0.3586, f1: 0.3703	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5688
BEST MODEL epoch: 105
train	acc: 0.8934 macro_p: 0.8605 macro_r: 0.7084 macro_f1: 0.7223 micro_p: 0.8934 micro_r: 0.8934 micro_f1: 0.8934 weighted_f1: 0.8813
dev	acc: 0.5834 macro_p: 0.5465 macro_r: 0.3665 macro_f1: 0.3717 micro_p: 0.5834 micro_r: 0.5834 micro_f1: 0.5834 weighted_f1: 0.5488
test	acc: 0.6096 macro_p: 0.4394 macro_r: 0.3630 macro_f1: 0.3673 micro_p: 0.6096 micro_r: 0.6096 micro_f1: 0.6096 weighted_f1: 0.5841
==========ROUND 5==========
loading word2vec...
load glove.txt
vocab_num:7687, in w2v: 7125, ratio:0.9268895537921166
global_step: 32001, epoch: 1, loss: 1.999951
global_step: 32002, epoch: 1, loss: 1.963465
global_step: 32003, epoch: 1, loss: 1.973645
global_step: 32004, epoch: 1, loss: 1.955965
global_step: 32005, epoch: 1, loss: 1.936406
global_step: 32006, epoch: 1, loss: 1.946309
global_step: 32007, epoch: 1, loss: 1.915560
global_step: 32008, epoch: 1, loss: 1.909289
global_step: 32009, epoch: 1, loss: 1.894339
global_step: 32010, epoch: 1, loss: 1.888906
global_step: 32011, epoch: 1, loss: 1.861641
global_step: 32012, epoch: 1, loss: 1.846270
global_step: 32013, epoch: 1, loss: 1.841743
global_step: 32014, epoch: 1, loss: 1.825237
global_step: 32015, epoch: 1, loss: 1.822865
global_step: 32016, epoch: 1, loss: 1.791556
global_step: 32017, epoch: 1, loss: 1.775136
global_step: 32018, epoch: 1, loss: 1.770834
global_step: 32019, epoch: 1, loss: 1.761816
global_step: 32020, epoch: 1, loss: 1.756386
global_step: 32021, epoch: 1, loss: 1.716986
global_step: 32022, epoch: 1, loss: 1.691942
global_step: 32023, epoch: 1, loss: 1.671430
global_step: 32024, epoch: 1, loss: 1.687028
global_step: 32025, epoch: 1, loss: 1.685100
global_step: 32026, epoch: 1, loss: 1.675433
global_step: 32027, epoch: 1, loss: 1.599259
global_step: 32028, epoch: 1, loss: 1.648737
global_step: 32029, epoch: 1, loss: 1.668167
global_step: 32030, epoch: 1, loss: 1.607454
global_step: 32031, epoch: 1, loss: 1.611688
global_step: 32032, epoch: 1, loss: 1.645332
global_step: 32033, epoch: 1, loss: 1.557905
global_step: 32034, epoch: 1, loss: 1.568237
global_step: 32035, epoch: 1, loss: 1.561764
global_step: 32036, epoch: 1, loss: 1.600307
global_step: 32037, epoch: 1, loss: 1.463963
global_step: 32038, epoch: 1, loss: 1.659618
global_step: 32039, epoch: 1, loss: 1.541407
global_step: 32040, epoch: 1, loss: 1.377443
epoch: 1
train	acc: 0.4707	macro: p 0.0888, r 0.1428, f1: 0.0919	micro: p 0.4707, r 0.4707, f1 0.4707	weighted_f1:0.3025
dev	acc: 0.4238	macro: p 0.0605, r 0.1429, f1: 0.0850	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.2523
test	acc: 0.4812	macro: p 0.0687, r 0.1429, f1: 0.0928	micro: p 0.4812, r 0.4812, f1 0.4812	weighted_f1:0.3127
New best model!
global_step: 32041, epoch: 2, loss: 1.602284
global_step: 32042, epoch: 2, loss: 1.573777
global_step: 32043, epoch: 2, loss: 1.591034
global_step: 32044, epoch: 2, loss: 1.462597
global_step: 32045, epoch: 2, loss: 1.645345
global_step: 32046, epoch: 2, loss: 1.593277
global_step: 32047, epoch: 2, loss: 1.544360
global_step: 32048, epoch: 2, loss: 1.533097
global_step: 32049, epoch: 2, loss: 1.602664
global_step: 32050, epoch: 2, loss: 1.535809
global_step: 32051, epoch: 2, loss: 1.593573
global_step: 32052, epoch: 2, loss: 1.445634
global_step: 32053, epoch: 2, loss: 1.569960
global_step: 32054, epoch: 2, loss: 1.620826
global_step: 32055, epoch: 2, loss: 1.625680
global_step: 32056, epoch: 2, loss: 1.483590
global_step: 32057, epoch: 2, loss: 1.612611
global_step: 32058, epoch: 2, loss: 1.520124
global_step: 32059, epoch: 2, loss: 1.640194
global_step: 32060, epoch: 2, loss: 1.456083
global_step: 32061, epoch: 2, loss: 1.546930
global_step: 32062, epoch: 2, loss: 1.565119
global_step: 32063, epoch: 2, loss: 1.574186
global_step: 32064, epoch: 2, loss: 1.505471
global_step: 32065, epoch: 2, loss: 1.614452
global_step: 32066, epoch: 2, loss: 1.476472
global_step: 32067, epoch: 2, loss: 1.568037
global_step: 32068, epoch: 2, loss: 1.431694
global_step: 32069, epoch: 2, loss: 1.629634
global_step: 32070, epoch: 2, loss: 1.465846
global_step: 32071, epoch: 2, loss: 1.540238
global_step: 32072, epoch: 2, loss: 1.547150
global_step: 32073, epoch: 2, loss: 1.568579
global_step: 32074, epoch: 2, loss: 1.471895
global_step: 32075, epoch: 2, loss: 1.432708
global_step: 32076, epoch: 2, loss: 1.577176
global_step: 32077, epoch: 2, loss: 1.452150
global_step: 32078, epoch: 2, loss: 1.491192
global_step: 32079, epoch: 2, loss: 1.534522
global_step: 32080, epoch: 2, loss: 1.372750
epoch: 2
train	acc: 0.4718	macro: p 0.1104, r 0.1439, f1: 0.0945	micro: p 0.4718, r 0.4718, f1 0.4718	weighted_f1:0.3059
dev	acc: 0.4256	macro: p 0.1085, r 0.1446, f1: 0.0888	micro: p 0.4256, r 0.4256, f1 0.4256	weighted_f1:0.2567
test	acc: 0.4820	macro: p 0.1200, r 0.1443, f1: 0.0964	micro: p 0.4820, r 0.4820, f1 0.4820	weighted_f1:0.3168
New best model!
global_step: 32081, epoch: 3, loss: 1.544029
global_step: 32082, epoch: 3, loss: 1.586349
global_step: 32083, epoch: 3, loss: 1.559652
global_step: 32084, epoch: 3, loss: 1.434286
global_step: 32085, epoch: 3, loss: 1.563747
global_step: 32086, epoch: 3, loss: 1.475665
global_step: 32087, epoch: 3, loss: 1.479893
global_step: 32088, epoch: 3, loss: 1.528097
global_step: 32089, epoch: 3, loss: 1.503844
global_step: 32090, epoch: 3, loss: 1.447589
global_step: 32091, epoch: 3, loss: 1.501586
global_step: 32092, epoch: 3, loss: 1.493568
global_step: 32093, epoch: 3, loss: 1.587166
global_step: 32094, epoch: 3, loss: 1.548064
global_step: 32095, epoch: 3, loss: 1.491128
global_step: 32096, epoch: 3, loss: 1.366548
global_step: 32097, epoch: 3, loss: 1.448904
global_step: 32098, epoch: 3, loss: 1.463713
global_step: 32099, epoch: 3, loss: 1.525267
global_step: 32100, epoch: 3, loss: 1.450607
global_step: 32101, epoch: 3, loss: 1.329504
global_step: 32102, epoch: 3, loss: 1.426310
global_step: 32103, epoch: 3, loss: 1.480001
global_step: 32104, epoch: 3, loss: 1.555092
global_step: 32105, epoch: 3, loss: 1.504409
global_step: 32106, epoch: 3, loss: 1.481761
global_step: 32107, epoch: 3, loss: 1.381467
global_step: 32108, epoch: 3, loss: 1.475713
global_step: 32109, epoch: 3, loss: 1.491107
global_step: 32110, epoch: 3, loss: 1.537910
global_step: 32111, epoch: 3, loss: 1.423143
global_step: 32112, epoch: 3, loss: 1.409375
global_step: 32113, epoch: 3, loss: 1.438997
global_step: 32114, epoch: 3, loss: 1.454177
global_step: 32115, epoch: 3, loss: 1.559812
global_step: 32116, epoch: 3, loss: 1.504694
global_step: 32117, epoch: 3, loss: 1.453886
global_step: 32118, epoch: 3, loss: 1.455523
global_step: 32119, epoch: 3, loss: 1.397511
global_step: 32120, epoch: 3, loss: 1.098773
epoch: 3
train	acc: 0.5100	macro: p 0.1322, r 0.1791, f1: 0.1441	micro: p 0.5100, r 0.5100, f1 0.5100	weighted_f1:0.3791
dev	acc: 0.4590	macro: p 0.1140, r 0.1799, f1: 0.1340	micro: p 0.4590, r 0.4590, f1 0.4590	weighted_f1:0.3165
test	acc: 0.5111	macro: p 0.1231, r 0.1761, f1: 0.1396	micro: p 0.5111, r 0.5111, f1 0.5111	weighted_f1:0.3774
New best model!
global_step: 32121, epoch: 4, loss: 1.455018
global_step: 32122, epoch: 4, loss: 1.481314
global_step: 32123, epoch: 4, loss: 1.386536
global_step: 32124, epoch: 4, loss: 1.497515
global_step: 32125, epoch: 4, loss: 1.540544
global_step: 32126, epoch: 4, loss: 1.399949
global_step: 32127, epoch: 4, loss: 1.404893
global_step: 32128, epoch: 4, loss: 1.399524
global_step: 32129, epoch: 4, loss: 1.382213
global_step: 32130, epoch: 4, loss: 1.355529
global_step: 32131, epoch: 4, loss: 1.393686
global_step: 32132, epoch: 4, loss: 1.529414
global_step: 32133, epoch: 4, loss: 1.517223
global_step: 32134, epoch: 4, loss: 1.431942
global_step: 32135, epoch: 4, loss: 1.487442
global_step: 32136, epoch: 4, loss: 1.455476
global_step: 32137, epoch: 4, loss: 1.423218
global_step: 32138, epoch: 4, loss: 1.441473
global_step: 32139, epoch: 4, loss: 1.432017
global_step: 32140, epoch: 4, loss: 1.400426
global_step: 32141, epoch: 4, loss: 1.371719
global_step: 32142, epoch: 4, loss: 1.402878
global_step: 32143, epoch: 4, loss: 1.340873
global_step: 32144, epoch: 4, loss: 1.412972
global_step: 32145, epoch: 4, loss: 1.485832
global_step: 32146, epoch: 4, loss: 1.430369
global_step: 32147, epoch: 4, loss: 1.364633
global_step: 32148, epoch: 4, loss: 1.321384
global_step: 32149, epoch: 4, loss: 1.449490
global_step: 32150, epoch: 4, loss: 1.464101
global_step: 32151, epoch: 4, loss: 1.409668
global_step: 32152, epoch: 4, loss: 1.419606
global_step: 32153, epoch: 4, loss: 1.365100
global_step: 32154, epoch: 4, loss: 1.386926
global_step: 32155, epoch: 4, loss: 1.428110
global_step: 32156, epoch: 4, loss: 1.395274
global_step: 32157, epoch: 4, loss: 1.511014
global_step: 32158, epoch: 4, loss: 1.315367
global_step: 32159, epoch: 4, loss: 1.405827
global_step: 32160, epoch: 4, loss: 2.307566
epoch: 4
train	acc: 0.5393	macro: p 0.1368, r 0.2127, f1: 0.1665	micro: p 0.5393, r 0.5393, f1 0.5393	weighted_f1:0.4247
dev	acc: 0.4842	macro: p 0.1212, r 0.2153, f1: 0.1548	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.3568
test	acc: 0.5444	macro: p 0.1362, r 0.2194, f1: 0.1676	micro: p 0.5444, r 0.5444, f1 0.5444	weighted_f1:0.4294
New best model!
global_step: 32161, epoch: 5, loss: 1.438959
global_step: 32162, epoch: 5, loss: 1.248127
global_step: 32163, epoch: 5, loss: 1.346548
global_step: 32164, epoch: 5, loss: 1.462524
global_step: 32165, epoch: 5, loss: 1.438219
global_step: 32166, epoch: 5, loss: 1.279182
global_step: 32167, epoch: 5, loss: 1.353971
global_step: 32168, epoch: 5, loss: 1.459506
global_step: 32169, epoch: 5, loss: 1.378826
global_step: 32170, epoch: 5, loss: 1.375263
global_step: 32171, epoch: 5, loss: 1.434596
global_step: 32172, epoch: 5, loss: 1.383230
global_step: 32173, epoch: 5, loss: 1.441363
global_step: 32174, epoch: 5, loss: 1.396992
global_step: 32175, epoch: 5, loss: 1.483653
global_step: 32176, epoch: 5, loss: 1.413155
global_step: 32177, epoch: 5, loss: 1.566304
global_step: 32178, epoch: 5, loss: 1.410533
global_step: 32179, epoch: 5, loss: 1.381521
global_step: 32180, epoch: 5, loss: 1.375447
global_step: 32181, epoch: 5, loss: 1.400974
global_step: 32182, epoch: 5, loss: 1.353030
global_step: 32183, epoch: 5, loss: 1.371382
global_step: 32184, epoch: 5, loss: 1.385474
global_step: 32185, epoch: 5, loss: 1.317355
global_step: 32186, epoch: 5, loss: 1.347141
global_step: 32187, epoch: 5, loss: 1.416507
global_step: 32188, epoch: 5, loss: 1.427786
global_step: 32189, epoch: 5, loss: 1.370176
global_step: 32190, epoch: 5, loss: 1.414247
global_step: 32191, epoch: 5, loss: 1.467472
global_step: 32192, epoch: 5, loss: 1.399627
global_step: 32193, epoch: 5, loss: 1.250041
global_step: 32194, epoch: 5, loss: 1.371535
global_step: 32195, epoch: 5, loss: 1.206241
global_step: 32196, epoch: 5, loss: 1.452254
global_step: 32197, epoch: 5, loss: 1.375857
global_step: 32198, epoch: 5, loss: 1.401754
global_step: 32199, epoch: 5, loss: 1.398273
global_step: 32200, epoch: 5, loss: 0.732885
epoch: 5
train	acc: 0.5401	macro: p 0.1370, r 0.2130, f1: 0.1668	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4251
dev	acc: 0.4842	macro: p 0.1212, r 0.2153, f1: 0.1548	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.3565
test	acc: 0.5452	macro: p 0.1362, r 0.2191, f1: 0.1675	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.4297
global_step: 32201, epoch: 6, loss: 1.385320
global_step: 32202, epoch: 6, loss: 1.319342
global_step: 32203, epoch: 6, loss: 1.454839
global_step: 32204, epoch: 6, loss: 1.374369
global_step: 32205, epoch: 6, loss: 1.407561
global_step: 32206, epoch: 6, loss: 1.366426
global_step: 32207, epoch: 6, loss: 1.473514
global_step: 32208, epoch: 6, loss: 1.403999
global_step: 32209, epoch: 6, loss: 1.248765
global_step: 32210, epoch: 6, loss: 1.394695
global_step: 32211, epoch: 6, loss: 1.303234
global_step: 32212, epoch: 6, loss: 1.318146
global_step: 32213, epoch: 6, loss: 1.392546
global_step: 32214, epoch: 6, loss: 1.381913
global_step: 32215, epoch: 6, loss: 1.328398
global_step: 32216, epoch: 6, loss: 1.472313
global_step: 32217, epoch: 6, loss: 1.304505
global_step: 32218, epoch: 6, loss: 1.499060
global_step: 32219, epoch: 6, loss: 1.337848
global_step: 32220, epoch: 6, loss: 1.392878
global_step: 32221, epoch: 6, loss: 1.463547
global_step: 32222, epoch: 6, loss: 1.341568
global_step: 32223, epoch: 6, loss: 1.440868
global_step: 32224, epoch: 6, loss: 1.381489
global_step: 32225, epoch: 6, loss: 1.330308
global_step: 32226, epoch: 6, loss: 1.392897
global_step: 32227, epoch: 6, loss: 1.288013
global_step: 32228, epoch: 6, loss: 1.339001
global_step: 32229, epoch: 6, loss: 1.263037
global_step: 32230, epoch: 6, loss: 1.268957
global_step: 32231, epoch: 6, loss: 1.454778
global_step: 32232, epoch: 6, loss: 1.342001
global_step: 32233, epoch: 6, loss: 1.362613
global_step: 32234, epoch: 6, loss: 1.397756
global_step: 32235, epoch: 6, loss: 1.396094
global_step: 32236, epoch: 6, loss: 1.416190
global_step: 32237, epoch: 6, loss: 1.338300
global_step: 32238, epoch: 6, loss: 1.399833
global_step: 32239, epoch: 6, loss: 1.314131
global_step: 32240, epoch: 6, loss: 1.675682
epoch: 6
train	acc: 0.5531	macro: p 0.2612, r 0.2305, f1: 0.1948	micro: p 0.5531, r 0.5531, f1 0.5531	weighted_f1:0.4518
dev	acc: 0.5041	macro: p 0.2444, r 0.2362, f1: 0.1851	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.3885
test	acc: 0.5598	macro: p 0.2685, r 0.2413, f1: 0.2033	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.4593
New best model!
global_step: 32241, epoch: 7, loss: 1.365848
global_step: 32242, epoch: 7, loss: 1.379701
global_step: 32243, epoch: 7, loss: 1.322511
global_step: 32244, epoch: 7, loss: 1.350472
global_step: 32245, epoch: 7, loss: 1.381311
global_step: 32246, epoch: 7, loss: 1.287617
global_step: 32247, epoch: 7, loss: 1.412108
global_step: 32248, epoch: 7, loss: 1.475946
global_step: 32249, epoch: 7, loss: 1.411199
global_step: 32250, epoch: 7, loss: 1.272759
global_step: 32251, epoch: 7, loss: 1.506077
global_step: 32252, epoch: 7, loss: 1.246554
global_step: 32253, epoch: 7, loss: 1.261776
global_step: 32254, epoch: 7, loss: 1.422022
global_step: 32255, epoch: 7, loss: 1.403437
global_step: 32256, epoch: 7, loss: 1.334860
global_step: 32257, epoch: 7, loss: 1.382235
global_step: 32258, epoch: 7, loss: 1.301731
global_step: 32259, epoch: 7, loss: 1.366399
global_step: 32260, epoch: 7, loss: 1.504118
global_step: 32261, epoch: 7, loss: 1.250760
global_step: 32262, epoch: 7, loss: 1.454060
global_step: 32263, epoch: 7, loss: 1.293943
global_step: 32264, epoch: 7, loss: 1.377072
global_step: 32265, epoch: 7, loss: 1.278372
global_step: 32266, epoch: 7, loss: 1.357984
global_step: 32267, epoch: 7, loss: 1.394442
global_step: 32268, epoch: 7, loss: 1.343782
global_step: 32269, epoch: 7, loss: 1.422988
global_step: 32270, epoch: 7, loss: 1.322262
global_step: 32271, epoch: 7, loss: 1.429619
global_step: 32272, epoch: 7, loss: 1.323833
global_step: 32273, epoch: 7, loss: 1.370465
global_step: 32274, epoch: 7, loss: 1.345833
global_step: 32275, epoch: 7, loss: 1.378513
global_step: 32276, epoch: 7, loss: 1.404278
global_step: 32277, epoch: 7, loss: 1.337632
global_step: 32278, epoch: 7, loss: 1.233240
global_step: 32279, epoch: 7, loss: 1.425246
global_step: 32280, epoch: 7, loss: 1.886924
epoch: 7
train	acc: 0.5542	macro: p 0.2587, r 0.2322, f1: 0.1975	micro: p 0.5542, r 0.5542, f1 0.5542	weighted_f1:0.4541
dev	acc: 0.5050	macro: p 0.2471, r 0.2378, f1: 0.1882	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.3911
test	acc: 0.5602	macro: p 0.2659, r 0.2418, f1: 0.2041	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.4599
New best model!
global_step: 32281, epoch: 8, loss: 1.359658
global_step: 32282, epoch: 8, loss: 1.312264
global_step: 32283, epoch: 8, loss: 1.336922
global_step: 32284, epoch: 8, loss: 1.271708
global_step: 32285, epoch: 8, loss: 1.330979
global_step: 32286, epoch: 8, loss: 1.421340
global_step: 32287, epoch: 8, loss: 1.306421
global_step: 32288, epoch: 8, loss: 1.303120
global_step: 32289, epoch: 8, loss: 1.338794
global_step: 32290, epoch: 8, loss: 1.347256
global_step: 32291, epoch: 8, loss: 1.307623
global_step: 32292, epoch: 8, loss: 1.337210
global_step: 32293, epoch: 8, loss: 1.272449
global_step: 32294, epoch: 8, loss: 1.352182
global_step: 32295, epoch: 8, loss: 1.404921
global_step: 32296, epoch: 8, loss: 1.332581
global_step: 32297, epoch: 8, loss: 1.251981
global_step: 32298, epoch: 8, loss: 1.391973
global_step: 32299, epoch: 8, loss: 1.342660
global_step: 32300, epoch: 8, loss: 1.316919
global_step: 32301, epoch: 8, loss: 1.257370
global_step: 32302, epoch: 8, loss: 1.351657
global_step: 32303, epoch: 8, loss: 1.406394
global_step: 32304, epoch: 8, loss: 1.234578
global_step: 32305, epoch: 8, loss: 1.474610
global_step: 32306, epoch: 8, loss: 1.414951
global_step: 32307, epoch: 8, loss: 1.227041
global_step: 32308, epoch: 8, loss: 1.334626
global_step: 32309, epoch: 8, loss: 1.437095
global_step: 32310, epoch: 8, loss: 1.531720
global_step: 32311, epoch: 8, loss: 1.285362
global_step: 32312, epoch: 8, loss: 1.447140
global_step: 32313, epoch: 8, loss: 1.306486
global_step: 32314, epoch: 8, loss: 1.424181
global_step: 32315, epoch: 8, loss: 1.185853
global_step: 32316, epoch: 8, loss: 1.356808
global_step: 32317, epoch: 8, loss: 1.324541
global_step: 32318, epoch: 8, loss: 1.315331
global_step: 32319, epoch: 8, loss: 1.455582
global_step: 32320, epoch: 8, loss: 1.544216
epoch: 8
train	acc: 0.5539	macro: p 0.2605, r 0.2313, f1: 0.1959	micro: p 0.5539, r 0.5539, f1 0.5539	weighted_f1:0.4529
dev	acc: 0.5059	macro: p 0.2538, r 0.2381, f1: 0.1885	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.3917
test	acc: 0.5598	macro: p 0.2717, r 0.2413, f1: 0.2033	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.4593
New best model!
global_step: 32321, epoch: 9, loss: 1.303586
global_step: 32322, epoch: 9, loss: 1.273038
global_step: 32323, epoch: 9, loss: 1.451385
global_step: 32324, epoch: 9, loss: 1.323272
global_step: 32325, epoch: 9, loss: 1.361455
global_step: 32326, epoch: 9, loss: 1.264257
global_step: 32327, epoch: 9, loss: 1.357747
global_step: 32328, epoch: 9, loss: 1.372843
global_step: 32329, epoch: 9, loss: 1.381165
global_step: 32330, epoch: 9, loss: 1.278636
global_step: 32331, epoch: 9, loss: 1.424367
global_step: 32332, epoch: 9, loss: 1.311428
global_step: 32333, epoch: 9, loss: 1.414875
global_step: 32334, epoch: 9, loss: 1.365846
global_step: 32335, epoch: 9, loss: 1.403523
global_step: 32336, epoch: 9, loss: 1.390225
global_step: 32337, epoch: 9, loss: 1.328099
global_step: 32338, epoch: 9, loss: 1.293498
global_step: 32339, epoch: 9, loss: 1.326147
global_step: 32340, epoch: 9, loss: 1.273769
global_step: 32341, epoch: 9, loss: 1.344558
global_step: 32342, epoch: 9, loss: 1.249255
global_step: 32343, epoch: 9, loss: 1.409644
global_step: 32344, epoch: 9, loss: 1.311723
global_step: 32345, epoch: 9, loss: 1.254874
global_step: 32346, epoch: 9, loss: 1.346404
global_step: 32347, epoch: 9, loss: 1.335753
global_step: 32348, epoch: 9, loss: 1.349348
global_step: 32349, epoch: 9, loss: 1.407760
global_step: 32350, epoch: 9, loss: 1.346914
global_step: 32351, epoch: 9, loss: 1.300345
global_step: 32352, epoch: 9, loss: 1.282057
global_step: 32353, epoch: 9, loss: 1.267394
global_step: 32354, epoch: 9, loss: 1.319723
global_step: 32355, epoch: 9, loss: 1.343525
global_step: 32356, epoch: 9, loss: 1.371884
global_step: 32357, epoch: 9, loss: 1.262323
global_step: 32358, epoch: 9, loss: 1.242971
global_step: 32359, epoch: 9, loss: 1.306355
global_step: 32360, epoch: 9, loss: 2.187077
epoch: 9
train	acc: 0.5558	macro: p 0.2586, r 0.2340, f1: 0.1999	micro: p 0.5558, r 0.5558, f1 0.5558	weighted_f1:0.4566
dev	acc: 0.5059	macro: p 0.2483, r 0.2388, f1: 0.1898	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.3926
test	acc: 0.5613	macro: p 0.2622, r 0.2435, f1: 0.2070	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.4623
New best model!
global_step: 32361, epoch: 10, loss: 1.263498
global_step: 32362, epoch: 10, loss: 1.332925
global_step: 32363, epoch: 10, loss: 1.435483
global_step: 32364, epoch: 10, loss: 1.334017
global_step: 32365, epoch: 10, loss: 1.353831
global_step: 32366, epoch: 10, loss: 1.324519
global_step: 32367, epoch: 10, loss: 1.306385
global_step: 32368, epoch: 10, loss: 1.295137
global_step: 32369, epoch: 10, loss: 1.178911
global_step: 32370, epoch: 10, loss: 1.258915
global_step: 32371, epoch: 10, loss: 1.240456
global_step: 32372, epoch: 10, loss: 1.403200
global_step: 32373, epoch: 10, loss: 1.307143
global_step: 32374, epoch: 10, loss: 1.291003
global_step: 32375, epoch: 10, loss: 1.379588
global_step: 32376, epoch: 10, loss: 1.271742
global_step: 32377, epoch: 10, loss: 1.279701
global_step: 32378, epoch: 10, loss: 1.428396
global_step: 32379, epoch: 10, loss: 1.379427
global_step: 32380, epoch: 10, loss: 1.352031
global_step: 32381, epoch: 10, loss: 1.307248
global_step: 32382, epoch: 10, loss: 1.395863
global_step: 32383, epoch: 10, loss: 1.448329
global_step: 32384, epoch: 10, loss: 1.230176
global_step: 32385, epoch: 10, loss: 1.391790
global_step: 32386, epoch: 10, loss: 1.290963
global_step: 32387, epoch: 10, loss: 1.312841
global_step: 32388, epoch: 10, loss: 1.370036
global_step: 32389, epoch: 10, loss: 1.295219
global_step: 32390, epoch: 10, loss: 1.315812
global_step: 32391, epoch: 10, loss: 1.297138
global_step: 32392, epoch: 10, loss: 1.337311
global_step: 32393, epoch: 10, loss: 1.246425
global_step: 32394, epoch: 10, loss: 1.299438
global_step: 32395, epoch: 10, loss: 1.311163
global_step: 32396, epoch: 10, loss: 1.256343
global_step: 32397, epoch: 10, loss: 1.316976
global_step: 32398, epoch: 10, loss: 1.280266
global_step: 32399, epoch: 10, loss: 1.430818
global_step: 32400, epoch: 10, loss: 1.181750
epoch: 10
train	acc: 0.5587	macro: p 0.2535, r 0.2375, f1: 0.2059	micro: p 0.5587, r 0.5587, f1 0.5587	weighted_f1:0.4619
dev	acc: 0.5104	macro: p 0.2365, r 0.2435, f1: 0.1974	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4001
test	acc: 0.5644	macro: p 0.2510, r 0.2477, f1: 0.2133	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.4673
New best model!
global_step: 32401, epoch: 11, loss: 1.336064
global_step: 32402, epoch: 11, loss: 1.223908
global_step: 32403, epoch: 11, loss: 1.330370
global_step: 32404, epoch: 11, loss: 1.257675
global_step: 32405, epoch: 11, loss: 1.374057
global_step: 32406, epoch: 11, loss: 1.359640
global_step: 32407, epoch: 11, loss: 1.345112
global_step: 32408, epoch: 11, loss: 1.303611
global_step: 32409, epoch: 11, loss: 1.228817
global_step: 32410, epoch: 11, loss: 1.213271
global_step: 32411, epoch: 11, loss: 1.305801
global_step: 32412, epoch: 11, loss: 1.261813
global_step: 32413, epoch: 11, loss: 1.285006
global_step: 32414, epoch: 11, loss: 1.365493
global_step: 32415, epoch: 11, loss: 1.236315
global_step: 32416, epoch: 11, loss: 1.361347
global_step: 32417, epoch: 11, loss: 1.325652
global_step: 32418, epoch: 11, loss: 1.325724
global_step: 32419, epoch: 11, loss: 1.317929
global_step: 32420, epoch: 11, loss: 1.267132
global_step: 32421, epoch: 11, loss: 1.258605
global_step: 32422, epoch: 11, loss: 1.279182
global_step: 32423, epoch: 11, loss: 1.429723
global_step: 32424, epoch: 11, loss: 1.276111
global_step: 32425, epoch: 11, loss: 1.400214
global_step: 32426, epoch: 11, loss: 1.384665
global_step: 32427, epoch: 11, loss: 1.288501
global_step: 32428, epoch: 11, loss: 1.365506
global_step: 32429, epoch: 11, loss: 1.305230
global_step: 32430, epoch: 11, loss: 1.318650
global_step: 32431, epoch: 11, loss: 1.180535
global_step: 32432, epoch: 11, loss: 1.365696
global_step: 32433, epoch: 11, loss: 1.308918
global_step: 32434, epoch: 11, loss: 1.376481
global_step: 32435, epoch: 11, loss: 1.242115
global_step: 32436, epoch: 11, loss: 1.374151
global_step: 32437, epoch: 11, loss: 1.282555
global_step: 32438, epoch: 11, loss: 1.316676
global_step: 32439, epoch: 11, loss: 1.274079
global_step: 32440, epoch: 11, loss: 1.683289
epoch: 11
train	acc: 0.5634	macro: p 0.3199, r 0.2418, f1: 0.2127	micro: p 0.5634, r 0.5634, f1 0.5634	weighted_f1:0.4685
dev	acc: 0.5185	macro: p 0.2322, r 0.2515, f1: 0.2088	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4115
test	acc: 0.5678	macro: p 0.2469, r 0.2526, f1: 0.2204	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.4729
New best model!
global_step: 32441, epoch: 12, loss: 1.239503
global_step: 32442, epoch: 12, loss: 1.358734
global_step: 32443, epoch: 12, loss: 1.244857
global_step: 32444, epoch: 12, loss: 1.359823
global_step: 32445, epoch: 12, loss: 1.269997
global_step: 32446, epoch: 12, loss: 1.253373
global_step: 32447, epoch: 12, loss: 1.122479
global_step: 32448, epoch: 12, loss: 1.271242
global_step: 32449, epoch: 12, loss: 1.347562
global_step: 32450, epoch: 12, loss: 1.282024
global_step: 32451, epoch: 12, loss: 1.211508
global_step: 32452, epoch: 12, loss: 1.328086
global_step: 32453, epoch: 12, loss: 1.391084
global_step: 32454, epoch: 12, loss: 1.324533
global_step: 32455, epoch: 12, loss: 1.366324
global_step: 32456, epoch: 12, loss: 1.336479
global_step: 32457, epoch: 12, loss: 1.259215
global_step: 32458, epoch: 12, loss: 1.279620
global_step: 32459, epoch: 12, loss: 1.211538
global_step: 32460, epoch: 12, loss: 1.396535
global_step: 32461, epoch: 12, loss: 1.248427
global_step: 32462, epoch: 12, loss: 1.303225
global_step: 32463, epoch: 12, loss: 1.271433
global_step: 32464, epoch: 12, loss: 1.241900
global_step: 32465, epoch: 12, loss: 1.367794
global_step: 32466, epoch: 12, loss: 1.299495
global_step: 32467, epoch: 12, loss: 1.244724
global_step: 32468, epoch: 12, loss: 1.310298
global_step: 32469, epoch: 12, loss: 1.337812
global_step: 32470, epoch: 12, loss: 1.309746
global_step: 32471, epoch: 12, loss: 1.171436
global_step: 32472, epoch: 12, loss: 1.207963
global_step: 32473, epoch: 12, loss: 1.317218
global_step: 32474, epoch: 12, loss: 1.346064
global_step: 32475, epoch: 12, loss: 1.370857
global_step: 32476, epoch: 12, loss: 1.286675
global_step: 32477, epoch: 12, loss: 1.309016
global_step: 32478, epoch: 12, loss: 1.408107
global_step: 32479, epoch: 12, loss: 1.275680
global_step: 32480, epoch: 12, loss: 1.784679
epoch: 12
train	acc: 0.5747	macro: p 0.3254, r 0.2571, f1: 0.2361	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.4902
dev	acc: 0.5203	macro: p 0.2750, r 0.2553, f1: 0.2156	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4185
test	acc: 0.5713	macro: p 0.3091, r 0.2594, f1: 0.2320	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.4835
New best model!
global_step: 32481, epoch: 13, loss: 1.339397
global_step: 32482, epoch: 13, loss: 1.372003
global_step: 32483, epoch: 13, loss: 1.271283
global_step: 32484, epoch: 13, loss: 1.325098
global_step: 32485, epoch: 13, loss: 1.276860
global_step: 32486, epoch: 13, loss: 1.283988
global_step: 32487, epoch: 13, loss: 1.409393
global_step: 32488, epoch: 13, loss: 1.253732
global_step: 32489, epoch: 13, loss: 1.252056
global_step: 32490, epoch: 13, loss: 1.183440
global_step: 32491, epoch: 13, loss: 1.271623
global_step: 32492, epoch: 13, loss: 1.246023
global_step: 32493, epoch: 13, loss: 1.233120
global_step: 32494, epoch: 13, loss: 1.313275
global_step: 32495, epoch: 13, loss: 1.226348
global_step: 32496, epoch: 13, loss: 1.335120
global_step: 32497, epoch: 13, loss: 1.168686
global_step: 32498, epoch: 13, loss: 1.218635
global_step: 32499, epoch: 13, loss: 1.286416
global_step: 32500, epoch: 13, loss: 1.306300
global_step: 32501, epoch: 13, loss: 1.315654
global_step: 32502, epoch: 13, loss: 1.369176
global_step: 32503, epoch: 13, loss: 1.270701
global_step: 32504, epoch: 13, loss: 1.303354
global_step: 32505, epoch: 13, loss: 1.248994
global_step: 32506, epoch: 13, loss: 1.331751
global_step: 32507, epoch: 13, loss: 1.286976
global_step: 32508, epoch: 13, loss: 1.283454
global_step: 32509, epoch: 13, loss: 1.287397
global_step: 32510, epoch: 13, loss: 1.313986
global_step: 32511, epoch: 13, loss: 1.352047
global_step: 32512, epoch: 13, loss: 1.225958
global_step: 32513, epoch: 13, loss: 1.318283
global_step: 32514, epoch: 13, loss: 1.284929
global_step: 32515, epoch: 13, loss: 1.270829
global_step: 32516, epoch: 13, loss: 1.253774
global_step: 32517, epoch: 13, loss: 1.241486
global_step: 32518, epoch: 13, loss: 1.321360
global_step: 32519, epoch: 13, loss: 1.274522
global_step: 32520, epoch: 13, loss: 0.765049
epoch: 13
train	acc: 0.5792	macro: p 0.3106, r 0.2621, f1: 0.2494	micro: p 0.5792, r 0.5792, f1 0.5792	weighted_f1:0.5002
dev	acc: 0.5284	macro: p 0.2909, r 0.2622, f1: 0.2323	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4348
test	acc: 0.5805	macro: p 0.3020, r 0.2670, f1: 0.2485	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.4992
New best model!
global_step: 32521, epoch: 14, loss: 1.268989
global_step: 32522, epoch: 14, loss: 1.153014
global_step: 32523, epoch: 14, loss: 1.359668
global_step: 32524, epoch: 14, loss: 1.291325
global_step: 32525, epoch: 14, loss: 1.238951
global_step: 32526, epoch: 14, loss: 1.156122
global_step: 32527, epoch: 14, loss: 1.211787
global_step: 32528, epoch: 14, loss: 1.255948
global_step: 32529, epoch: 14, loss: 1.340303
global_step: 32530, epoch: 14, loss: 1.241971
global_step: 32531, epoch: 14, loss: 1.154371
global_step: 32532, epoch: 14, loss: 1.285015
global_step: 32533, epoch: 14, loss: 1.241725
global_step: 32534, epoch: 14, loss: 1.337841
global_step: 32535, epoch: 14, loss: 1.310744
global_step: 32536, epoch: 14, loss: 1.223481
global_step: 32537, epoch: 14, loss: 1.260381
global_step: 32538, epoch: 14, loss: 1.255023
global_step: 32539, epoch: 14, loss: 1.333232
global_step: 32540, epoch: 14, loss: 1.267518
global_step: 32541, epoch: 14, loss: 1.276745
global_step: 32542, epoch: 14, loss: 1.235343
global_step: 32543, epoch: 14, loss: 1.224606
global_step: 32544, epoch: 14, loss: 1.288200
global_step: 32545, epoch: 14, loss: 1.279456
global_step: 32546, epoch: 14, loss: 1.334599
global_step: 32547, epoch: 14, loss: 1.238748
global_step: 32548, epoch: 14, loss: 1.257684
global_step: 32549, epoch: 14, loss: 1.359758
global_step: 32550, epoch: 14, loss: 1.335780
global_step: 32551, epoch: 14, loss: 1.338213
global_step: 32552, epoch: 14, loss: 1.287821
global_step: 32553, epoch: 14, loss: 1.334652
global_step: 32554, epoch: 14, loss: 1.312366
global_step: 32555, epoch: 14, loss: 1.203535
global_step: 32556, epoch: 14, loss: 1.299264
global_step: 32557, epoch: 14, loss: 1.296712
global_step: 32558, epoch: 14, loss: 1.232328
global_step: 32559, epoch: 14, loss: 1.277186
global_step: 32560, epoch: 14, loss: 1.132651
epoch: 14
train	acc: 0.5817	macro: p 0.3051, r 0.2678, f1: 0.2516	micro: p 0.5817, r 0.5817, f1 0.5817	weighted_f1:0.5034
dev	acc: 0.5275	macro: p 0.2922, r 0.2657, f1: 0.2320	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4337
test	acc: 0.5801	macro: p 0.2952, r 0.2716, f1: 0.2492	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.4991
global_step: 32561, epoch: 15, loss: 1.227795
global_step: 32562, epoch: 15, loss: 1.305102
global_step: 32563, epoch: 15, loss: 1.296248
global_step: 32564, epoch: 15, loss: 1.305400
global_step: 32565, epoch: 15, loss: 1.291157
global_step: 32566, epoch: 15, loss: 1.246701
global_step: 32567, epoch: 15, loss: 1.327642
global_step: 32568, epoch: 15, loss: 1.335605
global_step: 32569, epoch: 15, loss: 1.327173
global_step: 32570, epoch: 15, loss: 1.224774
global_step: 32571, epoch: 15, loss: 1.296688
global_step: 32572, epoch: 15, loss: 1.312699
global_step: 32573, epoch: 15, loss: 1.362012
global_step: 32574, epoch: 15, loss: 1.137235
global_step: 32575, epoch: 15, loss: 1.129475
global_step: 32576, epoch: 15, loss: 1.229104
global_step: 32577, epoch: 15, loss: 1.171783
global_step: 32578, epoch: 15, loss: 1.205166
global_step: 32579, epoch: 15, loss: 1.279315
global_step: 32580, epoch: 15, loss: 1.206477
global_step: 32581, epoch: 15, loss: 1.193850
global_step: 32582, epoch: 15, loss: 1.268313
global_step: 32583, epoch: 15, loss: 1.344198
global_step: 32584, epoch: 15, loss: 1.238813
global_step: 32585, epoch: 15, loss: 1.164816
global_step: 32586, epoch: 15, loss: 1.199517
global_step: 32587, epoch: 15, loss: 1.274692
global_step: 32588, epoch: 15, loss: 1.245180
global_step: 32589, epoch: 15, loss: 1.189584
global_step: 32590, epoch: 15, loss: 1.301058
global_step: 32591, epoch: 15, loss: 1.274000
global_step: 32592, epoch: 15, loss: 1.239252
global_step: 32593, epoch: 15, loss: 1.205732
global_step: 32594, epoch: 15, loss: 1.259139
global_step: 32595, epoch: 15, loss: 1.342383
global_step: 32596, epoch: 15, loss: 1.307678
global_step: 32597, epoch: 15, loss: 1.295221
global_step: 32598, epoch: 15, loss: 1.264817
global_step: 32599, epoch: 15, loss: 1.312658
global_step: 32600, epoch: 15, loss: 1.992366
epoch: 15
train	acc: 0.5933	macro: p 0.3110, r 0.2868, f1: 0.2793	micro: p 0.5933, r 0.5933, f1 0.5933	weighted_f1:0.5281
dev	acc: 0.5464	macro: p 0.3020, r 0.2870, f1: 0.2660	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4680
test	acc: 0.5908	macro: p 0.3739, r 0.2880, f1: 0.2758	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5242
New best model!
global_step: 32601, epoch: 16, loss: 1.259599
global_step: 32602, epoch: 16, loss: 1.311160
global_step: 32603, epoch: 16, loss: 1.267661
global_step: 32604, epoch: 16, loss: 1.170105
global_step: 32605, epoch: 16, loss: 1.266899
global_step: 32606, epoch: 16, loss: 1.211586
global_step: 32607, epoch: 16, loss: 1.183847
global_step: 32608, epoch: 16, loss: 1.369780
global_step: 32609, epoch: 16, loss: 1.210015
global_step: 32610, epoch: 16, loss: 1.288728
global_step: 32611, epoch: 16, loss: 1.260095
global_step: 32612, epoch: 16, loss: 1.258825
global_step: 32613, epoch: 16, loss: 1.199168
global_step: 32614, epoch: 16, loss: 1.253553
global_step: 32615, epoch: 16, loss: 1.252377
global_step: 32616, epoch: 16, loss: 1.247488
global_step: 32617, epoch: 16, loss: 1.230577
global_step: 32618, epoch: 16, loss: 1.433882
global_step: 32619, epoch: 16, loss: 1.282347
global_step: 32620, epoch: 16, loss: 1.346033
global_step: 32621, epoch: 16, loss: 1.186424
global_step: 32622, epoch: 16, loss: 1.274960
global_step: 32623, epoch: 16, loss: 1.269218
global_step: 32624, epoch: 16, loss: 1.099910
global_step: 32625, epoch: 16, loss: 1.346968
global_step: 32626, epoch: 16, loss: 1.266937
global_step: 32627, epoch: 16, loss: 1.246875
global_step: 32628, epoch: 16, loss: 1.249040
global_step: 32629, epoch: 16, loss: 1.285279
global_step: 32630, epoch: 16, loss: 1.208586
global_step: 32631, epoch: 16, loss: 1.348042
global_step: 32632, epoch: 16, loss: 1.157103
global_step: 32633, epoch: 16, loss: 1.218085
global_step: 32634, epoch: 16, loss: 1.277813
global_step: 32635, epoch: 16, loss: 1.188529
global_step: 32636, epoch: 16, loss: 1.244876
global_step: 32637, epoch: 16, loss: 1.137623
global_step: 32638, epoch: 16, loss: 1.324955
global_step: 32639, epoch: 16, loss: 1.275824
global_step: 32640, epoch: 16, loss: 1.004239
epoch: 16
train	acc: 0.5913	macro: p 0.3151, r 0.2803, f1: 0.2721	micro: p 0.5913, r 0.5913, f1 0.5913	weighted_f1:0.5214
dev	acc: 0.5329	macro: p 0.2885, r 0.2719, f1: 0.2454	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4469
test	acc: 0.5874	macro: p 0.3056, r 0.2803, f1: 0.2653	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5145
global_step: 32641, epoch: 17, loss: 1.341833
global_step: 32642, epoch: 17, loss: 1.203802
global_step: 32643, epoch: 17, loss: 1.293112
global_step: 32644, epoch: 17, loss: 1.266062
global_step: 32645, epoch: 17, loss: 1.240601
global_step: 32646, epoch: 17, loss: 1.263058
global_step: 32647, epoch: 17, loss: 1.316261
global_step: 32648, epoch: 17, loss: 1.186740
global_step: 32649, epoch: 17, loss: 1.233509
global_step: 32650, epoch: 17, loss: 1.159958
global_step: 32651, epoch: 17, loss: 1.238510
global_step: 32652, epoch: 17, loss: 1.203868
global_step: 32653, epoch: 17, loss: 1.212330
global_step: 32654, epoch: 17, loss: 1.280133
global_step: 32655, epoch: 17, loss: 1.262161
global_step: 32656, epoch: 17, loss: 1.199183
global_step: 32657, epoch: 17, loss: 1.208519
global_step: 32658, epoch: 17, loss: 1.305823
global_step: 32659, epoch: 17, loss: 1.243307
global_step: 32660, epoch: 17, loss: 1.195063
global_step: 32661, epoch: 17, loss: 1.176152
global_step: 32662, epoch: 17, loss: 1.125072
global_step: 32663, epoch: 17, loss: 1.354335
global_step: 32664, epoch: 17, loss: 1.278808
global_step: 32665, epoch: 17, loss: 1.198256
global_step: 32666, epoch: 17, loss: 1.280412
global_step: 32667, epoch: 17, loss: 1.261476
global_step: 32668, epoch: 17, loss: 1.259807
global_step: 32669, epoch: 17, loss: 1.194635
global_step: 32670, epoch: 17, loss: 1.247900
global_step: 32671, epoch: 17, loss: 1.290463
global_step: 32672, epoch: 17, loss: 1.350088
global_step: 32673, epoch: 17, loss: 1.224402
global_step: 32674, epoch: 17, loss: 1.251557
global_step: 32675, epoch: 17, loss: 1.156360
global_step: 32676, epoch: 17, loss: 1.184794
global_step: 32677, epoch: 17, loss: 1.326539
global_step: 32678, epoch: 17, loss: 1.237924
global_step: 32679, epoch: 17, loss: 1.214499
global_step: 32680, epoch: 17, loss: 1.110051
epoch: 17
train	acc: 0.5932	macro: p 0.3064, r 0.2829, f1: 0.2721	micro: p 0.5932, r 0.5932, f1 0.5932	weighted_f1:0.5225
dev	acc: 0.5347	macro: p 0.2821, r 0.2743, f1: 0.2467	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4482
test	acc: 0.5885	macro: p 0.2966, r 0.2836, f1: 0.2646	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5140
global_step: 32681, epoch: 18, loss: 1.288784
global_step: 32682, epoch: 18, loss: 1.246374
global_step: 32683, epoch: 18, loss: 1.199539
global_step: 32684, epoch: 18, loss: 1.209997
global_step: 32685, epoch: 18, loss: 1.131819
global_step: 32686, epoch: 18, loss: 1.210037
global_step: 32687, epoch: 18, loss: 1.273331
global_step: 32688, epoch: 18, loss: 1.222667
global_step: 32689, epoch: 18, loss: 1.236591
global_step: 32690, epoch: 18, loss: 1.154953
global_step: 32691, epoch: 18, loss: 1.201965
global_step: 32692, epoch: 18, loss: 1.271204
global_step: 32693, epoch: 18, loss: 1.172027
global_step: 32694, epoch: 18, loss: 1.267322
global_step: 32695, epoch: 18, loss: 1.340526
global_step: 32696, epoch: 18, loss: 1.249032
global_step: 32697, epoch: 18, loss: 1.192860
global_step: 32698, epoch: 18, loss: 1.214533
global_step: 32699, epoch: 18, loss: 1.187427
global_step: 32700, epoch: 18, loss: 1.246331
global_step: 32701, epoch: 18, loss: 1.257413
global_step: 32702, epoch: 18, loss: 1.301115
global_step: 32703, epoch: 18, loss: 1.299712
global_step: 32704, epoch: 18, loss: 1.217314
global_step: 32705, epoch: 18, loss: 1.169183
global_step: 32706, epoch: 18, loss: 1.221552
global_step: 32707, epoch: 18, loss: 1.278039
global_step: 32708, epoch: 18, loss: 1.098636
global_step: 32709, epoch: 18, loss: 1.380358
global_step: 32710, epoch: 18, loss: 1.239368
global_step: 32711, epoch: 18, loss: 1.230637
global_step: 32712, epoch: 18, loss: 1.168659
global_step: 32713, epoch: 18, loss: 1.093553
global_step: 32714, epoch: 18, loss: 1.369418
global_step: 32715, epoch: 18, loss: 1.179133
global_step: 32716, epoch: 18, loss: 1.294652
global_step: 32717, epoch: 18, loss: 1.288930
global_step: 32718, epoch: 18, loss: 1.305912
global_step: 32719, epoch: 18, loss: 1.213365
global_step: 32720, epoch: 18, loss: 1.553506
epoch: 18
train	acc: 0.5966	macro: p 0.3889, r 0.2990, f1: 0.2838	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5340
dev	acc: 0.5446	macro: p 0.2881, r 0.2942, f1: 0.2673	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4685
test	acc: 0.5881	macro: p 0.3566, r 0.2966, f1: 0.2750	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5230
New best model!
global_step: 32721, epoch: 19, loss: 1.200896
global_step: 32722, epoch: 19, loss: 1.176310
global_step: 32723, epoch: 19, loss: 1.257618
global_step: 32724, epoch: 19, loss: 1.250002
global_step: 32725, epoch: 19, loss: 1.214407
global_step: 32726, epoch: 19, loss: 1.164368
global_step: 32727, epoch: 19, loss: 1.279400
global_step: 32728, epoch: 19, loss: 1.262530
global_step: 32729, epoch: 19, loss: 1.070115
global_step: 32730, epoch: 19, loss: 1.163404
global_step: 32731, epoch: 19, loss: 1.359771
global_step: 32732, epoch: 19, loss: 1.248633
global_step: 32733, epoch: 19, loss: 1.223275
global_step: 32734, epoch: 19, loss: 1.176225
global_step: 32735, epoch: 19, loss: 1.259165
global_step: 32736, epoch: 19, loss: 1.243182
global_step: 32737, epoch: 19, loss: 1.263242
global_step: 32738, epoch: 19, loss: 1.245263
global_step: 32739, epoch: 19, loss: 1.233425
global_step: 32740, epoch: 19, loss: 1.181565
global_step: 32741, epoch: 19, loss: 1.223138
global_step: 32742, epoch: 19, loss: 1.248631
global_step: 32743, epoch: 19, loss: 1.218439
global_step: 32744, epoch: 19, loss: 1.285138
global_step: 32745, epoch: 19, loss: 1.222005
global_step: 32746, epoch: 19, loss: 1.249565
global_step: 32747, epoch: 19, loss: 1.187642
global_step: 32748, epoch: 19, loss: 1.210861
global_step: 32749, epoch: 19, loss: 1.155918
global_step: 32750, epoch: 19, loss: 1.114703
global_step: 32751, epoch: 19, loss: 1.212163
global_step: 32752, epoch: 19, loss: 1.172455
global_step: 32753, epoch: 19, loss: 1.262655
global_step: 32754, epoch: 19, loss: 1.225561
global_step: 32755, epoch: 19, loss: 1.228925
global_step: 32756, epoch: 19, loss: 1.371461
global_step: 32757, epoch: 19, loss: 1.218937
global_step: 32758, epoch: 19, loss: 1.139680
global_step: 32759, epoch: 19, loss: 1.331236
global_step: 32760, epoch: 19, loss: 1.524686
epoch: 19
train	acc: 0.6006	macro: p 0.4194, r 0.2924, f1: 0.2871	micro: p 0.6006, r 0.6006, f1 0.6006	weighted_f1:0.5355
dev	acc: 0.5410	macro: p 0.2867, r 0.2811, f1: 0.2594	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4614
test	acc: 0.5966	macro: p 0.3996, r 0.2929, f1: 0.2819	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5298
global_step: 32761, epoch: 20, loss: 1.426907
global_step: 32762, epoch: 20, loss: 1.173039
global_step: 32763, epoch: 20, loss: 1.172216
global_step: 32764, epoch: 20, loss: 1.167048
global_step: 32765, epoch: 20, loss: 1.149871
global_step: 32766, epoch: 20, loss: 1.198290
global_step: 32767, epoch: 20, loss: 1.152310
global_step: 32768, epoch: 20, loss: 1.108184
global_step: 32769, epoch: 20, loss: 1.295293
global_step: 32770, epoch: 20, loss: 1.272673
global_step: 32771, epoch: 20, loss: 1.210119
global_step: 32772, epoch: 20, loss: 1.210176
global_step: 32773, epoch: 20, loss: 1.161691
global_step: 32774, epoch: 20, loss: 1.185456
global_step: 32775, epoch: 20, loss: 1.375338
global_step: 32776, epoch: 20, loss: 1.203946
global_step: 32777, epoch: 20, loss: 1.210288
global_step: 32778, epoch: 20, loss: 1.300078
global_step: 32779, epoch: 20, loss: 1.187769
global_step: 32780, epoch: 20, loss: 1.356090
global_step: 32781, epoch: 20, loss: 1.238826
global_step: 32782, epoch: 20, loss: 1.139429
global_step: 32783, epoch: 20, loss: 1.141812
global_step: 32784, epoch: 20, loss: 1.198062
global_step: 32785, epoch: 20, loss: 1.144137
global_step: 32786, epoch: 20, loss: 1.222396
global_step: 32787, epoch: 20, loss: 1.367864
global_step: 32788, epoch: 20, loss: 1.159590
global_step: 32789, epoch: 20, loss: 1.112572
global_step: 32790, epoch: 20, loss: 1.217495
global_step: 32791, epoch: 20, loss: 1.255606
global_step: 32792, epoch: 20, loss: 1.195172
global_step: 32793, epoch: 20, loss: 1.180203
global_step: 32794, epoch: 20, loss: 1.219672
global_step: 32795, epoch: 20, loss: 1.256335
global_step: 32796, epoch: 20, loss: 1.221400
global_step: 32797, epoch: 20, loss: 1.153171
global_step: 32798, epoch: 20, loss: 1.211786
global_step: 32799, epoch: 20, loss: 1.218163
global_step: 32800, epoch: 20, loss: 1.337473
epoch: 20
train	acc: 0.6036	macro: p 0.4286, r 0.2992, f1: 0.2901	micro: p 0.6036, r 0.6036, f1 0.6036	weighted_f1:0.5402
dev	acc: 0.5374	macro: p 0.2785, r 0.2810, f1: 0.2540	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4569
test	acc: 0.5946	macro: p 0.4062, r 0.2950, f1: 0.2794	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5282
global_step: 32801, epoch: 21, loss: 1.241095
global_step: 32802, epoch: 21, loss: 1.159710
global_step: 32803, epoch: 21, loss: 1.233767
global_step: 32804, epoch: 21, loss: 1.120536
global_step: 32805, epoch: 21, loss: 1.161048
global_step: 32806, epoch: 21, loss: 1.278191
global_step: 32807, epoch: 21, loss: 1.199665
global_step: 32808, epoch: 21, loss: 1.142853
global_step: 32809, epoch: 21, loss: 1.266940
global_step: 32810, epoch: 21, loss: 1.202377
global_step: 32811, epoch: 21, loss: 1.261512
global_step: 32812, epoch: 21, loss: 1.168238
global_step: 32813, epoch: 21, loss: 1.135134
global_step: 32814, epoch: 21, loss: 1.200891
global_step: 32815, epoch: 21, loss: 1.223992
global_step: 32816, epoch: 21, loss: 1.255034
global_step: 32817, epoch: 21, loss: 1.216140
global_step: 32818, epoch: 21, loss: 1.127504
global_step: 32819, epoch: 21, loss: 1.188917
global_step: 32820, epoch: 21, loss: 1.220936
global_step: 32821, epoch: 21, loss: 1.222905
global_step: 32822, epoch: 21, loss: 1.258783
global_step: 32823, epoch: 21, loss: 1.191987
global_step: 32824, epoch: 21, loss: 1.268088
global_step: 32825, epoch: 21, loss: 1.149113
global_step: 32826, epoch: 21, loss: 1.271365
global_step: 32827, epoch: 21, loss: 1.203592
global_step: 32828, epoch: 21, loss: 1.135825
global_step: 32829, epoch: 21, loss: 1.254455
global_step: 32830, epoch: 21, loss: 1.194083
global_step: 32831, epoch: 21, loss: 1.181109
global_step: 32832, epoch: 21, loss: 1.204525
global_step: 32833, epoch: 21, loss: 1.134945
global_step: 32834, epoch: 21, loss: 1.257005
global_step: 32835, epoch: 21, loss: 1.241495
global_step: 32836, epoch: 21, loss: 1.238584
global_step: 32837, epoch: 21, loss: 1.241029
global_step: 32838, epoch: 21, loss: 1.167930
global_step: 32839, epoch: 21, loss: 1.167745
global_step: 32840, epoch: 21, loss: 1.128633
epoch: 21
train	acc: 0.6064	macro: p 0.4289, r 0.2998, f1: 0.2946	micro: p 0.6064, r 0.6064, f1 0.6064	weighted_f1:0.5436
dev	acc: 0.5410	macro: p 0.2919, r 0.2838, f1: 0.2586	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4613
test	acc: 0.6000	macro: p 0.4273, r 0.2986, f1: 0.2877	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5357
global_step: 32841, epoch: 22, loss: 1.210211
global_step: 32842, epoch: 22, loss: 1.224905
global_step: 32843, epoch: 22, loss: 1.101306
global_step: 32844, epoch: 22, loss: 1.208821
global_step: 32845, epoch: 22, loss: 1.218365
global_step: 32846, epoch: 22, loss: 1.087602
global_step: 32847, epoch: 22, loss: 1.180201
global_step: 32848, epoch: 22, loss: 1.212371
global_step: 32849, epoch: 22, loss: 1.183069
global_step: 32850, epoch: 22, loss: 1.207310
global_step: 32851, epoch: 22, loss: 1.256838
global_step: 32852, epoch: 22, loss: 1.147858
global_step: 32853, epoch: 22, loss: 1.131120
global_step: 32854, epoch: 22, loss: 1.144230
global_step: 32855, epoch: 22, loss: 1.192512
global_step: 32856, epoch: 22, loss: 1.247871
global_step: 32857, epoch: 22, loss: 1.167464
global_step: 32858, epoch: 22, loss: 1.168813
global_step: 32859, epoch: 22, loss: 1.163664
global_step: 32860, epoch: 22, loss: 1.146922
global_step: 32861, epoch: 22, loss: 1.188922
global_step: 32862, epoch: 22, loss: 1.109818
global_step: 32863, epoch: 22, loss: 1.243792
global_step: 32864, epoch: 22, loss: 1.222312
global_step: 32865, epoch: 22, loss: 1.292678
global_step: 32866, epoch: 22, loss: 1.216605
global_step: 32867, epoch: 22, loss: 1.231856
global_step: 32868, epoch: 22, loss: 1.243811
global_step: 32869, epoch: 22, loss: 1.269272
global_step: 32870, epoch: 22, loss: 1.289953
global_step: 32871, epoch: 22, loss: 1.188101
global_step: 32872, epoch: 22, loss: 1.263992
global_step: 32873, epoch: 22, loss: 1.114646
global_step: 32874, epoch: 22, loss: 1.130373
global_step: 32875, epoch: 22, loss: 1.373246
global_step: 32876, epoch: 22, loss: 1.133829
global_step: 32877, epoch: 22, loss: 1.188867
global_step: 32878, epoch: 22, loss: 1.277382
global_step: 32879, epoch: 22, loss: 1.105303
global_step: 32880, epoch: 22, loss: 0.893579
epoch: 22
train	acc: 0.6071	macro: p 0.3903, r 0.2998, f1: 0.2987	micro: p 0.6071, r 0.6071, f1 0.6071	weighted_f1:0.5442
dev	acc: 0.5383	macro: p 0.2759, r 0.2764, f1: 0.2623	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4618
test	acc: 0.6031	macro: p 0.4491, r 0.2959, f1: 0.2916	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5381
global_step: 32881, epoch: 23, loss: 1.270245
global_step: 32882, epoch: 23, loss: 1.328848
global_step: 32883, epoch: 23, loss: 1.157710
global_step: 32884, epoch: 23, loss: 1.195071
global_step: 32885, epoch: 23, loss: 1.101848
global_step: 32886, epoch: 23, loss: 1.203345
global_step: 32887, epoch: 23, loss: 1.204223
global_step: 32888, epoch: 23, loss: 1.129182
global_step: 32889, epoch: 23, loss: 1.197266
global_step: 32890, epoch: 23, loss: 1.101493
global_step: 32891, epoch: 23, loss: 1.228794
global_step: 32892, epoch: 23, loss: 1.328410
global_step: 32893, epoch: 23, loss: 1.133322
global_step: 32894, epoch: 23, loss: 1.094387
global_step: 32895, epoch: 23, loss: 1.158553
global_step: 32896, epoch: 23, loss: 1.166152
global_step: 32897, epoch: 23, loss: 1.361945
global_step: 32898, epoch: 23, loss: 1.161222
global_step: 32899, epoch: 23, loss: 1.164343
global_step: 32900, epoch: 23, loss: 1.153543
global_step: 32901, epoch: 23, loss: 1.164540
global_step: 32902, epoch: 23, loss: 1.131757
global_step: 32903, epoch: 23, loss: 1.191967
global_step: 32904, epoch: 23, loss: 1.249672
global_step: 32905, epoch: 23, loss: 1.030897
global_step: 32906, epoch: 23, loss: 1.146534
global_step: 32907, epoch: 23, loss: 1.249900
global_step: 32908, epoch: 23, loss: 1.202163
global_step: 32909, epoch: 23, loss: 1.256478
global_step: 32910, epoch: 23, loss: 1.164457
global_step: 32911, epoch: 23, loss: 1.130238
global_step: 32912, epoch: 23, loss: 1.209953
global_step: 32913, epoch: 23, loss: 1.212077
global_step: 32914, epoch: 23, loss: 1.130949
global_step: 32915, epoch: 23, loss: 1.161105
global_step: 32916, epoch: 23, loss: 1.260759
global_step: 32917, epoch: 23, loss: 1.212618
global_step: 32918, epoch: 23, loss: 1.200391
global_step: 32919, epoch: 23, loss: 1.211454
global_step: 32920, epoch: 23, loss: 1.520495
epoch: 23
train	acc: 0.6182	macro: p 0.4289, r 0.3158, f1: 0.3148	micro: p 0.6182, r 0.6182, f1 0.6182	weighted_f1:0.5604
dev	acc: 0.5509	macro: p 0.3588, r 0.2937, f1: 0.2776	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4781
test	acc: 0.6077	macro: p 0.4256, r 0.3083, f1: 0.3015	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5469
New best model!
global_step: 32921, epoch: 24, loss: 1.107275
global_step: 32922, epoch: 24, loss: 1.147662
global_step: 32923, epoch: 24, loss: 1.162623
global_step: 32924, epoch: 24, loss: 1.198684
global_step: 32925, epoch: 24, loss: 1.227877
global_step: 32926, epoch: 24, loss: 1.255502
global_step: 32927, epoch: 24, loss: 1.144523
global_step: 32928, epoch: 24, loss: 1.191509
global_step: 32929, epoch: 24, loss: 1.170360
global_step: 32930, epoch: 24, loss: 1.283795
global_step: 32931, epoch: 24, loss: 1.187504
global_step: 32932, epoch: 24, loss: 1.182159
global_step: 32933, epoch: 24, loss: 1.199007
global_step: 32934, epoch: 24, loss: 1.197052
global_step: 32935, epoch: 24, loss: 1.228833
global_step: 32936, epoch: 24, loss: 1.141862
global_step: 32937, epoch: 24, loss: 1.222837
global_step: 32938, epoch: 24, loss: 1.264228
global_step: 32939, epoch: 24, loss: 1.335093
global_step: 32940, epoch: 24, loss: 1.079576
global_step: 32941, epoch: 24, loss: 1.050503
global_step: 32942, epoch: 24, loss: 1.212592
global_step: 32943, epoch: 24, loss: 1.210672
global_step: 32944, epoch: 24, loss: 1.115428
global_step: 32945, epoch: 24, loss: 1.159078
global_step: 32946, epoch: 24, loss: 1.140549
global_step: 32947, epoch: 24, loss: 1.175281
global_step: 32948, epoch: 24, loss: 1.222747
global_step: 32949, epoch: 24, loss: 1.198772
global_step: 32950, epoch: 24, loss: 1.102459
global_step: 32951, epoch: 24, loss: 1.187479
global_step: 32952, epoch: 24, loss: 1.099977
global_step: 32953, epoch: 24, loss: 1.175261
global_step: 32954, epoch: 24, loss: 1.159651
global_step: 32955, epoch: 24, loss: 1.141586
global_step: 32956, epoch: 24, loss: 1.141481
global_step: 32957, epoch: 24, loss: 1.165216
global_step: 32958, epoch: 24, loss: 1.145496
global_step: 32959, epoch: 24, loss: 1.120145
global_step: 32960, epoch: 24, loss: 1.001718
epoch: 24
train	acc: 0.6163	macro: p 0.4201, r 0.3123, f1: 0.3115	micro: p 0.6163, r 0.6163, f1 0.6163	weighted_f1:0.5568
dev	acc: 0.5518	macro: p 0.3816, r 0.2932, f1: 0.2776	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4776
test	acc: 0.6050	macro: p 0.4209, r 0.3041, f1: 0.2972	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5424
global_step: 32961, epoch: 25, loss: 1.090307
global_step: 32962, epoch: 25, loss: 1.123949
global_step: 32963, epoch: 25, loss: 1.302526
global_step: 32964, epoch: 25, loss: 1.215265
global_step: 32965, epoch: 25, loss: 1.136662
global_step: 32966, epoch: 25, loss: 1.093985
global_step: 32967, epoch: 25, loss: 1.120984
global_step: 32968, epoch: 25, loss: 1.180230
global_step: 32969, epoch: 25, loss: 1.052047
global_step: 32970, epoch: 25, loss: 1.226462
global_step: 32971, epoch: 25, loss: 1.161301
global_step: 32972, epoch: 25, loss: 1.127672
global_step: 32973, epoch: 25, loss: 1.078384
global_step: 32974, epoch: 25, loss: 1.154696
global_step: 32975, epoch: 25, loss: 1.187664
global_step: 32976, epoch: 25, loss: 1.031516
global_step: 32977, epoch: 25, loss: 1.151187
global_step: 32978, epoch: 25, loss: 1.180932
global_step: 32979, epoch: 25, loss: 1.268257
global_step: 32980, epoch: 25, loss: 1.211813
global_step: 32981, epoch: 25, loss: 1.173158
global_step: 32982, epoch: 25, loss: 1.224115
global_step: 32983, epoch: 25, loss: 1.253679
global_step: 32984, epoch: 25, loss: 1.157892
global_step: 32985, epoch: 25, loss: 1.214076
global_step: 32986, epoch: 25, loss: 1.200714
global_step: 32987, epoch: 25, loss: 1.140289
global_step: 32988, epoch: 25, loss: 1.147831
global_step: 32989, epoch: 25, loss: 1.221501
global_step: 32990, epoch: 25, loss: 1.120916
global_step: 32991, epoch: 25, loss: 1.088238
global_step: 32992, epoch: 25, loss: 1.232764
global_step: 32993, epoch: 25, loss: 1.177382
global_step: 32994, epoch: 25, loss: 1.146151
global_step: 32995, epoch: 25, loss: 1.195988
global_step: 32996, epoch: 25, loss: 1.211699
global_step: 32997, epoch: 25, loss: 1.187773
global_step: 32998, epoch: 25, loss: 1.102224
global_step: 32999, epoch: 25, loss: 1.138358
global_step: 33000, epoch: 25, loss: 1.481685
epoch: 25
train	acc: 0.6182	macro: p 0.4064, r 0.3149, f1: 0.3162	micro: p 0.6182, r 0.6182, f1 0.6182	weighted_f1:0.5601
dev	acc: 0.5518	macro: p 0.3573, r 0.2930, f1: 0.2813	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4805
test	acc: 0.6061	macro: p 0.4042, r 0.3041, f1: 0.3001	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5450
New best model!
global_step: 33001, epoch: 26, loss: 1.194797
global_step: 33002, epoch: 26, loss: 1.138613
global_step: 33003, epoch: 26, loss: 1.140383
global_step: 33004, epoch: 26, loss: 1.220728
global_step: 33005, epoch: 26, loss: 1.187079
global_step: 33006, epoch: 26, loss: 1.117170
global_step: 33007, epoch: 26, loss: 1.165968
global_step: 33008, epoch: 26, loss: 1.089346
global_step: 33009, epoch: 26, loss: 1.179989
global_step: 33010, epoch: 26, loss: 1.262530
global_step: 33011, epoch: 26, loss: 1.063299
global_step: 33012, epoch: 26, loss: 1.128150
global_step: 33013, epoch: 26, loss: 1.226791
global_step: 33014, epoch: 26, loss: 1.196139
global_step: 33015, epoch: 26, loss: 1.224679
global_step: 33016, epoch: 26, loss: 1.072233
global_step: 33017, epoch: 26, loss: 1.224034
global_step: 33018, epoch: 26, loss: 1.062593
global_step: 33019, epoch: 26, loss: 1.217478
global_step: 33020, epoch: 26, loss: 1.091674
global_step: 33021, epoch: 26, loss: 1.141152
global_step: 33022, epoch: 26, loss: 1.177605
global_step: 33023, epoch: 26, loss: 1.100426
global_step: 33024, epoch: 26, loss: 1.143045
global_step: 33025, epoch: 26, loss: 1.250227
global_step: 33026, epoch: 26, loss: 1.206523
global_step: 33027, epoch: 26, loss: 1.171805
global_step: 33028, epoch: 26, loss: 1.280243
global_step: 33029, epoch: 26, loss: 1.055613
global_step: 33030, epoch: 26, loss: 1.131492
global_step: 33031, epoch: 26, loss: 1.203238
global_step: 33032, epoch: 26, loss: 1.058961
global_step: 33033, epoch: 26, loss: 1.202458
global_step: 33034, epoch: 26, loss: 1.099741
global_step: 33035, epoch: 26, loss: 1.033586
global_step: 33036, epoch: 26, loss: 1.226548
global_step: 33037, epoch: 26, loss: 1.219068
global_step: 33038, epoch: 26, loss: 1.208158
global_step: 33039, epoch: 26, loss: 1.141674
global_step: 33040, epoch: 26, loss: 1.016402
epoch: 26
train	acc: 0.6236	macro: p 0.4040, r 0.3271, f1: 0.3283	micro: p 0.6236, r 0.6236, f1 0.6236	weighted_f1:0.5719
dev	acc: 0.5518	macro: p 0.3625, r 0.3000, f1: 0.2796	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4820
test	acc: 0.6011	macro: p 0.3931, r 0.3137, f1: 0.3089	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5489
New best model!
global_step: 33041, epoch: 27, loss: 1.161923
global_step: 33042, epoch: 27, loss: 1.244411
global_step: 33043, epoch: 27, loss: 1.153812
global_step: 33044, epoch: 27, loss: 1.175935
global_step: 33045, epoch: 27, loss: 1.188561
global_step: 33046, epoch: 27, loss: 1.136804
global_step: 33047, epoch: 27, loss: 1.162845
global_step: 33048, epoch: 27, loss: 1.216120
global_step: 33049, epoch: 27, loss: 1.164213
global_step: 33050, epoch: 27, loss: 1.133458
global_step: 33051, epoch: 27, loss: 1.205465
global_step: 33052, epoch: 27, loss: 1.228829
global_step: 33053, epoch: 27, loss: 1.150298
global_step: 33054, epoch: 27, loss: 1.089061
global_step: 33055, epoch: 27, loss: 1.181285
global_step: 33056, epoch: 27, loss: 1.071454
global_step: 33057, epoch: 27, loss: 1.149144
global_step: 33058, epoch: 27, loss: 1.180170
global_step: 33059, epoch: 27, loss: 1.132678
global_step: 33060, epoch: 27, loss: 1.127928
global_step: 33061, epoch: 27, loss: 1.130360
global_step: 33062, epoch: 27, loss: 1.024906
global_step: 33063, epoch: 27, loss: 1.220300
global_step: 33064, epoch: 27, loss: 1.142212
global_step: 33065, epoch: 27, loss: 1.152188
global_step: 33066, epoch: 27, loss: 1.113620
global_step: 33067, epoch: 27, loss: 1.156216
global_step: 33068, epoch: 27, loss: 1.092225
global_step: 33069, epoch: 27, loss: 1.085521
global_step: 33070, epoch: 27, loss: 1.209228
global_step: 33071, epoch: 27, loss: 1.125561
global_step: 33072, epoch: 27, loss: 1.305357
global_step: 33073, epoch: 27, loss: 1.271712
global_step: 33074, epoch: 27, loss: 1.098453
global_step: 33075, epoch: 27, loss: 1.170247
global_step: 33076, epoch: 27, loss: 1.150808
global_step: 33077, epoch: 27, loss: 1.090885
global_step: 33078, epoch: 27, loss: 1.085547
global_step: 33079, epoch: 27, loss: 1.070158
global_step: 33080, epoch: 27, loss: 2.186025
epoch: 27
train	acc: 0.6338	macro: p 0.4074, r 0.3396, f1: 0.3442	micro: p 0.6338, r 0.6338, f1 0.6338	weighted_f1:0.5855
dev	acc: 0.5600	macro: p 0.3522, r 0.3065, f1: 0.2937	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.4947
test	acc: 0.6115	macro: p 0.3834, r 0.3215, f1: 0.3202	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5607
New best model!
global_step: 33081, epoch: 28, loss: 1.165388
global_step: 33082, epoch: 28, loss: 1.171580
global_step: 33083, epoch: 28, loss: 1.266956
global_step: 33084, epoch: 28, loss: 1.048204
global_step: 33085, epoch: 28, loss: 1.096406
global_step: 33086, epoch: 28, loss: 1.134233
global_step: 33087, epoch: 28, loss: 1.144464
global_step: 33088, epoch: 28, loss: 1.080207
global_step: 33089, epoch: 28, loss: 1.163252
global_step: 33090, epoch: 28, loss: 1.069780
global_step: 33091, epoch: 28, loss: 1.279525
global_step: 33092, epoch: 28, loss: 1.233728
global_step: 33093, epoch: 28, loss: 1.179142
global_step: 33094, epoch: 28, loss: 1.224611
global_step: 33095, epoch: 28, loss: 1.209955
global_step: 33096, epoch: 28, loss: 1.117559
global_step: 33097, epoch: 28, loss: 1.061824
global_step: 33098, epoch: 28, loss: 1.192171
global_step: 33099, epoch: 28, loss: 1.115443
global_step: 33100, epoch: 28, loss: 1.122028
global_step: 33101, epoch: 28, loss: 1.175657
global_step: 33102, epoch: 28, loss: 1.084116
global_step: 33103, epoch: 28, loss: 1.114687
global_step: 33104, epoch: 28, loss: 1.090616
global_step: 33105, epoch: 28, loss: 1.076935
global_step: 33106, epoch: 28, loss: 1.116778
global_step: 33107, epoch: 28, loss: 1.147444
global_step: 33108, epoch: 28, loss: 1.192920
global_step: 33109, epoch: 28, loss: 1.069716
global_step: 33110, epoch: 28, loss: 1.149957
global_step: 33111, epoch: 28, loss: 1.131022
global_step: 33112, epoch: 28, loss: 1.186547
global_step: 33113, epoch: 28, loss: 1.142994
global_step: 33114, epoch: 28, loss: 1.178762
global_step: 33115, epoch: 28, loss: 1.156824
global_step: 33116, epoch: 28, loss: 1.160091
global_step: 33117, epoch: 28, loss: 1.006336
global_step: 33118, epoch: 28, loss: 1.233401
global_step: 33119, epoch: 28, loss: 1.187177
global_step: 33120, epoch: 28, loss: 1.362093
epoch: 28
train	acc: 0.6363	macro: p 0.3979, r 0.3562, f1: 0.3566	micro: p 0.6363, r 0.6363, f1 0.6363	weighted_f1:0.5967
dev	acc: 0.5555	macro: p 0.3430, r 0.3186, f1: 0.3051	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5035
test	acc: 0.6015	macro: p 0.3665, r 0.3314, f1: 0.3252	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5606
New best model!
global_step: 33121, epoch: 29, loss: 1.232142
global_step: 33122, epoch: 29, loss: 1.218002
global_step: 33123, epoch: 29, loss: 1.094454
global_step: 33124, epoch: 29, loss: 1.136789
global_step: 33125, epoch: 29, loss: 1.074625
global_step: 33126, epoch: 29, loss: 1.125789
global_step: 33127, epoch: 29, loss: 1.136492
global_step: 33128, epoch: 29, loss: 1.178908
global_step: 33129, epoch: 29, loss: 1.260275
global_step: 33130, epoch: 29, loss: 1.200094
global_step: 33131, epoch: 29, loss: 1.093474
global_step: 33132, epoch: 29, loss: 1.084747
global_step: 33133, epoch: 29, loss: 1.143487
global_step: 33134, epoch: 29, loss: 1.126329
global_step: 33135, epoch: 29, loss: 1.070375
global_step: 33136, epoch: 29, loss: 1.147261
global_step: 33137, epoch: 29, loss: 1.211750
global_step: 33138, epoch: 29, loss: 1.132236
global_step: 33139, epoch: 29, loss: 1.095939
global_step: 33140, epoch: 29, loss: 1.062347
global_step: 33141, epoch: 29, loss: 1.052479
global_step: 33142, epoch: 29, loss: 1.099343
global_step: 33143, epoch: 29, loss: 1.052450
global_step: 33144, epoch: 29, loss: 1.114444
global_step: 33145, epoch: 29, loss: 1.129902
global_step: 33146, epoch: 29, loss: 1.142112
global_step: 33147, epoch: 29, loss: 1.135588
global_step: 33148, epoch: 29, loss: 1.130706
global_step: 33149, epoch: 29, loss: 1.123941
global_step: 33150, epoch: 29, loss: 1.153518
global_step: 33151, epoch: 29, loss: 1.037193
global_step: 33152, epoch: 29, loss: 1.196592
global_step: 33153, epoch: 29, loss: 1.071189
global_step: 33154, epoch: 29, loss: 1.143612
global_step: 33155, epoch: 29, loss: 1.175788
global_step: 33156, epoch: 29, loss: 1.100073
global_step: 33157, epoch: 29, loss: 1.256617
global_step: 33158, epoch: 29, loss: 1.121893
global_step: 33159, epoch: 29, loss: 1.164581
global_step: 33160, epoch: 29, loss: 0.557920
epoch: 29
train	acc: 0.6285	macro: p 0.4230, r 0.3232, f1: 0.3267	micro: p 0.6285, r 0.6285, f1 0.6285	weighted_f1:0.5714
dev	acc: 0.5446	macro: p 0.3479, r 0.2887, f1: 0.2715	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4709
test	acc: 0.6061	macro: p 0.4088, r 0.3062, f1: 0.3006	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5447
global_step: 33161, epoch: 30, loss: 1.043710
global_step: 33162, epoch: 30, loss: 1.055656
global_step: 33163, epoch: 30, loss: 1.111726
global_step: 33164, epoch: 30, loss: 1.159218
global_step: 33165, epoch: 30, loss: 1.243897
global_step: 33166, epoch: 30, loss: 1.080393
global_step: 33167, epoch: 30, loss: 1.159316
global_step: 33168, epoch: 30, loss: 1.197519
global_step: 33169, epoch: 30, loss: 1.062633
global_step: 33170, epoch: 30, loss: 1.107257
global_step: 33171, epoch: 30, loss: 1.081316
global_step: 33172, epoch: 30, loss: 1.137754
global_step: 33173, epoch: 30, loss: 1.188811
global_step: 33174, epoch: 30, loss: 1.163558
global_step: 33175, epoch: 30, loss: 1.175928
global_step: 33176, epoch: 30, loss: 1.287532
global_step: 33177, epoch: 30, loss: 1.151034
global_step: 33178, epoch: 30, loss: 1.130274
global_step: 33179, epoch: 30, loss: 1.089057
global_step: 33180, epoch: 30, loss: 1.053073
global_step: 33181, epoch: 30, loss: 1.070931
global_step: 33182, epoch: 30, loss: 1.004861
global_step: 33183, epoch: 30, loss: 1.076147
global_step: 33184, epoch: 30, loss: 1.083753
global_step: 33185, epoch: 30, loss: 1.126344
global_step: 33186, epoch: 30, loss: 1.062776
global_step: 33187, epoch: 30, loss: 1.194025
global_step: 33188, epoch: 30, loss: 1.238041
global_step: 33189, epoch: 30, loss: 1.144308
global_step: 33190, epoch: 30, loss: 1.101544
global_step: 33191, epoch: 30, loss: 1.233520
global_step: 33192, epoch: 30, loss: 1.142900
global_step: 33193, epoch: 30, loss: 1.204965
global_step: 33194, epoch: 30, loss: 1.053046
global_step: 33195, epoch: 30, loss: 1.210564
global_step: 33196, epoch: 30, loss: 1.101786
global_step: 33197, epoch: 30, loss: 1.044786
global_step: 33198, epoch: 30, loss: 1.107362
global_step: 33199, epoch: 30, loss: 1.017218
global_step: 33200, epoch: 30, loss: 0.379332
epoch: 30
train	acc: 0.6267	macro: p 0.4147, r 0.3207, f1: 0.3225	micro: p 0.6267, r 0.6267, f1 0.6267	weighted_f1:0.5676
dev	acc: 0.5573	macro: p 0.3711, r 0.2976, f1: 0.2838	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4831
test	acc: 0.6065	macro: p 0.4005, r 0.3031, f1: 0.2964	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5417
global_step: 33201, epoch: 31, loss: 1.245289
global_step: 33202, epoch: 31, loss: 1.081527
global_step: 33203, epoch: 31, loss: 1.086078
global_step: 33204, epoch: 31, loss: 1.085256
global_step: 33205, epoch: 31, loss: 1.164978
global_step: 33206, epoch: 31, loss: 1.266502
global_step: 33207, epoch: 31, loss: 1.084020
global_step: 33208, epoch: 31, loss: 1.103839
global_step: 33209, epoch: 31, loss: 1.125509
global_step: 33210, epoch: 31, loss: 1.128753
global_step: 33211, epoch: 31, loss: 1.099849
global_step: 33212, epoch: 31, loss: 1.119899
global_step: 33213, epoch: 31, loss: 1.078806
global_step: 33214, epoch: 31, loss: 1.240052
global_step: 33215, epoch: 31, loss: 1.093288
global_step: 33216, epoch: 31, loss: 1.075749
global_step: 33217, epoch: 31, loss: 0.992144
global_step: 33218, epoch: 31, loss: 1.273486
global_step: 33219, epoch: 31, loss: 1.052450
global_step: 33220, epoch: 31, loss: 1.108443
global_step: 33221, epoch: 31, loss: 1.160067
global_step: 33222, epoch: 31, loss: 1.074937
global_step: 33223, epoch: 31, loss: 1.011720
global_step: 33224, epoch: 31, loss: 1.200277
global_step: 33225, epoch: 31, loss: 1.138240
global_step: 33226, epoch: 31, loss: 1.061716
global_step: 33227, epoch: 31, loss: 1.028359
global_step: 33228, epoch: 31, loss: 1.139998
global_step: 33229, epoch: 31, loss: 1.159443
global_step: 33230, epoch: 31, loss: 1.095181
global_step: 33231, epoch: 31, loss: 1.120773
global_step: 33232, epoch: 31, loss: 1.192471
global_step: 33233, epoch: 31, loss: 1.116084
global_step: 33234, epoch: 31, loss: 1.190539
global_step: 33235, epoch: 31, loss: 1.066055
global_step: 33236, epoch: 31, loss: 1.083579
global_step: 33237, epoch: 31, loss: 1.165462
global_step: 33238, epoch: 31, loss: 1.181798
global_step: 33239, epoch: 31, loss: 1.101828
global_step: 33240, epoch: 31, loss: 0.905052
epoch: 31
train	acc: 0.6418	macro: p 0.4086, r 0.3459, f1: 0.3506	micro: p 0.6418, r 0.6418, f1 0.6418	weighted_f1:0.5926
dev	acc: 0.5636	macro: p 0.3764, r 0.3112, f1: 0.3023	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5005
test	acc: 0.6123	macro: p 0.3837, r 0.3204, f1: 0.3173	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5581
global_step: 33241, epoch: 32, loss: 1.084690
global_step: 33242, epoch: 32, loss: 1.124595
global_step: 33243, epoch: 32, loss: 1.063476
global_step: 33244, epoch: 32, loss: 1.119087
global_step: 33245, epoch: 32, loss: 1.267238
global_step: 33246, epoch: 32, loss: 1.156950
global_step: 33247, epoch: 32, loss: 1.097370
global_step: 33248, epoch: 32, loss: 1.187365
global_step: 33249, epoch: 32, loss: 1.153574
global_step: 33250, epoch: 32, loss: 1.040436
global_step: 33251, epoch: 32, loss: 1.040806
global_step: 33252, epoch: 32, loss: 1.083859
global_step: 33253, epoch: 32, loss: 1.200087
global_step: 33254, epoch: 32, loss: 1.105836
global_step: 33255, epoch: 32, loss: 1.158298
global_step: 33256, epoch: 32, loss: 1.045553
global_step: 33257, epoch: 32, loss: 1.173689
global_step: 33258, epoch: 32, loss: 1.111363
global_step: 33259, epoch: 32, loss: 1.235015
global_step: 33260, epoch: 32, loss: 1.105397
global_step: 33261, epoch: 32, loss: 1.106249
global_step: 33262, epoch: 32, loss: 1.181595
global_step: 33263, epoch: 32, loss: 1.104711
global_step: 33264, epoch: 32, loss: 1.091300
global_step: 33265, epoch: 32, loss: 1.006516
global_step: 33266, epoch: 32, loss: 1.121425
global_step: 33267, epoch: 32, loss: 1.043933
global_step: 33268, epoch: 32, loss: 1.147642
global_step: 33269, epoch: 32, loss: 1.095533
global_step: 33270, epoch: 32, loss: 1.132418
global_step: 33271, epoch: 32, loss: 1.226265
global_step: 33272, epoch: 32, loss: 1.106435
global_step: 33273, epoch: 32, loss: 1.115157
global_step: 33274, epoch: 32, loss: 0.969073
global_step: 33275, epoch: 32, loss: 1.132836
global_step: 33276, epoch: 32, loss: 1.039577
global_step: 33277, epoch: 32, loss: 1.129279
global_step: 33278, epoch: 32, loss: 1.008156
global_step: 33279, epoch: 32, loss: 1.037139
global_step: 33280, epoch: 32, loss: 0.369066
epoch: 32
train	acc: 0.6378	macro: p 0.4201, r 0.3364, f1: 0.3443	micro: p 0.6378, r 0.6378, f1 0.6378	weighted_f1:0.5857
dev	acc: 0.5618	macro: p 0.3699, r 0.3054, f1: 0.2990	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.4967
test	acc: 0.6146	macro: p 0.3967, r 0.3144, f1: 0.3148	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5571
global_step: 33281, epoch: 33, loss: 1.172423
global_step: 33282, epoch: 33, loss: 1.107533
global_step: 33283, epoch: 33, loss: 1.078252
global_step: 33284, epoch: 33, loss: 1.168082
global_step: 33285, epoch: 33, loss: 1.096163
global_step: 33286, epoch: 33, loss: 1.221432
global_step: 33287, epoch: 33, loss: 1.022973
global_step: 33288, epoch: 33, loss: 1.131474
global_step: 33289, epoch: 33, loss: 1.030330
global_step: 33290, epoch: 33, loss: 1.154880
global_step: 33291, epoch: 33, loss: 0.979427
global_step: 33292, epoch: 33, loss: 1.085209
global_step: 33293, epoch: 33, loss: 1.024019
global_step: 33294, epoch: 33, loss: 1.057002
global_step: 33295, epoch: 33, loss: 1.083607
global_step: 33296, epoch: 33, loss: 1.039665
global_step: 33297, epoch: 33, loss: 1.035617
global_step: 33298, epoch: 33, loss: 1.148502
global_step: 33299, epoch: 33, loss: 1.022655
global_step: 33300, epoch: 33, loss: 0.997283
global_step: 33301, epoch: 33, loss: 1.107704
global_step: 33302, epoch: 33, loss: 1.240568
global_step: 33303, epoch: 33, loss: 1.124968
global_step: 33304, epoch: 33, loss: 1.076248
global_step: 33305, epoch: 33, loss: 1.169490
global_step: 33306, epoch: 33, loss: 1.087029
global_step: 33307, epoch: 33, loss: 1.153962
global_step: 33308, epoch: 33, loss: 1.202920
global_step: 33309, epoch: 33, loss: 1.143097
global_step: 33310, epoch: 33, loss: 1.039347
global_step: 33311, epoch: 33, loss: 1.065880
global_step: 33312, epoch: 33, loss: 1.154589
global_step: 33313, epoch: 33, loss: 1.099155
global_step: 33314, epoch: 33, loss: 1.039983
global_step: 33315, epoch: 33, loss: 1.073127
global_step: 33316, epoch: 33, loss: 1.001451
global_step: 33317, epoch: 33, loss: 1.192687
global_step: 33318, epoch: 33, loss: 1.215820
global_step: 33319, epoch: 33, loss: 1.008912
global_step: 33320, epoch: 33, loss: 1.460684
epoch: 33
train	acc: 0.6560	macro: p 0.4065, r 0.3767, f1: 0.3774	micro: p 0.6560, r 0.6560, f1 0.6560	weighted_f1:0.6172
dev	acc: 0.5735	macro: p 0.3634, r 0.3320, f1: 0.3240	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5220
test	acc: 0.6046	macro: p 0.3534, r 0.3332, f1: 0.3280	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5640
New best model!
global_step: 33321, epoch: 34, loss: 1.139605
global_step: 33322, epoch: 34, loss: 1.057916
global_step: 33323, epoch: 34, loss: 1.116291
global_step: 33324, epoch: 34, loss: 1.096317
global_step: 33325, epoch: 34, loss: 1.117722
global_step: 33326, epoch: 34, loss: 1.049432
global_step: 33327, epoch: 34, loss: 1.217430
global_step: 33328, epoch: 34, loss: 0.996916
global_step: 33329, epoch: 34, loss: 1.049469
global_step: 33330, epoch: 34, loss: 1.139633
global_step: 33331, epoch: 34, loss: 1.121722
global_step: 33332, epoch: 34, loss: 1.072906
global_step: 33333, epoch: 34, loss: 1.054394
global_step: 33334, epoch: 34, loss: 1.082826
global_step: 33335, epoch: 34, loss: 1.127283
global_step: 33336, epoch: 34, loss: 0.988696
global_step: 33337, epoch: 34, loss: 1.019878
global_step: 33338, epoch: 34, loss: 1.038903
global_step: 33339, epoch: 34, loss: 1.125011
global_step: 33340, epoch: 34, loss: 1.034302
global_step: 33341, epoch: 34, loss: 1.097576
global_step: 33342, epoch: 34, loss: 1.148766
global_step: 33343, epoch: 34, loss: 1.023432
global_step: 33344, epoch: 34, loss: 1.121451
global_step: 33345, epoch: 34, loss: 1.097772
global_step: 33346, epoch: 34, loss: 1.204813
global_step: 33347, epoch: 34, loss: 1.077583
global_step: 33348, epoch: 34, loss: 1.179476
global_step: 33349, epoch: 34, loss: 1.206992
global_step: 33350, epoch: 34, loss: 1.064271
global_step: 33351, epoch: 34, loss: 1.204355
global_step: 33352, epoch: 34, loss: 1.094330
global_step: 33353, epoch: 34, loss: 1.023753
global_step: 33354, epoch: 34, loss: 0.971086
global_step: 33355, epoch: 34, loss: 1.165386
global_step: 33356, epoch: 34, loss: 1.083085
global_step: 33357, epoch: 34, loss: 1.087820
global_step: 33358, epoch: 34, loss: 1.022165
global_step: 33359, epoch: 34, loss: 1.041869
global_step: 33360, epoch: 34, loss: 0.477479
epoch: 34
train	acc: 0.6482	macro: p 0.4216, r 0.3526, f1: 0.3598	micro: p 0.6482, r 0.6482, f1 0.6482	weighted_f1:0.6012
dev	acc: 0.5600	macro: p 0.3815, r 0.3070, f1: 0.3019	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.4987
test	acc: 0.6169	macro: p 0.3863, r 0.3243, f1: 0.3262	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5660
global_step: 33361, epoch: 35, loss: 1.064647
global_step: 33362, epoch: 35, loss: 0.976017
global_step: 33363, epoch: 35, loss: 1.057338
global_step: 33364, epoch: 35, loss: 1.186159
global_step: 33365, epoch: 35, loss: 1.040863
global_step: 33366, epoch: 35, loss: 0.999258
global_step: 33367, epoch: 35, loss: 1.008824
global_step: 33368, epoch: 35, loss: 1.118983
global_step: 33369, epoch: 35, loss: 1.005416
global_step: 33370, epoch: 35, loss: 1.122659
global_step: 33371, epoch: 35, loss: 1.204807
global_step: 33372, epoch: 35, loss: 1.184946
global_step: 33373, epoch: 35, loss: 1.014001
global_step: 33374, epoch: 35, loss: 1.048789
global_step: 33375, epoch: 35, loss: 1.037366
global_step: 33376, epoch: 35, loss: 1.167122
global_step: 33377, epoch: 35, loss: 1.164318
global_step: 33378, epoch: 35, loss: 1.135226
global_step: 33379, epoch: 35, loss: 1.107426
global_step: 33380, epoch: 35, loss: 1.105363
global_step: 33381, epoch: 35, loss: 0.972459
global_step: 33382, epoch: 35, loss: 1.141345
global_step: 33383, epoch: 35, loss: 1.038236
global_step: 33384, epoch: 35, loss: 1.054977
global_step: 33385, epoch: 35, loss: 0.987651
global_step: 33386, epoch: 35, loss: 1.083640
global_step: 33387, epoch: 35, loss: 1.050568
global_step: 33388, epoch: 35, loss: 1.026737
global_step: 33389, epoch: 35, loss: 1.060272
global_step: 33390, epoch: 35, loss: 1.085562
global_step: 33391, epoch: 35, loss: 1.089957
global_step: 33392, epoch: 35, loss: 1.131356
global_step: 33393, epoch: 35, loss: 1.135398
global_step: 33394, epoch: 35, loss: 1.080906
global_step: 33395, epoch: 35, loss: 0.979483
global_step: 33396, epoch: 35, loss: 1.163157
global_step: 33397, epoch: 35, loss: 1.186645
global_step: 33398, epoch: 35, loss: 1.105574
global_step: 33399, epoch: 35, loss: 1.066417
global_step: 33400, epoch: 35, loss: 0.667735
epoch: 35
train	acc: 0.6502	macro: p 0.4253, r 0.3517, f1: 0.3576	micro: p 0.6502, r 0.6502, f1 0.6502	weighted_f1:0.6005
dev	acc: 0.5600	macro: p 0.3860, r 0.3088, f1: 0.3006	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.4974
test	acc: 0.6130	macro: p 0.3812, r 0.3197, f1: 0.3167	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5578
global_step: 33401, epoch: 36, loss: 1.244242
global_step: 33402, epoch: 36, loss: 1.044122
global_step: 33403, epoch: 36, loss: 1.062204
global_step: 33404, epoch: 36, loss: 1.091099
global_step: 33405, epoch: 36, loss: 1.015017
global_step: 33406, epoch: 36, loss: 1.015259
global_step: 33407, epoch: 36, loss: 1.039735
global_step: 33408, epoch: 36, loss: 1.048219
global_step: 33409, epoch: 36, loss: 1.099876
global_step: 33410, epoch: 36, loss: 1.121521
global_step: 33411, epoch: 36, loss: 1.033922
global_step: 33412, epoch: 36, loss: 1.089931
global_step: 33413, epoch: 36, loss: 1.042145
global_step: 33414, epoch: 36, loss: 1.143807
global_step: 33415, epoch: 36, loss: 1.027571
global_step: 33416, epoch: 36, loss: 1.091454
global_step: 33417, epoch: 36, loss: 0.959067
global_step: 33418, epoch: 36, loss: 1.048379
global_step: 33419, epoch: 36, loss: 1.021455
global_step: 33420, epoch: 36, loss: 1.135969
global_step: 33421, epoch: 36, loss: 1.039424
global_step: 33422, epoch: 36, loss: 1.008457
global_step: 33423, epoch: 36, loss: 0.953045
global_step: 33424, epoch: 36, loss: 1.047095
global_step: 33425, epoch: 36, loss: 1.078254
global_step: 33426, epoch: 36, loss: 1.092277
global_step: 33427, epoch: 36, loss: 1.019504
global_step: 33428, epoch: 36, loss: 1.109831
global_step: 33429, epoch: 36, loss: 1.060050
global_step: 33430, epoch: 36, loss: 1.118535
global_step: 33431, epoch: 36, loss: 1.181358
global_step: 33432, epoch: 36, loss: 1.127507
global_step: 33433, epoch: 36, loss: 1.226974
global_step: 33434, epoch: 36, loss: 1.143782
global_step: 33435, epoch: 36, loss: 1.010653
global_step: 33436, epoch: 36, loss: 1.050606
global_step: 33437, epoch: 36, loss: 1.109123
global_step: 33438, epoch: 36, loss: 0.980376
global_step: 33439, epoch: 36, loss: 1.045797
global_step: 33440, epoch: 36, loss: 0.725814
epoch: 36
train	acc: 0.6572	macro: p 0.4248, r 0.3623, f1: 0.3693	micro: p 0.6572, r 0.6572, f1 0.6572	weighted_f1:0.6114
dev	acc: 0.5681	macro: p 0.3987, r 0.3186, f1: 0.3131	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5094
test	acc: 0.6107	macro: p 0.3748, r 0.3228, f1: 0.3214	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5602
global_step: 33441, epoch: 37, loss: 1.021462
global_step: 33442, epoch: 37, loss: 1.092786
global_step: 33443, epoch: 37, loss: 0.973746
global_step: 33444, epoch: 37, loss: 1.058714
global_step: 33445, epoch: 37, loss: 1.080873
global_step: 33446, epoch: 37, loss: 1.014040
global_step: 33447, epoch: 37, loss: 1.080155
global_step: 33448, epoch: 37, loss: 1.042886
global_step: 33449, epoch: 37, loss: 1.072230
global_step: 33450, epoch: 37, loss: 1.125853
global_step: 33451, epoch: 37, loss: 1.147796
global_step: 33452, epoch: 37, loss: 1.024408
global_step: 33453, epoch: 37, loss: 1.153754
global_step: 33454, epoch: 37, loss: 1.023476
global_step: 33455, epoch: 37, loss: 1.069679
global_step: 33456, epoch: 37, loss: 1.046516
global_step: 33457, epoch: 37, loss: 1.140256
global_step: 33458, epoch: 37, loss: 1.115504
global_step: 33459, epoch: 37, loss: 1.148184
global_step: 33460, epoch: 37, loss: 1.102880
global_step: 33461, epoch: 37, loss: 1.062140
global_step: 33462, epoch: 37, loss: 1.084000
global_step: 33463, epoch: 37, loss: 1.001408
global_step: 33464, epoch: 37, loss: 1.094364
global_step: 33465, epoch: 37, loss: 1.075673
global_step: 33466, epoch: 37, loss: 1.091123
global_step: 33467, epoch: 37, loss: 1.132400
global_step: 33468, epoch: 37, loss: 1.179157
global_step: 33469, epoch: 37, loss: 1.024688
global_step: 33470, epoch: 37, loss: 0.993025
global_step: 33471, epoch: 37, loss: 1.031380
global_step: 33472, epoch: 37, loss: 1.044295
global_step: 33473, epoch: 37, loss: 1.128222
global_step: 33474, epoch: 37, loss: 1.038959
global_step: 33475, epoch: 37, loss: 1.033911
global_step: 33476, epoch: 37, loss: 1.102732
global_step: 33477, epoch: 37, loss: 1.049375
global_step: 33478, epoch: 37, loss: 0.976629
global_step: 33479, epoch: 37, loss: 1.027045
global_step: 33480, epoch: 37, loss: 0.505655
epoch: 37
train	acc: 0.6504	macro: p 0.4336, r 0.3489, f1: 0.3605	micro: p 0.6504, r 0.6504, f1 0.6504	weighted_f1:0.5997
dev	acc: 0.5636	macro: p 0.3848, r 0.3077, f1: 0.3033	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.4993
test	acc: 0.6134	macro: p 0.3755, r 0.3128, f1: 0.3136	micro: p 0.6134, r 0.6134, f1 0.6134	weighted_f1:0.5552
global_step: 33481, epoch: 38, loss: 1.085883
global_step: 33482, epoch: 38, loss: 0.953590
global_step: 33483, epoch: 38, loss: 1.068250
global_step: 33484, epoch: 38, loss: 1.076974
global_step: 33485, epoch: 38, loss: 1.063047
global_step: 33486, epoch: 38, loss: 0.974874
global_step: 33487, epoch: 38, loss: 1.022524
global_step: 33488, epoch: 38, loss: 0.923432
global_step: 33489, epoch: 38, loss: 1.058058
global_step: 33490, epoch: 38, loss: 1.146565
global_step: 33491, epoch: 38, loss: 1.122648
global_step: 33492, epoch: 38, loss: 1.037981
global_step: 33493, epoch: 38, loss: 1.126828
global_step: 33494, epoch: 38, loss: 0.968404
global_step: 33495, epoch: 38, loss: 1.044092
global_step: 33496, epoch: 38, loss: 1.010370
global_step: 33497, epoch: 38, loss: 1.075838
global_step: 33498, epoch: 38, loss: 1.118105
global_step: 33499, epoch: 38, loss: 0.899906
global_step: 33500, epoch: 38, loss: 1.041511
global_step: 33501, epoch: 38, loss: 1.010816
global_step: 33502, epoch: 38, loss: 1.135501
global_step: 33503, epoch: 38, loss: 1.040270
global_step: 33504, epoch: 38, loss: 1.200351
global_step: 33505, epoch: 38, loss: 1.096817
global_step: 33506, epoch: 38, loss: 1.073823
global_step: 33507, epoch: 38, loss: 1.064466
global_step: 33508, epoch: 38, loss: 0.981312
global_step: 33509, epoch: 38, loss: 1.020594
global_step: 33510, epoch: 38, loss: 1.100999
global_step: 33511, epoch: 38, loss: 1.092947
global_step: 33512, epoch: 38, loss: 1.055742
global_step: 33513, epoch: 38, loss: 0.997155
global_step: 33514, epoch: 38, loss: 1.058347
global_step: 33515, epoch: 38, loss: 1.138622
global_step: 33516, epoch: 38, loss: 1.092442
global_step: 33517, epoch: 38, loss: 1.029796
global_step: 33518, epoch: 38, loss: 1.097302
global_step: 33519, epoch: 38, loss: 1.088476
global_step: 33520, epoch: 38, loss: 0.396664
epoch: 38
train	acc: 0.6570	macro: p 0.4288, r 0.3601, f1: 0.3699	micro: p 0.6570, r 0.6570, f1 0.6570	weighted_f1:0.6110
dev	acc: 0.5645	macro: p 0.3840, r 0.3136, f1: 0.3097	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5060
test	acc: 0.6138	macro: p 0.3750, r 0.3214, f1: 0.3220	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5624
global_step: 33521, epoch: 39, loss: 1.018924
global_step: 33522, epoch: 39, loss: 1.049770
global_step: 33523, epoch: 39, loss: 1.081243
global_step: 33524, epoch: 39, loss: 0.978757
global_step: 33525, epoch: 39, loss: 1.086056
global_step: 33526, epoch: 39, loss: 1.040095
global_step: 33527, epoch: 39, loss: 1.027222
global_step: 33528, epoch: 39, loss: 1.084660
global_step: 33529, epoch: 39, loss: 0.988419
global_step: 33530, epoch: 39, loss: 1.018553
global_step: 33531, epoch: 39, loss: 1.117169
global_step: 33532, epoch: 39, loss: 1.050301
global_step: 33533, epoch: 39, loss: 1.082214
global_step: 33534, epoch: 39, loss: 1.049989
global_step: 33535, epoch: 39, loss: 1.058925
global_step: 33536, epoch: 39, loss: 0.988373
global_step: 33537, epoch: 39, loss: 1.067481
global_step: 33538, epoch: 39, loss: 1.114025
global_step: 33539, epoch: 39, loss: 1.063037
global_step: 33540, epoch: 39, loss: 1.025212
global_step: 33541, epoch: 39, loss: 1.227093
global_step: 33542, epoch: 39, loss: 1.004709
global_step: 33543, epoch: 39, loss: 1.098727
global_step: 33544, epoch: 39, loss: 1.032258
global_step: 33545, epoch: 39, loss: 0.913795
global_step: 33546, epoch: 39, loss: 0.996780
global_step: 33547, epoch: 39, loss: 1.056353
global_step: 33548, epoch: 39, loss: 1.020297
global_step: 33549, epoch: 39, loss: 1.068530
global_step: 33550, epoch: 39, loss: 1.158341
global_step: 33551, epoch: 39, loss: 1.011030
global_step: 33552, epoch: 39, loss: 1.129067
global_step: 33553, epoch: 39, loss: 1.083714
global_step: 33554, epoch: 39, loss: 1.050927
global_step: 33555, epoch: 39, loss: 0.919272
global_step: 33556, epoch: 39, loss: 0.964670
global_step: 33557, epoch: 39, loss: 1.047893
global_step: 33558, epoch: 39, loss: 1.001051
global_step: 33559, epoch: 39, loss: 1.114744
global_step: 33560, epoch: 39, loss: 1.402350
epoch: 39
train	acc: 0.6787	macro: p 0.4158, r 0.4150, f1: 0.4096	micro: p 0.6787, r 0.6787, f1 0.6787	weighted_f1:0.6502
dev	acc: 0.5627	macro: p 0.3411, r 0.3412, f1: 0.3308	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5252
test	acc: 0.5977	macro: p 0.3466, r 0.3473, f1: 0.3380	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5684
New best model!
global_step: 33561, epoch: 40, loss: 1.108208
global_step: 33562, epoch: 40, loss: 1.062523
global_step: 33563, epoch: 40, loss: 0.980052
global_step: 33564, epoch: 40, loss: 0.958774
global_step: 33565, epoch: 40, loss: 0.982996
global_step: 33566, epoch: 40, loss: 0.980238
global_step: 33567, epoch: 40, loss: 1.018666
global_step: 33568, epoch: 40, loss: 1.007745
global_step: 33569, epoch: 40, loss: 1.087023
global_step: 33570, epoch: 40, loss: 0.994152
global_step: 33571, epoch: 40, loss: 1.103192
global_step: 33572, epoch: 40, loss: 1.150902
global_step: 33573, epoch: 40, loss: 1.175391
global_step: 33574, epoch: 40, loss: 0.981040
global_step: 33575, epoch: 40, loss: 1.068022
global_step: 33576, epoch: 40, loss: 0.987753
global_step: 33577, epoch: 40, loss: 1.112842
global_step: 33578, epoch: 40, loss: 1.033113
global_step: 33579, epoch: 40, loss: 0.984925
global_step: 33580, epoch: 40, loss: 0.843021
global_step: 33581, epoch: 40, loss: 1.021258
global_step: 33582, epoch: 40, loss: 0.969315
global_step: 33583, epoch: 40, loss: 0.984913
global_step: 33584, epoch: 40, loss: 1.116055
global_step: 33585, epoch: 40, loss: 1.004613
global_step: 33586, epoch: 40, loss: 1.117401
global_step: 33587, epoch: 40, loss: 0.992886
global_step: 33588, epoch: 40, loss: 1.008680
global_step: 33589, epoch: 40, loss: 1.014598
global_step: 33590, epoch: 40, loss: 0.995829
global_step: 33591, epoch: 40, loss: 1.058146
global_step: 33592, epoch: 40, loss: 1.072410
global_step: 33593, epoch: 40, loss: 1.109526
global_step: 33594, epoch: 40, loss: 1.075782
global_step: 33595, epoch: 40, loss: 1.089928
global_step: 33596, epoch: 40, loss: 1.074793
global_step: 33597, epoch: 40, loss: 1.058343
global_step: 33598, epoch: 40, loss: 1.047191
global_step: 33599, epoch: 40, loss: 1.005911
global_step: 33600, epoch: 40, loss: 1.459010
epoch: 40
train	acc: 0.6744	macro: p 0.4276, r 0.3887, f1: 0.3961	micro: p 0.6744, r 0.6744, f1 0.6744	weighted_f1:0.6362
dev	acc: 0.5753	macro: p 0.3674, r 0.3321, f1: 0.3310	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5271
test	acc: 0.6138	macro: p 0.3612, r 0.3320, f1: 0.3322	micro: p 0.6138, r 0.6138, f1 0.6138	weighted_f1:0.5699
New best model!
global_step: 33601, epoch: 41, loss: 1.023884
global_step: 33602, epoch: 41, loss: 1.028106
global_step: 33603, epoch: 41, loss: 0.946999
global_step: 33604, epoch: 41, loss: 1.038864
global_step: 33605, epoch: 41, loss: 1.020254
global_step: 33606, epoch: 41, loss: 1.093144
global_step: 33607, epoch: 41, loss: 0.957078
global_step: 33608, epoch: 41, loss: 1.016772
global_step: 33609, epoch: 41, loss: 0.954358
global_step: 33610, epoch: 41, loss: 1.069113
global_step: 33611, epoch: 41, loss: 1.159686
global_step: 33612, epoch: 41, loss: 1.137050
global_step: 33613, epoch: 41, loss: 1.067218
global_step: 33614, epoch: 41, loss: 0.972191
global_step: 33615, epoch: 41, loss: 1.089604
global_step: 33616, epoch: 41, loss: 1.003994
global_step: 33617, epoch: 41, loss: 1.049366
global_step: 33618, epoch: 41, loss: 1.003789
global_step: 33619, epoch: 41, loss: 1.037221
global_step: 33620, epoch: 41, loss: 1.123756
global_step: 33621, epoch: 41, loss: 1.072641
global_step: 33622, epoch: 41, loss: 1.021642
global_step: 33623, epoch: 41, loss: 1.015264
global_step: 33624, epoch: 41, loss: 0.913827
global_step: 33625, epoch: 41, loss: 1.112514
global_step: 33626, epoch: 41, loss: 1.074973
global_step: 33627, epoch: 41, loss: 0.938165
global_step: 33628, epoch: 41, loss: 1.021958
global_step: 33629, epoch: 41, loss: 0.975426
global_step: 33630, epoch: 41, loss: 0.911058
global_step: 33631, epoch: 41, loss: 0.961228
global_step: 33632, epoch: 41, loss: 1.048394
global_step: 33633, epoch: 41, loss: 1.058080
global_step: 33634, epoch: 41, loss: 0.985598
global_step: 33635, epoch: 41, loss: 1.074198
global_step: 33636, epoch: 41, loss: 1.044368
global_step: 33637, epoch: 41, loss: 1.061331
global_step: 33638, epoch: 41, loss: 1.004183
global_step: 33639, epoch: 41, loss: 0.980111
global_step: 33640, epoch: 41, loss: 1.364076
epoch: 41
train	acc: 0.6824	macro: p 0.4319, r 0.4000, f1: 0.4056	micro: p 0.6824, r 0.6824, f1 0.6824	weighted_f1:0.6456
dev	acc: 0.5780	macro: p 0.3665, r 0.3360, f1: 0.3338	micro: p 0.5780, r 0.5780, f1 0.5780	weighted_f1:0.5302
test	acc: 0.6107	macro: p 0.3577, r 0.3335, f1: 0.3325	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5693
New best model!
global_step: 33641, epoch: 42, loss: 1.044881
global_step: 33642, epoch: 42, loss: 1.000709
global_step: 33643, epoch: 42, loss: 0.982114
global_step: 33644, epoch: 42, loss: 0.957631
global_step: 33645, epoch: 42, loss: 1.017586
global_step: 33646, epoch: 42, loss: 1.064921
global_step: 33647, epoch: 42, loss: 0.969204
global_step: 33648, epoch: 42, loss: 1.084334
global_step: 33649, epoch: 42, loss: 1.017934
global_step: 33650, epoch: 42, loss: 1.105895
global_step: 33651, epoch: 42, loss: 0.956968
global_step: 33652, epoch: 42, loss: 0.968311
global_step: 33653, epoch: 42, loss: 1.025475
global_step: 33654, epoch: 42, loss: 1.053325
global_step: 33655, epoch: 42, loss: 1.003957
global_step: 33656, epoch: 42, loss: 1.031857
global_step: 33657, epoch: 42, loss: 0.852993
global_step: 33658, epoch: 42, loss: 1.007212
global_step: 33659, epoch: 42, loss: 1.049740
global_step: 33660, epoch: 42, loss: 0.964993
global_step: 33661, epoch: 42, loss: 1.036498
global_step: 33662, epoch: 42, loss: 1.150904
global_step: 33663, epoch: 42, loss: 0.937406
global_step: 33664, epoch: 42, loss: 0.933075
global_step: 33665, epoch: 42, loss: 1.104280
global_step: 33666, epoch: 42, loss: 1.038528
global_step: 33667, epoch: 42, loss: 1.130108
global_step: 33668, epoch: 42, loss: 0.941543
global_step: 33669, epoch: 42, loss: 1.048794
global_step: 33670, epoch: 42, loss: 0.943458
global_step: 33671, epoch: 42, loss: 1.090349
global_step: 33672, epoch: 42, loss: 0.962413
global_step: 33673, epoch: 42, loss: 0.902599
global_step: 33674, epoch: 42, loss: 1.023405
global_step: 33675, epoch: 42, loss: 0.903470
global_step: 33676, epoch: 42, loss: 1.137677
global_step: 33677, epoch: 42, loss: 1.145325
global_step: 33678, epoch: 42, loss: 1.084441
global_step: 33679, epoch: 42, loss: 0.972340
global_step: 33680, epoch: 42, loss: 0.897751
epoch: 42
train	acc: 0.6836	macro: p 0.4371, r 0.3974, f1: 0.4025	micro: p 0.6836, r 0.6836, f1 0.6836	weighted_f1:0.6446
dev	acc: 0.5753	macro: p 0.3649, r 0.3332, f1: 0.3248	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5230
test	acc: 0.6100	macro: p 0.3589, r 0.3338, f1: 0.3289	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5658
global_step: 33681, epoch: 43, loss: 0.976250
global_step: 33682, epoch: 43, loss: 1.092864
global_step: 33683, epoch: 43, loss: 0.962921
global_step: 33684, epoch: 43, loss: 1.013700
global_step: 33685, epoch: 43, loss: 1.132242
global_step: 33686, epoch: 43, loss: 0.987460
global_step: 33687, epoch: 43, loss: 0.967830
global_step: 33688, epoch: 43, loss: 1.058156
global_step: 33689, epoch: 43, loss: 0.969474
global_step: 33690, epoch: 43, loss: 0.903120
global_step: 33691, epoch: 43, loss: 0.946276
global_step: 33692, epoch: 43, loss: 0.987943
global_step: 33693, epoch: 43, loss: 1.017831
global_step: 33694, epoch: 43, loss: 1.059677
global_step: 33695, epoch: 43, loss: 1.129182
global_step: 33696, epoch: 43, loss: 0.903406
global_step: 33697, epoch: 43, loss: 1.031090
global_step: 33698, epoch: 43, loss: 0.923257
global_step: 33699, epoch: 43, loss: 0.938484
global_step: 33700, epoch: 43, loss: 1.042889
global_step: 33701, epoch: 43, loss: 0.953566
global_step: 33702, epoch: 43, loss: 0.954983
global_step: 33703, epoch: 43, loss: 1.012905
global_step: 33704, epoch: 43, loss: 1.044089
global_step: 33705, epoch: 43, loss: 0.974304
global_step: 33706, epoch: 43, loss: 0.942413
global_step: 33707, epoch: 43, loss: 1.030185
global_step: 33708, epoch: 43, loss: 1.065905
global_step: 33709, epoch: 43, loss: 1.005763
global_step: 33710, epoch: 43, loss: 0.930873
global_step: 33711, epoch: 43, loss: 1.066220
global_step: 33712, epoch: 43, loss: 1.060068
global_step: 33713, epoch: 43, loss: 0.986892
global_step: 33714, epoch: 43, loss: 1.084761
global_step: 33715, epoch: 43, loss: 1.038260
global_step: 33716, epoch: 43, loss: 1.051924
global_step: 33717, epoch: 43, loss: 0.984081
global_step: 33718, epoch: 43, loss: 1.096455
global_step: 33719, epoch: 43, loss: 0.901077
global_step: 33720, epoch: 43, loss: 0.974277
epoch: 43
train	acc: 0.6854	macro: p 0.4427, r 0.3955, f1: 0.4030	micro: p 0.6854, r 0.6854, f1 0.6854	weighted_f1:0.6454
dev	acc: 0.5762	macro: p 0.3704, r 0.3309, f1: 0.3267	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5241
test	acc: 0.6146	macro: p 0.3678, r 0.3320, f1: 0.3311	micro: p 0.6146, r 0.6146, f1 0.6146	weighted_f1:0.5691
global_step: 33721, epoch: 44, loss: 0.975824
global_step: 33722, epoch: 44, loss: 0.948284
global_step: 33723, epoch: 44, loss: 1.063223
global_step: 33724, epoch: 44, loss: 0.984599
global_step: 33725, epoch: 44, loss: 1.027647
global_step: 33726, epoch: 44, loss: 0.971444
global_step: 33727, epoch: 44, loss: 0.955570
global_step: 33728, epoch: 44, loss: 1.015585
global_step: 33729, epoch: 44, loss: 1.045489
global_step: 33730, epoch: 44, loss: 1.008888
global_step: 33731, epoch: 44, loss: 0.977163
global_step: 33732, epoch: 44, loss: 1.078087
global_step: 33733, epoch: 44, loss: 1.105673
global_step: 33734, epoch: 44, loss: 0.932298
global_step: 33735, epoch: 44, loss: 0.969691
global_step: 33736, epoch: 44, loss: 1.046146
global_step: 33737, epoch: 44, loss: 0.979002
global_step: 33738, epoch: 44, loss: 1.039888
global_step: 33739, epoch: 44, loss: 1.015491
global_step: 33740, epoch: 44, loss: 1.062350
global_step: 33741, epoch: 44, loss: 1.066477
global_step: 33742, epoch: 44, loss: 1.058698
global_step: 33743, epoch: 44, loss: 1.071102
global_step: 33744, epoch: 44, loss: 0.900678
global_step: 33745, epoch: 44, loss: 1.019850
global_step: 33746, epoch: 44, loss: 0.975529
global_step: 33747, epoch: 44, loss: 1.030560
global_step: 33748, epoch: 44, loss: 0.980269
global_step: 33749, epoch: 44, loss: 0.914712
global_step: 33750, epoch: 44, loss: 0.866524
global_step: 33751, epoch: 44, loss: 0.974034
global_step: 33752, epoch: 44, loss: 0.980592
global_step: 33753, epoch: 44, loss: 1.188063
global_step: 33754, epoch: 44, loss: 1.053769
global_step: 33755, epoch: 44, loss: 0.925414
global_step: 33756, epoch: 44, loss: 1.070240
global_step: 33757, epoch: 44, loss: 0.996598
global_step: 33758, epoch: 44, loss: 1.010836
global_step: 33759, epoch: 44, loss: 0.897145
global_step: 33760, epoch: 44, loss: 1.034163
epoch: 44
train	acc: 0.6834	macro: p 0.4503, r 0.3883, f1: 0.3983	micro: p 0.6834, r 0.6834, f1 0.6834	weighted_f1:0.6390
dev	acc: 0.5735	macro: p 0.3981, r 0.3238, f1: 0.3218	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5157
test	acc: 0.6123	macro: p 0.3673, r 0.3218, f1: 0.3223	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5611
global_step: 33761, epoch: 45, loss: 1.048019
global_step: 33762, epoch: 45, loss: 1.001519
global_step: 33763, epoch: 45, loss: 1.054267
global_step: 33764, epoch: 45, loss: 1.027449
global_step: 33765, epoch: 45, loss: 0.904336
global_step: 33766, epoch: 45, loss: 1.044617
global_step: 33767, epoch: 45, loss: 0.920034
global_step: 33768, epoch: 45, loss: 0.809185
global_step: 33769, epoch: 45, loss: 1.055500
global_step: 33770, epoch: 45, loss: 0.962376
global_step: 33771, epoch: 45, loss: 1.075785
global_step: 33772, epoch: 45, loss: 1.048515
global_step: 33773, epoch: 45, loss: 0.946032
global_step: 33774, epoch: 45, loss: 0.942207
global_step: 33775, epoch: 45, loss: 0.948203
global_step: 33776, epoch: 45, loss: 0.977578
global_step: 33777, epoch: 45, loss: 1.007095
global_step: 33778, epoch: 45, loss: 0.962552
global_step: 33779, epoch: 45, loss: 0.978461
global_step: 33780, epoch: 45, loss: 0.980930
global_step: 33781, epoch: 45, loss: 1.030643
global_step: 33782, epoch: 45, loss: 1.050454
global_step: 33783, epoch: 45, loss: 1.063881
global_step: 33784, epoch: 45, loss: 0.866314
global_step: 33785, epoch: 45, loss: 0.969373
global_step: 33786, epoch: 45, loss: 0.953459
global_step: 33787, epoch: 45, loss: 1.068625
global_step: 33788, epoch: 45, loss: 0.997197
global_step: 33789, epoch: 45, loss: 0.965218
global_step: 33790, epoch: 45, loss: 1.003603
global_step: 33791, epoch: 45, loss: 0.976941
global_step: 33792, epoch: 45, loss: 1.018528
global_step: 33793, epoch: 45, loss: 0.977063
global_step: 33794, epoch: 45, loss: 0.898670
global_step: 33795, epoch: 45, loss: 1.075958
global_step: 33796, epoch: 45, loss: 1.025930
global_step: 33797, epoch: 45, loss: 1.021241
global_step: 33798, epoch: 45, loss: 0.952574
global_step: 33799, epoch: 45, loss: 0.994025
global_step: 33800, epoch: 45, loss: 0.859554
epoch: 45
train	acc: 0.6847	macro: p 0.4494, r 0.3873, f1: 0.3950	micro: p 0.6847, r 0.6847, f1 0.6847	weighted_f1:0.6392
dev	acc: 0.5663	macro: p 0.3901, r 0.3193, f1: 0.3112	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5060
test	acc: 0.6119	macro: p 0.3695, r 0.3238, f1: 0.3196	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5593
global_step: 33801, epoch: 46, loss: 0.977474
global_step: 33802, epoch: 46, loss: 1.068225
global_step: 33803, epoch: 46, loss: 1.013679
global_step: 33804, epoch: 46, loss: 0.898069
global_step: 33805, epoch: 46, loss: 0.935825
global_step: 33806, epoch: 46, loss: 0.980798
global_step: 33807, epoch: 46, loss: 1.007277
global_step: 33808, epoch: 46, loss: 0.966820
global_step: 33809, epoch: 46, loss: 1.040719
global_step: 33810, epoch: 46, loss: 1.015697
global_step: 33811, epoch: 46, loss: 0.977966
global_step: 33812, epoch: 46, loss: 0.986291
global_step: 33813, epoch: 46, loss: 0.847330
global_step: 33814, epoch: 46, loss: 0.949685
global_step: 33815, epoch: 46, loss: 1.019927
global_step: 33816, epoch: 46, loss: 0.931455
global_step: 33817, epoch: 46, loss: 1.062396
global_step: 33818, epoch: 46, loss: 0.990964
global_step: 33819, epoch: 46, loss: 0.906552
global_step: 33820, epoch: 46, loss: 1.012508
global_step: 33821, epoch: 46, loss: 1.048972
global_step: 33822, epoch: 46, loss: 0.967257
global_step: 33823, epoch: 46, loss: 0.798934
global_step: 33824, epoch: 46, loss: 0.955639
global_step: 33825, epoch: 46, loss: 1.000519
global_step: 33826, epoch: 46, loss: 1.094252
global_step: 33827, epoch: 46, loss: 1.047684
global_step: 33828, epoch: 46, loss: 1.060516
global_step: 33829, epoch: 46, loss: 1.049018
global_step: 33830, epoch: 46, loss: 1.002731
global_step: 33831, epoch: 46, loss: 0.948737
global_step: 33832, epoch: 46, loss: 1.009868
global_step: 33833, epoch: 46, loss: 0.956898
global_step: 33834, epoch: 46, loss: 0.969873
global_step: 33835, epoch: 46, loss: 0.907080
global_step: 33836, epoch: 46, loss: 0.981688
global_step: 33837, epoch: 46, loss: 0.951129
global_step: 33838, epoch: 46, loss: 0.975419
global_step: 33839, epoch: 46, loss: 1.027463
global_step: 33840, epoch: 46, loss: 0.541792
epoch: 46
train	acc: 0.6953	macro: p 0.4600, r 0.4032, f1: 0.4137	micro: p 0.6953, r 0.6953, f1 0.6953	weighted_f1:0.6552
dev	acc: 0.5762	macro: p 0.3877, r 0.3288, f1: 0.3274	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5230
test	acc: 0.6123	macro: p 0.3665, r 0.3268, f1: 0.3276	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5656
global_step: 33841, epoch: 47, loss: 0.936178
global_step: 33842, epoch: 47, loss: 0.961469
global_step: 33843, epoch: 47, loss: 1.047881
global_step: 33844, epoch: 47, loss: 0.983912
global_step: 33845, epoch: 47, loss: 0.964247
global_step: 33846, epoch: 47, loss: 0.976419
global_step: 33847, epoch: 47, loss: 0.985819
global_step: 33848, epoch: 47, loss: 1.024390
global_step: 33849, epoch: 47, loss: 1.022367
global_step: 33850, epoch: 47, loss: 1.029066
global_step: 33851, epoch: 47, loss: 0.900391
global_step: 33852, epoch: 47, loss: 1.025348
global_step: 33853, epoch: 47, loss: 0.975002
global_step: 33854, epoch: 47, loss: 1.143976
global_step: 33855, epoch: 47, loss: 0.991373
global_step: 33856, epoch: 47, loss: 1.010430
global_step: 33857, epoch: 47, loss: 0.975691
global_step: 33858, epoch: 47, loss: 0.964322
global_step: 33859, epoch: 47, loss: 1.156931
global_step: 33860, epoch: 47, loss: 1.029851
global_step: 33861, epoch: 47, loss: 0.902552
global_step: 33862, epoch: 47, loss: 0.876224
global_step: 33863, epoch: 47, loss: 0.918006
global_step: 33864, epoch: 47, loss: 1.056880
global_step: 33865, epoch: 47, loss: 0.930772
global_step: 33866, epoch: 47, loss: 0.914909
global_step: 33867, epoch: 47, loss: 1.060909
global_step: 33868, epoch: 47, loss: 0.921424
global_step: 33869, epoch: 47, loss: 1.086840
global_step: 33870, epoch: 47, loss: 0.998670
global_step: 33871, epoch: 47, loss: 0.918628
global_step: 33872, epoch: 47, loss: 1.035155
global_step: 33873, epoch: 47, loss: 0.913738
global_step: 33874, epoch: 47, loss: 0.907985
global_step: 33875, epoch: 47, loss: 0.936927
global_step: 33876, epoch: 47, loss: 0.957271
global_step: 33877, epoch: 47, loss: 0.935741
global_step: 33878, epoch: 47, loss: 0.959855
global_step: 33879, epoch: 47, loss: 0.868976
global_step: 33880, epoch: 47, loss: 1.123029
epoch: 47
train	acc: 0.6956	macro: p 0.4594, r 0.4033, f1: 0.4129	micro: p 0.6956, r 0.6956, f1 0.6956	weighted_f1:0.6554
dev	acc: 0.5717	macro: p 0.3802, r 0.3261, f1: 0.3225	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5186
test	acc: 0.6107	macro: p 0.3651, r 0.3278, f1: 0.3266	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5641
global_step: 33881, epoch: 48, loss: 0.997375
global_step: 33882, epoch: 48, loss: 0.883601
global_step: 33883, epoch: 48, loss: 1.072398
global_step: 33884, epoch: 48, loss: 0.912604
global_step: 33885, epoch: 48, loss: 0.869069
global_step: 33886, epoch: 48, loss: 1.059655
global_step: 33887, epoch: 48, loss: 1.027270
global_step: 33888, epoch: 48, loss: 1.060167
global_step: 33889, epoch: 48, loss: 0.971583
global_step: 33890, epoch: 48, loss: 0.960608
global_step: 33891, epoch: 48, loss: 0.925911
global_step: 33892, epoch: 48, loss: 1.008962
global_step: 33893, epoch: 48, loss: 1.127326
global_step: 33894, epoch: 48, loss: 1.020962
global_step: 33895, epoch: 48, loss: 0.913868
global_step: 33896, epoch: 48, loss: 0.935949
global_step: 33897, epoch: 48, loss: 1.032712
global_step: 33898, epoch: 48, loss: 0.939749
global_step: 33899, epoch: 48, loss: 0.972667
global_step: 33900, epoch: 48, loss: 0.902002
global_step: 33901, epoch: 48, loss: 0.965906
global_step: 33902, epoch: 48, loss: 0.832196
global_step: 33903, epoch: 48, loss: 0.920433
global_step: 33904, epoch: 48, loss: 0.988781
global_step: 33905, epoch: 48, loss: 1.008363
global_step: 33906, epoch: 48, loss: 0.945150
global_step: 33907, epoch: 48, loss: 0.846001
global_step: 33908, epoch: 48, loss: 0.953282
global_step: 33909, epoch: 48, loss: 0.887640
global_step: 33910, epoch: 48, loss: 0.867580
global_step: 33911, epoch: 48, loss: 0.950856
global_step: 33912, epoch: 48, loss: 1.037453
global_step: 33913, epoch: 48, loss: 0.932610
global_step: 33914, epoch: 48, loss: 0.967401
global_step: 33915, epoch: 48, loss: 0.915452
global_step: 33916, epoch: 48, loss: 0.972598
global_step: 33917, epoch: 48, loss: 0.979172
global_step: 33918, epoch: 48, loss: 1.028564
global_step: 33919, epoch: 48, loss: 0.894851
global_step: 33920, epoch: 48, loss: 0.675630
epoch: 48
train	acc: 0.6982	macro: p 0.4562, r 0.4083, f1: 0.4194	micro: p 0.6982, r 0.6982, f1 0.6982	weighted_f1:0.6593
dev	acc: 0.5789	macro: p 0.3875, r 0.3339, f1: 0.3339	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5279
test	acc: 0.6157	macro: p 0.3682, r 0.3312, f1: 0.3327	micro: p 0.6157, r 0.6157, f1 0.6157	weighted_f1:0.5697
global_step: 33921, epoch: 49, loss: 0.952621
global_step: 33922, epoch: 49, loss: 0.890131
global_step: 33923, epoch: 49, loss: 1.024933
global_step: 33924, epoch: 49, loss: 0.991719
global_step: 33925, epoch: 49, loss: 0.942841
global_step: 33926, epoch: 49, loss: 1.063250
global_step: 33927, epoch: 49, loss: 0.932310
global_step: 33928, epoch: 49, loss: 1.015126
global_step: 33929, epoch: 49, loss: 0.954337
global_step: 33930, epoch: 49, loss: 0.942029
global_step: 33931, epoch: 49, loss: 0.804602
global_step: 33932, epoch: 49, loss: 0.882912
global_step: 33933, epoch: 49, loss: 1.023353
global_step: 33934, epoch: 49, loss: 0.964826
global_step: 33935, epoch: 49, loss: 0.963845
global_step: 33936, epoch: 49, loss: 0.926355
global_step: 33937, epoch: 49, loss: 1.017974
global_step: 33938, epoch: 49, loss: 1.062955
global_step: 33939, epoch: 49, loss: 1.071730
global_step: 33940, epoch: 49, loss: 1.044413
global_step: 33941, epoch: 49, loss: 0.963283
global_step: 33942, epoch: 49, loss: 0.970814
global_step: 33943, epoch: 49, loss: 1.020368
global_step: 33944, epoch: 49, loss: 0.916350
global_step: 33945, epoch: 49, loss: 0.881683
global_step: 33946, epoch: 49, loss: 1.017970
global_step: 33947, epoch: 49, loss: 0.834095
global_step: 33948, epoch: 49, loss: 0.851248
global_step: 33949, epoch: 49, loss: 0.970120
global_step: 33950, epoch: 49, loss: 1.020766
global_step: 33951, epoch: 49, loss: 0.973518
global_step: 33952, epoch: 49, loss: 0.885633
global_step: 33953, epoch: 49, loss: 0.983535
global_step: 33954, epoch: 49, loss: 0.939619
global_step: 33955, epoch: 49, loss: 0.963764
global_step: 33956, epoch: 49, loss: 0.900298
global_step: 33957, epoch: 49, loss: 1.049947
global_step: 33958, epoch: 49, loss: 0.910361
global_step: 33959, epoch: 49, loss: 0.900438
global_step: 33960, epoch: 49, loss: 0.933683
epoch: 49
train	acc: 0.7045	macro: p 0.4608, r 0.4162, f1: 0.4238	micro: p 0.7045, r 0.7045, f1 0.7045	weighted_f1:0.6677
dev	acc: 0.5699	macro: p 0.3713, r 0.3292, f1: 0.3245	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5205
test	acc: 0.6061	macro: p 0.3690, r 0.3305, f1: 0.3301	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5640
global_step: 33961, epoch: 50, loss: 1.017713
global_step: 33962, epoch: 50, loss: 0.865964
global_step: 33963, epoch: 50, loss: 0.884531
global_step: 33964, epoch: 50, loss: 1.053387
global_step: 33965, epoch: 50, loss: 1.009735
global_step: 33966, epoch: 50, loss: 0.872628
global_step: 33967, epoch: 50, loss: 1.049654
global_step: 33968, epoch: 50, loss: 0.938296
global_step: 33969, epoch: 50, loss: 0.876352
global_step: 33970, epoch: 50, loss: 0.951690
global_step: 33971, epoch: 50, loss: 0.938493
global_step: 33972, epoch: 50, loss: 0.860025
global_step: 33973, epoch: 50, loss: 0.943560
global_step: 33974, epoch: 50, loss: 0.927980
global_step: 33975, epoch: 50, loss: 0.995635
global_step: 33976, epoch: 50, loss: 0.997529
global_step: 33977, epoch: 50, loss: 0.919103
global_step: 33978, epoch: 50, loss: 0.941628
global_step: 33979, epoch: 50, loss: 0.921080
global_step: 33980, epoch: 50, loss: 1.007253
global_step: 33981, epoch: 50, loss: 0.891473
global_step: 33982, epoch: 50, loss: 1.001230
global_step: 33983, epoch: 50, loss: 0.959130
global_step: 33984, epoch: 50, loss: 0.919760
global_step: 33985, epoch: 50, loss: 0.917198
global_step: 33986, epoch: 50, loss: 1.022209
global_step: 33987, epoch: 50, loss: 0.901206
global_step: 33988, epoch: 50, loss: 0.951826
global_step: 33989, epoch: 50, loss: 1.006854
global_step: 33990, epoch: 50, loss: 0.913204
global_step: 33991, epoch: 50, loss: 1.029881
global_step: 33992, epoch: 50, loss: 0.852886
global_step: 33993, epoch: 50, loss: 0.922003
global_step: 33994, epoch: 50, loss: 1.021753
global_step: 33995, epoch: 50, loss: 0.907864
global_step: 33996, epoch: 50, loss: 0.950306
global_step: 33997, epoch: 50, loss: 0.955219
global_step: 33998, epoch: 50, loss: 0.983988
global_step: 33999, epoch: 50, loss: 1.007542
global_step: 34000, epoch: 50, loss: 0.086341
epoch: 50
train	acc: 0.7007	macro: p 0.4685, r 0.4058, f1: 0.4176	micro: p 0.7007, r 0.7007, f1 0.7007	weighted_f1:0.6591
dev	acc: 0.5753	macro: p 0.3992, r 0.3265, f1: 0.3247	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5188
test	acc: 0.6126	macro: p 0.3651, r 0.3227, f1: 0.3225	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5621
global_step: 34001, epoch: 51, loss: 0.975600
global_step: 34002, epoch: 51, loss: 0.866392
global_step: 34003, epoch: 51, loss: 0.858450
global_step: 34004, epoch: 51, loss: 0.904868
global_step: 34005, epoch: 51, loss: 0.983672
global_step: 34006, epoch: 51, loss: 1.050218
global_step: 34007, epoch: 51, loss: 0.941825
global_step: 34008, epoch: 51, loss: 0.911660
global_step: 34009, epoch: 51, loss: 0.804832
global_step: 34010, epoch: 51, loss: 1.018174
global_step: 34011, epoch: 51, loss: 0.904530
global_step: 34012, epoch: 51, loss: 1.046036
global_step: 34013, epoch: 51, loss: 0.993503
global_step: 34014, epoch: 51, loss: 0.927678
global_step: 34015, epoch: 51, loss: 0.994176
global_step: 34016, epoch: 51, loss: 0.899421
global_step: 34017, epoch: 51, loss: 0.996379
global_step: 34018, epoch: 51, loss: 0.974561
global_step: 34019, epoch: 51, loss: 0.998484
global_step: 34020, epoch: 51, loss: 0.826106
global_step: 34021, epoch: 51, loss: 0.913033
global_step: 34022, epoch: 51, loss: 0.866283
global_step: 34023, epoch: 51, loss: 0.855852
global_step: 34024, epoch: 51, loss: 0.954101
global_step: 34025, epoch: 51, loss: 1.052288
global_step: 34026, epoch: 51, loss: 1.061014
global_step: 34027, epoch: 51, loss: 0.898789
global_step: 34028, epoch: 51, loss: 0.963422
global_step: 34029, epoch: 51, loss: 0.899614
global_step: 34030, epoch: 51, loss: 0.943703
global_step: 34031, epoch: 51, loss: 0.997598
global_step: 34032, epoch: 51, loss: 1.017641
global_step: 34033, epoch: 51, loss: 0.961860
global_step: 34034, epoch: 51, loss: 0.950819
global_step: 34035, epoch: 51, loss: 0.912347
global_step: 34036, epoch: 51, loss: 0.861164
global_step: 34037, epoch: 51, loss: 0.845797
global_step: 34038, epoch: 51, loss: 1.116182
global_step: 34039, epoch: 51, loss: 0.767212
global_step: 34040, epoch: 51, loss: 1.149804
epoch: 51
train	acc: 0.7180	macro: p 0.4747, r 0.4342, f1: 0.4436	micro: p 0.7180, r 0.7180, f1 0.7180	weighted_f1:0.6838
dev	acc: 0.5825	macro: p 0.3767, r 0.3384, f1: 0.3393	micro: p 0.5825, r 0.5825, f1 0.5825	weighted_f1:0.5354
test	acc: 0.6130	macro: p 0.3603, r 0.3330, f1: 0.3350	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5716
New best model!
global_step: 34041, epoch: 52, loss: 0.876605
global_step: 34042, epoch: 52, loss: 0.919775
global_step: 34043, epoch: 52, loss: 0.995122
global_step: 34044, epoch: 52, loss: 0.970190
global_step: 34045, epoch: 52, loss: 0.944793
global_step: 34046, epoch: 52, loss: 0.994379
global_step: 34047, epoch: 52, loss: 1.002006
global_step: 34048, epoch: 52, loss: 0.860141
global_step: 34049, epoch: 52, loss: 0.999061
global_step: 34050, epoch: 52, loss: 1.051940
global_step: 34051, epoch: 52, loss: 0.890735
global_step: 34052, epoch: 52, loss: 0.994837
global_step: 34053, epoch: 52, loss: 0.912357
global_step: 34054, epoch: 52, loss: 0.881504
global_step: 34055, epoch: 52, loss: 0.905813
global_step: 34056, epoch: 52, loss: 0.974732
global_step: 34057, epoch: 52, loss: 0.943791
global_step: 34058, epoch: 52, loss: 0.900436
global_step: 34059, epoch: 52, loss: 0.829422
global_step: 34060, epoch: 52, loss: 0.945061
global_step: 34061, epoch: 52, loss: 0.932898
global_step: 34062, epoch: 52, loss: 0.933981
global_step: 34063, epoch: 52, loss: 0.911026
global_step: 34064, epoch: 52, loss: 0.912257
global_step: 34065, epoch: 52, loss: 0.873477
global_step: 34066, epoch: 52, loss: 0.946182
global_step: 34067, epoch: 52, loss: 0.869016
global_step: 34068, epoch: 52, loss: 0.869742
global_step: 34069, epoch: 52, loss: 0.907284
global_step: 34070, epoch: 52, loss: 0.957801
global_step: 34071, epoch: 52, loss: 0.925241
global_step: 34072, epoch: 52, loss: 0.925438
global_step: 34073, epoch: 52, loss: 0.948128
global_step: 34074, epoch: 52, loss: 0.917884
global_step: 34075, epoch: 52, loss: 0.876027
global_step: 34076, epoch: 52, loss: 0.880844
global_step: 34077, epoch: 52, loss: 0.982480
global_step: 34078, epoch: 52, loss: 0.859233
global_step: 34079, epoch: 52, loss: 0.926814
global_step: 34080, epoch: 52, loss: 0.526705
epoch: 52
train	acc: 0.7083	macro: p 0.4749, r 0.4128, f1: 0.4234	micro: p 0.7083, r 0.7083, f1 0.7083	weighted_f1:0.6663
dev	acc: 0.5708	macro: p 0.3868, r 0.3227, f1: 0.3163	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5115
test	acc: 0.6100	macro: p 0.3636, r 0.3208, f1: 0.3185	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5579
global_step: 34081, epoch: 53, loss: 1.001075
global_step: 34082, epoch: 53, loss: 0.994827
global_step: 34083, epoch: 53, loss: 0.962667
global_step: 34084, epoch: 53, loss: 0.856535
global_step: 34085, epoch: 53, loss: 0.883368
global_step: 34086, epoch: 53, loss: 0.905280
global_step: 34087, epoch: 53, loss: 0.915639
global_step: 34088, epoch: 53, loss: 0.866139
global_step: 34089, epoch: 53, loss: 0.906711
global_step: 34090, epoch: 53, loss: 0.890308
global_step: 34091, epoch: 53, loss: 0.947980
global_step: 34092, epoch: 53, loss: 0.818096
global_step: 34093, epoch: 53, loss: 0.951073
global_step: 34094, epoch: 53, loss: 0.921337
global_step: 34095, epoch: 53, loss: 0.879210
global_step: 34096, epoch: 53, loss: 0.975814
global_step: 34097, epoch: 53, loss: 0.864842
global_step: 34098, epoch: 53, loss: 1.017846
global_step: 34099, epoch: 53, loss: 0.884884
global_step: 34100, epoch: 53, loss: 0.939011
global_step: 34101, epoch: 53, loss: 0.902034
global_step: 34102, epoch: 53, loss: 0.993210
global_step: 34103, epoch: 53, loss: 0.870506
global_step: 34104, epoch: 53, loss: 0.928598
global_step: 34105, epoch: 53, loss: 0.794659
global_step: 34106, epoch: 53, loss: 0.922201
global_step: 34107, epoch: 53, loss: 0.977436
global_step: 34108, epoch: 53, loss: 0.792260
global_step: 34109, epoch: 53, loss: 0.913533
global_step: 34110, epoch: 53, loss: 0.914235
global_step: 34111, epoch: 53, loss: 0.968273
global_step: 34112, epoch: 53, loss: 1.004890
global_step: 34113, epoch: 53, loss: 0.971611
global_step: 34114, epoch: 53, loss: 0.935782
global_step: 34115, epoch: 53, loss: 0.869658
global_step: 34116, epoch: 53, loss: 0.989593
global_step: 34117, epoch: 53, loss: 0.955091
global_step: 34118, epoch: 53, loss: 0.925309
global_step: 34119, epoch: 53, loss: 0.923294
global_step: 34120, epoch: 53, loss: 1.443520
epoch: 53
train	acc: 0.7370	macro: p 0.4766, r 0.4619, f1: 0.4650	micro: p 0.7370, r 0.7370, f1 0.7370	weighted_f1:0.7069
dev	acc: 0.5834	macro: p 0.3687, r 0.3482, f1: 0.3468	micro: p 0.5834, r 0.5834, f1 0.5834	weighted_f1:0.5412
test	acc: 0.6126	macro: p 0.3602, r 0.3465, f1: 0.3448	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5772
New best model!
global_step: 34121, epoch: 54, loss: 0.885762
global_step: 34122, epoch: 54, loss: 0.869216
global_step: 34123, epoch: 54, loss: 0.825286
global_step: 34124, epoch: 54, loss: 0.903662
global_step: 34125, epoch: 54, loss: 0.900911
global_step: 34126, epoch: 54, loss: 1.088883
global_step: 34127, epoch: 54, loss: 0.958933
global_step: 34128, epoch: 54, loss: 0.970830
global_step: 34129, epoch: 54, loss: 0.909526
global_step: 34130, epoch: 54, loss: 0.976632
global_step: 34131, epoch: 54, loss: 0.837457
global_step: 34132, epoch: 54, loss: 0.845159
global_step: 34133, epoch: 54, loss: 0.884376
global_step: 34134, epoch: 54, loss: 0.856948
global_step: 34135, epoch: 54, loss: 0.935511
global_step: 34136, epoch: 54, loss: 0.936363
global_step: 34137, epoch: 54, loss: 0.881240
global_step: 34138, epoch: 54, loss: 0.886378
global_step: 34139, epoch: 54, loss: 0.975803
global_step: 34140, epoch: 54, loss: 0.931707
global_step: 34141, epoch: 54, loss: 0.908161
global_step: 34142, epoch: 54, loss: 0.851140
global_step: 34143, epoch: 54, loss: 0.919272
global_step: 34144, epoch: 54, loss: 0.930780
global_step: 34145, epoch: 54, loss: 0.795583
global_step: 34146, epoch: 54, loss: 0.830903
global_step: 34147, epoch: 54, loss: 0.951184
global_step: 34148, epoch: 54, loss: 0.918423
global_step: 34149, epoch: 54, loss: 0.920818
global_step: 34150, epoch: 54, loss: 0.718971
global_step: 34151, epoch: 54, loss: 0.919855
global_step: 34152, epoch: 54, loss: 0.921608
global_step: 34153, epoch: 54, loss: 1.020798
global_step: 34154, epoch: 54, loss: 0.909045
global_step: 34155, epoch: 54, loss: 0.950581
global_step: 34156, epoch: 54, loss: 0.904403
global_step: 34157, epoch: 54, loss: 0.872081
global_step: 34158, epoch: 54, loss: 0.852984
global_step: 34159, epoch: 54, loss: 1.049145
global_step: 34160, epoch: 54, loss: 0.181418
epoch: 54
train	acc: 0.7214	macro: p 0.4812, r 0.4345, f1: 0.4464	micro: p 0.7214, r 0.7214, f1 0.7214	weighted_f1:0.6850
dev	acc: 0.5789	macro: p 0.3752, r 0.3329, f1: 0.3333	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5269
test	acc: 0.6126	macro: p 0.3592, r 0.3256, f1: 0.3289	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5660
global_step: 34161, epoch: 55, loss: 0.730753
global_step: 34162, epoch: 55, loss: 0.796870
global_step: 34163, epoch: 55, loss: 0.921856
global_step: 34164, epoch: 55, loss: 0.829103
global_step: 34165, epoch: 55, loss: 0.876244
global_step: 34166, epoch: 55, loss: 0.938263
global_step: 34167, epoch: 55, loss: 0.914115
global_step: 34168, epoch: 55, loss: 0.918683
global_step: 34169, epoch: 55, loss: 0.965900
global_step: 34170, epoch: 55, loss: 0.947125
global_step: 34171, epoch: 55, loss: 0.856951
global_step: 34172, epoch: 55, loss: 1.014979
global_step: 34173, epoch: 55, loss: 1.026337
global_step: 34174, epoch: 55, loss: 1.000055
global_step: 34175, epoch: 55, loss: 0.920217
global_step: 34176, epoch: 55, loss: 0.805723
global_step: 34177, epoch: 55, loss: 0.843260
global_step: 34178, epoch: 55, loss: 0.982644
global_step: 34179, epoch: 55, loss: 0.964492
global_step: 34180, epoch: 55, loss: 0.901702
global_step: 34181, epoch: 55, loss: 0.944412
global_step: 34182, epoch: 55, loss: 0.848175
global_step: 34183, epoch: 55, loss: 0.926465
global_step: 34184, epoch: 55, loss: 1.020563
global_step: 34185, epoch: 55, loss: 0.877346
global_step: 34186, epoch: 55, loss: 0.856404
global_step: 34187, epoch: 55, loss: 0.815730
global_step: 34188, epoch: 55, loss: 0.852137
global_step: 34189, epoch: 55, loss: 0.865264
global_step: 34190, epoch: 55, loss: 0.821372
global_step: 34191, epoch: 55, loss: 0.864217
global_step: 34192, epoch: 55, loss: 0.807482
global_step: 34193, epoch: 55, loss: 0.776892
global_step: 34194, epoch: 55, loss: 0.862063
global_step: 34195, epoch: 55, loss: 0.947935
global_step: 34196, epoch: 55, loss: 0.936593
global_step: 34197, epoch: 55, loss: 0.921069
global_step: 34198, epoch: 55, loss: 0.933464
global_step: 34199, epoch: 55, loss: 0.957528
global_step: 34200, epoch: 55, loss: 1.059827
epoch: 55
train	acc: 0.7246	macro: p 0.4817, r 0.4399, f1: 0.4477	micro: p 0.7246, r 0.7246, f1 0.7246	weighted_f1:0.6873
dev	acc: 0.5726	macro: p 0.3726, r 0.3288, f1: 0.3230	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5162
test	acc: 0.6100	macro: p 0.3568, r 0.3290, f1: 0.3262	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5628
global_step: 34201, epoch: 56, loss: 0.967812
global_step: 34202, epoch: 56, loss: 0.853037
global_step: 34203, epoch: 56, loss: 0.916028
global_step: 34204, epoch: 56, loss: 0.927213
global_step: 34205, epoch: 56, loss: 0.865177
global_step: 34206, epoch: 56, loss: 0.821336
global_step: 34207, epoch: 56, loss: 0.807300
global_step: 34208, epoch: 56, loss: 0.956933
global_step: 34209, epoch: 56, loss: 0.921980
global_step: 34210, epoch: 56, loss: 0.918827
global_step: 34211, epoch: 56, loss: 0.983483
global_step: 34212, epoch: 56, loss: 0.888449
global_step: 34213, epoch: 56, loss: 0.805592
global_step: 34214, epoch: 56, loss: 0.887272
global_step: 34215, epoch: 56, loss: 0.896466
global_step: 34216, epoch: 56, loss: 0.840189
global_step: 34217, epoch: 56, loss: 0.944810
global_step: 34218, epoch: 56, loss: 0.842459
global_step: 34219, epoch: 56, loss: 0.778801
global_step: 34220, epoch: 56, loss: 0.982298
global_step: 34221, epoch: 56, loss: 0.828713
global_step: 34222, epoch: 56, loss: 0.913163
global_step: 34223, epoch: 56, loss: 0.937861
global_step: 34224, epoch: 56, loss: 0.955893
global_step: 34225, epoch: 56, loss: 0.869954
global_step: 34226, epoch: 56, loss: 0.905999
global_step: 34227, epoch: 56, loss: 0.910928
global_step: 34228, epoch: 56, loss: 0.837266
global_step: 34229, epoch: 56, loss: 0.735632
global_step: 34230, epoch: 56, loss: 0.974217
global_step: 34231, epoch: 56, loss: 0.872046
global_step: 34232, epoch: 56, loss: 0.869164
global_step: 34233, epoch: 56, loss: 0.892577
global_step: 34234, epoch: 56, loss: 0.909551
global_step: 34235, epoch: 56, loss: 0.797862
global_step: 34236, epoch: 56, loss: 0.880021
global_step: 34237, epoch: 56, loss: 1.012354
global_step: 34238, epoch: 56, loss: 0.790679
global_step: 34239, epoch: 56, loss: 0.932837
global_step: 34240, epoch: 56, loss: 0.366200
epoch: 56
train	acc: 0.7263	macro: p 0.4933, r 0.4365, f1: 0.4474	micro: p 0.7263, r 0.7263, f1 0.7263	weighted_f1:0.6881
dev	acc: 0.5789	macro: p 0.3926, r 0.3310, f1: 0.3299	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5239
test	acc: 0.6126	macro: p 0.3610, r 0.3239, f1: 0.3237	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5630
global_step: 34241, epoch: 57, loss: 0.821764
global_step: 34242, epoch: 57, loss: 0.826436
global_step: 34243, epoch: 57, loss: 0.813546
global_step: 34244, epoch: 57, loss: 0.871912
global_step: 34245, epoch: 57, loss: 0.870536
global_step: 34246, epoch: 57, loss: 0.909115
global_step: 34247, epoch: 57, loss: 0.845948
global_step: 34248, epoch: 57, loss: 0.823018
global_step: 34249, epoch: 57, loss: 0.874418
global_step: 34250, epoch: 57, loss: 0.859117
global_step: 34251, epoch: 57, loss: 0.865583
global_step: 34252, epoch: 57, loss: 0.914629
global_step: 34253, epoch: 57, loss: 0.961354
global_step: 34254, epoch: 57, loss: 0.843310
global_step: 34255, epoch: 57, loss: 0.821537
global_step: 34256, epoch: 57, loss: 0.894752
global_step: 34257, epoch: 57, loss: 0.830565
global_step: 34258, epoch: 57, loss: 0.890393
global_step: 34259, epoch: 57, loss: 0.998054
global_step: 34260, epoch: 57, loss: 0.861523
global_step: 34261, epoch: 57, loss: 0.886681
global_step: 34262, epoch: 57, loss: 0.865524
global_step: 34263, epoch: 57, loss: 0.885540
global_step: 34264, epoch: 57, loss: 0.780760
global_step: 34265, epoch: 57, loss: 0.895467
global_step: 34266, epoch: 57, loss: 0.932774
global_step: 34267, epoch: 57, loss: 0.855906
global_step: 34268, epoch: 57, loss: 0.855566
global_step: 34269, epoch: 57, loss: 0.904431
global_step: 34270, epoch: 57, loss: 0.999115
global_step: 34271, epoch: 57, loss: 0.994304
global_step: 34272, epoch: 57, loss: 0.838530
global_step: 34273, epoch: 57, loss: 1.058964
global_step: 34274, epoch: 57, loss: 0.772385
global_step: 34275, epoch: 57, loss: 0.930486
global_step: 34276, epoch: 57, loss: 0.883647
global_step: 34277, epoch: 57, loss: 0.828022
global_step: 34278, epoch: 57, loss: 0.811362
global_step: 34279, epoch: 57, loss: 0.885084
global_step: 34280, epoch: 57, loss: 0.673609
epoch: 57
train	acc: 0.7571	macro: p 0.4858, r 0.4972, f1: 0.4876	micro: p 0.7571, r 0.7571, f1 0.7571	weighted_f1:0.7346
dev	acc: 0.5690	macro: p 0.3507, r 0.3551, f1: 0.3470	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5409
test	acc: 0.5931	macro: p 0.3506, r 0.3563, f1: 0.3477	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5718
global_step: 34281, epoch: 58, loss: 0.856304
global_step: 34282, epoch: 58, loss: 0.880256
global_step: 34283, epoch: 58, loss: 0.820689
global_step: 34284, epoch: 58, loss: 0.848150
global_step: 34285, epoch: 58, loss: 0.869037
global_step: 34286, epoch: 58, loss: 0.927067
global_step: 34287, epoch: 58, loss: 0.906663
global_step: 34288, epoch: 58, loss: 0.951176
global_step: 34289, epoch: 58, loss: 0.946577
global_step: 34290, epoch: 58, loss: 0.906701
global_step: 34291, epoch: 58, loss: 0.844044
global_step: 34292, epoch: 58, loss: 0.926538
global_step: 34293, epoch: 58, loss: 0.887789
global_step: 34294, epoch: 58, loss: 0.843008
global_step: 34295, epoch: 58, loss: 0.915949
global_step: 34296, epoch: 58, loss: 0.931291
global_step: 34297, epoch: 58, loss: 0.848477
global_step: 34298, epoch: 58, loss: 0.862997
global_step: 34299, epoch: 58, loss: 0.954132
global_step: 34300, epoch: 58, loss: 0.836119
global_step: 34301, epoch: 58, loss: 0.932608
global_step: 34302, epoch: 58, loss: 0.710778
global_step: 34303, epoch: 58, loss: 0.875765
global_step: 34304, epoch: 58, loss: 0.817260
global_step: 34305, epoch: 58, loss: 0.804504
global_step: 34306, epoch: 58, loss: 0.718542
global_step: 34307, epoch: 58, loss: 0.931770
global_step: 34308, epoch: 58, loss: 0.887901
global_step: 34309, epoch: 58, loss: 0.801828
global_step: 34310, epoch: 58, loss: 0.825105
global_step: 34311, epoch: 58, loss: 0.655360
global_step: 34312, epoch: 58, loss: 0.801263
global_step: 34313, epoch: 58, loss: 0.862549
global_step: 34314, epoch: 58, loss: 0.974045
global_step: 34315, epoch: 58, loss: 0.850797
global_step: 34316, epoch: 58, loss: 0.835170
global_step: 34317, epoch: 58, loss: 0.843575
global_step: 34318, epoch: 58, loss: 0.958930
global_step: 34319, epoch: 58, loss: 0.825437
global_step: 34320, epoch: 58, loss: 1.318330
epoch: 58
train	acc: 0.7641	macro: p 0.4959, r 0.4997, f1: 0.4948	micro: p 0.7641, r 0.7641, f1 0.7641	weighted_f1:0.7395
dev	acc: 0.5798	macro: p 0.3598, r 0.3519, f1: 0.3499	micro: p 0.5798, r 0.5798, f1 0.5798	weighted_f1:0.5450
test	acc: 0.6073	macro: p 0.3559, r 0.3481, f1: 0.3464	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5773
New best model!
global_step: 34321, epoch: 59, loss: 0.857288
global_step: 34322, epoch: 59, loss: 0.881367
global_step: 34323, epoch: 59, loss: 0.882499
global_step: 34324, epoch: 59, loss: 0.800557
global_step: 34325, epoch: 59, loss: 0.795042
global_step: 34326, epoch: 59, loss: 0.841926
global_step: 34327, epoch: 59, loss: 0.836286
global_step: 34328, epoch: 59, loss: 0.834593
global_step: 34329, epoch: 59, loss: 0.885577
global_step: 34330, epoch: 59, loss: 0.918643
global_step: 34331, epoch: 59, loss: 0.875668
global_step: 34332, epoch: 59, loss: 0.910846
global_step: 34333, epoch: 59, loss: 0.840083
global_step: 34334, epoch: 59, loss: 0.839723
global_step: 34335, epoch: 59, loss: 0.842308
global_step: 34336, epoch: 59, loss: 0.864162
global_step: 34337, epoch: 59, loss: 0.815532
global_step: 34338, epoch: 59, loss: 1.014898
global_step: 34339, epoch: 59, loss: 0.824506
global_step: 34340, epoch: 59, loss: 0.808982
global_step: 34341, epoch: 59, loss: 0.879893
global_step: 34342, epoch: 59, loss: 0.790465
global_step: 34343, epoch: 59, loss: 0.895744
global_step: 34344, epoch: 59, loss: 0.820142
global_step: 34345, epoch: 59, loss: 0.816242
global_step: 34346, epoch: 59, loss: 0.921346
global_step: 34347, epoch: 59, loss: 0.795437
global_step: 34348, epoch: 59, loss: 0.853820
global_step: 34349, epoch: 59, loss: 0.977323
global_step: 34350, epoch: 59, loss: 0.733815
global_step: 34351, epoch: 59, loss: 0.900258
global_step: 34352, epoch: 59, loss: 0.938746
global_step: 34353, epoch: 59, loss: 0.860443
global_step: 34354, epoch: 59, loss: 0.835145
global_step: 34355, epoch: 59, loss: 0.844392
global_step: 34356, epoch: 59, loss: 0.809760
global_step: 34357, epoch: 59, loss: 0.826360
global_step: 34358, epoch: 59, loss: 0.868441
global_step: 34359, epoch: 59, loss: 0.876397
global_step: 34360, epoch: 59, loss: 0.363994
epoch: 59
train	acc: 0.7445	macro: p 0.4991, r 0.4582, f1: 0.4667	micro: p 0.7445, r 0.7445, f1 0.7445	weighted_f1:0.7099
dev	acc: 0.5735	macro: p 0.3792, r 0.3289, f1: 0.3252	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5210
test	acc: 0.6096	macro: p 0.3585, r 0.3274, f1: 0.3237	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5622
global_step: 34361, epoch: 60, loss: 0.916029
global_step: 34362, epoch: 60, loss: 0.805427
global_step: 34363, epoch: 60, loss: 0.799750
global_step: 34364, epoch: 60, loss: 0.801430
global_step: 34365, epoch: 60, loss: 0.867870
global_step: 34366, epoch: 60, loss: 0.853475
global_step: 34367, epoch: 60, loss: 0.843501
global_step: 34368, epoch: 60, loss: 0.829219
global_step: 34369, epoch: 60, loss: 0.851455
global_step: 34370, epoch: 60, loss: 0.932163
global_step: 34371, epoch: 60, loss: 0.833651
global_step: 34372, epoch: 60, loss: 0.802861
global_step: 34373, epoch: 60, loss: 0.952312
global_step: 34374, epoch: 60, loss: 0.876797
global_step: 34375, epoch: 60, loss: 0.795147
global_step: 34376, epoch: 60, loss: 0.873263
global_step: 34377, epoch: 60, loss: 0.891626
global_step: 34378, epoch: 60, loss: 0.890687
global_step: 34379, epoch: 60, loss: 0.880825
global_step: 34380, epoch: 60, loss: 0.834674
global_step: 34381, epoch: 60, loss: 0.820188
global_step: 34382, epoch: 60, loss: 0.823257
global_step: 34383, epoch: 60, loss: 0.866360
global_step: 34384, epoch: 60, loss: 0.860254
global_step: 34385, epoch: 60, loss: 0.823664
global_step: 34386, epoch: 60, loss: 0.805659
global_step: 34387, epoch: 60, loss: 0.850113
global_step: 34388, epoch: 60, loss: 0.944365
global_step: 34389, epoch: 60, loss: 0.825315
global_step: 34390, epoch: 60, loss: 0.877869
global_step: 34391, epoch: 60, loss: 0.851653
global_step: 34392, epoch: 60, loss: 0.824977
global_step: 34393, epoch: 60, loss: 0.892264
global_step: 34394, epoch: 60, loss: 0.923384
global_step: 34395, epoch: 60, loss: 0.899189
global_step: 34396, epoch: 60, loss: 0.772764
global_step: 34397, epoch: 60, loss: 0.702827
global_step: 34398, epoch: 60, loss: 0.894127
global_step: 34399, epoch: 60, loss: 0.848049
global_step: 34400, epoch: 60, loss: 0.903450
epoch: 60
train	acc: 0.7748	macro: p 0.5038, r 0.5122, f1: 0.5063	micro: p 0.7748, r 0.7748, f1 0.7748	weighted_f1:0.7511
dev	acc: 0.5753	macro: p 0.3584, r 0.3503, f1: 0.3484	micro: p 0.5753, r 0.5753, f1 0.5753	weighted_f1:0.5431
test	acc: 0.6080	macro: p 0.3601, r 0.3521, f1: 0.3519	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5805
global_step: 34401, epoch: 61, loss: 0.804399
global_step: 34402, epoch: 61, loss: 0.895836
global_step: 34403, epoch: 61, loss: 0.806445
global_step: 34404, epoch: 61, loss: 0.858323
global_step: 34405, epoch: 61, loss: 0.920091
global_step: 34406, epoch: 61, loss: 0.764081
global_step: 34407, epoch: 61, loss: 0.857575
global_step: 34408, epoch: 61, loss: 0.907997
global_step: 34409, epoch: 61, loss: 0.833889
global_step: 34410, epoch: 61, loss: 0.873877
global_step: 34411, epoch: 61, loss: 0.846358
global_step: 34412, epoch: 61, loss: 0.905575
global_step: 34413, epoch: 61, loss: 0.908460
global_step: 34414, epoch: 61, loss: 0.817609
global_step: 34415, epoch: 61, loss: 0.749262
global_step: 34416, epoch: 61, loss: 0.779552
global_step: 34417, epoch: 61, loss: 0.819425
global_step: 34418, epoch: 61, loss: 0.752918
global_step: 34419, epoch: 61, loss: 0.927817
global_step: 34420, epoch: 61, loss: 0.884138
global_step: 34421, epoch: 61, loss: 0.806583
global_step: 34422, epoch: 61, loss: 0.909521
global_step: 34423, epoch: 61, loss: 0.789717
global_step: 34424, epoch: 61, loss: 0.868380
global_step: 34425, epoch: 61, loss: 0.918332
global_step: 34426, epoch: 61, loss: 0.839245
global_step: 34427, epoch: 61, loss: 0.848489
global_step: 34428, epoch: 61, loss: 0.923751
global_step: 34429, epoch: 61, loss: 0.795169
global_step: 34430, epoch: 61, loss: 0.819981
global_step: 34431, epoch: 61, loss: 0.792790
global_step: 34432, epoch: 61, loss: 0.812964
global_step: 34433, epoch: 61, loss: 0.872433
global_step: 34434, epoch: 61, loss: 0.807963
global_step: 34435, epoch: 61, loss: 0.844278
global_step: 34436, epoch: 61, loss: 0.827380
global_step: 34437, epoch: 61, loss: 0.858300
global_step: 34438, epoch: 61, loss: 0.757379
global_step: 34439, epoch: 61, loss: 0.851198
global_step: 34440, epoch: 61, loss: 1.931245
epoch: 61
train	acc: 0.7670	macro: p 0.6480, r 0.4954, f1: 0.4989	micro: p 0.7670, r 0.7670, f1 0.7670	weighted_f1:0.7388
dev	acc: 0.5744	macro: p 0.3628, r 0.3361, f1: 0.3361	micro: p 0.5744, r 0.5744, f1 0.5744	weighted_f1:0.5291
test	acc: 0.6119	macro: p 0.5023, r 0.3382, f1: 0.3424	micro: p 0.6119, r 0.6119, f1 0.6119	weighted_f1:0.5725
global_step: 34441, epoch: 62, loss: 0.905861
global_step: 34442, epoch: 62, loss: 0.829883
global_step: 34443, epoch: 62, loss: 0.919250
global_step: 34444, epoch: 62, loss: 0.834660
global_step: 34445, epoch: 62, loss: 0.822946
global_step: 34446, epoch: 62, loss: 0.763547
global_step: 34447, epoch: 62, loss: 0.713462
global_step: 34448, epoch: 62, loss: 0.777820
global_step: 34449, epoch: 62, loss: 0.908323
global_step: 34450, epoch: 62, loss: 0.902031
global_step: 34451, epoch: 62, loss: 0.795249
global_step: 34452, epoch: 62, loss: 0.833607
global_step: 34453, epoch: 62, loss: 0.862181
global_step: 34454, epoch: 62, loss: 0.808499
global_step: 34455, epoch: 62, loss: 0.764250
global_step: 34456, epoch: 62, loss: 0.859769
global_step: 34457, epoch: 62, loss: 0.852022
global_step: 34458, epoch: 62, loss: 0.843405
global_step: 34459, epoch: 62, loss: 0.816846
global_step: 34460, epoch: 62, loss: 0.864005
global_step: 34461, epoch: 62, loss: 0.831781
global_step: 34462, epoch: 62, loss: 0.790094
global_step: 34463, epoch: 62, loss: 0.830337
global_step: 34464, epoch: 62, loss: 0.787286
global_step: 34465, epoch: 62, loss: 0.856106
global_step: 34466, epoch: 62, loss: 0.787875
global_step: 34467, epoch: 62, loss: 0.848600
global_step: 34468, epoch: 62, loss: 0.822779
global_step: 34469, epoch: 62, loss: 0.835473
global_step: 34470, epoch: 62, loss: 0.859867
global_step: 34471, epoch: 62, loss: 0.871015
global_step: 34472, epoch: 62, loss: 0.784938
global_step: 34473, epoch: 62, loss: 0.877043
global_step: 34474, epoch: 62, loss: 0.824998
global_step: 34475, epoch: 62, loss: 0.907667
global_step: 34476, epoch: 62, loss: 0.770033
global_step: 34477, epoch: 62, loss: 0.740773
global_step: 34478, epoch: 62, loss: 0.892083
global_step: 34479, epoch: 62, loss: 0.836197
global_step: 34480, epoch: 62, loss: 0.153145
epoch: 62
train	acc: 0.7506	macro: p 0.5057, r 0.4623, f1: 0.4723	micro: p 0.7506, r 0.7506, f1 0.7506	weighted_f1:0.7156
dev	acc: 0.5663	macro: p 0.3767, r 0.3203, f1: 0.3170	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5124
test	acc: 0.6100	macro: p 0.5057, r 0.3277, f1: 0.3283	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5622
global_step: 34481, epoch: 63, loss: 0.928713
global_step: 34482, epoch: 63, loss: 0.865974
global_step: 34483, epoch: 63, loss: 0.925467
global_step: 34484, epoch: 63, loss: 0.869851
global_step: 34485, epoch: 63, loss: 0.830890
global_step: 34486, epoch: 63, loss: 0.807095
global_step: 34487, epoch: 63, loss: 0.793445
global_step: 34488, epoch: 63, loss: 0.787931
global_step: 34489, epoch: 63, loss: 0.877185
global_step: 34490, epoch: 63, loss: 0.834087
global_step: 34491, epoch: 63, loss: 0.690870
global_step: 34492, epoch: 63, loss: 0.819219
global_step: 34493, epoch: 63, loss: 0.707142
global_step: 34494, epoch: 63, loss: 0.865581
global_step: 34495, epoch: 63, loss: 0.814477
global_step: 34496, epoch: 63, loss: 0.736544
global_step: 34497, epoch: 63, loss: 0.851168
global_step: 34498, epoch: 63, loss: 0.792802
global_step: 34499, epoch: 63, loss: 0.849030
global_step: 34500, epoch: 63, loss: 0.760232
global_step: 34501, epoch: 63, loss: 0.807375
global_step: 34502, epoch: 63, loss: 0.870577
global_step: 34503, epoch: 63, loss: 0.823975
global_step: 34504, epoch: 63, loss: 0.804617
global_step: 34505, epoch: 63, loss: 0.865215
global_step: 34506, epoch: 63, loss: 0.892180
global_step: 34507, epoch: 63, loss: 0.756217
global_step: 34508, epoch: 63, loss: 0.758675
global_step: 34509, epoch: 63, loss: 0.842399
global_step: 34510, epoch: 63, loss: 0.824294
global_step: 34511, epoch: 63, loss: 0.843691
global_step: 34512, epoch: 63, loss: 0.915382
global_step: 34513, epoch: 63, loss: 0.755683
global_step: 34514, epoch: 63, loss: 0.764305
global_step: 34515, epoch: 63, loss: 0.839567
global_step: 34516, epoch: 63, loss: 0.805670
global_step: 34517, epoch: 63, loss: 0.901029
global_step: 34518, epoch: 63, loss: 0.783493
global_step: 34519, epoch: 63, loss: 0.847762
global_step: 34520, epoch: 63, loss: 0.687393
epoch: 63
train	acc: 0.7802	macro: p 0.6527, r 0.5124, f1: 0.5097	micro: p 0.7802, r 0.7802, f1 0.7802	weighted_f1:0.7532
dev	acc: 0.5771	macro: p 0.3570, r 0.3453, f1: 0.3398	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5344
test	acc: 0.6065	macro: p 0.4937, r 0.3429, f1: 0.3419	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5714
global_step: 34521, epoch: 64, loss: 0.763418
global_step: 34522, epoch: 64, loss: 0.735217
global_step: 34523, epoch: 64, loss: 0.773486
global_step: 34524, epoch: 64, loss: 0.886806
global_step: 34525, epoch: 64, loss: 0.783998
global_step: 34526, epoch: 64, loss: 0.835067
global_step: 34527, epoch: 64, loss: 0.842960
global_step: 34528, epoch: 64, loss: 0.747445
global_step: 34529, epoch: 64, loss: 0.840049
global_step: 34530, epoch: 64, loss: 0.828402
global_step: 34531, epoch: 64, loss: 0.758593
global_step: 34532, epoch: 64, loss: 0.802386
global_step: 34533, epoch: 64, loss: 0.801961
global_step: 34534, epoch: 64, loss: 0.713487
global_step: 34535, epoch: 64, loss: 0.868616
global_step: 34536, epoch: 64, loss: 0.842374
global_step: 34537, epoch: 64, loss: 0.796286
global_step: 34538, epoch: 64, loss: 0.868350
global_step: 34539, epoch: 64, loss: 0.854834
global_step: 34540, epoch: 64, loss: 0.860387
global_step: 34541, epoch: 64, loss: 0.883785
global_step: 34542, epoch: 64, loss: 0.670880
global_step: 34543, epoch: 64, loss: 0.762776
global_step: 34544, epoch: 64, loss: 0.855162
global_step: 34545, epoch: 64, loss: 0.805793
global_step: 34546, epoch: 64, loss: 0.943898
global_step: 34547, epoch: 64, loss: 0.913203
global_step: 34548, epoch: 64, loss: 0.779024
global_step: 34549, epoch: 64, loss: 0.855028
global_step: 34550, epoch: 64, loss: 0.863254
global_step: 34551, epoch: 64, loss: 0.706316
global_step: 34552, epoch: 64, loss: 0.817903
global_step: 34553, epoch: 64, loss: 0.719623
global_step: 34554, epoch: 64, loss: 0.766813
global_step: 34555, epoch: 64, loss: 0.827650
global_step: 34556, epoch: 64, loss: 0.846904
global_step: 34557, epoch: 64, loss: 0.850615
global_step: 34558, epoch: 64, loss: 0.840789
global_step: 34559, epoch: 64, loss: 0.795657
global_step: 34560, epoch: 64, loss: 0.625388
epoch: 64
train	acc: 0.7636	macro: p 0.6612, r 0.4795, f1: 0.4877	micro: p 0.7636, r 0.7636, f1 0.7636	weighted_f1:0.7303
dev	acc: 0.5717	macro: p 0.3833, r 0.3266, f1: 0.3252	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5186
test	acc: 0.6130	macro: p 0.3631, r 0.3281, f1: 0.3283	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5656
global_step: 34561, epoch: 65, loss: 0.866484
global_step: 34562, epoch: 65, loss: 0.795858
global_step: 34563, epoch: 65, loss: 0.858948
global_step: 34564, epoch: 65, loss: 0.852716
global_step: 34565, epoch: 65, loss: 0.834373
global_step: 34566, epoch: 65, loss: 0.759367
global_step: 34567, epoch: 65, loss: 0.752437
global_step: 34568, epoch: 65, loss: 0.769551
global_step: 34569, epoch: 65, loss: 0.867428
global_step: 34570, epoch: 65, loss: 0.935908
global_step: 34571, epoch: 65, loss: 0.864315
global_step: 34572, epoch: 65, loss: 0.931307
global_step: 34573, epoch: 65, loss: 0.820524
global_step: 34574, epoch: 65, loss: 0.804506
global_step: 34575, epoch: 65, loss: 0.749992
global_step: 34576, epoch: 65, loss: 0.735573
global_step: 34577, epoch: 65, loss: 0.750692
global_step: 34578, epoch: 65, loss: 1.002911
global_step: 34579, epoch: 65, loss: 0.729506
global_step: 34580, epoch: 65, loss: 0.833257
global_step: 34581, epoch: 65, loss: 0.725998
global_step: 34582, epoch: 65, loss: 0.736876
global_step: 34583, epoch: 65, loss: 0.784651
global_step: 34584, epoch: 65, loss: 0.828185
global_step: 34585, epoch: 65, loss: 0.732733
global_step: 34586, epoch: 65, loss: 0.764730
global_step: 34587, epoch: 65, loss: 0.712235
global_step: 34588, epoch: 65, loss: 0.880435
global_step: 34589, epoch: 65, loss: 0.760034
global_step: 34590, epoch: 65, loss: 0.733768
global_step: 34591, epoch: 65, loss: 0.818431
global_step: 34592, epoch: 65, loss: 0.761852
global_step: 34593, epoch: 65, loss: 0.729329
global_step: 34594, epoch: 65, loss: 0.846054
global_step: 34595, epoch: 65, loss: 0.842306
global_step: 34596, epoch: 65, loss: 0.807393
global_step: 34597, epoch: 65, loss: 0.800715
global_step: 34598, epoch: 65, loss: 0.815859
global_step: 34599, epoch: 65, loss: 0.857189
global_step: 34600, epoch: 65, loss: 0.513099
epoch: 65
train	acc: 0.7857	macro: p 0.6643, r 0.5135, f1: 0.5137	micro: p 0.7857, r 0.7857, f1 0.7857	weighted_f1:0.7585
dev	acc: 0.5771	macro: p 0.3677, r 0.3454, f1: 0.3432	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5377
test	acc: 0.6103	macro: p 0.3620, r 0.3418, f1: 0.3402	micro: p 0.6103, r 0.6103, f1 0.6103	weighted_f1:0.5739
global_step: 34601, epoch: 66, loss: 0.834072
global_step: 34602, epoch: 66, loss: 0.856063
global_step: 34603, epoch: 66, loss: 0.804682
global_step: 34604, epoch: 66, loss: 0.817220
global_step: 34605, epoch: 66, loss: 0.749425
global_step: 34606, epoch: 66, loss: 0.788401
global_step: 34607, epoch: 66, loss: 0.729887
global_step: 34608, epoch: 66, loss: 0.754873
global_step: 34609, epoch: 66, loss: 0.823221
global_step: 34610, epoch: 66, loss: 0.727058
global_step: 34611, epoch: 66, loss: 0.871995
global_step: 34612, epoch: 66, loss: 0.866453
global_step: 34613, epoch: 66, loss: 0.731959
global_step: 34614, epoch: 66, loss: 0.782585
global_step: 34615, epoch: 66, loss: 0.831280
global_step: 34616, epoch: 66, loss: 0.712486
global_step: 34617, epoch: 66, loss: 0.685536
global_step: 34618, epoch: 66, loss: 0.808202
global_step: 34619, epoch: 66, loss: 0.836849
global_step: 34620, epoch: 66, loss: 0.759490
global_step: 34621, epoch: 66, loss: 0.800133
global_step: 34622, epoch: 66, loss: 0.833113
global_step: 34623, epoch: 66, loss: 0.865608
global_step: 34624, epoch: 66, loss: 0.877753
global_step: 34625, epoch: 66, loss: 0.802210
global_step: 34626, epoch: 66, loss: 0.841958
global_step: 34627, epoch: 66, loss: 0.638668
global_step: 34628, epoch: 66, loss: 0.861269
global_step: 34629, epoch: 66, loss: 0.778300
global_step: 34630, epoch: 66, loss: 0.815302
global_step: 34631, epoch: 66, loss: 0.792348
global_step: 34632, epoch: 66, loss: 0.877157
global_step: 34633, epoch: 66, loss: 0.866535
global_step: 34634, epoch: 66, loss: 0.768916
global_step: 34635, epoch: 66, loss: 0.703773
global_step: 34636, epoch: 66, loss: 0.710312
global_step: 34637, epoch: 66, loss: 0.814627
global_step: 34638, epoch: 66, loss: 0.801434
global_step: 34639, epoch: 66, loss: 0.709652
global_step: 34640, epoch: 66, loss: 0.486151
epoch: 66
train	acc: 0.7272	macro: p 0.5185, r 0.4306, f1: 0.4482	micro: p 0.7272, r 0.7272, f1 0.7272	weighted_f1:0.6862
dev	acc: 0.5582	macro: p 0.3789, r 0.3047, f1: 0.3022	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4936
test	acc: 0.6130	macro: p 0.3817, r 0.3104, f1: 0.3149	micro: p 0.6130, r 0.6130, f1 0.6130	weighted_f1:0.5543
global_step: 34641, epoch: 67, loss: 0.992882
global_step: 34642, epoch: 67, loss: 0.839256
global_step: 34643, epoch: 67, loss: 0.702935
global_step: 34644, epoch: 67, loss: 0.859732
global_step: 34645, epoch: 67, loss: 0.683969
global_step: 34646, epoch: 67, loss: 0.769605
global_step: 34647, epoch: 67, loss: 0.695918
global_step: 34648, epoch: 67, loss: 0.708785
global_step: 34649, epoch: 67, loss: 0.807758
global_step: 34650, epoch: 67, loss: 0.664397
global_step: 34651, epoch: 67, loss: 0.700158
global_step: 34652, epoch: 67, loss: 0.795293
global_step: 34653, epoch: 67, loss: 0.896746
global_step: 34654, epoch: 67, loss: 0.725841
global_step: 34655, epoch: 67, loss: 0.863122
global_step: 34656, epoch: 67, loss: 0.884425
global_step: 34657, epoch: 67, loss: 0.804867
global_step: 34658, epoch: 67, loss: 0.769482
global_step: 34659, epoch: 67, loss: 0.728542
global_step: 34660, epoch: 67, loss: 0.758549
global_step: 34661, epoch: 67, loss: 0.783034
global_step: 34662, epoch: 67, loss: 0.810446
global_step: 34663, epoch: 67, loss: 0.819663
global_step: 34664, epoch: 67, loss: 0.795851
global_step: 34665, epoch: 67, loss: 0.839130
global_step: 34666, epoch: 67, loss: 0.757126
global_step: 34667, epoch: 67, loss: 0.901924
global_step: 34668, epoch: 67, loss: 0.794662
global_step: 34669, epoch: 67, loss: 0.717846
global_step: 34670, epoch: 67, loss: 0.800959
global_step: 34671, epoch: 67, loss: 0.781805
global_step: 34672, epoch: 67, loss: 0.773250
global_step: 34673, epoch: 67, loss: 0.851511
global_step: 34674, epoch: 67, loss: 0.850198
global_step: 34675, epoch: 67, loss: 0.769843
global_step: 34676, epoch: 67, loss: 0.711801
global_step: 34677, epoch: 67, loss: 0.694320
global_step: 34678, epoch: 67, loss: 0.827877
global_step: 34679, epoch: 67, loss: 0.770762
global_step: 34680, epoch: 67, loss: 1.297958
epoch: 67
train	acc: 0.7908	macro: p 0.6694, r 0.5244, f1: 0.5239	micro: p 0.7908, r 0.7908, f1 0.7908	weighted_f1:0.7649
dev	acc: 0.5735	macro: p 0.3598, r 0.3381, f1: 0.3375	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5324
test	acc: 0.6077	macro: p 0.3515, r 0.3368, f1: 0.3363	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5712
global_step: 34681, epoch: 68, loss: 0.746641
global_step: 34682, epoch: 68, loss: 0.824118
global_step: 34683, epoch: 68, loss: 0.700133
global_step: 34684, epoch: 68, loss: 0.703459
global_step: 34685, epoch: 68, loss: 0.758754
global_step: 34686, epoch: 68, loss: 0.847248
global_step: 34687, epoch: 68, loss: 0.783666
global_step: 34688, epoch: 68, loss: 0.709293
global_step: 34689, epoch: 68, loss: 0.808875
global_step: 34690, epoch: 68, loss: 0.854126
global_step: 34691, epoch: 68, loss: 0.733605
global_step: 34692, epoch: 68, loss: 0.849219
global_step: 34693, epoch: 68, loss: 0.788883
global_step: 34694, epoch: 68, loss: 0.729176
global_step: 34695, epoch: 68, loss: 0.798234
global_step: 34696, epoch: 68, loss: 0.840292
global_step: 34697, epoch: 68, loss: 0.751888
global_step: 34698, epoch: 68, loss: 0.753175
global_step: 34699, epoch: 68, loss: 0.893997
global_step: 34700, epoch: 68, loss: 0.778132
global_step: 34701, epoch: 68, loss: 0.776943
global_step: 34702, epoch: 68, loss: 0.773765
global_step: 34703, epoch: 68, loss: 0.739655
global_step: 34704, epoch: 68, loss: 0.823030
global_step: 34705, epoch: 68, loss: 0.806524
global_step: 34706, epoch: 68, loss: 0.740376
global_step: 34707, epoch: 68, loss: 0.842566
global_step: 34708, epoch: 68, loss: 0.784643
global_step: 34709, epoch: 68, loss: 0.691492
global_step: 34710, epoch: 68, loss: 0.722472
global_step: 34711, epoch: 68, loss: 0.806263
global_step: 34712, epoch: 68, loss: 0.767922
global_step: 34713, epoch: 68, loss: 0.788649
global_step: 34714, epoch: 68, loss: 0.750254
global_step: 34715, epoch: 68, loss: 0.727638
global_step: 34716, epoch: 68, loss: 0.793460
global_step: 34717, epoch: 68, loss: 0.794091
global_step: 34718, epoch: 68, loss: 0.781163
global_step: 34719, epoch: 68, loss: 0.748289
global_step: 34720, epoch: 68, loss: 1.084784
epoch: 68
train	acc: 0.8056	macro: p 0.6722, r 0.5480, f1: 0.5395	micro: p 0.8056, r 0.8056, f1 0.8056	weighted_f1:0.7824
dev	acc: 0.5771	macro: p 0.3549, r 0.3533, f1: 0.3490	micro: p 0.5771, r 0.5771, f1 0.5771	weighted_f1:0.5430
test	acc: 0.6031	macro: p 0.3492, r 0.3448, f1: 0.3419	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5734
global_step: 34721, epoch: 69, loss: 0.751302
global_step: 34722, epoch: 69, loss: 0.800402
global_step: 34723, epoch: 69, loss: 0.774395
global_step: 34724, epoch: 69, loss: 0.701884
global_step: 34725, epoch: 69, loss: 0.788074
global_step: 34726, epoch: 69, loss: 0.786076
global_step: 34727, epoch: 69, loss: 0.766817
global_step: 34728, epoch: 69, loss: 0.849243
global_step: 34729, epoch: 69, loss: 0.763622
global_step: 34730, epoch: 69, loss: 0.752338
global_step: 34731, epoch: 69, loss: 0.720892
global_step: 34732, epoch: 69, loss: 0.841320
global_step: 34733, epoch: 69, loss: 0.741648
global_step: 34734, epoch: 69, loss: 0.791368
global_step: 34735, epoch: 69, loss: 0.764712
global_step: 34736, epoch: 69, loss: 0.757890
global_step: 34737, epoch: 69, loss: 0.744209
global_step: 34738, epoch: 69, loss: 0.767079
global_step: 34739, epoch: 69, loss: 0.682538
global_step: 34740, epoch: 69, loss: 0.779211
global_step: 34741, epoch: 69, loss: 0.819670
global_step: 34742, epoch: 69, loss: 0.700441
global_step: 34743, epoch: 69, loss: 0.756937
global_step: 34744, epoch: 69, loss: 0.853362
global_step: 34745, epoch: 69, loss: 0.706270
global_step: 34746, epoch: 69, loss: 0.729459
global_step: 34747, epoch: 69, loss: 0.774342
global_step: 34748, epoch: 69, loss: 0.755110
global_step: 34749, epoch: 69, loss: 0.748362
global_step: 34750, epoch: 69, loss: 0.822564
global_step: 34751, epoch: 69, loss: 0.813118
global_step: 34752, epoch: 69, loss: 0.699523
global_step: 34753, epoch: 69, loss: 0.787679
global_step: 34754, epoch: 69, loss: 0.685089
global_step: 34755, epoch: 69, loss: 0.842358
global_step: 34756, epoch: 69, loss: 0.694710
global_step: 34757, epoch: 69, loss: 0.780763
global_step: 34758, epoch: 69, loss: 0.789645
global_step: 34759, epoch: 69, loss: 0.741837
global_step: 34760, epoch: 69, loss: 0.330283
epoch: 69
train	acc: 0.7605	macro: p 0.6714, r 0.4768, f1: 0.4930	micro: p 0.7605, r 0.7605, f1 0.7605	weighted_f1:0.7274
dev	acc: 0.5681	macro: p 0.3779, r 0.3176, f1: 0.3170	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5097
test	acc: 0.6115	macro: p 0.5030, r 0.3184, f1: 0.3227	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5581
global_step: 34761, epoch: 70, loss: 0.717696
global_step: 34762, epoch: 70, loss: 0.759174
global_step: 34763, epoch: 70, loss: 0.755907
global_step: 34764, epoch: 70, loss: 0.828449
global_step: 34765, epoch: 70, loss: 0.769811
global_step: 34766, epoch: 70, loss: 0.794831
global_step: 34767, epoch: 70, loss: 0.659991
global_step: 34768, epoch: 70, loss: 0.788827
global_step: 34769, epoch: 70, loss: 0.697074
global_step: 34770, epoch: 70, loss: 0.721972
global_step: 34771, epoch: 70, loss: 0.819169
global_step: 34772, epoch: 70, loss: 0.704037
global_step: 34773, epoch: 70, loss: 0.743240
global_step: 34774, epoch: 70, loss: 0.666780
global_step: 34775, epoch: 70, loss: 0.716630
global_step: 34776, epoch: 70, loss: 0.907541
global_step: 34777, epoch: 70, loss: 0.782822
global_step: 34778, epoch: 70, loss: 0.688324
global_step: 34779, epoch: 70, loss: 0.836574
global_step: 34780, epoch: 70, loss: 0.712286
global_step: 34781, epoch: 70, loss: 0.735745
global_step: 34782, epoch: 70, loss: 0.736117
global_step: 34783, epoch: 70, loss: 0.850933
global_step: 34784, epoch: 70, loss: 0.812385
global_step: 34785, epoch: 70, loss: 0.858147
global_step: 34786, epoch: 70, loss: 0.870376
global_step: 34787, epoch: 70, loss: 0.856607
global_step: 34788, epoch: 70, loss: 0.776170
global_step: 34789, epoch: 70, loss: 0.775739
global_step: 34790, epoch: 70, loss: 0.643631
global_step: 34791, epoch: 70, loss: 0.859990
global_step: 34792, epoch: 70, loss: 0.761587
global_step: 34793, epoch: 70, loss: 0.793571
global_step: 34794, epoch: 70, loss: 0.714988
global_step: 34795, epoch: 70, loss: 0.768987
global_step: 34796, epoch: 70, loss: 0.884650
global_step: 34797, epoch: 70, loss: 0.835186
global_step: 34798, epoch: 70, loss: 0.700821
global_step: 34799, epoch: 70, loss: 0.725710
global_step: 34800, epoch: 70, loss: 0.939414
epoch: 70
train	acc: 0.8126	macro: p 0.6563, r 0.5654, f1: 0.5524	micro: p 0.8126, r 0.8126, f1 0.8126	weighted_f1:0.7912
dev	acc: 0.5573	macro: p 0.3378, r 0.3485, f1: 0.3373	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5279
test	acc: 0.5920	macro: p 0.4836, r 0.3570, f1: 0.3479	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5709
global_step: 34801, epoch: 71, loss: 0.672234
global_step: 34802, epoch: 71, loss: 0.674829
global_step: 34803, epoch: 71, loss: 0.695597
global_step: 34804, epoch: 71, loss: 0.683265
global_step: 34805, epoch: 71, loss: 0.759793
global_step: 34806, epoch: 71, loss: 0.804760
global_step: 34807, epoch: 71, loss: 0.869406
global_step: 34808, epoch: 71, loss: 0.801202
global_step: 34809, epoch: 71, loss: 0.703316
global_step: 34810, epoch: 71, loss: 0.707890
global_step: 34811, epoch: 71, loss: 0.800371
global_step: 34812, epoch: 71, loss: 0.722255
global_step: 34813, epoch: 71, loss: 0.747816
global_step: 34814, epoch: 71, loss: 0.739722
global_step: 34815, epoch: 71, loss: 0.592886
global_step: 34816, epoch: 71, loss: 0.791350
global_step: 34817, epoch: 71, loss: 0.763760
global_step: 34818, epoch: 71, loss: 0.800060
global_step: 34819, epoch: 71, loss: 0.727870
global_step: 34820, epoch: 71, loss: 0.793055
global_step: 34821, epoch: 71, loss: 0.838369
global_step: 34822, epoch: 71, loss: 0.754684
global_step: 34823, epoch: 71, loss: 0.702418
global_step: 34824, epoch: 71, loss: 0.639197
global_step: 34825, epoch: 71, loss: 0.748240
global_step: 34826, epoch: 71, loss: 0.725220
global_step: 34827, epoch: 71, loss: 0.763811
global_step: 34828, epoch: 71, loss: 0.611486
global_step: 34829, epoch: 71, loss: 0.857849
global_step: 34830, epoch: 71, loss: 0.663462
global_step: 34831, epoch: 71, loss: 0.870533
global_step: 34832, epoch: 71, loss: 0.792164
global_step: 34833, epoch: 71, loss: 0.755190
global_step: 34834, epoch: 71, loss: 0.825504
global_step: 34835, epoch: 71, loss: 0.775606
global_step: 34836, epoch: 71, loss: 0.738814
global_step: 34837, epoch: 71, loss: 0.717108
global_step: 34838, epoch: 71, loss: 0.859332
global_step: 34839, epoch: 71, loss: 0.770911
global_step: 34840, epoch: 71, loss: 1.513718
epoch: 71
train	acc: 0.8161	macro: p 0.7358, r 0.5627, f1: 0.5559	micro: p 0.8161, r 0.8161, f1 0.8161	weighted_f1:0.7933
dev	acc: 0.5627	macro: p 0.3394, r 0.3430, f1: 0.3336	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5275
test	acc: 0.5973	macro: p 0.3450, r 0.3470, f1: 0.3392	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5684
global_step: 34841, epoch: 72, loss: 0.823501
global_step: 34842, epoch: 72, loss: 0.783371
global_step: 34843, epoch: 72, loss: 0.770140
global_step: 34844, epoch: 72, loss: 0.766423
global_step: 34845, epoch: 72, loss: 0.702057
global_step: 34846, epoch: 72, loss: 0.686638
global_step: 34847, epoch: 72, loss: 0.610290
global_step: 34848, epoch: 72, loss: 0.818772
global_step: 34849, epoch: 72, loss: 0.658149
global_step: 34850, epoch: 72, loss: 0.748112
global_step: 34851, epoch: 72, loss: 0.687989
global_step: 34852, epoch: 72, loss: 0.758815
global_step: 34853, epoch: 72, loss: 0.714305
global_step: 34854, epoch: 72, loss: 0.774834
global_step: 34855, epoch: 72, loss: 0.761149
global_step: 34856, epoch: 72, loss: 0.742791
global_step: 34857, epoch: 72, loss: 0.762327
global_step: 34858, epoch: 72, loss: 0.759963
global_step: 34859, epoch: 72, loss: 0.651729
global_step: 34860, epoch: 72, loss: 0.745393
global_step: 34861, epoch: 72, loss: 0.795183
global_step: 34862, epoch: 72, loss: 0.843440
global_step: 34863, epoch: 72, loss: 0.687551
global_step: 34864, epoch: 72, loss: 0.822653
global_step: 34865, epoch: 72, loss: 0.704925
global_step: 34866, epoch: 72, loss: 0.740820
global_step: 34867, epoch: 72, loss: 0.837549
global_step: 34868, epoch: 72, loss: 0.732535
global_step: 34869, epoch: 72, loss: 0.781436
global_step: 34870, epoch: 72, loss: 0.782283
global_step: 34871, epoch: 72, loss: 0.728035
global_step: 34872, epoch: 72, loss: 0.629345
global_step: 34873, epoch: 72, loss: 0.770401
global_step: 34874, epoch: 72, loss: 0.800012
global_step: 34875, epoch: 72, loss: 0.621177
global_step: 34876, epoch: 72, loss: 0.705248
global_step: 34877, epoch: 72, loss: 0.689538
global_step: 34878, epoch: 72, loss: 0.652818
global_step: 34879, epoch: 72, loss: 0.699278
global_step: 34880, epoch: 72, loss: 1.117457
epoch: 72
train	acc: 0.8168	macro: p 0.8052, r 0.5641, f1: 0.5549	micro: p 0.8168, r 0.8168, f1 0.8168	weighted_f1:0.7943
dev	acc: 0.5663	macro: p 0.3424, r 0.3479, f1: 0.3388	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5329
test	acc: 0.6023	macro: p 0.4915, r 0.3562, f1: 0.3488	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5758
global_step: 34881, epoch: 73, loss: 0.830219
global_step: 34882, epoch: 73, loss: 0.666080
global_step: 34883, epoch: 73, loss: 0.757053
global_step: 34884, epoch: 73, loss: 0.598730
global_step: 34885, epoch: 73, loss: 0.732901
global_step: 34886, epoch: 73, loss: 0.717613
global_step: 34887, epoch: 73, loss: 0.741444
global_step: 34888, epoch: 73, loss: 0.744890
global_step: 34889, epoch: 73, loss: 0.872233
global_step: 34890, epoch: 73, loss: 0.775575
global_step: 34891, epoch: 73, loss: 0.728256
global_step: 34892, epoch: 73, loss: 0.681922
global_step: 34893, epoch: 73, loss: 0.781344
global_step: 34894, epoch: 73, loss: 0.714583
global_step: 34895, epoch: 73, loss: 0.791859
global_step: 34896, epoch: 73, loss: 0.812115
global_step: 34897, epoch: 73, loss: 0.760506
global_step: 34898, epoch: 73, loss: 0.751482
global_step: 34899, epoch: 73, loss: 0.680528
global_step: 34900, epoch: 73, loss: 0.644873
global_step: 34901, epoch: 73, loss: 0.790209
global_step: 34902, epoch: 73, loss: 0.720490
global_step: 34903, epoch: 73, loss: 0.730156
global_step: 34904, epoch: 73, loss: 0.591802
global_step: 34905, epoch: 73, loss: 0.757582
global_step: 34906, epoch: 73, loss: 0.836190
global_step: 34907, epoch: 73, loss: 0.671219
global_step: 34908, epoch: 73, loss: 0.768775
global_step: 34909, epoch: 73, loss: 0.660507
global_step: 34910, epoch: 73, loss: 0.762327
global_step: 34911, epoch: 73, loss: 0.780045
global_step: 34912, epoch: 73, loss: 0.732507
global_step: 34913, epoch: 73, loss: 0.779445
global_step: 34914, epoch: 73, loss: 0.730767
global_step: 34915, epoch: 73, loss: 0.671592
global_step: 34916, epoch: 73, loss: 0.726222
global_step: 34917, epoch: 73, loss: 0.732839
global_step: 34918, epoch: 73, loss: 0.733558
global_step: 34919, epoch: 73, loss: 0.820970
global_step: 34920, epoch: 73, loss: 0.679565
epoch: 73
train	acc: 0.7938	macro: p 0.6840, r 0.5221, f1: 0.5330	micro: p 0.7938, r 0.7938, f1 0.7938	weighted_f1:0.7656
dev	acc: 0.5609	macro: p 0.3653, r 0.3176, f1: 0.3164	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5092
test	acc: 0.6123	macro: p 0.5063, r 0.3306, f1: 0.3347	micro: p 0.6123, r 0.6123, f1 0.6123	weighted_f1:0.5671
global_step: 34921, epoch: 74, loss: 0.786707
global_step: 34922, epoch: 74, loss: 0.727806
global_step: 34923, epoch: 74, loss: 0.789280
global_step: 34924, epoch: 74, loss: 0.708808
global_step: 34925, epoch: 74, loss: 0.733319
global_step: 34926, epoch: 74, loss: 0.686118
global_step: 34927, epoch: 74, loss: 0.738738
global_step: 34928, epoch: 74, loss: 0.717826
global_step: 34929, epoch: 74, loss: 0.691467
global_step: 34930, epoch: 74, loss: 0.676362
global_step: 34931, epoch: 74, loss: 0.738294
global_step: 34932, epoch: 74, loss: 0.665530
global_step: 34933, epoch: 74, loss: 0.757860
global_step: 34934, epoch: 74, loss: 0.804807
global_step: 34935, epoch: 74, loss: 0.734279
global_step: 34936, epoch: 74, loss: 0.696667
global_step: 34937, epoch: 74, loss: 0.700953
global_step: 34938, epoch: 74, loss: 0.754393
global_step: 34939, epoch: 74, loss: 0.760491
global_step: 34940, epoch: 74, loss: 0.758879
global_step: 34941, epoch: 74, loss: 0.734698
global_step: 34942, epoch: 74, loss: 0.764796
global_step: 34943, epoch: 74, loss: 0.762184
global_step: 34944, epoch: 74, loss: 0.710317
global_step: 34945, epoch: 74, loss: 0.624829
global_step: 34946, epoch: 74, loss: 0.789696
global_step: 34947, epoch: 74, loss: 0.650432
global_step: 34948, epoch: 74, loss: 0.706460
global_step: 34949, epoch: 74, loss: 0.706185
global_step: 34950, epoch: 74, loss: 0.711538
global_step: 34951, epoch: 74, loss: 0.730582
global_step: 34952, epoch: 74, loss: 0.785403
global_step: 34953, epoch: 74, loss: 0.746448
global_step: 34954, epoch: 74, loss: 0.763313
global_step: 34955, epoch: 74, loss: 0.736727
global_step: 34956, epoch: 74, loss: 0.744686
global_step: 34957, epoch: 74, loss: 0.724767
global_step: 34958, epoch: 74, loss: 0.816899
global_step: 34959, epoch: 74, loss: 0.759738
global_step: 34960, epoch: 74, loss: 0.282562
epoch: 74
train	acc: 0.7971	macro: p 0.6898, r 0.5284, f1: 0.5370	micro: p 0.7971, r 0.7971, f1 0.7971	weighted_f1:0.7697
dev	acc: 0.5708	macro: p 0.3784, r 0.3278, f1: 0.3307	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5233
test	acc: 0.6126	macro: p 0.5030, r 0.3308, f1: 0.3352	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5689
global_step: 34961, epoch: 75, loss: 0.657272
global_step: 34962, epoch: 75, loss: 0.741964
global_step: 34963, epoch: 75, loss: 0.774139
global_step: 34964, epoch: 75, loss: 0.647861
global_step: 34965, epoch: 75, loss: 0.751401
global_step: 34966, epoch: 75, loss: 0.750006
global_step: 34967, epoch: 75, loss: 0.702537
global_step: 34968, epoch: 75, loss: 0.717025
global_step: 34969, epoch: 75, loss: 0.695086
global_step: 34970, epoch: 75, loss: 0.697114
global_step: 34971, epoch: 75, loss: 0.702667
global_step: 34972, epoch: 75, loss: 0.801580
global_step: 34973, epoch: 75, loss: 0.685965
global_step: 34974, epoch: 75, loss: 0.686017
global_step: 34975, epoch: 75, loss: 0.582311
global_step: 34976, epoch: 75, loss: 0.743276
global_step: 34977, epoch: 75, loss: 0.732673
global_step: 34978, epoch: 75, loss: 0.625897
global_step: 34979, epoch: 75, loss: 0.754019
global_step: 34980, epoch: 75, loss: 0.812094
global_step: 34981, epoch: 75, loss: 0.748015
global_step: 34982, epoch: 75, loss: 0.832950
global_step: 34983, epoch: 75, loss: 0.751075
global_step: 34984, epoch: 75, loss: 0.736464
global_step: 34985, epoch: 75, loss: 0.636373
global_step: 34986, epoch: 75, loss: 0.730229
global_step: 34987, epoch: 75, loss: 0.680854
global_step: 34988, epoch: 75, loss: 0.743674
global_step: 34989, epoch: 75, loss: 0.732652
global_step: 34990, epoch: 75, loss: 0.746671
global_step: 34991, epoch: 75, loss: 0.869664
global_step: 34992, epoch: 75, loss: 0.770226
global_step: 34993, epoch: 75, loss: 0.701338
global_step: 34994, epoch: 75, loss: 0.744010
global_step: 34995, epoch: 75, loss: 0.729041
global_step: 34996, epoch: 75, loss: 0.666112
global_step: 34997, epoch: 75, loss: 0.698101
global_step: 34998, epoch: 75, loss: 0.715195
global_step: 34999, epoch: 75, loss: 0.855292
global_step: 35000, epoch: 75, loss: 0.383761
epoch: 75
train	acc: 0.8166	macro: p 0.6762, r 0.5567, f1: 0.5565	micro: p 0.8166, r 0.8166, f1 0.8166	weighted_f1:0.7922
dev	acc: 0.5555	macro: p 0.3529, r 0.3282, f1: 0.3225	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5155
test	acc: 0.6042	macro: p 0.4976, r 0.3407, f1: 0.3383	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5675
global_step: 35001, epoch: 76, loss: 0.652344
global_step: 35002, epoch: 76, loss: 0.714892
global_step: 35003, epoch: 76, loss: 0.669258
global_step: 35004, epoch: 76, loss: 0.714974
global_step: 35005, epoch: 76, loss: 0.849887
global_step: 35006, epoch: 76, loss: 0.643170
global_step: 35007, epoch: 76, loss: 0.744464
global_step: 35008, epoch: 76, loss: 0.536207
global_step: 35009, epoch: 76, loss: 0.756349
global_step: 35010, epoch: 76, loss: 0.803343
global_step: 35011, epoch: 76, loss: 0.619685
global_step: 35012, epoch: 76, loss: 0.692676
global_step: 35013, epoch: 76, loss: 0.720378
global_step: 35014, epoch: 76, loss: 0.695556
global_step: 35015, epoch: 76, loss: 0.862791
global_step: 35016, epoch: 76, loss: 0.748485
global_step: 35017, epoch: 76, loss: 0.739179
global_step: 35018, epoch: 76, loss: 0.630726
global_step: 35019, epoch: 76, loss: 0.613739
global_step: 35020, epoch: 76, loss: 0.718633
global_step: 35021, epoch: 76, loss: 0.725149
global_step: 35022, epoch: 76, loss: 0.709871
global_step: 35023, epoch: 76, loss: 0.693177
global_step: 35024, epoch: 76, loss: 0.778415
global_step: 35025, epoch: 76, loss: 0.671201
global_step: 35026, epoch: 76, loss: 0.743995
global_step: 35027, epoch: 76, loss: 0.806753
global_step: 35028, epoch: 76, loss: 0.801694
global_step: 35029, epoch: 76, loss: 0.607375
global_step: 35030, epoch: 76, loss: 0.684240
global_step: 35031, epoch: 76, loss: 0.648028
global_step: 35032, epoch: 76, loss: 0.755303
global_step: 35033, epoch: 76, loss: 0.707116
global_step: 35034, epoch: 76, loss: 0.828999
global_step: 35035, epoch: 76, loss: 0.734572
global_step: 35036, epoch: 76, loss: 0.697090
global_step: 35037, epoch: 76, loss: 0.728479
global_step: 35038, epoch: 76, loss: 0.627678
global_step: 35039, epoch: 76, loss: 0.789390
global_step: 35040, epoch: 76, loss: 0.830856
epoch: 76
train	acc: 0.8258	macro: p 0.8298, r 0.5781, f1: 0.5799	micro: p 0.8258, r 0.8258, f1 0.8258	weighted_f1:0.8034
dev	acc: 0.5600	macro: p 0.3435, r 0.3333, f1: 0.3248	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5169
test	acc: 0.6031	macro: p 0.4882, r 0.3421, f1: 0.3365	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5664
global_step: 35041, epoch: 77, loss: 0.585061
global_step: 35042, epoch: 77, loss: 0.725042
global_step: 35043, epoch: 77, loss: 0.605767
global_step: 35044, epoch: 77, loss: 0.710787
global_step: 35045, epoch: 77, loss: 0.717749
global_step: 35046, epoch: 77, loss: 0.586857
global_step: 35047, epoch: 77, loss: 0.651711
global_step: 35048, epoch: 77, loss: 0.680870
global_step: 35049, epoch: 77, loss: 0.833003
global_step: 35050, epoch: 77, loss: 0.628676
global_step: 35051, epoch: 77, loss: 0.673436
global_step: 35052, epoch: 77, loss: 0.799392
global_step: 35053, epoch: 77, loss: 0.735428
global_step: 35054, epoch: 77, loss: 0.656924
global_step: 35055, epoch: 77, loss: 0.711751
global_step: 35056, epoch: 77, loss: 0.672350
global_step: 35057, epoch: 77, loss: 0.704484
global_step: 35058, epoch: 77, loss: 0.657259
global_step: 35059, epoch: 77, loss: 0.720399
global_step: 35060, epoch: 77, loss: 0.684830
global_step: 35061, epoch: 77, loss: 0.700193
global_step: 35062, epoch: 77, loss: 0.740525
global_step: 35063, epoch: 77, loss: 0.719851
global_step: 35064, epoch: 77, loss: 0.644816
global_step: 35065, epoch: 77, loss: 0.713155
global_step: 35066, epoch: 77, loss: 0.687448
global_step: 35067, epoch: 77, loss: 0.709850
global_step: 35068, epoch: 77, loss: 0.658947
global_step: 35069, epoch: 77, loss: 0.748528
global_step: 35070, epoch: 77, loss: 0.788912
global_step: 35071, epoch: 77, loss: 0.712849
global_step: 35072, epoch: 77, loss: 0.675009
global_step: 35073, epoch: 77, loss: 0.733220
global_step: 35074, epoch: 77, loss: 0.815893
global_step: 35075, epoch: 77, loss: 0.723093
global_step: 35076, epoch: 77, loss: 0.737379
global_step: 35077, epoch: 77, loss: 0.721961
global_step: 35078, epoch: 77, loss: 0.744783
global_step: 35079, epoch: 77, loss: 0.748526
global_step: 35080, epoch: 77, loss: 0.716503
epoch: 77
train	acc: 0.8255	macro: p 0.8347, r 0.5770, f1: 0.5826	micro: p 0.8255, r 0.8255, f1 0.8255	weighted_f1:0.8030
dev	acc: 0.5726	macro: p 0.3587, r 0.3385, f1: 0.3340	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5269
test	acc: 0.6050	macro: p 0.4890, r 0.3352, f1: 0.3350	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5664
global_step: 35081, epoch: 78, loss: 0.683977
global_step: 35082, epoch: 78, loss: 0.659930
global_step: 35083, epoch: 78, loss: 0.604960
global_step: 35084, epoch: 78, loss: 0.735974
global_step: 35085, epoch: 78, loss: 0.710931
global_step: 35086, epoch: 78, loss: 0.741553
global_step: 35087, epoch: 78, loss: 0.617528
global_step: 35088, epoch: 78, loss: 0.684637
global_step: 35089, epoch: 78, loss: 0.577705
global_step: 35090, epoch: 78, loss: 0.606483
global_step: 35091, epoch: 78, loss: 0.852373
global_step: 35092, epoch: 78, loss: 0.706120
global_step: 35093, epoch: 78, loss: 0.618962
global_step: 35094, epoch: 78, loss: 0.777474
global_step: 35095, epoch: 78, loss: 0.805603
global_step: 35096, epoch: 78, loss: 0.710760
global_step: 35097, epoch: 78, loss: 0.678656
global_step: 35098, epoch: 78, loss: 0.724614
global_step: 35099, epoch: 78, loss: 0.663336
global_step: 35100, epoch: 78, loss: 0.745516
global_step: 35101, epoch: 78, loss: 0.658473
global_step: 35102, epoch: 78, loss: 0.856730
global_step: 35103, epoch: 78, loss: 0.667692
global_step: 35104, epoch: 78, loss: 0.662020
global_step: 35105, epoch: 78, loss: 0.666078
global_step: 35106, epoch: 78, loss: 0.695628
global_step: 35107, epoch: 78, loss: 0.686532
global_step: 35108, epoch: 78, loss: 0.690342
global_step: 35109, epoch: 78, loss: 0.706332
global_step: 35110, epoch: 78, loss: 0.691765
global_step: 35111, epoch: 78, loss: 0.773768
global_step: 35112, epoch: 78, loss: 0.587888
global_step: 35113, epoch: 78, loss: 0.795407
global_step: 35114, epoch: 78, loss: 0.702816
global_step: 35115, epoch: 78, loss: 0.721598
global_step: 35116, epoch: 78, loss: 0.712620
global_step: 35117, epoch: 78, loss: 0.642491
global_step: 35118, epoch: 78, loss: 0.765241
global_step: 35119, epoch: 78, loss: 0.680608
global_step: 35120, epoch: 78, loss: 0.221757
epoch: 78
train	acc: 0.8301	macro: p 0.8361, r 0.5784, f1: 0.5799	micro: p 0.8301, r 0.8301, f1 0.8301	weighted_f1:0.8070
dev	acc: 0.5717	macro: p 0.3602, r 0.3425, f1: 0.3377	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5301
test	acc: 0.6050	macro: p 0.4917, r 0.3379, f1: 0.3356	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5671
global_step: 35121, epoch: 79, loss: 0.635640
global_step: 35122, epoch: 79, loss: 0.646259
global_step: 35123, epoch: 79, loss: 0.770749
global_step: 35124, epoch: 79, loss: 0.708287
global_step: 35125, epoch: 79, loss: 0.577858
global_step: 35126, epoch: 79, loss: 0.726331
global_step: 35127, epoch: 79, loss: 0.719978
global_step: 35128, epoch: 79, loss: 0.604997
global_step: 35129, epoch: 79, loss: 0.653993
global_step: 35130, epoch: 79, loss: 0.732179
global_step: 35131, epoch: 79, loss: 0.670863
global_step: 35132, epoch: 79, loss: 0.675014
global_step: 35133, epoch: 79, loss: 0.688265
global_step: 35134, epoch: 79, loss: 0.587835
global_step: 35135, epoch: 79, loss: 0.583924
global_step: 35136, epoch: 79, loss: 0.679637
global_step: 35137, epoch: 79, loss: 0.790110
global_step: 35138, epoch: 79, loss: 0.724591
global_step: 35139, epoch: 79, loss: 0.651186
global_step: 35140, epoch: 79, loss: 0.829515
global_step: 35141, epoch: 79, loss: 0.579325
global_step: 35142, epoch: 79, loss: 0.778466
global_step: 35143, epoch: 79, loss: 0.746356
global_step: 35144, epoch: 79, loss: 0.685088
global_step: 35145, epoch: 79, loss: 0.728440
global_step: 35146, epoch: 79, loss: 0.803410
global_step: 35147, epoch: 79, loss: 0.704686
global_step: 35148, epoch: 79, loss: 0.760357
global_step: 35149, epoch: 79, loss: 0.616724
global_step: 35150, epoch: 79, loss: 0.654417
global_step: 35151, epoch: 79, loss: 0.648808
global_step: 35152, epoch: 79, loss: 0.630351
global_step: 35153, epoch: 79, loss: 0.637477
global_step: 35154, epoch: 79, loss: 0.696710
global_step: 35155, epoch: 79, loss: 0.699497
global_step: 35156, epoch: 79, loss: 0.622925
global_step: 35157, epoch: 79, loss: 0.737810
global_step: 35158, epoch: 79, loss: 0.689733
global_step: 35159, epoch: 79, loss: 0.757212
global_step: 35160, epoch: 79, loss: 0.556442
epoch: 79
train	acc: 0.8334	macro: p 0.8427, r 0.5882, f1: 0.5976	micro: p 0.8334, r 0.8334, f1 0.8334	weighted_f1:0.8123
dev	acc: 0.5654	macro: p 0.3627, r 0.3320, f1: 0.3305	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5221
test	acc: 0.6080	macro: p 0.4259, r 0.3378, f1: 0.3389	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5692
global_step: 35161, epoch: 80, loss: 0.590683
global_step: 35162, epoch: 80, loss: 0.619337
global_step: 35163, epoch: 80, loss: 0.718908
global_step: 35164, epoch: 80, loss: 0.597634
global_step: 35165, epoch: 80, loss: 0.597160
global_step: 35166, epoch: 80, loss: 0.715111
global_step: 35167, epoch: 80, loss: 0.688694
global_step: 35168, epoch: 80, loss: 0.763729
global_step: 35169, epoch: 80, loss: 0.724553
global_step: 35170, epoch: 80, loss: 0.656036
global_step: 35171, epoch: 80, loss: 0.733488
global_step: 35172, epoch: 80, loss: 0.764432
global_step: 35173, epoch: 80, loss: 0.691116
global_step: 35174, epoch: 80, loss: 0.679802
global_step: 35175, epoch: 80, loss: 0.640562
global_step: 35176, epoch: 80, loss: 0.602269
global_step: 35177, epoch: 80, loss: 0.825155
global_step: 35178, epoch: 80, loss: 0.648878
global_step: 35179, epoch: 80, loss: 0.618713
global_step: 35180, epoch: 80, loss: 0.674303
global_step: 35181, epoch: 80, loss: 0.671011
global_step: 35182, epoch: 80, loss: 0.575782
global_step: 35183, epoch: 80, loss: 0.644626
global_step: 35184, epoch: 80, loss: 0.682261
global_step: 35185, epoch: 80, loss: 0.631091
global_step: 35186, epoch: 80, loss: 0.687650
global_step: 35187, epoch: 80, loss: 0.654907
global_step: 35188, epoch: 80, loss: 0.656052
global_step: 35189, epoch: 80, loss: 0.758507
global_step: 35190, epoch: 80, loss: 0.646550
global_step: 35191, epoch: 80, loss: 0.680320
global_step: 35192, epoch: 80, loss: 0.655192
global_step: 35193, epoch: 80, loss: 0.730520
global_step: 35194, epoch: 80, loss: 0.663968
global_step: 35195, epoch: 80, loss: 0.645795
global_step: 35196, epoch: 80, loss: 0.684723
global_step: 35197, epoch: 80, loss: 0.776203
global_step: 35198, epoch: 80, loss: 0.585946
global_step: 35199, epoch: 80, loss: 0.772679
global_step: 35200, epoch: 80, loss: 0.715818
epoch: 80
train	acc: 0.8427	macro: p 0.8329, r 0.6114, f1: 0.6063	micro: p 0.8427, r 0.8427, f1 0.8427	weighted_f1:0.8256
dev	acc: 0.5618	macro: p 0.3444, r 0.3519, f1: 0.3458	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5361
test	acc: 0.5966	macro: p 0.4169, r 0.3538, f1: 0.3509	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5753
global_step: 35201, epoch: 81, loss: 0.750219
global_step: 35202, epoch: 81, loss: 0.687549
global_step: 35203, epoch: 81, loss: 0.624825
global_step: 35204, epoch: 81, loss: 0.735798
global_step: 35205, epoch: 81, loss: 0.643503
global_step: 35206, epoch: 81, loss: 0.607742
global_step: 35207, epoch: 81, loss: 0.600906
global_step: 35208, epoch: 81, loss: 0.689418
global_step: 35209, epoch: 81, loss: 0.696553
global_step: 35210, epoch: 81, loss: 0.611485
global_step: 35211, epoch: 81, loss: 0.682887
global_step: 35212, epoch: 81, loss: 0.598901
global_step: 35213, epoch: 81, loss: 0.651854
global_step: 35214, epoch: 81, loss: 0.573544
global_step: 35215, epoch: 81, loss: 0.721745
global_step: 35216, epoch: 81, loss: 0.835208
global_step: 35217, epoch: 81, loss: 0.559348
global_step: 35218, epoch: 81, loss: 0.672069
global_step: 35219, epoch: 81, loss: 0.642615
global_step: 35220, epoch: 81, loss: 0.638080
global_step: 35221, epoch: 81, loss: 0.675402
global_step: 35222, epoch: 81, loss: 0.682658
global_step: 35223, epoch: 81, loss: 0.645792
global_step: 35224, epoch: 81, loss: 0.618094
global_step: 35225, epoch: 81, loss: 0.705507
global_step: 35226, epoch: 81, loss: 0.749751
global_step: 35227, epoch: 81, loss: 0.719917
global_step: 35228, epoch: 81, loss: 0.659083
global_step: 35229, epoch: 81, loss: 0.762714
global_step: 35230, epoch: 81, loss: 0.682479
global_step: 35231, epoch: 81, loss: 0.727950
global_step: 35232, epoch: 81, loss: 0.665082
global_step: 35233, epoch: 81, loss: 0.619466
global_step: 35234, epoch: 81, loss: 0.790981
global_step: 35235, epoch: 81, loss: 0.662445
global_step: 35236, epoch: 81, loss: 0.677859
global_step: 35237, epoch: 81, loss: 0.780815
global_step: 35238, epoch: 81, loss: 0.753385
global_step: 35239, epoch: 81, loss: 0.654889
global_step: 35240, epoch: 81, loss: 0.249068
epoch: 81
train	acc: 0.7915	macro: p 0.8409, r 0.5192, f1: 0.5457	micro: p 0.7915, r 0.7915, f1 0.7915	weighted_f1:0.7624
dev	acc: 0.5546	macro: p 0.3814, r 0.3033, f1: 0.3023	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4918
test	acc: 0.6057	macro: p 0.5031, r 0.3120, f1: 0.3165	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5497
global_step: 35241, epoch: 82, loss: 0.737153
global_step: 35242, epoch: 82, loss: 0.635020
global_step: 35243, epoch: 82, loss: 0.629635
global_step: 35244, epoch: 82, loss: 0.611734
global_step: 35245, epoch: 82, loss: 0.642759
global_step: 35246, epoch: 82, loss: 0.660260
global_step: 35247, epoch: 82, loss: 0.646977
global_step: 35248, epoch: 82, loss: 0.722547
global_step: 35249, epoch: 82, loss: 0.651229
global_step: 35250, epoch: 82, loss: 0.686854
global_step: 35251, epoch: 82, loss: 0.668096
global_step: 35252, epoch: 82, loss: 0.730692
global_step: 35253, epoch: 82, loss: 0.621919
global_step: 35254, epoch: 82, loss: 0.646027
global_step: 35255, epoch: 82, loss: 0.686693
global_step: 35256, epoch: 82, loss: 0.656616
global_step: 35257, epoch: 82, loss: 0.698470
global_step: 35258, epoch: 82, loss: 0.658966
global_step: 35259, epoch: 82, loss: 0.614180
global_step: 35260, epoch: 82, loss: 0.684189
global_step: 35261, epoch: 82, loss: 0.615290
global_step: 35262, epoch: 82, loss: 0.662356
global_step: 35263, epoch: 82, loss: 0.527245
global_step: 35264, epoch: 82, loss: 0.668276
global_step: 35265, epoch: 82, loss: 0.755400
global_step: 35266, epoch: 82, loss: 0.702405
global_step: 35267, epoch: 82, loss: 0.639582
global_step: 35268, epoch: 82, loss: 0.625180
global_step: 35269, epoch: 82, loss: 0.647403
global_step: 35270, epoch: 82, loss: 0.695022
global_step: 35271, epoch: 82, loss: 0.644780
global_step: 35272, epoch: 82, loss: 0.743725
global_step: 35273, epoch: 82, loss: 0.629820
global_step: 35274, epoch: 82, loss: 0.690984
global_step: 35275, epoch: 82, loss: 0.719914
global_step: 35276, epoch: 82, loss: 0.588739
global_step: 35277, epoch: 82, loss: 0.715293
global_step: 35278, epoch: 82, loss: 0.721220
global_step: 35279, epoch: 82, loss: 0.606230
global_step: 35280, epoch: 82, loss: 2.010113
epoch: 82
train	acc: 0.8514	macro: p 0.8192, r 0.6347, f1: 0.6310	micro: p 0.8514, r 0.8514, f1 0.8514	weighted_f1:0.8372
dev	acc: 0.5609	macro: p 0.4886, r 0.3632, f1: 0.3623	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5399
test	acc: 0.5801	macro: p 0.3825, r 0.3557, f1: 0.3531	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5663
global_step: 35281, epoch: 83, loss: 0.807198
global_step: 35282, epoch: 83, loss: 0.629564
global_step: 35283, epoch: 83, loss: 0.563259
global_step: 35284, epoch: 83, loss: 0.617618
global_step: 35285, epoch: 83, loss: 0.622968
global_step: 35286, epoch: 83, loss: 0.654887
global_step: 35287, epoch: 83, loss: 0.620683
global_step: 35288, epoch: 83, loss: 0.653617
global_step: 35289, epoch: 83, loss: 0.584454
global_step: 35290, epoch: 83, loss: 0.593541
global_step: 35291, epoch: 83, loss: 0.709995
global_step: 35292, epoch: 83, loss: 0.682392
global_step: 35293, epoch: 83, loss: 0.582699
global_step: 35294, epoch: 83, loss: 0.712372
global_step: 35295, epoch: 83, loss: 0.684933
global_step: 35296, epoch: 83, loss: 0.568306
global_step: 35297, epoch: 83, loss: 0.687765
global_step: 35298, epoch: 83, loss: 0.679947
global_step: 35299, epoch: 83, loss: 0.675025
global_step: 35300, epoch: 83, loss: 0.599486
global_step: 35301, epoch: 83, loss: 0.720528
global_step: 35302, epoch: 83, loss: 0.642057
global_step: 35303, epoch: 83, loss: 0.798646
global_step: 35304, epoch: 83, loss: 0.706881
global_step: 35305, epoch: 83, loss: 0.616696
global_step: 35306, epoch: 83, loss: 0.606590
global_step: 35307, epoch: 83, loss: 0.705549
global_step: 35308, epoch: 83, loss: 0.660049
global_step: 35309, epoch: 83, loss: 0.655846
global_step: 35310, epoch: 83, loss: 0.576403
global_step: 35311, epoch: 83, loss: 0.685414
global_step: 35312, epoch: 83, loss: 0.625356
global_step: 35313, epoch: 83, loss: 0.678445
global_step: 35314, epoch: 83, loss: 0.695928
global_step: 35315, epoch: 83, loss: 0.571174
global_step: 35316, epoch: 83, loss: 0.672560
global_step: 35317, epoch: 83, loss: 0.571097
global_step: 35318, epoch: 83, loss: 0.694196
global_step: 35319, epoch: 83, loss: 0.666182
global_step: 35320, epoch: 83, loss: 0.279219
epoch: 83
train	acc: 0.8444	macro: p 0.8463, r 0.6036, f1: 0.6127	micro: p 0.8444, r 0.8444, f1 0.8444	weighted_f1:0.8238
dev	acc: 0.5636	macro: p 0.3502, r 0.3323, f1: 0.3281	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5203
test	acc: 0.6073	macro: p 0.4240, r 0.3396, f1: 0.3392	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5695
global_step: 35321, epoch: 84, loss: 0.506279
global_step: 35322, epoch: 84, loss: 0.653472
global_step: 35323, epoch: 84, loss: 0.728353
global_step: 35324, epoch: 84, loss: 0.697430
global_step: 35325, epoch: 84, loss: 0.588303
global_step: 35326, epoch: 84, loss: 0.587132
global_step: 35327, epoch: 84, loss: 0.611453
global_step: 35328, epoch: 84, loss: 0.704756
global_step: 35329, epoch: 84, loss: 0.643340
global_step: 35330, epoch: 84, loss: 0.691875
global_step: 35331, epoch: 84, loss: 0.652546
global_step: 35332, epoch: 84, loss: 0.622739
global_step: 35333, epoch: 84, loss: 0.556158
global_step: 35334, epoch: 84, loss: 0.738582
global_step: 35335, epoch: 84, loss: 0.606018
global_step: 35336, epoch: 84, loss: 0.674034
global_step: 35337, epoch: 84, loss: 0.664994
global_step: 35338, epoch: 84, loss: 0.648901
global_step: 35339, epoch: 84, loss: 0.645862
global_step: 35340, epoch: 84, loss: 0.586766
global_step: 35341, epoch: 84, loss: 0.638936
global_step: 35342, epoch: 84, loss: 0.679211
global_step: 35343, epoch: 84, loss: 0.650516
global_step: 35344, epoch: 84, loss: 0.667245
global_step: 35345, epoch: 84, loss: 0.621597
global_step: 35346, epoch: 84, loss: 0.754544
global_step: 35347, epoch: 84, loss: 0.607550
global_step: 35348, epoch: 84, loss: 0.586823
global_step: 35349, epoch: 84, loss: 0.643577
global_step: 35350, epoch: 84, loss: 0.646355
global_step: 35351, epoch: 84, loss: 0.584358
global_step: 35352, epoch: 84, loss: 0.723043
global_step: 35353, epoch: 84, loss: 0.643075
global_step: 35354, epoch: 84, loss: 0.615105
global_step: 35355, epoch: 84, loss: 0.574469
global_step: 35356, epoch: 84, loss: 0.567857
global_step: 35357, epoch: 84, loss: 0.577439
global_step: 35358, epoch: 84, loss: 0.743124
global_step: 35359, epoch: 84, loss: 0.643735
global_step: 35360, epoch: 84, loss: 0.519246
epoch: 84
train	acc: 0.8378	macro: p 0.8449, r 0.5919, f1: 0.6038	micro: p 0.8378, r 0.8378, f1 0.8378	weighted_f1:0.8159
dev	acc: 0.5672	macro: p 0.5079, r 0.3354, f1: 0.3374	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5193
test	acc: 0.6080	macro: p 0.4273, r 0.3343, f1: 0.3340	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5653
global_step: 35361, epoch: 85, loss: 0.589372
global_step: 35362, epoch: 85, loss: 0.651997
global_step: 35363, epoch: 85, loss: 0.506498
global_step: 35364, epoch: 85, loss: 0.648217
global_step: 35365, epoch: 85, loss: 0.592884
global_step: 35366, epoch: 85, loss: 0.632372
global_step: 35367, epoch: 85, loss: 0.610222
global_step: 35368, epoch: 85, loss: 0.677065
global_step: 35369, epoch: 85, loss: 0.657852
global_step: 35370, epoch: 85, loss: 0.661686
global_step: 35371, epoch: 85, loss: 0.686935
global_step: 35372, epoch: 85, loss: 0.627504
global_step: 35373, epoch: 85, loss: 0.653930
global_step: 35374, epoch: 85, loss: 0.642126
global_step: 35375, epoch: 85, loss: 0.625315
global_step: 35376, epoch: 85, loss: 0.705308
global_step: 35377, epoch: 85, loss: 0.684534
global_step: 35378, epoch: 85, loss: 0.576302
global_step: 35379, epoch: 85, loss: 0.651714
global_step: 35380, epoch: 85, loss: 0.569593
global_step: 35381, epoch: 85, loss: 0.640589
global_step: 35382, epoch: 85, loss: 0.616463
global_step: 35383, epoch: 85, loss: 0.647882
global_step: 35384, epoch: 85, loss: 0.650472
global_step: 35385, epoch: 85, loss: 0.608032
global_step: 35386, epoch: 85, loss: 0.629993
global_step: 35387, epoch: 85, loss: 0.566429
global_step: 35388, epoch: 85, loss: 0.606017
global_step: 35389, epoch: 85, loss: 0.666170
global_step: 35390, epoch: 85, loss: 0.735515
global_step: 35391, epoch: 85, loss: 0.653675
global_step: 35392, epoch: 85, loss: 0.690581
global_step: 35393, epoch: 85, loss: 0.689588
global_step: 35394, epoch: 85, loss: 0.657367
global_step: 35395, epoch: 85, loss: 0.759661
global_step: 35396, epoch: 85, loss: 0.637696
global_step: 35397, epoch: 85, loss: 0.641541
global_step: 35398, epoch: 85, loss: 0.639723
global_step: 35399, epoch: 85, loss: 0.614460
global_step: 35400, epoch: 85, loss: 0.315560
epoch: 85
train	acc: 0.8334	macro: p 0.7076, r 0.5873, f1: 0.6003	micro: p 0.8334, r 0.8334, f1 0.8334	weighted_f1:0.8113
dev	acc: 0.5681	macro: p 0.3658, r 0.3254, f1: 0.3275	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5184
test	acc: 0.6084	macro: p 0.4270, r 0.3272, f1: 0.3337	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5648
global_step: 35401, epoch: 86, loss: 0.685758
global_step: 35402, epoch: 86, loss: 0.603513
global_step: 35403, epoch: 86, loss: 0.624628
global_step: 35404, epoch: 86, loss: 0.527371
global_step: 35405, epoch: 86, loss: 0.676851
global_step: 35406, epoch: 86, loss: 0.585772
global_step: 35407, epoch: 86, loss: 0.649491
global_step: 35408, epoch: 86, loss: 0.645276
global_step: 35409, epoch: 86, loss: 0.593174
global_step: 35410, epoch: 86, loss: 0.703716
global_step: 35411, epoch: 86, loss: 0.680114
global_step: 35412, epoch: 86, loss: 0.557148
global_step: 35413, epoch: 86, loss: 0.669308
global_step: 35414, epoch: 86, loss: 0.651371
global_step: 35415, epoch: 86, loss: 0.621190
global_step: 35416, epoch: 86, loss: 0.623421
global_step: 35417, epoch: 86, loss: 0.540734
global_step: 35418, epoch: 86, loss: 0.522036
global_step: 35419, epoch: 86, loss: 0.552217
global_step: 35420, epoch: 86, loss: 0.548973
global_step: 35421, epoch: 86, loss: 0.543538
global_step: 35422, epoch: 86, loss: 0.771568
global_step: 35423, epoch: 86, loss: 0.698627
global_step: 35424, epoch: 86, loss: 0.591638
global_step: 35425, epoch: 86, loss: 0.666072
global_step: 35426, epoch: 86, loss: 0.624027
global_step: 35427, epoch: 86, loss: 0.641291
global_step: 35428, epoch: 86, loss: 0.586289
global_step: 35429, epoch: 86, loss: 0.574823
global_step: 35430, epoch: 86, loss: 0.636997
global_step: 35431, epoch: 86, loss: 0.668903
global_step: 35432, epoch: 86, loss: 0.660495
global_step: 35433, epoch: 86, loss: 0.670581
global_step: 35434, epoch: 86, loss: 0.684689
global_step: 35435, epoch: 86, loss: 0.697811
global_step: 35436, epoch: 86, loss: 0.674927
global_step: 35437, epoch: 86, loss: 0.661767
global_step: 35438, epoch: 86, loss: 0.631472
global_step: 35439, epoch: 86, loss: 0.654932
global_step: 35440, epoch: 86, loss: 0.600578
epoch: 86
train	acc: 0.8546	macro: p 0.8323, r 0.6367, f1: 0.6281	micro: p 0.8546, r 0.8546, f1 0.8546	weighted_f1:0.8402
dev	acc: 0.5455	macro: p 0.4812, r 0.3549, f1: 0.3524	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5292
test	acc: 0.5732	macro: p 0.3735, r 0.3580, f1: 0.3513	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5632
global_step: 35441, epoch: 87, loss: 0.693736
global_step: 35442, epoch: 87, loss: 0.598715
global_step: 35443, epoch: 87, loss: 0.710087
global_step: 35444, epoch: 87, loss: 0.660639
global_step: 35445, epoch: 87, loss: 0.596292
global_step: 35446, epoch: 87, loss: 0.633396
global_step: 35447, epoch: 87, loss: 0.549409
global_step: 35448, epoch: 87, loss: 0.704645
global_step: 35449, epoch: 87, loss: 0.690499
global_step: 35450, epoch: 87, loss: 0.591717
global_step: 35451, epoch: 87, loss: 0.690398
global_step: 35452, epoch: 87, loss: 0.590182
global_step: 35453, epoch: 87, loss: 0.683184
global_step: 35454, epoch: 87, loss: 0.615807
global_step: 35455, epoch: 87, loss: 0.600847
global_step: 35456, epoch: 87, loss: 0.641443
global_step: 35457, epoch: 87, loss: 0.632016
global_step: 35458, epoch: 87, loss: 0.669049
global_step: 35459, epoch: 87, loss: 0.709832
global_step: 35460, epoch: 87, loss: 0.673214
global_step: 35461, epoch: 87, loss: 0.693137
global_step: 35462, epoch: 87, loss: 0.570205
global_step: 35463, epoch: 87, loss: 0.683477
global_step: 35464, epoch: 87, loss: 0.588768
global_step: 35465, epoch: 87, loss: 0.573048
global_step: 35466, epoch: 87, loss: 0.654074
global_step: 35467, epoch: 87, loss: 0.642822
global_step: 35468, epoch: 87, loss: 0.570478
global_step: 35469, epoch: 87, loss: 0.631679
global_step: 35470, epoch: 87, loss: 0.616950
global_step: 35471, epoch: 87, loss: 0.737085
global_step: 35472, epoch: 87, loss: 0.621673
global_step: 35473, epoch: 87, loss: 0.606473
global_step: 35474, epoch: 87, loss: 0.649296
global_step: 35475, epoch: 87, loss: 0.631502
global_step: 35476, epoch: 87, loss: 0.591309
global_step: 35477, epoch: 87, loss: 0.620259
global_step: 35478, epoch: 87, loss: 0.628913
global_step: 35479, epoch: 87, loss: 0.608686
global_step: 35480, epoch: 87, loss: 0.525542
epoch: 87
train	acc: 0.8594	macro: p 0.8273, r 0.6308, f1: 0.6359	micro: p 0.8594, r 0.8594, f1 0.8594	weighted_f1:0.8415
dev	acc: 0.5645	macro: p 0.3472, r 0.3439, f1: 0.3383	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5304
test	acc: 0.5981	macro: p 0.3905, r 0.3422, f1: 0.3394	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5670
global_step: 35481, epoch: 88, loss: 0.585826
global_step: 35482, epoch: 88, loss: 0.574422
global_step: 35483, epoch: 88, loss: 0.520695
global_step: 35484, epoch: 88, loss: 0.520491
global_step: 35485, epoch: 88, loss: 0.706033
global_step: 35486, epoch: 88, loss: 0.715946
global_step: 35487, epoch: 88, loss: 0.684047
global_step: 35488, epoch: 88, loss: 0.597751
global_step: 35489, epoch: 88, loss: 0.534466
global_step: 35490, epoch: 88, loss: 0.516068
global_step: 35491, epoch: 88, loss: 0.631246
global_step: 35492, epoch: 88, loss: 0.637151
global_step: 35493, epoch: 88, loss: 0.621394
global_step: 35494, epoch: 88, loss: 0.702514
global_step: 35495, epoch: 88, loss: 0.598332
global_step: 35496, epoch: 88, loss: 0.725377
global_step: 35497, epoch: 88, loss: 0.644206
global_step: 35498, epoch: 88, loss: 0.633976
global_step: 35499, epoch: 88, loss: 0.704649
global_step: 35500, epoch: 88, loss: 0.636680
global_step: 35501, epoch: 88, loss: 0.732291
global_step: 35502, epoch: 88, loss: 0.559958
global_step: 35503, epoch: 88, loss: 0.630328
global_step: 35504, epoch: 88, loss: 0.635140
global_step: 35505, epoch: 88, loss: 0.672247
global_step: 35506, epoch: 88, loss: 0.528518
global_step: 35507, epoch: 88, loss: 0.540028
global_step: 35508, epoch: 88, loss: 0.687872
global_step: 35509, epoch: 88, loss: 0.525548
global_step: 35510, epoch: 88, loss: 0.638432
global_step: 35511, epoch: 88, loss: 0.682259
global_step: 35512, epoch: 88, loss: 0.652088
global_step: 35513, epoch: 88, loss: 0.633027
global_step: 35514, epoch: 88, loss: 0.581361
global_step: 35515, epoch: 88, loss: 0.534041
global_step: 35516, epoch: 88, loss: 0.608811
global_step: 35517, epoch: 88, loss: 0.695505
global_step: 35518, epoch: 88, loss: 0.624537
global_step: 35519, epoch: 88, loss: 0.604473
global_step: 35520, epoch: 88, loss: 0.344587
epoch: 88
train	acc: 0.8504	macro: p 0.8495, r 0.6150, f1: 0.6316	micro: p 0.8504, r 0.8504, f1 0.8504	weighted_f1:0.8310
dev	acc: 0.5609	macro: p 0.5037, r 0.3309, f1: 0.3335	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5150
test	acc: 0.6057	macro: p 0.4261, r 0.3347, f1: 0.3369	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5648
global_step: 35521, epoch: 89, loss: 0.616448
global_step: 35522, epoch: 89, loss: 0.694478
global_step: 35523, epoch: 89, loss: 0.559731
global_step: 35524, epoch: 89, loss: 0.541738
global_step: 35525, epoch: 89, loss: 0.584242
global_step: 35526, epoch: 89, loss: 0.529783
global_step: 35527, epoch: 89, loss: 0.683243
global_step: 35528, epoch: 89, loss: 0.541471
global_step: 35529, epoch: 89, loss: 0.583581
global_step: 35530, epoch: 89, loss: 0.706556
global_step: 35531, epoch: 89, loss: 0.609048
global_step: 35532, epoch: 89, loss: 0.557000
global_step: 35533, epoch: 89, loss: 0.574998
global_step: 35534, epoch: 89, loss: 0.658200
global_step: 35535, epoch: 89, loss: 0.625184
global_step: 35536, epoch: 89, loss: 0.547270
global_step: 35537, epoch: 89, loss: 0.610469
global_step: 35538, epoch: 89, loss: 0.511387
global_step: 35539, epoch: 89, loss: 0.550816
global_step: 35540, epoch: 89, loss: 0.657829
global_step: 35541, epoch: 89, loss: 0.509078
global_step: 35542, epoch: 89, loss: 0.650691
global_step: 35543, epoch: 89, loss: 0.583990
global_step: 35544, epoch: 89, loss: 0.664640
global_step: 35545, epoch: 89, loss: 0.667111
global_step: 35546, epoch: 89, loss: 0.623537
global_step: 35547, epoch: 89, loss: 0.515279
global_step: 35548, epoch: 89, loss: 0.746847
global_step: 35549, epoch: 89, loss: 0.699094
global_step: 35550, epoch: 89, loss: 0.710676
global_step: 35551, epoch: 89, loss: 0.575927
global_step: 35552, epoch: 89, loss: 0.544761
global_step: 35553, epoch: 89, loss: 0.700509
global_step: 35554, epoch: 89, loss: 0.674442
global_step: 35555, epoch: 89, loss: 0.599641
global_step: 35556, epoch: 89, loss: 0.659077
global_step: 35557, epoch: 89, loss: 0.696528
global_step: 35558, epoch: 89, loss: 0.690847
global_step: 35559, epoch: 89, loss: 0.602203
global_step: 35560, epoch: 89, loss: 1.661010
epoch: 89
train	acc: 0.8682	macro: p 0.8280, r 0.6635, f1: 0.6775	micro: p 0.8682, r 0.8682, f1 0.8682	weighted_f1:0.8544
dev	acc: 0.5681	macro: p 0.4282, r 0.3539, f1: 0.3557	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5313
test	acc: 0.5977	macro: p 0.4017, r 0.3405, f1: 0.3412	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5648
global_step: 35561, epoch: 90, loss: 0.591456
global_step: 35562, epoch: 90, loss: 0.593215
global_step: 35563, epoch: 90, loss: 0.636476
global_step: 35564, epoch: 90, loss: 0.622062
global_step: 35565, epoch: 90, loss: 0.596505
global_step: 35566, epoch: 90, loss: 0.661087
global_step: 35567, epoch: 90, loss: 0.577931
global_step: 35568, epoch: 90, loss: 0.648297
global_step: 35569, epoch: 90, loss: 0.702303
global_step: 35570, epoch: 90, loss: 0.624015
global_step: 35571, epoch: 90, loss: 0.510726
global_step: 35572, epoch: 90, loss: 0.636128
global_step: 35573, epoch: 90, loss: 0.559614
global_step: 35574, epoch: 90, loss: 0.556126
global_step: 35575, epoch: 90, loss: 0.609307
global_step: 35576, epoch: 90, loss: 0.611505
global_step: 35577, epoch: 90, loss: 0.682242
global_step: 35578, epoch: 90, loss: 0.574830
global_step: 35579, epoch: 90, loss: 0.667979
global_step: 35580, epoch: 90, loss: 0.664429
global_step: 35581, epoch: 90, loss: 0.591765
global_step: 35582, epoch: 90, loss: 0.615048
global_step: 35583, epoch: 90, loss: 0.534320
global_step: 35584, epoch: 90, loss: 0.559128
global_step: 35585, epoch: 90, loss: 0.528453
global_step: 35586, epoch: 90, loss: 0.607896
global_step: 35587, epoch: 90, loss: 0.662553
global_step: 35588, epoch: 90, loss: 0.678583
global_step: 35589, epoch: 90, loss: 0.598115
global_step: 35590, epoch: 90, loss: 0.610826
global_step: 35591, epoch: 90, loss: 0.601387
global_step: 35592, epoch: 90, loss: 0.603635
global_step: 35593, epoch: 90, loss: 0.596560
global_step: 35594, epoch: 90, loss: 0.615272
global_step: 35595, epoch: 90, loss: 0.470470
global_step: 35596, epoch: 90, loss: 0.701410
global_step: 35597, epoch: 90, loss: 0.611261
global_step: 35598, epoch: 90, loss: 0.601157
global_step: 35599, epoch: 90, loss: 0.537530
global_step: 35600, epoch: 90, loss: 1.340268
epoch: 90
train	acc: 0.8683	macro: p 0.8367, r 0.6672, f1: 0.6839	micro: p 0.8683, r 0.8683, f1 0.8683	weighted_f1:0.8559
dev	acc: 0.5627	macro: p 0.4224, r 0.3478, f1: 0.3516	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5292
test	acc: 0.5996	macro: p 0.3885, r 0.3455, f1: 0.3477	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5715
global_step: 35601, epoch: 91, loss: 0.639886
global_step: 35602, epoch: 91, loss: 0.631913
global_step: 35603, epoch: 91, loss: 0.621620
global_step: 35604, epoch: 91, loss: 0.633715
global_step: 35605, epoch: 91, loss: 0.600667
global_step: 35606, epoch: 91, loss: 0.552738
global_step: 35607, epoch: 91, loss: 0.548634
global_step: 35608, epoch: 91, loss: 0.579801
global_step: 35609, epoch: 91, loss: 0.580917
global_step: 35610, epoch: 91, loss: 0.543522
global_step: 35611, epoch: 91, loss: 0.580324
global_step: 35612, epoch: 91, loss: 0.653627
global_step: 35613, epoch: 91, loss: 0.613786
global_step: 35614, epoch: 91, loss: 0.626398
global_step: 35615, epoch: 91, loss: 0.551756
global_step: 35616, epoch: 91, loss: 0.536873
global_step: 35617, epoch: 91, loss: 0.720755
global_step: 35618, epoch: 91, loss: 0.614017
global_step: 35619, epoch: 91, loss: 0.579665
global_step: 35620, epoch: 91, loss: 0.585810
global_step: 35621, epoch: 91, loss: 0.728086
global_step: 35622, epoch: 91, loss: 0.528651
global_step: 35623, epoch: 91, loss: 0.577837
global_step: 35624, epoch: 91, loss: 0.580913
global_step: 35625, epoch: 91, loss: 0.593084
global_step: 35626, epoch: 91, loss: 0.687798
global_step: 35627, epoch: 91, loss: 0.616400
global_step: 35628, epoch: 91, loss: 0.524979
global_step: 35629, epoch: 91, loss: 0.594094
global_step: 35630, epoch: 91, loss: 0.538195
global_step: 35631, epoch: 91, loss: 0.658870
global_step: 35632, epoch: 91, loss: 0.514861
global_step: 35633, epoch: 91, loss: 0.613064
global_step: 35634, epoch: 91, loss: 0.543438
global_step: 35635, epoch: 91, loss: 0.702851
global_step: 35636, epoch: 91, loss: 0.625287
global_step: 35637, epoch: 91, loss: 0.611932
global_step: 35638, epoch: 91, loss: 0.682998
global_step: 35639, epoch: 91, loss: 0.492056
global_step: 35640, epoch: 91, loss: 1.207099
epoch: 91
train	acc: 0.8661	macro: p 0.8286, r 0.6524, f1: 0.6618	micro: p 0.8661, r 0.8661, f1 0.8661	weighted_f1:0.8510
dev	acc: 0.5573	macro: p 0.4864, r 0.3439, f1: 0.3456	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5231
test	acc: 0.5969	macro: p 0.4143, r 0.3436, f1: 0.3408	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5666
global_step: 35641, epoch: 92, loss: 0.601550
global_step: 35642, epoch: 92, loss: 0.677028
global_step: 35643, epoch: 92, loss: 0.655635
global_step: 35644, epoch: 92, loss: 0.519933
global_step: 35645, epoch: 92, loss: 0.600553
global_step: 35646, epoch: 92, loss: 0.627426
global_step: 35647, epoch: 92, loss: 0.585593
global_step: 35648, epoch: 92, loss: 0.545061
global_step: 35649, epoch: 92, loss: 0.580360
global_step: 35650, epoch: 92, loss: 0.642231
global_step: 35651, epoch: 92, loss: 0.715028
global_step: 35652, epoch: 92, loss: 0.536506
global_step: 35653, epoch: 92, loss: 0.606408
global_step: 35654, epoch: 92, loss: 0.504904
global_step: 35655, epoch: 92, loss: 0.587651
global_step: 35656, epoch: 92, loss: 0.576990
global_step: 35657, epoch: 92, loss: 0.624686
global_step: 35658, epoch: 92, loss: 0.549025
global_step: 35659, epoch: 92, loss: 0.577493
global_step: 35660, epoch: 92, loss: 0.586665
global_step: 35661, epoch: 92, loss: 0.473943
global_step: 35662, epoch: 92, loss: 0.648860
global_step: 35663, epoch: 92, loss: 0.591717
global_step: 35664, epoch: 92, loss: 0.649483
global_step: 35665, epoch: 92, loss: 0.616957
global_step: 35666, epoch: 92, loss: 0.638620
global_step: 35667, epoch: 92, loss: 0.536456
global_step: 35668, epoch: 92, loss: 0.462704
global_step: 35669, epoch: 92, loss: 0.720013
global_step: 35670, epoch: 92, loss: 0.573009
global_step: 35671, epoch: 92, loss: 0.640577
global_step: 35672, epoch: 92, loss: 0.643456
global_step: 35673, epoch: 92, loss: 0.601118
global_step: 35674, epoch: 92, loss: 0.593817
global_step: 35675, epoch: 92, loss: 0.627658
global_step: 35676, epoch: 92, loss: 0.673033
global_step: 35677, epoch: 92, loss: 0.587131
global_step: 35678, epoch: 92, loss: 0.565162
global_step: 35679, epoch: 92, loss: 0.540334
global_step: 35680, epoch: 92, loss: 1.037074
epoch: 92
train	acc: 0.8694	macro: p 0.8255, r 0.6559, f1: 0.6694	micro: p 0.8694, r 0.8694, f1 0.8694	weighted_f1:0.8548
dev	acc: 0.5681	macro: p 0.4990, r 0.3484, f1: 0.3538	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5338
test	acc: 0.6057	macro: p 0.4110, r 0.3463, f1: 0.3496	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5753
global_step: 35681, epoch: 93, loss: 0.544114
global_step: 35682, epoch: 93, loss: 0.528678
global_step: 35683, epoch: 93, loss: 0.608603
global_step: 35684, epoch: 93, loss: 0.499421
global_step: 35685, epoch: 93, loss: 0.678104
global_step: 35686, epoch: 93, loss: 0.604107
global_step: 35687, epoch: 93, loss: 0.542931
global_step: 35688, epoch: 93, loss: 0.701463
global_step: 35689, epoch: 93, loss: 0.557007
global_step: 35690, epoch: 93, loss: 0.584517
global_step: 35691, epoch: 93, loss: 0.587873
global_step: 35692, epoch: 93, loss: 0.535126
global_step: 35693, epoch: 93, loss: 0.552966
global_step: 35694, epoch: 93, loss: 0.638378
global_step: 35695, epoch: 93, loss: 0.641382
global_step: 35696, epoch: 93, loss: 0.548889
global_step: 35697, epoch: 93, loss: 0.611357
global_step: 35698, epoch: 93, loss: 0.575061
global_step: 35699, epoch: 93, loss: 0.502126
global_step: 35700, epoch: 93, loss: 0.621156
global_step: 35701, epoch: 93, loss: 0.548664
global_step: 35702, epoch: 93, loss: 0.548925
global_step: 35703, epoch: 93, loss: 0.544974
global_step: 35704, epoch: 93, loss: 0.597362
global_step: 35705, epoch: 93, loss: 0.638677
global_step: 35706, epoch: 93, loss: 0.630380
global_step: 35707, epoch: 93, loss: 0.559516
global_step: 35708, epoch: 93, loss: 0.663308
global_step: 35709, epoch: 93, loss: 0.548355
global_step: 35710, epoch: 93, loss: 0.596656
global_step: 35711, epoch: 93, loss: 0.565057
global_step: 35712, epoch: 93, loss: 0.539604
global_step: 35713, epoch: 93, loss: 0.552512
global_step: 35714, epoch: 93, loss: 0.555802
global_step: 35715, epoch: 93, loss: 0.625383
global_step: 35716, epoch: 93, loss: 0.716175
global_step: 35717, epoch: 93, loss: 0.538662
global_step: 35718, epoch: 93, loss: 0.570156
global_step: 35719, epoch: 93, loss: 0.578672
global_step: 35720, epoch: 93, loss: 0.956779
epoch: 93
train	acc: 0.8664	macro: p 0.8414, r 0.6502, f1: 0.6601	micro: p 0.8664, r 0.8664, f1 0.8664	weighted_f1:0.8512
dev	acc: 0.5645	macro: p 0.4952, r 0.3422, f1: 0.3484	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5278
test	acc: 0.6027	macro: p 0.4258, r 0.3362, f1: 0.3439	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5686
global_step: 35721, epoch: 94, loss: 0.533684
global_step: 35722, epoch: 94, loss: 0.472781
global_step: 35723, epoch: 94, loss: 0.599628
global_step: 35724, epoch: 94, loss: 0.686669
global_step: 35725, epoch: 94, loss: 0.582533
global_step: 35726, epoch: 94, loss: 0.525676
global_step: 35727, epoch: 94, loss: 0.615217
global_step: 35728, epoch: 94, loss: 0.568184
global_step: 35729, epoch: 94, loss: 0.587127
global_step: 35730, epoch: 94, loss: 0.549774
global_step: 35731, epoch: 94, loss: 0.655043
global_step: 35732, epoch: 94, loss: 0.506471
global_step: 35733, epoch: 94, loss: 0.592984
global_step: 35734, epoch: 94, loss: 0.497775
global_step: 35735, epoch: 94, loss: 0.537016
global_step: 35736, epoch: 94, loss: 0.555582
global_step: 35737, epoch: 94, loss: 0.562609
global_step: 35738, epoch: 94, loss: 0.577087
global_step: 35739, epoch: 94, loss: 0.554228
global_step: 35740, epoch: 94, loss: 0.678971
global_step: 35741, epoch: 94, loss: 0.675916
global_step: 35742, epoch: 94, loss: 0.587027
global_step: 35743, epoch: 94, loss: 0.522105
global_step: 35744, epoch: 94, loss: 0.571265
global_step: 35745, epoch: 94, loss: 0.651890
global_step: 35746, epoch: 94, loss: 0.551433
global_step: 35747, epoch: 94, loss: 0.623484
global_step: 35748, epoch: 94, loss: 0.542618
global_step: 35749, epoch: 94, loss: 0.569174
global_step: 35750, epoch: 94, loss: 0.644466
global_step: 35751, epoch: 94, loss: 0.502742
global_step: 35752, epoch: 94, loss: 0.622876
global_step: 35753, epoch: 94, loss: 0.697513
global_step: 35754, epoch: 94, loss: 0.542337
global_step: 35755, epoch: 94, loss: 0.487692
global_step: 35756, epoch: 94, loss: 0.501204
global_step: 35757, epoch: 94, loss: 0.632487
global_step: 35758, epoch: 94, loss: 0.560125
global_step: 35759, epoch: 94, loss: 0.604602
global_step: 35760, epoch: 94, loss: 0.290446
epoch: 94
train	acc: 0.8725	macro: p 0.8510, r 0.6606, f1: 0.6714	micro: p 0.8725, r 0.8725, f1 0.8725	weighted_f1:0.8577
dev	acc: 0.5681	macro: p 0.5014, r 0.3518, f1: 0.3561	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5365
test	acc: 0.6027	macro: p 0.3895, r 0.3460, f1: 0.3459	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5730
global_step: 35761, epoch: 95, loss: 0.704529
global_step: 35762, epoch: 95, loss: 0.563106
global_step: 35763, epoch: 95, loss: 0.493890
global_step: 35764, epoch: 95, loss: 0.556519
global_step: 35765, epoch: 95, loss: 0.532447
global_step: 35766, epoch: 95, loss: 0.588819
global_step: 35767, epoch: 95, loss: 0.607492
global_step: 35768, epoch: 95, loss: 0.551688
global_step: 35769, epoch: 95, loss: 0.653960
global_step: 35770, epoch: 95, loss: 0.652713
global_step: 35771, epoch: 95, loss: 0.553065
global_step: 35772, epoch: 95, loss: 0.543974
global_step: 35773, epoch: 95, loss: 0.621883
global_step: 35774, epoch: 95, loss: 0.661191
global_step: 35775, epoch: 95, loss: 0.628669
global_step: 35776, epoch: 95, loss: 0.578690
global_step: 35777, epoch: 95, loss: 0.609673
global_step: 35778, epoch: 95, loss: 0.494960
global_step: 35779, epoch: 95, loss: 0.552402
global_step: 35780, epoch: 95, loss: 0.491230
global_step: 35781, epoch: 95, loss: 0.498887
global_step: 35782, epoch: 95, loss: 0.572163
global_step: 35783, epoch: 95, loss: 0.568968
global_step: 35784, epoch: 95, loss: 0.508911
global_step: 35785, epoch: 95, loss: 0.532777
global_step: 35786, epoch: 95, loss: 0.530797
global_step: 35787, epoch: 95, loss: 0.600588
global_step: 35788, epoch: 95, loss: 0.634867
global_step: 35789, epoch: 95, loss: 0.560640
global_step: 35790, epoch: 95, loss: 0.582978
global_step: 35791, epoch: 95, loss: 0.508750
global_step: 35792, epoch: 95, loss: 0.603075
global_step: 35793, epoch: 95, loss: 0.581028
global_step: 35794, epoch: 95, loss: 0.561189
global_step: 35795, epoch: 95, loss: 0.544150
global_step: 35796, epoch: 95, loss: 0.589055
global_step: 35797, epoch: 95, loss: 0.608918
global_step: 35798, epoch: 95, loss: 0.677206
global_step: 35799, epoch: 95, loss: 0.577032
global_step: 35800, epoch: 95, loss: 0.334104
epoch: 95
train	acc: 0.8745	macro: p 0.8425, r 0.6688, f1: 0.6851	micro: p 0.8745, r 0.8745, f1 0.8745	weighted_f1:0.8600
dev	acc: 0.5672	macro: p 0.4243, r 0.3478, f1: 0.3471	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5274
test	acc: 0.6023	macro: p 0.4033, r 0.3416, f1: 0.3414	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5674
global_step: 35801, epoch: 96, loss: 0.566948
global_step: 35802, epoch: 96, loss: 0.605629
global_step: 35803, epoch: 96, loss: 0.609139
global_step: 35804, epoch: 96, loss: 0.527785
global_step: 35805, epoch: 96, loss: 0.638155
global_step: 35806, epoch: 96, loss: 0.630178
global_step: 35807, epoch: 96, loss: 0.494198
global_step: 35808, epoch: 96, loss: 0.510441
global_step: 35809, epoch: 96, loss: 0.576261
global_step: 35810, epoch: 96, loss: 0.715401
global_step: 35811, epoch: 96, loss: 0.544178
global_step: 35812, epoch: 96, loss: 0.592268
global_step: 35813, epoch: 96, loss: 0.562868
global_step: 35814, epoch: 96, loss: 0.589625
global_step: 35815, epoch: 96, loss: 0.556869
global_step: 35816, epoch: 96, loss: 0.564647
global_step: 35817, epoch: 96, loss: 0.627212
global_step: 35818, epoch: 96, loss: 0.651446
global_step: 35819, epoch: 96, loss: 0.607687
global_step: 35820, epoch: 96, loss: 0.583391
global_step: 35821, epoch: 96, loss: 0.550127
global_step: 35822, epoch: 96, loss: 0.559269
global_step: 35823, epoch: 96, loss: 0.473547
global_step: 35824, epoch: 96, loss: 0.521500
global_step: 35825, epoch: 96, loss: 0.526762
global_step: 35826, epoch: 96, loss: 0.609848
global_step: 35827, epoch: 96, loss: 0.560533
global_step: 35828, epoch: 96, loss: 0.599831
global_step: 35829, epoch: 96, loss: 0.567815
global_step: 35830, epoch: 96, loss: 0.551948
global_step: 35831, epoch: 96, loss: 0.591285
global_step: 35832, epoch: 96, loss: 0.614985
global_step: 35833, epoch: 96, loss: 0.581957
global_step: 35834, epoch: 96, loss: 0.589947
global_step: 35835, epoch: 96, loss: 0.575248
global_step: 35836, epoch: 96, loss: 0.573961
global_step: 35837, epoch: 96, loss: 0.598113
global_step: 35838, epoch: 96, loss: 0.552125
global_step: 35839, epoch: 96, loss: 0.592511
global_step: 35840, epoch: 96, loss: 0.633726
epoch: 96
train	acc: 0.8531	macro: p 0.8292, r 0.6281, f1: 0.6538	micro: p 0.8531, r 0.8531, f1 0.8531	weighted_f1:0.8351
dev	acc: 0.5546	macro: p 0.4994, r 0.3216, f1: 0.3212	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5014
test	acc: 0.5989	macro: p 0.3909, r 0.3192, f1: 0.3174	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5487
global_step: 35841, epoch: 97, loss: 0.646559
global_step: 35842, epoch: 97, loss: 0.688616
global_step: 35843, epoch: 97, loss: 0.575418
global_step: 35844, epoch: 97, loss: 0.587226
global_step: 35845, epoch: 97, loss: 0.449333
global_step: 35846, epoch: 97, loss: 0.567676
global_step: 35847, epoch: 97, loss: 0.491320
global_step: 35848, epoch: 97, loss: 0.588981
global_step: 35849, epoch: 97, loss: 0.524881
global_step: 35850, epoch: 97, loss: 0.550957
global_step: 35851, epoch: 97, loss: 0.614881
global_step: 35852, epoch: 97, loss: 0.590747
global_step: 35853, epoch: 97, loss: 0.482301
global_step: 35854, epoch: 97, loss: 0.526437
global_step: 35855, epoch: 97, loss: 0.572298
global_step: 35856, epoch: 97, loss: 0.523521
global_step: 35857, epoch: 97, loss: 0.555960
global_step: 35858, epoch: 97, loss: 0.605635
global_step: 35859, epoch: 97, loss: 0.609298
global_step: 35860, epoch: 97, loss: 0.568246
global_step: 35861, epoch: 97, loss: 0.547089
global_step: 35862, epoch: 97, loss: 0.447439
global_step: 35863, epoch: 97, loss: 0.554206
global_step: 35864, epoch: 97, loss: 0.616323
global_step: 35865, epoch: 97, loss: 0.542356
global_step: 35866, epoch: 97, loss: 0.575331
global_step: 35867, epoch: 97, loss: 0.554525
global_step: 35868, epoch: 97, loss: 0.502803
global_step: 35869, epoch: 97, loss: 0.547848
global_step: 35870, epoch: 97, loss: 0.480477
global_step: 35871, epoch: 97, loss: 0.602281
global_step: 35872, epoch: 97, loss: 0.563520
global_step: 35873, epoch: 97, loss: 0.572940
global_step: 35874, epoch: 97, loss: 0.638168
global_step: 35875, epoch: 97, loss: 0.570339
global_step: 35876, epoch: 97, loss: 0.515433
global_step: 35877, epoch: 97, loss: 0.552278
global_step: 35878, epoch: 97, loss: 0.525946
global_step: 35879, epoch: 97, loss: 0.605873
global_step: 35880, epoch: 97, loss: 0.054648
epoch: 97
train	acc: 0.8759	macro: p 0.8550, r 0.6796, f1: 0.7059	micro: p 0.8759, r 0.8759, f1 0.8759	weighted_f1:0.8632
dev	acc: 0.5654	macro: p 0.4286, r 0.3394, f1: 0.3441	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5248
test	acc: 0.6100	macro: p 0.3808, r 0.3386, f1: 0.3419	micro: p 0.6100, r 0.6100, f1 0.6100	weighted_f1:0.5721
global_step: 35881, epoch: 98, loss: 0.495860
global_step: 35882, epoch: 98, loss: 0.518763
global_step: 35883, epoch: 98, loss: 0.519213
global_step: 35884, epoch: 98, loss: 0.560942
global_step: 35885, epoch: 98, loss: 0.526640
global_step: 35886, epoch: 98, loss: 0.557254
global_step: 35887, epoch: 98, loss: 0.546911
global_step: 35888, epoch: 98, loss: 0.468242
global_step: 35889, epoch: 98, loss: 0.505120
global_step: 35890, epoch: 98, loss: 0.478016
global_step: 35891, epoch: 98, loss: 0.651482
global_step: 35892, epoch: 98, loss: 0.487406
global_step: 35893, epoch: 98, loss: 0.553867
global_step: 35894, epoch: 98, loss: 0.493489
global_step: 35895, epoch: 98, loss: 0.515199
global_step: 35896, epoch: 98, loss: 0.642077
global_step: 35897, epoch: 98, loss: 0.508637
global_step: 35898, epoch: 98, loss: 0.647152
global_step: 35899, epoch: 98, loss: 0.538021
global_step: 35900, epoch: 98, loss: 0.507801
global_step: 35901, epoch: 98, loss: 0.566263
global_step: 35902, epoch: 98, loss: 0.563639
global_step: 35903, epoch: 98, loss: 0.579478
global_step: 35904, epoch: 98, loss: 0.553212
global_step: 35905, epoch: 98, loss: 0.517105
global_step: 35906, epoch: 98, loss: 0.676528
global_step: 35907, epoch: 98, loss: 0.642411
global_step: 35908, epoch: 98, loss: 0.591367
global_step: 35909, epoch: 98, loss: 0.602737
global_step: 35910, epoch: 98, loss: 0.625284
global_step: 35911, epoch: 98, loss: 0.636026
global_step: 35912, epoch: 98, loss: 0.541752
global_step: 35913, epoch: 98, loss: 0.564832
global_step: 35914, epoch: 98, loss: 0.525565
global_step: 35915, epoch: 98, loss: 0.469118
global_step: 35916, epoch: 98, loss: 0.608339
global_step: 35917, epoch: 98, loss: 0.482722
global_step: 35918, epoch: 98, loss: 0.497236
global_step: 35919, epoch: 98, loss: 0.633079
global_step: 35920, epoch: 98, loss: 0.514498
epoch: 98
train	acc: 0.8659	macro: p 0.8559, r 0.6489, f1: 0.6753	micro: p 0.8659, r 0.8659, f1 0.8659	weighted_f1:0.8499
dev	acc: 0.5717	macro: p 0.4446, r 0.3344, f1: 0.3435	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5251
test	acc: 0.6027	macro: p 0.4264, r 0.3227, f1: 0.3310	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5590
global_step: 35921, epoch: 99, loss: 0.540112
global_step: 35922, epoch: 99, loss: 0.512048
global_step: 35923, epoch: 99, loss: 0.582138
global_step: 35924, epoch: 99, loss: 0.556461
global_step: 35925, epoch: 99, loss: 0.597011
global_step: 35926, epoch: 99, loss: 0.502491
global_step: 35927, epoch: 99, loss: 0.553960
global_step: 35928, epoch: 99, loss: 0.560838
global_step: 35929, epoch: 99, loss: 0.551760
global_step: 35930, epoch: 99, loss: 0.453463
global_step: 35931, epoch: 99, loss: 0.605851
global_step: 35932, epoch: 99, loss: 0.621973
global_step: 35933, epoch: 99, loss: 0.627580
global_step: 35934, epoch: 99, loss: 0.568567
global_step: 35935, epoch: 99, loss: 0.580603
global_step: 35936, epoch: 99, loss: 0.586339
global_step: 35937, epoch: 99, loss: 0.481118
global_step: 35938, epoch: 99, loss: 0.563209
global_step: 35939, epoch: 99, loss: 0.627618
global_step: 35940, epoch: 99, loss: 0.517896
global_step: 35941, epoch: 99, loss: 0.595726
global_step: 35942, epoch: 99, loss: 0.507630
global_step: 35943, epoch: 99, loss: 0.578865
global_step: 35944, epoch: 99, loss: 0.583754
global_step: 35945, epoch: 99, loss: 0.649895
global_step: 35946, epoch: 99, loss: 0.627419
global_step: 35947, epoch: 99, loss: 0.566673
global_step: 35948, epoch: 99, loss: 0.500307
global_step: 35949, epoch: 99, loss: 0.486851
global_step: 35950, epoch: 99, loss: 0.503896
global_step: 35951, epoch: 99, loss: 0.501009
global_step: 35952, epoch: 99, loss: 0.509858
global_step: 35953, epoch: 99, loss: 0.481336
global_step: 35954, epoch: 99, loss: 0.567286
global_step: 35955, epoch: 99, loss: 0.511143
global_step: 35956, epoch: 99, loss: 0.590855
global_step: 35957, epoch: 99, loss: 0.545085
global_step: 35958, epoch: 99, loss: 0.500887
global_step: 35959, epoch: 99, loss: 0.548333
global_step: 35960, epoch: 99, loss: 0.047649
epoch: 99
train	acc: 0.8785	macro: p 0.8683, r 0.6827, f1: 0.7127	micro: p 0.8785, r 0.8785, f1 0.8785	weighted_f1:0.8660
dev	acc: 0.5708	macro: p 0.4379, r 0.3401, f1: 0.3460	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5257
test	acc: 0.5981	macro: p 0.3713, r 0.3241, f1: 0.3267	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5569
global_step: 35961, epoch: 100, loss: 0.611692
global_step: 35962, epoch: 100, loss: 0.550154
global_step: 35963, epoch: 100, loss: 0.536855
global_step: 35964, epoch: 100, loss: 0.478810
global_step: 35965, epoch: 100, loss: 0.567778
global_step: 35966, epoch: 100, loss: 0.575217
global_step: 35967, epoch: 100, loss: 0.570056
global_step: 35968, epoch: 100, loss: 0.509227
global_step: 35969, epoch: 100, loss: 0.518773
global_step: 35970, epoch: 100, loss: 0.442428
global_step: 35971, epoch: 100, loss: 0.589603
global_step: 35972, epoch: 100, loss: 0.580827
global_step: 35973, epoch: 100, loss: 0.515174
global_step: 35974, epoch: 100, loss: 0.502582
global_step: 35975, epoch: 100, loss: 0.488483
global_step: 35976, epoch: 100, loss: 0.581471
global_step: 35977, epoch: 100, loss: 0.578927
global_step: 35978, epoch: 100, loss: 0.721248
global_step: 35979, epoch: 100, loss: 0.498838
global_step: 35980, epoch: 100, loss: 0.538339
global_step: 35981, epoch: 100, loss: 0.557778
global_step: 35982, epoch: 100, loss: 0.541358
global_step: 35983, epoch: 100, loss: 0.559741
global_step: 35984, epoch: 100, loss: 0.564250
global_step: 35985, epoch: 100, loss: 0.501885
global_step: 35986, epoch: 100, loss: 0.524320
global_step: 35987, epoch: 100, loss: 0.476264
global_step: 35988, epoch: 100, loss: 0.564598
global_step: 35989, epoch: 100, loss: 0.606435
global_step: 35990, epoch: 100, loss: 0.566915
global_step: 35991, epoch: 100, loss: 0.575631
global_step: 35992, epoch: 100, loss: 0.599844
global_step: 35993, epoch: 100, loss: 0.615706
global_step: 35994, epoch: 100, loss: 0.527668
global_step: 35995, epoch: 100, loss: 0.513768
global_step: 35996, epoch: 100, loss: 0.580325
global_step: 35997, epoch: 100, loss: 0.511739
global_step: 35998, epoch: 100, loss: 0.567938
global_step: 35999, epoch: 100, loss: 0.483527
global_step: 36000, epoch: 100, loss: 0.334955
epoch: 100
train	acc: 0.8763	macro: p 0.8608, r 0.6768, f1: 0.7078	micro: p 0.8763, r 0.8763, f1 0.8763	weighted_f1:0.8632
dev	acc: 0.5726	macro: p 0.4221, r 0.3379, f1: 0.3448	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.5271
test	acc: 0.6057	macro: p 0.3958, r 0.3313, f1: 0.3369	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5645
global_step: 36001, epoch: 101, loss: 0.566932
global_step: 36002, epoch: 101, loss: 0.464386
global_step: 36003, epoch: 101, loss: 0.528044
global_step: 36004, epoch: 101, loss: 0.448224
global_step: 36005, epoch: 101, loss: 0.453349
global_step: 36006, epoch: 101, loss: 0.526762
global_step: 36007, epoch: 101, loss: 0.521793
global_step: 36008, epoch: 101, loss: 0.520249
global_step: 36009, epoch: 101, loss: 0.558670
global_step: 36010, epoch: 101, loss: 0.616587
global_step: 36011, epoch: 101, loss: 0.589442
global_step: 36012, epoch: 101, loss: 0.598301
global_step: 36013, epoch: 101, loss: 0.472760
global_step: 36014, epoch: 101, loss: 0.461689
global_step: 36015, epoch: 101, loss: 0.585289
global_step: 36016, epoch: 101, loss: 0.517954
global_step: 36017, epoch: 101, loss: 0.576346
global_step: 36018, epoch: 101, loss: 0.527786
global_step: 36019, epoch: 101, loss: 0.423657
global_step: 36020, epoch: 101, loss: 0.512423
global_step: 36021, epoch: 101, loss: 0.535162
global_step: 36022, epoch: 101, loss: 0.530751
global_step: 36023, epoch: 101, loss: 0.591315
global_step: 36024, epoch: 101, loss: 0.585904
global_step: 36025, epoch: 101, loss: 0.602345
global_step: 36026, epoch: 101, loss: 0.591802
global_step: 36027, epoch: 101, loss: 0.524530
global_step: 36028, epoch: 101, loss: 0.473305
global_step: 36029, epoch: 101, loss: 0.559748
global_step: 36030, epoch: 101, loss: 0.591854
global_step: 36031, epoch: 101, loss: 0.603626
global_step: 36032, epoch: 101, loss: 0.470949
global_step: 36033, epoch: 101, loss: 0.575428
global_step: 36034, epoch: 101, loss: 0.656420
global_step: 36035, epoch: 101, loss: 0.631360
global_step: 36036, epoch: 101, loss: 0.557391
global_step: 36037, epoch: 101, loss: 0.515966
global_step: 36038, epoch: 101, loss: 0.528100
global_step: 36039, epoch: 101, loss: 0.447128
global_step: 36040, epoch: 101, loss: 0.830223
epoch: 101
train	acc: 0.8859	macro: p 0.8627, r 0.6921, f1: 0.7123	micro: p 0.8859, r 0.8859, f1 0.8859	weighted_f1:0.8735
dev	acc: 0.5555	macro: p 0.3811, r 0.3422, f1: 0.3392	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5201
test	acc: 0.6004	macro: p 0.3957, r 0.3457, f1: 0.3421	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5678
global_step: 36041, epoch: 102, loss: 0.643920
global_step: 36042, epoch: 102, loss: 0.513221
global_step: 36043, epoch: 102, loss: 0.586082
global_step: 36044, epoch: 102, loss: 0.611570
global_step: 36045, epoch: 102, loss: 0.552718
global_step: 36046, epoch: 102, loss: 0.474775
global_step: 36047, epoch: 102, loss: 0.491660
global_step: 36048, epoch: 102, loss: 0.575977
global_step: 36049, epoch: 102, loss: 0.483078
global_step: 36050, epoch: 102, loss: 0.564363
global_step: 36051, epoch: 102, loss: 0.547709
global_step: 36052, epoch: 102, loss: 0.461921
global_step: 36053, epoch: 102, loss: 0.603465
global_step: 36054, epoch: 102, loss: 0.447101
global_step: 36055, epoch: 102, loss: 0.448934
global_step: 36056, epoch: 102, loss: 0.563209
global_step: 36057, epoch: 102, loss: 0.550776
global_step: 36058, epoch: 102, loss: 0.557430
global_step: 36059, epoch: 102, loss: 0.473566
global_step: 36060, epoch: 102, loss: 0.600410
global_step: 36061, epoch: 102, loss: 0.577420
global_step: 36062, epoch: 102, loss: 0.552254
global_step: 36063, epoch: 102, loss: 0.520824
global_step: 36064, epoch: 102, loss: 0.531811
global_step: 36065, epoch: 102, loss: 0.428186
global_step: 36066, epoch: 102, loss: 0.580626
global_step: 36067, epoch: 102, loss: 0.455649
global_step: 36068, epoch: 102, loss: 0.464315
global_step: 36069, epoch: 102, loss: 0.422639
global_step: 36070, epoch: 102, loss: 0.565101
global_step: 36071, epoch: 102, loss: 0.478921
global_step: 36072, epoch: 102, loss: 0.635029
global_step: 36073, epoch: 102, loss: 0.521694
global_step: 36074, epoch: 102, loss: 0.521007
global_step: 36075, epoch: 102, loss: 0.501171
global_step: 36076, epoch: 102, loss: 0.577477
global_step: 36077, epoch: 102, loss: 0.475067
global_step: 36078, epoch: 102, loss: 0.579909
global_step: 36079, epoch: 102, loss: 0.598606
global_step: 36080, epoch: 102, loss: 0.357656
epoch: 102
train	acc: 0.8656	macro: p 0.8692, r 0.6501, f1: 0.6863	micro: p 0.8656, r 0.8656, f1 0.8656	weighted_f1:0.8500
dev	acc: 0.5618	macro: p 0.4139, r 0.3221, f1: 0.3259	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5093
test	acc: 0.6084	macro: p 0.4121, r 0.3258, f1: 0.3312	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5614
global_step: 36081, epoch: 103, loss: 0.520737
global_step: 36082, epoch: 103, loss: 0.438119
global_step: 36083, epoch: 103, loss: 0.537757
global_step: 36084, epoch: 103, loss: 0.530825
global_step: 36085, epoch: 103, loss: 0.520075
global_step: 36086, epoch: 103, loss: 0.546215
global_step: 36087, epoch: 103, loss: 0.543539
global_step: 36088, epoch: 103, loss: 0.480399
global_step: 36089, epoch: 103, loss: 0.513101
global_step: 36090, epoch: 103, loss: 0.517612
global_step: 36091, epoch: 103, loss: 0.559434
global_step: 36092, epoch: 103, loss: 0.529303
global_step: 36093, epoch: 103, loss: 0.462388
global_step: 36094, epoch: 103, loss: 0.504966
global_step: 36095, epoch: 103, loss: 0.532906
global_step: 36096, epoch: 103, loss: 0.428784
global_step: 36097, epoch: 103, loss: 0.478500
global_step: 36098, epoch: 103, loss: 0.535085
global_step: 36099, epoch: 103, loss: 0.513490
global_step: 36100, epoch: 103, loss: 0.534227
global_step: 36101, epoch: 103, loss: 0.514870
global_step: 36102, epoch: 103, loss: 0.479218
global_step: 36103, epoch: 103, loss: 0.518174
global_step: 36104, epoch: 103, loss: 0.588465
global_step: 36105, epoch: 103, loss: 0.591849
global_step: 36106, epoch: 103, loss: 0.583037
global_step: 36107, epoch: 103, loss: 0.497631
global_step: 36108, epoch: 103, loss: 0.479202
global_step: 36109, epoch: 103, loss: 0.441054
global_step: 36110, epoch: 103, loss: 0.630415
global_step: 36111, epoch: 103, loss: 0.570882
global_step: 36112, epoch: 103, loss: 0.497250
global_step: 36113, epoch: 103, loss: 0.554738
global_step: 36114, epoch: 103, loss: 0.539279
global_step: 36115, epoch: 103, loss: 0.529456
global_step: 36116, epoch: 103, loss: 0.711279
global_step: 36117, epoch: 103, loss: 0.518619
global_step: 36118, epoch: 103, loss: 0.515946
global_step: 36119, epoch: 103, loss: 0.499223
global_step: 36120, epoch: 103, loss: 0.651302
epoch: 103
train	acc: 0.8757	macro: p 0.8699, r 0.6940, f1: 0.7283	micro: p 0.8757, r 0.8757, f1 0.8757	weighted_f1:0.8649
dev	acc: 0.5681	macro: p 0.3988, r 0.3321, f1: 0.3436	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5224
test	acc: 0.6092	macro: p 0.5039, r 0.3369, f1: 0.3583	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5678
global_step: 36121, epoch: 104, loss: 0.581654
global_step: 36122, epoch: 104, loss: 0.453526
global_step: 36123, epoch: 104, loss: 0.516968
global_step: 36124, epoch: 104, loss: 0.620522
global_step: 36125, epoch: 104, loss: 0.549954
global_step: 36126, epoch: 104, loss: 0.489903
global_step: 36127, epoch: 104, loss: 0.468255
global_step: 36128, epoch: 104, loss: 0.489944
global_step: 36129, epoch: 104, loss: 0.511165
global_step: 36130, epoch: 104, loss: 0.431664
global_step: 36131, epoch: 104, loss: 0.467418
global_step: 36132, epoch: 104, loss: 0.482742
global_step: 36133, epoch: 104, loss: 0.651511
global_step: 36134, epoch: 104, loss: 0.567344
global_step: 36135, epoch: 104, loss: 0.489403
global_step: 36136, epoch: 104, loss: 0.488150
global_step: 36137, epoch: 104, loss: 0.642820
global_step: 36138, epoch: 104, loss: 0.394339
global_step: 36139, epoch: 104, loss: 0.523160
global_step: 36140, epoch: 104, loss: 0.492355
global_step: 36141, epoch: 104, loss: 0.569393
global_step: 36142, epoch: 104, loss: 0.460342
global_step: 36143, epoch: 104, loss: 0.467961
global_step: 36144, epoch: 104, loss: 0.605810
global_step: 36145, epoch: 104, loss: 0.468982
global_step: 36146, epoch: 104, loss: 0.542425
global_step: 36147, epoch: 104, loss: 0.454433
global_step: 36148, epoch: 104, loss: 0.504881
global_step: 36149, epoch: 104, loss: 0.625510
global_step: 36150, epoch: 104, loss: 0.465910
global_step: 36151, epoch: 104, loss: 0.547332
global_step: 36152, epoch: 104, loss: 0.470472
global_step: 36153, epoch: 104, loss: 0.496115
global_step: 36154, epoch: 104, loss: 0.565111
global_step: 36155, epoch: 104, loss: 0.552618
global_step: 36156, epoch: 104, loss: 0.507560
global_step: 36157, epoch: 104, loss: 0.559263
global_step: 36158, epoch: 104, loss: 0.461789
global_step: 36159, epoch: 104, loss: 0.502308
global_step: 36160, epoch: 104, loss: 0.121882
epoch: 104
train	acc: 0.8912	macro: p 0.8710, r 0.7145, f1: 0.7414	micro: p 0.8912, r 0.8912, f1 0.8912	weighted_f1:0.8812
dev	acc: 0.5717	macro: p 0.5259, r 0.3510, f1: 0.3551	micro: p 0.5717, r 0.5717, f1 0.5717	weighted_f1:0.5339
test	acc: 0.5992	macro: p 0.3732, r 0.3342, f1: 0.3358	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5638
global_step: 36161, epoch: 105, loss: 0.477824
global_step: 36162, epoch: 105, loss: 0.430231
global_step: 36163, epoch: 105, loss: 0.607015
global_step: 36164, epoch: 105, loss: 0.604287
global_step: 36165, epoch: 105, loss: 0.470299
global_step: 36166, epoch: 105, loss: 0.624192
global_step: 36167, epoch: 105, loss: 0.490811
global_step: 36168, epoch: 105, loss: 0.523244
global_step: 36169, epoch: 105, loss: 0.522289
global_step: 36170, epoch: 105, loss: 0.543033
global_step: 36171, epoch: 105, loss: 0.531613
global_step: 36172, epoch: 105, loss: 0.388867
global_step: 36173, epoch: 105, loss: 0.481416
global_step: 36174, epoch: 105, loss: 0.426240
global_step: 36175, epoch: 105, loss: 0.532406
global_step: 36176, epoch: 105, loss: 0.545494
global_step: 36177, epoch: 105, loss: 0.583431
global_step: 36178, epoch: 105, loss: 0.562011
global_step: 36179, epoch: 105, loss: 0.400473
global_step: 36180, epoch: 105, loss: 0.485525
global_step: 36181, epoch: 105, loss: 0.516719
global_step: 36182, epoch: 105, loss: 0.458193
global_step: 36183, epoch: 105, loss: 0.522836
global_step: 36184, epoch: 105, loss: 0.466796
global_step: 36185, epoch: 105, loss: 0.473846
global_step: 36186, epoch: 105, loss: 0.547443
global_step: 36187, epoch: 105, loss: 0.476291
global_step: 36188, epoch: 105, loss: 0.417063
global_step: 36189, epoch: 105, loss: 0.475997
global_step: 36190, epoch: 105, loss: 0.487428
global_step: 36191, epoch: 105, loss: 0.511644
global_step: 36192, epoch: 105, loss: 0.485051
global_step: 36193, epoch: 105, loss: 0.565907
global_step: 36194, epoch: 105, loss: 0.644494
global_step: 36195, epoch: 105, loss: 0.454457
global_step: 36196, epoch: 105, loss: 0.540381
global_step: 36197, epoch: 105, loss: 0.462221
global_step: 36198, epoch: 105, loss: 0.565520
global_step: 36199, epoch: 105, loss: 0.550256
global_step: 36200, epoch: 105, loss: 0.666864
epoch: 105
train	acc: 0.8848	macro: p 0.8932, r 0.7149, f1: 0.7580	micro: p 0.8848, r 0.8848, f1 0.8848	weighted_f1:0.8756
dev	acc: 0.5573	macro: p 0.5446, r 0.3328, f1: 0.3462	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5120
test	acc: 0.5958	macro: p 0.3884, r 0.3179, f1: 0.3273	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5494
global_step: 36201, epoch: 106, loss: 0.533163
global_step: 36202, epoch: 106, loss: 0.486126
global_step: 36203, epoch: 106, loss: 0.495900
global_step: 36204, epoch: 106, loss: 0.571560
global_step: 36205, epoch: 106, loss: 0.475171
global_step: 36206, epoch: 106, loss: 0.508376
global_step: 36207, epoch: 106, loss: 0.510563
global_step: 36208, epoch: 106, loss: 0.526966
global_step: 36209, epoch: 106, loss: 0.486466
global_step: 36210, epoch: 106, loss: 0.503048
global_step: 36211, epoch: 106, loss: 0.508822
global_step: 36212, epoch: 106, loss: 0.611361
global_step: 36213, epoch: 106, loss: 0.505154
global_step: 36214, epoch: 106, loss: 0.605891
global_step: 36215, epoch: 106, loss: 0.439185
global_step: 36216, epoch: 106, loss: 0.459228
global_step: 36217, epoch: 106, loss: 0.538700
global_step: 36218, epoch: 106, loss: 0.441099
global_step: 36219, epoch: 106, loss: 0.578591
global_step: 36220, epoch: 106, loss: 0.528162
global_step: 36221, epoch: 106, loss: 0.531461
global_step: 36222, epoch: 106, loss: 0.496989
global_step: 36223, epoch: 106, loss: 0.581670
global_step: 36224, epoch: 106, loss: 0.516107
global_step: 36225, epoch: 106, loss: 0.547165
global_step: 36226, epoch: 106, loss: 0.585904
global_step: 36227, epoch: 106, loss: 0.494745
global_step: 36228, epoch: 106, loss: 0.510513
global_step: 36229, epoch: 106, loss: 0.426118
global_step: 36230, epoch: 106, loss: 0.522055
global_step: 36231, epoch: 106, loss: 0.426029
global_step: 36232, epoch: 106, loss: 0.484021
global_step: 36233, epoch: 106, loss: 0.524031
global_step: 36234, epoch: 106, loss: 0.540502
global_step: 36235, epoch: 106, loss: 0.586608
global_step: 36236, epoch: 106, loss: 0.622079
global_step: 36237, epoch: 106, loss: 0.557306
global_step: 36238, epoch: 106, loss: 0.570898
global_step: 36239, epoch: 106, loss: 0.477092
global_step: 36240, epoch: 106, loss: 0.230951
epoch: 106
train	acc: 0.8966	macro: p 0.8805, r 0.7278, f1: 0.7542	micro: p 0.8966, r 0.8966, f1 0.8966	weighted_f1:0.8875
dev	acc: 0.5618	macro: p 0.5145, r 0.3487, f1: 0.3510	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5283
test	acc: 0.6000	macro: p 0.3776, r 0.3408, f1: 0.3382	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5667
global_step: 36241, epoch: 107, loss: 0.448792
global_step: 36242, epoch: 107, loss: 0.512890
global_step: 36243, epoch: 107, loss: 0.545759
global_step: 36244, epoch: 107, loss: 0.569449
global_step: 36245, epoch: 107, loss: 0.396423
global_step: 36246, epoch: 107, loss: 0.456493
global_step: 36247, epoch: 107, loss: 0.569335
global_step: 36248, epoch: 107, loss: 0.443617
global_step: 36249, epoch: 107, loss: 0.552937
global_step: 36250, epoch: 107, loss: 0.436297
global_step: 36251, epoch: 107, loss: 0.517096
global_step: 36252, epoch: 107, loss: 0.479155
global_step: 36253, epoch: 107, loss: 0.544664
global_step: 36254, epoch: 107, loss: 0.472151
global_step: 36255, epoch: 107, loss: 0.514773
global_step: 36256, epoch: 107, loss: 0.642938
global_step: 36257, epoch: 107, loss: 0.473380
global_step: 36258, epoch: 107, loss: 0.529577
global_step: 36259, epoch: 107, loss: 0.388633
global_step: 36260, epoch: 107, loss: 0.573312
global_step: 36261, epoch: 107, loss: 0.569367
global_step: 36262, epoch: 107, loss: 0.594642
global_step: 36263, epoch: 107, loss: 0.569842
global_step: 36264, epoch: 107, loss: 0.515474
global_step: 36265, epoch: 107, loss: 0.450171
global_step: 36266, epoch: 107, loss: 0.477375
global_step: 36267, epoch: 107, loss: 0.524718
global_step: 36268, epoch: 107, loss: 0.490328
global_step: 36269, epoch: 107, loss: 0.433488
global_step: 36270, epoch: 107, loss: 0.484231
global_step: 36271, epoch: 107, loss: 0.459257
global_step: 36272, epoch: 107, loss: 0.509965
global_step: 36273, epoch: 107, loss: 0.564581
global_step: 36274, epoch: 107, loss: 0.486109
global_step: 36275, epoch: 107, loss: 0.511122
global_step: 36276, epoch: 107, loss: 0.412966
global_step: 36277, epoch: 107, loss: 0.383231
global_step: 36278, epoch: 107, loss: 0.612631
global_step: 36279, epoch: 107, loss: 0.479096
global_step: 36280, epoch: 107, loss: 0.266219
epoch: 107
train	acc: 0.8866	macro: p 0.8824, r 0.7016, f1: 0.7340	micro: p 0.8866, r 0.8866, f1 0.8866	weighted_f1:0.8760
dev	acc: 0.5708	macro: p 0.5396, r 0.3422, f1: 0.3508	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5304
test	acc: 0.6054	macro: p 0.3995, r 0.3337, f1: 0.3412	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5676
global_step: 36281, epoch: 108, loss: 0.558938
global_step: 36282, epoch: 108, loss: 0.487108
global_step: 36283, epoch: 108, loss: 0.473990
global_step: 36284, epoch: 108, loss: 0.530519
global_step: 36285, epoch: 108, loss: 0.502426
global_step: 36286, epoch: 108, loss: 0.515263
global_step: 36287, epoch: 108, loss: 0.527322
global_step: 36288, epoch: 108, loss: 0.570339
global_step: 36289, epoch: 108, loss: 0.448378
global_step: 36290, epoch: 108, loss: 0.464916
global_step: 36291, epoch: 108, loss: 0.495878
global_step: 36292, epoch: 108, loss: 0.496697
global_step: 36293, epoch: 108, loss: 0.531754
global_step: 36294, epoch: 108, loss: 0.504580
global_step: 36295, epoch: 108, loss: 0.465002
global_step: 36296, epoch: 108, loss: 0.494797
global_step: 36297, epoch: 108, loss: 0.533661
global_step: 36298, epoch: 108, loss: 0.582330
global_step: 36299, epoch: 108, loss: 0.510521
global_step: 36300, epoch: 108, loss: 0.534728
global_step: 36301, epoch: 108, loss: 0.555584
global_step: 36302, epoch: 108, loss: 0.503555
global_step: 36303, epoch: 108, loss: 0.502317
global_step: 36304, epoch: 108, loss: 0.488139
global_step: 36305, epoch: 108, loss: 0.524403
global_step: 36306, epoch: 108, loss: 0.452136
global_step: 36307, epoch: 108, loss: 0.488849
global_step: 36308, epoch: 108, loss: 0.466044
global_step: 36309, epoch: 108, loss: 0.452221
global_step: 36310, epoch: 108, loss: 0.552708
global_step: 36311, epoch: 108, loss: 0.413449
global_step: 36312, epoch: 108, loss: 0.469808
global_step: 36313, epoch: 108, loss: 0.513946
global_step: 36314, epoch: 108, loss: 0.481912
global_step: 36315, epoch: 108, loss: 0.538584
global_step: 36316, epoch: 108, loss: 0.460710
global_step: 36317, epoch: 108, loss: 0.466740
global_step: 36318, epoch: 108, loss: 0.483907
global_step: 36319, epoch: 108, loss: 0.420128
global_step: 36320, epoch: 108, loss: 0.765509
epoch: 108
train	acc: 0.8979	macro: p 0.8779, r 0.7316, f1: 0.7545	micro: p 0.8979, r 0.8979, f1 0.8979	weighted_f1:0.8888
dev	acc: 0.5573	macro: p 0.5220, r 0.3475, f1: 0.3502	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5258
test	acc: 0.5897	macro: p 0.3765, r 0.3348, f1: 0.3347	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5563
global_step: 36321, epoch: 109, loss: 0.462737
global_step: 36322, epoch: 109, loss: 0.439562
global_step: 36323, epoch: 109, loss: 0.536737
global_step: 36324, epoch: 109, loss: 0.574371
global_step: 36325, epoch: 109, loss: 0.401171
global_step: 36326, epoch: 109, loss: 0.468930
global_step: 36327, epoch: 109, loss: 0.459242
global_step: 36328, epoch: 109, loss: 0.419519
global_step: 36329, epoch: 109, loss: 0.420345
global_step: 36330, epoch: 109, loss: 0.534207
global_step: 36331, epoch: 109, loss: 0.465497
global_step: 36332, epoch: 109, loss: 0.457465
global_step: 36333, epoch: 109, loss: 0.616624
global_step: 36334, epoch: 109, loss: 0.459131
global_step: 36335, epoch: 109, loss: 0.461735
global_step: 36336, epoch: 109, loss: 0.490137
global_step: 36337, epoch: 109, loss: 0.477762
global_step: 36338, epoch: 109, loss: 0.434063
global_step: 36339, epoch: 109, loss: 0.527766
global_step: 36340, epoch: 109, loss: 0.431115
global_step: 36341, epoch: 109, loss: 0.407169
global_step: 36342, epoch: 109, loss: 0.488036
global_step: 36343, epoch: 109, loss: 0.523799
global_step: 36344, epoch: 109, loss: 0.516142
global_step: 36345, epoch: 109, loss: 0.445631
global_step: 36346, epoch: 109, loss: 0.563504
global_step: 36347, epoch: 109, loss: 0.434950
global_step: 36348, epoch: 109, loss: 0.524887
global_step: 36349, epoch: 109, loss: 0.499401
global_step: 36350, epoch: 109, loss: 0.539309
global_step: 36351, epoch: 109, loss: 0.511437
global_step: 36352, epoch: 109, loss: 0.533194
global_step: 36353, epoch: 109, loss: 0.498064
global_step: 36354, epoch: 109, loss: 0.495963
global_step: 36355, epoch: 109, loss: 0.563756
global_step: 36356, epoch: 109, loss: 0.551166
global_step: 36357, epoch: 109, loss: 0.501260
global_step: 36358, epoch: 109, loss: 0.533027
global_step: 36359, epoch: 109, loss: 0.446717
global_step: 36360, epoch: 109, loss: 0.611880
epoch: 109
train	acc: 0.8958	macro: p 0.8767, r 0.7284, f1: 0.7549	micro: p 0.8958, r 0.8958, f1 0.8958	weighted_f1:0.8875
dev	acc: 0.5663	macro: p 0.4534, r 0.3405, f1: 0.3527	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5280
test	acc: 0.6004	macro: p 0.4189, r 0.3371, f1: 0.3534	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5661
global_step: 36361, epoch: 110, loss: 0.494431
global_step: 36362, epoch: 110, loss: 0.587485
global_step: 36363, epoch: 110, loss: 0.441321
global_step: 36364, epoch: 110, loss: 0.538685
global_step: 36365, epoch: 110, loss: 0.473876
global_step: 36366, epoch: 110, loss: 0.391562
global_step: 36367, epoch: 110, loss: 0.455120
global_step: 36368, epoch: 110, loss: 0.554790
global_step: 36369, epoch: 110, loss: 0.504256
global_step: 36370, epoch: 110, loss: 0.516547
global_step: 36371, epoch: 110, loss: 0.474334
global_step: 36372, epoch: 110, loss: 0.429104
global_step: 36373, epoch: 110, loss: 0.539545
global_step: 36374, epoch: 110, loss: 0.474919
global_step: 36375, epoch: 110, loss: 0.432876
global_step: 36376, epoch: 110, loss: 0.596828
global_step: 36377, epoch: 110, loss: 0.501219
global_step: 36378, epoch: 110, loss: 0.443689
global_step: 36379, epoch: 110, loss: 0.488079
global_step: 36380, epoch: 110, loss: 0.526869
global_step: 36381, epoch: 110, loss: 0.371584
global_step: 36382, epoch: 110, loss: 0.501878
global_step: 36383, epoch: 110, loss: 0.503183
global_step: 36384, epoch: 110, loss: 0.482008
global_step: 36385, epoch: 110, loss: 0.501402
global_step: 36386, epoch: 110, loss: 0.499269
global_step: 36387, epoch: 110, loss: 0.529615
global_step: 36388, epoch: 110, loss: 0.486620
global_step: 36389, epoch: 110, loss: 0.487050
global_step: 36390, epoch: 110, loss: 0.475539
global_step: 36391, epoch: 110, loss: 0.528393
global_step: 36392, epoch: 110, loss: 0.487596
global_step: 36393, epoch: 110, loss: 0.438084
global_step: 36394, epoch: 110, loss: 0.441264
global_step: 36395, epoch: 110, loss: 0.458141
global_step: 36396, epoch: 110, loss: 0.542991
global_step: 36397, epoch: 110, loss: 0.439832
global_step: 36398, epoch: 110, loss: 0.469898
global_step: 36399, epoch: 110, loss: 0.559042
global_step: 36400, epoch: 110, loss: 0.742097
epoch: 110
train	acc: 0.8990	macro: p 0.8805, r 0.7350, f1: 0.7590	micro: p 0.8990, r 0.8990, f1 0.8990	weighted_f1:0.8902
dev	acc: 0.5654	macro: p 0.4870, r 0.3538, f1: 0.3653	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5321
test	acc: 0.5954	macro: p 0.3935, r 0.3375, f1: 0.3411	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5637
global_step: 36401, epoch: 111, loss: 0.508362
global_step: 36402, epoch: 111, loss: 0.430646
global_step: 36403, epoch: 111, loss: 0.492376
global_step: 36404, epoch: 111, loss: 0.470443
global_step: 36405, epoch: 111, loss: 0.417484
global_step: 36406, epoch: 111, loss: 0.466669
global_step: 36407, epoch: 111, loss: 0.448142
global_step: 36408, epoch: 111, loss: 0.536998
global_step: 36409, epoch: 111, loss: 0.422783
global_step: 36410, epoch: 111, loss: 0.463166
global_step: 36411, epoch: 111, loss: 0.496266
global_step: 36412, epoch: 111, loss: 0.573858
global_step: 36413, epoch: 111, loss: 0.516292
global_step: 36414, epoch: 111, loss: 0.460166
global_step: 36415, epoch: 111, loss: 0.457281
global_step: 36416, epoch: 111, loss: 0.529330
global_step: 36417, epoch: 111, loss: 0.408008
global_step: 36418, epoch: 111, loss: 0.450488
global_step: 36419, epoch: 111, loss: 0.448735
global_step: 36420, epoch: 111, loss: 0.504166
global_step: 36421, epoch: 111, loss: 0.520716
global_step: 36422, epoch: 111, loss: 0.634813
global_step: 36423, epoch: 111, loss: 0.429721
global_step: 36424, epoch: 111, loss: 0.525034
global_step: 36425, epoch: 111, loss: 0.467474
global_step: 36426, epoch: 111, loss: 0.455619
global_step: 36427, epoch: 111, loss: 0.455006
global_step: 36428, epoch: 111, loss: 0.452443
global_step: 36429, epoch: 111, loss: 0.478066
global_step: 36430, epoch: 111, loss: 0.440674
global_step: 36431, epoch: 111, loss: 0.503374
global_step: 36432, epoch: 111, loss: 0.458220
global_step: 36433, epoch: 111, loss: 0.490027
global_step: 36434, epoch: 111, loss: 0.576814
global_step: 36435, epoch: 111, loss: 0.518396
global_step: 36436, epoch: 111, loss: 0.514599
global_step: 36437, epoch: 111, loss: 0.477295
global_step: 36438, epoch: 111, loss: 0.462404
global_step: 36439, epoch: 111, loss: 0.454551
global_step: 36440, epoch: 111, loss: 0.652707
epoch: 111
train	acc: 0.8997	macro: p 0.8894, r 0.7566, f1: 0.7968	micro: p 0.8997, r 0.8997, f1 0.8997	weighted_f1:0.8935
dev	acc: 0.5645	macro: p 0.5393, r 0.3381, f1: 0.3472	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5189
test	acc: 0.5996	macro: p 0.3843, r 0.3286, f1: 0.3359	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5571
global_step: 36441, epoch: 112, loss: 0.430150
global_step: 36442, epoch: 112, loss: 0.502351
global_step: 36443, epoch: 112, loss: 0.536057
global_step: 36444, epoch: 112, loss: 0.536803
global_step: 36445, epoch: 112, loss: 0.522123
global_step: 36446, epoch: 112, loss: 0.481669
global_step: 36447, epoch: 112, loss: 0.423095
global_step: 36448, epoch: 112, loss: 0.500734
global_step: 36449, epoch: 112, loss: 0.507526
global_step: 36450, epoch: 112, loss: 0.512575
global_step: 36451, epoch: 112, loss: 0.387395
global_step: 36452, epoch: 112, loss: 0.436489
global_step: 36453, epoch: 112, loss: 0.472571
global_step: 36454, epoch: 112, loss: 0.416769
global_step: 36455, epoch: 112, loss: 0.482638
global_step: 36456, epoch: 112, loss: 0.383363
global_step: 36457, epoch: 112, loss: 0.490516
global_step: 36458, epoch: 112, loss: 0.454465
global_step: 36459, epoch: 112, loss: 0.444029
global_step: 36460, epoch: 112, loss: 0.494391
global_step: 36461, epoch: 112, loss: 0.509163
global_step: 36462, epoch: 112, loss: 0.481838
global_step: 36463, epoch: 112, loss: 0.550164
global_step: 36464, epoch: 112, loss: 0.490939
global_step: 36465, epoch: 112, loss: 0.492973
global_step: 36466, epoch: 112, loss: 0.495616
global_step: 36467, epoch: 112, loss: 0.518188
global_step: 36468, epoch: 112, loss: 0.414024
global_step: 36469, epoch: 112, loss: 0.446928
global_step: 36470, epoch: 112, loss: 0.465903
global_step: 36471, epoch: 112, loss: 0.509263
global_step: 36472, epoch: 112, loss: 0.473359
global_step: 36473, epoch: 112, loss: 0.442656
global_step: 36474, epoch: 112, loss: 0.568096
global_step: 36475, epoch: 112, loss: 0.428521
global_step: 36476, epoch: 112, loss: 0.376446
global_step: 36477, epoch: 112, loss: 0.452373
global_step: 36478, epoch: 112, loss: 0.476634
global_step: 36479, epoch: 112, loss: 0.585295
global_step: 36480, epoch: 112, loss: 1.122943
epoch: 112
train	acc: 0.9069	macro: p 0.8830, r 0.7525, f1: 0.7724	micro: p 0.9069, r 0.9069, f1 0.9069	weighted_f1:0.8994
dev	acc: 0.5537	macro: p 0.5241, r 0.3569, f1: 0.3636	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5307
test	acc: 0.5900	macro: p 0.3983, r 0.3552, f1: 0.3614	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5695
global_step: 36481, epoch: 113, loss: 0.474729
global_step: 36482, epoch: 113, loss: 0.505133
global_step: 36483, epoch: 113, loss: 0.465383
global_step: 36484, epoch: 113, loss: 0.499815
global_step: 36485, epoch: 113, loss: 0.477487
global_step: 36486, epoch: 113, loss: 0.584331
global_step: 36487, epoch: 113, loss: 0.436337
global_step: 36488, epoch: 113, loss: 0.428019
global_step: 36489, epoch: 113, loss: 0.398214
global_step: 36490, epoch: 113, loss: 0.579802
global_step: 36491, epoch: 113, loss: 0.449679
global_step: 36492, epoch: 113, loss: 0.546627
global_step: 36493, epoch: 113, loss: 0.482283
global_step: 36494, epoch: 113, loss: 0.498579
global_step: 36495, epoch: 113, loss: 0.418883
global_step: 36496, epoch: 113, loss: 0.488121
global_step: 36497, epoch: 113, loss: 0.462825
global_step: 36498, epoch: 113, loss: 0.490703
global_step: 36499, epoch: 113, loss: 0.419310
global_step: 36500, epoch: 113, loss: 0.578978
global_step: 36501, epoch: 113, loss: 0.520074
global_step: 36502, epoch: 113, loss: 0.480730
global_step: 36503, epoch: 113, loss: 0.488438
global_step: 36504, epoch: 113, loss: 0.429638
global_step: 36505, epoch: 113, loss: 0.478604
global_step: 36506, epoch: 113, loss: 0.434348
global_step: 36507, epoch: 113, loss: 0.481105
global_step: 36508, epoch: 113, loss: 0.470882
global_step: 36509, epoch: 113, loss: 0.547155
global_step: 36510, epoch: 113, loss: 0.542307
global_step: 36511, epoch: 113, loss: 0.488544
global_step: 36512, epoch: 113, loss: 0.433519
global_step: 36513, epoch: 113, loss: 0.492634
global_step: 36514, epoch: 113, loss: 0.430120
global_step: 36515, epoch: 113, loss: 0.511741
global_step: 36516, epoch: 113, loss: 0.554824
global_step: 36517, epoch: 113, loss: 0.408896
global_step: 36518, epoch: 113, loss: 0.398680
global_step: 36519, epoch: 113, loss: 0.438678
global_step: 36520, epoch: 113, loss: 0.368731
epoch: 113
train	acc: 0.9075	macro: p 0.8912, r 0.7637, f1: 0.7946	micro: p 0.9075, r 0.9075, f1 0.9075	weighted_f1:0.9014
dev	acc: 0.5600	macro: p 0.4546, r 0.3526, f1: 0.3586	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5279
test	acc: 0.5989	macro: p 0.3849, r 0.3432, f1: 0.3448	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5652
global_step: 36521, epoch: 114, loss: 0.408353
global_step: 36522, epoch: 114, loss: 0.506464
global_step: 36523, epoch: 114, loss: 0.530887
global_step: 36524, epoch: 114, loss: 0.481441
global_step: 36525, epoch: 114, loss: 0.417886
global_step: 36526, epoch: 114, loss: 0.371659
global_step: 36527, epoch: 114, loss: 0.309334
global_step: 36528, epoch: 114, loss: 0.399374
global_step: 36529, epoch: 114, loss: 0.518549
global_step: 36530, epoch: 114, loss: 0.460398
global_step: 36531, epoch: 114, loss: 0.475018
global_step: 36532, epoch: 114, loss: 0.484000
global_step: 36533, epoch: 114, loss: 0.457908
global_step: 36534, epoch: 114, loss: 0.433103
global_step: 36535, epoch: 114, loss: 0.502555
global_step: 36536, epoch: 114, loss: 0.417197
global_step: 36537, epoch: 114, loss: 0.462304
global_step: 36538, epoch: 114, loss: 0.483037
global_step: 36539, epoch: 114, loss: 0.489619
global_step: 36540, epoch: 114, loss: 0.490731
global_step: 36541, epoch: 114, loss: 0.566425
global_step: 36542, epoch: 114, loss: 0.418761
global_step: 36543, epoch: 114, loss: 0.440542
global_step: 36544, epoch: 114, loss: 0.407122
global_step: 36545, epoch: 114, loss: 0.422994
global_step: 36546, epoch: 114, loss: 0.636346
global_step: 36547, epoch: 114, loss: 0.487031
global_step: 36548, epoch: 114, loss: 0.435140
global_step: 36549, epoch: 114, loss: 0.467476
global_step: 36550, epoch: 114, loss: 0.520231
global_step: 36551, epoch: 114, loss: 0.599416
global_step: 36552, epoch: 114, loss: 0.502861
global_step: 36553, epoch: 114, loss: 0.560731
global_step: 36554, epoch: 114, loss: 0.523801
global_step: 36555, epoch: 114, loss: 0.425631
global_step: 36556, epoch: 114, loss: 0.385587
global_step: 36557, epoch: 114, loss: 0.407458
global_step: 36558, epoch: 114, loss: 0.581503
global_step: 36559, epoch: 114, loss: 0.476761
global_step: 36560, epoch: 114, loss: 0.187450
epoch: 114
train	acc: 0.9068	macro: p 0.8886, r 0.7640, f1: 0.7989	micro: p 0.9068, r 0.9068, f1 0.9068	weighted_f1:0.9012
dev	acc: 0.5681	macro: p 0.5555, r 0.3546, f1: 0.3648	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5311
test	acc: 0.6027	macro: p 0.3849, r 0.3369, f1: 0.3414	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5677
global_step: 36561, epoch: 115, loss: 0.558165
global_step: 36562, epoch: 115, loss: 0.418634
global_step: 36563, epoch: 115, loss: 0.428688
global_step: 36564, epoch: 115, loss: 0.453228
global_step: 36565, epoch: 115, loss: 0.432315
global_step: 36566, epoch: 115, loss: 0.535284
global_step: 36567, epoch: 115, loss: 0.489454
global_step: 36568, epoch: 115, loss: 0.457284
global_step: 36569, epoch: 115, loss: 0.509852
global_step: 36570, epoch: 115, loss: 0.488202
global_step: 36571, epoch: 115, loss: 0.476342
global_step: 36572, epoch: 115, loss: 0.455651
global_step: 36573, epoch: 115, loss: 0.421347
global_step: 36574, epoch: 115, loss: 0.472951
global_step: 36575, epoch: 115, loss: 0.558907
global_step: 36576, epoch: 115, loss: 0.499061
global_step: 36577, epoch: 115, loss: 0.454714
global_step: 36578, epoch: 115, loss: 0.478217
global_step: 36579, epoch: 115, loss: 0.397661
global_step: 36580, epoch: 115, loss: 0.433639
global_step: 36581, epoch: 115, loss: 0.435790
global_step: 36582, epoch: 115, loss: 0.518191
global_step: 36583, epoch: 115, loss: 0.465089
global_step: 36584, epoch: 115, loss: 0.408267
global_step: 36585, epoch: 115, loss: 0.404235
global_step: 36586, epoch: 115, loss: 0.398182
global_step: 36587, epoch: 115, loss: 0.505092
global_step: 36588, epoch: 115, loss: 0.578610
global_step: 36589, epoch: 115, loss: 0.437710
global_step: 36590, epoch: 115, loss: 0.551986
global_step: 36591, epoch: 115, loss: 0.524093
global_step: 36592, epoch: 115, loss: 0.444893
global_step: 36593, epoch: 115, loss: 0.503798
global_step: 36594, epoch: 115, loss: 0.460064
global_step: 36595, epoch: 115, loss: 0.385092
global_step: 36596, epoch: 115, loss: 0.418424
global_step: 36597, epoch: 115, loss: 0.356260
global_step: 36598, epoch: 115, loss: 0.427264
global_step: 36599, epoch: 115, loss: 0.355223
global_step: 36600, epoch: 115, loss: 0.063772
epoch: 115
train	acc: 0.9067	macro: p 0.8930, r 0.7573, f1: 0.7919	micro: p 0.9067, r 0.9067, f1 0.9067	weighted_f1:0.9003
dev	acc: 0.5645	macro: p 0.5387, r 0.3515, f1: 0.3615	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5298
test	acc: 0.5981	macro: p 0.3779, r 0.3312, f1: 0.3358	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5621
global_step: 36601, epoch: 116, loss: 0.451289
global_step: 36602, epoch: 116, loss: 0.468005
global_step: 36603, epoch: 116, loss: 0.432034
global_step: 36604, epoch: 116, loss: 0.599106
global_step: 36605, epoch: 116, loss: 0.412326
global_step: 36606, epoch: 116, loss: 0.435316
global_step: 36607, epoch: 116, loss: 0.445606
global_step: 36608, epoch: 116, loss: 0.480399
global_step: 36609, epoch: 116, loss: 0.314906
global_step: 36610, epoch: 116, loss: 0.485638
global_step: 36611, epoch: 116, loss: 0.450072
global_step: 36612, epoch: 116, loss: 0.526644
global_step: 36613, epoch: 116, loss: 0.458076
global_step: 36614, epoch: 116, loss: 0.546330
global_step: 36615, epoch: 116, loss: 0.423170
global_step: 36616, epoch: 116, loss: 0.482378
global_step: 36617, epoch: 116, loss: 0.591673
global_step: 36618, epoch: 116, loss: 0.479180
global_step: 36619, epoch: 116, loss: 0.501856
global_step: 36620, epoch: 116, loss: 0.509854
global_step: 36621, epoch: 116, loss: 0.454300
global_step: 36622, epoch: 116, loss: 0.441299
global_step: 36623, epoch: 116, loss: 0.442536
global_step: 36624, epoch: 116, loss: 0.496822
global_step: 36625, epoch: 116, loss: 0.506673
global_step: 36626, epoch: 116, loss: 0.384165
global_step: 36627, epoch: 116, loss: 0.438088
global_step: 36628, epoch: 116, loss: 0.426567
global_step: 36629, epoch: 116, loss: 0.377461
global_step: 36630, epoch: 116, loss: 0.448387
global_step: 36631, epoch: 116, loss: 0.413529
global_step: 36632, epoch: 116, loss: 0.534297
global_step: 36633, epoch: 116, loss: 0.365252
global_step: 36634, epoch: 116, loss: 0.499300
global_step: 36635, epoch: 116, loss: 0.521130
global_step: 36636, epoch: 116, loss: 0.531415
global_step: 36637, epoch: 116, loss: 0.528394
global_step: 36638, epoch: 116, loss: 0.578858
global_step: 36639, epoch: 116, loss: 0.443133
global_step: 36640, epoch: 116, loss: 0.140182
epoch: 116
train	acc: 0.9137	macro: p 0.8937, r 0.7799, f1: 0.8059	micro: p 0.9137, r 0.9137, f1 0.9137	weighted_f1:0.9083
dev	acc: 0.5500	macro: p 0.4379, r 0.3499, f1: 0.3517	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5207
test	acc: 0.5881	macro: p 0.3746, r 0.3457, f1: 0.3461	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5614
global_step: 36641, epoch: 117, loss: 0.404296
global_step: 36642, epoch: 117, loss: 0.438174
global_step: 36643, epoch: 117, loss: 0.541410
global_step: 36644, epoch: 117, loss: 0.458373
global_step: 36645, epoch: 117, loss: 0.430305
global_step: 36646, epoch: 117, loss: 0.495510
global_step: 36647, epoch: 117, loss: 0.428672
global_step: 36648, epoch: 117, loss: 0.396958
global_step: 36649, epoch: 117, loss: 0.527008
global_step: 36650, epoch: 117, loss: 0.549007
global_step: 36651, epoch: 117, loss: 0.506059
global_step: 36652, epoch: 117, loss: 0.438022
global_step: 36653, epoch: 117, loss: 0.426143
global_step: 36654, epoch: 117, loss: 0.391098
global_step: 36655, epoch: 117, loss: 0.488425
global_step: 36656, epoch: 117, loss: 0.453298
global_step: 36657, epoch: 117, loss: 0.528819
global_step: 36658, epoch: 117, loss: 0.387013
global_step: 36659, epoch: 117, loss: 0.453813
global_step: 36660, epoch: 117, loss: 0.436924
global_step: 36661, epoch: 117, loss: 0.408301
global_step: 36662, epoch: 117, loss: 0.459649
global_step: 36663, epoch: 117, loss: 0.510114
global_step: 36664, epoch: 117, loss: 0.449275
global_step: 36665, epoch: 117, loss: 0.593569
global_step: 36666, epoch: 117, loss: 0.453022
global_step: 36667, epoch: 117, loss: 0.488014
global_step: 36668, epoch: 117, loss: 0.475875
global_step: 36669, epoch: 117, loss: 0.450225
global_step: 36670, epoch: 117, loss: 0.440673
global_step: 36671, epoch: 117, loss: 0.356186
global_step: 36672, epoch: 117, loss: 0.412938
global_step: 36673, epoch: 117, loss: 0.499078
global_step: 36674, epoch: 117, loss: 0.398817
global_step: 36675, epoch: 117, loss: 0.514829
global_step: 36676, epoch: 117, loss: 0.490004
global_step: 36677, epoch: 117, loss: 0.432919
global_step: 36678, epoch: 117, loss: 0.483684
global_step: 36679, epoch: 117, loss: 0.480040
global_step: 36680, epoch: 117, loss: 0.608944
epoch: 117
train	acc: 0.9223	macro: p 0.8898, r 0.8065, f1: 0.8313	micro: p 0.9223, r 0.9223, f1 0.9223	weighted_f1:0.9185
dev	acc: 0.5591	macro: p 0.4439, r 0.3575, f1: 0.3604	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5283
test	acc: 0.5969	macro: p 0.3874, r 0.3550, f1: 0.3604	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5701
global_step: 36681, epoch: 118, loss: 0.479810
global_step: 36682, epoch: 118, loss: 0.507872
global_step: 36683, epoch: 118, loss: 0.439285
global_step: 36684, epoch: 118, loss: 0.448080
global_step: 36685, epoch: 118, loss: 0.470815
global_step: 36686, epoch: 118, loss: 0.455854
global_step: 36687, epoch: 118, loss: 0.442739
global_step: 36688, epoch: 118, loss: 0.475307
global_step: 36689, epoch: 118, loss: 0.426458
global_step: 36690, epoch: 118, loss: 0.503580
global_step: 36691, epoch: 118, loss: 0.456373
global_step: 36692, epoch: 118, loss: 0.491880
global_step: 36693, epoch: 118, loss: 0.351269
global_step: 36694, epoch: 118, loss: 0.414537
global_step: 36695, epoch: 118, loss: 0.431723
global_step: 36696, epoch: 118, loss: 0.523064
global_step: 36697, epoch: 118, loss: 0.399553
global_step: 36698, epoch: 118, loss: 0.410508
global_step: 36699, epoch: 118, loss: 0.493308
global_step: 36700, epoch: 118, loss: 0.447490
global_step: 36701, epoch: 118, loss: 0.462906
global_step: 36702, epoch: 118, loss: 0.489215
global_step: 36703, epoch: 118, loss: 0.386720
global_step: 36704, epoch: 118, loss: 0.465920
global_step: 36705, epoch: 118, loss: 0.438066
global_step: 36706, epoch: 118, loss: 0.508928
global_step: 36707, epoch: 118, loss: 0.438819
global_step: 36708, epoch: 118, loss: 0.492799
global_step: 36709, epoch: 118, loss: 0.516450
global_step: 36710, epoch: 118, loss: 0.505427
global_step: 36711, epoch: 118, loss: 0.428853
global_step: 36712, epoch: 118, loss: 0.492611
global_step: 36713, epoch: 118, loss: 0.480441
global_step: 36714, epoch: 118, loss: 0.496056
global_step: 36715, epoch: 118, loss: 0.405617
global_step: 36716, epoch: 118, loss: 0.500181
global_step: 36717, epoch: 118, loss: 0.440635
global_step: 36718, epoch: 118, loss: 0.426587
global_step: 36719, epoch: 118, loss: 0.404197
global_step: 36720, epoch: 118, loss: 0.608600
epoch: 118
train	acc: 0.9092	macro: p 0.8885, r 0.7707, f1: 0.7942	micro: p 0.9092, r 0.9092, f1 0.9092	weighted_f1:0.9031
dev	acc: 0.5491	macro: p 0.4608, r 0.3516, f1: 0.3530	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5193
test	acc: 0.5716	macro: p 0.3693, r 0.3331, f1: 0.3325	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5440
global_step: 36721, epoch: 119, loss: 0.489633
global_step: 36722, epoch: 119, loss: 0.397433
global_step: 36723, epoch: 119, loss: 0.394008
global_step: 36724, epoch: 119, loss: 0.441483
global_step: 36725, epoch: 119, loss: 0.491822
global_step: 36726, epoch: 119, loss: 0.566444
global_step: 36727, epoch: 119, loss: 0.376984
global_step: 36728, epoch: 119, loss: 0.425131
global_step: 36729, epoch: 119, loss: 0.505078
global_step: 36730, epoch: 119, loss: 0.425677
global_step: 36731, epoch: 119, loss: 0.484525
global_step: 36732, epoch: 119, loss: 0.392924
global_step: 36733, epoch: 119, loss: 0.450481
global_step: 36734, epoch: 119, loss: 0.455543
global_step: 36735, epoch: 119, loss: 0.386651
global_step: 36736, epoch: 119, loss: 0.426688
global_step: 36737, epoch: 119, loss: 0.524821
global_step: 36738, epoch: 119, loss: 0.438958
global_step: 36739, epoch: 119, loss: 0.428860
global_step: 36740, epoch: 119, loss: 0.470454
global_step: 36741, epoch: 119, loss: 0.482923
global_step: 36742, epoch: 119, loss: 0.478897
global_step: 36743, epoch: 119, loss: 0.435856
global_step: 36744, epoch: 119, loss: 0.545644
global_step: 36745, epoch: 119, loss: 0.460674
global_step: 36746, epoch: 119, loss: 0.400813
global_step: 36747, epoch: 119, loss: 0.439079
global_step: 36748, epoch: 119, loss: 0.488730
global_step: 36749, epoch: 119, loss: 0.445757
global_step: 36750, epoch: 119, loss: 0.403685
global_step: 36751, epoch: 119, loss: 0.468031
global_step: 36752, epoch: 119, loss: 0.435753
global_step: 36753, epoch: 119, loss: 0.393785
global_step: 36754, epoch: 119, loss: 0.463227
global_step: 36755, epoch: 119, loss: 0.442699
global_step: 36756, epoch: 119, loss: 0.477531
global_step: 36757, epoch: 119, loss: 0.414654
global_step: 36758, epoch: 119, loss: 0.434303
global_step: 36759, epoch: 119, loss: 0.430932
global_step: 36760, epoch: 119, loss: 0.795270
epoch: 119
train	acc: 0.9176	macro: p 0.8942, r 0.7851, f1: 0.8071	micro: p 0.9176, r 0.9176, f1 0.9176	weighted_f1:0.9120
dev	acc: 0.5464	macro: p 0.4171, r 0.3531, f1: 0.3557	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5236
test	acc: 0.5866	macro: p 0.3774, r 0.3551, f1: 0.3554	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5678
global_step: 36761, epoch: 120, loss: 0.483324
global_step: 36762, epoch: 120, loss: 0.467377
global_step: 36763, epoch: 120, loss: 0.462188
global_step: 36764, epoch: 120, loss: 0.421577
global_step: 36765, epoch: 120, loss: 0.504966
global_step: 36766, epoch: 120, loss: 0.417836
global_step: 36767, epoch: 120, loss: 0.445654
global_step: 36768, epoch: 120, loss: 0.453193
global_step: 36769, epoch: 120, loss: 0.465367
global_step: 36770, epoch: 120, loss: 0.483570
global_step: 36771, epoch: 120, loss: 0.452699
global_step: 36772, epoch: 120, loss: 0.482007
global_step: 36773, epoch: 120, loss: 0.434935
global_step: 36774, epoch: 120, loss: 0.448374
global_step: 36775, epoch: 120, loss: 0.464009
global_step: 36776, epoch: 120, loss: 0.436440
global_step: 36777, epoch: 120, loss: 0.464231
global_step: 36778, epoch: 120, loss: 0.406602
global_step: 36779, epoch: 120, loss: 0.420949
global_step: 36780, epoch: 120, loss: 0.435620
global_step: 36781, epoch: 120, loss: 0.401825
global_step: 36782, epoch: 120, loss: 0.428895
global_step: 36783, epoch: 120, loss: 0.448600
global_step: 36784, epoch: 120, loss: 0.395687
global_step: 36785, epoch: 120, loss: 0.511433
global_step: 36786, epoch: 120, loss: 0.386241
global_step: 36787, epoch: 120, loss: 0.444165
global_step: 36788, epoch: 120, loss: 0.499322
global_step: 36789, epoch: 120, loss: 0.417410
global_step: 36790, epoch: 120, loss: 0.490513
global_step: 36791, epoch: 120, loss: 0.406986
global_step: 36792, epoch: 120, loss: 0.445575
global_step: 36793, epoch: 120, loss: 0.448403
global_step: 36794, epoch: 120, loss: 0.434146
global_step: 36795, epoch: 120, loss: 0.526755
global_step: 36796, epoch: 120, loss: 0.401761
global_step: 36797, epoch: 120, loss: 0.434014
global_step: 36798, epoch: 120, loss: 0.458595
global_step: 36799, epoch: 120, loss: 0.431495
global_step: 36800, epoch: 120, loss: 0.268386
epoch: 120
train	acc: 0.9233	macro: p 0.8961, r 0.8193, f1: 0.8438	micro: p 0.9233, r 0.9233, f1 0.9233	weighted_f1:0.9203
dev	acc: 0.5591	macro: p 0.4475, r 0.3533, f1: 0.3602	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5293
test	acc: 0.5920	macro: p 0.3799, r 0.3506, f1: 0.3576	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5674
global_step: 36801, epoch: 121, loss: 0.545883
global_step: 36802, epoch: 121, loss: 0.432646
global_step: 36803, epoch: 121, loss: 0.443474
global_step: 36804, epoch: 121, loss: 0.456008
global_step: 36805, epoch: 121, loss: 0.388387
global_step: 36806, epoch: 121, loss: 0.383681
global_step: 36807, epoch: 121, loss: 0.483111
global_step: 36808, epoch: 121, loss: 0.488551
global_step: 36809, epoch: 121, loss: 0.464170
global_step: 36810, epoch: 121, loss: 0.433393
global_step: 36811, epoch: 121, loss: 0.416867
global_step: 36812, epoch: 121, loss: 0.408586
global_step: 36813, epoch: 121, loss: 0.485286
global_step: 36814, epoch: 121, loss: 0.424838
global_step: 36815, epoch: 121, loss: 0.409852
global_step: 36816, epoch: 121, loss: 0.463312
global_step: 36817, epoch: 121, loss: 0.375366
global_step: 36818, epoch: 121, loss: 0.401781
global_step: 36819, epoch: 121, loss: 0.440668
global_step: 36820, epoch: 121, loss: 0.427599
global_step: 36821, epoch: 121, loss: 0.507363
global_step: 36822, epoch: 121, loss: 0.458382
global_step: 36823, epoch: 121, loss: 0.460692
global_step: 36824, epoch: 121, loss: 0.448812
global_step: 36825, epoch: 121, loss: 0.470750
global_step: 36826, epoch: 121, loss: 0.448127
global_step: 36827, epoch: 121, loss: 0.461629
global_step: 36828, epoch: 121, loss: 0.418618
global_step: 36829, epoch: 121, loss: 0.457217
global_step: 36830, epoch: 121, loss: 0.449642
global_step: 36831, epoch: 121, loss: 0.371272
global_step: 36832, epoch: 121, loss: 0.412921
global_step: 36833, epoch: 121, loss: 0.385918
global_step: 36834, epoch: 121, loss: 0.467526
global_step: 36835, epoch: 121, loss: 0.471707
global_step: 36836, epoch: 121, loss: 0.461126
global_step: 36837, epoch: 121, loss: 0.404657
global_step: 36838, epoch: 121, loss: 0.402220
global_step: 36839, epoch: 121, loss: 0.478902
global_step: 36840, epoch: 121, loss: 0.447589
epoch: 121
train	acc: 0.9186	macro: p 0.8982, r 0.7929, f1: 0.8186	micro: p 0.9186, r 0.9186, f1 0.9186	weighted_f1:0.9144
dev	acc: 0.5537	macro: p 0.4327, r 0.3621, f1: 0.3681	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5311
test	acc: 0.5893	macro: p 0.3733, r 0.3567, f1: 0.3576	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5725
global_step: 36841, epoch: 122, loss: 0.471634
global_step: 36842, epoch: 122, loss: 0.451687
global_step: 36843, epoch: 122, loss: 0.444912
global_step: 36844, epoch: 122, loss: 0.364838
global_step: 36845, epoch: 122, loss: 0.402089
global_step: 36846, epoch: 122, loss: 0.404829
global_step: 36847, epoch: 122, loss: 0.454842
global_step: 36848, epoch: 122, loss: 0.418203
global_step: 36849, epoch: 122, loss: 0.387598
global_step: 36850, epoch: 122, loss: 0.410473
global_step: 36851, epoch: 122, loss: 0.372506
global_step: 36852, epoch: 122, loss: 0.501915
global_step: 36853, epoch: 122, loss: 0.383572
global_step: 36854, epoch: 122, loss: 0.406329
global_step: 36855, epoch: 122, loss: 0.491245
global_step: 36856, epoch: 122, loss: 0.445333
global_step: 36857, epoch: 122, loss: 0.356095
global_step: 36858, epoch: 122, loss: 0.535699
global_step: 36859, epoch: 122, loss: 0.493605
global_step: 36860, epoch: 122, loss: 0.366312
global_step: 36861, epoch: 122, loss: 0.442483
global_step: 36862, epoch: 122, loss: 0.438603
global_step: 36863, epoch: 122, loss: 0.446609
global_step: 36864, epoch: 122, loss: 0.450948
global_step: 36865, epoch: 122, loss: 0.440107
global_step: 36866, epoch: 122, loss: 0.499784
global_step: 36867, epoch: 122, loss: 0.387255
global_step: 36868, epoch: 122, loss: 0.456056
global_step: 36869, epoch: 122, loss: 0.472039
global_step: 36870, epoch: 122, loss: 0.423049
global_step: 36871, epoch: 122, loss: 0.482796
global_step: 36872, epoch: 122, loss: 0.464926
global_step: 36873, epoch: 122, loss: 0.415947
global_step: 36874, epoch: 122, loss: 0.447112
global_step: 36875, epoch: 122, loss: 0.497912
global_step: 36876, epoch: 122, loss: 0.405285
global_step: 36877, epoch: 122, loss: 0.441545
global_step: 36878, epoch: 122, loss: 0.486210
global_step: 36879, epoch: 122, loss: 0.379730
global_step: 36880, epoch: 122, loss: 0.338010
epoch: 122
train	acc: 0.9217	macro: p 0.9076, r 0.8132, f1: 0.8496	micro: p 0.9217, r 0.9217, f1 0.9217	weighted_f1:0.9188
dev	acc: 0.5609	macro: p 0.4524, r 0.3358, f1: 0.3434	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5169
test	acc: 0.6019	macro: p 0.3979, r 0.3375, f1: 0.3493	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5640
global_step: 36881, epoch: 123, loss: 0.478754
global_step: 36882, epoch: 123, loss: 0.503344
global_step: 36883, epoch: 123, loss: 0.509441
global_step: 36884, epoch: 123, loss: 0.428271
global_step: 36885, epoch: 123, loss: 0.428530
global_step: 36886, epoch: 123, loss: 0.464478
global_step: 36887, epoch: 123, loss: 0.411130
global_step: 36888, epoch: 123, loss: 0.385703
global_step: 36889, epoch: 123, loss: 0.472127
global_step: 36890, epoch: 123, loss: 0.429790
global_step: 36891, epoch: 123, loss: 0.392376
global_step: 36892, epoch: 123, loss: 0.411735
global_step: 36893, epoch: 123, loss: 0.410740
global_step: 36894, epoch: 123, loss: 0.471069
global_step: 36895, epoch: 123, loss: 0.343986
global_step: 36896, epoch: 123, loss: 0.377604
global_step: 36897, epoch: 123, loss: 0.410413
global_step: 36898, epoch: 123, loss: 0.401507
global_step: 36899, epoch: 123, loss: 0.467973
global_step: 36900, epoch: 123, loss: 0.416708
global_step: 36901, epoch: 123, loss: 0.449261
global_step: 36902, epoch: 123, loss: 0.379481
global_step: 36903, epoch: 123, loss: 0.400300
global_step: 36904, epoch: 123, loss: 0.416199
global_step: 36905, epoch: 123, loss: 0.434191
global_step: 36906, epoch: 123, loss: 0.418173
global_step: 36907, epoch: 123, loss: 0.447449
global_step: 36908, epoch: 123, loss: 0.435466
global_step: 36909, epoch: 123, loss: 0.456309
global_step: 36910, epoch: 123, loss: 0.454397
global_step: 36911, epoch: 123, loss: 0.495050
global_step: 36912, epoch: 123, loss: 0.389782
global_step: 36913, epoch: 123, loss: 0.420921
global_step: 36914, epoch: 123, loss: 0.429956
global_step: 36915, epoch: 123, loss: 0.420071
global_step: 36916, epoch: 123, loss: 0.552491
global_step: 36917, epoch: 123, loss: 0.407466
global_step: 36918, epoch: 123, loss: 0.386158
global_step: 36919, epoch: 123, loss: 0.406639
global_step: 36920, epoch: 123, loss: 0.868023
epoch: 123
train	acc: 0.9183	macro: p 0.9063, r 0.7981, f1: 0.8333	micro: p 0.9183, r 0.9183, f1 0.9183	weighted_f1:0.9146
dev	acc: 0.5473	macro: p 0.4490, r 0.3407, f1: 0.3433	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5084
test	acc: 0.5897	macro: p 0.3743, r 0.3312, f1: 0.3303	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5517
global_step: 36921, epoch: 124, loss: 0.475837
global_step: 36922, epoch: 124, loss: 0.345672
global_step: 36923, epoch: 124, loss: 0.455680
global_step: 36924, epoch: 124, loss: 0.479090
global_step: 36925, epoch: 124, loss: 0.354916
global_step: 36926, epoch: 124, loss: 0.362212
global_step: 36927, epoch: 124, loss: 0.435476
global_step: 36928, epoch: 124, loss: 0.386181
global_step: 36929, epoch: 124, loss: 0.428297
global_step: 36930, epoch: 124, loss: 0.422717
global_step: 36931, epoch: 124, loss: 0.344672
global_step: 36932, epoch: 124, loss: 0.429702
global_step: 36933, epoch: 124, loss: 0.432035
global_step: 36934, epoch: 124, loss: 0.423961
global_step: 36935, epoch: 124, loss: 0.399270
global_step: 36936, epoch: 124, loss: 0.489805
global_step: 36937, epoch: 124, loss: 0.425290
global_step: 36938, epoch: 124, loss: 0.361569
global_step: 36939, epoch: 124, loss: 0.400034
global_step: 36940, epoch: 124, loss: 0.406719
global_step: 36941, epoch: 124, loss: 0.554585
global_step: 36942, epoch: 124, loss: 0.399128
global_step: 36943, epoch: 124, loss: 0.362531
global_step: 36944, epoch: 124, loss: 0.440188
global_step: 36945, epoch: 124, loss: 0.457803
global_step: 36946, epoch: 124, loss: 0.449299
global_step: 36947, epoch: 124, loss: 0.472937
global_step: 36948, epoch: 124, loss: 0.407857
global_step: 36949, epoch: 124, loss: 0.398603
global_step: 36950, epoch: 124, loss: 0.361720
global_step: 36951, epoch: 124, loss: 0.397747
global_step: 36952, epoch: 124, loss: 0.469123
global_step: 36953, epoch: 124, loss: 0.411762
global_step: 36954, epoch: 124, loss: 0.446190
global_step: 36955, epoch: 124, loss: 0.296577
global_step: 36956, epoch: 124, loss: 0.500200
global_step: 36957, epoch: 124, loss: 0.419763
global_step: 36958, epoch: 124, loss: 0.455074
global_step: 36959, epoch: 124, loss: 0.407642
global_step: 36960, epoch: 124, loss: 0.861874
epoch: 124
train	acc: 0.9157	macro: p 0.9103, r 0.7822, f1: 0.8198	micro: p 0.9157, r 0.9157, f1 0.9157	weighted_f1:0.9107
dev	acc: 0.5564	macro: p 0.5457, r 0.3386, f1: 0.3504	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5154
test	acc: 0.5981	macro: p 0.3906, r 0.3292, f1: 0.3377	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5584
global_step: 36961, epoch: 125, loss: 0.385344
global_step: 36962, epoch: 125, loss: 0.369113
global_step: 36963, epoch: 125, loss: 0.428087
global_step: 36964, epoch: 125, loss: 0.386330
global_step: 36965, epoch: 125, loss: 0.433052
global_step: 36966, epoch: 125, loss: 0.440171
global_step: 36967, epoch: 125, loss: 0.391678
global_step: 36968, epoch: 125, loss: 0.403647
global_step: 36969, epoch: 125, loss: 0.357649
global_step: 36970, epoch: 125, loss: 0.420675
global_step: 36971, epoch: 125, loss: 0.393672
global_step: 36972, epoch: 125, loss: 0.405950
global_step: 36973, epoch: 125, loss: 0.394062
global_step: 36974, epoch: 125, loss: 0.404183
global_step: 36975, epoch: 125, loss: 0.406565
global_step: 36976, epoch: 125, loss: 0.408896
global_step: 36977, epoch: 125, loss: 0.474083
global_step: 36978, epoch: 125, loss: 0.509843
global_step: 36979, epoch: 125, loss: 0.440360
global_step: 36980, epoch: 125, loss: 0.351668
global_step: 36981, epoch: 125, loss: 0.327840
global_step: 36982, epoch: 125, loss: 0.339527
global_step: 36983, epoch: 125, loss: 0.405924
global_step: 36984, epoch: 125, loss: 0.427413
global_step: 36985, epoch: 125, loss: 0.385265
global_step: 36986, epoch: 125, loss: 0.432847
global_step: 36987, epoch: 125, loss: 0.334881
global_step: 36988, epoch: 125, loss: 0.424683
global_step: 36989, epoch: 125, loss: 0.469837
global_step: 36990, epoch: 125, loss: 0.420692
global_step: 36991, epoch: 125, loss: 0.373074
global_step: 36992, epoch: 125, loss: 0.423793
global_step: 36993, epoch: 125, loss: 0.466155
global_step: 36994, epoch: 125, loss: 0.361611
global_step: 36995, epoch: 125, loss: 0.474415
global_step: 36996, epoch: 125, loss: 0.391686
global_step: 36997, epoch: 125, loss: 0.474515
global_step: 36998, epoch: 125, loss: 0.473699
global_step: 36999, epoch: 125, loss: 0.371700
global_step: 37000, epoch: 125, loss: 0.911983
epoch: 125
train	acc: 0.9150	macro: p 0.9145, r 0.7854, f1: 0.8256	micro: p 0.9150, r 0.9150, f1 0.9150	weighted_f1:0.9104
dev	acc: 0.5645	macro: p 0.4871, r 0.3410, f1: 0.3565	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5224
test	acc: 0.5981	macro: p 0.4070, r 0.3285, f1: 0.3427	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5568
global_step: 37001, epoch: 126, loss: 0.441299
global_step: 37002, epoch: 126, loss: 0.333421
global_step: 37003, epoch: 126, loss: 0.376088
global_step: 37004, epoch: 126, loss: 0.456126
global_step: 37005, epoch: 126, loss: 0.521664
global_step: 37006, epoch: 126, loss: 0.447684
global_step: 37007, epoch: 126, loss: 0.413386
global_step: 37008, epoch: 126, loss: 0.354353
global_step: 37009, epoch: 126, loss: 0.514772
global_step: 37010, epoch: 126, loss: 0.420097
global_step: 37011, epoch: 126, loss: 0.401147
global_step: 37012, epoch: 126, loss: 0.409942
global_step: 37013, epoch: 126, loss: 0.437382
global_step: 37014, epoch: 126, loss: 0.410365
global_step: 37015, epoch: 126, loss: 0.395688
global_step: 37016, epoch: 126, loss: 0.472610
global_step: 37017, epoch: 126, loss: 0.413834
global_step: 37018, epoch: 126, loss: 0.389077
global_step: 37019, epoch: 126, loss: 0.373936
global_step: 37020, epoch: 126, loss: 0.413462
global_step: 37021, epoch: 126, loss: 0.347838
global_step: 37022, epoch: 126, loss: 0.352096
global_step: 37023, epoch: 126, loss: 0.424784
global_step: 37024, epoch: 126, loss: 0.410775
global_step: 37025, epoch: 126, loss: 0.405072
global_step: 37026, epoch: 126, loss: 0.375051
global_step: 37027, epoch: 126, loss: 0.337581
global_step: 37028, epoch: 126, loss: 0.420660
global_step: 37029, epoch: 126, loss: 0.439305
global_step: 37030, epoch: 126, loss: 0.361747
global_step: 37031, epoch: 126, loss: 0.456711
global_step: 37032, epoch: 126, loss: 0.372903
global_step: 37033, epoch: 126, loss: 0.473571
global_step: 37034, epoch: 126, loss: 0.349751
global_step: 37035, epoch: 126, loss: 0.439892
global_step: 37036, epoch: 126, loss: 0.452023
global_step: 37037, epoch: 126, loss: 0.414745
global_step: 37038, epoch: 126, loss: 0.501393
global_step: 37039, epoch: 126, loss: 0.416316
global_step: 37040, epoch: 126, loss: 0.825238
epoch: 126
train	acc: 0.9292	macro: p 0.9097, r 0.8428, f1: 0.8701	micro: p 0.9292, r 0.9292, f1 0.9292	weighted_f1:0.9276
dev	acc: 0.5455	macro: p 0.4190, r 0.3411, f1: 0.3431	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5076
test	acc: 0.5927	macro: p 0.3834, r 0.3413, f1: 0.3413	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5585
global_step: 37041, epoch: 127, loss: 0.426436
global_step: 37042, epoch: 127, loss: 0.384526
global_step: 37043, epoch: 127, loss: 0.460310
global_step: 37044, epoch: 127, loss: 0.395162
global_step: 37045, epoch: 127, loss: 0.388801
global_step: 37046, epoch: 127, loss: 0.370103
global_step: 37047, epoch: 127, loss: 0.457758
global_step: 37048, epoch: 127, loss: 0.442915
global_step: 37049, epoch: 127, loss: 0.400472
global_step: 37050, epoch: 127, loss: 0.422057
global_step: 37051, epoch: 127, loss: 0.328135
global_step: 37052, epoch: 127, loss: 0.434690
global_step: 37053, epoch: 127, loss: 0.465160
global_step: 37054, epoch: 127, loss: 0.372682
global_step: 37055, epoch: 127, loss: 0.392585
global_step: 37056, epoch: 127, loss: 0.349721
global_step: 37057, epoch: 127, loss: 0.362861
global_step: 37058, epoch: 127, loss: 0.447255
global_step: 37059, epoch: 127, loss: 0.462722
global_step: 37060, epoch: 127, loss: 0.406058
global_step: 37061, epoch: 127, loss: 0.506223
global_step: 37062, epoch: 127, loss: 0.412481
global_step: 37063, epoch: 127, loss: 0.410771
global_step: 37064, epoch: 127, loss: 0.435492
global_step: 37065, epoch: 127, loss: 0.405201
global_step: 37066, epoch: 127, loss: 0.396019
global_step: 37067, epoch: 127, loss: 0.385638
global_step: 37068, epoch: 127, loss: 0.425231
global_step: 37069, epoch: 127, loss: 0.357271
global_step: 37070, epoch: 127, loss: 0.467671
global_step: 37071, epoch: 127, loss: 0.443673
global_step: 37072, epoch: 127, loss: 0.437306
global_step: 37073, epoch: 127, loss: 0.369982
global_step: 37074, epoch: 127, loss: 0.385250
global_step: 37075, epoch: 127, loss: 0.417435
global_step: 37076, epoch: 127, loss: 0.405776
global_step: 37077, epoch: 127, loss: 0.394689
global_step: 37078, epoch: 127, loss: 0.408411
global_step: 37079, epoch: 127, loss: 0.450096
global_step: 37080, epoch: 127, loss: 0.448046
epoch: 127
train	acc: 0.9211	macro: p 0.8949, r 0.8231, f1: 0.8396	micro: p 0.9211, r 0.9211, f1 0.9211	weighted_f1:0.9181
dev	acc: 0.5374	macro: p 0.4350, r 0.3663, f1: 0.3608	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5220
test	acc: 0.5548	macro: p 0.3616, r 0.3598, f1: 0.3507	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5468
global_step: 37081, epoch: 128, loss: 0.420039
global_step: 37082, epoch: 128, loss: 0.435844
global_step: 37083, epoch: 128, loss: 0.423486
global_step: 37084, epoch: 128, loss: 0.422692
global_step: 37085, epoch: 128, loss: 0.385766
global_step: 37086, epoch: 128, loss: 0.501376
global_step: 37087, epoch: 128, loss: 0.338448
global_step: 37088, epoch: 128, loss: 0.402012
global_step: 37089, epoch: 128, loss: 0.314688
global_step: 37090, epoch: 128, loss: 0.309555
global_step: 37091, epoch: 128, loss: 0.419898
global_step: 37092, epoch: 128, loss: 0.410926
global_step: 37093, epoch: 128, loss: 0.390972
global_step: 37094, epoch: 128, loss: 0.513150
global_step: 37095, epoch: 128, loss: 0.396724
global_step: 37096, epoch: 128, loss: 0.585583
global_step: 37097, epoch: 128, loss: 0.439687
global_step: 37098, epoch: 128, loss: 0.388720
global_step: 37099, epoch: 128, loss: 0.350101
global_step: 37100, epoch: 128, loss: 0.297056
global_step: 37101, epoch: 128, loss: 0.413367
global_step: 37102, epoch: 128, loss: 0.360248
global_step: 37103, epoch: 128, loss: 0.430727
global_step: 37104, epoch: 128, loss: 0.384625
global_step: 37105, epoch: 128, loss: 0.420173
global_step: 37106, epoch: 128, loss: 0.418994
global_step: 37107, epoch: 128, loss: 0.397879
global_step: 37108, epoch: 128, loss: 0.484672
global_step: 37109, epoch: 128, loss: 0.459435
global_step: 37110, epoch: 128, loss: 0.453658
global_step: 37111, epoch: 128, loss: 0.425383
global_step: 37112, epoch: 128, loss: 0.430557
global_step: 37113, epoch: 128, loss: 0.486854
global_step: 37114, epoch: 128, loss: 0.370302
global_step: 37115, epoch: 128, loss: 0.438515
global_step: 37116, epoch: 128, loss: 0.328526
global_step: 37117, epoch: 128, loss: 0.442477
global_step: 37118, epoch: 128, loss: 0.429001
global_step: 37119, epoch: 128, loss: 0.355323
global_step: 37120, epoch: 128, loss: 0.068120
epoch: 128
train	acc: 0.9262	macro: p 0.9153, r 0.8160, f1: 0.8506	micro: p 0.9262, r 0.9262, f1 0.9262	weighted_f1:0.9232
dev	acc: 0.5600	macro: p 0.4662, r 0.3454, f1: 0.3567	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5218
test	acc: 0.5981	macro: p 0.4197, r 0.3404, f1: 0.3548	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5622
global_step: 37121, epoch: 129, loss: 0.422489
global_step: 37122, epoch: 129, loss: 0.352058
global_step: 37123, epoch: 129, loss: 0.474134
global_step: 37124, epoch: 129, loss: 0.434941
global_step: 37125, epoch: 129, loss: 0.380299
global_step: 37126, epoch: 129, loss: 0.351445
global_step: 37127, epoch: 129, loss: 0.436296
global_step: 37128, epoch: 129, loss: 0.396706
global_step: 37129, epoch: 129, loss: 0.444700
global_step: 37130, epoch: 129, loss: 0.357473
global_step: 37131, epoch: 129, loss: 0.357476
global_step: 37132, epoch: 129, loss: 0.378845
global_step: 37133, epoch: 129, loss: 0.357667
global_step: 37134, epoch: 129, loss: 0.336416
global_step: 37135, epoch: 129, loss: 0.338663
global_step: 37136, epoch: 129, loss: 0.369162
global_step: 37137, epoch: 129, loss: 0.428859
global_step: 37138, epoch: 129, loss: 0.422112
global_step: 37139, epoch: 129, loss: 0.410937
global_step: 37140, epoch: 129, loss: 0.423565
global_step: 37141, epoch: 129, loss: 0.373669
global_step: 37142, epoch: 129, loss: 0.427454
global_step: 37143, epoch: 129, loss: 0.396322
global_step: 37144, epoch: 129, loss: 0.393519
global_step: 37145, epoch: 129, loss: 0.353021
global_step: 37146, epoch: 129, loss: 0.351647
global_step: 37147, epoch: 129, loss: 0.383535
global_step: 37148, epoch: 129, loss: 0.342248
global_step: 37149, epoch: 129, loss: 0.436115
global_step: 37150, epoch: 129, loss: 0.422944
global_step: 37151, epoch: 129, loss: 0.422225
global_step: 37152, epoch: 129, loss: 0.349446
global_step: 37153, epoch: 129, loss: 0.422818
global_step: 37154, epoch: 129, loss: 0.451246
global_step: 37155, epoch: 129, loss: 0.544871
global_step: 37156, epoch: 129, loss: 0.369774
global_step: 37157, epoch: 129, loss: 0.377396
global_step: 37158, epoch: 129, loss: 0.485188
global_step: 37159, epoch: 129, loss: 0.519762
global_step: 37160, epoch: 129, loss: 0.822588
epoch: 129
train	acc: 0.9325	macro: p 0.9152, r 0.8399, f1: 0.8665	micro: p 0.9325, r 0.9325, f1 0.9325	weighted_f1:0.9304
dev	acc: 0.5537	macro: p 0.4255, r 0.3582, f1: 0.3636	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5253
test	acc: 0.5885	macro: p 0.3771, r 0.3451, f1: 0.3504	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5614
global_step: 37161, epoch: 130, loss: 0.436241
global_step: 37162, epoch: 130, loss: 0.373780
global_step: 37163, epoch: 130, loss: 0.348497
global_step: 37164, epoch: 130, loss: 0.395286
global_step: 37165, epoch: 130, loss: 0.378177
global_step: 37166, epoch: 130, loss: 0.372732
global_step: 37167, epoch: 130, loss: 0.447941
global_step: 37168, epoch: 130, loss: 0.412242
global_step: 37169, epoch: 130, loss: 0.391214
global_step: 37170, epoch: 130, loss: 0.412704
global_step: 37171, epoch: 130, loss: 0.426037
global_step: 37172, epoch: 130, loss: 0.363000
global_step: 37173, epoch: 130, loss: 0.314085
global_step: 37174, epoch: 130, loss: 0.360776
global_step: 37175, epoch: 130, loss: 0.380363
global_step: 37176, epoch: 130, loss: 0.456670
global_step: 37177, epoch: 130, loss: 0.405528
global_step: 37178, epoch: 130, loss: 0.375938
global_step: 37179, epoch: 130, loss: 0.454797
global_step: 37180, epoch: 130, loss: 0.423556
global_step: 37181, epoch: 130, loss: 0.461286
global_step: 37182, epoch: 130, loss: 0.313070
global_step: 37183, epoch: 130, loss: 0.366805
global_step: 37184, epoch: 130, loss: 0.419762
global_step: 37185, epoch: 130, loss: 0.340143
global_step: 37186, epoch: 130, loss: 0.423915
global_step: 37187, epoch: 130, loss: 0.391128
global_step: 37188, epoch: 130, loss: 0.421582
global_step: 37189, epoch: 130, loss: 0.439046
global_step: 37190, epoch: 130, loss: 0.400678
global_step: 37191, epoch: 130, loss: 0.578824
global_step: 37192, epoch: 130, loss: 0.359330
global_step: 37193, epoch: 130, loss: 0.398311
global_step: 37194, epoch: 130, loss: 0.438442
global_step: 37195, epoch: 130, loss: 0.469805
global_step: 37196, epoch: 130, loss: 0.383464
global_step: 37197, epoch: 130, loss: 0.378725
global_step: 37198, epoch: 130, loss: 0.440730
global_step: 37199, epoch: 130, loss: 0.457062
global_step: 37200, epoch: 130, loss: 0.800623
epoch: 130
train	acc: 0.9305	macro: p 0.9113, r 0.8289, f1: 0.8549	micro: p 0.9305, r 0.9305, f1 0.9305	weighted_f1:0.9278
dev	acc: 0.5464	macro: p 0.4276, r 0.3566, f1: 0.3643	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5241
test	acc: 0.5866	macro: p 0.4058, r 0.3592, f1: 0.3679	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5688
global_step: 37201, epoch: 131, loss: 0.428152
global_step: 37202, epoch: 131, loss: 0.428899
global_step: 37203, epoch: 131, loss: 0.379745
global_step: 37204, epoch: 131, loss: 0.419755
global_step: 37205, epoch: 131, loss: 0.398259
global_step: 37206, epoch: 131, loss: 0.399405
global_step: 37207, epoch: 131, loss: 0.347534
global_step: 37208, epoch: 131, loss: 0.363831
global_step: 37209, epoch: 131, loss: 0.404655
global_step: 37210, epoch: 131, loss: 0.382782
global_step: 37211, epoch: 131, loss: 0.395517
global_step: 37212, epoch: 131, loss: 0.339950
global_step: 37213, epoch: 131, loss: 0.370108
global_step: 37214, epoch: 131, loss: 0.441476
global_step: 37215, epoch: 131, loss: 0.403447
global_step: 37216, epoch: 131, loss: 0.448633
global_step: 37217, epoch: 131, loss: 0.328536
global_step: 37218, epoch: 131, loss: 0.394669
global_step: 37219, epoch: 131, loss: 0.337243
global_step: 37220, epoch: 131, loss: 0.399657
global_step: 37221, epoch: 131, loss: 0.415795
global_step: 37222, epoch: 131, loss: 0.362885
global_step: 37223, epoch: 131, loss: 0.366923
global_step: 37224, epoch: 131, loss: 0.388540
global_step: 37225, epoch: 131, loss: 0.393122
global_step: 37226, epoch: 131, loss: 0.352176
global_step: 37227, epoch: 131, loss: 0.504011
global_step: 37228, epoch: 131, loss: 0.400784
global_step: 37229, epoch: 131, loss: 0.394737
global_step: 37230, epoch: 131, loss: 0.439461
global_step: 37231, epoch: 131, loss: 0.409594
global_step: 37232, epoch: 131, loss: 0.345942
global_step: 37233, epoch: 131, loss: 0.469065
global_step: 37234, epoch: 131, loss: 0.350043
global_step: 37235, epoch: 131, loss: 0.397701
global_step: 37236, epoch: 131, loss: 0.458844
global_step: 37237, epoch: 131, loss: 0.526240
global_step: 37238, epoch: 131, loss: 0.430536
global_step: 37239, epoch: 131, loss: 0.455796
global_step: 37240, epoch: 131, loss: 0.123328
epoch: 131
train	acc: 0.9182	macro: p 0.9192, r 0.8054, f1: 0.8487	micro: p 0.9182, r 0.9182, f1 0.9182	weighted_f1:0.9148
dev	acc: 0.5636	macro: p 0.4556, r 0.3307, f1: 0.3397	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5098
test	acc: 0.5992	macro: p 0.4172, r 0.3212, f1: 0.3343	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5511
global_step: 37241, epoch: 132, loss: 0.446751
global_step: 37242, epoch: 132, loss: 0.404625
global_step: 37243, epoch: 132, loss: 0.301455
global_step: 37244, epoch: 132, loss: 0.358540
global_step: 37245, epoch: 132, loss: 0.317257
global_step: 37246, epoch: 132, loss: 0.397454
global_step: 37247, epoch: 132, loss: 0.391188
global_step: 37248, epoch: 132, loss: 0.394316
global_step: 37249, epoch: 132, loss: 0.383859
global_step: 37250, epoch: 132, loss: 0.394183
global_step: 37251, epoch: 132, loss: 0.405734
global_step: 37252, epoch: 132, loss: 0.435584
global_step: 37253, epoch: 132, loss: 0.432099
global_step: 37254, epoch: 132, loss: 0.382991
global_step: 37255, epoch: 132, loss: 0.301476
global_step: 37256, epoch: 132, loss: 0.406413
global_step: 37257, epoch: 132, loss: 0.371717
global_step: 37258, epoch: 132, loss: 0.409007
global_step: 37259, epoch: 132, loss: 0.385958
global_step: 37260, epoch: 132, loss: 0.417237
global_step: 37261, epoch: 132, loss: 0.416872
global_step: 37262, epoch: 132, loss: 0.401348
global_step: 37263, epoch: 132, loss: 0.450964
global_step: 37264, epoch: 132, loss: 0.327107
global_step: 37265, epoch: 132, loss: 0.357992
global_step: 37266, epoch: 132, loss: 0.427851
global_step: 37267, epoch: 132, loss: 0.370678
global_step: 37268, epoch: 132, loss: 0.397190
global_step: 37269, epoch: 132, loss: 0.488989
global_step: 37270, epoch: 132, loss: 0.358640
global_step: 37271, epoch: 132, loss: 0.411103
global_step: 37272, epoch: 132, loss: 0.470754
global_step: 37273, epoch: 132, loss: 0.287500
global_step: 37274, epoch: 132, loss: 0.493351
global_step: 37275, epoch: 132, loss: 0.468254
global_step: 37276, epoch: 132, loss: 0.380549
global_step: 37277, epoch: 132, loss: 0.369029
global_step: 37278, epoch: 132, loss: 0.374551
global_step: 37279, epoch: 132, loss: 0.429992
global_step: 37280, epoch: 132, loss: 0.269230
epoch: 132
train	acc: 0.9330	macro: p 0.9201, r 0.8423, f1: 0.8716	micro: p 0.9330, r 0.9330, f1 0.9330	weighted_f1:0.9310
dev	acc: 0.5546	macro: p 0.4136, r 0.3412, f1: 0.3515	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5184
test	acc: 0.5989	macro: p 0.4111, r 0.3466, f1: 0.3605	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5666
global_step: 37281, epoch: 133, loss: 0.418875
global_step: 37282, epoch: 133, loss: 0.389812
global_step: 37283, epoch: 133, loss: 0.433957
global_step: 37284, epoch: 133, loss: 0.356178
global_step: 37285, epoch: 133, loss: 0.314566
global_step: 37286, epoch: 133, loss: 0.333358
global_step: 37287, epoch: 133, loss: 0.355440
global_step: 37288, epoch: 133, loss: 0.431291
global_step: 37289, epoch: 133, loss: 0.351347
global_step: 37290, epoch: 133, loss: 0.414048
global_step: 37291, epoch: 133, loss: 0.348978
global_step: 37292, epoch: 133, loss: 0.355741
global_step: 37293, epoch: 133, loss: 0.345691
global_step: 37294, epoch: 133, loss: 0.347898
global_step: 37295, epoch: 133, loss: 0.454434
global_step: 37296, epoch: 133, loss: 0.400267
global_step: 37297, epoch: 133, loss: 0.392982
global_step: 37298, epoch: 133, loss: 0.295901
global_step: 37299, epoch: 133, loss: 0.403515
global_step: 37300, epoch: 133, loss: 0.454341
global_step: 37301, epoch: 133, loss: 0.387632
global_step: 37302, epoch: 133, loss: 0.481731
global_step: 37303, epoch: 133, loss: 0.385301
global_step: 37304, epoch: 133, loss: 0.389744
global_step: 37305, epoch: 133, loss: 0.370106
global_step: 37306, epoch: 133, loss: 0.377054
global_step: 37307, epoch: 133, loss: 0.415248
global_step: 37308, epoch: 133, loss: 0.579921
global_step: 37309, epoch: 133, loss: 0.442775
global_step: 37310, epoch: 133, loss: 0.448917
global_step: 37311, epoch: 133, loss: 0.366264
global_step: 37312, epoch: 133, loss: 0.372688
global_step: 37313, epoch: 133, loss: 0.342994
global_step: 37314, epoch: 133, loss: 0.440858
global_step: 37315, epoch: 133, loss: 0.340037
global_step: 37316, epoch: 133, loss: 0.476957
global_step: 37317, epoch: 133, loss: 0.414824
global_step: 37318, epoch: 133, loss: 0.432334
global_step: 37319, epoch: 133, loss: 0.422517
global_step: 37320, epoch: 133, loss: 0.194599
epoch: 133
train	acc: 0.9339	macro: p 0.9190, r 0.8425, f1: 0.8663	micro: p 0.9339, r 0.9339, f1 0.9339	weighted_f1:0.9315
dev	acc: 0.5428	macro: p 0.3993, r 0.3443, f1: 0.3440	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5151
test	acc: 0.5774	macro: p 0.3820, r 0.3510, f1: 0.3521	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5556
global_step: 37321, epoch: 134, loss: 0.367338
global_step: 37322, epoch: 134, loss: 0.421350
global_step: 37323, epoch: 134, loss: 0.316674
global_step: 37324, epoch: 134, loss: 0.361863
global_step: 37325, epoch: 134, loss: 0.482955
global_step: 37326, epoch: 134, loss: 0.285457
global_step: 37327, epoch: 134, loss: 0.422149
global_step: 37328, epoch: 134, loss: 0.364042
global_step: 37329, epoch: 134, loss: 0.363928
global_step: 37330, epoch: 134, loss: 0.381239
global_step: 37331, epoch: 134, loss: 0.402457
global_step: 37332, epoch: 134, loss: 0.413758
global_step: 37333, epoch: 134, loss: 0.363932
global_step: 37334, epoch: 134, loss: 0.369826
global_step: 37335, epoch: 134, loss: 0.356503
global_step: 37336, epoch: 134, loss: 0.329619
global_step: 37337, epoch: 134, loss: 0.365943
global_step: 37338, epoch: 134, loss: 0.431952
global_step: 37339, epoch: 134, loss: 0.441369
global_step: 37340, epoch: 134, loss: 0.330423
global_step: 37341, epoch: 134, loss: 0.332365
global_step: 37342, epoch: 134, loss: 0.373319
global_step: 37343, epoch: 134, loss: 0.472861
global_step: 37344, epoch: 134, loss: 0.356076
global_step: 37345, epoch: 134, loss: 0.394942
global_step: 37346, epoch: 134, loss: 0.342610
global_step: 37347, epoch: 134, loss: 0.355040
global_step: 37348, epoch: 134, loss: 0.403577
global_step: 37349, epoch: 134, loss: 0.432931
global_step: 37350, epoch: 134, loss: 0.404756
global_step: 37351, epoch: 134, loss: 0.400829
global_step: 37352, epoch: 134, loss: 0.391100
global_step: 37353, epoch: 134, loss: 0.484845
global_step: 37354, epoch: 134, loss: 0.407339
global_step: 37355, epoch: 134, loss: 0.428392
global_step: 37356, epoch: 134, loss: 0.364190
global_step: 37357, epoch: 134, loss: 0.319403
global_step: 37358, epoch: 134, loss: 0.437790
global_step: 37359, epoch: 134, loss: 0.342079
global_step: 37360, epoch: 134, loss: 0.172591
epoch: 134
train	acc: 0.9345	macro: p 0.9205, r 0.8465, f1: 0.8748	micro: p 0.9345, r 0.9345, f1 0.9345	weighted_f1:0.9327
dev	acc: 0.5528	macro: p 0.4197, r 0.3478, f1: 0.3502	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5190
test	acc: 0.5874	macro: p 0.3854, r 0.3377, f1: 0.3409	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5549
global_step: 37361, epoch: 135, loss: 0.350251
global_step: 37362, epoch: 135, loss: 0.461665
global_step: 37363, epoch: 135, loss: 0.347378
global_step: 37364, epoch: 135, loss: 0.386086
global_step: 37365, epoch: 135, loss: 0.325418
global_step: 37366, epoch: 135, loss: 0.368399
global_step: 37367, epoch: 135, loss: 0.342629
global_step: 37368, epoch: 135, loss: 0.370341
global_step: 37369, epoch: 135, loss: 0.340965
global_step: 37370, epoch: 135, loss: 0.395561
global_step: 37371, epoch: 135, loss: 0.385318
global_step: 37372, epoch: 135, loss: 0.369294
global_step: 37373, epoch: 135, loss: 0.408643
global_step: 37374, epoch: 135, loss: 0.317988
global_step: 37375, epoch: 135, loss: 0.458370
global_step: 37376, epoch: 135, loss: 0.363663
global_step: 37377, epoch: 135, loss: 0.368409
global_step: 37378, epoch: 135, loss: 0.373309
global_step: 37379, epoch: 135, loss: 0.327837
global_step: 37380, epoch: 135, loss: 0.347592
global_step: 37381, epoch: 135, loss: 0.413905
global_step: 37382, epoch: 135, loss: 0.304269
global_step: 37383, epoch: 135, loss: 0.343752
global_step: 37384, epoch: 135, loss: 0.347062
global_step: 37385, epoch: 135, loss: 0.394048
global_step: 37386, epoch: 135, loss: 0.416266
global_step: 37387, epoch: 135, loss: 0.436777
global_step: 37388, epoch: 135, loss: 0.456350
global_step: 37389, epoch: 135, loss: 0.437511
global_step: 37390, epoch: 135, loss: 0.308849
global_step: 37391, epoch: 135, loss: 0.444500
global_step: 37392, epoch: 135, loss: 0.397105
global_step: 37393, epoch: 135, loss: 0.424666
global_step: 37394, epoch: 135, loss: 0.423902
global_step: 37395, epoch: 135, loss: 0.380180
global_step: 37396, epoch: 135, loss: 0.330853
global_step: 37397, epoch: 135, loss: 0.370035
global_step: 37398, epoch: 135, loss: 0.352709
global_step: 37399, epoch: 135, loss: 0.400805
global_step: 37400, epoch: 135, loss: 0.108797
epoch: 135
train	acc: 0.9305	macro: p 0.9242, r 0.8293, f1: 0.8654	micro: p 0.9305, r 0.9305, f1 0.9305	weighted_f1:0.9280
dev	acc: 0.5600	macro: p 0.5322, r 0.3341, f1: 0.3427	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5134
test	acc: 0.5996	macro: p 0.4106, r 0.3291, f1: 0.3400	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5579
global_step: 37401, epoch: 136, loss: 0.335849
global_step: 37402, epoch: 136, loss: 0.332884
global_step: 37403, epoch: 136, loss: 0.393545
global_step: 37404, epoch: 136, loss: 0.418152
global_step: 37405, epoch: 136, loss: 0.335577
global_step: 37406, epoch: 136, loss: 0.372651
global_step: 37407, epoch: 136, loss: 0.439869
global_step: 37408, epoch: 136, loss: 0.368255
global_step: 37409, epoch: 136, loss: 0.361590
global_step: 37410, epoch: 136, loss: 0.388019
global_step: 37411, epoch: 136, loss: 0.353072
global_step: 37412, epoch: 136, loss: 0.362177
global_step: 37413, epoch: 136, loss: 0.351031
global_step: 37414, epoch: 136, loss: 0.355581
global_step: 37415, epoch: 136, loss: 0.376619
global_step: 37416, epoch: 136, loss: 0.454740
global_step: 37417, epoch: 136, loss: 0.383663
global_step: 37418, epoch: 136, loss: 0.380678
global_step: 37419, epoch: 136, loss: 0.401267
global_step: 37420, epoch: 136, loss: 0.408760
global_step: 37421, epoch: 136, loss: 0.366914
global_step: 37422, epoch: 136, loss: 0.319504
global_step: 37423, epoch: 136, loss: 0.493829
global_step: 37424, epoch: 136, loss: 0.355251
global_step: 37425, epoch: 136, loss: 0.311480
global_step: 37426, epoch: 136, loss: 0.507740
global_step: 37427, epoch: 136, loss: 0.381214
global_step: 37428, epoch: 136, loss: 0.264505
global_step: 37429, epoch: 136, loss: 0.374627
global_step: 37430, epoch: 136, loss: 0.312490
global_step: 37431, epoch: 136, loss: 0.401887
global_step: 37432, epoch: 136, loss: 0.331109
global_step: 37433, epoch: 136, loss: 0.333676
global_step: 37434, epoch: 136, loss: 0.391423
global_step: 37435, epoch: 136, loss: 0.415945
global_step: 37436, epoch: 136, loss: 0.438792
global_step: 37437, epoch: 136, loss: 0.412178
global_step: 37438, epoch: 136, loss: 0.497789
global_step: 37439, epoch: 136, loss: 0.361967
global_step: 37440, epoch: 136, loss: 0.769533
epoch: 136
train	acc: 0.9345	macro: p 0.9256, r 0.8481, f1: 0.8787	micro: p 0.9345, r 0.9345, f1 0.9345	weighted_f1:0.9328
dev	acc: 0.5573	macro: p 0.4579, r 0.3433, f1: 0.3494	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5185
test	acc: 0.5946	macro: p 0.3991, r 0.3379, f1: 0.3449	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5608
global_step: 37441, epoch: 137, loss: 0.355585
global_step: 37442, epoch: 137, loss: 0.434333
global_step: 37443, epoch: 137, loss: 0.347217
global_step: 37444, epoch: 137, loss: 0.372764
global_step: 37445, epoch: 137, loss: 0.424820
global_step: 37446, epoch: 137, loss: 0.426030
global_step: 37447, epoch: 137, loss: 0.379615
global_step: 37448, epoch: 137, loss: 0.377444
global_step: 37449, epoch: 137, loss: 0.362517
global_step: 37450, epoch: 137, loss: 0.318704
global_step: 37451, epoch: 137, loss: 0.291203
global_step: 37452, epoch: 137, loss: 0.418880
global_step: 37453, epoch: 137, loss: 0.356466
global_step: 37454, epoch: 137, loss: 0.391478
global_step: 37455, epoch: 137, loss: 0.388686
global_step: 37456, epoch: 137, loss: 0.308725
global_step: 37457, epoch: 137, loss: 0.397411
global_step: 37458, epoch: 137, loss: 0.379038
global_step: 37459, epoch: 137, loss: 0.374621
global_step: 37460, epoch: 137, loss: 0.290570
global_step: 37461, epoch: 137, loss: 0.446224
global_step: 37462, epoch: 137, loss: 0.358192
global_step: 37463, epoch: 137, loss: 0.324561
global_step: 37464, epoch: 137, loss: 0.339538
global_step: 37465, epoch: 137, loss: 0.338214
global_step: 37466, epoch: 137, loss: 0.361741
global_step: 37467, epoch: 137, loss: 0.413198
global_step: 37468, epoch: 137, loss: 0.340695
global_step: 37469, epoch: 137, loss: 0.397631
global_step: 37470, epoch: 137, loss: 0.351270
global_step: 37471, epoch: 137, loss: 0.415614
global_step: 37472, epoch: 137, loss: 0.316732
global_step: 37473, epoch: 137, loss: 0.383751
global_step: 37474, epoch: 137, loss: 0.412507
global_step: 37475, epoch: 137, loss: 0.381324
global_step: 37476, epoch: 137, loss: 0.380581
global_step: 37477, epoch: 137, loss: 0.289739
global_step: 37478, epoch: 137, loss: 0.392131
global_step: 37479, epoch: 137, loss: 0.425174
global_step: 37480, epoch: 137, loss: 0.415337
epoch: 137
train	acc: 0.9354	macro: p 0.9264, r 0.8443, f1: 0.8753	micro: p 0.9354, r 0.9354, f1 0.9354	weighted_f1:0.9334
dev	acc: 0.5591	macro: p 0.5284, r 0.3475, f1: 0.3576	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5240
test	acc: 0.5958	macro: p 0.4021, r 0.3404, f1: 0.3526	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5645
global_step: 37481, epoch: 138, loss: 0.306724
global_step: 37482, epoch: 138, loss: 0.367118
global_step: 37483, epoch: 138, loss: 0.370422
global_step: 37484, epoch: 138, loss: 0.407306
global_step: 37485, epoch: 138, loss: 0.379113
global_step: 37486, epoch: 138, loss: 0.416055
global_step: 37487, epoch: 138, loss: 0.336452
global_step: 37488, epoch: 138, loss: 0.369895
global_step: 37489, epoch: 138, loss: 0.394615
global_step: 37490, epoch: 138, loss: 0.321391
global_step: 37491, epoch: 138, loss: 0.312726
global_step: 37492, epoch: 138, loss: 0.327470
global_step: 37493, epoch: 138, loss: 0.407175
global_step: 37494, epoch: 138, loss: 0.394591
global_step: 37495, epoch: 138, loss: 0.372369
global_step: 37496, epoch: 138, loss: 0.429606
global_step: 37497, epoch: 138, loss: 0.414002
global_step: 37498, epoch: 138, loss: 0.324414
global_step: 37499, epoch: 138, loss: 0.354917
global_step: 37500, epoch: 138, loss: 0.355425
global_step: 37501, epoch: 138, loss: 0.310386
global_step: 37502, epoch: 138, loss: 0.397059
global_step: 37503, epoch: 138, loss: 0.277677
global_step: 37504, epoch: 138, loss: 0.468081
global_step: 37505, epoch: 138, loss: 0.365851
global_step: 37506, epoch: 138, loss: 0.345452
global_step: 37507, epoch: 138, loss: 0.325930
global_step: 37508, epoch: 138, loss: 0.344063
global_step: 37509, epoch: 138, loss: 0.403712
global_step: 37510, epoch: 138, loss: 0.328465
global_step: 37511, epoch: 138, loss: 0.405338
global_step: 37512, epoch: 138, loss: 0.342215
global_step: 37513, epoch: 138, loss: 0.411720
global_step: 37514, epoch: 138, loss: 0.334698
global_step: 37515, epoch: 138, loss: 0.378119
global_step: 37516, epoch: 138, loss: 0.329431
global_step: 37517, epoch: 138, loss: 0.380409
global_step: 37518, epoch: 138, loss: 0.341241
global_step: 37519, epoch: 138, loss: 0.361156
global_step: 37520, epoch: 138, loss: 0.272515
epoch: 138
train	acc: 0.9357	macro: p 0.9331, r 0.8433, f1: 0.8766	micro: p 0.9357, r 0.9357, f1 0.9357	weighted_f1:0.9336
dev	acc: 0.5582	macro: p 0.5271, r 0.3425, f1: 0.3506	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5184
test	acc: 0.6008	macro: p 0.4083, r 0.3389, f1: 0.3494	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5644
global_step: 37521, epoch: 139, loss: 0.403261
global_step: 37522, epoch: 139, loss: 0.352216
global_step: 37523, epoch: 139, loss: 0.461928
global_step: 37524, epoch: 139, loss: 0.377878
global_step: 37525, epoch: 139, loss: 0.302099
global_step: 37526, epoch: 139, loss: 0.341882
global_step: 37527, epoch: 139, loss: 0.359296
global_step: 37528, epoch: 139, loss: 0.369340
global_step: 37529, epoch: 139, loss: 0.322791
global_step: 37530, epoch: 139, loss: 0.359090
global_step: 37531, epoch: 139, loss: 0.414999
global_step: 37532, epoch: 139, loss: 0.369966
global_step: 37533, epoch: 139, loss: 0.411154
global_step: 37534, epoch: 139, loss: 0.407794
global_step: 37535, epoch: 139, loss: 0.335199
global_step: 37536, epoch: 139, loss: 0.336332
global_step: 37537, epoch: 139, loss: 0.380591
global_step: 37538, epoch: 139, loss: 0.389745
global_step: 37539, epoch: 139, loss: 0.329693
global_step: 37540, epoch: 139, loss: 0.381382
global_step: 37541, epoch: 139, loss: 0.385141
global_step: 37542, epoch: 139, loss: 0.297496
global_step: 37543, epoch: 139, loss: 0.378626
global_step: 37544, epoch: 139, loss: 0.374963
global_step: 37545, epoch: 139, loss: 0.375379
global_step: 37546, epoch: 139, loss: 0.289141
global_step: 37547, epoch: 139, loss: 0.360523
global_step: 37548, epoch: 139, loss: 0.321989
global_step: 37549, epoch: 139, loss: 0.325094
global_step: 37550, epoch: 139, loss: 0.370158
global_step: 37551, epoch: 139, loss: 0.435031
global_step: 37552, epoch: 139, loss: 0.410234
global_step: 37553, epoch: 139, loss: 0.456717
global_step: 37554, epoch: 139, loss: 0.344710
global_step: 37555, epoch: 139, loss: 0.406866
global_step: 37556, epoch: 139, loss: 0.346856
global_step: 37557, epoch: 139, loss: 0.414186
global_step: 37558, epoch: 139, loss: 0.366708
global_step: 37559, epoch: 139, loss: 0.393344
global_step: 37560, epoch: 139, loss: 0.145202
epoch: 139
train	acc: 0.9376	macro: p 0.9277, r 0.8475, f1: 0.8756	micro: p 0.9376, r 0.9376, f1 0.9376	weighted_f1:0.9356
dev	acc: 0.5518	macro: p 0.4468, r 0.3501, f1: 0.3535	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5209
test	acc: 0.5908	macro: p 0.3903, r 0.3485, f1: 0.3531	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5652
global_step: 37561, epoch: 140, loss: 0.337831
global_step: 37562, epoch: 140, loss: 0.288666
global_step: 37563, epoch: 140, loss: 0.323933
global_step: 37564, epoch: 140, loss: 0.348138
global_step: 37565, epoch: 140, loss: 0.379557
global_step: 37566, epoch: 140, loss: 0.333718
global_step: 37567, epoch: 140, loss: 0.322753
global_step: 37568, epoch: 140, loss: 0.295006
global_step: 37569, epoch: 140, loss: 0.298321
global_step: 37570, epoch: 140, loss: 0.456135
global_step: 37571, epoch: 140, loss: 0.372828
global_step: 37572, epoch: 140, loss: 0.479039
global_step: 37573, epoch: 140, loss: 0.368117
global_step: 37574, epoch: 140, loss: 0.270609
global_step: 37575, epoch: 140, loss: 0.392339
global_step: 37576, epoch: 140, loss: 0.348242
global_step: 37577, epoch: 140, loss: 0.373010
global_step: 37578, epoch: 140, loss: 0.403457
global_step: 37579, epoch: 140, loss: 0.377892
global_step: 37580, epoch: 140, loss: 0.469493
global_step: 37581, epoch: 140, loss: 0.443656
global_step: 37582, epoch: 140, loss: 0.459249
global_step: 37583, epoch: 140, loss: 0.336207
global_step: 37584, epoch: 140, loss: 0.381870
global_step: 37585, epoch: 140, loss: 0.361407
global_step: 37586, epoch: 140, loss: 0.351036
global_step: 37587, epoch: 140, loss: 0.341469
global_step: 37588, epoch: 140, loss: 0.363840
global_step: 37589, epoch: 140, loss: 0.393500
global_step: 37590, epoch: 140, loss: 0.373162
global_step: 37591, epoch: 140, loss: 0.360834
global_step: 37592, epoch: 140, loss: 0.342286
global_step: 37593, epoch: 140, loss: 0.327150
global_step: 37594, epoch: 140, loss: 0.444223
global_step: 37595, epoch: 140, loss: 0.320310
global_step: 37596, epoch: 140, loss: 0.395891
global_step: 37597, epoch: 140, loss: 0.402990
global_step: 37598, epoch: 140, loss: 0.396934
global_step: 37599, epoch: 140, loss: 0.383669
global_step: 37600, epoch: 140, loss: 0.758102
epoch: 140
train	acc: 0.9398	macro: p 0.9286, r 0.8667, f1: 0.8912	micro: p 0.9398, r 0.9398, f1 0.9398	weighted_f1:0.9386
dev	acc: 0.5491	macro: p 0.4602, r 0.3607, f1: 0.3622	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5239
test	acc: 0.5674	macro: p 0.3721, r 0.3426, f1: 0.3424	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5467
global_step: 37601, epoch: 141, loss: 0.411795
global_step: 37602, epoch: 141, loss: 0.448335
global_step: 37603, epoch: 141, loss: 0.357646
global_step: 37604, epoch: 141, loss: 0.333051
global_step: 37605, epoch: 141, loss: 0.377247
global_step: 37606, epoch: 141, loss: 0.442471
global_step: 37607, epoch: 141, loss: 0.386851
global_step: 37608, epoch: 141, loss: 0.417873
global_step: 37609, epoch: 141, loss: 0.385621
global_step: 37610, epoch: 141, loss: 0.284611
global_step: 37611, epoch: 141, loss: 0.391161
global_step: 37612, epoch: 141, loss: 0.373113
global_step: 37613, epoch: 141, loss: 0.304809
global_step: 37614, epoch: 141, loss: 0.351835
global_step: 37615, epoch: 141, loss: 0.340860
global_step: 37616, epoch: 141, loss: 0.324143
global_step: 37617, epoch: 141, loss: 0.332187
global_step: 37618, epoch: 141, loss: 0.300221
global_step: 37619, epoch: 141, loss: 0.366040
global_step: 37620, epoch: 141, loss: 0.277333
global_step: 37621, epoch: 141, loss: 0.368049
global_step: 37622, epoch: 141, loss: 0.362600
global_step: 37623, epoch: 141, loss: 0.363894
global_step: 37624, epoch: 141, loss: 0.410305
global_step: 37625, epoch: 141, loss: 0.306787
global_step: 37626, epoch: 141, loss: 0.349716
global_step: 37627, epoch: 141, loss: 0.396017
global_step: 37628, epoch: 141, loss: 0.433381
global_step: 37629, epoch: 141, loss: 0.302144
global_step: 37630, epoch: 141, loss: 0.347683
global_step: 37631, epoch: 141, loss: 0.374049
global_step: 37632, epoch: 141, loss: 0.402532
global_step: 37633, epoch: 141, loss: 0.386408
global_step: 37634, epoch: 141, loss: 0.298271
global_step: 37635, epoch: 141, loss: 0.381273
global_step: 37636, epoch: 141, loss: 0.370955
global_step: 37637, epoch: 141, loss: 0.353981
global_step: 37638, epoch: 141, loss: 0.351034
global_step: 37639, epoch: 141, loss: 0.390712
global_step: 37640, epoch: 141, loss: 0.581426
epoch: 141
train	acc: 0.9430	macro: p 0.9323, r 0.8729, f1: 0.8975	micro: p 0.9430, r 0.9430, f1 0.9430	weighted_f1:0.9419
dev	acc: 0.5537	macro: p 0.4097, r 0.3521, f1: 0.3596	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5270
test	acc: 0.5904	macro: p 0.3873, r 0.3504, f1: 0.3586	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5666
global_step: 37641, epoch: 142, loss: 0.421849
global_step: 37642, epoch: 142, loss: 0.350705
global_step: 37643, epoch: 142, loss: 0.305295
global_step: 37644, epoch: 142, loss: 0.305268
global_step: 37645, epoch: 142, loss: 0.341164
global_step: 37646, epoch: 142, loss: 0.375963
global_step: 37647, epoch: 142, loss: 0.322762
global_step: 37648, epoch: 142, loss: 0.308091
global_step: 37649, epoch: 142, loss: 0.401429
global_step: 37650, epoch: 142, loss: 0.406563
global_step: 37651, epoch: 142, loss: 0.401834
global_step: 37652, epoch: 142, loss: 0.362921
global_step: 37653, epoch: 142, loss: 0.318706
global_step: 37654, epoch: 142, loss: 0.378145
global_step: 37655, epoch: 142, loss: 0.334031
global_step: 37656, epoch: 142, loss: 0.305545
global_step: 37657, epoch: 142, loss: 0.317889
global_step: 37658, epoch: 142, loss: 0.372461
global_step: 37659, epoch: 142, loss: 0.332514
global_step: 37660, epoch: 142, loss: 0.387899
global_step: 37661, epoch: 142, loss: 0.356615
global_step: 37662, epoch: 142, loss: 0.399266
global_step: 37663, epoch: 142, loss: 0.376245
global_step: 37664, epoch: 142, loss: 0.338800
global_step: 37665, epoch: 142, loss: 0.321845
global_step: 37666, epoch: 142, loss: 0.412133
global_step: 37667, epoch: 142, loss: 0.322304
global_step: 37668, epoch: 142, loss: 0.310942
global_step: 37669, epoch: 142, loss: 0.345261
global_step: 37670, epoch: 142, loss: 0.413728
global_step: 37671, epoch: 142, loss: 0.376225
global_step: 37672, epoch: 142, loss: 0.365486
global_step: 37673, epoch: 142, loss: 0.345078
global_step: 37674, epoch: 142, loss: 0.293885
global_step: 37675, epoch: 142, loss: 0.388813
global_step: 37676, epoch: 142, loss: 0.335099
global_step: 37677, epoch: 142, loss: 0.343289
global_step: 37678, epoch: 142, loss: 0.466107
global_step: 37679, epoch: 142, loss: 0.363649
global_step: 37680, epoch: 142, loss: 0.617535
epoch: 142
train	acc: 0.9384	macro: p 0.9324, r 0.8585, f1: 0.8887	micro: p 0.9384, r 0.9384, f1 0.9384	weighted_f1:0.9371
dev	acc: 0.5573	macro: p 0.4715, r 0.3465, f1: 0.3515	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5186
test	acc: 0.5885	macro: p 0.3975, r 0.3343, f1: 0.3363	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5544
global_step: 37681, epoch: 143, loss: 0.369904
global_step: 37682, epoch: 143, loss: 0.376778
global_step: 37683, epoch: 143, loss: 0.405235
global_step: 37684, epoch: 143, loss: 0.325426
global_step: 37685, epoch: 143, loss: 0.406797
global_step: 37686, epoch: 143, loss: 0.371713
global_step: 37687, epoch: 143, loss: 0.324458
global_step: 37688, epoch: 143, loss: 0.441213
global_step: 37689, epoch: 143, loss: 0.325101
global_step: 37690, epoch: 143, loss: 0.389920
global_step: 37691, epoch: 143, loss: 0.380368
global_step: 37692, epoch: 143, loss: 0.308857
global_step: 37693, epoch: 143, loss: 0.417048
global_step: 37694, epoch: 143, loss: 0.308922
global_step: 37695, epoch: 143, loss: 0.412471
global_step: 37696, epoch: 143, loss: 0.383873
global_step: 37697, epoch: 143, loss: 0.308675
global_step: 37698, epoch: 143, loss: 0.372069
global_step: 37699, epoch: 143, loss: 0.364833
global_step: 37700, epoch: 143, loss: 0.345225
global_step: 37701, epoch: 143, loss: 0.366146
global_step: 37702, epoch: 143, loss: 0.353595
global_step: 37703, epoch: 143, loss: 0.411177
global_step: 37704, epoch: 143, loss: 0.383588
global_step: 37705, epoch: 143, loss: 0.287241
global_step: 37706, epoch: 143, loss: 0.368977
global_step: 37707, epoch: 143, loss: 0.337803
global_step: 37708, epoch: 143, loss: 0.355101
global_step: 37709, epoch: 143, loss: 0.433031
global_step: 37710, epoch: 143, loss: 0.413738
global_step: 37711, epoch: 143, loss: 0.387751
global_step: 37712, epoch: 143, loss: 0.339721
global_step: 37713, epoch: 143, loss: 0.346770
global_step: 37714, epoch: 143, loss: 0.301156
global_step: 37715, epoch: 143, loss: 0.395217
global_step: 37716, epoch: 143, loss: 0.303428
global_step: 37717, epoch: 143, loss: 0.395991
global_step: 37718, epoch: 143, loss: 0.300804
global_step: 37719, epoch: 143, loss: 0.431393
global_step: 37720, epoch: 143, loss: 0.154476
epoch: 143
train	acc: 0.9270	macro: p 0.9372, r 0.8366, f1: 0.8777	micro: p 0.9270, r 0.9270, f1 0.9270	weighted_f1:0.9250
dev	acc: 0.5591	macro: p 0.4526, r 0.3245, f1: 0.3386	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5062
test	acc: 0.5969	macro: p 0.4317, r 0.3239, f1: 0.3446	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5505
global_step: 37721, epoch: 144, loss: 0.365445
global_step: 37722, epoch: 144, loss: 0.311094
global_step: 37723, epoch: 144, loss: 0.380752
global_step: 37724, epoch: 144, loss: 0.301106
global_step: 37725, epoch: 144, loss: 0.432800
global_step: 37726, epoch: 144, loss: 0.354685
global_step: 37727, epoch: 144, loss: 0.403972
global_step: 37728, epoch: 144, loss: 0.388392
global_step: 37729, epoch: 144, loss: 0.315822
global_step: 37730, epoch: 144, loss: 0.355699
global_step: 37731, epoch: 144, loss: 0.356612
global_step: 37732, epoch: 144, loss: 0.352474
global_step: 37733, epoch: 144, loss: 0.313147
global_step: 37734, epoch: 144, loss: 0.334750
global_step: 37735, epoch: 144, loss: 0.307375
global_step: 37736, epoch: 144, loss: 0.331470
global_step: 37737, epoch: 144, loss: 0.326208
global_step: 37738, epoch: 144, loss: 0.432257
global_step: 37739, epoch: 144, loss: 0.323955
global_step: 37740, epoch: 144, loss: 0.347928
global_step: 37741, epoch: 144, loss: 0.385319
global_step: 37742, epoch: 144, loss: 0.401098
global_step: 37743, epoch: 144, loss: 0.389547
global_step: 37744, epoch: 144, loss: 0.407307
global_step: 37745, epoch: 144, loss: 0.359180
global_step: 37746, epoch: 144, loss: 0.434236
global_step: 37747, epoch: 144, loss: 0.306810
global_step: 37748, epoch: 144, loss: 0.412093
global_step: 37749, epoch: 144, loss: 0.329342
global_step: 37750, epoch: 144, loss: 0.298379
global_step: 37751, epoch: 144, loss: 0.382208
global_step: 37752, epoch: 144, loss: 0.403777
global_step: 37753, epoch: 144, loss: 0.344214
global_step: 37754, epoch: 144, loss: 0.360586
global_step: 37755, epoch: 144, loss: 0.314798
global_step: 37756, epoch: 144, loss: 0.340477
global_step: 37757, epoch: 144, loss: 0.345570
global_step: 37758, epoch: 144, loss: 0.366655
global_step: 37759, epoch: 144, loss: 0.347736
global_step: 37760, epoch: 144, loss: 0.321664
epoch: 144
train	acc: 0.9414	macro: p 0.9318, r 0.8657, f1: 0.8910	micro: p 0.9414, r 0.9414, f1 0.9414	weighted_f1:0.9400
dev	acc: 0.5509	macro: p 0.4336, r 0.3476, f1: 0.3513	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5214
test	acc: 0.5831	macro: p 0.3800, r 0.3418, f1: 0.3434	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5556
global_step: 37761, epoch: 145, loss: 0.344813
global_step: 37762, epoch: 145, loss: 0.302952
global_step: 37763, epoch: 145, loss: 0.383435
global_step: 37764, epoch: 145, loss: 0.339546
global_step: 37765, epoch: 145, loss: 0.371623
global_step: 37766, epoch: 145, loss: 0.307247
global_step: 37767, epoch: 145, loss: 0.325123
global_step: 37768, epoch: 145, loss: 0.390091
global_step: 37769, epoch: 145, loss: 0.369742
global_step: 37770, epoch: 145, loss: 0.325681
global_step: 37771, epoch: 145, loss: 0.309074
global_step: 37772, epoch: 145, loss: 0.364187
global_step: 37773, epoch: 145, loss: 0.351427
global_step: 37774, epoch: 145, loss: 0.374184
global_step: 37775, epoch: 145, loss: 0.370685
global_step: 37776, epoch: 145, loss: 0.391901
global_step: 37777, epoch: 145, loss: 0.325530
global_step: 37778, epoch: 145, loss: 0.271909
global_step: 37779, epoch: 145, loss: 0.360107
global_step: 37780, epoch: 145, loss: 0.424098
global_step: 37781, epoch: 145, loss: 0.438908
global_step: 37782, epoch: 145, loss: 0.358546
global_step: 37783, epoch: 145, loss: 0.339949
global_step: 37784, epoch: 145, loss: 0.344772
global_step: 37785, epoch: 145, loss: 0.398715
global_step: 37786, epoch: 145, loss: 0.352181
global_step: 37787, epoch: 145, loss: 0.418149
global_step: 37788, epoch: 145, loss: 0.312544
global_step: 37789, epoch: 145, loss: 0.409829
global_step: 37790, epoch: 145, loss: 0.342317
global_step: 37791, epoch: 145, loss: 0.387464
global_step: 37792, epoch: 145, loss: 0.374263
global_step: 37793, epoch: 145, loss: 0.349412
global_step: 37794, epoch: 145, loss: 0.275008
global_step: 37795, epoch: 145, loss: 0.448177
global_step: 37796, epoch: 145, loss: 0.400069
global_step: 37797, epoch: 145, loss: 0.337678
global_step: 37798, epoch: 145, loss: 0.328971
global_step: 37799, epoch: 145, loss: 0.288830
global_step: 37800, epoch: 145, loss: 0.594966
epoch: 145
train	acc: 0.9454	macro: p 0.9394, r 0.8808, f1: 0.9061	micro: p 0.9454, r 0.9454, f1 0.9454	weighted_f1:0.9446
dev	acc: 0.5546	macro: p 0.4162, r 0.3419, f1: 0.3477	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5163
test	acc: 0.5881	macro: p 0.4022, r 0.3394, f1: 0.3479	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5553
global_step: 37801, epoch: 146, loss: 0.280187
global_step: 37802, epoch: 146, loss: 0.363776
global_step: 37803, epoch: 146, loss: 0.303876
global_step: 37804, epoch: 146, loss: 0.324078
global_step: 37805, epoch: 146, loss: 0.384715
global_step: 37806, epoch: 146, loss: 0.325667
global_step: 37807, epoch: 146, loss: 0.313917
global_step: 37808, epoch: 146, loss: 0.310309
global_step: 37809, epoch: 146, loss: 0.296829
global_step: 37810, epoch: 146, loss: 0.270082
global_step: 37811, epoch: 146, loss: 0.384524
global_step: 37812, epoch: 146, loss: 0.386366
global_step: 37813, epoch: 146, loss: 0.332555
global_step: 37814, epoch: 146, loss: 0.327340
global_step: 37815, epoch: 146, loss: 0.377752
global_step: 37816, epoch: 146, loss: 0.369399
global_step: 37817, epoch: 146, loss: 0.328350
global_step: 37818, epoch: 146, loss: 0.378868
global_step: 37819, epoch: 146, loss: 0.291815
global_step: 37820, epoch: 146, loss: 0.337289
global_step: 37821, epoch: 146, loss: 0.375564
global_step: 37822, epoch: 146, loss: 0.450853
global_step: 37823, epoch: 146, loss: 0.360321
global_step: 37824, epoch: 146, loss: 0.376131
global_step: 37825, epoch: 146, loss: 0.332957
global_step: 37826, epoch: 146, loss: 0.450422
global_step: 37827, epoch: 146, loss: 0.344026
global_step: 37828, epoch: 146, loss: 0.309279
global_step: 37829, epoch: 146, loss: 0.362113
global_step: 37830, epoch: 146, loss: 0.315608
global_step: 37831, epoch: 146, loss: 0.335626
global_step: 37832, epoch: 146, loss: 0.380139
global_step: 37833, epoch: 146, loss: 0.312305
global_step: 37834, epoch: 146, loss: 0.378627
global_step: 37835, epoch: 146, loss: 0.335481
global_step: 37836, epoch: 146, loss: 0.320939
global_step: 37837, epoch: 146, loss: 0.327553
global_step: 37838, epoch: 146, loss: 0.357817
global_step: 37839, epoch: 146, loss: 0.363007
global_step: 37840, epoch: 146, loss: 0.241438
epoch: 146
train	acc: 0.9338	macro: p 0.9346, r 0.8495, f1: 0.8855	micro: p 0.9338, r 0.9338, f1 0.9338	weighted_f1:0.9322
dev	acc: 0.5627	macro: p 0.4564, r 0.3302, f1: 0.3387	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5110
test	acc: 0.5981	macro: p 0.4101, r 0.3227, f1: 0.3345	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5529
global_step: 37841, epoch: 147, loss: 0.371859
global_step: 37842, epoch: 147, loss: 0.338012
global_step: 37843, epoch: 147, loss: 0.327945
global_step: 37844, epoch: 147, loss: 0.370644
global_step: 37845, epoch: 147, loss: 0.323031
global_step: 37846, epoch: 147, loss: 0.328936
global_step: 37847, epoch: 147, loss: 0.371346
global_step: 37848, epoch: 147, loss: 0.359470
global_step: 37849, epoch: 147, loss: 0.418963
global_step: 37850, epoch: 147, loss: 0.385911
global_step: 37851, epoch: 147, loss: 0.325823
global_step: 37852, epoch: 147, loss: 0.397773
global_step: 37853, epoch: 147, loss: 0.294587
global_step: 37854, epoch: 147, loss: 0.342973
global_step: 37855, epoch: 147, loss: 0.361279
global_step: 37856, epoch: 147, loss: 0.342759
global_step: 37857, epoch: 147, loss: 0.463420
global_step: 37858, epoch: 147, loss: 0.375974
global_step: 37859, epoch: 147, loss: 0.394399
global_step: 37860, epoch: 147, loss: 0.348656
global_step: 37861, epoch: 147, loss: 0.321502
global_step: 37862, epoch: 147, loss: 0.353523
global_step: 37863, epoch: 147, loss: 0.406941
global_step: 37864, epoch: 147, loss: 0.334770
global_step: 37865, epoch: 147, loss: 0.344793
global_step: 37866, epoch: 147, loss: 0.307410
global_step: 37867, epoch: 147, loss: 0.408391
global_step: 37868, epoch: 147, loss: 0.397837
global_step: 37869, epoch: 147, loss: 0.350037
global_step: 37870, epoch: 147, loss: 0.379512
global_step: 37871, epoch: 147, loss: 0.312096
global_step: 37872, epoch: 147, loss: 0.310538
global_step: 37873, epoch: 147, loss: 0.410638
global_step: 37874, epoch: 147, loss: 0.341055
global_step: 37875, epoch: 147, loss: 0.365228
global_step: 37876, epoch: 147, loss: 0.336872
global_step: 37877, epoch: 147, loss: 0.315070
global_step: 37878, epoch: 147, loss: 0.336455
global_step: 37879, epoch: 147, loss: 0.299584
global_step: 37880, epoch: 147, loss: 0.130921
epoch: 147
train	acc: 0.9451	macro: p 0.9382, r 0.8765, f1: 0.9020	micro: p 0.9451, r 0.9451, f1 0.9451	weighted_f1:0.9441
dev	acc: 0.5509	macro: p 0.4166, r 0.3455, f1: 0.3499	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5185
test	acc: 0.5866	macro: p 0.3917, r 0.3424, f1: 0.3482	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5578
global_step: 37881, epoch: 148, loss: 0.281998
global_step: 37882, epoch: 148, loss: 0.328265
global_step: 37883, epoch: 148, loss: 0.334658
global_step: 37884, epoch: 148, loss: 0.301904
global_step: 37885, epoch: 148, loss: 0.362866
global_step: 37886, epoch: 148, loss: 0.312453
global_step: 37887, epoch: 148, loss: 0.365785
global_step: 37888, epoch: 148, loss: 0.312654
global_step: 37889, epoch: 148, loss: 0.298945
global_step: 37890, epoch: 148, loss: 0.416240
global_step: 37891, epoch: 148, loss: 0.369573
global_step: 37892, epoch: 148, loss: 0.438599
global_step: 37893, epoch: 148, loss: 0.379541
global_step: 37894, epoch: 148, loss: 0.317878
global_step: 37895, epoch: 148, loss: 0.290894
global_step: 37896, epoch: 148, loss: 0.379227
global_step: 37897, epoch: 148, loss: 0.380736
global_step: 37898, epoch: 148, loss: 0.285959
global_step: 37899, epoch: 148, loss: 0.309144
global_step: 37900, epoch: 148, loss: 0.400315
global_step: 37901, epoch: 148, loss: 0.445428
global_step: 37902, epoch: 148, loss: 0.315477
global_step: 37903, epoch: 148, loss: 0.358839
global_step: 37904, epoch: 148, loss: 0.324747
global_step: 37905, epoch: 148, loss: 0.323344
global_step: 37906, epoch: 148, loss: 0.357379
global_step: 37907, epoch: 148, loss: 0.295543
global_step: 37908, epoch: 148, loss: 0.271613
global_step: 37909, epoch: 148, loss: 0.374911
global_step: 37910, epoch: 148, loss: 0.305681
global_step: 37911, epoch: 148, loss: 0.400876
global_step: 37912, epoch: 148, loss: 0.293646
global_step: 37913, epoch: 148, loss: 0.384214
global_step: 37914, epoch: 148, loss: 0.325889
global_step: 37915, epoch: 148, loss: 0.351944
global_step: 37916, epoch: 148, loss: 0.318211
global_step: 37917, epoch: 148, loss: 0.338870
global_step: 37918, epoch: 148, loss: 0.392388
global_step: 37919, epoch: 148, loss: 0.331686
global_step: 37920, epoch: 148, loss: 0.401128
epoch: 148
train	acc: 0.9414	macro: p 0.9285, r 0.8609, f1: 0.8840	micro: p 0.9414, r 0.9414, f1 0.9414	weighted_f1:0.9398
dev	acc: 0.5518	macro: p 0.3990, r 0.3608, f1: 0.3662	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5336
test	acc: 0.5793	macro: p 0.3853, r 0.3616, f1: 0.3678	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5680
global_step: 37921, epoch: 149, loss: 0.453279
global_step: 37922, epoch: 149, loss: 0.347339
global_step: 37923, epoch: 149, loss: 0.387301
global_step: 37924, epoch: 149, loss: 0.347319
global_step: 37925, epoch: 149, loss: 0.315798
global_step: 37926, epoch: 149, loss: 0.284415
global_step: 37927, epoch: 149, loss: 0.325717
global_step: 37928, epoch: 149, loss: 0.329330
global_step: 37929, epoch: 149, loss: 0.294188
global_step: 37930, epoch: 149, loss: 0.373097
global_step: 37931, epoch: 149, loss: 0.320546
global_step: 37932, epoch: 149, loss: 0.314445
global_step: 37933, epoch: 149, loss: 0.290129
global_step: 37934, epoch: 149, loss: 0.349306
global_step: 37935, epoch: 149, loss: 0.411277
global_step: 37936, epoch: 149, loss: 0.301123
global_step: 37937, epoch: 149, loss: 0.264972
global_step: 37938, epoch: 149, loss: 0.282939
global_step: 37939, epoch: 149, loss: 0.269628
global_step: 37940, epoch: 149, loss: 0.379295
global_step: 37941, epoch: 149, loss: 0.314912
global_step: 37942, epoch: 149, loss: 0.340601
global_step: 37943, epoch: 149, loss: 0.383730
global_step: 37944, epoch: 149, loss: 0.374369
global_step: 37945, epoch: 149, loss: 0.298850
global_step: 37946, epoch: 149, loss: 0.444415
global_step: 37947, epoch: 149, loss: 0.436758
global_step: 37948, epoch: 149, loss: 0.276539
global_step: 37949, epoch: 149, loss: 0.434811
global_step: 37950, epoch: 149, loss: 0.371040
global_step: 37951, epoch: 149, loss: 0.339040
global_step: 37952, epoch: 149, loss: 0.321645
global_step: 37953, epoch: 149, loss: 0.271772
global_step: 37954, epoch: 149, loss: 0.348528
global_step: 37955, epoch: 149, loss: 0.319981
global_step: 37956, epoch: 149, loss: 0.354339
global_step: 37957, epoch: 149, loss: 0.378966
global_step: 37958, epoch: 149, loss: 0.300508
global_step: 37959, epoch: 149, loss: 0.372720
global_step: 37960, epoch: 149, loss: 0.318238
epoch: 149
train	acc: 0.9466	macro: p 0.9399, r 0.8913, f1: 0.9121	micro: p 0.9466, r 0.9466, f1 0.9466	weighted_f1:0.9461
dev	acc: 0.5618	macro: p 0.4043, r 0.3647, f1: 0.3678	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5312
test	acc: 0.5782	macro: p 0.3849, r 0.3490, f1: 0.3538	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5534
global_step: 37961, epoch: 150, loss: 0.319605
global_step: 37962, epoch: 150, loss: 0.314660
global_step: 37963, epoch: 150, loss: 0.321822
global_step: 37964, epoch: 150, loss: 0.346379
global_step: 37965, epoch: 150, loss: 0.344352
global_step: 37966, epoch: 150, loss: 0.382751
global_step: 37967, epoch: 150, loss: 0.364337
global_step: 37968, epoch: 150, loss: 0.428887
global_step: 37969, epoch: 150, loss: 0.430686
global_step: 37970, epoch: 150, loss: 0.308209
global_step: 37971, epoch: 150, loss: 0.390948
global_step: 37972, epoch: 150, loss: 0.267987
global_step: 37973, epoch: 150, loss: 0.280247
global_step: 37974, epoch: 150, loss: 0.364740
global_step: 37975, epoch: 150, loss: 0.285938
global_step: 37976, epoch: 150, loss: 0.406148
global_step: 37977, epoch: 150, loss: 0.384655
global_step: 37978, epoch: 150, loss: 0.264924
global_step: 37979, epoch: 150, loss: 0.332412
global_step: 37980, epoch: 150, loss: 0.321728
global_step: 37981, epoch: 150, loss: 0.363772
global_step: 37982, epoch: 150, loss: 0.334520
global_step: 37983, epoch: 150, loss: 0.394428
global_step: 37984, epoch: 150, loss: 0.267180
global_step: 37985, epoch: 150, loss: 0.413989
global_step: 37986, epoch: 150, loss: 0.302541
global_step: 37987, epoch: 150, loss: 0.290010
global_step: 37988, epoch: 150, loss: 0.320471
global_step: 37989, epoch: 150, loss: 0.342704
global_step: 37990, epoch: 150, loss: 0.361324
global_step: 37991, epoch: 150, loss: 0.356131
global_step: 37992, epoch: 150, loss: 0.340871
global_step: 37993, epoch: 150, loss: 0.374968
global_step: 37994, epoch: 150, loss: 0.446132
global_step: 37995, epoch: 150, loss: 0.420113
global_step: 37996, epoch: 150, loss: 0.301298
global_step: 37997, epoch: 150, loss: 0.361574
global_step: 37998, epoch: 150, loss: 0.370737
global_step: 37999, epoch: 150, loss: 0.301281
global_step: 38000, epoch: 150, loss: 0.149330
epoch: 150
train	acc: 0.9474	macro: p 0.9441, r 0.8866, f1: 0.9115	micro: p 0.9474, r 0.9474, f1 0.9474	weighted_f1:0.9467
dev	acc: 0.5573	macro: p 0.4232, r 0.3449, f1: 0.3521	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5226
test	acc: 0.5916	macro: p 0.4062, r 0.3450, f1: 0.3569	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5635
global_step: 38001, epoch: 151, loss: 0.336118
global_step: 38002, epoch: 151, loss: 0.272610
global_step: 38003, epoch: 151, loss: 0.343462
global_step: 38004, epoch: 151, loss: 0.249797
global_step: 38005, epoch: 151, loss: 0.397654
global_step: 38006, epoch: 151, loss: 0.387063
global_step: 38007, epoch: 151, loss: 0.344035
global_step: 38008, epoch: 151, loss: 0.339351
global_step: 38009, epoch: 151, loss: 0.340277
global_step: 38010, epoch: 151, loss: 0.366282
global_step: 38011, epoch: 151, loss: 0.294614
global_step: 38012, epoch: 151, loss: 0.317948
global_step: 38013, epoch: 151, loss: 0.398981
global_step: 38014, epoch: 151, loss: 0.367842
global_step: 38015, epoch: 151, loss: 0.339872
global_step: 38016, epoch: 151, loss: 0.278137
global_step: 38017, epoch: 151, loss: 0.377291
global_step: 38018, epoch: 151, loss: 0.291204
global_step: 38019, epoch: 151, loss: 0.341014
global_step: 38020, epoch: 151, loss: 0.372979
global_step: 38021, epoch: 151, loss: 0.403010
global_step: 38022, epoch: 151, loss: 0.320065
global_step: 38023, epoch: 151, loss: 0.302954
global_step: 38024, epoch: 151, loss: 0.300962
global_step: 38025, epoch: 151, loss: 0.343970
global_step: 38026, epoch: 151, loss: 0.285847
global_step: 38027, epoch: 151, loss: 0.302489
global_step: 38028, epoch: 151, loss: 0.347573
global_step: 38029, epoch: 151, loss: 0.350109
global_step: 38030, epoch: 151, loss: 0.416018
global_step: 38031, epoch: 151, loss: 0.251850
global_step: 38032, epoch: 151, loss: 0.259716
global_step: 38033, epoch: 151, loss: 0.353322
global_step: 38034, epoch: 151, loss: 0.306237
global_step: 38035, epoch: 151, loss: 0.323868
global_step: 38036, epoch: 151, loss: 0.409419
global_step: 38037, epoch: 151, loss: 0.343796
global_step: 38038, epoch: 151, loss: 0.364719
global_step: 38039, epoch: 151, loss: 0.308049
global_step: 38040, epoch: 151, loss: 0.083412
epoch: 151
train	acc: 0.9490	macro: p 0.9421, r 0.8916, f1: 0.9124	micro: p 0.9490, r 0.9490, f1 0.9490	weighted_f1:0.9484
dev	acc: 0.5491	macro: p 0.3977, r 0.3525, f1: 0.3540	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5241
test	acc: 0.5808	macro: p 0.3788, r 0.3465, f1: 0.3482	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5583
global_step: 38041, epoch: 152, loss: 0.323326
global_step: 38042, epoch: 152, loss: 0.392172
global_step: 38043, epoch: 152, loss: 0.321273
global_step: 38044, epoch: 152, loss: 0.344446
global_step: 38045, epoch: 152, loss: 0.276601
global_step: 38046, epoch: 152, loss: 0.312751
global_step: 38047, epoch: 152, loss: 0.352565
global_step: 38048, epoch: 152, loss: 0.333097
global_step: 38049, epoch: 152, loss: 0.331627
global_step: 38050, epoch: 152, loss: 0.412374
global_step: 38051, epoch: 152, loss: 0.351579
global_step: 38052, epoch: 152, loss: 0.300334
global_step: 38053, epoch: 152, loss: 0.307527
global_step: 38054, epoch: 152, loss: 0.359072
global_step: 38055, epoch: 152, loss: 0.266374
global_step: 38056, epoch: 152, loss: 0.355998
global_step: 38057, epoch: 152, loss: 0.356599
global_step: 38058, epoch: 152, loss: 0.237562
global_step: 38059, epoch: 152, loss: 0.332851
global_step: 38060, epoch: 152, loss: 0.292978
global_step: 38061, epoch: 152, loss: 0.309950
global_step: 38062, epoch: 152, loss: 0.263939
global_step: 38063, epoch: 152, loss: 0.328347
global_step: 38064, epoch: 152, loss: 0.420417
global_step: 38065, epoch: 152, loss: 0.314459
global_step: 38066, epoch: 152, loss: 0.333190
global_step: 38067, epoch: 152, loss: 0.345206
global_step: 38068, epoch: 152, loss: 0.319048
global_step: 38069, epoch: 152, loss: 0.317537
global_step: 38070, epoch: 152, loss: 0.402662
global_step: 38071, epoch: 152, loss: 0.327885
global_step: 38072, epoch: 152, loss: 0.387048
global_step: 38073, epoch: 152, loss: 0.273629
global_step: 38074, epoch: 152, loss: 0.319364
global_step: 38075, epoch: 152, loss: 0.310482
global_step: 38076, epoch: 152, loss: 0.385660
global_step: 38077, epoch: 152, loss: 0.266282
global_step: 38078, epoch: 152, loss: 0.291342
global_step: 38079, epoch: 152, loss: 0.306705
global_step: 38080, epoch: 152, loss: 0.480903
epoch: 152
train	acc: 0.9495	macro: p 0.9411, r 0.8933, f1: 0.9132	micro: p 0.9495, r 0.9495, f1 0.9495	weighted_f1:0.9489
dev	acc: 0.5564	macro: p 0.3981, r 0.3629, f1: 0.3625	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5327
test	acc: 0.5793	macro: p 0.3792, r 0.3539, f1: 0.3555	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5611
global_step: 38081, epoch: 153, loss: 0.365036
global_step: 38082, epoch: 153, loss: 0.221200
global_step: 38083, epoch: 153, loss: 0.299986
global_step: 38084, epoch: 153, loss: 0.393056
global_step: 38085, epoch: 153, loss: 0.240321
global_step: 38086, epoch: 153, loss: 0.342631
global_step: 38087, epoch: 153, loss: 0.412887
global_step: 38088, epoch: 153, loss: 0.296980
global_step: 38089, epoch: 153, loss: 0.373909
global_step: 38090, epoch: 153, loss: 0.315555
global_step: 38091, epoch: 153, loss: 0.270072
global_step: 38092, epoch: 153, loss: 0.305062
global_step: 38093, epoch: 153, loss: 0.345175
global_step: 38094, epoch: 153, loss: 0.283128
global_step: 38095, epoch: 153, loss: 0.336004
global_step: 38096, epoch: 153, loss: 0.277380
global_step: 38097, epoch: 153, loss: 0.275404
global_step: 38098, epoch: 153, loss: 0.285521
global_step: 38099, epoch: 153, loss: 0.329293
global_step: 38100, epoch: 153, loss: 0.325857
global_step: 38101, epoch: 153, loss: 0.272438
global_step: 38102, epoch: 153, loss: 0.314124
global_step: 38103, epoch: 153, loss: 0.395285
global_step: 38104, epoch: 153, loss: 0.319277
global_step: 38105, epoch: 153, loss: 0.303827
global_step: 38106, epoch: 153, loss: 0.290398
global_step: 38107, epoch: 153, loss: 0.347663
global_step: 38108, epoch: 153, loss: 0.366395
global_step: 38109, epoch: 153, loss: 0.302081
global_step: 38110, epoch: 153, loss: 0.273184
global_step: 38111, epoch: 153, loss: 0.358158
global_step: 38112, epoch: 153, loss: 0.290702
global_step: 38113, epoch: 153, loss: 0.307054
global_step: 38114, epoch: 153, loss: 0.379896
global_step: 38115, epoch: 153, loss: 0.352668
global_step: 38116, epoch: 153, loss: 0.389514
global_step: 38117, epoch: 153, loss: 0.380349
global_step: 38118, epoch: 153, loss: 0.346394
global_step: 38119, epoch: 153, loss: 0.353969
global_step: 38120, epoch: 153, loss: 0.316482
epoch: 153
train	acc: 0.9490	macro: p 0.9433, r 0.8944, f1: 0.9157	micro: p 0.9490, r 0.9490, f1 0.9490	weighted_f1:0.9485
dev	acc: 0.5546	macro: p 0.4266, r 0.3485, f1: 0.3518	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5197
test	acc: 0.5839	macro: p 0.3820, r 0.3393, f1: 0.3432	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5542
global_step: 38121, epoch: 154, loss: 0.319886
global_step: 38122, epoch: 154, loss: 0.335172
global_step: 38123, epoch: 154, loss: 0.345508
global_step: 38124, epoch: 154, loss: 0.327591
global_step: 38125, epoch: 154, loss: 0.327045
global_step: 38126, epoch: 154, loss: 0.299875
global_step: 38127, epoch: 154, loss: 0.359698
global_step: 38128, epoch: 154, loss: 0.318585
global_step: 38129, epoch: 154, loss: 0.384024
global_step: 38130, epoch: 154, loss: 0.284818
global_step: 38131, epoch: 154, loss: 0.285207
global_step: 38132, epoch: 154, loss: 0.395083
global_step: 38133, epoch: 154, loss: 0.285802
global_step: 38134, epoch: 154, loss: 0.351258
global_step: 38135, epoch: 154, loss: 0.352505
global_step: 38136, epoch: 154, loss: 0.303861
global_step: 38137, epoch: 154, loss: 0.352380
global_step: 38138, epoch: 154, loss: 0.314871
global_step: 38139, epoch: 154, loss: 0.322216
global_step: 38140, epoch: 154, loss: 0.256152
global_step: 38141, epoch: 154, loss: 0.329943
global_step: 38142, epoch: 154, loss: 0.306063
global_step: 38143, epoch: 154, loss: 0.283793
global_step: 38144, epoch: 154, loss: 0.297248
global_step: 38145, epoch: 154, loss: 0.367649
global_step: 38146, epoch: 154, loss: 0.307406
global_step: 38147, epoch: 154, loss: 0.401064
global_step: 38148, epoch: 154, loss: 0.282479
global_step: 38149, epoch: 154, loss: 0.290589
global_step: 38150, epoch: 154, loss: 0.341263
global_step: 38151, epoch: 154, loss: 0.300328
global_step: 38152, epoch: 154, loss: 0.331422
global_step: 38153, epoch: 154, loss: 0.236757
global_step: 38154, epoch: 154, loss: 0.297953
global_step: 38155, epoch: 154, loss: 0.343422
global_step: 38156, epoch: 154, loss: 0.336858
global_step: 38157, epoch: 154, loss: 0.391112
global_step: 38158, epoch: 154, loss: 0.371036
global_step: 38159, epoch: 154, loss: 0.318571
global_step: 38160, epoch: 154, loss: 0.112557
epoch: 154
train	acc: 0.9502	macro: p 0.9419, r 0.8972, f1: 0.9159	micro: p 0.9502, r 0.9502, f1 0.9502	weighted_f1:0.9497
dev	acc: 0.5564	macro: p 0.3998, r 0.3568, f1: 0.3583	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5286
test	acc: 0.5812	macro: p 0.3762, r 0.3511, f1: 0.3531	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5592
global_step: 38161, epoch: 155, loss: 0.397140
global_step: 38162, epoch: 155, loss: 0.282564
global_step: 38163, epoch: 155, loss: 0.377515
global_step: 38164, epoch: 155, loss: 0.364436
global_step: 38165, epoch: 155, loss: 0.434162
global_step: 38166, epoch: 155, loss: 0.312313
global_step: 38167, epoch: 155, loss: 0.358950
global_step: 38168, epoch: 155, loss: 0.375967
global_step: 38169, epoch: 155, loss: 0.340200
global_step: 38170, epoch: 155, loss: 0.288325
global_step: 38171, epoch: 155, loss: 0.299644
global_step: 38172, epoch: 155, loss: 0.367321
global_step: 38173, epoch: 155, loss: 0.355581
global_step: 38174, epoch: 155, loss: 0.279086
global_step: 38175, epoch: 155, loss: 0.406458
global_step: 38176, epoch: 155, loss: 0.350035
global_step: 38177, epoch: 155, loss: 0.381947
global_step: 38178, epoch: 155, loss: 0.251117
global_step: 38179, epoch: 155, loss: 0.279312
global_step: 38180, epoch: 155, loss: 0.351573
global_step: 38181, epoch: 155, loss: 0.264752
global_step: 38182, epoch: 155, loss: 0.330782
global_step: 38183, epoch: 155, loss: 0.265651
global_step: 38184, epoch: 155, loss: 0.295664
global_step: 38185, epoch: 155, loss: 0.335505
global_step: 38186, epoch: 155, loss: 0.322776
global_step: 38187, epoch: 155, loss: 0.352813
global_step: 38188, epoch: 155, loss: 0.300578
global_step: 38189, epoch: 155, loss: 0.331986
global_step: 38190, epoch: 155, loss: 0.364380
global_step: 38191, epoch: 155, loss: 0.315304
global_step: 38192, epoch: 155, loss: 0.257534
global_step: 38193, epoch: 155, loss: 0.321293
global_step: 38194, epoch: 155, loss: 0.269961
global_step: 38195, epoch: 155, loss: 0.328490
global_step: 38196, epoch: 155, loss: 0.326134
global_step: 38197, epoch: 155, loss: 0.343573
global_step: 38198, epoch: 155, loss: 0.375616
global_step: 38199, epoch: 155, loss: 0.315138
global_step: 38200, epoch: 155, loss: 0.215597
epoch: 155
train	acc: 0.9475	macro: p 0.9383, r 0.8839, f1: 0.9060	micro: p 0.9475, r 0.9475, f1 0.9475	weighted_f1:0.9467
dev	acc: 0.5482	macro: p 0.3960, r 0.3534, f1: 0.3594	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5266
test	acc: 0.5870	macro: p 0.4061, r 0.3651, f1: 0.3771	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5713
global_step: 38201, epoch: 156, loss: 0.338519
global_step: 38202, epoch: 156, loss: 0.214247
global_step: 38203, epoch: 156, loss: 0.354404
global_step: 38204, epoch: 156, loss: 0.317444
global_step: 38205, epoch: 156, loss: 0.268862
global_step: 38206, epoch: 156, loss: 0.331019
global_step: 38207, epoch: 156, loss: 0.292550
global_step: 38208, epoch: 156, loss: 0.307410
global_step: 38209, epoch: 156, loss: 0.285613
global_step: 38210, epoch: 156, loss: 0.226276
global_step: 38211, epoch: 156, loss: 0.248408
global_step: 38212, epoch: 156, loss: 0.359787
global_step: 38213, epoch: 156, loss: 0.320900
global_step: 38214, epoch: 156, loss: 0.359653
global_step: 38215, epoch: 156, loss: 0.318656
global_step: 38216, epoch: 156, loss: 0.308151
global_step: 38217, epoch: 156, loss: 0.299528
global_step: 38218, epoch: 156, loss: 0.300249
global_step: 38219, epoch: 156, loss: 0.262832
global_step: 38220, epoch: 156, loss: 0.355301
global_step: 38221, epoch: 156, loss: 0.325469
global_step: 38222, epoch: 156, loss: 0.338770
global_step: 38223, epoch: 156, loss: 0.267752
global_step: 38224, epoch: 156, loss: 0.298903
global_step: 38225, epoch: 156, loss: 0.298063
global_step: 38226, epoch: 156, loss: 0.327751
global_step: 38227, epoch: 156, loss: 0.349384
global_step: 38228, epoch: 156, loss: 0.301015
global_step: 38229, epoch: 156, loss: 0.331318
global_step: 38230, epoch: 156, loss: 0.341207
global_step: 38231, epoch: 156, loss: 0.295096
global_step: 38232, epoch: 156, loss: 0.407118
global_step: 38233, epoch: 156, loss: 0.274475
global_step: 38234, epoch: 156, loss: 0.329515
global_step: 38235, epoch: 156, loss: 0.334065
global_step: 38236, epoch: 156, loss: 0.320110
global_step: 38237, epoch: 156, loss: 0.383152
global_step: 38238, epoch: 156, loss: 0.269542
global_step: 38239, epoch: 156, loss: 0.349013
global_step: 38240, epoch: 156, loss: 0.110898
epoch: 156
train	acc: 0.9488	macro: p 0.9405, r 0.8891, f1: 0.9101	micro: p 0.9488, r 0.9488, f1 0.9488	weighted_f1:0.9481
dev	acc: 0.5528	macro: p 0.4037, r 0.3539, f1: 0.3588	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5243
test	acc: 0.5862	macro: p 0.3950, r 0.3527, f1: 0.3611	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5634
global_step: 38241, epoch: 157, loss: 0.301791
global_step: 38242, epoch: 157, loss: 0.343293
global_step: 38243, epoch: 157, loss: 0.345469
global_step: 38244, epoch: 157, loss: 0.245293
global_step: 38245, epoch: 157, loss: 0.374681
global_step: 38246, epoch: 157, loss: 0.315824
global_step: 38247, epoch: 157, loss: 0.330678
global_step: 38248, epoch: 157, loss: 0.330317
global_step: 38249, epoch: 157, loss: 0.290214
global_step: 38250, epoch: 157, loss: 0.293362
global_step: 38251, epoch: 157, loss: 0.406104
global_step: 38252, epoch: 157, loss: 0.234978
global_step: 38253, epoch: 157, loss: 0.340801
global_step: 38254, epoch: 157, loss: 0.309805
global_step: 38255, epoch: 157, loss: 0.324677
global_step: 38256, epoch: 157, loss: 0.319161
global_step: 38257, epoch: 157, loss: 0.326268
global_step: 38258, epoch: 157, loss: 0.328814
global_step: 38259, epoch: 157, loss: 0.338560
global_step: 38260, epoch: 157, loss: 0.305330
global_step: 38261, epoch: 157, loss: 0.287867
global_step: 38262, epoch: 157, loss: 0.324995
global_step: 38263, epoch: 157, loss: 0.285456
global_step: 38264, epoch: 157, loss: 0.320006
global_step: 38265, epoch: 157, loss: 0.368262
global_step: 38266, epoch: 157, loss: 0.322716
global_step: 38267, epoch: 157, loss: 0.317442
global_step: 38268, epoch: 157, loss: 0.353581
global_step: 38269, epoch: 157, loss: 0.254935
global_step: 38270, epoch: 157, loss: 0.363020
global_step: 38271, epoch: 157, loss: 0.235746
global_step: 38272, epoch: 157, loss: 0.496560
global_step: 38273, epoch: 157, loss: 0.307801
global_step: 38274, epoch: 157, loss: 0.286414
global_step: 38275, epoch: 157, loss: 0.397864
global_step: 38276, epoch: 157, loss: 0.319541
global_step: 38277, epoch: 157, loss: 0.258381
global_step: 38278, epoch: 157, loss: 0.272265
global_step: 38279, epoch: 157, loss: 0.338122
global_step: 38280, epoch: 157, loss: 0.059144
epoch: 157
train	acc: 0.9500	macro: p 0.9457, r 0.8907, f1: 0.9133	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9492
dev	acc: 0.5555	macro: p 0.4067, r 0.3431, f1: 0.3501	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5217
test	acc: 0.5858	macro: p 0.4005, r 0.3420, f1: 0.3540	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5580
global_step: 38281, epoch: 158, loss: 0.275248
global_step: 38282, epoch: 158, loss: 0.368877
global_step: 38283, epoch: 158, loss: 0.259732
global_step: 38284, epoch: 158, loss: 0.315066
global_step: 38285, epoch: 158, loss: 0.304624
global_step: 38286, epoch: 158, loss: 0.345643
global_step: 38287, epoch: 158, loss: 0.329717
global_step: 38288, epoch: 158, loss: 0.363613
global_step: 38289, epoch: 158, loss: 0.329481
global_step: 38290, epoch: 158, loss: 0.306517
global_step: 38291, epoch: 158, loss: 0.313790
global_step: 38292, epoch: 158, loss: 0.301443
global_step: 38293, epoch: 158, loss: 0.363026
global_step: 38294, epoch: 158, loss: 0.336914
global_step: 38295, epoch: 158, loss: 0.278579
global_step: 38296, epoch: 158, loss: 0.364280
global_step: 38297, epoch: 158, loss: 0.339990
global_step: 38298, epoch: 158, loss: 0.287893
global_step: 38299, epoch: 158, loss: 0.245076
global_step: 38300, epoch: 158, loss: 0.267367
global_step: 38301, epoch: 158, loss: 0.332254
global_step: 38302, epoch: 158, loss: 0.396158
global_step: 38303, epoch: 158, loss: 0.283765
global_step: 38304, epoch: 158, loss: 0.318481
global_step: 38305, epoch: 158, loss: 0.358786
global_step: 38306, epoch: 158, loss: 0.315636
global_step: 38307, epoch: 158, loss: 0.292961
global_step: 38308, epoch: 158, loss: 0.336222
global_step: 38309, epoch: 158, loss: 0.323267
global_step: 38310, epoch: 158, loss: 0.262683
global_step: 38311, epoch: 158, loss: 0.312290
global_step: 38312, epoch: 158, loss: 0.310518
global_step: 38313, epoch: 158, loss: 0.248898
global_step: 38314, epoch: 158, loss: 0.344343
global_step: 38315, epoch: 158, loss: 0.301753
global_step: 38316, epoch: 158, loss: 0.362405
global_step: 38317, epoch: 158, loss: 0.322898
global_step: 38318, epoch: 158, loss: 0.379796
global_step: 38319, epoch: 158, loss: 0.363557
global_step: 38320, epoch: 158, loss: 0.317389
epoch: 158
train	acc: 0.9486	macro: p 0.9492, r 0.8952, f1: 0.9195	micro: p 0.9486, r 0.9486, f1 0.9486	weighted_f1:0.9481
dev	acc: 0.5582	macro: p 0.4311, r 0.3350, f1: 0.3441	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5121
test	acc: 0.5920	macro: p 0.4161, r 0.3327, f1: 0.3472	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5510
global_step: 38321, epoch: 159, loss: 0.283699
global_step: 38322, epoch: 159, loss: 0.360779
global_step: 38323, epoch: 159, loss: 0.362154
global_step: 38324, epoch: 159, loss: 0.330981
global_step: 38325, epoch: 159, loss: 0.339291
global_step: 38326, epoch: 159, loss: 0.310582
global_step: 38327, epoch: 159, loss: 0.344323
global_step: 38328, epoch: 159, loss: 0.285565
global_step: 38329, epoch: 159, loss: 0.346070
global_step: 38330, epoch: 159, loss: 0.337622
global_step: 38331, epoch: 159, loss: 0.339130
global_step: 38332, epoch: 159, loss: 0.288296
global_step: 38333, epoch: 159, loss: 0.368576
global_step: 38334, epoch: 159, loss: 0.362488
global_step: 38335, epoch: 159, loss: 0.277037
global_step: 38336, epoch: 159, loss: 0.227304
global_step: 38337, epoch: 159, loss: 0.373216
global_step: 38338, epoch: 159, loss: 0.344155
global_step: 38339, epoch: 159, loss: 0.283426
global_step: 38340, epoch: 159, loss: 0.287134
global_step: 38341, epoch: 159, loss: 0.302869
global_step: 38342, epoch: 159, loss: 0.263832
global_step: 38343, epoch: 159, loss: 0.263429
global_step: 38344, epoch: 159, loss: 0.295451
global_step: 38345, epoch: 159, loss: 0.292122
global_step: 38346, epoch: 159, loss: 0.342790
global_step: 38347, epoch: 159, loss: 0.285613
global_step: 38348, epoch: 159, loss: 0.280312
global_step: 38349, epoch: 159, loss: 0.257583
global_step: 38350, epoch: 159, loss: 0.261494
global_step: 38351, epoch: 159, loss: 0.297125
global_step: 38352, epoch: 159, loss: 0.425600
global_step: 38353, epoch: 159, loss: 0.392719
global_step: 38354, epoch: 159, loss: 0.343500
global_step: 38355, epoch: 159, loss: 0.339938
global_step: 38356, epoch: 159, loss: 0.363393
global_step: 38357, epoch: 159, loss: 0.277727
global_step: 38358, epoch: 159, loss: 0.249679
global_step: 38359, epoch: 159, loss: 0.289121
global_step: 38360, epoch: 159, loss: 0.066350
epoch: 159
train	acc: 0.9529	macro: p 0.9481, r 0.9029, f1: 0.9229	micro: p 0.9529, r 0.9529, f1 0.9529	weighted_f1:0.9525
dev	acc: 0.5573	macro: p 0.4148, r 0.3600, f1: 0.3669	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5303
test	acc: 0.5851	macro: p 0.3725, r 0.3461, f1: 0.3487	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5615
global_step: 38361, epoch: 160, loss: 0.336511
global_step: 38362, epoch: 160, loss: 0.313633
global_step: 38363, epoch: 160, loss: 0.362552
global_step: 38364, epoch: 160, loss: 0.281627
global_step: 38365, epoch: 160, loss: 0.297575
global_step: 38366, epoch: 160, loss: 0.261496
global_step: 38367, epoch: 160, loss: 0.267393
global_step: 38368, epoch: 160, loss: 0.332846
global_step: 38369, epoch: 160, loss: 0.332629
global_step: 38370, epoch: 160, loss: 0.466147
global_step: 38371, epoch: 160, loss: 0.241066
global_step: 38372, epoch: 160, loss: 0.264596
global_step: 38373, epoch: 160, loss: 0.358763
global_step: 38374, epoch: 160, loss: 0.328929
global_step: 38375, epoch: 160, loss: 0.320515
global_step: 38376, epoch: 160, loss: 0.260950
global_step: 38377, epoch: 160, loss: 0.261031
global_step: 38378, epoch: 160, loss: 0.256929
global_step: 38379, epoch: 160, loss: 0.362267
global_step: 38380, epoch: 160, loss: 0.217902
global_step: 38381, epoch: 160, loss: 0.300618
global_step: 38382, epoch: 160, loss: 0.365379
global_step: 38383, epoch: 160, loss: 0.299984
global_step: 38384, epoch: 160, loss: 0.342036
global_step: 38385, epoch: 160, loss: 0.249245
global_step: 38386, epoch: 160, loss: 0.438037
global_step: 38387, epoch: 160, loss: 0.342233
global_step: 38388, epoch: 160, loss: 0.259160
global_step: 38389, epoch: 160, loss: 0.309611
global_step: 38390, epoch: 160, loss: 0.300655
global_step: 38391, epoch: 160, loss: 0.269368
global_step: 38392, epoch: 160, loss: 0.384207
global_step: 38393, epoch: 160, loss: 0.260428
global_step: 38394, epoch: 160, loss: 0.377395
global_step: 38395, epoch: 160, loss: 0.317264
global_step: 38396, epoch: 160, loss: 0.266746
global_step: 38397, epoch: 160, loss: 0.324952
global_step: 38398, epoch: 160, loss: 0.259550
global_step: 38399, epoch: 160, loss: 0.295915
global_step: 38400, epoch: 160, loss: 0.696613
epoch: 160
train	acc: 0.9506	macro: p 0.9429, r 0.9035, f1: 0.9208	micro: p 0.9506, r 0.9506, f1 0.9506	weighted_f1:0.9503
dev	acc: 0.5473	macro: p 0.4149, r 0.3524, f1: 0.3620	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5250
test	acc: 0.5866	macro: p 0.3995, r 0.3582, f1: 0.3664	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5674
global_step: 38401, epoch: 161, loss: 0.256921
global_step: 38402, epoch: 161, loss: 0.355716
global_step: 38403, epoch: 161, loss: 0.285356
global_step: 38404, epoch: 161, loss: 0.367801
global_step: 38405, epoch: 161, loss: 0.247873
global_step: 38406, epoch: 161, loss: 0.301116
global_step: 38407, epoch: 161, loss: 0.324619
global_step: 38408, epoch: 161, loss: 0.191338
global_step: 38409, epoch: 161, loss: 0.227787
global_step: 38410, epoch: 161, loss: 0.316741
global_step: 38411, epoch: 161, loss: 0.338008
global_step: 38412, epoch: 161, loss: 0.348508
global_step: 38413, epoch: 161, loss: 0.261695
global_step: 38414, epoch: 161, loss: 0.303737
global_step: 38415, epoch: 161, loss: 0.284984
global_step: 38416, epoch: 161, loss: 0.294137
global_step: 38417, epoch: 161, loss: 0.271389
global_step: 38418, epoch: 161, loss: 0.355133
global_step: 38419, epoch: 161, loss: 0.400318
global_step: 38420, epoch: 161, loss: 0.286882
global_step: 38421, epoch: 161, loss: 0.374549
global_step: 38422, epoch: 161, loss: 0.290931
global_step: 38423, epoch: 161, loss: 0.336452
global_step: 38424, epoch: 161, loss: 0.329860
global_step: 38425, epoch: 161, loss: 0.236505
global_step: 38426, epoch: 161, loss: 0.386213
global_step: 38427, epoch: 161, loss: 0.316881
global_step: 38428, epoch: 161, loss: 0.437951
global_step: 38429, epoch: 161, loss: 0.238899
global_step: 38430, epoch: 161, loss: 0.269621
global_step: 38431, epoch: 161, loss: 0.410115
global_step: 38432, epoch: 161, loss: 0.299645
global_step: 38433, epoch: 161, loss: 0.357275
global_step: 38434, epoch: 161, loss: 0.315281
global_step: 38435, epoch: 161, loss: 0.338261
global_step: 38436, epoch: 161, loss: 0.373872
global_step: 38437, epoch: 161, loss: 0.314166
global_step: 38438, epoch: 161, loss: 0.328644
global_step: 38439, epoch: 161, loss: 0.317863
global_step: 38440, epoch: 161, loss: 0.231275
epoch: 161
train	acc: 0.9471	macro: p 0.9452, r 0.8808, f1: 0.9078	micro: p 0.9471, r 0.9471, f1 0.9471	weighted_f1:0.9462
dev	acc: 0.5591	macro: p 0.4302, r 0.3392, f1: 0.3546	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5205
test	acc: 0.6000	macro: p 0.4382, r 0.3431, f1: 0.3648	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5658
global_step: 38441, epoch: 162, loss: 0.287507
global_step: 38442, epoch: 162, loss: 0.363581
global_step: 38443, epoch: 162, loss: 0.273298
global_step: 38444, epoch: 162, loss: 0.344088
global_step: 38445, epoch: 162, loss: 0.348989
global_step: 38446, epoch: 162, loss: 0.316794
global_step: 38447, epoch: 162, loss: 0.369199
global_step: 38448, epoch: 162, loss: 0.302521
global_step: 38449, epoch: 162, loss: 0.288924
global_step: 38450, epoch: 162, loss: 0.278441
global_step: 38451, epoch: 162, loss: 0.285095
global_step: 38452, epoch: 162, loss: 0.276830
global_step: 38453, epoch: 162, loss: 0.229100
global_step: 38454, epoch: 162, loss: 0.377548
global_step: 38455, epoch: 162, loss: 0.259146
global_step: 38456, epoch: 162, loss: 0.301879
global_step: 38457, epoch: 162, loss: 0.374255
global_step: 38458, epoch: 162, loss: 0.298518
global_step: 38459, epoch: 162, loss: 0.303342
global_step: 38460, epoch: 162, loss: 0.252946
global_step: 38461, epoch: 162, loss: 0.290121
global_step: 38462, epoch: 162, loss: 0.236276
global_step: 38463, epoch: 162, loss: 0.272689
global_step: 38464, epoch: 162, loss: 0.374751
global_step: 38465, epoch: 162, loss: 0.338103
global_step: 38466, epoch: 162, loss: 0.297189
global_step: 38467, epoch: 162, loss: 0.276259
global_step: 38468, epoch: 162, loss: 0.317463
global_step: 38469, epoch: 162, loss: 0.323088
global_step: 38470, epoch: 162, loss: 0.325252
global_step: 38471, epoch: 162, loss: 0.286298
global_step: 38472, epoch: 162, loss: 0.312334
global_step: 38473, epoch: 162, loss: 0.272745
global_step: 38474, epoch: 162, loss: 0.383341
global_step: 38475, epoch: 162, loss: 0.305016
global_step: 38476, epoch: 162, loss: 0.324346
global_step: 38477, epoch: 162, loss: 0.259589
global_step: 38478, epoch: 162, loss: 0.349398
global_step: 38479, epoch: 162, loss: 0.271159
global_step: 38480, epoch: 162, loss: 0.175659
epoch: 162
train	acc: 0.9532	macro: p 0.9458, r 0.9054, f1: 0.9236	micro: p 0.9532, r 0.9532, f1 0.9532	weighted_f1:0.9528
dev	acc: 0.5528	macro: p 0.3862, r 0.3451, f1: 0.3509	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5208
test	acc: 0.5893	macro: p 0.4023, r 0.3510, f1: 0.3639	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5622
global_step: 38481, epoch: 163, loss: 0.303995
global_step: 38482, epoch: 163, loss: 0.279953
global_step: 38483, epoch: 163, loss: 0.314091
global_step: 38484, epoch: 163, loss: 0.279974
global_step: 38485, epoch: 163, loss: 0.242195
global_step: 38486, epoch: 163, loss: 0.315161
global_step: 38487, epoch: 163, loss: 0.332755
global_step: 38488, epoch: 163, loss: 0.276389
global_step: 38489, epoch: 163, loss: 0.248647
global_step: 38490, epoch: 163, loss: 0.317949
global_step: 38491, epoch: 163, loss: 0.265408
global_step: 38492, epoch: 163, loss: 0.285835
global_step: 38493, epoch: 163, loss: 0.348280
global_step: 38494, epoch: 163, loss: 0.346055
global_step: 38495, epoch: 163, loss: 0.341439
global_step: 38496, epoch: 163, loss: 0.286681
global_step: 38497, epoch: 163, loss: 0.323803
global_step: 38498, epoch: 163, loss: 0.308330
global_step: 38499, epoch: 163, loss: 0.263882
global_step: 38500, epoch: 163, loss: 0.344176
global_step: 38501, epoch: 163, loss: 0.265434
global_step: 38502, epoch: 163, loss: 0.285316
global_step: 38503, epoch: 163, loss: 0.345462
global_step: 38504, epoch: 163, loss: 0.271265
global_step: 38505, epoch: 163, loss: 0.276102
global_step: 38506, epoch: 163, loss: 0.262621
global_step: 38507, epoch: 163, loss: 0.337111
global_step: 38508, epoch: 163, loss: 0.337435
global_step: 38509, epoch: 163, loss: 0.320813
global_step: 38510, epoch: 163, loss: 0.283113
global_step: 38511, epoch: 163, loss: 0.304735
global_step: 38512, epoch: 163, loss: 0.330129
global_step: 38513, epoch: 163, loss: 0.336928
global_step: 38514, epoch: 163, loss: 0.308829
global_step: 38515, epoch: 163, loss: 0.332112
global_step: 38516, epoch: 163, loss: 0.315995
global_step: 38517, epoch: 163, loss: 0.269919
global_step: 38518, epoch: 163, loss: 0.307676
global_step: 38519, epoch: 163, loss: 0.292956
global_step: 38520, epoch: 163, loss: 0.111389
epoch: 163
train	acc: 0.9521	macro: p 0.9488, r 0.9057, f1: 0.9250	micro: p 0.9521, r 0.9521, f1 0.9521	weighted_f1:0.9518
dev	acc: 0.5546	macro: p 0.4183, r 0.3475, f1: 0.3516	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5180
test	acc: 0.5939	macro: p 0.3962, r 0.3485, f1: 0.3530	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5640
global_step: 38521, epoch: 164, loss: 0.219974
global_step: 38522, epoch: 164, loss: 0.267312
global_step: 38523, epoch: 164, loss: 0.234760
global_step: 38524, epoch: 164, loss: 0.346887
global_step: 38525, epoch: 164, loss: 0.300062
global_step: 38526, epoch: 164, loss: 0.325829
global_step: 38527, epoch: 164, loss: 0.283094
global_step: 38528, epoch: 164, loss: 0.308463
global_step: 38529, epoch: 164, loss: 0.307957
global_step: 38530, epoch: 164, loss: 0.300654
global_step: 38531, epoch: 164, loss: 0.384467
global_step: 38532, epoch: 164, loss: 0.342574
global_step: 38533, epoch: 164, loss: 0.276860
global_step: 38534, epoch: 164, loss: 0.266862
global_step: 38535, epoch: 164, loss: 0.299839
global_step: 38536, epoch: 164, loss: 0.318055
global_step: 38537, epoch: 164, loss: 0.304367
global_step: 38538, epoch: 164, loss: 0.223398
global_step: 38539, epoch: 164, loss: 0.256019
global_step: 38540, epoch: 164, loss: 0.370686
global_step: 38541, epoch: 164, loss: 0.293050
global_step: 38542, epoch: 164, loss: 0.237502
global_step: 38543, epoch: 164, loss: 0.238694
global_step: 38544, epoch: 164, loss: 0.271704
global_step: 38545, epoch: 164, loss: 0.328724
global_step: 38546, epoch: 164, loss: 0.295945
global_step: 38547, epoch: 164, loss: 0.441537
global_step: 38548, epoch: 164, loss: 0.313139
global_step: 38549, epoch: 164, loss: 0.271114
global_step: 38550, epoch: 164, loss: 0.338676
global_step: 38551, epoch: 164, loss: 0.237693
global_step: 38552, epoch: 164, loss: 0.357356
global_step: 38553, epoch: 164, loss: 0.351304
global_step: 38554, epoch: 164, loss: 0.295235
global_step: 38555, epoch: 164, loss: 0.289006
global_step: 38556, epoch: 164, loss: 0.412123
global_step: 38557, epoch: 164, loss: 0.316048
global_step: 38558, epoch: 164, loss: 0.382555
global_step: 38559, epoch: 164, loss: 0.353890
global_step: 38560, epoch: 164, loss: 0.025152
epoch: 164
train	acc: 0.9553	macro: p 0.9539, r 0.9122, f1: 0.9310	micro: p 0.9553, r 0.9553, f1 0.9553	weighted_f1:0.9549
dev	acc: 0.5464	macro: p 0.4335, r 0.3539, f1: 0.3596	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5179
test	acc: 0.5770	macro: p 0.3864, r 0.3503, f1: 0.3526	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5530
global_step: 38561, epoch: 165, loss: 0.402231
global_step: 38562, epoch: 165, loss: 0.390950
global_step: 38563, epoch: 165, loss: 0.370588
global_step: 38564, epoch: 165, loss: 0.390218
global_step: 38565, epoch: 165, loss: 0.334516
global_step: 38566, epoch: 165, loss: 0.323732
global_step: 38567, epoch: 165, loss: 0.218353
global_step: 38568, epoch: 165, loss: 0.223087
global_step: 38569, epoch: 165, loss: 0.282825
global_step: 38570, epoch: 165, loss: 0.244025
global_step: 38571, epoch: 165, loss: 0.268990
global_step: 38572, epoch: 165, loss: 0.273752
global_step: 38573, epoch: 165, loss: 0.269454
global_step: 38574, epoch: 165, loss: 0.320781
global_step: 38575, epoch: 165, loss: 0.293331
global_step: 38576, epoch: 165, loss: 0.208597
global_step: 38577, epoch: 165, loss: 0.319281
global_step: 38578, epoch: 165, loss: 0.287157
global_step: 38579, epoch: 165, loss: 0.298050
global_step: 38580, epoch: 165, loss: 0.263746
global_step: 38581, epoch: 165, loss: 0.327309
global_step: 38582, epoch: 165, loss: 0.324503
global_step: 38583, epoch: 165, loss: 0.337903
global_step: 38584, epoch: 165, loss: 0.267332
global_step: 38585, epoch: 165, loss: 0.338635
global_step: 38586, epoch: 165, loss: 0.293322
global_step: 38587, epoch: 165, loss: 0.244977
global_step: 38588, epoch: 165, loss: 0.311879
global_step: 38589, epoch: 165, loss: 0.344269
global_step: 38590, epoch: 165, loss: 0.355978
global_step: 38591, epoch: 165, loss: 0.282085
global_step: 38592, epoch: 165, loss: 0.248965
global_step: 38593, epoch: 165, loss: 0.320599
global_step: 38594, epoch: 165, loss: 0.272434
global_step: 38595, epoch: 165, loss: 0.299638
global_step: 38596, epoch: 165, loss: 0.253125
global_step: 38597, epoch: 165, loss: 0.339513
global_step: 38598, epoch: 165, loss: 0.258984
global_step: 38599, epoch: 165, loss: 0.275218
global_step: 38600, epoch: 165, loss: 0.223370
epoch: 165
train	acc: 0.9542	macro: p 0.9550, r 0.9119, f1: 0.9314	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9539
dev	acc: 0.5555	macro: p 0.4135, r 0.3456, f1: 0.3547	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5188
test	acc: 0.5946	macro: p 0.4095, r 0.3503, f1: 0.3652	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5630
global_step: 38601, epoch: 166, loss: 0.237023
global_step: 38602, epoch: 166, loss: 0.324187
global_step: 38603, epoch: 166, loss: 0.328430
global_step: 38604, epoch: 166, loss: 0.287686
global_step: 38605, epoch: 166, loss: 0.328101
global_step: 38606, epoch: 166, loss: 0.313820
global_step: 38607, epoch: 166, loss: 0.239034
global_step: 38608, epoch: 166, loss: 0.258754
global_step: 38609, epoch: 166, loss: 0.307511
global_step: 38610, epoch: 166, loss: 0.251855
global_step: 38611, epoch: 166, loss: 0.323513
global_step: 38612, epoch: 166, loss: 0.353075
global_step: 38613, epoch: 166, loss: 0.251006
global_step: 38614, epoch: 166, loss: 0.304201
global_step: 38615, epoch: 166, loss: 0.315100
global_step: 38616, epoch: 166, loss: 0.352859
global_step: 38617, epoch: 166, loss: 0.292974
global_step: 38618, epoch: 166, loss: 0.235287
global_step: 38619, epoch: 166, loss: 0.309043
global_step: 38620, epoch: 166, loss: 0.292415
global_step: 38621, epoch: 166, loss: 0.391747
global_step: 38622, epoch: 166, loss: 0.278050
global_step: 38623, epoch: 166, loss: 0.336824
global_step: 38624, epoch: 166, loss: 0.348874
global_step: 38625, epoch: 166, loss: 0.294531
global_step: 38626, epoch: 166, loss: 0.245938
global_step: 38627, epoch: 166, loss: 0.230664
global_step: 38628, epoch: 166, loss: 0.390812
global_step: 38629, epoch: 166, loss: 0.246872
global_step: 38630, epoch: 166, loss: 0.252755
global_step: 38631, epoch: 166, loss: 0.305649
global_step: 38632, epoch: 166, loss: 0.359915
global_step: 38633, epoch: 166, loss: 0.360726
global_step: 38634, epoch: 166, loss: 0.303839
global_step: 38635, epoch: 166, loss: 0.246982
global_step: 38636, epoch: 166, loss: 0.232012
global_step: 38637, epoch: 166, loss: 0.291529
global_step: 38638, epoch: 166, loss: 0.360058
global_step: 38639, epoch: 166, loss: 0.361142
global_step: 38640, epoch: 166, loss: 0.019112
epoch: 166
train	acc: 0.9550	macro: p 0.9555, r 0.9118, f1: 0.9314	micro: p 0.9550, r 0.9550, f1 0.9550	weighted_f1:0.9546
dev	acc: 0.5500	macro: p 0.3966, r 0.3388, f1: 0.3443	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5138
test	acc: 0.5969	macro: p 0.4021, r 0.3495, f1: 0.3620	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5672
global_step: 38641, epoch: 167, loss: 0.308450
global_step: 38642, epoch: 167, loss: 0.226194
global_step: 38643, epoch: 167, loss: 0.314883
global_step: 38644, epoch: 167, loss: 0.267836
global_step: 38645, epoch: 167, loss: 0.279988
global_step: 38646, epoch: 167, loss: 0.333740
global_step: 38647, epoch: 167, loss: 0.345499
global_step: 38648, epoch: 167, loss: 0.276500
global_step: 38649, epoch: 167, loss: 0.289379
global_step: 38650, epoch: 167, loss: 0.340227
global_step: 38651, epoch: 167, loss: 0.252620
global_step: 38652, epoch: 167, loss: 0.248276
global_step: 38653, epoch: 167, loss: 0.291346
global_step: 38654, epoch: 167, loss: 0.283828
global_step: 38655, epoch: 167, loss: 0.340837
global_step: 38656, epoch: 167, loss: 0.261778
global_step: 38657, epoch: 167, loss: 0.185524
global_step: 38658, epoch: 167, loss: 0.275413
global_step: 38659, epoch: 167, loss: 0.308977
global_step: 38660, epoch: 167, loss: 0.296400
global_step: 38661, epoch: 167, loss: 0.354038
global_step: 38662, epoch: 167, loss: 0.343187
global_step: 38663, epoch: 167, loss: 0.242950
global_step: 38664, epoch: 167, loss: 0.281764
global_step: 38665, epoch: 167, loss: 0.293303
global_step: 38666, epoch: 167, loss: 0.307597
global_step: 38667, epoch: 167, loss: 0.332808
global_step: 38668, epoch: 167, loss: 0.280728
global_step: 38669, epoch: 167, loss: 0.338500
global_step: 38670, epoch: 167, loss: 0.273571
global_step: 38671, epoch: 167, loss: 0.315438
global_step: 38672, epoch: 167, loss: 0.315722
global_step: 38673, epoch: 167, loss: 0.251067
global_step: 38674, epoch: 167, loss: 0.331492
global_step: 38675, epoch: 167, loss: 0.317626
global_step: 38676, epoch: 167, loss: 0.284714
global_step: 38677, epoch: 167, loss: 0.303504
global_step: 38678, epoch: 167, loss: 0.344887
global_step: 38679, epoch: 167, loss: 0.326620
global_step: 38680, epoch: 167, loss: 0.414880
epoch: 167
train	acc: 0.9547	macro: p 0.9531, r 0.9127, f1: 0.9309	micro: p 0.9547, r 0.9547, f1 0.9547	weighted_f1:0.9544
dev	acc: 0.5618	macro: p 0.4041, r 0.3486, f1: 0.3553	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5246
test	acc: 0.5931	macro: p 0.4023, r 0.3480, f1: 0.3592	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5616
global_step: 38681, epoch: 168, loss: 0.273943
global_step: 38682, epoch: 168, loss: 0.300531
global_step: 38683, epoch: 168, loss: 0.385087
global_step: 38684, epoch: 168, loss: 0.289809
global_step: 38685, epoch: 168, loss: 0.271576
global_step: 38686, epoch: 168, loss: 0.318857
global_step: 38687, epoch: 168, loss: 0.273011
global_step: 38688, epoch: 168, loss: 0.319120
global_step: 38689, epoch: 168, loss: 0.267882
global_step: 38690, epoch: 168, loss: 0.273789
global_step: 38691, epoch: 168, loss: 0.295542
global_step: 38692, epoch: 168, loss: 0.322628
global_step: 38693, epoch: 168, loss: 0.296512
global_step: 38694, epoch: 168, loss: 0.271291
global_step: 38695, epoch: 168, loss: 0.303571
global_step: 38696, epoch: 168, loss: 0.261722
global_step: 38697, epoch: 168, loss: 0.261393
global_step: 38698, epoch: 168, loss: 0.232379
global_step: 38699, epoch: 168, loss: 0.297443
global_step: 38700, epoch: 168, loss: 0.273844
global_step: 38701, epoch: 168, loss: 0.326762
global_step: 38702, epoch: 168, loss: 0.241236
global_step: 38703, epoch: 168, loss: 0.335833
global_step: 38704, epoch: 168, loss: 0.275351
global_step: 38705, epoch: 168, loss: 0.330325
global_step: 38706, epoch: 168, loss: 0.300541
global_step: 38707, epoch: 168, loss: 0.360962
global_step: 38708, epoch: 168, loss: 0.284483
global_step: 38709, epoch: 168, loss: 0.244441
global_step: 38710, epoch: 168, loss: 0.304723
global_step: 38711, epoch: 168, loss: 0.379674
global_step: 38712, epoch: 168, loss: 0.317755
global_step: 38713, epoch: 168, loss: 0.305347
global_step: 38714, epoch: 168, loss: 0.261808
global_step: 38715, epoch: 168, loss: 0.338013
global_step: 38716, epoch: 168, loss: 0.304399
global_step: 38717, epoch: 168, loss: 0.254769
global_step: 38718, epoch: 168, loss: 0.314521
global_step: 38719, epoch: 168, loss: 0.305601
global_step: 38720, epoch: 168, loss: 0.271743
epoch: 168
train	acc: 0.9544	macro: p 0.9570, r 0.9086, f1: 0.9301	micro: p 0.9544, r 0.9544, f1 0.9544	weighted_f1:0.9540
dev	acc: 0.5473	macro: p 0.4024, r 0.3447, f1: 0.3507	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5173
test	acc: 0.5927	macro: p 0.3931, r 0.3452, f1: 0.3526	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5651
global_step: 38721, epoch: 169, loss: 0.289830
global_step: 38722, epoch: 169, loss: 0.216878
global_step: 38723, epoch: 169, loss: 0.285686
global_step: 38724, epoch: 169, loss: 0.279588
global_step: 38725, epoch: 169, loss: 0.270824
global_step: 38726, epoch: 169, loss: 0.333875
global_step: 38727, epoch: 169, loss: 0.302711
global_step: 38728, epoch: 169, loss: 0.323979
global_step: 38729, epoch: 169, loss: 0.322973
global_step: 38730, epoch: 169, loss: 0.294893
global_step: 38731, epoch: 169, loss: 0.401579
global_step: 38732, epoch: 169, loss: 0.294267
global_step: 38733, epoch: 169, loss: 0.370150
global_step: 38734, epoch: 169, loss: 0.280771
global_step: 38735, epoch: 169, loss: 0.315583
global_step: 38736, epoch: 169, loss: 0.274606
global_step: 38737, epoch: 169, loss: 0.213315
global_step: 38738, epoch: 169, loss: 0.270908
global_step: 38739, epoch: 169, loss: 0.316674
global_step: 38740, epoch: 169, loss: 0.302103
global_step: 38741, epoch: 169, loss: 0.260452
global_step: 38742, epoch: 169, loss: 0.250231
global_step: 38743, epoch: 169, loss: 0.321750
global_step: 38744, epoch: 169, loss: 0.260505
global_step: 38745, epoch: 169, loss: 0.232428
global_step: 38746, epoch: 169, loss: 0.261789
global_step: 38747, epoch: 169, loss: 0.288894
global_step: 38748, epoch: 169, loss: 0.275010
global_step: 38749, epoch: 169, loss: 0.296068
global_step: 38750, epoch: 169, loss: 0.304516
global_step: 38751, epoch: 169, loss: 0.230391
global_step: 38752, epoch: 169, loss: 0.284350
global_step: 38753, epoch: 169, loss: 0.282993
global_step: 38754, epoch: 169, loss: 0.263793
global_step: 38755, epoch: 169, loss: 0.323777
global_step: 38756, epoch: 169, loss: 0.224949
global_step: 38757, epoch: 169, loss: 0.321271
global_step: 38758, epoch: 169, loss: 0.243394
global_step: 38759, epoch: 169, loss: 0.273353
global_step: 38760, epoch: 169, loss: 0.094355
epoch: 169
train	acc: 0.9537	macro: p 0.9555, r 0.9061, f1: 0.9280	micro: p 0.9537, r 0.9537, f1 0.9537	weighted_f1:0.9533
dev	acc: 0.5528	macro: p 0.4431, r 0.3362, f1: 0.3455	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5123
test	acc: 0.5946	macro: p 0.4024, r 0.3375, f1: 0.3477	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5594
global_step: 38761, epoch: 170, loss: 0.273072
global_step: 38762, epoch: 170, loss: 0.289399
global_step: 38763, epoch: 170, loss: 0.319164
global_step: 38764, epoch: 170, loss: 0.351005
global_step: 38765, epoch: 170, loss: 0.253640
global_step: 38766, epoch: 170, loss: 0.279815
global_step: 38767, epoch: 170, loss: 0.268611
global_step: 38768, epoch: 170, loss: 0.276087
global_step: 38769, epoch: 170, loss: 0.262280
global_step: 38770, epoch: 170, loss: 0.295371
global_step: 38771, epoch: 170, loss: 0.294016
global_step: 38772, epoch: 170, loss: 0.293104
global_step: 38773, epoch: 170, loss: 0.348259
global_step: 38774, epoch: 170, loss: 0.301808
global_step: 38775, epoch: 170, loss: 0.243823
global_step: 38776, epoch: 170, loss: 0.259203
global_step: 38777, epoch: 170, loss: 0.401955
global_step: 38778, epoch: 170, loss: 0.277397
global_step: 38779, epoch: 170, loss: 0.231940
global_step: 38780, epoch: 170, loss: 0.320133
global_step: 38781, epoch: 170, loss: 0.312237
global_step: 38782, epoch: 170, loss: 0.205859
global_step: 38783, epoch: 170, loss: 0.253046
global_step: 38784, epoch: 170, loss: 0.354334
global_step: 38785, epoch: 170, loss: 0.260389
global_step: 38786, epoch: 170, loss: 0.264171
global_step: 38787, epoch: 170, loss: 0.343885
global_step: 38788, epoch: 170, loss: 0.321094
global_step: 38789, epoch: 170, loss: 0.310158
global_step: 38790, epoch: 170, loss: 0.264095
global_step: 38791, epoch: 170, loss: 0.319892
global_step: 38792, epoch: 170, loss: 0.302287
global_step: 38793, epoch: 170, loss: 0.296491
global_step: 38794, epoch: 170, loss: 0.257494
global_step: 38795, epoch: 170, loss: 0.294659
global_step: 38796, epoch: 170, loss: 0.316514
global_step: 38797, epoch: 170, loss: 0.324576
global_step: 38798, epoch: 170, loss: 0.277041
global_step: 38799, epoch: 170, loss: 0.303882
global_step: 38800, epoch: 170, loss: 0.401597
epoch: 170
train	acc: 0.9558	macro: p 0.9543, r 0.9118, f1: 0.9306	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9554
dev	acc: 0.5419	macro: p 0.3891, r 0.3350, f1: 0.3431	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5116
test	acc: 0.5950	macro: p 0.4096, r 0.3489, f1: 0.3593	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5695
global_step: 38801, epoch: 171, loss: 0.282594
global_step: 38802, epoch: 171, loss: 0.308181
global_step: 38803, epoch: 171, loss: 0.351491
global_step: 38804, epoch: 171, loss: 0.217498
global_step: 38805, epoch: 171, loss: 0.294741
global_step: 38806, epoch: 171, loss: 0.253625
global_step: 38807, epoch: 171, loss: 0.280545
global_step: 38808, epoch: 171, loss: 0.279884
global_step: 38809, epoch: 171, loss: 0.362862
global_step: 38810, epoch: 171, loss: 0.255460
global_step: 38811, epoch: 171, loss: 0.372109
global_step: 38812, epoch: 171, loss: 0.293990
global_step: 38813, epoch: 171, loss: 0.306080
global_step: 38814, epoch: 171, loss: 0.248998
global_step: 38815, epoch: 171, loss: 0.250123
global_step: 38816, epoch: 171, loss: 0.277627
global_step: 38817, epoch: 171, loss: 0.275483
global_step: 38818, epoch: 171, loss: 0.209583
global_step: 38819, epoch: 171, loss: 0.282946
global_step: 38820, epoch: 171, loss: 0.302573
global_step: 38821, epoch: 171, loss: 0.294835
global_step: 38822, epoch: 171, loss: 0.324755
global_step: 38823, epoch: 171, loss: 0.186247
global_step: 38824, epoch: 171, loss: 0.258742
global_step: 38825, epoch: 171, loss: 0.315681
global_step: 38826, epoch: 171, loss: 0.275088
global_step: 38827, epoch: 171, loss: 0.273559
global_step: 38828, epoch: 171, loss: 0.307420
global_step: 38829, epoch: 171, loss: 0.284999
global_step: 38830, epoch: 171, loss: 0.364012
global_step: 38831, epoch: 171, loss: 0.371807
global_step: 38832, epoch: 171, loss: 0.315144
global_step: 38833, epoch: 171, loss: 0.353953
global_step: 38834, epoch: 171, loss: 0.266094
global_step: 38835, epoch: 171, loss: 0.292484
global_step: 38836, epoch: 171, loss: 0.264887
global_step: 38837, epoch: 171, loss: 0.287525
global_step: 38838, epoch: 171, loss: 0.258979
global_step: 38839, epoch: 171, loss: 0.217688
global_step: 38840, epoch: 171, loss: 0.177092
epoch: 171
train	acc: 0.9560	macro: p 0.9582, r 0.9125, f1: 0.9331	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9556
dev	acc: 0.5482	macro: p 0.4689, r 0.3330, f1: 0.3425	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5068
test	acc: 0.5931	macro: p 0.4133, r 0.3362, f1: 0.3463	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5586
global_step: 38841, epoch: 172, loss: 0.249029
global_step: 38842, epoch: 172, loss: 0.266147
global_step: 38843, epoch: 172, loss: 0.279019
global_step: 38844, epoch: 172, loss: 0.311573
global_step: 38845, epoch: 172, loss: 0.272912
global_step: 38846, epoch: 172, loss: 0.400844
global_step: 38847, epoch: 172, loss: 0.394658
global_step: 38848, epoch: 172, loss: 0.299145
global_step: 38849, epoch: 172, loss: 0.320178
global_step: 38850, epoch: 172, loss: 0.336560
global_step: 38851, epoch: 172, loss: 0.269831
global_step: 38852, epoch: 172, loss: 0.283098
global_step: 38853, epoch: 172, loss: 0.242658
global_step: 38854, epoch: 172, loss: 0.348744
global_step: 38855, epoch: 172, loss: 0.223770
global_step: 38856, epoch: 172, loss: 0.264695
global_step: 38857, epoch: 172, loss: 0.317377
global_step: 38858, epoch: 172, loss: 0.242342
global_step: 38859, epoch: 172, loss: 0.302801
global_step: 38860, epoch: 172, loss: 0.239336
global_step: 38861, epoch: 172, loss: 0.278448
global_step: 38862, epoch: 172, loss: 0.248684
global_step: 38863, epoch: 172, loss: 0.298086
global_step: 38864, epoch: 172, loss: 0.308943
global_step: 38865, epoch: 172, loss: 0.224958
global_step: 38866, epoch: 172, loss: 0.346380
global_step: 38867, epoch: 172, loss: 0.206059
global_step: 38868, epoch: 172, loss: 0.253564
global_step: 38869, epoch: 172, loss: 0.317625
global_step: 38870, epoch: 172, loss: 0.296318
global_step: 38871, epoch: 172, loss: 0.229553
global_step: 38872, epoch: 172, loss: 0.264490
global_step: 38873, epoch: 172, loss: 0.348978
global_step: 38874, epoch: 172, loss: 0.286531
global_step: 38875, epoch: 172, loss: 0.307552
global_step: 38876, epoch: 172, loss: 0.267391
global_step: 38877, epoch: 172, loss: 0.307808
global_step: 38878, epoch: 172, loss: 0.279983
global_step: 38879, epoch: 172, loss: 0.250145
global_step: 38880, epoch: 172, loss: 0.196066
epoch: 172
train	acc: 0.9533	macro: p 0.9538, r 0.9053, f1: 0.9270	micro: p 0.9533, r 0.9533, f1 0.9533	weighted_f1:0.9528
dev	acc: 0.5446	macro: p 0.4177, r 0.3310, f1: 0.3325	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5028
test	acc: 0.5808	macro: p 0.3877, r 0.3301, f1: 0.3351	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5449
global_step: 38881, epoch: 173, loss: 0.340600
global_step: 38882, epoch: 173, loss: 0.347037
global_step: 38883, epoch: 173, loss: 0.203070
global_step: 38884, epoch: 173, loss: 0.292306
global_step: 38885, epoch: 173, loss: 0.184153
global_step: 38886, epoch: 173, loss: 0.235805
global_step: 38887, epoch: 173, loss: 0.290204
global_step: 38888, epoch: 173, loss: 0.303645
global_step: 38889, epoch: 173, loss: 0.270889
global_step: 38890, epoch: 173, loss: 0.307653
global_step: 38891, epoch: 173, loss: 0.285395
global_step: 38892, epoch: 173, loss: 0.278916
global_step: 38893, epoch: 173, loss: 0.253633
global_step: 38894, epoch: 173, loss: 0.358074
global_step: 38895, epoch: 173, loss: 0.324489
global_step: 38896, epoch: 173, loss: 0.268388
global_step: 38897, epoch: 173, loss: 0.300630
global_step: 38898, epoch: 173, loss: 0.257788
global_step: 38899, epoch: 173, loss: 0.270334
global_step: 38900, epoch: 173, loss: 0.237216
global_step: 38901, epoch: 173, loss: 0.235386
global_step: 38902, epoch: 173, loss: 0.252508
global_step: 38903, epoch: 173, loss: 0.267238
global_step: 38904, epoch: 173, loss: 0.224611
global_step: 38905, epoch: 173, loss: 0.235129
global_step: 38906, epoch: 173, loss: 0.306908
global_step: 38907, epoch: 173, loss: 0.352737
global_step: 38908, epoch: 173, loss: 0.228825
global_step: 38909, epoch: 173, loss: 0.281121
global_step: 38910, epoch: 173, loss: 0.306470
global_step: 38911, epoch: 173, loss: 0.260360
global_step: 38912, epoch: 173, loss: 0.269971
global_step: 38913, epoch: 173, loss: 0.341545
global_step: 38914, epoch: 173, loss: 0.284497
global_step: 38915, epoch: 173, loss: 0.317371
global_step: 38916, epoch: 173, loss: 0.223910
global_step: 38917, epoch: 173, loss: 0.273199
global_step: 38918, epoch: 173, loss: 0.345323
global_step: 38919, epoch: 173, loss: 0.213628
global_step: 38920, epoch: 173, loss: 0.204302
epoch: 173
train	acc: 0.9573	macro: p 0.9568, r 0.9174, f1: 0.9354	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9570
dev	acc: 0.5537	macro: p 0.4287, r 0.3396, f1: 0.3523	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5154
test	acc: 0.5958	macro: p 0.4124, r 0.3386, f1: 0.3512	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5628
global_step: 38921, epoch: 174, loss: 0.262119
global_step: 38922, epoch: 174, loss: 0.274314
global_step: 38923, epoch: 174, loss: 0.230142
global_step: 38924, epoch: 174, loss: 0.220494
global_step: 38925, epoch: 174, loss: 0.341458
global_step: 38926, epoch: 174, loss: 0.305577
global_step: 38927, epoch: 174, loss: 0.282905
global_step: 38928, epoch: 174, loss: 0.349909
global_step: 38929, epoch: 174, loss: 0.307999
global_step: 38930, epoch: 174, loss: 0.187420
global_step: 38931, epoch: 174, loss: 0.282783
global_step: 38932, epoch: 174, loss: 0.331983
global_step: 38933, epoch: 174, loss: 0.243226
global_step: 38934, epoch: 174, loss: 0.312720
global_step: 38935, epoch: 174, loss: 0.267843
global_step: 38936, epoch: 174, loss: 0.256276
global_step: 38937, epoch: 174, loss: 0.342365
global_step: 38938, epoch: 174, loss: 0.338062
global_step: 38939, epoch: 174, loss: 0.245190
global_step: 38940, epoch: 174, loss: 0.301244
global_step: 38941, epoch: 174, loss: 0.220780
global_step: 38942, epoch: 174, loss: 0.282506
global_step: 38943, epoch: 174, loss: 0.259615
global_step: 38944, epoch: 174, loss: 0.321782
global_step: 38945, epoch: 174, loss: 0.227293
global_step: 38946, epoch: 174, loss: 0.252393
global_step: 38947, epoch: 174, loss: 0.265532
global_step: 38948, epoch: 174, loss: 0.340776
global_step: 38949, epoch: 174, loss: 0.287420
global_step: 38950, epoch: 174, loss: 0.294023
global_step: 38951, epoch: 174, loss: 0.299596
global_step: 38952, epoch: 174, loss: 0.287577
global_step: 38953, epoch: 174, loss: 0.245354
global_step: 38954, epoch: 174, loss: 0.357049
global_step: 38955, epoch: 174, loss: 0.313670
global_step: 38956, epoch: 174, loss: 0.242048
global_step: 38957, epoch: 174, loss: 0.278292
global_step: 38958, epoch: 174, loss: 0.250142
global_step: 38959, epoch: 174, loss: 0.261201
global_step: 38960, epoch: 174, loss: 0.071520
epoch: 174
train	acc: 0.9574	macro: p 0.9551, r 0.9195, f1: 0.9355	micro: p 0.9574, r 0.9574, f1 0.9574	weighted_f1:0.9572
dev	acc: 0.5528	macro: p 0.4025, r 0.3522, f1: 0.3588	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5228
test	acc: 0.5828	macro: p 0.3736, r 0.3394, f1: 0.3442	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5558
global_step: 38961, epoch: 175, loss: 0.246799
global_step: 38962, epoch: 175, loss: 0.226066
global_step: 38963, epoch: 175, loss: 0.289263
global_step: 38964, epoch: 175, loss: 0.330888
global_step: 38965, epoch: 175, loss: 0.260242
global_step: 38966, epoch: 175, loss: 0.295180
global_step: 38967, epoch: 175, loss: 0.312409
global_step: 38968, epoch: 175, loss: 0.219143
global_step: 38969, epoch: 175, loss: 0.386232
global_step: 38970, epoch: 175, loss: 0.223027
global_step: 38971, epoch: 175, loss: 0.305215
global_step: 38972, epoch: 175, loss: 0.215167
global_step: 38973, epoch: 175, loss: 0.265159
global_step: 38974, epoch: 175, loss: 0.296296
global_step: 38975, epoch: 175, loss: 0.233956
global_step: 38976, epoch: 175, loss: 0.245834
global_step: 38977, epoch: 175, loss: 0.259514
global_step: 38978, epoch: 175, loss: 0.272529
global_step: 38979, epoch: 175, loss: 0.274776
global_step: 38980, epoch: 175, loss: 0.238973
global_step: 38981, epoch: 175, loss: 0.326728
global_step: 38982, epoch: 175, loss: 0.258289
global_step: 38983, epoch: 175, loss: 0.219956
global_step: 38984, epoch: 175, loss: 0.270252
global_step: 38985, epoch: 175, loss: 0.254872
global_step: 38986, epoch: 175, loss: 0.248103
global_step: 38987, epoch: 175, loss: 0.307433
global_step: 38988, epoch: 175, loss: 0.274970
global_step: 38989, epoch: 175, loss: 0.278490
global_step: 38990, epoch: 175, loss: 0.226871
global_step: 38991, epoch: 175, loss: 0.309819
global_step: 38992, epoch: 175, loss: 0.319932
global_step: 38993, epoch: 175, loss: 0.299816
global_step: 38994, epoch: 175, loss: 0.267463
global_step: 38995, epoch: 175, loss: 0.273453
global_step: 38996, epoch: 175, loss: 0.353043
global_step: 38997, epoch: 175, loss: 0.297706
global_step: 38998, epoch: 175, loss: 0.243031
global_step: 38999, epoch: 175, loss: 0.386520
global_step: 39000, epoch: 175, loss: 0.368537
epoch: 175
train	acc: 0.9588	macro: p 0.9558, r 0.9225, f1: 0.9379	micro: p 0.9588, r 0.9588, f1 0.9588	weighted_f1:0.9586
dev	acc: 0.5528	macro: p 0.4067, r 0.3588, f1: 0.3699	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5254
test	acc: 0.5789	macro: p 0.3916, r 0.3519, f1: 0.3636	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5577
global_step: 39001, epoch: 176, loss: 0.337312
global_step: 39002, epoch: 176, loss: 0.320149
global_step: 39003, epoch: 176, loss: 0.249078
global_step: 39004, epoch: 176, loss: 0.317597
global_step: 39005, epoch: 176, loss: 0.279441
global_step: 39006, epoch: 176, loss: 0.249502
global_step: 39007, epoch: 176, loss: 0.372044
global_step: 39008, epoch: 176, loss: 0.206368
global_step: 39009, epoch: 176, loss: 0.210043
global_step: 39010, epoch: 176, loss: 0.251555
global_step: 39011, epoch: 176, loss: 0.212236
global_step: 39012, epoch: 176, loss: 0.298106
global_step: 39013, epoch: 176, loss: 0.267005
global_step: 39014, epoch: 176, loss: 0.221029
global_step: 39015, epoch: 176, loss: 0.269197
global_step: 39016, epoch: 176, loss: 0.249898
global_step: 39017, epoch: 176, loss: 0.258457
global_step: 39018, epoch: 176, loss: 0.284258
global_step: 39019, epoch: 176, loss: 0.255130
global_step: 39020, epoch: 176, loss: 0.233468
global_step: 39021, epoch: 176, loss: 0.382699
global_step: 39022, epoch: 176, loss: 0.287295
global_step: 39023, epoch: 176, loss: 0.288508
global_step: 39024, epoch: 176, loss: 0.318404
global_step: 39025, epoch: 176, loss: 0.279170
global_step: 39026, epoch: 176, loss: 0.301701
global_step: 39027, epoch: 176, loss: 0.315759
global_step: 39028, epoch: 176, loss: 0.284308
global_step: 39029, epoch: 176, loss: 0.262388
global_step: 39030, epoch: 176, loss: 0.247722
global_step: 39031, epoch: 176, loss: 0.272274
global_step: 39032, epoch: 176, loss: 0.317571
global_step: 39033, epoch: 176, loss: 0.270281
global_step: 39034, epoch: 176, loss: 0.216720
global_step: 39035, epoch: 176, loss: 0.303141
global_step: 39036, epoch: 176, loss: 0.322614
global_step: 39037, epoch: 176, loss: 0.325909
global_step: 39038, epoch: 176, loss: 0.260746
global_step: 39039, epoch: 176, loss: 0.343326
global_step: 39040, epoch: 176, loss: 0.342550
epoch: 176
train	acc: 0.9595	macro: p 0.9602, r 0.9270, f1: 0.9426	micro: p 0.9595, r 0.9595, f1 0.9595	weighted_f1:0.9593
dev	acc: 0.5473	macro: p 0.3975, r 0.3434, f1: 0.3504	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5149
test	acc: 0.5805	macro: p 0.3865, r 0.3406, f1: 0.3499	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5538
global_step: 39041, epoch: 177, loss: 0.270409
global_step: 39042, epoch: 177, loss: 0.254190
global_step: 39043, epoch: 177, loss: 0.205022
global_step: 39044, epoch: 177, loss: 0.234616
global_step: 39045, epoch: 177, loss: 0.286963
global_step: 39046, epoch: 177, loss: 0.201175
global_step: 39047, epoch: 177, loss: 0.252504
global_step: 39048, epoch: 177, loss: 0.321301
global_step: 39049, epoch: 177, loss: 0.251442
global_step: 39050, epoch: 177, loss: 0.215802
global_step: 39051, epoch: 177, loss: 0.289257
global_step: 39052, epoch: 177, loss: 0.259633
global_step: 39053, epoch: 177, loss: 0.275764
global_step: 39054, epoch: 177, loss: 0.209672
global_step: 39055, epoch: 177, loss: 0.249243
global_step: 39056, epoch: 177, loss: 0.255992
global_step: 39057, epoch: 177, loss: 0.268062
global_step: 39058, epoch: 177, loss: 0.312523
global_step: 39059, epoch: 177, loss: 0.265239
global_step: 39060, epoch: 177, loss: 0.277402
global_step: 39061, epoch: 177, loss: 0.223743
global_step: 39062, epoch: 177, loss: 0.297063
global_step: 39063, epoch: 177, loss: 0.284334
global_step: 39064, epoch: 177, loss: 0.289778
global_step: 39065, epoch: 177, loss: 0.268441
global_step: 39066, epoch: 177, loss: 0.274219
global_step: 39067, epoch: 177, loss: 0.278309
global_step: 39068, epoch: 177, loss: 0.313153
global_step: 39069, epoch: 177, loss: 0.291122
global_step: 39070, epoch: 177, loss: 0.249907
global_step: 39071, epoch: 177, loss: 0.338309
global_step: 39072, epoch: 177, loss: 0.292239
global_step: 39073, epoch: 177, loss: 0.325665
global_step: 39074, epoch: 177, loss: 0.253524
global_step: 39075, epoch: 177, loss: 0.266765
global_step: 39076, epoch: 177, loss: 0.289623
global_step: 39077, epoch: 177, loss: 0.225527
global_step: 39078, epoch: 177, loss: 0.312893
global_step: 39079, epoch: 177, loss: 0.294726
global_step: 39080, epoch: 177, loss: 0.016308
epoch: 177
train	acc: 0.9583	macro: p 0.9579, r 0.9185, f1: 0.9365	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9580
dev	acc: 0.5528	macro: p 0.4053, r 0.3399, f1: 0.3505	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5187
test	acc: 0.5931	macro: p 0.4267, r 0.3456, f1: 0.3609	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5645
global_step: 39081, epoch: 178, loss: 0.236643
global_step: 39082, epoch: 178, loss: 0.284676
global_step: 39083, epoch: 178, loss: 0.287887
global_step: 39084, epoch: 178, loss: 0.260619
global_step: 39085, epoch: 178, loss: 0.274379
global_step: 39086, epoch: 178, loss: 0.301544
global_step: 39087, epoch: 178, loss: 0.235051
global_step: 39088, epoch: 178, loss: 0.244666
global_step: 39089, epoch: 178, loss: 0.215984
global_step: 39090, epoch: 178, loss: 0.194302
global_step: 39091, epoch: 178, loss: 0.249421
global_step: 39092, epoch: 178, loss: 0.316776
global_step: 39093, epoch: 178, loss: 0.247410
global_step: 39094, epoch: 178, loss: 0.229420
global_step: 39095, epoch: 178, loss: 0.246669
global_step: 39096, epoch: 178, loss: 0.297836
global_step: 39097, epoch: 178, loss: 0.295112
global_step: 39098, epoch: 178, loss: 0.265280
global_step: 39099, epoch: 178, loss: 0.222328
global_step: 39100, epoch: 178, loss: 0.282922
global_step: 39101, epoch: 178, loss: 0.262255
global_step: 39102, epoch: 178, loss: 0.314206
global_step: 39103, epoch: 178, loss: 0.337617
global_step: 39104, epoch: 178, loss: 0.299244
global_step: 39105, epoch: 178, loss: 0.212862
global_step: 39106, epoch: 178, loss: 0.317453
global_step: 39107, epoch: 178, loss: 0.289695
global_step: 39108, epoch: 178, loss: 0.266294
global_step: 39109, epoch: 178, loss: 0.309562
global_step: 39110, epoch: 178, loss: 0.293880
global_step: 39111, epoch: 178, loss: 0.309518
global_step: 39112, epoch: 178, loss: 0.258354
global_step: 39113, epoch: 178, loss: 0.239605
global_step: 39114, epoch: 178, loss: 0.223592
global_step: 39115, epoch: 178, loss: 0.303911
global_step: 39116, epoch: 178, loss: 0.236512
global_step: 39117, epoch: 178, loss: 0.257377
global_step: 39118, epoch: 178, loss: 0.315322
global_step: 39119, epoch: 178, loss: 0.310161
global_step: 39120, epoch: 178, loss: 0.026097
epoch: 178
train	acc: 0.9587	macro: p 0.9591, r 0.9227, f1: 0.9394	micro: p 0.9587, r 0.9587, f1 0.9587	weighted_f1:0.9585
dev	acc: 0.5473	macro: p 0.4111, r 0.3451, f1: 0.3523	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5165
test	acc: 0.5889	macro: p 0.3864, r 0.3473, f1: 0.3546	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5638
global_step: 39121, epoch: 179, loss: 0.308668
global_step: 39122, epoch: 179, loss: 0.242687
global_step: 39123, epoch: 179, loss: 0.255924
global_step: 39124, epoch: 179, loss: 0.246564
global_step: 39125, epoch: 179, loss: 0.219896
global_step: 39126, epoch: 179, loss: 0.344721
global_step: 39127, epoch: 179, loss: 0.311908
global_step: 39128, epoch: 179, loss: 0.229787
global_step: 39129, epoch: 179, loss: 0.270987
global_step: 39130, epoch: 179, loss: 0.232014
global_step: 39131, epoch: 179, loss: 0.325576
global_step: 39132, epoch: 179, loss: 0.286774
global_step: 39133, epoch: 179, loss: 0.338139
global_step: 39134, epoch: 179, loss: 0.249937
global_step: 39135, epoch: 179, loss: 0.216258
global_step: 39136, epoch: 179, loss: 0.231447
global_step: 39137, epoch: 179, loss: 0.242122
global_step: 39138, epoch: 179, loss: 0.292145
global_step: 39139, epoch: 179, loss: 0.216472
global_step: 39140, epoch: 179, loss: 0.360475
global_step: 39141, epoch: 179, loss: 0.314414
global_step: 39142, epoch: 179, loss: 0.235194
global_step: 39143, epoch: 179, loss: 0.312142
global_step: 39144, epoch: 179, loss: 0.292351
global_step: 39145, epoch: 179, loss: 0.240799
global_step: 39146, epoch: 179, loss: 0.299434
global_step: 39147, epoch: 179, loss: 0.242812
global_step: 39148, epoch: 179, loss: 0.284089
global_step: 39149, epoch: 179, loss: 0.272436
global_step: 39150, epoch: 179, loss: 0.206167
global_step: 39151, epoch: 179, loss: 0.325948
global_step: 39152, epoch: 179, loss: 0.275402
global_step: 39153, epoch: 179, loss: 0.290253
global_step: 39154, epoch: 179, loss: 0.242435
global_step: 39155, epoch: 179, loss: 0.231922
global_step: 39156, epoch: 179, loss: 0.338446
global_step: 39157, epoch: 179, loss: 0.294177
global_step: 39158, epoch: 179, loss: 0.294287
global_step: 39159, epoch: 179, loss: 0.310922
global_step: 39160, epoch: 179, loss: 0.111753
epoch: 179
train	acc: 0.9527	macro: p 0.9626, r 0.9152, f1: 0.9375	micro: p 0.9527, r 0.9527, f1 0.9527	weighted_f1:0.9524
dev	acc: 0.5464	macro: p 0.4378, r 0.3251, f1: 0.3427	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5030
test	acc: 0.5912	macro: p 0.4359, r 0.3346, f1: 0.3587	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5530
global_step: 39161, epoch: 180, loss: 0.187300
global_step: 39162, epoch: 180, loss: 0.277091
global_step: 39163, epoch: 180, loss: 0.318530
global_step: 39164, epoch: 180, loss: 0.283126
global_step: 39165, epoch: 180, loss: 0.266864
global_step: 39166, epoch: 180, loss: 0.210775
global_step: 39167, epoch: 180, loss: 0.261852
global_step: 39168, epoch: 180, loss: 0.204223
global_step: 39169, epoch: 180, loss: 0.251820
global_step: 39170, epoch: 180, loss: 0.241070
global_step: 39171, epoch: 180, loss: 0.226224
global_step: 39172, epoch: 180, loss: 0.231408
global_step: 39173, epoch: 180, loss: 0.249091
global_step: 39174, epoch: 180, loss: 0.285741
global_step: 39175, epoch: 180, loss: 0.290427
global_step: 39176, epoch: 180, loss: 0.275970
global_step: 39177, epoch: 180, loss: 0.233784
global_step: 39178, epoch: 180, loss: 0.278625
global_step: 39179, epoch: 180, loss: 0.288918
global_step: 39180, epoch: 180, loss: 0.221073
global_step: 39181, epoch: 180, loss: 0.267362
global_step: 39182, epoch: 180, loss: 0.313600
global_step: 39183, epoch: 180, loss: 0.328907
global_step: 39184, epoch: 180, loss: 0.313402
global_step: 39185, epoch: 180, loss: 0.298027
global_step: 39186, epoch: 180, loss: 0.233874
global_step: 39187, epoch: 180, loss: 0.285408
global_step: 39188, epoch: 180, loss: 0.215751
global_step: 39189, epoch: 180, loss: 0.276230
global_step: 39190, epoch: 180, loss: 0.301207
global_step: 39191, epoch: 180, loss: 0.270131
global_step: 39192, epoch: 180, loss: 0.306302
global_step: 39193, epoch: 180, loss: 0.331140
global_step: 39194, epoch: 180, loss: 0.237117
global_step: 39195, epoch: 180, loss: 0.266856
global_step: 39196, epoch: 180, loss: 0.269213
global_step: 39197, epoch: 180, loss: 0.283810
global_step: 39198, epoch: 180, loss: 0.278268
global_step: 39199, epoch: 180, loss: 0.255385
global_step: 39200, epoch: 180, loss: 0.400608
epoch: 180
train	acc: 0.9583	macro: p 0.9565, r 0.9156, f1: 0.9336	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9579
dev	acc: 0.5528	macro: p 0.4018, r 0.3536, f1: 0.3618	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5290
test	acc: 0.5916	macro: p 0.4120, r 0.3607, f1: 0.3742	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5719
global_step: 39201, epoch: 181, loss: 0.284952
global_step: 39202, epoch: 181, loss: 0.230983
global_step: 39203, epoch: 181, loss: 0.318242
global_step: 39204, epoch: 181, loss: 0.257778
global_step: 39205, epoch: 181, loss: 0.295576
global_step: 39206, epoch: 181, loss: 0.212299
global_step: 39207, epoch: 181, loss: 0.239826
global_step: 39208, epoch: 181, loss: 0.252193
global_step: 39209, epoch: 181, loss: 0.266551
global_step: 39210, epoch: 181, loss: 0.226067
global_step: 39211, epoch: 181, loss: 0.252630
global_step: 39212, epoch: 181, loss: 0.274419
global_step: 39213, epoch: 181, loss: 0.320452
global_step: 39214, epoch: 181, loss: 0.229309
global_step: 39215, epoch: 181, loss: 0.259612
global_step: 39216, epoch: 181, loss: 0.274064
global_step: 39217, epoch: 181, loss: 0.265764
global_step: 39218, epoch: 181, loss: 0.291792
global_step: 39219, epoch: 181, loss: 0.359986
global_step: 39220, epoch: 181, loss: 0.230156
global_step: 39221, epoch: 181, loss: 0.310672
global_step: 39222, epoch: 181, loss: 0.295175
global_step: 39223, epoch: 181, loss: 0.252028
global_step: 39224, epoch: 181, loss: 0.249043
global_step: 39225, epoch: 181, loss: 0.335283
global_step: 39226, epoch: 181, loss: 0.253028
global_step: 39227, epoch: 181, loss: 0.250651
global_step: 39228, epoch: 181, loss: 0.226670
global_step: 39229, epoch: 181, loss: 0.278672
global_step: 39230, epoch: 181, loss: 0.323540
global_step: 39231, epoch: 181, loss: 0.293087
global_step: 39232, epoch: 181, loss: 0.281051
global_step: 39233, epoch: 181, loss: 0.262641
global_step: 39234, epoch: 181, loss: 0.280844
global_step: 39235, epoch: 181, loss: 0.298372
global_step: 39236, epoch: 181, loss: 0.252902
global_step: 39237, epoch: 181, loss: 0.335054
global_step: 39238, epoch: 181, loss: 0.279781
global_step: 39239, epoch: 181, loss: 0.276205
global_step: 39240, epoch: 181, loss: 0.383677
epoch: 181
train	acc: 0.9609	macro: p 0.9574, r 0.9285, f1: 0.9415	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9607
dev	acc: 0.5455	macro: p 0.4042, r 0.3687, f1: 0.3681	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5217
test	acc: 0.5728	macro: p 0.3706, r 0.3545, f1: 0.3552	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5534
global_step: 39241, epoch: 182, loss: 0.231631
global_step: 39242, epoch: 182, loss: 0.271071
global_step: 39243, epoch: 182, loss: 0.312351
global_step: 39244, epoch: 182, loss: 0.347188
global_step: 39245, epoch: 182, loss: 0.239992
global_step: 39246, epoch: 182, loss: 0.252191
global_step: 39247, epoch: 182, loss: 0.284844
global_step: 39248, epoch: 182, loss: 0.277190
global_step: 39249, epoch: 182, loss: 0.291457
global_step: 39250, epoch: 182, loss: 0.263230
global_step: 39251, epoch: 182, loss: 0.270519
global_step: 39252, epoch: 182, loss: 0.185684
global_step: 39253, epoch: 182, loss: 0.304537
global_step: 39254, epoch: 182, loss: 0.205127
global_step: 39255, epoch: 182, loss: 0.251892
global_step: 39256, epoch: 182, loss: 0.259172
global_step: 39257, epoch: 182, loss: 0.220133
global_step: 39258, epoch: 182, loss: 0.199733
global_step: 39259, epoch: 182, loss: 0.254520
global_step: 39260, epoch: 182, loss: 0.272675
global_step: 39261, epoch: 182, loss: 0.310435
global_step: 39262, epoch: 182, loss: 0.269522
global_step: 39263, epoch: 182, loss: 0.291196
global_step: 39264, epoch: 182, loss: 0.241939
global_step: 39265, epoch: 182, loss: 0.307348
global_step: 39266, epoch: 182, loss: 0.362915
global_step: 39267, epoch: 182, loss: 0.262686
global_step: 39268, epoch: 182, loss: 0.346907
global_step: 39269, epoch: 182, loss: 0.283697
global_step: 39270, epoch: 182, loss: 0.267317
global_step: 39271, epoch: 182, loss: 0.217782
global_step: 39272, epoch: 182, loss: 0.248820
global_step: 39273, epoch: 182, loss: 0.349127
global_step: 39274, epoch: 182, loss: 0.294663
global_step: 39275, epoch: 182, loss: 0.263352
global_step: 39276, epoch: 182, loss: 0.249181
global_step: 39277, epoch: 182, loss: 0.325860
global_step: 39278, epoch: 182, loss: 0.265681
global_step: 39279, epoch: 182, loss: 0.281469
global_step: 39280, epoch: 182, loss: 0.217467
epoch: 182
train	acc: 0.9612	macro: p 0.9626, r 0.9288, f1: 0.9445	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9610
dev	acc: 0.5528	macro: p 0.4023, r 0.3459, f1: 0.3548	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5219
test	acc: 0.5923	macro: p 0.4079, r 0.3546, f1: 0.3685	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5660
global_step: 39281, epoch: 183, loss: 0.290684
global_step: 39282, epoch: 183, loss: 0.324768
global_step: 39283, epoch: 183, loss: 0.252167
global_step: 39284, epoch: 183, loss: 0.208248
global_step: 39285, epoch: 183, loss: 0.251009
global_step: 39286, epoch: 183, loss: 0.188428
global_step: 39287, epoch: 183, loss: 0.350781
global_step: 39288, epoch: 183, loss: 0.276549
global_step: 39289, epoch: 183, loss: 0.245624
global_step: 39290, epoch: 183, loss: 0.218426
global_step: 39291, epoch: 183, loss: 0.219952
global_step: 39292, epoch: 183, loss: 0.266199
global_step: 39293, epoch: 183, loss: 0.227666
global_step: 39294, epoch: 183, loss: 0.249716
global_step: 39295, epoch: 183, loss: 0.273804
global_step: 39296, epoch: 183, loss: 0.253403
global_step: 39297, epoch: 183, loss: 0.289148
global_step: 39298, epoch: 183, loss: 0.260949
global_step: 39299, epoch: 183, loss: 0.240478
global_step: 39300, epoch: 183, loss: 0.322257
global_step: 39301, epoch: 183, loss: 0.283305
global_step: 39302, epoch: 183, loss: 0.277331
global_step: 39303, epoch: 183, loss: 0.271661
global_step: 39304, epoch: 183, loss: 0.273110
global_step: 39305, epoch: 183, loss: 0.250815
global_step: 39306, epoch: 183, loss: 0.207435
global_step: 39307, epoch: 183, loss: 0.347843
global_step: 39308, epoch: 183, loss: 0.298414
global_step: 39309, epoch: 183, loss: 0.271861
global_step: 39310, epoch: 183, loss: 0.278811
global_step: 39311, epoch: 183, loss: 0.239955
global_step: 39312, epoch: 183, loss: 0.228369
global_step: 39313, epoch: 183, loss: 0.275352
global_step: 39314, epoch: 183, loss: 0.252999
global_step: 39315, epoch: 183, loss: 0.277720
global_step: 39316, epoch: 183, loss: 0.268956
global_step: 39317, epoch: 183, loss: 0.214516
global_step: 39318, epoch: 183, loss: 0.250781
global_step: 39319, epoch: 183, loss: 0.263900
global_step: 39320, epoch: 183, loss: 0.097915
epoch: 183
train	acc: 0.9578	macro: p 0.9610, r 0.9176, f1: 0.9375	micro: p 0.9578, r 0.9578, f1 0.9578	weighted_f1:0.9574
dev	acc: 0.5455	macro: p 0.4294, r 0.3285, f1: 0.3364	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5036
test	acc: 0.5954	macro: p 0.4123, r 0.3344, f1: 0.3441	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5577
global_step: 39321, epoch: 184, loss: 0.286766
global_step: 39322, epoch: 184, loss: 0.267710
global_step: 39323, epoch: 184, loss: 0.285048
global_step: 39324, epoch: 184, loss: 0.274961
global_step: 39325, epoch: 184, loss: 0.221824
global_step: 39326, epoch: 184, loss: 0.260048
global_step: 39327, epoch: 184, loss: 0.276176
global_step: 39328, epoch: 184, loss: 0.261096
global_step: 39329, epoch: 184, loss: 0.253402
global_step: 39330, epoch: 184, loss: 0.276444
global_step: 39331, epoch: 184, loss: 0.221340
global_step: 39332, epoch: 184, loss: 0.281722
global_step: 39333, epoch: 184, loss: 0.248096
global_step: 39334, epoch: 184, loss: 0.239572
global_step: 39335, epoch: 184, loss: 0.193050
global_step: 39336, epoch: 184, loss: 0.282097
global_step: 39337, epoch: 184, loss: 0.270703
global_step: 39338, epoch: 184, loss: 0.285365
global_step: 39339, epoch: 184, loss: 0.189820
global_step: 39340, epoch: 184, loss: 0.267788
global_step: 39341, epoch: 184, loss: 0.218517
global_step: 39342, epoch: 184, loss: 0.231799
global_step: 39343, epoch: 184, loss: 0.244516
global_step: 39344, epoch: 184, loss: 0.299847
global_step: 39345, epoch: 184, loss: 0.378574
global_step: 39346, epoch: 184, loss: 0.319783
global_step: 39347, epoch: 184, loss: 0.261725
global_step: 39348, epoch: 184, loss: 0.276190
global_step: 39349, epoch: 184, loss: 0.260920
global_step: 39350, epoch: 184, loss: 0.229620
global_step: 39351, epoch: 184, loss: 0.262352
global_step: 39352, epoch: 184, loss: 0.258319
global_step: 39353, epoch: 184, loss: 0.279844
global_step: 39354, epoch: 184, loss: 0.218560
global_step: 39355, epoch: 184, loss: 0.285471
global_step: 39356, epoch: 184, loss: 0.238203
global_step: 39357, epoch: 184, loss: 0.268517
global_step: 39358, epoch: 184, loss: 0.303536
global_step: 39359, epoch: 184, loss: 0.343195
global_step: 39360, epoch: 184, loss: 0.283183
epoch: 184
train	acc: 0.9602	macro: p 0.9603, r 0.9290, f1: 0.9432	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9601
dev	acc: 0.5537	macro: p 0.4083, r 0.3578, f1: 0.3604	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5276
test	acc: 0.5762	macro: p 0.3737, r 0.3472, f1: 0.3472	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5536
global_step: 39361, epoch: 185, loss: 0.230687
global_step: 39362, epoch: 185, loss: 0.218202
global_step: 39363, epoch: 185, loss: 0.296694
global_step: 39364, epoch: 185, loss: 0.299541
global_step: 39365, epoch: 185, loss: 0.253679
global_step: 39366, epoch: 185, loss: 0.258099
global_step: 39367, epoch: 185, loss: 0.258873
global_step: 39368, epoch: 185, loss: 0.234626
global_step: 39369, epoch: 185, loss: 0.202446
global_step: 39370, epoch: 185, loss: 0.248388
global_step: 39371, epoch: 185, loss: 0.350973
global_step: 39372, epoch: 185, loss: 0.202335
global_step: 39373, epoch: 185, loss: 0.228777
global_step: 39374, epoch: 185, loss: 0.225079
global_step: 39375, epoch: 185, loss: 0.235390
global_step: 39376, epoch: 185, loss: 0.301908
global_step: 39377, epoch: 185, loss: 0.213504
global_step: 39378, epoch: 185, loss: 0.230693
global_step: 39379, epoch: 185, loss: 0.229229
global_step: 39380, epoch: 185, loss: 0.212159
global_step: 39381, epoch: 185, loss: 0.251157
global_step: 39382, epoch: 185, loss: 0.212841
global_step: 39383, epoch: 185, loss: 0.280148
global_step: 39384, epoch: 185, loss: 0.221440
global_step: 39385, epoch: 185, loss: 0.278975
global_step: 39386, epoch: 185, loss: 0.258071
global_step: 39387, epoch: 185, loss: 0.216621
global_step: 39388, epoch: 185, loss: 0.258688
global_step: 39389, epoch: 185, loss: 0.297060
global_step: 39390, epoch: 185, loss: 0.279952
global_step: 39391, epoch: 185, loss: 0.289424
global_step: 39392, epoch: 185, loss: 0.252319
global_step: 39393, epoch: 185, loss: 0.237639
global_step: 39394, epoch: 185, loss: 0.263403
global_step: 39395, epoch: 185, loss: 0.260484
global_step: 39396, epoch: 185, loss: 0.268659
global_step: 39397, epoch: 185, loss: 0.245912
global_step: 39398, epoch: 185, loss: 0.356141
global_step: 39399, epoch: 185, loss: 0.253547
global_step: 39400, epoch: 185, loss: 0.114151
epoch: 185
train	acc: 0.9605	macro: p 0.9635, r 0.9277, f1: 0.9441	micro: p 0.9605, r 0.9605, f1 0.9605	weighted_f1:0.9603
dev	acc: 0.5546	macro: p 0.4347, r 0.3516, f1: 0.3593	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5229
test	acc: 0.5835	macro: p 0.3878, r 0.3395, f1: 0.3449	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5534
global_step: 39401, epoch: 186, loss: 0.276656
global_step: 39402, epoch: 186, loss: 0.209972
global_step: 39403, epoch: 186, loss: 0.285463
global_step: 39404, epoch: 186, loss: 0.241665
global_step: 39405, epoch: 186, loss: 0.210244
global_step: 39406, epoch: 186, loss: 0.281630
global_step: 39407, epoch: 186, loss: 0.248027
global_step: 39408, epoch: 186, loss: 0.337633
global_step: 39409, epoch: 186, loss: 0.236557
global_step: 39410, epoch: 186, loss: 0.271368
global_step: 39411, epoch: 186, loss: 0.342738
global_step: 39412, epoch: 186, loss: 0.226191
global_step: 39413, epoch: 186, loss: 0.328958
global_step: 39414, epoch: 186, loss: 0.290157
global_step: 39415, epoch: 186, loss: 0.281138
global_step: 39416, epoch: 186, loss: 0.246741
global_step: 39417, epoch: 186, loss: 0.233720
global_step: 39418, epoch: 186, loss: 0.229648
global_step: 39419, epoch: 186, loss: 0.332657
global_step: 39420, epoch: 186, loss: 0.304350
global_step: 39421, epoch: 186, loss: 0.246042
global_step: 39422, epoch: 186, loss: 0.229126
global_step: 39423, epoch: 186, loss: 0.215205
global_step: 39424, epoch: 186, loss: 0.219617
global_step: 39425, epoch: 186, loss: 0.225252
global_step: 39426, epoch: 186, loss: 0.228517
global_step: 39427, epoch: 186, loss: 0.227291
global_step: 39428, epoch: 186, loss: 0.258867
global_step: 39429, epoch: 186, loss: 0.297865
global_step: 39430, epoch: 186, loss: 0.268580
global_step: 39431, epoch: 186, loss: 0.263841
global_step: 39432, epoch: 186, loss: 0.245747
global_step: 39433, epoch: 186, loss: 0.314573
global_step: 39434, epoch: 186, loss: 0.250823
global_step: 39435, epoch: 186, loss: 0.188064
global_step: 39436, epoch: 186, loss: 0.279664
global_step: 39437, epoch: 186, loss: 0.169633
global_step: 39438, epoch: 186, loss: 0.331614
global_step: 39439, epoch: 186, loss: 0.230253
global_step: 39440, epoch: 186, loss: 0.267105
epoch: 186
train	acc: 0.9563	macro: p 0.9599, r 0.9220, f1: 0.9398	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9560
dev	acc: 0.5428	macro: p 0.4042, r 0.3311, f1: 0.3444	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5041
test	acc: 0.5904	macro: p 0.4196, r 0.3423, f1: 0.3608	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5566
global_step: 39441, epoch: 187, loss: 0.255250
global_step: 39442, epoch: 187, loss: 0.292857
global_step: 39443, epoch: 187, loss: 0.179571
global_step: 39444, epoch: 187, loss: 0.271288
global_step: 39445, epoch: 187, loss: 0.261630
global_step: 39446, epoch: 187, loss: 0.313373
global_step: 39447, epoch: 187, loss: 0.244792
global_step: 39448, epoch: 187, loss: 0.282797
global_step: 39449, epoch: 187, loss: 0.261055
global_step: 39450, epoch: 187, loss: 0.217743
global_step: 39451, epoch: 187, loss: 0.281328
global_step: 39452, epoch: 187, loss: 0.272410
global_step: 39453, epoch: 187, loss: 0.262884
global_step: 39454, epoch: 187, loss: 0.213616
global_step: 39455, epoch: 187, loss: 0.225284
global_step: 39456, epoch: 187, loss: 0.222866
global_step: 39457, epoch: 187, loss: 0.283022
global_step: 39458, epoch: 187, loss: 0.224116
global_step: 39459, epoch: 187, loss: 0.269444
global_step: 39460, epoch: 187, loss: 0.287223
global_step: 39461, epoch: 187, loss: 0.285079
global_step: 39462, epoch: 187, loss: 0.251174
global_step: 39463, epoch: 187, loss: 0.223553
global_step: 39464, epoch: 187, loss: 0.218492
global_step: 39465, epoch: 187, loss: 0.377629
global_step: 39466, epoch: 187, loss: 0.320862
global_step: 39467, epoch: 187, loss: 0.260825
global_step: 39468, epoch: 187, loss: 0.221076
global_step: 39469, epoch: 187, loss: 0.232781
global_step: 39470, epoch: 187, loss: 0.270841
global_step: 39471, epoch: 187, loss: 0.213276
global_step: 39472, epoch: 187, loss: 0.249741
global_step: 39473, epoch: 187, loss: 0.207120
global_step: 39474, epoch: 187, loss: 0.229024
global_step: 39475, epoch: 187, loss: 0.311749
global_step: 39476, epoch: 187, loss: 0.226304
global_step: 39477, epoch: 187, loss: 0.270785
global_step: 39478, epoch: 187, loss: 0.257685
global_step: 39479, epoch: 187, loss: 0.314513
global_step: 39480, epoch: 187, loss: 0.208752
epoch: 187
train	acc: 0.9602	macro: p 0.9602, r 0.9269, f1: 0.9421	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9600
dev	acc: 0.5437	macro: p 0.4252, r 0.3407, f1: 0.3448	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5083
test	acc: 0.5801	macro: p 0.3777, r 0.3418, f1: 0.3428	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5513
global_step: 39481, epoch: 188, loss: 0.226335
global_step: 39482, epoch: 188, loss: 0.239278
global_step: 39483, epoch: 188, loss: 0.280187
global_step: 39484, epoch: 188, loss: 0.241471
global_step: 39485, epoch: 188, loss: 0.292085
global_step: 39486, epoch: 188, loss: 0.271918
global_step: 39487, epoch: 188, loss: 0.307225
global_step: 39488, epoch: 188, loss: 0.262478
global_step: 39489, epoch: 188, loss: 0.244641
global_step: 39490, epoch: 188, loss: 0.211338
global_step: 39491, epoch: 188, loss: 0.291173
global_step: 39492, epoch: 188, loss: 0.321005
global_step: 39493, epoch: 188, loss: 0.245724
global_step: 39494, epoch: 188, loss: 0.222272
global_step: 39495, epoch: 188, loss: 0.275752
global_step: 39496, epoch: 188, loss: 0.254727
global_step: 39497, epoch: 188, loss: 0.263189
global_step: 39498, epoch: 188, loss: 0.269922
global_step: 39499, epoch: 188, loss: 0.245955
global_step: 39500, epoch: 188, loss: 0.296900
global_step: 39501, epoch: 188, loss: 0.207332
global_step: 39502, epoch: 188, loss: 0.273334
global_step: 39503, epoch: 188, loss: 0.247806
global_step: 39504, epoch: 188, loss: 0.284275
global_step: 39505, epoch: 188, loss: 0.258201
global_step: 39506, epoch: 188, loss: 0.215714
global_step: 39507, epoch: 188, loss: 0.263723
global_step: 39508, epoch: 188, loss: 0.280261
global_step: 39509, epoch: 188, loss: 0.273142
global_step: 39510, epoch: 188, loss: 0.279882
global_step: 39511, epoch: 188, loss: 0.275846
global_step: 39512, epoch: 188, loss: 0.233688
global_step: 39513, epoch: 188, loss: 0.162731
global_step: 39514, epoch: 188, loss: 0.218097
global_step: 39515, epoch: 188, loss: 0.278924
global_step: 39516, epoch: 188, loss: 0.253043
global_step: 39517, epoch: 188, loss: 0.268472
global_step: 39518, epoch: 188, loss: 0.260999
global_step: 39519, epoch: 188, loss: 0.206702
global_step: 39520, epoch: 188, loss: 0.213951
epoch: 188
train	acc: 0.9606	macro: p 0.9577, r 0.9273, f1: 0.9413	micro: p 0.9606, r 0.9606, f1 0.9606	weighted_f1:0.9604
dev	acc: 0.5509	macro: p 0.3921, r 0.3534, f1: 0.3631	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5261
test	acc: 0.5874	macro: p 0.4124, r 0.3595, f1: 0.3755	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5668
global_step: 39521, epoch: 189, loss: 0.155843
global_step: 39522, epoch: 189, loss: 0.248700
global_step: 39523, epoch: 189, loss: 0.285868
global_step: 39524, epoch: 189, loss: 0.239674
global_step: 39525, epoch: 189, loss: 0.255476
global_step: 39526, epoch: 189, loss: 0.221960
global_step: 39527, epoch: 189, loss: 0.211329
global_step: 39528, epoch: 189, loss: 0.196553
global_step: 39529, epoch: 189, loss: 0.241984
global_step: 39530, epoch: 189, loss: 0.259588
global_step: 39531, epoch: 189, loss: 0.219094
global_step: 39532, epoch: 189, loss: 0.312721
global_step: 39533, epoch: 189, loss: 0.212550
global_step: 39534, epoch: 189, loss: 0.236106
global_step: 39535, epoch: 189, loss: 0.258254
global_step: 39536, epoch: 189, loss: 0.216542
global_step: 39537, epoch: 189, loss: 0.251096
global_step: 39538, epoch: 189, loss: 0.339150
global_step: 39539, epoch: 189, loss: 0.226157
global_step: 39540, epoch: 189, loss: 0.260315
global_step: 39541, epoch: 189, loss: 0.196463
global_step: 39542, epoch: 189, loss: 0.261550
global_step: 39543, epoch: 189, loss: 0.274916
global_step: 39544, epoch: 189, loss: 0.248205
global_step: 39545, epoch: 189, loss: 0.255782
global_step: 39546, epoch: 189, loss: 0.280212
global_step: 39547, epoch: 189, loss: 0.240702
global_step: 39548, epoch: 189, loss: 0.249075
global_step: 39549, epoch: 189, loss: 0.246806
global_step: 39550, epoch: 189, loss: 0.221225
global_step: 39551, epoch: 189, loss: 0.317009
global_step: 39552, epoch: 189, loss: 0.216249
global_step: 39553, epoch: 189, loss: 0.217508
global_step: 39554, epoch: 189, loss: 0.220870
global_step: 39555, epoch: 189, loss: 0.246542
global_step: 39556, epoch: 189, loss: 0.299791
global_step: 39557, epoch: 189, loss: 0.241180
global_step: 39558, epoch: 189, loss: 0.245477
global_step: 39559, epoch: 189, loss: 0.284770
global_step: 39560, epoch: 189, loss: 0.209063
epoch: 189
train	acc: 0.9625	macro: p 0.9614, r 0.9302, f1: 0.9446	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9623
dev	acc: 0.5528	macro: p 0.3944, r 0.3444, f1: 0.3490	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5204
test	acc: 0.5839	macro: p 0.3958, r 0.3502, f1: 0.3586	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5594run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

global_step: 39561, epoch: 190, loss: 0.289641
global_step: 39562, epoch: 190, loss: 0.266411
global_step: 39563, epoch: 190, loss: 0.192162
global_step: 39564, epoch: 190, loss: 0.249653
global_step: 39565, epoch: 190, loss: 0.190718
global_step: 39566, epoch: 190, loss: 0.269310
global_step: 39567, epoch: 190, loss: 0.279060
global_step: 39568, epoch: 190, loss: 0.283350
global_step: 39569, epoch: 190, loss: 0.284479
global_step: 39570, epoch: 190, loss: 0.286885
global_step: 39571, epoch: 190, loss: 0.181360
global_step: 39572, epoch: 190, loss: 0.229431
global_step: 39573, epoch: 190, loss: 0.215913
global_step: 39574, epoch: 190, loss: 0.252592
global_step: 39575, epoch: 190, loss: 0.268866
global_step: 39576, epoch: 190, loss: 0.306234
global_step: 39577, epoch: 190, loss: 0.246932
global_step: 39578, epoch: 190, loss: 0.305221
global_step: 39579, epoch: 190, loss: 0.258147
global_step: 39580, epoch: 190, loss: 0.281906
global_step: 39581, epoch: 190, loss: 0.270208
global_step: 39582, epoch: 190, loss: 0.200449
global_step: 39583, epoch: 190, loss: 0.244663
global_step: 39584, epoch: 190, loss: 0.242178
global_step: 39585, epoch: 190, loss: 0.194071
global_step: 39586, epoch: 190, loss: 0.272241
global_step: 39587, epoch: 190, loss: 0.244727
global_step: 39588, epoch: 190, loss: 0.233408
global_step: 39589, epoch: 190, loss: 0.198464
global_step: 39590, epoch: 190, loss: 0.268849
global_step: 39591, epoch: 190, loss: 0.234593
global_step: 39592, epoch: 190, loss: 0.299276
global_step: 39593, epoch: 190, loss: 0.241076
global_step: 39594, epoch: 190, loss: 0.226079
global_step: 39595, epoch: 190, loss: 0.275822
global_step: 39596, epoch: 190, loss: 0.329134
global_step: 39597, epoch: 190, loss: 0.237721
global_step: 39598, epoch: 190, loss: 0.267842
global_step: 39599, epoch: 190, loss: 0.197550
global_step: 39600, epoch: 190, loss: 0.802310
epoch: 190
train	acc: 0.9620	macro: p 0.9620, r 0.9308, f1: 0.9450	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9618
dev	acc: 0.5546	macro: p 0.4020, r 0.3509, f1: 0.3582	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5275
test	acc: 0.5847	macro: p 0.3970, r 0.3523, f1: 0.3626	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5632
global_step: 39601, epoch: 191, loss: 0.235481
global_step: 39602, epoch: 191, loss: 0.291597
global_step: 39603, epoch: 191, loss: 0.246820
global_step: 39604, epoch: 191, loss: 0.237881
global_step: 39605, epoch: 191, loss: 0.260358
global_step: 39606, epoch: 191, loss: 0.280008
global_step: 39607, epoch: 191, loss: 0.248767
global_step: 39608, epoch: 191, loss: 0.197115
global_step: 39609, epoch: 191, loss: 0.273733
global_step: 39610, epoch: 191, loss: 0.191141
global_step: 39611, epoch: 191, loss: 0.189910
global_step: 39612, epoch: 191, loss: 0.231483
global_step: 39613, epoch: 191, loss: 0.230508
global_step: 39614, epoch: 191, loss: 0.217536
global_step: 39615, epoch: 191, loss: 0.256620
global_step: 39616, epoch: 191, loss: 0.273821
global_step: 39617, epoch: 191, loss: 0.278266
global_step: 39618, epoch: 191, loss: 0.249522
global_step: 39619, epoch: 191, loss: 0.202031
global_step: 39620, epoch: 191, loss: 0.233581
global_step: 39621, epoch: 191, loss: 0.251051
global_step: 39622, epoch: 191, loss: 0.238566
global_step: 39623, epoch: 191, loss: 0.248473
global_step: 39624, epoch: 191, loss: 0.298975
global_step: 39625, epoch: 191, loss: 0.244319
global_step: 39626, epoch: 191, loss: 0.211728
global_step: 39627, epoch: 191, loss: 0.277345
global_step: 39628, epoch: 191, loss: 0.266382
global_step: 39629, epoch: 191, loss: 0.280098
global_step: 39630, epoch: 191, loss: 0.217240
global_step: 39631, epoch: 191, loss: 0.232530
global_step: 39632, epoch: 191, loss: 0.232744
global_step: 39633, epoch: 191, loss: 0.271575
global_step: 39634, epoch: 191, loss: 0.243292
global_step: 39635, epoch: 191, loss: 0.247539
global_step: 39636, epoch: 191, loss: 0.257026
global_step: 39637, epoch: 191, loss: 0.238443
global_step: 39638, epoch: 191, loss: 0.265699
global_step: 39639, epoch: 191, loss: 0.189104
global_step: 39640, epoch: 191, loss: 0.039994
epoch: 191
train	acc: 0.9620	macro: p 0.9613, r 0.9325, f1: 0.9461	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9618
dev	acc: 0.5528	macro: p 0.4111, r 0.3444, f1: 0.3567	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5207
test	acc: 0.5908	macro: p 0.4105, r 0.3487, f1: 0.3647	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5623
global_step: 39641, epoch: 192, loss: 0.206681
global_step: 39642, epoch: 192, loss: 0.238210
global_step: 39643, epoch: 192, loss: 0.285816
global_step: 39644, epoch: 192, loss: 0.241514
global_step: 39645, epoch: 192, loss: 0.226816
global_step: 39646, epoch: 192, loss: 0.294086
global_step: 39647, epoch: 192, loss: 0.317144
global_step: 39648, epoch: 192, loss: 0.239389
global_step: 39649, epoch: 192, loss: 0.298770
global_step: 39650, epoch: 192, loss: 0.287659
global_step: 39651, epoch: 192, loss: 0.186744
global_step: 39652, epoch: 192, loss: 0.230830
global_step: 39653, epoch: 192, loss: 0.257550
global_step: 39654, epoch: 192, loss: 0.240906
global_step: 39655, epoch: 192, loss: 0.217494
global_step: 39656, epoch: 192, loss: 0.295572
global_step: 39657, epoch: 192, loss: 0.283346
global_step: 39658, epoch: 192, loss: 0.208724
global_step: 39659, epoch: 192, loss: 0.257458
global_step: 39660, epoch: 192, loss: 0.293420
global_step: 39661, epoch: 192, loss: 0.282653
global_step: 39662, epoch: 192, loss: 0.239583
global_step: 39663, epoch: 192, loss: 0.254351
global_step: 39664, epoch: 192, loss: 0.221721
global_step: 39665, epoch: 192, loss: 0.220305
global_step: 39666, epoch: 192, loss: 0.204962
global_step: 39667, epoch: 192, loss: 0.284427
global_step: 39668, epoch: 192, loss: 0.214396
global_step: 39669, epoch: 192, loss: 0.233051
global_step: 39670, epoch: 192, loss: 0.235900
global_step: 39671, epoch: 192, loss: 0.208037
global_step: 39672, epoch: 192, loss: 0.231532
global_step: 39673, epoch: 192, loss: 0.212967
global_step: 39674, epoch: 192, loss: 0.259680
global_step: 39675, epoch: 192, loss: 0.295501
global_step: 39676, epoch: 192, loss: 0.260621
global_step: 39677, epoch: 192, loss: 0.191443
global_step: 39678, epoch: 192, loss: 0.224292
global_step: 39679, epoch: 192, loss: 0.254087
global_step: 39680, epoch: 192, loss: 0.161801
epoch: 192
train	acc: 0.9618	macro: p 0.9623, r 0.9307, f1: 0.9453	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9616
dev	acc: 0.5482	macro: p 0.3922, r 0.3435, f1: 0.3514	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5213
test	acc: 0.5893	macro: p 0.4131, r 0.3562, f1: 0.3691	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5683
global_step: 39681, epoch: 193, loss: 0.186157
global_step: 39682, epoch: 193, loss: 0.205006
global_step: 39683, epoch: 193, loss: 0.213602
global_step: 39684, epoch: 193, loss: 0.248450
global_step: 39685, epoch: 193, loss: 0.238163
global_step: 39686, epoch: 193, loss: 0.295867
global_step: 39687, epoch: 193, loss: 0.244625
global_step: 39688, epoch: 193, loss: 0.286437
global_step: 39689, epoch: 193, loss: 0.221896
global_step: 39690, epoch: 193, loss: 0.246413
global_step: 39691, epoch: 193, loss: 0.266072
global_step: 39692, epoch: 193, loss: 0.309467
global_step: 39693, epoch: 193, loss: 0.277843
global_step: 39694, epoch: 193, loss: 0.229807
global_step: 39695, epoch: 193, loss: 0.305184
global_step: 39696, epoch: 193, loss: 0.232877
global_step: 39697, epoch: 193, loss: 0.204191
global_step: 39698, epoch: 193, loss: 0.280160
global_step: 39699, epoch: 193, loss: 0.330107
global_step: 39700, epoch: 193, loss: 0.216276
global_step: 39701, epoch: 193, loss: 0.232400
global_step: 39702, epoch: 193, loss: 0.211037
global_step: 39703, epoch: 193, loss: 0.283660
global_step: 39704, epoch: 193, loss: 0.200501
global_step: 39705, epoch: 193, loss: 0.305651
global_step: 39706, epoch: 193, loss: 0.247922
global_step: 39707, epoch: 193, loss: 0.232528
global_step: 39708, epoch: 193, loss: 0.254906
global_step: 39709, epoch: 193, loss: 0.232914
global_step: 39710, epoch: 193, loss: 0.303747
global_step: 39711, epoch: 193, loss: 0.326622
global_step: 39712, epoch: 193, loss: 0.222398
global_step: 39713, epoch: 193, loss: 0.244708
global_step: 39714, epoch: 193, loss: 0.275246
global_step: 39715, epoch: 193, loss: 0.190040
global_step: 39716, epoch: 193, loss: 0.244544
global_step: 39717, epoch: 193, loss: 0.216020
global_step: 39718, epoch: 193, loss: 0.266131
global_step: 39719, epoch: 193, loss: 0.207736
global_step: 39720, epoch: 193, loss: 0.132529
epoch: 193
train	acc: 0.9621	macro: p 0.9642, r 0.9300, f1: 0.9457	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9619
dev	acc: 0.5428	macro: p 0.4071, r 0.3399, f1: 0.3444	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5128
test	acc: 0.5858	macro: p 0.3950, r 0.3453, f1: 0.3492	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5606
global_step: 39721, epoch: 194, loss: 0.344654
global_step: 39722, epoch: 194, loss: 0.252201
global_step: 39723, epoch: 194, loss: 0.232253
global_step: 39724, epoch: 194, loss: 0.254626
global_step: 39725, epoch: 194, loss: 0.264767
global_step: 39726, epoch: 194, loss: 0.224505
global_step: 39727, epoch: 194, loss: 0.294529
global_step: 39728, epoch: 194, loss: 0.261776
global_step: 39729, epoch: 194, loss: 0.214753
global_step: 39730, epoch: 194, loss: 0.235819
global_step: 39731, epoch: 194, loss: 0.283973
global_step: 39732, epoch: 194, loss: 0.259539
global_step: 39733, epoch: 194, loss: 0.244610
global_step: 39734, epoch: 194, loss: 0.280179
global_step: 39735, epoch: 194, loss: 0.217362
global_step: 39736, epoch: 194, loss: 0.230989
global_step: 39737, epoch: 194, loss: 0.264940
global_step: 39738, epoch: 194, loss: 0.279632
global_step: 39739, epoch: 194, loss: 0.221213
global_step: 39740, epoch: 194, loss: 0.218735
global_step: 39741, epoch: 194, loss: 0.236936
global_step: 39742, epoch: 194, loss: 0.315835
global_step: 39743, epoch: 194, loss: 0.250980
global_step: 39744, epoch: 194, loss: 0.222271
global_step: 39745, epoch: 194, loss: 0.207630
global_step: 39746, epoch: 194, loss: 0.247788
global_step: 39747, epoch: 194, loss: 0.293940
global_step: 39748, epoch: 194, loss: 0.246144
global_step: 39749, epoch: 194, loss: 0.256773
global_step: 39750, epoch: 194, loss: 0.271475
global_step: 39751, epoch: 194, loss: 0.217374
global_step: 39752, epoch: 194, loss: 0.221650
global_step: 39753, epoch: 194, loss: 0.256287
global_step: 39754, epoch: 194, loss: 0.240745
global_step: 39755, epoch: 194, loss: 0.286238
global_step: 39756, epoch: 194, loss: 0.179854
global_step: 39757, epoch: 194, loss: 0.258604
global_step: 39758, epoch: 194, loss: 0.320109
global_step: 39759, epoch: 194, loss: 0.190969
global_step: 39760, epoch: 194, loss: 0.179703
epoch: 194
train	acc: 0.9603	macro: p 0.9592, r 0.9282, f1: 0.9427	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9601
dev	acc: 0.5672	macro: p 0.4417, r 0.3486, f1: 0.3572	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5254
test	acc: 0.5946	macro: p 0.4095, r 0.3353, f1: 0.3447	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5587
global_step: 39761, epoch: 195, loss: 0.251670
global_step: 39762, epoch: 195, loss: 0.227002
global_step: 39763, epoch: 195, loss: 0.241751
global_step: 39764, epoch: 195, loss: 0.308975
global_step: 39765, epoch: 195, loss: 0.213167
global_step: 39766, epoch: 195, loss: 0.236603
global_step: 39767, epoch: 195, loss: 0.186421
global_step: 39768, epoch: 195, loss: 0.310171
global_step: 39769, epoch: 195, loss: 0.209212
global_step: 39770, epoch: 195, loss: 0.199272
global_step: 39771, epoch: 195, loss: 0.279463
global_step: 39772, epoch: 195, loss: 0.208180
global_step: 39773, epoch: 195, loss: 0.229534
global_step: 39774, epoch: 195, loss: 0.299279
global_step: 39775, epoch: 195, loss: 0.291707
global_step: 39776, epoch: 195, loss: 0.248584
global_step: 39777, epoch: 195, loss: 0.270848
global_step: 39778, epoch: 195, loss: 0.279606
global_step: 39779, epoch: 195, loss: 0.272873
global_step: 39780, epoch: 195, loss: 0.263746
global_step: 39781, epoch: 195, loss: 0.256353
global_step: 39782, epoch: 195, loss: 0.219353
global_step: 39783, epoch: 195, loss: 0.232462
global_step: 39784, epoch: 195, loss: 0.233603
global_step: 39785, epoch: 195, loss: 0.250752
global_step: 39786, epoch: 195, loss: 0.254005
global_step: 39787, epoch: 195, loss: 0.228488
global_step: 39788, epoch: 195, loss: 0.297474
global_step: 39789, epoch: 195, loss: 0.206775
global_step: 39790, epoch: 195, loss: 0.246249
global_step: 39791, epoch: 195, loss: 0.275865
global_step: 39792, epoch: 195, loss: 0.227725
global_step: 39793, epoch: 195, loss: 0.241159
global_step: 39794, epoch: 195, loss: 0.218287
global_step: 39795, epoch: 195, loss: 0.285715
global_step: 39796, epoch: 195, loss: 0.261345
global_step: 39797, epoch: 195, loss: 0.210529
global_step: 39798, epoch: 195, loss: 0.292011
global_step: 39799, epoch: 195, loss: 0.224285
global_step: 39800, epoch: 195, loss: 0.017866
epoch: 195
train	acc: 0.9628	macro: p 0.9632, r 0.9350, f1: 0.9485	micro: p 0.9628, r 0.9628, f1 0.9628	weighted_f1:0.9626
dev	acc: 0.5473	macro: p 0.3963, r 0.3390, f1: 0.3478	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5135
test	acc: 0.5920	macro: p 0.4117, r 0.3459, f1: 0.3607	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5614
global_step: 39801, epoch: 196, loss: 0.252085
global_step: 39802, epoch: 196, loss: 0.257141
global_step: 39803, epoch: 196, loss: 0.229359
global_step: 39804, epoch: 196, loss: 0.274198
global_step: 39805, epoch: 196, loss: 0.273197
global_step: 39806, epoch: 196, loss: 0.250424
global_step: 39807, epoch: 196, loss: 0.225495
global_step: 39808, epoch: 196, loss: 0.202812
global_step: 39809, epoch: 196, loss: 0.283163
global_step: 39810, epoch: 196, loss: 0.270151
global_step: 39811, epoch: 196, loss: 0.222435
global_step: 39812, epoch: 196, loss: 0.228123
global_step: 39813, epoch: 196, loss: 0.212756
global_step: 39814, epoch: 196, loss: 0.231849
global_step: 39815, epoch: 196, loss: 0.257472
global_step: 39816, epoch: 196, loss: 0.223900
global_step: 39817, epoch: 196, loss: 0.220868
global_step: 39818, epoch: 196, loss: 0.343671
global_step: 39819, epoch: 196, loss: 0.250529
global_step: 39820, epoch: 196, loss: 0.309547
global_step: 39821, epoch: 196, loss: 0.256243
global_step: 39822, epoch: 196, loss: 0.273066
global_step: 39823, epoch: 196, loss: 0.261284
global_step: 39824, epoch: 196, loss: 0.242610
global_step: 39825, epoch: 196, loss: 0.238003
global_step: 39826, epoch: 196, loss: 0.251094
global_step: 39827, epoch: 196, loss: 0.230916
global_step: 39828, epoch: 196, loss: 0.209311
global_step: 39829, epoch: 196, loss: 0.284501
global_step: 39830, epoch: 196, loss: 0.224001
global_step: 39831, epoch: 196, loss: 0.238867
global_step: 39832, epoch: 196, loss: 0.224153
global_step: 39833, epoch: 196, loss: 0.273345
global_step: 39834, epoch: 196, loss: 0.232853
global_step: 39835, epoch: 196, loss: 0.258687
global_step: 39836, epoch: 196, loss: 0.194229
global_step: 39837, epoch: 196, loss: 0.280046
global_step: 39838, epoch: 196, loss: 0.191280
global_step: 39839, epoch: 196, loss: 0.224523
global_step: 39840, epoch: 196, loss: 0.306609
epoch: 196
train	acc: 0.9635	macro: p 0.9612, r 0.9366, f1: 0.9482	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5509	macro: p 0.4009, r 0.3470, f1: 0.3566	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5207
test	acc: 0.5816	macro: p 0.3951, r 0.3447, f1: 0.3557	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5555
global_step: 39841, epoch: 197, loss: 0.198718
global_step: 39842, epoch: 197, loss: 0.204164
global_step: 39843, epoch: 197, loss: 0.254648
global_step: 39844, epoch: 197, loss: 0.220642
global_step: 39845, epoch: 197, loss: 0.216480
global_step: 39846, epoch: 197, loss: 0.264452
global_step: 39847, epoch: 197, loss: 0.224373
global_step: 39848, epoch: 197, loss: 0.246240
global_step: 39849, epoch: 197, loss: 0.313010
global_step: 39850, epoch: 197, loss: 0.246415
global_step: 39851, epoch: 197, loss: 0.241626
global_step: 39852, epoch: 197, loss: 0.269022
global_step: 39853, epoch: 197, loss: 0.212510
global_step: 39854, epoch: 197, loss: 0.399742
global_step: 39855, epoch: 197, loss: 0.214137
global_step: 39856, epoch: 197, loss: 0.198657
global_step: 39857, epoch: 197, loss: 0.211673
global_step: 39858, epoch: 197, loss: 0.212565
global_step: 39859, epoch: 197, loss: 0.201395
global_step: 39860, epoch: 197, loss: 0.162798
global_step: 39861, epoch: 197, loss: 0.284008
global_step: 39862, epoch: 197, loss: 0.208652
global_step: 39863, epoch: 197, loss: 0.223256
global_step: 39864, epoch: 197, loss: 0.318991
global_step: 39865, epoch: 197, loss: 0.218318
global_step: 39866, epoch: 197, loss: 0.216375
global_step: 39867, epoch: 197, loss: 0.225949
global_step: 39868, epoch: 197, loss: 0.273381
global_step: 39869, epoch: 197, loss: 0.240967
global_step: 39870, epoch: 197, loss: 0.230129
global_step: 39871, epoch: 197, loss: 0.334764
global_step: 39872, epoch: 197, loss: 0.209959
global_step: 39873, epoch: 197, loss: 0.281011
global_step: 39874, epoch: 197, loss: 0.221293
global_step: 39875, epoch: 197, loss: 0.182000
global_step: 39876, epoch: 197, loss: 0.234282
global_step: 39877, epoch: 197, loss: 0.275173
global_step: 39878, epoch: 197, loss: 0.207784
global_step: 39879, epoch: 197, loss: 0.286384
global_step: 39880, epoch: 197, loss: 0.175444
epoch: 197
train	acc: 0.9646	macro: p 0.9640, r 0.9397, f1: 0.9512	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9645
dev	acc: 0.5473	macro: p 0.3982, r 0.3485, f1: 0.3564	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5185
test	acc: 0.5831	macro: p 0.3960, r 0.3509, f1: 0.3625	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5611
global_step: 39881, epoch: 198, loss: 0.277025
global_step: 39882, epoch: 198, loss: 0.220078
global_step: 39883, epoch: 198, loss: 0.243148
global_step: 39884, epoch: 198, loss: 0.280850
global_step: 39885, epoch: 198, loss: 0.231737
global_step: 39886, epoch: 198, loss: 0.232980
global_step: 39887, epoch: 198, loss: 0.230071
global_step: 39888, epoch: 198, loss: 0.197251
global_step: 39889, epoch: 198, loss: 0.286057
global_step: 39890, epoch: 198, loss: 0.180915
global_step: 39891, epoch: 198, loss: 0.203581
global_step: 39892, epoch: 198, loss: 0.287905
global_step: 39893, epoch: 198, loss: 0.226363
global_step: 39894, epoch: 198, loss: 0.200718
global_step: 39895, epoch: 198, loss: 0.251057
global_step: 39896, epoch: 198, loss: 0.223666
global_step: 39897, epoch: 198, loss: 0.271175
global_step: 39898, epoch: 198, loss: 0.243567
global_step: 39899, epoch: 198, loss: 0.343419
global_step: 39900, epoch: 198, loss: 0.180152
global_step: 39901, epoch: 198, loss: 0.291593
global_step: 39902, epoch: 198, loss: 0.262945
global_step: 39903, epoch: 198, loss: 0.213050
global_step: 39904, epoch: 198, loss: 0.259165
global_step: 39905, epoch: 198, loss: 0.232884
global_step: 39906, epoch: 198, loss: 0.255776
global_step: 39907, epoch: 198, loss: 0.207734
global_step: 39908, epoch: 198, loss: 0.271118
global_step: 39909, epoch: 198, loss: 0.302044
global_step: 39910, epoch: 198, loss: 0.261754
global_step: 39911, epoch: 198, loss: 0.282288
global_step: 39912, epoch: 198, loss: 0.324792
global_step: 39913, epoch: 198, loss: 0.306253
global_step: 39914, epoch: 198, loss: 0.296573
global_step: 39915, epoch: 198, loss: 0.181621
global_step: 39916, epoch: 198, loss: 0.196455
global_step: 39917, epoch: 198, loss: 0.233580
global_step: 39918, epoch: 198, loss: 0.253886
global_step: 39919, epoch: 198, loss: 0.215093
global_step: 39920, epoch: 198, loss: 0.035055
epoch: 198
train	acc: 0.9634	macro: p 0.9642, r 0.9345, f1: 0.9484	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9632
dev	acc: 0.5491	macro: p 0.4017, r 0.3366, f1: 0.3455	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5138
test	acc: 0.5893	macro: p 0.3920, r 0.3387, f1: 0.3512	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5597
global_step: 39921, epoch: 199, loss: 0.252724
global_step: 39922, epoch: 199, loss: 0.192181
global_step: 39923, epoch: 199, loss: 0.245771
global_step: 39924, epoch: 199, loss: 0.185877
global_step: 39925, epoch: 199, loss: 0.242943
global_step: 39926, epoch: 199, loss: 0.251045
global_step: 39927, epoch: 199, loss: 0.195657
global_step: 39928, epoch: 199, loss: 0.222395
global_step: 39929, epoch: 199, loss: 0.213570
global_step: 39930, epoch: 199, loss: 0.231234
global_step: 39931, epoch: 199, loss: 0.316136
global_step: 39932, epoch: 199, loss: 0.247593
global_step: 39933, epoch: 199, loss: 0.261862
global_step: 39934, epoch: 199, loss: 0.196128
global_step: 39935, epoch: 199, loss: 0.312639
global_step: 39936, epoch: 199, loss: 0.239216
global_step: 39937, epoch: 199, loss: 0.200955
global_step: 39938, epoch: 199, loss: 0.236303
global_step: 39939, epoch: 199, loss: 0.283372
global_step: 39940, epoch: 199, loss: 0.346304
global_step: 39941, epoch: 199, loss: 0.227955
global_step: 39942, epoch: 199, loss: 0.237282
global_step: 39943, epoch: 199, loss: 0.244719
global_step: 39944, epoch: 199, loss: 0.216877
global_step: 39945, epoch: 199, loss: 0.258154
global_step: 39946, epoch: 199, loss: 0.196017
global_step: 39947, epoch: 199, loss: 0.206532
global_step: 39948, epoch: 199, loss: 0.224436
global_step: 39949, epoch: 199, loss: 0.284588
global_step: 39950, epoch: 199, loss: 0.244343
global_step: 39951, epoch: 199, loss: 0.244199
global_step: 39952, epoch: 199, loss: 0.198530
global_step: 39953, epoch: 199, loss: 0.280959
global_step: 39954, epoch: 199, loss: 0.254566
global_step: 39955, epoch: 199, loss: 0.213416
global_step: 39956, epoch: 199, loss: 0.279202
global_step: 39957, epoch: 199, loss: 0.263986
global_step: 39958, epoch: 199, loss: 0.245891
global_step: 39959, epoch: 199, loss: 0.227828
global_step: 39960, epoch: 199, loss: 0.136216
epoch: 199
train	acc: 0.9629	macro: p 0.9667, r 0.9361, f1: 0.9505	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9627
dev	acc: 0.5528	macro: p 0.4255, r 0.3378, f1: 0.3472	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5125
test	acc: 0.5969	macro: p 0.4053, r 0.3433, f1: 0.3563	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5635
global_step: 39961, epoch: 200, loss: 0.235887
global_step: 39962, epoch: 200, loss: 0.265077
global_step: 39963, epoch: 200, loss: 0.231705
global_step: 39964, epoch: 200, loss: 0.236149
global_step: 39965, epoch: 200, loss: 0.248733
global_step: 39966, epoch: 200, loss: 0.243911
global_step: 39967, epoch: 200, loss: 0.210916
global_step: 39968, epoch: 200, loss: 0.207263
global_step: 39969, epoch: 200, loss: 0.249255
global_step: 39970, epoch: 200, loss: 0.217358
global_step: 39971, epoch: 200, loss: 0.265917
global_step: 39972, epoch: 200, loss: 0.210038
global_step: 39973, epoch: 200, loss: 0.175378
global_step: 39974, epoch: 200, loss: 0.175598
global_step: 39975, epoch: 200, loss: 0.198319
global_step: 39976, epoch: 200, loss: 0.208772
global_step: 39977, epoch: 200, loss: 0.244322
global_step: 39978, epoch: 200, loss: 0.188298
global_step: 39979, epoch: 200, loss: 0.257472
global_step: 39980, epoch: 200, loss: 0.220948
global_step: 39981, epoch: 200, loss: 0.255388
global_step: 39982, epoch: 200, loss: 0.245217
global_step: 39983, epoch: 200, loss: 0.330971
global_step: 39984, epoch: 200, loss: 0.262266
global_step: 39985, epoch: 200, loss: 0.264487
global_step: 39986, epoch: 200, loss: 0.275039
global_step: 39987, epoch: 200, loss: 0.289465
global_step: 39988, epoch: 200, loss: 0.264363
global_step: 39989, epoch: 200, loss: 0.245740
global_step: 39990, epoch: 200, loss: 0.225716
global_step: 39991, epoch: 200, loss: 0.240077
global_step: 39992, epoch: 200, loss: 0.181809
global_step: 39993, epoch: 200, loss: 0.267254
global_step: 39994, epoch: 200, loss: 0.257858
global_step: 39995, epoch: 200, loss: 0.281300
global_step: 39996, epoch: 200, loss: 0.207228
global_step: 39997, epoch: 200, loss: 0.181458
global_step: 39998, epoch: 200, loss: 0.224232
global_step: 39999, epoch: 200, loss: 0.235283
global_step: 40000, epoch: 200, loss: 0.080726
epoch: 200
train	acc: 0.9637	macro: p 0.9642, r 0.9352, f1: 0.9489	micro: p 0.9637, r 0.9637, f1 0.9637	weighted_f1:0.9636
dev	acc: 0.5518	macro: p 0.4164, r 0.3440, f1: 0.3527	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5170
test	acc: 0.5923	macro: p 0.4181, r 0.3569, f1: 0.3698	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5654
BEST MODEL epoch: 58
train	acc: 0.7641 macro_p: 0.4959 macro_r: 0.4997 macro_f1: 0.4948 micro_p: 0.7641 micro_r: 0.7641 micro_f1: 0.7641 weighted_f1: 0.7395
dev	acc: 0.5798 macro_p: 0.3598 macro_r: 0.3519 macro_f1: 0.3499 micro_p: 0.5798 micro_r: 0.5798 micro_f1: 0.5798 weighted_f1: 0.5450
test	acc: 0.6073 macro_p: 0.3559 macro_r: 0.3481 macro_f1: 0.3464 micro_p: 0.6073 micro_r: 0.6073 micro_f1: 0.6073 weighted_f1: 0.5773
====================TRAINING FINISHED====================
best epoch: [59, 49, 129, 105, 58], avg test weighted f1: 0.579113
