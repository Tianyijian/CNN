nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['I', 'can', 'get', 'a', 'quick', 'bite', 'to', 'eat', ',', 'but', 'then', 'I', 'have', 'to', 'come', 'back', 'up', 'here', '.']   0
['No', ',', 'I', 'know', '!', 'I', 'get', 'it', '!', 'It', '?', 's', 'funny', '!']   1

-------dev--------
1109 1109
['Okay', '.']   0
['My', 'god', ',', 'you', 'guys', ',', 'I', 'do', "n't", 'believe', 'you', '.']   4

-------test--------
2610 2610
['Oh', 'uh', ',', 'up', 'or', 'down', '?']   0
['The', 'uh', ',', 'the', 'baby', 'that', 'has', "n't", 'been', 'born', 'yet', '?', 'Would', "n't", 'that', 'mean', 'you', "'re", '...', 'crazy', '?']   2
====================INFORMATION====================
MODEL: rand
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 200
LEARNING_RATE: 0.1
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
global_step: 1, epoch: 1, loss: 1.898233
global_step: 2, epoch: 1, loss: 1.847863
global_step: 3, epoch: 1, loss: 1.819684
global_step: 4, epoch: 1, loss: 1.779974
global_step: 5, epoch: 1, loss: 1.743824
global_step: 6, epoch: 1, loss: 1.736815
global_step: 7, epoch: 1, loss: 1.760703
global_step: 8, epoch: 1, loss: 1.637729
global_step: 9, epoch: 1, loss: 1.606469
global_step: 10, epoch: 1, loss: 1.691302
global_step: 11, epoch: 1, loss: 1.644093
global_step: 12, epoch: 1, loss: 1.612629
global_step: 13, epoch: 1, loss: 1.545308
global_step: 14, epoch: 1, loss: 1.618317
global_step: 15, epoch: 1, loss: 1.555202
global_step: 16, epoch: 1, loss: 1.562889
global_step: 17, epoch: 1, loss: 1.582982
global_step: 18, epoch: 1, loss: 1.558136
global_step: 19, epoch: 1, loss: 1.552793
global_step: 20, epoch: 1, loss: 1.539876
global_step: 21, epoch: 1, loss: 1.604126
global_step: 22, epoch: 1, loss: 1.535203
global_step: 23, epoch: 1, loss: 1.567921
global_step: 24, epoch: 1, loss: 1.590618
global_step: 25, epoch: 1, loss: 1.547529
global_step: 26, epoch: 1, loss: 1.558970
global_step: 27, epoch: 1, loss: 1.509048
global_step: 28, epoch: 1, loss: 1.580125
global_step: 29, epoch: 1, loss: 1.491996
global_step: 30, epoch: 1, loss: 1.514955
global_step: 31, epoch: 1, loss: 1.460110
global_step: 32, epoch: 1, loss: 1.471903
global_step: 33, epoch: 1, loss: 1.492907
global_step: 34, epoch: 1, loss: 1.440398
global_step: 35, epoch: 1, loss: 1.446003
global_step: 36, epoch: 1, loss: 1.574623
global_step: 37, epoch: 1, loss: 1.388060
global_step: 38, epoch: 1, loss: 1.550932
global_step: 39, epoch: 1, loss: 1.512558
global_step: 40, epoch: 1, loss: 1.103896
epoch: 1
train	acc: 0.5115	macro: p 0.2085, r 0.1861, f1: 0.1648	micro: p 0.5115, r 0.5115, f1 0.5115	weighted_f1:0.3907
dev	acc: 0.4608	macro: p 0.1844, r 0.1843, f1: 0.1536	micro: p 0.4608, r 0.4608, f1 0.4608	weighted_f1:0.3313
test	acc: 0.5157	macro: p 0.1881, r 0.1864, f1: 0.1636	micro: p 0.5157, r 0.5157, f1 0.5157	weighted_f1:0.3923
New best model!
global_step: 41, epoch: 2, loss: 1.421342
global_step: 42, epoch: 2, loss: 1.471916
global_step: 43, epoch: 2, loss: 1.561674
global_step: 44, epoch: 2, loss: 1.438947
global_step: 45, epoch: 2, loss: 1.522223
global_step: 46, epoch: 2, loss: 1.506019
global_step: 47, epoch: 2, loss: 1.284893
global_step: 48, epoch: 2, loss: 1.413224
global_step: 49, epoch: 2, loss: 1.444251
global_step: 50, epoch: 2, loss: 1.524524
global_step: 51, epoch: 2, loss: 1.420910
global_step: 52, epoch: 2, loss: 1.553962
global_step: 53, epoch: 2, loss: 1.482369
global_step: 54, epoch: 2, loss: 1.403180
global_step: 55, epoch: 2, loss: 1.391523
global_step: 56, epoch: 2, loss: 1.545612
global_step: 57, epoch: 2, loss: 1.427509
global_step: 58, epoch: 2, loss: 1.494902
global_step: 59, epoch: 2, loss: 1.470748
global_step: 60, epoch: 2, loss: 1.457157
global_step: 61, epoch: 2, loss: 1.452405
global_step: 62, epoch: 2, loss: 1.445020
global_step: 63, epoch: 2, loss: 1.426991
global_step: 64, epoch: 2, loss: 1.499291
global_step: 65, epoch: 2, loss: 1.441587
global_step: 66, epoch: 2, loss: 1.403949
global_step: 67, epoch: 2, loss: 1.445485
global_step: 68, epoch: 2, loss: 1.407939
global_step: 69, epoch: 2, loss: 1.483634
global_step: 70, epoch: 2, loss: 1.394193
global_step: 71, epoch: 2, loss: 1.355525
global_step: 72, epoch: 2, loss: 1.427817
global_step: 73, epoch: 2, loss: 1.429261
global_step: 74, epoch: 2, loss: 1.411327
global_step: 75, epoch: 2, loss: 1.384955
global_step: 76, epoch: 2, loss: 1.406232
global_step: 77, epoch: 2, loss: 1.448010
global_step: 78, epoch: 2, loss: 1.356665
global_step: 79, epoch: 2, loss: 1.349134
global_step: 80, epoch: 2, loss: 1.145324
epoch: 2
train	acc: 0.5464	macro: p 0.3131, r 0.2193, f1: 0.1937	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4407
dev	acc: 0.4941	macro: p 0.2180, r 0.2225, f1: 0.1845	micro: p 0.4941, r 0.4941, f1 0.4941	weighted_f1:0.3790
test	acc: 0.5521	macro: p 0.2203, r 0.2257, f1: 0.1964	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.4442
New best model!
global_step: 81, epoch: 3, loss: 1.515258
global_step: 82, epoch: 3, loss: 1.400037
global_step: 83, epoch: 3, loss: 1.437054
global_step: 84, epoch: 3, loss: 1.435834
global_step: 85, epoch: 3, loss: 1.408846
global_step: 86, epoch: 3, loss: 1.421077
global_step: 87, epoch: 3, loss: 1.333017
global_step: 88, epoch: 3, loss: 1.431871
global_step: 89, epoch: 3, loss: 1.310447
global_step: 90, epoch: 3, loss: 1.427529
global_step: 91, epoch: 3, loss: 1.344006
global_step: 92, epoch: 3, loss: 1.471477
global_step: 93, epoch: 3, loss: 1.393373
global_step: 94, epoch: 3, loss: 1.431229
global_step: 95, epoch: 3, loss: 1.388178
global_step: 96, epoch: 3, loss: 1.276374
global_step: 97, epoch: 3, loss: 1.520398
global_step: 98, epoch: 3, loss: 1.263519
global_step: 99, epoch: 3, loss: 1.402779
global_step: 100, epoch: 3, loss: 1.390502
global_step: 101, epoch: 3, loss: 1.387004
global_step: 102, epoch: 3, loss: 1.250139
global_step: 103, epoch: 3, loss: 1.409854
global_step: 104, epoch: 3, loss: 1.504045
global_step: 105, epoch: 3, loss: 1.371554
global_step: 106, epoch: 3, loss: 1.314535
global_step: 107, epoch: 3, loss: 1.376050
global_step: 108, epoch: 3, loss: 1.314717
global_step: 109, epoch: 3, loss: 1.411913
global_step: 110, epoch: 3, loss: 1.394785
global_step: 111, epoch: 3, loss: 1.438544
global_step: 112, epoch: 3, loss: 1.348190
global_step: 113, epoch: 3, loss: 1.397934
global_step: 114, epoch: 3, loss: 1.373583
global_step: 115, epoch: 3, loss: 1.370572
global_step: 116, epoch: 3, loss: 1.359362
global_step: 117, epoch: 3, loss: 1.308401
global_step: 118, epoch: 3, loss: 1.376644
global_step: 119, epoch: 3, loss: 1.333650
global_step: 120, epoch: 3, loss: 1.276456
epoch: 3
train	acc: 0.5604	macro: p 0.3240, r 0.2402, f1: 0.2162	micro: p 0.5604, r 0.5604, f1 0.5604	weighted_f1:0.4677
dev	acc: 0.5131	macro: p 0.2221, r 0.2482, f1: 0.2093	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4077
test	acc: 0.5590	macro: p 0.2266, r 0.2435, f1: 0.2135	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.4626
New best model!
global_step: 121, epoch: 4, loss: 1.417939
global_step: 122, epoch: 4, loss: 1.437105
global_step: 123, epoch: 4, loss: 1.336419
global_step: 124, epoch: 4, loss: 1.331415
global_step: 125, epoch: 4, loss: 1.354195
global_step: 126, epoch: 4, loss: 1.259310
global_step: 127, epoch: 4, loss: 1.270782
global_step: 128, epoch: 4, loss: 1.411577
global_step: 129, epoch: 4, loss: 1.406448
global_step: 130, epoch: 4, loss: 1.335065
global_step: 131, epoch: 4, loss: 1.336336
global_step: 132, epoch: 4, loss: 1.393050
global_step: 133, epoch: 4, loss: 1.401398
global_step: 134, epoch: 4, loss: 1.436727
global_step: 135, epoch: 4, loss: 1.365333
global_step: 136, epoch: 4, loss: 1.426421
global_step: 137, epoch: 4, loss: 1.421205
global_step: 138, epoch: 4, loss: 1.295163
global_step: 139, epoch: 4, loss: 1.260349
global_step: 140, epoch: 4, loss: 1.382932
global_step: 141, epoch: 4, loss: 1.355635
global_step: 142, epoch: 4, loss: 1.321449
global_step: 143, epoch: 4, loss: 1.439776
global_step: 144, epoch: 4, loss: 1.445269
global_step: 145, epoch: 4, loss: 1.399899
global_step: 146, epoch: 4, loss: 1.384657
global_step: 147, epoch: 4, loss: 1.371220
global_step: 148, epoch: 4, loss: 1.286132
global_step: 149, epoch: 4, loss: 1.457325
global_step: 150, epoch: 4, loss: 1.359562
global_step: 151, epoch: 4, loss: 1.346452
global_step: 152, epoch: 4, loss: 1.321973
global_step: 153, epoch: 4, loss: 1.271734
global_step: 154, epoch: 4, loss: 1.251114
global_step: 155, epoch: 4, loss: 1.367442
global_step: 156, epoch: 4, loss: 1.337537
global_step: 157, epoch: 4, loss: 1.393932
global_step: 158, epoch: 4, loss: 1.326490
global_step: 159, epoch: 4, loss: 1.296883
global_step: 160, epoch: 4, loss: 1.447798
epoch: 4
train	acc: 0.5739	macro: p 0.3071, r 0.2617, f1: 0.2601	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5001
dev	acc: 0.5113	macro: p 0.2693, r 0.2457, f1: 0.2318	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4264
test	acc: 0.5720	macro: p 0.2919, r 0.2570, f1: 0.2527	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.4965
New best model!
global_step: 161, epoch: 5, loss: 1.292488
global_step: 162, epoch: 5, loss: 1.474005
global_step: 163, epoch: 5, loss: 1.359232
global_step: 164, epoch: 5, loss: 1.375515
global_step: 165, epoch: 5, loss: 1.329209
global_step: 166, epoch: 5, loss: 1.359102
global_step: 167, epoch: 5, loss: 1.302048
global_step: 168, epoch: 5, loss: 1.323280
global_step: 169, epoch: 5, loss: 1.331689
global_step: 170, epoch: 5, loss: 1.393831
global_step: 171, epoch: 5, loss: 1.313851
global_step: 172, epoch: 5, loss: 1.236145
global_step: 173, epoch: 5, loss: 1.364445
global_step: 174, epoch: 5, loss: 1.307420
global_step: 175, epoch: 5, loss: 1.309352
global_step: 176, epoch: 5, loss: 1.395463
global_step: 177, epoch: 5, loss: 1.382014
global_step: 178, epoch: 5, loss: 1.295892
global_step: 179, epoch: 5, loss: 1.392003
global_step: 180, epoch: 5, loss: 1.371322
global_step: 181, epoch: 5, loss: 1.458922
global_step: 182, epoch: 5, loss: 1.324870
global_step: 183, epoch: 5, loss: 1.307541
global_step: 184, epoch: 5, loss: 1.309251
global_step: 185, epoch: 5, loss: 1.357857
global_step: 186, epoch: 5, loss: 1.356242
global_step: 187, epoch: 5, loss: 1.376671
global_step: 188, epoch: 5, loss: 1.355897
global_step: 189, epoch: 5, loss: 1.291788
global_step: 190, epoch: 5, loss: 1.290928
global_step: 191, epoch: 5, loss: 1.337409
global_step: 192, epoch: 5, loss: 1.343667
global_step: 193, epoch: 5, loss: 1.253458
global_step: 194, epoch: 5, loss: 1.375946
global_step: 195, epoch: 5, loss: 1.285971
global_step: 196, epoch: 5, loss: 1.301809
global_step: 197, epoch: 5, loss: 1.353155
global_step: 198, epoch: 5, loss: 1.343470
global_step: 199, epoch: 5, loss: 1.209144
global_step: 200, epoch: 5, loss: 0.542595
epoch: 5
train	acc: 0.5735	macro: p 0.3078, r 0.2564, f1: 0.2495	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.4936
dev	acc: 0.5104	macro: p 0.2681, r 0.2441, f1: 0.2184	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4143
test	acc: 0.5697	macro: p 0.2886, r 0.2539, f1: 0.2412	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.4859
global_step: 201, epoch: 6, loss: 1.383405
global_step: 202, epoch: 6, loss: 1.308478
global_step: 203, epoch: 6, loss: 1.326932
global_step: 204, epoch: 6, loss: 1.395003
global_step: 205, epoch: 6, loss: 1.384530
global_step: 206, epoch: 6, loss: 1.328737
global_step: 207, epoch: 6, loss: 1.299717
global_step: 208, epoch: 6, loss: 1.283911
global_step: 209, epoch: 6, loss: 1.437098
global_step: 210, epoch: 6, loss: 1.236194
global_step: 211, epoch: 6, loss: 1.457634
global_step: 212, epoch: 6, loss: 1.240106
global_step: 213, epoch: 6, loss: 1.166632
global_step: 214, epoch: 6, loss: 1.399744
global_step: 215, epoch: 6, loss: 1.302437
global_step: 216, epoch: 6, loss: 1.298497
global_step: 217, epoch: 6, loss: 1.258414
global_step: 218, epoch: 6, loss: 1.368683
global_step: 219, epoch: 6, loss: 1.362632
global_step: 220, epoch: 6, loss: 1.221727
global_step: 221, epoch: 6, loss: 1.324670
global_step: 222, epoch: 6, loss: 1.335389
global_step: 223, epoch: 6, loss: 1.484063
global_step: 224, epoch: 6, loss: 1.351488
global_step: 225, epoch: 6, loss: 1.295175
global_step: 226, epoch: 6, loss: 1.310681
global_step: 227, epoch: 6, loss: 1.311882
global_step: 228, epoch: 6, loss: 1.266157
global_step: 229, epoch: 6, loss: 1.258876
global_step: 230, epoch: 6, loss: 1.264877
global_step: 231, epoch: 6, loss: 1.299219
global_step: 232, epoch: 6, loss: 1.328877
global_step: 233, epoch: 6, loss: 1.285919
global_step: 234, epoch: 6, loss: 1.264237
global_step: 235, epoch: 6, loss: 1.316780
global_step: 236, epoch: 6, loss: 1.198621
global_step: 237, epoch: 6, loss: 1.351942
global_step: 238, epoch: 6, loss: 1.315559
global_step: 239, epoch: 6, loss: 1.269199
global_step: 240, epoch: 6, loss: 2.138232
epoch: 6
train	acc: 0.5883	macro: p 0.4632, r 0.2777, f1: 0.2758	micro: p 0.5883, r 0.5883, f1 0.5883	weighted_f1:0.5194
dev	acc: 0.5203	macro: p 0.2684, r 0.2565, f1: 0.2363	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4353
test	acc: 0.5778	macro: p 0.4403, r 0.2678, f1: 0.2606	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5060
New best model!
global_step: 241, epoch: 7, loss: 1.284482
global_step: 242, epoch: 7, loss: 1.264277
global_step: 243, epoch: 7, loss: 1.380641
global_step: 244, epoch: 7, loss: 1.237987
global_step: 245, epoch: 7, loss: 1.366302
global_step: 246, epoch: 7, loss: 1.220372
global_step: 247, epoch: 7, loss: 1.358627
global_step: 248, epoch: 7, loss: 1.195080
global_step: 249, epoch: 7, loss: 1.206771
global_step: 250, epoch: 7, loss: 1.286763
global_step: 251, epoch: 7, loss: 1.333024
global_step: 252, epoch: 7, loss: 1.283540
global_step: 253, epoch: 7, loss: 1.380028
global_step: 254, epoch: 7, loss: 1.251897
global_step: 255, epoch: 7, loss: 1.210108
global_step: 256, epoch: 7, loss: 1.357665
global_step: 257, epoch: 7, loss: 1.367254
global_step: 258, epoch: 7, loss: 1.244357
global_step: 259, epoch: 7, loss: 1.279478
global_step: 260, epoch: 7, loss: 1.235423
global_step: 261, epoch: 7, loss: 1.375674
global_step: 262, epoch: 7, loss: 1.284071
global_step: 263, epoch: 7, loss: 1.367245
global_step: 264, epoch: 7, loss: 1.162246
global_step: 265, epoch: 7, loss: 1.242534
global_step: 266, epoch: 7, loss: 1.344690
global_step: 267, epoch: 7, loss: 1.422088
global_step: 268, epoch: 7, loss: 1.219858
global_step: 269, epoch: 7, loss: 1.250506
global_step: 270, epoch: 7, loss: 1.260907
global_step: 271, epoch: 7, loss: 1.313928
global_step: 272, epoch: 7, loss: 1.320970
global_step: 273, epoch: 7, loss: 1.280573
global_step: 274, epoch: 7, loss: 1.359508
global_step: 275, epoch: 7, loss: 1.452891
global_step: 276, epoch: 7, loss: 1.311361
global_step: 277, epoch: 7, loss: 1.397777
global_step: 278, epoch: 7, loss: 1.232739
global_step: 279, epoch: 7, loss: 1.251463
global_step: 280, epoch: 7, loss: 1.096754
epoch: 7
train	acc: 0.5847	macro: p 0.4640, r 0.2720, f1: 0.2626	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5103
dev	acc: 0.5293	macro: p 0.2712, r 0.2660, f1: 0.2326	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4350
test	acc: 0.5762	macro: p 0.4344, r 0.2670, f1: 0.2476	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.4952
global_step: 281, epoch: 8, loss: 1.280255
global_step: 282, epoch: 8, loss: 1.189819
global_step: 283, epoch: 8, loss: 1.339110
global_step: 284, epoch: 8, loss: 1.307395
global_step: 285, epoch: 8, loss: 1.168501
global_step: 286, epoch: 8, loss: 1.207315
global_step: 287, epoch: 8, loss: 1.326441
global_step: 288, epoch: 8, loss: 1.237761
global_step: 289, epoch: 8, loss: 1.270905
global_step: 290, epoch: 8, loss: 1.288698
global_step: 291, epoch: 8, loss: 1.350080
global_step: 292, epoch: 8, loss: 1.315968
global_step: 293, epoch: 8, loss: 1.259212
global_step: 294, epoch: 8, loss: 1.255709
global_step: 295, epoch: 8, loss: 1.336408
global_step: 296, epoch: 8, loss: 1.329757
global_step: 297, epoch: 8, loss: 1.315472
global_step: 298, epoch: 8, loss: 1.331448
global_step: 299, epoch: 8, loss: 1.404829
global_step: 300, epoch: 8, loss: 1.292256
global_step: 301, epoch: 8, loss: 1.270394
global_step: 302, epoch: 8, loss: 1.233652
global_step: 303, epoch: 8, loss: 1.310126
global_step: 304, epoch: 8, loss: 1.246543
global_step: 305, epoch: 8, loss: 1.253016
global_step: 306, epoch: 8, loss: 1.229973
global_step: 307, epoch: 8, loss: 1.240224
global_step: 308, epoch: 8, loss: 1.237540
global_step: 309, epoch: 8, loss: 1.376259
global_step: 310, epoch: 8, loss: 1.364486
global_step: 311, epoch: 8, loss: 1.270635
global_step: 312, epoch: 8, loss: 1.314470
global_step: 313, epoch: 8, loss: 1.253632
global_step: 314, epoch: 8, loss: 1.239816
global_step: 315, epoch: 8, loss: 1.162079
global_step: 316, epoch: 8, loss: 1.277240
global_step: 317, epoch: 8, loss: 1.277145
global_step: 318, epoch: 8, loss: 1.244614
global_step: 319, epoch: 8, loss: 1.311063
global_step: 320, epoch: 8, loss: 1.215644
epoch: 8
train	acc: 0.5985	macro: p 0.4131, r 0.2976, f1: 0.2992	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5388
dev	acc: 0.5365	macro: p 0.4141, r 0.2792, f1: 0.2644	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4628
test	acc: 0.5866	macro: p 0.4282, r 0.2843, f1: 0.2774	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5211
New best model!
global_step: 321, epoch: 9, loss: 1.260385
global_step: 322, epoch: 9, loss: 1.195705
global_step: 323, epoch: 9, loss: 1.280492
global_step: 324, epoch: 9, loss: 1.317834
global_step: 325, epoch: 9, loss: 1.213770
global_step: 326, epoch: 9, loss: 1.341542
global_step: 327, epoch: 9, loss: 1.317411
global_step: 328, epoch: 9, loss: 1.258604
global_step: 329, epoch: 9, loss: 1.262772
global_step: 330, epoch: 9, loss: 1.237109
global_step: 331, epoch: 9, loss: 1.306826
global_step: 332, epoch: 9, loss: 1.175308
global_step: 333, epoch: 9, loss: 1.290645
global_step: 334, epoch: 9, loss: 1.152418
global_step: 335, epoch: 9, loss: 1.266190
global_step: 336, epoch: 9, loss: 1.377840
global_step: 337, epoch: 9, loss: 1.311918
global_step: 338, epoch: 9, loss: 1.375935
global_step: 339, epoch: 9, loss: 1.383302
global_step: 340, epoch: 9, loss: 1.308079
global_step: 341, epoch: 9, loss: 1.231488
global_step: 342, epoch: 9, loss: 1.286425
global_step: 343, epoch: 9, loss: 1.241120
global_step: 344, epoch: 9, loss: 1.227594
global_step: 345, epoch: 9, loss: 1.296935
global_step: 346, epoch: 9, loss: 1.105891
global_step: 347, epoch: 9, loss: 1.254223
global_step: 348, epoch: 9, loss: 1.277862
global_step: 349, epoch: 9, loss: 1.198124
global_step: 350, epoch: 9, loss: 1.258006
global_step: 351, epoch: 9, loss: 1.322738
global_step: 352, epoch: 9, loss: 1.269417
global_step: 353, epoch: 9, loss: 1.297266
global_step: 354, epoch: 9, loss: 1.309298
global_step: 355, epoch: 9, loss: 1.254710
global_step: 356, epoch: 9, loss: 1.275154
global_step: 357, epoch: 9, loss: 1.151422
global_step: 358, epoch: 9, loss: 1.227633
global_step: 359, epoch: 9, loss: 1.248681
global_step: 360, epoch: 9, loss: 1.165579
epoch: 9
train	acc: 0.6004	macro: p 0.4304, r 0.2933, f1: 0.2956	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5368
dev	acc: 0.5284	macro: p 0.2722, r 0.2652, f1: 0.2480	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4479
test	acc: 0.5870	macro: p 0.4450, r 0.2794, f1: 0.2750	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5192
global_step: 361, epoch: 10, loss: 1.133297
global_step: 362, epoch: 10, loss: 1.148471
global_step: 363, epoch: 10, loss: 1.185363
global_step: 364, epoch: 10, loss: 1.283862
global_step: 365, epoch: 10, loss: 1.226841
global_step: 366, epoch: 10, loss: 1.187102
global_step: 367, epoch: 10, loss: 1.357438
global_step: 368, epoch: 10, loss: 1.365986
global_step: 369, epoch: 10, loss: 1.213290
global_step: 370, epoch: 10, loss: 1.293211
global_step: 371, epoch: 10, loss: 1.301100
global_step: 372, epoch: 10, loss: 1.308616
global_step: 373, epoch: 10, loss: 1.259013
global_step: 374, epoch: 10, loss: 1.203998
global_step: 375, epoch: 10, loss: 1.264878
global_step: 376, epoch: 10, loss: 1.176771
global_step: 377, epoch: 10, loss: 1.165173
global_step: 378, epoch: 10, loss: 1.217562
global_step: 379, epoch: 10, loss: 1.310544
global_step: 380, epoch: 10, loss: 1.200255
global_step: 381, epoch: 10, loss: 1.283678
global_step: 382, epoch: 10, loss: 1.248553
global_step: 383, epoch: 10, loss: 1.322474
global_step: 384, epoch: 10, loss: 1.327902
global_step: 385, epoch: 10, loss: 1.236447
global_step: 386, epoch: 10, loss: 1.293992
global_step: 387, epoch: 10, loss: 1.173076
global_step: 388, epoch: 10, loss: 1.260435
global_step: 389, epoch: 10, loss: 1.275162
global_step: 390, epoch: 10, loss: 1.211700
global_step: 391, epoch: 10, loss: 1.219455
global_step: 392, epoch: 10, loss: 1.201571
global_step: 393, epoch: 10, loss: 1.189815
global_step: 394, epoch: 10, loss: 1.248068
global_step: 395, epoch: 10, loss: 1.311194
global_step: 396, epoch: 10, loss: 1.333475
global_step: 397, epoch: 10, loss: 1.161210
global_step: 398, epoch: 10, loss: 1.273538
global_step: 399, epoch: 10, loss: 1.203964
global_step: 400, epoch: 10, loss: 2.021751
epoch: 10
train	acc: 0.6050	macro: p 0.4015, r 0.3243, f1: 0.3277	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5583
dev	acc: 0.5455	macro: p 0.3333, r 0.2967, f1: 0.2898	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4865
test	acc: 0.5877	macro: p 0.3722, r 0.3027, f1: 0.3021	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5384
New best model!
global_step: 401, epoch: 11, loss: 1.256344
global_step: 402, epoch: 11, loss: 1.232044
global_step: 403, epoch: 11, loss: 1.238167
global_step: 404, epoch: 11, loss: 1.273275
global_step: 405, epoch: 11, loss: 1.222737
global_step: 406, epoch: 11, loss: 1.205793
global_step: 407, epoch: 11, loss: 1.217664
global_step: 408, epoch: 11, loss: 1.219256
global_step: 409, epoch: 11, loss: 1.250799
global_step: 410, epoch: 11, loss: 1.255495
global_step: 411, epoch: 11, loss: 1.301608
global_step: 412, epoch: 11, loss: 1.204824
global_step: 413, epoch: 11, loss: 1.167772
global_step: 414, epoch: 11, loss: 1.298977
global_step: 415, epoch: 11, loss: 1.205755
global_step: 416, epoch: 11, loss: 1.269284
global_step: 417, epoch: 11, loss: 1.281689
global_step: 418, epoch: 11, loss: 1.111241
global_step: 419, epoch: 11, loss: 1.128854
global_step: 420, epoch: 11, loss: 1.233667
global_step: 421, epoch: 11, loss: 1.160571
global_step: 422, epoch: 11, loss: 1.163015
global_step: 423, epoch: 11, loss: 1.284609
global_step: 424, epoch: 11, loss: 1.249679
global_step: 425, epoch: 11, loss: 1.242728
global_step: 426, epoch: 11, loss: 1.319411
global_step: 427, epoch: 11, loss: 1.213006
global_step: 428, epoch: 11, loss: 1.198838
global_step: 429, epoch: 11, loss: 1.133910
global_step: 430, epoch: 11, loss: 1.226013
global_step: 431, epoch: 11, loss: 1.208087
global_step: 432, epoch: 11, loss: 1.284891
global_step: 433, epoch: 11, loss: 1.303829
global_step: 434, epoch: 11, loss: 1.120281
global_step: 435, epoch: 11, loss: 1.244204
global_step: 436, epoch: 11, loss: 1.286155
global_step: 437, epoch: 11, loss: 1.259807
global_step: 438, epoch: 11, loss: 1.143455
global_step: 439, epoch: 11, loss: 1.222269
global_step: 440, epoch: 11, loss: 0.833741
epoch: 11
train	acc: 0.6068	macro: p 0.4365, r 0.3019, f1: 0.3074	micro: p 0.6068, r 0.6068, f1 0.6068	weighted_f1:0.5463
dev	acc: 0.5392	macro: p 0.4230, r 0.2790, f1: 0.2659	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4643
test	acc: 0.5885	macro: p 0.4187, r 0.2837, f1: 0.2804	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5232
global_step: 441, epoch: 12, loss: 1.172667
global_step: 442, epoch: 12, loss: 1.203689
global_step: 443, epoch: 12, loss: 1.247195
global_step: 444, epoch: 12, loss: 1.259376
global_step: 445, epoch: 12, loss: 1.220302
global_step: 446, epoch: 12, loss: 1.212054
global_step: 447, epoch: 12, loss: 1.198205
global_step: 448, epoch: 12, loss: 1.137203
global_step: 449, epoch: 12, loss: 1.224293
global_step: 450, epoch: 12, loss: 1.219677
global_step: 451, epoch: 12, loss: 1.288892
global_step: 452, epoch: 12, loss: 1.249772
global_step: 453, epoch: 12, loss: 1.297938
global_step: 454, epoch: 12, loss: 1.305029
global_step: 455, epoch: 12, loss: 1.129478
global_step: 456, epoch: 12, loss: 1.181457
global_step: 457, epoch: 12, loss: 1.161664
global_step: 458, epoch: 12, loss: 1.179322
global_step: 459, epoch: 12, loss: 1.178676
global_step: 460, epoch: 12, loss: 1.289849
global_step: 461, epoch: 12, loss: 1.210600
global_step: 462, epoch: 12, loss: 1.192705
global_step: 463, epoch: 12, loss: 1.074778
global_step: 464, epoch: 12, loss: 1.179045
global_step: 465, epoch: 12, loss: 1.226925
global_step: 466, epoch: 12, loss: 1.130939
global_step: 467, epoch: 12, loss: 1.246109
global_step: 468, epoch: 12, loss: 1.222150
global_step: 469, epoch: 12, loss: 1.208021
global_step: 470, epoch: 12, loss: 1.201883
global_step: 471, epoch: 12, loss: 1.288521
global_step: 472, epoch: 12, loss: 1.201156
global_step: 473, epoch: 12, loss: 1.245818
global_step: 474, epoch: 12, loss: 1.138901
global_step: 475, epoch: 12, loss: 1.249681
global_step: 476, epoch: 12, loss: 1.147057
global_step: 477, epoch: 12, loss: 1.209462
global_step: 478, epoch: 12, loss: 1.267202
global_step: 479, epoch: 12, loss: 1.265957
global_step: 480, epoch: 12, loss: 1.383507
epoch: 12
train	acc: 0.6188	macro: p 0.4197, r 0.3294, f1: 0.3395	micro: p 0.6188, r 0.6188, f1 0.6188	weighted_f1:0.5699
dev	acc: 0.5455	macro: p 0.3394, r 0.2934, f1: 0.2890	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4851
test	acc: 0.5927	macro: p 0.3718, r 0.2989, f1: 0.3034	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5398
global_step: 481, epoch: 13, loss: 1.295606
global_step: 482, epoch: 13, loss: 1.140138
global_step: 483, epoch: 13, loss: 1.197533
global_step: 484, epoch: 13, loss: 1.247972
global_step: 485, epoch: 13, loss: 1.215543
global_step: 486, epoch: 13, loss: 1.173602
global_step: 487, epoch: 13, loss: 1.178244
global_step: 488, epoch: 13, loss: 1.210536
global_step: 489, epoch: 13, loss: 1.211546
global_step: 490, epoch: 13, loss: 1.256303
global_step: 491, epoch: 13, loss: 1.299631
global_step: 492, epoch: 13, loss: 1.157954
global_step: 493, epoch: 13, loss: 1.154046
global_step: 494, epoch: 13, loss: 1.161169
global_step: 495, epoch: 13, loss: 1.174567
global_step: 496, epoch: 13, loss: 1.343176
global_step: 497, epoch: 13, loss: 1.335871
global_step: 498, epoch: 13, loss: 1.154390
global_step: 499, epoch: 13, loss: 1.181549
global_step: 500, epoch: 13, loss: 1.246724
global_step: 501, epoch: 13, loss: 1.155680
global_step: 502, epoch: 13, loss: 1.264991
global_step: 503, epoch: 13, loss: 1.153305
global_step: 504, epoch: 13, loss: 1.139465
global_step: 505, epoch: 13, loss: 1.086977
global_step: 506, epoch: 13, loss: 1.268565
global_step: 507, epoch: 13, loss: 1.192094
global_step: 508, epoch: 13, loss: 1.227359
global_step: 509, epoch: 13, loss: 1.262139
global_step: 510, epoch: 13, loss: 1.154851
global_step: 511, epoch: 13, loss: 1.134363
global_step: 512, epoch: 13, loss: 1.194544
global_step: 513, epoch: 13, loss: 1.194953
global_step: 514, epoch: 13, loss: 1.229395
global_step: 515, epoch: 13, loss: 1.121272
global_step: 516, epoch: 13, loss: 1.261860
global_step: 517, epoch: 13, loss: 1.292728
global_step: 518, epoch: 13, loss: 1.205852
global_step: 519, epoch: 13, loss: 1.125501
global_step: 520, epoch: 13, loss: 2.174829
epoch: 13
train	acc: 0.6259	macro: p 0.4183, r 0.3337, f1: 0.3445	micro: p 0.6259, r 0.6259, f1 0.6259	weighted_f1:0.5772
dev	acc: 0.5374	macro: p 0.3301, r 0.2863, f1: 0.2727	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4710
test	acc: 0.5954	macro: p 0.3733, r 0.3013, f1: 0.3012	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5392
global_step: 521, epoch: 14, loss: 1.275765
global_step: 522, epoch: 14, loss: 1.306340
global_step: 523, epoch: 14, loss: 1.278424
global_step: 524, epoch: 14, loss: 1.157033
global_step: 525, epoch: 14, loss: 1.126331
global_step: 526, epoch: 14, loss: 1.279777
global_step: 527, epoch: 14, loss: 1.090960
global_step: 528, epoch: 14, loss: 1.287241
global_step: 529, epoch: 14, loss: 1.066697
global_step: 530, epoch: 14, loss: 1.233444
global_step: 531, epoch: 14, loss: 1.212469
global_step: 532, epoch: 14, loss: 1.122127
global_step: 533, epoch: 14, loss: 1.175249
global_step: 534, epoch: 14, loss: 1.132743
global_step: 535, epoch: 14, loss: 1.199404
global_step: 536, epoch: 14, loss: 1.334029
global_step: 537, epoch: 14, loss: 1.254350
global_step: 538, epoch: 14, loss: 1.249774
global_step: 539, epoch: 14, loss: 1.135918
global_step: 540, epoch: 14, loss: 1.265451
global_step: 541, epoch: 14, loss: 1.171209
global_step: 542, epoch: 14, loss: 1.176953
global_step: 543, epoch: 14, loss: 1.145112
global_step: 544, epoch: 14, loss: 1.202535
global_step: 545, epoch: 14, loss: 1.205069
global_step: 546, epoch: 14, loss: 1.212027
global_step: 547, epoch: 14, loss: 1.089853
global_step: 548, epoch: 14, loss: 1.201461
global_step: 549, epoch: 14, loss: 1.151509
global_step: 550, epoch: 14, loss: 1.384659
global_step: 551, epoch: 14, loss: 1.250415
global_step: 552, epoch: 14, loss: 1.193725
global_step: 553, epoch: 14, loss: 1.188703
global_step: 554, epoch: 14, loss: 1.240986
global_step: 555, epoch: 14, loss: 1.017900
global_step: 556, epoch: 14, loss: 1.220524
global_step: 557, epoch: 14, loss: 1.181361
global_step: 558, epoch: 14, loss: 1.050244
global_step: 559, epoch: 14, loss: 1.051771
global_step: 560, epoch: 14, loss: 0.439958
epoch: 14
train	acc: 0.6181	macro: p 0.4510, r 0.3148, f1: 0.3257	micro: p 0.6181, r 0.6181, f1 0.6181	weighted_f1:0.5610
dev	acc: 0.5365	macro: p 0.3425, r 0.2776, f1: 0.2636	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4615
test	acc: 0.5916	macro: p 0.4030, r 0.2877, f1: 0.2857	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5259
global_step: 561, epoch: 15, loss: 1.253499
global_step: 562, epoch: 15, loss: 1.185573
global_step: 563, epoch: 15, loss: 1.116687
global_step: 564, epoch: 15, loss: 1.103104
global_step: 565, epoch: 15, loss: 1.243147
global_step: 566, epoch: 15, loss: 1.129210
global_step: 567, epoch: 15, loss: 1.190493
global_step: 568, epoch: 15, loss: 1.296218
global_step: 569, epoch: 15, loss: 1.096168
global_step: 570, epoch: 15, loss: 1.234961
global_step: 571, epoch: 15, loss: 1.134679
global_step: 572, epoch: 15, loss: 1.326803
global_step: 573, epoch: 15, loss: 1.234084
global_step: 574, epoch: 15, loss: 1.192488
global_step: 575, epoch: 15, loss: 1.245226
global_step: 576, epoch: 15, loss: 1.049297
global_step: 577, epoch: 15, loss: 1.124235
global_step: 578, epoch: 15, loss: 1.198344
global_step: 579, epoch: 15, loss: 1.217566
global_step: 580, epoch: 15, loss: 1.247964
global_step: 581, epoch: 15, loss: 1.219463
global_step: 582, epoch: 15, loss: 1.213852
global_step: 583, epoch: 15, loss: 1.133919
global_step: 584, epoch: 15, loss: 1.185658
global_step: 585, epoch: 15, loss: 1.173527
global_step: 586, epoch: 15, loss: 1.132203
global_step: 587, epoch: 15, loss: 1.102431
global_step: 588, epoch: 15, loss: 1.092406
global_step: 589, epoch: 15, loss: 1.218545
global_step: 590, epoch: 15, loss: 1.168189
global_step: 591, epoch: 15, loss: 1.225318
global_step: 592, epoch: 15, loss: 1.122306
global_step: 593, epoch: 15, loss: 1.134448
global_step: 594, epoch: 15, loss: 1.149159
global_step: 595, epoch: 15, loss: 1.222750
global_step: 596, epoch: 15, loss: 1.129980
global_step: 597, epoch: 15, loss: 1.278817
global_step: 598, epoch: 15, loss: 1.088635
global_step: 599, epoch: 15, loss: 1.269479
global_step: 600, epoch: 15, loss: 1.331604
epoch: 15
train	acc: 0.6286	macro: p 0.4364, r 0.3330, f1: 0.3398	micro: p 0.6286, r 0.6286, f1 0.6286	weighted_f1:0.5765
dev	acc: 0.5383	macro: p 0.3352, r 0.2878, f1: 0.2666	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4658
test	acc: 0.5923	macro: p 0.3731, r 0.2998, f1: 0.2928	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5317
global_step: 601, epoch: 16, loss: 1.179030
global_step: 602, epoch: 16, loss: 1.088188
global_step: 603, epoch: 16, loss: 1.167688
global_step: 604, epoch: 16, loss: 1.162511
global_step: 605, epoch: 16, loss: 1.311612
global_step: 606, epoch: 16, loss: 1.194438
global_step: 607, epoch: 16, loss: 1.218970
global_step: 608, epoch: 16, loss: 1.148060
global_step: 609, epoch: 16, loss: 1.213478
global_step: 610, epoch: 16, loss: 1.206009
global_step: 611, epoch: 16, loss: 1.199235
global_step: 612, epoch: 16, loss: 1.116631
global_step: 613, epoch: 16, loss: 1.148307
global_step: 614, epoch: 16, loss: 1.195554
global_step: 615, epoch: 16, loss: 1.128210
global_step: 616, epoch: 16, loss: 1.110064
global_step: 617, epoch: 16, loss: 1.142394
global_step: 618, epoch: 16, loss: 1.180525
global_step: 619, epoch: 16, loss: 1.084129
global_step: 620, epoch: 16, loss: 1.184318
global_step: 621, epoch: 16, loss: 1.092724
global_step: 622, epoch: 16, loss: 1.203936
global_step: 623, epoch: 16, loss: 1.180350
global_step: 624, epoch: 16, loss: 1.123738
global_step: 625, epoch: 16, loss: 1.057333
global_step: 626, epoch: 16, loss: 1.174074
global_step: 627, epoch: 16, loss: 1.179141
global_step: 628, epoch: 16, loss: 1.195025
global_step: 629, epoch: 16, loss: 1.165955
global_step: 630, epoch: 16, loss: 1.170515
global_step: 631, epoch: 16, loss: 1.135885
global_step: 632, epoch: 16, loss: 1.224687
global_step: 633, epoch: 16, loss: 1.158645
global_step: 634, epoch: 16, loss: 1.207831
global_step: 635, epoch: 16, loss: 1.190084
global_step: 636, epoch: 16, loss: 1.151983
global_step: 637, epoch: 16, loss: 1.126579
global_step: 638, epoch: 16, loss: 1.194831
global_step: 639, epoch: 16, loss: 1.089112
global_step: 640, epoch: 16, loss: 1.443709
epoch: 16
train	acc: 0.6371	macro: p 0.4376, r 0.3468, f1: 0.3571	micro: p 0.6371, r 0.6371, f1 0.6371	weighted_f1:0.5906
dev	acc: 0.5437	macro: p 0.3371, r 0.2916, f1: 0.2845	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4827
test	acc: 0.5992	macro: p 0.3786, r 0.3056, f1: 0.3091	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5472
global_step: 641, epoch: 17, loss: 1.109412
global_step: 642, epoch: 17, loss: 1.098156
global_step: 643, epoch: 17, loss: 1.152459
global_step: 644, epoch: 17, loss: 1.123516
global_step: 645, epoch: 17, loss: 1.142383
global_step: 646, epoch: 17, loss: 1.118369
global_step: 647, epoch: 17, loss: 1.129102
global_step: 648, epoch: 17, loss: 1.268584
global_step: 649, epoch: 17, loss: 1.167562
global_step: 650, epoch: 17, loss: 1.068480
global_step: 651, epoch: 17, loss: 1.131917
global_step: 652, epoch: 17, loss: 1.061208
global_step: 653, epoch: 17, loss: 1.148700
global_step: 654, epoch: 17, loss: 1.150906
global_step: 655, epoch: 17, loss: 1.261421
global_step: 656, epoch: 17, loss: 1.135063
global_step: 657, epoch: 17, loss: 1.179393
global_step: 658, epoch: 17, loss: 1.081954
global_step: 659, epoch: 17, loss: 1.130401
global_step: 660, epoch: 17, loss: 1.195537
global_step: 661, epoch: 17, loss: 1.100161
global_step: 662, epoch: 17, loss: 1.120407
global_step: 663, epoch: 17, loss: 1.166684
global_step: 664, epoch: 17, loss: 1.105794
global_step: 665, epoch: 17, loss: 1.090774
global_step: 666, epoch: 17, loss: 1.177609
global_step: 667, epoch: 17, loss: 1.282727
global_step: 668, epoch: 17, loss: 1.162838
global_step: 669, epoch: 17, loss: 1.182970
global_step: 670, epoch: 17, loss: 1.212524
global_step: 671, epoch: 17, loss: 1.176513
global_step: 672, epoch: 17, loss: 1.175166
global_step: 673, epoch: 17, loss: 1.232081
global_step: 674, epoch: 17, loss: 1.122303
global_step: 675, epoch: 17, loss: 1.060001
global_step: 676, epoch: 17, loss: 1.032555
global_step: 677, epoch: 17, loss: 1.169421
global_step: 678, epoch: 17, loss: 1.157091
global_step: 679, epoch: 17, loss: 1.110414
global_step: 680, epoch: 17, loss: 0.324190
epoch: 17
train	acc: 0.6344	macro: p 0.4550, r 0.3348, f1: 0.3485	micro: p 0.6344, r 0.6344, f1 0.6344	weighted_f1:0.5822
dev	acc: 0.5419	macro: p 0.3468, r 0.2843, f1: 0.2738	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4711
test	acc: 0.5958	macro: p 0.3807, r 0.2974, f1: 0.2993	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5365
global_step: 681, epoch: 18, loss: 1.097064
global_step: 682, epoch: 18, loss: 1.305529
global_step: 683, epoch: 18, loss: 1.169342
global_step: 684, epoch: 18, loss: 1.166868
global_step: 685, epoch: 18, loss: 1.165055
global_step: 686, epoch: 18, loss: 1.105559
global_step: 687, epoch: 18, loss: 1.034991
global_step: 688, epoch: 18, loss: 1.168326
global_step: 689, epoch: 18, loss: 1.184542
global_step: 690, epoch: 18, loss: 1.063039
global_step: 691, epoch: 18, loss: 1.148967
global_step: 692, epoch: 18, loss: 1.081024
global_step: 693, epoch: 18, loss: 1.151988
global_step: 694, epoch: 18, loss: 1.181599
global_step: 695, epoch: 18, loss: 1.083961
global_step: 696, epoch: 18, loss: 1.057019
global_step: 697, epoch: 18, loss: 1.137630
global_step: 698, epoch: 18, loss: 1.218531
global_step: 699, epoch: 18, loss: 1.090109
global_step: 700, epoch: 18, loss: 1.169968
global_step: 701, epoch: 18, loss: 1.194192
global_step: 702, epoch: 18, loss: 1.051958
global_step: 703, epoch: 18, loss: 1.180202
global_step: 704, epoch: 18, loss: 1.154440
global_step: 705, epoch: 18, loss: 1.202534
global_step: 706, epoch: 18, loss: 1.149066
global_step: 707, epoch: 18, loss: 1.112790
global_step: 708, epoch: 18, loss: 1.177648
global_step: 709, epoch: 18, loss: 1.191779
global_step: 710, epoch: 18, loss: 1.184339
global_step: 711, epoch: 18, loss: 1.221627
global_step: 712, epoch: 18, loss: 1.149983
global_step: 713, epoch: 18, loss: 1.082599
global_step: 714, epoch: 18, loss: 1.115414
global_step: 715, epoch: 18, loss: 1.081910
global_step: 716, epoch: 18, loss: 1.028348
global_step: 717, epoch: 18, loss: 1.095042
global_step: 718, epoch: 18, loss: 1.170409
global_step: 719, epoch: 18, loss: 1.148674
global_step: 720, epoch: 18, loss: 1.205061
epoch: 18
train	acc: 0.6551	macro: p 0.4439, r 0.3701, f1: 0.3836	micro: p 0.6551, r 0.6551, f1 0.6551	weighted_f1:0.6136
dev	acc: 0.5482	macro: p 0.3409, r 0.3007, f1: 0.2931	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4902
test	acc: 0.6000	macro: p 0.3727, r 0.3112, f1: 0.3142	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5498
New best model!
global_step: 721, epoch: 19, loss: 1.113743
global_step: 722, epoch: 19, loss: 1.156667
global_step: 723, epoch: 19, loss: 1.207824
global_step: 724, epoch: 19, loss: 1.131938
global_step: 725, epoch: 19, loss: 1.046719
global_step: 726, epoch: 19, loss: 1.170939
global_step: 727, epoch: 19, loss: 1.068130
global_step: 728, epoch: 19, loss: 0.986013
global_step: 729, epoch: 19, loss: 0.979932
global_step: 730, epoch: 19, loss: 1.089080
global_step: 731, epoch: 19, loss: 1.152103
global_step: 732, epoch: 19, loss: 1.177595
global_step: 733, epoch: 19, loss: 1.064798
global_step: 734, epoch: 19, loss: 1.097467
global_step: 735, epoch: 19, loss: 1.226235
global_step: 736, epoch: 19, loss: 1.173627
global_step: 737, epoch: 19, loss: 1.166216
global_step: 738, epoch: 19, loss: 1.244281
global_step: 739, epoch: 19, loss: 1.043078
global_step: 740, epoch: 19, loss: 1.072964
global_step: 741, epoch: 19, loss: 1.119582
global_step: 742, epoch: 19, loss: 1.202488
global_step: 743, epoch: 19, loss: 1.123290
global_step: 744, epoch: 19, loss: 1.154719
global_step: 745, epoch: 19, loss: 1.042875
global_step: 746, epoch: 19, loss: 1.163245
global_step: 747, epoch: 19, loss: 1.043999
global_step: 748, epoch: 19, loss: 1.023029
global_step: 749, epoch: 19, loss: 1.101151
global_step: 750, epoch: 19, loss: 1.064384
global_step: 751, epoch: 19, loss: 1.049488
global_step: 752, epoch: 19, loss: 1.078956
global_step: 753, epoch: 19, loss: 1.210500
global_step: 754, epoch: 19, loss: 1.098331
global_step: 755, epoch: 19, loss: 1.105556
global_step: 756, epoch: 19, loss: 1.187105
global_step: 757, epoch: 19, loss: 1.104424
global_step: 758, epoch: 19, loss: 1.068017
global_step: 759, epoch: 19, loss: 1.160410
global_step: 760, epoch: 19, loss: 1.515089
epoch: 19
train	acc: 0.6578	macro: p 0.4510, r 0.3677, f1: 0.3791	micro: p 0.6578, r 0.6578, f1 0.6578	weighted_f1:0.6135
dev	acc: 0.5464	macro: p 0.3398, r 0.2968, f1: 0.2834	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4824
test	acc: 0.5996	macro: p 0.3756, r 0.3109, f1: 0.3102	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5464
global_step: 761, epoch: 20, loss: 1.254043
global_step: 762, epoch: 20, loss: 1.087418
global_step: 763, epoch: 20, loss: 1.092311
global_step: 764, epoch: 20, loss: 1.011440
global_step: 765, epoch: 20, loss: 1.200607
global_step: 766, epoch: 20, loss: 1.087450
global_step: 767, epoch: 20, loss: 0.995481
global_step: 768, epoch: 20, loss: 1.069100
global_step: 769, epoch: 20, loss: 1.074259
global_step: 770, epoch: 20, loss: 1.143895
global_step: 771, epoch: 20, loss: 1.152316
global_step: 772, epoch: 20, loss: 1.253962
global_step: 773, epoch: 20, loss: 1.120080
global_step: 774, epoch: 20, loss: 1.069418
global_step: 775, epoch: 20, loss: 1.085598
global_step: 776, epoch: 20, loss: 1.086199
global_step: 777, epoch: 20, loss: 1.091462
global_step: 778, epoch: 20, loss: 1.113786
global_step: 779, epoch: 20, loss: 1.102296
global_step: 780, epoch: 20, loss: 1.059845
global_step: 781, epoch: 20, loss: 1.040924
global_step: 782, epoch: 20, loss: 1.149625
global_step: 783, epoch: 20, loss: 1.191766
global_step: 784, epoch: 20, loss: 1.138133
global_step: 785, epoch: 20, loss: 1.082899
global_step: 786, epoch: 20, loss: 1.051775
global_step: 787, epoch: 20, loss: 1.121742
global_step: 788, epoch: 20, loss: 1.194734
global_step: 789, epoch: 20, loss: 1.123549
global_step: 790, epoch: 20, loss: 1.086121
global_step: 791, epoch: 20, loss: 1.089255
global_step: 792, epoch: 20, loss: 1.167931
global_step: 793, epoch: 20, loss: 1.116577
global_step: 794, epoch: 20, loss: 1.029944
global_step: 795, epoch: 20, loss: 1.266084
global_step: 796, epoch: 20, loss: 1.025548
global_step: 797, epoch: 20, loss: 1.065433
global_step: 798, epoch: 20, loss: 1.127355
global_step: 799, epoch: 20, loss: 1.040932
global_step: 800, epoch: 20, loss: 1.296787
epoch: 20
train	acc: 0.6704	macro: p 0.4531, r 0.3896, f1: 0.4014	micro: p 0.6704, r 0.6704, f1 0.6704	weighted_f1:0.6331
dev	acc: 0.5446	macro: p 0.3346, r 0.2998, f1: 0.2856	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4848
test	acc: 0.5943	macro: p 0.3602, r 0.3138, f1: 0.3116	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5467
global_step: 801, epoch: 21, loss: 0.975269
global_step: 802, epoch: 21, loss: 1.107779
global_step: 803, epoch: 21, loss: 1.166743
global_step: 804, epoch: 21, loss: 1.220698
global_step: 805, epoch: 21, loss: 1.185275
global_step: 806, epoch: 21, loss: 1.078250
global_step: 807, epoch: 21, loss: 1.041426
global_step: 808, epoch: 21, loss: 1.079751
global_step: 809, epoch: 21, loss: 1.060888
global_step: 810, epoch: 21, loss: 1.134434
global_step: 811, epoch: 21, loss: 1.039789
global_step: 812, epoch: 21, loss: 1.132420
global_step: 813, epoch: 21, loss: 1.070169
global_step: 814, epoch: 21, loss: 1.110179
global_step: 815, epoch: 21, loss: 1.146793
global_step: 816, epoch: 21, loss: 1.049534
global_step: 817, epoch: 21, loss: 1.200388
global_step: 818, epoch: 21, loss: 1.008912
global_step: 819, epoch: 21, loss: 1.041898
global_step: 820, epoch: 21, loss: 1.046407
global_step: 821, epoch: 21, loss: 1.040692
global_step: 822, epoch: 21, loss: 1.105339
global_step: 823, epoch: 21, loss: 1.171378
global_step: 824, epoch: 21, loss: 1.089611
global_step: 825, epoch: 21, loss: 1.098098
global_step: 826, epoch: 21, loss: 1.072149
global_step: 827, epoch: 21, loss: 1.100346
global_step: 828, epoch: 21, loss: 1.045557
global_step: 829, epoch: 21, loss: 1.064011
global_step: 830, epoch: 21, loss: 1.095474
global_step: 831, epoch: 21, loss: 1.030974
global_step: 832, epoch: 21, loss: 1.108165
global_step: 833, epoch: 21, loss: 1.114757
global_step: 834, epoch: 21, loss: 1.116527
global_step: 835, epoch: 21, loss: 1.097076
global_step: 836, epoch: 21, loss: 1.137307
global_step: 837, epoch: 21, loss: 1.101846
global_step: 838, epoch: 21, loss: 1.013263
global_step: 839, epoch: 21, loss: 1.067548
global_step: 840, epoch: 21, loss: 1.071555
epoch: 21
train	acc: 0.6794	macro: p 0.4580, r 0.4043, f1: 0.4055	micro: p 0.6794, r 0.6794, f1 0.6794	weighted_f1:0.6392
dev	acc: 0.5383	macro: p 0.3159, r 0.2984, f1: 0.2780	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4755
test	acc: 0.5927	macro: p 0.3577, r 0.3182, f1: 0.3069	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5422
global_step: 841, epoch: 22, loss: 1.133033
global_step: 842, epoch: 22, loss: 1.039140
global_step: 843, epoch: 22, loss: 0.973337
global_step: 844, epoch: 22, loss: 1.137228
global_step: 845, epoch: 22, loss: 1.098762
global_step: 846, epoch: 22, loss: 1.070875
global_step: 847, epoch: 22, loss: 1.071730
global_step: 848, epoch: 22, loss: 1.133881
global_step: 849, epoch: 22, loss: 1.113006
global_step: 850, epoch: 22, loss: 1.091351
global_step: 851, epoch: 22, loss: 0.986494
global_step: 852, epoch: 22, loss: 1.118271
global_step: 853, epoch: 22, loss: 1.066248
global_step: 854, epoch: 22, loss: 1.148111
global_step: 855, epoch: 22, loss: 1.096868
global_step: 856, epoch: 22, loss: 1.104516
global_step: 857, epoch: 22, loss: 1.098548
global_step: 858, epoch: 22, loss: 1.082619
global_step: 859, epoch: 22, loss: 1.113524
global_step: 860, epoch: 22, loss: 1.067747
global_step: 861, epoch: 22, loss: 1.081645
global_step: 862, epoch: 22, loss: 1.108323
global_step: 863, epoch: 22, loss: 1.115645
global_step: 864, epoch: 22, loss: 1.043606
global_step: 865, epoch: 22, loss: 1.027269
global_step: 866, epoch: 22, loss: 0.989555
global_step: 867, epoch: 22, loss: 1.093285
global_step: 868, epoch: 22, loss: 1.093748
global_step: 869, epoch: 22, loss: 1.120910
global_step: 870, epoch: 22, loss: 1.105282
global_step: 871, epoch: 22, loss: 1.150272
global_step: 872, epoch: 22, loss: 0.989221
global_step: 873, epoch: 22, loss: 1.125192
global_step: 874, epoch: 22, loss: 1.016620
global_step: 875, epoch: 22, loss: 1.053514
global_step: 876, epoch: 22, loss: 1.060880
global_step: 877, epoch: 22, loss: 1.190682
global_step: 878, epoch: 22, loss: 1.024206
global_step: 879, epoch: 22, loss: 1.052868
global_step: 880, epoch: 22, loss: 0.446104
epoch: 22
train	acc: 0.6773	macro: p 0.4652, r 0.3917, f1: 0.4022	micro: p 0.6773, r 0.6773, f1 0.6773	weighted_f1:0.6362
dev	acc: 0.5374	macro: p 0.3218, r 0.2930, f1: 0.2754	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4721
test	acc: 0.6000	macro: p 0.3708, r 0.3146, f1: 0.3119	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5480
global_step: 881, epoch: 23, loss: 1.099577
global_step: 882, epoch: 23, loss: 1.047588
global_step: 883, epoch: 23, loss: 1.087620
global_step: 884, epoch: 23, loss: 1.013106
global_step: 885, epoch: 23, loss: 1.111684
global_step: 886, epoch: 23, loss: 1.084687
global_step: 887, epoch: 23, loss: 1.073588
global_step: 888, epoch: 23, loss: 1.002797
global_step: 889, epoch: 23, loss: 1.032709
global_step: 890, epoch: 23, loss: 1.105858
global_step: 891, epoch: 23, loss: 1.087158
global_step: 892, epoch: 23, loss: 1.057124
global_step: 893, epoch: 23, loss: 1.001372
global_step: 894, epoch: 23, loss: 1.169171
global_step: 895, epoch: 23, loss: 1.002103
global_step: 896, epoch: 23, loss: 1.130274
global_step: 897, epoch: 23, loss: 0.980589
global_step: 898, epoch: 23, loss: 1.000615
global_step: 899, epoch: 23, loss: 1.065312
global_step: 900, epoch: 23, loss: 1.014358
global_step: 901, epoch: 23, loss: 0.958521
global_step: 902, epoch: 23, loss: 1.071427
global_step: 903, epoch: 23, loss: 1.197355
global_step: 904, epoch: 23, loss: 1.087793
global_step: 905, epoch: 23, loss: 1.059776
global_step: 906, epoch: 23, loss: 1.070643
global_step: 907, epoch: 23, loss: 1.064786
global_step: 908, epoch: 23, loss: 1.040186
global_step: 909, epoch: 23, loss: 1.118438
global_step: 910, epoch: 23, loss: 1.004582
global_step: 911, epoch: 23, loss: 1.068493
global_step: 912, epoch: 23, loss: 1.047307
global_step: 913, epoch: 23, loss: 1.097637
global_step: 914, epoch: 23, loss: 1.023276
global_step: 915, epoch: 23, loss: 1.096846
global_step: 916, epoch: 23, loss: 0.993974
global_step: 917, epoch: 23, loss: 1.198480
global_step: 918, epoch: 23, loss: 1.044913
global_step: 919, epoch: 23, loss: 1.004401
global_step: 920, epoch: 23, loss: 1.311341
epoch: 23
train	acc: 0.6937	macro: p 0.4726, r 0.4132, f1: 0.4220	micro: p 0.6937, r 0.6937, f1 0.6937	weighted_f1:0.6566
dev	acc: 0.5419	macro: p 0.3340, r 0.3000, f1: 0.2899	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4864
test	acc: 0.6004	macro: p 0.3694, r 0.3182, f1: 0.3180	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5539
global_step: 921, epoch: 24, loss: 1.040661
global_step: 922, epoch: 24, loss: 1.082586
global_step: 923, epoch: 24, loss: 1.220851
global_step: 924, epoch: 24, loss: 1.071437
global_step: 925, epoch: 24, loss: 1.091232
global_step: 926, epoch: 24, loss: 1.153400
global_step: 927, epoch: 24, loss: 0.984526
global_step: 928, epoch: 24, loss: 1.046730
global_step: 929, epoch: 24, loss: 1.042661
global_step: 930, epoch: 24, loss: 1.009632
global_step: 931, epoch: 24, loss: 0.990379
global_step: 932, epoch: 24, loss: 1.114159
global_step: 933, epoch: 24, loss: 1.103971
global_step: 934, epoch: 24, loss: 1.065305
global_step: 935, epoch: 24, loss: 1.001342
global_step: 936, epoch: 24, loss: 1.047602
global_step: 937, epoch: 24, loss: 0.967980
global_step: 938, epoch: 24, loss: 1.126585
global_step: 939, epoch: 24, loss: 1.182486
global_step: 940, epoch: 24, loss: 1.006344
global_step: 941, epoch: 24, loss: 0.987169
global_step: 942, epoch: 24, loss: 1.000614
global_step: 943, epoch: 24, loss: 0.999980
global_step: 944, epoch: 24, loss: 1.115083
global_step: 945, epoch: 24, loss: 1.006344
global_step: 946, epoch: 24, loss: 1.083196
global_step: 947, epoch: 24, loss: 1.085863
global_step: 948, epoch: 24, loss: 0.985047
global_step: 949, epoch: 24, loss: 0.999167
global_step: 950, epoch: 24, loss: 1.021604
global_step: 951, epoch: 24, loss: 0.965796
global_step: 952, epoch: 24, loss: 0.884801
global_step: 953, epoch: 24, loss: 0.899721
global_step: 954, epoch: 24, loss: 1.041825
global_step: 955, epoch: 24, loss: 1.137091
global_step: 956, epoch: 24, loss: 1.049260
global_step: 957, epoch: 24, loss: 1.012305
global_step: 958, epoch: 24, loss: 1.060444
global_step: 959, epoch: 24, loss: 1.057501
global_step: 960, epoch: 24, loss: 1.192441
epoch: 24
train	acc: 0.6968	macro: p 0.4778, r 0.4167, f1: 0.4265	micro: p 0.6968, r 0.6968, f1 0.6968	weighted_f1:0.6589
dev	acc: 0.5392	macro: p 0.3246, r 0.2963, f1: 0.2827	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4794
test	acc: 0.6023	macro: p 0.3704, r 0.3198, f1: 0.3182	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5532
global_step: 961, epoch: 25, loss: 1.027012
global_step: 962, epoch: 25, loss: 1.111332
global_step: 963, epoch: 25, loss: 1.073465
global_step: 964, epoch: 25, loss: 1.024228
global_step: 965, epoch: 25, loss: 1.049116
global_step: 966, epoch: 25, loss: 1.105502
global_step: 967, epoch: 25, loss: 1.029593
global_step: 968, epoch: 25, loss: 1.103922
global_step: 969, epoch: 25, loss: 0.973252
global_step: 970, epoch: 25, loss: 1.159364
global_step: 971, epoch: 25, loss: 1.020913
global_step: 972, epoch: 25, loss: 1.079900
global_step: 973, epoch: 25, loss: 1.057789
global_step: 974, epoch: 25, loss: 1.125918
global_step: 975, epoch: 25, loss: 1.056897
global_step: 976, epoch: 25, loss: 1.046534
global_step: 977, epoch: 25, loss: 0.972347
global_step: 978, epoch: 25, loss: 0.970090
global_step: 979, epoch: 25, loss: 0.976706
global_step: 980, epoch: 25, loss: 0.920925
global_step: 981, epoch: 25, loss: 1.081425
global_step: 982, epoch: 25, loss: 1.048902
global_step: 983, epoch: 25, loss: 0.995740
global_step: 984, epoch: 25, loss: 1.083996
global_step: 985, epoch: 25, loss: 1.049204
global_step: 986, epoch: 25, loss: 1.021652
global_step: 987, epoch: 25, loss: 0.952859
global_step: 988, epoch: 25, loss: 1.068208
global_step: 989, epoch: 25, loss: 1.017166
global_step: 990, epoch: 25, loss: 1.030628
global_step: 991, epoch: 25, loss: 0.960368
global_step: 992, epoch: 25, loss: 1.081324
global_step: 993, epoch: 25, loss: 1.009101
global_step: 994, epoch: 25, loss: 1.029608
global_step: 995, epoch: 25, loss: 1.054422
global_step: 996, epoch: 25, loss: 0.975681
global_step: 997, epoch: 25, loss: 0.962638
global_step: 998, epoch: 25, loss: 1.023536
global_step: 999, epoch: 25, loss: 1.004964
global_step: 1000, epoch: 25, loss: 0.838481
epoch: 25
train	acc: 0.6860	macro: p 0.4836, r 0.3963, f1: 0.4069	micro: p 0.6860, r 0.6860, f1 0.6860	weighted_f1:0.6424
dev	acc: 0.5482	macro: p 0.3502, r 0.2993, f1: 0.2901	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4866
test	acc: 0.6031	macro: p 0.3722, r 0.3113, f1: 0.3112	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5496
global_step: 1001, epoch: 26, loss: 0.972519
global_step: 1002, epoch: 26, loss: 1.028606
global_step: 1003, epoch: 26, loss: 1.086630
global_step: 1004, epoch: 26, loss: 0.950956
global_step: 1005, epoch: 26, loss: 1.123375
global_step: 1006, epoch: 26, loss: 1.006929
global_step: 1007, epoch: 26, loss: 1.109562
global_step: 1008, epoch: 26, loss: 1.076093
global_step: 1009, epoch: 26, loss: 1.014012
global_step: 1010, epoch: 26, loss: 0.973317
global_step: 1011, epoch: 26, loss: 0.898771
global_step: 1012, epoch: 26, loss: 0.946303
global_step: 1013, epoch: 26, loss: 1.047945
global_step: 1014, epoch: 26, loss: 1.080679
global_step: 1015, epoch: 26, loss: 1.078122
global_step: 1016, epoch: 26, loss: 1.063458
global_step: 1017, epoch: 26, loss: 0.987041
global_step: 1018, epoch: 26, loss: 0.993099
global_step: 1019, epoch: 26, loss: 0.972845
global_step: 1020, epoch: 26, loss: 1.061742
global_step: 1021, epoch: 26, loss: 1.068446
global_step: 1022, epoch: 26, loss: 1.017759
global_step: 1023, epoch: 26, loss: 1.072707
global_step: 1024, epoch: 26, loss: 0.958477
global_step: 1025, epoch: 26, loss: 1.005178
global_step: 1026, epoch: 26, loss: 0.937880
global_step: 1027, epoch: 26, loss: 1.006545
global_step: 1028, epoch: 26, loss: 1.051761
global_step: 1029, epoch: 26, loss: 1.029488
global_step: 1030, epoch: 26, loss: 0.959691
global_step: 1031, epoch: 26, loss: 1.078304
global_step: 1032, epoch: 26, loss: 0.987042
global_step: 1033, epoch: 26, loss: 0.972723
global_step: 1034, epoch: 26, loss: 0.938954
global_step: 1035, epoch: 26, loss: 1.055830
global_step: 1036, epoch: 26, loss: 1.068535
global_step: 1037, epoch: 26, loss: 0.976269
global_step: 1038, epoch: 26, loss: 0.937049
global_step: 1039, epoch: 26, loss: 1.147582
global_step: 1040, epoch: 26, loss: 1.747820
epoch: 26
train	acc: 0.7112	macro: p 0.4888, r 0.4353, f1: 0.4482	micro: p 0.7112, r 0.7112, f1 0.7112	weighted_f1:0.6764
dev	acc: 0.5464	macro: p 0.3285, r 0.3006, f1: 0.2920	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4887
test	acc: 0.6050	macro: p 0.3694, r 0.3211, f1: 0.3228	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5567
global_step: 1041, epoch: 27, loss: 1.016333
global_step: 1042, epoch: 27, loss: 1.040576
global_step: 1043, epoch: 27, loss: 0.954022
global_step: 1044, epoch: 27, loss: 0.945984
global_step: 1045, epoch: 27, loss: 1.018449
global_step: 1046, epoch: 27, loss: 1.064317
global_step: 1047, epoch: 27, loss: 0.937764
global_step: 1048, epoch: 27, loss: 0.972430
global_step: 1049, epoch: 27, loss: 1.039144
global_step: 1050, epoch: 27, loss: 0.867607
global_step: 1051, epoch: 27, loss: 1.077592
global_step: 1052, epoch: 27, loss: 0.966259
global_step: 1053, epoch: 27, loss: 0.961336
global_step: 1054, epoch: 27, loss: 1.012309
global_step: 1055, epoch: 27, loss: 1.066937
global_step: 1056, epoch: 27, loss: 1.035893
global_step: 1057, epoch: 27, loss: 1.126053
global_step: 1058, epoch: 27, loss: 0.845038
global_step: 1059, epoch: 27, loss: 1.128401
global_step: 1060, epoch: 27, loss: 1.000025
global_step: 1061, epoch: 27, loss: 1.032810
global_step: 1062, epoch: 27, loss: 1.028359
global_step: 1063, epoch: 27, loss: 0.990741
global_step: 1064, epoch: 27, loss: 0.969673
global_step: 1065, epoch: 27, loss: 1.105623
global_step: 1066, epoch: 27, loss: 0.933279
global_step: 1067, epoch: 27, loss: 1.025754
global_step: 1068, epoch: 27, loss: 1.049423
global_step: 1069, epoch: 27, loss: 1.022360
global_step: 1070, epoch: 27, loss: 1.097820
global_step: 1071, epoch: 27, loss: 1.078070
global_step: 1072, epoch: 27, loss: 0.972293
global_step: 1073, epoch: 27, loss: 0.946398
global_step: 1074, epoch: 27, loss: 1.053161
global_step: 1075, epoch: 27, loss: 0.921795
global_step: 1076, epoch: 27, loss: 1.075380
global_step: 1077, epoch: 27, loss: 0.988760
global_step: 1078, epoch: 27, loss: 1.023613
global_step: 1079, epoch: 27, loss: 1.016681
global_step: 1080, epoch: 27, loss: 0.407684
epoch: 27
train	acc: 0.6861	macro: p 0.4966, r 0.3897, f1: 0.4061	micro: p 0.6861, r 0.6861, f1 0.6861	weighted_f1:0.6420
dev	acc: 0.5464	macro: p 0.3433, r 0.2903, f1: 0.2753	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4754
test	acc: 0.5966	macro: p 0.3602, r 0.3005, f1: 0.2985	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5382
global_step: 1081, epoch: 28, loss: 1.056806
global_step: 1082, epoch: 28, loss: 1.004905
global_step: 1083, epoch: 28, loss: 0.988346
global_step: 1084, epoch: 28, loss: 0.923786
global_step: 1085, epoch: 28, loss: 0.893084
global_step: 1086, epoch: 28, loss: 0.972186
global_step: 1087, epoch: 28, loss: 0.916369
global_step: 1088, epoch: 28, loss: 0.971865
global_step: 1089, epoch: 28, loss: 1.047128
global_step: 1090, epoch: 28, loss: 1.055619
global_step: 1091, epoch: 28, loss: 0.933235
global_step: 1092, epoch: 28, loss: 0.997794
global_step: 1093, epoch: 28, loss: 1.005812
global_step: 1094, epoch: 28, loss: 0.946566
global_step: 1095, epoch: 28, loss: 0.989067
global_step: 1096, epoch: 28, loss: 0.957132
global_step: 1097, epoch: 28, loss: 0.892937
global_step: 1098, epoch: 28, loss: 1.045636
global_step: 1099, epoch: 28, loss: 1.057769
global_step: 1100, epoch: 28, loss: 0.928424
global_step: 1101, epoch: 28, loss: 0.991392
global_step: 1102, epoch: 28, loss: 0.950272
global_step: 1103, epoch: 28, loss: 1.003371
global_step: 1104, epoch: 28, loss: 0.952525
global_step: 1105, epoch: 28, loss: 1.061803
global_step: 1106, epoch: 28, loss: 0.905040
global_step: 1107, epoch: 28, loss: 0.949317
global_step: 1108, epoch: 28, loss: 0.980072
global_step: 1109, epoch: 28, loss: 1.024123
global_step: 1110, epoch: 28, loss: 1.054483
global_step: 1111, epoch: 28, loss: 1.011060
global_step: 1112, epoch: 28, loss: 1.031941
global_step: 1113, epoch: 28, loss: 0.940820
global_step: 1114, epoch: 28, loss: 0.970694
global_step: 1115, epoch: 28, loss: 0.956769
global_step: 1116, epoch: 28, loss: 1.043160
global_step: 1117, epoch: 28, loss: 1.001005
global_step: 1118, epoch: 28, loss: 1.117372
global_step: 1119, epoch: 28, loss: 1.014048
global_step: 1120, epoch: 28, loss: 0.223845
epoch: 28
train	acc: 0.7035	macro: p 0.5027, r 0.4169, f1: 0.4359	micro: p 0.7035, r 0.7035, f1 0.7035	weighted_f1:0.6657
dev	acc: 0.5518	macro: p 0.3435, r 0.2989, f1: 0.2937	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4917
test	acc: 0.6054	macro: p 0.3735, r 0.3100, f1: 0.3144	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5527
New best model!
global_step: 1121, epoch: 29, loss: 1.004937
global_step: 1122, epoch: 29, loss: 0.989767
global_step: 1123, epoch: 29, loss: 0.984063
global_step: 1124, epoch: 29, loss: 0.961307
global_step: 1125, epoch: 29, loss: 0.986597
global_step: 1126, epoch: 29, loss: 0.993562
global_step: 1127, epoch: 29, loss: 1.002956
global_step: 1128, epoch: 29, loss: 1.030728
global_step: 1129, epoch: 29, loss: 0.950704
global_step: 1130, epoch: 29, loss: 0.948321
global_step: 1131, epoch: 29, loss: 1.018627
global_step: 1132, epoch: 29, loss: 1.129893
global_step: 1133, epoch: 29, loss: 1.025930
global_step: 1134, epoch: 29, loss: 0.941948
global_step: 1135, epoch: 29, loss: 0.970851
global_step: 1136, epoch: 29, loss: 0.966456
global_step: 1137, epoch: 29, loss: 0.976835
global_step: 1138, epoch: 29, loss: 0.944950
global_step: 1139, epoch: 29, loss: 0.997530
global_step: 1140, epoch: 29, loss: 0.946806
global_step: 1141, epoch: 29, loss: 0.972734
global_step: 1142, epoch: 29, loss: 1.048885
global_step: 1143, epoch: 29, loss: 0.966134
global_step: 1144, epoch: 29, loss: 0.920388
global_step: 1145, epoch: 29, loss: 0.949582
global_step: 1146, epoch: 29, loss: 0.938787
global_step: 1147, epoch: 29, loss: 1.139142
global_step: 1148, epoch: 29, loss: 0.998536
global_step: 1149, epoch: 29, loss: 0.913726
global_step: 1150, epoch: 29, loss: 1.028901
global_step: 1151, epoch: 29, loss: 0.917441
global_step: 1152, epoch: 29, loss: 0.953144
global_step: 1153, epoch: 29, loss: 0.901399
global_step: 1154, epoch: 29, loss: 0.935332
global_step: 1155, epoch: 29, loss: 0.956193
global_step: 1156, epoch: 29, loss: 0.982969
global_step: 1157, epoch: 29, loss: 0.993923
global_step: 1158, epoch: 29, loss: 0.925919
global_step: 1159, epoch: 29, loss: 0.941506
global_step: 1160, epoch: 29, loss: 0.527660
epoch: 29
train	acc: 0.7077	macro: p 0.5087, r 0.4200, f1: 0.4341	micro: p 0.7077, r 0.7077, f1 0.7077	weighted_f1:0.6674
dev	acc: 0.5537	macro: p 0.3519, r 0.2999, f1: 0.2927	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4908
test	acc: 0.6050	macro: p 0.3721, r 0.3116, f1: 0.3137	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5522
global_step: 1161, epoch: 30, loss: 0.987838
global_step: 1162, epoch: 30, loss: 0.936157
global_step: 1163, epoch: 30, loss: 0.994808
global_step: 1164, epoch: 30, loss: 0.890932
global_step: 1165, epoch: 30, loss: 0.902831
global_step: 1166, epoch: 30, loss: 0.937912
global_step: 1167, epoch: 30, loss: 1.019954
global_step: 1168, epoch: 30, loss: 1.074615
global_step: 1169, epoch: 30, loss: 0.964254
global_step: 1170, epoch: 30, loss: 0.950935
global_step: 1171, epoch: 30, loss: 1.028073
global_step: 1172, epoch: 30, loss: 0.961622
global_step: 1173, epoch: 30, loss: 0.979732
global_step: 1174, epoch: 30, loss: 0.974169
global_step: 1175, epoch: 30, loss: 0.889489
global_step: 1176, epoch: 30, loss: 0.941403
global_step: 1177, epoch: 30, loss: 0.931418
global_step: 1178, epoch: 30, loss: 0.993910
global_step: 1179, epoch: 30, loss: 0.944787
global_step: 1180, epoch: 30, loss: 0.932451
global_step: 1181, epoch: 30, loss: 0.976182
global_step: 1182, epoch: 30, loss: 0.890347
global_step: 1183, epoch: 30, loss: 1.049082
global_step: 1184, epoch: 30, loss: 0.967088
global_step: 1185, epoch: 30, loss: 0.974927
global_step: 1186, epoch: 30, loss: 0.986694
global_step: 1187, epoch: 30, loss: 1.001943
global_step: 1188, epoch: 30, loss: 0.973408
global_step: 1189, epoch: 30, loss: 0.918677
global_step: 1190, epoch: 30, loss: 0.970827
global_step: 1191, epoch: 30, loss: 1.025738
global_step: 1192, epoch: 30, loss: 0.905474
global_step: 1193, epoch: 30, loss: 0.931317
global_step: 1194, epoch: 30, loss: 0.982607
global_step: 1195, epoch: 30, loss: 1.066530
global_step: 1196, epoch: 30, loss: 0.906632
global_step: 1197, epoch: 30, loss: 1.045674
global_step: 1198, epoch: 30, loss: 0.993778
global_step: 1199, epoch: 30, loss: 0.848242
global_step: 1200, epoch: 30, loss: 0.539805
epoch: 30
train	acc: 0.7158	macro: p 0.5150, r 0.4294, f1: 0.4463	micro: p 0.7158, r 0.7158, f1 0.7158	weighted_f1:0.6780
dev	acc: 0.5500	macro: p 0.3433, r 0.2965, f1: 0.2913	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4885
test	acc: 0.6061	macro: p 0.3799, r 0.3113, f1: 0.3163	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5538
global_step: 1201, epoch: 31, loss: 0.974583
global_step: 1202, epoch: 31, loss: 0.879438
global_step: 1203, epoch: 31, loss: 0.889356
global_step: 1204, epoch: 31, loss: 0.862314
global_step: 1205, epoch: 31, loss: 0.911583
global_step: 1206, epoch: 31, loss: 0.940084
global_step: 1207, epoch: 31, loss: 0.981704
global_step: 1208, epoch: 31, loss: 0.976131
global_step: 1209, epoch: 31, loss: 0.841537
global_step: 1210, epoch: 31, loss: 1.006606
global_step: 1211, epoch: 31, loss: 0.933481
global_step: 1212, epoch: 31, loss: 0.903417
global_step: 1213, epoch: 31, loss: 1.109401
global_step: 1214, epoch: 31, loss: 0.856366
global_step: 1215, epoch: 31, loss: 0.935987
global_step: 1216, epoch: 31, loss: 0.961136
global_step: 1217, epoch: 31, loss: 0.955055
global_step: 1218, epoch: 31, loss: 0.985598
global_step: 1219, epoch: 31, loss: 0.905399
global_step: 1220, epoch: 31, loss: 1.016980
global_step: 1221, epoch: 31, loss: 1.048427
global_step: 1222, epoch: 31, loss: 0.824511
global_step: 1223, epoch: 31, loss: 0.960288
global_step: 1224, epoch: 31, loss: 1.012660
global_step: 1225, epoch: 31, loss: 0.872224
global_step: 1226, epoch: 31, loss: 0.841144
global_step: 1227, epoch: 31, loss: 0.941733
global_step: 1228, epoch: 31, loss: 0.999555
global_step: 1229, epoch: 31, loss: 0.958448
global_step: 1230, epoch: 31, loss: 0.877884
global_step: 1231, epoch: 31, loss: 0.941668
global_step: 1232, epoch: 31, loss: 0.858632
global_step: 1233, epoch: 31, loss: 0.889242
global_step: 1234, epoch: 31, loss: 1.000799
global_step: 1235, epoch: 31, loss: 0.899101
global_step: 1236, epoch: 31, loss: 1.067123
global_step: 1237, epoch: 31, loss: 0.967133
global_step: 1238, epoch: 31, loss: 0.946141
global_step: 1239, epoch: 31, loss: 1.092337
global_step: 1240, epoch: 31, loss: 0.841654
epoch: 31
train	acc: 0.7202	macro: p 0.6656, r 0.4315, f1: 0.4521	micro: p 0.7202, r 0.7202, f1 0.7202	weighted_f1:0.6826
dev	acc: 0.5491	macro: p 0.3384, r 0.2956, f1: 0.2841	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4832
test	acc: 0.5985	macro: p 0.3752, r 0.3045, f1: 0.3062	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5428
global_step: 1241, epoch: 32, loss: 1.001105
global_step: 1242, epoch: 32, loss: 0.951057
global_step: 1243, epoch: 32, loss: 0.945303
global_step: 1244, epoch: 32, loss: 1.000312
global_step: 1245, epoch: 32, loss: 0.953914
global_step: 1246, epoch: 32, loss: 0.939918
global_step: 1247, epoch: 32, loss: 0.868899
global_step: 1248, epoch: 32, loss: 0.897888
global_step: 1249, epoch: 32, loss: 0.807132
global_step: 1250, epoch: 32, loss: 0.817638
global_step: 1251, epoch: 32, loss: 0.817293
global_step: 1252, epoch: 32, loss: 0.919203
global_step: 1253, epoch: 32, loss: 0.869852
global_step: 1254, epoch: 32, loss: 0.954344
global_step: 1255, epoch: 32, loss: 0.983456
global_step: 1256, epoch: 32, loss: 0.895125
global_step: 1257, epoch: 32, loss: 1.044729
global_step: 1258, epoch: 32, loss: 0.915271
global_step: 1259, epoch: 32, loss: 0.909356
global_step: 1260, epoch: 32, loss: 1.087245
global_step: 1261, epoch: 32, loss: 1.123627
global_step: 1262, epoch: 32, loss: 0.927625
global_step: 1263, epoch: 32, loss: 1.010888
global_step: 1264, epoch: 32, loss: 0.944507
global_step: 1265, epoch: 32, loss: 0.970540
global_step: 1266, epoch: 32, loss: 0.917369
global_step: 1267, epoch: 32, loss: 0.969624
global_step: 1268, epoch: 32, loss: 0.881277
global_step: 1269, epoch: 32, loss: 1.010621
global_step: 1270, epoch: 32, loss: 0.917048
global_step: 1271, epoch: 32, loss: 0.935694
global_step: 1272, epoch: 32, loss: 0.875190
global_step: 1273, epoch: 32, loss: 0.901578
global_step: 1274, epoch: 32, loss: 0.849323
global_step: 1275, epoch: 32, loss: 0.963662
global_step: 1276, epoch: 32, loss: 0.899867
global_step: 1277, epoch: 32, loss: 0.893533
global_step: 1278, epoch: 32, loss: 0.897950
global_step: 1279, epoch: 32, loss: 0.874027
global_step: 1280, epoch: 32, loss: 0.358185
epoch: 32
train	acc: 0.7333	macro: p 0.6687, r 0.4516, f1: 0.4706	micro: p 0.7333, r 0.7333, f1 0.7333	weighted_f1:0.6982
dev	acc: 0.5546	macro: p 0.3359, r 0.3019, f1: 0.2956	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4938
test	acc: 0.6096	macro: p 0.3739, r 0.3162, f1: 0.3214	micro: p 0.6096, r 0.6096, f1 0.6096	weighted_f1:0.5580
New best model!
global_step: 1281, epoch: 33, loss: 0.799714
global_step: 1282, epoch: 33, loss: 0.916373
global_step: 1283, epoch: 33, loss: 0.851816
global_step: 1284, epoch: 33, loss: 0.921627
global_step: 1285, epoch: 33, loss: 0.800228
global_step: 1286, epoch: 33, loss: 0.847217
global_step: 1287, epoch: 33, loss: 0.865922
global_step: 1288, epoch: 33, loss: 0.919349
global_step: 1289, epoch: 33, loss: 0.897031
global_step: 1290, epoch: 33, loss: 0.891372
global_step: 1291, epoch: 33, loss: 0.941090
global_step: 1292, epoch: 33, loss: 0.879069
global_step: 1293, epoch: 33, loss: 0.957862
global_step: 1294, epoch: 33, loss: 0.920618
global_step: 1295, epoch: 33, loss: 1.020047
global_step: 1296, epoch: 33, loss: 1.005220
global_step: 1297, epoch: 33, loss: 0.826938
global_step: 1298, epoch: 33, loss: 0.915349
global_step: 1299, epoch: 33, loss: 0.841542
global_step: 1300, epoch: 33, loss: 0.892561
global_step: 1301, epoch: 33, loss: 0.979353
global_step: 1302, epoch: 33, loss: 0.864165
global_step: 1303, epoch: 33, loss: 0.989136
global_step: 1304, epoch: 33, loss: 1.028085
global_step: 1305, epoch: 33, loss: 0.821944
global_step: 1306, epoch: 33, loss: 0.861039
global_step: 1307, epoch: 33, loss: 1.014543
global_step: 1308, epoch: 33, loss: 1.092388
global_step: 1309, epoch: 33, loss: 0.899870
global_step: 1310, epoch: 33, loss: 0.861560
global_step: 1311, epoch: 33, loss: 0.934141
global_step: 1312, epoch: 33, loss: 0.949921
global_step: 1313, epoch: 33, loss: 0.786193
global_step: 1314, epoch: 33, loss: 0.905210
global_step: 1315, epoch: 33, loss: 0.910022
global_step: 1316, epoch: 33, loss: 0.842551
global_step: 1317, epoch: 33, loss: 0.969855
global_step: 1318, epoch: 33, loss: 0.841926
global_step: 1319, epoch: 33, loss: 0.955412
global_step: 1320, epoch: 33, loss: 0.769710
epoch: 33
train	acc: 0.7521	macro: p 0.5365, r 0.4758, f1: 0.4915	micro: p 0.7521, r 0.7521, f1 0.7521	weighted_f1:0.7204
dev	acc: 0.5446	macro: p 0.3278, r 0.2961, f1: 0.2880	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4855
test	acc: 0.6042	macro: p 0.3736, r 0.3151, f1: 0.3186	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5545
global_step: 1321, epoch: 34, loss: 1.016251
global_step: 1322, epoch: 34, loss: 0.829069
global_step: 1323, epoch: 34, loss: 0.861588
global_step: 1324, epoch: 34, loss: 0.843641
global_step: 1325, epoch: 34, loss: 0.876668
global_step: 1326, epoch: 34, loss: 0.935833
global_step: 1327, epoch: 34, loss: 0.760818
global_step: 1328, epoch: 34, loss: 0.914578
global_step: 1329, epoch: 34, loss: 0.910830
global_step: 1330, epoch: 34, loss: 0.915426
global_step: 1331, epoch: 34, loss: 0.840134
global_step: 1332, epoch: 34, loss: 0.941655
global_step: 1333, epoch: 34, loss: 0.842567
global_step: 1334, epoch: 34, loss: 0.823485
global_step: 1335, epoch: 34, loss: 0.825248
global_step: 1336, epoch: 34, loss: 0.955459
global_step: 1337, epoch: 34, loss: 0.863771
global_step: 1338, epoch: 34, loss: 0.872443
global_step: 1339, epoch: 34, loss: 0.971432
global_step: 1340, epoch: 34, loss: 0.805979
global_step: 1341, epoch: 34, loss: 0.924935
global_step: 1342, epoch: 34, loss: 0.969845
global_step: 1343, epoch: 34, loss: 0.912410
global_step: 1344, epoch: 34, loss: 0.884886
global_step: 1345, epoch: 34, loss: 0.998080
global_step: 1346, epoch: 34, loss: 0.939553
global_step: 1347, epoch: 34, loss: 0.840577
global_step: 1348, epoch: 34, loss: 1.005196
global_step: 1349, epoch: 34, loss: 0.828376
global_step: 1350, epoch: 34, loss: 0.936958
global_step: 1351, epoch: 34, loss: 0.861218
global_step: 1352, epoch: 34, loss: 0.889460
global_step: 1353, epoch: 34, loss: 1.027232
global_step: 1354, epoch: 34, loss: 0.842750
global_step: 1355, epoch: 34, loss: 0.901087
global_step: 1356, epoch: 34, loss: 0.835942
global_step: 1357, epoch: 34, loss: 0.961542
global_step: 1358, epoch: 34, loss: 0.910328
global_step: 1359, epoch: 34, loss: 0.937549
global_step: 1360, epoch: 34, loss: 0.586944
epoch: 34
train	acc: 0.7759	macro: p 0.5421, r 0.5054, f1: 0.5107	micro: p 0.7759, r 0.7759, f1 0.7759	weighted_f1:0.7462
dev	acc: 0.5473	macro: p 0.3325, r 0.3048, f1: 0.2965	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4948
test	acc: 0.6015	macro: p 0.3723, r 0.3213, f1: 0.3219	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5574
New best model!
global_step: 1361, epoch: 35, loss: 0.901578
global_step: 1362, epoch: 35, loss: 0.805731
global_step: 1363, epoch: 35, loss: 0.921473
global_step: 1364, epoch: 35, loss: 0.815461
global_step: 1365, epoch: 35, loss: 0.909190
global_step: 1366, epoch: 35, loss: 0.837263
global_step: 1367, epoch: 35, loss: 0.902308
global_step: 1368, epoch: 35, loss: 0.931961
global_step: 1369, epoch: 35, loss: 0.866690
global_step: 1370, epoch: 35, loss: 0.905517
global_step: 1371, epoch: 35, loss: 0.940210
global_step: 1372, epoch: 35, loss: 0.812632
global_step: 1373, epoch: 35, loss: 0.819234
global_step: 1374, epoch: 35, loss: 0.843749
global_step: 1375, epoch: 35, loss: 0.865292
global_step: 1376, epoch: 35, loss: 0.885570
global_step: 1377, epoch: 35, loss: 0.868442
global_step: 1378, epoch: 35, loss: 0.951235
global_step: 1379, epoch: 35, loss: 0.952840
global_step: 1380, epoch: 35, loss: 0.923541
global_step: 1381, epoch: 35, loss: 0.899205
global_step: 1382, epoch: 35, loss: 0.883848
global_step: 1383, epoch: 35, loss: 0.989292
global_step: 1384, epoch: 35, loss: 0.963309
global_step: 1385, epoch: 35, loss: 0.835610
global_step: 1386, epoch: 35, loss: 0.838421
global_step: 1387, epoch: 35, loss: 0.949945
global_step: 1388, epoch: 35, loss: 0.974144
global_step: 1389, epoch: 35, loss: 0.964104
global_step: 1390, epoch: 35, loss: 0.841505
global_step: 1391, epoch: 35, loss: 0.910679
global_step: 1392, epoch: 35, loss: 0.868967
global_step: 1393, epoch: 35, loss: 0.806334
global_step: 1394, epoch: 35, loss: 0.871002
global_step: 1395, epoch: 35, loss: 0.949464
global_step: 1396, epoch: 35, loss: 0.887975
global_step: 1397, epoch: 35, loss: 0.780877
global_step: 1398, epoch: 35, loss: 0.854383
global_step: 1399, epoch: 35, loss: 0.926119
global_step: 1400, epoch: 35, loss: 0.852251
epoch: 35
train	acc: 0.7950	macro: p 0.6860, r 0.5417, f1: 0.5413	micro: p 0.7950, r 0.7950, f1 0.7950	weighted_f1:0.7703
dev	acc: 0.5437	macro: p 0.3201, r 0.3062, f1: 0.2999	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4954
test	acc: 0.6000	macro: p 0.3575, r 0.3265, f1: 0.3292	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5610
New best model!
global_step: 1401, epoch: 36, loss: 0.983067
global_step: 1402, epoch: 36, loss: 0.849047
global_step: 1403, epoch: 36, loss: 0.870301
global_step: 1404, epoch: 36, loss: 0.879364
global_step: 1405, epoch: 36, loss: 0.863615
global_step: 1406, epoch: 36, loss: 0.909537
global_step: 1407, epoch: 36, loss: 0.820158
global_step: 1408, epoch: 36, loss: 0.874973
global_step: 1409, epoch: 36, loss: 0.871405
global_step: 1410, epoch: 36, loss: 0.857022
global_step: 1411, epoch: 36, loss: 0.889911
global_step: 1412, epoch: 36, loss: 0.815776
global_step: 1413, epoch: 36, loss: 0.794694
global_step: 1414, epoch: 36, loss: 0.795285
global_step: 1415, epoch: 36, loss: 0.867682
global_step: 1416, epoch: 36, loss: 0.973448
global_step: 1417, epoch: 36, loss: 0.879847
global_step: 1418, epoch: 36, loss: 0.788109
global_step: 1419, epoch: 36, loss: 0.942706
global_step: 1420, epoch: 36, loss: 0.933414
global_step: 1421, epoch: 36, loss: 0.889398
global_step: 1422, epoch: 36, loss: 0.900463
global_step: 1423, epoch: 36, loss: 0.859240
global_step: 1424, epoch: 36, loss: 0.882405
global_step: 1425, epoch: 36, loss: 0.873109
global_step: 1426, epoch: 36, loss: 0.865031
global_step: 1427, epoch: 36, loss: 0.837170
global_step: 1428, epoch: 36, loss: 0.825622
global_step: 1429, epoch: 36, loss: 0.879670
global_step: 1430, epoch: 36, loss: 0.879833
global_step: 1431, epoch: 36, loss: 0.866989
global_step: 1432, epoch: 36, loss: 0.831467
global_step: 1433, epoch: 36, loss: 0.829838
global_step: 1434, epoch: 36, loss: 0.868779
global_step: 1435, epoch: 36, loss: 0.790335
global_step: 1436, epoch: 36, loss: 0.765675
global_step: 1437, epoch: 36, loss: 0.857388
global_step: 1438, epoch: 36, loss: 0.906780
global_step: 1439, epoch: 36, loss: 0.901293
global_step: 1440, epoch: 36, loss: 1.383099
epoch: 36
train	acc: 0.7959	macro: p 0.8361, r 0.5399, f1: 0.5469	micro: p 0.7959, r 0.7959, f1 0.7959	weighted_f1:0.7713
dev	acc: 0.5437	macro: p 0.3284, r 0.3032, f1: 0.2968	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4931
test	acc: 0.6069	macro: p 0.3713, r 0.3272, f1: 0.3305	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5650
global_step: 1441, epoch: 37, loss: 0.756971
global_step: 1442, epoch: 37, loss: 0.908598
global_step: 1443, epoch: 37, loss: 0.891599
global_step: 1444, epoch: 37, loss: 0.819891
global_step: 1445, epoch: 37, loss: 0.846490
global_step: 1446, epoch: 37, loss: 0.795585
global_step: 1447, epoch: 37, loss: 0.884502
global_step: 1448, epoch: 37, loss: 0.915188
global_step: 1449, epoch: 37, loss: 0.937562
global_step: 1450, epoch: 37, loss: 0.833798
global_step: 1451, epoch: 37, loss: 0.920147
global_step: 1452, epoch: 37, loss: 0.870439
global_step: 1453, epoch: 37, loss: 0.849668
global_step: 1454, epoch: 37, loss: 0.793911
global_step: 1455, epoch: 37, loss: 0.922408
global_step: 1456, epoch: 37, loss: 0.902653
global_step: 1457, epoch: 37, loss: 0.756217
global_step: 1458, epoch: 37, loss: 0.780261
global_step: 1459, epoch: 37, loss: 0.785105
global_step: 1460, epoch: 37, loss: 0.825986
global_step: 1461, epoch: 37, loss: 0.777799
global_step: 1462, epoch: 37, loss: 0.831925
global_step: 1463, epoch: 37, loss: 0.856977
global_step: 1464, epoch: 37, loss: 0.876381
global_step: 1465, epoch: 37, loss: 0.905654
global_step: 1466, epoch: 37, loss: 0.894508
global_step: 1467, epoch: 37, loss: 0.762572
global_step: 1468, epoch: 37, loss: 0.844511
global_step: 1469, epoch: 37, loss: 0.896470
global_step: 1470, epoch: 37, loss: 0.838518
global_step: 1471, epoch: 37, loss: 0.846799
global_step: 1472, epoch: 37, loss: 0.766823
global_step: 1473, epoch: 37, loss: 0.789448
global_step: 1474, epoch: 37, loss: 0.784308
global_step: 1475, epoch: 37, loss: 0.884713
global_step: 1476, epoch: 37, loss: 0.794744
global_step: 1477, epoch: 37, loss: 0.784848
global_step: 1478, epoch: 37, loss: 0.839983
global_step: 1479, epoch: 37, loss: 1.002014
global_step: 1480, epoch: 37, loss: 0.802010
epoch: 37
train	acc: 0.8029	macro: p 0.8410, r 0.5435, f1: 0.5491	micro: p 0.8029, r 0.8029, f1 0.8029	weighted_f1:0.7762
dev	acc: 0.5437	macro: p 0.3295, r 0.3051, f1: 0.2961	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4918
test	acc: 0.6092	macro: p 0.3740, r 0.3309, f1: 0.3296	micro: p 0.6092, r 0.6092, f1 0.6092	weighted_f1:0.5652
global_step: 1481, epoch: 38, loss: 0.816728
global_step: 1482, epoch: 38, loss: 0.730686
global_step: 1483, epoch: 38, loss: 0.857125
global_step: 1484, epoch: 38, loss: 0.914667
global_step: 1485, epoch: 38, loss: 0.859305
global_step: 1486, epoch: 38, loss: 0.865583
global_step: 1487, epoch: 38, loss: 0.806695
global_step: 1488, epoch: 38, loss: 0.855558
global_step: 1489, epoch: 38, loss: 0.829982
global_step: 1490, epoch: 38, loss: 0.791182
global_step: 1491, epoch: 38, loss: 0.911637
global_step: 1492, epoch: 38, loss: 0.842025
global_step: 1493, epoch: 38, loss: 0.782341
global_step: 1494, epoch: 38, loss: 0.764214
global_step: 1495, epoch: 38, loss: 0.782272
global_step: 1496, epoch: 38, loss: 0.795002
global_step: 1497, epoch: 38, loss: 0.842266
global_step: 1498, epoch: 38, loss: 0.876979
global_step: 1499, epoch: 38, loss: 0.949796
global_step: 1500, epoch: 38, loss: 0.815480
global_step: 1501, epoch: 38, loss: 0.857009
global_step: 1502, epoch: 38, loss: 0.805768
global_step: 1503, epoch: 38, loss: 0.918771
global_step: 1504, epoch: 38, loss: 0.933550
global_step: 1505, epoch: 38, loss: 0.765944
global_step: 1506, epoch: 38, loss: 0.825619
global_step: 1507, epoch: 38, loss: 0.769651
global_step: 1508, epoch: 38, loss: 0.866838
global_step: 1509, epoch: 38, loss: 0.842593
global_step: 1510, epoch: 38, loss: 0.850604
global_step: 1511, epoch: 38, loss: 0.818882
global_step: 1512, epoch: 38, loss: 0.829548
global_step: 1513, epoch: 38, loss: 0.935525
global_step: 1514, epoch: 38, loss: 0.872302
global_step: 1515, epoch: 38, loss: 0.872990
global_step: 1516, epoch: 38, loss: 0.805120
global_step: 1517, epoch: 38, loss: 0.810559
global_step: 1518, epoch: 38, loss: 0.852295
global_step: 1519, epoch: 38, loss: 0.870051
global_step: 1520, epoch: 38, loss: 0.654675
epoch: 38
train	acc: 0.8196	macro: p 0.8373, r 0.5800, f1: 0.5715	micro: p 0.8196, r 0.8196, f1 0.8196	weighted_f1:0.7982
dev	acc: 0.5275	macro: p 0.3176, r 0.3092, f1: 0.2996	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4899
test	acc: 0.5851	macro: p 0.3449, r 0.3342, f1: 0.3280	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5551
global_step: 1521, epoch: 39, loss: 0.906830
global_step: 1522, epoch: 39, loss: 0.762341
global_step: 1523, epoch: 39, loss: 0.871266
global_step: 1524, epoch: 39, loss: 0.862334
global_step: 1525, epoch: 39, loss: 0.713736
global_step: 1526, epoch: 39, loss: 0.759851
global_step: 1527, epoch: 39, loss: 0.797894
global_step: 1528, epoch: 39, loss: 0.882500
global_step: 1529, epoch: 39, loss: 0.739425
global_step: 1530, epoch: 39, loss: 0.749299
global_step: 1531, epoch: 39, loss: 0.869648
global_step: 1532, epoch: 39, loss: 0.789256
global_step: 1533, epoch: 39, loss: 0.841291
global_step: 1534, epoch: 39, loss: 0.890927
global_step: 1535, epoch: 39, loss: 0.845109
global_step: 1536, epoch: 39, loss: 0.835959
global_step: 1537, epoch: 39, loss: 0.763492
global_step: 1538, epoch: 39, loss: 0.813092
global_step: 1539, epoch: 39, loss: 0.773260
global_step: 1540, epoch: 39, loss: 0.880499
global_step: 1541, epoch: 39, loss: 0.800222
global_step: 1542, epoch: 39, loss: 0.751758
global_step: 1543, epoch: 39, loss: 0.986459
global_step: 1544, epoch: 39, loss: 0.841185
global_step: 1545, epoch: 39, loss: 0.930770
global_step: 1546, epoch: 39, loss: 0.772501
global_step: 1547, epoch: 39, loss: 0.742437
global_step: 1548, epoch: 39, loss: 0.861097
global_step: 1549, epoch: 39, loss: 0.757002
global_step: 1550, epoch: 39, loss: 0.811557
global_step: 1551, epoch: 39, loss: 0.782251
global_step: 1552, epoch: 39, loss: 0.786878
global_step: 1553, epoch: 39, loss: 0.764210
global_step: 1554, epoch: 39, loss: 0.909883
global_step: 1555, epoch: 39, loss: 0.914297
global_step: 1556, epoch: 39, loss: 0.849294
global_step: 1557, epoch: 39, loss: 0.791352
global_step: 1558, epoch: 39, loss: 0.828874
global_step: 1559, epoch: 39, loss: 0.726750
global_step: 1560, epoch: 39, loss: 0.342637
epoch: 39
train	acc: 0.8090	macro: p 0.8451, r 0.5565, f1: 0.5620	micro: p 0.8090, r 0.8090, f1 0.8090	weighted_f1:0.7831
dev	acc: 0.5455	macro: p 0.3242, r 0.3042, f1: 0.2935	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4895
test	acc: 0.6034	macro: p 0.3641, r 0.3279, f1: 0.3238	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5575
global_step: 1561, epoch: 40, loss: 0.789638
global_step: 1562, epoch: 40, loss: 0.802351
global_step: 1563, epoch: 40, loss: 0.859088
global_step: 1564, epoch: 40, loss: 0.764037
global_step: 1565, epoch: 40, loss: 0.807294
global_step: 1566, epoch: 40, loss: 0.696214
global_step: 1567, epoch: 40, loss: 0.744934
global_step: 1568, epoch: 40, loss: 0.854004
global_step: 1569, epoch: 40, loss: 0.837467
global_step: 1570, epoch: 40, loss: 0.790940
global_step: 1571, epoch: 40, loss: 0.847553
global_step: 1572, epoch: 40, loss: 0.845104
global_step: 1573, epoch: 40, loss: 0.745509
global_step: 1574, epoch: 40, loss: 0.703048
global_step: 1575, epoch: 40, loss: 0.840071
global_step: 1576, epoch: 40, loss: 0.825125
global_step: 1577, epoch: 40, loss: 0.843488
global_step: 1578, epoch: 40, loss: 0.748321
global_step: 1579, epoch: 40, loss: 0.818900
global_step: 1580, epoch: 40, loss: 0.816980
global_step: 1581, epoch: 40, loss: 0.830446
global_step: 1582, epoch: 40, loss: 0.921738
global_step: 1583, epoch: 40, loss: 0.742478
global_step: 1584, epoch: 40, loss: 0.804570
global_step: 1585, epoch: 40, loss: 0.838728
global_step: 1586, epoch: 40, loss: 0.791072
global_step: 1587, epoch: 40, loss: 0.807305
global_step: 1588, epoch: 40, loss: 0.801148
global_step: 1589, epoch: 40, loss: 0.921647
global_step: 1590, epoch: 40, loss: 0.842338
global_step: 1591, epoch: 40, loss: 0.717621
global_step: 1592, epoch: 40, loss: 0.896334
global_step: 1593, epoch: 40, loss: 0.960244
global_step: 1594, epoch: 40, loss: 0.759111
global_step: 1595, epoch: 40, loss: 0.764335
global_step: 1596, epoch: 40, loss: 0.767362
global_step: 1597, epoch: 40, loss: 0.703386
global_step: 1598, epoch: 40, loss: 0.849939
global_step: 1599, epoch: 40, loss: 0.826948
global_step: 1600, epoch: 40, loss: 0.679889
epoch: 40
train	acc: 0.8190	macro: p 0.8510, r 0.5703, f1: 0.5762	micro: p 0.8190, r 0.8190, f1 0.8190	weighted_f1:0.7953
dev	acc: 0.5365	macro: p 0.3200, r 0.2982, f1: 0.2886	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4841
test	acc: 0.5985	macro: p 0.3621, r 0.3239, f1: 0.3225	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5544
global_step: 1601, epoch: 41, loss: 0.786762
global_step: 1602, epoch: 41, loss: 0.793041
global_step: 1603, epoch: 41, loss: 0.817609
global_step: 1604, epoch: 41, loss: 0.836553
global_step: 1605, epoch: 41, loss: 0.827180
global_step: 1606, epoch: 41, loss: 0.896155
global_step: 1607, epoch: 41, loss: 0.807194
global_step: 1608, epoch: 41, loss: 0.786631
global_step: 1609, epoch: 41, loss: 0.812133
global_step: 1610, epoch: 41, loss: 0.797353
global_step: 1611, epoch: 41, loss: 0.702677
global_step: 1612, epoch: 41, loss: 0.846296
global_step: 1613, epoch: 41, loss: 0.700261
global_step: 1614, epoch: 41, loss: 0.981375
global_step: 1615, epoch: 41, loss: 0.776430
global_step: 1616, epoch: 41, loss: 0.795445
global_step: 1617, epoch: 41, loss: 0.794181
global_step: 1618, epoch: 41, loss: 0.731698
global_step: 1619, epoch: 41, loss: 0.841706
global_step: 1620, epoch: 41, loss: 0.802128
global_step: 1621, epoch: 41, loss: 0.829518
global_step: 1622, epoch: 41, loss: 0.748746
global_step: 1623, epoch: 41, loss: 0.841955
global_step: 1624, epoch: 41, loss: 0.801566
global_step: 1625, epoch: 41, loss: 0.779523
global_step: 1626, epoch: 41, loss: 0.808779
global_step: 1627, epoch: 41, loss: 0.781030
global_step: 1628, epoch: 41, loss: 0.855235
global_step: 1629, epoch: 41, loss: 0.803518
global_step: 1630, epoch: 41, loss: 0.745020
global_step: 1631, epoch: 41, loss: 0.843436
global_step: 1632, epoch: 41, loss: 0.864883
global_step: 1633, epoch: 41, loss: 0.736440
global_step: 1634, epoch: 41, loss: 0.843921
global_step: 1635, epoch: 41, loss: 0.741970
global_step: 1636, epoch: 41, loss: 0.700423
global_step: 1637, epoch: 41, loss: 0.748275
global_step: 1638, epoch: 41, loss: 0.878424
global_step: 1639, epoch: 41, loss: 0.819249
global_step: 1640, epoch: 41, loss: 1.076289
epoch: 41
train	acc: 0.8221	macro: p 0.8603, r 0.5736, f1: 0.5877	micro: p 0.8221, r 0.8221, f1 0.8221	weighted_f1:0.7997
dev	acc: 0.5500	macro: p 0.3392, r 0.3079, f1: 0.3015	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4981
test	acc: 0.6057	macro: p 0.3794, r 0.3246, f1: 0.3283	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5626
New best model!
global_step: 1641, epoch: 42, loss: 0.783617
global_step: 1642, epoch: 42, loss: 0.733725
global_step: 1643, epoch: 42, loss: 0.782359
global_step: 1644, epoch: 42, loss: 0.794722
global_step: 1645, epoch: 42, loss: 0.774202
global_step: 1646, epoch: 42, loss: 0.692525
global_step: 1647, epoch: 42, loss: 0.815786
global_step: 1648, epoch: 42, loss: 0.706105
global_step: 1649, epoch: 42, loss: 0.743915
global_step: 1650, epoch: 42, loss: 0.726804
global_step: 1651, epoch: 42, loss: 0.837866
global_step: 1652, epoch: 42, loss: 0.811240
global_step: 1653, epoch: 42, loss: 0.874961
global_step: 1654, epoch: 42, loss: 0.855683
global_step: 1655, epoch: 42, loss: 0.773387
global_step: 1656, epoch: 42, loss: 0.759245
global_step: 1657, epoch: 42, loss: 0.811868
global_step: 1658, epoch: 42, loss: 0.836573
global_step: 1659, epoch: 42, loss: 0.700013
global_step: 1660, epoch: 42, loss: 0.740515
global_step: 1661, epoch: 42, loss: 0.806030
global_step: 1662, epoch: 42, loss: 0.751816
global_step: 1663, epoch: 42, loss: 0.859744
global_step: 1664, epoch: 42, loss: 0.860466
global_step: 1665, epoch: 42, loss: 0.752774
global_step: 1666, epoch: 42, loss: 0.811548
global_step: 1667, epoch: 42, loss: 0.872183
global_step: 1668, epoch: 42, loss: 0.837263
global_step: 1669, epoch: 42, loss: 0.831961
global_step: 1670, epoch: 42, loss: 0.765872
global_step: 1671, epoch: 42, loss: 0.594687
global_step: 1672, epoch: 42, loss: 0.759194
global_step: 1673, epoch: 42, loss: 0.761178
global_step: 1674, epoch: 42, loss: 0.842936
global_step: 1675, epoch: 42, loss: 0.750541
global_step: 1676, epoch: 42, loss: 0.708346
global_step: 1677, epoch: 42, loss: 0.729328
global_step: 1678, epoch: 42, loss: 0.753133
global_step: 1679, epoch: 42, loss: 0.820147
global_step: 1680, epoch: 42, loss: 0.763878
epoch: 42
train	acc: 0.7892	macro: p 0.8511, r 0.5248, f1: 0.5512	micro: p 0.7892, r 0.7892, f1 0.7892	weighted_f1:0.7605
dev	acc: 0.5428	macro: p 0.3395, r 0.2932, f1: 0.2856	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4783
test	acc: 0.6077	macro: p 0.3768, r 0.3120, f1: 0.3129	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5504
global_step: 1681, epoch: 43, loss: 0.692480
global_step: 1682, epoch: 43, loss: 0.834053
global_step: 1683, epoch: 43, loss: 0.784477
global_step: 1684, epoch: 43, loss: 0.786364
global_step: 1685, epoch: 43, loss: 0.837828
global_step: 1686, epoch: 43, loss: 0.794869
global_step: 1687, epoch: 43, loss: 0.745719
global_step: 1688, epoch: 43, loss: 0.779041
global_step: 1689, epoch: 43, loss: 0.850784
global_step: 1690, epoch: 43, loss: 0.805781
global_step: 1691, epoch: 43, loss: 0.832993
global_step: 1692, epoch: 43, loss: 0.808988
global_step: 1693, epoch: 43, loss: 0.738212
global_step: 1694, epoch: 43, loss: 0.766424
global_step: 1695, epoch: 43, loss: 0.734292
global_step: 1696, epoch: 43, loss: 0.717335
global_step: 1697, epoch: 43, loss: 0.706385
global_step: 1698, epoch: 43, loss: 0.736128
global_step: 1699, epoch: 43, loss: 0.730454
global_step: 1700, epoch: 43, loss: 0.820100
global_step: 1701, epoch: 43, loss: 0.797633
global_step: 1702, epoch: 43, loss: 0.797651
global_step: 1703, epoch: 43, loss: 0.685814
global_step: 1704, epoch: 43, loss: 0.984078
global_step: 1705, epoch: 43, loss: 0.888314
global_step: 1706, epoch: 43, loss: 0.757714
global_step: 1707, epoch: 43, loss: 0.766654
global_step: 1708, epoch: 43, loss: 0.716340
global_step: 1709, epoch: 43, loss: 0.700780
global_step: 1710, epoch: 43, loss: 0.635074
global_step: 1711, epoch: 43, loss: 0.825559
global_step: 1712, epoch: 43, loss: 0.772557
global_step: 1713, epoch: 43, loss: 0.711456
global_step: 1714, epoch: 43, loss: 0.777374
global_step: 1715, epoch: 43, loss: 0.875298
global_step: 1716, epoch: 43, loss: 0.814667
global_step: 1717, epoch: 43, loss: 0.788233
global_step: 1718, epoch: 43, loss: 0.781178
global_step: 1719, epoch: 43, loss: 0.833469
global_step: 1720, epoch: 43, loss: 0.340405
epoch: 43
train	acc: 0.8265	macro: p 0.8688, r 0.5785, f1: 0.5948	micro: p 0.8265, r 0.8265, f1 0.8265	weighted_f1:0.8034
dev	acc: 0.5500	macro: p 0.3489, r 0.3069, f1: 0.3024	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4961
test	acc: 0.6077	macro: p 0.3739, r 0.3212, f1: 0.3232	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5597
global_step: 1721, epoch: 44, loss: 0.735557
global_step: 1722, epoch: 44, loss: 0.678935
global_step: 1723, epoch: 44, loss: 0.839411
global_step: 1724, epoch: 44, loss: 0.612129
global_step: 1725, epoch: 44, loss: 0.661571
global_step: 1726, epoch: 44, loss: 0.805650
global_step: 1727, epoch: 44, loss: 0.729973
global_step: 1728, epoch: 44, loss: 0.848009
global_step: 1729, epoch: 44, loss: 0.762606
global_step: 1730, epoch: 44, loss: 0.651097
global_step: 1731, epoch: 44, loss: 0.763417
global_step: 1732, epoch: 44, loss: 0.719390
global_step: 1733, epoch: 44, loss: 0.795002
global_step: 1734, epoch: 44, loss: 0.807109
global_step: 1735, epoch: 44, loss: 0.713672
global_step: 1736, epoch: 44, loss: 0.773587
global_step: 1737, epoch: 44, loss: 0.754247
global_step: 1738, epoch: 44, loss: 0.706005
global_step: 1739, epoch: 44, loss: 0.706319
global_step: 1740, epoch: 44, loss: 0.662203
global_step: 1741, epoch: 44, loss: 0.705274
global_step: 1742, epoch: 44, loss: 0.857644
global_step: 1743, epoch: 44, loss: 0.735387
global_step: 1744, epoch: 44, loss: 0.820962
global_step: 1745, epoch: 44, loss: 0.700506
global_step: 1746, epoch: 44, loss: 0.671560
global_step: 1747, epoch: 44, loss: 0.845926
global_step: 1748, epoch: 44, loss: 0.732196
global_step: 1749, epoch: 44, loss: 0.789883
global_step: 1750, epoch: 44, loss: 0.682553
global_step: 1751, epoch: 44, loss: 0.774607
global_step: 1752, epoch: 44, loss: 0.734631
global_step: 1753, epoch: 44, loss: 0.858169
global_step: 1754, epoch: 44, loss: 0.872842
global_step: 1755, epoch: 44, loss: 0.805989
global_step: 1756, epoch: 44, loss: 0.793689
global_step: 1757, epoch: 44, loss: 0.720669
global_step: 1758, epoch: 44, loss: 0.810475
global_step: 1759, epoch: 44, loss: 0.790249
global_step: 1760, epoch: 44, loss: 1.407940
epoch: 44
train	acc: 0.8403	macro: p 0.8610, r 0.6161, f1: 0.6452	micro: p 0.8403, r 0.8403, f1 0.8403	weighted_f1:0.8224
dev	acc: 0.5482	macro: p 0.3349, r 0.3035, f1: 0.2989	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4933
test	acc: 0.6088	macro: p 0.3628, r 0.3239, f1: 0.3262	micro: p 0.6088, r 0.6088, f1 0.6088	weighted_f1:0.5615
global_step: 1761, epoch: 45, loss: 0.818350
global_step: 1762, epoch: 45, loss: 0.780346
global_step: 1763, epoch: 45, loss: 0.769165
global_step: 1764, epoch: 45, loss: 0.845574
global_step: 1765, epoch: 45, loss: 0.803269
global_step: 1766, epoch: 45, loss: 0.777226
global_step: 1767, epoch: 45, loss: 0.729065
global_step: 1768, epoch: 45, loss: 0.756575
global_step: 1769, epoch: 45, loss: 0.729505
global_step: 1770, epoch: 45, loss: 0.683036
global_step: 1771, epoch: 45, loss: 0.722509
global_step: 1772, epoch: 45, loss: 0.641423
global_step: 1773, epoch: 45, loss: 0.676422
global_step: 1774, epoch: 45, loss: 0.669691
global_step: 1775, epoch: 45, loss: 0.704176
global_step: 1776, epoch: 45, loss: 0.851351
global_step: 1777, epoch: 45, loss: 0.809272
global_step: 1778, epoch: 45, loss: 0.830388
global_step: 1779, epoch: 45, loss: 0.702460
global_step: 1780, epoch: 45, loss: 0.703918
global_step: 1781, epoch: 45, loss: 0.623865
global_step: 1782, epoch: 45, loss: 0.784262
global_step: 1783, epoch: 45, loss: 0.668007
global_step: 1784, epoch: 45, loss: 0.664032
global_step: 1785, epoch: 45, loss: 0.765349
global_step: 1786, epoch: 45, loss: 0.650254
global_step: 1787, epoch: 45, loss: 0.711655
global_step: 1788, epoch: 45, loss: 0.676140
global_step: 1789, epoch: 45, loss: 0.731768
global_step: 1790, epoch: 45, loss: 0.821522
global_step: 1791, epoch: 45, loss: 0.797498
global_step: 1792, epoch: 45, loss: 0.783625
global_step: 1793, epoch: 45, loss: 0.821319
global_step: 1794, epoch: 45, loss: 0.764576
global_step: 1795, epoch: 45, loss: 0.700468
global_step: 1796, epoch: 45, loss: 0.745527
global_step: 1797, epoch: 45, loss: 0.775314
global_step: 1798, epoch: 45, loss: 0.680133
global_step: 1799, epoch: 45, loss: 0.808172
global_step: 1800, epoch: 45, loss: 1.284297
epoch: 45
train	acc: 0.8530	macro: p 0.8729, r 0.6363, f1: 0.6639	micro: p 0.8530, r 0.8530, f1 0.8530	weighted_f1:0.8364
dev	acc: 0.5401	macro: p 0.3165, r 0.2979, f1: 0.2910	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4847
test	acc: 0.6057	macro: p 0.3591, r 0.3238, f1: 0.3257	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5589
global_step: 1801, epoch: 46, loss: 0.714765
global_step: 1802, epoch: 46, loss: 0.694190
global_step: 1803, epoch: 46, loss: 0.748799
global_step: 1804, epoch: 46, loss: 0.679637
global_step: 1805, epoch: 46, loss: 0.709049
global_step: 1806, epoch: 46, loss: 0.744241
global_step: 1807, epoch: 46, loss: 0.761966
global_step: 1808, epoch: 46, loss: 0.761874
global_step: 1809, epoch: 46, loss: 0.816449
global_step: 1810, epoch: 46, loss: 0.702017
global_step: 1811, epoch: 46, loss: 0.729962
global_step: 1812, epoch: 46, loss: 0.668423
global_step: 1813, epoch: 46, loss: 0.748863
global_step: 1814, epoch: 46, loss: 0.754353
global_step: 1815, epoch: 46, loss: 0.614168
global_step: 1816, epoch: 46, loss: 0.886353
global_step: 1817, epoch: 46, loss: 0.778317
global_step: 1818, epoch: 46, loss: 0.837231
global_step: 1819, epoch: 46, loss: 0.725128
global_step: 1820, epoch: 46, loss: 0.759986
global_step: 1821, epoch: 46, loss: 0.702351
global_step: 1822, epoch: 46, loss: 0.744583
global_step: 1823, epoch: 46, loss: 0.842992
global_step: 1824, epoch: 46, loss: 0.754729
global_step: 1825, epoch: 46, loss: 0.736224
global_step: 1826, epoch: 46, loss: 0.738533
global_step: 1827, epoch: 46, loss: 0.677983
global_step: 1828, epoch: 46, loss: 0.741712
global_step: 1829, epoch: 46, loss: 0.692586
global_step: 1830, epoch: 46, loss: 0.675516
global_step: 1831, epoch: 46, loss: 0.734238
global_step: 1832, epoch: 46, loss: 0.699452
global_step: 1833, epoch: 46, loss: 0.672450
global_step: 1834, epoch: 46, loss: 0.694423
global_step: 1835, epoch: 46, loss: 0.700869
global_step: 1836, epoch: 46, loss: 0.769900
global_step: 1837, epoch: 46, loss: 0.655524
global_step: 1838, epoch: 46, loss: 0.800265
global_step: 1839, epoch: 46, loss: 0.783507
global_step: 1840, epoch: 46, loss: 0.817222
epoch: 46
train	acc: 0.8526	macro: p 0.8755, r 0.6275, f1: 0.6536	micro: p 0.8526, r 0.8526, f1 0.8526	weighted_f1:0.8351
dev	acc: 0.5455	macro: p 0.3429, r 0.3073, f1: 0.3004	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4941
test	acc: 0.6034	macro: p 0.3661, r 0.3245, f1: 0.3235	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5581
global_step: 1841, epoch: 47, loss: 0.718316
global_step: 1842, epoch: 47, loss: 0.784438
global_step: 1843, epoch: 47, loss: 0.740686
global_step: 1844, epoch: 47, loss: 0.704747
global_step: 1845, epoch: 47, loss: 0.644180
global_step: 1846, epoch: 47, loss: 0.652575
global_step: 1847, epoch: 47, loss: 0.768173
global_step: 1848, epoch: 47, loss: 0.758340
global_step: 1849, epoch: 47, loss: 0.682665
global_step: 1850, epoch: 47, loss: 0.741659
global_step: 1851, epoch: 47, loss: 0.746218
global_step: 1852, epoch: 47, loss: 0.643724
global_step: 1853, epoch: 47, loss: 0.675580
global_step: 1854, epoch: 47, loss: 0.697952
global_step: 1855, epoch: 47, loss: 0.722246
global_step: 1856, epoch: 47, loss: 0.722749
global_step: 1857, epoch: 47, loss: 0.667782
global_step: 1858, epoch: 47, loss: 0.684540
global_step: 1859, epoch: 47, loss: 0.756706
global_step: 1860, epoch: 47, loss: 0.727297
global_step: 1861, epoch: 47, loss: 0.737212
global_step: 1862, epoch: 47, loss: 0.699629
global_step: 1863, epoch: 47, loss: 0.798810
global_step: 1864, epoch: 47, loss: 0.670289
global_step: 1865, epoch: 47, loss: 0.774716
global_step: 1866, epoch: 47, loss: 0.745995
global_step: 1867, epoch: 47, loss: 0.752133
global_step: 1868, epoch: 47, loss: 0.801592
global_step: 1869, epoch: 47, loss: 0.664853
global_step: 1870, epoch: 47, loss: 0.762293
global_step: 1871, epoch: 47, loss: 0.683186
global_step: 1872, epoch: 47, loss: 0.731168
global_step: 1873, epoch: 47, loss: 0.686620
global_step: 1874, epoch: 47, loss: 0.757789
global_step: 1875, epoch: 47, loss: 0.684478
global_step: 1876, epoch: 47, loss: 0.675502
global_step: 1877, epoch: 47, loss: 0.716845
global_step: 1878, epoch: 47, loss: 0.775305
global_step: 1879, epoch: 47, loss: 0.648710
global_step: 1880, epoch: 47, loss: 0.359902
epoch: 47
train	acc: 0.8586	macro: p 0.8759, r 0.6322, f1: 0.6489	micro: p 0.8586, r 0.8586, f1 0.8586	weighted_f1:0.8404
dev	acc: 0.5356	macro: p 0.3170, r 0.2957, f1: 0.2869	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4827
test	acc: 0.5985	macro: p 0.3651, r 0.3243, f1: 0.3267	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5573
global_step: 1881, epoch: 48, loss: 0.682031
global_step: 1882, epoch: 48, loss: 0.744413
global_step: 1883, epoch: 48, loss: 0.692797
global_step: 1884, epoch: 48, loss: 0.731635
global_step: 1885, epoch: 48, loss: 0.726701
global_step: 1886, epoch: 48, loss: 0.649234
global_step: 1887, epoch: 48, loss: 0.695702
global_step: 1888, epoch: 48, loss: 0.653851
global_step: 1889, epoch: 48, loss: 0.705178
global_step: 1890, epoch: 48, loss: 0.653919
global_step: 1891, epoch: 48, loss: 0.745279
global_step: 1892, epoch: 48, loss: 0.710446
global_step: 1893, epoch: 48, loss: 0.730510
global_step: 1894, epoch: 48, loss: 0.701861
global_step: 1895, epoch: 48, loss: 0.617726
global_step: 1896, epoch: 48, loss: 0.685751
global_step: 1897, epoch: 48, loss: 0.729123
global_step: 1898, epoch: 48, loss: 0.707696
global_step: 1899, epoch: 48, loss: 0.832279
global_step: 1900, epoch: 48, loss: 0.632047
global_step: 1901, epoch: 48, loss: 0.732149
global_step: 1902, epoch: 48, loss: 0.812411
global_step: 1903, epoch: 48, loss: 0.816561
global_step: 1904, epoch: 48, loss: 0.696843
global_step: 1905, epoch: 48, loss: 0.657443
global_step: 1906, epoch: 48, loss: 0.757006
global_step: 1907, epoch: 48, loss: 0.759924
global_step: 1908, epoch: 48, loss: 0.672691
global_step: 1909, epoch: 48, loss: 0.632797
global_step: 1910, epoch: 48, loss: 0.721648
global_step: 1911, epoch: 48, loss: 0.658652
global_step: 1912, epoch: 48, loss: 0.719305
global_step: 1913, epoch: 48, loss: 0.753863
global_step: 1914, epoch: 48, loss: 0.673760
global_step: 1915, epoch: 48, loss: 0.751384
global_step: 1916, epoch: 48, loss: 0.730913
global_step: 1917, epoch: 48, loss: 0.759017
global_step: 1918, epoch: 48, loss: 0.642850
global_step: 1919, epoch: 48, loss: 0.783806
global_step: 1920, epoch: 48, loss: 0.585192
epoch: 48
train	acc: 0.8517	macro: p 0.8800, r 0.6318, f1: 0.6604	micro: p 0.8517, r 0.8517, f1 0.8517	weighted_f1:0.8348
dev	acc: 0.5410	macro: p 0.3255, r 0.2969, f1: 0.2888	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4847
test	acc: 0.6027	macro: p 0.3697, r 0.3192, f1: 0.3219	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5551
global_step: 1921, epoch: 49, loss: 0.634580
global_step: 1922, epoch: 49, loss: 0.662482
global_step: 1923, epoch: 49, loss: 0.774835
global_step: 1924, epoch: 49, loss: 0.598351
global_step: 1925, epoch: 49, loss: 0.720864
global_step: 1926, epoch: 49, loss: 0.656470
global_step: 1927, epoch: 49, loss: 0.704962
global_step: 1928, epoch: 49, loss: 0.595947
global_step: 1929, epoch: 49, loss: 0.704431
global_step: 1930, epoch: 49, loss: 0.661226
global_step: 1931, epoch: 49, loss: 0.739651
global_step: 1932, epoch: 49, loss: 0.652430
global_step: 1933, epoch: 49, loss: 0.674767
global_step: 1934, epoch: 49, loss: 0.678031
global_step: 1935, epoch: 49, loss: 0.692853
global_step: 1936, epoch: 49, loss: 0.639425
global_step: 1937, epoch: 49, loss: 0.699160
global_step: 1938, epoch: 49, loss: 0.621463
global_step: 1939, epoch: 49, loss: 0.701643
global_step: 1940, epoch: 49, loss: 0.839905
global_step: 1941, epoch: 49, loss: 0.679810
global_step: 1942, epoch: 49, loss: 0.753738
global_step: 1943, epoch: 49, loss: 0.669592
global_step: 1944, epoch: 49, loss: 0.758461
global_step: 1945, epoch: 49, loss: 0.651481
global_step: 1946, epoch: 49, loss: 0.671724
global_step: 1947, epoch: 49, loss: 0.596319
global_step: 1948, epoch: 49, loss: 0.606543
global_step: 1949, epoch: 49, loss: 0.680064
global_step: 1950, epoch: 49, loss: 0.584280
global_step: 1951, epoch: 49, loss: 0.714637
global_step: 1952, epoch: 49, loss: 0.616847
global_step: 1953, epoch: 49, loss: 0.642891
global_step: 1954, epoch: 49, loss: 0.692701
global_step: 1955, epoch: 49, loss: 0.803216
global_step: 1956, epoch: 49, loss: 0.797887
global_step: 1957, epoch: 49, loss: 0.778350
global_step: 1958, epoch: 49, loss: 0.750668
global_step: 1959, epoch: 49, loss: 0.724191
global_step: 1960, epoch: 49, loss: 1.188395
epoch: 49
train	acc: 0.8650	macro: p 0.8862, r 0.6558, f1: 0.6876	micro: p 0.8650, r 0.8650, f1 0.8650	weighted_f1:0.8506
dev	acc: 0.5537	macro: p 0.4151, r 0.3155, f1: 0.3146	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5047
test	acc: 0.6027	macro: p 0.3634, r 0.3238, f1: 0.3267	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5597
New best model!
global_step: 1961, epoch: 50, loss: 0.634668
global_step: 1962, epoch: 50, loss: 0.589975
global_step: 1963, epoch: 50, loss: 0.649644
global_step: 1964, epoch: 50, loss: 0.745744
global_step: 1965, epoch: 50, loss: 0.740190
global_step: 1966, epoch: 50, loss: 0.660219
global_step: 1967, epoch: 50, loss: 0.681459
global_step: 1968, epoch: 50, loss: 0.691281
global_step: 1969, epoch: 50, loss: 0.628479
global_step: 1970, epoch: 50, loss: 0.724355
global_step: 1971, epoch: 50, loss: 0.593921
global_step: 1972, epoch: 50, loss: 0.780875
global_step: 1973, epoch: 50, loss: 0.618430
global_step: 1974, epoch: 50, loss: 0.711535
global_step: 1975, epoch: 50, loss: 0.645755
global_step: 1976, epoch: 50, loss: 0.716552
global_step: 1977, epoch: 50, loss: 0.672802
global_step: 1978, epoch: 50, loss: 0.718341
global_step: 1979, epoch: 50, loss: 0.774844
global_step: 1980, epoch: 50, loss: 0.702213
global_step: 1981, epoch: 50, loss: 0.564152
global_step: 1982, epoch: 50, loss: 0.731589
global_step: 1983, epoch: 50, loss: 0.671011
global_step: 1984, epoch: 50, loss: 0.652264
global_step: 1985, epoch: 50, loss: 0.630965
global_step: 1986, epoch: 50, loss: 0.739176
global_step: 1987, epoch: 50, loss: 0.714609
global_step: 1988, epoch: 50, loss: 0.724988
global_step: 1989, epoch: 50, loss: 0.663264
global_step: 1990, epoch: 50, loss: 0.657315
global_step: 1991, epoch: 50, loss: 0.602007
global_step: 1992, epoch: 50, loss: 0.752645
global_step: 1993, epoch: 50, loss: 0.757470
global_step: 1994, epoch: 50, loss: 0.716285
global_step: 1995, epoch: 50, loss: 0.658485
global_step: 1996, epoch: 50, loss: 0.665526
global_step: 1997, epoch: 50, loss: 0.646414
global_step: 1998, epoch: 50, loss: 0.673863
global_step: 1999, epoch: 50, loss: 0.651215
global_step: 2000, epoch: 50, loss: 0.567722
epoch: 50
train	acc: 0.8641	macro: p 0.8929, r 0.6547, f1: 0.6897	micro: p 0.8641, r 0.8641, f1 0.8641	weighted_f1:0.8490
dev	acc: 0.5455	macro: p 0.4050, r 0.3047, f1: 0.3019	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4900
test	acc: 0.6046	macro: p 0.4973, r 0.3194, f1: 0.3216	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5545
global_step: 2001, epoch: 51, loss: 0.576440
global_step: 2002, epoch: 51, loss: 0.690886
global_step: 2003, epoch: 51, loss: 0.706450
global_step: 2004, epoch: 51, loss: 0.649586
global_step: 2005, epoch: 51, loss: 0.722632
global_step: 2006, epoch: 51, loss: 0.596886
global_step: 2007, epoch: 51, loss: 0.591278
global_step: 2008, epoch: 51, loss: 0.659258
global_step: 2009, epoch: 51, loss: 0.673403
global_step: 2010, epoch: 51, loss: 0.625552
global_step: 2011, epoch: 51, loss: 0.549895
global_step: 2012, epoch: 51, loss: 0.676488
global_step: 2013, epoch: 51, loss: 0.711617
global_step: 2014, epoch: 51, loss: 0.797134
global_step: 2015, epoch: 51, loss: 0.689138
global_step: 2016, epoch: 51, loss: 0.620142
global_step: 2017, epoch: 51, loss: 0.704778
global_step: 2018, epoch: 51, loss: 0.563903
global_step: 2019, epoch: 51, loss: 0.608964
global_step: 2020, epoch: 51, loss: 0.702817
global_step: 2021, epoch: 51, loss: 0.760558
global_step: 2022, epoch: 51, loss: 0.618702
global_step: 2023, epoch: 51, loss: 0.836970
global_step: 2024, epoch: 51, loss: 0.629518
global_step: 2025, epoch: 51, loss: 0.715532
global_step: 2026, epoch: 51, loss: 0.688396
global_step: 2027, epoch: 51, loss: 0.622218
global_step: 2028, epoch: 51, loss: 0.728141
global_step: 2029, epoch: 51, loss: 0.677890
global_step: 2030, epoch: 51, loss: 0.692423
global_step: 2031, epoch: 51, loss: 0.738153
global_step: 2032, epoch: 51, loss: 0.717762
global_step: 2033, epoch: 51, loss: 0.646897
global_step: 2034, epoch: 51, loss: 0.663555
global_step: 2035, epoch: 51, loss: 0.658116
global_step: 2036, epoch: 51, loss: 0.586292
global_step: 2037, epoch: 51, loss: 0.785862
global_step: 2038, epoch: 51, loss: 0.628765
global_step: 2039, epoch: 51, loss: 0.643733
global_step: 2040, epoch: 51, loss: 1.743684
epoch: 51
train	acc: 0.8764	macro: p 0.8927, r 0.6944, f1: 0.7351	micro: p 0.8764, r 0.8764, f1 0.8764	weighted_f1:0.8660
dev	acc: 0.5464	macro: p 0.4002, r 0.3079, f1: 0.3047	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4945
test	acc: 0.6042	macro: p 0.5033, r 0.3234, f1: 0.3283	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5591
global_step: 2041, epoch: 52, loss: 0.699200
global_step: 2042, epoch: 52, loss: 0.675197
global_step: 2043, epoch: 52, loss: 0.598535
global_step: 2044, epoch: 52, loss: 0.562302
global_step: 2045, epoch: 52, loss: 0.635967
global_step: 2046, epoch: 52, loss: 0.590321
global_step: 2047, epoch: 52, loss: 0.581564
global_step: 2048, epoch: 52, loss: 0.567745
global_step: 2049, epoch: 52, loss: 0.639862
global_step: 2050, epoch: 52, loss: 0.704065
global_step: 2051, epoch: 52, loss: 0.651363
global_step: 2052, epoch: 52, loss: 0.750521
global_step: 2053, epoch: 52, loss: 0.560154
global_step: 2054, epoch: 52, loss: 0.629566
global_step: 2055, epoch: 52, loss: 0.629106
global_step: 2056, epoch: 52, loss: 0.587474
global_step: 2057, epoch: 52, loss: 0.686882
global_step: 2058, epoch: 52, loss: 0.665252
global_step: 2059, epoch: 52, loss: 0.764306
global_step: 2060, epoch: 52, loss: 0.796599
global_step: 2061, epoch: 52, loss: 0.711027
global_step: 2062, epoch: 52, loss: 0.798442
global_step: 2063, epoch: 52, loss: 0.607203
global_step: 2064, epoch: 52, loss: 0.640997
global_step: 2065, epoch: 52, loss: 0.663286
global_step: 2066, epoch: 52, loss: 0.555513
global_step: 2067, epoch: 52, loss: 0.648410
global_step: 2068, epoch: 52, loss: 0.571631
global_step: 2069, epoch: 52, loss: 0.805325
global_step: 2070, epoch: 52, loss: 0.599079
global_step: 2071, epoch: 52, loss: 0.555382
global_step: 2072, epoch: 52, loss: 0.701400
global_step: 2073, epoch: 52, loss: 0.639601
global_step: 2074, epoch: 52, loss: 0.629133
global_step: 2075, epoch: 52, loss: 0.777316
global_step: 2076, epoch: 52, loss: 0.629898
global_step: 2077, epoch: 52, loss: 0.678677
global_step: 2078, epoch: 52, loss: 0.656578
global_step: 2079, epoch: 52, loss: 0.714157
global_step: 2080, epoch: 52, loss: 0.099734
epoch: 52
train	acc: 0.8724	macro: p 0.8942, r 0.6802, f1: 0.7217	micro: p 0.8724, r 0.8724, f1 0.8724	weighted_f1:0.8605
dev	acc: 0.5500	macro: p 0.3416, r 0.3041, f1: 0.3004	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4937
test	acc: 0.6073	macro: p 0.3620, r 0.3181, f1: 0.3215	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5577
global_step: 2081, epoch: 53, loss: 0.555353
global_step: 2082, epoch: 53, loss: 0.676256
global_step: 2083, epoch: 53, loss: 0.651593
global_step: 2084, epoch: 53, loss: 0.657025
global_step: 2085, epoch: 53, loss: 0.763565
global_step: 2086, epoch: 53, loss: 0.665617
global_step: 2087, epoch: 53, loss: 0.670761
global_step: 2088, epoch: 53, loss: 0.647670
global_step: 2089, epoch: 53, loss: 0.737667
global_step: 2090, epoch: 53, loss: 0.576459
global_step: 2091, epoch: 53, loss: 0.613438
global_step: 2092, epoch: 53, loss: 0.516344
global_step: 2093, epoch: 53, loss: 0.689135
global_step: 2094, epoch: 53, loss: 0.658914
global_step: 2095, epoch: 53, loss: 0.678921
global_step: 2096, epoch: 53, loss: 0.640058
global_step: 2097, epoch: 53, loss: 0.656796
global_step: 2098, epoch: 53, loss: 0.674788
global_step: 2099, epoch: 53, loss: 0.661706
global_step: 2100, epoch: 53, loss: 0.616427
global_step: 2101, epoch: 53, loss: 0.650464
global_step: 2102, epoch: 53, loss: 0.699561
global_step: 2103, epoch: 53, loss: 0.643520
global_step: 2104, epoch: 53, loss: 0.641824
global_step: 2105, epoch: 53, loss: 0.650120
global_step: 2106, epoch: 53, loss: 0.693852
global_step: 2107, epoch: 53, loss: 0.659448
global_step: 2108, epoch: 53, loss: 0.587003
global_step: 2109, epoch: 53, loss: 0.706216
global_step: 2110, epoch: 53, loss: 0.638527
global_step: 2111, epoch: 53, loss: 0.603280
global_step: 2112, epoch: 53, loss: 0.644893
global_step: 2113, epoch: 53, loss: 0.620231
global_step: 2114, epoch: 53, loss: 0.638656
global_step: 2115, epoch: 53, loss: 0.604186
global_step: 2116, epoch: 53, loss: 0.698312
global_step: 2117, epoch: 53, loss: 0.588395
global_step: 2118, epoch: 53, loss: 0.694805
global_step: 2119, epoch: 53, loss: 0.707091
global_step: 2120, epoch: 53, loss: 1.292852
epoch: 53
train	acc: 0.8878	macro: p 0.8974, r 0.7195, f1: 0.7544	micro: p 0.8878, r 0.8878, f1 0.8878	weighted_f1:0.8798
dev	acc: 0.5419	macro: p 0.4030, r 0.3184, f1: 0.3162	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5033
test	acc: 0.5962	macro: p 0.4316, r 0.3404, f1: 0.3421	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5661
global_step: 2121, epoch: 54, loss: 0.678182
global_step: 2122, epoch: 54, loss: 0.577626
global_step: 2123, epoch: 54, loss: 0.676723
global_step: 2124, epoch: 54, loss: 0.672815
global_step: 2125, epoch: 54, loss: 0.576855
global_step: 2126, epoch: 54, loss: 0.569306
global_step: 2127, epoch: 54, loss: 0.623214
global_step: 2128, epoch: 54, loss: 0.647418
global_step: 2129, epoch: 54, loss: 0.607883
global_step: 2130, epoch: 54, loss: 0.681748
global_step: 2131, epoch: 54, loss: 0.542504
global_step: 2132, epoch: 54, loss: 0.626055
global_step: 2133, epoch: 54, loss: 0.575079
global_step: 2134, epoch: 54, loss: 0.617217
global_step: 2135, epoch: 54, loss: 0.588995
global_step: 2136, epoch: 54, loss: 0.641195
global_step: 2137, epoch: 54, loss: 0.640263
global_step: 2138, epoch: 54, loss: 0.650073
global_step: 2139, epoch: 54, loss: 0.697018
global_step: 2140, epoch: 54, loss: 0.552631
global_step: 2141, epoch: 54, loss: 0.624445
global_step: 2142, epoch: 54, loss: 0.602835
global_step: 2143, epoch: 54, loss: 0.592967
global_step: 2144, epoch: 54, loss: 0.546957
global_step: 2145, epoch: 54, loss: 0.568224
global_step: 2146, epoch: 54, loss: 0.641483
global_step: 2147, epoch: 54, loss: 0.634770
global_step: 2148, epoch: 54, loss: 0.695701
global_step: 2149, epoch: 54, loss: 0.672339
global_step: 2150, epoch: 54, loss: 0.641160
global_step: 2151, epoch: 54, loss: 0.800794
global_step: 2152, epoch: 54, loss: 0.669648
global_step: 2153, epoch: 54, loss: 0.649690
global_step: 2154, epoch: 54, loss: 0.657014
global_step: 2155, epoch: 54, loss: 0.626091
global_step: 2156, epoch: 54, loss: 0.621275
global_step: 2157, epoch: 54, loss: 0.569240
global_step: 2158, epoch: 54, loss: 0.612013
global_step: 2159, epoch: 54, loss: 0.687063
global_step: 2160, epoch: 54, loss: 1.614632
epoch: 54
train	acc: 0.8986	macro: p 0.9008, r 0.7552, f1: 0.7928	micro: p 0.8986, r 0.8986, f1 0.8986	weighted_f1:0.8930
dev	acc: 0.5482	macro: p 0.3980, r 0.3169, f1: 0.3169	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5061
test	acc: 0.5958	macro: p 0.3978, r 0.3371, f1: 0.3400	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5634
New best model!
global_step: 2161, epoch: 55, loss: 0.622216
global_step: 2162, epoch: 55, loss: 0.630011
global_step: 2163, epoch: 55, loss: 0.504319
global_step: 2164, epoch: 55, loss: 0.625358
global_step: 2165, epoch: 55, loss: 0.640121
global_step: 2166, epoch: 55, loss: 0.675935
global_step: 2167, epoch: 55, loss: 0.567593
global_step: 2168, epoch: 55, loss: 0.644676
global_step: 2169, epoch: 55, loss: 0.665008
global_step: 2170, epoch: 55, loss: 0.569685
global_step: 2171, epoch: 55, loss: 0.563215
global_step: 2172, epoch: 55, loss: 0.641497
global_step: 2173, epoch: 55, loss: 0.589454
global_step: 2174, epoch: 55, loss: 0.571062
global_step: 2175, epoch: 55, loss: 0.755902
global_step: 2176, epoch: 55, loss: 0.499348
global_step: 2177, epoch: 55, loss: 0.579080
global_step: 2178, epoch: 55, loss: 0.644267
global_step: 2179, epoch: 55, loss: 0.727996
global_step: 2180, epoch: 55, loss: 0.614216
global_step: 2181, epoch: 55, loss: 0.676067
global_step: 2182, epoch: 55, loss: 0.456652
global_step: 2183, epoch: 55, loss: 0.653861
global_step: 2184, epoch: 55, loss: 0.680236
global_step: 2185, epoch: 55, loss: 0.580687
global_step: 2186, epoch: 55, loss: 0.554123
global_step: 2187, epoch: 55, loss: 0.575156
global_step: 2188, epoch: 55, loss: 0.581872
global_step: 2189, epoch: 55, loss: 0.668081
global_step: 2190, epoch: 55, loss: 0.497069
global_step: 2191, epoch: 55, loss: 0.652216
global_step: 2192, epoch: 55, loss: 0.697556
global_step: 2193, epoch: 55, loss: 0.546262
global_step: 2194, epoch: 55, loss: 0.619444
global_step: 2195, epoch: 55, loss: 0.612512
global_step: 2196, epoch: 55, loss: 0.577097
global_step: 2197, epoch: 55, loss: 0.831493
global_step: 2198, epoch: 55, loss: 0.578840
global_step: 2199, epoch: 55, loss: 0.666125
global_step: 2200, epoch: 55, loss: 0.597801
epoch: 55
train	acc: 0.8939	macro: p 0.9049, r 0.7278, f1: 0.7687	micro: p 0.8939, r 0.8939, f1 0.8939	weighted_f1:0.8859
dev	acc: 0.5446	macro: p 0.4068, r 0.3122, f1: 0.3109	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4979
test	acc: 0.6000	macro: p 0.3554, r 0.3236, f1: 0.3259	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5582
global_step: 2201, epoch: 56, loss: 0.627475
global_step: 2202, epoch: 56, loss: 0.634006
global_step: 2203, epoch: 56, loss: 0.535640
global_step: 2204, epoch: 56, loss: 0.657890
global_step: 2205, epoch: 56, loss: 0.674638
global_step: 2206, epoch: 56, loss: 0.597823
global_step: 2207, epoch: 56, loss: 0.669780
global_step: 2208, epoch: 56, loss: 0.678087
global_step: 2209, epoch: 56, loss: 0.631702
global_step: 2210, epoch: 56, loss: 0.796784
global_step: 2211, epoch: 56, loss: 0.598357
global_step: 2212, epoch: 56, loss: 0.614041
global_step: 2213, epoch: 56, loss: 0.696121
global_step: 2214, epoch: 56, loss: 0.710946
global_step: 2215, epoch: 56, loss: 0.584798
global_step: 2216, epoch: 56, loss: 0.615390
global_step: 2217, epoch: 56, loss: 0.624343
global_step: 2218, epoch: 56, loss: 0.547722
global_step: 2219, epoch: 56, loss: 0.647220
global_step: 2220, epoch: 56, loss: 0.651967
global_step: 2221, epoch: 56, loss: 0.604562
global_step: 2222, epoch: 56, loss: 0.660037
global_step: 2223, epoch: 56, loss: 0.550387
global_step: 2224, epoch: 56, loss: 0.629330
global_step: 2225, epoch: 56, loss: 0.673835
global_step: 2226, epoch: 56, loss: 0.635323
global_step: 2227, epoch: 56, loss: 0.581397
global_step: 2228, epoch: 56, loss: 0.547536
global_step: 2229, epoch: 56, loss: 0.632918
global_step: 2230, epoch: 56, loss: 0.619499
global_step: 2231, epoch: 56, loss: 0.674654
global_step: 2232, epoch: 56, loss: 0.584612
global_step: 2233, epoch: 56, loss: 0.521619
global_step: 2234, epoch: 56, loss: 0.622704
global_step: 2235, epoch: 56, loss: 0.627080
global_step: 2236, epoch: 56, loss: 0.586061
global_step: 2237, epoch: 56, loss: 0.619207
global_step: 2238, epoch: 56, loss: 0.583136
global_step: 2239, epoch: 56, loss: 0.594972
global_step: 2240, epoch: 56, loss: 0.211089
epoch: 56
train	acc: 0.8855	macro: p 0.9082, r 0.7133, f1: 0.7574	micro: p 0.8855, r 0.8855, f1 0.8855	weighted_f1:0.8767
dev	acc: 0.5446	macro: p 0.3848, r 0.3076, f1: 0.3067	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4955
test	acc: 0.6057	macro: p 0.3656, r 0.3256, f1: 0.3287	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5624
global_step: 2241, epoch: 57, loss: 0.549625
global_step: 2242, epoch: 57, loss: 0.527229
global_step: 2243, epoch: 57, loss: 0.525814
global_step: 2244, epoch: 57, loss: 0.530935
global_step: 2245, epoch: 57, loss: 0.618961
global_step: 2246, epoch: 57, loss: 0.597139
global_step: 2247, epoch: 57, loss: 0.594185
global_step: 2248, epoch: 57, loss: 0.521384
global_step: 2249, epoch: 57, loss: 0.659996
global_step: 2250, epoch: 57, loss: 0.597467
global_step: 2251, epoch: 57, loss: 0.589409
global_step: 2252, epoch: 57, loss: 0.721675
global_step: 2253, epoch: 57, loss: 0.633328
global_step: 2254, epoch: 57, loss: 0.610406
global_step: 2255, epoch: 57, loss: 0.586633
global_step: 2256, epoch: 57, loss: 0.569949
global_step: 2257, epoch: 57, loss: 0.529492
global_step: 2258, epoch: 57, loss: 0.587293
global_step: 2259, epoch: 57, loss: 0.557992
global_step: 2260, epoch: 57, loss: 0.566999
global_step: 2261, epoch: 57, loss: 0.569695
global_step: 2262, epoch: 57, loss: 0.644853
global_step: 2263, epoch: 57, loss: 0.672461
global_step: 2264, epoch: 57, loss: 0.694007
global_step: 2265, epoch: 57, loss: 0.638880
global_step: 2266, epoch: 57, loss: 0.592991
global_step: 2267, epoch: 57, loss: 0.605378
global_step: 2268, epoch: 57, loss: 0.551210
global_step: 2269, epoch: 57, loss: 0.532247
global_step: 2270, epoch: 57, loss: 0.676317
global_step: 2271, epoch: 57, loss: 0.628068
global_step: 2272, epoch: 57, loss: 0.642527
global_step: 2273, epoch: 57, loss: 0.590253
global_step: 2274, epoch: 57, loss: 0.563531
global_step: 2275, epoch: 57, loss: 0.613958
global_step: 2276, epoch: 57, loss: 0.633457
global_step: 2277, epoch: 57, loss: 0.648678
global_step: 2278, epoch: 57, loss: 0.607157
global_step: 2279, epoch: 57, loss: 0.706152
global_step: 2280, epoch: 57, loss: 0.245179
epoch: 57
train	acc: 0.8967	macro: p 0.9119, r 0.7423, f1: 0.7868	micro: p 0.8967, r 0.8967, f1 0.8967	weighted_f1:0.8898
dev	acc: 0.5401	macro: p 0.3903, r 0.3051, f1: 0.3000	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4894
test	acc: 0.6027	macro: p 0.4284, r 0.3282, f1: 0.3291	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5594
global_step: 2281, epoch: 58, loss: 0.614286
global_step: 2282, epoch: 58, loss: 0.554148
global_step: 2283, epoch: 58, loss: 0.468399
global_step: 2284, epoch: 58, loss: 0.584044
global_step: 2285, epoch: 58, loss: 0.601073
global_step: 2286, epoch: 58, loss: 0.622252
global_step: 2287, epoch: 58, loss: 0.482700
global_step: 2288, epoch: 58, loss: 0.608543
global_step: 2289, epoch: 58, loss: 0.624153
global_step: 2290, epoch: 58, loss: 0.563367
global_step: 2291, epoch: 58, loss: 0.556244
global_step: 2292, epoch: 58, loss: 0.632642
global_step: 2293, epoch: 58, loss: 0.619964
global_step: 2294, epoch: 58, loss: 0.635749
global_step: 2295, epoch: 58, loss: 0.635689
global_step: 2296, epoch: 58, loss: 0.664942
global_step: 2297, epoch: 58, loss: 0.634692
global_step: 2298, epoch: 58, loss: 0.598225
global_step: 2299, epoch: 58, loss: 0.567294
global_step: 2300, epoch: 58, loss: 0.633924
global_step: 2301, epoch: 58, loss: 0.579124
global_step: 2302, epoch: 58, loss: 0.589381
global_step: 2303, epoch: 58, loss: 0.501223
global_step: 2304, epoch: 58, loss: 0.556928
global_step: 2305, epoch: 58, loss: 0.596241
global_step: 2306, epoch: 58, loss: 0.690164
global_step: 2307, epoch: 58, loss: 0.652603
global_step: 2308, epoch: 58, loss: 0.531880
global_step: 2309, epoch: 58, loss: 0.575424
global_step: 2310, epoch: 58, loss: 0.535398
global_step: 2311, epoch: 58, loss: 0.560794
global_step: 2312, epoch: 58, loss: 0.634578
global_step: 2313, epoch: 58, loss: 0.642312
global_step: 2314, epoch: 58, loss: 0.573355
global_step: 2315, epoch: 58, loss: 0.594957
global_step: 2316, epoch: 58, loss: 0.578619
global_step: 2317, epoch: 58, loss: 0.598784
global_step: 2318, epoch: 58, loss: 0.639283
global_step: 2319, epoch: 58, loss: 0.614487
global_step: 2320, epoch: 58, loss: 0.697618
epoch: 58
train	acc: 0.9023	macro: p 0.9150, r 0.7603, f1: 0.8037	micro: p 0.9023, r 0.9023, f1 0.9023	weighted_f1:0.8968
dev	acc: 0.5446	macro: p 0.3795, r 0.3119, f1: 0.3110	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4990
test	acc: 0.6027	macro: p 0.3563, r 0.3275, f1: 0.3267	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5603
global_step: 2321, epoch: 59, loss: 0.589482
global_step: 2322, epoch: 59, loss: 0.542540
global_step: 2323, epoch: 59, loss: 0.640933
global_step: 2324, epoch: 59, loss: 0.539590
global_step: 2325, epoch: 59, loss: 0.572886
global_step: 2326, epoch: 59, loss: 0.433467
global_step: 2327, epoch: 59, loss: 0.582222
global_step: 2328, epoch: 59, loss: 0.634065
global_step: 2329, epoch: 59, loss: 0.557911
global_step: 2330, epoch: 59, loss: 0.573591
global_step: 2331, epoch: 59, loss: 0.632434
global_step: 2332, epoch: 59, loss: 0.576163
global_step: 2333, epoch: 59, loss: 0.561059
global_step: 2334, epoch: 59, loss: 0.613692
global_step: 2335, epoch: 59, loss: 0.535516
global_step: 2336, epoch: 59, loss: 0.558179
global_step: 2337, epoch: 59, loss: 0.577927
global_step: 2338, epoch: 59, loss: 0.605681
global_step: 2339, epoch: 59, loss: 0.596546
global_step: 2340, epoch: 59, loss: 0.533074
global_step: 2341, epoch: 59, loss: 0.552401
global_step: 2342, epoch: 59, loss: 0.615669
global_step: 2343, epoch: 59, loss: 0.604074
global_step: 2344, epoch: 59, loss: 0.678983
global_step: 2345, epoch: 59, loss: 0.509673
global_step: 2346, epoch: 59, loss: 0.545682
global_step: 2347, epoch: 59, loss: 0.534982
global_step: 2348, epoch: 59, loss: 0.605903
global_step: 2349, epoch: 59, loss: 0.628084
global_step: 2350, epoch: 59, loss: 0.579694
global_step: 2351, epoch: 59, loss: 0.608647
global_step: 2352, epoch: 59, loss: 0.549015
global_step: 2353, epoch: 59, loss: 0.712979
global_step: 2354, epoch: 59, loss: 0.609311
global_step: 2355, epoch: 59, loss: 0.642346
global_step: 2356, epoch: 59, loss: 0.541850
global_step: 2357, epoch: 59, loss: 0.574700
global_step: 2358, epoch: 59, loss: 0.632401
global_step: 2359, epoch: 59, loss: 0.528090
global_step: 2360, epoch: 59, loss: 0.956389
epoch: 59
train	acc: 0.9064	macro: p 0.9166, r 0.7740, f1: 0.8174	micro: p 0.9064, r 0.9064, f1 0.9064	weighted_f1:0.9017
dev	acc: 0.5410	macro: p 0.3929, r 0.3084, f1: 0.3067	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4941
test	acc: 0.5950	macro: p 0.3729, r 0.3216, f1: 0.3250	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5537
global_step: 2361, epoch: 60, loss: 0.599296
global_step: 2362, epoch: 60, loss: 0.547936
global_step: 2363, epoch: 60, loss: 0.648519
global_step: 2364, epoch: 60, loss: 0.624725
global_step: 2365, epoch: 60, loss: 0.660679
global_step: 2366, epoch: 60, loss: 0.623697
global_step: 2367, epoch: 60, loss: 0.576143
global_step: 2368, epoch: 60, loss: 0.674469
global_step: 2369, epoch: 60, loss: 0.490327
global_step: 2370, epoch: 60, loss: 0.658065
global_step: 2371, epoch: 60, loss: 0.574837
global_step: 2372, epoch: 60, loss: 0.552157
global_step: 2373, epoch: 60, loss: 0.479787
global_step: 2374, epoch: 60, loss: 0.572789
global_step: 2375, epoch: 60, loss: 0.592951
global_step: 2376, epoch: 60, loss: 0.509674
global_step: 2377, epoch: 60, loss: 0.636544
global_step: 2378, epoch: 60, loss: 0.527701
global_step: 2379, epoch: 60, loss: 0.642213
global_step: 2380, epoch: 60, loss: 0.560048
global_step: 2381, epoch: 60, loss: 0.527978
global_step: 2382, epoch: 60, loss: 0.679214
global_step: 2383, epoch: 60, loss: 0.650926
global_step: 2384, epoch: 60, loss: 0.529718
global_step: 2385, epoch: 60, loss: 0.566620
global_step: 2386, epoch: 60, loss: 0.619113
global_step: 2387, epoch: 60, loss: 0.576950
global_step: 2388, epoch: 60, loss: 0.475937
global_step: 2389, epoch: 60, loss: 0.613542
global_step: 2390, epoch: 60, loss: 0.472701
global_step: 2391, epoch: 60, loss: 0.596272
global_step: 2392, epoch: 60, loss: 0.573921
global_step: 2393, epoch: 60, loss: 0.678593
global_step: 2394, epoch: 60, loss: 0.708994
global_step: 2395, epoch: 60, loss: 0.564419
global_step: 2396, epoch: 60, loss: 0.644422
global_step: 2397, epoch: 60, loss: 0.605757
global_step: 2398, epoch: 60, loss: 0.603968
global_step: 2399, epoch: 60, loss: 0.502001
global_step: 2400, epoch: 60, loss: 0.479436
epoch: 60
train	acc: 0.9135	macro: p 0.9247, r 0.8007, f1: 0.8430	micro: p 0.9135, r 0.9135, f1 0.9135	weighted_f1:0.9105
dev	acc: 0.5419	macro: p 0.3684, r 0.3124, f1: 0.3077	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4973
test	acc: 0.5958	macro: p 0.3842, r 0.3293, f1: 0.3285	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5577
global_step: 2401, epoch: 61, loss: 0.672328
global_step: 2402, epoch: 61, loss: 0.485211
global_step: 2403, epoch: 61, loss: 0.595483
global_step: 2404, epoch: 61, loss: 0.611158
global_step: 2405, epoch: 61, loss: 0.675067
global_step: 2406, epoch: 61, loss: 0.553947
global_step: 2407, epoch: 61, loss: 0.509934
global_step: 2408, epoch: 61, loss: 0.573574
global_step: 2409, epoch: 61, loss: 0.671503
global_step: 2410, epoch: 61, loss: 0.561420
global_step: 2411, epoch: 61, loss: 0.481446
global_step: 2412, epoch: 61, loss: 0.546771
global_step: 2413, epoch: 61, loss: 0.618720
global_step: 2414, epoch: 61, loss: 0.538759
global_step: 2415, epoch: 61, loss: 0.586374
global_step: 2416, epoch: 61, loss: 0.623294
global_step: 2417, epoch: 61, loss: 0.642629
global_step: 2418, epoch: 61, loss: 0.569693
global_step: 2419, epoch: 61, loss: 0.511724
global_step: 2420, epoch: 61, loss: 0.581696
global_step: 2421, epoch: 61, loss: 0.529777
global_step: 2422, epoch: 61, loss: 0.519525
global_step: 2423, epoch: 61, loss: 0.607273
global_step: 2424, epoch: 61, loss: 0.527192
global_step: 2425, epoch: 61, loss: 0.626235
global_step: 2426, epoch: 61, loss: 0.598713
global_step: 2427, epoch: 61, loss: 0.569642
global_step: 2428, epoch: 61, loss: 0.652707
global_step: 2429, epoch: 61, loss: 0.535520
global_step: 2430, epoch: 61, loss: 0.456282
global_step: 2431, epoch: 61, loss: 0.523305
global_step: 2432, epoch: 61, loss: 0.563815
global_step: 2433, epoch: 61, loss: 0.607081
global_step: 2434, epoch: 61, loss: 0.610882
global_step: 2435, epoch: 61, loss: 0.560265
global_step: 2436, epoch: 61, loss: 0.602687
global_step: 2437, epoch: 61, loss: 0.622854
global_step: 2438, epoch: 61, loss: 0.588283
global_step: 2439, epoch: 61, loss: 0.618082
global_step: 2440, epoch: 61, loss: 0.769866
epoch: 61
train	acc: 0.9172	macro: p 0.9281, r 0.8041, f1: 0.8461	micro: p 0.9172, r 0.9172, f1 0.9172	weighted_f1:0.9139
dev	acc: 0.5410	macro: p 0.3967, r 0.3078, f1: 0.3050	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4935
test	acc: 0.6004	macro: p 0.4019, r 0.3271, f1: 0.3312	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5587
global_step: 2441, epoch: 62, loss: 0.618964
global_step: 2442, epoch: 62, loss: 0.596087
global_step: 2443, epoch: 62, loss: 0.489974
global_step: 2444, epoch: 62, loss: 0.540069
global_step: 2445, epoch: 62, loss: 0.542411
global_step: 2446, epoch: 62, loss: 0.434257
global_step: 2447, epoch: 62, loss: 0.621863
global_step: 2448, epoch: 62, loss: 0.583758
global_step: 2449, epoch: 62, loss: 0.503033
global_step: 2450, epoch: 62, loss: 0.625705
global_step: 2451, epoch: 62, loss: 0.453493
global_step: 2452, epoch: 62, loss: 0.537369
global_step: 2453, epoch: 62, loss: 0.537222
global_step: 2454, epoch: 62, loss: 0.443898
global_step: 2455, epoch: 62, loss: 0.586894
global_step: 2456, epoch: 62, loss: 0.519624
global_step: 2457, epoch: 62, loss: 0.613269
global_step: 2458, epoch: 62, loss: 0.532391
global_step: 2459, epoch: 62, loss: 0.616012
global_step: 2460, epoch: 62, loss: 0.590268
global_step: 2461, epoch: 62, loss: 0.533822
global_step: 2462, epoch: 62, loss: 0.549111
global_step: 2463, epoch: 62, loss: 0.578771
global_step: 2464, epoch: 62, loss: 0.587443
global_step: 2465, epoch: 62, loss: 0.611893
global_step: 2466, epoch: 62, loss: 0.544362
global_step: 2467, epoch: 62, loss: 0.594385
global_step: 2468, epoch: 62, loss: 0.622933
global_step: 2469, epoch: 62, loss: 0.523790
global_step: 2470, epoch: 62, loss: 0.560419
global_step: 2471, epoch: 62, loss: 0.608620
global_step: 2472, epoch: 62, loss: 0.612751
global_step: 2473, epoch: 62, loss: 0.544521
global_step: 2474, epoch: 62, loss: 0.531172
global_step: 2475, epoch: 62, loss: 0.515639
global_step: 2476, epoch: 62, loss: 0.553648
global_step: 2477, epoch: 62, loss: 0.557479
global_step: 2478, epoch: 62, loss: 0.540484
global_step: 2479, epoch: 62, loss: 0.647535
global_step: 2480, epoch: 62, loss: 0.312031
epoch: 62
train	acc: 0.9084	macro: p 0.9278, r 0.7784, f1: 0.8255	micro: p 0.9084, r 0.9084, f1 0.9084	weighted_f1:0.9039
dev	acc: 0.5464	macro: p 0.4079, r 0.3085, f1: 0.3074	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4956
test	acc: 0.6057	macro: p 0.4422, r 0.3246, f1: 0.3280	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5590
global_step: 2481, epoch: 63, loss: 0.543024
global_step: 2482, epoch: 63, loss: 0.504492
global_step: 2483, epoch: 63, loss: 0.651414
global_step: 2484, epoch: 63, loss: 0.568178
global_step: 2485, epoch: 63, loss: 0.573200
global_step: 2486, epoch: 63, loss: 0.484851
global_step: 2487, epoch: 63, loss: 0.542583
global_step: 2488, epoch: 63, loss: 0.506035
global_step: 2489, epoch: 63, loss: 0.556866
global_step: 2490, epoch: 63, loss: 0.476627
global_step: 2491, epoch: 63, loss: 0.557684
global_step: 2492, epoch: 63, loss: 0.471086
global_step: 2493, epoch: 63, loss: 0.527067
global_step: 2494, epoch: 63, loss: 0.606608
global_step: 2495, epoch: 63, loss: 0.603431
global_step: 2496, epoch: 63, loss: 0.576273
global_step: 2497, epoch: 63, loss: 0.562987
global_step: 2498, epoch: 63, loss: 0.515549
global_step: 2499, epoch: 63, loss: 0.467025
global_step: 2500, epoch: 63, loss: 0.494493
global_step: 2501, epoch: 63, loss: 0.531140
global_step: 2502, epoch: 63, loss: 0.494998
global_step: 2503, epoch: 63, loss: 0.625614
global_step: 2504, epoch: 63, loss: 0.532182
global_step: 2505, epoch: 63, loss: 0.483275
global_step: 2506, epoch: 63, loss: 0.505023
global_step: 2507, epoch: 63, loss: 0.568933
global_step: 2508, epoch: 63, loss: 0.535286
global_step: 2509, epoch: 63, loss: 0.611715
global_step: 2510, epoch: 63, loss: 0.609939
global_step: 2511, epoch: 63, loss: 0.576732
global_step: 2512, epoch: 63, loss: 0.601962
global_step: 2513, epoch: 63, loss: 0.657362
global_step: 2514, epoch: 63, loss: 0.567137
global_step: 2515, epoch: 63, loss: 0.550884
global_step: 2516, epoch: 63, loss: 0.502116
global_step: 2517, epoch: 63, loss: 0.585614
global_step: 2518, epoch: 63, loss: 0.562887
global_step: 2519, epoch: 63, loss: 0.519637
global_step: 2520, epoch: 63, loss: 0.469160
epoch: 63
train	acc: 0.9162	macro: p 0.9305, r 0.7965, f1: 0.8415	micro: p 0.9162, r 0.9162, f1 0.9162	weighted_f1:0.9126
dev	acc: 0.5401	macro: p 0.3967, r 0.3059, f1: 0.3041	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4911
test	acc: 0.6015	macro: p 0.3576, r 0.3219, f1: 0.3237	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5574
global_step: 2521, epoch: 64, loss: 0.556906
global_step: 2522, epoch: 64, loss: 0.461086
global_step: 2523, epoch: 64, loss: 0.562315
global_step: 2524, epoch: 64, loss: 0.554078
global_step: 2525, epoch: 64, loss: 0.590854
global_step: 2526, epoch: 64, loss: 0.534700
global_step: 2527, epoch: 64, loss: 0.555225
global_step: 2528, epoch: 64, loss: 0.538186
global_step: 2529, epoch: 64, loss: 0.509233
global_step: 2530, epoch: 64, loss: 0.584875
global_step: 2531, epoch: 64, loss: 0.504434
global_step: 2532, epoch: 64, loss: 0.595182
global_step: 2533, epoch: 64, loss: 0.523055
global_step: 2534, epoch: 64, loss: 0.454368
global_step: 2535, epoch: 64, loss: 0.545300
global_step: 2536, epoch: 64, loss: 0.525876
global_step: 2537, epoch: 64, loss: 0.589262
global_step: 2538, epoch: 64, loss: 0.523269
global_step: 2539, epoch: 64, loss: 0.538502
global_step: 2540, epoch: 64, loss: 0.444616
global_step: 2541, epoch: 64, loss: 0.525210
global_step: 2542, epoch: 64, loss: 0.627488
global_step: 2543, epoch: 64, loss: 0.530744
global_step: 2544, epoch: 64, loss: 0.537810
global_step: 2545, epoch: 64, loss: 0.555393
global_step: 2546, epoch: 64, loss: 0.488487
global_step: 2547, epoch: 64, loss: 0.489910
global_step: 2548, epoch: 64, loss: 0.562077
global_step: 2549, epoch: 64, loss: 0.485128
global_step: 2550, epoch: 64, loss: 0.621475
global_step: 2551, epoch: 64, loss: 0.566132
global_step: 2552, epoch: 64, loss: 0.548392
global_step: 2553, epoch: 64, loss: 0.555014
global_step: 2554, epoch: 64, loss: 0.567241
global_step: 2555, epoch: 64, loss: 0.579963
global_step: 2556, epoch: 64, loss: 0.548225
global_step: 2557, epoch: 64, loss: 0.532535
global_step: 2558, epoch: 64, loss: 0.610866
global_step: 2559, epoch: 64, loss: 0.522506
global_step: 2560, epoch: 64, loss: 0.250597
epoch: 64
train	acc: 0.9168	macro: p 0.9266, r 0.8101, f1: 0.8513	micro: p 0.9168, r 0.9168, f1 0.9168	weighted_f1:0.9140
dev	acc: 0.5428	macro: p 0.3996, r 0.3094, f1: 0.3087	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4952
test	acc: 0.5973	macro: p 0.3806, r 0.3206, f1: 0.3229	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5531
global_step: 2561, epoch: 65, loss: 0.459258
global_step: 2562, epoch: 65, loss: 0.525125
global_step: 2563, epoch: 65, loss: 0.497591
global_step: 2564, epoch: 65, loss: 0.488621
global_step: 2565, epoch: 65, loss: 0.572053
global_step: 2566, epoch: 65, loss: 0.487170
global_step: 2567, epoch: 65, loss: 0.593407
global_step: 2568, epoch: 65, loss: 0.555382
global_step: 2569, epoch: 65, loss: 0.508173
global_step: 2570, epoch: 65, loss: 0.525234
global_step: 2571, epoch: 65, loss: 0.477389
global_step: 2572, epoch: 65, loss: 0.519659
global_step: 2573, epoch: 65, loss: 0.422657
global_step: 2574, epoch: 65, loss: 0.527522
global_step: 2575, epoch: 65, loss: 0.545836
global_step: 2576, epoch: 65, loss: 0.523290
global_step: 2577, epoch: 65, loss: 0.597583
global_step: 2578, epoch: 65, loss: 0.476471
global_step: 2579, epoch: 65, loss: 0.532965
global_step: 2580, epoch: 65, loss: 0.574255
global_step: 2581, epoch: 65, loss: 0.582386
global_step: 2582, epoch: 65, loss: 0.518828
global_step: 2583, epoch: 65, loss: 0.447979
global_step: 2584, epoch: 65, loss: 0.591754
global_step: 2585, epoch: 65, loss: 0.614787
global_step: 2586, epoch: 65, loss: 0.462556
global_step: 2587, epoch: 65, loss: 0.516349
global_step: 2588, epoch: 65, loss: 0.526806
global_step: 2589, epoch: 65, loss: 0.434197
global_step: 2590, epoch: 65, loss: 0.498975
global_step: 2591, epoch: 65, loss: 0.538181
global_step: 2592, epoch: 65, loss: 0.624431
global_step: 2593, epoch: 65, loss: 0.434524
global_step: 2594, epoch: 65, loss: 0.574574
global_step: 2595, epoch: 65, loss: 0.580321
global_step: 2596, epoch: 65, loss: 0.579183
global_step: 2597, epoch: 65, loss: 0.528185
global_step: 2598, epoch: 65, loss: 0.472433
global_step: 2599, epoch: 65, loss: 0.452530
global_step: 2600, epoch: 65, loss: 0.984716
epoch: 65
train	acc: 0.9236	macro: p 0.9352, r 0.8380, f1: 0.8772	micro: p 0.9236, r 0.9236, f1 0.9236	weighted_f1:0.9219
dev	acc: 0.5419	macro: p 0.3489, r 0.3036, f1: 0.3038	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4906
test	acc: 0.5966	macro: p 0.3977, r 0.3168, f1: 0.3253	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5514
global_step: 2601, epoch: 66, loss: 0.571668
global_step: 2602, epoch: 66, loss: 0.591160
global_step: 2603, epoch: 66, loss: 0.528908
global_step: 2604, epoch: 66, loss: 0.479823
global_step: 2605, epoch: 66, loss: 0.503112
global_step: 2606, epoch: 66, loss: 0.606273
global_step: 2607, epoch: 66, loss: 0.510940
global_step: 2608, epoch: 66, loss: 0.446282
global_step: 2609, epoch: 66, loss: 0.505114
global_step: 2610, epoch: 66, loss: 0.548297
global_step: 2611, epoch: 66, loss: 0.481710
global_step: 2612, epoch: 66, loss: 0.502369
global_step: 2613, epoch: 66, loss: 0.545438
global_step: 2614, epoch: 66, loss: 0.497811
global_step: 2615, epoch: 66, loss: 0.547338
global_step: 2616, epoch: 66, loss: 0.529557
global_step: 2617, epoch: 66, loss: 0.485511
global_step: 2618, epoch: 66, loss: 0.463253
global_step: 2619, epoch: 66, loss: 0.482879
global_step: 2620, epoch: 66, loss: 0.528284
global_step: 2621, epoch: 66, loss: 0.609396
global_step: 2622, epoch: 66, loss: 0.561102
global_step: 2623, epoch: 66, loss: 0.490223
global_step: 2624, epoch: 66, loss: 0.479399
global_step: 2625, epoch: 66, loss: 0.547587
global_step: 2626, epoch: 66, loss: 0.464264
global_step: 2627, epoch: 66, loss: 0.450577
global_step: 2628, epoch: 66, loss: 0.494045
global_step: 2629, epoch: 66, loss: 0.480915
global_step: 2630, epoch: 66, loss: 0.506558
global_step: 2631, epoch: 66, loss: 0.581862
global_step: 2632, epoch: 66, loss: 0.514918
global_step: 2633, epoch: 66, loss: 0.497235
global_step: 2634, epoch: 66, loss: 0.565730
global_step: 2635, epoch: 66, loss: 0.536807
global_step: 2636, epoch: 66, loss: 0.556661
global_step: 2637, epoch: 66, loss: 0.532464
global_step: 2638, epoch: 66, loss: 0.528388
global_step: 2639, epoch: 66, loss: 0.544369
global_step: 2640, epoch: 66, loss: 1.325254
epoch: 66
train	acc: 0.9267	macro: p 0.9391, r 0.8370, f1: 0.8759	micro: p 0.9267, r 0.9267, f1 0.9267	weighted_f1:0.9248
dev	acc: 0.5410	macro: p 0.3734, r 0.3088, f1: 0.3088	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4948
test	acc: 0.5958	macro: p 0.4111, r 0.3255, f1: 0.3344	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5560
global_step: 2641, epoch: 67, loss: 0.557274
global_step: 2642, epoch: 67, loss: 0.418524
global_step: 2643, epoch: 67, loss: 0.544924
global_step: 2644, epoch: 67, loss: 0.499354
global_step: 2645, epoch: 67, loss: 0.540629
global_step: 2646, epoch: 67, loss: 0.540392
global_step: 2647, epoch: 67, loss: 0.475077
global_step: 2648, epoch: 67, loss: 0.544632
global_step: 2649, epoch: 67, loss: 0.394867
global_step: 2650, epoch: 67, loss: 0.447658
global_step: 2651, epoch: 67, loss: 0.484112
global_step: 2652, epoch: 67, loss: 0.516278
global_step: 2653, epoch: 67, loss: 0.594918
global_step: 2654, epoch: 67, loss: 0.503787
global_step: 2655, epoch: 67, loss: 0.534496
global_step: 2656, epoch: 67, loss: 0.426422
global_step: 2657, epoch: 67, loss: 0.509274
global_step: 2658, epoch: 67, loss: 0.580415
global_step: 2659, epoch: 67, loss: 0.577339
global_step: 2660, epoch: 67, loss: 0.547491
global_step: 2661, epoch: 67, loss: 0.541763
global_step: 2662, epoch: 67, loss: 0.460526
global_step: 2663, epoch: 67, loss: 0.547496
global_step: 2664, epoch: 67, loss: 0.532030
global_step: 2665, epoch: 67, loss: 0.473469
global_step: 2666, epoch: 67, loss: 0.525664
global_step: 2667, epoch: 67, loss: 0.557908
global_step: 2668, epoch: 67, loss: 0.440516
global_step: 2669, epoch: 67, loss: 0.563653
global_step: 2670, epoch: 67, loss: 0.601858
global_step: 2671, epoch: 67, loss: 0.631436
global_step: 2672, epoch: 67, loss: 0.652991
global_step: 2673, epoch: 67, loss: 0.486132
global_step: 2674, epoch: 67, loss: 0.438879
global_step: 2675, epoch: 67, loss: 0.468398
global_step: 2676, epoch: 67, loss: 0.562800
global_step: 2677, epoch: 67, loss: 0.480987
global_step: 2678, epoch: 67, loss: 0.489961
global_step: 2679, epoch: 67, loss: 0.512201
global_step: 2680, epoch: 67, loss: 0.363258
epoch: 67
train	acc: 0.9318	macro: p 0.9377, r 0.8581, f1: 0.8898	micro: p 0.9318, r 0.9318, f1 0.9318	weighted_f1:0.9307
dev	acc: 0.5392	macro: p 0.3524, r 0.3114, f1: 0.3089	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4970
test	acc: 0.5904	macro: p 0.3730, r 0.3295, f1: 0.3338	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5554
global_step: 2681, epoch: 68, loss: 0.552550
global_step: 2682, epoch: 68, loss: 0.526242
global_step: 2683, epoch: 68, loss: 0.486950
global_step: 2684, epoch: 68, loss: 0.440163
global_step: 2685, epoch: 68, loss: 0.475881
global_step: 2686, epoch: 68, loss: 0.476377
global_step: 2687, epoch: 68, loss: 0.450417
global_step: 2688, epoch: 68, loss: 0.453252
global_step: 2689, epoch: 68, loss: 0.581868
global_step: 2690, epoch: 68, loss: 0.476468
global_step: 2691, epoch: 68, loss: 0.492472
global_step: 2692, epoch: 68, loss: 0.527428
global_step: 2693, epoch: 68, loss: 0.564095
global_step: 2694, epoch: 68, loss: 0.523655
global_step: 2695, epoch: 68, loss: 0.522181
global_step: 2696, epoch: 68, loss: 0.451143
global_step: 2697, epoch: 68, loss: 0.489575
global_step: 2698, epoch: 68, loss: 0.445294
global_step: 2699, epoch: 68, loss: 0.478600
global_step: 2700, epoch: 68, loss: 0.506019
global_step: 2701, epoch: 68, loss: 0.523584
global_step: 2702, epoch: 68, loss: 0.459652
global_step: 2703, epoch: 68, loss: 0.542991
global_step: 2704, epoch: 68, loss: 0.490267
global_step: 2705, epoch: 68, loss: 0.572328
global_step: 2706, epoch: 68, loss: 0.549713
global_step: 2707, epoch: 68, loss: 0.517977
global_step: 2708, epoch: 68, loss: 0.550128
global_step: 2709, epoch: 68, loss: 0.612407
global_step: 2710, epoch: 68, loss: 0.444129
global_step: 2711, epoch: 68, loss: 0.456616
global_step: 2712, epoch: 68, loss: 0.442836
global_step: 2713, epoch: 68, loss: 0.545603
global_step: 2714, epoch: 68, loss: 0.514079
global_step: 2715, epoch: 68, loss: 0.524493
global_step: 2716, epoch: 68, loss: 0.576217
global_step: 2717, epoch: 68, loss: 0.535835
global_step: 2718, epoch: 68, loss: 0.517509
global_step: 2719, epoch: 68, loss: 0.420322
global_step: 2720, epoch: 68, loss: 0.294153
epoch: 68
train	acc: 0.9258	macro: p 0.9401, r 0.8421, f1: 0.8810	micro: p 0.9258, r 0.9258, f1 0.9258	weighted_f1:0.9242
dev	acc: 0.5482	macro: p 0.3773, r 0.3106, f1: 0.3095	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4979
test	acc: 0.5946	macro: p 0.3943, r 0.3196, f1: 0.3233	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5493
global_step: 2721, epoch: 69, loss: 0.595124
global_step: 2722, epoch: 69, loss: 0.376926
global_step: 2723, epoch: 69, loss: 0.543934
global_step: 2724, epoch: 69, loss: 0.540032
global_step: 2725, epoch: 69, loss: 0.457516
global_step: 2726, epoch: 69, loss: 0.440527
global_step: 2727, epoch: 69, loss: 0.581793
global_step: 2728, epoch: 69, loss: 0.507027
global_step: 2729, epoch: 69, loss: 0.480927
global_step: 2730, epoch: 69, loss: 0.486672
global_step: 2731, epoch: 69, loss: 0.451838
global_step: 2732, epoch: 69, loss: 0.416937
global_step: 2733, epoch: 69, loss: 0.457612
global_step: 2734, epoch: 69, loss: 0.569470
global_step: 2735, epoch: 69, loss: 0.526317
global_step: 2736, epoch: 69, loss: 0.460856
global_step: 2737, epoch: 69, loss: 0.469892
global_step: 2738, epoch: 69, loss: 0.495368
global_step: 2739, epoch: 69, loss: 0.461579
global_step: 2740, epoch: 69, loss: 0.446971
global_step: 2741, epoch: 69, loss: 0.552216
global_step: 2742, epoch: 69, loss: 0.567795
global_step: 2743, epoch: 69, loss: 0.456510
global_step: 2744, epoch: 69, loss: 0.540228
global_step: 2745, epoch: 69, loss: 0.540596
global_step: 2746, epoch: 69, loss: 0.441741
global_step: 2747, epoch: 69, loss: 0.437565
global_step: 2748, epoch: 69, loss: 0.519874
global_step: 2749, epoch: 69, loss: 0.429596
global_step: 2750, epoch: 69, loss: 0.469059
global_step: 2751, epoch: 69, loss: 0.488618
global_step: 2752, epoch: 69, loss: 0.515814
global_step: 2753, epoch: 69, loss: 0.469616
global_step: 2754, epoch: 69, loss: 0.523269
global_step: 2755, epoch: 69, loss: 0.513050
global_step: 2756, epoch: 69, loss: 0.494296
global_step: 2757, epoch: 69, loss: 0.577524
global_step: 2758, epoch: 69, loss: 0.538901
global_step: 2759, epoch: 69, loss: 0.484559
global_step: 2760, epoch: 69, loss: 0.320889
epoch: 69
train	acc: 0.9270	macro: p 0.9416, r 0.8411, f1: 0.8793	micro: p 0.9270, r 0.9270, f1 0.9270	weighted_f1:0.9251
dev	acc: 0.5518	macro: p 0.4116, r 0.3157, f1: 0.3167	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5048
test	acc: 0.5981	macro: p 0.3945, r 0.3236, f1: 0.3325	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5572
global_step: 2761, epoch: 70, loss: 0.538598
global_step: 2762, epoch: 70, loss: 0.501964
global_step: 2763, epoch: 70, loss: 0.519007
global_step: 2764, epoch: 70, loss: 0.514392
global_step: 2765, epoch: 70, loss: 0.507635
global_step: 2766, epoch: 70, loss: 0.474647
global_step: 2767, epoch: 70, loss: 0.473480
global_step: 2768, epoch: 70, loss: 0.542950
global_step: 2769, epoch: 70, loss: 0.456931
global_step: 2770, epoch: 70, loss: 0.448713
global_step: 2771, epoch: 70, loss: 0.489378
global_step: 2772, epoch: 70, loss: 0.425683
global_step: 2773, epoch: 70, loss: 0.516340
global_step: 2774, epoch: 70, loss: 0.555326
global_step: 2775, epoch: 70, loss: 0.548508
global_step: 2776, epoch: 70, loss: 0.529130
global_step: 2777, epoch: 70, loss: 0.403258
global_step: 2778, epoch: 70, loss: 0.432284
global_step: 2779, epoch: 70, loss: 0.439217
global_step: 2780, epoch: 70, loss: 0.442732
global_step: 2781, epoch: 70, loss: 0.476334
global_step: 2782, epoch: 70, loss: 0.549565
global_step: 2783, epoch: 70, loss: 0.506274
global_step: 2784, epoch: 70, loss: 0.421647
global_step: 2785, epoch: 70, loss: 0.524081
global_step: 2786, epoch: 70, loss: 0.451935
global_step: 2787, epoch: 70, loss: 0.503545
global_step: 2788, epoch: 70, loss: 0.421962
global_step: 2789, epoch: 70, loss: 0.470943
global_step: 2790, epoch: 70, loss: 0.615332
global_step: 2791, epoch: 70, loss: 0.475017
global_step: 2792, epoch: 70, loss: 0.534057
global_step: 2793, epoch: 70, loss: 0.507965
global_step: 2794, epoch: 70, loss: 0.482988
global_step: 2795, epoch: 70, loss: 0.518749
global_step: 2796, epoch: 70, loss: 0.479276
global_step: 2797, epoch: 70, loss: 0.480184
global_step: 2798, epoch: 70, loss: 0.416870
global_step: 2799, epoch: 70, loss: 0.485610
global_step: 2800, epoch: 70, loss: 0.280779
epoch: 70
train	acc: 0.9287	macro: p 0.9459, r 0.8553, f1: 0.8931	micro: p 0.9287, r 0.9287, f1 0.9287	weighted_f1:0.9275
dev	acc: 0.5473	macro: p 0.3837, r 0.3078, f1: 0.3053	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4938
test	acc: 0.5920	macro: p 0.4015, r 0.3150, f1: 0.3195	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5446
global_step: 2801, epoch: 71, loss: 0.511566
global_step: 2802, epoch: 71, loss: 0.528518
global_step: 2803, epoch: 71, loss: 0.524426
global_step: 2804, epoch: 71, loss: 0.470391
global_step: 2805, epoch: 71, loss: 0.440597
global_step: 2806, epoch: 71, loss: 0.487264
global_step: 2807, epoch: 71, loss: 0.462832
global_step: 2808, epoch: 71, loss: 0.579209
global_step: 2809, epoch: 71, loss: 0.405391
global_step: 2810, epoch: 71, loss: 0.552641
global_step: 2811, epoch: 71, loss: 0.477824
global_step: 2812, epoch: 71, loss: 0.411425
global_step: 2813, epoch: 71, loss: 0.595239
global_step: 2814, epoch: 71, loss: 0.492567
global_step: 2815, epoch: 71, loss: 0.423530
global_step: 2816, epoch: 71, loss: 0.457024
global_step: 2817, epoch: 71, loss: 0.435582
global_step: 2818, epoch: 71, loss: 0.473915
global_step: 2819, epoch: 71, loss: 0.438639
global_step: 2820, epoch: 71, loss: 0.396205
global_step: 2821, epoch: 71, loss: 0.489112
global_step: 2822, epoch: 71, loss: 0.513948
global_step: 2823, epoch: 71, loss: 0.479718
global_step: 2824, epoch: 71, loss: 0.444749
global_step: 2825, epoch: 71, loss: 0.494526
global_step: 2826, epoch: 71, loss: 0.547610
global_step: 2827, epoch: 71, loss: 0.475981
global_step: 2828, epoch: 71, loss: 0.489124
global_step: 2829, epoch: 71, loss: 0.480633
global_step: 2830, epoch: 71, loss: 0.548161
global_step: 2831, epoch: 71, loss: 0.461257
global_step: 2832, epoch: 71, loss: 0.496966
global_step: 2833, epoch: 71, loss: 0.441289
global_step: 2834, epoch: 71, loss: 0.420273
global_step: 2835, epoch: 71, loss: 0.470698
global_step: 2836, epoch: 71, loss: 0.474673
global_step: 2837, epoch: 71, loss: 0.427391
global_step: 2838, epoch: 71, loss: 0.449235
global_step: 2839, epoch: 71, loss: 0.569997
global_step: 2840, epoch: 71, loss: 1.976543
epoch: 71
train	acc: 0.9372	macro: p 0.9482, r 0.8804, f1: 0.9099	micro: p 0.9372, r 0.9372, f1 0.9372	weighted_f1:0.9366
dev	acc: 0.5455	macro: p 0.3610, r 0.3111, f1: 0.3093	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4970
test	acc: 0.5908	macro: p 0.3731, r 0.3166, f1: 0.3202	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5463
global_step: 2841, epoch: 72, loss: 0.437539
global_step: 2842, epoch: 72, loss: 0.504306
global_step: 2843, epoch: 72, loss: 0.510991
global_step: 2844, epoch: 72, loss: 0.419330
global_step: 2845, epoch: 72, loss: 0.461382
global_step: 2846, epoch: 72, loss: 0.401959
global_step: 2847, epoch: 72, loss: 0.508738
global_step: 2848, epoch: 72, loss: 0.398885
global_step: 2849, epoch: 72, loss: 0.430859
global_step: 2850, epoch: 72, loss: 0.522667
global_step: 2851, epoch: 72, loss: 0.358914
global_step: 2852, epoch: 72, loss: 0.469147
global_step: 2853, epoch: 72, loss: 0.470370
global_step: 2854, epoch: 72, loss: 0.466763
global_step: 2855, epoch: 72, loss: 0.493454
global_step: 2856, epoch: 72, loss: 0.434009
global_step: 2857, epoch: 72, loss: 0.554216
global_step: 2858, epoch: 72, loss: 0.550035
global_step: 2859, epoch: 72, loss: 0.405849
global_step: 2860, epoch: 72, loss: 0.398556
global_step: 2861, epoch: 72, loss: 0.545315
global_step: 2862, epoch: 72, loss: 0.502555
global_step: 2863, epoch: 72, loss: 0.446562
global_step: 2864, epoch: 72, loss: 0.520725
global_step: 2865, epoch: 72, loss: 0.494898
global_step: 2866, epoch: 72, loss: 0.501323
global_step: 2867, epoch: 72, loss: 0.472579
global_step: 2868, epoch: 72, loss: 0.548734
global_step: 2869, epoch: 72, loss: 0.426444
global_step: 2870, epoch: 72, loss: 0.485111
global_step: 2871, epoch: 72, loss: 0.408243
global_step: 2872, epoch: 72, loss: 0.454881
global_step: 2873, epoch: 72, loss: 0.493755
global_step: 2874, epoch: 72, loss: 0.520046
global_step: 2875, epoch: 72, loss: 0.501967
global_step: 2876, epoch: 72, loss: 0.432721
global_step: 2877, epoch: 72, loss: 0.426155
global_step: 2878, epoch: 72, loss: 0.495061
global_step: 2879, epoch: 72, loss: 0.383832
global_step: 2880, epoch: 72, loss: 0.687187
epoch: 72
train	acc: 0.9380	macro: p 0.9480, r 0.8747, f1: 0.9055	micro: p 0.9380, r 0.9380, f1 0.9380	weighted_f1:0.9372
dev	acc: 0.5455	macro: p 0.4078, r 0.3134, f1: 0.3130	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5001
test	acc: 0.5935	macro: p 0.3749, r 0.3264, f1: 0.3287	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5534
global_step: 2881, epoch: 73, loss: 0.419736
global_step: 2882, epoch: 73, loss: 0.492840
global_step: 2883, epoch: 73, loss: 0.494934
global_step: 2884, epoch: 73, loss: 0.486070
global_step: 2885, epoch: 73, loss: 0.421373
global_step: 2886, epoch: 73, loss: 0.463097
global_step: 2887, epoch: 73, loss: 0.405664
global_step: 2888, epoch: 73, loss: 0.464383
global_step: 2889, epoch: 73, loss: 0.448965
global_step: 2890, epoch: 73, loss: 0.418134
global_step: 2891, epoch: 73, loss: 0.493680
global_step: 2892, epoch: 73, loss: 0.504138
global_step: 2893, epoch: 73, loss: 0.398841
global_step: 2894, epoch: 73, loss: 0.456431
global_step: 2895, epoch: 73, loss: 0.558450
global_step: 2896, epoch: 73, loss: 0.470569
global_step: 2897, epoch: 73, loss: 0.514548
global_step: 2898, epoch: 73, loss: 0.501732
global_step: 2899, epoch: 73, loss: 0.485846
global_step: 2900, epoch: 73, loss: 0.437580
global_step: 2901, epoch: 73, loss: 0.441074
global_step: 2902, epoch: 73, loss: 0.412125
global_step: 2903, epoch: 73, loss: 0.490324
global_step: 2904, epoch: 73, loss: 0.481576
global_step: 2905, epoch: 73, loss: 0.425726
global_step: 2906, epoch: 73, loss: 0.529298
global_step: 2907, epoch: 73, loss: 0.448247
global_step: 2908, epoch: 73, loss: 0.474144
global_step: 2909, epoch: 73, loss: 0.490501
global_step: 2910, epoch: 73, loss: 0.429286
global_step: 2911, epoch: 73, loss: 0.436102
global_step: 2912, epoch: 73, loss: 0.517723
global_step: 2913, epoch: 73, loss: 0.443320
global_step: 2914, epoch: 73, loss: 0.424250
global_step: 2915, epoch: 73, loss: 0.443542
global_step: 2916, epoch: 73, loss: 0.387667
global_step: 2917, epoch: 73, loss: 0.470186
global_step: 2918, epoch: 73, loss: 0.410426
global_step: 2919, epoch: 73, loss: 0.507635
global_step: 2920, epoch: 73, loss: 0.695500
epoch: 73
train	acc: 0.9380	macro: p 0.9480, r 0.8691, f1: 0.9018	micro: p 0.9380, r 0.9380, f1 0.9380	weighted_f1:0.9370
dev	acc: 0.5437	macro: p 0.4052, r 0.3118, f1: 0.3133	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4999
test	acc: 0.5950	macro: p 0.3855, r 0.3284, f1: 0.3346	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5579
global_step: 2921, epoch: 74, loss: 0.510115
global_step: 2922, epoch: 74, loss: 0.294673
global_step: 2923, epoch: 74, loss: 0.521885
global_step: 2924, epoch: 74, loss: 0.456732
global_step: 2925, epoch: 74, loss: 0.406802
global_step: 2926, epoch: 74, loss: 0.485456
global_step: 2927, epoch: 74, loss: 0.415153
global_step: 2928, epoch: 74, loss: 0.452531
global_step: 2929, epoch: 74, loss: 0.404829
global_step: 2930, epoch: 74, loss: 0.409970
global_step: 2931, epoch: 74, loss: 0.411089
global_step: 2932, epoch: 74, loss: 0.468606
global_step: 2933, epoch: 74, loss: 0.442499
global_step: 2934, epoch: 74, loss: 0.481216
global_step: 2935, epoch: 74, loss: 0.441043
global_step: 2936, epoch: 74, loss: 0.354955
global_step: 2937, epoch: 74, loss: 0.451079
global_step: 2938, epoch: 74, loss: 0.599908
global_step: 2939, epoch: 74, loss: 0.457597
global_step: 2940, epoch: 74, loss: 0.431502
global_step: 2941, epoch: 74, loss: 0.501039
global_step: 2942, epoch: 74, loss: 0.532525
global_step: 2943, epoch: 74, loss: 0.393183
global_step: 2944, epoch: 74, loss: 0.431531
global_step: 2945, epoch: 74, loss: 0.453698
global_step: 2946, epoch: 74, loss: 0.453909
global_step: 2947, epoch: 74, loss: 0.454033
global_step: 2948, epoch: 74, loss: 0.417797
global_step: 2949, epoch: 74, loss: 0.388285
global_step: 2950, epoch: 74, loss: 0.487357
global_step: 2951, epoch: 74, loss: 0.349623
global_step: 2952, epoch: 74, loss: 0.485028
global_step: 2953, epoch: 74, loss: 0.443595
global_step: 2954, epoch: 74, loss: 0.407682
global_step: 2955, epoch: 74, loss: 0.492379
global_step: 2956, epoch: 74, loss: 0.403727
global_step: 2957, epoch: 74, loss: 0.467411
global_step: 2958, epoch: 74, loss: 0.398707
global_step: 2959, epoch: 74, loss: 0.466893
global_step: 2960, epoch: 74, loss: 0.699678
epoch: 74
train	acc: 0.9416	macro: p 0.9508, r 0.8873, f1: 0.9151	micro: p 0.9416, r 0.9416, f1 0.9416	weighted_f1:0.9411
dev	acc: 0.5473	macro: p 0.4428, r 0.3219, f1: 0.3263	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5045
test	acc: 0.5920	macro: p 0.3801, r 0.3275, f1: 0.3317	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5550
global_step: 2961, epoch: 75, loss: 0.509297
global_step: 2962, epoch: 75, loss: 0.402569
global_step: 2963, epoch: 75, loss: 0.487577
global_step: 2964, epoch: 75, loss: 0.420632
global_step: 2965, epoch: 75, loss: 0.440177
global_step: 2966, epoch: 75, loss: 0.382769
global_step: 2967, epoch: 75, loss: 0.391324
global_step: 2968, epoch: 75, loss: 0.363011
global_step: 2969, epoch: 75, loss: 0.436025
global_step: 2970, epoch: 75, loss: 0.426424
global_step: 2971, epoch: 75, loss: 0.422073
global_step: 2972, epoch: 75, loss: 0.435654
global_step: 2973, epoch: 75, loss: 0.418714
global_step: 2974, epoch: 75, loss: 0.401881
global_step: 2975, epoch: 75, loss: 0.374078
global_step: 2976, epoch: 75, loss: 0.466570
global_step: 2977, epoch: 75, loss: 0.404628
global_step: 2978, epoch: 75, loss: 0.417928
global_step: 2979, epoch: 75, loss: 0.455310
global_step: 2980, epoch: 75, loss: 0.514329
global_step: 2981, epoch: 75, loss: 0.469799
global_step: 2982, epoch: 75, loss: 0.572034
global_step: 2983, epoch: 75, loss: 0.430750
global_step: 2984, epoch: 75, loss: 0.393574
global_step: 2985, epoch: 75, loss: 0.420580
global_step: 2986, epoch: 75, loss: 0.500149
global_step: 2987, epoch: 75, loss: 0.411226
global_step: 2988, epoch: 75, loss: 0.495533
global_step: 2989, epoch: 75, loss: 0.527132
global_step: 2990, epoch: 75, loss: 0.485613
global_step: 2991, epoch: 75, loss: 0.404995
global_step: 2992, epoch: 75, loss: 0.471067
global_step: 2993, epoch: 75, loss: 0.490365
global_step: 2994, epoch: 75, loss: 0.461429
global_step: 2995, epoch: 75, loss: 0.439935
global_step: 2996, epoch: 75, loss: 0.440845
global_step: 2997, epoch: 75, loss: 0.481944
global_step: 2998, epoch: 75, loss: 0.361372
global_step: 2999, epoch: 75, loss: 0.460248
global_step: 3000, epoch: 75, loss: 0.538414
epoch: 75
train	acc: 0.9403	macro: p 0.9458, r 0.8761, f1: 0.9048	micro: p 0.9403, r 0.9403, f1 0.9403	weighted_f1:0.9395
dev	acc: 0.5464	macro: p 0.4207, r 0.3189, f1: 0.3216	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5044
test	acc: 0.5900	macro: p 0.3835, r 0.3284, f1: 0.3354	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5552
global_step: 3001, epoch: 76, loss: 0.395618
global_step: 3002, epoch: 76, loss: 0.435246
global_step: 3003, epoch: 76, loss: 0.457161
global_step: 3004, epoch: 76, loss: 0.472503
global_step: 3005, epoch: 76, loss: 0.337066
global_step: 3006, epoch: 76, loss: 0.424335
global_step: 3007, epoch: 76, loss: 0.320280
global_step: 3008, epoch: 76, loss: 0.406043
global_step: 3009, epoch: 76, loss: 0.442112
global_step: 3010, epoch: 76, loss: 0.499057
global_step: 3011, epoch: 76, loss: 0.447273
global_step: 3012, epoch: 76, loss: 0.420991
global_step: 3013, epoch: 76, loss: 0.346728
global_step: 3014, epoch: 76, loss: 0.497867
global_step: 3015, epoch: 76, loss: 0.564742
global_step: 3016, epoch: 76, loss: 0.440066
global_step: 3017, epoch: 76, loss: 0.406300
global_step: 3018, epoch: 76, loss: 0.485154
global_step: 3019, epoch: 76, loss: 0.319223
global_step: 3020, epoch: 76, loss: 0.408048
global_step: 3021, epoch: 76, loss: 0.532358
global_step: 3022, epoch: 76, loss: 0.459182
global_step: 3023, epoch: 76, loss: 0.530311
global_step: 3024, epoch: 76, loss: 0.419270
global_step: 3025, epoch: 76, loss: 0.447722
global_step: 3026, epoch: 76, loss: 0.410100
global_step: 3027, epoch: 76, loss: 0.449684
global_step: 3028, epoch: 76, loss: 0.469228
global_step: 3029, epoch: 76, loss: 0.437592
global_step: 3030, epoch: 76, loss: 0.447807
global_step: 3031, epoch: 76, loss: 0.470506
global_step: 3032, epoch: 76, loss: 0.409941
global_step: 3033, epoch: 76, loss: 0.465122
global_step: 3034, epoch: 76, loss: 0.528805
global_step: 3035, epoch: 76, loss: 0.603467
global_step: 3036, epoch: 76, loss: 0.476273
global_step: 3037, epoch: 76, loss: 0.376141
global_step: 3038, epoch: 76, loss: 0.466289
global_step: 3039, epoch: 76, loss: 0.405397
global_step: 3040, epoch: 76, loss: 0.615811
epoch: 76
train	acc: 0.9440	macro: p 0.9513, r 0.8885, f1: 0.9157	micro: p 0.9440, r 0.9440, f1 0.9440	weighted_f1:0.9435
dev	acc: 0.5383	macro: p 0.3736, r 0.3142, f1: 0.3173	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4987
test	acc: 0.5874	macro: p 0.3694, r 0.3253, f1: 0.3304	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5536
global_step: 3041, epoch: 77, loss: 0.390214
global_step: 3042, epoch: 77, loss: 0.409699
global_step: 3043, epoch: 77, loss: 0.440051
global_step: 3044, epoch: 77, loss: 0.473626
global_step: 3045, epoch: 77, loss: 0.420819
global_step: 3046, epoch: 77, loss: 0.502729
global_step: 3047, epoch: 77, loss: 0.504063
global_step: 3048, epoch: 77, loss: 0.460629
global_step: 3049, epoch: 77, loss: 0.378457
global_step: 3050, epoch: 77, loss: 0.427064
global_step: 3051, epoch: 77, loss: 0.339274
global_step: 3052, epoch: 77, loss: 0.503501
global_step: 3053, epoch: 77, loss: 0.388436
global_step: 3054, epoch: 77, loss: 0.351982
global_step: 3055, epoch: 77, loss: 0.437140
global_step: 3056, epoch: 77, loss: 0.404176
global_step: 3057, epoch: 77, loss: 0.439194
global_step: 3058, epoch: 77, loss: 0.422815
global_step: 3059, epoch: 77, loss: 0.451983
global_step: 3060, epoch: 77, loss: 0.408828
global_step: 3061, epoch: 77, loss: 0.357111
global_step: 3062, epoch: 77, loss: 0.524520
global_step: 3063, epoch: 77, loss: 0.511495
global_step: 3064, epoch: 77, loss: 0.529885
global_step: 3065, epoch: 77, loss: 0.412183
global_step: 3066, epoch: 77, loss: 0.357441
global_step: 3067, epoch: 77, loss: 0.391212
global_step: 3068, epoch: 77, loss: 0.461229
global_step: 3069, epoch: 77, loss: 0.432516
global_step: 3070, epoch: 77, loss: 0.381265
global_step: 3071, epoch: 77, loss: 0.461520
global_step: 3072, epoch: 77, loss: 0.341063
global_step: 3073, epoch: 77, loss: 0.465792
global_step: 3074, epoch: 77, loss: 0.550149
global_step: 3075, epoch: 77, loss: 0.490483
global_step: 3076, epoch: 77, loss: 0.479394
global_step: 3077, epoch: 77, loss: 0.456223
global_step: 3078, epoch: 77, loss: 0.438901
global_step: 3079, epoch: 77, loss: 0.429444
global_step: 3080, epoch: 77, loss: 0.258807
epoch: 77
train	acc: 0.9354	macro: p 0.9519, r 0.8693, f1: 0.9046	micro: p 0.9354, r 0.9354, f1 0.9354	weighted_f1:0.9345
dev	acc: 0.5473	macro: p 0.3894, r 0.3044, f1: 0.3013	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4900
test	acc: 0.5958	macro: p 0.4428, r 0.3114, f1: 0.3153	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5448
global_step: 3081, epoch: 78, loss: 0.508703
global_step: 3082, epoch: 78, loss: 0.484946
global_step: 3083, epoch: 78, loss: 0.404409
global_step: 3084, epoch: 78, loss: 0.425783
global_step: 3085, epoch: 78, loss: 0.452603
global_step: 3086, epoch: 78, loss: 0.478304
global_step: 3087, epoch: 78, loss: 0.415363
global_step: 3088, epoch: 78, loss: 0.424500
global_step: 3089, epoch: 78, loss: 0.384770
global_step: 3090, epoch: 78, loss: 0.419169
global_step: 3091, epoch: 78, loss: 0.452767
global_step: 3092, epoch: 78, loss: 0.399594
global_step: 3093, epoch: 78, loss: 0.504105
global_step: 3094, epoch: 78, loss: 0.415824
global_step: 3095, epoch: 78, loss: 0.419081
global_step: 3096, epoch: 78, loss: 0.422936
global_step: 3097, epoch: 78, loss: 0.393967
global_step: 3098, epoch: 78, loss: 0.398168
global_step: 3099, epoch: 78, loss: 0.392726
global_step: 3100, epoch: 78, loss: 0.360147
global_step: 3101, epoch: 78, loss: 0.462968
global_step: 3102, epoch: 78, loss: 0.517022
global_step: 3103, epoch: 78, loss: 0.415615
global_step: 3104, epoch: 78, loss: 0.402966
global_step: 3105, epoch: 78, loss: 0.483928
global_step: 3106, epoch: 78, loss: 0.445138
global_step: 3107, epoch: 78, loss: 0.389780
global_step: 3108, epoch: 78, loss: 0.380273
global_step: 3109, epoch: 78, loss: 0.443851
global_step: 3110, epoch: 78, loss: 0.425251
global_step: 3111, epoch: 78, loss: 0.430891
global_step: 3112, epoch: 78, loss: 0.421874
global_step: 3113, epoch: 78, loss: 0.460621
global_step: 3114, epoch: 78, loss: 0.275890
global_step: 3115, epoch: 78, loss: 0.463863
global_step: 3116, epoch: 78, loss: 0.403773
global_step: 3117, epoch: 78, loss: 0.517059
global_step: 3118, epoch: 78, loss: 0.432954
global_step: 3119, epoch: 78, loss: 0.454051
global_step: 3120, epoch: 78, loss: 0.600879
epoch: 78
train	acc: 0.9439	macro: p 0.9520, r 0.8898, f1: 0.9167	micro: p 0.9439, r 0.9439, f1 0.9439	weighted_f1:0.9434
dev	acc: 0.5410	macro: p 0.4257, r 0.3134, f1: 0.3131	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4934
test	acc: 0.5862	macro: p 0.3759, r 0.3191, f1: 0.3199	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5448
global_step: 3121, epoch: 79, loss: 0.341979
global_step: 3122, epoch: 79, loss: 0.501374
global_step: 3123, epoch: 79, loss: 0.372681
global_step: 3124, epoch: 79, loss: 0.359954
global_step: 3125, epoch: 79, loss: 0.379701
global_step: 3126, epoch: 79, loss: 0.487867
global_step: 3127, epoch: 79, loss: 0.434574
global_step: 3128, epoch: 79, loss: 0.358662
global_step: 3129, epoch: 79, loss: 0.430139
global_step: 3130, epoch: 79, loss: 0.412381
global_step: 3131, epoch: 79, loss: 0.407178
global_step: 3132, epoch: 79, loss: 0.399281
global_step: 3133, epoch: 79, loss: 0.424374
global_step: 3134, epoch: 79, loss: 0.417980
global_step: 3135, epoch: 79, loss: 0.405615
global_step: 3136, epoch: 79, loss: 0.497535
global_step: 3137, epoch: 79, loss: 0.340793
global_step: 3138, epoch: 79, loss: 0.598501
global_step: 3139, epoch: 79, loss: 0.493371
global_step: 3140, epoch: 79, loss: 0.506429
global_step: 3141, epoch: 79, loss: 0.389075
global_step: 3142, epoch: 79, loss: 0.447828
global_step: 3143, epoch: 79, loss: 0.383981
global_step: 3144, epoch: 79, loss: 0.426961
global_step: 3145, epoch: 79, loss: 0.331174
global_step: 3146, epoch: 79, loss: 0.327265
global_step: 3147, epoch: 79, loss: 0.451725
global_step: 3148, epoch: 79, loss: 0.433651
global_step: 3149, epoch: 79, loss: 0.405818
global_step: 3150, epoch: 79, loss: 0.429229
global_step: 3151, epoch: 79, loss: 0.510852
global_step: 3152, epoch: 79, loss: 0.413238
global_step: 3153, epoch: 79, loss: 0.412226
global_step: 3154, epoch: 79, loss: 0.431760
global_step: 3155, epoch: 79, loss: 0.411457
global_step: 3156, epoch: 79, loss: 0.429450
global_step: 3157, epoch: 79, loss: 0.438335
global_step: 3158, epoch: 79, loss: 0.468728
global_step: 3159, epoch: 79, loss: 0.424153
global_step: 3160, epoch: 79, loss: 0.140136
epoch: 79
train	acc: 0.9440	macro: p 0.9542, r 0.8917, f1: 0.9193	micro: p 0.9440, r 0.9440, f1 0.9440	weighted_f1:0.9436
dev	acc: 0.5491	macro: p 0.4136, r 0.3156, f1: 0.3157	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4999
test	acc: 0.5912	macro: p 0.3967, r 0.3201, f1: 0.3248	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5497
global_step: 3161, epoch: 80, loss: 0.376958
global_step: 3162, epoch: 80, loss: 0.439426
global_step: 3163, epoch: 80, loss: 0.388678
global_step: 3164, epoch: 80, loss: 0.447409
global_step: 3165, epoch: 80, loss: 0.389686
global_step: 3166, epoch: 80, loss: 0.446241
global_step: 3167, epoch: 80, loss: 0.374031
global_step: 3168, epoch: 80, loss: 0.556501
global_step: 3169, epoch: 80, loss: 0.401679
global_step: 3170, epoch: 80, loss: 0.399398
global_step: 3171, epoch: 80, loss: 0.414006
global_step: 3172, epoch: 80, loss: 0.426757
global_step: 3173, epoch: 80, loss: 0.367462
global_step: 3174, epoch: 80, loss: 0.446235
global_step: 3175, epoch: 80, loss: 0.420812
global_step: 3176, epoch: 80, loss: 0.429211
global_step: 3177, epoch: 80, loss: 0.328528
global_step: 3178, epoch: 80, loss: 0.451394
global_step: 3179, epoch: 80, loss: 0.413037
global_step: 3180, epoch: 80, loss: 0.463336
global_step: 3181, epoch: 80, loss: 0.479151
global_step: 3182, epoch: 80, loss: 0.473847
global_step: 3183, epoch: 80, loss: 0.406666
global_step: 3184, epoch: 80, loss: 0.434325
global_step: 3185, epoch: 80, loss: 0.448694
global_step: 3186, epoch: 80, loss: 0.375876
global_step: 3187, epoch: 80, loss: 0.446396
global_step: 3188, epoch: 80, loss: 0.450484
global_step: 3189, epoch: 80, loss: 0.392288
global_step: 3190, epoch: 80, loss: 0.448577
global_step: 3191, epoch: 80, loss: 0.414899
global_step: 3192, epoch: 80, loss: 0.423388
global_step: 3193, epoch: 80, loss: 0.527226
global_step: 3194, epoch: 80, loss: 0.466530
global_step: 3195, epoch: 80, loss: 0.458895
global_step: 3196, epoch: 80, loss: 0.434611
global_step: 3197, epoch: 80, loss: 0.375854
global_step: 3198, epoch: 80, loss: 0.416388
global_step: 3199, epoch: 80, loss: 0.440290
global_step: 3200, epoch: 80, loss: 1.492928
epoch: 80
train	acc: 0.9482	macro: p 0.9531, r 0.9063, f1: 0.9270	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9480
dev	acc: 0.5329	macro: p 0.3728, r 0.3173, f1: 0.3182	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4984
test	acc: 0.5774	macro: p 0.3636, r 0.3360, f1: 0.3401	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5533
global_step: 3201, epoch: 81, loss: 0.435435
global_step: 3202, epoch: 81, loss: 0.393483
global_step: 3203, epoch: 81, loss: 0.415397
global_step: 3204, epoch: 81, loss: 0.381389
global_step: 3205, epoch: 81, loss: 0.436274
global_step: 3206, epoch: 81, loss: 0.423934
global_step: 3207, epoch: 81, loss: 0.412668
global_step: 3208, epoch: 81, loss: 0.324080
global_step: 3209, epoch: 81, loss: 0.396607
global_step: 3210, epoch: 81, loss: 0.405151
global_step: 3211, epoch: 81, loss: 0.458221
global_step: 3212, epoch: 81, loss: 0.398757
global_step: 3213, epoch: 81, loss: 0.429551
global_step: 3214, epoch: 81, loss: 0.498890
global_step: 3215, epoch: 81, loss: 0.453308
global_step: 3216, epoch: 81, loss: 0.339946
global_step: 3217, epoch: 81, loss: 0.406958
global_step: 3218, epoch: 81, loss: 0.357411
global_step: 3219, epoch: 81, loss: 0.409150
global_step: 3220, epoch: 81, loss: 0.521785
global_step: 3221, epoch: 81, loss: 0.426306
global_step: 3222, epoch: 81, loss: 0.455661
global_step: 3223, epoch: 81, loss: 0.360530
global_step: 3224, epoch: 81, loss: 0.407339
global_step: 3225, epoch: 81, loss: 0.369496
global_step: 3226, epoch: 81, loss: 0.560331
global_step: 3227, epoch: 81, loss: 0.369938
global_step: 3228, epoch: 81, loss: 0.383243
global_step: 3229, epoch: 81, loss: 0.320659
global_step: 3230, epoch: 81, loss: 0.341765
global_step: 3231, epoch: 81, loss: 0.380380
global_step: 3232, epoch: 81, loss: 0.414294
global_step: 3233, epoch: 81, loss: 0.353635
global_step: 3234, epoch: 81, loss: 0.436485
global_step: 3235, epoch: 81, loss: 0.503354
global_step: 3236, epoch: 81, loss: 0.410932
global_step: 3237, epoch: 81, loss: 0.493038
global_step: 3238, epoch: 81, loss: 0.458280
global_step: 3239, epoch: 81, loss: 0.419791
global_step: 3240, epoch: 81, loss: 0.624735
epoch: 81
train	acc: 0.9478	macro: p 0.9586, r 0.9023, f1: 0.9275	micro: p 0.9478, r 0.9478, f1 0.9478	weighted_f1:0.9475
dev	acc: 0.5473	macro: p 0.4019, r 0.3158, f1: 0.3181	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5013
test	acc: 0.5889	macro: p 0.3765, r 0.3207, f1: 0.3277	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5503
global_step: 3241, epoch: 82, loss: 0.443460
global_step: 3242, epoch: 82, loss: 0.430282
global_step: 3243, epoch: 82, loss: 0.459564
global_step: 3244, epoch: 82, loss: 0.497767
global_step: 3245, epoch: 82, loss: 0.394671
global_step: 3246, epoch: 82, loss: 0.391563
global_step: 3247, epoch: 82, loss: 0.392483
global_step: 3248, epoch: 82, loss: 0.398993
global_step: 3249, epoch: 82, loss: 0.320317
global_step: 3250, epoch: 82, loss: 0.376590
global_step: 3251, epoch: 82, loss: 0.412524
global_step: 3252, epoch: 82, loss: 0.372360
global_step: 3253, epoch: 82, loss: 0.396684
global_step: 3254, epoch: 82, loss: 0.394986
global_step: 3255, epoch: 82, loss: 0.405346
global_step: 3256, epoch: 82, loss: 0.385074
global_step: 3257, epoch: 82, loss: 0.430728
global_step: 3258, epoch: 82, loss: 0.370499
global_step: 3259, epoch: 82, loss: 0.354865
global_step: 3260, epoch: 82, loss: 0.371033
global_step: 3261, epoch: 82, loss: 0.460414
global_step: 3262, epoch: 82, loss: 0.426342
global_step: 3263, epoch: 82, loss: 0.331174
global_step: 3264, epoch: 82, loss: 0.440971
global_step: 3265, epoch: 82, loss: 0.455308
global_step: 3266, epoch: 82, loss: 0.447727
global_step: 3267, epoch: 82, loss: 0.384853
global_step: 3268, epoch: 82, loss: 0.516946
global_step: 3269, epoch: 82, loss: 0.410840
global_step: 3270, epoch: 82, loss: 0.387669
global_step: 3271, epoch: 82, loss: 0.449091
global_step: 3272, epoch: 82, loss: 0.414228
global_step: 3273, epoch: 82, loss: 0.435528
global_step: 3274, epoch: 82, loss: 0.439365
global_step: 3275, epoch: 82, loss: 0.411572
global_step: 3276, epoch: 82, loss: 0.409708
global_step: 3277, epoch: 82, loss: 0.451234
global_step: 3278, epoch: 82, loss: 0.501626
global_step: 3279, epoch: 82, loss: 0.369356
global_step: 3280, epoch: 82, loss: 0.029639
epoch: 82
train	acc: 0.9478	macro: p 0.9580, r 0.9014, f1: 0.9266	micro: p 0.9478, r 0.9478, f1 0.9478	weighted_f1:0.9475
dev	acc: 0.5446	macro: p 0.4020, r 0.3125, f1: 0.3150	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4972
test	acc: 0.5893	macro: p 0.3919, r 0.3229, f1: 0.3304	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5494
global_step: 3281, epoch: 83, loss: 0.329827
global_step: 3282, epoch: 83, loss: 0.283542
global_step: 3283, epoch: 83, loss: 0.309803
global_step: 3284, epoch: 83, loss: 0.371334
global_step: 3285, epoch: 83, loss: 0.401361
global_step: 3286, epoch: 83, loss: 0.497686
global_step: 3287, epoch: 83, loss: 0.420489
global_step: 3288, epoch: 83, loss: 0.365102
global_step: 3289, epoch: 83, loss: 0.406945
global_step: 3290, epoch: 83, loss: 0.395812
global_step: 3291, epoch: 83, loss: 0.382450
global_step: 3292, epoch: 83, loss: 0.429682
global_step: 3293, epoch: 83, loss: 0.422997
global_step: 3294, epoch: 83, loss: 0.532993
global_step: 3295, epoch: 83, loss: 0.350767
global_step: 3296, epoch: 83, loss: 0.410962
global_step: 3297, epoch: 83, loss: 0.477862
global_step: 3298, epoch: 83, loss: 0.414374
global_step: 3299, epoch: 83, loss: 0.378580
global_step: 3300, epoch: 83, loss: 0.447644
global_step: 3301, epoch: 83, loss: 0.353351
global_step: 3302, epoch: 83, loss: 0.369403
global_step: 3303, epoch: 83, loss: 0.400297
global_step: 3304, epoch: 83, loss: 0.364244
global_step: 3305, epoch: 83, loss: 0.384265
global_step: 3306, epoch: 83, loss: 0.368713
global_step: 3307, epoch: 83, loss: 0.476661
global_step: 3308, epoch: 83, loss: 0.499703
global_step: 3309, epoch: 83, loss: 0.404616
global_step: 3310, epoch: 83, loss: 0.435943
global_step: 3311, epoch: 83, loss: 0.429909
global_step: 3312, epoch: 83, loss: 0.451434
global_step: 3313, epoch: 83, loss: 0.430544
global_step: 3314, epoch: 83, loss: 0.437602
global_step: 3315, epoch: 83, loss: 0.513668
global_step: 3316, epoch: 83, loss: 0.423659
global_step: 3317, epoch: 83, loss: 0.327936
global_step: 3318, epoch: 83, loss: 0.404880
global_step: 3319, epoch: 83, loss: 0.424299
global_step: 3320, epoch: 83, loss: 0.059319
epoch: 83
train	acc: 0.9469	macro: p 0.9608, r 0.8980, f1: 0.9262	micro: p 0.9469, r 0.9469, f1 0.9469	weighted_f1:0.9465
dev	acc: 0.5455	macro: p 0.3888, r 0.3087, f1: 0.3104	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4937
test	acc: 0.5904	macro: p 0.4021, r 0.3150, f1: 0.3232	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5444
global_step: 3321, epoch: 84, loss: 0.351362
global_step: 3322, epoch: 84, loss: 0.377923
global_step: 3323, epoch: 84, loss: 0.337745
global_step: 3324, epoch: 84, loss: 0.386782
global_step: 3325, epoch: 84, loss: 0.359534
global_step: 3326, epoch: 84, loss: 0.382139
global_step: 3327, epoch: 84, loss: 0.412910
global_step: 3328, epoch: 84, loss: 0.345141
global_step: 3329, epoch: 84, loss: 0.376809
global_step: 3330, epoch: 84, loss: 0.429936
global_step: 3331, epoch: 84, loss: 0.311109
global_step: 3332, epoch: 84, loss: 0.363313
global_step: 3333, epoch: 84, loss: 0.412331
global_step: 3334, epoch: 84, loss: 0.384892
global_step: 3335, epoch: 84, loss: 0.406555
global_step: 3336, epoch: 84, loss: 0.397256
global_step: 3337, epoch: 84, loss: 0.381206
global_step: 3338, epoch: 84, loss: 0.384622
global_step: 3339, epoch: 84, loss: 0.455269
global_step: 3340, epoch: 84, loss: 0.357323
global_step: 3341, epoch: 84, loss: 0.376588
global_step: 3342, epoch: 84, loss: 0.429607
global_step: 3343, epoch: 84, loss: 0.281124
global_step: 3344, epoch: 84, loss: 0.453148
global_step: 3345, epoch: 84, loss: 0.377868
global_step: 3346, epoch: 84, loss: 0.344181
global_step: 3347, epoch: 84, loss: 0.413767
global_step: 3348, epoch: 84, loss: 0.384353
global_step: 3349, epoch: 84, loss: 0.459600
global_step: 3350, epoch: 84, loss: 0.521613
global_step: 3351, epoch: 84, loss: 0.503669
global_step: 3352, epoch: 84, loss: 0.433240
global_step: 3353, epoch: 84, loss: 0.397908
global_step: 3354, epoch: 84, loss: 0.430981
global_step: 3355, epoch: 84, loss: 0.393595
global_step: 3356, epoch: 84, loss: 0.393839
global_step: 3357, epoch: 84, loss: 0.431448
global_step: 3358, epoch: 84, loss: 0.384188
global_step: 3359, epoch: 84, loss: 0.352758
global_step: 3360, epoch: 84, loss: 0.501682
epoch: 84
train	acc: 0.9498	macro: p 0.9594, r 0.9042, f1: 0.9290	micro: p 0.9498, r 0.9498, f1 0.9498	weighted_f1:0.9494
dev	acc: 0.5428	macro: p 0.3757, r 0.3132, f1: 0.3143	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4971
test	acc: 0.5881	macro: p 0.3950, r 0.3209, f1: 0.3253	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5481
global_step: 3361, epoch: 85, loss: 0.349864
global_step: 3362, epoch: 85, loss: 0.464073
global_step: 3363, epoch: 85, loss: 0.370270
global_step: 3364, epoch: 85, loss: 0.395200
global_step: 3365, epoch: 85, loss: 0.382678
global_step: 3366, epoch: 85, loss: 0.422388
global_step: 3367, epoch: 85, loss: 0.406793
global_step: 3368, epoch: 85, loss: 0.389765
global_step: 3369, epoch: 85, loss: 0.484147
global_step: 3370, epoch: 85, loss: 0.345931
global_step: 3371, epoch: 85, loss: 0.425894
global_step: 3372, epoch: 85, loss: 0.328342
global_step: 3373, epoch: 85, loss: 0.419567
global_step: 3374, epoch: 85, loss: 0.353940
global_step: 3375, epoch: 85, loss: 0.327125
global_step: 3376, epoch: 85, loss: 0.373321
global_step: 3377, epoch: 85, loss: 0.360813
global_step: 3378, epoch: 85, loss: 0.383166
global_step: 3379, epoch: 85, loss: 0.359508
global_step: 3380, epoch: 85, loss: 0.377537
global_step: 3381, epoch: 85, loss: 0.428195
global_step: 3382, epoch: 85, loss: 0.423307
global_step: 3383, epoch: 85, loss: 0.405901
global_step: 3384, epoch: 85, loss: 0.502528
global_step: 3385, epoch: 85, loss: 0.421490
global_step: 3386, epoch: 85, loss: 0.380169
global_step: 3387, epoch: 85, loss: 0.416323
global_step: 3388, epoch: 85, loss: 0.384559
global_step: 3389, epoch: 85, loss: 0.351213
global_step: 3390, epoch: 85, loss: 0.434217
global_step: 3391, epoch: 85, loss: 0.381388
global_step: 3392, epoch: 85, loss: 0.421070
global_step: 3393, epoch: 85, loss: 0.351031
global_step: 3394, epoch: 85, loss: 0.400159
global_step: 3395, epoch: 85, loss: 0.427594
global_step: 3396, epoch: 85, loss: 0.418450
global_step: 3397, epoch: 85, loss: 0.413942
global_step: 3398, epoch: 85, loss: 0.469391
global_step: 3399, epoch: 85, loss: 0.493010
global_step: 3400, epoch: 85, loss: 0.208767
epoch: 85
train	acc: 0.9520	macro: p 0.9592, r 0.9161, f1: 0.9359	micro: p 0.9520, r 0.9520, f1 0.9520	weighted_f1:0.9518
dev	acc: 0.5446	macro: p 0.3733, r 0.3147, f1: 0.3203	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5019
test	acc: 0.5885	macro: p 0.4186, r 0.3283, f1: 0.3396	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5524
global_step: 3401, epoch: 86, loss: 0.439049
global_step: 3402, epoch: 86, loss: 0.415051
global_step: 3403, epoch: 86, loss: 0.365389
global_step: 3404, epoch: 86, loss: 0.427550
global_step: 3405, epoch: 86, loss: 0.393199
global_step: 3406, epoch: 86, loss: 0.404629
global_step: 3407, epoch: 86, loss: 0.447322
global_step: 3408, epoch: 86, loss: 0.511095
global_step: 3409, epoch: 86, loss: 0.382813
global_step: 3410, epoch: 86, loss: 0.473079
global_step: 3411, epoch: 86, loss: 0.381513
global_step: 3412, epoch: 86, loss: 0.331276
global_step: 3413, epoch: 86, loss: 0.317270
global_step: 3414, epoch: 86, loss: 0.382670
global_step: 3415, epoch: 86, loss: 0.417169
global_step: 3416, epoch: 86, loss: 0.419263
global_step: 3417, epoch: 86, loss: 0.334669
global_step: 3418, epoch: 86, loss: 0.400989
global_step: 3419, epoch: 86, loss: 0.390997
global_step: 3420, epoch: 86, loss: 0.427242
global_step: 3421, epoch: 86, loss: 0.364961
global_step: 3422, epoch: 86, loss: 0.331086
global_step: 3423, epoch: 86, loss: 0.377307
global_step: 3424, epoch: 86, loss: 0.392365
global_step: 3425, epoch: 86, loss: 0.429589
global_step: 3426, epoch: 86, loss: 0.475214
global_step: 3427, epoch: 86, loss: 0.339100
global_step: 3428, epoch: 86, loss: 0.352697
global_step: 3429, epoch: 86, loss: 0.542906
global_step: 3430, epoch: 86, loss: 0.390294
global_step: 3431, epoch: 86, loss: 0.294375
global_step: 3432, epoch: 86, loss: 0.402734
global_step: 3433, epoch: 86, loss: 0.468333
global_step: 3434, epoch: 86, loss: 0.353150
global_step: 3435, epoch: 86, loss: 0.465394
global_step: 3436, epoch: 86, loss: 0.470468
global_step: 3437, epoch: 86, loss: 0.407875
global_step: 3438, epoch: 86, loss: 0.371037
global_step: 3439, epoch: 86, loss: 0.463272
global_step: 3440, epoch: 86, loss: 0.944939
epoch: 86
train	acc: 0.9525	macro: p 0.9612, r 0.9168, f1: 0.9371	micro: p 0.9525, r 0.9525, f1 0.9525	weighted_f1:0.9524
dev	acc: 0.5419	macro: p 0.3838, r 0.3192, f1: 0.3236	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5003
test	acc: 0.5831	macro: p 0.4054, r 0.3281, f1: 0.3368	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5488
global_step: 3441, epoch: 87, loss: 0.329318
global_step: 3442, epoch: 87, loss: 0.364946
global_step: 3443, epoch: 87, loss: 0.496938
global_step: 3444, epoch: 87, loss: 0.463634
global_step: 3445, epoch: 87, loss: 0.374572
global_step: 3446, epoch: 87, loss: 0.311855
global_step: 3447, epoch: 87, loss: 0.310406
global_step: 3448, epoch: 87, loss: 0.361629
global_step: 3449, epoch: 87, loss: 0.350867
global_step: 3450, epoch: 87, loss: 0.301939
global_step: 3451, epoch: 87, loss: 0.402079
global_step: 3452, epoch: 87, loss: 0.374581
global_step: 3453, epoch: 87, loss: 0.388201
global_step: 3454, epoch: 87, loss: 0.373708
global_step: 3455, epoch: 87, loss: 0.385653
global_step: 3456, epoch: 87, loss: 0.403589
global_step: 3457, epoch: 87, loss: 0.329732
global_step: 3458, epoch: 87, loss: 0.308292
global_step: 3459, epoch: 87, loss: 0.351934
global_step: 3460, epoch: 87, loss: 0.429003
global_step: 3461, epoch: 87, loss: 0.357580
global_step: 3462, epoch: 87, loss: 0.361184
global_step: 3463, epoch: 87, loss: 0.406531
global_step: 3464, epoch: 87, loss: 0.423414
global_step: 3465, epoch: 87, loss: 0.383559
global_step: 3466, epoch: 87, loss: 0.479627
global_step: 3467, epoch: 87, loss: 0.446502
global_step: 3468, epoch: 87, loss: 0.455914
global_step: 3469, epoch: 87, loss: 0.366914
global_step: 3470, epoch: 87, loss: 0.277524
global_step: 3471, epoch: 87, loss: 0.389080
global_step: 3472, epoch: 87, loss: 0.421051
global_step: 3473, epoch: 87, loss: 0.437061
global_step: 3474, epoch: 87, loss: 0.454216
global_step: 3475, epoch: 87, loss: 0.532547
global_step: 3476, epoch: 87, loss: 0.346145
global_step: 3477, epoch: 87, loss: 0.450079
global_step: 3478, epoch: 87, loss: 0.398479
global_step: 3479, epoch: 87, loss: 0.401060
global_step: 3480, epoch: 87, loss: 0.041227
epoch: 87
train	acc: 0.9530	macro: p 0.9605, r 0.9151, f1: 0.9358	micro: p 0.9530, r 0.9530, f1 0.9530	weighted_f1:0.9528
dev	acc: 0.5464	macro: p 0.3930, r 0.3148, f1: 0.3197	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5007
test	acc: 0.5943	macro: p 0.4032, r 0.3239, f1: 0.3324	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5558
global_step: 3481, epoch: 88, loss: 0.345192
global_step: 3482, epoch: 88, loss: 0.381435
global_step: 3483, epoch: 88, loss: 0.337943
global_step: 3484, epoch: 88, loss: 0.410768
global_step: 3485, epoch: 88, loss: 0.342942
global_step: 3486, epoch: 88, loss: 0.409533
global_step: 3487, epoch: 88, loss: 0.369003
global_step: 3488, epoch: 88, loss: 0.340452
global_step: 3489, epoch: 88, loss: 0.354376
global_step: 3490, epoch: 88, loss: 0.362960
global_step: 3491, epoch: 88, loss: 0.406054
global_step: 3492, epoch: 88, loss: 0.331869
global_step: 3493, epoch: 88, loss: 0.446072
global_step: 3494, epoch: 88, loss: 0.348342
global_step: 3495, epoch: 88, loss: 0.497720
global_step: 3496, epoch: 88, loss: 0.445160
global_step: 3497, epoch: 88, loss: 0.414540
global_step: 3498, epoch: 88, loss: 0.381203
global_step: 3499, epoch: 88, loss: 0.328796
global_step: 3500, epoch: 88, loss: 0.423525
global_step: 3501, epoch: 88, loss: 0.330209
global_step: 3502, epoch: 88, loss: 0.380803
global_step: 3503, epoch: 88, loss: 0.447492
global_step: 3504, epoch: 88, loss: 0.354554
global_step: 3505, epoch: 88, loss: 0.467695
global_step: 3506, epoch: 88, loss: 0.437167
global_step: 3507, epoch: 88, loss: 0.353744
global_step: 3508, epoch: 88, loss: 0.397476
global_step: 3509, epoch: 88, loss: 0.391713
global_step: 3510, epoch: 88, loss: 0.351406
global_step: 3511, epoch: 88, loss: 0.330884
global_step: 3512, epoch: 88, loss: 0.396320
global_step: 3513, epoch: 88, loss: 0.405097
global_step: 3514, epoch: 88, loss: 0.409202
global_step: 3515, epoch: 88, loss: 0.467899
global_step: 3516, epoch: 88, loss: 0.410812
global_step: 3517, epoch: 88, loss: 0.357553
global_step: 3518, epoch: 88, loss: 0.371365
global_step: 3519, epoch: 88, loss: 0.408431
global_step: 3520, epoch: 88, loss: 0.395724
epoch: 88
train	acc: 0.9536	macro: p 0.9606, r 0.9141, f1: 0.9351	micro: p 0.9536, r 0.9536, f1 0.9536	weighted_f1:0.9534
dev	acc: 0.5482	macro: p 0.4189, r 0.3202, f1: 0.3256	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5024
test	acc: 0.5912	macro: p 0.3973, r 0.3245, f1: 0.3306	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5513
global_step: 3521, epoch: 89, loss: 0.286979
global_step: 3522, epoch: 89, loss: 0.398112
global_step: 3523, epoch: 89, loss: 0.345921
global_step: 3524, epoch: 89, loss: 0.332152
global_step: 3525, epoch: 89, loss: 0.486728
global_step: 3526, epoch: 89, loss: 0.351516
global_step: 3527, epoch: 89, loss: 0.360863
global_step: 3528, epoch: 89, loss: 0.364835
global_step: 3529, epoch: 89, loss: 0.405425
global_step: 3530, epoch: 89, loss: 0.381421
global_step: 3531, epoch: 89, loss: 0.313076
global_step: 3532, epoch: 89, loss: 0.404964
global_step: 3533, epoch: 89, loss: 0.361273
global_step: 3534, epoch: 89, loss: 0.355984
global_step: 3535, epoch: 89, loss: 0.344361
global_step: 3536, epoch: 89, loss: 0.375123
global_step: 3537, epoch: 89, loss: 0.370417
global_step: 3538, epoch: 89, loss: 0.337758
global_step: 3539, epoch: 89, loss: 0.328819
global_step: 3540, epoch: 89, loss: 0.356341
global_step: 3541, epoch: 89, loss: 0.464410
global_step: 3542, epoch: 89, loss: 0.394909
global_step: 3543, epoch: 89, loss: 0.391352
global_step: 3544, epoch: 89, loss: 0.371043
global_step: 3545, epoch: 89, loss: 0.319898
global_step: 3546, epoch: 89, loss: 0.321848
global_step: 3547, epoch: 89, loss: 0.454685
global_step: 3548, epoch: 89, loss: 0.393846
global_step: 3549, epoch: 89, loss: 0.366357
global_step: 3550, epoch: 89, loss: 0.401285
global_step: 3551, epoch: 89, loss: 0.404604
global_step: 3552, epoch: 89, loss: 0.299877
global_step: 3553, epoch: 89, loss: 0.340793
global_step: 3554, epoch: 89, loss: 0.438850
global_step: 3555, epoch: 89, loss: 0.590212
global_step: 3556, epoch: 89, loss: 0.486549
global_step: 3557, epoch: 89, loss: 0.342154
global_step: 3558, epoch: 89, loss: 0.416144
global_step: 3559, epoch: 89, loss: 0.329225
global_step: 3560, epoch: 89, loss: 0.374783
epoch: 89
train	acc: 0.9541	macro: p 0.9640, r 0.9165, f1: 0.9383	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9539
dev	acc: 0.5500	macro: p 0.3888, r 0.3170, f1: 0.3213	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5014
test	acc: 0.5908	macro: p 0.4132, r 0.3215, f1: 0.3322	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5494
global_step: 3561, epoch: 90, loss: 0.325900
global_step: 3562, epoch: 90, loss: 0.340962
global_step: 3563, epoch: 90, loss: 0.349797
global_step: 3564, epoch: 90, loss: 0.321899
global_step: 3565, epoch: 90, loss: 0.295934
global_step: 3566, epoch: 90, loss: 0.303134
global_step: 3567, epoch: 90, loss: 0.396344
global_step: 3568, epoch: 90, loss: 0.353117
global_step: 3569, epoch: 90, loss: 0.346901
global_step: 3570, epoch: 90, loss: 0.416199
global_step: 3571, epoch: 90, loss: 0.417376
global_step: 3572, epoch: 90, loss: 0.312386
global_step: 3573, epoch: 90, loss: 0.372786
global_step: 3574, epoch: 90, loss: 0.366508
global_step: 3575, epoch: 90, loss: 0.382700
global_step: 3576, epoch: 90, loss: 0.478798
global_step: 3577, epoch: 90, loss: 0.359139
global_step: 3578, epoch: 90, loss: 0.344849
global_step: 3579, epoch: 90, loss: 0.343688
global_step: 3580, epoch: 90, loss: 0.375154
global_step: 3581, epoch: 90, loss: 0.388221
global_step: 3582, epoch: 90, loss: 0.404443
global_step: 3583, epoch: 90, loss: 0.423513
global_step: 3584, epoch: 90, loss: 0.379944
global_step: 3585, epoch: 90, loss: 0.408400
global_step: 3586, epoch: 90, loss: 0.368898
global_step: 3587, epoch: 90, loss: 0.361486
global_step: 3588, epoch: 90, loss: 0.380606
global_step: 3589, epoch: 90, loss: 0.373426
global_step: 3590, epoch: 90, loss: 0.461219
global_step: 3591, epoch: 90, loss: 0.359195
global_step: 3592, epoch: 90, loss: 0.349575
global_step: 3593, epoch: 90, loss: 0.390091
global_step: 3594, epoch: 90, loss: 0.385948
global_step: 3595, epoch: 90, loss: 0.337676
global_step: 3596, epoch: 90, loss: 0.425807
global_step: 3597, epoch: 90, loss: 0.390541
global_step: 3598, epoch: 90, loss: 0.411960
global_step: 3599, epoch: 90, loss: 0.381233
global_step: 3600, epoch: 90, loss: 0.301293
epoch: 90
train	acc: 0.9567	macro: p 0.9613, r 0.9208, f1: 0.9393	micro: p 0.9567, r 0.9567, f1 0.9567	weighted_f1:0.9565
dev	acc: 0.5428	macro: p 0.3980, r 0.3181, f1: 0.3241	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5036
test	acc: 0.5824	macro: p 0.4186, r 0.3323, f1: 0.3436	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5526
global_step: 3601, epoch: 91, loss: 0.490528
global_step: 3602, epoch: 91, loss: 0.351276
global_step: 3603, epoch: 91, loss: 0.309195
global_step: 3604, epoch: 91, loss: 0.334370
global_step: 3605, epoch: 91, loss: 0.404701
global_step: 3606, epoch: 91, loss: 0.374023
global_step: 3607, epoch: 91, loss: 0.434694
global_step: 3608, epoch: 91, loss: 0.361437
global_step: 3609, epoch: 91, loss: 0.428252
global_step: 3610, epoch: 91, loss: 0.325636
global_step: 3611, epoch: 91, loss: 0.374211
global_step: 3612, epoch: 91, loss: 0.359996
global_step: 3613, epoch: 91, loss: 0.404837
global_step: 3614, epoch: 91, loss: 0.413948
global_step: 3615, epoch: 91, loss: 0.361354
global_step: 3616, epoch: 91, loss: 0.253964
global_step: 3617, epoch: 91, loss: 0.348915
global_step: 3618, epoch: 91, loss: 0.408122
global_step: 3619, epoch: 91, loss: 0.360323
global_step: 3620, epoch: 91, loss: 0.347441
global_step: 3621, epoch: 91, loss: 0.376398
global_step: 3622, epoch: 91, loss: 0.397191
global_step: 3623, epoch: 91, loss: 0.363866
global_step: 3624, epoch: 91, loss: 0.400013
global_step: 3625, epoch: 91, loss: 0.365472
global_step: 3626, epoch: 91, loss: 0.326476
global_step: 3627, epoch: 91, loss: 0.375990
global_step: 3628, epoch: 91, loss: 0.356117
global_step: 3629, epoch: 91, loss: 0.262234
global_step: 3630, epoch: 91, loss: 0.344516
global_step: 3631, epoch: 91, loss: 0.417701
global_step: 3632, epoch: 91, loss: 0.490806
global_step: 3633, epoch: 91, loss: 0.345929
global_step: 3634, epoch: 91, loss: 0.278855
global_step: 3635, epoch: 91, loss: 0.363775
global_step: 3636, epoch: 91, loss: 0.351544
global_step: 3637, epoch: 91, loss: 0.375470
global_step: 3638, epoch: 91, loss: 0.434250
global_step: 3639, epoch: 91, loss: 0.321646
global_step: 3640, epoch: 91, loss: 0.238803
epoch: 91
train	acc: 0.9522	macro: p 0.9624, r 0.9106, f1: 0.9341	micro: p 0.9522, r 0.9522, f1 0.9522	weighted_f1:0.9520
dev	acc: 0.5500	macro: p 0.4346, r 0.3160, f1: 0.3199	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5015
test	acc: 0.5877	macro: p 0.4036, r 0.3154, f1: 0.3200	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5431
global_step: 3641, epoch: 92, loss: 0.361499
global_step: 3642, epoch: 92, loss: 0.300833
global_step: 3643, epoch: 92, loss: 0.336800
global_step: 3644, epoch: 92, loss: 0.401559
global_step: 3645, epoch: 92, loss: 0.301692
global_step: 3646, epoch: 92, loss: 0.288479
global_step: 3647, epoch: 92, loss: 0.412171
global_step: 3648, epoch: 92, loss: 0.428875
global_step: 3649, epoch: 92, loss: 0.327629
global_step: 3650, epoch: 92, loss: 0.320322
global_step: 3651, epoch: 92, loss: 0.329843
global_step: 3652, epoch: 92, loss: 0.321879
global_step: 3653, epoch: 92, loss: 0.393473
global_step: 3654, epoch: 92, loss: 0.415758
global_step: 3655, epoch: 92, loss: 0.329197
global_step: 3656, epoch: 92, loss: 0.347252
global_step: 3657, epoch: 92, loss: 0.326041
global_step: 3658, epoch: 92, loss: 0.367879
global_step: 3659, epoch: 92, loss: 0.335537
global_step: 3660, epoch: 92, loss: 0.355947
global_step: 3661, epoch: 92, loss: 0.390945
global_step: 3662, epoch: 92, loss: 0.331691
global_step: 3663, epoch: 92, loss: 0.286610
global_step: 3664, epoch: 92, loss: 0.305986
global_step: 3665, epoch: 92, loss: 0.418202
global_step: 3666, epoch: 92, loss: 0.329952
global_step: 3667, epoch: 92, loss: 0.374466
global_step: 3668, epoch: 92, loss: 0.433370
global_step: 3669, epoch: 92, loss: 0.401332
global_step: 3670, epoch: 92, loss: 0.301585
global_step: 3671, epoch: 92, loss: 0.370408
global_step: 3672, epoch: 92, loss: 0.371455
global_step: 3673, epoch: 92, loss: 0.378238
global_step: 3674, epoch: 92, loss: 0.280283
global_step: 3675, epoch: 92, loss: 0.369657
global_step: 3676, epoch: 92, loss: 0.442589
global_step: 3677, epoch: 92, loss: 0.372508
global_step: 3678, epoch: 92, loss: 0.369697
global_step: 3679, epoch: 92, loss: 0.396512
global_step: 3680, epoch: 92, loss: 0.134450
epoch: 92
train	acc: 0.9564	macro: p 0.9639, r 0.9250, f1: 0.9430	micro: p 0.9564, r 0.9564, f1 0.9564	weighted_f1:0.9562
dev	acc: 0.5392	macro: p 0.3895, r 0.3118, f1: 0.3143	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4953
test	acc: 0.5839	macro: p 0.3707, r 0.3233, f1: 0.3274	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5492
global_step: 3681, epoch: 93, loss: 0.416397
global_step: 3682, epoch: 93, loss: 0.330989
global_step: 3683, epoch: 93, loss: 0.386213
global_step: 3684, epoch: 93, loss: 0.347301
global_step: 3685, epoch: 93, loss: 0.409875
global_step: 3686, epoch: 93, loss: 0.341175
global_step: 3687, epoch: 93, loss: 0.286468
global_step: 3688, epoch: 93, loss: 0.328595
global_step: 3689, epoch: 93, loss: 0.418036
global_step: 3690, epoch: 93, loss: 0.379960
global_step: 3691, epoch: 93, loss: 0.331085
global_step: 3692, epoch: 93, loss: 0.357873
global_step: 3693, epoch: 93, loss: 0.291133
global_step: 3694, epoch: 93, loss: 0.373828
global_step: 3695, epoch: 93, loss: 0.301297
global_step: 3696, epoch: 93, loss: 0.348708
global_step: 3697, epoch: 93, loss: 0.350814
global_step: 3698, epoch: 93, loss: 0.366795
global_step: 3699, epoch: 93, loss: 0.307653
global_step: 3700, epoch: 93, loss: 0.299132
global_step: 3701, epoch: 93, loss: 0.273415
global_step: 3702, epoch: 93, loss: 0.331385
global_step: 3703, epoch: 93, loss: 0.358634
global_step: 3704, epoch: 93, loss: 0.311280
global_step: 3705, epoch: 93, loss: 0.415272
global_step: 3706, epoch: 93, loss: 0.384371
global_step: 3707, epoch: 93, loss: 0.439049
global_step: 3708, epoch: 93, loss: 0.355548
global_step: 3709, epoch: 93, loss: 0.376072
global_step: 3710, epoch: 93, loss: 0.334985
global_step: 3711, epoch: 93, loss: 0.361050
global_step: 3712, epoch: 93, loss: 0.310444
global_step: 3713, epoch: 93, loss: 0.352303
global_step: 3714, epoch: 93, loss: 0.321092
global_step: 3715, epoch: 93, loss: 0.386015
global_step: 3716, epoch: 93, loss: 0.431789
global_step: 3717, epoch: 93, loss: 0.340113
global_step: 3718, epoch: 93, loss: 0.338828
global_step: 3719, epoch: 93, loss: 0.357982
global_step: 3720, epoch: 93, loss: 0.142828
epoch: 93
train	acc: 0.9559	macro: p 0.9645, r 0.9240, f1: 0.9427	micro: p 0.9559, r 0.9559, f1 0.9559	weighted_f1:0.9557
dev	acc: 0.5482	macro: p 0.5273, r 0.3221, f1: 0.3299	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5024
test	acc: 0.5897	macro: p 0.4167, r 0.3246, f1: 0.3321	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5500
global_step: 3721, epoch: 94, loss: 0.353464
global_step: 3722, epoch: 94, loss: 0.338283
global_step: 3723, epoch: 94, loss: 0.356233
global_step: 3724, epoch: 94, loss: 0.328888
global_step: 3725, epoch: 94, loss: 0.327560
global_step: 3726, epoch: 94, loss: 0.365359
global_step: 3727, epoch: 94, loss: 0.429237
global_step: 3728, epoch: 94, loss: 0.236750
global_step: 3729, epoch: 94, loss: 0.440244
global_step: 3730, epoch: 94, loss: 0.383555
global_step: 3731, epoch: 94, loss: 0.335452
global_step: 3732, epoch: 94, loss: 0.319519
global_step: 3733, epoch: 94, loss: 0.365090
global_step: 3734, epoch: 94, loss: 0.338573
global_step: 3735, epoch: 94, loss: 0.339658
global_step: 3736, epoch: 94, loss: 0.302072
global_step: 3737, epoch: 94, loss: 0.384305
global_step: 3738, epoch: 94, loss: 0.321012
global_step: 3739, epoch: 94, loss: 0.384604
global_step: 3740, epoch: 94, loss: 0.348328
global_step: 3741, epoch: 94, loss: 0.328050
global_step: 3742, epoch: 94, loss: 0.403887
global_step: 3743, epoch: 94, loss: 0.377492
global_step: 3744, epoch: 94, loss: 0.304893
global_step: 3745, epoch: 94, loss: 0.384078
global_step: 3746, epoch: 94, loss: 0.344260
global_step: 3747, epoch: 94, loss: 0.405469
global_step: 3748, epoch: 94, loss: 0.363952
global_step: 3749, epoch: 94, loss: 0.359385
global_step: 3750, epoch: 94, loss: 0.404343
global_step: 3751, epoch: 94, loss: 0.325378
global_step: 3752, epoch: 94, loss: 0.331194
global_step: 3753, epoch: 94, loss: 0.283337
global_step: 3754, epoch: 94, loss: 0.372999
global_step: 3755, epoch: 94, loss: 0.363004
global_step: 3756, epoch: 94, loss: 0.328486
global_step: 3757, epoch: 94, loss: 0.326559
global_step: 3758, epoch: 94, loss: 0.289867
global_step: 3759, epoch: 94, loss: 0.340075
global_step: 3760, epoch: 94, loss: 0.248790
epoch: 94
train	acc: 0.9564	macro: p 0.9646, r 0.9269, f1: 0.9445	micro: p 0.9564, r 0.9564, f1 0.9564	weighted_f1:0.9562
dev	acc: 0.5455	macro: p 0.4351, r 0.3137, f1: 0.3205	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4997
test	acc: 0.5866	macro: p 0.4130, r 0.3260, f1: 0.3404	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5493
global_step: 3761, epoch: 95, loss: 0.384202
global_step: 3762, epoch: 95, loss: 0.366133
global_step: 3763, epoch: 95, loss: 0.317525
global_step: 3764, epoch: 95, loss: 0.326566
global_step: 3765, epoch: 95, loss: 0.286536
global_step: 3766, epoch: 95, loss: 0.344842
global_step: 3767, epoch: 95, loss: 0.393910
global_step: 3768, epoch: 95, loss: 0.401173
global_step: 3769, epoch: 95, loss: 0.325362
global_step: 3770, epoch: 95, loss: 0.347490
global_step: 3771, epoch: 95, loss: 0.307564
global_step: 3772, epoch: 95, loss: 0.354655
global_step: 3773, epoch: 95, loss: 0.322440
global_step: 3774, epoch: 95, loss: 0.435007
global_step: 3775, epoch: 95, loss: 0.330632
global_step: 3776, epoch: 95, loss: 0.354297
global_step: 3777, epoch: 95, loss: 0.380216
global_step: 3778, epoch: 95, loss: 0.355586
global_step: 3779, epoch: 95, loss: 0.469726
global_step: 3780, epoch: 95, loss: 0.382367
global_step: 3781, epoch: 95, loss: 0.423800
global_step: 3782, epoch: 95, loss: 0.295754
global_step: 3783, epoch: 95, loss: 0.408304
global_step: 3784, epoch: 95, loss: 0.361668
global_step: 3785, epoch: 95, loss: 0.300153
global_step: 3786, epoch: 95, loss: 0.335247
global_step: 3787, epoch: 95, loss: 0.296016
global_step: 3788, epoch: 95, loss: 0.364771
global_step: 3789, epoch: 95, loss: 0.284987
global_step: 3790, epoch: 95, loss: 0.382572
global_step: 3791, epoch: 95, loss: 0.347308
global_step: 3792, epoch: 95, loss: 0.449351
global_step: 3793, epoch: 95, loss: 0.307040
global_step: 3794, epoch: 95, loss: 0.396023
global_step: 3795, epoch: 95, loss: 0.345494
global_step: 3796, epoch: 95, loss: 0.349365
global_step: 3797, epoch: 95, loss: 0.366298
global_step: 3798, epoch: 95, loss: 0.281624
global_step: 3799, epoch: 95, loss: 0.330442
global_step: 3800, epoch: 95, loss: 0.125695
epoch: 95
train	acc: 0.9555	macro: p 0.9645, r 0.9213, f1: 0.9412	micro: p 0.9555, r 0.9555, f1 0.9555	weighted_f1:0.9553
dev	acc: 0.5428	macro: p 0.4291, r 0.3093, f1: 0.3133	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4935
test	acc: 0.5885	macro: p 0.3833, r 0.3145, f1: 0.3198	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5446
global_step: 3801, epoch: 96, loss: 0.380634
global_step: 3802, epoch: 96, loss: 0.354607
global_step: 3803, epoch: 96, loss: 0.298106
global_step: 3804, epoch: 96, loss: 0.346667
global_step: 3805, epoch: 96, loss: 0.332758
global_step: 3806, epoch: 96, loss: 0.317742
global_step: 3807, epoch: 96, loss: 0.340026
global_step: 3808, epoch: 96, loss: 0.336808
global_step: 3809, epoch: 96, loss: 0.311821
global_step: 3810, epoch: 96, loss: 0.380260
global_step: 3811, epoch: 96, loss: 0.396779
global_step: 3812, epoch: 96, loss: 0.368330
global_step: 3813, epoch: 96, loss: 0.390043
global_step: 3814, epoch: 96, loss: 0.291290
global_step: 3815, epoch: 96, loss: 0.331373
global_step: 3816, epoch: 96, loss: 0.372783
global_step: 3817, epoch: 96, loss: 0.405491
global_step: 3818, epoch: 96, loss: 0.397741
global_step: 3819, epoch: 96, loss: 0.322338
global_step: 3820, epoch: 96, loss: 0.318575
global_step: 3821, epoch: 96, loss: 0.307755
global_step: 3822, epoch: 96, loss: 0.327022
global_step: 3823, epoch: 96, loss: 0.351624
global_step: 3824, epoch: 96, loss: 0.264307
global_step: 3825, epoch: 96, loss: 0.281105
global_step: 3826, epoch: 96, loss: 0.360524
global_step: 3827, epoch: 96, loss: 0.335192
global_step: 3828, epoch: 96, loss: 0.296499
global_step: 3829, epoch: 96, loss: 0.317775
global_step: 3830, epoch: 96, loss: 0.315820
global_step: 3831, epoch: 96, loss: 0.386979
global_step: 3832, epoch: 96, loss: 0.393060
global_step: 3833, epoch: 96, loss: 0.354340
global_step: 3834, epoch: 96, loss: 0.318444
global_step: 3835, epoch: 96, loss: 0.362500
global_step: 3836, epoch: 96, loss: 0.456859
global_step: 3837, epoch: 96, loss: 0.306482
global_step: 3838, epoch: 96, loss: 0.466325
global_step: 3839, epoch: 96, loss: 0.311915
global_step: 3840, epoch: 96, loss: 0.141954
epoch: 96
train	acc: 0.9594	macro: p 0.9665, r 0.9314, f1: 0.9478	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9593
dev	acc: 0.5419	macro: p 0.3613, r 0.3091, f1: 0.3101	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4940
test	acc: 0.5843	macro: p 0.3883, r 0.3206, f1: 0.3297	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5460
global_step: 3841, epoch: 97, loss: 0.360564
global_step: 3842, epoch: 97, loss: 0.381584
global_step: 3843, epoch: 97, loss: 0.247897
global_step: 3844, epoch: 97, loss: 0.333768
global_step: 3845, epoch: 97, loss: 0.279238
global_step: 3846, epoch: 97, loss: 0.347683
global_step: 3847, epoch: 97, loss: 0.293515
global_step: 3848, epoch: 97, loss: 0.386922
global_step: 3849, epoch: 97, loss: 0.363783
global_step: 3850, epoch: 97, loss: 0.328414
global_step: 3851, epoch: 97, loss: 0.390020
global_step: 3852, epoch: 97, loss: 0.402262
global_step: 3853, epoch: 97, loss: 0.364691
global_step: 3854, epoch: 97, loss: 0.230291
global_step: 3855, epoch: 97, loss: 0.294639
global_step: 3856, epoch: 97, loss: 0.300968
global_step: 3857, epoch: 97, loss: 0.349986
global_step: 3858, epoch: 97, loss: 0.411909
global_step: 3859, epoch: 97, loss: 0.389721
global_step: 3860, epoch: 97, loss: 0.427032
global_step: 3861, epoch: 97, loss: 0.403941
global_step: 3862, epoch: 97, loss: 0.313353
global_step: 3863, epoch: 97, loss: 0.358516
global_step: 3864, epoch: 97, loss: 0.274914
global_step: 3865, epoch: 97, loss: 0.409872
global_step: 3866, epoch: 97, loss: 0.293834
global_step: 3867, epoch: 97, loss: 0.385267
global_step: 3868, epoch: 97, loss: 0.334931
global_step: 3869, epoch: 97, loss: 0.373216
global_step: 3870, epoch: 97, loss: 0.364627
global_step: 3871, epoch: 97, loss: 0.341321
global_step: 3872, epoch: 97, loss: 0.342577
global_step: 3873, epoch: 97, loss: 0.303691
global_step: 3874, epoch: 97, loss: 0.387905
global_step: 3875, epoch: 97, loss: 0.303174
global_step: 3876, epoch: 97, loss: 0.310379
global_step: 3877, epoch: 97, loss: 0.345621
global_step: 3878, epoch: 97, loss: 0.317497
global_step: 3879, epoch: 97, loss: 0.339913
global_step: 3880, epoch: 97, loss: 0.617178
epoch: 97
train	acc: 0.9577	macro: p 0.9643, r 0.9319, f1: 0.9471	micro: p 0.9577, r 0.9577, f1 0.9577	weighted_f1:0.9576
dev	acc: 0.5464	macro: p 0.4091, r 0.3215, f1: 0.3279	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5021
test	acc: 0.5862	macro: p 0.3811, r 0.3222, f1: 0.3294	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5492
global_step: 3881, epoch: 98, loss: 0.354550
global_step: 3882, epoch: 98, loss: 0.309550
global_step: 3883, epoch: 98, loss: 0.318636
global_step: 3884, epoch: 98, loss: 0.455651
global_step: 3885, epoch: 98, loss: 0.313292
global_step: 3886, epoch: 98, loss: 0.249411
global_step: 3887, epoch: 98, loss: 0.296468
global_step: 3888, epoch: 98, loss: 0.251595
global_step: 3889, epoch: 98, loss: 0.294989
global_step: 3890, epoch: 98, loss: 0.273776
global_step: 3891, epoch: 98, loss: 0.306648
global_step: 3892, epoch: 98, loss: 0.366718
global_step: 3893, epoch: 98, loss: 0.345391
global_step: 3894, epoch: 98, loss: 0.336594
global_step: 3895, epoch: 98, loss: 0.350562
global_step: 3896, epoch: 98, loss: 0.361559
global_step: 3897, epoch: 98, loss: 0.373155
global_step: 3898, epoch: 98, loss: 0.295504
global_step: 3899, epoch: 98, loss: 0.329868
global_step: 3900, epoch: 98, loss: 0.359267
global_step: 3901, epoch: 98, loss: 0.256839
global_step: 3902, epoch: 98, loss: 0.407378
global_step: 3903, epoch: 98, loss: 0.275721
global_step: 3904, epoch: 98, loss: 0.387199
global_step: 3905, epoch: 98, loss: 0.424867
global_step: 3906, epoch: 98, loss: 0.350436
global_step: 3907, epoch: 98, loss: 0.383455
global_step: 3908, epoch: 98, loss: 0.370338
global_step: 3909, epoch: 98, loss: 0.394515
global_step: 3910, epoch: 98, loss: 0.308999
global_step: 3911, epoch: 98, loss: 0.423481
global_step: 3912, epoch: 98, loss: 0.299790
global_step: 3913, epoch: 98, loss: 0.279120
global_step: 3914, epoch: 98, loss: 0.356242
global_step: 3915, epoch: 98, loss: 0.340097
global_step: 3916, epoch: 98, loss: 0.374333
global_step: 3917, epoch: 98, loss: 0.389702
global_step: 3918, epoch: 98, loss: 0.414513
global_step: 3919, epoch: 98, loss: 0.293300
global_step: 3920, epoch: 98, loss: 0.109640
epoch: 98
train	acc: 0.9586	macro: p 0.9674, r 0.9276, f1: 0.9460	micro: p 0.9586, r 0.9586, f1 0.9586	weighted_f1:0.9584
dev	acc: 0.5383	macro: p 0.3603, r 0.3048, f1: 0.3051	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4879
test	acc: 0.5908	macro: p 0.4167, r 0.3198, f1: 0.3254	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5469
global_step: 3921, epoch: 99, loss: 0.319723
global_step: 3922, epoch: 99, loss: 0.297342
global_step: 3923, epoch: 99, loss: 0.288604
global_step: 3924, epoch: 99, loss: 0.300394
global_step: 3925, epoch: 99, loss: 0.281416
global_step: 3926, epoch: 99, loss: 0.288437
global_step: 3927, epoch: 99, loss: 0.360381
global_step: 3928, epoch: 99, loss: 0.319851
global_step: 3929, epoch: 99, loss: 0.332466
global_step: 3930, epoch: 99, loss: 0.363943
global_step: 3931, epoch: 99, loss: 0.293898
global_step: 3932, epoch: 99, loss: 0.243595
global_step: 3933, epoch: 99, loss: 0.298208
global_step: 3934, epoch: 99, loss: 0.369552
global_step: 3935, epoch: 99, loss: 0.385298
global_step: 3936, epoch: 99, loss: 0.378283
global_step: 3937, epoch: 99, loss: 0.377569
global_step: 3938, epoch: 99, loss: 0.348509
global_step: 3939, epoch: 99, loss: 0.389831
global_step: 3940, epoch: 99, loss: 0.206720
global_step: 3941, epoch: 99, loss: 0.320984
global_step: 3942, epoch: 99, loss: 0.374273
global_step: 3943, epoch: 99, loss: 0.313117
global_step: 3944, epoch: 99, loss: 0.373490
global_step: 3945, epoch: 99, loss: 0.375838
global_step: 3946, epoch: 99, loss: 0.370936
global_step: 3947, epoch: 99, loss: 0.336034
global_step: 3948, epoch: 99, loss: 0.288747
global_step: 3949, epoch: 99, loss: 0.291980
global_step: 3950, epoch: 99, loss: 0.370171
global_step: 3951, epoch: 99, loss: 0.309095
global_step: 3952, epoch: 99, loss: 0.328017
global_step: 3953, epoch: 99, loss: 0.245879
global_step: 3954, epoch: 99, loss: 0.335207
global_step: 3955, epoch: 99, loss: 0.332596
global_step: 3956, epoch: 99, loss: 0.382518
global_step: 3957, epoch: 99, loss: 0.328453
global_step: 3958, epoch: 99, loss: 0.378916
global_step: 3959, epoch: 99, loss: 0.389269
global_step: 3960, epoch: 99, loss: 0.119714
epoch: 99
train	acc: 0.9598	macro: p 0.9659, r 0.9320, f1: 0.9476	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9597
dev	acc: 0.5347	macro: p 0.3684, r 0.3065, f1: 0.3063	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4906
test	acc: 0.5877	macro: p 0.3844, r 0.3296, f1: 0.3339	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5533
global_step: 3961, epoch: 100, loss: 0.279706
global_step: 3962, epoch: 100, loss: 0.287914
global_step: 3963, epoch: 100, loss: 0.280934
global_step: 3964, epoch: 100, loss: 0.356612
global_step: 3965, epoch: 100, loss: 0.313382
global_step: 3966, epoch: 100, loss: 0.264638
global_step: 3967, epoch: 100, loss: 0.283072
global_step: 3968, epoch: 100, loss: 0.346654
global_step: 3969, epoch: 100, loss: 0.283788
global_step: 3970, epoch: 100, loss: 0.351801
global_step: 3971, epoch: 100, loss: 0.299052
global_step: 3972, epoch: 100, loss: 0.282306
global_step: 3973, epoch: 100, loss: 0.294501
global_step: 3974, epoch: 100, loss: 0.274995
global_step: 3975, epoch: 100, loss: 0.331327
global_step: 3976, epoch: 100, loss: 0.334930
global_step: 3977, epoch: 100, loss: 0.349520
global_step: 3978, epoch: 100, loss: 0.337854
global_step: 3979, epoch: 100, loss: 0.393500
global_step: 3980, epoch: 100, loss: 0.385825
global_step: 3981, epoch: 100, loss: 0.404353
global_step: 3982, epoch: 100, loss: 0.314016
global_step: 3983, epoch: 100, loss: 0.300623
global_step: 3984, epoch: 100, loss: 0.279672
global_step: 3985, epoch: 100, loss: 0.306859
global_step: 3986, epoch: 100, loss: 0.331318
global_step: 3987, epoch: 100, loss: 0.294162
global_step: 3988, epoch: 100, loss: 0.275947
global_step: 3989, epoch: 100, loss: 0.278004
global_step: 3990, epoch: 100, loss: 0.349616
global_step: 3991, epoch: 100, loss: 0.341421
global_step: 3992, epoch: 100, loss: 0.365914
global_step: 3993, epoch: 100, loss: 0.355668
global_step: 3994, epoch: 100, loss: 0.342102
global_step: 3995, epoch: 100, loss: 0.356649
global_step: 3996, epoch: 100, loss: 0.334105
global_step: 3997, epoch: 100, loss: 0.356819
global_step: 3998, epoch: 100, loss: 0.326377
global_step: 3999, epoch: 100, loss: 0.418544
global_step: 4000, epoch: 100, loss: 0.132895
epoch: 100
train	acc: 0.9609	macro: p 0.9677, r 0.9353, f1: 0.9504	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9608
dev	acc: 0.5374	macro: p 0.3690, r 0.3107, f1: 0.3110	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4941
test	acc: 0.5851	macro: p 0.3935, r 0.3297, f1: 0.3358	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5510
global_step: 4001, epoch: 101, loss: 0.314125
global_step: 4002, epoch: 101, loss: 0.324097
global_step: 4003, epoch: 101, loss: 0.375196
global_step: 4004, epoch: 101, loss: 0.258934
global_step: 4005, epoch: 101, loss: 0.401055
global_step: 4006, epoch: 101, loss: 0.359922
global_step: 4007, epoch: 101, loss: 0.260918
global_step: 4008, epoch: 101, loss: 0.255667
global_step: 4009, epoch: 101, loss: 0.300467
global_step: 4010, epoch: 101, loss: 0.320532
global_step: 4011, epoch: 101, loss: 0.357344
global_step: 4012, epoch: 101, loss: 0.381538
global_step: 4013, epoch: 101, loss: 0.307468
global_step: 4014, epoch: 101, loss: 0.328479
global_step: 4015, epoch: 101, loss: 0.313296
global_step: 4016, epoch: 101, loss: 0.314674
global_step: 4017, epoch: 101, loss: 0.365367
global_step: 4018, epoch: 101, loss: 0.320595
global_step: 4019, epoch: 101, loss: 0.346204
global_step: 4020, epoch: 101, loss: 0.320072
global_step: 4021, epoch: 101, loss: 0.279184
global_step: 4022, epoch: 101, loss: 0.368404
global_step: 4023, epoch: 101, loss: 0.308781
global_step: 4024, epoch: 101, loss: 0.382556
global_step: 4025, epoch: 101, loss: 0.380010
global_step: 4026, epoch: 101, loss: 0.255545
global_step: 4027, epoch: 101, loss: 0.339226
global_step: 4028, epoch: 101, loss: 0.326390
global_step: 4029, epoch: 101, loss: 0.417639
global_step: 4030, epoch: 101, loss: 0.298735
global_step: 4031, epoch: 101, loss: 0.427130
global_step: 4032, epoch: 101, loss: 0.323723
global_step: 4033, epoch: 101, loss: 0.315625
global_step: 4034, epoch: 101, loss: 0.335688
global_step: 4035, epoch: 101, loss: 0.418905
global_step: 4036, epoch: 101, loss: 0.350583
global_step: 4037, epoch: 101, loss: 0.351434
global_step: 4038, epoch: 101, loss: 0.255325
global_step: 4039, epoch: 101, loss: 0.340022
global_step: 4040, epoch: 101, loss: 0.471118
epoch: 101
train	acc: 0.9611	macro: p 0.9679, r 0.9358, f1: 0.9508	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9610
dev	acc: 0.5446	macro: p 0.4608, r 0.3257, f1: 0.3407	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5005
test	acc: 0.5870	macro: p 0.3783, r 0.3192, f1: 0.3287	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5492
global_step: 4041, epoch: 102, loss: 0.356271
global_step: 4042, epoch: 102, loss: 0.329797
global_step: 4043, epoch: 102, loss: 0.278320
global_step: 4044, epoch: 102, loss: 0.354186
global_step: 4045, epoch: 102, loss: 0.311760
global_step: 4046, epoch: 102, loss: 0.315112
global_step: 4047, epoch: 102, loss: 0.312019
global_step: 4048, epoch: 102, loss: 0.291077
global_step: 4049, epoch: 102, loss: 0.286074
global_step: 4050, epoch: 102, loss: 0.376878
global_step: 4051, epoch: 102, loss: 0.300619
global_step: 4052, epoch: 102, loss: 0.327991
global_step: 4053, epoch: 102, loss: 0.328999
global_step: 4054, epoch: 102, loss: 0.394688
global_step: 4055, epoch: 102, loss: 0.333611
global_step: 4056, epoch: 102, loss: 0.280564
global_step: 4057, epoch: 102, loss: 0.326034
global_step: 4058, epoch: 102, loss: 0.305327
global_step: 4059, epoch: 102, loss: 0.288124
global_step: 4060, epoch: 102, loss: 0.273758
global_step: 4061, epoch: 102, loss: 0.350046
global_step: 4062, epoch: 102, loss: 0.370008
global_step: 4063, epoch: 102, loss: 0.318707
global_step: 4064, epoch: 102, loss: 0.348078
global_step: 4065, epoch: 102, loss: 0.374406
global_step: 4066, epoch: 102, loss: 0.288258
global_step: 4067, epoch: 102, loss: 0.279357
global_step: 4068, epoch: 102, loss: 0.305108
global_step: 4069, epoch: 102, loss: 0.296315
global_step: 4070, epoch: 102, loss: 0.308181
global_step: 4071, epoch: 102, loss: 0.380547
global_step: 4072, epoch: 102, loss: 0.447072
global_step: 4073, epoch: 102, loss: 0.393009
global_step: 4074, epoch: 102, loss: 0.315387
global_step: 4075, epoch: 102, loss: 0.297625
global_step: 4076, epoch: 102, loss: 0.336021
global_step: 4077, epoch: 102, loss: 0.420301
global_step: 4078, epoch: 102, loss: 0.370052
global_step: 4079, epoch: 102, loss: 0.350620
global_step: 4080, epoch: 102, loss: 0.092215
epoch: 102
train	acc: 0.9611	macro: p 0.9682, r 0.9340, f1: 0.9499	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9610
dev	acc: 0.5437	macro: p 0.3874, r 0.3107, f1: 0.3111	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4950
test	acc: 0.5954	macro: p 0.4224, r 0.3282, f1: 0.3360	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5559
global_step: 4081, epoch: 103, loss: 0.278576
global_step: 4082, epoch: 103, loss: 0.350772
global_step: 4083, epoch: 103, loss: 0.268515
global_step: 4084, epoch: 103, loss: 0.272295
global_step: 4085, epoch: 103, loss: 0.289729
global_step: 4086, epoch: 103, loss: 0.383501
global_step: 4087, epoch: 103, loss: 0.234108
global_step: 4088, epoch: 103, loss: 0.349293
global_step: 4089, epoch: 103, loss: 0.335287
global_step: 4090, epoch: 103, loss: 0.341492
global_step: 4091, epoch: 103, loss: 0.333025
global_step: 4092, epoch: 103, loss: 0.330124
global_step: 4093, epoch: 103, loss: 0.261615
global_step: 4094, epoch: 103, loss: 0.339693
global_step: 4095, epoch: 103, loss: 0.383807
global_step: 4096, epoch: 103, loss: 0.257191
global_step: 4097, epoch: 103, loss: 0.354975
global_step: 4098, epoch: 103, loss: 0.360350
global_step: 4099, epoch: 103, loss: 0.263315
global_step: 4100, epoch: 103, loss: 0.300034
global_step: 4101, epoch: 103, loss: 0.305662
global_step: 4102, epoch: 103, loss: 0.322474
global_step: 4103, epoch: 103, loss: 0.347296
global_step: 4104, epoch: 103, loss: 0.287335
global_step: 4105, epoch: 103, loss: 0.354271
global_step: 4106, epoch: 103, loss: 0.372687
global_step: 4107, epoch: 103, loss: 0.300042
global_step: 4108, epoch: 103, loss: 0.312134
global_step: 4109, epoch: 103, loss: 0.308119
global_step: 4110, epoch: 103, loss: 0.375057
global_step: 4111, epoch: 103, loss: 0.349912
global_step: 4112, epoch: 103, loss: 0.332162
global_step: 4113, epoch: 103, loss: 0.334306
global_step: 4114, epoch: 103, loss: 0.246234
global_step: 4115, epoch: 103, loss: 0.329762
global_step: 4116, epoch: 103, loss: 0.378205
global_step: 4117, epoch: 103, loss: 0.291752
global_step: 4118, epoch: 103, loss: 0.257889
global_step: 4119, epoch: 103, loss: 0.343178
global_step: 4120, epoch: 103, loss: 0.008320
epoch: 103
train	acc: 0.9614	macro: p 0.9681, r 0.9378, f1: 0.9521	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9613
dev	acc: 0.5437	macro: p 0.3697, r 0.3110, f1: 0.3137	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4960
test	acc: 0.5904	macro: p 0.4266, r 0.3271, f1: 0.3389	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5533
global_step: 4121, epoch: 104, loss: 0.288043
global_step: 4122, epoch: 104, loss: 0.261837
global_step: 4123, epoch: 104, loss: 0.303148
global_step: 4124, epoch: 104, loss: 0.297068
global_step: 4125, epoch: 104, loss: 0.277228
global_step: 4126, epoch: 104, loss: 0.229084
global_step: 4127, epoch: 104, loss: 0.312070
global_step: 4128, epoch: 104, loss: 0.348186
global_step: 4129, epoch: 104, loss: 0.205561
global_step: 4130, epoch: 104, loss: 0.334500
global_step: 4131, epoch: 104, loss: 0.269873
global_step: 4132, epoch: 104, loss: 0.230816
global_step: 4133, epoch: 104, loss: 0.287303
global_step: 4134, epoch: 104, loss: 0.312068
global_step: 4135, epoch: 104, loss: 0.310985
global_step: 4136, epoch: 104, loss: 0.356214
global_step: 4137, epoch: 104, loss: 0.328008
global_step: 4138, epoch: 104, loss: 0.328832
global_step: 4139, epoch: 104, loss: 0.279410
global_step: 4140, epoch: 104, loss: 0.392869
global_step: 4141, epoch: 104, loss: 0.327848
global_step: 4142, epoch: 104, loss: 0.302419
global_step: 4143, epoch: 104, loss: 0.253096
global_step: 4144, epoch: 104, loss: 0.332207
global_step: 4145, epoch: 104, loss: 0.216574
global_step: 4146, epoch: 104, loss: 0.270732
global_step: 4147, epoch: 104, loss: 0.354957
global_step: 4148, epoch: 104, loss: 0.327038
global_step: 4149, epoch: 104, loss: 0.339923
global_step: 4150, epoch: 104, loss: 0.392684
global_step: 4151, epoch: 104, loss: 0.410009
global_step: 4152, epoch: 104, loss: 0.349548
global_step: 4153, epoch: 104, loss: 0.387713
global_step: 4154, epoch: 104, loss: 0.310471
global_step: 4155, epoch: 104, loss: 0.344853
global_step: 4156, epoch: 104, loss: 0.252196
global_step: 4157, epoch: 104, loss: 0.330261
global_step: 4158, epoch: 104, loss: 0.269689
global_step: 4159, epoch: 104, loss: 0.263776
global_step: 4160, epoch: 104, loss: 0.167521
epoch: 104
train	acc: 0.9586	macro: p 0.9710, r 0.9304, f1: 0.9496	micro: p 0.9586, r 0.9586, f1 0.9586	weighted_f1:0.9583
dev	acc: 0.5437	macro: p 0.3929, r 0.3040, f1: 0.3085	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4912
test	acc: 0.5893	macro: p 0.4288, r 0.3135, f1: 0.3253	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5452
global_step: 4161, epoch: 105, loss: 0.362776
global_step: 4162, epoch: 105, loss: 0.277509
global_step: 4163, epoch: 105, loss: 0.317226
global_step: 4164, epoch: 105, loss: 0.248081
global_step: 4165, epoch: 105, loss: 0.301984
global_step: 4166, epoch: 105, loss: 0.334961
global_step: 4167, epoch: 105, loss: 0.317656
global_step: 4168, epoch: 105, loss: 0.356110
global_step: 4169, epoch: 105, loss: 0.297777
global_step: 4170, epoch: 105, loss: 0.367116
global_step: 4171, epoch: 105, loss: 0.266620
global_step: 4172, epoch: 105, loss: 0.319219
global_step: 4173, epoch: 105, loss: 0.342282
global_step: 4174, epoch: 105, loss: 0.359214
global_step: 4175, epoch: 105, loss: 0.331293
global_step: 4176, epoch: 105, loss: 0.310598
global_step: 4177, epoch: 105, loss: 0.278298
global_step: 4178, epoch: 105, loss: 0.288879
global_step: 4179, epoch: 105, loss: 0.213914
global_step: 4180, epoch: 105, loss: 0.302806
global_step: 4181, epoch: 105, loss: 0.309863
global_step: 4182, epoch: 105, loss: 0.236299
global_step: 4183, epoch: 105, loss: 0.287013
global_step: 4184, epoch: 105, loss: 0.235024
global_step: 4185, epoch: 105, loss: 0.308879
global_step: 4186, epoch: 105, loss: 0.334618
global_step: 4187, epoch: 105, loss: 0.358788
global_step: 4188, epoch: 105, loss: 0.322656
global_step: 4189, epoch: 105, loss: 0.271574
global_step: 4190, epoch: 105, loss: 0.314358
global_step: 4191, epoch: 105, loss: 0.296445
global_step: 4192, epoch: 105, loss: 0.392231
global_step: 4193, epoch: 105, loss: 0.235602
global_step: 4194, epoch: 105, loss: 0.419061
global_step: 4195, epoch: 105, loss: 0.403488
global_step: 4196, epoch: 105, loss: 0.365948
global_step: 4197, epoch: 105, loss: 0.332864
global_step: 4198, epoch: 105, loss: 0.335225
global_step: 4199, epoch: 105, loss: 0.402949
global_step: 4200, epoch: 105, loss: 0.366888
epoch: 105
train	acc: 0.9617	macro: p 0.9680, r 0.9389, f1: 0.9526	micro: p 0.9617, r 0.9617, f1 0.9617	weighted_f1:0.9616
dev	acc: 0.5410	macro: p 0.4450, r 0.3158, f1: 0.3220	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4951
test	acc: 0.5847	macro: p 0.3946, r 0.3249, f1: 0.3316	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5464
global_step: 4201, epoch: 106, loss: 0.343230
global_step: 4202, epoch: 106, loss: 0.287873
global_step: 4203, epoch: 106, loss: 0.308511
global_step: 4204, epoch: 106, loss: 0.257440
global_step: 4205, epoch: 106, loss: 0.280234
global_step: 4206, epoch: 106, loss: 0.257664
global_step: 4207, epoch: 106, loss: 0.390762
global_step: 4208, epoch: 106, loss: 0.333658
global_step: 4209, epoch: 106, loss: 0.351921
global_step: 4210, epoch: 106, loss: 0.432225
global_step: 4211, epoch: 106, loss: 0.290987
global_step: 4212, epoch: 106, loss: 0.282230
global_step: 4213, epoch: 106, loss: 0.386833
global_step: 4214, epoch: 106, loss: 0.334048
global_step: 4215, epoch: 106, loss: 0.277374
global_step: 4216, epoch: 106, loss: 0.344790
global_step: 4217, epoch: 106, loss: 0.244924
global_step: 4218, epoch: 106, loss: 0.263062
global_step: 4219, epoch: 106, loss: 0.248726
global_step: 4220, epoch: 106, loss: 0.280941
global_step: 4221, epoch: 106, loss: 0.351966
global_step: 4222, epoch: 106, loss: 0.277014
global_step: 4223, epoch: 106, loss: 0.245532
global_step: 4224, epoch: 106, loss: 0.325672
global_step: 4225, epoch: 106, loss: 0.302279
global_step: 4226, epoch: 106, loss: 0.364200
global_step: 4227, epoch: 106, loss: 0.295321
global_step: 4228, epoch: 106, loss: 0.335752
global_step: 4229, epoch: 106, loss: 0.305130
global_step: 4230, epoch: 106, loss: 0.312129
global_step: 4231, epoch: 106, loss: 0.274445
global_step: 4232, epoch: 106, loss: 0.311382
global_step: 4233, epoch: 106, loss: 0.249936
global_step: 4234, epoch: 106, loss: 0.295784
global_step: 4235, epoch: 106, loss: 0.305126
global_step: 4236, epoch: 106, loss: 0.357840
global_step: 4237, epoch: 106, loss: 0.271652
global_step: 4238, epoch: 106, loss: 0.281621
global_step: 4239, epoch: 106, loss: 0.350225
global_step: 4240, epoch: 106, loss: 0.014635
epoch: 106
train	acc: 0.9620	macro: p 0.9689, r 0.9369, f1: 0.9519	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9619
dev	acc: 0.5383	macro: p 0.3802, r 0.3072, f1: 0.3112	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4921
test	acc: 0.5897	macro: p 0.4215, r 0.3234, f1: 0.3329	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5484
global_step: 4241, epoch: 107, loss: 0.271157
global_step: 4242, epoch: 107, loss: 0.225537
global_step: 4243, epoch: 107, loss: 0.286534
global_step: 4244, epoch: 107, loss: 0.230726
global_step: 4245, epoch: 107, loss: 0.382068
global_step: 4246, epoch: 107, loss: 0.293336
global_step: 4247, epoch: 107, loss: 0.275133
global_step: 4248, epoch: 107, loss: 0.322298
global_step: 4249, epoch: 107, loss: 0.325431
global_step: 4250, epoch: 107, loss: 0.323870
global_step: 4251, epoch: 107, loss: 0.310208
global_step: 4252, epoch: 107, loss: 0.325210
global_step: 4253, epoch: 107, loss: 0.267913
global_step: 4254, epoch: 107, loss: 0.314370
global_step: 4255, epoch: 107, loss: 0.328685
global_step: 4256, epoch: 107, loss: 0.318537
global_step: 4257, epoch: 107, loss: 0.344180
global_step: 4258, epoch: 107, loss: 0.386211
global_step: 4259, epoch: 107, loss: 0.392201
global_step: 4260, epoch: 107, loss: 0.260701
global_step: 4261, epoch: 107, loss: 0.303769
global_step: 4262, epoch: 107, loss: 0.311154
global_step: 4263, epoch: 107, loss: 0.321302
global_step: 4264, epoch: 107, loss: 0.306107
global_step: 4265, epoch: 107, loss: 0.253560
global_step: 4266, epoch: 107, loss: 0.378421
global_step: 4267, epoch: 107, loss: 0.376582
global_step: 4268, epoch: 107, loss: 0.319758
global_step: 4269, epoch: 107, loss: 0.371146
global_step: 4270, epoch: 107, loss: 0.291325
global_step: 4271, epoch: 107, loss: 0.217768
global_step: 4272, epoch: 107, loss: 0.320892
global_step: 4273, epoch: 107, loss: 0.256230
global_step: 4274, epoch: 107, loss: 0.319577
global_step: 4275, epoch: 107, loss: 0.299294
global_step: 4276, epoch: 107, loss: 0.336446
global_step: 4277, epoch: 107, loss: 0.315835
global_step: 4278, epoch: 107, loss: 0.423792
global_step: 4279, epoch: 107, loss: 0.330078
global_step: 4280, epoch: 107, loss: 0.087735
epoch: 107
train	acc: 0.9631	macro: p 0.9700, r 0.9427, f1: 0.9557	micro: p 0.9631, r 0.9631, f1 0.9631	weighted_f1:0.9630
dev	acc: 0.5428	macro: p 0.5169, r 0.3244, f1: 0.3380	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4966
test	acc: 0.5870	macro: p 0.4029, r 0.3245, f1: 0.3340	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5474
global_step: 4281, epoch: 108, loss: 0.276036
global_step: 4282, epoch: 108, loss: 0.322263
global_step: 4283, epoch: 108, loss: 0.254996
global_step: 4284, epoch: 108, loss: 0.229708
global_step: 4285, epoch: 108, loss: 0.283297
global_step: 4286, epoch: 108, loss: 0.207357
global_step: 4287, epoch: 108, loss: 0.340982
global_step: 4288, epoch: 108, loss: 0.347380
global_step: 4289, epoch: 108, loss: 0.304203
global_step: 4290, epoch: 108, loss: 0.265767
global_step: 4291, epoch: 108, loss: 0.306815
global_step: 4292, epoch: 108, loss: 0.367601
global_step: 4293, epoch: 108, loss: 0.309544
global_step: 4294, epoch: 108, loss: 0.297413
global_step: 4295, epoch: 108, loss: 0.329352
global_step: 4296, epoch: 108, loss: 0.292556
global_step: 4297, epoch: 108, loss: 0.245391
global_step: 4298, epoch: 108, loss: 0.301960
global_step: 4299, epoch: 108, loss: 0.310892
global_step: 4300, epoch: 108, loss: 0.261592
global_step: 4301, epoch: 108, loss: 0.253467
global_step: 4302, epoch: 108, loss: 0.339064
global_step: 4303, epoch: 108, loss: 0.294084
global_step: 4304, epoch: 108, loss: 0.338918
global_step: 4305, epoch: 108, loss: 0.308497
global_step: 4306, epoch: 108, loss: 0.332934
global_step: 4307, epoch: 108, loss: 0.349732
global_step: 4308, epoch: 108, loss: 0.283409
global_step: 4309, epoch: 108, loss: 0.267610
global_step: 4310, epoch: 108, loss: 0.332485
global_step: 4311, epoch: 108, loss: 0.296197
global_step: 4312, epoch: 108, loss: 0.268092
global_step: 4313, epoch: 108, loss: 0.225321
global_step: 4314, epoch: 108, loss: 0.352543
global_step: 4315, epoch: 108, loss: 0.311170
global_step: 4316, epoch: 108, loss: 0.265642
global_step: 4317, epoch: 108, loss: 0.327894
global_step: 4318, epoch: 108, loss: 0.296555
global_step: 4319, epoch: 108, loss: 0.363465
global_step: 4320, epoch: 108, loss: 0.066951
epoch: 108
train	acc: 0.9634	macro: p 0.9701, r 0.9420, f1: 0.9553	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9633
dev	acc: 0.5473	macro: p 0.5071, r 0.3202, f1: 0.3285	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5015
test	acc: 0.5889	macro: p 0.4096, r 0.3248, f1: 0.3350	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5506
global_step: 4321, epoch: 109, loss: 0.280279
global_step: 4322, epoch: 109, loss: 0.341977
global_step: 4323, epoch: 109, loss: 0.284479
global_step: 4324, epoch: 109, loss: 0.269078
global_step: 4325, epoch: 109, loss: 0.287097
global_step: 4326, epoch: 109, loss: 0.319403
global_step: 4327, epoch: 109, loss: 0.221800
global_step: 4328, epoch: 109, loss: 0.294678
global_step: 4329, epoch: 109, loss: 0.332194
global_step: 4330, epoch: 109, loss: 0.373725
global_step: 4331, epoch: 109, loss: 0.316346
global_step: 4332, epoch: 109, loss: 0.288129
global_step: 4333, epoch: 109, loss: 0.322910
global_step: 4334, epoch: 109, loss: 0.348124
global_step: 4335, epoch: 109, loss: 0.315383
global_step: 4336, epoch: 109, loss: 0.267557
global_step: 4337, epoch: 109, loss: 0.253977
global_step: 4338, epoch: 109, loss: 0.261966
global_step: 4339, epoch: 109, loss: 0.367655
global_step: 4340, epoch: 109, loss: 0.260233
global_step: 4341, epoch: 109, loss: 0.305721
global_step: 4342, epoch: 109, loss: 0.243621
global_step: 4343, epoch: 109, loss: 0.253001
global_step: 4344, epoch: 109, loss: 0.230900
global_step: 4345, epoch: 109, loss: 0.412140
global_step: 4346, epoch: 109, loss: 0.275689
global_step: 4347, epoch: 109, loss: 0.280260
global_step: 4348, epoch: 109, loss: 0.302031
global_step: 4349, epoch: 109, loss: 0.335736
global_step: 4350, epoch: 109, loss: 0.294016
global_step: 4351, epoch: 109, loss: 0.293012
global_step: 4352, epoch: 109, loss: 0.290632
global_step: 4353, epoch: 109, loss: 0.338243
global_step: 4354, epoch: 109, loss: 0.353588
global_step: 4355, epoch: 109, loss: 0.277166
global_step: 4356, epoch: 109, loss: 0.310068
global_step: 4357, epoch: 109, loss: 0.264351
global_step: 4358, epoch: 109, loss: 0.326995
global_step: 4359, epoch: 109, loss: 0.316989
global_step: 4360, epoch: 109, loss: 0.472701
epoch: 109
train	acc: 0.9615	macro: p 0.9685, r 0.9406, f1: 0.9538	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9615
dev	acc: 0.5473	macro: p 0.4182, r 0.3192, f1: 0.3251	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5004
test	acc: 0.5889	macro: p 0.4070, r 0.3259, f1: 0.3351	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5508
global_step: 4361, epoch: 110, loss: 0.314084
global_step: 4362, epoch: 110, loss: 0.230338
global_step: 4363, epoch: 110, loss: 0.261812
global_step: 4364, epoch: 110, loss: 0.258096
global_step: 4365, epoch: 110, loss: 0.207903
global_step: 4366, epoch: 110, loss: 0.355440
global_step: 4367, epoch: 110, loss: 0.365390
global_step: 4368, epoch: 110, loss: 0.412577
global_step: 4369, epoch: 110, loss: 0.255259
global_step: 4370, epoch: 110, loss: 0.283286
global_step: 4371, epoch: 110, loss: 0.334605
global_step: 4372, epoch: 110, loss: 0.274492
global_step: 4373, epoch: 110, loss: 0.261166
global_step: 4374, epoch: 110, loss: 0.282989
global_step: 4375, epoch: 110, loss: 0.355803
global_step: 4376, epoch: 110, loss: 0.380481
global_step: 4377, epoch: 110, loss: 0.257063
global_step: 4378, epoch: 110, loss: 0.268376
global_step: 4379, epoch: 110, loss: 0.293229
global_step: 4380, epoch: 110, loss: 0.337321
global_step: 4381, epoch: 110, loss: 0.313807
global_step: 4382, epoch: 110, loss: 0.330973
global_step: 4383, epoch: 110, loss: 0.314741
global_step: 4384, epoch: 110, loss: 0.276115
global_step: 4385, epoch: 110, loss: 0.302810
global_step: 4386, epoch: 110, loss: 0.334592
global_step: 4387, epoch: 110, loss: 0.373994
global_step: 4388, epoch: 110, loss: 0.355612
global_step: 4389, epoch: 110, loss: 0.251652
global_step: 4390, epoch: 110, loss: 0.344296
global_step: 4391, epoch: 110, loss: 0.298631
global_step: 4392, epoch: 110, loss: 0.313638
global_step: 4393, epoch: 110, loss: 0.247673
global_step: 4394, epoch: 110, loss: 0.254847
global_step: 4395, epoch: 110, loss: 0.297428
global_step: 4396, epoch: 110, loss: 0.298284
global_step: 4397, epoch: 110, loss: 0.274877
global_step: 4398, epoch: 110, loss: 0.243124
global_step: 4399, epoch: 110, loss: 0.340838
global_step: 4400, epoch: 110, loss: 0.088196
epoch: 110
train	acc: 0.9637	macro: p 0.9699, r 0.9425, f1: 0.9554	micro: p 0.9637, r 0.9637, f1 0.9637	weighted_f1:0.9636
dev	acc: 0.5428	macro: p 0.3558, r 0.3047, f1: 0.3046	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4917
test	acc: 0.5889	macro: p 0.3913, r 0.3229, f1: 0.3294	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5489
global_step: 4401, epoch: 111, loss: 0.270886
global_step: 4402, epoch: 111, loss: 0.280350
global_step: 4403, epoch: 111, loss: 0.328721
global_step: 4404, epoch: 111, loss: 0.352105
global_step: 4405, epoch: 111, loss: 0.259597
global_step: 4406, epoch: 111, loss: 0.318679
global_step: 4407, epoch: 111, loss: 0.256934
global_step: 4408, epoch: 111, loss: 0.255691
global_step: 4409, epoch: 111, loss: 0.205125
global_step: 4410, epoch: 111, loss: 0.264567
global_step: 4411, epoch: 111, loss: 0.296058
global_step: 4412, epoch: 111, loss: 0.295482
global_step: 4413, epoch: 111, loss: 0.269278
global_step: 4414, epoch: 111, loss: 0.306897
global_step: 4415, epoch: 111, loss: 0.228812
global_step: 4416, epoch: 111, loss: 0.290266
global_step: 4417, epoch: 111, loss: 0.363578
global_step: 4418, epoch: 111, loss: 0.261670
global_step: 4419, epoch: 111, loss: 0.301634
global_step: 4420, epoch: 111, loss: 0.337479
global_step: 4421, epoch: 111, loss: 0.308647
global_step: 4422, epoch: 111, loss: 0.245861
global_step: 4423, epoch: 111, loss: 0.253929
global_step: 4424, epoch: 111, loss: 0.268715
global_step: 4425, epoch: 111, loss: 0.232595
global_step: 4426, epoch: 111, loss: 0.249655
global_step: 4427, epoch: 111, loss: 0.376678
global_step: 4428, epoch: 111, loss: 0.267579
global_step: 4429, epoch: 111, loss: 0.260826
global_step: 4430, epoch: 111, loss: 0.310010
global_step: 4431, epoch: 111, loss: 0.320119
global_step: 4432, epoch: 111, loss: 0.231254
global_step: 4433, epoch: 111, loss: 0.301274
global_step: 4434, epoch: 111, loss: 0.278331
global_step: 4435, epoch: 111, loss: 0.337804
global_step: 4436, epoch: 111, loss: 0.360670
global_step: 4437, epoch: 111, loss: 0.281566
global_step: 4438, epoch: 111, loss: 0.289593
global_step: 4439, epoch: 111, loss: 0.334057
global_step: 4440, epoch: 111, loss: 0.858430
epoch: 111
train	acc: 0.9643	macro: p 0.9701, r 0.9426, f1: 0.9556	micro: p 0.9643, r 0.9643, f1 0.9643	weighted_f1:0.9643
dev	acc: 0.5383	macro: p 0.3875, r 0.3069, f1: 0.3088	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4891
test	acc: 0.5778	macro: p 0.3847, r 0.3100, f1: 0.3130	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5375
global_step: 4441, epoch: 112, loss: 0.294706
global_step: 4442, epoch: 112, loss: 0.283873
global_step: 4443, epoch: 112, loss: 0.252714
global_step: 4444, epoch: 112, loss: 0.291195
global_step: 4445, epoch: 112, loss: 0.264489
global_step: 4446, epoch: 112, loss: 0.285718
global_step: 4447, epoch: 112, loss: 0.319962
global_step: 4448, epoch: 112, loss: 0.293299
global_step: 4449, epoch: 112, loss: 0.333772
global_step: 4450, epoch: 112, loss: 0.257284
global_step: 4451, epoch: 112, loss: 0.248426
global_step: 4452, epoch: 112, loss: 0.247544
global_step: 4453, epoch: 112, loss: 0.277322
global_step: 4454, epoch: 112, loss: 0.266160
global_step: 4455, epoch: 112, loss: 0.272171
global_step: 4456, epoch: 112, loss: 0.328154
global_step: 4457, epoch: 112, loss: 0.236779
global_step: 4458, epoch: 112, loss: 0.280301
global_step: 4459, epoch: 112, loss: 0.241268
global_step: 4460, epoch: 112, loss: 0.303379
global_step: 4461, epoch: 112, loss: 0.334780
global_step: 4462, epoch: 112, loss: 0.239477
global_step: 4463, epoch: 112, loss: 0.340347
global_step: 4464, epoch: 112, loss: 0.231107
global_step: 4465, epoch: 112, loss: 0.248025
global_step: 4466, epoch: 112, loss: 0.285539
global_step: 4467, epoch: 112, loss: 0.245826
global_step: 4468, epoch: 112, loss: 0.353077
global_step: 4469, epoch: 112, loss: 0.321612
global_step: 4470, epoch: 112, loss: 0.299983
global_step: 4471, epoch: 112, loss: 0.327287
global_step: 4472, epoch: 112, loss: 0.313436
global_step: 4473, epoch: 112, loss: 0.206228
global_step: 4474, epoch: 112, loss: 0.294803
global_step: 4475, epoch: 112, loss: 0.298947
global_step: 4476, epoch: 112, loss: 0.330135
global_step: 4477, epoch: 112, loss: 0.287198
global_step: 4478, epoch: 112, loss: 0.291641
global_step: 4479, epoch: 112, loss: 0.236498
global_step: 4480, epoch: 112, loss: 0.436531
epoch: 112
train	acc: 0.9651	macro: p 0.9694, r 0.9461, f1: 0.9572	micro: p 0.9651, r 0.9651, f1 0.9651	weighted_f1:0.9650
dev	acc: 0.5419	macro: p 0.3853, r 0.3136, f1: 0.3182	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4977
test	acc: 0.5839	macro: p 0.4016, r 0.3219, f1: 0.3317	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5475
global_step: 4481, epoch: 113, loss: 0.202771
global_step: 4482, epoch: 113, loss: 0.238038
global_step: 4483, epoch: 113, loss: 0.237605
global_step: 4484, epoch: 113, loss: 0.304247
global_step: 4485, epoch: 113, loss: 0.268596
global_step: 4486, epoch: 113, loss: 0.218190
global_step: 4487, epoch: 113, loss: 0.282729
global_step: 4488, epoch: 113, loss: 0.209746
global_step: 4489, epoch: 113, loss: 0.316929
global_step: 4490, epoch: 113, loss: 0.291630
global_step: 4491, epoch: 113, loss: 0.296351
global_step: 4492, epoch: 113, loss: 0.259052
global_step: 4493, epoch: 113, loss: 0.287783
global_step: 4494, epoch: 113, loss: 0.273868
global_step: 4495, epoch: 113, loss: 0.297675
global_step: 4496, epoch: 113, loss: 0.235551
global_step: 4497, epoch: 113, loss: 0.360806
global_step: 4498, epoch: 113, loss: 0.183565
global_step: 4499, epoch: 113, loss: 0.344383
global_step: 4500, epoch: 113, loss: 0.329407
global_step: 4501, epoch: 113, loss: 0.358310
global_step: 4502, epoch: 113, loss: 0.394252
global_step: 4503, epoch: 113, loss: 0.230417
global_step: 4504, epoch: 113, loss: 0.300479
global_step: 4505, epoch: 113, loss: 0.302266
global_step: 4506, epoch: 113, loss: 0.322074
global_step: 4507, epoch: 113, loss: 0.276747
global_step: 4508, epoch: 113, loss: 0.326544
global_step: 4509, epoch: 113, loss: 0.275897
global_step: 4510, epoch: 113, loss: 0.297446
global_step: 4511, epoch: 113, loss: 0.323269
global_step: 4512, epoch: 113, loss: 0.273225
global_step: 4513, epoch: 113, loss: 0.288881
global_step: 4514, epoch: 113, loss: 0.255440
global_step: 4515, epoch: 113, loss: 0.330206
global_step: 4516, epoch: 113, loss: 0.274514
global_step: 4517, epoch: 113, loss: 0.370867
global_step: 4518, epoch: 113, loss: 0.264181
global_step: 4519, epoch: 113, loss: 0.342990
global_step: 4520, epoch: 113, loss: 1.304961
epoch: 113
train	acc: 0.9656	macro: p 0.9699, r 0.9465, f1: 0.9576	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9655
dev	acc: 0.5392	macro: p 0.3676, r 0.3147, f1: 0.3189	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4963
test	acc: 0.5759	macro: p 0.3560, r 0.3171, f1: 0.3214	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5406
global_step: 4521, epoch: 114, loss: 0.235523
global_step: 4522, epoch: 114, loss: 0.341211
global_step: 4523, epoch: 114, loss: 0.307916
global_step: 4524, epoch: 114, loss: 0.273187
global_step: 4525, epoch: 114, loss: 0.260966
global_step: 4526, epoch: 114, loss: 0.322822
global_step: 4527, epoch: 114, loss: 0.286669
global_step: 4528, epoch: 114, loss: 0.255908
global_step: 4529, epoch: 114, loss: 0.237120
global_step: 4530, epoch: 114, loss: 0.243337
global_step: 4531, epoch: 114, loss: 0.268313
global_step: 4532, epoch: 114, loss: 0.287293
global_step: 4533, epoch: 114, loss: 0.276381
global_step: 4534, epoch: 114, loss: 0.307386
global_step: 4535, epoch: 114, loss: 0.291901
global_step: 4536, epoch: 114, loss: 0.303201
global_step: 4537, epoch: 114, loss: 0.222150
global_step: 4538, epoch: 114, loss: 0.264328
global_step: 4539, epoch: 114, loss: 0.302987
global_step: 4540, epoch: 114, loss: 0.266733
global_step: 4541, epoch: 114, loss: 0.228661
global_step: 4542, epoch: 114, loss: 0.237716
global_step: 4543, epoch: 114, loss: 0.275444
global_step: 4544, epoch: 114, loss: 0.300251
global_step: 4545, epoch: 114, loss: 0.262869
global_step: 4546, epoch: 114, loss: 0.253978
global_step: 4547, epoch: 114, loss: 0.303805
global_step: 4548, epoch: 114, loss: 0.323988
global_step: 4549, epoch: 114, loss: 0.256304
global_step: 4550, epoch: 114, loss: 0.227698
global_step: 4551, epoch: 114, loss: 0.311537
global_step: 4552, epoch: 114, loss: 0.284297
global_step: 4553, epoch: 114, loss: 0.367544
global_step: 4554, epoch: 114, loss: 0.370419
global_step: 4555, epoch: 114, loss: 0.277184
global_step: 4556, epoch: 114, loss: 0.251867
global_step: 4557, epoch: 114, loss: 0.369820
global_step: 4558, epoch: 114, loss: 0.252949
global_step: 4559, epoch: 114, loss: 0.231876
global_step: 4560, epoch: 114, loss: 0.424316
epoch: 114
train	acc: 0.9652	macro: p 0.9703, r 0.9457, f1: 0.9574	micro: p 0.9652, r 0.9652, f1 0.9652	weighted_f1:0.9651
dev	acc: 0.5383	macro: p 0.3812, r 0.3118, f1: 0.3179	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4951
test	acc: 0.5785	macro: p 0.3777, r 0.3194, f1: 0.3266	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5433
global_step: 4561, epoch: 115, loss: 0.303842
global_step: 4562, epoch: 115, loss: 0.294692
global_step: 4563, epoch: 115, loss: 0.269324
global_step: 4564, epoch: 115, loss: 0.272586
global_step: 4565, epoch: 115, loss: 0.324729
global_step: 4566, epoch: 115, loss: 0.262870
global_step: 4567, epoch: 115, loss: 0.286589
global_step: 4568, epoch: 115, loss: 0.341314
global_step: 4569, epoch: 115, loss: 0.315722
global_step: 4570, epoch: 115, loss: 0.318226
global_step: 4571, epoch: 115, loss: 0.226506
global_step: 4572, epoch: 115, loss: 0.251340
global_step: 4573, epoch: 115, loss: 0.271917
global_step: 4574, epoch: 115, loss: 0.225052
global_step: 4575, epoch: 115, loss: 0.209005
global_step: 4576, epoch: 115, loss: 0.266783
global_step: 4577, epoch: 115, loss: 0.293295
global_step: 4578, epoch: 115, loss: 0.225443
global_step: 4579, epoch: 115, loss: 0.244128
global_step: 4580, epoch: 115, loss: 0.219741
global_step: 4581, epoch: 115, loss: 0.251895
global_step: 4582, epoch: 115, loss: 0.224073
global_step: 4583, epoch: 115, loss: 0.297495
global_step: 4584, epoch: 115, loss: 0.266666
global_step: 4585, epoch: 115, loss: 0.294550
global_step: 4586, epoch: 115, loss: 0.272562
global_step: 4587, epoch: 115, loss: 0.284057
global_step: 4588, epoch: 115, loss: 0.262218
global_step: 4589, epoch: 115, loss: 0.344139
global_step: 4590, epoch: 115, loss: 0.260540
global_step: 4591, epoch: 115, loss: 0.282729
global_step: 4592, epoch: 115, loss: 0.247954
global_step: 4593, epoch: 115, loss: 0.317552
global_step: 4594, epoch: 115, loss: 0.245392
global_step: 4595, epoch: 115, loss: 0.250061
global_step: 4596, epoch: 115, loss: 0.306664
global_step: 4597, epoch: 115, loss: 0.256496
global_step: 4598, epoch: 115, loss: 0.295136
global_step: 4599, epoch: 115, loss: 0.279027
global_step: 4600, epoch: 115, loss: 0.318480
epoch: 115
train	acc: 0.9656	macro: p 0.9718, r 0.9454, f1: 0.9579	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9655
dev	acc: 0.5392	macro: p 0.3959, r 0.3107, f1: 0.3179	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4916
test	acc: 0.5858	macro: p 0.3868, r 0.3147, f1: 0.3211	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5431
global_step: 4601, epoch: 116, loss: 0.255196
global_step: 4602, epoch: 116, loss: 0.260553
global_step: 4603, epoch: 116, loss: 0.284945
global_step: 4604, epoch: 116, loss: 0.202734
global_step: 4605, epoch: 116, loss: 0.275216
global_step: 4606, epoch: 116, loss: 0.331946
global_step: 4607, epoch: 116, loss: 0.264086
global_step: 4608, epoch: 116, loss: 0.291067
global_step: 4609, epoch: 116, loss: 0.281828
global_step: 4610, epoch: 116, loss: 0.230492
global_step: 4611, epoch: 116, loss: 0.254591
global_step: 4612, epoch: 116, loss: 0.228122
global_step: 4613, epoch: 116, loss: 0.308461
global_step: 4614, epoch: 116, loss: 0.307909
global_step: 4615, epoch: 116, loss: 0.250697
global_step: 4616, epoch: 116, loss: 0.300907
global_step: 4617, epoch: 116, loss: 0.272017
global_step: 4618, epoch: 116, loss: 0.248730
global_step: 4619, epoch: 116, loss: 0.243489
global_step: 4620, epoch: 116, loss: 0.262084
global_step: 4621, epoch: 116, loss: 0.273013
global_step: 4622, epoch: 116, loss: 0.231565
global_step: 4623, epoch: 116, loss: 0.259998
global_step: 4624, epoch: 116, loss: 0.244861
global_step: 4625, epoch: 116, loss: 0.261082
global_step: 4626, epoch: 116, loss: 0.290998
global_step: 4627, epoch: 116, loss: 0.245329
global_step: 4628, epoch: 116, loss: 0.307499
global_step: 4629, epoch: 116, loss: 0.300679
global_step: 4630, epoch: 116, loss: 0.209605
global_step: 4631, epoch: 116, loss: 0.292988
global_step: 4632, epoch: 116, loss: 0.312417
global_step: 4633, epoch: 116, loss: 0.287832
global_step: 4634, epoch: 116, loss: 0.356142
global_step: 4635, epoch: 116, loss: 0.339584
global_step: 4636, epoch: 116, loss: 0.240929
global_step: 4637, epoch: 116, loss: 0.252137
global_step: 4638, epoch: 116, loss: 0.307150
global_step: 4639, epoch: 116, loss: 0.206058
global_step: 4640, epoch: 116, loss: 0.169504
epoch: 116
train	acc: 0.9649	macro: p 0.9702, r 0.9463, f1: 0.9577	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5383	macro: p 0.3826, r 0.3108, f1: 0.3154	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4915
test	acc: 0.5808	macro: p 0.4132, r 0.3194, f1: 0.3261	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5420
global_step: 4641, epoch: 117, loss: 0.314994
global_step: 4642, epoch: 117, loss: 0.245020
global_step: 4643, epoch: 117, loss: 0.277090
global_step: 4644, epoch: 117, loss: 0.209572
global_step: 4645, epoch: 117, loss: 0.270675
global_step: 4646, epoch: 117, loss: 0.232313
global_step: 4647, epoch: 117, loss: 0.328599
global_step: 4648, epoch: 117, loss: 0.266190
global_step: 4649, epoch: 117, loss: 0.242261
global_step: 4650, epoch: 117, loss: 0.274890
global_step: 4651, epoch: 117, loss: 0.274774
global_step: 4652, epoch: 117, loss: 0.262915
global_step: 4653, epoch: 117, loss: 0.251576
global_step: 4654, epoch: 117, loss: 0.302240
global_step: 4655, epoch: 117, loss: 0.270999
global_step: 4656, epoch: 117, loss: 0.257918
global_step: 4657, epoch: 117, loss: 0.366944
global_step: 4658, epoch: 117, loss: 0.231125
global_step: 4659, epoch: 117, loss: 0.277636
global_step: 4660, epoch: 117, loss: 0.229446
global_step: 4661, epoch: 117, loss: 0.230701
global_step: 4662, epoch: 117, loss: 0.296952
global_step: 4663, epoch: 117, loss: 0.286542
global_step: 4664, epoch: 117, loss: 0.255935
global_step: 4665, epoch: 117, loss: 0.260455
global_step: 4666, epoch: 117, loss: 0.299356
global_step: 4667, epoch: 117, loss: 0.280639
global_step: 4668, epoch: 117, loss: 0.311176
global_step: 4669, epoch: 117, loss: 0.255665
global_step: 4670, epoch: 117, loss: 0.327009
global_step: 4671, epoch: 117, loss: 0.227974
global_step: 4672, epoch: 117, loss: 0.241219
global_step: 4673, epoch: 117, loss: 0.319331
global_step: 4674, epoch: 117, loss: 0.300660
global_step: 4675, epoch: 117, loss: 0.226680
global_step: 4676, epoch: 117, loss: 0.248007
global_step: 4677, epoch: 117, loss: 0.283132
global_step: 4678, epoch: 117, loss: 0.213580
global_step: 4679, epoch: 117, loss: 0.305214
global_step: 4680, epoch: 117, loss: 0.124429
epoch: 117
train	acc: 0.9650	macro: p 0.9703, r 0.9434, f1: 0.9561	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9649
dev	acc: 0.5383	macro: p 0.3730, r 0.3083, f1: 0.3118	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4920
test	acc: 0.5862	macro: p 0.4054, r 0.3213, f1: 0.3296	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5462
global_step: 4681, epoch: 118, loss: 0.242714
global_step: 4682, epoch: 118, loss: 0.277088
global_step: 4683, epoch: 118, loss: 0.304680
global_step: 4684, epoch: 118, loss: 0.232360
global_step: 4685, epoch: 118, loss: 0.243408
global_step: 4686, epoch: 118, loss: 0.275402
global_step: 4687, epoch: 118, loss: 0.238303
global_step: 4688, epoch: 118, loss: 0.261298
global_step: 4689, epoch: 118, loss: 0.287773
global_step: 4690, epoch: 118, loss: 0.249929
global_step: 4691, epoch: 118, loss: 0.276174
global_step: 4692, epoch: 118, loss: 0.246583
global_step: 4693, epoch: 118, loss: 0.240215
global_step: 4694, epoch: 118, loss: 0.272106
global_step: 4695, epoch: 118, loss: 0.421190
global_step: 4696, epoch: 118, loss: 0.298740
global_step: 4697, epoch: 118, loss: 0.337554
global_step: 4698, epoch: 118, loss: 0.272874
global_step: 4699, epoch: 118, loss: 0.254615
global_step: 4700, epoch: 118, loss: 0.248313
global_step: 4701, epoch: 118, loss: 0.275783
global_step: 4702, epoch: 118, loss: 0.298871
global_step: 4703, epoch: 118, loss: 0.236468
global_step: 4704, epoch: 118, loss: 0.270694
global_step: 4705, epoch: 118, loss: 0.311692
global_step: 4706, epoch: 118, loss: 0.227820
global_step: 4707, epoch: 118, loss: 0.275643
global_step: 4708, epoch: 118, loss: 0.220670
global_step: 4709, epoch: 118, loss: 0.239863
global_step: 4710, epoch: 118, loss: 0.256888
global_step: 4711, epoch: 118, loss: 0.270949
global_step: 4712, epoch: 118, loss: 0.326400
global_step: 4713, epoch: 118, loss: 0.270518
global_step: 4714, epoch: 118, loss: 0.313055
global_step: 4715, epoch: 118, loss: 0.250740
global_step: 4716, epoch: 118, loss: 0.293021
global_step: 4717, epoch: 118, loss: 0.275294
global_step: 4718, epoch: 118, loss: 0.330689
global_step: 4719, epoch: 118, loss: 0.330844
global_step: 4720, epoch: 118, loss: 0.745318
epoch: 118
train	acc: 0.9655	macro: p 0.9693, r 0.9485, f1: 0.9583	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5401	macro: p 0.3837, r 0.3165, f1: 0.3210	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4991
test	acc: 0.5805	macro: p 0.3998, r 0.3300, f1: 0.3389	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5483
global_step: 4721, epoch: 119, loss: 0.265368
global_step: 4722, epoch: 119, loss: 0.226593
global_step: 4723, epoch: 119, loss: 0.217238
global_step: 4724, epoch: 119, loss: 0.229362
global_step: 4725, epoch: 119, loss: 0.275250
global_step: 4726, epoch: 119, loss: 0.250526
global_step: 4727, epoch: 119, loss: 0.272450
global_step: 4728, epoch: 119, loss: 0.295738
global_step: 4729, epoch: 119, loss: 0.279847
global_step: 4730, epoch: 119, loss: 0.243870
global_step: 4731, epoch: 119, loss: 0.232447
global_step: 4732, epoch: 119, loss: 0.213364
global_step: 4733, epoch: 119, loss: 0.282358
global_step: 4734, epoch: 119, loss: 0.283944
global_step: 4735, epoch: 119, loss: 0.313407
global_step: 4736, epoch: 119, loss: 0.350880
global_step: 4737, epoch: 119, loss: 0.265984
global_step: 4738, epoch: 119, loss: 0.305639
global_step: 4739, epoch: 119, loss: 0.353571
global_step: 4740, epoch: 119, loss: 0.267887
global_step: 4741, epoch: 119, loss: 0.216557
global_step: 4742, epoch: 119, loss: 0.248955
global_step: 4743, epoch: 119, loss: 0.220878
global_step: 4744, epoch: 119, loss: 0.302004
global_step: 4745, epoch: 119, loss: 0.226693
global_step: 4746, epoch: 119, loss: 0.301531
global_step: 4747, epoch: 119, loss: 0.274853
global_step: 4748, epoch: 119, loss: 0.305346
global_step: 4749, epoch: 119, loss: 0.340233
global_step: 4750, epoch: 119, loss: 0.308994
global_step: 4751, epoch: 119, loss: 0.197595
global_step: 4752, epoch: 119, loss: 0.306348
global_step: 4753, epoch: 119, loss: 0.323850
global_step: 4754, epoch: 119, loss: 0.289772
global_step: 4755, epoch: 119, loss: 0.203980
global_step: 4756, epoch: 119, loss: 0.352912
global_step: 4757, epoch: 119, loss: 0.298481
global_step: 4758, epoch: 119, loss: 0.246341
global_step: 4759, epoch: 119, loss: 0.273616
global_step: 4760, epoch: 119, loss: 0.089659
epoch: 119
train	acc: 0.9671	macro: p 0.9707, r 0.9513, f1: 0.9606	micro: p 0.9671, r 0.9671, f1 0.9671	weighted_f1:0.9671
dev	acc: 0.5392	macro: p 0.3729, r 0.3121, f1: 0.3177	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4954
test	acc: 0.5812	macro: p 0.3861, r 0.3248, f1: 0.3339	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5477
global_step: 4761, epoch: 120, loss: 0.272880
global_step: 4762, epoch: 120, loss: 0.305035
global_step: 4763, epoch: 120, loss: 0.253991
global_step: 4764, epoch: 120, loss: 0.301961
global_step: 4765, epoch: 120, loss: 0.229334
global_step: 4766, epoch: 120, loss: 0.240655
global_step: 4767, epoch: 120, loss: 0.252963
global_step: 4768, epoch: 120, loss: 0.222162
global_step: 4769, epoch: 120, loss: 0.234375
global_step: 4770, epoch: 120, loss: 0.249244
global_step: 4771, epoch: 120, loss: 0.256082
global_step: 4772, epoch: 120, loss: 0.276129
global_step: 4773, epoch: 120, loss: 0.253781
global_step: 4774, epoch: 120, loss: 0.245377
global_step: 4775, epoch: 120, loss: 0.216166
global_step: 4776, epoch: 120, loss: 0.201171
global_step: 4777, epoch: 120, loss: 0.323503
global_step: 4778, epoch: 120, loss: 0.235068
global_step: 4779, epoch: 120, loss: 0.255217
global_step: 4780, epoch: 120, loss: 0.257445
global_step: 4781, epoch: 120, loss: 0.255083
global_step: 4782, epoch: 120, loss: 0.287330
global_step: 4783, epoch: 120, loss: 0.219028
global_step: 4784, epoch: 120, loss: 0.236070
global_step: 4785, epoch: 120, loss: 0.300266
global_step: 4786, epoch: 120, loss: 0.236041
global_step: 4787, epoch: 120, loss: 0.277181
global_step: 4788, epoch: 120, loss: 0.285258
global_step: 4789, epoch: 120, loss: 0.257141
global_step: 4790, epoch: 120, loss: 0.360165
global_step: 4791, epoch: 120, loss: 0.317009
global_step: 4792, epoch: 120, loss: 0.215580
global_step: 4793, epoch: 120, loss: 0.282214
global_step: 4794, epoch: 120, loss: 0.255678
global_step: 4795, epoch: 120, loss: 0.259578
global_step: 4796, epoch: 120, loss: 0.261768
global_step: 4797, epoch: 120, loss: 0.278923
global_step: 4798, epoch: 120, loss: 0.335809
global_step: 4799, epoch: 120, loss: 0.300387
global_step: 4800, epoch: 120, loss: 0.331798
epoch: 120
train	acc: 0.9648	macro: p 0.9706, r 0.9458, f1: 0.9576	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9647
dev	acc: 0.5428	macro: p 0.4633, r 0.3165, f1: 0.3256	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4933
test	acc: 0.5820	macro: p 0.3821, r 0.3108, f1: 0.3178	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5401
global_step: 4801, epoch: 121, loss: 0.243203
global_step: 4802, epoch: 121, loss: 0.223409
global_step: 4803, epoch: 121, loss: 0.214719
global_step: 4804, epoch: 121, loss: 0.265117
global_step: 4805, epoch: 121, loss: 0.232781
global_step: 4806, epoch: 121, loss: 0.233096
global_step: 4807, epoch: 121, loss: 0.229167
global_step: 4808, epoch: 121, loss: 0.318800
global_step: 4809, epoch: 121, loss: 0.321361
global_step: 4810, epoch: 121, loss: 0.235190
global_step: 4811, epoch: 121, loss: 0.249242
global_step: 4812, epoch: 121, loss: 0.223623
global_step: 4813, epoch: 121, loss: 0.292440
global_step: 4814, epoch: 121, loss: 0.290921
global_step: 4815, epoch: 121, loss: 0.189608
global_step: 4816, epoch: 121, loss: 0.302314
global_step: 4817, epoch: 121, loss: 0.257281
global_step: 4818, epoch: 121, loss: 0.242988
global_step: 4819, epoch: 121, loss: 0.210820
global_step: 4820, epoch: 121, loss: 0.262529
global_step: 4821, epoch: 121, loss: 0.239528
global_step: 4822, epoch: 121, loss: 0.242157
global_step: 4823, epoch: 121, loss: 0.249613
global_step: 4824, epoch: 121, loss: 0.298933
global_step: 4825, epoch: 121, loss: 0.278144
global_step: 4826, epoch: 121, loss: 0.243677
global_step: 4827, epoch: 121, loss: 0.205404
global_step: 4828, epoch: 121, loss: 0.321745
global_step: 4829, epoch: 121, loss: 0.254648
global_step: 4830, epoch: 121, loss: 0.267100
global_step: 4831, epoch: 121, loss: 0.218692
global_step: 4832, epoch: 121, loss: 0.308482
global_step: 4833, epoch: 121, loss: 0.308822
global_step: 4834, epoch: 121, loss: 0.261736
global_step: 4835, epoch: 121, loss: 0.231840
global_step: 4836, epoch: 121, loss: 0.306086
global_step: 4837, epoch: 121, loss: 0.260314
global_step: 4838, epoch: 121, loss: 0.307646
global_step: 4839, epoch: 121, loss: 0.361331
global_step: 4840, epoch: 121, loss: 0.116791
epoch: 121
train	acc: 0.9658	macro: p 0.9707, r 0.9474, f1: 0.9585	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9658
dev	acc: 0.5383	macro: p 0.3794, r 0.3052, f1: 0.3086	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4913
test	acc: 0.5831	macro: p 0.4422, r 0.3248, f1: 0.3368	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5478
global_step: 4841, epoch: 122, loss: 0.270860
global_step: 4842, epoch: 122, loss: 0.212533
global_step: 4843, epoch: 122, loss: 0.245232
global_step: 4844, epoch: 122, loss: 0.214872
global_step: 4845, epoch: 122, loss: 0.262574
global_step: 4846, epoch: 122, loss: 0.247846
global_step: 4847, epoch: 122, loss: 0.337624
global_step: 4848, epoch: 122, loss: 0.308220
global_step: 4849, epoch: 122, loss: 0.343035
global_step: 4850, epoch: 122, loss: 0.332718
global_step: 4851, epoch: 122, loss: 0.264564
global_step: 4852, epoch: 122, loss: 0.269705
global_step: 4853, epoch: 122, loss: 0.308378
global_step: 4854, epoch: 122, loss: 0.271474
global_step: 4855, epoch: 122, loss: 0.217095
global_step: 4856, epoch: 122, loss: 0.316041
global_step: 4857, epoch: 122, loss: 0.259294
global_step: 4858, epoch: 122, loss: 0.305449
global_step: 4859, epoch: 122, loss: 0.272363
global_step: 4860, epoch: 122, loss: 0.264084
global_step: 4861, epoch: 122, loss: 0.229094
global_step: 4862, epoch: 122, loss: 0.245319
global_step: 4863, epoch: 122, loss: 0.297146
global_step: 4864, epoch: 122, loss: 0.317379
global_step: 4865, epoch: 122, loss: 0.258732
global_step: 4866, epoch: 122, loss: 0.213204
global_step: 4867, epoch: 122, loss: 0.326763
global_step: 4868, epoch: 122, loss: 0.255845
global_step: 4869, epoch: 122, loss: 0.256961
global_step: 4870, epoch: 122, loss: 0.288709
global_step: 4871, epoch: 122, loss: 0.279157
global_step: 4872, epoch: 122, loss: 0.229270
global_step: 4873, epoch: 122, loss: 0.309344
global_step: 4874, epoch: 122, loss: 0.253495
global_step: 4875, epoch: 122, loss: 0.211675
global_step: 4876, epoch: 122, loss: 0.246757
global_step: 4877, epoch: 122, loss: 0.188935
global_step: 4878, epoch: 122, loss: 0.327932
global_step: 4879, epoch: 122, loss: 0.242006
global_step: 4880, epoch: 122, loss: 0.373481
epoch: 122
train	acc: 0.9658	macro: p 0.9725, r 0.9467, f1: 0.9590	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9657
dev	acc: 0.5293	macro: p 0.4222, r 0.3111, f1: 0.3210	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4811
test	acc: 0.5812	macro: p 0.3981, r 0.3160, f1: 0.3258	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5404
global_step: 4881, epoch: 123, loss: 0.245507
global_step: 4882, epoch: 123, loss: 0.258069
global_step: 4883, epoch: 123, loss: 0.245154
global_step: 4884, epoch: 123, loss: 0.243711
global_step: 4885, epoch: 123, loss: 0.253989
global_step: 4886, epoch: 123, loss: 0.248065
global_step: 4887, epoch: 123, loss: 0.263067
global_step: 4888, epoch: 123, loss: 0.256236
global_step: 4889, epoch: 123, loss: 0.212552
global_step: 4890, epoch: 123, loss: 0.237692
global_step: 4891, epoch: 123, loss: 0.282385
global_step: 4892, epoch: 123, loss: 0.274063
global_step: 4893, epoch: 123, loss: 0.222874
global_step: 4894, epoch: 123, loss: 0.225262
global_step: 4895, epoch: 123, loss: 0.238880
global_step: 4896, epoch: 123, loss: 0.206468
global_step: 4897, epoch: 123, loss: 0.255605
global_step: 4898, epoch: 123, loss: 0.237583
global_step: 4899, epoch: 123, loss: 0.238201
global_step: 4900, epoch: 123, loss: 0.202080
global_step: 4901, epoch: 123, loss: 0.298090
global_step: 4902, epoch: 123, loss: 0.305133
global_step: 4903, epoch: 123, loss: 0.255937
global_step: 4904, epoch: 123, loss: 0.266605
global_step: 4905, epoch: 123, loss: 0.244805
global_step: 4906, epoch: 123, loss: 0.291453
global_step: 4907, epoch: 123, loss: 0.259239
global_step: 4908, epoch: 123, loss: 0.275132
global_step: 4909, epoch: 123, loss: 0.244365
global_step: 4910, epoch: 123, loss: 0.293377
global_step: 4911, epoch: 123, loss: 0.342171
global_step: 4912, epoch: 123, loss: 0.244800
global_step: 4913, epoch: 123, loss: 0.307058
global_step: 4914, epoch: 123, loss: 0.217321
global_step: 4915, epoch: 123, loss: 0.304972
global_step: 4916, epoch: 123, loss: 0.255928
global_step: 4917, epoch: 123, loss: 0.300531
global_step: 4918, epoch: 123, loss: 0.273714
global_step: 4919, epoch: 123, loss: 0.329090
global_step: 4920, epoch: 123, loss: 0.012667
epoch: 123
train	acc: 0.9676	macro: p 0.9715, r 0.9519, f1: 0.9613	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5365	macro: p 0.4458, r 0.3253, f1: 0.3383	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4971
test	acc: 0.5720	macro: p 0.3829, r 0.3233, f1: 0.3327	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5427
global_step: 4921, epoch: 124, loss: 0.171674
global_step: 4922, epoch: 124, loss: 0.219384
global_step: 4923, epoch: 124, loss: 0.223893
global_step: 4924, epoch: 124, loss: 0.293153
global_step: 4925, epoch: 124, loss: 0.303431
global_step: 4926, epoch: 124, loss: 0.220105
global_step: 4927, epoch: 124, loss: 0.257531
global_step: 4928, epoch: 124, loss: 0.303492
global_step: 4929, epoch: 124, loss: 0.290790
global_step: 4930, epoch: 124, loss: 0.303852
global_step: 4931, epoch: 124, loss: 0.259501
global_step: 4932, epoch: 124, loss: 0.302372
global_step: 4933, epoch: 124, loss: 0.218014
global_step: 4934, epoch: 124, loss: 0.207386
global_step: 4935, epoch: 124, loss: 0.254317
global_step: 4936, epoch: 124, loss: 0.341207
global_step: 4937, epoch: 124, loss: 0.338008
global_step: 4938, epoch: 124, loss: 0.269667
global_step: 4939, epoch: 124, loss: 0.298764
global_step: 4940, epoch: 124, loss: 0.293490
global_step: 4941, epoch: 124, loss: 0.225383
global_step: 4942, epoch: 124, loss: 0.370625
global_step: 4943, epoch: 124, loss: 0.239558
global_step: 4944, epoch: 124, loss: 0.263556
global_step: 4945, epoch: 124, loss: 0.212796
global_step: 4946, epoch: 124, loss: 0.220681
global_step: 4947, epoch: 124, loss: 0.264380
global_step: 4948, epoch: 124, loss: 0.256059
global_step: 4949, epoch: 124, loss: 0.241610
global_step: 4950, epoch: 124, loss: 0.288619
global_step: 4951, epoch: 124, loss: 0.274077
global_step: 4952, epoch: 124, loss: 0.264336
global_step: 4953, epoch: 124, loss: 0.266897
global_step: 4954, epoch: 124, loss: 0.238882
global_step: 4955, epoch: 124, loss: 0.281077
global_step: 4956, epoch: 124, loss: 0.311053
global_step: 4957, epoch: 124, loss: 0.310019
global_step: 4958, epoch: 124, loss: 0.224397
global_step: 4959, epoch: 124, loss: 0.248180
global_step: 4960, epoch: 124, loss: 0.876328
epoch: 124
train	acc: 0.9655	macro: p 0.9679, r 0.9490, f1: 0.9580	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5365	macro: p 0.3683, r 0.3120, f1: 0.3176	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4968
test	acc: 0.5797	macro: p 0.4011, r 0.3257, f1: 0.3376	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5487
global_step: 4961, epoch: 125, loss: 0.340081
global_step: 4962, epoch: 125, loss: 0.270688
global_step: 4963, epoch: 125, loss: 0.263745
global_step: 4964, epoch: 125, loss: 0.250584
global_step: 4965, epoch: 125, loss: 0.314864
global_step: 4966, epoch: 125, loss: 0.220563
global_step: 4967, epoch: 125, loss: 0.229084
global_step: 4968, epoch: 125, loss: 0.227594
global_step: 4969, epoch: 125, loss: 0.310965
global_step: 4970, epoch: 125, loss: 0.319970
global_step: 4971, epoch: 125, loss: 0.225262
global_step: 4972, epoch: 125, loss: 0.220488
global_step: 4973, epoch: 125, loss: 0.264961
global_step: 4974, epoch: 125, loss: 0.302706
global_step: 4975, epoch: 125, loss: 0.193405
global_step: 4976, epoch: 125, loss: 0.245128
global_step: 4977, epoch: 125, loss: 0.203195
global_step: 4978, epoch: 125, loss: 0.325437
global_step: 4979, epoch: 125, loss: 0.253048
global_step: 4980, epoch: 125, loss: 0.267900
global_step: 4981, epoch: 125, loss: 0.228531
global_step: 4982, epoch: 125, loss: 0.226717
global_step: 4983, epoch: 125, loss: 0.252100
global_step: 4984, epoch: 125, loss: 0.271955
global_step: 4985, epoch: 125, loss: 0.259361
global_step: 4986, epoch: 125, loss: 0.209584
global_step: 4987, epoch: 125, loss: 0.280703
global_step: 4988, epoch: 125, loss: 0.262434
global_step: 4989, epoch: 125, loss: 0.296051
global_step: 4990, epoch: 125, loss: 0.277788
global_step: 4991, epoch: 125, loss: 0.264597
global_step: 4992, epoch: 125, loss: 0.280993
global_step: 4993, epoch: 125, loss: 0.286903
global_step: 4994, epoch: 125, loss: 0.248116
global_step: 4995, epoch: 125, loss: 0.243396
global_step: 4996, epoch: 125, loss: 0.214964
global_step: 4997, epoch: 125, loss: 0.213963
global_step: 4998, epoch: 125, loss: 0.276610
global_step: 4999, epoch: 125, loss: 0.212336
global_step: 5000, epoch: 125, loss: 0.035554
epoch: 125
train	acc: 0.9677	macro: p 0.9709, r 0.9509, f1: 0.9604	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5338	macro: p 0.3572, r 0.3054, f1: 0.3076	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4910
test	acc: 0.5782	macro: p 0.4034, r 0.3237, f1: 0.3330	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5455
global_step: 5001, epoch: 126, loss: 0.263791
global_step: 5002, epoch: 126, loss: 0.268214
global_step: 5003, epoch: 126, loss: 0.256442
global_step: 5004, epoch: 126, loss: 0.269923
global_step: 5005, epoch: 126, loss: 0.236570
global_step: 5006, epoch: 126, loss: 0.268684
global_step: 5007, epoch: 126, loss: 0.227168
global_step: 5008, epoch: 126, loss: 0.263071
global_step: 5009, epoch: 126, loss: 0.248106
global_step: 5010, epoch: 126, loss: 0.306446
global_step: 5011, epoch: 126, loss: 0.237405
global_step: 5012, epoch: 126, loss: 0.335462
global_step: 5013, epoch: 126, loss: 0.248466
global_step: 5014, epoch: 126, loss: 0.198889
global_step: 5015, epoch: 126, loss: 0.225560
global_step: 5016, epoch: 126, loss: 0.291449
global_step: 5017, epoch: 126, loss: 0.335810
global_step: 5018, epoch: 126, loss: 0.213244
global_step: 5019, epoch: 126, loss: 0.274262
global_step: 5020, epoch: 126, loss: 0.300201
global_step: 5021, epoch: 126, loss: 0.197675
global_step: 5022, epoch: 126, loss: 0.228017
global_step: 5023, epoch: 126, loss: 0.311706
global_step: 5024, epoch: 126, loss: 0.319962
global_step: 5025, epoch: 126, loss: 0.263869
global_step: 5026, epoch: 126, loss: 0.302764
global_step: 5027, epoch: 126, loss: 0.283328
global_step: 5028, epoch: 126, loss: 0.214980
global_step: 5029, epoch: 126, loss: 0.180927
global_step: 5030, epoch: 126, loss: 0.224285
global_step: 5031, epoch: 126, loss: 0.255961
global_step: 5032, epoch: 126, loss: 0.293480
global_step: 5033, epoch: 126, loss: 0.218655
global_step: 5034, epoch: 126, loss: 0.279985
global_step: 5035, epoch: 126, loss: 0.292029
global_step: 5036, epoch: 126, loss: 0.354860
global_step: 5037, epoch: 126, loss: 0.266044
global_step: 5038, epoch: 126, loss: 0.286674
global_step: 5039, epoch: 126, loss: 0.164396
global_step: 5040, epoch: 126, loss: 0.205922
epoch: 126
train	acc: 0.9678	macro: p 0.9731, r 0.9507, f1: 0.9614	micro: p 0.9678, r 0.9678, f1 0.9678	weighted_f1:0.9678
dev	acc: 0.5365	macro: p 0.4498, r 0.3116, f1: 0.3219	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4876
test	acc: 0.5870	macro: p 0.4031, r 0.3197, f1: 0.3304	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5444
global_step: 5041, epoch: 127, loss: 0.232929
global_step: 5042, epoch: 127, loss: 0.250240
global_step: 5043, epoch: 127, loss: 0.186689
global_step: 5044, epoch: 127, loss: 0.267001
global_step: 5045, epoch: 127, loss: 0.272494
global_step: 5046, epoch: 127, loss: 0.263653
global_step: 5047, epoch: 127, loss: 0.207834
global_step: 5048, epoch: 127, loss: 0.199387
global_step: 5049, epoch: 127, loss: 0.298269
global_step: 5050, epoch: 127, loss: 0.289010
global_step: 5051, epoch: 127, loss: 0.283179
global_step: 5052, epoch: 127, loss: 0.240298
global_step: 5053, epoch: 127, loss: 0.218833
global_step: 5054, epoch: 127, loss: 0.285141
global_step: 5055, epoch: 127, loss: 0.260598
global_step: 5056, epoch: 127, loss: 0.267364
global_step: 5057, epoch: 127, loss: 0.219586
global_step: 5058, epoch: 127, loss: 0.217745
global_step: 5059, epoch: 127, loss: 0.227763
global_step: 5060, epoch: 127, loss: 0.241404
global_step: 5061, epoch: 127, loss: 0.256277
global_step: 5062, epoch: 127, loss: 0.256930
global_step: 5063, epoch: 127, loss: 0.254492
global_step: 5064, epoch: 127, loss: 0.225576
global_step: 5065, epoch: 127, loss: 0.294890
global_step: 5066, epoch: 127, loss: 0.255619
global_step: 5067, epoch: 127, loss: 0.191177
global_step: 5068, epoch: 127, loss: 0.375152
global_step: 5069, epoch: 127, loss: 0.234287
global_step: 5070, epoch: 127, loss: 0.261237
global_step: 5071, epoch: 127, loss: 0.348857
global_step: 5072, epoch: 127, loss: 0.262936
global_step: 5073, epoch: 127, loss: 0.217105
global_step: 5074, epoch: 127, loss: 0.264072
global_step: 5075, epoch: 127, loss: 0.181589
global_step: 5076, epoch: 127, loss: 0.309736
global_step: 5077, epoch: 127, loss: 0.223891
global_step: 5078, epoch: 127, loss: 0.205696
global_step: 5079, epoch: 127, loss: 0.235998
global_step: 5080, epoch: 127, loss: 0.126214
epoch: 127
train	acc: 0.9665	macro: p 0.9720, r 0.9472, f1: 0.9590	micro: p 0.9665, r 0.9665, f1 0.9665	weighted_f1:0.9665
dev	acc: 0.5383	macro: p 0.4316, r 0.3113, f1: 0.3174	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4895
test	acc: 0.5831	macro: p 0.4140, r 0.3181, f1: 0.3257	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5425
global_step: 5081, epoch: 128, loss: 0.229091
global_step: 5082, epoch: 128, loss: 0.201952
global_step: 5083, epoch: 128, loss: 0.248586
global_step: 5084, epoch: 128, loss: 0.207116
global_step: 5085, epoch: 128, loss: 0.205224
global_step: 5086, epoch: 128, loss: 0.237093
global_step: 5087, epoch: 128, loss: 0.220004
global_step: 5088, epoch: 128, loss: 0.255360
global_step: 5089, epoch: 128, loss: 0.283834
global_step: 5090, epoch: 128, loss: 0.245003
global_step: 5091, epoch: 128, loss: 0.235640
global_step: 5092, epoch: 128, loss: 0.208122
global_step: 5093, epoch: 128, loss: 0.201680
global_step: 5094, epoch: 128, loss: 0.232858
global_step: 5095, epoch: 128, loss: 0.202581
global_step: 5096, epoch: 128, loss: 0.272334
global_step: 5097, epoch: 128, loss: 0.293920
global_step: 5098, epoch: 128, loss: 0.240003
global_step: 5099, epoch: 128, loss: 0.196588
global_step: 5100, epoch: 128, loss: 0.259714
global_step: 5101, epoch: 128, loss: 0.273091
global_step: 5102, epoch: 128, loss: 0.340476
global_step: 5103, epoch: 128, loss: 0.233275
global_step: 5104, epoch: 128, loss: 0.196705
global_step: 5105, epoch: 128, loss: 0.242919
global_step: 5106, epoch: 128, loss: 0.266676
global_step: 5107, epoch: 128, loss: 0.246029
global_step: 5108, epoch: 128, loss: 0.316137
global_step: 5109, epoch: 128, loss: 0.266511
global_step: 5110, epoch: 128, loss: 0.312084
global_step: 5111, epoch: 128, loss: 0.215427
global_step: 5112, epoch: 128, loss: 0.281778
global_step: 5113, epoch: 128, loss: 0.252528
global_step: 5114, epoch: 128, loss: 0.207121
global_step: 5115, epoch: 128, loss: 0.261544
global_step: 5116, epoch: 128, loss: 0.295870
global_step: 5117, epoch: 128, loss: 0.289338
global_step: 5118, epoch: 128, loss: 0.264139
global_step: 5119, epoch: 128, loss: 0.392921
global_step: 5120, epoch: 128, loss: 0.379051
epoch: 128
train	acc: 0.9682	macro: p 0.9726, r 0.9511, f1: 0.9614	micro: p 0.9682, r 0.9682, f1 0.9682	weighted_f1:0.9682
dev	acc: 0.5356	macro: p 0.3687, r 0.3042, f1: 0.3105	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4878
test	acc: 0.5835	macro: p 0.3968, r 0.3193, f1: 0.3284	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5449
global_step: 5121, epoch: 129, loss: 0.305316
global_step: 5122, epoch: 129, loss: 0.258236
global_step: 5123, epoch: 129, loss: 0.215583
global_step: 5124, epoch: 129, loss: 0.255738
global_step: 5125, epoch: 129, loss: 0.207987
global_step: 5126, epoch: 129, loss: 0.304848
global_step: 5127, epoch: 129, loss: 0.308616
global_step: 5128, epoch: 129, loss: 0.215607
global_step: 5129, epoch: 129, loss: 0.269469
global_step: 5130, epoch: 129, loss: 0.279302
global_step: 5131, epoch: 129, loss: 0.298915
global_step: 5132, epoch: 129, loss: 0.331396
global_step: 5133, epoch: 129, loss: 0.229542
global_step: 5134, epoch: 129, loss: 0.225174
global_step: 5135, epoch: 129, loss: 0.209192
global_step: 5136, epoch: 129, loss: 0.217690
global_step: 5137, epoch: 129, loss: 0.253355
global_step: 5138, epoch: 129, loss: 0.310813
global_step: 5139, epoch: 129, loss: 0.220957
global_step: 5140, epoch: 129, loss: 0.185608
global_step: 5141, epoch: 129, loss: 0.272749
global_step: 5142, epoch: 129, loss: 0.212166
global_step: 5143, epoch: 129, loss: 0.200480
global_step: 5144, epoch: 129, loss: 0.272340
global_step: 5145, epoch: 129, loss: 0.195198
global_step: 5146, epoch: 129, loss: 0.315388
global_step: 5147, epoch: 129, loss: 0.174998
global_step: 5148, epoch: 129, loss: 0.263747
global_step: 5149, epoch: 129, loss: 0.230782
global_step: 5150, epoch: 129, loss: 0.290794
global_step: 5151, epoch: 129, loss: 0.210330
global_step: 5152, epoch: 129, loss: 0.230950
global_step: 5153, epoch: 129, loss: 0.296026
global_step: 5154, epoch: 129, loss: 0.353620
global_step: 5155, epoch: 129, loss: 0.252546
global_step: 5156, epoch: 129, loss: 0.217035
global_step: 5157, epoch: 129, loss: 0.262828
global_step: 5158, epoch: 129, loss: 0.256330
global_step: 5159, epoch: 129, loss: 0.303763
global_step: 5160, epoch: 129, loss: 0.227513
epoch: 129
train	acc: 0.9684	macro: p 0.9726, r 0.9527, f1: 0.9622	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5338	macro: p 0.4087, r 0.3043, f1: 0.3135	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4842
test	acc: 0.5816	macro: p 0.3976, r 0.3121, f1: 0.3228	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5391
global_step: 5161, epoch: 130, loss: 0.242647
global_step: 5162, epoch: 130, loss: 0.233232
global_step: 5163, epoch: 130, loss: 0.250348
global_step: 5164, epoch: 130, loss: 0.208391
global_step: 5165, epoch: 130, loss: 0.250474
global_step: 5166, epoch: 130, loss: 0.189055
global_step: 5167, epoch: 130, loss: 0.326543
global_step: 5168, epoch: 130, loss: 0.258304
global_step: 5169, epoch: 130, loss: 0.237904
global_step: 5170, epoch: 130, loss: 0.211186
global_step: 5171, epoch: 130, loss: 0.286306
global_step: 5172, epoch: 130, loss: 0.221363
global_step: 5173, epoch: 130, loss: 0.271556
global_step: 5174, epoch: 130, loss: 0.233646
global_step: 5175, epoch: 130, loss: 0.161841
global_step: 5176, epoch: 130, loss: 0.215195
global_step: 5177, epoch: 130, loss: 0.306712
global_step: 5178, epoch: 130, loss: 0.369570
global_step: 5179, epoch: 130, loss: 0.331875
global_step: 5180, epoch: 130, loss: 0.233083
global_step: 5181, epoch: 130, loss: 0.244186
global_step: 5182, epoch: 130, loss: 0.278858
global_step: 5183, epoch: 130, loss: 0.194871
global_step: 5184, epoch: 130, loss: 0.186483
global_step: 5185, epoch: 130, loss: 0.294550
global_step: 5186, epoch: 130, loss: 0.226901
global_step: 5187, epoch: 130, loss: 0.264570
global_step: 5188, epoch: 130, loss: 0.221635
global_step: 5189, epoch: 130, loss: 0.254898
global_step: 5190, epoch: 130, loss: 0.251519
global_step: 5191, epoch: 130, loss: 0.274596
global_step: 5192, epoch: 130, loss: 0.294440
global_step: 5193, epoch: 130, loss: 0.192516
global_step: 5194, epoch: 130, loss: 0.188885
global_step: 5195, epoch: 130, loss: 0.191857
global_step: 5196, epoch: 130, loss: 0.201304
global_step: 5197, epoch: 130, loss: 0.214847
global_step: 5198, epoch: 130, loss: 0.216292
global_step: 5199, epoch: 130, loss: 0.233569
global_step: 5200, epoch: 130, loss: 0.263258
epoch: 130
train	acc: 0.9677	macro: p 0.9722, r 0.9513, f1: 0.9614	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9676
dev	acc: 0.5374	macro: p 0.4409, r 0.3131, f1: 0.3265	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4882
test	acc: 0.5793	macro: p 0.3691, r 0.3038, f1: 0.3110	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5345
global_step: 5201, epoch: 131, loss: 0.265416
global_step: 5202, epoch: 131, loss: 0.268621
global_step: 5203, epoch: 131, loss: 0.214800
global_step: 5204, epoch: 131, loss: 0.252958
global_step: 5205, epoch: 131, loss: 0.232741
global_step: 5206, epoch: 131, loss: 0.175211
global_step: 5207, epoch: 131, loss: 0.222934
global_step: 5208, epoch: 131, loss: 0.254066
global_step: 5209, epoch: 131, loss: 0.292715
global_step: 5210, epoch: 131, loss: 0.281396
global_step: 5211, epoch: 131, loss: 0.223370
global_step: 5212, epoch: 131, loss: 0.257161
global_step: 5213, epoch: 131, loss: 0.247890
global_step: 5214, epoch: 131, loss: 0.292401
global_step: 5215, epoch: 131, loss: 0.282118
global_step: 5216, epoch: 131, loss: 0.217057
global_step: 5217, epoch: 131, loss: 0.225859
global_step: 5218, epoch: 131, loss: 0.243339
global_step: 5219, epoch: 131, loss: 0.245911
global_step: 5220, epoch: 131, loss: 0.293365
global_step: 5221, epoch: 131, loss: 0.187067
global_step: 5222, epoch: 131, loss: 0.283439
global_step: 5223, epoch: 131, loss: 0.265745
global_step: 5224, epoch: 131, loss: 0.252287
global_step: 5225, epoch: 131, loss: 0.274070
global_step: 5226, epoch: 131, loss: 0.197519
global_step: 5227, epoch: 131, loss: 0.272478
global_step: 5228, epoch: 131, loss: 0.268690
global_step: 5229, epoch: 131, loss: 0.271092
global_step: 5230, epoch: 131, loss: 0.210958
global_step: 5231, epoch: 131, loss: 0.174792
global_step: 5232, epoch: 131, loss: 0.252237
global_step: 5233, epoch: 131, loss: 0.216248
global_step: 5234, epoch: 131, loss: 0.282489
global_step: 5235, epoch: 131, loss: 0.285210
global_step: 5236, epoch: 131, loss: 0.237106
global_step: 5237, epoch: 131, loss: 0.211884
global_step: 5238, epoch: 131, loss: 0.281011
global_step: 5239, epoch: 131, loss: 0.236218
global_step: 5240, epoch: 131, loss: 0.097133
epoch: 131
train	acc: 0.9685	macro: p 0.9720, r 0.9531, f1: 0.9622	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5266	macro: p 0.3636, r 0.2986, f1: 0.3050	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4817
test	acc: 0.5820	macro: p 0.3858, r 0.3232, f1: 0.3335	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5479
global_step: 5241, epoch: 132, loss: 0.215633
global_step: 5242, epoch: 132, loss: 0.246869
global_step: 5243, epoch: 132, loss: 0.197606
global_step: 5244, epoch: 132, loss: 0.220309
global_step: 5245, epoch: 132, loss: 0.257109
global_step: 5246, epoch: 132, loss: 0.207629
global_step: 5247, epoch: 132, loss: 0.281081
global_step: 5248, epoch: 132, loss: 0.205425
global_step: 5249, epoch: 132, loss: 0.270197
global_step: 5250, epoch: 132, loss: 0.228862
global_step: 5251, epoch: 132, loss: 0.283908
global_step: 5252, epoch: 132, loss: 0.274897
global_step: 5253, epoch: 132, loss: 0.360158
global_step: 5254, epoch: 132, loss: 0.201641
global_step: 5255, epoch: 132, loss: 0.220557
global_step: 5256, epoch: 132, loss: 0.288367
global_step: 5257, epoch: 132, loss: 0.219747
global_step: 5258, epoch: 132, loss: 0.255081
global_step: 5259, epoch: 132, loss: 0.341768
global_step: 5260, epoch: 132, loss: 0.205172
global_step: 5261, epoch: 132, loss: 0.383185
global_step: 5262, epoch: 132, loss: 0.241212
global_step: 5263, epoch: 132, loss: 0.236354
global_step: 5264, epoch: 132, loss: 0.228583
global_step: 5265, epoch: 132, loss: 0.236689
global_step: 5266, epoch: 132, loss: 0.259180
global_step: 5267, epoch: 132, loss: 0.246529
global_step: 5268, epoch: 132, loss: 0.253647
global_step: 5269, epoch: 132, loss: 0.238937
global_step: 5270, epoch: 132, loss: 0.231095
global_step: 5271, epoch: 132, loss: 0.224455
global_step: 5272, epoch: 132, loss: 0.231665
global_step: 5273, epoch: 132, loss: 0.332816
global_step: 5274, epoch: 132, loss: 0.207204
global_step: 5275, epoch: 132, loss: 0.203658
global_step: 5276, epoch: 132, loss: 0.278191
global_step: 5277, epoch: 132, loss: 0.246321
global_step: 5278, epoch: 132, loss: 0.246884
global_step: 5279, epoch: 132, loss: 0.240349
global_step: 5280, epoch: 132, loss: 0.005916
epoch: 132
train	acc: 0.9678	macro: p 0.9717, r 0.9503, f1: 0.9605	micro: p 0.9678, r 0.9678, f1 0.9678	weighted_f1:0.9678
dev	acc: 0.5329	macro: p 0.3465, r 0.2990, f1: 0.2985	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4836
test	acc: 0.5770	macro: p 0.3787, r 0.3099, f1: 0.3153	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5362
global_step: 5281, epoch: 133, loss: 0.190674
global_step: 5282, epoch: 133, loss: 0.198590
global_step: 5283, epoch: 133, loss: 0.230363
global_step: 5284, epoch: 133, loss: 0.212579
global_step: 5285, epoch: 133, loss: 0.231519
global_step: 5286, epoch: 133, loss: 0.223437
global_step: 5287, epoch: 133, loss: 0.293529
global_step: 5288, epoch: 133, loss: 0.238207
global_step: 5289, epoch: 133, loss: 0.185235
global_step: 5290, epoch: 133, loss: 0.222704
global_step: 5291, epoch: 133, loss: 0.258984
global_step: 5292, epoch: 133, loss: 0.227552
global_step: 5293, epoch: 133, loss: 0.247059
global_step: 5294, epoch: 133, loss: 0.257357
global_step: 5295, epoch: 133, loss: 0.209715
global_step: 5296, epoch: 133, loss: 0.267111
global_step: 5297, epoch: 133, loss: 0.275913
global_step: 5298, epoch: 133, loss: 0.270185
global_step: 5299, epoch: 133, loss: 0.250771
global_step: 5300, epoch: 133, loss: 0.246638
global_step: 5301, epoch: 133, loss: 0.237567
global_step: 5302, epoch: 133, loss: 0.216942
global_step: 5303, epoch: 133, loss: 0.353543
global_step: 5304, epoch: 133, loss: 0.227884
global_step: 5305, epoch: 133, loss: 0.261780
global_step: 5306, epoch: 133, loss: 0.306653
global_step: 5307, epoch: 133, loss: 0.226836
global_step: 5308, epoch: 133, loss: 0.255845
global_step: 5309, epoch: 133, loss: 0.187912
global_step: 5310, epoch: 133, loss: 0.213840
global_step: 5311, epoch: 133, loss: 0.273177
global_step: 5312, epoch: 133, loss: 0.323181
global_step: 5313, epoch: 133, loss: 0.320315
global_step: 5314, epoch: 133, loss: 0.256147
global_step: 5315, epoch: 133, loss: 0.231867
global_step: 5316, epoch: 133, loss: 0.265876
global_step: 5317, epoch: 133, loss: 0.213936
global_step: 5318, epoch: 133, loss: 0.230826
global_step: 5319, epoch: 133, loss: 0.267842
global_step: 5320, epoch: 133, loss: 0.214405
epoch: 133
train	acc: 0.9681	macro: p 0.9720, r 0.9515, f1: 0.9613	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9681
dev	acc: 0.5383	macro: p 0.3855, r 0.3131, f1: 0.3215	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4940
test	acc: 0.5808	macro: p 0.4267, r 0.3267, f1: 0.3394	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5437
global_step: 5321, epoch: 134, loss: 0.297069
global_step: 5322, epoch: 134, loss: 0.209925
global_step: 5323, epoch: 134, loss: 0.272928
global_step: 5324, epoch: 134, loss: 0.263386
global_step: 5325, epoch: 134, loss: 0.215541
global_step: 5326, epoch: 134, loss: 0.235772
global_step: 5327, epoch: 134, loss: 0.222731
global_step: 5328, epoch: 134, loss: 0.212114
global_step: 5329, epoch: 134, loss: 0.165686
global_step: 5330, epoch: 134, loss: 0.275630
global_step: 5331, epoch: 134, loss: 0.248818
global_step: 5332, epoch: 134, loss: 0.300662
global_step: 5333, epoch: 134, loss: 0.259681
global_step: 5334, epoch: 134, loss: 0.206251
global_step: 5335, epoch: 134, loss: 0.241573
global_step: 5336, epoch: 134, loss: 0.165463
global_step: 5337, epoch: 134, loss: 0.269920
global_step: 5338, epoch: 134, loss: 0.267030
global_step: 5339, epoch: 134, loss: 0.189916
global_step: 5340, epoch: 134, loss: 0.261072
global_step: 5341, epoch: 134, loss: 0.224927
global_step: 5342, epoch: 134, loss: 0.273598
global_step: 5343, epoch: 134, loss: 0.280206
global_step: 5344, epoch: 134, loss: 0.250711
global_step: 5345, epoch: 134, loss: 0.256222
global_step: 5346, epoch: 134, loss: 0.200458
global_step: 5347, epoch: 134, loss: 0.276193
global_step: 5348, epoch: 134, loss: 0.230786
global_step: 5349, epoch: 134, loss: 0.229995
global_step: 5350, epoch: 134, loss: 0.210209
global_step: 5351, epoch: 134, loss: 0.253207
global_step: 5352, epoch: 134, loss: 0.204442
global_step: 5353, epoch: 134, loss: 0.180933
global_step: 5354, epoch: 134, loss: 0.285745
global_step: 5355, epoch: 134, loss: 0.279543
global_step: 5356, epoch: 134, loss: 0.206641
global_step: 5357, epoch: 134, loss: 0.298477
global_step: 5358, epoch: 134, loss: 0.303371
global_step: 5359, epoch: 134, loss: 0.248049
global_step: 5360, epoch: 134, loss: 0.279139
epoch: 134
train	acc: 0.9696	macro: p 0.9726, r 0.9560, f1: 0.9639	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5329	macro: p 0.3930, r 0.3190, f1: 0.3308	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4953
test	acc: 0.5793	macro: p 0.3696, r 0.3270, f1: 0.3347	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5485
global_step: 5361, epoch: 135, loss: 0.184450
global_step: 5362, epoch: 135, loss: 0.214922
global_step: 5363, epoch: 135, loss: 0.200060
global_step: 5364, epoch: 135, loss: 0.267063
global_step: 5365, epoch: 135, loss: 0.293671
global_step: 5366, epoch: 135, loss: 0.205041
global_step: 5367, epoch: 135, loss: 0.217638
global_step: 5368, epoch: 135, loss: 0.246818
global_step: 5369, epoch: 135, loss: 0.219732
global_step: 5370, epoch: 135, loss: 0.234801
global_step: 5371, epoch: 135, loss: 0.250791
global_step: 5372, epoch: 135, loss: 0.267802
global_step: 5373, epoch: 135, loss: 0.220813
global_step: 5374, epoch: 135, loss: 0.204097
global_step: 5375, epoch: 135, loss: 0.206600
global_step: 5376, epoch: 135, loss: 0.183088
global_step: 5377, epoch: 135, loss: 0.244026
global_step: 5378, epoch: 135, loss: 0.274081
global_step: 5379, epoch: 135, loss: 0.247472
global_step: 5380, epoch: 135, loss: 0.220632
global_step: 5381, epoch: 135, loss: 0.294016
global_step: 5382, epoch: 135, loss: 0.243505
global_step: 5383, epoch: 135, loss: 0.268038
global_step: 5384, epoch: 135, loss: 0.315261
global_step: 5385, epoch: 135, loss: 0.254206
global_step: 5386, epoch: 135, loss: 0.228396
global_step: 5387, epoch: 135, loss: 0.306061
global_step: 5388, epoch: 135, loss: 0.309986
global_step: 5389, epoch: 135, loss: 0.300865
global_step: 5390, epoch: 135, loss: 0.321051
global_step: 5391, epoch: 135, loss: 0.217931
global_step: 5392, epoch: 135, loss: 0.259362
global_step: 5393, epoch: 135, loss: 0.260512
global_step: 5394, epoch: 135, loss: 0.252353
global_step: 5395, epoch: 135, loss: 0.274216
global_step: 5396, epoch: 135, loss: 0.304762
global_step: 5397, epoch: 135, loss: 0.309527
global_step: 5398, epoch: 135, loss: 0.213233
global_step: 5399, epoch: 135, loss: 0.227769
global_step: 5400, epoch: 135, loss: 0.075350
epoch: 135
train	acc: 0.9682	macro: p 0.9715, r 0.9529, f1: 0.9618	micro: p 0.9682, r 0.9682, f1 0.9682	weighted_f1:0.9682
dev	acc: 0.5338	macro: p 0.4110, r 0.3171, f1: 0.3285	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4932
test	acc: 0.5759	macro: p 0.3837, r 0.3229, f1: 0.3324	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5430
global_step: 5401, epoch: 136, loss: 0.225185
global_step: 5402, epoch: 136, loss: 0.235034
global_step: 5403, epoch: 136, loss: 0.199728
global_step: 5404, epoch: 136, loss: 0.240874
global_step: 5405, epoch: 136, loss: 0.248811
global_step: 5406, epoch: 136, loss: 0.202549
global_step: 5407, epoch: 136, loss: 0.252281
global_step: 5408, epoch: 136, loss: 0.166917
global_step: 5409, epoch: 136, loss: 0.228597
global_step: 5410, epoch: 136, loss: 0.287986
global_step: 5411, epoch: 136, loss: 0.281582
global_step: 5412, epoch: 136, loss: 0.245934
global_step: 5413, epoch: 136, loss: 0.320590
global_step: 5414, epoch: 136, loss: 0.235954
global_step: 5415, epoch: 136, loss: 0.208022
global_step: 5416, epoch: 136, loss: 0.303194
global_step: 5417, epoch: 136, loss: 0.215975
global_step: 5418, epoch: 136, loss: 0.271655
global_step: 5419, epoch: 136, loss: 0.199980
global_step: 5420, epoch: 136, loss: 0.204774
global_step: 5421, epoch: 136, loss: 0.177418
global_step: 5422, epoch: 136, loss: 0.347728
global_step: 5423, epoch: 136, loss: 0.264389
global_step: 5424, epoch: 136, loss: 0.288835
global_step: 5425, epoch: 136, loss: 0.261478
global_step: 5426, epoch: 136, loss: 0.208269
global_step: 5427, epoch: 136, loss: 0.244936
global_step: 5428, epoch: 136, loss: 0.243281
global_step: 5429, epoch: 136, loss: 0.203366
global_step: 5430, epoch: 136, loss: 0.189339
global_step: 5431, epoch: 136, loss: 0.270557
global_step: 5432, epoch: 136, loss: 0.222618
global_step: 5433, epoch: 136, loss: 0.223604
global_step: 5434, epoch: 136, loss: 0.234985
global_step: 5435, epoch: 136, loss: 0.206766
global_step: 5436, epoch: 136, loss: 0.271947
global_step: 5437, epoch: 136, loss: 0.310431
global_step: 5438, epoch: 136, loss: 0.287011
global_step: 5439, epoch: 136, loss: 0.245781
global_step: 5440, epoch: 136, loss: 0.022580
epoch: 136
train	acc: 0.9677	macro: p 0.9712, r 0.9515, f1: 0.9609	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5275	macro: p 0.3515, r 0.3035, f1: 0.3046	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4858
test	acc: 0.5820	macro: p 0.4142, r 0.3296, f1: 0.3385	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5488
global_step: 5441, epoch: 137, loss: 0.230273
global_step: 5442, epoch: 137, loss: 0.235016
global_step: 5443, epoch: 137, loss: 0.247843
global_step: 5444, epoch: 137, loss: 0.216172
global_step: 5445, epoch: 137, loss: 0.242693
global_step: 5446, epoch: 137, loss: 0.243901
global_step: 5447, epoch: 137, loss: 0.211397
global_step: 5448, epoch: 137, loss: 0.218347
global_step: 5449, epoch: 137, loss: 0.233166
global_step: 5450, epoch: 137, loss: 0.235193
global_step: 5451, epoch: 137, loss: 0.236795
global_step: 5452, epoch: 137, loss: 0.241061
global_step: 5453, epoch: 137, loss: 0.184914
global_step: 5454, epoch: 137, loss: 0.198854
global_step: 5455, epoch: 137, loss: 0.139391
global_step: 5456, epoch: 137, loss: 0.209510
global_step: 5457, epoch: 137, loss: 0.295156
global_step: 5458, epoch: 137, loss: 0.284739
global_step: 5459, epoch: 137, loss: 0.267167
global_step: 5460, epoch: 137, loss: 0.197509
global_step: 5461, epoch: 137, loss: 0.297404
global_step: 5462, epoch: 137, loss: 0.257128
global_step: 5463, epoch: 137, loss: 0.191627
global_step: 5464, epoch: 137, loss: 0.219463
global_step: 5465, epoch: 137, loss: 0.184040
global_step: 5466, epoch: 137, loss: 0.195546
global_step: 5467, epoch: 137, loss: 0.367886
global_step: 5468, epoch: 137, loss: 0.242636
global_step: 5469, epoch: 137, loss: 0.267452
global_step: 5470, epoch: 137, loss: 0.247781
global_step: 5471, epoch: 137, loss: 0.211527
global_step: 5472, epoch: 137, loss: 0.305558
global_step: 5473, epoch: 137, loss: 0.269264
global_step: 5474, epoch: 137, loss: 0.191957
global_step: 5475, epoch: 137, loss: 0.371905
global_step: 5476, epoch: 137, loss: 0.217539
global_step: 5477, epoch: 137, loss: 0.245176
global_step: 5478, epoch: 137, loss: 0.326942
global_step: 5479, epoch: 137, loss: 0.252687
global_step: 5480, epoch: 137, loss: 0.042197
epoch: 137
train	acc: 0.9690	macro: p 0.9721, r 0.9547, f1: 0.9631	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5302	macro: p 0.3608, r 0.3078, f1: 0.3113	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4900
test	acc: 0.5774	macro: p 0.3824, r 0.3232, f1: 0.3308	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5448
global_step: 5481, epoch: 138, loss: 0.167656
global_step: 5482, epoch: 138, loss: 0.217533
global_step: 5483, epoch: 138, loss: 0.226933
global_step: 5484, epoch: 138, loss: 0.236886
global_step: 5485, epoch: 138, loss: 0.279261
global_step: 5486, epoch: 138, loss: 0.238736
global_step: 5487, epoch: 138, loss: 0.224957
global_step: 5488, epoch: 138, loss: 0.233275
global_step: 5489, epoch: 138, loss: 0.304540
global_step: 5490, epoch: 138, loss: 0.220168
global_step: 5491, epoch: 138, loss: 0.305234
global_step: 5492, epoch: 138, loss: 0.217415
global_step: 5493, epoch: 138, loss: 0.260760
global_step: 5494, epoch: 138, loss: 0.269986
global_step: 5495, epoch: 138, loss: 0.201969
global_step: 5496, epoch: 138, loss: 0.265615
global_step: 5497, epoch: 138, loss: 0.292165
global_step: 5498, epoch: 138, loss: 0.218763
global_step: 5499, epoch: 138, loss: 0.189451
global_step: 5500, epoch: 138, loss: 0.207039
global_step: 5501, epoch: 138, loss: 0.221405
global_step: 5502, epoch: 138, loss: 0.205539
global_step: 5503, epoch: 138, loss: 0.194210
global_step: 5504, epoch: 138, loss: 0.327603
global_step: 5505, epoch: 138, loss: 0.409274
global_step: 5506, epoch: 138, loss: 0.278999
global_step: 5507, epoch: 138, loss: 0.278891
global_step: 5508, epoch: 138, loss: 0.287658
global_step: 5509, epoch: 138, loss: 0.327744
global_step: 5510, epoch: 138, loss: 0.197454
global_step: 5511, epoch: 138, loss: 0.314237
global_step: 5512, epoch: 138, loss: 0.269482
global_step: 5513, epoch: 138, loss: 0.227381
global_step: 5514, epoch: 138, loss: 0.212905
global_step: 5515, epoch: 138, loss: 0.255541
global_step: 5516, epoch: 138, loss: 0.184966
global_step: 5517, epoch: 138, loss: 0.265824
global_step: 5518, epoch: 138, loss: 0.276797
global_step: 5519, epoch: 138, loss: 0.351391
global_step: 5520, epoch: 138, loss: 0.153153
epoch: 138
train	acc: 0.9681	macro: p 0.9722, r 0.9530, f1: 0.9622	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9681
dev	acc: 0.5365	macro: p 0.4279, r 0.3136, f1: 0.3211	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4933
test	acc: 0.5766	macro: p 0.3833, r 0.3233, f1: 0.3316	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5421
global_step: 5521, epoch: 139, loss: 0.238923
global_step: 5522, epoch: 139, loss: 0.185132
global_step: 5523, epoch: 139, loss: 0.273793
global_step: 5524, epoch: 139, loss: 0.225743
global_step: 5525, epoch: 139, loss: 0.257087
global_step: 5526, epoch: 139, loss: 0.196657
global_step: 5527, epoch: 139, loss: 0.242876
global_step: 5528, epoch: 139, loss: 0.244365
global_step: 5529, epoch: 139, loss: 0.351130
global_step: 5530, epoch: 139, loss: 0.211602
global_step: 5531, epoch: 139, loss: 0.217743
global_step: 5532, epoch: 139, loss: 0.220187
global_step: 5533, epoch: 139, loss: 0.295872
global_step: 5534, epoch: 139, loss: 0.238477
global_step: 5535, epoch: 139, loss: 0.244624
global_step: 5536, epoch: 139, loss: 0.267596
global_step: 5537, epoch: 139, loss: 0.271916
global_step: 5538, epoch: 139, loss: 0.247472
global_step: 5539, epoch: 139, loss: 0.214045
global_step: 5540, epoch: 139, loss: 0.227660
global_step: 5541, epoch: 139, loss: 0.153556
global_step: 5542, epoch: 139, loss: 0.193745
global_step: 5543, epoch: 139, loss: 0.341210
global_step: 5544, epoch: 139, loss: 0.231170
global_step: 5545, epoch: 139, loss: 0.266514
global_step: 5546, epoch: 139, loss: 0.214514
global_step: 5547, epoch: 139, loss: 0.212180
global_step: 5548, epoch: 139, loss: 0.205975
global_step: 5549, epoch: 139, loss: 0.239328
global_step: 5550, epoch: 139, loss: 0.231577
global_step: 5551, epoch: 139, loss: 0.237902
global_step: 5552, epoch: 139, loss: 0.254714
global_step: 5553, epoch: 139, loss: 0.191404
global_step: 5554, epoch: 139, loss: 0.245882
global_step: 5555, epoch: 139, loss: 0.232658
global_step: 5556, epoch: 139, loss: 0.216777
global_step: 5557, epoch: 139, loss: 0.222748
global_step: 5558, epoch: 139, loss: 0.278417
global_step: 5559, epoch: 139, loss: 0.194758
global_step: 5560, epoch: 139, loss: 0.449938
epoch: 139
train	acc: 0.9683	macro: p 0.9719, r 0.9526, f1: 0.9618	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5365	macro: p 0.3670, r 0.3069, f1: 0.3091	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4929
test	acc: 0.5755	macro: p 0.3667, r 0.3149, f1: 0.3207	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5403
global_step: 5561, epoch: 140, loss: 0.276305
global_step: 5562, epoch: 140, loss: 0.237725
global_step: 5563, epoch: 140, loss: 0.176334
global_step: 5564, epoch: 140, loss: 0.199241
global_step: 5565, epoch: 140, loss: 0.214159
global_step: 5566, epoch: 140, loss: 0.210146
global_step: 5567, epoch: 140, loss: 0.235611
global_step: 5568, epoch: 140, loss: 0.244261
global_step: 5569, epoch: 140, loss: 0.267194
global_step: 5570, epoch: 140, loss: 0.228231
global_step: 5571, epoch: 140, loss: 0.219273
global_step: 5572, epoch: 140, loss: 0.231266
global_step: 5573, epoch: 140, loss: 0.215489
global_step: 5574, epoch: 140, loss: 0.248615
global_step: 5575, epoch: 140, loss: 0.247459
global_step: 5576, epoch: 140, loss: 0.255505
global_step: 5577, epoch: 140, loss: 0.263984
global_step: 5578, epoch: 140, loss: 0.245306
global_step: 5579, epoch: 140, loss: 0.274990
global_step: 5580, epoch: 140, loss: 0.213173
global_step: 5581, epoch: 140, loss: 0.248581
global_step: 5582, epoch: 140, loss: 0.268052
global_step: 5583, epoch: 140, loss: 0.221793
global_step: 5584, epoch: 140, loss: 0.235395
global_step: 5585, epoch: 140, loss: 0.211215
global_step: 5586, epoch: 140, loss: 0.215943
global_step: 5587, epoch: 140, loss: 0.231688
global_step: 5588, epoch: 140, loss: 0.252719
global_step: 5589, epoch: 140, loss: 0.241998
global_step: 5590, epoch: 140, loss: 0.235336
global_step: 5591, epoch: 140, loss: 0.297830
global_step: 5592, epoch: 140, loss: 0.340224
global_step: 5593, epoch: 140, loss: 0.183887
global_step: 5594, epoch: 140, loss: 0.247081
global_step: 5595, epoch: 140, loss: 0.200865
global_step: 5596, epoch: 140, loss: 0.274181
global_step: 5597, epoch: 140, loss: 0.279360
global_step: 5598, epoch: 140, loss: 0.222392
global_step: 5599, epoch: 140, loss: 0.232136
global_step: 5600, epoch: 140, loss: 0.007606
epoch: 140
train	acc: 0.9692	macro: p 0.9719, r 0.9549, f1: 0.9631	micro: p 0.9692, r 0.9692, f1 0.9692	weighted_f1:0.9692
dev	acc: 0.5374	macro: p 0.4216, r 0.3112, f1: 0.3190	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4925
test	acc: 0.5774	macro: p 0.3882, r 0.3217, f1: 0.3309	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5428
global_step: 5601, epoch: 141, loss: 0.257403
global_step: 5602, epoch: 141, loss: 0.194077
global_step: 5603, epoch: 141, loss: 0.224197
global_step: 5604, epoch: 141, loss: 0.216346
global_step: 5605, epoch: 141, loss: 0.218160
global_step: 5606, epoch: 141, loss: 0.244234
global_step: 5607, epoch: 141, loss: 0.256693
global_step: 5608, epoch: 141, loss: 0.184077
global_step: 5609, epoch: 141, loss: 0.228654
global_step: 5610, epoch: 141, loss: 0.220455
global_step: 5611, epoch: 141, loss: 0.236175
global_step: 5612, epoch: 141, loss: 0.221538
global_step: 5613, epoch: 141, loss: 0.213919
global_step: 5614, epoch: 141, loss: 0.243458
global_step: 5615, epoch: 141, loss: 0.213998
global_step: 5616, epoch: 141, loss: 0.252928
global_step: 5617, epoch: 141, loss: 0.189801
global_step: 5618, epoch: 141, loss: 0.226925
global_step: 5619, epoch: 141, loss: 0.195302
global_step: 5620, epoch: 141, loss: 0.263278
global_step: 5621, epoch: 141, loss: 0.301121
global_step: 5622, epoch: 141, loss: 0.157101
global_step: 5623, epoch: 141, loss: 0.250104
global_step: 5624, epoch: 141, loss: 0.209540
global_step: 5625, epoch: 141, loss: 0.269071
global_step: 5626, epoch: 141, loss: 0.203259
global_step: 5627, epoch: 141, loss: 0.240403
global_step: 5628, epoch: 141, loss: 0.274017
global_step: 5629, epoch: 141, loss: 0.244618
global_step: 5630, epoch: 141, loss: 0.225858
global_step: 5631, epoch: 141, loss: 0.226448
global_step: 5632, epoch: 141, loss: 0.275132
global_step: 5633, epoch: 141, loss: 0.159924
global_step: 5634, epoch: 141, loss: 0.225249
global_step: 5635, epoch: 141, loss: 0.155216
global_step: 5636, epoch: 141, loss: 0.275020
global_step: 5637, epoch: 141, loss: 0.203804
global_step: 5638, epoch: 141, loss: 0.333942
global_step: 5639, epoch: 141, loss: 0.296071
global_step: 5640, epoch: 141, loss: 0.439499
epoch: 141
train	acc: 0.9677	macro: p 0.9726, r 0.9513, f1: 0.9616	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9676
dev	acc: 0.5329	macro: p 0.4366, r 0.3020, f1: 0.3114	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4818
test	acc: 0.5839	macro: p 0.4052, r 0.3106, f1: 0.3220	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5392
global_step: 5641, epoch: 142, loss: 0.253193
global_step: 5642, epoch: 142, loss: 0.194062
global_step: 5643, epoch: 142, loss: 0.244807
global_step: 5644, epoch: 142, loss: 0.216254
global_step: 5645, epoch: 142, loss: 0.168121
global_step: 5646, epoch: 142, loss: 0.174629
global_step: 5647, epoch: 142, loss: 0.225551
global_step: 5648, epoch: 142, loss: 0.218455
global_step: 5649, epoch: 142, loss: 0.211463
global_step: 5650, epoch: 142, loss: 0.328795
global_step: 5651, epoch: 142, loss: 0.219961
global_step: 5652, epoch: 142, loss: 0.222193
global_step: 5653, epoch: 142, loss: 0.241834
global_step: 5654, epoch: 142, loss: 0.243531
global_step: 5655, epoch: 142, loss: 0.240535
global_step: 5656, epoch: 142, loss: 0.178705
global_step: 5657, epoch: 142, loss: 0.282943
global_step: 5658, epoch: 142, loss: 0.195721
global_step: 5659, epoch: 142, loss: 0.251014
global_step: 5660, epoch: 142, loss: 0.292340
global_step: 5661, epoch: 142, loss: 0.290638
global_step: 5662, epoch: 142, loss: 0.250752
global_step: 5663, epoch: 142, loss: 0.197860
global_step: 5664, epoch: 142, loss: 0.272592
global_step: 5665, epoch: 142, loss: 0.221373
global_step: 5666, epoch: 142, loss: 0.231185
global_step: 5667, epoch: 142, loss: 0.229602
global_step: 5668, epoch: 142, loss: 0.169180
global_step: 5669, epoch: 142, loss: 0.192524
global_step: 5670, epoch: 142, loss: 0.213692
global_step: 5671, epoch: 142, loss: 0.233055
global_step: 5672, epoch: 142, loss: 0.290303
global_step: 5673, epoch: 142, loss: 0.210493
global_step: 5674, epoch: 142, loss: 0.272346
global_step: 5675, epoch: 142, loss: 0.284575
global_step: 5676, epoch: 142, loss: 0.215903
global_step: 5677, epoch: 142, loss: 0.243054
global_step: 5678, epoch: 142, loss: 0.240478
global_step: 5679, epoch: 142, loss: 0.216112
global_step: 5680, epoch: 142, loss: 0.080878
epoch: 142
train	acc: 0.9683	macro: p 0.9724, r 0.9532, f1: 0.9625	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5293	macro: p 0.4125, r 0.2989, f1: 0.3025	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4787
test	acc: 0.5751	macro: p 0.3874, r 0.3072, f1: 0.3148	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5330
global_step: 5681, epoch: 143, loss: 0.170574
global_step: 5682, epoch: 143, loss: 0.186966
global_step: 5683, epoch: 143, loss: 0.199976
global_step: 5684, epoch: 143, loss: 0.262721
global_step: 5685, epoch: 143, loss: 0.238326
global_step: 5686, epoch: 143, loss: 0.210439
global_step: 5687, epoch: 143, loss: 0.164688
global_step: 5688, epoch: 143, loss: 0.305835
global_step: 5689, epoch: 143, loss: 0.150127
global_step: 5690, epoch: 143, loss: 0.267871
global_step: 5691, epoch: 143, loss: 0.191176
global_step: 5692, epoch: 143, loss: 0.286998
global_step: 5693, epoch: 143, loss: 0.177619
global_step: 5694, epoch: 143, loss: 0.287470
global_step: 5695, epoch: 143, loss: 0.244918
global_step: 5696, epoch: 143, loss: 0.190168
global_step: 5697, epoch: 143, loss: 0.165102
global_step: 5698, epoch: 143, loss: 0.225159
global_step: 5699, epoch: 143, loss: 0.286817
global_step: 5700, epoch: 143, loss: 0.232295
global_step: 5701, epoch: 143, loss: 0.259771
global_step: 5702, epoch: 143, loss: 0.294544
global_step: 5703, epoch: 143, loss: 0.245166
global_step: 5704, epoch: 143, loss: 0.230511
global_step: 5705, epoch: 143, loss: 0.191941
global_step: 5706, epoch: 143, loss: 0.223852
global_step: 5707, epoch: 143, loss: 0.279769
global_step: 5708, epoch: 143, loss: 0.184797
global_step: 5709, epoch: 143, loss: 0.211454
global_step: 5710, epoch: 143, loss: 0.209488
global_step: 5711, epoch: 143, loss: 0.261071
global_step: 5712, epoch: 143, loss: 0.241507
global_step: 5713, epoch: 143, loss: 0.220558
global_step: 5714, epoch: 143, loss: 0.263143
global_step: 5715, epoch: 143, loss: 0.305047
global_step: 5716, epoch: 143, loss: 0.285881
global_step: 5717, epoch: 143, loss: 0.255759
global_step: 5718, epoch: 143, loss: 0.253515
global_step: 5719, epoch: 143, loss: 0.269219
global_step: 5720, epoch: 143, loss: 0.745113
epoch: 143
train	acc: 0.9685	macro: p 0.9722, r 0.9542, f1: 0.9629	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5365	macro: p 0.5030, r 0.3135, f1: 0.3267	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4863
test	acc: 0.5805	macro: p 0.3820, r 0.3129, f1: 0.3207	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5379
global_step: 5721, epoch: 144, loss: 0.270636
global_step: 5722, epoch: 144, loss: 0.174190
global_step: 5723, epoch: 144, loss: 0.186087
global_step: 5724, epoch: 144, loss: 0.221867
global_step: 5725, epoch: 144, loss: 0.250878
global_step: 5726, epoch: 144, loss: 0.274090
global_step: 5727, epoch: 144, loss: 0.181631
global_step: 5728, epoch: 144, loss: 0.211009
global_step: 5729, epoch: 144, loss: 0.218801
global_step: 5730, epoch: 144, loss: 0.240689
global_step: 5731, epoch: 144, loss: 0.311603
global_step: 5732, epoch: 144, loss: 0.210800
global_step: 5733, epoch: 144, loss: 0.304147
global_step: 5734, epoch: 144, loss: 0.252698
global_step: 5735, epoch: 144, loss: 0.275912
global_step: 5736, epoch: 144, loss: 0.256722
global_step: 5737, epoch: 144, loss: 0.166077
global_step: 5738, epoch: 144, loss: 0.221377
global_step: 5739, epoch: 144, loss: 0.221104
global_step: 5740, epoch: 144, loss: 0.186330
global_step: 5741, epoch: 144, loss: 0.188141
global_step: 5742, epoch: 144, loss: 0.222438
global_step: 5743, epoch: 144, loss: 0.219966
global_step: 5744, epoch: 144, loss: 0.261981
global_step: 5745, epoch: 144, loss: 0.229753
global_step: 5746, epoch: 144, loss: 0.218546
global_step: 5747, epoch: 144, loss: 0.266447
global_step: 5748, epoch: 144, loss: 0.239428
global_step: 5749, epoch: 144, loss: 0.213773
global_step: 5750, epoch: 144, loss: 0.248624
global_step: 5751, epoch: 144, loss: 0.212776
global_step: 5752, epoch: 144, loss: 0.229872
global_step: 5753, epoch: 144, loss: 0.212858
global_step: 5754, epoch: 144, loss: 0.227517
global_step: 5755, epoch: 144, loss: 0.328295
global_step: 5756, epoch: 144, loss: 0.274029
global_step: 5757, epoch: 144, loss: 0.249399
global_step: 5758, epoch: 144, loss: 0.280594
global_step: 5759, epoch: 144, loss: 0.250558
global_step: 5760, epoch: 144, loss: 0.187633
epoch: 144
train	acc: 0.9688	macro: p 0.9731, r 0.9535, f1: 0.9629	micro: p 0.9688, r 0.9688, f1 0.9688	weighted_f1:0.9688
dev	acc: 0.5338	macro: p 0.3913, r 0.3141, f1: 0.3189	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4886
test	acc: 0.5720	macro: p 0.3827, r 0.3197, f1: 0.3269	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5371
global_step: 5761, epoch: 145, loss: 0.212973
global_step: 5762, epoch: 145, loss: 0.182911
global_step: 5763, epoch: 145, loss: 0.232309
global_step: 5764, epoch: 145, loss: 0.161415
global_step: 5765, epoch: 145, loss: 0.187527
global_step: 5766, epoch: 145, loss: 0.283890
global_step: 5767, epoch: 145, loss: 0.205498
global_step: 5768, epoch: 145, loss: 0.252077
global_step: 5769, epoch: 145, loss: 0.214635
global_step: 5770, epoch: 145, loss: 0.271983
global_step: 5771, epoch: 145, loss: 0.209223
global_step: 5772, epoch: 145, loss: 0.278279
global_step: 5773, epoch: 145, loss: 0.258136
global_step: 5774, epoch: 145, loss: 0.186645
global_step: 5775, epoch: 145, loss: 0.158656
global_step: 5776, epoch: 145, loss: 0.221671
global_step: 5777, epoch: 145, loss: 0.230512
global_step: 5778, epoch: 145, loss: 0.223205
global_step: 5779, epoch: 145, loss: 0.289736
global_step: 5780, epoch: 145, loss: 0.213069
global_step: 5781, epoch: 145, loss: 0.208773
global_step: 5782, epoch: 145, loss: 0.194726
global_step: 5783, epoch: 145, loss: 0.201142
global_step: 5784, epoch: 145, loss: 0.253124
global_step: 5785, epoch: 145, loss: 0.270422
global_step: 5786, epoch: 145, loss: 0.173946
global_step: 5787, epoch: 145, loss: 0.238292
global_step: 5788, epoch: 145, loss: 0.191407
global_step: 5789, epoch: 145, loss: 0.193295
global_step: 5790, epoch: 145, loss: 0.215761
global_step: 5791, epoch: 145, loss: 0.325468
global_step: 5792, epoch: 145, loss: 0.183177
global_step: 5793, epoch: 145, loss: 0.262073
global_step: 5794, epoch: 145, loss: 0.219997
global_step: 5795, epoch: 145, loss: 0.259340
global_step: 5796, epoch: 145, loss: 0.259815
global_step: 5797, epoch: 145, loss: 0.271844
global_step: 5798, epoch: 145, loss: 0.254272
global_step: 5799, epoch: 145, loss: 0.235319
global_step: 5800, epoch: 145, loss: 0.205625
epoch: 145
train	acc: 0.9691	macro: p 0.9721, r 0.9548, f1: 0.9631	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5293	macro: p 0.3820, r 0.3110, f1: 0.3156	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4891
test	acc: 0.5686	macro: p 0.3735, r 0.3202, f1: 0.3278	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5386
global_step: 5801, epoch: 146, loss: 0.159460
global_step: 5802, epoch: 146, loss: 0.194562
global_step: 5803, epoch: 146, loss: 0.217818
global_step: 5804, epoch: 146, loss: 0.179230
global_step: 5805, epoch: 146, loss: 0.318223
global_step: 5806, epoch: 146, loss: 0.243189
global_step: 5807, epoch: 146, loss: 0.270824
global_step: 5808, epoch: 146, loss: 0.262169
global_step: 5809, epoch: 146, loss: 0.221463
global_step: 5810, epoch: 146, loss: 0.240920
global_step: 5811, epoch: 146, loss: 0.218387
global_step: 5812, epoch: 146, loss: 0.241270
global_step: 5813, epoch: 146, loss: 0.220866
global_step: 5814, epoch: 146, loss: 0.225551
global_step: 5815, epoch: 146, loss: 0.197700
global_step: 5816, epoch: 146, loss: 0.215815
global_step: 5817, epoch: 146, loss: 0.159600
global_step: 5818, epoch: 146, loss: 0.184316
global_step: 5819, epoch: 146, loss: 0.228766
global_step: 5820, epoch: 146, loss: 0.213382
global_step: 5821, epoch: 146, loss: 0.229243
global_step: 5822, epoch: 146, loss: 0.192267
global_step: 5823, epoch: 146, loss: 0.189465
global_step: 5824, epoch: 146, loss: 0.252768
global_step: 5825, epoch: 146, loss: 0.189681
global_step: 5826, epoch: 146, loss: 0.245196
global_step: 5827, epoch: 146, loss: 0.216761
global_step: 5828, epoch: 146, loss: 0.242692
global_step: 5829, epoch: 146, loss: 0.323363
global_step: 5830, epoch: 146, loss: 0.261730
global_step: 5831, epoch: 146, loss: 0.208462
global_step: 5832, epoch: 146, loss: 0.239443
global_step: 5833, epoch: 146, loss: 0.317343
global_step: 5834, epoch: 146, loss: 0.295408
global_step: 5835, epoch: 146, loss: 0.200276
global_step: 5836, epoch: 146, loss: 0.182106
global_step: 5837, epoch: 146, loss: 0.212688
global_step: 5838, epoch: 146, loss: 0.199327
global_step: 5839, epoch: 146, loss: 0.257428
global_step: 5840, epoch: 146, loss: 0.123563
epoch: 146
train	acc: 0.9698	macro: p 0.9720, r 0.9560, f1: 0.9637	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5329	macro: p 0.4196, r 0.3193, f1: 0.3306	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4911
test	acc: 0.5751	macro: p 0.3777, r 0.3242, f1: 0.3323	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5426
global_step: 5841, epoch: 147, loss: 0.179659
global_step: 5842, epoch: 147, loss: 0.246289
global_step: 5843, epoch: 147, loss: 0.243954
global_step: 5844, epoch: 147, loss: 0.175369
global_step: 5845, epoch: 147, loss: 0.169092
global_step: 5846, epoch: 147, loss: 0.278621
global_step: 5847, epoch: 147, loss: 0.209567
global_step: 5848, epoch: 147, loss: 0.153765
global_step: 5849, epoch: 147, loss: 0.204388
global_step: 5850, epoch: 147, loss: 0.184547
global_step: 5851, epoch: 147, loss: 0.214655
global_step: 5852, epoch: 147, loss: 0.275607
global_step: 5853, epoch: 147, loss: 0.253604
global_step: 5854, epoch: 147, loss: 0.224017
global_step: 5855, epoch: 147, loss: 0.266573
global_step: 5856, epoch: 147, loss: 0.165785
global_step: 5857, epoch: 147, loss: 0.190339
global_step: 5858, epoch: 147, loss: 0.184201
global_step: 5859, epoch: 147, loss: 0.197525
global_step: 5860, epoch: 147, loss: 0.178857
global_step: 5861, epoch: 147, loss: 0.236628
global_step: 5862, epoch: 147, loss: 0.199051
global_step: 5863, epoch: 147, loss: 0.233136
global_step: 5864, epoch: 147, loss: 0.285781
global_step: 5865, epoch: 147, loss: 0.253630
global_step: 5866, epoch: 147, loss: 0.334800
global_step: 5867, epoch: 147, loss: 0.192462
global_step: 5868, epoch: 147, loss: 0.287072
global_step: 5869, epoch: 147, loss: 0.233492
global_step: 5870, epoch: 147, loss: 0.247239
global_step: 5871, epoch: 147, loss: 0.196968
global_step: 5872, epoch: 147, loss: 0.200851
global_step: 5873, epoch: 147, loss: 0.221528
global_step: 5874, epoch: 147, loss: 0.233177
global_step: 5875, epoch: 147, loss: 0.220752
global_step: 5876, epoch: 147, loss: 0.203347
global_step: 5877, epoch: 147, loss: 0.261655
global_step: 5878, epoch: 147, loss: 0.203453
global_step: 5879, epoch: 147, loss: 0.242019
global_step: 5880, epoch: 147, loss: 0.085503
epoch: 147
train	acc: 0.9706	macro: p 0.9728, r 0.9577, f1: 0.9649	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5266	macro: p 0.3925, r 0.3090, f1: 0.3183	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4828
test	acc: 0.5808	macro: p 0.4072, r 0.3287, f1: 0.3389	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5464
global_step: 5881, epoch: 148, loss: 0.284682
global_step: 5882, epoch: 148, loss: 0.168047
global_step: 5883, epoch: 148, loss: 0.244015
global_step: 5884, epoch: 148, loss: 0.207151
global_step: 5885, epoch: 148, loss: 0.163537
global_step: 5886, epoch: 148, loss: 0.278729
global_step: 5887, epoch: 148, loss: 0.121948
global_step: 5888, epoch: 148, loss: 0.189352
global_step: 5889, epoch: 148, loss: 0.219755
global_step: 5890, epoch: 148, loss: 0.215060
global_step: 5891, epoch: 148, loss: 0.212145
global_step: 5892, epoch: 148, loss: 0.299682
global_step: 5893, epoch: 148, loss: 0.300084
global_step: 5894, epoch: 148, loss: 0.233611
global_step: 5895, epoch: 148, loss: 0.182197
global_step: 5896, epoch: 148, loss: 0.199516
global_step: 5897, epoch: 148, loss: 0.223814
global_step: 5898, epoch: 148, loss: 0.236251
global_step: 5899, epoch: 148, loss: 0.220197
global_step: 5900, epoch: 148, loss: 0.239574
global_step: 5901, epoch: 148, loss: 0.274710
global_step: 5902, epoch: 148, loss: 0.228603
global_step: 5903, epoch: 148, loss: 0.260317
global_step: 5904, epoch: 148, loss: 0.186406
global_step: 5905, epoch: 148, loss: 0.202553
global_step: 5906, epoch: 148, loss: 0.165781
global_step: 5907, epoch: 148, loss: 0.275822
global_step: 5908, epoch: 148, loss: 0.179786
global_step: 5909, epoch: 148, loss: 0.233828
global_step: 5910, epoch: 148, loss: 0.255028
global_step: 5911, epoch: 148, loss: 0.193603
global_step: 5912, epoch: 148, loss: 0.205025
global_step: 5913, epoch: 148, loss: 0.216240
global_step: 5914, epoch: 148, loss: 0.297705
global_step: 5915, epoch: 148, loss: 0.216017
global_step: 5916, epoch: 148, loss: 0.207397
global_step: 5917, epoch: 148, loss: 0.202346
global_step: 5918, epoch: 148, loss: 0.188771
global_step: 5919, epoch: 148, loss: 0.219012
global_step: 5920, epoch: 148, loss: 0.040871
epoch: 148
train	acc: 0.9700	macro: p 0.9733, r 0.9569, f1: 0.9647	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5311	macro: p 0.3916, r 0.3041, f1: 0.3076	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4824
test	acc: 0.5785	macro: p 0.3812, r 0.3187, f1: 0.3245	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5421
global_step: 5921, epoch: 149, loss: 0.209064
global_step: 5922, epoch: 149, loss: 0.240005
global_step: 5923, epoch: 149, loss: 0.139209
global_step: 5924, epoch: 149, loss: 0.245362
global_step: 5925, epoch: 149, loss: 0.229251
global_step: 5926, epoch: 149, loss: 0.191280
global_step: 5927, epoch: 149, loss: 0.226015
global_step: 5928, epoch: 149, loss: 0.197993
global_step: 5929, epoch: 149, loss: 0.203972
global_step: 5930, epoch: 149, loss: 0.226394
global_step: 5931, epoch: 149, loss: 0.291385
global_step: 5932, epoch: 149, loss: 0.160430
global_step: 5933, epoch: 149, loss: 0.222509
global_step: 5934, epoch: 149, loss: 0.244189
global_step: 5935, epoch: 149, loss: 0.216531
global_step: 5936, epoch: 149, loss: 0.202075
global_step: 5937, epoch: 149, loss: 0.228860
global_step: 5938, epoch: 149, loss: 0.171220
global_step: 5939, epoch: 149, loss: 0.233692
global_step: 5940, epoch: 149, loss: 0.271969
global_step: 5941, epoch: 149, loss: 0.191495
global_step: 5942, epoch: 149, loss: 0.204196
global_step: 5943, epoch: 149, loss: 0.303896
global_step: 5944, epoch: 149, loss: 0.277573
global_step: 5945, epoch: 149, loss: 0.182158
global_step: 5946, epoch: 149, loss: 0.199498
global_step: 5947, epoch: 149, loss: 0.210804
global_step: 5948, epoch: 149, loss: 0.223013
global_step: 5949, epoch: 149, loss: 0.243227
global_step: 5950, epoch: 149, loss: 0.149766
global_step: 5951, epoch: 149, loss: 0.190417
global_step: 5952, epoch: 149, loss: 0.216584
global_step: 5953, epoch: 149, loss: 0.206469
global_step: 5954, epoch: 149, loss: 0.273062
global_step: 5955, epoch: 149, loss: 0.243310
global_step: 5956, epoch: 149, loss: 0.227669
global_step: 5957, epoch: 149, loss: 0.201319
global_step: 5958, epoch: 149, loss: 0.240250
global_step: 5959, epoch: 149, loss: 0.253575
global_step: 5960, epoch: 149, loss: 0.117083
epoch: 149
train	acc: 0.9699	macro: p 0.9728, r 0.9559, f1: 0.9640	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5293	macro: p 0.3998, r 0.3083, f1: 0.3112	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4870
test	acc: 0.5736	macro: p 0.3888, r 0.3227, f1: 0.3314	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5416
global_step: 5961, epoch: 150, loss: 0.280528
global_step: 5962, epoch: 150, loss: 0.222783
global_step: 5963, epoch: 150, loss: 0.208689
global_step: 5964, epoch: 150, loss: 0.168652
global_step: 5965, epoch: 150, loss: 0.273811
global_step: 5966, epoch: 150, loss: 0.172953
global_step: 5967, epoch: 150, loss: 0.155678
global_step: 5968, epoch: 150, loss: 0.216811
global_step: 5969, epoch: 150, loss: 0.237689
global_step: 5970, epoch: 150, loss: 0.209074
global_step: 5971, epoch: 150, loss: 0.282013
global_step: 5972, epoch: 150, loss: 0.208811
global_step: 5973, epoch: 150, loss: 0.221204
global_step: 5974, epoch: 150, loss: 0.240772
global_step: 5975, epoch: 150, loss: 0.257244
global_step: 5976, epoch: 150, loss: 0.225663
global_step: 5977, epoch: 150, loss: 0.228484
global_step: 5978, epoch: 150, loss: 0.197288
global_step: 5979, epoch: 150, loss: 0.197676
global_step: 5980, epoch: 150, loss: 0.330829
global_step: 5981, epoch: 150, loss: 0.260984
global_step: 5982, epoch: 150, loss: 0.159380
global_step: 5983, epoch: 150, loss: 0.168546
global_step: 5984, epoch: 150, loss: 0.243559
global_step: 5985, epoch: 150, loss: 0.238321
global_step: 5986, epoch: 150, loss: 0.240157
global_step: 5987, epoch: 150, loss: 0.193885
global_step: 5988, epoch: 150, loss: 0.221149
global_step: 5989, epoch: 150, loss: 0.216858
global_step: 5990, epoch: 150, loss: 0.234350
global_step: 5991, epoch: 150, loss: 0.185339
global_step: 5992, epoch: 150, loss: 0.237549
global_step: 5993, epoch: 150, loss: 0.217116
global_step: 5994, epoch: 150, loss: 0.138292
global_step: 5995, epoch: 150, loss: 0.253328
global_step: 5996, epoch: 150, loss: 0.221032
global_step: 5997, epoch: 150, loss: 0.160470
global_step: 5998, epoch: 150, loss: 0.260695
global_step: 5999, epoch: 150, loss: 0.275407
global_step: 6000, epoch: 150, loss: 0.062645
epoch: 150
train	acc: 0.9703	macro: p 0.9739, r 0.9560, f1: 0.9646	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5338	macro: p 0.4346, r 0.3088, f1: 0.3181	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4841
test	acc: 0.5824	macro: p 0.4059, r 0.3182, f1: 0.3304	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5417
global_step: 6001, epoch: 151, loss: 0.259962
global_step: 6002, epoch: 151, loss: 0.188295
global_step: 6003, epoch: 151, loss: 0.217825
global_step: 6004, epoch: 151, loss: 0.219292
global_step: 6005, epoch: 151, loss: 0.259360
global_step: 6006, epoch: 151, loss: 0.262844
global_step: 6007, epoch: 151, loss: 0.214494
global_step: 6008, epoch: 151, loss: 0.216548
global_step: 6009, epoch: 151, loss: 0.262557
global_step: 6010, epoch: 151, loss: 0.218830
global_step: 6011, epoch: 151, loss: 0.194247
global_step: 6012, epoch: 151, loss: 0.266139
global_step: 6013, epoch: 151, loss: 0.183300
global_step: 6014, epoch: 151, loss: 0.218055
global_step: 6015, epoch: 151, loss: 0.221289
global_step: 6016, epoch: 151, loss: 0.224104
global_step: 6017, epoch: 151, loss: 0.233332
global_step: 6018, epoch: 151, loss: 0.227772
global_step: 6019, epoch: 151, loss: 0.199424
global_step: 6020, epoch: 151, loss: 0.227534
global_step: 6021, epoch: 151, loss: 0.221706
global_step: 6022, epoch: 151, loss: 0.208391
global_step: 6023, epoch: 151, loss: 0.240201
global_step: 6024, epoch: 151, loss: 0.159674
global_step: 6025, epoch: 151, loss: 0.251070
global_step: 6026, epoch: 151, loss: 0.222974
global_step: 6027, epoch: 151, loss: 0.225791
global_step: 6028, epoch: 151, loss: 0.251611
global_step: 6029, epoch: 151, loss: 0.236934
global_step: 6030, epoch: 151, loss: 0.233267
global_step: 6031, epoch: 151, loss: 0.182752
global_step: 6032, epoch: 151, loss: 0.215019
global_step: 6033, epoch: 151, loss: 0.200772
global_step: 6034, epoch: 151, loss: 0.211959
global_step: 6035, epoch: 151, loss: 0.185567
global_step: 6036, epoch: 151, loss: 0.259103
global_step: 6037, epoch: 151, loss: 0.192674
global_step: 6038, epoch: 151, loss: 0.254948
global_step: 6039, epoch: 151, loss: 0.196721
global_step: 6040, epoch: 151, loss: 1.134814
epoch: 151
train	acc: 0.9694	macro: p 0.9727, r 0.9554, f1: 0.9637	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5347	macro: p 0.4946, r 0.3168, f1: 0.3237	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4929
test	acc: 0.5743	macro: p 0.4032, r 0.3275, f1: 0.3358	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5428
global_step: 6041, epoch: 152, loss: 0.183868
global_step: 6042, epoch: 152, loss: 0.169344
global_step: 6043, epoch: 152, loss: 0.268240
global_step: 6044, epoch: 152, loss: 0.210654
global_step: 6045, epoch: 152, loss: 0.157719
global_step: 6046, epoch: 152, loss: 0.254250
global_step: 6047, epoch: 152, loss: 0.216364
global_step: 6048, epoch: 152, loss: 0.169305
global_step: 6049, epoch: 152, loss: 0.201008
global_step: 6050, epoch: 152, loss: 0.132117
global_step: 6051, epoch: 152, loss: 0.195481
global_step: 6052, epoch: 152, loss: 0.209194
global_step: 6053, epoch: 152, loss: 0.177822
global_step: 6054, epoch: 152, loss: 0.250303
global_step: 6055, epoch: 152, loss: 0.216521
global_step: 6056, epoch: 152, loss: 0.206301
global_step: 6057, epoch: 152, loss: 0.283819
global_step: 6058, epoch: 152, loss: 0.189542
global_step: 6059, epoch: 152, loss: 0.215600
global_step: 6060, epoch: 152, loss: 0.200477
global_step: 6061, epoch: 152, loss: 0.211973
global_step: 6062, epoch: 152, loss: 0.211041
global_step: 6063, epoch: 152, loss: 0.221312
global_step: 6064, epoch: 152, loss: 0.173386
global_step: 6065, epoch: 152, loss: 0.198050
global_step: 6066, epoch: 152, loss: 0.240280
global_step: 6067, epoch: 152, loss: 0.215146
global_step: 6068, epoch: 152, loss: 0.300705
global_step: 6069, epoch: 152, loss: 0.235391
global_step: 6070, epoch: 152, loss: 0.210758
global_step: 6071, epoch: 152, loss: 0.162282
global_step: 6072, epoch: 152, loss: 0.212347
global_step: 6073, epoch: 152, loss: 0.224096
global_step: 6074, epoch: 152, loss: 0.259268
global_step: 6075, epoch: 152, loss: 0.208090
global_step: 6076, epoch: 152, loss: 0.160252
global_step: 6077, epoch: 152, loss: 0.210324
global_step: 6078, epoch: 152, loss: 0.313295
global_step: 6079, epoch: 152, loss: 0.195572
global_step: 6080, epoch: 152, loss: 0.374453
epoch: 152
train	acc: 0.9705	macro: p 0.9740, r 0.9562, f1: 0.9647	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5302	macro: p 0.4231, r 0.3114, f1: 0.3165	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4878
test	acc: 0.5755	macro: p 0.3942, r 0.3210, f1: 0.3281	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5416
global_step: 6081, epoch: 153, loss: 0.169699
global_step: 6082, epoch: 153, loss: 0.146528
global_step: 6083, epoch: 153, loss: 0.210539
global_step: 6084, epoch: 153, loss: 0.231575
global_step: 6085, epoch: 153, loss: 0.222370
global_step: 6086, epoch: 153, loss: 0.236194
global_step: 6087, epoch: 153, loss: 0.218240
global_step: 6088, epoch: 153, loss: 0.234795
global_step: 6089, epoch: 153, loss: 0.182780
global_step: 6090, epoch: 153, loss: 0.254590
global_step: 6091, epoch: 153, loss: 0.204972
global_step: 6092, epoch: 153, loss: 0.180526
global_step: 6093, epoch: 153, loss: 0.252793
global_step: 6094, epoch: 153, loss: 0.202697
global_step: 6095, epoch: 153, loss: 0.233305
global_step: 6096, epoch: 153, loss: 0.218287
global_step: 6097, epoch: 153, loss: 0.181036
global_step: 6098, epoch: 153, loss: 0.268366
global_step: 6099, epoch: 153, loss: 0.220286
global_step: 6100, epoch: 153, loss: 0.246438
global_step: 6101, epoch: 153, loss: 0.229722
global_step: 6102, epoch: 153, loss: 0.159961
global_step: 6103, epoch: 153, loss: 0.154866
global_step: 6104, epoch: 153, loss: 0.251955
global_step: 6105, epoch: 153, loss: 0.226426
global_step: 6106, epoch: 153, loss: 0.232560
global_step: 6107, epoch: 153, loss: 0.245402
global_step: 6108, epoch: 153, loss: 0.219190
global_step: 6109, epoch: 153, loss: 0.249083
global_step: 6110, epoch: 153, loss: 0.183039
global_step: 6111, epoch: 153, loss: 0.323500
global_step: 6112, epoch: 153, loss: 0.169637
global_step: 6113, epoch: 153, loss: 0.259983
global_step: 6114, epoch: 153, loss: 0.218353
global_step: 6115, epoch: 153, loss: 0.210294
global_step: 6116, epoch: 153, loss: 0.240327
global_step: 6117, epoch: 153, loss: 0.249720
global_step: 6118, epoch: 153, loss: 0.274961
global_step: 6119, epoch: 153, loss: 0.243750
global_step: 6120, epoch: 153, loss: 0.035718
epoch: 153
train	acc: 0.9695	macro: p 0.9731, r 0.9564, f1: 0.9644	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5392	macro: p 0.5117, r 0.3166, f1: 0.3249	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4935
test	acc: 0.5759	macro: p 0.4032, r 0.3134, f1: 0.3219	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5370
global_step: 6121, epoch: 154, loss: 0.167165
global_step: 6122, epoch: 154, loss: 0.194616
global_step: 6123, epoch: 154, loss: 0.223116
global_step: 6124, epoch: 154, loss: 0.261534
global_step: 6125, epoch: 154, loss: 0.221408
global_step: 6126, epoch: 154, loss: 0.243526
global_step: 6127, epoch: 154, loss: 0.271423
global_step: 6128, epoch: 154, loss: 0.146330
global_step: 6129, epoch: 154, loss: 0.232641
global_step: 6130, epoch: 154, loss: 0.265037
global_step: 6131, epoch: 154, loss: 0.232629
global_step: 6132, epoch: 154, loss: 0.200485
global_step: 6133, epoch: 154, loss: 0.209511
global_step: 6134, epoch: 154, loss: 0.193687
global_step: 6135, epoch: 154, loss: 0.214783
global_step: 6136, epoch: 154, loss: 0.167976
global_step: 6137, epoch: 154, loss: 0.169537
global_step: 6138, epoch: 154, loss: 0.196892
global_step: 6139, epoch: 154, loss: 0.194088
global_step: 6140, epoch: 154, loss: 0.275905
global_step: 6141, epoch: 154, loss: 0.201477
global_step: 6142, epoch: 154, loss: 0.157291
global_step: 6143, epoch: 154, loss: 0.267848
global_step: 6144, epoch: 154, loss: 0.295642
global_step: 6145, epoch: 154, loss: 0.221910
global_step: 6146, epoch: 154, loss: 0.226999
global_step: 6147, epoch: 154, loss: 0.237261
global_step: 6148, epoch: 154, loss: 0.204223
global_step: 6149, epoch: 154, loss: 0.210881
global_step: 6150, epoch: 154, loss: 0.255172
global_step: 6151, epoch: 154, loss: 0.223652
global_step: 6152, epoch: 154, loss: 0.237817
global_step: 6153, epoch: 154, loss: 0.251130
global_step: 6154, epoch: 154, loss: 0.205864
global_step: 6155, epoch: 154, loss: 0.206428
global_step: 6156, epoch: 154, loss: 0.167779
global_step: 6157, epoch: 154, loss: 0.294600
global_step: 6158, epoch: 154, loss: 0.176676
global_step: 6159, epoch: 154, loss: 0.130456
global_step: 6160, epoch: 154, loss: 0.046999
epoch: 154
train	acc: 0.9705	macro: p 0.9737, r 0.9570, f1: 0.9650	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5266	macro: p 0.4266, r 0.3033, f1: 0.3109	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4783
test	acc: 0.5839	macro: p 0.4279, r 0.3205, f1: 0.3312	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5436
global_step: 6161, epoch: 155, loss: 0.205189
global_step: 6162, epoch: 155, loss: 0.145672
global_step: 6163, epoch: 155, loss: 0.202250
global_step: 6164, epoch: 155, loss: 0.226721
global_step: 6165, epoch: 155, loss: 0.271918
global_step: 6166, epoch: 155, loss: 0.185697
global_step: 6167, epoch: 155, loss: 0.201788
global_step: 6168, epoch: 155, loss: 0.216908
global_step: 6169, epoch: 155, loss: 0.272739
global_step: 6170, epoch: 155, loss: 0.235449
global_step: 6171, epoch: 155, loss: 0.208846
global_step: 6172, epoch: 155, loss: 0.239611
global_step: 6173, epoch: 155, loss: 0.165486
global_step: 6174, epoch: 155, loss: 0.254770
global_step: 6175, epoch: 155, loss: 0.231479
global_step: 6176, epoch: 155, loss: 0.217270
global_step: 6177, epoch: 155, loss: 0.194772
global_step: 6178, epoch: 155, loss: 0.225574
global_step: 6179, epoch: 155, loss: 0.220268
global_step: 6180, epoch: 155, loss: 0.267756
global_step: 6181, epoch: 155, loss: 0.172147
global_step: 6182, epoch: 155, loss: 0.228414
global_step: 6183, epoch: 155, loss: 0.222870
global_step: 6184, epoch: 155, loss: 0.222035
global_step: 6185, epoch: 155, loss: 0.247541
global_step: 6186, epoch: 155, loss: 0.222398
global_step: 6187, epoch: 155, loss: 0.165887
global_step: 6188, epoch: 155, loss: 0.177422
global_step: 6189, epoch: 155, loss: 0.255182
global_step: 6190, epoch: 155, loss: 0.255272
global_step: 6191, epoch: 155, loss: 0.233797
global_step: 6192, epoch: 155, loss: 0.173613
global_step: 6193, epoch: 155, loss: 0.333583
global_step: 6194, epoch: 155, loss: 0.217846
global_step: 6195, epoch: 155, loss: 0.219845
global_step: 6196, epoch: 155, loss: 0.256208
global_step: 6197, epoch: 155, loss: 0.273021
global_step: 6198, epoch: 155, loss: 0.230458
global_step: 6199, epoch: 155, loss: 0.230014
global_step: 6200, epoch: 155, loss: 0.002542
epoch: 155
train	acc: 0.9700	macro: p 0.9735, r 0.9556, f1: 0.9642	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5257	macro: p 0.3300, r 0.2920, f1: 0.2912	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4765
test	acc: 0.5812	macro: p 0.4111, r 0.3197, f1: 0.3312	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5417
global_step: 6201, epoch: 156, loss: 0.269967
global_step: 6202, epoch: 156, loss: 0.169199
global_step: 6203, epoch: 156, loss: 0.179223
global_step: 6204, epoch: 156, loss: 0.225424
global_step: 6205, epoch: 156, loss: 0.166353
global_step: 6206, epoch: 156, loss: 0.238926
global_step: 6207, epoch: 156, loss: 0.226107
global_step: 6208, epoch: 156, loss: 0.185801
global_step: 6209, epoch: 156, loss: 0.229874
global_step: 6210, epoch: 156, loss: 0.194397
global_step: 6211, epoch: 156, loss: 0.171307
global_step: 6212, epoch: 156, loss: 0.258113
global_step: 6213, epoch: 156, loss: 0.163333
global_step: 6214, epoch: 156, loss: 0.239994
global_step: 6215, epoch: 156, loss: 0.174802
global_step: 6216, epoch: 156, loss: 0.185417
global_step: 6217, epoch: 156, loss: 0.204595
global_step: 6218, epoch: 156, loss: 0.229733
global_step: 6219, epoch: 156, loss: 0.232449
global_step: 6220, epoch: 156, loss: 0.209728
global_step: 6221, epoch: 156, loss: 0.188653
global_step: 6222, epoch: 156, loss: 0.192434
global_step: 6223, epoch: 156, loss: 0.236356
global_step: 6224, epoch: 156, loss: 0.178377
global_step: 6225, epoch: 156, loss: 0.248779
global_step: 6226, epoch: 156, loss: 0.194694
global_step: 6227, epoch: 156, loss: 0.226564
global_step: 6228, epoch: 156, loss: 0.225632
global_step: 6229, epoch: 156, loss: 0.168267
global_step: 6230, epoch: 156, loss: 0.208335
global_step: 6231, epoch: 156, loss: 0.214891
global_step: 6232, epoch: 156, loss: 0.177115
global_step: 6233, epoch: 156, loss: 0.194248
global_step: 6234, epoch: 156, loss: 0.235141
global_step: 6235, epoch: 156, loss: 0.206553
global_step: 6236, epoch: 156, loss: 0.233765
global_step: 6237, epoch: 156, loss: 0.250874
global_step: 6238, epoch: 156, loss: 0.312550
global_step: 6239, epoch: 156, loss: 0.238583
global_step: 6240, epoch: 156, loss: 0.146806
epoch: 156
train	acc: 0.9700	macro: p 0.9713, r 0.9595, f1: 0.9651	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5239	macro: p 0.3863, r 0.3103, f1: 0.3131	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4849
test	acc: 0.5755	macro: p 0.3757, r 0.3336, f1: 0.3409	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5495
global_step: 6241, epoch: 157, loss: 0.237926
global_step: 6242, epoch: 157, loss: 0.217292
global_step: 6243, epoch: 157, loss: 0.234084
global_step: 6244, epoch: 157, loss: 0.252055
global_step: 6245, epoch: 157, loss: 0.195256
global_step: 6246, epoch: 157, loss: 0.166010
global_step: 6247, epoch: 157, loss: 0.171366
global_step: 6248, epoch: 157, loss: 0.187702
global_step: 6249, epoch: 157, loss: 0.166712
global_step: 6250, epoch: 157, loss: 0.290564
global_step: 6251, epoch: 157, loss: 0.211225
global_step: 6252, epoch: 157, loss: 0.287133
global_step: 6253, epoch: 157, loss: 0.266246
global_step: 6254, epoch: 157, loss: 0.221051
global_step: 6255, epoch: 157, loss: 0.187039
global_step: 6256, epoch: 157, loss: 0.188188
global_step: 6257, epoch: 157, loss: 0.216230
global_step: 6258, epoch: 157, loss: 0.159970
global_step: 6259, epoch: 157, loss: 0.203117
global_step: 6260, epoch: 157, loss: 0.236294
global_step: 6261, epoch: 157, loss: 0.226945
global_step: 6262, epoch: 157, loss: 0.258765
global_step: 6263, epoch: 157, loss: 0.251532
global_step: 6264, epoch: 157, loss: 0.194966
global_step: 6265, epoch: 157, loss: 0.187192
global_step: 6266, epoch: 157, loss: 0.220762
global_step: 6267, epoch: 157, loss: 0.232740
global_step: 6268, epoch: 157, loss: 0.269915
global_step: 6269, epoch: 157, loss: 0.198453
global_step: 6270, epoch: 157, loss: 0.224906
global_step: 6271, epoch: 157, loss: 0.222838
global_step: 6272, epoch: 157, loss: 0.232187
global_step: 6273, epoch: 157, loss: 0.274433
global_step: 6274, epoch: 157, loss: 0.210110
global_step: 6275, epoch: 157, loss: 0.221197
global_step: 6276, epoch: 157, loss: 0.284934
global_step: 6277, epoch: 157, loss: 0.206544
global_step: 6278, epoch: 157, loss: 0.200186
global_step: 6279, epoch: 157, loss: 0.186948
global_step: 6280, epoch: 157, loss: 0.412392
epoch: 157
train	acc: 0.9689	macro: p 0.9729, r 0.9543, f1: 0.9633	micro: p 0.9689, r 0.9689, f1 0.9689	weighted_f1:0.9688
dev	acc: 0.5374	macro: p 0.3788, r 0.3045, f1: 0.3107	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4879
test	acc: 0.5916	macro: p 0.4473, r 0.3183, f1: 0.3324	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5467
global_step: 6281, epoch: 158, loss: 0.206665
global_step: 6282, epoch: 158, loss: 0.315565
global_step: 6283, epoch: 158, loss: 0.215477
global_step: 6284, epoch: 158, loss: 0.220183
global_step: 6285, epoch: 158, loss: 0.250637
global_step: 6286, epoch: 158, loss: 0.139966
global_step: 6287, epoch: 158, loss: 0.224089
global_step: 6288, epoch: 158, loss: 0.243322
global_step: 6289, epoch: 158, loss: 0.218628
global_step: 6290, epoch: 158, loss: 0.197603
global_step: 6291, epoch: 158, loss: 0.212143
global_step: 6292, epoch: 158, loss: 0.265756
global_step: 6293, epoch: 158, loss: 0.140993
global_step: 6294, epoch: 158, loss: 0.175590
global_step: 6295, epoch: 158, loss: 0.133824
global_step: 6296, epoch: 158, loss: 0.272110
global_step: 6297, epoch: 158, loss: 0.196114
global_step: 6298, epoch: 158, loss: 0.205404
global_step: 6299, epoch: 158, loss: 0.228799
global_step: 6300, epoch: 158, loss: 0.158991
global_step: 6301, epoch: 158, loss: 0.204943
global_step: 6302, epoch: 158, loss: 0.193898
global_step: 6303, epoch: 158, loss: 0.178120
global_step: 6304, epoch: 158, loss: 0.181176
global_step: 6305, epoch: 158, loss: 0.204433
global_step: 6306, epoch: 158, loss: 0.250674
global_step: 6307, epoch: 158, loss: 0.192904
global_step: 6308, epoch: 158, loss: 0.229060
global_step: 6309, epoch: 158, loss: 0.258039
global_step: 6310, epoch: 158, loss: 0.230342
global_step: 6311, epoch: 158, loss: 0.261405
global_step: 6312, epoch: 158, loss: 0.167143
global_step: 6313, epoch: 158, loss: 0.247454
global_step: 6314, epoch: 158, loss: 0.213764
global_step: 6315, epoch: 158, loss: 0.242021
global_step: 6316, epoch: 158, loss: 0.290515
global_step: 6317, epoch: 158, loss: 0.192148
global_step: 6318, epoch: 158, loss: 0.289073
global_step: 6319, epoch: 158, loss: 0.276836
global_step: 6320, epoch: 158, loss: 0.097322
epoch: 158
train	acc: 0.9703	macro: p 0.9728, r 0.9576, f1: 0.9649	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5302	macro: p 0.3983, r 0.3079, f1: 0.3162	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4875
test	acc: 0.5824	macro: p 0.4015, r 0.3201, f1: 0.3293	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5455
global_step: 6321, epoch: 159, loss: 0.159479
global_step: 6322, epoch: 159, loss: 0.197558
global_step: 6323, epoch: 159, loss: 0.188633
global_step: 6324, epoch: 159, loss: 0.150991
global_step: 6325, epoch: 159, loss: 0.262705
global_step: 6326, epoch: 159, loss: 0.205457
global_step: 6327, epoch: 159, loss: 0.209997
global_step: 6328, epoch: 159, loss: 0.181992
global_step: 6329, epoch: 159, loss: 0.187742
global_step: 6330, epoch: 159, loss: 0.206231
global_step: 6331, epoch: 159, loss: 0.297465
global_step: 6332, epoch: 159, loss: 0.230604
global_step: 6333, epoch: 159, loss: 0.153074
global_step: 6334, epoch: 159, loss: 0.252516
global_step: 6335, epoch: 159, loss: 0.222896
global_step: 6336, epoch: 159, loss: 0.199010
global_step: 6337, epoch: 159, loss: 0.194082
global_step: 6338, epoch: 159, loss: 0.210675
global_step: 6339, epoch: 159, loss: 0.253633
global_step: 6340, epoch: 159, loss: 0.244408
global_step: 6341, epoch: 159, loss: 0.227742
global_step: 6342, epoch: 159, loss: 0.166659
global_step: 6343, epoch: 159, loss: 0.169827
global_step: 6344, epoch: 159, loss: 0.164543
global_step: 6345, epoch: 159, loss: 0.220310
global_step: 6346, epoch: 159, loss: 0.283951
global_step: 6347, epoch: 159, loss: 0.198968
global_step: 6348, epoch: 159, loss: 0.212370
global_step: 6349, epoch: 159, loss: 0.173046
global_step: 6350, epoch: 159, loss: 0.277430
global_step: 6351, epoch: 159, loss: 0.259648
global_step: 6352, epoch: 159, loss: 0.240733
global_step: 6353, epoch: 159, loss: 0.209800
global_step: 6354, epoch: 159, loss: 0.212483
global_step: 6355, epoch: 159, loss: 0.210839
global_step: 6356, epoch: 159, loss: 0.224164
global_step: 6357, epoch: 159, loss: 0.255430
global_step: 6358, epoch: 159, loss: 0.201645
global_step: 6359, epoch: 159, loss: 0.156990
global_step: 6360, epoch: 159, loss: 0.187759
epoch: 159
train	acc: 0.9708	macro: p 0.9746, r 0.9568, f1: 0.9654	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5347	macro: p 0.4413, r 0.3133, f1: 0.3217	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4910
test	acc: 0.5789	macro: p 0.3858, r 0.3198, f1: 0.3282	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5432
global_step: 6361, epoch: 160, loss: 0.212721
global_step: 6362, epoch: 160, loss: 0.216296
global_step: 6363, epoch: 160, loss: 0.212824
global_step: 6364, epoch: 160, loss: 0.222653
global_step: 6365, epoch: 160, loss: 0.202656
global_step: 6366, epoch: 160, loss: 0.243423
global_step: 6367, epoch: 160, loss: 0.211458
global_step: 6368, epoch: 160, loss: 0.224853
global_step: 6369, epoch: 160, loss: 0.219194
global_step: 6370, epoch: 160, loss: 0.225241
global_step: 6371, epoch: 160, loss: 0.171070
global_step: 6372, epoch: 160, loss: 0.256366
global_step: 6373, epoch: 160, loss: 0.223710
global_step: 6374, epoch: 160, loss: 0.158228
global_step: 6375, epoch: 160, loss: 0.233471
global_step: 6376, epoch: 160, loss: 0.180708
global_step: 6377, epoch: 160, loss: 0.147330
global_step: 6378, epoch: 160, loss: 0.223023
global_step: 6379, epoch: 160, loss: 0.218394
global_step: 6380, epoch: 160, loss: 0.161388
global_step: 6381, epoch: 160, loss: 0.212648
global_step: 6382, epoch: 160, loss: 0.192719
global_step: 6383, epoch: 160, loss: 0.208457
global_step: 6384, epoch: 160, loss: 0.226523
global_step: 6385, epoch: 160, loss: 0.260771
global_step: 6386, epoch: 160, loss: 0.239052
global_step: 6387, epoch: 160, loss: 0.207542
global_step: 6388, epoch: 160, loss: 0.190450
global_step: 6389, epoch: 160, loss: 0.156779
global_step: 6390, epoch: 160, loss: 0.227937
global_step: 6391, epoch: 160, loss: 0.258742
global_step: 6392, epoch: 160, loss: 0.231927
global_step: 6393, epoch: 160, loss: 0.310231
global_step: 6394, epoch: 160, loss: 0.180448
global_step: 6395, epoch: 160, loss: 0.239381
global_step: 6396, epoch: 160, loss: 0.217824
global_step: 6397, epoch: 160, loss: 0.165727
global_step: 6398, epoch: 160, loss: 0.174998
global_step: 6399, epoch: 160, loss: 0.197324
global_step: 6400, epoch: 160, loss: 0.156648
epoch: 160
train	acc: 0.9703	macro: p 0.9736, r 0.9567, f1: 0.9648	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5374	macro: p 0.3651, r 0.3073, f1: 0.3095	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4897
test	acc: 0.5793	macro: p 0.4026, r 0.3203, f1: 0.3307	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5410
global_step: 6401, epoch: 161, loss: 0.179186
global_step: 6402, epoch: 161, loss: 0.234242
global_step: 6403, epoch: 161, loss: 0.260798
global_step: 6404, epoch: 161, loss: 0.184637
global_step: 6405, epoch: 161, loss: 0.245914
global_step: 6406, epoch: 161, loss: 0.254400
global_step: 6407, epoch: 161, loss: 0.168528
global_step: 6408, epoch: 161, loss: 0.244447
global_step: 6409, epoch: 161, loss: 0.265958
global_step: 6410, epoch: 161, loss: 0.201823
global_step: 6411, epoch: 161, loss: 0.158932
global_step: 6412, epoch: 161, loss: 0.199531
global_step: 6413, epoch: 161, loss: 0.224986
global_step: 6414, epoch: 161, loss: 0.244670
global_step: 6415, epoch: 161, loss: 0.201420
global_step: 6416, epoch: 161, loss: 0.173327
global_step: 6417, epoch: 161, loss: 0.205848
global_step: 6418, epoch: 161, loss: 0.288225
global_step: 6419, epoch: 161, loss: 0.204928
global_step: 6420, epoch: 161, loss: 0.194849
global_step: 6421, epoch: 161, loss: 0.210554
global_step: 6422, epoch: 161, loss: 0.183075
global_step: 6423, epoch: 161, loss: 0.184558
global_step: 6424, epoch: 161, loss: 0.191047
global_step: 6425, epoch: 161, loss: 0.253388
global_step: 6426, epoch: 161, loss: 0.255145
global_step: 6427, epoch: 161, loss: 0.207350
global_step: 6428, epoch: 161, loss: 0.287728
global_step: 6429, epoch: 161, loss: 0.155363
global_step: 6430, epoch: 161, loss: 0.205150
global_step: 6431, epoch: 161, loss: 0.213058
global_step: 6432, epoch: 161, loss: 0.232421
global_step: 6433, epoch: 161, loss: 0.232911
global_step: 6434, epoch: 161, loss: 0.217433
global_step: 6435, epoch: 161, loss: 0.234122
global_step: 6436, epoch: 161, loss: 0.203677
global_step: 6437, epoch: 161, loss: 0.165167
global_step: 6438, epoch: 161, loss: 0.275077
global_step: 6439, epoch: 161, loss: 0.184473
global_step: 6440, epoch: 161, loss: 0.072329
epoch: 161
train	acc: 0.9704	macro: p 0.9743, r 0.9575, f1: 0.9656	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5239	macro: p 0.4235, r 0.3008, f1: 0.3094	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4773
test	acc: 0.5820	macro: p 0.3896, r 0.3175, f1: 0.3266	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5430
global_step: 6441, epoch: 162, loss: 0.212124
global_step: 6442, epoch: 162, loss: 0.158666
global_step: 6443, epoch: 162, loss: 0.180116
global_step: 6444, epoch: 162, loss: 0.202468
global_step: 6445, epoch: 162, loss: 0.176979
global_step: 6446, epoch: 162, loss: 0.157645
global_step: 6447, epoch: 162, loss: 0.193081
global_step: 6448, epoch: 162, loss: 0.183811
global_step: 6449, epoch: 162, loss: 0.211198
global_step: 6450, epoch: 162, loss: 0.237012
global_step: 6451, epoch: 162, loss: 0.182688
global_step: 6452, epoch: 162, loss: 0.180111
global_step: 6453, epoch: 162, loss: 0.239940
global_step: 6454, epoch: 162, loss: 0.220062
global_step: 6455, epoch: 162, loss: 0.210518
global_step: 6456, epoch: 162, loss: 0.235922
global_step: 6457, epoch: 162, loss: 0.250601
global_step: 6458, epoch: 162, loss: 0.196778
global_step: 6459, epoch: 162, loss: 0.216034
global_step: 6460, epoch: 162, loss: 0.260568
global_step: 6461, epoch: 162, loss: 0.221024
global_step: 6462, epoch: 162, loss: 0.197181
global_step: 6463, epoch: 162, loss: 0.212810
global_step: 6464, epoch: 162, loss: 0.211777
global_step: 6465, epoch: 162, loss: 0.258155
global_step: 6466, epoch: 162, loss: 0.231359
global_step: 6467, epoch: 162, loss: 0.176988
global_step: 6468, epoch: 162, loss: 0.240481
global_step: 6469, epoch: 162, loss: 0.148111
global_step: 6470, epoch: 162, loss: 0.218355
global_step: 6471, epoch: 162, loss: 0.235120
global_step: 6472, epoch: 162, loss: 0.227630
global_step: 6473, epoch: 162, loss: 0.289964
global_step: 6474, epoch: 162, loss: 0.178844
global_step: 6475, epoch: 162, loss: 0.254997
global_step: 6476, epoch: 162, loss: 0.198751
global_step: 6477, epoch: 162, loss: 0.236938
global_step: 6478, epoch: 162, loss: 0.308058
global_step: 6479, epoch: 162, loss: 0.272580
global_step: 6480, epoch: 162, loss: 0.463232
epoch: 162
train	acc: 0.9706	macro: p 0.9739, r 0.9584, f1: 0.9659	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5239	macro: p 0.3760, r 0.3067, f1: 0.3131	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4830
test	acc: 0.5716	macro: p 0.3706, r 0.3185, f1: 0.3272	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5377
global_step: 6481, epoch: 163, loss: 0.160906
global_step: 6482, epoch: 163, loss: 0.174887
global_step: 6483, epoch: 163, loss: 0.208191
global_step: 6484, epoch: 163, loss: 0.151451
global_step: 6485, epoch: 163, loss: 0.139490
global_step: 6486, epoch: 163, loss: 0.285215
global_step: 6487, epoch: 163, loss: 0.209386
global_step: 6488, epoch: 163, loss: 0.230264
global_step: 6489, epoch: 163, loss: 0.193870
global_step: 6490, epoch: 163, loss: 0.191456
global_step: 6491, epoch: 163, loss: 0.185888
global_step: 6492, epoch: 163, loss: 0.195064
global_step: 6493, epoch: 163, loss: 0.232268
global_step: 6494, epoch: 163, loss: 0.172541
global_step: 6495, epoch: 163, loss: 0.196140
global_step: 6496, epoch: 163, loss: 0.210122
global_step: 6497, epoch: 163, loss: 0.226747
global_step: 6498, epoch: 163, loss: 0.147726
global_step: 6499, epoch: 163, loss: 0.227488
global_step: 6500, epoch: 163, loss: 0.213457
global_step: 6501, epoch: 163, loss: 0.214636
global_step: 6502, epoch: 163, loss: 0.209809
global_step: 6503, epoch: 163, loss: 0.252252
global_step: 6504, epoch: 163, loss: 0.140712
global_step: 6505, epoch: 163, loss: 0.265209
global_step: 6506, epoch: 163, loss: 0.185055
global_step: 6507, epoch: 163, loss: 0.207814
global_step: 6508, epoch: 163, loss: 0.244648
global_step: 6509, epoch: 163, loss: 0.254851
global_step: 6510, epoch: 163, loss: 0.230548
global_step: 6511, epoch: 163, loss: 0.214195
global_step: 6512, epoch: 163, loss: 0.186066
global_step: 6513, epoch: 163, loss: 0.247630
global_step: 6514, epoch: 163, loss: 0.131731
global_step: 6515, epoch: 163, loss: 0.201678
global_step: 6516, epoch: 163, loss: 0.222772
global_step: 6517, epoch: 163, loss: 0.291879
global_step: 6518, epoch: 163, loss: 0.250217
global_step: 6519, epoch: 163, loss: 0.214152
global_step: 6520, epoch: 163, loss: 0.001659
epoch: 163
train	acc: 0.9712	macro: p 0.9740, r 0.9598, f1: 0.9667	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5338	macro: p 0.3784, r 0.3089, f1: 0.3139	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4865
test	acc: 0.5801	macro: p 0.3733, r 0.3153, f1: 0.3228	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5393
global_step: 6521, epoch: 164, loss: 0.206527
global_step: 6522, epoch: 164, loss: 0.177223
global_step: 6523, epoch: 164, loss: 0.143873
global_step: 6524, epoch: 164, loss: 0.222751
global_step: 6525, epoch: 164, loss: 0.196670
global_step: 6526, epoch: 164, loss: 0.210761
global_step: 6527, epoch: 164, loss: 0.173333
global_step: 6528, epoch: 164, loss: 0.219510
global_step: 6529, epoch: 164, loss: 0.184102
global_step: 6530, epoch: 164, loss: 0.211896
global_step: 6531, epoch: 164, loss: 0.177624
global_step: 6532, epoch: 164, loss: 0.117580
global_step: 6533, epoch: 164, loss: 0.175272
global_step: 6534, epoch: 164, loss: 0.166500
global_step: 6535, epoch: 164, loss: 0.198929
global_step: 6536, epoch: 164, loss: 0.134964
global_step: 6537, epoch: 164, loss: 0.236013
global_step: 6538, epoch: 164, loss: 0.237202
global_step: 6539, epoch: 164, loss: 0.244704
global_step: 6540, epoch: 164, loss: 0.202695
global_step: 6541, epoch: 164, loss: 0.227809
global_step: 6542, epoch: 164, loss: 0.288481
global_step: 6543, epoch: 164, loss: 0.258760
global_step: 6544, epoch: 164, loss: 0.281636
global_step: 6545, epoch: 164, loss: 0.218776
global_step: 6546, epoch: 164, loss: 0.206176
global_step: 6547, epoch: 164, loss: 0.227159
global_step: 6548, epoch: 164, loss: 0.221321
global_step: 6549, epoch: 164, loss: 0.171546
global_step: 6550, epoch: 164, loss: 0.198830
global_step: 6551, epoch: 164, loss: 0.168593
global_step: 6552, epoch: 164, loss: 0.218204
global_step: 6553, epoch: 164, loss: 0.181659
global_step: 6554, epoch: 164, loss: 0.203642
global_step: 6555, epoch: 164, loss: 0.204274
global_step: 6556, epoch: 164, loss: 0.293025
global_step: 6557, epoch: 164, loss: 0.252069
global_step: 6558, epoch: 164, loss: 0.209897
global_step: 6559, epoch: 164, loss: 0.219170
global_step: 6560, epoch: 164, loss: 0.481670
epoch: 164
train	acc: 0.9709	macro: p 0.9750, r 0.9573, f1: 0.9658	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5257	macro: p 0.3318, r 0.3037, f1: 0.3012	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4865
test	acc: 0.5686	macro: p 0.3867, r 0.3225, f1: 0.3277	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5396
global_step: 6561, epoch: 165, loss: 0.212987
global_step: 6562, epoch: 165, loss: 0.193554
global_step: 6563, epoch: 165, loss: 0.159763
global_step: 6564, epoch: 165, loss: 0.219990
global_step: 6565, epoch: 165, loss: 0.198815
global_step: 6566, epoch: 165, loss: 0.245138
global_step: 6567, epoch: 165, loss: 0.201235
global_step: 6568, epoch: 165, loss: 0.200709
global_step: 6569, epoch: 165, loss: 0.163288
global_step: 6570, epoch: 165, loss: 0.191595
global_step: 6571, epoch: 165, loss: 0.166530
global_step: 6572, epoch: 165, loss: 0.268602
global_step: 6573, epoch: 165, loss: 0.233687
global_step: 6574, epoch: 165, loss: 0.218622
global_step: 6575, epoch: 165, loss: 0.180321
global_step: 6576, epoch: 165, loss: 0.189031
global_step: 6577, epoch: 165, loss: 0.204617
global_step: 6578, epoch: 165, loss: 0.274697
global_step: 6579, epoch: 165, loss: 0.247575
global_step: 6580, epoch: 165, loss: 0.186564
global_step: 6581, epoch: 165, loss: 0.195399
global_step: 6582, epoch: 165, loss: 0.180063
global_step: 6583, epoch: 165, loss: 0.185554
global_step: 6584, epoch: 165, loss: 0.198671
global_step: 6585, epoch: 165, loss: 0.213156
global_step: 6586, epoch: 165, loss: 0.138044
global_step: 6587, epoch: 165, loss: 0.209180
global_step: 6588, epoch: 165, loss: 0.257998
global_step: 6589, epoch: 165, loss: 0.133159
global_step: 6590, epoch: 165, loss: 0.304038
global_step: 6591, epoch: 165, loss: 0.245844
global_step: 6592, epoch: 165, loss: 0.266600
global_step: 6593, epoch: 165, loss: 0.215828
global_step: 6594, epoch: 165, loss: 0.189754
global_step: 6595, epoch: 165, loss: 0.185980
global_step: 6596, epoch: 165, loss: 0.206718
global_step: 6597, epoch: 165, loss: 0.174344
global_step: 6598, epoch: 165, loss: 0.235927
global_step: 6599, epoch: 165, loss: 0.210478
global_step: 6600, epoch: 165, loss: 0.009478
epoch: 165
train	acc: 0.9713	macro: p 0.9740, r 0.9606, f1: 0.9671	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5338	macro: p 0.3838, r 0.3092, f1: 0.3142	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4899
test	acc: 0.5797	macro: p 0.3821, r 0.3205, f1: 0.3289	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5441
global_step: 6601, epoch: 166, loss: 0.219672
global_step: 6602, epoch: 166, loss: 0.216485
global_step: 6603, epoch: 166, loss: 0.184625
global_step: 6604, epoch: 166, loss: 0.172238
global_step: 6605, epoch: 166, loss: 0.180139
global_step: 6606, epoch: 166, loss: 0.146558
global_step: 6607, epoch: 166, loss: 0.234246
global_step: 6608, epoch: 166, loss: 0.170423
global_step: 6609, epoch: 166, loss: 0.133378
global_step: 6610, epoch: 166, loss: 0.146564
global_step: 6611, epoch: 166, loss: 0.134337
global_step: 6612, epoch: 166, loss: 0.170384
global_step: 6613, epoch: 166, loss: 0.166323
global_step: 6614, epoch: 166, loss: 0.236246
global_step: 6615, epoch: 166, loss: 0.206131
global_step: 6616, epoch: 166, loss: 0.276688
global_step: 6617, epoch: 166, loss: 0.171376
global_step: 6618, epoch: 166, loss: 0.239080
global_step: 6619, epoch: 166, loss: 0.144065
global_step: 6620, epoch: 166, loss: 0.215660
global_step: 6621, epoch: 166, loss: 0.277202
global_step: 6622, epoch: 166, loss: 0.161776
global_step: 6623, epoch: 166, loss: 0.172939
global_step: 6624, epoch: 166, loss: 0.199120
global_step: 6625, epoch: 166, loss: 0.264794
global_step: 6626, epoch: 166, loss: 0.155315
global_step: 6627, epoch: 166, loss: 0.195065
global_step: 6628, epoch: 166, loss: 0.214855
global_step: 6629, epoch: 166, loss: 0.214553
global_step: 6630, epoch: 166, loss: 0.191489
global_step: 6631, epoch: 166, loss: 0.227698
global_step: 6632, epoch: 166, loss: 0.225369
global_step: 6633, epoch: 166, loss: 0.234528
global_step: 6634, epoch: 166, loss: 0.211856
global_step: 6635, epoch: 166, loss: 0.267433
global_step: 6636, epoch: 166, loss: 0.243181
global_step: 6637, epoch: 166, loss: 0.203973
global_step: 6638, epoch: 166, loss: 0.169030
global_step: 6639, epoch: 166, loss: 0.245044
global_step: 6640, epoch: 166, loss: 0.040765
epoch: 166
train	acc: 0.9713	macro: p 0.9749, r 0.9587, f1: 0.9665	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5347	macro: p 0.4106, r 0.3082, f1: 0.3163	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4912
test	acc: 0.5816	macro: p 0.3731, r 0.3163, f1: 0.3258	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5442
global_step: 6641, epoch: 167, loss: 0.249877
global_step: 6642, epoch: 167, loss: 0.124357
global_step: 6643, epoch: 167, loss: 0.160668
global_step: 6644, epoch: 167, loss: 0.187826
global_step: 6645, epoch: 167, loss: 0.182824
global_step: 6646, epoch: 167, loss: 0.207490
global_step: 6647, epoch: 167, loss: 0.200663
global_step: 6648, epoch: 167, loss: 0.170815
global_step: 6649, epoch: 167, loss: 0.181673
global_step: 6650, epoch: 167, loss: 0.183335
global_step: 6651, epoch: 167, loss: 0.221207
global_step: 6652, epoch: 167, loss: 0.182477
global_step: 6653, epoch: 167, loss: 0.164509
global_step: 6654, epoch: 167, loss: 0.181787
global_step: 6655, epoch: 167, loss: 0.200145
global_step: 6656, epoch: 167, loss: 0.202558
global_step: 6657, epoch: 167, loss: 0.098947
global_step: 6658, epoch: 167, loss: 0.172040
global_step: 6659, epoch: 167, loss: 0.256519
global_step: 6660, epoch: 167, loss: 0.234681
global_step: 6661, epoch: 167, loss: 0.249682
global_step: 6662, epoch: 167, loss: 0.259252
global_step: 6663, epoch: 167, loss: 0.215141
global_step: 6664, epoch: 167, loss: 0.232070
global_step: 6665, epoch: 167, loss: 0.121108
global_step: 6666, epoch: 167, loss: 0.207917
global_step: 6667, epoch: 167, loss: 0.239450
global_step: 6668, epoch: 167, loss: 0.151645
global_step: 6669, epoch: 167, loss: 0.198171
global_step: 6670, epoch: 167, loss: 0.195646
global_step: 6671, epoch: 167, loss: 0.201102
global_step: 6672, epoch: 167, loss: 0.162486
global_step: 6673, epoch: 167, loss: 0.245457
global_step: 6674, epoch: 167, loss: 0.188899
global_step: 6675, epoch: 167, loss: 0.286682
global_step: 6676, epoch: 167, loss: 0.203515
global_step: 6677, epoch: 167, loss: 0.224625
global_step: 6678, epoch: 167, loss: 0.196683
global_step: 6679, epoch: 167, loss: 0.186967
global_step: 6680, epoch: 167, loss: 0.038335
epoch: 167
train	acc: 0.9716	macro: p 0.9752, r 0.9594, f1: 0.9670	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5347	macro: p 0.4232, r 0.3163, f1: 0.3234	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4933
test	acc: 0.5774	macro: p 0.3691, r 0.3203, f1: 0.3271	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5436
global_step: 6681, epoch: 168, loss: 0.162854
global_step: 6682, epoch: 168, loss: 0.153111
global_step: 6683, epoch: 168, loss: 0.187661
global_step: 6684, epoch: 168, loss: 0.186633
global_step: 6685, epoch: 168, loss: 0.211267
global_step: 6686, epoch: 168, loss: 0.181955
global_step: 6687, epoch: 168, loss: 0.233290
global_step: 6688, epoch: 168, loss: 0.186307
global_step: 6689, epoch: 168, loss: 0.209365
global_step: 6690, epoch: 168, loss: 0.196196
global_step: 6691, epoch: 168, loss: 0.186354
global_step: 6692, epoch: 168, loss: 0.199625
global_step: 6693, epoch: 168, loss: 0.206996
global_step: 6694, epoch: 168, loss: 0.203984
global_step: 6695, epoch: 168, loss: 0.239472
global_step: 6696, epoch: 168, loss: 0.219277
global_step: 6697, epoch: 168, loss: 0.159174
global_step: 6698, epoch: 168, loss: 0.232592
global_step: 6699, epoch: 168, loss: 0.199940
global_step: 6700, epoch: 168, loss: 0.196017
global_step: 6701, epoch: 168, loss: 0.221546
global_step: 6702, epoch: 168, loss: 0.232149
global_step: 6703, epoch: 168, loss: 0.166221
global_step: 6704, epoch: 168, loss: 0.147971
global_step: 6705, epoch: 168, loss: 0.184659
global_step: 6706, epoch: 168, loss: 0.184824
global_step: 6707, epoch: 168, loss: 0.190679
global_step: 6708, epoch: 168, loss: 0.174068
global_step: 6709, epoch: 168, loss: 0.203323
global_step: 6710, epoch: 168, loss: 0.175583
global_step: 6711, epoch: 168, loss: 0.207787
global_step: 6712, epoch: 168, loss: 0.266049
global_step: 6713, epoch: 168, loss: 0.186428
global_step: 6714, epoch: 168, loss: 0.207008
global_step: 6715, epoch: 168, loss: 0.172026
global_step: 6716, epoch: 168, loss: 0.199300
global_step: 6717, epoch: 168, loss: 0.191061
global_step: 6718, epoch: 168, loss: 0.173098
global_step: 6719, epoch: 168, loss: 0.153734
global_step: 6720, epoch: 168, loss: 0.025926
epoch: 168
train	acc: 0.9704	macro: p 0.9752, r 0.9566, f1: 0.9656	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5311	macro: p 0.4360, r 0.3087, f1: 0.3149	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4849
test	acc: 0.5828	macro: p 0.3787, r 0.3153, f1: 0.3210	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5442
global_step: 6721, epoch: 169, loss: 0.153690
global_step: 6722, epoch: 169, loss: 0.143349
global_step: 6723, epoch: 169, loss: 0.182864
global_step: 6724, epoch: 169, loss: 0.161988
global_step: 6725, epoch: 169, loss: 0.171772
global_step: 6726, epoch: 169, loss: 0.201913
global_step: 6727, epoch: 169, loss: 0.215179
global_step: 6728, epoch: 169, loss: 0.155215
global_step: 6729, epoch: 169, loss: 0.241488
global_step: 6730, epoch: 169, loss: 0.143525
global_step: 6731, epoch: 169, loss: 0.155468
global_step: 6732, epoch: 169, loss: 0.208622
global_step: 6733, epoch: 169, loss: 0.170629
global_step: 6734, epoch: 169, loss: 0.188746
global_step: 6735, epoch: 169, loss: 0.246806
global_step: 6736, epoch: 169, loss: 0.209984
global_step: 6737, epoch: 169, loss: 0.149911
global_step: 6738, epoch: 169, loss: 0.289455
global_step: 6739, epoch: 169, loss: 0.165833
global_step: 6740, epoch: 169, loss: 0.276766
global_step: 6741, epoch: 169, loss: 0.293847
global_step: 6742, epoch: 169, loss: 0.243172
global_step: 6743, epoch: 169, loss: 0.243693
global_step: 6744, epoch: 169, loss: 0.218045
global_step: 6745, epoch: 169, loss: 0.213168
global_step: 6746, epoch: 169, loss: 0.125894
global_step: 6747, epoch: 169, loss: 0.229053
global_step: 6748, epoch: 169, loss: 0.186335
global_step: 6749, epoch: 169, loss: 0.184320
global_step: 6750, epoch: 169, loss: 0.202620
global_step: 6751, epoch: 169, loss: 0.237046
global_step: 6752, epoch: 169, loss: 0.292757
global_step: 6753, epoch: 169, loss: 0.205619
global_step: 6754, epoch: 169, loss: 0.210877
global_step: 6755, epoch: 169, loss: 0.265824
global_step: 6756, epoch: 169, loss: 0.164417
global_step: 6757, epoch: 169, loss: 0.156025
global_step: 6758, epoch: 169, loss: 0.223255
global_step: 6759, epoch: 169, loss: 0.167471
global_step: 6760, epoch: 169, loss: 0.393402
epoch: 169
train	acc: 0.9715	macro: p 0.9753, r 0.9587, f1: 0.9667	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5302	macro: p 0.5067, r 0.3057, f1: 0.3145	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4807
test	acc: 0.5843	macro: p 0.3764, r 0.3103, f1: 0.3154	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5404
global_step: 6761, epoch: 170, loss: 0.176673
global_step: 6762, epoch: 170, loss: 0.184914
global_step: 6763, epoch: 170, loss: 0.160927
global_step: 6764, epoch: 170, loss: 0.195234
global_step: 6765, epoch: 170, loss: 0.212604
global_step: 6766, epoch: 170, loss: 0.116258
global_step: 6767, epoch: 170, loss: 0.220667
global_step: 6768, epoch: 170, loss: 0.227033
global_step: 6769, epoch: 170, loss: 0.198540
global_step: 6770, epoch: 170, loss: 0.182055
global_step: 6771, epoch: 170, loss: 0.212817
global_step: 6772, epoch: 170, loss: 0.175692
global_step: 6773, epoch: 170, loss: 0.213506
global_step: 6774, epoch: 170, loss: 0.185471
global_step: 6775, epoch: 170, loss: 0.243125
global_step: 6776, epoch: 170, loss: 0.188674
global_step: 6777, epoch: 170, loss: 0.242979
global_step: 6778, epoch: 170, loss: 0.201904
global_step: 6779, epoch: 170, loss: 0.184697
global_step: 6780, epoch: 170, loss: 0.151258
global_step: 6781, epoch: 170, loss: 0.175098
global_step: 6782, epoch: 170, loss: 0.206625
global_step: 6783, epoch: 170, loss: 0.158915
global_step: 6784, epoch: 170, loss: 0.242805
global_step: 6785, epoch: 170, loss: 0.179531
global_step: 6786, epoch: 170, loss: 0.219303
global_step: 6787, epoch: 170, loss: 0.198117
global_step: 6788, epoch: 170, loss: 0.253292
global_step: 6789, epoch: 170, loss: 0.234645
global_step: 6790, epoch: 170, loss: 0.257600
global_step: 6791, epoch: 170, loss: 0.211360
global_step: 6792, epoch: 170, loss: 0.196762
global_step: 6793, epoch: 170, loss: 0.156959
global_step: 6794, epoch: 170, loss: 0.273376
global_step: 6795, epoch: 170, loss: 0.174588
global_step: 6796, epoch: 170, loss: 0.239008
global_step: 6797, epoch: 170, loss: 0.191665
global_step: 6798, epoch: 170, loss: 0.220222
global_step: 6799, epoch: 170, loss: 0.146921
global_step: 6800, epoch: 170, loss: 0.127308
epoch: 170
train	acc: 0.9711	macro: p 0.9744, r 0.9580, f1: 0.9659	micro: p 0.9711, r 0.9711, f1 0.9711	weighted_f1:0.9711
dev	acc: 0.5365	macro: p 0.3533, r 0.3093, f1: 0.3114	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4921
test	acc: 0.5812	macro: p 0.4047, r 0.3194, f1: 0.3255	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5435
global_step: 6801, epoch: 171, loss: 0.192426
global_step: 6802, epoch: 171, loss: 0.233732
global_step: 6803, epoch: 171, loss: 0.159539
global_step: 6804, epoch: 171, loss: 0.208300
global_step: 6805, epoch: 171, loss: 0.171866
global_step: 6806, epoch: 171, loss: 0.179602
global_step: 6807, epoch: 171, loss: 0.216324
global_step: 6808, epoch: 171, loss: 0.215335
global_step: 6809, epoch: 171, loss: 0.177705
global_step: 6810, epoch: 171, loss: 0.283105
global_step: 6811, epoch: 171, loss: 0.182503
global_step: 6812, epoch: 171, loss: 0.189536
global_step: 6813, epoch: 171, loss: 0.215747
global_step: 6814, epoch: 171, loss: 0.165239
global_step: 6815, epoch: 171, loss: 0.200192
global_step: 6816, epoch: 171, loss: 0.193938
global_step: 6817, epoch: 171, loss: 0.281596
global_step: 6818, epoch: 171, loss: 0.224393
global_step: 6819, epoch: 171, loss: 0.222545
global_step: 6820, epoch: 171, loss: 0.230681
global_step: 6821, epoch: 171, loss: 0.137943
global_step: 6822, epoch: 171, loss: 0.212359
global_step: 6823, epoch: 171, loss: 0.240830
global_step: 6824, epoch: 171, loss: 0.224713
global_step: 6825, epoch: 171, loss: 0.211866
global_step: 6826, epoch: 171, loss: 0.198532
global_step: 6827, epoch: 171, loss: 0.255032
global_step: 6828, epoch: 171, loss: 0.175820
global_step: 6829, epoch: 171, loss: 0.183309
global_step: 6830, epoch: 171, loss: 0.157248
global_step: 6831, epoch: 171, loss: 0.189423
global_step: 6832, epoch: 171, loss: 0.172141
global_step: 6833, epoch: 171, loss: 0.147223
global_step: 6834, epoch: 171, loss: 0.217039
global_step: 6835, epoch: 171, loss: 0.202176
global_step: 6836, epoch: 171, loss: 0.197352
global_step: 6837, epoch: 171, loss: 0.187424
global_step: 6838, epoch: 171, loss: 0.222378
global_step: 6839, epoch: 171, loss: 0.263557
global_step: 6840, epoch: 171, loss: 0.033809
epoch: 171
train	acc: 0.9710	macro: p 0.9745, r 0.9581, f1: 0.9660	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5320	macro: p 0.3525, r 0.3061, f1: 0.3108	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4902
test	acc: 0.5820	macro: p 0.3839, r 0.3204, f1: 0.3280	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5466
global_step: 6841, epoch: 172, loss: 0.211087
global_step: 6842, epoch: 172, loss: 0.183957
global_step: 6843, epoch: 172, loss: 0.144376
global_step: 6844, epoch: 172, loss: 0.232816
global_step: 6845, epoch: 172, loss: 0.219129
global_step: 6846, epoch: 172, loss: 0.199325
global_step: 6847, epoch: 172, loss: 0.149264
global_step: 6848, epoch: 172, loss: 0.218766
global_step: 6849, epoch: 172, loss: 0.190689
global_step: 6850, epoch: 172, loss: 0.176699
global_step: 6851, epoch: 172, loss: 0.270115
global_step: 6852, epoch: 172, loss: 0.182733
global_step: 6853, epoch: 172, loss: 0.176889
global_step: 6854, epoch: 172, loss: 0.194449
global_step: 6855, epoch: 172, loss: 0.195750
global_step: 6856, epoch: 172, loss: 0.199542
global_step: 6857, epoch: 172, loss: 0.259590
global_step: 6858, epoch: 172, loss: 0.222535
global_step: 6859, epoch: 172, loss: 0.176787
global_step: 6860, epoch: 172, loss: 0.185761
global_step: 6861, epoch: 172, loss: 0.180347
global_step: 6862, epoch: 172, loss: 0.207876
global_step: 6863, epoch: 172, loss: 0.206435
global_step: 6864, epoch: 172, loss: 0.223434
global_step: 6865, epoch: 172, loss: 0.238375
global_step: 6866, epoch: 172, loss: 0.136873
global_step: 6867, epoch: 172, loss: 0.218027
global_step: 6868, epoch: 172, loss: 0.288387
global_step: 6869, epoch: 172, loss: 0.156328
global_step: 6870, epoch: 172, loss: 0.205502
global_step: 6871, epoch: 172, loss: 0.154658
global_step: 6872, epoch: 172, loss: 0.178753
global_step: 6873, epoch: 172, loss: 0.225522
global_step: 6874, epoch: 172, loss: 0.271932
global_step: 6875, epoch: 172, loss: 0.175665
global_step: 6876, epoch: 172, loss: 0.179216
global_step: 6877, epoch: 172, loss: 0.262631
global_step: 6878, epoch: 172, loss: 0.235182
global_step: 6879, epoch: 172, loss: 0.228835
global_step: 6880, epoch: 172, loss: 0.202930
epoch: 172
train	acc: 0.9707	macro: p 0.9741, r 0.9578, f1: 0.9656	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5176	macro: p 0.3945, r 0.3101, f1: 0.3190	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4779
test	acc: 0.5736	macro: p 0.3758, r 0.3238, f1: 0.3321	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5412
global_step: 6881, epoch: 173, loss: 0.187221
global_step: 6882, epoch: 173, loss: 0.208067
global_step: 6883, epoch: 173, loss: 0.248755
global_step: 6884, epoch: 173, loss: 0.216817
global_step: 6885, epoch: 173, loss: 0.235555
global_step: 6886, epoch: 173, loss: 0.189241
global_step: 6887, epoch: 173, loss: 0.180558
global_step: 6888, epoch: 173, loss: 0.180408
global_step: 6889, epoch: 173, loss: 0.185995
global_step: 6890, epoch: 173, loss: 0.181645
global_step: 6891, epoch: 173, loss: 0.217250
global_step: 6892, epoch: 173, loss: 0.234696
global_step: 6893, epoch: 173, loss: 0.210433
global_step: 6894, epoch: 173, loss: 0.169754
global_step: 6895, epoch: 173, loss: 0.202041
global_step: 6896, epoch: 173, loss: 0.192762
global_step: 6897, epoch: 173, loss: 0.164459
global_step: 6898, epoch: 173, loss: 0.149973
global_step: 6899, epoch: 173, loss: 0.191468
global_step: 6900, epoch: 173, loss: 0.237989
global_step: 6901, epoch: 173, loss: 0.243903
global_step: 6902, epoch: 173, loss: 0.201294
global_step: 6903, epoch: 173, loss: 0.242365
global_step: 6904, epoch: 173, loss: 0.226639
global_step: 6905, epoch: 173, loss: 0.189012
global_step: 6906, epoch: 173, loss: 0.183691
global_step: 6907, epoch: 173, loss: 0.190336
global_step: 6908, epoch: 173, loss: 0.196914
global_step: 6909, epoch: 173, loss: 0.188667
global_step: 6910, epoch: 173, loss: 0.215530
global_step: 6911, epoch: 173, loss: 0.186234
global_step: 6912, epoch: 173, loss: 0.181711
global_step: 6913, epoch: 173, loss: 0.312920
global_step: 6914, epoch: 173, loss: 0.184748
global_step: 6915, epoch: 173, loss: 0.182971
global_step: 6916, epoch: 173, loss: 0.208659
global_step: 6917, epoch: 173, loss: 0.159681
global_step: 6918, epoch: 173, loss: 0.229408
global_step: 6919, epoch: 173, loss: 0.142589
global_step: 6920, epoch: 173, loss: 0.771478
epoch: 173
train	acc: 0.9709	macro: p 0.9753, r 0.9583, f1: 0.9664	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5221	macro: p 0.4799, r 0.3035, f1: 0.3075	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4769
test	acc: 0.5770	macro: p 0.3688, r 0.3188, f1: 0.3216	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5418
global_step: 6921, epoch: 174, loss: 0.169380
global_step: 6922, epoch: 174, loss: 0.214545
global_step: 6923, epoch: 174, loss: 0.231109
global_step: 6924, epoch: 174, loss: 0.139782
global_step: 6925, epoch: 174, loss: 0.253281
global_step: 6926, epoch: 174, loss: 0.210420
global_step: 6927, epoch: 174, loss: 0.199809
global_step: 6928, epoch: 174, loss: 0.155388
global_step: 6929, epoch: 174, loss: 0.170248
global_step: 6930, epoch: 174, loss: 0.211795
global_step: 6931, epoch: 174, loss: 0.168233
global_step: 6932, epoch: 174, loss: 0.188419
global_step: 6933, epoch: 174, loss: 0.190919
global_step: 6934, epoch: 174, loss: 0.181620
global_step: 6935, epoch: 174, loss: 0.169666
global_step: 6936, epoch: 174, loss: 0.172686
global_step: 6937, epoch: 174, loss: 0.209113
global_step: 6938, epoch: 174, loss: 0.239371
global_step: 6939, epoch: 174, loss: 0.183168
global_step: 6940, epoch: 174, loss: 0.238471
global_step: 6941, epoch: 174, loss: 0.153100
global_step: 6942, epoch: 174, loss: 0.173699
global_step: 6943, epoch: 174, loss: 0.208881
global_step: 6944, epoch: 174, loss: 0.195411
global_step: 6945, epoch: 174, loss: 0.284221
global_step: 6946, epoch: 174, loss: 0.172801
global_step: 6947, epoch: 174, loss: 0.192281
global_step: 6948, epoch: 174, loss: 0.162082
global_step: 6949, epoch: 174, loss: 0.291532
global_step: 6950, epoch: 174, loss: 0.216129
global_step: 6951, epoch: 174, loss: 0.154515
global_step: 6952, epoch: 174, loss: 0.241194
global_step: 6953, epoch: 174, loss: 0.161366
global_step: 6954, epoch: 174, loss: 0.250959
global_step: 6955, epoch: 174, loss: 0.172582
global_step: 6956, epoch: 174, loss: 0.258176
global_step: 6957, epoch: 174, loss: 0.203615
global_step: 6958, epoch: 174, loss: 0.213731
global_step: 6959, epoch: 174, loss: 0.202840
global_step: 6960, epoch: 174, loss: 0.847503
epoch: 174
train	acc: 0.9710	macro: p 0.9744, r 0.9587, f1: 0.9662	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5311	macro: p 0.3903, r 0.3070, f1: 0.3111	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4864
test	acc: 0.5747	macro: p 0.3583, r 0.3161, f1: 0.3198	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5403
global_step: 6961, epoch: 175, loss: 0.222664
global_step: 6962, epoch: 175, loss: 0.222245
global_step: 6963, epoch: 175, loss: 0.191455
global_step: 6964, epoch: 175, loss: 0.220691
global_step: 6965, epoch: 175, loss: 0.192988
global_step: 6966, epoch: 175, loss: 0.175990
global_step: 6967, epoch: 175, loss: 0.199655
global_step: 6968, epoch: 175, loss: 0.179127
global_step: 6969, epoch: 175, loss: 0.190167
global_step: 6970, epoch: 175, loss: 0.228822
global_step: 6971, epoch: 175, loss: 0.158540
global_step: 6972, epoch: 175, loss: 0.153170
global_step: 6973, epoch: 175, loss: 0.159260
global_step: 6974, epoch: 175, loss: 0.191534
global_step: 6975, epoch: 175, loss: 0.178651
global_step: 6976, epoch: 175, loss: 0.245315
global_step: 6977, epoch: 175, loss: 0.213720
global_step: 6978, epoch: 175, loss: 0.135096
global_step: 6979, epoch: 175, loss: 0.161747
global_step: 6980, epoch: 175, loss: 0.234574
global_step: 6981, epoch: 175, loss: 0.171281
global_step: 6982, epoch: 175, loss: 0.263313
global_step: 6983, epoch: 175, loss: 0.178360
global_step: 6984, epoch: 175, loss: 0.201527
global_step: 6985, epoch: 175, loss: 0.174833
global_step: 6986, epoch: 175, loss: 0.196387
global_step: 6987, epoch: 175, loss: 0.179120
global_step: 6988, epoch: 175, loss: 0.178275
global_step: 6989, epoch: 175, loss: 0.147605
global_step: 6990, epoch: 175, loss: 0.176993
global_step: 6991, epoch: 175, loss: 0.288636
global_step: 6992, epoch: 175, loss: 0.156283
global_step: 6993, epoch: 175, loss: 0.248335
global_step: 6994, epoch: 175, loss: 0.218275
global_step: 6995, epoch: 175, loss: 0.239559
global_step: 6996, epoch: 175, loss: 0.127039
global_step: 6997, epoch: 175, loss: 0.127222
global_step: 6998, epoch: 175, loss: 0.208350
global_step: 6999, epoch: 175, loss: 0.225367
global_step: 7000, epoch: 175, loss: 0.064483
epoch: 175
train	acc: 0.9718	macro: p 0.9747, r 0.9608, f1: 0.9675	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5329	macro: p 0.3918, r 0.3047, f1: 0.3105	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4849
test	acc: 0.5797	macro: p 0.3670, r 0.3143, f1: 0.3202	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5414
global_step: 7001, epoch: 176, loss: 0.190228
global_step: 7002, epoch: 176, loss: 0.182069
global_step: 7003, epoch: 176, loss: 0.186869
global_step: 7004, epoch: 176, loss: 0.190889
global_step: 7005, epoch: 176, loss: 0.172748
global_step: 7006, epoch: 176, loss: 0.220555
global_step: 7007, epoch: 176, loss: 0.210769
global_step: 7008, epoch: 176, loss: 0.175106
global_step: 7009, epoch: 176, loss: 0.230126
global_step: 7010, epoch: 176, loss: 0.229493
global_step: 7011, epoch: 176, loss: 0.111483
global_step: 7012, epoch: 176, loss: 0.175735
global_step: 7013, epoch: 176, loss: 0.217811
global_step: 7014, epoch: 176, loss: 0.168408
global_step: 7015, epoch: 176, loss: 0.116566
global_step: 7016, epoch: 176, loss: 0.164068
global_step: 7017, epoch: 176, loss: 0.199549
global_step: 7018, epoch: 176, loss: 0.188398
global_step: 7019, epoch: 176, loss: 0.147268
global_step: 7020, epoch: 176, loss: 0.198457
global_step: 7021, epoch: 176, loss: 0.197861
global_step: 7022, epoch: 176, loss: 0.212049
global_step: 7023, epoch: 176, loss: 0.182035
global_step: 7024, epoch: 176, loss: 0.216758
global_step: 7025, epoch: 176, loss: 0.160133
global_step: 7026, epoch: 176, loss: 0.160420
global_step: 7027, epoch: 176, loss: 0.287363
global_step: 7028, epoch: 176, loss: 0.175153
global_step: 7029, epoch: 176, loss: 0.206653
global_step: 7030, epoch: 176, loss: 0.185392
global_step: 7031, epoch: 176, loss: 0.204729
global_step: 7032, epoch: 176, loss: 0.248622
global_step: 7033, epoch: 176, loss: 0.185635
global_step: 7034, epoch: 176, loss: 0.179912
global_step: 7035, epoch: 176, loss: 0.205366
global_step: 7036, epoch: 176, loss: 0.207222
global_step: 7037, epoch: 176, loss: 0.241109
global_step: 7038, epoch: 176, loss: 0.146688
global_step: 7039, epoch: 176, loss: 0.156740
global_step: 7040, epoch: 176, loss: 0.113898
epoch: 176
train	acc: 0.9715	macro: p 0.9761, r 0.9582, f1: 0.9668	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5266	macro: p 0.3846, r 0.2964, f1: 0.3010	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4756
test	acc: 0.5801	macro: p 0.3870, r 0.3111, f1: 0.3182	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5372
global_step: 7041, epoch: 177, loss: 0.198186
global_step: 7042, epoch: 177, loss: 0.181767
global_step: 7043, epoch: 177, loss: 0.260667
global_step: 7044, epoch: 177, loss: 0.185010
global_step: 7045, epoch: 177, loss: 0.177464
global_step: 7046, epoch: 177, loss: 0.192817
global_step: 7047, epoch: 177, loss: 0.125710
global_step: 7048, epoch: 177, loss: 0.256746
global_step: 7049, epoch: 177, loss: 0.214986
global_step: 7050, epoch: 177, loss: 0.180864
global_step: 7051, epoch: 177, loss: 0.206273
global_step: 7052, epoch: 177, loss: 0.236728
global_step: 7053, epoch: 177, loss: 0.229936
global_step: 7054, epoch: 177, loss: 0.205532
global_step: 7055, epoch: 177, loss: 0.120996
global_step: 7056, epoch: 177, loss: 0.139765
global_step: 7057, epoch: 177, loss: 0.182284
global_step: 7058, epoch: 177, loss: 0.183387
global_step: 7059, epoch: 177, loss: 0.224003
global_step: 7060, epoch: 177, loss: 0.175888
global_step: 7061, epoch: 177, loss: 0.166491
global_step: 7062, epoch: 177, loss: 0.236254
global_step: 7063, epoch: 177, loss: 0.168008
global_step: 7064, epoch: 177, loss: 0.196669
global_step: 7065, epoch: 177, loss: 0.246568
global_step: 7066, epoch: 177, loss: 0.170904
global_step: 7067, epoch: 177, loss: 0.164233
global_step: 7068, epoch: 177, loss: 0.164041
global_step: 7069, epoch: 177, loss: 0.173649
global_step: 7070, epoch: 177, loss: 0.165658
global_step: 7071, epoch: 177, loss: 0.158748
global_step: 7072, epoch: 177, loss: 0.228359
global_step: 7073, epoch: 177, loss: 0.214730
global_step: 7074, epoch: 177, loss: 0.216431
global_step: 7075, epoch: 177, loss: 0.154615
global_step: 7076, epoch: 177, loss: 0.284285
global_step: 7077, epoch: 177, loss: 0.195884
global_step: 7078, epoch: 177, loss: 0.180854
global_step: 7079, epoch: 177, loss: 0.157821
global_step: 7080, epoch: 177, loss: 0.075330
epoch: 177
train	acc: 0.9717	macro: p 0.9734, r 0.9608, f1: 0.9669	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5338	macro: p 0.4039, r 0.3134, f1: 0.3210	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4877
test	acc: 0.5797	macro: p 0.3905, r 0.3202, f1: 0.3291	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5416
global_step: 7081, epoch: 178, loss: 0.159901
global_step: 7082, epoch: 178, loss: 0.095407
global_step: 7083, epoch: 178, loss: 0.219812
global_step: 7084, epoch: 178, loss: 0.178684
global_step: 7085, epoch: 178, loss: 0.168676
global_step: 7086, epoch: 178, loss: 0.241837
global_step: 7087, epoch: 178, loss: 0.197403
global_step: 7088, epoch: 178, loss: 0.235609
global_step: 7089, epoch: 178, loss: 0.221752
global_step: 7090, epoch: 178, loss: 0.216662
global_step: 7091, epoch: 178, loss: 0.246267
global_step: 7092, epoch: 178, loss: 0.206001
global_step: 7093, epoch: 178, loss: 0.175550
global_step: 7094, epoch: 178, loss: 0.249406
global_step: 7095, epoch: 178, loss: 0.211430
global_step: 7096, epoch: 178, loss: 0.161021
global_step: 7097, epoch: 178, loss: 0.265261
global_step: 7098, epoch: 178, loss: 0.227438
global_step: 7099, epoch: 178, loss: 0.164970
global_step: 7100, epoch: 178, loss: 0.182883
global_step: 7101, epoch: 178, loss: 0.169033
global_step: 7102, epoch: 178, loss: 0.198483
global_step: 7103, epoch: 178, loss: 0.168391
global_step: 7104, epoch: 178, loss: 0.165844
global_step: 7105, epoch: 178, loss: 0.195048
global_step: 7106, epoch: 178, loss: 0.176551
global_step: 7107, epoch: 178, loss: 0.226320
global_step: 7108, epoch: 178, loss: 0.185888
global_step: 7109, epoch: 178, loss: 0.190339
global_step: 7110, epoch: 178, loss: 0.178507
global_step: 7111, epoch: 178, loss: 0.178054
global_step: 7112, epoch: 178, loss: 0.210196
global_step: 7113, epoch: 178, loss: 0.172495
global_step: 7114, epoch: 178, loss: 0.187759
global_step: 7115, epoch: 178, loss: 0.204822
global_step: 7116, epoch: 178, loss: 0.157163
global_step: 7117, epoch: 178, loss: 0.145339
global_step: 7118, epoch: 178, loss: 0.214743
global_step: 7119, epoch: 178, loss: 0.175148
global_step: 7120, epoch: 178, loss: 0.244796
epoch: 178
train	acc: 0.9718	macro: p 0.9751, r 0.9601, f1: 0.9673	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5320	macro: p 0.3997, r 0.3124, f1: 0.3196	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4868
test	acc: 0.5820	macro: p 0.3916, r 0.3245, f1: 0.3359	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5459
global_step: 7121, epoch: 179, loss: 0.154199
global_step: 7122, epoch: 179, loss: 0.132562
global_step: 7123, epoch: 179, loss: 0.155361
global_step: 7124, epoch: 179, loss: 0.179494
global_step: 7125, epoch: 179, loss: 0.218996
global_step: 7126, epoch: 179, loss: 0.177605
global_step: 7127, epoch: 179, loss: 0.144911
global_step: 7128, epoch: 179, loss: 0.167861
global_step: 7129, epoch: 179, loss: 0.205946
global_step: 7130, epoch: 179, loss: 0.199418
global_step: 7131, epoch: 179, loss: 0.205447
global_step: 7132, epoch: 179, loss: 0.157456
global_step: 7133, epoch: 179, loss: 0.216403
global_step: 7134, epoch: 179, loss: 0.245140
global_step: 7135, epoch: 179, loss: 0.230868
global_step: 7136, epoch: 179, loss: 0.193021
global_step: 7137, epoch: 179, loss: 0.195062
global_step: 7138, epoch: 179, loss: 0.178772
global_step: 7139, epoch: 179, loss: 0.220656
global_step: 7140, epoch: 179, loss: 0.172474
global_step: 7141, epoch: 179, loss: 0.163031
global_step: 7142, epoch: 179, loss: 0.167895
global_step: 7143, epoch: 179, loss: 0.295254
global_step: 7144, epoch: 179, loss: 0.199161
global_step: 7145, epoch: 179, loss: 0.172524
global_step: 7146, epoch: 179, loss: 0.216898
global_step: 7147, epoch: 179, loss: 0.212940
global_step: 7148, epoch: 179, loss: 0.174054
global_step: 7149, epoch: 179, loss: 0.230921
global_step: 7150, epoch: 179, loss: 0.181283
global_step: 7151, epoch: 179, loss: 0.214191
global_step: 7152, epoch: 179, loss: 0.227013
global_step: 7153, epoch: 179, loss: 0.231807
global_step: 7154, epoch: 179, loss: 0.168274
global_step: 7155, epoch: 179, loss: 0.263382
global_step: 7156, epoch: 179, loss: 0.229279
global_step: 7157, epoch: 179, loss: 0.184734
global_step: 7158, epoch: 179, loss: 0.200765
global_step: 7159, epoch: 179, loss: 0.205888
global_step: 7160, epoch: 179, loss: 0.152656
epoch: 179
train	acc: 0.9720	macro: p 0.9739, r 0.9625, f1: 0.9680	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5275	macro: p 0.4031, r 0.3162, f1: 0.3262	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4881
test	acc: 0.5743	macro: p 0.3807, r 0.3271, f1: 0.3366	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5448
global_step: 7161, epoch: 180, loss: 0.173531
global_step: 7162, epoch: 180, loss: 0.214230
global_step: 7163, epoch: 180, loss: 0.211806
global_step: 7164, epoch: 180, loss: 0.207193
global_step: 7165, epoch: 180, loss: 0.151319
global_step: 7166, epoch: 180, loss: 0.273428
global_step: 7167, epoch: 180, loss: 0.179803
global_step: 7168, epoch: 180, loss: 0.236152
global_step: 7169, epoch: 180, loss: 0.237328
global_step: 7170, epoch: 180, loss: 0.229589
global_step: 7171, epoch: 180, loss: 0.189801
global_step: 7172, epoch: 180, loss: 0.153341
global_step: 7173, epoch: 180, loss: 0.159008
global_step: 7174, epoch: 180, loss: 0.190438
global_step: 7175, epoch: 180, loss: 0.155497
global_step: 7176, epoch: 180, loss: 0.220922
global_step: 7177, epoch: 180, loss: 0.138990
global_step: 7178, epoch: 180, loss: 0.155922
global_step: 7179, epoch: 180, loss: 0.150110
global_step: 7180, epoch: 180, loss: 0.217214
global_step: 7181, epoch: 180, loss: 0.246405
global_step: 7182, epoch: 180, loss: 0.329907
global_step: 7183, epoch: 180, loss: 0.215497
global_step: 7184, epoch: 180, loss: 0.159217
global_step: 7185, epoch: 180, loss: 0.185685
global_step: 7186, epoch: 180, loss: 0.171046
global_step: 7187, epoch: 180, loss: 0.212526
global_step: 7188, epoch: 180, loss: 0.304974
global_step: 7189, epoch: 180, loss: 0.198969
global_step: 7190, epoch: 180, loss: 0.107765
global_step: 7191, epoch: 180, loss: 0.174871
global_step: 7192, epoch: 180, loss: 0.173653
global_step: 7193, epoch: 180, loss: 0.228747
global_step: 7194, epoch: 180, loss: 0.229166
global_step: 7195, epoch: 180, loss: 0.202888
global_step: 7196, epoch: 180, loss: 0.199893
global_step: 7197, epoch: 180, loss: 0.125395
global_step: 7198, epoch: 180, loss: 0.286217
global_step: 7199, epoch: 180, loss: 0.224610
global_step: 7200, epoch: 180, loss: 0.036941
epoch: 180
train	acc: 0.9721	macro: p 0.9745, r 0.9621, f1: 0.9681	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5266	macro: p 0.3911, r 0.3035, f1: 0.3093	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4809
test	acc: 0.5835	macro: p 0.4006, r 0.3259, f1: 0.3367	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5485
global_step: 7201, epoch: 181, loss: 0.129869
global_step: 7202, epoch: 181, loss: 0.224330
global_step: 7203, epoch: 181, loss: 0.162014
global_step: 7204, epoch: 181, loss: 0.214633
global_step: 7205, epoch: 181, loss: 0.165606
global_step: 7206, epoch: 181, loss: 0.205397
global_step: 7207, epoch: 181, loss: 0.201996
global_step: 7208, epoch: 181, loss: 0.189660
global_step: 7209, epoch: 181, loss: 0.212329
global_step: 7210, epoch: 181, loss: 0.133803
global_step: 7211, epoch: 181, loss: 0.167784
global_step: 7212, epoch: 181, loss: 0.174650
global_step: 7213, epoch: 181, loss: 0.142912
global_step: 7214, epoch: 181, loss: 0.163871
global_step: 7215, epoch: 181, loss: 0.247140
global_step: 7216, epoch: 181, loss: 0.180590
global_step: 7217, epoch: 181, loss: 0.166551
global_step: 7218, epoch: 181, loss: 0.232268
global_step: 7219, epoch: 181, loss: 0.180606
global_step: 7220, epoch: 181, loss: 0.200341
global_step: 7221, epoch: 181, loss: 0.159056
global_step: 7222, epoch: 181, loss: 0.221463
global_step: 7223, epoch: 181, loss: 0.187613
global_step: 7224, epoch: 181, loss: 0.225534
global_step: 7225, epoch: 181, loss: 0.168600
global_step: 7226, epoch: 181, loss: 0.243180
global_step: 7227, epoch: 181, loss: 0.168835
global_step: 7228, epoch: 181, loss: 0.171047
global_step: 7229, epoch: 181, loss: 0.175889
global_step: 7230, epoch: 181, loss: 0.208090
global_step: 7231, epoch: 181, loss: 0.172697
global_step: 7232, epoch: 181, loss: 0.225250
global_step: 7233, epoch: 181, loss: 0.156613
global_step: 7234, epoch: 181, loss: 0.217752
global_step: 7235, epoch: 181, loss: 0.162585
global_step: 7236, epoch: 181, loss: 0.110245
global_step: 7237, epoch: 181, loss: 0.244115
global_step: 7238, epoch: 181, loss: 0.185442
global_step: 7239, epoch: 181, loss: 0.274259
global_step: 7240, epoch: 181, loss: 0.065664
epoch: 181
train	acc: 0.9722	macro: p 0.9743, r 0.9624, f1: 0.9682	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5320	macro: p 0.4252, r 0.3127, f1: 0.3216	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4877
test	acc: 0.5789	macro: p 0.3939, r 0.3270, f1: 0.3372	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5458
global_step: 7241, epoch: 182, loss: 0.181958
global_step: 7242, epoch: 182, loss: 0.192462
global_step: 7243, epoch: 182, loss: 0.113530
global_step: 7244, epoch: 182, loss: 0.182518
global_step: 7245, epoch: 182, loss: 0.176919
global_step: 7246, epoch: 182, loss: 0.175802
global_step: 7247, epoch: 182, loss: 0.203240
global_step: 7248, epoch: 182, loss: 0.308147
global_step: 7249, epoch: 182, loss: 0.152316
global_step: 7250, epoch: 182, loss: 0.232103
global_step: 7251, epoch: 182, loss: 0.134421
global_step: 7252, epoch: 182, loss: 0.147532
global_step: 7253, epoch: 182, loss: 0.256182
global_step: 7254, epoch: 182, loss: 0.198746
global_step: 7255, epoch: 182, loss: 0.204086
global_step: 7256, epoch: 182, loss: 0.216184
global_step: 7257, epoch: 182, loss: 0.161965
global_step: 7258, epoch: 182, loss: 0.140535
global_step: 7259, epoch: 182, loss: 0.184767
global_step: 7260, epoch: 182, loss: 0.189950
global_step: 7261, epoch: 182, loss: 0.173486
global_step: 7262, epoch: 182, loss: 0.190370
global_step: 7263, epoch: 182, loss: 0.221385
global_step: 7264, epoch: 182, loss: 0.254738
global_step: 7265, epoch: 182, loss: 0.180302
global_step: 7266, epoch: 182, loss: 0.174564
global_step: 7267, epoch: 182, loss: 0.172787
global_step: 7268, epoch: 182, loss: 0.164950
global_step: 7269, epoch: 182, loss: 0.146115
global_step: 7270, epoch: 182, loss: 0.163183
global_step: 7271, epoch: 182, loss: 0.165836
global_step: 7272, epoch: 182, loss: 0.162178
global_step: 7273, epoch: 182, loss: 0.206590
global_step: 7274, epoch: 182, loss: 0.216205
global_step: 7275, epoch: 182, loss: 0.219463
global_step: 7276, epoch: 182, loss: 0.179617
global_step: 7277, epoch: 182, loss: 0.233471
global_step: 7278, epoch: 182, loss: 0.195779
global_step: 7279, epoch: 182, loss: 0.284721
global_step: 7280, epoch: 182, loss: 0.173182
epoch: 182
train	acc: 0.9715	macro: p 0.9761, r 0.9584, f1: 0.9670	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5311	macro: p 0.4534, r 0.3052, f1: 0.3162	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4813
test	acc: 0.5808	macro: p 0.3883, r 0.3105, f1: 0.3182	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5396
global_step: 7281, epoch: 183, loss: 0.156838
global_step: 7282, epoch: 183, loss: 0.207019
global_step: 7283, epoch: 183, loss: 0.235256
global_step: 7284, epoch: 183, loss: 0.187086
global_step: 7285, epoch: 183, loss: 0.193803
global_step: 7286, epoch: 183, loss: 0.131593
global_step: 7287, epoch: 183, loss: 0.182997
global_step: 7288, epoch: 183, loss: 0.209369
global_step: 7289, epoch: 183, loss: 0.250808
global_step: 7290, epoch: 183, loss: 0.137758
global_step: 7291, epoch: 183, loss: 0.114854
global_step: 7292, epoch: 183, loss: 0.163768
global_step: 7293, epoch: 183, loss: 0.163799
global_step: 7294, epoch: 183, loss: 0.267806
global_step: 7295, epoch: 183, loss: 0.181060
global_step: 7296, epoch: 183, loss: 0.175151
global_step: 7297, epoch: 183, loss: 0.164218
global_step: 7298, epoch: 183, loss: 0.197696
global_step: 7299, epoch: 183, loss: 0.183480
global_step: 7300, epoch: 183, loss: 0.206423
global_step: 7301, epoch: 183, loss: 0.134819
global_step: 7302, epoch: 183, loss: 0.174604
global_step: 7303, epoch: 183, loss: 0.156353
global_step: 7304, epoch: 183, loss: 0.167308
global_step: 7305, epoch: 183, loss: 0.205575
global_step: 7306, epoch: 183, loss: 0.196923
global_step: 7307, epoch: 183, loss: 0.162731
global_step: 7308, epoch: 183, loss: 0.180663
global_step: 7309, epoch: 183, loss: 0.220257
global_step: 7310, epoch: 183, loss: 0.289469
global_step: 7311, epoch: 183, loss: 0.173420
global_step: 7312, epoch: 183, loss: 0.215141
global_step: 7313, epoch: 183, loss: 0.228514
global_step: 7314, epoch: 183, loss: 0.167316
global_step: 7315, epoch: 183, loss: 0.197118
global_step: 7316, epoch: 183, loss: 0.159743
global_step: 7317, epoch: 183, loss: 0.291157
global_step: 7318, epoch: 183, loss: 0.222460
global_step: 7319, epoch: 183, loss: 0.181181
global_step: 7320, epoch: 183, loss: 0.031379
epoch: 183
train	acc: 0.9721	macro: p 0.9740, r 0.9626, f1: 0.9682	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5320	macro: p 0.4637, r 0.3165, f1: 0.3317	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4886
test	acc: 0.5874	macro: p 0.3979, r 0.3223, f1: 0.3309	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5503
global_step: 7321, epoch: 184, loss: 0.187761
global_step: 7322, epoch: 184, loss: 0.181644
global_step: 7323, epoch: 184, loss: 0.210098
global_step: 7324, epoch: 184, loss: 0.136972
global_step: 7325, epoch: 184, loss: 0.159873
global_step: 7326, epoch: 184, loss: 0.197761
global_step: 7327, epoch: 184, loss: 0.170613
global_step: 7328, epoch: 184, loss: 0.188141
global_step: 7329, epoch: 184, loss: 0.208454
global_step: 7330, epoch: 184, loss: 0.201238
global_step: 7331, epoch: 184, loss: 0.163674
global_step: 7332, epoch: 184, loss: 0.126929
global_step: 7333, epoch: 184, loss: 0.270552
global_step: 7334, epoch: 184, loss: 0.177862
global_step: 7335, epoch: 184, loss: 0.256915
global_step: 7336, epoch: 184, loss: 0.154110
global_step: 7337, epoch: 184, loss: 0.195308
global_step: 7338, epoch: 184, loss: 0.138327
global_step: 7339, epoch: 184, loss: 0.168794
global_step: 7340, epoch: 184, loss: 0.192113
global_step: 7341, epoch: 184, loss: 0.151712
global_step: 7342, epoch: 184, loss: 0.189943
global_step: 7343, epoch: 184, loss: 0.276012
global_step: 7344, epoch: 184, loss: 0.107795
global_step: 7345, epoch: 184, loss: 0.262159
global_step: 7346, epoch: 184, loss: 0.286933
global_step: 7347, epoch: 184, loss: 0.217368
global_step: 7348, epoch: 184, loss: 0.149102
global_step: 7349, epoch: 184, loss: 0.148928
global_step: 7350, epoch: 184, loss: 0.220966
global_step: 7351, epoch: 184, loss: 0.183660
global_step: 7352, epoch: 184, loss: 0.200879
global_step: 7353, epoch: 184, loss: 0.215830
global_step: 7354, epoch: 184, loss: 0.150200
global_step: 7355, epoch: 184, loss: 0.177118
global_step: 7356, epoch: 184, loss: 0.180185
global_step: 7357, epoch: 184, loss: 0.207431
global_step: 7358, epoch: 184, loss: 0.208520
global_step: 7359, epoch: 184, loss: 0.208454
global_step: 7360, epoch: 184, loss: 0.080080
epoch: 184
train	acc: 0.9720	macro: p 0.9743, r 0.9620, f1: 0.9680	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5302	macro: p 0.4364, r 0.3132, f1: 0.3252	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4867
test	acc: 0.5805	macro: p 0.4182, r 0.3259, f1: 0.3369	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5457
global_step: 7361, epoch: 185, loss: 0.236212
global_step: 7362, epoch: 185, loss: 0.198059
global_step: 7363, epoch: 185, loss: 0.167567
global_step: 7364, epoch: 185, loss: 0.177134
global_step: 7365, epoch: 185, loss: 0.197866
global_step: 7366, epoch: 185, loss: 0.143337
global_step: 7367, epoch: 185, loss: 0.201591
global_step: 7368, epoch: 185, loss: 0.195131
global_step: 7369, epoch: 185, loss: 0.179349
global_step: 7370, epoch: 185, loss: 0.215865
global_step: 7371, epoch: 185, loss: 0.161473
global_step: 7372, epoch: 185, loss: 0.172337
global_step: 7373, epoch: 185, loss: 0.244561
global_step: 7374, epoch: 185, loss: 0.145162
global_step: 7375, epoch: 185, loss: 0.199908
global_step: 7376, epoch: 185, loss: 0.164610
global_step: 7377, epoch: 185, loss: 0.200912
global_step: 7378, epoch: 185, loss: 0.227593
global_step: 7379, epoch: 185, loss: 0.212152
global_step: 7380, epoch: 185, loss: 0.162545
global_step: 7381, epoch: 185, loss: 0.193178
global_step: 7382, epoch: 185, loss: 0.199194
global_step: 7383, epoch: 185, loss: 0.157926
global_step: 7384, epoch: 185, loss: 0.183026
global_step: 7385, epoch: 185, loss: 0.168725
global_step: 7386, epoch: 185, loss: 0.181113
global_step: 7387, epoch: 185, loss: 0.246819
global_step: 7388, epoch: 185, loss: 0.195434
global_step: 7389, epoch: 185, loss: 0.157960
global_step: 7390, epoch: 185, loss: 0.152755
global_step: 7391, epoch: 185, loss: 0.205557
global_step: 7392, epoch: 185, loss: 0.290731
global_step: 7393, epoch: 185, loss: 0.191976
global_step: 7394, epoch: 185, loss: 0.209468
global_step: 7395, epoch: 185, loss: 0.164437
global_step: 7396, epoch: 185, loss: 0.198037
global_step: 7397, epoch: 185, loss: 0.226514
global_step: 7398, epoch: 185, loss: 0.211623
global_step: 7399, epoch: 185, loss: 0.146226
global_step: 7400, epoch: 185, loss: 0.185379
epoch: 185
train	acc: 0.9718	macro: p 0.9749, r 0.9617, f1: 0.9680	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5302	macro: p 0.4420, r 0.3144, f1: 0.3246	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4873
test	acc: 0.5831	macro: p 0.4157, r 0.3238, f1: 0.3326	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5469
global_step: 7401, epoch: 186, loss: 0.187364
global_step: 7402, epoch: 186, loss: 0.134026
global_step: 7403, epoch: 186, loss: 0.191651
global_step: 7404, epoch: 186, loss: 0.184501
global_step: 7405, epoch: 186, loss: 0.138154
global_step: 7406, epoch: 186, loss: 0.166280
global_step: 7407, epoch: 186, loss: 0.121799
global_step: 7408, epoch: 186, loss: 0.154268
global_step: 7409, epoch: 186, loss: 0.187530
global_step: 7410, epoch: 186, loss: 0.193069
global_step: 7411, epoch: 186, loss: 0.189715
global_step: 7412, epoch: 186, loss: 0.246239
global_step: 7413, epoch: 186, loss: 0.218930
global_step: 7414, epoch: 186, loss: 0.157765
global_step: 7415, epoch: 186, loss: 0.193923
global_step: 7416, epoch: 186, loss: 0.178471
global_step: 7417, epoch: 186, loss: 0.213449
global_step: 7418, epoch: 186, loss: 0.211708
global_step: 7419, epoch: 186, loss: 0.213856
global_step: 7420, epoch: 186, loss: 0.093029
global_step: 7421, epoch: 186, loss: 0.221871
global_step: 7422, epoch: 186, loss: 0.197196
global_step: 7423, epoch: 186, loss: 0.184795
global_step: 7424, epoch: 186, loss: 0.267317
global_step: 7425, epoch: 186, loss: 0.180851
global_step: 7426, epoch: 186, loss: 0.193510
global_step: 7427, epoch: 186, loss: 0.172881
global_step: 7428, epoch: 186, loss: 0.185669
global_step: 7429, epoch: 186, loss: 0.103366
global_step: 7430, epoch: 186, loss: 0.237409
global_step: 7431, epoch: 186, loss: 0.140968
global_step: 7432, epoch: 186, loss: 0.191978
global_step: 7433, epoch: 186, loss: 0.174149
global_step: 7434, epoch: 186, loss: 0.202201
global_step: 7435, epoch: 186, loss: 0.237917
global_step: 7436, epoch: 186, loss: 0.153281
global_step: 7437, epoch: 186, loss: 0.185069
global_step: 7438, epoch: 186, loss: 0.198463
global_step: 7439, epoch: 186, loss: 0.195071
global_step: 7440, epoch: 186, loss: 0.036838
epoch: 186
train	acc: 0.9722	macro: p 0.9757, r 0.9599, f1: 0.9675	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5248	macro: p 0.4053, r 0.3067, f1: 0.3160	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4795
test	acc: 0.5854	macro: p 0.3883, r 0.3189, f1: 0.3269	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5453
global_step: 7441, epoch: 187, loss: 0.185778
global_step: 7442, epoch: 187, loss: 0.225684
global_step: 7443, epoch: 187, loss: 0.120582
global_step: 7444, epoch: 187, loss: 0.212510
global_step: 7445, epoch: 187, loss: 0.151077
global_step: 7446, epoch: 187, loss: 0.214388
global_step: 7447, epoch: 187, loss: 0.148325
global_step: 7448, epoch: 187, loss: 0.182802
global_step: 7449, epoch: 187, loss: 0.114299
global_step: 7450, epoch: 187, loss: 0.199338
global_step: 7451, epoch: 187, loss: 0.170527
global_step: 7452, epoch: 187, loss: 0.182095
global_step: 7453, epoch: 187, loss: 0.129697
global_step: 7454, epoch: 187, loss: 0.182766
global_step: 7455, epoch: 187, loss: 0.158027
global_step: 7456, epoch: 187, loss: 0.152964
global_step: 7457, epoch: 187, loss: 0.174313
global_step: 7458, epoch: 187, loss: 0.160945
global_step: 7459, epoch: 187, loss: 0.171399
global_step: 7460, epoch: 187, loss: 0.184636
global_step: 7461, epoch: 187, loss: 0.163429
global_step: 7462, epoch: 187, loss: 0.184433
global_step: 7463, epoch: 187, loss: 0.114509
global_step: 7464, epoch: 187, loss: 0.171934
global_step: 7465, epoch: 187, loss: 0.233917
global_step: 7466, epoch: 187, loss: 0.215758
global_step: 7467, epoch: 187, loss: 0.191912
global_step: 7468, epoch: 187, loss: 0.203885
global_step: 7469, epoch: 187, loss: 0.247003
global_step: 7470, epoch: 187, loss: 0.144198
global_step: 7471, epoch: 187, loss: 0.209204
global_step: 7472, epoch: 187, loss: 0.219540
global_step: 7473, epoch: 187, loss: 0.179261
global_step: 7474, epoch: 187, loss: 0.250181
global_step: 7475, epoch: 187, loss: 0.207551
global_step: 7476, epoch: 187, loss: 0.259211
global_step: 7477, epoch: 187, loss: 0.130740
global_step: 7478, epoch: 187, loss: 0.257948
global_step: 7479, epoch: 187, loss: 0.158917
global_step: 7480, epoch: 187, loss: 0.489771
epoch: 187
train	acc: 0.9722	macro: p 0.9758, r 0.9619, f1: 0.9686	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5293	macro: p 0.5035, r 0.3092, f1: 0.3163	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4827
test	acc: 0.5839	macro: p 0.4033, r 0.3179, f1: 0.3249	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5449
global_step: 7481, epoch: 188, loss: 0.155675
global_step: 7482, epoch: 188, loss: 0.176727
global_step: 7483, epoch: 188, loss: 0.219204
global_step: 7484, epoch: 188, loss: 0.151562
global_step: 7485, epoch: 188, loss: 0.186233
global_step: 7486, epoch: 188, loss: 0.123564
global_step: 7487, epoch: 188, loss: 0.147936
global_step: 7488, epoch: 188, loss: 0.191982
global_step: 7489, epoch: 188, loss: 0.181917
global_step: 7490, epoch: 188, loss: 0.172070
global_step: 7491, epoch: 188, loss: 0.187977
global_step: 7492, epoch: 188, loss: 0.202549
global_step: 7493, epoch: 188, loss: 0.126344
global_step: 7494, epoch: 188, loss: 0.222415
global_step: 7495, epoch: 188, loss: 0.157559
global_step: 7496, epoch: 188, loss: 0.144736
global_step: 7497, epoch: 188, loss: 0.206483
global_step: 7498, epoch: 188, loss: 0.222767
global_step: 7499, epoch: 188, loss: 0.205355
global_step: 7500, epoch: 188, loss: 0.147130
global_step: 7501, epoch: 188, loss: 0.208191
global_step: 7502, epoch: 188, loss: 0.135424
global_step: 7503, epoch: 188, loss: 0.151393
global_step: 7504, epoch: 188, loss: 0.189078
global_step: 7505, epoch: 188, loss: 0.165828
global_step: 7506, epoch: 188, loss: 0.195562
global_step: 7507, epoch: 188, loss: 0.145195
global_step: 7508, epoch: 188, loss: 0.198666
global_step: 7509, epoch: 188, loss: 0.192158
global_step: 7510, epoch: 188, loss: 0.182646
global_step: 7511, epoch: 188, loss: 0.208116
global_step: 7512, epoch: 188, loss: 0.227697
global_step: 7513, epoch: 188, loss: 0.192237
global_step: 7514, epoch: 188, loss: 0.211607
global_step: 7515, epoch: 188, loss: 0.191932
global_step: 7516, epoch: 188, loss: 0.192935
global_step: 7517, epoch: 188, loss: 0.204530
global_step: 7518, epoch: 188, loss: 0.213236
global_step: 7519, epoch: 188, loss: 0.187921
global_step: 7520, epoch: 188, loss: 0.026586
epoch: 188
train	acc: 0.9720	macro: p 0.9754, r 0.9622, f1: 0.9686	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5338	macro: p 0.4467, r 0.3178, f1: 0.3264	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4892
test	acc: 0.5805	macro: p 0.3989, r 0.3219, f1: 0.3270	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5451
global_step: 7521, epoch: 189, loss: 0.195533
global_step: 7522, epoch: 189, loss: 0.164172
global_step: 7523, epoch: 189, loss: 0.175780
global_step: 7524, epoch: 189, loss: 0.218528
global_step: 7525, epoch: 189, loss: 0.167237
global_step: 7526, epoch: 189, loss: 0.166100
global_step: 7527, epoch: 189, loss: 0.210682
global_step: 7528, epoch: 189, loss: 0.169378
global_step: 7529, epoch: 189, loss: 0.188850
global_step: 7530, epoch: 189, loss: 0.207417
global_step: 7531, epoch: 189, loss: 0.147088
global_step: 7532, epoch: 189, loss: 0.150024
global_step: 7533, epoch: 189, loss: 0.188056
global_step: 7534, epoch: 189, loss: 0.203965
global_step: 7535, epoch: 189, loss: 0.177775
global_step: 7536, epoch: 189, loss: 0.167971
global_step: 7537, epoch: 189, loss: 0.188098
global_step: 7538, epoch: 189, loss: 0.217437
global_step: 7539, epoch: 189, loss: 0.139788
global_step: 7540, epoch: 189, loss: 0.222052
global_step: 7541, epoch: 189, loss: 0.195979
global_step: 7542, epoch: 189, loss: 0.150889
global_step: 7543, epoch: 189, loss: 0.145499
global_step: 7544, epoch: 189, loss: 0.192231
global_step: 7545, epoch: 189, loss: 0.153070
global_step: 7546, epoch: 189, loss: 0.202469
global_step: 7547, epoch: 189, loss: 0.183902
global_step: 7548, epoch: 189, loss: 0.155249
global_step: 7549, epoch: 189, loss: 0.167696
global_step: 7550, epoch: 189, loss: 0.159718
global_step: 7551, epoch: 189, loss: 0.180875
global_step: 7552, epoch: 189, loss: 0.170937
global_step: 7553, epoch: 189, loss: 0.200106
global_step: 7554, epoch: 189, loss: 0.164436
global_step: 7555, epoch: 189, loss: 0.221651
global_step: 7556, epoch: 189, loss: 0.260988
global_step: 7557, epoch: 189, loss: 0.221226
global_step: 7558, epoch: 189, loss: 0.206458
global_step: 7559, epoch: 189, loss: 0.222997
global_step: 7560, epoch: 189, loss: 0.245481
epoch: 189
train	acc: 0.9723	macro: p 0.9750, r 0.9619, f1: 0.9682	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5401	macro: p 0.4439, r 0.3160, f1: 0.3284	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4933
test	acc: 0.5854	macro: p 0.3957, r 0.3214, f1: 0.3309	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5460
global_step: 7561, epoch: 190, loss: 0.153659
global_step: 7562, epoch: 190, loss: 0.164996
global_step: 7563, epoch: 190, loss: 0.186543
global_step: 7564, epoch: 190, loss: 0.137431
global_step: 7565, epoch: 190, loss: 0.173376
global_step: 7566, epoch: 190, loss: 0.167258
global_step: 7567, epoch: 190, loss: 0.188413
global_step: 7568, epoch: 190, loss: 0.164406
global_step: 7569, epoch: 190, loss: 0.173549
global_step: 7570, epoch: 190, loss: 0.178106
global_step: 7571, epoch: 190, loss: 0.168231
global_step: 7572, epoch: 190, loss: 0.191317
global_step: 7573, epoch: 190, loss: 0.212673
global_step: 7574, epoch: 190, loss: 0.148946
global_step: 7575, epoch: 190, loss: 0.159346
global_step: 7576, epoch: 190, loss: 0.205860
global_step: 7577, epoch: 190, loss: 0.219438
global_step: 7578, epoch: 190, loss: 0.183911
global_step: 7579, epoch: 190, loss: 0.194386
global_step: 7580, epoch: 190, loss: 0.178338
global_step: 7581, epoch: 190, loss: 0.230790
global_step: 7582, epoch: 190, loss: 0.209545
global_step: 7583, epoch: 190, loss: 0.176370
global_step: 7584, epoch: 190, loss: 0.200598
global_step: 7585, epoch: 190, loss: 0.184574
global_step: 7586, epoch: 190, loss: 0.180987
global_step: 7587, epoch: 190, loss: 0.153248
global_step: 7588, epoch: 190, loss: 0.178016
global_step: 7589, epoch: 190, loss: 0.290918
global_step: 7590, epoch: 190, loss: 0.258807
global_step: 7591, epoch: 190, loss: 0.180514
global_step: 7592, epoch: 190, loss: 0.289920
global_step: 7593, epoch: 190, loss: 0.170525
global_step: 7594, epoch: 190, loss: 0.207048
global_step: 7595, epoch: 190, loss: 0.200381
global_step: 7596, epoch: 190, loss: 0.149176
global_step: 7597, epoch: 190, loss: 0.196296
global_step: 7598, epoch: 190, loss: 0.185997
global_step: 7599, epoch: 190, loss: 0.142651
global_step: 7600, epoch: 190, loss: 0.150154
epoch: 190
train	acc: 0.9724	macro: p 0.9750, r 0.9621, f1: 0.9683	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5356	macro: p 0.4408, r 0.3126, f1: 0.3219	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4881
test	acc: 0.5828	macro: p 0.3802, r 0.3196, f1: 0.3264	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5450
global_step: 7601, epoch: 191, loss: 0.145875
global_step: 7602, epoch: 191, loss: 0.150979
global_step: 7603, epoch: 191, loss: 0.180678
global_step: 7604, epoch: 191, loss: 0.183277
global_step: 7605, epoch: 191, loss: 0.192117
global_step: 7606, epoch: 191, loss: 0.162132
global_step: 7607, epoch: 191, loss: 0.173660
global_step: 7608, epoch: 191, loss: 0.158563
global_step: 7609, epoch: 191, loss: 0.191073
global_step: 7610, epoch: 191, loss: 0.163986
global_step: 7611, epoch: 191, loss: 0.154716
global_step: 7612, epoch: 191, loss: 0.159114
global_step: 7613, epoch: 191, loss: 0.139903
global_step: 7614, epoch: 191, loss: 0.152051
global_step: 7615, epoch: 191, loss: 0.196116
global_step: 7616, epoch: 191, loss: 0.231808
global_step: 7617, epoch: 191, loss: 0.170518
global_step: 7618, epoch: 191, loss: 0.192888
global_step: 7619, epoch: 191, loss: 0.108639
global_step: 7620, epoch: 191, loss: 0.118462
global_step: 7621, epoch: 191, loss: 0.138152
global_step: 7622, epoch: 191, loss: 0.158683
global_step: 7623, epoch: 191, loss: 0.185711
global_step: 7624, epoch: 191, loss: 0.187256
global_step: 7625, epoch: 191, loss: 0.171433
global_step: 7626, epoch: 191, loss: 0.158040
global_step: 7627, epoch: 191, loss: 0.187423
global_step: 7628, epoch: 191, loss: 0.194711
global_step: 7629, epoch: 191, loss: 0.175250
global_step: 7630, epoch: 191, loss: 0.151271
global_step: 7631, epoch: 191, loss: 0.182905
global_step: 7632, epoch: 191, loss: 0.166652
global_step: 7633, epoch: 191, loss: 0.275077
global_step: 7634, epoch: 191, loss: 0.261488
global_step: 7635, epoch: 191, loss: 0.165197
global_step: 7636, epoch: 191, loss: 0.198933
global_step: 7637, epoch: 191, loss: 0.168584
global_step: 7638, epoch: 191, loss: 0.222370
global_step: 7639, epoch: 191, loss: 0.161632
global_step: 7640, epoch: 191, loss: 0.289663
epoch: 191
train	acc: 0.9727	macro: p 0.9745, r 0.9637, f1: 0.9689	micro: p 0.9727, r 0.9727, f1 0.9727	weighted_f1:0.9727
dev	acc: 0.5284	macro: p 0.4907, r 0.2985, f1: 0.3088	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4771
test	acc: 0.5824	macro: p 0.3848, r 0.3119, f1: 0.3213	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5401
global_step: 7641, epoch: 192, loss: 0.210651
global_step: 7642, epoch: 192, loss: 0.206969
global_step: 7643, epoch: 192, loss: 0.195583
global_step: 7644, epoch: 192, loss: 0.210675
global_step: 7645, epoch: 192, loss: 0.143804
global_step: 7646, epoch: 192, loss: 0.193467
global_step: 7647, epoch: 192, loss: 0.120218
global_step: 7648, epoch: 192, loss: 0.146924
global_step: 7649, epoch: 192, loss: 0.208867
global_step: 7650, epoch: 192, loss: 0.157601
global_step: 7651, epoch: 192, loss: 0.206256
global_step: 7652, epoch: 192, loss: 0.118799
global_step: 7653, epoch: 192, loss: 0.248162
global_step: 7654, epoch: 192, loss: 0.202866
global_step: 7655, epoch: 192, loss: 0.191313
global_step: 7656, epoch: 192, loss: 0.134676
global_step: 7657, epoch: 192, loss: 0.157941
global_step: 7658, epoch: 192, loss: 0.172166
global_step: 7659, epoch: 192, loss: 0.177551
global_step: 7660, epoch: 192, loss: 0.207607
global_step: 7661, epoch: 192, loss: 0.237015
global_step: 7662, epoch: 192, loss: 0.152220
global_step: 7663, epoch: 192, loss: 0.166673
global_step: 7664, epoch: 192, loss: 0.199776
global_step: 7665, epoch: 192, loss: 0.164218
global_step: 7666, epoch: 192, loss: 0.237604
global_step: 7667, epoch: 192, loss: 0.195078
global_step: 7668, epoch: 192, loss: 0.194798
global_step: 7669, epoch: 192, loss: 0.207527
global_step: 7670, epoch: 192, loss: 0.193175
global_step: 7671, epoch: 192, loss: 0.164145
global_step: 7672, epoch: 192, loss: 0.120616
global_step: 7673, epoch: 192, loss: 0.125491
global_step: 7674, epoch: 192, loss: 0.169662
global_step: 7675, epoch: 192, loss: 0.225060
global_step: 7676, epoch: 192, loss: 0.219959
global_step: 7677, epoch: 192, loss: 0.225149
global_step: 7678, epoch: 192, loss: 0.186500
global_step: 7679, epoch: 192, loss: 0.160182
global_step: 7680, epoch: 192, loss: 0.300538
epoch: 192
train	acc: 0.9728	macro: p 0.9753, r 0.9621, f1: 0.9685	micro: p 0.9728, r 0.9728, f1 0.9728	weighted_f1:0.9728
dev	acc: 0.5284	macro: p 0.4462, r 0.3120, f1: 0.3239	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4815
test	acc: 0.5789	macro: p 0.3659, r 0.3176, f1: 0.3221	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5417
global_step: 7681, epoch: 193, loss: 0.160857
global_step: 7682, epoch: 193, loss: 0.228334
global_step: 7683, epoch: 193, loss: 0.227112
global_step: 7684, epoch: 193, loss: 0.133511
global_step: 7685, epoch: 193, loss: 0.148387
global_step: 7686, epoch: 193, loss: 0.162994
global_step: 7687, epoch: 193, loss: 0.231683
global_step: 7688, epoch: 193, loss: 0.158016
global_step: 7689, epoch: 193, loss: 0.141731
global_step: 7690, epoch: 193, loss: 0.168549
global_step: 7691, epoch: 193, loss: 0.170044
global_step: 7692, epoch: 193, loss: 0.132359
global_step: 7693, epoch: 193, loss: 0.129764
global_step: 7694, epoch: 193, loss: 0.202678
global_step: 7695, epoch: 193, loss: 0.165541
global_step: 7696, epoch: 193, loss: 0.114865
global_step: 7697, epoch: 193, loss: 0.158450
global_step: 7698, epoch: 193, loss: 0.200436
global_step: 7699, epoch: 193, loss: 0.169069
global_step: 7700, epoch: 193, loss: 0.223035
global_step: 7701, epoch: 193, loss: 0.228215
global_step: 7702, epoch: 193, loss: 0.249992
global_step: 7703, epoch: 193, loss: 0.205651
global_step: 7704, epoch: 193, loss: 0.153374
global_step: 7705, epoch: 193, loss: 0.169207
global_step: 7706, epoch: 193, loss: 0.165205
global_step: 7707, epoch: 193, loss: 0.174782
global_step: 7708, epoch: 193, loss: 0.191503
global_step: 7709, epoch: 193, loss: 0.158854
global_step: 7710, epoch: 193, loss: 0.184159
global_step: 7711, epoch: 193, loss: 0.177398
global_step: 7712, epoch: 193, loss: 0.214497
global_step: 7713, epoch: 193, loss: 0.190196
global_step: 7714, epoch: 193, loss: 0.216632
global_step: 7715, epoch: 193, loss: 0.236595
global_step: 7716, epoch: 193, loss: 0.225712
global_step: 7717, epoch: 193, loss: 0.212885
global_step: 7718, epoch: 193, loss: 0.145377
global_step: 7719, epoch: 193, loss: 0.205825
global_step: 7720, epoch: 193, loss: 0.643371
epoch: 193
train	acc: 0.9720	macro: p 0.9753, r 0.9611, f1: 0.9679	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5302	macro: p 0.4460, r 0.3106, f1: 0.3212	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4845
test	acc: 0.5797	macro: p 0.3750, r 0.3199, f1: 0.3256	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5449
global_step: 7721, epoch: 194, loss: 0.147059
global_step: 7722, epoch: 194, loss: 0.188178
global_step: 7723, epoch: 194, loss: 0.173700
global_step: 7724, epoch: 194, loss: 0.160967
global_step: 7725, epoch: 194, loss: 0.207802
global_step: 7726, epoch: 194, loss: 0.164501
global_step: 7727, epoch: 194, loss: 0.160605
global_step: 7728, epoch: 194, loss: 0.143643
global_step: 7729, epoch: 194, loss: 0.212150
global_step: 7730, epoch: 194, loss: 0.148286
global_step: 7731, epoch: 194, loss: 0.244492
global_step: 7732, epoch: 194, loss: 0.199361
global_step: 7733, epoch: 194, loss: 0.145471
global_step: 7734, epoch: 194, loss: 0.137171
global_step: 7735, epoch: 194, loss: 0.239709
global_step: 7736, epoch: 194, loss: 0.131815
global_step: 7737, epoch: 194, loss: 0.185560
global_step: 7738, epoch: 194, loss: 0.145148
global_step: 7739, epoch: 194, loss: 0.292910
global_step: 7740, epoch: 194, loss: 0.159488
global_step: 7741, epoch: 194, loss: 0.194769
global_step: 7742, epoch: 194, loss: 0.184533
global_step: 7743, epoch: 194, loss: 0.153198
global_step: 7744, epoch: 194, loss: 0.209257
global_step: 7745, epoch: 194, loss: 0.166433
global_step: 7746, epoch: 194, loss: 0.159428
global_step: 7747, epoch: 194, loss: 0.127125
global_step: 7748, epoch: 194, loss: 0.187104
global_step: 7749, epoch: 194, loss: 0.213397
global_step: 7750, epoch: 194, loss: 0.151116
global_step: 7751, epoch: 194, loss: 0.218189
global_step: 7752, epoch: 194, loss: 0.167211
global_step: 7753, epoch: 194, loss: 0.168260
global_step: 7754, epoch: 194, loss: 0.171090
global_step: 7755, epoch: 194, loss: 0.210891
global_step: 7756, epoch: 194, loss: 0.208519
global_step: 7757, epoch: 194, loss: 0.158062
global_step: 7758, epoch: 194, loss: 0.162810
global_step: 7759, epoch: 194, loss: 0.186104
global_step: 7760, epoch: 194, loss: 0.604989
epoch: 194
train	acc: 0.9726	macro: p 0.9749, r 0.9640, f1: 0.9693	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5248	macro: p 0.3932, r 0.3037, f1: 0.3091	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4800
test	acc: 0.5751	macro: p 0.3706, r 0.3178, f1: 0.3250	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5405
global_step: 7761, epoch: 195, loss: 0.182774
global_step: 7762, epoch: 195, loss: 0.128065
global_step: 7763, epoch: 195, loss: 0.222742
global_step: 7764, epoch: 195, loss: 0.181408
global_step: 7765, epoch: 195, loss: 0.154885
global_step: 7766, epoch: 195, loss: 0.170277
global_step: 7767, epoch: 195, loss: 0.108684
global_step: 7768, epoch: 195, loss: 0.182711
global_step: 7769, epoch: 195, loss: 0.137356
global_step: 7770, epoch: 195, loss: 0.165512
global_step: 7771, epoch: 195, loss: 0.142812
global_step: 7772, epoch: 195, loss: 0.172458
global_step: 7773, epoch: 195, loss: 0.130465
global_step: 7774, epoch: 195, loss: 0.186835
global_step: 7775, epoch: 195, loss: 0.147435
global_step: 7776, epoch: 195, loss: 0.162693
global_step: 7777, epoch: 195, loss: 0.168292
global_step: 7778, epoch: 195, loss: 0.158966
global_step: 7779, epoch: 195, loss: 0.215801
global_step: 7780, epoch: 195, loss: 0.189443
global_step: 7781, epoch: 195, loss: 0.180947
global_step: 7782, epoch: 195, loss: 0.165253
global_step: 7783, epoch: 195, loss: 0.159992
global_step: 7784, epoch: 195, loss: 0.160539
global_step: 7785, epoch: 195, loss: 0.215841
global_step: 7786, epoch: 195, loss: 0.125095
global_step: 7787, epoch: 195, loss: 0.220381
global_step: 7788, epoch: 195, loss: 0.165816
global_step: 7789, epoch: 195, loss: 0.110093
global_step: 7790, epoch: 195, loss: 0.189210
global_step: 7791, epoch: 195, loss: 0.197262
global_step: 7792, epoch: 195, loss: 0.153934
global_step: 7793, epoch: 195, loss: 0.179338
global_step: 7794, epoch: 195, loss: 0.166480
global_step: 7795, epoch: 195, loss: 0.117091
global_step: 7796, epoch: 195, loss: 0.199610
global_step: 7797, epoch: 195, loss: 0.200851
global_step: 7798, epoch: 195, loss: 0.215936
global_step: 7799, epoch: 195, loss: 0.190129
global_step: 7800, epoch: 195, loss: 0.461313
epoch: 195
train	acc: 0.9727	macro: p 0.9753, r 0.9630, f1: 0.9690	micro: p 0.9727, r 0.9727, f1 0.9727	weighted_f1:0.9727
dev	acc: 0.5293	macro: p 0.4138, r 0.3026, f1: 0.3095	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4810
test	acc: 0.5797	macro: p 0.3935, r 0.3184, f1: 0.3281	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5419
global_step: 7801, epoch: 196, loss: 0.139782
global_step: 7802, epoch: 196, loss: 0.227101
global_step: 7803, epoch: 196, loss: 0.180751
global_step: 7804, epoch: 196, loss: 0.148525
global_step: 7805, epoch: 196, loss: 0.124902
global_step: 7806, epoch: 196, loss: 0.179119
global_step: 7807, epoch: 196, loss: 0.214140
global_step: 7808, epoch: 196, loss: 0.167274
global_step: 7809, epoch: 196, loss: 0.123617
global_step: 7810, epoch: 196, loss: 0.179577
global_step: 7811, epoch: 196, loss: 0.234484
global_step: 7812, epoch: 196, loss: 0.168900
global_step: 7813, epoch: 196, loss: 0.171444
global_step: 7814, epoch: 196, loss: 0.200459
global_step: 7815, epoch: 196, loss: 0.166303
global_step: 7816, epoch: 196, loss: 0.222485
global_step: 7817, epoch: 196, loss: 0.163964
global_step: 7818, epoch: 196, loss: 0.154659
global_step: 7819, epoch: 196, loss: 0.181918
global_step: 7820, epoch: 196, loss: 0.183195
global_step: 7821, epoch: 196, loss: 0.211938
global_step: 7822, epoch: 196, loss: 0.137704
global_step: 7823, epoch: 196, loss: 0.126943
global_step: 7824, epoch: 196, loss: 0.144142
global_step: 7825, epoch: 196, loss: 0.223929
global_step: 7826, epoch: 196, loss: 0.152130
global_step: 7827, epoch: 196, loss: 0.167661
global_step: 7828, epoch: 196, loss: 0.210587
global_step: 7829, epoch: 196, loss: 0.184985
global_step: 7830, epoch: 196, loss: 0.139268
global_step: 7831, epoch: 196, loss: 0.172363
global_step: 7832, epoch: 196, loss: 0.249938
global_step: 7833, epoch: 196, loss: 0.184008
global_step: 7834, epoch: 196, loss: 0.203887
global_step: 7835, epoch: 196, loss: 0.193830
global_step: 7836, epoch: 196, loss: 0.213842
global_step: 7837, epoch: 196, loss: 0.141009
global_step: 7838, epoch: 196, loss: 0.170193
global_step: 7839, epoch: 196, loss: 0.198417
global_step: 7840, epoch: 196, loss: 0.124954
epoch: 196
train	acc: 0.9723	macro: p 0.9757, r 0.9610, f1: 0.9680	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5320	macro: p 0.4240, r 0.3115, f1: 0.3203	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4882
test	acc: 0.5774	macro: p 0.3652, r 0.3179, f1: 0.3237	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5420
global_step: 7841, epoch: 197, loss: 0.154686
global_step: 7842, epoch: 197, loss: 0.141572
global_step: 7843, epoch: 197, loss: 0.175011
global_step: 7844, epoch: 197, loss: 0.190083
global_step: 7845, epoch: 197, loss: 0.164351
global_step: 7846, epoch: 197, loss: 0.133984
global_step: 7847, epoch: 197, loss: 0.117965
global_step: 7848, epoch: 197, loss: 0.155984
global_step: 7849, epoch: 197, loss: 0.147057
global_step: 7850, epoch: 197, loss: 0.192058
global_step: 7851, epoch: 197, loss: 0.168144
global_step: 7852, epoch: 197, loss: 0.158256
global_step: 7853, epoch: 197, loss: 0.245545
global_step: 7854, epoch: 197, loss: 0.188615
global_step: 7855, epoch: 197, loss: 0.223195
global_step: 7856, epoch: 197, loss: 0.126020
global_step: 7857, epoch: 197, loss: 0.149848
global_step: 7858, epoch: 197, loss: 0.155354
global_step: 7859, epoch: 197, loss: 0.168277
global_step: 7860, epoch: 197, loss: 0.258816
global_step: 7861, epoch: 197, loss: 0.132104
global_step: 7862, epoch: 197, loss: 0.170078
global_step: 7863, epoch: 197, loss: 0.179260
global_step: 7864, epoch: 197, loss: 0.163633
global_step: 7865, epoch: 197, loss: 0.162895
global_step: 7866, epoch: 197, loss: 0.138303
global_step: 7867, epoch: 197, loss: 0.265396
global_step: 7868, epoch: 197, loss: 0.149296
global_step: 7869, epoch: 197, loss: 0.212127
global_step: 7870, epoch: 197, loss: 0.180514
global_step: 7871, epoch: 197, loss: 0.193785
global_step: 7872, epoch: 197, loss: 0.204593
global_step: 7873, epoch: 197, loss: 0.196235
global_step: 7874, epoch: 197, loss: 0.244307
global_step: 7875, epoch: 197, loss: 0.164879
global_step: 7876, epoch: 197, loss: 0.181395
global_step: 7877, epoch: 197, loss: 0.176302
global_step: 7878, epoch: 197, loss: 0.153874
global_step: 7879, epoch: 197, loss: 0.171644
global_step: 7880, epoch: 197, loss: 0.161725
epoch: 197
train	acc: 0.9729	macro: p 0.9757, r 0.9642, f1: 0.9698	micro: p 0.9729, r 0.9729, f1 0.9729	weighted_f1:0.9729
dev	acc: 0.5266	macro: p 0.4340, r 0.3093, f1: 0.3173	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4821
test	acc: 0.5759	macro: p 0.3596, r 0.3134, f1: 0.3175	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5384
global_step: 7881, epoch: 198, loss: 0.194515
global_step: 7882, epoch: 198, loss: 0.165636
global_step: 7883, epoch: 198, loss: 0.134932
global_step: 7884, epoch: 198, loss: 0.156656
global_step: 7885, epoch: 198, loss: 0.234589
global_step: 7886, epoch: 198, loss: 0.238075
global_step: 7887, epoch: 198, loss: 0.150394
global_step: 7888, epoch: 198, loss: 0.147483
global_step: 7889, epoch: 198, loss: 0.156756
global_step: 7890, epoch: 198, loss: 0.159482
global_step: 7891, epoch: 198, loss: 0.165049
global_step: 7892, epoch: 198, loss: 0.205602
global_step: 7893, epoch: 198, loss: 0.190874
global_step: 7894, epoch: 198, loss: 0.224385
global_step: 7895, epoch: 198, loss: 0.214779
global_step: 7896, epoch: 198, loss: 0.163320
global_step: 7897, epoch: 198, loss: 0.180996
global_step: 7898, epoch: 198, loss: 0.157827
global_step: 7899, epoch: 198, loss: 0.131614
global_step: 7900, epoch: 198, loss: 0.111589
global_step: 7901, epoch: 198, loss: 0.261160
global_step: 7902, epoch: 198, loss: 0.150453
global_step: 7903, epoch: 198, loss: 0.201709
global_step: 7904, epoch: 198, loss: 0.163196
global_step: 7905, epoch: 198, loss: 0.191297
global_step: 7906, epoch: 198, loss: 0.174773
global_step: 7907, epoch: 198, loss: 0.169024
global_step: 7908, epoch: 198, loss: 0.239688
global_step: 7909, epoch: 198, loss: 0.147210
global_step: 7910, epoch: 198, loss: 0.220561
global_step: 7911, epoch: 198, loss: 0.298980
global_step: 7912, epoch: 198, loss: 0.193152
global_step: 7913, epoch: 198, loss: 0.229419
global_step: 7914, epoch: 198, loss: 0.158908
global_step: 7915, epoch: 198, loss: 0.178128
global_step: 7916, epoch: 198, loss: 0.125014
global_step: 7917, epoch: 198, loss: 0.216734
global_step: 7918, epoch: 198, loss: 0.185222
global_step: 7919, epoch: 198, loss: 0.162919
global_step: 7920, epoch: 198, loss: 0.260814
epoch: 198
train	acc: 0.9726	macro: p 0.9750, r 0.9628, f1: 0.9687	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5311	macro: p 0.4087, r 0.3077, f1: 0.3174	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4837
test	acc: 0.5797	macro: p 0.3695, r 0.3135, f1: 0.3204	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5392
global_step: 7921, epoch: 199, loss: 0.145624
global_step: 7922, epoch: 199, loss: 0.219456
global_step: 7923, epoch: 199, loss: 0.149393
global_step: 7924, epoch: 199, loss: 0.110353
global_step: 7925, epoch: 199, loss: 0.175404
global_step: 7926, epoch: 199, loss: 0.191333
global_step: 7927, epoch: 199, loss: 0.197064
global_step: 7928, epoch: 199, loss: 0.157988
global_step: 7929, epoch: 199, loss: 0.110723
global_step: 7930, epoch: 199, loss: 0.185851
global_step: 7931, epoch: 199, loss: 0.175796
global_step: 7932, epoch: 199, loss: 0.156114
global_step: 7933, epoch: 199, loss: 0.220834
global_step: 7934, epoch: 199, loss: 0.217892
global_step: 7935, epoch: 199, loss: 0.189846
global_step: 7936, epoch: 199, loss: 0.180108
global_step: 7937, epoch: 199, loss: 0.213183
global_step: 7938, epoch: 199, loss: 0.252044
global_step: 7939, epoch: 199, loss: 0.218367
global_step: 7940, epoch: 199, loss: 0.203963
global_step: 7941, epoch: 199, loss: 0.202629
global_step: 7942, epoch: 199, loss: 0.198092
global_step: 7943, epoch: 199, loss: 0.161119
global_step: 7944, epoch: 199, loss: 0.190227
global_step: 7945, epoch: 199, loss: 0.150900
global_step: 7946, epoch: 199, loss: 0.161389
global_step: 7947, epoch: 199, loss: 0.213067
global_step: 7948, epoch: 199, loss: 0.156964
global_step: 7949, epoch: 199, loss: 0.159249
global_step: 7950, epoch: 199, loss: 0.198619
global_step: 7951, epoch: 199, loss: 0.230095
global_step: 7952, epoch: 199, loss: 0.153908
global_step: 7953, epoch: 199, loss: 0.164250
global_step: 7954, epoch: 199, loss: 0.135061
global_step: 7955, epoch: 199, loss: 0.164945
global_step: 7956, epoch: 199, loss: 0.145957
global_step: 7957, epoch: 199, loss: 0.178427
global_step: 7958, epoch: 199, loss: 0.122686
global_step: 7959, epoch: 199, loss: 0.168096
global_step: 7960, epoch: 199, loss: 0.034451
epoch: 199
train	acc: 0.9724	macro: p 0.9758, r 0.9632, f1: 0.9693	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5311	macro: p 0.4938, r 0.3048, f1: 0.3129	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4821
test	acc: 0.5831	macro: p 0.3808, r 0.3142, f1: 0.3205	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5408
global_step: 7961, epoch: 200, loss: 0.187459
global_step: 7962, epoch: 200, loss: 0.225534
global_step: 7963, epoch: 200, loss: 0.214969
global_step: 7964, epoch: 200, loss: 0.191937
global_step: 7965, epoch: 200, loss: 0.167966
global_step: 7966, epoch: 200, loss: 0.221365
global_step: 7967, epoch: 200, loss: 0.160668
global_step: 7968, epoch: 200, loss: 0.184713
global_step: 7969, epoch: 200, loss: 0.143101
global_step: 7970, epoch: 200, loss: 0.141175
global_step: 7971, epoch: 200, loss: 0.224303
global_step: 7972, epoch: 200, loss: 0.157077
global_step: 7973, epoch: 200, loss: 0.174433
global_step: 7974, epoch: 200, loss: 0.218135
global_step: 7975, epoch: 200, loss: 0.168062
global_step: 7976, epoch: 200, loss: 0.168467
global_step: 7977, epoch: 200, loss: 0.187960
global_step: 7978, epoch: 200, loss: 0.238895
global_step: 7979, epoch: 200, loss: 0.215063
global_step: 7980, epoch: 200, loss: 0.117438
global_step: 7981, epoch: 200, loss: 0.190351
global_step: 7982, epoch: 200, loss: 0.222421
global_step: 7983, epoch: 200, loss: 0.112349
global_step: 7984, epoch: 200, loss: 0.180348
global_step: 7985, epoch: 200, loss: 0.158571
global_step: 7986, epoch: 200, loss: 0.234368
global_step: 7987, epoch: 200, loss: 0.178102
global_step: 7988, epoch: 200, loss: 0.166210
global_step: 7989, epoch: 200, loss: 0.208138
global_step: 7990, epoch: 200, loss: 0.186990
global_step: 7991, epoch: 200, loss: 0.190175
global_step: 7992, epoch: 200, loss: 0.174395
global_step: 7993, epoch: 200, loss: 0.087554
global_step: 7994, epoch: 200, loss: 0.220926
global_step: 7995, epoch: 200, loss: 0.180520
global_step: 7996, epoch: 200, loss: 0.230513
global_step: 7997, epoch: 200, loss: 0.194439
global_step: 7998, epoch: 200, loss: 0.175549
global_step: 7999, epoch: 200, loss: 0.214919
global_step: 8000, epoch: 200, loss: 0.014868
epoch: 200
train	acc: 0.9726	macro: p 0.9750, r 0.9634, f1: 0.9690	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5248	macro: p 0.4257, r 0.3084, f1: 0.3171	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4817
test	acc: 0.5789	macro: p 0.3620, r 0.3168, f1: 0.3213	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5423
BEST MODEL epoch: 54
train	acc: 0.8986 macro_p: 0.9008 macro_r: 0.7552 macro_f1: 0.7928 micro_p: 0.8986 micro_r: 0.8986 micro_f1: 0.8986 weighted_f1: 0.8930
dev	acc: 0.5482 macro_p: 0.3980 macro_r: 0.3169 macro_f1: 0.3169 micro_p: 0.5482 micro_r: 0.5482 micro_f1: 0.5482 weighted_f1: 0.5061
test	acc: 0.5958 macro_p: 0.3978 macro_r: 0.3371 macro_f1: 0.3400 micro_p: 0.5958 micro_r: 0.5958 micro_f1: 0.5958 weighted_f1: 0.5634
==========ROUND 2==========
global_step: 8001, epoch: 1, loss: 1.919070
global_step: 8002, epoch: 1, loss: 1.871912
global_step: 8003, epoch: 1, loss: 1.791508
global_step: 8004, epoch: 1, loss: 1.773659
global_step: 8005, epoch: 1, loss: 1.738810
global_step: 8006, epoch: 1, loss: 1.759761
global_step: 8007, epoch: 1, loss: 1.711744
global_step: 8008, epoch: 1, loss: 1.624391
global_step: 8009, epoch: 1, loss: 1.621891
global_step: 8010, epoch: 1, loss: 1.660117
global_step: 8011, epoch: 1, loss: 1.656914
global_step: 8012, epoch: 1, loss: 1.629834
global_step: 8013, epoch: 1, loss: 1.560929
global_step: 8014, epoch: 1, loss: 1.530418
global_step: 8015, epoch: 1, loss: 1.615967
global_step: 8016, epoch: 1, loss: 1.563408
global_step: 8017, epoch: 1, loss: 1.559738
global_step: 8018, epoch: 1, loss: 1.559162
global_step: 8019, epoch: 1, loss: 1.554582
global_step: 8020, epoch: 1, loss: 1.512374
global_step: 8021, epoch: 1, loss: 1.586591
global_step: 8022, epoch: 1, loss: 1.579858
global_step: 8023, epoch: 1, loss: 1.535352
global_step: 8024, epoch: 1, loss: 1.589327
global_step: 8025, epoch: 1, loss: 1.512783
global_step: 8026, epoch: 1, loss: 1.520973
global_step: 8027, epoch: 1, loss: 1.486672
global_step: 8028, epoch: 1, loss: 1.523209
global_step: 8029, epoch: 1, loss: 1.565873
global_step: 8030, epoch: 1, loss: 1.458911
global_step: 8031, epoch: 1, loss: 1.490772
global_step: 8032, epoch: 1, loss: 1.445441
global_step: 8033, epoch: 1, loss: 1.509953
global_step: 8034, epoch: 1, loss: 1.483455
global_step: 8035, epoch: 1, loss: 1.435283
global_step: 8036, epoch: 1, loss: 1.554653
global_step: 8037, epoch: 1, loss: 1.531068
global_step: 8038, epoch: 1, loss: 1.506255
global_step: 8039, epoch: 1, loss: 1.443188
global_step: 8040, epoch: 1, loss: 1.847375
epoch: 1
train	acc: 0.5267	macro: p 0.2546, r 0.1973, f1: 0.1699	micro: p 0.5267, r 0.5267, f1 0.5267	weighted_f1:0.4082
dev	acc: 0.4698	macro: p 0.2576, r 0.1953, f1: 0.1579	micro: p 0.4698, r 0.4698, f1 0.4698	weighted_f1:0.3419
test	acc: 0.5330	macro: p 0.2657, r 0.2019, f1: 0.1761	micro: p 0.5330, r 0.5330, f1 0.5330	weighted_f1:0.4134
New best model!
global_step: 8041, epoch: 2, loss: 1.513093
global_step: 8042, epoch: 2, loss: 1.510959
global_step: 8043, epoch: 2, loss: 1.430788
global_step: 8044, epoch: 2, loss: 1.417395
global_step: 8045, epoch: 2, loss: 1.464863
global_step: 8046, epoch: 2, loss: 1.397900
global_step: 8047, epoch: 2, loss: 1.532304
global_step: 8048, epoch: 2, loss: 1.419112
global_step: 8049, epoch: 2, loss: 1.452163
global_step: 8050, epoch: 2, loss: 1.398203
global_step: 8051, epoch: 2, loss: 1.443948
global_step: 8052, epoch: 2, loss: 1.415887
global_step: 8053, epoch: 2, loss: 1.405589
global_step: 8054, epoch: 2, loss: 1.484259
global_step: 8055, epoch: 2, loss: 1.409567
global_step: 8056, epoch: 2, loss: 1.275882
global_step: 8057, epoch: 2, loss: 1.552980
global_step: 8058, epoch: 2, loss: 1.489807
global_step: 8059, epoch: 2, loss: 1.496595
global_step: 8060, epoch: 2, loss: 1.401016
global_step: 8061, epoch: 2, loss: 1.470299
global_step: 8062, epoch: 2, loss: 1.425562
global_step: 8063, epoch: 2, loss: 1.361638
global_step: 8064, epoch: 2, loss: 1.451107
global_step: 8065, epoch: 2, loss: 1.451878
global_step: 8066, epoch: 2, loss: 1.416069
global_step: 8067, epoch: 2, loss: 1.462214
global_step: 8068, epoch: 2, loss: 1.389065
global_step: 8069, epoch: 2, loss: 1.461075
global_step: 8070, epoch: 2, loss: 1.291279
global_step: 8071, epoch: 2, loss: 1.488995
global_step: 8072, epoch: 2, loss: 1.501374
global_step: 8073, epoch: 2, loss: 1.404540
global_step: 8074, epoch: 2, loss: 1.409008
global_step: 8075, epoch: 2, loss: 1.382868
global_step: 8076, epoch: 2, loss: 1.339859
global_step: 8077, epoch: 2, loss: 1.393466
global_step: 8078, epoch: 2, loss: 1.294747
global_step: 8079, epoch: 2, loss: 1.512112
global_step: 8080, epoch: 2, loss: 1.316878
epoch: 2
train	acc: 0.5576	macro: p 0.3037, r 0.2358, f1: 0.2209	micro: p 0.5576, r 0.5576, f1 0.5576	weighted_f1:0.4666
dev	acc: 0.5122	macro: p 0.2913, r 0.2431, f1: 0.2114	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4088
test	acc: 0.5648	macro: p 0.2979, r 0.2437, f1: 0.2259	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.4728
New best model!
global_step: 8081, epoch: 3, loss: 1.431595
global_step: 8082, epoch: 3, loss: 1.439023
global_step: 8083, epoch: 3, loss: 1.409587
global_step: 8084, epoch: 3, loss: 1.290098
global_step: 8085, epoch: 3, loss: 1.342889
global_step: 8086, epoch: 3, loss: 1.427512
global_step: 8087, epoch: 3, loss: 1.383869
global_step: 8088, epoch: 3, loss: 1.400607
global_step: 8089, epoch: 3, loss: 1.321430
global_step: 8090, epoch: 3, loss: 1.418924
global_step: 8091, epoch: 3, loss: 1.374030
global_step: 8092, epoch: 3, loss: 1.537036
global_step: 8093, epoch: 3, loss: 1.501521
global_step: 8094, epoch: 3, loss: 1.359668
global_step: 8095, epoch: 3, loss: 1.401979
global_step: 8096, epoch: 3, loss: 1.385192
global_step: 8097, epoch: 3, loss: 1.370611
global_step: 8098, epoch: 3, loss: 1.368333
global_step: 8099, epoch: 3, loss: 1.355556
global_step: 8100, epoch: 3, loss: 1.401297
global_step: 8101, epoch: 3, loss: 1.410097
global_step: 8102, epoch: 3, loss: 1.407711
global_step: 8103, epoch: 3, loss: 1.309958
global_step: 8104, epoch: 3, loss: 1.414109
global_step: 8105, epoch: 3, loss: 1.425433
global_step: 8106, epoch: 3, loss: 1.376687
global_step: 8107, epoch: 3, loss: 1.390733
global_step: 8108, epoch: 3, loss: 1.274892
global_step: 8109, epoch: 3, loss: 1.495713
global_step: 8110, epoch: 3, loss: 1.281846
global_step: 8111, epoch: 3, loss: 1.345028
global_step: 8112, epoch: 3, loss: 1.413003
global_step: 8113, epoch: 3, loss: 1.427635
global_step: 8114, epoch: 3, loss: 1.349012
global_step: 8115, epoch: 3, loss: 1.440968
global_step: 8116, epoch: 3, loss: 1.273973
global_step: 8117, epoch: 3, loss: 1.309165
global_step: 8118, epoch: 3, loss: 1.311673
global_step: 8119, epoch: 3, loss: 1.396483
global_step: 8120, epoch: 3, loss: 0.942166
epoch: 3
train	acc: 0.5709	macro: p 0.2892, r 0.2597, f1: 0.2550	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.4982
dev	acc: 0.5185	macro: p 0.2647, r 0.2545, f1: 0.2367	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4349
test	acc: 0.5724	macro: p 0.2807, r 0.2606, f1: 0.2524	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.4979
New best model!
global_step: 8121, epoch: 4, loss: 1.470952
global_step: 8122, epoch: 4, loss: 1.365816
global_step: 8123, epoch: 4, loss: 1.469724
global_step: 8124, epoch: 4, loss: 1.360964
global_step: 8125, epoch: 4, loss: 1.493450
global_step: 8126, epoch: 4, loss: 1.267512
global_step: 8127, epoch: 4, loss: 1.311230
global_step: 8128, epoch: 4, loss: 1.356677
global_step: 8129, epoch: 4, loss: 1.251680
global_step: 8130, epoch: 4, loss: 1.414945
global_step: 8131, epoch: 4, loss: 1.414843
global_step: 8132, epoch: 4, loss: 1.372086
global_step: 8133, epoch: 4, loss: 1.265012
global_step: 8134, epoch: 4, loss: 1.425052
global_step: 8135, epoch: 4, loss: 1.482589
global_step: 8136, epoch: 4, loss: 1.433660
global_step: 8137, epoch: 4, loss: 1.303193
global_step: 8138, epoch: 4, loss: 1.357518
global_step: 8139, epoch: 4, loss: 1.397388
global_step: 8140, epoch: 4, loss: 1.366723
global_step: 8141, epoch: 4, loss: 1.248106
global_step: 8142, epoch: 4, loss: 1.421165
global_step: 8143, epoch: 4, loss: 1.340305
global_step: 8144, epoch: 4, loss: 1.213648
global_step: 8145, epoch: 4, loss: 1.315656
global_step: 8146, epoch: 4, loss: 1.285064
global_step: 8147, epoch: 4, loss: 1.401893
global_step: 8148, epoch: 4, loss: 1.325570
global_step: 8149, epoch: 4, loss: 1.367296
global_step: 8150, epoch: 4, loss: 1.353602
global_step: 8151, epoch: 4, loss: 1.308585
global_step: 8152, epoch: 4, loss: 1.331888
global_step: 8153, epoch: 4, loss: 1.342366
global_step: 8154, epoch: 4, loss: 1.432343
global_step: 8155, epoch: 4, loss: 1.369500
global_step: 8156, epoch: 4, loss: 1.433537
global_step: 8157, epoch: 4, loss: 1.269589
global_step: 8158, epoch: 4, loss: 1.330019
global_step: 8159, epoch: 4, loss: 1.288182
global_step: 8160, epoch: 4, loss: 2.311999
epoch: 4
train	acc: 0.5758	macro: p 0.3027, r 0.2727, f1: 0.2672	micro: p 0.5758, r 0.5758, f1 0.5758	weighted_f1:0.5104
dev	acc: 0.5212	macro: p 0.2794, r 0.2610, f1: 0.2458	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4444
test	acc: 0.5759	macro: p 0.2907, r 0.2682, f1: 0.2624	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5100
New best model!
global_step: 8161, epoch: 5, loss: 1.347471
global_step: 8162, epoch: 5, loss: 1.346051
global_step: 8163, epoch: 5, loss: 1.331308
global_step: 8164, epoch: 5, loss: 1.357695
global_step: 8165, epoch: 5, loss: 1.257173
global_step: 8166, epoch: 5, loss: 1.306975
global_step: 8167, epoch: 5, loss: 1.308901
global_step: 8168, epoch: 5, loss: 1.341272
global_step: 8169, epoch: 5, loss: 1.361089
global_step: 8170, epoch: 5, loss: 1.194054
global_step: 8171, epoch: 5, loss: 1.326676
global_step: 8172, epoch: 5, loss: 1.341121
global_step: 8173, epoch: 5, loss: 1.443873
global_step: 8174, epoch: 5, loss: 1.282258
global_step: 8175, epoch: 5, loss: 1.384678
global_step: 8176, epoch: 5, loss: 1.408627
global_step: 8177, epoch: 5, loss: 1.297788
global_step: 8178, epoch: 5, loss: 1.425028
global_step: 8179, epoch: 5, loss: 1.273133
global_step: 8180, epoch: 5, loss: 1.336569
global_step: 8181, epoch: 5, loss: 1.417261
global_step: 8182, epoch: 5, loss: 1.399660
global_step: 8183, epoch: 5, loss: 1.283544
global_step: 8184, epoch: 5, loss: 1.301622
global_step: 8185, epoch: 5, loss: 1.271449
global_step: 8186, epoch: 5, loss: 1.314034
global_step: 8187, epoch: 5, loss: 1.234412
global_step: 8188, epoch: 5, loss: 1.357173
global_step: 8189, epoch: 5, loss: 1.360520
global_step: 8190, epoch: 5, loss: 1.231580
global_step: 8191, epoch: 5, loss: 1.379102
global_step: 8192, epoch: 5, loss: 1.296605
global_step: 8193, epoch: 5, loss: 1.398425
global_step: 8194, epoch: 5, loss: 1.432886
global_step: 8195, epoch: 5, loss: 1.424932
global_step: 8196, epoch: 5, loss: 1.309471
global_step: 8197, epoch: 5, loss: 1.283978
global_step: 8198, epoch: 5, loss: 1.341032
global_step: 8199, epoch: 5, loss: 1.285846
global_step: 8200, epoch: 5, loss: 1.921833
epoch: 5
train	acc: 0.5830	macro: p 0.2975, r 0.2763, f1: 0.2731	micro: p 0.5830, r 0.5830, f1 0.5830	weighted_f1:0.5164
dev	acc: 0.5293	macro: p 0.2741, r 0.2673, f1: 0.2512	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4500
test	acc: 0.5812	macro: p 0.2827, r 0.2743, f1: 0.2666	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5129
New best model!
global_step: 8201, epoch: 6, loss: 1.378543
global_step: 8202, epoch: 6, loss: 1.260452
global_step: 8203, epoch: 6, loss: 1.266630
global_step: 8204, epoch: 6, loss: 1.242223
global_step: 8205, epoch: 6, loss: 1.299888
global_step: 8206, epoch: 6, loss: 1.388026
global_step: 8207, epoch: 6, loss: 1.311368
global_step: 8208, epoch: 6, loss: 1.293049
global_step: 8209, epoch: 6, loss: 1.372023
global_step: 8210, epoch: 6, loss: 1.218632
global_step: 8211, epoch: 6, loss: 1.313565
global_step: 8212, epoch: 6, loss: 1.345492
global_step: 8213, epoch: 6, loss: 1.335945
global_step: 8214, epoch: 6, loss: 1.309133
global_step: 8215, epoch: 6, loss: 1.480593
global_step: 8216, epoch: 6, loss: 1.298339
global_step: 8217, epoch: 6, loss: 1.352887
global_step: 8218, epoch: 6, loss: 1.378767
global_step: 8219, epoch: 6, loss: 1.326727
global_step: 8220, epoch: 6, loss: 1.324759
global_step: 8221, epoch: 6, loss: 1.180834
global_step: 8222, epoch: 6, loss: 1.327006
global_step: 8223, epoch: 6, loss: 1.354602
global_step: 8224, epoch: 6, loss: 1.246697
global_step: 8225, epoch: 6, loss: 1.317635
global_step: 8226, epoch: 6, loss: 1.201670
global_step: 8227, epoch: 6, loss: 1.262872
global_step: 8228, epoch: 6, loss: 1.191062
global_step: 8229, epoch: 6, loss: 1.300115
global_step: 8230, epoch: 6, loss: 1.345258
global_step: 8231, epoch: 6, loss: 1.195614
global_step: 8232, epoch: 6, loss: 1.316641
global_step: 8233, epoch: 6, loss: 1.409885
global_step: 8234, epoch: 6, loss: 1.251827
global_step: 8235, epoch: 6, loss: 1.373260
global_step: 8236, epoch: 6, loss: 1.255571
global_step: 8237, epoch: 6, loss: 1.283940
global_step: 8238, epoch: 6, loss: 1.289460
global_step: 8239, epoch: 6, loss: 1.236467
global_step: 8240, epoch: 6, loss: 2.014971
epoch: 6
train	acc: 0.5854	macro: p 0.4513, r 0.2822, f1: 0.2802	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5224
dev	acc: 0.5275	macro: p 0.2775, r 0.2662, f1: 0.2510	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4508
test	acc: 0.5824	macro: p 0.4354, r 0.2764, f1: 0.2715	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5178
New best model!
global_step: 8241, epoch: 7, loss: 1.326403
global_step: 8242, epoch: 7, loss: 1.283328
global_step: 8243, epoch: 7, loss: 1.320372
global_step: 8244, epoch: 7, loss: 1.247782
global_step: 8245, epoch: 7, loss: 1.341998
global_step: 8246, epoch: 7, loss: 1.183999
global_step: 8247, epoch: 7, loss: 1.271695
global_step: 8248, epoch: 7, loss: 1.271720
global_step: 8249, epoch: 7, loss: 1.230554
global_step: 8250, epoch: 7, loss: 1.312967
global_step: 8251, epoch: 7, loss: 1.338252
global_step: 8252, epoch: 7, loss: 1.321379
global_step: 8253, epoch: 7, loss: 1.346928
global_step: 8254, epoch: 7, loss: 1.301786
global_step: 8255, epoch: 7, loss: 1.370478
global_step: 8256, epoch: 7, loss: 1.258700
global_step: 8257, epoch: 7, loss: 1.317347
global_step: 8258, epoch: 7, loss: 1.245423
global_step: 8259, epoch: 7, loss: 1.353802
global_step: 8260, epoch: 7, loss: 1.293575
global_step: 8261, epoch: 7, loss: 1.249386
global_step: 8262, epoch: 7, loss: 1.312396
global_step: 8263, epoch: 7, loss: 1.297000
global_step: 8264, epoch: 7, loss: 1.343952
global_step: 8265, epoch: 7, loss: 1.256031
global_step: 8266, epoch: 7, loss: 1.317614
global_step: 8267, epoch: 7, loss: 1.180936
global_step: 8268, epoch: 7, loss: 1.338924
global_step: 8269, epoch: 7, loss: 1.396715
global_step: 8270, epoch: 7, loss: 1.184793
global_step: 8271, epoch: 7, loss: 1.259301
global_step: 8272, epoch: 7, loss: 1.245158
global_step: 8273, epoch: 7, loss: 1.338264
global_step: 8274, epoch: 7, loss: 1.393764
global_step: 8275, epoch: 7, loss: 1.382907
global_step: 8276, epoch: 7, loss: 1.263552
global_step: 8277, epoch: 7, loss: 1.202382
global_step: 8278, epoch: 7, loss: 1.324209
global_step: 8279, epoch: 7, loss: 1.314630
global_step: 8280, epoch: 7, loss: 1.475169
epoch: 7
train	acc: 0.5884	macro: p 0.4543, r 0.2812, f1: 0.2785	micro: p 0.5884, r 0.5884, f1 0.5884	weighted_f1:0.5225
dev	acc: 0.5230	macro: p 0.2683, r 0.2629, f1: 0.2415	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4410
test	acc: 0.5839	macro: p 0.4376, r 0.2770, f1: 0.2683	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5152
global_step: 8281, epoch: 8, loss: 1.385966
global_step: 8282, epoch: 8, loss: 1.211979
global_step: 8283, epoch: 8, loss: 1.251502
global_step: 8284, epoch: 8, loss: 1.169624
global_step: 8285, epoch: 8, loss: 1.312098
global_step: 8286, epoch: 8, loss: 1.302205
global_step: 8287, epoch: 8, loss: 1.132664
global_step: 8288, epoch: 8, loss: 1.198493
global_step: 8289, epoch: 8, loss: 1.283664
global_step: 8290, epoch: 8, loss: 1.406410
global_step: 8291, epoch: 8, loss: 1.298996
global_step: 8292, epoch: 8, loss: 1.257551
global_step: 8293, epoch: 8, loss: 1.272484
global_step: 8294, epoch: 8, loss: 1.207830
global_step: 8295, epoch: 8, loss: 1.318598
global_step: 8296, epoch: 8, loss: 1.201487
global_step: 8297, epoch: 8, loss: 1.353138
global_step: 8298, epoch: 8, loss: 1.209441
global_step: 8299, epoch: 8, loss: 1.216598
global_step: 8300, epoch: 8, loss: 1.189861
global_step: 8301, epoch: 8, loss: 1.344647
global_step: 8302, epoch: 8, loss: 1.388351
global_step: 8303, epoch: 8, loss: 1.380607
global_step: 8304, epoch: 8, loss: 1.369268
global_step: 8305, epoch: 8, loss: 1.270685
global_step: 8306, epoch: 8, loss: 1.274479
global_step: 8307, epoch: 8, loss: 1.218729
global_step: 8308, epoch: 8, loss: 1.339440
global_step: 8309, epoch: 8, loss: 1.322314
global_step: 8310, epoch: 8, loss: 1.125363
global_step: 8311, epoch: 8, loss: 1.235437
global_step: 8312, epoch: 8, loss: 1.312253
global_step: 8313, epoch: 8, loss: 1.319652
global_step: 8314, epoch: 8, loss: 1.214645
global_step: 8315, epoch: 8, loss: 1.330965
global_step: 8316, epoch: 8, loss: 1.325069
global_step: 8317, epoch: 8, loss: 1.411993
global_step: 8318, epoch: 8, loss: 1.147279
global_step: 8319, epoch: 8, loss: 1.332652
global_step: 8320, epoch: 8, loss: 1.814860
epoch: 8
train	acc: 0.5959	macro: p 0.4072, r 0.3058, f1: 0.3081	micro: p 0.5959, r 0.5959, f1 0.5959	weighted_f1:0.5429
dev	acc: 0.5356	macro: p 0.3549, r 0.2806, f1: 0.2706	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4689
test	acc: 0.5858	macro: p 0.3867, r 0.2888, f1: 0.2860	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5290
New best model!
global_step: 8321, epoch: 9, loss: 1.165155
global_step: 8322, epoch: 9, loss: 1.306008
global_step: 8323, epoch: 9, loss: 1.233579
global_step: 8324, epoch: 9, loss: 1.371303
global_step: 8325, epoch: 9, loss: 1.220364
global_step: 8326, epoch: 9, loss: 1.264485
global_step: 8327, epoch: 9, loss: 1.261747
global_step: 8328, epoch: 9, loss: 1.273529
global_step: 8329, epoch: 9, loss: 1.296923
global_step: 8330, epoch: 9, loss: 1.439899
global_step: 8331, epoch: 9, loss: 1.405183
global_step: 8332, epoch: 9, loss: 1.232155
global_step: 8333, epoch: 9, loss: 1.303686
global_step: 8334, epoch: 9, loss: 1.187448
global_step: 8335, epoch: 9, loss: 1.267596
global_step: 8336, epoch: 9, loss: 1.335117
global_step: 8337, epoch: 9, loss: 1.179018
global_step: 8338, epoch: 9, loss: 1.351589
global_step: 8339, epoch: 9, loss: 1.188219
global_step: 8340, epoch: 9, loss: 1.132121
global_step: 8341, epoch: 9, loss: 1.339560
global_step: 8342, epoch: 9, loss: 1.296418
global_step: 8343, epoch: 9, loss: 1.233049
global_step: 8344, epoch: 9, loss: 1.288408
global_step: 8345, epoch: 9, loss: 1.224452
global_step: 8346, epoch: 9, loss: 1.296149
global_step: 8347, epoch: 9, loss: 1.225508
global_step: 8348, epoch: 9, loss: 1.264687
global_step: 8349, epoch: 9, loss: 1.192078
global_step: 8350, epoch: 9, loss: 1.264147
global_step: 8351, epoch: 9, loss: 1.291250
global_step: 8352, epoch: 9, loss: 1.213460
global_step: 8353, epoch: 9, loss: 1.281466
global_step: 8354, epoch: 9, loss: 1.269059
global_step: 8355, epoch: 9, loss: 1.217924
global_step: 8356, epoch: 9, loss: 1.284998
global_step: 8357, epoch: 9, loss: 1.235558
global_step: 8358, epoch: 9, loss: 1.251842
global_step: 8359, epoch: 9, loss: 1.245775
global_step: 8360, epoch: 9, loss: 1.847647
epoch: 9
train	acc: 0.5994	macro: p 0.4200, r 0.2966, f1: 0.3001	micro: p 0.5994, r 0.5994, f1 0.5994	weighted_f1:0.5386
dev	acc: 0.5320	macro: p 0.3740, r 0.2724, f1: 0.2547	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4532
test	acc: 0.5847	macro: p 0.4002, r 0.2815, f1: 0.2751	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5187
global_step: 8361, epoch: 10, loss: 1.253512
global_step: 8362, epoch: 10, loss: 1.293984
global_step: 8363, epoch: 10, loss: 1.254213
global_step: 8364, epoch: 10, loss: 1.218854
global_step: 8365, epoch: 10, loss: 1.300079
global_step: 8366, epoch: 10, loss: 1.210495
global_step: 8367, epoch: 10, loss: 1.227970
global_step: 8368, epoch: 10, loss: 1.263176
global_step: 8369, epoch: 10, loss: 1.325805
global_step: 8370, epoch: 10, loss: 1.215208
global_step: 8371, epoch: 10, loss: 1.281082
global_step: 8372, epoch: 10, loss: 1.334759
global_step: 8373, epoch: 10, loss: 1.292036
global_step: 8374, epoch: 10, loss: 1.187096
global_step: 8375, epoch: 10, loss: 1.239405
global_step: 8376, epoch: 10, loss: 1.263304
global_step: 8377, epoch: 10, loss: 1.302609
global_step: 8378, epoch: 10, loss: 1.311291
global_step: 8379, epoch: 10, loss: 1.241544
global_step: 8380, epoch: 10, loss: 1.157415
global_step: 8381, epoch: 10, loss: 1.214643
global_step: 8382, epoch: 10, loss: 1.293722
global_step: 8383, epoch: 10, loss: 1.275784
global_step: 8384, epoch: 10, loss: 1.268699
global_step: 8385, epoch: 10, loss: 1.393182
global_step: 8386, epoch: 10, loss: 1.224921
global_step: 8387, epoch: 10, loss: 1.436006
global_step: 8388, epoch: 10, loss: 1.288734
global_step: 8389, epoch: 10, loss: 1.210748
global_step: 8390, epoch: 10, loss: 1.219697
global_step: 8391, epoch: 10, loss: 1.189329
global_step: 8392, epoch: 10, loss: 1.282125
global_step: 8393, epoch: 10, loss: 1.190074
global_step: 8394, epoch: 10, loss: 1.293857
global_step: 8395, epoch: 10, loss: 1.164323
global_step: 8396, epoch: 10, loss: 1.332655
global_step: 8397, epoch: 10, loss: 1.166631
global_step: 8398, epoch: 10, loss: 1.148131
global_step: 8399, epoch: 10, loss: 1.268831
global_step: 8400, epoch: 10, loss: 1.065501
epoch: 10
train	acc: 0.5943	macro: p 0.4277, r 0.2888, f1: 0.2890	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5303
dev	acc: 0.5329	macro: p 0.3783, r 0.2733, f1: 0.2521	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4513
test	acc: 0.5862	macro: p 0.4102, r 0.2823, f1: 0.2725	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5173
global_step: 8401, epoch: 11, loss: 1.261259
global_step: 8402, epoch: 11, loss: 1.232623
global_step: 8403, epoch: 11, loss: 1.175673
global_step: 8404, epoch: 11, loss: 1.174796
global_step: 8405, epoch: 11, loss: 1.237699
global_step: 8406, epoch: 11, loss: 1.170890
global_step: 8407, epoch: 11, loss: 1.309912
global_step: 8408, epoch: 11, loss: 1.187637
global_step: 8409, epoch: 11, loss: 1.316206
global_step: 8410, epoch: 11, loss: 1.177407
global_step: 8411, epoch: 11, loss: 1.268659
global_step: 8412, epoch: 11, loss: 1.300185
global_step: 8413, epoch: 11, loss: 1.277702
global_step: 8414, epoch: 11, loss: 1.279131
global_step: 8415, epoch: 11, loss: 1.275990
global_step: 8416, epoch: 11, loss: 1.177755
global_step: 8417, epoch: 11, loss: 1.192180
global_step: 8418, epoch: 11, loss: 1.150612
global_step: 8419, epoch: 11, loss: 1.318258
global_step: 8420, epoch: 11, loss: 1.240859
global_step: 8421, epoch: 11, loss: 1.136585
global_step: 8422, epoch: 11, loss: 1.137070
global_step: 8423, epoch: 11, loss: 1.272528
global_step: 8424, epoch: 11, loss: 1.235407
global_step: 8425, epoch: 11, loss: 1.110773
global_step: 8426, epoch: 11, loss: 1.243043
global_step: 8427, epoch: 11, loss: 1.298765
global_step: 8428, epoch: 11, loss: 1.289969
global_step: 8429, epoch: 11, loss: 1.272805
global_step: 8430, epoch: 11, loss: 1.234973
global_step: 8431, epoch: 11, loss: 1.287435
global_step: 8432, epoch: 11, loss: 1.235926
global_step: 8433, epoch: 11, loss: 1.282764
global_step: 8434, epoch: 11, loss: 1.228746
global_step: 8435, epoch: 11, loss: 1.144991
global_step: 8436, epoch: 11, loss: 1.141675
global_step: 8437, epoch: 11, loss: 1.373990
global_step: 8438, epoch: 11, loss: 1.231455
global_step: 8439, epoch: 11, loss: 1.164728
global_step: 8440, epoch: 11, loss: 1.025187
epoch: 11
train	acc: 0.6057	macro: p 0.4122, r 0.3106, f1: 0.3155	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5509
dev	acc: 0.5419	macro: p 0.3752, r 0.2829, f1: 0.2752	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4736
test	acc: 0.5900	macro: p 0.3806, r 0.2908, f1: 0.2907	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5322
New best model!
global_step: 8441, epoch: 12, loss: 1.177533
global_step: 8442, epoch: 12, loss: 1.231255
global_step: 8443, epoch: 12, loss: 1.279657
global_step: 8444, epoch: 12, loss: 1.219129
global_step: 8445, epoch: 12, loss: 1.306000
global_step: 8446, epoch: 12, loss: 1.299703
global_step: 8447, epoch: 12, loss: 1.236100
global_step: 8448, epoch: 12, loss: 1.238642
global_step: 8449, epoch: 12, loss: 1.202630
global_step: 8450, epoch: 12, loss: 1.225452
global_step: 8451, epoch: 12, loss: 1.230328
global_step: 8452, epoch: 12, loss: 1.142143
global_step: 8453, epoch: 12, loss: 1.180037
global_step: 8454, epoch: 12, loss: 1.121902
global_step: 8455, epoch: 12, loss: 1.214880
global_step: 8456, epoch: 12, loss: 1.316110
global_step: 8457, epoch: 12, loss: 1.215345
global_step: 8458, epoch: 12, loss: 1.198351
global_step: 8459, epoch: 12, loss: 1.259087
global_step: 8460, epoch: 12, loss: 1.199446
global_step: 8461, epoch: 12, loss: 1.245538
global_step: 8462, epoch: 12, loss: 1.134990
global_step: 8463, epoch: 12, loss: 1.219683
global_step: 8464, epoch: 12, loss: 1.177235
global_step: 8465, epoch: 12, loss: 1.200161
global_step: 8466, epoch: 12, loss: 1.359686
global_step: 8467, epoch: 12, loss: 1.149862
global_step: 8468, epoch: 12, loss: 1.043356
global_step: 8469, epoch: 12, loss: 1.226505
global_step: 8470, epoch: 12, loss: 1.223813
global_step: 8471, epoch: 12, loss: 1.292633
global_step: 8472, epoch: 12, loss: 1.300564
global_step: 8473, epoch: 12, loss: 1.204681
global_step: 8474, epoch: 12, loss: 1.223524
global_step: 8475, epoch: 12, loss: 1.185224
global_step: 8476, epoch: 12, loss: 1.203255
global_step: 8477, epoch: 12, loss: 1.350449
global_step: 8478, epoch: 12, loss: 1.273156
global_step: 8479, epoch: 12, loss: 1.062012
global_step: 8480, epoch: 12, loss: 1.686295
epoch: 12
train	acc: 0.6165	macro: p 0.4034, r 0.3354, f1: 0.3398	micro: p 0.6165, r 0.6165, f1 0.6165	weighted_f1:0.5705
dev	acc: 0.5410	macro: p 0.3285, r 0.2919, f1: 0.2817	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4787
test	acc: 0.5858	macro: p 0.3676, r 0.3017, f1: 0.3003	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5363
New best model!
global_step: 8481, epoch: 13, loss: 1.318905
global_step: 8482, epoch: 13, loss: 1.197239
global_step: 8483, epoch: 13, loss: 1.093581
global_step: 8484, epoch: 13, loss: 1.066182
global_step: 8485, epoch: 13, loss: 1.342008
global_step: 8486, epoch: 13, loss: 1.261069
global_step: 8487, epoch: 13, loss: 1.193833
global_step: 8488, epoch: 13, loss: 1.172706
global_step: 8489, epoch: 13, loss: 1.237734
global_step: 8490, epoch: 13, loss: 1.193558
global_step: 8491, epoch: 13, loss: 1.240670
global_step: 8492, epoch: 13, loss: 1.212708
global_step: 8493, epoch: 13, loss: 1.218322
global_step: 8494, epoch: 13, loss: 1.202132
global_step: 8495, epoch: 13, loss: 1.241893
global_step: 8496, epoch: 13, loss: 1.331727
global_step: 8497, epoch: 13, loss: 1.204022
global_step: 8498, epoch: 13, loss: 1.147998
global_step: 8499, epoch: 13, loss: 1.290838
global_step: 8500, epoch: 13, loss: 1.212338
global_step: 8501, epoch: 13, loss: 1.198867
global_step: 8502, epoch: 13, loss: 1.093740
global_step: 8503, epoch: 13, loss: 1.279985
global_step: 8504, epoch: 13, loss: 1.173390
global_step: 8505, epoch: 13, loss: 1.204310
global_step: 8506, epoch: 13, loss: 1.201164
global_step: 8507, epoch: 13, loss: 1.241038
global_step: 8508, epoch: 13, loss: 1.175771
global_step: 8509, epoch: 13, loss: 1.239849
global_step: 8510, epoch: 13, loss: 1.278599
global_step: 8511, epoch: 13, loss: 1.187311
global_step: 8512, epoch: 13, loss: 1.155906
global_step: 8513, epoch: 13, loss: 1.166141
global_step: 8514, epoch: 13, loss: 1.149451
global_step: 8515, epoch: 13, loss: 1.146432
global_step: 8516, epoch: 13, loss: 1.295520
global_step: 8517, epoch: 13, loss: 1.266726
global_step: 8518, epoch: 13, loss: 1.191306
global_step: 8519, epoch: 13, loss: 1.247773
global_step: 8520, epoch: 13, loss: 1.240585
epoch: 13
train	acc: 0.6236	macro: p 0.3932, r 0.3426, f1: 0.3545	micro: p 0.6236, r 0.6236, f1 0.6236	weighted_f1:0.5824
dev	acc: 0.5320	macro: p 0.3077, r 0.2838, f1: 0.2745	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4710
test	acc: 0.5897	macro: p 0.3440, r 0.3012, f1: 0.3044	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5412
global_step: 8521, epoch: 14, loss: 1.219128
global_step: 8522, epoch: 14, loss: 1.246869
global_step: 8523, epoch: 14, loss: 1.232092
global_step: 8524, epoch: 14, loss: 1.205829
global_step: 8525, epoch: 14, loss: 1.313443
global_step: 8526, epoch: 14, loss: 1.176332
global_step: 8527, epoch: 14, loss: 1.122324
global_step: 8528, epoch: 14, loss: 1.070225
global_step: 8529, epoch: 14, loss: 1.172269
global_step: 8530, epoch: 14, loss: 1.193816
global_step: 8531, epoch: 14, loss: 1.274495
global_step: 8532, epoch: 14, loss: 1.212820
global_step: 8533, epoch: 14, loss: 1.207518
global_step: 8534, epoch: 14, loss: 1.164359
global_step: 8535, epoch: 14, loss: 1.139888
global_step: 8536, epoch: 14, loss: 1.165326
global_step: 8537, epoch: 14, loss: 1.115269
global_step: 8538, epoch: 14, loss: 1.150052
global_step: 8539, epoch: 14, loss: 1.257154
global_step: 8540, epoch: 14, loss: 1.162233
global_step: 8541, epoch: 14, loss: 1.228456
global_step: 8542, epoch: 14, loss: 1.311466
global_step: 8543, epoch: 14, loss: 1.147628
global_step: 8544, epoch: 14, loss: 1.198844
global_step: 8545, epoch: 14, loss: 1.242388
global_step: 8546, epoch: 14, loss: 1.151938
global_step: 8547, epoch: 14, loss: 1.186839
global_step: 8548, epoch: 14, loss: 1.161205
global_step: 8549, epoch: 14, loss: 1.201248
global_step: 8550, epoch: 14, loss: 1.248654
global_step: 8551, epoch: 14, loss: 1.185854
global_step: 8552, epoch: 14, loss: 1.232979
global_step: 8553, epoch: 14, loss: 1.199003
global_step: 8554, epoch: 14, loss: 1.156363
global_step: 8555, epoch: 14, loss: 1.194755
global_step: 8556, epoch: 14, loss: 1.155496
global_step: 8557, epoch: 14, loss: 1.161628
global_step: 8558, epoch: 14, loss: 1.202964
global_step: 8559, epoch: 14, loss: 1.259777
global_step: 8560, epoch: 14, loss: 1.341133
epoch: 14
train	acc: 0.6179	macro: p 0.4275, r 0.3201, f1: 0.3319	micro: p 0.6179, r 0.6179, f1 0.6179	weighted_f1:0.5648
dev	acc: 0.5410	macro: p 0.3347, r 0.2825, f1: 0.2663	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4660
test	acc: 0.5920	macro: p 0.3784, r 0.2929, f1: 0.2916	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5315
global_step: 8561, epoch: 15, loss: 1.170058
global_step: 8562, epoch: 15, loss: 1.122210
global_step: 8563, epoch: 15, loss: 1.288862
global_step: 8564, epoch: 15, loss: 1.169790
global_step: 8565, epoch: 15, loss: 1.132951
global_step: 8566, epoch: 15, loss: 1.123426
global_step: 8567, epoch: 15, loss: 1.159201
global_step: 8568, epoch: 15, loss: 1.209823
global_step: 8569, epoch: 15, loss: 1.275309
global_step: 8570, epoch: 15, loss: 1.077042
global_step: 8571, epoch: 15, loss: 1.210654
global_step: 8572, epoch: 15, loss: 1.127245
global_step: 8573, epoch: 15, loss: 1.113689
global_step: 8574, epoch: 15, loss: 1.142277
global_step: 8575, epoch: 15, loss: 1.248915
global_step: 8576, epoch: 15, loss: 1.182708
global_step: 8577, epoch: 15, loss: 1.115575
global_step: 8578, epoch: 15, loss: 1.113113
global_step: 8579, epoch: 15, loss: 1.238067
global_step: 8580, epoch: 15, loss: 1.166508
global_step: 8581, epoch: 15, loss: 1.170558
global_step: 8582, epoch: 15, loss: 1.200598
global_step: 8583, epoch: 15, loss: 1.110087
global_step: 8584, epoch: 15, loss: 1.291395
global_step: 8585, epoch: 15, loss: 1.208215
global_step: 8586, epoch: 15, loss: 1.222101
global_step: 8587, epoch: 15, loss: 1.216052
global_step: 8588, epoch: 15, loss: 1.228411
global_step: 8589, epoch: 15, loss: 1.173922
global_step: 8590, epoch: 15, loss: 1.198629
global_step: 8591, epoch: 15, loss: 1.211294
global_step: 8592, epoch: 15, loss: 1.160409
global_step: 8593, epoch: 15, loss: 1.219991
global_step: 8594, epoch: 15, loss: 1.116982
global_step: 8595, epoch: 15, loss: 1.269738
global_step: 8596, epoch: 15, loss: 1.248139
global_step: 8597, epoch: 15, loss: 1.119110
global_step: 8598, epoch: 15, loss: 1.251419
global_step: 8599, epoch: 15, loss: 1.210237
global_step: 8600, epoch: 15, loss: 0.982942
epoch: 15
train	acc: 0.6233	macro: p 0.4358, r 0.3273, f1: 0.3373	micro: p 0.6233, r 0.6233, f1 0.6233	weighted_f1:0.5718
dev	acc: 0.5446	macro: p 0.3585, r 0.2870, f1: 0.2767	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4762
test	acc: 0.5950	macro: p 0.3913, r 0.2972, f1: 0.2995	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5393
global_step: 8601, epoch: 16, loss: 1.262272
global_step: 8602, epoch: 16, loss: 1.111610
global_step: 8603, epoch: 16, loss: 1.223112
global_step: 8604, epoch: 16, loss: 1.141542
global_step: 8605, epoch: 16, loss: 1.170726
global_step: 8606, epoch: 16, loss: 1.237989
global_step: 8607, epoch: 16, loss: 1.206936
global_step: 8608, epoch: 16, loss: 1.120828
global_step: 8609, epoch: 16, loss: 1.056423
global_step: 8610, epoch: 16, loss: 1.194332
global_step: 8611, epoch: 16, loss: 1.126426
global_step: 8612, epoch: 16, loss: 1.074155
global_step: 8613, epoch: 16, loss: 1.137081
global_step: 8614, epoch: 16, loss: 1.113575
global_step: 8615, epoch: 16, loss: 1.159175
global_step: 8616, epoch: 16, loss: 1.157437
global_step: 8617, epoch: 16, loss: 1.113100
global_step: 8618, epoch: 16, loss: 1.215351
global_step: 8619, epoch: 16, loss: 1.171168
global_step: 8620, epoch: 16, loss: 1.248245
global_step: 8621, epoch: 16, loss: 1.230195
global_step: 8622, epoch: 16, loss: 1.241182
global_step: 8623, epoch: 16, loss: 1.159879
global_step: 8624, epoch: 16, loss: 1.080535
global_step: 8625, epoch: 16, loss: 1.131593
global_step: 8626, epoch: 16, loss: 1.194590
global_step: 8627, epoch: 16, loss: 1.080682
global_step: 8628, epoch: 16, loss: 1.171183
global_step: 8629, epoch: 16, loss: 1.145929
global_step: 8630, epoch: 16, loss: 1.124610
global_step: 8631, epoch: 16, loss: 1.118589
global_step: 8632, epoch: 16, loss: 1.122545
global_step: 8633, epoch: 16, loss: 1.199007
global_step: 8634, epoch: 16, loss: 1.196375
global_step: 8635, epoch: 16, loss: 1.225606
global_step: 8636, epoch: 16, loss: 1.203594
global_step: 8637, epoch: 16, loss: 1.161140
global_step: 8638, epoch: 16, loss: 1.211841
global_step: 8639, epoch: 16, loss: 1.266546
global_step: 8640, epoch: 16, loss: 0.842944
epoch: 16
train	acc: 0.6323	macro: p 0.4411, r 0.3368, f1: 0.3471	micro: p 0.6323, r 0.6323, f1 0.6323	weighted_f1:0.5811
dev	acc: 0.5473	macro: p 0.3608, r 0.2893, f1: 0.2738	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4736
test	acc: 0.5931	macro: p 0.3865, r 0.2971, f1: 0.2961	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5349
global_step: 8641, epoch: 17, loss: 1.138302
global_step: 8642, epoch: 17, loss: 1.149100
global_step: 8643, epoch: 17, loss: 1.195340
global_step: 8644, epoch: 17, loss: 1.106210
global_step: 8645, epoch: 17, loss: 1.060506
global_step: 8646, epoch: 17, loss: 1.178817
global_step: 8647, epoch: 17, loss: 1.071367
global_step: 8648, epoch: 17, loss: 1.134760
global_step: 8649, epoch: 17, loss: 1.205208
global_step: 8650, epoch: 17, loss: 1.145020
global_step: 8651, epoch: 17, loss: 1.101418
global_step: 8652, epoch: 17, loss: 1.291294
global_step: 8653, epoch: 17, loss: 1.168355
global_step: 8654, epoch: 17, loss: 1.227089
global_step: 8655, epoch: 17, loss: 1.125227
global_step: 8656, epoch: 17, loss: 1.123906
global_step: 8657, epoch: 17, loss: 1.166496
global_step: 8658, epoch: 17, loss: 1.159011
global_step: 8659, epoch: 17, loss: 1.157740
global_step: 8660, epoch: 17, loss: 1.134507
global_step: 8661, epoch: 17, loss: 1.193903
global_step: 8662, epoch: 17, loss: 1.129695
global_step: 8663, epoch: 17, loss: 1.221124
global_step: 8664, epoch: 17, loss: 1.196402
global_step: 8665, epoch: 17, loss: 1.154686
global_step: 8666, epoch: 17, loss: 1.219047
global_step: 8667, epoch: 17, loss: 1.128973
global_step: 8668, epoch: 17, loss: 1.194733
global_step: 8669, epoch: 17, loss: 1.113049
global_step: 8670, epoch: 17, loss: 1.110072
global_step: 8671, epoch: 17, loss: 1.229176
global_step: 8672, epoch: 17, loss: 1.097326
global_step: 8673, epoch: 17, loss: 1.143448
global_step: 8674, epoch: 17, loss: 1.214633
global_step: 8675, epoch: 17, loss: 1.150776
global_step: 8676, epoch: 17, loss: 1.228531
global_step: 8677, epoch: 17, loss: 1.192923
global_step: 8678, epoch: 17, loss: 1.140284
global_step: 8679, epoch: 17, loss: 1.166777
global_step: 8680, epoch: 17, loss: 0.977798
epoch: 17
train	acc: 0.6417	macro: p 0.4347, r 0.3533, f1: 0.3634	micro: p 0.6417, r 0.6417, f1 0.6417	weighted_f1:0.5951
dev	acc: 0.5518	macro: p 0.3361, r 0.2981, f1: 0.2853	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4849
test	acc: 0.5946	macro: p 0.3714, r 0.3038, f1: 0.3042	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5412
New best model!
global_step: 8681, epoch: 18, loss: 1.136737
global_step: 8682, epoch: 18, loss: 1.169274
global_step: 8683, epoch: 18, loss: 1.205922
global_step: 8684, epoch: 18, loss: 1.219350
global_step: 8685, epoch: 18, loss: 1.120235
global_step: 8686, epoch: 18, loss: 1.048562
global_step: 8687, epoch: 18, loss: 1.062151
global_step: 8688, epoch: 18, loss: 1.123825
global_step: 8689, epoch: 18, loss: 1.140421
global_step: 8690, epoch: 18, loss: 1.071097
global_step: 8691, epoch: 18, loss: 1.240880
global_step: 8692, epoch: 18, loss: 1.128318
global_step: 8693, epoch: 18, loss: 1.219022
global_step: 8694, epoch: 18, loss: 1.065589
global_step: 8695, epoch: 18, loss: 1.196569
global_step: 8696, epoch: 18, loss: 1.041522
global_step: 8697, epoch: 18, loss: 1.186670
global_step: 8698, epoch: 18, loss: 1.116995
global_step: 8699, epoch: 18, loss: 1.139191
global_step: 8700, epoch: 18, loss: 1.009600
global_step: 8701, epoch: 18, loss: 1.139353
global_step: 8702, epoch: 18, loss: 1.147614
global_step: 8703, epoch: 18, loss: 1.100665
global_step: 8704, epoch: 18, loss: 1.204411
global_step: 8705, epoch: 18, loss: 1.128888
global_step: 8706, epoch: 18, loss: 1.254047
global_step: 8707, epoch: 18, loss: 1.127192
global_step: 8708, epoch: 18, loss: 1.224365
global_step: 8709, epoch: 18, loss: 1.230281
global_step: 8710, epoch: 18, loss: 1.179121
global_step: 8711, epoch: 18, loss: 1.151298
global_step: 8712, epoch: 18, loss: 1.260093
global_step: 8713, epoch: 18, loss: 1.183843
global_step: 8714, epoch: 18, loss: 1.200282
global_step: 8715, epoch: 18, loss: 1.075580
global_step: 8716, epoch: 18, loss: 1.126730
global_step: 8717, epoch: 18, loss: 1.320847
global_step: 8718, epoch: 18, loss: 1.049101
global_step: 8719, epoch: 18, loss: 1.181107
global_step: 8720, epoch: 18, loss: 1.330336
epoch: 18
train	acc: 0.6477	macro: p 0.4321, r 0.3627, f1: 0.3716	micro: p 0.6477, r 0.6477, f1 0.6477	weighted_f1:0.6053
dev	acc: 0.5528	macro: p 0.3386, r 0.3038, f1: 0.2953	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4942
test	acc: 0.5985	macro: p 0.3746, r 0.3077, f1: 0.3090	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5484
New best model!
global_step: 8721, epoch: 19, loss: 1.132126
global_step: 8722, epoch: 19, loss: 1.070956
global_step: 8723, epoch: 19, loss: 1.177456
global_step: 8724, epoch: 19, loss: 0.971809
global_step: 8725, epoch: 19, loss: 1.259084
global_step: 8726, epoch: 19, loss: 0.984531
global_step: 8727, epoch: 19, loss: 1.138561
global_step: 8728, epoch: 19, loss: 1.117385
global_step: 8729, epoch: 19, loss: 1.123033
global_step: 8730, epoch: 19, loss: 1.071394
global_step: 8731, epoch: 19, loss: 1.183973
global_step: 8732, epoch: 19, loss: 1.131602
global_step: 8733, epoch: 19, loss: 1.144858
global_step: 8734, epoch: 19, loss: 1.123991
global_step: 8735, epoch: 19, loss: 1.121605
global_step: 8736, epoch: 19, loss: 1.083911
global_step: 8737, epoch: 19, loss: 1.195563
global_step: 8738, epoch: 19, loss: 1.202411
global_step: 8739, epoch: 19, loss: 1.086218
global_step: 8740, epoch: 19, loss: 1.153159
global_step: 8741, epoch: 19, loss: 1.061225
global_step: 8742, epoch: 19, loss: 1.171937
global_step: 8743, epoch: 19, loss: 1.052908
global_step: 8744, epoch: 19, loss: 1.156327
global_step: 8745, epoch: 19, loss: 1.088644
global_step: 8746, epoch: 19, loss: 1.049428
global_step: 8747, epoch: 19, loss: 1.090973
global_step: 8748, epoch: 19, loss: 1.072361
global_step: 8749, epoch: 19, loss: 1.206004
global_step: 8750, epoch: 19, loss: 1.146436
global_step: 8751, epoch: 19, loss: 1.059285
global_step: 8752, epoch: 19, loss: 1.136419
global_step: 8753, epoch: 19, loss: 1.194306
global_step: 8754, epoch: 19, loss: 1.085169
global_step: 8755, epoch: 19, loss: 1.159729
global_step: 8756, epoch: 19, loss: 1.231888
global_step: 8757, epoch: 19, loss: 1.309211
global_step: 8758, epoch: 19, loss: 1.123063
global_step: 8759, epoch: 19, loss: 1.152238
global_step: 8760, epoch: 19, loss: 0.612903
epoch: 19
train	acc: 0.6497	macro: p 0.4400, r 0.3625, f1: 0.3725	micro: p 0.6497, r 0.6497, f1 0.6497	weighted_f1:0.6069
dev	acc: 0.5555	macro: p 0.3534, r 0.3040, f1: 0.2958	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4956
test	acc: 0.5966	macro: p 0.3796, r 0.3053, f1: 0.3082	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5466
New best model!
global_step: 8761, epoch: 20, loss: 1.039317
global_step: 8762, epoch: 20, loss: 1.005586
global_step: 8763, epoch: 20, loss: 1.190863
global_step: 8764, epoch: 20, loss: 1.077772
global_step: 8765, epoch: 20, loss: 1.104955
global_step: 8766, epoch: 20, loss: 1.092298
global_step: 8767, epoch: 20, loss: 0.935682
global_step: 8768, epoch: 20, loss: 1.036735
global_step: 8769, epoch: 20, loss: 1.130002
global_step: 8770, epoch: 20, loss: 1.104300
global_step: 8771, epoch: 20, loss: 1.108790
global_step: 8772, epoch: 20, loss: 1.291695
global_step: 8773, epoch: 20, loss: 1.021719
global_step: 8774, epoch: 20, loss: 1.128715
global_step: 8775, epoch: 20, loss: 1.207544
global_step: 8776, epoch: 20, loss: 1.130496
global_step: 8777, epoch: 20, loss: 0.966326
global_step: 8778, epoch: 20, loss: 1.070127
global_step: 8779, epoch: 20, loss: 1.139144
global_step: 8780, epoch: 20, loss: 1.144873
global_step: 8781, epoch: 20, loss: 1.117948
global_step: 8782, epoch: 20, loss: 1.107435
global_step: 8783, epoch: 20, loss: 1.111180
global_step: 8784, epoch: 20, loss: 1.097049
global_step: 8785, epoch: 20, loss: 1.193143
global_step: 8786, epoch: 20, loss: 1.296242
global_step: 8787, epoch: 20, loss: 1.026020
global_step: 8788, epoch: 20, loss: 1.147507
global_step: 8789, epoch: 20, loss: 1.083414
global_step: 8790, epoch: 20, loss: 1.034188
global_step: 8791, epoch: 20, loss: 1.048129
global_step: 8792, epoch: 20, loss: 1.186051
global_step: 8793, epoch: 20, loss: 1.150178
global_step: 8794, epoch: 20, loss: 1.150896
global_step: 8795, epoch: 20, loss: 1.112045
global_step: 8796, epoch: 20, loss: 1.061783
global_step: 8797, epoch: 20, loss: 1.167413
global_step: 8798, epoch: 20, loss: 1.204772
global_step: 8799, epoch: 20, loss: 1.112372
global_step: 8800, epoch: 20, loss: 0.340716
epoch: 20
train	acc: 0.6446	macro: p 0.4582, r 0.3465, f1: 0.3616	micro: p 0.6446, r 0.6446, f1 0.6446	weighted_f1:0.5948
dev	acc: 0.5528	macro: p 0.3623, r 0.2929, f1: 0.2830	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4821
test	acc: 0.5992	macro: p 0.3867, r 0.2999, f1: 0.3047	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5420
global_step: 8801, epoch: 21, loss: 1.080648
global_step: 8802, epoch: 21, loss: 1.127355
global_step: 8803, epoch: 21, loss: 1.015172
global_step: 8804, epoch: 21, loss: 1.174930
global_step: 8805, epoch: 21, loss: 1.073292
global_step: 8806, epoch: 21, loss: 1.160744
global_step: 8807, epoch: 21, loss: 1.059340
global_step: 8808, epoch: 21, loss: 1.164635
global_step: 8809, epoch: 21, loss: 1.073106
global_step: 8810, epoch: 21, loss: 1.089748
global_step: 8811, epoch: 21, loss: 1.180393
global_step: 8812, epoch: 21, loss: 1.129453
global_step: 8813, epoch: 21, loss: 1.191187
global_step: 8814, epoch: 21, loss: 1.106048
global_step: 8815, epoch: 21, loss: 1.105543
global_step: 8816, epoch: 21, loss: 1.073373
global_step: 8817, epoch: 21, loss: 1.025834
global_step: 8818, epoch: 21, loss: 1.060142
global_step: 8819, epoch: 21, loss: 0.958533
global_step: 8820, epoch: 21, loss: 1.074503
global_step: 8821, epoch: 21, loss: 1.098770
global_step: 8822, epoch: 21, loss: 1.086467
global_step: 8823, epoch: 21, loss: 1.097091
global_step: 8824, epoch: 21, loss: 1.104270
global_step: 8825, epoch: 21, loss: 1.112852
global_step: 8826, epoch: 21, loss: 1.038876
global_step: 8827, epoch: 21, loss: 1.132159
global_step: 8828, epoch: 21, loss: 1.053227
global_step: 8829, epoch: 21, loss: 1.101616
global_step: 8830, epoch: 21, loss: 1.198664
global_step: 8831, epoch: 21, loss: 1.096879
global_step: 8832, epoch: 21, loss: 1.044761
global_step: 8833, epoch: 21, loss: 1.169664
global_step: 8834, epoch: 21, loss: 1.043399
global_step: 8835, epoch: 21, loss: 1.066292
global_step: 8836, epoch: 21, loss: 1.047435
global_step: 8837, epoch: 21, loss: 1.121962
global_step: 8838, epoch: 21, loss: 1.140358
global_step: 8839, epoch: 21, loss: 1.123746
global_step: 8840, epoch: 21, loss: 0.896779
epoch: 21
train	acc: 0.6663	macro: p 0.4497, r 0.3860, f1: 0.3959	micro: p 0.6663, r 0.6663, f1 0.6663	weighted_f1:0.6273
dev	acc: 0.5627	macro: p 0.3543, r 0.3141, f1: 0.3080	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5064
test	acc: 0.5981	macro: p 0.3643, r 0.3108, f1: 0.3125	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5507
New best model!
global_step: 8841, epoch: 22, loss: 1.056460
global_step: 8842, epoch: 22, loss: 1.111840
global_step: 8843, epoch: 22, loss: 1.021307
global_step: 8844, epoch: 22, loss: 0.973210
global_step: 8845, epoch: 22, loss: 1.121854
global_step: 8846, epoch: 22, loss: 1.083407
global_step: 8847, epoch: 22, loss: 1.094910
global_step: 8848, epoch: 22, loss: 0.970207
global_step: 8849, epoch: 22, loss: 1.126936
global_step: 8850, epoch: 22, loss: 1.143820
global_step: 8851, epoch: 22, loss: 1.001210
global_step: 8852, epoch: 22, loss: 1.123435
global_step: 8853, epoch: 22, loss: 1.184296
global_step: 8854, epoch: 22, loss: 0.936445
global_step: 8855, epoch: 22, loss: 0.972991
global_step: 8856, epoch: 22, loss: 1.141716
global_step: 8857, epoch: 22, loss: 0.916315
global_step: 8858, epoch: 22, loss: 1.092661
global_step: 8859, epoch: 22, loss: 1.103010
global_step: 8860, epoch: 22, loss: 1.172037
global_step: 8861, epoch: 22, loss: 1.200284
global_step: 8862, epoch: 22, loss: 1.101771
global_step: 8863, epoch: 22, loss: 1.037495
global_step: 8864, epoch: 22, loss: 1.123919
global_step: 8865, epoch: 22, loss: 1.029337
global_step: 8866, epoch: 22, loss: 1.116699
global_step: 8867, epoch: 22, loss: 1.051108
global_step: 8868, epoch: 22, loss: 1.034873
global_step: 8869, epoch: 22, loss: 1.099258
global_step: 8870, epoch: 22, loss: 1.120301
global_step: 8871, epoch: 22, loss: 1.050114
global_step: 8872, epoch: 22, loss: 1.062620
global_step: 8873, epoch: 22, loss: 1.065746
global_step: 8874, epoch: 22, loss: 1.197129
global_step: 8875, epoch: 22, loss: 1.136467
global_step: 8876, epoch: 22, loss: 1.121378
global_step: 8877, epoch: 22, loss: 1.004599
global_step: 8878, epoch: 22, loss: 0.998489
global_step: 8879, epoch: 22, loss: 1.193008
global_step: 8880, epoch: 22, loss: 1.066054
epoch: 22
train	acc: 0.6804	macro: p 0.4547, r 0.4031, f1: 0.4131	micro: p 0.6804, r 0.6804, f1 0.6804	weighted_f1:0.6439
dev	acc: 0.5482	macro: p 0.3214, r 0.3021, f1: 0.2827	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4824
test	acc: 0.5912	macro: p 0.3563, r 0.3092, f1: 0.3050	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5403
global_step: 8881, epoch: 23, loss: 1.034388
global_step: 8882, epoch: 23, loss: 1.100321
global_step: 8883, epoch: 23, loss: 1.160095
global_step: 8884, epoch: 23, loss: 1.055489
global_step: 8885, epoch: 23, loss: 1.145137
global_step: 8886, epoch: 23, loss: 1.101258
global_step: 8887, epoch: 23, loss: 1.146896
global_step: 8888, epoch: 23, loss: 1.085435
global_step: 8889, epoch: 23, loss: 1.001360
global_step: 8890, epoch: 23, loss: 1.033586
global_step: 8891, epoch: 23, loss: 0.913225
global_step: 8892, epoch: 23, loss: 1.122556
global_step: 8893, epoch: 23, loss: 1.075654
global_step: 8894, epoch: 23, loss: 0.963310
global_step: 8895, epoch: 23, loss: 0.944223
global_step: 8896, epoch: 23, loss: 1.164658
global_step: 8897, epoch: 23, loss: 1.036684
global_step: 8898, epoch: 23, loss: 0.961352
global_step: 8899, epoch: 23, loss: 1.023585
global_step: 8900, epoch: 23, loss: 1.017699
global_step: 8901, epoch: 23, loss: 1.125323
global_step: 8902, epoch: 23, loss: 1.025403
global_step: 8903, epoch: 23, loss: 1.113234
global_step: 8904, epoch: 23, loss: 0.991186
global_step: 8905, epoch: 23, loss: 1.156078
global_step: 8906, epoch: 23, loss: 1.117538
global_step: 8907, epoch: 23, loss: 1.115994
global_step: 8908, epoch: 23, loss: 1.052797
global_step: 8909, epoch: 23, loss: 1.011358
global_step: 8910, epoch: 23, loss: 1.083104
global_step: 8911, epoch: 23, loss: 1.012472
global_step: 8912, epoch: 23, loss: 1.094709
global_step: 8913, epoch: 23, loss: 0.986654
global_step: 8914, epoch: 23, loss: 1.138736
global_step: 8915, epoch: 23, loss: 1.036927
global_step: 8916, epoch: 23, loss: 1.082478
global_step: 8917, epoch: 23, loss: 1.204197
global_step: 8918, epoch: 23, loss: 1.062033
global_step: 8919, epoch: 23, loss: 1.062082
global_step: 8920, epoch: 23, loss: 1.105530
epoch: 23
train	acc: 0.6858	macro: p 0.4648, r 0.4119, f1: 0.4206	micro: p 0.6858, r 0.6858, f1 0.6858	weighted_f1:0.6529
dev	acc: 0.5627	macro: p 0.3457, r 0.3135, f1: 0.3064	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5071
test	acc: 0.6008	macro: p 0.3674, r 0.3172, f1: 0.3209	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5575
New best model!
global_step: 8921, epoch: 24, loss: 0.985863
global_step: 8922, epoch: 24, loss: 1.208573
global_step: 8923, epoch: 24, loss: 0.958567
global_step: 8924, epoch: 24, loss: 0.996042
global_step: 8925, epoch: 24, loss: 1.057328
global_step: 8926, epoch: 24, loss: 0.945789
global_step: 8927, epoch: 24, loss: 0.930853
global_step: 8928, epoch: 24, loss: 1.149136
global_step: 8929, epoch: 24, loss: 1.059567
global_step: 8930, epoch: 24, loss: 1.041832
global_step: 8931, epoch: 24, loss: 1.075105
global_step: 8932, epoch: 24, loss: 0.956197
global_step: 8933, epoch: 24, loss: 1.080402
global_step: 8934, epoch: 24, loss: 1.040002
global_step: 8935, epoch: 24, loss: 1.062553
global_step: 8936, epoch: 24, loss: 1.037018
global_step: 8937, epoch: 24, loss: 1.101654
global_step: 8938, epoch: 24, loss: 1.024514
global_step: 8939, epoch: 24, loss: 1.135078
global_step: 8940, epoch: 24, loss: 1.013850
global_step: 8941, epoch: 24, loss: 1.132926
global_step: 8942, epoch: 24, loss: 1.022778
global_step: 8943, epoch: 24, loss: 1.034416
global_step: 8944, epoch: 24, loss: 1.079758
global_step: 8945, epoch: 24, loss: 1.055601
global_step: 8946, epoch: 24, loss: 1.037714
global_step: 8947, epoch: 24, loss: 0.929195
global_step: 8948, epoch: 24, loss: 1.134606
global_step: 8949, epoch: 24, loss: 1.099932
global_step: 8950, epoch: 24, loss: 1.009855
global_step: 8951, epoch: 24, loss: 1.060249
global_step: 8952, epoch: 24, loss: 1.126279
global_step: 8953, epoch: 24, loss: 0.961355
global_step: 8954, epoch: 24, loss: 1.094293
global_step: 8955, epoch: 24, loss: 1.138830
global_step: 8956, epoch: 24, loss: 1.043703
global_step: 8957, epoch: 24, loss: 1.073380
global_step: 8958, epoch: 24, loss: 1.086494
global_step: 8959, epoch: 24, loss: 1.073992
global_step: 8960, epoch: 24, loss: 0.819615
epoch: 24
train	acc: 0.7134	macro: p 0.4666, r 0.4542, f1: 0.4574	micro: p 0.7134, r 0.7134, f1 0.7134	weighted_f1:0.6848
dev	acc: 0.5546	macro: p 0.3252, r 0.3159, f1: 0.3071	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5034
test	acc: 0.6000	macro: p 0.3510, r 0.3285, f1: 0.3282	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5604
global_step: 8961, epoch: 25, loss: 1.030259
global_step: 8962, epoch: 25, loss: 1.044689
global_step: 8963, epoch: 25, loss: 0.983630
global_step: 8964, epoch: 25, loss: 1.040955
global_step: 8965, epoch: 25, loss: 1.097308
global_step: 8966, epoch: 25, loss: 1.146032
global_step: 8967, epoch: 25, loss: 0.938157
global_step: 8968, epoch: 25, loss: 0.953068
global_step: 8969, epoch: 25, loss: 1.028484
global_step: 8970, epoch: 25, loss: 1.066089
global_step: 8971, epoch: 25, loss: 0.965993
global_step: 8972, epoch: 25, loss: 1.021665
global_step: 8973, epoch: 25, loss: 1.096224
global_step: 8974, epoch: 25, loss: 1.030862
global_step: 8975, epoch: 25, loss: 0.940394
global_step: 8976, epoch: 25, loss: 1.095949
global_step: 8977, epoch: 25, loss: 1.092211
global_step: 8978, epoch: 25, loss: 1.044829
global_step: 8979, epoch: 25, loss: 1.150029
global_step: 8980, epoch: 25, loss: 1.069374
global_step: 8981, epoch: 25, loss: 1.012090
global_step: 8982, epoch: 25, loss: 1.042240
global_step: 8983, epoch: 25, loss: 1.036555
global_step: 8984, epoch: 25, loss: 0.940514
global_step: 8985, epoch: 25, loss: 1.052309
global_step: 8986, epoch: 25, loss: 0.970205
global_step: 8987, epoch: 25, loss: 0.966205
global_step: 8988, epoch: 25, loss: 1.051224
global_step: 8989, epoch: 25, loss: 1.048786
global_step: 8990, epoch: 25, loss: 1.097793
global_step: 8991, epoch: 25, loss: 0.970940
global_step: 8992, epoch: 25, loss: 1.098648
global_step: 8993, epoch: 25, loss: 1.141231
global_step: 8994, epoch: 25, loss: 1.051318
global_step: 8995, epoch: 25, loss: 1.070006
global_step: 8996, epoch: 25, loss: 1.002513
global_step: 8997, epoch: 25, loss: 1.171325
global_step: 8998, epoch: 25, loss: 1.036209
global_step: 8999, epoch: 25, loss: 1.044402
global_step: 9000, epoch: 25, loss: 0.933595
epoch: 25
train	acc: 0.7103	macro: p 0.4777, r 0.4390, f1: 0.4495	micro: p 0.7103, r 0.7103, f1 0.7103	weighted_f1:0.6777
dev	acc: 0.5618	macro: p 0.3383, r 0.3139, f1: 0.3042	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5035
test	acc: 0.5992	macro: p 0.3587, r 0.3190, f1: 0.3199	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5539
global_step: 9001, epoch: 26, loss: 0.952322
global_step: 9002, epoch: 26, loss: 0.902688
global_step: 9003, epoch: 26, loss: 1.047623
global_step: 9004, epoch: 26, loss: 0.999098
global_step: 9005, epoch: 26, loss: 1.070235
global_step: 9006, epoch: 26, loss: 0.990887
global_step: 9007, epoch: 26, loss: 0.965702
global_step: 9008, epoch: 26, loss: 1.043766
global_step: 9009, epoch: 26, loss: 1.128226
global_step: 9010, epoch: 26, loss: 1.122056
global_step: 9011, epoch: 26, loss: 1.128993
global_step: 9012, epoch: 26, loss: 0.928214
global_step: 9013, epoch: 26, loss: 1.051724
global_step: 9014, epoch: 26, loss: 0.985487
global_step: 9015, epoch: 26, loss: 1.037542
global_step: 9016, epoch: 26, loss: 1.029189
global_step: 9017, epoch: 26, loss: 1.075516
global_step: 9018, epoch: 26, loss: 1.016639
global_step: 9019, epoch: 26, loss: 0.971434
global_step: 9020, epoch: 26, loss: 1.074117
global_step: 9021, epoch: 26, loss: 1.057135
global_step: 9022, epoch: 26, loss: 0.958928
global_step: 9023, epoch: 26, loss: 0.947568
global_step: 9024, epoch: 26, loss: 1.052866
global_step: 9025, epoch: 26, loss: 1.048249
global_step: 9026, epoch: 26, loss: 1.041078
global_step: 9027, epoch: 26, loss: 1.097001
global_step: 9028, epoch: 26, loss: 1.021796
global_step: 9029, epoch: 26, loss: 1.078005
global_step: 9030, epoch: 26, loss: 0.932377
global_step: 9031, epoch: 26, loss: 0.939503
global_step: 9032, epoch: 26, loss: 0.883896
global_step: 9033, epoch: 26, loss: 1.096526
global_step: 9034, epoch: 26, loss: 1.095538
global_step: 9035, epoch: 26, loss: 1.019462
global_step: 9036, epoch: 26, loss: 1.116157
global_step: 9037, epoch: 26, loss: 0.879146
global_step: 9038, epoch: 26, loss: 1.050970
global_step: 9039, epoch: 26, loss: 1.025019
global_step: 9040, epoch: 26, loss: 0.828387
epoch: 26
train	acc: 0.7027	macro: p 0.4810, r 0.4268, f1: 0.4316	micro: p 0.7027, r 0.7027, f1 0.7027	weighted_f1:0.6695
dev	acc: 0.5446	macro: p 0.3510, r 0.3092, f1: 0.2864	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4836
test	acc: 0.5824	macro: p 0.3551, r 0.3107, f1: 0.2981	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5326
global_step: 9041, epoch: 27, loss: 1.111835
global_step: 9042, epoch: 27, loss: 0.965977
global_step: 9043, epoch: 27, loss: 1.088016
global_step: 9044, epoch: 27, loss: 0.952591
global_step: 9045, epoch: 27, loss: 0.907189
global_step: 9046, epoch: 27, loss: 1.198278
global_step: 9047, epoch: 27, loss: 1.090558
global_step: 9048, epoch: 27, loss: 1.094868
global_step: 9049, epoch: 27, loss: 0.964018
global_step: 9050, epoch: 27, loss: 1.044146
global_step: 9051, epoch: 27, loss: 0.995341
global_step: 9052, epoch: 27, loss: 0.942494
global_step: 9053, epoch: 27, loss: 0.980480
global_step: 9054, epoch: 27, loss: 1.078777
global_step: 9055, epoch: 27, loss: 1.008668
global_step: 9056, epoch: 27, loss: 1.040543
global_step: 9057, epoch: 27, loss: 0.978548
global_step: 9058, epoch: 27, loss: 0.954293
global_step: 9059, epoch: 27, loss: 1.023481
global_step: 9060, epoch: 27, loss: 0.968781
global_step: 9061, epoch: 27, loss: 1.020716
global_step: 9062, epoch: 27, loss: 0.992912
global_step: 9063, epoch: 27, loss: 0.970239
global_step: 9064, epoch: 27, loss: 1.084212
global_step: 9065, epoch: 27, loss: 1.079470
global_step: 9066, epoch: 27, loss: 0.935955
global_step: 9067, epoch: 27, loss: 1.066636
global_step: 9068, epoch: 27, loss: 1.026448
global_step: 9069, epoch: 27, loss: 0.974309
global_step: 9070, epoch: 27, loss: 0.945467
global_step: 9071, epoch: 27, loss: 1.045515
global_step: 9072, epoch: 27, loss: 0.993417
global_step: 9073, epoch: 27, loss: 1.017025
global_step: 9074, epoch: 27, loss: 1.020682
global_step: 9075, epoch: 27, loss: 0.999300
global_step: 9076, epoch: 27, loss: 0.963430
global_step: 9077, epoch: 27, loss: 1.006906
global_step: 9078, epoch: 27, loss: 1.020624
global_step: 9079, epoch: 27, loss: 1.064171
global_step: 9080, epoch: 27, loss: 1.181689
epoch: 27
train	acc: 0.6957	macro: p 0.4862, r 0.4074, f1: 0.4235	micro: p 0.6957, r 0.6957, f1 0.6957	weighted_f1:0.6571
dev	acc: 0.5555	macro: p 0.3544, r 0.3025, f1: 0.2873	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4876
test	acc: 0.6004	macro: p 0.3834, r 0.3081, f1: 0.3085	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5452
global_step: 9081, epoch: 28, loss: 0.914547
global_step: 9082, epoch: 28, loss: 0.992806
global_step: 9083, epoch: 28, loss: 0.982660
global_step: 9084, epoch: 28, loss: 0.898173
global_step: 9085, epoch: 28, loss: 1.018376
global_step: 9086, epoch: 28, loss: 0.960471
global_step: 9087, epoch: 28, loss: 0.938143
global_step: 9088, epoch: 28, loss: 1.085546
global_step: 9089, epoch: 28, loss: 0.953649
global_step: 9090, epoch: 28, loss: 0.971555
global_step: 9091, epoch: 28, loss: 1.026086
global_step: 9092, epoch: 28, loss: 0.931986
global_step: 9093, epoch: 28, loss: 0.951193
global_step: 9094, epoch: 28, loss: 1.057834
global_step: 9095, epoch: 28, loss: 1.149092
global_step: 9096, epoch: 28, loss: 0.933942
global_step: 9097, epoch: 28, loss: 1.041067
global_step: 9098, epoch: 28, loss: 0.946436
global_step: 9099, epoch: 28, loss: 1.098510
global_step: 9100, epoch: 28, loss: 1.006714
global_step: 9101, epoch: 28, loss: 1.013469
global_step: 9102, epoch: 28, loss: 0.881410
global_step: 9103, epoch: 28, loss: 0.946193
global_step: 9104, epoch: 28, loss: 0.954579
global_step: 9105, epoch: 28, loss: 1.002870
global_step: 9106, epoch: 28, loss: 1.024798
global_step: 9107, epoch: 28, loss: 0.961299
global_step: 9108, epoch: 28, loss: 0.943125
global_step: 9109, epoch: 28, loss: 1.072420
global_step: 9110, epoch: 28, loss: 0.969527
global_step: 9111, epoch: 28, loss: 0.978914
global_step: 9112, epoch: 28, loss: 0.964680
global_step: 9113, epoch: 28, loss: 1.043454
global_step: 9114, epoch: 28, loss: 0.980053
global_step: 9115, epoch: 28, loss: 1.070357
global_step: 9116, epoch: 28, loss: 1.046859
global_step: 9117, epoch: 28, loss: 0.913091
global_step: 9118, epoch: 28, loss: 1.075241
global_step: 9119, epoch: 28, loss: 1.018315
global_step: 9120, epoch: 28, loss: 0.720227
epoch: 28
train	acc: 0.7230	macro: p 0.4936, r 0.4486, f1: 0.4609	micro: p 0.7230, r 0.7230, f1 0.7230	weighted_f1:0.6910
dev	acc: 0.5681	macro: p 0.3642, r 0.3199, f1: 0.3110	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5100
test	acc: 0.6027	macro: p 0.3675, r 0.3187, f1: 0.3210	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5558
New best model!
global_step: 9121, epoch: 29, loss: 0.941303
global_step: 9122, epoch: 29, loss: 0.937778
global_step: 9123, epoch: 29, loss: 0.968034
global_step: 9124, epoch: 29, loss: 0.967498
global_step: 9125, epoch: 29, loss: 1.092847
global_step: 9126, epoch: 29, loss: 0.865484
global_step: 9127, epoch: 29, loss: 1.006279
global_step: 9128, epoch: 29, loss: 1.071503
global_step: 9129, epoch: 29, loss: 0.948299
global_step: 9130, epoch: 29, loss: 0.953240
global_step: 9131, epoch: 29, loss: 1.031764
global_step: 9132, epoch: 29, loss: 0.967736
global_step: 9133, epoch: 29, loss: 0.960108
global_step: 9134, epoch: 29, loss: 0.918151
global_step: 9135, epoch: 29, loss: 1.041437
global_step: 9136, epoch: 29, loss: 0.896040
global_step: 9137, epoch: 29, loss: 0.875794
global_step: 9138, epoch: 29, loss: 1.014906
global_step: 9139, epoch: 29, loss: 0.934689
global_step: 9140, epoch: 29, loss: 0.892777
global_step: 9141, epoch: 29, loss: 1.151851
global_step: 9142, epoch: 29, loss: 0.974839
global_step: 9143, epoch: 29, loss: 0.856955
global_step: 9144, epoch: 29, loss: 1.006602
global_step: 9145, epoch: 29, loss: 1.044868
global_step: 9146, epoch: 29, loss: 0.863635
global_step: 9147, epoch: 29, loss: 0.997446
global_step: 9148, epoch: 29, loss: 1.006044
global_step: 9149, epoch: 29, loss: 0.873104
global_step: 9150, epoch: 29, loss: 0.993817
global_step: 9151, epoch: 29, loss: 0.970983
global_step: 9152, epoch: 29, loss: 0.997119
global_step: 9153, epoch: 29, loss: 1.069595
global_step: 9154, epoch: 29, loss: 1.044934
global_step: 9155, epoch: 29, loss: 0.972410
global_step: 9156, epoch: 29, loss: 1.126755
global_step: 9157, epoch: 29, loss: 1.077554
global_step: 9158, epoch: 29, loss: 0.850539
global_step: 9159, epoch: 29, loss: 1.107608
global_step: 9160, epoch: 29, loss: 1.277495
epoch: 29
train	acc: 0.7076	macro: p 0.6454, r 0.4225, f1: 0.4428	micro: p 0.7076, r 0.7076, f1 0.7076	weighted_f1:0.6706
dev	acc: 0.5627	macro: p 0.3671, r 0.3077, f1: 0.3004	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.4983
test	acc: 0.6023	macro: p 0.3879, r 0.3069, f1: 0.3117	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5488
global_step: 9161, epoch: 30, loss: 0.940007
global_step: 9162, epoch: 30, loss: 0.936486
global_step: 9163, epoch: 30, loss: 0.951109
global_step: 9164, epoch: 30, loss: 0.978706
global_step: 9165, epoch: 30, loss: 0.889625
global_step: 9166, epoch: 30, loss: 1.028092
global_step: 9167, epoch: 30, loss: 0.978978
global_step: 9168, epoch: 30, loss: 0.965175
global_step: 9169, epoch: 30, loss: 0.975882
global_step: 9170, epoch: 30, loss: 1.065115
global_step: 9171, epoch: 30, loss: 0.957495
global_step: 9172, epoch: 30, loss: 0.861595
global_step: 9173, epoch: 30, loss: 0.958836
global_step: 9174, epoch: 30, loss: 0.991653
global_step: 9175, epoch: 30, loss: 1.052272
global_step: 9176, epoch: 30, loss: 0.949333
global_step: 9177, epoch: 30, loss: 0.919350
global_step: 9178, epoch: 30, loss: 0.934448
global_step: 9179, epoch: 30, loss: 0.875373
global_step: 9180, epoch: 30, loss: 0.891768
global_step: 9181, epoch: 30, loss: 1.021670
global_step: 9182, epoch: 30, loss: 1.034758
global_step: 9183, epoch: 30, loss: 1.027932
global_step: 9184, epoch: 30, loss: 0.964588
global_step: 9185, epoch: 30, loss: 0.914837
global_step: 9186, epoch: 30, loss: 0.923940
global_step: 9187, epoch: 30, loss: 1.022394
global_step: 9188, epoch: 30, loss: 0.922038
global_step: 9189, epoch: 30, loss: 1.038469
global_step: 9190, epoch: 30, loss: 1.035561
global_step: 9191, epoch: 30, loss: 1.009824
global_step: 9192, epoch: 30, loss: 0.928492
global_step: 9193, epoch: 30, loss: 0.876754
global_step: 9194, epoch: 30, loss: 0.992666
global_step: 9195, epoch: 30, loss: 1.004424
global_step: 9196, epoch: 30, loss: 0.941210
global_step: 9197, epoch: 30, loss: 0.883988
global_step: 9198, epoch: 30, loss: 0.885605
global_step: 9199, epoch: 30, loss: 1.056503
global_step: 9200, epoch: 30, loss: 0.090630
epoch: 30
train	acc: 0.7349	macro: p 0.6480, r 0.4644, f1: 0.4784	micro: p 0.7349, r 0.7349, f1 0.7349	weighted_f1:0.7044
dev	acc: 0.5618	macro: p 0.3393, r 0.3136, f1: 0.3052	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5040
test	acc: 0.6019	macro: p 0.3669, r 0.3173, f1: 0.3221	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5557
global_step: 9201, epoch: 31, loss: 0.980773
global_step: 9202, epoch: 31, loss: 0.915918
global_step: 9203, epoch: 31, loss: 0.976966
global_step: 9204, epoch: 31, loss: 1.035179
global_step: 9205, epoch: 31, loss: 0.854396
global_step: 9206, epoch: 31, loss: 1.010280
global_step: 9207, epoch: 31, loss: 1.017424
global_step: 9208, epoch: 31, loss: 0.923392
global_step: 9209, epoch: 31, loss: 1.002241
global_step: 9210, epoch: 31, loss: 1.018860
global_step: 9211, epoch: 31, loss: 1.010884
global_step: 9212, epoch: 31, loss: 0.909892
global_step: 9213, epoch: 31, loss: 0.988832
global_step: 9214, epoch: 31, loss: 0.988057
global_step: 9215, epoch: 31, loss: 0.886504
global_step: 9216, epoch: 31, loss: 0.878724
global_step: 9217, epoch: 31, loss: 0.841134
global_step: 9218, epoch: 31, loss: 0.988879
global_step: 9219, epoch: 31, loss: 1.020045
global_step: 9220, epoch: 31, loss: 0.965838
global_step: 9221, epoch: 31, loss: 0.936909
global_step: 9222, epoch: 31, loss: 0.930971
global_step: 9223, epoch: 31, loss: 1.074217
global_step: 9224, epoch: 31, loss: 0.910185
global_step: 9225, epoch: 31, loss: 0.916964
global_step: 9226, epoch: 31, loss: 0.986231
global_step: 9227, epoch: 31, loss: 0.877200
global_step: 9228, epoch: 31, loss: 0.908151
global_step: 9229, epoch: 31, loss: 0.941064
global_step: 9230, epoch: 31, loss: 1.022073
global_step: 9231, epoch: 31, loss: 0.934146
global_step: 9232, epoch: 31, loss: 0.866553
global_step: 9233, epoch: 31, loss: 1.029541
global_step: 9234, epoch: 31, loss: 0.946685
global_step: 9235, epoch: 31, loss: 0.956536
global_step: 9236, epoch: 31, loss: 1.008443
global_step: 9237, epoch: 31, loss: 0.972714
global_step: 9238, epoch: 31, loss: 0.976414
global_step: 9239, epoch: 31, loss: 0.917306
global_step: 9240, epoch: 31, loss: 0.561492
epoch: 31
train	acc: 0.7410	macro: p 0.5060, r 0.4728, f1: 0.4838	micro: p 0.7410, r 0.7410, f1 0.7410	weighted_f1:0.7112
dev	acc: 0.5591	macro: p 0.3382, r 0.3130, f1: 0.3035	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5013
test	acc: 0.6008	macro: p 0.3599, r 0.3181, f1: 0.3201	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5543
global_step: 9241, epoch: 32, loss: 0.886890
global_step: 9242, epoch: 32, loss: 0.987336
global_step: 9243, epoch: 32, loss: 0.898210
global_step: 9244, epoch: 32, loss: 1.096566
global_step: 9245, epoch: 32, loss: 0.912979
global_step: 9246, epoch: 32, loss: 0.875444
global_step: 9247, epoch: 32, loss: 0.933291
global_step: 9248, epoch: 32, loss: 0.878143
global_step: 9249, epoch: 32, loss: 0.908345
global_step: 9250, epoch: 32, loss: 0.890552
global_step: 9251, epoch: 32, loss: 1.078689
global_step: 9252, epoch: 32, loss: 0.937151
global_step: 9253, epoch: 32, loss: 0.938645
global_step: 9254, epoch: 32, loss: 0.920725
global_step: 9255, epoch: 32, loss: 0.990341
global_step: 9256, epoch: 32, loss: 0.951487
global_step: 9257, epoch: 32, loss: 0.995292
global_step: 9258, epoch: 32, loss: 0.890109
global_step: 9259, epoch: 32, loss: 0.846138
global_step: 9260, epoch: 32, loss: 1.091196
global_step: 9261, epoch: 32, loss: 0.949834
global_step: 9262, epoch: 32, loss: 0.953220
global_step: 9263, epoch: 32, loss: 0.925115
global_step: 9264, epoch: 32, loss: 0.919709
global_step: 9265, epoch: 32, loss: 0.991822
global_step: 9266, epoch: 32, loss: 0.869120
global_step: 9267, epoch: 32, loss: 0.943412
global_step: 9268, epoch: 32, loss: 0.816958
global_step: 9269, epoch: 32, loss: 1.009870
global_step: 9270, epoch: 32, loss: 1.066957
global_step: 9271, epoch: 32, loss: 0.902926
global_step: 9272, epoch: 32, loss: 0.924003
global_step: 9273, epoch: 32, loss: 0.952991
global_step: 9274, epoch: 32, loss: 0.931395
global_step: 9275, epoch: 32, loss: 0.941303
global_step: 9276, epoch: 32, loss: 0.898983
global_step: 9277, epoch: 32, loss: 0.914734
global_step: 9278, epoch: 32, loss: 0.914182
global_step: 9279, epoch: 32, loss: 0.946206
global_step: 9280, epoch: 32, loss: 0.291178
epoch: 32
train	acc: 0.7578	macro: p 0.5152, r 0.4955, f1: 0.4998	micro: p 0.7578, r 0.7578, f1 0.7578	weighted_f1:0.7288
dev	acc: 0.5627	macro: p 0.3436, r 0.3206, f1: 0.3093	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5067
test	acc: 0.5989	macro: p 0.3545, r 0.3223, f1: 0.3208	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5544
global_step: 9281, epoch: 33, loss: 0.951704
global_step: 9282, epoch: 33, loss: 0.892405
global_step: 9283, epoch: 33, loss: 0.946965
global_step: 9284, epoch: 33, loss: 0.822260
global_step: 9285, epoch: 33, loss: 0.957905
global_step: 9286, epoch: 33, loss: 0.939434
global_step: 9287, epoch: 33, loss: 0.845057
global_step: 9288, epoch: 33, loss: 0.907937
global_step: 9289, epoch: 33, loss: 0.955857
global_step: 9290, epoch: 33, loss: 0.862938
global_step: 9291, epoch: 33, loss: 0.907820
global_step: 9292, epoch: 33, loss: 0.934194
global_step: 9293, epoch: 33, loss: 0.949292
global_step: 9294, epoch: 33, loss: 0.901941
global_step: 9295, epoch: 33, loss: 0.952152
global_step: 9296, epoch: 33, loss: 0.946964
global_step: 9297, epoch: 33, loss: 0.896330
global_step: 9298, epoch: 33, loss: 0.992926
global_step: 9299, epoch: 33, loss: 0.866281
global_step: 9300, epoch: 33, loss: 0.988497
global_step: 9301, epoch: 33, loss: 0.867065
global_step: 9302, epoch: 33, loss: 0.915211
global_step: 9303, epoch: 33, loss: 0.931592
global_step: 9304, epoch: 33, loss: 0.957029
global_step: 9305, epoch: 33, loss: 0.912850
global_step: 9306, epoch: 33, loss: 0.930453
global_step: 9307, epoch: 33, loss: 0.945959
global_step: 9308, epoch: 33, loss: 0.892178
global_step: 9309, epoch: 33, loss: 0.821983
global_step: 9310, epoch: 33, loss: 0.859947
global_step: 9311, epoch: 33, loss: 0.849983
global_step: 9312, epoch: 33, loss: 1.006118
global_step: 9313, epoch: 33, loss: 0.915614
global_step: 9314, epoch: 33, loss: 0.852519
global_step: 9315, epoch: 33, loss: 0.913162
global_step: 9316, epoch: 33, loss: 0.941918
global_step: 9317, epoch: 33, loss: 0.977899
global_step: 9318, epoch: 33, loss: 0.898023
global_step: 9319, epoch: 33, loss: 1.061494
global_step: 9320, epoch: 33, loss: 1.266810
epoch: 33
train	acc: 0.7699	macro: p 0.6648, r 0.5186, f1: 0.5158	micro: p 0.7699, r 0.7699, f1 0.7699	weighted_f1:0.7453
dev	acc: 0.5609	macro: p 0.3608, r 0.3251, f1: 0.3221	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5158
test	acc: 0.5946	macro: p 0.3549, r 0.3238, f1: 0.3243	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5561
New best model!
global_step: 9321, epoch: 34, loss: 0.871906
global_step: 9322, epoch: 34, loss: 0.728311
global_step: 9323, epoch: 34, loss: 0.899809
global_step: 9324, epoch: 34, loss: 0.878181
global_step: 9325, epoch: 34, loss: 0.895731
global_step: 9326, epoch: 34, loss: 0.833494
global_step: 9327, epoch: 34, loss: 0.906968
global_step: 9328, epoch: 34, loss: 0.982236
global_step: 9329, epoch: 34, loss: 0.974139
global_step: 9330, epoch: 34, loss: 0.874569
global_step: 9331, epoch: 34, loss: 0.919135
global_step: 9332, epoch: 34, loss: 0.973970
global_step: 9333, epoch: 34, loss: 0.908508
global_step: 9334, epoch: 34, loss: 0.900990
global_step: 9335, epoch: 34, loss: 0.858362
global_step: 9336, epoch: 34, loss: 0.908587
global_step: 9337, epoch: 34, loss: 0.922604
global_step: 9338, epoch: 34, loss: 0.861700
global_step: 9339, epoch: 34, loss: 0.895737
global_step: 9340, epoch: 34, loss: 0.898421
global_step: 9341, epoch: 34, loss: 0.918808
global_step: 9342, epoch: 34, loss: 0.877298
global_step: 9343, epoch: 34, loss: 0.930822
global_step: 9344, epoch: 34, loss: 0.946982
global_step: 9345, epoch: 34, loss: 0.829789
global_step: 9346, epoch: 34, loss: 0.951356
global_step: 9347, epoch: 34, loss: 0.838375
global_step: 9348, epoch: 34, loss: 0.932580
global_step: 9349, epoch: 34, loss: 1.008522
global_step: 9350, epoch: 34, loss: 0.902652
global_step: 9351, epoch: 34, loss: 0.921774
global_step: 9352, epoch: 34, loss: 0.926670
global_step: 9353, epoch: 34, loss: 0.863358
global_step: 9354, epoch: 34, loss: 0.947903
global_step: 9355, epoch: 34, loss: 0.997901
global_step: 9356, epoch: 34, loss: 0.927314
global_step: 9357, epoch: 34, loss: 0.910611
global_step: 9358, epoch: 34, loss: 0.805719
global_step: 9359, epoch: 34, loss: 0.786077
global_step: 9360, epoch: 34, loss: 1.634695
epoch: 34
train	acc: 0.7846	macro: p 0.6746, r 0.5293, f1: 0.5309	micro: p 0.7846, r 0.7846, f1 0.7846	weighted_f1:0.7587
dev	acc: 0.5582	macro: p 0.3469, r 0.3217, f1: 0.3086	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5045
test	acc: 0.5962	macro: p 0.3549, r 0.3248, f1: 0.3226	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5547
global_step: 9361, epoch: 35, loss: 0.869820
global_step: 9362, epoch: 35, loss: 0.873806
global_step: 9363, epoch: 35, loss: 0.766021
global_step: 9364, epoch: 35, loss: 0.973154
global_step: 9365, epoch: 35, loss: 0.782419
global_step: 9366, epoch: 35, loss: 0.883715
global_step: 9367, epoch: 35, loss: 0.947587
global_step: 9368, epoch: 35, loss: 0.848357
global_step: 9369, epoch: 35, loss: 0.947558
global_step: 9370, epoch: 35, loss: 0.907489
global_step: 9371, epoch: 35, loss: 0.911960
global_step: 9372, epoch: 35, loss: 0.986062
global_step: 9373, epoch: 35, loss: 0.943373
global_step: 9374, epoch: 35, loss: 0.811931
global_step: 9375, epoch: 35, loss: 0.973367
global_step: 9376, epoch: 35, loss: 0.883462
global_step: 9377, epoch: 35, loss: 0.901511
global_step: 9378, epoch: 35, loss: 0.831251
global_step: 9379, epoch: 35, loss: 0.975292
global_step: 9380, epoch: 35, loss: 0.792793
global_step: 9381, epoch: 35, loss: 0.959264
global_step: 9382, epoch: 35, loss: 0.847448
global_step: 9383, epoch: 35, loss: 0.932285
global_step: 9384, epoch: 35, loss: 0.905267
global_step: 9385, epoch: 35, loss: 0.826248
global_step: 9386, epoch: 35, loss: 0.894808
global_step: 9387, epoch: 35, loss: 0.963658
global_step: 9388, epoch: 35, loss: 0.807319
global_step: 9389, epoch: 35, loss: 0.884728
global_step: 9390, epoch: 35, loss: 0.835869
global_step: 9391, epoch: 35, loss: 0.890127
global_step: 9392, epoch: 35, loss: 1.028925
global_step: 9393, epoch: 35, loss: 0.981984
global_step: 9394, epoch: 35, loss: 0.989432
global_step: 9395, epoch: 35, loss: 0.883106
global_step: 9396, epoch: 35, loss: 0.888695
global_step: 9397, epoch: 35, loss: 0.869693
global_step: 9398, epoch: 35, loss: 0.983497
global_step: 9399, epoch: 35, loss: 0.808732
global_step: 9400, epoch: 35, loss: 1.176862
epoch: 35
train	acc: 0.7790	macro: p 0.6759, r 0.5262, f1: 0.5277	micro: p 0.7790, r 0.7790, f1 0.7790	weighted_f1:0.7542
dev	acc: 0.5699	macro: p 0.3752, r 0.3260, f1: 0.3259	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5212
test	acc: 0.6019	macro: p 0.3638, r 0.3232, f1: 0.3289	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5610
New best model!
global_step: 9401, epoch: 36, loss: 0.924467
global_step: 9402, epoch: 36, loss: 0.784715
global_step: 9403, epoch: 36, loss: 0.891931
global_step: 9404, epoch: 36, loss: 0.892515
global_step: 9405, epoch: 36, loss: 0.920414
global_step: 9406, epoch: 36, loss: 0.729301
global_step: 9407, epoch: 36, loss: 0.917160
global_step: 9408, epoch: 36, loss: 0.929782
global_step: 9409, epoch: 36, loss: 0.889725
global_step: 9410, epoch: 36, loss: 0.777184
global_step: 9411, epoch: 36, loss: 0.903492
global_step: 9412, epoch: 36, loss: 0.806532
global_step: 9413, epoch: 36, loss: 0.819904
global_step: 9414, epoch: 36, loss: 0.867558
global_step: 9415, epoch: 36, loss: 0.965588
global_step: 9416, epoch: 36, loss: 0.919685
global_step: 9417, epoch: 36, loss: 0.788336
global_step: 9418, epoch: 36, loss: 0.871808
global_step: 9419, epoch: 36, loss: 0.963250
global_step: 9420, epoch: 36, loss: 0.744074
global_step: 9421, epoch: 36, loss: 0.872883
global_step: 9422, epoch: 36, loss: 0.928832
global_step: 9423, epoch: 36, loss: 0.851737
global_step: 9424, epoch: 36, loss: 0.899233
global_step: 9425, epoch: 36, loss: 0.846346
global_step: 9426, epoch: 36, loss: 0.857563
global_step: 9427, epoch: 36, loss: 0.936297
global_step: 9428, epoch: 36, loss: 0.879061
global_step: 9429, epoch: 36, loss: 0.929168
global_step: 9430, epoch: 36, loss: 0.803136
global_step: 9431, epoch: 36, loss: 0.844348
global_step: 9432, epoch: 36, loss: 0.854478
global_step: 9433, epoch: 36, loss: 0.834327
global_step: 9434, epoch: 36, loss: 0.871579
global_step: 9435, epoch: 36, loss: 0.957106
global_step: 9436, epoch: 36, loss: 0.810646
global_step: 9437, epoch: 36, loss: 0.892201
global_step: 9438, epoch: 36, loss: 0.864294
global_step: 9439, epoch: 36, loss: 0.878995
global_step: 9440, epoch: 36, loss: 0.266157
epoch: 36
train	acc: 0.7667	macro: p 0.6850, r 0.4973, f1: 0.5100	micro: p 0.7667, r 0.7667, f1 0.7667	weighted_f1:0.7364
dev	acc: 0.5681	macro: p 0.3699, r 0.3193, f1: 0.3124	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5103
test	acc: 0.5992	macro: p 0.3701, r 0.3110, f1: 0.3140	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5497
global_step: 9441, epoch: 37, loss: 0.883634
global_step: 9442, epoch: 37, loss: 0.890508
global_step: 9443, epoch: 37, loss: 0.800908
global_step: 9444, epoch: 37, loss: 0.872148
global_step: 9445, epoch: 37, loss: 1.029254
global_step: 9446, epoch: 37, loss: 0.804390
global_step: 9447, epoch: 37, loss: 0.773165
global_step: 9448, epoch: 37, loss: 0.848865
global_step: 9449, epoch: 37, loss: 0.904642
global_step: 9450, epoch: 37, loss: 0.851290
global_step: 9451, epoch: 37, loss: 0.852833
global_step: 9452, epoch: 37, loss: 0.819074
global_step: 9453, epoch: 37, loss: 0.843889
global_step: 9454, epoch: 37, loss: 0.819619
global_step: 9455, epoch: 37, loss: 0.828944
global_step: 9456, epoch: 37, loss: 0.790272
global_step: 9457, epoch: 37, loss: 0.771473
global_step: 9458, epoch: 37, loss: 0.815791
global_step: 9459, epoch: 37, loss: 0.824249
global_step: 9460, epoch: 37, loss: 0.739689
global_step: 9461, epoch: 37, loss: 0.916842
global_step: 9462, epoch: 37, loss: 0.900733
global_step: 9463, epoch: 37, loss: 0.822030
global_step: 9464, epoch: 37, loss: 0.858538
global_step: 9465, epoch: 37, loss: 0.915977
global_step: 9466, epoch: 37, loss: 0.887371
global_step: 9467, epoch: 37, loss: 0.874291
global_step: 9468, epoch: 37, loss: 0.863531
global_step: 9469, epoch: 37, loss: 0.813828
global_step: 9470, epoch: 37, loss: 0.921894
global_step: 9471, epoch: 37, loss: 0.949033
global_step: 9472, epoch: 37, loss: 0.816401
global_step: 9473, epoch: 37, loss: 0.876228
global_step: 9474, epoch: 37, loss: 0.763361
global_step: 9475, epoch: 37, loss: 0.975457
global_step: 9476, epoch: 37, loss: 0.901829
global_step: 9477, epoch: 37, loss: 0.963220
global_step: 9478, epoch: 37, loss: 0.856451
global_step: 9479, epoch: 37, loss: 0.761306
global_step: 9480, epoch: 37, loss: 0.991034
epoch: 37
train	acc: 0.8157	macro: p 0.8358, r 0.5664, f1: 0.5598	micro: p 0.8157, r 0.8157, f1 0.8157	weighted_f1:0.7920
dev	acc: 0.5491	macro: p 0.3412, r 0.3190, f1: 0.3099	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5029
test	acc: 0.5912	macro: p 0.3501, r 0.3223, f1: 0.3237	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5535
global_step: 9481, epoch: 38, loss: 0.831281
global_step: 9482, epoch: 38, loss: 0.683271
global_step: 9483, epoch: 38, loss: 0.784366
global_step: 9484, epoch: 38, loss: 0.884767
global_step: 9485, epoch: 38, loss: 0.818761
global_step: 9486, epoch: 38, loss: 0.787718
global_step: 9487, epoch: 38, loss: 0.804868
global_step: 9488, epoch: 38, loss: 0.890540
global_step: 9489, epoch: 38, loss: 0.794392
global_step: 9490, epoch: 38, loss: 0.927434
global_step: 9491, epoch: 38, loss: 0.870832
global_step: 9492, epoch: 38, loss: 0.882805
global_step: 9493, epoch: 38, loss: 0.880269
global_step: 9494, epoch: 38, loss: 0.812503
global_step: 9495, epoch: 38, loss: 0.838288
global_step: 9496, epoch: 38, loss: 0.804957
global_step: 9497, epoch: 38, loss: 0.741102
global_step: 9498, epoch: 38, loss: 0.887897
global_step: 9499, epoch: 38, loss: 0.918292
global_step: 9500, epoch: 38, loss: 0.922131
global_step: 9501, epoch: 38, loss: 0.926315
global_step: 9502, epoch: 38, loss: 0.917105
global_step: 9503, epoch: 38, loss: 0.808893
global_step: 9504, epoch: 38, loss: 0.804530
global_step: 9505, epoch: 38, loss: 0.806895
global_step: 9506, epoch: 38, loss: 1.007725
global_step: 9507, epoch: 38, loss: 0.848779
global_step: 9508, epoch: 38, loss: 0.886357
global_step: 9509, epoch: 38, loss: 0.801834
global_step: 9510, epoch: 38, loss: 0.822032
global_step: 9511, epoch: 38, loss: 0.904209
global_step: 9512, epoch: 38, loss: 0.960108
global_step: 9513, epoch: 38, loss: 0.892845
global_step: 9514, epoch: 38, loss: 0.807010
global_step: 9515, epoch: 38, loss: 0.841271
global_step: 9516, epoch: 38, loss: 0.922644
global_step: 9517, epoch: 38, loss: 0.816175
global_step: 9518, epoch: 38, loss: 0.846348
global_step: 9519, epoch: 38, loss: 0.793012
global_step: 9520, epoch: 38, loss: 0.496672
epoch: 38
train	acc: 0.8182	macro: p 0.6915, r 0.5724, f1: 0.5610	micro: p 0.8182, r 0.8182, f1 0.8182	weighted_f1:0.7948
dev	acc: 0.5564	macro: p 0.3336, r 0.3269, f1: 0.3187	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5118
test	acc: 0.5920	macro: p 0.3439, r 0.3248, f1: 0.3260	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5551
global_step: 9521, epoch: 39, loss: 0.786179
global_step: 9522, epoch: 39, loss: 0.791480
global_step: 9523, epoch: 39, loss: 0.857288
global_step: 9524, epoch: 39, loss: 0.787985
global_step: 9525, epoch: 39, loss: 0.911087
global_step: 9526, epoch: 39, loss: 0.891779
global_step: 9527, epoch: 39, loss: 0.852494
global_step: 9528, epoch: 39, loss: 0.914144
global_step: 9529, epoch: 39, loss: 0.887781
global_step: 9530, epoch: 39, loss: 0.777619
global_step: 9531, epoch: 39, loss: 0.839686
global_step: 9532, epoch: 39, loss: 0.770333
global_step: 9533, epoch: 39, loss: 0.803375
global_step: 9534, epoch: 39, loss: 0.832474
global_step: 9535, epoch: 39, loss: 0.874357
global_step: 9536, epoch: 39, loss: 0.784685
global_step: 9537, epoch: 39, loss: 0.787814
global_step: 9538, epoch: 39, loss: 0.832421
global_step: 9539, epoch: 39, loss: 0.766676
global_step: 9540, epoch: 39, loss: 0.799678
global_step: 9541, epoch: 39, loss: 0.782943
global_step: 9542, epoch: 39, loss: 0.748148
global_step: 9543, epoch: 39, loss: 0.820063
global_step: 9544, epoch: 39, loss: 0.747356
global_step: 9545, epoch: 39, loss: 0.923603
global_step: 9546, epoch: 39, loss: 0.824570
global_step: 9547, epoch: 39, loss: 0.743110
global_step: 9548, epoch: 39, loss: 0.931829
global_step: 9549, epoch: 39, loss: 0.884175
global_step: 9550, epoch: 39, loss: 0.826817
global_step: 9551, epoch: 39, loss: 0.783526
global_step: 9552, epoch: 39, loss: 0.907169
global_step: 9553, epoch: 39, loss: 0.808908
global_step: 9554, epoch: 39, loss: 0.936978
global_step: 9555, epoch: 39, loss: 0.839792
global_step: 9556, epoch: 39, loss: 0.878820
global_step: 9557, epoch: 39, loss: 0.834427
global_step: 9558, epoch: 39, loss: 0.780971
global_step: 9559, epoch: 39, loss: 0.823795
global_step: 9560, epoch: 39, loss: 0.936051
epoch: 39
train	acc: 0.8210	macro: p 0.7988, r 0.5853, f1: 0.5879	micro: p 0.8210, r 0.8210, f1 0.8210	weighted_f1:0.8016
dev	acc: 0.5455	macro: p 0.3374, r 0.3218, f1: 0.3121	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5039
test	acc: 0.5862	macro: p 0.3462, r 0.3233, f1: 0.3219	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5518
global_step: 9561, epoch: 40, loss: 0.772372
global_step: 9562, epoch: 40, loss: 0.812030
global_step: 9563, epoch: 40, loss: 0.823305
global_step: 9564, epoch: 40, loss: 0.774338
global_step: 9565, epoch: 40, loss: 0.808774
global_step: 9566, epoch: 40, loss: 0.773292
global_step: 9567, epoch: 40, loss: 0.822025
global_step: 9568, epoch: 40, loss: 0.820343
global_step: 9569, epoch: 40, loss: 0.794206
global_step: 9570, epoch: 40, loss: 0.775955
global_step: 9571, epoch: 40, loss: 0.679151
global_step: 9572, epoch: 40, loss: 0.798025
global_step: 9573, epoch: 40, loss: 0.748265
global_step: 9574, epoch: 40, loss: 0.882726
global_step: 9575, epoch: 40, loss: 0.797582
global_step: 9576, epoch: 40, loss: 0.714302
global_step: 9577, epoch: 40, loss: 0.783830
global_step: 9578, epoch: 40, loss: 0.723141
global_step: 9579, epoch: 40, loss: 0.842622
global_step: 9580, epoch: 40, loss: 0.802422
global_step: 9581, epoch: 40, loss: 0.851130
global_step: 9582, epoch: 40, loss: 0.787753
global_step: 9583, epoch: 40, loss: 0.800993
global_step: 9584, epoch: 40, loss: 0.770985
global_step: 9585, epoch: 40, loss: 0.821945
global_step: 9586, epoch: 40, loss: 0.775899
global_step: 9587, epoch: 40, loss: 0.769085
global_step: 9588, epoch: 40, loss: 0.839693
global_step: 9589, epoch: 40, loss: 0.783877
global_step: 9590, epoch: 40, loss: 0.737933
global_step: 9591, epoch: 40, loss: 0.875894
global_step: 9592, epoch: 40, loss: 0.851995
global_step: 9593, epoch: 40, loss: 0.805305
global_step: 9594, epoch: 40, loss: 0.766195
global_step: 9595, epoch: 40, loss: 0.802030
global_step: 9596, epoch: 40, loss: 0.843697
global_step: 9597, epoch: 40, loss: 0.908560
global_step: 9598, epoch: 40, loss: 0.839537
global_step: 9599, epoch: 40, loss: 0.814345
global_step: 9600, epoch: 40, loss: 0.636885
epoch: 40
train	acc: 0.8159	macro: p 0.8518, r 0.5645, f1: 0.5739	micro: p 0.8159, r 0.8159, f1 0.8159	weighted_f1:0.7913
dev	acc: 0.5609	macro: p 0.3457, r 0.3193, f1: 0.3043	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5015
test	acc: 0.5950	macro: p 0.3600, r 0.3148, f1: 0.3125	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5465
global_step: 9601, epoch: 41, loss: 0.756277
global_step: 9602, epoch: 41, loss: 0.715612
global_step: 9603, epoch: 41, loss: 0.836484
global_step: 9604, epoch: 41, loss: 0.808413
global_step: 9605, epoch: 41, loss: 0.707829
global_step: 9606, epoch: 41, loss: 0.708901
global_step: 9607, epoch: 41, loss: 0.874762
global_step: 9608, epoch: 41, loss: 0.802427
global_step: 9609, epoch: 41, loss: 0.770868
global_step: 9610, epoch: 41, loss: 0.806286
global_step: 9611, epoch: 41, loss: 0.857353
global_step: 9612, epoch: 41, loss: 0.771786
global_step: 9613, epoch: 41, loss: 0.688137
global_step: 9614, epoch: 41, loss: 0.847746
global_step: 9615, epoch: 41, loss: 0.666413
global_step: 9616, epoch: 41, loss: 0.743875
global_step: 9617, epoch: 41, loss: 0.796593
global_step: 9618, epoch: 41, loss: 0.800695
global_step: 9619, epoch: 41, loss: 0.816036
global_step: 9620, epoch: 41, loss: 0.847219
global_step: 9621, epoch: 41, loss: 0.855880
global_step: 9622, epoch: 41, loss: 0.859586
global_step: 9623, epoch: 41, loss: 0.676789
global_step: 9624, epoch: 41, loss: 0.812195
global_step: 9625, epoch: 41, loss: 0.749561
global_step: 9626, epoch: 41, loss: 0.632443
global_step: 9627, epoch: 41, loss: 0.796390
global_step: 9628, epoch: 41, loss: 0.786121
global_step: 9629, epoch: 41, loss: 0.909073
global_step: 9630, epoch: 41, loss: 0.654207
global_step: 9631, epoch: 41, loss: 0.734640
global_step: 9632, epoch: 41, loss: 0.822819
global_step: 9633, epoch: 41, loss: 0.784431
global_step: 9634, epoch: 41, loss: 0.799795
global_step: 9635, epoch: 41, loss: 0.791161
global_step: 9636, epoch: 41, loss: 0.907109
global_step: 9637, epoch: 41, loss: 0.879153
global_step: 9638, epoch: 41, loss: 0.773421
global_step: 9639, epoch: 41, loss: 0.824435
global_step: 9640, epoch: 41, loss: 0.534959
epoch: 41
train	acc: 0.8271	macro: p 0.8518, r 0.5868, f1: 0.5920	micro: p 0.8271, r 0.8271, f1 0.8271	weighted_f1:0.8052
dev	acc: 0.5564	macro: p 0.3515, r 0.3169, f1: 0.3143	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5063
test	acc: 0.5985	macro: p 0.3555, r 0.3188, f1: 0.3239	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5557
global_step: 9641, epoch: 42, loss: 0.729590
global_step: 9642, epoch: 42, loss: 0.678856
global_step: 9643, epoch: 42, loss: 0.782338
global_step: 9644, epoch: 42, loss: 0.876792
global_step: 9645, epoch: 42, loss: 0.776743
global_step: 9646, epoch: 42, loss: 0.767927
global_step: 9647, epoch: 42, loss: 0.867532
global_step: 9648, epoch: 42, loss: 0.784198
global_step: 9649, epoch: 42, loss: 0.702595
global_step: 9650, epoch: 42, loss: 0.814329
global_step: 9651, epoch: 42, loss: 0.794779
global_step: 9652, epoch: 42, loss: 0.690529
global_step: 9653, epoch: 42, loss: 0.777265
global_step: 9654, epoch: 42, loss: 0.822214
global_step: 9655, epoch: 42, loss: 0.735279
global_step: 9656, epoch: 42, loss: 0.783581
global_step: 9657, epoch: 42, loss: 0.729132
global_step: 9658, epoch: 42, loss: 0.725420
global_step: 9659, epoch: 42, loss: 0.800046
global_step: 9660, epoch: 42, loss: 0.708558
global_step: 9661, epoch: 42, loss: 0.902481
global_step: 9662, epoch: 42, loss: 0.775485
global_step: 9663, epoch: 42, loss: 0.812555
global_step: 9664, epoch: 42, loss: 0.821658
global_step: 9665, epoch: 42, loss: 0.866390
global_step: 9666, epoch: 42, loss: 0.793986
global_step: 9667, epoch: 42, loss: 0.892217
global_step: 9668, epoch: 42, loss: 0.839231
global_step: 9669, epoch: 42, loss: 0.775400
global_step: 9670, epoch: 42, loss: 0.696617
global_step: 9671, epoch: 42, loss: 0.758680
global_step: 9672, epoch: 42, loss: 0.805286
global_step: 9673, epoch: 42, loss: 0.805687
global_step: 9674, epoch: 42, loss: 0.697529
global_step: 9675, epoch: 42, loss: 0.805702
global_step: 9676, epoch: 42, loss: 0.840709
global_step: 9677, epoch: 42, loss: 0.773472
global_step: 9678, epoch: 42, loss: 0.786706
global_step: 9679, epoch: 42, loss: 0.821879
global_step: 9680, epoch: 42, loss: 0.556766
epoch: 42
train	acc: 0.8341	macro: p 0.8619, r 0.6120, f1: 0.6373	micro: p 0.8341, r 0.8341, f1 0.8341	weighted_f1:0.8162
dev	acc: 0.5627	macro: p 0.3694, r 0.3224, f1: 0.3186	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5120
test	acc: 0.5962	macro: p 0.3564, r 0.3156, f1: 0.3186	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5515
global_step: 9681, epoch: 43, loss: 0.659885
global_step: 9682, epoch: 43, loss: 0.948655
global_step: 9683, epoch: 43, loss: 0.826706
global_step: 9684, epoch: 43, loss: 0.734925
global_step: 9685, epoch: 43, loss: 0.813754
global_step: 9686, epoch: 43, loss: 0.719217
global_step: 9687, epoch: 43, loss: 0.712633
global_step: 9688, epoch: 43, loss: 0.710779
global_step: 9689, epoch: 43, loss: 0.614920
global_step: 9690, epoch: 43, loss: 0.807758
global_step: 9691, epoch: 43, loss: 0.712840
global_step: 9692, epoch: 43, loss: 0.775942
global_step: 9693, epoch: 43, loss: 0.731619
global_step: 9694, epoch: 43, loss: 0.737770
global_step: 9695, epoch: 43, loss: 0.751424
global_step: 9696, epoch: 43, loss: 0.750804
global_step: 9697, epoch: 43, loss: 0.757486
global_step: 9698, epoch: 43, loss: 0.805960
global_step: 9699, epoch: 43, loss: 0.764007
global_step: 9700, epoch: 43, loss: 0.740781
global_step: 9701, epoch: 43, loss: 0.755366
global_step: 9702, epoch: 43, loss: 0.758470
global_step: 9703, epoch: 43, loss: 0.830393
global_step: 9704, epoch: 43, loss: 0.757235
global_step: 9705, epoch: 43, loss: 0.783804
global_step: 9706, epoch: 43, loss: 0.648246
global_step: 9707, epoch: 43, loss: 0.745404
global_step: 9708, epoch: 43, loss: 0.817462
global_step: 9709, epoch: 43, loss: 0.783495
global_step: 9710, epoch: 43, loss: 0.829334
global_step: 9711, epoch: 43, loss: 0.836490
global_step: 9712, epoch: 43, loss: 0.794473
global_step: 9713, epoch: 43, loss: 0.762823
global_step: 9714, epoch: 43, loss: 0.794800
global_step: 9715, epoch: 43, loss: 0.670015
global_step: 9716, epoch: 43, loss: 0.801552
global_step: 9717, epoch: 43, loss: 0.803013
global_step: 9718, epoch: 43, loss: 0.769419
global_step: 9719, epoch: 43, loss: 0.842795
global_step: 9720, epoch: 43, loss: 0.850180
epoch: 43
train	acc: 0.8317	macro: p 0.8573, r 0.5979, f1: 0.6039	micro: p 0.8317, r 0.8317, f1 0.8317	weighted_f1:0.8120
dev	acc: 0.5582	macro: p 0.3610, r 0.3183, f1: 0.3149	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5092
test	acc: 0.5992	macro: p 0.3679, r 0.3227, f1: 0.3272	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5595
global_step: 9721, epoch: 44, loss: 0.750818
global_step: 9722, epoch: 44, loss: 0.656913
global_step: 9723, epoch: 44, loss: 0.748936
global_step: 9724, epoch: 44, loss: 0.765974
global_step: 9725, epoch: 44, loss: 0.834365
global_step: 9726, epoch: 44, loss: 0.795931
global_step: 9727, epoch: 44, loss: 0.757823
global_step: 9728, epoch: 44, loss: 0.708312
global_step: 9729, epoch: 44, loss: 0.727709
global_step: 9730, epoch: 44, loss: 0.703925
global_step: 9731, epoch: 44, loss: 0.761288
global_step: 9732, epoch: 44, loss: 0.698760
global_step: 9733, epoch: 44, loss: 0.806926
global_step: 9734, epoch: 44, loss: 0.770601
global_step: 9735, epoch: 44, loss: 0.799045
global_step: 9736, epoch: 44, loss: 0.792826
global_step: 9737, epoch: 44, loss: 0.772068
global_step: 9738, epoch: 44, loss: 0.791648
global_step: 9739, epoch: 44, loss: 0.816007
global_step: 9740, epoch: 44, loss: 0.693427
global_step: 9741, epoch: 44, loss: 0.741047
global_step: 9742, epoch: 44, loss: 0.873994
global_step: 9743, epoch: 44, loss: 0.773642
global_step: 9744, epoch: 44, loss: 0.793169
global_step: 9745, epoch: 44, loss: 0.693991
global_step: 9746, epoch: 44, loss: 0.810168
global_step: 9747, epoch: 44, loss: 0.671869
global_step: 9748, epoch: 44, loss: 0.796935
global_step: 9749, epoch: 44, loss: 0.806478
global_step: 9750, epoch: 44, loss: 0.836726
global_step: 9751, epoch: 44, loss: 0.779061
global_step: 9752, epoch: 44, loss: 0.695946
global_step: 9753, epoch: 44, loss: 0.778096
global_step: 9754, epoch: 44, loss: 0.713586
global_step: 9755, epoch: 44, loss: 0.825058
global_step: 9756, epoch: 44, loss: 0.706767
global_step: 9757, epoch: 44, loss: 0.706138
global_step: 9758, epoch: 44, loss: 0.715465
global_step: 9759, epoch: 44, loss: 0.929186
global_step: 9760, epoch: 44, loss: 0.243856
epoch: 44
train	acc: 0.8439	macro: p 0.8545, r 0.6124, f1: 0.6202	micro: p 0.8439, r 0.8439, f1 0.8439	weighted_f1:0.8246
dev	acc: 0.5618	macro: p 0.3554, r 0.3242, f1: 0.3167	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5122
test	acc: 0.5981	macro: p 0.3657, r 0.3261, f1: 0.3288	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5598
global_step: 9761, epoch: 45, loss: 0.652504
global_step: 9762, epoch: 45, loss: 0.800776
global_step: 9763, epoch: 45, loss: 0.754334
global_step: 9764, epoch: 45, loss: 0.712725
global_step: 9765, epoch: 45, loss: 0.625572
global_step: 9766, epoch: 45, loss: 0.795826
global_step: 9767, epoch: 45, loss: 0.701465
global_step: 9768, epoch: 45, loss: 0.757716
global_step: 9769, epoch: 45, loss: 0.765525
global_step: 9770, epoch: 45, loss: 0.764675
global_step: 9771, epoch: 45, loss: 0.651660
global_step: 9772, epoch: 45, loss: 0.798158
global_step: 9773, epoch: 45, loss: 0.773257
global_step: 9774, epoch: 45, loss: 0.834272
global_step: 9775, epoch: 45, loss: 0.735298
global_step: 9776, epoch: 45, loss: 0.693844
global_step: 9777, epoch: 45, loss: 0.755013
global_step: 9778, epoch: 45, loss: 0.847207
global_step: 9779, epoch: 45, loss: 0.761695
global_step: 9780, epoch: 45, loss: 0.728668
global_step: 9781, epoch: 45, loss: 0.689526
global_step: 9782, epoch: 45, loss: 0.759840
global_step: 9783, epoch: 45, loss: 0.768485
global_step: 9784, epoch: 45, loss: 0.731348
global_step: 9785, epoch: 45, loss: 0.694838
global_step: 9786, epoch: 45, loss: 0.741317
global_step: 9787, epoch: 45, loss: 0.777696
global_step: 9788, epoch: 45, loss: 0.691540
global_step: 9789, epoch: 45, loss: 0.802263
global_step: 9790, epoch: 45, loss: 0.747597
global_step: 9791, epoch: 45, loss: 0.721887
global_step: 9792, epoch: 45, loss: 0.662432
global_step: 9793, epoch: 45, loss: 0.683184
global_step: 9794, epoch: 45, loss: 0.784244
global_step: 9795, epoch: 45, loss: 0.772317
global_step: 9796, epoch: 45, loss: 0.766415
global_step: 9797, epoch: 45, loss: 0.742356
global_step: 9798, epoch: 45, loss: 0.697599
global_step: 9799, epoch: 45, loss: 0.805458
global_step: 9800, epoch: 45, loss: 0.814503
epoch: 45
train	acc: 0.8486	macro: p 0.8579, r 0.6307, f1: 0.6461	micro: p 0.8486, r 0.8486, f1 0.8486	weighted_f1:0.8321
dev	acc: 0.5645	macro: p 0.3456, r 0.3243, f1: 0.3192	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5150
test	acc: 0.5950	macro: p 0.3437, r 0.3199, f1: 0.3231	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5557
global_step: 9801, epoch: 46, loss: 0.713027
global_step: 9802, epoch: 46, loss: 0.753819
global_step: 9803, epoch: 46, loss: 0.665898
global_step: 9804, epoch: 46, loss: 0.745060
global_step: 9805, epoch: 46, loss: 0.570837
global_step: 9806, epoch: 46, loss: 0.726201
global_step: 9807, epoch: 46, loss: 0.694907
global_step: 9808, epoch: 46, loss: 0.714134
global_step: 9809, epoch: 46, loss: 0.782195
global_step: 9810, epoch: 46, loss: 0.673985
global_step: 9811, epoch: 46, loss: 0.686866
global_step: 9812, epoch: 46, loss: 0.725844
global_step: 9813, epoch: 46, loss: 0.733897
global_step: 9814, epoch: 46, loss: 0.710848
global_step: 9815, epoch: 46, loss: 0.758619
global_step: 9816, epoch: 46, loss: 0.757253
global_step: 9817, epoch: 46, loss: 0.745845
global_step: 9818, epoch: 46, loss: 0.763212
global_step: 9819, epoch: 46, loss: 0.738134
global_step: 9820, epoch: 46, loss: 0.805312
global_step: 9821, epoch: 46, loss: 0.682215
global_step: 9822, epoch: 46, loss: 0.687757
global_step: 9823, epoch: 46, loss: 0.709022
global_step: 9824, epoch: 46, loss: 0.739872
global_step: 9825, epoch: 46, loss: 0.862322
global_step: 9826, epoch: 46, loss: 0.759645
global_step: 9827, epoch: 46, loss: 0.596111
global_step: 9828, epoch: 46, loss: 0.717649
global_step: 9829, epoch: 46, loss: 0.795060
global_step: 9830, epoch: 46, loss: 0.672612
global_step: 9831, epoch: 46, loss: 0.700645
global_step: 9832, epoch: 46, loss: 0.635751
global_step: 9833, epoch: 46, loss: 0.703385
global_step: 9834, epoch: 46, loss: 0.704268
global_step: 9835, epoch: 46, loss: 0.844794
global_step: 9836, epoch: 46, loss: 0.814062
global_step: 9837, epoch: 46, loss: 0.674687
global_step: 9838, epoch: 46, loss: 0.713296
global_step: 9839, epoch: 46, loss: 0.735590
global_step: 9840, epoch: 46, loss: 0.845033
epoch: 46
train	acc: 0.8566	macro: p 0.8675, r 0.6471, f1: 0.6694	micro: p 0.8566, r 0.8566, f1 0.8566	weighted_f1:0.8421
dev	acc: 0.5528	macro: p 0.3354, r 0.3187, f1: 0.3072	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5012
test	acc: 0.5950	macro: p 0.3533, r 0.3217, f1: 0.3233	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5535
global_step: 9841, epoch: 47, loss: 0.731530
global_step: 9842, epoch: 47, loss: 0.727726
global_step: 9843, epoch: 47, loss: 0.671990
global_step: 9844, epoch: 47, loss: 0.659632
global_step: 9845, epoch: 47, loss: 0.676047
global_step: 9846, epoch: 47, loss: 0.727455
global_step: 9847, epoch: 47, loss: 0.711783
global_step: 9848, epoch: 47, loss: 0.691068
global_step: 9849, epoch: 47, loss: 0.746967
global_step: 9850, epoch: 47, loss: 0.621433
global_step: 9851, epoch: 47, loss: 0.717002
global_step: 9852, epoch: 47, loss: 0.616884
global_step: 9853, epoch: 47, loss: 0.766924
global_step: 9854, epoch: 47, loss: 0.791682
global_step: 9855, epoch: 47, loss: 0.753479
global_step: 9856, epoch: 47, loss: 0.641816
global_step: 9857, epoch: 47, loss: 0.772615
global_step: 9858, epoch: 47, loss: 0.727022
global_step: 9859, epoch: 47, loss: 0.652885
global_step: 9860, epoch: 47, loss: 0.702304
global_step: 9861, epoch: 47, loss: 0.642699
global_step: 9862, epoch: 47, loss: 0.644840
global_step: 9863, epoch: 47, loss: 0.717265
global_step: 9864, epoch: 47, loss: 0.754485
global_step: 9865, epoch: 47, loss: 0.804205
global_step: 9866, epoch: 47, loss: 0.737796
global_step: 9867, epoch: 47, loss: 0.859723
global_step: 9868, epoch: 47, loss: 0.757244
global_step: 9869, epoch: 47, loss: 0.678838
global_step: 9870, epoch: 47, loss: 0.723556
global_step: 9871, epoch: 47, loss: 0.728400
global_step: 9872, epoch: 47, loss: 0.733895
global_step: 9873, epoch: 47, loss: 0.684720
global_step: 9874, epoch: 47, loss: 0.679252
global_step: 9875, epoch: 47, loss: 0.639235
global_step: 9876, epoch: 47, loss: 0.740175
global_step: 9877, epoch: 47, loss: 0.720109
global_step: 9878, epoch: 47, loss: 0.705413
global_step: 9879, epoch: 47, loss: 0.727836
global_step: 9880, epoch: 47, loss: 0.385252
epoch: 47
train	acc: 0.8559	macro: p 0.8646, r 0.6235, f1: 0.6323	micro: p 0.8559, r 0.8559, f1 0.8559	weighted_f1:0.8360
dev	acc: 0.5600	macro: p 0.3520, r 0.3214, f1: 0.3118	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5064
test	acc: 0.5912	macro: p 0.3519, r 0.3174, f1: 0.3173	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5490
global_step: 9881, epoch: 48, loss: 0.642872
global_step: 9882, epoch: 48, loss: 0.691896
global_step: 9883, epoch: 48, loss: 0.716937
global_step: 9884, epoch: 48, loss: 0.654279
global_step: 9885, epoch: 48, loss: 0.694426
global_step: 9886, epoch: 48, loss: 0.781045
global_step: 9887, epoch: 48, loss: 0.769881
global_step: 9888, epoch: 48, loss: 0.668916
global_step: 9889, epoch: 48, loss: 0.734063
global_step: 9890, epoch: 48, loss: 0.776343
global_step: 9891, epoch: 48, loss: 0.676255
global_step: 9892, epoch: 48, loss: 0.806685
global_step: 9893, epoch: 48, loss: 0.728574
global_step: 9894, epoch: 48, loss: 0.710151
global_step: 9895, epoch: 48, loss: 0.688665
global_step: 9896, epoch: 48, loss: 0.704646
global_step: 9897, epoch: 48, loss: 0.665991
global_step: 9898, epoch: 48, loss: 0.640896
global_step: 9899, epoch: 48, loss: 0.808967
global_step: 9900, epoch: 48, loss: 0.715263
global_step: 9901, epoch: 48, loss: 0.630490
global_step: 9902, epoch: 48, loss: 0.682830
global_step: 9903, epoch: 48, loss: 0.724609
global_step: 9904, epoch: 48, loss: 0.618523
global_step: 9905, epoch: 48, loss: 0.694358
global_step: 9906, epoch: 48, loss: 0.659112
global_step: 9907, epoch: 48, loss: 0.826030
global_step: 9908, epoch: 48, loss: 0.748600
global_step: 9909, epoch: 48, loss: 0.722301
global_step: 9910, epoch: 48, loss: 0.701969
global_step: 9911, epoch: 48, loss: 0.681883
global_step: 9912, epoch: 48, loss: 0.827553
global_step: 9913, epoch: 48, loss: 0.695481
global_step: 9914, epoch: 48, loss: 0.722903
global_step: 9915, epoch: 48, loss: 0.739129
global_step: 9916, epoch: 48, loss: 0.728821
global_step: 9917, epoch: 48, loss: 0.647237
global_step: 9918, epoch: 48, loss: 0.651279
global_step: 9919, epoch: 48, loss: 0.635605
global_step: 9920, epoch: 48, loss: 0.524482
epoch: 48
train	acc: 0.8664	macro: p 0.8625, r 0.6499, f1: 0.6535	micro: p 0.8664, r 0.8664, f1 0.8664	weighted_f1:0.8495
dev	acc: 0.5528	macro: p 0.3345, r 0.3261, f1: 0.3206	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5122
test	acc: 0.5908	macro: p 0.3452, r 0.3279, f1: 0.3299	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5577
global_step: 9921, epoch: 49, loss: 0.600478
global_step: 9922, epoch: 49, loss: 0.691203
global_step: 9923, epoch: 49, loss: 0.656871
global_step: 9924, epoch: 49, loss: 0.666933
global_step: 9925, epoch: 49, loss: 0.722402
global_step: 9926, epoch: 49, loss: 0.716625
global_step: 9927, epoch: 49, loss: 0.671962
global_step: 9928, epoch: 49, loss: 0.652540
global_step: 9929, epoch: 49, loss: 0.610928
global_step: 9930, epoch: 49, loss: 0.758393
global_step: 9931, epoch: 49, loss: 0.703330
global_step: 9932, epoch: 49, loss: 0.770277
global_step: 9933, epoch: 49, loss: 0.771178
global_step: 9934, epoch: 49, loss: 0.630518
global_step: 9935, epoch: 49, loss: 0.677797
global_step: 9936, epoch: 49, loss: 0.690402
global_step: 9937, epoch: 49, loss: 0.788537
global_step: 9938, epoch: 49, loss: 0.677861
global_step: 9939, epoch: 49, loss: 0.728870
global_step: 9940, epoch: 49, loss: 0.664139
global_step: 9941, epoch: 49, loss: 0.670757
global_step: 9942, epoch: 49, loss: 0.583670
global_step: 9943, epoch: 49, loss: 0.744141
global_step: 9944, epoch: 49, loss: 0.697857
global_step: 9945, epoch: 49, loss: 0.640568
global_step: 9946, epoch: 49, loss: 0.650631
global_step: 9947, epoch: 49, loss: 0.720279
global_step: 9948, epoch: 49, loss: 0.606160
global_step: 9949, epoch: 49, loss: 0.625489
global_step: 9950, epoch: 49, loss: 0.696408
global_step: 9951, epoch: 49, loss: 0.707472
global_step: 9952, epoch: 49, loss: 0.728355
global_step: 9953, epoch: 49, loss: 0.643667
global_step: 9954, epoch: 49, loss: 0.743069
global_step: 9955, epoch: 49, loss: 0.736686
global_step: 9956, epoch: 49, loss: 0.698525
global_step: 9957, epoch: 49, loss: 0.710907
global_step: 9958, epoch: 49, loss: 0.675725
global_step: 9959, epoch: 49, loss: 0.670536
global_step: 9960, epoch: 49, loss: 0.758540
epoch: 49
train	acc: 0.8692	macro: p 0.8700, r 0.6717, f1: 0.6891	micro: p 0.8692, r 0.8692, f1 0.8692	weighted_f1:0.8561
dev	acc: 0.5473	macro: p 0.3408, r 0.3256, f1: 0.3157	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5066
test	acc: 0.5851	macro: p 0.3507, r 0.3256, f1: 0.3252	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5526
global_step: 9961, epoch: 50, loss: 0.687981
global_step: 9962, epoch: 50, loss: 0.571767
global_step: 9963, epoch: 50, loss: 0.646645
global_step: 9964, epoch: 50, loss: 0.683004
global_step: 9965, epoch: 50, loss: 0.681721
global_step: 9966, epoch: 50, loss: 0.632561
global_step: 9967, epoch: 50, loss: 0.681493
global_step: 9968, epoch: 50, loss: 0.678686
global_step: 9969, epoch: 50, loss: 0.733088
global_step: 9970, epoch: 50, loss: 0.585651
global_step: 9971, epoch: 50, loss: 0.646242
global_step: 9972, epoch: 50, loss: 0.646531
global_step: 9973, epoch: 50, loss: 0.674936
global_step: 9974, epoch: 50, loss: 0.661421
global_step: 9975, epoch: 50, loss: 0.827853
global_step: 9976, epoch: 50, loss: 0.642517
global_step: 9977, epoch: 50, loss: 0.623706
global_step: 9978, epoch: 50, loss: 0.616691
global_step: 9979, epoch: 50, loss: 0.772750
global_step: 9980, epoch: 50, loss: 0.666211
global_step: 9981, epoch: 50, loss: 0.790651
global_step: 9982, epoch: 50, loss: 0.685496
global_step: 9983, epoch: 50, loss: 0.675595
global_step: 9984, epoch: 50, loss: 0.607733
global_step: 9985, epoch: 50, loss: 0.716267
global_step: 9986, epoch: 50, loss: 0.743133
global_step: 9987, epoch: 50, loss: 0.691634
global_step: 9988, epoch: 50, loss: 0.715004
global_step: 9989, epoch: 50, loss: 0.657063
global_step: 9990, epoch: 50, loss: 0.735024
global_step: 9991, epoch: 50, loss: 0.662348
global_step: 9992, epoch: 50, loss: 0.636275
global_step: 9993, epoch: 50, loss: 0.690736
global_step: 9994, epoch: 50, loss: 0.739541
global_step: 9995, epoch: 50, loss: 0.507080
global_step: 9996, epoch: 50, loss: 0.708415
global_step: 9997, epoch: 50, loss: 0.787520
global_step: 9998, epoch: 50, loss: 0.672008
global_step: 9999, epoch: 50, loss: 0.767792
global_step: 10000, epoch: 50, loss: 1.616896
epoch: 50
train	acc: 0.8819	macro: p 0.8857, r 0.7055, f1: 0.7339	micro: p 0.8819, r 0.8819, f1 0.8819	weighted_f1:0.8721
dev	acc: 0.5473	macro: p 0.3376, r 0.3199, f1: 0.3116	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5047
test	acc: 0.5835	macro: p 0.3485, r 0.3229, f1: 0.3252	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5524
global_step: 10001, epoch: 51, loss: 0.663114
global_step: 10002, epoch: 51, loss: 0.663672
global_step: 10003, epoch: 51, loss: 0.642316
global_step: 10004, epoch: 51, loss: 0.597415
global_step: 10005, epoch: 51, loss: 0.637767
global_step: 10006, epoch: 51, loss: 0.606619
global_step: 10007, epoch: 51, loss: 0.686245
global_step: 10008, epoch: 51, loss: 0.701645
global_step: 10009, epoch: 51, loss: 0.609092
global_step: 10010, epoch: 51, loss: 0.689893
global_step: 10011, epoch: 51, loss: 0.593279
global_step: 10012, epoch: 51, loss: 0.643580
global_step: 10013, epoch: 51, loss: 0.627638
global_step: 10014, epoch: 51, loss: 0.659378
global_step: 10015, epoch: 51, loss: 0.643957
global_step: 10016, epoch: 51, loss: 0.734139
global_step: 10017, epoch: 51, loss: 0.685133
global_step: 10018, epoch: 51, loss: 0.628518
global_step: 10019, epoch: 51, loss: 0.626207
global_step: 10020, epoch: 51, loss: 0.698002
global_step: 10021, epoch: 51, loss: 0.683672
global_step: 10022, epoch: 51, loss: 0.710697
global_step: 10023, epoch: 51, loss: 0.566609
global_step: 10024, epoch: 51, loss: 0.575661
global_step: 10025, epoch: 51, loss: 0.654515
global_step: 10026, epoch: 51, loss: 0.701944
global_step: 10027, epoch: 51, loss: 0.644429
global_step: 10028, epoch: 51, loss: 0.559240
global_step: 10029, epoch: 51, loss: 0.581614
global_step: 10030, epoch: 51, loss: 0.817605
global_step: 10031, epoch: 51, loss: 0.687363
global_step: 10032, epoch: 51, loss: 0.722631
global_step: 10033, epoch: 51, loss: 0.634299
global_step: 10034, epoch: 51, loss: 0.745167
global_step: 10035, epoch: 51, loss: 0.788128
global_step: 10036, epoch: 51, loss: 0.632101
global_step: 10037, epoch: 51, loss: 0.738816
global_step: 10038, epoch: 51, loss: 0.673740
global_step: 10039, epoch: 51, loss: 0.747997
global_step: 10040, epoch: 51, loss: 1.336189
epoch: 51
train	acc: 0.8794	macro: p 0.8922, r 0.6969, f1: 0.7328	micro: p 0.8794, r 0.8794, f1 0.8794	weighted_f1:0.8686
dev	acc: 0.5509	macro: p 0.3500, r 0.3100, f1: 0.3021	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4959
test	acc: 0.5954	macro: p 0.3509, r 0.3147, f1: 0.3171	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5505
global_step: 10041, epoch: 52, loss: 0.653541
global_step: 10042, epoch: 52, loss: 0.735756
global_step: 10043, epoch: 52, loss: 0.664481
global_step: 10044, epoch: 52, loss: 0.618795
global_step: 10045, epoch: 52, loss: 0.705385
global_step: 10046, epoch: 52, loss: 0.747579
global_step: 10047, epoch: 52, loss: 0.627616
global_step: 10048, epoch: 52, loss: 0.581236
global_step: 10049, epoch: 52, loss: 0.712114
global_step: 10050, epoch: 52, loss: 0.634605
global_step: 10051, epoch: 52, loss: 0.699528
global_step: 10052, epoch: 52, loss: 0.631745
global_step: 10053, epoch: 52, loss: 0.577923
global_step: 10054, epoch: 52, loss: 0.669592
global_step: 10055, epoch: 52, loss: 0.666703
global_step: 10056, epoch: 52, loss: 0.615528
global_step: 10057, epoch: 52, loss: 0.541398
global_step: 10058, epoch: 52, loss: 0.654482
global_step: 10059, epoch: 52, loss: 0.673195
global_step: 10060, epoch: 52, loss: 0.669997
global_step: 10061, epoch: 52, loss: 0.721879
global_step: 10062, epoch: 52, loss: 0.633000
global_step: 10063, epoch: 52, loss: 0.686574
global_step: 10064, epoch: 52, loss: 0.579684
global_step: 10065, epoch: 52, loss: 0.603332
global_step: 10066, epoch: 52, loss: 0.651892
global_step: 10067, epoch: 52, loss: 0.626659
global_step: 10068, epoch: 52, loss: 0.585474
global_step: 10069, epoch: 52, loss: 0.621887
global_step: 10070, epoch: 52, loss: 0.680434
global_step: 10071, epoch: 52, loss: 0.584351
global_step: 10072, epoch: 52, loss: 0.610932
global_step: 10073, epoch: 52, loss: 0.684657
global_step: 10074, epoch: 52, loss: 0.735657
global_step: 10075, epoch: 52, loss: 0.665292
global_step: 10076, epoch: 52, loss: 0.640226
global_step: 10077, epoch: 52, loss: 0.630319
global_step: 10078, epoch: 52, loss: 0.720613
global_step: 10079, epoch: 52, loss: 0.603197
global_step: 10080, epoch: 52, loss: 0.973400
epoch: 52
train	acc: 0.8885	macro: p 0.8859, r 0.7053, f1: 0.7244	micro: p 0.8885, r 0.8885, f1 0.8885	weighted_f1:0.8779
dev	acc: 0.5383	macro: p 0.3234, r 0.3194, f1: 0.3150	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5008
test	acc: 0.5920	macro: p 0.3410, r 0.3305, f1: 0.3326	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5606
global_step: 10081, epoch: 53, loss: 0.631552
global_step: 10082, epoch: 53, loss: 0.679688
global_step: 10083, epoch: 53, loss: 0.619256
global_step: 10084, epoch: 53, loss: 0.581190
global_step: 10085, epoch: 53, loss: 0.637647
global_step: 10086, epoch: 53, loss: 0.738011
global_step: 10087, epoch: 53, loss: 0.724206
global_step: 10088, epoch: 53, loss: 0.603072
global_step: 10089, epoch: 53, loss: 0.647726
global_step: 10090, epoch: 53, loss: 0.675489
global_step: 10091, epoch: 53, loss: 0.670702
global_step: 10092, epoch: 53, loss: 0.636504
global_step: 10093, epoch: 53, loss: 0.601844
global_step: 10094, epoch: 53, loss: 0.550315
global_step: 10095, epoch: 53, loss: 0.617847
global_step: 10096, epoch: 53, loss: 0.640905
global_step: 10097, epoch: 53, loss: 0.604850
global_step: 10098, epoch: 53, loss: 0.583435
global_step: 10099, epoch: 53, loss: 0.706040
global_step: 10100, epoch: 53, loss: 0.724497
global_step: 10101, epoch: 53, loss: 0.511945
global_step: 10102, epoch: 53, loss: 0.589940
global_step: 10103, epoch: 53, loss: 0.634976
global_step: 10104, epoch: 53, loss: 0.571488
global_step: 10105, epoch: 53, loss: 0.642412
global_step: 10106, epoch: 53, loss: 0.616186
global_step: 10107, epoch: 53, loss: 0.670611
global_step: 10108, epoch: 53, loss: 0.804379
global_step: 10109, epoch: 53, loss: 0.729905
global_step: 10110, epoch: 53, loss: 0.687262
global_step: 10111, epoch: 53, loss: 0.618503
global_step: 10112, epoch: 53, loss: 0.630255
global_step: 10113, epoch: 53, loss: 0.815487
global_step: 10114, epoch: 53, loss: 0.606785
global_step: 10115, epoch: 53, loss: 0.587278
global_step: 10116, epoch: 53, loss: 0.697372
global_step: 10117, epoch: 53, loss: 0.681675
global_step: 10118, epoch: 53, loss: 0.700389
global_step: 10119, epoch: 53, loss: 0.681262
global_step: 10120, epoch: 53, loss: 0.554719
epoch: 53
train	acc: 0.8816	macro: p 0.8915, r 0.7081, f1: 0.7459	micro: p 0.8816, r 0.8816, f1 0.8816	weighted_f1:0.8728
dev	acc: 0.5446	macro: p 0.3422, r 0.3113, f1: 0.2972	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4925
test	acc: 0.5877	macro: p 0.3567, r 0.3210, f1: 0.3194	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5499
global_step: 10121, epoch: 54, loss: 0.669875
global_step: 10122, epoch: 54, loss: 0.700435
global_step: 10123, epoch: 54, loss: 0.607121
global_step: 10124, epoch: 54, loss: 0.670125
global_step: 10125, epoch: 54, loss: 0.672393
global_step: 10126, epoch: 54, loss: 0.666732
global_step: 10127, epoch: 54, loss: 0.632267
global_step: 10128, epoch: 54, loss: 0.636363
global_step: 10129, epoch: 54, loss: 0.638066
global_step: 10130, epoch: 54, loss: 0.649900
global_step: 10131, epoch: 54, loss: 0.598084
global_step: 10132, epoch: 54, loss: 0.553636
global_step: 10133, epoch: 54, loss: 0.636026
global_step: 10134, epoch: 54, loss: 0.612204
global_step: 10135, epoch: 54, loss: 0.676902
global_step: 10136, epoch: 54, loss: 0.665576
global_step: 10137, epoch: 54, loss: 0.680002
global_step: 10138, epoch: 54, loss: 0.682061
global_step: 10139, epoch: 54, loss: 0.643272
global_step: 10140, epoch: 54, loss: 0.590582
global_step: 10141, epoch: 54, loss: 0.678099
global_step: 10142, epoch: 54, loss: 0.589538
global_step: 10143, epoch: 54, loss: 0.516726
global_step: 10144, epoch: 54, loss: 0.739674
global_step: 10145, epoch: 54, loss: 0.716776
global_step: 10146, epoch: 54, loss: 0.678405
global_step: 10147, epoch: 54, loss: 0.679713
global_step: 10148, epoch: 54, loss: 0.678111
global_step: 10149, epoch: 54, loss: 0.676076
global_step: 10150, epoch: 54, loss: 0.690937
global_step: 10151, epoch: 54, loss: 0.675590
global_step: 10152, epoch: 54, loss: 0.625028
global_step: 10153, epoch: 54, loss: 0.686367
global_step: 10154, epoch: 54, loss: 0.628534
global_step: 10155, epoch: 54, loss: 0.597236
global_step: 10156, epoch: 54, loss: 0.602378
global_step: 10157, epoch: 54, loss: 0.626596
global_step: 10158, epoch: 54, loss: 0.673433
global_step: 10159, epoch: 54, loss: 0.617665
global_step: 10160, epoch: 54, loss: 0.726952
epoch: 54
train	acc: 0.8883	macro: p 0.8973, r 0.7176, f1: 0.7519	micro: p 0.8883, r 0.8883, f1 0.8883	weighted_f1:0.8791
dev	acc: 0.5528	macro: p 0.3401, r 0.3155, f1: 0.3094	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5022
test	acc: 0.5966	macro: p 0.3542, r 0.3219, f1: 0.3256	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5552
global_step: 10161, epoch: 55, loss: 0.799133
global_step: 10162, epoch: 55, loss: 0.589829
global_step: 10163, epoch: 55, loss: 0.652673
global_step: 10164, epoch: 55, loss: 0.650162
global_step: 10165, epoch: 55, loss: 0.676771
global_step: 10166, epoch: 55, loss: 0.621934
global_step: 10167, epoch: 55, loss: 0.639894
global_step: 10168, epoch: 55, loss: 0.713019
global_step: 10169, epoch: 55, loss: 0.618974
global_step: 10170, epoch: 55, loss: 0.692967
global_step: 10171, epoch: 55, loss: 0.584477
global_step: 10172, epoch: 55, loss: 0.522394
global_step: 10173, epoch: 55, loss: 0.555763
global_step: 10174, epoch: 55, loss: 0.721821
global_step: 10175, epoch: 55, loss: 0.580885
global_step: 10176, epoch: 55, loss: 0.596473
global_step: 10177, epoch: 55, loss: 0.698710
global_step: 10178, epoch: 55, loss: 0.636160
global_step: 10179, epoch: 55, loss: 0.755006
global_step: 10180, epoch: 55, loss: 0.638271
global_step: 10181, epoch: 55, loss: 0.694313
global_step: 10182, epoch: 55, loss: 0.620563
global_step: 10183, epoch: 55, loss: 0.625710
global_step: 10184, epoch: 55, loss: 0.651523
global_step: 10185, epoch: 55, loss: 0.624451
global_step: 10186, epoch: 55, loss: 0.605587
global_step: 10187, epoch: 55, loss: 0.607159
global_step: 10188, epoch: 55, loss: 0.575466
global_step: 10189, epoch: 55, loss: 0.581939
global_step: 10190, epoch: 55, loss: 0.671920
global_step: 10191, epoch: 55, loss: 0.648574
global_step: 10192, epoch: 55, loss: 0.735030
global_step: 10193, epoch: 55, loss: 0.575923
global_step: 10194, epoch: 55, loss: 0.673716
global_step: 10195, epoch: 55, loss: 0.627418
global_step: 10196, epoch: 55, loss: 0.691656
global_step: 10197, epoch: 55, loss: 0.590862
global_step: 10198, epoch: 55, loss: 0.575932
global_step: 10199, epoch: 55, loss: 0.604789
global_step: 10200, epoch: 55, loss: 0.621848
epoch: 55
train	acc: 0.8963	macro: p 0.9035, r 0.7372, f1: 0.7740	micro: p 0.8963, r 0.8963, f1 0.8963	weighted_f1:0.8888
dev	acc: 0.5491	macro: p 0.3394, r 0.3137, f1: 0.3115	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5017
test	acc: 0.5977	macro: p 0.3540, r 0.3221, f1: 0.3272	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5569
global_step: 10201, epoch: 56, loss: 0.583285
global_step: 10202, epoch: 56, loss: 0.613580
global_step: 10203, epoch: 56, loss: 0.635625
global_step: 10204, epoch: 56, loss: 0.582012
global_step: 10205, epoch: 56, loss: 0.589620
global_step: 10206, epoch: 56, loss: 0.628181
global_step: 10207, epoch: 56, loss: 0.582700
global_step: 10208, epoch: 56, loss: 0.670291
global_step: 10209, epoch: 56, loss: 0.508756
global_step: 10210, epoch: 56, loss: 0.636152
global_step: 10211, epoch: 56, loss: 0.652578
global_step: 10212, epoch: 56, loss: 0.562916
global_step: 10213, epoch: 56, loss: 0.642067
global_step: 10214, epoch: 56, loss: 0.632563
global_step: 10215, epoch: 56, loss: 0.581683
global_step: 10216, epoch: 56, loss: 0.609128
global_step: 10217, epoch: 56, loss: 0.617790
global_step: 10218, epoch: 56, loss: 0.628964
global_step: 10219, epoch: 56, loss: 0.553832
global_step: 10220, epoch: 56, loss: 0.583938
global_step: 10221, epoch: 56, loss: 0.657910
global_step: 10222, epoch: 56, loss: 0.539870
global_step: 10223, epoch: 56, loss: 0.654014
global_step: 10224, epoch: 56, loss: 0.582541
global_step: 10225, epoch: 56, loss: 0.614143
global_step: 10226, epoch: 56, loss: 0.619129
global_step: 10227, epoch: 56, loss: 0.602128
global_step: 10228, epoch: 56, loss: 0.609843
global_step: 10229, epoch: 56, loss: 0.704796
global_step: 10230, epoch: 56, loss: 0.526194
global_step: 10231, epoch: 56, loss: 0.623761
global_step: 10232, epoch: 56, loss: 0.584750
global_step: 10233, epoch: 56, loss: 0.626026
global_step: 10234, epoch: 56, loss: 0.632088
global_step: 10235, epoch: 56, loss: 0.682262
global_step: 10236, epoch: 56, loss: 0.669837
global_step: 10237, epoch: 56, loss: 0.619286
global_step: 10238, epoch: 56, loss: 0.653036
global_step: 10239, epoch: 56, loss: 0.629971
global_step: 10240, epoch: 56, loss: 0.713392
epoch: 56
train	acc: 0.8948	macro: p 0.8978, r 0.7420, f1: 0.7739	micro: p 0.8948, r 0.8948, f1 0.8948	weighted_f1:0.8875
dev	acc: 0.5464	macro: p 0.3430, r 0.3201, f1: 0.3166	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5045
test	acc: 0.5923	macro: p 0.3471, r 0.3247, f1: 0.3277	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5569
global_step: 10241, epoch: 57, loss: 0.654507
global_step: 10242, epoch: 57, loss: 0.581581
global_step: 10243, epoch: 57, loss: 0.582161
global_step: 10244, epoch: 57, loss: 0.589939
global_step: 10245, epoch: 57, loss: 0.541625
global_step: 10246, epoch: 57, loss: 0.513111
global_step: 10247, epoch: 57, loss: 0.637788
global_step: 10248, epoch: 57, loss: 0.577146
global_step: 10249, epoch: 57, loss: 0.613568
global_step: 10250, epoch: 57, loss: 0.614990
global_step: 10251, epoch: 57, loss: 0.577202
global_step: 10252, epoch: 57, loss: 0.600010
global_step: 10253, epoch: 57, loss: 0.527162
global_step: 10254, epoch: 57, loss: 0.676304
global_step: 10255, epoch: 57, loss: 0.627040
global_step: 10256, epoch: 57, loss: 0.669046
global_step: 10257, epoch: 57, loss: 0.621430
global_step: 10258, epoch: 57, loss: 0.553102
global_step: 10259, epoch: 57, loss: 0.578129
global_step: 10260, epoch: 57, loss: 0.587257
global_step: 10261, epoch: 57, loss: 0.494065
global_step: 10262, epoch: 57, loss: 0.559950
global_step: 10263, epoch: 57, loss: 0.580947
global_step: 10264, epoch: 57, loss: 0.747827
global_step: 10265, epoch: 57, loss: 0.572282
global_step: 10266, epoch: 57, loss: 0.658055
global_step: 10267, epoch: 57, loss: 0.632491
global_step: 10268, epoch: 57, loss: 0.612505
global_step: 10269, epoch: 57, loss: 0.706166
global_step: 10270, epoch: 57, loss: 0.648004
global_step: 10271, epoch: 57, loss: 0.591171
global_step: 10272, epoch: 57, loss: 0.606891
global_step: 10273, epoch: 57, loss: 0.662551
global_step: 10274, epoch: 57, loss: 0.621939
global_step: 10275, epoch: 57, loss: 0.636001
global_step: 10276, epoch: 57, loss: 0.667489
global_step: 10277, epoch: 57, loss: 0.586794
global_step: 10278, epoch: 57, loss: 0.703341
global_step: 10279, epoch: 57, loss: 0.633020
global_step: 10280, epoch: 57, loss: 0.533759
epoch: 57
train	acc: 0.8852	macro: p 0.9038, r 0.7259, f1: 0.7716	micro: p 0.8852, r 0.8852, f1 0.8852	weighted_f1:0.8780
dev	acc: 0.5464	macro: p 0.3549, r 0.3052, f1: 0.2942	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4883
test	acc: 0.5908	macro: p 0.3571, r 0.3114, f1: 0.3118	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5444
global_step: 10281, epoch: 58, loss: 0.658424
global_step: 10282, epoch: 58, loss: 0.601140
global_step: 10283, epoch: 58, loss: 0.625044
global_step: 10284, epoch: 58, loss: 0.588043
global_step: 10285, epoch: 58, loss: 0.532272
global_step: 10286, epoch: 58, loss: 0.558958
global_step: 10287, epoch: 58, loss: 0.651720
global_step: 10288, epoch: 58, loss: 0.518757
global_step: 10289, epoch: 58, loss: 0.634750
global_step: 10290, epoch: 58, loss: 0.554052
global_step: 10291, epoch: 58, loss: 0.621710
global_step: 10292, epoch: 58, loss: 0.659190
global_step: 10293, epoch: 58, loss: 0.579521
global_step: 10294, epoch: 58, loss: 0.622711
global_step: 10295, epoch: 58, loss: 0.650707
global_step: 10296, epoch: 58, loss: 0.590255
global_step: 10297, epoch: 58, loss: 0.618631
global_step: 10298, epoch: 58, loss: 0.680663
global_step: 10299, epoch: 58, loss: 0.623025
global_step: 10300, epoch: 58, loss: 0.606492
global_step: 10301, epoch: 58, loss: 0.647684
global_step: 10302, epoch: 58, loss: 0.553473
global_step: 10303, epoch: 58, loss: 0.674378
global_step: 10304, epoch: 58, loss: 0.565367
global_step: 10305, epoch: 58, loss: 0.622567
global_step: 10306, epoch: 58, loss: 0.568224
global_step: 10307, epoch: 58, loss: 0.539376
global_step: 10308, epoch: 58, loss: 0.611077
global_step: 10309, epoch: 58, loss: 0.552936
global_step: 10310, epoch: 58, loss: 0.644462
global_step: 10311, epoch: 58, loss: 0.558424
global_step: 10312, epoch: 58, loss: 0.580701
global_step: 10313, epoch: 58, loss: 0.613982
global_step: 10314, epoch: 58, loss: 0.574146
global_step: 10315, epoch: 58, loss: 0.600225
global_step: 10316, epoch: 58, loss: 0.552986
global_step: 10317, epoch: 58, loss: 0.592502
global_step: 10318, epoch: 58, loss: 0.514511
global_step: 10319, epoch: 58, loss: 0.699589
global_step: 10320, epoch: 58, loss: 1.047520
epoch: 58
train	acc: 0.9095	macro: p 0.9115, r 0.7849, f1: 0.8215	micro: p 0.9095, r 0.9095, f1 0.9095	weighted_f1:0.9053
dev	acc: 0.5500	macro: p 0.3470, r 0.3243, f1: 0.3193	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5076
test	acc: 0.5908	macro: p 0.3443, r 0.3268, f1: 0.3272	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5563
global_step: 10321, epoch: 59, loss: 0.614450
global_step: 10322, epoch: 59, loss: 0.546936
global_step: 10323, epoch: 59, loss: 0.630733
global_step: 10324, epoch: 59, loss: 0.615104
global_step: 10325, epoch: 59, loss: 0.568782
global_step: 10326, epoch: 59, loss: 0.631623
global_step: 10327, epoch: 59, loss: 0.632527
global_step: 10328, epoch: 59, loss: 0.613184
global_step: 10329, epoch: 59, loss: 0.527714
global_step: 10330, epoch: 59, loss: 0.463906
global_step: 10331, epoch: 59, loss: 0.611099
global_step: 10332, epoch: 59, loss: 0.536755
global_step: 10333, epoch: 59, loss: 0.601932
global_step: 10334, epoch: 59, loss: 0.554250
global_step: 10335, epoch: 59, loss: 0.610026
global_step: 10336, epoch: 59, loss: 0.596404
global_step: 10337, epoch: 59, loss: 0.581401
global_step: 10338, epoch: 59, loss: 0.595341
global_step: 10339, epoch: 59, loss: 0.579054
global_step: 10340, epoch: 59, loss: 0.615289
global_step: 10341, epoch: 59, loss: 0.517379
global_step: 10342, epoch: 59, loss: 0.489297
global_step: 10343, epoch: 59, loss: 0.590691
global_step: 10344, epoch: 59, loss: 0.592911
global_step: 10345, epoch: 59, loss: 0.619206
global_step: 10346, epoch: 59, loss: 0.552919
global_step: 10347, epoch: 59, loss: 0.651760
global_step: 10348, epoch: 59, loss: 0.551306
global_step: 10349, epoch: 59, loss: 0.490467
global_step: 10350, epoch: 59, loss: 0.609989
global_step: 10351, epoch: 59, loss: 0.594631
global_step: 10352, epoch: 59, loss: 0.619467
global_step: 10353, epoch: 59, loss: 0.590645
global_step: 10354, epoch: 59, loss: 0.687124
global_step: 10355, epoch: 59, loss: 0.657027
global_step: 10356, epoch: 59, loss: 0.612911
global_step: 10357, epoch: 59, loss: 0.532142
global_step: 10358, epoch: 59, loss: 0.625856
global_step: 10359, epoch: 59, loss: 0.634036
global_step: 10360, epoch: 59, loss: 0.402013
epoch: 59
train	acc: 0.9039	macro: p 0.9140, r 0.7728, f1: 0.8161	micro: p 0.9039, r 0.9039, f1 0.9039	weighted_f1:0.8993
dev	acc: 0.5509	macro: p 0.3483, r 0.3131, f1: 0.3032	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4969
test	acc: 0.5931	macro: p 0.3448, r 0.3225, f1: 0.3196	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5513
global_step: 10361, epoch: 60, loss: 0.479113
global_step: 10362, epoch: 60, loss: 0.555433
global_step: 10363, epoch: 60, loss: 0.638845
global_step: 10364, epoch: 60, loss: 0.514666
global_step: 10365, epoch: 60, loss: 0.529105
global_step: 10366, epoch: 60, loss: 0.655318
global_step: 10367, epoch: 60, loss: 0.571385
global_step: 10368, epoch: 60, loss: 0.563628
global_step: 10369, epoch: 60, loss: 0.549093
global_step: 10370, epoch: 60, loss: 0.549075
global_step: 10371, epoch: 60, loss: 0.551265
global_step: 10372, epoch: 60, loss: 0.502811
global_step: 10373, epoch: 60, loss: 0.677366
global_step: 10374, epoch: 60, loss: 0.597077
global_step: 10375, epoch: 60, loss: 0.655390
global_step: 10376, epoch: 60, loss: 0.600559
global_step: 10377, epoch: 60, loss: 0.660578
global_step: 10378, epoch: 60, loss: 0.596740
global_step: 10379, epoch: 60, loss: 0.594951
global_step: 10380, epoch: 60, loss: 0.516595
global_step: 10381, epoch: 60, loss: 0.535428
global_step: 10382, epoch: 60, loss: 0.594293
global_step: 10383, epoch: 60, loss: 0.613164
global_step: 10384, epoch: 60, loss: 0.542109
global_step: 10385, epoch: 60, loss: 0.682254
global_step: 10386, epoch: 60, loss: 0.607300
global_step: 10387, epoch: 60, loss: 0.683047
global_step: 10388, epoch: 60, loss: 0.526342
global_step: 10389, epoch: 60, loss: 0.515221
global_step: 10390, epoch: 60, loss: 0.512984
global_step: 10391, epoch: 60, loss: 0.630441
global_step: 10392, epoch: 60, loss: 0.555265
global_step: 10393, epoch: 60, loss: 0.678571
global_step: 10394, epoch: 60, loss: 0.613977
global_step: 10395, epoch: 60, loss: 0.626525
global_step: 10396, epoch: 60, loss: 0.622938
global_step: 10397, epoch: 60, loss: 0.627469
global_step: 10398, epoch: 60, loss: 0.564129
global_step: 10399, epoch: 60, loss: 0.538611
global_step: 10400, epoch: 60, loss: 0.556312
epoch: 60
train	acc: 0.9012	macro: p 0.9117, r 0.7506, f1: 0.7919	micro: p 0.9012, r 0.9012, f1 0.9012	weighted_f1:0.8948
dev	acc: 0.5528	macro: p 0.3465, r 0.3130, f1: 0.3096	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5021
test	acc: 0.5989	macro: p 0.3566, r 0.3234, f1: 0.3284	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5585
global_step: 10401, epoch: 61, loss: 0.594896
global_step: 10402, epoch: 61, loss: 0.525101
global_step: 10403, epoch: 61, loss: 0.644923
global_step: 10404, epoch: 61, loss: 0.683807
global_step: 10405, epoch: 61, loss: 0.624121
global_step: 10406, epoch: 61, loss: 0.617533
global_step: 10407, epoch: 61, loss: 0.552368
global_step: 10408, epoch: 61, loss: 0.481233
global_step: 10409, epoch: 61, loss: 0.543852
global_step: 10410, epoch: 61, loss: 0.580590
global_step: 10411, epoch: 61, loss: 0.514890
global_step: 10412, epoch: 61, loss: 0.599156
global_step: 10413, epoch: 61, loss: 0.562563
global_step: 10414, epoch: 61, loss: 0.601972
global_step: 10415, epoch: 61, loss: 0.542925
global_step: 10416, epoch: 61, loss: 0.657179
global_step: 10417, epoch: 61, loss: 0.555554
global_step: 10418, epoch: 61, loss: 0.632112
global_step: 10419, epoch: 61, loss: 0.524368
global_step: 10420, epoch: 61, loss: 0.648456
global_step: 10421, epoch: 61, loss: 0.588580
global_step: 10422, epoch: 61, loss: 0.567743
global_step: 10423, epoch: 61, loss: 0.503539
global_step: 10424, epoch: 61, loss: 0.582203
global_step: 10425, epoch: 61, loss: 0.593469
global_step: 10426, epoch: 61, loss: 0.521302
global_step: 10427, epoch: 61, loss: 0.536680
global_step: 10428, epoch: 61, loss: 0.684669
global_step: 10429, epoch: 61, loss: 0.544042
global_step: 10430, epoch: 61, loss: 0.539370
global_step: 10431, epoch: 61, loss: 0.600669
global_step: 10432, epoch: 61, loss: 0.599020
global_step: 10433, epoch: 61, loss: 0.598477
global_step: 10434, epoch: 61, loss: 0.526741
global_step: 10435, epoch: 61, loss: 0.523382
global_step: 10436, epoch: 61, loss: 0.606006
global_step: 10437, epoch: 61, loss: 0.592995
global_step: 10438, epoch: 61, loss: 0.617399
global_step: 10439, epoch: 61, loss: 0.498158
global_step: 10440, epoch: 61, loss: 0.959674
epoch: 61
train	acc: 0.9070	macro: p 0.9093, r 0.7638, f1: 0.7977	micro: p 0.9070, r 0.9070, f1 0.9070	weighted_f1:0.9010
dev	acc: 0.5509	macro: p 0.3402, r 0.3206, f1: 0.3169	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5047
test	acc: 0.5862	macro: p 0.3331, r 0.3189, f1: 0.3185	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5468
global_step: 10441, epoch: 62, loss: 0.594257
global_step: 10442, epoch: 62, loss: 0.499498
global_step: 10443, epoch: 62, loss: 0.497078
global_step: 10444, epoch: 62, loss: 0.563784
global_step: 10445, epoch: 62, loss: 0.525447
global_step: 10446, epoch: 62, loss: 0.582753
global_step: 10447, epoch: 62, loss: 0.499907
global_step: 10448, epoch: 62, loss: 0.595851
global_step: 10449, epoch: 62, loss: 0.528728
global_step: 10450, epoch: 62, loss: 0.521272
global_step: 10451, epoch: 62, loss: 0.559498
global_step: 10452, epoch: 62, loss: 0.609127
global_step: 10453, epoch: 62, loss: 0.520110
global_step: 10454, epoch: 62, loss: 0.624844
global_step: 10455, epoch: 62, loss: 0.573991
global_step: 10456, epoch: 62, loss: 0.561470
global_step: 10457, epoch: 62, loss: 0.522160
global_step: 10458, epoch: 62, loss: 0.602668
global_step: 10459, epoch: 62, loss: 0.570879
global_step: 10460, epoch: 62, loss: 0.598541
global_step: 10461, epoch: 62, loss: 0.568036
global_step: 10462, epoch: 62, loss: 0.496424
global_step: 10463, epoch: 62, loss: 0.586461
global_step: 10464, epoch: 62, loss: 0.617779
global_step: 10465, epoch: 62, loss: 0.592980
global_step: 10466, epoch: 62, loss: 0.539964
global_step: 10467, epoch: 62, loss: 0.582409
global_step: 10468, epoch: 62, loss: 0.555899
global_step: 10469, epoch: 62, loss: 0.514552
global_step: 10470, epoch: 62, loss: 0.545631
global_step: 10471, epoch: 62, loss: 0.559587
global_step: 10472, epoch: 62, loss: 0.553750
global_step: 10473, epoch: 62, loss: 0.623028
global_step: 10474, epoch: 62, loss: 0.594143
global_step: 10475, epoch: 62, loss: 0.566022
global_step: 10476, epoch: 62, loss: 0.483563
global_step: 10477, epoch: 62, loss: 0.604360
global_step: 10478, epoch: 62, loss: 0.516025
global_step: 10479, epoch: 62, loss: 0.620220
global_step: 10480, epoch: 62, loss: 0.194244
epoch: 62
train	acc: 0.9186	macro: p 0.9179, r 0.8036, f1: 0.8383	micro: p 0.9186, r 0.9186, f1 0.9186	weighted_f1:0.9153
dev	acc: 0.5473	macro: p 0.3353, r 0.3261, f1: 0.3221	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5103
test	acc: 0.5870	macro: p 0.3384, r 0.3310, f1: 0.3303	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5572
global_step: 10481, epoch: 63, loss: 0.502278
global_step: 10482, epoch: 63, loss: 0.484585
global_step: 10483, epoch: 63, loss: 0.482579
global_step: 10484, epoch: 63, loss: 0.623178
global_step: 10485, epoch: 63, loss: 0.530510
global_step: 10486, epoch: 63, loss: 0.494290
global_step: 10487, epoch: 63, loss: 0.524388
global_step: 10488, epoch: 63, loss: 0.517124
global_step: 10489, epoch: 63, loss: 0.468578
global_step: 10490, epoch: 63, loss: 0.556048
global_step: 10491, epoch: 63, loss: 0.627520
global_step: 10492, epoch: 63, loss: 0.550524
global_step: 10493, epoch: 63, loss: 0.583991
global_step: 10494, epoch: 63, loss: 0.572214
global_step: 10495, epoch: 63, loss: 0.541082
global_step: 10496, epoch: 63, loss: 0.530065
global_step: 10497, epoch: 63, loss: 0.484083
global_step: 10498, epoch: 63, loss: 0.576204
global_step: 10499, epoch: 63, loss: 0.568935
global_step: 10500, epoch: 63, loss: 0.544607
global_step: 10501, epoch: 63, loss: 0.574528
global_step: 10502, epoch: 63, loss: 0.588239
global_step: 10503, epoch: 63, loss: 0.600053
global_step: 10504, epoch: 63, loss: 0.542068
global_step: 10505, epoch: 63, loss: 0.648134
global_step: 10506, epoch: 63, loss: 0.504449
global_step: 10507, epoch: 63, loss: 0.493103
global_step: 10508, epoch: 63, loss: 0.536418
global_step: 10509, epoch: 63, loss: 0.499537
global_step: 10510, epoch: 63, loss: 0.601784
global_step: 10511, epoch: 63, loss: 0.474380
global_step: 10512, epoch: 63, loss: 0.662344
global_step: 10513, epoch: 63, loss: 0.582515
global_step: 10514, epoch: 63, loss: 0.528863
global_step: 10515, epoch: 63, loss: 0.599091
global_step: 10516, epoch: 63, loss: 0.556445
global_step: 10517, epoch: 63, loss: 0.676036
global_step: 10518, epoch: 63, loss: 0.587428
global_step: 10519, epoch: 63, loss: 0.576495
global_step: 10520, epoch: 63, loss: 0.855068
epoch: 63
train	acc: 0.9195	macro: p 0.9241, r 0.8033, f1: 0.8394	micro: p 0.9195, r 0.9195, f1 0.9195	weighted_f1:0.9161
dev	acc: 0.5419	macro: p 0.3919, r 0.3290, f1: 0.3248	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5075
test	acc: 0.5820	macro: p 0.3447, r 0.3292, f1: 0.3271	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5545
global_step: 10521, epoch: 64, loss: 0.540083
global_step: 10522, epoch: 64, loss: 0.565957
global_step: 10523, epoch: 64, loss: 0.579945
global_step: 10524, epoch: 64, loss: 0.531044
global_step: 10525, epoch: 64, loss: 0.625544
global_step: 10526, epoch: 64, loss: 0.516452
global_step: 10527, epoch: 64, loss: 0.494747
global_step: 10528, epoch: 64, loss: 0.526969
global_step: 10529, epoch: 64, loss: 0.526507
global_step: 10530, epoch: 64, loss: 0.569862
global_step: 10531, epoch: 64, loss: 0.492476
global_step: 10532, epoch: 64, loss: 0.471799
global_step: 10533, epoch: 64, loss: 0.483884
global_step: 10534, epoch: 64, loss: 0.579610
global_step: 10535, epoch: 64, loss: 0.526491
global_step: 10536, epoch: 64, loss: 0.546981
global_step: 10537, epoch: 64, loss: 0.652144
global_step: 10538, epoch: 64, loss: 0.572719
global_step: 10539, epoch: 64, loss: 0.553471
global_step: 10540, epoch: 64, loss: 0.546574
global_step: 10541, epoch: 64, loss: 0.495780
global_step: 10542, epoch: 64, loss: 0.500299
global_step: 10543, epoch: 64, loss: 0.511857
global_step: 10544, epoch: 64, loss: 0.549659
global_step: 10545, epoch: 64, loss: 0.613718
global_step: 10546, epoch: 64, loss: 0.532222
global_step: 10547, epoch: 64, loss: 0.605356
global_step: 10548, epoch: 64, loss: 0.526321
global_step: 10549, epoch: 64, loss: 0.535326
global_step: 10550, epoch: 64, loss: 0.459507
global_step: 10551, epoch: 64, loss: 0.523866
global_step: 10552, epoch: 64, loss: 0.590469
global_step: 10553, epoch: 64, loss: 0.595874
global_step: 10554, epoch: 64, loss: 0.644883
global_step: 10555, epoch: 64, loss: 0.607342
global_step: 10556, epoch: 64, loss: 0.610826
global_step: 10557, epoch: 64, loss: 0.729110
global_step: 10558, epoch: 64, loss: 0.609791
global_step: 10559, epoch: 64, loss: 0.538620
global_step: 10560, epoch: 64, loss: 0.734509
epoch: 64
train	acc: 0.9236	macro: p 0.9291, r 0.8271, f1: 0.8650	micro: p 0.9236, r 0.9236, f1 0.9236	weighted_f1:0.9215
dev	acc: 0.5573	macro: p 0.4102, r 0.3238, f1: 0.3225	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5107
test	acc: 0.5889	macro: p 0.3448, r 0.3202, f1: 0.3218	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5523
global_step: 10561, epoch: 65, loss: 0.533222
global_step: 10562, epoch: 65, loss: 0.576206
global_step: 10563, epoch: 65, loss: 0.532647
global_step: 10564, epoch: 65, loss: 0.464939
global_step: 10565, epoch: 65, loss: 0.529880
global_step: 10566, epoch: 65, loss: 0.540033
global_step: 10567, epoch: 65, loss: 0.555403
global_step: 10568, epoch: 65, loss: 0.505213
global_step: 10569, epoch: 65, loss: 0.608413
global_step: 10570, epoch: 65, loss: 0.608762
global_step: 10571, epoch: 65, loss: 0.643406
global_step: 10572, epoch: 65, loss: 0.494219
global_step: 10573, epoch: 65, loss: 0.501068
global_step: 10574, epoch: 65, loss: 0.535567
global_step: 10575, epoch: 65, loss: 0.509199
global_step: 10576, epoch: 65, loss: 0.555224
global_step: 10577, epoch: 65, loss: 0.600794
global_step: 10578, epoch: 65, loss: 0.495409
global_step: 10579, epoch: 65, loss: 0.531964
global_step: 10580, epoch: 65, loss: 0.496362
global_step: 10581, epoch: 65, loss: 0.474308
global_step: 10582, epoch: 65, loss: 0.543358
global_step: 10583, epoch: 65, loss: 0.535689
global_step: 10584, epoch: 65, loss: 0.565538
global_step: 10585, epoch: 65, loss: 0.565567
global_step: 10586, epoch: 65, loss: 0.638202
global_step: 10587, epoch: 65, loss: 0.496942
global_step: 10588, epoch: 65, loss: 0.486818
global_step: 10589, epoch: 65, loss: 0.584495
global_step: 10590, epoch: 65, loss: 0.588976
global_step: 10591, epoch: 65, loss: 0.539953
global_step: 10592, epoch: 65, loss: 0.524064
global_step: 10593, epoch: 65, loss: 0.575712
global_step: 10594, epoch: 65, loss: 0.588082
global_step: 10595, epoch: 65, loss: 0.524722
global_step: 10596, epoch: 65, loss: 0.501220
global_step: 10597, epoch: 65, loss: 0.522206
global_step: 10598, epoch: 65, loss: 0.526445
global_step: 10599, epoch: 65, loss: 0.557101
global_step: 10600, epoch: 65, loss: 0.477320
epoch: 65
train	acc: 0.9234	macro: p 0.9243, r 0.8246, f1: 0.8564	micro: p 0.9234, r 0.9234, f1 0.9234	weighted_f1:0.9208
dev	acc: 0.5437	macro: p 0.3827, r 0.3252, f1: 0.3246	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5088
test	acc: 0.5820	macro: p 0.3362, r 0.3250, f1: 0.3248	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5534
global_step: 10601, epoch: 66, loss: 0.554752
global_step: 10602, epoch: 66, loss: 0.447143
global_step: 10603, epoch: 66, loss: 0.533463
global_step: 10604, epoch: 66, loss: 0.518212
global_step: 10605, epoch: 66, loss: 0.472681
global_step: 10606, epoch: 66, loss: 0.461848
global_step: 10607, epoch: 66, loss: 0.498966
global_step: 10608, epoch: 66, loss: 0.609648
global_step: 10609, epoch: 66, loss: 0.494088
global_step: 10610, epoch: 66, loss: 0.487476
global_step: 10611, epoch: 66, loss: 0.481638
global_step: 10612, epoch: 66, loss: 0.500843
global_step: 10613, epoch: 66, loss: 0.506842
global_step: 10614, epoch: 66, loss: 0.501925
global_step: 10615, epoch: 66, loss: 0.558864
global_step: 10616, epoch: 66, loss: 0.494448
global_step: 10617, epoch: 66, loss: 0.453005
global_step: 10618, epoch: 66, loss: 0.538715
global_step: 10619, epoch: 66, loss: 0.542698
global_step: 10620, epoch: 66, loss: 0.544513
global_step: 10621, epoch: 66, loss: 0.488358
global_step: 10622, epoch: 66, loss: 0.588643
global_step: 10623, epoch: 66, loss: 0.512632
global_step: 10624, epoch: 66, loss: 0.488523
global_step: 10625, epoch: 66, loss: 0.499173
global_step: 10626, epoch: 66, loss: 0.431055
global_step: 10627, epoch: 66, loss: 0.545559
global_step: 10628, epoch: 66, loss: 0.501620
global_step: 10629, epoch: 66, loss: 0.542504
global_step: 10630, epoch: 66, loss: 0.560572
global_step: 10631, epoch: 66, loss: 0.596474
global_step: 10632, epoch: 66, loss: 0.473337
global_step: 10633, epoch: 66, loss: 0.536732
global_step: 10634, epoch: 66, loss: 0.526358
global_step: 10635, epoch: 66, loss: 0.584621
global_step: 10636, epoch: 66, loss: 0.549567
global_step: 10637, epoch: 66, loss: 0.527256
global_step: 10638, epoch: 66, loss: 0.520106
global_step: 10639, epoch: 66, loss: 0.590871
global_step: 10640, epoch: 66, loss: 0.122658
epoch: 66
train	acc: 0.9240	macro: p 0.9322, r 0.8294, f1: 0.8680	micro: p 0.9240, r 0.9240, f1 0.9240	weighted_f1:0.9218
dev	acc: 0.5546	macro: p 0.3497, r 0.3154, f1: 0.3110	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5040
test	acc: 0.5920	macro: p 0.3448, r 0.3154, f1: 0.3175	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5493
global_step: 10641, epoch: 67, loss: 0.436826
global_step: 10642, epoch: 67, loss: 0.492589
global_step: 10643, epoch: 67, loss: 0.479191
global_step: 10644, epoch: 67, loss: 0.524663
global_step: 10645, epoch: 67, loss: 0.431254
global_step: 10646, epoch: 67, loss: 0.456585
global_step: 10647, epoch: 67, loss: 0.489976
global_step: 10648, epoch: 67, loss: 0.572680
global_step: 10649, epoch: 67, loss: 0.509413
global_step: 10650, epoch: 67, loss: 0.516462
global_step: 10651, epoch: 67, loss: 0.487512
global_step: 10652, epoch: 67, loss: 0.544441
global_step: 10653, epoch: 67, loss: 0.504937
global_step: 10654, epoch: 67, loss: 0.583602
global_step: 10655, epoch: 67, loss: 0.497770
global_step: 10656, epoch: 67, loss: 0.583115
global_step: 10657, epoch: 67, loss: 0.532010
global_step: 10658, epoch: 67, loss: 0.576277
global_step: 10659, epoch: 67, loss: 0.500844
global_step: 10660, epoch: 67, loss: 0.494066
global_step: 10661, epoch: 67, loss: 0.504720
global_step: 10662, epoch: 67, loss: 0.510817
global_step: 10663, epoch: 67, loss: 0.546969
global_step: 10664, epoch: 67, loss: 0.449075
global_step: 10665, epoch: 67, loss: 0.475738
global_step: 10666, epoch: 67, loss: 0.551005
global_step: 10667, epoch: 67, loss: 0.568885
global_step: 10668, epoch: 67, loss: 0.541721
global_step: 10669, epoch: 67, loss: 0.597943
global_step: 10670, epoch: 67, loss: 0.499625
global_step: 10671, epoch: 67, loss: 0.523078
global_step: 10672, epoch: 67, loss: 0.517906
global_step: 10673, epoch: 67, loss: 0.569169
global_step: 10674, epoch: 67, loss: 0.527150
global_step: 10675, epoch: 67, loss: 0.595246
global_step: 10676, epoch: 67, loss: 0.596815
global_step: 10677, epoch: 67, loss: 0.594482
global_step: 10678, epoch: 67, loss: 0.566365
global_step: 10679, epoch: 67, loss: 0.538671
global_step: 10680, epoch: 67, loss: 0.062337
epoch: 67
train	acc: 0.9254	macro: p 0.9338, r 0.8376, f1: 0.8739	micro: p 0.9254, r 0.9254, f1 0.9254	weighted_f1:0.9236
dev	acc: 0.5509	macro: p 0.3943, r 0.3199, f1: 0.3222	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5061
test	acc: 0.5923	macro: p 0.3415, r 0.3174, f1: 0.3208	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5522
global_step: 10681, epoch: 68, loss: 0.509837
global_step: 10682, epoch: 68, loss: 0.507155
global_step: 10683, epoch: 68, loss: 0.525732
global_step: 10684, epoch: 68, loss: 0.525527
global_step: 10685, epoch: 68, loss: 0.445889
global_step: 10686, epoch: 68, loss: 0.474993
global_step: 10687, epoch: 68, loss: 0.519142
global_step: 10688, epoch: 68, loss: 0.507481
global_step: 10689, epoch: 68, loss: 0.558535
global_step: 10690, epoch: 68, loss: 0.463907
global_step: 10691, epoch: 68, loss: 0.403491
global_step: 10692, epoch: 68, loss: 0.596404
global_step: 10693, epoch: 68, loss: 0.563572
global_step: 10694, epoch: 68, loss: 0.569687
global_step: 10695, epoch: 68, loss: 0.496688
global_step: 10696, epoch: 68, loss: 0.528100
global_step: 10697, epoch: 68, loss: 0.467343
global_step: 10698, epoch: 68, loss: 0.425639
global_step: 10699, epoch: 68, loss: 0.522020
global_step: 10700, epoch: 68, loss: 0.549165
global_step: 10701, epoch: 68, loss: 0.539985
global_step: 10702, epoch: 68, loss: 0.561731
global_step: 10703, epoch: 68, loss: 0.534013
global_step: 10704, epoch: 68, loss: 0.678843
global_step: 10705, epoch: 68, loss: 0.577339
global_step: 10706, epoch: 68, loss: 0.538674
global_step: 10707, epoch: 68, loss: 0.463403
global_step: 10708, epoch: 68, loss: 0.490425
global_step: 10709, epoch: 68, loss: 0.615671
global_step: 10710, epoch: 68, loss: 0.576697
global_step: 10711, epoch: 68, loss: 0.599933
global_step: 10712, epoch: 68, loss: 0.553814
global_step: 10713, epoch: 68, loss: 0.579295
global_step: 10714, epoch: 68, loss: 0.499988
global_step: 10715, epoch: 68, loss: 0.540989
global_step: 10716, epoch: 68, loss: 0.514451
global_step: 10717, epoch: 68, loss: 0.531842
global_step: 10718, epoch: 68, loss: 0.531681
global_step: 10719, epoch: 68, loss: 0.395630
global_step: 10720, epoch: 68, loss: 0.401552
epoch: 68
train	acc: 0.9260	macro: p 0.9308, r 0.8328, f1: 0.8681	micro: p 0.9260, r 0.9260, f1 0.9260	weighted_f1:0.9239
dev	acc: 0.5518	macro: p 0.4205, r 0.3244, f1: 0.3191	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5069
test	acc: 0.5908	macro: p 0.3427, r 0.3247, f1: 0.3218	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5535
global_step: 10721, epoch: 69, loss: 0.501889
global_step: 10722, epoch: 69, loss: 0.470307
global_step: 10723, epoch: 69, loss: 0.419589
global_step: 10724, epoch: 69, loss: 0.535005
global_step: 10725, epoch: 69, loss: 0.505923
global_step: 10726, epoch: 69, loss: 0.500548
global_step: 10727, epoch: 69, loss: 0.529002
global_step: 10728, epoch: 69, loss: 0.485761
global_step: 10729, epoch: 69, loss: 0.490421
global_step: 10730, epoch: 69, loss: 0.518853
global_step: 10731, epoch: 69, loss: 0.598368
global_step: 10732, epoch: 69, loss: 0.495357
global_step: 10733, epoch: 69, loss: 0.442816
global_step: 10734, epoch: 69, loss: 0.543502
global_step: 10735, epoch: 69, loss: 0.411973
global_step: 10736, epoch: 69, loss: 0.505261
global_step: 10737, epoch: 69, loss: 0.541192
global_step: 10738, epoch: 69, loss: 0.435102
global_step: 10739, epoch: 69, loss: 0.509973
global_step: 10740, epoch: 69, loss: 0.580620
global_step: 10741, epoch: 69, loss: 0.447876
global_step: 10742, epoch: 69, loss: 0.477712
global_step: 10743, epoch: 69, loss: 0.569769
global_step: 10744, epoch: 69, loss: 0.546898
global_step: 10745, epoch: 69, loss: 0.472805
global_step: 10746, epoch: 69, loss: 0.462815
global_step: 10747, epoch: 69, loss: 0.502941
global_step: 10748, epoch: 69, loss: 0.507007
global_step: 10749, epoch: 69, loss: 0.468746
global_step: 10750, epoch: 69, loss: 0.495380
global_step: 10751, epoch: 69, loss: 0.552485
global_step: 10752, epoch: 69, loss: 0.569257
global_step: 10753, epoch: 69, loss: 0.492063
global_step: 10754, epoch: 69, loss: 0.500721
global_step: 10755, epoch: 69, loss: 0.571883
global_step: 10756, epoch: 69, loss: 0.483747
global_step: 10757, epoch: 69, loss: 0.546048
global_step: 10758, epoch: 69, loss: 0.504091
global_step: 10759, epoch: 69, loss: 0.580113
global_step: 10760, epoch: 69, loss: 0.719797
epoch: 69
train	acc: 0.9286	macro: p 0.9416, r 0.8535, f1: 0.8907	micro: p 0.9286, r 0.9286, f1 0.9286	weighted_f1:0.9273
dev	acc: 0.5546	macro: p 0.3880, r 0.3084, f1: 0.3103	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5001
test	acc: 0.5897	macro: p 0.3485, r 0.3046, f1: 0.3129	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5439
global_step: 10761, epoch: 70, loss: 0.507920
global_step: 10762, epoch: 70, loss: 0.521384
global_step: 10763, epoch: 70, loss: 0.442390
global_step: 10764, epoch: 70, loss: 0.361124
global_step: 10765, epoch: 70, loss: 0.508323
global_step: 10766, epoch: 70, loss: 0.561683
global_step: 10767, epoch: 70, loss: 0.439271
global_step: 10768, epoch: 70, loss: 0.439613
global_step: 10769, epoch: 70, loss: 0.578219
global_step: 10770, epoch: 70, loss: 0.463254
global_step: 10771, epoch: 70, loss: 0.459480
global_step: 10772, epoch: 70, loss: 0.494966
global_step: 10773, epoch: 70, loss: 0.514947
global_step: 10774, epoch: 70, loss: 0.480134
global_step: 10775, epoch: 70, loss: 0.555449
global_step: 10776, epoch: 70, loss: 0.588273
global_step: 10777, epoch: 70, loss: 0.579904
global_step: 10778, epoch: 70, loss: 0.510514
global_step: 10779, epoch: 70, loss: 0.523906
global_step: 10780, epoch: 70, loss: 0.413449
global_step: 10781, epoch: 70, loss: 0.523296
global_step: 10782, epoch: 70, loss: 0.547235
global_step: 10783, epoch: 70, loss: 0.561100
global_step: 10784, epoch: 70, loss: 0.516762
global_step: 10785, epoch: 70, loss: 0.569983
global_step: 10786, epoch: 70, loss: 0.604754
global_step: 10787, epoch: 70, loss: 0.523633
global_step: 10788, epoch: 70, loss: 0.416097
global_step: 10789, epoch: 70, loss: 0.433602
global_step: 10790, epoch: 70, loss: 0.477594
global_step: 10791, epoch: 70, loss: 0.586159
global_step: 10792, epoch: 70, loss: 0.418737
global_step: 10793, epoch: 70, loss: 0.507871
global_step: 10794, epoch: 70, loss: 0.627267
global_step: 10795, epoch: 70, loss: 0.517190
global_step: 10796, epoch: 70, loss: 0.558035
global_step: 10797, epoch: 70, loss: 0.414866
global_step: 10798, epoch: 70, loss: 0.513311
global_step: 10799, epoch: 70, loss: 0.564735
global_step: 10800, epoch: 70, loss: 0.501474
epoch: 70
train	acc: 0.9342	macro: p 0.9403, r 0.8602, f1: 0.8919	micro: p 0.9342, r 0.9342, f1 0.9342	weighted_f1:0.9330
dev	acc: 0.5555	macro: p 0.4251, r 0.3253, f1: 0.3280	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5133
test	acc: 0.5893	macro: p 0.3428, r 0.3171, f1: 0.3209	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5507
global_step: 10801, epoch: 71, loss: 0.573952
global_step: 10802, epoch: 71, loss: 0.427715
global_step: 10803, epoch: 71, loss: 0.399913
global_step: 10804, epoch: 71, loss: 0.429569
global_step: 10805, epoch: 71, loss: 0.534372
global_step: 10806, epoch: 71, loss: 0.475382
global_step: 10807, epoch: 71, loss: 0.552678
global_step: 10808, epoch: 71, loss: 0.522950
global_step: 10809, epoch: 71, loss: 0.440816
global_step: 10810, epoch: 71, loss: 0.535511
global_step: 10811, epoch: 71, loss: 0.534356
global_step: 10812, epoch: 71, loss: 0.452920
global_step: 10813, epoch: 71, loss: 0.437075
global_step: 10814, epoch: 71, loss: 0.454809
global_step: 10815, epoch: 71, loss: 0.459676
global_step: 10816, epoch: 71, loss: 0.518305
global_step: 10817, epoch: 71, loss: 0.517860
global_step: 10818, epoch: 71, loss: 0.406600
global_step: 10819, epoch: 71, loss: 0.467625
global_step: 10820, epoch: 71, loss: 0.593764
global_step: 10821, epoch: 71, loss: 0.528492
global_step: 10822, epoch: 71, loss: 0.578516
global_step: 10823, epoch: 71, loss: 0.568113
global_step: 10824, epoch: 71, loss: 0.495172
global_step: 10825, epoch: 71, loss: 0.494356
global_step: 10826, epoch: 71, loss: 0.505729
global_step: 10827, epoch: 71, loss: 0.529863
global_step: 10828, epoch: 71, loss: 0.464311
global_step: 10829, epoch: 71, loss: 0.479062
global_step: 10830, epoch: 71, loss: 0.611873
global_step: 10831, epoch: 71, loss: 0.510341
global_step: 10832, epoch: 71, loss: 0.491931
global_step: 10833, epoch: 71, loss: 0.549297
global_step: 10834, epoch: 71, loss: 0.436585
global_step: 10835, epoch: 71, loss: 0.424760
global_step: 10836, epoch: 71, loss: 0.637672
global_step: 10837, epoch: 71, loss: 0.501766
global_step: 10838, epoch: 71, loss: 0.467943
global_step: 10839, epoch: 71, loss: 0.437986
global_step: 10840, epoch: 71, loss: 0.488168
epoch: 71
train	acc: 0.9352	macro: p 0.9404, r 0.8628, f1: 0.8932	micro: p 0.9352, r 0.9352, f1 0.9352	weighted_f1:0.9340
dev	acc: 0.5555	macro: p 0.3919, r 0.3311, f1: 0.3318	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5164
test	acc: 0.5885	macro: p 0.3387, r 0.3239, f1: 0.3248	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5536
global_step: 10841, epoch: 72, loss: 0.496573
global_step: 10842, epoch: 72, loss: 0.470132
global_step: 10843, epoch: 72, loss: 0.457060
global_step: 10844, epoch: 72, loss: 0.372537
global_step: 10845, epoch: 72, loss: 0.443038
global_step: 10846, epoch: 72, loss: 0.597977
global_step: 10847, epoch: 72, loss: 0.434261
global_step: 10848, epoch: 72, loss: 0.496940
global_step: 10849, epoch: 72, loss: 0.534753
global_step: 10850, epoch: 72, loss: 0.400689
global_step: 10851, epoch: 72, loss: 0.506422
global_step: 10852, epoch: 72, loss: 0.502891
global_step: 10853, epoch: 72, loss: 0.471161
global_step: 10854, epoch: 72, loss: 0.457841
global_step: 10855, epoch: 72, loss: 0.442596
global_step: 10856, epoch: 72, loss: 0.404333
global_step: 10857, epoch: 72, loss: 0.496845
global_step: 10858, epoch: 72, loss: 0.493785
global_step: 10859, epoch: 72, loss: 0.510970
global_step: 10860, epoch: 72, loss: 0.434767
global_step: 10861, epoch: 72, loss: 0.430809
global_step: 10862, epoch: 72, loss: 0.465868
global_step: 10863, epoch: 72, loss: 0.542950
global_step: 10864, epoch: 72, loss: 0.419763
global_step: 10865, epoch: 72, loss: 0.477268
global_step: 10866, epoch: 72, loss: 0.511320
global_step: 10867, epoch: 72, loss: 0.494578
global_step: 10868, epoch: 72, loss: 0.463968
global_step: 10869, epoch: 72, loss: 0.503445
global_step: 10870, epoch: 72, loss: 0.505091
global_step: 10871, epoch: 72, loss: 0.488930
global_step: 10872, epoch: 72, loss: 0.501222
global_step: 10873, epoch: 72, loss: 0.488210
global_step: 10874, epoch: 72, loss: 0.456670
global_step: 10875, epoch: 72, loss: 0.486864
global_step: 10876, epoch: 72, loss: 0.506655
global_step: 10877, epoch: 72, loss: 0.530080
global_step: 10878, epoch: 72, loss: 0.435571
global_step: 10879, epoch: 72, loss: 0.495228
global_step: 10880, epoch: 72, loss: 0.351810
epoch: 72
train	acc: 0.9369	macro: p 0.9442, r 0.8659, f1: 0.8972	micro: p 0.9369, r 0.9369, f1 0.9369	weighted_f1:0.9358
dev	acc: 0.5491	macro: p 0.3849, r 0.3186, f1: 0.3196	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5055
test	acc: 0.5858	macro: p 0.3402, r 0.3129, f1: 0.3181	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5470
global_step: 10881, epoch: 73, loss: 0.415158
global_step: 10882, epoch: 73, loss: 0.526555
global_step: 10883, epoch: 73, loss: 0.517029
global_step: 10884, epoch: 73, loss: 0.468631
global_step: 10885, epoch: 73, loss: 0.532507
global_step: 10886, epoch: 73, loss: 0.440740
global_step: 10887, epoch: 73, loss: 0.458711
global_step: 10888, epoch: 73, loss: 0.441671
global_step: 10889, epoch: 73, loss: 0.468036
global_step: 10890, epoch: 73, loss: 0.454577
global_step: 10891, epoch: 73, loss: 0.315302
global_step: 10892, epoch: 73, loss: 0.452027
global_step: 10893, epoch: 73, loss: 0.429526
global_step: 10894, epoch: 73, loss: 0.386341
global_step: 10895, epoch: 73, loss: 0.574653
global_step: 10896, epoch: 73, loss: 0.504448
global_step: 10897, epoch: 73, loss: 0.417212
global_step: 10898, epoch: 73, loss: 0.443049
global_step: 10899, epoch: 73, loss: 0.525553
global_step: 10900, epoch: 73, loss: 0.431293
global_step: 10901, epoch: 73, loss: 0.549192
global_step: 10902, epoch: 73, loss: 0.447519
global_step: 10903, epoch: 73, loss: 0.518819
global_step: 10904, epoch: 73, loss: 0.542714
global_step: 10905, epoch: 73, loss: 0.524814
global_step: 10906, epoch: 73, loss: 0.455913
global_step: 10907, epoch: 73, loss: 0.541555
global_step: 10908, epoch: 73, loss: 0.549962
global_step: 10909, epoch: 73, loss: 0.463370
global_step: 10910, epoch: 73, loss: 0.504973
global_step: 10911, epoch: 73, loss: 0.602437
global_step: 10912, epoch: 73, loss: 0.493098
global_step: 10913, epoch: 73, loss: 0.516166
global_step: 10914, epoch: 73, loss: 0.486417
global_step: 10915, epoch: 73, loss: 0.352017
global_step: 10916, epoch: 73, loss: 0.505340
global_step: 10917, epoch: 73, loss: 0.369982
global_step: 10918, epoch: 73, loss: 0.509925
global_step: 10919, epoch: 73, loss: 0.431519
global_step: 10920, epoch: 73, loss: 0.630538
epoch: 73
train	acc: 0.9364	macro: p 0.9441, r 0.8633, f1: 0.8956	micro: p 0.9364, r 0.9364, f1 0.9364	weighted_f1:0.9353
dev	acc: 0.5464	macro: p 0.4162, r 0.3204, f1: 0.3188	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5048
test	acc: 0.5870	macro: p 0.3492, r 0.3194, f1: 0.3215	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5528
global_step: 10921, epoch: 74, loss: 0.454319
global_step: 10922, epoch: 74, loss: 0.411939
global_step: 10923, epoch: 74, loss: 0.476110
global_step: 10924, epoch: 74, loss: 0.509741
global_step: 10925, epoch: 74, loss: 0.465103
global_step: 10926, epoch: 74, loss: 0.442641
global_step: 10927, epoch: 74, loss: 0.425507
global_step: 10928, epoch: 74, loss: 0.471969
global_step: 10929, epoch: 74, loss: 0.462875
global_step: 10930, epoch: 74, loss: 0.492754
global_step: 10931, epoch: 74, loss: 0.572146
global_step: 10932, epoch: 74, loss: 0.488477
global_step: 10933, epoch: 74, loss: 0.471995
global_step: 10934, epoch: 74, loss: 0.422728
global_step: 10935, epoch: 74, loss: 0.488032
global_step: 10936, epoch: 74, loss: 0.449978
global_step: 10937, epoch: 74, loss: 0.401087
global_step: 10938, epoch: 74, loss: 0.419601
global_step: 10939, epoch: 74, loss: 0.583925
global_step: 10940, epoch: 74, loss: 0.384493
global_step: 10941, epoch: 74, loss: 0.468744
global_step: 10942, epoch: 74, loss: 0.414145
global_step: 10943, epoch: 74, loss: 0.602566
global_step: 10944, epoch: 74, loss: 0.511596
global_step: 10945, epoch: 74, loss: 0.486318
global_step: 10946, epoch: 74, loss: 0.437611
global_step: 10947, epoch: 74, loss: 0.501166
global_step: 10948, epoch: 74, loss: 0.405503
global_step: 10949, epoch: 74, loss: 0.535539
global_step: 10950, epoch: 74, loss: 0.405219
global_step: 10951, epoch: 74, loss: 0.434333
global_step: 10952, epoch: 74, loss: 0.475007
global_step: 10953, epoch: 74, loss: 0.504004
global_step: 10954, epoch: 74, loss: 0.491351
global_step: 10955, epoch: 74, loss: 0.527943
global_step: 10956, epoch: 74, loss: 0.529114
global_step: 10957, epoch: 74, loss: 0.569406
global_step: 10958, epoch: 74, loss: 0.400377
global_step: 10959, epoch: 74, loss: 0.448676
global_step: 10960, epoch: 74, loss: 0.402071
epoch: 74
train	acc: 0.9413	macro: p 0.9504, r 0.8864, f1: 0.9139	micro: p 0.9413, r 0.9413, f1 0.9413	weighted_f1:0.9408
dev	acc: 0.5537	macro: p 0.3892, r 0.3272, f1: 0.3261	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5121
test	acc: 0.5866	macro: p 0.3415, r 0.3168, f1: 0.3188	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5488
global_step: 10961, epoch: 75, loss: 0.464231
global_step: 10962, epoch: 75, loss: 0.498576
global_step: 10963, epoch: 75, loss: 0.334625
global_step: 10964, epoch: 75, loss: 0.440685
global_step: 10965, epoch: 75, loss: 0.433362
global_step: 10966, epoch: 75, loss: 0.454174
global_step: 10967, epoch: 75, loss: 0.568498
global_step: 10968, epoch: 75, loss: 0.479992
global_step: 10969, epoch: 75, loss: 0.424967
global_step: 10970, epoch: 75, loss: 0.437385
global_step: 10971, epoch: 75, loss: 0.379841
global_step: 10972, epoch: 75, loss: 0.450326
global_step: 10973, epoch: 75, loss: 0.479898
global_step: 10974, epoch: 75, loss: 0.476429
global_step: 10975, epoch: 75, loss: 0.521672
global_step: 10976, epoch: 75, loss: 0.468884
global_step: 10977, epoch: 75, loss: 0.414872
global_step: 10978, epoch: 75, loss: 0.484242
global_step: 10979, epoch: 75, loss: 0.549022
global_step: 10980, epoch: 75, loss: 0.478392
global_step: 10981, epoch: 75, loss: 0.455024
global_step: 10982, epoch: 75, loss: 0.408976
global_step: 10983, epoch: 75, loss: 0.473590
global_step: 10984, epoch: 75, loss: 0.510595
global_step: 10985, epoch: 75, loss: 0.560609
global_step: 10986, epoch: 75, loss: 0.414174
global_step: 10987, epoch: 75, loss: 0.508300
global_step: 10988, epoch: 75, loss: 0.403648
global_step: 10989, epoch: 75, loss: 0.456525
global_step: 10990, epoch: 75, loss: 0.408678
global_step: 10991, epoch: 75, loss: 0.492905
global_step: 10992, epoch: 75, loss: 0.488659
global_step: 10993, epoch: 75, loss: 0.472135
global_step: 10994, epoch: 75, loss: 0.534624
global_step: 10995, epoch: 75, loss: 0.532866
global_step: 10996, epoch: 75, loss: 0.463778
global_step: 10997, epoch: 75, loss: 0.484363
global_step: 10998, epoch: 75, loss: 0.489646
global_step: 10999, epoch: 75, loss: 0.428895
global_step: 11000, epoch: 75, loss: 1.226704
epoch: 75
train	acc: 0.9449	macro: p 0.9475, r 0.8884, f1: 0.9132	micro: p 0.9449, r 0.9449, f1 0.9449	weighted_f1:0.9444
dev	acc: 0.5392	macro: p 0.3749, r 0.3218, f1: 0.3219	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5050
test	acc: 0.5801	macro: p 0.3361, r 0.3211, f1: 0.3235	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5509
global_step: 11001, epoch: 76, loss: 0.461336
global_step: 11002, epoch: 76, loss: 0.563448
global_step: 11003, epoch: 76, loss: 0.455449
global_step: 11004, epoch: 76, loss: 0.397512
global_step: 11005, epoch: 76, loss: 0.438337
global_step: 11006, epoch: 76, loss: 0.429394
global_step: 11007, epoch: 76, loss: 0.520372
global_step: 11008, epoch: 76, loss: 0.461032
global_step: 11009, epoch: 76, loss: 0.489883
global_step: 11010, epoch: 76, loss: 0.496378
global_step: 11011, epoch: 76, loss: 0.539544
global_step: 11012, epoch: 76, loss: 0.501485
global_step: 11013, epoch: 76, loss: 0.557268
global_step: 11014, epoch: 76, loss: 0.391017
global_step: 11015, epoch: 76, loss: 0.421425
global_step: 11016, epoch: 76, loss: 0.387407
global_step: 11017, epoch: 76, loss: 0.509985
global_step: 11018, epoch: 76, loss: 0.472873
global_step: 11019, epoch: 76, loss: 0.409277
global_step: 11020, epoch: 76, loss: 0.485991
global_step: 11021, epoch: 76, loss: 0.393495
global_step: 11022, epoch: 76, loss: 0.470211
global_step: 11023, epoch: 76, loss: 0.460980
global_step: 11024, epoch: 76, loss: 0.432915
global_step: 11025, epoch: 76, loss: 0.417000
global_step: 11026, epoch: 76, loss: 0.512501
global_step: 11027, epoch: 76, loss: 0.510287
global_step: 11028, epoch: 76, loss: 0.406087
global_step: 11029, epoch: 76, loss: 0.387425
global_step: 11030, epoch: 76, loss: 0.508258
global_step: 11031, epoch: 76, loss: 0.416725
global_step: 11032, epoch: 76, loss: 0.363944
global_step: 11033, epoch: 76, loss: 0.406140
global_step: 11034, epoch: 76, loss: 0.426305
global_step: 11035, epoch: 76, loss: 0.479371
global_step: 11036, epoch: 76, loss: 0.489523
global_step: 11037, epoch: 76, loss: 0.485753
global_step: 11038, epoch: 76, loss: 0.514827
global_step: 11039, epoch: 76, loss: 0.458800
global_step: 11040, epoch: 76, loss: 0.803951
epoch: 76
train	acc: 0.9422	macro: p 0.9558, r 0.8868, f1: 0.9168	micro: p 0.9422, r 0.9422, f1 0.9422	weighted_f1:0.9416
dev	acc: 0.5591	macro: p 0.5157, r 0.3202, f1: 0.3206	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5076
test	acc: 0.5866	macro: p 0.3521, r 0.3086, f1: 0.3121	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5420
global_step: 11041, epoch: 77, loss: 0.441051
global_step: 11042, epoch: 77, loss: 0.425413
global_step: 11043, epoch: 77, loss: 0.466510
global_step: 11044, epoch: 77, loss: 0.464320
global_step: 11045, epoch: 77, loss: 0.453160
global_step: 11046, epoch: 77, loss: 0.399701
global_step: 11047, epoch: 77, loss: 0.401421
global_step: 11048, epoch: 77, loss: 0.440661
global_step: 11049, epoch: 77, loss: 0.450834
global_step: 11050, epoch: 77, loss: 0.556581
global_step: 11051, epoch: 77, loss: 0.501980
global_step: 11052, epoch: 77, loss: 0.422404
global_step: 11053, epoch: 77, loss: 0.420539
global_step: 11054, epoch: 77, loss: 0.552293
global_step: 11055, epoch: 77, loss: 0.445589
global_step: 11056, epoch: 77, loss: 0.389183
global_step: 11057, epoch: 77, loss: 0.397490
global_step: 11058, epoch: 77, loss: 0.474426
global_step: 11059, epoch: 77, loss: 0.502006
global_step: 11060, epoch: 77, loss: 0.397974
global_step: 11061, epoch: 77, loss: 0.441389
global_step: 11062, epoch: 77, loss: 0.403053
global_step: 11063, epoch: 77, loss: 0.433317
global_step: 11064, epoch: 77, loss: 0.389860
global_step: 11065, epoch: 77, loss: 0.431433
global_step: 11066, epoch: 77, loss: 0.448089
global_step: 11067, epoch: 77, loss: 0.484450
global_step: 11068, epoch: 77, loss: 0.409621
global_step: 11069, epoch: 77, loss: 0.403436
global_step: 11070, epoch: 77, loss: 0.508103
global_step: 11071, epoch: 77, loss: 0.456066
global_step: 11072, epoch: 77, loss: 0.435438
global_step: 11073, epoch: 77, loss: 0.524562
global_step: 11074, epoch: 77, loss: 0.449178
global_step: 11075, epoch: 77, loss: 0.408831
global_step: 11076, epoch: 77, loss: 0.473257
global_step: 11077, epoch: 77, loss: 0.482008
global_step: 11078, epoch: 77, loss: 0.546660
global_step: 11079, epoch: 77, loss: 0.511920
global_step: 11080, epoch: 77, loss: 0.612397
epoch: 77
train	acc: 0.9433	macro: p 0.9505, r 0.8902, f1: 0.9160	micro: p 0.9433, r 0.9433, f1 0.9433	weighted_f1:0.9429
dev	acc: 0.5491	macro: p 0.4095, r 0.3209, f1: 0.3183	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5047
test	acc: 0.5858	macro: p 0.3361, r 0.3156, f1: 0.3142	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5442
global_step: 11081, epoch: 78, loss: 0.617190
global_step: 11082, epoch: 78, loss: 0.387486
global_step: 11083, epoch: 78, loss: 0.354925
global_step: 11084, epoch: 78, loss: 0.403625
global_step: 11085, epoch: 78, loss: 0.381173
global_step: 11086, epoch: 78, loss: 0.474202
global_step: 11087, epoch: 78, loss: 0.362949
global_step: 11088, epoch: 78, loss: 0.378049
global_step: 11089, epoch: 78, loss: 0.438562
global_step: 11090, epoch: 78, loss: 0.428823
global_step: 11091, epoch: 78, loss: 0.416954
global_step: 11092, epoch: 78, loss: 0.422241
global_step: 11093, epoch: 78, loss: 0.552707
global_step: 11094, epoch: 78, loss: 0.397338
global_step: 11095, epoch: 78, loss: 0.501543
global_step: 11096, epoch: 78, loss: 0.521027
global_step: 11097, epoch: 78, loss: 0.505577
global_step: 11098, epoch: 78, loss: 0.396336
global_step: 11099, epoch: 78, loss: 0.421235
global_step: 11100, epoch: 78, loss: 0.512290
global_step: 11101, epoch: 78, loss: 0.436033
global_step: 11102, epoch: 78, loss: 0.419427
global_step: 11103, epoch: 78, loss: 0.382413
global_step: 11104, epoch: 78, loss: 0.440909
global_step: 11105, epoch: 78, loss: 0.497858
global_step: 11106, epoch: 78, loss: 0.471334
global_step: 11107, epoch: 78, loss: 0.394343
global_step: 11108, epoch: 78, loss: 0.443712
global_step: 11109, epoch: 78, loss: 0.442710
global_step: 11110, epoch: 78, loss: 0.375712
global_step: 11111, epoch: 78, loss: 0.526508
global_step: 11112, epoch: 78, loss: 0.382239
global_step: 11113, epoch: 78, loss: 0.414685
global_step: 11114, epoch: 78, loss: 0.422862
global_step: 11115, epoch: 78, loss: 0.400111
global_step: 11116, epoch: 78, loss: 0.425674
global_step: 11117, epoch: 78, loss: 0.442695
global_step: 11118, epoch: 78, loss: 0.457978
global_step: 11119, epoch: 78, loss: 0.427702
global_step: 11120, epoch: 78, loss: 0.496557
epoch: 78
train	acc: 0.9463	macro: p 0.9522, r 0.8991, f1: 0.9224	micro: p 0.9463, r 0.9463, f1 0.9463	weighted_f1:0.9460
dev	acc: 0.5537	macro: p 0.4317, r 0.3242, f1: 0.3246	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5107
test	acc: 0.5839	macro: p 0.3392, r 0.3121, f1: 0.3144	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5458
global_step: 11121, epoch: 79, loss: 0.381924
global_step: 11122, epoch: 79, loss: 0.376740
global_step: 11123, epoch: 79, loss: 0.478161
global_step: 11124, epoch: 79, loss: 0.390086
global_step: 11125, epoch: 79, loss: 0.341795
global_step: 11126, epoch: 79, loss: 0.397614
global_step: 11127, epoch: 79, loss: 0.421196
global_step: 11128, epoch: 79, loss: 0.487880
global_step: 11129, epoch: 79, loss: 0.477932
global_step: 11130, epoch: 79, loss: 0.398331
global_step: 11131, epoch: 79, loss: 0.533321
global_step: 11132, epoch: 79, loss: 0.389561
global_step: 11133, epoch: 79, loss: 0.441618
global_step: 11134, epoch: 79, loss: 0.401337
global_step: 11135, epoch: 79, loss: 0.455205
global_step: 11136, epoch: 79, loss: 0.458783
global_step: 11137, epoch: 79, loss: 0.427056
global_step: 11138, epoch: 79, loss: 0.445246
global_step: 11139, epoch: 79, loss: 0.357517
global_step: 11140, epoch: 79, loss: 0.346424
global_step: 11141, epoch: 79, loss: 0.462127
global_step: 11142, epoch: 79, loss: 0.448232
global_step: 11143, epoch: 79, loss: 0.418336
global_step: 11144, epoch: 79, loss: 0.455541
global_step: 11145, epoch: 79, loss: 0.429510
global_step: 11146, epoch: 79, loss: 0.375724
global_step: 11147, epoch: 79, loss: 0.386556
global_step: 11148, epoch: 79, loss: 0.497140
global_step: 11149, epoch: 79, loss: 0.431109
global_step: 11150, epoch: 79, loss: 0.474174
global_step: 11151, epoch: 79, loss: 0.374508
global_step: 11152, epoch: 79, loss: 0.464655
global_step: 11153, epoch: 79, loss: 0.372333
global_step: 11154, epoch: 79, loss: 0.474449
global_step: 11155, epoch: 79, loss: 0.432890
global_step: 11156, epoch: 79, loss: 0.425834
global_step: 11157, epoch: 79, loss: 0.427948
global_step: 11158, epoch: 79, loss: 0.517434
global_step: 11159, epoch: 79, loss: 0.446500
global_step: 11160, epoch: 79, loss: 0.209276
epoch: 79
train	acc: 0.9471	macro: p 0.9524, r 0.8968, f1: 0.9207	micro: p 0.9471, r 0.9471, f1 0.9471	weighted_f1:0.9467
dev	acc: 0.5546	macro: p 0.3957, r 0.3306, f1: 0.3292	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5142
test	acc: 0.5858	macro: p 0.3410, r 0.3213, f1: 0.3211	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5497
global_step: 11161, epoch: 80, loss: 0.530049
global_step: 11162, epoch: 80, loss: 0.430477
global_step: 11163, epoch: 80, loss: 0.419077
global_step: 11164, epoch: 80, loss: 0.462376
global_step: 11165, epoch: 80, loss: 0.363879
global_step: 11166, epoch: 80, loss: 0.460811
global_step: 11167, epoch: 80, loss: 0.423228
global_step: 11168, epoch: 80, loss: 0.495518
global_step: 11169, epoch: 80, loss: 0.415571
global_step: 11170, epoch: 80, loss: 0.442867
global_step: 11171, epoch: 80, loss: 0.407379
global_step: 11172, epoch: 80, loss: 0.439178
global_step: 11173, epoch: 80, loss: 0.443793
global_step: 11174, epoch: 80, loss: 0.383765
global_step: 11175, epoch: 80, loss: 0.433468
global_step: 11176, epoch: 80, loss: 0.447736
global_step: 11177, epoch: 80, loss: 0.431369
global_step: 11178, epoch: 80, loss: 0.544138
global_step: 11179, epoch: 80, loss: 0.402249
global_step: 11180, epoch: 80, loss: 0.273764
global_step: 11181, epoch: 80, loss: 0.466406
global_step: 11182, epoch: 80, loss: 0.454483
global_step: 11183, epoch: 80, loss: 0.468383
global_step: 11184, epoch: 80, loss: 0.414526
global_step: 11185, epoch: 80, loss: 0.420341
global_step: 11186, epoch: 80, loss: 0.444150
global_step: 11187, epoch: 80, loss: 0.377957
global_step: 11188, epoch: 80, loss: 0.428651
global_step: 11189, epoch: 80, loss: 0.402030
global_step: 11190, epoch: 80, loss: 0.452738
global_step: 11191, epoch: 80, loss: 0.462118
global_step: 11192, epoch: 80, loss: 0.509074
global_step: 11193, epoch: 80, loss: 0.333491
global_step: 11194, epoch: 80, loss: 0.401382
global_step: 11195, epoch: 80, loss: 0.439078
global_step: 11196, epoch: 80, loss: 0.506934
global_step: 11197, epoch: 80, loss: 0.469843
global_step: 11198, epoch: 80, loss: 0.486476
global_step: 11199, epoch: 80, loss: 0.411229
global_step: 11200, epoch: 80, loss: 1.467063
epoch: 80
train	acc: 0.9516	macro: p 0.9585, r 0.9136, f1: 0.9340	micro: p 0.9516, r 0.9516, f1 0.9516	weighted_f1:0.9514
dev	acc: 0.5582	macro: p 0.4367, r 0.3261, f1: 0.3248	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5133
test	acc: 0.5851	macro: p 0.3599, r 0.3198, f1: 0.3237	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5498
global_step: 11201, epoch: 81, loss: 0.426763
global_step: 11202, epoch: 81, loss: 0.331504
global_step: 11203, epoch: 81, loss: 0.380985
global_step: 11204, epoch: 81, loss: 0.314333
global_step: 11205, epoch: 81, loss: 0.465458
global_step: 11206, epoch: 81, loss: 0.362601
global_step: 11207, epoch: 81, loss: 0.354426
global_step: 11208, epoch: 81, loss: 0.402490
global_step: 11209, epoch: 81, loss: 0.348561
global_step: 11210, epoch: 81, loss: 0.432814
global_step: 11211, epoch: 81, loss: 0.416782
global_step: 11212, epoch: 81, loss: 0.354179
global_step: 11213, epoch: 81, loss: 0.440216
global_step: 11214, epoch: 81, loss: 0.446926
global_step: 11215, epoch: 81, loss: 0.404938
global_step: 11216, epoch: 81, loss: 0.433393
global_step: 11217, epoch: 81, loss: 0.493619
global_step: 11218, epoch: 81, loss: 0.451142
global_step: 11219, epoch: 81, loss: 0.484363
global_step: 11220, epoch: 81, loss: 0.360498
global_step: 11221, epoch: 81, loss: 0.486709
global_step: 11222, epoch: 81, loss: 0.476806
global_step: 11223, epoch: 81, loss: 0.450710
global_step: 11224, epoch: 81, loss: 0.512736
global_step: 11225, epoch: 81, loss: 0.428004
global_step: 11226, epoch: 81, loss: 0.429962
global_step: 11227, epoch: 81, loss: 0.445106
global_step: 11228, epoch: 81, loss: 0.317304
global_step: 11229, epoch: 81, loss: 0.390889
global_step: 11230, epoch: 81, loss: 0.472070
global_step: 11231, epoch: 81, loss: 0.426439
global_step: 11232, epoch: 81, loss: 0.449783
global_step: 11233, epoch: 81, loss: 0.388910
global_step: 11234, epoch: 81, loss: 0.327964
global_step: 11235, epoch: 81, loss: 0.541888
global_step: 11236, epoch: 81, loss: 0.437169
global_step: 11237, epoch: 81, loss: 0.401120
global_step: 11238, epoch: 81, loss: 0.513809
global_step: 11239, epoch: 81, loss: 0.508001
global_step: 11240, epoch: 81, loss: 1.807539
epoch: 81
train	acc: 0.9500	macro: p 0.9544, r 0.9048, f1: 0.9266	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9498
dev	acc: 0.5374	macro: p 0.4029, r 0.3226, f1: 0.3205	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5016
test	acc: 0.5751	macro: p 0.3504, r 0.3232, f1: 0.3245	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5475
global_step: 11241, epoch: 82, loss: 0.552460
global_step: 11242, epoch: 82, loss: 0.359745
global_step: 11243, epoch: 82, loss: 0.400778
global_step: 11244, epoch: 82, loss: 0.575673
global_step: 11245, epoch: 82, loss: 0.479796
global_step: 11246, epoch: 82, loss: 0.369618
global_step: 11247, epoch: 82, loss: 0.371745
global_step: 11248, epoch: 82, loss: 0.409651
global_step: 11249, epoch: 82, loss: 0.418253
global_step: 11250, epoch: 82, loss: 0.418385
global_step: 11251, epoch: 82, loss: 0.447496
global_step: 11252, epoch: 82, loss: 0.405378
global_step: 11253, epoch: 82, loss: 0.381370
global_step: 11254, epoch: 82, loss: 0.433900
global_step: 11255, epoch: 82, loss: 0.368939
global_step: 11256, epoch: 82, loss: 0.386427
global_step: 11257, epoch: 82, loss: 0.415328
global_step: 11258, epoch: 82, loss: 0.377195
global_step: 11259, epoch: 82, loss: 0.338024
global_step: 11260, epoch: 82, loss: 0.337736
global_step: 11261, epoch: 82, loss: 0.411226
global_step: 11262, epoch: 82, loss: 0.377014
global_step: 11263, epoch: 82, loss: 0.425078
global_step: 11264, epoch: 82, loss: 0.397764
global_step: 11265, epoch: 82, loss: 0.425977
global_step: 11266, epoch: 82, loss: 0.385318
global_step: 11267, epoch: 82, loss: 0.418906
global_step: 11268, epoch: 82, loss: 0.470523
global_step: 11269, epoch: 82, loss: 0.413654
global_step: 11270, epoch: 82, loss: 0.401754
global_step: 11271, epoch: 82, loss: 0.360918
global_step: 11272, epoch: 82, loss: 0.512719
global_step: 11273, epoch: 82, loss: 0.462533
global_step: 11274, epoch: 82, loss: 0.489795
global_step: 11275, epoch: 82, loss: 0.443345
global_step: 11276, epoch: 82, loss: 0.349060
global_step: 11277, epoch: 82, loss: 0.394047
global_step: 11278, epoch: 82, loss: 0.347216
global_step: 11279, epoch: 82, loss: 0.391951
global_step: 11280, epoch: 82, loss: 0.349594
epoch: 82
train	acc: 0.9500	macro: p 0.9553, r 0.9079, f1: 0.9290	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9498
dev	acc: 0.5473	macro: p 0.3844, r 0.3234, f1: 0.3238	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5099
test	acc: 0.5805	macro: p 0.3701, r 0.3180, f1: 0.3236	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5492
global_step: 11281, epoch: 83, loss: 0.402528
global_step: 11282, epoch: 83, loss: 0.427569
global_step: 11283, epoch: 83, loss: 0.371081
global_step: 11284, epoch: 83, loss: 0.471275
global_step: 11285, epoch: 83, loss: 0.353437
global_step: 11286, epoch: 83, loss: 0.322612
global_step: 11287, epoch: 83, loss: 0.401652
global_step: 11288, epoch: 83, loss: 0.433590
global_step: 11289, epoch: 83, loss: 0.455018
global_step: 11290, epoch: 83, loss: 0.367878
global_step: 11291, epoch: 83, loss: 0.402039
global_step: 11292, epoch: 83, loss: 0.431169
global_step: 11293, epoch: 83, loss: 0.468526
global_step: 11294, epoch: 83, loss: 0.442670
global_step: 11295, epoch: 83, loss: 0.370131
global_step: 11296, epoch: 83, loss: 0.372810
global_step: 11297, epoch: 83, loss: 0.431492
global_step: 11298, epoch: 83, loss: 0.462294
global_step: 11299, epoch: 83, loss: 0.358009
global_step: 11300, epoch: 83, loss: 0.380614
global_step: 11301, epoch: 83, loss: 0.426877
global_step: 11302, epoch: 83, loss: 0.458681
global_step: 11303, epoch: 83, loss: 0.382026
global_step: 11304, epoch: 83, loss: 0.452932
global_step: 11305, epoch: 83, loss: 0.395266
global_step: 11306, epoch: 83, loss: 0.345830
global_step: 11307, epoch: 83, loss: 0.408196
global_step: 11308, epoch: 83, loss: 0.520686
global_step: 11309, epoch: 83, loss: 0.536988
global_step: 11310, epoch: 83, loss: 0.455610
global_step: 11311, epoch: 83, loss: 0.359127
global_step: 11312, epoch: 83, loss: 0.426556
global_step: 11313, epoch: 83, loss: 0.417951
global_step: 11314, epoch: 83, loss: 0.392864
global_step: 11315, epoch: 83, loss: 0.459702
global_step: 11316, epoch: 83, loss: 0.505794
global_step: 11317, epoch: 83, loss: 0.380062
global_step: 11318, epoch: 83, loss: 0.466434
global_step: 11319, epoch: 83, loss: 0.434529
global_step: 11320, epoch: 83, loss: 0.677541
epoch: 83
train	acc: 0.9480	macro: p 0.9520, r 0.9042, f1: 0.9250	micro: p 0.9480, r 0.9480, f1 0.9480	weighted_f1:0.9478
dev	acc: 0.5437	macro: p 0.3603, r 0.3254, f1: 0.3241	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5082
test	acc: 0.5843	macro: p 0.3577, r 0.3285, f1: 0.3303	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5542
global_step: 11321, epoch: 84, loss: 0.486502
global_step: 11322, epoch: 84, loss: 0.443589
global_step: 11323, epoch: 84, loss: 0.356515
global_step: 11324, epoch: 84, loss: 0.369001
global_step: 11325, epoch: 84, loss: 0.337481
global_step: 11326, epoch: 84, loss: 0.441139
global_step: 11327, epoch: 84, loss: 0.391059
global_step: 11328, epoch: 84, loss: 0.390079
global_step: 11329, epoch: 84, loss: 0.415574
global_step: 11330, epoch: 84, loss: 0.386631
global_step: 11331, epoch: 84, loss: 0.386685
global_step: 11332, epoch: 84, loss: 0.387192
global_step: 11333, epoch: 84, loss: 0.450270
global_step: 11334, epoch: 84, loss: 0.388623
global_step: 11335, epoch: 84, loss: 0.450664
global_step: 11336, epoch: 84, loss: 0.390700
global_step: 11337, epoch: 84, loss: 0.454616
global_step: 11338, epoch: 84, loss: 0.431461
global_step: 11339, epoch: 84, loss: 0.486803
global_step: 11340, epoch: 84, loss: 0.409613
global_step: 11341, epoch: 84, loss: 0.486180
global_step: 11342, epoch: 84, loss: 0.389298
global_step: 11343, epoch: 84, loss: 0.339306
global_step: 11344, epoch: 84, loss: 0.484757
global_step: 11345, epoch: 84, loss: 0.358459
global_step: 11346, epoch: 84, loss: 0.324243
global_step: 11347, epoch: 84, loss: 0.401235
global_step: 11348, epoch: 84, loss: 0.346414
global_step: 11349, epoch: 84, loss: 0.371857
global_step: 11350, epoch: 84, loss: 0.364165
global_step: 11351, epoch: 84, loss: 0.374379
global_step: 11352, epoch: 84, loss: 0.393512
global_step: 11353, epoch: 84, loss: 0.415381
global_step: 11354, epoch: 84, loss: 0.397604
global_step: 11355, epoch: 84, loss: 0.427456
global_step: 11356, epoch: 84, loss: 0.379174
global_step: 11357, epoch: 84, loss: 0.455782
global_step: 11358, epoch: 84, loss: 0.420967
global_step: 11359, epoch: 84, loss: 0.370294
global_step: 11360, epoch: 84, loss: 0.305513
epoch: 84
train	acc: 0.9508	macro: p 0.9579, r 0.9093, f1: 0.9309	micro: p 0.9508, r 0.9508, f1 0.9508	weighted_f1:0.9506
dev	acc: 0.5518	macro: p 0.3857, r 0.3301, f1: 0.3261	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5113
test	acc: 0.5812	macro: p 0.3707, r 0.3267, f1: 0.3281	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5506
global_step: 11361, epoch: 85, loss: 0.366410
global_step: 11362, epoch: 85, loss: 0.359698
global_step: 11363, epoch: 85, loss: 0.416144
global_step: 11364, epoch: 85, loss: 0.346483
global_step: 11365, epoch: 85, loss: 0.386942
global_step: 11366, epoch: 85, loss: 0.463848
global_step: 11367, epoch: 85, loss: 0.370394
global_step: 11368, epoch: 85, loss: 0.307230
global_step: 11369, epoch: 85, loss: 0.424298
global_step: 11370, epoch: 85, loss: 0.320639
global_step: 11371, epoch: 85, loss: 0.355006
global_step: 11372, epoch: 85, loss: 0.417702
global_step: 11373, epoch: 85, loss: 0.318253
global_step: 11374, epoch: 85, loss: 0.394098
global_step: 11375, epoch: 85, loss: 0.417505
global_step: 11376, epoch: 85, loss: 0.377723
global_step: 11377, epoch: 85, loss: 0.428156
global_step: 11378, epoch: 85, loss: 0.440500
global_step: 11379, epoch: 85, loss: 0.410062
global_step: 11380, epoch: 85, loss: 0.372098
global_step: 11381, epoch: 85, loss: 0.396674
global_step: 11382, epoch: 85, loss: 0.345082
global_step: 11383, epoch: 85, loss: 0.421224
global_step: 11384, epoch: 85, loss: 0.445656
global_step: 11385, epoch: 85, loss: 0.432177
global_step: 11386, epoch: 85, loss: 0.462465
global_step: 11387, epoch: 85, loss: 0.428142
global_step: 11388, epoch: 85, loss: 0.460039
global_step: 11389, epoch: 85, loss: 0.405278
global_step: 11390, epoch: 85, loss: 0.273598
global_step: 11391, epoch: 85, loss: 0.349335
global_step: 11392, epoch: 85, loss: 0.403009
global_step: 11393, epoch: 85, loss: 0.430181
global_step: 11394, epoch: 85, loss: 0.413879
global_step: 11395, epoch: 85, loss: 0.414013
global_step: 11396, epoch: 85, loss: 0.325384
global_step: 11397, epoch: 85, loss: 0.370796
global_step: 11398, epoch: 85, loss: 0.365091
global_step: 11399, epoch: 85, loss: 0.393348
global_step: 11400, epoch: 85, loss: 0.367293
epoch: 85
train	acc: 0.9508	macro: p 0.9561, r 0.9093, f1: 0.9299	micro: p 0.9508, r 0.9508, f1 0.9508	weighted_f1:0.9506
dev	acc: 0.5500	macro: p 0.3861, r 0.3311, f1: 0.3316	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5145
test	acc: 0.5877	macro: p 0.3632, r 0.3293, f1: 0.3324	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5569
global_step: 11401, epoch: 86, loss: 0.481581
global_step: 11402, epoch: 86, loss: 0.399909
global_step: 11403, epoch: 86, loss: 0.377917
global_step: 11404, epoch: 86, loss: 0.357945
global_step: 11405, epoch: 86, loss: 0.387374
global_step: 11406, epoch: 86, loss: 0.388469
global_step: 11407, epoch: 86, loss: 0.409086
global_step: 11408, epoch: 86, loss: 0.383776
global_step: 11409, epoch: 86, loss: 0.396474
global_step: 11410, epoch: 86, loss: 0.409426
global_step: 11411, epoch: 86, loss: 0.460192
global_step: 11412, epoch: 86, loss: 0.374576
global_step: 11413, epoch: 86, loss: 0.465438
global_step: 11414, epoch: 86, loss: 0.375436
global_step: 11415, epoch: 86, loss: 0.398655
global_step: 11416, epoch: 86, loss: 0.375023
global_step: 11417, epoch: 86, loss: 0.421146
global_step: 11418, epoch: 86, loss: 0.449119
global_step: 11419, epoch: 86, loss: 0.357693
global_step: 11420, epoch: 86, loss: 0.425728
global_step: 11421, epoch: 86, loss: 0.419522
global_step: 11422, epoch: 86, loss: 0.339462
global_step: 11423, epoch: 86, loss: 0.408355
global_step: 11424, epoch: 86, loss: 0.413410
global_step: 11425, epoch: 86, loss: 0.360658
global_step: 11426, epoch: 86, loss: 0.330582
global_step: 11427, epoch: 86, loss: 0.424548
global_step: 11428, epoch: 86, loss: 0.393547
global_step: 11429, epoch: 86, loss: 0.377431
global_step: 11430, epoch: 86, loss: 0.534089
global_step: 11431, epoch: 86, loss: 0.393978
global_step: 11432, epoch: 86, loss: 0.388913
global_step: 11433, epoch: 86, loss: 0.496454
global_step: 11434, epoch: 86, loss: 0.418110
global_step: 11435, epoch: 86, loss: 0.406716
global_step: 11436, epoch: 86, loss: 0.435060
global_step: 11437, epoch: 86, loss: 0.425076
global_step: 11438, epoch: 86, loss: 0.422327
global_step: 11439, epoch: 86, loss: 0.455579
global_step: 11440, epoch: 86, loss: 0.867350
epoch: 86
train	acc: 0.9493	macro: p 0.9588, r 0.9055, f1: 0.9292	micro: p 0.9493, r 0.9493, f1 0.9493	weighted_f1:0.9490
dev	acc: 0.5573	macro: p 0.4302, r 0.3219, f1: 0.3214	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5082
test	acc: 0.5954	macro: p 0.3567, r 0.3176, f1: 0.3231	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5532
global_step: 11441, epoch: 87, loss: 0.358657
global_step: 11442, epoch: 87, loss: 0.402424
global_step: 11443, epoch: 87, loss: 0.461782
global_step: 11444, epoch: 87, loss: 0.308212
global_step: 11445, epoch: 87, loss: 0.379333
global_step: 11446, epoch: 87, loss: 0.453083
global_step: 11447, epoch: 87, loss: 0.429922
global_step: 11448, epoch: 87, loss: 0.345499
global_step: 11449, epoch: 87, loss: 0.454893
global_step: 11450, epoch: 87, loss: 0.409656
global_step: 11451, epoch: 87, loss: 0.379497
global_step: 11452, epoch: 87, loss: 0.291501
global_step: 11453, epoch: 87, loss: 0.337849
global_step: 11454, epoch: 87, loss: 0.409183
global_step: 11455, epoch: 87, loss: 0.512841
global_step: 11456, epoch: 87, loss: 0.406330
global_step: 11457, epoch: 87, loss: 0.422341
global_step: 11458, epoch: 87, loss: 0.439464
global_step: 11459, epoch: 87, loss: 0.430007
global_step: 11460, epoch: 87, loss: 0.371982
global_step: 11461, epoch: 87, loss: 0.419082
global_step: 11462, epoch: 87, loss: 0.385370
global_step: 11463, epoch: 87, loss: 0.312484
global_step: 11464, epoch: 87, loss: 0.402935
global_step: 11465, epoch: 87, loss: 0.373611
global_step: 11466, epoch: 87, loss: 0.454375
global_step: 11467, epoch: 87, loss: 0.346037
global_step: 11468, epoch: 87, loss: 0.378929
global_step: 11469, epoch: 87, loss: 0.415309
global_step: 11470, epoch: 87, loss: 0.330359
global_step: 11471, epoch: 87, loss: 0.377222
global_step: 11472, epoch: 87, loss: 0.381046
global_step: 11473, epoch: 87, loss: 0.433117
global_step: 11474, epoch: 87, loss: 0.435858
global_step: 11475, epoch: 87, loss: 0.422618
global_step: 11476, epoch: 87, loss: 0.338959
global_step: 11477, epoch: 87, loss: 0.431367
global_step: 11478, epoch: 87, loss: 0.348524
global_step: 11479, epoch: 87, loss: 0.349677
global_step: 11480, epoch: 87, loss: 0.344636
epoch: 87
train	acc: 0.9491	macro: p 0.9584, r 0.9049, f1: 0.9286	micro: p 0.9491, r 0.9491, f1 0.9491	weighted_f1:0.9489
dev	acc: 0.5582	macro: p 0.4300, r 0.3225, f1: 0.3172	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5072
test	acc: 0.5858	macro: p 0.3499, r 0.3131, f1: 0.3147	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5443
global_step: 11481, epoch: 88, loss: 0.399661
global_step: 11482, epoch: 88, loss: 0.439083
global_step: 11483, epoch: 88, loss: 0.371002
global_step: 11484, epoch: 88, loss: 0.441265
global_step: 11485, epoch: 88, loss: 0.515047
global_step: 11486, epoch: 88, loss: 0.447217
global_step: 11487, epoch: 88, loss: 0.377104
global_step: 11488, epoch: 88, loss: 0.354284
global_step: 11489, epoch: 88, loss: 0.387918
global_step: 11490, epoch: 88, loss: 0.363520
global_step: 11491, epoch: 88, loss: 0.382955
global_step: 11492, epoch: 88, loss: 0.321368
global_step: 11493, epoch: 88, loss: 0.261543
global_step: 11494, epoch: 88, loss: 0.423174
global_step: 11495, epoch: 88, loss: 0.319963
global_step: 11496, epoch: 88, loss: 0.339670
global_step: 11497, epoch: 88, loss: 0.466824
global_step: 11498, epoch: 88, loss: 0.472933
global_step: 11499, epoch: 88, loss: 0.368890
global_step: 11500, epoch: 88, loss: 0.356745
global_step: 11501, epoch: 88, loss: 0.428737
global_step: 11502, epoch: 88, loss: 0.280836
global_step: 11503, epoch: 88, loss: 0.390580
global_step: 11504, epoch: 88, loss: 0.394176
global_step: 11505, epoch: 88, loss: 0.362969
global_step: 11506, epoch: 88, loss: 0.361289
global_step: 11507, epoch: 88, loss: 0.413584
global_step: 11508, epoch: 88, loss: 0.329962
global_step: 11509, epoch: 88, loss: 0.385160
global_step: 11510, epoch: 88, loss: 0.419450
global_step: 11511, epoch: 88, loss: 0.314090
global_step: 11512, epoch: 88, loss: 0.329514
global_step: 11513, epoch: 88, loss: 0.437892
global_step: 11514, epoch: 88, loss: 0.464254
global_step: 11515, epoch: 88, loss: 0.396788
global_step: 11516, epoch: 88, loss: 0.325987
global_step: 11517, epoch: 88, loss: 0.392968
global_step: 11518, epoch: 88, loss: 0.481983
global_step: 11519, epoch: 88, loss: 0.429477
global_step: 11520, epoch: 88, loss: 0.666236
epoch: 88
train	acc: 0.9524	macro: p 0.9565, r 0.9173, f1: 0.9348	micro: p 0.9524, r 0.9524, f1 0.9524	weighted_f1:0.9524
dev	acc: 0.5482	macro: p 0.3780, r 0.3274, f1: 0.3242	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5099
test	acc: 0.5808	macro: p 0.3617, r 0.3266, f1: 0.3263	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5503
global_step: 11521, epoch: 89, loss: 0.408177
global_step: 11522, epoch: 89, loss: 0.509861
global_step: 11523, epoch: 89, loss: 0.317018
global_step: 11524, epoch: 89, loss: 0.382396
global_step: 11525, epoch: 89, loss: 0.384443
global_step: 11526, epoch: 89, loss: 0.349535
global_step: 11527, epoch: 89, loss: 0.341802
global_step: 11528, epoch: 89, loss: 0.366667
global_step: 11529, epoch: 89, loss: 0.384260
global_step: 11530, epoch: 89, loss: 0.432466
global_step: 11531, epoch: 89, loss: 0.310261
global_step: 11532, epoch: 89, loss: 0.379882
global_step: 11533, epoch: 89, loss: 0.381771
global_step: 11534, epoch: 89, loss: 0.309351
global_step: 11535, epoch: 89, loss: 0.375290
global_step: 11536, epoch: 89, loss: 0.424823
global_step: 11537, epoch: 89, loss: 0.355729
global_step: 11538, epoch: 89, loss: 0.351559
global_step: 11539, epoch: 89, loss: 0.367396
global_step: 11540, epoch: 89, loss: 0.334875
global_step: 11541, epoch: 89, loss: 0.335986
global_step: 11542, epoch: 89, loss: 0.370895
global_step: 11543, epoch: 89, loss: 0.350234
global_step: 11544, epoch: 89, loss: 0.379964
global_step: 11545, epoch: 89, loss: 0.287607
global_step: 11546, epoch: 89, loss: 0.456880
global_step: 11547, epoch: 89, loss: 0.406004
global_step: 11548, epoch: 89, loss: 0.427510
global_step: 11549, epoch: 89, loss: 0.470772
global_step: 11550, epoch: 89, loss: 0.329717
global_step: 11551, epoch: 89, loss: 0.423669
global_step: 11552, epoch: 89, loss: 0.488855
global_step: 11553, epoch: 89, loss: 0.347058
global_step: 11554, epoch: 89, loss: 0.421539
global_step: 11555, epoch: 89, loss: 0.420492
global_step: 11556, epoch: 89, loss: 0.375142
global_step: 11557, epoch: 89, loss: 0.338404
global_step: 11558, epoch: 89, loss: 0.376203
global_step: 11559, epoch: 89, loss: 0.346293
global_step: 11560, epoch: 89, loss: 0.382775
epoch: 89
train	acc: 0.9503	macro: p 0.9586, r 0.9086, f1: 0.9311	micro: p 0.9503, r 0.9503, f1 0.9503	weighted_f1:0.9500
dev	acc: 0.5546	macro: p 0.4195, r 0.3199, f1: 0.3182	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5055
test	acc: 0.5897	macro: p 0.3616, r 0.3131, f1: 0.3183	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5468
global_step: 11561, epoch: 90, loss: 0.435908
global_step: 11562, epoch: 90, loss: 0.330431
global_step: 11563, epoch: 90, loss: 0.416163
global_step: 11564, epoch: 90, loss: 0.344762
global_step: 11565, epoch: 90, loss: 0.305279
global_step: 11566, epoch: 90, loss: 0.354932
global_step: 11567, epoch: 90, loss: 0.343101
global_step: 11568, epoch: 90, loss: 0.403730
global_step: 11569, epoch: 90, loss: 0.358919
global_step: 11570, epoch: 90, loss: 0.364937
global_step: 11571, epoch: 90, loss: 0.406062
global_step: 11572, epoch: 90, loss: 0.290287
global_step: 11573, epoch: 90, loss: 0.367281
global_step: 11574, epoch: 90, loss: 0.417215
global_step: 11575, epoch: 90, loss: 0.391094
global_step: 11576, epoch: 90, loss: 0.354327
global_step: 11577, epoch: 90, loss: 0.477130
global_step: 11578, epoch: 90, loss: 0.305022
global_step: 11579, epoch: 90, loss: 0.322950
global_step: 11580, epoch: 90, loss: 0.327020
global_step: 11581, epoch: 90, loss: 0.365509
global_step: 11582, epoch: 90, loss: 0.410570
global_step: 11583, epoch: 90, loss: 0.368532
global_step: 11584, epoch: 90, loss: 0.408441
global_step: 11585, epoch: 90, loss: 0.368945
global_step: 11586, epoch: 90, loss: 0.409370
global_step: 11587, epoch: 90, loss: 0.333993
global_step: 11588, epoch: 90, loss: 0.408623
global_step: 11589, epoch: 90, loss: 0.335236
global_step: 11590, epoch: 90, loss: 0.334589
global_step: 11591, epoch: 90, loss: 0.363437
global_step: 11592, epoch: 90, loss: 0.443542
global_step: 11593, epoch: 90, loss: 0.373606
global_step: 11594, epoch: 90, loss: 0.426066
global_step: 11595, epoch: 90, loss: 0.358823
global_step: 11596, epoch: 90, loss: 0.370011
global_step: 11597, epoch: 90, loss: 0.330630
global_step: 11598, epoch: 90, loss: 0.403015
global_step: 11599, epoch: 90, loss: 0.481489
global_step: 11600, epoch: 90, loss: 0.483906
epoch: 90
train	acc: 0.9516	macro: p 0.9623, r 0.9131, f1: 0.9355	micro: p 0.9516, r 0.9516, f1 0.9516	weighted_f1:0.9514
dev	acc: 0.5582	macro: p 0.4370, r 0.3172, f1: 0.3173	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5065
test	acc: 0.5946	macro: p 0.3846, r 0.3135, f1: 0.3208	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5502
global_step: 11601, epoch: 91, loss: 0.385964
global_step: 11602, epoch: 91, loss: 0.400278
global_step: 11603, epoch: 91, loss: 0.306669
global_step: 11604, epoch: 91, loss: 0.367736
global_step: 11605, epoch: 91, loss: 0.352350
global_step: 11606, epoch: 91, loss: 0.354970
global_step: 11607, epoch: 91, loss: 0.348875
global_step: 11608, epoch: 91, loss: 0.334635
global_step: 11609, epoch: 91, loss: 0.320840
global_step: 11610, epoch: 91, loss: 0.335583
global_step: 11611, epoch: 91, loss: 0.467432
global_step: 11612, epoch: 91, loss: 0.333669
global_step: 11613, epoch: 91, loss: 0.364239
global_step: 11614, epoch: 91, loss: 0.395110
global_step: 11615, epoch: 91, loss: 0.412338
global_step: 11616, epoch: 91, loss: 0.373410
global_step: 11617, epoch: 91, loss: 0.370325
global_step: 11618, epoch: 91, loss: 0.263870
global_step: 11619, epoch: 91, loss: 0.333894
global_step: 11620, epoch: 91, loss: 0.390440
global_step: 11621, epoch: 91, loss: 0.358825
global_step: 11622, epoch: 91, loss: 0.335096
global_step: 11623, epoch: 91, loss: 0.374107
global_step: 11624, epoch: 91, loss: 0.314201
global_step: 11625, epoch: 91, loss: 0.319466
global_step: 11626, epoch: 91, loss: 0.351580
global_step: 11627, epoch: 91, loss: 0.353449
global_step: 11628, epoch: 91, loss: 0.366392
global_step: 11629, epoch: 91, loss: 0.401320
global_step: 11630, epoch: 91, loss: 0.475670
global_step: 11631, epoch: 91, loss: 0.391785
global_step: 11632, epoch: 91, loss: 0.347518
global_step: 11633, epoch: 91, loss: 0.411975
global_step: 11634, epoch: 91, loss: 0.391840
global_step: 11635, epoch: 91, loss: 0.375342
global_step: 11636, epoch: 91, loss: 0.359643
global_step: 11637, epoch: 91, loss: 0.456023
global_step: 11638, epoch: 91, loss: 0.426706
global_step: 11639, epoch: 91, loss: 0.475057
global_step: 11640, epoch: 91, loss: 0.077263
epoch: 91
train	acc: 0.9547	macro: p 0.9611, r 0.9200, f1: 0.9387	micro: p 0.9547, r 0.9547, f1 0.9547	weighted_f1:0.9545
dev	acc: 0.5509	macro: p 0.3778, r 0.3153, f1: 0.3158	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5036
test	acc: 0.5904	macro: p 0.3720, r 0.3168, f1: 0.3221	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5504
global_step: 11641, epoch: 92, loss: 0.386351
global_step: 11642, epoch: 92, loss: 0.406094
global_step: 11643, epoch: 92, loss: 0.348159
global_step: 11644, epoch: 92, loss: 0.347217
global_step: 11645, epoch: 92, loss: 0.404531
global_step: 11646, epoch: 92, loss: 0.361655
global_step: 11647, epoch: 92, loss: 0.362828
global_step: 11648, epoch: 92, loss: 0.403677
global_step: 11649, epoch: 92, loss: 0.372891
global_step: 11650, epoch: 92, loss: 0.384916
global_step: 11651, epoch: 92, loss: 0.403383
global_step: 11652, epoch: 92, loss: 0.359534
global_step: 11653, epoch: 92, loss: 0.312250
global_step: 11654, epoch: 92, loss: 0.355446
global_step: 11655, epoch: 92, loss: 0.358810
global_step: 11656, epoch: 92, loss: 0.415427
global_step: 11657, epoch: 92, loss: 0.424044
global_step: 11658, epoch: 92, loss: 0.425599
global_step: 11659, epoch: 92, loss: 0.290313
global_step: 11660, epoch: 92, loss: 0.351870
global_step: 11661, epoch: 92, loss: 0.358622
global_step: 11662, epoch: 92, loss: 0.371173
global_step: 11663, epoch: 92, loss: 0.406180
global_step: 11664, epoch: 92, loss: 0.382110
global_step: 11665, epoch: 92, loss: 0.313363
global_step: 11666, epoch: 92, loss: 0.304043
global_step: 11667, epoch: 92, loss: 0.281487
global_step: 11668, epoch: 92, loss: 0.436092
global_step: 11669, epoch: 92, loss: 0.409611
global_step: 11670, epoch: 92, loss: 0.392564
global_step: 11671, epoch: 92, loss: 0.383256
global_step: 11672, epoch: 92, loss: 0.411149
global_step: 11673, epoch: 92, loss: 0.325440
global_step: 11674, epoch: 92, loss: 0.415194
global_step: 11675, epoch: 92, loss: 0.339935
global_step: 11676, epoch: 92, loss: 0.330783
global_step: 11677, epoch: 92, loss: 0.424555
global_step: 11678, epoch: 92, loss: 0.358242
global_step: 11679, epoch: 92, loss: 0.415597
global_step: 11680, epoch: 92, loss: 0.061566
epoch: 92
train	acc: 0.9537	macro: p 0.9625, r 0.9200, f1: 0.9395	micro: p 0.9537, r 0.9537, f1 0.9537	weighted_f1:0.9536
dev	acc: 0.5555	macro: p 0.4282, r 0.3200, f1: 0.3198	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5067
test	acc: 0.5908	macro: p 0.3749, r 0.3151, f1: 0.3212	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5487
global_step: 11681, epoch: 93, loss: 0.323726
global_step: 11682, epoch: 93, loss: 0.395226
global_step: 11683, epoch: 93, loss: 0.322868
global_step: 11684, epoch: 93, loss: 0.327078
global_step: 11685, epoch: 93, loss: 0.426301
global_step: 11686, epoch: 93, loss: 0.320522
global_step: 11687, epoch: 93, loss: 0.298310
global_step: 11688, epoch: 93, loss: 0.427797
global_step: 11689, epoch: 93, loss: 0.304528
global_step: 11690, epoch: 93, loss: 0.343984
global_step: 11691, epoch: 93, loss: 0.439936
global_step: 11692, epoch: 93, loss: 0.386772
global_step: 11693, epoch: 93, loss: 0.312628
global_step: 11694, epoch: 93, loss: 0.355392
global_step: 11695, epoch: 93, loss: 0.385290
global_step: 11696, epoch: 93, loss: 0.325688
global_step: 11697, epoch: 93, loss: 0.359408
global_step: 11698, epoch: 93, loss: 0.372963
global_step: 11699, epoch: 93, loss: 0.320443
global_step: 11700, epoch: 93, loss: 0.322092
global_step: 11701, epoch: 93, loss: 0.433632
global_step: 11702, epoch: 93, loss: 0.410222
global_step: 11703, epoch: 93, loss: 0.457600
global_step: 11704, epoch: 93, loss: 0.391761
global_step: 11705, epoch: 93, loss: 0.350849
global_step: 11706, epoch: 93, loss: 0.426713
global_step: 11707, epoch: 93, loss: 0.411767
global_step: 11708, epoch: 93, loss: 0.366081
global_step: 11709, epoch: 93, loss: 0.407353
global_step: 11710, epoch: 93, loss: 0.300493
global_step: 11711, epoch: 93, loss: 0.470783
global_step: 11712, epoch: 93, loss: 0.419773
global_step: 11713, epoch: 93, loss: 0.339751
global_step: 11714, epoch: 93, loss: 0.421137
global_step: 11715, epoch: 93, loss: 0.400019
global_step: 11716, epoch: 93, loss: 0.407544
global_step: 11717, epoch: 93, loss: 0.403661
global_step: 11718, epoch: 93, loss: 0.336036
global_step: 11719, epoch: 93, loss: 0.439533
global_step: 11720, epoch: 93, loss: 0.093820
epoch: 93
train	acc: 0.9530	macro: p 0.9620, r 0.9159, f1: 0.9370	micro: p 0.9530, r 0.9530, f1 0.9530	weighted_f1:0.9528
dev	acc: 0.5618	macro: p 0.4481, r 0.3252, f1: 0.3269	micro: p 0.5618, r 0.5618, f1 0.5618	weighted_f1:0.5137
test	acc: 0.5870	macro: p 0.3736, r 0.3125, f1: 0.3178	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5434
global_step: 11721, epoch: 94, loss: 0.336086
global_step: 11722, epoch: 94, loss: 0.341581
global_step: 11723, epoch: 94, loss: 0.317416
global_step: 11724, epoch: 94, loss: 0.406606
global_step: 11725, epoch: 94, loss: 0.374123
global_step: 11726, epoch: 94, loss: 0.312519
global_step: 11727, epoch: 94, loss: 0.369605
global_step: 11728, epoch: 94, loss: 0.366359
global_step: 11729, epoch: 94, loss: 0.287126
global_step: 11730, epoch: 94, loss: 0.275839
global_step: 11731, epoch: 94, loss: 0.347582
global_step: 11732, epoch: 94, loss: 0.301762
global_step: 11733, epoch: 94, loss: 0.417914
global_step: 11734, epoch: 94, loss: 0.373879
global_step: 11735, epoch: 94, loss: 0.389950
global_step: 11736, epoch: 94, loss: 0.314537
global_step: 11737, epoch: 94, loss: 0.328676
global_step: 11738, epoch: 94, loss: 0.424760
global_step: 11739, epoch: 94, loss: 0.393433
global_step: 11740, epoch: 94, loss: 0.392587
global_step: 11741, epoch: 94, loss: 0.409721
global_step: 11742, epoch: 94, loss: 0.349918
global_step: 11743, epoch: 94, loss: 0.360907
global_step: 11744, epoch: 94, loss: 0.331243
global_step: 11745, epoch: 94, loss: 0.378665
global_step: 11746, epoch: 94, loss: 0.299005
global_step: 11747, epoch: 94, loss: 0.350273
global_step: 11748, epoch: 94, loss: 0.374762
global_step: 11749, epoch: 94, loss: 0.336353
global_step: 11750, epoch: 94, loss: 0.413878
global_step: 11751, epoch: 94, loss: 0.336191
global_step: 11752, epoch: 94, loss: 0.400572
global_step: 11753, epoch: 94, loss: 0.388792
global_step: 11754, epoch: 94, loss: 0.303898
global_step: 11755, epoch: 94, loss: 0.409407
global_step: 11756, epoch: 94, loss: 0.344102
global_step: 11757, epoch: 94, loss: 0.387116
global_step: 11758, epoch: 94, loss: 0.402343
global_step: 11759, epoch: 94, loss: 0.370997
global_step: 11760, epoch: 94, loss: 0.062997
epoch: 94
train	acc: 0.9557	macro: p 0.9608, r 0.9234, f1: 0.9405	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9555
dev	acc: 0.5582	macro: p 0.4248, r 0.3285, f1: 0.3296	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5141
test	acc: 0.5920	macro: p 0.3742, r 0.3234, f1: 0.3282	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5531
global_step: 11761, epoch: 95, loss: 0.285848
global_step: 11762, epoch: 95, loss: 0.327979
global_step: 11763, epoch: 95, loss: 0.345140
global_step: 11764, epoch: 95, loss: 0.396252
global_step: 11765, epoch: 95, loss: 0.335389
global_step: 11766, epoch: 95, loss: 0.310692
global_step: 11767, epoch: 95, loss: 0.325912
global_step: 11768, epoch: 95, loss: 0.344923
global_step: 11769, epoch: 95, loss: 0.448770
global_step: 11770, epoch: 95, loss: 0.360514
global_step: 11771, epoch: 95, loss: 0.343316
global_step: 11772, epoch: 95, loss: 0.308715
global_step: 11773, epoch: 95, loss: 0.325872
global_step: 11774, epoch: 95, loss: 0.348954
global_step: 11775, epoch: 95, loss: 0.306726
global_step: 11776, epoch: 95, loss: 0.327115
global_step: 11777, epoch: 95, loss: 0.366281
global_step: 11778, epoch: 95, loss: 0.402740
global_step: 11779, epoch: 95, loss: 0.345817
global_step: 11780, epoch: 95, loss: 0.354838
global_step: 11781, epoch: 95, loss: 0.387383
global_step: 11782, epoch: 95, loss: 0.288460
global_step: 11783, epoch: 95, loss: 0.304680
global_step: 11784, epoch: 95, loss: 0.344029
global_step: 11785, epoch: 95, loss: 0.363189
global_step: 11786, epoch: 95, loss: 0.296272
global_step: 11787, epoch: 95, loss: 0.387765
global_step: 11788, epoch: 95, loss: 0.374322
global_step: 11789, epoch: 95, loss: 0.339104
global_step: 11790, epoch: 95, loss: 0.246087
global_step: 11791, epoch: 95, loss: 0.370592
global_step: 11792, epoch: 95, loss: 0.380827
global_step: 11793, epoch: 95, loss: 0.379255
global_step: 11794, epoch: 95, loss: 0.424696
global_step: 11795, epoch: 95, loss: 0.369086
global_step: 11796, epoch: 95, loss: 0.446932
global_step: 11797, epoch: 95, loss: 0.326937
global_step: 11798, epoch: 95, loss: 0.374361
global_step: 11799, epoch: 95, loss: 0.388800
global_step: 11800, epoch: 95, loss: 0.059606
epoch: 95
train	acc: 0.9566	macro: p 0.9626, r 0.9282, f1: 0.9443	micro: p 0.9566, r 0.9566, f1 0.9566	weighted_f1:0.9565
dev	acc: 0.5528	macro: p 0.3891, r 0.3235, f1: 0.3245	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5100
test	acc: 0.5874	macro: p 0.3674, r 0.3238, f1: 0.3312	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5530
global_step: 11801, epoch: 96, loss: 0.341548
global_step: 11802, epoch: 96, loss: 0.365648
global_step: 11803, epoch: 96, loss: 0.384167
global_step: 11804, epoch: 96, loss: 0.421850
global_step: 11805, epoch: 96, loss: 0.300732
global_step: 11806, epoch: 96, loss: 0.360609
global_step: 11807, epoch: 96, loss: 0.403303
global_step: 11808, epoch: 96, loss: 0.263683
global_step: 11809, epoch: 96, loss: 0.351676
global_step: 11810, epoch: 96, loss: 0.319819
global_step: 11811, epoch: 96, loss: 0.396041
global_step: 11812, epoch: 96, loss: 0.327677
global_step: 11813, epoch: 96, loss: 0.405218
global_step: 11814, epoch: 96, loss: 0.473766
global_step: 11815, epoch: 96, loss: 0.310402
global_step: 11816, epoch: 96, loss: 0.357015
global_step: 11817, epoch: 96, loss: 0.389881
global_step: 11818, epoch: 96, loss: 0.346846
global_step: 11819, epoch: 96, loss: 0.350541
global_step: 11820, epoch: 96, loss: 0.378349
global_step: 11821, epoch: 96, loss: 0.376253
global_step: 11822, epoch: 96, loss: 0.302159
global_step: 11823, epoch: 96, loss: 0.341951
global_step: 11824, epoch: 96, loss: 0.332078
global_step: 11825, epoch: 96, loss: 0.394613
global_step: 11826, epoch: 96, loss: 0.404266
global_step: 11827, epoch: 96, loss: 0.317827
global_step: 11828, epoch: 96, loss: 0.347232
global_step: 11829, epoch: 96, loss: 0.369086
global_step: 11830, epoch: 96, loss: 0.408156
global_step: 11831, epoch: 96, loss: 0.366880
global_step: 11832, epoch: 96, loss: 0.358858
global_step: 11833, epoch: 96, loss: 0.343581
global_step: 11834, epoch: 96, loss: 0.376706
global_step: 11835, epoch: 96, loss: 0.282628
global_step: 11836, epoch: 96, loss: 0.364796
global_step: 11837, epoch: 96, loss: 0.367499
global_step: 11838, epoch: 96, loss: 0.434625
global_step: 11839, epoch: 96, loss: 0.375223
global_step: 11840, epoch: 96, loss: 0.285619
epoch: 96
train	acc: 0.9532	macro: p 0.9621, r 0.9147, f1: 0.9362	micro: p 0.9532, r 0.9532, f1 0.9532	weighted_f1:0.9530
dev	acc: 0.5482	macro: p 0.4889, r 0.3183, f1: 0.3164	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5021
test	acc: 0.5858	macro: p 0.3619, r 0.3171, f1: 0.3203	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5476
global_step: 11841, epoch: 97, loss: 0.380414
global_step: 11842, epoch: 97, loss: 0.259815
global_step: 11843, epoch: 97, loss: 0.341478
global_step: 11844, epoch: 97, loss: 0.299943
global_step: 11845, epoch: 97, loss: 0.368082
global_step: 11846, epoch: 97, loss: 0.396280
global_step: 11847, epoch: 97, loss: 0.321572
global_step: 11848, epoch: 97, loss: 0.298467
global_step: 11849, epoch: 97, loss: 0.365079
global_step: 11850, epoch: 97, loss: 0.286364
global_step: 11851, epoch: 97, loss: 0.326666
global_step: 11852, epoch: 97, loss: 0.351881
global_step: 11853, epoch: 97, loss: 0.286878
global_step: 11854, epoch: 97, loss: 0.346409
global_step: 11855, epoch: 97, loss: 0.328925
global_step: 11856, epoch: 97, loss: 0.348292
global_step: 11857, epoch: 97, loss: 0.389202
global_step: 11858, epoch: 97, loss: 0.422817
global_step: 11859, epoch: 97, loss: 0.290070
global_step: 11860, epoch: 97, loss: 0.327354
global_step: 11861, epoch: 97, loss: 0.305943
global_step: 11862, epoch: 97, loss: 0.357564
global_step: 11863, epoch: 97, loss: 0.414674
global_step: 11864, epoch: 97, loss: 0.354553
global_step: 11865, epoch: 97, loss: 0.364368
global_step: 11866, epoch: 97, loss: 0.304723
global_step: 11867, epoch: 97, loss: 0.373078
global_step: 11868, epoch: 97, loss: 0.344638
global_step: 11869, epoch: 97, loss: 0.322742
global_step: 11870, epoch: 97, loss: 0.366995
global_step: 11871, epoch: 97, loss: 0.439579
global_step: 11872, epoch: 97, loss: 0.418021
global_step: 11873, epoch: 97, loss: 0.329784
global_step: 11874, epoch: 97, loss: 0.420540
global_step: 11875, epoch: 97, loss: 0.428118
global_step: 11876, epoch: 97, loss: 0.394460
global_step: 11877, epoch: 97, loss: 0.320926
global_step: 11878, epoch: 97, loss: 0.395587
global_step: 11879, epoch: 97, loss: 0.348840
global_step: 11880, epoch: 97, loss: 0.600553
epoch: 97
train	acc: 0.9564	macro: p 0.9628, r 0.9239, f1: 0.9418	micro: p 0.9564, r 0.9564, f1 0.9564	weighted_f1:0.9562
dev	acc: 0.5437	macro: p 0.3808, r 0.3177, f1: 0.3156	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5007
test	acc: 0.5870	macro: p 0.3706, r 0.3220, f1: 0.3277	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5529
global_step: 11881, epoch: 98, loss: 0.287626
global_step: 11882, epoch: 98, loss: 0.283115
global_step: 11883, epoch: 98, loss: 0.370669
global_step: 11884, epoch: 98, loss: 0.312407
global_step: 11885, epoch: 98, loss: 0.410341
global_step: 11886, epoch: 98, loss: 0.329710
global_step: 11887, epoch: 98, loss: 0.265493
global_step: 11888, epoch: 98, loss: 0.327178
global_step: 11889, epoch: 98, loss: 0.342080
global_step: 11890, epoch: 98, loss: 0.267019
global_step: 11891, epoch: 98, loss: 0.377566
global_step: 11892, epoch: 98, loss: 0.354556
global_step: 11893, epoch: 98, loss: 0.388575
global_step: 11894, epoch: 98, loss: 0.292129
global_step: 11895, epoch: 98, loss: 0.368608
global_step: 11896, epoch: 98, loss: 0.355923
global_step: 11897, epoch: 98, loss: 0.322121
global_step: 11898, epoch: 98, loss: 0.337170
global_step: 11899, epoch: 98, loss: 0.361753
global_step: 11900, epoch: 98, loss: 0.313310
global_step: 11901, epoch: 98, loss: 0.419434
global_step: 11902, epoch: 98, loss: 0.303410
global_step: 11903, epoch: 98, loss: 0.392250
global_step: 11904, epoch: 98, loss: 0.347712
global_step: 11905, epoch: 98, loss: 0.375544
global_step: 11906, epoch: 98, loss: 0.406426
global_step: 11907, epoch: 98, loss: 0.334442
global_step: 11908, epoch: 98, loss: 0.314523
global_step: 11909, epoch: 98, loss: 0.323883
global_step: 11910, epoch: 98, loss: 0.284319
global_step: 11911, epoch: 98, loss: 0.442152
global_step: 11912, epoch: 98, loss: 0.330830
global_step: 11913, epoch: 98, loss: 0.443834
global_step: 11914, epoch: 98, loss: 0.382321
global_step: 11915, epoch: 98, loss: 0.376301
global_step: 11916, epoch: 98, loss: 0.325560
global_step: 11917, epoch: 98, loss: 0.350547
global_step: 11918, epoch: 98, loss: 0.358109
global_step: 11919, epoch: 98, loss: 0.346038
global_step: 11920, epoch: 98, loss: 0.309819
epoch: 98
train	acc: 0.9570	macro: p 0.9621, r 0.9268, f1: 0.9431	micro: p 0.9570, r 0.9570, f1 0.9570	weighted_f1:0.9569
dev	acc: 0.5491	macro: p 0.3899, r 0.3204, f1: 0.3167	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5032
test	acc: 0.5877	macro: p 0.3902, r 0.3259, f1: 0.3327	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5531
global_step: 11921, epoch: 99, loss: 0.327504
global_step: 11922, epoch: 99, loss: 0.342847
global_step: 11923, epoch: 99, loss: 0.252115
global_step: 11924, epoch: 99, loss: 0.346725
global_step: 11925, epoch: 99, loss: 0.394567
global_step: 11926, epoch: 99, loss: 0.257431
global_step: 11927, epoch: 99, loss: 0.327147
global_step: 11928, epoch: 99, loss: 0.409062
global_step: 11929, epoch: 99, loss: 0.362233
global_step: 11930, epoch: 99, loss: 0.314091
global_step: 11931, epoch: 99, loss: 0.363536
global_step: 11932, epoch: 99, loss: 0.290878
global_step: 11933, epoch: 99, loss: 0.362860
global_step: 11934, epoch: 99, loss: 0.361735
global_step: 11935, epoch: 99, loss: 0.315179
global_step: 11936, epoch: 99, loss: 0.330309
global_step: 11937, epoch: 99, loss: 0.318282
global_step: 11938, epoch: 99, loss: 0.355744
global_step: 11939, epoch: 99, loss: 0.318413
global_step: 11940, epoch: 99, loss: 0.334163
global_step: 11941, epoch: 99, loss: 0.430629
global_step: 11942, epoch: 99, loss: 0.364925
global_step: 11943, epoch: 99, loss: 0.323697
global_step: 11944, epoch: 99, loss: 0.278571
global_step: 11945, epoch: 99, loss: 0.388646
global_step: 11946, epoch: 99, loss: 0.263188
global_step: 11947, epoch: 99, loss: 0.357186
global_step: 11948, epoch: 99, loss: 0.330444
global_step: 11949, epoch: 99, loss: 0.382273
global_step: 11950, epoch: 99, loss: 0.297931
global_step: 11951, epoch: 99, loss: 0.319511
global_step: 11952, epoch: 99, loss: 0.377213
global_step: 11953, epoch: 99, loss: 0.384896
global_step: 11954, epoch: 99, loss: 0.392140
global_step: 11955, epoch: 99, loss: 0.252304
global_step: 11956, epoch: 99, loss: 0.306232
global_step: 11957, epoch: 99, loss: 0.328467
global_step: 11958, epoch: 99, loss: 0.408558
global_step: 11959, epoch: 99, loss: 0.349740
global_step: 11960, epoch: 99, loss: 0.784801
epoch: 99
train	acc: 0.9546	macro: p 0.9671, r 0.9190, f1: 0.9414	micro: p 0.9546, r 0.9546, f1 0.9546	weighted_f1:0.9543
dev	acc: 0.5564	macro: p 0.3983, r 0.3117, f1: 0.3104	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5010
test	acc: 0.5889	macro: p 0.3691, r 0.3042, f1: 0.3127	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5417
global_step: 11961, epoch: 100, loss: 0.383936
global_step: 11962, epoch: 100, loss: 0.322469
global_step: 11963, epoch: 100, loss: 0.299657
global_step: 11964, epoch: 100, loss: 0.331679
global_step: 11965, epoch: 100, loss: 0.420727
global_step: 11966, epoch: 100, loss: 0.359616
global_step: 11967, epoch: 100, loss: 0.366713
global_step: 11968, epoch: 100, loss: 0.375840
global_step: 11969, epoch: 100, loss: 0.386505
global_step: 11970, epoch: 100, loss: 0.290322
global_step: 11971, epoch: 100, loss: 0.355784
global_step: 11972, epoch: 100, loss: 0.347181
global_step: 11973, epoch: 100, loss: 0.374322
global_step: 11974, epoch: 100, loss: 0.281927
global_step: 11975, epoch: 100, loss: 0.341715
global_step: 11976, epoch: 100, loss: 0.348502
global_step: 11977, epoch: 100, loss: 0.368758
global_step: 11978, epoch: 100, loss: 0.376142
global_step: 11979, epoch: 100, loss: 0.358126
global_step: 11980, epoch: 100, loss: 0.344365
global_step: 11981, epoch: 100, loss: 0.306376
global_step: 11982, epoch: 100, loss: 0.384668
global_step: 11983, epoch: 100, loss: 0.346430
global_step: 11984, epoch: 100, loss: 0.336713
global_step: 11985, epoch: 100, loss: 0.322344
global_step: 11986, epoch: 100, loss: 0.273257
global_step: 11987, epoch: 100, loss: 0.325063
global_step: 11988, epoch: 100, loss: 0.362654
global_step: 11989, epoch: 100, loss: 0.273668
global_step: 11990, epoch: 100, loss: 0.334831
global_step: 11991, epoch: 100, loss: 0.371882
global_step: 11992, epoch: 100, loss: 0.361739
global_step: 11993, epoch: 100, loss: 0.333612
global_step: 11994, epoch: 100, loss: 0.339274
global_step: 11995, epoch: 100, loss: 0.295538
global_step: 11996, epoch: 100, loss: 0.296237
global_step: 11997, epoch: 100, loss: 0.391250
global_step: 11998, epoch: 100, loss: 0.318921
global_step: 11999, epoch: 100, loss: 0.283991
global_step: 12000, epoch: 100, loss: 0.021300
epoch: 100
train	acc: 0.9594	macro: p 0.9651, r 0.9307, f1: 0.9466	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9593
dev	acc: 0.5473	macro: p 0.3735, r 0.3225, f1: 0.3212	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5066
test	acc: 0.5858	macro: p 0.3598, r 0.3241, f1: 0.3286	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5525
global_step: 12001, epoch: 101, loss: 0.329278
global_step: 12002, epoch: 101, loss: 0.346533
global_step: 12003, epoch: 101, loss: 0.298693
global_step: 12004, epoch: 101, loss: 0.304744
global_step: 12005, epoch: 101, loss: 0.302268
global_step: 12006, epoch: 101, loss: 0.373922
global_step: 12007, epoch: 101, loss: 0.294667
global_step: 12008, epoch: 101, loss: 0.301803
global_step: 12009, epoch: 101, loss: 0.317017
global_step: 12010, epoch: 101, loss: 0.295706
global_step: 12011, epoch: 101, loss: 0.311763
global_step: 12012, epoch: 101, loss: 0.334299
global_step: 12013, epoch: 101, loss: 0.406020
global_step: 12014, epoch: 101, loss: 0.314087
global_step: 12015, epoch: 101, loss: 0.280341
global_step: 12016, epoch: 101, loss: 0.295207
global_step: 12017, epoch: 101, loss: 0.328352
global_step: 12018, epoch: 101, loss: 0.420887
global_step: 12019, epoch: 101, loss: 0.268043
global_step: 12020, epoch: 101, loss: 0.324554
global_step: 12021, epoch: 101, loss: 0.348672
global_step: 12022, epoch: 101, loss: 0.381837
global_step: 12023, epoch: 101, loss: 0.347635
global_step: 12024, epoch: 101, loss: 0.359126
global_step: 12025, epoch: 101, loss: 0.282647
global_step: 12026, epoch: 101, loss: 0.364797
global_step: 12027, epoch: 101, loss: 0.403059
global_step: 12028, epoch: 101, loss: 0.372205
global_step: 12029, epoch: 101, loss: 0.335060
global_step: 12030, epoch: 101, loss: 0.401547
global_step: 12031, epoch: 101, loss: 0.334782
global_step: 12032, epoch: 101, loss: 0.310504
global_step: 12033, epoch: 101, loss: 0.330609
global_step: 12034, epoch: 101, loss: 0.236301
global_step: 12035, epoch: 101, loss: 0.366162
global_step: 12036, epoch: 101, loss: 0.281726
global_step: 12037, epoch: 101, loss: 0.374536
global_step: 12038, epoch: 101, loss: 0.386468
global_step: 12039, epoch: 101, loss: 0.301924
global_step: 12040, epoch: 101, loss: 0.065846
epoch: 101
train	acc: 0.9589	macro: p 0.9663, r 0.9309, f1: 0.9474	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9588
dev	acc: 0.5528	macro: p 0.3845, r 0.3187, f1: 0.3179	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5063
test	acc: 0.5920	macro: p 0.3682, r 0.3223, f1: 0.3290	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5550
global_step: 12041, epoch: 102, loss: 0.368068
global_step: 12042, epoch: 102, loss: 0.386529
global_step: 12043, epoch: 102, loss: 0.309202
global_step: 12044, epoch: 102, loss: 0.325943
global_step: 12045, epoch: 102, loss: 0.358214
global_step: 12046, epoch: 102, loss: 0.273008
global_step: 12047, epoch: 102, loss: 0.288833
global_step: 12048, epoch: 102, loss: 0.376136
global_step: 12049, epoch: 102, loss: 0.333246
global_step: 12050, epoch: 102, loss: 0.318969
global_step: 12051, epoch: 102, loss: 0.270037
global_step: 12052, epoch: 102, loss: 0.352544
global_step: 12053, epoch: 102, loss: 0.309847
global_step: 12054, epoch: 102, loss: 0.304690
global_step: 12055, epoch: 102, loss: 0.346138
global_step: 12056, epoch: 102, loss: 0.308575
global_step: 12057, epoch: 102, loss: 0.293732
global_step: 12058, epoch: 102, loss: 0.289886
global_step: 12059, epoch: 102, loss: 0.396087
global_step: 12060, epoch: 102, loss: 0.325178
global_step: 12061, epoch: 102, loss: 0.302111
global_step: 12062, epoch: 102, loss: 0.356916
global_step: 12063, epoch: 102, loss: 0.276104
global_step: 12064, epoch: 102, loss: 0.271995
global_step: 12065, epoch: 102, loss: 0.286900
global_step: 12066, epoch: 102, loss: 0.322796
global_step: 12067, epoch: 102, loss: 0.346787
global_step: 12068, epoch: 102, loss: 0.326596
global_step: 12069, epoch: 102, loss: 0.353957
global_step: 12070, epoch: 102, loss: 0.369424
global_step: 12071, epoch: 102, loss: 0.269283
global_step: 12072, epoch: 102, loss: 0.338198
global_step: 12073, epoch: 102, loss: 0.352337
global_step: 12074, epoch: 102, loss: 0.295690
global_step: 12075, epoch: 102, loss: 0.297129
global_step: 12076, epoch: 102, loss: 0.372761
global_step: 12077, epoch: 102, loss: 0.304870
global_step: 12078, epoch: 102, loss: 0.344398
global_step: 12079, epoch: 102, loss: 0.282539
global_step: 12080, epoch: 102, loss: 0.256842
epoch: 102
train	acc: 0.9583	macro: p 0.9642, r 0.9296, f1: 0.9455	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9582
dev	acc: 0.5446	macro: p 0.3866, r 0.3223, f1: 0.3217	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5042
test	acc: 0.5824	macro: p 0.3587, r 0.3225, f1: 0.3254	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5476
global_step: 12081, epoch: 103, loss: 0.309857
global_step: 12082, epoch: 103, loss: 0.355807
global_step: 12083, epoch: 103, loss: 0.351143
global_step: 12084, epoch: 103, loss: 0.384842
global_step: 12085, epoch: 103, loss: 0.307449
global_step: 12086, epoch: 103, loss: 0.288517
global_step: 12087, epoch: 103, loss: 0.319527
global_step: 12088, epoch: 103, loss: 0.326352
global_step: 12089, epoch: 103, loss: 0.331440
global_step: 12090, epoch: 103, loss: 0.387663
global_step: 12091, epoch: 103, loss: 0.279298
global_step: 12092, epoch: 103, loss: 0.321971
global_step: 12093, epoch: 103, loss: 0.322777
global_step: 12094, epoch: 103, loss: 0.307822
global_step: 12095, epoch: 103, loss: 0.329024
global_step: 12096, epoch: 103, loss: 0.365808
global_step: 12097, epoch: 103, loss: 0.317982
global_step: 12098, epoch: 103, loss: 0.315972
global_step: 12099, epoch: 103, loss: 0.320311
global_step: 12100, epoch: 103, loss: 0.335201
global_step: 12101, epoch: 103, loss: 0.390242
global_step: 12102, epoch: 103, loss: 0.334411
global_step: 12103, epoch: 103, loss: 0.376096
global_step: 12104, epoch: 103, loss: 0.286036
global_step: 12105, epoch: 103, loss: 0.413065
global_step: 12106, epoch: 103, loss: 0.312029
global_step: 12107, epoch: 103, loss: 0.322848
global_step: 12108, epoch: 103, loss: 0.375726
global_step: 12109, epoch: 103, loss: 0.245174
global_step: 12110, epoch: 103, loss: 0.305539
global_step: 12111, epoch: 103, loss: 0.389100
global_step: 12112, epoch: 103, loss: 0.376803
global_step: 12113, epoch: 103, loss: 0.369984
global_step: 12114, epoch: 103, loss: 0.287849
global_step: 12115, epoch: 103, loss: 0.363516
global_step: 12116, epoch: 103, loss: 0.325005
global_step: 12117, epoch: 103, loss: 0.356497
global_step: 12118, epoch: 103, loss: 0.269816
global_step: 12119, epoch: 103, loss: 0.357652
global_step: 12120, epoch: 103, loss: 0.133402
epoch: 103
train	acc: 0.9596	macro: p 0.9644, r 0.9331, f1: 0.9476	micro: p 0.9596, r 0.9596, f1 0.9596	weighted_f1:0.9595
dev	acc: 0.5582	macro: p 0.4044, r 0.3261, f1: 0.3228	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5107
test	acc: 0.5828	macro: p 0.3593, r 0.3177, f1: 0.3199	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5439
global_step: 12121, epoch: 104, loss: 0.304834
global_step: 12122, epoch: 104, loss: 0.275236
global_step: 12123, epoch: 104, loss: 0.292407
global_step: 12124, epoch: 104, loss: 0.302494
global_step: 12125, epoch: 104, loss: 0.442143
global_step: 12126, epoch: 104, loss: 0.295082
global_step: 12127, epoch: 104, loss: 0.259499
global_step: 12128, epoch: 104, loss: 0.353208
global_step: 12129, epoch: 104, loss: 0.298486
global_step: 12130, epoch: 104, loss: 0.393574
global_step: 12131, epoch: 104, loss: 0.303139
global_step: 12132, epoch: 104, loss: 0.297070
global_step: 12133, epoch: 104, loss: 0.413896
global_step: 12134, epoch: 104, loss: 0.281341
global_step: 12135, epoch: 104, loss: 0.265214
global_step: 12136, epoch: 104, loss: 0.339723
global_step: 12137, epoch: 104, loss: 0.267266
global_step: 12138, epoch: 104, loss: 0.343846
global_step: 12139, epoch: 104, loss: 0.357213
global_step: 12140, epoch: 104, loss: 0.333312
global_step: 12141, epoch: 104, loss: 0.339274
global_step: 12142, epoch: 104, loss: 0.360384
global_step: 12143, epoch: 104, loss: 0.252540
global_step: 12144, epoch: 104, loss: 0.349984
global_step: 12145, epoch: 104, loss: 0.332976
global_step: 12146, epoch: 104, loss: 0.353209
global_step: 12147, epoch: 104, loss: 0.306228
global_step: 12148, epoch: 104, loss: 0.407873
global_step: 12149, epoch: 104, loss: 0.378200
global_step: 12150, epoch: 104, loss: 0.301039
global_step: 12151, epoch: 104, loss: 0.273641
global_step: 12152, epoch: 104, loss: 0.292358
global_step: 12153, epoch: 104, loss: 0.380950
global_step: 12154, epoch: 104, loss: 0.365778
global_step: 12155, epoch: 104, loss: 0.275223
global_step: 12156, epoch: 104, loss: 0.329271
global_step: 12157, epoch: 104, loss: 0.333290
global_step: 12158, epoch: 104, loss: 0.428160
global_step: 12159, epoch: 104, loss: 0.364890
global_step: 12160, epoch: 104, loss: 0.600558
epoch: 104
train	acc: 0.9614	macro: p 0.9666, r 0.9396, f1: 0.9523	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9614
dev	acc: 0.5482	macro: p 0.3940, r 0.3270, f1: 0.3241	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5094
test	acc: 0.5693	macro: p 0.3512, r 0.3154, f1: 0.3187	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5398
global_step: 12161, epoch: 105, loss: 0.358318
global_step: 12162, epoch: 105, loss: 0.364773
global_step: 12163, epoch: 105, loss: 0.309160
global_step: 12164, epoch: 105, loss: 0.256023
global_step: 12165, epoch: 105, loss: 0.345367
global_step: 12166, epoch: 105, loss: 0.292880
global_step: 12167, epoch: 105, loss: 0.331757
global_step: 12168, epoch: 105, loss: 0.302567
global_step: 12169, epoch: 105, loss: 0.285154
global_step: 12170, epoch: 105, loss: 0.326890
global_step: 12171, epoch: 105, loss: 0.340189
global_step: 12172, epoch: 105, loss: 0.332420
global_step: 12173, epoch: 105, loss: 0.347462
global_step: 12174, epoch: 105, loss: 0.319747
global_step: 12175, epoch: 105, loss: 0.368365
global_step: 12176, epoch: 105, loss: 0.273189
global_step: 12177, epoch: 105, loss: 0.313773
global_step: 12178, epoch: 105, loss: 0.298403
global_step: 12179, epoch: 105, loss: 0.337681
global_step: 12180, epoch: 105, loss: 0.340247
global_step: 12181, epoch: 105, loss: 0.311768
global_step: 12182, epoch: 105, loss: 0.387690
global_step: 12183, epoch: 105, loss: 0.325765
global_step: 12184, epoch: 105, loss: 0.311039
global_step: 12185, epoch: 105, loss: 0.300494
global_step: 12186, epoch: 105, loss: 0.316865
global_step: 12187, epoch: 105, loss: 0.290523
global_step: 12188, epoch: 105, loss: 0.260239
global_step: 12189, epoch: 105, loss: 0.257618
global_step: 12190, epoch: 105, loss: 0.290915
global_step: 12191, epoch: 105, loss: 0.365317
global_step: 12192, epoch: 105, loss: 0.329881
global_step: 12193, epoch: 105, loss: 0.273398
global_step: 12194, epoch: 105, loss: 0.341980
global_step: 12195, epoch: 105, loss: 0.293687
global_step: 12196, epoch: 105, loss: 0.319664
global_step: 12197, epoch: 105, loss: 0.268582
global_step: 12198, epoch: 105, loss: 0.333569
global_step: 12199, epoch: 105, loss: 0.295157
global_step: 12200, epoch: 105, loss: 0.166152
epoch: 105
train	acc: 0.9620	macro: p 0.9657, r 0.9418, f1: 0.9530	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9620
dev	acc: 0.5509	macro: p 0.3881, r 0.3302, f1: 0.3297	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5138
test	acc: 0.5755	macro: p 0.3813, r 0.3278, f1: 0.3344	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5463
global_step: 12201, epoch: 106, loss: 0.326550
global_step: 12202, epoch: 106, loss: 0.259081
global_step: 12203, epoch: 106, loss: 0.288935
global_step: 12204, epoch: 106, loss: 0.364005
global_step: 12205, epoch: 106, loss: 0.301950
global_step: 12206, epoch: 106, loss: 0.303469
global_step: 12207, epoch: 106, loss: 0.322119
global_step: 12208, epoch: 106, loss: 0.293971
global_step: 12209, epoch: 106, loss: 0.347680
global_step: 12210, epoch: 106, loss: 0.251518
global_step: 12211, epoch: 106, loss: 0.353159
global_step: 12212, epoch: 106, loss: 0.287893
global_step: 12213, epoch: 106, loss: 0.320970
global_step: 12214, epoch: 106, loss: 0.267781
global_step: 12215, epoch: 106, loss: 0.343264
global_step: 12216, epoch: 106, loss: 0.332723
global_step: 12217, epoch: 106, loss: 0.339164
global_step: 12218, epoch: 106, loss: 0.307416
global_step: 12219, epoch: 106, loss: 0.316354
global_step: 12220, epoch: 106, loss: 0.314883
global_step: 12221, epoch: 106, loss: 0.330283
global_step: 12222, epoch: 106, loss: 0.293931
global_step: 12223, epoch: 106, loss: 0.297374
global_step: 12224, epoch: 106, loss: 0.352014
global_step: 12225, epoch: 106, loss: 0.284612
global_step: 12226, epoch: 106, loss: 0.297932
global_step: 12227, epoch: 106, loss: 0.350341
global_step: 12228, epoch: 106, loss: 0.395070
global_step: 12229, epoch: 106, loss: 0.297259
global_step: 12230, epoch: 106, loss: 0.368297
global_step: 12231, epoch: 106, loss: 0.245120
global_step: 12232, epoch: 106, loss: 0.290734
global_step: 12233, epoch: 106, loss: 0.325079
global_step: 12234, epoch: 106, loss: 0.317901
global_step: 12235, epoch: 106, loss: 0.349416
global_step: 12236, epoch: 106, loss: 0.308286
global_step: 12237, epoch: 106, loss: 0.375805
global_step: 12238, epoch: 106, loss: 0.380514
global_step: 12239, epoch: 106, loss: 0.311363
global_step: 12240, epoch: 106, loss: 0.198883
epoch: 106
train	acc: 0.9618	macro: p 0.9655, r 0.9410, f1: 0.9525	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9618
dev	acc: 0.5491	macro: p 0.3673, r 0.3249, f1: 0.3261	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5105
test	acc: 0.5912	macro: p 0.3655, r 0.3259, f1: 0.3318	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5572
global_step: 12241, epoch: 107, loss: 0.312518
global_step: 12242, epoch: 107, loss: 0.324301
global_step: 12243, epoch: 107, loss: 0.263909
global_step: 12244, epoch: 107, loss: 0.364460
global_step: 12245, epoch: 107, loss: 0.279493
global_step: 12246, epoch: 107, loss: 0.296661
global_step: 12247, epoch: 107, loss: 0.302216
global_step: 12248, epoch: 107, loss: 0.284020
global_step: 12249, epoch: 107, loss: 0.259017
global_step: 12250, epoch: 107, loss: 0.314890
global_step: 12251, epoch: 107, loss: 0.291980
global_step: 12252, epoch: 107, loss: 0.368433
global_step: 12253, epoch: 107, loss: 0.280275
global_step: 12254, epoch: 107, loss: 0.253506
global_step: 12255, epoch: 107, loss: 0.271853
global_step: 12256, epoch: 107, loss: 0.266112
global_step: 12257, epoch: 107, loss: 0.341494
global_step: 12258, epoch: 107, loss: 0.354891
global_step: 12259, epoch: 107, loss: 0.266421
global_step: 12260, epoch: 107, loss: 0.331198
global_step: 12261, epoch: 107, loss: 0.290867
global_step: 12262, epoch: 107, loss: 0.367095
global_step: 12263, epoch: 107, loss: 0.367233
global_step: 12264, epoch: 107, loss: 0.350103
global_step: 12265, epoch: 107, loss: 0.266600
global_step: 12266, epoch: 107, loss: 0.211612
global_step: 12267, epoch: 107, loss: 0.339062
global_step: 12268, epoch: 107, loss: 0.350533
global_step: 12269, epoch: 107, loss: 0.307523
global_step: 12270, epoch: 107, loss: 0.289038
global_step: 12271, epoch: 107, loss: 0.311142
global_step: 12272, epoch: 107, loss: 0.376859
global_step: 12273, epoch: 107, loss: 0.267524
global_step: 12274, epoch: 107, loss: 0.347549
global_step: 12275, epoch: 107, loss: 0.365206
global_step: 12276, epoch: 107, loss: 0.263134
global_step: 12277, epoch: 107, loss: 0.281359
global_step: 12278, epoch: 107, loss: 0.330136
global_step: 12279, epoch: 107, loss: 0.251159
global_step: 12280, epoch: 107, loss: 0.035315
epoch: 107
train	acc: 0.9606	macro: p 0.9676, r 0.9363, f1: 0.9511	micro: p 0.9606, r 0.9606, f1 0.9606	weighted_f1:0.9605
dev	acc: 0.5491	macro: p 0.3649, r 0.3188, f1: 0.3162	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5047
test	acc: 0.5870	macro: p 0.3846, r 0.3247, f1: 0.3338	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5522
global_step: 12281, epoch: 108, loss: 0.312892
global_step: 12282, epoch: 108, loss: 0.249521
global_step: 12283, epoch: 108, loss: 0.272794
global_step: 12284, epoch: 108, loss: 0.316754
global_step: 12285, epoch: 108, loss: 0.339995
global_step: 12286, epoch: 108, loss: 0.278923
global_step: 12287, epoch: 108, loss: 0.306590
global_step: 12288, epoch: 108, loss: 0.326245
global_step: 12289, epoch: 108, loss: 0.308312
global_step: 12290, epoch: 108, loss: 0.304658
global_step: 12291, epoch: 108, loss: 0.373060
global_step: 12292, epoch: 108, loss: 0.323676
global_step: 12293, epoch: 108, loss: 0.370549
global_step: 12294, epoch: 108, loss: 0.274656
global_step: 12295, epoch: 108, loss: 0.302214
global_step: 12296, epoch: 108, loss: 0.361784
global_step: 12297, epoch: 108, loss: 0.294659
global_step: 12298, epoch: 108, loss: 0.367383
global_step: 12299, epoch: 108, loss: 0.307719
global_step: 12300, epoch: 108, loss: 0.301495
global_step: 12301, epoch: 108, loss: 0.274061
global_step: 12302, epoch: 108, loss: 0.370383
global_step: 12303, epoch: 108, loss: 0.270338
global_step: 12304, epoch: 108, loss: 0.316048
global_step: 12305, epoch: 108, loss: 0.286069
global_step: 12306, epoch: 108, loss: 0.296404
global_step: 12307, epoch: 108, loss: 0.313016
global_step: 12308, epoch: 108, loss: 0.337180
global_step: 12309, epoch: 108, loss: 0.373549
global_step: 12310, epoch: 108, loss: 0.317217
global_step: 12311, epoch: 108, loss: 0.254213
global_step: 12312, epoch: 108, loss: 0.213193
global_step: 12313, epoch: 108, loss: 0.238720
global_step: 12314, epoch: 108, loss: 0.310574
global_step: 12315, epoch: 108, loss: 0.281769
global_step: 12316, epoch: 108, loss: 0.358372
global_step: 12317, epoch: 108, loss: 0.299937
global_step: 12318, epoch: 108, loss: 0.278644
global_step: 12319, epoch: 108, loss: 0.393828
global_step: 12320, epoch: 108, loss: 0.191143
epoch: 108
train	acc: 0.9612	macro: p 0.9648, r 0.9367, f1: 0.9496	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9612
dev	acc: 0.5428	macro: p 0.3743, r 0.3214, f1: 0.3185	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5043
test	acc: 0.5785	macro: p 0.3538, r 0.3235, f1: 0.3247	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5470
global_step: 12321, epoch: 109, loss: 0.258770
global_step: 12322, epoch: 109, loss: 0.240028
global_step: 12323, epoch: 109, loss: 0.270988
global_step: 12324, epoch: 109, loss: 0.269785
global_step: 12325, epoch: 109, loss: 0.312128
global_step: 12326, epoch: 109, loss: 0.266716
global_step: 12327, epoch: 109, loss: 0.277393
global_step: 12328, epoch: 109, loss: 0.273180
global_step: 12329, epoch: 109, loss: 0.296937
global_step: 12330, epoch: 109, loss: 0.326391
global_step: 12331, epoch: 109, loss: 0.294066
global_step: 12332, epoch: 109, loss: 0.348886
global_step: 12333, epoch: 109, loss: 0.244144
global_step: 12334, epoch: 109, loss: 0.312271
global_step: 12335, epoch: 109, loss: 0.328331
global_step: 12336, epoch: 109, loss: 0.303501
global_step: 12337, epoch: 109, loss: 0.362383
global_step: 12338, epoch: 109, loss: 0.356286
global_step: 12339, epoch: 109, loss: 0.267270
global_step: 12340, epoch: 109, loss: 0.281615
global_step: 12341, epoch: 109, loss: 0.289530
global_step: 12342, epoch: 109, loss: 0.279869
global_step: 12343, epoch: 109, loss: 0.277828
global_step: 12344, epoch: 109, loss: 0.299860
global_step: 12345, epoch: 109, loss: 0.294012
global_step: 12346, epoch: 109, loss: 0.187742
global_step: 12347, epoch: 109, loss: 0.326288
global_step: 12348, epoch: 109, loss: 0.398694
global_step: 12349, epoch: 109, loss: 0.327845
global_step: 12350, epoch: 109, loss: 0.299676
global_step: 12351, epoch: 109, loss: 0.355192
global_step: 12352, epoch: 109, loss: 0.336883
global_step: 12353, epoch: 109, loss: 0.295952
global_step: 12354, epoch: 109, loss: 0.312830
global_step: 12355, epoch: 109, loss: 0.273544
global_step: 12356, epoch: 109, loss: 0.334547
global_step: 12357, epoch: 109, loss: 0.402181
global_step: 12358, epoch: 109, loss: 0.286371
global_step: 12359, epoch: 109, loss: 0.279851
global_step: 12360, epoch: 109, loss: 0.177689
epoch: 109
train	acc: 0.9618	macro: p 0.9666, r 0.9377, f1: 0.9512	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9618
dev	acc: 0.5392	macro: p 0.3720, r 0.3162, f1: 0.3114	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4973
test	acc: 0.5770	macro: p 0.3541, r 0.3217, f1: 0.3221	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5441
global_step: 12361, epoch: 110, loss: 0.288795
global_step: 12362, epoch: 110, loss: 0.263901
global_step: 12363, epoch: 110, loss: 0.247276
global_step: 12364, epoch: 110, loss: 0.268940
global_step: 12365, epoch: 110, loss: 0.350869
global_step: 12366, epoch: 110, loss: 0.245104
global_step: 12367, epoch: 110, loss: 0.253788
global_step: 12368, epoch: 110, loss: 0.328687
global_step: 12369, epoch: 110, loss: 0.356414
global_step: 12370, epoch: 110, loss: 0.294716
global_step: 12371, epoch: 110, loss: 0.265653
global_step: 12372, epoch: 110, loss: 0.249784
global_step: 12373, epoch: 110, loss: 0.295221
global_step: 12374, epoch: 110, loss: 0.277437
global_step: 12375, epoch: 110, loss: 0.307513
global_step: 12376, epoch: 110, loss: 0.289388
global_step: 12377, epoch: 110, loss: 0.321179
global_step: 12378, epoch: 110, loss: 0.265171
global_step: 12379, epoch: 110, loss: 0.279443
global_step: 12380, epoch: 110, loss: 0.364791
global_step: 12381, epoch: 110, loss: 0.264398
global_step: 12382, epoch: 110, loss: 0.373605
global_step: 12383, epoch: 110, loss: 0.259070
global_step: 12384, epoch: 110, loss: 0.267665
global_step: 12385, epoch: 110, loss: 0.356895
global_step: 12386, epoch: 110, loss: 0.273598
global_step: 12387, epoch: 110, loss: 0.350415
global_step: 12388, epoch: 110, loss: 0.343647
global_step: 12389, epoch: 110, loss: 0.295997
global_step: 12390, epoch: 110, loss: 0.370531
global_step: 12391, epoch: 110, loss: 0.283095
global_step: 12392, epoch: 110, loss: 0.346348
global_step: 12393, epoch: 110, loss: 0.362725
global_step: 12394, epoch: 110, loss: 0.363057
global_step: 12395, epoch: 110, loss: 0.283179
global_step: 12396, epoch: 110, loss: 0.279866
global_step: 12397, epoch: 110, loss: 0.279484
global_step: 12398, epoch: 110, loss: 0.316548
global_step: 12399, epoch: 110, loss: 0.310302
global_step: 12400, epoch: 110, loss: 0.057524
epoch: 110
train	acc: 0.9620	macro: p 0.9667, r 0.9404, f1: 0.9528	micro: p 0.9620, r 0.9620, f1 0.9620	weighted_f1:0.9620
dev	acc: 0.5329	macro: p 0.3622, r 0.3152, f1: 0.3127	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4958
test	acc: 0.5778	macro: p 0.4029, r 0.3269, f1: 0.3374	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5491
global_step: 12401, epoch: 111, loss: 0.282942
global_step: 12402, epoch: 111, loss: 0.258938
global_step: 12403, epoch: 111, loss: 0.338165
global_step: 12404, epoch: 111, loss: 0.269746
global_step: 12405, epoch: 111, loss: 0.310799
global_step: 12406, epoch: 111, loss: 0.275527
global_step: 12407, epoch: 111, loss: 0.277846
global_step: 12408, epoch: 111, loss: 0.231969
global_step: 12409, epoch: 111, loss: 0.373530
global_step: 12410, epoch: 111, loss: 0.333816
global_step: 12411, epoch: 111, loss: 0.341385
global_step: 12412, epoch: 111, loss: 0.346618
global_step: 12413, epoch: 111, loss: 0.280840
global_step: 12414, epoch: 111, loss: 0.320370
global_step: 12415, epoch: 111, loss: 0.318010
global_step: 12416, epoch: 111, loss: 0.234001
global_step: 12417, epoch: 111, loss: 0.332534
global_step: 12418, epoch: 111, loss: 0.231647
global_step: 12419, epoch: 111, loss: 0.275445
global_step: 12420, epoch: 111, loss: 0.315404
global_step: 12421, epoch: 111, loss: 0.299095
global_step: 12422, epoch: 111, loss: 0.297300
global_step: 12423, epoch: 111, loss: 0.277202
global_step: 12424, epoch: 111, loss: 0.322955
global_step: 12425, epoch: 111, loss: 0.329113
global_step: 12426, epoch: 111, loss: 0.266335
global_step: 12427, epoch: 111, loss: 0.311206
global_step: 12428, epoch: 111, loss: 0.235375
global_step: 12429, epoch: 111, loss: 0.247918
global_step: 12430, epoch: 111, loss: 0.304841
global_step: 12431, epoch: 111, loss: 0.275644
global_step: 12432, epoch: 111, loss: 0.297557
global_step: 12433, epoch: 111, loss: 0.334181
global_step: 12434, epoch: 111, loss: 0.309623
global_step: 12435, epoch: 111, loss: 0.283752
global_step: 12436, epoch: 111, loss: 0.335670
global_step: 12437, epoch: 111, loss: 0.291480
global_step: 12438, epoch: 111, loss: 0.251033
global_step: 12439, epoch: 111, loss: 0.273366
global_step: 12440, epoch: 111, loss: 0.662581
epoch: 111
train	acc: 0.9614	macro: p 0.9667, r 0.9380, f1: 0.9513	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9613
dev	acc: 0.5437	macro: p 0.3781, r 0.3163, f1: 0.3165	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5010
test	acc: 0.5874	macro: p 0.3830, r 0.3244, f1: 0.3316	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5506
global_step: 12441, epoch: 112, loss: 0.284858
global_step: 12442, epoch: 112, loss: 0.326195
global_step: 12443, epoch: 112, loss: 0.304180
global_step: 12444, epoch: 112, loss: 0.272689
global_step: 12445, epoch: 112, loss: 0.333323
global_step: 12446, epoch: 112, loss: 0.345838
global_step: 12447, epoch: 112, loss: 0.271796
global_step: 12448, epoch: 112, loss: 0.217199
global_step: 12449, epoch: 112, loss: 0.242929
global_step: 12450, epoch: 112, loss: 0.313790
global_step: 12451, epoch: 112, loss: 0.331914
global_step: 12452, epoch: 112, loss: 0.329059
global_step: 12453, epoch: 112, loss: 0.290712
global_step: 12454, epoch: 112, loss: 0.273449
global_step: 12455, epoch: 112, loss: 0.309411
global_step: 12456, epoch: 112, loss: 0.289219
global_step: 12457, epoch: 112, loss: 0.336084
global_step: 12458, epoch: 112, loss: 0.287034
global_step: 12459, epoch: 112, loss: 0.350783
global_step: 12460, epoch: 112, loss: 0.343942
global_step: 12461, epoch: 112, loss: 0.306384
global_step: 12462, epoch: 112, loss: 0.309047
global_step: 12463, epoch: 112, loss: 0.259641
global_step: 12464, epoch: 112, loss: 0.304374
global_step: 12465, epoch: 112, loss: 0.335108
global_step: 12466, epoch: 112, loss: 0.244826
global_step: 12467, epoch: 112, loss: 0.305304
global_step: 12468, epoch: 112, loss: 0.373679
global_step: 12469, epoch: 112, loss: 0.243294
global_step: 12470, epoch: 112, loss: 0.246526
global_step: 12471, epoch: 112, loss: 0.307049
global_step: 12472, epoch: 112, loss: 0.262189
global_step: 12473, epoch: 112, loss: 0.282705
global_step: 12474, epoch: 112, loss: 0.346230
global_step: 12475, epoch: 112, loss: 0.257625
global_step: 12476, epoch: 112, loss: 0.427079
global_step: 12477, epoch: 112, loss: 0.419928
global_step: 12478, epoch: 112, loss: 0.251910
global_step: 12479, epoch: 112, loss: 0.240718
global_step: 12480, epoch: 112, loss: 0.017543
epoch: 112
train	acc: 0.9628	macro: p 0.9679, r 0.9425, f1: 0.9544	micro: p 0.9628, r 0.9628, f1 0.9628	weighted_f1:0.9628
dev	acc: 0.5365	macro: p 0.3709, r 0.3132, f1: 0.3095	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4952
test	acc: 0.5805	macro: p 0.3785, r 0.3228, f1: 0.3274	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5467
global_step: 12481, epoch: 113, loss: 0.368183
global_step: 12482, epoch: 113, loss: 0.279613
global_step: 12483, epoch: 113, loss: 0.268894
global_step: 12484, epoch: 113, loss: 0.310302
global_step: 12485, epoch: 113, loss: 0.394767
global_step: 12486, epoch: 113, loss: 0.228358
global_step: 12487, epoch: 113, loss: 0.285381
global_step: 12488, epoch: 113, loss: 0.318077
global_step: 12489, epoch: 113, loss: 0.315166
global_step: 12490, epoch: 113, loss: 0.377319
global_step: 12491, epoch: 113, loss: 0.298178
global_step: 12492, epoch: 113, loss: 0.285486
global_step: 12493, epoch: 113, loss: 0.307087
global_step: 12494, epoch: 113, loss: 0.297857
global_step: 12495, epoch: 113, loss: 0.294384
global_step: 12496, epoch: 113, loss: 0.255511
global_step: 12497, epoch: 113, loss: 0.372909
global_step: 12498, epoch: 113, loss: 0.288299
global_step: 12499, epoch: 113, loss: 0.277726
global_step: 12500, epoch: 113, loss: 0.216015
global_step: 12501, epoch: 113, loss: 0.277027
global_step: 12502, epoch: 113, loss: 0.294390
global_step: 12503, epoch: 113, loss: 0.266893
global_step: 12504, epoch: 113, loss: 0.350230
global_step: 12505, epoch: 113, loss: 0.308024
global_step: 12506, epoch: 113, loss: 0.303178
global_step: 12507, epoch: 113, loss: 0.281013
global_step: 12508, epoch: 113, loss: 0.314931
global_step: 12509, epoch: 113, loss: 0.258774
global_step: 12510, epoch: 113, loss: 0.310261
global_step: 12511, epoch: 113, loss: 0.283854
global_step: 12512, epoch: 113, loss: 0.293099
global_step: 12513, epoch: 113, loss: 0.209661
global_step: 12514, epoch: 113, loss: 0.363678
global_step: 12515, epoch: 113, loss: 0.283686
global_step: 12516, epoch: 113, loss: 0.243345
global_step: 12517, epoch: 113, loss: 0.307253
global_step: 12518, epoch: 113, loss: 0.282864
global_step: 12519, epoch: 113, loss: 0.376566
global_step: 12520, epoch: 113, loss: 0.309347
epoch: 113
train	acc: 0.9642	macro: p 0.9669, r 0.9455, f1: 0.9557	micro: p 0.9642, r 0.9642, f1 0.9642	weighted_f1:0.9642
dev	acc: 0.5428	macro: p 0.3718, r 0.3186, f1: 0.3191	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5034
test	acc: 0.5858	macro: p 0.3863, r 0.3263, f1: 0.3343	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5530
global_step: 12521, epoch: 114, loss: 0.299643
global_step: 12522, epoch: 114, loss: 0.295079
global_step: 12523, epoch: 114, loss: 0.306303
global_step: 12524, epoch: 114, loss: 0.313173
global_step: 12525, epoch: 114, loss: 0.289982
global_step: 12526, epoch: 114, loss: 0.270474
global_step: 12527, epoch: 114, loss: 0.239891
global_step: 12528, epoch: 114, loss: 0.272026
global_step: 12529, epoch: 114, loss: 0.371270
global_step: 12530, epoch: 114, loss: 0.301530
global_step: 12531, epoch: 114, loss: 0.319589
global_step: 12532, epoch: 114, loss: 0.279171
global_step: 12533, epoch: 114, loss: 0.340888
global_step: 12534, epoch: 114, loss: 0.353352
global_step: 12535, epoch: 114, loss: 0.313269
global_step: 12536, epoch: 114, loss: 0.249959
global_step: 12537, epoch: 114, loss: 0.332534
global_step: 12538, epoch: 114, loss: 0.406999
global_step: 12539, epoch: 114, loss: 0.278570
global_step: 12540, epoch: 114, loss: 0.296109
global_step: 12541, epoch: 114, loss: 0.307447
global_step: 12542, epoch: 114, loss: 0.396805
global_step: 12543, epoch: 114, loss: 0.216275
global_step: 12544, epoch: 114, loss: 0.350846
global_step: 12545, epoch: 114, loss: 0.314195
global_step: 12546, epoch: 114, loss: 0.311123
global_step: 12547, epoch: 114, loss: 0.398266
global_step: 12548, epoch: 114, loss: 0.370920
global_step: 12549, epoch: 114, loss: 0.291232
global_step: 12550, epoch: 114, loss: 0.269077
global_step: 12551, epoch: 114, loss: 0.369349
global_step: 12552, epoch: 114, loss: 0.268070
global_step: 12553, epoch: 114, loss: 0.319571
global_step: 12554, epoch: 114, loss: 0.304022
global_step: 12555, epoch: 114, loss: 0.285741
global_step: 12556, epoch: 114, loss: 0.226711
global_step: 12557, epoch: 114, loss: 0.267923
global_step: 12558, epoch: 114, loss: 0.270461
global_step: 12559, epoch: 114, loss: 0.324478
global_step: 12560, epoch: 114, loss: 0.280778
epoch: 114
train	acc: 0.9626	macro: p 0.9675, r 0.9419, f1: 0.9540	micro: p 0.9626, r 0.9626, f1 0.9626	weighted_f1:0.9625
dev	acc: 0.5383	macro: p 0.3922, r 0.3091, f1: 0.3075	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4934
test	acc: 0.5885	macro: p 0.3720, r 0.3211, f1: 0.3285	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5532
global_step: 12561, epoch: 115, loss: 0.282194
global_step: 12562, epoch: 115, loss: 0.274670
global_step: 12563, epoch: 115, loss: 0.256240
global_step: 12564, epoch: 115, loss: 0.304503
global_step: 12565, epoch: 115, loss: 0.267477
global_step: 12566, epoch: 115, loss: 0.200926
global_step: 12567, epoch: 115, loss: 0.225207
global_step: 12568, epoch: 115, loss: 0.290568
global_step: 12569, epoch: 115, loss: 0.357628
global_step: 12570, epoch: 115, loss: 0.310810
global_step: 12571, epoch: 115, loss: 0.299614
global_step: 12572, epoch: 115, loss: 0.310181
global_step: 12573, epoch: 115, loss: 0.283075
global_step: 12574, epoch: 115, loss: 0.292830
global_step: 12575, epoch: 115, loss: 0.339520
global_step: 12576, epoch: 115, loss: 0.278894
global_step: 12577, epoch: 115, loss: 0.367927
global_step: 12578, epoch: 115, loss: 0.274826
global_step: 12579, epoch: 115, loss: 0.259300
global_step: 12580, epoch: 115, loss: 0.278131
global_step: 12581, epoch: 115, loss: 0.269353
global_step: 12582, epoch: 115, loss: 0.284489
global_step: 12583, epoch: 115, loss: 0.225508
global_step: 12584, epoch: 115, loss: 0.294508
global_step: 12585, epoch: 115, loss: 0.238505
global_step: 12586, epoch: 115, loss: 0.292074
global_step: 12587, epoch: 115, loss: 0.404839
global_step: 12588, epoch: 115, loss: 0.325075
global_step: 12589, epoch: 115, loss: 0.338046
global_step: 12590, epoch: 115, loss: 0.223560
global_step: 12591, epoch: 115, loss: 0.293861
global_step: 12592, epoch: 115, loss: 0.227614
global_step: 12593, epoch: 115, loss: 0.266945
global_step: 12594, epoch: 115, loss: 0.284029
global_step: 12595, epoch: 115, loss: 0.274448
global_step: 12596, epoch: 115, loss: 0.320245
global_step: 12597, epoch: 115, loss: 0.368358
global_step: 12598, epoch: 115, loss: 0.260723
global_step: 12599, epoch: 115, loss: 0.358215
global_step: 12600, epoch: 115, loss: 0.195672
epoch: 115
train	acc: 0.9625	macro: p 0.9678, r 0.9403, f1: 0.9531	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9625
dev	acc: 0.5419	macro: p 0.4042, r 0.3123, f1: 0.3099	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4958
test	acc: 0.5912	macro: p 0.3834, r 0.3203, f1: 0.3262	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5513
global_step: 12601, epoch: 116, loss: 0.234038
global_step: 12602, epoch: 116, loss: 0.292382
global_step: 12603, epoch: 116, loss: 0.256083
global_step: 12604, epoch: 116, loss: 0.246875
global_step: 12605, epoch: 116, loss: 0.284855
global_step: 12606, epoch: 116, loss: 0.325889
global_step: 12607, epoch: 116, loss: 0.251681
global_step: 12608, epoch: 116, loss: 0.291858
global_step: 12609, epoch: 116, loss: 0.301744
global_step: 12610, epoch: 116, loss: 0.289822
global_step: 12611, epoch: 116, loss: 0.334543
global_step: 12612, epoch: 116, loss: 0.348044
global_step: 12613, epoch: 116, loss: 0.219608
global_step: 12614, epoch: 116, loss: 0.280237
global_step: 12615, epoch: 116, loss: 0.314754
global_step: 12616, epoch: 116, loss: 0.323488
global_step: 12617, epoch: 116, loss: 0.264896
global_step: 12618, epoch: 116, loss: 0.278883
global_step: 12619, epoch: 116, loss: 0.342287
global_step: 12620, epoch: 116, loss: 0.383198
global_step: 12621, epoch: 116, loss: 0.296082
global_step: 12622, epoch: 116, loss: 0.282227
global_step: 12623, epoch: 116, loss: 0.263213
global_step: 12624, epoch: 116, loss: 0.287744
global_step: 12625, epoch: 116, loss: 0.262030
global_step: 12626, epoch: 116, loss: 0.356566
global_step: 12627, epoch: 116, loss: 0.271165
global_step: 12628, epoch: 116, loss: 0.210938
global_step: 12629, epoch: 116, loss: 0.281271
global_step: 12630, epoch: 116, loss: 0.262986
global_step: 12631, epoch: 116, loss: 0.244097
global_step: 12632, epoch: 116, loss: 0.263489
global_step: 12633, epoch: 116, loss: 0.351333
global_step: 12634, epoch: 116, loss: 0.268957
global_step: 12635, epoch: 116, loss: 0.243811
global_step: 12636, epoch: 116, loss: 0.291458
global_step: 12637, epoch: 116, loss: 0.330687
global_step: 12638, epoch: 116, loss: 0.276569
global_step: 12639, epoch: 116, loss: 0.246591
global_step: 12640, epoch: 116, loss: 0.014937
epoch: 116
train	acc: 0.9634	macro: p 0.9685, r 0.9439, f1: 0.9555	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9634
dev	acc: 0.5374	macro: p 0.3957, r 0.3121, f1: 0.3098	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4952
test	acc: 0.5820	macro: p 0.3726, r 0.3208, f1: 0.3292	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5493
global_step: 12641, epoch: 117, loss: 0.209524
global_step: 12642, epoch: 117, loss: 0.253620
global_step: 12643, epoch: 117, loss: 0.239641
global_step: 12644, epoch: 117, loss: 0.324340
global_step: 12645, epoch: 117, loss: 0.264843
global_step: 12646, epoch: 117, loss: 0.286534
global_step: 12647, epoch: 117, loss: 0.325033
global_step: 12648, epoch: 117, loss: 0.277578
global_step: 12649, epoch: 117, loss: 0.284397
global_step: 12650, epoch: 117, loss: 0.270171
global_step: 12651, epoch: 117, loss: 0.228966
global_step: 12652, epoch: 117, loss: 0.247799
global_step: 12653, epoch: 117, loss: 0.334440
global_step: 12654, epoch: 117, loss: 0.203227
global_step: 12655, epoch: 117, loss: 0.291471
global_step: 12656, epoch: 117, loss: 0.270961
global_step: 12657, epoch: 117, loss: 0.353922
global_step: 12658, epoch: 117, loss: 0.290506
global_step: 12659, epoch: 117, loss: 0.265556
global_step: 12660, epoch: 117, loss: 0.297223
global_step: 12661, epoch: 117, loss: 0.301737
global_step: 12662, epoch: 117, loss: 0.272558
global_step: 12663, epoch: 117, loss: 0.253861
global_step: 12664, epoch: 117, loss: 0.300635
global_step: 12665, epoch: 117, loss: 0.229668
global_step: 12666, epoch: 117, loss: 0.268940
global_step: 12667, epoch: 117, loss: 0.289285
global_step: 12668, epoch: 117, loss: 0.361653
global_step: 12669, epoch: 117, loss: 0.299309
global_step: 12670, epoch: 117, loss: 0.281755
global_step: 12671, epoch: 117, loss: 0.306854
global_step: 12672, epoch: 117, loss: 0.306903
global_step: 12673, epoch: 117, loss: 0.279262
global_step: 12674, epoch: 117, loss: 0.255793
global_step: 12675, epoch: 117, loss: 0.340141
global_step: 12676, epoch: 117, loss: 0.345051
global_step: 12677, epoch: 117, loss: 0.275399
global_step: 12678, epoch: 117, loss: 0.293070
global_step: 12679, epoch: 117, loss: 0.211133
global_step: 12680, epoch: 117, loss: 0.029575
epoch: 117
train	acc: 0.9637	macro: p 0.9699, r 0.9435, f1: 0.9560	micro: p 0.9637, r 0.9637, f1 0.9637	weighted_f1:0.9636
dev	acc: 0.5464	macro: p 0.3875, r 0.3115, f1: 0.3110	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4985
test	acc: 0.5870	macro: p 0.3754, r 0.3136, f1: 0.3208	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5464
global_step: 12681, epoch: 118, loss: 0.273667
global_step: 12682, epoch: 118, loss: 0.333718
global_step: 12683, epoch: 118, loss: 0.262131
global_step: 12684, epoch: 118, loss: 0.220422
global_step: 12685, epoch: 118, loss: 0.258490
global_step: 12686, epoch: 118, loss: 0.243756
global_step: 12687, epoch: 118, loss: 0.293151
global_step: 12688, epoch: 118, loss: 0.245519
global_step: 12689, epoch: 118, loss: 0.335247
global_step: 12690, epoch: 118, loss: 0.296719
global_step: 12691, epoch: 118, loss: 0.283591
global_step: 12692, epoch: 118, loss: 0.349286
global_step: 12693, epoch: 118, loss: 0.239888
global_step: 12694, epoch: 118, loss: 0.237639
global_step: 12695, epoch: 118, loss: 0.291522
global_step: 12696, epoch: 118, loss: 0.349098
global_step: 12697, epoch: 118, loss: 0.236923
global_step: 12698, epoch: 118, loss: 0.248754
global_step: 12699, epoch: 118, loss: 0.302431
global_step: 12700, epoch: 118, loss: 0.320560
global_step: 12701, epoch: 118, loss: 0.389862
global_step: 12702, epoch: 118, loss: 0.260255
global_step: 12703, epoch: 118, loss: 0.299698
global_step: 12704, epoch: 118, loss: 0.305981
global_step: 12705, epoch: 118, loss: 0.230350
global_step: 12706, epoch: 118, loss: 0.276467
global_step: 12707, epoch: 118, loss: 0.384017
global_step: 12708, epoch: 118, loss: 0.239322
global_step: 12709, epoch: 118, loss: 0.284751
global_step: 12710, epoch: 118, loss: 0.346619
global_step: 12711, epoch: 118, loss: 0.278135
global_step: 12712, epoch: 118, loss: 0.239338
global_step: 12713, epoch: 118, loss: 0.268379
global_step: 12714, epoch: 118, loss: 0.284104
global_step: 12715, epoch: 118, loss: 0.323048
global_step: 12716, epoch: 118, loss: 0.224209
global_step: 12717, epoch: 118, loss: 0.240257
global_step: 12718, epoch: 118, loss: 0.270011
global_step: 12719, epoch: 118, loss: 0.270969
global_step: 12720, epoch: 118, loss: 0.708687
epoch: 118
train	acc: 0.9648	macro: p 0.9703, r 0.9452, f1: 0.9571	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9647
dev	acc: 0.5455	macro: p 0.4068, r 0.3156, f1: 0.3154	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5015
test	acc: 0.5816	macro: p 0.3692, r 0.3131, f1: 0.3214	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5444
global_step: 12721, epoch: 119, loss: 0.284831
global_step: 12722, epoch: 119, loss: 0.261065
global_step: 12723, epoch: 119, loss: 0.245987
global_step: 12724, epoch: 119, loss: 0.270194
global_step: 12725, epoch: 119, loss: 0.296513
global_step: 12726, epoch: 119, loss: 0.226704
global_step: 12727, epoch: 119, loss: 0.296947
global_step: 12728, epoch: 119, loss: 0.346016
global_step: 12729, epoch: 119, loss: 0.275609
global_step: 12730, epoch: 119, loss: 0.259110
global_step: 12731, epoch: 119, loss: 0.292267
global_step: 12732, epoch: 119, loss: 0.248106
global_step: 12733, epoch: 119, loss: 0.377276
global_step: 12734, epoch: 119, loss: 0.264877
global_step: 12735, epoch: 119, loss: 0.226271
global_step: 12736, epoch: 119, loss: 0.285737
global_step: 12737, epoch: 119, loss: 0.244897
global_step: 12738, epoch: 119, loss: 0.268192
global_step: 12739, epoch: 119, loss: 0.303276
global_step: 12740, epoch: 119, loss: 0.311228
global_step: 12741, epoch: 119, loss: 0.290138
global_step: 12742, epoch: 119, loss: 0.387408
global_step: 12743, epoch: 119, loss: 0.218175
global_step: 12744, epoch: 119, loss: 0.336018
global_step: 12745, epoch: 119, loss: 0.295157
global_step: 12746, epoch: 119, loss: 0.239330
global_step: 12747, epoch: 119, loss: 0.345231
global_step: 12748, epoch: 119, loss: 0.325521
global_step: 12749, epoch: 119, loss: 0.292962
global_step: 12750, epoch: 119, loss: 0.319674
global_step: 12751, epoch: 119, loss: 0.285307
global_step: 12752, epoch: 119, loss: 0.296227
global_step: 12753, epoch: 119, loss: 0.277098
global_step: 12754, epoch: 119, loss: 0.340571
global_step: 12755, epoch: 119, loss: 0.283458
global_step: 12756, epoch: 119, loss: 0.339724
global_step: 12757, epoch: 119, loss: 0.324041
global_step: 12758, epoch: 119, loss: 0.250019
global_step: 12759, epoch: 119, loss: 0.253672
global_step: 12760, epoch: 119, loss: 0.004691
epoch: 119
train	acc: 0.9646	macro: p 0.9698, r 0.9450, f1: 0.9567	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9646
dev	acc: 0.5437	macro: p 0.3644, r 0.3156, f1: 0.3131	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5004
test	acc: 0.5835	macro: p 0.3892, r 0.3212, f1: 0.3287	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5471
global_step: 12761, epoch: 120, loss: 0.261396
global_step: 12762, epoch: 120, loss: 0.276947
global_step: 12763, epoch: 120, loss: 0.266457
global_step: 12764, epoch: 120, loss: 0.288418
global_step: 12765, epoch: 120, loss: 0.215842
global_step: 12766, epoch: 120, loss: 0.257119
global_step: 12767, epoch: 120, loss: 0.295162
global_step: 12768, epoch: 120, loss: 0.295110
global_step: 12769, epoch: 120, loss: 0.251848
global_step: 12770, epoch: 120, loss: 0.311294
global_step: 12771, epoch: 120, loss: 0.300501
global_step: 12772, epoch: 120, loss: 0.290460
global_step: 12773, epoch: 120, loss: 0.230438
global_step: 12774, epoch: 120, loss: 0.231672
global_step: 12775, epoch: 120, loss: 0.335781
global_step: 12776, epoch: 120, loss: 0.210783
global_step: 12777, epoch: 120, loss: 0.245708
global_step: 12778, epoch: 120, loss: 0.308340
global_step: 12779, epoch: 120, loss: 0.289518
global_step: 12780, epoch: 120, loss: 0.339924
global_step: 12781, epoch: 120, loss: 0.261657
global_step: 12782, epoch: 120, loss: 0.317979
global_step: 12783, epoch: 120, loss: 0.240831
global_step: 12784, epoch: 120, loss: 0.320977
global_step: 12785, epoch: 120, loss: 0.265870
global_step: 12786, epoch: 120, loss: 0.200346
global_step: 12787, epoch: 120, loss: 0.333353
global_step: 12788, epoch: 120, loss: 0.251962
global_step: 12789, epoch: 120, loss: 0.339024
global_step: 12790, epoch: 120, loss: 0.362417
global_step: 12791, epoch: 120, loss: 0.199134
global_step: 12792, epoch: 120, loss: 0.314998
global_step: 12793, epoch: 120, loss: 0.290112
global_step: 12794, epoch: 120, loss: 0.283059
global_step: 12795, epoch: 120, loss: 0.288315
global_step: 12796, epoch: 120, loss: 0.227541
global_step: 12797, epoch: 120, loss: 0.236027
global_step: 12798, epoch: 120, loss: 0.210461
global_step: 12799, epoch: 120, loss: 0.231779
global_step: 12800, epoch: 120, loss: 0.267098
epoch: 120
train	acc: 0.9651	macro: p 0.9703, r 0.9455, f1: 0.9573	micro: p 0.9651, r 0.9651, f1 0.9651	weighted_f1:0.9651
dev	acc: 0.5437	macro: p 0.3857, r 0.3144, f1: 0.3135	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4985
test	acc: 0.5854	macro: p 0.4030, r 0.3163, f1: 0.3269	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5466
global_step: 12801, epoch: 121, loss: 0.296373
global_step: 12802, epoch: 121, loss: 0.274861
global_step: 12803, epoch: 121, loss: 0.272274
global_step: 12804, epoch: 121, loss: 0.297351
global_step: 12805, epoch: 121, loss: 0.266517
global_step: 12806, epoch: 121, loss: 0.264192
global_step: 12807, epoch: 121, loss: 0.270318
global_step: 12808, epoch: 121, loss: 0.195668
global_step: 12809, epoch: 121, loss: 0.272724
global_step: 12810, epoch: 121, loss: 0.296095
global_step: 12811, epoch: 121, loss: 0.270909
global_step: 12812, epoch: 121, loss: 0.321080
global_step: 12813, epoch: 121, loss: 0.290459
global_step: 12814, epoch: 121, loss: 0.268726
global_step: 12815, epoch: 121, loss: 0.283278
global_step: 12816, epoch: 121, loss: 0.307687
global_step: 12817, epoch: 121, loss: 0.245274
global_step: 12818, epoch: 121, loss: 0.290130
global_step: 12819, epoch: 121, loss: 0.297065
global_step: 12820, epoch: 121, loss: 0.305945
global_step: 12821, epoch: 121, loss: 0.314997
global_step: 12822, epoch: 121, loss: 0.248419
global_step: 12823, epoch: 121, loss: 0.303516
global_step: 12824, epoch: 121, loss: 0.301119
global_step: 12825, epoch: 121, loss: 0.323537
global_step: 12826, epoch: 121, loss: 0.243251
global_step: 12827, epoch: 121, loss: 0.286214
global_step: 12828, epoch: 121, loss: 0.232279
global_step: 12829, epoch: 121, loss: 0.238994
global_step: 12830, epoch: 121, loss: 0.199608
global_step: 12831, epoch: 121, loss: 0.218834
global_step: 12832, epoch: 121, loss: 0.255438
global_step: 12833, epoch: 121, loss: 0.354388
global_step: 12834, epoch: 121, loss: 0.230935
global_step: 12835, epoch: 121, loss: 0.348923
global_step: 12836, epoch: 121, loss: 0.251426
global_step: 12837, epoch: 121, loss: 0.232091
global_step: 12838, epoch: 121, loss: 0.247102
global_step: 12839, epoch: 121, loss: 0.248651
global_step: 12840, epoch: 121, loss: 0.122177
epoch: 121
train	acc: 0.9642	macro: p 0.9691, r 0.9459, f1: 0.9568	micro: p 0.9642, r 0.9642, f1 0.9642	weighted_f1:0.9642
dev	acc: 0.5455	macro: p 0.3735, r 0.3210, f1: 0.3194	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5041
test	acc: 0.5854	macro: p 0.3650, r 0.3194, f1: 0.3239	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5479
global_step: 12841, epoch: 122, loss: 0.269447
global_step: 12842, epoch: 122, loss: 0.279380
global_step: 12843, epoch: 122, loss: 0.242655
global_step: 12844, epoch: 122, loss: 0.274498
global_step: 12845, epoch: 122, loss: 0.249767
global_step: 12846, epoch: 122, loss: 0.190850
global_step: 12847, epoch: 122, loss: 0.257657
global_step: 12848, epoch: 122, loss: 0.223260
global_step: 12849, epoch: 122, loss: 0.247072
global_step: 12850, epoch: 122, loss: 0.285146
global_step: 12851, epoch: 122, loss: 0.280747
global_step: 12852, epoch: 122, loss: 0.262643
global_step: 12853, epoch: 122, loss: 0.237823
global_step: 12854, epoch: 122, loss: 0.297947
global_step: 12855, epoch: 122, loss: 0.201139
global_step: 12856, epoch: 122, loss: 0.348559
global_step: 12857, epoch: 122, loss: 0.254620
global_step: 12858, epoch: 122, loss: 0.263264
global_step: 12859, epoch: 122, loss: 0.314148
global_step: 12860, epoch: 122, loss: 0.310296
global_step: 12861, epoch: 122, loss: 0.302511
global_step: 12862, epoch: 122, loss: 0.320774
global_step: 12863, epoch: 122, loss: 0.233080
global_step: 12864, epoch: 122, loss: 0.262891
global_step: 12865, epoch: 122, loss: 0.255988
global_step: 12866, epoch: 122, loss: 0.223991
global_step: 12867, epoch: 122, loss: 0.306349
global_step: 12868, epoch: 122, loss: 0.339100
global_step: 12869, epoch: 122, loss: 0.254013
global_step: 12870, epoch: 122, loss: 0.270964
global_step: 12871, epoch: 122, loss: 0.331046
global_step: 12872, epoch: 122, loss: 0.355602
global_step: 12873, epoch: 122, loss: 0.280872
global_step: 12874, epoch: 122, loss: 0.241516
global_step: 12875, epoch: 122, loss: 0.312861
global_step: 12876, epoch: 122, loss: 0.219093
global_step: 12877, epoch: 122, loss: 0.318487
global_step: 12878, epoch: 122, loss: 0.297150
global_step: 12879, epoch: 122, loss: 0.268330
global_step: 12880, epoch: 122, loss: 0.289150
epoch: 122
train	acc: 0.9642	macro: p 0.9696, r 0.9448, f1: 0.9564	micro: p 0.9642, r 0.9642, f1 0.9642	weighted_f1:0.9642
dev	acc: 0.5428	macro: p 0.3637, r 0.3137, f1: 0.3105	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4979
test	acc: 0.5877	macro: p 0.3733, r 0.3189, f1: 0.3240	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5490
global_step: 12881, epoch: 123, loss: 0.346197
global_step: 12882, epoch: 123, loss: 0.270486
global_step: 12883, epoch: 123, loss: 0.314135
global_step: 12884, epoch: 123, loss: 0.210576
global_step: 12885, epoch: 123, loss: 0.269712
global_step: 12886, epoch: 123, loss: 0.256200
global_step: 12887, epoch: 123, loss: 0.298556
global_step: 12888, epoch: 123, loss: 0.293894
global_step: 12889, epoch: 123, loss: 0.248468
global_step: 12890, epoch: 123, loss: 0.256132
global_step: 12891, epoch: 123, loss: 0.231541
global_step: 12892, epoch: 123, loss: 0.200642
global_step: 12893, epoch: 123, loss: 0.289363
global_step: 12894, epoch: 123, loss: 0.298841
global_step: 12895, epoch: 123, loss: 0.225503
global_step: 12896, epoch: 123, loss: 0.312635
global_step: 12897, epoch: 123, loss: 0.152120
global_step: 12898, epoch: 123, loss: 0.296157
global_step: 12899, epoch: 123, loss: 0.273292
global_step: 12900, epoch: 123, loss: 0.186577
global_step: 12901, epoch: 123, loss: 0.268726
global_step: 12902, epoch: 123, loss: 0.337726
global_step: 12903, epoch: 123, loss: 0.210800
global_step: 12904, epoch: 123, loss: 0.297625
global_step: 12905, epoch: 123, loss: 0.234676
global_step: 12906, epoch: 123, loss: 0.378706
global_step: 12907, epoch: 123, loss: 0.232432
global_step: 12908, epoch: 123, loss: 0.394493
global_step: 12909, epoch: 123, loss: 0.310488
global_step: 12910, epoch: 123, loss: 0.249157
global_step: 12911, epoch: 123, loss: 0.325770
global_step: 12912, epoch: 123, loss: 0.245350
global_step: 12913, epoch: 123, loss: 0.223200
global_step: 12914, epoch: 123, loss: 0.244400
global_step: 12915, epoch: 123, loss: 0.242079
global_step: 12916, epoch: 123, loss: 0.236988
global_step: 12917, epoch: 123, loss: 0.273351
global_step: 12918, epoch: 123, loss: 0.250745
global_step: 12919, epoch: 123, loss: 0.275681
global_step: 12920, epoch: 123, loss: 0.126974
epoch: 123
train	acc: 0.9656	macro: p 0.9710, r 0.9479, f1: 0.9590	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9656
dev	acc: 0.5428	macro: p 0.3689, r 0.3127, f1: 0.3133	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4980
test	acc: 0.5824	macro: p 0.3780, r 0.3159, f1: 0.3261	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5453
global_step: 12921, epoch: 124, loss: 0.230326
global_step: 12922, epoch: 124, loss: 0.288144
global_step: 12923, epoch: 124, loss: 0.181625
global_step: 12924, epoch: 124, loss: 0.255339
global_step: 12925, epoch: 124, loss: 0.241746
global_step: 12926, epoch: 124, loss: 0.332374
global_step: 12927, epoch: 124, loss: 0.288264
global_step: 12928, epoch: 124, loss: 0.257115
global_step: 12929, epoch: 124, loss: 0.252137
global_step: 12930, epoch: 124, loss: 0.272136
global_step: 12931, epoch: 124, loss: 0.251016
global_step: 12932, epoch: 124, loss: 0.278819
global_step: 12933, epoch: 124, loss: 0.240610
global_step: 12934, epoch: 124, loss: 0.247088
global_step: 12935, epoch: 124, loss: 0.262614
global_step: 12936, epoch: 124, loss: 0.329595
global_step: 12937, epoch: 124, loss: 0.270707
global_step: 12938, epoch: 124, loss: 0.255340
global_step: 12939, epoch: 124, loss: 0.350746
global_step: 12940, epoch: 124, loss: 0.351541
global_step: 12941, epoch: 124, loss: 0.269327
global_step: 12942, epoch: 124, loss: 0.265903
global_step: 12943, epoch: 124, loss: 0.296537
global_step: 12944, epoch: 124, loss: 0.270592
global_step: 12945, epoch: 124, loss: 0.236909
global_step: 12946, epoch: 124, loss: 0.224865
global_step: 12947, epoch: 124, loss: 0.282670
global_step: 12948, epoch: 124, loss: 0.226776
global_step: 12949, epoch: 124, loss: 0.293650
global_step: 12950, epoch: 124, loss: 0.285359
global_step: 12951, epoch: 124, loss: 0.282066
global_step: 12952, epoch: 124, loss: 0.242718
global_step: 12953, epoch: 124, loss: 0.300535
global_step: 12954, epoch: 124, loss: 0.238718
global_step: 12955, epoch: 124, loss: 0.242334
global_step: 12956, epoch: 124, loss: 0.285337
global_step: 12957, epoch: 124, loss: 0.291439
global_step: 12958, epoch: 124, loss: 0.242646
global_step: 12959, epoch: 124, loss: 0.357661
global_step: 12960, epoch: 124, loss: 0.516869
epoch: 124
train	acc: 0.9645	macro: p 0.9706, r 0.9478, f1: 0.9586	micro: p 0.9645, r 0.9645, f1 0.9645	weighted_f1:0.9645
dev	acc: 0.5446	macro: p 0.3665, r 0.3160, f1: 0.3137	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5006
test	acc: 0.5858	macro: p 0.3725, r 0.3165, f1: 0.3235	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5490
global_step: 12961, epoch: 125, loss: 0.316861
global_step: 12962, epoch: 125, loss: 0.249371
global_step: 12963, epoch: 125, loss: 0.283320
global_step: 12964, epoch: 125, loss: 0.254959
global_step: 12965, epoch: 125, loss: 0.324051
global_step: 12966, epoch: 125, loss: 0.236376
global_step: 12967, epoch: 125, loss: 0.250877
global_step: 12968, epoch: 125, loss: 0.230867
global_step: 12969, epoch: 125, loss: 0.280548
global_step: 12970, epoch: 125, loss: 0.293652
global_step: 12971, epoch: 125, loss: 0.241757
global_step: 12972, epoch: 125, loss: 0.202686
global_step: 12973, epoch: 125, loss: 0.228167
global_step: 12974, epoch: 125, loss: 0.222328
global_step: 12975, epoch: 125, loss: 0.299415
global_step: 12976, epoch: 125, loss: 0.278336
global_step: 12977, epoch: 125, loss: 0.182740
global_step: 12978, epoch: 125, loss: 0.361745
global_step: 12979, epoch: 125, loss: 0.274726
global_step: 12980, epoch: 125, loss: 0.259554
global_step: 12981, epoch: 125, loss: 0.291943
global_step: 12982, epoch: 125, loss: 0.240971
global_step: 12983, epoch: 125, loss: 0.299345
global_step: 12984, epoch: 125, loss: 0.242817
global_step: 12985, epoch: 125, loss: 0.212636
global_step: 12986, epoch: 125, loss: 0.221224
global_step: 12987, epoch: 125, loss: 0.246104
global_step: 12988, epoch: 125, loss: 0.297866
global_step: 12989, epoch: 125, loss: 0.298554
global_step: 12990, epoch: 125, loss: 0.280988
global_step: 12991, epoch: 125, loss: 0.280661
global_step: 12992, epoch: 125, loss: 0.293715
global_step: 12993, epoch: 125, loss: 0.258121
global_step: 12994, epoch: 125, loss: 0.219172
global_step: 12995, epoch: 125, loss: 0.296508
global_step: 12996, epoch: 125, loss: 0.285203
global_step: 12997, epoch: 125, loss: 0.290959
global_step: 12998, epoch: 125, loss: 0.323776
global_step: 12999, epoch: 125, loss: 0.280509
global_step: 13000, epoch: 125, loss: 0.720401
epoch: 125
train	acc: 0.9669	macro: p 0.9724, r 0.9506, f1: 0.9610	micro: p 0.9669, r 0.9669, f1 0.9669	weighted_f1:0.9669
dev	acc: 0.5428	macro: p 0.3672, r 0.3135, f1: 0.3128	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4979
test	acc: 0.5851	macro: p 0.3780, r 0.3173, f1: 0.3263	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5461
global_step: 13001, epoch: 126, loss: 0.198010
global_step: 13002, epoch: 126, loss: 0.280958
global_step: 13003, epoch: 126, loss: 0.216952
global_step: 13004, epoch: 126, loss: 0.267349
global_step: 13005, epoch: 126, loss: 0.209367
global_step: 13006, epoch: 126, loss: 0.222393
global_step: 13007, epoch: 126, loss: 0.268643
global_step: 13008, epoch: 126, loss: 0.233316
global_step: 13009, epoch: 126, loss: 0.240157
global_step: 13010, epoch: 126, loss: 0.298733
global_step: 13011, epoch: 126, loss: 0.223542
global_step: 13012, epoch: 126, loss: 0.287864
global_step: 13013, epoch: 126, loss: 0.280298
global_step: 13014, epoch: 126, loss: 0.262959
global_step: 13015, epoch: 126, loss: 0.273271
global_step: 13016, epoch: 126, loss: 0.277590
global_step: 13017, epoch: 126, loss: 0.274965
global_step: 13018, epoch: 126, loss: 0.323999
global_step: 13019, epoch: 126, loss: 0.255355
global_step: 13020, epoch: 126, loss: 0.326987
global_step: 13021, epoch: 126, loss: 0.320935
global_step: 13022, epoch: 126, loss: 0.273535
global_step: 13023, epoch: 126, loss: 0.321823
global_step: 13024, epoch: 126, loss: 0.247143
global_step: 13025, epoch: 126, loss: 0.259368
global_step: 13026, epoch: 126, loss: 0.246031
global_step: 13027, epoch: 126, loss: 0.305534
global_step: 13028, epoch: 126, loss: 0.278738
global_step: 13029, epoch: 126, loss: 0.244385
global_step: 13030, epoch: 126, loss: 0.197516
global_step: 13031, epoch: 126, loss: 0.267185
global_step: 13032, epoch: 126, loss: 0.236131
global_step: 13033, epoch: 126, loss: 0.249027
global_step: 13034, epoch: 126, loss: 0.271380
global_step: 13035, epoch: 126, loss: 0.245840
global_step: 13036, epoch: 126, loss: 0.225625
global_step: 13037, epoch: 126, loss: 0.255926
global_step: 13038, epoch: 126, loss: 0.248665
global_step: 13039, epoch: 126, loss: 0.270859
global_step: 13040, epoch: 126, loss: 0.059723
epoch: 126
train	acc: 0.9671	macro: p 0.9729, r 0.9499, f1: 0.9609	micro: p 0.9671, r 0.9671, f1 0.9671	weighted_f1:0.9671
dev	acc: 0.5437	macro: p 0.3639, r 0.3118, f1: 0.3099	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4972
test	acc: 0.5812	macro: p 0.3565, r 0.3120, f1: 0.3188	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5430
global_step: 13041, epoch: 127, loss: 0.283642
global_step: 13042, epoch: 127, loss: 0.233125
global_step: 13043, epoch: 127, loss: 0.206719
global_step: 13044, epoch: 127, loss: 0.217206
global_step: 13045, epoch: 127, loss: 0.221059
global_step: 13046, epoch: 127, loss: 0.233281
global_step: 13047, epoch: 127, loss: 0.281779
global_step: 13048, epoch: 127, loss: 0.334256
global_step: 13049, epoch: 127, loss: 0.293536
global_step: 13050, epoch: 127, loss: 0.263658
global_step: 13051, epoch: 127, loss: 0.241389
global_step: 13052, epoch: 127, loss: 0.218099
global_step: 13053, epoch: 127, loss: 0.248580
global_step: 13054, epoch: 127, loss: 0.238885
global_step: 13055, epoch: 127, loss: 0.247694
global_step: 13056, epoch: 127, loss: 0.247834
global_step: 13057, epoch: 127, loss: 0.246435
global_step: 13058, epoch: 127, loss: 0.167839
global_step: 13059, epoch: 127, loss: 0.224455
global_step: 13060, epoch: 127, loss: 0.346456
global_step: 13061, epoch: 127, loss: 0.238147
global_step: 13062, epoch: 127, loss: 0.237996
global_step: 13063, epoch: 127, loss: 0.203476
global_step: 13064, epoch: 127, loss: 0.259591
global_step: 13065, epoch: 127, loss: 0.265096
global_step: 13066, epoch: 127, loss: 0.254514
global_step: 13067, epoch: 127, loss: 0.256285
global_step: 13068, epoch: 127, loss: 0.212016
global_step: 13069, epoch: 127, loss: 0.224413
global_step: 13070, epoch: 127, loss: 0.271619
global_step: 13071, epoch: 127, loss: 0.339096
global_step: 13072, epoch: 127, loss: 0.240008
global_step: 13073, epoch: 127, loss: 0.199254
global_step: 13074, epoch: 127, loss: 0.278818
global_step: 13075, epoch: 127, loss: 0.284353
global_step: 13076, epoch: 127, loss: 0.237978
global_step: 13077, epoch: 127, loss: 0.276426
global_step: 13078, epoch: 127, loss: 0.260040
global_step: 13079, epoch: 127, loss: 0.227027
global_step: 13080, epoch: 127, loss: 0.123732
epoch: 127
train	acc: 0.9660	macro: p 0.9700, r 0.9488, f1: 0.9589	micro: p 0.9660, r 0.9660, f1 0.9660	weighted_f1:0.9660
dev	acc: 0.5482	macro: p 0.3809, r 0.3186, f1: 0.3162	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5024
test	acc: 0.5843	macro: p 0.3819, r 0.3203, f1: 0.3258	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5457
global_step: 13081, epoch: 128, loss: 0.199181
global_step: 13082, epoch: 128, loss: 0.213575
global_step: 13083, epoch: 128, loss: 0.295162
global_step: 13084, epoch: 128, loss: 0.209690
global_step: 13085, epoch: 128, loss: 0.302281
global_step: 13086, epoch: 128, loss: 0.267108
global_step: 13087, epoch: 128, loss: 0.261524
global_step: 13088, epoch: 128, loss: 0.271387
global_step: 13089, epoch: 128, loss: 0.242687
global_step: 13090, epoch: 128, loss: 0.292868
global_step: 13091, epoch: 128, loss: 0.206732
global_step: 13092, epoch: 128, loss: 0.248993
global_step: 13093, epoch: 128, loss: 0.275588
global_step: 13094, epoch: 128, loss: 0.201253
global_step: 13095, epoch: 128, loss: 0.208403
global_step: 13096, epoch: 128, loss: 0.233340
global_step: 13097, epoch: 128, loss: 0.300551
global_step: 13098, epoch: 128, loss: 0.321398
global_step: 13099, epoch: 128, loss: 0.282431
global_step: 13100, epoch: 128, loss: 0.236445
global_step: 13101, epoch: 128, loss: 0.245206
global_step: 13102, epoch: 128, loss: 0.326523
global_step: 13103, epoch: 128, loss: 0.243543
global_step: 13104, epoch: 128, loss: 0.233250
global_step: 13105, epoch: 128, loss: 0.209965
global_step: 13106, epoch: 128, loss: 0.227967
global_step: 13107, epoch: 128, loss: 0.335092
global_step: 13108, epoch: 128, loss: 0.301052
global_step: 13109, epoch: 128, loss: 0.248421
global_step: 13110, epoch: 128, loss: 0.216430
global_step: 13111, epoch: 128, loss: 0.305402
global_step: 13112, epoch: 128, loss: 0.225746
global_step: 13113, epoch: 128, loss: 0.341252
global_step: 13114, epoch: 128, loss: 0.320557
global_step: 13115, epoch: 128, loss: 0.256274
global_step: 13116, epoch: 128, loss: 0.333043
global_step: 13117, epoch: 128, loss: 0.297217
global_step: 13118, epoch: 128, loss: 0.298396
global_step: 13119, epoch: 128, loss: 0.324917
global_step: 13120, epoch: 128, loss: 0.146082
epoch: 128
train	acc: 0.9666	macro: p 0.9716, r 0.9493, f1: 0.9599	micro: p 0.9666, r 0.9666, f1 0.9666	weighted_f1:0.9666
dev	acc: 0.5419	macro: p 0.3744, r 0.3115, f1: 0.3113	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4970
test	acc: 0.5793	macro: p 0.3571, r 0.3112, f1: 0.3176	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5416
global_step: 13121, epoch: 129, loss: 0.218953
global_step: 13122, epoch: 129, loss: 0.219349
global_step: 13123, epoch: 129, loss: 0.215230
global_step: 13124, epoch: 129, loss: 0.209994
global_step: 13125, epoch: 129, loss: 0.229862
global_step: 13126, epoch: 129, loss: 0.268309
global_step: 13127, epoch: 129, loss: 0.227366
global_step: 13128, epoch: 129, loss: 0.252975
global_step: 13129, epoch: 129, loss: 0.316517
global_step: 13130, epoch: 129, loss: 0.274905
global_step: 13131, epoch: 129, loss: 0.277109
global_step: 13132, epoch: 129, loss: 0.217655
global_step: 13133, epoch: 129, loss: 0.189375
global_step: 13134, epoch: 129, loss: 0.206666
global_step: 13135, epoch: 129, loss: 0.286380
global_step: 13136, epoch: 129, loss: 0.283030
global_step: 13137, epoch: 129, loss: 0.263534
global_step: 13138, epoch: 129, loss: 0.291865
global_step: 13139, epoch: 129, loss: 0.239318
global_step: 13140, epoch: 129, loss: 0.319928
global_step: 13141, epoch: 129, loss: 0.202791
global_step: 13142, epoch: 129, loss: 0.238550
global_step: 13143, epoch: 129, loss: 0.222491
global_step: 13144, epoch: 129, loss: 0.271775
global_step: 13145, epoch: 129, loss: 0.307489
global_step: 13146, epoch: 129, loss: 0.263128
global_step: 13147, epoch: 129, loss: 0.328497
global_step: 13148, epoch: 129, loss: 0.225907
global_step: 13149, epoch: 129, loss: 0.266265
global_step: 13150, epoch: 129, loss: 0.252685
global_step: 13151, epoch: 129, loss: 0.238380
global_step: 13152, epoch: 129, loss: 0.235166
global_step: 13153, epoch: 129, loss: 0.223534
global_step: 13154, epoch: 129, loss: 0.291833
global_step: 13155, epoch: 129, loss: 0.257010
global_step: 13156, epoch: 129, loss: 0.339617
global_step: 13157, epoch: 129, loss: 0.214641
global_step: 13158, epoch: 129, loss: 0.319862
global_step: 13159, epoch: 129, loss: 0.283085
global_step: 13160, epoch: 129, loss: 0.042753
epoch: 129
train	acc: 0.9673	macro: p 0.9708, r 0.9543, f1: 0.9622	micro: p 0.9673, r 0.9673, f1 0.9673	weighted_f1:0.9673
dev	acc: 0.5464	macro: p 0.3597, r 0.3168, f1: 0.3148	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5023
test	acc: 0.5839	macro: p 0.3885, r 0.3218, f1: 0.3305	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5484
global_step: 13161, epoch: 130, loss: 0.199117
global_step: 13162, epoch: 130, loss: 0.155570
global_step: 13163, epoch: 130, loss: 0.245082
global_step: 13164, epoch: 130, loss: 0.238495
global_step: 13165, epoch: 130, loss: 0.291249
global_step: 13166, epoch: 130, loss: 0.220417
global_step: 13167, epoch: 130, loss: 0.320281
global_step: 13168, epoch: 130, loss: 0.235972
global_step: 13169, epoch: 130, loss: 0.198516
global_step: 13170, epoch: 130, loss: 0.271349
global_step: 13171, epoch: 130, loss: 0.189734
global_step: 13172, epoch: 130, loss: 0.250512
global_step: 13173, epoch: 130, loss: 0.201132
global_step: 13174, epoch: 130, loss: 0.223650
global_step: 13175, epoch: 130, loss: 0.283308
global_step: 13176, epoch: 130, loss: 0.300977
global_step: 13177, epoch: 130, loss: 0.306766
global_step: 13178, epoch: 130, loss: 0.189096
global_step: 13179, epoch: 130, loss: 0.261729
global_step: 13180, epoch: 130, loss: 0.301874
global_step: 13181, epoch: 130, loss: 0.224216
global_step: 13182, epoch: 130, loss: 0.263831
global_step: 13183, epoch: 130, loss: 0.263775
global_step: 13184, epoch: 130, loss: 0.235295
global_step: 13185, epoch: 130, loss: 0.216354
global_step: 13186, epoch: 130, loss: 0.231901
global_step: 13187, epoch: 130, loss: 0.269663
global_step: 13188, epoch: 130, loss: 0.201222
global_step: 13189, epoch: 130, loss: 0.224478
global_step: 13190, epoch: 130, loss: 0.247026
global_step: 13191, epoch: 130, loss: 0.258692
global_step: 13192, epoch: 130, loss: 0.209543
global_step: 13193, epoch: 130, loss: 0.288314
global_step: 13194, epoch: 130, loss: 0.260421
global_step: 13195, epoch: 130, loss: 0.258791
global_step: 13196, epoch: 130, loss: 0.241648
global_step: 13197, epoch: 130, loss: 0.289895
global_step: 13198, epoch: 130, loss: 0.272214
global_step: 13199, epoch: 130, loss: 0.238018
global_step: 13200, epoch: 130, loss: 0.164048
epoch: 130
train	acc: 0.9680	macro: p 0.9723, r 0.9545, f1: 0.9631	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5401	macro: p 0.3701, r 0.3138, f1: 0.3144	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4979
test	acc: 0.5739	macro: p 0.3718, r 0.3140, f1: 0.3228	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5392
global_step: 13201, epoch: 131, loss: 0.287370
global_step: 13202, epoch: 131, loss: 0.185676
global_step: 13203, epoch: 131, loss: 0.288370
global_step: 13204, epoch: 131, loss: 0.200877
global_step: 13205, epoch: 131, loss: 0.251260
global_step: 13206, epoch: 131, loss: 0.223015
global_step: 13207, epoch: 131, loss: 0.320130
global_step: 13208, epoch: 131, loss: 0.282494
global_step: 13209, epoch: 131, loss: 0.241225
global_step: 13210, epoch: 131, loss: 0.271215
global_step: 13211, epoch: 131, loss: 0.189697
global_step: 13212, epoch: 131, loss: 0.255075
global_step: 13213, epoch: 131, loss: 0.215111
global_step: 13214, epoch: 131, loss: 0.211214
global_step: 13215, epoch: 131, loss: 0.261114
global_step: 13216, epoch: 131, loss: 0.353349
global_step: 13217, epoch: 131, loss: 0.197758
global_step: 13218, epoch: 131, loss: 0.218787
global_step: 13219, epoch: 131, loss: 0.315084
global_step: 13220, epoch: 131, loss: 0.249023
global_step: 13221, epoch: 131, loss: 0.223189
global_step: 13222, epoch: 131, loss: 0.261101
global_step: 13223, epoch: 131, loss: 0.275734
global_step: 13224, epoch: 131, loss: 0.250972
global_step: 13225, epoch: 131, loss: 0.281989
global_step: 13226, epoch: 131, loss: 0.293304
global_step: 13227, epoch: 131, loss: 0.231515
global_step: 13228, epoch: 131, loss: 0.253129
global_step: 13229, epoch: 131, loss: 0.212186
global_step: 13230, epoch: 131, loss: 0.287107
global_step: 13231, epoch: 131, loss: 0.261398
global_step: 13232, epoch: 131, loss: 0.281227
global_step: 13233, epoch: 131, loss: 0.289105
global_step: 13234, epoch: 131, loss: 0.253475
global_step: 13235, epoch: 131, loss: 0.378302
global_step: 13236, epoch: 131, loss: 0.310406
global_step: 13237, epoch: 131, loss: 0.307381
global_step: 13238, epoch: 131, loss: 0.253521
global_step: 13239, epoch: 131, loss: 0.286845
global_step: 13240, epoch: 131, loss: 0.316890
epoch: 131
train	acc: 0.9647	macro: p 0.9721, r 0.9491, f1: 0.9603	micro: p 0.9647, r 0.9647, f1 0.9647	weighted_f1:0.9645
dev	acc: 0.5464	macro: p 0.3617, r 0.3092, f1: 0.3095	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5011
test	acc: 0.5835	macro: p 0.3781, r 0.3132, f1: 0.3227	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5458
global_step: 13241, epoch: 132, loss: 0.244623
global_step: 13242, epoch: 132, loss: 0.241542
global_step: 13243, epoch: 132, loss: 0.172802
global_step: 13244, epoch: 132, loss: 0.216930
global_step: 13245, epoch: 132, loss: 0.240692
global_step: 13246, epoch: 132, loss: 0.184757
global_step: 13247, epoch: 132, loss: 0.280026
global_step: 13248, epoch: 132, loss: 0.282563
global_step: 13249, epoch: 132, loss: 0.243981
global_step: 13250, epoch: 132, loss: 0.336464
global_step: 13251, epoch: 132, loss: 0.240856
global_step: 13252, epoch: 132, loss: 0.276360
global_step: 13253, epoch: 132, loss: 0.207027
global_step: 13254, epoch: 132, loss: 0.196391
global_step: 13255, epoch: 132, loss: 0.254850
global_step: 13256, epoch: 132, loss: 0.251179
global_step: 13257, epoch: 132, loss: 0.238658
global_step: 13258, epoch: 132, loss: 0.294319
global_step: 13259, epoch: 132, loss: 0.302286
global_step: 13260, epoch: 132, loss: 0.282313
global_step: 13261, epoch: 132, loss: 0.238566
global_step: 13262, epoch: 132, loss: 0.296424
global_step: 13263, epoch: 132, loss: 0.265763
global_step: 13264, epoch: 132, loss: 0.220502
global_step: 13265, epoch: 132, loss: 0.276923
global_step: 13266, epoch: 132, loss: 0.299884
global_step: 13267, epoch: 132, loss: 0.282870
global_step: 13268, epoch: 132, loss: 0.301199
global_step: 13269, epoch: 132, loss: 0.241465
global_step: 13270, epoch: 132, loss: 0.293649
global_step: 13271, epoch: 132, loss: 0.256314
global_step: 13272, epoch: 132, loss: 0.299677
global_step: 13273, epoch: 132, loss: 0.279116
global_step: 13274, epoch: 132, loss: 0.269990
global_step: 13275, epoch: 132, loss: 0.261286
global_step: 13276, epoch: 132, loss: 0.279602
global_step: 13277, epoch: 132, loss: 0.208367
global_step: 13278, epoch: 132, loss: 0.351099
global_step: 13279, epoch: 132, loss: 0.230625
global_step: 13280, epoch: 132, loss: 0.810149
epoch: 132
train	acc: 0.9670	macro: p 0.9700, r 0.9557, f1: 0.9625	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5446	macro: p 0.3873, r 0.3273, f1: 0.3283	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5085
test	acc: 0.5751	macro: p 0.3883, r 0.3236, f1: 0.3297	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5448
global_step: 13281, epoch: 133, loss: 0.245859
global_step: 13282, epoch: 133, loss: 0.238457
global_step: 13283, epoch: 133, loss: 0.265346
global_step: 13284, epoch: 133, loss: 0.208107
global_step: 13285, epoch: 133, loss: 0.204812
global_step: 13286, epoch: 133, loss: 0.272163
global_step: 13287, epoch: 133, loss: 0.254368
global_step: 13288, epoch: 133, loss: 0.232846
global_step: 13289, epoch: 133, loss: 0.295429
global_step: 13290, epoch: 133, loss: 0.243175
global_step: 13291, epoch: 133, loss: 0.295767
global_step: 13292, epoch: 133, loss: 0.338569
global_step: 13293, epoch: 133, loss: 0.206875
global_step: 13294, epoch: 133, loss: 0.254345
global_step: 13295, epoch: 133, loss: 0.280295
global_step: 13296, epoch: 133, loss: 0.267498
global_step: 13297, epoch: 133, loss: 0.296424
global_step: 13298, epoch: 133, loss: 0.219056
global_step: 13299, epoch: 133, loss: 0.315228
global_step: 13300, epoch: 133, loss: 0.303377
global_step: 13301, epoch: 133, loss: 0.310254
global_step: 13302, epoch: 133, loss: 0.243674
global_step: 13303, epoch: 133, loss: 0.232914
global_step: 13304, epoch: 133, loss: 0.254196
global_step: 13305, epoch: 133, loss: 0.291460
global_step: 13306, epoch: 133, loss: 0.205225
global_step: 13307, epoch: 133, loss: 0.223013
global_step: 13308, epoch: 133, loss: 0.259082
global_step: 13309, epoch: 133, loss: 0.262095
global_step: 13310, epoch: 133, loss: 0.259060
global_step: 13311, epoch: 133, loss: 0.299200
global_step: 13312, epoch: 133, loss: 0.231724
global_step: 13313, epoch: 133, loss: 0.210729
global_step: 13314, epoch: 133, loss: 0.214149
global_step: 13315, epoch: 133, loss: 0.260354
global_step: 13316, epoch: 133, loss: 0.270081
global_step: 13317, epoch: 133, loss: 0.198465
global_step: 13318, epoch: 133, loss: 0.250249
global_step: 13319, epoch: 133, loss: 0.218876
global_step: 13320, epoch: 133, loss: 0.036110
epoch: 133
train	acc: 0.9684	macro: p 0.9732, r 0.9561, f1: 0.9643	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5446	macro: p 0.3754, r 0.3169, f1: 0.3151	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5023
test	acc: 0.5820	macro: p 0.3919, r 0.3204, f1: 0.3308	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5473
global_step: 13321, epoch: 134, loss: 0.267042
global_step: 13322, epoch: 134, loss: 0.241287
global_step: 13323, epoch: 134, loss: 0.256599
global_step: 13324, epoch: 134, loss: 0.198240
global_step: 13325, epoch: 134, loss: 0.268701
global_step: 13326, epoch: 134, loss: 0.300319
global_step: 13327, epoch: 134, loss: 0.184288
global_step: 13328, epoch: 134, loss: 0.296607
global_step: 13329, epoch: 134, loss: 0.297032
global_step: 13330, epoch: 134, loss: 0.249463
global_step: 13331, epoch: 134, loss: 0.243294
global_step: 13332, epoch: 134, loss: 0.237414
global_step: 13333, epoch: 134, loss: 0.219268
global_step: 13334, epoch: 134, loss: 0.293755
global_step: 13335, epoch: 134, loss: 0.253683
global_step: 13336, epoch: 134, loss: 0.203442
global_step: 13337, epoch: 134, loss: 0.232811
global_step: 13338, epoch: 134, loss: 0.222171
global_step: 13339, epoch: 134, loss: 0.265441
global_step: 13340, epoch: 134, loss: 0.271727
global_step: 13341, epoch: 134, loss: 0.251229
global_step: 13342, epoch: 134, loss: 0.249777
global_step: 13343, epoch: 134, loss: 0.249198
global_step: 13344, epoch: 134, loss: 0.209056
global_step: 13345, epoch: 134, loss: 0.194582
global_step: 13346, epoch: 134, loss: 0.241131
global_step: 13347, epoch: 134, loss: 0.259317
global_step: 13348, epoch: 134, loss: 0.230167
global_step: 13349, epoch: 134, loss: 0.271933
global_step: 13350, epoch: 134, loss: 0.205816
global_step: 13351, epoch: 134, loss: 0.241287
global_step: 13352, epoch: 134, loss: 0.221221
global_step: 13353, epoch: 134, loss: 0.253939
global_step: 13354, epoch: 134, loss: 0.266203
global_step: 13355, epoch: 134, loss: 0.234602
global_step: 13356, epoch: 134, loss: 0.274595
global_step: 13357, epoch: 134, loss: 0.248128
global_step: 13358, epoch: 134, loss: 0.198233
global_step: 13359, epoch: 134, loss: 0.302087
global_step: 13360, epoch: 134, loss: 0.034087
epoch: 134
train	acc: 0.9683	macro: p 0.9734, r 0.9546, f1: 0.9637	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5464	macro: p 0.3787, r 0.3181, f1: 0.3184	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5038
test	acc: 0.5774	macro: p 0.3811, r 0.3129, f1: 0.3248	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5399
global_step: 13361, epoch: 135, loss: 0.207649
global_step: 13362, epoch: 135, loss: 0.181164
global_step: 13363, epoch: 135, loss: 0.258855
global_step: 13364, epoch: 135, loss: 0.220982
global_step: 13365, epoch: 135, loss: 0.197940
global_step: 13366, epoch: 135, loss: 0.226985
global_step: 13367, epoch: 135, loss: 0.274665
global_step: 13368, epoch: 135, loss: 0.193625
global_step: 13369, epoch: 135, loss: 0.281944
global_step: 13370, epoch: 135, loss: 0.175266
global_step: 13371, epoch: 135, loss: 0.273745
global_step: 13372, epoch: 135, loss: 0.253843
global_step: 13373, epoch: 135, loss: 0.246532
global_step: 13374, epoch: 135, loss: 0.229891
global_step: 13375, epoch: 135, loss: 0.206466
global_step: 13376, epoch: 135, loss: 0.261911
global_step: 13377, epoch: 135, loss: 0.336548
global_step: 13378, epoch: 135, loss: 0.240352
global_step: 13379, epoch: 135, loss: 0.197408
global_step: 13380, epoch: 135, loss: 0.171936
global_step: 13381, epoch: 135, loss: 0.280786
global_step: 13382, epoch: 135, loss: 0.224839
global_step: 13383, epoch: 135, loss: 0.205435
global_step: 13384, epoch: 135, loss: 0.230515
global_step: 13385, epoch: 135, loss: 0.209630
global_step: 13386, epoch: 135, loss: 0.281970
global_step: 13387, epoch: 135, loss: 0.297718
global_step: 13388, epoch: 135, loss: 0.237311
global_step: 13389, epoch: 135, loss: 0.264527
global_step: 13390, epoch: 135, loss: 0.170816
global_step: 13391, epoch: 135, loss: 0.339221
global_step: 13392, epoch: 135, loss: 0.236956
global_step: 13393, epoch: 135, loss: 0.302005
global_step: 13394, epoch: 135, loss: 0.265292
global_step: 13395, epoch: 135, loss: 0.288842
global_step: 13396, epoch: 135, loss: 0.332900
global_step: 13397, epoch: 135, loss: 0.338468
global_step: 13398, epoch: 135, loss: 0.326629
global_step: 13399, epoch: 135, loss: 0.291048
global_step: 13400, epoch: 135, loss: 0.014876
epoch: 135
train	acc: 0.9680	macro: p 0.9723, r 0.9551, f1: 0.9634	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5419	macro: p 0.3907, r 0.3200, f1: 0.3215	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5003
test	acc: 0.5759	macro: p 0.3890, r 0.3188, f1: 0.3260	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5408
global_step: 13401, epoch: 136, loss: 0.243569
global_step: 13402, epoch: 136, loss: 0.234148
global_step: 13403, epoch: 136, loss: 0.172371
global_step: 13404, epoch: 136, loss: 0.235580
global_step: 13405, epoch: 136, loss: 0.225503
global_step: 13406, epoch: 136, loss: 0.203374
global_step: 13407, epoch: 136, loss: 0.266460
global_step: 13408, epoch: 136, loss: 0.199108
global_step: 13409, epoch: 136, loss: 0.248188
global_step: 13410, epoch: 136, loss: 0.193422
global_step: 13411, epoch: 136, loss: 0.216242
global_step: 13412, epoch: 136, loss: 0.172544
global_step: 13413, epoch: 136, loss: 0.200954
global_step: 13414, epoch: 136, loss: 0.159234
global_step: 13415, epoch: 136, loss: 0.196621
global_step: 13416, epoch: 136, loss: 0.225076
global_step: 13417, epoch: 136, loss: 0.345326
global_step: 13418, epoch: 136, loss: 0.247531
global_step: 13419, epoch: 136, loss: 0.220832
global_step: 13420, epoch: 136, loss: 0.196311
global_step: 13421, epoch: 136, loss: 0.239721
global_step: 13422, epoch: 136, loss: 0.257192
global_step: 13423, epoch: 136, loss: 0.306185
global_step: 13424, epoch: 136, loss: 0.220177
global_step: 13425, epoch: 136, loss: 0.238116
global_step: 13426, epoch: 136, loss: 0.344128
global_step: 13427, epoch: 136, loss: 0.235993
global_step: 13428, epoch: 136, loss: 0.263087
global_step: 13429, epoch: 136, loss: 0.201244
global_step: 13430, epoch: 136, loss: 0.243641
global_step: 13431, epoch: 136, loss: 0.266627
global_step: 13432, epoch: 136, loss: 0.248263
global_step: 13433, epoch: 136, loss: 0.209647
global_step: 13434, epoch: 136, loss: 0.250493
global_step: 13435, epoch: 136, loss: 0.321775
global_step: 13436, epoch: 136, loss: 0.244159
global_step: 13437, epoch: 136, loss: 0.298147
global_step: 13438, epoch: 136, loss: 0.296364
global_step: 13439, epoch: 136, loss: 0.256801
global_step: 13440, epoch: 136, loss: 0.033857
epoch: 136
train	acc: 0.9689	macro: p 0.9736, r 0.9565, f1: 0.9647	micro: p 0.9689, r 0.9689, f1 0.9689	weighted_f1:0.9689
dev	acc: 0.5365	macro: p 0.3670, r 0.3152, f1: 0.3130	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4938
test	acc: 0.5793	macro: p 0.3813, r 0.3223, f1: 0.3290	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5451
global_step: 13441, epoch: 137, loss: 0.186783
global_step: 13442, epoch: 137, loss: 0.200013
global_step: 13443, epoch: 137, loss: 0.217678
global_step: 13444, epoch: 137, loss: 0.323899
global_step: 13445, epoch: 137, loss: 0.228280
global_step: 13446, epoch: 137, loss: 0.292419
global_step: 13447, epoch: 137, loss: 0.265527
global_step: 13448, epoch: 137, loss: 0.236252
global_step: 13449, epoch: 137, loss: 0.243717
global_step: 13450, epoch: 137, loss: 0.276908
global_step: 13451, epoch: 137, loss: 0.226682
global_step: 13452, epoch: 137, loss: 0.165505
global_step: 13453, epoch: 137, loss: 0.193499
global_step: 13454, epoch: 137, loss: 0.294120
global_step: 13455, epoch: 137, loss: 0.216592
global_step: 13456, epoch: 137, loss: 0.209078
global_step: 13457, epoch: 137, loss: 0.212516
global_step: 13458, epoch: 137, loss: 0.205353
global_step: 13459, epoch: 137, loss: 0.347686
global_step: 13460, epoch: 137, loss: 0.248991
global_step: 13461, epoch: 137, loss: 0.207722
global_step: 13462, epoch: 137, loss: 0.246929
global_step: 13463, epoch: 137, loss: 0.289877
global_step: 13464, epoch: 137, loss: 0.181804
global_step: 13465, epoch: 137, loss: 0.206223
global_step: 13466, epoch: 137, loss: 0.292140
global_step: 13467, epoch: 137, loss: 0.250103
global_step: 13468, epoch: 137, loss: 0.212591
global_step: 13469, epoch: 137, loss: 0.268903
global_step: 13470, epoch: 137, loss: 0.278496
global_step: 13471, epoch: 137, loss: 0.339324
global_step: 13472, epoch: 137, loss: 0.283213
global_step: 13473, epoch: 137, loss: 0.220973
global_step: 13474, epoch: 137, loss: 0.272035
global_step: 13475, epoch: 137, loss: 0.204011
global_step: 13476, epoch: 137, loss: 0.313536
global_step: 13477, epoch: 137, loss: 0.219577
global_step: 13478, epoch: 137, loss: 0.207374
global_step: 13479, epoch: 137, loss: 0.317535
global_step: 13480, epoch: 137, loss: 0.086407
epoch: 137
train	acc: 0.9681	macro: p 0.9736, r 0.9535, f1: 0.9631	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9681
dev	acc: 0.5410	macro: p 0.3968, r 0.3126, f1: 0.3099	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4953
test	acc: 0.5808	macro: p 0.3841, r 0.3145, f1: 0.3225	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5420
global_step: 13481, epoch: 138, loss: 0.249125
global_step: 13482, epoch: 138, loss: 0.219592
global_step: 13483, epoch: 138, loss: 0.328581
global_step: 13484, epoch: 138, loss: 0.281451
global_step: 13485, epoch: 138, loss: 0.244856
global_step: 13486, epoch: 138, loss: 0.320520
global_step: 13487, epoch: 138, loss: 0.232810
global_step: 13488, epoch: 138, loss: 0.282975
global_step: 13489, epoch: 138, loss: 0.294325
global_step: 13490, epoch: 138, loss: 0.218968
global_step: 13491, epoch: 138, loss: 0.254703
global_step: 13492, epoch: 138, loss: 0.207778
global_step: 13493, epoch: 138, loss: 0.266151
global_step: 13494, epoch: 138, loss: 0.270153
global_step: 13495, epoch: 138, loss: 0.184816
global_step: 13496, epoch: 138, loss: 0.290918
global_step: 13497, epoch: 138, loss: 0.259525
global_step: 13498, epoch: 138, loss: 0.274362
global_step: 13499, epoch: 138, loss: 0.226882
global_step: 13500, epoch: 138, loss: 0.210564
global_step: 13501, epoch: 138, loss: 0.185673
global_step: 13502, epoch: 138, loss: 0.228490
global_step: 13503, epoch: 138, loss: 0.250293
global_step: 13504, epoch: 138, loss: 0.285059
global_step: 13505, epoch: 138, loss: 0.196496
global_step: 13506, epoch: 138, loss: 0.190369
global_step: 13507, epoch: 138, loss: 0.243970
global_step: 13508, epoch: 138, loss: 0.234519
global_step: 13509, epoch: 138, loss: 0.245777
global_step: 13510, epoch: 138, loss: 0.196006
global_step: 13511, epoch: 138, loss: 0.230022
global_step: 13512, epoch: 138, loss: 0.240757
global_step: 13513, epoch: 138, loss: 0.313078
global_step: 13514, epoch: 138, loss: 0.256171
global_step: 13515, epoch: 138, loss: 0.286040
global_step: 13516, epoch: 138, loss: 0.301226
global_step: 13517, epoch: 138, loss: 0.212533
global_step: 13518, epoch: 138, loss: 0.350325
global_step: 13519, epoch: 138, loss: 0.203440
global_step: 13520, epoch: 138, loss: 0.392811
epoch: 138
train	acc: 0.9699	macro: p 0.9732, r 0.9587, f1: 0.9657	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5383	macro: p 0.3745, r 0.3150, f1: 0.3153	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4982
test	acc: 0.5789	macro: p 0.3711, r 0.3196, f1: 0.3262	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5451
global_step: 13521, epoch: 139, loss: 0.303703
global_step: 13522, epoch: 139, loss: 0.207300
global_step: 13523, epoch: 139, loss: 0.237181
global_step: 13524, epoch: 139, loss: 0.285028
global_step: 13525, epoch: 139, loss: 0.195393
global_step: 13526, epoch: 139, loss: 0.256205
global_step: 13527, epoch: 139, loss: 0.216911
global_step: 13528, epoch: 139, loss: 0.255601
global_step: 13529, epoch: 139, loss: 0.217556
global_step: 13530, epoch: 139, loss: 0.246306
global_step: 13531, epoch: 139, loss: 0.297974
global_step: 13532, epoch: 139, loss: 0.290419
global_step: 13533, epoch: 139, loss: 0.196586
global_step: 13534, epoch: 139, loss: 0.265105
global_step: 13535, epoch: 139, loss: 0.292454
global_step: 13536, epoch: 139, loss: 0.196485
global_step: 13537, epoch: 139, loss: 0.212706
global_step: 13538, epoch: 139, loss: 0.150560
global_step: 13539, epoch: 139, loss: 0.250745
global_step: 13540, epoch: 139, loss: 0.208810
global_step: 13541, epoch: 139, loss: 0.275420
global_step: 13542, epoch: 139, loss: 0.256571
global_step: 13543, epoch: 139, loss: 0.303539
global_step: 13544, epoch: 139, loss: 0.208355
global_step: 13545, epoch: 139, loss: 0.246015
global_step: 13546, epoch: 139, loss: 0.251122
global_step: 13547, epoch: 139, loss: 0.246252
global_step: 13548, epoch: 139, loss: 0.261656
global_step: 13549, epoch: 139, loss: 0.270081
global_step: 13550, epoch: 139, loss: 0.286567
global_step: 13551, epoch: 139, loss: 0.248431
global_step: 13552, epoch: 139, loss: 0.185212
global_step: 13553, epoch: 139, loss: 0.248385
global_step: 13554, epoch: 139, loss: 0.184180
global_step: 13555, epoch: 139, loss: 0.227171
global_step: 13556, epoch: 139, loss: 0.211215
global_step: 13557, epoch: 139, loss: 0.257913
global_step: 13558, epoch: 139, loss: 0.188958
global_step: 13559, epoch: 139, loss: 0.261081
global_step: 13560, epoch: 139, loss: 0.090672
epoch: 139
train	acc: 0.9694	macro: p 0.9725, r 0.9585, f1: 0.9653	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5365	macro: p 0.3586, r 0.3125, f1: 0.3131	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4952
test	acc: 0.5808	macro: p 0.3736, r 0.3206, f1: 0.3270	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5460
global_step: 13561, epoch: 140, loss: 0.194046
global_step: 13562, epoch: 140, loss: 0.277786
global_step: 13563, epoch: 140, loss: 0.277104
global_step: 13564, epoch: 140, loss: 0.282969
global_step: 13565, epoch: 140, loss: 0.211719
global_step: 13566, epoch: 140, loss: 0.200799
global_step: 13567, epoch: 140, loss: 0.247471
global_step: 13568, epoch: 140, loss: 0.176194
global_step: 13569, epoch: 140, loss: 0.241384
global_step: 13570, epoch: 140, loss: 0.247202
global_step: 13571, epoch: 140, loss: 0.269973
global_step: 13572, epoch: 140, loss: 0.245162
global_step: 13573, epoch: 140, loss: 0.258198
global_step: 13574, epoch: 140, loss: 0.240335
global_step: 13575, epoch: 140, loss: 0.192504
global_step: 13576, epoch: 140, loss: 0.218688
global_step: 13577, epoch: 140, loss: 0.224226
global_step: 13578, epoch: 140, loss: 0.217530
global_step: 13579, epoch: 140, loss: 0.273379
global_step: 13580, epoch: 140, loss: 0.212624
global_step: 13581, epoch: 140, loss: 0.299254
global_step: 13582, epoch: 140, loss: 0.225671
global_step: 13583, epoch: 140, loss: 0.182921
global_step: 13584, epoch: 140, loss: 0.229548
global_step: 13585, epoch: 140, loss: 0.296832
global_step: 13586, epoch: 140, loss: 0.220796
global_step: 13587, epoch: 140, loss: 0.263256
global_step: 13588, epoch: 140, loss: 0.238946
global_step: 13589, epoch: 140, loss: 0.175615
global_step: 13590, epoch: 140, loss: 0.196705
global_step: 13591, epoch: 140, loss: 0.232594
global_step: 13592, epoch: 140, loss: 0.298595
global_step: 13593, epoch: 140, loss: 0.291869
global_step: 13594, epoch: 140, loss: 0.229888
global_step: 13595, epoch: 140, loss: 0.265677
global_step: 13596, epoch: 140, loss: 0.230650
global_step: 13597, epoch: 140, loss: 0.227907
global_step: 13598, epoch: 140, loss: 0.177726
global_step: 13599, epoch: 140, loss: 0.289675
global_step: 13600, epoch: 140, loss: 0.440814
epoch: 140
train	acc: 0.9694	macro: p 0.9723, r 0.9596, f1: 0.9657	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5473	macro: p 0.3766, r 0.3214, f1: 0.3231	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5082
test	acc: 0.5801	macro: p 0.3750, r 0.3237, f1: 0.3312	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5468
global_step: 13601, epoch: 141, loss: 0.278355
global_step: 13602, epoch: 141, loss: 0.248409
global_step: 13603, epoch: 141, loss: 0.272873
global_step: 13604, epoch: 141, loss: 0.185802
global_step: 13605, epoch: 141, loss: 0.221734
global_step: 13606, epoch: 141, loss: 0.282204
global_step: 13607, epoch: 141, loss: 0.265594
global_step: 13608, epoch: 141, loss: 0.242302
global_step: 13609, epoch: 141, loss: 0.210940
global_step: 13610, epoch: 141, loss: 0.272529
global_step: 13611, epoch: 141, loss: 0.226145
global_step: 13612, epoch: 141, loss: 0.195262
global_step: 13613, epoch: 141, loss: 0.216574
global_step: 13614, epoch: 141, loss: 0.258188
global_step: 13615, epoch: 141, loss: 0.210936
global_step: 13616, epoch: 141, loss: 0.174284
global_step: 13617, epoch: 141, loss: 0.225330
global_step: 13618, epoch: 141, loss: 0.277261
global_step: 13619, epoch: 141, loss: 0.187417
global_step: 13620, epoch: 141, loss: 0.231844
global_step: 13621, epoch: 141, loss: 0.202278
global_step: 13622, epoch: 141, loss: 0.231835
global_step: 13623, epoch: 141, loss: 0.221103
global_step: 13624, epoch: 141, loss: 0.296740
global_step: 13625, epoch: 141, loss: 0.270920
global_step: 13626, epoch: 141, loss: 0.285165
global_step: 13627, epoch: 141, loss: 0.216146
global_step: 13628, epoch: 141, loss: 0.286750
global_step: 13629, epoch: 141, loss: 0.233594
global_step: 13630, epoch: 141, loss: 0.241174
global_step: 13631, epoch: 141, loss: 0.153001
global_step: 13632, epoch: 141, loss: 0.169268
global_step: 13633, epoch: 141, loss: 0.267432
global_step: 13634, epoch: 141, loss: 0.260878
global_step: 13635, epoch: 141, loss: 0.165060
global_step: 13636, epoch: 141, loss: 0.173435
global_step: 13637, epoch: 141, loss: 0.306195
global_step: 13638, epoch: 141, loss: 0.234986
global_step: 13639, epoch: 141, loss: 0.198222
global_step: 13640, epoch: 141, loss: 0.822367
epoch: 141
train	acc: 0.9695	macro: p 0.9736, r 0.9581, f1: 0.9656	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5428	macro: p 0.3546, r 0.3145, f1: 0.3140	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5005
test	acc: 0.5789	macro: p 0.3699, r 0.3144, f1: 0.3226	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5420
global_step: 13641, epoch: 142, loss: 0.162929
global_step: 13642, epoch: 142, loss: 0.254736
global_step: 13643, epoch: 142, loss: 0.174906
global_step: 13644, epoch: 142, loss: 0.231053
global_step: 13645, epoch: 142, loss: 0.245447
global_step: 13646, epoch: 142, loss: 0.174774
global_step: 13647, epoch: 142, loss: 0.188239
global_step: 13648, epoch: 142, loss: 0.244459
global_step: 13649, epoch: 142, loss: 0.205772
global_step: 13650, epoch: 142, loss: 0.233451
global_step: 13651, epoch: 142, loss: 0.305904
global_step: 13652, epoch: 142, loss: 0.251620
global_step: 13653, epoch: 142, loss: 0.344382
global_step: 13654, epoch: 142, loss: 0.198818
global_step: 13655, epoch: 142, loss: 0.214452
global_step: 13656, epoch: 142, loss: 0.220439
global_step: 13657, epoch: 142, loss: 0.231651
global_step: 13658, epoch: 142, loss: 0.208222
global_step: 13659, epoch: 142, loss: 0.339390
global_step: 13660, epoch: 142, loss: 0.248224
global_step: 13661, epoch: 142, loss: 0.265845
global_step: 13662, epoch: 142, loss: 0.153669
global_step: 13663, epoch: 142, loss: 0.301118
global_step: 13664, epoch: 142, loss: 0.243554
global_step: 13665, epoch: 142, loss: 0.325471
global_step: 13666, epoch: 142, loss: 0.175004
global_step: 13667, epoch: 142, loss: 0.236835
global_step: 13668, epoch: 142, loss: 0.247761
global_step: 13669, epoch: 142, loss: 0.313170
global_step: 13670, epoch: 142, loss: 0.182697
global_step: 13671, epoch: 142, loss: 0.217692
global_step: 13672, epoch: 142, loss: 0.200987
global_step: 13673, epoch: 142, loss: 0.255331
global_step: 13674, epoch: 142, loss: 0.297505
global_step: 13675, epoch: 142, loss: 0.202744
global_step: 13676, epoch: 142, loss: 0.238618
global_step: 13677, epoch: 142, loss: 0.250335
global_step: 13678, epoch: 142, loss: 0.190219
global_step: 13679, epoch: 142, loss: 0.248328
global_step: 13680, epoch: 142, loss: 0.014160
epoch: 142
train	acc: 0.9708	macro: p 0.9741, r 0.9611, f1: 0.9674	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5401	macro: p 0.3528, r 0.3106, f1: 0.3104	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4968
test	acc: 0.5797	macro: p 0.3715, r 0.3175, f1: 0.3272	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5449
global_step: 13681, epoch: 143, loss: 0.291813
global_step: 13682, epoch: 143, loss: 0.254127
global_step: 13683, epoch: 143, loss: 0.269402
global_step: 13684, epoch: 143, loss: 0.208988
global_step: 13685, epoch: 143, loss: 0.205525
global_step: 13686, epoch: 143, loss: 0.261367
global_step: 13687, epoch: 143, loss: 0.197661
global_step: 13688, epoch: 143, loss: 0.250063
global_step: 13689, epoch: 143, loss: 0.250877
global_step: 13690, epoch: 143, loss: 0.198278
global_step: 13691, epoch: 143, loss: 0.235266
global_step: 13692, epoch: 143, loss: 0.232973
global_step: 13693, epoch: 143, loss: 0.212534
global_step: 13694, epoch: 143, loss: 0.224409
global_step: 13695, epoch: 143, loss: 0.217095
global_step: 13696, epoch: 143, loss: 0.253099
global_step: 13697, epoch: 143, loss: 0.233451
global_step: 13698, epoch: 143, loss: 0.234355
global_step: 13699, epoch: 143, loss: 0.179790
global_step: 13700, epoch: 143, loss: 0.215857
global_step: 13701, epoch: 143, loss: 0.199052
global_step: 13702, epoch: 143, loss: 0.227521
global_step: 13703, epoch: 143, loss: 0.280428
global_step: 13704, epoch: 143, loss: 0.219372
global_step: 13705, epoch: 143, loss: 0.293130
global_step: 13706, epoch: 143, loss: 0.279066
global_step: 13707, epoch: 143, loss: 0.205361
global_step: 13708, epoch: 143, loss: 0.289388
global_step: 13709, epoch: 143, loss: 0.222251
global_step: 13710, epoch: 143, loss: 0.199568
global_step: 13711, epoch: 143, loss: 0.257671
global_step: 13712, epoch: 143, loss: 0.296906
global_step: 13713, epoch: 143, loss: 0.175450
global_step: 13714, epoch: 143, loss: 0.198546
global_step: 13715, epoch: 143, loss: 0.182906
global_step: 13716, epoch: 143, loss: 0.324484
global_step: 13717, epoch: 143, loss: 0.307993
global_step: 13718, epoch: 143, loss: 0.166722
global_step: 13719, epoch: 143, loss: 0.231351
global_step: 13720, epoch: 143, loss: 0.140732
epoch: 143
train	acc: 0.9699	macro: p 0.9740, r 0.9582, f1: 0.9658	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5446	macro: p 0.4037, r 0.3130, f1: 0.3114	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4979
test	acc: 0.5839	macro: p 0.3947, r 0.3163, f1: 0.3254	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5443
global_step: 13721, epoch: 144, loss: 0.194350
global_step: 13722, epoch: 144, loss: 0.199497
global_step: 13723, epoch: 144, loss: 0.227092
global_step: 13724, epoch: 144, loss: 0.222067
global_step: 13725, epoch: 144, loss: 0.193903
global_step: 13726, epoch: 144, loss: 0.216580
global_step: 13727, epoch: 144, loss: 0.267370
global_step: 13728, epoch: 144, loss: 0.264683
global_step: 13729, epoch: 144, loss: 0.213162
global_step: 13730, epoch: 144, loss: 0.232058
global_step: 13731, epoch: 144, loss: 0.276453
global_step: 13732, epoch: 144, loss: 0.179148
global_step: 13733, epoch: 144, loss: 0.252643
global_step: 13734, epoch: 144, loss: 0.171825
global_step: 13735, epoch: 144, loss: 0.262089
global_step: 13736, epoch: 144, loss: 0.232819
global_step: 13737, epoch: 144, loss: 0.211646
global_step: 13738, epoch: 144, loss: 0.239500
global_step: 13739, epoch: 144, loss: 0.222629
global_step: 13740, epoch: 144, loss: 0.224272
global_step: 13741, epoch: 144, loss: 0.191512
global_step: 13742, epoch: 144, loss: 0.211320
global_step: 13743, epoch: 144, loss: 0.222523
global_step: 13744, epoch: 144, loss: 0.276878
global_step: 13745, epoch: 144, loss: 0.273281
global_step: 13746, epoch: 144, loss: 0.230443
global_step: 13747, epoch: 144, loss: 0.211192
global_step: 13748, epoch: 144, loss: 0.263782
global_step: 13749, epoch: 144, loss: 0.220753
global_step: 13750, epoch: 144, loss: 0.250851
global_step: 13751, epoch: 144, loss: 0.234460
global_step: 13752, epoch: 144, loss: 0.243947
global_step: 13753, epoch: 144, loss: 0.294278
global_step: 13754, epoch: 144, loss: 0.212405
global_step: 13755, epoch: 144, loss: 0.221203
global_step: 13756, epoch: 144, loss: 0.212428
global_step: 13757, epoch: 144, loss: 0.216352
global_step: 13758, epoch: 144, loss: 0.258440
global_step: 13759, epoch: 144, loss: 0.252898
global_step: 13760, epoch: 144, loss: 0.445639
epoch: 144
train	acc: 0.9696	macro: p 0.9744, r 0.9579, f1: 0.9659	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5455	macro: p 0.3587, r 0.3118, f1: 0.3134	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4987
test	acc: 0.5782	macro: p 0.3663, r 0.3081, f1: 0.3158	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5357
global_step: 13761, epoch: 145, loss: 0.310662
global_step: 13762, epoch: 145, loss: 0.189042
global_step: 13763, epoch: 145, loss: 0.257333
global_step: 13764, epoch: 145, loss: 0.290997
global_step: 13765, epoch: 145, loss: 0.224070
global_step: 13766, epoch: 145, loss: 0.225417
global_step: 13767, epoch: 145, loss: 0.238919
global_step: 13768, epoch: 145, loss: 0.185874
global_step: 13769, epoch: 145, loss: 0.244311
global_step: 13770, epoch: 145, loss: 0.184331
global_step: 13771, epoch: 145, loss: 0.217256
global_step: 13772, epoch: 145, loss: 0.200171
global_step: 13773, epoch: 145, loss: 0.210803
global_step: 13774, epoch: 145, loss: 0.210802
global_step: 13775, epoch: 145, loss: 0.186181
global_step: 13776, epoch: 145, loss: 0.247839
global_step: 13777, epoch: 145, loss: 0.291081
global_step: 13778, epoch: 145, loss: 0.253140
global_step: 13779, epoch: 145, loss: 0.231223
global_step: 13780, epoch: 145, loss: 0.267198
global_step: 13781, epoch: 145, loss: 0.262190
global_step: 13782, epoch: 145, loss: 0.208241
global_step: 13783, epoch: 145, loss: 0.262716
global_step: 13784, epoch: 145, loss: 0.247975
global_step: 13785, epoch: 145, loss: 0.207318
global_step: 13786, epoch: 145, loss: 0.278884
global_step: 13787, epoch: 145, loss: 0.171519
global_step: 13788, epoch: 145, loss: 0.314850
global_step: 13789, epoch: 145, loss: 0.157980
global_step: 13790, epoch: 145, loss: 0.279629
global_step: 13791, epoch: 145, loss: 0.307250
global_step: 13792, epoch: 145, loss: 0.210738
global_step: 13793, epoch: 145, loss: 0.334441
global_step: 13794, epoch: 145, loss: 0.215475
global_step: 13795, epoch: 145, loss: 0.246611
global_step: 13796, epoch: 145, loss: 0.243982
global_step: 13797, epoch: 145, loss: 0.227370
global_step: 13798, epoch: 145, loss: 0.209191
global_step: 13799, epoch: 145, loss: 0.201461
global_step: 13800, epoch: 145, loss: 0.295693
epoch: 145
train	acc: 0.9693	macro: p 0.9738, r 0.9571, f1: 0.9652	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5428	macro: p 0.3708, r 0.3105, f1: 0.3112	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4957
test	acc: 0.5831	macro: p 0.3953, r 0.3118, f1: 0.3211	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5416
global_step: 13801, epoch: 146, loss: 0.219688
global_step: 13802, epoch: 146, loss: 0.248219
global_step: 13803, epoch: 146, loss: 0.211390
global_step: 13804, epoch: 146, loss: 0.206184
global_step: 13805, epoch: 146, loss: 0.204788
global_step: 13806, epoch: 146, loss: 0.203129
global_step: 13807, epoch: 146, loss: 0.270960
global_step: 13808, epoch: 146, loss: 0.268065
global_step: 13809, epoch: 146, loss: 0.236124
global_step: 13810, epoch: 146, loss: 0.237802
global_step: 13811, epoch: 146, loss: 0.227770
global_step: 13812, epoch: 146, loss: 0.188302
global_step: 13813, epoch: 146, loss: 0.212997
global_step: 13814, epoch: 146, loss: 0.223102
global_step: 13815, epoch: 146, loss: 0.154253
global_step: 13816, epoch: 146, loss: 0.314880
global_step: 13817, epoch: 146, loss: 0.251449
global_step: 13818, epoch: 146, loss: 0.260954
global_step: 13819, epoch: 146, loss: 0.230284
global_step: 13820, epoch: 146, loss: 0.219833
global_step: 13821, epoch: 146, loss: 0.218257
global_step: 13822, epoch: 146, loss: 0.259781
global_step: 13823, epoch: 146, loss: 0.265884
global_step: 13824, epoch: 146, loss: 0.226023
global_step: 13825, epoch: 146, loss: 0.196001
global_step: 13826, epoch: 146, loss: 0.283960
global_step: 13827, epoch: 146, loss: 0.251225
global_step: 13828, epoch: 146, loss: 0.196650
global_step: 13829, epoch: 146, loss: 0.231858
global_step: 13830, epoch: 146, loss: 0.213638
global_step: 13831, epoch: 146, loss: 0.256214
global_step: 13832, epoch: 146, loss: 0.236846
global_step: 13833, epoch: 146, loss: 0.175419
global_step: 13834, epoch: 146, loss: 0.229308
global_step: 13835, epoch: 146, loss: 0.271603
global_step: 13836, epoch: 146, loss: 0.186435
global_step: 13837, epoch: 146, loss: 0.207240
global_step: 13838, epoch: 146, loss: 0.234714
global_step: 13839, epoch: 146, loss: 0.219039
global_step: 13840, epoch: 146, loss: 0.147287
epoch: 146
train	acc: 0.9696	macro: p 0.9738, r 0.9564, f1: 0.9647	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5455	macro: p 0.3857, r 0.3175, f1: 0.3164	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5018
test	acc: 0.5831	macro: p 0.4069, r 0.3191, f1: 0.3230	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5446
global_step: 13841, epoch: 147, loss: 0.261690
global_step: 13842, epoch: 147, loss: 0.212440
global_step: 13843, epoch: 147, loss: 0.216657
global_step: 13844, epoch: 147, loss: 0.185920
global_step: 13845, epoch: 147, loss: 0.216096
global_step: 13846, epoch: 147, loss: 0.230672
global_step: 13847, epoch: 147, loss: 0.227009
global_step: 13848, epoch: 147, loss: 0.246247
global_step: 13849, epoch: 147, loss: 0.250748
global_step: 13850, epoch: 147, loss: 0.184985
global_step: 13851, epoch: 147, loss: 0.322780
global_step: 13852, epoch: 147, loss: 0.293200
global_step: 13853, epoch: 147, loss: 0.215394
global_step: 13854, epoch: 147, loss: 0.236416
global_step: 13855, epoch: 147, loss: 0.164632
global_step: 13856, epoch: 147, loss: 0.217584
global_step: 13857, epoch: 147, loss: 0.229970
global_step: 13858, epoch: 147, loss: 0.249035
global_step: 13859, epoch: 147, loss: 0.223856
global_step: 13860, epoch: 147, loss: 0.224968
global_step: 13861, epoch: 147, loss: 0.193766
global_step: 13862, epoch: 147, loss: 0.207855
global_step: 13863, epoch: 147, loss: 0.220992
global_step: 13864, epoch: 147, loss: 0.161697
global_step: 13865, epoch: 147, loss: 0.310866
global_step: 13866, epoch: 147, loss: 0.222555
global_step: 13867, epoch: 147, loss: 0.216083
global_step: 13868, epoch: 147, loss: 0.238389
global_step: 13869, epoch: 147, loss: 0.169488
global_step: 13870, epoch: 147, loss: 0.194277
global_step: 13871, epoch: 147, loss: 0.251211
global_step: 13872, epoch: 147, loss: 0.244988
global_step: 13873, epoch: 147, loss: 0.212659
global_step: 13874, epoch: 147, loss: 0.314730
global_step: 13875, epoch: 147, loss: 0.250147
global_step: 13876, epoch: 147, loss: 0.214355
global_step: 13877, epoch: 147, loss: 0.248616
global_step: 13878, epoch: 147, loss: 0.127920
global_step: 13879, epoch: 147, loss: 0.211838
global_step: 13880, epoch: 147, loss: 0.026453
epoch: 147
train	acc: 0.9674	macro: p 0.9749, r 0.9531, f1: 0.9637	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9673
dev	acc: 0.5455	macro: p 0.3591, r 0.3104, f1: 0.3110	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4983
test	acc: 0.5862	macro: p 0.4043, r 0.3138, f1: 0.3247	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5464
global_step: 13881, epoch: 148, loss: 0.214394
global_step: 13882, epoch: 148, loss: 0.323845
global_step: 13883, epoch: 148, loss: 0.154083
global_step: 13884, epoch: 148, loss: 0.185567
global_step: 13885, epoch: 148, loss: 0.218589
global_step: 13886, epoch: 148, loss: 0.220887
global_step: 13887, epoch: 148, loss: 0.202962
global_step: 13888, epoch: 148, loss: 0.208362
global_step: 13889, epoch: 148, loss: 0.216130
global_step: 13890, epoch: 148, loss: 0.242966
global_step: 13891, epoch: 148, loss: 0.284492
global_step: 13892, epoch: 148, loss: 0.223308
global_step: 13893, epoch: 148, loss: 0.217165
global_step: 13894, epoch: 148, loss: 0.306679
global_step: 13895, epoch: 148, loss: 0.262783
global_step: 13896, epoch: 148, loss: 0.203201
global_step: 13897, epoch: 148, loss: 0.244180
global_step: 13898, epoch: 148, loss: 0.274455
global_step: 13899, epoch: 148, loss: 0.148524
global_step: 13900, epoch: 148, loss: 0.276684
global_step: 13901, epoch: 148, loss: 0.234059
global_step: 13902, epoch: 148, loss: 0.192325
global_step: 13903, epoch: 148, loss: 0.294924
global_step: 13904, epoch: 148, loss: 0.190433
global_step: 13905, epoch: 148, loss: 0.136881
global_step: 13906, epoch: 148, loss: 0.158488
global_step: 13907, epoch: 148, loss: 0.182649
global_step: 13908, epoch: 148, loss: 0.259593
global_step: 13909, epoch: 148, loss: 0.201564
global_step: 13910, epoch: 148, loss: 0.204085
global_step: 13911, epoch: 148, loss: 0.259978
global_step: 13912, epoch: 148, loss: 0.258462
global_step: 13913, epoch: 148, loss: 0.292914
global_step: 13914, epoch: 148, loss: 0.243586
global_step: 13915, epoch: 148, loss: 0.260772
global_step: 13916, epoch: 148, loss: 0.190334
global_step: 13917, epoch: 148, loss: 0.241101
global_step: 13918, epoch: 148, loss: 0.141233
global_step: 13919, epoch: 148, loss: 0.292309
global_step: 13920, epoch: 148, loss: 0.627757
epoch: 148
train	acc: 0.9704	macro: p 0.9736, r 0.9593, f1: 0.9662	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5401	macro: p 0.3587, r 0.3119, f1: 0.3121	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4953
test	acc: 0.5839	macro: p 0.3883, r 0.3184, f1: 0.3278	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5441
global_step: 13921, epoch: 149, loss: 0.263432
global_step: 13922, epoch: 149, loss: 0.208795
global_step: 13923, epoch: 149, loss: 0.186354
global_step: 13924, epoch: 149, loss: 0.283666
global_step: 13925, epoch: 149, loss: 0.168828
global_step: 13926, epoch: 149, loss: 0.272844
global_step: 13927, epoch: 149, loss: 0.320576
global_step: 13928, epoch: 149, loss: 0.129113
global_step: 13929, epoch: 149, loss: 0.225501
global_step: 13930, epoch: 149, loss: 0.240452
global_step: 13931, epoch: 149, loss: 0.187743
global_step: 13932, epoch: 149, loss: 0.205863
global_step: 13933, epoch: 149, loss: 0.144990
global_step: 13934, epoch: 149, loss: 0.189483
global_step: 13935, epoch: 149, loss: 0.255353
global_step: 13936, epoch: 149, loss: 0.196732
global_step: 13937, epoch: 149, loss: 0.288626
global_step: 13938, epoch: 149, loss: 0.184733
global_step: 13939, epoch: 149, loss: 0.220426
global_step: 13940, epoch: 149, loss: 0.247231
global_step: 13941, epoch: 149, loss: 0.240688
global_step: 13942, epoch: 149, loss: 0.235217
global_step: 13943, epoch: 149, loss: 0.257963
global_step: 13944, epoch: 149, loss: 0.169315
global_step: 13945, epoch: 149, loss: 0.211901
global_step: 13946, epoch: 149, loss: 0.197009
global_step: 13947, epoch: 149, loss: 0.217052
global_step: 13948, epoch: 149, loss: 0.303240
global_step: 13949, epoch: 149, loss: 0.268197
global_step: 13950, epoch: 149, loss: 0.249282
global_step: 13951, epoch: 149, loss: 0.225636
global_step: 13952, epoch: 149, loss: 0.210521
global_step: 13953, epoch: 149, loss: 0.178853
global_step: 13954, epoch: 149, loss: 0.277406
global_step: 13955, epoch: 149, loss: 0.257891
global_step: 13956, epoch: 149, loss: 0.250369
global_step: 13957, epoch: 149, loss: 0.184932
global_step: 13958, epoch: 149, loss: 0.265964
global_step: 13959, epoch: 149, loss: 0.275007
global_step: 13960, epoch: 149, loss: 0.008884
epoch: 149
train	acc: 0.9702	macro: p 0.9735, r 0.9588, f1: 0.9659	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5338	macro: p 0.3594, r 0.3047, f1: 0.3051	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4891
test	acc: 0.5805	macro: p 0.3994, r 0.3138, f1: 0.3258	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5405
global_step: 13961, epoch: 150, loss: 0.198338
global_step: 13962, epoch: 150, loss: 0.186754
global_step: 13963, epoch: 150, loss: 0.194102
global_step: 13964, epoch: 150, loss: 0.238072
global_step: 13965, epoch: 150, loss: 0.165052
global_step: 13966, epoch: 150, loss: 0.212386
global_step: 13967, epoch: 150, loss: 0.179011
global_step: 13968, epoch: 150, loss: 0.197867
global_step: 13969, epoch: 150, loss: 0.220703
global_step: 13970, epoch: 150, loss: 0.289312
global_step: 13971, epoch: 150, loss: 0.231892
global_step: 13972, epoch: 150, loss: 0.228679
global_step: 13973, epoch: 150, loss: 0.207560
global_step: 13974, epoch: 150, loss: 0.183310
global_step: 13975, epoch: 150, loss: 0.168956
global_step: 13976, epoch: 150, loss: 0.207698
global_step: 13977, epoch: 150, loss: 0.215947
global_step: 13978, epoch: 150, loss: 0.194063
global_step: 13979, epoch: 150, loss: 0.213793
global_step: 13980, epoch: 150, loss: 0.314601
global_step: 13981, epoch: 150, loss: 0.167510
global_step: 13982, epoch: 150, loss: 0.261445
global_step: 13983, epoch: 150, loss: 0.212567
global_step: 13984, epoch: 150, loss: 0.293013
global_step: 13985, epoch: 150, loss: 0.279392
global_step: 13986, epoch: 150, loss: 0.250345
global_step: 13987, epoch: 150, loss: 0.245402
global_step: 13988, epoch: 150, loss: 0.217970
global_step: 13989, epoch: 150, loss: 0.247844
global_step: 13990, epoch: 150, loss: 0.233769
global_step: 13991, epoch: 150, loss: 0.181267
global_step: 13992, epoch: 150, loss: 0.175170
global_step: 13993, epoch: 150, loss: 0.221350
global_step: 13994, epoch: 150, loss: 0.222509
global_step: 13995, epoch: 150, loss: 0.166487
global_step: 13996, epoch: 150, loss: 0.253623
global_step: 13997, epoch: 150, loss: 0.196672
global_step: 13998, epoch: 150, loss: 0.186879
global_step: 13999, epoch: 150, loss: 0.205269
global_step: 14000, epoch: 150, loss: 0.129079
epoch: 150
train	acc: 0.9704	macro: p 0.9734, r 0.9605, f1: 0.9667	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5374	macro: p 0.3581, r 0.3106, f1: 0.3095	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4948
test	acc: 0.5816	macro: p 0.3852, r 0.3209, f1: 0.3291	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5469
global_step: 14001, epoch: 151, loss: 0.222350
global_step: 14002, epoch: 151, loss: 0.225911
global_step: 14003, epoch: 151, loss: 0.220833
global_step: 14004, epoch: 151, loss: 0.249200
global_step: 14005, epoch: 151, loss: 0.173003
global_step: 14006, epoch: 151, loss: 0.287268
global_step: 14007, epoch: 151, loss: 0.236001
global_step: 14008, epoch: 151, loss: 0.209341
global_step: 14009, epoch: 151, loss: 0.216588
global_step: 14010, epoch: 151, loss: 0.202249
global_step: 14011, epoch: 151, loss: 0.213624
global_step: 14012, epoch: 151, loss: 0.225299
global_step: 14013, epoch: 151, loss: 0.160942
global_step: 14014, epoch: 151, loss: 0.235750
global_step: 14015, epoch: 151, loss: 0.168565
global_step: 14016, epoch: 151, loss: 0.218914
global_step: 14017, epoch: 151, loss: 0.200984
global_step: 14018, epoch: 151, loss: 0.197471
global_step: 14019, epoch: 151, loss: 0.260798
global_step: 14020, epoch: 151, loss: 0.177061
global_step: 14021, epoch: 151, loss: 0.200270
global_step: 14022, epoch: 151, loss: 0.256926
global_step: 14023, epoch: 151, loss: 0.242695
global_step: 14024, epoch: 151, loss: 0.276012
global_step: 14025, epoch: 151, loss: 0.267190
global_step: 14026, epoch: 151, loss: 0.226918
global_step: 14027, epoch: 151, loss: 0.245511
global_step: 14028, epoch: 151, loss: 0.203760
global_step: 14029, epoch: 151, loss: 0.251819
global_step: 14030, epoch: 151, loss: 0.249525
global_step: 14031, epoch: 151, loss: 0.195224
global_step: 14032, epoch: 151, loss: 0.247595
global_step: 14033, epoch: 151, loss: 0.219404
global_step: 14034, epoch: 151, loss: 0.205680
global_step: 14035, epoch: 151, loss: 0.228059
global_step: 14036, epoch: 151, loss: 0.169588
global_step: 14037, epoch: 151, loss: 0.195873
global_step: 14038, epoch: 151, loss: 0.212943
global_step: 14039, epoch: 151, loss: 0.251060
global_step: 14040, epoch: 151, loss: 0.015721
epoch: 151
train	acc: 0.9709	macro: p 0.9737, r 0.9601, f1: 0.9666	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5464	macro: p 0.3823, r 0.3170, f1: 0.3191	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5014
test	acc: 0.5797	macro: p 0.3863, r 0.3183, f1: 0.3275	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5432
global_step: 14041, epoch: 152, loss: 0.252759
global_step: 14042, epoch: 152, loss: 0.192848
global_step: 14043, epoch: 152, loss: 0.218731
global_step: 14044, epoch: 152, loss: 0.251988
global_step: 14045, epoch: 152, loss: 0.236764
global_step: 14046, epoch: 152, loss: 0.225341
global_step: 14047, epoch: 152, loss: 0.237690
global_step: 14048, epoch: 152, loss: 0.179736
global_step: 14049, epoch: 152, loss: 0.219397
global_step: 14050, epoch: 152, loss: 0.206594
global_step: 14051, epoch: 152, loss: 0.181215
global_step: 14052, epoch: 152, loss: 0.211802
global_step: 14053, epoch: 152, loss: 0.150356
global_step: 14054, epoch: 152, loss: 0.213451
global_step: 14055, epoch: 152, loss: 0.215293
global_step: 14056, epoch: 152, loss: 0.258366
global_step: 14057, epoch: 152, loss: 0.251340
global_step: 14058, epoch: 152, loss: 0.245130
global_step: 14059, epoch: 152, loss: 0.164033
global_step: 14060, epoch: 152, loss: 0.169856
global_step: 14061, epoch: 152, loss: 0.241190
global_step: 14062, epoch: 152, loss: 0.266577
global_step: 14063, epoch: 152, loss: 0.201816
global_step: 14064, epoch: 152, loss: 0.179149
global_step: 14065, epoch: 152, loss: 0.245515
global_step: 14066, epoch: 152, loss: 0.217858
global_step: 14067, epoch: 152, loss: 0.165984
global_step: 14068, epoch: 152, loss: 0.254844
global_step: 14069, epoch: 152, loss: 0.224901
global_step: 14070, epoch: 152, loss: 0.200802
global_step: 14071, epoch: 152, loss: 0.247627
global_step: 14072, epoch: 152, loss: 0.201060
global_step: 14073, epoch: 152, loss: 0.199586
global_step: 14074, epoch: 152, loss: 0.237265
global_step: 14075, epoch: 152, loss: 0.275786
global_step: 14076, epoch: 152, loss: 0.305949
global_step: 14077, epoch: 152, loss: 0.167386
global_step: 14078, epoch: 152, loss: 0.284304
global_step: 14079, epoch: 152, loss: 0.254602
global_step: 14080, epoch: 152, loss: 0.166462
epoch: 152
train	acc: 0.9707	macro: p 0.9744, r 0.9602, f1: 0.9671	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5338	macro: p 0.3820, r 0.3066, f1: 0.3094	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4896
test	acc: 0.5828	macro: p 0.3540, r 0.3156, f1: 0.3213	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5453
global_step: 14081, epoch: 153, loss: 0.240758
global_step: 14082, epoch: 153, loss: 0.184087
global_step: 14083, epoch: 153, loss: 0.172634
global_step: 14084, epoch: 153, loss: 0.222973
global_step: 14085, epoch: 153, loss: 0.245166
global_step: 14086, epoch: 153, loss: 0.164896
global_step: 14087, epoch: 153, loss: 0.201793
global_step: 14088, epoch: 153, loss: 0.240337
global_step: 14089, epoch: 153, loss: 0.183934
global_step: 14090, epoch: 153, loss: 0.124554
global_step: 14091, epoch: 153, loss: 0.205299
global_step: 14092, epoch: 153, loss: 0.267073
global_step: 14093, epoch: 153, loss: 0.225249
global_step: 14094, epoch: 153, loss: 0.207960
global_step: 14095, epoch: 153, loss: 0.198163
global_step: 14096, epoch: 153, loss: 0.214003
global_step: 14097, epoch: 153, loss: 0.249389
global_step: 14098, epoch: 153, loss: 0.254286
global_step: 14099, epoch: 153, loss: 0.268716
global_step: 14100, epoch: 153, loss: 0.185741
global_step: 14101, epoch: 153, loss: 0.260485
global_step: 14102, epoch: 153, loss: 0.266655
global_step: 14103, epoch: 153, loss: 0.305434
global_step: 14104, epoch: 153, loss: 0.229966
global_step: 14105, epoch: 153, loss: 0.218774
global_step: 14106, epoch: 153, loss: 0.241205
global_step: 14107, epoch: 153, loss: 0.255398
global_step: 14108, epoch: 153, loss: 0.254978
global_step: 14109, epoch: 153, loss: 0.273749
global_step: 14110, epoch: 153, loss: 0.210115
global_step: 14111, epoch: 153, loss: 0.205751
global_step: 14112, epoch: 153, loss: 0.267106
global_step: 14113, epoch: 153, loss: 0.185780
global_step: 14114, epoch: 153, loss: 0.237836
global_step: 14115, epoch: 153, loss: 0.205555
global_step: 14116, epoch: 153, loss: 0.268715
global_step: 14117, epoch: 153, loss: 0.254920
global_step: 14118, epoch: 153, loss: 0.283984
global_step: 14119, epoch: 153, loss: 0.249937
global_step: 14120, epoch: 153, loss: 0.129468
epoch: 153
train	acc: 0.9708	macro: p 0.9745, r 0.9598, f1: 0.9669	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5410	macro: p 0.3760, r 0.3164, f1: 0.3177	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4983
test	acc: 0.5774	macro: p 0.3638, r 0.3128, f1: 0.3203	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5401
global_step: 14121, epoch: 154, loss: 0.197457
global_step: 14122, epoch: 154, loss: 0.208415
global_step: 14123, epoch: 154, loss: 0.216956
global_step: 14124, epoch: 154, loss: 0.261729
global_step: 14125, epoch: 154, loss: 0.259726
global_step: 14126, epoch: 154, loss: 0.166090
global_step: 14127, epoch: 154, loss: 0.229188
global_step: 14128, epoch: 154, loss: 0.228259
global_step: 14129, epoch: 154, loss: 0.254032
global_step: 14130, epoch: 154, loss: 0.298815
global_step: 14131, epoch: 154, loss: 0.220437
global_step: 14132, epoch: 154, loss: 0.212381
global_step: 14133, epoch: 154, loss: 0.270377
global_step: 14134, epoch: 154, loss: 0.217661
global_step: 14135, epoch: 154, loss: 0.197167
global_step: 14136, epoch: 154, loss: 0.223057
global_step: 14137, epoch: 154, loss: 0.197666
global_step: 14138, epoch: 154, loss: 0.152525
global_step: 14139, epoch: 154, loss: 0.178012
global_step: 14140, epoch: 154, loss: 0.352801
global_step: 14141, epoch: 154, loss: 0.309426
global_step: 14142, epoch: 154, loss: 0.205648
global_step: 14143, epoch: 154, loss: 0.246483
global_step: 14144, epoch: 154, loss: 0.245655
global_step: 14145, epoch: 154, loss: 0.288020
global_step: 14146, epoch: 154, loss: 0.266086
global_step: 14147, epoch: 154, loss: 0.212419
global_step: 14148, epoch: 154, loss: 0.281234
global_step: 14149, epoch: 154, loss: 0.198001
global_step: 14150, epoch: 154, loss: 0.164431
global_step: 14151, epoch: 154, loss: 0.205976
global_step: 14152, epoch: 154, loss: 0.230960
global_step: 14153, epoch: 154, loss: 0.212649
global_step: 14154, epoch: 154, loss: 0.152799
global_step: 14155, epoch: 154, loss: 0.260929
global_step: 14156, epoch: 154, loss: 0.239874
global_step: 14157, epoch: 154, loss: 0.213090
global_step: 14158, epoch: 154, loss: 0.212072
global_step: 14159, epoch: 154, loss: 0.220532
global_step: 14160, epoch: 154, loss: 0.692174
epoch: 154
train	acc: 0.9683	macro: p 0.9756, r 0.9551, f1: 0.9650	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9682
dev	acc: 0.5374	macro: p 0.3980, r 0.3093, f1: 0.3128	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4927
test	acc: 0.5816	macro: p 0.3882, r 0.3115, f1: 0.3236	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5422
global_step: 14161, epoch: 155, loss: 0.192327
global_step: 14162, epoch: 155, loss: 0.198371
global_step: 14163, epoch: 155, loss: 0.231587
global_step: 14164, epoch: 155, loss: 0.240865
global_step: 14165, epoch: 155, loss: 0.182690
global_step: 14166, epoch: 155, loss: 0.256813
global_step: 14167, epoch: 155, loss: 0.165781
global_step: 14168, epoch: 155, loss: 0.217545
global_step: 14169, epoch: 155, loss: 0.254369
global_step: 14170, epoch: 155, loss: 0.260494
global_step: 14171, epoch: 155, loss: 0.167951
global_step: 14172, epoch: 155, loss: 0.320095
global_step: 14173, epoch: 155, loss: 0.272515
global_step: 14174, epoch: 155, loss: 0.185614
global_step: 14175, epoch: 155, loss: 0.225096
global_step: 14176, epoch: 155, loss: 0.306375
global_step: 14177, epoch: 155, loss: 0.229482
global_step: 14178, epoch: 155, loss: 0.252549
global_step: 14179, epoch: 155, loss: 0.264382
global_step: 14180, epoch: 155, loss: 0.193835
global_step: 14181, epoch: 155, loss: 0.225036
global_step: 14182, epoch: 155, loss: 0.277463
global_step: 14183, epoch: 155, loss: 0.196055
global_step: 14184, epoch: 155, loss: 0.243805
global_step: 14185, epoch: 155, loss: 0.156482
global_step: 14186, epoch: 155, loss: 0.161269
global_step: 14187, epoch: 155, loss: 0.215368
global_step: 14188, epoch: 155, loss: 0.266089
global_step: 14189, epoch: 155, loss: 0.200176
global_step: 14190, epoch: 155, loss: 0.269617
global_step: 14191, epoch: 155, loss: 0.223029
global_step: 14192, epoch: 155, loss: 0.220305
global_step: 14193, epoch: 155, loss: 0.186791
global_step: 14194, epoch: 155, loss: 0.279202
global_step: 14195, epoch: 155, loss: 0.188791
global_step: 14196, epoch: 155, loss: 0.210598
global_step: 14197, epoch: 155, loss: 0.230661
global_step: 14198, epoch: 155, loss: 0.279596
global_step: 14199, epoch: 155, loss: 0.196610
global_step: 14200, epoch: 155, loss: 0.130299
epoch: 155
train	acc: 0.9707	macro: p 0.9736, r 0.9607, f1: 0.9669	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5473	macro: p 0.3856, r 0.3225, f1: 0.3244	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5045
test	acc: 0.5797	macro: p 0.3652, r 0.3161, f1: 0.3216	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5422
global_step: 14201, epoch: 156, loss: 0.189664
global_step: 14202, epoch: 156, loss: 0.224798
global_step: 14203, epoch: 156, loss: 0.196487
global_step: 14204, epoch: 156, loss: 0.220227
global_step: 14205, epoch: 156, loss: 0.195672
global_step: 14206, epoch: 156, loss: 0.204381
global_step: 14207, epoch: 156, loss: 0.249877
global_step: 14208, epoch: 156, loss: 0.221050
global_step: 14209, epoch: 156, loss: 0.203304
global_step: 14210, epoch: 156, loss: 0.211684
global_step: 14211, epoch: 156, loss: 0.203091
global_step: 14212, epoch: 156, loss: 0.245718
global_step: 14213, epoch: 156, loss: 0.228044
global_step: 14214, epoch: 156, loss: 0.181011
global_step: 14215, epoch: 156, loss: 0.298077
global_step: 14216, epoch: 156, loss: 0.182030
global_step: 14217, epoch: 156, loss: 0.214102
global_step: 14218, epoch: 156, loss: 0.176917
global_step: 14219, epoch: 156, loss: 0.166959
global_step: 14220, epoch: 156, loss: 0.197682
global_step: 14221, epoch: 156, loss: 0.251540
global_step: 14222, epoch: 156, loss: 0.295359
global_step: 14223, epoch: 156, loss: 0.253702
global_step: 14224, epoch: 156, loss: 0.261590
global_step: 14225, epoch: 156, loss: 0.167294
global_step: 14226, epoch: 156, loss: 0.245676
global_step: 14227, epoch: 156, loss: 0.195210
global_step: 14228, epoch: 156, loss: 0.273652
global_step: 14229, epoch: 156, loss: 0.194770
global_step: 14230, epoch: 156, loss: 0.234502
global_step: 14231, epoch: 156, loss: 0.221464
global_step: 14232, epoch: 156, loss: 0.181174
global_step: 14233, epoch: 156, loss: 0.243255
global_step: 14234, epoch: 156, loss: 0.199363
global_step: 14235, epoch: 156, loss: 0.198446
global_step: 14236, epoch: 156, loss: 0.313724
global_step: 14237, epoch: 156, loss: 0.284953
global_step: 14238, epoch: 156, loss: 0.164301
global_step: 14239, epoch: 156, loss: 0.258978
global_step: 14240, epoch: 156, loss: 0.108079
epoch: 156
train	acc: 0.9710	macro: p 0.9748, r 0.9595, f1: 0.9669	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5455	macro: p 0.3970, r 0.3148, f1: 0.3172	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4990
test	acc: 0.5831	macro: p 0.3768, r 0.3096, f1: 0.3185	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5395
global_step: 14241, epoch: 157, loss: 0.183596
global_step: 14242, epoch: 157, loss: 0.173224
global_step: 14243, epoch: 157, loss: 0.241982
global_step: 14244, epoch: 157, loss: 0.288719
global_step: 14245, epoch: 157, loss: 0.202381
global_step: 14246, epoch: 157, loss: 0.222271
global_step: 14247, epoch: 157, loss: 0.153660
global_step: 14248, epoch: 157, loss: 0.224180
global_step: 14249, epoch: 157, loss: 0.208590
global_step: 14250, epoch: 157, loss: 0.203014
global_step: 14251, epoch: 157, loss: 0.202385
global_step: 14252, epoch: 157, loss: 0.144753
global_step: 14253, epoch: 157, loss: 0.193417
global_step: 14254, epoch: 157, loss: 0.148698
global_step: 14255, epoch: 157, loss: 0.200061
global_step: 14256, epoch: 157, loss: 0.210858
global_step: 14257, epoch: 157, loss: 0.228583
global_step: 14258, epoch: 157, loss: 0.252897
global_step: 14259, epoch: 157, loss: 0.205907
global_step: 14260, epoch: 157, loss: 0.259715
global_step: 14261, epoch: 157, loss: 0.289359
global_step: 14262, epoch: 157, loss: 0.196737
global_step: 14263, epoch: 157, loss: 0.219158
global_step: 14264, epoch: 157, loss: 0.188374
global_step: 14265, epoch: 157, loss: 0.204312
global_step: 14266, epoch: 157, loss: 0.155555
global_step: 14267, epoch: 157, loss: 0.200146
global_step: 14268, epoch: 157, loss: 0.253620
global_step: 14269, epoch: 157, loss: 0.228004
global_step: 14270, epoch: 157, loss: 0.191981
global_step: 14271, epoch: 157, loss: 0.206542
global_step: 14272, epoch: 157, loss: 0.182789
global_step: 14273, epoch: 157, loss: 0.184762
global_step: 14274, epoch: 157, loss: 0.219241
global_step: 14275, epoch: 157, loss: 0.182589
global_step: 14276, epoch: 157, loss: 0.214751
global_step: 14277, epoch: 157, loss: 0.188598
global_step: 14278, epoch: 157, loss: 0.241104
global_step: 14279, epoch: 157, loss: 0.189718
global_step: 14280, epoch: 157, loss: 0.514704
epoch: 157
train	acc: 0.9696	macro: p 0.9744, r 0.9568, f1: 0.9652	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5437	macro: p 0.3702, r 0.3140, f1: 0.3146	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4984
test	acc: 0.5851	macro: p 0.3764, r 0.3176, f1: 0.3269	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5480
global_step: 14281, epoch: 158, loss: 0.240430
global_step: 14282, epoch: 158, loss: 0.264832
global_step: 14283, epoch: 158, loss: 0.207778
global_step: 14284, epoch: 158, loss: 0.250704
global_step: 14285, epoch: 158, loss: 0.186221
global_step: 14286, epoch: 158, loss: 0.237319
global_step: 14287, epoch: 158, loss: 0.232556
global_step: 14288, epoch: 158, loss: 0.178148
global_step: 14289, epoch: 158, loss: 0.258534
global_step: 14290, epoch: 158, loss: 0.207090
global_step: 14291, epoch: 158, loss: 0.152724
global_step: 14292, epoch: 158, loss: 0.196805
global_step: 14293, epoch: 158, loss: 0.248427
global_step: 14294, epoch: 158, loss: 0.153782
global_step: 14295, epoch: 158, loss: 0.203884
global_step: 14296, epoch: 158, loss: 0.249619
global_step: 14297, epoch: 158, loss: 0.223028
global_step: 14298, epoch: 158, loss: 0.245897
global_step: 14299, epoch: 158, loss: 0.181542
global_step: 14300, epoch: 158, loss: 0.187209
global_step: 14301, epoch: 158, loss: 0.207582
global_step: 14302, epoch: 158, loss: 0.253316
global_step: 14303, epoch: 158, loss: 0.200101
global_step: 14304, epoch: 158, loss: 0.241386
global_step: 14305, epoch: 158, loss: 0.189109
global_step: 14306, epoch: 158, loss: 0.197088
global_step: 14307, epoch: 158, loss: 0.223342
global_step: 14308, epoch: 158, loss: 0.236670
global_step: 14309, epoch: 158, loss: 0.238178
global_step: 14310, epoch: 158, loss: 0.191229
global_step: 14311, epoch: 158, loss: 0.228279
global_step: 14312, epoch: 158, loss: 0.191510
global_step: 14313, epoch: 158, loss: 0.274487
global_step: 14314, epoch: 158, loss: 0.189302
global_step: 14315, epoch: 158, loss: 0.222796
global_step: 14316, epoch: 158, loss: 0.184339
global_step: 14317, epoch: 158, loss: 0.233757
global_step: 14318, epoch: 158, loss: 0.166242
global_step: 14319, epoch: 158, loss: 0.219751
global_step: 14320, epoch: 158, loss: 0.026283
epoch: 158
train	acc: 0.9712	macro: p 0.9742, r 0.9609, f1: 0.9674	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5491	macro: p 0.3900, r 0.3245, f1: 0.3296	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5095
test	acc: 0.5797	macro: p 0.3684, r 0.3150, f1: 0.3244	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5442
global_step: 14321, epoch: 159, loss: 0.270339
global_step: 14322, epoch: 159, loss: 0.241100
global_step: 14323, epoch: 159, loss: 0.196353
global_step: 14324, epoch: 159, loss: 0.199711
global_step: 14325, epoch: 159, loss: 0.176911
global_step: 14326, epoch: 159, loss: 0.226954
global_step: 14327, epoch: 159, loss: 0.197468
global_step: 14328, epoch: 159, loss: 0.207612
global_step: 14329, epoch: 159, loss: 0.227032
global_step: 14330, epoch: 159, loss: 0.185186
global_step: 14331, epoch: 159, loss: 0.225957
global_step: 14332, epoch: 159, loss: 0.202870
global_step: 14333, epoch: 159, loss: 0.204677
global_step: 14334, epoch: 159, loss: 0.297816
global_step: 14335, epoch: 159, loss: 0.179085
global_step: 14336, epoch: 159, loss: 0.186611
global_step: 14337, epoch: 159, loss: 0.152490
global_step: 14338, epoch: 159, loss: 0.222474
global_step: 14339, epoch: 159, loss: 0.265618
global_step: 14340, epoch: 159, loss: 0.209386
global_step: 14341, epoch: 159, loss: 0.231889
global_step: 14342, epoch: 159, loss: 0.191422
global_step: 14343, epoch: 159, loss: 0.178903
global_step: 14344, epoch: 159, loss: 0.215637
global_step: 14345, epoch: 159, loss: 0.247861
global_step: 14346, epoch: 159, loss: 0.210572
global_step: 14347, epoch: 159, loss: 0.186439
global_step: 14348, epoch: 159, loss: 0.275748
global_step: 14349, epoch: 159, loss: 0.218783
global_step: 14350, epoch: 159, loss: 0.227842
global_step: 14351, epoch: 159, loss: 0.224010
global_step: 14352, epoch: 159, loss: 0.232551
global_step: 14353, epoch: 159, loss: 0.165577
global_step: 14354, epoch: 159, loss: 0.181586
global_step: 14355, epoch: 159, loss: 0.178820
global_step: 14356, epoch: 159, loss: 0.179936
global_step: 14357, epoch: 159, loss: 0.179819
global_step: 14358, epoch: 159, loss: 0.305449
global_step: 14359, epoch: 159, loss: 0.206702
global_step: 14360, epoch: 159, loss: 0.030931
epoch: 159
train	acc: 0.9715	macro: p 0.9750, r 0.9606, f1: 0.9675	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5446	macro: p 0.3776, r 0.3180, f1: 0.3204	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5023
test	acc: 0.5793	macro: p 0.3706, r 0.3129, f1: 0.3207	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5398
global_step: 14361, epoch: 160, loss: 0.193706
global_step: 14362, epoch: 160, loss: 0.216434
global_step: 14363, epoch: 160, loss: 0.214721
global_step: 14364, epoch: 160, loss: 0.241180
global_step: 14365, epoch: 160, loss: 0.227553
global_step: 14366, epoch: 160, loss: 0.295201
global_step: 14367, epoch: 160, loss: 0.179797
global_step: 14368, epoch: 160, loss: 0.172310
global_step: 14369, epoch: 160, loss: 0.233796
global_step: 14370, epoch: 160, loss: 0.199080
global_step: 14371, epoch: 160, loss: 0.274514
global_step: 14372, epoch: 160, loss: 0.205977
global_step: 14373, epoch: 160, loss: 0.181236
global_step: 14374, epoch: 160, loss: 0.182034
global_step: 14375, epoch: 160, loss: 0.177949
global_step: 14376, epoch: 160, loss: 0.166324
global_step: 14377, epoch: 160, loss: 0.161156
global_step: 14378, epoch: 160, loss: 0.239136
global_step: 14379, epoch: 160, loss: 0.206124
global_step: 14380, epoch: 160, loss: 0.194858
global_step: 14381, epoch: 160, loss: 0.186500
global_step: 14382, epoch: 160, loss: 0.188100
global_step: 14383, epoch: 160, loss: 0.168760
global_step: 14384, epoch: 160, loss: 0.209716
global_step: 14385, epoch: 160, loss: 0.235415
global_step: 14386, epoch: 160, loss: 0.231475
global_step: 14387, epoch: 160, loss: 0.218123
global_step: 14388, epoch: 160, loss: 0.227165
global_step: 14389, epoch: 160, loss: 0.171323
global_step: 14390, epoch: 160, loss: 0.181587
global_step: 14391, epoch: 160, loss: 0.172968
global_step: 14392, epoch: 160, loss: 0.252312
global_step: 14393, epoch: 160, loss: 0.203109
global_step: 14394, epoch: 160, loss: 0.216409
global_step: 14395, epoch: 160, loss: 0.297583
global_step: 14396, epoch: 160, loss: 0.248256
global_step: 14397, epoch: 160, loss: 0.195311
global_step: 14398, epoch: 160, loss: 0.222991
global_step: 14399, epoch: 160, loss: 0.250281
global_step: 14400, epoch: 160, loss: 0.147997
epoch: 160
train	acc: 0.9702	macro: p 0.9758, r 0.9586, f1: 0.9669	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5419	macro: p 0.3784, r 0.3149, f1: 0.3195	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4984
test	acc: 0.5770	macro: p 0.3770, r 0.3114, f1: 0.3247	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5382
global_step: 14401, epoch: 161, loss: 0.170130
global_step: 14402, epoch: 161, loss: 0.205247
global_step: 14403, epoch: 161, loss: 0.219037
global_step: 14404, epoch: 161, loss: 0.207462
global_step: 14405, epoch: 161, loss: 0.205700
global_step: 14406, epoch: 161, loss: 0.244003
global_step: 14407, epoch: 161, loss: 0.226550
global_step: 14408, epoch: 161, loss: 0.222500
global_step: 14409, epoch: 161, loss: 0.155286
global_step: 14410, epoch: 161, loss: 0.156087
global_step: 14411, epoch: 161, loss: 0.205097
global_step: 14412, epoch: 161, loss: 0.197347
global_step: 14413, epoch: 161, loss: 0.202007
global_step: 14414, epoch: 161, loss: 0.158566
global_step: 14415, epoch: 161, loss: 0.256501
global_step: 14416, epoch: 161, loss: 0.203571
global_step: 14417, epoch: 161, loss: 0.206218
global_step: 14418, epoch: 161, loss: 0.194068
global_step: 14419, epoch: 161, loss: 0.256466
global_step: 14420, epoch: 161, loss: 0.194930
global_step: 14421, epoch: 161, loss: 0.214523
global_step: 14422, epoch: 161, loss: 0.193281
global_step: 14423, epoch: 161, loss: 0.214258
global_step: 14424, epoch: 161, loss: 0.268753
global_step: 14425, epoch: 161, loss: 0.223399
global_step: 14426, epoch: 161, loss: 0.213567
global_step: 14427, epoch: 161, loss: 0.165789
global_step: 14428, epoch: 161, loss: 0.163542
global_step: 14429, epoch: 161, loss: 0.149995
global_step: 14430, epoch: 161, loss: 0.208882
global_step: 14431, epoch: 161, loss: 0.173691
global_step: 14432, epoch: 161, loss: 0.189804
global_step: 14433, epoch: 161, loss: 0.256358
global_step: 14434, epoch: 161, loss: 0.301737
global_step: 14435, epoch: 161, loss: 0.252247
global_step: 14436, epoch: 161, loss: 0.183570
global_step: 14437, epoch: 161, loss: 0.200320
global_step: 14438, epoch: 161, loss: 0.190899
global_step: 14439, epoch: 161, loss: 0.181158
global_step: 14440, epoch: 161, loss: 0.458699
epoch: 161
train	acc: 0.9713	macro: p 0.9747, r 0.9607, f1: 0.9675	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5383	macro: p 0.3797, r 0.3189, f1: 0.3223	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4996
test	acc: 0.5797	macro: p 0.3779, r 0.3232, f1: 0.3333	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5470
global_step: 14441, epoch: 162, loss: 0.264786
global_step: 14442, epoch: 162, loss: 0.192843
global_step: 14443, epoch: 162, loss: 0.242801
global_step: 14444, epoch: 162, loss: 0.106601
global_step: 14445, epoch: 162, loss: 0.237362
global_step: 14446, epoch: 162, loss: 0.211669
global_step: 14447, epoch: 162, loss: 0.265382
global_step: 14448, epoch: 162, loss: 0.188460
global_step: 14449, epoch: 162, loss: 0.178314
global_step: 14450, epoch: 162, loss: 0.234741
global_step: 14451, epoch: 162, loss: 0.291879
global_step: 14452, epoch: 162, loss: 0.267445
global_step: 14453, epoch: 162, loss: 0.251634
global_step: 14454, epoch: 162, loss: 0.222568
global_step: 14455, epoch: 162, loss: 0.259326
global_step: 14456, epoch: 162, loss: 0.151634
global_step: 14457, epoch: 162, loss: 0.174512
global_step: 14458, epoch: 162, loss: 0.172868
global_step: 14459, epoch: 162, loss: 0.234155
global_step: 14460, epoch: 162, loss: 0.214762
global_step: 14461, epoch: 162, loss: 0.193871
global_step: 14462, epoch: 162, loss: 0.227228
global_step: 14463, epoch: 162, loss: 0.167804
global_step: 14464, epoch: 162, loss: 0.194276
global_step: 14465, epoch: 162, loss: 0.184019
global_step: 14466, epoch: 162, loss: 0.149578
global_step: 14467, epoch: 162, loss: 0.199907
global_step: 14468, epoch: 162, loss: 0.178110
global_step: 14469, epoch: 162, loss: 0.300692
global_step: 14470, epoch: 162, loss: 0.192369
global_step: 14471, epoch: 162, loss: 0.210452
global_step: 14472, epoch: 162, loss: 0.235532
global_step: 14473, epoch: 162, loss: 0.264000
global_step: 14474, epoch: 162, loss: 0.271837
global_step: 14475, epoch: 162, loss: 0.195080
global_step: 14476, epoch: 162, loss: 0.183334
global_step: 14477, epoch: 162, loss: 0.257545
global_step: 14478, epoch: 162, loss: 0.239066
global_step: 14479, epoch: 162, loss: 0.292190
global_step: 14480, epoch: 162, loss: 0.125764
epoch: 162
train	acc: 0.9714	macro: p 0.9746, r 0.9610, f1: 0.9676	micro: p 0.9714, r 0.9714, f1 0.9714	weighted_f1:0.9714
dev	acc: 0.5410	macro: p 0.3775, r 0.3194, f1: 0.3263	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5001
test	acc: 0.5812	macro: p 0.3768, r 0.3155, f1: 0.3290	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5428
global_step: 14481, epoch: 163, loss: 0.246279
global_step: 14482, epoch: 163, loss: 0.239832
global_step: 14483, epoch: 163, loss: 0.244612
global_step: 14484, epoch: 163, loss: 0.208743
global_step: 14485, epoch: 163, loss: 0.217141
global_step: 14486, epoch: 163, loss: 0.200874
global_step: 14487, epoch: 163, loss: 0.195894
global_step: 14488, epoch: 163, loss: 0.145527
global_step: 14489, epoch: 163, loss: 0.158393
global_step: 14490, epoch: 163, loss: 0.209517
global_step: 14491, epoch: 163, loss: 0.199397
global_step: 14492, epoch: 163, loss: 0.191996
global_step: 14493, epoch: 163, loss: 0.249498
global_step: 14494, epoch: 163, loss: 0.201435
global_step: 14495, epoch: 163, loss: 0.194548
global_step: 14496, epoch: 163, loss: 0.147891
global_step: 14497, epoch: 163, loss: 0.242855
global_step: 14498, epoch: 163, loss: 0.136461
global_step: 14499, epoch: 163, loss: 0.167707
global_step: 14500, epoch: 163, loss: 0.263385
global_step: 14501, epoch: 163, loss: 0.231231
global_step: 14502, epoch: 163, loss: 0.165077
global_step: 14503, epoch: 163, loss: 0.199629
global_step: 14504, epoch: 163, loss: 0.187609
global_step: 14505, epoch: 163, loss: 0.218991
global_step: 14506, epoch: 163, loss: 0.152301
global_step: 14507, epoch: 163, loss: 0.207578
global_step: 14508, epoch: 163, loss: 0.166859
global_step: 14509, epoch: 163, loss: 0.177299
global_step: 14510, epoch: 163, loss: 0.202688
global_step: 14511, epoch: 163, loss: 0.173052
global_step: 14512, epoch: 163, loss: 0.209691
global_step: 14513, epoch: 163, loss: 0.208495
global_step: 14514, epoch: 163, loss: 0.209330
global_step: 14515, epoch: 163, loss: 0.198654
global_step: 14516, epoch: 163, loss: 0.259750
global_step: 14517, epoch: 163, loss: 0.192610
global_step: 14518, epoch: 163, loss: 0.123699
global_step: 14519, epoch: 163, loss: 0.207713
global_step: 14520, epoch: 163, loss: 0.232961
epoch: 163
train	acc: 0.9713	macro: p 0.9753, r 0.9610, f1: 0.9679	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5356	macro: p 0.3829, r 0.3147, f1: 0.3163	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4952
test	acc: 0.5828	macro: p 0.3998, r 0.3228, f1: 0.3318	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5485
global_step: 14521, epoch: 164, loss: 0.179156
global_step: 14522, epoch: 164, loss: 0.228927
global_step: 14523, epoch: 164, loss: 0.166992
global_step: 14524, epoch: 164, loss: 0.291648
global_step: 14525, epoch: 164, loss: 0.157465
global_step: 14526, epoch: 164, loss: 0.190855
global_step: 14527, epoch: 164, loss: 0.209125
global_step: 14528, epoch: 164, loss: 0.196297
global_step: 14529, epoch: 164, loss: 0.218339
global_step: 14530, epoch: 164, loss: 0.172151
global_step: 14531, epoch: 164, loss: 0.221297
global_step: 14532, epoch: 164, loss: 0.249241
global_step: 14533, epoch: 164, loss: 0.267819
global_step: 14534, epoch: 164, loss: 0.237009
global_step: 14535, epoch: 164, loss: 0.209759
global_step: 14536, epoch: 164, loss: 0.186543
global_step: 14537, epoch: 164, loss: 0.234791
global_step: 14538, epoch: 164, loss: 0.197686
global_step: 14539, epoch: 164, loss: 0.277846
global_step: 14540, epoch: 164, loss: 0.286459
global_step: 14541, epoch: 164, loss: 0.198832
global_step: 14542, epoch: 164, loss: 0.195822
global_step: 14543, epoch: 164, loss: 0.220602
global_step: 14544, epoch: 164, loss: 0.223541
global_step: 14545, epoch: 164, loss: 0.144610
global_step: 14546, epoch: 164, loss: 0.215955
global_step: 14547, epoch: 164, loss: 0.204875
global_step: 14548, epoch: 164, loss: 0.200856
global_step: 14549, epoch: 164, loss: 0.148703
global_step: 14550, epoch: 164, loss: 0.218888
global_step: 14551, epoch: 164, loss: 0.105913
global_step: 14552, epoch: 164, loss: 0.196416
global_step: 14553, epoch: 164, loss: 0.181493
global_step: 14554, epoch: 164, loss: 0.172033
global_step: 14555, epoch: 164, loss: 0.244587
global_step: 14556, epoch: 164, loss: 0.244446
global_step: 14557, epoch: 164, loss: 0.214213
global_step: 14558, epoch: 164, loss: 0.169956
global_step: 14559, epoch: 164, loss: 0.247708
global_step: 14560, epoch: 164, loss: 0.111091
epoch: 164
train	acc: 0.9719	macro: p 0.9749, r 0.9623, f1: 0.9684	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5455	macro: p 0.3943, r 0.3225, f1: 0.3271	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5051
test	acc: 0.5808	macro: p 0.3747, r 0.3192, f1: 0.3281	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5445
global_step: 14561, epoch: 165, loss: 0.191594
global_step: 14562, epoch: 165, loss: 0.145131
global_step: 14563, epoch: 165, loss: 0.173177
global_step: 14564, epoch: 165, loss: 0.224129
global_step: 14565, epoch: 165, loss: 0.162561
global_step: 14566, epoch: 165, loss: 0.236227
global_step: 14567, epoch: 165, loss: 0.150856
global_step: 14568, epoch: 165, loss: 0.202751
global_step: 14569, epoch: 165, loss: 0.196290
global_step: 14570, epoch: 165, loss: 0.199731
global_step: 14571, epoch: 165, loss: 0.178919
global_step: 14572, epoch: 165, loss: 0.176564
global_step: 14573, epoch: 165, loss: 0.161654
global_step: 14574, epoch: 165, loss: 0.203181
global_step: 14575, epoch: 165, loss: 0.185755
global_step: 14576, epoch: 165, loss: 0.178455
global_step: 14577, epoch: 165, loss: 0.193688
global_step: 14578, epoch: 165, loss: 0.228675
global_step: 14579, epoch: 165, loss: 0.249352
global_step: 14580, epoch: 165, loss: 0.186050
global_step: 14581, epoch: 165, loss: 0.264980
global_step: 14582, epoch: 165, loss: 0.222827
global_step: 14583, epoch: 165, loss: 0.211295
global_step: 14584, epoch: 165, loss: 0.304743
global_step: 14585, epoch: 165, loss: 0.224518
global_step: 14586, epoch: 165, loss: 0.215205
global_step: 14587, epoch: 165, loss: 0.222513
global_step: 14588, epoch: 165, loss: 0.260102
global_step: 14589, epoch: 165, loss: 0.207198
global_step: 14590, epoch: 165, loss: 0.226182
global_step: 14591, epoch: 165, loss: 0.158805
global_step: 14592, epoch: 165, loss: 0.275996
global_step: 14593, epoch: 165, loss: 0.196230
global_step: 14594, epoch: 165, loss: 0.235951
global_step: 14595, epoch: 165, loss: 0.190512
global_step: 14596, epoch: 165, loss: 0.203734
global_step: 14597, epoch: 165, loss: 0.226078
global_step: 14598, epoch: 165, loss: 0.144215
global_step: 14599, epoch: 165, loss: 0.234892
global_step: 14600, epoch: 165, loss: 0.131251
epoch: 165
train	acc: 0.9721	macro: p 0.9760, r 0.9621, f1: 0.9689	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5347	macro: p 0.3637, r 0.3171, f1: 0.3182	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4957
test	acc: 0.5805	macro: p 0.3812, r 0.3200, f1: 0.3273	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5453
global_step: 14601, epoch: 166, loss: 0.160613
global_step: 14602, epoch: 166, loss: 0.151528
global_step: 14603, epoch: 166, loss: 0.261771
global_step: 14604, epoch: 166, loss: 0.231489
global_step: 14605, epoch: 166, loss: 0.182437
global_step: 14606, epoch: 166, loss: 0.256344
global_step: 14607, epoch: 166, loss: 0.147759
global_step: 14608, epoch: 166, loss: 0.206792
global_step: 14609, epoch: 166, loss: 0.255273
global_step: 14610, epoch: 166, loss: 0.211401
global_step: 14611, epoch: 166, loss: 0.201700
global_step: 14612, epoch: 166, loss: 0.237628
global_step: 14613, epoch: 166, loss: 0.251070
global_step: 14614, epoch: 166, loss: 0.204347
global_step: 14615, epoch: 166, loss: 0.163335
global_step: 14616, epoch: 166, loss: 0.198622
global_step: 14617, epoch: 166, loss: 0.176836
global_step: 14618, epoch: 166, loss: 0.188135
global_step: 14619, epoch: 166, loss: 0.166525
global_step: 14620, epoch: 166, loss: 0.200513
global_step: 14621, epoch: 166, loss: 0.154658
global_step: 14622, epoch: 166, loss: 0.235560
global_step: 14623, epoch: 166, loss: 0.193986
global_step: 14624, epoch: 166, loss: 0.168116
global_step: 14625, epoch: 166, loss: 0.192100
global_step: 14626, epoch: 166, loss: 0.139290
global_step: 14627, epoch: 166, loss: 0.230615
global_step: 14628, epoch: 166, loss: 0.212428
global_step: 14629, epoch: 166, loss: 0.174431
global_step: 14630, epoch: 166, loss: 0.171231
global_step: 14631, epoch: 166, loss: 0.179759
global_step: 14632, epoch: 166, loss: 0.202805
global_step: 14633, epoch: 166, loss: 0.175539
global_step: 14634, epoch: 166, loss: 0.212147
global_step: 14635, epoch: 166, loss: 0.205944
global_step: 14636, epoch: 166, loss: 0.233146
global_step: 14637, epoch: 166, loss: 0.145592
global_step: 14638, epoch: 166, loss: 0.279343
global_step: 14639, epoch: 166, loss: 0.230538
global_step: 14640, epoch: 166, loss: 0.443741
epoch: 166
train	acc: 0.9712	macro: p 0.9737, r 0.9619, f1: 0.9676	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5482	macro: p 0.3887, r 0.3246, f1: 0.3276	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5061
test	acc: 0.5770	macro: p 0.3689, r 0.3184, f1: 0.3262	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5414
global_step: 14641, epoch: 167, loss: 0.219759
global_step: 14642, epoch: 167, loss: 0.174753
global_step: 14643, epoch: 167, loss: 0.198514
global_step: 14644, epoch: 167, loss: 0.207216
global_step: 14645, epoch: 167, loss: 0.145849
global_step: 14646, epoch: 167, loss: 0.133899
global_step: 14647, epoch: 167, loss: 0.187556
global_step: 14648, epoch: 167, loss: 0.153325
global_step: 14649, epoch: 167, loss: 0.164110
global_step: 14650, epoch: 167, loss: 0.254645
global_step: 14651, epoch: 167, loss: 0.251166
global_step: 14652, epoch: 167, loss: 0.149674
global_step: 14653, epoch: 167, loss: 0.256388
global_step: 14654, epoch: 167, loss: 0.204024
global_step: 14655, epoch: 167, loss: 0.226278
global_step: 14656, epoch: 167, loss: 0.267418
global_step: 14657, epoch: 167, loss: 0.170717
global_step: 14658, epoch: 167, loss: 0.187154
global_step: 14659, epoch: 167, loss: 0.257413
global_step: 14660, epoch: 167, loss: 0.212289
global_step: 14661, epoch: 167, loss: 0.238020
global_step: 14662, epoch: 167, loss: 0.154811
global_step: 14663, epoch: 167, loss: 0.194830
global_step: 14664, epoch: 167, loss: 0.203531
global_step: 14665, epoch: 167, loss: 0.180481
global_step: 14666, epoch: 167, loss: 0.230406
global_step: 14667, epoch: 167, loss: 0.171835
global_step: 14668, epoch: 167, loss: 0.204327
global_step: 14669, epoch: 167, loss: 0.230348
global_step: 14670, epoch: 167, loss: 0.161077
global_step: 14671, epoch: 167, loss: 0.215844
global_step: 14672, epoch: 167, loss: 0.277560
global_step: 14673, epoch: 167, loss: 0.231400
global_step: 14674, epoch: 167, loss: 0.235985
global_step: 14675, epoch: 167, loss: 0.220522
global_step: 14676, epoch: 167, loss: 0.160815
global_step: 14677, epoch: 167, loss: 0.259595
global_step: 14678, epoch: 167, loss: 0.167387
global_step: 14679, epoch: 167, loss: 0.248531
global_step: 14680, epoch: 167, loss: 0.104014
epoch: 167
train	acc: 0.9712	macro: p 0.9744, r 0.9617, f1: 0.9678	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5437	macro: p 0.3887, r 0.3219, f1: 0.3271	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5040
test	acc: 0.5816	macro: p 0.3722, r 0.3172, f1: 0.3238	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5429
global_step: 14681, epoch: 168, loss: 0.115861
global_step: 14682, epoch: 168, loss: 0.215758
global_step: 14683, epoch: 168, loss: 0.137661
global_step: 14684, epoch: 168, loss: 0.131265
global_step: 14685, epoch: 168, loss: 0.236601
global_step: 14686, epoch: 168, loss: 0.162269
global_step: 14687, epoch: 168, loss: 0.138903
global_step: 14688, epoch: 168, loss: 0.184953
global_step: 14689, epoch: 168, loss: 0.168515
global_step: 14690, epoch: 168, loss: 0.186466
global_step: 14691, epoch: 168, loss: 0.192978
global_step: 14692, epoch: 168, loss: 0.207097
global_step: 14693, epoch: 168, loss: 0.182606
global_step: 14694, epoch: 168, loss: 0.261371
global_step: 14695, epoch: 168, loss: 0.299218
global_step: 14696, epoch: 168, loss: 0.200338
global_step: 14697, epoch: 168, loss: 0.165047
global_step: 14698, epoch: 168, loss: 0.178605
global_step: 14699, epoch: 168, loss: 0.143384
global_step: 14700, epoch: 168, loss: 0.195522
global_step: 14701, epoch: 168, loss: 0.204409
global_step: 14702, epoch: 168, loss: 0.196929
global_step: 14703, epoch: 168, loss: 0.186468
global_step: 14704, epoch: 168, loss: 0.225266
global_step: 14705, epoch: 168, loss: 0.217708
global_step: 14706, epoch: 168, loss: 0.231578
global_step: 14707, epoch: 168, loss: 0.196590
global_step: 14708, epoch: 168, loss: 0.174343
global_step: 14709, epoch: 168, loss: 0.204062
global_step: 14710, epoch: 168, loss: 0.160302
global_step: 14711, epoch: 168, loss: 0.210328
global_step: 14712, epoch: 168, loss: 0.217345
global_step: 14713, epoch: 168, loss: 0.302267
global_step: 14714, epoch: 168, loss: 0.172913
global_step: 14715, epoch: 168, loss: 0.201621
global_step: 14716, epoch: 168, loss: 0.289585
global_step: 14717, epoch: 168, loss: 0.229766
global_step: 14718, epoch: 168, loss: 0.138650
global_step: 14719, epoch: 168, loss: 0.206587
global_step: 14720, epoch: 168, loss: 0.070051
epoch: 168
train	acc: 0.9716	macro: p 0.9750, r 0.9618, f1: 0.9682	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5464	macro: p 0.3787, r 0.3244, f1: 0.3298	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5084
test	acc: 0.5831	macro: p 0.3796, r 0.3238, f1: 0.3326	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5488
global_step: 14721, epoch: 169, loss: 0.235608
global_step: 14722, epoch: 169, loss: 0.133457
global_step: 14723, epoch: 169, loss: 0.168982
global_step: 14724, epoch: 169, loss: 0.243418
global_step: 14725, epoch: 169, loss: 0.176537
global_step: 14726, epoch: 169, loss: 0.162838
global_step: 14727, epoch: 169, loss: 0.168805
global_step: 14728, epoch: 169, loss: 0.152445
global_step: 14729, epoch: 169, loss: 0.203268
global_step: 14730, epoch: 169, loss: 0.248322
global_step: 14731, epoch: 169, loss: 0.189990
global_step: 14732, epoch: 169, loss: 0.227175
global_step: 14733, epoch: 169, loss: 0.241923
global_step: 14734, epoch: 169, loss: 0.180830
global_step: 14735, epoch: 169, loss: 0.208401
global_step: 14736, epoch: 169, loss: 0.187575
global_step: 14737, epoch: 169, loss: 0.193783
global_step: 14738, epoch: 169, loss: 0.149538
global_step: 14739, epoch: 169, loss: 0.184215
global_step: 14740, epoch: 169, loss: 0.214990
global_step: 14741, epoch: 169, loss: 0.234036
global_step: 14742, epoch: 169, loss: 0.176755
global_step: 14743, epoch: 169, loss: 0.178459
global_step: 14744, epoch: 169, loss: 0.208933
global_step: 14745, epoch: 169, loss: 0.196333
global_step: 14746, epoch: 169, loss: 0.271124
global_step: 14747, epoch: 169, loss: 0.169901
global_step: 14748, epoch: 169, loss: 0.201714
global_step: 14749, epoch: 169, loss: 0.166288
global_step: 14750, epoch: 169, loss: 0.204141
global_step: 14751, epoch: 169, loss: 0.186407
global_step: 14752, epoch: 169, loss: 0.212101
global_step: 14753, epoch: 169, loss: 0.181461
global_step: 14754, epoch: 169, loss: 0.161986
global_step: 14755, epoch: 169, loss: 0.199090
global_step: 14756, epoch: 169, loss: 0.216177
global_step: 14757, epoch: 169, loss: 0.176036
global_step: 14758, epoch: 169, loss: 0.227374
global_step: 14759, epoch: 169, loss: 0.186081
global_step: 14760, epoch: 169, loss: 1.388108
epoch: 169
train	acc: 0.9711	macro: p 0.9747, r 0.9604, f1: 0.9673	micro: p 0.9711, r 0.9711, f1 0.9711	weighted_f1:0.9711
dev	acc: 0.5428	macro: p 0.3762, r 0.3128, f1: 0.3174	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4984
test	acc: 0.5816	macro: p 0.3805, r 0.3119, f1: 0.3235	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5398
global_step: 14761, epoch: 170, loss: 0.176495
global_step: 14762, epoch: 170, loss: 0.300785
global_step: 14763, epoch: 170, loss: 0.173844
global_step: 14764, epoch: 170, loss: 0.218929
global_step: 14765, epoch: 170, loss: 0.254686
global_step: 14766, epoch: 170, loss: 0.187177
global_step: 14767, epoch: 170, loss: 0.216061
global_step: 14768, epoch: 170, loss: 0.287903
global_step: 14769, epoch: 170, loss: 0.205148
global_step: 14770, epoch: 170, loss: 0.191037
global_step: 14771, epoch: 170, loss: 0.215034
global_step: 14772, epoch: 170, loss: 0.289077
global_step: 14773, epoch: 170, loss: 0.183472
global_step: 14774, epoch: 170, loss: 0.125659
global_step: 14775, epoch: 170, loss: 0.197536
global_step: 14776, epoch: 170, loss: 0.197055
global_step: 14777, epoch: 170, loss: 0.191789
global_step: 14778, epoch: 170, loss: 0.188740
global_step: 14779, epoch: 170, loss: 0.200366
global_step: 14780, epoch: 170, loss: 0.184702
global_step: 14781, epoch: 170, loss: 0.182707
global_step: 14782, epoch: 170, loss: 0.169738
global_step: 14783, epoch: 170, loss: 0.116172
global_step: 14784, epoch: 170, loss: 0.217792
global_step: 14785, epoch: 170, loss: 0.204749
global_step: 14786, epoch: 170, loss: 0.171535
global_step: 14787, epoch: 170, loss: 0.167800
global_step: 14788, epoch: 170, loss: 0.240363
global_step: 14789, epoch: 170, loss: 0.182493
global_step: 14790, epoch: 170, loss: 0.181435
global_step: 14791, epoch: 170, loss: 0.258465
global_step: 14792, epoch: 170, loss: 0.224111
global_step: 14793, epoch: 170, loss: 0.295713
global_step: 14794, epoch: 170, loss: 0.203477
global_step: 14795, epoch: 170, loss: 0.219975
global_step: 14796, epoch: 170, loss: 0.209506
global_step: 14797, epoch: 170, loss: 0.253298
global_step: 14798, epoch: 170, loss: 0.152237
global_step: 14799, epoch: 170, loss: 0.205367
global_step: 14800, epoch: 170, loss: 0.013225
epoch: 170
train	acc: 0.9715	macro: p 0.9753, r 0.9607, f1: 0.9678	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5446	macro: p 0.3837, r 0.3198, f1: 0.3245	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5039
test	acc: 0.5789	macro: p 0.3690, r 0.3141, f1: 0.3220	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5418
global_step: 14801, epoch: 171, loss: 0.188251
global_step: 14802, epoch: 171, loss: 0.192970
global_step: 14803, epoch: 171, loss: 0.225991
global_step: 14804, epoch: 171, loss: 0.159683
global_step: 14805, epoch: 171, loss: 0.234261
global_step: 14806, epoch: 171, loss: 0.239985
global_step: 14807, epoch: 171, loss: 0.215105
global_step: 14808, epoch: 171, loss: 0.147064
global_step: 14809, epoch: 171, loss: 0.167771
global_step: 14810, epoch: 171, loss: 0.178191
global_step: 14811, epoch: 171, loss: 0.172348
global_step: 14812, epoch: 171, loss: 0.240457
global_step: 14813, epoch: 171, loss: 0.213353
global_step: 14814, epoch: 171, loss: 0.212234
global_step: 14815, epoch: 171, loss: 0.129505
global_step: 14816, epoch: 171, loss: 0.156313
global_step: 14817, epoch: 171, loss: 0.195040
global_step: 14818, epoch: 171, loss: 0.229183
global_step: 14819, epoch: 171, loss: 0.202941
global_step: 14820, epoch: 171, loss: 0.239699
global_step: 14821, epoch: 171, loss: 0.197411
global_step: 14822, epoch: 171, loss: 0.241770
global_step: 14823, epoch: 171, loss: 0.172076
global_step: 14824, epoch: 171, loss: 0.232991
global_step: 14825, epoch: 171, loss: 0.255251
global_step: 14826, epoch: 171, loss: 0.208407
global_step: 14827, epoch: 171, loss: 0.255387
global_step: 14828, epoch: 171, loss: 0.174084
global_step: 14829, epoch: 171, loss: 0.286043
global_step: 14830, epoch: 171, loss: 0.201049
global_step: 14831, epoch: 171, loss: 0.255465
global_step: 14832, epoch: 171, loss: 0.193828
global_step: 14833, epoch: 171, loss: 0.190476
global_step: 14834, epoch: 171, loss: 0.224836
global_step: 14835, epoch: 171, loss: 0.232894
global_step: 14836, epoch: 171, loss: 0.231425
global_step: 14837, epoch: 171, loss: 0.180036
global_step: 14838, epoch: 171, loss: 0.205820
global_step: 14839, epoch: 171, loss: 0.175985
global_step: 14840, epoch: 171, loss: 0.040060
epoch: 171
train	acc: 0.9712	macro: p 0.9752, r 0.9608, f1: 0.9678	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5491	macro: p 0.3710, r 0.3238, f1: 0.3268	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5093
test	acc: 0.5805	macro: p 0.3794, r 0.3196, f1: 0.3282	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5423
global_step: 14841, epoch: 172, loss: 0.233489
global_step: 14842, epoch: 172, loss: 0.145573
global_step: 14843, epoch: 172, loss: 0.158349
global_step: 14844, epoch: 172, loss: 0.196014
global_step: 14845, epoch: 172, loss: 0.182678
global_step: 14846, epoch: 172, loss: 0.174248
global_step: 14847, epoch: 172, loss: 0.174215
global_step: 14848, epoch: 172, loss: 0.159338
global_step: 14849, epoch: 172, loss: 0.203859
global_step: 14850, epoch: 172, loss: 0.228646
global_step: 14851, epoch: 172, loss: 0.172570
global_step: 14852, epoch: 172, loss: 0.253791
global_step: 14853, epoch: 172, loss: 0.224815
global_step: 14854, epoch: 172, loss: 0.219798
global_step: 14855, epoch: 172, loss: 0.226325
global_step: 14856, epoch: 172, loss: 0.212516
global_step: 14857, epoch: 172, loss: 0.128271
global_step: 14858, epoch: 172, loss: 0.198310
global_step: 14859, epoch: 172, loss: 0.209548
global_step: 14860, epoch: 172, loss: 0.215201
global_step: 14861, epoch: 172, loss: 0.206633
global_step: 14862, epoch: 172, loss: 0.211733
global_step: 14863, epoch: 172, loss: 0.190657
global_step: 14864, epoch: 172, loss: 0.218387
global_step: 14865, epoch: 172, loss: 0.139491
global_step: 14866, epoch: 172, loss: 0.190797
global_step: 14867, epoch: 172, loss: 0.229896
global_step: 14868, epoch: 172, loss: 0.189909
global_step: 14869, epoch: 172, loss: 0.205299
global_step: 14870, epoch: 172, loss: 0.245306
global_step: 14871, epoch: 172, loss: 0.210026
global_step: 14872, epoch: 172, loss: 0.172375
global_step: 14873, epoch: 172, loss: 0.191731
global_step: 14874, epoch: 172, loss: 0.231555
global_step: 14875, epoch: 172, loss: 0.180365
global_step: 14876, epoch: 172, loss: 0.239019
global_step: 14877, epoch: 172, loss: 0.159979
global_step: 14878, epoch: 172, loss: 0.271868
global_step: 14879, epoch: 172, loss: 0.244403
global_step: 14880, epoch: 172, loss: 0.076150
epoch: 172
train	acc: 0.9721	macro: p 0.9750, r 0.9630, f1: 0.9688	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5419	macro: p 0.3691, r 0.3205, f1: 0.3252	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5030
test	acc: 0.5778	macro: p 0.3720, r 0.3168, f1: 0.3251	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5436
global_step: 14881, epoch: 173, loss: 0.233142
global_step: 14882, epoch: 173, loss: 0.185534
global_step: 14883, epoch: 173, loss: 0.261557
global_step: 14884, epoch: 173, loss: 0.245937
global_step: 14885, epoch: 173, loss: 0.205081
global_step: 14886, epoch: 173, loss: 0.162553
global_step: 14887, epoch: 173, loss: 0.150852
global_step: 14888, epoch: 173, loss: 0.184533
global_step: 14889, epoch: 173, loss: 0.182987
global_step: 14890, epoch: 173, loss: 0.192368
global_step: 14891, epoch: 173, loss: 0.147478
global_step: 14892, epoch: 173, loss: 0.252386
global_step: 14893, epoch: 173, loss: 0.213620
global_step: 14894, epoch: 173, loss: 0.234555
global_step: 14895, epoch: 173, loss: 0.143261
global_step: 14896, epoch: 173, loss: 0.160998
global_step: 14897, epoch: 173, loss: 0.196456
global_step: 14898, epoch: 173, loss: 0.243199
global_step: 14899, epoch: 173, loss: 0.198335
global_step: 14900, epoch: 173, loss: 0.214686
global_step: 14901, epoch: 173, loss: 0.179833
global_step: 14902, epoch: 173, loss: 0.153052
global_step: 14903, epoch: 173, loss: 0.233103
global_step: 14904, epoch: 173, loss: 0.200995
global_step: 14905, epoch: 173, loss: 0.243066
global_step: 14906, epoch: 173, loss: 0.246732
global_step: 14907, epoch: 173, loss: 0.165903
global_step: 14908, epoch: 173, loss: 0.184309
global_step: 14909, epoch: 173, loss: 0.246840
global_step: 14910, epoch: 173, loss: 0.199773
global_step: 14911, epoch: 173, loss: 0.180207
global_step: 14912, epoch: 173, loss: 0.186538
global_step: 14913, epoch: 173, loss: 0.156367
global_step: 14914, epoch: 173, loss: 0.244594
global_step: 14915, epoch: 173, loss: 0.181794
global_step: 14916, epoch: 173, loss: 0.193278
global_step: 14917, epoch: 173, loss: 0.274877
global_step: 14918, epoch: 173, loss: 0.159591
global_step: 14919, epoch: 173, loss: 0.209229
global_step: 14920, epoch: 173, loss: 0.122872
epoch: 173
train	acc: 0.9722	macro: p 0.9744, r 0.9631, f1: 0.9686	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5311	macro: p 0.3659, r 0.3138, f1: 0.3192	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4920
test	acc: 0.5851	macro: p 0.3901, r 0.3302, f1: 0.3398	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5497
global_step: 14921, epoch: 174, loss: 0.164354
global_step: 14922, epoch: 174, loss: 0.185793
global_step: 14923, epoch: 174, loss: 0.153123
global_step: 14924, epoch: 174, loss: 0.150350
global_step: 14925, epoch: 174, loss: 0.183184
global_step: 14926, epoch: 174, loss: 0.140543
global_step: 14927, epoch: 174, loss: 0.289407
global_step: 14928, epoch: 174, loss: 0.183977
global_step: 14929, epoch: 174, loss: 0.158159
global_step: 14930, epoch: 174, loss: 0.212689
global_step: 14931, epoch: 174, loss: 0.157437
global_step: 14932, epoch: 174, loss: 0.180461
global_step: 14933, epoch: 174, loss: 0.138333
global_step: 14934, epoch: 174, loss: 0.139474
global_step: 14935, epoch: 174, loss: 0.175328
global_step: 14936, epoch: 174, loss: 0.208216
global_step: 14937, epoch: 174, loss: 0.181466
global_step: 14938, epoch: 174, loss: 0.146186
global_step: 14939, epoch: 174, loss: 0.148964
global_step: 14940, epoch: 174, loss: 0.219697
global_step: 14941, epoch: 174, loss: 0.246869
global_step: 14942, epoch: 174, loss: 0.201411
global_step: 14943, epoch: 174, loss: 0.190800
global_step: 14944, epoch: 174, loss: 0.192964
global_step: 14945, epoch: 174, loss: 0.156663
global_step: 14946, epoch: 174, loss: 0.193509
global_step: 14947, epoch: 174, loss: 0.141956
global_step: 14948, epoch: 174, loss: 0.263726
global_step: 14949, epoch: 174, loss: 0.110977
global_step: 14950, epoch: 174, loss: 0.206322
global_step: 14951, epoch: 174, loss: 0.234501
global_step: 14952, epoch: 174, loss: 0.170286
global_step: 14953, epoch: 174, loss: 0.229581
global_step: 14954, epoch: 174, loss: 0.350970
global_step: 14955, epoch: 174, loss: 0.186370
global_step: 14956, epoch: 174, loss: 0.137541
global_step: 14957, epoch: 174, loss: 0.240343
global_step: 14958, epoch: 174, loss: 0.153340
global_step: 14959, epoch: 174, loss: 0.220599
global_step: 14960, epoch: 174, loss: 0.018823
epoch: 174
train	acc: 0.9722	macro: p 0.9741, r 0.9641, f1: 0.9689	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5374	macro: p 0.3763, r 0.3148, f1: 0.3226	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4973
test	acc: 0.5805	macro: p 0.3923, r 0.3188, f1: 0.3309	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5419
global_step: 14961, epoch: 175, loss: 0.195649
global_step: 14962, epoch: 175, loss: 0.219648
global_step: 14963, epoch: 175, loss: 0.181603
global_step: 14964, epoch: 175, loss: 0.216117
global_step: 14965, epoch: 175, loss: 0.242715
global_step: 14966, epoch: 175, loss: 0.212535
global_step: 14967, epoch: 175, loss: 0.195732
global_step: 14968, epoch: 175, loss: 0.171010
global_step: 14969, epoch: 175, loss: 0.131298
global_step: 14970, epoch: 175, loss: 0.136198
global_step: 14971, epoch: 175, loss: 0.189390
global_step: 14972, epoch: 175, loss: 0.198999
global_step: 14973, epoch: 175, loss: 0.248731
global_step: 14974, epoch: 175, loss: 0.189059
global_step: 14975, epoch: 175, loss: 0.205027
global_step: 14976, epoch: 175, loss: 0.190173
global_step: 14977, epoch: 175, loss: 0.152823
global_step: 14978, epoch: 175, loss: 0.135093
global_step: 14979, epoch: 175, loss: 0.228404
global_step: 14980, epoch: 175, loss: 0.193342
global_step: 14981, epoch: 175, loss: 0.104151
global_step: 14982, epoch: 175, loss: 0.169051
global_step: 14983, epoch: 175, loss: 0.215704
global_step: 14984, epoch: 175, loss: 0.154101
global_step: 14985, epoch: 175, loss: 0.210457
global_step: 14986, epoch: 175, loss: 0.201349
global_step: 14987, epoch: 175, loss: 0.185703
global_step: 14988, epoch: 175, loss: 0.236958
global_step: 14989, epoch: 175, loss: 0.156533
global_step: 14990, epoch: 175, loss: 0.241491
global_step: 14991, epoch: 175, loss: 0.254072
global_step: 14992, epoch: 175, loss: 0.167863
global_step: 14993, epoch: 175, loss: 0.256142
global_step: 14994, epoch: 175, loss: 0.205752
global_step: 14995, epoch: 175, loss: 0.164738
global_step: 14996, epoch: 175, loss: 0.172560
global_step: 14997, epoch: 175, loss: 0.250459
global_step: 14998, epoch: 175, loss: 0.179591
global_step: 14999, epoch: 175, loss: 0.173618
global_step: 15000, epoch: 175, loss: 0.046591
epoch: 175
train	acc: 0.9717	macro: p 0.9732, r 0.9635, f1: 0.9682	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5482	macro: p 0.3867, r 0.3259, f1: 0.3319	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5090
test	acc: 0.5782	macro: p 0.4037, r 0.3219, f1: 0.3309	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5425
global_step: 15001, epoch: 176, loss: 0.207264
global_step: 15002, epoch: 176, loss: 0.156017
global_step: 15003, epoch: 176, loss: 0.130080
global_step: 15004, epoch: 176, loss: 0.174050
global_step: 15005, epoch: 176, loss: 0.142029
global_step: 15006, epoch: 176, loss: 0.165402
global_step: 15007, epoch: 176, loss: 0.198055
global_step: 15008, epoch: 176, loss: 0.166640
global_step: 15009, epoch: 176, loss: 0.195275
global_step: 15010, epoch: 176, loss: 0.174866
global_step: 15011, epoch: 176, loss: 0.240716
global_step: 15012, epoch: 176, loss: 0.179581
global_step: 15013, epoch: 176, loss: 0.161826
global_step: 15014, epoch: 176, loss: 0.261662
global_step: 15015, epoch: 176, loss: 0.208838
global_step: 15016, epoch: 176, loss: 0.221939
global_step: 15017, epoch: 176, loss: 0.240059
global_step: 15018, epoch: 176, loss: 0.177234
global_step: 15019, epoch: 176, loss: 0.179757
global_step: 15020, epoch: 176, loss: 0.137290
global_step: 15021, epoch: 176, loss: 0.270897
global_step: 15022, epoch: 176, loss: 0.152827
global_step: 15023, epoch: 176, loss: 0.162446
global_step: 15024, epoch: 176, loss: 0.095315
global_step: 15025, epoch: 176, loss: 0.191368
global_step: 15026, epoch: 176, loss: 0.225814
global_step: 15027, epoch: 176, loss: 0.204023
global_step: 15028, epoch: 176, loss: 0.172150
global_step: 15029, epoch: 176, loss: 0.166838
global_step: 15030, epoch: 176, loss: 0.261475
global_step: 15031, epoch: 176, loss: 0.235316
global_step: 15032, epoch: 176, loss: 0.177868
global_step: 15033, epoch: 176, loss: 0.212135
global_step: 15034, epoch: 176, loss: 0.246876
global_step: 15035, epoch: 176, loss: 0.222298
global_step: 15036, epoch: 176, loss: 0.231486
global_step: 15037, epoch: 176, loss: 0.147218
global_step: 15038, epoch: 176, loss: 0.232546
global_step: 15039, epoch: 176, loss: 0.156032
global_step: 15040, epoch: 176, loss: 0.000132
epoch: 176
train	acc: 0.9721	macro: p 0.9748, r 0.9635, f1: 0.9689	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5401	macro: p 0.3639, r 0.3114, f1: 0.3127	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4959
test	acc: 0.5812	macro: p 0.3941, r 0.3223, f1: 0.3327	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5454
global_step: 15041, epoch: 177, loss: 0.195476
global_step: 15042, epoch: 177, loss: 0.200124
global_step: 15043, epoch: 177, loss: 0.188060
global_step: 15044, epoch: 177, loss: 0.149991
global_step: 15045, epoch: 177, loss: 0.281493
global_step: 15046, epoch: 177, loss: 0.126338
global_step: 15047, epoch: 177, loss: 0.193380
global_step: 15048, epoch: 177, loss: 0.180551
global_step: 15049, epoch: 177, loss: 0.161377
global_step: 15050, epoch: 177, loss: 0.178619
global_step: 15051, epoch: 177, loss: 0.162804
global_step: 15052, epoch: 177, loss: 0.164764
global_step: 15053, epoch: 177, loss: 0.207018
global_step: 15054, epoch: 177, loss: 0.169746
global_step: 15055, epoch: 177, loss: 0.177683
global_step: 15056, epoch: 177, loss: 0.148091
global_step: 15057, epoch: 177, loss: 0.196876
global_step: 15058, epoch: 177, loss: 0.157904
global_step: 15059, epoch: 177, loss: 0.173265
global_step: 15060, epoch: 177, loss: 0.212990
global_step: 15061, epoch: 177, loss: 0.161609
global_step: 15062, epoch: 177, loss: 0.166186
global_step: 15063, epoch: 177, loss: 0.192667
global_step: 15064, epoch: 177, loss: 0.272362
global_step: 15065, epoch: 177, loss: 0.164669
global_step: 15066, epoch: 177, loss: 0.165715
global_step: 15067, epoch: 177, loss: 0.168641
global_step: 15068, epoch: 177, loss: 0.216967
global_step: 15069, epoch: 177, loss: 0.178990
global_step: 15070, epoch: 177, loss: 0.230696
global_step: 15071, epoch: 177, loss: 0.156869
global_step: 15072, epoch: 177, loss: 0.217736
global_step: 15073, epoch: 177, loss: 0.234588
global_step: 15074, epoch: 177, loss: 0.168466
global_step: 15075, epoch: 177, loss: 0.287209
global_step: 15076, epoch: 177, loss: 0.204452
global_step: 15077, epoch: 177, loss: 0.184627
global_step: 15078, epoch: 177, loss: 0.223106
global_step: 15079, epoch: 177, loss: 0.222557
global_step: 15080, epoch: 177, loss: 0.376293
epoch: 177
train	acc: 0.9719	macro: p 0.9742, r 0.9635, f1: 0.9687	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5401	macro: p 0.3775, r 0.3230, f1: 0.3291	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.5050
test	acc: 0.5736	macro: p 0.3787, r 0.3190, f1: 0.3305	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5427
global_step: 15081, epoch: 178, loss: 0.140429
global_step: 15082, epoch: 178, loss: 0.205136
global_step: 15083, epoch: 178, loss: 0.170788
global_step: 15084, epoch: 178, loss: 0.157733
global_step: 15085, epoch: 178, loss: 0.217818
global_step: 15086, epoch: 178, loss: 0.167145
global_step: 15087, epoch: 178, loss: 0.218952
global_step: 15088, epoch: 178, loss: 0.215774
global_step: 15089, epoch: 178, loss: 0.187754
global_step: 15090, epoch: 178, loss: 0.115914
global_step: 15091, epoch: 178, loss: 0.209236
global_step: 15092, epoch: 178, loss: 0.299699
global_step: 15093, epoch: 178, loss: 0.155855
global_step: 15094, epoch: 178, loss: 0.166680
global_step: 15095, epoch: 178, loss: 0.198994
global_step: 15096, epoch: 178, loss: 0.234851
global_step: 15097, epoch: 178, loss: 0.254460
global_step: 15098, epoch: 178, loss: 0.196878
global_step: 15099, epoch: 178, loss: 0.227187
global_step: 15100, epoch: 178, loss: 0.161189
global_step: 15101, epoch: 178, loss: 0.161996
global_step: 15102, epoch: 178, loss: 0.156542
global_step: 15103, epoch: 178, loss: 0.219105
global_step: 15104, epoch: 178, loss: 0.169131
global_step: 15105, epoch: 178, loss: 0.155853
global_step: 15106, epoch: 178, loss: 0.266248
global_step: 15107, epoch: 178, loss: 0.218775
global_step: 15108, epoch: 178, loss: 0.172821
global_step: 15109, epoch: 178, loss: 0.222157
global_step: 15110, epoch: 178, loss: 0.165423
global_step: 15111, epoch: 178, loss: 0.207478
global_step: 15112, epoch: 178, loss: 0.171528
global_step: 15113, epoch: 178, loss: 0.196852
global_step: 15114, epoch: 178, loss: 0.234906
global_step: 15115, epoch: 178, loss: 0.188183
global_step: 15116, epoch: 178, loss: 0.243045
global_step: 15117, epoch: 178, loss: 0.173073
global_step: 15118, epoch: 178, loss: 0.142732
global_step: 15119, epoch: 178, loss: 0.209468
global_step: 15120, epoch: 178, loss: 1.083856
epoch: 178
train	acc: 0.9717	macro: p 0.9752, r 0.9621, f1: 0.9685	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5455	macro: p 0.3657, r 0.3180, f1: 0.3205	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5039
test	acc: 0.5793	macro: p 0.3780, r 0.3144, f1: 0.3227	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5403
global_step: 15121, epoch: 179, loss: 0.182184
global_step: 15122, epoch: 179, loss: 0.195995
global_step: 15123, epoch: 179, loss: 0.275907
global_step: 15124, epoch: 179, loss: 0.184131
global_step: 15125, epoch: 179, loss: 0.257498
global_step: 15126, epoch: 179, loss: 0.147317
global_step: 15127, epoch: 179, loss: 0.170589
global_step: 15128, epoch: 179, loss: 0.217672
global_step: 15129, epoch: 179, loss: 0.237962
global_step: 15130, epoch: 179, loss: 0.228382
global_step: 15131, epoch: 179, loss: 0.183335
global_step: 15132, epoch: 179, loss: 0.180410
global_step: 15133, epoch: 179, loss: 0.238112
global_step: 15134, epoch: 179, loss: 0.142675
global_step: 15135, epoch: 179, loss: 0.190907
global_step: 15136, epoch: 179, loss: 0.173672
global_step: 15137, epoch: 179, loss: 0.163231
global_step: 15138, epoch: 179, loss: 0.203441
global_step: 15139, epoch: 179, loss: 0.201978
global_step: 15140, epoch: 179, loss: 0.229947
global_step: 15141, epoch: 179, loss: 0.187949
global_step: 15142, epoch: 179, loss: 0.147639
global_step: 15143, epoch: 179, loss: 0.249484
global_step: 15144, epoch: 179, loss: 0.258093
global_step: 15145, epoch: 179, loss: 0.165616
global_step: 15146, epoch: 179, loss: 0.212661
global_step: 15147, epoch: 179, loss: 0.195050
global_step: 15148, epoch: 179, loss: 0.171084
global_step: 15149, epoch: 179, loss: 0.204979
global_step: 15150, epoch: 179, loss: 0.236896
global_step: 15151, epoch: 179, loss: 0.153158
global_step: 15152, epoch: 179, loss: 0.153406
global_step: 15153, epoch: 179, loss: 0.185057
global_step: 15154, epoch: 179, loss: 0.186554
global_step: 15155, epoch: 179, loss: 0.175144
global_step: 15156, epoch: 179, loss: 0.222158
global_step: 15157, epoch: 179, loss: 0.177691
global_step: 15158, epoch: 179, loss: 0.113508
global_step: 15159, epoch: 179, loss: 0.221772
global_step: 15160, epoch: 179, loss: 0.951820
epoch: 179
train	acc: 0.9719	macro: p 0.9756, r 0.9621, f1: 0.9687	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5509	macro: p 0.3787, r 0.3224, f1: 0.3267	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5099
test	acc: 0.5801	macro: p 0.3909, r 0.3167, f1: 0.3283	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5442
global_step: 15161, epoch: 180, loss: 0.179553
global_step: 15162, epoch: 180, loss: 0.172483
global_step: 15163, epoch: 180, loss: 0.201394
global_step: 15164, epoch: 180, loss: 0.144454
global_step: 15165, epoch: 180, loss: 0.206787
global_step: 15166, epoch: 180, loss: 0.169834
global_step: 15167, epoch: 180, loss: 0.179198
global_step: 15168, epoch: 180, loss: 0.196303
global_step: 15169, epoch: 180, loss: 0.238318
global_step: 15170, epoch: 180, loss: 0.224468
global_step: 15171, epoch: 180, loss: 0.198087
global_step: 15172, epoch: 180, loss: 0.191948
global_step: 15173, epoch: 180, loss: 0.196211
global_step: 15174, epoch: 180, loss: 0.234871
global_step: 15175, epoch: 180, loss: 0.261183
global_step: 15176, epoch: 180, loss: 0.180341
global_step: 15177, epoch: 180, loss: 0.125350
global_step: 15178, epoch: 180, loss: 0.218552
global_step: 15179, epoch: 180, loss: 0.176779
global_step: 15180, epoch: 180, loss: 0.186179
global_step: 15181, epoch: 180, loss: 0.114416
global_step: 15182, epoch: 180, loss: 0.189208
global_step: 15183, epoch: 180, loss: 0.186497
global_step: 15184, epoch: 180, loss: 0.165972
global_step: 15185, epoch: 180, loss: 0.237893
global_step: 15186, epoch: 180, loss: 0.232391
global_step: 15187, epoch: 180, loss: 0.143335
global_step: 15188, epoch: 180, loss: 0.203258
global_step: 15189, epoch: 180, loss: 0.221181
global_step: 15190, epoch: 180, loss: 0.152367
global_step: 15191, epoch: 180, loss: 0.218775
global_step: 15192, epoch: 180, loss: 0.159068
global_step: 15193, epoch: 180, loss: 0.185949
global_step: 15194, epoch: 180, loss: 0.173307
global_step: 15195, epoch: 180, loss: 0.183590
global_step: 15196, epoch: 180, loss: 0.200160
global_step: 15197, epoch: 180, loss: 0.174962
global_step: 15198, epoch: 180, loss: 0.188709
global_step: 15199, epoch: 180, loss: 0.167532
global_step: 15200, epoch: 180, loss: 1.106073
epoch: 180
train	acc: 0.9725	macro: p 0.9749, r 0.9633, f1: 0.9689	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5473	macro: p 0.3758, r 0.3191, f1: 0.3235	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5056
test	acc: 0.5728	macro: p 0.3672, r 0.3130, f1: 0.3203	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5362
global_step: 15201, epoch: 181, loss: 0.206274
global_step: 15202, epoch: 181, loss: 0.153873
global_step: 15203, epoch: 181, loss: 0.138782
global_step: 15204, epoch: 181, loss: 0.120524
global_step: 15205, epoch: 181, loss: 0.185893
global_step: 15206, epoch: 181, loss: 0.180371
global_step: 15207, epoch: 181, loss: 0.126933
global_step: 15208, epoch: 181, loss: 0.249746
global_step: 15209, epoch: 181, loss: 0.212454
global_step: 15210, epoch: 181, loss: 0.178511
global_step: 15211, epoch: 181, loss: 0.158443
global_step: 15212, epoch: 181, loss: 0.191758
global_step: 15213, epoch: 181, loss: 0.220651
global_step: 15214, epoch: 181, loss: 0.179531
global_step: 15215, epoch: 181, loss: 0.180653
global_step: 15216, epoch: 181, loss: 0.230353
global_step: 15217, epoch: 181, loss: 0.248084
global_step: 15218, epoch: 181, loss: 0.211083
global_step: 15219, epoch: 181, loss: 0.175306
global_step: 15220, epoch: 181, loss: 0.216541
global_step: 15221, epoch: 181, loss: 0.190995
global_step: 15222, epoch: 181, loss: 0.191435
global_step: 15223, epoch: 181, loss: 0.259327
global_step: 15224, epoch: 181, loss: 0.203794
global_step: 15225, epoch: 181, loss: 0.230796
global_step: 15226, epoch: 181, loss: 0.172735
global_step: 15227, epoch: 181, loss: 0.270266
global_step: 15228, epoch: 181, loss: 0.241783
global_step: 15229, epoch: 181, loss: 0.178286
global_step: 15230, epoch: 181, loss: 0.200951
global_step: 15231, epoch: 181, loss: 0.245051
global_step: 15232, epoch: 181, loss: 0.142153
global_step: 15233, epoch: 181, loss: 0.172213
global_step: 15234, epoch: 181, loss: 0.211017
global_step: 15235, epoch: 181, loss: 0.215575
global_step: 15236, epoch: 181, loss: 0.175908
global_step: 15237, epoch: 181, loss: 0.246626
global_step: 15238, epoch: 181, loss: 0.245465
global_step: 15239, epoch: 181, loss: 0.268873
global_step: 15240, epoch: 181, loss: 0.100895
epoch: 181
train	acc: 0.9725	macro: p 0.9744, r 0.9642, f1: 0.9691	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5464	macro: p 0.3927, r 0.3323, f1: 0.3387	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5101
test	acc: 0.5709	macro: p 0.3704, r 0.3197, f1: 0.3255	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5400
global_step: 15241, epoch: 182, loss: 0.203157
global_step: 15242, epoch: 182, loss: 0.206924
global_step: 15243, epoch: 182, loss: 0.181973
global_step: 15244, epoch: 182, loss: 0.187581
global_step: 15245, epoch: 182, loss: 0.176984
global_step: 15246, epoch: 182, loss: 0.198688
global_step: 15247, epoch: 182, loss: 0.135575
global_step: 15248, epoch: 182, loss: 0.176804
global_step: 15249, epoch: 182, loss: 0.228199
global_step: 15250, epoch: 182, loss: 0.219290
global_step: 15251, epoch: 182, loss: 0.184040
global_step: 15252, epoch: 182, loss: 0.192784
global_step: 15253, epoch: 182, loss: 0.187672
global_step: 15254, epoch: 182, loss: 0.134373
global_step: 15255, epoch: 182, loss: 0.212598
global_step: 15256, epoch: 182, loss: 0.179541
global_step: 15257, epoch: 182, loss: 0.150897
global_step: 15258, epoch: 182, loss: 0.186492
global_step: 15259, epoch: 182, loss: 0.241458
global_step: 15260, epoch: 182, loss: 0.169964
global_step: 15261, epoch: 182, loss: 0.189740
global_step: 15262, epoch: 182, loss: 0.188315
global_step: 15263, epoch: 182, loss: 0.150764
global_step: 15264, epoch: 182, loss: 0.206514
global_step: 15265, epoch: 182, loss: 0.154212
global_step: 15266, epoch: 182, loss: 0.196721
global_step: 15267, epoch: 182, loss: 0.140671
global_step: 15268, epoch: 182, loss: 0.218952
global_step: 15269, epoch: 182, loss: 0.205581
global_step: 15270, epoch: 182, loss: 0.134725
global_step: 15271, epoch: 182, loss: 0.223856
global_step: 15272, epoch: 182, loss: 0.158893
global_step: 15273, epoch: 182, loss: 0.211178
global_step: 15274, epoch: 182, loss: 0.132151
global_step: 15275, epoch: 182, loss: 0.261530
global_step: 15276, epoch: 182, loss: 0.217348
global_step: 15277, epoch: 182, loss: 0.274504
global_step: 15278, epoch: 182, loss: 0.197241
global_step: 15279, epoch: 182, loss: 0.157336
global_step: 15280, epoch: 182, loss: 0.162336
epoch: 182
train	acc: 0.9723	macro: p 0.9754, r 0.9638, f1: 0.9694	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5401	macro: p 0.3848, r 0.3163, f1: 0.3239	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4971
test	acc: 0.5747	macro: p 0.3843, r 0.3097, f1: 0.3187	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5349
global_step: 15281, epoch: 183, loss: 0.205427
global_step: 15282, epoch: 183, loss: 0.160468
global_step: 15283, epoch: 183, loss: 0.212687
global_step: 15284, epoch: 183, loss: 0.168837
global_step: 15285, epoch: 183, loss: 0.213012
global_step: 15286, epoch: 183, loss: 0.141600
global_step: 15287, epoch: 183, loss: 0.209925
global_step: 15288, epoch: 183, loss: 0.187510
global_step: 15289, epoch: 183, loss: 0.138302
global_step: 15290, epoch: 183, loss: 0.139098
global_step: 15291, epoch: 183, loss: 0.185184
global_step: 15292, epoch: 183, loss: 0.156278
global_step: 15293, epoch: 183, loss: 0.170736
global_step: 15294, epoch: 183, loss: 0.211737
global_step: 15295, epoch: 183, loss: 0.231814
global_step: 15296, epoch: 183, loss: 0.110848
global_step: 15297, epoch: 183, loss: 0.122459
global_step: 15298, epoch: 183, loss: 0.217157
global_step: 15299, epoch: 183, loss: 0.199502
global_step: 15300, epoch: 183, loss: 0.172121
global_step: 15301, epoch: 183, loss: 0.181516
global_step: 15302, epoch: 183, loss: 0.234495
global_step: 15303, epoch: 183, loss: 0.204697
global_step: 15304, epoch: 183, loss: 0.238431
global_step: 15305, epoch: 183, loss: 0.096991
global_step: 15306, epoch: 183, loss: 0.183784
global_step: 15307, epoch: 183, loss: 0.205009
global_step: 15308, epoch: 183, loss: 0.239965
global_step: 15309, epoch: 183, loss: 0.198477
global_step: 15310, epoch: 183, loss: 0.221086
global_step: 15311, epoch: 183, loss: 0.169202
global_step: 15312, epoch: 183, loss: 0.216061
global_step: 15313, epoch: 183, loss: 0.155730
global_step: 15314, epoch: 183, loss: 0.227994
global_step: 15315, epoch: 183, loss: 0.201476
global_step: 15316, epoch: 183, loss: 0.121148
global_step: 15317, epoch: 183, loss: 0.201130
global_step: 15318, epoch: 183, loss: 0.155367
global_step: 15319, epoch: 183, loss: 0.179975
global_step: 15320, epoch: 183, loss: 0.112987
epoch: 183
train	acc: 0.9722	macro: p 0.9761, r 0.9621, f1: 0.9689	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5491	macro: p 0.4019, r 0.3264, f1: 0.3320	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5057
test	acc: 0.5705	macro: p 0.3587, r 0.3059, f1: 0.3126	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5316
global_step: 15321, epoch: 184, loss: 0.170959
global_step: 15322, epoch: 184, loss: 0.181241
global_step: 15323, epoch: 184, loss: 0.126575
global_step: 15324, epoch: 184, loss: 0.237626
global_step: 15325, epoch: 184, loss: 0.158859
global_step: 15326, epoch: 184, loss: 0.269254
global_step: 15327, epoch: 184, loss: 0.175311
global_step: 15328, epoch: 184, loss: 0.195130
global_step: 15329, epoch: 184, loss: 0.180011
global_step: 15330, epoch: 184, loss: 0.147531
global_step: 15331, epoch: 184, loss: 0.188757
global_step: 15332, epoch: 184, loss: 0.196618
global_step: 15333, epoch: 184, loss: 0.161881
global_step: 15334, epoch: 184, loss: 0.213434
global_step: 15335, epoch: 184, loss: 0.161628
global_step: 15336, epoch: 184, loss: 0.110630
global_step: 15337, epoch: 184, loss: 0.155678
global_step: 15338, epoch: 184, loss: 0.233174
global_step: 15339, epoch: 184, loss: 0.227650
global_step: 15340, epoch: 184, loss: 0.152311
global_step: 15341, epoch: 184, loss: 0.223253
global_step: 15342, epoch: 184, loss: 0.194724
global_step: 15343, epoch: 184, loss: 0.180472
global_step: 15344, epoch: 184, loss: 0.224025
global_step: 15345, epoch: 184, loss: 0.161109
global_step: 15346, epoch: 184, loss: 0.184606
global_step: 15347, epoch: 184, loss: 0.204473
global_step: 15348, epoch: 184, loss: 0.167739
global_step: 15349, epoch: 184, loss: 0.195326
global_step: 15350, epoch: 184, loss: 0.147732
global_step: 15351, epoch: 184, loss: 0.165647
global_step: 15352, epoch: 184, loss: 0.186084
global_step: 15353, epoch: 184, loss: 0.175686
global_step: 15354, epoch: 184, loss: 0.147765
global_step: 15355, epoch: 184, loss: 0.131517
global_step: 15356, epoch: 184, loss: 0.200946
global_step: 15357, epoch: 184, loss: 0.217032
global_step: 15358, epoch: 184, loss: 0.197261
global_step: 15359, epoch: 184, loss: 0.186355
global_step: 15360, epoch: 184, loss: 0.032122
epoch: 184
train	acc: 0.9724	macro: p 0.9757, r 0.9636, f1: 0.9694	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5473	macro: p 0.3881, r 0.3243, f1: 0.3298	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5054
test	acc: 0.5785	macro: p 0.3850, r 0.3157, f1: 0.3237	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5409
global_step: 15361, epoch: 185, loss: 0.177235
global_step: 15362, epoch: 185, loss: 0.173374
global_step: 15363, epoch: 185, loss: 0.143309
global_step: 15364, epoch: 185, loss: 0.151080
global_step: 15365, epoch: 185, loss: 0.247893
global_step: 15366, epoch: 185, loss: 0.209217
global_step: 15367, epoch: 185, loss: 0.166056
global_step: 15368, epoch: 185, loss: 0.138798
global_step: 15369, epoch: 185, loss: 0.231038
global_step: 15370, epoch: 185, loss: 0.172734
global_step: 15371, epoch: 185, loss: 0.132643
global_step: 15372, epoch: 185, loss: 0.224097
global_step: 15373, epoch: 185, loss: 0.158290
global_step: 15374, epoch: 185, loss: 0.190404
global_step: 15375, epoch: 185, loss: 0.163472
global_step: 15376, epoch: 185, loss: 0.162034
global_step: 15377, epoch: 185, loss: 0.165734
global_step: 15378, epoch: 185, loss: 0.210417
global_step: 15379, epoch: 185, loss: 0.163336
global_step: 15380, epoch: 185, loss: 0.196620
global_step: 15381, epoch: 185, loss: 0.200165
global_step: 15382, epoch: 185, loss: 0.187492
global_step: 15383, epoch: 185, loss: 0.199733
global_step: 15384, epoch: 185, loss: 0.123653
global_step: 15385, epoch: 185, loss: 0.172649
global_step: 15386, epoch: 185, loss: 0.200382
global_step: 15387, epoch: 185, loss: 0.174127
global_step: 15388, epoch: 185, loss: 0.179275
global_step: 15389, epoch: 185, loss: 0.200593
global_step: 15390, epoch: 185, loss: 0.254361
global_step: 15391, epoch: 185, loss: 0.213082
global_step: 15392, epoch: 185, loss: 0.167103
global_step: 15393, epoch: 185, loss: 0.175826
global_step: 15394, epoch: 185, loss: 0.162844
global_step: 15395, epoch: 185, loss: 0.206665
global_step: 15396, epoch: 185, loss: 0.189305
global_step: 15397, epoch: 185, loss: 0.189777
global_step: 15398, epoch: 185, loss: 0.179638
global_step: 15399, epoch: 185, loss: 0.242595
global_step: 15400, epoch: 185, loss: 0.173620
epoch: 185
train	acc: 0.9720	macro: p 0.9759, r 0.9623, f1: 0.9689	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5365	macro: p 0.3854, r 0.3123, f1: 0.3163	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4900
test	acc: 0.5766	macro: p 0.3812, r 0.3059, f1: 0.3148	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5333
global_step: 15401, epoch: 186, loss: 0.218051
global_step: 15402, epoch: 186, loss: 0.134114
global_step: 15403, epoch: 186, loss: 0.136140
global_step: 15404, epoch: 186, loss: 0.159074
global_step: 15405, epoch: 186, loss: 0.138363
global_step: 15406, epoch: 186, loss: 0.180425
global_step: 15407, epoch: 186, loss: 0.239784
global_step: 15408, epoch: 186, loss: 0.186499
global_step: 15409, epoch: 186, loss: 0.139900
global_step: 15410, epoch: 186, loss: 0.163556
global_step: 15411, epoch: 186, loss: 0.138112
global_step: 15412, epoch: 186, loss: 0.236818
global_step: 15413, epoch: 186, loss: 0.186482
global_step: 15414, epoch: 186, loss: 0.243449
global_step: 15415, epoch: 186, loss: 0.143647
global_step: 15416, epoch: 186, loss: 0.194430
global_step: 15417, epoch: 186, loss: 0.203019
global_step: 15418, epoch: 186, loss: 0.169894
global_step: 15419, epoch: 186, loss: 0.236603
global_step: 15420, epoch: 186, loss: 0.206410
global_step: 15421, epoch: 186, loss: 0.158397
global_step: 15422, epoch: 186, loss: 0.125243
global_step: 15423, epoch: 186, loss: 0.173987
global_step: 15424, epoch: 186, loss: 0.209264
global_step: 15425, epoch: 186, loss: 0.243016
global_step: 15426, epoch: 186, loss: 0.164714
global_step: 15427, epoch: 186, loss: 0.192417
global_step: 15428, epoch: 186, loss: 0.257304
global_step: 15429, epoch: 186, loss: 0.159007
global_step: 15430, epoch: 186, loss: 0.205837
global_step: 15431, epoch: 186, loss: 0.208714
global_step: 15432, epoch: 186, loss: 0.213689
global_step: 15433, epoch: 186, loss: 0.181153
global_step: 15434, epoch: 186, loss: 0.255453
global_step: 15435, epoch: 186, loss: 0.170476
global_step: 15436, epoch: 186, loss: 0.182690
global_step: 15437, epoch: 186, loss: 0.201880
global_step: 15438, epoch: 186, loss: 0.153924
global_step: 15439, epoch: 186, loss: 0.123018
global_step: 15440, epoch: 186, loss: 0.000276
epoch: 186
train	acc: 0.9722	macro: p 0.9766, r 0.9618, f1: 0.9690	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5437	macro: p 0.4032, r 0.3213, f1: 0.3285	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4997
test	acc: 0.5720	macro: p 0.3776, r 0.3087, f1: 0.3168	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5328
global_step: 15441, epoch: 187, loss: 0.149275
global_step: 15442, epoch: 187, loss: 0.175451
global_step: 15443, epoch: 187, loss: 0.184164
global_step: 15444, epoch: 187, loss: 0.203480
global_step: 15445, epoch: 187, loss: 0.159780
global_step: 15446, epoch: 187, loss: 0.155881
global_step: 15447, epoch: 187, loss: 0.216915
global_step: 15448, epoch: 187, loss: 0.122927
global_step: 15449, epoch: 187, loss: 0.120735
global_step: 15450, epoch: 187, loss: 0.201949
global_step: 15451, epoch: 187, loss: 0.208904
global_step: 15452, epoch: 187, loss: 0.185926
global_step: 15453, epoch: 187, loss: 0.213729
global_step: 15454, epoch: 187, loss: 0.217772
global_step: 15455, epoch: 187, loss: 0.200371
global_step: 15456, epoch: 187, loss: 0.197564
global_step: 15457, epoch: 187, loss: 0.181169
global_step: 15458, epoch: 187, loss: 0.190644
global_step: 15459, epoch: 187, loss: 0.172174
global_step: 15460, epoch: 187, loss: 0.151986
global_step: 15461, epoch: 187, loss: 0.183108
global_step: 15462, epoch: 187, loss: 0.110818
global_step: 15463, epoch: 187, loss: 0.187275
global_step: 15464, epoch: 187, loss: 0.196579
global_step: 15465, epoch: 187, loss: 0.221123
global_step: 15466, epoch: 187, loss: 0.169733
global_step: 15467, epoch: 187, loss: 0.194373
global_step: 15468, epoch: 187, loss: 0.254482
global_step: 15469, epoch: 187, loss: 0.188996
global_step: 15470, epoch: 187, loss: 0.207325
global_step: 15471, epoch: 187, loss: 0.128629
global_step: 15472, epoch: 187, loss: 0.228797
global_step: 15473, epoch: 187, loss: 0.268177
global_step: 15474, epoch: 187, loss: 0.166625
global_step: 15475, epoch: 187, loss: 0.192059
global_step: 15476, epoch: 187, loss: 0.193945
global_step: 15477, epoch: 187, loss: 0.162385
global_step: 15478, epoch: 187, loss: 0.185930
global_step: 15479, epoch: 187, loss: 0.164463
global_step: 15480, epoch: 187, loss: 0.003019
epoch: 187
train	acc: 0.9721	macro: p 0.9761, r 0.9624, f1: 0.9690	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5410	macro: p 0.3944, r 0.3190, f1: 0.3268	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4990
test	acc: 0.5770	macro: p 0.3893, r 0.3157, f1: 0.3277	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5400
global_step: 15481, epoch: 188, loss: 0.211614
global_step: 15482, epoch: 188, loss: 0.185238
global_step: 15483, epoch: 188, loss: 0.217133
global_step: 15484, epoch: 188, loss: 0.195016
global_step: 15485, epoch: 188, loss: 0.151366
global_step: 15486, epoch: 188, loss: 0.143286
global_step: 15487, epoch: 188, loss: 0.203033
global_step: 15488, epoch: 188, loss: 0.205302
global_step: 15489, epoch: 188, loss: 0.145127
global_step: 15490, epoch: 188, loss: 0.199418
global_step: 15491, epoch: 188, loss: 0.203771
global_step: 15492, epoch: 188, loss: 0.141285
global_step: 15493, epoch: 188, loss: 0.154997
global_step: 15494, epoch: 188, loss: 0.265578
global_step: 15495, epoch: 188, loss: 0.241293
global_step: 15496, epoch: 188, loss: 0.205539
global_step: 15497, epoch: 188, loss: 0.128157
global_step: 15498, epoch: 188, loss: 0.289010
global_step: 15499, epoch: 188, loss: 0.173313
global_step: 15500, epoch: 188, loss: 0.236159
global_step: 15501, epoch: 188, loss: 0.169179
global_step: 15502, epoch: 188, loss: 0.150713
global_step: 15503, epoch: 188, loss: 0.176207
global_step: 15504, epoch: 188, loss: 0.197929
global_step: 15505, epoch: 188, loss: 0.250706
global_step: 15506, epoch: 188, loss: 0.190781
global_step: 15507, epoch: 188, loss: 0.132269
global_step: 15508, epoch: 188, loss: 0.176235
global_step: 15509, epoch: 188, loss: 0.196862
global_step: 15510, epoch: 188, loss: 0.151178
global_step: 15511, epoch: 188, loss: 0.245138
global_step: 15512, epoch: 188, loss: 0.185009
global_step: 15513, epoch: 188, loss: 0.178813
global_step: 15514, epoch: 188, loss: 0.160297
global_step: 15515, epoch: 188, loss: 0.178867
global_step: 15516, epoch: 188, loss: 0.233927
global_step: 15517, epoch: 188, loss: 0.180642
global_step: 15518, epoch: 188, loss: 0.170813
global_step: 15519, epoch: 188, loss: 0.208315
global_step: 15520, epoch: 188, loss: 0.023874
epoch: 188
train	acc: 0.9724	macro: p 0.9769, r 0.9612, f1: 0.9688	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5482	macro: p 0.4021, r 0.3282, f1: 0.3342	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5064
test	acc: 0.5713	macro: p 0.3703, r 0.3129, f1: 0.3207	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5340
global_step: 15521, epoch: 189, loss: 0.165914
global_step: 15522, epoch: 189, loss: 0.179753
global_step: 15523, epoch: 189, loss: 0.166293
global_step: 15524, epoch: 189, loss: 0.177050
global_step: 15525, epoch: 189, loss: 0.208846
global_step: 15526, epoch: 189, loss: 0.137404
global_step: 15527, epoch: 189, loss: 0.235436
global_step: 15528, epoch: 189, loss: 0.182126
global_step: 15529, epoch: 189, loss: 0.147280
global_step: 15530, epoch: 189, loss: 0.227881
global_step: 15531, epoch: 189, loss: 0.201950
global_step: 15532, epoch: 189, loss: 0.173218
global_step: 15533, epoch: 189, loss: 0.205578
global_step: 15534, epoch: 189, loss: 0.191185
global_step: 15535, epoch: 189, loss: 0.226569
global_step: 15536, epoch: 189, loss: 0.196811
global_step: 15537, epoch: 189, loss: 0.196686
global_step: 15538, epoch: 189, loss: 0.125354
global_step: 15539, epoch: 189, loss: 0.174684
global_step: 15540, epoch: 189, loss: 0.172188
global_step: 15541, epoch: 189, loss: 0.186185
global_step: 15542, epoch: 189, loss: 0.203479
global_step: 15543, epoch: 189, loss: 0.208354
global_step: 15544, epoch: 189, loss: 0.180907
global_step: 15545, epoch: 189, loss: 0.189205
global_step: 15546, epoch: 189, loss: 0.178214
global_step: 15547, epoch: 189, loss: 0.211409
global_step: 15548, epoch: 189, loss: 0.168432
global_step: 15549, epoch: 189, loss: 0.216450
global_step: 15550, epoch: 189, loss: 0.188967
global_step: 15551, epoch: 189, loss: 0.207942
global_step: 15552, epoch: 189, loss: 0.184248
global_step: 15553, epoch: 189, loss: 0.180900
global_step: 15554, epoch: 189, loss: 0.222776
global_step: 15555, epoch: 189, loss: 0.186262
global_step: 15556, epoch: 189, loss: 0.189808
global_step: 15557, epoch: 189, loss: 0.213450
global_step: 15558, epoch: 189, loss: 0.180995
global_step: 15559, epoch: 189, loss: 0.159671
global_step: 15560, epoch: 189, loss: 0.003452
epoch: 189
train	acc: 0.9722	macro: p 0.9770, r 0.9617, f1: 0.9691	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5374	macro: p 0.3964, r 0.3242, f1: 0.3295	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4978
test	acc: 0.5709	macro: p 0.3808, r 0.3155, f1: 0.3243	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5347
global_step: 15561, epoch: 190, loss: 0.183809
global_step: 15562, epoch: 190, loss: 0.207754
global_step: 15563, epoch: 190, loss: 0.157798
global_step: 15564, epoch: 190, loss: 0.189889
global_step: 15565, epoch: 190, loss: 0.135686
global_step: 15566, epoch: 190, loss: 0.167298
global_step: 15567, epoch: 190, loss: 0.166651
global_step: 15568, epoch: 190, loss: 0.125847
global_step: 15569, epoch: 190, loss: 0.153641
global_step: 15570, epoch: 190, loss: 0.182668
global_step: 15571, epoch: 190, loss: 0.183894
global_step: 15572, epoch: 190, loss: 0.222687
global_step: 15573, epoch: 190, loss: 0.200364
global_step: 15574, epoch: 190, loss: 0.238268
global_step: 15575, epoch: 190, loss: 0.131148
global_step: 15576, epoch: 190, loss: 0.183069
global_step: 15577, epoch: 190, loss: 0.275931
global_step: 15578, epoch: 190, loss: 0.174227
global_step: 15579, epoch: 190, loss: 0.235081
global_step: 15580, epoch: 190, loss: 0.255731
global_step: 15581, epoch: 190, loss: 0.138589
global_step: 15582, epoch: 190, loss: 0.148707
global_step: 15583, epoch: 190, loss: 0.223250
global_step: 15584, epoch: 190, loss: 0.146076
global_step: 15585, epoch: 190, loss: 0.151199
global_step: 15586, epoch: 190, loss: 0.202386
global_step: 15587, epoch: 190, loss: 0.206568
global_step: 15588, epoch: 190, loss: 0.177541
global_step: 15589, epoch: 190, loss: 0.232395
global_step: 15590, epoch: 190, loss: 0.141950
global_step: 15591, epoch: 190, loss: 0.209562
global_step: 15592, epoch: 190, loss: 0.194812
global_step: 15593, epoch: 190, loss: 0.186620
global_step: 15594, epoch: 190, loss: 0.205649
global_step: 15595, epoch: 190, loss: 0.287978
global_step: 15596, epoch: 190, loss: 0.226091
global_step: 15597, epoch: 190, loss: 0.236662
global_step: 15598, epoch: 190, loss: 0.169184
global_step: 15599, epoch: 190, loss: 0.148788
global_step: 15600, epoch: 190, loss: 0.039574
epoch: 190
train	acc: 0.9726	macro: p 0.9748, r 0.9631, f1: 0.9688	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5392	macro: p 0.3771, r 0.3136, f1: 0.3163	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4959
test	acc: 0.5770	macro: p 0.3822, r 0.3122, f1: 0.3205	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5376
global_step: 15601, epoch: 191, loss: 0.172836
global_step: 15602, epoch: 191, loss: 0.189111
global_step: 15603, epoch: 191, loss: 0.246712
global_step: 15604, epoch: 191, loss: 0.172809
global_step: 15605, epoch: 191, loss: 0.180270
global_step: 15606, epoch: 191, loss: 0.182058
global_step: 15607, epoch: 191, loss: 0.218310
global_step: 15608, epoch: 191, loss: 0.166657
global_step: 15609, epoch: 191, loss: 0.165636
global_step: 15610, epoch: 191, loss: 0.107458
global_step: 15611, epoch: 191, loss: 0.241326
global_step: 15612, epoch: 191, loss: 0.161643
global_step: 15613, epoch: 191, loss: 0.162578
global_step: 15614, epoch: 191, loss: 0.179969
global_step: 15615, epoch: 191, loss: 0.185982
global_step: 15616, epoch: 191, loss: 0.190077
global_step: 15617, epoch: 191, loss: 0.220206
global_step: 15618, epoch: 191, loss: 0.191714
global_step: 15619, epoch: 191, loss: 0.159231
global_step: 15620, epoch: 191, loss: 0.194048
global_step: 15621, epoch: 191, loss: 0.202548
global_step: 15622, epoch: 191, loss: 0.185468
global_step: 15623, epoch: 191, loss: 0.182018
global_step: 15624, epoch: 191, loss: 0.135775
global_step: 15625, epoch: 191, loss: 0.175689
global_step: 15626, epoch: 191, loss: 0.318612
global_step: 15627, epoch: 191, loss: 0.150427
global_step: 15628, epoch: 191, loss: 0.238679
global_step: 15629, epoch: 191, loss: 0.208456
global_step: 15630, epoch: 191, loss: 0.107890
global_step: 15631, epoch: 191, loss: 0.129291
global_step: 15632, epoch: 191, loss: 0.183051
global_step: 15633, epoch: 191, loss: 0.204787
global_step: 15634, epoch: 191, loss: 0.144773
global_step: 15635, epoch: 191, loss: 0.129158
global_step: 15636, epoch: 191, loss: 0.206442
global_step: 15637, epoch: 191, loss: 0.254996
global_step: 15638, epoch: 191, loss: 0.165477
global_step: 15639, epoch: 191, loss: 0.243117
global_step: 15640, epoch: 191, loss: 0.615909
epoch: 191
train	acc: 0.9728	macro: p 0.9755, r 0.9638, f1: 0.9694	micro: p 0.9728, r 0.9728, f1 0.9728	weighted_f1:0.9728
dev	acc: 0.5419	macro: p 0.3722, r 0.3235, f1: 0.3249	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5030
test	acc: 0.5713	macro: p 0.3732, r 0.3161, f1: 0.3197	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5351
global_step: 15641, epoch: 192, loss: 0.190284
global_step: 15642, epoch: 192, loss: 0.160902
global_step: 15643, epoch: 192, loss: 0.108356
global_step: 15644, epoch: 192, loss: 0.197692
global_step: 15645, epoch: 192, loss: 0.255894
global_step: 15646, epoch: 192, loss: 0.130776
global_step: 15647, epoch: 192, loss: 0.155108
global_step: 15648, epoch: 192, loss: 0.132154
global_step: 15649, epoch: 192, loss: 0.171675
global_step: 15650, epoch: 192, loss: 0.170361
global_step: 15651, epoch: 192, loss: 0.275199
global_step: 15652, epoch: 192, loss: 0.148660
global_step: 15653, epoch: 192, loss: 0.158460
global_step: 15654, epoch: 192, loss: 0.240463
global_step: 15655, epoch: 192, loss: 0.145393
global_step: 15656, epoch: 192, loss: 0.200123
global_step: 15657, epoch: 192, loss: 0.246681
global_step: 15658, epoch: 192, loss: 0.213917
global_step: 15659, epoch: 192, loss: 0.185667
global_step: 15660, epoch: 192, loss: 0.220149
global_step: 15661, epoch: 192, loss: 0.160514
global_step: 15662, epoch: 192, loss: 0.227818
global_step: 15663, epoch: 192, loss: 0.189197
global_step: 15664, epoch: 192, loss: 0.255184
global_step: 15665, epoch: 192, loss: 0.188760
global_step: 15666, epoch: 192, loss: 0.222637
global_step: 15667, epoch: 192, loss: 0.201404
global_step: 15668, epoch: 192, loss: 0.160784
global_step: 15669, epoch: 192, loss: 0.131982
global_step: 15670, epoch: 192, loss: 0.187608
global_step: 15671, epoch: 192, loss: 0.228588
global_step: 15672, epoch: 192, loss: 0.181627
global_step: 15673, epoch: 192, loss: 0.202998
global_step: 15674, epoch: 192, loss: 0.169284
global_step: 15675, epoch: 192, loss: 0.134261
global_step: 15676, epoch: 192, loss: 0.196190
global_step: 15677, epoch: 192, loss: 0.228902
global_step: 15678, epoch: 192, loss: 0.244916
global_step: 15679, epoch: 192, loss: 0.139310
global_step: 15680, epoch: 192, loss: 0.222436
epoch: 192
train	acc: 0.9726	macro: p 0.9762, r 0.9633, f1: 0.9695	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5374	macro: p 0.3600, r 0.3112, f1: 0.3098	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4926
test	acc: 0.5770	macro: p 0.3824, r 0.3114, f1: 0.3185	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5380
global_step: 15681, epoch: 193, loss: 0.122226
global_step: 15682, epoch: 193, loss: 0.124600
global_step: 15683, epoch: 193, loss: 0.156053
global_step: 15684, epoch: 193, loss: 0.264692
global_step: 15685, epoch: 193, loss: 0.227499
global_step: 15686, epoch: 193, loss: 0.136943
global_step: 15687, epoch: 193, loss: 0.173367
global_step: 15688, epoch: 193, loss: 0.145057
global_step: 15689, epoch: 193, loss: 0.181697
global_step: 15690, epoch: 193, loss: 0.185751
global_step: 15691, epoch: 193, loss: 0.239381
global_step: 15692, epoch: 193, loss: 0.168494
global_step: 15693, epoch: 193, loss: 0.206401
global_step: 15694, epoch: 193, loss: 0.156609
global_step: 15695, epoch: 193, loss: 0.141139
global_step: 15696, epoch: 193, loss: 0.155306
global_step: 15697, epoch: 193, loss: 0.164715
global_step: 15698, epoch: 193, loss: 0.200127
global_step: 15699, epoch: 193, loss: 0.147048
global_step: 15700, epoch: 193, loss: 0.114601
global_step: 15701, epoch: 193, loss: 0.210639
global_step: 15702, epoch: 193, loss: 0.253827
global_step: 15703, epoch: 193, loss: 0.201372
global_step: 15704, epoch: 193, loss: 0.163085
global_step: 15705, epoch: 193, loss: 0.257563
global_step: 15706, epoch: 193, loss: 0.152010
global_step: 15707, epoch: 193, loss: 0.138127
global_step: 15708, epoch: 193, loss: 0.167764
global_step: 15709, epoch: 193, loss: 0.178872
global_step: 15710, epoch: 193, loss: 0.151782
global_step: 15711, epoch: 193, loss: 0.187706
global_step: 15712, epoch: 193, loss: 0.217777
global_step: 15713, epoch: 193, loss: 0.175525
global_step: 15714, epoch: 193, loss: 0.177949
global_step: 15715, epoch: 193, loss: 0.260030
global_step: 15716, epoch: 193, loss: 0.164872
global_step: 15717, epoch: 193, loss: 0.206905
global_step: 15718, epoch: 193, loss: 0.234565
global_step: 15719, epoch: 193, loss: 0.277774
global_step: 15720, epoch: 193, loss: 0.026618
epoch: 193
train	acc: 0.9731	macro: p 0.9756, r 0.9646, f1: 0.9699	micro: p 0.9731, r 0.9731, f1 0.9731	weighted_f1:0.9731
dev	acc: 0.5401	macro: p 0.3898, r 0.3138, f1: 0.3169	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4950
test	acc: 0.5843	macro: p 0.3903, r 0.3174, f1: 0.3266	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5437
global_step: 15721, epoch: 194, loss: 0.140303
global_step: 15722, epoch: 194, loss: 0.230302
global_step: 15723, epoch: 194, loss: 0.204204
global_step: 15724, epoch: 194, loss: 0.174553
global_step: 15725, epoch: 194, loss: 0.188424
global_step: 15726, epoch: 194, loss: 0.162164
global_step: 15727, epoch: 194, loss: 0.218361
global_step: 15728, epoch: 194, loss: 0.143929
global_step: 15729, epoch: 194, loss: 0.252694
global_step: 15730, epoch: 194, loss: 0.218002
global_step: 15731, epoch: 194, loss: 0.232723
global_step: 15732, epoch: 194, loss: 0.131874
global_step: 15733, epoch: 194, loss: 0.191879
global_step: 15734, epoch: 194, loss: 0.213050
global_step: 15735, epoch: 194, loss: 0.205861
global_step: 15736, epoch: 194, loss: 0.233406
global_step: 15737, epoch: 194, loss: 0.173400
global_step: 15738, epoch: 194, loss: 0.173668
global_step: 15739, epoch: 194, loss: 0.221540
global_step: 15740, epoch: 194, loss: 0.143611
global_step: 15741, epoch: 194, loss: 0.135642
global_step: 15742, epoch: 194, loss: 0.204485
global_step: 15743, epoch: 194, loss: 0.238418
global_step: 15744, epoch: 194, loss: 0.185911
global_step: 15745, epoch: 194, loss: 0.167537
global_step: 15746, epoch: 194, loss: 0.237538
global_step: 15747, epoch: 194, loss: 0.236638
global_step: 15748, epoch: 194, loss: 0.185113
global_step: 15749, epoch: 194, loss: 0.144711
global_step: 15750, epoch: 194, loss: 0.129186
global_step: 15751, epoch: 194, loss: 0.247683
global_step: 15752, epoch: 194, loss: 0.136296
global_step: 15753, epoch: 194, loss: 0.134859
global_step: 15754, epoch: 194, loss: 0.137332
global_step: 15755, epoch: 194, loss: 0.131719
global_step: 15756, epoch: 194, loss: 0.174615
global_step: 15757, epoch: 194, loss: 0.182140
global_step: 15758, epoch: 194, loss: 0.243618
global_step: 15759, epoch: 194, loss: 0.164043
global_step: 15760, epoch: 194, loss: 0.175415
epoch: 194
train	acc: 0.9719	macro: p 0.9765, r 0.9617, f1: 0.9688	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5428	macro: p 0.3751, r 0.3183, f1: 0.3185	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4987
test	acc: 0.5816	macro: p 0.4110, r 0.3178, f1: 0.3232	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5414
global_step: 15761, epoch: 195, loss: 0.250894
global_step: 15762, epoch: 195, loss: 0.174620
global_step: 15763, epoch: 195, loss: 0.190712
global_step: 15764, epoch: 195, loss: 0.201872
global_step: 15765, epoch: 195, loss: 0.135199
global_step: 15766, epoch: 195, loss: 0.191857
global_step: 15767, epoch: 195, loss: 0.193227
global_step: 15768, epoch: 195, loss: 0.184164
global_step: 15769, epoch: 195, loss: 0.151879
global_step: 15770, epoch: 195, loss: 0.219832
global_step: 15771, epoch: 195, loss: 0.170894
global_step: 15772, epoch: 195, loss: 0.199216
global_step: 15773, epoch: 195, loss: 0.177399
global_step: 15774, epoch: 195, loss: 0.204143
global_step: 15775, epoch: 195, loss: 0.154159
global_step: 15776, epoch: 195, loss: 0.151901
global_step: 15777, epoch: 195, loss: 0.166531
global_step: 15778, epoch: 195, loss: 0.154125
global_step: 15779, epoch: 195, loss: 0.206577
global_step: 15780, epoch: 195, loss: 0.198422
global_step: 15781, epoch: 195, loss: 0.181141
global_step: 15782, epoch: 195, loss: 0.133651
global_step: 15783, epoch: 195, loss: 0.213156
global_step: 15784, epoch: 195, loss: 0.168788
global_step: 15785, epoch: 195, loss: 0.149570
global_step: 15786, epoch: 195, loss: 0.189620
global_step: 15787, epoch: 195, loss: 0.225487
global_step: 15788, epoch: 195, loss: 0.203928
global_step: 15789, epoch: 195, loss: 0.201183
global_step: 15790, epoch: 195, loss: 0.176933
global_step: 15791, epoch: 195, loss: 0.159741
global_step: 15792, epoch: 195, loss: 0.221056
global_step: 15793, epoch: 195, loss: 0.182613
global_step: 15794, epoch: 195, loss: 0.166488
global_step: 15795, epoch: 195, loss: 0.172634
global_step: 15796, epoch: 195, loss: 0.196171
global_step: 15797, epoch: 195, loss: 0.182357
global_step: 15798, epoch: 195, loss: 0.195670
global_step: 15799, epoch: 195, loss: 0.179025
global_step: 15800, epoch: 195, loss: 0.028456
epoch: 195
train	acc: 0.9728	macro: p 0.9766, r 0.9632, f1: 0.9696	micro: p 0.9728, r 0.9728, f1 0.9728	weighted_f1:0.9728
dev	acc: 0.5410	macro: p 0.3678, r 0.3198, f1: 0.3214	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.5012
test	acc: 0.5728	macro: p 0.3771, r 0.3204, f1: 0.3284	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5412
global_step: 15801, epoch: 196, loss: 0.188491
global_step: 15802, epoch: 196, loss: 0.203622
global_step: 15803, epoch: 196, loss: 0.175073
global_step: 15804, epoch: 196, loss: 0.178324
global_step: 15805, epoch: 196, loss: 0.168956
global_step: 15806, epoch: 196, loss: 0.143458
global_step: 15807, epoch: 196, loss: 0.189418
global_step: 15808, epoch: 196, loss: 0.129261
global_step: 15809, epoch: 196, loss: 0.098202
global_step: 15810, epoch: 196, loss: 0.208674
global_step: 15811, epoch: 196, loss: 0.146874
global_step: 15812, epoch: 196, loss: 0.232751
global_step: 15813, epoch: 196, loss: 0.308866
global_step: 15814, epoch: 196, loss: 0.208534
global_step: 15815, epoch: 196, loss: 0.101492
global_step: 15816, epoch: 196, loss: 0.215379
global_step: 15817, epoch: 196, loss: 0.176004
global_step: 15818, epoch: 196, loss: 0.164341
global_step: 15819, epoch: 196, loss: 0.161803
global_step: 15820, epoch: 196, loss: 0.203493
global_step: 15821, epoch: 196, loss: 0.135667
global_step: 15822, epoch: 196, loss: 0.146997
global_step: 15823, epoch: 196, loss: 0.222231
global_step: 15824, epoch: 196, loss: 0.141884
global_step: 15825, epoch: 196, loss: 0.172726
global_step: 15826, epoch: 196, loss: 0.170738
global_step: 15827, epoch: 196, loss: 0.180778
global_step: 15828, epoch: 196, loss: 0.128639
global_step: 15829, epoch: 196, loss: 0.220320
global_step: 15830, epoch: 196, loss: 0.184280
global_step: 15831, epoch: 196, loss: 0.137160
global_step: 15832, epoch: 196, loss: 0.160454
global_step: 15833, epoch: 196, loss: 0.141652
global_step: 15834, epoch: 196, loss: 0.209831
global_step: 15835, epoch: 196, loss: 0.150283
global_step: 15836, epoch: 196, loss: 0.164997
global_step: 15837, epoch: 196, loss: 0.210874
global_step: 15838, epoch: 196, loss: 0.124521
global_step: 15839, epoch: 196, loss: 0.194181
global_step: 15840, epoch: 196, loss: 0.028432
epoch: 196
train	acc: 0.9725	macro: p 0.9760, r 0.9629, f1: 0.9692	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5365	macro: p 0.3731, r 0.3133, f1: 0.3173	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4943
test	acc: 0.5766	macro: p 0.3892, r 0.3168, f1: 0.3274	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5374
global_step: 15841, epoch: 197, loss: 0.214029
global_step: 15842, epoch: 197, loss: 0.163307
global_step: 15843, epoch: 197, loss: 0.188209
global_step: 15844, epoch: 197, loss: 0.209345
global_step: 15845, epoch: 197, loss: 0.217416
global_step: 15846, epoch: 197, loss: 0.109213
global_step: 15847, epoch: 197, loss: 0.201357
global_step: 15848, epoch: 197, loss: 0.149774
global_step: 15849, epoch: 197, loss: 0.162670
global_step: 15850, epoch: 197, loss: 0.179744
global_step: 15851, epoch: 197, loss: 0.155698
global_step: 15852, epoch: 197, loss: 0.169381
global_step: 15853, epoch: 197, loss: 0.172194
global_step: 15854, epoch: 197, loss: 0.158979
global_step: 15855, epoch: 197, loss: 0.193924
global_step: 15856, epoch: 197, loss: 0.193564
global_step: 15857, epoch: 197, loss: 0.166127
global_step: 15858, epoch: 197, loss: 0.174278
global_step: 15859, epoch: 197, loss: 0.132270
global_step: 15860, epoch: 197, loss: 0.200873
global_step: 15861, epoch: 197, loss: 0.161905
global_step: 15862, epoch: 197, loss: 0.157930
global_step: 15863, epoch: 197, loss: 0.184025
global_step: 15864, epoch: 197, loss: 0.175857
global_step: 15865, epoch: 197, loss: 0.127178
global_step: 15866, epoch: 197, loss: 0.169692
global_step: 15867, epoch: 197, loss: 0.157672
global_step: 15868, epoch: 197, loss: 0.172702
global_step: 15869, epoch: 197, loss: 0.191488
global_step: 15870, epoch: 197, loss: 0.154167
global_step: 15871, epoch: 197, loss: 0.200907
global_step: 15872, epoch: 197, loss: 0.118401
global_step: 15873, epoch: 197, loss: 0.132076
global_step: 15874, epoch: 197, loss: 0.279085
global_step: 15875, epoch: 197, loss: 0.197255
global_step: 15876, epoch: 197, loss: 0.161624
global_step: 15877, epoch: 197, loss: 0.151636
global_step: 15878, epoch: 197, loss: 0.206288
global_step: 15879, epoch: 197, loss: 0.224711
global_step: 15880, epoch: 197, loss: 0.120990
epoch: 197
train	acc: 0.9727	macro: p 0.9756, r 0.9635, f1: 0.9693	micro: p 0.9727, r 0.9727, f1 0.9727	weighted_f1:0.9727
dev	acc: 0.5392	macro: p 0.3667, r 0.3173, f1: 0.3177	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4988
test	acc: 0.5759	macro: p 0.4058, r 0.3209, f1: 0.3300	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5410
global_step: 15881, epoch: 198, loss: 0.216300
global_step: 15882, epoch: 198, loss: 0.156082
global_step: 15883, epoch: 198, loss: 0.204988
global_step: 15884, epoch: 198, loss: 0.211037
global_step: 15885, epoch: 198, loss: 0.146835
global_step: 15886, epoch: 198, loss: 0.177751
global_step: 15887, epoch: 198, loss: 0.185609
global_step: 15888, epoch: 198, loss: 0.176863
global_step: 15889, epoch: 198, loss: 0.116287
global_step: 15890, epoch: 198, loss: 0.192357
global_step: 15891, epoch: 198, loss: 0.167752
global_step: 15892, epoch: 198, loss: 0.276089
global_step: 15893, epoch: 198, loss: 0.153299
global_step: 15894, epoch: 198, loss: 0.248697
global_step: 15895, epoch: 198, loss: 0.123193
global_step: 15896, epoch: 198, loss: 0.100376
global_step: 15897, epoch: 198, loss: 0.163065
global_step: 15898, epoch: 198, loss: 0.165075
global_step: 15899, epoch: 198, loss: 0.151164
global_step: 15900, epoch: 198, loss: 0.178668
global_step: 15901, epoch: 198, loss: 0.227142
global_step: 15902, epoch: 198, loss: 0.175306
global_step: 15903, epoch: 198, loss: 0.202750
global_step: 15904, epoch: 198, loss: 0.258017
global_step: 15905, epoch: 198, loss: 0.120241
global_step: 15906, epoch: 198, loss: 0.171002
global_step: 15907, epoch: 198, loss: 0.192761
global_step: 15908, epoch: 198, loss: 0.165257
global_step: 15909, epoch: 198, loss: 0.131118
global_step: 15910, epoch: 198, loss: 0.131229
global_step: 15911, epoch: 198, loss: 0.123512
global_step: 15912, epoch: 198, loss: 0.183137
global_step: 15913, epoch: 198, loss: 0.187031
global_step: 15914, epoch: 198, loss: 0.126607
global_step: 15915, epoch: 198, loss: 0.248891
global_step: 15916, epoch: 198, loss: 0.170062
global_step: 15917, epoch: 198, loss: 0.134318
global_step: 15918, epoch: 198, loss: 0.156582
global_step: 15919, epoch: 198, loss: 0.182589
global_step: 15920, epoch: 198, loss: 0.036664
epoch: 198
train	acc: 0.9727	macro: p 0.9765, r 0.9632, f1: 0.9697	micro: p 0.9727, r 0.9727, f1 0.9727	weighted_f1:0.9727
dev	acc: 0.5410	macro: p 0.3841, r 0.3178, f1: 0.3208	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4992
test	acc: 0.5759	macro: p 0.3954, r 0.3193, f1: 0.3321	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5414
global_step: 15921, epoch: 199, loss: 0.223705
global_step: 15922, epoch: 199, loss: 0.112751
global_step: 15923, epoch: 199, loss: 0.199289
global_step: 15924, epoch: 199, loss: 0.198805
global_step: 15925, epoch: 199, loss: 0.213471
global_step: 15926, epoch: 199, loss: 0.188289
global_step: 15927, epoch: 199, loss: 0.223410
global_step: 15928, epoch: 199, loss: 0.217008
global_step: 15929, epoch: 199, loss: 0.266338
global_step: 15930, epoch: 199, loss: 0.161645
global_step: 15931, epoch: 199, loss: 0.172237
global_step: 15932, epoch: 199, loss: 0.146098
global_step: 15933, epoch: 199, loss: 0.122460
global_step: 15934, epoch: 199, loss: 0.146367
global_step: 15935, epoch: 199, loss: 0.218384
global_step: 15936, epoch: 199, loss: 0.152275
global_step: 15937, epoch: 199, loss: 0.206956
global_step: 15938, epoch: 199, loss: 0.167336
global_step: 15939, epoch: 199, loss: 0.157436
global_step: 15940, epoch: 199, loss: 0.147629
global_step: 15941, epoch: 199, loss: 0.160406
global_step: 15942, epoch: 199, loss: 0.152413
global_step: 15943, epoch: 199, loss: 0.092395
global_step: 15944, epoch: 199, loss: 0.132848
global_step: 15945, epoch: 199, loss: 0.170860
global_step: 15946, epoch: 199, loss: 0.174445
global_step: 15947, epoch: 199, loss: 0.182184
global_step: 15948, epoch: 199, loss: 0.147269
global_step: 15949, epoch: 199, loss: 0.158717
global_step: 15950, epoch: 199, loss: 0.163835
global_step: 15951, epoch: 199, loss: 0.205875
global_step: 15952, epoch: 199, loss: 0.153446
global_step: 15953, epoch: 199, loss: 0.203566
global_step: 15954, epoch: 199, loss: 0.157292
global_step: 15955, epoch: 199, loss: 0.211959
global_step: 15956, epoch: 199, loss: 0.218665
global_step: 15957, epoch: 199, loss: 0.193319
global_step: 15958, epoch: 199, loss: 0.174677
global_step: 15959, epoch: 199, loss: 0.152671
global_step: 15960, epoch: 199, loss: 0.327530
epoch: 199
train	acc: 0.9726	macro: p 0.9761, r 0.9630, f1: 0.9693	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5446	macro: p 0.3847, r 0.3190, f1: 0.3244	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5022
test	acc: 0.5732	macro: p 0.3832, r 0.3119, f1: 0.3218	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5333
global_step: 15961, epoch: 200, loss: 0.142808
global_step: 15962, epoch: 200, loss: 0.153439
global_step: 15963, epoch: 200, loss: 0.121228
global_step: 15964, epoch: 200, loss: 0.105632
global_step: 15965, epoch: 200, loss: 0.155746
global_step: 15966, epoch: 200, loss: 0.118323
global_step: 15967, epoch: 200, loss: 0.163491
global_step: 15968, epoch: 200, loss: 0.191001
global_step: 15969, epoch: 200, loss: 0.177044
global_step: 15970, epoch: 200, loss: 0.241569
global_step: 15971, epoch: 200, loss: 0.183332
global_step: 15972, epoch: 200, loss: 0.201467
global_step: 15973, epoch: 200, loss: 0.246345
global_step: 15974, epoch: 200, loss: 0.104813
global_step: 15975, epoch: 200, loss: 0.158877
global_step: 15976, epoch: 200, loss: 0.203505
global_step: 15977, epoch: 200, loss: 0.290150
global_step: 15978, epoch: 200, loss: 0.157490
global_step: 15979, epoch: 200, loss: 0.144099
global_step: 15980, epoch: 200, loss: 0.234296
global_step: 15981, epoch: 200, loss: 0.140054
global_step: 15982, epoch: 200, loss: 0.164863
global_step: 15983, epoch: 200, loss: 0.157070
global_step: 15984, epoch: 200, loss: 0.184823
global_step: 15985, epoch: 200, loss: 0.171370
global_step: 15986, epoch: 200, loss: 0.280825
global_step: 15987, epoch: 200, loss: 0.218818
global_step: 15988, epoch: 200, loss: 0.129205
global_step: 15989, epoch: 200, loss: 0.194030
global_step: 15990, epoch: 200, loss: 0.167760
global_step: 15991, epoch: 200, loss: 0.229234
global_step: 15992, epoch: 200, loss: 0.154214
global_step: 15993, epoch: 200, loss: 0.181749
global_step: 15994, epoch: 200, loss: 0.175944
global_step: 15995, epoch: 200, loss: 0.232850
global_step: 15996, epoch: 200, loss: 0.169665
global_step: 15997, epoch: 200, loss: 0.204985
global_step: 15998, epoch: 200, loss: 0.211183
global_step: 15999, epoch: 200, loss: 0.227482
global_step: 16000, epoch: 200, loss: 0.202287
epoch: 200
train	acc: 0.9729	macro: p 0.9753, r 0.9661, f1: 0.9705	micro: p 0.9729, r 0.9729, f1 0.9729	weighted_f1:0.9729
dev	acc: 0.5329	macro: p 0.3639, r 0.3202, f1: 0.3222	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4970
test	acc: 0.5713	macro: p 0.3636, r 0.3210, f1: 0.3285	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5405
BEST MODEL epoch: 35
train	acc: 0.7790 macro_p: 0.6759 macro_r: 0.5262 macro_f1: 0.5277 micro_p: 0.7790 micro_r: 0.7790 micro_f1: 0.7790 weighted_f1: 0.7542
dev	acc: 0.5699 macro_p: 0.3752 macro_r: 0.3260 macro_f1: 0.3259 micro_p: 0.5699 micro_r: 0.5699 micro_f1: 0.5699 weighted_f1: 0.5212
test	acc: 0.6019 macro_p: 0.3638 macro_r: 0.3232 macro_f1: 0.3289 micro_p: 0.6019 micro_r: 0.6019 micro_f1: 0.6019 weighted_f1: 0.5610
==========ROUND 3==========
global_step: 16001, epoch: 1, loss: 2.066785
global_step: 16002, epoch: 1, loss: 2.012724
global_step: 16003, epoch: 1, loss: 1.971998
global_step: 16004, epoch: 1, loss: 1.938641
global_step: 16005, epoch: 1, loss: 1.888432
global_step: 16006, epoch: 1, loss: 1.867962
global_step: 16007, epoch: 1, loss: 1.842375
global_step: 16008, epoch: 1, loss: 1.805190
global_step: 16009, epoch: 1, loss: 1.796193
global_step: 16010, epoch: 1, loss: 1.731630
global_step: 16011, epoch: 1, loss: 1.729579
global_step: 16012, epoch: 1, loss: 1.682548
global_step: 16013, epoch: 1, loss: 1.716399
global_step: 16014, epoch: 1, loss: 1.619528
global_step: 16015, epoch: 1, loss: 1.536650
global_step: 16016, epoch: 1, loss: 1.580947
global_step: 16017, epoch: 1, loss: 1.644655
global_step: 16018, epoch: 1, loss: 1.608005
global_step: 16019, epoch: 1, loss: 1.623406
global_step: 16020, epoch: 1, loss: 1.546398
global_step: 16021, epoch: 1, loss: 1.582486
global_step: 16022, epoch: 1, loss: 1.539383
global_step: 16023, epoch: 1, loss: 1.510208
global_step: 16024, epoch: 1, loss: 1.579441
global_step: 16025, epoch: 1, loss: 1.448314
global_step: 16026, epoch: 1, loss: 1.629990
global_step: 16027, epoch: 1, loss: 1.427655
global_step: 16028, epoch: 1, loss: 1.510896
global_step: 16029, epoch: 1, loss: 1.589858
global_step: 16030, epoch: 1, loss: 1.549087
global_step: 16031, epoch: 1, loss: 1.520478
global_step: 16032, epoch: 1, loss: 1.464699
global_step: 16033, epoch: 1, loss: 1.472109
global_step: 16034, epoch: 1, loss: 1.448337
global_step: 16035, epoch: 1, loss: 1.525876
global_step: 16036, epoch: 1, loss: 1.484984
global_step: 16037, epoch: 1, loss: 1.489598
global_step: 16038, epoch: 1, loss: 1.543084
global_step: 16039, epoch: 1, loss: 1.466113
global_step: 16040, epoch: 1, loss: 0.748191
epoch: 1
train	acc: 0.5186	macro: p 0.2762, r 0.1880, f1: 0.1519	micro: p 0.5186, r 0.5186, f1 0.5186	weighted_f1:0.3921
dev	acc: 0.4626	macro: p 0.1138, r 0.1851, f1: 0.1377	micro: p 0.4626, r 0.4626, f1 0.4626	weighted_f1:0.3230
test	acc: 0.5230	macro: p 0.2715, r 0.1888, f1: 0.1511	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.3941
New best model!
global_step: 16041, epoch: 2, loss: 1.366394
global_step: 16042, epoch: 2, loss: 1.404977
global_step: 16043, epoch: 2, loss: 1.542759
global_step: 16044, epoch: 2, loss: 1.488812
global_step: 16045, epoch: 2, loss: 1.365557
global_step: 16046, epoch: 2, loss: 1.514100
global_step: 16047, epoch: 2, loss: 1.409555
global_step: 16048, epoch: 2, loss: 1.428892
global_step: 16049, epoch: 2, loss: 1.455129
global_step: 16050, epoch: 2, loss: 1.527563
global_step: 16051, epoch: 2, loss: 1.467144
global_step: 16052, epoch: 2, loss: 1.432905
global_step: 16053, epoch: 2, loss: 1.391232
global_step: 16054, epoch: 2, loss: 1.357180
global_step: 16055, epoch: 2, loss: 1.414011
global_step: 16056, epoch: 2, loss: 1.429991
global_step: 16057, epoch: 2, loss: 1.449113
global_step: 16058, epoch: 2, loss: 1.416489
global_step: 16059, epoch: 2, loss: 1.400840
global_step: 16060, epoch: 2, loss: 1.450253
global_step: 16061, epoch: 2, loss: 1.393104
global_step: 16062, epoch: 2, loss: 1.426252
global_step: 16063, epoch: 2, loss: 1.478463
global_step: 16064, epoch: 2, loss: 1.299920
global_step: 16065, epoch: 2, loss: 1.443389
global_step: 16066, epoch: 2, loss: 1.553777
global_step: 16067, epoch: 2, loss: 1.398135
global_step: 16068, epoch: 2, loss: 1.427095
global_step: 16069, epoch: 2, loss: 1.496050
global_step: 16070, epoch: 2, loss: 1.376928
global_step: 16071, epoch: 2, loss: 1.479771
global_step: 16072, epoch: 2, loss: 1.367076
global_step: 16073, epoch: 2, loss: 1.378109
global_step: 16074, epoch: 2, loss: 1.507267
global_step: 16075, epoch: 2, loss: 1.394755
global_step: 16076, epoch: 2, loss: 1.368167
global_step: 16077, epoch: 2, loss: 1.507706
global_step: 16078, epoch: 2, loss: 1.431538
global_step: 16079, epoch: 2, loss: 1.451973
global_step: 16080, epoch: 2, loss: 1.307901
epoch: 2
train	acc: 0.5492	macro: p 0.2520, r 0.2256, f1: 0.1909	micro: p 0.5492, r 0.5492, f1 0.5492	weighted_f1:0.4460
dev	acc: 0.4968	macro: p 0.2430, r 0.2299, f1: 0.1828	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.3822
test	acc: 0.5540	macro: p 0.2411, r 0.2335, f1: 0.1960	micro: p 0.5540, r 0.5540, f1 0.5540	weighted_f1:0.4505
New best model!
global_step: 16081, epoch: 3, loss: 1.512213
global_step: 16082, epoch: 3, loss: 1.454955
global_step: 16083, epoch: 3, loss: 1.399190
global_step: 16084, epoch: 3, loss: 1.470133
global_step: 16085, epoch: 3, loss: 1.478209
global_step: 16086, epoch: 3, loss: 1.246078
global_step: 16087, epoch: 3, loss: 1.556224
global_step: 16088, epoch: 3, loss: 1.432359
global_step: 16089, epoch: 3, loss: 1.393309
global_step: 16090, epoch: 3, loss: 1.464700
global_step: 16091, epoch: 3, loss: 1.318804
global_step: 16092, epoch: 3, loss: 1.265964
global_step: 16093, epoch: 3, loss: 1.464235
global_step: 16094, epoch: 3, loss: 1.269397
global_step: 16095, epoch: 3, loss: 1.369899
global_step: 16096, epoch: 3, loss: 1.318331
global_step: 16097, epoch: 3, loss: 1.359718
global_step: 16098, epoch: 3, loss: 1.269709
global_step: 16099, epoch: 3, loss: 1.384926
global_step: 16100, epoch: 3, loss: 1.449816
global_step: 16101, epoch: 3, loss: 1.299916
global_step: 16102, epoch: 3, loss: 1.377715
global_step: 16103, epoch: 3, loss: 1.425746
global_step: 16104, epoch: 3, loss: 1.327120
global_step: 16105, epoch: 3, loss: 1.364743
global_step: 16106, epoch: 3, loss: 1.333089
global_step: 16107, epoch: 3, loss: 1.410910
global_step: 16108, epoch: 3, loss: 1.376644
global_step: 16109, epoch: 3, loss: 1.341044
global_step: 16110, epoch: 3, loss: 1.334691
global_step: 16111, epoch: 3, loss: 1.387664
global_step: 16112, epoch: 3, loss: 1.289004
global_step: 16113, epoch: 3, loss: 1.460626
global_step: 16114, epoch: 3, loss: 1.406013
global_step: 16115, epoch: 3, loss: 1.409528
global_step: 16116, epoch: 3, loss: 1.466053
global_step: 16117, epoch: 3, loss: 1.415688
global_step: 16118, epoch: 3, loss: 1.386277
global_step: 16119, epoch: 3, loss: 1.357917
global_step: 16120, epoch: 3, loss: 0.719299
epoch: 3
train	acc: 0.5632	macro: p 0.3214, r 0.2411, f1: 0.2220	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.4720
dev	acc: 0.5131	macro: p 0.3198, r 0.2451, f1: 0.2111	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4095
test	acc: 0.5648	macro: p 0.2953, r 0.2458, f1: 0.2206	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.4706
New best model!
global_step: 16121, epoch: 4, loss: 1.360715
global_step: 16122, epoch: 4, loss: 1.370630
global_step: 16123, epoch: 4, loss: 1.329713
global_step: 16124, epoch: 4, loss: 1.359158
global_step: 16125, epoch: 4, loss: 1.339112
global_step: 16126, epoch: 4, loss: 1.336192
global_step: 16127, epoch: 4, loss: 1.228413
global_step: 16128, epoch: 4, loss: 1.351344
global_step: 16129, epoch: 4, loss: 1.445038
global_step: 16130, epoch: 4, loss: 1.361805
global_step: 16131, epoch: 4, loss: 1.330670
global_step: 16132, epoch: 4, loss: 1.459861
global_step: 16133, epoch: 4, loss: 1.384182
global_step: 16134, epoch: 4, loss: 1.347226
global_step: 16135, epoch: 4, loss: 1.252421
global_step: 16136, epoch: 4, loss: 1.424335
global_step: 16137, epoch: 4, loss: 1.286746
global_step: 16138, epoch: 4, loss: 1.336078
global_step: 16139, epoch: 4, loss: 1.449003
global_step: 16140, epoch: 4, loss: 1.434468
global_step: 16141, epoch: 4, loss: 1.418616
global_step: 16142, epoch: 4, loss: 1.335476
global_step: 16143, epoch: 4, loss: 1.395445
global_step: 16144, epoch: 4, loss: 1.319606
global_step: 16145, epoch: 4, loss: 1.407207
global_step: 16146, epoch: 4, loss: 1.488457
global_step: 16147, epoch: 4, loss: 1.372590
global_step: 16148, epoch: 4, loss: 1.312517
global_step: 16149, epoch: 4, loss: 1.343628
global_step: 16150, epoch: 4, loss: 1.319614
global_step: 16151, epoch: 4, loss: 1.213655
global_step: 16152, epoch: 4, loss: 1.285357
global_step: 16153, epoch: 4, loss: 1.334117
global_step: 16154, epoch: 4, loss: 1.337127
global_step: 16155, epoch: 4, loss: 1.282953
global_step: 16156, epoch: 4, loss: 1.423699
global_step: 16157, epoch: 4, loss: 1.237622
global_step: 16158, epoch: 4, loss: 1.451996
global_step: 16159, epoch: 4, loss: 1.338728
global_step: 16160, epoch: 4, loss: 1.250295
epoch: 4
train	acc: 0.5814	macro: p 0.3010, r 0.2737, f1: 0.2703	micro: p 0.5814, r 0.5814, f1 0.5814	weighted_f1:0.5127
dev	acc: 0.5230	macro: p 0.2695, r 0.2580, f1: 0.2433	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4417
test	acc: 0.5713	macro: p 0.2783, r 0.2605, f1: 0.2542	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5013
New best model!
global_step: 16161, epoch: 5, loss: 1.218595
global_step: 16162, epoch: 5, loss: 1.309681
global_step: 16163, epoch: 5, loss: 1.375008
global_step: 16164, epoch: 5, loss: 1.270724
global_step: 16165, epoch: 5, loss: 1.312114
global_step: 16166, epoch: 5, loss: 1.321860
global_step: 16167, epoch: 5, loss: 1.341914
global_step: 16168, epoch: 5, loss: 1.378736
global_step: 16169, epoch: 5, loss: 1.286306
global_step: 16170, epoch: 5, loss: 1.325967
global_step: 16171, epoch: 5, loss: 1.370127
global_step: 16172, epoch: 5, loss: 1.336854
global_step: 16173, epoch: 5, loss: 1.285405
global_step: 16174, epoch: 5, loss: 1.374255
global_step: 16175, epoch: 5, loss: 1.352799
global_step: 16176, epoch: 5, loss: 1.310515
global_step: 16177, epoch: 5, loss: 1.337705
global_step: 16178, epoch: 5, loss: 1.423808
global_step: 16179, epoch: 5, loss: 1.292960
global_step: 16180, epoch: 5, loss: 1.294443
global_step: 16181, epoch: 5, loss: 1.374337
global_step: 16182, epoch: 5, loss: 1.323938
global_step: 16183, epoch: 5, loss: 1.236277
global_step: 16184, epoch: 5, loss: 1.373672
global_step: 16185, epoch: 5, loss: 1.362581
global_step: 16186, epoch: 5, loss: 1.328321
global_step: 16187, epoch: 5, loss: 1.361515
global_step: 16188, epoch: 5, loss: 1.354913
global_step: 16189, epoch: 5, loss: 1.348961
global_step: 16190, epoch: 5, loss: 1.255394
global_step: 16191, epoch: 5, loss: 1.286519
global_step: 16192, epoch: 5, loss: 1.316317
global_step: 16193, epoch: 5, loss: 1.371675
global_step: 16194, epoch: 5, loss: 1.271396
global_step: 16195, epoch: 5, loss: 1.375138
global_step: 16196, epoch: 5, loss: 1.345855
global_step: 16197, epoch: 5, loss: 1.376536
global_step: 16198, epoch: 5, loss: 1.323697
global_step: 16199, epoch: 5, loss: 1.432285
global_step: 16200, epoch: 5, loss: 1.470939
epoch: 5
train	acc: 0.5850	macro: p 0.3187, r 0.2759, f1: 0.2696	micro: p 0.5850, r 0.5850, f1 0.5850	weighted_f1:0.5151
dev	acc: 0.5257	macro: p 0.2892, r 0.2649, f1: 0.2389	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4385
test	acc: 0.5728	macro: p 0.2813, r 0.2636, f1: 0.2454	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.4944
global_step: 16201, epoch: 6, loss: 1.305964
global_step: 16202, epoch: 6, loss: 1.393995
global_step: 16203, epoch: 6, loss: 1.307682
global_step: 16204, epoch: 6, loss: 1.283959
global_step: 16205, epoch: 6, loss: 1.366846
global_step: 16206, epoch: 6, loss: 1.289422
global_step: 16207, epoch: 6, loss: 1.352632
global_step: 16208, epoch: 6, loss: 1.301516
global_step: 16209, epoch: 6, loss: 1.364367
global_step: 16210, epoch: 6, loss: 1.189057
global_step: 16211, epoch: 6, loss: 1.294419
global_step: 16212, epoch: 6, loss: 1.419880
global_step: 16213, epoch: 6, loss: 1.317125
global_step: 16214, epoch: 6, loss: 1.294049
global_step: 16215, epoch: 6, loss: 1.272532
global_step: 16216, epoch: 6, loss: 1.272375
global_step: 16217, epoch: 6, loss: 1.307787
global_step: 16218, epoch: 6, loss: 1.291991
global_step: 16219, epoch: 6, loss: 1.279058
global_step: 16220, epoch: 6, loss: 1.278174
global_step: 16221, epoch: 6, loss: 1.368982
global_step: 16222, epoch: 6, loss: 1.366778
global_step: 16223, epoch: 6, loss: 1.372001
global_step: 16224, epoch: 6, loss: 1.422501
global_step: 16225, epoch: 6, loss: 1.223100
global_step: 16226, epoch: 6, loss: 1.361910
global_step: 16227, epoch: 6, loss: 1.338385
global_step: 16228, epoch: 6, loss: 1.277056
global_step: 16229, epoch: 6, loss: 1.279092
global_step: 16230, epoch: 6, loss: 1.282217
global_step: 16231, epoch: 6, loss: 1.288985
global_step: 16232, epoch: 6, loss: 1.283128
global_step: 16233, epoch: 6, loss: 1.268752
global_step: 16234, epoch: 6, loss: 1.457612
global_step: 16235, epoch: 6, loss: 1.285581
global_step: 16236, epoch: 6, loss: 1.329953
global_step: 16237, epoch: 6, loss: 1.165374
global_step: 16238, epoch: 6, loss: 1.303867
global_step: 16239, epoch: 6, loss: 1.349407
global_step: 16240, epoch: 6, loss: 1.422649
epoch: 6
train	acc: 0.5901	macro: p 0.3869, r 0.2871, f1: 0.2849	micro: p 0.5901, r 0.5901, f1 0.5901	weighted_f1:0.5271
dev	acc: 0.5275	macro: p 0.2770, r 0.2673, f1: 0.2509	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4504
test	acc: 0.5805	macro: p 0.4358, r 0.2735, f1: 0.2671	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5139
New best model!
global_step: 16241, epoch: 7, loss: 1.309865
global_step: 16242, epoch: 7, loss: 1.279179
global_step: 16243, epoch: 7, loss: 1.369078
global_step: 16244, epoch: 7, loss: 1.327834
global_step: 16245, epoch: 7, loss: 1.295659
global_step: 16246, epoch: 7, loss: 1.306607
global_step: 16247, epoch: 7, loss: 1.316040
global_step: 16248, epoch: 7, loss: 1.209504
global_step: 16249, epoch: 7, loss: 1.267373
global_step: 16250, epoch: 7, loss: 1.308912
global_step: 16251, epoch: 7, loss: 1.379167
global_step: 16252, epoch: 7, loss: 1.250477
global_step: 16253, epoch: 7, loss: 1.310868
global_step: 16254, epoch: 7, loss: 1.250360
global_step: 16255, epoch: 7, loss: 1.244838
global_step: 16256, epoch: 7, loss: 1.290232
global_step: 16257, epoch: 7, loss: 1.320729
global_step: 16258, epoch: 7, loss: 1.303271
global_step: 16259, epoch: 7, loss: 1.248065
global_step: 16260, epoch: 7, loss: 1.298036
global_step: 16261, epoch: 7, loss: 1.341701
global_step: 16262, epoch: 7, loss: 1.358289
global_step: 16263, epoch: 7, loss: 1.332756
global_step: 16264, epoch: 7, loss: 1.397834
global_step: 16265, epoch: 7, loss: 1.284815
global_step: 16266, epoch: 7, loss: 1.219402
global_step: 16267, epoch: 7, loss: 1.332408
global_step: 16268, epoch: 7, loss: 1.342536
global_step: 16269, epoch: 7, loss: 1.210294
global_step: 16270, epoch: 7, loss: 1.262001
global_step: 16271, epoch: 7, loss: 1.255521
global_step: 16272, epoch: 7, loss: 1.306590
global_step: 16273, epoch: 7, loss: 1.232386
global_step: 16274, epoch: 7, loss: 1.291048
global_step: 16275, epoch: 7, loss: 1.345125
global_step: 16276, epoch: 7, loss: 1.356316
global_step: 16277, epoch: 7, loss: 1.245375
global_step: 16278, epoch: 7, loss: 1.218828
global_step: 16279, epoch: 7, loss: 1.355449
global_step: 16280, epoch: 7, loss: 0.620371
epoch: 7
train	acc: 0.5937	macro: p 0.3206, r 0.2872, f1: 0.2867	micro: p 0.5937, r 0.5937, f1 0.5937	weighted_f1:0.5284
dev	acc: 0.5239	macro: p 0.2663, r 0.2609, f1: 0.2457	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4443
test	acc: 0.5835	macro: p 0.2970, r 0.2745, f1: 0.2705	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5161
global_step: 16281, epoch: 8, loss: 1.294375
global_step: 16282, epoch: 8, loss: 1.302581
global_step: 16283, epoch: 8, loss: 1.163310
global_step: 16284, epoch: 8, loss: 1.358568
global_step: 16285, epoch: 8, loss: 1.268692
global_step: 16286, epoch: 8, loss: 1.388804
global_step: 16287, epoch: 8, loss: 1.327820
global_step: 16288, epoch: 8, loss: 1.435004
global_step: 16289, epoch: 8, loss: 1.186354
global_step: 16290, epoch: 8, loss: 1.316829
global_step: 16291, epoch: 8, loss: 1.232185
global_step: 16292, epoch: 8, loss: 1.257152
global_step: 16293, epoch: 8, loss: 1.424500
global_step: 16294, epoch: 8, loss: 1.281635
global_step: 16295, epoch: 8, loss: 1.233989
global_step: 16296, epoch: 8, loss: 1.306388
global_step: 16297, epoch: 8, loss: 1.255847
global_step: 16298, epoch: 8, loss: 1.316653
global_step: 16299, epoch: 8, loss: 1.387427
global_step: 16300, epoch: 8, loss: 1.278747
global_step: 16301, epoch: 8, loss: 1.283712
global_step: 16302, epoch: 8, loss: 1.313170
global_step: 16303, epoch: 8, loss: 1.354132
global_step: 16304, epoch: 8, loss: 1.287483
global_step: 16305, epoch: 8, loss: 1.227787
global_step: 16306, epoch: 8, loss: 1.264151
global_step: 16307, epoch: 8, loss: 1.200498
global_step: 16308, epoch: 8, loss: 1.151882
global_step: 16309, epoch: 8, loss: 1.252861
global_step: 16310, epoch: 8, loss: 1.280100
global_step: 16311, epoch: 8, loss: 1.244846
global_step: 16312, epoch: 8, loss: 1.331953
global_step: 16313, epoch: 8, loss: 1.311830
global_step: 16314, epoch: 8, loss: 1.290106
global_step: 16315, epoch: 8, loss: 1.206364
global_step: 16316, epoch: 8, loss: 1.190709
global_step: 16317, epoch: 8, loss: 1.293185
global_step: 16318, epoch: 8, loss: 1.234101
global_step: 16319, epoch: 8, loss: 1.294421
global_step: 16320, epoch: 8, loss: 1.261237
epoch: 8
train	acc: 0.5971	macro: p 0.4736, r 0.2879, f1: 0.2877	micro: p 0.5971, r 0.5971, f1 0.5971	weighted_f1:0.5306
dev	acc: 0.5275	macro: p 0.2780, r 0.2648, f1: 0.2476	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4464
test	acc: 0.5839	macro: p 0.3066, r 0.2747, f1: 0.2678	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5140
global_step: 16321, epoch: 9, loss: 1.286156
global_step: 16322, epoch: 9, loss: 1.306295
global_step: 16323, epoch: 9, loss: 1.178552
global_step: 16324, epoch: 9, loss: 1.304004
global_step: 16325, epoch: 9, loss: 1.230468
global_step: 16326, epoch: 9, loss: 1.244376
global_step: 16327, epoch: 9, loss: 1.218583
global_step: 16328, epoch: 9, loss: 1.296596
global_step: 16329, epoch: 9, loss: 1.233306
global_step: 16330, epoch: 9, loss: 1.245489
global_step: 16331, epoch: 9, loss: 1.327008
global_step: 16332, epoch: 9, loss: 1.217421
global_step: 16333, epoch: 9, loss: 1.244355
global_step: 16334, epoch: 9, loss: 1.210391
global_step: 16335, epoch: 9, loss: 1.311573
global_step: 16336, epoch: 9, loss: 1.288480
global_step: 16337, epoch: 9, loss: 1.215162
global_step: 16338, epoch: 9, loss: 1.322550
global_step: 16339, epoch: 9, loss: 1.196028
global_step: 16340, epoch: 9, loss: 1.287845
global_step: 16341, epoch: 9, loss: 1.318891
global_step: 16342, epoch: 9, loss: 1.267637
global_step: 16343, epoch: 9, loss: 1.276139
global_step: 16344, epoch: 9, loss: 1.178086
global_step: 16345, epoch: 9, loss: 1.291150
global_step: 16346, epoch: 9, loss: 1.316819
global_step: 16347, epoch: 9, loss: 1.190565
global_step: 16348, epoch: 9, loss: 1.282189
global_step: 16349, epoch: 9, loss: 1.252020
global_step: 16350, epoch: 9, loss: 1.233385
global_step: 16351, epoch: 9, loss: 1.273099
global_step: 16352, epoch: 9, loss: 1.267595
global_step: 16353, epoch: 9, loss: 1.314829
global_step: 16354, epoch: 9, loss: 1.255051
global_step: 16355, epoch: 9, loss: 1.323866
global_step: 16356, epoch: 9, loss: 1.244124
global_step: 16357, epoch: 9, loss: 1.257687
global_step: 16358, epoch: 9, loss: 1.212411
global_step: 16359, epoch: 9, loss: 1.209584
global_step: 16360, epoch: 9, loss: 1.471770
epoch: 9
train	acc: 0.5983	macro: p 0.4363, r 0.2925, f1: 0.2927	micro: p 0.5983, r 0.5983, f1 0.5983	weighted_f1:0.5348
dev	acc: 0.5401	macro: p 0.4388, r 0.2795, f1: 0.2597	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4599
test	acc: 0.5828	macro: p 0.4408, r 0.2762, f1: 0.2661	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5123
New best model!
global_step: 16361, epoch: 10, loss: 1.357407
global_step: 16362, epoch: 10, loss: 1.258396
global_step: 16363, epoch: 10, loss: 1.258652
global_step: 16364, epoch: 10, loss: 1.129014
global_step: 16365, epoch: 10, loss: 1.254593
global_step: 16366, epoch: 10, loss: 1.304168
global_step: 16367, epoch: 10, loss: 1.124077
global_step: 16368, epoch: 10, loss: 1.198721
global_step: 16369, epoch: 10, loss: 1.204605
global_step: 16370, epoch: 10, loss: 1.240360
global_step: 16371, epoch: 10, loss: 1.311011
global_step: 16372, epoch: 10, loss: 1.274304
global_step: 16373, epoch: 10, loss: 1.245272
global_step: 16374, epoch: 10, loss: 1.248133
global_step: 16375, epoch: 10, loss: 1.357156
global_step: 16376, epoch: 10, loss: 1.314116
global_step: 16377, epoch: 10, loss: 1.175690
global_step: 16378, epoch: 10, loss: 1.226338
global_step: 16379, epoch: 10, loss: 1.275479
global_step: 16380, epoch: 10, loss: 1.168599
global_step: 16381, epoch: 10, loss: 1.258797
global_step: 16382, epoch: 10, loss: 1.296996
global_step: 16383, epoch: 10, loss: 1.218755
global_step: 16384, epoch: 10, loss: 1.315322
global_step: 16385, epoch: 10, loss: 1.253320
global_step: 16386, epoch: 10, loss: 1.238042
global_step: 16387, epoch: 10, loss: 1.205116
global_step: 16388, epoch: 10, loss: 1.288795
global_step: 16389, epoch: 10, loss: 1.180915
global_step: 16390, epoch: 10, loss: 1.197076
global_step: 16391, epoch: 10, loss: 1.334499
global_step: 16392, epoch: 10, loss: 1.281112
global_step: 16393, epoch: 10, loss: 1.279368
global_step: 16394, epoch: 10, loss: 1.118209
global_step: 16395, epoch: 10, loss: 1.253530
global_step: 16396, epoch: 10, loss: 1.105096
global_step: 16397, epoch: 10, loss: 1.149278
global_step: 16398, epoch: 10, loss: 1.344291
global_step: 16399, epoch: 10, loss: 1.382840
global_step: 16400, epoch: 10, loss: 1.909142
epoch: 10
train	acc: 0.6106	macro: p 0.4340, r 0.3173, f1: 0.3202	micro: p 0.6106, r 0.6106, f1 0.6106	weighted_f1:0.5567
dev	acc: 0.5473	macro: p 0.3930, r 0.2931, f1: 0.2830	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4804
test	acc: 0.5920	macro: p 0.4305, r 0.2949, f1: 0.2931	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5346
New best model!
global_step: 16401, epoch: 11, loss: 1.243534
global_step: 16402, epoch: 11, loss: 1.217987
global_step: 16403, epoch: 11, loss: 1.310156
global_step: 16404, epoch: 11, loss: 1.266216
global_step: 16405, epoch: 11, loss: 1.195409
global_step: 16406, epoch: 11, loss: 1.076127
global_step: 16407, epoch: 11, loss: 1.266655
global_step: 16408, epoch: 11, loss: 1.231179
global_step: 16409, epoch: 11, loss: 1.260473
global_step: 16410, epoch: 11, loss: 1.233632
global_step: 16411, epoch: 11, loss: 1.165547
global_step: 16412, epoch: 11, loss: 1.308513
global_step: 16413, epoch: 11, loss: 1.330130
global_step: 16414, epoch: 11, loss: 1.309955
global_step: 16415, epoch: 11, loss: 1.274534
global_step: 16416, epoch: 11, loss: 1.249056
global_step: 16417, epoch: 11, loss: 1.361898
global_step: 16418, epoch: 11, loss: 1.205703
global_step: 16419, epoch: 11, loss: 1.143771
global_step: 16420, epoch: 11, loss: 1.125050
global_step: 16421, epoch: 11, loss: 1.309615
global_step: 16422, epoch: 11, loss: 1.266012
global_step: 16423, epoch: 11, loss: 1.266041
global_step: 16424, epoch: 11, loss: 1.236183
global_step: 16425, epoch: 11, loss: 1.247435
global_step: 16426, epoch: 11, loss: 1.214217
global_step: 16427, epoch: 11, loss: 1.154891
global_step: 16428, epoch: 11, loss: 1.170901
global_step: 16429, epoch: 11, loss: 1.092402
global_step: 16430, epoch: 11, loss: 1.182739
global_step: 16431, epoch: 11, loss: 1.235542
global_step: 16432, epoch: 11, loss: 1.325952
global_step: 16433, epoch: 11, loss: 1.184125
global_step: 16434, epoch: 11, loss: 1.228245
global_step: 16435, epoch: 11, loss: 1.134076
global_step: 16436, epoch: 11, loss: 1.244519
global_step: 16437, epoch: 11, loss: 1.165375
global_step: 16438, epoch: 11, loss: 1.173561
global_step: 16439, epoch: 11, loss: 1.288333
global_step: 16440, epoch: 11, loss: 1.228514
epoch: 11
train	acc: 0.6113	macro: p 0.4385, r 0.3109, f1: 0.3147	micro: p 0.6113, r 0.6113, f1 0.6113	weighted_f1:0.5532
dev	acc: 0.5437	macro: p 0.4247, r 0.2853, f1: 0.2743	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4722
test	acc: 0.5885	macro: p 0.4334, r 0.2861, f1: 0.2812	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5249
global_step: 16441, epoch: 12, loss: 1.192287
global_step: 16442, epoch: 12, loss: 1.315423
global_step: 16443, epoch: 12, loss: 1.181593
global_step: 16444, epoch: 12, loss: 1.297042
global_step: 16445, epoch: 12, loss: 1.138309
global_step: 16446, epoch: 12, loss: 1.217448
global_step: 16447, epoch: 12, loss: 1.180860
global_step: 16448, epoch: 12, loss: 1.118799
global_step: 16449, epoch: 12, loss: 1.170255
global_step: 16450, epoch: 12, loss: 1.211345
global_step: 16451, epoch: 12, loss: 1.154832
global_step: 16452, epoch: 12, loss: 1.165811
global_step: 16453, epoch: 12, loss: 1.204659
global_step: 16454, epoch: 12, loss: 1.200563
global_step: 16455, epoch: 12, loss: 1.171661
global_step: 16456, epoch: 12, loss: 1.241165
global_step: 16457, epoch: 12, loss: 1.174473
global_step: 16458, epoch: 12, loss: 1.187673
global_step: 16459, epoch: 12, loss: 1.293180
global_step: 16460, epoch: 12, loss: 1.114157
global_step: 16461, epoch: 12, loss: 1.140970
global_step: 16462, epoch: 12, loss: 1.343675
global_step: 16463, epoch: 12, loss: 1.223577
global_step: 16464, epoch: 12, loss: 1.354648
global_step: 16465, epoch: 12, loss: 1.256720
global_step: 16466, epoch: 12, loss: 1.173606
global_step: 16467, epoch: 12, loss: 1.163815
global_step: 16468, epoch: 12, loss: 1.200497
global_step: 16469, epoch: 12, loss: 1.240692
global_step: 16470, epoch: 12, loss: 1.289036
global_step: 16471, epoch: 12, loss: 1.160215
global_step: 16472, epoch: 12, loss: 1.274746
global_step: 16473, epoch: 12, loss: 1.192284
global_step: 16474, epoch: 12, loss: 1.281642
global_step: 16475, epoch: 12, loss: 1.211753
global_step: 16476, epoch: 12, loss: 1.250988
global_step: 16477, epoch: 12, loss: 1.233482
global_step: 16478, epoch: 12, loss: 1.164754
global_step: 16479, epoch: 12, loss: 1.305566
global_step: 16480, epoch: 12, loss: 0.615078
epoch: 12
train	acc: 0.6164	macro: p 0.4384, r 0.3180, f1: 0.3290	micro: p 0.6164, r 0.6164, f1 0.6164	weighted_f1:0.5619
dev	acc: 0.5455	macro: p 0.3851, r 0.2860, f1: 0.2795	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4764
test	acc: 0.5939	macro: p 0.3935, r 0.2915, f1: 0.2944	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5345
global_step: 16481, epoch: 13, loss: 1.192442
global_step: 16482, epoch: 13, loss: 1.064654
global_step: 16483, epoch: 13, loss: 1.144678
global_step: 16484, epoch: 13, loss: 1.243151
global_step: 16485, epoch: 13, loss: 1.146902
global_step: 16486, epoch: 13, loss: 1.295237
global_step: 16487, epoch: 13, loss: 1.158018
global_step: 16488, epoch: 13, loss: 1.234565
global_step: 16489, epoch: 13, loss: 1.195508
global_step: 16490, epoch: 13, loss: 1.261332
global_step: 16491, epoch: 13, loss: 1.233054
global_step: 16492, epoch: 13, loss: 1.120218
global_step: 16493, epoch: 13, loss: 1.160891
global_step: 16494, epoch: 13, loss: 1.216674
global_step: 16495, epoch: 13, loss: 1.365169
global_step: 16496, epoch: 13, loss: 1.184270
global_step: 16497, epoch: 13, loss: 1.122708
global_step: 16498, epoch: 13, loss: 1.140382
global_step: 16499, epoch: 13, loss: 1.331589
global_step: 16500, epoch: 13, loss: 1.079900
global_step: 16501, epoch: 13, loss: 1.280435
global_step: 16502, epoch: 13, loss: 1.196713
global_step: 16503, epoch: 13, loss: 1.229329
global_step: 16504, epoch: 13, loss: 1.235475
global_step: 16505, epoch: 13, loss: 1.278426
global_step: 16506, epoch: 13, loss: 1.160912
global_step: 16507, epoch: 13, loss: 1.136971
global_step: 16508, epoch: 13, loss: 1.350644
global_step: 16509, epoch: 13, loss: 1.083292
global_step: 16510, epoch: 13, loss: 1.252060
global_step: 16511, epoch: 13, loss: 1.213123
global_step: 16512, epoch: 13, loss: 1.213150
global_step: 16513, epoch: 13, loss: 1.198804
global_step: 16514, epoch: 13, loss: 1.183180
global_step: 16515, epoch: 13, loss: 1.353507
global_step: 16516, epoch: 13, loss: 1.258671
global_step: 16517, epoch: 13, loss: 1.171048
global_step: 16518, epoch: 13, loss: 1.060722
global_step: 16519, epoch: 13, loss: 1.256812
global_step: 16520, epoch: 13, loss: 0.848018
epoch: 13
train	acc: 0.6176	macro: p 0.4450, r 0.3170, f1: 0.3217	micro: p 0.6176, r 0.6176, f1 0.6176	weighted_f1:0.5609
dev	acc: 0.5428	macro: p 0.3638, r 0.2879, f1: 0.2647	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4647
test	acc: 0.5904	macro: p 0.4081, r 0.2906, f1: 0.2803	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5228
global_step: 16521, epoch: 14, loss: 1.161862
global_step: 16522, epoch: 14, loss: 1.106183
global_step: 16523, epoch: 14, loss: 1.199348
global_step: 16524, epoch: 14, loss: 1.190225
global_step: 16525, epoch: 14, loss: 1.161098
global_step: 16526, epoch: 14, loss: 1.217875
global_step: 16527, epoch: 14, loss: 1.238181
global_step: 16528, epoch: 14, loss: 1.244876
global_step: 16529, epoch: 14, loss: 1.199443
global_step: 16530, epoch: 14, loss: 1.139763
global_step: 16531, epoch: 14, loss: 1.079940
global_step: 16532, epoch: 14, loss: 1.169063
global_step: 16533, epoch: 14, loss: 1.162407
global_step: 16534, epoch: 14, loss: 1.052716
global_step: 16535, epoch: 14, loss: 1.374209
global_step: 16536, epoch: 14, loss: 1.219111
global_step: 16537, epoch: 14, loss: 1.162317
global_step: 16538, epoch: 14, loss: 1.184584
global_step: 16539, epoch: 14, loss: 1.268953
global_step: 16540, epoch: 14, loss: 1.196266
global_step: 16541, epoch: 14, loss: 1.127501
global_step: 16542, epoch: 14, loss: 1.280187
global_step: 16543, epoch: 14, loss: 1.161055
global_step: 16544, epoch: 14, loss: 1.265655
global_step: 16545, epoch: 14, loss: 1.074174
global_step: 16546, epoch: 14, loss: 1.140888
global_step: 16547, epoch: 14, loss: 1.123043
global_step: 16548, epoch: 14, loss: 1.175973
global_step: 16549, epoch: 14, loss: 1.238405
global_step: 16550, epoch: 14, loss: 1.087288
global_step: 16551, epoch: 14, loss: 1.220259
global_step: 16552, epoch: 14, loss: 1.330194
global_step: 16553, epoch: 14, loss: 1.231849
global_step: 16554, epoch: 14, loss: 1.163266
global_step: 16555, epoch: 14, loss: 1.144675
global_step: 16556, epoch: 14, loss: 1.202654
global_step: 16557, epoch: 14, loss: 1.171292
global_step: 16558, epoch: 14, loss: 1.224522
global_step: 16559, epoch: 14, loss: 1.050360
global_step: 16560, epoch: 14, loss: 0.757964
epoch: 14
train	acc: 0.6194	macro: p 0.4495, r 0.3170, f1: 0.3255	micro: p 0.6194, r 0.6194, f1 0.6194	weighted_f1:0.5628
dev	acc: 0.5464	macro: p 0.3911, r 0.2876, f1: 0.2761	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4739
test	acc: 0.5920	macro: p 0.4049, r 0.2889, f1: 0.2850	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5275
global_step: 16561, epoch: 15, loss: 1.238136
global_step: 16562, epoch: 15, loss: 1.196149
global_step: 16563, epoch: 15, loss: 1.104455
global_step: 16564, epoch: 15, loss: 1.093379
global_step: 16565, epoch: 15, loss: 1.158698
global_step: 16566, epoch: 15, loss: 1.154068
global_step: 16567, epoch: 15, loss: 1.133458
global_step: 16568, epoch: 15, loss: 1.166311
global_step: 16569, epoch: 15, loss: 1.248744
global_step: 16570, epoch: 15, loss: 1.311364
global_step: 16571, epoch: 15, loss: 1.170848
global_step: 16572, epoch: 15, loss: 1.265431
global_step: 16573, epoch: 15, loss: 1.133830
global_step: 16574, epoch: 15, loss: 1.289548
global_step: 16575, epoch: 15, loss: 1.118439
global_step: 16576, epoch: 15, loss: 1.217883
global_step: 16577, epoch: 15, loss: 1.088502
global_step: 16578, epoch: 15, loss: 1.154206
global_step: 16579, epoch: 15, loss: 1.115950
global_step: 16580, epoch: 15, loss: 1.133657
global_step: 16581, epoch: 15, loss: 1.178997
global_step: 16582, epoch: 15, loss: 1.120089
global_step: 16583, epoch: 15, loss: 1.060097
global_step: 16584, epoch: 15, loss: 1.213519
global_step: 16585, epoch: 15, loss: 1.164289
global_step: 16586, epoch: 15, loss: 1.106191
global_step: 16587, epoch: 15, loss: 1.137795
global_step: 16588, epoch: 15, loss: 1.150216
global_step: 16589, epoch: 15, loss: 1.191390
global_step: 16590, epoch: 15, loss: 1.163234
global_step: 16591, epoch: 15, loss: 1.091228
global_step: 16592, epoch: 15, loss: 1.208316
global_step: 16593, epoch: 15, loss: 1.115495
global_step: 16594, epoch: 15, loss: 1.254578
global_step: 16595, epoch: 15, loss: 1.217052
global_step: 16596, epoch: 15, loss: 1.244861
global_step: 16597, epoch: 15, loss: 1.123214
global_step: 16598, epoch: 15, loss: 1.229274
global_step: 16599, epoch: 15, loss: 1.151559
global_step: 16600, epoch: 15, loss: 1.641193
epoch: 15
train	acc: 0.6301	macro: p 0.4437, r 0.3331, f1: 0.3421	micro: p 0.6301, r 0.6301, f1 0.6301	weighted_f1:0.5785
dev	acc: 0.5464	macro: p 0.3630, r 0.2920, f1: 0.2766	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4757
test	acc: 0.5950	macro: p 0.4036, r 0.2970, f1: 0.2925	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5331
global_step: 16601, epoch: 16, loss: 0.969905
global_step: 16602, epoch: 16, loss: 1.228440
global_step: 16603, epoch: 16, loss: 1.223573
global_step: 16604, epoch: 16, loss: 1.036892
global_step: 16605, epoch: 16, loss: 1.011318
global_step: 16606, epoch: 16, loss: 1.169465
global_step: 16607, epoch: 16, loss: 1.167256
global_step: 16608, epoch: 16, loss: 1.118791
global_step: 16609, epoch: 16, loss: 1.201375
global_step: 16610, epoch: 16, loss: 1.094283
global_step: 16611, epoch: 16, loss: 1.241911
global_step: 16612, epoch: 16, loss: 1.067868
global_step: 16613, epoch: 16, loss: 1.136660
global_step: 16614, epoch: 16, loss: 1.216024
global_step: 16615, epoch: 16, loss: 1.154213
global_step: 16616, epoch: 16, loss: 1.180163
global_step: 16617, epoch: 16, loss: 1.108653
global_step: 16618, epoch: 16, loss: 1.197676
global_step: 16619, epoch: 16, loss: 1.063846
global_step: 16620, epoch: 16, loss: 1.118857
global_step: 16621, epoch: 16, loss: 1.079371
global_step: 16622, epoch: 16, loss: 1.211792
global_step: 16623, epoch: 16, loss: 1.082861
global_step: 16624, epoch: 16, loss: 1.111959
global_step: 16625, epoch: 16, loss: 1.063435
global_step: 16626, epoch: 16, loss: 1.137848
global_step: 16627, epoch: 16, loss: 1.164289
global_step: 16628, epoch: 16, loss: 1.263689
global_step: 16629, epoch: 16, loss: 1.199563
global_step: 16630, epoch: 16, loss: 1.127951
global_step: 16631, epoch: 16, loss: 1.245417
global_step: 16632, epoch: 16, loss: 1.167502
global_step: 16633, epoch: 16, loss: 1.199589
global_step: 16634, epoch: 16, loss: 1.175217
global_step: 16635, epoch: 16, loss: 1.244721
global_step: 16636, epoch: 16, loss: 1.236668
global_step: 16637, epoch: 16, loss: 1.031104
global_step: 16638, epoch: 16, loss: 1.223633
global_step: 16639, epoch: 16, loss: 1.131703
global_step: 16640, epoch: 16, loss: 1.492214
epoch: 16
train	acc: 0.6449	macro: p 0.4436, r 0.3529, f1: 0.3636	micro: p 0.6449, r 0.6449, f1 0.6449	weighted_f1:0.5984
dev	acc: 0.5528	macro: p 0.3632, r 0.2997, f1: 0.2896	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4887
test	acc: 0.6015	macro: p 0.3893, r 0.3057, f1: 0.3053	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5457
New best model!
global_step: 16641, epoch: 17, loss: 1.171516
global_step: 16642, epoch: 17, loss: 1.060671
global_step: 16643, epoch: 17, loss: 1.185602
global_step: 16644, epoch: 17, loss: 1.164393
global_step: 16645, epoch: 17, loss: 1.200059
global_step: 16646, epoch: 17, loss: 1.151727
global_step: 16647, epoch: 17, loss: 1.271099
global_step: 16648, epoch: 17, loss: 1.209508
global_step: 16649, epoch: 17, loss: 1.022316
global_step: 16650, epoch: 17, loss: 1.143338
global_step: 16651, epoch: 17, loss: 1.162064
global_step: 16652, epoch: 17, loss: 1.160065
global_step: 16653, epoch: 17, loss: 1.146760
global_step: 16654, epoch: 17, loss: 1.118885
global_step: 16655, epoch: 17, loss: 1.188467
global_step: 16656, epoch: 17, loss: 1.204212
global_step: 16657, epoch: 17, loss: 1.159545
global_step: 16658, epoch: 17, loss: 1.112357
global_step: 16659, epoch: 17, loss: 1.088233
global_step: 16660, epoch: 17, loss: 1.119703
global_step: 16661, epoch: 17, loss: 1.105187
global_step: 16662, epoch: 17, loss: 1.181950
global_step: 16663, epoch: 17, loss: 1.182407
global_step: 16664, epoch: 17, loss: 1.092493
global_step: 16665, epoch: 17, loss: 1.013456
global_step: 16666, epoch: 17, loss: 1.130743
global_step: 16667, epoch: 17, loss: 1.052947
global_step: 16668, epoch: 17, loss: 1.152383
global_step: 16669, epoch: 17, loss: 1.143117
global_step: 16670, epoch: 17, loss: 1.089282
global_step: 16671, epoch: 17, loss: 1.235216
global_step: 16672, epoch: 17, loss: 1.208844
global_step: 16673, epoch: 17, loss: 1.176307
global_step: 16674, epoch: 17, loss: 1.081112
global_step: 16675, epoch: 17, loss: 1.071489
global_step: 16676, epoch: 17, loss: 1.086234
global_step: 16677, epoch: 17, loss: 1.174061
global_step: 16678, epoch: 17, loss: 1.184732
global_step: 16679, epoch: 17, loss: 1.170981
global_step: 16680, epoch: 17, loss: 1.074759
epoch: 17
train	acc: 0.6465	macro: p 0.4434, r 0.3548, f1: 0.3662	micro: p 0.6465, r 0.6465, f1 0.6465	weighted_f1:0.6004
dev	acc: 0.5518	macro: p 0.3655, r 0.3001, f1: 0.2869	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4863
test	acc: 0.5981	macro: p 0.3805, r 0.3047, f1: 0.3007	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5401
global_step: 16681, epoch: 18, loss: 1.127704
global_step: 16682, epoch: 18, loss: 1.199692
global_step: 16683, epoch: 18, loss: 1.195240
global_step: 16684, epoch: 18, loss: 1.127143
global_step: 16685, epoch: 18, loss: 1.103410
global_step: 16686, epoch: 18, loss: 1.257779
global_step: 16687, epoch: 18, loss: 1.209347
global_step: 16688, epoch: 18, loss: 1.110678
global_step: 16689, epoch: 18, loss: 1.071253
global_step: 16690, epoch: 18, loss: 1.064557
global_step: 16691, epoch: 18, loss: 1.087058
global_step: 16692, epoch: 18, loss: 1.180212
global_step: 16693, epoch: 18, loss: 1.120217
global_step: 16694, epoch: 18, loss: 1.107332
global_step: 16695, epoch: 18, loss: 1.087641
global_step: 16696, epoch: 18, loss: 1.105204
global_step: 16697, epoch: 18, loss: 1.037385
global_step: 16698, epoch: 18, loss: 1.142007
global_step: 16699, epoch: 18, loss: 1.202910
global_step: 16700, epoch: 18, loss: 1.145841
global_step: 16701, epoch: 18, loss: 1.011660
global_step: 16702, epoch: 18, loss: 1.147297
global_step: 16703, epoch: 18, loss: 1.070941
global_step: 16704, epoch: 18, loss: 1.143667
global_step: 16705, epoch: 18, loss: 1.095969
global_step: 16706, epoch: 18, loss: 1.140066
global_step: 16707, epoch: 18, loss: 1.209478
global_step: 16708, epoch: 18, loss: 1.124038
global_step: 16709, epoch: 18, loss: 1.156642
global_step: 16710, epoch: 18, loss: 1.129009
global_step: 16711, epoch: 18, loss: 1.012024
global_step: 16712, epoch: 18, loss: 1.055080
global_step: 16713, epoch: 18, loss: 1.095907
global_step: 16714, epoch: 18, loss: 1.128524
global_step: 16715, epoch: 18, loss: 1.017422
global_step: 16716, epoch: 18, loss: 1.118840
global_step: 16717, epoch: 18, loss: 1.016066
global_step: 16718, epoch: 18, loss: 1.232445
global_step: 16719, epoch: 18, loss: 1.066049
global_step: 16720, epoch: 18, loss: 0.720953
epoch: 18
train	acc: 0.6552	macro: p 0.4487, r 0.3677, f1: 0.3750	micro: p 0.6552, r 0.6552, f1 0.6552	weighted_f1:0.6083
dev	acc: 0.5564	macro: p 0.3591, r 0.3056, f1: 0.2922	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4896
test	acc: 0.5973	macro: p 0.3656, r 0.3065, f1: 0.3024	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5416
New best model!
global_step: 16721, epoch: 19, loss: 1.097379
global_step: 16722, epoch: 19, loss: 1.154552
global_step: 16723, epoch: 19, loss: 1.086592
global_step: 16724, epoch: 19, loss: 1.220241
global_step: 16725, epoch: 19, loss: 1.064646
global_step: 16726, epoch: 19, loss: 1.104264
global_step: 16727, epoch: 19, loss: 1.163850
global_step: 16728, epoch: 19, loss: 0.988081
global_step: 16729, epoch: 19, loss: 1.160668
global_step: 16730, epoch: 19, loss: 1.077779
global_step: 16731, epoch: 19, loss: 1.241832
global_step: 16732, epoch: 19, loss: 1.033853
global_step: 16733, epoch: 19, loss: 0.981705
global_step: 16734, epoch: 19, loss: 1.007571
global_step: 16735, epoch: 19, loss: 1.153860
global_step: 16736, epoch: 19, loss: 1.034444
global_step: 16737, epoch: 19, loss: 1.136509
global_step: 16738, epoch: 19, loss: 1.105431
global_step: 16739, epoch: 19, loss: 1.096771
global_step: 16740, epoch: 19, loss: 1.093924
global_step: 16741, epoch: 19, loss: 1.125724
global_step: 16742, epoch: 19, loss: 1.143085
global_step: 16743, epoch: 19, loss: 1.054331
global_step: 16744, epoch: 19, loss: 1.140630
global_step: 16745, epoch: 19, loss: 1.106229
global_step: 16746, epoch: 19, loss: 1.183676
global_step: 16747, epoch: 19, loss: 1.180250
global_step: 16748, epoch: 19, loss: 1.031763
global_step: 16749, epoch: 19, loss: 1.056547
global_step: 16750, epoch: 19, loss: 1.090793
global_step: 16751, epoch: 19, loss: 1.266966
global_step: 16752, epoch: 19, loss: 1.250867
global_step: 16753, epoch: 19, loss: 1.143813
global_step: 16754, epoch: 19, loss: 1.087671
global_step: 16755, epoch: 19, loss: 1.048594
global_step: 16756, epoch: 19, loss: 1.193832
global_step: 16757, epoch: 19, loss: 1.145811
global_step: 16758, epoch: 19, loss: 1.143442
global_step: 16759, epoch: 19, loss: 1.039996
global_step: 16760, epoch: 19, loss: 1.122457
epoch: 19
train	acc: 0.6704	macro: p 0.4563, r 0.3851, f1: 0.3917	micro: p 0.6704, r 0.6704, f1 0.6704	weighted_f1:0.6270
dev	acc: 0.5573	macro: p 0.3719, r 0.3101, f1: 0.2977	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4945
test	acc: 0.5962	macro: p 0.3611, r 0.3069, f1: 0.3015	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5417
New best model!
global_step: 16761, epoch: 20, loss: 0.994014
global_step: 16762, epoch: 20, loss: 1.181393
global_step: 16763, epoch: 20, loss: 0.968492
global_step: 16764, epoch: 20, loss: 1.113384
global_step: 16765, epoch: 20, loss: 1.049650
global_step: 16766, epoch: 20, loss: 1.045101
global_step: 16767, epoch: 20, loss: 1.073067
global_step: 16768, epoch: 20, loss: 1.226728
global_step: 16769, epoch: 20, loss: 1.128363
global_step: 16770, epoch: 20, loss: 1.076904
global_step: 16771, epoch: 20, loss: 1.056323
global_step: 16772, epoch: 20, loss: 1.087074
global_step: 16773, epoch: 20, loss: 1.035012
global_step: 16774, epoch: 20, loss: 1.053586
global_step: 16775, epoch: 20, loss: 1.040359
global_step: 16776, epoch: 20, loss: 1.027628
global_step: 16777, epoch: 20, loss: 1.057585
global_step: 16778, epoch: 20, loss: 1.127489
global_step: 16779, epoch: 20, loss: 1.091841
global_step: 16780, epoch: 20, loss: 1.126494
global_step: 16781, epoch: 20, loss: 1.082784
global_step: 16782, epoch: 20, loss: 1.029078
global_step: 16783, epoch: 20, loss: 1.086445
global_step: 16784, epoch: 20, loss: 1.027040
global_step: 16785, epoch: 20, loss: 1.101857
global_step: 16786, epoch: 20, loss: 1.075664
global_step: 16787, epoch: 20, loss: 1.137628
global_step: 16788, epoch: 20, loss: 1.341728
global_step: 16789, epoch: 20, loss: 1.054032
global_step: 16790, epoch: 20, loss: 1.162823
global_step: 16791, epoch: 20, loss: 1.230212
global_step: 16792, epoch: 20, loss: 1.130646
global_step: 16793, epoch: 20, loss: 1.036857
global_step: 16794, epoch: 20, loss: 1.040477
global_step: 16795, epoch: 20, loss: 1.162403
global_step: 16796, epoch: 20, loss: 1.104475
global_step: 16797, epoch: 20, loss: 1.151558
global_step: 16798, epoch: 20, loss: 1.079995
global_step: 16799, epoch: 20, loss: 1.120373
global_step: 16800, epoch: 20, loss: 0.557792
epoch: 20
train	acc: 0.6567	macro: p 0.4655, r 0.3640, f1: 0.3778	micro: p 0.6567, r 0.6567, f1 0.6567	weighted_f1:0.6106
dev	acc: 0.5528	macro: p 0.3579, r 0.2957, f1: 0.2903	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4887
test	acc: 0.6061	macro: p 0.3910, r 0.3084, f1: 0.3137	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5522
global_step: 16801, epoch: 21, loss: 1.058830
global_step: 16802, epoch: 21, loss: 0.976385
global_step: 16803, epoch: 21, loss: 1.046266
global_step: 16804, epoch: 21, loss: 1.114299
global_step: 16805, epoch: 21, loss: 0.994534
global_step: 16806, epoch: 21, loss: 1.093427
global_step: 16807, epoch: 21, loss: 1.089155
global_step: 16808, epoch: 21, loss: 1.061362
global_step: 16809, epoch: 21, loss: 1.107969
global_step: 16810, epoch: 21, loss: 1.042273
global_step: 16811, epoch: 21, loss: 1.133464
global_step: 16812, epoch: 21, loss: 1.019233
global_step: 16813, epoch: 21, loss: 1.080510
global_step: 16814, epoch: 21, loss: 1.006633
global_step: 16815, epoch: 21, loss: 1.109246
global_step: 16816, epoch: 21, loss: 1.147403
global_step: 16817, epoch: 21, loss: 1.135553
global_step: 16818, epoch: 21, loss: 1.033547
global_step: 16819, epoch: 21, loss: 0.989158
global_step: 16820, epoch: 21, loss: 1.158137
global_step: 16821, epoch: 21, loss: 1.260572
global_step: 16822, epoch: 21, loss: 1.085038
global_step: 16823, epoch: 21, loss: 1.058851
global_step: 16824, epoch: 21, loss: 1.150020
global_step: 16825, epoch: 21, loss: 1.080889
global_step: 16826, epoch: 21, loss: 1.113297
global_step: 16827, epoch: 21, loss: 1.058419
global_step: 16828, epoch: 21, loss: 1.132370
global_step: 16829, epoch: 21, loss: 1.144579
global_step: 16830, epoch: 21, loss: 0.988451
global_step: 16831, epoch: 21, loss: 1.094904
global_step: 16832, epoch: 21, loss: 1.007515
global_step: 16833, epoch: 21, loss: 0.996256
global_step: 16834, epoch: 21, loss: 1.054668
global_step: 16835, epoch: 21, loss: 1.085086
global_step: 16836, epoch: 21, loss: 1.078717
global_step: 16837, epoch: 21, loss: 1.100727
global_step: 16838, epoch: 21, loss: 1.187796
global_step: 16839, epoch: 21, loss: 1.069295
global_step: 16840, epoch: 21, loss: 1.451240
epoch: 21
train	acc: 0.6705	macro: p 0.4644, r 0.3831, f1: 0.3952	micro: p 0.6705, r 0.6705, f1 0.6705	weighted_f1:0.6277
dev	acc: 0.5654	macro: p 0.3655, r 0.3108, f1: 0.3041	micro: p 0.5654, r 0.5654, f1 0.5654	weighted_f1:0.5026
test	acc: 0.6027	macro: p 0.3691, r 0.3090, f1: 0.3112	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5498
New best model!
global_step: 16841, epoch: 22, loss: 1.098962
global_step: 16842, epoch: 22, loss: 1.151987
global_step: 16843, epoch: 22, loss: 1.004108
global_step: 16844, epoch: 22, loss: 1.126461
global_step: 16845, epoch: 22, loss: 1.038658
global_step: 16846, epoch: 22, loss: 1.040645
global_step: 16847, epoch: 22, loss: 1.141294
global_step: 16848, epoch: 22, loss: 1.091028
global_step: 16849, epoch: 22, loss: 0.977053
global_step: 16850, epoch: 22, loss: 1.098755
global_step: 16851, epoch: 22, loss: 1.277476
global_step: 16852, epoch: 22, loss: 1.155621
global_step: 16853, epoch: 22, loss: 0.997472
global_step: 16854, epoch: 22, loss: 1.044739
global_step: 16855, epoch: 22, loss: 0.988586
global_step: 16856, epoch: 22, loss: 0.969523
global_step: 16857, epoch: 22, loss: 1.129549
global_step: 16858, epoch: 22, loss: 0.946091
global_step: 16859, epoch: 22, loss: 1.064837
global_step: 16860, epoch: 22, loss: 1.003883
global_step: 16861, epoch: 22, loss: 1.027606
global_step: 16862, epoch: 22, loss: 1.058997
global_step: 16863, epoch: 22, loss: 1.126668
global_step: 16864, epoch: 22, loss: 1.056397
global_step: 16865, epoch: 22, loss: 1.060532
global_step: 16866, epoch: 22, loss: 1.032233
global_step: 16867, epoch: 22, loss: 1.129086
global_step: 16868, epoch: 22, loss: 1.174309
global_step: 16869, epoch: 22, loss: 0.987806
global_step: 16870, epoch: 22, loss: 1.092313
global_step: 16871, epoch: 22, loss: 1.068720
global_step: 16872, epoch: 22, loss: 1.065167
global_step: 16873, epoch: 22, loss: 1.187008
global_step: 16874, epoch: 22, loss: 1.020596
global_step: 16875, epoch: 22, loss: 1.025254
global_step: 16876, epoch: 22, loss: 1.005247
global_step: 16877, epoch: 22, loss: 1.063092
global_step: 16878, epoch: 22, loss: 1.050453
global_step: 16879, epoch: 22, loss: 1.194675
global_step: 16880, epoch: 22, loss: 1.309896
epoch: 22
train	acc: 0.6865	macro: p 0.4749, r 0.3989, f1: 0.4090	micro: p 0.6865, r 0.6865, f1 0.6865	weighted_f1:0.6439
dev	acc: 0.5645	macro: p 0.3729, r 0.3152, f1: 0.3041	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5015
test	acc: 0.6000	macro: p 0.3638, r 0.3097, f1: 0.3081	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5462
global_step: 16881, epoch: 23, loss: 1.082757
global_step: 16882, epoch: 23, loss: 1.038357
global_step: 16883, epoch: 23, loss: 1.096593
global_step: 16884, epoch: 23, loss: 0.915029
global_step: 16885, epoch: 23, loss: 0.991010
global_step: 16886, epoch: 23, loss: 0.949032
global_step: 16887, epoch: 23, loss: 0.974302
global_step: 16888, epoch: 23, loss: 1.057195
global_step: 16889, epoch: 23, loss: 0.952404
global_step: 16890, epoch: 23, loss: 1.119615
global_step: 16891, epoch: 23, loss: 1.090650
global_step: 16892, epoch: 23, loss: 1.026908
global_step: 16893, epoch: 23, loss: 0.919425
global_step: 16894, epoch: 23, loss: 1.076365
global_step: 16895, epoch: 23, loss: 1.072721
global_step: 16896, epoch: 23, loss: 1.031524
global_step: 16897, epoch: 23, loss: 1.114311
global_step: 16898, epoch: 23, loss: 1.045522
global_step: 16899, epoch: 23, loss: 1.126618
global_step: 16900, epoch: 23, loss: 1.085209
global_step: 16901, epoch: 23, loss: 1.009780
global_step: 16902, epoch: 23, loss: 1.100693
global_step: 16903, epoch: 23, loss: 1.069126
global_step: 16904, epoch: 23, loss: 0.919610
global_step: 16905, epoch: 23, loss: 1.057994
global_step: 16906, epoch: 23, loss: 1.060686
global_step: 16907, epoch: 23, loss: 1.139607
global_step: 16908, epoch: 23, loss: 1.123079
global_step: 16909, epoch: 23, loss: 1.043714
global_step: 16910, epoch: 23, loss: 1.108572
global_step: 16911, epoch: 23, loss: 1.132623
global_step: 16912, epoch: 23, loss: 1.083183
global_step: 16913, epoch: 23, loss: 1.095594
global_step: 16914, epoch: 23, loss: 1.046565
global_step: 16915, epoch: 23, loss: 1.125002
global_step: 16916, epoch: 23, loss: 1.130671
global_step: 16917, epoch: 23, loss: 0.952638
global_step: 16918, epoch: 23, loss: 1.010634
global_step: 16919, epoch: 23, loss: 1.058831
global_step: 16920, epoch: 23, loss: 0.977481
epoch: 23
train	acc: 0.7079	macro: p 0.4677, r 0.4391, f1: 0.4471	micro: p 0.7079, r 0.7079, f1 0.7079	weighted_f1:0.6773
dev	acc: 0.5537	macro: p 0.3453, r 0.3149, f1: 0.3068	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5013
test	acc: 0.6008	macro: p 0.3603, r 0.3219, f1: 0.3243	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5571
global_step: 16921, epoch: 24, loss: 1.019249
global_step: 16922, epoch: 24, loss: 1.075435
global_step: 16923, epoch: 24, loss: 0.955968
global_step: 16924, epoch: 24, loss: 1.149972
global_step: 16925, epoch: 24, loss: 1.025497
global_step: 16926, epoch: 24, loss: 0.910753
global_step: 16927, epoch: 24, loss: 0.988915
global_step: 16928, epoch: 24, loss: 1.008842
global_step: 16929, epoch: 24, loss: 1.130945
global_step: 16930, epoch: 24, loss: 1.082353
global_step: 16931, epoch: 24, loss: 1.155360
global_step: 16932, epoch: 24, loss: 1.054308
global_step: 16933, epoch: 24, loss: 1.018837
global_step: 16934, epoch: 24, loss: 1.011862
global_step: 16935, epoch: 24, loss: 1.009735
global_step: 16936, epoch: 24, loss: 1.092512
global_step: 16937, epoch: 24, loss: 1.086465
global_step: 16938, epoch: 24, loss: 0.958761
global_step: 16939, epoch: 24, loss: 0.978836
global_step: 16940, epoch: 24, loss: 1.064420
global_step: 16941, epoch: 24, loss: 1.120277
global_step: 16942, epoch: 24, loss: 1.027997
global_step: 16943, epoch: 24, loss: 0.988614
global_step: 16944, epoch: 24, loss: 1.036973
global_step: 16945, epoch: 24, loss: 1.042004
global_step: 16946, epoch: 24, loss: 1.066558
global_step: 16947, epoch: 24, loss: 1.196291
global_step: 16948, epoch: 24, loss: 1.024095
global_step: 16949, epoch: 24, loss: 1.105136
global_step: 16950, epoch: 24, loss: 1.023834
global_step: 16951, epoch: 24, loss: 1.041610
global_step: 16952, epoch: 24, loss: 0.997501
global_step: 16953, epoch: 24, loss: 0.995382
global_step: 16954, epoch: 24, loss: 0.998534
global_step: 16955, epoch: 24, loss: 1.070287
global_step: 16956, epoch: 24, loss: 0.999369
global_step: 16957, epoch: 24, loss: 1.070267
global_step: 16958, epoch: 24, loss: 0.987887
global_step: 16959, epoch: 24, loss: 0.944115
global_step: 16960, epoch: 24, loss: 0.528852
epoch: 24
train	acc: 0.6792	macro: p 0.4835, r 0.3839, f1: 0.3999	micro: p 0.6792, r 0.6792, f1 0.6792	weighted_f1:0.6346
dev	acc: 0.5500	macro: p 0.3629, r 0.2928, f1: 0.2821	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4809
test	acc: 0.6004	macro: p 0.3731, r 0.3013, f1: 0.3015	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5409
global_step: 16961, epoch: 25, loss: 1.060176
global_step: 16962, epoch: 25, loss: 0.982264
global_step: 16963, epoch: 25, loss: 0.938866
global_step: 16964, epoch: 25, loss: 1.047636
global_step: 16965, epoch: 25, loss: 0.956487
global_step: 16966, epoch: 25, loss: 1.095599
global_step: 16967, epoch: 25, loss: 1.047245
global_step: 16968, epoch: 25, loss: 0.974556
global_step: 16969, epoch: 25, loss: 1.010861
global_step: 16970, epoch: 25, loss: 0.959408
global_step: 16971, epoch: 25, loss: 1.047929
global_step: 16972, epoch: 25, loss: 0.985674
global_step: 16973, epoch: 25, loss: 1.059706
global_step: 16974, epoch: 25, loss: 1.062353
global_step: 16975, epoch: 25, loss: 0.999703
global_step: 16976, epoch: 25, loss: 1.016747
global_step: 16977, epoch: 25, loss: 1.044177
global_step: 16978, epoch: 25, loss: 1.017323
global_step: 16979, epoch: 25, loss: 1.027498
global_step: 16980, epoch: 25, loss: 1.000597
global_step: 16981, epoch: 25, loss: 1.044161
global_step: 16982, epoch: 25, loss: 1.177681
global_step: 16983, epoch: 25, loss: 0.981287
global_step: 16984, epoch: 25, loss: 1.136279
global_step: 16985, epoch: 25, loss: 1.030549
global_step: 16986, epoch: 25, loss: 1.029740
global_step: 16987, epoch: 25, loss: 1.025587
global_step: 16988, epoch: 25, loss: 1.081785
global_step: 16989, epoch: 25, loss: 1.074886
global_step: 16990, epoch: 25, loss: 1.051093
global_step: 16991, epoch: 25, loss: 1.074364
global_step: 16992, epoch: 25, loss: 0.970935
global_step: 16993, epoch: 25, loss: 1.022415
global_step: 16994, epoch: 25, loss: 0.949019
global_step: 16995, epoch: 25, loss: 0.961721
global_step: 16996, epoch: 25, loss: 0.968795
global_step: 16997, epoch: 25, loss: 0.993563
global_step: 16998, epoch: 25, loss: 1.100566
global_step: 16999, epoch: 25, loss: 0.908220
global_step: 17000, epoch: 25, loss: 0.406540
epoch: 25
train	acc: 0.6808	macro: p 0.4892, r 0.3866, f1: 0.4001	micro: p 0.6808, r 0.6808, f1 0.6808	weighted_f1:0.6372
dev	acc: 0.5482	macro: p 0.3742, r 0.2956, f1: 0.2775	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4760
test	acc: 0.5939	macro: p 0.3843, r 0.2997, f1: 0.2933	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5323
global_step: 17001, epoch: 26, loss: 1.068229
global_step: 17002, epoch: 26, loss: 0.929471
global_step: 17003, epoch: 26, loss: 1.036330
global_step: 17004, epoch: 26, loss: 0.926393
global_step: 17005, epoch: 26, loss: 1.119624
global_step: 17006, epoch: 26, loss: 0.919717
global_step: 17007, epoch: 26, loss: 1.006577
global_step: 17008, epoch: 26, loss: 1.024411
global_step: 17009, epoch: 26, loss: 0.926117
global_step: 17010, epoch: 26, loss: 1.048470
global_step: 17011, epoch: 26, loss: 0.936996
global_step: 17012, epoch: 26, loss: 1.050459
global_step: 17013, epoch: 26, loss: 1.022765
global_step: 17014, epoch: 26, loss: 0.955056
global_step: 17015, epoch: 26, loss: 0.984641
global_step: 17016, epoch: 26, loss: 0.964954
global_step: 17017, epoch: 26, loss: 0.885544
global_step: 17018, epoch: 26, loss: 0.999354
global_step: 17019, epoch: 26, loss: 1.036748
global_step: 17020, epoch: 26, loss: 1.047700
global_step: 17021, epoch: 26, loss: 1.084211
global_step: 17022, epoch: 26, loss: 1.041630
global_step: 17023, epoch: 26, loss: 1.023131
global_step: 17024, epoch: 26, loss: 1.126915
global_step: 17025, epoch: 26, loss: 0.988340
global_step: 17026, epoch: 26, loss: 0.975294
global_step: 17027, epoch: 26, loss: 1.008711
global_step: 17028, epoch: 26, loss: 1.060849
global_step: 17029, epoch: 26, loss: 1.029984
global_step: 17030, epoch: 26, loss: 1.007303
global_step: 17031, epoch: 26, loss: 0.989473
global_step: 17032, epoch: 26, loss: 0.978827
global_step: 17033, epoch: 26, loss: 1.062028
global_step: 17034, epoch: 26, loss: 0.969943
global_step: 17035, epoch: 26, loss: 1.105113
global_step: 17036, epoch: 26, loss: 0.900533
global_step: 17037, epoch: 26, loss: 1.106990
global_step: 17038, epoch: 26, loss: 0.948158
global_step: 17039, epoch: 26, loss: 0.987649
global_step: 17040, epoch: 26, loss: 0.463030
epoch: 26
train	acc: 0.6962	macro: p 0.4910, r 0.4044, f1: 0.4201	micro: p 0.6962, r 0.6962, f1 0.6962	weighted_f1:0.6537
dev	acc: 0.5636	macro: p 0.3751, r 0.3079, f1: 0.3009	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.4977
test	acc: 0.6034	macro: p 0.3742, r 0.3072, f1: 0.3096	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5472
global_step: 17041, epoch: 27, loss: 1.170488
global_step: 17042, epoch: 27, loss: 0.992714
global_step: 17043, epoch: 27, loss: 0.951692
global_step: 17044, epoch: 27, loss: 1.040995
global_step: 17045, epoch: 27, loss: 1.004915
global_step: 17046, epoch: 27, loss: 1.035844
global_step: 17047, epoch: 27, loss: 0.916304
global_step: 17048, epoch: 27, loss: 0.979499
global_step: 17049, epoch: 27, loss: 1.080064
global_step: 17050, epoch: 27, loss: 0.949793
global_step: 17051, epoch: 27, loss: 0.904555
global_step: 17052, epoch: 27, loss: 0.986673
global_step: 17053, epoch: 27, loss: 0.969746
global_step: 17054, epoch: 27, loss: 0.931761
global_step: 17055, epoch: 27, loss: 0.889472
global_step: 17056, epoch: 27, loss: 0.989487
global_step: 17057, epoch: 27, loss: 0.923800
global_step: 17058, epoch: 27, loss: 1.026601
global_step: 17059, epoch: 27, loss: 1.021556
global_step: 17060, epoch: 27, loss: 0.977331
global_step: 17061, epoch: 27, loss: 0.937040
global_step: 17062, epoch: 27, loss: 1.043136
global_step: 17063, epoch: 27, loss: 0.967657
global_step: 17064, epoch: 27, loss: 0.863897
global_step: 17065, epoch: 27, loss: 1.094509
global_step: 17066, epoch: 27, loss: 0.931471
global_step: 17067, epoch: 27, loss: 0.967232
global_step: 17068, epoch: 27, loss: 0.976845
global_step: 17069, epoch: 27, loss: 1.089611
global_step: 17070, epoch: 27, loss: 0.975301
global_step: 17071, epoch: 27, loss: 0.984786
global_step: 17072, epoch: 27, loss: 0.981732
global_step: 17073, epoch: 27, loss: 1.105562
global_step: 17074, epoch: 27, loss: 1.008088
global_step: 17075, epoch: 27, loss: 1.027741
global_step: 17076, epoch: 27, loss: 0.969978
global_step: 17077, epoch: 27, loss: 0.873533
global_step: 17078, epoch: 27, loss: 1.024214
global_step: 17079, epoch: 27, loss: 1.000566
global_step: 17080, epoch: 27, loss: 1.683724
epoch: 27
train	acc: 0.7495	macro: p 0.5057, r 0.4863, f1: 0.4868	micro: p 0.7495, r 0.7495, f1 0.7495	weighted_f1:0.7232
dev	acc: 0.5564	macro: p 0.3536, r 0.3245, f1: 0.3176	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5119
test	acc: 0.6069	macro: p 0.3752, r 0.3341, f1: 0.3373	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5699
New best model!
global_step: 17081, epoch: 28, loss: 0.973193
global_step: 17082, epoch: 28, loss: 0.951884
global_step: 17083, epoch: 28, loss: 0.869100
global_step: 17084, epoch: 28, loss: 0.984209
global_step: 17085, epoch: 28, loss: 0.899532
global_step: 17086, epoch: 28, loss: 1.005707
global_step: 17087, epoch: 28, loss: 1.017071
global_step: 17088, epoch: 28, loss: 0.974691
global_step: 17089, epoch: 28, loss: 0.937553
global_step: 17090, epoch: 28, loss: 0.891488
global_step: 17091, epoch: 28, loss: 0.944457
global_step: 17092, epoch: 28, loss: 1.015456
global_step: 17093, epoch: 28, loss: 0.928480
global_step: 17094, epoch: 28, loss: 1.047176
global_step: 17095, epoch: 28, loss: 0.996437
global_step: 17096, epoch: 28, loss: 0.992605
global_step: 17097, epoch: 28, loss: 1.053949
global_step: 17098, epoch: 28, loss: 0.978205
global_step: 17099, epoch: 28, loss: 0.979971
global_step: 17100, epoch: 28, loss: 0.997292
global_step: 17101, epoch: 28, loss: 0.905907
global_step: 17102, epoch: 28, loss: 0.944422
global_step: 17103, epoch: 28, loss: 0.919353
global_step: 17104, epoch: 28, loss: 0.995022
global_step: 17105, epoch: 28, loss: 1.126836
global_step: 17106, epoch: 28, loss: 0.939278
global_step: 17107, epoch: 28, loss: 0.913416
global_step: 17108, epoch: 28, loss: 0.949109
global_step: 17109, epoch: 28, loss: 0.938435
global_step: 17110, epoch: 28, loss: 0.899749
global_step: 17111, epoch: 28, loss: 1.058901
global_step: 17112, epoch: 28, loss: 0.933121
global_step: 17113, epoch: 28, loss: 1.010553
global_step: 17114, epoch: 28, loss: 1.007206
global_step: 17115, epoch: 28, loss: 1.019958
global_step: 17116, epoch: 28, loss: 1.032810
global_step: 17117, epoch: 28, loss: 0.926997
global_step: 17118, epoch: 28, loss: 0.997404
global_step: 17119, epoch: 28, loss: 1.061337
global_step: 17120, epoch: 28, loss: 1.420793
epoch: 28
train	acc: 0.7447	macro: p 0.5001, r 0.4792, f1: 0.4854	micro: p 0.7447, r 0.7447, f1 0.7447	weighted_f1:0.7160
dev	acc: 0.5600	macro: p 0.3439, r 0.3195, f1: 0.3166	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5103
test	acc: 0.6080	macro: p 0.3602, r 0.3252, f1: 0.3302	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5650
global_step: 17121, epoch: 29, loss: 1.066639
global_step: 17122, epoch: 29, loss: 0.956321
global_step: 17123, epoch: 29, loss: 1.017555
global_step: 17124, epoch: 29, loss: 0.993831
global_step: 17125, epoch: 29, loss: 0.889238
global_step: 17126, epoch: 29, loss: 1.081025
global_step: 17127, epoch: 29, loss: 0.968577
global_step: 17128, epoch: 29, loss: 0.937475
global_step: 17129, epoch: 29, loss: 0.999285
global_step: 17130, epoch: 29, loss: 0.964372
global_step: 17131, epoch: 29, loss: 0.965744
global_step: 17132, epoch: 29, loss: 1.059474
global_step: 17133, epoch: 29, loss: 0.905286
global_step: 17134, epoch: 29, loss: 0.926988
global_step: 17135, epoch: 29, loss: 1.001288
global_step: 17136, epoch: 29, loss: 0.970167
global_step: 17137, epoch: 29, loss: 0.907118
global_step: 17138, epoch: 29, loss: 0.923439
global_step: 17139, epoch: 29, loss: 0.908892
global_step: 17140, epoch: 29, loss: 0.921556
global_step: 17141, epoch: 29, loss: 0.960939
global_step: 17142, epoch: 29, loss: 0.994809
global_step: 17143, epoch: 29, loss: 1.045050
global_step: 17144, epoch: 29, loss: 0.991742
global_step: 17145, epoch: 29, loss: 0.997620
global_step: 17146, epoch: 29, loss: 1.071365
global_step: 17147, epoch: 29, loss: 1.012461
global_step: 17148, epoch: 29, loss: 0.936446
global_step: 17149, epoch: 29, loss: 0.989368
global_step: 17150, epoch: 29, loss: 0.897610
global_step: 17151, epoch: 29, loss: 1.020822
global_step: 17152, epoch: 29, loss: 0.973342
global_step: 17153, epoch: 29, loss: 1.045367
global_step: 17154, epoch: 29, loss: 0.970478
global_step: 17155, epoch: 29, loss: 0.877046
global_step: 17156, epoch: 29, loss: 0.888431
global_step: 17157, epoch: 29, loss: 0.930843
global_step: 17158, epoch: 29, loss: 0.953492
global_step: 17159, epoch: 29, loss: 0.881272
global_step: 17160, epoch: 29, loss: 1.237276
epoch: 29
train	acc: 0.7540	macro: p 0.5045, r 0.4922, f1: 0.4932	micro: p 0.7540, r 0.7540, f1 0.7540	weighted_f1:0.7252
dev	acc: 0.5564	macro: p 0.3327, r 0.3193, f1: 0.3073	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5025
test	acc: 0.6042	macro: p 0.3584, r 0.3290, f1: 0.3289	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5624
global_step: 17161, epoch: 30, loss: 0.918333
global_step: 17162, epoch: 30, loss: 0.940517
global_step: 17163, epoch: 30, loss: 0.924196
global_step: 17164, epoch: 30, loss: 0.994253
global_step: 17165, epoch: 30, loss: 0.916706
global_step: 17166, epoch: 30, loss: 0.968860
global_step: 17167, epoch: 30, loss: 0.967381
global_step: 17168, epoch: 30, loss: 0.944989
global_step: 17169, epoch: 30, loss: 0.899998
global_step: 17170, epoch: 30, loss: 0.957932
global_step: 17171, epoch: 30, loss: 0.989137
global_step: 17172, epoch: 30, loss: 0.979232
global_step: 17173, epoch: 30, loss: 0.902294
global_step: 17174, epoch: 30, loss: 0.954341
global_step: 17175, epoch: 30, loss: 0.957371
global_step: 17176, epoch: 30, loss: 1.013065
global_step: 17177, epoch: 30, loss: 0.898237
global_step: 17178, epoch: 30, loss: 0.980183
global_step: 17179, epoch: 30, loss: 0.858090
global_step: 17180, epoch: 30, loss: 0.941457
global_step: 17181, epoch: 30, loss: 0.860233
global_step: 17182, epoch: 30, loss: 1.062342
global_step: 17183, epoch: 30, loss: 0.983875
global_step: 17184, epoch: 30, loss: 1.064717
global_step: 17185, epoch: 30, loss: 0.890384
global_step: 17186, epoch: 30, loss: 0.913669
global_step: 17187, epoch: 30, loss: 0.887573
global_step: 17188, epoch: 30, loss: 1.010199
global_step: 17189, epoch: 30, loss: 0.972046
global_step: 17190, epoch: 30, loss: 0.844496
global_step: 17191, epoch: 30, loss: 0.999067
global_step: 17192, epoch: 30, loss: 0.828223
global_step: 17193, epoch: 30, loss: 0.959181
global_step: 17194, epoch: 30, loss: 0.957198
global_step: 17195, epoch: 30, loss: 1.006853
global_step: 17196, epoch: 30, loss: 0.977207
global_step: 17197, epoch: 30, loss: 0.970447
global_step: 17198, epoch: 30, loss: 0.974753
global_step: 17199, epoch: 30, loss: 0.878839
global_step: 17200, epoch: 30, loss: 0.800683
epoch: 30
train	acc: 0.7690	macro: p 0.5225, r 0.5025, f1: 0.5040	micro: p 0.7690, r 0.7690, f1 0.7690	weighted_f1:0.7400
dev	acc: 0.5591	macro: p 0.3523, r 0.3224, f1: 0.3091	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5059
test	acc: 0.6019	macro: p 0.3605, r 0.3264, f1: 0.3233	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5584
global_step: 17201, epoch: 31, loss: 1.028862
global_step: 17202, epoch: 31, loss: 0.887949
global_step: 17203, epoch: 31, loss: 0.921154
global_step: 17204, epoch: 31, loss: 0.893408
global_step: 17205, epoch: 31, loss: 0.895371
global_step: 17206, epoch: 31, loss: 0.936736
global_step: 17207, epoch: 31, loss: 0.936890
global_step: 17208, epoch: 31, loss: 0.968103
global_step: 17209, epoch: 31, loss: 0.934410
global_step: 17210, epoch: 31, loss: 0.813775
global_step: 17211, epoch: 31, loss: 1.006346
global_step: 17212, epoch: 31, loss: 0.955581
global_step: 17213, epoch: 31, loss: 0.937314
global_step: 17214, epoch: 31, loss: 0.932511
global_step: 17215, epoch: 31, loss: 0.966944
global_step: 17216, epoch: 31, loss: 1.106406
global_step: 17217, epoch: 31, loss: 0.949735
global_step: 17218, epoch: 31, loss: 0.910080
global_step: 17219, epoch: 31, loss: 0.893744
global_step: 17220, epoch: 31, loss: 0.881089
global_step: 17221, epoch: 31, loss: 0.870431
global_step: 17222, epoch: 31, loss: 0.886213
global_step: 17223, epoch: 31, loss: 0.884269
global_step: 17224, epoch: 31, loss: 1.009982
global_step: 17225, epoch: 31, loss: 0.970417
global_step: 17226, epoch: 31, loss: 0.952162
global_step: 17227, epoch: 31, loss: 0.970171
global_step: 17228, epoch: 31, loss: 0.921571
global_step: 17229, epoch: 31, loss: 0.838063
global_step: 17230, epoch: 31, loss: 0.953756
global_step: 17231, epoch: 31, loss: 0.871917
global_step: 17232, epoch: 31, loss: 1.019589
global_step: 17233, epoch: 31, loss: 0.966641
global_step: 17234, epoch: 31, loss: 0.944184
global_step: 17235, epoch: 31, loss: 0.926077
global_step: 17236, epoch: 31, loss: 0.892050
global_step: 17237, epoch: 31, loss: 0.906893
global_step: 17238, epoch: 31, loss: 0.969543
global_step: 17239, epoch: 31, loss: 0.919679
global_step: 17240, epoch: 31, loss: 1.188858
epoch: 31
train	acc: 0.7495	macro: p 0.6736, r 0.4680, f1: 0.4820	micro: p 0.7495, r 0.7495, f1 0.7495	weighted_f1:0.7155
dev	acc: 0.5627	macro: p 0.3626, r 0.3106, f1: 0.3009	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5010
test	acc: 0.6042	macro: p 0.3777, r 0.3124, f1: 0.3142	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5516
global_step: 17241, epoch: 32, loss: 0.930872
global_step: 17242, epoch: 32, loss: 1.022873
global_step: 17243, epoch: 32, loss: 0.925371
global_step: 17244, epoch: 32, loss: 0.971424
global_step: 17245, epoch: 32, loss: 0.842952
global_step: 17246, epoch: 32, loss: 0.954784
global_step: 17247, epoch: 32, loss: 0.836625
global_step: 17248, epoch: 32, loss: 0.909865
global_step: 17249, epoch: 32, loss: 0.925710
global_step: 17250, epoch: 32, loss: 0.872751
global_step: 17251, epoch: 32, loss: 1.016825
global_step: 17252, epoch: 32, loss: 0.861803
global_step: 17253, epoch: 32, loss: 0.843573
global_step: 17254, epoch: 32, loss: 0.930827
global_step: 17255, epoch: 32, loss: 0.814732
global_step: 17256, epoch: 32, loss: 0.926190
global_step: 17257, epoch: 32, loss: 0.799434
global_step: 17258, epoch: 32, loss: 0.951909
global_step: 17259, epoch: 32, loss: 0.940561
global_step: 17260, epoch: 32, loss: 0.883754
global_step: 17261, epoch: 32, loss: 0.876849
global_step: 17262, epoch: 32, loss: 0.914631
global_step: 17263, epoch: 32, loss: 0.949659
global_step: 17264, epoch: 32, loss: 0.895315
global_step: 17265, epoch: 32, loss: 0.927018
global_step: 17266, epoch: 32, loss: 0.983787
global_step: 17267, epoch: 32, loss: 0.993791
global_step: 17268, epoch: 32, loss: 0.826673
global_step: 17269, epoch: 32, loss: 0.973284
global_step: 17270, epoch: 32, loss: 0.961209
global_step: 17271, epoch: 32, loss: 0.874237
global_step: 17272, epoch: 32, loss: 0.791288
global_step: 17273, epoch: 32, loss: 0.856512
global_step: 17274, epoch: 32, loss: 0.846360
global_step: 17275, epoch: 32, loss: 0.991339
global_step: 17276, epoch: 32, loss: 0.940354
global_step: 17277, epoch: 32, loss: 0.925496
global_step: 17278, epoch: 32, loss: 0.953577
global_step: 17279, epoch: 32, loss: 0.831013
global_step: 17280, epoch: 32, loss: 0.740703
epoch: 32
train	acc: 0.7737	macro: p 0.6761, r 0.5093, f1: 0.5126	micro: p 0.7737, r 0.7737, f1 0.7737	weighted_f1:0.7470
dev	acc: 0.5708	macro: p 0.3716, r 0.3277, f1: 0.3215	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.5202
test	acc: 0.6084	macro: p 0.3760, r 0.3275, f1: 0.3312	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5665
New best model!
global_step: 17281, epoch: 33, loss: 0.915002
global_step: 17282, epoch: 33, loss: 0.871956
global_step: 17283, epoch: 33, loss: 0.940331
global_step: 17284, epoch: 33, loss: 0.899058
global_step: 17285, epoch: 33, loss: 0.839290
global_step: 17286, epoch: 33, loss: 0.853063
global_step: 17287, epoch: 33, loss: 0.980785
global_step: 17288, epoch: 33, loss: 0.913221
global_step: 17289, epoch: 33, loss: 1.012017
global_step: 17290, epoch: 33, loss: 0.837328
global_step: 17291, epoch: 33, loss: 0.899625
global_step: 17292, epoch: 33, loss: 0.909303
global_step: 17293, epoch: 33, loss: 0.943665
global_step: 17294, epoch: 33, loss: 0.910829
global_step: 17295, epoch: 33, loss: 0.967984
global_step: 17296, epoch: 33, loss: 0.855861
global_step: 17297, epoch: 33, loss: 0.850424
global_step: 17298, epoch: 33, loss: 0.997643
global_step: 17299, epoch: 33, loss: 0.902549
global_step: 17300, epoch: 33, loss: 0.916170
global_step: 17301, epoch: 33, loss: 0.822109
global_step: 17302, epoch: 33, loss: 0.961986
global_step: 17303, epoch: 33, loss: 0.932162
global_step: 17304, epoch: 33, loss: 0.945626
global_step: 17305, epoch: 33, loss: 0.826380
global_step: 17306, epoch: 33, loss: 0.870651
global_step: 17307, epoch: 33, loss: 0.806687
global_step: 17308, epoch: 33, loss: 0.901214
global_step: 17309, epoch: 33, loss: 0.936216
global_step: 17310, epoch: 33, loss: 0.907176
global_step: 17311, epoch: 33, loss: 0.958500
global_step: 17312, epoch: 33, loss: 0.937898
global_step: 17313, epoch: 33, loss: 0.853598
global_step: 17314, epoch: 33, loss: 0.818896
global_step: 17315, epoch: 33, loss: 0.918731
global_step: 17316, epoch: 33, loss: 0.962725
global_step: 17317, epoch: 33, loss: 0.903316
global_step: 17318, epoch: 33, loss: 0.852362
global_step: 17319, epoch: 33, loss: 0.835277
global_step: 17320, epoch: 33, loss: 1.198406
epoch: 33
train	acc: 0.7574	macro: p 0.5403, r 0.4739, f1: 0.4868	micro: p 0.7574, r 0.7574, f1 0.7574	weighted_f1:0.7228
dev	acc: 0.5681	macro: p 0.3774, r 0.3147, f1: 0.3036	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5033
test	acc: 0.6042	macro: p 0.3754, r 0.3113, f1: 0.3120	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5504
global_step: 17321, epoch: 34, loss: 0.829447
global_step: 17322, epoch: 34, loss: 0.977015
global_step: 17323, epoch: 34, loss: 0.923523
global_step: 17324, epoch: 34, loss: 0.893380
global_step: 17325, epoch: 34, loss: 0.830955
global_step: 17326, epoch: 34, loss: 0.932732
global_step: 17327, epoch: 34, loss: 0.843574
global_step: 17328, epoch: 34, loss: 0.851553
global_step: 17329, epoch: 34, loss: 0.900637
global_step: 17330, epoch: 34, loss: 0.871686
global_step: 17331, epoch: 34, loss: 0.865093
global_step: 17332, epoch: 34, loss: 0.894663
global_step: 17333, epoch: 34, loss: 0.868926
global_step: 17334, epoch: 34, loss: 0.888963
global_step: 17335, epoch: 34, loss: 0.933514
global_step: 17336, epoch: 34, loss: 0.824607
global_step: 17337, epoch: 34, loss: 0.843318
global_step: 17338, epoch: 34, loss: 0.814265
global_step: 17339, epoch: 34, loss: 0.869653
global_step: 17340, epoch: 34, loss: 0.841262
global_step: 17341, epoch: 34, loss: 0.861353
global_step: 17342, epoch: 34, loss: 0.947194
global_step: 17343, epoch: 34, loss: 0.895581
global_step: 17344, epoch: 34, loss: 0.987819
global_step: 17345, epoch: 34, loss: 0.869068
global_step: 17346, epoch: 34, loss: 0.863496
global_step: 17347, epoch: 34, loss: 0.838552
global_step: 17348, epoch: 34, loss: 0.831092
global_step: 17349, epoch: 34, loss: 0.855344
global_step: 17350, epoch: 34, loss: 0.904231
global_step: 17351, epoch: 34, loss: 0.902707
global_step: 17352, epoch: 34, loss: 0.886041
global_step: 17353, epoch: 34, loss: 0.920928
global_step: 17354, epoch: 34, loss: 0.921766
global_step: 17355, epoch: 34, loss: 0.893224
global_step: 17356, epoch: 34, loss: 0.995211
global_step: 17357, epoch: 34, loss: 0.919278
global_step: 17358, epoch: 34, loss: 0.896534
global_step: 17359, epoch: 34, loss: 0.924410
global_step: 17360, epoch: 34, loss: 0.356783
epoch: 34
train	acc: 0.7873	macro: p 0.6841, r 0.5246, f1: 0.5293	micro: p 0.7873, r 0.7873, f1 0.7873	weighted_f1:0.7594
dev	acc: 0.5555	macro: p 0.3399, r 0.3128, f1: 0.3022	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4989
test	acc: 0.6011	macro: p 0.3572, r 0.3197, f1: 0.3186	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5540
global_step: 17361, epoch: 35, loss: 0.899507
global_step: 17362, epoch: 35, loss: 0.845568
global_step: 17363, epoch: 35, loss: 0.714161
global_step: 17364, epoch: 35, loss: 0.901265
global_step: 17365, epoch: 35, loss: 0.745488
global_step: 17366, epoch: 35, loss: 0.784149
global_step: 17367, epoch: 35, loss: 0.918484
global_step: 17368, epoch: 35, loss: 0.801137
global_step: 17369, epoch: 35, loss: 1.013589
global_step: 17370, epoch: 35, loss: 0.987436
global_step: 17371, epoch: 35, loss: 0.834753
global_step: 17372, epoch: 35, loss: 0.818690
global_step: 17373, epoch: 35, loss: 0.850049
global_step: 17374, epoch: 35, loss: 0.714373
global_step: 17375, epoch: 35, loss: 0.875543
global_step: 17376, epoch: 35, loss: 0.891050
global_step: 17377, epoch: 35, loss: 0.841483
global_step: 17378, epoch: 35, loss: 0.924798
global_step: 17379, epoch: 35, loss: 0.815157
global_step: 17380, epoch: 35, loss: 0.834753
global_step: 17381, epoch: 35, loss: 0.872562
global_step: 17382, epoch: 35, loss: 0.871039
global_step: 17383, epoch: 35, loss: 0.828901
global_step: 17384, epoch: 35, loss: 0.901178
global_step: 17385, epoch: 35, loss: 0.868433
global_step: 17386, epoch: 35, loss: 0.906464
global_step: 17387, epoch: 35, loss: 0.965822
global_step: 17388, epoch: 35, loss: 0.847215
global_step: 17389, epoch: 35, loss: 0.878797
global_step: 17390, epoch: 35, loss: 1.024283
global_step: 17391, epoch: 35, loss: 0.918401
global_step: 17392, epoch: 35, loss: 0.889058
global_step: 17393, epoch: 35, loss: 0.789403
global_step: 17394, epoch: 35, loss: 0.854180
global_step: 17395, epoch: 35, loss: 1.010604
global_step: 17396, epoch: 35, loss: 0.965143
global_step: 17397, epoch: 35, loss: 0.963626
global_step: 17398, epoch: 35, loss: 0.941898
global_step: 17399, epoch: 35, loss: 0.791554
global_step: 17400, epoch: 35, loss: 0.919976
epoch: 35
train	acc: 0.7937	macro: p 0.6928, r 0.5295, f1: 0.5339	micro: p 0.7937, r 0.7937, f1 0.7937	weighted_f1:0.7662
dev	acc: 0.5518	macro: p 0.3449, r 0.3141, f1: 0.3006	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4967
test	acc: 0.5950	macro: p 0.3627, r 0.3155, f1: 0.3142	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5484
global_step: 17401, epoch: 36, loss: 0.786504
global_step: 17402, epoch: 36, loss: 0.851652
global_step: 17403, epoch: 36, loss: 0.805267
global_step: 17404, epoch: 36, loss: 0.847501
global_step: 17405, epoch: 36, loss: 0.922447
global_step: 17406, epoch: 36, loss: 0.888627
global_step: 17407, epoch: 36, loss: 0.745830
global_step: 17408, epoch: 36, loss: 0.757417
global_step: 17409, epoch: 36, loss: 0.918191
global_step: 17410, epoch: 36, loss: 0.794645
global_step: 17411, epoch: 36, loss: 0.807589
global_step: 17412, epoch: 36, loss: 0.905350
global_step: 17413, epoch: 36, loss: 0.840318
global_step: 17414, epoch: 36, loss: 0.872817
global_step: 17415, epoch: 36, loss: 0.883865
global_step: 17416, epoch: 36, loss: 0.897502
global_step: 17417, epoch: 36, loss: 0.871510
global_step: 17418, epoch: 36, loss: 0.857777
global_step: 17419, epoch: 36, loss: 0.802136
global_step: 17420, epoch: 36, loss: 0.773108
global_step: 17421, epoch: 36, loss: 0.807738
global_step: 17422, epoch: 36, loss: 0.850394
global_step: 17423, epoch: 36, loss: 0.953348
global_step: 17424, epoch: 36, loss: 0.923341
global_step: 17425, epoch: 36, loss: 0.879913
global_step: 17426, epoch: 36, loss: 0.834543
global_step: 17427, epoch: 36, loss: 0.754816
global_step: 17428, epoch: 36, loss: 0.956670
global_step: 17429, epoch: 36, loss: 0.980655
global_step: 17430, epoch: 36, loss: 0.711657
global_step: 17431, epoch: 36, loss: 0.826571
global_step: 17432, epoch: 36, loss: 0.919150
global_step: 17433, epoch: 36, loss: 0.848869
global_step: 17434, epoch: 36, loss: 0.894308
global_step: 17435, epoch: 36, loss: 0.845456
global_step: 17436, epoch: 36, loss: 0.884924
global_step: 17437, epoch: 36, loss: 0.925920
global_step: 17438, epoch: 36, loss: 0.803751
global_step: 17439, epoch: 36, loss: 0.836901
global_step: 17440, epoch: 36, loss: 0.635996
epoch: 36
train	acc: 0.7913	macro: p 0.6986, r 0.5224, f1: 0.5327	micro: p 0.7913, r 0.7913, f1 0.7913	weighted_f1:0.7624
dev	acc: 0.5627	macro: p 0.3488, r 0.3093, f1: 0.3035	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5015
test	acc: 0.6084	macro: p 0.3766, r 0.3172, f1: 0.3231	micro: p 0.6084, r 0.6084, f1 0.6084	weighted_f1:0.5584
global_step: 17441, epoch: 37, loss: 0.730834
global_step: 17442, epoch: 37, loss: 0.768602
global_step: 17443, epoch: 37, loss: 0.943522
global_step: 17444, epoch: 37, loss: 0.939103
global_step: 17445, epoch: 37, loss: 0.952757
global_step: 17446, epoch: 37, loss: 0.817381
global_step: 17447, epoch: 37, loss: 0.842094
global_step: 17448, epoch: 37, loss: 0.846942
global_step: 17449, epoch: 37, loss: 0.876568
global_step: 17450, epoch: 37, loss: 0.759363
global_step: 17451, epoch: 37, loss: 0.876830
global_step: 17452, epoch: 37, loss: 0.757740
global_step: 17453, epoch: 37, loss: 0.862257
global_step: 17454, epoch: 37, loss: 0.912212
global_step: 17455, epoch: 37, loss: 0.885913
global_step: 17456, epoch: 37, loss: 0.736013
global_step: 17457, epoch: 37, loss: 0.927235
global_step: 17458, epoch: 37, loss: 0.874824
global_step: 17459, epoch: 37, loss: 0.869060
global_step: 17460, epoch: 37, loss: 0.767666
global_step: 17461, epoch: 37, loss: 0.932098
global_step: 17462, epoch: 37, loss: 0.933115
global_step: 17463, epoch: 37, loss: 0.869140
global_step: 17464, epoch: 37, loss: 0.772644
global_step: 17465, epoch: 37, loss: 0.862498
global_step: 17466, epoch: 37, loss: 0.815410
global_step: 17467, epoch: 37, loss: 0.777654
global_step: 17468, epoch: 37, loss: 0.837901
global_step: 17469, epoch: 37, loss: 0.812424
global_step: 17470, epoch: 37, loss: 0.883688
global_step: 17471, epoch: 37, loss: 0.899759
global_step: 17472, epoch: 37, loss: 0.812026
global_step: 17473, epoch: 37, loss: 0.874938
global_step: 17474, epoch: 37, loss: 0.844531
global_step: 17475, epoch: 37, loss: 0.779818
global_step: 17476, epoch: 37, loss: 0.869825
global_step: 17477, epoch: 37, loss: 0.882975
global_step: 17478, epoch: 37, loss: 0.804437
global_step: 17479, epoch: 37, loss: 0.772871
global_step: 17480, epoch: 37, loss: 0.706354
epoch: 37
train	acc: 0.8144	macro: p 0.7050, r 0.5589, f1: 0.5608	micro: p 0.8144, r 0.8144, f1 0.8144	weighted_f1:0.7886
dev	acc: 0.5555	macro: p 0.3319, r 0.3121, f1: 0.3021	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4996
test	acc: 0.6054	macro: p 0.3653, r 0.3242, f1: 0.3264	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5603
global_step: 17481, epoch: 38, loss: 0.914761
global_step: 17482, epoch: 38, loss: 0.809831
global_step: 17483, epoch: 38, loss: 0.740635
global_step: 17484, epoch: 38, loss: 0.831624
global_step: 17485, epoch: 38, loss: 0.816430
global_step: 17486, epoch: 38, loss: 0.746257
global_step: 17487, epoch: 38, loss: 0.727852
global_step: 17488, epoch: 38, loss: 0.905688
global_step: 17489, epoch: 38, loss: 0.802386
global_step: 17490, epoch: 38, loss: 0.915086
global_step: 17491, epoch: 38, loss: 0.824002
global_step: 17492, epoch: 38, loss: 0.776058
global_step: 17493, epoch: 38, loss: 0.936409
global_step: 17494, epoch: 38, loss: 0.943770
global_step: 17495, epoch: 38, loss: 0.824254
global_step: 17496, epoch: 38, loss: 0.811475
global_step: 17497, epoch: 38, loss: 0.815595
global_step: 17498, epoch: 38, loss: 0.797858
global_step: 17499, epoch: 38, loss: 0.858009
global_step: 17500, epoch: 38, loss: 0.782301
global_step: 17501, epoch: 38, loss: 0.804628
global_step: 17502, epoch: 38, loss: 0.882555
global_step: 17503, epoch: 38, loss: 0.817580
global_step: 17504, epoch: 38, loss: 0.667877
global_step: 17505, epoch: 38, loss: 0.917748
global_step: 17506, epoch: 38, loss: 0.866722
global_step: 17507, epoch: 38, loss: 0.797746
global_step: 17508, epoch: 38, loss: 0.890267
global_step: 17509, epoch: 38, loss: 0.906381
global_step: 17510, epoch: 38, loss: 0.837130
global_step: 17511, epoch: 38, loss: 0.808741
global_step: 17512, epoch: 38, loss: 0.799287
global_step: 17513, epoch: 38, loss: 0.842609
global_step: 17514, epoch: 38, loss: 0.739806
global_step: 17515, epoch: 38, loss: 0.861545
global_step: 17516, epoch: 38, loss: 0.842520
global_step: 17517, epoch: 38, loss: 0.907876
global_step: 17518, epoch: 38, loss: 0.935552
global_step: 17519, epoch: 38, loss: 0.843276
global_step: 17520, epoch: 38, loss: 0.733912
epoch: 38
train	acc: 0.8227	macro: p 0.8495, r 0.5736, f1: 0.5722	micro: p 0.8227, r 0.8227, f1 0.8227	weighted_f1:0.7982
dev	acc: 0.5573	macro: p 0.3406, r 0.3168, f1: 0.3080	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5045
test	acc: 0.5989	macro: p 0.3555, r 0.3235, f1: 0.3236	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5563
global_step: 17521, epoch: 39, loss: 0.772988
global_step: 17522, epoch: 39, loss: 0.818100
global_step: 17523, epoch: 39, loss: 0.758331
global_step: 17524, epoch: 39, loss: 0.768338
global_step: 17525, epoch: 39, loss: 0.780843
global_step: 17526, epoch: 39, loss: 0.764047
global_step: 17527, epoch: 39, loss: 0.792865
global_step: 17528, epoch: 39, loss: 0.841846
global_step: 17529, epoch: 39, loss: 0.736750
global_step: 17530, epoch: 39, loss: 0.822907
global_step: 17531, epoch: 39, loss: 0.909972
global_step: 17532, epoch: 39, loss: 0.765349
global_step: 17533, epoch: 39, loss: 0.748590
global_step: 17534, epoch: 39, loss: 0.747982
global_step: 17535, epoch: 39, loss: 0.927088
global_step: 17536, epoch: 39, loss: 0.758944
global_step: 17537, epoch: 39, loss: 0.873862
global_step: 17538, epoch: 39, loss: 0.789478
global_step: 17539, epoch: 39, loss: 0.762358
global_step: 17540, epoch: 39, loss: 0.724459
global_step: 17541, epoch: 39, loss: 0.706093
global_step: 17542, epoch: 39, loss: 0.824907
global_step: 17543, epoch: 39, loss: 0.816075
global_step: 17544, epoch: 39, loss: 0.921725
global_step: 17545, epoch: 39, loss: 0.705214
global_step: 17546, epoch: 39, loss: 0.820941
global_step: 17547, epoch: 39, loss: 0.815032
global_step: 17548, epoch: 39, loss: 0.773476
global_step: 17549, epoch: 39, loss: 0.863992
global_step: 17550, epoch: 39, loss: 0.950903
global_step: 17551, epoch: 39, loss: 0.750333
global_step: 17552, epoch: 39, loss: 0.852783
global_step: 17553, epoch: 39, loss: 0.799223
global_step: 17554, epoch: 39, loss: 0.883860
global_step: 17555, epoch: 39, loss: 0.909154
global_step: 17556, epoch: 39, loss: 0.849674
global_step: 17557, epoch: 39, loss: 0.915339
global_step: 17558, epoch: 39, loss: 0.798100
global_step: 17559, epoch: 39, loss: 0.852252
global_step: 17560, epoch: 39, loss: 0.708009
epoch: 39
train	acc: 0.8313	macro: p 0.8545, r 0.5844, f1: 0.5781	micro: p 0.8313, r 0.8313, f1 0.8313	weighted_f1:0.8080
dev	acc: 0.5573	macro: p 0.3406, r 0.3220, f1: 0.3104	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5088
test	acc: 0.5904	macro: p 0.3484, r 0.3229, f1: 0.3205	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5523
global_step: 17561, epoch: 40, loss: 0.823647
global_step: 17562, epoch: 40, loss: 0.681356
global_step: 17563, epoch: 40, loss: 0.776630
global_step: 17564, epoch: 40, loss: 0.814300
global_step: 17565, epoch: 40, loss: 0.830261
global_step: 17566, epoch: 40, loss: 0.783837
global_step: 17567, epoch: 40, loss: 0.791741
global_step: 17568, epoch: 40, loss: 0.782730
global_step: 17569, epoch: 40, loss: 0.850912
global_step: 17570, epoch: 40, loss: 0.774486
global_step: 17571, epoch: 40, loss: 0.777754
global_step: 17572, epoch: 40, loss: 0.768936
global_step: 17573, epoch: 40, loss: 0.728141
global_step: 17574, epoch: 40, loss: 0.745568
global_step: 17575, epoch: 40, loss: 0.750309
global_step: 17576, epoch: 40, loss: 0.699876
global_step: 17577, epoch: 40, loss: 0.877947
global_step: 17578, epoch: 40, loss: 0.802704
global_step: 17579, epoch: 40, loss: 0.814329
global_step: 17580, epoch: 40, loss: 0.733308
global_step: 17581, epoch: 40, loss: 0.766242
global_step: 17582, epoch: 40, loss: 0.773076
global_step: 17583, epoch: 40, loss: 0.923053
global_step: 17584, epoch: 40, loss: 0.740783
global_step: 17585, epoch: 40, loss: 0.842101
global_step: 17586, epoch: 40, loss: 0.818878
global_step: 17587, epoch: 40, loss: 0.804403
global_step: 17588, epoch: 40, loss: 0.874205
global_step: 17589, epoch: 40, loss: 0.803027
global_step: 17590, epoch: 40, loss: 0.798854
global_step: 17591, epoch: 40, loss: 0.751146
global_step: 17592, epoch: 40, loss: 0.732181
global_step: 17593, epoch: 40, loss: 0.807188
global_step: 17594, epoch: 40, loss: 0.802001
global_step: 17595, epoch: 40, loss: 0.808616
global_step: 17596, epoch: 40, loss: 0.785346
global_step: 17597, epoch: 40, loss: 0.820472
global_step: 17598, epoch: 40, loss: 0.781629
global_step: 17599, epoch: 40, loss: 0.778655
global_step: 17600, epoch: 40, loss: 1.100113
epoch: 40
train	acc: 0.8388	macro: p 0.8557, r 0.5971, f1: 0.5870	micro: p 0.8388, r 0.8388, f1 0.8388	weighted_f1:0.8163
dev	acc: 0.5573	macro: p 0.3337, r 0.3208, f1: 0.3138	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5113
test	acc: 0.5969	macro: p 0.3468, r 0.3295, f1: 0.3304	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5621
global_step: 17601, epoch: 41, loss: 0.744937
global_step: 17602, epoch: 41, loss: 0.694328
global_step: 17603, epoch: 41, loss: 0.737493
global_step: 17604, epoch: 41, loss: 0.749772
global_step: 17605, epoch: 41, loss: 0.724898
global_step: 17606, epoch: 41, loss: 0.740446
global_step: 17607, epoch: 41, loss: 0.949729
global_step: 17608, epoch: 41, loss: 0.739565
global_step: 17609, epoch: 41, loss: 0.905346
global_step: 17610, epoch: 41, loss: 0.806278
global_step: 17611, epoch: 41, loss: 0.785846
global_step: 17612, epoch: 41, loss: 0.835136
global_step: 17613, epoch: 41, loss: 0.804766
global_step: 17614, epoch: 41, loss: 0.727608
global_step: 17615, epoch: 41, loss: 0.760072
global_step: 17616, epoch: 41, loss: 0.819888
global_step: 17617, epoch: 41, loss: 0.776734
global_step: 17618, epoch: 41, loss: 0.739537
global_step: 17619, epoch: 41, loss: 0.835654
global_step: 17620, epoch: 41, loss: 0.757594
global_step: 17621, epoch: 41, loss: 0.747772
global_step: 17622, epoch: 41, loss: 0.800233
global_step: 17623, epoch: 41, loss: 0.795688
global_step: 17624, epoch: 41, loss: 0.837544
global_step: 17625, epoch: 41, loss: 0.835982
global_step: 17626, epoch: 41, loss: 0.774424
global_step: 17627, epoch: 41, loss: 0.703739
global_step: 17628, epoch: 41, loss: 0.744050
global_step: 17629, epoch: 41, loss: 0.751182
global_step: 17630, epoch: 41, loss: 0.707415
global_step: 17631, epoch: 41, loss: 0.893891
global_step: 17632, epoch: 41, loss: 0.761026
global_step: 17633, epoch: 41, loss: 0.795484
global_step: 17634, epoch: 41, loss: 0.832062
global_step: 17635, epoch: 41, loss: 0.676646
global_step: 17636, epoch: 41, loss: 0.941590
global_step: 17637, epoch: 41, loss: 0.815782
global_step: 17638, epoch: 41, loss: 0.688987
global_step: 17639, epoch: 41, loss: 0.849881
global_step: 17640, epoch: 41, loss: 0.411138
epoch: 41
train	acc: 0.8401	macro: p 0.8636, r 0.5967, f1: 0.5936	micro: p 0.8401, r 0.8401, f1 0.8401	weighted_f1:0.8168
dev	acc: 0.5609	macro: p 0.3363, r 0.3173, f1: 0.3109	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5086
test	acc: 0.6008	macro: p 0.3569, r 0.3211, f1: 0.3252	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5581
global_step: 17641, epoch: 42, loss: 0.744873
global_step: 17642, epoch: 42, loss: 0.817098
global_step: 17643, epoch: 42, loss: 0.770438
global_step: 17644, epoch: 42, loss: 0.710900
global_step: 17645, epoch: 42, loss: 0.739290
global_step: 17646, epoch: 42, loss: 0.733748
global_step: 17647, epoch: 42, loss: 0.804000
global_step: 17648, epoch: 42, loss: 0.768438
global_step: 17649, epoch: 42, loss: 0.721497
global_step: 17650, epoch: 42, loss: 0.706747
global_step: 17651, epoch: 42, loss: 0.826537
global_step: 17652, epoch: 42, loss: 0.734517
global_step: 17653, epoch: 42, loss: 0.729163
global_step: 17654, epoch: 42, loss: 0.845273
global_step: 17655, epoch: 42, loss: 0.775431
global_step: 17656, epoch: 42, loss: 0.810635
global_step: 17657, epoch: 42, loss: 0.750612
global_step: 17658, epoch: 42, loss: 0.787661
global_step: 17659, epoch: 42, loss: 0.725951
global_step: 17660, epoch: 42, loss: 0.689816
global_step: 17661, epoch: 42, loss: 0.777126
global_step: 17662, epoch: 42, loss: 0.804709
global_step: 17663, epoch: 42, loss: 0.770126
global_step: 17664, epoch: 42, loss: 0.688506
global_step: 17665, epoch: 42, loss: 0.723671
global_step: 17666, epoch: 42, loss: 0.729292
global_step: 17667, epoch: 42, loss: 0.793623
global_step: 17668, epoch: 42, loss: 0.838626
global_step: 17669, epoch: 42, loss: 0.703466
global_step: 17670, epoch: 42, loss: 0.731899
global_step: 17671, epoch: 42, loss: 0.807591
global_step: 17672, epoch: 42, loss: 0.864938
global_step: 17673, epoch: 42, loss: 0.747121
global_step: 17674, epoch: 42, loss: 0.759124
global_step: 17675, epoch: 42, loss: 0.812773
global_step: 17676, epoch: 42, loss: 0.725522
global_step: 17677, epoch: 42, loss: 0.748158
global_step: 17678, epoch: 42, loss: 0.727588
global_step: 17679, epoch: 42, loss: 0.773613
global_step: 17680, epoch: 42, loss: 0.548986
epoch: 42
train	acc: 0.8382	macro: p 0.8664, r 0.5912, f1: 0.5910	micro: p 0.8382, r 0.8382, f1 0.8382	weighted_f1:0.8148
dev	acc: 0.5609	macro: p 0.3373, r 0.3155, f1: 0.3093	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5074
test	acc: 0.6107	macro: p 0.3744, r 0.3273, f1: 0.3330	micro: p 0.6107, r 0.6107, f1 0.6107	weighted_f1:0.5675
global_step: 17681, epoch: 43, loss: 0.770257
global_step: 17682, epoch: 43, loss: 0.695138
global_step: 17683, epoch: 43, loss: 0.746240
global_step: 17684, epoch: 43, loss: 0.605440
global_step: 17685, epoch: 43, loss: 0.805883
global_step: 17686, epoch: 43, loss: 0.687870
global_step: 17687, epoch: 43, loss: 0.744973
global_step: 17688, epoch: 43, loss: 0.729040
global_step: 17689, epoch: 43, loss: 0.756233
global_step: 17690, epoch: 43, loss: 0.772781
global_step: 17691, epoch: 43, loss: 0.780733
global_step: 17692, epoch: 43, loss: 0.689791
global_step: 17693, epoch: 43, loss: 0.726224
global_step: 17694, epoch: 43, loss: 0.714876
global_step: 17695, epoch: 43, loss: 0.668612
global_step: 17696, epoch: 43, loss: 0.730717
global_step: 17697, epoch: 43, loss: 0.711003
global_step: 17698, epoch: 43, loss: 0.761243
global_step: 17699, epoch: 43, loss: 0.753559
global_step: 17700, epoch: 43, loss: 0.666832
global_step: 17701, epoch: 43, loss: 0.761693
global_step: 17702, epoch: 43, loss: 0.761661
global_step: 17703, epoch: 43, loss: 0.871603
global_step: 17704, epoch: 43, loss: 0.671304
global_step: 17705, epoch: 43, loss: 0.883313
global_step: 17706, epoch: 43, loss: 0.791610
global_step: 17707, epoch: 43, loss: 0.719250
global_step: 17708, epoch: 43, loss: 0.737325
global_step: 17709, epoch: 43, loss: 0.823144
global_step: 17710, epoch: 43, loss: 0.879702
global_step: 17711, epoch: 43, loss: 0.776455
global_step: 17712, epoch: 43, loss: 0.730237
global_step: 17713, epoch: 43, loss: 0.810269
global_step: 17714, epoch: 43, loss: 0.711300
global_step: 17715, epoch: 43, loss: 0.845179
global_step: 17716, epoch: 43, loss: 0.757092
global_step: 17717, epoch: 43, loss: 0.806914
global_step: 17718, epoch: 43, loss: 0.784728
global_step: 17719, epoch: 43, loss: 0.789391
global_step: 17720, epoch: 43, loss: 1.008132
epoch: 43
train	acc: 0.8395	macro: p 0.8530, r 0.5962, f1: 0.6033	micro: p 0.8395, r 0.8395, f1 0.8395	weighted_f1:0.8175
dev	acc: 0.5627	macro: p 0.3448, r 0.3155, f1: 0.3095	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5085
test	acc: 0.6080	macro: p 0.3773, r 0.3250, f1: 0.3305	micro: p 0.6080, r 0.6080, f1 0.6080	weighted_f1:0.5644
global_step: 17721, epoch: 44, loss: 0.651772
global_step: 17722, epoch: 44, loss: 0.688070
global_step: 17723, epoch: 44, loss: 0.764673
global_step: 17724, epoch: 44, loss: 0.671686
global_step: 17725, epoch: 44, loss: 0.692598
global_step: 17726, epoch: 44, loss: 0.624827
global_step: 17727, epoch: 44, loss: 0.728889
global_step: 17728, epoch: 44, loss: 0.751789
global_step: 17729, epoch: 44, loss: 0.687453
global_step: 17730, epoch: 44, loss: 0.749620
global_step: 17731, epoch: 44, loss: 0.762274
global_step: 17732, epoch: 44, loss: 0.718133
global_step: 17733, epoch: 44, loss: 0.937814
global_step: 17734, epoch: 44, loss: 0.823221
global_step: 17735, epoch: 44, loss: 0.752034
global_step: 17736, epoch: 44, loss: 0.626461
global_step: 17737, epoch: 44, loss: 0.760711
global_step: 17738, epoch: 44, loss: 0.770446
global_step: 17739, epoch: 44, loss: 0.677892
global_step: 17740, epoch: 44, loss: 0.771163
global_step: 17741, epoch: 44, loss: 0.655441
global_step: 17742, epoch: 44, loss: 0.660009
global_step: 17743, epoch: 44, loss: 0.772440
global_step: 17744, epoch: 44, loss: 0.662092
global_step: 17745, epoch: 44, loss: 0.793085
global_step: 17746, epoch: 44, loss: 0.706394
global_step: 17747, epoch: 44, loss: 0.690763
global_step: 17748, epoch: 44, loss: 0.800874
global_step: 17749, epoch: 44, loss: 0.801396
global_step: 17750, epoch: 44, loss: 0.782007
global_step: 17751, epoch: 44, loss: 0.697756
global_step: 17752, epoch: 44, loss: 0.684766
global_step: 17753, epoch: 44, loss: 0.689259
global_step: 17754, epoch: 44, loss: 0.677664
global_step: 17755, epoch: 44, loss: 0.846123
global_step: 17756, epoch: 44, loss: 0.826924
global_step: 17757, epoch: 44, loss: 0.718827
global_step: 17758, epoch: 44, loss: 0.695074
global_step: 17759, epoch: 44, loss: 0.886173
global_step: 17760, epoch: 44, loss: 0.223083
epoch: 44
train	acc: 0.8452	macro: p 0.8740, r 0.6015, f1: 0.6078	micro: p 0.8452, r 0.8452, f1 0.8452	weighted_f1:0.8222
dev	acc: 0.5573	macro: p 0.3352, r 0.3102, f1: 0.3008	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4982
test	acc: 0.6057	macro: p 0.3625, r 0.3186, f1: 0.3222	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5575
global_step: 17761, epoch: 45, loss: 0.718984
global_step: 17762, epoch: 45, loss: 0.759109
global_step: 17763, epoch: 45, loss: 0.729782
global_step: 17764, epoch: 45, loss: 0.663455
global_step: 17765, epoch: 45, loss: 0.742163
global_step: 17766, epoch: 45, loss: 0.721080
global_step: 17767, epoch: 45, loss: 0.775342
global_step: 17768, epoch: 45, loss: 0.686870
global_step: 17769, epoch: 45, loss: 0.734650
global_step: 17770, epoch: 45, loss: 0.727383
global_step: 17771, epoch: 45, loss: 0.755399
global_step: 17772, epoch: 45, loss: 0.751114
global_step: 17773, epoch: 45, loss: 0.744111
global_step: 17774, epoch: 45, loss: 0.768869
global_step: 17775, epoch: 45, loss: 0.571530
global_step: 17776, epoch: 45, loss: 0.718933
global_step: 17777, epoch: 45, loss: 0.741719
global_step: 17778, epoch: 45, loss: 0.693436
global_step: 17779, epoch: 45, loss: 0.671692
global_step: 17780, epoch: 45, loss: 0.847935
global_step: 17781, epoch: 45, loss: 0.859410
global_step: 17782, epoch: 45, loss: 0.824178
global_step: 17783, epoch: 45, loss: 0.663891
global_step: 17784, epoch: 45, loss: 0.667870
global_step: 17785, epoch: 45, loss: 0.714660
global_step: 17786, epoch: 45, loss: 0.840005
global_step: 17787, epoch: 45, loss: 0.645245
global_step: 17788, epoch: 45, loss: 0.791779
global_step: 17789, epoch: 45, loss: 0.804448
global_step: 17790, epoch: 45, loss: 0.803136
global_step: 17791, epoch: 45, loss: 0.783396
global_step: 17792, epoch: 45, loss: 0.777417
global_step: 17793, epoch: 45, loss: 0.783482
global_step: 17794, epoch: 45, loss: 0.810726
global_step: 17795, epoch: 45, loss: 0.669322
global_step: 17796, epoch: 45, loss: 0.766815
global_step: 17797, epoch: 45, loss: 0.716596
global_step: 17798, epoch: 45, loss: 0.769795
global_step: 17799, epoch: 45, loss: 0.651970
global_step: 17800, epoch: 45, loss: 1.239297
epoch: 45
train	acc: 0.8517	macro: p 0.8734, r 0.6160, f1: 0.6170	micro: p 0.8517, r 0.8517, f1 0.8517	weighted_f1:0.8323
dev	acc: 0.5500	macro: p 0.3352, r 0.3140, f1: 0.3072	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5043
test	acc: 0.5989	macro: p 0.3631, r 0.3296, f1: 0.3329	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5640
global_step: 17801, epoch: 46, loss: 0.770090
global_step: 17802, epoch: 46, loss: 0.662448
global_step: 17803, epoch: 46, loss: 0.645074
global_step: 17804, epoch: 46, loss: 0.748369
global_step: 17805, epoch: 46, loss: 0.715560
global_step: 17806, epoch: 46, loss: 0.698538
global_step: 17807, epoch: 46, loss: 0.763009
global_step: 17808, epoch: 46, loss: 0.777895
global_step: 17809, epoch: 46, loss: 0.744450
global_step: 17810, epoch: 46, loss: 0.695777
global_step: 17811, epoch: 46, loss: 0.700376
global_step: 17812, epoch: 46, loss: 0.644131
global_step: 17813, epoch: 46, loss: 0.785353
global_step: 17814, epoch: 46, loss: 0.647649
global_step: 17815, epoch: 46, loss: 0.799520
global_step: 17816, epoch: 46, loss: 0.737575
global_step: 17817, epoch: 46, loss: 0.743475
global_step: 17818, epoch: 46, loss: 0.703749
global_step: 17819, epoch: 46, loss: 0.692333
global_step: 17820, epoch: 46, loss: 0.628993
global_step: 17821, epoch: 46, loss: 0.749639
global_step: 17822, epoch: 46, loss: 0.683030
global_step: 17823, epoch: 46, loss: 0.675526
global_step: 17824, epoch: 46, loss: 0.708539
global_step: 17825, epoch: 46, loss: 0.786086
global_step: 17826, epoch: 46, loss: 0.693369
global_step: 17827, epoch: 46, loss: 0.719915
global_step: 17828, epoch: 46, loss: 0.784271
global_step: 17829, epoch: 46, loss: 0.600089
global_step: 17830, epoch: 46, loss: 0.771920
global_step: 17831, epoch: 46, loss: 0.747512
global_step: 17832, epoch: 46, loss: 0.768246
global_step: 17833, epoch: 46, loss: 0.755374
global_step: 17834, epoch: 46, loss: 0.654021
global_step: 17835, epoch: 46, loss: 0.601453
global_step: 17836, epoch: 46, loss: 0.745167
global_step: 17837, epoch: 46, loss: 0.661020
global_step: 17838, epoch: 46, loss: 0.747596
global_step: 17839, epoch: 46, loss: 0.734116
global_step: 17840, epoch: 46, loss: 1.069936
epoch: 46
train	acc: 0.8633	macro: p 0.8743, r 0.6468, f1: 0.6634	micro: p 0.8633, r 0.8633, f1 0.8633	weighted_f1:0.8467
dev	acc: 0.5528	macro: p 0.3384, r 0.3179, f1: 0.3056	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5009
test	acc: 0.5931	macro: p 0.3438, r 0.3224, f1: 0.3190	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5522
global_step: 17841, epoch: 47, loss: 0.739824
global_step: 17842, epoch: 47, loss: 0.567226
global_step: 17843, epoch: 47, loss: 0.709884
global_step: 17844, epoch: 47, loss: 0.709991
global_step: 17845, epoch: 47, loss: 0.768600
global_step: 17846, epoch: 47, loss: 0.722125
global_step: 17847, epoch: 47, loss: 0.754631
global_step: 17848, epoch: 47, loss: 0.639703
global_step: 17849, epoch: 47, loss: 0.665639
global_step: 17850, epoch: 47, loss: 0.640131
global_step: 17851, epoch: 47, loss: 0.648316
global_step: 17852, epoch: 47, loss: 0.777914
global_step: 17853, epoch: 47, loss: 0.684717
global_step: 17854, epoch: 47, loss: 0.750717
global_step: 17855, epoch: 47, loss: 0.772739
global_step: 17856, epoch: 47, loss: 0.723001
global_step: 17857, epoch: 47, loss: 0.746821
global_step: 17858, epoch: 47, loss: 0.714555
global_step: 17859, epoch: 47, loss: 0.694825
global_step: 17860, epoch: 47, loss: 0.673060
global_step: 17861, epoch: 47, loss: 0.634417
global_step: 17862, epoch: 47, loss: 0.722170
global_step: 17863, epoch: 47, loss: 0.673590
global_step: 17864, epoch: 47, loss: 0.756991
global_step: 17865, epoch: 47, loss: 0.648191
global_step: 17866, epoch: 47, loss: 0.752246
global_step: 17867, epoch: 47, loss: 0.707574
global_step: 17868, epoch: 47, loss: 0.704150
global_step: 17869, epoch: 47, loss: 0.622656
global_step: 17870, epoch: 47, loss: 0.679351
global_step: 17871, epoch: 47, loss: 0.731356
global_step: 17872, epoch: 47, loss: 0.707773
global_step: 17873, epoch: 47, loss: 0.790263
global_step: 17874, epoch: 47, loss: 0.703849
global_step: 17875, epoch: 47, loss: 0.825276
global_step: 17876, epoch: 47, loss: 0.771335
global_step: 17877, epoch: 47, loss: 0.676530
global_step: 17878, epoch: 47, loss: 0.823206
global_step: 17879, epoch: 47, loss: 0.698268
global_step: 17880, epoch: 47, loss: 0.811038
epoch: 47
train	acc: 0.8619	macro: p 0.8835, r 0.6321, f1: 0.6430	micro: p 0.8619, r 0.8619, f1 0.8619	weighted_f1:0.8426
dev	acc: 0.5609	macro: p 0.3609, r 0.3184, f1: 0.3114	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5082
test	acc: 0.6019	macro: p 0.3597, r 0.3234, f1: 0.3251	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5594
global_step: 17881, epoch: 48, loss: 0.610448
global_step: 17882, epoch: 48, loss: 0.617534
global_step: 17883, epoch: 48, loss: 0.716150
global_step: 17884, epoch: 48, loss: 0.739199
global_step: 17885, epoch: 48, loss: 0.685166
global_step: 17886, epoch: 48, loss: 0.671075
global_step: 17887, epoch: 48, loss: 0.670045
global_step: 17888, epoch: 48, loss: 0.592022
global_step: 17889, epoch: 48, loss: 0.702156
global_step: 17890, epoch: 48, loss: 0.658739
global_step: 17891, epoch: 48, loss: 0.628135
global_step: 17892, epoch: 48, loss: 0.685071
global_step: 17893, epoch: 48, loss: 0.685443
global_step: 17894, epoch: 48, loss: 0.706130
global_step: 17895, epoch: 48, loss: 0.746507
global_step: 17896, epoch: 48, loss: 0.730940
global_step: 17897, epoch: 48, loss: 0.720507
global_step: 17898, epoch: 48, loss: 0.635919
global_step: 17899, epoch: 48, loss: 0.702153
global_step: 17900, epoch: 48, loss: 0.643949
global_step: 17901, epoch: 48, loss: 0.647831
global_step: 17902, epoch: 48, loss: 0.713667
global_step: 17903, epoch: 48, loss: 0.657730
global_step: 17904, epoch: 48, loss: 0.712046
global_step: 17905, epoch: 48, loss: 0.593372
global_step: 17906, epoch: 48, loss: 0.683082
global_step: 17907, epoch: 48, loss: 0.689453
global_step: 17908, epoch: 48, loss: 0.647149
global_step: 17909, epoch: 48, loss: 0.680249
global_step: 17910, epoch: 48, loss: 0.791209
global_step: 17911, epoch: 48, loss: 0.711797
global_step: 17912, epoch: 48, loss: 0.718440
global_step: 17913, epoch: 48, loss: 0.772291
global_step: 17914, epoch: 48, loss: 0.608455
global_step: 17915, epoch: 48, loss: 0.886478
global_step: 17916, epoch: 48, loss: 0.723425
global_step: 17917, epoch: 48, loss: 0.703941
global_step: 17918, epoch: 48, loss: 0.568334
global_step: 17919, epoch: 48, loss: 0.743972
global_step: 17920, epoch: 48, loss: 0.137001
epoch: 48
train	acc: 0.8659	macro: p 0.8831, r 0.6372, f1: 0.6428	micro: p 0.8659, r 0.8659, f1 0.8659	weighted_f1:0.8459
dev	acc: 0.5600	macro: p 0.3478, r 0.3184, f1: 0.3147	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5078
test	acc: 0.6050	macro: p 0.3563, r 0.3226, f1: 0.3269	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5604
global_step: 17921, epoch: 49, loss: 0.636642
global_step: 17922, epoch: 49, loss: 0.741357
global_step: 17923, epoch: 49, loss: 0.731276
global_step: 17924, epoch: 49, loss: 0.737579
global_step: 17925, epoch: 49, loss: 0.602307
global_step: 17926, epoch: 49, loss: 0.647035
global_step: 17927, epoch: 49, loss: 0.672674
global_step: 17928, epoch: 49, loss: 0.650647
global_step: 17929, epoch: 49, loss: 0.624489
global_step: 17930, epoch: 49, loss: 0.711634
global_step: 17931, epoch: 49, loss: 0.655185
global_step: 17932, epoch: 49, loss: 0.647155
global_step: 17933, epoch: 49, loss: 0.654611
global_step: 17934, epoch: 49, loss: 0.647225
global_step: 17935, epoch: 49, loss: 0.665267
global_step: 17936, epoch: 49, loss: 0.652048
global_step: 17937, epoch: 49, loss: 0.717373
global_step: 17938, epoch: 49, loss: 0.635391
global_step: 17939, epoch: 49, loss: 0.688340
global_step: 17940, epoch: 49, loss: 0.658266
global_step: 17941, epoch: 49, loss: 0.686925
global_step: 17942, epoch: 49, loss: 0.713035
global_step: 17943, epoch: 49, loss: 0.697881
global_step: 17944, epoch: 49, loss: 0.618088
global_step: 17945, epoch: 49, loss: 0.655000
global_step: 17946, epoch: 49, loss: 0.700893
global_step: 17947, epoch: 49, loss: 0.681645
global_step: 17948, epoch: 49, loss: 0.649685
global_step: 17949, epoch: 49, loss: 0.548721
global_step: 17950, epoch: 49, loss: 0.645037
global_step: 17951, epoch: 49, loss: 0.742573
global_step: 17952, epoch: 49, loss: 0.741316
global_step: 17953, epoch: 49, loss: 0.692737
global_step: 17954, epoch: 49, loss: 0.767261
global_step: 17955, epoch: 49, loss: 0.709148
global_step: 17956, epoch: 49, loss: 0.694503
global_step: 17957, epoch: 49, loss: 0.730731
global_step: 17958, epoch: 49, loss: 0.701687
global_step: 17959, epoch: 49, loss: 0.643502
global_step: 17960, epoch: 49, loss: 0.337741
epoch: 49
train	acc: 0.8679	macro: p 0.8852, r 0.6423, f1: 0.6532	micro: p 0.8679, r 0.8679, f1 0.8679	weighted_f1:0.8491
dev	acc: 0.5600	macro: p 0.3466, r 0.3169, f1: 0.3113	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.5070
test	acc: 0.6019	macro: p 0.3589, r 0.3214, f1: 0.3257	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5594
global_step: 17961, epoch: 50, loss: 0.695773
global_step: 17962, epoch: 50, loss: 0.617932
global_step: 17963, epoch: 50, loss: 0.666843
global_step: 17964, epoch: 50, loss: 0.622462
global_step: 17965, epoch: 50, loss: 0.609783
global_step: 17966, epoch: 50, loss: 0.745437
global_step: 17967, epoch: 50, loss: 0.714617
global_step: 17968, epoch: 50, loss: 0.537082
global_step: 17969, epoch: 50, loss: 0.604973
global_step: 17970, epoch: 50, loss: 0.675657
global_step: 17971, epoch: 50, loss: 0.648537
global_step: 17972, epoch: 50, loss: 0.702649
global_step: 17973, epoch: 50, loss: 0.636200
global_step: 17974, epoch: 50, loss: 0.665837
global_step: 17975, epoch: 50, loss: 0.635350
global_step: 17976, epoch: 50, loss: 0.711767
global_step: 17977, epoch: 50, loss: 0.741542
global_step: 17978, epoch: 50, loss: 0.840705
global_step: 17979, epoch: 50, loss: 0.653745
global_step: 17980, epoch: 50, loss: 0.657746
global_step: 17981, epoch: 50, loss: 0.701370
global_step: 17982, epoch: 50, loss: 0.587043
global_step: 17983, epoch: 50, loss: 0.775356
global_step: 17984, epoch: 50, loss: 0.662697
global_step: 17985, epoch: 50, loss: 0.664991
global_step: 17986, epoch: 50, loss: 0.691294
global_step: 17987, epoch: 50, loss: 0.630202
global_step: 17988, epoch: 50, loss: 0.718902
global_step: 17989, epoch: 50, loss: 0.691578
global_step: 17990, epoch: 50, loss: 0.647947
global_step: 17991, epoch: 50, loss: 0.571078
global_step: 17992, epoch: 50, loss: 0.746953
global_step: 17993, epoch: 50, loss: 0.616943
global_step: 17994, epoch: 50, loss: 0.707939
global_step: 17995, epoch: 50, loss: 0.643265
global_step: 17996, epoch: 50, loss: 0.656834
global_step: 17997, epoch: 50, loss: 0.625247
global_step: 17998, epoch: 50, loss: 0.773205
global_step: 17999, epoch: 50, loss: 0.647804
global_step: 18000, epoch: 50, loss: 0.286327
epoch: 50
train	acc: 0.8684	macro: p 0.8826, r 0.6447, f1: 0.6494	micro: p 0.8684, r 0.8684, f1 0.8684	weighted_f1:0.8492
dev	acc: 0.5528	macro: p 0.3329, r 0.3126, f1: 0.3082	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5010
test	acc: 0.5992	macro: p 0.3453, r 0.3212, f1: 0.3239	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5560
global_step: 18001, epoch: 51, loss: 0.687913
global_step: 18002, epoch: 51, loss: 0.637651
global_step: 18003, epoch: 51, loss: 0.649270
global_step: 18004, epoch: 51, loss: 0.645374
global_step: 18005, epoch: 51, loss: 0.625123
global_step: 18006, epoch: 51, loss: 0.613600
global_step: 18007, epoch: 51, loss: 0.549420
global_step: 18008, epoch: 51, loss: 0.674121
global_step: 18009, epoch: 51, loss: 0.662499
global_step: 18010, epoch: 51, loss: 0.568665
global_step: 18011, epoch: 51, loss: 0.634122
global_step: 18012, epoch: 51, loss: 0.600945
global_step: 18013, epoch: 51, loss: 0.647322
global_step: 18014, epoch: 51, loss: 0.581888
global_step: 18015, epoch: 51, loss: 0.705453
global_step: 18016, epoch: 51, loss: 0.685574
global_step: 18017, epoch: 51, loss: 0.619331
global_step: 18018, epoch: 51, loss: 0.687679
global_step: 18019, epoch: 51, loss: 0.685411
global_step: 18020, epoch: 51, loss: 0.666275
global_step: 18021, epoch: 51, loss: 0.684435
global_step: 18022, epoch: 51, loss: 0.705582
global_step: 18023, epoch: 51, loss: 0.683551
global_step: 18024, epoch: 51, loss: 0.501618
global_step: 18025, epoch: 51, loss: 0.711795
global_step: 18026, epoch: 51, loss: 0.783851
global_step: 18027, epoch: 51, loss: 0.747842
global_step: 18028, epoch: 51, loss: 0.704993
global_step: 18029, epoch: 51, loss: 0.754659
global_step: 18030, epoch: 51, loss: 0.660265
global_step: 18031, epoch: 51, loss: 0.590460
global_step: 18032, epoch: 51, loss: 0.641202
global_step: 18033, epoch: 51, loss: 0.712825
global_step: 18034, epoch: 51, loss: 0.678824
global_step: 18035, epoch: 51, loss: 0.730739
global_step: 18036, epoch: 51, loss: 0.684225
global_step: 18037, epoch: 51, loss: 0.694470
global_step: 18038, epoch: 51, loss: 0.734043
global_step: 18039, epoch: 51, loss: 0.672750
global_step: 18040, epoch: 51, loss: 0.337846
epoch: 51
train	acc: 0.8736	macro: p 0.8824, r 0.6661, f1: 0.6879	micro: p 0.8736, r 0.8736, f1 0.8736	weighted_f1:0.8586
dev	acc: 0.5500	macro: p 0.3338, r 0.3090, f1: 0.2944	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4914
test	acc: 0.5943	macro: p 0.3460, r 0.3161, f1: 0.3140	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5485
global_step: 18041, epoch: 52, loss: 0.586634
global_step: 18042, epoch: 52, loss: 0.619075
global_step: 18043, epoch: 52, loss: 0.681654
global_step: 18044, epoch: 52, loss: 0.601557
global_step: 18045, epoch: 52, loss: 0.615348
global_step: 18046, epoch: 52, loss: 0.575864
global_step: 18047, epoch: 52, loss: 0.671096
global_step: 18048, epoch: 52, loss: 0.623958
global_step: 18049, epoch: 52, loss: 0.576349
global_step: 18050, epoch: 52, loss: 0.597507
global_step: 18051, epoch: 52, loss: 0.578611
global_step: 18052, epoch: 52, loss: 0.721372
global_step: 18053, epoch: 52, loss: 0.639504
global_step: 18054, epoch: 52, loss: 0.628755
global_step: 18055, epoch: 52, loss: 0.713845
global_step: 18056, epoch: 52, loss: 0.616822
global_step: 18057, epoch: 52, loss: 0.718065
global_step: 18058, epoch: 52, loss: 0.641614
global_step: 18059, epoch: 52, loss: 0.666090
global_step: 18060, epoch: 52, loss: 0.605073
global_step: 18061, epoch: 52, loss: 0.675838
global_step: 18062, epoch: 52, loss: 0.620018
global_step: 18063, epoch: 52, loss: 0.590433
global_step: 18064, epoch: 52, loss: 0.760340
global_step: 18065, epoch: 52, loss: 0.646591
global_step: 18066, epoch: 52, loss: 0.661677
global_step: 18067, epoch: 52, loss: 0.633741
global_step: 18068, epoch: 52, loss: 0.667192
global_step: 18069, epoch: 52, loss: 0.762119
global_step: 18070, epoch: 52, loss: 0.666470
global_step: 18071, epoch: 52, loss: 0.655266
global_step: 18072, epoch: 52, loss: 0.686207
global_step: 18073, epoch: 52, loss: 0.609624
global_step: 18074, epoch: 52, loss: 0.582364
global_step: 18075, epoch: 52, loss: 0.609668
global_step: 18076, epoch: 52, loss: 0.688512
global_step: 18077, epoch: 52, loss: 0.658507
global_step: 18078, epoch: 52, loss: 0.632569
global_step: 18079, epoch: 52, loss: 0.731651
global_step: 18080, epoch: 52, loss: 0.200745
epoch: 52
train	acc: 0.8704	macro: p 0.8862, r 0.6655, f1: 0.6937	micro: p 0.8704, r 0.8704, f1 0.8704	weighted_f1:0.8561
dev	acc: 0.5500	macro: p 0.3393, r 0.3037, f1: 0.2946	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4911
test	acc: 0.6000	macro: p 0.3618, r 0.3150, f1: 0.3194	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5529
global_step: 18081, epoch: 53, loss: 0.636180
global_step: 18082, epoch: 53, loss: 0.666104
global_step: 18083, epoch: 53, loss: 0.548433
global_step: 18084, epoch: 53, loss: 0.652906
global_step: 18085, epoch: 53, loss: 0.590619
global_step: 18086, epoch: 53, loss: 0.632940
global_step: 18087, epoch: 53, loss: 0.589381
global_step: 18088, epoch: 53, loss: 0.575242
global_step: 18089, epoch: 53, loss: 0.607944
global_step: 18090, epoch: 53, loss: 0.693084
global_step: 18091, epoch: 53, loss: 0.680884
global_step: 18092, epoch: 53, loss: 0.747450
global_step: 18093, epoch: 53, loss: 0.610044
global_step: 18094, epoch: 53, loss: 0.593674
global_step: 18095, epoch: 53, loss: 0.713751
global_step: 18096, epoch: 53, loss: 0.676330
global_step: 18097, epoch: 53, loss: 0.727464
global_step: 18098, epoch: 53, loss: 0.608545
global_step: 18099, epoch: 53, loss: 0.741356
global_step: 18100, epoch: 53, loss: 0.611016
global_step: 18101, epoch: 53, loss: 0.644985
global_step: 18102, epoch: 53, loss: 0.634691
global_step: 18103, epoch: 53, loss: 0.574348
global_step: 18104, epoch: 53, loss: 0.693118
global_step: 18105, epoch: 53, loss: 0.504023
global_step: 18106, epoch: 53, loss: 0.668406
global_step: 18107, epoch: 53, loss: 0.681547
global_step: 18108, epoch: 53, loss: 0.637185
global_step: 18109, epoch: 53, loss: 0.542678
global_step: 18110, epoch: 53, loss: 0.720119
global_step: 18111, epoch: 53, loss: 0.605918
global_step: 18112, epoch: 53, loss: 0.700688
global_step: 18113, epoch: 53, loss: 0.623954
global_step: 18114, epoch: 53, loss: 0.698238
global_step: 18115, epoch: 53, loss: 0.612653
global_step: 18116, epoch: 53, loss: 0.553579
global_step: 18117, epoch: 53, loss: 0.600487
global_step: 18118, epoch: 53, loss: 0.680739
global_step: 18119, epoch: 53, loss: 0.707431
global_step: 18120, epoch: 53, loss: 0.222030
epoch: 53
train	acc: 0.8828	macro: p 0.8842, r 0.6894, f1: 0.7070	micro: p 0.8828, r 0.8828, f1 0.8828	weighted_f1:0.8698
dev	acc: 0.5383	macro: p 0.3265, r 0.3180, f1: 0.3061	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4971
test	acc: 0.5743	macro: p 0.3332, r 0.3247, f1: 0.3179	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5428
global_step: 18121, epoch: 54, loss: 0.614688
global_step: 18122, epoch: 54, loss: 0.682981
global_step: 18123, epoch: 54, loss: 0.641313
global_step: 18124, epoch: 54, loss: 0.561903
global_step: 18125, epoch: 54, loss: 0.637462
global_step: 18126, epoch: 54, loss: 0.616400
global_step: 18127, epoch: 54, loss: 0.643327
global_step: 18128, epoch: 54, loss: 0.577415
global_step: 18129, epoch: 54, loss: 0.611947
global_step: 18130, epoch: 54, loss: 0.643948
global_step: 18131, epoch: 54, loss: 0.588932
global_step: 18132, epoch: 54, loss: 0.600417
global_step: 18133, epoch: 54, loss: 0.666044
global_step: 18134, epoch: 54, loss: 0.675049
global_step: 18135, epoch: 54, loss: 0.579085
global_step: 18136, epoch: 54, loss: 0.669203
global_step: 18137, epoch: 54, loss: 0.518274
global_step: 18138, epoch: 54, loss: 0.528787
global_step: 18139, epoch: 54, loss: 0.678576
global_step: 18140, epoch: 54, loss: 0.668423
global_step: 18141, epoch: 54, loss: 0.579826
global_step: 18142, epoch: 54, loss: 0.606960
global_step: 18143, epoch: 54, loss: 0.628915
global_step: 18144, epoch: 54, loss: 0.620739
global_step: 18145, epoch: 54, loss: 0.588085
global_step: 18146, epoch: 54, loss: 0.617443
global_step: 18147, epoch: 54, loss: 0.600862
global_step: 18148, epoch: 54, loss: 0.697661
global_step: 18149, epoch: 54, loss: 0.597179
global_step: 18150, epoch: 54, loss: 0.684052
global_step: 18151, epoch: 54, loss: 0.640631
global_step: 18152, epoch: 54, loss: 0.595677
global_step: 18153, epoch: 54, loss: 0.686770
global_step: 18154, epoch: 54, loss: 0.600166
global_step: 18155, epoch: 54, loss: 0.677204
global_step: 18156, epoch: 54, loss: 0.658188
global_step: 18157, epoch: 54, loss: 0.651205
global_step: 18158, epoch: 54, loss: 0.638058
global_step: 18159, epoch: 54, loss: 0.620740
global_step: 18160, epoch: 54, loss: 0.107747
epoch: 54
train	acc: 0.8911	macro: p 0.8922, r 0.7104, f1: 0.7381	micro: p 0.8911, r 0.8911, f1 0.8911	weighted_f1:0.8801
dev	acc: 0.5518	macro: p 0.3335, r 0.3146, f1: 0.3056	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4997
test	acc: 0.5943	macro: p 0.3435, r 0.3236, f1: 0.3228	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5532
global_step: 18161, epoch: 55, loss: 0.578162
global_step: 18162, epoch: 55, loss: 0.626153
global_step: 18163, epoch: 55, loss: 0.632388
global_step: 18164, epoch: 55, loss: 0.539025
global_step: 18165, epoch: 55, loss: 0.553840
global_step: 18166, epoch: 55, loss: 0.590558
global_step: 18167, epoch: 55, loss: 0.646235
global_step: 18168, epoch: 55, loss: 0.587777
global_step: 18169, epoch: 55, loss: 0.594609
global_step: 18170, epoch: 55, loss: 0.681234
global_step: 18171, epoch: 55, loss: 0.601433
global_step: 18172, epoch: 55, loss: 0.692226
global_step: 18173, epoch: 55, loss: 0.560341
global_step: 18174, epoch: 55, loss: 0.611223
global_step: 18175, epoch: 55, loss: 0.657319
global_step: 18176, epoch: 55, loss: 0.613098
global_step: 18177, epoch: 55, loss: 0.644989
global_step: 18178, epoch: 55, loss: 0.571669
global_step: 18179, epoch: 55, loss: 0.643271
global_step: 18180, epoch: 55, loss: 0.635882
global_step: 18181, epoch: 55, loss: 0.661626
global_step: 18182, epoch: 55, loss: 0.634805
global_step: 18183, epoch: 55, loss: 0.606443
global_step: 18184, epoch: 55, loss: 0.745379
global_step: 18185, epoch: 55, loss: 0.520177
global_step: 18186, epoch: 55, loss: 0.626039
global_step: 18187, epoch: 55, loss: 0.594002
global_step: 18188, epoch: 55, loss: 0.723222
global_step: 18189, epoch: 55, loss: 0.728676
global_step: 18190, epoch: 55, loss: 0.617834
global_step: 18191, epoch: 55, loss: 0.564648
global_step: 18192, epoch: 55, loss: 0.637956
global_step: 18193, epoch: 55, loss: 0.589438
global_step: 18194, epoch: 55, loss: 0.664029
global_step: 18195, epoch: 55, loss: 0.604685
global_step: 18196, epoch: 55, loss: 0.621045
global_step: 18197, epoch: 55, loss: 0.567230
global_step: 18198, epoch: 55, loss: 0.551815
global_step: 18199, epoch: 55, loss: 0.539469
global_step: 18200, epoch: 55, loss: 0.275994
epoch: 55
train	acc: 0.8903	macro: p 0.8894, r 0.7029, f1: 0.7237	micro: p 0.8903, r 0.8903, f1 0.8903	weighted_f1:0.8781
dev	acc: 0.5528	macro: p 0.3314, r 0.3152, f1: 0.3064	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5010
test	acc: 0.5943	macro: p 0.3431, r 0.3215, f1: 0.3227	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5536
global_step: 18201, epoch: 56, loss: 0.544839
global_step: 18202, epoch: 56, loss: 0.557318
global_step: 18203, epoch: 56, loss: 0.664295
global_step: 18204, epoch: 56, loss: 0.551179
global_step: 18205, epoch: 56, loss: 0.573467
global_step: 18206, epoch: 56, loss: 0.610238
global_step: 18207, epoch: 56, loss: 0.537124
global_step: 18208, epoch: 56, loss: 0.561469
global_step: 18209, epoch: 56, loss: 0.588859
global_step: 18210, epoch: 56, loss: 0.580299
global_step: 18211, epoch: 56, loss: 0.584676
global_step: 18212, epoch: 56, loss: 0.624385
global_step: 18213, epoch: 56, loss: 0.594161
global_step: 18214, epoch: 56, loss: 0.633369
global_step: 18215, epoch: 56, loss: 0.621091
global_step: 18216, epoch: 56, loss: 0.649382
global_step: 18217, epoch: 56, loss: 0.517244
global_step: 18218, epoch: 56, loss: 0.635720
global_step: 18219, epoch: 56, loss: 0.593909
global_step: 18220, epoch: 56, loss: 0.578372
global_step: 18221, epoch: 56, loss: 0.566962
global_step: 18222, epoch: 56, loss: 0.652328
global_step: 18223, epoch: 56, loss: 0.664676
global_step: 18224, epoch: 56, loss: 0.632384
global_step: 18225, epoch: 56, loss: 0.719716
global_step: 18226, epoch: 56, loss: 0.595062
global_step: 18227, epoch: 56, loss: 0.554634
global_step: 18228, epoch: 56, loss: 0.613897
global_step: 18229, epoch: 56, loss: 0.741341
global_step: 18230, epoch: 56, loss: 0.667577
global_step: 18231, epoch: 56, loss: 0.573136
global_step: 18232, epoch: 56, loss: 0.542271
global_step: 18233, epoch: 56, loss: 0.699830
global_step: 18234, epoch: 56, loss: 0.643581
global_step: 18235, epoch: 56, loss: 0.602714
global_step: 18236, epoch: 56, loss: 0.526637
global_step: 18237, epoch: 56, loss: 0.585602
global_step: 18238, epoch: 56, loss: 0.512652
global_step: 18239, epoch: 56, loss: 0.578568
global_step: 18240, epoch: 56, loss: 0.621424
epoch: 56
train	acc: 0.8855	macro: p 0.9012, r 0.6954, f1: 0.7307	micro: p 0.8855, r 0.8855, f1 0.8855	weighted_f1:0.8735
dev	acc: 0.5564	macro: p 0.3553, r 0.3104, f1: 0.3045	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4996
test	acc: 0.6000	macro: p 0.3550, r 0.3119, f1: 0.3154	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5508
global_step: 18241, epoch: 57, loss: 0.610387
global_step: 18242, epoch: 57, loss: 0.634418
global_step: 18243, epoch: 57, loss: 0.469831
global_step: 18244, epoch: 57, loss: 0.470630
global_step: 18245, epoch: 57, loss: 0.559877
global_step: 18246, epoch: 57, loss: 0.627664
global_step: 18247, epoch: 57, loss: 0.684633
global_step: 18248, epoch: 57, loss: 0.602026
global_step: 18249, epoch: 57, loss: 0.585213
global_step: 18250, epoch: 57, loss: 0.594609
global_step: 18251, epoch: 57, loss: 0.536707
global_step: 18252, epoch: 57, loss: 0.541738
global_step: 18253, epoch: 57, loss: 0.669887
global_step: 18254, epoch: 57, loss: 0.753800
global_step: 18255, epoch: 57, loss: 0.565665
global_step: 18256, epoch: 57, loss: 0.575306
global_step: 18257, epoch: 57, loss: 0.585964
global_step: 18258, epoch: 57, loss: 0.627224
global_step: 18259, epoch: 57, loss: 0.657725
global_step: 18260, epoch: 57, loss: 0.552118
global_step: 18261, epoch: 57, loss: 0.581596
global_step: 18262, epoch: 57, loss: 0.581867
global_step: 18263, epoch: 57, loss: 0.504079
global_step: 18264, epoch: 57, loss: 0.534268
global_step: 18265, epoch: 57, loss: 0.550581
global_step: 18266, epoch: 57, loss: 0.535592
global_step: 18267, epoch: 57, loss: 0.582445
global_step: 18268, epoch: 57, loss: 0.619695
global_step: 18269, epoch: 57, loss: 0.564630
global_step: 18270, epoch: 57, loss: 0.660473
global_step: 18271, epoch: 57, loss: 0.664192
global_step: 18272, epoch: 57, loss: 0.571948
global_step: 18273, epoch: 57, loss: 0.673095
global_step: 18274, epoch: 57, loss: 0.618215
global_step: 18275, epoch: 57, loss: 0.603075
global_step: 18276, epoch: 57, loss: 0.588088
global_step: 18277, epoch: 57, loss: 0.641881
global_step: 18278, epoch: 57, loss: 0.555013
global_step: 18279, epoch: 57, loss: 0.600668
global_step: 18280, epoch: 57, loss: 1.005573
epoch: 57
train	acc: 0.8979	macro: p 0.9050, r 0.7419, f1: 0.7809	micro: p 0.8979, r 0.8979, f1 0.8979	weighted_f1:0.8908
dev	acc: 0.5582	macro: p 0.4930, r 0.3248, f1: 0.3201	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5066
test	acc: 0.5874	macro: p 0.3483, r 0.3170, f1: 0.3162	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5459
global_step: 18281, epoch: 58, loss: 0.564751
global_step: 18282, epoch: 58, loss: 0.647051
global_step: 18283, epoch: 58, loss: 0.560921
global_step: 18284, epoch: 58, loss: 0.602028
global_step: 18285, epoch: 58, loss: 0.588410
global_step: 18286, epoch: 58, loss: 0.585587
global_step: 18287, epoch: 58, loss: 0.622195
global_step: 18288, epoch: 58, loss: 0.557903
global_step: 18289, epoch: 58, loss: 0.489945
global_step: 18290, epoch: 58, loss: 0.566766
global_step: 18291, epoch: 58, loss: 0.517065
global_step: 18292, epoch: 58, loss: 0.581388
global_step: 18293, epoch: 58, loss: 0.547499
global_step: 18294, epoch: 58, loss: 0.625260
global_step: 18295, epoch: 58, loss: 0.658344
global_step: 18296, epoch: 58, loss: 0.520650
global_step: 18297, epoch: 58, loss: 0.596134
global_step: 18298, epoch: 58, loss: 0.607084
global_step: 18299, epoch: 58, loss: 0.588295
global_step: 18300, epoch: 58, loss: 0.582835
global_step: 18301, epoch: 58, loss: 0.535230
global_step: 18302, epoch: 58, loss: 0.667948
global_step: 18303, epoch: 58, loss: 0.541306
global_step: 18304, epoch: 58, loss: 0.604466
global_step: 18305, epoch: 58, loss: 0.522962
global_step: 18306, epoch: 58, loss: 0.703421
global_step: 18307, epoch: 58, loss: 0.555583
global_step: 18308, epoch: 58, loss: 0.623254
global_step: 18309, epoch: 58, loss: 0.630374
global_step: 18310, epoch: 58, loss: 0.536197
global_step: 18311, epoch: 58, loss: 0.545695
global_step: 18312, epoch: 58, loss: 0.516206
global_step: 18313, epoch: 58, loss: 0.541745
global_step: 18314, epoch: 58, loss: 0.611773
global_step: 18315, epoch: 58, loss: 0.534845
global_step: 18316, epoch: 58, loss: 0.523936
global_step: 18317, epoch: 58, loss: 0.501116
global_step: 18318, epoch: 58, loss: 0.593912
global_step: 18319, epoch: 58, loss: 0.653177
global_step: 18320, epoch: 58, loss: 1.235296
epoch: 58
train	acc: 0.9077	macro: p 0.9124, r 0.7682, f1: 0.8076	micro: p 0.9077, r 0.9077, f1 0.9077	weighted_f1:0.9024
dev	acc: 0.5564	macro: p 0.3422, r 0.3213, f1: 0.3161	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5093
test	acc: 0.5920	macro: p 0.3418, r 0.3239, f1: 0.3238	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5544
global_step: 18321, epoch: 59, loss: 0.575025
global_step: 18322, epoch: 59, loss: 0.556572
global_step: 18323, epoch: 59, loss: 0.555925
global_step: 18324, epoch: 59, loss: 0.513251
global_step: 18325, epoch: 59, loss: 0.527812
global_step: 18326, epoch: 59, loss: 0.570725
global_step: 18327, epoch: 59, loss: 0.552905
global_step: 18328, epoch: 59, loss: 0.591074
global_step: 18329, epoch: 59, loss: 0.488790
global_step: 18330, epoch: 59, loss: 0.573935
global_step: 18331, epoch: 59, loss: 0.459670
global_step: 18332, epoch: 59, loss: 0.618065
global_step: 18333, epoch: 59, loss: 0.515050
global_step: 18334, epoch: 59, loss: 0.535057
global_step: 18335, epoch: 59, loss: 0.552155
global_step: 18336, epoch: 59, loss: 0.613960
global_step: 18337, epoch: 59, loss: 0.607517
global_step: 18338, epoch: 59, loss: 0.572935
global_step: 18339, epoch: 59, loss: 0.604096
global_step: 18340, epoch: 59, loss: 0.661104
global_step: 18341, epoch: 59, loss: 0.511793
global_step: 18342, epoch: 59, loss: 0.625719
global_step: 18343, epoch: 59, loss: 0.539396
global_step: 18344, epoch: 59, loss: 0.586167
global_step: 18345, epoch: 59, loss: 0.488095
global_step: 18346, epoch: 59, loss: 0.643681
global_step: 18347, epoch: 59, loss: 0.528729
global_step: 18348, epoch: 59, loss: 0.499833
global_step: 18349, epoch: 59, loss: 0.539218
global_step: 18350, epoch: 59, loss: 0.490757
global_step: 18351, epoch: 59, loss: 0.614865
global_step: 18352, epoch: 59, loss: 0.675361
global_step: 18353, epoch: 59, loss: 0.685776
global_step: 18354, epoch: 59, loss: 0.602909
global_step: 18355, epoch: 59, loss: 0.552840
global_step: 18356, epoch: 59, loss: 0.572151
global_step: 18357, epoch: 59, loss: 0.555025
global_step: 18358, epoch: 59, loss: 0.649929
global_step: 18359, epoch: 59, loss: 0.516593
global_step: 18360, epoch: 59, loss: 1.563473
epoch: 59
train	acc: 0.9029	macro: p 0.9138, r 0.7415, f1: 0.7793	micro: p 0.9029, r 0.9029, f1 0.9029	weighted_f1:0.8953
dev	acc: 0.5518	macro: p 0.3350, r 0.3137, f1: 0.3029	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4995
test	acc: 0.5946	macro: p 0.3558, r 0.3242, f1: 0.3263	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5570
global_step: 18361, epoch: 60, loss: 0.591823
global_step: 18362, epoch: 60, loss: 0.455820
global_step: 18363, epoch: 60, loss: 0.528951
global_step: 18364, epoch: 60, loss: 0.593576
global_step: 18365, epoch: 60, loss: 0.573253
global_step: 18366, epoch: 60, loss: 0.448677
global_step: 18367, epoch: 60, loss: 0.581702
global_step: 18368, epoch: 60, loss: 0.513646
global_step: 18369, epoch: 60, loss: 0.578768
global_step: 18370, epoch: 60, loss: 0.499098
global_step: 18371, epoch: 60, loss: 0.461268
global_step: 18372, epoch: 60, loss: 0.520234
global_step: 18373, epoch: 60, loss: 0.518932
global_step: 18374, epoch: 60, loss: 0.606453
global_step: 18375, epoch: 60, loss: 0.598369
global_step: 18376, epoch: 60, loss: 0.643569
global_step: 18377, epoch: 60, loss: 0.570751
global_step: 18378, epoch: 60, loss: 0.507945
global_step: 18379, epoch: 60, loss: 0.542296
global_step: 18380, epoch: 60, loss: 0.516001
global_step: 18381, epoch: 60, loss: 0.616924
global_step: 18382, epoch: 60, loss: 0.682436
global_step: 18383, epoch: 60, loss: 0.594853
global_step: 18384, epoch: 60, loss: 0.607006
global_step: 18385, epoch: 60, loss: 0.610570
global_step: 18386, epoch: 60, loss: 0.623008
global_step: 18387, epoch: 60, loss: 0.561884
global_step: 18388, epoch: 60, loss: 0.532783
global_step: 18389, epoch: 60, loss: 0.441266
global_step: 18390, epoch: 60, loss: 0.625729
global_step: 18391, epoch: 60, loss: 0.591169
global_step: 18392, epoch: 60, loss: 0.587409
global_step: 18393, epoch: 60, loss: 0.668226
global_step: 18394, epoch: 60, loss: 0.559458
global_step: 18395, epoch: 60, loss: 0.656027
global_step: 18396, epoch: 60, loss: 0.650774
global_step: 18397, epoch: 60, loss: 0.529750
global_step: 18398, epoch: 60, loss: 0.625131
global_step: 18399, epoch: 60, loss: 0.481508
global_step: 18400, epoch: 60, loss: 0.883828
epoch: 60
train	acc: 0.9062	macro: p 0.9100, r 0.7520, f1: 0.7847	micro: p 0.9062, r 0.9062, f1 0.9062	weighted_f1:0.8987
dev	acc: 0.5555	macro: p 0.3392, r 0.3185, f1: 0.3148	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5076
test	acc: 0.5943	macro: p 0.3448, r 0.3245, f1: 0.3281	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5579
global_step: 18401, epoch: 61, loss: 0.476001
global_step: 18402, epoch: 61, loss: 0.502407
global_step: 18403, epoch: 61, loss: 0.541619
global_step: 18404, epoch: 61, loss: 0.496341
global_step: 18405, epoch: 61, loss: 0.596441
global_step: 18406, epoch: 61, loss: 0.574332
global_step: 18407, epoch: 61, loss: 0.533537
global_step: 18408, epoch: 61, loss: 0.364958
global_step: 18409, epoch: 61, loss: 0.483075
global_step: 18410, epoch: 61, loss: 0.495278
global_step: 18411, epoch: 61, loss: 0.539666
global_step: 18412, epoch: 61, loss: 0.620117
global_step: 18413, epoch: 61, loss: 0.611604
global_step: 18414, epoch: 61, loss: 0.553847
global_step: 18415, epoch: 61, loss: 0.661670
global_step: 18416, epoch: 61, loss: 0.502245
global_step: 18417, epoch: 61, loss: 0.515896
global_step: 18418, epoch: 61, loss: 0.551757
global_step: 18419, epoch: 61, loss: 0.550394
global_step: 18420, epoch: 61, loss: 0.590933
global_step: 18421, epoch: 61, loss: 0.578843
global_step: 18422, epoch: 61, loss: 0.600959
global_step: 18423, epoch: 61, loss: 0.495818
global_step: 18424, epoch: 61, loss: 0.543271
global_step: 18425, epoch: 61, loss: 0.525829
global_step: 18426, epoch: 61, loss: 0.563286
global_step: 18427, epoch: 61, loss: 0.614794
global_step: 18428, epoch: 61, loss: 0.629843
global_step: 18429, epoch: 61, loss: 0.520115
global_step: 18430, epoch: 61, loss: 0.471575
global_step: 18431, epoch: 61, loss: 0.551516
global_step: 18432, epoch: 61, loss: 0.515604
global_step: 18433, epoch: 61, loss: 0.541148
global_step: 18434, epoch: 61, loss: 0.540558
global_step: 18435, epoch: 61, loss: 0.472695
global_step: 18436, epoch: 61, loss: 0.479574
global_step: 18437, epoch: 61, loss: 0.648161
global_step: 18438, epoch: 61, loss: 0.573430
global_step: 18439, epoch: 61, loss: 0.594969
global_step: 18440, epoch: 61, loss: 0.657141
epoch: 61
train	acc: 0.9087	macro: p 0.9192, r 0.7610, f1: 0.7993	micro: p 0.9087, r 0.9087, f1 0.9087	weighted_f1:0.9025
dev	acc: 0.5609	macro: p 0.4159, r 0.3292, f1: 0.3292	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5140
test	acc: 0.5962	macro: p 0.4011, r 0.3300, f1: 0.3347	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5617
global_step: 18441, epoch: 62, loss: 0.556771
global_step: 18442, epoch: 62, loss: 0.523611
global_step: 18443, epoch: 62, loss: 0.552442
global_step: 18444, epoch: 62, loss: 0.716262
global_step: 18445, epoch: 62, loss: 0.461510
global_step: 18446, epoch: 62, loss: 0.505406
global_step: 18447, epoch: 62, loss: 0.466009
global_step: 18448, epoch: 62, loss: 0.581506
global_step: 18449, epoch: 62, loss: 0.605560
global_step: 18450, epoch: 62, loss: 0.540443
global_step: 18451, epoch: 62, loss: 0.534849
global_step: 18452, epoch: 62, loss: 0.588525
global_step: 18453, epoch: 62, loss: 0.501594
global_step: 18454, epoch: 62, loss: 0.507996
global_step: 18455, epoch: 62, loss: 0.538101
global_step: 18456, epoch: 62, loss: 0.464308
global_step: 18457, epoch: 62, loss: 0.631491
global_step: 18458, epoch: 62, loss: 0.477078
global_step: 18459, epoch: 62, loss: 0.557423
global_step: 18460, epoch: 62, loss: 0.499423
global_step: 18461, epoch: 62, loss: 0.499946
global_step: 18462, epoch: 62, loss: 0.595422
global_step: 18463, epoch: 62, loss: 0.455474
global_step: 18464, epoch: 62, loss: 0.498952
global_step: 18465, epoch: 62, loss: 0.560837
global_step: 18466, epoch: 62, loss: 0.547511
global_step: 18467, epoch: 62, loss: 0.496746
global_step: 18468, epoch: 62, loss: 0.672320
global_step: 18469, epoch: 62, loss: 0.540440
global_step: 18470, epoch: 62, loss: 0.540045
global_step: 18471, epoch: 62, loss: 0.624598
global_step: 18472, epoch: 62, loss: 0.517189
global_step: 18473, epoch: 62, loss: 0.504882
global_step: 18474, epoch: 62, loss: 0.574180
global_step: 18475, epoch: 62, loss: 0.569028
global_step: 18476, epoch: 62, loss: 0.524862
global_step: 18477, epoch: 62, loss: 0.556181
global_step: 18478, epoch: 62, loss: 0.531587
global_step: 18479, epoch: 62, loss: 0.569670
global_step: 18480, epoch: 62, loss: 0.784286
epoch: 62
train	acc: 0.9099	macro: p 0.9163, r 0.7600, f1: 0.7965	micro: p 0.9099, r 0.9099, f1 0.9099	weighted_f1:0.9029
dev	acc: 0.5609	macro: p 0.4898, r 0.3214, f1: 0.3239	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5086
test	acc: 0.5950	macro: p 0.3475, r 0.3156, f1: 0.3206	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5521
global_step: 18481, epoch: 63, loss: 0.490168
global_step: 18482, epoch: 63, loss: 0.542691
global_step: 18483, epoch: 63, loss: 0.578032
global_step: 18484, epoch: 63, loss: 0.546355
global_step: 18485, epoch: 63, loss: 0.591156
global_step: 18486, epoch: 63, loss: 0.530680
global_step: 18487, epoch: 63, loss: 0.553795
global_step: 18488, epoch: 63, loss: 0.615065
global_step: 18489, epoch: 63, loss: 0.485008
global_step: 18490, epoch: 63, loss: 0.544194
global_step: 18491, epoch: 63, loss: 0.553334
global_step: 18492, epoch: 63, loss: 0.566074
global_step: 18493, epoch: 63, loss: 0.613422
global_step: 18494, epoch: 63, loss: 0.643942
global_step: 18495, epoch: 63, loss: 0.491137
global_step: 18496, epoch: 63, loss: 0.540494
global_step: 18497, epoch: 63, loss: 0.506868
global_step: 18498, epoch: 63, loss: 0.550507
global_step: 18499, epoch: 63, loss: 0.507334
global_step: 18500, epoch: 63, loss: 0.455337
global_step: 18501, epoch: 63, loss: 0.595729
global_step: 18502, epoch: 63, loss: 0.533825
global_step: 18503, epoch: 63, loss: 0.488004
global_step: 18504, epoch: 63, loss: 0.484759
global_step: 18505, epoch: 63, loss: 0.450985
global_step: 18506, epoch: 63, loss: 0.457419
global_step: 18507, epoch: 63, loss: 0.525939
global_step: 18508, epoch: 63, loss: 0.560849
global_step: 18509, epoch: 63, loss: 0.393834
global_step: 18510, epoch: 63, loss: 0.526611
global_step: 18511, epoch: 63, loss: 0.487817
global_step: 18512, epoch: 63, loss: 0.519684
global_step: 18513, epoch: 63, loss: 0.659899
global_step: 18514, epoch: 63, loss: 0.464357
global_step: 18515, epoch: 63, loss: 0.612531
global_step: 18516, epoch: 63, loss: 0.603774
global_step: 18517, epoch: 63, loss: 0.505156
global_step: 18518, epoch: 63, loss: 0.625997
global_step: 18519, epoch: 63, loss: 0.512728
global_step: 18520, epoch: 63, loss: 0.727827
epoch: 63
train	acc: 0.9157	macro: p 0.9137, r 0.7806, f1: 0.8112	micro: p 0.9157, r 0.9157, f1 0.9157	weighted_f1:0.9102
dev	acc: 0.5464	macro: p 0.4069, r 0.3244, f1: 0.3283	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5074
test	acc: 0.5881	macro: p 0.3404, r 0.3257, f1: 0.3284	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5576
global_step: 18521, epoch: 64, loss: 0.540421
global_step: 18522, epoch: 64, loss: 0.536732
global_step: 18523, epoch: 64, loss: 0.494853
global_step: 18524, epoch: 64, loss: 0.574815
global_step: 18525, epoch: 64, loss: 0.559745
global_step: 18526, epoch: 64, loss: 0.535610
global_step: 18527, epoch: 64, loss: 0.623050
global_step: 18528, epoch: 64, loss: 0.597997
global_step: 18529, epoch: 64, loss: 0.533834
global_step: 18530, epoch: 64, loss: 0.548990
global_step: 18531, epoch: 64, loss: 0.538416
global_step: 18532, epoch: 64, loss: 0.407862
global_step: 18533, epoch: 64, loss: 0.544190
global_step: 18534, epoch: 64, loss: 0.520732
global_step: 18535, epoch: 64, loss: 0.495362
global_step: 18536, epoch: 64, loss: 0.534611
global_step: 18537, epoch: 64, loss: 0.495921
global_step: 18538, epoch: 64, loss: 0.590352
global_step: 18539, epoch: 64, loss: 0.394255
global_step: 18540, epoch: 64, loss: 0.531073
global_step: 18541, epoch: 64, loss: 0.454944
global_step: 18542, epoch: 64, loss: 0.542358
global_step: 18543, epoch: 64, loss: 0.575233
global_step: 18544, epoch: 64, loss: 0.625953
global_step: 18545, epoch: 64, loss: 0.437939
global_step: 18546, epoch: 64, loss: 0.543233
global_step: 18547, epoch: 64, loss: 0.609137
global_step: 18548, epoch: 64, loss: 0.647930
global_step: 18549, epoch: 64, loss: 0.484886
global_step: 18550, epoch: 64, loss: 0.557217
global_step: 18551, epoch: 64, loss: 0.493050
global_step: 18552, epoch: 64, loss: 0.573273
global_step: 18553, epoch: 64, loss: 0.464756
global_step: 18554, epoch: 64, loss: 0.529421
global_step: 18555, epoch: 64, loss: 0.556328
global_step: 18556, epoch: 64, loss: 0.599177
global_step: 18557, epoch: 64, loss: 0.546036
global_step: 18558, epoch: 64, loss: 0.594503
global_step: 18559, epoch: 64, loss: 0.507606
global_step: 18560, epoch: 64, loss: 0.600749
epoch: 64
train	acc: 0.9170	macro: p 0.9290, r 0.8059, f1: 0.8496	micro: p 0.9170, r 0.9170, f1 0.9170	weighted_f1:0.9140
dev	acc: 0.5564	macro: p 0.4196, r 0.3163, f1: 0.3165	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5021
test	acc: 0.5904	macro: p 0.3829, r 0.3085, f1: 0.3149	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5457
global_step: 18561, epoch: 65, loss: 0.469677
global_step: 18562, epoch: 65, loss: 0.532675
global_step: 18563, epoch: 65, loss: 0.499028
global_step: 18564, epoch: 65, loss: 0.527178
global_step: 18565, epoch: 65, loss: 0.563905
global_step: 18566, epoch: 65, loss: 0.622440
global_step: 18567, epoch: 65, loss: 0.507274
global_step: 18568, epoch: 65, loss: 0.513454
global_step: 18569, epoch: 65, loss: 0.477046
global_step: 18570, epoch: 65, loss: 0.576042
global_step: 18571, epoch: 65, loss: 0.581705
global_step: 18572, epoch: 65, loss: 0.505195
global_step: 18573, epoch: 65, loss: 0.615133
global_step: 18574, epoch: 65, loss: 0.505666
global_step: 18575, epoch: 65, loss: 0.544875
global_step: 18576, epoch: 65, loss: 0.459523
global_step: 18577, epoch: 65, loss: 0.565824
global_step: 18578, epoch: 65, loss: 0.504120
global_step: 18579, epoch: 65, loss: 0.505743
global_step: 18580, epoch: 65, loss: 0.444077
global_step: 18581, epoch: 65, loss: 0.499695
global_step: 18582, epoch: 65, loss: 0.506320
global_step: 18583, epoch: 65, loss: 0.563712
global_step: 18584, epoch: 65, loss: 0.470973
global_step: 18585, epoch: 65, loss: 0.528835
global_step: 18586, epoch: 65, loss: 0.588964
global_step: 18587, epoch: 65, loss: 0.480804
global_step: 18588, epoch: 65, loss: 0.560592
global_step: 18589, epoch: 65, loss: 0.457774
global_step: 18590, epoch: 65, loss: 0.511335
global_step: 18591, epoch: 65, loss: 0.438329
global_step: 18592, epoch: 65, loss: 0.603751
global_step: 18593, epoch: 65, loss: 0.564062
global_step: 18594, epoch: 65, loss: 0.490598
global_step: 18595, epoch: 65, loss: 0.551029
global_step: 18596, epoch: 65, loss: 0.617558
global_step: 18597, epoch: 65, loss: 0.542698
global_step: 18598, epoch: 65, loss: 0.561537
global_step: 18599, epoch: 65, loss: 0.437493
global_step: 18600, epoch: 65, loss: 0.462477
epoch: 65
train	acc: 0.9187	macro: p 0.9254, r 0.8090, f1: 0.8467	micro: p 0.9187, r 0.9187, f1 0.9187	weighted_f1:0.9157
dev	acc: 0.5419	macro: p 0.3310, r 0.3158, f1: 0.3038	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4961
test	acc: 0.5743	macro: p 0.3532, r 0.3172, f1: 0.3155	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5408
global_step: 18601, epoch: 66, loss: 0.519080
global_step: 18602, epoch: 66, loss: 0.541633
global_step: 18603, epoch: 66, loss: 0.484453
global_step: 18604, epoch: 66, loss: 0.464448
global_step: 18605, epoch: 66, loss: 0.513485
global_step: 18606, epoch: 66, loss: 0.614907
global_step: 18607, epoch: 66, loss: 0.532623
global_step: 18608, epoch: 66, loss: 0.509776
global_step: 18609, epoch: 66, loss: 0.467662
global_step: 18610, epoch: 66, loss: 0.429665
global_step: 18611, epoch: 66, loss: 0.576780
global_step: 18612, epoch: 66, loss: 0.517908
global_step: 18613, epoch: 66, loss: 0.546886
global_step: 18614, epoch: 66, loss: 0.567421
global_step: 18615, epoch: 66, loss: 0.444512
global_step: 18616, epoch: 66, loss: 0.510253
global_step: 18617, epoch: 66, loss: 0.569405
global_step: 18618, epoch: 66, loss: 0.533892
global_step: 18619, epoch: 66, loss: 0.519927
global_step: 18620, epoch: 66, loss: 0.518271
global_step: 18621, epoch: 66, loss: 0.506405
global_step: 18622, epoch: 66, loss: 0.501738
global_step: 18623, epoch: 66, loss: 0.650968
global_step: 18624, epoch: 66, loss: 0.530109
global_step: 18625, epoch: 66, loss: 0.494464
global_step: 18626, epoch: 66, loss: 0.532828
global_step: 18627, epoch: 66, loss: 0.546833
global_step: 18628, epoch: 66, loss: 0.486916
global_step: 18629, epoch: 66, loss: 0.473486
global_step: 18630, epoch: 66, loss: 0.608705
global_step: 18631, epoch: 66, loss: 0.427529
global_step: 18632, epoch: 66, loss: 0.514231
global_step: 18633, epoch: 66, loss: 0.603970
global_step: 18634, epoch: 66, loss: 0.486058
global_step: 18635, epoch: 66, loss: 0.499234
global_step: 18636, epoch: 66, loss: 0.593997
global_step: 18637, epoch: 66, loss: 0.519313
global_step: 18638, epoch: 66, loss: 0.549362
global_step: 18639, epoch: 66, loss: 0.439587
global_step: 18640, epoch: 66, loss: 0.501044
epoch: 66
train	acc: 0.9246	macro: p 0.9242, r 0.8224, f1: 0.8557	micro: p 0.9246, r 0.9246, f1 0.9246	weighted_f1:0.9221
dev	acc: 0.5392	macro: p 0.3990, r 0.3272, f1: 0.3260	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5028
test	acc: 0.5785	macro: p 0.3576, r 0.3323, f1: 0.3333	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5527
global_step: 18641, epoch: 67, loss: 0.599792
global_step: 18642, epoch: 67, loss: 0.524865
global_step: 18643, epoch: 67, loss: 0.521791
global_step: 18644, epoch: 67, loss: 0.479494
global_step: 18645, epoch: 67, loss: 0.458582
global_step: 18646, epoch: 67, loss: 0.539076
global_step: 18647, epoch: 67, loss: 0.504594
global_step: 18648, epoch: 67, loss: 0.617187
global_step: 18649, epoch: 67, loss: 0.545288
global_step: 18650, epoch: 67, loss: 0.504878
global_step: 18651, epoch: 67, loss: 0.516291
global_step: 18652, epoch: 67, loss: 0.625648
global_step: 18653, epoch: 67, loss: 0.452117
global_step: 18654, epoch: 67, loss: 0.453171
global_step: 18655, epoch: 67, loss: 0.502368
global_step: 18656, epoch: 67, loss: 0.597561
global_step: 18657, epoch: 67, loss: 0.529940
global_step: 18658, epoch: 67, loss: 0.405097
global_step: 18659, epoch: 67, loss: 0.523686
global_step: 18660, epoch: 67, loss: 0.468428
global_step: 18661, epoch: 67, loss: 0.546084
global_step: 18662, epoch: 67, loss: 0.412700
global_step: 18663, epoch: 67, loss: 0.447812
global_step: 18664, epoch: 67, loss: 0.451257
global_step: 18665, epoch: 67, loss: 0.478858
global_step: 18666, epoch: 67, loss: 0.465241
global_step: 18667, epoch: 67, loss: 0.452795
global_step: 18668, epoch: 67, loss: 0.410148
global_step: 18669, epoch: 67, loss: 0.481359
global_step: 18670, epoch: 67, loss: 0.550798
global_step: 18671, epoch: 67, loss: 0.544007
global_step: 18672, epoch: 67, loss: 0.509259
global_step: 18673, epoch: 67, loss: 0.538288
global_step: 18674, epoch: 67, loss: 0.486890
global_step: 18675, epoch: 67, loss: 0.507776
global_step: 18676, epoch: 67, loss: 0.445434
global_step: 18677, epoch: 67, loss: 0.585853
global_step: 18678, epoch: 67, loss: 0.481458
global_step: 18679, epoch: 67, loss: 0.517836
global_step: 18680, epoch: 67, loss: 0.408803
epoch: 67
train	acc: 0.9227	macro: p 0.9310, r 0.8121, f1: 0.8511	micro: p 0.9227, r 0.9227, f1 0.9227	weighted_f1:0.9198
dev	acc: 0.5546	macro: p 0.4804, r 0.3230, f1: 0.3231	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5066
test	acc: 0.5943	macro: p 0.3506, r 0.3227, f1: 0.3255	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5571
global_step: 18681, epoch: 68, loss: 0.488982
global_step: 18682, epoch: 68, loss: 0.435097
global_step: 18683, epoch: 68, loss: 0.428120
global_step: 18684, epoch: 68, loss: 0.534917
global_step: 18685, epoch: 68, loss: 0.474641
global_step: 18686, epoch: 68, loss: 0.466654
global_step: 18687, epoch: 68, loss: 0.588296
global_step: 18688, epoch: 68, loss: 0.544343
global_step: 18689, epoch: 68, loss: 0.526541
global_step: 18690, epoch: 68, loss: 0.542808
global_step: 18691, epoch: 68, loss: 0.579229
global_step: 18692, epoch: 68, loss: 0.429073
global_step: 18693, epoch: 68, loss: 0.443327
global_step: 18694, epoch: 68, loss: 0.461667
global_step: 18695, epoch: 68, loss: 0.532191
global_step: 18696, epoch: 68, loss: 0.589997
global_step: 18697, epoch: 68, loss: 0.498870
global_step: 18698, epoch: 68, loss: 0.463896
global_step: 18699, epoch: 68, loss: 0.413508
global_step: 18700, epoch: 68, loss: 0.488037
global_step: 18701, epoch: 68, loss: 0.503818
global_step: 18702, epoch: 68, loss: 0.597011
global_step: 18703, epoch: 68, loss: 0.434001
global_step: 18704, epoch: 68, loss: 0.451432
global_step: 18705, epoch: 68, loss: 0.413591
global_step: 18706, epoch: 68, loss: 0.525386
global_step: 18707, epoch: 68, loss: 0.497103
global_step: 18708, epoch: 68, loss: 0.418033
global_step: 18709, epoch: 68, loss: 0.480889
global_step: 18710, epoch: 68, loss: 0.526919
global_step: 18711, epoch: 68, loss: 0.450134
global_step: 18712, epoch: 68, loss: 0.542487
global_step: 18713, epoch: 68, loss: 0.558122
global_step: 18714, epoch: 68, loss: 0.471479
global_step: 18715, epoch: 68, loss: 0.476993
global_step: 18716, epoch: 68, loss: 0.526495
global_step: 18717, epoch: 68, loss: 0.523096
global_step: 18718, epoch: 68, loss: 0.514674
global_step: 18719, epoch: 68, loss: 0.580883
global_step: 18720, epoch: 68, loss: 0.664893
epoch: 68
train	acc: 0.9280	macro: p 0.9332, r 0.8363, f1: 0.8713	micro: p 0.9280, r 0.9280, f1 0.9280	weighted_f1:0.9261
dev	acc: 0.5546	macro: p 0.4139, r 0.3262, f1: 0.3259	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5090
test	acc: 0.5889	macro: p 0.3618, r 0.3270, f1: 0.3286	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5554
global_step: 18721, epoch: 69, loss: 0.536428
global_step: 18722, epoch: 69, loss: 0.572658
global_step: 18723, epoch: 69, loss: 0.428762
global_step: 18724, epoch: 69, loss: 0.488380
global_step: 18725, epoch: 69, loss: 0.469427
global_step: 18726, epoch: 69, loss: 0.475095
global_step: 18727, epoch: 69, loss: 0.469564
global_step: 18728, epoch: 69, loss: 0.498624
global_step: 18729, epoch: 69, loss: 0.552667
global_step: 18730, epoch: 69, loss: 0.417161
global_step: 18731, epoch: 69, loss: 0.474471
global_step: 18732, epoch: 69, loss: 0.354981
global_step: 18733, epoch: 69, loss: 0.507284
global_step: 18734, epoch: 69, loss: 0.449335
global_step: 18735, epoch: 69, loss: 0.525347
global_step: 18736, epoch: 69, loss: 0.477609
global_step: 18737, epoch: 69, loss: 0.422502
global_step: 18738, epoch: 69, loss: 0.475447
global_step: 18739, epoch: 69, loss: 0.450132
global_step: 18740, epoch: 69, loss: 0.559489
global_step: 18741, epoch: 69, loss: 0.507853
global_step: 18742, epoch: 69, loss: 0.468654
global_step: 18743, epoch: 69, loss: 0.510389
global_step: 18744, epoch: 69, loss: 0.567856
global_step: 18745, epoch: 69, loss: 0.487449
global_step: 18746, epoch: 69, loss: 0.517944
global_step: 18747, epoch: 69, loss: 0.519462
global_step: 18748, epoch: 69, loss: 0.569732
global_step: 18749, epoch: 69, loss: 0.395660
global_step: 18750, epoch: 69, loss: 0.625831
global_step: 18751, epoch: 69, loss: 0.509179
global_step: 18752, epoch: 69, loss: 0.553581
global_step: 18753, epoch: 69, loss: 0.429166
global_step: 18754, epoch: 69, loss: 0.575867
global_step: 18755, epoch: 69, loss: 0.553879
global_step: 18756, epoch: 69, loss: 0.494577
global_step: 18757, epoch: 69, loss: 0.561982
global_step: 18758, epoch: 69, loss: 0.473357
global_step: 18759, epoch: 69, loss: 0.492104
global_step: 18760, epoch: 69, loss: 0.369541
epoch: 69
train	acc: 0.9286	macro: p 0.9325, r 0.8312, f1: 0.8656	micro: p 0.9286, r 0.9286, f1 0.9286	weighted_f1:0.9262
dev	acc: 0.5546	macro: p 0.3928, r 0.3270, f1: 0.3285	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5101
test	acc: 0.5904	macro: p 0.3415, r 0.3246, f1: 0.3267	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5557
global_step: 18761, epoch: 70, loss: 0.496984
global_step: 18762, epoch: 70, loss: 0.423449
global_step: 18763, epoch: 70, loss: 0.508761
global_step: 18764, epoch: 70, loss: 0.469812
global_step: 18765, epoch: 70, loss: 0.420201
global_step: 18766, epoch: 70, loss: 0.438969
global_step: 18767, epoch: 70, loss: 0.465562
global_step: 18768, epoch: 70, loss: 0.544422
global_step: 18769, epoch: 70, loss: 0.512631
global_step: 18770, epoch: 70, loss: 0.457130
global_step: 18771, epoch: 70, loss: 0.524577
global_step: 18772, epoch: 70, loss: 0.519706
global_step: 18773, epoch: 70, loss: 0.456219
global_step: 18774, epoch: 70, loss: 0.555466
global_step: 18775, epoch: 70, loss: 0.562590
global_step: 18776, epoch: 70, loss: 0.452119
global_step: 18777, epoch: 70, loss: 0.484837
global_step: 18778, epoch: 70, loss: 0.543528
global_step: 18779, epoch: 70, loss: 0.510115
global_step: 18780, epoch: 70, loss: 0.535735
global_step: 18781, epoch: 70, loss: 0.454609
global_step: 18782, epoch: 70, loss: 0.460144
global_step: 18783, epoch: 70, loss: 0.518296
global_step: 18784, epoch: 70, loss: 0.445088
global_step: 18785, epoch: 70, loss: 0.507040
global_step: 18786, epoch: 70, loss: 0.503440
global_step: 18787, epoch: 70, loss: 0.468227
global_step: 18788, epoch: 70, loss: 0.358060
global_step: 18789, epoch: 70, loss: 0.512444
global_step: 18790, epoch: 70, loss: 0.515449
global_step: 18791, epoch: 70, loss: 0.468602
global_step: 18792, epoch: 70, loss: 0.502015
global_step: 18793, epoch: 70, loss: 0.515115
global_step: 18794, epoch: 70, loss: 0.519937
global_step: 18795, epoch: 70, loss: 0.472905
global_step: 18796, epoch: 70, loss: 0.499209
global_step: 18797, epoch: 70, loss: 0.519975
global_step: 18798, epoch: 70, loss: 0.498476
global_step: 18799, epoch: 70, loss: 0.479384
global_step: 18800, epoch: 70, loss: 0.800285
epoch: 70
train	acc: 0.9301	macro: p 0.9364, r 0.8324, f1: 0.8701	micro: p 0.9301, r 0.9301, f1 0.9301	weighted_f1:0.9278
dev	acc: 0.5564	macro: p 0.4177, r 0.3191, f1: 0.3213	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5046
test	acc: 0.5927	macro: p 0.3454, r 0.3166, f1: 0.3219	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5517
global_step: 18801, epoch: 71, loss: 0.486901
global_step: 18802, epoch: 71, loss: 0.457484
global_step: 18803, epoch: 71, loss: 0.496217
global_step: 18804, epoch: 71, loss: 0.462013
global_step: 18805, epoch: 71, loss: 0.350652
global_step: 18806, epoch: 71, loss: 0.461782
global_step: 18807, epoch: 71, loss: 0.470275
global_step: 18808, epoch: 71, loss: 0.457187
global_step: 18809, epoch: 71, loss: 0.544007
global_step: 18810, epoch: 71, loss: 0.445181
global_step: 18811, epoch: 71, loss: 0.471560
global_step: 18812, epoch: 71, loss: 0.502670
global_step: 18813, epoch: 71, loss: 0.529436
global_step: 18814, epoch: 71, loss: 0.544904
global_step: 18815, epoch: 71, loss: 0.431822
global_step: 18816, epoch: 71, loss: 0.481898
global_step: 18817, epoch: 71, loss: 0.437661
global_step: 18818, epoch: 71, loss: 0.539410
global_step: 18819, epoch: 71, loss: 0.429949
global_step: 18820, epoch: 71, loss: 0.489762
global_step: 18821, epoch: 71, loss: 0.401439
global_step: 18822, epoch: 71, loss: 0.484909
global_step: 18823, epoch: 71, loss: 0.470615
global_step: 18824, epoch: 71, loss: 0.565574
global_step: 18825, epoch: 71, loss: 0.510585
global_step: 18826, epoch: 71, loss: 0.500971
global_step: 18827, epoch: 71, loss: 0.539031
global_step: 18828, epoch: 71, loss: 0.524949
global_step: 18829, epoch: 71, loss: 0.538833
global_step: 18830, epoch: 71, loss: 0.480921
global_step: 18831, epoch: 71, loss: 0.457158
global_step: 18832, epoch: 71, loss: 0.559095
global_step: 18833, epoch: 71, loss: 0.400217
global_step: 18834, epoch: 71, loss: 0.480277
global_step: 18835, epoch: 71, loss: 0.475459
global_step: 18836, epoch: 71, loss: 0.523554
global_step: 18837, epoch: 71, loss: 0.507308
global_step: 18838, epoch: 71, loss: 0.478678
global_step: 18839, epoch: 71, loss: 0.479466
global_step: 18840, epoch: 71, loss: 0.109111
epoch: 71
train	acc: 0.9310	macro: p 0.9364, r 0.8390, f1: 0.8748	micro: p 0.9310, r 0.9310, f1 0.9310	weighted_f1:0.9290
dev	acc: 0.5564	macro: p 0.3718, r 0.3274, f1: 0.3299	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5154
test	acc: 0.5916	macro: p 0.3506, r 0.3254, f1: 0.3297	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5581
global_step: 18841, epoch: 72, loss: 0.430257
global_step: 18842, epoch: 72, loss: 0.430191
global_step: 18843, epoch: 72, loss: 0.393906
global_step: 18844, epoch: 72, loss: 0.517491
global_step: 18845, epoch: 72, loss: 0.402014
global_step: 18846, epoch: 72, loss: 0.474311
global_step: 18847, epoch: 72, loss: 0.442009
global_step: 18848, epoch: 72, loss: 0.441069
global_step: 18849, epoch: 72, loss: 0.454640
global_step: 18850, epoch: 72, loss: 0.450616
global_step: 18851, epoch: 72, loss: 0.486512
global_step: 18852, epoch: 72, loss: 0.413806
global_step: 18853, epoch: 72, loss: 0.398305
global_step: 18854, epoch: 72, loss: 0.525800
global_step: 18855, epoch: 72, loss: 0.558557
global_step: 18856, epoch: 72, loss: 0.539870
global_step: 18857, epoch: 72, loss: 0.493901
global_step: 18858, epoch: 72, loss: 0.514739
global_step: 18859, epoch: 72, loss: 0.443396
global_step: 18860, epoch: 72, loss: 0.414631
global_step: 18861, epoch: 72, loss: 0.400770
global_step: 18862, epoch: 72, loss: 0.484829
global_step: 18863, epoch: 72, loss: 0.492748
global_step: 18864, epoch: 72, loss: 0.360824
global_step: 18865, epoch: 72, loss: 0.460469
global_step: 18866, epoch: 72, loss: 0.558754
global_step: 18867, epoch: 72, loss: 0.456298
global_step: 18868, epoch: 72, loss: 0.507801
global_step: 18869, epoch: 72, loss: 0.499114
global_step: 18870, epoch: 72, loss: 0.497072
global_step: 18871, epoch: 72, loss: 0.529170
global_step: 18872, epoch: 72, loss: 0.549844
global_step: 18873, epoch: 72, loss: 0.601276
global_step: 18874, epoch: 72, loss: 0.613127
global_step: 18875, epoch: 72, loss: 0.398833
global_step: 18876, epoch: 72, loss: 0.367543
global_step: 18877, epoch: 72, loss: 0.426920
global_step: 18878, epoch: 72, loss: 0.514474
global_step: 18879, epoch: 72, loss: 0.469226
global_step: 18880, epoch: 72, loss: 0.166158
epoch: 72
train	acc: 0.9360	macro: p 0.9423, r 0.8586, f1: 0.8920	micro: p 0.9360, r 0.9360, f1 0.9360	weighted_f1:0.9347
dev	acc: 0.5518	macro: p 0.3680, r 0.3190, f1: 0.3181	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5034
test	acc: 0.5877	macro: p 0.3496, r 0.3157, f1: 0.3210	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5503
global_step: 18881, epoch: 73, loss: 0.419610
global_step: 18882, epoch: 73, loss: 0.461985
global_step: 18883, epoch: 73, loss: 0.399536
global_step: 18884, epoch: 73, loss: 0.411037
global_step: 18885, epoch: 73, loss: 0.574681
global_step: 18886, epoch: 73, loss: 0.463266
global_step: 18887, epoch: 73, loss: 0.455981
global_step: 18888, epoch: 73, loss: 0.500162
global_step: 18889, epoch: 73, loss: 0.424773
global_step: 18890, epoch: 73, loss: 0.511961
global_step: 18891, epoch: 73, loss: 0.485054
global_step: 18892, epoch: 73, loss: 0.541412
global_step: 18893, epoch: 73, loss: 0.467116
global_step: 18894, epoch: 73, loss: 0.396960
global_step: 18895, epoch: 73, loss: 0.446229
global_step: 18896, epoch: 73, loss: 0.450932
global_step: 18897, epoch: 73, loss: 0.467235
global_step: 18898, epoch: 73, loss: 0.472365
global_step: 18899, epoch: 73, loss: 0.488069
global_step: 18900, epoch: 73, loss: 0.466673
global_step: 18901, epoch: 73, loss: 0.451009
global_step: 18902, epoch: 73, loss: 0.468461
global_step: 18903, epoch: 73, loss: 0.611203
global_step: 18904, epoch: 73, loss: 0.415312
global_step: 18905, epoch: 73, loss: 0.508843
global_step: 18906, epoch: 73, loss: 0.493567
global_step: 18907, epoch: 73, loss: 0.394156
global_step: 18908, epoch: 73, loss: 0.585454
global_step: 18909, epoch: 73, loss: 0.438566
global_step: 18910, epoch: 73, loss: 0.440917
global_step: 18911, epoch: 73, loss: 0.388109
global_step: 18912, epoch: 73, loss: 0.488075
global_step: 18913, epoch: 73, loss: 0.471292
global_step: 18914, epoch: 73, loss: 0.357575
global_step: 18915, epoch: 73, loss: 0.469711
global_step: 18916, epoch: 73, loss: 0.533574
global_step: 18917, epoch: 73, loss: 0.439668
global_step: 18918, epoch: 73, loss: 0.456064
global_step: 18919, epoch: 73, loss: 0.469638
global_step: 18920, epoch: 73, loss: 0.792151
epoch: 73
train	acc: 0.9346	macro: p 0.9417, r 0.8571, f1: 0.8910	micro: p 0.9346, r 0.9346, f1 0.9346	weighted_f1:0.9333
dev	acc: 0.5491	macro: p 0.3727, r 0.3147, f1: 0.3204	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5024
test	acc: 0.5858	macro: p 0.3409, r 0.3077, f1: 0.3155	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5454
global_step: 18921, epoch: 74, loss: 0.399248
global_step: 18922, epoch: 74, loss: 0.355662
global_step: 18923, epoch: 74, loss: 0.459489
global_step: 18924, epoch: 74, loss: 0.506860
global_step: 18925, epoch: 74, loss: 0.389419
global_step: 18926, epoch: 74, loss: 0.430983
global_step: 18927, epoch: 74, loss: 0.452163
global_step: 18928, epoch: 74, loss: 0.444707
global_step: 18929, epoch: 74, loss: 0.461665
global_step: 18930, epoch: 74, loss: 0.413267
global_step: 18931, epoch: 74, loss: 0.448035
global_step: 18932, epoch: 74, loss: 0.461387
global_step: 18933, epoch: 74, loss: 0.441999
global_step: 18934, epoch: 74, loss: 0.530656
global_step: 18935, epoch: 74, loss: 0.504470
global_step: 18936, epoch: 74, loss: 0.466446
global_step: 18937, epoch: 74, loss: 0.439689
global_step: 18938, epoch: 74, loss: 0.570426
global_step: 18939, epoch: 74, loss: 0.434610
global_step: 18940, epoch: 74, loss: 0.456663
global_step: 18941, epoch: 74, loss: 0.415680
global_step: 18942, epoch: 74, loss: 0.583656
global_step: 18943, epoch: 74, loss: 0.423765
global_step: 18944, epoch: 74, loss: 0.525360
global_step: 18945, epoch: 74, loss: 0.412220
global_step: 18946, epoch: 74, loss: 0.436887
global_step: 18947, epoch: 74, loss: 0.500783
global_step: 18948, epoch: 74, loss: 0.424783
global_step: 18949, epoch: 74, loss: 0.447767
global_step: 18950, epoch: 74, loss: 0.476395
global_step: 18951, epoch: 74, loss: 0.563744
global_step: 18952, epoch: 74, loss: 0.556113
global_step: 18953, epoch: 74, loss: 0.446438
global_step: 18954, epoch: 74, loss: 0.443324
global_step: 18955, epoch: 74, loss: 0.501434
global_step: 18956, epoch: 74, loss: 0.414789
global_step: 18957, epoch: 74, loss: 0.432946
global_step: 18958, epoch: 74, loss: 0.431581
global_step: 18959, epoch: 74, loss: 0.458994
global_step: 18960, epoch: 74, loss: 0.562225
epoch: 74
train	acc: 0.9345	macro: p 0.9450, r 0.8596, f1: 0.8941	micro: p 0.9345, r 0.9345, f1 0.9345	weighted_f1:0.9333
dev	acc: 0.5528	macro: p 0.3660, r 0.3159, f1: 0.3154	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5011
test	acc: 0.5893	macro: p 0.3553, r 0.3128, f1: 0.3194	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5489
global_step: 18961, epoch: 75, loss: 0.426521
global_step: 18962, epoch: 75, loss: 0.406427
global_step: 18963, epoch: 75, loss: 0.494010
global_step: 18964, epoch: 75, loss: 0.427533
global_step: 18965, epoch: 75, loss: 0.456306
global_step: 18966, epoch: 75, loss: 0.437176
global_step: 18967, epoch: 75, loss: 0.468341
global_step: 18968, epoch: 75, loss: 0.425043
global_step: 18969, epoch: 75, loss: 0.458931
global_step: 18970, epoch: 75, loss: 0.421007
global_step: 18971, epoch: 75, loss: 0.425942
global_step: 18972, epoch: 75, loss: 0.428793
global_step: 18973, epoch: 75, loss: 0.631593
global_step: 18974, epoch: 75, loss: 0.437084
global_step: 18975, epoch: 75, loss: 0.396016
global_step: 18976, epoch: 75, loss: 0.353266
global_step: 18977, epoch: 75, loss: 0.490601
global_step: 18978, epoch: 75, loss: 0.523752
global_step: 18979, epoch: 75, loss: 0.391261
global_step: 18980, epoch: 75, loss: 0.419648
global_step: 18981, epoch: 75, loss: 0.437283
global_step: 18982, epoch: 75, loss: 0.488066
global_step: 18983, epoch: 75, loss: 0.464926
global_step: 18984, epoch: 75, loss: 0.507595
global_step: 18985, epoch: 75, loss: 0.389329
global_step: 18986, epoch: 75, loss: 0.408381
global_step: 18987, epoch: 75, loss: 0.399006
global_step: 18988, epoch: 75, loss: 0.474702
global_step: 18989, epoch: 75, loss: 0.464139
global_step: 18990, epoch: 75, loss: 0.437768
global_step: 18991, epoch: 75, loss: 0.403814
global_step: 18992, epoch: 75, loss: 0.474964
global_step: 18993, epoch: 75, loss: 0.506745
global_step: 18994, epoch: 75, loss: 0.365853
global_step: 18995, epoch: 75, loss: 0.353613
global_step: 18996, epoch: 75, loss: 0.414921
global_step: 18997, epoch: 75, loss: 0.409194
global_step: 18998, epoch: 75, loss: 0.409066
global_step: 18999, epoch: 75, loss: 0.427488
global_step: 19000, epoch: 75, loss: 0.166597
epoch: 75
train	acc: 0.9326	macro: p 0.9436, r 0.8505, f1: 0.8868	micro: p 0.9326, r 0.9326, f1 0.9326	weighted_f1:0.9312
dev	acc: 0.5509	macro: p 0.3520, r 0.3083, f1: 0.2999	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4947
test	acc: 0.5862	macro: p 0.3446, r 0.3078, f1: 0.3104	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5424
global_step: 19001, epoch: 76, loss: 0.428543
global_step: 19002, epoch: 76, loss: 0.445620
global_step: 19003, epoch: 76, loss: 0.423545
global_step: 19004, epoch: 76, loss: 0.453143
global_step: 19005, epoch: 76, loss: 0.455515
global_step: 19006, epoch: 76, loss: 0.389649
global_step: 19007, epoch: 76, loss: 0.446013
global_step: 19008, epoch: 76, loss: 0.418783
global_step: 19009, epoch: 76, loss: 0.459124
global_step: 19010, epoch: 76, loss: 0.462024
global_step: 19011, epoch: 76, loss: 0.452221
global_step: 19012, epoch: 76, loss: 0.420844
global_step: 19013, epoch: 76, loss: 0.427369
global_step: 19014, epoch: 76, loss: 0.440499
global_step: 19015, epoch: 76, loss: 0.419164
global_step: 19016, epoch: 76, loss: 0.417687
global_step: 19017, epoch: 76, loss: 0.445579
global_step: 19018, epoch: 76, loss: 0.505774
global_step: 19019, epoch: 76, loss: 0.390656
global_step: 19020, epoch: 76, loss: 0.427372
global_step: 19021, epoch: 76, loss: 0.477504
global_step: 19022, epoch: 76, loss: 0.402524
global_step: 19023, epoch: 76, loss: 0.486118
global_step: 19024, epoch: 76, loss: 0.420686
global_step: 19025, epoch: 76, loss: 0.520340
global_step: 19026, epoch: 76, loss: 0.536499
global_step: 19027, epoch: 76, loss: 0.449802
global_step: 19028, epoch: 76, loss: 0.441873
global_step: 19029, epoch: 76, loss: 0.392926
global_step: 19030, epoch: 76, loss: 0.378357
global_step: 19031, epoch: 76, loss: 0.539475
global_step: 19032, epoch: 76, loss: 0.414291
global_step: 19033, epoch: 76, loss: 0.433491
global_step: 19034, epoch: 76, loss: 0.463973
global_step: 19035, epoch: 76, loss: 0.467504
global_step: 19036, epoch: 76, loss: 0.413412
global_step: 19037, epoch: 76, loss: 0.487757
global_step: 19038, epoch: 76, loss: 0.489068
global_step: 19039, epoch: 76, loss: 0.426119
global_step: 19040, epoch: 76, loss: 0.254703
epoch: 76
train	acc: 0.9387	macro: p 0.9454, r 0.8663, f1: 0.8979	micro: p 0.9387, r 0.9387, f1 0.9387	weighted_f1:0.9377
dev	acc: 0.5491	macro: p 0.3752, r 0.3226, f1: 0.3195	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5027
test	acc: 0.5866	macro: p 0.3547, r 0.3223, f1: 0.3241	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5517
global_step: 19041, epoch: 77, loss: 0.414001
global_step: 19042, epoch: 77, loss: 0.426874
global_step: 19043, epoch: 77, loss: 0.414455
global_step: 19044, epoch: 77, loss: 0.398156
global_step: 19045, epoch: 77, loss: 0.459479
global_step: 19046, epoch: 77, loss: 0.448728
global_step: 19047, epoch: 77, loss: 0.484955
global_step: 19048, epoch: 77, loss: 0.372986
global_step: 19049, epoch: 77, loss: 0.444842
global_step: 19050, epoch: 77, loss: 0.470386
global_step: 19051, epoch: 77, loss: 0.422341
global_step: 19052, epoch: 77, loss: 0.460910
global_step: 19053, epoch: 77, loss: 0.351411
global_step: 19054, epoch: 77, loss: 0.440511
global_step: 19055, epoch: 77, loss: 0.479290
global_step: 19056, epoch: 77, loss: 0.371253
global_step: 19057, epoch: 77, loss: 0.479147
global_step: 19058, epoch: 77, loss: 0.432488
global_step: 19059, epoch: 77, loss: 0.390109
global_step: 19060, epoch: 77, loss: 0.482526
global_step: 19061, epoch: 77, loss: 0.492935
global_step: 19062, epoch: 77, loss: 0.349365
global_step: 19063, epoch: 77, loss: 0.404938
global_step: 19064, epoch: 77, loss: 0.514663
global_step: 19065, epoch: 77, loss: 0.456623
global_step: 19066, epoch: 77, loss: 0.388870
global_step: 19067, epoch: 77, loss: 0.467281
global_step: 19068, epoch: 77, loss: 0.560749
global_step: 19069, epoch: 77, loss: 0.423460
global_step: 19070, epoch: 77, loss: 0.424513
global_step: 19071, epoch: 77, loss: 0.442506
global_step: 19072, epoch: 77, loss: 0.465211
global_step: 19073, epoch: 77, loss: 0.532840
global_step: 19074, epoch: 77, loss: 0.477481
global_step: 19075, epoch: 77, loss: 0.515723
global_step: 19076, epoch: 77, loss: 0.501318
global_step: 19077, epoch: 77, loss: 0.429300
global_step: 19078, epoch: 77, loss: 0.406505
global_step: 19079, epoch: 77, loss: 0.491119
global_step: 19080, epoch: 77, loss: 0.570083
epoch: 77
train	acc: 0.9400	macro: p 0.9478, r 0.8704, f1: 0.9019	micro: p 0.9400, r 0.9400, f1 0.9400	weighted_f1:0.9390
dev	acc: 0.5518	macro: p 0.3892, r 0.3209, f1: 0.3191	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5026
test	acc: 0.5835	macro: p 0.3394, r 0.3140, f1: 0.3147	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5450
global_step: 19081, epoch: 78, loss: 0.445019
global_step: 19082, epoch: 78, loss: 0.379615
global_step: 19083, epoch: 78, loss: 0.440010
global_step: 19084, epoch: 78, loss: 0.406601
global_step: 19085, epoch: 78, loss: 0.466336
global_step: 19086, epoch: 78, loss: 0.366020
global_step: 19087, epoch: 78, loss: 0.461843
global_step: 19088, epoch: 78, loss: 0.520395
global_step: 19089, epoch: 78, loss: 0.384593
global_step: 19090, epoch: 78, loss: 0.390638
global_step: 19091, epoch: 78, loss: 0.535398
global_step: 19092, epoch: 78, loss: 0.399627
global_step: 19093, epoch: 78, loss: 0.402685
global_step: 19094, epoch: 78, loss: 0.480694
global_step: 19095, epoch: 78, loss: 0.443193
global_step: 19096, epoch: 78, loss: 0.393964
global_step: 19097, epoch: 78, loss: 0.478059
global_step: 19098, epoch: 78, loss: 0.435664
global_step: 19099, epoch: 78, loss: 0.368282
global_step: 19100, epoch: 78, loss: 0.401600
global_step: 19101, epoch: 78, loss: 0.494004
global_step: 19102, epoch: 78, loss: 0.459210
global_step: 19103, epoch: 78, loss: 0.388058
global_step: 19104, epoch: 78, loss: 0.406478
global_step: 19105, epoch: 78, loss: 0.423344
global_step: 19106, epoch: 78, loss: 0.548829
global_step: 19107, epoch: 78, loss: 0.405974
global_step: 19108, epoch: 78, loss: 0.421063
global_step: 19109, epoch: 78, loss: 0.492024
global_step: 19110, epoch: 78, loss: 0.419880
global_step: 19111, epoch: 78, loss: 0.384690
global_step: 19112, epoch: 78, loss: 0.447703
global_step: 19113, epoch: 78, loss: 0.444843
global_step: 19114, epoch: 78, loss: 0.420289
global_step: 19115, epoch: 78, loss: 0.379008
global_step: 19116, epoch: 78, loss: 0.448815
global_step: 19117, epoch: 78, loss: 0.447099
global_step: 19118, epoch: 78, loss: 0.488063
global_step: 19119, epoch: 78, loss: 0.556936
global_step: 19120, epoch: 78, loss: 0.200042
epoch: 78
train	acc: 0.9385	macro: p 0.9476, r 0.8709, f1: 0.9031	micro: p 0.9385, r 0.9385, f1 0.9385	weighted_f1:0.9376
dev	acc: 0.5582	macro: p 0.3980, r 0.3217, f1: 0.3228	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5073
test	acc: 0.5931	macro: p 0.3646, r 0.3145, f1: 0.3213	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5505
global_step: 19121, epoch: 79, loss: 0.407572
global_step: 19122, epoch: 79, loss: 0.400208
global_step: 19123, epoch: 79, loss: 0.419798
global_step: 19124, epoch: 79, loss: 0.434320
global_step: 19125, epoch: 79, loss: 0.422936
global_step: 19126, epoch: 79, loss: 0.432699
global_step: 19127, epoch: 79, loss: 0.391714
global_step: 19128, epoch: 79, loss: 0.359089
global_step: 19129, epoch: 79, loss: 0.410335
global_step: 19130, epoch: 79, loss: 0.413812
global_step: 19131, epoch: 79, loss: 0.391203
global_step: 19132, epoch: 79, loss: 0.389742
global_step: 19133, epoch: 79, loss: 0.458744
global_step: 19134, epoch: 79, loss: 0.539215
global_step: 19135, epoch: 79, loss: 0.430634
global_step: 19136, epoch: 79, loss: 0.333041
global_step: 19137, epoch: 79, loss: 0.475762
global_step: 19138, epoch: 79, loss: 0.460347
global_step: 19139, epoch: 79, loss: 0.405931
global_step: 19140, epoch: 79, loss: 0.413874
global_step: 19141, epoch: 79, loss: 0.435373
global_step: 19142, epoch: 79, loss: 0.367464
global_step: 19143, epoch: 79, loss: 0.407228
global_step: 19144, epoch: 79, loss: 0.484739
global_step: 19145, epoch: 79, loss: 0.422772
global_step: 19146, epoch: 79, loss: 0.423193
global_step: 19147, epoch: 79, loss: 0.418848
global_step: 19148, epoch: 79, loss: 0.439749
global_step: 19149, epoch: 79, loss: 0.429277
global_step: 19150, epoch: 79, loss: 0.458665
global_step: 19151, epoch: 79, loss: 0.357609
global_step: 19152, epoch: 79, loss: 0.370532
global_step: 19153, epoch: 79, loss: 0.430762
global_step: 19154, epoch: 79, loss: 0.442835
global_step: 19155, epoch: 79, loss: 0.412108
global_step: 19156, epoch: 79, loss: 0.383140
global_step: 19157, epoch: 79, loss: 0.435504
global_step: 19158, epoch: 79, loss: 0.470740
global_step: 19159, epoch: 79, loss: 0.430744
global_step: 19160, epoch: 79, loss: 0.036274
epoch: 79
train	acc: 0.9429	macro: p 0.9477, r 0.8822, f1: 0.9097	micro: p 0.9429, r 0.9429, f1 0.9429	weighted_f1:0.9422
dev	acc: 0.5528	macro: p 0.3768, r 0.3244, f1: 0.3251	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5095
test	acc: 0.5824	macro: p 0.3543, r 0.3236, f1: 0.3283	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5512
global_step: 19161, epoch: 80, loss: 0.438312
global_step: 19162, epoch: 80, loss: 0.336934
global_step: 19163, epoch: 80, loss: 0.391759
global_step: 19164, epoch: 80, loss: 0.417563
global_step: 19165, epoch: 80, loss: 0.469070
global_step: 19166, epoch: 80, loss: 0.442057
global_step: 19167, epoch: 80, loss: 0.479579
global_step: 19168, epoch: 80, loss: 0.393539
global_step: 19169, epoch: 80, loss: 0.407936
global_step: 19170, epoch: 80, loss: 0.429258
global_step: 19171, epoch: 80, loss: 0.444537
global_step: 19172, epoch: 80, loss: 0.400515
global_step: 19173, epoch: 80, loss: 0.389900
global_step: 19174, epoch: 80, loss: 0.376530
global_step: 19175, epoch: 80, loss: 0.371507
global_step: 19176, epoch: 80, loss: 0.475435
global_step: 19177, epoch: 80, loss: 0.408273
global_step: 19178, epoch: 80, loss: 0.390016
global_step: 19179, epoch: 80, loss: 0.339308
global_step: 19180, epoch: 80, loss: 0.479868
global_step: 19181, epoch: 80, loss: 0.412849
global_step: 19182, epoch: 80, loss: 0.359326
global_step: 19183, epoch: 80, loss: 0.460855
global_step: 19184, epoch: 80, loss: 0.423761
global_step: 19185, epoch: 80, loss: 0.332947
global_step: 19186, epoch: 80, loss: 0.361410
global_step: 19187, epoch: 80, loss: 0.464705
global_step: 19188, epoch: 80, loss: 0.465190
global_step: 19189, epoch: 80, loss: 0.347633
global_step: 19190, epoch: 80, loss: 0.428716
global_step: 19191, epoch: 80, loss: 0.418213
global_step: 19192, epoch: 80, loss: 0.462099
global_step: 19193, epoch: 80, loss: 0.397097
global_step: 19194, epoch: 80, loss: 0.389367
global_step: 19195, epoch: 80, loss: 0.441570
global_step: 19196, epoch: 80, loss: 0.464774
global_step: 19197, epoch: 80, loss: 0.425398
global_step: 19198, epoch: 80, loss: 0.440060
global_step: 19199, epoch: 80, loss: 0.390383
global_step: 19200, epoch: 80, loss: 0.166338
epoch: 80
train	acc: 0.9444	macro: p 0.9521, r 0.8888, f1: 0.9158	micro: p 0.9444, r 0.9444, f1 0.9444	weighted_f1:0.9439
dev	acc: 0.5491	macro: p 0.4026, r 0.3231, f1: 0.3250	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5040
test	acc: 0.5835	macro: p 0.3493, r 0.3188, f1: 0.3239	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5493
global_step: 19201, epoch: 81, loss: 0.363160
global_step: 19202, epoch: 81, loss: 0.454200
global_step: 19203, epoch: 81, loss: 0.290456
global_step: 19204, epoch: 81, loss: 0.392014
global_step: 19205, epoch: 81, loss: 0.449108
global_step: 19206, epoch: 81, loss: 0.482187
global_step: 19207, epoch: 81, loss: 0.484211
global_step: 19208, epoch: 81, loss: 0.433377
global_step: 19209, epoch: 81, loss: 0.408517
global_step: 19210, epoch: 81, loss: 0.387358
global_step: 19211, epoch: 81, loss: 0.429680
global_step: 19212, epoch: 81, loss: 0.447414
global_step: 19213, epoch: 81, loss: 0.410575
global_step: 19214, epoch: 81, loss: 0.305271
global_step: 19215, epoch: 81, loss: 0.465650
global_step: 19216, epoch: 81, loss: 0.439922
global_step: 19217, epoch: 81, loss: 0.454329
global_step: 19218, epoch: 81, loss: 0.407702
global_step: 19219, epoch: 81, loss: 0.464914
global_step: 19220, epoch: 81, loss: 0.411831
global_step: 19221, epoch: 81, loss: 0.444372
global_step: 19222, epoch: 81, loss: 0.437724
global_step: 19223, epoch: 81, loss: 0.428306
global_step: 19224, epoch: 81, loss: 0.394334
global_step: 19225, epoch: 81, loss: 0.469929
global_step: 19226, epoch: 81, loss: 0.353305
global_step: 19227, epoch: 81, loss: 0.432939
global_step: 19228, epoch: 81, loss: 0.414524
global_step: 19229, epoch: 81, loss: 0.427644
global_step: 19230, epoch: 81, loss: 0.393234
global_step: 19231, epoch: 81, loss: 0.405973
global_step: 19232, epoch: 81, loss: 0.449968
global_step: 19233, epoch: 81, loss: 0.427412
global_step: 19234, epoch: 81, loss: 0.419742
global_step: 19235, epoch: 81, loss: 0.504723
global_step: 19236, epoch: 81, loss: 0.371793
global_step: 19237, epoch: 81, loss: 0.466065
global_step: 19238, epoch: 81, loss: 0.390720
global_step: 19239, epoch: 81, loss: 0.382394
global_step: 19240, epoch: 81, loss: 0.237026
epoch: 81
train	acc: 0.9447	macro: p 0.9514, r 0.8936, f1: 0.9188	micro: p 0.9447, r 0.9447, f1 0.9447	weighted_f1:0.9443
dev	acc: 0.5591	macro: p 0.4254, r 0.3289, f1: 0.3334	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5143
test	acc: 0.5862	macro: p 0.3790, r 0.3214, f1: 0.3297	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5512
global_step: 19241, epoch: 82, loss: 0.396024
global_step: 19242, epoch: 82, loss: 0.321149
global_step: 19243, epoch: 82, loss: 0.373550
global_step: 19244, epoch: 82, loss: 0.435019
global_step: 19245, epoch: 82, loss: 0.394464
global_step: 19246, epoch: 82, loss: 0.456659
global_step: 19247, epoch: 82, loss: 0.424157
global_step: 19248, epoch: 82, loss: 0.402928
global_step: 19249, epoch: 82, loss: 0.469467
global_step: 19250, epoch: 82, loss: 0.402342
global_step: 19251, epoch: 82, loss: 0.436433
global_step: 19252, epoch: 82, loss: 0.369442
global_step: 19253, epoch: 82, loss: 0.547915
global_step: 19254, epoch: 82, loss: 0.445329
global_step: 19255, epoch: 82, loss: 0.426707
global_step: 19256, epoch: 82, loss: 0.403461
global_step: 19257, epoch: 82, loss: 0.515782
global_step: 19258, epoch: 82, loss: 0.399328
global_step: 19259, epoch: 82, loss: 0.417052
global_step: 19260, epoch: 82, loss: 0.430246
global_step: 19261, epoch: 82, loss: 0.385901
global_step: 19262, epoch: 82, loss: 0.326543
global_step: 19263, epoch: 82, loss: 0.476900
global_step: 19264, epoch: 82, loss: 0.390692
global_step: 19265, epoch: 82, loss: 0.389586
global_step: 19266, epoch: 82, loss: 0.469781
global_step: 19267, epoch: 82, loss: 0.362130
global_step: 19268, epoch: 82, loss: 0.392956
global_step: 19269, epoch: 82, loss: 0.318045
global_step: 19270, epoch: 82, loss: 0.368041
global_step: 19271, epoch: 82, loss: 0.435685
global_step: 19272, epoch: 82, loss: 0.445361
global_step: 19273, epoch: 82, loss: 0.418602
global_step: 19274, epoch: 82, loss: 0.524508
global_step: 19275, epoch: 82, loss: 0.368000
global_step: 19276, epoch: 82, loss: 0.338742
global_step: 19277, epoch: 82, loss: 0.441352
global_step: 19278, epoch: 82, loss: 0.547265
global_step: 19279, epoch: 82, loss: 0.433505
global_step: 19280, epoch: 82, loss: 0.343803
epoch: 82
train	acc: 0.9462	macro: p 0.9539, r 0.8908, f1: 0.9179	micro: p 0.9462, r 0.9462, f1 0.9462	weighted_f1:0.9456
dev	acc: 0.5573	macro: p 0.4110, r 0.3238, f1: 0.3281	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5108
test	acc: 0.5885	macro: p 0.3538, r 0.3158, f1: 0.3231	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5516
global_step: 19281, epoch: 83, loss: 0.342320
global_step: 19282, epoch: 83, loss: 0.309326
global_step: 19283, epoch: 83, loss: 0.443845
global_step: 19284, epoch: 83, loss: 0.400514
global_step: 19285, epoch: 83, loss: 0.415796
global_step: 19286, epoch: 83, loss: 0.389882
global_step: 19287, epoch: 83, loss: 0.475153
global_step: 19288, epoch: 83, loss: 0.382926
global_step: 19289, epoch: 83, loss: 0.452512
global_step: 19290, epoch: 83, loss: 0.429062
global_step: 19291, epoch: 83, loss: 0.327678
global_step: 19292, epoch: 83, loss: 0.351818
global_step: 19293, epoch: 83, loss: 0.472322
global_step: 19294, epoch: 83, loss: 0.428754
global_step: 19295, epoch: 83, loss: 0.356766
global_step: 19296, epoch: 83, loss: 0.476228
global_step: 19297, epoch: 83, loss: 0.419507
global_step: 19298, epoch: 83, loss: 0.389970
global_step: 19299, epoch: 83, loss: 0.354529
global_step: 19300, epoch: 83, loss: 0.447695
global_step: 19301, epoch: 83, loss: 0.399716
global_step: 19302, epoch: 83, loss: 0.443676
global_step: 19303, epoch: 83, loss: 0.378984
global_step: 19304, epoch: 83, loss: 0.394805
global_step: 19305, epoch: 83, loss: 0.386477
global_step: 19306, epoch: 83, loss: 0.491659
global_step: 19307, epoch: 83, loss: 0.383596
global_step: 19308, epoch: 83, loss: 0.452044
global_step: 19309, epoch: 83, loss: 0.382916
global_step: 19310, epoch: 83, loss: 0.417984
global_step: 19311, epoch: 83, loss: 0.431805
global_step: 19312, epoch: 83, loss: 0.441493
global_step: 19313, epoch: 83, loss: 0.516962
global_step: 19314, epoch: 83, loss: 0.325380
global_step: 19315, epoch: 83, loss: 0.365859
global_step: 19316, epoch: 83, loss: 0.385256
global_step: 19317, epoch: 83, loss: 0.362307
global_step: 19318, epoch: 83, loss: 0.446622
global_step: 19319, epoch: 83, loss: 0.399086
global_step: 19320, epoch: 83, loss: 0.371714
epoch: 83
train	acc: 0.9466	macro: p 0.9501, r 0.8904, f1: 0.9151	micro: p 0.9466, r 0.9466, f1 0.9466	weighted_f1:0.9460
dev	acc: 0.5509	macro: p 0.3387, r 0.3190, f1: 0.3158	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5070
test	acc: 0.5831	macro: p 0.3388, r 0.3229, f1: 0.3255	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5517
global_step: 19321, epoch: 84, loss: 0.394218
global_step: 19322, epoch: 84, loss: 0.390766
global_step: 19323, epoch: 84, loss: 0.375942
global_step: 19324, epoch: 84, loss: 0.417607
global_step: 19325, epoch: 84, loss: 0.389854
global_step: 19326, epoch: 84, loss: 0.386201
global_step: 19327, epoch: 84, loss: 0.399255
global_step: 19328, epoch: 84, loss: 0.444811
global_step: 19329, epoch: 84, loss: 0.373532
global_step: 19330, epoch: 84, loss: 0.348552
global_step: 19331, epoch: 84, loss: 0.393073
global_step: 19332, epoch: 84, loss: 0.430270
global_step: 19333, epoch: 84, loss: 0.359741
global_step: 19334, epoch: 84, loss: 0.408177
global_step: 19335, epoch: 84, loss: 0.424089
global_step: 19336, epoch: 84, loss: 0.378123
global_step: 19337, epoch: 84, loss: 0.417863
global_step: 19338, epoch: 84, loss: 0.363980
global_step: 19339, epoch: 84, loss: 0.446372
global_step: 19340, epoch: 84, loss: 0.350115
global_step: 19341, epoch: 84, loss: 0.391610
global_step: 19342, epoch: 84, loss: 0.421213
global_step: 19343, epoch: 84, loss: 0.439564
global_step: 19344, epoch: 84, loss: 0.364432
global_step: 19345, epoch: 84, loss: 0.414447
global_step: 19346, epoch: 84, loss: 0.367017
global_step: 19347, epoch: 84, loss: 0.476298
global_step: 19348, epoch: 84, loss: 0.362406
global_step: 19349, epoch: 84, loss: 0.438160
global_step: 19350, epoch: 84, loss: 0.365930
global_step: 19351, epoch: 84, loss: 0.305413
global_step: 19352, epoch: 84, loss: 0.399398
global_step: 19353, epoch: 84, loss: 0.405393
global_step: 19354, epoch: 84, loss: 0.360785
global_step: 19355, epoch: 84, loss: 0.373230
global_step: 19356, epoch: 84, loss: 0.451814
global_step: 19357, epoch: 84, loss: 0.379463
global_step: 19358, epoch: 84, loss: 0.339632
global_step: 19359, epoch: 84, loss: 0.379718
global_step: 19360, epoch: 84, loss: 0.131696
epoch: 84
train	acc: 0.9461	macro: p 0.9542, r 0.8897, f1: 0.9174	micro: p 0.9461, r 0.9461, f1 0.9461	weighted_f1:0.9455
dev	acc: 0.5627	macro: p 0.4413, r 0.3203, f1: 0.3207	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5102
test	acc: 0.5962	macro: p 0.3535, r 0.3170, f1: 0.3216	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5535
global_step: 19361, epoch: 85, loss: 0.522186
global_step: 19362, epoch: 85, loss: 0.378684
global_step: 19363, epoch: 85, loss: 0.285146
global_step: 19364, epoch: 85, loss: 0.380648
global_step: 19365, epoch: 85, loss: 0.472865
global_step: 19366, epoch: 85, loss: 0.426622
global_step: 19367, epoch: 85, loss: 0.434811
global_step: 19368, epoch: 85, loss: 0.370649
global_step: 19369, epoch: 85, loss: 0.381114
global_step: 19370, epoch: 85, loss: 0.401187
global_step: 19371, epoch: 85, loss: 0.383310
global_step: 19372, epoch: 85, loss: 0.429479
global_step: 19373, epoch: 85, loss: 0.369503
global_step: 19374, epoch: 85, loss: 0.401403
global_step: 19375, epoch: 85, loss: 0.259680
global_step: 19376, epoch: 85, loss: 0.400506
global_step: 19377, epoch: 85, loss: 0.446775
global_step: 19378, epoch: 85, loss: 0.310369
global_step: 19379, epoch: 85, loss: 0.320388
global_step: 19380, epoch: 85, loss: 0.328143
global_step: 19381, epoch: 85, loss: 0.373280
global_step: 19382, epoch: 85, loss: 0.460671
global_step: 19383, epoch: 85, loss: 0.447074
global_step: 19384, epoch: 85, loss: 0.375624
global_step: 19385, epoch: 85, loss: 0.459694
global_step: 19386, epoch: 85, loss: 0.372496
global_step: 19387, epoch: 85, loss: 0.386029
global_step: 19388, epoch: 85, loss: 0.391432
global_step: 19389, epoch: 85, loss: 0.349839
global_step: 19390, epoch: 85, loss: 0.455097
global_step: 19391, epoch: 85, loss: 0.309733
global_step: 19392, epoch: 85, loss: 0.406160
global_step: 19393, epoch: 85, loss: 0.370079
global_step: 19394, epoch: 85, loss: 0.376993
global_step: 19395, epoch: 85, loss: 0.385795
global_step: 19396, epoch: 85, loss: 0.417588
global_step: 19397, epoch: 85, loss: 0.373169
global_step: 19398, epoch: 85, loss: 0.373230
global_step: 19399, epoch: 85, loss: 0.320573
global_step: 19400, epoch: 85, loss: 0.513310
epoch: 85
train	acc: 0.9501	macro: p 0.9573, r 0.9083, f1: 0.9303	micro: p 0.9501, r 0.9501, f1 0.9501	weighted_f1:0.9499
dev	acc: 0.5573	macro: p 0.4072, r 0.3271, f1: 0.3340	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5138
test	acc: 0.5851	macro: p 0.3600, r 0.3158, f1: 0.3223	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5496
global_step: 19401, epoch: 86, loss: 0.390826
global_step: 19402, epoch: 86, loss: 0.280630
global_step: 19403, epoch: 86, loss: 0.329442
global_step: 19404, epoch: 86, loss: 0.441539
global_step: 19405, epoch: 86, loss: 0.404119
global_step: 19406, epoch: 86, loss: 0.410917
global_step: 19407, epoch: 86, loss: 0.471331
global_step: 19408, epoch: 86, loss: 0.394335
global_step: 19409, epoch: 86, loss: 0.363501
global_step: 19410, epoch: 86, loss: 0.389207
global_step: 19411, epoch: 86, loss: 0.342960
global_step: 19412, epoch: 86, loss: 0.371817
global_step: 19413, epoch: 86, loss: 0.332909
global_step: 19414, epoch: 86, loss: 0.375273
global_step: 19415, epoch: 86, loss: 0.334098
global_step: 19416, epoch: 86, loss: 0.392364
global_step: 19417, epoch: 86, loss: 0.329337
global_step: 19418, epoch: 86, loss: 0.333201
global_step: 19419, epoch: 86, loss: 0.403533
global_step: 19420, epoch: 86, loss: 0.327570
global_step: 19421, epoch: 86, loss: 0.389343
global_step: 19422, epoch: 86, loss: 0.372235
global_step: 19423, epoch: 86, loss: 0.406232
global_step: 19424, epoch: 86, loss: 0.366521
global_step: 19425, epoch: 86, loss: 0.400337
global_step: 19426, epoch: 86, loss: 0.431588
global_step: 19427, epoch: 86, loss: 0.383067
global_step: 19428, epoch: 86, loss: 0.351667
global_step: 19429, epoch: 86, loss: 0.346091
global_step: 19430, epoch: 86, loss: 0.404549
global_step: 19431, epoch: 86, loss: 0.392924
global_step: 19432, epoch: 86, loss: 0.307206
global_step: 19433, epoch: 86, loss: 0.339737
global_step: 19434, epoch: 86, loss: 0.424179
global_step: 19435, epoch: 86, loss: 0.399790
global_step: 19436, epoch: 86, loss: 0.404805
global_step: 19437, epoch: 86, loss: 0.393577
global_step: 19438, epoch: 86, loss: 0.542801
global_step: 19439, epoch: 86, loss: 0.352364
global_step: 19440, epoch: 86, loss: 0.020145
epoch: 86
train	acc: 0.9523	macro: p 0.9596, r 0.9124, f1: 0.9337	micro: p 0.9523, r 0.9523, f1 0.9523	weighted_f1:0.9521
dev	acc: 0.5509	macro: p 0.3995, r 0.3205, f1: 0.3236	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5033
test	acc: 0.5854	macro: p 0.3589, r 0.3150, f1: 0.3212	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5465
global_step: 19441, epoch: 87, loss: 0.384757
global_step: 19442, epoch: 87, loss: 0.303410
global_step: 19443, epoch: 87, loss: 0.366139
global_step: 19444, epoch: 87, loss: 0.408284
global_step: 19445, epoch: 87, loss: 0.349129
global_step: 19446, epoch: 87, loss: 0.326024
global_step: 19447, epoch: 87, loss: 0.367744
global_step: 19448, epoch: 87, loss: 0.328479
global_step: 19449, epoch: 87, loss: 0.354513
global_step: 19450, epoch: 87, loss: 0.379491
global_step: 19451, epoch: 87, loss: 0.333973
global_step: 19452, epoch: 87, loss: 0.495613
global_step: 19453, epoch: 87, loss: 0.512168
global_step: 19454, epoch: 87, loss: 0.345606
global_step: 19455, epoch: 87, loss: 0.378004
global_step: 19456, epoch: 87, loss: 0.426901
global_step: 19457, epoch: 87, loss: 0.353804
global_step: 19458, epoch: 87, loss: 0.392120
global_step: 19459, epoch: 87, loss: 0.347322
global_step: 19460, epoch: 87, loss: 0.409330
global_step: 19461, epoch: 87, loss: 0.345527
global_step: 19462, epoch: 87, loss: 0.326149
global_step: 19463, epoch: 87, loss: 0.321185
global_step: 19464, epoch: 87, loss: 0.399068
global_step: 19465, epoch: 87, loss: 0.362297
global_step: 19466, epoch: 87, loss: 0.397486
global_step: 19467, epoch: 87, loss: 0.455019
global_step: 19468, epoch: 87, loss: 0.391503
global_step: 19469, epoch: 87, loss: 0.421568
global_step: 19470, epoch: 87, loss: 0.318515
global_step: 19471, epoch: 87, loss: 0.408240
global_step: 19472, epoch: 87, loss: 0.355368
global_step: 19473, epoch: 87, loss: 0.407131
global_step: 19474, epoch: 87, loss: 0.346757
global_step: 19475, epoch: 87, loss: 0.347737
global_step: 19476, epoch: 87, loss: 0.365669
global_step: 19477, epoch: 87, loss: 0.361977
global_step: 19478, epoch: 87, loss: 0.378099
global_step: 19479, epoch: 87, loss: 0.487564
global_step: 19480, epoch: 87, loss: 0.393421
epoch: 87
train	acc: 0.9490	macro: p 0.9584, r 0.9024, f1: 0.9275	micro: p 0.9490, r 0.9490, f1 0.9490	weighted_f1:0.9486
dev	acc: 0.5546	macro: p 0.4085, r 0.3142, f1: 0.3103	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5004
test	acc: 0.5904	macro: p 0.3525, r 0.3093, f1: 0.3136	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5457
global_step: 19481, epoch: 88, loss: 0.346413
global_step: 19482, epoch: 88, loss: 0.298836
global_step: 19483, epoch: 88, loss: 0.349751
global_step: 19484, epoch: 88, loss: 0.372211
global_step: 19485, epoch: 88, loss: 0.369461
global_step: 19486, epoch: 88, loss: 0.403760
global_step: 19487, epoch: 88, loss: 0.378410
global_step: 19488, epoch: 88, loss: 0.335248
global_step: 19489, epoch: 88, loss: 0.417947
global_step: 19490, epoch: 88, loss: 0.410866
global_step: 19491, epoch: 88, loss: 0.398039
global_step: 19492, epoch: 88, loss: 0.374537
global_step: 19493, epoch: 88, loss: 0.307866
global_step: 19494, epoch: 88, loss: 0.361692
global_step: 19495, epoch: 88, loss: 0.403049
global_step: 19496, epoch: 88, loss: 0.386994
global_step: 19497, epoch: 88, loss: 0.458603
global_step: 19498, epoch: 88, loss: 0.308460
global_step: 19499, epoch: 88, loss: 0.377990
global_step: 19500, epoch: 88, loss: 0.380714
global_step: 19501, epoch: 88, loss: 0.430254
global_step: 19502, epoch: 88, loss: 0.388242
global_step: 19503, epoch: 88, loss: 0.429540
global_step: 19504, epoch: 88, loss: 0.365318
global_step: 19505, epoch: 88, loss: 0.387861
global_step: 19506, epoch: 88, loss: 0.375426
global_step: 19507, epoch: 88, loss: 0.320753
global_step: 19508, epoch: 88, loss: 0.413214
global_step: 19509, epoch: 88, loss: 0.386105
global_step: 19510, epoch: 88, loss: 0.375745
global_step: 19511, epoch: 88, loss: 0.387470
global_step: 19512, epoch: 88, loss: 0.379482
global_step: 19513, epoch: 88, loss: 0.388383
global_step: 19514, epoch: 88, loss: 0.427667
global_step: 19515, epoch: 88, loss: 0.333731
global_step: 19516, epoch: 88, loss: 0.344171
global_step: 19517, epoch: 88, loss: 0.333095
global_step: 19518, epoch: 88, loss: 0.370599
global_step: 19519, epoch: 88, loss: 0.448087
global_step: 19520, epoch: 88, loss: 0.021962
epoch: 88
train	acc: 0.9560	macro: p 0.9605, r 0.9174, f1: 0.9368	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9557
dev	acc: 0.5464	macro: p 0.4057, r 0.3209, f1: 0.3253	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5035
test	acc: 0.5828	macro: p 0.3526, r 0.3187, f1: 0.3254	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5497
global_step: 19521, epoch: 89, loss: 0.368634
global_step: 19522, epoch: 89, loss: 0.289906
global_step: 19523, epoch: 89, loss: 0.341413
global_step: 19524, epoch: 89, loss: 0.292689
global_step: 19525, epoch: 89, loss: 0.368205
global_step: 19526, epoch: 89, loss: 0.295873
global_step: 19527, epoch: 89, loss: 0.355103
global_step: 19528, epoch: 89, loss: 0.381982
global_step: 19529, epoch: 89, loss: 0.323333
global_step: 19530, epoch: 89, loss: 0.381368
global_step: 19531, epoch: 89, loss: 0.365959
global_step: 19532, epoch: 89, loss: 0.388073
global_step: 19533, epoch: 89, loss: 0.386525
global_step: 19534, epoch: 89, loss: 0.367806
global_step: 19535, epoch: 89, loss: 0.386612
global_step: 19536, epoch: 89, loss: 0.386336
global_step: 19537, epoch: 89, loss: 0.394298
global_step: 19538, epoch: 89, loss: 0.377630
global_step: 19539, epoch: 89, loss: 0.421717
global_step: 19540, epoch: 89, loss: 0.413701
global_step: 19541, epoch: 89, loss: 0.424478
global_step: 19542, epoch: 89, loss: 0.435499
global_step: 19543, epoch: 89, loss: 0.415163
global_step: 19544, epoch: 89, loss: 0.305053
global_step: 19545, epoch: 89, loss: 0.426477
global_step: 19546, epoch: 89, loss: 0.355854
global_step: 19547, epoch: 89, loss: 0.329317
global_step: 19548, epoch: 89, loss: 0.347178
global_step: 19549, epoch: 89, loss: 0.356733
global_step: 19550, epoch: 89, loss: 0.424859
global_step: 19551, epoch: 89, loss: 0.394741
global_step: 19552, epoch: 89, loss: 0.386793
global_step: 19553, epoch: 89, loss: 0.312521
global_step: 19554, epoch: 89, loss: 0.404329
global_step: 19555, epoch: 89, loss: 0.363676
global_step: 19556, epoch: 89, loss: 0.338642
global_step: 19557, epoch: 89, loss: 0.410358
global_step: 19558, epoch: 89, loss: 0.252056
global_step: 19559, epoch: 89, loss: 0.421979
global_step: 19560, epoch: 89, loss: 0.455367
epoch: 89
train	acc: 0.9526	macro: p 0.9551, r 0.9096, f1: 0.9296	micro: p 0.9526, r 0.9526, f1 0.9526	weighted_f1:0.9523
dev	acc: 0.5482	macro: p 0.4217, r 0.3294, f1: 0.3366	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5113
test	acc: 0.5789	macro: p 0.3514, r 0.3205, f1: 0.3261	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5493
global_step: 19561, epoch: 90, loss: 0.380434
global_step: 19562, epoch: 90, loss: 0.336152
global_step: 19563, epoch: 90, loss: 0.411417
global_step: 19564, epoch: 90, loss: 0.379045
global_step: 19565, epoch: 90, loss: 0.444708
global_step: 19566, epoch: 90, loss: 0.341973
global_step: 19567, epoch: 90, loss: 0.366869
global_step: 19568, epoch: 90, loss: 0.314089
global_step: 19569, epoch: 90, loss: 0.381093
global_step: 19570, epoch: 90, loss: 0.344033
global_step: 19571, epoch: 90, loss: 0.424585
global_step: 19572, epoch: 90, loss: 0.386729
global_step: 19573, epoch: 90, loss: 0.295921
global_step: 19574, epoch: 90, loss: 0.320020
global_step: 19575, epoch: 90, loss: 0.335493
global_step: 19576, epoch: 90, loss: 0.263321
global_step: 19577, epoch: 90, loss: 0.351195
global_step: 19578, epoch: 90, loss: 0.448211
global_step: 19579, epoch: 90, loss: 0.397850
global_step: 19580, epoch: 90, loss: 0.364591
global_step: 19581, epoch: 90, loss: 0.332477
global_step: 19582, epoch: 90, loss: 0.365264
global_step: 19583, epoch: 90, loss: 0.365222
global_step: 19584, epoch: 90, loss: 0.386358
global_step: 19585, epoch: 90, loss: 0.338290
global_step: 19586, epoch: 90, loss: 0.338564
global_step: 19587, epoch: 90, loss: 0.340191
global_step: 19588, epoch: 90, loss: 0.388764
global_step: 19589, epoch: 90, loss: 0.379521
global_step: 19590, epoch: 90, loss: 0.320643
global_step: 19591, epoch: 90, loss: 0.329895
global_step: 19592, epoch: 90, loss: 0.310725
global_step: 19593, epoch: 90, loss: 0.480862
global_step: 19594, epoch: 90, loss: 0.313561
global_step: 19595, epoch: 90, loss: 0.327421
global_step: 19596, epoch: 90, loss: 0.244595
global_step: 19597, epoch: 90, loss: 0.355286
global_step: 19598, epoch: 90, loss: 0.433231
global_step: 19599, epoch: 90, loss: 0.459189
global_step: 19600, epoch: 90, loss: 0.031511
epoch: 90
train	acc: 0.9541	macro: p 0.9582, r 0.9160, f1: 0.9350	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9540
dev	acc: 0.5482	macro: p 0.3687, r 0.3189, f1: 0.3185	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5050
test	acc: 0.5820	macro: p 0.3492, r 0.3225, f1: 0.3264	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5500
global_step: 19601, epoch: 91, loss: 0.344918
global_step: 19602, epoch: 91, loss: 0.332346
global_step: 19603, epoch: 91, loss: 0.342581
global_step: 19604, epoch: 91, loss: 0.376964
global_step: 19605, epoch: 91, loss: 0.339933
global_step: 19606, epoch: 91, loss: 0.337422
global_step: 19607, epoch: 91, loss: 0.332947
global_step: 19608, epoch: 91, loss: 0.305385
global_step: 19609, epoch: 91, loss: 0.468025
global_step: 19610, epoch: 91, loss: 0.333659
global_step: 19611, epoch: 91, loss: 0.329056
global_step: 19612, epoch: 91, loss: 0.333601
global_step: 19613, epoch: 91, loss: 0.299042
global_step: 19614, epoch: 91, loss: 0.331299
global_step: 19615, epoch: 91, loss: 0.450694
global_step: 19616, epoch: 91, loss: 0.343010
global_step: 19617, epoch: 91, loss: 0.301786
global_step: 19618, epoch: 91, loss: 0.306901
global_step: 19619, epoch: 91, loss: 0.311475
global_step: 19620, epoch: 91, loss: 0.395317
global_step: 19621, epoch: 91, loss: 0.465293
global_step: 19622, epoch: 91, loss: 0.420545
global_step: 19623, epoch: 91, loss: 0.334362
global_step: 19624, epoch: 91, loss: 0.394138
global_step: 19625, epoch: 91, loss: 0.432265
global_step: 19626, epoch: 91, loss: 0.396313
global_step: 19627, epoch: 91, loss: 0.328920
global_step: 19628, epoch: 91, loss: 0.404879
global_step: 19629, epoch: 91, loss: 0.303094
global_step: 19630, epoch: 91, loss: 0.351530
global_step: 19631, epoch: 91, loss: 0.327172
global_step: 19632, epoch: 91, loss: 0.308342
global_step: 19633, epoch: 91, loss: 0.363064
global_step: 19634, epoch: 91, loss: 0.331641
global_step: 19635, epoch: 91, loss: 0.481517
global_step: 19636, epoch: 91, loss: 0.372631
global_step: 19637, epoch: 91, loss: 0.376229
global_step: 19638, epoch: 91, loss: 0.431384
global_step: 19639, epoch: 91, loss: 0.380188
global_step: 19640, epoch: 91, loss: 0.845454
epoch: 91
train	acc: 0.9558	macro: p 0.9590, r 0.9277, f1: 0.9420	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9557
dev	acc: 0.5347	macro: p 0.3738, r 0.3335, f1: 0.3379	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.5106
test	acc: 0.5536	macro: p 0.3472, r 0.3258, f1: 0.3303	micro: p 0.5536, r 0.5536, f1 0.5536	weighted_f1:0.5380
global_step: 19641, epoch: 92, loss: 0.435311
global_step: 19642, epoch: 92, loss: 0.420103
global_step: 19643, epoch: 92, loss: 0.465495
global_step: 19644, epoch: 92, loss: 0.375472
global_step: 19645, epoch: 92, loss: 0.358224
global_step: 19646, epoch: 92, loss: 0.364395
global_step: 19647, epoch: 92, loss: 0.391678
global_step: 19648, epoch: 92, loss: 0.274365
global_step: 19649, epoch: 92, loss: 0.280139
global_step: 19650, epoch: 92, loss: 0.384066
global_step: 19651, epoch: 92, loss: 0.394591
global_step: 19652, epoch: 92, loss: 0.365758
global_step: 19653, epoch: 92, loss: 0.295138
global_step: 19654, epoch: 92, loss: 0.332248
global_step: 19655, epoch: 92, loss: 0.363717
global_step: 19656, epoch: 92, loss: 0.391271
global_step: 19657, epoch: 92, loss: 0.332263
global_step: 19658, epoch: 92, loss: 0.442934
global_step: 19659, epoch: 92, loss: 0.421722
global_step: 19660, epoch: 92, loss: 0.327237
global_step: 19661, epoch: 92, loss: 0.336581
global_step: 19662, epoch: 92, loss: 0.278586
global_step: 19663, epoch: 92, loss: 0.385455
global_step: 19664, epoch: 92, loss: 0.342242
global_step: 19665, epoch: 92, loss: 0.409454
global_step: 19666, epoch: 92, loss: 0.457652
global_step: 19667, epoch: 92, loss: 0.357128
global_step: 19668, epoch: 92, loss: 0.306911
global_step: 19669, epoch: 92, loss: 0.346636
global_step: 19670, epoch: 92, loss: 0.335376
global_step: 19671, epoch: 92, loss: 0.420010
global_step: 19672, epoch: 92, loss: 0.321483
global_step: 19673, epoch: 92, loss: 0.332056
global_step: 19674, epoch: 92, loss: 0.306477
global_step: 19675, epoch: 92, loss: 0.323077
global_step: 19676, epoch: 92, loss: 0.321791
global_step: 19677, epoch: 92, loss: 0.412845
global_step: 19678, epoch: 92, loss: 0.372168
global_step: 19679, epoch: 92, loss: 0.338317
global_step: 19680, epoch: 92, loss: 0.520663
epoch: 92
train	acc: 0.9560	macro: p 0.9598, r 0.9210, f1: 0.9387	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9558
dev	acc: 0.5428	macro: p 0.3817, r 0.3169, f1: 0.3189	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4987
test	acc: 0.5801	macro: p 0.3574, r 0.3140, f1: 0.3205	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5471
global_step: 19681, epoch: 93, loss: 0.357217
global_step: 19682, epoch: 93, loss: 0.377115
global_step: 19683, epoch: 93, loss: 0.361955
global_step: 19684, epoch: 93, loss: 0.372632
global_step: 19685, epoch: 93, loss: 0.354534
global_step: 19686, epoch: 93, loss: 0.388841
global_step: 19687, epoch: 93, loss: 0.357943
global_step: 19688, epoch: 93, loss: 0.405697
global_step: 19689, epoch: 93, loss: 0.323927
global_step: 19690, epoch: 93, loss: 0.273612
global_step: 19691, epoch: 93, loss: 0.328943
global_step: 19692, epoch: 93, loss: 0.458888
global_step: 19693, epoch: 93, loss: 0.339414
global_step: 19694, epoch: 93, loss: 0.333176
global_step: 19695, epoch: 93, loss: 0.310518
global_step: 19696, epoch: 93, loss: 0.273857
global_step: 19697, epoch: 93, loss: 0.321327
global_step: 19698, epoch: 93, loss: 0.311228
global_step: 19699, epoch: 93, loss: 0.356065
global_step: 19700, epoch: 93, loss: 0.363632
global_step: 19701, epoch: 93, loss: 0.335528
global_step: 19702, epoch: 93, loss: 0.304444
global_step: 19703, epoch: 93, loss: 0.353530
global_step: 19704, epoch: 93, loss: 0.379275
global_step: 19705, epoch: 93, loss: 0.338518
global_step: 19706, epoch: 93, loss: 0.394153
global_step: 19707, epoch: 93, loss: 0.315012
global_step: 19708, epoch: 93, loss: 0.397964
global_step: 19709, epoch: 93, loss: 0.369284
global_step: 19710, epoch: 93, loss: 0.355805
global_step: 19711, epoch: 93, loss: 0.311049
global_step: 19712, epoch: 93, loss: 0.361671
global_step: 19713, epoch: 93, loss: 0.387427
global_step: 19714, epoch: 93, loss: 0.344561
global_step: 19715, epoch: 93, loss: 0.311707
global_step: 19716, epoch: 93, loss: 0.374045
global_step: 19717, epoch: 93, loss: 0.365542
global_step: 19718, epoch: 93, loss: 0.348393
global_step: 19719, epoch: 93, loss: 0.330302
global_step: 19720, epoch: 93, loss: 0.416405
epoch: 93
train	acc: 0.9551	macro: p 0.9607, r 0.9189, f1: 0.9378	micro: p 0.9551, r 0.9551, f1 0.9551	weighted_f1:0.9549
dev	acc: 0.5500	macro: p 0.3805, r 0.3151, f1: 0.3119	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5008
test	acc: 0.5897	macro: p 0.3494, r 0.3210, f1: 0.3229	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5516
global_step: 19721, epoch: 94, loss: 0.380864
global_step: 19722, epoch: 94, loss: 0.339523
global_step: 19723, epoch: 94, loss: 0.388373
global_step: 19724, epoch: 94, loss: 0.340844
global_step: 19725, epoch: 94, loss: 0.306489
global_step: 19726, epoch: 94, loss: 0.340356
global_step: 19727, epoch: 94, loss: 0.322207
global_step: 19728, epoch: 94, loss: 0.301952
global_step: 19729, epoch: 94, loss: 0.264431
global_step: 19730, epoch: 94, loss: 0.353759
global_step: 19731, epoch: 94, loss: 0.368431
global_step: 19732, epoch: 94, loss: 0.366924
global_step: 19733, epoch: 94, loss: 0.370007
global_step: 19734, epoch: 94, loss: 0.385121
global_step: 19735, epoch: 94, loss: 0.343238
global_step: 19736, epoch: 94, loss: 0.335418
global_step: 19737, epoch: 94, loss: 0.386157
global_step: 19738, epoch: 94, loss: 0.399530
global_step: 19739, epoch: 94, loss: 0.304263
global_step: 19740, epoch: 94, loss: 0.253975
global_step: 19741, epoch: 94, loss: 0.381015
global_step: 19742, epoch: 94, loss: 0.336424
global_step: 19743, epoch: 94, loss: 0.367578
global_step: 19744, epoch: 94, loss: 0.366601
global_step: 19745, epoch: 94, loss: 0.311448
global_step: 19746, epoch: 94, loss: 0.326120
global_step: 19747, epoch: 94, loss: 0.408615
global_step: 19748, epoch: 94, loss: 0.363132
global_step: 19749, epoch: 94, loss: 0.359622
global_step: 19750, epoch: 94, loss: 0.331863
global_step: 19751, epoch: 94, loss: 0.298319
global_step: 19752, epoch: 94, loss: 0.349512
global_step: 19753, epoch: 94, loss: 0.384100
global_step: 19754, epoch: 94, loss: 0.382968
global_step: 19755, epoch: 94, loss: 0.339350
global_step: 19756, epoch: 94, loss: 0.355053
global_step: 19757, epoch: 94, loss: 0.340021
global_step: 19758, epoch: 94, loss: 0.443527
global_step: 19759, epoch: 94, loss: 0.333825
global_step: 19760, epoch: 94, loss: 0.784648
epoch: 94
train	acc: 0.9550	macro: p 0.9618, r 0.9175, f1: 0.9377	micro: p 0.9550, r 0.9550, f1 0.9550	weighted_f1:0.9547
dev	acc: 0.5518	macro: p 0.3721, r 0.3134, f1: 0.3139	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5017
test	acc: 0.5824	macro: p 0.3433, r 0.3075, f1: 0.3129	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5421
global_step: 19761, epoch: 95, loss: 0.350644
global_step: 19762, epoch: 95, loss: 0.390416
global_step: 19763, epoch: 95, loss: 0.371970
global_step: 19764, epoch: 95, loss: 0.299189
global_step: 19765, epoch: 95, loss: 0.285499
global_step: 19766, epoch: 95, loss: 0.327977
global_step: 19767, epoch: 95, loss: 0.313554
global_step: 19768, epoch: 95, loss: 0.403746
global_step: 19769, epoch: 95, loss: 0.351019
global_step: 19770, epoch: 95, loss: 0.379487
global_step: 19771, epoch: 95, loss: 0.385689
global_step: 19772, epoch: 95, loss: 0.340651
global_step: 19773, epoch: 95, loss: 0.313887
global_step: 19774, epoch: 95, loss: 0.302610
global_step: 19775, epoch: 95, loss: 0.407219
global_step: 19776, epoch: 95, loss: 0.382339
global_step: 19777, epoch: 95, loss: 0.288888
global_step: 19778, epoch: 95, loss: 0.388956
global_step: 19779, epoch: 95, loss: 0.362357
global_step: 19780, epoch: 95, loss: 0.311764
global_step: 19781, epoch: 95, loss: 0.351703
global_step: 19782, epoch: 95, loss: 0.328013
global_step: 19783, epoch: 95, loss: 0.328809
global_step: 19784, epoch: 95, loss: 0.441203
global_step: 19785, epoch: 95, loss: 0.330195
global_step: 19786, epoch: 95, loss: 0.424641
global_step: 19787, epoch: 95, loss: 0.302996
global_step: 19788, epoch: 95, loss: 0.355328
global_step: 19789, epoch: 95, loss: 0.307060
global_step: 19790, epoch: 95, loss: 0.330251
global_step: 19791, epoch: 95, loss: 0.322005
global_step: 19792, epoch: 95, loss: 0.368722
global_step: 19793, epoch: 95, loss: 0.330655
global_step: 19794, epoch: 95, loss: 0.266479
global_step: 19795, epoch: 95, loss: 0.339329
global_step: 19796, epoch: 95, loss: 0.324973
global_step: 19797, epoch: 95, loss: 0.326984
global_step: 19798, epoch: 95, loss: 0.369146
global_step: 19799, epoch: 95, loss: 0.337181
global_step: 19800, epoch: 95, loss: 1.552446
epoch: 95
train	acc: 0.9558	macro: p 0.9625, r 0.9182, f1: 0.9382	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9555
dev	acc: 0.5509	macro: p 0.3629, r 0.3148, f1: 0.3128	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5043
test	acc: 0.5824	macro: p 0.3572, r 0.3182, f1: 0.3241	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5493
global_step: 19801, epoch: 96, loss: 0.340148
global_step: 19802, epoch: 96, loss: 0.457037
global_step: 19803, epoch: 96, loss: 0.332470
global_step: 19804, epoch: 96, loss: 0.361981
global_step: 19805, epoch: 96, loss: 0.277641
global_step: 19806, epoch: 96, loss: 0.329877
global_step: 19807, epoch: 96, loss: 0.328019
global_step: 19808, epoch: 96, loss: 0.369254
global_step: 19809, epoch: 96, loss: 0.346482
global_step: 19810, epoch: 96, loss: 0.301576
global_step: 19811, epoch: 96, loss: 0.321742
global_step: 19812, epoch: 96, loss: 0.360645
global_step: 19813, epoch: 96, loss: 0.373096
global_step: 19814, epoch: 96, loss: 0.311430
global_step: 19815, epoch: 96, loss: 0.375969
global_step: 19816, epoch: 96, loss: 0.362728
global_step: 19817, epoch: 96, loss: 0.286186
global_step: 19818, epoch: 96, loss: 0.364471
global_step: 19819, epoch: 96, loss: 0.404127
global_step: 19820, epoch: 96, loss: 0.281163
global_step: 19821, epoch: 96, loss: 0.425516
global_step: 19822, epoch: 96, loss: 0.308971
global_step: 19823, epoch: 96, loss: 0.259577
global_step: 19824, epoch: 96, loss: 0.311814
global_step: 19825, epoch: 96, loss: 0.293452
global_step: 19826, epoch: 96, loss: 0.258622
global_step: 19827, epoch: 96, loss: 0.325266
global_step: 19828, epoch: 96, loss: 0.371006
global_step: 19829, epoch: 96, loss: 0.325833
global_step: 19830, epoch: 96, loss: 0.346994
global_step: 19831, epoch: 96, loss: 0.364733
global_step: 19832, epoch: 96, loss: 0.341435
global_step: 19833, epoch: 96, loss: 0.330191
global_step: 19834, epoch: 96, loss: 0.399336
global_step: 19835, epoch: 96, loss: 0.378152
global_step: 19836, epoch: 96, loss: 0.391715
global_step: 19837, epoch: 96, loss: 0.337645
global_step: 19838, epoch: 96, loss: 0.308060
global_step: 19839, epoch: 96, loss: 0.365068
global_step: 19840, epoch: 96, loss: 0.617511
epoch: 96
train	acc: 0.9551	macro: p 0.9625, r 0.9198, f1: 0.9391	micro: p 0.9551, r 0.9551, f1 0.9551	weighted_f1:0.9549
dev	acc: 0.5464	macro: p 0.3932, r 0.3162, f1: 0.3141	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4966
test	acc: 0.5835	macro: p 0.3635, r 0.3143, f1: 0.3190	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5440
global_step: 19841, epoch: 97, loss: 0.321174
global_step: 19842, epoch: 97, loss: 0.337699
global_step: 19843, epoch: 97, loss: 0.228664
global_step: 19844, epoch: 97, loss: 0.387781
global_step: 19845, epoch: 97, loss: 0.217657
global_step: 19846, epoch: 97, loss: 0.324808
global_step: 19847, epoch: 97, loss: 0.317527
global_step: 19848, epoch: 97, loss: 0.373885
global_step: 19849, epoch: 97, loss: 0.285529
global_step: 19850, epoch: 97, loss: 0.310177
global_step: 19851, epoch: 97, loss: 0.290269
global_step: 19852, epoch: 97, loss: 0.270292
global_step: 19853, epoch: 97, loss: 0.324174
global_step: 19854, epoch: 97, loss: 0.367181
global_step: 19855, epoch: 97, loss: 0.287706
global_step: 19856, epoch: 97, loss: 0.294352
global_step: 19857, epoch: 97, loss: 0.350283
global_step: 19858, epoch: 97, loss: 0.345050
global_step: 19859, epoch: 97, loss: 0.293078
global_step: 19860, epoch: 97, loss: 0.396227
global_step: 19861, epoch: 97, loss: 0.385160
global_step: 19862, epoch: 97, loss: 0.312953
global_step: 19863, epoch: 97, loss: 0.416567
global_step: 19864, epoch: 97, loss: 0.349601
global_step: 19865, epoch: 97, loss: 0.377716
global_step: 19866, epoch: 97, loss: 0.315460
global_step: 19867, epoch: 97, loss: 0.422806
global_step: 19868, epoch: 97, loss: 0.305260
global_step: 19869, epoch: 97, loss: 0.293061
global_step: 19870, epoch: 97, loss: 0.276869
global_step: 19871, epoch: 97, loss: 0.385884
global_step: 19872, epoch: 97, loss: 0.308102
global_step: 19873, epoch: 97, loss: 0.346548
global_step: 19874, epoch: 97, loss: 0.382869
global_step: 19875, epoch: 97, loss: 0.289670
global_step: 19876, epoch: 97, loss: 0.273217
global_step: 19877, epoch: 97, loss: 0.312034
global_step: 19878, epoch: 97, loss: 0.328221
global_step: 19879, epoch: 97, loss: 0.275969
global_step: 19880, epoch: 97, loss: 0.341335
epoch: 97
train	acc: 0.9533	macro: p 0.9621, r 0.9173, f1: 0.9378	micro: p 0.9533, r 0.9533, f1 0.9533	weighted_f1:0.9532
dev	acc: 0.5546	macro: p 0.3841, r 0.3143, f1: 0.3117	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5023
test	acc: 0.5874	macro: p 0.3726, r 0.3129, f1: 0.3201	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5447
global_step: 19881, epoch: 98, loss: 0.397929
global_step: 19882, epoch: 98, loss: 0.311899
global_step: 19883, epoch: 98, loss: 0.343874
global_step: 19884, epoch: 98, loss: 0.279294
global_step: 19885, epoch: 98, loss: 0.233470
global_step: 19886, epoch: 98, loss: 0.347782
global_step: 19887, epoch: 98, loss: 0.296215
global_step: 19888, epoch: 98, loss: 0.283825
global_step: 19889, epoch: 98, loss: 0.361823
global_step: 19890, epoch: 98, loss: 0.397845
global_step: 19891, epoch: 98, loss: 0.361703
global_step: 19892, epoch: 98, loss: 0.354624
global_step: 19893, epoch: 98, loss: 0.199599
global_step: 19894, epoch: 98, loss: 0.289035
global_step: 19895, epoch: 98, loss: 0.414258
global_step: 19896, epoch: 98, loss: 0.408364
global_step: 19897, epoch: 98, loss: 0.220511
global_step: 19898, epoch: 98, loss: 0.290607
global_step: 19899, epoch: 98, loss: 0.367089
global_step: 19900, epoch: 98, loss: 0.356961
global_step: 19901, epoch: 98, loss: 0.341363
global_step: 19902, epoch: 98, loss: 0.356071
global_step: 19903, epoch: 98, loss: 0.350550
global_step: 19904, epoch: 98, loss: 0.356059
global_step: 19905, epoch: 98, loss: 0.270107
global_step: 19906, epoch: 98, loss: 0.306952
global_step: 19907, epoch: 98, loss: 0.340856
global_step: 19908, epoch: 98, loss: 0.273427
global_step: 19909, epoch: 98, loss: 0.324936
global_step: 19910, epoch: 98, loss: 0.290916
global_step: 19911, epoch: 98, loss: 0.356625
global_step: 19912, epoch: 98, loss: 0.341136
global_step: 19913, epoch: 98, loss: 0.347279
global_step: 19914, epoch: 98, loss: 0.288202
global_step: 19915, epoch: 98, loss: 0.334257
global_step: 19916, epoch: 98, loss: 0.418744
global_step: 19917, epoch: 98, loss: 0.366331
global_step: 19918, epoch: 98, loss: 0.353460
global_step: 19919, epoch: 98, loss: 0.389576
global_step: 19920, epoch: 98, loss: 0.218390
epoch: 98
train	acc: 0.9582	macro: p 0.9639, r 0.9285, f1: 0.9449	micro: p 0.9582, r 0.9582, f1 0.9582	weighted_f1:0.9581
dev	acc: 0.5455	macro: p 0.3562, r 0.3131, f1: 0.3110	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4996
test	acc: 0.5785	macro: p 0.3608, r 0.3204, f1: 0.3272	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5451
global_step: 19921, epoch: 99, loss: 0.314987
global_step: 19922, epoch: 99, loss: 0.286808
global_step: 19923, epoch: 99, loss: 0.301842
global_step: 19924, epoch: 99, loss: 0.409351
global_step: 19925, epoch: 99, loss: 0.354463
global_step: 19926, epoch: 99, loss: 0.293155
global_step: 19927, epoch: 99, loss: 0.343829
global_step: 19928, epoch: 99, loss: 0.268122
global_step: 19929, epoch: 99, loss: 0.287498
global_step: 19930, epoch: 99, loss: 0.285594
global_step: 19931, epoch: 99, loss: 0.285967
global_step: 19932, epoch: 99, loss: 0.279335
global_step: 19933, epoch: 99, loss: 0.355197
global_step: 19934, epoch: 99, loss: 0.227646
global_step: 19935, epoch: 99, loss: 0.316778
global_step: 19936, epoch: 99, loss: 0.272951
global_step: 19937, epoch: 99, loss: 0.328508
global_step: 19938, epoch: 99, loss: 0.273372
global_step: 19939, epoch: 99, loss: 0.335858
global_step: 19940, epoch: 99, loss: 0.329045
global_step: 19941, epoch: 99, loss: 0.337164
global_step: 19942, epoch: 99, loss: 0.301776
global_step: 19943, epoch: 99, loss: 0.341454
global_step: 19944, epoch: 99, loss: 0.317580
global_step: 19945, epoch: 99, loss: 0.340775
global_step: 19946, epoch: 99, loss: 0.248687
global_step: 19947, epoch: 99, loss: 0.303330
global_step: 19948, epoch: 99, loss: 0.335933
global_step: 19949, epoch: 99, loss: 0.346320
global_step: 19950, epoch: 99, loss: 0.331061
global_step: 19951, epoch: 99, loss: 0.340254
global_step: 19952, epoch: 99, loss: 0.376690
global_step: 19953, epoch: 99, loss: 0.322789
global_step: 19954, epoch: 99, loss: 0.323048
global_step: 19955, epoch: 99, loss: 0.305912
global_step: 19956, epoch: 99, loss: 0.353475
global_step: 19957, epoch: 99, loss: 0.312215
global_step: 19958, epoch: 99, loss: 0.339232
global_step: 19959, epoch: 99, loss: 0.381301
global_step: 19960, epoch: 99, loss: 0.920681
epoch: 99
train	acc: 0.9591	macro: p 0.9652, r 0.9284, f1: 0.9454	micro: p 0.9591, r 0.9591, f1 0.9591	weighted_f1:0.9589
dev	acc: 0.5473	macro: p 0.3818, r 0.3165, f1: 0.3211	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5025
test	acc: 0.5862	macro: p 0.3573, r 0.3171, f1: 0.3262	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5501
global_step: 19961, epoch: 100, loss: 0.318503
global_step: 19962, epoch: 100, loss: 0.267002
global_step: 19963, epoch: 100, loss: 0.309885
global_step: 19964, epoch: 100, loss: 0.340010
global_step: 19965, epoch: 100, loss: 0.292599
global_step: 19966, epoch: 100, loss: 0.303925
global_step: 19967, epoch: 100, loss: 0.448771
global_step: 19968, epoch: 100, loss: 0.283931
global_step: 19969, epoch: 100, loss: 0.243284
global_step: 19970, epoch: 100, loss: 0.275566
global_step: 19971, epoch: 100, loss: 0.329938
global_step: 19972, epoch: 100, loss: 0.318061
global_step: 19973, epoch: 100, loss: 0.335858
global_step: 19974, epoch: 100, loss: 0.248031
global_step: 19975, epoch: 100, loss: 0.342785
global_step: 19976, epoch: 100, loss: 0.308239
global_step: 19977, epoch: 100, loss: 0.327419
global_step: 19978, epoch: 100, loss: 0.349080
global_step: 19979, epoch: 100, loss: 0.381888
global_step: 19980, epoch: 100, loss: 0.415648
global_step: 19981, epoch: 100, loss: 0.327609
global_step: 19982, epoch: 100, loss: 0.368709
global_step: 19983, epoch: 100, loss: 0.328892
global_step: 19984, epoch: 100, loss: 0.338161
global_step: 19985, epoch: 100, loss: 0.316301
global_step: 19986, epoch: 100, loss: 0.260683
global_step: 19987, epoch: 100, loss: 0.281516
global_step: 19988, epoch: 100, loss: 0.325755
global_step: 19989, epoch: 100, loss: 0.363051
global_step: 19990, epoch: 100, loss: 0.378230
global_step: 19991, epoch: 100, loss: 0.342591
global_step: 19992, epoch: 100, loss: 0.322766
global_step: 19993, epoch: 100, loss: 0.256135
global_step: 19994, epoch: 100, loss: 0.326952
global_step: 19995, epoch: 100, loss: 0.311946
global_step: 19996, epoch: 100, loss: 0.267848
global_step: 19997, epoch: 100, loss: 0.332153
global_step: 19998, epoch: 100, loss: 0.331929
global_step: 19999, epoch: 100, loss: 0.360747
global_step: 20000, epoch: 100, loss: 0.954416
epoch: 100
train	acc: 0.9583	macro: p 0.9650, r 0.9288, f1: 0.9456	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9581
dev	acc: 0.5482	macro: p 0.3947, r 0.3221, f1: 0.3260	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5032
test	acc: 0.5801	macro: p 0.3566, r 0.3150, f1: 0.3230	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5446
global_step: 20001, epoch: 101, loss: 0.326986
global_step: 20002, epoch: 101, loss: 0.302921
global_step: 20003, epoch: 101, loss: 0.278430
global_step: 20004, epoch: 101, loss: 0.327850
global_step: 20005, epoch: 101, loss: 0.395175
global_step: 20006, epoch: 101, loss: 0.272267
global_step: 20007, epoch: 101, loss: 0.295321
global_step: 20008, epoch: 101, loss: 0.335860
global_step: 20009, epoch: 101, loss: 0.270191
global_step: 20010, epoch: 101, loss: 0.292952
global_step: 20011, epoch: 101, loss: 0.329219
global_step: 20012, epoch: 101, loss: 0.330692
global_step: 20013, epoch: 101, loss: 0.288528
global_step: 20014, epoch: 101, loss: 0.333784
global_step: 20015, epoch: 101, loss: 0.306850
global_step: 20016, epoch: 101, loss: 0.300482
global_step: 20017, epoch: 101, loss: 0.272951
global_step: 20018, epoch: 101, loss: 0.357032
global_step: 20019, epoch: 101, loss: 0.385031
global_step: 20020, epoch: 101, loss: 0.416312
global_step: 20021, epoch: 101, loss: 0.282050
global_step: 20022, epoch: 101, loss: 0.354867
global_step: 20023, epoch: 101, loss: 0.364391
global_step: 20024, epoch: 101, loss: 0.344020
global_step: 20025, epoch: 101, loss: 0.299089
global_step: 20026, epoch: 101, loss: 0.352581
global_step: 20027, epoch: 101, loss: 0.293118
global_step: 20028, epoch: 101, loss: 0.318216
global_step: 20029, epoch: 101, loss: 0.345391
global_step: 20030, epoch: 101, loss: 0.345022
global_step: 20031, epoch: 101, loss: 0.382452
global_step: 20032, epoch: 101, loss: 0.267928
global_step: 20033, epoch: 101, loss: 0.345053
global_step: 20034, epoch: 101, loss: 0.399279
global_step: 20035, epoch: 101, loss: 0.369168
global_step: 20036, epoch: 101, loss: 0.379203
global_step: 20037, epoch: 101, loss: 0.311527
global_step: 20038, epoch: 101, loss: 0.323265
global_step: 20039, epoch: 101, loss: 0.344410
global_step: 20040, epoch: 101, loss: 0.533562
epoch: 101
train	acc: 0.9590	macro: p 0.9661, r 0.9324, f1: 0.9482	micro: p 0.9590, r 0.9590, f1 0.9590	weighted_f1:0.9589
dev	acc: 0.5464	macro: p 0.3850, r 0.3174, f1: 0.3224	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5001
test	acc: 0.5812	macro: p 0.3631, r 0.3130, f1: 0.3236	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5419
global_step: 20041, epoch: 102, loss: 0.356804
global_step: 20042, epoch: 102, loss: 0.367722
global_step: 20043, epoch: 102, loss: 0.244959
global_step: 20044, epoch: 102, loss: 0.310427
global_step: 20045, epoch: 102, loss: 0.270043
global_step: 20046, epoch: 102, loss: 0.369955
global_step: 20047, epoch: 102, loss: 0.309040
global_step: 20048, epoch: 102, loss: 0.296926
global_step: 20049, epoch: 102, loss: 0.324737
global_step: 20050, epoch: 102, loss: 0.269460
global_step: 20051, epoch: 102, loss: 0.345009
global_step: 20052, epoch: 102, loss: 0.359042
global_step: 20053, epoch: 102, loss: 0.321524
global_step: 20054, epoch: 102, loss: 0.276177
global_step: 20055, epoch: 102, loss: 0.326986
global_step: 20056, epoch: 102, loss: 0.346849
global_step: 20057, epoch: 102, loss: 0.331714
global_step: 20058, epoch: 102, loss: 0.289553
global_step: 20059, epoch: 102, loss: 0.249062
global_step: 20060, epoch: 102, loss: 0.309307
global_step: 20061, epoch: 102, loss: 0.434916
global_step: 20062, epoch: 102, loss: 0.290280
global_step: 20063, epoch: 102, loss: 0.303152
global_step: 20064, epoch: 102, loss: 0.332912
global_step: 20065, epoch: 102, loss: 0.243192
global_step: 20066, epoch: 102, loss: 0.342487
global_step: 20067, epoch: 102, loss: 0.272893
global_step: 20068, epoch: 102, loss: 0.324102
global_step: 20069, epoch: 102, loss: 0.299797
global_step: 20070, epoch: 102, loss: 0.300148
global_step: 20071, epoch: 102, loss: 0.407644
global_step: 20072, epoch: 102, loss: 0.286457
global_step: 20073, epoch: 102, loss: 0.365731
global_step: 20074, epoch: 102, loss: 0.309730
global_step: 20075, epoch: 102, loss: 0.389183
global_step: 20076, epoch: 102, loss: 0.353487
global_step: 20077, epoch: 102, loss: 0.368438
global_step: 20078, epoch: 102, loss: 0.248809
global_step: 20079, epoch: 102, loss: 0.427197
global_step: 20080, epoch: 102, loss: 0.196338
epoch: 102
train	acc: 0.9603	macro: p 0.9685, r 0.9335, f1: 0.9499	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9602
dev	acc: 0.5464	macro: p 0.3730, r 0.3099, f1: 0.3086	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4974
test	acc: 0.5831	macro: p 0.3509, r 0.3115, f1: 0.3175	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5447
global_step: 20081, epoch: 103, loss: 0.329946
global_step: 20082, epoch: 103, loss: 0.304574
global_step: 20083, epoch: 103, loss: 0.319808
global_step: 20084, epoch: 103, loss: 0.270110
global_step: 20085, epoch: 103, loss: 0.293351
global_step: 20086, epoch: 103, loss: 0.324561
global_step: 20087, epoch: 103, loss: 0.312482
global_step: 20088, epoch: 103, loss: 0.303105
global_step: 20089, epoch: 103, loss: 0.264762
global_step: 20090, epoch: 103, loss: 0.321688
global_step: 20091, epoch: 103, loss: 0.287087
global_step: 20092, epoch: 103, loss: 0.302347
global_step: 20093, epoch: 103, loss: 0.348071
global_step: 20094, epoch: 103, loss: 0.365056
global_step: 20095, epoch: 103, loss: 0.279144
global_step: 20096, epoch: 103, loss: 0.272423
global_step: 20097, epoch: 103, loss: 0.349795
global_step: 20098, epoch: 103, loss: 0.340486
global_step: 20099, epoch: 103, loss: 0.366617
global_step: 20100, epoch: 103, loss: 0.359316
global_step: 20101, epoch: 103, loss: 0.388046
global_step: 20102, epoch: 103, loss: 0.309672
global_step: 20103, epoch: 103, loss: 0.289904
global_step: 20104, epoch: 103, loss: 0.281924
global_step: 20105, epoch: 103, loss: 0.298532
global_step: 20106, epoch: 103, loss: 0.290795
global_step: 20107, epoch: 103, loss: 0.312549
global_step: 20108, epoch: 103, loss: 0.281151
global_step: 20109, epoch: 103, loss: 0.256517
global_step: 20110, epoch: 103, loss: 0.293900
global_step: 20111, epoch: 103, loss: 0.268445
global_step: 20112, epoch: 103, loss: 0.369550
global_step: 20113, epoch: 103, loss: 0.300489
global_step: 20114, epoch: 103, loss: 0.307021
global_step: 20115, epoch: 103, loss: 0.365799
global_step: 20116, epoch: 103, loss: 0.343316
global_step: 20117, epoch: 103, loss: 0.342831
global_step: 20118, epoch: 103, loss: 0.321233
global_step: 20119, epoch: 103, loss: 0.335510
global_step: 20120, epoch: 103, loss: 0.034868
epoch: 103
train	acc: 0.9594	macro: p 0.9655, r 0.9302, f1: 0.9466	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9593
dev	acc: 0.5410	macro: p 0.3585, r 0.3075, f1: 0.3024	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4908
test	acc: 0.5854	macro: p 0.3652, r 0.3160, f1: 0.3218	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5458
global_step: 20121, epoch: 104, loss: 0.267059
global_step: 20122, epoch: 104, loss: 0.340610
global_step: 20123, epoch: 104, loss: 0.279332
global_step: 20124, epoch: 104, loss: 0.299654
global_step: 20125, epoch: 104, loss: 0.282543
global_step: 20126, epoch: 104, loss: 0.375215
global_step: 20127, epoch: 104, loss: 0.230189
global_step: 20128, epoch: 104, loss: 0.304675
global_step: 20129, epoch: 104, loss: 0.337702
global_step: 20130, epoch: 104, loss: 0.281626
global_step: 20131, epoch: 104, loss: 0.297851
global_step: 20132, epoch: 104, loss: 0.324505
global_step: 20133, epoch: 104, loss: 0.384424
global_step: 20134, epoch: 104, loss: 0.269084
global_step: 20135, epoch: 104, loss: 0.317199
global_step: 20136, epoch: 104, loss: 0.296717
global_step: 20137, epoch: 104, loss: 0.355907
global_step: 20138, epoch: 104, loss: 0.305701
global_step: 20139, epoch: 104, loss: 0.309401
global_step: 20140, epoch: 104, loss: 0.402534
global_step: 20141, epoch: 104, loss: 0.318075
global_step: 20142, epoch: 104, loss: 0.308948
global_step: 20143, epoch: 104, loss: 0.333331
global_step: 20144, epoch: 104, loss: 0.270015
global_step: 20145, epoch: 104, loss: 0.278938
global_step: 20146, epoch: 104, loss: 0.356363
global_step: 20147, epoch: 104, loss: 0.343362
global_step: 20148, epoch: 104, loss: 0.330545
global_step: 20149, epoch: 104, loss: 0.282109
global_step: 20150, epoch: 104, loss: 0.286153
global_step: 20151, epoch: 104, loss: 0.314497
global_step: 20152, epoch: 104, loss: 0.217821
global_step: 20153, epoch: 104, loss: 0.291061
global_step: 20154, epoch: 104, loss: 0.316535
global_step: 20155, epoch: 104, loss: 0.402527
global_step: 20156, epoch: 104, loss: 0.296006
global_step: 20157, epoch: 104, loss: 0.282492
global_step: 20158, epoch: 104, loss: 0.312544
global_step: 20159, epoch: 104, loss: 0.385216
global_step: 20160, epoch: 104, loss: 0.147356
epoch: 104
train	acc: 0.9604	macro: p 0.9651, r 0.9350, f1: 0.9491	micro: p 0.9604, r 0.9604, f1 0.9604	weighted_f1:0.9603
dev	acc: 0.5383	macro: p 0.3609, r 0.3101, f1: 0.3061	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4929
test	acc: 0.5782	macro: p 0.3652, r 0.3228, f1: 0.3286	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5450
global_step: 20161, epoch: 105, loss: 0.381519
global_step: 20162, epoch: 105, loss: 0.285316
global_step: 20163, epoch: 105, loss: 0.318087
global_step: 20164, epoch: 105, loss: 0.304879
global_step: 20165, epoch: 105, loss: 0.305112
global_step: 20166, epoch: 105, loss: 0.350915
global_step: 20167, epoch: 105, loss: 0.268405
global_step: 20168, epoch: 105, loss: 0.297882
global_step: 20169, epoch: 105, loss: 0.289547
global_step: 20170, epoch: 105, loss: 0.319427
global_step: 20171, epoch: 105, loss: 0.341816
global_step: 20172, epoch: 105, loss: 0.328790
global_step: 20173, epoch: 105, loss: 0.264466
global_step: 20174, epoch: 105, loss: 0.369383
global_step: 20175, epoch: 105, loss: 0.349482
global_step: 20176, epoch: 105, loss: 0.254542
global_step: 20177, epoch: 105, loss: 0.285965
global_step: 20178, epoch: 105, loss: 0.383938
global_step: 20179, epoch: 105, loss: 0.323497
global_step: 20180, epoch: 105, loss: 0.312740
global_step: 20181, epoch: 105, loss: 0.303814
global_step: 20182, epoch: 105, loss: 0.403204
global_step: 20183, epoch: 105, loss: 0.384184
global_step: 20184, epoch: 105, loss: 0.303888
global_step: 20185, epoch: 105, loss: 0.320452
global_step: 20186, epoch: 105, loss: 0.273764
global_step: 20187, epoch: 105, loss: 0.377674
global_step: 20188, epoch: 105, loss: 0.307641
global_step: 20189, epoch: 105, loss: 0.309610
global_step: 20190, epoch: 105, loss: 0.282447
global_step: 20191, epoch: 105, loss: 0.299900
global_step: 20192, epoch: 105, loss: 0.303428
global_step: 20193, epoch: 105, loss: 0.273976
global_step: 20194, epoch: 105, loss: 0.300746
global_step: 20195, epoch: 105, loss: 0.278755
global_step: 20196, epoch: 105, loss: 0.293876
global_step: 20197, epoch: 105, loss: 0.359858
global_step: 20198, epoch: 105, loss: 0.350858
global_step: 20199, epoch: 105, loss: 0.326936
global_step: 20200, epoch: 105, loss: 0.254388
epoch: 105
train	acc: 0.9598	macro: p 0.9654, r 0.9316, f1: 0.9473	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9597
dev	acc: 0.5365	macro: p 0.3523, r 0.3051, f1: 0.3053	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4916
test	acc: 0.5866	macro: p 0.3836, r 0.3234, f1: 0.3344	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5518
global_step: 20201, epoch: 106, loss: 0.258889
global_step: 20202, epoch: 106, loss: 0.310174
global_step: 20203, epoch: 106, loss: 0.322622
global_step: 20204, epoch: 106, loss: 0.271759
global_step: 20205, epoch: 106, loss: 0.294462
global_step: 20206, epoch: 106, loss: 0.357861
global_step: 20207, epoch: 106, loss: 0.381139
global_step: 20208, epoch: 106, loss: 0.343818
global_step: 20209, epoch: 106, loss: 0.270813
global_step: 20210, epoch: 106, loss: 0.266131
global_step: 20211, epoch: 106, loss: 0.240827
global_step: 20212, epoch: 106, loss: 0.309228
global_step: 20213, epoch: 106, loss: 0.261289
global_step: 20214, epoch: 106, loss: 0.266782
global_step: 20215, epoch: 106, loss: 0.249507
global_step: 20216, epoch: 106, loss: 0.266846
global_step: 20217, epoch: 106, loss: 0.206117
global_step: 20218, epoch: 106, loss: 0.266210
global_step: 20219, epoch: 106, loss: 0.312795
global_step: 20220, epoch: 106, loss: 0.279528
global_step: 20221, epoch: 106, loss: 0.349943
global_step: 20222, epoch: 106, loss: 0.342871
global_step: 20223, epoch: 106, loss: 0.321394
global_step: 20224, epoch: 106, loss: 0.280920
global_step: 20225, epoch: 106, loss: 0.287953
global_step: 20226, epoch: 106, loss: 0.391121
global_step: 20227, epoch: 106, loss: 0.276297
global_step: 20228, epoch: 106, loss: 0.303896
global_step: 20229, epoch: 106, loss: 0.280841
global_step: 20230, epoch: 106, loss: 0.260664
global_step: 20231, epoch: 106, loss: 0.285342
global_step: 20232, epoch: 106, loss: 0.279733
global_step: 20233, epoch: 106, loss: 0.312796
global_step: 20234, epoch: 106, loss: 0.334478
global_step: 20235, epoch: 106, loss: 0.296713
global_step: 20236, epoch: 106, loss: 0.205040
global_step: 20237, epoch: 106, loss: 0.335597
global_step: 20238, epoch: 106, loss: 0.294675
global_step: 20239, epoch: 106, loss: 0.315839
global_step: 20240, epoch: 106, loss: 0.320479
epoch: 106
train	acc: 0.9622	macro: p 0.9665, r 0.9386, f1: 0.9516	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9621
dev	acc: 0.5257	macro: p 0.3353, r 0.3037, f1: 0.3032	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4869
test	acc: 0.5747	macro: p 0.3560, r 0.3193, f1: 0.3268	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5449
global_step: 20241, epoch: 107, loss: 0.283733
global_step: 20242, epoch: 107, loss: 0.273982
global_step: 20243, epoch: 107, loss: 0.270939
global_step: 20244, epoch: 107, loss: 0.273673
global_step: 20245, epoch: 107, loss: 0.279354
global_step: 20246, epoch: 107, loss: 0.252286
global_step: 20247, epoch: 107, loss: 0.315854
global_step: 20248, epoch: 107, loss: 0.313229
global_step: 20249, epoch: 107, loss: 0.326864
global_step: 20250, epoch: 107, loss: 0.315979
global_step: 20251, epoch: 107, loss: 0.281944
global_step: 20252, epoch: 107, loss: 0.351043
global_step: 20253, epoch: 107, loss: 0.324268
global_step: 20254, epoch: 107, loss: 0.286898
global_step: 20255, epoch: 107, loss: 0.257793
global_step: 20256, epoch: 107, loss: 0.297434
global_step: 20257, epoch: 107, loss: 0.293471
global_step: 20258, epoch: 107, loss: 0.203569
global_step: 20259, epoch: 107, loss: 0.328701
global_step: 20260, epoch: 107, loss: 0.319499
global_step: 20261, epoch: 107, loss: 0.341809
global_step: 20262, epoch: 107, loss: 0.342478
global_step: 20263, epoch: 107, loss: 0.297342
global_step: 20264, epoch: 107, loss: 0.367119
global_step: 20265, epoch: 107, loss: 0.310600
global_step: 20266, epoch: 107, loss: 0.242924
global_step: 20267, epoch: 107, loss: 0.358817
global_step: 20268, epoch: 107, loss: 0.307174
global_step: 20269, epoch: 107, loss: 0.365662
global_step: 20270, epoch: 107, loss: 0.274795
global_step: 20271, epoch: 107, loss: 0.259573
global_step: 20272, epoch: 107, loss: 0.339797
global_step: 20273, epoch: 107, loss: 0.313907
global_step: 20274, epoch: 107, loss: 0.292237
global_step: 20275, epoch: 107, loss: 0.347706
global_step: 20276, epoch: 107, loss: 0.295104
global_step: 20277, epoch: 107, loss: 0.294603
global_step: 20278, epoch: 107, loss: 0.244853
global_step: 20279, epoch: 107, loss: 0.387029
global_step: 20280, epoch: 107, loss: 0.543890
epoch: 107
train	acc: 0.9612	macro: p 0.9652, r 0.9380, f1: 0.9507	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9611
dev	acc: 0.5410	macro: p 0.3519, r 0.3124, f1: 0.3128	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4990
test	acc: 0.5801	macro: p 0.3473, r 0.3158, f1: 0.3226	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5473
global_step: 20281, epoch: 108, loss: 0.313441
global_step: 20282, epoch: 108, loss: 0.333801
global_step: 20283, epoch: 108, loss: 0.333809
global_step: 20284, epoch: 108, loss: 0.298275
global_step: 20285, epoch: 108, loss: 0.252564
global_step: 20286, epoch: 108, loss: 0.326969
global_step: 20287, epoch: 108, loss: 0.324926
global_step: 20288, epoch: 108, loss: 0.296763
global_step: 20289, epoch: 108, loss: 0.294687
global_step: 20290, epoch: 108, loss: 0.291696
global_step: 20291, epoch: 108, loss: 0.272935
global_step: 20292, epoch: 108, loss: 0.257512
global_step: 20293, epoch: 108, loss: 0.220425
global_step: 20294, epoch: 108, loss: 0.395555
global_step: 20295, epoch: 108, loss: 0.291590
global_step: 20296, epoch: 108, loss: 0.241741
global_step: 20297, epoch: 108, loss: 0.211912
global_step: 20298, epoch: 108, loss: 0.295950
global_step: 20299, epoch: 108, loss: 0.267303
global_step: 20300, epoch: 108, loss: 0.281642
global_step: 20301, epoch: 108, loss: 0.280371
global_step: 20302, epoch: 108, loss: 0.318866
global_step: 20303, epoch: 108, loss: 0.308617
global_step: 20304, epoch: 108, loss: 0.422039
global_step: 20305, epoch: 108, loss: 0.363398
global_step: 20306, epoch: 108, loss: 0.278475
global_step: 20307, epoch: 108, loss: 0.299969
global_step: 20308, epoch: 108, loss: 0.381837
global_step: 20309, epoch: 108, loss: 0.323179
global_step: 20310, epoch: 108, loss: 0.384694
global_step: 20311, epoch: 108, loss: 0.319853
global_step: 20312, epoch: 108, loss: 0.347129
global_step: 20313, epoch: 108, loss: 0.280601
global_step: 20314, epoch: 108, loss: 0.301210
global_step: 20315, epoch: 108, loss: 0.270038
global_step: 20316, epoch: 108, loss: 0.296597
global_step: 20317, epoch: 108, loss: 0.328151
global_step: 20318, epoch: 108, loss: 0.279556
global_step: 20319, epoch: 108, loss: 0.309558
global_step: 20320, epoch: 108, loss: 0.704288
epoch: 108
train	acc: 0.9610	macro: p 0.9670, r 0.9361, f1: 0.9505	micro: p 0.9610, r 0.9610, f1 0.9610	weighted_f1:0.9609
dev	acc: 0.5347	macro: p 0.3593, r 0.3086, f1: 0.3058	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4898
test	acc: 0.5805	macro: p 0.3667, r 0.3197, f1: 0.3258	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5445
global_step: 20321, epoch: 109, loss: 0.350168
global_step: 20322, epoch: 109, loss: 0.301489
global_step: 20323, epoch: 109, loss: 0.317074
global_step: 20324, epoch: 109, loss: 0.230340
global_step: 20325, epoch: 109, loss: 0.304926
global_step: 20326, epoch: 109, loss: 0.267715
global_step: 20327, epoch: 109, loss: 0.305735
global_step: 20328, epoch: 109, loss: 0.278493
global_step: 20329, epoch: 109, loss: 0.360315
global_step: 20330, epoch: 109, loss: 0.331011
global_step: 20331, epoch: 109, loss: 0.321265
global_step: 20332, epoch: 109, loss: 0.276883
global_step: 20333, epoch: 109, loss: 0.263437
global_step: 20334, epoch: 109, loss: 0.312794
global_step: 20335, epoch: 109, loss: 0.357023
global_step: 20336, epoch: 109, loss: 0.305999
global_step: 20337, epoch: 109, loss: 0.260973
global_step: 20338, epoch: 109, loss: 0.224513
global_step: 20339, epoch: 109, loss: 0.305666
global_step: 20340, epoch: 109, loss: 0.264266
global_step: 20341, epoch: 109, loss: 0.361262
global_step: 20342, epoch: 109, loss: 0.299103
global_step: 20343, epoch: 109, loss: 0.314532
global_step: 20344, epoch: 109, loss: 0.316239
global_step: 20345, epoch: 109, loss: 0.292002
global_step: 20346, epoch: 109, loss: 0.274039
global_step: 20347, epoch: 109, loss: 0.324617
global_step: 20348, epoch: 109, loss: 0.365155
global_step: 20349, epoch: 109, loss: 0.321119
global_step: 20350, epoch: 109, loss: 0.301801
global_step: 20351, epoch: 109, loss: 0.296940
global_step: 20352, epoch: 109, loss: 0.346148
global_step: 20353, epoch: 109, loss: 0.288065
global_step: 20354, epoch: 109, loss: 0.351660
global_step: 20355, epoch: 109, loss: 0.336118
global_step: 20356, epoch: 109, loss: 0.293145
global_step: 20357, epoch: 109, loss: 0.300550
global_step: 20358, epoch: 109, loss: 0.286130
global_step: 20359, epoch: 109, loss: 0.336342
global_step: 20360, epoch: 109, loss: 0.901982
epoch: 109
train	acc: 0.9622	macro: p 0.9676, r 0.9376, f1: 0.9517	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9621
dev	acc: 0.5338	macro: p 0.3412, r 0.3030, f1: 0.3031	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4903
test	acc: 0.5736	macro: p 0.3549, r 0.3115, f1: 0.3204	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5394
global_step: 20361, epoch: 110, loss: 0.306416
global_step: 20362, epoch: 110, loss: 0.337248
global_step: 20363, epoch: 110, loss: 0.325016
global_step: 20364, epoch: 110, loss: 0.270978
global_step: 20365, epoch: 110, loss: 0.277974
global_step: 20366, epoch: 110, loss: 0.285828
global_step: 20367, epoch: 110, loss: 0.252965
global_step: 20368, epoch: 110, loss: 0.294694
global_step: 20369, epoch: 110, loss: 0.407005
global_step: 20370, epoch: 110, loss: 0.238534
global_step: 20371, epoch: 110, loss: 0.267606
global_step: 20372, epoch: 110, loss: 0.310833
global_step: 20373, epoch: 110, loss: 0.296678
global_step: 20374, epoch: 110, loss: 0.247945
global_step: 20375, epoch: 110, loss: 0.367948
global_step: 20376, epoch: 110, loss: 0.266637
global_step: 20377, epoch: 110, loss: 0.266056
global_step: 20378, epoch: 110, loss: 0.258129
global_step: 20379, epoch: 110, loss: 0.295453
global_step: 20380, epoch: 110, loss: 0.347297
global_step: 20381, epoch: 110, loss: 0.280921
global_step: 20382, epoch: 110, loss: 0.255749
global_step: 20383, epoch: 110, loss: 0.285959
global_step: 20384, epoch: 110, loss: 0.423024
global_step: 20385, epoch: 110, loss: 0.344360
global_step: 20386, epoch: 110, loss: 0.306995
global_step: 20387, epoch: 110, loss: 0.286716
global_step: 20388, epoch: 110, loss: 0.339455
global_step: 20389, epoch: 110, loss: 0.338097
global_step: 20390, epoch: 110, loss: 0.245862
global_step: 20391, epoch: 110, loss: 0.320756
global_step: 20392, epoch: 110, loss: 0.339719
global_step: 20393, epoch: 110, loss: 0.278989
global_step: 20394, epoch: 110, loss: 0.380113
global_step: 20395, epoch: 110, loss: 0.280980
global_step: 20396, epoch: 110, loss: 0.345173
global_step: 20397, epoch: 110, loss: 0.314606
global_step: 20398, epoch: 110, loss: 0.311430
global_step: 20399, epoch: 110, loss: 0.340563
global_step: 20400, epoch: 110, loss: 0.034826
epoch: 110
train	acc: 0.9635	macro: p 0.9691, r 0.9402, f1: 0.9538	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5428	macro: p 0.3593, r 0.3125, f1: 0.3136	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4989
test	acc: 0.5785	macro: p 0.3610, r 0.3159, f1: 0.3252	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5425
global_step: 20401, epoch: 111, loss: 0.287909
global_step: 20402, epoch: 111, loss: 0.309273
global_step: 20403, epoch: 111, loss: 0.226415
global_step: 20404, epoch: 111, loss: 0.313010
global_step: 20405, epoch: 111, loss: 0.294137
global_step: 20406, epoch: 111, loss: 0.249433
global_step: 20407, epoch: 111, loss: 0.261310
global_step: 20408, epoch: 111, loss: 0.247878
global_step: 20409, epoch: 111, loss: 0.257288
global_step: 20410, epoch: 111, loss: 0.281926
global_step: 20411, epoch: 111, loss: 0.252584
global_step: 20412, epoch: 111, loss: 0.311278
global_step: 20413, epoch: 111, loss: 0.390812
global_step: 20414, epoch: 111, loss: 0.294114
global_step: 20415, epoch: 111, loss: 0.280065
global_step: 20416, epoch: 111, loss: 0.271382
global_step: 20417, epoch: 111, loss: 0.223347
global_step: 20418, epoch: 111, loss: 0.221787
global_step: 20419, epoch: 111, loss: 0.285923
global_step: 20420, epoch: 111, loss: 0.175036
global_step: 20421, epoch: 111, loss: 0.291039
global_step: 20422, epoch: 111, loss: 0.310005
global_step: 20423, epoch: 111, loss: 0.269019
global_step: 20424, epoch: 111, loss: 0.326290
global_step: 20425, epoch: 111, loss: 0.273105
global_step: 20426, epoch: 111, loss: 0.319338
global_step: 20427, epoch: 111, loss: 0.320305
global_step: 20428, epoch: 111, loss: 0.309567
global_step: 20429, epoch: 111, loss: 0.349562
global_step: 20430, epoch: 111, loss: 0.310455
global_step: 20431, epoch: 111, loss: 0.280033
global_step: 20432, epoch: 111, loss: 0.306147
global_step: 20433, epoch: 111, loss: 0.282892
global_step: 20434, epoch: 111, loss: 0.313836
global_step: 20435, epoch: 111, loss: 0.287884
global_step: 20436, epoch: 111, loss: 0.256635
global_step: 20437, epoch: 111, loss: 0.214365
global_step: 20438, epoch: 111, loss: 0.342441
global_step: 20439, epoch: 111, loss: 0.362133
global_step: 20440, epoch: 111, loss: 0.035739
epoch: 111
train	acc: 0.9636	macro: p 0.9694, r 0.9403, f1: 0.9540	micro: p 0.9636, r 0.9636, f1 0.9636	weighted_f1:0.9635
dev	acc: 0.5392	macro: p 0.3807, r 0.3171, f1: 0.3204	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4961
test	acc: 0.5824	macro: p 0.3665, r 0.3184, f1: 0.3270	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5458
global_step: 20441, epoch: 112, loss: 0.259624
global_step: 20442, epoch: 112, loss: 0.198510
global_step: 20443, epoch: 112, loss: 0.283057
global_step: 20444, epoch: 112, loss: 0.271592
global_step: 20445, epoch: 112, loss: 0.275265
global_step: 20446, epoch: 112, loss: 0.297098
global_step: 20447, epoch: 112, loss: 0.313328
global_step: 20448, epoch: 112, loss: 0.260212
global_step: 20449, epoch: 112, loss: 0.303419
global_step: 20450, epoch: 112, loss: 0.238519
global_step: 20451, epoch: 112, loss: 0.359479
global_step: 20452, epoch: 112, loss: 0.247637
global_step: 20453, epoch: 112, loss: 0.285331
global_step: 20454, epoch: 112, loss: 0.306283
global_step: 20455, epoch: 112, loss: 0.318446
global_step: 20456, epoch: 112, loss: 0.265281
global_step: 20457, epoch: 112, loss: 0.285053
global_step: 20458, epoch: 112, loss: 0.309527
global_step: 20459, epoch: 112, loss: 0.278049
global_step: 20460, epoch: 112, loss: 0.301108
global_step: 20461, epoch: 112, loss: 0.266830
global_step: 20462, epoch: 112, loss: 0.230781
global_step: 20463, epoch: 112, loss: 0.307342
global_step: 20464, epoch: 112, loss: 0.288686
global_step: 20465, epoch: 112, loss: 0.228609
global_step: 20466, epoch: 112, loss: 0.236021
global_step: 20467, epoch: 112, loss: 0.268239
global_step: 20468, epoch: 112, loss: 0.307004
global_step: 20469, epoch: 112, loss: 0.259495
global_step: 20470, epoch: 112, loss: 0.316600
global_step: 20471, epoch: 112, loss: 0.292405
global_step: 20472, epoch: 112, loss: 0.353752
global_step: 20473, epoch: 112, loss: 0.281337
global_step: 20474, epoch: 112, loss: 0.272641
global_step: 20475, epoch: 112, loss: 0.291817
global_step: 20476, epoch: 112, loss: 0.375372
global_step: 20477, epoch: 112, loss: 0.294974
global_step: 20478, epoch: 112, loss: 0.473778
global_step: 20479, epoch: 112, loss: 0.217299
global_step: 20480, epoch: 112, loss: 0.225922
epoch: 112
train	acc: 0.9630	macro: p 0.9694, r 0.9405, f1: 0.9542	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9629
dev	acc: 0.5401	macro: p 0.3910, r 0.3142, f1: 0.3189	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4940
test	acc: 0.5812	macro: p 0.3613, r 0.3106, f1: 0.3187	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5413
global_step: 20481, epoch: 113, loss: 0.280244
global_step: 20482, epoch: 113, loss: 0.319584
global_step: 20483, epoch: 113, loss: 0.234671
global_step: 20484, epoch: 113, loss: 0.305295
global_step: 20485, epoch: 113, loss: 0.285261
global_step: 20486, epoch: 113, loss: 0.375997
global_step: 20487, epoch: 113, loss: 0.205437
global_step: 20488, epoch: 113, loss: 0.297624
global_step: 20489, epoch: 113, loss: 0.326260
global_step: 20490, epoch: 113, loss: 0.245586
global_step: 20491, epoch: 113, loss: 0.242114
global_step: 20492, epoch: 113, loss: 0.265014
global_step: 20493, epoch: 113, loss: 0.378096
global_step: 20494, epoch: 113, loss: 0.287219
global_step: 20495, epoch: 113, loss: 0.307286
global_step: 20496, epoch: 113, loss: 0.240961
global_step: 20497, epoch: 113, loss: 0.228479
global_step: 20498, epoch: 113, loss: 0.321263
global_step: 20499, epoch: 113, loss: 0.343884
global_step: 20500, epoch: 113, loss: 0.263689
global_step: 20501, epoch: 113, loss: 0.263192
global_step: 20502, epoch: 113, loss: 0.279583
global_step: 20503, epoch: 113, loss: 0.217128
global_step: 20504, epoch: 113, loss: 0.350394
global_step: 20505, epoch: 113, loss: 0.349849
global_step: 20506, epoch: 113, loss: 0.268994
global_step: 20507, epoch: 113, loss: 0.248543
global_step: 20508, epoch: 113, loss: 0.270447
global_step: 20509, epoch: 113, loss: 0.267885
global_step: 20510, epoch: 113, loss: 0.302690
global_step: 20511, epoch: 113, loss: 0.276691
global_step: 20512, epoch: 113, loss: 0.260279
global_step: 20513, epoch: 113, loss: 0.375295
global_step: 20514, epoch: 113, loss: 0.358368
global_step: 20515, epoch: 113, loss: 0.364825
global_step: 20516, epoch: 113, loss: 0.242935
global_step: 20517, epoch: 113, loss: 0.273029
global_step: 20518, epoch: 113, loss: 0.277364
global_step: 20519, epoch: 113, loss: 0.288534
global_step: 20520, epoch: 113, loss: 0.237409
epoch: 113
train	acc: 0.9649	macro: p 0.9695, r 0.9460, f1: 0.9571	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5329	macro: p 0.3662, r 0.3199, f1: 0.3207	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4957
test	acc: 0.5667	macro: p 0.3419, r 0.3134, f1: 0.3178	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5370
global_step: 20521, epoch: 114, loss: 0.236379
global_step: 20522, epoch: 114, loss: 0.327859
global_step: 20523, epoch: 114, loss: 0.230528
global_step: 20524, epoch: 114, loss: 0.331591
global_step: 20525, epoch: 114, loss: 0.250973
global_step: 20526, epoch: 114, loss: 0.293739
global_step: 20527, epoch: 114, loss: 0.289166
global_step: 20528, epoch: 114, loss: 0.233590
global_step: 20529, epoch: 114, loss: 0.334349
global_step: 20530, epoch: 114, loss: 0.276993
global_step: 20531, epoch: 114, loss: 0.342260
global_step: 20532, epoch: 114, loss: 0.308249
global_step: 20533, epoch: 114, loss: 0.363096
global_step: 20534, epoch: 114, loss: 0.231504
global_step: 20535, epoch: 114, loss: 0.301216
global_step: 20536, epoch: 114, loss: 0.406859
global_step: 20537, epoch: 114, loss: 0.288577
global_step: 20538, epoch: 114, loss: 0.249362
global_step: 20539, epoch: 114, loss: 0.318084
global_step: 20540, epoch: 114, loss: 0.326657
global_step: 20541, epoch: 114, loss: 0.200013
global_step: 20542, epoch: 114, loss: 0.382478
global_step: 20543, epoch: 114, loss: 0.286323
global_step: 20544, epoch: 114, loss: 0.287139
global_step: 20545, epoch: 114, loss: 0.250309
global_step: 20546, epoch: 114, loss: 0.233423
global_step: 20547, epoch: 114, loss: 0.262471
global_step: 20548, epoch: 114, loss: 0.368587
global_step: 20549, epoch: 114, loss: 0.261115
global_step: 20550, epoch: 114, loss: 0.276015
global_step: 20551, epoch: 114, loss: 0.249921
global_step: 20552, epoch: 114, loss: 0.259783
global_step: 20553, epoch: 114, loss: 0.327826
global_step: 20554, epoch: 114, loss: 0.354521
global_step: 20555, epoch: 114, loss: 0.314897
global_step: 20556, epoch: 114, loss: 0.287957
global_step: 20557, epoch: 114, loss: 0.264268
global_step: 20558, epoch: 114, loss: 0.227729
global_step: 20559, epoch: 114, loss: 0.301048
global_step: 20560, epoch: 114, loss: 0.936176
epoch: 114
train	acc: 0.9632	macro: p 0.9695, r 0.9411, f1: 0.9545	micro: p 0.9632, r 0.9632, f1 0.9632	weighted_f1:0.9631
dev	acc: 0.5428	macro: p 0.3761, r 0.3100, f1: 0.3108	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4951
test	acc: 0.5828	macro: p 0.3702, r 0.3083, f1: 0.3163	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5395
global_step: 20561, epoch: 115, loss: 0.339845
global_step: 20562, epoch: 115, loss: 0.290303
global_step: 20563, epoch: 115, loss: 0.281368
global_step: 20564, epoch: 115, loss: 0.359856
global_step: 20565, epoch: 115, loss: 0.304416
global_step: 20566, epoch: 115, loss: 0.271390
global_step: 20567, epoch: 115, loss: 0.300337
global_step: 20568, epoch: 115, loss: 0.325506
global_step: 20569, epoch: 115, loss: 0.307123
global_step: 20570, epoch: 115, loss: 0.262526
global_step: 20571, epoch: 115, loss: 0.251633
global_step: 20572, epoch: 115, loss: 0.277242
global_step: 20573, epoch: 115, loss: 0.254245
global_step: 20574, epoch: 115, loss: 0.289904
global_step: 20575, epoch: 115, loss: 0.284825
global_step: 20576, epoch: 115, loss: 0.238694
global_step: 20577, epoch: 115, loss: 0.342429
global_step: 20578, epoch: 115, loss: 0.273930
global_step: 20579, epoch: 115, loss: 0.307746
global_step: 20580, epoch: 115, loss: 0.265798
global_step: 20581, epoch: 115, loss: 0.222076
global_step: 20582, epoch: 115, loss: 0.292125
global_step: 20583, epoch: 115, loss: 0.295187
global_step: 20584, epoch: 115, loss: 0.253414
global_step: 20585, epoch: 115, loss: 0.300967
global_step: 20586, epoch: 115, loss: 0.218624
global_step: 20587, epoch: 115, loss: 0.258009
global_step: 20588, epoch: 115, loss: 0.335016
global_step: 20589, epoch: 115, loss: 0.256742
global_step: 20590, epoch: 115, loss: 0.237158
global_step: 20591, epoch: 115, loss: 0.287252
global_step: 20592, epoch: 115, loss: 0.287660
global_step: 20593, epoch: 115, loss: 0.301049
global_step: 20594, epoch: 115, loss: 0.296871
global_step: 20595, epoch: 115, loss: 0.335472
global_step: 20596, epoch: 115, loss: 0.247416
global_step: 20597, epoch: 115, loss: 0.301248
global_step: 20598, epoch: 115, loss: 0.302450
global_step: 20599, epoch: 115, loss: 0.209772
global_step: 20600, epoch: 115, loss: 0.355145
epoch: 115
train	acc: 0.9630	macro: p 0.9682, r 0.9411, f1: 0.9539	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9629
dev	acc: 0.5419	macro: p 0.3893, r 0.3189, f1: 0.3239	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4998
test	acc: 0.5778	macro: p 0.3387, r 0.3091, f1: 0.3148	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5413
global_step: 20601, epoch: 116, loss: 0.271267
global_step: 20602, epoch: 116, loss: 0.267423
global_step: 20603, epoch: 116, loss: 0.228667
global_step: 20604, epoch: 116, loss: 0.268438
global_step: 20605, epoch: 116, loss: 0.229241
global_step: 20606, epoch: 116, loss: 0.327485
global_step: 20607, epoch: 116, loss: 0.252917
global_step: 20608, epoch: 116, loss: 0.282941
global_step: 20609, epoch: 116, loss: 0.204776
global_step: 20610, epoch: 116, loss: 0.246265
global_step: 20611, epoch: 116, loss: 0.274626
global_step: 20612, epoch: 116, loss: 0.242398
global_step: 20613, epoch: 116, loss: 0.234869
global_step: 20614, epoch: 116, loss: 0.231054
global_step: 20615, epoch: 116, loss: 0.232477
global_step: 20616, epoch: 116, loss: 0.280281
global_step: 20617, epoch: 116, loss: 0.277382
global_step: 20618, epoch: 116, loss: 0.232650
global_step: 20619, epoch: 116, loss: 0.239912
global_step: 20620, epoch: 116, loss: 0.231589
global_step: 20621, epoch: 116, loss: 0.233382
global_step: 20622, epoch: 116, loss: 0.312390
global_step: 20623, epoch: 116, loss: 0.246067
global_step: 20624, epoch: 116, loss: 0.297219
global_step: 20625, epoch: 116, loss: 0.309454
global_step: 20626, epoch: 116, loss: 0.309016
global_step: 20627, epoch: 116, loss: 0.291408
global_step: 20628, epoch: 116, loss: 0.253207
global_step: 20629, epoch: 116, loss: 0.291106
global_step: 20630, epoch: 116, loss: 0.205084
global_step: 20631, epoch: 116, loss: 0.270029
global_step: 20632, epoch: 116, loss: 0.358115
global_step: 20633, epoch: 116, loss: 0.390402
global_step: 20634, epoch: 116, loss: 0.272795
global_step: 20635, epoch: 116, loss: 0.299201
global_step: 20636, epoch: 116, loss: 0.326590
global_step: 20637, epoch: 116, loss: 0.216040
global_step: 20638, epoch: 116, loss: 0.373326
global_step: 20639, epoch: 116, loss: 0.202668
global_step: 20640, epoch: 116, loss: 1.320344
epoch: 116
train	acc: 0.9640	macro: p 0.9681, r 0.9436, f1: 0.9553	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9639
dev	acc: 0.5401	macro: p 0.3680, r 0.3112, f1: 0.3153	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4936
test	acc: 0.5824	macro: p 0.3619, r 0.3065, f1: 0.3158	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5392
global_step: 20641, epoch: 117, loss: 0.237761
global_step: 20642, epoch: 117, loss: 0.187362
global_step: 20643, epoch: 117, loss: 0.276320
global_step: 20644, epoch: 117, loss: 0.259041
global_step: 20645, epoch: 117, loss: 0.263521
global_step: 20646, epoch: 117, loss: 0.275821
global_step: 20647, epoch: 117, loss: 0.275976
global_step: 20648, epoch: 117, loss: 0.265690
global_step: 20649, epoch: 117, loss: 0.289513
global_step: 20650, epoch: 117, loss: 0.274069
global_step: 20651, epoch: 117, loss: 0.328317
global_step: 20652, epoch: 117, loss: 0.282162
global_step: 20653, epoch: 117, loss: 0.316703
global_step: 20654, epoch: 117, loss: 0.264135
global_step: 20655, epoch: 117, loss: 0.296491
global_step: 20656, epoch: 117, loss: 0.289060
global_step: 20657, epoch: 117, loss: 0.278252
global_step: 20658, epoch: 117, loss: 0.328567
global_step: 20659, epoch: 117, loss: 0.253319
global_step: 20660, epoch: 117, loss: 0.293322
global_step: 20661, epoch: 117, loss: 0.297336
global_step: 20662, epoch: 117, loss: 0.246552
global_step: 20663, epoch: 117, loss: 0.248158
global_step: 20664, epoch: 117, loss: 0.238732
global_step: 20665, epoch: 117, loss: 0.269190
global_step: 20666, epoch: 117, loss: 0.207938
global_step: 20667, epoch: 117, loss: 0.266355
global_step: 20668, epoch: 117, loss: 0.292188
global_step: 20669, epoch: 117, loss: 0.304026
global_step: 20670, epoch: 117, loss: 0.214246
global_step: 20671, epoch: 117, loss: 0.281588
global_step: 20672, epoch: 117, loss: 0.233846
global_step: 20673, epoch: 117, loss: 0.273033
global_step: 20674, epoch: 117, loss: 0.260563
global_step: 20675, epoch: 117, loss: 0.267162
global_step: 20676, epoch: 117, loss: 0.274895
global_step: 20677, epoch: 117, loss: 0.269675
global_step: 20678, epoch: 117, loss: 0.300837
global_step: 20679, epoch: 117, loss: 0.298487
global_step: 20680, epoch: 117, loss: 0.260126
epoch: 117
train	acc: 0.9642	macro: p 0.9686, r 0.9460, f1: 0.9567	micro: p 0.9642, r 0.9642, f1 0.9642	weighted_f1:0.9642
dev	acc: 0.5365	macro: p 0.3629, r 0.3095, f1: 0.3067	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4914
test	acc: 0.5759	macro: p 0.3488, r 0.3166, f1: 0.3197	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5414
global_step: 20681, epoch: 118, loss: 0.297706
global_step: 20682, epoch: 118, loss: 0.202938
global_step: 20683, epoch: 118, loss: 0.274880
global_step: 20684, epoch: 118, loss: 0.226946
global_step: 20685, epoch: 118, loss: 0.307382
global_step: 20686, epoch: 118, loss: 0.297603
global_step: 20687, epoch: 118, loss: 0.296475
global_step: 20688, epoch: 118, loss: 0.246390
global_step: 20689, epoch: 118, loss: 0.257083
global_step: 20690, epoch: 118, loss: 0.203376
global_step: 20691, epoch: 118, loss: 0.196269
global_step: 20692, epoch: 118, loss: 0.329731
global_step: 20693, epoch: 118, loss: 0.236919
global_step: 20694, epoch: 118, loss: 0.309249
global_step: 20695, epoch: 118, loss: 0.266973
global_step: 20696, epoch: 118, loss: 0.235841
global_step: 20697, epoch: 118, loss: 0.299691
global_step: 20698, epoch: 118, loss: 0.238083
global_step: 20699, epoch: 118, loss: 0.288046
global_step: 20700, epoch: 118, loss: 0.278204
global_step: 20701, epoch: 118, loss: 0.284357
global_step: 20702, epoch: 118, loss: 0.246675
global_step: 20703, epoch: 118, loss: 0.265319
global_step: 20704, epoch: 118, loss: 0.254476
global_step: 20705, epoch: 118, loss: 0.226716
global_step: 20706, epoch: 118, loss: 0.367796
global_step: 20707, epoch: 118, loss: 0.240965
global_step: 20708, epoch: 118, loss: 0.236438
global_step: 20709, epoch: 118, loss: 0.300057
global_step: 20710, epoch: 118, loss: 0.293493
global_step: 20711, epoch: 118, loss: 0.335178
global_step: 20712, epoch: 118, loss: 0.256079
global_step: 20713, epoch: 118, loss: 0.261814
global_step: 20714, epoch: 118, loss: 0.330317
global_step: 20715, epoch: 118, loss: 0.251939
global_step: 20716, epoch: 118, loss: 0.246207
global_step: 20717, epoch: 118, loss: 0.320223
global_step: 20718, epoch: 118, loss: 0.271056
global_step: 20719, epoch: 118, loss: 0.400282
global_step: 20720, epoch: 118, loss: 0.110806
epoch: 118
train	acc: 0.9650	macro: p 0.9697, r 0.9454, f1: 0.9569	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9649
dev	acc: 0.5374	macro: p 0.3619, r 0.3111, f1: 0.3103	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4959
test	acc: 0.5751	macro: p 0.3542, r 0.3130, f1: 0.3216	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5424
global_step: 20721, epoch: 119, loss: 0.266051
global_step: 20722, epoch: 119, loss: 0.278695
global_step: 20723, epoch: 119, loss: 0.314731
global_step: 20724, epoch: 119, loss: 0.223836
global_step: 20725, epoch: 119, loss: 0.281825
global_step: 20726, epoch: 119, loss: 0.250701
global_step: 20727, epoch: 119, loss: 0.279788
global_step: 20728, epoch: 119, loss: 0.234754
global_step: 20729, epoch: 119, loss: 0.304031
global_step: 20730, epoch: 119, loss: 0.251220
global_step: 20731, epoch: 119, loss: 0.327334
global_step: 20732, epoch: 119, loss: 0.276110
global_step: 20733, epoch: 119, loss: 0.374750
global_step: 20734, epoch: 119, loss: 0.345287
global_step: 20735, epoch: 119, loss: 0.238917
global_step: 20736, epoch: 119, loss: 0.328166
global_step: 20737, epoch: 119, loss: 0.229551
global_step: 20738, epoch: 119, loss: 0.265625
global_step: 20739, epoch: 119, loss: 0.215647
global_step: 20740, epoch: 119, loss: 0.283982
global_step: 20741, epoch: 119, loss: 0.312916
global_step: 20742, epoch: 119, loss: 0.295676
global_step: 20743, epoch: 119, loss: 0.269199
global_step: 20744, epoch: 119, loss: 0.207353
global_step: 20745, epoch: 119, loss: 0.243447
global_step: 20746, epoch: 119, loss: 0.313476
global_step: 20747, epoch: 119, loss: 0.242499
global_step: 20748, epoch: 119, loss: 0.241931
global_step: 20749, epoch: 119, loss: 0.334469
global_step: 20750, epoch: 119, loss: 0.250890
global_step: 20751, epoch: 119, loss: 0.263329
global_step: 20752, epoch: 119, loss: 0.227969
global_step: 20753, epoch: 119, loss: 0.405907
global_step: 20754, epoch: 119, loss: 0.241022
global_step: 20755, epoch: 119, loss: 0.349437
global_step: 20756, epoch: 119, loss: 0.308075
global_step: 20757, epoch: 119, loss: 0.289715
global_step: 20758, epoch: 119, loss: 0.261503
global_step: 20759, epoch: 119, loss: 0.230980
global_step: 20760, epoch: 119, loss: 0.244361
epoch: 119
train	acc: 0.9625	macro: p 0.9685, r 0.9424, f1: 0.9546	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9625
dev	acc: 0.5392	macro: p 0.4124, r 0.3130, f1: 0.3099	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4951
test	acc: 0.5667	macro: p 0.3456, r 0.3129, f1: 0.3155	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5340
global_step: 20761, epoch: 120, loss: 0.252786
global_step: 20762, epoch: 120, loss: 0.270718
global_step: 20763, epoch: 120, loss: 0.173156
global_step: 20764, epoch: 120, loss: 0.326845
global_step: 20765, epoch: 120, loss: 0.286025
global_step: 20766, epoch: 120, loss: 0.279345
global_step: 20767, epoch: 120, loss: 0.244860
global_step: 20768, epoch: 120, loss: 0.272222
global_step: 20769, epoch: 120, loss: 0.248100
global_step: 20770, epoch: 120, loss: 0.307436
global_step: 20771, epoch: 120, loss: 0.348066
global_step: 20772, epoch: 120, loss: 0.288906
global_step: 20773, epoch: 120, loss: 0.214998
global_step: 20774, epoch: 120, loss: 0.230136
global_step: 20775, epoch: 120, loss: 0.365108
global_step: 20776, epoch: 120, loss: 0.299005
global_step: 20777, epoch: 120, loss: 0.265707
global_step: 20778, epoch: 120, loss: 0.256822
global_step: 20779, epoch: 120, loss: 0.258635
global_step: 20780, epoch: 120, loss: 0.248041
global_step: 20781, epoch: 120, loss: 0.365773
global_step: 20782, epoch: 120, loss: 0.239986
global_step: 20783, epoch: 120, loss: 0.322366
global_step: 20784, epoch: 120, loss: 0.288084
global_step: 20785, epoch: 120, loss: 0.270719
global_step: 20786, epoch: 120, loss: 0.244136
global_step: 20787, epoch: 120, loss: 0.236370
global_step: 20788, epoch: 120, loss: 0.246812
global_step: 20789, epoch: 120, loss: 0.321433
global_step: 20790, epoch: 120, loss: 0.228489
global_step: 20791, epoch: 120, loss: 0.307951
global_step: 20792, epoch: 120, loss: 0.281516
global_step: 20793, epoch: 120, loss: 0.241092
global_step: 20794, epoch: 120, loss: 0.263429
global_step: 20795, epoch: 120, loss: 0.296645
global_step: 20796, epoch: 120, loss: 0.294889
global_step: 20797, epoch: 120, loss: 0.332474
global_step: 20798, epoch: 120, loss: 0.314651
global_step: 20799, epoch: 120, loss: 0.309730
global_step: 20800, epoch: 120, loss: 0.139941
epoch: 120
train	acc: 0.9649	macro: p 0.9685, r 0.9467, f1: 0.9570	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5446	macro: p 0.4057, r 0.3222, f1: 0.3255	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5014
test	acc: 0.5782	macro: p 0.3620, r 0.3154, f1: 0.3216	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5424
global_step: 20801, epoch: 121, loss: 0.194747
global_step: 20802, epoch: 121, loss: 0.264534
global_step: 20803, epoch: 121, loss: 0.227783
global_step: 20804, epoch: 121, loss: 0.309103
global_step: 20805, epoch: 121, loss: 0.283313
global_step: 20806, epoch: 121, loss: 0.306111
global_step: 20807, epoch: 121, loss: 0.286115
global_step: 20808, epoch: 121, loss: 0.274429
global_step: 20809, epoch: 121, loss: 0.222329
global_step: 20810, epoch: 121, loss: 0.426961
global_step: 20811, epoch: 121, loss: 0.261500
global_step: 20812, epoch: 121, loss: 0.301871
global_step: 20813, epoch: 121, loss: 0.223866
global_step: 20814, epoch: 121, loss: 0.292638
global_step: 20815, epoch: 121, loss: 0.274729
global_step: 20816, epoch: 121, loss: 0.221157
global_step: 20817, epoch: 121, loss: 0.325742
global_step: 20818, epoch: 121, loss: 0.243289
global_step: 20819, epoch: 121, loss: 0.273758
global_step: 20820, epoch: 121, loss: 0.245307
global_step: 20821, epoch: 121, loss: 0.271104
global_step: 20822, epoch: 121, loss: 0.241012
global_step: 20823, epoch: 121, loss: 0.215960
global_step: 20824, epoch: 121, loss: 0.249687
global_step: 20825, epoch: 121, loss: 0.274176
global_step: 20826, epoch: 121, loss: 0.226153
global_step: 20827, epoch: 121, loss: 0.286800
global_step: 20828, epoch: 121, loss: 0.244293
global_step: 20829, epoch: 121, loss: 0.389208
global_step: 20830, epoch: 121, loss: 0.273632
global_step: 20831, epoch: 121, loss: 0.249011
global_step: 20832, epoch: 121, loss: 0.241034
global_step: 20833, epoch: 121, loss: 0.281221
global_step: 20834, epoch: 121, loss: 0.221163
global_step: 20835, epoch: 121, loss: 0.215073
global_step: 20836, epoch: 121, loss: 0.237200
global_step: 20837, epoch: 121, loss: 0.271600
global_step: 20838, epoch: 121, loss: 0.257007
global_step: 20839, epoch: 121, loss: 0.330859
global_step: 20840, epoch: 121, loss: 0.068327
epoch: 121
train	acc: 0.9662	macro: p 0.9698, r 0.9494, f1: 0.9592	micro: p 0.9662, r 0.9662, f1 0.9662	weighted_f1:0.9662
dev	acc: 0.5392	macro: p 0.3760, r 0.3176, f1: 0.3208	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4966
test	acc: 0.5785	macro: p 0.3553, r 0.3188, f1: 0.3259	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5449
global_step: 20841, epoch: 122, loss: 0.314826
global_step: 20842, epoch: 122, loss: 0.286223
global_step: 20843, epoch: 122, loss: 0.215937
global_step: 20844, epoch: 122, loss: 0.222029
global_step: 20845, epoch: 122, loss: 0.281086
global_step: 20846, epoch: 122, loss: 0.238130
global_step: 20847, epoch: 122, loss: 0.184524
global_step: 20848, epoch: 122, loss: 0.225087
global_step: 20849, epoch: 122, loss: 0.209506
global_step: 20850, epoch: 122, loss: 0.195933
global_step: 20851, epoch: 122, loss: 0.281313
global_step: 20852, epoch: 122, loss: 0.226336
global_step: 20853, epoch: 122, loss: 0.252166
global_step: 20854, epoch: 122, loss: 0.241288
global_step: 20855, epoch: 122, loss: 0.264295
global_step: 20856, epoch: 122, loss: 0.257250
global_step: 20857, epoch: 122, loss: 0.212557
global_step: 20858, epoch: 122, loss: 0.252372
global_step: 20859, epoch: 122, loss: 0.286025
global_step: 20860, epoch: 122, loss: 0.199596
global_step: 20861, epoch: 122, loss: 0.235364
global_step: 20862, epoch: 122, loss: 0.278948
global_step: 20863, epoch: 122, loss: 0.312403
global_step: 20864, epoch: 122, loss: 0.291640
global_step: 20865, epoch: 122, loss: 0.279785
global_step: 20866, epoch: 122, loss: 0.253940
global_step: 20867, epoch: 122, loss: 0.318801
global_step: 20868, epoch: 122, loss: 0.280265
global_step: 20869, epoch: 122, loss: 0.244959
global_step: 20870, epoch: 122, loss: 0.248780
global_step: 20871, epoch: 122, loss: 0.234602
global_step: 20872, epoch: 122, loss: 0.234974
global_step: 20873, epoch: 122, loss: 0.309212
global_step: 20874, epoch: 122, loss: 0.326176
global_step: 20875, epoch: 122, loss: 0.242923
global_step: 20876, epoch: 122, loss: 0.344117
global_step: 20877, epoch: 122, loss: 0.262132
global_step: 20878, epoch: 122, loss: 0.280324
global_step: 20879, epoch: 122, loss: 0.203555
global_step: 20880, epoch: 122, loss: 0.051171
epoch: 122
train	acc: 0.9666	macro: p 0.9703, r 0.9504, f1: 0.9599	micro: p 0.9666, r 0.9666, f1 0.9666	weighted_f1:0.9666
dev	acc: 0.5311	macro: p 0.3702, r 0.3144, f1: 0.3185	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4934
test	acc: 0.5713	macro: p 0.3499, r 0.3179, f1: 0.3240	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5407
global_step: 20881, epoch: 123, loss: 0.277433
global_step: 20882, epoch: 123, loss: 0.257050
global_step: 20883, epoch: 123, loss: 0.232305
global_step: 20884, epoch: 123, loss: 0.215813
global_step: 20885, epoch: 123, loss: 0.287305
global_step: 20886, epoch: 123, loss: 0.261484
global_step: 20887, epoch: 123, loss: 0.302581
global_step: 20888, epoch: 123, loss: 0.207387
global_step: 20889, epoch: 123, loss: 0.262384
global_step: 20890, epoch: 123, loss: 0.249019
global_step: 20891, epoch: 123, loss: 0.284839
global_step: 20892, epoch: 123, loss: 0.278427
global_step: 20893, epoch: 123, loss: 0.208306
global_step: 20894, epoch: 123, loss: 0.184275
global_step: 20895, epoch: 123, loss: 0.331383
global_step: 20896, epoch: 123, loss: 0.166718
global_step: 20897, epoch: 123, loss: 0.224623
global_step: 20898, epoch: 123, loss: 0.265482
global_step: 20899, epoch: 123, loss: 0.232888
global_step: 20900, epoch: 123, loss: 0.237945
global_step: 20901, epoch: 123, loss: 0.237254
global_step: 20902, epoch: 123, loss: 0.191773
global_step: 20903, epoch: 123, loss: 0.280865
global_step: 20904, epoch: 123, loss: 0.253320
global_step: 20905, epoch: 123, loss: 0.253840
global_step: 20906, epoch: 123, loss: 0.311141
global_step: 20907, epoch: 123, loss: 0.294188
global_step: 20908, epoch: 123, loss: 0.243168
global_step: 20909, epoch: 123, loss: 0.220301
global_step: 20910, epoch: 123, loss: 0.307133
global_step: 20911, epoch: 123, loss: 0.240152
global_step: 20912, epoch: 123, loss: 0.290779
global_step: 20913, epoch: 123, loss: 0.268783
global_step: 20914, epoch: 123, loss: 0.311680
global_step: 20915, epoch: 123, loss: 0.222644
global_step: 20916, epoch: 123, loss: 0.235537
global_step: 20917, epoch: 123, loss: 0.270273
global_step: 20918, epoch: 123, loss: 0.305074
global_step: 20919, epoch: 123, loss: 0.245039
global_step: 20920, epoch: 123, loss: 0.034284
epoch: 123
train	acc: 0.9663	macro: p 0.9698, r 0.9482, f1: 0.9584	micro: p 0.9663, r 0.9663, f1 0.9663	weighted_f1:0.9663
dev	acc: 0.5419	macro: p 0.3677, r 0.3153, f1: 0.3122	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4982
test	acc: 0.5739	macro: p 0.3667, r 0.3122, f1: 0.3169	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5381
global_step: 20921, epoch: 124, loss: 0.204609
global_step: 20922, epoch: 124, loss: 0.303046
global_step: 20923, epoch: 124, loss: 0.327127
global_step: 20924, epoch: 124, loss: 0.245294
global_step: 20925, epoch: 124, loss: 0.207890
global_step: 20926, epoch: 124, loss: 0.337267
global_step: 20927, epoch: 124, loss: 0.223909
global_step: 20928, epoch: 124, loss: 0.247930
global_step: 20929, epoch: 124, loss: 0.219447
global_step: 20930, epoch: 124, loss: 0.215548
global_step: 20931, epoch: 124, loss: 0.166085
global_step: 20932, epoch: 124, loss: 0.244070
global_step: 20933, epoch: 124, loss: 0.255099
global_step: 20934, epoch: 124, loss: 0.237097
global_step: 20935, epoch: 124, loss: 0.234908
global_step: 20936, epoch: 124, loss: 0.251767
global_step: 20937, epoch: 124, loss: 0.320140
global_step: 20938, epoch: 124, loss: 0.233182
global_step: 20939, epoch: 124, loss: 0.291556
global_step: 20940, epoch: 124, loss: 0.300989
global_step: 20941, epoch: 124, loss: 0.250470
global_step: 20942, epoch: 124, loss: 0.258872
global_step: 20943, epoch: 124, loss: 0.270342
global_step: 20944, epoch: 124, loss: 0.294765
global_step: 20945, epoch: 124, loss: 0.266448
global_step: 20946, epoch: 124, loss: 0.336582
global_step: 20947, epoch: 124, loss: 0.240696
global_step: 20948, epoch: 124, loss: 0.261383
global_step: 20949, epoch: 124, loss: 0.254766
global_step: 20950, epoch: 124, loss: 0.213266
global_step: 20951, epoch: 124, loss: 0.286558
global_step: 20952, epoch: 124, loss: 0.307066
global_step: 20953, epoch: 124, loss: 0.230222
global_step: 20954, epoch: 124, loss: 0.287693
global_step: 20955, epoch: 124, loss: 0.274688
global_step: 20956, epoch: 124, loss: 0.254928
global_step: 20957, epoch: 124, loss: 0.233070
global_step: 20958, epoch: 124, loss: 0.252583
global_step: 20959, epoch: 124, loss: 0.270936
global_step: 20960, epoch: 124, loss: 0.016241
epoch: 124
train	acc: 0.9668	macro: p 0.9698, r 0.9518, f1: 0.9604	micro: p 0.9668, r 0.9668, f1 0.9668	weighted_f1:0.9668
dev	acc: 0.5347	macro: p 0.3474, r 0.3065, f1: 0.3047	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4906
test	acc: 0.5751	macro: p 0.3473, r 0.3146, f1: 0.3190	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5404
global_step: 20961, epoch: 125, loss: 0.261902
global_step: 20962, epoch: 125, loss: 0.266291
global_step: 20963, epoch: 125, loss: 0.254898
global_step: 20964, epoch: 125, loss: 0.204069
global_step: 20965, epoch: 125, loss: 0.298625
global_step: 20966, epoch: 125, loss: 0.262886
global_step: 20967, epoch: 125, loss: 0.288080
global_step: 20968, epoch: 125, loss: 0.226757
global_step: 20969, epoch: 125, loss: 0.395026
global_step: 20970, epoch: 125, loss: 0.279141
global_step: 20971, epoch: 125, loss: 0.231917
global_step: 20972, epoch: 125, loss: 0.240218
global_step: 20973, epoch: 125, loss: 0.291999
global_step: 20974, epoch: 125, loss: 0.192892
global_step: 20975, epoch: 125, loss: 0.239334
global_step: 20976, epoch: 125, loss: 0.247945
global_step: 20977, epoch: 125, loss: 0.254657
global_step: 20978, epoch: 125, loss: 0.203880
global_step: 20979, epoch: 125, loss: 0.327999
global_step: 20980, epoch: 125, loss: 0.264702
global_step: 20981, epoch: 125, loss: 0.212957
global_step: 20982, epoch: 125, loss: 0.219309
global_step: 20983, epoch: 125, loss: 0.252163
global_step: 20984, epoch: 125, loss: 0.185454
global_step: 20985, epoch: 125, loss: 0.331552
global_step: 20986, epoch: 125, loss: 0.325819
global_step: 20987, epoch: 125, loss: 0.338357
global_step: 20988, epoch: 125, loss: 0.321985
global_step: 20989, epoch: 125, loss: 0.198468
global_step: 20990, epoch: 125, loss: 0.224909
global_step: 20991, epoch: 125, loss: 0.263464
global_step: 20992, epoch: 125, loss: 0.317359
global_step: 20993, epoch: 125, loss: 0.215541
global_step: 20994, epoch: 125, loss: 0.256375
global_step: 20995, epoch: 125, loss: 0.296067
global_step: 20996, epoch: 125, loss: 0.251913
global_step: 20997, epoch: 125, loss: 0.251993
global_step: 20998, epoch: 125, loss: 0.273867
global_step: 20999, epoch: 125, loss: 0.239116
global_step: 21000, epoch: 125, loss: 0.450029
epoch: 125
train	acc: 0.9663	macro: p 0.9695, r 0.9490, f1: 0.9589	micro: p 0.9663, r 0.9663, f1 0.9663	weighted_f1:0.9662
dev	acc: 0.5383	macro: p 0.3628, r 0.3077, f1: 0.3104	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4949
test	acc: 0.5743	macro: p 0.3530, r 0.3055, f1: 0.3156	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5366
global_step: 21001, epoch: 126, loss: 0.228864
global_step: 21002, epoch: 126, loss: 0.246098
global_step: 21003, epoch: 126, loss: 0.252535
global_step: 21004, epoch: 126, loss: 0.227750
global_step: 21005, epoch: 126, loss: 0.274437
global_step: 21006, epoch: 126, loss: 0.217012
global_step: 21007, epoch: 126, loss: 0.224611
global_step: 21008, epoch: 126, loss: 0.200238
global_step: 21009, epoch: 126, loss: 0.260492
global_step: 21010, epoch: 126, loss: 0.254719
global_step: 21011, epoch: 126, loss: 0.261541
global_step: 21012, epoch: 126, loss: 0.223247
global_step: 21013, epoch: 126, loss: 0.287807
global_step: 21014, epoch: 126, loss: 0.201518
global_step: 21015, epoch: 126, loss: 0.182661
global_step: 21016, epoch: 126, loss: 0.244338
global_step: 21017, epoch: 126, loss: 0.234983
global_step: 21018, epoch: 126, loss: 0.239509
global_step: 21019, epoch: 126, loss: 0.250755
global_step: 21020, epoch: 126, loss: 0.230067
global_step: 21021, epoch: 126, loss: 0.288663
global_step: 21022, epoch: 126, loss: 0.231178
global_step: 21023, epoch: 126, loss: 0.291408
global_step: 21024, epoch: 126, loss: 0.262942
global_step: 21025, epoch: 126, loss: 0.240136
global_step: 21026, epoch: 126, loss: 0.317900
global_step: 21027, epoch: 126, loss: 0.207578
global_step: 21028, epoch: 126, loss: 0.290987
global_step: 21029, epoch: 126, loss: 0.221690
global_step: 21030, epoch: 126, loss: 0.252586
global_step: 21031, epoch: 126, loss: 0.279187
global_step: 21032, epoch: 126, loss: 0.267584
global_step: 21033, epoch: 126, loss: 0.254984
global_step: 21034, epoch: 126, loss: 0.331346
global_step: 21035, epoch: 126, loss: 0.235683
global_step: 21036, epoch: 126, loss: 0.292683
global_step: 21037, epoch: 126, loss: 0.271742
global_step: 21038, epoch: 126, loss: 0.251132
global_step: 21039, epoch: 126, loss: 0.325376
global_step: 21040, epoch: 126, loss: 0.038017
epoch: 126
train	acc: 0.9648	macro: p 0.9702, r 0.9451, f1: 0.9569	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9648
dev	acc: 0.5401	macro: p 0.3568, r 0.3104, f1: 0.3047	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4927
test	acc: 0.5655	macro: p 0.3417, r 0.3076, f1: 0.3100	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5301
global_step: 21041, epoch: 127, loss: 0.150690
global_step: 21042, epoch: 127, loss: 0.239112
global_step: 21043, epoch: 127, loss: 0.237345
global_step: 21044, epoch: 127, loss: 0.225798
global_step: 21045, epoch: 127, loss: 0.222002
global_step: 21046, epoch: 127, loss: 0.275888
global_step: 21047, epoch: 127, loss: 0.235085
global_step: 21048, epoch: 127, loss: 0.294785
global_step: 21049, epoch: 127, loss: 0.221610
global_step: 21050, epoch: 127, loss: 0.215938
global_step: 21051, epoch: 127, loss: 0.335929
global_step: 21052, epoch: 127, loss: 0.334274
global_step: 21053, epoch: 127, loss: 0.263877
global_step: 21054, epoch: 127, loss: 0.242589
global_step: 21055, epoch: 127, loss: 0.270474
global_step: 21056, epoch: 127, loss: 0.254368
global_step: 21057, epoch: 127, loss: 0.251230
global_step: 21058, epoch: 127, loss: 0.204518
global_step: 21059, epoch: 127, loss: 0.321360
global_step: 21060, epoch: 127, loss: 0.212902
global_step: 21061, epoch: 127, loss: 0.249362
global_step: 21062, epoch: 127, loss: 0.349714
global_step: 21063, epoch: 127, loss: 0.295143
global_step: 21064, epoch: 127, loss: 0.254650
global_step: 21065, epoch: 127, loss: 0.261569
global_step: 21066, epoch: 127, loss: 0.226557
global_step: 21067, epoch: 127, loss: 0.314807
global_step: 21068, epoch: 127, loss: 0.246843
global_step: 21069, epoch: 127, loss: 0.251686
global_step: 21070, epoch: 127, loss: 0.205977
global_step: 21071, epoch: 127, loss: 0.222910
global_step: 21072, epoch: 127, loss: 0.216087
global_step: 21073, epoch: 127, loss: 0.239134
global_step: 21074, epoch: 127, loss: 0.236143
global_step: 21075, epoch: 127, loss: 0.321010
global_step: 21076, epoch: 127, loss: 0.259212
global_step: 21077, epoch: 127, loss: 0.248992
global_step: 21078, epoch: 127, loss: 0.339143
global_step: 21079, epoch: 127, loss: 0.206753
global_step: 21080, epoch: 127, loss: 0.012180
epoch: 127
train	acc: 0.9674	macro: p 0.9726, r 0.9505, f1: 0.9611	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9674
dev	acc: 0.5401	macro: p 0.3663, r 0.3096, f1: 0.3103	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4957
test	acc: 0.5774	macro: p 0.3427, r 0.3076, f1: 0.3131	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5402
global_step: 21081, epoch: 128, loss: 0.273802
global_step: 21082, epoch: 128, loss: 0.309236
global_step: 21083, epoch: 128, loss: 0.243683
global_step: 21084, epoch: 128, loss: 0.251410
global_step: 21085, epoch: 128, loss: 0.287543
global_step: 21086, epoch: 128, loss: 0.253151
global_step: 21087, epoch: 128, loss: 0.207783
global_step: 21088, epoch: 128, loss: 0.251538
global_step: 21089, epoch: 128, loss: 0.264348
global_step: 21090, epoch: 128, loss: 0.266921
global_step: 21091, epoch: 128, loss: 0.296585
global_step: 21092, epoch: 128, loss: 0.258704
global_step: 21093, epoch: 128, loss: 0.222370
global_step: 21094, epoch: 128, loss: 0.283383
global_step: 21095, epoch: 128, loss: 0.256856
global_step: 21096, epoch: 128, loss: 0.275847
global_step: 21097, epoch: 128, loss: 0.231244
global_step: 21098, epoch: 128, loss: 0.300727
global_step: 21099, epoch: 128, loss: 0.218484
global_step: 21100, epoch: 128, loss: 0.250231
global_step: 21101, epoch: 128, loss: 0.309918
global_step: 21102, epoch: 128, loss: 0.209048
global_step: 21103, epoch: 128, loss: 0.179177
global_step: 21104, epoch: 128, loss: 0.225215
global_step: 21105, epoch: 128, loss: 0.284102
global_step: 21106, epoch: 128, loss: 0.300632
global_step: 21107, epoch: 128, loss: 0.320302
global_step: 21108, epoch: 128, loss: 0.215493
global_step: 21109, epoch: 128, loss: 0.318430
global_step: 21110, epoch: 128, loss: 0.263218
global_step: 21111, epoch: 128, loss: 0.294760
global_step: 21112, epoch: 128, loss: 0.221422
global_step: 21113, epoch: 128, loss: 0.211526
global_step: 21114, epoch: 128, loss: 0.260287
global_step: 21115, epoch: 128, loss: 0.245693
global_step: 21116, epoch: 128, loss: 0.299619
global_step: 21117, epoch: 128, loss: 0.279195
global_step: 21118, epoch: 128, loss: 0.315123
global_step: 21119, epoch: 128, loss: 0.298079
global_step: 21120, epoch: 128, loss: 0.882665
epoch: 128
train	acc: 0.9680	macro: p 0.9714, r 0.9524, f1: 0.9615	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5293	macro: p 0.3659, r 0.3176, f1: 0.3219	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4954
test	acc: 0.5693	macro: p 0.3419, r 0.3160, f1: 0.3219	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5414
global_step: 21121, epoch: 129, loss: 0.245877
global_step: 21122, epoch: 129, loss: 0.249952
global_step: 21123, epoch: 129, loss: 0.240221
global_step: 21124, epoch: 129, loss: 0.230417
global_step: 21125, epoch: 129, loss: 0.240384
global_step: 21126, epoch: 129, loss: 0.275136
global_step: 21127, epoch: 129, loss: 0.185594
global_step: 21128, epoch: 129, loss: 0.216724
global_step: 21129, epoch: 129, loss: 0.260418
global_step: 21130, epoch: 129, loss: 0.380416
global_step: 21131, epoch: 129, loss: 0.243833
global_step: 21132, epoch: 129, loss: 0.251713
global_step: 21133, epoch: 129, loss: 0.247779
global_step: 21134, epoch: 129, loss: 0.198111
global_step: 21135, epoch: 129, loss: 0.212092
global_step: 21136, epoch: 129, loss: 0.284453
global_step: 21137, epoch: 129, loss: 0.249021
global_step: 21138, epoch: 129, loss: 0.293797
global_step: 21139, epoch: 129, loss: 0.333422
global_step: 21140, epoch: 129, loss: 0.295911
global_step: 21141, epoch: 129, loss: 0.250837
global_step: 21142, epoch: 129, loss: 0.242790
global_step: 21143, epoch: 129, loss: 0.257780
global_step: 21144, epoch: 129, loss: 0.172821
global_step: 21145, epoch: 129, loss: 0.293341
global_step: 21146, epoch: 129, loss: 0.204518
global_step: 21147, epoch: 129, loss: 0.208336
global_step: 21148, epoch: 129, loss: 0.245362
global_step: 21149, epoch: 129, loss: 0.254368
global_step: 21150, epoch: 129, loss: 0.176208
global_step: 21151, epoch: 129, loss: 0.212063
global_step: 21152, epoch: 129, loss: 0.197497
global_step: 21153, epoch: 129, loss: 0.278648
global_step: 21154, epoch: 129, loss: 0.285408
global_step: 21155, epoch: 129, loss: 0.197397
global_step: 21156, epoch: 129, loss: 0.291463
global_step: 21157, epoch: 129, loss: 0.282938
global_step: 21158, epoch: 129, loss: 0.268284
global_step: 21159, epoch: 129, loss: 0.286991
global_step: 21160, epoch: 129, loss: 0.021881
epoch: 129
train	acc: 0.9668	macro: p 0.9712, r 0.9502, f1: 0.9602	micro: p 0.9668, r 0.9668, f1 0.9668	weighted_f1:0.9668
dev	acc: 0.5374	macro: p 0.3778, r 0.3121, f1: 0.3157	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4953
test	acc: 0.5797	macro: p 0.3526, r 0.3103, f1: 0.3180	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5421
global_step: 21161, epoch: 130, loss: 0.214392
global_step: 21162, epoch: 130, loss: 0.278134
global_step: 21163, epoch: 130, loss: 0.232992
global_step: 21164, epoch: 130, loss: 0.272945
global_step: 21165, epoch: 130, loss: 0.230497
global_step: 21166, epoch: 130, loss: 0.337360
global_step: 21167, epoch: 130, loss: 0.261245
global_step: 21168, epoch: 130, loss: 0.219151
global_step: 21169, epoch: 130, loss: 0.235286
global_step: 21170, epoch: 130, loss: 0.267465
global_step: 21171, epoch: 130, loss: 0.225979
global_step: 21172, epoch: 130, loss: 0.283373
global_step: 21173, epoch: 130, loss: 0.222271
global_step: 21174, epoch: 130, loss: 0.302979
global_step: 21175, epoch: 130, loss: 0.348174
global_step: 21176, epoch: 130, loss: 0.182799
global_step: 21177, epoch: 130, loss: 0.236551
global_step: 21178, epoch: 130, loss: 0.234811
global_step: 21179, epoch: 130, loss: 0.239902
global_step: 21180, epoch: 130, loss: 0.261108
global_step: 21181, epoch: 130, loss: 0.211369
global_step: 21182, epoch: 130, loss: 0.226072
global_step: 21183, epoch: 130, loss: 0.220231
global_step: 21184, epoch: 130, loss: 0.290739
global_step: 21185, epoch: 130, loss: 0.316398
global_step: 21186, epoch: 130, loss: 0.215926
global_step: 21187, epoch: 130, loss: 0.242034
global_step: 21188, epoch: 130, loss: 0.325748
global_step: 21189, epoch: 130, loss: 0.311930
global_step: 21190, epoch: 130, loss: 0.164854
global_step: 21191, epoch: 130, loss: 0.296719
global_step: 21192, epoch: 130, loss: 0.267104
global_step: 21193, epoch: 130, loss: 0.228513
global_step: 21194, epoch: 130, loss: 0.293291
global_step: 21195, epoch: 130, loss: 0.221846
global_step: 21196, epoch: 130, loss: 0.299893
global_step: 21197, epoch: 130, loss: 0.260460
global_step: 21198, epoch: 130, loss: 0.241540
global_step: 21199, epoch: 130, loss: 0.208967
global_step: 21200, epoch: 130, loss: 0.047780
epoch: 130
train	acc: 0.9661	macro: p 0.9705, r 0.9496, f1: 0.9596	micro: p 0.9661, r 0.9661, f1 0.9661	weighted_f1:0.9661
dev	acc: 0.5410	macro: p 0.3599, r 0.3123, f1: 0.3114	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4980
test	acc: 0.5797	macro: p 0.3491, r 0.3131, f1: 0.3195	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5443
global_step: 21201, epoch: 131, loss: 0.259067
global_step: 21202, epoch: 131, loss: 0.208867
global_step: 21203, epoch: 131, loss: 0.207893
global_step: 21204, epoch: 131, loss: 0.166178
global_step: 21205, epoch: 131, loss: 0.311547
global_step: 21206, epoch: 131, loss: 0.193186
global_step: 21207, epoch: 131, loss: 0.159143
global_step: 21208, epoch: 131, loss: 0.191895
global_step: 21209, epoch: 131, loss: 0.215878
global_step: 21210, epoch: 131, loss: 0.245078
global_step: 21211, epoch: 131, loss: 0.250994
global_step: 21212, epoch: 131, loss: 0.234156
global_step: 21213, epoch: 131, loss: 0.272035
global_step: 21214, epoch: 131, loss: 0.191650
global_step: 21215, epoch: 131, loss: 0.242627
global_step: 21216, epoch: 131, loss: 0.252069
global_step: 21217, epoch: 131, loss: 0.242891
global_step: 21218, epoch: 131, loss: 0.236385
global_step: 21219, epoch: 131, loss: 0.167016
global_step: 21220, epoch: 131, loss: 0.319020
global_step: 21221, epoch: 131, loss: 0.186090
global_step: 21222, epoch: 131, loss: 0.223959
global_step: 21223, epoch: 131, loss: 0.256031
global_step: 21224, epoch: 131, loss: 0.318594
global_step: 21225, epoch: 131, loss: 0.204764
global_step: 21226, epoch: 131, loss: 0.256258
global_step: 21227, epoch: 131, loss: 0.283892
global_step: 21228, epoch: 131, loss: 0.252378
global_step: 21229, epoch: 131, loss: 0.226734
global_step: 21230, epoch: 131, loss: 0.200649
global_step: 21231, epoch: 131, loss: 0.247830
global_step: 21232, epoch: 131, loss: 0.229672
global_step: 21233, epoch: 131, loss: 0.275855
global_step: 21234, epoch: 131, loss: 0.266379
global_step: 21235, epoch: 131, loss: 0.305323
global_step: 21236, epoch: 131, loss: 0.293417
global_step: 21237, epoch: 131, loss: 0.236458
global_step: 21238, epoch: 131, loss: 0.222772
global_step: 21239, epoch: 131, loss: 0.225595
global_step: 21240, epoch: 131, loss: 0.023148
epoch: 131
train	acc: 0.9673	macro: p 0.9720, r 0.9511, f1: 0.9611	micro: p 0.9673, r 0.9673, f1 0.9673	weighted_f1:0.9673
dev	acc: 0.5437	macro: p 0.3852, r 0.3128, f1: 0.3171	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4971
test	acc: 0.5824	macro: p 0.3617, r 0.3113, f1: 0.3221	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5444
global_step: 21241, epoch: 132, loss: 0.203913
global_step: 21242, epoch: 132, loss: 0.235390
global_step: 21243, epoch: 132, loss: 0.250100
global_step: 21244, epoch: 132, loss: 0.184577
global_step: 21245, epoch: 132, loss: 0.278868
global_step: 21246, epoch: 132, loss: 0.261714
global_step: 21247, epoch: 132, loss: 0.297985
global_step: 21248, epoch: 132, loss: 0.236378
global_step: 21249, epoch: 132, loss: 0.250709
global_step: 21250, epoch: 132, loss: 0.274913
global_step: 21251, epoch: 132, loss: 0.202085
global_step: 21252, epoch: 132, loss: 0.276141
global_step: 21253, epoch: 132, loss: 0.230863
global_step: 21254, epoch: 132, loss: 0.251623
global_step: 21255, epoch: 132, loss: 0.204676
global_step: 21256, epoch: 132, loss: 0.234862
global_step: 21257, epoch: 132, loss: 0.188249
global_step: 21258, epoch: 132, loss: 0.234937
global_step: 21259, epoch: 132, loss: 0.289339
global_step: 21260, epoch: 132, loss: 0.245073
global_step: 21261, epoch: 132, loss: 0.171953
global_step: 21262, epoch: 132, loss: 0.284326
global_step: 21263, epoch: 132, loss: 0.249983
global_step: 21264, epoch: 132, loss: 0.278905
global_step: 21265, epoch: 132, loss: 0.273523
global_step: 21266, epoch: 132, loss: 0.311026
global_step: 21267, epoch: 132, loss: 0.291597
global_step: 21268, epoch: 132, loss: 0.269807
global_step: 21269, epoch: 132, loss: 0.236664
global_step: 21270, epoch: 132, loss: 0.242697
global_step: 21271, epoch: 132, loss: 0.231524
global_step: 21272, epoch: 132, loss: 0.309978
global_step: 21273, epoch: 132, loss: 0.180612
global_step: 21274, epoch: 132, loss: 0.260841
global_step: 21275, epoch: 132, loss: 0.288630
global_step: 21276, epoch: 132, loss: 0.209898
global_step: 21277, epoch: 132, loss: 0.285393
global_step: 21278, epoch: 132, loss: 0.243386
global_step: 21279, epoch: 132, loss: 0.236404
global_step: 21280, epoch: 132, loss: 1.161774
epoch: 132
train	acc: 0.9671	macro: p 0.9712, r 0.9507, f1: 0.9604	micro: p 0.9671, r 0.9671, f1 0.9671	weighted_f1:0.9671
dev	acc: 0.5347	macro: p 0.3649, r 0.3094, f1: 0.3079	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4927
test	acc: 0.5713	macro: p 0.3487, r 0.3129, f1: 0.3193	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5386
global_step: 21281, epoch: 133, loss: 0.217819
global_step: 21282, epoch: 133, loss: 0.198150
global_step: 21283, epoch: 133, loss: 0.209197
global_step: 21284, epoch: 133, loss: 0.212029
global_step: 21285, epoch: 133, loss: 0.249599
global_step: 21286, epoch: 133, loss: 0.184495
global_step: 21287, epoch: 133, loss: 0.246181
global_step: 21288, epoch: 133, loss: 0.163928
global_step: 21289, epoch: 133, loss: 0.306202
global_step: 21290, epoch: 133, loss: 0.187415
global_step: 21291, epoch: 133, loss: 0.283554
global_step: 21292, epoch: 133, loss: 0.239992
global_step: 21293, epoch: 133, loss: 0.165632
global_step: 21294, epoch: 133, loss: 0.209381
global_step: 21295, epoch: 133, loss: 0.232342
global_step: 21296, epoch: 133, loss: 0.201218
global_step: 21297, epoch: 133, loss: 0.251936
global_step: 21298, epoch: 133, loss: 0.241753
global_step: 21299, epoch: 133, loss: 0.264657
global_step: 21300, epoch: 133, loss: 0.260563
global_step: 21301, epoch: 133, loss: 0.230356
global_step: 21302, epoch: 133, loss: 0.234947
global_step: 21303, epoch: 133, loss: 0.308992
global_step: 21304, epoch: 133, loss: 0.291210
global_step: 21305, epoch: 133, loss: 0.240867
global_step: 21306, epoch: 133, loss: 0.274242
global_step: 21307, epoch: 133, loss: 0.235807
global_step: 21308, epoch: 133, loss: 0.260905
global_step: 21309, epoch: 133, loss: 0.279617
global_step: 21310, epoch: 133, loss: 0.186707
global_step: 21311, epoch: 133, loss: 0.288518
global_step: 21312, epoch: 133, loss: 0.277782
global_step: 21313, epoch: 133, loss: 0.326636
global_step: 21314, epoch: 133, loss: 0.244882
global_step: 21315, epoch: 133, loss: 0.245165
global_step: 21316, epoch: 133, loss: 0.250903
global_step: 21317, epoch: 133, loss: 0.259605
global_step: 21318, epoch: 133, loss: 0.255316
global_step: 21319, epoch: 133, loss: 0.253392
global_step: 21320, epoch: 133, loss: 0.174626
epoch: 133
train	acc: 0.9670	macro: p 0.9707, r 0.9510, f1: 0.9604	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5275	macro: p 0.3752, r 0.3197, f1: 0.3267	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4947
test	acc: 0.5690	macro: p 0.3413, r 0.3174, f1: 0.3237	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5432
global_step: 21321, epoch: 134, loss: 0.210292
global_step: 21322, epoch: 134, loss: 0.296720
global_step: 21323, epoch: 134, loss: 0.196533
global_step: 21324, epoch: 134, loss: 0.290089
global_step: 21325, epoch: 134, loss: 0.190454
global_step: 21326, epoch: 134, loss: 0.253598
global_step: 21327, epoch: 134, loss: 0.250827
global_step: 21328, epoch: 134, loss: 0.277933
global_step: 21329, epoch: 134, loss: 0.226581
global_step: 21330, epoch: 134, loss: 0.281287
global_step: 21331, epoch: 134, loss: 0.189154
global_step: 21332, epoch: 134, loss: 0.266348
global_step: 21333, epoch: 134, loss: 0.146272
global_step: 21334, epoch: 134, loss: 0.259019
global_step: 21335, epoch: 134, loss: 0.230626
global_step: 21336, epoch: 134, loss: 0.196440
global_step: 21337, epoch: 134, loss: 0.325734
global_step: 21338, epoch: 134, loss: 0.255997
global_step: 21339, epoch: 134, loss: 0.224791
global_step: 21340, epoch: 134, loss: 0.287419
global_step: 21341, epoch: 134, loss: 0.253827
global_step: 21342, epoch: 134, loss: 0.246469
global_step: 21343, epoch: 134, loss: 0.208021
global_step: 21344, epoch: 134, loss: 0.212951
global_step: 21345, epoch: 134, loss: 0.229227
global_step: 21346, epoch: 134, loss: 0.171542
global_step: 21347, epoch: 134, loss: 0.262331
global_step: 21348, epoch: 134, loss: 0.257264
global_step: 21349, epoch: 134, loss: 0.193962
global_step: 21350, epoch: 134, loss: 0.290891
global_step: 21351, epoch: 134, loss: 0.324517
global_step: 21352, epoch: 134, loss: 0.239766
global_step: 21353, epoch: 134, loss: 0.269370
global_step: 21354, epoch: 134, loss: 0.193895
global_step: 21355, epoch: 134, loss: 0.127796
global_step: 21356, epoch: 134, loss: 0.181703
global_step: 21357, epoch: 134, loss: 0.241999
global_step: 21358, epoch: 134, loss: 0.283522
global_step: 21359, epoch: 134, loss: 0.198630
global_step: 21360, epoch: 134, loss: 0.179216
epoch: 134
train	acc: 0.9674	macro: p 0.9712, r 0.9504, f1: 0.9603	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9674
dev	acc: 0.5329	macro: p 0.3697, r 0.3046, f1: 0.3009	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4856
test	acc: 0.5736	macro: p 0.3626, r 0.3114, f1: 0.3160	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5351
global_step: 21361, epoch: 135, loss: 0.255669
global_step: 21362, epoch: 135, loss: 0.185176
global_step: 21363, epoch: 135, loss: 0.263530
global_step: 21364, epoch: 135, loss: 0.191974
global_step: 21365, epoch: 135, loss: 0.225146
global_step: 21366, epoch: 135, loss: 0.184159
global_step: 21367, epoch: 135, loss: 0.251710
global_step: 21368, epoch: 135, loss: 0.210819
global_step: 21369, epoch: 135, loss: 0.239972
global_step: 21370, epoch: 135, loss: 0.202668
global_step: 21371, epoch: 135, loss: 0.280982
global_step: 21372, epoch: 135, loss: 0.176949
global_step: 21373, epoch: 135, loss: 0.250762
global_step: 21374, epoch: 135, loss: 0.273855
global_step: 21375, epoch: 135, loss: 0.237782
global_step: 21376, epoch: 135, loss: 0.262676
global_step: 21377, epoch: 135, loss: 0.282816
global_step: 21378, epoch: 135, loss: 0.226426
global_step: 21379, epoch: 135, loss: 0.247304
global_step: 21380, epoch: 135, loss: 0.248716
global_step: 21381, epoch: 135, loss: 0.253314
global_step: 21382, epoch: 135, loss: 0.302593
global_step: 21383, epoch: 135, loss: 0.186155
global_step: 21384, epoch: 135, loss: 0.250446
global_step: 21385, epoch: 135, loss: 0.308445
global_step: 21386, epoch: 135, loss: 0.179806
global_step: 21387, epoch: 135, loss: 0.275501
global_step: 21388, epoch: 135, loss: 0.314694
global_step: 21389, epoch: 135, loss: 0.254652
global_step: 21390, epoch: 135, loss: 0.167820
global_step: 21391, epoch: 135, loss: 0.239250
global_step: 21392, epoch: 135, loss: 0.265587
global_step: 21393, epoch: 135, loss: 0.299794
global_step: 21394, epoch: 135, loss: 0.328760
global_step: 21395, epoch: 135, loss: 0.273766
global_step: 21396, epoch: 135, loss: 0.203891
global_step: 21397, epoch: 135, loss: 0.235135
global_step: 21398, epoch: 135, loss: 0.220336
global_step: 21399, epoch: 135, loss: 0.220622
global_step: 21400, epoch: 135, loss: 0.376140
epoch: 135
train	acc: 0.9662	macro: p 0.9710, r 0.9479, f1: 0.9589	micro: p 0.9662, r 0.9662, f1 0.9662	weighted_f1:0.9662
dev	acc: 0.5383	macro: p 0.3651, r 0.3040, f1: 0.3005	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4882
test	acc: 0.5801	macro: p 0.3588, r 0.3099, f1: 0.3146	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5382
global_step: 21401, epoch: 136, loss: 0.211624
global_step: 21402, epoch: 136, loss: 0.264525
global_step: 21403, epoch: 136, loss: 0.202560
global_step: 21404, epoch: 136, loss: 0.230906
global_step: 21405, epoch: 136, loss: 0.199515
global_step: 21406, epoch: 136, loss: 0.220562
global_step: 21407, epoch: 136, loss: 0.266507
global_step: 21408, epoch: 136, loss: 0.199428
global_step: 21409, epoch: 136, loss: 0.199692
global_step: 21410, epoch: 136, loss: 0.294778
global_step: 21411, epoch: 136, loss: 0.230060
global_step: 21412, epoch: 136, loss: 0.199400
global_step: 21413, epoch: 136, loss: 0.246885
global_step: 21414, epoch: 136, loss: 0.251892
global_step: 21415, epoch: 136, loss: 0.239761
global_step: 21416, epoch: 136, loss: 0.263841
global_step: 21417, epoch: 136, loss: 0.253956
global_step: 21418, epoch: 136, loss: 0.318416
global_step: 21419, epoch: 136, loss: 0.262271
global_step: 21420, epoch: 136, loss: 0.207871
global_step: 21421, epoch: 136, loss: 0.172959
global_step: 21422, epoch: 136, loss: 0.188566
global_step: 21423, epoch: 136, loss: 0.267192
global_step: 21424, epoch: 136, loss: 0.208622
global_step: 21425, epoch: 136, loss: 0.182860
global_step: 21426, epoch: 136, loss: 0.269759
global_step: 21427, epoch: 136, loss: 0.246339
global_step: 21428, epoch: 136, loss: 0.189194
global_step: 21429, epoch: 136, loss: 0.237363
global_step: 21430, epoch: 136, loss: 0.259670
global_step: 21431, epoch: 136, loss: 0.288351
global_step: 21432, epoch: 136, loss: 0.248991
global_step: 21433, epoch: 136, loss: 0.343581
global_step: 21434, epoch: 136, loss: 0.265558
global_step: 21435, epoch: 136, loss: 0.205476
global_step: 21436, epoch: 136, loss: 0.242636
global_step: 21437, epoch: 136, loss: 0.254326
global_step: 21438, epoch: 136, loss: 0.251198
global_step: 21439, epoch: 136, loss: 0.271551
global_step: 21440, epoch: 136, loss: 0.055010
epoch: 136
train	acc: 0.9677	macro: p 0.9713, r 0.9513, f1: 0.9609	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5347	macro: p 0.3753, r 0.3146, f1: 0.3191	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4936
test	acc: 0.5789	macro: p 0.3608, r 0.3151, f1: 0.3233	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5427
global_step: 21441, epoch: 137, loss: 0.201347
global_step: 21442, epoch: 137, loss: 0.205961
global_step: 21443, epoch: 137, loss: 0.147473
global_step: 21444, epoch: 137, loss: 0.268084
global_step: 21445, epoch: 137, loss: 0.243379
global_step: 21446, epoch: 137, loss: 0.246157
global_step: 21447, epoch: 137, loss: 0.282984
global_step: 21448, epoch: 137, loss: 0.276127
global_step: 21449, epoch: 137, loss: 0.247184
global_step: 21450, epoch: 137, loss: 0.235911
global_step: 21451, epoch: 137, loss: 0.198864
global_step: 21452, epoch: 137, loss: 0.245071
global_step: 21453, epoch: 137, loss: 0.277908
global_step: 21454, epoch: 137, loss: 0.186845
global_step: 21455, epoch: 137, loss: 0.242571
global_step: 21456, epoch: 137, loss: 0.253939
global_step: 21457, epoch: 137, loss: 0.176611
global_step: 21458, epoch: 137, loss: 0.251130
global_step: 21459, epoch: 137, loss: 0.289746
global_step: 21460, epoch: 137, loss: 0.265905
global_step: 21461, epoch: 137, loss: 0.231218
global_step: 21462, epoch: 137, loss: 0.260951
global_step: 21463, epoch: 137, loss: 0.178749
global_step: 21464, epoch: 137, loss: 0.215658
global_step: 21465, epoch: 137, loss: 0.228887
global_step: 21466, epoch: 137, loss: 0.258985
global_step: 21467, epoch: 137, loss: 0.240586
global_step: 21468, epoch: 137, loss: 0.219021
global_step: 21469, epoch: 137, loss: 0.187686
global_step: 21470, epoch: 137, loss: 0.217955
global_step: 21471, epoch: 137, loss: 0.184638
global_step: 21472, epoch: 137, loss: 0.204482
global_step: 21473, epoch: 137, loss: 0.269049
global_step: 21474, epoch: 137, loss: 0.174565
global_step: 21475, epoch: 137, loss: 0.222567
global_step: 21476, epoch: 137, loss: 0.231506
global_step: 21477, epoch: 137, loss: 0.270866
global_step: 21478, epoch: 137, loss: 0.223704
global_step: 21479, epoch: 137, loss: 0.281473
global_step: 21480, epoch: 137, loss: 0.175024
epoch: 137
train	acc: 0.9675	macro: p 0.9707, r 0.9537, f1: 0.9619	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5329	macro: p 0.3509, r 0.3042, f1: 0.3051	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4895
test	acc: 0.5847	macro: p 0.3641, r 0.3178, f1: 0.3262	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5484
global_step: 21481, epoch: 138, loss: 0.170722
global_step: 21482, epoch: 138, loss: 0.208524
global_step: 21483, epoch: 138, loss: 0.236423
global_step: 21484, epoch: 138, loss: 0.187642
global_step: 21485, epoch: 138, loss: 0.198708
global_step: 21486, epoch: 138, loss: 0.180655
global_step: 21487, epoch: 138, loss: 0.209954
global_step: 21488, epoch: 138, loss: 0.255940
global_step: 21489, epoch: 138, loss: 0.245200
global_step: 21490, epoch: 138, loss: 0.241465
global_step: 21491, epoch: 138, loss: 0.238188
global_step: 21492, epoch: 138, loss: 0.215186
global_step: 21493, epoch: 138, loss: 0.196448
global_step: 21494, epoch: 138, loss: 0.233529
global_step: 21495, epoch: 138, loss: 0.180014
global_step: 21496, epoch: 138, loss: 0.266402
global_step: 21497, epoch: 138, loss: 0.262639
global_step: 21498, epoch: 138, loss: 0.296281
global_step: 21499, epoch: 138, loss: 0.293618
global_step: 21500, epoch: 138, loss: 0.243521
global_step: 21501, epoch: 138, loss: 0.225191
global_step: 21502, epoch: 138, loss: 0.277496
global_step: 21503, epoch: 138, loss: 0.229866
global_step: 21504, epoch: 138, loss: 0.226917
global_step: 21505, epoch: 138, loss: 0.210846
global_step: 21506, epoch: 138, loss: 0.211089
global_step: 21507, epoch: 138, loss: 0.259297
global_step: 21508, epoch: 138, loss: 0.184077
global_step: 21509, epoch: 138, loss: 0.244799
global_step: 21510, epoch: 138, loss: 0.298630
global_step: 21511, epoch: 138, loss: 0.247990
global_step: 21512, epoch: 138, loss: 0.229868
global_step: 21513, epoch: 138, loss: 0.262472
global_step: 21514, epoch: 138, loss: 0.140236
global_step: 21515, epoch: 138, loss: 0.198384
global_step: 21516, epoch: 138, loss: 0.229389
global_step: 21517, epoch: 138, loss: 0.233007
global_step: 21518, epoch: 138, loss: 0.256967
global_step: 21519, epoch: 138, loss: 0.264712
global_step: 21520, epoch: 138, loss: 0.128154
epoch: 138
train	acc: 0.9675	macro: p 0.9728, r 0.9532, f1: 0.9625	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5338	macro: p 0.3575, r 0.3025, f1: 0.2983	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4854
test	acc: 0.5770	macro: p 0.3520, r 0.3082, f1: 0.3121	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5375
global_step: 21521, epoch: 139, loss: 0.287014
global_step: 21522, epoch: 139, loss: 0.280814
global_step: 21523, epoch: 139, loss: 0.210341
global_step: 21524, epoch: 139, loss: 0.283920
global_step: 21525, epoch: 139, loss: 0.224425
global_step: 21526, epoch: 139, loss: 0.248757
global_step: 21527, epoch: 139, loss: 0.208332
global_step: 21528, epoch: 139, loss: 0.244410
global_step: 21529, epoch: 139, loss: 0.190211
global_step: 21530, epoch: 139, loss: 0.248762
global_step: 21531, epoch: 139, loss: 0.163604
global_step: 21532, epoch: 139, loss: 0.316149
global_step: 21533, epoch: 139, loss: 0.224176
global_step: 21534, epoch: 139, loss: 0.231449
global_step: 21535, epoch: 139, loss: 0.232336
global_step: 21536, epoch: 139, loss: 0.220784
global_step: 21537, epoch: 139, loss: 0.223956
global_step: 21538, epoch: 139, loss: 0.210768
global_step: 21539, epoch: 139, loss: 0.225152
global_step: 21540, epoch: 139, loss: 0.234577
global_step: 21541, epoch: 139, loss: 0.211204
global_step: 21542, epoch: 139, loss: 0.246222
global_step: 21543, epoch: 139, loss: 0.218259
global_step: 21544, epoch: 139, loss: 0.219656
global_step: 21545, epoch: 139, loss: 0.256273
global_step: 21546, epoch: 139, loss: 0.172468
global_step: 21547, epoch: 139, loss: 0.252092
global_step: 21548, epoch: 139, loss: 0.277601
global_step: 21549, epoch: 139, loss: 0.182373
global_step: 21550, epoch: 139, loss: 0.269742
global_step: 21551, epoch: 139, loss: 0.248889
global_step: 21552, epoch: 139, loss: 0.222994
global_step: 21553, epoch: 139, loss: 0.332429
global_step: 21554, epoch: 139, loss: 0.187501
global_step: 21555, epoch: 139, loss: 0.151763
global_step: 21556, epoch: 139, loss: 0.237537
global_step: 21557, epoch: 139, loss: 0.225997
global_step: 21558, epoch: 139, loss: 0.214448
global_step: 21559, epoch: 139, loss: 0.213750
global_step: 21560, epoch: 139, loss: 0.038131
epoch: 139
train	acc: 0.9678	macro: p 0.9729, r 0.9520, f1: 0.9620	micro: p 0.9678, r 0.9678, f1 0.9678	weighted_f1:0.9678
dev	acc: 0.5347	macro: p 0.3669, r 0.3050, f1: 0.3056	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4895
test	acc: 0.5847	macro: p 0.3512, r 0.3131, f1: 0.3195	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5460
global_step: 21561, epoch: 140, loss: 0.215102
global_step: 21562, epoch: 140, loss: 0.178842
global_step: 21563, epoch: 140, loss: 0.175455
global_step: 21564, epoch: 140, loss: 0.215491
global_step: 21565, epoch: 140, loss: 0.255443
global_step: 21566, epoch: 140, loss: 0.241346
global_step: 21567, epoch: 140, loss: 0.290401
global_step: 21568, epoch: 140, loss: 0.233841
global_step: 21569, epoch: 140, loss: 0.227772
global_step: 21570, epoch: 140, loss: 0.274097
global_step: 21571, epoch: 140, loss: 0.343581
global_step: 21572, epoch: 140, loss: 0.220302
global_step: 21573, epoch: 140, loss: 0.284987
global_step: 21574, epoch: 140, loss: 0.224687
global_step: 21575, epoch: 140, loss: 0.207352
global_step: 21576, epoch: 140, loss: 0.235803
global_step: 21577, epoch: 140, loss: 0.257616
global_step: 21578, epoch: 140, loss: 0.194021
global_step: 21579, epoch: 140, loss: 0.290008
global_step: 21580, epoch: 140, loss: 0.205723
global_step: 21581, epoch: 140, loss: 0.246042
global_step: 21582, epoch: 140, loss: 0.282133
global_step: 21583, epoch: 140, loss: 0.241374
global_step: 21584, epoch: 140, loss: 0.254885
global_step: 21585, epoch: 140, loss: 0.192961
global_step: 21586, epoch: 140, loss: 0.255138
global_step: 21587, epoch: 140, loss: 0.319482
global_step: 21588, epoch: 140, loss: 0.259954
global_step: 21589, epoch: 140, loss: 0.185584
global_step: 21590, epoch: 140, loss: 0.201789
global_step: 21591, epoch: 140, loss: 0.255154
global_step: 21592, epoch: 140, loss: 0.222188
global_step: 21593, epoch: 140, loss: 0.247157
global_step: 21594, epoch: 140, loss: 0.233354
global_step: 21595, epoch: 140, loss: 0.364234
global_step: 21596, epoch: 140, loss: 0.247309
global_step: 21597, epoch: 140, loss: 0.218730
global_step: 21598, epoch: 140, loss: 0.220270
global_step: 21599, epoch: 140, loss: 0.263755
global_step: 21600, epoch: 140, loss: 0.018717
epoch: 140
train	acc: 0.9687	macro: p 0.9733, r 0.9532, f1: 0.9628	micro: p 0.9687, r 0.9687, f1 0.9687	weighted_f1:0.9687
dev	acc: 0.5419	macro: p 0.4043, r 0.3160, f1: 0.3222	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4973
test	acc: 0.5874	macro: p 0.3725, r 0.3170, f1: 0.3256	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5478
global_step: 21601, epoch: 141, loss: 0.178062
global_step: 21602, epoch: 141, loss: 0.180801
global_step: 21603, epoch: 141, loss: 0.182378
global_step: 21604, epoch: 141, loss: 0.263666
global_step: 21605, epoch: 141, loss: 0.240304
global_step: 21606, epoch: 141, loss: 0.197505
global_step: 21607, epoch: 141, loss: 0.224597
global_step: 21608, epoch: 141, loss: 0.264701
global_step: 21609, epoch: 141, loss: 0.194582
global_step: 21610, epoch: 141, loss: 0.221111
global_step: 21611, epoch: 141, loss: 0.261333
global_step: 21612, epoch: 141, loss: 0.259367
global_step: 21613, epoch: 141, loss: 0.313237
global_step: 21614, epoch: 141, loss: 0.240739
global_step: 21615, epoch: 141, loss: 0.279636
global_step: 21616, epoch: 141, loss: 0.194778
global_step: 21617, epoch: 141, loss: 0.225944
global_step: 21618, epoch: 141, loss: 0.263472
global_step: 21619, epoch: 141, loss: 0.208498
global_step: 21620, epoch: 141, loss: 0.217980
global_step: 21621, epoch: 141, loss: 0.274561
global_step: 21622, epoch: 141, loss: 0.232058
global_step: 21623, epoch: 141, loss: 0.245219
global_step: 21624, epoch: 141, loss: 0.239059
global_step: 21625, epoch: 141, loss: 0.248996
global_step: 21626, epoch: 141, loss: 0.305019
global_step: 21627, epoch: 141, loss: 0.245121
global_step: 21628, epoch: 141, loss: 0.249562
global_step: 21629, epoch: 141, loss: 0.238968
global_step: 21630, epoch: 141, loss: 0.262777
global_step: 21631, epoch: 141, loss: 0.275740
global_step: 21632, epoch: 141, loss: 0.277542
global_step: 21633, epoch: 141, loss: 0.248050
global_step: 21634, epoch: 141, loss: 0.183645
global_step: 21635, epoch: 141, loss: 0.239995
global_step: 21636, epoch: 141, loss: 0.220622
global_step: 21637, epoch: 141, loss: 0.194343
global_step: 21638, epoch: 141, loss: 0.264870
global_step: 21639, epoch: 141, loss: 0.277003
global_step: 21640, epoch: 141, loss: 0.034158
epoch: 141
train	acc: 0.9685	macro: p 0.9710, r 0.9552, f1: 0.9628	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5329	macro: p 0.3661, r 0.3144, f1: 0.3197	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4947
test	acc: 0.5782	macro: p 0.3613, r 0.3212, f1: 0.3291	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5476
global_step: 21641, epoch: 142, loss: 0.217511
global_step: 21642, epoch: 142, loss: 0.225567
global_step: 21643, epoch: 142, loss: 0.248267
global_step: 21644, epoch: 142, loss: 0.287186
global_step: 21645, epoch: 142, loss: 0.187579
global_step: 21646, epoch: 142, loss: 0.233269
global_step: 21647, epoch: 142, loss: 0.176850
global_step: 21648, epoch: 142, loss: 0.206411
global_step: 21649, epoch: 142, loss: 0.225716
global_step: 21650, epoch: 142, loss: 0.249229
global_step: 21651, epoch: 142, loss: 0.162618
global_step: 21652, epoch: 142, loss: 0.297616
global_step: 21653, epoch: 142, loss: 0.280898
global_step: 21654, epoch: 142, loss: 0.224668
global_step: 21655, epoch: 142, loss: 0.270276
global_step: 21656, epoch: 142, loss: 0.232887
global_step: 21657, epoch: 142, loss: 0.184742
global_step: 21658, epoch: 142, loss: 0.147730
global_step: 21659, epoch: 142, loss: 0.243090
global_step: 21660, epoch: 142, loss: 0.221125
global_step: 21661, epoch: 142, loss: 0.253235
global_step: 21662, epoch: 142, loss: 0.217117
global_step: 21663, epoch: 142, loss: 0.278960
global_step: 21664, epoch: 142, loss: 0.274199
global_step: 21665, epoch: 142, loss: 0.269955
global_step: 21666, epoch: 142, loss: 0.272879
global_step: 21667, epoch: 142, loss: 0.204830
global_step: 21668, epoch: 142, loss: 0.240204
global_step: 21669, epoch: 142, loss: 0.296307
global_step: 21670, epoch: 142, loss: 0.227756
global_step: 21671, epoch: 142, loss: 0.273149
global_step: 21672, epoch: 142, loss: 0.228506
global_step: 21673, epoch: 142, loss: 0.219586
global_step: 21674, epoch: 142, loss: 0.180171
global_step: 21675, epoch: 142, loss: 0.201928
global_step: 21676, epoch: 142, loss: 0.222821
global_step: 21677, epoch: 142, loss: 0.257410
global_step: 21678, epoch: 142, loss: 0.266243
global_step: 21679, epoch: 142, loss: 0.223178
global_step: 21680, epoch: 142, loss: 0.063681
epoch: 142
train	acc: 0.9681	macro: p 0.9710, r 0.9558, f1: 0.9631	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9681
dev	acc: 0.5311	macro: p 0.3613, r 0.3034, f1: 0.3043	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4886
test	acc: 0.5774	macro: p 0.3567, r 0.3143, f1: 0.3207	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5422
global_step: 21681, epoch: 143, loss: 0.190246
global_step: 21682, epoch: 143, loss: 0.200651
global_step: 21683, epoch: 143, loss: 0.228028
global_step: 21684, epoch: 143, loss: 0.225368
global_step: 21685, epoch: 143, loss: 0.262137
global_step: 21686, epoch: 143, loss: 0.237493
global_step: 21687, epoch: 143, loss: 0.243269
global_step: 21688, epoch: 143, loss: 0.196583
global_step: 21689, epoch: 143, loss: 0.201408
global_step: 21690, epoch: 143, loss: 0.292931
global_step: 21691, epoch: 143, loss: 0.226959
global_step: 21692, epoch: 143, loss: 0.215405
global_step: 21693, epoch: 143, loss: 0.198067
global_step: 21694, epoch: 143, loss: 0.253453
global_step: 21695, epoch: 143, loss: 0.236683
global_step: 21696, epoch: 143, loss: 0.250667
global_step: 21697, epoch: 143, loss: 0.158571
global_step: 21698, epoch: 143, loss: 0.293864
global_step: 21699, epoch: 143, loss: 0.213921
global_step: 21700, epoch: 143, loss: 0.162014
global_step: 21701, epoch: 143, loss: 0.197385
global_step: 21702, epoch: 143, loss: 0.242986
global_step: 21703, epoch: 143, loss: 0.205541
global_step: 21704, epoch: 143, loss: 0.175657
global_step: 21705, epoch: 143, loss: 0.243270
global_step: 21706, epoch: 143, loss: 0.264977
global_step: 21707, epoch: 143, loss: 0.238428
global_step: 21708, epoch: 143, loss: 0.180595
global_step: 21709, epoch: 143, loss: 0.235556
global_step: 21710, epoch: 143, loss: 0.224800
global_step: 21711, epoch: 143, loss: 0.258599
global_step: 21712, epoch: 143, loss: 0.234119
global_step: 21713, epoch: 143, loss: 0.180884
global_step: 21714, epoch: 143, loss: 0.216103
global_step: 21715, epoch: 143, loss: 0.205883
global_step: 21716, epoch: 143, loss: 0.161523
global_step: 21717, epoch: 143, loss: 0.265994
global_step: 21718, epoch: 143, loss: 0.343208
global_step: 21719, epoch: 143, loss: 0.249741
global_step: 21720, epoch: 143, loss: 0.024567
epoch: 143
train	acc: 0.9682	macro: p 0.9717, r 0.9538, f1: 0.9624	micro: p 0.9682, r 0.9682, f1 0.9682	weighted_f1:0.9682
dev	acc: 0.5329	macro: p 0.3606, r 0.3035, f1: 0.3058	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4898
test	acc: 0.5828	macro: p 0.3581, r 0.3148, f1: 0.3229	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5463
global_step: 21721, epoch: 144, loss: 0.210164
global_step: 21722, epoch: 144, loss: 0.201043
global_step: 21723, epoch: 144, loss: 0.142006
global_step: 21724, epoch: 144, loss: 0.137426
global_step: 21725, epoch: 144, loss: 0.199405
global_step: 21726, epoch: 144, loss: 0.186416
global_step: 21727, epoch: 144, loss: 0.205284
global_step: 21728, epoch: 144, loss: 0.324873
global_step: 21729, epoch: 144, loss: 0.196183
global_step: 21730, epoch: 144, loss: 0.230612
global_step: 21731, epoch: 144, loss: 0.194298
global_step: 21732, epoch: 144, loss: 0.225155
global_step: 21733, epoch: 144, loss: 0.186704
global_step: 21734, epoch: 144, loss: 0.204303
global_step: 21735, epoch: 144, loss: 0.227112
global_step: 21736, epoch: 144, loss: 0.272671
global_step: 21737, epoch: 144, loss: 0.271005
global_step: 21738, epoch: 144, loss: 0.233264
global_step: 21739, epoch: 144, loss: 0.242127
global_step: 21740, epoch: 144, loss: 0.258497
global_step: 21741, epoch: 144, loss: 0.216342
global_step: 21742, epoch: 144, loss: 0.221948
global_step: 21743, epoch: 144, loss: 0.234834
global_step: 21744, epoch: 144, loss: 0.222925
global_step: 21745, epoch: 144, loss: 0.253300
global_step: 21746, epoch: 144, loss: 0.240893
global_step: 21747, epoch: 144, loss: 0.241691
global_step: 21748, epoch: 144, loss: 0.262116
global_step: 21749, epoch: 144, loss: 0.260211
global_step: 21750, epoch: 144, loss: 0.242058
global_step: 21751, epoch: 144, loss: 0.310569
global_step: 21752, epoch: 144, loss: 0.227764
global_step: 21753, epoch: 144, loss: 0.279564
global_step: 21754, epoch: 144, loss: 0.201631
global_step: 21755, epoch: 144, loss: 0.271295
global_step: 21756, epoch: 144, loss: 0.225904
global_step: 21757, epoch: 144, loss: 0.289185
global_step: 21758, epoch: 144, loss: 0.229182
global_step: 21759, epoch: 144, loss: 0.217709
global_step: 21760, epoch: 144, loss: 0.468626
epoch: 144
train	acc: 0.9678	macro: p 0.9710, r 0.9534, f1: 0.9618	micro: p 0.9678, r 0.9678, f1 0.9678	weighted_f1:0.9678
dev	acc: 0.5383	macro: p 0.3950, r 0.3127, f1: 0.3173	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4930
test	acc: 0.5820	macro: p 0.3669, r 0.3143, f1: 0.3217	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5419
global_step: 21761, epoch: 145, loss: 0.201043
global_step: 21762, epoch: 145, loss: 0.221400
global_step: 21763, epoch: 145, loss: 0.247238
global_step: 21764, epoch: 145, loss: 0.228189
global_step: 21765, epoch: 145, loss: 0.207853
global_step: 21766, epoch: 145, loss: 0.230144
global_step: 21767, epoch: 145, loss: 0.207856
global_step: 21768, epoch: 145, loss: 0.207326
global_step: 21769, epoch: 145, loss: 0.263773
global_step: 21770, epoch: 145, loss: 0.246746
global_step: 21771, epoch: 145, loss: 0.241818
global_step: 21772, epoch: 145, loss: 0.281984
global_step: 21773, epoch: 145, loss: 0.242323
global_step: 21774, epoch: 145, loss: 0.267699
global_step: 21775, epoch: 145, loss: 0.193017
global_step: 21776, epoch: 145, loss: 0.229054
global_step: 21777, epoch: 145, loss: 0.271978
global_step: 21778, epoch: 145, loss: 0.191994
global_step: 21779, epoch: 145, loss: 0.236218
global_step: 21780, epoch: 145, loss: 0.234250
global_step: 21781, epoch: 145, loss: 0.216737
global_step: 21782, epoch: 145, loss: 0.185972
global_step: 21783, epoch: 145, loss: 0.250638
global_step: 21784, epoch: 145, loss: 0.268754
global_step: 21785, epoch: 145, loss: 0.171407
global_step: 21786, epoch: 145, loss: 0.204559
global_step: 21787, epoch: 145, loss: 0.188846
global_step: 21788, epoch: 145, loss: 0.235566
global_step: 21789, epoch: 145, loss: 0.242907
global_step: 21790, epoch: 145, loss: 0.226213
global_step: 21791, epoch: 145, loss: 0.220694
global_step: 21792, epoch: 145, loss: 0.186187
global_step: 21793, epoch: 145, loss: 0.245175
global_step: 21794, epoch: 145, loss: 0.174285
global_step: 21795, epoch: 145, loss: 0.246810
global_step: 21796, epoch: 145, loss: 0.273324
global_step: 21797, epoch: 145, loss: 0.185681
global_step: 21798, epoch: 145, loss: 0.237643
global_step: 21799, epoch: 145, loss: 0.272482
global_step: 21800, epoch: 145, loss: 0.027559
epoch: 145
train	acc: 0.9683	macro: p 0.9708, r 0.9548, f1: 0.9624	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5374	macro: p 0.3649, r 0.3095, f1: 0.3091	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4935
test	acc: 0.5762	macro: p 0.3573, r 0.3154, f1: 0.3211	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5393
global_step: 21801, epoch: 146, loss: 0.220482
global_step: 21802, epoch: 146, loss: 0.145571
global_step: 21803, epoch: 146, loss: 0.216898
global_step: 21804, epoch: 146, loss: 0.171622
global_step: 21805, epoch: 146, loss: 0.176784
global_step: 21806, epoch: 146, loss: 0.180549
global_step: 21807, epoch: 146, loss: 0.249276
global_step: 21808, epoch: 146, loss: 0.170033
global_step: 21809, epoch: 146, loss: 0.198151
global_step: 21810, epoch: 146, loss: 0.231439
global_step: 21811, epoch: 146, loss: 0.184080
global_step: 21812, epoch: 146, loss: 0.275529
global_step: 21813, epoch: 146, loss: 0.164188
global_step: 21814, epoch: 146, loss: 0.267205
global_step: 21815, epoch: 146, loss: 0.198917
global_step: 21816, epoch: 146, loss: 0.249595
global_step: 21817, epoch: 146, loss: 0.175849
global_step: 21818, epoch: 146, loss: 0.292646
global_step: 21819, epoch: 146, loss: 0.178411
global_step: 21820, epoch: 146, loss: 0.210447
global_step: 21821, epoch: 146, loss: 0.224938
global_step: 21822, epoch: 146, loss: 0.263737
global_step: 21823, epoch: 146, loss: 0.180814
global_step: 21824, epoch: 146, loss: 0.263235
global_step: 21825, epoch: 146, loss: 0.251674
global_step: 21826, epoch: 146, loss: 0.186978
global_step: 21827, epoch: 146, loss: 0.253270
global_step: 21828, epoch: 146, loss: 0.219649
global_step: 21829, epoch: 146, loss: 0.237074
global_step: 21830, epoch: 146, loss: 0.201209
global_step: 21831, epoch: 146, loss: 0.291599
global_step: 21832, epoch: 146, loss: 0.237586
global_step: 21833, epoch: 146, loss: 0.178656
global_step: 21834, epoch: 146, loss: 0.240680
global_step: 21835, epoch: 146, loss: 0.151681
global_step: 21836, epoch: 146, loss: 0.342715
global_step: 21837, epoch: 146, loss: 0.226057
global_step: 21838, epoch: 146, loss: 0.277622
global_step: 21839, epoch: 146, loss: 0.191200
global_step: 21840, epoch: 146, loss: 0.138050
epoch: 146
train	acc: 0.9684	macro: p 0.9733, r 0.9529, f1: 0.9627	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5446	macro: p 0.4084, r 0.3154, f1: 0.3204	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4967
test	acc: 0.5812	macro: p 0.3619, r 0.3156, f1: 0.3241	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5429
global_step: 21841, epoch: 147, loss: 0.223267
global_step: 21842, epoch: 147, loss: 0.208427
global_step: 21843, epoch: 147, loss: 0.198542
global_step: 21844, epoch: 147, loss: 0.220491
global_step: 21845, epoch: 147, loss: 0.292652
global_step: 21846, epoch: 147, loss: 0.272695
global_step: 21847, epoch: 147, loss: 0.229302
global_step: 21848, epoch: 147, loss: 0.210191
global_step: 21849, epoch: 147, loss: 0.159472
global_step: 21850, epoch: 147, loss: 0.283645
global_step: 21851, epoch: 147, loss: 0.371230
global_step: 21852, epoch: 147, loss: 0.203457
global_step: 21853, epoch: 147, loss: 0.227099
global_step: 21854, epoch: 147, loss: 0.210685
global_step: 21855, epoch: 147, loss: 0.227156
global_step: 21856, epoch: 147, loss: 0.191646
global_step: 21857, epoch: 147, loss: 0.201131
global_step: 21858, epoch: 147, loss: 0.209371
global_step: 21859, epoch: 147, loss: 0.214813
global_step: 21860, epoch: 147, loss: 0.193609
global_step: 21861, epoch: 147, loss: 0.188839
global_step: 21862, epoch: 147, loss: 0.212199
global_step: 21863, epoch: 147, loss: 0.255998
global_step: 21864, epoch: 147, loss: 0.253081
global_step: 21865, epoch: 147, loss: 0.211923
global_step: 21866, epoch: 147, loss: 0.293175
global_step: 21867, epoch: 147, loss: 0.213916
global_step: 21868, epoch: 147, loss: 0.188093
global_step: 21869, epoch: 147, loss: 0.279595
global_step: 21870, epoch: 147, loss: 0.214979
global_step: 21871, epoch: 147, loss: 0.191278
global_step: 21872, epoch: 147, loss: 0.232270
global_step: 21873, epoch: 147, loss: 0.230533
global_step: 21874, epoch: 147, loss: 0.220200
global_step: 21875, epoch: 147, loss: 0.276621
global_step: 21876, epoch: 147, loss: 0.276308
global_step: 21877, epoch: 147, loss: 0.238294
global_step: 21878, epoch: 147, loss: 0.284445
global_step: 21879, epoch: 147, loss: 0.250340
global_step: 21880, epoch: 147, loss: 0.217937
epoch: 147
train	acc: 0.9690	macro: p 0.9726, r 0.9554, f1: 0.9636	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5320	macro: p 0.3526, r 0.3075, f1: 0.3083	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4908
test	acc: 0.5774	macro: p 0.3533, r 0.3159, f1: 0.3232	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5436
global_step: 21881, epoch: 148, loss: 0.211354
global_step: 21882, epoch: 148, loss: 0.225677
global_step: 21883, epoch: 148, loss: 0.268474
global_step: 21884, epoch: 148, loss: 0.220474
global_step: 21885, epoch: 148, loss: 0.248117
global_step: 21886, epoch: 148, loss: 0.239344
global_step: 21887, epoch: 148, loss: 0.162508
global_step: 21888, epoch: 148, loss: 0.295889
global_step: 21889, epoch: 148, loss: 0.246278
global_step: 21890, epoch: 148, loss: 0.260849
global_step: 21891, epoch: 148, loss: 0.202435
global_step: 21892, epoch: 148, loss: 0.164334
global_step: 21893, epoch: 148, loss: 0.234238
global_step: 21894, epoch: 148, loss: 0.181845
global_step: 21895, epoch: 148, loss: 0.194828
global_step: 21896, epoch: 148, loss: 0.199124
global_step: 21897, epoch: 148, loss: 0.242301
global_step: 21898, epoch: 148, loss: 0.292133
global_step: 21899, epoch: 148, loss: 0.258398
global_step: 21900, epoch: 148, loss: 0.247520
global_step: 21901, epoch: 148, loss: 0.197879
global_step: 21902, epoch: 148, loss: 0.215671
global_step: 21903, epoch: 148, loss: 0.186792
global_step: 21904, epoch: 148, loss: 0.210599
global_step: 21905, epoch: 148, loss: 0.261407
global_step: 21906, epoch: 148, loss: 0.312856
global_step: 21907, epoch: 148, loss: 0.244069
global_step: 21908, epoch: 148, loss: 0.255786
global_step: 21909, epoch: 148, loss: 0.239220
global_step: 21910, epoch: 148, loss: 0.200229
global_step: 21911, epoch: 148, loss: 0.263855
global_step: 21912, epoch: 148, loss: 0.196983
global_step: 21913, epoch: 148, loss: 0.278689
global_step: 21914, epoch: 148, loss: 0.266275
global_step: 21915, epoch: 148, loss: 0.302817
global_step: 21916, epoch: 148, loss: 0.213042
global_step: 21917, epoch: 148, loss: 0.175183
global_step: 21918, epoch: 148, loss: 0.239832
global_step: 21919, epoch: 148, loss: 0.287634
global_step: 21920, epoch: 148, loss: 0.359278
epoch: 148
train	acc: 0.9698	macro: p 0.9738, r 0.9562, f1: 0.9647	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5401	macro: p 0.3852, r 0.3116, f1: 0.3172	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4933
test	acc: 0.5774	macro: p 0.3473, r 0.3033, f1: 0.3111	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5358
global_step: 21921, epoch: 149, loss: 0.197990
global_step: 21922, epoch: 149, loss: 0.158529
global_step: 21923, epoch: 149, loss: 0.234614
global_step: 21924, epoch: 149, loss: 0.255153
global_step: 21925, epoch: 149, loss: 0.210129
global_step: 21926, epoch: 149, loss: 0.253269
global_step: 21927, epoch: 149, loss: 0.156027
global_step: 21928, epoch: 149, loss: 0.186310
global_step: 21929, epoch: 149, loss: 0.162607
global_step: 21930, epoch: 149, loss: 0.262855
global_step: 21931, epoch: 149, loss: 0.266302
global_step: 21932, epoch: 149, loss: 0.179117
global_step: 21933, epoch: 149, loss: 0.243306
global_step: 21934, epoch: 149, loss: 0.182231
global_step: 21935, epoch: 149, loss: 0.260858
global_step: 21936, epoch: 149, loss: 0.204300
global_step: 21937, epoch: 149, loss: 0.245106
global_step: 21938, epoch: 149, loss: 0.257571
global_step: 21939, epoch: 149, loss: 0.245350
global_step: 21940, epoch: 149, loss: 0.195586
global_step: 21941, epoch: 149, loss: 0.280560
global_step: 21942, epoch: 149, loss: 0.257946
global_step: 21943, epoch: 149, loss: 0.203633
global_step: 21944, epoch: 149, loss: 0.246733
global_step: 21945, epoch: 149, loss: 0.165683
global_step: 21946, epoch: 149, loss: 0.260867
global_step: 21947, epoch: 149, loss: 0.184028
global_step: 21948, epoch: 149, loss: 0.212756
global_step: 21949, epoch: 149, loss: 0.236845
global_step: 21950, epoch: 149, loss: 0.226350
global_step: 21951, epoch: 149, loss: 0.223416
global_step: 21952, epoch: 149, loss: 0.205121
global_step: 21953, epoch: 149, loss: 0.237918
global_step: 21954, epoch: 149, loss: 0.208101
global_step: 21955, epoch: 149, loss: 0.210459
global_step: 21956, epoch: 149, loss: 0.202511
global_step: 21957, epoch: 149, loss: 0.213058
global_step: 21958, epoch: 149, loss: 0.255219
global_step: 21959, epoch: 149, loss: 0.265264
global_step: 21960, epoch: 149, loss: 0.883116
epoch: 149
train	acc: 0.9681	macro: p 0.9712, r 0.9546, f1: 0.9624	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9682
dev	acc: 0.5365	macro: p 0.3801, r 0.3107, f1: 0.3134	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4900
test	acc: 0.5743	macro: p 0.3370, r 0.3076, f1: 0.3115	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5362
global_step: 21961, epoch: 150, loss: 0.284032
global_step: 21962, epoch: 150, loss: 0.197289
global_step: 21963, epoch: 150, loss: 0.193596
global_step: 21964, epoch: 150, loss: 0.236548
global_step: 21965, epoch: 150, loss: 0.222608
global_step: 21966, epoch: 150, loss: 0.181189
global_step: 21967, epoch: 150, loss: 0.227393
global_step: 21968, epoch: 150, loss: 0.210729
global_step: 21969, epoch: 150, loss: 0.215072
global_step: 21970, epoch: 150, loss: 0.228825
global_step: 21971, epoch: 150, loss: 0.270417
global_step: 21972, epoch: 150, loss: 0.140872
global_step: 21973, epoch: 150, loss: 0.194110
global_step: 21974, epoch: 150, loss: 0.169152
global_step: 21975, epoch: 150, loss: 0.224727
global_step: 21976, epoch: 150, loss: 0.183821
global_step: 21977, epoch: 150, loss: 0.208101
global_step: 21978, epoch: 150, loss: 0.175177
global_step: 21979, epoch: 150, loss: 0.243091
global_step: 21980, epoch: 150, loss: 0.175950
global_step: 21981, epoch: 150, loss: 0.272756
global_step: 21982, epoch: 150, loss: 0.295955
global_step: 21983, epoch: 150, loss: 0.221722
global_step: 21984, epoch: 150, loss: 0.198793
global_step: 21985, epoch: 150, loss: 0.177330
global_step: 21986, epoch: 150, loss: 0.249098
global_step: 21987, epoch: 150, loss: 0.198551
global_step: 21988, epoch: 150, loss: 0.235921
global_step: 21989, epoch: 150, loss: 0.282347
global_step: 21990, epoch: 150, loss: 0.238813
global_step: 21991, epoch: 150, loss: 0.258738
global_step: 21992, epoch: 150, loss: 0.240527
global_step: 21993, epoch: 150, loss: 0.201817
global_step: 21994, epoch: 150, loss: 0.302977
global_step: 21995, epoch: 150, loss: 0.202593
global_step: 21996, epoch: 150, loss: 0.236175
global_step: 21997, epoch: 150, loss: 0.248085
global_step: 21998, epoch: 150, loss: 0.159604
global_step: 21999, epoch: 150, loss: 0.173793
global_step: 22000, epoch: 150, loss: 0.007832
epoch: 150
train	acc: 0.9694	macro: p 0.9730, r 0.9561, f1: 0.9642	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5311	macro: p 0.3585, r 0.3109, f1: 0.3117	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4922
test	acc: 0.5663	macro: p 0.3367, r 0.3079, f1: 0.3108	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5343
global_step: 22001, epoch: 151, loss: 0.201349
global_step: 22002, epoch: 151, loss: 0.175636
global_step: 22003, epoch: 151, loss: 0.261197
global_step: 22004, epoch: 151, loss: 0.224545
global_step: 22005, epoch: 151, loss: 0.204287
global_step: 22006, epoch: 151, loss: 0.235962
global_step: 22007, epoch: 151, loss: 0.193350
global_step: 22008, epoch: 151, loss: 0.203494
global_step: 22009, epoch: 151, loss: 0.210800
global_step: 22010, epoch: 151, loss: 0.182095
global_step: 22011, epoch: 151, loss: 0.168770
global_step: 22012, epoch: 151, loss: 0.189345
global_step: 22013, epoch: 151, loss: 0.217457
global_step: 22014, epoch: 151, loss: 0.159363
global_step: 22015, epoch: 151, loss: 0.181736
global_step: 22016, epoch: 151, loss: 0.174833
global_step: 22017, epoch: 151, loss: 0.224238
global_step: 22018, epoch: 151, loss: 0.172815
global_step: 22019, epoch: 151, loss: 0.188799
global_step: 22020, epoch: 151, loss: 0.222573
global_step: 22021, epoch: 151, loss: 0.253597
global_step: 22022, epoch: 151, loss: 0.174122
global_step: 22023, epoch: 151, loss: 0.200133
global_step: 22024, epoch: 151, loss: 0.177952
global_step: 22025, epoch: 151, loss: 0.250483
global_step: 22026, epoch: 151, loss: 0.200316
global_step: 22027, epoch: 151, loss: 0.154770
global_step: 22028, epoch: 151, loss: 0.263059
global_step: 22029, epoch: 151, loss: 0.246602
global_step: 22030, epoch: 151, loss: 0.206969
global_step: 22031, epoch: 151, loss: 0.256693
global_step: 22032, epoch: 151, loss: 0.216539
global_step: 22033, epoch: 151, loss: 0.273155
global_step: 22034, epoch: 151, loss: 0.185214
global_step: 22035, epoch: 151, loss: 0.247252
global_step: 22036, epoch: 151, loss: 0.187718
global_step: 22037, epoch: 151, loss: 0.220142
global_step: 22038, epoch: 151, loss: 0.164351
global_step: 22039, epoch: 151, loss: 0.277960
global_step: 22040, epoch: 151, loss: 0.776788
epoch: 151
train	acc: 0.9693	macro: p 0.9732, r 0.9557, f1: 0.9641	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5347	macro: p 0.3622, r 0.3080, f1: 0.3060	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4905
test	acc: 0.5682	macro: p 0.3427, r 0.3088, f1: 0.3122	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5332
global_step: 22041, epoch: 152, loss: 0.280306
global_step: 22042, epoch: 152, loss: 0.204867
global_step: 22043, epoch: 152, loss: 0.194744
global_step: 22044, epoch: 152, loss: 0.219559
global_step: 22045, epoch: 152, loss: 0.193347
global_step: 22046, epoch: 152, loss: 0.212383
global_step: 22047, epoch: 152, loss: 0.297171
global_step: 22048, epoch: 152, loss: 0.241822
global_step: 22049, epoch: 152, loss: 0.246925
global_step: 22050, epoch: 152, loss: 0.145674
global_step: 22051, epoch: 152, loss: 0.162329
global_step: 22052, epoch: 152, loss: 0.228370
global_step: 22053, epoch: 152, loss: 0.208018
global_step: 22054, epoch: 152, loss: 0.193330
global_step: 22055, epoch: 152, loss: 0.225026
global_step: 22056, epoch: 152, loss: 0.267735
global_step: 22057, epoch: 152, loss: 0.260980
global_step: 22058, epoch: 152, loss: 0.204315
global_step: 22059, epoch: 152, loss: 0.271235
global_step: 22060, epoch: 152, loss: 0.229969
global_step: 22061, epoch: 152, loss: 0.253011
global_step: 22062, epoch: 152, loss: 0.232103
global_step: 22063, epoch: 152, loss: 0.155209
global_step: 22064, epoch: 152, loss: 0.209568
global_step: 22065, epoch: 152, loss: 0.188371
global_step: 22066, epoch: 152, loss: 0.257815
global_step: 22067, epoch: 152, loss: 0.206890
global_step: 22068, epoch: 152, loss: 0.169938
global_step: 22069, epoch: 152, loss: 0.238131
global_step: 22070, epoch: 152, loss: 0.223220
global_step: 22071, epoch: 152, loss: 0.243140
global_step: 22072, epoch: 152, loss: 0.231251
global_step: 22073, epoch: 152, loss: 0.218122
global_step: 22074, epoch: 152, loss: 0.227647
global_step: 22075, epoch: 152, loss: 0.231326
global_step: 22076, epoch: 152, loss: 0.268991
global_step: 22077, epoch: 152, loss: 0.225123
global_step: 22078, epoch: 152, loss: 0.211865
global_step: 22079, epoch: 152, loss: 0.177341
global_step: 22080, epoch: 152, loss: 0.067858
epoch: 152
train	acc: 0.9697	macro: p 0.9737, r 0.9555, f1: 0.9642	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5419	macro: p 0.3994, r 0.3164, f1: 0.3201	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4965
test	acc: 0.5747	macro: p 0.3492, r 0.3113, f1: 0.3167	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5382
global_step: 22081, epoch: 153, loss: 0.197631
global_step: 22082, epoch: 153, loss: 0.195761
global_step: 22083, epoch: 153, loss: 0.219055
global_step: 22084, epoch: 153, loss: 0.172900
global_step: 22085, epoch: 153, loss: 0.268824
global_step: 22086, epoch: 153, loss: 0.292708
global_step: 22087, epoch: 153, loss: 0.215200
global_step: 22088, epoch: 153, loss: 0.253830
global_step: 22089, epoch: 153, loss: 0.154022
global_step: 22090, epoch: 153, loss: 0.205792
global_step: 22091, epoch: 153, loss: 0.191210
global_step: 22092, epoch: 153, loss: 0.193983
global_step: 22093, epoch: 153, loss: 0.168535
global_step: 22094, epoch: 153, loss: 0.166400
global_step: 22095, epoch: 153, loss: 0.204444
global_step: 22096, epoch: 153, loss: 0.224610
global_step: 22097, epoch: 153, loss: 0.215114
global_step: 22098, epoch: 153, loss: 0.225417
global_step: 22099, epoch: 153, loss: 0.232934
global_step: 22100, epoch: 153, loss: 0.204855
global_step: 22101, epoch: 153, loss: 0.242032
global_step: 22102, epoch: 153, loss: 0.250129
global_step: 22103, epoch: 153, loss: 0.267474
global_step: 22104, epoch: 153, loss: 0.176852
global_step: 22105, epoch: 153, loss: 0.233475
global_step: 22106, epoch: 153, loss: 0.172485
global_step: 22107, epoch: 153, loss: 0.175012
global_step: 22108, epoch: 153, loss: 0.176610
global_step: 22109, epoch: 153, loss: 0.195673
global_step: 22110, epoch: 153, loss: 0.199924
global_step: 22111, epoch: 153, loss: 0.223384
global_step: 22112, epoch: 153, loss: 0.175517
global_step: 22113, epoch: 153, loss: 0.170340
global_step: 22114, epoch: 153, loss: 0.208266
global_step: 22115, epoch: 153, loss: 0.245026
global_step: 22116, epoch: 153, loss: 0.196899
global_step: 22117, epoch: 153, loss: 0.220472
global_step: 22118, epoch: 153, loss: 0.216565
global_step: 22119, epoch: 153, loss: 0.259945
global_step: 22120, epoch: 153, loss: 0.064833
epoch: 153
train	acc: 0.9701	macro: p 0.9739, r 0.9582, f1: 0.9657	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5284	macro: p 0.3659, r 0.3068, f1: 0.3054	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4874
test	acc: 0.5755	macro: p 0.3402, r 0.3134, f1: 0.3157	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5415
global_step: 22121, epoch: 154, loss: 0.142865
global_step: 22122, epoch: 154, loss: 0.200475
global_step: 22123, epoch: 154, loss: 0.176355
global_step: 22124, epoch: 154, loss: 0.238423
global_step: 22125, epoch: 154, loss: 0.184371
global_step: 22126, epoch: 154, loss: 0.180504
global_step: 22127, epoch: 154, loss: 0.288383
global_step: 22128, epoch: 154, loss: 0.160435
global_step: 22129, epoch: 154, loss: 0.240520
global_step: 22130, epoch: 154, loss: 0.183883
global_step: 22131, epoch: 154, loss: 0.206465
global_step: 22132, epoch: 154, loss: 0.175400
global_step: 22133, epoch: 154, loss: 0.207338
global_step: 22134, epoch: 154, loss: 0.257707
global_step: 22135, epoch: 154, loss: 0.208639
global_step: 22136, epoch: 154, loss: 0.170429
global_step: 22137, epoch: 154, loss: 0.205264
global_step: 22138, epoch: 154, loss: 0.221418
global_step: 22139, epoch: 154, loss: 0.163448
global_step: 22140, epoch: 154, loss: 0.282033
global_step: 22141, epoch: 154, loss: 0.222006
global_step: 22142, epoch: 154, loss: 0.281265
global_step: 22143, epoch: 154, loss: 0.238616
global_step: 22144, epoch: 154, loss: 0.194319
global_step: 22145, epoch: 154, loss: 0.149195
global_step: 22146, epoch: 154, loss: 0.225606
global_step: 22147, epoch: 154, loss: 0.226557
global_step: 22148, epoch: 154, loss: 0.180912
global_step: 22149, epoch: 154, loss: 0.336915
global_step: 22150, epoch: 154, loss: 0.294495
global_step: 22151, epoch: 154, loss: 0.239393
global_step: 22152, epoch: 154, loss: 0.234857
global_step: 22153, epoch: 154, loss: 0.188525
global_step: 22154, epoch: 154, loss: 0.231465
global_step: 22155, epoch: 154, loss: 0.258560
global_step: 22156, epoch: 154, loss: 0.245120
global_step: 22157, epoch: 154, loss: 0.217667
global_step: 22158, epoch: 154, loss: 0.196241
global_step: 22159, epoch: 154, loss: 0.200968
global_step: 22160, epoch: 154, loss: 0.040581
epoch: 154
train	acc: 0.9704	macro: p 0.9743, r 0.9584, f1: 0.9661	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5329	macro: p 0.3470, r 0.3061, f1: 0.3091	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4925
test	acc: 0.5762	macro: p 0.3604, r 0.3162, f1: 0.3270	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5440
global_step: 22161, epoch: 155, loss: 0.264300
global_step: 22162, epoch: 155, loss: 0.177274
global_step: 22163, epoch: 155, loss: 0.158288
global_step: 22164, epoch: 155, loss: 0.233765
global_step: 22165, epoch: 155, loss: 0.148790
global_step: 22166, epoch: 155, loss: 0.189263
global_step: 22167, epoch: 155, loss: 0.165984
global_step: 22168, epoch: 155, loss: 0.160053
global_step: 22169, epoch: 155, loss: 0.204821
global_step: 22170, epoch: 155, loss: 0.216818
global_step: 22171, epoch: 155, loss: 0.236559
global_step: 22172, epoch: 155, loss: 0.210422
global_step: 22173, epoch: 155, loss: 0.259277
global_step: 22174, epoch: 155, loss: 0.242232
global_step: 22175, epoch: 155, loss: 0.292737
global_step: 22176, epoch: 155, loss: 0.172449
global_step: 22177, epoch: 155, loss: 0.178760
global_step: 22178, epoch: 155, loss: 0.162204
global_step: 22179, epoch: 155, loss: 0.192917
global_step: 22180, epoch: 155, loss: 0.210804
global_step: 22181, epoch: 155, loss: 0.185166
global_step: 22182, epoch: 155, loss: 0.201732
global_step: 22183, epoch: 155, loss: 0.157566
global_step: 22184, epoch: 155, loss: 0.174190
global_step: 22185, epoch: 155, loss: 0.284300
global_step: 22186, epoch: 155, loss: 0.269810
global_step: 22187, epoch: 155, loss: 0.289095
global_step: 22188, epoch: 155, loss: 0.288889
global_step: 22189, epoch: 155, loss: 0.216090
global_step: 22190, epoch: 155, loss: 0.221810
global_step: 22191, epoch: 155, loss: 0.181782
global_step: 22192, epoch: 155, loss: 0.225463
global_step: 22193, epoch: 155, loss: 0.301205
global_step: 22194, epoch: 155, loss: 0.212946
global_step: 22195, epoch: 155, loss: 0.160684
global_step: 22196, epoch: 155, loss: 0.210257
global_step: 22197, epoch: 155, loss: 0.237362
global_step: 22198, epoch: 155, loss: 0.203286
global_step: 22199, epoch: 155, loss: 0.276734
global_step: 22200, epoch: 155, loss: 0.035895
epoch: 155
train	acc: 0.9701	macro: p 0.9733, r 0.9574, f1: 0.9650	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5374	macro: p 0.3824, r 0.3095, f1: 0.3108	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4931
test	acc: 0.5774	macro: p 0.3584, r 0.3091, f1: 0.3127	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5382
global_step: 22201, epoch: 156, loss: 0.231010
global_step: 22202, epoch: 156, loss: 0.148914
global_step: 22203, epoch: 156, loss: 0.320226
global_step: 22204, epoch: 156, loss: 0.229731
global_step: 22205, epoch: 156, loss: 0.192007
global_step: 22206, epoch: 156, loss: 0.119721
global_step: 22207, epoch: 156, loss: 0.207307
global_step: 22208, epoch: 156, loss: 0.221715
global_step: 22209, epoch: 156, loss: 0.262112
global_step: 22210, epoch: 156, loss: 0.278019
global_step: 22211, epoch: 156, loss: 0.230022
global_step: 22212, epoch: 156, loss: 0.162402
global_step: 22213, epoch: 156, loss: 0.235029
global_step: 22214, epoch: 156, loss: 0.179088
global_step: 22215, epoch: 156, loss: 0.253808
global_step: 22216, epoch: 156, loss: 0.273771
global_step: 22217, epoch: 156, loss: 0.179333
global_step: 22218, epoch: 156, loss: 0.299947
global_step: 22219, epoch: 156, loss: 0.268988
global_step: 22220, epoch: 156, loss: 0.199383
global_step: 22221, epoch: 156, loss: 0.202262
global_step: 22222, epoch: 156, loss: 0.198155
global_step: 22223, epoch: 156, loss: 0.243409
global_step: 22224, epoch: 156, loss: 0.201276
global_step: 22225, epoch: 156, loss: 0.202681
global_step: 22226, epoch: 156, loss: 0.199402
global_step: 22227, epoch: 156, loss: 0.173032
global_step: 22228, epoch: 156, loss: 0.201183
global_step: 22229, epoch: 156, loss: 0.252288
global_step: 22230, epoch: 156, loss: 0.252973
global_step: 22231, epoch: 156, loss: 0.232659
global_step: 22232, epoch: 156, loss: 0.231913
global_step: 22233, epoch: 156, loss: 0.247423
global_step: 22234, epoch: 156, loss: 0.193529
global_step: 22235, epoch: 156, loss: 0.197847
global_step: 22236, epoch: 156, loss: 0.223373
global_step: 22237, epoch: 156, loss: 0.166721
global_step: 22238, epoch: 156, loss: 0.205493
global_step: 22239, epoch: 156, loss: 0.150134
global_step: 22240, epoch: 156, loss: 0.619213
epoch: 156
train	acc: 0.9700	macro: p 0.9732, r 0.9570, f1: 0.9647	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5392	macro: p 0.3731, r 0.3130, f1: 0.3142	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4971
test	acc: 0.5793	macro: p 0.3408, r 0.3147, f1: 0.3192	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5453
global_step: 22241, epoch: 157, loss: 0.248976
global_step: 22242, epoch: 157, loss: 0.189470
global_step: 22243, epoch: 157, loss: 0.147150
global_step: 22244, epoch: 157, loss: 0.183659
global_step: 22245, epoch: 157, loss: 0.253434
global_step: 22246, epoch: 157, loss: 0.242757
global_step: 22247, epoch: 157, loss: 0.179507
global_step: 22248, epoch: 157, loss: 0.170865
global_step: 22249, epoch: 157, loss: 0.217415
global_step: 22250, epoch: 157, loss: 0.159638
global_step: 22251, epoch: 157, loss: 0.181749
global_step: 22252, epoch: 157, loss: 0.331877
global_step: 22253, epoch: 157, loss: 0.284432
global_step: 22254, epoch: 157, loss: 0.240256
global_step: 22255, epoch: 157, loss: 0.234323
global_step: 22256, epoch: 157, loss: 0.207254
global_step: 22257, epoch: 157, loss: 0.179504
global_step: 22258, epoch: 157, loss: 0.204619
global_step: 22259, epoch: 157, loss: 0.235938
global_step: 22260, epoch: 157, loss: 0.218353
global_step: 22261, epoch: 157, loss: 0.192194
global_step: 22262, epoch: 157, loss: 0.228048
global_step: 22263, epoch: 157, loss: 0.243575
global_step: 22264, epoch: 157, loss: 0.239923
global_step: 22265, epoch: 157, loss: 0.198141
global_step: 22266, epoch: 157, loss: 0.242162
global_step: 22267, epoch: 157, loss: 0.194274
global_step: 22268, epoch: 157, loss: 0.208245
global_step: 22269, epoch: 157, loss: 0.196843
global_step: 22270, epoch: 157, loss: 0.200093
global_step: 22271, epoch: 157, loss: 0.173071
global_step: 22272, epoch: 157, loss: 0.222425
global_step: 22273, epoch: 157, loss: 0.187555
global_step: 22274, epoch: 157, loss: 0.219710
global_step: 22275, epoch: 157, loss: 0.170087
global_step: 22276, epoch: 157, loss: 0.184344
global_step: 22277, epoch: 157, loss: 0.186162
global_step: 22278, epoch: 157, loss: 0.241799
global_step: 22279, epoch: 157, loss: 0.277628
global_step: 22280, epoch: 157, loss: 0.269438
epoch: 157
train	acc: 0.9705	macro: p 0.9746, r 0.9582, f1: 0.9661	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5356	macro: p 0.3656, r 0.3094, f1: 0.3099	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4933
test	acc: 0.5713	macro: p 0.3380, r 0.3027, f1: 0.3064	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5337
global_step: 22281, epoch: 158, loss: 0.232314
global_step: 22282, epoch: 158, loss: 0.154629
global_step: 22283, epoch: 158, loss: 0.235008
global_step: 22284, epoch: 158, loss: 0.169385
global_step: 22285, epoch: 158, loss: 0.174274
global_step: 22286, epoch: 158, loss: 0.145252
global_step: 22287, epoch: 158, loss: 0.181420
global_step: 22288, epoch: 158, loss: 0.161128
global_step: 22289, epoch: 158, loss: 0.206202
global_step: 22290, epoch: 158, loss: 0.146837
global_step: 22291, epoch: 158, loss: 0.232186
global_step: 22292, epoch: 158, loss: 0.212119
global_step: 22293, epoch: 158, loss: 0.169542
global_step: 22294, epoch: 158, loss: 0.166991
global_step: 22295, epoch: 158, loss: 0.196040
global_step: 22296, epoch: 158, loss: 0.176672
global_step: 22297, epoch: 158, loss: 0.199745
global_step: 22298, epoch: 158, loss: 0.166091
global_step: 22299, epoch: 158, loss: 0.156847
global_step: 22300, epoch: 158, loss: 0.153523
global_step: 22301, epoch: 158, loss: 0.258895
global_step: 22302, epoch: 158, loss: 0.228444
global_step: 22303, epoch: 158, loss: 0.182008
global_step: 22304, epoch: 158, loss: 0.247351
global_step: 22305, epoch: 158, loss: 0.230591
global_step: 22306, epoch: 158, loss: 0.227752
global_step: 22307, epoch: 158, loss: 0.214210
global_step: 22308, epoch: 158, loss: 0.279479
global_step: 22309, epoch: 158, loss: 0.266259
global_step: 22310, epoch: 158, loss: 0.177168
global_step: 22311, epoch: 158, loss: 0.221003
global_step: 22312, epoch: 158, loss: 0.241622
global_step: 22313, epoch: 158, loss: 0.269248
global_step: 22314, epoch: 158, loss: 0.245691
global_step: 22315, epoch: 158, loss: 0.219498
global_step: 22316, epoch: 158, loss: 0.166703
global_step: 22317, epoch: 158, loss: 0.321013
global_step: 22318, epoch: 158, loss: 0.201807
global_step: 22319, epoch: 158, loss: 0.196841
global_step: 22320, epoch: 158, loss: 0.038389
epoch: 158
train	acc: 0.9708	macro: p 0.9743, r 0.9583, f1: 0.9660	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5374	macro: p 0.3683, r 0.3104, f1: 0.3135	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4959
test	acc: 0.5770	macro: p 0.3519, r 0.3125, f1: 0.3196	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5415
global_step: 22321, epoch: 159, loss: 0.214681
global_step: 22322, epoch: 159, loss: 0.204339
global_step: 22323, epoch: 159, loss: 0.193879
global_step: 22324, epoch: 159, loss: 0.224810
global_step: 22325, epoch: 159, loss: 0.184832
global_step: 22326, epoch: 159, loss: 0.236980
global_step: 22327, epoch: 159, loss: 0.191592
global_step: 22328, epoch: 159, loss: 0.234960
global_step: 22329, epoch: 159, loss: 0.257103
global_step: 22330, epoch: 159, loss: 0.259345
global_step: 22331, epoch: 159, loss: 0.203620
global_step: 22332, epoch: 159, loss: 0.190363
global_step: 22333, epoch: 159, loss: 0.212420
global_step: 22334, epoch: 159, loss: 0.188556
global_step: 22335, epoch: 159, loss: 0.242482
global_step: 22336, epoch: 159, loss: 0.191048
global_step: 22337, epoch: 159, loss: 0.172252
global_step: 22338, epoch: 159, loss: 0.184553
global_step: 22339, epoch: 159, loss: 0.243392
global_step: 22340, epoch: 159, loss: 0.253607
global_step: 22341, epoch: 159, loss: 0.180629
global_step: 22342, epoch: 159, loss: 0.139764
global_step: 22343, epoch: 159, loss: 0.175035
global_step: 22344, epoch: 159, loss: 0.202580
global_step: 22345, epoch: 159, loss: 0.220336
global_step: 22346, epoch: 159, loss: 0.262786
global_step: 22347, epoch: 159, loss: 0.238340
global_step: 22348, epoch: 159, loss: 0.167093
global_step: 22349, epoch: 159, loss: 0.254105
global_step: 22350, epoch: 159, loss: 0.214921
global_step: 22351, epoch: 159, loss: 0.220242
global_step: 22352, epoch: 159, loss: 0.228762
global_step: 22353, epoch: 159, loss: 0.177721
global_step: 22354, epoch: 159, loss: 0.216646
global_step: 22355, epoch: 159, loss: 0.175204
global_step: 22356, epoch: 159, loss: 0.250068
global_step: 22357, epoch: 159, loss: 0.214850
global_step: 22358, epoch: 159, loss: 0.173130
global_step: 22359, epoch: 159, loss: 0.251830
global_step: 22360, epoch: 159, loss: 0.098602
epoch: 159
train	acc: 0.9698	macro: p 0.9728, r 0.9572, f1: 0.9647	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5356	macro: p 0.3980, r 0.3174, f1: 0.3203	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4943
test	acc: 0.5774	macro: p 0.3411, r 0.3100, f1: 0.3127	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5404
global_step: 22361, epoch: 160, loss: 0.227768
global_step: 22362, epoch: 160, loss: 0.206709
global_step: 22363, epoch: 160, loss: 0.188175
global_step: 22364, epoch: 160, loss: 0.227423
global_step: 22365, epoch: 160, loss: 0.204258
global_step: 22366, epoch: 160, loss: 0.211279
global_step: 22367, epoch: 160, loss: 0.287829
global_step: 22368, epoch: 160, loss: 0.158044
global_step: 22369, epoch: 160, loss: 0.142919
global_step: 22370, epoch: 160, loss: 0.217119
global_step: 22371, epoch: 160, loss: 0.210111
global_step: 22372, epoch: 160, loss: 0.184512
global_step: 22373, epoch: 160, loss: 0.141279
global_step: 22374, epoch: 160, loss: 0.228273
global_step: 22375, epoch: 160, loss: 0.171978
global_step: 22376, epoch: 160, loss: 0.171767
global_step: 22377, epoch: 160, loss: 0.272803
global_step: 22378, epoch: 160, loss: 0.307110
global_step: 22379, epoch: 160, loss: 0.242048
global_step: 22380, epoch: 160, loss: 0.170908
global_step: 22381, epoch: 160, loss: 0.178064
global_step: 22382, epoch: 160, loss: 0.216671
global_step: 22383, epoch: 160, loss: 0.210609
global_step: 22384, epoch: 160, loss: 0.218738
global_step: 22385, epoch: 160, loss: 0.177392
global_step: 22386, epoch: 160, loss: 0.209523
global_step: 22387, epoch: 160, loss: 0.213633
global_step: 22388, epoch: 160, loss: 0.200134
global_step: 22389, epoch: 160, loss: 0.288315
global_step: 22390, epoch: 160, loss: 0.235451
global_step: 22391, epoch: 160, loss: 0.229783
global_step: 22392, epoch: 160, loss: 0.256052
global_step: 22393, epoch: 160, loss: 0.208318
global_step: 22394, epoch: 160, loss: 0.158477
global_step: 22395, epoch: 160, loss: 0.307853
global_step: 22396, epoch: 160, loss: 0.227210
global_step: 22397, epoch: 160, loss: 0.162386
global_step: 22398, epoch: 160, loss: 0.241443
global_step: 22399, epoch: 160, loss: 0.178848
global_step: 22400, epoch: 160, loss: 0.004932
epoch: 160
train	acc: 0.9708	macro: p 0.9750, r 0.9577, f1: 0.9660	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5455	macro: p 0.3994, r 0.3172, f1: 0.3247	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5007
test	acc: 0.5831	macro: p 0.3507, r 0.3055, f1: 0.3116	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5404
global_step: 22401, epoch: 161, loss: 0.158780
global_step: 22402, epoch: 161, loss: 0.206966
global_step: 22403, epoch: 161, loss: 0.179588
global_step: 22404, epoch: 161, loss: 0.202545
global_step: 22405, epoch: 161, loss: 0.184518
global_step: 22406, epoch: 161, loss: 0.252908
global_step: 22407, epoch: 161, loss: 0.185439
global_step: 22408, epoch: 161, loss: 0.214963
global_step: 22409, epoch: 161, loss: 0.162210
global_step: 22410, epoch: 161, loss: 0.246825
global_step: 22411, epoch: 161, loss: 0.206341
global_step: 22412, epoch: 161, loss: 0.260663
global_step: 22413, epoch: 161, loss: 0.149478
global_step: 22414, epoch: 161, loss: 0.177972
global_step: 22415, epoch: 161, loss: 0.205706
global_step: 22416, epoch: 161, loss: 0.264732
global_step: 22417, epoch: 161, loss: 0.253643
global_step: 22418, epoch: 161, loss: 0.188973
global_step: 22419, epoch: 161, loss: 0.179778
global_step: 22420, epoch: 161, loss: 0.256279
global_step: 22421, epoch: 161, loss: 0.248735
global_step: 22422, epoch: 161, loss: 0.165958
global_step: 22423, epoch: 161, loss: 0.182873
global_step: 22424, epoch: 161, loss: 0.242072
global_step: 22425, epoch: 161, loss: 0.220041
global_step: 22426, epoch: 161, loss: 0.259032
global_step: 22427, epoch: 161, loss: 0.167273
global_step: 22428, epoch: 161, loss: 0.198302
global_step: 22429, epoch: 161, loss: 0.234867
global_step: 22430, epoch: 161, loss: 0.160803
global_step: 22431, epoch: 161, loss: 0.255392
global_step: 22432, epoch: 161, loss: 0.192383
global_step: 22433, epoch: 161, loss: 0.245758
global_step: 22434, epoch: 161, loss: 0.227450
global_step: 22435, epoch: 161, loss: 0.218891
global_step: 22436, epoch: 161, loss: 0.201379
global_step: 22437, epoch: 161, loss: 0.188719
global_step: 22438, epoch: 161, loss: 0.290207
global_step: 22439, epoch: 161, loss: 0.249774
global_step: 22440, epoch: 161, loss: 0.028963
epoch: 161
train	acc: 0.9704	macro: p 0.9744, r 0.9584, f1: 0.9661	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5329	macro: p 0.3526, r 0.3074, f1: 0.3078	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4922
test	acc: 0.5782	macro: p 0.3538, r 0.3148, f1: 0.3206	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5421
global_step: 22441, epoch: 162, loss: 0.236068
global_step: 22442, epoch: 162, loss: 0.250554
global_step: 22443, epoch: 162, loss: 0.206385
global_step: 22444, epoch: 162, loss: 0.156457
global_step: 22445, epoch: 162, loss: 0.192137
global_step: 22446, epoch: 162, loss: 0.245807
global_step: 22447, epoch: 162, loss: 0.223816
global_step: 22448, epoch: 162, loss: 0.219520
global_step: 22449, epoch: 162, loss: 0.216436
global_step: 22450, epoch: 162, loss: 0.169435
global_step: 22451, epoch: 162, loss: 0.183849
global_step: 22452, epoch: 162, loss: 0.143231
global_step: 22453, epoch: 162, loss: 0.236616
global_step: 22454, epoch: 162, loss: 0.212097
global_step: 22455, epoch: 162, loss: 0.145787
global_step: 22456, epoch: 162, loss: 0.183750
global_step: 22457, epoch: 162, loss: 0.197694
global_step: 22458, epoch: 162, loss: 0.211756
global_step: 22459, epoch: 162, loss: 0.250093
global_step: 22460, epoch: 162, loss: 0.265678
global_step: 22461, epoch: 162, loss: 0.221700
global_step: 22462, epoch: 162, loss: 0.194267
global_step: 22463, epoch: 162, loss: 0.191498
global_step: 22464, epoch: 162, loss: 0.223713
global_step: 22465, epoch: 162, loss: 0.222220
global_step: 22466, epoch: 162, loss: 0.181707
global_step: 22467, epoch: 162, loss: 0.180380
global_step: 22468, epoch: 162, loss: 0.175518
global_step: 22469, epoch: 162, loss: 0.252064
global_step: 22470, epoch: 162, loss: 0.176909
global_step: 22471, epoch: 162, loss: 0.196930
global_step: 22472, epoch: 162, loss: 0.237451
global_step: 22473, epoch: 162, loss: 0.223719
global_step: 22474, epoch: 162, loss: 0.173022
global_step: 22475, epoch: 162, loss: 0.133849
global_step: 22476, epoch: 162, loss: 0.305532
global_step: 22477, epoch: 162, loss: 0.191608
global_step: 22478, epoch: 162, loss: 0.185776
global_step: 22479, epoch: 162, loss: 0.220338
global_step: 22480, epoch: 162, loss: 1.139312
epoch: 162
train	acc: 0.9703	macro: p 0.9741, r 0.9590, f1: 0.9663	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5356	macro: p 0.3741, r 0.3125, f1: 0.3183	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4919
test	acc: 0.5808	macro: p 0.3581, r 0.3101, f1: 0.3186	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5404
global_step: 22481, epoch: 163, loss: 0.139192
global_step: 22482, epoch: 163, loss: 0.186371
global_step: 22483, epoch: 163, loss: 0.181079
global_step: 22484, epoch: 163, loss: 0.206135
global_step: 22485, epoch: 163, loss: 0.251423
global_step: 22486, epoch: 163, loss: 0.250441
global_step: 22487, epoch: 163, loss: 0.253316
global_step: 22488, epoch: 163, loss: 0.187674
global_step: 22489, epoch: 163, loss: 0.216592
global_step: 22490, epoch: 163, loss: 0.241979
global_step: 22491, epoch: 163, loss: 0.213207
global_step: 22492, epoch: 163, loss: 0.201416
global_step: 22493, epoch: 163, loss: 0.196858
global_step: 22494, epoch: 163, loss: 0.186245
global_step: 22495, epoch: 163, loss: 0.167773
global_step: 22496, epoch: 163, loss: 0.248313
global_step: 22497, epoch: 163, loss: 0.230441
global_step: 22498, epoch: 163, loss: 0.165318
global_step: 22499, epoch: 163, loss: 0.175855
global_step: 22500, epoch: 163, loss: 0.133954
global_step: 22501, epoch: 163, loss: 0.241522
global_step: 22502, epoch: 163, loss: 0.218802
global_step: 22503, epoch: 163, loss: 0.184827
global_step: 22504, epoch: 163, loss: 0.230356
global_step: 22505, epoch: 163, loss: 0.193941
global_step: 22506, epoch: 163, loss: 0.204518
global_step: 22507, epoch: 163, loss: 0.187488
global_step: 22508, epoch: 163, loss: 0.186158
global_step: 22509, epoch: 163, loss: 0.198708
global_step: 22510, epoch: 163, loss: 0.240654
global_step: 22511, epoch: 163, loss: 0.167280
global_step: 22512, epoch: 163, loss: 0.214485
global_step: 22513, epoch: 163, loss: 0.266213
global_step: 22514, epoch: 163, loss: 0.211103
global_step: 22515, epoch: 163, loss: 0.227507
global_step: 22516, epoch: 163, loss: 0.171687
global_step: 22517, epoch: 163, loss: 0.189087
global_step: 22518, epoch: 163, loss: 0.183371
global_step: 22519, epoch: 163, loss: 0.212321
global_step: 22520, epoch: 163, loss: 0.350179
epoch: 163
train	acc: 0.9698	macro: p 0.9738, r 0.9573, f1: 0.9652	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5383	macro: p 0.3759, r 0.3131, f1: 0.3130	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4953
test	acc: 0.5747	macro: p 0.3437, r 0.3076, f1: 0.3101	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5370
global_step: 22521, epoch: 164, loss: 0.235467
global_step: 22522, epoch: 164, loss: 0.206980
global_step: 22523, epoch: 164, loss: 0.200856
global_step: 22524, epoch: 164, loss: 0.153420
global_step: 22525, epoch: 164, loss: 0.156206
global_step: 22526, epoch: 164, loss: 0.198436
global_step: 22527, epoch: 164, loss: 0.238727
global_step: 22528, epoch: 164, loss: 0.222978
global_step: 22529, epoch: 164, loss: 0.165396
global_step: 22530, epoch: 164, loss: 0.184946
global_step: 22531, epoch: 164, loss: 0.238952
global_step: 22532, epoch: 164, loss: 0.174474
global_step: 22533, epoch: 164, loss: 0.188886
global_step: 22534, epoch: 164, loss: 0.153496
global_step: 22535, epoch: 164, loss: 0.201386
global_step: 22536, epoch: 164, loss: 0.249976
global_step: 22537, epoch: 164, loss: 0.217514
global_step: 22538, epoch: 164, loss: 0.198251
global_step: 22539, epoch: 164, loss: 0.195206
global_step: 22540, epoch: 164, loss: 0.286326
global_step: 22541, epoch: 164, loss: 0.192774
global_step: 22542, epoch: 164, loss: 0.180312
global_step: 22543, epoch: 164, loss: 0.185212
global_step: 22544, epoch: 164, loss: 0.278104
global_step: 22545, epoch: 164, loss: 0.215322
global_step: 22546, epoch: 164, loss: 0.163749
global_step: 22547, epoch: 164, loss: 0.240586
global_step: 22548, epoch: 164, loss: 0.238387
global_step: 22549, epoch: 164, loss: 0.215641
global_step: 22550, epoch: 164, loss: 0.237469
global_step: 22551, epoch: 164, loss: 0.183745
global_step: 22552, epoch: 164, loss: 0.170722
global_step: 22553, epoch: 164, loss: 0.224822
global_step: 22554, epoch: 164, loss: 0.180615
global_step: 22555, epoch: 164, loss: 0.283985
global_step: 22556, epoch: 164, loss: 0.209281
global_step: 22557, epoch: 164, loss: 0.224027
global_step: 22558, epoch: 164, loss: 0.217840
global_step: 22559, epoch: 164, loss: 0.174537
global_step: 22560, epoch: 164, loss: 0.333234
epoch: 164
train	acc: 0.9702	macro: p 0.9729, r 0.9583, f1: 0.9653	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5311	macro: p 0.3602, r 0.3052, f1: 0.3060	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4879
test	acc: 0.5759	macro: p 0.3491, r 0.3078, f1: 0.3130	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5369
global_step: 22561, epoch: 165, loss: 0.154948
global_step: 22562, epoch: 165, loss: 0.256839
global_step: 22563, epoch: 165, loss: 0.258296
global_step: 22564, epoch: 165, loss: 0.204208
global_step: 22565, epoch: 165, loss: 0.211057
global_step: 22566, epoch: 165, loss: 0.164589
global_step: 22567, epoch: 165, loss: 0.201369
global_step: 22568, epoch: 165, loss: 0.171872
global_step: 22569, epoch: 165, loss: 0.161345
global_step: 22570, epoch: 165, loss: 0.248866
global_step: 22571, epoch: 165, loss: 0.206291
global_step: 22572, epoch: 165, loss: 0.208388
global_step: 22573, epoch: 165, loss: 0.140994
global_step: 22574, epoch: 165, loss: 0.136728
global_step: 22575, epoch: 165, loss: 0.186248
global_step: 22576, epoch: 165, loss: 0.229959
global_step: 22577, epoch: 165, loss: 0.191152
global_step: 22578, epoch: 165, loss: 0.158462
global_step: 22579, epoch: 165, loss: 0.259755
global_step: 22580, epoch: 165, loss: 0.217345
global_step: 22581, epoch: 165, loss: 0.151291
global_step: 22582, epoch: 165, loss: 0.176819
global_step: 22583, epoch: 165, loss: 0.242170
global_step: 22584, epoch: 165, loss: 0.147311
global_step: 22585, epoch: 165, loss: 0.228973
global_step: 22586, epoch: 165, loss: 0.258106
global_step: 22587, epoch: 165, loss: 0.161136
global_step: 22588, epoch: 165, loss: 0.184398
global_step: 22589, epoch: 165, loss: 0.331910
global_step: 22590, epoch: 165, loss: 0.212891
global_step: 22591, epoch: 165, loss: 0.191148
global_step: 22592, epoch: 165, loss: 0.288266
global_step: 22593, epoch: 165, loss: 0.208426
global_step: 22594, epoch: 165, loss: 0.210825
global_step: 22595, epoch: 165, loss: 0.198768
global_step: 22596, epoch: 165, loss: 0.247402
global_step: 22597, epoch: 165, loss: 0.174705
global_step: 22598, epoch: 165, loss: 0.230202
global_step: 22599, epoch: 165, loss: 0.215644
global_step: 22600, epoch: 165, loss: 0.420410
epoch: 165
train	acc: 0.9702	macro: p 0.9728, r 0.9586, f1: 0.9654	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5266	macro: p 0.3566, r 0.3077, f1: 0.3051	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4868
test	acc: 0.5678	macro: p 0.3620, r 0.3147, f1: 0.3211	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5360
global_step: 22601, epoch: 166, loss: 0.205961
global_step: 22602, epoch: 166, loss: 0.215456
global_step: 22603, epoch: 166, loss: 0.242636
global_step: 22604, epoch: 166, loss: 0.202612
global_step: 22605, epoch: 166, loss: 0.224167
global_step: 22606, epoch: 166, loss: 0.201313
global_step: 22607, epoch: 166, loss: 0.216681
global_step: 22608, epoch: 166, loss: 0.230106
global_step: 22609, epoch: 166, loss: 0.262435
global_step: 22610, epoch: 166, loss: 0.273533
global_step: 22611, epoch: 166, loss: 0.174172
global_step: 22612, epoch: 166, loss: 0.229725
global_step: 22613, epoch: 166, loss: 0.199061
global_step: 22614, epoch: 166, loss: 0.263090
global_step: 22615, epoch: 166, loss: 0.178621
global_step: 22616, epoch: 166, loss: 0.169775
global_step: 22617, epoch: 166, loss: 0.176053
global_step: 22618, epoch: 166, loss: 0.160102
global_step: 22619, epoch: 166, loss: 0.180040
global_step: 22620, epoch: 166, loss: 0.275222
global_step: 22621, epoch: 166, loss: 0.141016
global_step: 22622, epoch: 166, loss: 0.195857
global_step: 22623, epoch: 166, loss: 0.179882
global_step: 22624, epoch: 166, loss: 0.192767
global_step: 22625, epoch: 166, loss: 0.183340
global_step: 22626, epoch: 166, loss: 0.121639
global_step: 22627, epoch: 166, loss: 0.178292
global_step: 22628, epoch: 166, loss: 0.220360
global_step: 22629, epoch: 166, loss: 0.206668
global_step: 22630, epoch: 166, loss: 0.128067
global_step: 22631, epoch: 166, loss: 0.241221
global_step: 22632, epoch: 166, loss: 0.227296
global_step: 22633, epoch: 166, loss: 0.242658
global_step: 22634, epoch: 166, loss: 0.173934
global_step: 22635, epoch: 166, loss: 0.309176
global_step: 22636, epoch: 166, loss: 0.126720
global_step: 22637, epoch: 166, loss: 0.228636
global_step: 22638, epoch: 166, loss: 0.237058
global_step: 22639, epoch: 166, loss: 0.270329
global_step: 22640, epoch: 166, loss: 0.079961
epoch: 166
train	acc: 0.9702	macro: p 0.9729, r 0.9597, f1: 0.9660	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5320	macro: p 0.3495, r 0.3063, f1: 0.3038	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4889
test	acc: 0.5747	macro: p 0.3539, r 0.3146, f1: 0.3225	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5405
global_step: 22641, epoch: 167, loss: 0.220580
global_step: 22642, epoch: 167, loss: 0.172482
global_step: 22643, epoch: 167, loss: 0.153709
global_step: 22644, epoch: 167, loss: 0.191168
global_step: 22645, epoch: 167, loss: 0.179528
global_step: 22646, epoch: 167, loss: 0.173621
global_step: 22647, epoch: 167, loss: 0.187755
global_step: 22648, epoch: 167, loss: 0.220452
global_step: 22649, epoch: 167, loss: 0.212344
global_step: 22650, epoch: 167, loss: 0.186860
global_step: 22651, epoch: 167, loss: 0.211207
global_step: 22652, epoch: 167, loss: 0.202470
global_step: 22653, epoch: 167, loss: 0.128248
global_step: 22654, epoch: 167, loss: 0.195398
global_step: 22655, epoch: 167, loss: 0.184562
global_step: 22656, epoch: 167, loss: 0.262716
global_step: 22657, epoch: 167, loss: 0.210721
global_step: 22658, epoch: 167, loss: 0.166174
global_step: 22659, epoch: 167, loss: 0.254742
global_step: 22660, epoch: 167, loss: 0.246782
global_step: 22661, epoch: 167, loss: 0.196323
global_step: 22662, epoch: 167, loss: 0.223267
global_step: 22663, epoch: 167, loss: 0.191396
global_step: 22664, epoch: 167, loss: 0.136555
global_step: 22665, epoch: 167, loss: 0.175052
global_step: 22666, epoch: 167, loss: 0.251960
global_step: 22667, epoch: 167, loss: 0.259328
global_step: 22668, epoch: 167, loss: 0.173620
global_step: 22669, epoch: 167, loss: 0.197248
global_step: 22670, epoch: 167, loss: 0.181473
global_step: 22671, epoch: 167, loss: 0.225443
global_step: 22672, epoch: 167, loss: 0.159475
global_step: 22673, epoch: 167, loss: 0.210047
global_step: 22674, epoch: 167, loss: 0.134860
global_step: 22675, epoch: 167, loss: 0.257149
global_step: 22676, epoch: 167, loss: 0.247350
global_step: 22677, epoch: 167, loss: 0.158816
global_step: 22678, epoch: 167, loss: 0.204282
global_step: 22679, epoch: 167, loss: 0.171990
global_step: 22680, epoch: 167, loss: 0.248992
epoch: 167
train	acc: 0.9711	macro: p 0.9732, r 0.9616, f1: 0.9672	micro: p 0.9711, r 0.9711, f1 0.9711	weighted_f1:0.9711
dev	acc: 0.5392	macro: p 0.3596, r 0.3119, f1: 0.3120	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4972
test	acc: 0.5736	macro: p 0.3623, r 0.3176, f1: 0.3264	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5411
global_step: 22681, epoch: 168, loss: 0.219799
global_step: 22682, epoch: 168, loss: 0.133143
global_step: 22683, epoch: 168, loss: 0.182464
global_step: 22684, epoch: 168, loss: 0.233858
global_step: 22685, epoch: 168, loss: 0.293912
global_step: 22686, epoch: 168, loss: 0.241520
global_step: 22687, epoch: 168, loss: 0.202888
global_step: 22688, epoch: 168, loss: 0.195030
global_step: 22689, epoch: 168, loss: 0.236219
global_step: 22690, epoch: 168, loss: 0.183200
global_step: 22691, epoch: 168, loss: 0.138524
global_step: 22692, epoch: 168, loss: 0.150660
global_step: 22693, epoch: 168, loss: 0.213825
global_step: 22694, epoch: 168, loss: 0.169463
global_step: 22695, epoch: 168, loss: 0.134702
global_step: 22696, epoch: 168, loss: 0.163138
global_step: 22697, epoch: 168, loss: 0.181218
global_step: 22698, epoch: 168, loss: 0.230480
global_step: 22699, epoch: 168, loss: 0.188103
global_step: 22700, epoch: 168, loss: 0.203244
global_step: 22701, epoch: 168, loss: 0.294025
global_step: 22702, epoch: 168, loss: 0.172735
global_step: 22703, epoch: 168, loss: 0.182160
global_step: 22704, epoch: 168, loss: 0.209231
global_step: 22705, epoch: 168, loss: 0.201300
global_step: 22706, epoch: 168, loss: 0.208940
global_step: 22707, epoch: 168, loss: 0.196502
global_step: 22708, epoch: 168, loss: 0.176959
global_step: 22709, epoch: 168, loss: 0.209860
global_step: 22710, epoch: 168, loss: 0.193711
global_step: 22711, epoch: 168, loss: 0.195532
global_step: 22712, epoch: 168, loss: 0.231606
global_step: 22713, epoch: 168, loss: 0.124824
global_step: 22714, epoch: 168, loss: 0.162055
global_step: 22715, epoch: 168, loss: 0.191013
global_step: 22716, epoch: 168, loss: 0.209536
global_step: 22717, epoch: 168, loss: 0.217540
global_step: 22718, epoch: 168, loss: 0.191117
global_step: 22719, epoch: 168, loss: 0.251527
global_step: 22720, epoch: 168, loss: 0.422822
epoch: 168
train	acc: 0.9710	macro: p 0.9737, r 0.9600, f1: 0.9666	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5356	macro: p 0.3529, r 0.3136, f1: 0.3136	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4969
test	acc: 0.5705	macro: p 0.3464, r 0.3153, f1: 0.3221	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5410
global_step: 22721, epoch: 169, loss: 0.223968
global_step: 22722, epoch: 169, loss: 0.158991
global_step: 22723, epoch: 169, loss: 0.197751
global_step: 22724, epoch: 169, loss: 0.218229
global_step: 22725, epoch: 169, loss: 0.189490
global_step: 22726, epoch: 169, loss: 0.199435
global_step: 22727, epoch: 169, loss: 0.231603
global_step: 22728, epoch: 169, loss: 0.178547
global_step: 22729, epoch: 169, loss: 0.117958
global_step: 22730, epoch: 169, loss: 0.183560
global_step: 22731, epoch: 169, loss: 0.217824
global_step: 22732, epoch: 169, loss: 0.179823
global_step: 22733, epoch: 169, loss: 0.172350
global_step: 22734, epoch: 169, loss: 0.169040
global_step: 22735, epoch: 169, loss: 0.216604
global_step: 22736, epoch: 169, loss: 0.184460
global_step: 22737, epoch: 169, loss: 0.162698
global_step: 22738, epoch: 169, loss: 0.250313
global_step: 22739, epoch: 169, loss: 0.247109
global_step: 22740, epoch: 169, loss: 0.195984
global_step: 22741, epoch: 169, loss: 0.232534
global_step: 22742, epoch: 169, loss: 0.166820
global_step: 22743, epoch: 169, loss: 0.230540
global_step: 22744, epoch: 169, loss: 0.173498
global_step: 22745, epoch: 169, loss: 0.210882
global_step: 22746, epoch: 169, loss: 0.254038
global_step: 22747, epoch: 169, loss: 0.108890
global_step: 22748, epoch: 169, loss: 0.221920
global_step: 22749, epoch: 169, loss: 0.227398
global_step: 22750, epoch: 169, loss: 0.196679
global_step: 22751, epoch: 169, loss: 0.170198
global_step: 22752, epoch: 169, loss: 0.122626
global_step: 22753, epoch: 169, loss: 0.231243
global_step: 22754, epoch: 169, loss: 0.186373
global_step: 22755, epoch: 169, loss: 0.241692
global_step: 22756, epoch: 169, loss: 0.244904
global_step: 22757, epoch: 169, loss: 0.246830
global_step: 22758, epoch: 169, loss: 0.204932
global_step: 22759, epoch: 169, loss: 0.236385
global_step: 22760, epoch: 169, loss: 0.060059
epoch: 169
train	acc: 0.9708	macro: p 0.9742, r 0.9582, f1: 0.9659	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5419	macro: p 0.3887, r 0.3105, f1: 0.3105	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4948
test	acc: 0.5805	macro: p 0.3523, r 0.3090, f1: 0.3156	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5409
global_step: 22761, epoch: 170, loss: 0.149288
global_step: 22762, epoch: 170, loss: 0.176922
global_step: 22763, epoch: 170, loss: 0.262015
global_step: 22764, epoch: 170, loss: 0.208650
global_step: 22765, epoch: 170, loss: 0.179556
global_step: 22766, epoch: 170, loss: 0.186829
global_step: 22767, epoch: 170, loss: 0.243423
global_step: 22768, epoch: 170, loss: 0.205727
global_step: 22769, epoch: 170, loss: 0.202627
global_step: 22770, epoch: 170, loss: 0.194777
global_step: 22771, epoch: 170, loss: 0.175148
global_step: 22772, epoch: 170, loss: 0.221347
global_step: 22773, epoch: 170, loss: 0.213936
global_step: 22774, epoch: 170, loss: 0.133866
global_step: 22775, epoch: 170, loss: 0.151873
global_step: 22776, epoch: 170, loss: 0.200275
global_step: 22777, epoch: 170, loss: 0.230565
global_step: 22778, epoch: 170, loss: 0.225188
global_step: 22779, epoch: 170, loss: 0.156592
global_step: 22780, epoch: 170, loss: 0.176823
global_step: 22781, epoch: 170, loss: 0.283840
global_step: 22782, epoch: 170, loss: 0.225425
global_step: 22783, epoch: 170, loss: 0.151470
global_step: 22784, epoch: 170, loss: 0.172278
global_step: 22785, epoch: 170, loss: 0.214983
global_step: 22786, epoch: 170, loss: 0.168685
global_step: 22787, epoch: 170, loss: 0.178748
global_step: 22788, epoch: 170, loss: 0.263736
global_step: 22789, epoch: 170, loss: 0.177318
global_step: 22790, epoch: 170, loss: 0.191905
global_step: 22791, epoch: 170, loss: 0.190260
global_step: 22792, epoch: 170, loss: 0.249420
global_step: 22793, epoch: 170, loss: 0.213630
global_step: 22794, epoch: 170, loss: 0.263835
global_step: 22795, epoch: 170, loss: 0.234264
global_step: 22796, epoch: 170, loss: 0.237721
global_step: 22797, epoch: 170, loss: 0.234080
global_step: 22798, epoch: 170, loss: 0.228638
global_step: 22799, epoch: 170, loss: 0.232057
global_step: 22800, epoch: 170, loss: 0.019830
epoch: 170
train	acc: 0.9716	macro: p 0.9745, r 0.9606, f1: 0.9673	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5311	macro: p 0.3574, r 0.3046, f1: 0.3026	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4865
test	acc: 0.5705	macro: p 0.3522, r 0.3110, f1: 0.3181	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5347
global_step: 22801, epoch: 171, loss: 0.151575
global_step: 22802, epoch: 171, loss: 0.231117
global_step: 22803, epoch: 171, loss: 0.142292
global_step: 22804, epoch: 171, loss: 0.210275
global_step: 22805, epoch: 171, loss: 0.171332
global_step: 22806, epoch: 171, loss: 0.148437
global_step: 22807, epoch: 171, loss: 0.205774
global_step: 22808, epoch: 171, loss: 0.153579
global_step: 22809, epoch: 171, loss: 0.179894
global_step: 22810, epoch: 171, loss: 0.149821
global_step: 22811, epoch: 171, loss: 0.181623
global_step: 22812, epoch: 171, loss: 0.193891
global_step: 22813, epoch: 171, loss: 0.219227
global_step: 22814, epoch: 171, loss: 0.234755
global_step: 22815, epoch: 171, loss: 0.257025
global_step: 22816, epoch: 171, loss: 0.246431
global_step: 22817, epoch: 171, loss: 0.159024
global_step: 22818, epoch: 171, loss: 0.150127
global_step: 22819, epoch: 171, loss: 0.247855
global_step: 22820, epoch: 171, loss: 0.192842
global_step: 22821, epoch: 171, loss: 0.191270
global_step: 22822, epoch: 171, loss: 0.200347
global_step: 22823, epoch: 171, loss: 0.194297
global_step: 22824, epoch: 171, loss: 0.201346
global_step: 22825, epoch: 171, loss: 0.247853
global_step: 22826, epoch: 171, loss: 0.115691
global_step: 22827, epoch: 171, loss: 0.217314
global_step: 22828, epoch: 171, loss: 0.180402
global_step: 22829, epoch: 171, loss: 0.160670
global_step: 22830, epoch: 171, loss: 0.211768
global_step: 22831, epoch: 171, loss: 0.231299
global_step: 22832, epoch: 171, loss: 0.236933
global_step: 22833, epoch: 171, loss: 0.193829
global_step: 22834, epoch: 171, loss: 0.171960
global_step: 22835, epoch: 171, loss: 0.178412
global_step: 22836, epoch: 171, loss: 0.212718
global_step: 22837, epoch: 171, loss: 0.205838
global_step: 22838, epoch: 171, loss: 0.291717
global_step: 22839, epoch: 171, loss: 0.154221
global_step: 22840, epoch: 171, loss: 0.082104
epoch: 171
train	acc: 0.9704	macro: p 0.9733, r 0.9600, f1: 0.9664	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5383	macro: p 0.3670, r 0.3109, f1: 0.3117	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4963
test	acc: 0.5770	macro: p 0.3501, r 0.3122, f1: 0.3171	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5419
global_step: 22841, epoch: 172, loss: 0.182901
global_step: 22842, epoch: 172, loss: 0.269561
global_step: 22843, epoch: 172, loss: 0.185395
global_step: 22844, epoch: 172, loss: 0.198616
global_step: 22845, epoch: 172, loss: 0.182517
global_step: 22846, epoch: 172, loss: 0.301872
global_step: 22847, epoch: 172, loss: 0.206913
global_step: 22848, epoch: 172, loss: 0.188376
global_step: 22849, epoch: 172, loss: 0.165569
global_step: 22850, epoch: 172, loss: 0.126780
global_step: 22851, epoch: 172, loss: 0.169482
global_step: 22852, epoch: 172, loss: 0.150890
global_step: 22853, epoch: 172, loss: 0.214555
global_step: 22854, epoch: 172, loss: 0.199505
global_step: 22855, epoch: 172, loss: 0.194411
global_step: 22856, epoch: 172, loss: 0.186826
global_step: 22857, epoch: 172, loss: 0.166697
global_step: 22858, epoch: 172, loss: 0.237779
global_step: 22859, epoch: 172, loss: 0.180351
global_step: 22860, epoch: 172, loss: 0.217254
global_step: 22861, epoch: 172, loss: 0.207965
global_step: 22862, epoch: 172, loss: 0.233627
global_step: 22863, epoch: 172, loss: 0.189929
global_step: 22864, epoch: 172, loss: 0.196384
global_step: 22865, epoch: 172, loss: 0.138721
global_step: 22866, epoch: 172, loss: 0.191891
global_step: 22867, epoch: 172, loss: 0.171692
global_step: 22868, epoch: 172, loss: 0.201678
global_step: 22869, epoch: 172, loss: 0.206665
global_step: 22870, epoch: 172, loss: 0.201553
global_step: 22871, epoch: 172, loss: 0.210864
global_step: 22872, epoch: 172, loss: 0.196071
global_step: 22873, epoch: 172, loss: 0.252328
global_step: 22874, epoch: 172, loss: 0.187070
global_step: 22875, epoch: 172, loss: 0.200991
global_step: 22876, epoch: 172, loss: 0.230772
global_step: 22877, epoch: 172, loss: 0.172456
global_step: 22878, epoch: 172, loss: 0.192917
global_step: 22879, epoch: 172, loss: 0.138404
global_step: 22880, epoch: 172, loss: 0.312670
epoch: 172
train	acc: 0.9711	macro: p 0.9737, r 0.9616, f1: 0.9675	micro: p 0.9711, r 0.9711, f1 0.9711	weighted_f1:0.9711
dev	acc: 0.5383	macro: p 0.3853, r 0.3123, f1: 0.3183	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4939
test	acc: 0.5812	macro: p 0.3646, r 0.3159, f1: 0.3254	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5445
global_step: 22881, epoch: 173, loss: 0.183433
global_step: 22882, epoch: 173, loss: 0.184892
global_step: 22883, epoch: 173, loss: 0.142303
global_step: 22884, epoch: 173, loss: 0.211121
global_step: 22885, epoch: 173, loss: 0.182068
global_step: 22886, epoch: 173, loss: 0.233421
global_step: 22887, epoch: 173, loss: 0.158168
global_step: 22888, epoch: 173, loss: 0.183493
global_step: 22889, epoch: 173, loss: 0.168443
global_step: 22890, epoch: 173, loss: 0.234525
global_step: 22891, epoch: 173, loss: 0.160002
global_step: 22892, epoch: 173, loss: 0.201901
global_step: 22893, epoch: 173, loss: 0.169939
global_step: 22894, epoch: 173, loss: 0.208926
global_step: 22895, epoch: 173, loss: 0.256707
global_step: 22896, epoch: 173, loss: 0.201389
global_step: 22897, epoch: 173, loss: 0.227644
global_step: 22898, epoch: 173, loss: 0.162606
global_step: 22899, epoch: 173, loss: 0.219033
global_step: 22900, epoch: 173, loss: 0.210708
global_step: 22901, epoch: 173, loss: 0.218506
global_step: 22902, epoch: 173, loss: 0.206729
global_step: 22903, epoch: 173, loss: 0.145380
global_step: 22904, epoch: 173, loss: 0.240185
global_step: 22905, epoch: 173, loss: 0.190566
global_step: 22906, epoch: 173, loss: 0.163102
global_step: 22907, epoch: 173, loss: 0.159379
global_step: 22908, epoch: 173, loss: 0.232609
global_step: 22909, epoch: 173, loss: 0.151620
global_step: 22910, epoch: 173, loss: 0.184235
global_step: 22911, epoch: 173, loss: 0.145242
global_step: 22912, epoch: 173, loss: 0.214826
global_step: 22913, epoch: 173, loss: 0.172015
global_step: 22914, epoch: 173, loss: 0.183635
global_step: 22915, epoch: 173, loss: 0.162821
global_step: 22916, epoch: 173, loss: 0.178458
global_step: 22917, epoch: 173, loss: 0.212318
global_step: 22918, epoch: 173, loss: 0.227279
global_step: 22919, epoch: 173, loss: 0.203509
global_step: 22920, epoch: 173, loss: 0.009968
epoch: 173
train	acc: 0.9710	macro: p 0.9740, r 0.9599, f1: 0.9667	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5383	macro: p 0.4369, r 0.3254, f1: 0.3347	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4957
test	acc: 0.5755	macro: p 0.3539, r 0.3120, f1: 0.3152	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5369
global_step: 22921, epoch: 174, loss: 0.154716
global_step: 22922, epoch: 174, loss: 0.155474
global_step: 22923, epoch: 174, loss: 0.166708
global_step: 22924, epoch: 174, loss: 0.157516
global_step: 22925, epoch: 174, loss: 0.180409
global_step: 22926, epoch: 174, loss: 0.215108
global_step: 22927, epoch: 174, loss: 0.243986
global_step: 22928, epoch: 174, loss: 0.192756
global_step: 22929, epoch: 174, loss: 0.139186
global_step: 22930, epoch: 174, loss: 0.274809
global_step: 22931, epoch: 174, loss: 0.218506
global_step: 22932, epoch: 174, loss: 0.162020
global_step: 22933, epoch: 174, loss: 0.115616
global_step: 22934, epoch: 174, loss: 0.208453
global_step: 22935, epoch: 174, loss: 0.122779
global_step: 22936, epoch: 174, loss: 0.187742
global_step: 22937, epoch: 174, loss: 0.169748
global_step: 22938, epoch: 174, loss: 0.284562
global_step: 22939, epoch: 174, loss: 0.120810
global_step: 22940, epoch: 174, loss: 0.173655
global_step: 22941, epoch: 174, loss: 0.190556
global_step: 22942, epoch: 174, loss: 0.183197
global_step: 22943, epoch: 174, loss: 0.212216
global_step: 22944, epoch: 174, loss: 0.199875
global_step: 22945, epoch: 174, loss: 0.249630
global_step: 22946, epoch: 174, loss: 0.298198
global_step: 22947, epoch: 174, loss: 0.230782
global_step: 22948, epoch: 174, loss: 0.200356
global_step: 22949, epoch: 174, loss: 0.221276
global_step: 22950, epoch: 174, loss: 0.180886
global_step: 22951, epoch: 174, loss: 0.225504
global_step: 22952, epoch: 174, loss: 0.211408
global_step: 22953, epoch: 174, loss: 0.201075
global_step: 22954, epoch: 174, loss: 0.171300
global_step: 22955, epoch: 174, loss: 0.244114
global_step: 22956, epoch: 174, loss: 0.217146
global_step: 22957, epoch: 174, loss: 0.265376
global_step: 22958, epoch: 174, loss: 0.177879
global_step: 22959, epoch: 174, loss: 0.177155
global_step: 22960, epoch: 174, loss: 0.143091
epoch: 174
train	acc: 0.9708	macro: p 0.9752, r 0.9597, f1: 0.9672	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5356	macro: p 0.4050, r 0.3220, f1: 0.3303	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4942
test	acc: 0.5713	macro: p 0.3487, r 0.3076, f1: 0.3126	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5352
global_step: 22961, epoch: 175, loss: 0.146932
global_step: 22962, epoch: 175, loss: 0.156397
global_step: 22963, epoch: 175, loss: 0.156637
global_step: 22964, epoch: 175, loss: 0.218418
global_step: 22965, epoch: 175, loss: 0.194430
global_step: 22966, epoch: 175, loss: 0.181070
global_step: 22967, epoch: 175, loss: 0.205661
global_step: 22968, epoch: 175, loss: 0.187049
global_step: 22969, epoch: 175, loss: 0.181809
global_step: 22970, epoch: 175, loss: 0.146917
global_step: 22971, epoch: 175, loss: 0.222638
global_step: 22972, epoch: 175, loss: 0.197838
global_step: 22973, epoch: 175, loss: 0.252629
global_step: 22974, epoch: 175, loss: 0.181590
global_step: 22975, epoch: 175, loss: 0.152448
global_step: 22976, epoch: 175, loss: 0.235251
global_step: 22977, epoch: 175, loss: 0.183640
global_step: 22978, epoch: 175, loss: 0.217109
global_step: 22979, epoch: 175, loss: 0.165026
global_step: 22980, epoch: 175, loss: 0.214242
global_step: 22981, epoch: 175, loss: 0.183139
global_step: 22982, epoch: 175, loss: 0.145413
global_step: 22983, epoch: 175, loss: 0.218274
global_step: 22984, epoch: 175, loss: 0.205209
global_step: 22985, epoch: 175, loss: 0.193780
global_step: 22986, epoch: 175, loss: 0.190101
global_step: 22987, epoch: 175, loss: 0.179777
global_step: 22988, epoch: 175, loss: 0.200281
global_step: 22989, epoch: 175, loss: 0.187479
global_step: 22990, epoch: 175, loss: 0.207508
global_step: 22991, epoch: 175, loss: 0.243878
global_step: 22992, epoch: 175, loss: 0.199391
global_step: 22993, epoch: 175, loss: 0.242541
global_step: 22994, epoch: 175, loss: 0.195714
global_step: 22995, epoch: 175, loss: 0.179824
global_step: 22996, epoch: 175, loss: 0.293136
global_step: 22997, epoch: 175, loss: 0.183872
global_step: 22998, epoch: 175, loss: 0.183467
global_step: 22999, epoch: 175, loss: 0.161613
global_step: 23000, epoch: 175, loss: 0.008576
epoch: 175
train	acc: 0.9717	macro: p 0.9746, r 0.9625, f1: 0.9684	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5338	macro: p 0.3733, r 0.3112, f1: 0.3151	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4899
test	acc: 0.5732	macro: p 0.3450, r 0.3062, f1: 0.3132	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5355
global_step: 23001, epoch: 176, loss: 0.250036
global_step: 23002, epoch: 176, loss: 0.176410
global_step: 23003, epoch: 176, loss: 0.234938
global_step: 23004, epoch: 176, loss: 0.166206
global_step: 23005, epoch: 176, loss: 0.244768
global_step: 23006, epoch: 176, loss: 0.152866
global_step: 23007, epoch: 176, loss: 0.179008
global_step: 23008, epoch: 176, loss: 0.189071
global_step: 23009, epoch: 176, loss: 0.161963
global_step: 23010, epoch: 176, loss: 0.208332
global_step: 23011, epoch: 176, loss: 0.185639
global_step: 23012, epoch: 176, loss: 0.227222
global_step: 23013, epoch: 176, loss: 0.213971
global_step: 23014, epoch: 176, loss: 0.212065
global_step: 23015, epoch: 176, loss: 0.166945
global_step: 23016, epoch: 176, loss: 0.218251
global_step: 23017, epoch: 176, loss: 0.163099
global_step: 23018, epoch: 176, loss: 0.185855
global_step: 23019, epoch: 176, loss: 0.215648
global_step: 23020, epoch: 176, loss: 0.222178
global_step: 23021, epoch: 176, loss: 0.217083
global_step: 23022, epoch: 176, loss: 0.171519
global_step: 23023, epoch: 176, loss: 0.233150
global_step: 23024, epoch: 176, loss: 0.179986
global_step: 23025, epoch: 176, loss: 0.162080
global_step: 23026, epoch: 176, loss: 0.273247
global_step: 23027, epoch: 176, loss: 0.181130
global_step: 23028, epoch: 176, loss: 0.260444
global_step: 23029, epoch: 176, loss: 0.183413
global_step: 23030, epoch: 176, loss: 0.156837
global_step: 23031, epoch: 176, loss: 0.240731
global_step: 23032, epoch: 176, loss: 0.182636
global_step: 23033, epoch: 176, loss: 0.182993
global_step: 23034, epoch: 176, loss: 0.127262
global_step: 23035, epoch: 176, loss: 0.236637
global_step: 23036, epoch: 176, loss: 0.239631
global_step: 23037, epoch: 176, loss: 0.183024
global_step: 23038, epoch: 176, loss: 0.298747
global_step: 23039, epoch: 176, loss: 0.176552
global_step: 23040, epoch: 176, loss: 0.089720
epoch: 176
train	acc: 0.9710	macro: p 0.9751, r 0.9621, f1: 0.9684	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5437	macro: p 0.4065, r 0.3270, f1: 0.3319	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5005
test	acc: 0.5716	macro: p 0.3314, r 0.3063, f1: 0.3073	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5337
global_step: 23041, epoch: 177, loss: 0.165688
global_step: 23042, epoch: 177, loss: 0.176710
global_step: 23043, epoch: 177, loss: 0.157572
global_step: 23044, epoch: 177, loss: 0.185153
global_step: 23045, epoch: 177, loss: 0.194122
global_step: 23046, epoch: 177, loss: 0.155279
global_step: 23047, epoch: 177, loss: 0.188023
global_step: 23048, epoch: 177, loss: 0.198508
global_step: 23049, epoch: 177, loss: 0.167841
global_step: 23050, epoch: 177, loss: 0.147364
global_step: 23051, epoch: 177, loss: 0.203002
global_step: 23052, epoch: 177, loss: 0.188137
global_step: 23053, epoch: 177, loss: 0.181842
global_step: 23054, epoch: 177, loss: 0.186807
global_step: 23055, epoch: 177, loss: 0.210758
global_step: 23056, epoch: 177, loss: 0.180867
global_step: 23057, epoch: 177, loss: 0.098781
global_step: 23058, epoch: 177, loss: 0.242013
global_step: 23059, epoch: 177, loss: 0.175047
global_step: 23060, epoch: 177, loss: 0.240648
global_step: 23061, epoch: 177, loss: 0.203204
global_step: 23062, epoch: 177, loss: 0.215504
global_step: 23063, epoch: 177, loss: 0.243833
global_step: 23064, epoch: 177, loss: 0.203702
global_step: 23065, epoch: 177, loss: 0.215622
global_step: 23066, epoch: 177, loss: 0.162406
global_step: 23067, epoch: 177, loss: 0.201535
global_step: 23068, epoch: 177, loss: 0.186641
global_step: 23069, epoch: 177, loss: 0.156777
global_step: 23070, epoch: 177, loss: 0.193008
global_step: 23071, epoch: 177, loss: 0.137143
global_step: 23072, epoch: 177, loss: 0.234110
global_step: 23073, epoch: 177, loss: 0.179226
global_step: 23074, epoch: 177, loss: 0.249123
global_step: 23075, epoch: 177, loss: 0.126933
global_step: 23076, epoch: 177, loss: 0.180547
global_step: 23077, epoch: 177, loss: 0.200216
global_step: 23078, epoch: 177, loss: 0.246746
global_step: 23079, epoch: 177, loss: 0.227723
global_step: 23080, epoch: 177, loss: 0.377383
epoch: 177
train	acc: 0.9706	macro: p 0.9756, r 0.9594, f1: 0.9673	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5401	macro: p 0.3694, r 0.3084, f1: 0.3099	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4946
test	acc: 0.5743	macro: p 0.3495, r 0.3035, f1: 0.3106	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5339
global_step: 23081, epoch: 178, loss: 0.190257
global_step: 23082, epoch: 178, loss: 0.206208
global_step: 23083, epoch: 178, loss: 0.170939
global_step: 23084, epoch: 178, loss: 0.151557
global_step: 23085, epoch: 178, loss: 0.186051
global_step: 23086, epoch: 178, loss: 0.169247
global_step: 23087, epoch: 178, loss: 0.236872
global_step: 23088, epoch: 178, loss: 0.221041
global_step: 23089, epoch: 178, loss: 0.198023
global_step: 23090, epoch: 178, loss: 0.197485
global_step: 23091, epoch: 178, loss: 0.212065
global_step: 23092, epoch: 178, loss: 0.195849
global_step: 23093, epoch: 178, loss: 0.202910
global_step: 23094, epoch: 178, loss: 0.190066
global_step: 23095, epoch: 178, loss: 0.187160
global_step: 23096, epoch: 178, loss: 0.160553
global_step: 23097, epoch: 178, loss: 0.209398
global_step: 23098, epoch: 178, loss: 0.180869
global_step: 23099, epoch: 178, loss: 0.277407
global_step: 23100, epoch: 178, loss: 0.218751
global_step: 23101, epoch: 178, loss: 0.211933
global_step: 23102, epoch: 178, loss: 0.181575
global_step: 23103, epoch: 178, loss: 0.208186
global_step: 23104, epoch: 178, loss: 0.191595
global_step: 23105, epoch: 178, loss: 0.212301
global_step: 23106, epoch: 178, loss: 0.289261
global_step: 23107, epoch: 178, loss: 0.193018
global_step: 23108, epoch: 178, loss: 0.149841
global_step: 23109, epoch: 178, loss: 0.124168
global_step: 23110, epoch: 178, loss: 0.237855
global_step: 23111, epoch: 178, loss: 0.220847
global_step: 23112, epoch: 178, loss: 0.170439
global_step: 23113, epoch: 178, loss: 0.189074
global_step: 23114, epoch: 178, loss: 0.149262
global_step: 23115, epoch: 178, loss: 0.142238
global_step: 23116, epoch: 178, loss: 0.211371
global_step: 23117, epoch: 178, loss: 0.157963
global_step: 23118, epoch: 178, loss: 0.293886
global_step: 23119, epoch: 178, loss: 0.170759
global_step: 23120, epoch: 178, loss: 0.028113
epoch: 178
train	acc: 0.9714	macro: p 0.9751, r 0.9605, f1: 0.9676	micro: p 0.9714, r 0.9714, f1 0.9714	weighted_f1:0.9714
dev	acc: 0.5392	macro: p 0.3791, r 0.3153, f1: 0.3167	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4987
test	acc: 0.5663	macro: p 0.3357, r 0.3038, f1: 0.3068	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5316
global_step: 23121, epoch: 179, loss: 0.186068
global_step: 23122, epoch: 179, loss: 0.150778
global_step: 23123, epoch: 179, loss: 0.138515
global_step: 23124, epoch: 179, loss: 0.232182
global_step: 23125, epoch: 179, loss: 0.209365
global_step: 23126, epoch: 179, loss: 0.157249
global_step: 23127, epoch: 179, loss: 0.186684
global_step: 23128, epoch: 179, loss: 0.178650
global_step: 23129, epoch: 179, loss: 0.179629
global_step: 23130, epoch: 179, loss: 0.183969
global_step: 23131, epoch: 179, loss: 0.116167
global_step: 23132, epoch: 179, loss: 0.169843
global_step: 23133, epoch: 179, loss: 0.152971
global_step: 23134, epoch: 179, loss: 0.200096
global_step: 23135, epoch: 179, loss: 0.145291
global_step: 23136, epoch: 179, loss: 0.229929
global_step: 23137, epoch: 179, loss: 0.201114
global_step: 23138, epoch: 179, loss: 0.179465
global_step: 23139, epoch: 179, loss: 0.182159
global_step: 23140, epoch: 179, loss: 0.180580
global_step: 23141, epoch: 179, loss: 0.165881
global_step: 23142, epoch: 179, loss: 0.243114
global_step: 23143, epoch: 179, loss: 0.244830
global_step: 23144, epoch: 179, loss: 0.232961
global_step: 23145, epoch: 179, loss: 0.147291
global_step: 23146, epoch: 179, loss: 0.176563
global_step: 23147, epoch: 179, loss: 0.172495
global_step: 23148, epoch: 179, loss: 0.170762
global_step: 23149, epoch: 179, loss: 0.183804
global_step: 23150, epoch: 179, loss: 0.219738
global_step: 23151, epoch: 179, loss: 0.142960
global_step: 23152, epoch: 179, loss: 0.153936
global_step: 23153, epoch: 179, loss: 0.201981
global_step: 23154, epoch: 179, loss: 0.238361
global_step: 23155, epoch: 179, loss: 0.181821
global_step: 23156, epoch: 179, loss: 0.158106
global_step: 23157, epoch: 179, loss: 0.259359
global_step: 23158, epoch: 179, loss: 0.220254
global_step: 23159, epoch: 179, loss: 0.197085
global_step: 23160, epoch: 179, loss: 0.018777
epoch: 179
train	acc: 0.9715	macro: p 0.9749, r 0.9616, f1: 0.9681	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5455	macro: p 0.4285, r 0.3245, f1: 0.3308	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5026
test	acc: 0.5774	macro: p 0.3515, r 0.3118, f1: 0.3166	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5396
global_step: 23161, epoch: 180, loss: 0.226087
global_step: 23162, epoch: 180, loss: 0.250243
global_step: 23163, epoch: 180, loss: 0.168493
global_step: 23164, epoch: 180, loss: 0.209076
global_step: 23165, epoch: 180, loss: 0.260790
global_step: 23166, epoch: 180, loss: 0.149613
global_step: 23167, epoch: 180, loss: 0.166195
global_step: 23168, epoch: 180, loss: 0.141357
global_step: 23169, epoch: 180, loss: 0.207036
global_step: 23170, epoch: 180, loss: 0.211317
global_step: 23171, epoch: 180, loss: 0.168830
global_step: 23172, epoch: 180, loss: 0.193734
global_step: 23173, epoch: 180, loss: 0.129442
global_step: 23174, epoch: 180, loss: 0.186074
global_step: 23175, epoch: 180, loss: 0.212740
global_step: 23176, epoch: 180, loss: 0.227818
global_step: 23177, epoch: 180, loss: 0.245998
global_step: 23178, epoch: 180, loss: 0.205461
global_step: 23179, epoch: 180, loss: 0.166558
global_step: 23180, epoch: 180, loss: 0.162979
global_step: 23181, epoch: 180, loss: 0.227577
global_step: 23182, epoch: 180, loss: 0.145786
global_step: 23183, epoch: 180, loss: 0.199805
global_step: 23184, epoch: 180, loss: 0.169086
global_step: 23185, epoch: 180, loss: 0.157822
global_step: 23186, epoch: 180, loss: 0.215347
global_step: 23187, epoch: 180, loss: 0.159198
global_step: 23188, epoch: 180, loss: 0.200608
global_step: 23189, epoch: 180, loss: 0.156912
global_step: 23190, epoch: 180, loss: 0.155562
global_step: 23191, epoch: 180, loss: 0.229250
global_step: 23192, epoch: 180, loss: 0.255255
global_step: 23193, epoch: 180, loss: 0.182777
global_step: 23194, epoch: 180, loss: 0.207355
global_step: 23195, epoch: 180, loss: 0.183665
global_step: 23196, epoch: 180, loss: 0.194117
global_step: 23197, epoch: 180, loss: 0.228638
global_step: 23198, epoch: 180, loss: 0.156518
global_step: 23199, epoch: 180, loss: 0.231749
global_step: 23200, epoch: 180, loss: 0.007902
epoch: 180
train	acc: 0.9719	macro: p 0.9751, r 0.9620, f1: 0.9684	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5419	macro: p 0.3899, r 0.3234, f1: 0.3306	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5035
test	acc: 0.5755	macro: p 0.3582, r 0.3166, f1: 0.3245	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5419
global_step: 23201, epoch: 181, loss: 0.149300
global_step: 23202, epoch: 181, loss: 0.196783
global_step: 23203, epoch: 181, loss: 0.198597
global_step: 23204, epoch: 181, loss: 0.201113
global_step: 23205, epoch: 181, loss: 0.181522
global_step: 23206, epoch: 181, loss: 0.242793
global_step: 23207, epoch: 181, loss: 0.189959
global_step: 23208, epoch: 181, loss: 0.240560
global_step: 23209, epoch: 181, loss: 0.233725
global_step: 23210, epoch: 181, loss: 0.255775
global_step: 23211, epoch: 181, loss: 0.161276
global_step: 23212, epoch: 181, loss: 0.270484
global_step: 23213, epoch: 181, loss: 0.124767
global_step: 23214, epoch: 181, loss: 0.210498
global_step: 23215, epoch: 181, loss: 0.158220
global_step: 23216, epoch: 181, loss: 0.192302
global_step: 23217, epoch: 181, loss: 0.184143
global_step: 23218, epoch: 181, loss: 0.193576
global_step: 23219, epoch: 181, loss: 0.174950
global_step: 23220, epoch: 181, loss: 0.212107
global_step: 23221, epoch: 181, loss: 0.219066
global_step: 23222, epoch: 181, loss: 0.157036
global_step: 23223, epoch: 181, loss: 0.165283
global_step: 23224, epoch: 181, loss: 0.194903
global_step: 23225, epoch: 181, loss: 0.175725
global_step: 23226, epoch: 181, loss: 0.234087
global_step: 23227, epoch: 181, loss: 0.175172
global_step: 23228, epoch: 181, loss: 0.181555
global_step: 23229, epoch: 181, loss: 0.163035
global_step: 23230, epoch: 181, loss: 0.221853
global_step: 23231, epoch: 181, loss: 0.171988
global_step: 23232, epoch: 181, loss: 0.212051
global_step: 23233, epoch: 181, loss: 0.142328
global_step: 23234, epoch: 181, loss: 0.138714
global_step: 23235, epoch: 181, loss: 0.229786
global_step: 23236, epoch: 181, loss: 0.203566
global_step: 23237, epoch: 181, loss: 0.184172
global_step: 23238, epoch: 181, loss: 0.173089
global_step: 23239, epoch: 181, loss: 0.267137
global_step: 23240, epoch: 181, loss: 0.190102
epoch: 181
train	acc: 0.9714	macro: p 0.9753, r 0.9609, f1: 0.9678	micro: p 0.9714, r 0.9714, f1 0.9714	weighted_f1:0.9714
dev	acc: 0.5365	macro: p 0.3662, r 0.3059, f1: 0.3070	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4909
test	acc: 0.5743	macro: p 0.3528, r 0.3081, f1: 0.3150	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5357
global_step: 23241, epoch: 182, loss: 0.187120
global_step: 23242, epoch: 182, loss: 0.235798
global_step: 23243, epoch: 182, loss: 0.174498
global_step: 23244, epoch: 182, loss: 0.112794
global_step: 23245, epoch: 182, loss: 0.127723
global_step: 23246, epoch: 182, loss: 0.174252
global_step: 23247, epoch: 182, loss: 0.223293
global_step: 23248, epoch: 182, loss: 0.155557
global_step: 23249, epoch: 182, loss: 0.161119
global_step: 23250, epoch: 182, loss: 0.170262
global_step: 23251, epoch: 182, loss: 0.156839
global_step: 23252, epoch: 182, loss: 0.189996
global_step: 23253, epoch: 182, loss: 0.245883
global_step: 23254, epoch: 182, loss: 0.151967
global_step: 23255, epoch: 182, loss: 0.199408
global_step: 23256, epoch: 182, loss: 0.202310
global_step: 23257, epoch: 182, loss: 0.210025
global_step: 23258, epoch: 182, loss: 0.139564
global_step: 23259, epoch: 182, loss: 0.183902
global_step: 23260, epoch: 182, loss: 0.206231
global_step: 23261, epoch: 182, loss: 0.187230
global_step: 23262, epoch: 182, loss: 0.205938
global_step: 23263, epoch: 182, loss: 0.164897
global_step: 23264, epoch: 182, loss: 0.170149
global_step: 23265, epoch: 182, loss: 0.200370
global_step: 23266, epoch: 182, loss: 0.213099
global_step: 23267, epoch: 182, loss: 0.151056
global_step: 23268, epoch: 182, loss: 0.158902
global_step: 23269, epoch: 182, loss: 0.166660
global_step: 23270, epoch: 182, loss: 0.173148
global_step: 23271, epoch: 182, loss: 0.232906
global_step: 23272, epoch: 182, loss: 0.122211
global_step: 23273, epoch: 182, loss: 0.173641
global_step: 23274, epoch: 182, loss: 0.154284
global_step: 23275, epoch: 182, loss: 0.249461
global_step: 23276, epoch: 182, loss: 0.122779
global_step: 23277, epoch: 182, loss: 0.191495
global_step: 23278, epoch: 182, loss: 0.234834
global_step: 23279, epoch: 182, loss: 0.283056
global_step: 23280, epoch: 182, loss: 0.080487
epoch: 182
train	acc: 0.9719	macro: p 0.9752, r 0.9621, f1: 0.9684	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5446	macro: p 0.3828, r 0.3164, f1: 0.3233	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4995
test	acc: 0.5743	macro: p 0.3574, r 0.3114, f1: 0.3215	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5379
global_step: 23281, epoch: 183, loss: 0.211282
global_step: 23282, epoch: 183, loss: 0.164682
global_step: 23283, epoch: 183, loss: 0.171823
global_step: 23284, epoch: 183, loss: 0.265402
global_step: 23285, epoch: 183, loss: 0.156935
global_step: 23286, epoch: 183, loss: 0.199452
global_step: 23287, epoch: 183, loss: 0.135364
global_step: 23288, epoch: 183, loss: 0.203464
global_step: 23289, epoch: 183, loss: 0.178807
global_step: 23290, epoch: 183, loss: 0.196860
global_step: 23291, epoch: 183, loss: 0.170410
global_step: 23292, epoch: 183, loss: 0.184652
global_step: 23293, epoch: 183, loss: 0.182025
global_step: 23294, epoch: 183, loss: 0.148593
global_step: 23295, epoch: 183, loss: 0.171916
global_step: 23296, epoch: 183, loss: 0.181147
global_step: 23297, epoch: 183, loss: 0.183038
global_step: 23298, epoch: 183, loss: 0.173232
global_step: 23299, epoch: 183, loss: 0.175214
global_step: 23300, epoch: 183, loss: 0.147971
global_step: 23301, epoch: 183, loss: 0.231193
global_step: 23302, epoch: 183, loss: 0.172021
global_step: 23303, epoch: 183, loss: 0.118864
global_step: 23304, epoch: 183, loss: 0.227098
global_step: 23305, epoch: 183, loss: 0.125376
global_step: 23306, epoch: 183, loss: 0.203342
global_step: 23307, epoch: 183, loss: 0.164885
global_step: 23308, epoch: 183, loss: 0.216413
global_step: 23309, epoch: 183, loss: 0.210688
global_step: 23310, epoch: 183, loss: 0.217803
global_step: 23311, epoch: 183, loss: 0.239603
global_step: 23312, epoch: 183, loss: 0.214931
global_step: 23313, epoch: 183, loss: 0.201753
global_step: 23314, epoch: 183, loss: 0.153545
global_step: 23315, epoch: 183, loss: 0.157161
global_step: 23316, epoch: 183, loss: 0.170290
global_step: 23317, epoch: 183, loss: 0.256103
global_step: 23318, epoch: 183, loss: 0.201280
global_step: 23319, epoch: 183, loss: 0.174190
global_step: 23320, epoch: 183, loss: 0.152697
epoch: 183
train	acc: 0.9708	macro: p 0.9749, r 0.9582, f1: 0.9662	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5419	macro: p 0.4003, r 0.3109, f1: 0.3094	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4932
test	acc: 0.5693	macro: p 0.3414, r 0.2992, f1: 0.3015	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5265
global_step: 23321, epoch: 184, loss: 0.154608
global_step: 23322, epoch: 184, loss: 0.163786
global_step: 23323, epoch: 184, loss: 0.267707
global_step: 23324, epoch: 184, loss: 0.171165
global_step: 23325, epoch: 184, loss: 0.158163
global_step: 23326, epoch: 184, loss: 0.204458
global_step: 23327, epoch: 184, loss: 0.226710
global_step: 23328, epoch: 184, loss: 0.185148
global_step: 23329, epoch: 184, loss: 0.160574
global_step: 23330, epoch: 184, loss: 0.186390
global_step: 23331, epoch: 184, loss: 0.198895
global_step: 23332, epoch: 184, loss: 0.154675
global_step: 23333, epoch: 184, loss: 0.214796
global_step: 23334, epoch: 184, loss: 0.198271
global_step: 23335, epoch: 184, loss: 0.244996
global_step: 23336, epoch: 184, loss: 0.216044
global_step: 23337, epoch: 184, loss: 0.192521
global_step: 23338, epoch: 184, loss: 0.195927
global_step: 23339, epoch: 184, loss: 0.147457
global_step: 23340, epoch: 184, loss: 0.228608
global_step: 23341, epoch: 184, loss: 0.156786
global_step: 23342, epoch: 184, loss: 0.164720
global_step: 23343, epoch: 184, loss: 0.167942
global_step: 23344, epoch: 184, loss: 0.193486
global_step: 23345, epoch: 184, loss: 0.161968
global_step: 23346, epoch: 184, loss: 0.163393
global_step: 23347, epoch: 184, loss: 0.171561
global_step: 23348, epoch: 184, loss: 0.243786
global_step: 23349, epoch: 184, loss: 0.147540
global_step: 23350, epoch: 184, loss: 0.159248
global_step: 23351, epoch: 184, loss: 0.213237
global_step: 23352, epoch: 184, loss: 0.244183
global_step: 23353, epoch: 184, loss: 0.126205
global_step: 23354, epoch: 184, loss: 0.164472
global_step: 23355, epoch: 184, loss: 0.223219
global_step: 23356, epoch: 184, loss: 0.158484
global_step: 23357, epoch: 184, loss: 0.208723
global_step: 23358, epoch: 184, loss: 0.165293
global_step: 23359, epoch: 184, loss: 0.153713
global_step: 23360, epoch: 184, loss: 0.043543
epoch: 184
train	acc: 0.9712	macro: p 0.9747, r 0.9611, f1: 0.9676	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5374	macro: p 0.3882, r 0.3177, f1: 0.3207	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4947
test	acc: 0.5747	macro: p 0.3429, r 0.3100, f1: 0.3143	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5388
global_step: 23361, epoch: 185, loss: 0.234860
global_step: 23362, epoch: 185, loss: 0.164326
global_step: 23363, epoch: 185, loss: 0.193788
global_step: 23364, epoch: 185, loss: 0.163981
global_step: 23365, epoch: 185, loss: 0.170418
global_step: 23366, epoch: 185, loss: 0.204914
global_step: 23367, epoch: 185, loss: 0.213670
global_step: 23368, epoch: 185, loss: 0.175115
global_step: 23369, epoch: 185, loss: 0.177378
global_step: 23370, epoch: 185, loss: 0.203798
global_step: 23371, epoch: 185, loss: 0.187926
global_step: 23372, epoch: 185, loss: 0.143936
global_step: 23373, epoch: 185, loss: 0.165409
global_step: 23374, epoch: 185, loss: 0.181147
global_step: 23375, epoch: 185, loss: 0.245523
global_step: 23376, epoch: 185, loss: 0.167932
global_step: 23377, epoch: 185, loss: 0.253932
global_step: 23378, epoch: 185, loss: 0.153412
global_step: 23379, epoch: 185, loss: 0.218856
global_step: 23380, epoch: 185, loss: 0.128989
global_step: 23381, epoch: 185, loss: 0.160642
global_step: 23382, epoch: 185, loss: 0.266477
global_step: 23383, epoch: 185, loss: 0.141662
global_step: 23384, epoch: 185, loss: 0.192236
global_step: 23385, epoch: 185, loss: 0.152167
global_step: 23386, epoch: 185, loss: 0.245754
global_step: 23387, epoch: 185, loss: 0.168153
global_step: 23388, epoch: 185, loss: 0.162354
global_step: 23389, epoch: 185, loss: 0.284113
global_step: 23390, epoch: 185, loss: 0.270986
global_step: 23391, epoch: 185, loss: 0.171952
global_step: 23392, epoch: 185, loss: 0.189121
global_step: 23393, epoch: 185, loss: 0.203284
global_step: 23394, epoch: 185, loss: 0.163149
global_step: 23395, epoch: 185, loss: 0.136986
global_step: 23396, epoch: 185, loss: 0.177473
global_step: 23397, epoch: 185, loss: 0.148229
global_step: 23398, epoch: 185, loss: 0.199939
global_step: 23399, epoch: 185, loss: 0.241692
global_step: 23400, epoch: 185, loss: 0.026982
epoch: 185
train	acc: 0.9713	macro: p 0.9735, r 0.9620, f1: 0.9676	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5284	macro: p 0.3795, r 0.3145, f1: 0.3180	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4899
test	acc: 0.5728	macro: p 0.3555, r 0.3159, f1: 0.3226	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5403
global_step: 23401, epoch: 186, loss: 0.198382
global_step: 23402, epoch: 186, loss: 0.140906
global_step: 23403, epoch: 186, loss: 0.171253
global_step: 23404, epoch: 186, loss: 0.157724
global_step: 23405, epoch: 186, loss: 0.188984
global_step: 23406, epoch: 186, loss: 0.189952
global_step: 23407, epoch: 186, loss: 0.172119
global_step: 23408, epoch: 186, loss: 0.207715
global_step: 23409, epoch: 186, loss: 0.211201
global_step: 23410, epoch: 186, loss: 0.159346
global_step: 23411, epoch: 186, loss: 0.169803
global_step: 23412, epoch: 186, loss: 0.188980
global_step: 23413, epoch: 186, loss: 0.137985
global_step: 23414, epoch: 186, loss: 0.227491
global_step: 23415, epoch: 186, loss: 0.247396
global_step: 23416, epoch: 186, loss: 0.169374
global_step: 23417, epoch: 186, loss: 0.167588
global_step: 23418, epoch: 186, loss: 0.222665
global_step: 23419, epoch: 186, loss: 0.184672
global_step: 23420, epoch: 186, loss: 0.184636
global_step: 23421, epoch: 186, loss: 0.211086
global_step: 23422, epoch: 186, loss: 0.218847
global_step: 23423, epoch: 186, loss: 0.186303
global_step: 23424, epoch: 186, loss: 0.150354
global_step: 23425, epoch: 186, loss: 0.171760
global_step: 23426, epoch: 186, loss: 0.178599
global_step: 23427, epoch: 186, loss: 0.253234
global_step: 23428, epoch: 186, loss: 0.148542
global_step: 23429, epoch: 186, loss: 0.236455
global_step: 23430, epoch: 186, loss: 0.160937
global_step: 23431, epoch: 186, loss: 0.174320
global_step: 23432, epoch: 186, loss: 0.119013
global_step: 23433, epoch: 186, loss: 0.209059
global_step: 23434, epoch: 186, loss: 0.170052
global_step: 23435, epoch: 186, loss: 0.151606
global_step: 23436, epoch: 186, loss: 0.185616
global_step: 23437, epoch: 186, loss: 0.141700
global_step: 23438, epoch: 186, loss: 0.135682
global_step: 23439, epoch: 186, loss: 0.144607
global_step: 23440, epoch: 186, loss: 0.488961
epoch: 186
train	acc: 0.9720	macro: p 0.9759, r 0.9608, f1: 0.9681	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5311	macro: p 0.3710, r 0.3070, f1: 0.3068	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4883
test	acc: 0.5739	macro: p 0.3550, r 0.3103, f1: 0.3157	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5373
global_step: 23441, epoch: 187, loss: 0.197826
global_step: 23442, epoch: 187, loss: 0.130865
global_step: 23443, epoch: 187, loss: 0.220012
global_step: 23444, epoch: 187, loss: 0.135716
global_step: 23445, epoch: 187, loss: 0.122282
global_step: 23446, epoch: 187, loss: 0.174694
global_step: 23447, epoch: 187, loss: 0.183400
global_step: 23448, epoch: 187, loss: 0.167677
global_step: 23449, epoch: 187, loss: 0.209044
global_step: 23450, epoch: 187, loss: 0.184545
global_step: 23451, epoch: 187, loss: 0.154556
global_step: 23452, epoch: 187, loss: 0.203627
global_step: 23453, epoch: 187, loss: 0.178821
global_step: 23454, epoch: 187, loss: 0.198957
global_step: 23455, epoch: 187, loss: 0.150630
global_step: 23456, epoch: 187, loss: 0.153503
global_step: 23457, epoch: 187, loss: 0.176198
global_step: 23458, epoch: 187, loss: 0.230406
global_step: 23459, epoch: 187, loss: 0.185319
global_step: 23460, epoch: 187, loss: 0.203246
global_step: 23461, epoch: 187, loss: 0.226660
global_step: 23462, epoch: 187, loss: 0.163633
global_step: 23463, epoch: 187, loss: 0.127051
global_step: 23464, epoch: 187, loss: 0.192469
global_step: 23465, epoch: 187, loss: 0.175737
global_step: 23466, epoch: 187, loss: 0.176390
global_step: 23467, epoch: 187, loss: 0.189766
global_step: 23468, epoch: 187, loss: 0.156104
global_step: 23469, epoch: 187, loss: 0.218934
global_step: 23470, epoch: 187, loss: 0.162583
global_step: 23471, epoch: 187, loss: 0.268314
global_step: 23472, epoch: 187, loss: 0.140188
global_step: 23473, epoch: 187, loss: 0.210178
global_step: 23474, epoch: 187, loss: 0.121101
global_step: 23475, epoch: 187, loss: 0.174280
global_step: 23476, epoch: 187, loss: 0.196930
global_step: 23477, epoch: 187, loss: 0.165263
global_step: 23478, epoch: 187, loss: 0.232748
global_step: 23479, epoch: 187, loss: 0.161793
global_step: 23480, epoch: 187, loss: 0.187235
epoch: 187
train	acc: 0.9722	macro: p 0.9742, r 0.9638, f1: 0.9688	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5302	macro: p 0.3734, r 0.3088, f1: 0.3126	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4885
test	acc: 0.5751	macro: p 0.3526, r 0.3146, f1: 0.3208	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5412
global_step: 23481, epoch: 188, loss: 0.095741
global_step: 23482, epoch: 188, loss: 0.191033
global_step: 23483, epoch: 188, loss: 0.220922
global_step: 23484, epoch: 188, loss: 0.191982
global_step: 23485, epoch: 188, loss: 0.173986
global_step: 23486, epoch: 188, loss: 0.198858
global_step: 23487, epoch: 188, loss: 0.188406
global_step: 23488, epoch: 188, loss: 0.215040
global_step: 23489, epoch: 188, loss: 0.169748
global_step: 23490, epoch: 188, loss: 0.170218
global_step: 23491, epoch: 188, loss: 0.146042
global_step: 23492, epoch: 188, loss: 0.110934
global_step: 23493, epoch: 188, loss: 0.153002
global_step: 23494, epoch: 188, loss: 0.167479
global_step: 23495, epoch: 188, loss: 0.188866
global_step: 23496, epoch: 188, loss: 0.178568
global_step: 23497, epoch: 188, loss: 0.241045
global_step: 23498, epoch: 188, loss: 0.176628
global_step: 23499, epoch: 188, loss: 0.183398
global_step: 23500, epoch: 188, loss: 0.185372
global_step: 23501, epoch: 188, loss: 0.205113
global_step: 23502, epoch: 188, loss: 0.157020
global_step: 23503, epoch: 188, loss: 0.224326
global_step: 23504, epoch: 188, loss: 0.195517
global_step: 23505, epoch: 188, loss: 0.223775
global_step: 23506, epoch: 188, loss: 0.185480
global_step: 23507, epoch: 188, loss: 0.120590
global_step: 23508, epoch: 188, loss: 0.145821
global_step: 23509, epoch: 188, loss: 0.223473
global_step: 23510, epoch: 188, loss: 0.199508
global_step: 23511, epoch: 188, loss: 0.190888
global_step: 23512, epoch: 188, loss: 0.184534
global_step: 23513, epoch: 188, loss: 0.220546
global_step: 23514, epoch: 188, loss: 0.207539
global_step: 23515, epoch: 188, loss: 0.172309
global_step: 23516, epoch: 188, loss: 0.252906
global_step: 23517, epoch: 188, loss: 0.117246
global_step: 23518, epoch: 188, loss: 0.140348
global_step: 23519, epoch: 188, loss: 0.223778
global_step: 23520, epoch: 188, loss: 0.247489
epoch: 188
train	acc: 0.9717	macro: p 0.9748, r 0.9615, f1: 0.9679	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5437	macro: p 0.3698, r 0.3122, f1: 0.3125	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4960
test	acc: 0.5747	macro: p 0.3549, r 0.3104, f1: 0.3159	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5343
global_step: 23521, epoch: 189, loss: 0.197228
global_step: 23522, epoch: 189, loss: 0.225532
global_step: 23523, epoch: 189, loss: 0.111693
global_step: 23524, epoch: 189, loss: 0.146067
global_step: 23525, epoch: 189, loss: 0.264902
global_step: 23526, epoch: 189, loss: 0.132794
global_step: 23527, epoch: 189, loss: 0.174565
global_step: 23528, epoch: 189, loss: 0.137027
global_step: 23529, epoch: 189, loss: 0.163790
global_step: 23530, epoch: 189, loss: 0.139318
global_step: 23531, epoch: 189, loss: 0.171980
global_step: 23532, epoch: 189, loss: 0.239776
global_step: 23533, epoch: 189, loss: 0.201516
global_step: 23534, epoch: 189, loss: 0.200592
global_step: 23535, epoch: 189, loss: 0.198539
global_step: 23536, epoch: 189, loss: 0.186039
global_step: 23537, epoch: 189, loss: 0.214759
global_step: 23538, epoch: 189, loss: 0.177924
global_step: 23539, epoch: 189, loss: 0.277293
global_step: 23540, epoch: 189, loss: 0.210494
global_step: 23541, epoch: 189, loss: 0.185376
global_step: 23542, epoch: 189, loss: 0.215269
global_step: 23543, epoch: 189, loss: 0.234605
global_step: 23544, epoch: 189, loss: 0.217686
global_step: 23545, epoch: 189, loss: 0.257657
global_step: 23546, epoch: 189, loss: 0.164953
global_step: 23547, epoch: 189, loss: 0.227796
global_step: 23548, epoch: 189, loss: 0.205289
global_step: 23549, epoch: 189, loss: 0.138942
global_step: 23550, epoch: 189, loss: 0.209060
global_step: 23551, epoch: 189, loss: 0.174598
global_step: 23552, epoch: 189, loss: 0.156033
global_step: 23553, epoch: 189, loss: 0.174340
global_step: 23554, epoch: 189, loss: 0.160591
global_step: 23555, epoch: 189, loss: 0.134801
global_step: 23556, epoch: 189, loss: 0.271658
global_step: 23557, epoch: 189, loss: 0.201201
global_step: 23558, epoch: 189, loss: 0.240179
global_step: 23559, epoch: 189, loss: 0.197060
global_step: 23560, epoch: 189, loss: 0.022976
epoch: 189
train	acc: 0.9714	macro: p 0.9749, r 0.9592, f1: 0.9668	micro: p 0.9714, r 0.9714, f1 0.9714	weighted_f1:0.9714
dev	acc: 0.5284	macro: p 0.3528, r 0.3005, f1: 0.3006	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4838
test	acc: 0.5801	macro: p 0.3626, r 0.3114, f1: 0.3171	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5416
global_step: 23561, epoch: 190, loss: 0.176100
global_step: 23562, epoch: 190, loss: 0.155038
global_step: 23563, epoch: 190, loss: 0.173188
global_step: 23564, epoch: 190, loss: 0.172770
global_step: 23565, epoch: 190, loss: 0.198940
global_step: 23566, epoch: 190, loss: 0.190205
global_step: 23567, epoch: 190, loss: 0.174327
global_step: 23568, epoch: 190, loss: 0.156804
global_step: 23569, epoch: 190, loss: 0.161201
global_step: 23570, epoch: 190, loss: 0.120894
global_step: 23571, epoch: 190, loss: 0.279210
global_step: 23572, epoch: 190, loss: 0.126902
global_step: 23573, epoch: 190, loss: 0.188427
global_step: 23574, epoch: 190, loss: 0.192477
global_step: 23575, epoch: 190, loss: 0.166426
global_step: 23576, epoch: 190, loss: 0.151878
global_step: 23577, epoch: 190, loss: 0.142646
global_step: 23578, epoch: 190, loss: 0.237779
global_step: 23579, epoch: 190, loss: 0.208080
global_step: 23580, epoch: 190, loss: 0.162957
global_step: 23581, epoch: 190, loss: 0.199874
global_step: 23582, epoch: 190, loss: 0.217411
global_step: 23583, epoch: 190, loss: 0.210008
global_step: 23584, epoch: 190, loss: 0.155657
global_step: 23585, epoch: 190, loss: 0.184245
global_step: 23586, epoch: 190, loss: 0.225194
global_step: 23587, epoch: 190, loss: 0.162935
global_step: 23588, epoch: 190, loss: 0.193300
global_step: 23589, epoch: 190, loss: 0.155697
global_step: 23590, epoch: 190, loss: 0.236406
global_step: 23591, epoch: 190, loss: 0.183792
global_step: 23592, epoch: 190, loss: 0.192891
global_step: 23593, epoch: 190, loss: 0.215470
global_step: 23594, epoch: 190, loss: 0.153847
global_step: 23595, epoch: 190, loss: 0.222266
global_step: 23596, epoch: 190, loss: 0.187323
global_step: 23597, epoch: 190, loss: 0.195611
global_step: 23598, epoch: 190, loss: 0.173904
global_step: 23599, epoch: 190, loss: 0.179664
global_step: 23600, epoch: 190, loss: 0.800727
epoch: 190
train	acc: 0.9720	macro: p 0.9755, r 0.9614, f1: 0.9682	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5383	macro: p 0.3791, r 0.3032, f1: 0.3019	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4861
test	acc: 0.5743	macro: p 0.3469, r 0.2963, f1: 0.2981	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5271
global_step: 23601, epoch: 191, loss: 0.199146
global_step: 23602, epoch: 191, loss: 0.162519
global_step: 23603, epoch: 191, loss: 0.201797
global_step: 23604, epoch: 191, loss: 0.211977
global_step: 23605, epoch: 191, loss: 0.138834
global_step: 23606, epoch: 191, loss: 0.266524
global_step: 23607, epoch: 191, loss: 0.172082
global_step: 23608, epoch: 191, loss: 0.167491
global_step: 23609, epoch: 191, loss: 0.222466
global_step: 23610, epoch: 191, loss: 0.160637
global_step: 23611, epoch: 191, loss: 0.155481
global_step: 23612, epoch: 191, loss: 0.252677
global_step: 23613, epoch: 191, loss: 0.225269
global_step: 23614, epoch: 191, loss: 0.165809
global_step: 23615, epoch: 191, loss: 0.165337
global_step: 23616, epoch: 191, loss: 0.209168
global_step: 23617, epoch: 191, loss: 0.131540
global_step: 23618, epoch: 191, loss: 0.156938
global_step: 23619, epoch: 191, loss: 0.231094
global_step: 23620, epoch: 191, loss: 0.154693
global_step: 23621, epoch: 191, loss: 0.142419
global_step: 23622, epoch: 191, loss: 0.220887
global_step: 23623, epoch: 191, loss: 0.148110
global_step: 23624, epoch: 191, loss: 0.133787
global_step: 23625, epoch: 191, loss: 0.209522
global_step: 23626, epoch: 191, loss: 0.170074
global_step: 23627, epoch: 191, loss: 0.264535
global_step: 23628, epoch: 191, loss: 0.195306
global_step: 23629, epoch: 191, loss: 0.146761
global_step: 23630, epoch: 191, loss: 0.232122
global_step: 23631, epoch: 191, loss: 0.124475
global_step: 23632, epoch: 191, loss: 0.131925
global_step: 23633, epoch: 191, loss: 0.148871
global_step: 23634, epoch: 191, loss: 0.185560
global_step: 23635, epoch: 191, loss: 0.257513
global_step: 23636, epoch: 191, loss: 0.142346
global_step: 23637, epoch: 191, loss: 0.157596
global_step: 23638, epoch: 191, loss: 0.154937
global_step: 23639, epoch: 191, loss: 0.207840
global_step: 23640, epoch: 191, loss: 0.103643
epoch: 191
train	acc: 0.9715	macro: p 0.9747, r 0.9610, f1: 0.9676	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5356	macro: p 0.3633, r 0.3081, f1: 0.3091	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4912
test	acc: 0.5762	macro: p 0.3463, r 0.3072, f1: 0.3119	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5375
global_step: 23641, epoch: 192, loss: 0.237853
global_step: 23642, epoch: 192, loss: 0.188748
global_step: 23643, epoch: 192, loss: 0.197863
global_step: 23644, epoch: 192, loss: 0.177856
global_step: 23645, epoch: 192, loss: 0.143287
global_step: 23646, epoch: 192, loss: 0.168503
global_step: 23647, epoch: 192, loss: 0.212022
global_step: 23648, epoch: 192, loss: 0.192785
global_step: 23649, epoch: 192, loss: 0.223022
global_step: 23650, epoch: 192, loss: 0.206165
global_step: 23651, epoch: 192, loss: 0.173607
global_step: 23652, epoch: 192, loss: 0.237263
global_step: 23653, epoch: 192, loss: 0.221345
global_step: 23654, epoch: 192, loss: 0.130747
global_step: 23655, epoch: 192, loss: 0.138943
global_step: 23656, epoch: 192, loss: 0.177686
global_step: 23657, epoch: 192, loss: 0.234967
global_step: 23658, epoch: 192, loss: 0.215243
global_step: 23659, epoch: 192, loss: 0.189800
global_step: 23660, epoch: 192, loss: 0.182544
global_step: 23661, epoch: 192, loss: 0.108730
global_step: 23662, epoch: 192, loss: 0.175227
global_step: 23663, epoch: 192, loss: 0.206210
global_step: 23664, epoch: 192, loss: 0.144329
global_step: 23665, epoch: 192, loss: 0.177679
global_step: 23666, epoch: 192, loss: 0.185318
global_step: 23667, epoch: 192, loss: 0.150648
global_step: 23668, epoch: 192, loss: 0.159674
global_step: 23669, epoch: 192, loss: 0.148387
global_step: 23670, epoch: 192, loss: 0.157356
global_step: 23671, epoch: 192, loss: 0.205286
global_step: 23672, epoch: 192, loss: 0.217392
global_step: 23673, epoch: 192, loss: 0.149556
global_step: 23674, epoch: 192, loss: 0.152896
global_step: 23675, epoch: 192, loss: 0.198595
global_step: 23676, epoch: 192, loss: 0.151129
global_step: 23677, epoch: 192, loss: 0.130074
global_step: 23678, epoch: 192, loss: 0.174862
global_step: 23679, epoch: 192, loss: 0.155853
global_step: 23680, epoch: 192, loss: 0.047538
epoch: 192
train	acc: 0.9715	macro: p 0.9741, r 0.9612, f1: 0.9674	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5320	macro: p 0.3850, r 0.3163, f1: 0.3216	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4927
test	acc: 0.5785	macro: p 0.3632, r 0.3196, f1: 0.3255	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5442
global_step: 23681, epoch: 193, loss: 0.172277
global_step: 23682, epoch: 193, loss: 0.130008
global_step: 23683, epoch: 193, loss: 0.134086
global_step: 23684, epoch: 193, loss: 0.164467
global_step: 23685, epoch: 193, loss: 0.160902
global_step: 23686, epoch: 193, loss: 0.122372
global_step: 23687, epoch: 193, loss: 0.185182
global_step: 23688, epoch: 193, loss: 0.131068
global_step: 23689, epoch: 193, loss: 0.188750
global_step: 23690, epoch: 193, loss: 0.132382
global_step: 23691, epoch: 193, loss: 0.159985
global_step: 23692, epoch: 193, loss: 0.215730
global_step: 23693, epoch: 193, loss: 0.192814
global_step: 23694, epoch: 193, loss: 0.195918
global_step: 23695, epoch: 193, loss: 0.169113
global_step: 23696, epoch: 193, loss: 0.148672
global_step: 23697, epoch: 193, loss: 0.200875
global_step: 23698, epoch: 193, loss: 0.215548
global_step: 23699, epoch: 193, loss: 0.259155
global_step: 23700, epoch: 193, loss: 0.147993
global_step: 23701, epoch: 193, loss: 0.156085
global_step: 23702, epoch: 193, loss: 0.116479
global_step: 23703, epoch: 193, loss: 0.211520
global_step: 23704, epoch: 193, loss: 0.163987
global_step: 23705, epoch: 193, loss: 0.146769
global_step: 23706, epoch: 193, loss: 0.238782
global_step: 23707, epoch: 193, loss: 0.156258
global_step: 23708, epoch: 193, loss: 0.151604
global_step: 23709, epoch: 193, loss: 0.102017
global_step: 23710, epoch: 193, loss: 0.163579
global_step: 23711, epoch: 193, loss: 0.159240
global_step: 23712, epoch: 193, loss: 0.189074
global_step: 23713, epoch: 193, loss: 0.138337
global_step: 23714, epoch: 193, loss: 0.235606
global_step: 23715, epoch: 193, loss: 0.147835
global_step: 23716, epoch: 193, loss: 0.253671
global_step: 23717, epoch: 193, loss: 0.197971
global_step: 23718, epoch: 193, loss: 0.149799
global_step: 23719, epoch: 193, loss: 0.249885
global_step: 23720, epoch: 193, loss: 0.000225
epoch: 193
train	acc: 0.9721	macro: p 0.9747, r 0.9626, f1: 0.9684	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5428	macro: p 0.4019, r 0.3204, f1: 0.3256	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4981
test	acc: 0.5751	macro: p 0.3452, r 0.3041, f1: 0.3083	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5334
global_step: 23721, epoch: 194, loss: 0.140573
global_step: 23722, epoch: 194, loss: 0.134358
global_step: 23723, epoch: 194, loss: 0.145457
global_step: 23724, epoch: 194, loss: 0.197969
global_step: 23725, epoch: 194, loss: 0.226661
global_step: 23726, epoch: 194, loss: 0.167710
global_step: 23727, epoch: 194, loss: 0.142738
global_step: 23728, epoch: 194, loss: 0.138532
global_step: 23729, epoch: 194, loss: 0.190787
global_step: 23730, epoch: 194, loss: 0.119405
global_step: 23731, epoch: 194, loss: 0.169555
global_step: 23732, epoch: 194, loss: 0.142689
global_step: 23733, epoch: 194, loss: 0.191554
global_step: 23734, epoch: 194, loss: 0.119190
global_step: 23735, epoch: 194, loss: 0.235996
global_step: 23736, epoch: 194, loss: 0.108515
global_step: 23737, epoch: 194, loss: 0.196964
global_step: 23738, epoch: 194, loss: 0.181457
global_step: 23739, epoch: 194, loss: 0.196345
global_step: 23740, epoch: 194, loss: 0.167548
global_step: 23741, epoch: 194, loss: 0.113859
global_step: 23742, epoch: 194, loss: 0.137177
global_step: 23743, epoch: 194, loss: 0.221141
global_step: 23744, epoch: 194, loss: 0.242106
global_step: 23745, epoch: 194, loss: 0.172152
global_step: 23746, epoch: 194, loss: 0.185518
global_step: 23747, epoch: 194, loss: 0.148910
global_step: 23748, epoch: 194, loss: 0.146824
global_step: 23749, epoch: 194, loss: 0.195392
global_step: 23750, epoch: 194, loss: 0.147292
global_step: 23751, epoch: 194, loss: 0.168098
global_step: 23752, epoch: 194, loss: 0.205712
global_step: 23753, epoch: 194, loss: 0.155586
global_step: 23754, epoch: 194, loss: 0.204449
global_step: 23755, epoch: 194, loss: 0.175920
global_step: 23756, epoch: 194, loss: 0.184407
global_step: 23757, epoch: 194, loss: 0.106593
global_step: 23758, epoch: 194, loss: 0.154444
global_step: 23759, epoch: 194, loss: 0.186192
global_step: 23760, epoch: 194, loss: 0.027021
epoch: 194
train	acc: 0.9718	macro: p 0.9737, r 0.9638, f1: 0.9685	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5275	macro: p 0.4102, r 0.3215, f1: 0.3265	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4870
test	acc: 0.5701	macro: p 0.3413, r 0.3097, f1: 0.3128	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5359
global_step: 23761, epoch: 195, loss: 0.153041
global_step: 23762, epoch: 195, loss: 0.162616
global_step: 23763, epoch: 195, loss: 0.175793
global_step: 23764, epoch: 195, loss: 0.167625
global_step: 23765, epoch: 195, loss: 0.221848
global_step: 23766, epoch: 195, loss: 0.167867
global_step: 23767, epoch: 195, loss: 0.157548
global_step: 23768, epoch: 195, loss: 0.218198
global_step: 23769, epoch: 195, loss: 0.235982
global_step: 23770, epoch: 195, loss: 0.171013
global_step: 23771, epoch: 195, loss: 0.174534
global_step: 23772, epoch: 195, loss: 0.144525
global_step: 23773, epoch: 195, loss: 0.139495
global_step: 23774, epoch: 195, loss: 0.140315
global_step: 23775, epoch: 195, loss: 0.216425
global_step: 23776, epoch: 195, loss: 0.217772
global_step: 23777, epoch: 195, loss: 0.242948
global_step: 23778, epoch: 195, loss: 0.165913
global_step: 23779, epoch: 195, loss: 0.131685
global_step: 23780, epoch: 195, loss: 0.193036
global_step: 23781, epoch: 195, loss: 0.156608
global_step: 23782, epoch: 195, loss: 0.187062
global_step: 23783, epoch: 195, loss: 0.137407
global_step: 23784, epoch: 195, loss: 0.176705
global_step: 23785, epoch: 195, loss: 0.159944
global_step: 23786, epoch: 195, loss: 0.184440
global_step: 23787, epoch: 195, loss: 0.202800
global_step: 23788, epoch: 195, loss: 0.229288
global_step: 23789, epoch: 195, loss: 0.255095
global_step: 23790, epoch: 195, loss: 0.173666
global_step: 23791, epoch: 195, loss: 0.132891
global_step: 23792, epoch: 195, loss: 0.208111
global_step: 23793, epoch: 195, loss: 0.120908
global_step: 23794, epoch: 195, loss: 0.198909
global_step: 23795, epoch: 195, loss: 0.150652
global_step: 23796, epoch: 195, loss: 0.201673
global_step: 23797, epoch: 195, loss: 0.184541
global_step: 23798, epoch: 195, loss: 0.155939
global_step: 23799, epoch: 195, loss: 0.103427
global_step: 23800, epoch: 195, loss: 0.200713
epoch: 195
train	acc: 0.9718	macro: p 0.9741, r 0.9618, f1: 0.9677	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5329	macro: p 0.4151, r 0.3174, f1: 0.3224	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4925
test	acc: 0.5785	macro: p 0.3620, r 0.3152, f1: 0.3198	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5424
global_step: 23801, epoch: 196, loss: 0.165216
global_step: 23802, epoch: 196, loss: 0.206352
global_step: 23803, epoch: 196, loss: 0.142622
global_step: 23804, epoch: 196, loss: 0.156791
global_step: 23805, epoch: 196, loss: 0.182620
global_step: 23806, epoch: 196, loss: 0.181051
global_step: 23807, epoch: 196, loss: 0.199498
global_step: 23808, epoch: 196, loss: 0.132471
global_step: 23809, epoch: 196, loss: 0.163370
global_step: 23810, epoch: 196, loss: 0.204914
global_step: 23811, epoch: 196, loss: 0.203383
global_step: 23812, epoch: 196, loss: 0.156309
global_step: 23813, epoch: 196, loss: 0.159665
global_step: 23814, epoch: 196, loss: 0.178290
global_step: 23815, epoch: 196, loss: 0.175494
global_step: 23816, epoch: 196, loss: 0.158056
global_step: 23817, epoch: 196, loss: 0.187108
global_step: 23818, epoch: 196, loss: 0.177893
global_step: 23819, epoch: 196, loss: 0.204502
global_step: 23820, epoch: 196, loss: 0.148659
global_step: 23821, epoch: 196, loss: 0.233488
global_step: 23822, epoch: 196, loss: 0.282078
global_step: 23823, epoch: 196, loss: 0.176422
global_step: 23824, epoch: 196, loss: 0.153019
global_step: 23825, epoch: 196, loss: 0.180979
global_step: 23826, epoch: 196, loss: 0.225272
global_step: 23827, epoch: 196, loss: 0.208528
global_step: 23828, epoch: 196, loss: 0.192422
global_step: 23829, epoch: 196, loss: 0.122190
global_step: 23830, epoch: 196, loss: 0.125832
global_step: 23831, epoch: 196, loss: 0.192323
global_step: 23832, epoch: 196, loss: 0.177765
global_step: 23833, epoch: 196, loss: 0.180421
global_step: 23834, epoch: 196, loss: 0.182829
global_step: 23835, epoch: 196, loss: 0.169130
global_step: 23836, epoch: 196, loss: 0.192920
global_step: 23837, epoch: 196, loss: 0.154272
global_step: 23838, epoch: 196, loss: 0.186030
global_step: 23839, epoch: 196, loss: 0.193237
global_step: 23840, epoch: 196, loss: 0.101246
epoch: 196
train	acc: 0.9716	macro: p 0.9749, r 0.9615, f1: 0.9679	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5266	macro: p 0.3896, r 0.3126, f1: 0.3153	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4858
test	acc: 0.5674	macro: p 0.3390, r 0.3089, f1: 0.3110	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5322
global_step: 23841, epoch: 197, loss: 0.275036
global_step: 23842, epoch: 197, loss: 0.218350
global_step: 23843, epoch: 197, loss: 0.127817
global_step: 23844, epoch: 197, loss: 0.234341
global_step: 23845, epoch: 197, loss: 0.240702
global_step: 23846, epoch: 197, loss: 0.194956
global_step: 23847, epoch: 197, loss: 0.200270
global_step: 23848, epoch: 197, loss: 0.161067
global_step: 23849, epoch: 197, loss: 0.159260
global_step: 23850, epoch: 197, loss: 0.156332
global_step: 23851, epoch: 197, loss: 0.203314
global_step: 23852, epoch: 197, loss: 0.129917
global_step: 23853, epoch: 197, loss: 0.165460
global_step: 23854, epoch: 197, loss: 0.183097
global_step: 23855, epoch: 197, loss: 0.181773
global_step: 23856, epoch: 197, loss: 0.198956
global_step: 23857, epoch: 197, loss: 0.171223
global_step: 23858, epoch: 197, loss: 0.189218
global_step: 23859, epoch: 197, loss: 0.153719
global_step: 23860, epoch: 197, loss: 0.185473
global_step: 23861, epoch: 197, loss: 0.187389
global_step: 23862, epoch: 197, loss: 0.156755
global_step: 23863, epoch: 197, loss: 0.192270
global_step: 23864, epoch: 197, loss: 0.120806
global_step: 23865, epoch: 197, loss: 0.207020
global_step: 23866, epoch: 197, loss: 0.099553
global_step: 23867, epoch: 197, loss: 0.246993
global_step: 23868, epoch: 197, loss: 0.194815
global_step: 23869, epoch: 197, loss: 0.150462
global_step: 23870, epoch: 197, loss: 0.120361
global_step: 23871, epoch: 197, loss: 0.236548
global_step: 23872, epoch: 197, loss: 0.109077
global_step: 23873, epoch: 197, loss: 0.147468
global_step: 23874, epoch: 197, loss: 0.158673
global_step: 23875, epoch: 197, loss: 0.220626
global_step: 23876, epoch: 197, loss: 0.178559
global_step: 23877, epoch: 197, loss: 0.148151
global_step: 23878, epoch: 197, loss: 0.181582
global_step: 23879, epoch: 197, loss: 0.149720
global_step: 23880, epoch: 197, loss: 0.009181
epoch: 197
train	acc: 0.9724	macro: p 0.9755, r 0.9631, f1: 0.9691	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5311	macro: p 0.4087, r 0.3184, f1: 0.3286	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4889
test	acc: 0.5785	macro: p 0.3444, r 0.3101, f1: 0.3151	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5402
global_step: 23881, epoch: 198, loss: 0.129690
global_step: 23882, epoch: 198, loss: 0.109877
global_step: 23883, epoch: 198, loss: 0.206735
global_step: 23884, epoch: 198, loss: 0.180657
global_step: 23885, epoch: 198, loss: 0.141871
global_step: 23886, epoch: 198, loss: 0.242112
global_step: 23887, epoch: 198, loss: 0.194157
global_step: 23888, epoch: 198, loss: 0.228572
global_step: 23889, epoch: 198, loss: 0.157964
global_step: 23890, epoch: 198, loss: 0.223200
global_step: 23891, epoch: 198, loss: 0.123796
global_step: 23892, epoch: 198, loss: 0.116119
global_step: 23893, epoch: 198, loss: 0.132018
global_step: 23894, epoch: 198, loss: 0.127691
global_step: 23895, epoch: 198, loss: 0.145915
global_step: 23896, epoch: 198, loss: 0.129752
global_step: 23897, epoch: 198, loss: 0.164100
global_step: 23898, epoch: 198, loss: 0.141087
global_step: 23899, epoch: 198, loss: 0.147940
global_step: 23900, epoch: 198, loss: 0.197794
global_step: 23901, epoch: 198, loss: 0.175091
global_step: 23902, epoch: 198, loss: 0.196677
global_step: 23903, epoch: 198, loss: 0.113703
global_step: 23904, epoch: 198, loss: 0.188213
global_step: 23905, epoch: 198, loss: 0.187810
global_step: 23906, epoch: 198, loss: 0.157999
global_step: 23907, epoch: 198, loss: 0.233477
global_step: 23908, epoch: 198, loss: 0.186512
global_step: 23909, epoch: 198, loss: 0.201395
global_step: 23910, epoch: 198, loss: 0.254606
global_step: 23911, epoch: 198, loss: 0.181255
global_step: 23912, epoch: 198, loss: 0.148212
global_step: 23913, epoch: 198, loss: 0.165640
global_step: 23914, epoch: 198, loss: 0.178738
global_step: 23915, epoch: 198, loss: 0.170627
global_step: 23916, epoch: 198, loss: 0.146284
global_step: 23917, epoch: 198, loss: 0.161161
global_step: 23918, epoch: 198, loss: 0.162116
global_step: 23919, epoch: 198, loss: 0.199783
global_step: 23920, epoch: 198, loss: 0.171805
epoch: 198
train	acc: 0.9721	macro: p 0.9754, r 0.9627, f1: 0.9688	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5320	macro: p 0.4032, r 0.3157, f1: 0.3230	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4874
test	acc: 0.5812	macro: p 0.3592, r 0.3152, f1: 0.3228	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5430
global_step: 23921, epoch: 199, loss: 0.177326
global_step: 23922, epoch: 199, loss: 0.226222
global_step: 23923, epoch: 199, loss: 0.165500
global_step: 23924, epoch: 199, loss: 0.163112
global_step: 23925, epoch: 199, loss: 0.107524
global_step: 23926, epoch: 199, loss: 0.130689
global_step: 23927, epoch: 199, loss: 0.171360
global_step: 23928, epoch: 199, loss: 0.202948
global_step: 23929, epoch: 199, loss: 0.227646
global_step: 23930, epoch: 199, loss: 0.112273
global_step: 23931, epoch: 199, loss: 0.169030
global_step: 23932, epoch: 199, loss: 0.257444
global_step: 23933, epoch: 199, loss: 0.133290
global_step: 23934, epoch: 199, loss: 0.182958
global_step: 23935, epoch: 199, loss: 0.157413
global_step: 23936, epoch: 199, loss: 0.169294
global_step: 23937, epoch: 199, loss: 0.190122
global_step: 23938, epoch: 199, loss: 0.150659
global_step: 23939, epoch: 199, loss: 0.173511
global_step: 23940, epoch: 199, loss: 0.157226
global_step: 23941, epoch: 199, loss: 0.184392
global_step: 23942, epoch: 199, loss: 0.238246
global_step: 23943, epoch: 199, loss: 0.182173
global_step: 23944, epoch: 199, loss: 0.191120
global_step: 23945, epoch: 199, loss: 0.184160
global_step: 23946, epoch: 199, loss: 0.172199
global_step: 23947, epoch: 199, loss: 0.141053
global_step: 23948, epoch: 199, loss: 0.239290
global_step: 23949, epoch: 199, loss: 0.121981
global_step: 23950, epoch: 199, loss: 0.139065
global_step: 23951, epoch: 199, loss: 0.168277
global_step: 23952, epoch: 199, loss: 0.199023
global_step: 23953, epoch: 199, loss: 0.262163
global_step: 23954, epoch: 199, loss: 0.118527
global_step: 23955, epoch: 199, loss: 0.159889
global_step: 23956, epoch: 199, loss: 0.144926
global_step: 23957, epoch: 199, loss: 0.177001
global_step: 23958, epoch: 199, loss: 0.202822
global_step: 23959, epoch: 199, loss: 0.185953
global_step: 23960, epoch: 199, loss: 0.004215
epoch: 199
train	acc: 0.9726	macro: p 0.9755, r 0.9636, f1: 0.9694	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5302	macro: p 0.3600, r 0.3003, f1: 0.3005	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4835
test	acc: 0.5770	macro: p 0.3538, r 0.3080, f1: 0.3142	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5368
global_step: 23961, epoch: 200, loss: 0.260339
global_step: 23962, epoch: 200, loss: 0.174943
global_step: 23963, epoch: 200, loss: 0.185577
global_step: 23964, epoch: 200, loss: 0.138346
global_step: 23965, epoch: 200, loss: 0.125755
global_step: 23966, epoch: 200, loss: 0.165656
global_step: 23967, epoch: 200, loss: 0.219109
global_step: 23968, epoch: 200, loss: 0.189656
global_step: 23969, epoch: 200, loss: 0.224358
global_step: 23970, epoch: 200, loss: 0.160669
global_step: 23971, epoch: 200, loss: 0.147957
global_step: 23972, epoch: 200, loss: 0.192263
global_step: 23973, epoch: 200, loss: 0.161969
global_step: 23974, epoch: 200, loss: 0.210544
global_step: 23975, epoch: 200, loss: 0.231387
global_step: 23976, epoch: 200, loss: 0.125833
global_step: 23977, epoch: 200, loss: 0.144451
global_step: 23978, epoch: 200, loss: 0.207532
global_step: 23979, epoch: 200, loss: 0.171874
global_step: 23980, epoch: 200, loss: 0.195272
global_step: 23981, epoch: 200, loss: 0.122405
global_step: 23982, epoch: 200, loss: 0.190023
global_step: 23983, epoch: 200, loss: 0.138186
global_step: 23984, epoch: 200, loss: 0.167719
global_step: 23985, epoch: 200, loss: 0.184065
global_step: 23986, epoch: 200, loss: 0.186036
global_step: 23987, epoch: 200, loss: 0.139733
global_step: 23988, epoch: 200, loss: 0.224644
global_step: 23989, epoch: 200, loss: 0.216597
global_step: 23990, epoch: 200, loss: 0.184553
global_step: 23991, epoch: 200, loss: 0.150417
global_step: 23992, epoch: 200, loss: 0.132684
global_step: 23993, epoch: 200, loss: 0.197331
global_step: 23994, epoch: 200, loss: 0.201424
global_step: 23995, epoch: 200, loss: 0.212223
global_step: 23996, epoch: 200, loss: 0.133274
global_step: 23997, epoch: 200, loss: 0.236614
global_step: 23998, epoch: 200, loss: 0.103880
global_step: 23999, epoch: 200, loss: 0.125400
global_step: 24000, epoch: 200, loss: 0.034736
epoch: 200
train	acc: 0.9725	macro: p 0.9760, r 0.9633, f1: 0.9694	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5347	macro: p 0.4100, r 0.3186, f1: 0.3277	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4915
test	acc: 0.5770	macro: p 0.3746, r 0.3159, f1: 0.3258	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5385
BEST MODEL epoch: 32
train	acc: 0.7737 macro_p: 0.6761 macro_r: 0.5093 macro_f1: 0.5126 micro_p: 0.7737 micro_r: 0.7737 micro_f1: 0.7737 weighted_f1: 0.7470
dev	acc: 0.5708 macro_p: 0.3716 macro_r: 0.3277 macro_f1: 0.3215 micro_p: 0.5708 micro_r: 0.5708 micro_f1: 0.5708 weighted_f1: 0.5202
test	acc: 0.6084 macro_p: 0.3760 macro_r: 0.3275 macro_f1: 0.3312 micro_p: 0.6084 micro_r: 0.6084 micro_f1: 0.6084 weighted_f1: 0.5665
==========ROUND 4==========
global_step: 24001, epoch: 1, loss: 1.998615
global_step: 24002, epoch: 1, loss: 1.922987
global_step: 24003, epoch: 1, loss: 1.886966
global_step: 24004, epoch: 1, loss: 1.821052
global_step: 24005, epoch: 1, loss: 1.761033
global_step: 24006, epoch: 1, loss: 1.753781
global_step: 24007, epoch: 1, loss: 1.751583
global_step: 24008, epoch: 1, loss: 1.750434
global_step: 24009, epoch: 1, loss: 1.684319
global_step: 24010, epoch: 1, loss: 1.649586
global_step: 24011, epoch: 1, loss: 1.614181
global_step: 24012, epoch: 1, loss: 1.608042
global_step: 24013, epoch: 1, loss: 1.565477
global_step: 24014, epoch: 1, loss: 1.559069
global_step: 24015, epoch: 1, loss: 1.611970
global_step: 24016, epoch: 1, loss: 1.587260
global_step: 24017, epoch: 1, loss: 1.569537
global_step: 24018, epoch: 1, loss: 1.566830
global_step: 24019, epoch: 1, loss: 1.608207
global_step: 24020, epoch: 1, loss: 1.552069
global_step: 24021, epoch: 1, loss: 1.580122
global_step: 24022, epoch: 1, loss: 1.559856
global_step: 24023, epoch: 1, loss: 1.429950
global_step: 24024, epoch: 1, loss: 1.436363
global_step: 24025, epoch: 1, loss: 1.455542
global_step: 24026, epoch: 1, loss: 1.610669
global_step: 24027, epoch: 1, loss: 1.499842
global_step: 24028, epoch: 1, loss: 1.530964
global_step: 24029, epoch: 1, loss: 1.541406
global_step: 24030, epoch: 1, loss: 1.552685
global_step: 24031, epoch: 1, loss: 1.529693
global_step: 24032, epoch: 1, loss: 1.536622
global_step: 24033, epoch: 1, loss: 1.505041
global_step: 24034, epoch: 1, loss: 1.572502
global_step: 24035, epoch: 1, loss: 1.544590
global_step: 24036, epoch: 1, loss: 1.420215
global_step: 24037, epoch: 1, loss: 1.474544
global_step: 24038, epoch: 1, loss: 1.560626
global_step: 24039, epoch: 1, loss: 1.550436
global_step: 24040, epoch: 1, loss: 1.159136
epoch: 1
train	acc: 0.5277	macro: p 0.2075, r 0.2019, f1: 0.1822	micro: p 0.5277, r 0.5277, f1 0.5277	weighted_f1:0.4168
dev	acc: 0.4725	macro: p 0.1923, r 0.1998, f1: 0.1718	micro: p 0.4725, r 0.4725, f1 0.4725	weighted_f1:0.3532
test	acc: 0.5272	macro: p 0.1969, r 0.2004, f1: 0.1791	micro: p 0.5272, r 0.5272, f1 0.5272	weighted_f1:0.4124
New best model!
global_step: 24041, epoch: 2, loss: 1.441102
global_step: 24042, epoch: 2, loss: 1.512567
global_step: 24043, epoch: 2, loss: 1.483478
global_step: 24044, epoch: 2, loss: 1.369701
global_step: 24045, epoch: 2, loss: 1.501223
global_step: 24046, epoch: 2, loss: 1.473862
global_step: 24047, epoch: 2, loss: 1.493629
global_step: 24048, epoch: 2, loss: 1.462049
global_step: 24049, epoch: 2, loss: 1.412634
global_step: 24050, epoch: 2, loss: 1.460056
global_step: 24051, epoch: 2, loss: 1.450010
global_step: 24052, epoch: 2, loss: 1.383883
global_step: 24053, epoch: 2, loss: 1.411971
global_step: 24054, epoch: 2, loss: 1.372751
global_step: 24055, epoch: 2, loss: 1.495043
global_step: 24056, epoch: 2, loss: 1.343665
global_step: 24057, epoch: 2, loss: 1.430959
global_step: 24058, epoch: 2, loss: 1.402206
global_step: 24059, epoch: 2, loss: 1.489237
global_step: 24060, epoch: 2, loss: 1.518890
global_step: 24061, epoch: 2, loss: 1.395106
global_step: 24062, epoch: 2, loss: 1.425686
global_step: 24063, epoch: 2, loss: 1.361739
global_step: 24064, epoch: 2, loss: 1.412879
global_step: 24065, epoch: 2, loss: 1.443514
global_step: 24066, epoch: 2, loss: 1.480217
global_step: 24067, epoch: 2, loss: 1.462321
global_step: 24068, epoch: 2, loss: 1.529243
global_step: 24069, epoch: 2, loss: 1.373023
global_step: 24070, epoch: 2, loss: 1.408418
global_step: 24071, epoch: 2, loss: 1.451066
global_step: 24072, epoch: 2, loss: 1.535810
global_step: 24073, epoch: 2, loss: 1.529800
global_step: 24074, epoch: 2, loss: 1.447605
global_step: 24075, epoch: 2, loss: 1.409830
global_step: 24076, epoch: 2, loss: 1.443811
global_step: 24077, epoch: 2, loss: 1.371950
global_step: 24078, epoch: 2, loss: 1.423839
global_step: 24079, epoch: 2, loss: 1.426044
global_step: 24080, epoch: 2, loss: 0.939466
epoch: 2
train	acc: 0.5489	macro: p 0.3778, r 0.2236, f1: 0.1987	micro: p 0.5489, r 0.5489, f1 0.5489	weighted_f1:0.4466
dev	acc: 0.5014	macro: p 0.2283, r 0.2318, f1: 0.1962	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.3911
test	acc: 0.5548	macro: p 0.2340, r 0.2317, f1: 0.2041	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.4506
New best model!
global_step: 24081, epoch: 3, loss: 1.494778
global_step: 24082, epoch: 3, loss: 1.320880
global_step: 24083, epoch: 3, loss: 1.449658
global_step: 24084, epoch: 3, loss: 1.402873
global_step: 24085, epoch: 3, loss: 1.533225
global_step: 24086, epoch: 3, loss: 1.436886
global_step: 24087, epoch: 3, loss: 1.417680
global_step: 24088, epoch: 3, loss: 1.384120
global_step: 24089, epoch: 3, loss: 1.429604
global_step: 24090, epoch: 3, loss: 1.352656
global_step: 24091, epoch: 3, loss: 1.374402
global_step: 24092, epoch: 3, loss: 1.372278
global_step: 24093, epoch: 3, loss: 1.310236
global_step: 24094, epoch: 3, loss: 1.434232
global_step: 24095, epoch: 3, loss: 1.364795
global_step: 24096, epoch: 3, loss: 1.382131
global_step: 24097, epoch: 3, loss: 1.416199
global_step: 24098, epoch: 3, loss: 1.357507
global_step: 24099, epoch: 3, loss: 1.303226
global_step: 24100, epoch: 3, loss: 1.281512
global_step: 24101, epoch: 3, loss: 1.434554
global_step: 24102, epoch: 3, loss: 1.359327
global_step: 24103, epoch: 3, loss: 1.413928
global_step: 24104, epoch: 3, loss: 1.374350
global_step: 24105, epoch: 3, loss: 1.312068
global_step: 24106, epoch: 3, loss: 1.467171
global_step: 24107, epoch: 3, loss: 1.414950
global_step: 24108, epoch: 3, loss: 1.451714
global_step: 24109, epoch: 3, loss: 1.385844
global_step: 24110, epoch: 3, loss: 1.476145
global_step: 24111, epoch: 3, loss: 1.440475
global_step: 24112, epoch: 3, loss: 1.326645
global_step: 24113, epoch: 3, loss: 1.309727
global_step: 24114, epoch: 3, loss: 1.362081
global_step: 24115, epoch: 3, loss: 1.308923
global_step: 24116, epoch: 3, loss: 1.351402
global_step: 24117, epoch: 3, loss: 1.273102
global_step: 24118, epoch: 3, loss: 1.433471
global_step: 24119, epoch: 3, loss: 1.363041
global_step: 24120, epoch: 3, loss: 1.406544
epoch: 3
train	acc: 0.5626	macro: p 0.3493, r 0.2454, f1: 0.2184	micro: p 0.5626, r 0.5626, f1 0.5626	weighted_f1:0.4726
dev	acc: 0.5095	macro: p 0.2234, r 0.2505, f1: 0.2094	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4085
test	acc: 0.5598	macro: p 0.2304, r 0.2478, f1: 0.2147	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.4666
New best model!
global_step: 24121, epoch: 4, loss: 1.341402
global_step: 24122, epoch: 4, loss: 1.306308
global_step: 24123, epoch: 4, loss: 1.342825
global_step: 24124, epoch: 4, loss: 1.355259
global_step: 24125, epoch: 4, loss: 1.390306
global_step: 24126, epoch: 4, loss: 1.399622
global_step: 24127, epoch: 4, loss: 1.449355
global_step: 24128, epoch: 4, loss: 1.383977
global_step: 24129, epoch: 4, loss: 1.272426
global_step: 24130, epoch: 4, loss: 1.214753
global_step: 24131, epoch: 4, loss: 1.276070
global_step: 24132, epoch: 4, loss: 1.313902
global_step: 24133, epoch: 4, loss: 1.382814
global_step: 24134, epoch: 4, loss: 1.464424
global_step: 24135, epoch: 4, loss: 1.371609
global_step: 24136, epoch: 4, loss: 1.397730
global_step: 24137, epoch: 4, loss: 1.435102
global_step: 24138, epoch: 4, loss: 1.466698
global_step: 24139, epoch: 4, loss: 1.395770
global_step: 24140, epoch: 4, loss: 1.461153
global_step: 24141, epoch: 4, loss: 1.230330
global_step: 24142, epoch: 4, loss: 1.338123
global_step: 24143, epoch: 4, loss: 1.419815
global_step: 24144, epoch: 4, loss: 1.398341
global_step: 24145, epoch: 4, loss: 1.305025
global_step: 24146, epoch: 4, loss: 1.367834
global_step: 24147, epoch: 4, loss: 1.355405
global_step: 24148, epoch: 4, loss: 1.327020
global_step: 24149, epoch: 4, loss: 1.406477
global_step: 24150, epoch: 4, loss: 1.323542
global_step: 24151, epoch: 4, loss: 1.370770
global_step: 24152, epoch: 4, loss: 1.431951
global_step: 24153, epoch: 4, loss: 1.423232
global_step: 24154, epoch: 4, loss: 1.344940
global_step: 24155, epoch: 4, loss: 1.210755
global_step: 24156, epoch: 4, loss: 1.331006
global_step: 24157, epoch: 4, loss: 1.359103
global_step: 24158, epoch: 4, loss: 1.348728
global_step: 24159, epoch: 4, loss: 1.318469
global_step: 24160, epoch: 4, loss: 0.508801
epoch: 4
train	acc: 0.5640	macro: p 0.3365, r 0.2450, f1: 0.2205	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.4737
dev	acc: 0.5131	macro: p 0.2251, r 0.2499, f1: 0.2093	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4091
test	acc: 0.5617	macro: p 0.2625, r 0.2474, f1: 0.2164	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.4675
New best model!
global_step: 24161, epoch: 5, loss: 1.306302
global_step: 24162, epoch: 5, loss: 1.312596
global_step: 24163, epoch: 5, loss: 1.298148
global_step: 24164, epoch: 5, loss: 1.270211
global_step: 24165, epoch: 5, loss: 1.291764
global_step: 24166, epoch: 5, loss: 1.293186
global_step: 24167, epoch: 5, loss: 1.332780
global_step: 24168, epoch: 5, loss: 1.300593
global_step: 24169, epoch: 5, loss: 1.354819
global_step: 24170, epoch: 5, loss: 1.355718
global_step: 24171, epoch: 5, loss: 1.262388
global_step: 24172, epoch: 5, loss: 1.383206
global_step: 24173, epoch: 5, loss: 1.319422
global_step: 24174, epoch: 5, loss: 1.331350
global_step: 24175, epoch: 5, loss: 1.439408
global_step: 24176, epoch: 5, loss: 1.351997
global_step: 24177, epoch: 5, loss: 1.386129
global_step: 24178, epoch: 5, loss: 1.342102
global_step: 24179, epoch: 5, loss: 1.274961
global_step: 24180, epoch: 5, loss: 1.339123
global_step: 24181, epoch: 5, loss: 1.307948
global_step: 24182, epoch: 5, loss: 1.352069
global_step: 24183, epoch: 5, loss: 1.327334
global_step: 24184, epoch: 5, loss: 1.330807
global_step: 24185, epoch: 5, loss: 1.313913
global_step: 24186, epoch: 5, loss: 1.354338
global_step: 24187, epoch: 5, loss: 1.362177
global_step: 24188, epoch: 5, loss: 1.301915
global_step: 24189, epoch: 5, loss: 1.355936
global_step: 24190, epoch: 5, loss: 1.340637
global_step: 24191, epoch: 5, loss: 1.352309
global_step: 24192, epoch: 5, loss: 1.299249
global_step: 24193, epoch: 5, loss: 1.296860
global_step: 24194, epoch: 5, loss: 1.343458
global_step: 24195, epoch: 5, loss: 1.419204
global_step: 24196, epoch: 5, loss: 1.358113
global_step: 24197, epoch: 5, loss: 1.402282
global_step: 24198, epoch: 5, loss: 1.276722
global_step: 24199, epoch: 5, loss: 1.429983
global_step: 24200, epoch: 5, loss: 2.361212
epoch: 5
train	acc: 0.5736	macro: p 0.4452, r 0.2676, f1: 0.2502	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.4990
dev	acc: 0.5140	macro: p 0.2572, r 0.2626, f1: 0.2265	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4246
test	acc: 0.5659	macro: p 0.2741, r 0.2644, f1: 0.2367	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.4847
New best model!
global_step: 24201, epoch: 6, loss: 1.298451
global_step: 24202, epoch: 6, loss: 1.269932
global_step: 24203, epoch: 6, loss: 1.428170
global_step: 24204, epoch: 6, loss: 1.283654
global_step: 24205, epoch: 6, loss: 1.298724
global_step: 24206, epoch: 6, loss: 1.229215
global_step: 24207, epoch: 6, loss: 1.336160
global_step: 24208, epoch: 6, loss: 1.295752
global_step: 24209, epoch: 6, loss: 1.459105
global_step: 24210, epoch: 6, loss: 1.308475
global_step: 24211, epoch: 6, loss: 1.317722
global_step: 24212, epoch: 6, loss: 1.371944
global_step: 24213, epoch: 6, loss: 1.333016
global_step: 24214, epoch: 6, loss: 1.391944
global_step: 24215, epoch: 6, loss: 1.301737
global_step: 24216, epoch: 6, loss: 1.330622
global_step: 24217, epoch: 6, loss: 1.336934
global_step: 24218, epoch: 6, loss: 1.429587
global_step: 24219, epoch: 6, loss: 1.320878
global_step: 24220, epoch: 6, loss: 1.335354
global_step: 24221, epoch: 6, loss: 1.368739
global_step: 24222, epoch: 6, loss: 1.208143
global_step: 24223, epoch: 6, loss: 1.221840
global_step: 24224, epoch: 6, loss: 1.235692
global_step: 24225, epoch: 6, loss: 1.439993
global_step: 24226, epoch: 6, loss: 1.258234
global_step: 24227, epoch: 6, loss: 1.251712
global_step: 24228, epoch: 6, loss: 1.323999
global_step: 24229, epoch: 6, loss: 1.384671
global_step: 24230, epoch: 6, loss: 1.289776
global_step: 24231, epoch: 6, loss: 1.300333
global_step: 24232, epoch: 6, loss: 1.304189
global_step: 24233, epoch: 6, loss: 1.337597
global_step: 24234, epoch: 6, loss: 1.271785
global_step: 24235, epoch: 6, loss: 1.276209
global_step: 24236, epoch: 6, loss: 1.297495
global_step: 24237, epoch: 6, loss: 1.270889
global_step: 24238, epoch: 6, loss: 1.251743
global_step: 24239, epoch: 6, loss: 1.378628
global_step: 24240, epoch: 6, loss: 1.014133
epoch: 6
train	acc: 0.5924	macro: p 0.4688, r 0.2827, f1: 0.2813	micro: p 0.5924, r 0.5924, f1 0.5924	weighted_f1:0.5250
dev	acc: 0.5194	macro: p 0.2648, r 0.2588, f1: 0.2389	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4374
test	acc: 0.5851	macro: p 0.3064, r 0.2753, f1: 0.2679	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5146
New best model!
global_step: 24241, epoch: 7, loss: 1.325003
global_step: 24242, epoch: 7, loss: 1.366098
global_step: 24243, epoch: 7, loss: 1.206499
global_step: 24244, epoch: 7, loss: 1.238649
global_step: 24245, epoch: 7, loss: 1.274540
global_step: 24246, epoch: 7, loss: 1.316064
global_step: 24247, epoch: 7, loss: 1.210364
global_step: 24248, epoch: 7, loss: 1.263623
global_step: 24249, epoch: 7, loss: 1.439817
global_step: 24250, epoch: 7, loss: 1.187048
global_step: 24251, epoch: 7, loss: 1.359713
global_step: 24252, epoch: 7, loss: 1.313764
global_step: 24253, epoch: 7, loss: 1.260223
global_step: 24254, epoch: 7, loss: 1.320806
global_step: 24255, epoch: 7, loss: 1.310487
global_step: 24256, epoch: 7, loss: 1.236058
global_step: 24257, epoch: 7, loss: 1.374236
global_step: 24258, epoch: 7, loss: 1.299725
global_step: 24259, epoch: 7, loss: 1.326632
global_step: 24260, epoch: 7, loss: 1.237918
global_step: 24261, epoch: 7, loss: 1.397402
global_step: 24262, epoch: 7, loss: 1.328896
global_step: 24263, epoch: 7, loss: 1.320561
global_step: 24264, epoch: 7, loss: 1.288442
global_step: 24265, epoch: 7, loss: 1.323412
global_step: 24266, epoch: 7, loss: 1.222434
global_step: 24267, epoch: 7, loss: 1.255080
global_step: 24268, epoch: 7, loss: 1.261007
global_step: 24269, epoch: 7, loss: 1.308908
global_step: 24270, epoch: 7, loss: 1.237086
global_step: 24271, epoch: 7, loss: 1.330158
global_step: 24272, epoch: 7, loss: 1.257789
global_step: 24273, epoch: 7, loss: 1.344049
global_step: 24274, epoch: 7, loss: 1.273736
global_step: 24275, epoch: 7, loss: 1.340060
global_step: 24276, epoch: 7, loss: 1.240697
global_step: 24277, epoch: 7, loss: 1.257954
global_step: 24278, epoch: 7, loss: 1.252977
global_step: 24279, epoch: 7, loss: 1.365332
global_step: 24280, epoch: 7, loss: 0.979595
epoch: 7
train	acc: 0.5982	macro: p 0.4565, r 0.2940, f1: 0.2927	micro: p 0.5982, r 0.5982, f1 0.5982	weighted_f1:0.5351
dev	acc: 0.5356	macro: p 0.2736, r 0.2767, f1: 0.2597	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4588
test	acc: 0.5851	macro: p 0.2836, r 0.2811, f1: 0.2714	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5177
New best model!
global_step: 24281, epoch: 8, loss: 1.253842
global_step: 24282, epoch: 8, loss: 1.269511
global_step: 24283, epoch: 8, loss: 1.237782
global_step: 24284, epoch: 8, loss: 1.299857
global_step: 24285, epoch: 8, loss: 1.297859
global_step: 24286, epoch: 8, loss: 1.206627
global_step: 24287, epoch: 8, loss: 1.344188
global_step: 24288, epoch: 8, loss: 1.205841
global_step: 24289, epoch: 8, loss: 1.116758
global_step: 24290, epoch: 8, loss: 1.247666
global_step: 24291, epoch: 8, loss: 1.229405
global_step: 24292, epoch: 8, loss: 1.300495
global_step: 24293, epoch: 8, loss: 1.213667
global_step: 24294, epoch: 8, loss: 1.377320
global_step: 24295, epoch: 8, loss: 1.254839
global_step: 24296, epoch: 8, loss: 1.255312
global_step: 24297, epoch: 8, loss: 1.315092
global_step: 24298, epoch: 8, loss: 1.228653
global_step: 24299, epoch: 8, loss: 1.287583
global_step: 24300, epoch: 8, loss: 1.266217
global_step: 24301, epoch: 8, loss: 1.261676
global_step: 24302, epoch: 8, loss: 1.300005
global_step: 24303, epoch: 8, loss: 1.319425
global_step: 24304, epoch: 8, loss: 1.345544
global_step: 24305, epoch: 8, loss: 1.275425
global_step: 24306, epoch: 8, loss: 1.306295
global_step: 24307, epoch: 8, loss: 1.277944
global_step: 24308, epoch: 8, loss: 1.480883
global_step: 24309, epoch: 8, loss: 1.344076
global_step: 24310, epoch: 8, loss: 1.306711
global_step: 24311, epoch: 8, loss: 1.345604
global_step: 24312, epoch: 8, loss: 1.355924
global_step: 24313, epoch: 8, loss: 1.279717
global_step: 24314, epoch: 8, loss: 1.246062
global_step: 24315, epoch: 8, loss: 1.238616
global_step: 24316, epoch: 8, loss: 1.221837
global_step: 24317, epoch: 8, loss: 1.156980
global_step: 24318, epoch: 8, loss: 1.234163
global_step: 24319, epoch: 8, loss: 1.204587
global_step: 24320, epoch: 8, loss: 0.677507
epoch: 8
train	acc: 0.5845	macro: p 0.4700, r 0.2695, f1: 0.2593	micro: p 0.5845, r 0.5845, f1 0.5845	weighted_f1:0.5078
dev	acc: 0.5248	macro: p 0.2617, r 0.2632, f1: 0.2309	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4304
test	acc: 0.5747	macro: p 0.2888, r 0.2644, f1: 0.2432	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.4914
global_step: 24321, epoch: 9, loss: 1.474977
global_step: 24322, epoch: 9, loss: 1.315676
global_step: 24323, epoch: 9, loss: 1.269507
global_step: 24324, epoch: 9, loss: 1.297365
global_step: 24325, epoch: 9, loss: 1.283950
global_step: 24326, epoch: 9, loss: 1.334899
global_step: 24327, epoch: 9, loss: 1.354708
global_step: 24328, epoch: 9, loss: 1.328404
global_step: 24329, epoch: 9, loss: 1.317612
global_step: 24330, epoch: 9, loss: 1.270765
global_step: 24331, epoch: 9, loss: 1.337048
global_step: 24332, epoch: 9, loss: 1.299039
global_step: 24333, epoch: 9, loss: 1.152903
global_step: 24334, epoch: 9, loss: 1.286385
global_step: 24335, epoch: 9, loss: 1.316850
global_step: 24336, epoch: 9, loss: 1.196568
global_step: 24337, epoch: 9, loss: 1.267963
global_step: 24338, epoch: 9, loss: 1.216716
global_step: 24339, epoch: 9, loss: 1.270420
global_step: 24340, epoch: 9, loss: 1.348184
global_step: 24341, epoch: 9, loss: 1.219061
global_step: 24342, epoch: 9, loss: 1.166353
global_step: 24343, epoch: 9, loss: 1.272609
global_step: 24344, epoch: 9, loss: 1.192299
global_step: 24345, epoch: 9, loss: 1.177016
global_step: 24346, epoch: 9, loss: 1.182257
global_step: 24347, epoch: 9, loss: 1.219477
global_step: 24348, epoch: 9, loss: 1.299040
global_step: 24349, epoch: 9, loss: 1.195380
global_step: 24350, epoch: 9, loss: 1.340399
global_step: 24351, epoch: 9, loss: 1.206091
global_step: 24352, epoch: 9, loss: 1.181683
global_step: 24353, epoch: 9, loss: 1.214933
global_step: 24354, epoch: 9, loss: 1.164003
global_step: 24355, epoch: 9, loss: 1.289282
global_step: 24356, epoch: 9, loss: 1.222021
global_step: 24357, epoch: 9, loss: 1.169493
global_step: 24358, epoch: 9, loss: 1.165777
global_step: 24359, epoch: 9, loss: 1.341003
global_step: 24360, epoch: 9, loss: 1.832565
epoch: 9
train	acc: 0.6079	macro: p 0.4189, r 0.3146, f1: 0.3186	micro: p 0.6079, r 0.6079, f1 0.6079	weighted_f1:0.5551
dev	acc: 0.5383	macro: p 0.3875, r 0.2883, f1: 0.2760	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4730
test	acc: 0.5900	macro: p 0.4003, r 0.2941, f1: 0.2898	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5320
New best model!
global_step: 24361, epoch: 10, loss: 1.233759
global_step: 24362, epoch: 10, loss: 1.211807
global_step: 24363, epoch: 10, loss: 1.181475
global_step: 24364, epoch: 10, loss: 1.305900
global_step: 24365, epoch: 10, loss: 1.261234
global_step: 24366, epoch: 10, loss: 1.162403
global_step: 24367, epoch: 10, loss: 1.218641
global_step: 24368, epoch: 10, loss: 1.251176
global_step: 24369, epoch: 10, loss: 1.308808
global_step: 24370, epoch: 10, loss: 1.290434
global_step: 24371, epoch: 10, loss: 1.306102
global_step: 24372, epoch: 10, loss: 1.274777
global_step: 24373, epoch: 10, loss: 1.286734
global_step: 24374, epoch: 10, loss: 1.363048
global_step: 24375, epoch: 10, loss: 1.276950
global_step: 24376, epoch: 10, loss: 1.207902
global_step: 24377, epoch: 10, loss: 1.188842
global_step: 24378, epoch: 10, loss: 1.225653
global_step: 24379, epoch: 10, loss: 1.225280
global_step: 24380, epoch: 10, loss: 1.221939
global_step: 24381, epoch: 10, loss: 1.166908
global_step: 24382, epoch: 10, loss: 1.181691
global_step: 24383, epoch: 10, loss: 1.246302
global_step: 24384, epoch: 10, loss: 1.257181
global_step: 24385, epoch: 10, loss: 1.246626
global_step: 24386, epoch: 10, loss: 1.203762
global_step: 24387, epoch: 10, loss: 1.306386
global_step: 24388, epoch: 10, loss: 1.116087
global_step: 24389, epoch: 10, loss: 1.292110
global_step: 24390, epoch: 10, loss: 1.261393
global_step: 24391, epoch: 10, loss: 1.248091
global_step: 24392, epoch: 10, loss: 1.213547
global_step: 24393, epoch: 10, loss: 1.273024
global_step: 24394, epoch: 10, loss: 1.151370
global_step: 24395, epoch: 10, loss: 1.294446
global_step: 24396, epoch: 10, loss: 1.312267
global_step: 24397, epoch: 10, loss: 1.229054
global_step: 24398, epoch: 10, loss: 1.135406
global_step: 24399, epoch: 10, loss: 1.241777
global_step: 24400, epoch: 10, loss: 0.673249
epoch: 10
train	acc: 0.6104	macro: p 0.4281, r 0.3155, f1: 0.3218	micro: p 0.6104, r 0.6104, f1 0.6104	weighted_f1:0.5566
dev	acc: 0.5509	macro: p 0.4055, r 0.2964, f1: 0.2895	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4861
test	acc: 0.5954	macro: p 0.4186, r 0.2973, f1: 0.2996	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5393
New best model!
global_step: 24401, epoch: 11, loss: 1.245905
global_step: 24402, epoch: 11, loss: 1.276332
global_step: 24403, epoch: 11, loss: 1.268846
global_step: 24404, epoch: 11, loss: 1.201340
global_step: 24405, epoch: 11, loss: 1.285370
global_step: 24406, epoch: 11, loss: 1.223502
global_step: 24407, epoch: 11, loss: 1.188711
global_step: 24408, epoch: 11, loss: 1.256808
global_step: 24409, epoch: 11, loss: 1.251221
global_step: 24410, epoch: 11, loss: 1.265389
global_step: 24411, epoch: 11, loss: 1.306649
global_step: 24412, epoch: 11, loss: 1.185026
global_step: 24413, epoch: 11, loss: 1.254696
global_step: 24414, epoch: 11, loss: 1.238307
global_step: 24415, epoch: 11, loss: 1.227164
global_step: 24416, epoch: 11, loss: 1.226410
global_step: 24417, epoch: 11, loss: 1.245898
global_step: 24418, epoch: 11, loss: 1.056465
global_step: 24419, epoch: 11, loss: 1.187776
global_step: 24420, epoch: 11, loss: 1.286737
global_step: 24421, epoch: 11, loss: 1.325410
global_step: 24422, epoch: 11, loss: 1.221867
global_step: 24423, epoch: 11, loss: 1.259949
global_step: 24424, epoch: 11, loss: 1.134408
global_step: 24425, epoch: 11, loss: 1.148236
global_step: 24426, epoch: 11, loss: 1.342659
global_step: 24427, epoch: 11, loss: 1.234558
global_step: 24428, epoch: 11, loss: 1.294798
global_step: 24429, epoch: 11, loss: 1.275735
global_step: 24430, epoch: 11, loss: 1.209432
global_step: 24431, epoch: 11, loss: 1.158930
global_step: 24432, epoch: 11, loss: 1.119413
global_step: 24433, epoch: 11, loss: 1.204520
global_step: 24434, epoch: 11, loss: 1.219536
global_step: 24435, epoch: 11, loss: 1.316411
global_step: 24436, epoch: 11, loss: 1.250821
global_step: 24437, epoch: 11, loss: 1.228418
global_step: 24438, epoch: 11, loss: 1.167197
global_step: 24439, epoch: 11, loss: 1.198208
global_step: 24440, epoch: 11, loss: 0.222201
epoch: 11
train	acc: 0.6060	macro: p 0.4381, r 0.3008, f1: 0.3063	micro: p 0.6060, r 0.6060, f1 0.6060	weighted_f1:0.5452
dev	acc: 0.5401	macro: p 0.4006, r 0.2819, f1: 0.2675	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4653
test	acc: 0.5916	macro: p 0.4075, r 0.2855, f1: 0.2788	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5233
global_step: 24441, epoch: 12, loss: 1.344170
global_step: 24442, epoch: 12, loss: 1.207405
global_step: 24443, epoch: 12, loss: 1.172389
global_step: 24444, epoch: 12, loss: 1.251286
global_step: 24445, epoch: 12, loss: 1.303582
global_step: 24446, epoch: 12, loss: 1.234509
global_step: 24447, epoch: 12, loss: 1.237085
global_step: 24448, epoch: 12, loss: 1.149436
global_step: 24449, epoch: 12, loss: 1.268233
global_step: 24450, epoch: 12, loss: 1.254384
global_step: 24451, epoch: 12, loss: 1.189230
global_step: 24452, epoch: 12, loss: 1.256977
global_step: 24453, epoch: 12, loss: 1.275051
global_step: 24454, epoch: 12, loss: 1.342248
global_step: 24455, epoch: 12, loss: 1.190183
global_step: 24456, epoch: 12, loss: 1.221852
global_step: 24457, epoch: 12, loss: 1.232861
global_step: 24458, epoch: 12, loss: 1.248544
global_step: 24459, epoch: 12, loss: 1.194341
global_step: 24460, epoch: 12, loss: 1.285919
global_step: 24461, epoch: 12, loss: 1.198282
global_step: 24462, epoch: 12, loss: 1.284919
global_step: 24463, epoch: 12, loss: 1.184144
global_step: 24464, epoch: 12, loss: 1.108197
global_step: 24465, epoch: 12, loss: 1.278955
global_step: 24466, epoch: 12, loss: 1.163333
global_step: 24467, epoch: 12, loss: 1.224601
global_step: 24468, epoch: 12, loss: 1.254882
global_step: 24469, epoch: 12, loss: 1.131527
global_step: 24470, epoch: 12, loss: 1.184506
global_step: 24471, epoch: 12, loss: 1.209976
global_step: 24472, epoch: 12, loss: 1.235975
global_step: 24473, epoch: 12, loss: 1.168675
global_step: 24474, epoch: 12, loss: 1.233149
global_step: 24475, epoch: 12, loss: 1.101866
global_step: 24476, epoch: 12, loss: 1.135342
global_step: 24477, epoch: 12, loss: 1.073158
global_step: 24478, epoch: 12, loss: 1.199441
global_step: 24479, epoch: 12, loss: 1.302332
global_step: 24480, epoch: 12, loss: 1.536095
epoch: 12
train	acc: 0.6114	macro: p 0.4430, r 0.3086, f1: 0.3161	micro: p 0.6114, r 0.6114, f1 0.6114	weighted_f1:0.5534
dev	acc: 0.5410	macro: p 0.4015, r 0.2829, f1: 0.2696	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4675
test	acc: 0.5939	macro: p 0.4160, r 0.2911, f1: 0.2892	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5303
global_step: 24481, epoch: 13, loss: 1.278801
global_step: 24482, epoch: 13, loss: 1.153237
global_step: 24483, epoch: 13, loss: 1.185773
global_step: 24484, epoch: 13, loss: 1.226839
global_step: 24485, epoch: 13, loss: 1.238360
global_step: 24486, epoch: 13, loss: 1.120350
global_step: 24487, epoch: 13, loss: 1.223999
global_step: 24488, epoch: 13, loss: 1.198413
global_step: 24489, epoch: 13, loss: 1.118334
global_step: 24490, epoch: 13, loss: 1.140628
global_step: 24491, epoch: 13, loss: 1.364785
global_step: 24492, epoch: 13, loss: 1.106114
global_step: 24493, epoch: 13, loss: 1.181793
global_step: 24494, epoch: 13, loss: 1.249913
global_step: 24495, epoch: 13, loss: 1.284566
global_step: 24496, epoch: 13, loss: 1.311014
global_step: 24497, epoch: 13, loss: 1.105401
global_step: 24498, epoch: 13, loss: 1.150532
global_step: 24499, epoch: 13, loss: 1.218321
global_step: 24500, epoch: 13, loss: 1.184975
global_step: 24501, epoch: 13, loss: 1.168142
global_step: 24502, epoch: 13, loss: 1.186808
global_step: 24503, epoch: 13, loss: 1.161135
global_step: 24504, epoch: 13, loss: 1.181748
global_step: 24505, epoch: 13, loss: 1.216692
global_step: 24506, epoch: 13, loss: 1.065051
global_step: 24507, epoch: 13, loss: 1.178120
global_step: 24508, epoch: 13, loss: 1.258848
global_step: 24509, epoch: 13, loss: 1.111695
global_step: 24510, epoch: 13, loss: 1.186900
global_step: 24511, epoch: 13, loss: 1.241418
global_step: 24512, epoch: 13, loss: 1.217694
global_step: 24513, epoch: 13, loss: 1.235863
global_step: 24514, epoch: 13, loss: 1.177890
global_step: 24515, epoch: 13, loss: 1.208531
global_step: 24516, epoch: 13, loss: 1.241949
global_step: 24517, epoch: 13, loss: 1.217849
global_step: 24518, epoch: 13, loss: 1.223586
global_step: 24519, epoch: 13, loss: 1.137175
global_step: 24520, epoch: 13, loss: 0.647330
epoch: 13
train	acc: 0.6304	macro: p 0.4249, r 0.3402, f1: 0.3489	micro: p 0.6304, r 0.6304, f1 0.6304	weighted_f1:0.5834
dev	acc: 0.5401	macro: p 0.3308, r 0.2928, f1: 0.2795	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4767
test	acc: 0.5950	macro: p 0.3751, r 0.3036, f1: 0.3016	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5408
global_step: 24521, epoch: 14, loss: 1.180736
global_step: 24522, epoch: 14, loss: 1.168632
global_step: 24523, epoch: 14, loss: 1.339735
global_step: 24524, epoch: 14, loss: 1.184333
global_step: 24525, epoch: 14, loss: 1.125445
global_step: 24526, epoch: 14, loss: 1.092265
global_step: 24527, epoch: 14, loss: 1.156816
global_step: 24528, epoch: 14, loss: 1.255295
global_step: 24529, epoch: 14, loss: 1.172292
global_step: 24530, epoch: 14, loss: 1.156045
global_step: 24531, epoch: 14, loss: 1.294163
global_step: 24532, epoch: 14, loss: 1.232267
global_step: 24533, epoch: 14, loss: 1.159228
global_step: 24534, epoch: 14, loss: 1.171853
global_step: 24535, epoch: 14, loss: 1.213754
global_step: 24536, epoch: 14, loss: 1.119477
global_step: 24537, epoch: 14, loss: 1.106187
global_step: 24538, epoch: 14, loss: 1.096079
global_step: 24539, epoch: 14, loss: 1.291886
global_step: 24540, epoch: 14, loss: 1.251193
global_step: 24541, epoch: 14, loss: 1.164243
global_step: 24542, epoch: 14, loss: 1.088604
global_step: 24543, epoch: 14, loss: 1.152586
global_step: 24544, epoch: 14, loss: 1.134949
global_step: 24545, epoch: 14, loss: 1.061169
global_step: 24546, epoch: 14, loss: 1.215287
global_step: 24547, epoch: 14, loss: 1.174927
global_step: 24548, epoch: 14, loss: 1.330789
global_step: 24549, epoch: 14, loss: 1.147539
global_step: 24550, epoch: 14, loss: 1.198963
global_step: 24551, epoch: 14, loss: 1.240057
global_step: 24552, epoch: 14, loss: 1.136417
global_step: 24553, epoch: 14, loss: 1.114217
global_step: 24554, epoch: 14, loss: 1.170736
global_step: 24555, epoch: 14, loss: 1.128581
global_step: 24556, epoch: 14, loss: 1.088482
global_step: 24557, epoch: 14, loss: 1.270989
global_step: 24558, epoch: 14, loss: 1.240094
global_step: 24559, epoch: 14, loss: 1.367649
global_step: 24560, epoch: 14, loss: 1.797986
epoch: 14
train	acc: 0.6436	macro: p 0.4326, r 0.3577, f1: 0.3633	micro: p 0.6436, r 0.6436, f1 0.6436	weighted_f1:0.6004
dev	acc: 0.5428	macro: p 0.3251, r 0.3004, f1: 0.2848	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4832
test	acc: 0.5889	macro: p 0.3565, r 0.3059, f1: 0.3010	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5388
global_step: 24561, epoch: 15, loss: 1.150113
global_step: 24562, epoch: 15, loss: 1.162425
global_step: 24563, epoch: 15, loss: 1.267674
global_step: 24564, epoch: 15, loss: 1.231351
global_step: 24565, epoch: 15, loss: 1.165109
global_step: 24566, epoch: 15, loss: 1.035540
global_step: 24567, epoch: 15, loss: 1.244417
global_step: 24568, epoch: 15, loss: 1.160148
global_step: 24569, epoch: 15, loss: 1.200343
global_step: 24570, epoch: 15, loss: 1.072931
global_step: 24571, epoch: 15, loss: 1.240437
global_step: 24572, epoch: 15, loss: 1.128780
global_step: 24573, epoch: 15, loss: 1.256787
global_step: 24574, epoch: 15, loss: 1.093116
global_step: 24575, epoch: 15, loss: 1.230338
global_step: 24576, epoch: 15, loss: 1.111482
global_step: 24577, epoch: 15, loss: 1.278213
global_step: 24578, epoch: 15, loss: 1.176565
global_step: 24579, epoch: 15, loss: 1.093849
global_step: 24580, epoch: 15, loss: 1.110884
global_step: 24581, epoch: 15, loss: 1.188009
global_step: 24582, epoch: 15, loss: 1.139890
global_step: 24583, epoch: 15, loss: 1.072792
global_step: 24584, epoch: 15, loss: 1.328735
global_step: 24585, epoch: 15, loss: 1.102373
global_step: 24586, epoch: 15, loss: 1.198904
global_step: 24587, epoch: 15, loss: 1.120366
global_step: 24588, epoch: 15, loss: 1.171883
global_step: 24589, epoch: 15, loss: 1.149033
global_step: 24590, epoch: 15, loss: 1.225848
global_step: 24591, epoch: 15, loss: 1.122709
global_step: 24592, epoch: 15, loss: 1.189935
global_step: 24593, epoch: 15, loss: 1.132556
global_step: 24594, epoch: 15, loss: 1.128954
global_step: 24595, epoch: 15, loss: 1.246630
global_step: 24596, epoch: 15, loss: 1.131159
global_step: 24597, epoch: 15, loss: 1.130401
global_step: 24598, epoch: 15, loss: 1.112466
global_step: 24599, epoch: 15, loss: 1.118392
global_step: 24600, epoch: 15, loss: 1.100593
epoch: 15
train	acc: 0.6358	macro: p 0.4415, r 0.3459, f1: 0.3530	micro: p 0.6358, r 0.6358, f1 0.6358	weighted_f1:0.5877
dev	acc: 0.5410	macro: p 0.3311, r 0.2943, f1: 0.2755	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4732
test	acc: 0.5931	macro: p 0.3790, r 0.3042, f1: 0.2966	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5361
global_step: 24601, epoch: 16, loss: 1.174944
global_step: 24602, epoch: 16, loss: 1.140238
global_step: 24603, epoch: 16, loss: 1.076962
global_step: 24604, epoch: 16, loss: 1.053092
global_step: 24605, epoch: 16, loss: 1.102295
global_step: 24606, epoch: 16, loss: 1.190219
global_step: 24607, epoch: 16, loss: 1.067315
global_step: 24608, epoch: 16, loss: 1.022307
global_step: 24609, epoch: 16, loss: 1.257210
global_step: 24610, epoch: 16, loss: 1.119599
global_step: 24611, epoch: 16, loss: 1.194671
global_step: 24612, epoch: 16, loss: 1.149268
global_step: 24613, epoch: 16, loss: 1.088503
global_step: 24614, epoch: 16, loss: 1.212945
global_step: 24615, epoch: 16, loss: 1.056827
global_step: 24616, epoch: 16, loss: 1.195539
global_step: 24617, epoch: 16, loss: 1.107452
global_step: 24618, epoch: 16, loss: 1.136979
global_step: 24619, epoch: 16, loss: 1.256463
global_step: 24620, epoch: 16, loss: 1.076852
global_step: 24621, epoch: 16, loss: 1.183086
global_step: 24622, epoch: 16, loss: 1.190340
global_step: 24623, epoch: 16, loss: 1.208727
global_step: 24624, epoch: 16, loss: 1.081736
global_step: 24625, epoch: 16, loss: 1.279010
global_step: 24626, epoch: 16, loss: 1.182322
global_step: 24627, epoch: 16, loss: 1.198475
global_step: 24628, epoch: 16, loss: 1.151134
global_step: 24629, epoch: 16, loss: 1.200251
global_step: 24630, epoch: 16, loss: 1.055315
global_step: 24631, epoch: 16, loss: 1.135741
global_step: 24632, epoch: 16, loss: 1.176456
global_step: 24633, epoch: 16, loss: 1.095941
global_step: 24634, epoch: 16, loss: 1.148130
global_step: 24635, epoch: 16, loss: 1.118285
global_step: 24636, epoch: 16, loss: 1.266804
global_step: 24637, epoch: 16, loss: 1.233720
global_step: 24638, epoch: 16, loss: 1.202906
global_step: 24639, epoch: 16, loss: 1.156480
global_step: 24640, epoch: 16, loss: 0.541241
epoch: 16
train	acc: 0.6324	macro: p 0.4466, r 0.3356, f1: 0.3456	micro: p 0.6324, r 0.6324, f1 0.6324	weighted_f1:0.5820
dev	acc: 0.5410	macro: p 0.3398, r 0.2902, f1: 0.2744	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4721
test	acc: 0.5912	macro: p 0.3875, r 0.2958, f1: 0.2927	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5321
global_step: 24641, epoch: 17, loss: 1.138253
global_step: 24642, epoch: 17, loss: 1.125280
global_step: 24643, epoch: 17, loss: 1.046162
global_step: 24644, epoch: 17, loss: 1.185335
global_step: 24645, epoch: 17, loss: 1.255835
global_step: 24646, epoch: 17, loss: 1.057455
global_step: 24647, epoch: 17, loss: 1.085433
global_step: 24648, epoch: 17, loss: 1.018540
global_step: 24649, epoch: 17, loss: 1.187885
global_step: 24650, epoch: 17, loss: 1.015745
global_step: 24651, epoch: 17, loss: 1.190838
global_step: 24652, epoch: 17, loss: 1.146456
global_step: 24653, epoch: 17, loss: 1.158154
global_step: 24654, epoch: 17, loss: 1.090176
global_step: 24655, epoch: 17, loss: 1.227323
global_step: 24656, epoch: 17, loss: 1.142772
global_step: 24657, epoch: 17, loss: 1.114067
global_step: 24658, epoch: 17, loss: 1.151548
global_step: 24659, epoch: 17, loss: 1.179113
global_step: 24660, epoch: 17, loss: 1.132831
global_step: 24661, epoch: 17, loss: 1.087987
global_step: 24662, epoch: 17, loss: 1.229873
global_step: 24663, epoch: 17, loss: 1.162811
global_step: 24664, epoch: 17, loss: 1.160336
global_step: 24665, epoch: 17, loss: 1.039603
global_step: 24666, epoch: 17, loss: 1.150961
global_step: 24667, epoch: 17, loss: 1.064202
global_step: 24668, epoch: 17, loss: 1.141165
global_step: 24669, epoch: 17, loss: 1.059499
global_step: 24670, epoch: 17, loss: 1.133636
global_step: 24671, epoch: 17, loss: 1.120200
global_step: 24672, epoch: 17, loss: 1.170827
global_step: 24673, epoch: 17, loss: 1.142615
global_step: 24674, epoch: 17, loss: 1.146304
global_step: 24675, epoch: 17, loss: 1.137566
global_step: 24676, epoch: 17, loss: 1.065266
global_step: 24677, epoch: 17, loss: 1.158463
global_step: 24678, epoch: 17, loss: 1.039611
global_step: 24679, epoch: 17, loss: 1.171424
global_step: 24680, epoch: 17, loss: 0.819750
epoch: 17
train	acc: 0.6417	macro: p 0.4426, r 0.3520, f1: 0.3639	micro: p 0.6417, r 0.6417, f1 0.6417	weighted_f1:0.5968
dev	acc: 0.5401	macro: p 0.3320, r 0.2923, f1: 0.2742	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4719
test	acc: 0.5881	macro: p 0.3595, r 0.2978, f1: 0.2926	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5311
global_step: 24681, epoch: 18, loss: 1.087137
global_step: 24682, epoch: 18, loss: 1.097104
global_step: 24683, epoch: 18, loss: 1.028524
global_step: 24684, epoch: 18, loss: 1.223268
global_step: 24685, epoch: 18, loss: 1.033050
global_step: 24686, epoch: 18, loss: 1.149239
global_step: 24687, epoch: 18, loss: 1.074238
global_step: 24688, epoch: 18, loss: 1.081691
global_step: 24689, epoch: 18, loss: 1.080300
global_step: 24690, epoch: 18, loss: 1.211672
global_step: 24691, epoch: 18, loss: 1.194749
global_step: 24692, epoch: 18, loss: 1.104269
global_step: 24693, epoch: 18, loss: 1.136458
global_step: 24694, epoch: 18, loss: 1.189383
global_step: 24695, epoch: 18, loss: 1.115950
global_step: 24696, epoch: 18, loss: 1.216653
global_step: 24697, epoch: 18, loss: 1.177191
global_step: 24698, epoch: 18, loss: 1.210175
global_step: 24699, epoch: 18, loss: 0.995617
global_step: 24700, epoch: 18, loss: 1.165448
global_step: 24701, epoch: 18, loss: 1.172371
global_step: 24702, epoch: 18, loss: 1.187016
global_step: 24703, epoch: 18, loss: 1.157486
global_step: 24704, epoch: 18, loss: 1.045449
global_step: 24705, epoch: 18, loss: 1.010816
global_step: 24706, epoch: 18, loss: 1.121685
global_step: 24707, epoch: 18, loss: 1.013312
global_step: 24708, epoch: 18, loss: 1.006406
global_step: 24709, epoch: 18, loss: 1.120605
global_step: 24710, epoch: 18, loss: 1.094194
global_step: 24711, epoch: 18, loss: 1.166891
global_step: 24712, epoch: 18, loss: 1.142727
global_step: 24713, epoch: 18, loss: 1.119631
global_step: 24714, epoch: 18, loss: 1.016289
global_step: 24715, epoch: 18, loss: 1.126608
global_step: 24716, epoch: 18, loss: 1.179499
global_step: 24717, epoch: 18, loss: 1.236896
global_step: 24718, epoch: 18, loss: 1.172816
global_step: 24719, epoch: 18, loss: 1.183081
global_step: 24720, epoch: 18, loss: 0.992955
epoch: 18
train	acc: 0.6567	macro: p 0.4556, r 0.3664, f1: 0.3750	micro: p 0.6567, r 0.6567, f1 0.6567	weighted_f1:0.6124
dev	acc: 0.5410	macro: p 0.3355, r 0.2964, f1: 0.2767	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4754
test	acc: 0.5881	macro: p 0.3702, r 0.3033, f1: 0.2974	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5344
global_step: 24721, epoch: 19, loss: 1.035934
global_step: 24722, epoch: 19, loss: 1.200448
global_step: 24723, epoch: 19, loss: 1.228353
global_step: 24724, epoch: 19, loss: 1.123693
global_step: 24725, epoch: 19, loss: 1.137253
global_step: 24726, epoch: 19, loss: 1.173345
global_step: 24727, epoch: 19, loss: 1.004207
global_step: 24728, epoch: 19, loss: 0.903819
global_step: 24729, epoch: 19, loss: 1.156569
global_step: 24730, epoch: 19, loss: 0.983606
global_step: 24731, epoch: 19, loss: 1.090973
global_step: 24732, epoch: 19, loss: 1.121348
global_step: 24733, epoch: 19, loss: 1.073542
global_step: 24734, epoch: 19, loss: 1.069658
global_step: 24735, epoch: 19, loss: 1.139182
global_step: 24736, epoch: 19, loss: 1.007665
global_step: 24737, epoch: 19, loss: 1.166858
global_step: 24738, epoch: 19, loss: 1.069192
global_step: 24739, epoch: 19, loss: 1.146529
global_step: 24740, epoch: 19, loss: 1.181286
global_step: 24741, epoch: 19, loss: 1.106041
global_step: 24742, epoch: 19, loss: 1.158802
global_step: 24743, epoch: 19, loss: 1.122484
global_step: 24744, epoch: 19, loss: 1.134818
global_step: 24745, epoch: 19, loss: 1.115302
global_step: 24746, epoch: 19, loss: 1.151073
global_step: 24747, epoch: 19, loss: 1.154148
global_step: 24748, epoch: 19, loss: 1.146683
global_step: 24749, epoch: 19, loss: 1.022730
global_step: 24750, epoch: 19, loss: 1.128246
global_step: 24751, epoch: 19, loss: 1.026957
global_step: 24752, epoch: 19, loss: 0.921542
global_step: 24753, epoch: 19, loss: 1.040387
global_step: 24754, epoch: 19, loss: 1.046010
global_step: 24755, epoch: 19, loss: 1.074145
global_step: 24756, epoch: 19, loss: 1.177567
global_step: 24757, epoch: 19, loss: 1.101006
global_step: 24758, epoch: 19, loss: 1.076750
global_step: 24759, epoch: 19, loss: 1.093183
global_step: 24760, epoch: 19, loss: 1.877594
epoch: 19
train	acc: 0.6797	macro: p 0.4567, r 0.4026, f1: 0.4052	micro: p 0.6797, r 0.6797, f1 0.6797	weighted_f1:0.6413
dev	acc: 0.5455	macro: p 0.3407, r 0.3089, f1: 0.2916	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4873
test	acc: 0.5923	macro: p 0.3625, r 0.3196, f1: 0.3120	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5463
New best model!
global_step: 24761, epoch: 20, loss: 1.030057
global_step: 24762, epoch: 20, loss: 1.092304
global_step: 24763, epoch: 20, loss: 1.016427
global_step: 24764, epoch: 20, loss: 1.155845
global_step: 24765, epoch: 20, loss: 1.104887
global_step: 24766, epoch: 20, loss: 1.121054
global_step: 24767, epoch: 20, loss: 1.034116
global_step: 24768, epoch: 20, loss: 1.070469
global_step: 24769, epoch: 20, loss: 1.165713
global_step: 24770, epoch: 20, loss: 1.117930
global_step: 24771, epoch: 20, loss: 1.097695
global_step: 24772, epoch: 20, loss: 1.012785
global_step: 24773, epoch: 20, loss: 1.029851
global_step: 24774, epoch: 20, loss: 1.084587
global_step: 24775, epoch: 20, loss: 1.107969
global_step: 24776, epoch: 20, loss: 1.127222
global_step: 24777, epoch: 20, loss: 1.059292
global_step: 24778, epoch: 20, loss: 1.060696
global_step: 24779, epoch: 20, loss: 1.063843
global_step: 24780, epoch: 20, loss: 1.114436
global_step: 24781, epoch: 20, loss: 0.985802
global_step: 24782, epoch: 20, loss: 1.130320
global_step: 24783, epoch: 20, loss: 1.084674
global_step: 24784, epoch: 20, loss: 1.105709
global_step: 24785, epoch: 20, loss: 1.171916
global_step: 24786, epoch: 20, loss: 1.082626
global_step: 24787, epoch: 20, loss: 1.051184
global_step: 24788, epoch: 20, loss: 1.084780
global_step: 24789, epoch: 20, loss: 1.041487
global_step: 24790, epoch: 20, loss: 1.106058
global_step: 24791, epoch: 20, loss: 1.096702
global_step: 24792, epoch: 20, loss: 1.181404
global_step: 24793, epoch: 20, loss: 1.021764
global_step: 24794, epoch: 20, loss: 1.070212
global_step: 24795, epoch: 20, loss: 1.040683
global_step: 24796, epoch: 20, loss: 1.198991
global_step: 24797, epoch: 20, loss: 1.090893
global_step: 24798, epoch: 20, loss: 1.119971
global_step: 24799, epoch: 20, loss: 1.088351
global_step: 24800, epoch: 20, loss: 0.810204
epoch: 20
train	acc: 0.6581	macro: p 0.4614, r 0.3669, f1: 0.3839	micro: p 0.6581, r 0.6581, f1 0.6581	weighted_f1:0.6143
dev	acc: 0.5500	macro: p 0.3422, r 0.2964, f1: 0.2845	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4833
test	acc: 0.5966	macro: p 0.3681, r 0.3021, f1: 0.3029	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5406
global_step: 24801, epoch: 21, loss: 1.172979
global_step: 24802, epoch: 21, loss: 0.989162
global_step: 24803, epoch: 21, loss: 1.091993
global_step: 24804, epoch: 21, loss: 1.112533
global_step: 24805, epoch: 21, loss: 1.112779
global_step: 24806, epoch: 21, loss: 1.045181
global_step: 24807, epoch: 21, loss: 1.071646
global_step: 24808, epoch: 21, loss: 1.041355
global_step: 24809, epoch: 21, loss: 1.057001
global_step: 24810, epoch: 21, loss: 1.049621
global_step: 24811, epoch: 21, loss: 1.025136
global_step: 24812, epoch: 21, loss: 1.000750
global_step: 24813, epoch: 21, loss: 1.042269
global_step: 24814, epoch: 21, loss: 1.103243
global_step: 24815, epoch: 21, loss: 1.023016
global_step: 24816, epoch: 21, loss: 1.165441
global_step: 24817, epoch: 21, loss: 1.077452
global_step: 24818, epoch: 21, loss: 1.085526
global_step: 24819, epoch: 21, loss: 1.029604
global_step: 24820, epoch: 21, loss: 1.084320
global_step: 24821, epoch: 21, loss: 1.039207
global_step: 24822, epoch: 21, loss: 1.256967
global_step: 24823, epoch: 21, loss: 1.052027
global_step: 24824, epoch: 21, loss: 1.113417
global_step: 24825, epoch: 21, loss: 1.061962
global_step: 24826, epoch: 21, loss: 1.092587
global_step: 24827, epoch: 21, loss: 1.006119
global_step: 24828, epoch: 21, loss: 0.975553
global_step: 24829, epoch: 21, loss: 1.066775
global_step: 24830, epoch: 21, loss: 1.106947
global_step: 24831, epoch: 21, loss: 1.050288
global_step: 24832, epoch: 21, loss: 1.054159
global_step: 24833, epoch: 21, loss: 1.122476
global_step: 24834, epoch: 21, loss: 1.161540
global_step: 24835, epoch: 21, loss: 1.074504
global_step: 24836, epoch: 21, loss: 1.013806
global_step: 24837, epoch: 21, loss: 1.087427
global_step: 24838, epoch: 21, loss: 1.004757
global_step: 24839, epoch: 21, loss: 1.157088
global_step: 24840, epoch: 21, loss: 0.762285
epoch: 21
train	acc: 0.6903	macro: p 0.4691, r 0.4143, f1: 0.4227	micro: p 0.6903, r 0.6903, f1 0.6903	weighted_f1:0.6542
dev	acc: 0.5482	macro: p 0.3392, r 0.3083, f1: 0.2989	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4936
test	acc: 0.6034	macro: p 0.3664, r 0.3225, f1: 0.3219	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5582
New best model!
global_step: 24841, epoch: 22, loss: 1.103149
global_step: 24842, epoch: 22, loss: 1.052473
global_step: 24843, epoch: 22, loss: 1.084524
global_step: 24844, epoch: 22, loss: 1.056026
global_step: 24845, epoch: 22, loss: 1.025397
global_step: 24846, epoch: 22, loss: 1.207546
global_step: 24847, epoch: 22, loss: 1.079372
global_step: 24848, epoch: 22, loss: 1.045452
global_step: 24849, epoch: 22, loss: 1.058884
global_step: 24850, epoch: 22, loss: 0.915671
global_step: 24851, epoch: 22, loss: 0.986647
global_step: 24852, epoch: 22, loss: 1.021407
global_step: 24853, epoch: 22, loss: 1.094349
global_step: 24854, epoch: 22, loss: 1.109284
global_step: 24855, epoch: 22, loss: 1.073967
global_step: 24856, epoch: 22, loss: 1.189171
global_step: 24857, epoch: 22, loss: 0.984713
global_step: 24858, epoch: 22, loss: 1.031720
global_step: 24859, epoch: 22, loss: 0.976819
global_step: 24860, epoch: 22, loss: 0.956167
global_step: 24861, epoch: 22, loss: 1.055151
global_step: 24862, epoch: 22, loss: 1.102117
global_step: 24863, epoch: 22, loss: 1.062045
global_step: 24864, epoch: 22, loss: 0.979548
global_step: 24865, epoch: 22, loss: 0.955300
global_step: 24866, epoch: 22, loss: 1.092287
global_step: 24867, epoch: 22, loss: 1.065329
global_step: 24868, epoch: 22, loss: 1.065304
global_step: 24869, epoch: 22, loss: 1.115103
global_step: 24870, epoch: 22, loss: 1.018558
global_step: 24871, epoch: 22, loss: 1.055709
global_step: 24872, epoch: 22, loss: 1.119592
global_step: 24873, epoch: 22, loss: 0.966926
global_step: 24874, epoch: 22, loss: 1.055907
global_step: 24875, epoch: 22, loss: 1.089564
global_step: 24876, epoch: 22, loss: 0.911500
global_step: 24877, epoch: 22, loss: 1.170878
global_step: 24878, epoch: 22, loss: 1.006675
global_step: 24879, epoch: 22, loss: 1.057484
global_step: 24880, epoch: 22, loss: 1.411173
epoch: 22
train	acc: 0.7043	macro: p 0.4754, r 0.4361, f1: 0.4454	micro: p 0.7043, r 0.7043, f1 0.7043	weighted_f1:0.6726
dev	acc: 0.5509	macro: p 0.3376, r 0.3109, f1: 0.3048	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4992
test	acc: 0.6019	macro: p 0.3556, r 0.3249, f1: 0.3256	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5597
New best model!
global_step: 24881, epoch: 23, loss: 1.051057
global_step: 24882, epoch: 23, loss: 0.980273
global_step: 24883, epoch: 23, loss: 1.030745
global_step: 24884, epoch: 23, loss: 1.063362
global_step: 24885, epoch: 23, loss: 1.000548
global_step: 24886, epoch: 23, loss: 0.919021
global_step: 24887, epoch: 23, loss: 1.149137
global_step: 24888, epoch: 23, loss: 0.884757
global_step: 24889, epoch: 23, loss: 1.013954
global_step: 24890, epoch: 23, loss: 0.944616
global_step: 24891, epoch: 23, loss: 1.102059
global_step: 24892, epoch: 23, loss: 1.112903
global_step: 24893, epoch: 23, loss: 1.034200
global_step: 24894, epoch: 23, loss: 1.032534
global_step: 24895, epoch: 23, loss: 1.039219
global_step: 24896, epoch: 23, loss: 1.099320
global_step: 24897, epoch: 23, loss: 1.063551
global_step: 24898, epoch: 23, loss: 1.075055
global_step: 24899, epoch: 23, loss: 1.025485
global_step: 24900, epoch: 23, loss: 1.026437
global_step: 24901, epoch: 23, loss: 1.126541
global_step: 24902, epoch: 23, loss: 1.078514
global_step: 24903, epoch: 23, loss: 0.986310
global_step: 24904, epoch: 23, loss: 1.024309
global_step: 24905, epoch: 23, loss: 1.018464
global_step: 24906, epoch: 23, loss: 0.993790
global_step: 24907, epoch: 23, loss: 1.093870
global_step: 24908, epoch: 23, loss: 1.111807
global_step: 24909, epoch: 23, loss: 1.255218
global_step: 24910, epoch: 23, loss: 1.060187
global_step: 24911, epoch: 23, loss: 1.001888
global_step: 24912, epoch: 23, loss: 1.080436
global_step: 24913, epoch: 23, loss: 1.036901
global_step: 24914, epoch: 23, loss: 1.054290
global_step: 24915, epoch: 23, loss: 1.164640
global_step: 24916, epoch: 23, loss: 1.080465
global_step: 24917, epoch: 23, loss: 0.990324
global_step: 24918, epoch: 23, loss: 0.994179
global_step: 24919, epoch: 23, loss: 0.998182
global_step: 24920, epoch: 23, loss: 0.627134
epoch: 23
train	acc: 0.6774	macro: p 0.4803, r 0.3892, f1: 0.4076	micro: p 0.6774, r 0.6774, f1 0.6774	weighted_f1:0.6371
dev	acc: 0.5446	macro: p 0.3387, r 0.2923, f1: 0.2791	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4776
test	acc: 0.5981	macro: p 0.3777, r 0.3042, f1: 0.3039	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5417
global_step: 24921, epoch: 24, loss: 1.023553
global_step: 24922, epoch: 24, loss: 0.991284
global_step: 24923, epoch: 24, loss: 0.905934
global_step: 24924, epoch: 24, loss: 1.014480
global_step: 24925, epoch: 24, loss: 1.031855
global_step: 24926, epoch: 24, loss: 1.128080
global_step: 24927, epoch: 24, loss: 1.038575
global_step: 24928, epoch: 24, loss: 1.033098
global_step: 24929, epoch: 24, loss: 0.896144
global_step: 24930, epoch: 24, loss: 1.011097
global_step: 24931, epoch: 24, loss: 1.047824
global_step: 24932, epoch: 24, loss: 0.975378
global_step: 24933, epoch: 24, loss: 0.926058
global_step: 24934, epoch: 24, loss: 1.154818
global_step: 24935, epoch: 24, loss: 1.054187
global_step: 24936, epoch: 24, loss: 1.020506
global_step: 24937, epoch: 24, loss: 1.039107
global_step: 24938, epoch: 24, loss: 0.989982
global_step: 24939, epoch: 24, loss: 1.059672
global_step: 24940, epoch: 24, loss: 0.959925
global_step: 24941, epoch: 24, loss: 1.032438
global_step: 24942, epoch: 24, loss: 1.049988
global_step: 24943, epoch: 24, loss: 1.119181
global_step: 24944, epoch: 24, loss: 0.965897
global_step: 24945, epoch: 24, loss: 0.962118
global_step: 24946, epoch: 24, loss: 0.946997
global_step: 24947, epoch: 24, loss: 1.004252
global_step: 24948, epoch: 24, loss: 1.124008
global_step: 24949, epoch: 24, loss: 1.026741
global_step: 24950, epoch: 24, loss: 0.971263
global_step: 24951, epoch: 24, loss: 1.078752
global_step: 24952, epoch: 24, loss: 1.199298
global_step: 24953, epoch: 24, loss: 0.929484
global_step: 24954, epoch: 24, loss: 1.028874
global_step: 24955, epoch: 24, loss: 1.067823
global_step: 24956, epoch: 24, loss: 1.062892
global_step: 24957, epoch: 24, loss: 1.125093
global_step: 24958, epoch: 24, loss: 1.121654
global_step: 24959, epoch: 24, loss: 1.006499
global_step: 24960, epoch: 24, loss: 0.196912
epoch: 24
train	acc: 0.6996	macro: p 0.4873, r 0.4197, f1: 0.4372	micro: p 0.6996, r 0.6996, f1 0.6996	weighted_f1:0.6643
dev	acc: 0.5419	macro: p 0.3235, r 0.2942, f1: 0.2826	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4796
test	acc: 0.5969	macro: p 0.3582, r 0.3084, f1: 0.3086	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5448
global_step: 24961, epoch: 25, loss: 1.037013
global_step: 24962, epoch: 25, loss: 0.964912
global_step: 24963, epoch: 25, loss: 1.054468
global_step: 24964, epoch: 25, loss: 0.999153
global_step: 24965, epoch: 25, loss: 0.998556
global_step: 24966, epoch: 25, loss: 1.006493
global_step: 24967, epoch: 25, loss: 0.979926
global_step: 24968, epoch: 25, loss: 0.988037
global_step: 24969, epoch: 25, loss: 1.053522
global_step: 24970, epoch: 25, loss: 0.955335
global_step: 24971, epoch: 25, loss: 1.102496
global_step: 24972, epoch: 25, loss: 0.945240
global_step: 24973, epoch: 25, loss: 0.968568
global_step: 24974, epoch: 25, loss: 1.078596
global_step: 24975, epoch: 25, loss: 0.973073
global_step: 24976, epoch: 25, loss: 0.968096
global_step: 24977, epoch: 25, loss: 0.930084
global_step: 24978, epoch: 25, loss: 1.054113
global_step: 24979, epoch: 25, loss: 0.960231
global_step: 24980, epoch: 25, loss: 0.950049
global_step: 24981, epoch: 25, loss: 1.034046
global_step: 24982, epoch: 25, loss: 0.893418
global_step: 24983, epoch: 25, loss: 1.011826
global_step: 24984, epoch: 25, loss: 1.022674
global_step: 24985, epoch: 25, loss: 1.020569
global_step: 24986, epoch: 25, loss: 1.048741
global_step: 24987, epoch: 25, loss: 0.997412
global_step: 24988, epoch: 25, loss: 1.047551
global_step: 24989, epoch: 25, loss: 0.961090
global_step: 24990, epoch: 25, loss: 1.082623
global_step: 24991, epoch: 25, loss: 1.024116
global_step: 24992, epoch: 25, loss: 1.027340
global_step: 24993, epoch: 25, loss: 1.000868
global_step: 24994, epoch: 25, loss: 0.939690
global_step: 24995, epoch: 25, loss: 0.877674
global_step: 24996, epoch: 25, loss: 1.030462
global_step: 24997, epoch: 25, loss: 1.166036
global_step: 24998, epoch: 25, loss: 1.009298
global_step: 24999, epoch: 25, loss: 1.054932
global_step: 25000, epoch: 25, loss: 0.997414
epoch: 25
train	acc: 0.7148	macro: p 0.4993, r 0.4380, f1: 0.4516	micro: p 0.7148, r 0.7148, f1 0.7148	weighted_f1:0.6815
dev	acc: 0.5528	macro: p 0.3445, r 0.3052, f1: 0.2950	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4932
test	acc: 0.6000	macro: p 0.3706, r 0.3174, f1: 0.3195	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5533
global_step: 25001, epoch: 26, loss: 1.043159
global_step: 25002, epoch: 26, loss: 1.001942
global_step: 25003, epoch: 26, loss: 0.984661
global_step: 25004, epoch: 26, loss: 1.006329
global_step: 25005, epoch: 26, loss: 0.981322
global_step: 25006, epoch: 26, loss: 0.992923
global_step: 25007, epoch: 26, loss: 1.020856
global_step: 25008, epoch: 26, loss: 1.077595
global_step: 25009, epoch: 26, loss: 0.955367
global_step: 25010, epoch: 26, loss: 0.888086
global_step: 25011, epoch: 26, loss: 0.952698
global_step: 25012, epoch: 26, loss: 0.996468
global_step: 25013, epoch: 26, loss: 1.037826
global_step: 25014, epoch: 26, loss: 1.080855
global_step: 25015, epoch: 26, loss: 1.049027
global_step: 25016, epoch: 26, loss: 1.030581
global_step: 25017, epoch: 26, loss: 0.988635
global_step: 25018, epoch: 26, loss: 0.961074
global_step: 25019, epoch: 26, loss: 0.970764
global_step: 25020, epoch: 26, loss: 1.089467
global_step: 25021, epoch: 26, loss: 1.077822
global_step: 25022, epoch: 26, loss: 0.985537
global_step: 25023, epoch: 26, loss: 1.034807
global_step: 25024, epoch: 26, loss: 0.987035
global_step: 25025, epoch: 26, loss: 0.921984
global_step: 25026, epoch: 26, loss: 0.969851
global_step: 25027, epoch: 26, loss: 1.006258
global_step: 25028, epoch: 26, loss: 0.967551
global_step: 25029, epoch: 26, loss: 0.929791
global_step: 25030, epoch: 26, loss: 0.972022
global_step: 25031, epoch: 26, loss: 0.946666
global_step: 25032, epoch: 26, loss: 0.990329
global_step: 25033, epoch: 26, loss: 1.077166
global_step: 25034, epoch: 26, loss: 0.920608
global_step: 25035, epoch: 26, loss: 0.870599
global_step: 25036, epoch: 26, loss: 1.016637
global_step: 25037, epoch: 26, loss: 1.033632
global_step: 25038, epoch: 26, loss: 1.074333
global_step: 25039, epoch: 26, loss: 1.062277
global_step: 25040, epoch: 26, loss: 1.132499
epoch: 26
train	acc: 0.6937	macro: p 0.5031, r 0.4035, f1: 0.4214	micro: p 0.6937, r 0.6937, f1 0.6937	weighted_f1:0.6530
dev	acc: 0.5491	macro: p 0.3502, r 0.2955, f1: 0.2901	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4861
test	acc: 0.6069	macro: p 0.3947, r 0.3088, f1: 0.3153	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5524
global_step: 25041, epoch: 27, loss: 0.892977
global_step: 25042, epoch: 27, loss: 1.043340
global_step: 25043, epoch: 27, loss: 0.903771
global_step: 25044, epoch: 27, loss: 1.014912
global_step: 25045, epoch: 27, loss: 1.068940
global_step: 25046, epoch: 27, loss: 0.939094
global_step: 25047, epoch: 27, loss: 0.883630
global_step: 25048, epoch: 27, loss: 1.082723
global_step: 25049, epoch: 27, loss: 0.975258
global_step: 25050, epoch: 27, loss: 0.950430
global_step: 25051, epoch: 27, loss: 0.890220
global_step: 25052, epoch: 27, loss: 0.956377
global_step: 25053, epoch: 27, loss: 0.968431
global_step: 25054, epoch: 27, loss: 1.044705
global_step: 25055, epoch: 27, loss: 0.899367
global_step: 25056, epoch: 27, loss: 1.084183
global_step: 25057, epoch: 27, loss: 0.931939
global_step: 25058, epoch: 27, loss: 0.861577
global_step: 25059, epoch: 27, loss: 1.033692
global_step: 25060, epoch: 27, loss: 0.914496
global_step: 25061, epoch: 27, loss: 1.023998
global_step: 25062, epoch: 27, loss: 0.948760
global_step: 25063, epoch: 27, loss: 0.965591
global_step: 25064, epoch: 27, loss: 1.032124
global_step: 25065, epoch: 27, loss: 1.135750
global_step: 25066, epoch: 27, loss: 0.831083
global_step: 25067, epoch: 27, loss: 1.005503
global_step: 25068, epoch: 27, loss: 0.972727
global_step: 25069, epoch: 27, loss: 0.824212
global_step: 25070, epoch: 27, loss: 0.947575
global_step: 25071, epoch: 27, loss: 0.974872
global_step: 25072, epoch: 27, loss: 0.973390
global_step: 25073, epoch: 27, loss: 1.041687
global_step: 25074, epoch: 27, loss: 1.007776
global_step: 25075, epoch: 27, loss: 0.978733
global_step: 25076, epoch: 27, loss: 1.057211
global_step: 25077, epoch: 27, loss: 1.053231
global_step: 25078, epoch: 27, loss: 0.897145
global_step: 25079, epoch: 27, loss: 1.000737
global_step: 25080, epoch: 27, loss: 0.497136
epoch: 27
train	acc: 0.7292	macro: p 0.5105, r 0.4552, f1: 0.4696	micro: p 0.7292, r 0.7292, f1 0.7292	weighted_f1:0.6962
dev	acc: 0.5573	macro: p 0.3401, r 0.3076, f1: 0.3002	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4980
test	acc: 0.6069	macro: p 0.3727, r 0.3221, f1: 0.3252	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5595
global_step: 25081, epoch: 28, loss: 0.918841
global_step: 25082, epoch: 28, loss: 0.848719
global_step: 25083, epoch: 28, loss: 0.903737
global_step: 25084, epoch: 28, loss: 0.926155
global_step: 25085, epoch: 28, loss: 0.980087
global_step: 25086, epoch: 28, loss: 1.049235
global_step: 25087, epoch: 28, loss: 0.911372
global_step: 25088, epoch: 28, loss: 0.926402
global_step: 25089, epoch: 28, loss: 0.848547
global_step: 25090, epoch: 28, loss: 0.941867
global_step: 25091, epoch: 28, loss: 1.005251
global_step: 25092, epoch: 28, loss: 0.980530
global_step: 25093, epoch: 28, loss: 0.992468
global_step: 25094, epoch: 28, loss: 0.913949
global_step: 25095, epoch: 28, loss: 1.004919
global_step: 25096, epoch: 28, loss: 0.930927
global_step: 25097, epoch: 28, loss: 0.991905
global_step: 25098, epoch: 28, loss: 0.897789
global_step: 25099, epoch: 28, loss: 0.929562
global_step: 25100, epoch: 28, loss: 0.931947
global_step: 25101, epoch: 28, loss: 0.969116
global_step: 25102, epoch: 28, loss: 1.019693
global_step: 25103, epoch: 28, loss: 1.001622
global_step: 25104, epoch: 28, loss: 0.991138
global_step: 25105, epoch: 28, loss: 0.965527
global_step: 25106, epoch: 28, loss: 0.953988
global_step: 25107, epoch: 28, loss: 0.949826
global_step: 25108, epoch: 28, loss: 1.084999
global_step: 25109, epoch: 28, loss: 0.987227
global_step: 25110, epoch: 28, loss: 0.928053
global_step: 25111, epoch: 28, loss: 1.096439
global_step: 25112, epoch: 28, loss: 1.000503
global_step: 25113, epoch: 28, loss: 0.933941
global_step: 25114, epoch: 28, loss: 0.942119
global_step: 25115, epoch: 28, loss: 0.960879
global_step: 25116, epoch: 28, loss: 1.051924
global_step: 25117, epoch: 28, loss: 1.062035
global_step: 25118, epoch: 28, loss: 0.836045
global_step: 25119, epoch: 28, loss: 0.936012
global_step: 25120, epoch: 28, loss: 0.296028
epoch: 28
train	acc: 0.7163	macro: p 0.5133, r 0.4329, f1: 0.4509	micro: p 0.7163, r 0.7163, f1 0.7163	weighted_f1:0.6799
dev	acc: 0.5537	macro: p 0.3501, r 0.3011, f1: 0.2953	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4921
test	acc: 0.6019	macro: p 0.3799, r 0.3076, f1: 0.3117	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5484
global_step: 25121, epoch: 29, loss: 0.880934
global_step: 25122, epoch: 29, loss: 0.840830
global_step: 25123, epoch: 29, loss: 0.842806
global_step: 25124, epoch: 29, loss: 0.808004
global_step: 25125, epoch: 29, loss: 1.064505
global_step: 25126, epoch: 29, loss: 1.063576
global_step: 25127, epoch: 29, loss: 1.014392
global_step: 25128, epoch: 29, loss: 0.912049
global_step: 25129, epoch: 29, loss: 0.906314
global_step: 25130, epoch: 29, loss: 0.902812
global_step: 25131, epoch: 29, loss: 0.856616
global_step: 25132, epoch: 29, loss: 1.026690
global_step: 25133, epoch: 29, loss: 1.105737
global_step: 25134, epoch: 29, loss: 0.936376
global_step: 25135, epoch: 29, loss: 0.894524
global_step: 25136, epoch: 29, loss: 0.982795
global_step: 25137, epoch: 29, loss: 0.939956
global_step: 25138, epoch: 29, loss: 0.883465
global_step: 25139, epoch: 29, loss: 0.933704
global_step: 25140, epoch: 29, loss: 0.956967
global_step: 25141, epoch: 29, loss: 0.947122
global_step: 25142, epoch: 29, loss: 0.884352
global_step: 25143, epoch: 29, loss: 1.053144
global_step: 25144, epoch: 29, loss: 0.961621
global_step: 25145, epoch: 29, loss: 0.968622
global_step: 25146, epoch: 29, loss: 1.019668
global_step: 25147, epoch: 29, loss: 0.973344
global_step: 25148, epoch: 29, loss: 0.945585
global_step: 25149, epoch: 29, loss: 0.912952
global_step: 25150, epoch: 29, loss: 1.044191
global_step: 25151, epoch: 29, loss: 0.902634
global_step: 25152, epoch: 29, loss: 0.980687
global_step: 25153, epoch: 29, loss: 1.055564
global_step: 25154, epoch: 29, loss: 0.993083
global_step: 25155, epoch: 29, loss: 0.963081
global_step: 25156, epoch: 29, loss: 1.013205
global_step: 25157, epoch: 29, loss: 0.931954
global_step: 25158, epoch: 29, loss: 0.917666
global_step: 25159, epoch: 29, loss: 1.058949
global_step: 25160, epoch: 29, loss: 0.773998
epoch: 29
train	acc: 0.7437	macro: p 0.6691, r 0.4674, f1: 0.4799	micro: p 0.7437, r 0.7437, f1 0.7437	weighted_f1:0.7118
dev	acc: 0.5473	macro: p 0.3483, r 0.3008, f1: 0.2893	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4864
test	acc: 0.6000	macro: p 0.3828, r 0.3166, f1: 0.3162	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5520
global_step: 25161, epoch: 30, loss: 0.920241
global_step: 25162, epoch: 30, loss: 0.952722
global_step: 25163, epoch: 30, loss: 0.922853
global_step: 25164, epoch: 30, loss: 0.944613
global_step: 25165, epoch: 30, loss: 0.949781
global_step: 25166, epoch: 30, loss: 0.939762
global_step: 25167, epoch: 30, loss: 0.963135
global_step: 25168, epoch: 30, loss: 0.968142
global_step: 25169, epoch: 30, loss: 1.027588
global_step: 25170, epoch: 30, loss: 0.889973
global_step: 25171, epoch: 30, loss: 0.849916
global_step: 25172, epoch: 30, loss: 0.912705
global_step: 25173, epoch: 30, loss: 0.945789
global_step: 25174, epoch: 30, loss: 0.974617
global_step: 25175, epoch: 30, loss: 1.035359
global_step: 25176, epoch: 30, loss: 0.969072
global_step: 25177, epoch: 30, loss: 1.009799
global_step: 25178, epoch: 30, loss: 0.879642
global_step: 25179, epoch: 30, loss: 0.967446
global_step: 25180, epoch: 30, loss: 0.807642
global_step: 25181, epoch: 30, loss: 0.970037
global_step: 25182, epoch: 30, loss: 0.975096
global_step: 25183, epoch: 30, loss: 0.896463
global_step: 25184, epoch: 30, loss: 0.791316
global_step: 25185, epoch: 30, loss: 0.833701
global_step: 25186, epoch: 30, loss: 0.927400
global_step: 25187, epoch: 30, loss: 0.922824
global_step: 25188, epoch: 30, loss: 0.909249
global_step: 25189, epoch: 30, loss: 0.917490
global_step: 25190, epoch: 30, loss: 0.893163
global_step: 25191, epoch: 30, loss: 0.946442
global_step: 25192, epoch: 30, loss: 0.891543
global_step: 25193, epoch: 30, loss: 0.894684
global_step: 25194, epoch: 30, loss: 0.840912
global_step: 25195, epoch: 30, loss: 0.924434
global_step: 25196, epoch: 30, loss: 1.048046
global_step: 25197, epoch: 30, loss: 0.874392
global_step: 25198, epoch: 30, loss: 0.899390
global_step: 25199, epoch: 30, loss: 0.956759
global_step: 25200, epoch: 30, loss: 1.173250
epoch: 30
train	acc: 0.7685	macro: p 0.5209, r 0.5163, f1: 0.5159	micro: p 0.7685, r 0.7685, f1 0.7685	weighted_f1:0.7417
dev	acc: 0.5437	macro: p 0.3214, r 0.3087, f1: 0.3001	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4916
test	acc: 0.5973	macro: p 0.3443, r 0.3272, f1: 0.3255	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5570
global_step: 25201, epoch: 31, loss: 0.814910
global_step: 25202, epoch: 31, loss: 0.854292
global_step: 25203, epoch: 31, loss: 0.934888
global_step: 25204, epoch: 31, loss: 0.836284
global_step: 25205, epoch: 31, loss: 0.934955
global_step: 25206, epoch: 31, loss: 0.862744
global_step: 25207, epoch: 31, loss: 0.945966
global_step: 25208, epoch: 31, loss: 1.004724
global_step: 25209, epoch: 31, loss: 0.862361
global_step: 25210, epoch: 31, loss: 0.904533
global_step: 25211, epoch: 31, loss: 0.883374
global_step: 25212, epoch: 31, loss: 0.876513
global_step: 25213, epoch: 31, loss: 0.920818
global_step: 25214, epoch: 31, loss: 0.887468
global_step: 25215, epoch: 31, loss: 1.012723
global_step: 25216, epoch: 31, loss: 0.923145
global_step: 25217, epoch: 31, loss: 0.933308
global_step: 25218, epoch: 31, loss: 0.925699
global_step: 25219, epoch: 31, loss: 0.829112
global_step: 25220, epoch: 31, loss: 0.902768
global_step: 25221, epoch: 31, loss: 0.886795
global_step: 25222, epoch: 31, loss: 1.022260
global_step: 25223, epoch: 31, loss: 0.867040
global_step: 25224, epoch: 31, loss: 0.937310
global_step: 25225, epoch: 31, loss: 0.935041
global_step: 25226, epoch: 31, loss: 0.999586
global_step: 25227, epoch: 31, loss: 0.923066
global_step: 25228, epoch: 31, loss: 0.999464
global_step: 25229, epoch: 31, loss: 0.973881
global_step: 25230, epoch: 31, loss: 0.907534
global_step: 25231, epoch: 31, loss: 0.950308
global_step: 25232, epoch: 31, loss: 0.868975
global_step: 25233, epoch: 31, loss: 0.951881
global_step: 25234, epoch: 31, loss: 0.924966
global_step: 25235, epoch: 31, loss: 0.904333
global_step: 25236, epoch: 31, loss: 0.895313
global_step: 25237, epoch: 31, loss: 0.897617
global_step: 25238, epoch: 31, loss: 0.845689
global_step: 25239, epoch: 31, loss: 0.911175
global_step: 25240, epoch: 31, loss: 1.283147
epoch: 31
train	acc: 0.7729	macro: p 0.8169, r 0.5199, f1: 0.5223	micro: p 0.7729, r 0.7729, f1 0.7729	weighted_f1:0.7487
dev	acc: 0.5455	macro: p 0.3261, r 0.3088, f1: 0.3011	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4953
test	acc: 0.5923	macro: p 0.3446, r 0.3229, f1: 0.3224	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5548
global_step: 25241, epoch: 32, loss: 0.903310
global_step: 25242, epoch: 32, loss: 0.928456
global_step: 25243, epoch: 32, loss: 0.881519
global_step: 25244, epoch: 32, loss: 0.879955
global_step: 25245, epoch: 32, loss: 0.924871
global_step: 25246, epoch: 32, loss: 0.940591
global_step: 25247, epoch: 32, loss: 0.768954
global_step: 25248, epoch: 32, loss: 0.899626
global_step: 25249, epoch: 32, loss: 0.992446
global_step: 25250, epoch: 32, loss: 0.919742
global_step: 25251, epoch: 32, loss: 0.919470
global_step: 25252, epoch: 32, loss: 0.875315
global_step: 25253, epoch: 32, loss: 0.914119
global_step: 25254, epoch: 32, loss: 0.898962
global_step: 25255, epoch: 32, loss: 0.904757
global_step: 25256, epoch: 32, loss: 0.904986
global_step: 25257, epoch: 32, loss: 0.977715
global_step: 25258, epoch: 32, loss: 0.910028
global_step: 25259, epoch: 32, loss: 0.851952
global_step: 25260, epoch: 32, loss: 0.825758
global_step: 25261, epoch: 32, loss: 0.833020
global_step: 25262, epoch: 32, loss: 0.830556
global_step: 25263, epoch: 32, loss: 0.959497
global_step: 25264, epoch: 32, loss: 0.973344
global_step: 25265, epoch: 32, loss: 0.937378
global_step: 25266, epoch: 32, loss: 0.917233
global_step: 25267, epoch: 32, loss: 0.890317
global_step: 25268, epoch: 32, loss: 0.835442
global_step: 25269, epoch: 32, loss: 0.873962
global_step: 25270, epoch: 32, loss: 0.923915
global_step: 25271, epoch: 32, loss: 0.903222
global_step: 25272, epoch: 32, loss: 0.830613
global_step: 25273, epoch: 32, loss: 0.920865
global_step: 25274, epoch: 32, loss: 1.033662
global_step: 25275, epoch: 32, loss: 0.768562
global_step: 25276, epoch: 32, loss: 0.906006
global_step: 25277, epoch: 32, loss: 0.855483
global_step: 25278, epoch: 32, loss: 0.929517
global_step: 25279, epoch: 32, loss: 0.872868
global_step: 25280, epoch: 32, loss: 1.741127
epoch: 32
train	acc: 0.7962	macro: p 0.8185, r 0.5562, f1: 0.5459	micro: p 0.7962, r 0.7962, f1 0.7962	weighted_f1:0.7740
dev	acc: 0.5401	macro: p 0.3206, r 0.3173, f1: 0.3103	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4999
test	acc: 0.5897	macro: p 0.3415, r 0.3346, f1: 0.3329	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5598
New best model!
global_step: 25281, epoch: 33, loss: 0.852907
global_step: 25282, epoch: 33, loss: 0.978743
global_step: 25283, epoch: 33, loss: 0.844573
global_step: 25284, epoch: 33, loss: 0.846363
global_step: 25285, epoch: 33, loss: 0.917128
global_step: 25286, epoch: 33, loss: 0.748054
global_step: 25287, epoch: 33, loss: 0.985004
global_step: 25288, epoch: 33, loss: 0.878924
global_step: 25289, epoch: 33, loss: 0.848102
global_step: 25290, epoch: 33, loss: 0.843419
global_step: 25291, epoch: 33, loss: 0.948986
global_step: 25292, epoch: 33, loss: 0.818440
global_step: 25293, epoch: 33, loss: 0.813540
global_step: 25294, epoch: 33, loss: 0.858474
global_step: 25295, epoch: 33, loss: 0.797722
global_step: 25296, epoch: 33, loss: 0.895293
global_step: 25297, epoch: 33, loss: 0.940654
global_step: 25298, epoch: 33, loss: 0.943160
global_step: 25299, epoch: 33, loss: 0.886613
global_step: 25300, epoch: 33, loss: 0.848180
global_step: 25301, epoch: 33, loss: 0.901801
global_step: 25302, epoch: 33, loss: 0.936097
global_step: 25303, epoch: 33, loss: 0.999440
global_step: 25304, epoch: 33, loss: 0.884066
global_step: 25305, epoch: 33, loss: 0.930862
global_step: 25306, epoch: 33, loss: 0.818502
global_step: 25307, epoch: 33, loss: 0.802447
global_step: 25308, epoch: 33, loss: 0.962800
global_step: 25309, epoch: 33, loss: 0.939470
global_step: 25310, epoch: 33, loss: 0.777750
global_step: 25311, epoch: 33, loss: 0.961719
global_step: 25312, epoch: 33, loss: 0.911540
global_step: 25313, epoch: 33, loss: 0.911044
global_step: 25314, epoch: 33, loss: 0.797901
global_step: 25315, epoch: 33, loss: 0.826020
global_step: 25316, epoch: 33, loss: 0.929652
global_step: 25317, epoch: 33, loss: 0.775683
global_step: 25318, epoch: 33, loss: 0.890323
global_step: 25319, epoch: 33, loss: 0.881470
global_step: 25320, epoch: 33, loss: 0.488551
epoch: 33
train	acc: 0.7885	macro: p 0.6857, r 0.5347, f1: 0.5362	micro: p 0.7885, r 0.7885, f1 0.7885	weighted_f1:0.7628
dev	acc: 0.5419	macro: p 0.3217, r 0.3064, f1: 0.2974	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4896
test	acc: 0.5981	macro: p 0.3524, r 0.3286, f1: 0.3276	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5588
global_step: 25321, epoch: 34, loss: 0.840033
global_step: 25322, epoch: 34, loss: 0.893244
global_step: 25323, epoch: 34, loss: 0.811338
global_step: 25324, epoch: 34, loss: 0.982687
global_step: 25325, epoch: 34, loss: 0.894193
global_step: 25326, epoch: 34, loss: 0.875741
global_step: 25327, epoch: 34, loss: 0.796186
global_step: 25328, epoch: 34, loss: 0.931915
global_step: 25329, epoch: 34, loss: 0.806783
global_step: 25330, epoch: 34, loss: 0.961922
global_step: 25331, epoch: 34, loss: 0.870258
global_step: 25332, epoch: 34, loss: 0.852031
global_step: 25333, epoch: 34, loss: 0.929069
global_step: 25334, epoch: 34, loss: 0.965766
global_step: 25335, epoch: 34, loss: 0.882261
global_step: 25336, epoch: 34, loss: 0.805783
global_step: 25337, epoch: 34, loss: 0.950306
global_step: 25338, epoch: 34, loss: 0.883961
global_step: 25339, epoch: 34, loss: 0.863867
global_step: 25340, epoch: 34, loss: 0.789946
global_step: 25341, epoch: 34, loss: 0.841901
global_step: 25342, epoch: 34, loss: 0.840546
global_step: 25343, epoch: 34, loss: 0.840618
global_step: 25344, epoch: 34, loss: 0.903664
global_step: 25345, epoch: 34, loss: 0.912045
global_step: 25346, epoch: 34, loss: 0.911185
global_step: 25347, epoch: 34, loss: 0.878000
global_step: 25348, epoch: 34, loss: 0.846561
global_step: 25349, epoch: 34, loss: 0.884547
global_step: 25350, epoch: 34, loss: 0.868309
global_step: 25351, epoch: 34, loss: 0.895482
global_step: 25352, epoch: 34, loss: 0.859139
global_step: 25353, epoch: 34, loss: 0.857642
global_step: 25354, epoch: 34, loss: 0.778303
global_step: 25355, epoch: 34, loss: 0.865490
global_step: 25356, epoch: 34, loss: 0.909446
global_step: 25357, epoch: 34, loss: 0.849323
global_step: 25358, epoch: 34, loss: 0.874231
global_step: 25359, epoch: 34, loss: 0.994371
global_step: 25360, epoch: 34, loss: 0.399696
epoch: 34
train	acc: 0.7641	macro: p 0.8364, r 0.4969, f1: 0.5191	micro: p 0.7641, r 0.7641, f1 0.7641	weighted_f1:0.7357
dev	acc: 0.5482	macro: p 0.3360, r 0.2959, f1: 0.2895	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4858
test	acc: 0.6073	macro: p 0.5275, r 0.3155, f1: 0.3238	micro: p 0.6073, r 0.6073, f1 0.6073	weighted_f1:0.5559
global_step: 25361, epoch: 35, loss: 0.835886
global_step: 25362, epoch: 35, loss: 0.773906
global_step: 25363, epoch: 35, loss: 0.774490
global_step: 25364, epoch: 35, loss: 0.831345
global_step: 25365, epoch: 35, loss: 0.799241
global_step: 25366, epoch: 35, loss: 0.814859
global_step: 25367, epoch: 35, loss: 0.876608
global_step: 25368, epoch: 35, loss: 0.988997
global_step: 25369, epoch: 35, loss: 0.869338
global_step: 25370, epoch: 35, loss: 0.837780
global_step: 25371, epoch: 35, loss: 0.840776
global_step: 25372, epoch: 35, loss: 0.877356
global_step: 25373, epoch: 35, loss: 0.883478
global_step: 25374, epoch: 35, loss: 0.783115
global_step: 25375, epoch: 35, loss: 0.893819
global_step: 25376, epoch: 35, loss: 0.866773
global_step: 25377, epoch: 35, loss: 0.935814
global_step: 25378, epoch: 35, loss: 0.894605
global_step: 25379, epoch: 35, loss: 0.800456
global_step: 25380, epoch: 35, loss: 0.777117
global_step: 25381, epoch: 35, loss: 0.857401
global_step: 25382, epoch: 35, loss: 0.869309
global_step: 25383, epoch: 35, loss: 0.822649
global_step: 25384, epoch: 35, loss: 0.878775
global_step: 25385, epoch: 35, loss: 0.780248
global_step: 25386, epoch: 35, loss: 0.892849
global_step: 25387, epoch: 35, loss: 0.911840
global_step: 25388, epoch: 35, loss: 0.842986
global_step: 25389, epoch: 35, loss: 0.868964
global_step: 25390, epoch: 35, loss: 0.693475
global_step: 25391, epoch: 35, loss: 0.898494
global_step: 25392, epoch: 35, loss: 0.896913
global_step: 25393, epoch: 35, loss: 0.951924
global_step: 25394, epoch: 35, loss: 0.937450
global_step: 25395, epoch: 35, loss: 0.855959
global_step: 25396, epoch: 35, loss: 0.892335
global_step: 25397, epoch: 35, loss: 0.878693
global_step: 25398, epoch: 35, loss: 0.780415
global_step: 25399, epoch: 35, loss: 0.865295
global_step: 25400, epoch: 35, loss: 0.884169
epoch: 35
train	acc: 0.8060	macro: p 0.6977, r 0.5496, f1: 0.5485	micro: p 0.8060, r 0.8060, f1 0.8060	weighted_f1:0.7803
dev	acc: 0.5338	macro: p 0.3167, r 0.3036, f1: 0.2872	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4807
test	acc: 0.5812	macro: p 0.3382, r 0.3189, f1: 0.3107	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5414
global_step: 25401, epoch: 36, loss: 0.685235
global_step: 25402, epoch: 36, loss: 0.838011
global_step: 25403, epoch: 36, loss: 0.858901
global_step: 25404, epoch: 36, loss: 0.858597
global_step: 25405, epoch: 36, loss: 0.791630
global_step: 25406, epoch: 36, loss: 0.886618
global_step: 25407, epoch: 36, loss: 0.961111
global_step: 25408, epoch: 36, loss: 0.785180
global_step: 25409, epoch: 36, loss: 0.832894
global_step: 25410, epoch: 36, loss: 0.774415
global_step: 25411, epoch: 36, loss: 0.879415
global_step: 25412, epoch: 36, loss: 0.905013
global_step: 25413, epoch: 36, loss: 0.902347
global_step: 25414, epoch: 36, loss: 0.908329
global_step: 25415, epoch: 36, loss: 0.856523
global_step: 25416, epoch: 36, loss: 0.831828
global_step: 25417, epoch: 36, loss: 0.900927
global_step: 25418, epoch: 36, loss: 0.825398
global_step: 25419, epoch: 36, loss: 0.854330
global_step: 25420, epoch: 36, loss: 0.764134
global_step: 25421, epoch: 36, loss: 0.773624
global_step: 25422, epoch: 36, loss: 0.756363
global_step: 25423, epoch: 36, loss: 0.727569
global_step: 25424, epoch: 36, loss: 0.834095
global_step: 25425, epoch: 36, loss: 0.884735
global_step: 25426, epoch: 36, loss: 0.836722
global_step: 25427, epoch: 36, loss: 0.799419
global_step: 25428, epoch: 36, loss: 0.879741
global_step: 25429, epoch: 36, loss: 0.773671
global_step: 25430, epoch: 36, loss: 0.852616
global_step: 25431, epoch: 36, loss: 0.916037
global_step: 25432, epoch: 36, loss: 0.890426
global_step: 25433, epoch: 36, loss: 0.836409
global_step: 25434, epoch: 36, loss: 0.848760
global_step: 25435, epoch: 36, loss: 0.948501
global_step: 25436, epoch: 36, loss: 0.912860
global_step: 25437, epoch: 36, loss: 0.930471
global_step: 25438, epoch: 36, loss: 0.812840
global_step: 25439, epoch: 36, loss: 0.849376
global_step: 25440, epoch: 36, loss: 2.947218
epoch: 36
train	acc: 0.8104	macro: p 0.8476, r 0.5634, f1: 0.5753	micro: p 0.8104, r 0.8104, f1 0.8104	weighted_f1:0.7875
dev	acc: 0.5509	macro: p 0.3361, r 0.3056, f1: 0.2991	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4943
test	acc: 0.5966	macro: p 0.4947, r 0.3193, f1: 0.3222	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5525
global_step: 25441, epoch: 37, loss: 0.760233
global_step: 25442, epoch: 37, loss: 0.730064
global_step: 25443, epoch: 37, loss: 0.813825
global_step: 25444, epoch: 37, loss: 0.880511
global_step: 25445, epoch: 37, loss: 0.769381
global_step: 25446, epoch: 37, loss: 0.797810
global_step: 25447, epoch: 37, loss: 0.907751
global_step: 25448, epoch: 37, loss: 0.845410
global_step: 25449, epoch: 37, loss: 0.749002
global_step: 25450, epoch: 37, loss: 0.888957
global_step: 25451, epoch: 37, loss: 0.895319
global_step: 25452, epoch: 37, loss: 0.802509
global_step: 25453, epoch: 37, loss: 0.853706
global_step: 25454, epoch: 37, loss: 0.828246
global_step: 25455, epoch: 37, loss: 0.791459
global_step: 25456, epoch: 37, loss: 0.765563
global_step: 25457, epoch: 37, loss: 0.932101
global_step: 25458, epoch: 37, loss: 0.860424
global_step: 25459, epoch: 37, loss: 0.841679
global_step: 25460, epoch: 37, loss: 0.776667
global_step: 25461, epoch: 37, loss: 0.826877
global_step: 25462, epoch: 37, loss: 0.756024
global_step: 25463, epoch: 37, loss: 0.871995
global_step: 25464, epoch: 37, loss: 0.695080
global_step: 25465, epoch: 37, loss: 0.845378
global_step: 25466, epoch: 37, loss: 0.949868
global_step: 25467, epoch: 37, loss: 0.827222
global_step: 25468, epoch: 37, loss: 0.877765
global_step: 25469, epoch: 37, loss: 0.894665
global_step: 25470, epoch: 37, loss: 0.769381
global_step: 25471, epoch: 37, loss: 0.738233
global_step: 25472, epoch: 37, loss: 0.844262
global_step: 25473, epoch: 37, loss: 0.812604
global_step: 25474, epoch: 37, loss: 0.832165
global_step: 25475, epoch: 37, loss: 0.802252
global_step: 25476, epoch: 37, loss: 0.841479
global_step: 25477, epoch: 37, loss: 0.879351
global_step: 25478, epoch: 37, loss: 0.772699
global_step: 25479, epoch: 37, loss: 0.918137
global_step: 25480, epoch: 37, loss: 1.760085
epoch: 37
train	acc: 0.8148	macro: p 0.8492, r 0.5706, f1: 0.5826	micro: p 0.8148, r 0.8148, f1 0.8148	weighted_f1:0.7925
dev	acc: 0.5401	macro: p 0.3231, r 0.2989, f1: 0.2925	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4849
test	acc: 0.5969	macro: p 0.4990, r 0.3198, f1: 0.3260	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5535
global_step: 25481, epoch: 38, loss: 0.800536
global_step: 25482, epoch: 38, loss: 0.779471
global_step: 25483, epoch: 38, loss: 0.821251
global_step: 25484, epoch: 38, loss: 0.820600
global_step: 25485, epoch: 38, loss: 0.762494
global_step: 25486, epoch: 38, loss: 0.776171
global_step: 25487, epoch: 38, loss: 0.882970
global_step: 25488, epoch: 38, loss: 0.709975
global_step: 25489, epoch: 38, loss: 0.797210
global_step: 25490, epoch: 38, loss: 0.864141
global_step: 25491, epoch: 38, loss: 0.895697
global_step: 25492, epoch: 38, loss: 0.835462
global_step: 25493, epoch: 38, loss: 0.782806
global_step: 25494, epoch: 38, loss: 0.706121
global_step: 25495, epoch: 38, loss: 0.778305
global_step: 25496, epoch: 38, loss: 0.784687
global_step: 25497, epoch: 38, loss: 0.743248
global_step: 25498, epoch: 38, loss: 0.872192
global_step: 25499, epoch: 38, loss: 0.902604
global_step: 25500, epoch: 38, loss: 0.769197
global_step: 25501, epoch: 38, loss: 0.804025
global_step: 25502, epoch: 38, loss: 0.732672
global_step: 25503, epoch: 38, loss: 0.854936
global_step: 25504, epoch: 38, loss: 0.884653
global_step: 25505, epoch: 38, loss: 0.837957
global_step: 25506, epoch: 38, loss: 0.844771
global_step: 25507, epoch: 38, loss: 0.862585
global_step: 25508, epoch: 38, loss: 0.854143
global_step: 25509, epoch: 38, loss: 0.826207
global_step: 25510, epoch: 38, loss: 0.847723
global_step: 25511, epoch: 38, loss: 0.830039
global_step: 25512, epoch: 38, loss: 0.826455
global_step: 25513, epoch: 38, loss: 0.852248
global_step: 25514, epoch: 38, loss: 0.868564
global_step: 25515, epoch: 38, loss: 0.794231
global_step: 25516, epoch: 38, loss: 0.830237
global_step: 25517, epoch: 38, loss: 0.844078
global_step: 25518, epoch: 38, loss: 0.809080
global_step: 25519, epoch: 38, loss: 0.743388
global_step: 25520, epoch: 38, loss: 0.662519
epoch: 38
train	acc: 0.8200	macro: p 0.8538, r 0.5741, f1: 0.5826	micro: p 0.8200, r 0.8200, f1 0.8200	weighted_f1:0.7973
dev	acc: 0.5392	macro: p 0.3271, r 0.3038, f1: 0.2901	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4838
test	acc: 0.5866	macro: p 0.4978, r 0.3190, f1: 0.3185	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5453
global_step: 25521, epoch: 39, loss: 0.777319
global_step: 25522, epoch: 39, loss: 0.792735
global_step: 25523, epoch: 39, loss: 0.773606
global_step: 25524, epoch: 39, loss: 0.826095
global_step: 25525, epoch: 39, loss: 0.821675
global_step: 25526, epoch: 39, loss: 0.840649
global_step: 25527, epoch: 39, loss: 0.872658
global_step: 25528, epoch: 39, loss: 0.679953
global_step: 25529, epoch: 39, loss: 0.789360
global_step: 25530, epoch: 39, loss: 0.681743
global_step: 25531, epoch: 39, loss: 0.847111
global_step: 25532, epoch: 39, loss: 0.751817
global_step: 25533, epoch: 39, loss: 0.744834
global_step: 25534, epoch: 39, loss: 0.883940
global_step: 25535, epoch: 39, loss: 0.837239
global_step: 25536, epoch: 39, loss: 0.799565
global_step: 25537, epoch: 39, loss: 0.767684
global_step: 25538, epoch: 39, loss: 0.849541
global_step: 25539, epoch: 39, loss: 0.811998
global_step: 25540, epoch: 39, loss: 0.823283
global_step: 25541, epoch: 39, loss: 0.904482
global_step: 25542, epoch: 39, loss: 0.764379
global_step: 25543, epoch: 39, loss: 0.798939
global_step: 25544, epoch: 39, loss: 0.794987
global_step: 25545, epoch: 39, loss: 0.794988
global_step: 25546, epoch: 39, loss: 0.769717
global_step: 25547, epoch: 39, loss: 0.897810
global_step: 25548, epoch: 39, loss: 0.752808
global_step: 25549, epoch: 39, loss: 0.714760
global_step: 25550, epoch: 39, loss: 0.673885
global_step: 25551, epoch: 39, loss: 0.842466
global_step: 25552, epoch: 39, loss: 0.777613
global_step: 25553, epoch: 39, loss: 0.818499
global_step: 25554, epoch: 39, loss: 0.725223
global_step: 25555, epoch: 39, loss: 0.832285
global_step: 25556, epoch: 39, loss: 0.768076
global_step: 25557, epoch: 39, loss: 0.717624
global_step: 25558, epoch: 39, loss: 0.863016
global_step: 25559, epoch: 39, loss: 0.892444
global_step: 25560, epoch: 39, loss: 1.071604
epoch: 39
train	acc: 0.8322	macro: p 0.8561, r 0.5965, f1: 0.6021	micro: p 0.8322, r 0.8322, f1 0.8322	weighted_f1:0.8113
dev	acc: 0.5446	macro: p 0.3282, r 0.3075, f1: 0.3016	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4938
test	acc: 0.5985	macro: p 0.3533, r 0.3259, f1: 0.3280	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5593
global_step: 25561, epoch: 40, loss: 0.824597
global_step: 25562, epoch: 40, loss: 0.790508
global_step: 25563, epoch: 40, loss: 0.743671
global_step: 25564, epoch: 40, loss: 0.745367
global_step: 25565, epoch: 40, loss: 0.871551
global_step: 25566, epoch: 40, loss: 0.844378
global_step: 25567, epoch: 40, loss: 0.811502
global_step: 25568, epoch: 40, loss: 0.782984
global_step: 25569, epoch: 40, loss: 0.746574
global_step: 25570, epoch: 40, loss: 0.732607
global_step: 25571, epoch: 40, loss: 0.772923
global_step: 25572, epoch: 40, loss: 0.781758
global_step: 25573, epoch: 40, loss: 0.739038
global_step: 25574, epoch: 40, loss: 0.861166
global_step: 25575, epoch: 40, loss: 0.733361
global_step: 25576, epoch: 40, loss: 0.754244
global_step: 25577, epoch: 40, loss: 0.805713
global_step: 25578, epoch: 40, loss: 0.756372
global_step: 25579, epoch: 40, loss: 0.836248
global_step: 25580, epoch: 40, loss: 0.785549
global_step: 25581, epoch: 40, loss: 0.895857
global_step: 25582, epoch: 40, loss: 0.767837
global_step: 25583, epoch: 40, loss: 0.889685
global_step: 25584, epoch: 40, loss: 0.770131
global_step: 25585, epoch: 40, loss: 0.839385
global_step: 25586, epoch: 40, loss: 0.748191
global_step: 25587, epoch: 40, loss: 0.805533
global_step: 25588, epoch: 40, loss: 0.704796
global_step: 25589, epoch: 40, loss: 0.777774
global_step: 25590, epoch: 40, loss: 0.802214
global_step: 25591, epoch: 40, loss: 0.768540
global_step: 25592, epoch: 40, loss: 0.769070
global_step: 25593, epoch: 40, loss: 0.812068
global_step: 25594, epoch: 40, loss: 0.780213
global_step: 25595, epoch: 40, loss: 0.764919
global_step: 25596, epoch: 40, loss: 0.842811
global_step: 25597, epoch: 40, loss: 0.782472
global_step: 25598, epoch: 40, loss: 0.772990
global_step: 25599, epoch: 40, loss: 0.914828
global_step: 25600, epoch: 40, loss: 0.778289
epoch: 40
train	acc: 0.8315	macro: p 0.8592, r 0.5922, f1: 0.5970	micro: p 0.8315, r 0.8315, f1 0.8315	weighted_f1:0.8096
dev	acc: 0.5419	macro: p 0.3255, r 0.3044, f1: 0.2985	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4903
test	acc: 0.5977	macro: p 0.3548, r 0.3234, f1: 0.3269	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5580
global_step: 25601, epoch: 41, loss: 0.790449
global_step: 25602, epoch: 41, loss: 0.835163
global_step: 25603, epoch: 41, loss: 0.783295
global_step: 25604, epoch: 41, loss: 0.822633
global_step: 25605, epoch: 41, loss: 0.806456
global_step: 25606, epoch: 41, loss: 0.777311
global_step: 25607, epoch: 41, loss: 0.790264
global_step: 25608, epoch: 41, loss: 0.837855
global_step: 25609, epoch: 41, loss: 0.803847
global_step: 25610, epoch: 41, loss: 0.661952
global_step: 25611, epoch: 41, loss: 0.796290
global_step: 25612, epoch: 41, loss: 0.753629
global_step: 25613, epoch: 41, loss: 0.746330
global_step: 25614, epoch: 41, loss: 0.874799
global_step: 25615, epoch: 41, loss: 0.793295
global_step: 25616, epoch: 41, loss: 0.807084
global_step: 25617, epoch: 41, loss: 0.673925
global_step: 25618, epoch: 41, loss: 0.785455
global_step: 25619, epoch: 41, loss: 0.780470
global_step: 25620, epoch: 41, loss: 0.736260
global_step: 25621, epoch: 41, loss: 0.810230
global_step: 25622, epoch: 41, loss: 0.779103
global_step: 25623, epoch: 41, loss: 0.761228
global_step: 25624, epoch: 41, loss: 0.769708
global_step: 25625, epoch: 41, loss: 0.777213
global_step: 25626, epoch: 41, loss: 0.715717
global_step: 25627, epoch: 41, loss: 0.755887
global_step: 25628, epoch: 41, loss: 0.805303
global_step: 25629, epoch: 41, loss: 0.736462
global_step: 25630, epoch: 41, loss: 0.896705
global_step: 25631, epoch: 41, loss: 0.763251
global_step: 25632, epoch: 41, loss: 0.757284
global_step: 25633, epoch: 41, loss: 0.772150
global_step: 25634, epoch: 41, loss: 0.755059
global_step: 25635, epoch: 41, loss: 0.791442
global_step: 25636, epoch: 41, loss: 0.672588
global_step: 25637, epoch: 41, loss: 0.793152
global_step: 25638, epoch: 41, loss: 0.716305
global_step: 25639, epoch: 41, loss: 0.765922
global_step: 25640, epoch: 41, loss: 0.998396
epoch: 41
train	acc: 0.8379	macro: p 0.8641, r 0.5948, f1: 0.5991	micro: p 0.8379, r 0.8379, f1 0.8379	weighted_f1:0.8163
dev	acc: 0.5410	macro: p 0.3251, r 0.3018, f1: 0.2943	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4882
test	acc: 0.5893	macro: p 0.3548, r 0.3176, f1: 0.3193	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5503
global_step: 25641, epoch: 42, loss: 0.679119
global_step: 25642, epoch: 42, loss: 0.751233
global_step: 25643, epoch: 42, loss: 0.716946
global_step: 25644, epoch: 42, loss: 0.725593
global_step: 25645, epoch: 42, loss: 0.751542
global_step: 25646, epoch: 42, loss: 0.690472
global_step: 25647, epoch: 42, loss: 0.728073
global_step: 25648, epoch: 42, loss: 0.814355
global_step: 25649, epoch: 42, loss: 0.748596
global_step: 25650, epoch: 42, loss: 0.744026
global_step: 25651, epoch: 42, loss: 0.792600
global_step: 25652, epoch: 42, loss: 0.699396
global_step: 25653, epoch: 42, loss: 0.809148
global_step: 25654, epoch: 42, loss: 0.728539
global_step: 25655, epoch: 42, loss: 0.845867
global_step: 25656, epoch: 42, loss: 0.758924
global_step: 25657, epoch: 42, loss: 0.674403
global_step: 25658, epoch: 42, loss: 0.810589
global_step: 25659, epoch: 42, loss: 0.768957
global_step: 25660, epoch: 42, loss: 0.673304
global_step: 25661, epoch: 42, loss: 0.802450
global_step: 25662, epoch: 42, loss: 0.673856
global_step: 25663, epoch: 42, loss: 0.773741
global_step: 25664, epoch: 42, loss: 0.836412
global_step: 25665, epoch: 42, loss: 0.675244
global_step: 25666, epoch: 42, loss: 0.818459
global_step: 25667, epoch: 42, loss: 0.786350
global_step: 25668, epoch: 42, loss: 0.776880
global_step: 25669, epoch: 42, loss: 0.732270
global_step: 25670, epoch: 42, loss: 0.731249
global_step: 25671, epoch: 42, loss: 0.778068
global_step: 25672, epoch: 42, loss: 0.762722
global_step: 25673, epoch: 42, loss: 0.667050
global_step: 25674, epoch: 42, loss: 0.865017
global_step: 25675, epoch: 42, loss: 0.787336
global_step: 25676, epoch: 42, loss: 0.738228
global_step: 25677, epoch: 42, loss: 0.770226
global_step: 25678, epoch: 42, loss: 0.817957
global_step: 25679, epoch: 42, loss: 0.915893
global_step: 25680, epoch: 42, loss: 0.500778
epoch: 42
train	acc: 0.8521	macro: p 0.8711, r 0.6228, f1: 0.6297	micro: p 0.8521, r 0.8521, f1 0.8521	weighted_f1:0.8329
dev	acc: 0.5464	macro: p 0.3300, r 0.3123, f1: 0.3045	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4962
test	acc: 0.5931	macro: p 0.3515, r 0.3260, f1: 0.3241	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5551
global_step: 25681, epoch: 43, loss: 0.757776
global_step: 25682, epoch: 43, loss: 0.824834
global_step: 25683, epoch: 43, loss: 0.843463
global_step: 25684, epoch: 43, loss: 0.726906
global_step: 25685, epoch: 43, loss: 0.728908
global_step: 25686, epoch: 43, loss: 0.742533
global_step: 25687, epoch: 43, loss: 0.794760
global_step: 25688, epoch: 43, loss: 0.771294
global_step: 25689, epoch: 43, loss: 0.756724
global_step: 25690, epoch: 43, loss: 0.683394
global_step: 25691, epoch: 43, loss: 0.719563
global_step: 25692, epoch: 43, loss: 0.689626
global_step: 25693, epoch: 43, loss: 0.827924
global_step: 25694, epoch: 43, loss: 0.676409
global_step: 25695, epoch: 43, loss: 0.809692
global_step: 25696, epoch: 43, loss: 0.726966
global_step: 25697, epoch: 43, loss: 0.762836
global_step: 25698, epoch: 43, loss: 0.770180
global_step: 25699, epoch: 43, loss: 0.732227
global_step: 25700, epoch: 43, loss: 0.743852
global_step: 25701, epoch: 43, loss: 0.704265
global_step: 25702, epoch: 43, loss: 0.845033
global_step: 25703, epoch: 43, loss: 0.688436
global_step: 25704, epoch: 43, loss: 0.738053
global_step: 25705, epoch: 43, loss: 0.817624
global_step: 25706, epoch: 43, loss: 0.770480
global_step: 25707, epoch: 43, loss: 0.710192
global_step: 25708, epoch: 43, loss: 0.765900
global_step: 25709, epoch: 43, loss: 0.845333
global_step: 25710, epoch: 43, loss: 0.733393
global_step: 25711, epoch: 43, loss: 0.831194
global_step: 25712, epoch: 43, loss: 0.843293
global_step: 25713, epoch: 43, loss: 0.806103
global_step: 25714, epoch: 43, loss: 0.763932
global_step: 25715, epoch: 43, loss: 0.861498
global_step: 25716, epoch: 43, loss: 0.701689
global_step: 25717, epoch: 43, loss: 0.771182
global_step: 25718, epoch: 43, loss: 0.658509
global_step: 25719, epoch: 43, loss: 0.648343
global_step: 25720, epoch: 43, loss: 0.863981
epoch: 43
train	acc: 0.8160	macro: p 0.8574, r 0.5647, f1: 0.5890	micro: p 0.8160, r 0.8160, f1 0.8160	weighted_f1:0.7918
dev	acc: 0.5455	macro: p 0.3336, r 0.2921, f1: 0.2834	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4791
test	acc: 0.5992	macro: p 0.3701, r 0.3056, f1: 0.3071	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5421
global_step: 25721, epoch: 44, loss: 0.700870
global_step: 25722, epoch: 44, loss: 0.654627
global_step: 25723, epoch: 44, loss: 0.701786
global_step: 25724, epoch: 44, loss: 0.787655
global_step: 25725, epoch: 44, loss: 0.726649
global_step: 25726, epoch: 44, loss: 0.798614
global_step: 25727, epoch: 44, loss: 0.823979
global_step: 25728, epoch: 44, loss: 0.797416
global_step: 25729, epoch: 44, loss: 0.734185
global_step: 25730, epoch: 44, loss: 0.813357
global_step: 25731, epoch: 44, loss: 0.667505
global_step: 25732, epoch: 44, loss: 0.763876
global_step: 25733, epoch: 44, loss: 0.649158
global_step: 25734, epoch: 44, loss: 0.834495
global_step: 25735, epoch: 44, loss: 0.642297
global_step: 25736, epoch: 44, loss: 0.780807
global_step: 25737, epoch: 44, loss: 0.660381
global_step: 25738, epoch: 44, loss: 0.728761
global_step: 25739, epoch: 44, loss: 0.709629
global_step: 25740, epoch: 44, loss: 0.750721
global_step: 25741, epoch: 44, loss: 0.727755
global_step: 25742, epoch: 44, loss: 0.666176
global_step: 25743, epoch: 44, loss: 0.736686
global_step: 25744, epoch: 44, loss: 0.751744
global_step: 25745, epoch: 44, loss: 0.733507
global_step: 25746, epoch: 44, loss: 0.696561
global_step: 25747, epoch: 44, loss: 0.767668
global_step: 25748, epoch: 44, loss: 0.696291
global_step: 25749, epoch: 44, loss: 0.723096
global_step: 25750, epoch: 44, loss: 0.666793
global_step: 25751, epoch: 44, loss: 0.856280
global_step: 25752, epoch: 44, loss: 0.628273
global_step: 25753, epoch: 44, loss: 0.769339
global_step: 25754, epoch: 44, loss: 0.766293
global_step: 25755, epoch: 44, loss: 0.754379
global_step: 25756, epoch: 44, loss: 0.783445
global_step: 25757, epoch: 44, loss: 0.696064
global_step: 25758, epoch: 44, loss: 0.652437
global_step: 25759, epoch: 44, loss: 0.768039
global_step: 25760, epoch: 44, loss: 0.185984
epoch: 44
train	acc: 0.8323	macro: p 0.8765, r 0.5870, f1: 0.6040	micro: p 0.8323, r 0.8323, f1 0.8323	weighted_f1:0.8099
dev	acc: 0.5437	macro: p 0.3268, r 0.2959, f1: 0.2868	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4831
test	acc: 0.6008	macro: p 0.5148, r 0.3150, f1: 0.3185	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5514
global_step: 25761, epoch: 45, loss: 0.731308
global_step: 25762, epoch: 45, loss: 0.744394
global_step: 25763, epoch: 45, loss: 0.724389
global_step: 25764, epoch: 45, loss: 0.648338
global_step: 25765, epoch: 45, loss: 0.716902
global_step: 25766, epoch: 45, loss: 0.802945
global_step: 25767, epoch: 45, loss: 0.761575
global_step: 25768, epoch: 45, loss: 0.737238
global_step: 25769, epoch: 45, loss: 0.748763
global_step: 25770, epoch: 45, loss: 0.749125
global_step: 25771, epoch: 45, loss: 0.650652
global_step: 25772, epoch: 45, loss: 0.701091
global_step: 25773, epoch: 45, loss: 0.728694
global_step: 25774, epoch: 45, loss: 0.770797
global_step: 25775, epoch: 45, loss: 0.891123
global_step: 25776, epoch: 45, loss: 0.681016
global_step: 25777, epoch: 45, loss: 0.723007
global_step: 25778, epoch: 45, loss: 0.688361
global_step: 25779, epoch: 45, loss: 0.722426
global_step: 25780, epoch: 45, loss: 0.768134
global_step: 25781, epoch: 45, loss: 0.752663
global_step: 25782, epoch: 45, loss: 0.597894
global_step: 25783, epoch: 45, loss: 0.713903
global_step: 25784, epoch: 45, loss: 0.785019
global_step: 25785, epoch: 45, loss: 0.726318
global_step: 25786, epoch: 45, loss: 0.812871
global_step: 25787, epoch: 45, loss: 0.703705
global_step: 25788, epoch: 45, loss: 0.711849
global_step: 25789, epoch: 45, loss: 0.666732
global_step: 25790, epoch: 45, loss: 0.640188
global_step: 25791, epoch: 45, loss: 0.778507
global_step: 25792, epoch: 45, loss: 0.776389
global_step: 25793, epoch: 45, loss: 0.655988
global_step: 25794, epoch: 45, loss: 0.664450
global_step: 25795, epoch: 45, loss: 0.685670
global_step: 25796, epoch: 45, loss: 0.766035
global_step: 25797, epoch: 45, loss: 0.734145
global_step: 25798, epoch: 45, loss: 0.649833
global_step: 25799, epoch: 45, loss: 0.741961
global_step: 25800, epoch: 45, loss: 0.587192
epoch: 45
train	acc: 0.8552	macro: p 0.8685, r 0.6428, f1: 0.6502	micro: p 0.8552, r 0.8552, f1 0.8552	weighted_f1:0.8381
dev	acc: 0.5464	macro: p 0.3276, r 0.3149, f1: 0.3095	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4986
test	acc: 0.5939	macro: p 0.3392, r 0.3287, f1: 0.3275	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5578
global_step: 25801, epoch: 46, loss: 0.672849
global_step: 25802, epoch: 46, loss: 0.866138
global_step: 25803, epoch: 46, loss: 0.680915
global_step: 25804, epoch: 46, loss: 0.714864
global_step: 25805, epoch: 46, loss: 0.708518
global_step: 25806, epoch: 46, loss: 0.704042
global_step: 25807, epoch: 46, loss: 0.849258
global_step: 25808, epoch: 46, loss: 0.722518
global_step: 25809, epoch: 46, loss: 0.741997
global_step: 25810, epoch: 46, loss: 0.692570
global_step: 25811, epoch: 46, loss: 0.699319
global_step: 25812, epoch: 46, loss: 0.671337
global_step: 25813, epoch: 46, loss: 0.688553
global_step: 25814, epoch: 46, loss: 0.690639
global_step: 25815, epoch: 46, loss: 0.747947
global_step: 25816, epoch: 46, loss: 0.716603
global_step: 25817, epoch: 46, loss: 0.630204
global_step: 25818, epoch: 46, loss: 0.692126
global_step: 25819, epoch: 46, loss: 0.801909
global_step: 25820, epoch: 46, loss: 0.667882
global_step: 25821, epoch: 46, loss: 0.568512
global_step: 25822, epoch: 46, loss: 0.691809
global_step: 25823, epoch: 46, loss: 0.671823
global_step: 25824, epoch: 46, loss: 0.647658
global_step: 25825, epoch: 46, loss: 0.699327
global_step: 25826, epoch: 46, loss: 0.792604
global_step: 25827, epoch: 46, loss: 0.686060
global_step: 25828, epoch: 46, loss: 0.738193
global_step: 25829, epoch: 46, loss: 0.768325
global_step: 25830, epoch: 46, loss: 0.788526
global_step: 25831, epoch: 46, loss: 0.755590
global_step: 25832, epoch: 46, loss: 0.669338
global_step: 25833, epoch: 46, loss: 0.614253
global_step: 25834, epoch: 46, loss: 0.756199
global_step: 25835, epoch: 46, loss: 0.679935
global_step: 25836, epoch: 46, loss: 0.649702
global_step: 25837, epoch: 46, loss: 0.770324
global_step: 25838, epoch: 46, loss: 0.678854
global_step: 25839, epoch: 46, loss: 0.716900
global_step: 25840, epoch: 46, loss: 0.084030
epoch: 46
train	acc: 0.8548	macro: p 0.8751, r 0.6448, f1: 0.6722	micro: p 0.8548, r 0.8548, f1 0.8548	weighted_f1:0.8391
dev	acc: 0.5401	macro: p 0.3161, r 0.2973, f1: 0.2868	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4807
test	acc: 0.6000	macro: p 0.5022, r 0.3213, f1: 0.3249	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5536
global_step: 25841, epoch: 47, loss: 0.694525
global_step: 25842, epoch: 47, loss: 0.723213
global_step: 25843, epoch: 47, loss: 0.726937
global_step: 25844, epoch: 47, loss: 0.635758
global_step: 25845, epoch: 47, loss: 0.718668
global_step: 25846, epoch: 47, loss: 0.659331
global_step: 25847, epoch: 47, loss: 0.715682
global_step: 25848, epoch: 47, loss: 0.652075
global_step: 25849, epoch: 47, loss: 0.636450
global_step: 25850, epoch: 47, loss: 0.724535
global_step: 25851, epoch: 47, loss: 0.736662
global_step: 25852, epoch: 47, loss: 0.645537
global_step: 25853, epoch: 47, loss: 0.698776
global_step: 25854, epoch: 47, loss: 0.733764
global_step: 25855, epoch: 47, loss: 0.717005
global_step: 25856, epoch: 47, loss: 0.773360
global_step: 25857, epoch: 47, loss: 0.611433
global_step: 25858, epoch: 47, loss: 0.710947
global_step: 25859, epoch: 47, loss: 0.664982
global_step: 25860, epoch: 47, loss: 0.762395
global_step: 25861, epoch: 47, loss: 0.753806
global_step: 25862, epoch: 47, loss: 0.754263
global_step: 25863, epoch: 47, loss: 0.744672
global_step: 25864, epoch: 47, loss: 0.780312
global_step: 25865, epoch: 47, loss: 0.725314
global_step: 25866, epoch: 47, loss: 0.704453
global_step: 25867, epoch: 47, loss: 0.733185
global_step: 25868, epoch: 47, loss: 0.784103
global_step: 25869, epoch: 47, loss: 0.761194
global_step: 25870, epoch: 47, loss: 0.689418
global_step: 25871, epoch: 47, loss: 0.770834
global_step: 25872, epoch: 47, loss: 0.730009
global_step: 25873, epoch: 47, loss: 0.705031
global_step: 25874, epoch: 47, loss: 0.709246
global_step: 25875, epoch: 47, loss: 0.738895
global_step: 25876, epoch: 47, loss: 0.683455
global_step: 25877, epoch: 47, loss: 0.573216
global_step: 25878, epoch: 47, loss: 0.764513
global_step: 25879, epoch: 47, loss: 0.675325
global_step: 25880, epoch: 47, loss: 0.287899
epoch: 47
train	acc: 0.8661	macro: p 0.8779, r 0.6658, f1: 0.6958	micro: p 0.8661, r 0.8661, f1 0.8661	weighted_f1:0.8525
dev	acc: 0.5356	macro: p 0.3137, r 0.2994, f1: 0.2864	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4791
test	acc: 0.5847	macro: p 0.3354, r 0.3120, f1: 0.3070	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5401
global_step: 25881, epoch: 48, loss: 0.590552
global_step: 25882, epoch: 48, loss: 0.720580
global_step: 25883, epoch: 48, loss: 0.735112
global_step: 25884, epoch: 48, loss: 0.675947
global_step: 25885, epoch: 48, loss: 0.628103
global_step: 25886, epoch: 48, loss: 0.623919
global_step: 25887, epoch: 48, loss: 0.706248
global_step: 25888, epoch: 48, loss: 0.736422
global_step: 25889, epoch: 48, loss: 0.630439
global_step: 25890, epoch: 48, loss: 0.635964
global_step: 25891, epoch: 48, loss: 0.783197
global_step: 25892, epoch: 48, loss: 0.662521
global_step: 25893, epoch: 48, loss: 0.694474
global_step: 25894, epoch: 48, loss: 0.668281
global_step: 25895, epoch: 48, loss: 0.722660
global_step: 25896, epoch: 48, loss: 0.621740
global_step: 25897, epoch: 48, loss: 0.673911
global_step: 25898, epoch: 48, loss: 0.673120
global_step: 25899, epoch: 48, loss: 0.647633
global_step: 25900, epoch: 48, loss: 0.688754
global_step: 25901, epoch: 48, loss: 0.667964
global_step: 25902, epoch: 48, loss: 0.705190
global_step: 25903, epoch: 48, loss: 0.656326
global_step: 25904, epoch: 48, loss: 0.853529
global_step: 25905, epoch: 48, loss: 0.617366
global_step: 25906, epoch: 48, loss: 0.599096
global_step: 25907, epoch: 48, loss: 0.618727
global_step: 25908, epoch: 48, loss: 0.755904
global_step: 25909, epoch: 48, loss: 0.676485
global_step: 25910, epoch: 48, loss: 0.650207
global_step: 25911, epoch: 48, loss: 0.666911
global_step: 25912, epoch: 48, loss: 0.753815
global_step: 25913, epoch: 48, loss: 0.675265
global_step: 25914, epoch: 48, loss: 0.857424
global_step: 25915, epoch: 48, loss: 0.788942
global_step: 25916, epoch: 48, loss: 0.687250
global_step: 25917, epoch: 48, loss: 0.639359
global_step: 25918, epoch: 48, loss: 0.647343
global_step: 25919, epoch: 48, loss: 0.601167
global_step: 25920, epoch: 48, loss: 0.193504
epoch: 48
train	acc: 0.8675	macro: p 0.8938, r 0.6609, f1: 0.6934	micro: p 0.8675, r 0.8675, f1 0.8675	weighted_f1:0.8532
dev	acc: 0.5365	macro: p 0.3166, r 0.2933, f1: 0.2851	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4788
test	acc: 0.5927	macro: p 0.4950, r 0.3127, f1: 0.3173	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5473
global_step: 25921, epoch: 49, loss: 0.639305
global_step: 25922, epoch: 49, loss: 0.721630
global_step: 25923, epoch: 49, loss: 0.745855
global_step: 25924, epoch: 49, loss: 0.686745
global_step: 25925, epoch: 49, loss: 0.670185
global_step: 25926, epoch: 49, loss: 0.676502
global_step: 25927, epoch: 49, loss: 0.806910
global_step: 25928, epoch: 49, loss: 0.689332
global_step: 25929, epoch: 49, loss: 0.651693
global_step: 25930, epoch: 49, loss: 0.668754
global_step: 25931, epoch: 49, loss: 0.735669
global_step: 25932, epoch: 49, loss: 0.741313
global_step: 25933, epoch: 49, loss: 0.633385
global_step: 25934, epoch: 49, loss: 0.602834
global_step: 25935, epoch: 49, loss: 0.656211
global_step: 25936, epoch: 49, loss: 0.484860
global_step: 25937, epoch: 49, loss: 0.670890
global_step: 25938, epoch: 49, loss: 0.633036
global_step: 25939, epoch: 49, loss: 0.621502
global_step: 25940, epoch: 49, loss: 0.747162
global_step: 25941, epoch: 49, loss: 0.711793
global_step: 25942, epoch: 49, loss: 0.739275
global_step: 25943, epoch: 49, loss: 0.785787
global_step: 25944, epoch: 49, loss: 0.787300
global_step: 25945, epoch: 49, loss: 0.648817
global_step: 25946, epoch: 49, loss: 0.706955
global_step: 25947, epoch: 49, loss: 0.653714
global_step: 25948, epoch: 49, loss: 0.715711
global_step: 25949, epoch: 49, loss: 0.664860
global_step: 25950, epoch: 49, loss: 0.707755
global_step: 25951, epoch: 49, loss: 0.660493
global_step: 25952, epoch: 49, loss: 0.681667
global_step: 25953, epoch: 49, loss: 0.619491
global_step: 25954, epoch: 49, loss: 0.667191
global_step: 25955, epoch: 49, loss: 0.603347
global_step: 25956, epoch: 49, loss: 0.700958
global_step: 25957, epoch: 49, loss: 0.718256
global_step: 25958, epoch: 49, loss: 0.532955
global_step: 25959, epoch: 49, loss: 0.757894
global_step: 25960, epoch: 49, loss: 1.502903
epoch: 49
train	acc: 0.8677	macro: p 0.8897, r 0.6624, f1: 0.6865	micro: p 0.8677, r 0.8677, f1 0.8677	weighted_f1:0.8533
dev	acc: 0.5500	macro: p 0.3320, r 0.3108, f1: 0.3050	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4987
test	acc: 0.5923	macro: p 0.4874, r 0.3188, f1: 0.3202	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5517
global_step: 25961, epoch: 50, loss: 0.624244
global_step: 25962, epoch: 50, loss: 0.599394
global_step: 25963, epoch: 50, loss: 0.724643
global_step: 25964, epoch: 50, loss: 0.630947
global_step: 25965, epoch: 50, loss: 0.682898
global_step: 25966, epoch: 50, loss: 0.623906
global_step: 25967, epoch: 50, loss: 0.630498
global_step: 25968, epoch: 50, loss: 0.624817
global_step: 25969, epoch: 50, loss: 0.734883
global_step: 25970, epoch: 50, loss: 0.552567
global_step: 25971, epoch: 50, loss: 0.679874
global_step: 25972, epoch: 50, loss: 0.686028
global_step: 25973, epoch: 50, loss: 0.592530
global_step: 25974, epoch: 50, loss: 0.766934
global_step: 25975, epoch: 50, loss: 0.683557
global_step: 25976, epoch: 50, loss: 0.601166
global_step: 25977, epoch: 50, loss: 0.606855
global_step: 25978, epoch: 50, loss: 0.582387
global_step: 25979, epoch: 50, loss: 0.592522
global_step: 25980, epoch: 50, loss: 0.693381
global_step: 25981, epoch: 50, loss: 0.683291
global_step: 25982, epoch: 50, loss: 0.653759
global_step: 25983, epoch: 50, loss: 0.624742
global_step: 25984, epoch: 50, loss: 0.646576
global_step: 25985, epoch: 50, loss: 0.768473
global_step: 25986, epoch: 50, loss: 0.642428
global_step: 25987, epoch: 50, loss: 0.606080
global_step: 25988, epoch: 50, loss: 0.717997
global_step: 25989, epoch: 50, loss: 0.783625
global_step: 25990, epoch: 50, loss: 0.744372
global_step: 25991, epoch: 50, loss: 0.662586
global_step: 25992, epoch: 50, loss: 0.646266
global_step: 25993, epoch: 50, loss: 0.687192
global_step: 25994, epoch: 50, loss: 0.727520
global_step: 25995, epoch: 50, loss: 0.680707
global_step: 25996, epoch: 50, loss: 0.625911
global_step: 25997, epoch: 50, loss: 0.652124
global_step: 25998, epoch: 50, loss: 0.672704
global_step: 25999, epoch: 50, loss: 0.676834
global_step: 26000, epoch: 50, loss: 0.200195
epoch: 50
train	acc: 0.8879	macro: p 0.8957, r 0.7142, f1: 0.7498	micro: p 0.8879, r 0.8879, f1 0.8879	weighted_f1:0.8786
dev	acc: 0.5356	macro: p 0.4494, r 0.3046, f1: 0.2980	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4851
test	acc: 0.5912	macro: p 0.3487, r 0.3220, f1: 0.3217	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5527
global_step: 26001, epoch: 51, loss: 0.738145
global_step: 26002, epoch: 51, loss: 0.649577
global_step: 26003, epoch: 51, loss: 0.610843
global_step: 26004, epoch: 51, loss: 0.684038
global_step: 26005, epoch: 51, loss: 0.606913
global_step: 26006, epoch: 51, loss: 0.679451
global_step: 26007, epoch: 51, loss: 0.577258
global_step: 26008, epoch: 51, loss: 0.629662
global_step: 26009, epoch: 51, loss: 0.557954
global_step: 26010, epoch: 51, loss: 0.656959
global_step: 26011, epoch: 51, loss: 0.671484
global_step: 26012, epoch: 51, loss: 0.727560
global_step: 26013, epoch: 51, loss: 0.690399
global_step: 26014, epoch: 51, loss: 0.645611
global_step: 26015, epoch: 51, loss: 0.614213
global_step: 26016, epoch: 51, loss: 0.613091
global_step: 26017, epoch: 51, loss: 0.701819
global_step: 26018, epoch: 51, loss: 0.646362
global_step: 26019, epoch: 51, loss: 0.614589
global_step: 26020, epoch: 51, loss: 0.630792
global_step: 26021, epoch: 51, loss: 0.698144
global_step: 26022, epoch: 51, loss: 0.690715
global_step: 26023, epoch: 51, loss: 0.628569
global_step: 26024, epoch: 51, loss: 0.658255
global_step: 26025, epoch: 51, loss: 0.621924
global_step: 26026, epoch: 51, loss: 0.591505
global_step: 26027, epoch: 51, loss: 0.703419
global_step: 26028, epoch: 51, loss: 0.618392
global_step: 26029, epoch: 51, loss: 0.643811
global_step: 26030, epoch: 51, loss: 0.647499
global_step: 26031, epoch: 51, loss: 0.783445
global_step: 26032, epoch: 51, loss: 0.638210
global_step: 26033, epoch: 51, loss: 0.653642
global_step: 26034, epoch: 51, loss: 0.659468
global_step: 26035, epoch: 51, loss: 0.633610
global_step: 26036, epoch: 51, loss: 0.603564
global_step: 26037, epoch: 51, loss: 0.677659
global_step: 26038, epoch: 51, loss: 0.693864
global_step: 26039, epoch: 51, loss: 0.743371
global_step: 26040, epoch: 51, loss: 1.137056
epoch: 51
train	acc: 0.8880	macro: p 0.8899, r 0.7106, f1: 0.7372	micro: p 0.8880, r 0.8880, f1 0.8880	weighted_f1:0.8782
dev	acc: 0.5284	macro: p 0.3125, r 0.3040, f1: 0.3004	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4888
test	acc: 0.5851	macro: p 0.4824, r 0.3309, f1: 0.3323	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5561
global_step: 26041, epoch: 52, loss: 0.600748
global_step: 26042, epoch: 52, loss: 0.671309
global_step: 26043, epoch: 52, loss: 0.657774
global_step: 26044, epoch: 52, loss: 0.727559
global_step: 26045, epoch: 52, loss: 0.619544
global_step: 26046, epoch: 52, loss: 0.752438
global_step: 26047, epoch: 52, loss: 0.605808
global_step: 26048, epoch: 52, loss: 0.623623
global_step: 26049, epoch: 52, loss: 0.685316
global_step: 26050, epoch: 52, loss: 0.654495
global_step: 26051, epoch: 52, loss: 0.704336
global_step: 26052, epoch: 52, loss: 0.689071
global_step: 26053, epoch: 52, loss: 0.653862
global_step: 26054, epoch: 52, loss: 0.566980
global_step: 26055, epoch: 52, loss: 0.589889
global_step: 26056, epoch: 52, loss: 0.564815
global_step: 26057, epoch: 52, loss: 0.528922
global_step: 26058, epoch: 52, loss: 0.596756
global_step: 26059, epoch: 52, loss: 0.664611
global_step: 26060, epoch: 52, loss: 0.571320
global_step: 26061, epoch: 52, loss: 0.694565
global_step: 26062, epoch: 52, loss: 0.608801
global_step: 26063, epoch: 52, loss: 0.629599
global_step: 26064, epoch: 52, loss: 0.694489
global_step: 26065, epoch: 52, loss: 0.620755
global_step: 26066, epoch: 52, loss: 0.652614
global_step: 26067, epoch: 52, loss: 0.580289
global_step: 26068, epoch: 52, loss: 0.583726
global_step: 26069, epoch: 52, loss: 0.641916
global_step: 26070, epoch: 52, loss: 0.573225
global_step: 26071, epoch: 52, loss: 0.746644
global_step: 26072, epoch: 52, loss: 0.624634
global_step: 26073, epoch: 52, loss: 0.615774
global_step: 26074, epoch: 52, loss: 0.590792
global_step: 26075, epoch: 52, loss: 0.725685
global_step: 26076, epoch: 52, loss: 0.652279
global_step: 26077, epoch: 52, loss: 0.584471
global_step: 26078, epoch: 52, loss: 0.584198
global_step: 26079, epoch: 52, loss: 0.622722
global_step: 26080, epoch: 52, loss: 0.196664
epoch: 52
train	acc: 0.8913	macro: p 0.9045, r 0.7310, f1: 0.7738	micro: p 0.8913, r 0.8913, f1 0.8913	weighted_f1:0.8837
dev	acc: 0.5338	macro: p 0.3050, r 0.2946, f1: 0.2839	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4772
test	acc: 0.5912	macro: p 0.4182, r 0.3156, f1: 0.3173	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5478
global_step: 26081, epoch: 53, loss: 0.558947
global_step: 26082, epoch: 53, loss: 0.642258
global_step: 26083, epoch: 53, loss: 0.564066
global_step: 26084, epoch: 53, loss: 0.710042
global_step: 26085, epoch: 53, loss: 0.554532
global_step: 26086, epoch: 53, loss: 0.664595
global_step: 26087, epoch: 53, loss: 0.573045
global_step: 26088, epoch: 53, loss: 0.540619
global_step: 26089, epoch: 53, loss: 0.555944
global_step: 26090, epoch: 53, loss: 0.645584
global_step: 26091, epoch: 53, loss: 0.521898
global_step: 26092, epoch: 53, loss: 0.599224
global_step: 26093, epoch: 53, loss: 0.667635
global_step: 26094, epoch: 53, loss: 0.661498
global_step: 26095, epoch: 53, loss: 0.608328
global_step: 26096, epoch: 53, loss: 0.648072
global_step: 26097, epoch: 53, loss: 0.614777
global_step: 26098, epoch: 53, loss: 0.648348
global_step: 26099, epoch: 53, loss: 0.608302
global_step: 26100, epoch: 53, loss: 0.648870
global_step: 26101, epoch: 53, loss: 0.590609
global_step: 26102, epoch: 53, loss: 0.682134
global_step: 26103, epoch: 53, loss: 0.608971
global_step: 26104, epoch: 53, loss: 0.588110
global_step: 26105, epoch: 53, loss: 0.707653
global_step: 26106, epoch: 53, loss: 0.602623
global_step: 26107, epoch: 53, loss: 0.764806
global_step: 26108, epoch: 53, loss: 0.538166
global_step: 26109, epoch: 53, loss: 0.606659
global_step: 26110, epoch: 53, loss: 0.635186
global_step: 26111, epoch: 53, loss: 0.647792
global_step: 26112, epoch: 53, loss: 0.741743
global_step: 26113, epoch: 53, loss: 0.622448
global_step: 26114, epoch: 53, loss: 0.704726
global_step: 26115, epoch: 53, loss: 0.555551
global_step: 26116, epoch: 53, loss: 0.565232
global_step: 26117, epoch: 53, loss: 0.663784
global_step: 26118, epoch: 53, loss: 0.652176
global_step: 26119, epoch: 53, loss: 0.597958
global_step: 26120, epoch: 53, loss: 0.074307
epoch: 53
train	acc: 0.8948	macro: p 0.9085, r 0.7291, f1: 0.7685	micro: p 0.8948, r 0.8948, f1 0.8948	weighted_f1:0.8864
dev	acc: 0.5455	macro: p 0.3258, r 0.3074, f1: 0.3012	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4932
test	acc: 0.5935	macro: p 0.4926, r 0.3211, f1: 0.3242	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5527
global_step: 26121, epoch: 54, loss: 0.600939
global_step: 26122, epoch: 54, loss: 0.615740
global_step: 26123, epoch: 54, loss: 0.579707
global_step: 26124, epoch: 54, loss: 0.614608
global_step: 26125, epoch: 54, loss: 0.548180
global_step: 26126, epoch: 54, loss: 0.553424
global_step: 26127, epoch: 54, loss: 0.637727
global_step: 26128, epoch: 54, loss: 0.571787
global_step: 26129, epoch: 54, loss: 0.603925
global_step: 26130, epoch: 54, loss: 0.737675
global_step: 26131, epoch: 54, loss: 0.555654
global_step: 26132, epoch: 54, loss: 0.626193
global_step: 26133, epoch: 54, loss: 0.582402
global_step: 26134, epoch: 54, loss: 0.587018
global_step: 26135, epoch: 54, loss: 0.665382
global_step: 26136, epoch: 54, loss: 0.568215
global_step: 26137, epoch: 54, loss: 0.683174
global_step: 26138, epoch: 54, loss: 0.626190
global_step: 26139, epoch: 54, loss: 0.630032
global_step: 26140, epoch: 54, loss: 0.619926
global_step: 26141, epoch: 54, loss: 0.661258
global_step: 26142, epoch: 54, loss: 0.648473
global_step: 26143, epoch: 54, loss: 0.588557
global_step: 26144, epoch: 54, loss: 0.644024
global_step: 26145, epoch: 54, loss: 0.682463
global_step: 26146, epoch: 54, loss: 0.629350
global_step: 26147, epoch: 54, loss: 0.596744
global_step: 26148, epoch: 54, loss: 0.629055
global_step: 26149, epoch: 54, loss: 0.631411
global_step: 26150, epoch: 54, loss: 0.655579
global_step: 26151, epoch: 54, loss: 0.617139
global_step: 26152, epoch: 54, loss: 0.699463
global_step: 26153, epoch: 54, loss: 0.573832
global_step: 26154, epoch: 54, loss: 0.642363
global_step: 26155, epoch: 54, loss: 0.603182
global_step: 26156, epoch: 54, loss: 0.643166
global_step: 26157, epoch: 54, loss: 0.659534
global_step: 26158, epoch: 54, loss: 0.663729
global_step: 26159, epoch: 54, loss: 0.613653
global_step: 26160, epoch: 54, loss: 0.234773
epoch: 54
train	acc: 0.8909	macro: p 0.9080, r 0.7385, f1: 0.7836	micro: p 0.8909, r 0.8909, f1 0.8909	weighted_f1:0.8840
dev	acc: 0.5437	macro: p 0.4605, r 0.3045, f1: 0.2959	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4846
test	acc: 0.5920	macro: p 0.4862, r 0.3132, f1: 0.3141	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5432
global_step: 26161, epoch: 55, loss: 0.660349
global_step: 26162, epoch: 55, loss: 0.620714
global_step: 26163, epoch: 55, loss: 0.591529
global_step: 26164, epoch: 55, loss: 0.623858
global_step: 26165, epoch: 55, loss: 0.618713
global_step: 26166, epoch: 55, loss: 0.530579
global_step: 26167, epoch: 55, loss: 0.630642
global_step: 26168, epoch: 55, loss: 0.581296
global_step: 26169, epoch: 55, loss: 0.601010
global_step: 26170, epoch: 55, loss: 0.565845
global_step: 26171, epoch: 55, loss: 0.541795
global_step: 26172, epoch: 55, loss: 0.525239
global_step: 26173, epoch: 55, loss: 0.557871
global_step: 26174, epoch: 55, loss: 0.601943
global_step: 26175, epoch: 55, loss: 0.603733
global_step: 26176, epoch: 55, loss: 0.573958
global_step: 26177, epoch: 55, loss: 0.549376
global_step: 26178, epoch: 55, loss: 0.506986
global_step: 26179, epoch: 55, loss: 0.671318
global_step: 26180, epoch: 55, loss: 0.649856
global_step: 26181, epoch: 55, loss: 0.606204
global_step: 26182, epoch: 55, loss: 0.555576
global_step: 26183, epoch: 55, loss: 0.652250
global_step: 26184, epoch: 55, loss: 0.614336
global_step: 26185, epoch: 55, loss: 0.690556
global_step: 26186, epoch: 55, loss: 0.636445
global_step: 26187, epoch: 55, loss: 0.609371
global_step: 26188, epoch: 55, loss: 0.670632
global_step: 26189, epoch: 55, loss: 0.608033
global_step: 26190, epoch: 55, loss: 0.547892
global_step: 26191, epoch: 55, loss: 0.541583
global_step: 26192, epoch: 55, loss: 0.564210
global_step: 26193, epoch: 55, loss: 0.581984
global_step: 26194, epoch: 55, loss: 0.686237
global_step: 26195, epoch: 55, loss: 0.610605
global_step: 26196, epoch: 55, loss: 0.682540
global_step: 26197, epoch: 55, loss: 0.605400
global_step: 26198, epoch: 55, loss: 0.579934
global_step: 26199, epoch: 55, loss: 0.602422
global_step: 26200, epoch: 55, loss: 0.205586
epoch: 55
train	acc: 0.9039	macro: p 0.9171, r 0.7808, f1: 0.8244	micro: p 0.9039, r 0.9039, f1 0.9039	weighted_f1:0.9000
dev	acc: 0.5275	macro: p 0.3833, r 0.3019, f1: 0.2926	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4765
test	acc: 0.5862	macro: p 0.3973, r 0.3210, f1: 0.3184	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5455
global_step: 26201, epoch: 56, loss: 0.478545
global_step: 26202, epoch: 56, loss: 0.554873
global_step: 26203, epoch: 56, loss: 0.565051
global_step: 26204, epoch: 56, loss: 0.502165
global_step: 26205, epoch: 56, loss: 0.556774
global_step: 26206, epoch: 56, loss: 0.648306
global_step: 26207, epoch: 56, loss: 0.620862
global_step: 26208, epoch: 56, loss: 0.563169
global_step: 26209, epoch: 56, loss: 0.582430
global_step: 26210, epoch: 56, loss: 0.683635
global_step: 26211, epoch: 56, loss: 0.583806
global_step: 26212, epoch: 56, loss: 0.621596
global_step: 26213, epoch: 56, loss: 0.622835
global_step: 26214, epoch: 56, loss: 0.563972
global_step: 26215, epoch: 56, loss: 0.620665
global_step: 26216, epoch: 56, loss: 0.600266
global_step: 26217, epoch: 56, loss: 0.538007
global_step: 26218, epoch: 56, loss: 0.648229
global_step: 26219, epoch: 56, loss: 0.556574
global_step: 26220, epoch: 56, loss: 0.657420
global_step: 26221, epoch: 56, loss: 0.637794
global_step: 26222, epoch: 56, loss: 0.653406
global_step: 26223, epoch: 56, loss: 0.676680
global_step: 26224, epoch: 56, loss: 0.620378
global_step: 26225, epoch: 56, loss: 0.553834
global_step: 26226, epoch: 56, loss: 0.575390
global_step: 26227, epoch: 56, loss: 0.613835
global_step: 26228, epoch: 56, loss: 0.638271
global_step: 26229, epoch: 56, loss: 0.516803
global_step: 26230, epoch: 56, loss: 0.626101
global_step: 26231, epoch: 56, loss: 0.605841
global_step: 26232, epoch: 56, loss: 0.590357
global_step: 26233, epoch: 56, loss: 0.652537
global_step: 26234, epoch: 56, loss: 0.606656
global_step: 26235, epoch: 56, loss: 0.660116
global_step: 26236, epoch: 56, loss: 0.611430
global_step: 26237, epoch: 56, loss: 0.574550
global_step: 26238, epoch: 56, loss: 0.489804
global_step: 26239, epoch: 56, loss: 0.609171
global_step: 26240, epoch: 56, loss: 0.272894
epoch: 56
train	acc: 0.9057	macro: p 0.9215, r 0.7712, f1: 0.8181	micro: p 0.9057, r 0.9057, f1 0.9057	weighted_f1:0.9009
dev	acc: 0.5446	macro: p 0.4008, r 0.3037, f1: 0.2983	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4863
test	acc: 0.5950	macro: p 0.3527, r 0.3160, f1: 0.3164	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5485
global_step: 26241, epoch: 57, loss: 0.648905
global_step: 26242, epoch: 57, loss: 0.593781
global_step: 26243, epoch: 57, loss: 0.563645
global_step: 26244, epoch: 57, loss: 0.541321
global_step: 26245, epoch: 57, loss: 0.507092
global_step: 26246, epoch: 57, loss: 0.595281
global_step: 26247, epoch: 57, loss: 0.585814
global_step: 26248, epoch: 57, loss: 0.532152
global_step: 26249, epoch: 57, loss: 0.564206
global_step: 26250, epoch: 57, loss: 0.662954
global_step: 26251, epoch: 57, loss: 0.608986
global_step: 26252, epoch: 57, loss: 0.518245
global_step: 26253, epoch: 57, loss: 0.579041
global_step: 26254, epoch: 57, loss: 0.557235
global_step: 26255, epoch: 57, loss: 0.675408
global_step: 26256, epoch: 57, loss: 0.582949
global_step: 26257, epoch: 57, loss: 0.566364
global_step: 26258, epoch: 57, loss: 0.567633
global_step: 26259, epoch: 57, loss: 0.561500
global_step: 26260, epoch: 57, loss: 0.525247
global_step: 26261, epoch: 57, loss: 0.631753
global_step: 26262, epoch: 57, loss: 0.608263
global_step: 26263, epoch: 57, loss: 0.520259
global_step: 26264, epoch: 57, loss: 0.569711
global_step: 26265, epoch: 57, loss: 0.502962
global_step: 26266, epoch: 57, loss: 0.518879
global_step: 26267, epoch: 57, loss: 0.546318
global_step: 26268, epoch: 57, loss: 0.646093
global_step: 26269, epoch: 57, loss: 0.669162
global_step: 26270, epoch: 57, loss: 0.550040
global_step: 26271, epoch: 57, loss: 0.592653
global_step: 26272, epoch: 57, loss: 0.533086
global_step: 26273, epoch: 57, loss: 0.697029
global_step: 26274, epoch: 57, loss: 0.606737
global_step: 26275, epoch: 57, loss: 0.674827
global_step: 26276, epoch: 57, loss: 0.590495
global_step: 26277, epoch: 57, loss: 0.512260
global_step: 26278, epoch: 57, loss: 0.649070
global_step: 26279, epoch: 57, loss: 0.577463
global_step: 26280, epoch: 57, loss: 0.245229
epoch: 57
train	acc: 0.9025	macro: p 0.9206, r 0.7671, f1: 0.8124	micro: p 0.9025, r 0.9025, f1 0.9025	weighted_f1:0.8971
dev	acc: 0.5401	macro: p 0.3212, r 0.2961, f1: 0.2893	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4816
test	acc: 0.5943	macro: p 0.3979, r 0.3127, f1: 0.3180	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5463
global_step: 26281, epoch: 58, loss: 0.486859
global_step: 26282, epoch: 58, loss: 0.607885
global_step: 26283, epoch: 58, loss: 0.628544
global_step: 26284, epoch: 58, loss: 0.497578
global_step: 26285, epoch: 58, loss: 0.512463
global_step: 26286, epoch: 58, loss: 0.577635
global_step: 26287, epoch: 58, loss: 0.577947
global_step: 26288, epoch: 58, loss: 0.581972
global_step: 26289, epoch: 58, loss: 0.528204
global_step: 26290, epoch: 58, loss: 0.577136
global_step: 26291, epoch: 58, loss: 0.643714
global_step: 26292, epoch: 58, loss: 0.501987
global_step: 26293, epoch: 58, loss: 0.679824
global_step: 26294, epoch: 58, loss: 0.584854
global_step: 26295, epoch: 58, loss: 0.594333
global_step: 26296, epoch: 58, loss: 0.561802
global_step: 26297, epoch: 58, loss: 0.557646
global_step: 26298, epoch: 58, loss: 0.515437
global_step: 26299, epoch: 58, loss: 0.537182
global_step: 26300, epoch: 58, loss: 0.532430
global_step: 26301, epoch: 58, loss: 0.553373
global_step: 26302, epoch: 58, loss: 0.559323
global_step: 26303, epoch: 58, loss: 0.622596
global_step: 26304, epoch: 58, loss: 0.675488
global_step: 26305, epoch: 58, loss: 0.605260
global_step: 26306, epoch: 58, loss: 0.509633
global_step: 26307, epoch: 58, loss: 0.471364
global_step: 26308, epoch: 58, loss: 0.550611
global_step: 26309, epoch: 58, loss: 0.651271
global_step: 26310, epoch: 58, loss: 0.558268
global_step: 26311, epoch: 58, loss: 0.601908
global_step: 26312, epoch: 58, loss: 0.581129
global_step: 26313, epoch: 58, loss: 0.537134
global_step: 26314, epoch: 58, loss: 0.514355
global_step: 26315, epoch: 58, loss: 0.520617
global_step: 26316, epoch: 58, loss: 0.628702
global_step: 26317, epoch: 58, loss: 0.530802
global_step: 26318, epoch: 58, loss: 0.519837
global_step: 26319, epoch: 58, loss: 0.633505
global_step: 26320, epoch: 58, loss: 0.181860
epoch: 58
train	acc: 0.9098	macro: p 0.9212, r 0.7923, f1: 0.8344	micro: p 0.9098, r 0.9098, f1 0.9098	weighted_f1:0.9062
dev	acc: 0.5329	macro: p 0.4512, r 0.3046, f1: 0.2952	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4804
test	acc: 0.5847	macro: p 0.3624, r 0.3176, f1: 0.3144	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5419
global_step: 26321, epoch: 59, loss: 0.514499
global_step: 26322, epoch: 59, loss: 0.533589
global_step: 26323, epoch: 59, loss: 0.534710
global_step: 26324, epoch: 59, loss: 0.573834
global_step: 26325, epoch: 59, loss: 0.582102
global_step: 26326, epoch: 59, loss: 0.572124
global_step: 26327, epoch: 59, loss: 0.499278
global_step: 26328, epoch: 59, loss: 0.529830
global_step: 26329, epoch: 59, loss: 0.533817
global_step: 26330, epoch: 59, loss: 0.487042
global_step: 26331, epoch: 59, loss: 0.607057
global_step: 26332, epoch: 59, loss: 0.575957
global_step: 26333, epoch: 59, loss: 0.543418
global_step: 26334, epoch: 59, loss: 0.560280
global_step: 26335, epoch: 59, loss: 0.556235
global_step: 26336, epoch: 59, loss: 0.526676
global_step: 26337, epoch: 59, loss: 0.579802
global_step: 26338, epoch: 59, loss: 0.599049
global_step: 26339, epoch: 59, loss: 0.624689
global_step: 26340, epoch: 59, loss: 0.586514
global_step: 26341, epoch: 59, loss: 0.467209
global_step: 26342, epoch: 59, loss: 0.566688
global_step: 26343, epoch: 59, loss: 0.623775
global_step: 26344, epoch: 59, loss: 0.474472
global_step: 26345, epoch: 59, loss: 0.718955
global_step: 26346, epoch: 59, loss: 0.565543
global_step: 26347, epoch: 59, loss: 0.581896
global_step: 26348, epoch: 59, loss: 0.569699
global_step: 26349, epoch: 59, loss: 0.545552
global_step: 26350, epoch: 59, loss: 0.538292
global_step: 26351, epoch: 59, loss: 0.658825
global_step: 26352, epoch: 59, loss: 0.565367
global_step: 26353, epoch: 59, loss: 0.533276
global_step: 26354, epoch: 59, loss: 0.646162
global_step: 26355, epoch: 59, loss: 0.549445
global_step: 26356, epoch: 59, loss: 0.607286
global_step: 26357, epoch: 59, loss: 0.549151
global_step: 26358, epoch: 59, loss: 0.684759
global_step: 26359, epoch: 59, loss: 0.628462
global_step: 26360, epoch: 59, loss: 0.136573
epoch: 59
train	acc: 0.9151	macro: p 0.9238, r 0.7975, f1: 0.8369	micro: p 0.9151, r 0.9151, f1 0.9151	weighted_f1:0.9114
dev	acc: 0.5338	macro: p 0.4541, r 0.3091, f1: 0.3044	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4880
test	acc: 0.5862	macro: p 0.3718, r 0.3237, f1: 0.3235	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5493
global_step: 26361, epoch: 60, loss: 0.508448
global_step: 26362, epoch: 60, loss: 0.573022
global_step: 26363, epoch: 60, loss: 0.631761
global_step: 26364, epoch: 60, loss: 0.521488
global_step: 26365, epoch: 60, loss: 0.565452
global_step: 26366, epoch: 60, loss: 0.617587
global_step: 26367, epoch: 60, loss: 0.577947
global_step: 26368, epoch: 60, loss: 0.513180
global_step: 26369, epoch: 60, loss: 0.519885
global_step: 26370, epoch: 60, loss: 0.490812
global_step: 26371, epoch: 60, loss: 0.531610
global_step: 26372, epoch: 60, loss: 0.596648
global_step: 26373, epoch: 60, loss: 0.519782
global_step: 26374, epoch: 60, loss: 0.600442
global_step: 26375, epoch: 60, loss: 0.628178
global_step: 26376, epoch: 60, loss: 0.561631
global_step: 26377, epoch: 60, loss: 0.492787
global_step: 26378, epoch: 60, loss: 0.426540
global_step: 26379, epoch: 60, loss: 0.712910
global_step: 26380, epoch: 60, loss: 0.537213
global_step: 26381, epoch: 60, loss: 0.549052
global_step: 26382, epoch: 60, loss: 0.544051
global_step: 26383, epoch: 60, loss: 0.485243
global_step: 26384, epoch: 60, loss: 0.555242
global_step: 26385, epoch: 60, loss: 0.597241
global_step: 26386, epoch: 60, loss: 0.574499
global_step: 26387, epoch: 60, loss: 0.510981
global_step: 26388, epoch: 60, loss: 0.539317
global_step: 26389, epoch: 60, loss: 0.436372
global_step: 26390, epoch: 60, loss: 0.537753
global_step: 26391, epoch: 60, loss: 0.534537
global_step: 26392, epoch: 60, loss: 0.622277
global_step: 26393, epoch: 60, loss: 0.538534
global_step: 26394, epoch: 60, loss: 0.537556
global_step: 26395, epoch: 60, loss: 0.562671
global_step: 26396, epoch: 60, loss: 0.452525
global_step: 26397, epoch: 60, loss: 0.586101
global_step: 26398, epoch: 60, loss: 0.637545
global_step: 26399, epoch: 60, loss: 0.539490
global_step: 26400, epoch: 60, loss: 1.214290
epoch: 60
train	acc: 0.9214	macro: p 0.9295, r 0.8144, f1: 0.8537	micro: p 0.9214, r 0.9214, f1 0.9214	weighted_f1:0.9185
dev	acc: 0.5311	macro: p 0.4554, r 0.3068, f1: 0.3032	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4863
test	acc: 0.5897	macro: p 0.3876, r 0.3268, f1: 0.3310	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5554
global_step: 26401, epoch: 61, loss: 0.599259
global_step: 26402, epoch: 61, loss: 0.475709
global_step: 26403, epoch: 61, loss: 0.482070
global_step: 26404, epoch: 61, loss: 0.563873
global_step: 26405, epoch: 61, loss: 0.512728
global_step: 26406, epoch: 61, loss: 0.486535
global_step: 26407, epoch: 61, loss: 0.497162
global_step: 26408, epoch: 61, loss: 0.510513
global_step: 26409, epoch: 61, loss: 0.532422
global_step: 26410, epoch: 61, loss: 0.594724
global_step: 26411, epoch: 61, loss: 0.484325
global_step: 26412, epoch: 61, loss: 0.631260
global_step: 26413, epoch: 61, loss: 0.539399
global_step: 26414, epoch: 61, loss: 0.449419
global_step: 26415, epoch: 61, loss: 0.583201
global_step: 26416, epoch: 61, loss: 0.591047
global_step: 26417, epoch: 61, loss: 0.506248
global_step: 26418, epoch: 61, loss: 0.489046
global_step: 26419, epoch: 61, loss: 0.632408
global_step: 26420, epoch: 61, loss: 0.547400
global_step: 26421, epoch: 61, loss: 0.457506
global_step: 26422, epoch: 61, loss: 0.600327
global_step: 26423, epoch: 61, loss: 0.462436
global_step: 26424, epoch: 61, loss: 0.544886
global_step: 26425, epoch: 61, loss: 0.548297
global_step: 26426, epoch: 61, loss: 0.525623
global_step: 26427, epoch: 61, loss: 0.621529
global_step: 26428, epoch: 61, loss: 0.542896
global_step: 26429, epoch: 61, loss: 0.510168
global_step: 26430, epoch: 61, loss: 0.615685
global_step: 26431, epoch: 61, loss: 0.579035
global_step: 26432, epoch: 61, loss: 0.515375
global_step: 26433, epoch: 61, loss: 0.543123
global_step: 26434, epoch: 61, loss: 0.636205
global_step: 26435, epoch: 61, loss: 0.538647
global_step: 26436, epoch: 61, loss: 0.591469
global_step: 26437, epoch: 61, loss: 0.524152
global_step: 26438, epoch: 61, loss: 0.594438
global_step: 26439, epoch: 61, loss: 0.456455
global_step: 26440, epoch: 61, loss: 0.514058
epoch: 61
train	acc: 0.9208	macro: p 0.9294, r 0.8161, f1: 0.8558	micro: p 0.9208, r 0.9208, f1 0.9208	weighted_f1:0.9181
dev	acc: 0.5356	macro: p 0.4548, r 0.3089, f1: 0.3046	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4885
test	acc: 0.5870	macro: p 0.4115, r 0.3197, f1: 0.3209	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5474
global_step: 26441, epoch: 62, loss: 0.620065
global_step: 26442, epoch: 62, loss: 0.564304
global_step: 26443, epoch: 62, loss: 0.560899
global_step: 26444, epoch: 62, loss: 0.466740
global_step: 26445, epoch: 62, loss: 0.568543
global_step: 26446, epoch: 62, loss: 0.500350
global_step: 26447, epoch: 62, loss: 0.529346
global_step: 26448, epoch: 62, loss: 0.525408
global_step: 26449, epoch: 62, loss: 0.459940
global_step: 26450, epoch: 62, loss: 0.491728
global_step: 26451, epoch: 62, loss: 0.440915
global_step: 26452, epoch: 62, loss: 0.555098
global_step: 26453, epoch: 62, loss: 0.605281
global_step: 26454, epoch: 62, loss: 0.438453
global_step: 26455, epoch: 62, loss: 0.535128
global_step: 26456, epoch: 62, loss: 0.549650
global_step: 26457, epoch: 62, loss: 0.560177
global_step: 26458, epoch: 62, loss: 0.507100
global_step: 26459, epoch: 62, loss: 0.491559
global_step: 26460, epoch: 62, loss: 0.554361
global_step: 26461, epoch: 62, loss: 0.613500
global_step: 26462, epoch: 62, loss: 0.525749
global_step: 26463, epoch: 62, loss: 0.577721
global_step: 26464, epoch: 62, loss: 0.569318
global_step: 26465, epoch: 62, loss: 0.454151
global_step: 26466, epoch: 62, loss: 0.501415
global_step: 26467, epoch: 62, loss: 0.541070
global_step: 26468, epoch: 62, loss: 0.493666
global_step: 26469, epoch: 62, loss: 0.460413
global_step: 26470, epoch: 62, loss: 0.474283
global_step: 26471, epoch: 62, loss: 0.469684
global_step: 26472, epoch: 62, loss: 0.601529
global_step: 26473, epoch: 62, loss: 0.494710
global_step: 26474, epoch: 62, loss: 0.491475
global_step: 26475, epoch: 62, loss: 0.578716
global_step: 26476, epoch: 62, loss: 0.548272
global_step: 26477, epoch: 62, loss: 0.582713
global_step: 26478, epoch: 62, loss: 0.684270
global_step: 26479, epoch: 62, loss: 0.467669
global_step: 26480, epoch: 62, loss: 0.739562
epoch: 62
train	acc: 0.9198	macro: p 0.9308, r 0.8175, f1: 0.8578	micro: p 0.9198, r 0.9198, f1 0.9198	weighted_f1:0.9170
dev	acc: 0.5428	macro: p 0.4598, r 0.3046, f1: 0.3032	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4909
test	acc: 0.5923	macro: p 0.3879, r 0.3169, f1: 0.3236	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5494
global_step: 26481, epoch: 63, loss: 0.535424
global_step: 26482, epoch: 63, loss: 0.517159
global_step: 26483, epoch: 63, loss: 0.562095
global_step: 26484, epoch: 63, loss: 0.482686
global_step: 26485, epoch: 63, loss: 0.509042
global_step: 26486, epoch: 63, loss: 0.429268
global_step: 26487, epoch: 63, loss: 0.447917
global_step: 26488, epoch: 63, loss: 0.452749
global_step: 26489, epoch: 63, loss: 0.546147
global_step: 26490, epoch: 63, loss: 0.503735
global_step: 26491, epoch: 63, loss: 0.472438
global_step: 26492, epoch: 63, loss: 0.523840
global_step: 26493, epoch: 63, loss: 0.437338
global_step: 26494, epoch: 63, loss: 0.486522
global_step: 26495, epoch: 63, loss: 0.606944
global_step: 26496, epoch: 63, loss: 0.467295
global_step: 26497, epoch: 63, loss: 0.538212
global_step: 26498, epoch: 63, loss: 0.586414
global_step: 26499, epoch: 63, loss: 0.569915
global_step: 26500, epoch: 63, loss: 0.394224
global_step: 26501, epoch: 63, loss: 0.470139
global_step: 26502, epoch: 63, loss: 0.561153
global_step: 26503, epoch: 63, loss: 0.557443
global_step: 26504, epoch: 63, loss: 0.643989
global_step: 26505, epoch: 63, loss: 0.549102
global_step: 26506, epoch: 63, loss: 0.452524
global_step: 26507, epoch: 63, loss: 0.593010
global_step: 26508, epoch: 63, loss: 0.552551
global_step: 26509, epoch: 63, loss: 0.573499
global_step: 26510, epoch: 63, loss: 0.542153
global_step: 26511, epoch: 63, loss: 0.488403
global_step: 26512, epoch: 63, loss: 0.479106
global_step: 26513, epoch: 63, loss: 0.504586
global_step: 26514, epoch: 63, loss: 0.461018
global_step: 26515, epoch: 63, loss: 0.590617
global_step: 26516, epoch: 63, loss: 0.591408
global_step: 26517, epoch: 63, loss: 0.463537
global_step: 26518, epoch: 63, loss: 0.595651
global_step: 26519, epoch: 63, loss: 0.425294
global_step: 26520, epoch: 63, loss: 0.394104
epoch: 63
train	acc: 0.9209	macro: p 0.9294, r 0.8201, f1: 0.8596	micro: p 0.9209, r 0.9209, f1 0.9209	weighted_f1:0.9186
dev	acc: 0.5392	macro: p 0.3190, r 0.3073, f1: 0.3026	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4928
test	acc: 0.5885	macro: p 0.3918, r 0.3206, f1: 0.3229	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5516
global_step: 26521, epoch: 64, loss: 0.505372
global_step: 26522, epoch: 64, loss: 0.529574
global_step: 26523, epoch: 64, loss: 0.491333
global_step: 26524, epoch: 64, loss: 0.520722
global_step: 26525, epoch: 64, loss: 0.530784
global_step: 26526, epoch: 64, loss: 0.458677
global_step: 26527, epoch: 64, loss: 0.598546
global_step: 26528, epoch: 64, loss: 0.547646
global_step: 26529, epoch: 64, loss: 0.504612
global_step: 26530, epoch: 64, loss: 0.509907
global_step: 26531, epoch: 64, loss: 0.537440
global_step: 26532, epoch: 64, loss: 0.482107
global_step: 26533, epoch: 64, loss: 0.460742
global_step: 26534, epoch: 64, loss: 0.506759
global_step: 26535, epoch: 64, loss: 0.561290
global_step: 26536, epoch: 64, loss: 0.504005
global_step: 26537, epoch: 64, loss: 0.461987
global_step: 26538, epoch: 64, loss: 0.526339
global_step: 26539, epoch: 64, loss: 0.605975
global_step: 26540, epoch: 64, loss: 0.581990
global_step: 26541, epoch: 64, loss: 0.577707
global_step: 26542, epoch: 64, loss: 0.469756
global_step: 26543, epoch: 64, loss: 0.571420
global_step: 26544, epoch: 64, loss: 0.557234
global_step: 26545, epoch: 64, loss: 0.536440
global_step: 26546, epoch: 64, loss: 0.397693
global_step: 26547, epoch: 64, loss: 0.443861
global_step: 26548, epoch: 64, loss: 0.464185
global_step: 26549, epoch: 64, loss: 0.456118
global_step: 26550, epoch: 64, loss: 0.594803
global_step: 26551, epoch: 64, loss: 0.560455
global_step: 26552, epoch: 64, loss: 0.514763
global_step: 26553, epoch: 64, loss: 0.488969
global_step: 26554, epoch: 64, loss: 0.438813
global_step: 26555, epoch: 64, loss: 0.529839
global_step: 26556, epoch: 64, loss: 0.427017
global_step: 26557, epoch: 64, loss: 0.529739
global_step: 26558, epoch: 64, loss: 0.488408
global_step: 26559, epoch: 64, loss: 0.512983
global_step: 26560, epoch: 64, loss: 0.072336
epoch: 64
train	acc: 0.9261	macro: p 0.9384, r 0.8385, f1: 0.8767	micro: p 0.9261, r 0.9261, f1 0.9261	weighted_f1:0.9244
dev	acc: 0.5221	macro: p 0.3710, r 0.2976, f1: 0.2892	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4725
test	acc: 0.5881	macro: p 0.3790, r 0.3188, f1: 0.3182	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5468
global_step: 26561, epoch: 65, loss: 0.524369
global_step: 26562, epoch: 65, loss: 0.512360
global_step: 26563, epoch: 65, loss: 0.543323
global_step: 26564, epoch: 65, loss: 0.474581
global_step: 26565, epoch: 65, loss: 0.501137
global_step: 26566, epoch: 65, loss: 0.552454
global_step: 26567, epoch: 65, loss: 0.460806
global_step: 26568, epoch: 65, loss: 0.368307
global_step: 26569, epoch: 65, loss: 0.466187
global_step: 26570, epoch: 65, loss: 0.485890
global_step: 26571, epoch: 65, loss: 0.579366
global_step: 26572, epoch: 65, loss: 0.510577
global_step: 26573, epoch: 65, loss: 0.511115
global_step: 26574, epoch: 65, loss: 0.430618
global_step: 26575, epoch: 65, loss: 0.513149
global_step: 26576, epoch: 65, loss: 0.512956
global_step: 26577, epoch: 65, loss: 0.528264
global_step: 26578, epoch: 65, loss: 0.484954
global_step: 26579, epoch: 65, loss: 0.525439
global_step: 26580, epoch: 65, loss: 0.497617
global_step: 26581, epoch: 65, loss: 0.617842
global_step: 26582, epoch: 65, loss: 0.484425
global_step: 26583, epoch: 65, loss: 0.583167
global_step: 26584, epoch: 65, loss: 0.477537
global_step: 26585, epoch: 65, loss: 0.588024
global_step: 26586, epoch: 65, loss: 0.498560
global_step: 26587, epoch: 65, loss: 0.545883
global_step: 26588, epoch: 65, loss: 0.541697
global_step: 26589, epoch: 65, loss: 0.630213
global_step: 26590, epoch: 65, loss: 0.504135
global_step: 26591, epoch: 65, loss: 0.463231
global_step: 26592, epoch: 65, loss: 0.494402
global_step: 26593, epoch: 65, loss: 0.628178
global_step: 26594, epoch: 65, loss: 0.512966
global_step: 26595, epoch: 65, loss: 0.493086
global_step: 26596, epoch: 65, loss: 0.543057
global_step: 26597, epoch: 65, loss: 0.450424
global_step: 26598, epoch: 65, loss: 0.521347
global_step: 26599, epoch: 65, loss: 0.427726
global_step: 26600, epoch: 65, loss: 0.234453
epoch: 65
train	acc: 0.9225	macro: p 0.9364, r 0.8261, f1: 0.8673	micro: p 0.9225, r 0.9225, f1 0.9225	weighted_f1:0.9203
dev	acc: 0.5347	macro: p 0.3842, r 0.2989, f1: 0.2921	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4791
test	acc: 0.5935	macro: p 0.4247, r 0.3161, f1: 0.3201	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5482
global_step: 26601, epoch: 66, loss: 0.585645
global_step: 26602, epoch: 66, loss: 0.482161
global_step: 26603, epoch: 66, loss: 0.545606
global_step: 26604, epoch: 66, loss: 0.479410
global_step: 26605, epoch: 66, loss: 0.463914
global_step: 26606, epoch: 66, loss: 0.426688
global_step: 26607, epoch: 66, loss: 0.401997
global_step: 26608, epoch: 66, loss: 0.443084
global_step: 26609, epoch: 66, loss: 0.527807
global_step: 26610, epoch: 66, loss: 0.524869
global_step: 26611, epoch: 66, loss: 0.504174
global_step: 26612, epoch: 66, loss: 0.440558
global_step: 26613, epoch: 66, loss: 0.529257
global_step: 26614, epoch: 66, loss: 0.589095
global_step: 26615, epoch: 66, loss: 0.507204
global_step: 26616, epoch: 66, loss: 0.482200
global_step: 26617, epoch: 66, loss: 0.498984
global_step: 26618, epoch: 66, loss: 0.491538
global_step: 26619, epoch: 66, loss: 0.596321
global_step: 26620, epoch: 66, loss: 0.532477
global_step: 26621, epoch: 66, loss: 0.469072
global_step: 26622, epoch: 66, loss: 0.491596
global_step: 26623, epoch: 66, loss: 0.520363
global_step: 26624, epoch: 66, loss: 0.527608
global_step: 26625, epoch: 66, loss: 0.545891
global_step: 26626, epoch: 66, loss: 0.549313
global_step: 26627, epoch: 66, loss: 0.538846
global_step: 26628, epoch: 66, loss: 0.442414
global_step: 26629, epoch: 66, loss: 0.537140
global_step: 26630, epoch: 66, loss: 0.486982
global_step: 26631, epoch: 66, loss: 0.532447
global_step: 26632, epoch: 66, loss: 0.558602
global_step: 26633, epoch: 66, loss: 0.486479
global_step: 26634, epoch: 66, loss: 0.548159
global_step: 26635, epoch: 66, loss: 0.431050
global_step: 26636, epoch: 66, loss: 0.493008
global_step: 26637, epoch: 66, loss: 0.498071
global_step: 26638, epoch: 66, loss: 0.568473
global_step: 26639, epoch: 66, loss: 0.545978
global_step: 26640, epoch: 66, loss: 1.255400
epoch: 66
train	acc: 0.9284	macro: p 0.9399, r 0.8390, f1: 0.8776	micro: p 0.9284, r 0.9284, f1 0.9284	weighted_f1:0.9265
dev	acc: 0.5446	macro: p 0.3948, r 0.3061, f1: 0.3053	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4922
test	acc: 0.5958	macro: p 0.4229, r 0.3203, f1: 0.3288	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5526
global_step: 26641, epoch: 67, loss: 0.519630
global_step: 26642, epoch: 67, loss: 0.477035
global_step: 26643, epoch: 67, loss: 0.388478
global_step: 26644, epoch: 67, loss: 0.480718
global_step: 26645, epoch: 67, loss: 0.501886
global_step: 26646, epoch: 67, loss: 0.512220
global_step: 26647, epoch: 67, loss: 0.449434
global_step: 26648, epoch: 67, loss: 0.513787
global_step: 26649, epoch: 67, loss: 0.527644
global_step: 26650, epoch: 67, loss: 0.469347
global_step: 26651, epoch: 67, loss: 0.390423
global_step: 26652, epoch: 67, loss: 0.443127
global_step: 26653, epoch: 67, loss: 0.511524
global_step: 26654, epoch: 67, loss: 0.458604
global_step: 26655, epoch: 67, loss: 0.521647
global_step: 26656, epoch: 67, loss: 0.462679
global_step: 26657, epoch: 67, loss: 0.490171
global_step: 26658, epoch: 67, loss: 0.512904
global_step: 26659, epoch: 67, loss: 0.475087
global_step: 26660, epoch: 67, loss: 0.614172
global_step: 26661, epoch: 67, loss: 0.529486
global_step: 26662, epoch: 67, loss: 0.481061
global_step: 26663, epoch: 67, loss: 0.546165
global_step: 26664, epoch: 67, loss: 0.556308
global_step: 26665, epoch: 67, loss: 0.501577
global_step: 26666, epoch: 67, loss: 0.491299
global_step: 26667, epoch: 67, loss: 0.614513
global_step: 26668, epoch: 67, loss: 0.464417
global_step: 26669, epoch: 67, loss: 0.417246
global_step: 26670, epoch: 67, loss: 0.501736
global_step: 26671, epoch: 67, loss: 0.422209
global_step: 26672, epoch: 67, loss: 0.532258
global_step: 26673, epoch: 67, loss: 0.574802
global_step: 26674, epoch: 67, loss: 0.434904
global_step: 26675, epoch: 67, loss: 0.495934
global_step: 26676, epoch: 67, loss: 0.558524
global_step: 26677, epoch: 67, loss: 0.514475
global_step: 26678, epoch: 67, loss: 0.457894
global_step: 26679, epoch: 67, loss: 0.540942
global_step: 26680, epoch: 67, loss: 0.338651
epoch: 67
train	acc: 0.9263	macro: p 0.9437, r 0.8340, f1: 0.8765	micro: p 0.9263, r 0.9263, f1 0.9263	weighted_f1:0.9243
dev	acc: 0.5365	macro: p 0.4584, r 0.2992, f1: 0.2921	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4791
test	acc: 0.5904	macro: p 0.4205, r 0.3120, f1: 0.3143	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5438
global_step: 26681, epoch: 68, loss: 0.481482
global_step: 26682, epoch: 68, loss: 0.478868
global_step: 26683, epoch: 68, loss: 0.554834
global_step: 26684, epoch: 68, loss: 0.538067
global_step: 26685, epoch: 68, loss: 0.457511
global_step: 26686, epoch: 68, loss: 0.435092
global_step: 26687, epoch: 68, loss: 0.483475
global_step: 26688, epoch: 68, loss: 0.518156
global_step: 26689, epoch: 68, loss: 0.522795
global_step: 26690, epoch: 68, loss: 0.535404
global_step: 26691, epoch: 68, loss: 0.553796
global_step: 26692, epoch: 68, loss: 0.503374
global_step: 26693, epoch: 68, loss: 0.504797
global_step: 26694, epoch: 68, loss: 0.409929
global_step: 26695, epoch: 68, loss: 0.479333
global_step: 26696, epoch: 68, loss: 0.632616
global_step: 26697, epoch: 68, loss: 0.487471
global_step: 26698, epoch: 68, loss: 0.478964
global_step: 26699, epoch: 68, loss: 0.432581
global_step: 26700, epoch: 68, loss: 0.429090
global_step: 26701, epoch: 68, loss: 0.425232
global_step: 26702, epoch: 68, loss: 0.431453
global_step: 26703, epoch: 68, loss: 0.504490
global_step: 26704, epoch: 68, loss: 0.488002
global_step: 26705, epoch: 68, loss: 0.526923
global_step: 26706, epoch: 68, loss: 0.532076
global_step: 26707, epoch: 68, loss: 0.388365
global_step: 26708, epoch: 68, loss: 0.634947
global_step: 26709, epoch: 68, loss: 0.479720
global_step: 26710, epoch: 68, loss: 0.586032
global_step: 26711, epoch: 68, loss: 0.480223
global_step: 26712, epoch: 68, loss: 0.476404
global_step: 26713, epoch: 68, loss: 0.383748
global_step: 26714, epoch: 68, loss: 0.475062
global_step: 26715, epoch: 68, loss: 0.539923
global_step: 26716, epoch: 68, loss: 0.433290
global_step: 26717, epoch: 68, loss: 0.504089
global_step: 26718, epoch: 68, loss: 0.420668
global_step: 26719, epoch: 68, loss: 0.539282
global_step: 26720, epoch: 68, loss: 0.146375
epoch: 68
train	acc: 0.9304	macro: p 0.9449, r 0.8548, f1: 0.8920	micro: p 0.9304, r 0.9304, f1 0.9304	weighted_f1:0.9292
dev	acc: 0.5356	macro: p 0.3717, r 0.2994, f1: 0.2924	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4800
test	acc: 0.5897	macro: p 0.4090, r 0.3119, f1: 0.3130	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5439
global_step: 26721, epoch: 69, loss: 0.434844
global_step: 26722, epoch: 69, loss: 0.499203
global_step: 26723, epoch: 69, loss: 0.455720
global_step: 26724, epoch: 69, loss: 0.418563
global_step: 26725, epoch: 69, loss: 0.441100
global_step: 26726, epoch: 69, loss: 0.495831
global_step: 26727, epoch: 69, loss: 0.503736
global_step: 26728, epoch: 69, loss: 0.531974
global_step: 26729, epoch: 69, loss: 0.485864
global_step: 26730, epoch: 69, loss: 0.490377
global_step: 26731, epoch: 69, loss: 0.523738
global_step: 26732, epoch: 69, loss: 0.468277
global_step: 26733, epoch: 69, loss: 0.498407
global_step: 26734, epoch: 69, loss: 0.425382
global_step: 26735, epoch: 69, loss: 0.488629
global_step: 26736, epoch: 69, loss: 0.459095
global_step: 26737, epoch: 69, loss: 0.403714
global_step: 26738, epoch: 69, loss: 0.412984
global_step: 26739, epoch: 69, loss: 0.432927
global_step: 26740, epoch: 69, loss: 0.589668
global_step: 26741, epoch: 69, loss: 0.440668
global_step: 26742, epoch: 69, loss: 0.421186
global_step: 26743, epoch: 69, loss: 0.510793
global_step: 26744, epoch: 69, loss: 0.522735
global_step: 26745, epoch: 69, loss: 0.517059
global_step: 26746, epoch: 69, loss: 0.503033
global_step: 26747, epoch: 69, loss: 0.521947
global_step: 26748, epoch: 69, loss: 0.484770
global_step: 26749, epoch: 69, loss: 0.568611
global_step: 26750, epoch: 69, loss: 0.373664
global_step: 26751, epoch: 69, loss: 0.393531
global_step: 26752, epoch: 69, loss: 0.508410
global_step: 26753, epoch: 69, loss: 0.489883
global_step: 26754, epoch: 69, loss: 0.438001
global_step: 26755, epoch: 69, loss: 0.539599
global_step: 26756, epoch: 69, loss: 0.414526
global_step: 26757, epoch: 69, loss: 0.366977
global_step: 26758, epoch: 69, loss: 0.505672
global_step: 26759, epoch: 69, loss: 0.548005
global_step: 26760, epoch: 69, loss: 1.314025
epoch: 69
train	acc: 0.9403	macro: p 0.9484, r 0.8826, f1: 0.9108	micro: p 0.9403, r 0.9403, f1 0.9403	weighted_f1:0.9397
dev	acc: 0.5230	macro: p 0.3305, r 0.3010, f1: 0.2950	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4784
test	acc: 0.5828	macro: p 0.3683, r 0.3224, f1: 0.3260	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5491
global_step: 26761, epoch: 70, loss: 0.389221
global_step: 26762, epoch: 70, loss: 0.411525
global_step: 26763, epoch: 70, loss: 0.464896
global_step: 26764, epoch: 70, loss: 0.358897
global_step: 26765, epoch: 70, loss: 0.466534
global_step: 26766, epoch: 70, loss: 0.448507
global_step: 26767, epoch: 70, loss: 0.483288
global_step: 26768, epoch: 70, loss: 0.460282
global_step: 26769, epoch: 70, loss: 0.415906
global_step: 26770, epoch: 70, loss: 0.467324
global_step: 26771, epoch: 70, loss: 0.416585
global_step: 26772, epoch: 70, loss: 0.502698
global_step: 26773, epoch: 70, loss: 0.401841
global_step: 26774, epoch: 70, loss: 0.439549
global_step: 26775, epoch: 70, loss: 0.457414
global_step: 26776, epoch: 70, loss: 0.479786
global_step: 26777, epoch: 70, loss: 0.548568
global_step: 26778, epoch: 70, loss: 0.518409
global_step: 26779, epoch: 70, loss: 0.427284
global_step: 26780, epoch: 70, loss: 0.441025
global_step: 26781, epoch: 70, loss: 0.462322
global_step: 26782, epoch: 70, loss: 0.400086
global_step: 26783, epoch: 70, loss: 0.505268
global_step: 26784, epoch: 70, loss: 0.428969
global_step: 26785, epoch: 70, loss: 0.559818
global_step: 26786, epoch: 70, loss: 0.546184
global_step: 26787, epoch: 70, loss: 0.499420
global_step: 26788, epoch: 70, loss: 0.455975
global_step: 26789, epoch: 70, loss: 0.587927
global_step: 26790, epoch: 70, loss: 0.475721
global_step: 26791, epoch: 70, loss: 0.501007
global_step: 26792, epoch: 70, loss: 0.475054
global_step: 26793, epoch: 70, loss: 0.457641
global_step: 26794, epoch: 70, loss: 0.474039
global_step: 26795, epoch: 70, loss: 0.511794
global_step: 26796, epoch: 70, loss: 0.489219
global_step: 26797, epoch: 70, loss: 0.505738
global_step: 26798, epoch: 70, loss: 0.475499
global_step: 26799, epoch: 70, loss: 0.509419
global_step: 26800, epoch: 70, loss: 0.777101
epoch: 70
train	acc: 0.9366	macro: p 0.9474, r 0.8656, f1: 0.8992	micro: p 0.9366, r 0.9366, f1 0.9366	weighted_f1:0.9355
dev	acc: 0.5365	macro: p 0.4541, r 0.3036, f1: 0.2991	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4844
test	acc: 0.5885	macro: p 0.3991, r 0.3144, f1: 0.3196	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5438
global_step: 26801, epoch: 71, loss: 0.525953
global_step: 26802, epoch: 71, loss: 0.500400
global_step: 26803, epoch: 71, loss: 0.436690
global_step: 26804, epoch: 71, loss: 0.472002
global_step: 26805, epoch: 71, loss: 0.401729
global_step: 26806, epoch: 71, loss: 0.502140
global_step: 26807, epoch: 71, loss: 0.427106
global_step: 26808, epoch: 71, loss: 0.451532
global_step: 26809, epoch: 71, loss: 0.422193
global_step: 26810, epoch: 71, loss: 0.432225
global_step: 26811, epoch: 71, loss: 0.423390
global_step: 26812, epoch: 71, loss: 0.330181
global_step: 26813, epoch: 71, loss: 0.510944
global_step: 26814, epoch: 71, loss: 0.518953
global_step: 26815, epoch: 71, loss: 0.512935
global_step: 26816, epoch: 71, loss: 0.432096
global_step: 26817, epoch: 71, loss: 0.398756
global_step: 26818, epoch: 71, loss: 0.419603
global_step: 26819, epoch: 71, loss: 0.411612
global_step: 26820, epoch: 71, loss: 0.477392
global_step: 26821, epoch: 71, loss: 0.413413
global_step: 26822, epoch: 71, loss: 0.445669
global_step: 26823, epoch: 71, loss: 0.461141
global_step: 26824, epoch: 71, loss: 0.400879
global_step: 26825, epoch: 71, loss: 0.403729
global_step: 26826, epoch: 71, loss: 0.476659
global_step: 26827, epoch: 71, loss: 0.487549
global_step: 26828, epoch: 71, loss: 0.508220
global_step: 26829, epoch: 71, loss: 0.487392
global_step: 26830, epoch: 71, loss: 0.471509
global_step: 26831, epoch: 71, loss: 0.465365
global_step: 26832, epoch: 71, loss: 0.445934
global_step: 26833, epoch: 71, loss: 0.509396
global_step: 26834, epoch: 71, loss: 0.402078
global_step: 26835, epoch: 71, loss: 0.481300
global_step: 26836, epoch: 71, loss: 0.434357
global_step: 26837, epoch: 71, loss: 0.470801
global_step: 26838, epoch: 71, loss: 0.459885
global_step: 26839, epoch: 71, loss: 0.489638
global_step: 26840, epoch: 71, loss: 0.627926
epoch: 71
train	acc: 0.9348	macro: p 0.9518, r 0.8689, f1: 0.9045	micro: p 0.9348, r 0.9348, f1 0.9348	weighted_f1:0.9338
dev	acc: 0.5239	macro: p 0.3728, r 0.2878, f1: 0.2882	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4711
test	acc: 0.5874	macro: p 0.3993, r 0.3064, f1: 0.3164	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5415
global_step: 26841, epoch: 72, loss: 0.476161
global_step: 26842, epoch: 72, loss: 0.343441
global_step: 26843, epoch: 72, loss: 0.512996
global_step: 26844, epoch: 72, loss: 0.486741
global_step: 26845, epoch: 72, loss: 0.405580
global_step: 26846, epoch: 72, loss: 0.380546
global_step: 26847, epoch: 72, loss: 0.449516
global_step: 26848, epoch: 72, loss: 0.433429
global_step: 26849, epoch: 72, loss: 0.531332
global_step: 26850, epoch: 72, loss: 0.412198
global_step: 26851, epoch: 72, loss: 0.503042
global_step: 26852, epoch: 72, loss: 0.482436
global_step: 26853, epoch: 72, loss: 0.443176
global_step: 26854, epoch: 72, loss: 0.467816
global_step: 26855, epoch: 72, loss: 0.406992
global_step: 26856, epoch: 72, loss: 0.456600
global_step: 26857, epoch: 72, loss: 0.449697
global_step: 26858, epoch: 72, loss: 0.455186
global_step: 26859, epoch: 72, loss: 0.493944
global_step: 26860, epoch: 72, loss: 0.458928
global_step: 26861, epoch: 72, loss: 0.434824
global_step: 26862, epoch: 72, loss: 0.462659
global_step: 26863, epoch: 72, loss: 0.516321
global_step: 26864, epoch: 72, loss: 0.362044
global_step: 26865, epoch: 72, loss: 0.481257
global_step: 26866, epoch: 72, loss: 0.464808
global_step: 26867, epoch: 72, loss: 0.493834
global_step: 26868, epoch: 72, loss: 0.549535
global_step: 26869, epoch: 72, loss: 0.421587
global_step: 26870, epoch: 72, loss: 0.461955
global_step: 26871, epoch: 72, loss: 0.432317
global_step: 26872, epoch: 72, loss: 0.474400
global_step: 26873, epoch: 72, loss: 0.481144
global_step: 26874, epoch: 72, loss: 0.403033
global_step: 26875, epoch: 72, loss: 0.442967
global_step: 26876, epoch: 72, loss: 0.539423
global_step: 26877, epoch: 72, loss: 0.433933
global_step: 26878, epoch: 72, loss: 0.431375
global_step: 26879, epoch: 72, loss: 0.504250
global_step: 26880, epoch: 72, loss: 0.609492
epoch: 72
train	acc: 0.9414	macro: p 0.9483, r 0.8773, f1: 0.9065	micro: p 0.9414, r 0.9414, f1 0.9414	weighted_f1:0.9406
dev	acc: 0.5221	macro: p 0.3531, r 0.3036, f1: 0.3005	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4818
test	acc: 0.5778	macro: p 0.3898, r 0.3226, f1: 0.3272	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5475
global_step: 26881, epoch: 73, loss: 0.431430
global_step: 26882, epoch: 73, loss: 0.411153
global_step: 26883, epoch: 73, loss: 0.311496
global_step: 26884, epoch: 73, loss: 0.493880
global_step: 26885, epoch: 73, loss: 0.429298
global_step: 26886, epoch: 73, loss: 0.430054
global_step: 26887, epoch: 73, loss: 0.440868
global_step: 26888, epoch: 73, loss: 0.499172
global_step: 26889, epoch: 73, loss: 0.535703
global_step: 26890, epoch: 73, loss: 0.425786
global_step: 26891, epoch: 73, loss: 0.429375
global_step: 26892, epoch: 73, loss: 0.469488
global_step: 26893, epoch: 73, loss: 0.407174
global_step: 26894, epoch: 73, loss: 0.476919
global_step: 26895, epoch: 73, loss: 0.420096
global_step: 26896, epoch: 73, loss: 0.359198
global_step: 26897, epoch: 73, loss: 0.429423
global_step: 26898, epoch: 73, loss: 0.452511
global_step: 26899, epoch: 73, loss: 0.459521
global_step: 26900, epoch: 73, loss: 0.422500
global_step: 26901, epoch: 73, loss: 0.490196
global_step: 26902, epoch: 73, loss: 0.425334
global_step: 26903, epoch: 73, loss: 0.458387
global_step: 26904, epoch: 73, loss: 0.403563
global_step: 26905, epoch: 73, loss: 0.416531
global_step: 26906, epoch: 73, loss: 0.459472
global_step: 26907, epoch: 73, loss: 0.466627
global_step: 26908, epoch: 73, loss: 0.449155
global_step: 26909, epoch: 73, loss: 0.412431
global_step: 26910, epoch: 73, loss: 0.478946
global_step: 26911, epoch: 73, loss: 0.443330
global_step: 26912, epoch: 73, loss: 0.397937
global_step: 26913, epoch: 73, loss: 0.393386
global_step: 26914, epoch: 73, loss: 0.399089
global_step: 26915, epoch: 73, loss: 0.372399
global_step: 26916, epoch: 73, loss: 0.466728
global_step: 26917, epoch: 73, loss: 0.500231
global_step: 26918, epoch: 73, loss: 0.464376
global_step: 26919, epoch: 73, loss: 0.446818
global_step: 26920, epoch: 73, loss: 0.066262
epoch: 73
train	acc: 0.9434	macro: p 0.9540, r 0.8855, f1: 0.9150	micro: p 0.9434, r 0.9434, f1 0.9434	weighted_f1:0.9428
dev	acc: 0.5194	macro: p 0.3669, r 0.2953, f1: 0.2921	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4748
test	acc: 0.5920	macro: p 0.3864, r 0.3279, f1: 0.3335	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5574
global_step: 26921, epoch: 74, loss: 0.382523
global_step: 26922, epoch: 74, loss: 0.364665
global_step: 26923, epoch: 74, loss: 0.364791
global_step: 26924, epoch: 74, loss: 0.428390
global_step: 26925, epoch: 74, loss: 0.399544
global_step: 26926, epoch: 74, loss: 0.434395
global_step: 26927, epoch: 74, loss: 0.404764
global_step: 26928, epoch: 74, loss: 0.416630
global_step: 26929, epoch: 74, loss: 0.468417
global_step: 26930, epoch: 74, loss: 0.554719
global_step: 26931, epoch: 74, loss: 0.389685
global_step: 26932, epoch: 74, loss: 0.421497
global_step: 26933, epoch: 74, loss: 0.396860
global_step: 26934, epoch: 74, loss: 0.464935
global_step: 26935, epoch: 74, loss: 0.426178
global_step: 26936, epoch: 74, loss: 0.474838
global_step: 26937, epoch: 74, loss: 0.440205
global_step: 26938, epoch: 74, loss: 0.432392
global_step: 26939, epoch: 74, loss: 0.384789
global_step: 26940, epoch: 74, loss: 0.491887
global_step: 26941, epoch: 74, loss: 0.449287
global_step: 26942, epoch: 74, loss: 0.519064
global_step: 26943, epoch: 74, loss: 0.444386
global_step: 26944, epoch: 74, loss: 0.494016
global_step: 26945, epoch: 74, loss: 0.424213
global_step: 26946, epoch: 74, loss: 0.435614
global_step: 26947, epoch: 74, loss: 0.385454
global_step: 26948, epoch: 74, loss: 0.468572
global_step: 26949, epoch: 74, loss: 0.530760
global_step: 26950, epoch: 74, loss: 0.554761
global_step: 26951, epoch: 74, loss: 0.467750
global_step: 26952, epoch: 74, loss: 0.457156
global_step: 26953, epoch: 74, loss: 0.480679
global_step: 26954, epoch: 74, loss: 0.469009
global_step: 26955, epoch: 74, loss: 0.514360
global_step: 26956, epoch: 74, loss: 0.411916
global_step: 26957, epoch: 74, loss: 0.445268
global_step: 26958, epoch: 74, loss: 0.502770
global_step: 26959, epoch: 74, loss: 0.446686
global_step: 26960, epoch: 74, loss: 1.173569
epoch: 74
train	acc: 0.9402	macro: p 0.9552, r 0.8855, f1: 0.9161	micro: p 0.9402, r 0.9402, f1 0.9402	weighted_f1:0.9396
dev	acc: 0.5266	macro: p 0.3439, r 0.2885, f1: 0.2842	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4714
test	acc: 0.5904	macro: p 0.3755, r 0.3141, f1: 0.3248	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5458
global_step: 26961, epoch: 75, loss: 0.454949
global_step: 26962, epoch: 75, loss: 0.418639
global_step: 26963, epoch: 75, loss: 0.493799
global_step: 26964, epoch: 75, loss: 0.461404
global_step: 26965, epoch: 75, loss: 0.399695
global_step: 26966, epoch: 75, loss: 0.429399
global_step: 26967, epoch: 75, loss: 0.442210
global_step: 26968, epoch: 75, loss: 0.430097
global_step: 26969, epoch: 75, loss: 0.446025
global_step: 26970, epoch: 75, loss: 0.372277
global_step: 26971, epoch: 75, loss: 0.454756
global_step: 26972, epoch: 75, loss: 0.476470
global_step: 26973, epoch: 75, loss: 0.413268
global_step: 26974, epoch: 75, loss: 0.401268
global_step: 26975, epoch: 75, loss: 0.391853
global_step: 26976, epoch: 75, loss: 0.554922
global_step: 26977, epoch: 75, loss: 0.419809
global_step: 26978, epoch: 75, loss: 0.435160
global_step: 26979, epoch: 75, loss: 0.405161
global_step: 26980, epoch: 75, loss: 0.431905
global_step: 26981, epoch: 75, loss: 0.457233
global_step: 26982, epoch: 75, loss: 0.514989
global_step: 26983, epoch: 75, loss: 0.442139
global_step: 26984, epoch: 75, loss: 0.441196
global_step: 26985, epoch: 75, loss: 0.477922
global_step: 26986, epoch: 75, loss: 0.378826
global_step: 26987, epoch: 75, loss: 0.559756
global_step: 26988, epoch: 75, loss: 0.435415
global_step: 26989, epoch: 75, loss: 0.453318
global_step: 26990, epoch: 75, loss: 0.434290
global_step: 26991, epoch: 75, loss: 0.431124
global_step: 26992, epoch: 75, loss: 0.442308
global_step: 26993, epoch: 75, loss: 0.305432
global_step: 26994, epoch: 75, loss: 0.410060
global_step: 26995, epoch: 75, loss: 0.337458
global_step: 26996, epoch: 75, loss: 0.388156
global_step: 26997, epoch: 75, loss: 0.464467
global_step: 26998, epoch: 75, loss: 0.474816
global_step: 26999, epoch: 75, loss: 0.424003
global_step: 27000, epoch: 75, loss: 0.426500
epoch: 75
train	acc: 0.9426	macro: p 0.9519, r 0.8873, f1: 0.9152	micro: p 0.9426, r 0.9426, f1 0.9426	weighted_f1:0.9421
dev	acc: 0.5266	macro: p 0.3730, r 0.3009, f1: 0.2935	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4781
test	acc: 0.5870	macro: p 0.3764, r 0.3212, f1: 0.3249	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5490
global_step: 27001, epoch: 76, loss: 0.387843
global_step: 27002, epoch: 76, loss: 0.410642
global_step: 27003, epoch: 76, loss: 0.386962
global_step: 27004, epoch: 76, loss: 0.403208
global_step: 27005, epoch: 76, loss: 0.407146
global_step: 27006, epoch: 76, loss: 0.406510
global_step: 27007, epoch: 76, loss: 0.416778
global_step: 27008, epoch: 76, loss: 0.406795
global_step: 27009, epoch: 76, loss: 0.420782
global_step: 27010, epoch: 76, loss: 0.373737
global_step: 27011, epoch: 76, loss: 0.409346
global_step: 27012, epoch: 76, loss: 0.454719
global_step: 27013, epoch: 76, loss: 0.396255
global_step: 27014, epoch: 76, loss: 0.430440
global_step: 27015, epoch: 76, loss: 0.410659
global_step: 27016, epoch: 76, loss: 0.346647
global_step: 27017, epoch: 76, loss: 0.432769
global_step: 27018, epoch: 76, loss: 0.407254
global_step: 27019, epoch: 76, loss: 0.427256
global_step: 27020, epoch: 76, loss: 0.496249
global_step: 27021, epoch: 76, loss: 0.488148
global_step: 27022, epoch: 76, loss: 0.482911
global_step: 27023, epoch: 76, loss: 0.413963
global_step: 27024, epoch: 76, loss: 0.398426
global_step: 27025, epoch: 76, loss: 0.445070
global_step: 27026, epoch: 76, loss: 0.410985
global_step: 27027, epoch: 76, loss: 0.408355
global_step: 27028, epoch: 76, loss: 0.466206
global_step: 27029, epoch: 76, loss: 0.379696
global_step: 27030, epoch: 76, loss: 0.461861
global_step: 27031, epoch: 76, loss: 0.380731
global_step: 27032, epoch: 76, loss: 0.364245
global_step: 27033, epoch: 76, loss: 0.457539
global_step: 27034, epoch: 76, loss: 0.384696
global_step: 27035, epoch: 76, loss: 0.476199
global_step: 27036, epoch: 76, loss: 0.425505
global_step: 27037, epoch: 76, loss: 0.387398
global_step: 27038, epoch: 76, loss: 0.326012
global_step: 27039, epoch: 76, loss: 0.428354
global_step: 27040, epoch: 76, loss: 1.378748
epoch: 76
train	acc: 0.9448	macro: p 0.9528, r 0.8948, f1: 0.9202	micro: p 0.9448, r 0.9448, f1 0.9448	weighted_f1:0.9445
dev	acc: 0.5230	macro: p 0.3260, r 0.3017, f1: 0.2931	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4761
test	acc: 0.5820	macro: p 0.3856, r 0.3209, f1: 0.3218	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5452
global_step: 27041, epoch: 77, loss: 0.389620
global_step: 27042, epoch: 77, loss: 0.445873
global_step: 27043, epoch: 77, loss: 0.444630
global_step: 27044, epoch: 77, loss: 0.462247
global_step: 27045, epoch: 77, loss: 0.426359
global_step: 27046, epoch: 77, loss: 0.461086
global_step: 27047, epoch: 77, loss: 0.379313
global_step: 27048, epoch: 77, loss: 0.452738
global_step: 27049, epoch: 77, loss: 0.411296
global_step: 27050, epoch: 77, loss: 0.473358
global_step: 27051, epoch: 77, loss: 0.365238
global_step: 27052, epoch: 77, loss: 0.375276
global_step: 27053, epoch: 77, loss: 0.466147
global_step: 27054, epoch: 77, loss: 0.371105
global_step: 27055, epoch: 77, loss: 0.469752
global_step: 27056, epoch: 77, loss: 0.349586
global_step: 27057, epoch: 77, loss: 0.363810
global_step: 27058, epoch: 77, loss: 0.352664
global_step: 27059, epoch: 77, loss: 0.343776
global_step: 27060, epoch: 77, loss: 0.425810
global_step: 27061, epoch: 77, loss: 0.394851
global_step: 27062, epoch: 77, loss: 0.441828
global_step: 27063, epoch: 77, loss: 0.363887
global_step: 27064, epoch: 77, loss: 0.409615
global_step: 27065, epoch: 77, loss: 0.421041
global_step: 27066, epoch: 77, loss: 0.428541
global_step: 27067, epoch: 77, loss: 0.415305
global_step: 27068, epoch: 77, loss: 0.470581
global_step: 27069, epoch: 77, loss: 0.390264
global_step: 27070, epoch: 77, loss: 0.377418
global_step: 27071, epoch: 77, loss: 0.449342
global_step: 27072, epoch: 77, loss: 0.412326
global_step: 27073, epoch: 77, loss: 0.357123
global_step: 27074, epoch: 77, loss: 0.395801
global_step: 27075, epoch: 77, loss: 0.438232
global_step: 27076, epoch: 77, loss: 0.377111
global_step: 27077, epoch: 77, loss: 0.412849
global_step: 27078, epoch: 77, loss: 0.359505
global_step: 27079, epoch: 77, loss: 0.444358
global_step: 27080, epoch: 77, loss: 0.095348
epoch: 77
train	acc: 0.9456	macro: p 0.9543, r 0.8913, f1: 0.9186	micro: p 0.9456, r 0.9456, f1 0.9456	weighted_f1:0.9451
dev	acc: 0.5248	macro: p 0.3717, r 0.2977, f1: 0.2940	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4780
test	acc: 0.5874	macro: p 0.3959, r 0.3196, f1: 0.3244	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5497
global_step: 27081, epoch: 78, loss: 0.398956
global_step: 27082, epoch: 78, loss: 0.356143
global_step: 27083, epoch: 78, loss: 0.351681
global_step: 27084, epoch: 78, loss: 0.506357
global_step: 27085, epoch: 78, loss: 0.340672
global_step: 27086, epoch: 78, loss: 0.328060
global_step: 27087, epoch: 78, loss: 0.413482
global_step: 27088, epoch: 78, loss: 0.390379
global_step: 27089, epoch: 78, loss: 0.439701
global_step: 27090, epoch: 78, loss: 0.454292
global_step: 27091, epoch: 78, loss: 0.439270
global_step: 27092, epoch: 78, loss: 0.413519
global_step: 27093, epoch: 78, loss: 0.489576
global_step: 27094, epoch: 78, loss: 0.431787
global_step: 27095, epoch: 78, loss: 0.340143
global_step: 27096, epoch: 78, loss: 0.368761
global_step: 27097, epoch: 78, loss: 0.405239
global_step: 27098, epoch: 78, loss: 0.501013
global_step: 27099, epoch: 78, loss: 0.415912
global_step: 27100, epoch: 78, loss: 0.455222
global_step: 27101, epoch: 78, loss: 0.329160
global_step: 27102, epoch: 78, loss: 0.370195
global_step: 27103, epoch: 78, loss: 0.421674
global_step: 27104, epoch: 78, loss: 0.402156
global_step: 27105, epoch: 78, loss: 0.424237
global_step: 27106, epoch: 78, loss: 0.446456
global_step: 27107, epoch: 78, loss: 0.378017
global_step: 27108, epoch: 78, loss: 0.343367
global_step: 27109, epoch: 78, loss: 0.324180
global_step: 27110, epoch: 78, loss: 0.528232
global_step: 27111, epoch: 78, loss: 0.427578
global_step: 27112, epoch: 78, loss: 0.517365
global_step: 27113, epoch: 78, loss: 0.394022
global_step: 27114, epoch: 78, loss: 0.484913
global_step: 27115, epoch: 78, loss: 0.403036
global_step: 27116, epoch: 78, loss: 0.436764
global_step: 27117, epoch: 78, loss: 0.371374
global_step: 27118, epoch: 78, loss: 0.386910
global_step: 27119, epoch: 78, loss: 0.445157
global_step: 27120, epoch: 78, loss: 0.259531
epoch: 78
train	acc: 0.9450	macro: p 0.9560, r 0.8987, f1: 0.9239	micro: p 0.9450, r 0.9450, f1 0.9450	weighted_f1:0.9448
dev	acc: 0.5113	macro: p 0.3435, r 0.2963, f1: 0.2880	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4696
test	acc: 0.5766	macro: p 0.3637, r 0.3194, f1: 0.3218	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5447
global_step: 27121, epoch: 79, loss: 0.431031
global_step: 27122, epoch: 79, loss: 0.364256
global_step: 27123, epoch: 79, loss: 0.402795
global_step: 27124, epoch: 79, loss: 0.401195
global_step: 27125, epoch: 79, loss: 0.347163
global_step: 27126, epoch: 79, loss: 0.388692
global_step: 27127, epoch: 79, loss: 0.441014
global_step: 27128, epoch: 79, loss: 0.410249
global_step: 27129, epoch: 79, loss: 0.408293
global_step: 27130, epoch: 79, loss: 0.309908
global_step: 27131, epoch: 79, loss: 0.360004
global_step: 27132, epoch: 79, loss: 0.438116
global_step: 27133, epoch: 79, loss: 0.334906
global_step: 27134, epoch: 79, loss: 0.332700
global_step: 27135, epoch: 79, loss: 0.352152
global_step: 27136, epoch: 79, loss: 0.511568
global_step: 27137, epoch: 79, loss: 0.368034
global_step: 27138, epoch: 79, loss: 0.427709
global_step: 27139, epoch: 79, loss: 0.443720
global_step: 27140, epoch: 79, loss: 0.456188
global_step: 27141, epoch: 79, loss: 0.440389
global_step: 27142, epoch: 79, loss: 0.456736
global_step: 27143, epoch: 79, loss: 0.416565
global_step: 27144, epoch: 79, loss: 0.454778
global_step: 27145, epoch: 79, loss: 0.419039
global_step: 27146, epoch: 79, loss: 0.402606
global_step: 27147, epoch: 79, loss: 0.399232
global_step: 27148, epoch: 79, loss: 0.417789
global_step: 27149, epoch: 79, loss: 0.359950
global_step: 27150, epoch: 79, loss: 0.399527
global_step: 27151, epoch: 79, loss: 0.422816
global_step: 27152, epoch: 79, loss: 0.373616
global_step: 27153, epoch: 79, loss: 0.394313
global_step: 27154, epoch: 79, loss: 0.443657
global_step: 27155, epoch: 79, loss: 0.473553
global_step: 27156, epoch: 79, loss: 0.432519
global_step: 27157, epoch: 79, loss: 0.509665
global_step: 27158, epoch: 79, loss: 0.443208
global_step: 27159, epoch: 79, loss: 0.393833
global_step: 27160, epoch: 79, loss: 0.200378
epoch: 79
train	acc: 0.9477	macro: p 0.9581, r 0.8969, f1: 0.9238	micro: p 0.9477, r 0.9477, f1 0.9477	weighted_f1:0.9473
dev	acc: 0.5356	macro: p 0.3828, r 0.3056, f1: 0.3049	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4891
test	acc: 0.5908	macro: p 0.3953, r 0.3182, f1: 0.3238	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5514
global_step: 27161, epoch: 80, loss: 0.399629
global_step: 27162, epoch: 80, loss: 0.439464
global_step: 27163, epoch: 80, loss: 0.362459
global_step: 27164, epoch: 80, loss: 0.411368
global_step: 27165, epoch: 80, loss: 0.324529
global_step: 27166, epoch: 80, loss: 0.410559
global_step: 27167, epoch: 80, loss: 0.430303
global_step: 27168, epoch: 80, loss: 0.463420
global_step: 27169, epoch: 80, loss: 0.406005
global_step: 27170, epoch: 80, loss: 0.327307
global_step: 27171, epoch: 80, loss: 0.370452
global_step: 27172, epoch: 80, loss: 0.338122
global_step: 27173, epoch: 80, loss: 0.383251
global_step: 27174, epoch: 80, loss: 0.404338
global_step: 27175, epoch: 80, loss: 0.436279
global_step: 27176, epoch: 80, loss: 0.335398
global_step: 27177, epoch: 80, loss: 0.461014
global_step: 27178, epoch: 80, loss: 0.489992
global_step: 27179, epoch: 80, loss: 0.412683
global_step: 27180, epoch: 80, loss: 0.371488
global_step: 27181, epoch: 80, loss: 0.438387
global_step: 27182, epoch: 80, loss: 0.397372
global_step: 27183, epoch: 80, loss: 0.414922
global_step: 27184, epoch: 80, loss: 0.426694
global_step: 27185, epoch: 80, loss: 0.437623
global_step: 27186, epoch: 80, loss: 0.364141
global_step: 27187, epoch: 80, loss: 0.461453
global_step: 27188, epoch: 80, loss: 0.387183
global_step: 27189, epoch: 80, loss: 0.394087
global_step: 27190, epoch: 80, loss: 0.328337
global_step: 27191, epoch: 80, loss: 0.349455
global_step: 27192, epoch: 80, loss: 0.423042
global_step: 27193, epoch: 80, loss: 0.402812
global_step: 27194, epoch: 80, loss: 0.418128
global_step: 27195, epoch: 80, loss: 0.431761
global_step: 27196, epoch: 80, loss: 0.447208
global_step: 27197, epoch: 80, loss: 0.360433
global_step: 27198, epoch: 80, loss: 0.395488
global_step: 27199, epoch: 80, loss: 0.463783
global_step: 27200, epoch: 80, loss: 0.786536
epoch: 80
train	acc: 0.9482	macro: p 0.9555, r 0.9027, f1: 0.9259	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9479
dev	acc: 0.5203	macro: p 0.3112, r 0.3026, f1: 0.2989	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4824
test	acc: 0.5824	macro: p 0.3769, r 0.3259, f1: 0.3291	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5530
global_step: 27201, epoch: 81, loss: 0.431276
global_step: 27202, epoch: 81, loss: 0.351365
global_step: 27203, epoch: 81, loss: 0.393282
global_step: 27204, epoch: 81, loss: 0.442018
global_step: 27205, epoch: 81, loss: 0.436408
global_step: 27206, epoch: 81, loss: 0.439761
global_step: 27207, epoch: 81, loss: 0.363369
global_step: 27208, epoch: 81, loss: 0.376456
global_step: 27209, epoch: 81, loss: 0.440543
global_step: 27210, epoch: 81, loss: 0.392716
global_step: 27211, epoch: 81, loss: 0.473982
global_step: 27212, epoch: 81, loss: 0.380261
global_step: 27213, epoch: 81, loss: 0.395928
global_step: 27214, epoch: 81, loss: 0.357877
global_step: 27215, epoch: 81, loss: 0.408561
global_step: 27216, epoch: 81, loss: 0.408190
global_step: 27217, epoch: 81, loss: 0.433006
global_step: 27218, epoch: 81, loss: 0.421287
global_step: 27219, epoch: 81, loss: 0.398861
global_step: 27220, epoch: 81, loss: 0.411519
global_step: 27221, epoch: 81, loss: 0.341828
global_step: 27222, epoch: 81, loss: 0.386518
global_step: 27223, epoch: 81, loss: 0.359947
global_step: 27224, epoch: 81, loss: 0.422127
global_step: 27225, epoch: 81, loss: 0.415480
global_step: 27226, epoch: 81, loss: 0.408335
global_step: 27227, epoch: 81, loss: 0.389415
global_step: 27228, epoch: 81, loss: 0.474216
global_step: 27229, epoch: 81, loss: 0.395310
global_step: 27230, epoch: 81, loss: 0.344844
global_step: 27231, epoch: 81, loss: 0.501946
global_step: 27232, epoch: 81, loss: 0.351963
global_step: 27233, epoch: 81, loss: 0.334223
global_step: 27234, epoch: 81, loss: 0.404861
global_step: 27235, epoch: 81, loss: 0.370198
global_step: 27236, epoch: 81, loss: 0.446912
global_step: 27237, epoch: 81, loss: 0.410598
global_step: 27238, epoch: 81, loss: 0.441074
global_step: 27239, epoch: 81, loss: 0.477198
global_step: 27240, epoch: 81, loss: 0.057019
epoch: 81
train	acc: 0.9498	macro: p 0.9612, r 0.9064, f1: 0.9311	micro: p 0.9498, r 0.9498, f1 0.9498	weighted_f1:0.9495
dev	acc: 0.5383	macro: p 0.3891, r 0.3034, f1: 0.3016	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4870
test	acc: 0.5877	macro: p 0.3694, r 0.3132, f1: 0.3207	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5442
global_step: 27241, epoch: 82, loss: 0.345827
global_step: 27242, epoch: 82, loss: 0.418498
global_step: 27243, epoch: 82, loss: 0.384529
global_step: 27244, epoch: 82, loss: 0.321822
global_step: 27245, epoch: 82, loss: 0.322956
global_step: 27246, epoch: 82, loss: 0.460367
global_step: 27247, epoch: 82, loss: 0.420204
global_step: 27248, epoch: 82, loss: 0.316974
global_step: 27249, epoch: 82, loss: 0.416794
global_step: 27250, epoch: 82, loss: 0.488797
global_step: 27251, epoch: 82, loss: 0.404258
global_step: 27252, epoch: 82, loss: 0.382074
global_step: 27253, epoch: 82, loss: 0.456281
global_step: 27254, epoch: 82, loss: 0.475916
global_step: 27255, epoch: 82, loss: 0.481763
global_step: 27256, epoch: 82, loss: 0.318537
global_step: 27257, epoch: 82, loss: 0.404195
global_step: 27258, epoch: 82, loss: 0.380059
global_step: 27259, epoch: 82, loss: 0.343095
global_step: 27260, epoch: 82, loss: 0.435551
global_step: 27261, epoch: 82, loss: 0.389086
global_step: 27262, epoch: 82, loss: 0.422524
global_step: 27263, epoch: 82, loss: 0.438570
global_step: 27264, epoch: 82, loss: 0.362548
global_step: 27265, epoch: 82, loss: 0.364675
global_step: 27266, epoch: 82, loss: 0.448091
global_step: 27267, epoch: 82, loss: 0.405109
global_step: 27268, epoch: 82, loss: 0.413906
global_step: 27269, epoch: 82, loss: 0.320197
global_step: 27270, epoch: 82, loss: 0.465087
global_step: 27271, epoch: 82, loss: 0.405046
global_step: 27272, epoch: 82, loss: 0.406873
global_step: 27273, epoch: 82, loss: 0.404608
global_step: 27274, epoch: 82, loss: 0.344004
global_step: 27275, epoch: 82, loss: 0.378421
global_step: 27276, epoch: 82, loss: 0.412656
global_step: 27277, epoch: 82, loss: 0.396015
global_step: 27278, epoch: 82, loss: 0.361218
global_step: 27279, epoch: 82, loss: 0.329640
global_step: 27280, epoch: 82, loss: 1.405780
epoch: 82
train	acc: 0.9497	macro: p 0.9596, r 0.9054, f1: 0.9297	micro: p 0.9497, r 0.9497, f1 0.9497	weighted_f1:0.9494
dev	acc: 0.5374	macro: p 0.3471, r 0.3053, f1: 0.3032	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4895
test	acc: 0.5881	macro: p 0.3833, r 0.3158, f1: 0.3214	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5478
global_step: 27281, epoch: 83, loss: 0.356808
global_step: 27282, epoch: 83, loss: 0.384220
global_step: 27283, epoch: 83, loss: 0.438095
global_step: 27284, epoch: 83, loss: 0.332927
global_step: 27285, epoch: 83, loss: 0.327253
global_step: 27286, epoch: 83, loss: 0.366074
global_step: 27287, epoch: 83, loss: 0.435633
global_step: 27288, epoch: 83, loss: 0.341368
global_step: 27289, epoch: 83, loss: 0.483956
global_step: 27290, epoch: 83, loss: 0.363617
global_step: 27291, epoch: 83, loss: 0.447891
global_step: 27292, epoch: 83, loss: 0.449102
global_step: 27293, epoch: 83, loss: 0.438762
global_step: 27294, epoch: 83, loss: 0.330274
global_step: 27295, epoch: 83, loss: 0.407858
global_step: 27296, epoch: 83, loss: 0.335386
global_step: 27297, epoch: 83, loss: 0.408893
global_step: 27298, epoch: 83, loss: 0.401981
global_step: 27299, epoch: 83, loss: 0.345909
global_step: 27300, epoch: 83, loss: 0.439989
global_step: 27301, epoch: 83, loss: 0.459350
global_step: 27302, epoch: 83, loss: 0.332079
global_step: 27303, epoch: 83, loss: 0.395280
global_step: 27304, epoch: 83, loss: 0.364532
global_step: 27305, epoch: 83, loss: 0.368893
global_step: 27306, epoch: 83, loss: 0.500815
global_step: 27307, epoch: 83, loss: 0.345611
global_step: 27308, epoch: 83, loss: 0.350452
global_step: 27309, epoch: 83, loss: 0.435812
global_step: 27310, epoch: 83, loss: 0.374259
global_step: 27311, epoch: 83, loss: 0.388282
global_step: 27312, epoch: 83, loss: 0.437948
global_step: 27313, epoch: 83, loss: 0.404585
global_step: 27314, epoch: 83, loss: 0.444194
global_step: 27315, epoch: 83, loss: 0.376067
global_step: 27316, epoch: 83, loss: 0.407170
global_step: 27317, epoch: 83, loss: 0.450408
global_step: 27318, epoch: 83, loss: 0.374228
global_step: 27319, epoch: 83, loss: 0.435832
global_step: 27320, epoch: 83, loss: 0.260929
epoch: 83
train	acc: 0.9512	macro: p 0.9610, r 0.9077, f1: 0.9317	micro: p 0.9512, r 0.9512, f1 0.9512	weighted_f1:0.9509
dev	acc: 0.5365	macro: p 0.3874, r 0.3052, f1: 0.3053	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4897
test	acc: 0.5874	macro: p 0.3740, r 0.3192, f1: 0.3264	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5505
global_step: 27321, epoch: 84, loss: 0.354885
global_step: 27322, epoch: 84, loss: 0.397464
global_step: 27323, epoch: 84, loss: 0.430296
global_step: 27324, epoch: 84, loss: 0.364674
global_step: 27325, epoch: 84, loss: 0.437256
global_step: 27326, epoch: 84, loss: 0.351669
global_step: 27327, epoch: 84, loss: 0.332060
global_step: 27328, epoch: 84, loss: 0.428129
global_step: 27329, epoch: 84, loss: 0.367012
global_step: 27330, epoch: 84, loss: 0.378306
global_step: 27331, epoch: 84, loss: 0.432267
global_step: 27332, epoch: 84, loss: 0.424497
global_step: 27333, epoch: 84, loss: 0.331546
global_step: 27334, epoch: 84, loss: 0.510323
global_step: 27335, epoch: 84, loss: 0.407332
global_step: 27336, epoch: 84, loss: 0.390070
global_step: 27337, epoch: 84, loss: 0.404186
global_step: 27338, epoch: 84, loss: 0.359814
global_step: 27339, epoch: 84, loss: 0.318601
global_step: 27340, epoch: 84, loss: 0.416183
global_step: 27341, epoch: 84, loss: 0.407385
global_step: 27342, epoch: 84, loss: 0.348339
global_step: 27343, epoch: 84, loss: 0.348318
global_step: 27344, epoch: 84, loss: 0.339602
global_step: 27345, epoch: 84, loss: 0.383846
global_step: 27346, epoch: 84, loss: 0.347309
global_step: 27347, epoch: 84, loss: 0.415461
global_step: 27348, epoch: 84, loss: 0.291862
global_step: 27349, epoch: 84, loss: 0.370284
global_step: 27350, epoch: 84, loss: 0.363641
global_step: 27351, epoch: 84, loss: 0.507420
global_step: 27352, epoch: 84, loss: 0.311946
global_step: 27353, epoch: 84, loss: 0.296456
global_step: 27354, epoch: 84, loss: 0.300017
global_step: 27355, epoch: 84, loss: 0.353185
global_step: 27356, epoch: 84, loss: 0.350288
global_step: 27357, epoch: 84, loss: 0.346605
global_step: 27358, epoch: 84, loss: 0.336097
global_step: 27359, epoch: 84, loss: 0.346889
global_step: 27360, epoch: 84, loss: 0.256262
epoch: 84
train	acc: 0.9491	macro: p 0.9619, r 0.9060, f1: 0.9313	micro: p 0.9491, r 0.9491, f1 0.9491	weighted_f1:0.9488
dev	acc: 0.5374	macro: p 0.3885, r 0.2990, f1: 0.2952	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4826
test	acc: 0.5877	macro: p 0.3746, r 0.3089, f1: 0.3133	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5418
global_step: 27361, epoch: 85, loss: 0.378241
global_step: 27362, epoch: 85, loss: 0.353808
global_step: 27363, epoch: 85, loss: 0.337526
global_step: 27364, epoch: 85, loss: 0.407235
global_step: 27365, epoch: 85, loss: 0.371447
global_step: 27366, epoch: 85, loss: 0.428376
global_step: 27367, epoch: 85, loss: 0.445817
global_step: 27368, epoch: 85, loss: 0.386728
global_step: 27369, epoch: 85, loss: 0.313049
global_step: 27370, epoch: 85, loss: 0.299953
global_step: 27371, epoch: 85, loss: 0.381016
global_step: 27372, epoch: 85, loss: 0.390313
global_step: 27373, epoch: 85, loss: 0.394902
global_step: 27374, epoch: 85, loss: 0.397077
global_step: 27375, epoch: 85, loss: 0.367352
global_step: 27376, epoch: 85, loss: 0.349317
global_step: 27377, epoch: 85, loss: 0.449485
global_step: 27378, epoch: 85, loss: 0.427356
global_step: 27379, epoch: 85, loss: 0.382881
global_step: 27380, epoch: 85, loss: 0.351375
global_step: 27381, epoch: 85, loss: 0.353577
global_step: 27382, epoch: 85, loss: 0.378172
global_step: 27383, epoch: 85, loss: 0.417652
global_step: 27384, epoch: 85, loss: 0.359429
global_step: 27385, epoch: 85, loss: 0.391458
global_step: 27386, epoch: 85, loss: 0.463561
global_step: 27387, epoch: 85, loss: 0.354866
global_step: 27388, epoch: 85, loss: 0.450128
global_step: 27389, epoch: 85, loss: 0.409386
global_step: 27390, epoch: 85, loss: 0.356068
global_step: 27391, epoch: 85, loss: 0.361701
global_step: 27392, epoch: 85, loss: 0.341536
global_step: 27393, epoch: 85, loss: 0.366700
global_step: 27394, epoch: 85, loss: 0.439801
global_step: 27395, epoch: 85, loss: 0.364401
global_step: 27396, epoch: 85, loss: 0.377085
global_step: 27397, epoch: 85, loss: 0.309929
global_step: 27398, epoch: 85, loss: 0.372744
global_step: 27399, epoch: 85, loss: 0.373708
global_step: 27400, epoch: 85, loss: 0.131067
epoch: 85
train	acc: 0.9535	macro: p 0.9629, r 0.9176, f1: 0.9384	micro: p 0.9535, r 0.9535, f1 0.9535	weighted_f1:0.9533
dev	acc: 0.5221	macro: p 0.3510, r 0.2951, f1: 0.2925	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4750
test	acc: 0.5835	macro: p 0.3665, r 0.3126, f1: 0.3187	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5432
global_step: 27401, epoch: 86, loss: 0.292824
global_step: 27402, epoch: 86, loss: 0.330954
global_step: 27403, epoch: 86, loss: 0.332057
global_step: 27404, epoch: 86, loss: 0.373509
global_step: 27405, epoch: 86, loss: 0.399892
global_step: 27406, epoch: 86, loss: 0.378608
global_step: 27407, epoch: 86, loss: 0.422835
global_step: 27408, epoch: 86, loss: 0.412320
global_step: 27409, epoch: 86, loss: 0.331459
global_step: 27410, epoch: 86, loss: 0.404507
global_step: 27411, epoch: 86, loss: 0.360099
global_step: 27412, epoch: 86, loss: 0.382882
global_step: 27413, epoch: 86, loss: 0.376621
global_step: 27414, epoch: 86, loss: 0.358850
global_step: 27415, epoch: 86, loss: 0.404945
global_step: 27416, epoch: 86, loss: 0.352755
global_step: 27417, epoch: 86, loss: 0.335292
global_step: 27418, epoch: 86, loss: 0.354458
global_step: 27419, epoch: 86, loss: 0.375337
global_step: 27420, epoch: 86, loss: 0.368053
global_step: 27421, epoch: 86, loss: 0.350323
global_step: 27422, epoch: 86, loss: 0.349626
global_step: 27423, epoch: 86, loss: 0.415631
global_step: 27424, epoch: 86, loss: 0.286062
global_step: 27425, epoch: 86, loss: 0.441460
global_step: 27426, epoch: 86, loss: 0.397715
global_step: 27427, epoch: 86, loss: 0.415394
global_step: 27428, epoch: 86, loss: 0.442628
global_step: 27429, epoch: 86, loss: 0.354300
global_step: 27430, epoch: 86, loss: 0.404135
global_step: 27431, epoch: 86, loss: 0.338442
global_step: 27432, epoch: 86, loss: 0.380748
global_step: 27433, epoch: 86, loss: 0.468309
global_step: 27434, epoch: 86, loss: 0.385385
global_step: 27435, epoch: 86, loss: 0.353212
global_step: 27436, epoch: 86, loss: 0.310153
global_step: 27437, epoch: 86, loss: 0.381786
global_step: 27438, epoch: 86, loss: 0.452344
global_step: 27439, epoch: 86, loss: 0.333831
global_step: 27440, epoch: 86, loss: 0.668860
epoch: 86
train	acc: 0.9538	macro: p 0.9625, r 0.9149, f1: 0.9364	micro: p 0.9538, r 0.9538, f1 0.9538	weighted_f1:0.9536
dev	acc: 0.5158	macro: p 0.3546, r 0.2989, f1: 0.2957	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4754
test	acc: 0.5743	macro: p 0.3710, r 0.3160, f1: 0.3173	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5403
global_step: 27441, epoch: 87, loss: 0.454473
global_step: 27442, epoch: 87, loss: 0.387031
global_step: 27443, epoch: 87, loss: 0.273641
global_step: 27444, epoch: 87, loss: 0.391356
global_step: 27445, epoch: 87, loss: 0.369340
global_step: 27446, epoch: 87, loss: 0.350683
global_step: 27447, epoch: 87, loss: 0.357652
global_step: 27448, epoch: 87, loss: 0.388618
global_step: 27449, epoch: 87, loss: 0.373488
global_step: 27450, epoch: 87, loss: 0.380292
global_step: 27451, epoch: 87, loss: 0.439267
global_step: 27452, epoch: 87, loss: 0.419119
global_step: 27453, epoch: 87, loss: 0.386896
global_step: 27454, epoch: 87, loss: 0.390184
global_step: 27455, epoch: 87, loss: 0.327712
global_step: 27456, epoch: 87, loss: 0.363349
global_step: 27457, epoch: 87, loss: 0.433246
global_step: 27458, epoch: 87, loss: 0.360424
global_step: 27459, epoch: 87, loss: 0.321409
global_step: 27460, epoch: 87, loss: 0.398602
global_step: 27461, epoch: 87, loss: 0.396062
global_step: 27462, epoch: 87, loss: 0.391189
global_step: 27463, epoch: 87, loss: 0.474216
global_step: 27464, epoch: 87, loss: 0.333969
global_step: 27465, epoch: 87, loss: 0.358636
global_step: 27466, epoch: 87, loss: 0.547459
global_step: 27467, epoch: 87, loss: 0.477940
global_step: 27468, epoch: 87, loss: 0.330053
global_step: 27469, epoch: 87, loss: 0.396785
global_step: 27470, epoch: 87, loss: 0.393075
global_step: 27471, epoch: 87, loss: 0.316334
global_step: 27472, epoch: 87, loss: 0.348038
global_step: 27473, epoch: 87, loss: 0.431102
global_step: 27474, epoch: 87, loss: 0.346416
global_step: 27475, epoch: 87, loss: 0.369234
global_step: 27476, epoch: 87, loss: 0.385862
global_step: 27477, epoch: 87, loss: 0.460250
global_step: 27478, epoch: 87, loss: 0.304662
global_step: 27479, epoch: 87, loss: 0.353406
global_step: 27480, epoch: 87, loss: 0.415460
epoch: 87
train	acc: 0.9541	macro: p 0.9646, r 0.9147, f1: 0.9373	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9539
dev	acc: 0.5266	macro: p 0.3763, r 0.3052, f1: 0.3068	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4845
test	acc: 0.5816	macro: p 0.3748, r 0.3194, f1: 0.3260	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5474
global_step: 27481, epoch: 88, loss: 0.288454
global_step: 27482, epoch: 88, loss: 0.356161
global_step: 27483, epoch: 88, loss: 0.431773
global_step: 27484, epoch: 88, loss: 0.328136
global_step: 27485, epoch: 88, loss: 0.370542
global_step: 27486, epoch: 88, loss: 0.389052
global_step: 27487, epoch: 88, loss: 0.360344
global_step: 27488, epoch: 88, loss: 0.330696
global_step: 27489, epoch: 88, loss: 0.306336
global_step: 27490, epoch: 88, loss: 0.367090
global_step: 27491, epoch: 88, loss: 0.381012
global_step: 27492, epoch: 88, loss: 0.337435
global_step: 27493, epoch: 88, loss: 0.371985
global_step: 27494, epoch: 88, loss: 0.417636
global_step: 27495, epoch: 88, loss: 0.379937
global_step: 27496, epoch: 88, loss: 0.327894
global_step: 27497, epoch: 88, loss: 0.388918
global_step: 27498, epoch: 88, loss: 0.332369
global_step: 27499, epoch: 88, loss: 0.342678
global_step: 27500, epoch: 88, loss: 0.377603
global_step: 27501, epoch: 88, loss: 0.386727
global_step: 27502, epoch: 88, loss: 0.335549
global_step: 27503, epoch: 88, loss: 0.371696
global_step: 27504, epoch: 88, loss: 0.294178
global_step: 27505, epoch: 88, loss: 0.376609
global_step: 27506, epoch: 88, loss: 0.307329
global_step: 27507, epoch: 88, loss: 0.409209
global_step: 27508, epoch: 88, loss: 0.395089
global_step: 27509, epoch: 88, loss: 0.407347
global_step: 27510, epoch: 88, loss: 0.353126
global_step: 27511, epoch: 88, loss: 0.422883
global_step: 27512, epoch: 88, loss: 0.327816
global_step: 27513, epoch: 88, loss: 0.436999
global_step: 27514, epoch: 88, loss: 0.434447
global_step: 27515, epoch: 88, loss: 0.376939
global_step: 27516, epoch: 88, loss: 0.379093
global_step: 27517, epoch: 88, loss: 0.418494
global_step: 27518, epoch: 88, loss: 0.399652
global_step: 27519, epoch: 88, loss: 0.359234
global_step: 27520, epoch: 88, loss: 0.303380
epoch: 88
train	acc: 0.9566	macro: p 0.9639, r 0.9264, f1: 0.9437	micro: p 0.9566, r 0.9566, f1 0.9566	weighted_f1:0.9565
dev	acc: 0.5086	macro: p 0.3270, r 0.3043, f1: 0.3027	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4753
test	acc: 0.5690	macro: p 0.3542, r 0.3218, f1: 0.3246	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5423
global_step: 27521, epoch: 89, loss: 0.352087
global_step: 27522, epoch: 89, loss: 0.400712
global_step: 27523, epoch: 89, loss: 0.320868
global_step: 27524, epoch: 89, loss: 0.343642
global_step: 27525, epoch: 89, loss: 0.397642
global_step: 27526, epoch: 89, loss: 0.426914
global_step: 27527, epoch: 89, loss: 0.328568
global_step: 27528, epoch: 89, loss: 0.384367
global_step: 27529, epoch: 89, loss: 0.398703
global_step: 27530, epoch: 89, loss: 0.349505
global_step: 27531, epoch: 89, loss: 0.338561
global_step: 27532, epoch: 89, loss: 0.376820
global_step: 27533, epoch: 89, loss: 0.326378
global_step: 27534, epoch: 89, loss: 0.313807
global_step: 27535, epoch: 89, loss: 0.319531
global_step: 27536, epoch: 89, loss: 0.445114
global_step: 27537, epoch: 89, loss: 0.382702
global_step: 27538, epoch: 89, loss: 0.328624
global_step: 27539, epoch: 89, loss: 0.360442
global_step: 27540, epoch: 89, loss: 0.254878
global_step: 27541, epoch: 89, loss: 0.376295
global_step: 27542, epoch: 89, loss: 0.396581
global_step: 27543, epoch: 89, loss: 0.316221
global_step: 27544, epoch: 89, loss: 0.419509
global_step: 27545, epoch: 89, loss: 0.459107
global_step: 27546, epoch: 89, loss: 0.382611
global_step: 27547, epoch: 89, loss: 0.436812
global_step: 27548, epoch: 89, loss: 0.403258
global_step: 27549, epoch: 89, loss: 0.361838
global_step: 27550, epoch: 89, loss: 0.308250
global_step: 27551, epoch: 89, loss: 0.416606
global_step: 27552, epoch: 89, loss: 0.402348
global_step: 27553, epoch: 89, loss: 0.342507
global_step: 27554, epoch: 89, loss: 0.404088
global_step: 27555, epoch: 89, loss: 0.370514
global_step: 27556, epoch: 89, loss: 0.404284
global_step: 27557, epoch: 89, loss: 0.377912
global_step: 27558, epoch: 89, loss: 0.369961
global_step: 27559, epoch: 89, loss: 0.294378
global_step: 27560, epoch: 89, loss: 0.948755
epoch: 89
train	acc: 0.9552	macro: p 0.9635, r 0.9180, f1: 0.9386	micro: p 0.9552, r 0.9552, f1 0.9552	weighted_f1:0.9549
dev	acc: 0.5212	macro: p 0.4478, r 0.3053, f1: 0.3079	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4817
test	acc: 0.5862	macro: p 0.3660, r 0.3215, f1: 0.3265	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5506
global_step: 27561, epoch: 90, loss: 0.385909
global_step: 27562, epoch: 90, loss: 0.316747
global_step: 27563, epoch: 90, loss: 0.437767
global_step: 27564, epoch: 90, loss: 0.325304
global_step: 27565, epoch: 90, loss: 0.342969
global_step: 27566, epoch: 90, loss: 0.329677
global_step: 27567, epoch: 90, loss: 0.344810
global_step: 27568, epoch: 90, loss: 0.407552
global_step: 27569, epoch: 90, loss: 0.330743
global_step: 27570, epoch: 90, loss: 0.333516
global_step: 27571, epoch: 90, loss: 0.337725
global_step: 27572, epoch: 90, loss: 0.327169
global_step: 27573, epoch: 90, loss: 0.391272
global_step: 27574, epoch: 90, loss: 0.371010
global_step: 27575, epoch: 90, loss: 0.324299
global_step: 27576, epoch: 90, loss: 0.328523
global_step: 27577, epoch: 90, loss: 0.373738
global_step: 27578, epoch: 90, loss: 0.329508
global_step: 27579, epoch: 90, loss: 0.349283
global_step: 27580, epoch: 90, loss: 0.367167
global_step: 27581, epoch: 90, loss: 0.355045
global_step: 27582, epoch: 90, loss: 0.322885
global_step: 27583, epoch: 90, loss: 0.405551
global_step: 27584, epoch: 90, loss: 0.362081
global_step: 27585, epoch: 90, loss: 0.284514
global_step: 27586, epoch: 90, loss: 0.383177
global_step: 27587, epoch: 90, loss: 0.353665
global_step: 27588, epoch: 90, loss: 0.400545
global_step: 27589, epoch: 90, loss: 0.323576
global_step: 27590, epoch: 90, loss: 0.376945
global_step: 27591, epoch: 90, loss: 0.282714
global_step: 27592, epoch: 90, loss: 0.378276
global_step: 27593, epoch: 90, loss: 0.375513
global_step: 27594, epoch: 90, loss: 0.335361
global_step: 27595, epoch: 90, loss: 0.404183
global_step: 27596, epoch: 90, loss: 0.310051
global_step: 27597, epoch: 90, loss: 0.323267
global_step: 27598, epoch: 90, loss: 0.345436
global_step: 27599, epoch: 90, loss: 0.325687
global_step: 27600, epoch: 90, loss: 0.794162
epoch: 90
train	acc: 0.9557	macro: p 0.9658, r 0.9199, f1: 0.9410	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9554
dev	acc: 0.5275	macro: p 0.3498, r 0.3003, f1: 0.3003	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4807
test	acc: 0.5904	macro: p 0.3813, r 0.3208, f1: 0.3278	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5517
global_step: 27601, epoch: 91, loss: 0.390052
global_step: 27602, epoch: 91, loss: 0.350261
global_step: 27603, epoch: 91, loss: 0.279255
global_step: 27604, epoch: 91, loss: 0.358672
global_step: 27605, epoch: 91, loss: 0.379963
global_step: 27606, epoch: 91, loss: 0.324814
global_step: 27607, epoch: 91, loss: 0.311645
global_step: 27608, epoch: 91, loss: 0.334655
global_step: 27609, epoch: 91, loss: 0.371075
global_step: 27610, epoch: 91, loss: 0.362704
global_step: 27611, epoch: 91, loss: 0.356950
global_step: 27612, epoch: 91, loss: 0.353372
global_step: 27613, epoch: 91, loss: 0.452245
global_step: 27614, epoch: 91, loss: 0.314450
global_step: 27615, epoch: 91, loss: 0.371229
global_step: 27616, epoch: 91, loss: 0.314706
global_step: 27617, epoch: 91, loss: 0.364304
global_step: 27618, epoch: 91, loss: 0.350229
global_step: 27619, epoch: 91, loss: 0.333555
global_step: 27620, epoch: 91, loss: 0.316108
global_step: 27621, epoch: 91, loss: 0.331843
global_step: 27622, epoch: 91, loss: 0.309165
global_step: 27623, epoch: 91, loss: 0.357442
global_step: 27624, epoch: 91, loss: 0.392025
global_step: 27625, epoch: 91, loss: 0.355752
global_step: 27626, epoch: 91, loss: 0.458077
global_step: 27627, epoch: 91, loss: 0.318013
global_step: 27628, epoch: 91, loss: 0.347681
global_step: 27629, epoch: 91, loss: 0.343910
global_step: 27630, epoch: 91, loss: 0.455231
global_step: 27631, epoch: 91, loss: 0.383086
global_step: 27632, epoch: 91, loss: 0.451652
global_step: 27633, epoch: 91, loss: 0.377034
global_step: 27634, epoch: 91, loss: 0.413018
global_step: 27635, epoch: 91, loss: 0.365208
global_step: 27636, epoch: 91, loss: 0.326507
global_step: 27637, epoch: 91, loss: 0.333136
global_step: 27638, epoch: 91, loss: 0.325237
global_step: 27639, epoch: 91, loss: 0.352862
global_step: 27640, epoch: 91, loss: 0.450427
epoch: 91
train	acc: 0.9534	macro: p 0.9665, r 0.9165, f1: 0.9394	micro: p 0.9534, r 0.9534, f1 0.9534	weighted_f1:0.9532
dev	acc: 0.5293	macro: p 0.3579, r 0.2946, f1: 0.2876	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4718
test	acc: 0.5870	macro: p 0.4001, r 0.3125, f1: 0.3180	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5415
global_step: 27641, epoch: 92, loss: 0.371310
global_step: 27642, epoch: 92, loss: 0.369310
global_step: 27643, epoch: 92, loss: 0.392968
global_step: 27644, epoch: 92, loss: 0.345808
global_step: 27645, epoch: 92, loss: 0.275480
global_step: 27646, epoch: 92, loss: 0.319690
global_step: 27647, epoch: 92, loss: 0.294486
global_step: 27648, epoch: 92, loss: 0.340097
global_step: 27649, epoch: 92, loss: 0.413300
global_step: 27650, epoch: 92, loss: 0.288098
global_step: 27651, epoch: 92, loss: 0.334819
global_step: 27652, epoch: 92, loss: 0.357352
global_step: 27653, epoch: 92, loss: 0.324039
global_step: 27654, epoch: 92, loss: 0.349110
global_step: 27655, epoch: 92, loss: 0.320605
global_step: 27656, epoch: 92, loss: 0.359919
global_step: 27657, epoch: 92, loss: 0.361397
global_step: 27658, epoch: 92, loss: 0.312577
global_step: 27659, epoch: 92, loss: 0.344616
global_step: 27660, epoch: 92, loss: 0.365674
global_step: 27661, epoch: 92, loss: 0.296028
global_step: 27662, epoch: 92, loss: 0.388353
global_step: 27663, epoch: 92, loss: 0.305943
global_step: 27664, epoch: 92, loss: 0.397213
global_step: 27665, epoch: 92, loss: 0.448280
global_step: 27666, epoch: 92, loss: 0.301789
global_step: 27667, epoch: 92, loss: 0.433923
global_step: 27668, epoch: 92, loss: 0.375971
global_step: 27669, epoch: 92, loss: 0.368905
global_step: 27670, epoch: 92, loss: 0.396516
global_step: 27671, epoch: 92, loss: 0.304083
global_step: 27672, epoch: 92, loss: 0.343751
global_step: 27673, epoch: 92, loss: 0.310341
global_step: 27674, epoch: 92, loss: 0.405930
global_step: 27675, epoch: 92, loss: 0.405041
global_step: 27676, epoch: 92, loss: 0.394118
global_step: 27677, epoch: 92, loss: 0.348938
global_step: 27678, epoch: 92, loss: 0.388314
global_step: 27679, epoch: 92, loss: 0.360032
global_step: 27680, epoch: 92, loss: 0.875377
epoch: 92
train	acc: 0.9575	macro: p 0.9665, r 0.9243, f1: 0.9438	micro: p 0.9575, r 0.9575, f1 0.9575	weighted_f1:0.9573
dev	acc: 0.5293	macro: p 0.3740, r 0.3046, f1: 0.3081	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4861
test	acc: 0.5881	macro: p 0.3873, r 0.3230, f1: 0.3315	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5504
global_step: 27681, epoch: 93, loss: 0.344558
global_step: 27682, epoch: 93, loss: 0.352652
global_step: 27683, epoch: 93, loss: 0.351810
global_step: 27684, epoch: 93, loss: 0.361337
global_step: 27685, epoch: 93, loss: 0.322325
global_step: 27686, epoch: 93, loss: 0.361697
global_step: 27687, epoch: 93, loss: 0.349312
global_step: 27688, epoch: 93, loss: 0.313157
global_step: 27689, epoch: 93, loss: 0.265868
global_step: 27690, epoch: 93, loss: 0.392637
global_step: 27691, epoch: 93, loss: 0.312720
global_step: 27692, epoch: 93, loss: 0.374916
global_step: 27693, epoch: 93, loss: 0.464490
global_step: 27694, epoch: 93, loss: 0.391152
global_step: 27695, epoch: 93, loss: 0.292131
global_step: 27696, epoch: 93, loss: 0.348881
global_step: 27697, epoch: 93, loss: 0.328173
global_step: 27698, epoch: 93, loss: 0.316653
global_step: 27699, epoch: 93, loss: 0.368668
global_step: 27700, epoch: 93, loss: 0.300059
global_step: 27701, epoch: 93, loss: 0.389568
global_step: 27702, epoch: 93, loss: 0.444694
global_step: 27703, epoch: 93, loss: 0.378755
global_step: 27704, epoch: 93, loss: 0.333865
global_step: 27705, epoch: 93, loss: 0.463698
global_step: 27706, epoch: 93, loss: 0.315297
global_step: 27707, epoch: 93, loss: 0.306191
global_step: 27708, epoch: 93, loss: 0.253439
global_step: 27709, epoch: 93, loss: 0.433145
global_step: 27710, epoch: 93, loss: 0.378426
global_step: 27711, epoch: 93, loss: 0.415651
global_step: 27712, epoch: 93, loss: 0.416601
global_step: 27713, epoch: 93, loss: 0.320938
global_step: 27714, epoch: 93, loss: 0.369655
global_step: 27715, epoch: 93, loss: 0.302426
global_step: 27716, epoch: 93, loss: 0.369805
global_step: 27717, epoch: 93, loss: 0.353115
global_step: 27718, epoch: 93, loss: 0.354460
global_step: 27719, epoch: 93, loss: 0.392389
global_step: 27720, epoch: 93, loss: 0.030907
epoch: 93
train	acc: 0.9563	macro: p 0.9662, r 0.9207, f1: 0.9417	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9561
dev	acc: 0.5320	macro: p 0.3807, r 0.3033, f1: 0.3049	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4847
test	acc: 0.5935	macro: p 0.3870, r 0.3233, f1: 0.3325	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5543
global_step: 27721, epoch: 94, loss: 0.322440
global_step: 27722, epoch: 94, loss: 0.337258
global_step: 27723, epoch: 94, loss: 0.294084
global_step: 27724, epoch: 94, loss: 0.273380
global_step: 27725, epoch: 94, loss: 0.305198
global_step: 27726, epoch: 94, loss: 0.406201
global_step: 27727, epoch: 94, loss: 0.264931
global_step: 27728, epoch: 94, loss: 0.349519
global_step: 27729, epoch: 94, loss: 0.278384
global_step: 27730, epoch: 94, loss: 0.279814
global_step: 27731, epoch: 94, loss: 0.342877
global_step: 27732, epoch: 94, loss: 0.299066
global_step: 27733, epoch: 94, loss: 0.351837
global_step: 27734, epoch: 94, loss: 0.350623
global_step: 27735, epoch: 94, loss: 0.287879
global_step: 27736, epoch: 94, loss: 0.312987
global_step: 27737, epoch: 94, loss: 0.360045
global_step: 27738, epoch: 94, loss: 0.376165
global_step: 27739, epoch: 94, loss: 0.303680
global_step: 27740, epoch: 94, loss: 0.357808
global_step: 27741, epoch: 94, loss: 0.330540
global_step: 27742, epoch: 94, loss: 0.446744
global_step: 27743, epoch: 94, loss: 0.359479
global_step: 27744, epoch: 94, loss: 0.358067
global_step: 27745, epoch: 94, loss: 0.309718
global_step: 27746, epoch: 94, loss: 0.393852
global_step: 27747, epoch: 94, loss: 0.360672
global_step: 27748, epoch: 94, loss: 0.380635
global_step: 27749, epoch: 94, loss: 0.353157
global_step: 27750, epoch: 94, loss: 0.364641
global_step: 27751, epoch: 94, loss: 0.344498
global_step: 27752, epoch: 94, loss: 0.302213
global_step: 27753, epoch: 94, loss: 0.347025
global_step: 27754, epoch: 94, loss: 0.340779
global_step: 27755, epoch: 94, loss: 0.322241
global_step: 27756, epoch: 94, loss: 0.415411
global_step: 27757, epoch: 94, loss: 0.344542
global_step: 27758, epoch: 94, loss: 0.329671
global_step: 27759, epoch: 94, loss: 0.379929
global_step: 27760, epoch: 94, loss: 0.201248
epoch: 94
train	acc: 0.9594	macro: p 0.9662, r 0.9313, f1: 0.9474	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9593
dev	acc: 0.5185	macro: p 0.3574, r 0.3024, f1: 0.3009	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4764
test	acc: 0.5812	macro: p 0.3622, r 0.3279, f1: 0.3320	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5494
global_step: 27761, epoch: 95, loss: 0.374141
global_step: 27762, epoch: 95, loss: 0.248158
global_step: 27763, epoch: 95, loss: 0.333222
global_step: 27764, epoch: 95, loss: 0.313341
global_step: 27765, epoch: 95, loss: 0.370494
global_step: 27766, epoch: 95, loss: 0.336698
global_step: 27767, epoch: 95, loss: 0.296248
global_step: 27768, epoch: 95, loss: 0.298281
global_step: 27769, epoch: 95, loss: 0.362078
global_step: 27770, epoch: 95, loss: 0.350001
global_step: 27771, epoch: 95, loss: 0.370673
global_step: 27772, epoch: 95, loss: 0.398769
global_step: 27773, epoch: 95, loss: 0.324437
global_step: 27774, epoch: 95, loss: 0.402683
global_step: 27775, epoch: 95, loss: 0.312888
global_step: 27776, epoch: 95, loss: 0.274174
global_step: 27777, epoch: 95, loss: 0.333342
global_step: 27778, epoch: 95, loss: 0.304109
global_step: 27779, epoch: 95, loss: 0.371956
global_step: 27780, epoch: 95, loss: 0.324342
global_step: 27781, epoch: 95, loss: 0.357804
global_step: 27782, epoch: 95, loss: 0.406674
global_step: 27783, epoch: 95, loss: 0.345418
global_step: 27784, epoch: 95, loss: 0.333480
global_step: 27785, epoch: 95, loss: 0.326533
global_step: 27786, epoch: 95, loss: 0.360114
global_step: 27787, epoch: 95, loss: 0.328843
global_step: 27788, epoch: 95, loss: 0.363252
global_step: 27789, epoch: 95, loss: 0.337260
global_step: 27790, epoch: 95, loss: 0.342040
global_step: 27791, epoch: 95, loss: 0.307784
global_step: 27792, epoch: 95, loss: 0.308797
global_step: 27793, epoch: 95, loss: 0.365051
global_step: 27794, epoch: 95, loss: 0.355997
global_step: 27795, epoch: 95, loss: 0.399127
global_step: 27796, epoch: 95, loss: 0.392245
global_step: 27797, epoch: 95, loss: 0.374869
global_step: 27798, epoch: 95, loss: 0.294904
global_step: 27799, epoch: 95, loss: 0.345301
global_step: 27800, epoch: 95, loss: 0.203313
epoch: 95
train	acc: 0.9573	macro: p 0.9656, r 0.9255, f1: 0.9439	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9571
dev	acc: 0.5293	macro: p 0.3834, r 0.3069, f1: 0.3088	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4859
test	acc: 0.5816	macro: p 0.3746, r 0.3217, f1: 0.3280	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5462
global_step: 27801, epoch: 96, loss: 0.263090
global_step: 27802, epoch: 96, loss: 0.359373
global_step: 27803, epoch: 96, loss: 0.336242
global_step: 27804, epoch: 96, loss: 0.465286
global_step: 27805, epoch: 96, loss: 0.370130
global_step: 27806, epoch: 96, loss: 0.301263
global_step: 27807, epoch: 96, loss: 0.427807
global_step: 27808, epoch: 96, loss: 0.301641
global_step: 27809, epoch: 96, loss: 0.296290
global_step: 27810, epoch: 96, loss: 0.349480
global_step: 27811, epoch: 96, loss: 0.248740
global_step: 27812, epoch: 96, loss: 0.290250
global_step: 27813, epoch: 96, loss: 0.299552
global_step: 27814, epoch: 96, loss: 0.311384
global_step: 27815, epoch: 96, loss: 0.305137
global_step: 27816, epoch: 96, loss: 0.289835
global_step: 27817, epoch: 96, loss: 0.304472
global_step: 27818, epoch: 96, loss: 0.315957
global_step: 27819, epoch: 96, loss: 0.379194
global_step: 27820, epoch: 96, loss: 0.374454
global_step: 27821, epoch: 96, loss: 0.282189
global_step: 27822, epoch: 96, loss: 0.305400
global_step: 27823, epoch: 96, loss: 0.389751
global_step: 27824, epoch: 96, loss: 0.307832
global_step: 27825, epoch: 96, loss: 0.271529
global_step: 27826, epoch: 96, loss: 0.368996
global_step: 27827, epoch: 96, loss: 0.333559
global_step: 27828, epoch: 96, loss: 0.355924
global_step: 27829, epoch: 96, loss: 0.357862
global_step: 27830, epoch: 96, loss: 0.336478
global_step: 27831, epoch: 96, loss: 0.307038
global_step: 27832, epoch: 96, loss: 0.365395
global_step: 27833, epoch: 96, loss: 0.277692
global_step: 27834, epoch: 96, loss: 0.317590
global_step: 27835, epoch: 96, loss: 0.350667
global_step: 27836, epoch: 96, loss: 0.298590
global_step: 27837, epoch: 96, loss: 0.315233
global_step: 27838, epoch: 96, loss: 0.396120
global_step: 27839, epoch: 96, loss: 0.285036
global_step: 27840, epoch: 96, loss: 0.030750
epoch: 96
train	acc: 0.9592	macro: p 0.9675, r 0.9295, f1: 0.9471	micro: p 0.9592, r 0.9592, f1 0.9592	weighted_f1:0.9591
dev	acc: 0.5221	macro: p 0.3502, r 0.3013, f1: 0.3006	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4792
test	acc: 0.5812	macro: p 0.3769, r 0.3204, f1: 0.3284	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5457
global_step: 27841, epoch: 97, loss: 0.316378
global_step: 27842, epoch: 97, loss: 0.359458
global_step: 27843, epoch: 97, loss: 0.281325
global_step: 27844, epoch: 97, loss: 0.449138
global_step: 27845, epoch: 97, loss: 0.351390
global_step: 27846, epoch: 97, loss: 0.309014
global_step: 27847, epoch: 97, loss: 0.298669
global_step: 27848, epoch: 97, loss: 0.392846
global_step: 27849, epoch: 97, loss: 0.364786
global_step: 27850, epoch: 97, loss: 0.345856
global_step: 27851, epoch: 97, loss: 0.347804
global_step: 27852, epoch: 97, loss: 0.277955
global_step: 27853, epoch: 97, loss: 0.305486
global_step: 27854, epoch: 97, loss: 0.324007
global_step: 27855, epoch: 97, loss: 0.306950
global_step: 27856, epoch: 97, loss: 0.290276
global_step: 27857, epoch: 97, loss: 0.331525
global_step: 27858, epoch: 97, loss: 0.438589
global_step: 27859, epoch: 97, loss: 0.353512
global_step: 27860, epoch: 97, loss: 0.365556
global_step: 27861, epoch: 97, loss: 0.341304
global_step: 27862, epoch: 97, loss: 0.267241
global_step: 27863, epoch: 97, loss: 0.300507
global_step: 27864, epoch: 97, loss: 0.262130
global_step: 27865, epoch: 97, loss: 0.279145
global_step: 27866, epoch: 97, loss: 0.283456
global_step: 27867, epoch: 97, loss: 0.332196
global_step: 27868, epoch: 97, loss: 0.280884
global_step: 27869, epoch: 97, loss: 0.405777
global_step: 27870, epoch: 97, loss: 0.272093
global_step: 27871, epoch: 97, loss: 0.357001
global_step: 27872, epoch: 97, loss: 0.304476
global_step: 27873, epoch: 97, loss: 0.322776
global_step: 27874, epoch: 97, loss: 0.300960
global_step: 27875, epoch: 97, loss: 0.262913
global_step: 27876, epoch: 97, loss: 0.369075
global_step: 27877, epoch: 97, loss: 0.299083
global_step: 27878, epoch: 97, loss: 0.316691
global_step: 27879, epoch: 97, loss: 0.378205
global_step: 27880, epoch: 97, loss: 0.754259
epoch: 97
train	acc: 0.9606	macro: p 0.9666, r 0.9320, f1: 0.9480	micro: p 0.9606, r 0.9606, f1 0.9606	weighted_f1:0.9605
dev	acc: 0.5167	macro: p 0.3451, r 0.3045, f1: 0.3052	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4790
test	acc: 0.5808	macro: p 0.3579, r 0.3254, f1: 0.3287	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5504
global_step: 27881, epoch: 98, loss: 0.274041
global_step: 27882, epoch: 98, loss: 0.337900
global_step: 27883, epoch: 98, loss: 0.302629
global_step: 27884, epoch: 98, loss: 0.385040
global_step: 27885, epoch: 98, loss: 0.305088
global_step: 27886, epoch: 98, loss: 0.309514
global_step: 27887, epoch: 98, loss: 0.293203
global_step: 27888, epoch: 98, loss: 0.279993
global_step: 27889, epoch: 98, loss: 0.318572
global_step: 27890, epoch: 98, loss: 0.345938
global_step: 27891, epoch: 98, loss: 0.309298
global_step: 27892, epoch: 98, loss: 0.269731
global_step: 27893, epoch: 98, loss: 0.273150
global_step: 27894, epoch: 98, loss: 0.349216
global_step: 27895, epoch: 98, loss: 0.309804
global_step: 27896, epoch: 98, loss: 0.245132
global_step: 27897, epoch: 98, loss: 0.273774
global_step: 27898, epoch: 98, loss: 0.311698
global_step: 27899, epoch: 98, loss: 0.367519
global_step: 27900, epoch: 98, loss: 0.285630
global_step: 27901, epoch: 98, loss: 0.340481
global_step: 27902, epoch: 98, loss: 0.377284
global_step: 27903, epoch: 98, loss: 0.345347
global_step: 27904, epoch: 98, loss: 0.312045
global_step: 27905, epoch: 98, loss: 0.415618
global_step: 27906, epoch: 98, loss: 0.330758
global_step: 27907, epoch: 98, loss: 0.316830
global_step: 27908, epoch: 98, loss: 0.365324
global_step: 27909, epoch: 98, loss: 0.384587
global_step: 27910, epoch: 98, loss: 0.295338
global_step: 27911, epoch: 98, loss: 0.350079
global_step: 27912, epoch: 98, loss: 0.299807
global_step: 27913, epoch: 98, loss: 0.317404
global_step: 27914, epoch: 98, loss: 0.348399
global_step: 27915, epoch: 98, loss: 0.337947
global_step: 27916, epoch: 98, loss: 0.325078
global_step: 27917, epoch: 98, loss: 0.362297
global_step: 27918, epoch: 98, loss: 0.310767
global_step: 27919, epoch: 98, loss: 0.382965
global_step: 27920, epoch: 98, loss: 0.072304
epoch: 98
train	acc: 0.9610	macro: p 0.9674, r 0.9346, f1: 0.9500	micro: p 0.9610, r 0.9610, f1 0.9610	weighted_f1:0.9609
dev	acc: 0.5257	macro: p 0.3563, r 0.3067, f1: 0.3108	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4862
test	acc: 0.5831	macro: p 0.3590, r 0.3190, f1: 0.3247	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5505
global_step: 27921, epoch: 99, loss: 0.298424
global_step: 27922, epoch: 99, loss: 0.377426
global_step: 27923, epoch: 99, loss: 0.299790
global_step: 27924, epoch: 99, loss: 0.286030
global_step: 27925, epoch: 99, loss: 0.292847
global_step: 27926, epoch: 99, loss: 0.324571
global_step: 27927, epoch: 99, loss: 0.248827
global_step: 27928, epoch: 99, loss: 0.304325
global_step: 27929, epoch: 99, loss: 0.283535
global_step: 27930, epoch: 99, loss: 0.391912
global_step: 27931, epoch: 99, loss: 0.378175
global_step: 27932, epoch: 99, loss: 0.275823
global_step: 27933, epoch: 99, loss: 0.347946
global_step: 27934, epoch: 99, loss: 0.322638
global_step: 27935, epoch: 99, loss: 0.375059
global_step: 27936, epoch: 99, loss: 0.271658
global_step: 27937, epoch: 99, loss: 0.340534
global_step: 27938, epoch: 99, loss: 0.361304
global_step: 27939, epoch: 99, loss: 0.322844
global_step: 27940, epoch: 99, loss: 0.333515
global_step: 27941, epoch: 99, loss: 0.281403
global_step: 27942, epoch: 99, loss: 0.292940
global_step: 27943, epoch: 99, loss: 0.291661
global_step: 27944, epoch: 99, loss: 0.389164
global_step: 27945, epoch: 99, loss: 0.331299
global_step: 27946, epoch: 99, loss: 0.291821
global_step: 27947, epoch: 99, loss: 0.281194
global_step: 27948, epoch: 99, loss: 0.332695
global_step: 27949, epoch: 99, loss: 0.332365
global_step: 27950, epoch: 99, loss: 0.261285
global_step: 27951, epoch: 99, loss: 0.435820
global_step: 27952, epoch: 99, loss: 0.280346
global_step: 27953, epoch: 99, loss: 0.343685
global_step: 27954, epoch: 99, loss: 0.334929
global_step: 27955, epoch: 99, loss: 0.438134
global_step: 27956, epoch: 99, loss: 0.369538
global_step: 27957, epoch: 99, loss: 0.340410
global_step: 27958, epoch: 99, loss: 0.277722
global_step: 27959, epoch: 99, loss: 0.391007
global_step: 27960, epoch: 99, loss: 0.484773
epoch: 99
train	acc: 0.9615	macro: p 0.9667, r 0.9362, f1: 0.9505	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9614
dev	acc: 0.5239	macro: p 0.3420, r 0.3037, f1: 0.3045	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4820
test	acc: 0.5816	macro: p 0.3617, r 0.3188, f1: 0.3256	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5464
global_step: 27961, epoch: 100, loss: 0.241461
global_step: 27962, epoch: 100, loss: 0.483558
global_step: 27963, epoch: 100, loss: 0.347588
global_step: 27964, epoch: 100, loss: 0.368493
global_step: 27965, epoch: 100, loss: 0.345665
global_step: 27966, epoch: 100, loss: 0.242670
global_step: 27967, epoch: 100, loss: 0.285553
global_step: 27968, epoch: 100, loss: 0.369592
global_step: 27969, epoch: 100, loss: 0.269699
global_step: 27970, epoch: 100, loss: 0.282967
global_step: 27971, epoch: 100, loss: 0.292548
global_step: 27972, epoch: 100, loss: 0.350583
global_step: 27973, epoch: 100, loss: 0.360561
global_step: 27974, epoch: 100, loss: 0.295270
global_step: 27975, epoch: 100, loss: 0.327841
global_step: 27976, epoch: 100, loss: 0.268895
global_step: 27977, epoch: 100, loss: 0.309315
global_step: 27978, epoch: 100, loss: 0.260721
global_step: 27979, epoch: 100, loss: 0.390042
global_step: 27980, epoch: 100, loss: 0.378043
global_step: 27981, epoch: 100, loss: 0.274572
global_step: 27982, epoch: 100, loss: 0.313813
global_step: 27983, epoch: 100, loss: 0.357400
global_step: 27984, epoch: 100, loss: 0.280762
global_step: 27985, epoch: 100, loss: 0.229245
global_step: 27986, epoch: 100, loss: 0.354203
global_step: 27987, epoch: 100, loss: 0.344567
global_step: 27988, epoch: 100, loss: 0.326615
global_step: 27989, epoch: 100, loss: 0.350413
global_step: 27990, epoch: 100, loss: 0.433792
global_step: 27991, epoch: 100, loss: 0.385834
global_step: 27992, epoch: 100, loss: 0.440404
global_step: 27993, epoch: 100, loss: 0.358823
global_step: 27994, epoch: 100, loss: 0.318234
global_step: 27995, epoch: 100, loss: 0.346327
global_step: 27996, epoch: 100, loss: 0.306711
global_step: 27997, epoch: 100, loss: 0.318722
global_step: 27998, epoch: 100, loss: 0.280491
global_step: 27999, epoch: 100, loss: 0.348814
global_step: 28000, epoch: 100, loss: 0.039950
epoch: 100
train	acc: 0.9609	macro: p 0.9673, r 0.9340, f1: 0.9495	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9608
dev	acc: 0.5275	macro: p 0.3623, r 0.3065, f1: 0.3072	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4851
test	acc: 0.5866	macro: p 0.3786, r 0.3289, f1: 0.3378	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5540
global_step: 28001, epoch: 101, loss: 0.368761
global_step: 28002, epoch: 101, loss: 0.422000
global_step: 28003, epoch: 101, loss: 0.304159
global_step: 28004, epoch: 101, loss: 0.286603
global_step: 28005, epoch: 101, loss: 0.317864
global_step: 28006, epoch: 101, loss: 0.333184
global_step: 28007, epoch: 101, loss: 0.362101
global_step: 28008, epoch: 101, loss: 0.260084
global_step: 28009, epoch: 101, loss: 0.229423
global_step: 28010, epoch: 101, loss: 0.326209
global_step: 28011, epoch: 101, loss: 0.367969
global_step: 28012, epoch: 101, loss: 0.345465
global_step: 28013, epoch: 101, loss: 0.359962
global_step: 28014, epoch: 101, loss: 0.295603
global_step: 28015, epoch: 101, loss: 0.288522
global_step: 28016, epoch: 101, loss: 0.350337
global_step: 28017, epoch: 101, loss: 0.301781
global_step: 28018, epoch: 101, loss: 0.314994
global_step: 28019, epoch: 101, loss: 0.287091
global_step: 28020, epoch: 101, loss: 0.388035
global_step: 28021, epoch: 101, loss: 0.290045
global_step: 28022, epoch: 101, loss: 0.328409
global_step: 28023, epoch: 101, loss: 0.297735
global_step: 28024, epoch: 101, loss: 0.353789
global_step: 28025, epoch: 101, loss: 0.307914
global_step: 28026, epoch: 101, loss: 0.374140
global_step: 28027, epoch: 101, loss: 0.238163
global_step: 28028, epoch: 101, loss: 0.353551
global_step: 28029, epoch: 101, loss: 0.386321
global_step: 28030, epoch: 101, loss: 0.344044
global_step: 28031, epoch: 101, loss: 0.283987
global_step: 28032, epoch: 101, loss: 0.276132
global_step: 28033, epoch: 101, loss: 0.332222
global_step: 28034, epoch: 101, loss: 0.280880
global_step: 28035, epoch: 101, loss: 0.344617
global_step: 28036, epoch: 101, loss: 0.291917
global_step: 28037, epoch: 101, loss: 0.308621
global_step: 28038, epoch: 101, loss: 0.399836
global_step: 28039, epoch: 101, loss: 0.282941
global_step: 28040, epoch: 101, loss: 0.185332
epoch: 101
train	acc: 0.9602	macro: p 0.9659, r 0.9312, f1: 0.9472	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9601
dev	acc: 0.5284	macro: p 0.3680, r 0.3114, f1: 0.3106	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4883
test	acc: 0.5789	macro: p 0.3699, r 0.3271, f1: 0.3291	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5501
global_step: 28041, epoch: 102, loss: 0.296159
global_step: 28042, epoch: 102, loss: 0.413877
global_step: 28043, epoch: 102, loss: 0.243718
global_step: 28044, epoch: 102, loss: 0.298882
global_step: 28045, epoch: 102, loss: 0.273953
global_step: 28046, epoch: 102, loss: 0.400976
global_step: 28047, epoch: 102, loss: 0.291356
global_step: 28048, epoch: 102, loss: 0.318342
global_step: 28049, epoch: 102, loss: 0.318635
global_step: 28050, epoch: 102, loss: 0.339324
global_step: 28051, epoch: 102, loss: 0.358090
global_step: 28052, epoch: 102, loss: 0.243303
global_step: 28053, epoch: 102, loss: 0.260990
global_step: 28054, epoch: 102, loss: 0.275473
global_step: 28055, epoch: 102, loss: 0.342043
global_step: 28056, epoch: 102, loss: 0.261104
global_step: 28057, epoch: 102, loss: 0.264591
global_step: 28058, epoch: 102, loss: 0.271587
global_step: 28059, epoch: 102, loss: 0.293804
global_step: 28060, epoch: 102, loss: 0.306015
global_step: 28061, epoch: 102, loss: 0.389370
global_step: 28062, epoch: 102, loss: 0.413543
global_step: 28063, epoch: 102, loss: 0.345621
global_step: 28064, epoch: 102, loss: 0.314084
global_step: 28065, epoch: 102, loss: 0.366169
global_step: 28066, epoch: 102, loss: 0.300678
global_step: 28067, epoch: 102, loss: 0.368534
global_step: 28068, epoch: 102, loss: 0.364567
global_step: 28069, epoch: 102, loss: 0.257050
global_step: 28070, epoch: 102, loss: 0.412570
global_step: 28071, epoch: 102, loss: 0.260523
global_step: 28072, epoch: 102, loss: 0.281653
global_step: 28073, epoch: 102, loss: 0.375038
global_step: 28074, epoch: 102, loss: 0.345821
global_step: 28075, epoch: 102, loss: 0.339937
global_step: 28076, epoch: 102, loss: 0.416296
global_step: 28077, epoch: 102, loss: 0.265802
global_step: 28078, epoch: 102, loss: 0.321774
global_step: 28079, epoch: 102, loss: 0.344106
global_step: 28080, epoch: 102, loss: 0.418124
epoch: 102
train	acc: 0.9587	macro: p 0.9679, r 0.9290, f1: 0.9472	micro: p 0.9587, r 0.9587, f1 0.9587	weighted_f1:0.9585
dev	acc: 0.5275	macro: p 0.3670, r 0.2989, f1: 0.2989	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4783
test	acc: 0.5862	macro: p 0.3661, r 0.3122, f1: 0.3185	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5441
global_step: 28081, epoch: 103, loss: 0.265560
global_step: 28082, epoch: 103, loss: 0.382321
global_step: 28083, epoch: 103, loss: 0.300362
global_step: 28084, epoch: 103, loss: 0.335734
global_step: 28085, epoch: 103, loss: 0.218657
global_step: 28086, epoch: 103, loss: 0.324401
global_step: 28087, epoch: 103, loss: 0.236377
global_step: 28088, epoch: 103, loss: 0.370788
global_step: 28089, epoch: 103, loss: 0.274591
global_step: 28090, epoch: 103, loss: 0.272260
global_step: 28091, epoch: 103, loss: 0.317370
global_step: 28092, epoch: 103, loss: 0.372746
global_step: 28093, epoch: 103, loss: 0.338395
global_step: 28094, epoch: 103, loss: 0.295072
global_step: 28095, epoch: 103, loss: 0.308682
global_step: 28096, epoch: 103, loss: 0.367975
global_step: 28097, epoch: 103, loss: 0.322193
global_step: 28098, epoch: 103, loss: 0.354831
global_step: 28099, epoch: 103, loss: 0.221136
global_step: 28100, epoch: 103, loss: 0.318076
global_step: 28101, epoch: 103, loss: 0.290673
global_step: 28102, epoch: 103, loss: 0.220996
global_step: 28103, epoch: 103, loss: 0.251784
global_step: 28104, epoch: 103, loss: 0.316873
global_step: 28105, epoch: 103, loss: 0.346984
global_step: 28106, epoch: 103, loss: 0.371241
global_step: 28107, epoch: 103, loss: 0.372607
global_step: 28108, epoch: 103, loss: 0.362887
global_step: 28109, epoch: 103, loss: 0.285171
global_step: 28110, epoch: 103, loss: 0.335778
global_step: 28111, epoch: 103, loss: 0.285333
global_step: 28112, epoch: 103, loss: 0.278236
global_step: 28113, epoch: 103, loss: 0.441438
global_step: 28114, epoch: 103, loss: 0.342993
global_step: 28115, epoch: 103, loss: 0.252906
global_step: 28116, epoch: 103, loss: 0.367816
global_step: 28117, epoch: 103, loss: 0.275222
global_step: 28118, epoch: 103, loss: 0.261729
global_step: 28119, epoch: 103, loss: 0.300795
global_step: 28120, epoch: 103, loss: 0.384952
epoch: 103
train	acc: 0.9603	macro: p 0.9680, r 0.9325, f1: 0.9492	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9602
dev	acc: 0.5410	macro: p 0.3645, r 0.3101, f1: 0.3105	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4917
test	acc: 0.5854	macro: p 0.3824, r 0.3164, f1: 0.3254	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5451
global_step: 28121, epoch: 104, loss: 0.272711
global_step: 28122, epoch: 104, loss: 0.275604
global_step: 28123, epoch: 104, loss: 0.249005
global_step: 28124, epoch: 104, loss: 0.296508
global_step: 28125, epoch: 104, loss: 0.388150
global_step: 28126, epoch: 104, loss: 0.334540
global_step: 28127, epoch: 104, loss: 0.296248
global_step: 28128, epoch: 104, loss: 0.319937
global_step: 28129, epoch: 104, loss: 0.304271
global_step: 28130, epoch: 104, loss: 0.264528
global_step: 28131, epoch: 104, loss: 0.270083
global_step: 28132, epoch: 104, loss: 0.313841
global_step: 28133, epoch: 104, loss: 0.264193
global_step: 28134, epoch: 104, loss: 0.297036
global_step: 28135, epoch: 104, loss: 0.346874
global_step: 28136, epoch: 104, loss: 0.302171
global_step: 28137, epoch: 104, loss: 0.296321
global_step: 28138, epoch: 104, loss: 0.325343
global_step: 28139, epoch: 104, loss: 0.322251
global_step: 28140, epoch: 104, loss: 0.311572
global_step: 28141, epoch: 104, loss: 0.312864
global_step: 28142, epoch: 104, loss: 0.348712
global_step: 28143, epoch: 104, loss: 0.252446
global_step: 28144, epoch: 104, loss: 0.282100
global_step: 28145, epoch: 104, loss: 0.290482
global_step: 28146, epoch: 104, loss: 0.359286
global_step: 28147, epoch: 104, loss: 0.361223
global_step: 28148, epoch: 104, loss: 0.278433
global_step: 28149, epoch: 104, loss: 0.344659
global_step: 28150, epoch: 104, loss: 0.243097
global_step: 28151, epoch: 104, loss: 0.239373
global_step: 28152, epoch: 104, loss: 0.308205
global_step: 28153, epoch: 104, loss: 0.285245
global_step: 28154, epoch: 104, loss: 0.384231
global_step: 28155, epoch: 104, loss: 0.336304
global_step: 28156, epoch: 104, loss: 0.292492
global_step: 28157, epoch: 104, loss: 0.286099
global_step: 28158, epoch: 104, loss: 0.395863
global_step: 28159, epoch: 104, loss: 0.350338
global_step: 28160, epoch: 104, loss: 0.336900
epoch: 104
train	acc: 0.9617	macro: p 0.9684, r 0.9353, f1: 0.9509	micro: p 0.9617, r 0.9617, f1 0.9617	weighted_f1:0.9615
dev	acc: 0.5194	macro: p 0.3551, r 0.2988, f1: 0.3026	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4779
test	acc: 0.5828	macro: p 0.3670, r 0.3157, f1: 0.3253	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5468
global_step: 28161, epoch: 105, loss: 0.344613
global_step: 28162, epoch: 105, loss: 0.285601
global_step: 28163, epoch: 105, loss: 0.354042
global_step: 28164, epoch: 105, loss: 0.352590
global_step: 28165, epoch: 105, loss: 0.303691
global_step: 28166, epoch: 105, loss: 0.252453
global_step: 28167, epoch: 105, loss: 0.304569
global_step: 28168, epoch: 105, loss: 0.253610
global_step: 28169, epoch: 105, loss: 0.234888
global_step: 28170, epoch: 105, loss: 0.290912
global_step: 28171, epoch: 105, loss: 0.344915
global_step: 28172, epoch: 105, loss: 0.254282
global_step: 28173, epoch: 105, loss: 0.335300
global_step: 28174, epoch: 105, loss: 0.264429
global_step: 28175, epoch: 105, loss: 0.303628
global_step: 28176, epoch: 105, loss: 0.284341
global_step: 28177, epoch: 105, loss: 0.329173
global_step: 28178, epoch: 105, loss: 0.256952
global_step: 28179, epoch: 105, loss: 0.376289
global_step: 28180, epoch: 105, loss: 0.287627
global_step: 28181, epoch: 105, loss: 0.342754
global_step: 28182, epoch: 105, loss: 0.292912
global_step: 28183, epoch: 105, loss: 0.303889
global_step: 28184, epoch: 105, loss: 0.278904
global_step: 28185, epoch: 105, loss: 0.302913
global_step: 28186, epoch: 105, loss: 0.334215
global_step: 28187, epoch: 105, loss: 0.317927
global_step: 28188, epoch: 105, loss: 0.264261
global_step: 28189, epoch: 105, loss: 0.302091
global_step: 28190, epoch: 105, loss: 0.303701
global_step: 28191, epoch: 105, loss: 0.344903
global_step: 28192, epoch: 105, loss: 0.296440
global_step: 28193, epoch: 105, loss: 0.272179
global_step: 28194, epoch: 105, loss: 0.384262
global_step: 28195, epoch: 105, loss: 0.407161
global_step: 28196, epoch: 105, loss: 0.308579
global_step: 28197, epoch: 105, loss: 0.294445
global_step: 28198, epoch: 105, loss: 0.281474
global_step: 28199, epoch: 105, loss: 0.370684
global_step: 28200, epoch: 105, loss: 0.520379
epoch: 105
train	acc: 0.9611	macro: p 0.9701, r 0.9334, f1: 0.9506	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9610
dev	acc: 0.5275	macro: p 0.3579, r 0.3056, f1: 0.3061	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4832
test	acc: 0.5874	macro: p 0.3642, r 0.3161, f1: 0.3204	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5479
global_step: 28201, epoch: 106, loss: 0.290062
global_step: 28202, epoch: 106, loss: 0.351996
global_step: 28203, epoch: 106, loss: 0.355906
global_step: 28204, epoch: 106, loss: 0.306309
global_step: 28205, epoch: 106, loss: 0.268852
global_step: 28206, epoch: 106, loss: 0.291486
global_step: 28207, epoch: 106, loss: 0.298545
global_step: 28208, epoch: 106, loss: 0.304597
global_step: 28209, epoch: 106, loss: 0.305797
global_step: 28210, epoch: 106, loss: 0.340763
global_step: 28211, epoch: 106, loss: 0.335464
global_step: 28212, epoch: 106, loss: 0.238668
global_step: 28213, epoch: 106, loss: 0.405814
global_step: 28214, epoch: 106, loss: 0.275019
global_step: 28215, epoch: 106, loss: 0.315922
global_step: 28216, epoch: 106, loss: 0.244605
global_step: 28217, epoch: 106, loss: 0.264264
global_step: 28218, epoch: 106, loss: 0.279048
global_step: 28219, epoch: 106, loss: 0.321121
global_step: 28220, epoch: 106, loss: 0.289956
global_step: 28221, epoch: 106, loss: 0.293394
global_step: 28222, epoch: 106, loss: 0.318845
global_step: 28223, epoch: 106, loss: 0.374641
global_step: 28224, epoch: 106, loss: 0.279066
global_step: 28225, epoch: 106, loss: 0.268571
global_step: 28226, epoch: 106, loss: 0.284387
global_step: 28227, epoch: 106, loss: 0.294331
global_step: 28228, epoch: 106, loss: 0.365733
global_step: 28229, epoch: 106, loss: 0.323004
global_step: 28230, epoch: 106, loss: 0.309762
global_step: 28231, epoch: 106, loss: 0.266967
global_step: 28232, epoch: 106, loss: 0.351423
global_step: 28233, epoch: 106, loss: 0.287987
global_step: 28234, epoch: 106, loss: 0.227463
global_step: 28235, epoch: 106, loss: 0.355080
global_step: 28236, epoch: 106, loss: 0.309275
global_step: 28237, epoch: 106, loss: 0.364263
global_step: 28238, epoch: 106, loss: 0.315771
global_step: 28239, epoch: 106, loss: 0.304045
global_step: 28240, epoch: 106, loss: 1.272295
epoch: 106
train	acc: 0.9624	macro: p 0.9704, r 0.9364, f1: 0.9523	micro: p 0.9624, r 0.9624, f1 0.9624	weighted_f1:0.9623
dev	acc: 0.5275	macro: p 0.3654, r 0.3039, f1: 0.3024	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4815
test	acc: 0.5824	macro: p 0.3721, r 0.3135, f1: 0.3161	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5425
global_step: 28241, epoch: 107, loss: 0.314086
global_step: 28242, epoch: 107, loss: 0.224567
global_step: 28243, epoch: 107, loss: 0.219432
global_step: 28244, epoch: 107, loss: 0.324707
global_step: 28245, epoch: 107, loss: 0.306618
global_step: 28246, epoch: 107, loss: 0.342939
global_step: 28247, epoch: 107, loss: 0.216374
global_step: 28248, epoch: 107, loss: 0.322809
global_step: 28249, epoch: 107, loss: 0.212939
global_step: 28250, epoch: 107, loss: 0.318928
global_step: 28251, epoch: 107, loss: 0.319706
global_step: 28252, epoch: 107, loss: 0.290357
global_step: 28253, epoch: 107, loss: 0.265720
global_step: 28254, epoch: 107, loss: 0.350443
global_step: 28255, epoch: 107, loss: 0.238161
global_step: 28256, epoch: 107, loss: 0.334394
global_step: 28257, epoch: 107, loss: 0.308216
global_step: 28258, epoch: 107, loss: 0.330144
global_step: 28259, epoch: 107, loss: 0.311305
global_step: 28260, epoch: 107, loss: 0.278682
global_step: 28261, epoch: 107, loss: 0.348356
global_step: 28262, epoch: 107, loss: 0.296736
global_step: 28263, epoch: 107, loss: 0.279858
global_step: 28264, epoch: 107, loss: 0.283199
global_step: 28265, epoch: 107, loss: 0.326447
global_step: 28266, epoch: 107, loss: 0.276251
global_step: 28267, epoch: 107, loss: 0.296137
global_step: 28268, epoch: 107, loss: 0.264972
global_step: 28269, epoch: 107, loss: 0.305404
global_step: 28270, epoch: 107, loss: 0.256926
global_step: 28271, epoch: 107, loss: 0.278189
global_step: 28272, epoch: 107, loss: 0.356746
global_step: 28273, epoch: 107, loss: 0.268902
global_step: 28274, epoch: 107, loss: 0.227415
global_step: 28275, epoch: 107, loss: 0.300698
global_step: 28276, epoch: 107, loss: 0.367185
global_step: 28277, epoch: 107, loss: 0.280919
global_step: 28278, epoch: 107, loss: 0.353033
global_step: 28279, epoch: 107, loss: 0.309280
global_step: 28280, epoch: 107, loss: 0.064803
epoch: 107
train	acc: 0.9631	macro: p 0.9703, r 0.9390, f1: 0.9537	micro: p 0.9631, r 0.9631, f1 0.9631	weighted_f1:0.9630
dev	acc: 0.5212	macro: p 0.3456, r 0.2969, f1: 0.2972	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4770
test	acc: 0.5843	macro: p 0.3815, r 0.3194, f1: 0.3276	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5476
global_step: 28281, epoch: 108, loss: 0.254650
global_step: 28282, epoch: 108, loss: 0.320546
global_step: 28283, epoch: 108, loss: 0.316491
global_step: 28284, epoch: 108, loss: 0.270509
global_step: 28285, epoch: 108, loss: 0.276701
global_step: 28286, epoch: 108, loss: 0.253786
global_step: 28287, epoch: 108, loss: 0.249193
global_step: 28288, epoch: 108, loss: 0.247051
global_step: 28289, epoch: 108, loss: 0.279453
global_step: 28290, epoch: 108, loss: 0.188911
global_step: 28291, epoch: 108, loss: 0.350256
global_step: 28292, epoch: 108, loss: 0.296347
global_step: 28293, epoch: 108, loss: 0.377092
global_step: 28294, epoch: 108, loss: 0.331486
global_step: 28295, epoch: 108, loss: 0.333999
global_step: 28296, epoch: 108, loss: 0.283297
global_step: 28297, epoch: 108, loss: 0.221674
global_step: 28298, epoch: 108, loss: 0.270790
global_step: 28299, epoch: 108, loss: 0.243317
global_step: 28300, epoch: 108, loss: 0.274556
global_step: 28301, epoch: 108, loss: 0.358730
global_step: 28302, epoch: 108, loss: 0.255942
global_step: 28303, epoch: 108, loss: 0.292898
global_step: 28304, epoch: 108, loss: 0.284470
global_step: 28305, epoch: 108, loss: 0.316164
global_step: 28306, epoch: 108, loss: 0.225304
global_step: 28307, epoch: 108, loss: 0.288579
global_step: 28308, epoch: 108, loss: 0.327460
global_step: 28309, epoch: 108, loss: 0.345184
global_step: 28310, epoch: 108, loss: 0.271889
global_step: 28311, epoch: 108, loss: 0.308773
global_step: 28312, epoch: 108, loss: 0.325981
global_step: 28313, epoch: 108, loss: 0.321424
global_step: 28314, epoch: 108, loss: 0.400542
global_step: 28315, epoch: 108, loss: 0.298049
global_step: 28316, epoch: 108, loss: 0.293363
global_step: 28317, epoch: 108, loss: 0.260965
global_step: 28318, epoch: 108, loss: 0.375658
global_step: 28319, epoch: 108, loss: 0.318793
global_step: 28320, epoch: 108, loss: 0.264915
epoch: 108
train	acc: 0.9629	macro: p 0.9693, r 0.9397, f1: 0.9536	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9628
dev	acc: 0.5239	macro: p 0.3465, r 0.3053, f1: 0.3018	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4809
test	acc: 0.5728	macro: p 0.3509, r 0.3166, f1: 0.3199	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5393
global_step: 28321, epoch: 109, loss: 0.314062
global_step: 28322, epoch: 109, loss: 0.286874
global_step: 28323, epoch: 109, loss: 0.371165
global_step: 28324, epoch: 109, loss: 0.247366
global_step: 28325, epoch: 109, loss: 0.272823
global_step: 28326, epoch: 109, loss: 0.311134
global_step: 28327, epoch: 109, loss: 0.288865
global_step: 28328, epoch: 109, loss: 0.263754
global_step: 28329, epoch: 109, loss: 0.193612
global_step: 28330, epoch: 109, loss: 0.256253
global_step: 28331, epoch: 109, loss: 0.252615
global_step: 28332, epoch: 109, loss: 0.253735
global_step: 28333, epoch: 109, loss: 0.285363
global_step: 28334, epoch: 109, loss: 0.218180
global_step: 28335, epoch: 109, loss: 0.349920
global_step: 28336, epoch: 109, loss: 0.259868
global_step: 28337, epoch: 109, loss: 0.270748
global_step: 28338, epoch: 109, loss: 0.296564
global_step: 28339, epoch: 109, loss: 0.219040
global_step: 28340, epoch: 109, loss: 0.283199
global_step: 28341, epoch: 109, loss: 0.249116
global_step: 28342, epoch: 109, loss: 0.334037
global_step: 28343, epoch: 109, loss: 0.311458
global_step: 28344, epoch: 109, loss: 0.228822
global_step: 28345, epoch: 109, loss: 0.297900
global_step: 28346, epoch: 109, loss: 0.287627
global_step: 28347, epoch: 109, loss: 0.345711
global_step: 28348, epoch: 109, loss: 0.303072
global_step: 28349, epoch: 109, loss: 0.263009
global_step: 28350, epoch: 109, loss: 0.341905
global_step: 28351, epoch: 109, loss: 0.338679
global_step: 28352, epoch: 109, loss: 0.286875
global_step: 28353, epoch: 109, loss: 0.332506
global_step: 28354, epoch: 109, loss: 0.226828
global_step: 28355, epoch: 109, loss: 0.230744
global_step: 28356, epoch: 109, loss: 0.327478
global_step: 28357, epoch: 109, loss: 0.301748
global_step: 28358, epoch: 109, loss: 0.299941
global_step: 28359, epoch: 109, loss: 0.317854
global_step: 28360, epoch: 109, loss: 0.089048
epoch: 109
train	acc: 0.9627	macro: p 0.9699, r 0.9381, f1: 0.9530	micro: p 0.9627, r 0.9627, f1 0.9627	weighted_f1:0.9626
dev	acc: 0.5248	macro: p 0.3584, r 0.3033, f1: 0.3009	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4797
test	acc: 0.5801	macro: p 0.3672, r 0.3176, f1: 0.3204	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5435
global_step: 28361, epoch: 110, loss: 0.299663
global_step: 28362, epoch: 110, loss: 0.356545
global_step: 28363, epoch: 110, loss: 0.299264
global_step: 28364, epoch: 110, loss: 0.280579
global_step: 28365, epoch: 110, loss: 0.365448
global_step: 28366, epoch: 110, loss: 0.264246
global_step: 28367, epoch: 110, loss: 0.339015
global_step: 28368, epoch: 110, loss: 0.276216
global_step: 28369, epoch: 110, loss: 0.200198
global_step: 28370, epoch: 110, loss: 0.225081
global_step: 28371, epoch: 110, loss: 0.268118
global_step: 28372, epoch: 110, loss: 0.219326
global_step: 28373, epoch: 110, loss: 0.254075
global_step: 28374, epoch: 110, loss: 0.264401
global_step: 28375, epoch: 110, loss: 0.220385
global_step: 28376, epoch: 110, loss: 0.218269
global_step: 28377, epoch: 110, loss: 0.251316
global_step: 28378, epoch: 110, loss: 0.301076
global_step: 28379, epoch: 110, loss: 0.380523
global_step: 28380, epoch: 110, loss: 0.328281
global_step: 28381, epoch: 110, loss: 0.311532
global_step: 28382, epoch: 110, loss: 0.331493
global_step: 28383, epoch: 110, loss: 0.347560
global_step: 28384, epoch: 110, loss: 0.238770
global_step: 28385, epoch: 110, loss: 0.304077
global_step: 28386, epoch: 110, loss: 0.240936
global_step: 28387, epoch: 110, loss: 0.273373
global_step: 28388, epoch: 110, loss: 0.396122
global_step: 28389, epoch: 110, loss: 0.287075
global_step: 28390, epoch: 110, loss: 0.304899
global_step: 28391, epoch: 110, loss: 0.268078
global_step: 28392, epoch: 110, loss: 0.275874
global_step: 28393, epoch: 110, loss: 0.298957
global_step: 28394, epoch: 110, loss: 0.326698
global_step: 28395, epoch: 110, loss: 0.279590
global_step: 28396, epoch: 110, loss: 0.338657
global_step: 28397, epoch: 110, loss: 0.338910
global_step: 28398, epoch: 110, loss: 0.281225
global_step: 28399, epoch: 110, loss: 0.272392
global_step: 28400, epoch: 110, loss: 0.692787
epoch: 110
train	acc: 0.9632	macro: p 0.9699, r 0.9407, f1: 0.9544	micro: p 0.9632, r 0.9632, f1 0.9632	weighted_f1:0.9631
dev	acc: 0.5140	macro: p 0.3498, r 0.3007, f1: 0.3017	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4757
test	acc: 0.5755	macro: p 0.3496, r 0.3189, f1: 0.3208	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5440
global_step: 28401, epoch: 111, loss: 0.179352
global_step: 28402, epoch: 111, loss: 0.264479
global_step: 28403, epoch: 111, loss: 0.302601
global_step: 28404, epoch: 111, loss: 0.234115
global_step: 28405, epoch: 111, loss: 0.368387
global_step: 28406, epoch: 111, loss: 0.212518
global_step: 28407, epoch: 111, loss: 0.359247
global_step: 28408, epoch: 111, loss: 0.289056
global_step: 28409, epoch: 111, loss: 0.258136
global_step: 28410, epoch: 111, loss: 0.217159
global_step: 28411, epoch: 111, loss: 0.259487
global_step: 28412, epoch: 111, loss: 0.284507
global_step: 28413, epoch: 111, loss: 0.283784
global_step: 28414, epoch: 111, loss: 0.284441
global_step: 28415, epoch: 111, loss: 0.299557
global_step: 28416, epoch: 111, loss: 0.281868
global_step: 28417, epoch: 111, loss: 0.328087
global_step: 28418, epoch: 111, loss: 0.345825
global_step: 28419, epoch: 111, loss: 0.342954
global_step: 28420, epoch: 111, loss: 0.237735
global_step: 28421, epoch: 111, loss: 0.362612
global_step: 28422, epoch: 111, loss: 0.356533
global_step: 28423, epoch: 111, loss: 0.218528
global_step: 28424, epoch: 111, loss: 0.283881
global_step: 28425, epoch: 111, loss: 0.320512
global_step: 28426, epoch: 111, loss: 0.253120
global_step: 28427, epoch: 111, loss: 0.292697
global_step: 28428, epoch: 111, loss: 0.240808
global_step: 28429, epoch: 111, loss: 0.341176
global_step: 28430, epoch: 111, loss: 0.308350
global_step: 28431, epoch: 111, loss: 0.264545
global_step: 28432, epoch: 111, loss: 0.311532
global_step: 28433, epoch: 111, loss: 0.258212
global_step: 28434, epoch: 111, loss: 0.336119
global_step: 28435, epoch: 111, loss: 0.279632
global_step: 28436, epoch: 111, loss: 0.371468
global_step: 28437, epoch: 111, loss: 0.263382
global_step: 28438, epoch: 111, loss: 0.320698
global_step: 28439, epoch: 111, loss: 0.250353
global_step: 28440, epoch: 111, loss: 0.009302
epoch: 111
train	acc: 0.9635	macro: p 0.9710, r 0.9416, f1: 0.9555	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5311	macro: p 0.3605, r 0.3054, f1: 0.3060	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4861
test	acc: 0.5820	macro: p 0.3661, r 0.3140, f1: 0.3191	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5434
global_step: 28441, epoch: 112, loss: 0.305344
global_step: 28442, epoch: 112, loss: 0.311539
global_step: 28443, epoch: 112, loss: 0.347475
global_step: 28444, epoch: 112, loss: 0.275173
global_step: 28445, epoch: 112, loss: 0.280511
global_step: 28446, epoch: 112, loss: 0.272232
global_step: 28447, epoch: 112, loss: 0.254963
global_step: 28448, epoch: 112, loss: 0.299242
global_step: 28449, epoch: 112, loss: 0.275244
global_step: 28450, epoch: 112, loss: 0.261928
global_step: 28451, epoch: 112, loss: 0.225110
global_step: 28452, epoch: 112, loss: 0.223244
global_step: 28453, epoch: 112, loss: 0.286438
global_step: 28454, epoch: 112, loss: 0.296940
global_step: 28455, epoch: 112, loss: 0.205051
global_step: 28456, epoch: 112, loss: 0.231759
global_step: 28457, epoch: 112, loss: 0.289601
global_step: 28458, epoch: 112, loss: 0.310971
global_step: 28459, epoch: 112, loss: 0.319694
global_step: 28460, epoch: 112, loss: 0.208657
global_step: 28461, epoch: 112, loss: 0.318327
global_step: 28462, epoch: 112, loss: 0.376670
global_step: 28463, epoch: 112, loss: 0.251266
global_step: 28464, epoch: 112, loss: 0.303474
global_step: 28465, epoch: 112, loss: 0.268692
global_step: 28466, epoch: 112, loss: 0.369057
global_step: 28467, epoch: 112, loss: 0.254626
global_step: 28468, epoch: 112, loss: 0.289031
global_step: 28469, epoch: 112, loss: 0.312677
global_step: 28470, epoch: 112, loss: 0.343654
global_step: 28471, epoch: 112, loss: 0.299194
global_step: 28472, epoch: 112, loss: 0.353102
global_step: 28473, epoch: 112, loss: 0.312208
global_step: 28474, epoch: 112, loss: 0.311580
global_step: 28475, epoch: 112, loss: 0.285665
global_step: 28476, epoch: 112, loss: 0.329985
global_step: 28477, epoch: 112, loss: 0.299638
global_step: 28478, epoch: 112, loss: 0.290047
global_step: 28479, epoch: 112, loss: 0.346394
global_step: 28480, epoch: 112, loss: 0.155118
epoch: 112
train	acc: 0.9624	macro: p 0.9708, r 0.9397, f1: 0.9544	micro: p 0.9624, r 0.9624, f1 0.9624	weighted_f1:0.9623
dev	acc: 0.5302	macro: p 0.3625, r 0.3045, f1: 0.3083	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4875
test	acc: 0.5805	macro: p 0.3692, r 0.3090, f1: 0.3155	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5426
global_step: 28481, epoch: 113, loss: 0.260213
global_step: 28482, epoch: 113, loss: 0.321643
global_step: 28483, epoch: 113, loss: 0.302927
global_step: 28484, epoch: 113, loss: 0.310679
global_step: 28485, epoch: 113, loss: 0.284207
global_step: 28486, epoch: 113, loss: 0.257058
global_step: 28487, epoch: 113, loss: 0.309237
global_step: 28488, epoch: 113, loss: 0.324668
global_step: 28489, epoch: 113, loss: 0.300458
global_step: 28490, epoch: 113, loss: 0.280227
global_step: 28491, epoch: 113, loss: 0.242568
global_step: 28492, epoch: 113, loss: 0.290433
global_step: 28493, epoch: 113, loss: 0.271161
global_step: 28494, epoch: 113, loss: 0.258702
global_step: 28495, epoch: 113, loss: 0.318388
global_step: 28496, epoch: 113, loss: 0.232665
global_step: 28497, epoch: 113, loss: 0.321822
global_step: 28498, epoch: 113, loss: 0.250589
global_step: 28499, epoch: 113, loss: 0.360460
global_step: 28500, epoch: 113, loss: 0.308436
global_step: 28501, epoch: 113, loss: 0.362739
global_step: 28502, epoch: 113, loss: 0.318134
global_step: 28503, epoch: 113, loss: 0.247380
global_step: 28504, epoch: 113, loss: 0.358492
global_step: 28505, epoch: 113, loss: 0.297239
global_step: 28506, epoch: 113, loss: 0.321398
global_step: 28507, epoch: 113, loss: 0.292502
global_step: 28508, epoch: 113, loss: 0.266226
global_step: 28509, epoch: 113, loss: 0.362755
global_step: 28510, epoch: 113, loss: 0.262335
global_step: 28511, epoch: 113, loss: 0.208463
global_step: 28512, epoch: 113, loss: 0.318695
global_step: 28513, epoch: 113, loss: 0.299673
global_step: 28514, epoch: 113, loss: 0.266345
global_step: 28515, epoch: 113, loss: 0.240713
global_step: 28516, epoch: 113, loss: 0.305568
global_step: 28517, epoch: 113, loss: 0.243407
global_step: 28518, epoch: 113, loss: 0.309323
global_step: 28519, epoch: 113, loss: 0.278006
global_step: 28520, epoch: 113, loss: 0.015904
epoch: 113
train	acc: 0.9641	macro: p 0.9701, r 0.9410, f1: 0.9547	micro: p 0.9641, r 0.9641, f1 0.9641	weighted_f1:0.9640
dev	acc: 0.5329	macro: p 0.3656, r 0.3107, f1: 0.3132	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4917
test	acc: 0.5831	macro: p 0.3520, r 0.3186, f1: 0.3221	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5494
global_step: 28521, epoch: 114, loss: 0.231192
global_step: 28522, epoch: 114, loss: 0.235076
global_step: 28523, epoch: 114, loss: 0.246636
global_step: 28524, epoch: 114, loss: 0.320989
global_step: 28525, epoch: 114, loss: 0.271968
global_step: 28526, epoch: 114, loss: 0.244042
global_step: 28527, epoch: 114, loss: 0.280159
global_step: 28528, epoch: 114, loss: 0.315927
global_step: 28529, epoch: 114, loss: 0.308883
global_step: 28530, epoch: 114, loss: 0.217050
global_step: 28531, epoch: 114, loss: 0.246753
global_step: 28532, epoch: 114, loss: 0.300494
global_step: 28533, epoch: 114, loss: 0.275884
global_step: 28534, epoch: 114, loss: 0.219565
global_step: 28535, epoch: 114, loss: 0.268384
global_step: 28536, epoch: 114, loss: 0.223571
global_step: 28537, epoch: 114, loss: 0.217356
global_step: 28538, epoch: 114, loss: 0.392749
global_step: 28539, epoch: 114, loss: 0.268040
global_step: 28540, epoch: 114, loss: 0.244269
global_step: 28541, epoch: 114, loss: 0.329348
global_step: 28542, epoch: 114, loss: 0.277459
global_step: 28543, epoch: 114, loss: 0.290812
global_step: 28544, epoch: 114, loss: 0.256932
global_step: 28545, epoch: 114, loss: 0.300144
global_step: 28546, epoch: 114, loss: 0.284895
global_step: 28547, epoch: 114, loss: 0.270246
global_step: 28548, epoch: 114, loss: 0.244253
global_step: 28549, epoch: 114, loss: 0.219291
global_step: 28550, epoch: 114, loss: 0.304024
global_step: 28551, epoch: 114, loss: 0.299456
global_step: 28552, epoch: 114, loss: 0.276474
global_step: 28553, epoch: 114, loss: 0.305965
global_step: 28554, epoch: 114, loss: 0.290888
global_step: 28555, epoch: 114, loss: 0.273294
global_step: 28556, epoch: 114, loss: 0.297888
global_step: 28557, epoch: 114, loss: 0.282526
global_step: 28558, epoch: 114, loss: 0.279353
global_step: 28559, epoch: 114, loss: 0.314519
global_step: 28560, epoch: 114, loss: 0.040770
epoch: 114
train	acc: 0.9647	macro: p 0.9715, r 0.9425, f1: 0.9562	micro: p 0.9647, r 0.9647, f1 0.9647	weighted_f1:0.9646
dev	acc: 0.5275	macro: p 0.3719, r 0.3046, f1: 0.3070	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4837
test	acc: 0.5716	macro: p 0.3613, r 0.3100, f1: 0.3161	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5366
global_step: 28561, epoch: 115, loss: 0.243674
global_step: 28562, epoch: 115, loss: 0.328653
global_step: 28563, epoch: 115, loss: 0.195335
global_step: 28564, epoch: 115, loss: 0.226804
global_step: 28565, epoch: 115, loss: 0.296755
global_step: 28566, epoch: 115, loss: 0.274341
global_step: 28567, epoch: 115, loss: 0.308296
global_step: 28568, epoch: 115, loss: 0.231177
global_step: 28569, epoch: 115, loss: 0.244949
global_step: 28570, epoch: 115, loss: 0.240421
global_step: 28571, epoch: 115, loss: 0.214187
global_step: 28572, epoch: 115, loss: 0.263205
global_step: 28573, epoch: 115, loss: 0.245487
global_step: 28574, epoch: 115, loss: 0.325433
global_step: 28575, epoch: 115, loss: 0.301656
global_step: 28576, epoch: 115, loss: 0.346269
global_step: 28577, epoch: 115, loss: 0.275532
global_step: 28578, epoch: 115, loss: 0.242601
global_step: 28579, epoch: 115, loss: 0.248457
global_step: 28580, epoch: 115, loss: 0.353697
global_step: 28581, epoch: 115, loss: 0.295659
global_step: 28582, epoch: 115, loss: 0.337350
global_step: 28583, epoch: 115, loss: 0.226902
global_step: 28584, epoch: 115, loss: 0.290820
global_step: 28585, epoch: 115, loss: 0.233473
global_step: 28586, epoch: 115, loss: 0.233282
global_step: 28587, epoch: 115, loss: 0.278794
global_step: 28588, epoch: 115, loss: 0.257547
global_step: 28589, epoch: 115, loss: 0.318731
global_step: 28590, epoch: 115, loss: 0.359600
global_step: 28591, epoch: 115, loss: 0.290881
global_step: 28592, epoch: 115, loss: 0.300598
global_step: 28593, epoch: 115, loss: 0.297966
global_step: 28594, epoch: 115, loss: 0.253262
global_step: 28595, epoch: 115, loss: 0.271240
global_step: 28596, epoch: 115, loss: 0.288726
global_step: 28597, epoch: 115, loss: 0.350531
global_step: 28598, epoch: 115, loss: 0.380195
global_step: 28599, epoch: 115, loss: 0.273847
global_step: 28600, epoch: 115, loss: 0.074506
epoch: 115
train	acc: 0.9640	macro: p 0.9714, r 0.9418, f1: 0.9558	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9639
dev	acc: 0.5293	macro: p 0.4032, r 0.3018, f1: 0.3016	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4809
test	acc: 0.5774	macro: p 0.3607, r 0.3120, f1: 0.3165	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5394
global_step: 28601, epoch: 116, loss: 0.297813
global_step: 28602, epoch: 116, loss: 0.263962
global_step: 28603, epoch: 116, loss: 0.271858
global_step: 28604, epoch: 116, loss: 0.222049
global_step: 28605, epoch: 116, loss: 0.256382
global_step: 28606, epoch: 116, loss: 0.240801
global_step: 28607, epoch: 116, loss: 0.230940
global_step: 28608, epoch: 116, loss: 0.308338
global_step: 28609, epoch: 116, loss: 0.297299
global_step: 28610, epoch: 116, loss: 0.250037
global_step: 28611, epoch: 116, loss: 0.251097
global_step: 28612, epoch: 116, loss: 0.243851
global_step: 28613, epoch: 116, loss: 0.264883
global_step: 28614, epoch: 116, loss: 0.296299
global_step: 28615, epoch: 116, loss: 0.270975
global_step: 28616, epoch: 116, loss: 0.296208
global_step: 28617, epoch: 116, loss: 0.289403
global_step: 28618, epoch: 116, loss: 0.246769
global_step: 28619, epoch: 116, loss: 0.245964
global_step: 28620, epoch: 116, loss: 0.299840
global_step: 28621, epoch: 116, loss: 0.293714
global_step: 28622, epoch: 116, loss: 0.270976
global_step: 28623, epoch: 116, loss: 0.325064
global_step: 28624, epoch: 116, loss: 0.373982
global_step: 28625, epoch: 116, loss: 0.324402
global_step: 28626, epoch: 116, loss: 0.237035
global_step: 28627, epoch: 116, loss: 0.276320
global_step: 28628, epoch: 116, loss: 0.255543
global_step: 28629, epoch: 116, loss: 0.248002
global_step: 28630, epoch: 116, loss: 0.298347
global_step: 28631, epoch: 116, loss: 0.240212
global_step: 28632, epoch: 116, loss: 0.280576
global_step: 28633, epoch: 116, loss: 0.342126
global_step: 28634, epoch: 116, loss: 0.333630
global_step: 28635, epoch: 116, loss: 0.290091
global_step: 28636, epoch: 116, loss: 0.253190
global_step: 28637, epoch: 116, loss: 0.274720
global_step: 28638, epoch: 116, loss: 0.294837
global_step: 28639, epoch: 116, loss: 0.268898
global_step: 28640, epoch: 116, loss: 0.121472
epoch: 116
train	acc: 0.9637	macro: p 0.9693, r 0.9417, f1: 0.9546	micro: p 0.9637, r 0.9637, f1 0.9637	weighted_f1:0.9637
dev	acc: 0.5239	macro: p 0.3753, r 0.3076, f1: 0.3055	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4815
test	acc: 0.5759	macro: p 0.3585, r 0.3188, f1: 0.3193	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5415
global_step: 28641, epoch: 117, loss: 0.258396
global_step: 28642, epoch: 117, loss: 0.358671
global_step: 28643, epoch: 117, loss: 0.264701
global_step: 28644, epoch: 117, loss: 0.290387
global_step: 28645, epoch: 117, loss: 0.249449
global_step: 28646, epoch: 117, loss: 0.267059
global_step: 28647, epoch: 117, loss: 0.273817
global_step: 28648, epoch: 117, loss: 0.248821
global_step: 28649, epoch: 117, loss: 0.233549
global_step: 28650, epoch: 117, loss: 0.272465
global_step: 28651, epoch: 117, loss: 0.266079
global_step: 28652, epoch: 117, loss: 0.346187
global_step: 28653, epoch: 117, loss: 0.304338
global_step: 28654, epoch: 117, loss: 0.217278
global_step: 28655, epoch: 117, loss: 0.204100
global_step: 28656, epoch: 117, loss: 0.271143
global_step: 28657, epoch: 117, loss: 0.306073
global_step: 28658, epoch: 117, loss: 0.295959
global_step: 28659, epoch: 117, loss: 0.191412
global_step: 28660, epoch: 117, loss: 0.325895
global_step: 28661, epoch: 117, loss: 0.293903
global_step: 28662, epoch: 117, loss: 0.285783
global_step: 28663, epoch: 117, loss: 0.303857
global_step: 28664, epoch: 117, loss: 0.253969
global_step: 28665, epoch: 117, loss: 0.290845
global_step: 28666, epoch: 117, loss: 0.238625
global_step: 28667, epoch: 117, loss: 0.305268
global_step: 28668, epoch: 117, loss: 0.321089
global_step: 28669, epoch: 117, loss: 0.239166
global_step: 28670, epoch: 117, loss: 0.286794
global_step: 28671, epoch: 117, loss: 0.291067
global_step: 28672, epoch: 117, loss: 0.244644
global_step: 28673, epoch: 117, loss: 0.280790
global_step: 28674, epoch: 117, loss: 0.347182
global_step: 28675, epoch: 117, loss: 0.313638
global_step: 28676, epoch: 117, loss: 0.295256
global_step: 28677, epoch: 117, loss: 0.313890
global_step: 28678, epoch: 117, loss: 0.328214
global_step: 28679, epoch: 117, loss: 0.258898
global_step: 28680, epoch: 117, loss: 0.046366
epoch: 117
train	acc: 0.9652	macro: p 0.9706, r 0.9441, f1: 0.9567	micro: p 0.9652, r 0.9652, f1 0.9652	weighted_f1:0.9651
dev	acc: 0.5194	macro: p 0.3525, r 0.3025, f1: 0.3046	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4788
test	acc: 0.5755	macro: p 0.3642, r 0.3201, f1: 0.3276	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5443
global_step: 28681, epoch: 118, loss: 0.179098
global_step: 28682, epoch: 118, loss: 0.251531
global_step: 28683, epoch: 118, loss: 0.291464
global_step: 28684, epoch: 118, loss: 0.268452
global_step: 28685, epoch: 118, loss: 0.246119
global_step: 28686, epoch: 118, loss: 0.283375
global_step: 28687, epoch: 118, loss: 0.226061
global_step: 28688, epoch: 118, loss: 0.201565
global_step: 28689, epoch: 118, loss: 0.287959
global_step: 28690, epoch: 118, loss: 0.242678
global_step: 28691, epoch: 118, loss: 0.329465
global_step: 28692, epoch: 118, loss: 0.270071
global_step: 28693, epoch: 118, loss: 0.308818
global_step: 28694, epoch: 118, loss: 0.236982
global_step: 28695, epoch: 118, loss: 0.301929
global_step: 28696, epoch: 118, loss: 0.288535
global_step: 28697, epoch: 118, loss: 0.248000
global_step: 28698, epoch: 118, loss: 0.291259
global_step: 28699, epoch: 118, loss: 0.250818
global_step: 28700, epoch: 118, loss: 0.333528
global_step: 28701, epoch: 118, loss: 0.306961
global_step: 28702, epoch: 118, loss: 0.320328
global_step: 28703, epoch: 118, loss: 0.240160
global_step: 28704, epoch: 118, loss: 0.323297
global_step: 28705, epoch: 118, loss: 0.255275
global_step: 28706, epoch: 118, loss: 0.342187
global_step: 28707, epoch: 118, loss: 0.282789
global_step: 28708, epoch: 118, loss: 0.371378
global_step: 28709, epoch: 118, loss: 0.248380
global_step: 28710, epoch: 118, loss: 0.236639
global_step: 28711, epoch: 118, loss: 0.218839
global_step: 28712, epoch: 118, loss: 0.261052
global_step: 28713, epoch: 118, loss: 0.265391
global_step: 28714, epoch: 118, loss: 0.291700
global_step: 28715, epoch: 118, loss: 0.233002
global_step: 28716, epoch: 118, loss: 0.267528
global_step: 28717, epoch: 118, loss: 0.302709
global_step: 28718, epoch: 118, loss: 0.407459
global_step: 28719, epoch: 118, loss: 0.241709
global_step: 28720, epoch: 118, loss: 0.143092
epoch: 118
train	acc: 0.9656	macro: p 0.9712, r 0.9461, f1: 0.9581	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9655
dev	acc: 0.5293	macro: p 0.3551, r 0.3018, f1: 0.3056	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4837
test	acc: 0.5831	macro: p 0.3581, r 0.3141, f1: 0.3215	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5452
global_step: 28721, epoch: 119, loss: 0.333819
global_step: 28722, epoch: 119, loss: 0.285570
global_step: 28723, epoch: 119, loss: 0.202256
global_step: 28724, epoch: 119, loss: 0.259611
global_step: 28725, epoch: 119, loss: 0.203845
global_step: 28726, epoch: 119, loss: 0.268874
global_step: 28727, epoch: 119, loss: 0.257635
global_step: 28728, epoch: 119, loss: 0.233121
global_step: 28729, epoch: 119, loss: 0.233670
global_step: 28730, epoch: 119, loss: 0.219540
global_step: 28731, epoch: 119, loss: 0.223618
global_step: 28732, epoch: 119, loss: 0.310877
global_step: 28733, epoch: 119, loss: 0.256699
global_step: 28734, epoch: 119, loss: 0.306035
global_step: 28735, epoch: 119, loss: 0.211478
global_step: 28736, epoch: 119, loss: 0.262213
global_step: 28737, epoch: 119, loss: 0.256753
global_step: 28738, epoch: 119, loss: 0.330046
global_step: 28739, epoch: 119, loss: 0.267702
global_step: 28740, epoch: 119, loss: 0.213942
global_step: 28741, epoch: 119, loss: 0.297798
global_step: 28742, epoch: 119, loss: 0.328649
global_step: 28743, epoch: 119, loss: 0.249416
global_step: 28744, epoch: 119, loss: 0.326624
global_step: 28745, epoch: 119, loss: 0.287240
global_step: 28746, epoch: 119, loss: 0.280870
global_step: 28747, epoch: 119, loss: 0.298397
global_step: 28748, epoch: 119, loss: 0.279944
global_step: 28749, epoch: 119, loss: 0.254691
global_step: 28750, epoch: 119, loss: 0.295326
global_step: 28751, epoch: 119, loss: 0.295370
global_step: 28752, epoch: 119, loss: 0.215955
global_step: 28753, epoch: 119, loss: 0.344348
global_step: 28754, epoch: 119, loss: 0.284504
global_step: 28755, epoch: 119, loss: 0.317293
global_step: 28756, epoch: 119, loss: 0.247850
global_step: 28757, epoch: 119, loss: 0.288785
global_step: 28758, epoch: 119, loss: 0.223085
global_step: 28759, epoch: 119, loss: 0.308268
global_step: 28760, epoch: 119, loss: 0.502676
epoch: 119
train	acc: 0.9640	macro: p 0.9713, r 0.9416, f1: 0.9556	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9639
dev	acc: 0.5257	macro: p 0.3432, r 0.2978, f1: 0.2946	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4768
test	acc: 0.5778	macro: p 0.3605, r 0.3122, f1: 0.3153	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5390
global_step: 28761, epoch: 120, loss: 0.268862
global_step: 28762, epoch: 120, loss: 0.280814
global_step: 28763, epoch: 120, loss: 0.278698
global_step: 28764, epoch: 120, loss: 0.236116
global_step: 28765, epoch: 120, loss: 0.233255
global_step: 28766, epoch: 120, loss: 0.300133
global_step: 28767, epoch: 120, loss: 0.261063
global_step: 28768, epoch: 120, loss: 0.321961
global_step: 28769, epoch: 120, loss: 0.223563
global_step: 28770, epoch: 120, loss: 0.232610
global_step: 28771, epoch: 120, loss: 0.211592
global_step: 28772, epoch: 120, loss: 0.284344
global_step: 28773, epoch: 120, loss: 0.247230
global_step: 28774, epoch: 120, loss: 0.293641
global_step: 28775, epoch: 120, loss: 0.283918
global_step: 28776, epoch: 120, loss: 0.259568
global_step: 28777, epoch: 120, loss: 0.210614
global_step: 28778, epoch: 120, loss: 0.305891
global_step: 28779, epoch: 120, loss: 0.316557
global_step: 28780, epoch: 120, loss: 0.274971
global_step: 28781, epoch: 120, loss: 0.219191
global_step: 28782, epoch: 120, loss: 0.290669
global_step: 28783, epoch: 120, loss: 0.234990
global_step: 28784, epoch: 120, loss: 0.304676
global_step: 28785, epoch: 120, loss: 0.238960
global_step: 28786, epoch: 120, loss: 0.266387
global_step: 28787, epoch: 120, loss: 0.280344
global_step: 28788, epoch: 120, loss: 0.243441
global_step: 28789, epoch: 120, loss: 0.287345
global_step: 28790, epoch: 120, loss: 0.277145
global_step: 28791, epoch: 120, loss: 0.361065
global_step: 28792, epoch: 120, loss: 0.335090
global_step: 28793, epoch: 120, loss: 0.302118
global_step: 28794, epoch: 120, loss: 0.247194
global_step: 28795, epoch: 120, loss: 0.183875
global_step: 28796, epoch: 120, loss: 0.289328
global_step: 28797, epoch: 120, loss: 0.215685
global_step: 28798, epoch: 120, loss: 0.302672
global_step: 28799, epoch: 120, loss: 0.261536
global_step: 28800, epoch: 120, loss: 0.017706
epoch: 120
train	acc: 0.9654	macro: p 0.9715, r 0.9435, f1: 0.9568	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9653
dev	acc: 0.5257	macro: p 0.3504, r 0.2985, f1: 0.2993	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4789
test	acc: 0.5801	macro: p 0.3526, r 0.3095, f1: 0.3153	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5422
global_step: 28801, epoch: 121, loss: 0.227274
global_step: 28802, epoch: 121, loss: 0.310308
global_step: 28803, epoch: 121, loss: 0.210047
global_step: 28804, epoch: 121, loss: 0.266331
global_step: 28805, epoch: 121, loss: 0.225591
global_step: 28806, epoch: 121, loss: 0.264274
global_step: 28807, epoch: 121, loss: 0.182115
global_step: 28808, epoch: 121, loss: 0.225217
global_step: 28809, epoch: 121, loss: 0.314328
global_step: 28810, epoch: 121, loss: 0.213017
global_step: 28811, epoch: 121, loss: 0.220090
global_step: 28812, epoch: 121, loss: 0.263115
global_step: 28813, epoch: 121, loss: 0.299538
global_step: 28814, epoch: 121, loss: 0.231352
global_step: 28815, epoch: 121, loss: 0.254760
global_step: 28816, epoch: 121, loss: 0.245549
global_step: 28817, epoch: 121, loss: 0.268389
global_step: 28818, epoch: 121, loss: 0.339148
global_step: 28819, epoch: 121, loss: 0.279291
global_step: 28820, epoch: 121, loss: 0.300697
global_step: 28821, epoch: 121, loss: 0.253941
global_step: 28822, epoch: 121, loss: 0.202273
global_step: 28823, epoch: 121, loss: 0.300948
global_step: 28824, epoch: 121, loss: 0.290038
global_step: 28825, epoch: 121, loss: 0.290655
global_step: 28826, epoch: 121, loss: 0.247519
global_step: 28827, epoch: 121, loss: 0.236290
global_step: 28828, epoch: 121, loss: 0.344049
global_step: 28829, epoch: 121, loss: 0.224230
global_step: 28830, epoch: 121, loss: 0.263720
global_step: 28831, epoch: 121, loss: 0.225627
global_step: 28832, epoch: 121, loss: 0.230197
global_step: 28833, epoch: 121, loss: 0.313899
global_step: 28834, epoch: 121, loss: 0.202895
global_step: 28835, epoch: 121, loss: 0.215242
global_step: 28836, epoch: 121, loss: 0.231802
global_step: 28837, epoch: 121, loss: 0.256416
global_step: 28838, epoch: 121, loss: 0.338570
global_step: 28839, epoch: 121, loss: 0.277391
global_step: 28840, epoch: 121, loss: 0.466253
epoch: 121
train	acc: 0.9665	macro: p 0.9718, r 0.9474, f1: 0.9590	micro: p 0.9665, r 0.9665, f1 0.9665	weighted_f1:0.9665
dev	acc: 0.5185	macro: p 0.3506, r 0.3033, f1: 0.3061	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4795
test	acc: 0.5755	macro: p 0.3557, r 0.3158, f1: 0.3213	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5428
global_step: 28841, epoch: 122, loss: 0.282947
global_step: 28842, epoch: 122, loss: 0.231401
global_step: 28843, epoch: 122, loss: 0.271155
global_step: 28844, epoch: 122, loss: 0.267524
global_step: 28845, epoch: 122, loss: 0.365327
global_step: 28846, epoch: 122, loss: 0.275182
global_step: 28847, epoch: 122, loss: 0.220533
global_step: 28848, epoch: 122, loss: 0.235990
global_step: 28849, epoch: 122, loss: 0.297951
global_step: 28850, epoch: 122, loss: 0.235248
global_step: 28851, epoch: 122, loss: 0.249683
global_step: 28852, epoch: 122, loss: 0.152605
global_step: 28853, epoch: 122, loss: 0.301479
global_step: 28854, epoch: 122, loss: 0.298670
global_step: 28855, epoch: 122, loss: 0.219666
global_step: 28856, epoch: 122, loss: 0.250918
global_step: 28857, epoch: 122, loss: 0.296956
global_step: 28858, epoch: 122, loss: 0.229532
global_step: 28859, epoch: 122, loss: 0.230967
global_step: 28860, epoch: 122, loss: 0.323630
global_step: 28861, epoch: 122, loss: 0.291817
global_step: 28862, epoch: 122, loss: 0.247036
global_step: 28863, epoch: 122, loss: 0.219964
global_step: 28864, epoch: 122, loss: 0.230429
global_step: 28865, epoch: 122, loss: 0.337567
global_step: 28866, epoch: 122, loss: 0.218874
global_step: 28867, epoch: 122, loss: 0.181507
global_step: 28868, epoch: 122, loss: 0.273290
global_step: 28869, epoch: 122, loss: 0.286089
global_step: 28870, epoch: 122, loss: 0.302649
global_step: 28871, epoch: 122, loss: 0.221459
global_step: 28872, epoch: 122, loss: 0.242593
global_step: 28873, epoch: 122, loss: 0.237919
global_step: 28874, epoch: 122, loss: 0.254452
global_step: 28875, epoch: 122, loss: 0.286450
global_step: 28876, epoch: 122, loss: 0.265759
global_step: 28877, epoch: 122, loss: 0.339643
global_step: 28878, epoch: 122, loss: 0.310138
global_step: 28879, epoch: 122, loss: 0.368595
global_step: 28880, epoch: 122, loss: 0.053096
epoch: 122
train	acc: 0.9650	macro: p 0.9717, r 0.9437, f1: 0.9569	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9649
dev	acc: 0.5266	macro: p 0.3720, r 0.2987, f1: 0.2996	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4766
test	acc: 0.5808	macro: p 0.3547, r 0.3041, f1: 0.3084	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5372
global_step: 28881, epoch: 123, loss: 0.187601
global_step: 28882, epoch: 123, loss: 0.287367
global_step: 28883, epoch: 123, loss: 0.237872
global_step: 28884, epoch: 123, loss: 0.296566
global_step: 28885, epoch: 123, loss: 0.214541
global_step: 28886, epoch: 123, loss: 0.315944
global_step: 28887, epoch: 123, loss: 0.293746
global_step: 28888, epoch: 123, loss: 0.179992
global_step: 28889, epoch: 123, loss: 0.246002
global_step: 28890, epoch: 123, loss: 0.219228
global_step: 28891, epoch: 123, loss: 0.244691
global_step: 28892, epoch: 123, loss: 0.235495
global_step: 28893, epoch: 123, loss: 0.330444
global_step: 28894, epoch: 123, loss: 0.224002
global_step: 28895, epoch: 123, loss: 0.307504
global_step: 28896, epoch: 123, loss: 0.215253
global_step: 28897, epoch: 123, loss: 0.285765
global_step: 28898, epoch: 123, loss: 0.250737
global_step: 28899, epoch: 123, loss: 0.341453
global_step: 28900, epoch: 123, loss: 0.250975
global_step: 28901, epoch: 123, loss: 0.305297
global_step: 28902, epoch: 123, loss: 0.284788
global_step: 28903, epoch: 123, loss: 0.315037
global_step: 28904, epoch: 123, loss: 0.173114
global_step: 28905, epoch: 123, loss: 0.230685
global_step: 28906, epoch: 123, loss: 0.297081
global_step: 28907, epoch: 123, loss: 0.289463
global_step: 28908, epoch: 123, loss: 0.272359
global_step: 28909, epoch: 123, loss: 0.203575
global_step: 28910, epoch: 123, loss: 0.287529
global_step: 28911, epoch: 123, loss: 0.232867
global_step: 28912, epoch: 123, loss: 0.228689
global_step: 28913, epoch: 123, loss: 0.237518
global_step: 28914, epoch: 123, loss: 0.333863
global_step: 28915, epoch: 123, loss: 0.267008
global_step: 28916, epoch: 123, loss: 0.236703
global_step: 28917, epoch: 123, loss: 0.285168
global_step: 28918, epoch: 123, loss: 0.207923
global_step: 28919, epoch: 123, loss: 0.317369
global_step: 28920, epoch: 123, loss: 0.155432
epoch: 123
train	acc: 0.9656	macro: p 0.9711, r 0.9436, f1: 0.9566	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9655
dev	acc: 0.5230	macro: p 0.3662, r 0.3022, f1: 0.3032	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4791
test	acc: 0.5812	macro: p 0.3654, r 0.3176, f1: 0.3241	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5452
global_step: 28921, epoch: 124, loss: 0.237885
global_step: 28922, epoch: 124, loss: 0.231580
global_step: 28923, epoch: 124, loss: 0.277961
global_step: 28924, epoch: 124, loss: 0.231578
global_step: 28925, epoch: 124, loss: 0.232403
global_step: 28926, epoch: 124, loss: 0.326846
global_step: 28927, epoch: 124, loss: 0.271112
global_step: 28928, epoch: 124, loss: 0.253186
global_step: 28929, epoch: 124, loss: 0.278711
global_step: 28930, epoch: 124, loss: 0.210316
global_step: 28931, epoch: 124, loss: 0.207611
global_step: 28932, epoch: 124, loss: 0.222424
global_step: 28933, epoch: 124, loss: 0.240159
global_step: 28934, epoch: 124, loss: 0.191033
global_step: 28935, epoch: 124, loss: 0.266935
global_step: 28936, epoch: 124, loss: 0.286421
global_step: 28937, epoch: 124, loss: 0.291205
global_step: 28938, epoch: 124, loss: 0.267255
global_step: 28939, epoch: 124, loss: 0.276651
global_step: 28940, epoch: 124, loss: 0.206480
global_step: 28941, epoch: 124, loss: 0.304221
global_step: 28942, epoch: 124, loss: 0.260428
global_step: 28943, epoch: 124, loss: 0.367024
global_step: 28944, epoch: 124, loss: 0.273522
global_step: 28945, epoch: 124, loss: 0.208073
global_step: 28946, epoch: 124, loss: 0.230598
global_step: 28947, epoch: 124, loss: 0.246693
global_step: 28948, epoch: 124, loss: 0.212433
global_step: 28949, epoch: 124, loss: 0.222651
global_step: 28950, epoch: 124, loss: 0.320008
global_step: 28951, epoch: 124, loss: 0.197528
global_step: 28952, epoch: 124, loss: 0.218833
global_step: 28953, epoch: 124, loss: 0.262799
global_step: 28954, epoch: 124, loss: 0.322919
global_step: 28955, epoch: 124, loss: 0.255063
global_step: 28956, epoch: 124, loss: 0.324053
global_step: 28957, epoch: 124, loss: 0.164611
global_step: 28958, epoch: 124, loss: 0.216577
global_step: 28959, epoch: 124, loss: 0.245905
global_step: 28960, epoch: 124, loss: 0.309845
epoch: 124
train	acc: 0.9650	macro: p 0.9705, r 0.9442, f1: 0.9565	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9650
dev	acc: 0.5275	macro: p 0.3751, r 0.3054, f1: 0.3032	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4820
test	acc: 0.5812	macro: p 0.3526, r 0.3133, f1: 0.3147	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5422
global_step: 28961, epoch: 125, loss: 0.293188
global_step: 28962, epoch: 125, loss: 0.271825
global_step: 28963, epoch: 125, loss: 0.254358
global_step: 28964, epoch: 125, loss: 0.209307
global_step: 28965, epoch: 125, loss: 0.256903
global_step: 28966, epoch: 125, loss: 0.337279
global_step: 28967, epoch: 125, loss: 0.239284
global_step: 28968, epoch: 125, loss: 0.224025
global_step: 28969, epoch: 125, loss: 0.252481
global_step: 28970, epoch: 125, loss: 0.218531
global_step: 28971, epoch: 125, loss: 0.266657
global_step: 28972, epoch: 125, loss: 0.281774
global_step: 28973, epoch: 125, loss: 0.206607
global_step: 28974, epoch: 125, loss: 0.247302
global_step: 28975, epoch: 125, loss: 0.209406
global_step: 28976, epoch: 125, loss: 0.245967
global_step: 28977, epoch: 125, loss: 0.299896
global_step: 28978, epoch: 125, loss: 0.264859
global_step: 28979, epoch: 125, loss: 0.205431
global_step: 28980, epoch: 125, loss: 0.257725
global_step: 28981, epoch: 125, loss: 0.199299
global_step: 28982, epoch: 125, loss: 0.269440
global_step: 28983, epoch: 125, loss: 0.311278
global_step: 28984, epoch: 125, loss: 0.218614
global_step: 28985, epoch: 125, loss: 0.239934
global_step: 28986, epoch: 125, loss: 0.295091
global_step: 28987, epoch: 125, loss: 0.209862
global_step: 28988, epoch: 125, loss: 0.243247
global_step: 28989, epoch: 125, loss: 0.278448
global_step: 28990, epoch: 125, loss: 0.216665
global_step: 28991, epoch: 125, loss: 0.313134
global_step: 28992, epoch: 125, loss: 0.249033
global_step: 28993, epoch: 125, loss: 0.249442
global_step: 28994, epoch: 125, loss: 0.272586
global_step: 28995, epoch: 125, loss: 0.226204
global_step: 28996, epoch: 125, loss: 0.319925
global_step: 28997, epoch: 125, loss: 0.218113
global_step: 28998, epoch: 125, loss: 0.247810
global_step: 28999, epoch: 125, loss: 0.226220
global_step: 29000, epoch: 125, loss: 0.288050
epoch: 125
train	acc: 0.9672	macro: p 0.9728, r 0.9487, f1: 0.9602	micro: p 0.9672, r 0.9672, f1 0.9672	weighted_f1:0.9672
dev	acc: 0.5257	macro: p 0.3632, r 0.3041, f1: 0.3045	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4801
test	acc: 0.5759	macro: p 0.3659, r 0.3117, f1: 0.3167	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5384
global_step: 29001, epoch: 126, loss: 0.268410
global_step: 29002, epoch: 126, loss: 0.221000
global_step: 29003, epoch: 126, loss: 0.287292
global_step: 29004, epoch: 126, loss: 0.226137
global_step: 29005, epoch: 126, loss: 0.289346
global_step: 29006, epoch: 126, loss: 0.230228
global_step: 29007, epoch: 126, loss: 0.239222
global_step: 29008, epoch: 126, loss: 0.295137
global_step: 29009, epoch: 126, loss: 0.219614
global_step: 29010, epoch: 126, loss: 0.270372
global_step: 29011, epoch: 126, loss: 0.258604
global_step: 29012, epoch: 126, loss: 0.230999
global_step: 29013, epoch: 126, loss: 0.208117
global_step: 29014, epoch: 126, loss: 0.261584
global_step: 29015, epoch: 126, loss: 0.198561
global_step: 29016, epoch: 126, loss: 0.214106
global_step: 29017, epoch: 126, loss: 0.230705
global_step: 29018, epoch: 126, loss: 0.319770
global_step: 29019, epoch: 126, loss: 0.278952
global_step: 29020, epoch: 126, loss: 0.271709
global_step: 29021, epoch: 126, loss: 0.303826
global_step: 29022, epoch: 126, loss: 0.229611
global_step: 29023, epoch: 126, loss: 0.211094
global_step: 29024, epoch: 126, loss: 0.296591
global_step: 29025, epoch: 126, loss: 0.296349
global_step: 29026, epoch: 126, loss: 0.217805
global_step: 29027, epoch: 126, loss: 0.221456
global_step: 29028, epoch: 126, loss: 0.186382
global_step: 29029, epoch: 126, loss: 0.319382
global_step: 29030, epoch: 126, loss: 0.290701
global_step: 29031, epoch: 126, loss: 0.286280
global_step: 29032, epoch: 126, loss: 0.253593
global_step: 29033, epoch: 126, loss: 0.332885
global_step: 29034, epoch: 126, loss: 0.331442
global_step: 29035, epoch: 126, loss: 0.239987
global_step: 29036, epoch: 126, loss: 0.293503
global_step: 29037, epoch: 126, loss: 0.184808
global_step: 29038, epoch: 126, loss: 0.270056
global_step: 29039, epoch: 126, loss: 0.212001
global_step: 29040, epoch: 126, loss: 0.069564
epoch: 126
train	acc: 0.9657	macro: p 0.9725, r 0.9466, f1: 0.9590	micro: p 0.9657, r 0.9657, f1 0.9657	weighted_f1:0.9656
dev	acc: 0.5257	macro: p 0.3695, r 0.3002, f1: 0.3045	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4814
test	acc: 0.5808	macro: p 0.3782, r 0.3143, f1: 0.3242	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5435
global_step: 29041, epoch: 127, loss: 0.247988
global_step: 29042, epoch: 127, loss: 0.241745
global_step: 29043, epoch: 127, loss: 0.224734
global_step: 29044, epoch: 127, loss: 0.263411
global_step: 29045, epoch: 127, loss: 0.301790
global_step: 29046, epoch: 127, loss: 0.296024
global_step: 29047, epoch: 127, loss: 0.226013
global_step: 29048, epoch: 127, loss: 0.332708
global_step: 29049, epoch: 127, loss: 0.254473
global_step: 29050, epoch: 127, loss: 0.196544
global_step: 29051, epoch: 127, loss: 0.270597
global_step: 29052, epoch: 127, loss: 0.288854
global_step: 29053, epoch: 127, loss: 0.233959
global_step: 29054, epoch: 127, loss: 0.249547
global_step: 29055, epoch: 127, loss: 0.249947
global_step: 29056, epoch: 127, loss: 0.221246
global_step: 29057, epoch: 127, loss: 0.195911
global_step: 29058, epoch: 127, loss: 0.250303
global_step: 29059, epoch: 127, loss: 0.313542
global_step: 29060, epoch: 127, loss: 0.262944
global_step: 29061, epoch: 127, loss: 0.230314
global_step: 29062, epoch: 127, loss: 0.320893
global_step: 29063, epoch: 127, loss: 0.289712
global_step: 29064, epoch: 127, loss: 0.223472
global_step: 29065, epoch: 127, loss: 0.242378
global_step: 29066, epoch: 127, loss: 0.278964
global_step: 29067, epoch: 127, loss: 0.224805
global_step: 29068, epoch: 127, loss: 0.295219
global_step: 29069, epoch: 127, loss: 0.245102
global_step: 29070, epoch: 127, loss: 0.230662
global_step: 29071, epoch: 127, loss: 0.277164
global_step: 29072, epoch: 127, loss: 0.292065
global_step: 29073, epoch: 127, loss: 0.289616
global_step: 29074, epoch: 127, loss: 0.237704
global_step: 29075, epoch: 127, loss: 0.278599
global_step: 29076, epoch: 127, loss: 0.261190
global_step: 29077, epoch: 127, loss: 0.247871
global_step: 29078, epoch: 127, loss: 0.171918
global_step: 29079, epoch: 127, loss: 0.287902
global_step: 29080, epoch: 127, loss: 0.066315
epoch: 127
train	acc: 0.9664	macro: p 0.9724, r 0.9473, f1: 0.9593	micro: p 0.9664, r 0.9664, f1 0.9664	weighted_f1:0.9664
dev	acc: 0.5257	macro: p 0.3566, r 0.3010, f1: 0.3012	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4807
test	acc: 0.5820	macro: p 0.3621, r 0.3148, f1: 0.3201	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5432
global_step: 29081, epoch: 128, loss: 0.179110
global_step: 29082, epoch: 128, loss: 0.218027
global_step: 29083, epoch: 128, loss: 0.208449
global_step: 29084, epoch: 128, loss: 0.264323
global_step: 29085, epoch: 128, loss: 0.290269
global_step: 29086, epoch: 128, loss: 0.204719
global_step: 29087, epoch: 128, loss: 0.216582
global_step: 29088, epoch: 128, loss: 0.275570
global_step: 29089, epoch: 128, loss: 0.278471
global_step: 29090, epoch: 128, loss: 0.256903
global_step: 29091, epoch: 128, loss: 0.225843
global_step: 29092, epoch: 128, loss: 0.274661
global_step: 29093, epoch: 128, loss: 0.249354
global_step: 29094, epoch: 128, loss: 0.227920
global_step: 29095, epoch: 128, loss: 0.284092
global_step: 29096, epoch: 128, loss: 0.272917
global_step: 29097, epoch: 128, loss: 0.272907
global_step: 29098, epoch: 128, loss: 0.248165
global_step: 29099, epoch: 128, loss: 0.217734
global_step: 29100, epoch: 128, loss: 0.227860
global_step: 29101, epoch: 128, loss: 0.279921
global_step: 29102, epoch: 128, loss: 0.243108
global_step: 29103, epoch: 128, loss: 0.242892
global_step: 29104, epoch: 128, loss: 0.297624
global_step: 29105, epoch: 128, loss: 0.242373
global_step: 29106, epoch: 128, loss: 0.209323
global_step: 29107, epoch: 128, loss: 0.322308
global_step: 29108, epoch: 128, loss: 0.196110
global_step: 29109, epoch: 128, loss: 0.279438
global_step: 29110, epoch: 128, loss: 0.187400
global_step: 29111, epoch: 128, loss: 0.349317
global_step: 29112, epoch: 128, loss: 0.268722
global_step: 29113, epoch: 128, loss: 0.227358
global_step: 29114, epoch: 128, loss: 0.191618
global_step: 29115, epoch: 128, loss: 0.228100
global_step: 29116, epoch: 128, loss: 0.229222
global_step: 29117, epoch: 128, loss: 0.265950
global_step: 29118, epoch: 128, loss: 0.304563
global_step: 29119, epoch: 128, loss: 0.192884
global_step: 29120, epoch: 128, loss: 1.773186
epoch: 128
train	acc: 0.9679	macro: p 0.9737, r 0.9489, f1: 0.9607	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9678
dev	acc: 0.5158	macro: p 0.3697, r 0.3028, f1: 0.3032	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4797
test	acc: 0.5716	macro: p 0.3460, r 0.3136, f1: 0.3175	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5408
global_step: 29121, epoch: 129, loss: 0.258392
global_step: 29122, epoch: 129, loss: 0.222767
global_step: 29123, epoch: 129, loss: 0.194395
global_step: 29124, epoch: 129, loss: 0.282501
global_step: 29125, epoch: 129, loss: 0.255424
global_step: 29126, epoch: 129, loss: 0.212359
global_step: 29127, epoch: 129, loss: 0.213248
global_step: 29128, epoch: 129, loss: 0.237914
global_step: 29129, epoch: 129, loss: 0.237400
global_step: 29130, epoch: 129, loss: 0.224973
global_step: 29131, epoch: 129, loss: 0.239257
global_step: 29132, epoch: 129, loss: 0.271953
global_step: 29133, epoch: 129, loss: 0.261879
global_step: 29134, epoch: 129, loss: 0.269787
global_step: 29135, epoch: 129, loss: 0.264879
global_step: 29136, epoch: 129, loss: 0.290886
global_step: 29137, epoch: 129, loss: 0.205809
global_step: 29138, epoch: 129, loss: 0.260044
global_step: 29139, epoch: 129, loss: 0.287860
global_step: 29140, epoch: 129, loss: 0.230635
global_step: 29141, epoch: 129, loss: 0.220129
global_step: 29142, epoch: 129, loss: 0.288024
global_step: 29143, epoch: 129, loss: 0.345915
global_step: 29144, epoch: 129, loss: 0.276658
global_step: 29145, epoch: 129, loss: 0.207996
global_step: 29146, epoch: 129, loss: 0.182697
global_step: 29147, epoch: 129, loss: 0.227581
global_step: 29148, epoch: 129, loss: 0.268510
global_step: 29149, epoch: 129, loss: 0.258969
global_step: 29150, epoch: 129, loss: 0.211106
global_step: 29151, epoch: 129, loss: 0.192800
global_step: 29152, epoch: 129, loss: 0.326362
global_step: 29153, epoch: 129, loss: 0.239054
global_step: 29154, epoch: 129, loss: 0.312505
global_step: 29155, epoch: 129, loss: 0.218413
global_step: 29156, epoch: 129, loss: 0.268929
global_step: 29157, epoch: 129, loss: 0.304883
global_step: 29158, epoch: 129, loss: 0.264789
global_step: 29159, epoch: 129, loss: 0.278597
global_step: 29160, epoch: 129, loss: 0.067228
epoch: 129
train	acc: 0.9672	macro: p 0.9726, r 0.9493, f1: 0.9603	micro: p 0.9672, r 0.9672, f1 0.9672	weighted_f1:0.9672
dev	acc: 0.5140	macro: p 0.3409, r 0.3010, f1: 0.3015	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4763
test	acc: 0.5743	macro: p 0.3542, r 0.3193, f1: 0.3244	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5442
global_step: 29161, epoch: 130, loss: 0.258168
global_step: 29162, epoch: 130, loss: 0.203975
global_step: 29163, epoch: 130, loss: 0.274493
global_step: 29164, epoch: 130, loss: 0.236854
global_step: 29165, epoch: 130, loss: 0.223233
global_step: 29166, epoch: 130, loss: 0.267113
global_step: 29167, epoch: 130, loss: 0.221977
global_step: 29168, epoch: 130, loss: 0.246083
global_step: 29169, epoch: 130, loss: 0.210927
global_step: 29170, epoch: 130, loss: 0.305051
global_step: 29171, epoch: 130, loss: 0.201674
global_step: 29172, epoch: 130, loss: 0.240875
global_step: 29173, epoch: 130, loss: 0.202769
global_step: 29174, epoch: 130, loss: 0.193833
global_step: 29175, epoch: 130, loss: 0.239398
global_step: 29176, epoch: 130, loss: 0.255808
global_step: 29177, epoch: 130, loss: 0.258073
global_step: 29178, epoch: 130, loss: 0.300857
global_step: 29179, epoch: 130, loss: 0.178188
global_step: 29180, epoch: 130, loss: 0.208677
global_step: 29181, epoch: 130, loss: 0.188396
global_step: 29182, epoch: 130, loss: 0.276640
global_step: 29183, epoch: 130, loss: 0.270461
global_step: 29184, epoch: 130, loss: 0.291867
global_step: 29185, epoch: 130, loss: 0.271370
global_step: 29186, epoch: 130, loss: 0.243299
global_step: 29187, epoch: 130, loss: 0.201692
global_step: 29188, epoch: 130, loss: 0.218990
global_step: 29189, epoch: 130, loss: 0.214242
global_step: 29190, epoch: 130, loss: 0.160532
global_step: 29191, epoch: 130, loss: 0.185919
global_step: 29192, epoch: 130, loss: 0.197093
global_step: 29193, epoch: 130, loss: 0.251559
global_step: 29194, epoch: 130, loss: 0.167667
global_step: 29195, epoch: 130, loss: 0.290334
global_step: 29196, epoch: 130, loss: 0.238330
global_step: 29197, epoch: 130, loss: 0.331825
global_step: 29198, epoch: 130, loss: 0.250193
global_step: 29199, epoch: 130, loss: 0.273890
global_step: 29200, epoch: 130, loss: 0.029034
epoch: 130
train	acc: 0.9674	macro: p 0.9733, r 0.9498, f1: 0.9610	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9674
dev	acc: 0.5203	macro: p 0.3446, r 0.3020, f1: 0.3027	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4795
test	acc: 0.5762	macro: p 0.3647, r 0.3182, f1: 0.3264	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5428
global_step: 29201, epoch: 131, loss: 0.273340
global_step: 29202, epoch: 131, loss: 0.265889
global_step: 29203, epoch: 131, loss: 0.233676
global_step: 29204, epoch: 131, loss: 0.279126
global_step: 29205, epoch: 131, loss: 0.206005
global_step: 29206, epoch: 131, loss: 0.198778
global_step: 29207, epoch: 131, loss: 0.268276
global_step: 29208, epoch: 131, loss: 0.183638
global_step: 29209, epoch: 131, loss: 0.246921
global_step: 29210, epoch: 131, loss: 0.359596
global_step: 29211, epoch: 131, loss: 0.261014
global_step: 29212, epoch: 131, loss: 0.305459
global_step: 29213, epoch: 131, loss: 0.245218
global_step: 29214, epoch: 131, loss: 0.182109
global_step: 29215, epoch: 131, loss: 0.274645
global_step: 29216, epoch: 131, loss: 0.260992
global_step: 29217, epoch: 131, loss: 0.238537
global_step: 29218, epoch: 131, loss: 0.189004
global_step: 29219, epoch: 131, loss: 0.254387
global_step: 29220, epoch: 131, loss: 0.313007
global_step: 29221, epoch: 131, loss: 0.241837
global_step: 29222, epoch: 131, loss: 0.210230
global_step: 29223, epoch: 131, loss: 0.238216
global_step: 29224, epoch: 131, loss: 0.270193
global_step: 29225, epoch: 131, loss: 0.242712
global_step: 29226, epoch: 131, loss: 0.220335
global_step: 29227, epoch: 131, loss: 0.232869
global_step: 29228, epoch: 131, loss: 0.289328
global_step: 29229, epoch: 131, loss: 0.312752
global_step: 29230, epoch: 131, loss: 0.351190
global_step: 29231, epoch: 131, loss: 0.244266
global_step: 29232, epoch: 131, loss: 0.253043
global_step: 29233, epoch: 131, loss: 0.222550
global_step: 29234, epoch: 131, loss: 0.221619
global_step: 29235, epoch: 131, loss: 0.166332
global_step: 29236, epoch: 131, loss: 0.234666
global_step: 29237, epoch: 131, loss: 0.260577
global_step: 29238, epoch: 131, loss: 0.247600
global_step: 29239, epoch: 131, loss: 0.220251
global_step: 29240, epoch: 131, loss: 0.060626
epoch: 131
train	acc: 0.9677	macro: p 0.9729, r 0.9483, f1: 0.9600	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5221	macro: p 0.3424, r 0.2992, f1: 0.3001	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4788
test	acc: 0.5797	macro: p 0.3782, r 0.3177, f1: 0.3256	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5449
global_step: 29241, epoch: 132, loss: 0.184774
global_step: 29242, epoch: 132, loss: 0.247735
global_step: 29243, epoch: 132, loss: 0.256075
global_step: 29244, epoch: 132, loss: 0.247192
global_step: 29245, epoch: 132, loss: 0.251340
global_step: 29246, epoch: 132, loss: 0.225540
global_step: 29247, epoch: 132, loss: 0.198940
global_step: 29248, epoch: 132, loss: 0.193330
global_step: 29249, epoch: 132, loss: 0.200548
global_step: 29250, epoch: 132, loss: 0.271805
global_step: 29251, epoch: 132, loss: 0.298381
global_step: 29252, epoch: 132, loss: 0.250174
global_step: 29253, epoch: 132, loss: 0.227312
global_step: 29254, epoch: 132, loss: 0.295897
global_step: 29255, epoch: 132, loss: 0.264861
global_step: 29256, epoch: 132, loss: 0.205505
global_step: 29257, epoch: 132, loss: 0.288286
global_step: 29258, epoch: 132, loss: 0.205170
global_step: 29259, epoch: 132, loss: 0.269930
global_step: 29260, epoch: 132, loss: 0.339518
global_step: 29261, epoch: 132, loss: 0.275661
global_step: 29262, epoch: 132, loss: 0.231776
global_step: 29263, epoch: 132, loss: 0.239662
global_step: 29264, epoch: 132, loss: 0.249741
global_step: 29265, epoch: 132, loss: 0.201589
global_step: 29266, epoch: 132, loss: 0.183261
global_step: 29267, epoch: 132, loss: 0.251424
global_step: 29268, epoch: 132, loss: 0.233735
global_step: 29269, epoch: 132, loss: 0.221421
global_step: 29270, epoch: 132, loss: 0.192034
global_step: 29271, epoch: 132, loss: 0.211027
global_step: 29272, epoch: 132, loss: 0.263764
global_step: 29273, epoch: 132, loss: 0.326910
global_step: 29274, epoch: 132, loss: 0.223408
global_step: 29275, epoch: 132, loss: 0.256092
global_step: 29276, epoch: 132, loss: 0.186910
global_step: 29277, epoch: 132, loss: 0.218233
global_step: 29278, epoch: 132, loss: 0.206505
global_step: 29279, epoch: 132, loss: 0.201445
global_step: 29280, epoch: 132, loss: 2.574888
epoch: 132
train	acc: 0.9674	macro: p 0.9735, r 0.9498, f1: 0.9612	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9673
dev	acc: 0.5302	macro: p 0.3638, r 0.2985, f1: 0.3052	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4817
test	acc: 0.5766	macro: p 0.3557, r 0.3055, f1: 0.3151	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5369
global_step: 29281, epoch: 133, loss: 0.201931
global_step: 29282, epoch: 133, loss: 0.277223
global_step: 29283, epoch: 133, loss: 0.218526
global_step: 29284, epoch: 133, loss: 0.223762
global_step: 29285, epoch: 133, loss: 0.197073
global_step: 29286, epoch: 133, loss: 0.231398
global_step: 29287, epoch: 133, loss: 0.346548
global_step: 29288, epoch: 133, loss: 0.193987
global_step: 29289, epoch: 133, loss: 0.265131
global_step: 29290, epoch: 133, loss: 0.177871
global_step: 29291, epoch: 133, loss: 0.231878
global_step: 29292, epoch: 133, loss: 0.244334
global_step: 29293, epoch: 133, loss: 0.204004
global_step: 29294, epoch: 133, loss: 0.240039
global_step: 29295, epoch: 133, loss: 0.306085
global_step: 29296, epoch: 133, loss: 0.291245
global_step: 29297, epoch: 133, loss: 0.192645
global_step: 29298, epoch: 133, loss: 0.280404
global_step: 29299, epoch: 133, loss: 0.252406
global_step: 29300, epoch: 133, loss: 0.272296
global_step: 29301, epoch: 133, loss: 0.226940
global_step: 29302, epoch: 133, loss: 0.256658
global_step: 29303, epoch: 133, loss: 0.222870
global_step: 29304, epoch: 133, loss: 0.361423
global_step: 29305, epoch: 133, loss: 0.210318
global_step: 29306, epoch: 133, loss: 0.224421
global_step: 29307, epoch: 133, loss: 0.211330
global_step: 29308, epoch: 133, loss: 0.219260
global_step: 29309, epoch: 133, loss: 0.246077
global_step: 29310, epoch: 133, loss: 0.197751
global_step: 29311, epoch: 133, loss: 0.229012
global_step: 29312, epoch: 133, loss: 0.270760
global_step: 29313, epoch: 133, loss: 0.223780
global_step: 29314, epoch: 133, loss: 0.253706
global_step: 29315, epoch: 133, loss: 0.318588
global_step: 29316, epoch: 133, loss: 0.257460
global_step: 29317, epoch: 133, loss: 0.237357
global_step: 29318, epoch: 133, loss: 0.216485
global_step: 29319, epoch: 133, loss: 0.193355
global_step: 29320, epoch: 133, loss: 0.008183
epoch: 133
train	acc: 0.9677	macro: p 0.9727, r 0.9510, f1: 0.9613	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5284	macro: p 0.3680, r 0.3020, f1: 0.3035	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4820
test	acc: 0.5778	macro: p 0.3523, r 0.3091, f1: 0.3141	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5387
global_step: 29321, epoch: 134, loss: 0.175621
global_step: 29322, epoch: 134, loss: 0.254992
global_step: 29323, epoch: 134, loss: 0.353233
global_step: 29324, epoch: 134, loss: 0.224885
global_step: 29325, epoch: 134, loss: 0.214510
global_step: 29326, epoch: 134, loss: 0.179386
global_step: 29327, epoch: 134, loss: 0.271775
global_step: 29328, epoch: 134, loss: 0.263606
global_step: 29329, epoch: 134, loss: 0.283081
global_step: 29330, epoch: 134, loss: 0.197579
global_step: 29331, epoch: 134, loss: 0.230357
global_step: 29332, epoch: 134, loss: 0.227894
global_step: 29333, epoch: 134, loss: 0.177595
global_step: 29334, epoch: 134, loss: 0.239998
global_step: 29335, epoch: 134, loss: 0.244652
global_step: 29336, epoch: 134, loss: 0.225134
global_step: 29337, epoch: 134, loss: 0.223833
global_step: 29338, epoch: 134, loss: 0.163344
global_step: 29339, epoch: 134, loss: 0.204521
global_step: 29340, epoch: 134, loss: 0.195576
global_step: 29341, epoch: 134, loss: 0.297726
global_step: 29342, epoch: 134, loss: 0.292945
global_step: 29343, epoch: 134, loss: 0.301004
global_step: 29344, epoch: 134, loss: 0.204976
global_step: 29345, epoch: 134, loss: 0.261433
global_step: 29346, epoch: 134, loss: 0.213738
global_step: 29347, epoch: 134, loss: 0.183188
global_step: 29348, epoch: 134, loss: 0.195010
global_step: 29349, epoch: 134, loss: 0.196491
global_step: 29350, epoch: 134, loss: 0.279391
global_step: 29351, epoch: 134, loss: 0.306019
global_step: 29352, epoch: 134, loss: 0.227802
global_step: 29353, epoch: 134, loss: 0.210665
global_step: 29354, epoch: 134, loss: 0.235000
global_step: 29355, epoch: 134, loss: 0.276149
global_step: 29356, epoch: 134, loss: 0.255733
global_step: 29357, epoch: 134, loss: 0.192312
global_step: 29358, epoch: 134, loss: 0.324781
global_step: 29359, epoch: 134, loss: 0.200084
global_step: 29360, epoch: 134, loss: 0.031345
epoch: 134
train	acc: 0.9676	macro: p 0.9731, r 0.9507, f1: 0.9614	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5302	macro: p 0.3803, r 0.3050, f1: 0.3068	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4828
test	acc: 0.5751	macro: p 0.3291, r 0.3034, f1: 0.3047	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5345
global_step: 29361, epoch: 135, loss: 0.290241
global_step: 29362, epoch: 135, loss: 0.228381
global_step: 29363, epoch: 135, loss: 0.256337
global_step: 29364, epoch: 135, loss: 0.272653
global_step: 29365, epoch: 135, loss: 0.196290
global_step: 29366, epoch: 135, loss: 0.229438
global_step: 29367, epoch: 135, loss: 0.242495
global_step: 29368, epoch: 135, loss: 0.193548
global_step: 29369, epoch: 135, loss: 0.222018
global_step: 29370, epoch: 135, loss: 0.193346
global_step: 29371, epoch: 135, loss: 0.235756
global_step: 29372, epoch: 135, loss: 0.240772
global_step: 29373, epoch: 135, loss: 0.177902
global_step: 29374, epoch: 135, loss: 0.181838
global_step: 29375, epoch: 135, loss: 0.239209
global_step: 29376, epoch: 135, loss: 0.230292
global_step: 29377, epoch: 135, loss: 0.242365
global_step: 29378, epoch: 135, loss: 0.244684
global_step: 29379, epoch: 135, loss: 0.155830
global_step: 29380, epoch: 135, loss: 0.182726
global_step: 29381, epoch: 135, loss: 0.261688
global_step: 29382, epoch: 135, loss: 0.268477
global_step: 29383, epoch: 135, loss: 0.232251
global_step: 29384, epoch: 135, loss: 0.210156
global_step: 29385, epoch: 135, loss: 0.307653
global_step: 29386, epoch: 135, loss: 0.243740
global_step: 29387, epoch: 135, loss: 0.288303
global_step: 29388, epoch: 135, loss: 0.238398
global_step: 29389, epoch: 135, loss: 0.211775
global_step: 29390, epoch: 135, loss: 0.244454
global_step: 29391, epoch: 135, loss: 0.285647
global_step: 29392, epoch: 135, loss: 0.232967
global_step: 29393, epoch: 135, loss: 0.197669
global_step: 29394, epoch: 135, loss: 0.234663
global_step: 29395, epoch: 135, loss: 0.263524
global_step: 29396, epoch: 135, loss: 0.204347
global_step: 29397, epoch: 135, loss: 0.229479
global_step: 29398, epoch: 135, loss: 0.183186
global_step: 29399, epoch: 135, loss: 0.230062
global_step: 29400, epoch: 135, loss: 0.020908
epoch: 135
train	acc: 0.9683	macro: p 0.9733, r 0.9536, f1: 0.9630	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5239	macro: p 0.4078, r 0.3008, f1: 0.3036	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4780
test	acc: 0.5747	macro: p 0.3524, r 0.3086, f1: 0.3131	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5363
global_step: 29401, epoch: 136, loss: 0.263116
global_step: 29402, epoch: 136, loss: 0.250483
global_step: 29403, epoch: 136, loss: 0.248120
global_step: 29404, epoch: 136, loss: 0.236840
global_step: 29405, epoch: 136, loss: 0.230662
global_step: 29406, epoch: 136, loss: 0.174603
global_step: 29407, epoch: 136, loss: 0.284997
global_step: 29408, epoch: 136, loss: 0.256709
global_step: 29409, epoch: 136, loss: 0.198538
global_step: 29410, epoch: 136, loss: 0.251530
global_step: 29411, epoch: 136, loss: 0.185754
global_step: 29412, epoch: 136, loss: 0.232311
global_step: 29413, epoch: 136, loss: 0.148306
global_step: 29414, epoch: 136, loss: 0.308407
global_step: 29415, epoch: 136, loss: 0.271155
global_step: 29416, epoch: 136, loss: 0.267899
global_step: 29417, epoch: 136, loss: 0.217086
global_step: 29418, epoch: 136, loss: 0.242667
global_step: 29419, epoch: 136, loss: 0.310526
global_step: 29420, epoch: 136, loss: 0.244797
global_step: 29421, epoch: 136, loss: 0.217644
global_step: 29422, epoch: 136, loss: 0.251495
global_step: 29423, epoch: 136, loss: 0.242808
global_step: 29424, epoch: 136, loss: 0.304894
global_step: 29425, epoch: 136, loss: 0.258320
global_step: 29426, epoch: 136, loss: 0.237842
global_step: 29427, epoch: 136, loss: 0.212752
global_step: 29428, epoch: 136, loss: 0.192929
global_step: 29429, epoch: 136, loss: 0.229795
global_step: 29430, epoch: 136, loss: 0.205800
global_step: 29431, epoch: 136, loss: 0.195478
global_step: 29432, epoch: 136, loss: 0.300865
global_step: 29433, epoch: 136, loss: 0.202000
global_step: 29434, epoch: 136, loss: 0.261944
global_step: 29435, epoch: 136, loss: 0.205488
global_step: 29436, epoch: 136, loss: 0.296308
global_step: 29437, epoch: 136, loss: 0.270717
global_step: 29438, epoch: 136, loss: 0.246249
global_step: 29439, epoch: 136, loss: 0.270463
global_step: 29440, epoch: 136, loss: 0.829940
epoch: 136
train	acc: 0.9684	macro: p 0.9732, r 0.9521, f1: 0.9622	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5212	macro: p 0.3913, r 0.3025, f1: 0.3059	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4783
test	acc: 0.5739	macro: p 0.3448, r 0.3074, f1: 0.3113	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5355
global_step: 29441, epoch: 137, loss: 0.202091
global_step: 29442, epoch: 137, loss: 0.230977
global_step: 29443, epoch: 137, loss: 0.189285
global_step: 29444, epoch: 137, loss: 0.180054
global_step: 29445, epoch: 137, loss: 0.180310
global_step: 29446, epoch: 137, loss: 0.287713
global_step: 29447, epoch: 137, loss: 0.162575
global_step: 29448, epoch: 137, loss: 0.225506
global_step: 29449, epoch: 137, loss: 0.283654
global_step: 29450, epoch: 137, loss: 0.259803
global_step: 29451, epoch: 137, loss: 0.200151
global_step: 29452, epoch: 137, loss: 0.205647
global_step: 29453, epoch: 137, loss: 0.229675
global_step: 29454, epoch: 137, loss: 0.284965
global_step: 29455, epoch: 137, loss: 0.208457
global_step: 29456, epoch: 137, loss: 0.241030
global_step: 29457, epoch: 137, loss: 0.296205
global_step: 29458, epoch: 137, loss: 0.250064
global_step: 29459, epoch: 137, loss: 0.171837
global_step: 29460, epoch: 137, loss: 0.307993
global_step: 29461, epoch: 137, loss: 0.139901
global_step: 29462, epoch: 137, loss: 0.244606
global_step: 29463, epoch: 137, loss: 0.256628
global_step: 29464, epoch: 137, loss: 0.220738
global_step: 29465, epoch: 137, loss: 0.307940
global_step: 29466, epoch: 137, loss: 0.244155
global_step: 29467, epoch: 137, loss: 0.235842
global_step: 29468, epoch: 137, loss: 0.186511
global_step: 29469, epoch: 137, loss: 0.221014
global_step: 29470, epoch: 137, loss: 0.225294
global_step: 29471, epoch: 137, loss: 0.229201
global_step: 29472, epoch: 137, loss: 0.265612
global_step: 29473, epoch: 137, loss: 0.202235
global_step: 29474, epoch: 137, loss: 0.301223
global_step: 29475, epoch: 137, loss: 0.229955
global_step: 29476, epoch: 137, loss: 0.346095
global_step: 29477, epoch: 137, loss: 0.270613
global_step: 29478, epoch: 137, loss: 0.225088
global_step: 29479, epoch: 137, loss: 0.186054
global_step: 29480, epoch: 137, loss: 0.042603
epoch: 137
train	acc: 0.9684	macro: p 0.9731, r 0.9508, f1: 0.9614	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5311	macro: p 0.3862, r 0.3090, f1: 0.3142	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4877
test	acc: 0.5793	macro: p 0.3448, r 0.3104, f1: 0.3156	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5415
global_step: 29481, epoch: 138, loss: 0.220307
global_step: 29482, epoch: 138, loss: 0.188351
global_step: 29483, epoch: 138, loss: 0.202782
global_step: 29484, epoch: 138, loss: 0.312237
global_step: 29485, epoch: 138, loss: 0.175764
global_step: 29486, epoch: 138, loss: 0.259576
global_step: 29487, epoch: 138, loss: 0.237064
global_step: 29488, epoch: 138, loss: 0.191552
global_step: 29489, epoch: 138, loss: 0.265603
global_step: 29490, epoch: 138, loss: 0.224449
global_step: 29491, epoch: 138, loss: 0.279771
global_step: 29492, epoch: 138, loss: 0.203751
global_step: 29493, epoch: 138, loss: 0.194311
global_step: 29494, epoch: 138, loss: 0.206786
global_step: 29495, epoch: 138, loss: 0.213281
global_step: 29496, epoch: 138, loss: 0.206153
global_step: 29497, epoch: 138, loss: 0.268505
global_step: 29498, epoch: 138, loss: 0.213339
global_step: 29499, epoch: 138, loss: 0.263133
global_step: 29500, epoch: 138, loss: 0.203991
global_step: 29501, epoch: 138, loss: 0.238199
global_step: 29502, epoch: 138, loss: 0.241484
global_step: 29503, epoch: 138, loss: 0.255514
global_step: 29504, epoch: 138, loss: 0.221337
global_step: 29505, epoch: 138, loss: 0.241946
global_step: 29506, epoch: 138, loss: 0.237442
global_step: 29507, epoch: 138, loss: 0.249857
global_step: 29508, epoch: 138, loss: 0.218021
global_step: 29509, epoch: 138, loss: 0.261870
global_step: 29510, epoch: 138, loss: 0.241496
global_step: 29511, epoch: 138, loss: 0.191391
global_step: 29512, epoch: 138, loss: 0.314560
global_step: 29513, epoch: 138, loss: 0.229481
global_step: 29514, epoch: 138, loss: 0.185303
global_step: 29515, epoch: 138, loss: 0.239972
global_step: 29516, epoch: 138, loss: 0.209123
global_step: 29517, epoch: 138, loss: 0.227229
global_step: 29518, epoch: 138, loss: 0.204590
global_step: 29519, epoch: 138, loss: 0.264245
global_step: 29520, epoch: 138, loss: 0.063636
epoch: 138
train	acc: 0.9684	macro: p 0.9728, r 0.9527, f1: 0.9623	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5248	macro: p 0.3912, r 0.3117, f1: 0.3166	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4850
test	acc: 0.5782	macro: p 0.3620, r 0.3210, f1: 0.3256	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5447
global_step: 29521, epoch: 139, loss: 0.254787
global_step: 29522, epoch: 139, loss: 0.240034
global_step: 29523, epoch: 139, loss: 0.235527
global_step: 29524, epoch: 139, loss: 0.188307
global_step: 29525, epoch: 139, loss: 0.204793
global_step: 29526, epoch: 139, loss: 0.192589
global_step: 29527, epoch: 139, loss: 0.197779
global_step: 29528, epoch: 139, loss: 0.268696
global_step: 29529, epoch: 139, loss: 0.309888
global_step: 29530, epoch: 139, loss: 0.298713
global_step: 29531, epoch: 139, loss: 0.214458
global_step: 29532, epoch: 139, loss: 0.226358
global_step: 29533, epoch: 139, loss: 0.210313
global_step: 29534, epoch: 139, loss: 0.238496
global_step: 29535, epoch: 139, loss: 0.187598
global_step: 29536, epoch: 139, loss: 0.293010
global_step: 29537, epoch: 139, loss: 0.242169
global_step: 29538, epoch: 139, loss: 0.208496
global_step: 29539, epoch: 139, loss: 0.238435
global_step: 29540, epoch: 139, loss: 0.278322
global_step: 29541, epoch: 139, loss: 0.234542
global_step: 29542, epoch: 139, loss: 0.261284
global_step: 29543, epoch: 139, loss: 0.348626
global_step: 29544, epoch: 139, loss: 0.211424
global_step: 29545, epoch: 139, loss: 0.258455
global_step: 29546, epoch: 139, loss: 0.225966
global_step: 29547, epoch: 139, loss: 0.211556
global_step: 29548, epoch: 139, loss: 0.214964
global_step: 29549, epoch: 139, loss: 0.197496
global_step: 29550, epoch: 139, loss: 0.212150
global_step: 29551, epoch: 139, loss: 0.222450
global_step: 29552, epoch: 139, loss: 0.196092
global_step: 29553, epoch: 139, loss: 0.309076
global_step: 29554, epoch: 139, loss: 0.333526
global_step: 29555, epoch: 139, loss: 0.193446
global_step: 29556, epoch: 139, loss: 0.265773
global_step: 29557, epoch: 139, loss: 0.220506
global_step: 29558, epoch: 139, loss: 0.217712
global_step: 29559, epoch: 139, loss: 0.265885
global_step: 29560, epoch: 139, loss: 0.141898
epoch: 139
train	acc: 0.9687	macro: p 0.9745, r 0.9525, f1: 0.9631	micro: p 0.9687, r 0.9687, f1 0.9687	weighted_f1:0.9687
dev	acc: 0.5293	macro: p 0.3756, r 0.3063, f1: 0.3110	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4855
test	acc: 0.5785	macro: p 0.3603, r 0.3127, f1: 0.3201	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5411
global_step: 29561, epoch: 140, loss: 0.178116
global_step: 29562, epoch: 140, loss: 0.259549
global_step: 29563, epoch: 140, loss: 0.257548
global_step: 29564, epoch: 140, loss: 0.225561
global_step: 29565, epoch: 140, loss: 0.280427
global_step: 29566, epoch: 140, loss: 0.196783
global_step: 29567, epoch: 140, loss: 0.274718
global_step: 29568, epoch: 140, loss: 0.184963
global_step: 29569, epoch: 140, loss: 0.282432
global_step: 29570, epoch: 140, loss: 0.205769
global_step: 29571, epoch: 140, loss: 0.210610
global_step: 29572, epoch: 140, loss: 0.220100
global_step: 29573, epoch: 140, loss: 0.191206
global_step: 29574, epoch: 140, loss: 0.122929
global_step: 29575, epoch: 140, loss: 0.239260
global_step: 29576, epoch: 140, loss: 0.229119
global_step: 29577, epoch: 140, loss: 0.282977
global_step: 29578, epoch: 140, loss: 0.184691
global_step: 29579, epoch: 140, loss: 0.208960
global_step: 29580, epoch: 140, loss: 0.233291
global_step: 29581, epoch: 140, loss: 0.232058
global_step: 29582, epoch: 140, loss: 0.183838
global_step: 29583, epoch: 140, loss: 0.277772
global_step: 29584, epoch: 140, loss: 0.217397
global_step: 29585, epoch: 140, loss: 0.252159
global_step: 29586, epoch: 140, loss: 0.252455
global_step: 29587, epoch: 140, loss: 0.220789
global_step: 29588, epoch: 140, loss: 0.219961
global_step: 29589, epoch: 140, loss: 0.196913
global_step: 29590, epoch: 140, loss: 0.152921
global_step: 29591, epoch: 140, loss: 0.314278
global_step: 29592, epoch: 140, loss: 0.262757
global_step: 29593, epoch: 140, loss: 0.225179
global_step: 29594, epoch: 140, loss: 0.210367
global_step: 29595, epoch: 140, loss: 0.271713
global_step: 29596, epoch: 140, loss: 0.213129
global_step: 29597, epoch: 140, loss: 0.239363
global_step: 29598, epoch: 140, loss: 0.290333
global_step: 29599, epoch: 140, loss: 0.231049
global_step: 29600, epoch: 140, loss: 0.026685
epoch: 140
train	acc: 0.9686	macro: p 0.9734, r 0.9529, f1: 0.9627	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5203	macro: p 0.3830, r 0.3084, f1: 0.3143	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4840
test	acc: 0.5831	macro: p 0.3541, r 0.3168, f1: 0.3216	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5489
global_step: 29601, epoch: 141, loss: 0.214271
global_step: 29602, epoch: 141, loss: 0.214139
global_step: 29603, epoch: 141, loss: 0.180720
global_step: 29604, epoch: 141, loss: 0.188799
global_step: 29605, epoch: 141, loss: 0.202081
global_step: 29606, epoch: 141, loss: 0.272199
global_step: 29607, epoch: 141, loss: 0.217817
global_step: 29608, epoch: 141, loss: 0.177608
global_step: 29609, epoch: 141, loss: 0.186311
global_step: 29610, epoch: 141, loss: 0.244531
global_step: 29611, epoch: 141, loss: 0.218094
global_step: 29612, epoch: 141, loss: 0.215957
global_step: 29613, epoch: 141, loss: 0.275259
global_step: 29614, epoch: 141, loss: 0.215224
global_step: 29615, epoch: 141, loss: 0.253495
global_step: 29616, epoch: 141, loss: 0.190430
global_step: 29617, epoch: 141, loss: 0.256563
global_step: 29618, epoch: 141, loss: 0.168431
global_step: 29619, epoch: 141, loss: 0.212540
global_step: 29620, epoch: 141, loss: 0.257799
global_step: 29621, epoch: 141, loss: 0.214604
global_step: 29622, epoch: 141, loss: 0.259353
global_step: 29623, epoch: 141, loss: 0.221199
global_step: 29624, epoch: 141, loss: 0.181575
global_step: 29625, epoch: 141, loss: 0.208209
global_step: 29626, epoch: 141, loss: 0.212586
global_step: 29627, epoch: 141, loss: 0.231959
global_step: 29628, epoch: 141, loss: 0.264938
global_step: 29629, epoch: 141, loss: 0.252102
global_step: 29630, epoch: 141, loss: 0.243934
global_step: 29631, epoch: 141, loss: 0.228758
global_step: 29632, epoch: 141, loss: 0.217714
global_step: 29633, epoch: 141, loss: 0.190542
global_step: 29634, epoch: 141, loss: 0.291531
global_step: 29635, epoch: 141, loss: 0.311094
global_step: 29636, epoch: 141, loss: 0.298006
global_step: 29637, epoch: 141, loss: 0.241988
global_step: 29638, epoch: 141, loss: 0.246271
global_step: 29639, epoch: 141, loss: 0.225583
global_step: 29640, epoch: 141, loss: 0.115340
epoch: 141
train	acc: 0.9673	macro: p 0.9734, r 0.9504, f1: 0.9614	micro: p 0.9673, r 0.9673, f1 0.9673	weighted_f1:0.9673
dev	acc: 0.5212	macro: p 0.3765, r 0.2966, f1: 0.2947	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4709
test	acc: 0.5816	macro: p 0.3683, r 0.3090, f1: 0.3127	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5375
global_step: 29641, epoch: 142, loss: 0.236475
global_step: 29642, epoch: 142, loss: 0.223011
global_step: 29643, epoch: 142, loss: 0.185542
global_step: 29644, epoch: 142, loss: 0.269107
global_step: 29645, epoch: 142, loss: 0.188884
global_step: 29646, epoch: 142, loss: 0.255738
global_step: 29647, epoch: 142, loss: 0.258329
global_step: 29648, epoch: 142, loss: 0.121261
global_step: 29649, epoch: 142, loss: 0.257377
global_step: 29650, epoch: 142, loss: 0.245188
global_step: 29651, epoch: 142, loss: 0.226027
global_step: 29652, epoch: 142, loss: 0.246885
global_step: 29653, epoch: 142, loss: 0.258647
global_step: 29654, epoch: 142, loss: 0.277964
global_step: 29655, epoch: 142, loss: 0.181501
global_step: 29656, epoch: 142, loss: 0.180416
global_step: 29657, epoch: 142, loss: 0.171232
global_step: 29658, epoch: 142, loss: 0.270569
global_step: 29659, epoch: 142, loss: 0.174213
global_step: 29660, epoch: 142, loss: 0.227707
global_step: 29661, epoch: 142, loss: 0.246234
global_step: 29662, epoch: 142, loss: 0.202064
global_step: 29663, epoch: 142, loss: 0.277249
global_step: 29664, epoch: 142, loss: 0.275117
global_step: 29665, epoch: 142, loss: 0.265212
global_step: 29666, epoch: 142, loss: 0.223838
global_step: 29667, epoch: 142, loss: 0.254784
global_step: 29668, epoch: 142, loss: 0.174946
global_step: 29669, epoch: 142, loss: 0.241344
global_step: 29670, epoch: 142, loss: 0.233516
global_step: 29671, epoch: 142, loss: 0.257731
global_step: 29672, epoch: 142, loss: 0.253911
global_step: 29673, epoch: 142, loss: 0.233504
global_step: 29674, epoch: 142, loss: 0.216054
global_step: 29675, epoch: 142, loss: 0.311076
global_step: 29676, epoch: 142, loss: 0.226293
global_step: 29677, epoch: 142, loss: 0.207343
global_step: 29678, epoch: 142, loss: 0.245233
global_step: 29679, epoch: 142, loss: 0.196333
global_step: 29680, epoch: 142, loss: 0.290617
epoch: 142
train	acc: 0.9691	macro: p 0.9736, r 0.9552, f1: 0.9640	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5122	macro: p 0.3718, r 0.3032, f1: 0.3082	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4762
test	acc: 0.5782	macro: p 0.3686, r 0.3243, f1: 0.3326	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5475
global_step: 29681, epoch: 143, loss: 0.300224
global_step: 29682, epoch: 143, loss: 0.172498
global_step: 29683, epoch: 143, loss: 0.170275
global_step: 29684, epoch: 143, loss: 0.226451
global_step: 29685, epoch: 143, loss: 0.205061
global_step: 29686, epoch: 143, loss: 0.170088
global_step: 29687, epoch: 143, loss: 0.243529
global_step: 29688, epoch: 143, loss: 0.272437
global_step: 29689, epoch: 143, loss: 0.242447
global_step: 29690, epoch: 143, loss: 0.272471
global_step: 29691, epoch: 143, loss: 0.199187
global_step: 29692, epoch: 143, loss: 0.294590
global_step: 29693, epoch: 143, loss: 0.219951
global_step: 29694, epoch: 143, loss: 0.284507
global_step: 29695, epoch: 143, loss: 0.219564
global_step: 29696, epoch: 143, loss: 0.259438
global_step: 29697, epoch: 143, loss: 0.242849
global_step: 29698, epoch: 143, loss: 0.235666
global_step: 29699, epoch: 143, loss: 0.213549
global_step: 29700, epoch: 143, loss: 0.175544
global_step: 29701, epoch: 143, loss: 0.283714
global_step: 29702, epoch: 143, loss: 0.264280
global_step: 29703, epoch: 143, loss: 0.263916
global_step: 29704, epoch: 143, loss: 0.177116
global_step: 29705, epoch: 143, loss: 0.247521
global_step: 29706, epoch: 143, loss: 0.211623
global_step: 29707, epoch: 143, loss: 0.293796
global_step: 29708, epoch: 143, loss: 0.206672
global_step: 29709, epoch: 143, loss: 0.265154
global_step: 29710, epoch: 143, loss: 0.268200
global_step: 29711, epoch: 143, loss: 0.147929
global_step: 29712, epoch: 143, loss: 0.267797
global_step: 29713, epoch: 143, loss: 0.244585
global_step: 29714, epoch: 143, loss: 0.215282
global_step: 29715, epoch: 143, loss: 0.180581
global_step: 29716, epoch: 143, loss: 0.227510
global_step: 29717, epoch: 143, loss: 0.258954
global_step: 29718, epoch: 143, loss: 0.212357
global_step: 29719, epoch: 143, loss: 0.217402
global_step: 29720, epoch: 143, loss: 0.080858
epoch: 143
train	acc: 0.9690	macro: p 0.9741, r 0.9523, f1: 0.9627	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5212	macro: p 0.3747, r 0.2985, f1: 0.3004	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4762
test	acc: 0.5816	macro: p 0.3730, r 0.3170, f1: 0.3252	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5448
global_step: 29721, epoch: 144, loss: 0.233316
global_step: 29722, epoch: 144, loss: 0.216676
global_step: 29723, epoch: 144, loss: 0.222064
global_step: 29724, epoch: 144, loss: 0.205418
global_step: 29725, epoch: 144, loss: 0.272156
global_step: 29726, epoch: 144, loss: 0.234729
global_step: 29727, epoch: 144, loss: 0.190814
global_step: 29728, epoch: 144, loss: 0.207032
global_step: 29729, epoch: 144, loss: 0.158220
global_step: 29730, epoch: 144, loss: 0.236460
global_step: 29731, epoch: 144, loss: 0.271717
global_step: 29732, epoch: 144, loss: 0.237301
global_step: 29733, epoch: 144, loss: 0.141051
global_step: 29734, epoch: 144, loss: 0.263506
global_step: 29735, epoch: 144, loss: 0.182186
global_step: 29736, epoch: 144, loss: 0.194465
global_step: 29737, epoch: 144, loss: 0.212203
global_step: 29738, epoch: 144, loss: 0.272205
global_step: 29739, epoch: 144, loss: 0.305342
global_step: 29740, epoch: 144, loss: 0.184809
global_step: 29741, epoch: 144, loss: 0.260054
global_step: 29742, epoch: 144, loss: 0.327766
global_step: 29743, epoch: 144, loss: 0.258724
global_step: 29744, epoch: 144, loss: 0.262038
global_step: 29745, epoch: 144, loss: 0.182670
global_step: 29746, epoch: 144, loss: 0.164820
global_step: 29747, epoch: 144, loss: 0.239504
global_step: 29748, epoch: 144, loss: 0.190846
global_step: 29749, epoch: 144, loss: 0.207307
global_step: 29750, epoch: 144, loss: 0.223190
global_step: 29751, epoch: 144, loss: 0.192734
global_step: 29752, epoch: 144, loss: 0.234896
global_step: 29753, epoch: 144, loss: 0.216173
global_step: 29754, epoch: 144, loss: 0.249825
global_step: 29755, epoch: 144, loss: 0.210716
global_step: 29756, epoch: 144, loss: 0.281908
global_step: 29757, epoch: 144, loss: 0.195538
global_step: 29758, epoch: 144, loss: 0.238799
global_step: 29759, epoch: 144, loss: 0.264349
global_step: 29760, epoch: 144, loss: 0.070757
epoch: 144
train	acc: 0.9696	macro: p 0.9744, r 0.9569, f1: 0.9653	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5176	macro: p 0.3573, r 0.3020, f1: 0.3053	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4744
test	acc: 0.5713	macro: p 0.3744, r 0.3153, f1: 0.3244	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5354
global_step: 29761, epoch: 145, loss: 0.203796
global_step: 29762, epoch: 145, loss: 0.206653
global_step: 29763, epoch: 145, loss: 0.157867
global_step: 29764, epoch: 145, loss: 0.217160
global_step: 29765, epoch: 145, loss: 0.218963
global_step: 29766, epoch: 145, loss: 0.211606
global_step: 29767, epoch: 145, loss: 0.133750
global_step: 29768, epoch: 145, loss: 0.249489
global_step: 29769, epoch: 145, loss: 0.162183
global_step: 29770, epoch: 145, loss: 0.189273
global_step: 29771, epoch: 145, loss: 0.232216
global_step: 29772, epoch: 145, loss: 0.264381
global_step: 29773, epoch: 145, loss: 0.223135
global_step: 29774, epoch: 145, loss: 0.287292
global_step: 29775, epoch: 145, loss: 0.193712
global_step: 29776, epoch: 145, loss: 0.263060
global_step: 29777, epoch: 145, loss: 0.230917
global_step: 29778, epoch: 145, loss: 0.266047
global_step: 29779, epoch: 145, loss: 0.208265
global_step: 29780, epoch: 145, loss: 0.242478
global_step: 29781, epoch: 145, loss: 0.271055
global_step: 29782, epoch: 145, loss: 0.206225
global_step: 29783, epoch: 145, loss: 0.192301
global_step: 29784, epoch: 145, loss: 0.227644
global_step: 29785, epoch: 145, loss: 0.287258
global_step: 29786, epoch: 145, loss: 0.255442
global_step: 29787, epoch: 145, loss: 0.251459
global_step: 29788, epoch: 145, loss: 0.216992
global_step: 29789, epoch: 145, loss: 0.181449
global_step: 29790, epoch: 145, loss: 0.250957
global_step: 29791, epoch: 145, loss: 0.234451
global_step: 29792, epoch: 145, loss: 0.230997
global_step: 29793, epoch: 145, loss: 0.288351
global_step: 29794, epoch: 145, loss: 0.262671
global_step: 29795, epoch: 145, loss: 0.288377
global_step: 29796, epoch: 145, loss: 0.216912
global_step: 29797, epoch: 145, loss: 0.269050
global_step: 29798, epoch: 145, loss: 0.176155
global_step: 29799, epoch: 145, loss: 0.198271
global_step: 29800, epoch: 145, loss: 0.210022
epoch: 145
train	acc: 0.9706	macro: p 0.9748, r 0.9582, f1: 0.9662	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5149	macro: p 0.3440, r 0.2954, f1: 0.3004	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4728
test	acc: 0.5766	macro: p 0.3643, r 0.3120, f1: 0.3215	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5401
global_step: 29801, epoch: 146, loss: 0.181020
global_step: 29802, epoch: 146, loss: 0.211265
global_step: 29803, epoch: 146, loss: 0.217829
global_step: 29804, epoch: 146, loss: 0.227354
global_step: 29805, epoch: 146, loss: 0.229038
global_step: 29806, epoch: 146, loss: 0.180300
global_step: 29807, epoch: 146, loss: 0.237085
global_step: 29808, epoch: 146, loss: 0.228825
global_step: 29809, epoch: 146, loss: 0.241127
global_step: 29810, epoch: 146, loss: 0.186522
global_step: 29811, epoch: 146, loss: 0.229007
global_step: 29812, epoch: 146, loss: 0.238011
global_step: 29813, epoch: 146, loss: 0.216377
global_step: 29814, epoch: 146, loss: 0.220834
global_step: 29815, epoch: 146, loss: 0.163223
global_step: 29816, epoch: 146, loss: 0.275359
global_step: 29817, epoch: 146, loss: 0.186768
global_step: 29818, epoch: 146, loss: 0.277359
global_step: 29819, epoch: 146, loss: 0.237889
global_step: 29820, epoch: 146, loss: 0.310757
global_step: 29821, epoch: 146, loss: 0.207707
global_step: 29822, epoch: 146, loss: 0.226498
global_step: 29823, epoch: 146, loss: 0.255503
global_step: 29824, epoch: 146, loss: 0.237542
global_step: 29825, epoch: 146, loss: 0.232437
global_step: 29826, epoch: 146, loss: 0.210901
global_step: 29827, epoch: 146, loss: 0.236977
global_step: 29828, epoch: 146, loss: 0.204427
global_step: 29829, epoch: 146, loss: 0.195367
global_step: 29830, epoch: 146, loss: 0.295841
global_step: 29831, epoch: 146, loss: 0.192947
global_step: 29832, epoch: 146, loss: 0.205809
global_step: 29833, epoch: 146, loss: 0.200176
global_step: 29834, epoch: 146, loss: 0.254294
global_step: 29835, epoch: 146, loss: 0.164902
global_step: 29836, epoch: 146, loss: 0.212335
global_step: 29837, epoch: 146, loss: 0.257456
global_step: 29838, epoch: 146, loss: 0.238234
global_step: 29839, epoch: 146, loss: 0.206289
global_step: 29840, epoch: 146, loss: 0.164443
epoch: 146
train	acc: 0.9697	macro: p 0.9743, r 0.9561, f1: 0.9648	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5194	macro: p 0.3650, r 0.3027, f1: 0.3054	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4777
test	acc: 0.5716	macro: p 0.3583, r 0.3121, f1: 0.3199	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5369
global_step: 29841, epoch: 147, loss: 0.240223
global_step: 29842, epoch: 147, loss: 0.205720
global_step: 29843, epoch: 147, loss: 0.194410
global_step: 29844, epoch: 147, loss: 0.216751
global_step: 29845, epoch: 147, loss: 0.209483
global_step: 29846, epoch: 147, loss: 0.202925
global_step: 29847, epoch: 147, loss: 0.178405
global_step: 29848, epoch: 147, loss: 0.247476
global_step: 29849, epoch: 147, loss: 0.175490
global_step: 29850, epoch: 147, loss: 0.234302
global_step: 29851, epoch: 147, loss: 0.229775
global_step: 29852, epoch: 147, loss: 0.246984
global_step: 29853, epoch: 147, loss: 0.224952
global_step: 29854, epoch: 147, loss: 0.198968
global_step: 29855, epoch: 147, loss: 0.219872
global_step: 29856, epoch: 147, loss: 0.187447
global_step: 29857, epoch: 147, loss: 0.212428
global_step: 29858, epoch: 147, loss: 0.201912
global_step: 29859, epoch: 147, loss: 0.207008
global_step: 29860, epoch: 147, loss: 0.221181
global_step: 29861, epoch: 147, loss: 0.238670
global_step: 29862, epoch: 147, loss: 0.167463
global_step: 29863, epoch: 147, loss: 0.244985
global_step: 29864, epoch: 147, loss: 0.190045
global_step: 29865, epoch: 147, loss: 0.212819
global_step: 29866, epoch: 147, loss: 0.214351
global_step: 29867, epoch: 147, loss: 0.196435
global_step: 29868, epoch: 147, loss: 0.364097
global_step: 29869, epoch: 147, loss: 0.228568
global_step: 29870, epoch: 147, loss: 0.186012
global_step: 29871, epoch: 147, loss: 0.256595
global_step: 29872, epoch: 147, loss: 0.214024
global_step: 29873, epoch: 147, loss: 0.237323
global_step: 29874, epoch: 147, loss: 0.232721
global_step: 29875, epoch: 147, loss: 0.264720
global_step: 29876, epoch: 147, loss: 0.181566
global_step: 29877, epoch: 147, loss: 0.286136
global_step: 29878, epoch: 147, loss: 0.276760
global_step: 29879, epoch: 147, loss: 0.267291
global_step: 29880, epoch: 147, loss: 0.033689
epoch: 147
train	acc: 0.9698	macro: p 0.9739, r 0.9556, f1: 0.9644	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5275	macro: p 0.3828, r 0.3141, f1: 0.3202	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4889
test	acc: 0.5747	macro: p 0.3530, r 0.3145, f1: 0.3196	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5408
global_step: 29881, epoch: 148, loss: 0.170359
global_step: 29882, epoch: 148, loss: 0.242947
global_step: 29883, epoch: 148, loss: 0.202646
global_step: 29884, epoch: 148, loss: 0.230866
global_step: 29885, epoch: 148, loss: 0.238316
global_step: 29886, epoch: 148, loss: 0.179441
global_step: 29887, epoch: 148, loss: 0.207039
global_step: 29888, epoch: 148, loss: 0.186459
global_step: 29889, epoch: 148, loss: 0.279110
global_step: 29890, epoch: 148, loss: 0.186897
global_step: 29891, epoch: 148, loss: 0.281867
global_step: 29892, epoch: 148, loss: 0.200085
global_step: 29893, epoch: 148, loss: 0.241368
global_step: 29894, epoch: 148, loss: 0.237740
global_step: 29895, epoch: 148, loss: 0.205861
global_step: 29896, epoch: 148, loss: 0.166523
global_step: 29897, epoch: 148, loss: 0.297727
global_step: 29898, epoch: 148, loss: 0.217786
global_step: 29899, epoch: 148, loss: 0.205201
global_step: 29900, epoch: 148, loss: 0.192507
global_step: 29901, epoch: 148, loss: 0.214948
global_step: 29902, epoch: 148, loss: 0.191242
global_step: 29903, epoch: 148, loss: 0.216413
global_step: 29904, epoch: 148, loss: 0.166380
global_step: 29905, epoch: 148, loss: 0.237781
global_step: 29906, epoch: 148, loss: 0.165412
global_step: 29907, epoch: 148, loss: 0.198174
global_step: 29908, epoch: 148, loss: 0.263879
global_step: 29909, epoch: 148, loss: 0.236449
global_step: 29910, epoch: 148, loss: 0.201761
global_step: 29911, epoch: 148, loss: 0.179735
global_step: 29912, epoch: 148, loss: 0.204767
global_step: 29913, epoch: 148, loss: 0.174679
global_step: 29914, epoch: 148, loss: 0.172047
global_step: 29915, epoch: 148, loss: 0.235875
global_step: 29916, epoch: 148, loss: 0.207247
global_step: 29917, epoch: 148, loss: 0.226396
global_step: 29918, epoch: 148, loss: 0.273548
global_step: 29919, epoch: 148, loss: 0.239548
global_step: 29920, epoch: 148, loss: 0.021737
epoch: 148
train	acc: 0.9701	macro: p 0.9754, r 0.9568, f1: 0.9657	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5284	macro: p 0.3773, r 0.3066, f1: 0.3119	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4847
test	acc: 0.5747	macro: p 0.3486, r 0.3054, f1: 0.3106	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5354
global_step: 29921, epoch: 149, loss: 0.176402
global_step: 29922, epoch: 149, loss: 0.236629
global_step: 29923, epoch: 149, loss: 0.215178
global_step: 29924, epoch: 149, loss: 0.213344
global_step: 29925, epoch: 149, loss: 0.210442
global_step: 29926, epoch: 149, loss: 0.206236
global_step: 29927, epoch: 149, loss: 0.206888
global_step: 29928, epoch: 149, loss: 0.195998
global_step: 29929, epoch: 149, loss: 0.152840
global_step: 29930, epoch: 149, loss: 0.253654
global_step: 29931, epoch: 149, loss: 0.179480
global_step: 29932, epoch: 149, loss: 0.176132
global_step: 29933, epoch: 149, loss: 0.230207
global_step: 29934, epoch: 149, loss: 0.193188
global_step: 29935, epoch: 149, loss: 0.213398
global_step: 29936, epoch: 149, loss: 0.223339
global_step: 29937, epoch: 149, loss: 0.212141
global_step: 29938, epoch: 149, loss: 0.172414
global_step: 29939, epoch: 149, loss: 0.184926
global_step: 29940, epoch: 149, loss: 0.248544
global_step: 29941, epoch: 149, loss: 0.200856
global_step: 29942, epoch: 149, loss: 0.241776
global_step: 29943, epoch: 149, loss: 0.297931
global_step: 29944, epoch: 149, loss: 0.195422
global_step: 29945, epoch: 149, loss: 0.225630
global_step: 29946, epoch: 149, loss: 0.290313
global_step: 29947, epoch: 149, loss: 0.210344
global_step: 29948, epoch: 149, loss: 0.237488
global_step: 29949, epoch: 149, loss: 0.198029
global_step: 29950, epoch: 149, loss: 0.291711
global_step: 29951, epoch: 149, loss: 0.210621
global_step: 29952, epoch: 149, loss: 0.201969
global_step: 29953, epoch: 149, loss: 0.189034
global_step: 29954, epoch: 149, loss: 0.169369
global_step: 29955, epoch: 149, loss: 0.271162
global_step: 29956, epoch: 149, loss: 0.280213
global_step: 29957, epoch: 149, loss: 0.269376
global_step: 29958, epoch: 149, loss: 0.206177
global_step: 29959, epoch: 149, loss: 0.183552
global_step: 29960, epoch: 149, loss: 0.139827
epoch: 149
train	acc: 0.9687	macro: p 0.9733, r 0.9524, f1: 0.9624	micro: p 0.9687, r 0.9687, f1 0.9687	weighted_f1:0.9687
dev	acc: 0.5338	macro: p 0.3734, r 0.3041, f1: 0.3072	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4867
test	acc: 0.5831	macro: p 0.3510, r 0.3089, f1: 0.3120	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5420
global_step: 29961, epoch: 150, loss: 0.252344
global_step: 29962, epoch: 150, loss: 0.223042
global_step: 29963, epoch: 150, loss: 0.178250
global_step: 29964, epoch: 150, loss: 0.270781
global_step: 29965, epoch: 150, loss: 0.185189
global_step: 29966, epoch: 150, loss: 0.173475
global_step: 29967, epoch: 150, loss: 0.195120
global_step: 29968, epoch: 150, loss: 0.168802
global_step: 29969, epoch: 150, loss: 0.249718
global_step: 29970, epoch: 150, loss: 0.221552
global_step: 29971, epoch: 150, loss: 0.210643
global_step: 29972, epoch: 150, loss: 0.211555
global_step: 29973, epoch: 150, loss: 0.212597
global_step: 29974, epoch: 150, loss: 0.119538
global_step: 29975, epoch: 150, loss: 0.200383
global_step: 29976, epoch: 150, loss: 0.275959
global_step: 29977, epoch: 150, loss: 0.219566
global_step: 29978, epoch: 150, loss: 0.223913
global_step: 29979, epoch: 150, loss: 0.246614
global_step: 29980, epoch: 150, loss: 0.206508
global_step: 29981, epoch: 150, loss: 0.256248
global_step: 29982, epoch: 150, loss: 0.205391
global_step: 29983, epoch: 150, loss: 0.197247
global_step: 29984, epoch: 150, loss: 0.178558
global_step: 29985, epoch: 150, loss: 0.234707
global_step: 29986, epoch: 150, loss: 0.251546
global_step: 29987, epoch: 150, loss: 0.231788
global_step: 29988, epoch: 150, loss: 0.198055
global_step: 29989, epoch: 150, loss: 0.230262
global_step: 29990, epoch: 150, loss: 0.253027
global_step: 29991, epoch: 150, loss: 0.182868
global_step: 29992, epoch: 150, loss: 0.222939
global_step: 29993, epoch: 150, loss: 0.210622
global_step: 29994, epoch: 150, loss: 0.271849
global_step: 29995, epoch: 150, loss: 0.214366
global_step: 29996, epoch: 150, loss: 0.238818
global_step: 29997, epoch: 150, loss: 0.229466
global_step: 29998, epoch: 150, loss: 0.176379
global_step: 29999, epoch: 150, loss: 0.239362
global_step: 30000, epoch: 150, loss: 0.040055
epoch: 150
train	acc: 0.9706	macro: p 0.9754, r 0.9581, f1: 0.9664	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5185	macro: p 0.3701, r 0.3082, f1: 0.3130	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4815
test	acc: 0.5743	macro: p 0.3617, r 0.3197, f1: 0.3253	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5424
global_step: 30001, epoch: 151, loss: 0.231634
global_step: 30002, epoch: 151, loss: 0.210577
global_step: 30003, epoch: 151, loss: 0.211213
global_step: 30004, epoch: 151, loss: 0.237206
global_step: 30005, epoch: 151, loss: 0.161219
global_step: 30006, epoch: 151, loss: 0.284573
global_step: 30007, epoch: 151, loss: 0.257684
global_step: 30008, epoch: 151, loss: 0.250075
global_step: 30009, epoch: 151, loss: 0.158040
global_step: 30010, epoch: 151, loss: 0.144256
global_step: 30011, epoch: 151, loss: 0.229671
global_step: 30012, epoch: 151, loss: 0.288845
global_step: 30013, epoch: 151, loss: 0.188337
global_step: 30014, epoch: 151, loss: 0.172889
global_step: 30015, epoch: 151, loss: 0.178378
global_step: 30016, epoch: 151, loss: 0.185427
global_step: 30017, epoch: 151, loss: 0.269307
global_step: 30018, epoch: 151, loss: 0.202664
global_step: 30019, epoch: 151, loss: 0.204158
global_step: 30020, epoch: 151, loss: 0.187946
global_step: 30021, epoch: 151, loss: 0.213906
global_step: 30022, epoch: 151, loss: 0.237977
global_step: 30023, epoch: 151, loss: 0.244459
global_step: 30024, epoch: 151, loss: 0.281233
global_step: 30025, epoch: 151, loss: 0.235594
global_step: 30026, epoch: 151, loss: 0.184448
global_step: 30027, epoch: 151, loss: 0.220756
global_step: 30028, epoch: 151, loss: 0.236776
global_step: 30029, epoch: 151, loss: 0.170048
global_step: 30030, epoch: 151, loss: 0.245257
global_step: 30031, epoch: 151, loss: 0.159011
global_step: 30032, epoch: 151, loss: 0.249473
global_step: 30033, epoch: 151, loss: 0.207090
global_step: 30034, epoch: 151, loss: 0.205592
global_step: 30035, epoch: 151, loss: 0.251700
global_step: 30036, epoch: 151, loss: 0.271309
global_step: 30037, epoch: 151, loss: 0.194433
global_step: 30038, epoch: 151, loss: 0.271152
global_step: 30039, epoch: 151, loss: 0.233727
global_step: 30040, epoch: 151, loss: 0.103299
epoch: 151
train	acc: 0.9692	macro: p 0.9746, r 0.9557, f1: 0.9647	micro: p 0.9692, r 0.9692, f1 0.9692	weighted_f1:0.9692
dev	acc: 0.5212	macro: p 0.3740, r 0.3026, f1: 0.3040	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4781
test	acc: 0.5774	macro: p 0.3702, r 0.3157, f1: 0.3213	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5410
global_step: 30041, epoch: 152, loss: 0.203228
global_step: 30042, epoch: 152, loss: 0.214467
global_step: 30043, epoch: 152, loss: 0.177395
global_step: 30044, epoch: 152, loss: 0.204253
global_step: 30045, epoch: 152, loss: 0.270173
global_step: 30046, epoch: 152, loss: 0.198156
global_step: 30047, epoch: 152, loss: 0.135546
global_step: 30048, epoch: 152, loss: 0.213432
global_step: 30049, epoch: 152, loss: 0.257977
global_step: 30050, epoch: 152, loss: 0.239459
global_step: 30051, epoch: 152, loss: 0.245401
global_step: 30052, epoch: 152, loss: 0.259597
global_step: 30053, epoch: 152, loss: 0.179297
global_step: 30054, epoch: 152, loss: 0.266047
global_step: 30055, epoch: 152, loss: 0.195165
global_step: 30056, epoch: 152, loss: 0.219818
global_step: 30057, epoch: 152, loss: 0.192230
global_step: 30058, epoch: 152, loss: 0.182500
global_step: 30059, epoch: 152, loss: 0.267097
global_step: 30060, epoch: 152, loss: 0.165320
global_step: 30061, epoch: 152, loss: 0.185958
global_step: 30062, epoch: 152, loss: 0.181929
global_step: 30063, epoch: 152, loss: 0.136249
global_step: 30064, epoch: 152, loss: 0.192438
global_step: 30065, epoch: 152, loss: 0.228150
global_step: 30066, epoch: 152, loss: 0.180636
global_step: 30067, epoch: 152, loss: 0.236871
global_step: 30068, epoch: 152, loss: 0.227625
global_step: 30069, epoch: 152, loss: 0.273173
global_step: 30070, epoch: 152, loss: 0.287374
global_step: 30071, epoch: 152, loss: 0.209456
global_step: 30072, epoch: 152, loss: 0.221571
global_step: 30073, epoch: 152, loss: 0.224067
global_step: 30074, epoch: 152, loss: 0.209694
global_step: 30075, epoch: 152, loss: 0.151076
global_step: 30076, epoch: 152, loss: 0.152651
global_step: 30077, epoch: 152, loss: 0.246465
global_step: 30078, epoch: 152, loss: 0.246267
global_step: 30079, epoch: 152, loss: 0.166746
global_step: 30080, epoch: 152, loss: 0.141147
epoch: 152
train	acc: 0.9698	macro: p 0.9750, r 0.9556, f1: 0.9649	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5104	macro: p 0.3551, r 0.2975, f1: 0.2983	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4689
test	acc: 0.5713	macro: p 0.3505, r 0.3100, f1: 0.3137	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5355
global_step: 30081, epoch: 153, loss: 0.187330
global_step: 30082, epoch: 153, loss: 0.195778
global_step: 30083, epoch: 153, loss: 0.159140
global_step: 30084, epoch: 153, loss: 0.236651
global_step: 30085, epoch: 153, loss: 0.154450
global_step: 30086, epoch: 153, loss: 0.216657
global_step: 30087, epoch: 153, loss: 0.201185
global_step: 30088, epoch: 153, loss: 0.227094
global_step: 30089, epoch: 153, loss: 0.216946
global_step: 30090, epoch: 153, loss: 0.144495
global_step: 30091, epoch: 153, loss: 0.276342
global_step: 30092, epoch: 153, loss: 0.260911
global_step: 30093, epoch: 153, loss: 0.178570
global_step: 30094, epoch: 153, loss: 0.155174
global_step: 30095, epoch: 153, loss: 0.233784
global_step: 30096, epoch: 153, loss: 0.275910
global_step: 30097, epoch: 153, loss: 0.149740
global_step: 30098, epoch: 153, loss: 0.218029
global_step: 30099, epoch: 153, loss: 0.308339
global_step: 30100, epoch: 153, loss: 0.208267
global_step: 30101, epoch: 153, loss: 0.160423
global_step: 30102, epoch: 153, loss: 0.182365
global_step: 30103, epoch: 153, loss: 0.198745
global_step: 30104, epoch: 153, loss: 0.195911
global_step: 30105, epoch: 153, loss: 0.215798
global_step: 30106, epoch: 153, loss: 0.228731
global_step: 30107, epoch: 153, loss: 0.217360
global_step: 30108, epoch: 153, loss: 0.183753
global_step: 30109, epoch: 153, loss: 0.250276
global_step: 30110, epoch: 153, loss: 0.274720
global_step: 30111, epoch: 153, loss: 0.218284
global_step: 30112, epoch: 153, loss: 0.232612
global_step: 30113, epoch: 153, loss: 0.133794
global_step: 30114, epoch: 153, loss: 0.174110
global_step: 30115, epoch: 153, loss: 0.200817
global_step: 30116, epoch: 153, loss: 0.230466
global_step: 30117, epoch: 153, loss: 0.174663
global_step: 30118, epoch: 153, loss: 0.228505
global_step: 30119, epoch: 153, loss: 0.226506
global_step: 30120, epoch: 153, loss: 0.100356
epoch: 153
train	acc: 0.9697	macro: p 0.9752, r 0.9548, f1: 0.9646	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5266	macro: p 0.3619, r 0.2996, f1: 0.3033	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4813
test	acc: 0.5785	macro: p 0.3739, r 0.3121, f1: 0.3227	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5397
global_step: 30121, epoch: 154, loss: 0.195825
global_step: 30122, epoch: 154, loss: 0.199078
global_step: 30123, epoch: 154, loss: 0.212589
global_step: 30124, epoch: 154, loss: 0.177357
global_step: 30125, epoch: 154, loss: 0.233444
global_step: 30126, epoch: 154, loss: 0.202058
global_step: 30127, epoch: 154, loss: 0.152075
global_step: 30128, epoch: 154, loss: 0.155303
global_step: 30129, epoch: 154, loss: 0.169373
global_step: 30130, epoch: 154, loss: 0.209548
global_step: 30131, epoch: 154, loss: 0.229159
global_step: 30132, epoch: 154, loss: 0.226535
global_step: 30133, epoch: 154, loss: 0.265404
global_step: 30134, epoch: 154, loss: 0.236012
global_step: 30135, epoch: 154, loss: 0.204957
global_step: 30136, epoch: 154, loss: 0.225608
global_step: 30137, epoch: 154, loss: 0.217926
global_step: 30138, epoch: 154, loss: 0.274930
global_step: 30139, epoch: 154, loss: 0.178580
global_step: 30140, epoch: 154, loss: 0.257718
global_step: 30141, epoch: 154, loss: 0.262493
global_step: 30142, epoch: 154, loss: 0.240506
global_step: 30143, epoch: 154, loss: 0.188537
global_step: 30144, epoch: 154, loss: 0.305620
global_step: 30145, epoch: 154, loss: 0.279259
global_step: 30146, epoch: 154, loss: 0.203602
global_step: 30147, epoch: 154, loss: 0.221238
global_step: 30148, epoch: 154, loss: 0.202237
global_step: 30149, epoch: 154, loss: 0.139618
global_step: 30150, epoch: 154, loss: 0.258504
global_step: 30151, epoch: 154, loss: 0.197409
global_step: 30152, epoch: 154, loss: 0.213135
global_step: 30153, epoch: 154, loss: 0.204377
global_step: 30154, epoch: 154, loss: 0.223291
global_step: 30155, epoch: 154, loss: 0.238300
global_step: 30156, epoch: 154, loss: 0.187605
global_step: 30157, epoch: 154, loss: 0.323533
global_step: 30158, epoch: 154, loss: 0.199485
global_step: 30159, epoch: 154, loss: 0.192256
global_step: 30160, epoch: 154, loss: 0.117983
epoch: 154
train	acc: 0.9698	macro: p 0.9753, r 0.9553, f1: 0.9649	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5185	macro: p 0.3422, r 0.2978, f1: 0.2972	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4747
test	acc: 0.5743	macro: p 0.3588, r 0.3130, f1: 0.3179	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5373
global_step: 30161, epoch: 155, loss: 0.195272
global_step: 30162, epoch: 155, loss: 0.242801
global_step: 30163, epoch: 155, loss: 0.186980
global_step: 30164, epoch: 155, loss: 0.170643
global_step: 30165, epoch: 155, loss: 0.216647
global_step: 30166, epoch: 155, loss: 0.195508
global_step: 30167, epoch: 155, loss: 0.136089
global_step: 30168, epoch: 155, loss: 0.221571
global_step: 30169, epoch: 155, loss: 0.177868
global_step: 30170, epoch: 155, loss: 0.205014
global_step: 30171, epoch: 155, loss: 0.267407
global_step: 30172, epoch: 155, loss: 0.227875
global_step: 30173, epoch: 155, loss: 0.181042
global_step: 30174, epoch: 155, loss: 0.231291
global_step: 30175, epoch: 155, loss: 0.171250
global_step: 30176, epoch: 155, loss: 0.210019
global_step: 30177, epoch: 155, loss: 0.188911
global_step: 30178, epoch: 155, loss: 0.249885
global_step: 30179, epoch: 155, loss: 0.206997
global_step: 30180, epoch: 155, loss: 0.248439
global_step: 30181, epoch: 155, loss: 0.230801
global_step: 30182, epoch: 155, loss: 0.281260
global_step: 30183, epoch: 155, loss: 0.211698
global_step: 30184, epoch: 155, loss: 0.208670
global_step: 30185, epoch: 155, loss: 0.242780
global_step: 30186, epoch: 155, loss: 0.161318
global_step: 30187, epoch: 155, loss: 0.184825
global_step: 30188, epoch: 155, loss: 0.163307
global_step: 30189, epoch: 155, loss: 0.207306
global_step: 30190, epoch: 155, loss: 0.248391
global_step: 30191, epoch: 155, loss: 0.202120
global_step: 30192, epoch: 155, loss: 0.191531
global_step: 30193, epoch: 155, loss: 0.204149
global_step: 30194, epoch: 155, loss: 0.239032
global_step: 30195, epoch: 155, loss: 0.219828
global_step: 30196, epoch: 155, loss: 0.188901
global_step: 30197, epoch: 155, loss: 0.222000
global_step: 30198, epoch: 155, loss: 0.185088
global_step: 30199, epoch: 155, loss: 0.209708
global_step: 30200, epoch: 155, loss: 0.170275
epoch: 155
train	acc: 0.9701	macro: p 0.9751, r 0.9564, f1: 0.9654	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5257	macro: p 0.3582, r 0.2996, f1: 0.3023	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4798
test	acc: 0.5743	macro: p 0.3490, r 0.3046, f1: 0.3084	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5332
global_step: 30201, epoch: 156, loss: 0.143393
global_step: 30202, epoch: 156, loss: 0.234639
global_step: 30203, epoch: 156, loss: 0.237485
global_step: 30204, epoch: 156, loss: 0.204693
global_step: 30205, epoch: 156, loss: 0.266031
global_step: 30206, epoch: 156, loss: 0.292100
global_step: 30207, epoch: 156, loss: 0.196213
global_step: 30208, epoch: 156, loss: 0.179093
global_step: 30209, epoch: 156, loss: 0.193424
global_step: 30210, epoch: 156, loss: 0.251154
global_step: 30211, epoch: 156, loss: 0.156904
global_step: 30212, epoch: 156, loss: 0.186454
global_step: 30213, epoch: 156, loss: 0.218209
global_step: 30214, epoch: 156, loss: 0.220620
global_step: 30215, epoch: 156, loss: 0.204853
global_step: 30216, epoch: 156, loss: 0.197373
global_step: 30217, epoch: 156, loss: 0.178690
global_step: 30218, epoch: 156, loss: 0.155886
global_step: 30219, epoch: 156, loss: 0.301183
global_step: 30220, epoch: 156, loss: 0.228491
global_step: 30221, epoch: 156, loss: 0.233488
global_step: 30222, epoch: 156, loss: 0.249186
global_step: 30223, epoch: 156, loss: 0.264759
global_step: 30224, epoch: 156, loss: 0.182232
global_step: 30225, epoch: 156, loss: 0.165410
global_step: 30226, epoch: 156, loss: 0.159353
global_step: 30227, epoch: 156, loss: 0.211840
global_step: 30228, epoch: 156, loss: 0.226825
global_step: 30229, epoch: 156, loss: 0.255195
global_step: 30230, epoch: 156, loss: 0.222797
global_step: 30231, epoch: 156, loss: 0.229920
global_step: 30232, epoch: 156, loss: 0.231788
global_step: 30233, epoch: 156, loss: 0.180003
global_step: 30234, epoch: 156, loss: 0.243035
global_step: 30235, epoch: 156, loss: 0.220340
global_step: 30236, epoch: 156, loss: 0.233465
global_step: 30237, epoch: 156, loss: 0.231021
global_step: 30238, epoch: 156, loss: 0.227453
global_step: 30239, epoch: 156, loss: 0.178534
global_step: 30240, epoch: 156, loss: 0.094504
epoch: 156
train	acc: 0.9700	macro: p 0.9754, r 0.9568, f1: 0.9658	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5338	macro: p 0.3740, r 0.3067, f1: 0.3110	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4886
test	acc: 0.5782	macro: p 0.3458, r 0.3038, f1: 0.3070	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5354
global_step: 30241, epoch: 157, loss: 0.228690
global_step: 30242, epoch: 157, loss: 0.243348
global_step: 30243, epoch: 157, loss: 0.287693
global_step: 30244, epoch: 157, loss: 0.249231
global_step: 30245, epoch: 157, loss: 0.215960
global_step: 30246, epoch: 157, loss: 0.203104
global_step: 30247, epoch: 157, loss: 0.225650
global_step: 30248, epoch: 157, loss: 0.168691
global_step: 30249, epoch: 157, loss: 0.231558
global_step: 30250, epoch: 157, loss: 0.191578
global_step: 30251, epoch: 157, loss: 0.180507
global_step: 30252, epoch: 157, loss: 0.153130
global_step: 30253, epoch: 157, loss: 0.262030
global_step: 30254, epoch: 157, loss: 0.297272
global_step: 30255, epoch: 157, loss: 0.175711
global_step: 30256, epoch: 157, loss: 0.161112
global_step: 30257, epoch: 157, loss: 0.194159
global_step: 30258, epoch: 157, loss: 0.157940
global_step: 30259, epoch: 157, loss: 0.175056
global_step: 30260, epoch: 157, loss: 0.225745
global_step: 30261, epoch: 157, loss: 0.183512
global_step: 30262, epoch: 157, loss: 0.162042
global_step: 30263, epoch: 157, loss: 0.203514
global_step: 30264, epoch: 157, loss: 0.225737
global_step: 30265, epoch: 157, loss: 0.240309
global_step: 30266, epoch: 157, loss: 0.222054
global_step: 30267, epoch: 157, loss: 0.222238
global_step: 30268, epoch: 157, loss: 0.177317
global_step: 30269, epoch: 157, loss: 0.181919
global_step: 30270, epoch: 157, loss: 0.224107
global_step: 30271, epoch: 157, loss: 0.213608
global_step: 30272, epoch: 157, loss: 0.229779
global_step: 30273, epoch: 157, loss: 0.197281
global_step: 30274, epoch: 157, loss: 0.318541
global_step: 30275, epoch: 157, loss: 0.180352
global_step: 30276, epoch: 157, loss: 0.254196
global_step: 30277, epoch: 157, loss: 0.209961
global_step: 30278, epoch: 157, loss: 0.196877
global_step: 30279, epoch: 157, loss: 0.264594
global_step: 30280, epoch: 157, loss: 0.001381
epoch: 157
train	acc: 0.9703	macro: p 0.9741, r 0.9585, f1: 0.9661	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5203	macro: p 0.3520, r 0.3015, f1: 0.3043	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4794
test	acc: 0.5728	macro: p 0.3594, r 0.3095, f1: 0.3151	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5371
global_step: 30281, epoch: 158, loss: 0.186779
global_step: 30282, epoch: 158, loss: 0.204935
global_step: 30283, epoch: 158, loss: 0.174610
global_step: 30284, epoch: 158, loss: 0.190311
global_step: 30285, epoch: 158, loss: 0.272957
global_step: 30286, epoch: 158, loss: 0.230473
global_step: 30287, epoch: 158, loss: 0.166740
global_step: 30288, epoch: 158, loss: 0.217392
global_step: 30289, epoch: 158, loss: 0.229196
global_step: 30290, epoch: 158, loss: 0.183925
global_step: 30291, epoch: 158, loss: 0.162327
global_step: 30292, epoch: 158, loss: 0.169013
global_step: 30293, epoch: 158, loss: 0.321043
global_step: 30294, epoch: 158, loss: 0.196667
global_step: 30295, epoch: 158, loss: 0.198226
global_step: 30296, epoch: 158, loss: 0.196647
global_step: 30297, epoch: 158, loss: 0.185869
global_step: 30298, epoch: 158, loss: 0.206295
global_step: 30299, epoch: 158, loss: 0.260167
global_step: 30300, epoch: 158, loss: 0.290047
global_step: 30301, epoch: 158, loss: 0.242308
global_step: 30302, epoch: 158, loss: 0.197431
global_step: 30303, epoch: 158, loss: 0.208590
global_step: 30304, epoch: 158, loss: 0.221273
global_step: 30305, epoch: 158, loss: 0.202025
global_step: 30306, epoch: 158, loss: 0.219183
global_step: 30307, epoch: 158, loss: 0.244471
global_step: 30308, epoch: 158, loss: 0.189940
global_step: 30309, epoch: 158, loss: 0.246283
global_step: 30310, epoch: 158, loss: 0.290674
global_step: 30311, epoch: 158, loss: 0.256444
global_step: 30312, epoch: 158, loss: 0.185312
global_step: 30313, epoch: 158, loss: 0.195309
global_step: 30314, epoch: 158, loss: 0.257301
global_step: 30315, epoch: 158, loss: 0.174019
global_step: 30316, epoch: 158, loss: 0.202250
global_step: 30317, epoch: 158, loss: 0.232317
global_step: 30318, epoch: 158, loss: 0.230287
global_step: 30319, epoch: 158, loss: 0.155388
global_step: 30320, epoch: 158, loss: 0.002350
epoch: 158
train	acc: 0.9703	macro: p 0.9750, r 0.9574, f1: 0.9659	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5167	macro: p 0.3507, r 0.2985, f1: 0.3016	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4768
test	acc: 0.5755	macro: p 0.3631, r 0.3189, f1: 0.3276	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5431
global_step: 30321, epoch: 159, loss: 0.160320
global_step: 30322, epoch: 159, loss: 0.195861
global_step: 30323, epoch: 159, loss: 0.196697
global_step: 30324, epoch: 159, loss: 0.206143
global_step: 30325, epoch: 159, loss: 0.191650
global_step: 30326, epoch: 159, loss: 0.195659
global_step: 30327, epoch: 159, loss: 0.212477
global_step: 30328, epoch: 159, loss: 0.221014
global_step: 30329, epoch: 159, loss: 0.159570
global_step: 30330, epoch: 159, loss: 0.152435
global_step: 30331, epoch: 159, loss: 0.216131
global_step: 30332, epoch: 159, loss: 0.159424
global_step: 30333, epoch: 159, loss: 0.121190
global_step: 30334, epoch: 159, loss: 0.185949
global_step: 30335, epoch: 159, loss: 0.183447
global_step: 30336, epoch: 159, loss: 0.171707
global_step: 30337, epoch: 159, loss: 0.274693
global_step: 30338, epoch: 159, loss: 0.153054
global_step: 30339, epoch: 159, loss: 0.176927
global_step: 30340, epoch: 159, loss: 0.233851
global_step: 30341, epoch: 159, loss: 0.228265
global_step: 30342, epoch: 159, loss: 0.229932
global_step: 30343, epoch: 159, loss: 0.253151
global_step: 30344, epoch: 159, loss: 0.223244
global_step: 30345, epoch: 159, loss: 0.265118
global_step: 30346, epoch: 159, loss: 0.189719
global_step: 30347, epoch: 159, loss: 0.222393
global_step: 30348, epoch: 159, loss: 0.228957
global_step: 30349, epoch: 159, loss: 0.154761
global_step: 30350, epoch: 159, loss: 0.222523
global_step: 30351, epoch: 159, loss: 0.209827
global_step: 30352, epoch: 159, loss: 0.189221
global_step: 30353, epoch: 159, loss: 0.192295
global_step: 30354, epoch: 159, loss: 0.192487
global_step: 30355, epoch: 159, loss: 0.222188
global_step: 30356, epoch: 159, loss: 0.183666
global_step: 30357, epoch: 159, loss: 0.171028
global_step: 30358, epoch: 159, loss: 0.216220
global_step: 30359, epoch: 159, loss: 0.194275
global_step: 30360, epoch: 159, loss: 0.004577
epoch: 159
train	acc: 0.9703	macro: p 0.9757, r 0.9564, f1: 0.9656	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5266	macro: p 0.3852, r 0.3014, f1: 0.3033	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4804
test	acc: 0.5743	macro: p 0.3456, r 0.3063, f1: 0.3102	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5346
global_step: 30361, epoch: 160, loss: 0.189280
global_step: 30362, epoch: 160, loss: 0.179287
global_step: 30363, epoch: 160, loss: 0.143438
global_step: 30364, epoch: 160, loss: 0.171896
global_step: 30365, epoch: 160, loss: 0.169708
global_step: 30366, epoch: 160, loss: 0.180721
global_step: 30367, epoch: 160, loss: 0.209552
global_step: 30368, epoch: 160, loss: 0.240802
global_step: 30369, epoch: 160, loss: 0.226551
global_step: 30370, epoch: 160, loss: 0.175565
global_step: 30371, epoch: 160, loss: 0.214034
global_step: 30372, epoch: 160, loss: 0.180217
global_step: 30373, epoch: 160, loss: 0.238898
global_step: 30374, epoch: 160, loss: 0.151196
global_step: 30375, epoch: 160, loss: 0.189592
global_step: 30376, epoch: 160, loss: 0.189496
global_step: 30377, epoch: 160, loss: 0.183462
global_step: 30378, epoch: 160, loss: 0.216593
global_step: 30379, epoch: 160, loss: 0.151060
global_step: 30380, epoch: 160, loss: 0.199959
global_step: 30381, epoch: 160, loss: 0.185607
global_step: 30382, epoch: 160, loss: 0.173801
global_step: 30383, epoch: 160, loss: 0.202289
global_step: 30384, epoch: 160, loss: 0.185814
global_step: 30385, epoch: 160, loss: 0.206020
global_step: 30386, epoch: 160, loss: 0.219442
global_step: 30387, epoch: 160, loss: 0.207654
global_step: 30388, epoch: 160, loss: 0.147647
global_step: 30389, epoch: 160, loss: 0.198502
global_step: 30390, epoch: 160, loss: 0.232360
global_step: 30391, epoch: 160, loss: 0.325579
global_step: 30392, epoch: 160, loss: 0.168399
global_step: 30393, epoch: 160, loss: 0.212199
global_step: 30394, epoch: 160, loss: 0.262993
global_step: 30395, epoch: 160, loss: 0.169054
global_step: 30396, epoch: 160, loss: 0.234819
global_step: 30397, epoch: 160, loss: 0.280534
global_step: 30398, epoch: 160, loss: 0.200415
global_step: 30399, epoch: 160, loss: 0.221650
global_step: 30400, epoch: 160, loss: 0.148776
epoch: 160
train	acc: 0.9704	macro: p 0.9750, r 0.9572, f1: 0.9657	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5212	macro: p 0.3607, r 0.3052, f1: 0.3058	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4804
test	acc: 0.5644	macro: p 0.3276, r 0.3003, f1: 0.3013	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5275
global_step: 30401, epoch: 161, loss: 0.175189
global_step: 30402, epoch: 161, loss: 0.219057
global_step: 30403, epoch: 161, loss: 0.201773
global_step: 30404, epoch: 161, loss: 0.227498
global_step: 30405, epoch: 161, loss: 0.183982
global_step: 30406, epoch: 161, loss: 0.160199
global_step: 30407, epoch: 161, loss: 0.191751
global_step: 30408, epoch: 161, loss: 0.247823
global_step: 30409, epoch: 161, loss: 0.248443
global_step: 30410, epoch: 161, loss: 0.212346
global_step: 30411, epoch: 161, loss: 0.301296
global_step: 30412, epoch: 161, loss: 0.263358
global_step: 30413, epoch: 161, loss: 0.152932
global_step: 30414, epoch: 161, loss: 0.235572
global_step: 30415, epoch: 161, loss: 0.226156
global_step: 30416, epoch: 161, loss: 0.146315
global_step: 30417, epoch: 161, loss: 0.118190
global_step: 30418, epoch: 161, loss: 0.230470
global_step: 30419, epoch: 161, loss: 0.273951
global_step: 30420, epoch: 161, loss: 0.189943
global_step: 30421, epoch: 161, loss: 0.211177
global_step: 30422, epoch: 161, loss: 0.204295
global_step: 30423, epoch: 161, loss: 0.250314
global_step: 30424, epoch: 161, loss: 0.214778
global_step: 30425, epoch: 161, loss: 0.212221
global_step: 30426, epoch: 161, loss: 0.156250
global_step: 30427, epoch: 161, loss: 0.177847
global_step: 30428, epoch: 161, loss: 0.153491
global_step: 30429, epoch: 161, loss: 0.232250
global_step: 30430, epoch: 161, loss: 0.194282
global_step: 30431, epoch: 161, loss: 0.202273
global_step: 30432, epoch: 161, loss: 0.163446
global_step: 30433, epoch: 161, loss: 0.231499
global_step: 30434, epoch: 161, loss: 0.275556
global_step: 30435, epoch: 161, loss: 0.160216
global_step: 30436, epoch: 161, loss: 0.203707
global_step: 30437, epoch: 161, loss: 0.190623
global_step: 30438, epoch: 161, loss: 0.162904
global_step: 30439, epoch: 161, loss: 0.178413
global_step: 30440, epoch: 161, loss: 0.552929
epoch: 161
train	acc: 0.9712	macro: p 0.9758, r 0.9584, f1: 0.9667	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5203	macro: p 0.3551, r 0.3033, f1: 0.3074	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4825
test	acc: 0.5770	macro: p 0.3486, r 0.3137, f1: 0.3188	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5437
global_step: 30441, epoch: 162, loss: 0.233621
global_step: 30442, epoch: 162, loss: 0.175282
global_step: 30443, epoch: 162, loss: 0.215855
global_step: 30444, epoch: 162, loss: 0.174801
global_step: 30445, epoch: 162, loss: 0.178716
global_step: 30446, epoch: 162, loss: 0.176805
global_step: 30447, epoch: 162, loss: 0.216329
global_step: 30448, epoch: 162, loss: 0.208955
global_step: 30449, epoch: 162, loss: 0.217510
global_step: 30450, epoch: 162, loss: 0.221411
global_step: 30451, epoch: 162, loss: 0.130833
global_step: 30452, epoch: 162, loss: 0.217221
global_step: 30453, epoch: 162, loss: 0.218554
global_step: 30454, epoch: 162, loss: 0.211757
global_step: 30455, epoch: 162, loss: 0.180276
global_step: 30456, epoch: 162, loss: 0.236085
global_step: 30457, epoch: 162, loss: 0.146299
global_step: 30458, epoch: 162, loss: 0.231708
global_step: 30459, epoch: 162, loss: 0.279195
global_step: 30460, epoch: 162, loss: 0.226566
global_step: 30461, epoch: 162, loss: 0.185597
global_step: 30462, epoch: 162, loss: 0.150663
global_step: 30463, epoch: 162, loss: 0.185879
global_step: 30464, epoch: 162, loss: 0.196410
global_step: 30465, epoch: 162, loss: 0.197455
global_step: 30466, epoch: 162, loss: 0.192786
global_step: 30467, epoch: 162, loss: 0.197110
global_step: 30468, epoch: 162, loss: 0.264280
global_step: 30469, epoch: 162, loss: 0.184203
global_step: 30470, epoch: 162, loss: 0.218387
global_step: 30471, epoch: 162, loss: 0.241040
global_step: 30472, epoch: 162, loss: 0.168267
global_step: 30473, epoch: 162, loss: 0.213494
global_step: 30474, epoch: 162, loss: 0.253277
global_step: 30475, epoch: 162, loss: 0.254998
global_step: 30476, epoch: 162, loss: 0.210021
global_step: 30477, epoch: 162, loss: 0.175798
global_step: 30478, epoch: 162, loss: 0.334660
global_step: 30479, epoch: 162, loss: 0.224341
global_step: 30480, epoch: 162, loss: 0.066016
epoch: 162
train	acc: 0.9703	macro: p 0.9756, r 0.9587, f1: 0.9669	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5284	macro: p 0.3646, r 0.3005, f1: 0.3042	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4815
test	acc: 0.5801	macro: p 0.3692, r 0.3091, f1: 0.3188	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5389
global_step: 30481, epoch: 163, loss: 0.201417
global_step: 30482, epoch: 163, loss: 0.164899
global_step: 30483, epoch: 163, loss: 0.240643
global_step: 30484, epoch: 163, loss: 0.231309
global_step: 30485, epoch: 163, loss: 0.177722
global_step: 30486, epoch: 163, loss: 0.185456
global_step: 30487, epoch: 163, loss: 0.208958
global_step: 30488, epoch: 163, loss: 0.245839
global_step: 30489, epoch: 163, loss: 0.199846
global_step: 30490, epoch: 163, loss: 0.190272
global_step: 30491, epoch: 163, loss: 0.175087
global_step: 30492, epoch: 163, loss: 0.192538
global_step: 30493, epoch: 163, loss: 0.188868
global_step: 30494, epoch: 163, loss: 0.177579
global_step: 30495, epoch: 163, loss: 0.200237
global_step: 30496, epoch: 163, loss: 0.154401
global_step: 30497, epoch: 163, loss: 0.168146
global_step: 30498, epoch: 163, loss: 0.189752
global_step: 30499, epoch: 163, loss: 0.210335
global_step: 30500, epoch: 163, loss: 0.168835
global_step: 30501, epoch: 163, loss: 0.206041
global_step: 30502, epoch: 163, loss: 0.194133
global_step: 30503, epoch: 163, loss: 0.278671
global_step: 30504, epoch: 163, loss: 0.173299
global_step: 30505, epoch: 163, loss: 0.178229
global_step: 30506, epoch: 163, loss: 0.202930
global_step: 30507, epoch: 163, loss: 0.194439
global_step: 30508, epoch: 163, loss: 0.164036
global_step: 30509, epoch: 163, loss: 0.183058
global_step: 30510, epoch: 163, loss: 0.266163
global_step: 30511, epoch: 163, loss: 0.224471
global_step: 30512, epoch: 163, loss: 0.198473
global_step: 30513, epoch: 163, loss: 0.199897
global_step: 30514, epoch: 163, loss: 0.266856
global_step: 30515, epoch: 163, loss: 0.226260
global_step: 30516, epoch: 163, loss: 0.209806
global_step: 30517, epoch: 163, loss: 0.209524
global_step: 30518, epoch: 163, loss: 0.224018
global_step: 30519, epoch: 163, loss: 0.198171
global_step: 30520, epoch: 163, loss: 0.230703
epoch: 163
train	acc: 0.9709	macro: p 0.9756, r 0.9586, f1: 0.9668	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5239	macro: p 0.3545, r 0.3008, f1: 0.3032	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4810
test	acc: 0.5755	macro: p 0.3584, r 0.3099, f1: 0.3168	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5381
global_step: 30521, epoch: 164, loss: 0.238049
global_step: 30522, epoch: 164, loss: 0.242025
global_step: 30523, epoch: 164, loss: 0.162052
global_step: 30524, epoch: 164, loss: 0.182561
global_step: 30525, epoch: 164, loss: 0.237903
global_step: 30526, epoch: 164, loss: 0.200280
global_step: 30527, epoch: 164, loss: 0.259661
global_step: 30528, epoch: 164, loss: 0.211118
global_step: 30529, epoch: 164, loss: 0.171033
global_step: 30530, epoch: 164, loss: 0.147093
global_step: 30531, epoch: 164, loss: 0.189986
global_step: 30532, epoch: 164, loss: 0.204227
global_step: 30533, epoch: 164, loss: 0.208746
global_step: 30534, epoch: 164, loss: 0.138442
global_step: 30535, epoch: 164, loss: 0.231171
global_step: 30536, epoch: 164, loss: 0.258347
global_step: 30537, epoch: 164, loss: 0.216453
global_step: 30538, epoch: 164, loss: 0.197154
global_step: 30539, epoch: 164, loss: 0.274236
global_step: 30540, epoch: 164, loss: 0.237198
global_step: 30541, epoch: 164, loss: 0.234735
global_step: 30542, epoch: 164, loss: 0.140081
global_step: 30543, epoch: 164, loss: 0.241597
global_step: 30544, epoch: 164, loss: 0.231344
global_step: 30545, epoch: 164, loss: 0.259487
global_step: 30546, epoch: 164, loss: 0.212458
global_step: 30547, epoch: 164, loss: 0.256934
global_step: 30548, epoch: 164, loss: 0.091693
global_step: 30549, epoch: 164, loss: 0.201158
global_step: 30550, epoch: 164, loss: 0.182004
global_step: 30551, epoch: 164, loss: 0.161357
global_step: 30552, epoch: 164, loss: 0.227245
global_step: 30553, epoch: 164, loss: 0.193797
global_step: 30554, epoch: 164, loss: 0.209354
global_step: 30555, epoch: 164, loss: 0.151931
global_step: 30556, epoch: 164, loss: 0.219614
global_step: 30557, epoch: 164, loss: 0.184229
global_step: 30558, epoch: 164, loss: 0.208599
global_step: 30559, epoch: 164, loss: 0.254641
global_step: 30560, epoch: 164, loss: 0.199725
epoch: 164
train	acc: 0.9709	macro: p 0.9753, r 0.9594, f1: 0.9671	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5230	macro: p 0.3559, r 0.3065, f1: 0.3060	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4825
test	acc: 0.5670	macro: p 0.3532, r 0.3119, f1: 0.3154	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5336
global_step: 30561, epoch: 165, loss: 0.218383
global_step: 30562, epoch: 165, loss: 0.205517
global_step: 30563, epoch: 165, loss: 0.178927
global_step: 30564, epoch: 165, loss: 0.198467
global_step: 30565, epoch: 165, loss: 0.217435
global_step: 30566, epoch: 165, loss: 0.146660
global_step: 30567, epoch: 165, loss: 0.184459
global_step: 30568, epoch: 165, loss: 0.213788
global_step: 30569, epoch: 165, loss: 0.201905
global_step: 30570, epoch: 165, loss: 0.209592
global_step: 30571, epoch: 165, loss: 0.219195
global_step: 30572, epoch: 165, loss: 0.221134
global_step: 30573, epoch: 165, loss: 0.163547
global_step: 30574, epoch: 165, loss: 0.189828
global_step: 30575, epoch: 165, loss: 0.157011
global_step: 30576, epoch: 165, loss: 0.211029
global_step: 30577, epoch: 165, loss: 0.274828
global_step: 30578, epoch: 165, loss: 0.185435
global_step: 30579, epoch: 165, loss: 0.232423
global_step: 30580, epoch: 165, loss: 0.262527
global_step: 30581, epoch: 165, loss: 0.218516
global_step: 30582, epoch: 165, loss: 0.262260
global_step: 30583, epoch: 165, loss: 0.134114
global_step: 30584, epoch: 165, loss: 0.176746
global_step: 30585, epoch: 165, loss: 0.193400
global_step: 30586, epoch: 165, loss: 0.161138
global_step: 30587, epoch: 165, loss: 0.183887
global_step: 30588, epoch: 165, loss: 0.199838
global_step: 30589, epoch: 165, loss: 0.236360
global_step: 30590, epoch: 165, loss: 0.199567
global_step: 30591, epoch: 165, loss: 0.234784
global_step: 30592, epoch: 165, loss: 0.228097
global_step: 30593, epoch: 165, loss: 0.182513
global_step: 30594, epoch: 165, loss: 0.211435
global_step: 30595, epoch: 165, loss: 0.159229
global_step: 30596, epoch: 165, loss: 0.209464
global_step: 30597, epoch: 165, loss: 0.202837
global_step: 30598, epoch: 165, loss: 0.183413
global_step: 30599, epoch: 165, loss: 0.182454
global_step: 30600, epoch: 165, loss: 0.519703
epoch: 165
train	acc: 0.9709	macro: p 0.9757, r 0.9596, f1: 0.9674	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5221	macro: p 0.3450, r 0.2954, f1: 0.2990	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4776
test	acc: 0.5828	macro: p 0.3876, r 0.3158, f1: 0.3275	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5437
global_step: 30601, epoch: 166, loss: 0.280151
global_step: 30602, epoch: 166, loss: 0.225741
global_step: 30603, epoch: 166, loss: 0.209992
global_step: 30604, epoch: 166, loss: 0.173823
global_step: 30605, epoch: 166, loss: 0.152754
global_step: 30606, epoch: 166, loss: 0.160339
global_step: 30607, epoch: 166, loss: 0.235825
global_step: 30608, epoch: 166, loss: 0.264615
global_step: 30609, epoch: 166, loss: 0.222915
global_step: 30610, epoch: 166, loss: 0.233935
global_step: 30611, epoch: 166, loss: 0.214161
global_step: 30612, epoch: 166, loss: 0.212014
global_step: 30613, epoch: 166, loss: 0.195322
global_step: 30614, epoch: 166, loss: 0.213210
global_step: 30615, epoch: 166, loss: 0.175289
global_step: 30616, epoch: 166, loss: 0.247977
global_step: 30617, epoch: 166, loss: 0.227300
global_step: 30618, epoch: 166, loss: 0.181466
global_step: 30619, epoch: 166, loss: 0.169959
global_step: 30620, epoch: 166, loss: 0.210504
global_step: 30621, epoch: 166, loss: 0.228910
global_step: 30622, epoch: 166, loss: 0.175636
global_step: 30623, epoch: 166, loss: 0.216138
global_step: 30624, epoch: 166, loss: 0.226223
global_step: 30625, epoch: 166, loss: 0.181280
global_step: 30626, epoch: 166, loss: 0.257494
global_step: 30627, epoch: 166, loss: 0.213598
global_step: 30628, epoch: 166, loss: 0.222034
global_step: 30629, epoch: 166, loss: 0.212468
global_step: 30630, epoch: 166, loss: 0.188735
global_step: 30631, epoch: 166, loss: 0.167793
global_step: 30632, epoch: 166, loss: 0.196670
global_step: 30633, epoch: 166, loss: 0.171849
global_step: 30634, epoch: 166, loss: 0.238954
global_step: 30635, epoch: 166, loss: 0.239600
global_step: 30636, epoch: 166, loss: 0.181707
global_step: 30637, epoch: 166, loss: 0.216933
global_step: 30638, epoch: 166, loss: 0.139179
global_step: 30639, epoch: 166, loss: 0.204615
global_step: 30640, epoch: 166, loss: 0.005020
epoch: 166
train	acc: 0.9717	macro: p 0.9763, r 0.9608, f1: 0.9682	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5167	macro: p 0.3510, r 0.2995, f1: 0.3004	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4756
test	acc: 0.5755	macro: p 0.3681, r 0.3174, f1: 0.3252	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5405
global_step: 30641, epoch: 167, loss: 0.182848
global_step: 30642, epoch: 167, loss: 0.257073
global_step: 30643, epoch: 167, loss: 0.199579
global_step: 30644, epoch: 167, loss: 0.244685
global_step: 30645, epoch: 167, loss: 0.207719
global_step: 30646, epoch: 167, loss: 0.191996
global_step: 30647, epoch: 167, loss: 0.153677
global_step: 30648, epoch: 167, loss: 0.168862
global_step: 30649, epoch: 167, loss: 0.260475
global_step: 30650, epoch: 167, loss: 0.166189
global_step: 30651, epoch: 167, loss: 0.199068
global_step: 30652, epoch: 167, loss: 0.216223
global_step: 30653, epoch: 167, loss: 0.235923
global_step: 30654, epoch: 167, loss: 0.184453
global_step: 30655, epoch: 167, loss: 0.177355
global_step: 30656, epoch: 167, loss: 0.188664
global_step: 30657, epoch: 167, loss: 0.200883
global_step: 30658, epoch: 167, loss: 0.239799
global_step: 30659, epoch: 167, loss: 0.175810
global_step: 30660, epoch: 167, loss: 0.150914
global_step: 30661, epoch: 167, loss: 0.191743
global_step: 30662, epoch: 167, loss: 0.148976
global_step: 30663, epoch: 167, loss: 0.206410
global_step: 30664, epoch: 167, loss: 0.182602
global_step: 30665, epoch: 167, loss: 0.147470
global_step: 30666, epoch: 167, loss: 0.155237
global_step: 30667, epoch: 167, loss: 0.219595
global_step: 30668, epoch: 167, loss: 0.211107
global_step: 30669, epoch: 167, loss: 0.201684
global_step: 30670, epoch: 167, loss: 0.175028
global_step: 30671, epoch: 167, loss: 0.181893
global_step: 30672, epoch: 167, loss: 0.200424
global_step: 30673, epoch: 167, loss: 0.233248
global_step: 30674, epoch: 167, loss: 0.229844
global_step: 30675, epoch: 167, loss: 0.178126
global_step: 30676, epoch: 167, loss: 0.185004
global_step: 30677, epoch: 167, loss: 0.174022
global_step: 30678, epoch: 167, loss: 0.241711
global_step: 30679, epoch: 167, loss: 0.177479
global_step: 30680, epoch: 167, loss: 0.002585
epoch: 167
train	acc: 0.9718	macro: p 0.9768, r 0.9594, f1: 0.9678	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5230	macro: p 0.3546, r 0.2998, f1: 0.3023	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4805
test	acc: 0.5828	macro: p 0.3586, r 0.3130, f1: 0.3180	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5436
global_step: 30681, epoch: 168, loss: 0.218267
global_step: 30682, epoch: 168, loss: 0.199447
global_step: 30683, epoch: 168, loss: 0.206011
global_step: 30684, epoch: 168, loss: 0.240780
global_step: 30685, epoch: 168, loss: 0.237668
global_step: 30686, epoch: 168, loss: 0.202887
global_step: 30687, epoch: 168, loss: 0.218417
global_step: 30688, epoch: 168, loss: 0.130655
global_step: 30689, epoch: 168, loss: 0.185752
global_step: 30690, epoch: 168, loss: 0.193172
global_step: 30691, epoch: 168, loss: 0.176549
global_step: 30692, epoch: 168, loss: 0.139296
global_step: 30693, epoch: 168, loss: 0.251625
global_step: 30694, epoch: 168, loss: 0.226737
global_step: 30695, epoch: 168, loss: 0.185822
global_step: 30696, epoch: 168, loss: 0.252674
global_step: 30697, epoch: 168, loss: 0.156807
global_step: 30698, epoch: 168, loss: 0.235834
global_step: 30699, epoch: 168, loss: 0.301440
global_step: 30700, epoch: 168, loss: 0.160803
global_step: 30701, epoch: 168, loss: 0.219317
global_step: 30702, epoch: 168, loss: 0.130714
global_step: 30703, epoch: 168, loss: 0.136677
global_step: 30704, epoch: 168, loss: 0.181557
global_step: 30705, epoch: 168, loss: 0.187891
global_step: 30706, epoch: 168, loss: 0.215888
global_step: 30707, epoch: 168, loss: 0.219628
global_step: 30708, epoch: 168, loss: 0.182478
global_step: 30709, epoch: 168, loss: 0.189508
global_step: 30710, epoch: 168, loss: 0.188535
global_step: 30711, epoch: 168, loss: 0.195434
global_step: 30712, epoch: 168, loss: 0.186285
global_step: 30713, epoch: 168, loss: 0.239290
global_step: 30714, epoch: 168, loss: 0.258125
global_step: 30715, epoch: 168, loss: 0.153435
global_step: 30716, epoch: 168, loss: 0.263644
global_step: 30717, epoch: 168, loss: 0.190182
global_step: 30718, epoch: 168, loss: 0.208704
global_step: 30719, epoch: 168, loss: 0.207516
global_step: 30720, epoch: 168, loss: 0.017533
epoch: 168
train	acc: 0.9714	macro: p 0.9751, r 0.9590, f1: 0.9668	micro: p 0.9714, r 0.9714, f1 0.9714	weighted_f1:0.9714
dev	acc: 0.5149	macro: p 0.3483, r 0.2991, f1: 0.3006	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4754
test	acc: 0.5782	macro: p 0.3547, r 0.3161, f1: 0.3208	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5427
global_step: 30721, epoch: 169, loss: 0.176506
global_step: 30722, epoch: 169, loss: 0.179578
global_step: 30723, epoch: 169, loss: 0.138387
global_step: 30724, epoch: 169, loss: 0.169986
global_step: 30725, epoch: 169, loss: 0.211040
global_step: 30726, epoch: 169, loss: 0.206508
global_step: 30727, epoch: 169, loss: 0.174122
global_step: 30728, epoch: 169, loss: 0.115682
global_step: 30729, epoch: 169, loss: 0.184108
global_step: 30730, epoch: 169, loss: 0.164278
global_step: 30731, epoch: 169, loss: 0.203085
global_step: 30732, epoch: 169, loss: 0.234736
global_step: 30733, epoch: 169, loss: 0.190108
global_step: 30734, epoch: 169, loss: 0.153682
global_step: 30735, epoch: 169, loss: 0.169867
global_step: 30736, epoch: 169, loss: 0.229051
global_step: 30737, epoch: 169, loss: 0.267923
global_step: 30738, epoch: 169, loss: 0.186225
global_step: 30739, epoch: 169, loss: 0.164264
global_step: 30740, epoch: 169, loss: 0.223098
global_step: 30741, epoch: 169, loss: 0.179737
global_step: 30742, epoch: 169, loss: 0.196242
global_step: 30743, epoch: 169, loss: 0.222504
global_step: 30744, epoch: 169, loss: 0.212168
global_step: 30745, epoch: 169, loss: 0.257818
global_step: 30746, epoch: 169, loss: 0.263645
global_step: 30747, epoch: 169, loss: 0.202573
global_step: 30748, epoch: 169, loss: 0.220013
global_step: 30749, epoch: 169, loss: 0.200257
global_step: 30750, epoch: 169, loss: 0.236711
global_step: 30751, epoch: 169, loss: 0.234935
global_step: 30752, epoch: 169, loss: 0.161680
global_step: 30753, epoch: 169, loss: 0.199695
global_step: 30754, epoch: 169, loss: 0.232708
global_step: 30755, epoch: 169, loss: 0.190351
global_step: 30756, epoch: 169, loss: 0.283469
global_step: 30757, epoch: 169, loss: 0.224134
global_step: 30758, epoch: 169, loss: 0.335051
global_step: 30759, epoch: 169, loss: 0.186438
global_step: 30760, epoch: 169, loss: 0.424250
epoch: 169
train	acc: 0.9719	macro: p 0.9752, r 0.9613, f1: 0.9681	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5221	macro: p 0.3567, r 0.3040, f1: 0.3076	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4831
test	acc: 0.5751	macro: p 0.3527, r 0.3151, f1: 0.3208	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5423
global_step: 30761, epoch: 170, loss: 0.200415
global_step: 30762, epoch: 170, loss: 0.161551
global_step: 30763, epoch: 170, loss: 0.181083
global_step: 30764, epoch: 170, loss: 0.163014
global_step: 30765, epoch: 170, loss: 0.231993
global_step: 30766, epoch: 170, loss: 0.235082
global_step: 30767, epoch: 170, loss: 0.210131
global_step: 30768, epoch: 170, loss: 0.181594
global_step: 30769, epoch: 170, loss: 0.176280
global_step: 30770, epoch: 170, loss: 0.212724
global_step: 30771, epoch: 170, loss: 0.192921
global_step: 30772, epoch: 170, loss: 0.170829
global_step: 30773, epoch: 170, loss: 0.179605
global_step: 30774, epoch: 170, loss: 0.172982
global_step: 30775, epoch: 170, loss: 0.181102
global_step: 30776, epoch: 170, loss: 0.137920
global_step: 30777, epoch: 170, loss: 0.184736
global_step: 30778, epoch: 170, loss: 0.206488
global_step: 30779, epoch: 170, loss: 0.167539
global_step: 30780, epoch: 170, loss: 0.144342
global_step: 30781, epoch: 170, loss: 0.205819
global_step: 30782, epoch: 170, loss: 0.169686
global_step: 30783, epoch: 170, loss: 0.235649
global_step: 30784, epoch: 170, loss: 0.220064
global_step: 30785, epoch: 170, loss: 0.141902
global_step: 30786, epoch: 170, loss: 0.132400
global_step: 30787, epoch: 170, loss: 0.178721
global_step: 30788, epoch: 170, loss: 0.190918
global_step: 30789, epoch: 170, loss: 0.183151
global_step: 30790, epoch: 170, loss: 0.172964
global_step: 30791, epoch: 170, loss: 0.175587
global_step: 30792, epoch: 170, loss: 0.231147
global_step: 30793, epoch: 170, loss: 0.283451
global_step: 30794, epoch: 170, loss: 0.207372
global_step: 30795, epoch: 170, loss: 0.239974
global_step: 30796, epoch: 170, loss: 0.151067
global_step: 30797, epoch: 170, loss: 0.310003
global_step: 30798, epoch: 170, loss: 0.207835
global_step: 30799, epoch: 170, loss: 0.166877
global_step: 30800, epoch: 170, loss: 0.624687
epoch: 170
train	acc: 0.9700	macro: p 0.9770, r 0.9574, f1: 0.9669	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9699
dev	acc: 0.5167	macro: p 0.3513, r 0.2903, f1: 0.2934	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4690
test	acc: 0.5724	macro: p 0.3578, r 0.3056, f1: 0.3154	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5333
global_step: 30801, epoch: 171, loss: 0.210879
global_step: 30802, epoch: 171, loss: 0.167831
global_step: 30803, epoch: 171, loss: 0.148811
global_step: 30804, epoch: 171, loss: 0.175864
global_step: 30805, epoch: 171, loss: 0.181043
global_step: 30806, epoch: 171, loss: 0.208986
global_step: 30807, epoch: 171, loss: 0.127830
global_step: 30808, epoch: 171, loss: 0.186209
global_step: 30809, epoch: 171, loss: 0.183589
global_step: 30810, epoch: 171, loss: 0.185965
global_step: 30811, epoch: 171, loss: 0.186439
global_step: 30812, epoch: 171, loss: 0.201323
global_step: 30813, epoch: 171, loss: 0.154530
global_step: 30814, epoch: 171, loss: 0.241340
global_step: 30815, epoch: 171, loss: 0.129816
global_step: 30816, epoch: 171, loss: 0.185145
global_step: 30817, epoch: 171, loss: 0.150344
global_step: 30818, epoch: 171, loss: 0.172274
global_step: 30819, epoch: 171, loss: 0.199832
global_step: 30820, epoch: 171, loss: 0.287179
global_step: 30821, epoch: 171, loss: 0.219641
global_step: 30822, epoch: 171, loss: 0.223133
global_step: 30823, epoch: 171, loss: 0.171049
global_step: 30824, epoch: 171, loss: 0.184054
global_step: 30825, epoch: 171, loss: 0.205234
global_step: 30826, epoch: 171, loss: 0.147504
global_step: 30827, epoch: 171, loss: 0.216931
global_step: 30828, epoch: 171, loss: 0.190042
global_step: 30829, epoch: 171, loss: 0.149411
global_step: 30830, epoch: 171, loss: 0.245664
global_step: 30831, epoch: 171, loss: 0.200864
global_step: 30832, epoch: 171, loss: 0.229992
global_step: 30833, epoch: 171, loss: 0.235498
global_step: 30834, epoch: 171, loss: 0.169524
global_step: 30835, epoch: 171, loss: 0.260016
global_step: 30836, epoch: 171, loss: 0.144299
global_step: 30837, epoch: 171, loss: 0.278984
global_step: 30838, epoch: 171, loss: 0.218442
global_step: 30839, epoch: 171, loss: 0.155421
global_step: 30840, epoch: 171, loss: 0.243289
epoch: 171
train	acc: 0.9711	macro: p 0.9753, r 0.9599, f1: 0.9673	micro: p 0.9711, r 0.9711, f1 0.9711	weighted_f1:0.9711
dev	acc: 0.5149	macro: p 0.3826, r 0.3130, f1: 0.3180	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4796
test	acc: 0.5716	macro: p 0.3448, r 0.3153, f1: 0.3179	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5406
global_step: 30841, epoch: 172, loss: 0.168474
global_step: 30842, epoch: 172, loss: 0.288363
global_step: 30843, epoch: 172, loss: 0.226408
global_step: 30844, epoch: 172, loss: 0.134567
global_step: 30845, epoch: 172, loss: 0.194158
global_step: 30846, epoch: 172, loss: 0.145220
global_step: 30847, epoch: 172, loss: 0.134160
global_step: 30848, epoch: 172, loss: 0.255414
global_step: 30849, epoch: 172, loss: 0.202515
global_step: 30850, epoch: 172, loss: 0.196177
global_step: 30851, epoch: 172, loss: 0.199807
global_step: 30852, epoch: 172, loss: 0.177812
global_step: 30853, epoch: 172, loss: 0.110108
global_step: 30854, epoch: 172, loss: 0.186224
global_step: 30855, epoch: 172, loss: 0.172973
global_step: 30856, epoch: 172, loss: 0.238339
global_step: 30857, epoch: 172, loss: 0.214054
global_step: 30858, epoch: 172, loss: 0.186010
global_step: 30859, epoch: 172, loss: 0.221387
global_step: 30860, epoch: 172, loss: 0.280166
global_step: 30861, epoch: 172, loss: 0.250745
global_step: 30862, epoch: 172, loss: 0.231636
global_step: 30863, epoch: 172, loss: 0.195757
global_step: 30864, epoch: 172, loss: 0.175889
global_step: 30865, epoch: 172, loss: 0.199378
global_step: 30866, epoch: 172, loss: 0.262791
global_step: 30867, epoch: 172, loss: 0.187582
global_step: 30868, epoch: 172, loss: 0.220802
global_step: 30869, epoch: 172, loss: 0.230436
global_step: 30870, epoch: 172, loss: 0.207293
global_step: 30871, epoch: 172, loss: 0.189872
global_step: 30872, epoch: 172, loss: 0.216855
global_step: 30873, epoch: 172, loss: 0.143156
global_step: 30874, epoch: 172, loss: 0.203189
global_step: 30875, epoch: 172, loss: 0.307111
global_step: 30876, epoch: 172, loss: 0.135199
global_step: 30877, epoch: 172, loss: 0.251089
global_step: 30878, epoch: 172, loss: 0.196473
global_step: 30879, epoch: 172, loss: 0.175772
global_step: 30880, epoch: 172, loss: 0.089459
epoch: 172
train	acc: 0.9718	macro: p 0.9746, r 0.9614, f1: 0.9678	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5203	macro: p 0.3641, r 0.3024, f1: 0.3041	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4803
test	acc: 0.5678	macro: p 0.3556, r 0.3126, f1: 0.3181	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5355
global_step: 30881, epoch: 173, loss: 0.162305
global_step: 30882, epoch: 173, loss: 0.175864
global_step: 30883, epoch: 173, loss: 0.186023
global_step: 30884, epoch: 173, loss: 0.165639
global_step: 30885, epoch: 173, loss: 0.207926
global_step: 30886, epoch: 173, loss: 0.211016
global_step: 30887, epoch: 173, loss: 0.163121
global_step: 30888, epoch: 173, loss: 0.219676
global_step: 30889, epoch: 173, loss: 0.232719
global_step: 30890, epoch: 173, loss: 0.196455
global_step: 30891, epoch: 173, loss: 0.183243
global_step: 30892, epoch: 173, loss: 0.214073
global_step: 30893, epoch: 173, loss: 0.169565
global_step: 30894, epoch: 173, loss: 0.142883
global_step: 30895, epoch: 173, loss: 0.254175
global_step: 30896, epoch: 173, loss: 0.160660
global_step: 30897, epoch: 173, loss: 0.206591
global_step: 30898, epoch: 173, loss: 0.209839
global_step: 30899, epoch: 173, loss: 0.170217
global_step: 30900, epoch: 173, loss: 0.325703
global_step: 30901, epoch: 173, loss: 0.185676
global_step: 30902, epoch: 173, loss: 0.157983
global_step: 30903, epoch: 173, loss: 0.179805
global_step: 30904, epoch: 173, loss: 0.169673
global_step: 30905, epoch: 173, loss: 0.213644
global_step: 30906, epoch: 173, loss: 0.183244
global_step: 30907, epoch: 173, loss: 0.210271
global_step: 30908, epoch: 173, loss: 0.190797
global_step: 30909, epoch: 173, loss: 0.258381
global_step: 30910, epoch: 173, loss: 0.194409
global_step: 30911, epoch: 173, loss: 0.187186
global_step: 30912, epoch: 173, loss: 0.225065
global_step: 30913, epoch: 173, loss: 0.286443
global_step: 30914, epoch: 173, loss: 0.223107
global_step: 30915, epoch: 173, loss: 0.220587
global_step: 30916, epoch: 173, loss: 0.189458
global_step: 30917, epoch: 173, loss: 0.171356
global_step: 30918, epoch: 173, loss: 0.210196
global_step: 30919, epoch: 173, loss: 0.228471
global_step: 30920, epoch: 173, loss: 0.182636
epoch: 173
train	acc: 0.9719	macro: p 0.9748, r 0.9627, f1: 0.9685	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5212	macro: p 0.3439, r 0.2970, f1: 0.2995	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4760
test	acc: 0.5716	macro: p 0.3603, r 0.3100, f1: 0.3186	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5337
global_step: 30921, epoch: 174, loss: 0.134189
global_step: 30922, epoch: 174, loss: 0.181182
global_step: 30923, epoch: 174, loss: 0.231702
global_step: 30924, epoch: 174, loss: 0.196491
global_step: 30925, epoch: 174, loss: 0.203970
global_step: 30926, epoch: 174, loss: 0.195174
global_step: 30927, epoch: 174, loss: 0.192994
global_step: 30928, epoch: 174, loss: 0.252513
global_step: 30929, epoch: 174, loss: 0.180755
global_step: 30930, epoch: 174, loss: 0.178909
global_step: 30931, epoch: 174, loss: 0.187170
global_step: 30932, epoch: 174, loss: 0.210569
global_step: 30933, epoch: 174, loss: 0.194024
global_step: 30934, epoch: 174, loss: 0.193441
global_step: 30935, epoch: 174, loss: 0.165596
global_step: 30936, epoch: 174, loss: 0.206758
global_step: 30937, epoch: 174, loss: 0.225803
global_step: 30938, epoch: 174, loss: 0.215174
global_step: 30939, epoch: 174, loss: 0.233972
global_step: 30940, epoch: 174, loss: 0.189676
global_step: 30941, epoch: 174, loss: 0.203460
global_step: 30942, epoch: 174, loss: 0.161049
global_step: 30943, epoch: 174, loss: 0.186688
global_step: 30944, epoch: 174, loss: 0.203893
global_step: 30945, epoch: 174, loss: 0.210762
global_step: 30946, epoch: 174, loss: 0.228690
global_step: 30947, epoch: 174, loss: 0.180134
global_step: 30948, epoch: 174, loss: 0.200868
global_step: 30949, epoch: 174, loss: 0.161647
global_step: 30950, epoch: 174, loss: 0.213525
global_step: 30951, epoch: 174, loss: 0.287952
global_step: 30952, epoch: 174, loss: 0.216558
global_step: 30953, epoch: 174, loss: 0.193926
global_step: 30954, epoch: 174, loss: 0.236566
global_step: 30955, epoch: 174, loss: 0.164682
global_step: 30956, epoch: 174, loss: 0.221314
global_step: 30957, epoch: 174, loss: 0.181719
global_step: 30958, epoch: 174, loss: 0.143152
global_step: 30959, epoch: 174, loss: 0.186523
global_step: 30960, epoch: 174, loss: 0.002643
epoch: 174
train	acc: 0.9719	macro: p 0.9754, r 0.9620, f1: 0.9685	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5284	macro: p 0.3760, r 0.3104, f1: 0.3178	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4869
test	acc: 0.5782	macro: p 0.3534, r 0.3124, f1: 0.3189	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5421
global_step: 30961, epoch: 175, loss: 0.236408
global_step: 30962, epoch: 175, loss: 0.165736
global_step: 30963, epoch: 175, loss: 0.225249
global_step: 30964, epoch: 175, loss: 0.165718
global_step: 30965, epoch: 175, loss: 0.245458
global_step: 30966, epoch: 175, loss: 0.163940
global_step: 30967, epoch: 175, loss: 0.244270
global_step: 30968, epoch: 175, loss: 0.194663
global_step: 30969, epoch: 175, loss: 0.208517
global_step: 30970, epoch: 175, loss: 0.167060
global_step: 30971, epoch: 175, loss: 0.176722
global_step: 30972, epoch: 175, loss: 0.210319
global_step: 30973, epoch: 175, loss: 0.229730
global_step: 30974, epoch: 175, loss: 0.227401
global_step: 30975, epoch: 175, loss: 0.184682
global_step: 30976, epoch: 175, loss: 0.224615
global_step: 30977, epoch: 175, loss: 0.232373
global_step: 30978, epoch: 175, loss: 0.170792
global_step: 30979, epoch: 175, loss: 0.172065
global_step: 30980, epoch: 175, loss: 0.190456
global_step: 30981, epoch: 175, loss: 0.169413
global_step: 30982, epoch: 175, loss: 0.141258
global_step: 30983, epoch: 175, loss: 0.198920
global_step: 30984, epoch: 175, loss: 0.172855
global_step: 30985, epoch: 175, loss: 0.238858
global_step: 30986, epoch: 175, loss: 0.187662
global_step: 30987, epoch: 175, loss: 0.164583
global_step: 30988, epoch: 175, loss: 0.206580
global_step: 30989, epoch: 175, loss: 0.188917
global_step: 30990, epoch: 175, loss: 0.206966
global_step: 30991, epoch: 175, loss: 0.216106
global_step: 30992, epoch: 175, loss: 0.178702
global_step: 30993, epoch: 175, loss: 0.177241
global_step: 30994, epoch: 175, loss: 0.170082
global_step: 30995, epoch: 175, loss: 0.142145
global_step: 30996, epoch: 175, loss: 0.192229
global_step: 30997, epoch: 175, loss: 0.212020
global_step: 30998, epoch: 175, loss: 0.124607
global_step: 30999, epoch: 175, loss: 0.222845
global_step: 31000, epoch: 175, loss: 0.060923
epoch: 175
train	acc: 0.9718	macro: p 0.9754, r 0.9612, f1: 0.9681	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5221	macro: p 0.3641, r 0.3040, f1: 0.3048	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4812
test	acc: 0.5701	macro: p 0.3561, r 0.3115, f1: 0.3170	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5372
global_step: 31001, epoch: 176, loss: 0.175618
global_step: 31002, epoch: 176, loss: 0.134867
global_step: 31003, epoch: 176, loss: 0.167603
global_step: 31004, epoch: 176, loss: 0.157250
global_step: 31005, epoch: 176, loss: 0.198224
global_step: 31006, epoch: 176, loss: 0.208423
global_step: 31007, epoch: 176, loss: 0.182073
global_step: 31008, epoch: 176, loss: 0.206813
global_step: 31009, epoch: 176, loss: 0.202341
global_step: 31010, epoch: 176, loss: 0.234346
global_step: 31011, epoch: 176, loss: 0.176103
global_step: 31012, epoch: 176, loss: 0.157568
global_step: 31013, epoch: 176, loss: 0.205196
global_step: 31014, epoch: 176, loss: 0.165125
global_step: 31015, epoch: 176, loss: 0.222428
global_step: 31016, epoch: 176, loss: 0.151031
global_step: 31017, epoch: 176, loss: 0.202355
global_step: 31018, epoch: 176, loss: 0.176181
global_step: 31019, epoch: 176, loss: 0.268892
global_step: 31020, epoch: 176, loss: 0.259310
global_step: 31021, epoch: 176, loss: 0.142034
global_step: 31022, epoch: 176, loss: 0.183777
global_step: 31023, epoch: 176, loss: 0.221585
global_step: 31024, epoch: 176, loss: 0.189152
global_step: 31025, epoch: 176, loss: 0.135607
global_step: 31026, epoch: 176, loss: 0.219615
global_step: 31027, epoch: 176, loss: 0.204357
global_step: 31028, epoch: 176, loss: 0.183187
global_step: 31029, epoch: 176, loss: 0.268687
global_step: 31030, epoch: 176, loss: 0.212301
global_step: 31031, epoch: 176, loss: 0.151314
global_step: 31032, epoch: 176, loss: 0.225305
global_step: 31033, epoch: 176, loss: 0.151633
global_step: 31034, epoch: 176, loss: 0.244864
global_step: 31035, epoch: 176, loss: 0.228838
global_step: 31036, epoch: 176, loss: 0.134536
global_step: 31037, epoch: 176, loss: 0.149683
global_step: 31038, epoch: 176, loss: 0.191249
global_step: 31039, epoch: 176, loss: 0.185500
global_step: 31040, epoch: 176, loss: 0.468791
epoch: 176
train	acc: 0.9720	macro: p 0.9749, r 0.9620, f1: 0.9682	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5320	macro: p 0.3796, r 0.3160, f1: 0.3227	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4919
test	acc: 0.5759	macro: p 0.3599, r 0.3199, f1: 0.3272	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5446
global_step: 31041, epoch: 177, loss: 0.189037
global_step: 31042, epoch: 177, loss: 0.223400
global_step: 31043, epoch: 177, loss: 0.236455
global_step: 31044, epoch: 177, loss: 0.175683
global_step: 31045, epoch: 177, loss: 0.116889
global_step: 31046, epoch: 177, loss: 0.173635
global_step: 31047, epoch: 177, loss: 0.165454
global_step: 31048, epoch: 177, loss: 0.147418
global_step: 31049, epoch: 177, loss: 0.193067
global_step: 31050, epoch: 177, loss: 0.166159
global_step: 31051, epoch: 177, loss: 0.158990
global_step: 31052, epoch: 177, loss: 0.173776
global_step: 31053, epoch: 177, loss: 0.188938
global_step: 31054, epoch: 177, loss: 0.174674
global_step: 31055, epoch: 177, loss: 0.222162
global_step: 31056, epoch: 177, loss: 0.169636
global_step: 31057, epoch: 177, loss: 0.209752
global_step: 31058, epoch: 177, loss: 0.221268
global_step: 31059, epoch: 177, loss: 0.197636
global_step: 31060, epoch: 177, loss: 0.226318
global_step: 31061, epoch: 177, loss: 0.197475
global_step: 31062, epoch: 177, loss: 0.126123
global_step: 31063, epoch: 177, loss: 0.189431
global_step: 31064, epoch: 177, loss: 0.210142
global_step: 31065, epoch: 177, loss: 0.250054
global_step: 31066, epoch: 177, loss: 0.222650
global_step: 31067, epoch: 177, loss: 0.193947
global_step: 31068, epoch: 177, loss: 0.217936
global_step: 31069, epoch: 177, loss: 0.183578
global_step: 31070, epoch: 177, loss: 0.197785
global_step: 31071, epoch: 177, loss: 0.176285
global_step: 31072, epoch: 177, loss: 0.200963
global_step: 31073, epoch: 177, loss: 0.206987
global_step: 31074, epoch: 177, loss: 0.213129
global_step: 31075, epoch: 177, loss: 0.161231
global_step: 31076, epoch: 177, loss: 0.166913
global_step: 31077, epoch: 177, loss: 0.203002
global_step: 31078, epoch: 177, loss: 0.123557
global_step: 31079, epoch: 177, loss: 0.170014
global_step: 31080, epoch: 177, loss: 1.071775
epoch: 177
train	acc: 0.9717	macro: p 0.9749, r 0.9615, f1: 0.9680	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5248	macro: p 0.3567, r 0.3043, f1: 0.3068	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4837
test	acc: 0.5762	macro: p 0.3705, r 0.3215, f1: 0.3303	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5453
global_step: 31081, epoch: 178, loss: 0.177256
global_step: 31082, epoch: 178, loss: 0.220737
global_step: 31083, epoch: 178, loss: 0.195852
global_step: 31084, epoch: 178, loss: 0.205940
global_step: 31085, epoch: 178, loss: 0.174527
global_step: 31086, epoch: 178, loss: 0.209450
global_step: 31087, epoch: 178, loss: 0.157409
global_step: 31088, epoch: 178, loss: 0.198794
global_step: 31089, epoch: 178, loss: 0.168785
global_step: 31090, epoch: 178, loss: 0.180161
global_step: 31091, epoch: 178, loss: 0.216845
global_step: 31092, epoch: 178, loss: 0.195039
global_step: 31093, epoch: 178, loss: 0.176262
global_step: 31094, epoch: 178, loss: 0.194974
global_step: 31095, epoch: 178, loss: 0.268036
global_step: 31096, epoch: 178, loss: 0.158594
global_step: 31097, epoch: 178, loss: 0.190088
global_step: 31098, epoch: 178, loss: 0.214974
global_step: 31099, epoch: 178, loss: 0.158844
global_step: 31100, epoch: 178, loss: 0.137387
global_step: 31101, epoch: 178, loss: 0.210815
global_step: 31102, epoch: 178, loss: 0.199449
global_step: 31103, epoch: 178, loss: 0.206513
global_step: 31104, epoch: 178, loss: 0.233105
global_step: 31105, epoch: 178, loss: 0.153120
global_step: 31106, epoch: 178, loss: 0.186481
global_step: 31107, epoch: 178, loss: 0.191818
global_step: 31108, epoch: 178, loss: 0.205538
global_step: 31109, epoch: 178, loss: 0.209424
global_step: 31110, epoch: 178, loss: 0.159052
global_step: 31111, epoch: 178, loss: 0.193228
global_step: 31112, epoch: 178, loss: 0.143646
global_step: 31113, epoch: 178, loss: 0.158275
global_step: 31114, epoch: 178, loss: 0.213283
global_step: 31115, epoch: 178, loss: 0.187053
global_step: 31116, epoch: 178, loss: 0.167599
global_step: 31117, epoch: 178, loss: 0.196162
global_step: 31118, epoch: 178, loss: 0.154509
global_step: 31119, epoch: 178, loss: 0.244748
global_step: 31120, epoch: 178, loss: 0.121965
epoch: 178
train	acc: 0.9718	macro: p 0.9746, r 0.9611, f1: 0.9676	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5212	macro: p 0.3779, r 0.3049, f1: 0.3095	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4784
test	acc: 0.5770	macro: p 0.3699, r 0.3192, f1: 0.3281	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5435
global_step: 31121, epoch: 179, loss: 0.223055
global_step: 31122, epoch: 179, loss: 0.244035
global_step: 31123, epoch: 179, loss: 0.167592
global_step: 31124, epoch: 179, loss: 0.186256
global_step: 31125, epoch: 179, loss: 0.117459
global_step: 31126, epoch: 179, loss: 0.150129
global_step: 31127, epoch: 179, loss: 0.163358
global_step: 31128, epoch: 179, loss: 0.160592
global_step: 31129, epoch: 179, loss: 0.148758
global_step: 31130, epoch: 179, loss: 0.242556
global_step: 31131, epoch: 179, loss: 0.153214
global_step: 31132, epoch: 179, loss: 0.162343
global_step: 31133, epoch: 179, loss: 0.170567
global_step: 31134, epoch: 179, loss: 0.173805
global_step: 31135, epoch: 179, loss: 0.213724
global_step: 31136, epoch: 179, loss: 0.225188
global_step: 31137, epoch: 179, loss: 0.149120
global_step: 31138, epoch: 179, loss: 0.231857
global_step: 31139, epoch: 179, loss: 0.142445
global_step: 31140, epoch: 179, loss: 0.244876
global_step: 31141, epoch: 179, loss: 0.163928
global_step: 31142, epoch: 179, loss: 0.209307
global_step: 31143, epoch: 179, loss: 0.213832
global_step: 31144, epoch: 179, loss: 0.176855
global_step: 31145, epoch: 179, loss: 0.209974
global_step: 31146, epoch: 179, loss: 0.220103
global_step: 31147, epoch: 179, loss: 0.132066
global_step: 31148, epoch: 179, loss: 0.160395
global_step: 31149, epoch: 179, loss: 0.238309
global_step: 31150, epoch: 179, loss: 0.310636
global_step: 31151, epoch: 179, loss: 0.202384
global_step: 31152, epoch: 179, loss: 0.186375
global_step: 31153, epoch: 179, loss: 0.221437
global_step: 31154, epoch: 179, loss: 0.214558
global_step: 31155, epoch: 179, loss: 0.139952
global_step: 31156, epoch: 179, loss: 0.209158
global_step: 31157, epoch: 179, loss: 0.209197
global_step: 31158, epoch: 179, loss: 0.127712
global_step: 31159, epoch: 179, loss: 0.200059
global_step: 31160, epoch: 179, loss: 0.251469
epoch: 179
train	acc: 0.9708	macro: p 0.9753, r 0.9597, f1: 0.9672	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5257	macro: p 0.3874, r 0.3125, f1: 0.3162	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4846
test	acc: 0.5747	macro: p 0.3589, r 0.3154, f1: 0.3203	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5402
global_step: 31161, epoch: 180, loss: 0.125218
global_step: 31162, epoch: 180, loss: 0.242082
global_step: 31163, epoch: 180, loss: 0.200096
global_step: 31164, epoch: 180, loss: 0.184863
global_step: 31165, epoch: 180, loss: 0.186585
global_step: 31166, epoch: 180, loss: 0.212952
global_step: 31167, epoch: 180, loss: 0.234735
global_step: 31168, epoch: 180, loss: 0.130413
global_step: 31169, epoch: 180, loss: 0.128524
global_step: 31170, epoch: 180, loss: 0.186461
global_step: 31171, epoch: 180, loss: 0.224815
global_step: 31172, epoch: 180, loss: 0.176364
global_step: 31173, epoch: 180, loss: 0.201808
global_step: 31174, epoch: 180, loss: 0.175720
global_step: 31175, epoch: 180, loss: 0.166961
global_step: 31176, epoch: 180, loss: 0.147672
global_step: 31177, epoch: 180, loss: 0.233420
global_step: 31178, epoch: 180, loss: 0.171398
global_step: 31179, epoch: 180, loss: 0.228998
global_step: 31180, epoch: 180, loss: 0.170741
global_step: 31181, epoch: 180, loss: 0.240112
global_step: 31182, epoch: 180, loss: 0.217878
global_step: 31183, epoch: 180, loss: 0.163268
global_step: 31184, epoch: 180, loss: 0.236545
global_step: 31185, epoch: 180, loss: 0.268732
global_step: 31186, epoch: 180, loss: 0.223323
global_step: 31187, epoch: 180, loss: 0.193154
global_step: 31188, epoch: 180, loss: 0.235953
global_step: 31189, epoch: 180, loss: 0.192512
global_step: 31190, epoch: 180, loss: 0.188978
global_step: 31191, epoch: 180, loss: 0.122247
global_step: 31192, epoch: 180, loss: 0.141925
global_step: 31193, epoch: 180, loss: 0.173282
global_step: 31194, epoch: 180, loss: 0.185336
global_step: 31195, epoch: 180, loss: 0.235273
global_step: 31196, epoch: 180, loss: 0.188587
global_step: 31197, epoch: 180, loss: 0.199757
global_step: 31198, epoch: 180, loss: 0.210559
global_step: 31199, epoch: 180, loss: 0.179569
global_step: 31200, epoch: 180, loss: 0.193180
epoch: 180
train	acc: 0.9724	macro: p 0.9768, r 0.9618, f1: 0.9691	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5275	macro: p 0.3688, r 0.3010, f1: 0.3044	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4817
test	acc: 0.5782	macro: p 0.3671, r 0.3108, f1: 0.3196	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5410
global_step: 31201, epoch: 181, loss: 0.183167
global_step: 31202, epoch: 181, loss: 0.161277
global_step: 31203, epoch: 181, loss: 0.125840
global_step: 31204, epoch: 181, loss: 0.208575
global_step: 31205, epoch: 181, loss: 0.144119
global_step: 31206, epoch: 181, loss: 0.195216
global_step: 31207, epoch: 181, loss: 0.157962
global_step: 31208, epoch: 181, loss: 0.138770
global_step: 31209, epoch: 181, loss: 0.186887
global_step: 31210, epoch: 181, loss: 0.152108
global_step: 31211, epoch: 181, loss: 0.170591
global_step: 31212, epoch: 181, loss: 0.166205
global_step: 31213, epoch: 181, loss: 0.186520
global_step: 31214, epoch: 181, loss: 0.173519
global_step: 31215, epoch: 181, loss: 0.181979
global_step: 31216, epoch: 181, loss: 0.197406
global_step: 31217, epoch: 181, loss: 0.115781
global_step: 31218, epoch: 181, loss: 0.249682
global_step: 31219, epoch: 181, loss: 0.165200
global_step: 31220, epoch: 181, loss: 0.152670
global_step: 31221, epoch: 181, loss: 0.260981
global_step: 31222, epoch: 181, loss: 0.151315
global_step: 31223, epoch: 181, loss: 0.180861
global_step: 31224, epoch: 181, loss: 0.239345
global_step: 31225, epoch: 181, loss: 0.189675
global_step: 31226, epoch: 181, loss: 0.261056
global_step: 31227, epoch: 181, loss: 0.196030
global_step: 31228, epoch: 181, loss: 0.117285
global_step: 31229, epoch: 181, loss: 0.147631
global_step: 31230, epoch: 181, loss: 0.165603
global_step: 31231, epoch: 181, loss: 0.295434
global_step: 31232, epoch: 181, loss: 0.190537
global_step: 31233, epoch: 181, loss: 0.188256
global_step: 31234, epoch: 181, loss: 0.178856
global_step: 31235, epoch: 181, loss: 0.207283
global_step: 31236, epoch: 181, loss: 0.153412
global_step: 31237, epoch: 181, loss: 0.187677
global_step: 31238, epoch: 181, loss: 0.176261
global_step: 31239, epoch: 181, loss: 0.220970
global_step: 31240, epoch: 181, loss: 0.472052
epoch: 181
train	acc: 0.9718	macro: p 0.9763, r 0.9599, f1: 0.9678	micro: p 0.9718, r 0.9718, f1 0.9718	weighted_f1:0.9718
dev	acc: 0.5257	macro: p 0.3505, r 0.2979, f1: 0.3006	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4787
test	acc: 0.5739	macro: p 0.3494, r 0.3039, f1: 0.3102	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5352
global_step: 31241, epoch: 182, loss: 0.183207
global_step: 31242, epoch: 182, loss: 0.224972
global_step: 31243, epoch: 182, loss: 0.216319
global_step: 31244, epoch: 182, loss: 0.177577
global_step: 31245, epoch: 182, loss: 0.212242
global_step: 31246, epoch: 182, loss: 0.185625
global_step: 31247, epoch: 182, loss: 0.156775
global_step: 31248, epoch: 182, loss: 0.148383
global_step: 31249, epoch: 182, loss: 0.175289
global_step: 31250, epoch: 182, loss: 0.132689
global_step: 31251, epoch: 182, loss: 0.179259
global_step: 31252, epoch: 182, loss: 0.179370
global_step: 31253, epoch: 182, loss: 0.124167
global_step: 31254, epoch: 182, loss: 0.179898
global_step: 31255, epoch: 182, loss: 0.184357
global_step: 31256, epoch: 182, loss: 0.158191
global_step: 31257, epoch: 182, loss: 0.162133
global_step: 31258, epoch: 182, loss: 0.144993
global_step: 31259, epoch: 182, loss: 0.199865
global_step: 31260, epoch: 182, loss: 0.180723
global_step: 31261, epoch: 182, loss: 0.143312
global_step: 31262, epoch: 182, loss: 0.167101
global_step: 31263, epoch: 182, loss: 0.207566
global_step: 31264, epoch: 182, loss: 0.138735
global_step: 31265, epoch: 182, loss: 0.173365
global_step: 31266, epoch: 182, loss: 0.164407
global_step: 31267, epoch: 182, loss: 0.186996
global_step: 31268, epoch: 182, loss: 0.244612
global_step: 31269, epoch: 182, loss: 0.174895
global_step: 31270, epoch: 182, loss: 0.216502
global_step: 31271, epoch: 182, loss: 0.187961
global_step: 31272, epoch: 182, loss: 0.155847
global_step: 31273, epoch: 182, loss: 0.207027
global_step: 31274, epoch: 182, loss: 0.161513
global_step: 31275, epoch: 182, loss: 0.220855
global_step: 31276, epoch: 182, loss: 0.242307
global_step: 31277, epoch: 182, loss: 0.185061
global_step: 31278, epoch: 182, loss: 0.212490
global_step: 31279, epoch: 182, loss: 0.216203
global_step: 31280, epoch: 182, loss: 0.000890
epoch: 182
train	acc: 0.9720	macro: p 0.9762, r 0.9616, f1: 0.9686	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5221	macro: p 0.3765, r 0.3110, f1: 0.3170	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4836
test	acc: 0.5690	macro: p 0.3521, r 0.3152, f1: 0.3217	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5387
global_step: 31281, epoch: 183, loss: 0.170429
global_step: 31282, epoch: 183, loss: 0.221699
global_step: 31283, epoch: 183, loss: 0.236970
global_step: 31284, epoch: 183, loss: 0.202973
global_step: 31285, epoch: 183, loss: 0.151545
global_step: 31286, epoch: 183, loss: 0.197051
global_step: 31287, epoch: 183, loss: 0.175804
global_step: 31288, epoch: 183, loss: 0.221818
global_step: 31289, epoch: 183, loss: 0.160759
global_step: 31290, epoch: 183, loss: 0.204336
global_step: 31291, epoch: 183, loss: 0.170520
global_step: 31292, epoch: 183, loss: 0.219885
global_step: 31293, epoch: 183, loss: 0.196662
global_step: 31294, epoch: 183, loss: 0.179926
global_step: 31295, epoch: 183, loss: 0.197883
global_step: 31296, epoch: 183, loss: 0.170352
global_step: 31297, epoch: 183, loss: 0.184966
global_step: 31298, epoch: 183, loss: 0.164380
global_step: 31299, epoch: 183, loss: 0.178659
global_step: 31300, epoch: 183, loss: 0.127107
global_step: 31301, epoch: 183, loss: 0.192147
global_step: 31302, epoch: 183, loss: 0.249678
global_step: 31303, epoch: 183, loss: 0.184333
global_step: 31304, epoch: 183, loss: 0.155320
global_step: 31305, epoch: 183, loss: 0.190226
global_step: 31306, epoch: 183, loss: 0.170866
global_step: 31307, epoch: 183, loss: 0.157347
global_step: 31308, epoch: 183, loss: 0.177325
global_step: 31309, epoch: 183, loss: 0.150218
global_step: 31310, epoch: 183, loss: 0.232412
global_step: 31311, epoch: 183, loss: 0.209442
global_step: 31312, epoch: 183, loss: 0.132188
global_step: 31313, epoch: 183, loss: 0.217432
global_step: 31314, epoch: 183, loss: 0.206087
global_step: 31315, epoch: 183, loss: 0.201475
global_step: 31316, epoch: 183, loss: 0.167195
global_step: 31317, epoch: 183, loss: 0.149596
global_step: 31318, epoch: 183, loss: 0.259800
global_step: 31319, epoch: 183, loss: 0.192601
global_step: 31320, epoch: 183, loss: 0.013507
epoch: 183
train	acc: 0.9724	macro: p 0.9765, r 0.9613, f1: 0.9686	micro: p 0.9724, r 0.9724, f1 0.9724	weighted_f1:0.9724
dev	acc: 0.5230	macro: p 0.3586, r 0.2991, f1: 0.3016	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4779
test	acc: 0.5728	macro: p 0.3576, r 0.3078, f1: 0.3153	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5357
global_step: 31321, epoch: 184, loss: 0.159880
global_step: 31322, epoch: 184, loss: 0.173859
global_step: 31323, epoch: 184, loss: 0.141982
global_step: 31324, epoch: 184, loss: 0.169241
global_step: 31325, epoch: 184, loss: 0.140932
global_step: 31326, epoch: 184, loss: 0.249505
global_step: 31327, epoch: 184, loss: 0.174256
global_step: 31328, epoch: 184, loss: 0.213442
global_step: 31329, epoch: 184, loss: 0.273924
global_step: 31330, epoch: 184, loss: 0.133390
global_step: 31331, epoch: 184, loss: 0.152406
global_step: 31332, epoch: 184, loss: 0.184146
global_step: 31333, epoch: 184, loss: 0.237992
global_step: 31334, epoch: 184, loss: 0.215398
global_step: 31335, epoch: 184, loss: 0.223255
global_step: 31336, epoch: 184, loss: 0.199674
global_step: 31337, epoch: 184, loss: 0.125565
global_step: 31338, epoch: 184, loss: 0.218659
global_step: 31339, epoch: 184, loss: 0.136038
global_step: 31340, epoch: 184, loss: 0.130100
global_step: 31341, epoch: 184, loss: 0.149660
global_step: 31342, epoch: 184, loss: 0.264940
global_step: 31343, epoch: 184, loss: 0.168880
global_step: 31344, epoch: 184, loss: 0.199256
global_step: 31345, epoch: 184, loss: 0.172764
global_step: 31346, epoch: 184, loss: 0.198033
global_step: 31347, epoch: 184, loss: 0.169935
global_step: 31348, epoch: 184, loss: 0.154812
global_step: 31349, epoch: 184, loss: 0.253343
global_step: 31350, epoch: 184, loss: 0.115418
global_step: 31351, epoch: 184, loss: 0.166730
global_step: 31352, epoch: 184, loss: 0.216766
global_step: 31353, epoch: 184, loss: 0.164505
global_step: 31354, epoch: 184, loss: 0.168548
global_step: 31355, epoch: 184, loss: 0.137772
global_step: 31356, epoch: 184, loss: 0.167606
global_step: 31357, epoch: 184, loss: 0.145162
global_step: 31358, epoch: 184, loss: 0.172775
global_step: 31359, epoch: 184, loss: 0.207266
global_step: 31360, epoch: 184, loss: 0.017215
epoch: 184
train	acc: 0.9725	macro: p 0.9761, r 0.9621, f1: 0.9689	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5149	macro: p 0.3426, r 0.3003, f1: 0.3009	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4751
test	acc: 0.5670	macro: p 0.3390, r 0.3071, f1: 0.3107	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5343
global_step: 31361, epoch: 185, loss: 0.172268
global_step: 31362, epoch: 185, loss: 0.213079
global_step: 31363, epoch: 185, loss: 0.175968
global_step: 31364, epoch: 185, loss: 0.188291
global_step: 31365, epoch: 185, loss: 0.209821
global_step: 31366, epoch: 185, loss: 0.192817
global_step: 31367, epoch: 185, loss: 0.298563
global_step: 31368, epoch: 185, loss: 0.165370
global_step: 31369, epoch: 185, loss: 0.169685
global_step: 31370, epoch: 185, loss: 0.216906
global_step: 31371, epoch: 185, loss: 0.178780
global_step: 31372, epoch: 185, loss: 0.189598
global_step: 31373, epoch: 185, loss: 0.196535
global_step: 31374, epoch: 185, loss: 0.221859
global_step: 31375, epoch: 185, loss: 0.154406
global_step: 31376, epoch: 185, loss: 0.149923
global_step: 31377, epoch: 185, loss: 0.130517
global_step: 31378, epoch: 185, loss: 0.190297
global_step: 31379, epoch: 185, loss: 0.174729
global_step: 31380, epoch: 185, loss: 0.175127
global_step: 31381, epoch: 185, loss: 0.120860
global_step: 31382, epoch: 185, loss: 0.221162
global_step: 31383, epoch: 185, loss: 0.138829
global_step: 31384, epoch: 185, loss: 0.248243
global_step: 31385, epoch: 185, loss: 0.174104
global_step: 31386, epoch: 185, loss: 0.232724
global_step: 31387, epoch: 185, loss: 0.194859
global_step: 31388, epoch: 185, loss: 0.203346
global_step: 31389, epoch: 185, loss: 0.186807
global_step: 31390, epoch: 185, loss: 0.190951
global_step: 31391, epoch: 185, loss: 0.178127
global_step: 31392, epoch: 185, loss: 0.172504
global_step: 31393, epoch: 185, loss: 0.180350
global_step: 31394, epoch: 185, loss: 0.167614
global_step: 31395, epoch: 185, loss: 0.205692
global_step: 31396, epoch: 185, loss: 0.256259
global_step: 31397, epoch: 185, loss: 0.262802
global_step: 31398, epoch: 185, loss: 0.164562
global_step: 31399, epoch: 185, loss: 0.216143
global_step: 31400, epoch: 185, loss: 0.073231
epoch: 185
train	acc: 0.9717	macro: p 0.9756, r 0.9606, f1: 0.9678	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5284	macro: p 0.3706, r 0.3058, f1: 0.3065	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4842
test	acc: 0.5759	macro: p 0.3546, r 0.3110, f1: 0.3144	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5376
global_step: 31401, epoch: 186, loss: 0.178442
global_step: 31402, epoch: 186, loss: 0.173590
global_step: 31403, epoch: 186, loss: 0.200421
global_step: 31404, epoch: 186, loss: 0.196447
global_step: 31405, epoch: 186, loss: 0.141134
global_step: 31406, epoch: 186, loss: 0.155877
global_step: 31407, epoch: 186, loss: 0.143910
global_step: 31408, epoch: 186, loss: 0.169662
global_step: 31409, epoch: 186, loss: 0.210435
global_step: 31410, epoch: 186, loss: 0.188741
global_step: 31411, epoch: 186, loss: 0.166741
global_step: 31412, epoch: 186, loss: 0.164334
global_step: 31413, epoch: 186, loss: 0.167644
global_step: 31414, epoch: 186, loss: 0.208582
global_step: 31415, epoch: 186, loss: 0.188190
global_step: 31416, epoch: 186, loss: 0.162703
global_step: 31417, epoch: 186, loss: 0.229678
global_step: 31418, epoch: 186, loss: 0.177230
global_step: 31419, epoch: 186, loss: 0.216756
global_step: 31420, epoch: 186, loss: 0.182888
global_step: 31421, epoch: 186, loss: 0.251364
global_step: 31422, epoch: 186, loss: 0.215070
global_step: 31423, epoch: 186, loss: 0.251666
global_step: 31424, epoch: 186, loss: 0.189112
global_step: 31425, epoch: 186, loss: 0.205598
global_step: 31426, epoch: 186, loss: 0.165594
global_step: 31427, epoch: 186, loss: 0.177471
global_step: 31428, epoch: 186, loss: 0.188139
global_step: 31429, epoch: 186, loss: 0.265194
global_step: 31430, epoch: 186, loss: 0.132067
global_step: 31431, epoch: 186, loss: 0.225128
global_step: 31432, epoch: 186, loss: 0.226780
global_step: 31433, epoch: 186, loss: 0.203968
global_step: 31434, epoch: 186, loss: 0.134878
global_step: 31435, epoch: 186, loss: 0.133706
global_step: 31436, epoch: 186, loss: 0.187422
global_step: 31437, epoch: 186, loss: 0.211927
global_step: 31438, epoch: 186, loss: 0.219584
global_step: 31439, epoch: 186, loss: 0.239086
global_step: 31440, epoch: 186, loss: 0.029887
epoch: 186
train	acc: 0.9723	macro: p 0.9766, r 0.9618, f1: 0.9689	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5194	macro: p 0.3579, r 0.3025, f1: 0.3054	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4796
test	acc: 0.5739	macro: p 0.3547, r 0.3128, f1: 0.3178	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5399
global_step: 31441, epoch: 187, loss: 0.126647
global_step: 31442, epoch: 187, loss: 0.166165
global_step: 31443, epoch: 187, loss: 0.126427
global_step: 31444, epoch: 187, loss: 0.141308
global_step: 31445, epoch: 187, loss: 0.186110
global_step: 31446, epoch: 187, loss: 0.138191
global_step: 31447, epoch: 187, loss: 0.215274
global_step: 31448, epoch: 187, loss: 0.213306
global_step: 31449, epoch: 187, loss: 0.134685
global_step: 31450, epoch: 187, loss: 0.198537
global_step: 31451, epoch: 187, loss: 0.177006
global_step: 31452, epoch: 187, loss: 0.169374
global_step: 31453, epoch: 187, loss: 0.147055
global_step: 31454, epoch: 187, loss: 0.204951
global_step: 31455, epoch: 187, loss: 0.235065
global_step: 31456, epoch: 187, loss: 0.200336
global_step: 31457, epoch: 187, loss: 0.157510
global_step: 31458, epoch: 187, loss: 0.172221
global_step: 31459, epoch: 187, loss: 0.234637
global_step: 31460, epoch: 187, loss: 0.216254
global_step: 31461, epoch: 187, loss: 0.197711
global_step: 31462, epoch: 187, loss: 0.234829
global_step: 31463, epoch: 187, loss: 0.236340
global_step: 31464, epoch: 187, loss: 0.122649
global_step: 31465, epoch: 187, loss: 0.194005
global_step: 31466, epoch: 187, loss: 0.217448
global_step: 31467, epoch: 187, loss: 0.196578
global_step: 31468, epoch: 187, loss: 0.199940
global_step: 31469, epoch: 187, loss: 0.167169
global_step: 31470, epoch: 187, loss: 0.138881
global_step: 31471, epoch: 187, loss: 0.199055
global_step: 31472, epoch: 187, loss: 0.161618
global_step: 31473, epoch: 187, loss: 0.193976
global_step: 31474, epoch: 187, loss: 0.153370
global_step: 31475, epoch: 187, loss: 0.221028
global_step: 31476, epoch: 187, loss: 0.148813
global_step: 31477, epoch: 187, loss: 0.120158
global_step: 31478, epoch: 187, loss: 0.257530
global_step: 31479, epoch: 187, loss: 0.195565
global_step: 31480, epoch: 187, loss: 0.052126
epoch: 187
train	acc: 0.9720	macro: p 0.9759, r 0.9620, f1: 0.9687	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5230	macro: p 0.3553, r 0.3063, f1: 0.3097	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4847
test	acc: 0.5751	macro: p 0.3668, r 0.3162, f1: 0.3220	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5427
global_step: 31481, epoch: 188, loss: 0.134891
global_step: 31482, epoch: 188, loss: 0.099877
global_step: 31483, epoch: 188, loss: 0.148090
global_step: 31484, epoch: 188, loss: 0.196814
global_step: 31485, epoch: 188, loss: 0.201474
global_step: 31486, epoch: 188, loss: 0.146415
global_step: 31487, epoch: 188, loss: 0.122032
global_step: 31488, epoch: 188, loss: 0.191322
global_step: 31489, epoch: 188, loss: 0.183757
global_step: 31490, epoch: 188, loss: 0.161669
global_step: 31491, epoch: 188, loss: 0.175694
global_step: 31492, epoch: 188, loss: 0.149588
global_step: 31493, epoch: 188, loss: 0.163959
global_step: 31494, epoch: 188, loss: 0.139752
global_step: 31495, epoch: 188, loss: 0.179769
global_step: 31496, epoch: 188, loss: 0.163895
global_step: 31497, epoch: 188, loss: 0.199960
global_step: 31498, epoch: 188, loss: 0.232849
global_step: 31499, epoch: 188, loss: 0.175318
global_step: 31500, epoch: 188, loss: 0.182034
global_step: 31501, epoch: 188, loss: 0.144446
global_step: 31502, epoch: 188, loss: 0.204335
global_step: 31503, epoch: 188, loss: 0.171216
global_step: 31504, epoch: 188, loss: 0.128033
global_step: 31505, epoch: 188, loss: 0.176412
global_step: 31506, epoch: 188, loss: 0.177568
global_step: 31507, epoch: 188, loss: 0.161577
global_step: 31508, epoch: 188, loss: 0.205660
global_step: 31509, epoch: 188, loss: 0.200548
global_step: 31510, epoch: 188, loss: 0.197875
global_step: 31511, epoch: 188, loss: 0.200023
global_step: 31512, epoch: 188, loss: 0.231184
global_step: 31513, epoch: 188, loss: 0.198190
global_step: 31514, epoch: 188, loss: 0.185746
global_step: 31515, epoch: 188, loss: 0.197587
global_step: 31516, epoch: 188, loss: 0.184701
global_step: 31517, epoch: 188, loss: 0.223496
global_step: 31518, epoch: 188, loss: 0.273357
global_step: 31519, epoch: 188, loss: 0.152771
global_step: 31520, epoch: 188, loss: 0.419222
epoch: 188
train	acc: 0.9728	macro: p 0.9755, r 0.9646, f1: 0.9699	micro: p 0.9728, r 0.9728, f1 0.9728	weighted_f1:0.9728
dev	acc: 0.5185	macro: p 0.3570, r 0.3010, f1: 0.3046	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4786
test	acc: 0.5705	macro: p 0.3576, r 0.3136, f1: 0.3202	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5374
global_step: 31521, epoch: 189, loss: 0.139630
global_step: 31522, epoch: 189, loss: 0.205545
global_step: 31523, epoch: 189, loss: 0.225680
global_step: 31524, epoch: 189, loss: 0.172859
global_step: 31525, epoch: 189, loss: 0.178900
global_step: 31526, epoch: 189, loss: 0.184716
global_step: 31527, epoch: 189, loss: 0.152621
global_step: 31528, epoch: 189, loss: 0.189299
global_step: 31529, epoch: 189, loss: 0.158371
global_step: 31530, epoch: 189, loss: 0.192077
global_step: 31531, epoch: 189, loss: 0.213537
global_step: 31532, epoch: 189, loss: 0.169881
global_step: 31533, epoch: 189, loss: 0.153008
global_step: 31534, epoch: 189, loss: 0.150135
global_step: 31535, epoch: 189, loss: 0.170288
global_step: 31536, epoch: 189, loss: 0.185004
global_step: 31537, epoch: 189, loss: 0.210151
global_step: 31538, epoch: 189, loss: 0.195373
global_step: 31539, epoch: 189, loss: 0.182963
global_step: 31540, epoch: 189, loss: 0.167495
global_step: 31541, epoch: 189, loss: 0.219315
global_step: 31542, epoch: 189, loss: 0.195453
global_step: 31543, epoch: 189, loss: 0.162090
global_step: 31544, epoch: 189, loss: 0.150671
global_step: 31545, epoch: 189, loss: 0.178325
global_step: 31546, epoch: 189, loss: 0.180046
global_step: 31547, epoch: 189, loss: 0.242043
global_step: 31548, epoch: 189, loss: 0.198362
global_step: 31549, epoch: 189, loss: 0.170327
global_step: 31550, epoch: 189, loss: 0.224787
global_step: 31551, epoch: 189, loss: 0.184757
global_step: 31552, epoch: 189, loss: 0.154484
global_step: 31553, epoch: 189, loss: 0.181937
global_step: 31554, epoch: 189, loss: 0.199912
global_step: 31555, epoch: 189, loss: 0.213568
global_step: 31556, epoch: 189, loss: 0.189676
global_step: 31557, epoch: 189, loss: 0.171558
global_step: 31558, epoch: 189, loss: 0.167375
global_step: 31559, epoch: 189, loss: 0.222637
global_step: 31560, epoch: 189, loss: 0.457453
epoch: 189
train	acc: 0.9731	macro: p 0.9763, r 0.9639, f1: 0.9699	micro: p 0.9731, r 0.9731, f1 0.9731	weighted_f1:0.9731
dev	acc: 0.5176	macro: p 0.3544, r 0.3028, f1: 0.3049	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4782
test	acc: 0.5697	macro: p 0.3496, r 0.3115, f1: 0.3142	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5353
global_step: 31561, epoch: 190, loss: 0.236510
global_step: 31562, epoch: 190, loss: 0.176789
global_step: 31563, epoch: 190, loss: 0.232492
global_step: 31564, epoch: 190, loss: 0.140411
global_step: 31565, epoch: 190, loss: 0.233774
global_step: 31566, epoch: 190, loss: 0.165956
global_step: 31567, epoch: 190, loss: 0.184908
global_step: 31568, epoch: 190, loss: 0.152153
global_step: 31569, epoch: 190, loss: 0.179532
global_step: 31570, epoch: 190, loss: 0.176509
global_step: 31571, epoch: 190, loss: 0.169819
global_step: 31572, epoch: 190, loss: 0.162785
global_step: 31573, epoch: 190, loss: 0.173121
global_step: 31574, epoch: 190, loss: 0.162508
global_step: 31575, epoch: 190, loss: 0.181873
global_step: 31576, epoch: 190, loss: 0.164131
global_step: 31577, epoch: 190, loss: 0.162783
global_step: 31578, epoch: 190, loss: 0.262642
global_step: 31579, epoch: 190, loss: 0.171793
global_step: 31580, epoch: 190, loss: 0.227644
global_step: 31581, epoch: 190, loss: 0.213299
global_step: 31582, epoch: 190, loss: 0.186073
global_step: 31583, epoch: 190, loss: 0.272111
global_step: 31584, epoch: 190, loss: 0.156210
global_step: 31585, epoch: 190, loss: 0.176607
global_step: 31586, epoch: 190, loss: 0.210004
global_step: 31587, epoch: 190, loss: 0.158935
global_step: 31588, epoch: 190, loss: 0.159878
global_step: 31589, epoch: 190, loss: 0.146412
global_step: 31590, epoch: 190, loss: 0.191850
global_step: 31591, epoch: 190, loss: 0.114207
global_step: 31592, epoch: 190, loss: 0.136922
global_step: 31593, epoch: 190, loss: 0.270875
global_step: 31594, epoch: 190, loss: 0.170907
global_step: 31595, epoch: 190, loss: 0.159582
global_step: 31596, epoch: 190, loss: 0.157287
global_step: 31597, epoch: 190, loss: 0.238132
global_step: 31598, epoch: 190, loss: 0.170217
global_step: 31599, epoch: 190, loss: 0.187485
global_step: 31600, epoch: 190, loss: 0.156050
epoch: 190
train	acc: 0.9723	macro: p 0.9754, r 0.9633, f1: 0.9692	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5248	macro: p 0.3574, r 0.3028, f1: 0.3055	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4815
test	acc: 0.5709	macro: p 0.3465, r 0.3069, f1: 0.3097	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5330
global_step: 31601, epoch: 191, loss: 0.158733
global_step: 31602, epoch: 191, loss: 0.151046
global_step: 31603, epoch: 191, loss: 0.180012
global_step: 31604, epoch: 191, loss: 0.189119
global_step: 31605, epoch: 191, loss: 0.183447
global_step: 31606, epoch: 191, loss: 0.157046
global_step: 31607, epoch: 191, loss: 0.171507
global_step: 31608, epoch: 191, loss: 0.171441
global_step: 31609, epoch: 191, loss: 0.184893
global_step: 31610, epoch: 191, loss: 0.195864
global_step: 31611, epoch: 191, loss: 0.153848
global_step: 31612, epoch: 191, loss: 0.168543
global_step: 31613, epoch: 191, loss: 0.204827
global_step: 31614, epoch: 191, loss: 0.138717
global_step: 31615, epoch: 191, loss: 0.297701
global_step: 31616, epoch: 191, loss: 0.153897
global_step: 31617, epoch: 191, loss: 0.190612
global_step: 31618, epoch: 191, loss: 0.200479
global_step: 31619, epoch: 191, loss: 0.160816
global_step: 31620, epoch: 191, loss: 0.206150
global_step: 31621, epoch: 191, loss: 0.131808
global_step: 31622, epoch: 191, loss: 0.250749
global_step: 31623, epoch: 191, loss: 0.204425
global_step: 31624, epoch: 191, loss: 0.129957
global_step: 31625, epoch: 191, loss: 0.232487
global_step: 31626, epoch: 191, loss: 0.200803
global_step: 31627, epoch: 191, loss: 0.216589
global_step: 31628, epoch: 191, loss: 0.186535
global_step: 31629, epoch: 191, loss: 0.203926
global_step: 31630, epoch: 191, loss: 0.198525
global_step: 31631, epoch: 191, loss: 0.195615
global_step: 31632, epoch: 191, loss: 0.138533
global_step: 31633, epoch: 191, loss: 0.152811
global_step: 31634, epoch: 191, loss: 0.129914
global_step: 31635, epoch: 191, loss: 0.161732
global_step: 31636, epoch: 191, loss: 0.179006
global_step: 31637, epoch: 191, loss: 0.172436
global_step: 31638, epoch: 191, loss: 0.286279
global_step: 31639, epoch: 191, loss: 0.226093
global_step: 31640, epoch: 191, loss: 0.269778
epoch: 191
train	acc: 0.9723	macro: p 0.9768, r 0.9615, f1: 0.9689	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5239	macro: p 0.3836, r 0.3011, f1: 0.3035	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4782
test	acc: 0.5697	macro: p 0.3544, r 0.3074, f1: 0.3128	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5325
global_step: 31641, epoch: 192, loss: 0.205889
global_step: 31642, epoch: 192, loss: 0.217451
global_step: 31643, epoch: 192, loss: 0.163452
global_step: 31644, epoch: 192, loss: 0.152202
global_step: 31645, epoch: 192, loss: 0.197735
global_step: 31646, epoch: 192, loss: 0.148817
global_step: 31647, epoch: 192, loss: 0.159861
global_step: 31648, epoch: 192, loss: 0.197969
global_step: 31649, epoch: 192, loss: 0.207719
global_step: 31650, epoch: 192, loss: 0.155558
global_step: 31651, epoch: 192, loss: 0.152360
global_step: 31652, epoch: 192, loss: 0.317402
global_step: 31653, epoch: 192, loss: 0.175341
global_step: 31654, epoch: 192, loss: 0.137288
global_step: 31655, epoch: 192, loss: 0.130997
global_step: 31656, epoch: 192, loss: 0.148534
global_step: 31657, epoch: 192, loss: 0.166462
global_step: 31658, epoch: 192, loss: 0.186195
global_step: 31659, epoch: 192, loss: 0.151380
global_step: 31660, epoch: 192, loss: 0.245077
global_step: 31661, epoch: 192, loss: 0.183142
global_step: 31662, epoch: 192, loss: 0.229690
global_step: 31663, epoch: 192, loss: 0.281576
global_step: 31664, epoch: 192, loss: 0.199658
global_step: 31665, epoch: 192, loss: 0.172238
global_step: 31666, epoch: 192, loss: 0.205830
global_step: 31667, epoch: 192, loss: 0.201315
global_step: 31668, epoch: 192, loss: 0.164427
global_step: 31669, epoch: 192, loss: 0.088304
global_step: 31670, epoch: 192, loss: 0.191515
global_step: 31671, epoch: 192, loss: 0.170206
global_step: 31672, epoch: 192, loss: 0.164921
global_step: 31673, epoch: 192, loss: 0.177343
global_step: 31674, epoch: 192, loss: 0.215399
global_step: 31675, epoch: 192, loss: 0.207049
global_step: 31676, epoch: 192, loss: 0.197775
global_step: 31677, epoch: 192, loss: 0.170231
global_step: 31678, epoch: 192, loss: 0.184139
global_step: 31679, epoch: 192, loss: 0.209055
global_step: 31680, epoch: 192, loss: 0.000196
epoch: 192
train	acc: 0.9726	macro: p 0.9775, r 0.9614, f1: 0.9692	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5257	macro: p 0.3835, r 0.3019, f1: 0.3052	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4818
test	acc: 0.5724	macro: p 0.3879, r 0.3127, f1: 0.3232	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5374
global_step: 31681, epoch: 193, loss: 0.206897
global_step: 31682, epoch: 193, loss: 0.163818
global_step: 31683, epoch: 193, loss: 0.193196
global_step: 31684, epoch: 193, loss: 0.163537
global_step: 31685, epoch: 193, loss: 0.196238
global_step: 31686, epoch: 193, loss: 0.181237
global_step: 31687, epoch: 193, loss: 0.160066
global_step: 31688, epoch: 193, loss: 0.209516
global_step: 31689, epoch: 193, loss: 0.133753
global_step: 31690, epoch: 193, loss: 0.210787
global_step: 31691, epoch: 193, loss: 0.206277
global_step: 31692, epoch: 193, loss: 0.138229
global_step: 31693, epoch: 193, loss: 0.139215
global_step: 31694, epoch: 193, loss: 0.189899
global_step: 31695, epoch: 193, loss: 0.177988
global_step: 31696, epoch: 193, loss: 0.144294
global_step: 31697, epoch: 193, loss: 0.166834
global_step: 31698, epoch: 193, loss: 0.132669
global_step: 31699, epoch: 193, loss: 0.168795
global_step: 31700, epoch: 193, loss: 0.170375
global_step: 31701, epoch: 193, loss: 0.179697
global_step: 31702, epoch: 193, loss: 0.160861
global_step: 31703, epoch: 193, loss: 0.191008
global_step: 31704, epoch: 193, loss: 0.224233
global_step: 31705, epoch: 193, loss: 0.177812
global_step: 31706, epoch: 193, loss: 0.168916
global_step: 31707, epoch: 193, loss: 0.158873
global_step: 31708, epoch: 193, loss: 0.175868
global_step: 31709, epoch: 193, loss: 0.194476
global_step: 31710, epoch: 193, loss: 0.174440
global_step: 31711, epoch: 193, loss: 0.176539
global_step: 31712, epoch: 193, loss: 0.168622
global_step: 31713, epoch: 193, loss: 0.236834
global_step: 31714, epoch: 193, loss: 0.172407
global_step: 31715, epoch: 193, loss: 0.124167
global_step: 31716, epoch: 193, loss: 0.160925
global_step: 31717, epoch: 193, loss: 0.190830
global_step: 31718, epoch: 193, loss: 0.179727
global_step: 31719, epoch: 193, loss: 0.163463
global_step: 31720, epoch: 193, loss: 0.072397
epoch: 193
train	acc: 0.9722	macro: p 0.9767, r 0.9615, f1: 0.9688	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5203	macro: p 0.3640, r 0.3034, f1: 0.3027	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4780
test	acc: 0.5674	macro: p 0.3486, r 0.3102, f1: 0.3123	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5339
global_step: 31721, epoch: 194, loss: 0.145960
global_step: 31722, epoch: 194, loss: 0.175241
global_step: 31723, epoch: 194, loss: 0.216005
global_step: 31724, epoch: 194, loss: 0.174386
global_step: 31725, epoch: 194, loss: 0.185204
global_step: 31726, epoch: 194, loss: 0.226593
global_step: 31727, epoch: 194, loss: 0.170801
global_step: 31728, epoch: 194, loss: 0.192844
global_step: 31729, epoch: 194, loss: 0.206467
global_step: 31730, epoch: 194, loss: 0.147056
global_step: 31731, epoch: 194, loss: 0.179768
global_step: 31732, epoch: 194, loss: 0.211299
global_step: 31733, epoch: 194, loss: 0.153515
global_step: 31734, epoch: 194, loss: 0.150789
global_step: 31735, epoch: 194, loss: 0.211053
global_step: 31736, epoch: 194, loss: 0.195689
global_step: 31737, epoch: 194, loss: 0.215041
global_step: 31738, epoch: 194, loss: 0.199939
global_step: 31739, epoch: 194, loss: 0.204256
global_step: 31740, epoch: 194, loss: 0.225336
global_step: 31741, epoch: 194, loss: 0.190027
global_step: 31742, epoch: 194, loss: 0.178890
global_step: 31743, epoch: 194, loss: 0.143067
global_step: 31744, epoch: 194, loss: 0.129823
global_step: 31745, epoch: 194, loss: 0.165718
global_step: 31746, epoch: 194, loss: 0.135473
global_step: 31747, epoch: 194, loss: 0.150254
global_step: 31748, epoch: 194, loss: 0.171974
global_step: 31749, epoch: 194, loss: 0.188053
global_step: 31750, epoch: 194, loss: 0.210151
global_step: 31751, epoch: 194, loss: 0.139866
global_step: 31752, epoch: 194, loss: 0.206833
global_step: 31753, epoch: 194, loss: 0.167595
global_step: 31754, epoch: 194, loss: 0.140953
global_step: 31755, epoch: 194, loss: 0.199524
global_step: 31756, epoch: 194, loss: 0.219059
global_step: 31757, epoch: 194, loss: 0.179893
global_step: 31758, epoch: 194, loss: 0.169603
global_step: 31759, epoch: 194, loss: 0.264790
global_step: 31760, epoch: 194, loss: 0.001147
epoch: 194
train	acc: 0.9728	macro: p 0.9769, r 0.9627, f1: 0.9695	micro: p 0.9728, r 0.9728, f1 0.9728	weighted_f1:0.9728
dev	acc: 0.5239	macro: p 0.3515, r 0.3007, f1: 0.3031	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4792
test	acc: 0.5728	macro: p 0.3497, r 0.3081, f1: 0.3119	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5353
global_step: 31761, epoch: 195, loss: 0.130752
global_step: 31762, epoch: 195, loss: 0.213029
global_step: 31763, epoch: 195, loss: 0.177722
global_step: 31764, epoch: 195, loss: 0.190928
global_step: 31765, epoch: 195, loss: 0.163887
global_step: 31766, epoch: 195, loss: 0.135940
global_step: 31767, epoch: 195, loss: 0.179825
global_step: 31768, epoch: 195, loss: 0.204195
global_step: 31769, epoch: 195, loss: 0.200822
global_step: 31770, epoch: 195, loss: 0.176431
global_step: 31771, epoch: 195, loss: 0.141274
global_step: 31772, epoch: 195, loss: 0.139356
global_step: 31773, epoch: 195, loss: 0.157578
global_step: 31774, epoch: 195, loss: 0.182978
global_step: 31775, epoch: 195, loss: 0.188508
global_step: 31776, epoch: 195, loss: 0.153123
global_step: 31777, epoch: 195, loss: 0.217364
global_step: 31778, epoch: 195, loss: 0.107897
global_step: 31779, epoch: 195, loss: 0.104843
global_step: 31780, epoch: 195, loss: 0.145666
global_step: 31781, epoch: 195, loss: 0.170861
global_step: 31782, epoch: 195, loss: 0.232792
global_step: 31783, epoch: 195, loss: 0.140509
global_step: 31784, epoch: 195, loss: 0.158259
global_step: 31785, epoch: 195, loss: 0.236655
global_step: 31786, epoch: 195, loss: 0.147515
global_step: 31787, epoch: 195, loss: 0.161471
global_step: 31788, epoch: 195, loss: 0.218727
global_step: 31789, epoch: 195, loss: 0.211106
global_step: 31790, epoch: 195, loss: 0.185531
global_step: 31791, epoch: 195, loss: 0.129538
global_step: 31792, epoch: 195, loss: 0.210977
global_step: 31793, epoch: 195, loss: 0.217406
global_step: 31794, epoch: 195, loss: 0.175194
global_step: 31795, epoch: 195, loss: 0.133916
global_step: 31796, epoch: 195, loss: 0.129582
global_step: 31797, epoch: 195, loss: 0.131288
global_step: 31798, epoch: 195, loss: 0.178230
global_step: 31799, epoch: 195, loss: 0.159168
global_step: 31800, epoch: 195, loss: 0.560606
epoch: 195
train	acc: 0.9723	macro: p 0.9757, r 0.9627, f1: 0.9690	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5185	macro: p 0.3496, r 0.3022, f1: 0.3046	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4785
test	acc: 0.5686	macro: p 0.3498, r 0.3070, f1: 0.3124	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5338
global_step: 31801, epoch: 196, loss: 0.163990
global_step: 31802, epoch: 196, loss: 0.172355
global_step: 31803, epoch: 196, loss: 0.207399
global_step: 31804, epoch: 196, loss: 0.203301
global_step: 31805, epoch: 196, loss: 0.215874
global_step: 31806, epoch: 196, loss: 0.204108
global_step: 31807, epoch: 196, loss: 0.148277
global_step: 31808, epoch: 196, loss: 0.167643
global_step: 31809, epoch: 196, loss: 0.167626
global_step: 31810, epoch: 196, loss: 0.149132
global_step: 31811, epoch: 196, loss: 0.225873
global_step: 31812, epoch: 196, loss: 0.163507
global_step: 31813, epoch: 196, loss: 0.172841
global_step: 31814, epoch: 196, loss: 0.163234
global_step: 31815, epoch: 196, loss: 0.164964
global_step: 31816, epoch: 196, loss: 0.162625
global_step: 31817, epoch: 196, loss: 0.174417
global_step: 31818, epoch: 196, loss: 0.145736
global_step: 31819, epoch: 196, loss: 0.183535
global_step: 31820, epoch: 196, loss: 0.200671
global_step: 31821, epoch: 196, loss: 0.132451
global_step: 31822, epoch: 196, loss: 0.165610
global_step: 31823, epoch: 196, loss: 0.174521
global_step: 31824, epoch: 196, loss: 0.169548
global_step: 31825, epoch: 196, loss: 0.207866
global_step: 31826, epoch: 196, loss: 0.237072
global_step: 31827, epoch: 196, loss: 0.155503
global_step: 31828, epoch: 196, loss: 0.181527
global_step: 31829, epoch: 196, loss: 0.164075
global_step: 31830, epoch: 196, loss: 0.209614
global_step: 31831, epoch: 196, loss: 0.157512
global_step: 31832, epoch: 196, loss: 0.148377
global_step: 31833, epoch: 196, loss: 0.148819
global_step: 31834, epoch: 196, loss: 0.166864
global_step: 31835, epoch: 196, loss: 0.191711
global_step: 31836, epoch: 196, loss: 0.140096
global_step: 31837, epoch: 196, loss: 0.176060
global_step: 31838, epoch: 196, loss: 0.141260
global_step: 31839, epoch: 196, loss: 0.199756
global_step: 31840, epoch: 196, loss: 0.059750
epoch: 196
train	acc: 0.9730	macro: p 0.9763, r 0.9645, f1: 0.9702	micro: p 0.9730, r 0.9730, f1 0.9730	weighted_f1:0.9730
dev	acc: 0.5212	macro: p 0.3524, r 0.3087, f1: 0.3113	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4823
test	acc: 0.5739	macro: p 0.3614, r 0.3138, f1: 0.3200	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5396
global_step: 31841, epoch: 197, loss: 0.202591
global_step: 31842, epoch: 197, loss: 0.142287
global_step: 31843, epoch: 197, loss: 0.161832
global_step: 31844, epoch: 197, loss: 0.232858
global_step: 31845, epoch: 197, loss: 0.176035
global_step: 31846, epoch: 197, loss: 0.157907
global_step: 31847, epoch: 197, loss: 0.117877
global_step: 31848, epoch: 197, loss: 0.136824
global_step: 31849, epoch: 197, loss: 0.180633
global_step: 31850, epoch: 197, loss: 0.218029
global_step: 31851, epoch: 197, loss: 0.229303
global_step: 31852, epoch: 197, loss: 0.160285
global_step: 31853, epoch: 197, loss: 0.148897
global_step: 31854, epoch: 197, loss: 0.136343
global_step: 31855, epoch: 197, loss: 0.220234
global_step: 31856, epoch: 197, loss: 0.172817
global_step: 31857, epoch: 197, loss: 0.180369
global_step: 31858, epoch: 197, loss: 0.173780
global_step: 31859, epoch: 197, loss: 0.214353
global_step: 31860, epoch: 197, loss: 0.191916
global_step: 31861, epoch: 197, loss: 0.183500
global_step: 31862, epoch: 197, loss: 0.167855
global_step: 31863, epoch: 197, loss: 0.193182
global_step: 31864, epoch: 197, loss: 0.159721
global_step: 31865, epoch: 197, loss: 0.174295
global_step: 31866, epoch: 197, loss: 0.145016
global_step: 31867, epoch: 197, loss: 0.162766
global_step: 31868, epoch: 197, loss: 0.157509
global_step: 31869, epoch: 197, loss: 0.176959
global_step: 31870, epoch: 197, loss: 0.215088
global_step: 31871, epoch: 197, loss: 0.158311
global_step: 31872, epoch: 197, loss: 0.193334
global_step: 31873, epoch: 197, loss: 0.143640
global_step: 31874, epoch: 197, loss: 0.134167
global_step: 31875, epoch: 197, loss: 0.225393
global_step: 31876, epoch: 197, loss: 0.152329
global_step: 31877, epoch: 197, loss: 0.189438
global_step: 31878, epoch: 197, loss: 0.131711
global_step: 31879, epoch: 197, loss: 0.158678
global_step: 31880, epoch: 197, loss: 0.100278
epoch: 197
train	acc: 0.9725	macro: p 0.9754, r 0.9643, f1: 0.9697	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5167	macro: p 0.3560, r 0.3086, f1: 0.3110	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4801
test	acc: 0.5655	macro: p 0.3577, r 0.3141, f1: 0.3193	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5348
global_step: 31881, epoch: 198, loss: 0.166768
global_step: 31882, epoch: 198, loss: 0.114631
global_step: 31883, epoch: 198, loss: 0.191606
global_step: 31884, epoch: 198, loss: 0.176487
global_step: 31885, epoch: 198, loss: 0.299014
global_step: 31886, epoch: 198, loss: 0.216201
global_step: 31887, epoch: 198, loss: 0.212998
global_step: 31888, epoch: 198, loss: 0.193990
global_step: 31889, epoch: 198, loss: 0.127408
global_step: 31890, epoch: 198, loss: 0.214488
global_step: 31891, epoch: 198, loss: 0.174447
global_step: 31892, epoch: 198, loss: 0.190968
global_step: 31893, epoch: 198, loss: 0.193289
global_step: 31894, epoch: 198, loss: 0.237321
global_step: 31895, epoch: 198, loss: 0.131635
global_step: 31896, epoch: 198, loss: 0.173966
global_step: 31897, epoch: 198, loss: 0.221366
global_step: 31898, epoch: 198, loss: 0.101797
global_step: 31899, epoch: 198, loss: 0.221513
global_step: 31900, epoch: 198, loss: 0.150086
global_step: 31901, epoch: 198, loss: 0.128040
global_step: 31902, epoch: 198, loss: 0.141732
global_step: 31903, epoch: 198, loss: 0.166324
global_step: 31904, epoch: 198, loss: 0.205665
global_step: 31905, epoch: 198, loss: 0.146434
global_step: 31906, epoch: 198, loss: 0.150273
global_step: 31907, epoch: 198, loss: 0.116831
global_step: 31908, epoch: 198, loss: 0.190280
global_step: 31909, epoch: 198, loss: 0.194569
global_step: 31910, epoch: 198, loss: 0.134691
global_step: 31911, epoch: 198, loss: 0.165360
global_step: 31912, epoch: 198, loss: 0.170103
global_step: 31913, epoch: 198, loss: 0.227757
global_step: 31914, epoch: 198, loss: 0.126557
global_step: 31915, epoch: 198, loss: 0.270121
global_step: 31916, epoch: 198, loss: 0.220018
global_step: 31917, epoch: 198, loss: 0.205425
global_step: 31918, epoch: 198, loss: 0.126056
global_step: 31919, epoch: 198, loss: 0.180572
global_step: 31920, epoch: 198, loss: 0.108465
epoch: 198
train	acc: 0.9722	macro: p 0.9765, r 0.9626, f1: 0.9693	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5230	macro: p 0.3681, r 0.3051, f1: 0.3073	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4796
test	acc: 0.5736	macro: p 0.3639, r 0.3126, f1: 0.3185	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5379
global_step: 31921, epoch: 199, loss: 0.159064
global_step: 31922, epoch: 199, loss: 0.213898
global_step: 31923, epoch: 199, loss: 0.147335
global_step: 31924, epoch: 199, loss: 0.191445
global_step: 31925, epoch: 199, loss: 0.184250
global_step: 31926, epoch: 199, loss: 0.215627
global_step: 31927, epoch: 199, loss: 0.230183
global_step: 31928, epoch: 199, loss: 0.175373
global_step: 31929, epoch: 199, loss: 0.115188
global_step: 31930, epoch: 199, loss: 0.151083
global_step: 31931, epoch: 199, loss: 0.163277
global_step: 31932, epoch: 199, loss: 0.229765
global_step: 31933, epoch: 199, loss: 0.109310
global_step: 31934, epoch: 199, loss: 0.174754
global_step: 31935, epoch: 199, loss: 0.161185
global_step: 31936, epoch: 199, loss: 0.206860
global_step: 31937, epoch: 199, loss: 0.188883
global_step: 31938, epoch: 199, loss: 0.249757
global_step: 31939, epoch: 199, loss: 0.181966
global_step: 31940, epoch: 199, loss: 0.167036
global_step: 31941, epoch: 199, loss: 0.187331
global_step: 31942, epoch: 199, loss: 0.126519
global_step: 31943, epoch: 199, loss: 0.183095
global_step: 31944, epoch: 199, loss: 0.132906
global_step: 31945, epoch: 199, loss: 0.147307
global_step: 31946, epoch: 199, loss: 0.150317
global_step: 31947, epoch: 199, loss: 0.137162
global_step: 31948, epoch: 199, loss: 0.157407
global_step: 31949, epoch: 199, loss: 0.162441
global_step: 31950, epoch: 199, loss: 0.223835
global_step: 31951, epoch: 199, loss: 0.155608
global_step: 31952, epoch: 199, loss: 0.207281
global_step: 31953, epoch: 199, loss: 0.147090
global_step: 31954, epoch: 199, loss: 0.203843
global_step: 31955, epoch: 199, loss: 0.184240
global_step: 31956, epoch: 199, loss: 0.146073
global_step: 31957, epoch: 199, loss: 0.211764
global_step: 31958, epoch: 199, loss: 0.197475
global_step: 31959, epoch: 199, loss: 0.167628
global_step: 31960, epoch: 199, loss: 0.013500
epoch: 199
train	acc: 0.9720	macro: p 0.9756, r 0.9628, f1: 0.9690	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5257	macro: p 0.3678, r 0.3083, f1: 0.3131	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4847
test	acc: 0.5747	macro: p 0.3698, r 0.3140, f1: 0.3221	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5387
global_step: 31961, epoch: 200, loss: 0.207583
global_step: 31962, epoch: 200, loss: 0.157530
global_step: 31963, epoch: 200, loss: 0.191439
global_step: 31964, epoch: 200, loss: 0.158445
global_step: 31965, epoch: 200, loss: 0.128666
global_step: 31966, epoch: 200, loss: 0.096071
global_step: 31967, epoch: 200, loss: 0.178892
global_step: 31968, epoch: 200, loss: 0.149846
global_step: 31969, epoch: 200, loss: 0.172141
global_step: 31970, epoch: 200, loss: 0.209187
global_step: 31971, epoch: 200, loss: 0.205347
global_step: 31972, epoch: 200, loss: 0.208966
global_step: 31973, epoch: 200, loss: 0.174544
global_step: 31974, epoch: 200, loss: 0.181713
global_step: 31975, epoch: 200, loss: 0.180127
global_step: 31976, epoch: 200, loss: 0.207456
global_step: 31977, epoch: 200, loss: 0.148953
global_step: 31978, epoch: 200, loss: 0.116807
global_step: 31979, epoch: 200, loss: 0.170540
global_step: 31980, epoch: 200, loss: 0.183740
global_step: 31981, epoch: 200, loss: 0.188179
global_step: 31982, epoch: 200, loss: 0.204766
global_step: 31983, epoch: 200, loss: 0.130884
global_step: 31984, epoch: 200, loss: 0.143521
global_step: 31985, epoch: 200, loss: 0.214073
global_step: 31986, epoch: 200, loss: 0.146388
global_step: 31987, epoch: 200, loss: 0.192311
global_step: 31988, epoch: 200, loss: 0.229836
global_step: 31989, epoch: 200, loss: 0.163193
global_step: 31990, epoch: 200, loss: 0.157820
global_step: 31991, epoch: 200, loss: 0.164329
global_step: 31992, epoch: 200, loss: 0.105228
global_step: 31993, epoch: 200, loss: 0.188201
global_step: 31994, epoch: 200, loss: 0.199002
global_step: 31995, epoch: 200, loss: 0.169470
global_step: 31996, epoch: 200, loss: 0.181363
global_step: 31997, epoch: 200, loss: 0.164877
global_step: 31998, epoch: 200, loss: 0.220033
global_step: 31999, epoch: 200, loss: 0.200047
global_step: 32000, epoch: 200, loss: 0.000785
epoch: 200
train	acc: 0.9722	macro: p 0.9762, r 0.9620, f1: 0.9689	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5221	macro: p 0.3611, r 0.3043, f1: 0.3067	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4792
test	acc: 0.5678	macro: p 0.3547, r 0.3096, f1: 0.3164	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5324
BEST MODEL epoch: 32
train	acc: 0.7962 macro_p: 0.8185 macro_r: 0.5562 macro_f1: 0.5459 micro_p: 0.7962 micro_r: 0.7962 micro_f1: 0.7962 weighted_f1: 0.7740
dev	acc: 0.5401 macro_p: 0.3206 macro_r: 0.3173 macro_f1: 0.3103 micro_p: 0.5401 micro_r: 0.5401 micro_f1: 0.5401 weighted_f1: 0.4999
test	acc: 0.5897 macro_p: 0.3415 macro_r: 0.3346 macro_f1: 0.3329 micro_p: 0.5897 micro_r: 0.5897 micro_f1: 0.5897 weighted_f1: 0.5598
==========ROUND 5==========
global_step: 32001, epoch: 1, loss: 1.990869
global_step: 32002, epoch: 1, loss: 1.970430
global_step: 32003, epoch: 1, loss: 1.922222
global_step: 32004, epoch: 1, loss: 1.875544
global_step: 32005, epoch: 1, loss: 1.849818
global_step: 32006, epoch: 1, loss: 1.811694
global_step: 32007, epoch: 1, loss: 1.775115
global_step: 32008, epoch: 1, loss: 1.728613
global_step: 32009, epoch: 1, loss: 1.700601
global_step: 32010, epoch: 1, loss: 1.674773
global_step: 32011, epoch: 1, loss: 1.674582
global_step: 32012, epoch: 1, loss: 1.609504
global_step: 32013, epoch: 1, loss: 1.600292
global_step: 32014, epoch: 1, loss: 1.552930
global_step: 32015, epoch: 1, loss: 1.609235
global_step: 32016, epoch: 1, loss: 1.636378
global_step: 32017, epoch: 1, loss: 1.640694
global_step: 32018, epoch: 1, loss: 1.599694
global_step: 32019, epoch: 1, loss: 1.545041
global_step: 32020, epoch: 1, loss: 1.496651
global_step: 32021, epoch: 1, loss: 1.501658
global_step: 32022, epoch: 1, loss: 1.489979
global_step: 32023, epoch: 1, loss: 1.478733
global_step: 32024, epoch: 1, loss: 1.524412
global_step: 32025, epoch: 1, loss: 1.557339
global_step: 32026, epoch: 1, loss: 1.542953
global_step: 32027, epoch: 1, loss: 1.558864
global_step: 32028, epoch: 1, loss: 1.393971
global_step: 32029, epoch: 1, loss: 1.509480
global_step: 32030, epoch: 1, loss: 1.454216
global_step: 32031, epoch: 1, loss: 1.544955
global_step: 32032, epoch: 1, loss: 1.461478
global_step: 32033, epoch: 1, loss: 1.525509
global_step: 32034, epoch: 1, loss: 1.519222
global_step: 32035, epoch: 1, loss: 1.603150
global_step: 32036, epoch: 1, loss: 1.489021
global_step: 32037, epoch: 1, loss: 1.510838
global_step: 32038, epoch: 1, loss: 1.505524
global_step: 32039, epoch: 1, loss: 1.529275
global_step: 32040, epoch: 1, loss: 1.040704
epoch: 1
train	acc: 0.5257	macro: p 0.2420, r 0.1971, f1: 0.1711	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4083
dev	acc: 0.4725	macro: p 0.2401, r 0.1968, f1: 0.1608	micro: p 0.4725, r 0.4725, f1 0.4725	weighted_f1:0.3444
test	acc: 0.5307	macro: p 0.2432, r 0.2006, f1: 0.1757	micro: p 0.5307, r 0.5307, f1 0.5307	weighted_f1:0.4118
New best model!
global_step: 32041, epoch: 2, loss: 1.456088
global_step: 32042, epoch: 2, loss: 1.456063
global_step: 32043, epoch: 2, loss: 1.422022
global_step: 32044, epoch: 2, loss: 1.473254
global_step: 32045, epoch: 2, loss: 1.555129
global_step: 32046, epoch: 2, loss: 1.608808
global_step: 32047, epoch: 2, loss: 1.493574
global_step: 32048, epoch: 2, loss: 1.440397
global_step: 32049, epoch: 2, loss: 1.435721
global_step: 32050, epoch: 2, loss: 1.444366
global_step: 32051, epoch: 2, loss: 1.587192
global_step: 32052, epoch: 2, loss: 1.429630
global_step: 32053, epoch: 2, loss: 1.382354
global_step: 32054, epoch: 2, loss: 1.391398
global_step: 32055, epoch: 2, loss: 1.425844
global_step: 32056, epoch: 2, loss: 1.347453
global_step: 32057, epoch: 2, loss: 1.477410
global_step: 32058, epoch: 2, loss: 1.449706
global_step: 32059, epoch: 2, loss: 1.438008
global_step: 32060, epoch: 2, loss: 1.415140
global_step: 32061, epoch: 2, loss: 1.426499
global_step: 32062, epoch: 2, loss: 1.454062
global_step: 32063, epoch: 2, loss: 1.449603
global_step: 32064, epoch: 2, loss: 1.436380
global_step: 32065, epoch: 2, loss: 1.352404
global_step: 32066, epoch: 2, loss: 1.385270
global_step: 32067, epoch: 2, loss: 1.401224
global_step: 32068, epoch: 2, loss: 1.518420
global_step: 32069, epoch: 2, loss: 1.379507
global_step: 32070, epoch: 2, loss: 1.528433
global_step: 32071, epoch: 2, loss: 1.462007
global_step: 32072, epoch: 2, loss: 1.419005
global_step: 32073, epoch: 2, loss: 1.395996
global_step: 32074, epoch: 2, loss: 1.441091
global_step: 32075, epoch: 2, loss: 1.370424
global_step: 32076, epoch: 2, loss: 1.344532
global_step: 32077, epoch: 2, loss: 1.462513
global_step: 32078, epoch: 2, loss: 1.482761
global_step: 32079, epoch: 2, loss: 1.359261
global_step: 32080, epoch: 2, loss: 2.565229
epoch: 2
train	acc: 0.5611	macro: p 0.2990, r 0.2428, f1: 0.2220	micro: p 0.5611, r 0.5611, f1 0.5611	weighted_f1:0.4713
dev	acc: 0.5077	macro: p 0.2433, r 0.2443, f1: 0.2084	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4055
test	acc: 0.5567	macro: p 0.2755, r 0.2439, f1: 0.2176	micro: p 0.5567, r 0.5567, f1 0.5567	weighted_f1:0.4632
New best model!
global_step: 32081, epoch: 3, loss: 1.514730
global_step: 32082, epoch: 3, loss: 1.371193
global_step: 32083, epoch: 3, loss: 1.377596
global_step: 32084, epoch: 3, loss: 1.445988
global_step: 32085, epoch: 3, loss: 1.483987
global_step: 32086, epoch: 3, loss: 1.357351
global_step: 32087, epoch: 3, loss: 1.283319
global_step: 32088, epoch: 3, loss: 1.446033
global_step: 32089, epoch: 3, loss: 1.516243
global_step: 32090, epoch: 3, loss: 1.349528
global_step: 32091, epoch: 3, loss: 1.431394
global_step: 32092, epoch: 3, loss: 1.378804
global_step: 32093, epoch: 3, loss: 1.312652
global_step: 32094, epoch: 3, loss: 1.329202
global_step: 32095, epoch: 3, loss: 1.325593
global_step: 32096, epoch: 3, loss: 1.464387
global_step: 32097, epoch: 3, loss: 1.302693
global_step: 32098, epoch: 3, loss: 1.414703
global_step: 32099, epoch: 3, loss: 1.418817
global_step: 32100, epoch: 3, loss: 1.381673
global_step: 32101, epoch: 3, loss: 1.283839
global_step: 32102, epoch: 3, loss: 1.427234
global_step: 32103, epoch: 3, loss: 1.388706
global_step: 32104, epoch: 3, loss: 1.365690
global_step: 32105, epoch: 3, loss: 1.429919
global_step: 32106, epoch: 3, loss: 1.495573
global_step: 32107, epoch: 3, loss: 1.401892
global_step: 32108, epoch: 3, loss: 1.361483
global_step: 32109, epoch: 3, loss: 1.351888
global_step: 32110, epoch: 3, loss: 1.379106
global_step: 32111, epoch: 3, loss: 1.411367
global_step: 32112, epoch: 3, loss: 1.386582
global_step: 32113, epoch: 3, loss: 1.504651
global_step: 32114, epoch: 3, loss: 1.389227
global_step: 32115, epoch: 3, loss: 1.337079
global_step: 32116, epoch: 3, loss: 1.279997
global_step: 32117, epoch: 3, loss: 1.360475
global_step: 32118, epoch: 3, loss: 1.392442
global_step: 32119, epoch: 3, loss: 1.315923
global_step: 32120, epoch: 3, loss: 1.259270
epoch: 3
train	acc: 0.5674	macro: p 0.3302, r 0.2524, f1: 0.2294	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.4803
dev	acc: 0.5158	macro: p 0.2077, r 0.2523, f1: 0.2153	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4145
test	acc: 0.5605	macro: p 0.2572, r 0.2509, f1: 0.2213	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.4681
New best model!
global_step: 32121, epoch: 4, loss: 1.450846
global_step: 32122, epoch: 4, loss: 1.329763
global_step: 32123, epoch: 4, loss: 1.283821
global_step: 32124, epoch: 4, loss: 1.368058
global_step: 32125, epoch: 4, loss: 1.301128
global_step: 32126, epoch: 4, loss: 1.319629
global_step: 32127, epoch: 4, loss: 1.442871
global_step: 32128, epoch: 4, loss: 1.386760
global_step: 32129, epoch: 4, loss: 1.299995
global_step: 32130, epoch: 4, loss: 1.306014
global_step: 32131, epoch: 4, loss: 1.384698
global_step: 32132, epoch: 4, loss: 1.346352
global_step: 32133, epoch: 4, loss: 1.371818
global_step: 32134, epoch: 4, loss: 1.403938
global_step: 32135, epoch: 4, loss: 1.325034
global_step: 32136, epoch: 4, loss: 1.312535
global_step: 32137, epoch: 4, loss: 1.347341
global_step: 32138, epoch: 4, loss: 1.324963
global_step: 32139, epoch: 4, loss: 1.406930
global_step: 32140, epoch: 4, loss: 1.293185
global_step: 32141, epoch: 4, loss: 1.354211
global_step: 32142, epoch: 4, loss: 1.266244
global_step: 32143, epoch: 4, loss: 1.355235
global_step: 32144, epoch: 4, loss: 1.326057
global_step: 32145, epoch: 4, loss: 1.303351
global_step: 32146, epoch: 4, loss: 1.369679
global_step: 32147, epoch: 4, loss: 1.328362
global_step: 32148, epoch: 4, loss: 1.381640
global_step: 32149, epoch: 4, loss: 1.334297
global_step: 32150, epoch: 4, loss: 1.433644
global_step: 32151, epoch: 4, loss: 1.416869
global_step: 32152, epoch: 4, loss: 1.308317
global_step: 32153, epoch: 4, loss: 1.393093
global_step: 32154, epoch: 4, loss: 1.313260
global_step: 32155, epoch: 4, loss: 1.423047
global_step: 32156, epoch: 4, loss: 1.415019
global_step: 32157, epoch: 4, loss: 1.322489
global_step: 32158, epoch: 4, loss: 1.467128
global_step: 32159, epoch: 4, loss: 1.332248
global_step: 32160, epoch: 4, loss: 0.597865
epoch: 4
train	acc: 0.5762	macro: p 0.3102, r 0.2627, f1: 0.2498	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.4976
dev	acc: 0.5284	macro: p 0.2973, r 0.2652, f1: 0.2379	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4370
test	acc: 0.5682	macro: p 0.2765, r 0.2587, f1: 0.2377	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.4839
New best model!
global_step: 32161, epoch: 5, loss: 1.369149
global_step: 32162, epoch: 5, loss: 1.334429
global_step: 32163, epoch: 5, loss: 1.237007
global_step: 32164, epoch: 5, loss: 1.388754
global_step: 32165, epoch: 5, loss: 1.335117
global_step: 32166, epoch: 5, loss: 1.223378
global_step: 32167, epoch: 5, loss: 1.271446
global_step: 32168, epoch: 5, loss: 1.419015
global_step: 32169, epoch: 5, loss: 1.277403
global_step: 32170, epoch: 5, loss: 1.232763
global_step: 32171, epoch: 5, loss: 1.355893
global_step: 32172, epoch: 5, loss: 1.472669
global_step: 32173, epoch: 5, loss: 1.285810
global_step: 32174, epoch: 5, loss: 1.367708
global_step: 32175, epoch: 5, loss: 1.392083
global_step: 32176, epoch: 5, loss: 1.299925
global_step: 32177, epoch: 5, loss: 1.422746
global_step: 32178, epoch: 5, loss: 1.241793
global_step: 32179, epoch: 5, loss: 1.392287
global_step: 32180, epoch: 5, loss: 1.330528
global_step: 32181, epoch: 5, loss: 1.324639
global_step: 32182, epoch: 5, loss: 1.318255
global_step: 32183, epoch: 5, loss: 1.272947
global_step: 32184, epoch: 5, loss: 1.385967
global_step: 32185, epoch: 5, loss: 1.417442
global_step: 32186, epoch: 5, loss: 1.323058
global_step: 32187, epoch: 5, loss: 1.472345
global_step: 32188, epoch: 5, loss: 1.363860
global_step: 32189, epoch: 5, loss: 1.398804
global_step: 32190, epoch: 5, loss: 1.425187
global_step: 32191, epoch: 5, loss: 1.188429
global_step: 32192, epoch: 5, loss: 1.353695
global_step: 32193, epoch: 5, loss: 1.395713
global_step: 32194, epoch: 5, loss: 1.327617
global_step: 32195, epoch: 5, loss: 1.215564
global_step: 32196, epoch: 5, loss: 1.321551
global_step: 32197, epoch: 5, loss: 1.326953
global_step: 32198, epoch: 5, loss: 1.406438
global_step: 32199, epoch: 5, loss: 1.189198
global_step: 32200, epoch: 5, loss: 1.850944
epoch: 5
train	acc: 0.5911	macro: p 0.4459, r 0.2936, f1: 0.2907	micro: p 0.5911, r 0.5911, f1 0.5911	weighted_f1:0.5314
dev	acc: 0.5392	macro: p 0.2762, r 0.2813, f1: 0.2688	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4678
test	acc: 0.5866	macro: p 0.2894, r 0.2859, f1: 0.2807	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5251
New best model!
global_step: 32201, epoch: 6, loss: 1.283441
global_step: 32202, epoch: 6, loss: 1.312661
global_step: 32203, epoch: 6, loss: 1.362350
global_step: 32204, epoch: 6, loss: 1.461941
global_step: 32205, epoch: 6, loss: 1.244122
global_step: 32206, epoch: 6, loss: 1.240750
global_step: 32207, epoch: 6, loss: 1.261698
global_step: 32208, epoch: 6, loss: 1.368644
global_step: 32209, epoch: 6, loss: 1.275485
global_step: 32210, epoch: 6, loss: 1.240191
global_step: 32211, epoch: 6, loss: 1.291260
global_step: 32212, epoch: 6, loss: 1.336535
global_step: 32213, epoch: 6, loss: 1.328481
global_step: 32214, epoch: 6, loss: 1.302791
global_step: 32215, epoch: 6, loss: 1.237524
global_step: 32216, epoch: 6, loss: 1.316541
global_step: 32217, epoch: 6, loss: 1.460378
global_step: 32218, epoch: 6, loss: 1.346077
global_step: 32219, epoch: 6, loss: 1.316366
global_step: 32220, epoch: 6, loss: 1.277800
global_step: 32221, epoch: 6, loss: 1.299489
global_step: 32222, epoch: 6, loss: 1.308651
global_step: 32223, epoch: 6, loss: 1.297061
global_step: 32224, epoch: 6, loss: 1.410457
global_step: 32225, epoch: 6, loss: 1.341133
global_step: 32226, epoch: 6, loss: 1.411421
global_step: 32227, epoch: 6, loss: 1.269977
global_step: 32228, epoch: 6, loss: 1.301128
global_step: 32229, epoch: 6, loss: 1.368911
global_step: 32230, epoch: 6, loss: 1.273844
global_step: 32231, epoch: 6, loss: 1.298835
global_step: 32232, epoch: 6, loss: 1.155165
global_step: 32233, epoch: 6, loss: 1.328022
global_step: 32234, epoch: 6, loss: 1.312418
global_step: 32235, epoch: 6, loss: 1.326374
global_step: 32236, epoch: 6, loss: 1.252581
global_step: 32237, epoch: 6, loss: 1.304999
global_step: 32238, epoch: 6, loss: 1.371944
global_step: 32239, epoch: 6, loss: 1.431327
global_step: 32240, epoch: 6, loss: 1.770551
epoch: 6
train	acc: 0.5836	macro: p 0.4509, r 0.2799, f1: 0.2650	micro: p 0.5836, r 0.5836, f1 0.5836	weighted_f1:0.5122
dev	acc: 0.5320	macro: p 0.2713, r 0.2755, f1: 0.2427	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4432
test	acc: 0.5697	macro: p 0.2766, r 0.2711, f1: 0.2449	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.4916
global_step: 32241, epoch: 7, loss: 1.148696
global_step: 32242, epoch: 7, loss: 1.327451
global_step: 32243, epoch: 7, loss: 1.290528
global_step: 32244, epoch: 7, loss: 1.207908
global_step: 32245, epoch: 7, loss: 1.328434
global_step: 32246, epoch: 7, loss: 1.390418
global_step: 32247, epoch: 7, loss: 1.289788
global_step: 32248, epoch: 7, loss: 1.423332
global_step: 32249, epoch: 7, loss: 1.250666
global_step: 32250, epoch: 7, loss: 1.401781
global_step: 32251, epoch: 7, loss: 1.355677
global_step: 32252, epoch: 7, loss: 1.272925
global_step: 32253, epoch: 7, loss: 1.309924
global_step: 32254, epoch: 7, loss: 1.263538
global_step: 32255, epoch: 7, loss: 1.264581
global_step: 32256, epoch: 7, loss: 1.434735
global_step: 32257, epoch: 7, loss: 1.173380
global_step: 32258, epoch: 7, loss: 1.314267
global_step: 32259, epoch: 7, loss: 1.332456
global_step: 32260, epoch: 7, loss: 1.244978
global_step: 32261, epoch: 7, loss: 1.335467
global_step: 32262, epoch: 7, loss: 1.261761
global_step: 32263, epoch: 7, loss: 1.273192
global_step: 32264, epoch: 7, loss: 1.353695
global_step: 32265, epoch: 7, loss: 1.177311
global_step: 32266, epoch: 7, loss: 1.288178
global_step: 32267, epoch: 7, loss: 1.286255
global_step: 32268, epoch: 7, loss: 1.402866
global_step: 32269, epoch: 7, loss: 1.271810
global_step: 32270, epoch: 7, loss: 1.284935
global_step: 32271, epoch: 7, loss: 1.340672
global_step: 32272, epoch: 7, loss: 1.239599
global_step: 32273, epoch: 7, loss: 1.291363
global_step: 32274, epoch: 7, loss: 1.314115
global_step: 32275, epoch: 7, loss: 1.328555
global_step: 32276, epoch: 7, loss: 1.178299
global_step: 32277, epoch: 7, loss: 1.321809
global_step: 32278, epoch: 7, loss: 1.282321
global_step: 32279, epoch: 7, loss: 1.281977
global_step: 32280, epoch: 7, loss: 1.823924
epoch: 7
train	acc: 0.5897	macro: p 0.4726, r 0.2767, f1: 0.2700	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5169
dev	acc: 0.5275	macro: p 0.2871, r 0.2653, f1: 0.2391	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4388
test	acc: 0.5797	macro: p 0.3023, r 0.2706, f1: 0.2556	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5019
global_step: 32281, epoch: 8, loss: 1.314409
global_step: 32282, epoch: 8, loss: 1.155461
global_step: 32283, epoch: 8, loss: 1.139238
global_step: 32284, epoch: 8, loss: 1.263816
global_step: 32285, epoch: 8, loss: 1.346351
global_step: 32286, epoch: 8, loss: 1.330548
global_step: 32287, epoch: 8, loss: 1.265292
global_step: 32288, epoch: 8, loss: 1.287332
global_step: 32289, epoch: 8, loss: 1.293232
global_step: 32290, epoch: 8, loss: 1.111419
global_step: 32291, epoch: 8, loss: 1.308355
global_step: 32292, epoch: 8, loss: 1.349468
global_step: 32293, epoch: 8, loss: 1.224962
global_step: 32294, epoch: 8, loss: 1.342940
global_step: 32295, epoch: 8, loss: 1.173217
global_step: 32296, epoch: 8, loss: 1.325674
global_step: 32297, epoch: 8, loss: 1.325148
global_step: 32298, epoch: 8, loss: 1.510721
global_step: 32299, epoch: 8, loss: 1.270215
global_step: 32300, epoch: 8, loss: 1.379709
global_step: 32301, epoch: 8, loss: 1.250975
global_step: 32302, epoch: 8, loss: 1.319332
global_step: 32303, epoch: 8, loss: 1.343757
global_step: 32304, epoch: 8, loss: 1.246025
global_step: 32305, epoch: 8, loss: 1.201508
global_step: 32306, epoch: 8, loss: 1.286540
global_step: 32307, epoch: 8, loss: 1.305537
global_step: 32308, epoch: 8, loss: 1.278591
global_step: 32309, epoch: 8, loss: 1.253457
global_step: 32310, epoch: 8, loss: 1.138709
global_step: 32311, epoch: 8, loss: 1.274002
global_step: 32312, epoch: 8, loss: 1.413574
global_step: 32313, epoch: 8, loss: 1.272414
global_step: 32314, epoch: 8, loss: 1.290904
global_step: 32315, epoch: 8, loss: 1.207341
global_step: 32316, epoch: 8, loss: 1.333426
global_step: 32317, epoch: 8, loss: 1.203306
global_step: 32318, epoch: 8, loss: 1.267591
global_step: 32319, epoch: 8, loss: 1.335211
global_step: 32320, epoch: 8, loss: 1.232803
epoch: 8
train	acc: 0.6056	macro: p 0.4408, r 0.3065, f1: 0.3078	micro: p 0.6056, r 0.6056, f1 0.6056	weighted_f1:0.5480
dev	acc: 0.5455	macro: p 0.4305, r 0.2904, f1: 0.2779	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4768
test	acc: 0.5900	macro: p 0.4185, r 0.2906, f1: 0.2870	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5298
New best model!
global_step: 32321, epoch: 9, loss: 1.235341
global_step: 32322, epoch: 9, loss: 1.291776
global_step: 32323, epoch: 9, loss: 1.223572
global_step: 32324, epoch: 9, loss: 1.349529
global_step: 32325, epoch: 9, loss: 1.174101
global_step: 32326, epoch: 9, loss: 1.226901
global_step: 32327, epoch: 9, loss: 1.248436
global_step: 32328, epoch: 9, loss: 1.350789
global_step: 32329, epoch: 9, loss: 1.243809
global_step: 32330, epoch: 9, loss: 1.251991
global_step: 32331, epoch: 9, loss: 1.266895
global_step: 32332, epoch: 9, loss: 1.206810
global_step: 32333, epoch: 9, loss: 1.244607
global_step: 32334, epoch: 9, loss: 1.166291
global_step: 32335, epoch: 9, loss: 1.253312
global_step: 32336, epoch: 9, loss: 1.379874
global_step: 32337, epoch: 9, loss: 1.294561
global_step: 32338, epoch: 9, loss: 1.285249
global_step: 32339, epoch: 9, loss: 1.255866
global_step: 32340, epoch: 9, loss: 1.279194
global_step: 32341, epoch: 9, loss: 1.258064
global_step: 32342, epoch: 9, loss: 1.332330
global_step: 32343, epoch: 9, loss: 1.239122
global_step: 32344, epoch: 9, loss: 1.244768
global_step: 32345, epoch: 9, loss: 1.274741
global_step: 32346, epoch: 9, loss: 1.280476
global_step: 32347, epoch: 9, loss: 1.188180
global_step: 32348, epoch: 9, loss: 1.210135
global_step: 32349, epoch: 9, loss: 1.323115
global_step: 32350, epoch: 9, loss: 1.239148
global_step: 32351, epoch: 9, loss: 1.248001
global_step: 32352, epoch: 9, loss: 1.253064
global_step: 32353, epoch: 9, loss: 1.167702
global_step: 32354, epoch: 9, loss: 1.321345
global_step: 32355, epoch: 9, loss: 1.495049
global_step: 32356, epoch: 9, loss: 1.345972
global_step: 32357, epoch: 9, loss: 1.287680
global_step: 32358, epoch: 9, loss: 1.308558
global_step: 32359, epoch: 9, loss: 1.275757
global_step: 32360, epoch: 9, loss: 2.342662
epoch: 9
train	acc: 0.6083	macro: p 0.4423, r 0.3081, f1: 0.3120	micro: p 0.6083, r 0.6083, f1 0.6083	weighted_f1:0.5511
dev	acc: 0.5410	macro: p 0.4311, r 0.2846, f1: 0.2677	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4678
test	acc: 0.5904	macro: p 0.4291, r 0.2902, f1: 0.2863	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5289
global_step: 32361, epoch: 10, loss: 1.305520
global_step: 32362, epoch: 10, loss: 1.188664
global_step: 32363, epoch: 10, loss: 1.258460
global_step: 32364, epoch: 10, loss: 1.195415
global_step: 32365, epoch: 10, loss: 1.205518
global_step: 32366, epoch: 10, loss: 1.065148
global_step: 32367, epoch: 10, loss: 1.297965
global_step: 32368, epoch: 10, loss: 1.259329
global_step: 32369, epoch: 10, loss: 1.207222
global_step: 32370, epoch: 10, loss: 1.203964
global_step: 32371, epoch: 10, loss: 1.341617
global_step: 32372, epoch: 10, loss: 1.316919
global_step: 32373, epoch: 10, loss: 1.285608
global_step: 32374, epoch: 10, loss: 1.178885
global_step: 32375, epoch: 10, loss: 1.287658
global_step: 32376, epoch: 10, loss: 1.257509
global_step: 32377, epoch: 10, loss: 1.172178
global_step: 32378, epoch: 10, loss: 1.293691
global_step: 32379, epoch: 10, loss: 1.399167
global_step: 32380, epoch: 10, loss: 1.264552
global_step: 32381, epoch: 10, loss: 1.288691
global_step: 32382, epoch: 10, loss: 1.260299
global_step: 32383, epoch: 10, loss: 1.320295
global_step: 32384, epoch: 10, loss: 1.290953
global_step: 32385, epoch: 10, loss: 1.291885
global_step: 32386, epoch: 10, loss: 1.274708
global_step: 32387, epoch: 10, loss: 1.260514
global_step: 32388, epoch: 10, loss: 1.278720
global_step: 32389, epoch: 10, loss: 1.145812
global_step: 32390, epoch: 10, loss: 1.263273
global_step: 32391, epoch: 10, loss: 1.150860
global_step: 32392, epoch: 10, loss: 1.321584
global_step: 32393, epoch: 10, loss: 1.221234
global_step: 32394, epoch: 10, loss: 1.259854
global_step: 32395, epoch: 10, loss: 1.212582
global_step: 32396, epoch: 10, loss: 1.239747
global_step: 32397, epoch: 10, loss: 1.189825
global_step: 32398, epoch: 10, loss: 1.233579
global_step: 32399, epoch: 10, loss: 1.266331
global_step: 32400, epoch: 10, loss: 1.570047
epoch: 10
train	acc: 0.6137	macro: p 0.4370, r 0.3193, f1: 0.3274	micro: p 0.6137, r 0.6137, f1 0.6137	weighted_f1:0.5611
dev	acc: 0.5555	macro: p 0.4366, r 0.2979, f1: 0.2914	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4896
test	acc: 0.5946	macro: p 0.4016, r 0.2953, f1: 0.2972	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5375
New best model!
global_step: 32401, epoch: 11, loss: 1.151949
global_step: 32402, epoch: 11, loss: 1.276343
global_step: 32403, epoch: 11, loss: 1.134628
global_step: 32404, epoch: 11, loss: 1.316250
global_step: 32405, epoch: 11, loss: 1.272011
global_step: 32406, epoch: 11, loss: 1.231078
global_step: 32407, epoch: 11, loss: 1.176805
global_step: 32408, epoch: 11, loss: 1.299813
global_step: 32409, epoch: 11, loss: 1.223920
global_step: 32410, epoch: 11, loss: 1.346674
global_step: 32411, epoch: 11, loss: 1.301260
global_step: 32412, epoch: 11, loss: 1.151518
global_step: 32413, epoch: 11, loss: 1.226705
global_step: 32414, epoch: 11, loss: 1.247716
global_step: 32415, epoch: 11, loss: 1.134145
global_step: 32416, epoch: 11, loss: 1.184898
global_step: 32417, epoch: 11, loss: 1.325572
global_step: 32418, epoch: 11, loss: 1.214277
global_step: 32419, epoch: 11, loss: 1.177776
global_step: 32420, epoch: 11, loss: 1.171910
global_step: 32421, epoch: 11, loss: 1.340901
global_step: 32422, epoch: 11, loss: 1.218836
global_step: 32423, epoch: 11, loss: 1.250790
global_step: 32424, epoch: 11, loss: 1.246281
global_step: 32425, epoch: 11, loss: 1.225929
global_step: 32426, epoch: 11, loss: 1.294739
global_step: 32427, epoch: 11, loss: 1.282156
global_step: 32428, epoch: 11, loss: 1.214643
global_step: 32429, epoch: 11, loss: 1.175568
global_step: 32430, epoch: 11, loss: 1.226907
global_step: 32431, epoch: 11, loss: 1.237390
global_step: 32432, epoch: 11, loss: 1.161288
global_step: 32433, epoch: 11, loss: 1.265076
global_step: 32434, epoch: 11, loss: 1.270695
global_step: 32435, epoch: 11, loss: 1.320284
global_step: 32436, epoch: 11, loss: 1.223422
global_step: 32437, epoch: 11, loss: 1.221626
global_step: 32438, epoch: 11, loss: 1.228242
global_step: 32439, epoch: 11, loss: 1.309971
global_step: 32440, epoch: 11, loss: 1.315909
epoch: 11
train	acc: 0.6164	macro: p 0.4277, r 0.3229, f1: 0.3263	micro: p 0.6164, r 0.6164, f1 0.6164	weighted_f1:0.5631
dev	acc: 0.5437	macro: p 0.3419, r 0.2916, f1: 0.2705	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4712
test	acc: 0.5843	macro: p 0.3761, r 0.2933, f1: 0.2841	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5237
global_step: 32441, epoch: 12, loss: 1.198269
global_step: 32442, epoch: 12, loss: 1.259582
global_step: 32443, epoch: 12, loss: 1.117014
global_step: 32444, epoch: 12, loss: 1.172105
global_step: 32445, epoch: 12, loss: 1.338245
global_step: 32446, epoch: 12, loss: 1.234793
global_step: 32447, epoch: 12, loss: 1.216738
global_step: 32448, epoch: 12, loss: 1.246722
global_step: 32449, epoch: 12, loss: 1.264428
global_step: 32450, epoch: 12, loss: 1.171139
global_step: 32451, epoch: 12, loss: 1.178985
global_step: 32452, epoch: 12, loss: 1.258531
global_step: 32453, epoch: 12, loss: 1.182947
global_step: 32454, epoch: 12, loss: 1.228442
global_step: 32455, epoch: 12, loss: 1.162905
global_step: 32456, epoch: 12, loss: 1.216592
global_step: 32457, epoch: 12, loss: 1.171751
global_step: 32458, epoch: 12, loss: 1.257971
global_step: 32459, epoch: 12, loss: 1.357791
global_step: 32460, epoch: 12, loss: 1.324216
global_step: 32461, epoch: 12, loss: 1.252302
global_step: 32462, epoch: 12, loss: 1.291274
global_step: 32463, epoch: 12, loss: 1.253508
global_step: 32464, epoch: 12, loss: 1.186666
global_step: 32465, epoch: 12, loss: 1.227555
global_step: 32466, epoch: 12, loss: 1.179801
global_step: 32467, epoch: 12, loss: 1.254910
global_step: 32468, epoch: 12, loss: 1.204867
global_step: 32469, epoch: 12, loss: 1.202130
global_step: 32470, epoch: 12, loss: 1.206886
global_step: 32471, epoch: 12, loss: 1.132048
global_step: 32472, epoch: 12, loss: 1.223352
global_step: 32473, epoch: 12, loss: 1.186109
global_step: 32474, epoch: 12, loss: 1.219413
global_step: 32475, epoch: 12, loss: 1.269621
global_step: 32476, epoch: 12, loss: 1.266599
global_step: 32477, epoch: 12, loss: 1.052753
global_step: 32478, epoch: 12, loss: 1.201615
global_step: 32479, epoch: 12, loss: 1.235254
global_step: 32480, epoch: 12, loss: 1.029457
epoch: 12
train	acc: 0.6115	macro: p 0.4418, r 0.3104, f1: 0.3150	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5534
dev	acc: 0.5392	macro: p 0.3611, r 0.2822, f1: 0.2604	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4612
test	acc: 0.5858	macro: p 0.3879, r 0.2861, f1: 0.2771	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5187
global_step: 32481, epoch: 13, loss: 1.215532
global_step: 32482, epoch: 13, loss: 1.077316
global_step: 32483, epoch: 13, loss: 1.165587
global_step: 32484, epoch: 13, loss: 1.200613
global_step: 32485, epoch: 13, loss: 1.271961
global_step: 32486, epoch: 13, loss: 1.125235
global_step: 32487, epoch: 13, loss: 1.233641
global_step: 32488, epoch: 13, loss: 1.169813
global_step: 32489, epoch: 13, loss: 1.345868
global_step: 32490, epoch: 13, loss: 1.110906
global_step: 32491, epoch: 13, loss: 1.156295
global_step: 32492, epoch: 13, loss: 1.182019
global_step: 32493, epoch: 13, loss: 1.168423
global_step: 32494, epoch: 13, loss: 1.272589
global_step: 32495, epoch: 13, loss: 1.167153
global_step: 32496, epoch: 13, loss: 1.282920
global_step: 32497, epoch: 13, loss: 1.124466
global_step: 32498, epoch: 13, loss: 1.216639
global_step: 32499, epoch: 13, loss: 1.233191
global_step: 32500, epoch: 13, loss: 1.213208
global_step: 32501, epoch: 13, loss: 1.288987
global_step: 32502, epoch: 13, loss: 1.177672
global_step: 32503, epoch: 13, loss: 1.173053
global_step: 32504, epoch: 13, loss: 1.256596
global_step: 32505, epoch: 13, loss: 1.335357
global_step: 32506, epoch: 13, loss: 1.177220
global_step: 32507, epoch: 13, loss: 1.256148
global_step: 32508, epoch: 13, loss: 1.150404
global_step: 32509, epoch: 13, loss: 1.217173
global_step: 32510, epoch: 13, loss: 1.190670
global_step: 32511, epoch: 13, loss: 1.247436
global_step: 32512, epoch: 13, loss: 1.209546
global_step: 32513, epoch: 13, loss: 1.216133
global_step: 32514, epoch: 13, loss: 1.142552
global_step: 32515, epoch: 13, loss: 1.248262
global_step: 32516, epoch: 13, loss: 1.273291
global_step: 32517, epoch: 13, loss: 1.213895
global_step: 32518, epoch: 13, loss: 1.144369
global_step: 32519, epoch: 13, loss: 1.222106
global_step: 32520, epoch: 13, loss: 1.608871
epoch: 13
train	acc: 0.6211	macro: p 0.4419, r 0.3270, f1: 0.3360	micro: p 0.6211, r 0.6211, f1 0.6211	weighted_f1:0.5693
dev	acc: 0.5518	macro: p 0.3757, r 0.2951, f1: 0.2901	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4874
test	acc: 0.5992	macro: p 0.4035, r 0.2998, f1: 0.3039	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5428
global_step: 32521, epoch: 14, loss: 1.207884
global_step: 32522, epoch: 14, loss: 1.161881
global_step: 32523, epoch: 14, loss: 1.211706
global_step: 32524, epoch: 14, loss: 1.232758
global_step: 32525, epoch: 14, loss: 1.270875
global_step: 32526, epoch: 14, loss: 1.074021
global_step: 32527, epoch: 14, loss: 1.159700
global_step: 32528, epoch: 14, loss: 1.155960
global_step: 32529, epoch: 14, loss: 1.251472
global_step: 32530, epoch: 14, loss: 1.231933
global_step: 32531, epoch: 14, loss: 1.215430
global_step: 32532, epoch: 14, loss: 1.204196
global_step: 32533, epoch: 14, loss: 1.086187
global_step: 32534, epoch: 14, loss: 1.102697
global_step: 32535, epoch: 14, loss: 1.191363
global_step: 32536, epoch: 14, loss: 1.125110
global_step: 32537, epoch: 14, loss: 1.151285
global_step: 32538, epoch: 14, loss: 1.127971
global_step: 32539, epoch: 14, loss: 1.235717
global_step: 32540, epoch: 14, loss: 1.248850
global_step: 32541, epoch: 14, loss: 1.239709
global_step: 32542, epoch: 14, loss: 1.114265
global_step: 32543, epoch: 14, loss: 1.166968
global_step: 32544, epoch: 14, loss: 1.275791
global_step: 32545, epoch: 14, loss: 1.180623
global_step: 32546, epoch: 14, loss: 1.181519
global_step: 32547, epoch: 14, loss: 1.153363
global_step: 32548, epoch: 14, loss: 1.187671
global_step: 32549, epoch: 14, loss: 1.302971
global_step: 32550, epoch: 14, loss: 1.118993
global_step: 32551, epoch: 14, loss: 1.122772
global_step: 32552, epoch: 14, loss: 1.178850
global_step: 32553, epoch: 14, loss: 1.431718
global_step: 32554, epoch: 14, loss: 1.137977
global_step: 32555, epoch: 14, loss: 1.226253
global_step: 32556, epoch: 14, loss: 1.213113
global_step: 32557, epoch: 14, loss: 1.187158
global_step: 32558, epoch: 14, loss: 1.214582
global_step: 32559, epoch: 14, loss: 1.195585
global_step: 32560, epoch: 14, loss: 1.219782
epoch: 14
train	acc: 0.6316	macro: p 0.4327, r 0.3402, f1: 0.3492	micro: p 0.6316, r 0.6316, f1 0.6316	weighted_f1:0.5846
dev	acc: 0.5410	macro: p 0.3486, r 0.2910, f1: 0.2767	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4767
test	acc: 0.5885	macro: p 0.3658, r 0.2985, f1: 0.2943	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5335
global_step: 32561, epoch: 15, loss: 1.087448
global_step: 32562, epoch: 15, loss: 1.169626
global_step: 32563, epoch: 15, loss: 1.246134
global_step: 32564, epoch: 15, loss: 1.134472
global_step: 32565, epoch: 15, loss: 1.155079
global_step: 32566, epoch: 15, loss: 1.156364
global_step: 32567, epoch: 15, loss: 1.148847
global_step: 32568, epoch: 15, loss: 1.202138
global_step: 32569, epoch: 15, loss: 1.096279
global_step: 32570, epoch: 15, loss: 1.315030
global_step: 32571, epoch: 15, loss: 1.200450
global_step: 32572, epoch: 15, loss: 1.276281
global_step: 32573, epoch: 15, loss: 1.129501
global_step: 32574, epoch: 15, loss: 1.283465
global_step: 32575, epoch: 15, loss: 1.201134
global_step: 32576, epoch: 15, loss: 1.055209
global_step: 32577, epoch: 15, loss: 1.137368
global_step: 32578, epoch: 15, loss: 1.169599
global_step: 32579, epoch: 15, loss: 1.074442
global_step: 32580, epoch: 15, loss: 1.074455
global_step: 32581, epoch: 15, loss: 1.180815
global_step: 32582, epoch: 15, loss: 1.215778
global_step: 32583, epoch: 15, loss: 1.087243
global_step: 32584, epoch: 15, loss: 1.098400
global_step: 32585, epoch: 15, loss: 1.231428
global_step: 32586, epoch: 15, loss: 1.236344
global_step: 32587, epoch: 15, loss: 1.202688
global_step: 32588, epoch: 15, loss: 1.305912
global_step: 32589, epoch: 15, loss: 1.144425
global_step: 32590, epoch: 15, loss: 1.313959
global_step: 32591, epoch: 15, loss: 1.213167
global_step: 32592, epoch: 15, loss: 1.270797
global_step: 32593, epoch: 15, loss: 1.195737
global_step: 32594, epoch: 15, loss: 1.068671
global_step: 32595, epoch: 15, loss: 1.242873
global_step: 32596, epoch: 15, loss: 1.113119
global_step: 32597, epoch: 15, loss: 1.325987
global_step: 32598, epoch: 15, loss: 1.218761
global_step: 32599, epoch: 15, loss: 1.187446
global_step: 32600, epoch: 15, loss: 1.186525
epoch: 15
train	acc: 0.6416	macro: p 0.4397, r 0.3500, f1: 0.3589	micro: p 0.6416, r 0.6416, f1 0.6416	weighted_f1:0.5939
dev	acc: 0.5564	macro: p 0.3517, r 0.3012, f1: 0.2878	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4889
test	acc: 0.6000	macro: p 0.3885, r 0.3067, f1: 0.3064	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5450
global_step: 32601, epoch: 16, loss: 1.165890
global_step: 32602, epoch: 16, loss: 1.214554
global_step: 32603, epoch: 16, loss: 1.077259
global_step: 32604, epoch: 16, loss: 1.189796
global_step: 32605, epoch: 16, loss: 1.152577
global_step: 32606, epoch: 16, loss: 1.046169
global_step: 32607, epoch: 16, loss: 1.159258
global_step: 32608, epoch: 16, loss: 1.291167
global_step: 32609, epoch: 16, loss: 1.193208
global_step: 32610, epoch: 16, loss: 1.106039
global_step: 32611, epoch: 16, loss: 1.028416
global_step: 32612, epoch: 16, loss: 1.185830
global_step: 32613, epoch: 16, loss: 1.274242
global_step: 32614, epoch: 16, loss: 1.299581
global_step: 32615, epoch: 16, loss: 1.221864
global_step: 32616, epoch: 16, loss: 1.242821
global_step: 32617, epoch: 16, loss: 1.102488
global_step: 32618, epoch: 16, loss: 1.158242
global_step: 32619, epoch: 16, loss: 1.114967
global_step: 32620, epoch: 16, loss: 1.193978
global_step: 32621, epoch: 16, loss: 1.140003
global_step: 32622, epoch: 16, loss: 1.250530
global_step: 32623, epoch: 16, loss: 1.061641
global_step: 32624, epoch: 16, loss: 1.237754
global_step: 32625, epoch: 16, loss: 1.228318
global_step: 32626, epoch: 16, loss: 1.133372
global_step: 32627, epoch: 16, loss: 1.219943
global_step: 32628, epoch: 16, loss: 1.110070
global_step: 32629, epoch: 16, loss: 1.112350
global_step: 32630, epoch: 16, loss: 1.093165
global_step: 32631, epoch: 16, loss: 1.267232
global_step: 32632, epoch: 16, loss: 1.190103
global_step: 32633, epoch: 16, loss: 1.076895
global_step: 32634, epoch: 16, loss: 1.044690
global_step: 32635, epoch: 16, loss: 1.200236
global_step: 32636, epoch: 16, loss: 1.159981
global_step: 32637, epoch: 16, loss: 1.133287
global_step: 32638, epoch: 16, loss: 1.182189
global_step: 32639, epoch: 16, loss: 1.130937
global_step: 32640, epoch: 16, loss: 0.569177
epoch: 16
train	acc: 0.6339	macro: p 0.4573, r 0.3377, f1: 0.3484	micro: p 0.6339, r 0.6339, f1 0.6339	weighted_f1:0.5833
dev	acc: 0.5464	macro: p 0.3676, r 0.2893, f1: 0.2760	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4756
test	acc: 0.5946	macro: p 0.3822, r 0.2966, f1: 0.2959	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5362
global_step: 32641, epoch: 17, loss: 1.041603
global_step: 32642, epoch: 17, loss: 1.326847
global_step: 32643, epoch: 17, loss: 1.086460
global_step: 32644, epoch: 17, loss: 1.009526
global_step: 32645, epoch: 17, loss: 1.044297
global_step: 32646, epoch: 17, loss: 1.170069
global_step: 32647, epoch: 17, loss: 1.126203
global_step: 32648, epoch: 17, loss: 1.058251
global_step: 32649, epoch: 17, loss: 1.213826
global_step: 32650, epoch: 17, loss: 1.076049
global_step: 32651, epoch: 17, loss: 1.097854
global_step: 32652, epoch: 17, loss: 1.087570
global_step: 32653, epoch: 17, loss: 1.013870
global_step: 32654, epoch: 17, loss: 1.057140
global_step: 32655, epoch: 17, loss: 1.195109
global_step: 32656, epoch: 17, loss: 1.182189
global_step: 32657, epoch: 17, loss: 1.219537
global_step: 32658, epoch: 17, loss: 1.176517
global_step: 32659, epoch: 17, loss: 1.136370
global_step: 32660, epoch: 17, loss: 1.243897
global_step: 32661, epoch: 17, loss: 1.184631
global_step: 32662, epoch: 17, loss: 1.185307
global_step: 32663, epoch: 17, loss: 1.249535
global_step: 32664, epoch: 17, loss: 1.043944
global_step: 32665, epoch: 17, loss: 1.140255
global_step: 32666, epoch: 17, loss: 1.251322
global_step: 32667, epoch: 17, loss: 1.178822
global_step: 32668, epoch: 17, loss: 1.144740
global_step: 32669, epoch: 17, loss: 1.170847
global_step: 32670, epoch: 17, loss: 1.195299
global_step: 32671, epoch: 17, loss: 1.166025
global_step: 32672, epoch: 17, loss: 1.105631
global_step: 32673, epoch: 17, loss: 1.101598
global_step: 32674, epoch: 17, loss: 1.145557
global_step: 32675, epoch: 17, loss: 1.171034
global_step: 32676, epoch: 17, loss: 1.193909
global_step: 32677, epoch: 17, loss: 1.281683
global_step: 32678, epoch: 17, loss: 1.264089
global_step: 32679, epoch: 17, loss: 1.185887
global_step: 32680, epoch: 17, loss: 1.078584
epoch: 17
train	acc: 0.6401	macro: p 0.4479, r 0.3459, f1: 0.3587	micro: p 0.6401, r 0.6401, f1 0.6401	weighted_f1:0.5920
dev	acc: 0.5473	macro: p 0.3494, r 0.2910, f1: 0.2800	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4796
test	acc: 0.5989	macro: p 0.3840, r 0.3010, f1: 0.3035	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5427
global_step: 32681, epoch: 18, loss: 1.151530
global_step: 32682, epoch: 18, loss: 1.084008
global_step: 32683, epoch: 18, loss: 1.055646
global_step: 32684, epoch: 18, loss: 1.165645
global_step: 32685, epoch: 18, loss: 1.127741
global_step: 32686, epoch: 18, loss: 1.177242
global_step: 32687, epoch: 18, loss: 1.211221
global_step: 32688, epoch: 18, loss: 1.110608
global_step: 32689, epoch: 18, loss: 1.201069
global_step: 32690, epoch: 18, loss: 1.143583
global_step: 32691, epoch: 18, loss: 1.224545
global_step: 32692, epoch: 18, loss: 1.168140
global_step: 32693, epoch: 18, loss: 1.218071
global_step: 32694, epoch: 18, loss: 1.050643
global_step: 32695, epoch: 18, loss: 1.049643
global_step: 32696, epoch: 18, loss: 1.094684
global_step: 32697, epoch: 18, loss: 1.179260
global_step: 32698, epoch: 18, loss: 1.102299
global_step: 32699, epoch: 18, loss: 1.145645
global_step: 32700, epoch: 18, loss: 1.100441
global_step: 32701, epoch: 18, loss: 1.265206
global_step: 32702, epoch: 18, loss: 1.052161
global_step: 32703, epoch: 18, loss: 1.096522
global_step: 32704, epoch: 18, loss: 1.181975
global_step: 32705, epoch: 18, loss: 1.209082
global_step: 32706, epoch: 18, loss: 1.183245
global_step: 32707, epoch: 18, loss: 1.097999
global_step: 32708, epoch: 18, loss: 1.100357
global_step: 32709, epoch: 18, loss: 1.160452
global_step: 32710, epoch: 18, loss: 1.061686
global_step: 32711, epoch: 18, loss: 1.120752
global_step: 32712, epoch: 18, loss: 1.194943
global_step: 32713, epoch: 18, loss: 1.159820
global_step: 32714, epoch: 18, loss: 1.183943
global_step: 32715, epoch: 18, loss: 1.123970
global_step: 32716, epoch: 18, loss: 1.038922
global_step: 32717, epoch: 18, loss: 1.071386
global_step: 32718, epoch: 18, loss: 1.179439
global_step: 32719, epoch: 18, loss: 1.179345
global_step: 32720, epoch: 18, loss: 1.456638
epoch: 18
train	acc: 0.6461	macro: p 0.4487, r 0.3633, f1: 0.3709	micro: p 0.6461, r 0.6461, f1 0.6461	weighted_f1:0.6045
dev	acc: 0.5546	macro: p 0.3570, r 0.3023, f1: 0.2982	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4973
test	acc: 0.6050	macro: p 0.3902, r 0.3134, f1: 0.3175	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5560
New best model!
global_step: 32721, epoch: 19, loss: 1.170334
global_step: 32722, epoch: 19, loss: 1.052363
global_step: 32723, epoch: 19, loss: 1.249879
global_step: 32724, epoch: 19, loss: 1.220822
global_step: 32725, epoch: 19, loss: 1.099306
global_step: 32726, epoch: 19, loss: 1.160210
global_step: 32727, epoch: 19, loss: 1.128881
global_step: 32728, epoch: 19, loss: 1.141775
global_step: 32729, epoch: 19, loss: 1.135988
global_step: 32730, epoch: 19, loss: 0.946802
global_step: 32731, epoch: 19, loss: 1.063502
global_step: 32732, epoch: 19, loss: 1.109788
global_step: 32733, epoch: 19, loss: 1.114158
global_step: 32734, epoch: 19, loss: 1.046653
global_step: 32735, epoch: 19, loss: 1.171628
global_step: 32736, epoch: 19, loss: 1.077894
global_step: 32737, epoch: 19, loss: 0.984661
global_step: 32738, epoch: 19, loss: 1.163946
global_step: 32739, epoch: 19, loss: 1.102091
global_step: 32740, epoch: 19, loss: 1.174536
global_step: 32741, epoch: 19, loss: 1.040261
global_step: 32742, epoch: 19, loss: 1.029587
global_step: 32743, epoch: 19, loss: 1.113644
global_step: 32744, epoch: 19, loss: 1.299214
global_step: 32745, epoch: 19, loss: 1.239898
global_step: 32746, epoch: 19, loss: 1.025042
global_step: 32747, epoch: 19, loss: 1.207192
global_step: 32748, epoch: 19, loss: 1.102505
global_step: 32749, epoch: 19, loss: 1.057224
global_step: 32750, epoch: 19, loss: 1.155696
global_step: 32751, epoch: 19, loss: 1.098341
global_step: 32752, epoch: 19, loss: 1.163813
global_step: 32753, epoch: 19, loss: 1.187275
global_step: 32754, epoch: 19, loss: 1.181124
global_step: 32755, epoch: 19, loss: 1.168634
global_step: 32756, epoch: 19, loss: 1.114660
global_step: 32757, epoch: 19, loss: 1.100107
global_step: 32758, epoch: 19, loss: 1.171988
global_step: 32759, epoch: 19, loss: 1.056791
global_step: 32760, epoch: 19, loss: 0.884605
epoch: 19
train	acc: 0.6595	macro: p 0.4602, r 0.3732, f1: 0.3820	micro: p 0.6595, r 0.6595, f1 0.6595	weighted_f1:0.6156
dev	acc: 0.5645	macro: p 0.3597, r 0.3114, f1: 0.3042	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5028
test	acc: 0.6038	macro: p 0.3878, r 0.3128, f1: 0.3152	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5524
New best model!
global_step: 32761, epoch: 20, loss: 1.060021
global_step: 32762, epoch: 20, loss: 1.221118
global_step: 32763, epoch: 20, loss: 1.006631
global_step: 32764, epoch: 20, loss: 1.099491
global_step: 32765, epoch: 20, loss: 1.111456
global_step: 32766, epoch: 20, loss: 1.058551
global_step: 32767, epoch: 20, loss: 1.107990
global_step: 32768, epoch: 20, loss: 1.147293
global_step: 32769, epoch: 20, loss: 1.160379
global_step: 32770, epoch: 20, loss: 1.034105
global_step: 32771, epoch: 20, loss: 1.187675
global_step: 32772, epoch: 20, loss: 1.250157
global_step: 32773, epoch: 20, loss: 1.225417
global_step: 32774, epoch: 20, loss: 1.074909
global_step: 32775, epoch: 20, loss: 1.109376
global_step: 32776, epoch: 20, loss: 1.088096
global_step: 32777, epoch: 20, loss: 1.055308
global_step: 32778, epoch: 20, loss: 1.089100
global_step: 32779, epoch: 20, loss: 1.065303
global_step: 32780, epoch: 20, loss: 1.031753
global_step: 32781, epoch: 20, loss: 1.027781
global_step: 32782, epoch: 20, loss: 1.113228
global_step: 32783, epoch: 20, loss: 1.111845
global_step: 32784, epoch: 20, loss: 1.044365
global_step: 32785, epoch: 20, loss: 0.985665
global_step: 32786, epoch: 20, loss: 1.076306
global_step: 32787, epoch: 20, loss: 1.082665
global_step: 32788, epoch: 20, loss: 1.023719
global_step: 32789, epoch: 20, loss: 1.181794
global_step: 32790, epoch: 20, loss: 1.154750
global_step: 32791, epoch: 20, loss: 1.114320
global_step: 32792, epoch: 20, loss: 1.049847
global_step: 32793, epoch: 20, loss: 1.059076
global_step: 32794, epoch: 20, loss: 1.164866
global_step: 32795, epoch: 20, loss: 1.036144
global_step: 32796, epoch: 20, loss: 1.210390
global_step: 32797, epoch: 20, loss: 1.168654
global_step: 32798, epoch: 20, loss: 1.062968
global_step: 32799, epoch: 20, loss: 1.181367
global_step: 32800, epoch: 20, loss: 0.696681
epoch: 20
train	acc: 0.6572	macro: p 0.4519, r 0.3667, f1: 0.3815	micro: p 0.6572, r 0.6572, f1 0.6572	weighted_f1:0.6135
dev	acc: 0.5500	macro: p 0.3519, r 0.2954, f1: 0.2873	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4854
test	acc: 0.6011	macro: p 0.3780, r 0.3073, f1: 0.3120	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5485
global_step: 32801, epoch: 21, loss: 1.051469
global_step: 32802, epoch: 21, loss: 1.067794
global_step: 32803, epoch: 21, loss: 1.127418
global_step: 32804, epoch: 21, loss: 1.007177
global_step: 32805, epoch: 21, loss: 0.970455
global_step: 32806, epoch: 21, loss: 0.996240
global_step: 32807, epoch: 21, loss: 1.074849
global_step: 32808, epoch: 21, loss: 1.086120
global_step: 32809, epoch: 21, loss: 1.009360
global_step: 32810, epoch: 21, loss: 1.015153
global_step: 32811, epoch: 21, loss: 1.055009
global_step: 32812, epoch: 21, loss: 0.916247
global_step: 32813, epoch: 21, loss: 1.095926
global_step: 32814, epoch: 21, loss: 1.126570
global_step: 32815, epoch: 21, loss: 1.206236
global_step: 32816, epoch: 21, loss: 1.092170
global_step: 32817, epoch: 21, loss: 1.024165
global_step: 32818, epoch: 21, loss: 1.042694
global_step: 32819, epoch: 21, loss: 1.096153
global_step: 32820, epoch: 21, loss: 1.026941
global_step: 32821, epoch: 21, loss: 1.224701
global_step: 32822, epoch: 21, loss: 1.255417
global_step: 32823, epoch: 21, loss: 1.194008
global_step: 32824, epoch: 21, loss: 1.083312
global_step: 32825, epoch: 21, loss: 1.242144
global_step: 32826, epoch: 21, loss: 1.243020
global_step: 32827, epoch: 21, loss: 1.036653
global_step: 32828, epoch: 21, loss: 1.046724
global_step: 32829, epoch: 21, loss: 1.034156
global_step: 32830, epoch: 21, loss: 1.140766
global_step: 32831, epoch: 21, loss: 1.070840
global_step: 32832, epoch: 21, loss: 0.966812
global_step: 32833, epoch: 21, loss: 1.114473
global_step: 32834, epoch: 21, loss: 1.206600
global_step: 32835, epoch: 21, loss: 0.989473
global_step: 32836, epoch: 21, loss: 0.978961
global_step: 32837, epoch: 21, loss: 1.073614
global_step: 32838, epoch: 21, loss: 1.148505
global_step: 32839, epoch: 21, loss: 1.039775
global_step: 32840, epoch: 21, loss: 0.969054
epoch: 21
train	acc: 0.6650	macro: p 0.4691, r 0.3743, f1: 0.3884	micro: p 0.6650, r 0.6650, f1 0.6650	weighted_f1:0.6203
dev	acc: 0.5609	macro: p 0.3617, r 0.3047, f1: 0.3001	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.4974
test	acc: 0.6069	macro: p 0.3855, r 0.3112, f1: 0.3179	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5537
global_step: 32841, epoch: 22, loss: 1.148398
global_step: 32842, epoch: 22, loss: 1.038784
global_step: 32843, epoch: 22, loss: 1.114025
global_step: 32844, epoch: 22, loss: 1.068799
global_step: 32845, epoch: 22, loss: 1.117345
global_step: 32846, epoch: 22, loss: 0.980023
global_step: 32847, epoch: 22, loss: 1.102980
global_step: 32848, epoch: 22, loss: 1.033178
global_step: 32849, epoch: 22, loss: 1.122355
global_step: 32850, epoch: 22, loss: 1.134372
global_step: 32851, epoch: 22, loss: 1.004454
global_step: 32852, epoch: 22, loss: 1.114466
global_step: 32853, epoch: 22, loss: 1.199736
global_step: 32854, epoch: 22, loss: 1.031928
global_step: 32855, epoch: 22, loss: 1.048865
global_step: 32856, epoch: 22, loss: 1.026312
global_step: 32857, epoch: 22, loss: 1.051613
global_step: 32858, epoch: 22, loss: 1.070863
global_step: 32859, epoch: 22, loss: 1.131450
global_step: 32860, epoch: 22, loss: 1.023667
global_step: 32861, epoch: 22, loss: 1.120745
global_step: 32862, epoch: 22, loss: 1.054528
global_step: 32863, epoch: 22, loss: 0.997340
global_step: 32864, epoch: 22, loss: 0.999765
global_step: 32865, epoch: 22, loss: 1.148509
global_step: 32866, epoch: 22, loss: 1.119126
global_step: 32867, epoch: 22, loss: 0.951192
global_step: 32868, epoch: 22, loss: 1.138374
global_step: 32869, epoch: 22, loss: 1.115364
global_step: 32870, epoch: 22, loss: 1.073190
global_step: 32871, epoch: 22, loss: 1.004133
global_step: 32872, epoch: 22, loss: 1.184758
global_step: 32873, epoch: 22, loss: 1.009502
global_step: 32874, epoch: 22, loss: 1.097883
global_step: 32875, epoch: 22, loss: 1.171867
global_step: 32876, epoch: 22, loss: 1.123821
global_step: 32877, epoch: 22, loss: 0.967126
global_step: 32878, epoch: 22, loss: 1.110505
global_step: 32879, epoch: 22, loss: 1.090852
global_step: 32880, epoch: 22, loss: 2.054012
epoch: 22
train	acc: 0.6854	macro: p 0.4710, r 0.4011, f1: 0.4101	micro: p 0.6854, r 0.6854, f1 0.6854	weighted_f1:0.6458
dev	acc: 0.5681	macro: p 0.3723, r 0.3172, f1: 0.3124	micro: p 0.5681, r 0.5681, f1 0.5681	weighted_f1:0.5111
test	acc: 0.6054	macro: p 0.3825, r 0.3189, f1: 0.3234	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5586
New best model!
global_step: 32881, epoch: 23, loss: 1.083144
global_step: 32882, epoch: 23, loss: 1.163588
global_step: 32883, epoch: 23, loss: 1.039971
global_step: 32884, epoch: 23, loss: 1.066699
global_step: 32885, epoch: 23, loss: 1.052755
global_step: 32886, epoch: 23, loss: 1.111573
global_step: 32887, epoch: 23, loss: 1.027070
global_step: 32888, epoch: 23, loss: 1.109743
global_step: 32889, epoch: 23, loss: 1.022201
global_step: 32890, epoch: 23, loss: 1.039968
global_step: 32891, epoch: 23, loss: 1.047064
global_step: 32892, epoch: 23, loss: 1.177870
global_step: 32893, epoch: 23, loss: 0.963647
global_step: 32894, epoch: 23, loss: 1.045459
global_step: 32895, epoch: 23, loss: 1.069380
global_step: 32896, epoch: 23, loss: 1.121078
global_step: 32897, epoch: 23, loss: 1.077028
global_step: 32898, epoch: 23, loss: 1.097482
global_step: 32899, epoch: 23, loss: 0.978758
global_step: 32900, epoch: 23, loss: 1.148764
global_step: 32901, epoch: 23, loss: 1.164635
global_step: 32902, epoch: 23, loss: 1.132224
global_step: 32903, epoch: 23, loss: 1.023781
global_step: 32904, epoch: 23, loss: 1.112412
global_step: 32905, epoch: 23, loss: 1.111242
global_step: 32906, epoch: 23, loss: 1.073519
global_step: 32907, epoch: 23, loss: 1.058287
global_step: 32908, epoch: 23, loss: 1.017628
global_step: 32909, epoch: 23, loss: 1.093736
global_step: 32910, epoch: 23, loss: 1.074625
global_step: 32911, epoch: 23, loss: 1.029770
global_step: 32912, epoch: 23, loss: 1.049848
global_step: 32913, epoch: 23, loss: 0.876854
global_step: 32914, epoch: 23, loss: 1.038103
global_step: 32915, epoch: 23, loss: 1.094693
global_step: 32916, epoch: 23, loss: 0.988372
global_step: 32917, epoch: 23, loss: 0.973254
global_step: 32918, epoch: 23, loss: 0.989930
global_step: 32919, epoch: 23, loss: 1.167346
global_step: 32920, epoch: 23, loss: 1.040237
epoch: 23
train	acc: 0.7034	macro: p 0.4719, r 0.4353, f1: 0.4408	micro: p 0.7034, r 0.7034, f1 0.7034	weighted_f1:0.6731
dev	acc: 0.5582	macro: p 0.3531, r 0.3215, f1: 0.3188	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5124
test	acc: 0.6019	macro: p 0.3644, r 0.3255, f1: 0.3290	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5622
New best model!
global_step: 32921, epoch: 24, loss: 1.074266
global_step: 32922, epoch: 24, loss: 1.020420
global_step: 32923, epoch: 24, loss: 0.999880
global_step: 32924, epoch: 24, loss: 1.106738
global_step: 32925, epoch: 24, loss: 1.127844
global_step: 32926, epoch: 24, loss: 1.099966
global_step: 32927, epoch: 24, loss: 0.966126
global_step: 32928, epoch: 24, loss: 1.085249
global_step: 32929, epoch: 24, loss: 0.981942
global_step: 32930, epoch: 24, loss: 1.050267
global_step: 32931, epoch: 24, loss: 1.018734
global_step: 32932, epoch: 24, loss: 1.032113
global_step: 32933, epoch: 24, loss: 0.964836
global_step: 32934, epoch: 24, loss: 1.032554
global_step: 32935, epoch: 24, loss: 1.063685
global_step: 32936, epoch: 24, loss: 1.043883
global_step: 32937, epoch: 24, loss: 0.998719
global_step: 32938, epoch: 24, loss: 1.119476
global_step: 32939, epoch: 24, loss: 1.055799
global_step: 32940, epoch: 24, loss: 0.996708
global_step: 32941, epoch: 24, loss: 0.970967
global_step: 32942, epoch: 24, loss: 1.133065
global_step: 32943, epoch: 24, loss: 1.109392
global_step: 32944, epoch: 24, loss: 0.929654
global_step: 32945, epoch: 24, loss: 0.976050
global_step: 32946, epoch: 24, loss: 1.174691
global_step: 32947, epoch: 24, loss: 1.026162
global_step: 32948, epoch: 24, loss: 0.981681
global_step: 32949, epoch: 24, loss: 1.135254
global_step: 32950, epoch: 24, loss: 1.058457
global_step: 32951, epoch: 24, loss: 0.983267
global_step: 32952, epoch: 24, loss: 1.033680
global_step: 32953, epoch: 24, loss: 1.085333
global_step: 32954, epoch: 24, loss: 1.102782
global_step: 32955, epoch: 24, loss: 1.116367
global_step: 32956, epoch: 24, loss: 0.949831
global_step: 32957, epoch: 24, loss: 0.985276
global_step: 32958, epoch: 24, loss: 1.057805
global_step: 32959, epoch: 24, loss: 0.985013
global_step: 32960, epoch: 24, loss: 0.864555
epoch: 24
train	acc: 0.6856	macro: p 0.4785, r 0.4028, f1: 0.4160	micro: p 0.6856, r 0.6856, f1 0.6856	weighted_f1:0.6463
dev	acc: 0.5699	macro: p 0.3630, r 0.3163, f1: 0.3132	micro: p 0.5699, r 0.5699, f1 0.5699	weighted_f1:0.5119
test	acc: 0.6115	macro: p 0.3825, r 0.3201, f1: 0.3262	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5620
global_step: 32961, epoch: 25, loss: 1.042836
global_step: 32962, epoch: 25, loss: 1.110138
global_step: 32963, epoch: 25, loss: 1.073333
global_step: 32964, epoch: 25, loss: 0.979604
global_step: 32965, epoch: 25, loss: 1.047924
global_step: 32966, epoch: 25, loss: 1.093542
global_step: 32967, epoch: 25, loss: 1.001184
global_step: 32968, epoch: 25, loss: 0.959953
global_step: 32969, epoch: 25, loss: 1.026801
global_step: 32970, epoch: 25, loss: 0.963947
global_step: 32971, epoch: 25, loss: 1.020096
global_step: 32972, epoch: 25, loss: 1.030177
global_step: 32973, epoch: 25, loss: 1.130207
global_step: 32974, epoch: 25, loss: 0.982145
global_step: 32975, epoch: 25, loss: 0.948276
global_step: 32976, epoch: 25, loss: 1.072058
global_step: 32977, epoch: 25, loss: 1.079528
global_step: 32978, epoch: 25, loss: 1.053725
global_step: 32979, epoch: 25, loss: 1.037907
global_step: 32980, epoch: 25, loss: 1.174292
global_step: 32981, epoch: 25, loss: 1.030062
global_step: 32982, epoch: 25, loss: 1.134492
global_step: 32983, epoch: 25, loss: 0.927479
global_step: 32984, epoch: 25, loss: 1.073130
global_step: 32985, epoch: 25, loss: 1.104794
global_step: 32986, epoch: 25, loss: 1.083225
global_step: 32987, epoch: 25, loss: 1.129835
global_step: 32988, epoch: 25, loss: 1.083142
global_step: 32989, epoch: 25, loss: 1.095104
global_step: 32990, epoch: 25, loss: 1.005127
global_step: 32991, epoch: 25, loss: 1.074710
global_step: 32992, epoch: 25, loss: 1.104292
global_step: 32993, epoch: 25, loss: 0.922423
global_step: 32994, epoch: 25, loss: 1.076789
global_step: 32995, epoch: 25, loss: 1.078476
global_step: 32996, epoch: 25, loss: 0.974157
global_step: 32997, epoch: 25, loss: 1.090599
global_step: 32998, epoch: 25, loss: 1.049569
global_step: 32999, epoch: 25, loss: 0.982677
global_step: 33000, epoch: 25, loss: 1.425832
epoch: 25
train	acc: 0.7158	macro: p 0.4895, r 0.4390, f1: 0.4471	micro: p 0.7158, r 0.7158, f1 0.7158	weighted_f1:0.6818
dev	acc: 0.5645	macro: p 0.3679, r 0.3215, f1: 0.3157	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5127
test	acc: 0.6065	macro: p 0.3774, r 0.3247, f1: 0.3283	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5631
New best model!
global_step: 33001, epoch: 26, loss: 1.017890
global_step: 33002, epoch: 26, loss: 0.936221
global_step: 33003, epoch: 26, loss: 0.972088
global_step: 33004, epoch: 26, loss: 0.953192
global_step: 33005, epoch: 26, loss: 0.932474
global_step: 33006, epoch: 26, loss: 0.953747
global_step: 33007, epoch: 26, loss: 1.034268
global_step: 33008, epoch: 26, loss: 1.042160
global_step: 33009, epoch: 26, loss: 0.968795
global_step: 33010, epoch: 26, loss: 1.105979
global_step: 33011, epoch: 26, loss: 1.037205
global_step: 33012, epoch: 26, loss: 0.945998
global_step: 33013, epoch: 26, loss: 1.025881
global_step: 33014, epoch: 26, loss: 1.066765
global_step: 33015, epoch: 26, loss: 0.921161
global_step: 33016, epoch: 26, loss: 0.972013
global_step: 33017, epoch: 26, loss: 1.089539
global_step: 33018, epoch: 26, loss: 1.087268
global_step: 33019, epoch: 26, loss: 0.949370
global_step: 33020, epoch: 26, loss: 1.036984
global_step: 33021, epoch: 26, loss: 0.973125
global_step: 33022, epoch: 26, loss: 0.943484
global_step: 33023, epoch: 26, loss: 1.046396
global_step: 33024, epoch: 26, loss: 1.082970
global_step: 33025, epoch: 26, loss: 1.081764
global_step: 33026, epoch: 26, loss: 1.058010
global_step: 33027, epoch: 26, loss: 0.973720
global_step: 33028, epoch: 26, loss: 0.895745
global_step: 33029, epoch: 26, loss: 1.160091
global_step: 33030, epoch: 26, loss: 1.039539
global_step: 33031, epoch: 26, loss: 0.926399
global_step: 33032, epoch: 26, loss: 1.043332
global_step: 33033, epoch: 26, loss: 1.016010
global_step: 33034, epoch: 26, loss: 0.975846
global_step: 33035, epoch: 26, loss: 1.009211
global_step: 33036, epoch: 26, loss: 1.001855
global_step: 33037, epoch: 26, loss: 1.105592
global_step: 33038, epoch: 26, loss: 1.076849
global_step: 33039, epoch: 26, loss: 1.121860
global_step: 33040, epoch: 26, loss: 0.604457
epoch: 26
train	acc: 0.7109	macro: p 0.4904, r 0.4295, f1: 0.4382	micro: p 0.7109, r 0.7109, f1 0.7109	weighted_f1:0.6726
dev	acc: 0.5663	macro: p 0.3550, r 0.3180, f1: 0.3072	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5056
test	acc: 0.6069	macro: p 0.3787, r 0.3236, f1: 0.3262	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5600
global_step: 33041, epoch: 27, loss: 0.921705
global_step: 33042, epoch: 27, loss: 0.973816
global_step: 33043, epoch: 27, loss: 1.056109
global_step: 33044, epoch: 27, loss: 1.140223
global_step: 33045, epoch: 27, loss: 0.941273
global_step: 33046, epoch: 27, loss: 0.995697
global_step: 33047, epoch: 27, loss: 1.016339
global_step: 33048, epoch: 27, loss: 0.985687
global_step: 33049, epoch: 27, loss: 0.965671
global_step: 33050, epoch: 27, loss: 0.986305
global_step: 33051, epoch: 27, loss: 0.977798
global_step: 33052, epoch: 27, loss: 0.926826
global_step: 33053, epoch: 27, loss: 1.042448
global_step: 33054, epoch: 27, loss: 1.049730
global_step: 33055, epoch: 27, loss: 1.005401
global_step: 33056, epoch: 27, loss: 0.935427
global_step: 33057, epoch: 27, loss: 1.096240
global_step: 33058, epoch: 27, loss: 0.966164
global_step: 33059, epoch: 27, loss: 1.085597
global_step: 33060, epoch: 27, loss: 1.082310
global_step: 33061, epoch: 27, loss: 0.928948
global_step: 33062, epoch: 27, loss: 1.046428
global_step: 33063, epoch: 27, loss: 0.951044
global_step: 33064, epoch: 27, loss: 0.996513
global_step: 33065, epoch: 27, loss: 1.018642
global_step: 33066, epoch: 27, loss: 0.944722
global_step: 33067, epoch: 27, loss: 1.146448
global_step: 33068, epoch: 27, loss: 0.955450
global_step: 33069, epoch: 27, loss: 0.976950
global_step: 33070, epoch: 27, loss: 0.980437
global_step: 33071, epoch: 27, loss: 0.993858
global_step: 33072, epoch: 27, loss: 1.071306
global_step: 33073, epoch: 27, loss: 1.140273
global_step: 33074, epoch: 27, loss: 0.969305
global_step: 33075, epoch: 27, loss: 1.015262
global_step: 33076, epoch: 27, loss: 0.971326
global_step: 33077, epoch: 27, loss: 0.980032
global_step: 33078, epoch: 27, loss: 0.996137
global_step: 33079, epoch: 27, loss: 0.923859
global_step: 33080, epoch: 27, loss: 1.457352
epoch: 27
train	acc: 0.7303	macro: p 0.4982, r 0.4577, f1: 0.4654	micro: p 0.7303, r 0.7303, f1 0.7303	weighted_f1:0.6985
dev	acc: 0.5509	macro: p 0.3536, r 0.3109, f1: 0.3027	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4984
test	acc: 0.6027	macro: p 0.3755, r 0.3229, f1: 0.3248	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5587
global_step: 33081, epoch: 28, loss: 0.880766
global_step: 33082, epoch: 28, loss: 1.019995
global_step: 33083, epoch: 28, loss: 0.921619
global_step: 33084, epoch: 28, loss: 0.930638
global_step: 33085, epoch: 28, loss: 0.919656
global_step: 33086, epoch: 28, loss: 0.945092
global_step: 33087, epoch: 28, loss: 1.013695
global_step: 33088, epoch: 28, loss: 1.105918
global_step: 33089, epoch: 28, loss: 1.033535
global_step: 33090, epoch: 28, loss: 1.003716
global_step: 33091, epoch: 28, loss: 1.044295
global_step: 33092, epoch: 28, loss: 1.015978
global_step: 33093, epoch: 28, loss: 1.047806
global_step: 33094, epoch: 28, loss: 0.955370
global_step: 33095, epoch: 28, loss: 0.980466
global_step: 33096, epoch: 28, loss: 0.953989
global_step: 33097, epoch: 28, loss: 0.943349
global_step: 33098, epoch: 28, loss: 0.996268
global_step: 33099, epoch: 28, loss: 1.014035
global_step: 33100, epoch: 28, loss: 0.967928
global_step: 33101, epoch: 28, loss: 0.943599
global_step: 33102, epoch: 28, loss: 0.993068
global_step: 33103, epoch: 28, loss: 0.906708
global_step: 33104, epoch: 28, loss: 1.033949
global_step: 33105, epoch: 28, loss: 1.013751
global_step: 33106, epoch: 28, loss: 1.011098
global_step: 33107, epoch: 28, loss: 1.017298
global_step: 33108, epoch: 28, loss: 1.020787
global_step: 33109, epoch: 28, loss: 0.966298
global_step: 33110, epoch: 28, loss: 0.894254
global_step: 33111, epoch: 28, loss: 0.918252
global_step: 33112, epoch: 28, loss: 1.082515
global_step: 33113, epoch: 28, loss: 0.972494
global_step: 33114, epoch: 28, loss: 0.925589
global_step: 33115, epoch: 28, loss: 1.005074
global_step: 33116, epoch: 28, loss: 1.117270
global_step: 33117, epoch: 28, loss: 0.965419
global_step: 33118, epoch: 28, loss: 1.028584
global_step: 33119, epoch: 28, loss: 0.983824
global_step: 33120, epoch: 28, loss: 1.701318
epoch: 28
train	acc: 0.7365	macro: p 0.4973, r 0.4741, f1: 0.4807	micro: p 0.7365, r 0.7365, f1 0.7365	weighted_f1:0.7078
dev	acc: 0.5627	macro: p 0.3519, r 0.3251, f1: 0.3218	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5146
test	acc: 0.6038	macro: p 0.3585, r 0.3266, f1: 0.3314	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5629
New best model!
global_step: 33121, epoch: 29, loss: 0.983355
global_step: 33122, epoch: 29, loss: 0.949921
global_step: 33123, epoch: 29, loss: 1.058645
global_step: 33124, epoch: 29, loss: 0.899688
global_step: 33125, epoch: 29, loss: 0.871763
global_step: 33126, epoch: 29, loss: 0.942748
global_step: 33127, epoch: 29, loss: 0.911063
global_step: 33128, epoch: 29, loss: 0.907427
global_step: 33129, epoch: 29, loss: 0.974968
global_step: 33130, epoch: 29, loss: 1.031243
global_step: 33131, epoch: 29, loss: 1.085860
global_step: 33132, epoch: 29, loss: 0.941986
global_step: 33133, epoch: 29, loss: 0.948826
global_step: 33134, epoch: 29, loss: 1.003585
global_step: 33135, epoch: 29, loss: 1.035045
global_step: 33136, epoch: 29, loss: 1.028073
global_step: 33137, epoch: 29, loss: 0.984407
global_step: 33138, epoch: 29, loss: 1.019767
global_step: 33139, epoch: 29, loss: 0.975848
global_step: 33140, epoch: 29, loss: 0.982519
global_step: 33141, epoch: 29, loss: 1.033233
global_step: 33142, epoch: 29, loss: 0.983126
global_step: 33143, epoch: 29, loss: 0.937017
global_step: 33144, epoch: 29, loss: 0.971080
global_step: 33145, epoch: 29, loss: 0.919089
global_step: 33146, epoch: 29, loss: 1.032252
global_step: 33147, epoch: 29, loss: 0.974836
global_step: 33148, epoch: 29, loss: 0.978836
global_step: 33149, epoch: 29, loss: 1.054106
global_step: 33150, epoch: 29, loss: 0.970233
global_step: 33151, epoch: 29, loss: 1.037502
global_step: 33152, epoch: 29, loss: 0.885092
global_step: 33153, epoch: 29, loss: 0.877433
global_step: 33154, epoch: 29, loss: 0.967384
global_step: 33155, epoch: 29, loss: 1.038606
global_step: 33156, epoch: 29, loss: 0.993087
global_step: 33157, epoch: 29, loss: 0.952850
global_step: 33158, epoch: 29, loss: 0.965176
global_step: 33159, epoch: 29, loss: 1.069587
global_step: 33160, epoch: 29, loss: 1.268538
epoch: 29
train	acc: 0.7545	macro: p 0.5065, r 0.4942, f1: 0.4951	micro: p 0.7545, r 0.7545, f1 0.7545	weighted_f1:0.7281
dev	acc: 0.5365	macro: p 0.3280, r 0.3082, f1: 0.2996	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4911
test	acc: 0.5989	macro: p 0.3592, r 0.3288, f1: 0.3286	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5607
global_step: 33161, epoch: 30, loss: 0.927673
global_step: 33162, epoch: 30, loss: 0.931041
global_step: 33163, epoch: 30, loss: 0.901668
global_step: 33164, epoch: 30, loss: 0.952763
global_step: 33165, epoch: 30, loss: 0.941038
global_step: 33166, epoch: 30, loss: 0.908317
global_step: 33167, epoch: 30, loss: 0.936798
global_step: 33168, epoch: 30, loss: 0.955228
global_step: 33169, epoch: 30, loss: 0.907252
global_step: 33170, epoch: 30, loss: 1.008565
global_step: 33171, epoch: 30, loss: 0.983480
global_step: 33172, epoch: 30, loss: 0.902427
global_step: 33173, epoch: 30, loss: 0.925987
global_step: 33174, epoch: 30, loss: 0.927516
global_step: 33175, epoch: 30, loss: 0.966279
global_step: 33176, epoch: 30, loss: 0.941519
global_step: 33177, epoch: 30, loss: 0.886089
global_step: 33178, epoch: 30, loss: 0.946353
global_step: 33179, epoch: 30, loss: 1.010015
global_step: 33180, epoch: 30, loss: 1.067888
global_step: 33181, epoch: 30, loss: 0.849646
global_step: 33182, epoch: 30, loss: 0.910283
global_step: 33183, epoch: 30, loss: 0.971719
global_step: 33184, epoch: 30, loss: 1.037559
global_step: 33185, epoch: 30, loss: 0.845650
global_step: 33186, epoch: 30, loss: 0.927822
global_step: 33187, epoch: 30, loss: 0.976450
global_step: 33188, epoch: 30, loss: 0.923078
global_step: 33189, epoch: 30, loss: 0.940848
global_step: 33190, epoch: 30, loss: 1.048097
global_step: 33191, epoch: 30, loss: 1.003460
global_step: 33192, epoch: 30, loss: 0.973817
global_step: 33193, epoch: 30, loss: 0.960876
global_step: 33194, epoch: 30, loss: 0.933700
global_step: 33195, epoch: 30, loss: 0.911539
global_step: 33196, epoch: 30, loss: 0.957102
global_step: 33197, epoch: 30, loss: 0.961469
global_step: 33198, epoch: 30, loss: 1.038226
global_step: 33199, epoch: 30, loss: 1.030208
global_step: 33200, epoch: 30, loss: 1.164276
epoch: 30
train	acc: 0.7506	macro: p 0.5128, r 0.4842, f1: 0.4894	micro: p 0.7506, r 0.7506, f1 0.7506	weighted_f1:0.7229
dev	acc: 0.5573	macro: p 0.3481, r 0.3179, f1: 0.3129	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5090
test	acc: 0.6011	macro: p 0.3673, r 0.3244, f1: 0.3288	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5612
global_step: 33201, epoch: 31, loss: 0.834920
global_step: 33202, epoch: 31, loss: 0.906839
global_step: 33203, epoch: 31, loss: 0.909388
global_step: 33204, epoch: 31, loss: 0.950151
global_step: 33205, epoch: 31, loss: 0.983943
global_step: 33206, epoch: 31, loss: 0.865450
global_step: 33207, epoch: 31, loss: 1.004345
global_step: 33208, epoch: 31, loss: 1.013617
global_step: 33209, epoch: 31, loss: 0.989794
global_step: 33210, epoch: 31, loss: 0.953074
global_step: 33211, epoch: 31, loss: 0.889555
global_step: 33212, epoch: 31, loss: 0.857740
global_step: 33213, epoch: 31, loss: 0.932491
global_step: 33214, epoch: 31, loss: 0.923801
global_step: 33215, epoch: 31, loss: 0.940692
global_step: 33216, epoch: 31, loss: 0.867668
global_step: 33217, epoch: 31, loss: 0.987851
global_step: 33218, epoch: 31, loss: 0.883718
global_step: 33219, epoch: 31, loss: 0.979525
global_step: 33220, epoch: 31, loss: 0.940649
global_step: 33221, epoch: 31, loss: 0.976284
global_step: 33222, epoch: 31, loss: 0.940660
global_step: 33223, epoch: 31, loss: 0.934672
global_step: 33224, epoch: 31, loss: 0.926177
global_step: 33225, epoch: 31, loss: 1.008062
global_step: 33226, epoch: 31, loss: 0.967799
global_step: 33227, epoch: 31, loss: 0.949629
global_step: 33228, epoch: 31, loss: 0.996494
global_step: 33229, epoch: 31, loss: 0.932389
global_step: 33230, epoch: 31, loss: 0.848495
global_step: 33231, epoch: 31, loss: 0.998909
global_step: 33232, epoch: 31, loss: 0.929058
global_step: 33233, epoch: 31, loss: 1.021236
global_step: 33234, epoch: 31, loss: 0.951160
global_step: 33235, epoch: 31, loss: 0.953204
global_step: 33236, epoch: 31, loss: 0.919693
global_step: 33237, epoch: 31, loss: 0.934478
global_step: 33238, epoch: 31, loss: 1.001724
global_step: 33239, epoch: 31, loss: 0.932109
global_step: 33240, epoch: 31, loss: 1.503924
epoch: 31
train	acc: 0.7511	macro: p 0.5217, r 0.4773, f1: 0.4856	micro: p 0.7511, r 0.7511, f1 0.7511	weighted_f1:0.7184
dev	acc: 0.5690	macro: p 0.3693, r 0.3258, f1: 0.3183	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5134
test	acc: 0.6019	macro: p 0.3662, r 0.3213, f1: 0.3238	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5564
global_step: 33241, epoch: 32, loss: 0.875721
global_step: 33242, epoch: 32, loss: 0.972344
global_step: 33243, epoch: 32, loss: 0.963648
global_step: 33244, epoch: 32, loss: 1.059385
global_step: 33245, epoch: 32, loss: 1.016580
global_step: 33246, epoch: 32, loss: 0.861911
global_step: 33247, epoch: 32, loss: 0.848220
global_step: 33248, epoch: 32, loss: 0.901271
global_step: 33249, epoch: 32, loss: 0.864448
global_step: 33250, epoch: 32, loss: 0.850232
global_step: 33251, epoch: 32, loss: 0.950349
global_step: 33252, epoch: 32, loss: 0.892421
global_step: 33253, epoch: 32, loss: 0.865685
global_step: 33254, epoch: 32, loss: 1.052426
global_step: 33255, epoch: 32, loss: 0.919894
global_step: 33256, epoch: 32, loss: 1.006790
global_step: 33257, epoch: 32, loss: 0.911971
global_step: 33258, epoch: 32, loss: 0.931985
global_step: 33259, epoch: 32, loss: 0.845922
global_step: 33260, epoch: 32, loss: 0.919090
global_step: 33261, epoch: 32, loss: 0.849676
global_step: 33262, epoch: 32, loss: 0.874061
global_step: 33263, epoch: 32, loss: 1.063998
global_step: 33264, epoch: 32, loss: 0.888979
global_step: 33265, epoch: 32, loss: 0.983246
global_step: 33266, epoch: 32, loss: 0.905085
global_step: 33267, epoch: 32, loss: 0.878245
global_step: 33268, epoch: 32, loss: 0.913189
global_step: 33269, epoch: 32, loss: 0.910015
global_step: 33270, epoch: 32, loss: 0.847971
global_step: 33271, epoch: 32, loss: 0.946809
global_step: 33272, epoch: 32, loss: 0.960608
global_step: 33273, epoch: 32, loss: 0.857363
global_step: 33274, epoch: 32, loss: 0.902166
global_step: 33275, epoch: 32, loss: 0.918903
global_step: 33276, epoch: 32, loss: 1.023165
global_step: 33277, epoch: 32, loss: 0.974532
global_step: 33278, epoch: 32, loss: 0.880011
global_step: 33279, epoch: 32, loss: 0.961080
global_step: 33280, epoch: 32, loss: 1.134001
epoch: 32
train	acc: 0.7504	macro: p 0.5252, r 0.4769, f1: 0.4889	micro: p 0.7504, r 0.7504, f1 0.7504	weighted_f1:0.7185
dev	acc: 0.5672	macro: p 0.3664, r 0.3200, f1: 0.3140	micro: p 0.5672, r 0.5672, f1 0.5672	weighted_f1:0.5098
test	acc: 0.6069	macro: p 0.3708, r 0.3216, f1: 0.3257	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5595
global_step: 33281, epoch: 33, loss: 0.874755
global_step: 33282, epoch: 33, loss: 0.943397
global_step: 33283, epoch: 33, loss: 0.949743
global_step: 33284, epoch: 33, loss: 0.849465
global_step: 33285, epoch: 33, loss: 0.927962
global_step: 33286, epoch: 33, loss: 0.919538
global_step: 33287, epoch: 33, loss: 0.974709
global_step: 33288, epoch: 33, loss: 0.958900
global_step: 33289, epoch: 33, loss: 0.932605
global_step: 33290, epoch: 33, loss: 1.079200
global_step: 33291, epoch: 33, loss: 0.934782
global_step: 33292, epoch: 33, loss: 0.864863
global_step: 33293, epoch: 33, loss: 0.844386
global_step: 33294, epoch: 33, loss: 1.034980
global_step: 33295, epoch: 33, loss: 0.898028
global_step: 33296, epoch: 33, loss: 0.860010
global_step: 33297, epoch: 33, loss: 0.922224
global_step: 33298, epoch: 33, loss: 0.855857
global_step: 33299, epoch: 33, loss: 0.948619
global_step: 33300, epoch: 33, loss: 0.883092
global_step: 33301, epoch: 33, loss: 0.975358
global_step: 33302, epoch: 33, loss: 0.886878
global_step: 33303, epoch: 33, loss: 0.945485
global_step: 33304, epoch: 33, loss: 0.973647
global_step: 33305, epoch: 33, loss: 0.826027
global_step: 33306, epoch: 33, loss: 0.828959
global_step: 33307, epoch: 33, loss: 0.827269
global_step: 33308, epoch: 33, loss: 0.899059
global_step: 33309, epoch: 33, loss: 0.994677
global_step: 33310, epoch: 33, loss: 0.901086
global_step: 33311, epoch: 33, loss: 0.903269
global_step: 33312, epoch: 33, loss: 0.931362
global_step: 33313, epoch: 33, loss: 0.920717
global_step: 33314, epoch: 33, loss: 0.875439
global_step: 33315, epoch: 33, loss: 0.953589
global_step: 33316, epoch: 33, loss: 0.930501
global_step: 33317, epoch: 33, loss: 0.892550
global_step: 33318, epoch: 33, loss: 0.936358
global_step: 33319, epoch: 33, loss: 0.940990
global_step: 33320, epoch: 33, loss: 1.652558
epoch: 33
train	acc: 0.7606	macro: p 0.8147, r 0.4959, f1: 0.5030	micro: p 0.7606, r 0.7606, f1 0.7606	weighted_f1:0.7318
dev	acc: 0.5564	macro: p 0.3539, r 0.3152, f1: 0.3098	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5049
test	acc: 0.6061	macro: p 0.3686, r 0.3248, f1: 0.3278	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5621
global_step: 33321, epoch: 34, loss: 0.908168
global_step: 33322, epoch: 34, loss: 1.013979
global_step: 33323, epoch: 34, loss: 0.883339
global_step: 33324, epoch: 34, loss: 0.958197
global_step: 33325, epoch: 34, loss: 0.874291
global_step: 33326, epoch: 34, loss: 0.942274
global_step: 33327, epoch: 34, loss: 0.886338
global_step: 33328, epoch: 34, loss: 0.761142
global_step: 33329, epoch: 34, loss: 0.984113
global_step: 33330, epoch: 34, loss: 0.897310
global_step: 33331, epoch: 34, loss: 0.941358
global_step: 33332, epoch: 34, loss: 0.837706
global_step: 33333, epoch: 34, loss: 0.828199
global_step: 33334, epoch: 34, loss: 0.947366
global_step: 33335, epoch: 34, loss: 0.883483
global_step: 33336, epoch: 34, loss: 0.897367
global_step: 33337, epoch: 34, loss: 0.882652
global_step: 33338, epoch: 34, loss: 0.955779
global_step: 33339, epoch: 34, loss: 0.749462
global_step: 33340, epoch: 34, loss: 0.908143
global_step: 33341, epoch: 34, loss: 0.885573
global_step: 33342, epoch: 34, loss: 0.944384
global_step: 33343, epoch: 34, loss: 0.883222
global_step: 33344, epoch: 34, loss: 0.847003
global_step: 33345, epoch: 34, loss: 0.882239
global_step: 33346, epoch: 34, loss: 0.950408
global_step: 33347, epoch: 34, loss: 0.895828
global_step: 33348, epoch: 34, loss: 0.875934
global_step: 33349, epoch: 34, loss: 0.833809
global_step: 33350, epoch: 34, loss: 1.046358
global_step: 33351, epoch: 34, loss: 0.871526
global_step: 33352, epoch: 34, loss: 1.061079
global_step: 33353, epoch: 34, loss: 0.907340
global_step: 33354, epoch: 34, loss: 0.921885
global_step: 33355, epoch: 34, loss: 0.955501
global_step: 33356, epoch: 34, loss: 0.845698
global_step: 33357, epoch: 34, loss: 0.851654
global_step: 33358, epoch: 34, loss: 0.926803
global_step: 33359, epoch: 34, loss: 0.897061
global_step: 33360, epoch: 34, loss: 0.619890
epoch: 34
train	acc: 0.7677	macro: p 0.6842, r 0.4946, f1: 0.5001	micro: p 0.7677, r 0.7677, f1 0.7677	weighted_f1:0.7367
dev	acc: 0.5573	macro: p 0.3653, r 0.3163, f1: 0.3107	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5052
test	acc: 0.6019	macro: p 0.3765, r 0.3206, f1: 0.3238	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5580
global_step: 33361, epoch: 35, loss: 0.856171
global_step: 33362, epoch: 35, loss: 0.769964
global_step: 33363, epoch: 35, loss: 0.907624
global_step: 33364, epoch: 35, loss: 0.870602
global_step: 33365, epoch: 35, loss: 0.965350
global_step: 33366, epoch: 35, loss: 0.907023
global_step: 33367, epoch: 35, loss: 0.849616
global_step: 33368, epoch: 35, loss: 0.922347
global_step: 33369, epoch: 35, loss: 0.880531
global_step: 33370, epoch: 35, loss: 0.879522
global_step: 33371, epoch: 35, loss: 0.982539
global_step: 33372, epoch: 35, loss: 0.850579
global_step: 33373, epoch: 35, loss: 0.927530
global_step: 33374, epoch: 35, loss: 0.824567
global_step: 33375, epoch: 35, loss: 0.954398
global_step: 33376, epoch: 35, loss: 0.905215
global_step: 33377, epoch: 35, loss: 0.868438
global_step: 33378, epoch: 35, loss: 0.946708
global_step: 33379, epoch: 35, loss: 0.940564
global_step: 33380, epoch: 35, loss: 0.852621
global_step: 33381, epoch: 35, loss: 0.863866
global_step: 33382, epoch: 35, loss: 0.801423
global_step: 33383, epoch: 35, loss: 0.872421
global_step: 33384, epoch: 35, loss: 0.856597
global_step: 33385, epoch: 35, loss: 0.935121
global_step: 33386, epoch: 35, loss: 0.875979
global_step: 33387, epoch: 35, loss: 0.998405
global_step: 33388, epoch: 35, loss: 0.937312
global_step: 33389, epoch: 35, loss: 0.857892
global_step: 33390, epoch: 35, loss: 1.006785
global_step: 33391, epoch: 35, loss: 0.953672
global_step: 33392, epoch: 35, loss: 0.853509
global_step: 33393, epoch: 35, loss: 0.847854
global_step: 33394, epoch: 35, loss: 0.866819
global_step: 33395, epoch: 35, loss: 0.874566
global_step: 33396, epoch: 35, loss: 0.905498
global_step: 33397, epoch: 35, loss: 0.924245
global_step: 33398, epoch: 35, loss: 0.851379
global_step: 33399, epoch: 35, loss: 0.825468
global_step: 33400, epoch: 35, loss: 0.864836
epoch: 35
train	acc: 0.7848	macro: p 0.6882, r 0.5206, f1: 0.5226	micro: p 0.7848, r 0.7848, f1 0.7848	weighted_f1:0.7568
dev	acc: 0.5537	macro: p 0.3600, r 0.3176, f1: 0.3100	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5043
test	acc: 0.5992	macro: p 0.3682, r 0.3235, f1: 0.3249	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5578
global_step: 33401, epoch: 36, loss: 0.889095
global_step: 33402, epoch: 36, loss: 0.905769
global_step: 33403, epoch: 36, loss: 0.938629
global_step: 33404, epoch: 36, loss: 0.879422
global_step: 33405, epoch: 36, loss: 0.822862
global_step: 33406, epoch: 36, loss: 0.742448
global_step: 33407, epoch: 36, loss: 0.783815
global_step: 33408, epoch: 36, loss: 0.943140
global_step: 33409, epoch: 36, loss: 0.898140
global_step: 33410, epoch: 36, loss: 0.780352
global_step: 33411, epoch: 36, loss: 0.846876
global_step: 33412, epoch: 36, loss: 0.780729
global_step: 33413, epoch: 36, loss: 0.908381
global_step: 33414, epoch: 36, loss: 0.839217
global_step: 33415, epoch: 36, loss: 0.894650
global_step: 33416, epoch: 36, loss: 0.822175
global_step: 33417, epoch: 36, loss: 0.816391
global_step: 33418, epoch: 36, loss: 0.812893
global_step: 33419, epoch: 36, loss: 0.820885
global_step: 33420, epoch: 36, loss: 0.881932
global_step: 33421, epoch: 36, loss: 0.861975
global_step: 33422, epoch: 36, loss: 0.908214
global_step: 33423, epoch: 36, loss: 0.908254
global_step: 33424, epoch: 36, loss: 0.843934
global_step: 33425, epoch: 36, loss: 1.052867
global_step: 33426, epoch: 36, loss: 0.920465
global_step: 33427, epoch: 36, loss: 0.916251
global_step: 33428, epoch: 36, loss: 0.836535
global_step: 33429, epoch: 36, loss: 0.982646
global_step: 33430, epoch: 36, loss: 1.026657
global_step: 33431, epoch: 36, loss: 0.964695
global_step: 33432, epoch: 36, loss: 0.865961
global_step: 33433, epoch: 36, loss: 0.977238
global_step: 33434, epoch: 36, loss: 0.810031
global_step: 33435, epoch: 36, loss: 0.839576
global_step: 33436, epoch: 36, loss: 0.956467
global_step: 33437, epoch: 36, loss: 0.906513
global_step: 33438, epoch: 36, loss: 0.876187
global_step: 33439, epoch: 36, loss: 0.782455
global_step: 33440, epoch: 36, loss: 0.660436
epoch: 36
train	acc: 0.7615	macro: p 0.6930, r 0.4837, f1: 0.4953	micro: p 0.7615, r 0.7615, f1 0.7615	weighted_f1:0.7283
dev	acc: 0.5645	macro: p 0.3556, r 0.3142, f1: 0.3078	micro: p 0.5645, r 0.5645, f1 0.5645	weighted_f1:0.5057
test	acc: 0.6142	macro: p 0.3922, r 0.3198, f1: 0.3258	micro: p 0.6142, r 0.6142, f1 0.6142	weighted_f1:0.5633
global_step: 33441, epoch: 37, loss: 0.763701
global_step: 33442, epoch: 37, loss: 0.878045
global_step: 33443, epoch: 37, loss: 0.889108
global_step: 33444, epoch: 37, loss: 0.762348
global_step: 33445, epoch: 37, loss: 0.800488
global_step: 33446, epoch: 37, loss: 0.840247
global_step: 33447, epoch: 37, loss: 0.872015
global_step: 33448, epoch: 37, loss: 0.838598
global_step: 33449, epoch: 37, loss: 0.873845
global_step: 33450, epoch: 37, loss: 0.907054
global_step: 33451, epoch: 37, loss: 0.838174
global_step: 33452, epoch: 37, loss: 0.871771
global_step: 33453, epoch: 37, loss: 0.851972
global_step: 33454, epoch: 37, loss: 0.786850
global_step: 33455, epoch: 37, loss: 0.756276
global_step: 33456, epoch: 37, loss: 0.903636
global_step: 33457, epoch: 37, loss: 0.813928
global_step: 33458, epoch: 37, loss: 0.854224
global_step: 33459, epoch: 37, loss: 0.977092
global_step: 33460, epoch: 37, loss: 0.881061
global_step: 33461, epoch: 37, loss: 1.069774
global_step: 33462, epoch: 37, loss: 0.835676
global_step: 33463, epoch: 37, loss: 0.787012
global_step: 33464, epoch: 37, loss: 0.866406
global_step: 33465, epoch: 37, loss: 0.859952
global_step: 33466, epoch: 37, loss: 0.831950
global_step: 33467, epoch: 37, loss: 0.858239
global_step: 33468, epoch: 37, loss: 0.805737
global_step: 33469, epoch: 37, loss: 0.925534
global_step: 33470, epoch: 37, loss: 0.869766
global_step: 33471, epoch: 37, loss: 0.900004
global_step: 33472, epoch: 37, loss: 0.816863
global_step: 33473, epoch: 37, loss: 0.843560
global_step: 33474, epoch: 37, loss: 0.783094
global_step: 33475, epoch: 37, loss: 0.850164
global_step: 33476, epoch: 37, loss: 0.909054
global_step: 33477, epoch: 37, loss: 0.892829
global_step: 33478, epoch: 37, loss: 0.783086
global_step: 33479, epoch: 37, loss: 0.904238
global_step: 33480, epoch: 37, loss: 0.426719
epoch: 37
train	acc: 0.8059	macro: p 0.8376, r 0.5478, f1: 0.5457	micro: p 0.8059, r 0.8059, f1 0.8059	weighted_f1:0.7789
dev	acc: 0.5473	macro: p 0.3371, r 0.3142, f1: 0.3012	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4950
test	acc: 0.5966	macro: p 0.3581, r 0.3252, f1: 0.3214	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5538
global_step: 33481, epoch: 38, loss: 0.850475
global_step: 33482, epoch: 38, loss: 0.849101
global_step: 33483, epoch: 38, loss: 0.803206
global_step: 33484, epoch: 38, loss: 0.919515
global_step: 33485, epoch: 38, loss: 0.737081
global_step: 33486, epoch: 38, loss: 0.843250
global_step: 33487, epoch: 38, loss: 0.826763
global_step: 33488, epoch: 38, loss: 0.806102
global_step: 33489, epoch: 38, loss: 0.760166
global_step: 33490, epoch: 38, loss: 0.889947
global_step: 33491, epoch: 38, loss: 0.834360
global_step: 33492, epoch: 38, loss: 0.901765
global_step: 33493, epoch: 38, loss: 0.792476
global_step: 33494, epoch: 38, loss: 0.865883
global_step: 33495, epoch: 38, loss: 0.816440
global_step: 33496, epoch: 38, loss: 0.772849
global_step: 33497, epoch: 38, loss: 0.812053
global_step: 33498, epoch: 38, loss: 0.805987
global_step: 33499, epoch: 38, loss: 0.766865
global_step: 33500, epoch: 38, loss: 0.952804
global_step: 33501, epoch: 38, loss: 0.860597
global_step: 33502, epoch: 38, loss: 0.972371
global_step: 33503, epoch: 38, loss: 0.790285
global_step: 33504, epoch: 38, loss: 0.816187
global_step: 33505, epoch: 38, loss: 0.959707
global_step: 33506, epoch: 38, loss: 0.882346
global_step: 33507, epoch: 38, loss: 0.827159
global_step: 33508, epoch: 38, loss: 0.758962
global_step: 33509, epoch: 38, loss: 0.773184
global_step: 33510, epoch: 38, loss: 0.846915
global_step: 33511, epoch: 38, loss: 0.860776
global_step: 33512, epoch: 38, loss: 0.965105
global_step: 33513, epoch: 38, loss: 0.879817
global_step: 33514, epoch: 38, loss: 0.810433
global_step: 33515, epoch: 38, loss: 0.838141
global_step: 33516, epoch: 38, loss: 0.860470
global_step: 33517, epoch: 38, loss: 0.965983
global_step: 33518, epoch: 38, loss: 0.752561
global_step: 33519, epoch: 38, loss: 0.886437
global_step: 33520, epoch: 38, loss: 1.227144
epoch: 38
train	acc: 0.8180	macro: p 0.8387, r 0.5712, f1: 0.5639	micro: p 0.8180, r 0.8180, f1 0.8180	weighted_f1:0.7943
dev	acc: 0.5464	macro: p 0.3337, r 0.3187, f1: 0.3089	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5022
test	acc: 0.5866	macro: p 0.3461, r 0.3294, f1: 0.3258	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5536
global_step: 33521, epoch: 39, loss: 0.785067
global_step: 33522, epoch: 39, loss: 0.926120
global_step: 33523, epoch: 39, loss: 0.770215
global_step: 33524, epoch: 39, loss: 0.845396
global_step: 33525, epoch: 39, loss: 0.886160
global_step: 33526, epoch: 39, loss: 0.877716
global_step: 33527, epoch: 39, loss: 0.763898
global_step: 33528, epoch: 39, loss: 0.855738
global_step: 33529, epoch: 39, loss: 0.757242
global_step: 33530, epoch: 39, loss: 0.798368
global_step: 33531, epoch: 39, loss: 0.830986
global_step: 33532, epoch: 39, loss: 0.881781
global_step: 33533, epoch: 39, loss: 0.895623
global_step: 33534, epoch: 39, loss: 0.712821
global_step: 33535, epoch: 39, loss: 0.802737
global_step: 33536, epoch: 39, loss: 0.845075
global_step: 33537, epoch: 39, loss: 0.799321
global_step: 33538, epoch: 39, loss: 0.853812
global_step: 33539, epoch: 39, loss: 0.807828
global_step: 33540, epoch: 39, loss: 0.716357
global_step: 33541, epoch: 39, loss: 0.785576
global_step: 33542, epoch: 39, loss: 0.813735
global_step: 33543, epoch: 39, loss: 0.860457
global_step: 33544, epoch: 39, loss: 0.752051
global_step: 33545, epoch: 39, loss: 0.934237
global_step: 33546, epoch: 39, loss: 0.847415
global_step: 33547, epoch: 39, loss: 0.714933
global_step: 33548, epoch: 39, loss: 0.891366
global_step: 33549, epoch: 39, loss: 0.863360
global_step: 33550, epoch: 39, loss: 0.746952
global_step: 33551, epoch: 39, loss: 0.976345
global_step: 33552, epoch: 39, loss: 0.857299
global_step: 33553, epoch: 39, loss: 0.789625
global_step: 33554, epoch: 39, loss: 0.911192
global_step: 33555, epoch: 39, loss: 0.909160
global_step: 33556, epoch: 39, loss: 0.904901
global_step: 33557, epoch: 39, loss: 0.852205
global_step: 33558, epoch: 39, loss: 0.917253
global_step: 33559, epoch: 39, loss: 0.797117
global_step: 33560, epoch: 39, loss: 1.262198
epoch: 39
train	acc: 0.8100	macro: p 0.8449, r 0.5537, f1: 0.5544	micro: p 0.8100, r 0.8100, f1 0.8100	weighted_f1:0.7846
dev	acc: 0.5500	macro: p 0.3331, r 0.3124, f1: 0.3048	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4998
test	acc: 0.6000	macro: p 0.3602, r 0.3252, f1: 0.3267	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5589
global_step: 33561, epoch: 40, loss: 0.807166
global_step: 33562, epoch: 40, loss: 0.834220
global_step: 33563, epoch: 40, loss: 0.870775
global_step: 33564, epoch: 40, loss: 0.734143
global_step: 33565, epoch: 40, loss: 0.911223
global_step: 33566, epoch: 40, loss: 0.846525
global_step: 33567, epoch: 40, loss: 0.840143
global_step: 33568, epoch: 40, loss: 0.764040
global_step: 33569, epoch: 40, loss: 0.741897
global_step: 33570, epoch: 40, loss: 0.854284
global_step: 33571, epoch: 40, loss: 0.675451
global_step: 33572, epoch: 40, loss: 0.786654
global_step: 33573, epoch: 40, loss: 0.840767
global_step: 33574, epoch: 40, loss: 0.808903
global_step: 33575, epoch: 40, loss: 0.686075
global_step: 33576, epoch: 40, loss: 0.669569
global_step: 33577, epoch: 40, loss: 0.858279
global_step: 33578, epoch: 40, loss: 0.825988
global_step: 33579, epoch: 40, loss: 0.727681
global_step: 33580, epoch: 40, loss: 0.834133
global_step: 33581, epoch: 40, loss: 0.965644
global_step: 33582, epoch: 40, loss: 0.774086
global_step: 33583, epoch: 40, loss: 0.859033
global_step: 33584, epoch: 40, loss: 0.818935
global_step: 33585, epoch: 40, loss: 0.831567
global_step: 33586, epoch: 40, loss: 0.898523
global_step: 33587, epoch: 40, loss: 0.754227
global_step: 33588, epoch: 40, loss: 0.706313
global_step: 33589, epoch: 40, loss: 0.906202
global_step: 33590, epoch: 40, loss: 0.928426
global_step: 33591, epoch: 40, loss: 0.827102
global_step: 33592, epoch: 40, loss: 0.900627
global_step: 33593, epoch: 40, loss: 0.743037
global_step: 33594, epoch: 40, loss: 0.883390
global_step: 33595, epoch: 40, loss: 0.801301
global_step: 33596, epoch: 40, loss: 0.778838
global_step: 33597, epoch: 40, loss: 0.843677
global_step: 33598, epoch: 40, loss: 0.804527
global_step: 33599, epoch: 40, loss: 0.806658
global_step: 33600, epoch: 40, loss: 0.473949
epoch: 40
train	acc: 0.7907	macro: p 0.8476, r 0.5236, f1: 0.5372	micro: p 0.7907, r 0.7907, f1 0.7907	weighted_f1:0.7622
dev	acc: 0.5518	macro: p 0.3548, r 0.3021, f1: 0.2951	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4911
test	acc: 0.6115	macro: p 0.3820, r 0.3165, f1: 0.3223	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5587
global_step: 33601, epoch: 41, loss: 0.853019
global_step: 33602, epoch: 41, loss: 0.834658
global_step: 33603, epoch: 41, loss: 0.796342
global_step: 33604, epoch: 41, loss: 0.860822
global_step: 33605, epoch: 41, loss: 0.799766
global_step: 33606, epoch: 41, loss: 0.844119
global_step: 33607, epoch: 41, loss: 0.771145
global_step: 33608, epoch: 41, loss: 0.768899
global_step: 33609, epoch: 41, loss: 0.822227
global_step: 33610, epoch: 41, loss: 0.879350
global_step: 33611, epoch: 41, loss: 0.858511
global_step: 33612, epoch: 41, loss: 0.920179
global_step: 33613, epoch: 41, loss: 0.788711
global_step: 33614, epoch: 41, loss: 0.730202
global_step: 33615, epoch: 41, loss: 0.819472
global_step: 33616, epoch: 41, loss: 0.732552
global_step: 33617, epoch: 41, loss: 0.787725
global_step: 33618, epoch: 41, loss: 0.801608
global_step: 33619, epoch: 41, loss: 0.826500
global_step: 33620, epoch: 41, loss: 0.753996
global_step: 33621, epoch: 41, loss: 0.739739
global_step: 33622, epoch: 41, loss: 0.808301
global_step: 33623, epoch: 41, loss: 0.827147
global_step: 33624, epoch: 41, loss: 0.718509
global_step: 33625, epoch: 41, loss: 0.904918
global_step: 33626, epoch: 41, loss: 0.803894
global_step: 33627, epoch: 41, loss: 0.785391
global_step: 33628, epoch: 41, loss: 0.767656
global_step: 33629, epoch: 41, loss: 0.827438
global_step: 33630, epoch: 41, loss: 0.770182
global_step: 33631, epoch: 41, loss: 0.811427
global_step: 33632, epoch: 41, loss: 0.830361
global_step: 33633, epoch: 41, loss: 0.832072
global_step: 33634, epoch: 41, loss: 0.806281
global_step: 33635, epoch: 41, loss: 0.853121
global_step: 33636, epoch: 41, loss: 0.713674
global_step: 33637, epoch: 41, loss: 0.813447
global_step: 33638, epoch: 41, loss: 0.724625
global_step: 33639, epoch: 41, loss: 0.842324
global_step: 33640, epoch: 41, loss: 0.510898
epoch: 41
train	acc: 0.8220	macro: p 0.8575, r 0.5666, f1: 0.5698	micro: p 0.8220, r 0.8220, f1 0.8220	weighted_f1:0.7966
dev	acc: 0.5500	macro: p 0.3591, r 0.3125, f1: 0.3017	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4961
test	acc: 0.5958	macro: p 0.3636, r 0.3183, f1: 0.3181	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5514
global_step: 33641, epoch: 42, loss: 0.760400
global_step: 33642, epoch: 42, loss: 0.796017
global_step: 33643, epoch: 42, loss: 0.773494
global_step: 33644, epoch: 42, loss: 0.905134
global_step: 33645, epoch: 42, loss: 0.775905
global_step: 33646, epoch: 42, loss: 0.931185
global_step: 33647, epoch: 42, loss: 0.829935
global_step: 33648, epoch: 42, loss: 0.823676
global_step: 33649, epoch: 42, loss: 0.728831
global_step: 33650, epoch: 42, loss: 0.788140
global_step: 33651, epoch: 42, loss: 0.699466
global_step: 33652, epoch: 42, loss: 0.750034
global_step: 33653, epoch: 42, loss: 0.801737
global_step: 33654, epoch: 42, loss: 0.810422
global_step: 33655, epoch: 42, loss: 0.856919
global_step: 33656, epoch: 42, loss: 0.723204
global_step: 33657, epoch: 42, loss: 0.778795
global_step: 33658, epoch: 42, loss: 0.696836
global_step: 33659, epoch: 42, loss: 0.785153
global_step: 33660, epoch: 42, loss: 0.823393
global_step: 33661, epoch: 42, loss: 0.684539
global_step: 33662, epoch: 42, loss: 0.851602
global_step: 33663, epoch: 42, loss: 0.776201
global_step: 33664, epoch: 42, loss: 0.795717
global_step: 33665, epoch: 42, loss: 0.731525
global_step: 33666, epoch: 42, loss: 0.683735
global_step: 33667, epoch: 42, loss: 0.811270
global_step: 33668, epoch: 42, loss: 0.850180
global_step: 33669, epoch: 42, loss: 0.811503
global_step: 33670, epoch: 42, loss: 0.812337
global_step: 33671, epoch: 42, loss: 0.731278
global_step: 33672, epoch: 42, loss: 0.729524
global_step: 33673, epoch: 42, loss: 0.819984
global_step: 33674, epoch: 42, loss: 0.828827
global_step: 33675, epoch: 42, loss: 0.831912
global_step: 33676, epoch: 42, loss: 0.828354
global_step: 33677, epoch: 42, loss: 0.796376
global_step: 33678, epoch: 42, loss: 0.775361
global_step: 33679, epoch: 42, loss: 0.690999
global_step: 33680, epoch: 42, loss: 1.115802
epoch: 42
train	acc: 0.8293	macro: p 0.8510, r 0.5865, f1: 0.6020	micro: p 0.8293, r 0.8293, f1 0.8293	weighted_f1:0.8072
dev	acc: 0.5546	macro: p 0.3448, r 0.3129, f1: 0.3034	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4990
test	acc: 0.6023	macro: p 0.3629, r 0.3183, f1: 0.3212	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5560
global_step: 33681, epoch: 43, loss: 0.781973
global_step: 33682, epoch: 43, loss: 0.703407
global_step: 33683, epoch: 43, loss: 0.790826
global_step: 33684, epoch: 43, loss: 0.709381
global_step: 33685, epoch: 43, loss: 0.657902
global_step: 33686, epoch: 43, loss: 0.780693
global_step: 33687, epoch: 43, loss: 0.801277
global_step: 33688, epoch: 43, loss: 0.705307
global_step: 33689, epoch: 43, loss: 0.731106
global_step: 33690, epoch: 43, loss: 0.849823
global_step: 33691, epoch: 43, loss: 0.711793
global_step: 33692, epoch: 43, loss: 0.705783
global_step: 33693, epoch: 43, loss: 0.804752
global_step: 33694, epoch: 43, loss: 0.694375
global_step: 33695, epoch: 43, loss: 0.846606
global_step: 33696, epoch: 43, loss: 0.734952
global_step: 33697, epoch: 43, loss: 0.702092
global_step: 33698, epoch: 43, loss: 0.871067
global_step: 33699, epoch: 43, loss: 0.780241
global_step: 33700, epoch: 43, loss: 0.870929
global_step: 33701, epoch: 43, loss: 0.712830
global_step: 33702, epoch: 43, loss: 0.715479
global_step: 33703, epoch: 43, loss: 0.742619
global_step: 33704, epoch: 43, loss: 0.806757
global_step: 33705, epoch: 43, loss: 0.764618
global_step: 33706, epoch: 43, loss: 0.898777
global_step: 33707, epoch: 43, loss: 0.709938
global_step: 33708, epoch: 43, loss: 0.804577
global_step: 33709, epoch: 43, loss: 0.832849
global_step: 33710, epoch: 43, loss: 0.878104
global_step: 33711, epoch: 43, loss: 0.683163
global_step: 33712, epoch: 43, loss: 0.778778
global_step: 33713, epoch: 43, loss: 0.737959
global_step: 33714, epoch: 43, loss: 0.772175
global_step: 33715, epoch: 43, loss: 0.690269
global_step: 33716, epoch: 43, loss: 0.880169
global_step: 33717, epoch: 43, loss: 0.817767
global_step: 33718, epoch: 43, loss: 0.749794
global_step: 33719, epoch: 43, loss: 0.884217
global_step: 33720, epoch: 43, loss: 0.184664
epoch: 43
train	acc: 0.8347	macro: p 0.8620, r 0.5879, f1: 0.5905	micro: p 0.8347, r 0.8347, f1 0.8347	weighted_f1:0.8110
dev	acc: 0.5446	macro: p 0.3426, r 0.3106, f1: 0.2970	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4913
test	acc: 0.5927	macro: p 0.3592, r 0.3205, f1: 0.3167	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5495
global_step: 33721, epoch: 44, loss: 0.768474
global_step: 33722, epoch: 44, loss: 0.816918
global_step: 33723, epoch: 44, loss: 0.823203
global_step: 33724, epoch: 44, loss: 0.760626
global_step: 33725, epoch: 44, loss: 0.916814
global_step: 33726, epoch: 44, loss: 0.728706
global_step: 33727, epoch: 44, loss: 0.706303
global_step: 33728, epoch: 44, loss: 0.659518
global_step: 33729, epoch: 44, loss: 0.742229
global_step: 33730, epoch: 44, loss: 0.767235
global_step: 33731, epoch: 44, loss: 0.630662
global_step: 33732, epoch: 44, loss: 0.729712
global_step: 33733, epoch: 44, loss: 0.698765
global_step: 33734, epoch: 44, loss: 0.739744
global_step: 33735, epoch: 44, loss: 0.670266
global_step: 33736, epoch: 44, loss: 0.730250
global_step: 33737, epoch: 44, loss: 0.733340
global_step: 33738, epoch: 44, loss: 0.786955
global_step: 33739, epoch: 44, loss: 0.871001
global_step: 33740, epoch: 44, loss: 0.747398
global_step: 33741, epoch: 44, loss: 0.692574
global_step: 33742, epoch: 44, loss: 0.750340
global_step: 33743, epoch: 44, loss: 0.720769
global_step: 33744, epoch: 44, loss: 0.733572
global_step: 33745, epoch: 44, loss: 0.698854
global_step: 33746, epoch: 44, loss: 0.729678
global_step: 33747, epoch: 44, loss: 0.693137
global_step: 33748, epoch: 44, loss: 0.652880
global_step: 33749, epoch: 44, loss: 0.775199
global_step: 33750, epoch: 44, loss: 0.821331
global_step: 33751, epoch: 44, loss: 0.754098
global_step: 33752, epoch: 44, loss: 0.854756
global_step: 33753, epoch: 44, loss: 0.760857
global_step: 33754, epoch: 44, loss: 0.833094
global_step: 33755, epoch: 44, loss: 0.737000
global_step: 33756, epoch: 44, loss: 0.779363
global_step: 33757, epoch: 44, loss: 0.858388
global_step: 33758, epoch: 44, loss: 0.856785
global_step: 33759, epoch: 44, loss: 0.849074
global_step: 33760, epoch: 44, loss: 0.533283
epoch: 44
train	acc: 0.8444	macro: p 0.8411, r 0.6182, f1: 0.6207	micro: p 0.8444, r 0.8444, f1 0.8444	weighted_f1:0.8255
dev	acc: 0.5275	macro: p 0.3179, r 0.3103, f1: 0.2965	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4860
test	acc: 0.5831	macro: p 0.3462, r 0.3325, f1: 0.3248	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5502
global_step: 33761, epoch: 45, loss: 0.761250
global_step: 33762, epoch: 45, loss: 0.778131
global_step: 33763, epoch: 45, loss: 0.776120
global_step: 33764, epoch: 45, loss: 0.818394
global_step: 33765, epoch: 45, loss: 0.680969
global_step: 33766, epoch: 45, loss: 0.798470
global_step: 33767, epoch: 45, loss: 0.743825
global_step: 33768, epoch: 45, loss: 0.761135
global_step: 33769, epoch: 45, loss: 0.764448
global_step: 33770, epoch: 45, loss: 0.746343
global_step: 33771, epoch: 45, loss: 0.740439
global_step: 33772, epoch: 45, loss: 0.828274
global_step: 33773, epoch: 45, loss: 0.679522
global_step: 33774, epoch: 45, loss: 0.807348
global_step: 33775, epoch: 45, loss: 0.756370
global_step: 33776, epoch: 45, loss: 0.709863
global_step: 33777, epoch: 45, loss: 0.703057
global_step: 33778, epoch: 45, loss: 0.803173
global_step: 33779, epoch: 45, loss: 0.718518
global_step: 33780, epoch: 45, loss: 0.771420
global_step: 33781, epoch: 45, loss: 0.669008
global_step: 33782, epoch: 45, loss: 0.803859
global_step: 33783, epoch: 45, loss: 0.750164
global_step: 33784, epoch: 45, loss: 0.772067
global_step: 33785, epoch: 45, loss: 0.692955
global_step: 33786, epoch: 45, loss: 0.774357
global_step: 33787, epoch: 45, loss: 0.740112
global_step: 33788, epoch: 45, loss: 0.767781
global_step: 33789, epoch: 45, loss: 0.770789
global_step: 33790, epoch: 45, loss: 0.828433
global_step: 33791, epoch: 45, loss: 0.831157
global_step: 33792, epoch: 45, loss: 0.714177
global_step: 33793, epoch: 45, loss: 0.787709
global_step: 33794, epoch: 45, loss: 0.772912
global_step: 33795, epoch: 45, loss: 0.771822
global_step: 33796, epoch: 45, loss: 0.738280
global_step: 33797, epoch: 45, loss: 0.721300
global_step: 33798, epoch: 45, loss: 0.808613
global_step: 33799, epoch: 45, loss: 0.699654
global_step: 33800, epoch: 45, loss: 0.478738
epoch: 45
train	acc: 0.8384	macro: p 0.8720, r 0.5974, f1: 0.6111	micro: p 0.8384, r 0.8384, f1 0.8384	weighted_f1:0.8164
dev	acc: 0.5591	macro: p 0.3468, r 0.3153, f1: 0.3072	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5029
test	acc: 0.6027	macro: p 0.3536, r 0.3166, f1: 0.3183	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5540
global_step: 33801, epoch: 46, loss: 0.698386
global_step: 33802, epoch: 46, loss: 0.713974
global_step: 33803, epoch: 46, loss: 0.701021
global_step: 33804, epoch: 46, loss: 0.761191
global_step: 33805, epoch: 46, loss: 0.614728
global_step: 33806, epoch: 46, loss: 0.771762
global_step: 33807, epoch: 46, loss: 0.676003
global_step: 33808, epoch: 46, loss: 0.722158
global_step: 33809, epoch: 46, loss: 0.656113
global_step: 33810, epoch: 46, loss: 0.677590
global_step: 33811, epoch: 46, loss: 0.762453
global_step: 33812, epoch: 46, loss: 0.689720
global_step: 33813, epoch: 46, loss: 0.762890
global_step: 33814, epoch: 46, loss: 0.789790
global_step: 33815, epoch: 46, loss: 0.737881
global_step: 33816, epoch: 46, loss: 0.689358
global_step: 33817, epoch: 46, loss: 0.868894
global_step: 33818, epoch: 46, loss: 0.650937
global_step: 33819, epoch: 46, loss: 0.646038
global_step: 33820, epoch: 46, loss: 0.767939
global_step: 33821, epoch: 46, loss: 0.759049
global_step: 33822, epoch: 46, loss: 0.782571
global_step: 33823, epoch: 46, loss: 0.828817
global_step: 33824, epoch: 46, loss: 0.749651
global_step: 33825, epoch: 46, loss: 0.763998
global_step: 33826, epoch: 46, loss: 0.670410
global_step: 33827, epoch: 46, loss: 0.755930
global_step: 33828, epoch: 46, loss: 0.782295
global_step: 33829, epoch: 46, loss: 0.698237
global_step: 33830, epoch: 46, loss: 0.765062
global_step: 33831, epoch: 46, loss: 0.759587
global_step: 33832, epoch: 46, loss: 0.742293
global_step: 33833, epoch: 46, loss: 0.736408
global_step: 33834, epoch: 46, loss: 0.717190
global_step: 33835, epoch: 46, loss: 0.814877
global_step: 33836, epoch: 46, loss: 0.792576
global_step: 33837, epoch: 46, loss: 0.669247
global_step: 33838, epoch: 46, loss: 0.857755
global_step: 33839, epoch: 46, loss: 0.737032
global_step: 33840, epoch: 46, loss: 0.494023
epoch: 46
train	acc: 0.8544	macro: p 0.8570, r 0.6315, f1: 0.6387	micro: p 0.8544, r 0.8544, f1 0.8544	weighted_f1:0.8365
dev	acc: 0.5464	macro: p 0.3292, r 0.3169, f1: 0.3074	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5021
test	acc: 0.5885	macro: p 0.3417, r 0.3249, f1: 0.3225	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5529
global_step: 33841, epoch: 47, loss: 0.667679
global_step: 33842, epoch: 47, loss: 0.712319
global_step: 33843, epoch: 47, loss: 0.638772
global_step: 33844, epoch: 47, loss: 0.707608
global_step: 33845, epoch: 47, loss: 0.722071
global_step: 33846, epoch: 47, loss: 0.644036
global_step: 33847, epoch: 47, loss: 0.658765
global_step: 33848, epoch: 47, loss: 0.745409
global_step: 33849, epoch: 47, loss: 0.688802
global_step: 33850, epoch: 47, loss: 0.722491
global_step: 33851, epoch: 47, loss: 0.687619
global_step: 33852, epoch: 47, loss: 0.739633
global_step: 33853, epoch: 47, loss: 0.696879
global_step: 33854, epoch: 47, loss: 0.675436
global_step: 33855, epoch: 47, loss: 0.706818
global_step: 33856, epoch: 47, loss: 0.696967
global_step: 33857, epoch: 47, loss: 0.761173
global_step: 33858, epoch: 47, loss: 0.722310
global_step: 33859, epoch: 47, loss: 0.793052
global_step: 33860, epoch: 47, loss: 0.619676
global_step: 33861, epoch: 47, loss: 0.704897
global_step: 33862, epoch: 47, loss: 0.715251
global_step: 33863, epoch: 47, loss: 0.735531
global_step: 33864, epoch: 47, loss: 0.665286
global_step: 33865, epoch: 47, loss: 0.693908
global_step: 33866, epoch: 47, loss: 0.767980
global_step: 33867, epoch: 47, loss: 0.658843
global_step: 33868, epoch: 47, loss: 0.776648
global_step: 33869, epoch: 47, loss: 0.770264
global_step: 33870, epoch: 47, loss: 0.783974
global_step: 33871, epoch: 47, loss: 0.691686
global_step: 33872, epoch: 47, loss: 0.779162
global_step: 33873, epoch: 47, loss: 0.719127
global_step: 33874, epoch: 47, loss: 0.810671
global_step: 33875, epoch: 47, loss: 0.802187
global_step: 33876, epoch: 47, loss: 0.736960
global_step: 33877, epoch: 47, loss: 0.795495
global_step: 33878, epoch: 47, loss: 0.751644
global_step: 33879, epoch: 47, loss: 0.689177
global_step: 33880, epoch: 47, loss: 1.432136
epoch: 47
train	acc: 0.8639	macro: p 0.8684, r 0.6539, f1: 0.6765	micro: p 0.8639, r 0.8639, f1 0.8639	weighted_f1:0.8483
dev	acc: 0.5528	macro: p 0.3355, r 0.3155, f1: 0.3086	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5016
test	acc: 0.6046	macro: p 0.3937, r 0.3272, f1: 0.3322	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5620
global_step: 33881, epoch: 48, loss: 0.747212
global_step: 33882, epoch: 48, loss: 0.719820
global_step: 33883, epoch: 48, loss: 0.678262
global_step: 33884, epoch: 48, loss: 0.680129
global_step: 33885, epoch: 48, loss: 0.700074
global_step: 33886, epoch: 48, loss: 0.707350
global_step: 33887, epoch: 48, loss: 0.627295
global_step: 33888, epoch: 48, loss: 0.666346
global_step: 33889, epoch: 48, loss: 0.718379
global_step: 33890, epoch: 48, loss: 0.678964
global_step: 33891, epoch: 48, loss: 0.668635
global_step: 33892, epoch: 48, loss: 0.619473
global_step: 33893, epoch: 48, loss: 0.762915
global_step: 33894, epoch: 48, loss: 0.581522
global_step: 33895, epoch: 48, loss: 0.645385
global_step: 33896, epoch: 48, loss: 0.748839
global_step: 33897, epoch: 48, loss: 0.711113
global_step: 33898, epoch: 48, loss: 0.726893
global_step: 33899, epoch: 48, loss: 0.698924
global_step: 33900, epoch: 48, loss: 0.539462
global_step: 33901, epoch: 48, loss: 0.752187
global_step: 33902, epoch: 48, loss: 0.692185
global_step: 33903, epoch: 48, loss: 0.708806
global_step: 33904, epoch: 48, loss: 0.659486
global_step: 33905, epoch: 48, loss: 0.686376
global_step: 33906, epoch: 48, loss: 0.698525
global_step: 33907, epoch: 48, loss: 0.662278
global_step: 33908, epoch: 48, loss: 0.776929
global_step: 33909, epoch: 48, loss: 0.753762
global_step: 33910, epoch: 48, loss: 0.818842
global_step: 33911, epoch: 48, loss: 0.672375
global_step: 33912, epoch: 48, loss: 0.698233
global_step: 33913, epoch: 48, loss: 0.692241
global_step: 33914, epoch: 48, loss: 0.739321
global_step: 33915, epoch: 48, loss: 0.750913
global_step: 33916, epoch: 48, loss: 0.746647
global_step: 33917, epoch: 48, loss: 0.683264
global_step: 33918, epoch: 48, loss: 0.741822
global_step: 33919, epoch: 48, loss: 0.714891
global_step: 33920, epoch: 48, loss: 0.324448
epoch: 48
train	acc: 0.8581	macro: p 0.8762, r 0.6332, f1: 0.6450	micro: p 0.8581, r 0.8581, f1 0.8581	weighted_f1:0.8394
dev	acc: 0.5446	macro: p 0.3236, r 0.3101, f1: 0.3004	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4942
test	acc: 0.6000	macro: p 0.3629, r 0.3237, f1: 0.3250	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5581
global_step: 33921, epoch: 49, loss: 0.622019
global_step: 33922, epoch: 49, loss: 0.667077
global_step: 33923, epoch: 49, loss: 0.714223
global_step: 33924, epoch: 49, loss: 0.709032
global_step: 33925, epoch: 49, loss: 0.657656
global_step: 33926, epoch: 49, loss: 0.658183
global_step: 33927, epoch: 49, loss: 0.589715
global_step: 33928, epoch: 49, loss: 0.714413
global_step: 33929, epoch: 49, loss: 0.632041
global_step: 33930, epoch: 49, loss: 0.623056
global_step: 33931, epoch: 49, loss: 0.708358
global_step: 33932, epoch: 49, loss: 0.715495
global_step: 33933, epoch: 49, loss: 0.600709
global_step: 33934, epoch: 49, loss: 0.636854
global_step: 33935, epoch: 49, loss: 0.703520
global_step: 33936, epoch: 49, loss: 0.780016
global_step: 33937, epoch: 49, loss: 0.720267
global_step: 33938, epoch: 49, loss: 0.636074
global_step: 33939, epoch: 49, loss: 0.597267
global_step: 33940, epoch: 49, loss: 0.764937
global_step: 33941, epoch: 49, loss: 0.700924
global_step: 33942, epoch: 49, loss: 0.759465
global_step: 33943, epoch: 49, loss: 0.743675
global_step: 33944, epoch: 49, loss: 0.703925
global_step: 33945, epoch: 49, loss: 0.757424
global_step: 33946, epoch: 49, loss: 0.786208
global_step: 33947, epoch: 49, loss: 0.771155
global_step: 33948, epoch: 49, loss: 0.705837
global_step: 33949, epoch: 49, loss: 0.776128
global_step: 33950, epoch: 49, loss: 0.667174
global_step: 33951, epoch: 49, loss: 0.737992
global_step: 33952, epoch: 49, loss: 0.732925
global_step: 33953, epoch: 49, loss: 0.667051
global_step: 33954, epoch: 49, loss: 0.840615
global_step: 33955, epoch: 49, loss: 0.724718
global_step: 33956, epoch: 49, loss: 0.755211
global_step: 33957, epoch: 49, loss: 0.645807
global_step: 33958, epoch: 49, loss: 0.817000
global_step: 33959, epoch: 49, loss: 0.656629
global_step: 33960, epoch: 49, loss: 0.426615
epoch: 49
train	acc: 0.8508	macro: p 0.8814, r 0.6232, f1: 0.6448	micro: p 0.8508, r 0.8508, f1 0.8508	weighted_f1:0.8339
dev	acc: 0.5437	macro: p 0.3464, r 0.3100, f1: 0.3016	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4960
test	acc: 0.5962	macro: p 0.3665, r 0.3202, f1: 0.3199	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5545
global_step: 33961, epoch: 50, loss: 0.728336
global_step: 33962, epoch: 50, loss: 0.761194
global_step: 33963, epoch: 50, loss: 0.694089
global_step: 33964, epoch: 50, loss: 0.666924
global_step: 33965, epoch: 50, loss: 0.805267
global_step: 33966, epoch: 50, loss: 0.617928
global_step: 33967, epoch: 50, loss: 0.664586
global_step: 33968, epoch: 50, loss: 0.667281
global_step: 33969, epoch: 50, loss: 0.660051
global_step: 33970, epoch: 50, loss: 0.628398
global_step: 33971, epoch: 50, loss: 0.685672
global_step: 33972, epoch: 50, loss: 0.647366
global_step: 33973, epoch: 50, loss: 0.744519
global_step: 33974, epoch: 50, loss: 0.612705
global_step: 33975, epoch: 50, loss: 0.719103
global_step: 33976, epoch: 50, loss: 0.707808
global_step: 33977, epoch: 50, loss: 0.722877
global_step: 33978, epoch: 50, loss: 0.763193
global_step: 33979, epoch: 50, loss: 0.672809
global_step: 33980, epoch: 50, loss: 0.779825
global_step: 33981, epoch: 50, loss: 0.663334
global_step: 33982, epoch: 50, loss: 0.764557
global_step: 33983, epoch: 50, loss: 0.689592
global_step: 33984, epoch: 50, loss: 0.704010
global_step: 33985, epoch: 50, loss: 0.641635
global_step: 33986, epoch: 50, loss: 0.731272
global_step: 33987, epoch: 50, loss: 0.618495
global_step: 33988, epoch: 50, loss: 0.639788
global_step: 33989, epoch: 50, loss: 0.615337
global_step: 33990, epoch: 50, loss: 0.606703
global_step: 33991, epoch: 50, loss: 0.699952
global_step: 33992, epoch: 50, loss: 0.736333
global_step: 33993, epoch: 50, loss: 0.719178
global_step: 33994, epoch: 50, loss: 0.655046
global_step: 33995, epoch: 50, loss: 0.655205
global_step: 33996, epoch: 50, loss: 0.679687
global_step: 33997, epoch: 50, loss: 0.649653
global_step: 33998, epoch: 50, loss: 0.684810
global_step: 33999, epoch: 50, loss: 0.656014
global_step: 34000, epoch: 50, loss: 1.150126
epoch: 50
train	acc: 0.8663	macro: p 0.8846, r 0.6616, f1: 0.6884	micro: p 0.8663, r 0.8663, f1 0.8663	weighted_f1:0.8520
dev	acc: 0.5627	macro: p 0.3477, r 0.3277, f1: 0.3205	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5145
test	acc: 0.5985	macro: p 0.3501, r 0.3228, f1: 0.3206	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5548
global_step: 34001, epoch: 51, loss: 0.663633
global_step: 34002, epoch: 51, loss: 0.737578
global_step: 34003, epoch: 51, loss: 0.693282
global_step: 34004, epoch: 51, loss: 0.739115
global_step: 34005, epoch: 51, loss: 0.718735
global_step: 34006, epoch: 51, loss: 0.669988
global_step: 34007, epoch: 51, loss: 0.620923
global_step: 34008, epoch: 51, loss: 0.669174
global_step: 34009, epoch: 51, loss: 0.585645
global_step: 34010, epoch: 51, loss: 0.722990
global_step: 34011, epoch: 51, loss: 0.674705
global_step: 34012, epoch: 51, loss: 0.750192
global_step: 34013, epoch: 51, loss: 0.662359
global_step: 34014, epoch: 51, loss: 0.648535
global_step: 34015, epoch: 51, loss: 0.676546
global_step: 34016, epoch: 51, loss: 0.642862
global_step: 34017, epoch: 51, loss: 0.642963
global_step: 34018, epoch: 51, loss: 0.559827
global_step: 34019, epoch: 51, loss: 0.625272
global_step: 34020, epoch: 51, loss: 0.551815
global_step: 34021, epoch: 51, loss: 0.751321
global_step: 34022, epoch: 51, loss: 0.609660
global_step: 34023, epoch: 51, loss: 0.741334
global_step: 34024, epoch: 51, loss: 0.647868
global_step: 34025, epoch: 51, loss: 0.585924
global_step: 34026, epoch: 51, loss: 0.706934
global_step: 34027, epoch: 51, loss: 0.746531
global_step: 34028, epoch: 51, loss: 0.618504
global_step: 34029, epoch: 51, loss: 0.661399
global_step: 34030, epoch: 51, loss: 0.632108
global_step: 34031, epoch: 51, loss: 0.636541
global_step: 34032, epoch: 51, loss: 0.612130
global_step: 34033, epoch: 51, loss: 0.635453
global_step: 34034, epoch: 51, loss: 0.736298
global_step: 34035, epoch: 51, loss: 0.617681
global_step: 34036, epoch: 51, loss: 0.652322
global_step: 34037, epoch: 51, loss: 0.714770
global_step: 34038, epoch: 51, loss: 0.735299
global_step: 34039, epoch: 51, loss: 0.716582
global_step: 34040, epoch: 51, loss: 0.430504
epoch: 51
train	acc: 0.8749	macro: p 0.8776, r 0.6756, f1: 0.6961	micro: p 0.8749, r 0.8749, f1 0.8749	weighted_f1:0.8613
dev	acc: 0.5365	macro: p 0.3196, r 0.3105, f1: 0.2998	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4921
test	acc: 0.5904	macro: p 0.3452, r 0.3268, f1: 0.3249	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5538
global_step: 34041, epoch: 52, loss: 0.578122
global_step: 34042, epoch: 52, loss: 0.676766
global_step: 34043, epoch: 52, loss: 0.561771
global_step: 34044, epoch: 52, loss: 0.713853
global_step: 34045, epoch: 52, loss: 0.829754
global_step: 34046, epoch: 52, loss: 0.576931
global_step: 34047, epoch: 52, loss: 0.740610
global_step: 34048, epoch: 52, loss: 0.630609
global_step: 34049, epoch: 52, loss: 0.680426
global_step: 34050, epoch: 52, loss: 0.632299
global_step: 34051, epoch: 52, loss: 0.626360
global_step: 34052, epoch: 52, loss: 0.609396
global_step: 34053, epoch: 52, loss: 0.755578
global_step: 34054, epoch: 52, loss: 0.603032
global_step: 34055, epoch: 52, loss: 0.707655
global_step: 34056, epoch: 52, loss: 0.620716
global_step: 34057, epoch: 52, loss: 0.671834
global_step: 34058, epoch: 52, loss: 0.734969
global_step: 34059, epoch: 52, loss: 0.651232
global_step: 34060, epoch: 52, loss: 0.645108
global_step: 34061, epoch: 52, loss: 0.647981
global_step: 34062, epoch: 52, loss: 0.674955
global_step: 34063, epoch: 52, loss: 0.747375
global_step: 34064, epoch: 52, loss: 0.612360
global_step: 34065, epoch: 52, loss: 0.647327
global_step: 34066, epoch: 52, loss: 0.733161
global_step: 34067, epoch: 52, loss: 0.681293
global_step: 34068, epoch: 52, loss: 0.718201
global_step: 34069, epoch: 52, loss: 0.630556
global_step: 34070, epoch: 52, loss: 0.638384
global_step: 34071, epoch: 52, loss: 0.720981
global_step: 34072, epoch: 52, loss: 0.664927
global_step: 34073, epoch: 52, loss: 0.643284
global_step: 34074, epoch: 52, loss: 0.698673
global_step: 34075, epoch: 52, loss: 0.633262
global_step: 34076, epoch: 52, loss: 0.619570
global_step: 34077, epoch: 52, loss: 0.690038
global_step: 34078, epoch: 52, loss: 0.633802
global_step: 34079, epoch: 52, loss: 0.607303
global_step: 34080, epoch: 52, loss: 0.442929
epoch: 52
train	acc: 0.8854	macro: p 0.8865, r 0.7158, f1: 0.7507	micro: p 0.8854, r 0.8854, f1 0.8854	weighted_f1:0.8762
dev	acc: 0.5509	macro: p 0.3265, r 0.3163, f1: 0.3079	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5024
test	acc: 0.6015	macro: p 0.3857, r 0.3284, f1: 0.3307	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5599
global_step: 34081, epoch: 53, loss: 0.624973
global_step: 34082, epoch: 53, loss: 0.547709
global_step: 34083, epoch: 53, loss: 0.697161
global_step: 34084, epoch: 53, loss: 0.620279
global_step: 34085, epoch: 53, loss: 0.718999
global_step: 34086, epoch: 53, loss: 0.747191
global_step: 34087, epoch: 53, loss: 0.722138
global_step: 34088, epoch: 53, loss: 0.616562
global_step: 34089, epoch: 53, loss: 0.673910
global_step: 34090, epoch: 53, loss: 0.789737
global_step: 34091, epoch: 53, loss: 0.552943
global_step: 34092, epoch: 53, loss: 0.609267
global_step: 34093, epoch: 53, loss: 0.726675
global_step: 34094, epoch: 53, loss: 0.654081
global_step: 34095, epoch: 53, loss: 0.674028
global_step: 34096, epoch: 53, loss: 0.572776
global_step: 34097, epoch: 53, loss: 0.709309
global_step: 34098, epoch: 53, loss: 0.598904
global_step: 34099, epoch: 53, loss: 0.616517
global_step: 34100, epoch: 53, loss: 0.775766
global_step: 34101, epoch: 53, loss: 0.708691
global_step: 34102, epoch: 53, loss: 0.608395
global_step: 34103, epoch: 53, loss: 0.575657
global_step: 34104, epoch: 53, loss: 0.728085
global_step: 34105, epoch: 53, loss: 0.699224
global_step: 34106, epoch: 53, loss: 0.488838
global_step: 34107, epoch: 53, loss: 0.556203
global_step: 34108, epoch: 53, loss: 0.629915
global_step: 34109, epoch: 53, loss: 0.620974
global_step: 34110, epoch: 53, loss: 0.698459
global_step: 34111, epoch: 53, loss: 0.562109
global_step: 34112, epoch: 53, loss: 0.657613
global_step: 34113, epoch: 53, loss: 0.661885
global_step: 34114, epoch: 53, loss: 0.654555
global_step: 34115, epoch: 53, loss: 0.582438
global_step: 34116, epoch: 53, loss: 0.719183
global_step: 34117, epoch: 53, loss: 0.686391
global_step: 34118, epoch: 53, loss: 0.630712
global_step: 34119, epoch: 53, loss: 0.667130
global_step: 34120, epoch: 53, loss: 0.632035
epoch: 53
train	acc: 0.8742	macro: p 0.8993, r 0.6834, f1: 0.7232	micro: p 0.8742, r 0.8742, f1 0.8742	weighted_f1:0.8629
dev	acc: 0.5528	macro: p 0.3496, r 0.3087, f1: 0.3050	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5000
test	acc: 0.6069	macro: p 0.3680, r 0.3185, f1: 0.3235	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5593
global_step: 34121, epoch: 54, loss: 0.604154
global_step: 34122, epoch: 54, loss: 0.647727
global_step: 34123, epoch: 54, loss: 0.760152
global_step: 34124, epoch: 54, loss: 0.588219
global_step: 34125, epoch: 54, loss: 0.535224
global_step: 34126, epoch: 54, loss: 0.573733
global_step: 34127, epoch: 54, loss: 0.652332
global_step: 34128, epoch: 54, loss: 0.562347
global_step: 34129, epoch: 54, loss: 0.589942
global_step: 34130, epoch: 54, loss: 0.637551
global_step: 34131, epoch: 54, loss: 0.673085
global_step: 34132, epoch: 54, loss: 0.585286
global_step: 34133, epoch: 54, loss: 0.639085
global_step: 34134, epoch: 54, loss: 0.642648
global_step: 34135, epoch: 54, loss: 0.657904
global_step: 34136, epoch: 54, loss: 0.668803
global_step: 34137, epoch: 54, loss: 0.598678
global_step: 34138, epoch: 54, loss: 0.618316
global_step: 34139, epoch: 54, loss: 0.664070
global_step: 34140, epoch: 54, loss: 0.697901
global_step: 34141, epoch: 54, loss: 0.626399
global_step: 34142, epoch: 54, loss: 0.524159
global_step: 34143, epoch: 54, loss: 0.671919
global_step: 34144, epoch: 54, loss: 0.572364
global_step: 34145, epoch: 54, loss: 0.666752
global_step: 34146, epoch: 54, loss: 0.649997
global_step: 34147, epoch: 54, loss: 0.687576
global_step: 34148, epoch: 54, loss: 0.583483
global_step: 34149, epoch: 54, loss: 0.704892
global_step: 34150, epoch: 54, loss: 0.681331
global_step: 34151, epoch: 54, loss: 0.692454
global_step: 34152, epoch: 54, loss: 0.675575
global_step: 34153, epoch: 54, loss: 0.645086
global_step: 34154, epoch: 54, loss: 0.671295
global_step: 34155, epoch: 54, loss: 0.519916
global_step: 34156, epoch: 54, loss: 0.738509
global_step: 34157, epoch: 54, loss: 0.629022
global_step: 34158, epoch: 54, loss: 0.634794
global_step: 34159, epoch: 54, loss: 0.609492
global_step: 34160, epoch: 54, loss: 1.033419
epoch: 54
train	acc: 0.8904	macro: p 0.8870, r 0.7240, f1: 0.7474	micro: p 0.8904, r 0.8904, f1 0.8904	weighted_f1:0.8819
dev	acc: 0.5491	macro: p 0.3319, r 0.3310, f1: 0.3284	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5170
test	acc: 0.5862	macro: p 0.5324, r 0.3406, f1: 0.3466	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5617
New best model!
global_step: 34161, epoch: 55, loss: 0.678238
global_step: 34162, epoch: 55, loss: 0.706742
global_step: 34163, epoch: 55, loss: 0.643616
global_step: 34164, epoch: 55, loss: 0.626055
global_step: 34165, epoch: 55, loss: 0.584968
global_step: 34166, epoch: 55, loss: 0.614541
global_step: 34167, epoch: 55, loss: 0.611164
global_step: 34168, epoch: 55, loss: 0.749448
global_step: 34169, epoch: 55, loss: 0.579798
global_step: 34170, epoch: 55, loss: 0.645159
global_step: 34171, epoch: 55, loss: 0.651858
global_step: 34172, epoch: 55, loss: 0.548475
global_step: 34173, epoch: 55, loss: 0.645080
global_step: 34174, epoch: 55, loss: 0.650545
global_step: 34175, epoch: 55, loss: 0.617047
global_step: 34176, epoch: 55, loss: 0.588431
global_step: 34177, epoch: 55, loss: 0.660719
global_step: 34178, epoch: 55, loss: 0.597515
global_step: 34179, epoch: 55, loss: 0.653645
global_step: 34180, epoch: 55, loss: 0.584771
global_step: 34181, epoch: 55, loss: 0.569728
global_step: 34182, epoch: 55, loss: 0.653433
global_step: 34183, epoch: 55, loss: 0.588461
global_step: 34184, epoch: 55, loss: 0.621599
global_step: 34185, epoch: 55, loss: 0.552579
global_step: 34186, epoch: 55, loss: 0.624320
global_step: 34187, epoch: 55, loss: 0.651784
global_step: 34188, epoch: 55, loss: 0.703066
global_step: 34189, epoch: 55, loss: 0.579132
global_step: 34190, epoch: 55, loss: 0.574240
global_step: 34191, epoch: 55, loss: 0.620366
global_step: 34192, epoch: 55, loss: 0.690278
global_step: 34193, epoch: 55, loss: 0.503104
global_step: 34194, epoch: 55, loss: 0.677678
global_step: 34195, epoch: 55, loss: 0.592733
global_step: 34196, epoch: 55, loss: 0.730651
global_step: 34197, epoch: 55, loss: 0.565362
global_step: 34198, epoch: 55, loss: 0.738082
global_step: 34199, epoch: 55, loss: 0.668332
global_step: 34200, epoch: 55, loss: 0.270372
epoch: 55
train	acc: 0.8927	macro: p 0.8947, r 0.7199, f1: 0.7492	micro: p 0.8927, r 0.8927, f1 0.8927	weighted_f1:0.8834
dev	acc: 0.5455	macro: p 0.3243, r 0.3158, f1: 0.3118	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.5032
test	acc: 0.5954	macro: p 0.3949, r 0.3265, f1: 0.3333	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5589
global_step: 34201, epoch: 56, loss: 0.626149
global_step: 34202, epoch: 56, loss: 0.700974
global_step: 34203, epoch: 56, loss: 0.565245
global_step: 34204, epoch: 56, loss: 0.634765
global_step: 34205, epoch: 56, loss: 0.626488
global_step: 34206, epoch: 56, loss: 0.573742
global_step: 34207, epoch: 56, loss: 0.586297
global_step: 34208, epoch: 56, loss: 0.625639
global_step: 34209, epoch: 56, loss: 0.549359
global_step: 34210, epoch: 56, loss: 0.455793
global_step: 34211, epoch: 56, loss: 0.592239
global_step: 34212, epoch: 56, loss: 0.567077
global_step: 34213, epoch: 56, loss: 0.728086
global_step: 34214, epoch: 56, loss: 0.561746
global_step: 34215, epoch: 56, loss: 0.636124
global_step: 34216, epoch: 56, loss: 0.596453
global_step: 34217, epoch: 56, loss: 0.609468
global_step: 34218, epoch: 56, loss: 0.630534
global_step: 34219, epoch: 56, loss: 0.544786
global_step: 34220, epoch: 56, loss: 0.513863
global_step: 34221, epoch: 56, loss: 0.620691
global_step: 34222, epoch: 56, loss: 0.692273
global_step: 34223, epoch: 56, loss: 0.640879
global_step: 34224, epoch: 56, loss: 0.592483
global_step: 34225, epoch: 56, loss: 0.739885
global_step: 34226, epoch: 56, loss: 0.556622
global_step: 34227, epoch: 56, loss: 0.600074
global_step: 34228, epoch: 56, loss: 0.761483
global_step: 34229, epoch: 56, loss: 0.643844
global_step: 34230, epoch: 56, loss: 0.581638
global_step: 34231, epoch: 56, loss: 0.647779
global_step: 34232, epoch: 56, loss: 0.654589
global_step: 34233, epoch: 56, loss: 0.605953
global_step: 34234, epoch: 56, loss: 0.596124
global_step: 34235, epoch: 56, loss: 0.643417
global_step: 34236, epoch: 56, loss: 0.607462
global_step: 34237, epoch: 56, loss: 0.601870
global_step: 34238, epoch: 56, loss: 0.657523
global_step: 34239, epoch: 56, loss: 0.658303
global_step: 34240, epoch: 56, loss: 0.318708
epoch: 56
train	acc: 0.8994	macro: p 0.9039, r 0.7555, f1: 0.7944	micro: p 0.8994, r 0.8994, f1 0.8994	weighted_f1:0.8942
dev	acc: 0.5491	macro: p 0.3426, r 0.3210, f1: 0.3166	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5081
test	acc: 0.5885	macro: p 0.3450, r 0.3235, f1: 0.3259	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5542
global_step: 34241, epoch: 57, loss: 0.656233
global_step: 34242, epoch: 57, loss: 0.597039
global_step: 34243, epoch: 57, loss: 0.649043
global_step: 34244, epoch: 57, loss: 0.547732
global_step: 34245, epoch: 57, loss: 0.626874
global_step: 34246, epoch: 57, loss: 0.582768
global_step: 34247, epoch: 57, loss: 0.650982
global_step: 34248, epoch: 57, loss: 0.586293
global_step: 34249, epoch: 57, loss: 0.607835
global_step: 34250, epoch: 57, loss: 0.668528
global_step: 34251, epoch: 57, loss: 0.539215
global_step: 34252, epoch: 57, loss: 0.679845
global_step: 34253, epoch: 57, loss: 0.597056
global_step: 34254, epoch: 57, loss: 0.612564
global_step: 34255, epoch: 57, loss: 0.599900
global_step: 34256, epoch: 57, loss: 0.524300
global_step: 34257, epoch: 57, loss: 0.685104
global_step: 34258, epoch: 57, loss: 0.569663
global_step: 34259, epoch: 57, loss: 0.540163
global_step: 34260, epoch: 57, loss: 0.550618
global_step: 34261, epoch: 57, loss: 0.654662
global_step: 34262, epoch: 57, loss: 0.613727
global_step: 34263, epoch: 57, loss: 0.520240
global_step: 34264, epoch: 57, loss: 0.598489
global_step: 34265, epoch: 57, loss: 0.635999
global_step: 34266, epoch: 57, loss: 0.576793
global_step: 34267, epoch: 57, loss: 0.545552
global_step: 34268, epoch: 57, loss: 0.630641
global_step: 34269, epoch: 57, loss: 0.537714
global_step: 34270, epoch: 57, loss: 0.638759
global_step: 34271, epoch: 57, loss: 0.676916
global_step: 34272, epoch: 57, loss: 0.570668
global_step: 34273, epoch: 57, loss: 0.566883
global_step: 34274, epoch: 57, loss: 0.659760
global_step: 34275, epoch: 57, loss: 0.565435
global_step: 34276, epoch: 57, loss: 0.674700
global_step: 34277, epoch: 57, loss: 0.626833
global_step: 34278, epoch: 57, loss: 0.621861
global_step: 34279, epoch: 57, loss: 0.588996
global_step: 34280, epoch: 57, loss: 0.857792
epoch: 57
train	acc: 0.8942	macro: p 0.9084, r 0.7336, f1: 0.7722	micro: p 0.8942, r 0.8942, f1 0.8942	weighted_f1:0.8862
dev	acc: 0.5401	macro: p 0.3305, r 0.3077, f1: 0.2995	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4922
test	acc: 0.5935	macro: p 0.3929, r 0.3231, f1: 0.3290	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5551
global_step: 34281, epoch: 58, loss: 0.584027
global_step: 34282, epoch: 58, loss: 0.608107
global_step: 34283, epoch: 58, loss: 0.550676
global_step: 34284, epoch: 58, loss: 0.585840
global_step: 34285, epoch: 58, loss: 0.538128
global_step: 34286, epoch: 58, loss: 0.665720
global_step: 34287, epoch: 58, loss: 0.589959
global_step: 34288, epoch: 58, loss: 0.550444
global_step: 34289, epoch: 58, loss: 0.623296
global_step: 34290, epoch: 58, loss: 0.581024
global_step: 34291, epoch: 58, loss: 0.533732
global_step: 34292, epoch: 58, loss: 0.630018
global_step: 34293, epoch: 58, loss: 0.595581
global_step: 34294, epoch: 58, loss: 0.558458
global_step: 34295, epoch: 58, loss: 0.496566
global_step: 34296, epoch: 58, loss: 0.623450
global_step: 34297, epoch: 58, loss: 0.636574
global_step: 34298, epoch: 58, loss: 0.654881
global_step: 34299, epoch: 58, loss: 0.656364
global_step: 34300, epoch: 58, loss: 0.517799
global_step: 34301, epoch: 58, loss: 0.579211
global_step: 34302, epoch: 58, loss: 0.662604
global_step: 34303, epoch: 58, loss: 0.562928
global_step: 34304, epoch: 58, loss: 0.664426
global_step: 34305, epoch: 58, loss: 0.512412
global_step: 34306, epoch: 58, loss: 0.659581
global_step: 34307, epoch: 58, loss: 0.657848
global_step: 34308, epoch: 58, loss: 0.652890
global_step: 34309, epoch: 58, loss: 0.518028
global_step: 34310, epoch: 58, loss: 0.649994
global_step: 34311, epoch: 58, loss: 0.550533
global_step: 34312, epoch: 58, loss: 0.651148
global_step: 34313, epoch: 58, loss: 0.598931
global_step: 34314, epoch: 58, loss: 0.660232
global_step: 34315, epoch: 58, loss: 0.505480
global_step: 34316, epoch: 58, loss: 0.589380
global_step: 34317, epoch: 58, loss: 0.595360
global_step: 34318, epoch: 58, loss: 0.525394
global_step: 34319, epoch: 58, loss: 0.683181
global_step: 34320, epoch: 58, loss: 1.472777
epoch: 58
train	acc: 0.9059	macro: p 0.9122, r 0.7782, f1: 0.8199	micro: p 0.9059, r 0.9059, f1 0.9059	weighted_f1:0.9017
dev	acc: 0.5528	macro: p 0.3326, r 0.3211, f1: 0.3121	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5058
test	acc: 0.5977	macro: p 0.3755, r 0.3270, f1: 0.3273	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5574
global_step: 34321, epoch: 59, loss: 0.724135
global_step: 34322, epoch: 59, loss: 0.658802
global_step: 34323, epoch: 59, loss: 0.579316
global_step: 34324, epoch: 59, loss: 0.488607
global_step: 34325, epoch: 59, loss: 0.614370
global_step: 34326, epoch: 59, loss: 0.637270
global_step: 34327, epoch: 59, loss: 0.612875
global_step: 34328, epoch: 59, loss: 0.560423
global_step: 34329, epoch: 59, loss: 0.643334
global_step: 34330, epoch: 59, loss: 0.574341
global_step: 34331, epoch: 59, loss: 0.555263
global_step: 34332, epoch: 59, loss: 0.692872
global_step: 34333, epoch: 59, loss: 0.508061
global_step: 34334, epoch: 59, loss: 0.465847
global_step: 34335, epoch: 59, loss: 0.521258
global_step: 34336, epoch: 59, loss: 0.712130
global_step: 34337, epoch: 59, loss: 0.521539
global_step: 34338, epoch: 59, loss: 0.605688
global_step: 34339, epoch: 59, loss: 0.608130
global_step: 34340, epoch: 59, loss: 0.575501
global_step: 34341, epoch: 59, loss: 0.504263
global_step: 34342, epoch: 59, loss: 0.647152
global_step: 34343, epoch: 59, loss: 0.490318
global_step: 34344, epoch: 59, loss: 0.504674
global_step: 34345, epoch: 59, loss: 0.653810
global_step: 34346, epoch: 59, loss: 0.649135
global_step: 34347, epoch: 59, loss: 0.512890
global_step: 34348, epoch: 59, loss: 0.550083
global_step: 34349, epoch: 59, loss: 0.551692
global_step: 34350, epoch: 59, loss: 0.525956
global_step: 34351, epoch: 59, loss: 0.590420
global_step: 34352, epoch: 59, loss: 0.598083
global_step: 34353, epoch: 59, loss: 0.528558
global_step: 34354, epoch: 59, loss: 0.640787
global_step: 34355, epoch: 59, loss: 0.498837
global_step: 34356, epoch: 59, loss: 0.703617
global_step: 34357, epoch: 59, loss: 0.569930
global_step: 34358, epoch: 59, loss: 0.584942
global_step: 34359, epoch: 59, loss: 0.575449
global_step: 34360, epoch: 59, loss: 0.992617
epoch: 59
train	acc: 0.9083	macro: p 0.9088, r 0.7800, f1: 0.8169	micro: p 0.9083, r 0.9083, f1 0.9083	weighted_f1:0.9038
dev	acc: 0.5419	macro: p 0.4705, r 0.3178, f1: 0.3134	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5000
test	acc: 0.5908	macro: p 0.3630, r 0.3274, f1: 0.3288	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5555
global_step: 34361, epoch: 60, loss: 0.591981
global_step: 34362, epoch: 60, loss: 0.582343
global_step: 34363, epoch: 60, loss: 0.465230
global_step: 34364, epoch: 60, loss: 0.601473
global_step: 34365, epoch: 60, loss: 0.546918
global_step: 34366, epoch: 60, loss: 0.537332
global_step: 34367, epoch: 60, loss: 0.560708
global_step: 34368, epoch: 60, loss: 0.607388
global_step: 34369, epoch: 60, loss: 0.583258
global_step: 34370, epoch: 60, loss: 0.587854
global_step: 34371, epoch: 60, loss: 0.613458
global_step: 34372, epoch: 60, loss: 0.581773
global_step: 34373, epoch: 60, loss: 0.650206
global_step: 34374, epoch: 60, loss: 0.574625
global_step: 34375, epoch: 60, loss: 0.628919
global_step: 34376, epoch: 60, loss: 0.631114
global_step: 34377, epoch: 60, loss: 0.605177
global_step: 34378, epoch: 60, loss: 0.531556
global_step: 34379, epoch: 60, loss: 0.653618
global_step: 34380, epoch: 60, loss: 0.468635
global_step: 34381, epoch: 60, loss: 0.668601
global_step: 34382, epoch: 60, loss: 0.587960
global_step: 34383, epoch: 60, loss: 0.515948
global_step: 34384, epoch: 60, loss: 0.558050
global_step: 34385, epoch: 60, loss: 0.621501
global_step: 34386, epoch: 60, loss: 0.492727
global_step: 34387, epoch: 60, loss: 0.538858
global_step: 34388, epoch: 60, loss: 0.519313
global_step: 34389, epoch: 60, loss: 0.675275
global_step: 34390, epoch: 60, loss: 0.602793
global_step: 34391, epoch: 60, loss: 0.590891
global_step: 34392, epoch: 60, loss: 0.573473
global_step: 34393, epoch: 60, loss: 0.598592
global_step: 34394, epoch: 60, loss: 0.621311
global_step: 34395, epoch: 60, loss: 0.548985
global_step: 34396, epoch: 60, loss: 0.567892
global_step: 34397, epoch: 60, loss: 0.634199
global_step: 34398, epoch: 60, loss: 0.509017
global_step: 34399, epoch: 60, loss: 0.609462
global_step: 34400, epoch: 60, loss: 0.152473
epoch: 60
train	acc: 0.9106	macro: p 0.9264, r 0.7886, f1: 0.8349	micro: p 0.9106, r 0.9106, f1 0.9106	weighted_f1:0.9067
dev	acc: 0.5528	macro: p 0.3415, r 0.3155, f1: 0.3085	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5017
test	acc: 0.6050	macro: p 0.3822, r 0.3258, f1: 0.3313	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5609
global_step: 34401, epoch: 61, loss: 0.552133
global_step: 34402, epoch: 61, loss: 0.575638
global_step: 34403, epoch: 61, loss: 0.594633
global_step: 34404, epoch: 61, loss: 0.529259
global_step: 34405, epoch: 61, loss: 0.554392
global_step: 34406, epoch: 61, loss: 0.600022
global_step: 34407, epoch: 61, loss: 0.625917
global_step: 34408, epoch: 61, loss: 0.514565
global_step: 34409, epoch: 61, loss: 0.579148
global_step: 34410, epoch: 61, loss: 0.581130
global_step: 34411, epoch: 61, loss: 0.575843
global_step: 34412, epoch: 61, loss: 0.590132
global_step: 34413, epoch: 61, loss: 0.610175
global_step: 34414, epoch: 61, loss: 0.512229
global_step: 34415, epoch: 61, loss: 0.492122
global_step: 34416, epoch: 61, loss: 0.540334
global_step: 34417, epoch: 61, loss: 0.566382
global_step: 34418, epoch: 61, loss: 0.597639
global_step: 34419, epoch: 61, loss: 0.548517
global_step: 34420, epoch: 61, loss: 0.519130
global_step: 34421, epoch: 61, loss: 0.512061
global_step: 34422, epoch: 61, loss: 0.628232
global_step: 34423, epoch: 61, loss: 0.560879
global_step: 34424, epoch: 61, loss: 0.642722
global_step: 34425, epoch: 61, loss: 0.521540
global_step: 34426, epoch: 61, loss: 0.600461
global_step: 34427, epoch: 61, loss: 0.549180
global_step: 34428, epoch: 61, loss: 0.659967
global_step: 34429, epoch: 61, loss: 0.583379
global_step: 34430, epoch: 61, loss: 0.568759
global_step: 34431, epoch: 61, loss: 0.499716
global_step: 34432, epoch: 61, loss: 0.565569
global_step: 34433, epoch: 61, loss: 0.588749
global_step: 34434, epoch: 61, loss: 0.520146
global_step: 34435, epoch: 61, loss: 0.589335
global_step: 34436, epoch: 61, loss: 0.480338
global_step: 34437, epoch: 61, loss: 0.590071
global_step: 34438, epoch: 61, loss: 0.598744
global_step: 34439, epoch: 61, loss: 0.490061
global_step: 34440, epoch: 61, loss: 0.360661
epoch: 61
train	acc: 0.9102	macro: p 0.9185, r 0.7816, f1: 0.8223	micro: p 0.9102, r 0.9102, f1 0.9102	weighted_f1:0.9057
dev	acc: 0.5446	macro: p 0.3298, r 0.3151, f1: 0.3075	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4998
test	acc: 0.5958	macro: p 0.3465, r 0.3247, f1: 0.3241	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5558
global_step: 34441, epoch: 62, loss: 0.540597
global_step: 34442, epoch: 62, loss: 0.497661
global_step: 34443, epoch: 62, loss: 0.539548
global_step: 34444, epoch: 62, loss: 0.574330
global_step: 34445, epoch: 62, loss: 0.458245
global_step: 34446, epoch: 62, loss: 0.534774
global_step: 34447, epoch: 62, loss: 0.562126
global_step: 34448, epoch: 62, loss: 0.542355
global_step: 34449, epoch: 62, loss: 0.529994
global_step: 34450, epoch: 62, loss: 0.602615
global_step: 34451, epoch: 62, loss: 0.544018
global_step: 34452, epoch: 62, loss: 0.512669
global_step: 34453, epoch: 62, loss: 0.577837
global_step: 34454, epoch: 62, loss: 0.651676
global_step: 34455, epoch: 62, loss: 0.570474
global_step: 34456, epoch: 62, loss: 0.524857
global_step: 34457, epoch: 62, loss: 0.621708
global_step: 34458, epoch: 62, loss: 0.513792
global_step: 34459, epoch: 62, loss: 0.557848
global_step: 34460, epoch: 62, loss: 0.551502
global_step: 34461, epoch: 62, loss: 0.483076
global_step: 34462, epoch: 62, loss: 0.590587
global_step: 34463, epoch: 62, loss: 0.578684
global_step: 34464, epoch: 62, loss: 0.623688
global_step: 34465, epoch: 62, loss: 0.547739
global_step: 34466, epoch: 62, loss: 0.639506
global_step: 34467, epoch: 62, loss: 0.513456
global_step: 34468, epoch: 62, loss: 0.617465
global_step: 34469, epoch: 62, loss: 0.672988
global_step: 34470, epoch: 62, loss: 0.583095
global_step: 34471, epoch: 62, loss: 0.610968
global_step: 34472, epoch: 62, loss: 0.553391
global_step: 34473, epoch: 62, loss: 0.542936
global_step: 34474, epoch: 62, loss: 0.557070
global_step: 34475, epoch: 62, loss: 0.605233
global_step: 34476, epoch: 62, loss: 0.585344
global_step: 34477, epoch: 62, loss: 0.585866
global_step: 34478, epoch: 62, loss: 0.514308
global_step: 34479, epoch: 62, loss: 0.589990
global_step: 34480, epoch: 62, loss: 0.378834
epoch: 62
train	acc: 0.9155	macro: p 0.9266, r 0.8007, f1: 0.8426	micro: p 0.9155, r 0.9155, f1 0.9155	weighted_f1:0.9122
dev	acc: 0.5437	macro: p 0.3333, r 0.3146, f1: 0.3050	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4970
test	acc: 0.5969	macro: p 0.3545, r 0.3280, f1: 0.3270	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5575
global_step: 34481, epoch: 63, loss: 0.507450
global_step: 34482, epoch: 63, loss: 0.529894
global_step: 34483, epoch: 63, loss: 0.558112
global_step: 34484, epoch: 63, loss: 0.601036
global_step: 34485, epoch: 63, loss: 0.529078
global_step: 34486, epoch: 63, loss: 0.545795
global_step: 34487, epoch: 63, loss: 0.473882
global_step: 34488, epoch: 63, loss: 0.522274
global_step: 34489, epoch: 63, loss: 0.519475
global_step: 34490, epoch: 63, loss: 0.562272
global_step: 34491, epoch: 63, loss: 0.511572
global_step: 34492, epoch: 63, loss: 0.502966
global_step: 34493, epoch: 63, loss: 0.556628
global_step: 34494, epoch: 63, loss: 0.539167
global_step: 34495, epoch: 63, loss: 0.506875
global_step: 34496, epoch: 63, loss: 0.468369
global_step: 34497, epoch: 63, loss: 0.564147
global_step: 34498, epoch: 63, loss: 0.586552
global_step: 34499, epoch: 63, loss: 0.577025
global_step: 34500, epoch: 63, loss: 0.618662
global_step: 34501, epoch: 63, loss: 0.576082
global_step: 34502, epoch: 63, loss: 0.588158
global_step: 34503, epoch: 63, loss: 0.675131
global_step: 34504, epoch: 63, loss: 0.575434
global_step: 34505, epoch: 63, loss: 0.626009
global_step: 34506, epoch: 63, loss: 0.565010
global_step: 34507, epoch: 63, loss: 0.511238
global_step: 34508, epoch: 63, loss: 0.588663
global_step: 34509, epoch: 63, loss: 0.501533
global_step: 34510, epoch: 63, loss: 0.661391
global_step: 34511, epoch: 63, loss: 0.597138
global_step: 34512, epoch: 63, loss: 0.582869
global_step: 34513, epoch: 63, loss: 0.560301
global_step: 34514, epoch: 63, loss: 0.537363
global_step: 34515, epoch: 63, loss: 0.454392
global_step: 34516, epoch: 63, loss: 0.592043
global_step: 34517, epoch: 63, loss: 0.538732
global_step: 34518, epoch: 63, loss: 0.523811
global_step: 34519, epoch: 63, loss: 0.628494
global_step: 34520, epoch: 63, loss: 0.518511
epoch: 63
train	acc: 0.9136	macro: p 0.9173, r 0.7869, f1: 0.8234	micro: p 0.9136, r 0.9136, f1 0.9136	weighted_f1:0.9091
dev	acc: 0.5455	macro: p 0.3237, r 0.3142, f1: 0.3067	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4996
test	acc: 0.5931	macro: p 0.3457, r 0.3266, f1: 0.3280	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5559
global_step: 34521, epoch: 64, loss: 0.524584
global_step: 34522, epoch: 64, loss: 0.644591
global_step: 34523, epoch: 64, loss: 0.582746
global_step: 34524, epoch: 64, loss: 0.551824
global_step: 34525, epoch: 64, loss: 0.530671
global_step: 34526, epoch: 64, loss: 0.524224
global_step: 34527, epoch: 64, loss: 0.615707
global_step: 34528, epoch: 64, loss: 0.548241
global_step: 34529, epoch: 64, loss: 0.507178
global_step: 34530, epoch: 64, loss: 0.536615
global_step: 34531, epoch: 64, loss: 0.608434
global_step: 34532, epoch: 64, loss: 0.532332
global_step: 34533, epoch: 64, loss: 0.597465
global_step: 34534, epoch: 64, loss: 0.503491
global_step: 34535, epoch: 64, loss: 0.560646
global_step: 34536, epoch: 64, loss: 0.566442
global_step: 34537, epoch: 64, loss: 0.616315
global_step: 34538, epoch: 64, loss: 0.617176
global_step: 34539, epoch: 64, loss: 0.576637
global_step: 34540, epoch: 64, loss: 0.433948
global_step: 34541, epoch: 64, loss: 0.611204
global_step: 34542, epoch: 64, loss: 0.481022
global_step: 34543, epoch: 64, loss: 0.567795
global_step: 34544, epoch: 64, loss: 0.582242
global_step: 34545, epoch: 64, loss: 0.557847
global_step: 34546, epoch: 64, loss: 0.519975
global_step: 34547, epoch: 64, loss: 0.531976
global_step: 34548, epoch: 64, loss: 0.603225
global_step: 34549, epoch: 64, loss: 0.434053
global_step: 34550, epoch: 64, loss: 0.616903
global_step: 34551, epoch: 64, loss: 0.501880
global_step: 34552, epoch: 64, loss: 0.495223
global_step: 34553, epoch: 64, loss: 0.447344
global_step: 34554, epoch: 64, loss: 0.554955
global_step: 34555, epoch: 64, loss: 0.578651
global_step: 34556, epoch: 64, loss: 0.542606
global_step: 34557, epoch: 64, loss: 0.540242
global_step: 34558, epoch: 64, loss: 0.579535
global_step: 34559, epoch: 64, loss: 0.569230
global_step: 34560, epoch: 64, loss: 0.525847
epoch: 64
train	acc: 0.9182	macro: p 0.9292, r 0.8070, f1: 0.8497	micro: p 0.9182, r 0.9182, f1 0.9182	weighted_f1:0.9152
dev	acc: 0.5419	macro: p 0.3218, r 0.3055, f1: 0.2994	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4917
test	acc: 0.6031	macro: p 0.3641, r 0.3220, f1: 0.3263	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5591
global_step: 34561, epoch: 65, loss: 0.604021
global_step: 34562, epoch: 65, loss: 0.538035
global_step: 34563, epoch: 65, loss: 0.600194
global_step: 34564, epoch: 65, loss: 0.505347
global_step: 34565, epoch: 65, loss: 0.585669
global_step: 34566, epoch: 65, loss: 0.504847
global_step: 34567, epoch: 65, loss: 0.513651
global_step: 34568, epoch: 65, loss: 0.566001
global_step: 34569, epoch: 65, loss: 0.528657
global_step: 34570, epoch: 65, loss: 0.450879
global_step: 34571, epoch: 65, loss: 0.490133
global_step: 34572, epoch: 65, loss: 0.582121
global_step: 34573, epoch: 65, loss: 0.581199
global_step: 34574, epoch: 65, loss: 0.567124
global_step: 34575, epoch: 65, loss: 0.513736
global_step: 34576, epoch: 65, loss: 0.539561
global_step: 34577, epoch: 65, loss: 0.559685
global_step: 34578, epoch: 65, loss: 0.558156
global_step: 34579, epoch: 65, loss: 0.528563
global_step: 34580, epoch: 65, loss: 0.528175
global_step: 34581, epoch: 65, loss: 0.496027
global_step: 34582, epoch: 65, loss: 0.597133
global_step: 34583, epoch: 65, loss: 0.547806
global_step: 34584, epoch: 65, loss: 0.515344
global_step: 34585, epoch: 65, loss: 0.487886
global_step: 34586, epoch: 65, loss: 0.543669
global_step: 34587, epoch: 65, loss: 0.457756
global_step: 34588, epoch: 65, loss: 0.547017
global_step: 34589, epoch: 65, loss: 0.643296
global_step: 34590, epoch: 65, loss: 0.577357
global_step: 34591, epoch: 65, loss: 0.567467
global_step: 34592, epoch: 65, loss: 0.469390
global_step: 34593, epoch: 65, loss: 0.551573
global_step: 34594, epoch: 65, loss: 0.511093
global_step: 34595, epoch: 65, loss: 0.550356
global_step: 34596, epoch: 65, loss: 0.544382
global_step: 34597, epoch: 65, loss: 0.561960
global_step: 34598, epoch: 65, loss: 0.523241
global_step: 34599, epoch: 65, loss: 0.516574
global_step: 34600, epoch: 65, loss: 0.752618
epoch: 65
train	acc: 0.9215	macro: p 0.9238, r 0.8119, f1: 0.8472	micro: p 0.9215, r 0.9215, f1 0.9215	weighted_f1:0.9183
dev	acc: 0.5419	macro: p 0.3204, r 0.3173, f1: 0.3095	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.5005
test	acc: 0.5927	macro: p 0.3468, r 0.3319, f1: 0.3325	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5595
global_step: 34601, epoch: 66, loss: 0.518679
global_step: 34602, epoch: 66, loss: 0.499644
global_step: 34603, epoch: 66, loss: 0.504771
global_step: 34604, epoch: 66, loss: 0.565771
global_step: 34605, epoch: 66, loss: 0.457492
global_step: 34606, epoch: 66, loss: 0.461294
global_step: 34607, epoch: 66, loss: 0.504032
global_step: 34608, epoch: 66, loss: 0.507811
global_step: 34609, epoch: 66, loss: 0.482753
global_step: 34610, epoch: 66, loss: 0.445070
global_step: 34611, epoch: 66, loss: 0.511332
global_step: 34612, epoch: 66, loss: 0.545467
global_step: 34613, epoch: 66, loss: 0.578564
global_step: 34614, epoch: 66, loss: 0.587220
global_step: 34615, epoch: 66, loss: 0.591132
global_step: 34616, epoch: 66, loss: 0.444300
global_step: 34617, epoch: 66, loss: 0.620253
global_step: 34618, epoch: 66, loss: 0.511169
global_step: 34619, epoch: 66, loss: 0.482067
global_step: 34620, epoch: 66, loss: 0.465299
global_step: 34621, epoch: 66, loss: 0.659663
global_step: 34622, epoch: 66, loss: 0.576544
global_step: 34623, epoch: 66, loss: 0.546819
global_step: 34624, epoch: 66, loss: 0.437558
global_step: 34625, epoch: 66, loss: 0.475427
global_step: 34626, epoch: 66, loss: 0.493390
global_step: 34627, epoch: 66, loss: 0.506693
global_step: 34628, epoch: 66, loss: 0.641477
global_step: 34629, epoch: 66, loss: 0.541978
global_step: 34630, epoch: 66, loss: 0.505611
global_step: 34631, epoch: 66, loss: 0.579603
global_step: 34632, epoch: 66, loss: 0.536520
global_step: 34633, epoch: 66, loss: 0.461769
global_step: 34634, epoch: 66, loss: 0.585388
global_step: 34635, epoch: 66, loss: 0.576431
global_step: 34636, epoch: 66, loss: 0.576814
global_step: 34637, epoch: 66, loss: 0.580686
global_step: 34638, epoch: 66, loss: 0.540796
global_step: 34639, epoch: 66, loss: 0.518069
global_step: 34640, epoch: 66, loss: 0.175429
epoch: 66
train	acc: 0.9303	macro: p 0.9341, r 0.8472, f1: 0.8806	micro: p 0.9303, r 0.9303, f1 0.9303	weighted_f1:0.9289
dev	acc: 0.5446	macro: p 0.3622, r 0.3236, f1: 0.3209	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5065
test	acc: 0.5920	macro: p 0.3504, r 0.3319, f1: 0.3327	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5606
global_step: 34641, epoch: 67, loss: 0.598943
global_step: 34642, epoch: 67, loss: 0.638762
global_step: 34643, epoch: 67, loss: 0.566248
global_step: 34644, epoch: 67, loss: 0.471696
global_step: 34645, epoch: 67, loss: 0.489141
global_step: 34646, epoch: 67, loss: 0.543356
global_step: 34647, epoch: 67, loss: 0.505322
global_step: 34648, epoch: 67, loss: 0.484892
global_step: 34649, epoch: 67, loss: 0.533088
global_step: 34650, epoch: 67, loss: 0.532125
global_step: 34651, epoch: 67, loss: 0.510411
global_step: 34652, epoch: 67, loss: 0.565196
global_step: 34653, epoch: 67, loss: 0.584510
global_step: 34654, epoch: 67, loss: 0.471120
global_step: 34655, epoch: 67, loss: 0.521033
global_step: 34656, epoch: 67, loss: 0.616959
global_step: 34657, epoch: 67, loss: 0.512722
global_step: 34658, epoch: 67, loss: 0.475515
global_step: 34659, epoch: 67, loss: 0.569164
global_step: 34660, epoch: 67, loss: 0.555676
global_step: 34661, epoch: 67, loss: 0.440125
global_step: 34662, epoch: 67, loss: 0.458803
global_step: 34663, epoch: 67, loss: 0.587635
global_step: 34664, epoch: 67, loss: 0.523754
global_step: 34665, epoch: 67, loss: 0.426250
global_step: 34666, epoch: 67, loss: 0.566055
global_step: 34667, epoch: 67, loss: 0.511415
global_step: 34668, epoch: 67, loss: 0.504326
global_step: 34669, epoch: 67, loss: 0.550824
global_step: 34670, epoch: 67, loss: 0.477419
global_step: 34671, epoch: 67, loss: 0.500581
global_step: 34672, epoch: 67, loss: 0.519752
global_step: 34673, epoch: 67, loss: 0.557387
global_step: 34674, epoch: 67, loss: 0.535333
global_step: 34675, epoch: 67, loss: 0.568153
global_step: 34676, epoch: 67, loss: 0.512229
global_step: 34677, epoch: 67, loss: 0.481073
global_step: 34678, epoch: 67, loss: 0.518887
global_step: 34679, epoch: 67, loss: 0.563295
global_step: 34680, epoch: 67, loss: 0.231994
epoch: 67
train	acc: 0.9233	macro: p 0.9367, r 0.8237, f1: 0.8655	micro: p 0.9233, r 0.9233, f1 0.9233	weighted_f1:0.9209
dev	acc: 0.5582	macro: p 0.3377, r 0.3187, f1: 0.3135	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5074
test	acc: 0.6000	macro: p 0.3512, r 0.3173, f1: 0.3203	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5548
global_step: 34681, epoch: 68, loss: 0.500360
global_step: 34682, epoch: 68, loss: 0.476908
global_step: 34683, epoch: 68, loss: 0.547665
global_step: 34684, epoch: 68, loss: 0.547159
global_step: 34685, epoch: 68, loss: 0.518383
global_step: 34686, epoch: 68, loss: 0.426092
global_step: 34687, epoch: 68, loss: 0.485669
global_step: 34688, epoch: 68, loss: 0.552409
global_step: 34689, epoch: 68, loss: 0.505050
global_step: 34690, epoch: 68, loss: 0.553740
global_step: 34691, epoch: 68, loss: 0.506040
global_step: 34692, epoch: 68, loss: 0.463141
global_step: 34693, epoch: 68, loss: 0.510368
global_step: 34694, epoch: 68, loss: 0.464662
global_step: 34695, epoch: 68, loss: 0.485361
global_step: 34696, epoch: 68, loss: 0.504269
global_step: 34697, epoch: 68, loss: 0.563324
global_step: 34698, epoch: 68, loss: 0.539660
global_step: 34699, epoch: 68, loss: 0.530104
global_step: 34700, epoch: 68, loss: 0.475397
global_step: 34701, epoch: 68, loss: 0.551024
global_step: 34702, epoch: 68, loss: 0.533480
global_step: 34703, epoch: 68, loss: 0.542416
global_step: 34704, epoch: 68, loss: 0.489961
global_step: 34705, epoch: 68, loss: 0.554374
global_step: 34706, epoch: 68, loss: 0.496059
global_step: 34707, epoch: 68, loss: 0.460142
global_step: 34708, epoch: 68, loss: 0.596193
global_step: 34709, epoch: 68, loss: 0.442769
global_step: 34710, epoch: 68, loss: 0.482771
global_step: 34711, epoch: 68, loss: 0.515554
global_step: 34712, epoch: 68, loss: 0.519874
global_step: 34713, epoch: 68, loss: 0.612506
global_step: 34714, epoch: 68, loss: 0.487240
global_step: 34715, epoch: 68, loss: 0.529749
global_step: 34716, epoch: 68, loss: 0.590471
global_step: 34717, epoch: 68, loss: 0.641178
global_step: 34718, epoch: 68, loss: 0.433450
global_step: 34719, epoch: 68, loss: 0.455261
global_step: 34720, epoch: 68, loss: 0.149849
epoch: 68
train	acc: 0.9280	macro: p 0.9437, r 0.8441, f1: 0.8837	micro: p 0.9280, r 0.9280, f1 0.9280	weighted_f1:0.9264
dev	acc: 0.5464	macro: p 0.3281, r 0.3088, f1: 0.2975	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4939
test	acc: 0.5946	macro: p 0.3551, r 0.3202, f1: 0.3190	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5514
global_step: 34721, epoch: 69, loss: 0.491888
global_step: 34722, epoch: 69, loss: 0.427507
global_step: 34723, epoch: 69, loss: 0.503976
global_step: 34724, epoch: 69, loss: 0.572076
global_step: 34725, epoch: 69, loss: 0.498996
global_step: 34726, epoch: 69, loss: 0.554145
global_step: 34727, epoch: 69, loss: 0.382766
global_step: 34728, epoch: 69, loss: 0.447428
global_step: 34729, epoch: 69, loss: 0.397944
global_step: 34730, epoch: 69, loss: 0.484593
global_step: 34731, epoch: 69, loss: 0.496521
global_step: 34732, epoch: 69, loss: 0.563672
global_step: 34733, epoch: 69, loss: 0.458854
global_step: 34734, epoch: 69, loss: 0.533894
global_step: 34735, epoch: 69, loss: 0.435508
global_step: 34736, epoch: 69, loss: 0.532099
global_step: 34737, epoch: 69, loss: 0.476481
global_step: 34738, epoch: 69, loss: 0.504510
global_step: 34739, epoch: 69, loss: 0.466447
global_step: 34740, epoch: 69, loss: 0.481970
global_step: 34741, epoch: 69, loss: 0.423484
global_step: 34742, epoch: 69, loss: 0.527155
global_step: 34743, epoch: 69, loss: 0.438498
global_step: 34744, epoch: 69, loss: 0.488617
global_step: 34745, epoch: 69, loss: 0.466291
global_step: 34746, epoch: 69, loss: 0.502138
global_step: 34747, epoch: 69, loss: 0.518895
global_step: 34748, epoch: 69, loss: 0.496325
global_step: 34749, epoch: 69, loss: 0.499948
global_step: 34750, epoch: 69, loss: 0.542630
global_step: 34751, epoch: 69, loss: 0.575677
global_step: 34752, epoch: 69, loss: 0.411376
global_step: 34753, epoch: 69, loss: 0.506606
global_step: 34754, epoch: 69, loss: 0.415134
global_step: 34755, epoch: 69, loss: 0.636174
global_step: 34756, epoch: 69, loss: 0.511052
global_step: 34757, epoch: 69, loss: 0.562043
global_step: 34758, epoch: 69, loss: 0.475693
global_step: 34759, epoch: 69, loss: 0.485216
global_step: 34760, epoch: 69, loss: 0.579290
epoch: 69
train	acc: 0.9315	macro: p 0.9328, r 0.8502, f1: 0.8807	micro: p 0.9315, r 0.9315, f1 0.9315	weighted_f1:0.9301
dev	acc: 0.5383	macro: p 0.3177, r 0.3170, f1: 0.3121	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.5029
test	acc: 0.5762	macro: p 0.3308, r 0.3247, f1: 0.3243	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5499
global_step: 34761, epoch: 70, loss: 0.497656
global_step: 34762, epoch: 70, loss: 0.496038
global_step: 34763, epoch: 70, loss: 0.454630
global_step: 34764, epoch: 70, loss: 0.541112
global_step: 34765, epoch: 70, loss: 0.463450
global_step: 34766, epoch: 70, loss: 0.528316
global_step: 34767, epoch: 70, loss: 0.502607
global_step: 34768, epoch: 70, loss: 0.492538
global_step: 34769, epoch: 70, loss: 0.408224
global_step: 34770, epoch: 70, loss: 0.467831
global_step: 34771, epoch: 70, loss: 0.502303
global_step: 34772, epoch: 70, loss: 0.506967
global_step: 34773, epoch: 70, loss: 0.454621
global_step: 34774, epoch: 70, loss: 0.465304
global_step: 34775, epoch: 70, loss: 0.450052
global_step: 34776, epoch: 70, loss: 0.510728
global_step: 34777, epoch: 70, loss: 0.463286
global_step: 34778, epoch: 70, loss: 0.549823
global_step: 34779, epoch: 70, loss: 0.474933
global_step: 34780, epoch: 70, loss: 0.540233
global_step: 34781, epoch: 70, loss: 0.531504
global_step: 34782, epoch: 70, loss: 0.489420
global_step: 34783, epoch: 70, loss: 0.516512
global_step: 34784, epoch: 70, loss: 0.475871
global_step: 34785, epoch: 70, loss: 0.517961
global_step: 34786, epoch: 70, loss: 0.496355
global_step: 34787, epoch: 70, loss: 0.428671
global_step: 34788, epoch: 70, loss: 0.514928
global_step: 34789, epoch: 70, loss: 0.545129
global_step: 34790, epoch: 70, loss: 0.535302
global_step: 34791, epoch: 70, loss: 0.493973
global_step: 34792, epoch: 70, loss: 0.538298
global_step: 34793, epoch: 70, loss: 0.447374
global_step: 34794, epoch: 70, loss: 0.495627
global_step: 34795, epoch: 70, loss: 0.462204
global_step: 34796, epoch: 70, loss: 0.502403
global_step: 34797, epoch: 70, loss: 0.544148
global_step: 34798, epoch: 70, loss: 0.475210
global_step: 34799, epoch: 70, loss: 0.530308
global_step: 34800, epoch: 70, loss: 0.359811
epoch: 70
train	acc: 0.9282	macro: p 0.9386, r 0.8416, f1: 0.8787	micro: p 0.9282, r 0.9282, f1 0.9282	weighted_f1:0.9266
dev	acc: 0.5464	macro: p 0.3284, r 0.3131, f1: 0.3062	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5000
test	acc: 0.5927	macro: p 0.3575, r 0.3187, f1: 0.3222	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5535
global_step: 34801, epoch: 71, loss: 0.449915
global_step: 34802, epoch: 71, loss: 0.485108
global_step: 34803, epoch: 71, loss: 0.482862
global_step: 34804, epoch: 71, loss: 0.529126
global_step: 34805, epoch: 71, loss: 0.415016
global_step: 34806, epoch: 71, loss: 0.579095
global_step: 34807, epoch: 71, loss: 0.524238
global_step: 34808, epoch: 71, loss: 0.525912
global_step: 34809, epoch: 71, loss: 0.484867
global_step: 34810, epoch: 71, loss: 0.535997
global_step: 34811, epoch: 71, loss: 0.445095
global_step: 34812, epoch: 71, loss: 0.451446
global_step: 34813, epoch: 71, loss: 0.409553
global_step: 34814, epoch: 71, loss: 0.542930
global_step: 34815, epoch: 71, loss: 0.471370
global_step: 34816, epoch: 71, loss: 0.539830
global_step: 34817, epoch: 71, loss: 0.515056
global_step: 34818, epoch: 71, loss: 0.514651
global_step: 34819, epoch: 71, loss: 0.447427
global_step: 34820, epoch: 71, loss: 0.421746
global_step: 34821, epoch: 71, loss: 0.446334
global_step: 34822, epoch: 71, loss: 0.421358
global_step: 34823, epoch: 71, loss: 0.462854
global_step: 34824, epoch: 71, loss: 0.528603
global_step: 34825, epoch: 71, loss: 0.493676
global_step: 34826, epoch: 71, loss: 0.641056
global_step: 34827, epoch: 71, loss: 0.617222
global_step: 34828, epoch: 71, loss: 0.470253
global_step: 34829, epoch: 71, loss: 0.530509
global_step: 34830, epoch: 71, loss: 0.578361
global_step: 34831, epoch: 71, loss: 0.465179
global_step: 34832, epoch: 71, loss: 0.475725
global_step: 34833, epoch: 71, loss: 0.492329
global_step: 34834, epoch: 71, loss: 0.550542
global_step: 34835, epoch: 71, loss: 0.553846
global_step: 34836, epoch: 71, loss: 0.503448
global_step: 34837, epoch: 71, loss: 0.529598
global_step: 34838, epoch: 71, loss: 0.499321
global_step: 34839, epoch: 71, loss: 0.485278
global_step: 34840, epoch: 71, loss: 0.008247
epoch: 71
train	acc: 0.9372	macro: p 0.9460, r 0.8690, f1: 0.9010	micro: p 0.9372, r 0.9372, f1 0.9372	weighted_f1:0.9363
dev	acc: 0.5491	macro: p 0.3329, r 0.3157, f1: 0.3110	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5048
test	acc: 0.5904	macro: p 0.3498, r 0.3219, f1: 0.3259	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5555
global_step: 34841, epoch: 72, loss: 0.504610
global_step: 34842, epoch: 72, loss: 0.509642
global_step: 34843, epoch: 72, loss: 0.489506
global_step: 34844, epoch: 72, loss: 0.419939
global_step: 34845, epoch: 72, loss: 0.532408
global_step: 34846, epoch: 72, loss: 0.522782
global_step: 34847, epoch: 72, loss: 0.472547
global_step: 34848, epoch: 72, loss: 0.496681
global_step: 34849, epoch: 72, loss: 0.480647
global_step: 34850, epoch: 72, loss: 0.430902
global_step: 34851, epoch: 72, loss: 0.523783
global_step: 34852, epoch: 72, loss: 0.558727
global_step: 34853, epoch: 72, loss: 0.539952
global_step: 34854, epoch: 72, loss: 0.483064
global_step: 34855, epoch: 72, loss: 0.574750
global_step: 34856, epoch: 72, loss: 0.497528
global_step: 34857, epoch: 72, loss: 0.452032
global_step: 34858, epoch: 72, loss: 0.445335
global_step: 34859, epoch: 72, loss: 0.379776
global_step: 34860, epoch: 72, loss: 0.450242
global_step: 34861, epoch: 72, loss: 0.451605
global_step: 34862, epoch: 72, loss: 0.534294
global_step: 34863, epoch: 72, loss: 0.403579
global_step: 34864, epoch: 72, loss: 0.423684
global_step: 34865, epoch: 72, loss: 0.476994
global_step: 34866, epoch: 72, loss: 0.430765
global_step: 34867, epoch: 72, loss: 0.576322
global_step: 34868, epoch: 72, loss: 0.572217
global_step: 34869, epoch: 72, loss: 0.437116
global_step: 34870, epoch: 72, loss: 0.517421
global_step: 34871, epoch: 72, loss: 0.452388
global_step: 34872, epoch: 72, loss: 0.421871
global_step: 34873, epoch: 72, loss: 0.491918
global_step: 34874, epoch: 72, loss: 0.446426
global_step: 34875, epoch: 72, loss: 0.452402
global_step: 34876, epoch: 72, loss: 0.545864
global_step: 34877, epoch: 72, loss: 0.516858
global_step: 34878, epoch: 72, loss: 0.478554
global_step: 34879, epoch: 72, loss: 0.503405
global_step: 34880, epoch: 72, loss: 0.245936
epoch: 72
train	acc: 0.9288	macro: p 0.9367, r 0.8432, f1: 0.8778	micro: p 0.9288, r 0.9288, f1 0.9288	weighted_f1:0.9275
dev	acc: 0.5383	macro: p 0.3264, r 0.3070, f1: 0.2999	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4942
test	acc: 0.5916	macro: p 0.3569, r 0.3238, f1: 0.3246	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5555
global_step: 34881, epoch: 73, loss: 0.474016
global_step: 34882, epoch: 73, loss: 0.398140
global_step: 34883, epoch: 73, loss: 0.514754
global_step: 34884, epoch: 73, loss: 0.457933
global_step: 34885, epoch: 73, loss: 0.477719
global_step: 34886, epoch: 73, loss: 0.449606
global_step: 34887, epoch: 73, loss: 0.508911
global_step: 34888, epoch: 73, loss: 0.480600
global_step: 34889, epoch: 73, loss: 0.400277
global_step: 34890, epoch: 73, loss: 0.497892
global_step: 34891, epoch: 73, loss: 0.514896
global_step: 34892, epoch: 73, loss: 0.459452
global_step: 34893, epoch: 73, loss: 0.479450
global_step: 34894, epoch: 73, loss: 0.435011
global_step: 34895, epoch: 73, loss: 0.423048
global_step: 34896, epoch: 73, loss: 0.454941
global_step: 34897, epoch: 73, loss: 0.490622
global_step: 34898, epoch: 73, loss: 0.489993
global_step: 34899, epoch: 73, loss: 0.553277
global_step: 34900, epoch: 73, loss: 0.474704
global_step: 34901, epoch: 73, loss: 0.518234
global_step: 34902, epoch: 73, loss: 0.528526
global_step: 34903, epoch: 73, loss: 0.433782
global_step: 34904, epoch: 73, loss: 0.532595
global_step: 34905, epoch: 73, loss: 0.518256
global_step: 34906, epoch: 73, loss: 0.492923
global_step: 34907, epoch: 73, loss: 0.443809
global_step: 34908, epoch: 73, loss: 0.508887
global_step: 34909, epoch: 73, loss: 0.414882
global_step: 34910, epoch: 73, loss: 0.427487
global_step: 34911, epoch: 73, loss: 0.464853
global_step: 34912, epoch: 73, loss: 0.474684
global_step: 34913, epoch: 73, loss: 0.554625
global_step: 34914, epoch: 73, loss: 0.422051
global_step: 34915, epoch: 73, loss: 0.503135
global_step: 34916, epoch: 73, loss: 0.496282
global_step: 34917, epoch: 73, loss: 0.533000
global_step: 34918, epoch: 73, loss: 0.444847
global_step: 34919, epoch: 73, loss: 0.554756
global_step: 34920, epoch: 73, loss: 0.641000
epoch: 73
train	acc: 0.9383	macro: p 0.9434, r 0.8684, f1: 0.8987	micro: p 0.9383, r 0.9383, f1 0.9383	weighted_f1:0.9373
dev	acc: 0.5338	macro: p 0.3127, r 0.3016, f1: 0.2978	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4903
test	acc: 0.5881	macro: p 0.3394, r 0.3216, f1: 0.3240	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5525
global_step: 34921, epoch: 74, loss: 0.446463
global_step: 34922, epoch: 74, loss: 0.491658
global_step: 34923, epoch: 74, loss: 0.382976
global_step: 34924, epoch: 74, loss: 0.422710
global_step: 34925, epoch: 74, loss: 0.489446
global_step: 34926, epoch: 74, loss: 0.654111
global_step: 34927, epoch: 74, loss: 0.528803
global_step: 34928, epoch: 74, loss: 0.439687
global_step: 34929, epoch: 74, loss: 0.435723
global_step: 34930, epoch: 74, loss: 0.466142
global_step: 34931, epoch: 74, loss: 0.531539
global_step: 34932, epoch: 74, loss: 0.474146
global_step: 34933, epoch: 74, loss: 0.387023
global_step: 34934, epoch: 74, loss: 0.550581
global_step: 34935, epoch: 74, loss: 0.433445
global_step: 34936, epoch: 74, loss: 0.469994
global_step: 34937, epoch: 74, loss: 0.525907
global_step: 34938, epoch: 74, loss: 0.565630
global_step: 34939, epoch: 74, loss: 0.458688
global_step: 34940, epoch: 74, loss: 0.466195
global_step: 34941, epoch: 74, loss: 0.512081
global_step: 34942, epoch: 74, loss: 0.451154
global_step: 34943, epoch: 74, loss: 0.468417
global_step: 34944, epoch: 74, loss: 0.503425
global_step: 34945, epoch: 74, loss: 0.394035
global_step: 34946, epoch: 74, loss: 0.441924
global_step: 34947, epoch: 74, loss: 0.416075
global_step: 34948, epoch: 74, loss: 0.491799
global_step: 34949, epoch: 74, loss: 0.442826
global_step: 34950, epoch: 74, loss: 0.449639
global_step: 34951, epoch: 74, loss: 0.563406
global_step: 34952, epoch: 74, loss: 0.494841
global_step: 34953, epoch: 74, loss: 0.350105
global_step: 34954, epoch: 74, loss: 0.504148
global_step: 34955, epoch: 74, loss: 0.394707
global_step: 34956, epoch: 74, loss: 0.457266
global_step: 34957, epoch: 74, loss: 0.477659
global_step: 34958, epoch: 74, loss: 0.535501
global_step: 34959, epoch: 74, loss: 0.475286
global_step: 34960, epoch: 74, loss: 0.227062
epoch: 74
train	acc: 0.9410	macro: p 0.9535, r 0.8787, f1: 0.9106	micro: p 0.9410, r 0.9410, f1 0.9410	weighted_f1:0.9402
dev	acc: 0.5455	macro: p 0.3272, r 0.3076, f1: 0.3040	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4965
test	acc: 0.5939	macro: p 0.3452, r 0.3146, f1: 0.3197	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5522
global_step: 34961, epoch: 75, loss: 0.392685
global_step: 34962, epoch: 75, loss: 0.374083
global_step: 34963, epoch: 75, loss: 0.473861
global_step: 34964, epoch: 75, loss: 0.426416
global_step: 34965, epoch: 75, loss: 0.446720
global_step: 34966, epoch: 75, loss: 0.484728
global_step: 34967, epoch: 75, loss: 0.431581
global_step: 34968, epoch: 75, loss: 0.539851
global_step: 34969, epoch: 75, loss: 0.412104
global_step: 34970, epoch: 75, loss: 0.422528
global_step: 34971, epoch: 75, loss: 0.543584
global_step: 34972, epoch: 75, loss: 0.403484
global_step: 34973, epoch: 75, loss: 0.456019
global_step: 34974, epoch: 75, loss: 0.363518
global_step: 34975, epoch: 75, loss: 0.458955
global_step: 34976, epoch: 75, loss: 0.451266
global_step: 34977, epoch: 75, loss: 0.382033
global_step: 34978, epoch: 75, loss: 0.423885
global_step: 34979, epoch: 75, loss: 0.490095
global_step: 34980, epoch: 75, loss: 0.468148
global_step: 34981, epoch: 75, loss: 0.445324
global_step: 34982, epoch: 75, loss: 0.558307
global_step: 34983, epoch: 75, loss: 0.462951
global_step: 34984, epoch: 75, loss: 0.540369
global_step: 34985, epoch: 75, loss: 0.492986
global_step: 34986, epoch: 75, loss: 0.391519
global_step: 34987, epoch: 75, loss: 0.492918
global_step: 34988, epoch: 75, loss: 0.472517
global_step: 34989, epoch: 75, loss: 0.508779
global_step: 34990, epoch: 75, loss: 0.442092
global_step: 34991, epoch: 75, loss: 0.392338
global_step: 34992, epoch: 75, loss: 0.415814
global_step: 34993, epoch: 75, loss: 0.459083
global_step: 34994, epoch: 75, loss: 0.426802
global_step: 34995, epoch: 75, loss: 0.426353
global_step: 34996, epoch: 75, loss: 0.406644
global_step: 34997, epoch: 75, loss: 0.439678
global_step: 34998, epoch: 75, loss: 0.471443
global_step: 34999, epoch: 75, loss: 0.461583
global_step: 35000, epoch: 75, loss: 0.136570
epoch: 75
train	acc: 0.9370	macro: p 0.9514, r 0.8681, f1: 0.9028	micro: p 0.9370, r 0.9370, f1 0.9370	weighted_f1:0.9361
dev	acc: 0.5500	macro: p 0.3388, r 0.3099, f1: 0.3021	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4964
test	acc: 0.5989	macro: p 0.3599, r 0.3151, f1: 0.3184	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5523
global_step: 35001, epoch: 76, loss: 0.381857
global_step: 35002, epoch: 76, loss: 0.561573
global_step: 35003, epoch: 76, loss: 0.522709
global_step: 35004, epoch: 76, loss: 0.442392
global_step: 35005, epoch: 76, loss: 0.432310
global_step: 35006, epoch: 76, loss: 0.460525
global_step: 35007, epoch: 76, loss: 0.427917
global_step: 35008, epoch: 76, loss: 0.490167
global_step: 35009, epoch: 76, loss: 0.453536
global_step: 35010, epoch: 76, loss: 0.506650
global_step: 35011, epoch: 76, loss: 0.430258
global_step: 35012, epoch: 76, loss: 0.373343
global_step: 35013, epoch: 76, loss: 0.476558
global_step: 35014, epoch: 76, loss: 0.488651
global_step: 35015, epoch: 76, loss: 0.429338
global_step: 35016, epoch: 76, loss: 0.461936
global_step: 35017, epoch: 76, loss: 0.391534
global_step: 35018, epoch: 76, loss: 0.397716
global_step: 35019, epoch: 76, loss: 0.434166
global_step: 35020, epoch: 76, loss: 0.434514
global_step: 35021, epoch: 76, loss: 0.448984
global_step: 35022, epoch: 76, loss: 0.468890
global_step: 35023, epoch: 76, loss: 0.445864
global_step: 35024, epoch: 76, loss: 0.486062
global_step: 35025, epoch: 76, loss: 0.337227
global_step: 35026, epoch: 76, loss: 0.544246
global_step: 35027, epoch: 76, loss: 0.412484
global_step: 35028, epoch: 76, loss: 0.455077
global_step: 35029, epoch: 76, loss: 0.394938
global_step: 35030, epoch: 76, loss: 0.437308
global_step: 35031, epoch: 76, loss: 0.509801
global_step: 35032, epoch: 76, loss: 0.417084
global_step: 35033, epoch: 76, loss: 0.404105
global_step: 35034, epoch: 76, loss: 0.493284
global_step: 35035, epoch: 76, loss: 0.471580
global_step: 35036, epoch: 76, loss: 0.471764
global_step: 35037, epoch: 76, loss: 0.471994
global_step: 35038, epoch: 76, loss: 0.538928
global_step: 35039, epoch: 76, loss: 0.441717
global_step: 35040, epoch: 76, loss: 0.378575
epoch: 76
train	acc: 0.9424	macro: p 0.9485, r 0.8856, f1: 0.9117	micro: p 0.9424, r 0.9424, f1 0.9424	weighted_f1:0.9419
dev	acc: 0.5302	macro: p 0.3766, r 0.3120, f1: 0.3045	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4910
test	acc: 0.5797	macro: p 0.3387, r 0.3292, f1: 0.3270	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5503
global_step: 35041, epoch: 77, loss: 0.423912
global_step: 35042, epoch: 77, loss: 0.381377
global_step: 35043, epoch: 77, loss: 0.473521
global_step: 35044, epoch: 77, loss: 0.513383
global_step: 35045, epoch: 77, loss: 0.514368
global_step: 35046, epoch: 77, loss: 0.435820
global_step: 35047, epoch: 77, loss: 0.430474
global_step: 35048, epoch: 77, loss: 0.416122
global_step: 35049, epoch: 77, loss: 0.393956
global_step: 35050, epoch: 77, loss: 0.418504
global_step: 35051, epoch: 77, loss: 0.479962
global_step: 35052, epoch: 77, loss: 0.328000
global_step: 35053, epoch: 77, loss: 0.408877
global_step: 35054, epoch: 77, loss: 0.424416
global_step: 35055, epoch: 77, loss: 0.399173
global_step: 35056, epoch: 77, loss: 0.432052
global_step: 35057, epoch: 77, loss: 0.403957
global_step: 35058, epoch: 77, loss: 0.498315
global_step: 35059, epoch: 77, loss: 0.516603
global_step: 35060, epoch: 77, loss: 0.454924
global_step: 35061, epoch: 77, loss: 0.469815
global_step: 35062, epoch: 77, loss: 0.525555
global_step: 35063, epoch: 77, loss: 0.457013
global_step: 35064, epoch: 77, loss: 0.431310
global_step: 35065, epoch: 77, loss: 0.381359
global_step: 35066, epoch: 77, loss: 0.460296
global_step: 35067, epoch: 77, loss: 0.479969
global_step: 35068, epoch: 77, loss: 0.484088
global_step: 35069, epoch: 77, loss: 0.501464
global_step: 35070, epoch: 77, loss: 0.536069
global_step: 35071, epoch: 77, loss: 0.406620
global_step: 35072, epoch: 77, loss: 0.466234
global_step: 35073, epoch: 77, loss: 0.472643
global_step: 35074, epoch: 77, loss: 0.460859
global_step: 35075, epoch: 77, loss: 0.520578
global_step: 35076, epoch: 77, loss: 0.481162
global_step: 35077, epoch: 77, loss: 0.492886
global_step: 35078, epoch: 77, loss: 0.431541
global_step: 35079, epoch: 77, loss: 0.407274
global_step: 35080, epoch: 77, loss: 0.341909
epoch: 77
train	acc: 0.9450	macro: p 0.9576, r 0.8922, f1: 0.9208	micro: p 0.9450, r 0.9450, f1 0.9450	weighted_f1:0.9445
dev	acc: 0.5392	macro: p 0.4603, r 0.3051, f1: 0.3039	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4897
test	acc: 0.5943	macro: p 0.3473, r 0.3159, f1: 0.3186	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5500
global_step: 35081, epoch: 78, loss: 0.452129
global_step: 35082, epoch: 78, loss: 0.429665
global_step: 35083, epoch: 78, loss: 0.447490
global_step: 35084, epoch: 78, loss: 0.418132
global_step: 35085, epoch: 78, loss: 0.462260
global_step: 35086, epoch: 78, loss: 0.345742
global_step: 35087, epoch: 78, loss: 0.474283
global_step: 35088, epoch: 78, loss: 0.485263
global_step: 35089, epoch: 78, loss: 0.459582
global_step: 35090, epoch: 78, loss: 0.447973
global_step: 35091, epoch: 78, loss: 0.433178
global_step: 35092, epoch: 78, loss: 0.470461
global_step: 35093, epoch: 78, loss: 0.354397
global_step: 35094, epoch: 78, loss: 0.403709
global_step: 35095, epoch: 78, loss: 0.438600
global_step: 35096, epoch: 78, loss: 0.459006
global_step: 35097, epoch: 78, loss: 0.454857
global_step: 35098, epoch: 78, loss: 0.491982
global_step: 35099, epoch: 78, loss: 0.529615
global_step: 35100, epoch: 78, loss: 0.356086
global_step: 35101, epoch: 78, loss: 0.462325
global_step: 35102, epoch: 78, loss: 0.451073
global_step: 35103, epoch: 78, loss: 0.497368
global_step: 35104, epoch: 78, loss: 0.468670
global_step: 35105, epoch: 78, loss: 0.467691
global_step: 35106, epoch: 78, loss: 0.410884
global_step: 35107, epoch: 78, loss: 0.427436
global_step: 35108, epoch: 78, loss: 0.457961
global_step: 35109, epoch: 78, loss: 0.389688
global_step: 35110, epoch: 78, loss: 0.468429
global_step: 35111, epoch: 78, loss: 0.445641
global_step: 35112, epoch: 78, loss: 0.397181
global_step: 35113, epoch: 78, loss: 0.415674
global_step: 35114, epoch: 78, loss: 0.411648
global_step: 35115, epoch: 78, loss: 0.368570
global_step: 35116, epoch: 78, loss: 0.525677
global_step: 35117, epoch: 78, loss: 0.543153
global_step: 35118, epoch: 78, loss: 0.376699
global_step: 35119, epoch: 78, loss: 0.478355
global_step: 35120, epoch: 78, loss: 0.197810
epoch: 78
train	acc: 0.9452	macro: p 0.9565, r 0.8915, f1: 0.9197	micro: p 0.9452, r 0.9452, f1 0.9452	weighted_f1:0.9447
dev	acc: 0.5446	macro: p 0.3278, r 0.3103, f1: 0.3035	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4974
test	acc: 0.5977	macro: p 0.3493, r 0.3198, f1: 0.3217	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5558
global_step: 35121, epoch: 79, loss: 0.530432
global_step: 35122, epoch: 79, loss: 0.370577
global_step: 35123, epoch: 79, loss: 0.462216
global_step: 35124, epoch: 79, loss: 0.413254
global_step: 35125, epoch: 79, loss: 0.439933
global_step: 35126, epoch: 79, loss: 0.465087
global_step: 35127, epoch: 79, loss: 0.379334
global_step: 35128, epoch: 79, loss: 0.459351
global_step: 35129, epoch: 79, loss: 0.403542
global_step: 35130, epoch: 79, loss: 0.417564
global_step: 35131, epoch: 79, loss: 0.404449
global_step: 35132, epoch: 79, loss: 0.369769
global_step: 35133, epoch: 79, loss: 0.373207
global_step: 35134, epoch: 79, loss: 0.552571
global_step: 35135, epoch: 79, loss: 0.464024
global_step: 35136, epoch: 79, loss: 0.393892
global_step: 35137, epoch: 79, loss: 0.576166
global_step: 35138, epoch: 79, loss: 0.414792
global_step: 35139, epoch: 79, loss: 0.433548
global_step: 35140, epoch: 79, loss: 0.423703
global_step: 35141, epoch: 79, loss: 0.385648
global_step: 35142, epoch: 79, loss: 0.380990
global_step: 35143, epoch: 79, loss: 0.490539
global_step: 35144, epoch: 79, loss: 0.500552
global_step: 35145, epoch: 79, loss: 0.457515
global_step: 35146, epoch: 79, loss: 0.423581
global_step: 35147, epoch: 79, loss: 0.399538
global_step: 35148, epoch: 79, loss: 0.357483
global_step: 35149, epoch: 79, loss: 0.441737
global_step: 35150, epoch: 79, loss: 0.467084
global_step: 35151, epoch: 79, loss: 0.454948
global_step: 35152, epoch: 79, loss: 0.410005
global_step: 35153, epoch: 79, loss: 0.370437
global_step: 35154, epoch: 79, loss: 0.434527
global_step: 35155, epoch: 79, loss: 0.435545
global_step: 35156, epoch: 79, loss: 0.492848
global_step: 35157, epoch: 79, loss: 0.437187
global_step: 35158, epoch: 79, loss: 0.391345
global_step: 35159, epoch: 79, loss: 0.432757
global_step: 35160, epoch: 79, loss: 1.006749
epoch: 79
train	acc: 0.9462	macro: p 0.9562, r 0.8945, f1: 0.9217	micro: p 0.9462, r 0.9462, f1 0.9462	weighted_f1:0.9457
dev	acc: 0.5491	macro: p 0.4041, r 0.3170, f1: 0.3158	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5032
test	acc: 0.5897	macro: p 0.3460, r 0.3178, f1: 0.3229	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5515
global_step: 35161, epoch: 80, loss: 0.399009
global_step: 35162, epoch: 80, loss: 0.482190
global_step: 35163, epoch: 80, loss: 0.391374
global_step: 35164, epoch: 80, loss: 0.383688
global_step: 35165, epoch: 80, loss: 0.397342
global_step: 35166, epoch: 80, loss: 0.473531
global_step: 35167, epoch: 80, loss: 0.422849
global_step: 35168, epoch: 80, loss: 0.376792
global_step: 35169, epoch: 80, loss: 0.366284
global_step: 35170, epoch: 80, loss: 0.385294
global_step: 35171, epoch: 80, loss: 0.420698
global_step: 35172, epoch: 80, loss: 0.452764
global_step: 35173, epoch: 80, loss: 0.357996
global_step: 35174, epoch: 80, loss: 0.463498
global_step: 35175, epoch: 80, loss: 0.401717
global_step: 35176, epoch: 80, loss: 0.351779
global_step: 35177, epoch: 80, loss: 0.413498
global_step: 35178, epoch: 80, loss: 0.396080
global_step: 35179, epoch: 80, loss: 0.428963
global_step: 35180, epoch: 80, loss: 0.394637
global_step: 35181, epoch: 80, loss: 0.449846
global_step: 35182, epoch: 80, loss: 0.431315
global_step: 35183, epoch: 80, loss: 0.451883
global_step: 35184, epoch: 80, loss: 0.423414
global_step: 35185, epoch: 80, loss: 0.404280
global_step: 35186, epoch: 80, loss: 0.452449
global_step: 35187, epoch: 80, loss: 0.477866
global_step: 35188, epoch: 80, loss: 0.435746
global_step: 35189, epoch: 80, loss: 0.468846
global_step: 35190, epoch: 80, loss: 0.373828
global_step: 35191, epoch: 80, loss: 0.365205
global_step: 35192, epoch: 80, loss: 0.447338
global_step: 35193, epoch: 80, loss: 0.472688
global_step: 35194, epoch: 80, loss: 0.441316
global_step: 35195, epoch: 80, loss: 0.520212
global_step: 35196, epoch: 80, loss: 0.387372
global_step: 35197, epoch: 80, loss: 0.476408
global_step: 35198, epoch: 80, loss: 0.478023
global_step: 35199, epoch: 80, loss: 0.533396
global_step: 35200, epoch: 80, loss: 0.444081
epoch: 80
train	acc: 0.9473	macro: p 0.9545, r 0.8996, f1: 0.9236	micro: p 0.9473, r 0.9473, f1 0.9473	weighted_f1:0.9470
dev	acc: 0.5419	macro: p 0.3899, r 0.3171, f1: 0.3155	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4994
test	acc: 0.5897	macro: p 0.3463, r 0.3244, f1: 0.3250	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5525
global_step: 35201, epoch: 81, loss: 0.404916
global_step: 35202, epoch: 81, loss: 0.384075
global_step: 35203, epoch: 81, loss: 0.453619
global_step: 35204, epoch: 81, loss: 0.400143
global_step: 35205, epoch: 81, loss: 0.390854
global_step: 35206, epoch: 81, loss: 0.341636
global_step: 35207, epoch: 81, loss: 0.411322
global_step: 35208, epoch: 81, loss: 0.465029
global_step: 35209, epoch: 81, loss: 0.453531
global_step: 35210, epoch: 81, loss: 0.373582
global_step: 35211, epoch: 81, loss: 0.349610
global_step: 35212, epoch: 81, loss: 0.428411
global_step: 35213, epoch: 81, loss: 0.491395
global_step: 35214, epoch: 81, loss: 0.430082
global_step: 35215, epoch: 81, loss: 0.429386
global_step: 35216, epoch: 81, loss: 0.469231
global_step: 35217, epoch: 81, loss: 0.432827
global_step: 35218, epoch: 81, loss: 0.429160
global_step: 35219, epoch: 81, loss: 0.370640
global_step: 35220, epoch: 81, loss: 0.458631
global_step: 35221, epoch: 81, loss: 0.426867
global_step: 35222, epoch: 81, loss: 0.471814
global_step: 35223, epoch: 81, loss: 0.440283
global_step: 35224, epoch: 81, loss: 0.413459
global_step: 35225, epoch: 81, loss: 0.525482
global_step: 35226, epoch: 81, loss: 0.411008
global_step: 35227, epoch: 81, loss: 0.406544
global_step: 35228, epoch: 81, loss: 0.345173
global_step: 35229, epoch: 81, loss: 0.427260
global_step: 35230, epoch: 81, loss: 0.383887
global_step: 35231, epoch: 81, loss: 0.366347
global_step: 35232, epoch: 81, loss: 0.380600
global_step: 35233, epoch: 81, loss: 0.357551
global_step: 35234, epoch: 81, loss: 0.339061
global_step: 35235, epoch: 81, loss: 0.434135
global_step: 35236, epoch: 81, loss: 0.571967
global_step: 35237, epoch: 81, loss: 0.414030
global_step: 35238, epoch: 81, loss: 0.433955
global_step: 35239, epoch: 81, loss: 0.459896
global_step: 35240, epoch: 81, loss: 0.091770
epoch: 81
train	acc: 0.9449	macro: p 0.9560, r 0.8913, f1: 0.9194	micro: p 0.9449, r 0.9449, f1 0.9449	weighted_f1:0.9444
dev	acc: 0.5410	macro: p 0.3262, r 0.3061, f1: 0.3001	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4929
test	acc: 0.5900	macro: p 0.3396, r 0.3132, f1: 0.3140	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5465
global_step: 35241, epoch: 82, loss: 0.361590
global_step: 35242, epoch: 82, loss: 0.382661
global_step: 35243, epoch: 82, loss: 0.440762
global_step: 35244, epoch: 82, loss: 0.443965
global_step: 35245, epoch: 82, loss: 0.498812
global_step: 35246, epoch: 82, loss: 0.339958
global_step: 35247, epoch: 82, loss: 0.378121
global_step: 35248, epoch: 82, loss: 0.432701
global_step: 35249, epoch: 82, loss: 0.410746
global_step: 35250, epoch: 82, loss: 0.357940
global_step: 35251, epoch: 82, loss: 0.407606
global_step: 35252, epoch: 82, loss: 0.381661
global_step: 35253, epoch: 82, loss: 0.431871
global_step: 35254, epoch: 82, loss: 0.342799
global_step: 35255, epoch: 82, loss: 0.339691
global_step: 35256, epoch: 82, loss: 0.384121
global_step: 35257, epoch: 82, loss: 0.327897
global_step: 35258, epoch: 82, loss: 0.404946
global_step: 35259, epoch: 82, loss: 0.388661
global_step: 35260, epoch: 82, loss: 0.462649
global_step: 35261, epoch: 82, loss: 0.367250
global_step: 35262, epoch: 82, loss: 0.466122
global_step: 35263, epoch: 82, loss: 0.462540
global_step: 35264, epoch: 82, loss: 0.414819
global_step: 35265, epoch: 82, loss: 0.427360
global_step: 35266, epoch: 82, loss: 0.413188
global_step: 35267, epoch: 82, loss: 0.411518
global_step: 35268, epoch: 82, loss: 0.441516
global_step: 35269, epoch: 82, loss: 0.382368
global_step: 35270, epoch: 82, loss: 0.444356
global_step: 35271, epoch: 82, loss: 0.395378
global_step: 35272, epoch: 82, loss: 0.447790
global_step: 35273, epoch: 82, loss: 0.527905
global_step: 35274, epoch: 82, loss: 0.500570
global_step: 35275, epoch: 82, loss: 0.468024
global_step: 35276, epoch: 82, loss: 0.416790
global_step: 35277, epoch: 82, loss: 0.371881
global_step: 35278, epoch: 82, loss: 0.512758
global_step: 35279, epoch: 82, loss: 0.391006
global_step: 35280, epoch: 82, loss: 0.587912
epoch: 82
train	acc: 0.9483	macro: p 0.9542, r 0.9066, f1: 0.9275	micro: p 0.9483, r 0.9483, f1 0.9483	weighted_f1:0.9481
dev	acc: 0.5392	macro: p 0.3794, r 0.3179, f1: 0.3198	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5028
test	acc: 0.5839	macro: p 0.3424, r 0.3246, f1: 0.3272	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5544
global_step: 35281, epoch: 83, loss: 0.461799
global_step: 35282, epoch: 83, loss: 0.491553
global_step: 35283, epoch: 83, loss: 0.315881
global_step: 35284, epoch: 83, loss: 0.424112
global_step: 35285, epoch: 83, loss: 0.301108
global_step: 35286, epoch: 83, loss: 0.388466
global_step: 35287, epoch: 83, loss: 0.329138
global_step: 35288, epoch: 83, loss: 0.347944
global_step: 35289, epoch: 83, loss: 0.403863
global_step: 35290, epoch: 83, loss: 0.480676
global_step: 35291, epoch: 83, loss: 0.358897
global_step: 35292, epoch: 83, loss: 0.372455
global_step: 35293, epoch: 83, loss: 0.322984
global_step: 35294, epoch: 83, loss: 0.495308
global_step: 35295, epoch: 83, loss: 0.413593
global_step: 35296, epoch: 83, loss: 0.423174
global_step: 35297, epoch: 83, loss: 0.423242
global_step: 35298, epoch: 83, loss: 0.446488
global_step: 35299, epoch: 83, loss: 0.424352
global_step: 35300, epoch: 83, loss: 0.434712
global_step: 35301, epoch: 83, loss: 0.427891
global_step: 35302, epoch: 83, loss: 0.382381
global_step: 35303, epoch: 83, loss: 0.435664
global_step: 35304, epoch: 83, loss: 0.377672
global_step: 35305, epoch: 83, loss: 0.364627
global_step: 35306, epoch: 83, loss: 0.336953
global_step: 35307, epoch: 83, loss: 0.442814
global_step: 35308, epoch: 83, loss: 0.419900
global_step: 35309, epoch: 83, loss: 0.394698
global_step: 35310, epoch: 83, loss: 0.444125
global_step: 35311, epoch: 83, loss: 0.437554
global_step: 35312, epoch: 83, loss: 0.402926
global_step: 35313, epoch: 83, loss: 0.459628
global_step: 35314, epoch: 83, loss: 0.385222
global_step: 35315, epoch: 83, loss: 0.415540
global_step: 35316, epoch: 83, loss: 0.305035
global_step: 35317, epoch: 83, loss: 0.384157
global_step: 35318, epoch: 83, loss: 0.396213
global_step: 35319, epoch: 83, loss: 0.432769
global_step: 35320, epoch: 83, loss: 0.153913
epoch: 83
train	acc: 0.9505	macro: p 0.9572, r 0.9049, f1: 0.9280	micro: p 0.9505, r 0.9505, f1 0.9505	weighted_f1:0.9502
dev	acc: 0.5437	macro: p 0.3955, r 0.3154, f1: 0.3137	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5014
test	acc: 0.5881	macro: p 0.3400, r 0.3175, f1: 0.3205	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5514
global_step: 35321, epoch: 84, loss: 0.332147
global_step: 35322, epoch: 84, loss: 0.416769
global_step: 35323, epoch: 84, loss: 0.378954
global_step: 35324, epoch: 84, loss: 0.334634
global_step: 35325, epoch: 84, loss: 0.405213
global_step: 35326, epoch: 84, loss: 0.389001
global_step: 35327, epoch: 84, loss: 0.412867
global_step: 35328, epoch: 84, loss: 0.477525
global_step: 35329, epoch: 84, loss: 0.442339
global_step: 35330, epoch: 84, loss: 0.443982
global_step: 35331, epoch: 84, loss: 0.373533
global_step: 35332, epoch: 84, loss: 0.368705
global_step: 35333, epoch: 84, loss: 0.362566
global_step: 35334, epoch: 84, loss: 0.382735
global_step: 35335, epoch: 84, loss: 0.377246
global_step: 35336, epoch: 84, loss: 0.368792
global_step: 35337, epoch: 84, loss: 0.370516
global_step: 35338, epoch: 84, loss: 0.374309
global_step: 35339, epoch: 84, loss: 0.438329
global_step: 35340, epoch: 84, loss: 0.323042
global_step: 35341, epoch: 84, loss: 0.409770
global_step: 35342, epoch: 84, loss: 0.460223
global_step: 35343, epoch: 84, loss: 0.415855
global_step: 35344, epoch: 84, loss: 0.426373
global_step: 35345, epoch: 84, loss: 0.415348
global_step: 35346, epoch: 84, loss: 0.457954
global_step: 35347, epoch: 84, loss: 0.393989
global_step: 35348, epoch: 84, loss: 0.428109
global_step: 35349, epoch: 84, loss: 0.443074
global_step: 35350, epoch: 84, loss: 0.335497
global_step: 35351, epoch: 84, loss: 0.438466
global_step: 35352, epoch: 84, loss: 0.366967
global_step: 35353, epoch: 84, loss: 0.369659
global_step: 35354, epoch: 84, loss: 0.412298
global_step: 35355, epoch: 84, loss: 0.407653
global_step: 35356, epoch: 84, loss: 0.376205
global_step: 35357, epoch: 84, loss: 0.368536
global_step: 35358, epoch: 84, loss: 0.404325
global_step: 35359, epoch: 84, loss: 0.439871
global_step: 35360, epoch: 84, loss: 0.633206
epoch: 84
train	acc: 0.9498	macro: p 0.9591, r 0.9057, f1: 0.9295	micro: p 0.9498, r 0.9498, f1 0.9498	weighted_f1:0.9495
dev	acc: 0.5428	macro: p 0.4722, r 0.3117, f1: 0.3082	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4974
test	acc: 0.5874	macro: p 0.3541, r 0.3113, f1: 0.3150	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5469
global_step: 35361, epoch: 85, loss: 0.415133
global_step: 35362, epoch: 85, loss: 0.403222
global_step: 35363, epoch: 85, loss: 0.353373
global_step: 35364, epoch: 85, loss: 0.448724
global_step: 35365, epoch: 85, loss: 0.380361
global_step: 35366, epoch: 85, loss: 0.396601
global_step: 35367, epoch: 85, loss: 0.385093
global_step: 35368, epoch: 85, loss: 0.410761
global_step: 35369, epoch: 85, loss: 0.391234
global_step: 35370, epoch: 85, loss: 0.389427
global_step: 35371, epoch: 85, loss: 0.347639
global_step: 35372, epoch: 85, loss: 0.455761
global_step: 35373, epoch: 85, loss: 0.427656
global_step: 35374, epoch: 85, loss: 0.383882
global_step: 35375, epoch: 85, loss: 0.429822
global_step: 35376, epoch: 85, loss: 0.386089
global_step: 35377, epoch: 85, loss: 0.326867
global_step: 35378, epoch: 85, loss: 0.364977
global_step: 35379, epoch: 85, loss: 0.385046
global_step: 35380, epoch: 85, loss: 0.479518
global_step: 35381, epoch: 85, loss: 0.397524
global_step: 35382, epoch: 85, loss: 0.366423
global_step: 35383, epoch: 85, loss: 0.449738
global_step: 35384, epoch: 85, loss: 0.422732
global_step: 35385, epoch: 85, loss: 0.367745
global_step: 35386, epoch: 85, loss: 0.359109
global_step: 35387, epoch: 85, loss: 0.554922
global_step: 35388, epoch: 85, loss: 0.325799
global_step: 35389, epoch: 85, loss: 0.417122
global_step: 35390, epoch: 85, loss: 0.365453
global_step: 35391, epoch: 85, loss: 0.374852
global_step: 35392, epoch: 85, loss: 0.426932
global_step: 35393, epoch: 85, loss: 0.392867
global_step: 35394, epoch: 85, loss: 0.360800
global_step: 35395, epoch: 85, loss: 0.471882
global_step: 35396, epoch: 85, loss: 0.332162
global_step: 35397, epoch: 85, loss: 0.442388
global_step: 35398, epoch: 85, loss: 0.396064
global_step: 35399, epoch: 85, loss: 0.428930
global_step: 35400, epoch: 85, loss: 0.373623
epoch: 85
train	acc: 0.9499	macro: p 0.9600, r 0.9075, f1: 0.9310	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9497
dev	acc: 0.5455	macro: p 0.3964, r 0.3142, f1: 0.3092	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4992
test	acc: 0.5881	macro: p 0.3505, r 0.3169, f1: 0.3202	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5496
global_step: 35401, epoch: 86, loss: 0.329516
global_step: 35402, epoch: 86, loss: 0.451414
global_step: 35403, epoch: 86, loss: 0.385000
global_step: 35404, epoch: 86, loss: 0.472786
global_step: 35405, epoch: 86, loss: 0.401355
global_step: 35406, epoch: 86, loss: 0.401133
global_step: 35407, epoch: 86, loss: 0.365176
global_step: 35408, epoch: 86, loss: 0.388057
global_step: 35409, epoch: 86, loss: 0.355104
global_step: 35410, epoch: 86, loss: 0.347068
global_step: 35411, epoch: 86, loss: 0.360832
global_step: 35412, epoch: 86, loss: 0.370861
global_step: 35413, epoch: 86, loss: 0.368761
global_step: 35414, epoch: 86, loss: 0.401402
global_step: 35415, epoch: 86, loss: 0.320193
global_step: 35416, epoch: 86, loss: 0.437317
global_step: 35417, epoch: 86, loss: 0.327781
global_step: 35418, epoch: 86, loss: 0.400302
global_step: 35419, epoch: 86, loss: 0.416501
global_step: 35420, epoch: 86, loss: 0.415683
global_step: 35421, epoch: 86, loss: 0.389663
global_step: 35422, epoch: 86, loss: 0.452153
global_step: 35423, epoch: 86, loss: 0.348624
global_step: 35424, epoch: 86, loss: 0.426350
global_step: 35425, epoch: 86, loss: 0.346675
global_step: 35426, epoch: 86, loss: 0.416639
global_step: 35427, epoch: 86, loss: 0.353498
global_step: 35428, epoch: 86, loss: 0.406470
global_step: 35429, epoch: 86, loss: 0.419974
global_step: 35430, epoch: 86, loss: 0.383396
global_step: 35431, epoch: 86, loss: 0.320476
global_step: 35432, epoch: 86, loss: 0.378298
global_step: 35433, epoch: 86, loss: 0.374187
global_step: 35434, epoch: 86, loss: 0.334137
global_step: 35435, epoch: 86, loss: 0.362701
global_step: 35436, epoch: 86, loss: 0.455714
global_step: 35437, epoch: 86, loss: 0.441802
global_step: 35438, epoch: 86, loss: 0.368786
global_step: 35439, epoch: 86, loss: 0.421030
global_step: 35440, epoch: 86, loss: 0.114296
epoch: 86
train	acc: 0.9496	macro: p 0.9620, r 0.9040, f1: 0.9298	micro: p 0.9496, r 0.9496, f1 0.9496	weighted_f1:0.9493
dev	acc: 0.5446	macro: p 0.3964, r 0.3104, f1: 0.3064	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4946
test	acc: 0.5939	macro: p 0.3476, r 0.3146, f1: 0.3168	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5495
global_step: 35441, epoch: 87, loss: 0.364748
global_step: 35442, epoch: 87, loss: 0.397309
global_step: 35443, epoch: 87, loss: 0.306498
global_step: 35444, epoch: 87, loss: 0.292235
global_step: 35445, epoch: 87, loss: 0.354081
global_step: 35446, epoch: 87, loss: 0.335697
global_step: 35447, epoch: 87, loss: 0.393339
global_step: 35448, epoch: 87, loss: 0.418371
global_step: 35449, epoch: 87, loss: 0.420826
global_step: 35450, epoch: 87, loss: 0.414670
global_step: 35451, epoch: 87, loss: 0.331067
global_step: 35452, epoch: 87, loss: 0.371380
global_step: 35453, epoch: 87, loss: 0.393717
global_step: 35454, epoch: 87, loss: 0.366370
global_step: 35455, epoch: 87, loss: 0.465626
global_step: 35456, epoch: 87, loss: 0.346189
global_step: 35457, epoch: 87, loss: 0.404381
global_step: 35458, epoch: 87, loss: 0.345774
global_step: 35459, epoch: 87, loss: 0.339871
global_step: 35460, epoch: 87, loss: 0.383966
global_step: 35461, epoch: 87, loss: 0.456375
global_step: 35462, epoch: 87, loss: 0.387608
global_step: 35463, epoch: 87, loss: 0.336878
global_step: 35464, epoch: 87, loss: 0.446143
global_step: 35465, epoch: 87, loss: 0.427066
global_step: 35466, epoch: 87, loss: 0.374917
global_step: 35467, epoch: 87, loss: 0.375272
global_step: 35468, epoch: 87, loss: 0.349694
global_step: 35469, epoch: 87, loss: 0.452852
global_step: 35470, epoch: 87, loss: 0.506098
global_step: 35471, epoch: 87, loss: 0.414818
global_step: 35472, epoch: 87, loss: 0.387147
global_step: 35473, epoch: 87, loss: 0.381139
global_step: 35474, epoch: 87, loss: 0.380583
global_step: 35475, epoch: 87, loss: 0.469155
global_step: 35476, epoch: 87, loss: 0.371654
global_step: 35477, epoch: 87, loss: 0.353524
global_step: 35478, epoch: 87, loss: 0.363711
global_step: 35479, epoch: 87, loss: 0.352325
global_step: 35480, epoch: 87, loss: 0.615932
epoch: 87
train	acc: 0.9536	macro: p 0.9616, r 0.9126, f1: 0.9347	micro: p 0.9536, r 0.9536, f1 0.9536	weighted_f1:0.9534
dev	acc: 0.5437	macro: p 0.4006, r 0.3147, f1: 0.3168	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4995
test	acc: 0.5870	macro: p 0.3422, r 0.3126, f1: 0.3164	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5479
global_step: 35481, epoch: 88, loss: 0.369758
global_step: 35482, epoch: 88, loss: 0.420766
global_step: 35483, epoch: 88, loss: 0.411945
global_step: 35484, epoch: 88, loss: 0.343271
global_step: 35485, epoch: 88, loss: 0.413273
global_step: 35486, epoch: 88, loss: 0.415680
global_step: 35487, epoch: 88, loss: 0.368052
global_step: 35488, epoch: 88, loss: 0.367827
global_step: 35489, epoch: 88, loss: 0.350765
global_step: 35490, epoch: 88, loss: 0.297594
global_step: 35491, epoch: 88, loss: 0.359898
global_step: 35492, epoch: 88, loss: 0.419323
global_step: 35493, epoch: 88, loss: 0.450617
global_step: 35494, epoch: 88, loss: 0.324059
global_step: 35495, epoch: 88, loss: 0.308312
global_step: 35496, epoch: 88, loss: 0.419808
global_step: 35497, epoch: 88, loss: 0.447960
global_step: 35498, epoch: 88, loss: 0.355853
global_step: 35499, epoch: 88, loss: 0.448885
global_step: 35500, epoch: 88, loss: 0.318305
global_step: 35501, epoch: 88, loss: 0.363955
global_step: 35502, epoch: 88, loss: 0.485274
global_step: 35503, epoch: 88, loss: 0.425465
global_step: 35504, epoch: 88, loss: 0.359656
global_step: 35505, epoch: 88, loss: 0.357470
global_step: 35506, epoch: 88, loss: 0.495859
global_step: 35507, epoch: 88, loss: 0.421479
global_step: 35508, epoch: 88, loss: 0.392002
global_step: 35509, epoch: 88, loss: 0.459034
global_step: 35510, epoch: 88, loss: 0.408483
global_step: 35511, epoch: 88, loss: 0.386460
global_step: 35512, epoch: 88, loss: 0.325697
global_step: 35513, epoch: 88, loss: 0.321057
global_step: 35514, epoch: 88, loss: 0.409704
global_step: 35515, epoch: 88, loss: 0.393772
global_step: 35516, epoch: 88, loss: 0.472534
global_step: 35517, epoch: 88, loss: 0.331510
global_step: 35518, epoch: 88, loss: 0.364152
global_step: 35519, epoch: 88, loss: 0.333043
global_step: 35520, epoch: 88, loss: 0.173875
epoch: 88
train	acc: 0.9510	macro: p 0.9617, r 0.9063, f1: 0.9310	micro: p 0.9510, r 0.9510, f1 0.9510	weighted_f1:0.9507
dev	acc: 0.5509	macro: p 0.4009, r 0.3175, f1: 0.3171	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5028
test	acc: 0.5904	macro: p 0.3438, r 0.3075, f1: 0.3097	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5435
global_step: 35521, epoch: 89, loss: 0.377689
global_step: 35522, epoch: 89, loss: 0.387104
global_step: 35523, epoch: 89, loss: 0.470713
global_step: 35524, epoch: 89, loss: 0.440335
global_step: 35525, epoch: 89, loss: 0.362911
global_step: 35526, epoch: 89, loss: 0.374085
global_step: 35527, epoch: 89, loss: 0.354024
global_step: 35528, epoch: 89, loss: 0.416730
global_step: 35529, epoch: 89, loss: 0.386115
global_step: 35530, epoch: 89, loss: 0.394740
global_step: 35531, epoch: 89, loss: 0.443537
global_step: 35532, epoch: 89, loss: 0.381602
global_step: 35533, epoch: 89, loss: 0.306943
global_step: 35534, epoch: 89, loss: 0.351683
global_step: 35535, epoch: 89, loss: 0.323237
global_step: 35536, epoch: 89, loss: 0.329827
global_step: 35537, epoch: 89, loss: 0.298153
global_step: 35538, epoch: 89, loss: 0.370429
global_step: 35539, epoch: 89, loss: 0.333972
global_step: 35540, epoch: 89, loss: 0.502056
global_step: 35541, epoch: 89, loss: 0.405477
global_step: 35542, epoch: 89, loss: 0.445557
global_step: 35543, epoch: 89, loss: 0.471281
global_step: 35544, epoch: 89, loss: 0.427017
global_step: 35545, epoch: 89, loss: 0.409120
global_step: 35546, epoch: 89, loss: 0.358590
global_step: 35547, epoch: 89, loss: 0.327669
global_step: 35548, epoch: 89, loss: 0.369170
global_step: 35549, epoch: 89, loss: 0.360345
global_step: 35550, epoch: 89, loss: 0.392618
global_step: 35551, epoch: 89, loss: 0.339468
global_step: 35552, epoch: 89, loss: 0.399452
global_step: 35553, epoch: 89, loss: 0.414726
global_step: 35554, epoch: 89, loss: 0.303010
global_step: 35555, epoch: 89, loss: 0.371506
global_step: 35556, epoch: 89, loss: 0.398019
global_step: 35557, epoch: 89, loss: 0.487347
global_step: 35558, epoch: 89, loss: 0.409309
global_step: 35559, epoch: 89, loss: 0.358232
global_step: 35560, epoch: 89, loss: 0.243834
epoch: 89
train	acc: 0.9553	macro: p 0.9616, r 0.9208, f1: 0.9394	micro: p 0.9553, r 0.9553, f1 0.9553	weighted_f1:0.9551
dev	acc: 0.5446	macro: p 0.3898, r 0.3197, f1: 0.3228	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5047
test	acc: 0.5897	macro: p 0.3644, r 0.3249, f1: 0.3314	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5559
global_step: 35561, epoch: 90, loss: 0.327911
global_step: 35562, epoch: 90, loss: 0.365611
global_step: 35563, epoch: 90, loss: 0.331187
global_step: 35564, epoch: 90, loss: 0.329282
global_step: 35565, epoch: 90, loss: 0.378011
global_step: 35566, epoch: 90, loss: 0.325209
global_step: 35567, epoch: 90, loss: 0.422487
global_step: 35568, epoch: 90, loss: 0.359807
global_step: 35569, epoch: 90, loss: 0.427612
global_step: 35570, epoch: 90, loss: 0.380168
global_step: 35571, epoch: 90, loss: 0.309665
global_step: 35572, epoch: 90, loss: 0.385048
global_step: 35573, epoch: 90, loss: 0.298548
global_step: 35574, epoch: 90, loss: 0.448667
global_step: 35575, epoch: 90, loss: 0.336743
global_step: 35576, epoch: 90, loss: 0.369691
global_step: 35577, epoch: 90, loss: 0.343985
global_step: 35578, epoch: 90, loss: 0.323172
global_step: 35579, epoch: 90, loss: 0.420167
global_step: 35580, epoch: 90, loss: 0.361430
global_step: 35581, epoch: 90, loss: 0.356309
global_step: 35582, epoch: 90, loss: 0.459028
global_step: 35583, epoch: 90, loss: 0.409430
global_step: 35584, epoch: 90, loss: 0.287487
global_step: 35585, epoch: 90, loss: 0.368748
global_step: 35586, epoch: 90, loss: 0.318253
global_step: 35587, epoch: 90, loss: 0.358513
global_step: 35588, epoch: 90, loss: 0.390059
global_step: 35589, epoch: 90, loss: 0.460119
global_step: 35590, epoch: 90, loss: 0.402942
global_step: 35591, epoch: 90, loss: 0.349996
global_step: 35592, epoch: 90, loss: 0.307620
global_step: 35593, epoch: 90, loss: 0.429481
global_step: 35594, epoch: 90, loss: 0.379066
global_step: 35595, epoch: 90, loss: 0.327941
global_step: 35596, epoch: 90, loss: 0.441118
global_step: 35597, epoch: 90, loss: 0.378476
global_step: 35598, epoch: 90, loss: 0.481429
global_step: 35599, epoch: 90, loss: 0.361748
global_step: 35600, epoch: 90, loss: 0.053021
epoch: 90
train	acc: 0.9536	macro: p 0.9633, r 0.9163, f1: 0.9376	micro: p 0.9536, r 0.9536, f1 0.9536	weighted_f1:0.9534
dev	acc: 0.5401	macro: p 0.4104, r 0.3102, f1: 0.3098	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4941
test	acc: 0.5904	macro: p 0.3764, r 0.3217, f1: 0.3292	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5518
global_step: 35601, epoch: 91, loss: 0.366912
global_step: 35602, epoch: 91, loss: 0.425767
global_step: 35603, epoch: 91, loss: 0.449825
global_step: 35604, epoch: 91, loss: 0.348296
global_step: 35605, epoch: 91, loss: 0.382061
global_step: 35606, epoch: 91, loss: 0.338933
global_step: 35607, epoch: 91, loss: 0.283099
global_step: 35608, epoch: 91, loss: 0.397132
global_step: 35609, epoch: 91, loss: 0.376013
global_step: 35610, epoch: 91, loss: 0.350242
global_step: 35611, epoch: 91, loss: 0.406769
global_step: 35612, epoch: 91, loss: 0.330227
global_step: 35613, epoch: 91, loss: 0.449506
global_step: 35614, epoch: 91, loss: 0.367646
global_step: 35615, epoch: 91, loss: 0.339308
global_step: 35616, epoch: 91, loss: 0.356739
global_step: 35617, epoch: 91, loss: 0.379958
global_step: 35618, epoch: 91, loss: 0.376532
global_step: 35619, epoch: 91, loss: 0.372182
global_step: 35620, epoch: 91, loss: 0.376032
global_step: 35621, epoch: 91, loss: 0.323800
global_step: 35622, epoch: 91, loss: 0.326145
global_step: 35623, epoch: 91, loss: 0.356004
global_step: 35624, epoch: 91, loss: 0.388292
global_step: 35625, epoch: 91, loss: 0.282535
global_step: 35626, epoch: 91, loss: 0.440707
global_step: 35627, epoch: 91, loss: 0.308009
global_step: 35628, epoch: 91, loss: 0.363343
global_step: 35629, epoch: 91, loss: 0.372149
global_step: 35630, epoch: 91, loss: 0.332581
global_step: 35631, epoch: 91, loss: 0.408937
global_step: 35632, epoch: 91, loss: 0.460517
global_step: 35633, epoch: 91, loss: 0.318057
global_step: 35634, epoch: 91, loss: 0.411488
global_step: 35635, epoch: 91, loss: 0.329914
global_step: 35636, epoch: 91, loss: 0.406910
global_step: 35637, epoch: 91, loss: 0.396777
global_step: 35638, epoch: 91, loss: 0.403918
global_step: 35639, epoch: 91, loss: 0.357146
global_step: 35640, epoch: 91, loss: 0.590623
epoch: 91
train	acc: 0.9557	macro: p 0.9632, r 0.9234, f1: 0.9416	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9555
dev	acc: 0.5473	macro: p 0.4381, r 0.3304, f1: 0.3398	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5071
test	acc: 0.5897	macro: p 0.3698, r 0.3240, f1: 0.3312	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5535
global_step: 35641, epoch: 92, loss: 0.369519
global_step: 35642, epoch: 92, loss: 0.375949
global_step: 35643, epoch: 92, loss: 0.336284
global_step: 35644, epoch: 92, loss: 0.315648
global_step: 35645, epoch: 92, loss: 0.348411
global_step: 35646, epoch: 92, loss: 0.358123
global_step: 35647, epoch: 92, loss: 0.408810
global_step: 35648, epoch: 92, loss: 0.395847
global_step: 35649, epoch: 92, loss: 0.364790
global_step: 35650, epoch: 92, loss: 0.371876
global_step: 35651, epoch: 92, loss: 0.425242
global_step: 35652, epoch: 92, loss: 0.290799
global_step: 35653, epoch: 92, loss: 0.454915
global_step: 35654, epoch: 92, loss: 0.331061
global_step: 35655, epoch: 92, loss: 0.343337
global_step: 35656, epoch: 92, loss: 0.405604
global_step: 35657, epoch: 92, loss: 0.398779
global_step: 35658, epoch: 92, loss: 0.329340
global_step: 35659, epoch: 92, loss: 0.339480
global_step: 35660, epoch: 92, loss: 0.343837
global_step: 35661, epoch: 92, loss: 0.349182
global_step: 35662, epoch: 92, loss: 0.360183
global_step: 35663, epoch: 92, loss: 0.312493
global_step: 35664, epoch: 92, loss: 0.331662
global_step: 35665, epoch: 92, loss: 0.339567
global_step: 35666, epoch: 92, loss: 0.345427
global_step: 35667, epoch: 92, loss: 0.345419
global_step: 35668, epoch: 92, loss: 0.439572
global_step: 35669, epoch: 92, loss: 0.349898
global_step: 35670, epoch: 92, loss: 0.382709
global_step: 35671, epoch: 92, loss: 0.348701
global_step: 35672, epoch: 92, loss: 0.351126
global_step: 35673, epoch: 92, loss: 0.373690
global_step: 35674, epoch: 92, loss: 0.466482
global_step: 35675, epoch: 92, loss: 0.368968
global_step: 35676, epoch: 92, loss: 0.388081
global_step: 35677, epoch: 92, loss: 0.391026
global_step: 35678, epoch: 92, loss: 0.346091
global_step: 35679, epoch: 92, loss: 0.452144
global_step: 35680, epoch: 92, loss: 0.370539
epoch: 92
train	acc: 0.9513	macro: p 0.9628, r 0.9142, f1: 0.9364	micro: p 0.9513, r 0.9513, f1 0.9513	weighted_f1:0.9511
dev	acc: 0.5329	macro: p 0.3850, r 0.3067, f1: 0.3052	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4904
test	acc: 0.5820	macro: p 0.3758, r 0.3193, f1: 0.3259	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5469
global_step: 35681, epoch: 93, loss: 0.332474
global_step: 35682, epoch: 93, loss: 0.225614
global_step: 35683, epoch: 93, loss: 0.319095
global_step: 35684, epoch: 93, loss: 0.400577
global_step: 35685, epoch: 93, loss: 0.443414
global_step: 35686, epoch: 93, loss: 0.461242
global_step: 35687, epoch: 93, loss: 0.364616
global_step: 35688, epoch: 93, loss: 0.274879
global_step: 35689, epoch: 93, loss: 0.356274
global_step: 35690, epoch: 93, loss: 0.368507
global_step: 35691, epoch: 93, loss: 0.367322
global_step: 35692, epoch: 93, loss: 0.380183
global_step: 35693, epoch: 93, loss: 0.404705
global_step: 35694, epoch: 93, loss: 0.359522
global_step: 35695, epoch: 93, loss: 0.320947
global_step: 35696, epoch: 93, loss: 0.429100
global_step: 35697, epoch: 93, loss: 0.381558
global_step: 35698, epoch: 93, loss: 0.361573
global_step: 35699, epoch: 93, loss: 0.364436
global_step: 35700, epoch: 93, loss: 0.295379
global_step: 35701, epoch: 93, loss: 0.496179
global_step: 35702, epoch: 93, loss: 0.341350
global_step: 35703, epoch: 93, loss: 0.333459
global_step: 35704, epoch: 93, loss: 0.395321
global_step: 35705, epoch: 93, loss: 0.377082
global_step: 35706, epoch: 93, loss: 0.344252
global_step: 35707, epoch: 93, loss: 0.390812
global_step: 35708, epoch: 93, loss: 0.406605
global_step: 35709, epoch: 93, loss: 0.325795
global_step: 35710, epoch: 93, loss: 0.324827
global_step: 35711, epoch: 93, loss: 0.369497
global_step: 35712, epoch: 93, loss: 0.447978
global_step: 35713, epoch: 93, loss: 0.359986
global_step: 35714, epoch: 93, loss: 0.310705
global_step: 35715, epoch: 93, loss: 0.420610
global_step: 35716, epoch: 93, loss: 0.335744
global_step: 35717, epoch: 93, loss: 0.391777
global_step: 35718, epoch: 93, loss: 0.444657
global_step: 35719, epoch: 93, loss: 0.494103
global_step: 35720, epoch: 93, loss: 0.641448
epoch: 93
train	acc: 0.9542	macro: p 0.9629, r 0.9188, f1: 0.9389	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9541
dev	acc: 0.5374	macro: p 0.3662, r 0.3058, f1: 0.3031	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4929
test	acc: 0.5866	macro: p 0.3760, r 0.3202, f1: 0.3273	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5507
global_step: 35721, epoch: 94, loss: 0.447211
global_step: 35722, epoch: 94, loss: 0.322120
global_step: 35723, epoch: 94, loss: 0.334027
global_step: 35724, epoch: 94, loss: 0.370734
global_step: 35725, epoch: 94, loss: 0.433692
global_step: 35726, epoch: 94, loss: 0.338067
global_step: 35727, epoch: 94, loss: 0.399439
global_step: 35728, epoch: 94, loss: 0.362910
global_step: 35729, epoch: 94, loss: 0.367072
global_step: 35730, epoch: 94, loss: 0.360258
global_step: 35731, epoch: 94, loss: 0.284166
global_step: 35732, epoch: 94, loss: 0.409022
global_step: 35733, epoch: 94, loss: 0.396133
global_step: 35734, epoch: 94, loss: 0.323337
global_step: 35735, epoch: 94, loss: 0.286702
global_step: 35736, epoch: 94, loss: 0.274657
global_step: 35737, epoch: 94, loss: 0.395258
global_step: 35738, epoch: 94, loss: 0.396891
global_step: 35739, epoch: 94, loss: 0.387282
global_step: 35740, epoch: 94, loss: 0.321700
global_step: 35741, epoch: 94, loss: 0.356734
global_step: 35742, epoch: 94, loss: 0.416314
global_step: 35743, epoch: 94, loss: 0.246498
global_step: 35744, epoch: 94, loss: 0.402102
global_step: 35745, epoch: 94, loss: 0.335943
global_step: 35746, epoch: 94, loss: 0.313790
global_step: 35747, epoch: 94, loss: 0.365310
global_step: 35748, epoch: 94, loss: 0.286646
global_step: 35749, epoch: 94, loss: 0.392771
global_step: 35750, epoch: 94, loss: 0.338522
global_step: 35751, epoch: 94, loss: 0.405533
global_step: 35752, epoch: 94, loss: 0.304896
global_step: 35753, epoch: 94, loss: 0.386028
global_step: 35754, epoch: 94, loss: 0.363540
global_step: 35755, epoch: 94, loss: 0.431042
global_step: 35756, epoch: 94, loss: 0.320984
global_step: 35757, epoch: 94, loss: 0.356639
global_step: 35758, epoch: 94, loss: 0.301108
global_step: 35759, epoch: 94, loss: 0.421770
global_step: 35760, epoch: 94, loss: 0.783367
epoch: 94
train	acc: 0.9556	macro: p 0.9644, r 0.9232, f1: 0.9422	micro: p 0.9556, r 0.9556, f1 0.9556	weighted_f1:0.9554
dev	acc: 0.5374	macro: p 0.3942, r 0.3100, f1: 0.3138	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4915
test	acc: 0.5920	macro: p 0.3771, r 0.3188, f1: 0.3282	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5521
global_step: 35761, epoch: 95, loss: 0.317677
global_step: 35762, epoch: 95, loss: 0.280531
global_step: 35763, epoch: 95, loss: 0.372618
global_step: 35764, epoch: 95, loss: 0.379143
global_step: 35765, epoch: 95, loss: 0.327773
global_step: 35766, epoch: 95, loss: 0.319732
global_step: 35767, epoch: 95, loss: 0.334479
global_step: 35768, epoch: 95, loss: 0.459928
global_step: 35769, epoch: 95, loss: 0.318511
global_step: 35770, epoch: 95, loss: 0.247972
global_step: 35771, epoch: 95, loss: 0.287280
global_step: 35772, epoch: 95, loss: 0.319249
global_step: 35773, epoch: 95, loss: 0.378038
global_step: 35774, epoch: 95, loss: 0.353166
global_step: 35775, epoch: 95, loss: 0.387708
global_step: 35776, epoch: 95, loss: 0.455329
global_step: 35777, epoch: 95, loss: 0.228359
global_step: 35778, epoch: 95, loss: 0.360239
global_step: 35779, epoch: 95, loss: 0.352902
global_step: 35780, epoch: 95, loss: 0.383610
global_step: 35781, epoch: 95, loss: 0.345935
global_step: 35782, epoch: 95, loss: 0.359121
global_step: 35783, epoch: 95, loss: 0.311438
global_step: 35784, epoch: 95, loss: 0.355815
global_step: 35785, epoch: 95, loss: 0.401734
global_step: 35786, epoch: 95, loss: 0.376016
global_step: 35787, epoch: 95, loss: 0.363393
global_step: 35788, epoch: 95, loss: 0.364532
global_step: 35789, epoch: 95, loss: 0.358805
global_step: 35790, epoch: 95, loss: 0.366164
global_step: 35791, epoch: 95, loss: 0.335944
global_step: 35792, epoch: 95, loss: 0.435607
global_step: 35793, epoch: 95, loss: 0.325662
global_step: 35794, epoch: 95, loss: 0.387826
global_step: 35795, epoch: 95, loss: 0.367077
global_step: 35796, epoch: 95, loss: 0.333509
global_step: 35797, epoch: 95, loss: 0.414896
global_step: 35798, epoch: 95, loss: 0.343023
global_step: 35799, epoch: 95, loss: 0.401462
global_step: 35800, epoch: 95, loss: 0.118772
epoch: 95
train	acc: 0.9570	macro: p 0.9629, r 0.9274, f1: 0.9437	micro: p 0.9570, r 0.9570, f1 0.9570	weighted_f1:0.9569
dev	acc: 0.5302	macro: p 0.3742, r 0.3102, f1: 0.3112	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4872
test	acc: 0.5877	macro: p 0.3544, r 0.3229, f1: 0.3263	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5505
global_step: 35801, epoch: 96, loss: 0.396210
global_step: 35802, epoch: 96, loss: 0.375465
global_step: 35803, epoch: 96, loss: 0.287925
global_step: 35804, epoch: 96, loss: 0.272407
global_step: 35805, epoch: 96, loss: 0.303767
global_step: 35806, epoch: 96, loss: 0.341457
global_step: 35807, epoch: 96, loss: 0.338464
global_step: 35808, epoch: 96, loss: 0.315672
global_step: 35809, epoch: 96, loss: 0.457442
global_step: 35810, epoch: 96, loss: 0.401775
global_step: 35811, epoch: 96, loss: 0.402838
global_step: 35812, epoch: 96, loss: 0.342632
global_step: 35813, epoch: 96, loss: 0.377428
global_step: 35814, epoch: 96, loss: 0.281623
global_step: 35815, epoch: 96, loss: 0.303999
global_step: 35816, epoch: 96, loss: 0.368158
global_step: 35817, epoch: 96, loss: 0.312394
global_step: 35818, epoch: 96, loss: 0.209099
global_step: 35819, epoch: 96, loss: 0.365120
global_step: 35820, epoch: 96, loss: 0.387121
global_step: 35821, epoch: 96, loss: 0.357511
global_step: 35822, epoch: 96, loss: 0.317381
global_step: 35823, epoch: 96, loss: 0.351308
global_step: 35824, epoch: 96, loss: 0.367701
global_step: 35825, epoch: 96, loss: 0.330040
global_step: 35826, epoch: 96, loss: 0.300712
global_step: 35827, epoch: 96, loss: 0.314158
global_step: 35828, epoch: 96, loss: 0.446042
global_step: 35829, epoch: 96, loss: 0.380000
global_step: 35830, epoch: 96, loss: 0.311744
global_step: 35831, epoch: 96, loss: 0.339968
global_step: 35832, epoch: 96, loss: 0.397183
global_step: 35833, epoch: 96, loss: 0.326978
global_step: 35834, epoch: 96, loss: 0.346899
global_step: 35835, epoch: 96, loss: 0.374369
global_step: 35836, epoch: 96, loss: 0.354835
global_step: 35837, epoch: 96, loss: 0.442464
global_step: 35838, epoch: 96, loss: 0.364614
global_step: 35839, epoch: 96, loss: 0.331219
global_step: 35840, epoch: 96, loss: 0.632215
epoch: 96
train	acc: 0.9589	macro: p 0.9651, r 0.9314, f1: 0.9470	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9588
dev	acc: 0.5356	macro: p 0.3733, r 0.3138, f1: 0.3135	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4966
test	acc: 0.5858	macro: p 0.3684, r 0.3234, f1: 0.3285	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5512
global_step: 35841, epoch: 97, loss: 0.321869
global_step: 35842, epoch: 97, loss: 0.439089
global_step: 35843, epoch: 97, loss: 0.308191
global_step: 35844, epoch: 97, loss: 0.330990
global_step: 35845, epoch: 97, loss: 0.306841
global_step: 35846, epoch: 97, loss: 0.352323
global_step: 35847, epoch: 97, loss: 0.360413
global_step: 35848, epoch: 97, loss: 0.362427
global_step: 35849, epoch: 97, loss: 0.399881
global_step: 35850, epoch: 97, loss: 0.355083
global_step: 35851, epoch: 97, loss: 0.368968
global_step: 35852, epoch: 97, loss: 0.305657
global_step: 35853, epoch: 97, loss: 0.289372
global_step: 35854, epoch: 97, loss: 0.311451
global_step: 35855, epoch: 97, loss: 0.369284
global_step: 35856, epoch: 97, loss: 0.313653
global_step: 35857, epoch: 97, loss: 0.354214
global_step: 35858, epoch: 97, loss: 0.346308
global_step: 35859, epoch: 97, loss: 0.343397
global_step: 35860, epoch: 97, loss: 0.391205
global_step: 35861, epoch: 97, loss: 0.398096
global_step: 35862, epoch: 97, loss: 0.297034
global_step: 35863, epoch: 97, loss: 0.363535
global_step: 35864, epoch: 97, loss: 0.321429
global_step: 35865, epoch: 97, loss: 0.337666
global_step: 35866, epoch: 97, loss: 0.358263
global_step: 35867, epoch: 97, loss: 0.281494
global_step: 35868, epoch: 97, loss: 0.337534
global_step: 35869, epoch: 97, loss: 0.331372
global_step: 35870, epoch: 97, loss: 0.343106
global_step: 35871, epoch: 97, loss: 0.342343
global_step: 35872, epoch: 97, loss: 0.332326
global_step: 35873, epoch: 97, loss: 0.342199
global_step: 35874, epoch: 97, loss: 0.321539
global_step: 35875, epoch: 97, loss: 0.334444
global_step: 35876, epoch: 97, loss: 0.382363
global_step: 35877, epoch: 97, loss: 0.305668
global_step: 35878, epoch: 97, loss: 0.357565
global_step: 35879, epoch: 97, loss: 0.397245
global_step: 35880, epoch: 97, loss: 0.075037
epoch: 97
train	acc: 0.9558	macro: p 0.9661, r 0.9206, f1: 0.9415	micro: p 0.9558, r 0.9558, f1 0.9558	weighted_f1:0.9555
dev	acc: 0.5410	macro: p 0.3686, r 0.3053, f1: 0.3071	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4921
test	acc: 0.5866	macro: p 0.3506, r 0.3074, f1: 0.3137	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5412
global_step: 35881, epoch: 98, loss: 0.364159
global_step: 35882, epoch: 98, loss: 0.270808
global_step: 35883, epoch: 98, loss: 0.330340
global_step: 35884, epoch: 98, loss: 0.323033
global_step: 35885, epoch: 98, loss: 0.284857
global_step: 35886, epoch: 98, loss: 0.335977
global_step: 35887, epoch: 98, loss: 0.364697
global_step: 35888, epoch: 98, loss: 0.327116
global_step: 35889, epoch: 98, loss: 0.351403
global_step: 35890, epoch: 98, loss: 0.307592
global_step: 35891, epoch: 98, loss: 0.387266
global_step: 35892, epoch: 98, loss: 0.270327
global_step: 35893, epoch: 98, loss: 0.320416
global_step: 35894, epoch: 98, loss: 0.309392
global_step: 35895, epoch: 98, loss: 0.343567
global_step: 35896, epoch: 98, loss: 0.323322
global_step: 35897, epoch: 98, loss: 0.310718
global_step: 35898, epoch: 98, loss: 0.281341
global_step: 35899, epoch: 98, loss: 0.322755
global_step: 35900, epoch: 98, loss: 0.254564
global_step: 35901, epoch: 98, loss: 0.402981
global_step: 35902, epoch: 98, loss: 0.399283
global_step: 35903, epoch: 98, loss: 0.365232
global_step: 35904, epoch: 98, loss: 0.391172
global_step: 35905, epoch: 98, loss: 0.270012
global_step: 35906, epoch: 98, loss: 0.286477
global_step: 35907, epoch: 98, loss: 0.322220
global_step: 35908, epoch: 98, loss: 0.346237
global_step: 35909, epoch: 98, loss: 0.280728
global_step: 35910, epoch: 98, loss: 0.337056
global_step: 35911, epoch: 98, loss: 0.304904
global_step: 35912, epoch: 98, loss: 0.398256
global_step: 35913, epoch: 98, loss: 0.359322
global_step: 35914, epoch: 98, loss: 0.307713
global_step: 35915, epoch: 98, loss: 0.298222
global_step: 35916, epoch: 98, loss: 0.335344
global_step: 35917, epoch: 98, loss: 0.394173
global_step: 35918, epoch: 98, loss: 0.410954
global_step: 35919, epoch: 98, loss: 0.379412
global_step: 35920, epoch: 98, loss: 0.160148
epoch: 98
train	acc: 0.9580	macro: p 0.9640, r 0.9303, f1: 0.9458	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9579
dev	acc: 0.5401	macro: p 0.3673, r 0.3221, f1: 0.3225	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.5050
test	acc: 0.5770	macro: p 0.3434, r 0.3207, f1: 0.3233	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5469
global_step: 35921, epoch: 99, loss: 0.309347
global_step: 35922, epoch: 99, loss: 0.368970
global_step: 35923, epoch: 99, loss: 0.294370
global_step: 35924, epoch: 99, loss: 0.262747
global_step: 35925, epoch: 99, loss: 0.307233
global_step: 35926, epoch: 99, loss: 0.373120
global_step: 35927, epoch: 99, loss: 0.330614
global_step: 35928, epoch: 99, loss: 0.371934
global_step: 35929, epoch: 99, loss: 0.297386
global_step: 35930, epoch: 99, loss: 0.318803
global_step: 35931, epoch: 99, loss: 0.343934
global_step: 35932, epoch: 99, loss: 0.376450
global_step: 35933, epoch: 99, loss: 0.341294
global_step: 35934, epoch: 99, loss: 0.332217
global_step: 35935, epoch: 99, loss: 0.325717
global_step: 35936, epoch: 99, loss: 0.331852
global_step: 35937, epoch: 99, loss: 0.325670
global_step: 35938, epoch: 99, loss: 0.295741
global_step: 35939, epoch: 99, loss: 0.352519
global_step: 35940, epoch: 99, loss: 0.393448
global_step: 35941, epoch: 99, loss: 0.326164
global_step: 35942, epoch: 99, loss: 0.297483
global_step: 35943, epoch: 99, loss: 0.380721
global_step: 35944, epoch: 99, loss: 0.361994
global_step: 35945, epoch: 99, loss: 0.353034
global_step: 35946, epoch: 99, loss: 0.322717
global_step: 35947, epoch: 99, loss: 0.365769
global_step: 35948, epoch: 99, loss: 0.322964
global_step: 35949, epoch: 99, loss: 0.344649
global_step: 35950, epoch: 99, loss: 0.346955
global_step: 35951, epoch: 99, loss: 0.329320
global_step: 35952, epoch: 99, loss: 0.327604
global_step: 35953, epoch: 99, loss: 0.401989
global_step: 35954, epoch: 99, loss: 0.295361
global_step: 35955, epoch: 99, loss: 0.348789
global_step: 35956, epoch: 99, loss: 0.323974
global_step: 35957, epoch: 99, loss: 0.370359
global_step: 35958, epoch: 99, loss: 0.321607
global_step: 35959, epoch: 99, loss: 0.382962
global_step: 35960, epoch: 99, loss: 0.054269
epoch: 99
train	acc: 0.9591	macro: p 0.9669, r 0.9292, f1: 0.9467	micro: p 0.9591, r 0.9591, f1 0.9591	weighted_f1:0.9589
dev	acc: 0.5401	macro: p 0.3703, r 0.3086, f1: 0.3071	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4937
test	acc: 0.5847	macro: p 0.3346, r 0.3118, f1: 0.3146	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5445
global_step: 35961, epoch: 100, loss: 0.305987
global_step: 35962, epoch: 100, loss: 0.356183
global_step: 35963, epoch: 100, loss: 0.374951
global_step: 35964, epoch: 100, loss: 0.272299
global_step: 35965, epoch: 100, loss: 0.309297
global_step: 35966, epoch: 100, loss: 0.313120
global_step: 35967, epoch: 100, loss: 0.257572
global_step: 35968, epoch: 100, loss: 0.331961
global_step: 35969, epoch: 100, loss: 0.248711
global_step: 35970, epoch: 100, loss: 0.307586
global_step: 35971, epoch: 100, loss: 0.330229
global_step: 35972, epoch: 100, loss: 0.351083
global_step: 35973, epoch: 100, loss: 0.311988
global_step: 35974, epoch: 100, loss: 0.274022
global_step: 35975, epoch: 100, loss: 0.433984
global_step: 35976, epoch: 100, loss: 0.272195
global_step: 35977, epoch: 100, loss: 0.314982
global_step: 35978, epoch: 100, loss: 0.329602
global_step: 35979, epoch: 100, loss: 0.342959
global_step: 35980, epoch: 100, loss: 0.323964
global_step: 35981, epoch: 100, loss: 0.408687
global_step: 35982, epoch: 100, loss: 0.314746
global_step: 35983, epoch: 100, loss: 0.330099
global_step: 35984, epoch: 100, loss: 0.318030
global_step: 35985, epoch: 100, loss: 0.305180
global_step: 35986, epoch: 100, loss: 0.338293
global_step: 35987, epoch: 100, loss: 0.221141
global_step: 35988, epoch: 100, loss: 0.319112
global_step: 35989, epoch: 100, loss: 0.366720
global_step: 35990, epoch: 100, loss: 0.312824
global_step: 35991, epoch: 100, loss: 0.298531
global_step: 35992, epoch: 100, loss: 0.335369
global_step: 35993, epoch: 100, loss: 0.305801
global_step: 35994, epoch: 100, loss: 0.406824
global_step: 35995, epoch: 100, loss: 0.297198
global_step: 35996, epoch: 100, loss: 0.338752
global_step: 35997, epoch: 100, loss: 0.269065
global_step: 35998, epoch: 100, loss: 0.379142
global_step: 35999, epoch: 100, loss: 0.341330
global_step: 36000, epoch: 100, loss: 0.161700
epoch: 100
train	acc: 0.9585	macro: p 0.9648, r 0.9300, f1: 0.9460	micro: p 0.9585, r 0.9585, f1 0.9585	weighted_f1:0.9584
dev	acc: 0.5365	macro: p 0.3667, r 0.3113, f1: 0.3086	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4970
test	acc: 0.5747	macro: p 0.3277, r 0.3124, f1: 0.3121	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5412
global_step: 36001, epoch: 101, loss: 0.278728
global_step: 36002, epoch: 101, loss: 0.308437
global_step: 36003, epoch: 101, loss: 0.353502
global_step: 36004, epoch: 101, loss: 0.266068
global_step: 36005, epoch: 101, loss: 0.324804
global_step: 36006, epoch: 101, loss: 0.353015
global_step: 36007, epoch: 101, loss: 0.297806
global_step: 36008, epoch: 101, loss: 0.394513
global_step: 36009, epoch: 101, loss: 0.310311
global_step: 36010, epoch: 101, loss: 0.281794
global_step: 36011, epoch: 101, loss: 0.353343
global_step: 36012, epoch: 101, loss: 0.316617
global_step: 36013, epoch: 101, loss: 0.322806
global_step: 36014, epoch: 101, loss: 0.348653
global_step: 36015, epoch: 101, loss: 0.384223
global_step: 36016, epoch: 101, loss: 0.299890
global_step: 36017, epoch: 101, loss: 0.377520
global_step: 36018, epoch: 101, loss: 0.303587
global_step: 36019, epoch: 101, loss: 0.291734
global_step: 36020, epoch: 101, loss: 0.351828
global_step: 36021, epoch: 101, loss: 0.282252
global_step: 36022, epoch: 101, loss: 0.327075
global_step: 36023, epoch: 101, loss: 0.274160
global_step: 36024, epoch: 101, loss: 0.326682
global_step: 36025, epoch: 101, loss: 0.332661
global_step: 36026, epoch: 101, loss: 0.313721
global_step: 36027, epoch: 101, loss: 0.414474
global_step: 36028, epoch: 101, loss: 0.281788
global_step: 36029, epoch: 101, loss: 0.292530
global_step: 36030, epoch: 101, loss: 0.256497
global_step: 36031, epoch: 101, loss: 0.321004
global_step: 36032, epoch: 101, loss: 0.388866
global_step: 36033, epoch: 101, loss: 0.310606
global_step: 36034, epoch: 101, loss: 0.346225
global_step: 36035, epoch: 101, loss: 0.351763
global_step: 36036, epoch: 101, loss: 0.336400
global_step: 36037, epoch: 101, loss: 0.301382
global_step: 36038, epoch: 101, loss: 0.342220
global_step: 36039, epoch: 101, loss: 0.413790
global_step: 36040, epoch: 101, loss: 0.068982
epoch: 101
train	acc: 0.9607	macro: p 0.9659, r 0.9351, f1: 0.9494	micro: p 0.9607, r 0.9607, f1 0.9607	weighted_f1:0.9606
dev	acc: 0.5311	macro: p 0.3492, r 0.3057, f1: 0.3054	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4894
test	acc: 0.5831	macro: p 0.3579, r 0.3229, f1: 0.3292	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5493
global_step: 36041, epoch: 102, loss: 0.368681
global_step: 36042, epoch: 102, loss: 0.330441
global_step: 36043, epoch: 102, loss: 0.291781
global_step: 36044, epoch: 102, loss: 0.307894
global_step: 36045, epoch: 102, loss: 0.417341
global_step: 36046, epoch: 102, loss: 0.298137
global_step: 36047, epoch: 102, loss: 0.225450
global_step: 36048, epoch: 102, loss: 0.440305
global_step: 36049, epoch: 102, loss: 0.324766
global_step: 36050, epoch: 102, loss: 0.280166
global_step: 36051, epoch: 102, loss: 0.279304
global_step: 36052, epoch: 102, loss: 0.308838
global_step: 36053, epoch: 102, loss: 0.307837
global_step: 36054, epoch: 102, loss: 0.310266
global_step: 36055, epoch: 102, loss: 0.326038
global_step: 36056, epoch: 102, loss: 0.339465
global_step: 36057, epoch: 102, loss: 0.363336
global_step: 36058, epoch: 102, loss: 0.310264
global_step: 36059, epoch: 102, loss: 0.330465
global_step: 36060, epoch: 102, loss: 0.317281
global_step: 36061, epoch: 102, loss: 0.347679
global_step: 36062, epoch: 102, loss: 0.288369
global_step: 36063, epoch: 102, loss: 0.299711
global_step: 36064, epoch: 102, loss: 0.303783
global_step: 36065, epoch: 102, loss: 0.217444
global_step: 36066, epoch: 102, loss: 0.252718
global_step: 36067, epoch: 102, loss: 0.301969
global_step: 36068, epoch: 102, loss: 0.306974
global_step: 36069, epoch: 102, loss: 0.333906
global_step: 36070, epoch: 102, loss: 0.379834
global_step: 36071, epoch: 102, loss: 0.441993
global_step: 36072, epoch: 102, loss: 0.280670
global_step: 36073, epoch: 102, loss: 0.325390
global_step: 36074, epoch: 102, loss: 0.283883
global_step: 36075, epoch: 102, loss: 0.299379
global_step: 36076, epoch: 102, loss: 0.264047
global_step: 36077, epoch: 102, loss: 0.260620
global_step: 36078, epoch: 102, loss: 0.386495
global_step: 36079, epoch: 102, loss: 0.372817
global_step: 36080, epoch: 102, loss: 0.233702
epoch: 102
train	acc: 0.9576	macro: p 0.9661, r 0.9252, f1: 0.9440	micro: p 0.9576, r 0.9576, f1 0.9576	weighted_f1:0.9574
dev	acc: 0.5383	macro: p 0.3701, r 0.3080, f1: 0.3058	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4926
test	acc: 0.5881	macro: p 0.3370, r 0.3128, f1: 0.3127	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5454
global_step: 36081, epoch: 103, loss: 0.338112
global_step: 36082, epoch: 103, loss: 0.400682
global_step: 36083, epoch: 103, loss: 0.396400
global_step: 36084, epoch: 103, loss: 0.348638
global_step: 36085, epoch: 103, loss: 0.340263
global_step: 36086, epoch: 103, loss: 0.293489
global_step: 36087, epoch: 103, loss: 0.321111
global_step: 36088, epoch: 103, loss: 0.308177
global_step: 36089, epoch: 103, loss: 0.300192
global_step: 36090, epoch: 103, loss: 0.331878
global_step: 36091, epoch: 103, loss: 0.326821
global_step: 36092, epoch: 103, loss: 0.273762
global_step: 36093, epoch: 103, loss: 0.301252
global_step: 36094, epoch: 103, loss: 0.242601
global_step: 36095, epoch: 103, loss: 0.392821
global_step: 36096, epoch: 103, loss: 0.304001
global_step: 36097, epoch: 103, loss: 0.309902
global_step: 36098, epoch: 103, loss: 0.293603
global_step: 36099, epoch: 103, loss: 0.275989
global_step: 36100, epoch: 103, loss: 0.321468
global_step: 36101, epoch: 103, loss: 0.261572
global_step: 36102, epoch: 103, loss: 0.299756
global_step: 36103, epoch: 103, loss: 0.272198
global_step: 36104, epoch: 103, loss: 0.324305
global_step: 36105, epoch: 103, loss: 0.326186
global_step: 36106, epoch: 103, loss: 0.335469
global_step: 36107, epoch: 103, loss: 0.353903
global_step: 36108, epoch: 103, loss: 0.334682
global_step: 36109, epoch: 103, loss: 0.334242
global_step: 36110, epoch: 103, loss: 0.265425
global_step: 36111, epoch: 103, loss: 0.280080
global_step: 36112, epoch: 103, loss: 0.297133
global_step: 36113, epoch: 103, loss: 0.480960
global_step: 36114, epoch: 103, loss: 0.251683
global_step: 36115, epoch: 103, loss: 0.309488
global_step: 36116, epoch: 103, loss: 0.367562
global_step: 36117, epoch: 103, loss: 0.296903
global_step: 36118, epoch: 103, loss: 0.375207
global_step: 36119, epoch: 103, loss: 0.364247
global_step: 36120, epoch: 103, loss: 0.644840
epoch: 103
train	acc: 0.9616	macro: p 0.9657, r 0.9390, f1: 0.9514	micro: p 0.9616, r 0.9616, f1 0.9616	weighted_f1:0.9616
dev	acc: 0.5284	macro: p 0.3720, r 0.3183, f1: 0.3207	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4958
test	acc: 0.5805	macro: p 0.3346, r 0.3215, f1: 0.3227	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5499
global_step: 36121, epoch: 104, loss: 0.276628
global_step: 36122, epoch: 104, loss: 0.286719
global_step: 36123, epoch: 104, loss: 0.316599
global_step: 36124, epoch: 104, loss: 0.380122
global_step: 36125, epoch: 104, loss: 0.283187
global_step: 36126, epoch: 104, loss: 0.359618
global_step: 36127, epoch: 104, loss: 0.284807
global_step: 36128, epoch: 104, loss: 0.328176
global_step: 36129, epoch: 104, loss: 0.236938
global_step: 36130, epoch: 104, loss: 0.343469
global_step: 36131, epoch: 104, loss: 0.319422
global_step: 36132, epoch: 104, loss: 0.260309
global_step: 36133, epoch: 104, loss: 0.298705
global_step: 36134, epoch: 104, loss: 0.278713
global_step: 36135, epoch: 104, loss: 0.313014
global_step: 36136, epoch: 104, loss: 0.311640
global_step: 36137, epoch: 104, loss: 0.307059
global_step: 36138, epoch: 104, loss: 0.255862
global_step: 36139, epoch: 104, loss: 0.289844
global_step: 36140, epoch: 104, loss: 0.286562
global_step: 36141, epoch: 104, loss: 0.336286
global_step: 36142, epoch: 104, loss: 0.263774
global_step: 36143, epoch: 104, loss: 0.317122
global_step: 36144, epoch: 104, loss: 0.339927
global_step: 36145, epoch: 104, loss: 0.348646
global_step: 36146, epoch: 104, loss: 0.292966
global_step: 36147, epoch: 104, loss: 0.329524
global_step: 36148, epoch: 104, loss: 0.351704
global_step: 36149, epoch: 104, loss: 0.257602
global_step: 36150, epoch: 104, loss: 0.378968
global_step: 36151, epoch: 104, loss: 0.320007
global_step: 36152, epoch: 104, loss: 0.354898
global_step: 36153, epoch: 104, loss: 0.297380
global_step: 36154, epoch: 104, loss: 0.303490
global_step: 36155, epoch: 104, loss: 0.302836
global_step: 36156, epoch: 104, loss: 0.438168
global_step: 36157, epoch: 104, loss: 0.365325
global_step: 36158, epoch: 104, loss: 0.371214
global_step: 36159, epoch: 104, loss: 0.393137
global_step: 36160, epoch: 104, loss: 0.156223
epoch: 104
train	acc: 0.9601	macro: p 0.9686, r 0.9328, f1: 0.9496	micro: p 0.9601, r 0.9601, f1 0.9601	weighted_f1:0.9600
dev	acc: 0.5347	macro: p 0.3603, r 0.2990, f1: 0.3002	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4846
test	acc: 0.5920	macro: p 0.3621, r 0.3112, f1: 0.3190	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5463
global_step: 36161, epoch: 105, loss: 0.287479
global_step: 36162, epoch: 105, loss: 0.247366
global_step: 36163, epoch: 105, loss: 0.281305
global_step: 36164, epoch: 105, loss: 0.253461
global_step: 36165, epoch: 105, loss: 0.247029
global_step: 36166, epoch: 105, loss: 0.334823
global_step: 36167, epoch: 105, loss: 0.270941
global_step: 36168, epoch: 105, loss: 0.300496
global_step: 36169, epoch: 105, loss: 0.324900
global_step: 36170, epoch: 105, loss: 0.242067
global_step: 36171, epoch: 105, loss: 0.328150
global_step: 36172, epoch: 105, loss: 0.278584
global_step: 36173, epoch: 105, loss: 0.316626
global_step: 36174, epoch: 105, loss: 0.348812
global_step: 36175, epoch: 105, loss: 0.280315
global_step: 36176, epoch: 105, loss: 0.310789
global_step: 36177, epoch: 105, loss: 0.277703
global_step: 36178, epoch: 105, loss: 0.274355
global_step: 36179, epoch: 105, loss: 0.255647
global_step: 36180, epoch: 105, loss: 0.342627
global_step: 36181, epoch: 105, loss: 0.424756
global_step: 36182, epoch: 105, loss: 0.219434
global_step: 36183, epoch: 105, loss: 0.369569
global_step: 36184, epoch: 105, loss: 0.333801
global_step: 36185, epoch: 105, loss: 0.341219
global_step: 36186, epoch: 105, loss: 0.314602
global_step: 36187, epoch: 105, loss: 0.292033
global_step: 36188, epoch: 105, loss: 0.319479
global_step: 36189, epoch: 105, loss: 0.314960
global_step: 36190, epoch: 105, loss: 0.324768
global_step: 36191, epoch: 105, loss: 0.340323
global_step: 36192, epoch: 105, loss: 0.314846
global_step: 36193, epoch: 105, loss: 0.308426
global_step: 36194, epoch: 105, loss: 0.314606
global_step: 36195, epoch: 105, loss: 0.307465
global_step: 36196, epoch: 105, loss: 0.308114
global_step: 36197, epoch: 105, loss: 0.328901
global_step: 36198, epoch: 105, loss: 0.352435
global_step: 36199, epoch: 105, loss: 0.350458
global_step: 36200, epoch: 105, loss: 0.019700
epoch: 105
train	acc: 0.9618	macro: p 0.9674, r 0.9372, f1: 0.9513	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9617
dev	acc: 0.5365	macro: p 0.3671, r 0.3124, f1: 0.3116	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4969
test	acc: 0.5820	macro: p 0.3439, r 0.3169, f1: 0.3194	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5457
global_step: 36201, epoch: 106, loss: 0.293662
global_step: 36202, epoch: 106, loss: 0.270652
global_step: 36203, epoch: 106, loss: 0.360210
global_step: 36204, epoch: 106, loss: 0.280057
global_step: 36205, epoch: 106, loss: 0.247953
global_step: 36206, epoch: 106, loss: 0.309958
global_step: 36207, epoch: 106, loss: 0.343643
global_step: 36208, epoch: 106, loss: 0.255855
global_step: 36209, epoch: 106, loss: 0.320433
global_step: 36210, epoch: 106, loss: 0.287669
global_step: 36211, epoch: 106, loss: 0.287800
global_step: 36212, epoch: 106, loss: 0.226103
global_step: 36213, epoch: 106, loss: 0.348475
global_step: 36214, epoch: 106, loss: 0.263840
global_step: 36215, epoch: 106, loss: 0.275942
global_step: 36216, epoch: 106, loss: 0.417468
global_step: 36217, epoch: 106, loss: 0.257264
global_step: 36218, epoch: 106, loss: 0.289194
global_step: 36219, epoch: 106, loss: 0.288316
global_step: 36220, epoch: 106, loss: 0.275940
global_step: 36221, epoch: 106, loss: 0.294179
global_step: 36222, epoch: 106, loss: 0.309321
global_step: 36223, epoch: 106, loss: 0.273764
global_step: 36224, epoch: 106, loss: 0.383335
global_step: 36225, epoch: 106, loss: 0.301670
global_step: 36226, epoch: 106, loss: 0.233193
global_step: 36227, epoch: 106, loss: 0.319467
global_step: 36228, epoch: 106, loss: 0.383372
global_step: 36229, epoch: 106, loss: 0.341170
global_step: 36230, epoch: 106, loss: 0.306196
global_step: 36231, epoch: 106, loss: 0.248825
global_step: 36232, epoch: 106, loss: 0.381741
global_step: 36233, epoch: 106, loss: 0.290444
global_step: 36234, epoch: 106, loss: 0.407174
global_step: 36235, epoch: 106, loss: 0.326178
global_step: 36236, epoch: 106, loss: 0.322014
global_step: 36237, epoch: 106, loss: 0.373527
global_step: 36238, epoch: 106, loss: 0.363339
global_step: 36239, epoch: 106, loss: 0.329974
global_step: 36240, epoch: 106, loss: 0.421389
epoch: 106
train	acc: 0.9616	macro: p 0.9659, r 0.9376, f1: 0.9508	micro: p 0.9616, r 0.9616, f1 0.9616	weighted_f1:0.9615
dev	acc: 0.5374	macro: p 0.4009, r 0.3128, f1: 0.3143	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4965
test	acc: 0.5851	macro: p 0.3511, r 0.3186, f1: 0.3197	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5472
global_step: 36241, epoch: 107, loss: 0.340520
global_step: 36242, epoch: 107, loss: 0.347387
global_step: 36243, epoch: 107, loss: 0.397794
global_step: 36244, epoch: 107, loss: 0.345459
global_step: 36245, epoch: 107, loss: 0.370049
global_step: 36246, epoch: 107, loss: 0.283999
global_step: 36247, epoch: 107, loss: 0.269288
global_step: 36248, epoch: 107, loss: 0.303194
global_step: 36249, epoch: 107, loss: 0.268492
global_step: 36250, epoch: 107, loss: 0.242837
global_step: 36251, epoch: 107, loss: 0.266596
global_step: 36252, epoch: 107, loss: 0.286310
global_step: 36253, epoch: 107, loss: 0.222396
global_step: 36254, epoch: 107, loss: 0.245848
global_step: 36255, epoch: 107, loss: 0.304110
global_step: 36256, epoch: 107, loss: 0.311002
global_step: 36257, epoch: 107, loss: 0.374293
global_step: 36258, epoch: 107, loss: 0.243903
global_step: 36259, epoch: 107, loss: 0.270752
global_step: 36260, epoch: 107, loss: 0.329398
global_step: 36261, epoch: 107, loss: 0.342385
global_step: 36262, epoch: 107, loss: 0.290447
global_step: 36263, epoch: 107, loss: 0.329561
global_step: 36264, epoch: 107, loss: 0.375269
global_step: 36265, epoch: 107, loss: 0.327850
global_step: 36266, epoch: 107, loss: 0.340417
global_step: 36267, epoch: 107, loss: 0.310610
global_step: 36268, epoch: 107, loss: 0.330350
global_step: 36269, epoch: 107, loss: 0.341229
global_step: 36270, epoch: 107, loss: 0.287739
global_step: 36271, epoch: 107, loss: 0.315458
global_step: 36272, epoch: 107, loss: 0.398945
global_step: 36273, epoch: 107, loss: 0.394927
global_step: 36274, epoch: 107, loss: 0.303302
global_step: 36275, epoch: 107, loss: 0.318245
global_step: 36276, epoch: 107, loss: 0.317062
global_step: 36277, epoch: 107, loss: 0.295301
global_step: 36278, epoch: 107, loss: 0.286376
global_step: 36279, epoch: 107, loss: 0.274463
global_step: 36280, epoch: 107, loss: 0.412904
epoch: 107
train	acc: 0.9622	macro: p 0.9678, r 0.9370, f1: 0.9515	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9621
dev	acc: 0.5374	macro: p 0.3547, r 0.3097, f1: 0.3084	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4945
test	acc: 0.5847	macro: p 0.3594, r 0.3128, f1: 0.3198	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5456
global_step: 36281, epoch: 108, loss: 0.336003
global_step: 36282, epoch: 108, loss: 0.289710
global_step: 36283, epoch: 108, loss: 0.295832
global_step: 36284, epoch: 108, loss: 0.314860
global_step: 36285, epoch: 108, loss: 0.300025
global_step: 36286, epoch: 108, loss: 0.262070
global_step: 36287, epoch: 108, loss: 0.235124
global_step: 36288, epoch: 108, loss: 0.242213
global_step: 36289, epoch: 108, loss: 0.280110
global_step: 36290, epoch: 108, loss: 0.326568
global_step: 36291, epoch: 108, loss: 0.292254
global_step: 36292, epoch: 108, loss: 0.239720
global_step: 36293, epoch: 108, loss: 0.362536
global_step: 36294, epoch: 108, loss: 0.310103
global_step: 36295, epoch: 108, loss: 0.326797
global_step: 36296, epoch: 108, loss: 0.282124
global_step: 36297, epoch: 108, loss: 0.314446
global_step: 36298, epoch: 108, loss: 0.306050
global_step: 36299, epoch: 108, loss: 0.374424
global_step: 36300, epoch: 108, loss: 0.263984
global_step: 36301, epoch: 108, loss: 0.346960
global_step: 36302, epoch: 108, loss: 0.295945
global_step: 36303, epoch: 108, loss: 0.320518
global_step: 36304, epoch: 108, loss: 0.310572
global_step: 36305, epoch: 108, loss: 0.287552
global_step: 36306, epoch: 108, loss: 0.301644
global_step: 36307, epoch: 108, loss: 0.249357
global_step: 36308, epoch: 108, loss: 0.297578
global_step: 36309, epoch: 108, loss: 0.313778
global_step: 36310, epoch: 108, loss: 0.299648
global_step: 36311, epoch: 108, loss: 0.334487
global_step: 36312, epoch: 108, loss: 0.313622
global_step: 36313, epoch: 108, loss: 0.340650
global_step: 36314, epoch: 108, loss: 0.345742
global_step: 36315, epoch: 108, loss: 0.228533
global_step: 36316, epoch: 108, loss: 0.324594
global_step: 36317, epoch: 108, loss: 0.374077
global_step: 36318, epoch: 108, loss: 0.320412
global_step: 36319, epoch: 108, loss: 0.271500
global_step: 36320, epoch: 108, loss: 0.394305
epoch: 108
train	acc: 0.9631	macro: p 0.9674, r 0.9415, f1: 0.9537	micro: p 0.9631, r 0.9631, f1 0.9631	weighted_f1:0.9631
dev	acc: 0.5437	macro: p 0.3652, r 0.3235, f1: 0.3231	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5083
test	acc: 0.5820	macro: p 0.3460, r 0.3204, f1: 0.3245	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5487
global_step: 36321, epoch: 109, loss: 0.298893
global_step: 36322, epoch: 109, loss: 0.278150
global_step: 36323, epoch: 109, loss: 0.299114
global_step: 36324, epoch: 109, loss: 0.256730
global_step: 36325, epoch: 109, loss: 0.370361
global_step: 36326, epoch: 109, loss: 0.334513
global_step: 36327, epoch: 109, loss: 0.306089
global_step: 36328, epoch: 109, loss: 0.328111
global_step: 36329, epoch: 109, loss: 0.285948
global_step: 36330, epoch: 109, loss: 0.241957
global_step: 36331, epoch: 109, loss: 0.291330
global_step: 36332, epoch: 109, loss: 0.309873
global_step: 36333, epoch: 109, loss: 0.262444
global_step: 36334, epoch: 109, loss: 0.331010
global_step: 36335, epoch: 109, loss: 0.298445
global_step: 36336, epoch: 109, loss: 0.267589
global_step: 36337, epoch: 109, loss: 0.220591
global_step: 36338, epoch: 109, loss: 0.405159
global_step: 36339, epoch: 109, loss: 0.340991
global_step: 36340, epoch: 109, loss: 0.312177
global_step: 36341, epoch: 109, loss: 0.303129
global_step: 36342, epoch: 109, loss: 0.284126
global_step: 36343, epoch: 109, loss: 0.331715
global_step: 36344, epoch: 109, loss: 0.293171
global_step: 36345, epoch: 109, loss: 0.269545
global_step: 36346, epoch: 109, loss: 0.378149
global_step: 36347, epoch: 109, loss: 0.296134
global_step: 36348, epoch: 109, loss: 0.366766
global_step: 36349, epoch: 109, loss: 0.333457
global_step: 36350, epoch: 109, loss: 0.380416
global_step: 36351, epoch: 109, loss: 0.266743
global_step: 36352, epoch: 109, loss: 0.263951
global_step: 36353, epoch: 109, loss: 0.253767
global_step: 36354, epoch: 109, loss: 0.313241
global_step: 36355, epoch: 109, loss: 0.354052
global_step: 36356, epoch: 109, loss: 0.255091
global_step: 36357, epoch: 109, loss: 0.314284
global_step: 36358, epoch: 109, loss: 0.350992
global_step: 36359, epoch: 109, loss: 0.350614
global_step: 36360, epoch: 109, loss: 0.550889
epoch: 109
train	acc: 0.9614	macro: p 0.9683, r 0.9356, f1: 0.9509	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9613
dev	acc: 0.5392	macro: p 0.3583, r 0.3110, f1: 0.3101	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4977
test	acc: 0.5858	macro: p 0.3450, r 0.3115, f1: 0.3168	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5475
global_step: 36361, epoch: 110, loss: 0.294322
global_step: 36362, epoch: 110, loss: 0.317305
global_step: 36363, epoch: 110, loss: 0.256350
global_step: 36364, epoch: 110, loss: 0.271286
global_step: 36365, epoch: 110, loss: 0.324585
global_step: 36366, epoch: 110, loss: 0.349142
global_step: 36367, epoch: 110, loss: 0.300078
global_step: 36368, epoch: 110, loss: 0.246831
global_step: 36369, epoch: 110, loss: 0.244607
global_step: 36370, epoch: 110, loss: 0.233658
global_step: 36371, epoch: 110, loss: 0.385508
global_step: 36372, epoch: 110, loss: 0.362957
global_step: 36373, epoch: 110, loss: 0.241309
global_step: 36374, epoch: 110, loss: 0.287707
global_step: 36375, epoch: 110, loss: 0.307705
global_step: 36376, epoch: 110, loss: 0.298433
global_step: 36377, epoch: 110, loss: 0.248962
global_step: 36378, epoch: 110, loss: 0.307218
global_step: 36379, epoch: 110, loss: 0.310919
global_step: 36380, epoch: 110, loss: 0.283673
global_step: 36381, epoch: 110, loss: 0.255061
global_step: 36382, epoch: 110, loss: 0.363727
global_step: 36383, epoch: 110, loss: 0.363375
global_step: 36384, epoch: 110, loss: 0.268236
global_step: 36385, epoch: 110, loss: 0.296657
global_step: 36386, epoch: 110, loss: 0.272819
global_step: 36387, epoch: 110, loss: 0.422780
global_step: 36388, epoch: 110, loss: 0.338646
global_step: 36389, epoch: 110, loss: 0.285602
global_step: 36390, epoch: 110, loss: 0.266341
global_step: 36391, epoch: 110, loss: 0.257684
global_step: 36392, epoch: 110, loss: 0.290326
global_step: 36393, epoch: 110, loss: 0.265334
global_step: 36394, epoch: 110, loss: 0.291382
global_step: 36395, epoch: 110, loss: 0.257152
global_step: 36396, epoch: 110, loss: 0.331188
global_step: 36397, epoch: 110, loss: 0.367458
global_step: 36398, epoch: 110, loss: 0.287987
global_step: 36399, epoch: 110, loss: 0.391304
global_step: 36400, epoch: 110, loss: 0.091026
epoch: 110
train	acc: 0.9629	macro: p 0.9699, r 0.9394, f1: 0.9537	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9628
dev	acc: 0.5383	macro: p 0.3781, r 0.3097, f1: 0.3096	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4923
test	acc: 0.5912	macro: p 0.3581, r 0.3171, f1: 0.3233	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5507
global_step: 36401, epoch: 111, loss: 0.269727
global_step: 36402, epoch: 111, loss: 0.296701
global_step: 36403, epoch: 111, loss: 0.291882
global_step: 36404, epoch: 111, loss: 0.288483
global_step: 36405, epoch: 111, loss: 0.386463
global_step: 36406, epoch: 111, loss: 0.245959
global_step: 36407, epoch: 111, loss: 0.319693
global_step: 36408, epoch: 111, loss: 0.307162
global_step: 36409, epoch: 111, loss: 0.281531
global_step: 36410, epoch: 111, loss: 0.401568
global_step: 36411, epoch: 111, loss: 0.251376
global_step: 36412, epoch: 111, loss: 0.290383
global_step: 36413, epoch: 111, loss: 0.297475
global_step: 36414, epoch: 111, loss: 0.356558
global_step: 36415, epoch: 111, loss: 0.259135
global_step: 36416, epoch: 111, loss: 0.187402
global_step: 36417, epoch: 111, loss: 0.293992
global_step: 36418, epoch: 111, loss: 0.346777
global_step: 36419, epoch: 111, loss: 0.306837
global_step: 36420, epoch: 111, loss: 0.218425
global_step: 36421, epoch: 111, loss: 0.279935
global_step: 36422, epoch: 111, loss: 0.262946
global_step: 36423, epoch: 111, loss: 0.288788
global_step: 36424, epoch: 111, loss: 0.299808
global_step: 36425, epoch: 111, loss: 0.325819
global_step: 36426, epoch: 111, loss: 0.239931
global_step: 36427, epoch: 111, loss: 0.306933
global_step: 36428, epoch: 111, loss: 0.352700
global_step: 36429, epoch: 111, loss: 0.242483
global_step: 36430, epoch: 111, loss: 0.412447
global_step: 36431, epoch: 111, loss: 0.277958
global_step: 36432, epoch: 111, loss: 0.345508
global_step: 36433, epoch: 111, loss: 0.281900
global_step: 36434, epoch: 111, loss: 0.339992
global_step: 36435, epoch: 111, loss: 0.265066
global_step: 36436, epoch: 111, loss: 0.326925
global_step: 36437, epoch: 111, loss: 0.338136
global_step: 36438, epoch: 111, loss: 0.346073
global_step: 36439, epoch: 111, loss: 0.234820
global_step: 36440, epoch: 111, loss: 0.074808
epoch: 111
train	acc: 0.9628	macro: p 0.9689, r 0.9396, f1: 0.9533	micro: p 0.9628, r 0.9628, f1 0.9628	weighted_f1:0.9627
dev	acc: 0.5329	macro: p 0.3481, r 0.3109, f1: 0.3085	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4936
test	acc: 0.5801	macro: p 0.3425, r 0.3151, f1: 0.3183	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5442
global_step: 36441, epoch: 112, loss: 0.336191
global_step: 36442, epoch: 112, loss: 0.243109
global_step: 36443, epoch: 112, loss: 0.254844
global_step: 36444, epoch: 112, loss: 0.309015
global_step: 36445, epoch: 112, loss: 0.301514
global_step: 36446, epoch: 112, loss: 0.289627
global_step: 36447, epoch: 112, loss: 0.294385
global_step: 36448, epoch: 112, loss: 0.276239
global_step: 36449, epoch: 112, loss: 0.218236
global_step: 36450, epoch: 112, loss: 0.253693
global_step: 36451, epoch: 112, loss: 0.324137
global_step: 36452, epoch: 112, loss: 0.253612
global_step: 36453, epoch: 112, loss: 0.426395
global_step: 36454, epoch: 112, loss: 0.326091
global_step: 36455, epoch: 112, loss: 0.223719
global_step: 36456, epoch: 112, loss: 0.279090
global_step: 36457, epoch: 112, loss: 0.394320
global_step: 36458, epoch: 112, loss: 0.292630
global_step: 36459, epoch: 112, loss: 0.320362
global_step: 36460, epoch: 112, loss: 0.256991
global_step: 36461, epoch: 112, loss: 0.278614
global_step: 36462, epoch: 112, loss: 0.359205
global_step: 36463, epoch: 112, loss: 0.360909
global_step: 36464, epoch: 112, loss: 0.302128
global_step: 36465, epoch: 112, loss: 0.257662
global_step: 36466, epoch: 112, loss: 0.340468
global_step: 36467, epoch: 112, loss: 0.308595
global_step: 36468, epoch: 112, loss: 0.263560
global_step: 36469, epoch: 112, loss: 0.238461
global_step: 36470, epoch: 112, loss: 0.310880
global_step: 36471, epoch: 112, loss: 0.308005
global_step: 36472, epoch: 112, loss: 0.287446
global_step: 36473, epoch: 112, loss: 0.257292
global_step: 36474, epoch: 112, loss: 0.288126
global_step: 36475, epoch: 112, loss: 0.362003
global_step: 36476, epoch: 112, loss: 0.287992
global_step: 36477, epoch: 112, loss: 0.310768
global_step: 36478, epoch: 112, loss: 0.275607
global_step: 36479, epoch: 112, loss: 0.333964
global_step: 36480, epoch: 112, loss: 0.050535
epoch: 112
train	acc: 0.9635	macro: p 0.9690, r 0.9411, f1: 0.9542	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5392	macro: p 0.3749, r 0.3132, f1: 0.3130	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4981
test	acc: 0.5828	macro: p 0.3565, r 0.3152, f1: 0.3210	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5449
global_step: 36481, epoch: 113, loss: 0.353648
global_step: 36482, epoch: 113, loss: 0.280490
global_step: 36483, epoch: 113, loss: 0.224038
global_step: 36484, epoch: 113, loss: 0.253986
global_step: 36485, epoch: 113, loss: 0.288633
global_step: 36486, epoch: 113, loss: 0.226560
global_step: 36487, epoch: 113, loss: 0.234379
global_step: 36488, epoch: 113, loss: 0.231461
global_step: 36489, epoch: 113, loss: 0.296586
global_step: 36490, epoch: 113, loss: 0.315735
global_step: 36491, epoch: 113, loss: 0.361816
global_step: 36492, epoch: 113, loss: 0.235700
global_step: 36493, epoch: 113, loss: 0.268179
global_step: 36494, epoch: 113, loss: 0.322014
global_step: 36495, epoch: 113, loss: 0.287537
global_step: 36496, epoch: 113, loss: 0.276610
global_step: 36497, epoch: 113, loss: 0.338878
global_step: 36498, epoch: 113, loss: 0.263712
global_step: 36499, epoch: 113, loss: 0.227233
global_step: 36500, epoch: 113, loss: 0.344109
global_step: 36501, epoch: 113, loss: 0.304770
global_step: 36502, epoch: 113, loss: 0.318239
global_step: 36503, epoch: 113, loss: 0.280152
global_step: 36504, epoch: 113, loss: 0.249549
global_step: 36505, epoch: 113, loss: 0.226561
global_step: 36506, epoch: 113, loss: 0.425450
global_step: 36507, epoch: 113, loss: 0.302696
global_step: 36508, epoch: 113, loss: 0.278546
global_step: 36509, epoch: 113, loss: 0.340545
global_step: 36510, epoch: 113, loss: 0.260954
global_step: 36511, epoch: 113, loss: 0.390572
global_step: 36512, epoch: 113, loss: 0.292201
global_step: 36513, epoch: 113, loss: 0.276904
global_step: 36514, epoch: 113, loss: 0.357756
global_step: 36515, epoch: 113, loss: 0.338692
global_step: 36516, epoch: 113, loss: 0.287807
global_step: 36517, epoch: 113, loss: 0.321829
global_step: 36518, epoch: 113, loss: 0.265538
global_step: 36519, epoch: 113, loss: 0.214343
global_step: 36520, epoch: 113, loss: 0.310959
epoch: 113
train	acc: 0.9644	macro: p 0.9684, r 0.9445, f1: 0.9558	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.5374	macro: p 0.3486, r 0.3192, f1: 0.3179	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.5027
test	acc: 0.5785	macro: p 0.3509, r 0.3230, f1: 0.3269	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5474
global_step: 36521, epoch: 114, loss: 0.286392
global_step: 36522, epoch: 114, loss: 0.240305
global_step: 36523, epoch: 114, loss: 0.246761
global_step: 36524, epoch: 114, loss: 0.184647
global_step: 36525, epoch: 114, loss: 0.295015
global_step: 36526, epoch: 114, loss: 0.219033
global_step: 36527, epoch: 114, loss: 0.326876
global_step: 36528, epoch: 114, loss: 0.264580
global_step: 36529, epoch: 114, loss: 0.294641
global_step: 36530, epoch: 114, loss: 0.261449
global_step: 36531, epoch: 114, loss: 0.392390
global_step: 36532, epoch: 114, loss: 0.282606
global_step: 36533, epoch: 114, loss: 0.289464
global_step: 36534, epoch: 114, loss: 0.300118
global_step: 36535, epoch: 114, loss: 0.297789
global_step: 36536, epoch: 114, loss: 0.286455
global_step: 36537, epoch: 114, loss: 0.348861
global_step: 36538, epoch: 114, loss: 0.305452
global_step: 36539, epoch: 114, loss: 0.307538
global_step: 36540, epoch: 114, loss: 0.221121
global_step: 36541, epoch: 114, loss: 0.242792
global_step: 36542, epoch: 114, loss: 0.354367
global_step: 36543, epoch: 114, loss: 0.310426
global_step: 36544, epoch: 114, loss: 0.314397
global_step: 36545, epoch: 114, loss: 0.295841
global_step: 36546, epoch: 114, loss: 0.297684
global_step: 36547, epoch: 114, loss: 0.279041
global_step: 36548, epoch: 114, loss: 0.237345
global_step: 36549, epoch: 114, loss: 0.265741
global_step: 36550, epoch: 114, loss: 0.272329
global_step: 36551, epoch: 114, loss: 0.257741
global_step: 36552, epoch: 114, loss: 0.198704
global_step: 36553, epoch: 114, loss: 0.246032
global_step: 36554, epoch: 114, loss: 0.311920
global_step: 36555, epoch: 114, loss: 0.357250
global_step: 36556, epoch: 114, loss: 0.260342
global_step: 36557, epoch: 114, loss: 0.308512
global_step: 36558, epoch: 114, loss: 0.270897
global_step: 36559, epoch: 114, loss: 0.341595
global_step: 36560, epoch: 114, loss: 0.119554
epoch: 114
train	acc: 0.9643	macro: p 0.9705, r 0.9423, f1: 0.9556	micro: p 0.9643, r 0.9643, f1 0.9643	weighted_f1:0.9642
dev	acc: 0.5446	macro: p 0.3871, r 0.3136, f1: 0.3156	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4983
test	acc: 0.5912	macro: p 0.3640, r 0.3153, f1: 0.3230	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5490
global_step: 36561, epoch: 115, loss: 0.284527
global_step: 36562, epoch: 115, loss: 0.283900
global_step: 36563, epoch: 115, loss: 0.294854
global_step: 36564, epoch: 115, loss: 0.230749
global_step: 36565, epoch: 115, loss: 0.269483
global_step: 36566, epoch: 115, loss: 0.304291
global_step: 36567, epoch: 115, loss: 0.240519
global_step: 36568, epoch: 115, loss: 0.265853
global_step: 36569, epoch: 115, loss: 0.305019
global_step: 36570, epoch: 115, loss: 0.280434
global_step: 36571, epoch: 115, loss: 0.394154
global_step: 36572, epoch: 115, loss: 0.367398
global_step: 36573, epoch: 115, loss: 0.278170
global_step: 36574, epoch: 115, loss: 0.232757
global_step: 36575, epoch: 115, loss: 0.395080
global_step: 36576, epoch: 115, loss: 0.307508
global_step: 36577, epoch: 115, loss: 0.308243
global_step: 36578, epoch: 115, loss: 0.340716
global_step: 36579, epoch: 115, loss: 0.290231
global_step: 36580, epoch: 115, loss: 0.250660
global_step: 36581, epoch: 115, loss: 0.278887
global_step: 36582, epoch: 115, loss: 0.223297
global_step: 36583, epoch: 115, loss: 0.314131
global_step: 36584, epoch: 115, loss: 0.317261
global_step: 36585, epoch: 115, loss: 0.261314
global_step: 36586, epoch: 115, loss: 0.217587
global_step: 36587, epoch: 115, loss: 0.258011
global_step: 36588, epoch: 115, loss: 0.248414
global_step: 36589, epoch: 115, loss: 0.369832
global_step: 36590, epoch: 115, loss: 0.266215
global_step: 36591, epoch: 115, loss: 0.326326
global_step: 36592, epoch: 115, loss: 0.328599
global_step: 36593, epoch: 115, loss: 0.239701
global_step: 36594, epoch: 115, loss: 0.335474
global_step: 36595, epoch: 115, loss: 0.262479
global_step: 36596, epoch: 115, loss: 0.245523
global_step: 36597, epoch: 115, loss: 0.266697
global_step: 36598, epoch: 115, loss: 0.335054
global_step: 36599, epoch: 115, loss: 0.289673
global_step: 36600, epoch: 115, loss: 0.051815
epoch: 115
train	acc: 0.9644	macro: p 0.9698, r 0.9433, f1: 0.9559	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9643
dev	acc: 0.5410	macro: p 0.3892, r 0.3144, f1: 0.3183	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4994
test	acc: 0.5828	macro: p 0.3699, r 0.3162, f1: 0.3248	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5448
global_step: 36601, epoch: 116, loss: 0.301428
global_step: 36602, epoch: 116, loss: 0.293177
global_step: 36603, epoch: 116, loss: 0.277366
global_step: 36604, epoch: 116, loss: 0.226082
global_step: 36605, epoch: 116, loss: 0.312409
global_step: 36606, epoch: 116, loss: 0.275595
global_step: 36607, epoch: 116, loss: 0.274891
global_step: 36608, epoch: 116, loss: 0.316381
global_step: 36609, epoch: 116, loss: 0.301407
global_step: 36610, epoch: 116, loss: 0.329879
global_step: 36611, epoch: 116, loss: 0.333310
global_step: 36612, epoch: 116, loss: 0.300810
global_step: 36613, epoch: 116, loss: 0.224364
global_step: 36614, epoch: 116, loss: 0.255100
global_step: 36615, epoch: 116, loss: 0.277590
global_step: 36616, epoch: 116, loss: 0.316007
global_step: 36617, epoch: 116, loss: 0.313670
global_step: 36618, epoch: 116, loss: 0.253939
global_step: 36619, epoch: 116, loss: 0.296653
global_step: 36620, epoch: 116, loss: 0.230319
global_step: 36621, epoch: 116, loss: 0.324496
global_step: 36622, epoch: 116, loss: 0.257603
global_step: 36623, epoch: 116, loss: 0.243748
global_step: 36624, epoch: 116, loss: 0.271161
global_step: 36625, epoch: 116, loss: 0.267124
global_step: 36626, epoch: 116, loss: 0.315899
global_step: 36627, epoch: 116, loss: 0.282958
global_step: 36628, epoch: 116, loss: 0.288264
global_step: 36629, epoch: 116, loss: 0.325870
global_step: 36630, epoch: 116, loss: 0.281174
global_step: 36631, epoch: 116, loss: 0.286956
global_step: 36632, epoch: 116, loss: 0.277810
global_step: 36633, epoch: 116, loss: 0.256647
global_step: 36634, epoch: 116, loss: 0.313085
global_step: 36635, epoch: 116, loss: 0.279911
global_step: 36636, epoch: 116, loss: 0.297149
global_step: 36637, epoch: 116, loss: 0.259357
global_step: 36638, epoch: 116, loss: 0.292101
global_step: 36639, epoch: 116, loss: 0.237264
global_step: 36640, epoch: 116, loss: 0.122145
epoch: 116
train	acc: 0.9648	macro: p 0.9712, r 0.9424, f1: 0.9560	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9647
dev	acc: 0.5392	macro: p 0.4277, r 0.3097, f1: 0.3141	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4955
test	acc: 0.5870	macro: p 0.3725, r 0.3139, f1: 0.3234	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5470
global_step: 36641, epoch: 117, loss: 0.317946
global_step: 36642, epoch: 117, loss: 0.279615
global_step: 36643, epoch: 117, loss: 0.325593
global_step: 36644, epoch: 117, loss: 0.301758
global_step: 36645, epoch: 117, loss: 0.208495
global_step: 36646, epoch: 117, loss: 0.304683
global_step: 36647, epoch: 117, loss: 0.290156
global_step: 36648, epoch: 117, loss: 0.279889
global_step: 36649, epoch: 117, loss: 0.212008
global_step: 36650, epoch: 117, loss: 0.276964
global_step: 36651, epoch: 117, loss: 0.326381
global_step: 36652, epoch: 117, loss: 0.324582
global_step: 36653, epoch: 117, loss: 0.264935
global_step: 36654, epoch: 117, loss: 0.305117
global_step: 36655, epoch: 117, loss: 0.304016
global_step: 36656, epoch: 117, loss: 0.262306
global_step: 36657, epoch: 117, loss: 0.287527
global_step: 36658, epoch: 117, loss: 0.326276
global_step: 36659, epoch: 117, loss: 0.268390
global_step: 36660, epoch: 117, loss: 0.374210
global_step: 36661, epoch: 117, loss: 0.256805
global_step: 36662, epoch: 117, loss: 0.268683
global_step: 36663, epoch: 117, loss: 0.222110
global_step: 36664, epoch: 117, loss: 0.295452
global_step: 36665, epoch: 117, loss: 0.268233
global_step: 36666, epoch: 117, loss: 0.244654
global_step: 36667, epoch: 117, loss: 0.302106
global_step: 36668, epoch: 117, loss: 0.281720
global_step: 36669, epoch: 117, loss: 0.271458
global_step: 36670, epoch: 117, loss: 0.238897
global_step: 36671, epoch: 117, loss: 0.260414
global_step: 36672, epoch: 117, loss: 0.337035
global_step: 36673, epoch: 117, loss: 0.305853
global_step: 36674, epoch: 117, loss: 0.333394
global_step: 36675, epoch: 117, loss: 0.195755
global_step: 36676, epoch: 117, loss: 0.325258
global_step: 36677, epoch: 117, loss: 0.279584
global_step: 36678, epoch: 117, loss: 0.224956
global_step: 36679, epoch: 117, loss: 0.232562
global_step: 36680, epoch: 117, loss: 0.018360
epoch: 117
train	acc: 0.9659	macro: p 0.9710, r 0.9473, f1: 0.9586	micro: p 0.9659, r 0.9659, f1 0.9659	weighted_f1:0.9659
dev	acc: 0.5329	macro: p 0.4179, r 0.3095, f1: 0.3131	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4920
test	acc: 0.5877	macro: p 0.3572, r 0.3160, f1: 0.3227	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5481
global_step: 36681, epoch: 118, loss: 0.177707
global_step: 36682, epoch: 118, loss: 0.349242
global_step: 36683, epoch: 118, loss: 0.246246
global_step: 36684, epoch: 118, loss: 0.309450
global_step: 36685, epoch: 118, loss: 0.268903
global_step: 36686, epoch: 118, loss: 0.232520
global_step: 36687, epoch: 118, loss: 0.248153
global_step: 36688, epoch: 118, loss: 0.276676
global_step: 36689, epoch: 118, loss: 0.327820
global_step: 36690, epoch: 118, loss: 0.246531
global_step: 36691, epoch: 118, loss: 0.307839
global_step: 36692, epoch: 118, loss: 0.268691
global_step: 36693, epoch: 118, loss: 0.242854
global_step: 36694, epoch: 118, loss: 0.209400
global_step: 36695, epoch: 118, loss: 0.208369
global_step: 36696, epoch: 118, loss: 0.234421
global_step: 36697, epoch: 118, loss: 0.326312
global_step: 36698, epoch: 118, loss: 0.253999
global_step: 36699, epoch: 118, loss: 0.286145
global_step: 36700, epoch: 118, loss: 0.277970
global_step: 36701, epoch: 118, loss: 0.290464
global_step: 36702, epoch: 118, loss: 0.213883
global_step: 36703, epoch: 118, loss: 0.302536
global_step: 36704, epoch: 118, loss: 0.239295
global_step: 36705, epoch: 118, loss: 0.264480
global_step: 36706, epoch: 118, loss: 0.267671
global_step: 36707, epoch: 118, loss: 0.242056
global_step: 36708, epoch: 118, loss: 0.257250
global_step: 36709, epoch: 118, loss: 0.240743
global_step: 36710, epoch: 118, loss: 0.236448
global_step: 36711, epoch: 118, loss: 0.371773
global_step: 36712, epoch: 118, loss: 0.255915
global_step: 36713, epoch: 118, loss: 0.319437
global_step: 36714, epoch: 118, loss: 0.366571
global_step: 36715, epoch: 118, loss: 0.245731
global_step: 36716, epoch: 118, loss: 0.316962
global_step: 36717, epoch: 118, loss: 0.239752
global_step: 36718, epoch: 118, loss: 0.254786
global_step: 36719, epoch: 118, loss: 0.283217
global_step: 36720, epoch: 118, loss: 0.145480
epoch: 118
train	acc: 0.9658	macro: p 0.9711, r 0.9463, f1: 0.9580	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9658
dev	acc: 0.5383	macro: p 0.3642, r 0.3107, f1: 0.3091	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4941
test	acc: 0.5835	macro: p 0.3448, r 0.3133, f1: 0.3147	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5421
global_step: 36721, epoch: 119, loss: 0.256060
global_step: 36722, epoch: 119, loss: 0.225549
global_step: 36723, epoch: 119, loss: 0.283078
global_step: 36724, epoch: 119, loss: 0.262229
global_step: 36725, epoch: 119, loss: 0.290495
global_step: 36726, epoch: 119, loss: 0.204505
global_step: 36727, epoch: 119, loss: 0.321982
global_step: 36728, epoch: 119, loss: 0.236921
global_step: 36729, epoch: 119, loss: 0.281955
global_step: 36730, epoch: 119, loss: 0.372714
global_step: 36731, epoch: 119, loss: 0.221320
global_step: 36732, epoch: 119, loss: 0.228747
global_step: 36733, epoch: 119, loss: 0.303459
global_step: 36734, epoch: 119, loss: 0.387015
global_step: 36735, epoch: 119, loss: 0.242907
global_step: 36736, epoch: 119, loss: 0.247498
global_step: 36737, epoch: 119, loss: 0.261759
global_step: 36738, epoch: 119, loss: 0.304232
global_step: 36739, epoch: 119, loss: 0.264085
global_step: 36740, epoch: 119, loss: 0.209645
global_step: 36741, epoch: 119, loss: 0.374473
global_step: 36742, epoch: 119, loss: 0.233539
global_step: 36743, epoch: 119, loss: 0.265081
global_step: 36744, epoch: 119, loss: 0.236849
global_step: 36745, epoch: 119, loss: 0.266055
global_step: 36746, epoch: 119, loss: 0.281268
global_step: 36747, epoch: 119, loss: 0.216391
global_step: 36748, epoch: 119, loss: 0.222536
global_step: 36749, epoch: 119, loss: 0.261627
global_step: 36750, epoch: 119, loss: 0.347620
global_step: 36751, epoch: 119, loss: 0.288526
global_step: 36752, epoch: 119, loss: 0.285713
global_step: 36753, epoch: 119, loss: 0.240576
global_step: 36754, epoch: 119, loss: 0.319139
global_step: 36755, epoch: 119, loss: 0.311527
global_step: 36756, epoch: 119, loss: 0.247192
global_step: 36757, epoch: 119, loss: 0.272838
global_step: 36758, epoch: 119, loss: 0.331245
global_step: 36759, epoch: 119, loss: 0.298972
global_step: 36760, epoch: 119, loss: 0.100458
epoch: 119
train	acc: 0.9652	macro: p 0.9717, r 0.9453, f1: 0.9578	micro: p 0.9652, r 0.9652, f1 0.9652	weighted_f1:0.9651
dev	acc: 0.5374	macro: p 0.3555, r 0.3046, f1: 0.3052	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4902
test	acc: 0.5881	macro: p 0.3731, r 0.3124, f1: 0.3221	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5438
global_step: 36761, epoch: 120, loss: 0.324660
global_step: 36762, epoch: 120, loss: 0.227789
global_step: 36763, epoch: 120, loss: 0.274947
global_step: 36764, epoch: 120, loss: 0.267526
global_step: 36765, epoch: 120, loss: 0.248865
global_step: 36766, epoch: 120, loss: 0.280925
global_step: 36767, epoch: 120, loss: 0.230725
global_step: 36768, epoch: 120, loss: 0.232156
global_step: 36769, epoch: 120, loss: 0.250770
global_step: 36770, epoch: 120, loss: 0.239485
global_step: 36771, epoch: 120, loss: 0.218048
global_step: 36772, epoch: 120, loss: 0.238465
global_step: 36773, epoch: 120, loss: 0.280828
global_step: 36774, epoch: 120, loss: 0.248539
global_step: 36775, epoch: 120, loss: 0.307647
global_step: 36776, epoch: 120, loss: 0.278946
global_step: 36777, epoch: 120, loss: 0.280155
global_step: 36778, epoch: 120, loss: 0.260688
global_step: 36779, epoch: 120, loss: 0.250457
global_step: 36780, epoch: 120, loss: 0.304280
global_step: 36781, epoch: 120, loss: 0.345123
global_step: 36782, epoch: 120, loss: 0.310153
global_step: 36783, epoch: 120, loss: 0.264248
global_step: 36784, epoch: 120, loss: 0.210345
global_step: 36785, epoch: 120, loss: 0.253472
global_step: 36786, epoch: 120, loss: 0.235170
global_step: 36787, epoch: 120, loss: 0.241931
global_step: 36788, epoch: 120, loss: 0.279250
global_step: 36789, epoch: 120, loss: 0.271979
global_step: 36790, epoch: 120, loss: 0.255533
global_step: 36791, epoch: 120, loss: 0.191799
global_step: 36792, epoch: 120, loss: 0.202609
global_step: 36793, epoch: 120, loss: 0.321767
global_step: 36794, epoch: 120, loss: 0.319544
global_step: 36795, epoch: 120, loss: 0.296339
global_step: 36796, epoch: 120, loss: 0.296306
global_step: 36797, epoch: 120, loss: 0.267105
global_step: 36798, epoch: 120, loss: 0.292676
global_step: 36799, epoch: 120, loss: 0.311340
global_step: 36800, epoch: 120, loss: 0.087836
epoch: 120
train	acc: 0.9647	macro: p 0.9701, r 0.9465, f1: 0.9576	micro: p 0.9647, r 0.9647, f1 0.9647	weighted_f1:0.9647
dev	acc: 0.5401	macro: p 0.3842, r 0.3178, f1: 0.3199	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.5012
test	acc: 0.5824	macro: p 0.3427, r 0.3163, f1: 0.3183	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5446
global_step: 36801, epoch: 121, loss: 0.210852
global_step: 36802, epoch: 121, loss: 0.169996
global_step: 36803, epoch: 121, loss: 0.248835
global_step: 36804, epoch: 121, loss: 0.244449
global_step: 36805, epoch: 121, loss: 0.277121
global_step: 36806, epoch: 121, loss: 0.260257
global_step: 36807, epoch: 121, loss: 0.269295
global_step: 36808, epoch: 121, loss: 0.340419
global_step: 36809, epoch: 121, loss: 0.309330
global_step: 36810, epoch: 121, loss: 0.373211
global_step: 36811, epoch: 121, loss: 0.280526
global_step: 36812, epoch: 121, loss: 0.260029
global_step: 36813, epoch: 121, loss: 0.235564
global_step: 36814, epoch: 121, loss: 0.308361
global_step: 36815, epoch: 121, loss: 0.250527
global_step: 36816, epoch: 121, loss: 0.291390
global_step: 36817, epoch: 121, loss: 0.255887
global_step: 36818, epoch: 121, loss: 0.297672
global_step: 36819, epoch: 121, loss: 0.238117
global_step: 36820, epoch: 121, loss: 0.317781
global_step: 36821, epoch: 121, loss: 0.243127
global_step: 36822, epoch: 121, loss: 0.191019
global_step: 36823, epoch: 121, loss: 0.245433
global_step: 36824, epoch: 121, loss: 0.301305
global_step: 36825, epoch: 121, loss: 0.292797
global_step: 36826, epoch: 121, loss: 0.204168
global_step: 36827, epoch: 121, loss: 0.259589
global_step: 36828, epoch: 121, loss: 0.333442
global_step: 36829, epoch: 121, loss: 0.212640
global_step: 36830, epoch: 121, loss: 0.315562
global_step: 36831, epoch: 121, loss: 0.221172
global_step: 36832, epoch: 121, loss: 0.306521
global_step: 36833, epoch: 121, loss: 0.271980
global_step: 36834, epoch: 121, loss: 0.391423
global_step: 36835, epoch: 121, loss: 0.355280
global_step: 36836, epoch: 121, loss: 0.292858
global_step: 36837, epoch: 121, loss: 0.355245
global_step: 36838, epoch: 121, loss: 0.308915
global_step: 36839, epoch: 121, loss: 0.334337
global_step: 36840, epoch: 121, loss: 0.563323
epoch: 121
train	acc: 0.9655	macro: p 0.9700, r 0.9464, f1: 0.9576	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9654
dev	acc: 0.5329	macro: p 0.3712, r 0.3065, f1: 0.3109	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4913
test	acc: 0.5874	macro: p 0.3575, r 0.3144, f1: 0.3214	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5478
global_step: 36841, epoch: 122, loss: 0.237300
global_step: 36842, epoch: 122, loss: 0.270828
global_step: 36843, epoch: 122, loss: 0.289004
global_step: 36844, epoch: 122, loss: 0.283290
global_step: 36845, epoch: 122, loss: 0.274700
global_step: 36846, epoch: 122, loss: 0.275938
global_step: 36847, epoch: 122, loss: 0.207924
global_step: 36848, epoch: 122, loss: 0.235617
global_step: 36849, epoch: 122, loss: 0.237697
global_step: 36850, epoch: 122, loss: 0.228843
global_step: 36851, epoch: 122, loss: 0.229156
global_step: 36852, epoch: 122, loss: 0.243526
global_step: 36853, epoch: 122, loss: 0.259382
global_step: 36854, epoch: 122, loss: 0.266952
global_step: 36855, epoch: 122, loss: 0.270138
global_step: 36856, epoch: 122, loss: 0.286689
global_step: 36857, epoch: 122, loss: 0.272484
global_step: 36858, epoch: 122, loss: 0.273813
global_step: 36859, epoch: 122, loss: 0.278371
global_step: 36860, epoch: 122, loss: 0.259315
global_step: 36861, epoch: 122, loss: 0.348055
global_step: 36862, epoch: 122, loss: 0.300940
global_step: 36863, epoch: 122, loss: 0.334201
global_step: 36864, epoch: 122, loss: 0.221350
global_step: 36865, epoch: 122, loss: 0.258383
global_step: 36866, epoch: 122, loss: 0.264461
global_step: 36867, epoch: 122, loss: 0.241137
global_step: 36868, epoch: 122, loss: 0.320713
global_step: 36869, epoch: 122, loss: 0.314185
global_step: 36870, epoch: 122, loss: 0.243382
global_step: 36871, epoch: 122, loss: 0.209874
global_step: 36872, epoch: 122, loss: 0.303570
global_step: 36873, epoch: 122, loss: 0.232176
global_step: 36874, epoch: 122, loss: 0.238007
global_step: 36875, epoch: 122, loss: 0.306011
global_step: 36876, epoch: 122, loss: 0.246761
global_step: 36877, epoch: 122, loss: 0.242825
global_step: 36878, epoch: 122, loss: 0.271975
global_step: 36879, epoch: 122, loss: 0.284401
global_step: 36880, epoch: 122, loss: 0.340391
epoch: 122
train	acc: 0.9653	macro: p 0.9712, r 0.9445, f1: 0.9571	micro: p 0.9653, r 0.9653, f1 0.9653	weighted_f1:0.9653
dev	acc: 0.5320	macro: p 0.3965, r 0.3050, f1: 0.3054	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4872
test	acc: 0.5900	macro: p 0.3473, r 0.3131, f1: 0.3171	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5467
global_step: 36881, epoch: 123, loss: 0.183559
global_step: 36882, epoch: 123, loss: 0.183136
global_step: 36883, epoch: 123, loss: 0.285594
global_step: 36884, epoch: 123, loss: 0.260803
global_step: 36885, epoch: 123, loss: 0.208035
global_step: 36886, epoch: 123, loss: 0.270534
global_step: 36887, epoch: 123, loss: 0.361763
global_step: 36888, epoch: 123, loss: 0.384447
global_step: 36889, epoch: 123, loss: 0.214512
global_step: 36890, epoch: 123, loss: 0.300474
global_step: 36891, epoch: 123, loss: 0.186855
global_step: 36892, epoch: 123, loss: 0.247663
global_step: 36893, epoch: 123, loss: 0.272920
global_step: 36894, epoch: 123, loss: 0.266999
global_step: 36895, epoch: 123, loss: 0.257454
global_step: 36896, epoch: 123, loss: 0.275863
global_step: 36897, epoch: 123, loss: 0.281288
global_step: 36898, epoch: 123, loss: 0.300120
global_step: 36899, epoch: 123, loss: 0.244035
global_step: 36900, epoch: 123, loss: 0.268223
global_step: 36901, epoch: 123, loss: 0.240540
global_step: 36902, epoch: 123, loss: 0.271881
global_step: 36903, epoch: 123, loss: 0.242584
global_step: 36904, epoch: 123, loss: 0.197168
global_step: 36905, epoch: 123, loss: 0.287524
global_step: 36906, epoch: 123, loss: 0.214544
global_step: 36907, epoch: 123, loss: 0.269977
global_step: 36908, epoch: 123, loss: 0.339791
global_step: 36909, epoch: 123, loss: 0.270392
global_step: 36910, epoch: 123, loss: 0.269860
global_step: 36911, epoch: 123, loss: 0.251229
global_step: 36912, epoch: 123, loss: 0.229202
global_step: 36913, epoch: 123, loss: 0.266950
global_step: 36914, epoch: 123, loss: 0.282919
global_step: 36915, epoch: 123, loss: 0.297817
global_step: 36916, epoch: 123, loss: 0.263924
global_step: 36917, epoch: 123, loss: 0.216399
global_step: 36918, epoch: 123, loss: 0.305702
global_step: 36919, epoch: 123, loss: 0.260088
global_step: 36920, epoch: 123, loss: 0.268188
epoch: 123
train	acc: 0.9658	macro: p 0.9716, r 0.9464, f1: 0.9583	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9657
dev	acc: 0.5221	macro: p 0.3535, r 0.2945, f1: 0.2946	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4796
test	acc: 0.5881	macro: p 0.3507, r 0.3146, f1: 0.3209	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5492
global_step: 36921, epoch: 124, loss: 0.255247
global_step: 36922, epoch: 124, loss: 0.258412
global_step: 36923, epoch: 124, loss: 0.204607
global_step: 36924, epoch: 124, loss: 0.254801
global_step: 36925, epoch: 124, loss: 0.302443
global_step: 36926, epoch: 124, loss: 0.216548
global_step: 36927, epoch: 124, loss: 0.263519
global_step: 36928, epoch: 124, loss: 0.255331
global_step: 36929, epoch: 124, loss: 0.277712
global_step: 36930, epoch: 124, loss: 0.268894
global_step: 36931, epoch: 124, loss: 0.274554
global_step: 36932, epoch: 124, loss: 0.278540
global_step: 36933, epoch: 124, loss: 0.252351
global_step: 36934, epoch: 124, loss: 0.230912
global_step: 36935, epoch: 124, loss: 0.240643
global_step: 36936, epoch: 124, loss: 0.252496
global_step: 36937, epoch: 124, loss: 0.233915
global_step: 36938, epoch: 124, loss: 0.263601
global_step: 36939, epoch: 124, loss: 0.318759
global_step: 36940, epoch: 124, loss: 0.316891
global_step: 36941, epoch: 124, loss: 0.330910
global_step: 36942, epoch: 124, loss: 0.261214
global_step: 36943, epoch: 124, loss: 0.265048
global_step: 36944, epoch: 124, loss: 0.240693
global_step: 36945, epoch: 124, loss: 0.235827
global_step: 36946, epoch: 124, loss: 0.287841
global_step: 36947, epoch: 124, loss: 0.219468
global_step: 36948, epoch: 124, loss: 0.209869
global_step: 36949, epoch: 124, loss: 0.228135
global_step: 36950, epoch: 124, loss: 0.237018
global_step: 36951, epoch: 124, loss: 0.332251
global_step: 36952, epoch: 124, loss: 0.279524
global_step: 36953, epoch: 124, loss: 0.325394
global_step: 36954, epoch: 124, loss: 0.325368
global_step: 36955, epoch: 124, loss: 0.291971
global_step: 36956, epoch: 124, loss: 0.272801
global_step: 36957, epoch: 124, loss: 0.304314
global_step: 36958, epoch: 124, loss: 0.320323
global_step: 36959, epoch: 124, loss: 0.273442
global_step: 36960, epoch: 124, loss: 0.099814
epoch: 124
train	acc: 0.9657	macro: p 0.9708, r 0.9469, f1: 0.9582	micro: p 0.9657, r 0.9657, f1 0.9657	weighted_f1:0.9657
dev	acc: 0.5230	macro: p 0.3359, r 0.3004, f1: 0.2984	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4822
test	acc: 0.5858	macro: p 0.3539, r 0.3168, f1: 0.3209	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5464
global_step: 36961, epoch: 125, loss: 0.252732
global_step: 36962, epoch: 125, loss: 0.340773
global_step: 36963, epoch: 125, loss: 0.237128
global_step: 36964, epoch: 125, loss: 0.196141
global_step: 36965, epoch: 125, loss: 0.230838
global_step: 36966, epoch: 125, loss: 0.245588
global_step: 36967, epoch: 125, loss: 0.267257
global_step: 36968, epoch: 125, loss: 0.254063
global_step: 36969, epoch: 125, loss: 0.231538
global_step: 36970, epoch: 125, loss: 0.266285
global_step: 36971, epoch: 125, loss: 0.223571
global_step: 36972, epoch: 125, loss: 0.253515
global_step: 36973, epoch: 125, loss: 0.216080
global_step: 36974, epoch: 125, loss: 0.276035
global_step: 36975, epoch: 125, loss: 0.231845
global_step: 36976, epoch: 125, loss: 0.225636
global_step: 36977, epoch: 125, loss: 0.224293
global_step: 36978, epoch: 125, loss: 0.297616
global_step: 36979, epoch: 125, loss: 0.256914
global_step: 36980, epoch: 125, loss: 0.255399
global_step: 36981, epoch: 125, loss: 0.239556
global_step: 36982, epoch: 125, loss: 0.235704
global_step: 36983, epoch: 125, loss: 0.215400
global_step: 36984, epoch: 125, loss: 0.253153
global_step: 36985, epoch: 125, loss: 0.256394
global_step: 36986, epoch: 125, loss: 0.214278
global_step: 36987, epoch: 125, loss: 0.213240
global_step: 36988, epoch: 125, loss: 0.318113
global_step: 36989, epoch: 125, loss: 0.228091
global_step: 36990, epoch: 125, loss: 0.209196
global_step: 36991, epoch: 125, loss: 0.249856
global_step: 36992, epoch: 125, loss: 0.299106
global_step: 36993, epoch: 125, loss: 0.269063
global_step: 36994, epoch: 125, loss: 0.254887
global_step: 36995, epoch: 125, loss: 0.275288
global_step: 36996, epoch: 125, loss: 0.251033
global_step: 36997, epoch: 125, loss: 0.352436
global_step: 36998, epoch: 125, loss: 0.344134
global_step: 36999, epoch: 125, loss: 0.210664
global_step: 37000, epoch: 125, loss: 0.320901
epoch: 125
train	acc: 0.9666	macro: p 0.9721, r 0.9469, f1: 0.9589	micro: p 0.9666, r 0.9666, f1 0.9666	weighted_f1:0.9665
dev	acc: 0.5302	macro: p 0.3948, r 0.3119, f1: 0.3189	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4884
test	acc: 0.5831	macro: p 0.3490, r 0.3092, f1: 0.3151	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5415
global_step: 37001, epoch: 126, loss: 0.299279
global_step: 37002, epoch: 126, loss: 0.221087
global_step: 37003, epoch: 126, loss: 0.281621
global_step: 37004, epoch: 126, loss: 0.273140
global_step: 37005, epoch: 126, loss: 0.239071
global_step: 37006, epoch: 126, loss: 0.258097
global_step: 37007, epoch: 126, loss: 0.238267
global_step: 37008, epoch: 126, loss: 0.257116
global_step: 37009, epoch: 126, loss: 0.268310
global_step: 37010, epoch: 126, loss: 0.224184
global_step: 37011, epoch: 126, loss: 0.302897
global_step: 37012, epoch: 126, loss: 0.230951
global_step: 37013, epoch: 126, loss: 0.268013
global_step: 37014, epoch: 126, loss: 0.321503
global_step: 37015, epoch: 126, loss: 0.301666
global_step: 37016, epoch: 126, loss: 0.219562
global_step: 37017, epoch: 126, loss: 0.223218
global_step: 37018, epoch: 126, loss: 0.181269
global_step: 37019, epoch: 126, loss: 0.314500
global_step: 37020, epoch: 126, loss: 0.291836
global_step: 37021, epoch: 126, loss: 0.232467
global_step: 37022, epoch: 126, loss: 0.257160
global_step: 37023, epoch: 126, loss: 0.216712
global_step: 37024, epoch: 126, loss: 0.254412
global_step: 37025, epoch: 126, loss: 0.232900
global_step: 37026, epoch: 126, loss: 0.264693
global_step: 37027, epoch: 126, loss: 0.321163
global_step: 37028, epoch: 126, loss: 0.280010
global_step: 37029, epoch: 126, loss: 0.212247
global_step: 37030, epoch: 126, loss: 0.287472
global_step: 37031, epoch: 126, loss: 0.227492
global_step: 37032, epoch: 126, loss: 0.289374
global_step: 37033, epoch: 126, loss: 0.277202
global_step: 37034, epoch: 126, loss: 0.321819
global_step: 37035, epoch: 126, loss: 0.276320
global_step: 37036, epoch: 126, loss: 0.254359
global_step: 37037, epoch: 126, loss: 0.248536
global_step: 37038, epoch: 126, loss: 0.223653
global_step: 37039, epoch: 126, loss: 0.256849
global_step: 37040, epoch: 126, loss: 0.333605
epoch: 126
train	acc: 0.9676	macro: p 0.9727, r 0.9495, f1: 0.9605	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5212	macro: p 0.3381, r 0.2976, f1: 0.2976	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4805
test	acc: 0.5816	macro: p 0.3531, r 0.3111, f1: 0.3175	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5422
global_step: 37041, epoch: 127, loss: 0.263118
global_step: 37042, epoch: 127, loss: 0.244189
global_step: 37043, epoch: 127, loss: 0.274037
global_step: 37044, epoch: 127, loss: 0.347464
global_step: 37045, epoch: 127, loss: 0.212689
global_step: 37046, epoch: 127, loss: 0.261854
global_step: 37047, epoch: 127, loss: 0.199024
global_step: 37048, epoch: 127, loss: 0.217238
global_step: 37049, epoch: 127, loss: 0.200143
global_step: 37050, epoch: 127, loss: 0.229999
global_step: 37051, epoch: 127, loss: 0.305966
global_step: 37052, epoch: 127, loss: 0.266340
global_step: 37053, epoch: 127, loss: 0.363420
global_step: 37054, epoch: 127, loss: 0.242265
global_step: 37055, epoch: 127, loss: 0.231748
global_step: 37056, epoch: 127, loss: 0.255534
global_step: 37057, epoch: 127, loss: 0.172953
global_step: 37058, epoch: 127, loss: 0.283668
global_step: 37059, epoch: 127, loss: 0.288825
global_step: 37060, epoch: 127, loss: 0.257414
global_step: 37061, epoch: 127, loss: 0.197975
global_step: 37062, epoch: 127, loss: 0.232420
global_step: 37063, epoch: 127, loss: 0.250082
global_step: 37064, epoch: 127, loss: 0.346726
global_step: 37065, epoch: 127, loss: 0.317347
global_step: 37066, epoch: 127, loss: 0.291912
global_step: 37067, epoch: 127, loss: 0.291623
global_step: 37068, epoch: 127, loss: 0.211347
global_step: 37069, epoch: 127, loss: 0.344071
global_step: 37070, epoch: 127, loss: 0.311941
global_step: 37071, epoch: 127, loss: 0.262392
global_step: 37072, epoch: 127, loss: 0.220742
global_step: 37073, epoch: 127, loss: 0.204138
global_step: 37074, epoch: 127, loss: 0.223640
global_step: 37075, epoch: 127, loss: 0.242295
global_step: 37076, epoch: 127, loss: 0.276735
global_step: 37077, epoch: 127, loss: 0.248281
global_step: 37078, epoch: 127, loss: 0.306900
global_step: 37079, epoch: 127, loss: 0.254832
global_step: 37080, epoch: 127, loss: 0.157328
epoch: 127
train	acc: 0.9676	macro: p 0.9711, r 0.9514, f1: 0.9608	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5266	macro: p 0.3600, r 0.3055, f1: 0.3105	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4878
test	acc: 0.5820	macro: p 0.3605, r 0.3163, f1: 0.3257	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5452
global_step: 37081, epoch: 128, loss: 0.203214
global_step: 37082, epoch: 128, loss: 0.248667
global_step: 37083, epoch: 128, loss: 0.291647
global_step: 37084, epoch: 128, loss: 0.246143
global_step: 37085, epoch: 128, loss: 0.233412
global_step: 37086, epoch: 128, loss: 0.205005
global_step: 37087, epoch: 128, loss: 0.243146
global_step: 37088, epoch: 128, loss: 0.248786
global_step: 37089, epoch: 128, loss: 0.290537
global_step: 37090, epoch: 128, loss: 0.222131
global_step: 37091, epoch: 128, loss: 0.186331
global_step: 37092, epoch: 128, loss: 0.246761
global_step: 37093, epoch: 128, loss: 0.247528
global_step: 37094, epoch: 128, loss: 0.263490
global_step: 37095, epoch: 128, loss: 0.249426
global_step: 37096, epoch: 128, loss: 0.289842
global_step: 37097, epoch: 128, loss: 0.307639
global_step: 37098, epoch: 128, loss: 0.231891
global_step: 37099, epoch: 128, loss: 0.254066
global_step: 37100, epoch: 128, loss: 0.265636
global_step: 37101, epoch: 128, loss: 0.266135
global_step: 37102, epoch: 128, loss: 0.210709
global_step: 37103, epoch: 128, loss: 0.255697
global_step: 37104, epoch: 128, loss: 0.267817
global_step: 37105, epoch: 128, loss: 0.208745
global_step: 37106, epoch: 128, loss: 0.278212
global_step: 37107, epoch: 128, loss: 0.292305
global_step: 37108, epoch: 128, loss: 0.282164
global_step: 37109, epoch: 128, loss: 0.262599
global_step: 37110, epoch: 128, loss: 0.176560
global_step: 37111, epoch: 128, loss: 0.338816
global_step: 37112, epoch: 128, loss: 0.211618
global_step: 37113, epoch: 128, loss: 0.279910
global_step: 37114, epoch: 128, loss: 0.243922
global_step: 37115, epoch: 128, loss: 0.278355
global_step: 37116, epoch: 128, loss: 0.282453
global_step: 37117, epoch: 128, loss: 0.253138
global_step: 37118, epoch: 128, loss: 0.303693
global_step: 37119, epoch: 128, loss: 0.201545
global_step: 37120, epoch: 128, loss: 0.375643
epoch: 128
train	acc: 0.9675	macro: p 0.9721, r 0.9507, f1: 0.9609	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5320	macro: p 0.3662, r 0.3081, f1: 0.3110	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4898
test	acc: 0.5858	macro: p 0.3448, r 0.3128, f1: 0.3156	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5444
global_step: 37121, epoch: 129, loss: 0.262209
global_step: 37122, epoch: 129, loss: 0.207456
global_step: 37123, epoch: 129, loss: 0.334304
global_step: 37124, epoch: 129, loss: 0.255521
global_step: 37125, epoch: 129, loss: 0.184844
global_step: 37126, epoch: 129, loss: 0.238600
global_step: 37127, epoch: 129, loss: 0.226707
global_step: 37128, epoch: 129, loss: 0.237390
global_step: 37129, epoch: 129, loss: 0.255332
global_step: 37130, epoch: 129, loss: 0.285947
global_step: 37131, epoch: 129, loss: 0.252336
global_step: 37132, epoch: 129, loss: 0.235422
global_step: 37133, epoch: 129, loss: 0.264037
global_step: 37134, epoch: 129, loss: 0.272459
global_step: 37135, epoch: 129, loss: 0.277922
global_step: 37136, epoch: 129, loss: 0.230499
global_step: 37137, epoch: 129, loss: 0.225201
global_step: 37138, epoch: 129, loss: 0.196067
global_step: 37139, epoch: 129, loss: 0.253152
global_step: 37140, epoch: 129, loss: 0.234820
global_step: 37141, epoch: 129, loss: 0.252908
global_step: 37142, epoch: 129, loss: 0.225471
global_step: 37143, epoch: 129, loss: 0.211670
global_step: 37144, epoch: 129, loss: 0.260624
global_step: 37145, epoch: 129, loss: 0.240337
global_step: 37146, epoch: 129, loss: 0.269210
global_step: 37147, epoch: 129, loss: 0.263134
global_step: 37148, epoch: 129, loss: 0.241010
global_step: 37149, epoch: 129, loss: 0.206245
global_step: 37150, epoch: 129, loss: 0.280183
global_step: 37151, epoch: 129, loss: 0.258352
global_step: 37152, epoch: 129, loss: 0.316026
global_step: 37153, epoch: 129, loss: 0.234724
global_step: 37154, epoch: 129, loss: 0.313158
global_step: 37155, epoch: 129, loss: 0.225831
global_step: 37156, epoch: 129, loss: 0.339335
global_step: 37157, epoch: 129, loss: 0.332516
global_step: 37158, epoch: 129, loss: 0.231545
global_step: 37159, epoch: 129, loss: 0.273512
global_step: 37160, epoch: 129, loss: 0.131974
epoch: 129
train	acc: 0.9667	macro: p 0.9704, r 0.9522, f1: 0.9609	micro: p 0.9667, r 0.9667, f1 0.9667	weighted_f1:0.9667
dev	acc: 0.5167	macro: p 0.3342, r 0.2959, f1: 0.2961	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4791
test	acc: 0.5820	macro: p 0.3617, r 0.3167, f1: 0.3239	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5452
global_step: 37161, epoch: 130, loss: 0.288569
global_step: 37162, epoch: 130, loss: 0.271775
global_step: 37163, epoch: 130, loss: 0.258337
global_step: 37164, epoch: 130, loss: 0.207101
global_step: 37165, epoch: 130, loss: 0.232010
global_step: 37166, epoch: 130, loss: 0.225718
global_step: 37167, epoch: 130, loss: 0.250317
global_step: 37168, epoch: 130, loss: 0.198390
global_step: 37169, epoch: 130, loss: 0.251915
global_step: 37170, epoch: 130, loss: 0.216216
global_step: 37171, epoch: 130, loss: 0.223193
global_step: 37172, epoch: 130, loss: 0.215873
global_step: 37173, epoch: 130, loss: 0.206881
global_step: 37174, epoch: 130, loss: 0.285812
global_step: 37175, epoch: 130, loss: 0.210747
global_step: 37176, epoch: 130, loss: 0.241408
global_step: 37177, epoch: 130, loss: 0.266441
global_step: 37178, epoch: 130, loss: 0.208778
global_step: 37179, epoch: 130, loss: 0.248841
global_step: 37180, epoch: 130, loss: 0.269448
global_step: 37181, epoch: 130, loss: 0.227013
global_step: 37182, epoch: 130, loss: 0.188279
global_step: 37183, epoch: 130, loss: 0.285662
global_step: 37184, epoch: 130, loss: 0.254866
global_step: 37185, epoch: 130, loss: 0.271717
global_step: 37186, epoch: 130, loss: 0.238241
global_step: 37187, epoch: 130, loss: 0.251383
global_step: 37188, epoch: 130, loss: 0.316735
global_step: 37189, epoch: 130, loss: 0.274297
global_step: 37190, epoch: 130, loss: 0.206511
global_step: 37191, epoch: 130, loss: 0.182784
global_step: 37192, epoch: 130, loss: 0.258783
global_step: 37193, epoch: 130, loss: 0.246172
global_step: 37194, epoch: 130, loss: 0.285355
global_step: 37195, epoch: 130, loss: 0.256777
global_step: 37196, epoch: 130, loss: 0.231958
global_step: 37197, epoch: 130, loss: 0.263091
global_step: 37198, epoch: 130, loss: 0.259715
global_step: 37199, epoch: 130, loss: 0.346451
global_step: 37200, epoch: 130, loss: 2.814585
epoch: 130
train	acc: 0.9679	macro: p 0.9717, r 0.9499, f1: 0.9603	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5293	macro: p 0.3609, r 0.3027, f1: 0.3031	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4841
test	acc: 0.5824	macro: p 0.3316, r 0.3075, f1: 0.3093	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5397
global_step: 37201, epoch: 131, loss: 0.253419
global_step: 37202, epoch: 131, loss: 0.209902
global_step: 37203, epoch: 131, loss: 0.221476
global_step: 37204, epoch: 131, loss: 0.244358
global_step: 37205, epoch: 131, loss: 0.250222
global_step: 37206, epoch: 131, loss: 0.281794
global_step: 37207, epoch: 131, loss: 0.229481
global_step: 37208, epoch: 131, loss: 0.174284
global_step: 37209, epoch: 131, loss: 0.286659
global_step: 37210, epoch: 131, loss: 0.233445
global_step: 37211, epoch: 131, loss: 0.308162
global_step: 37212, epoch: 131, loss: 0.211326
global_step: 37213, epoch: 131, loss: 0.221519
global_step: 37214, epoch: 131, loss: 0.337433
global_step: 37215, epoch: 131, loss: 0.283962
global_step: 37216, epoch: 131, loss: 0.208925
global_step: 37217, epoch: 131, loss: 0.258834
global_step: 37218, epoch: 131, loss: 0.224319
global_step: 37219, epoch: 131, loss: 0.199477
global_step: 37220, epoch: 131, loss: 0.252199
global_step: 37221, epoch: 131, loss: 0.196606
global_step: 37222, epoch: 131, loss: 0.184080
global_step: 37223, epoch: 131, loss: 0.234242
global_step: 37224, epoch: 131, loss: 0.279216
global_step: 37225, epoch: 131, loss: 0.255699
global_step: 37226, epoch: 131, loss: 0.375541
global_step: 37227, epoch: 131, loss: 0.201098
global_step: 37228, epoch: 131, loss: 0.257365
global_step: 37229, epoch: 131, loss: 0.212228
global_step: 37230, epoch: 131, loss: 0.301456
global_step: 37231, epoch: 131, loss: 0.239409
global_step: 37232, epoch: 131, loss: 0.198512
global_step: 37233, epoch: 131, loss: 0.321856
global_step: 37234, epoch: 131, loss: 0.259300
global_step: 37235, epoch: 131, loss: 0.272708
global_step: 37236, epoch: 131, loss: 0.227386
global_step: 37237, epoch: 131, loss: 0.241678
global_step: 37238, epoch: 131, loss: 0.280217
global_step: 37239, epoch: 131, loss: 0.254070
global_step: 37240, epoch: 131, loss: 0.032131
epoch: 131
train	acc: 0.9680	macro: p 0.9730, r 0.9524, f1: 0.9622	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5239	macro: p 0.3334, r 0.3034, f1: 0.3030	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4850
test	acc: 0.5812	macro: p 0.3408, r 0.3106, f1: 0.3139	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5420
global_step: 37241, epoch: 132, loss: 0.278681
global_step: 37242, epoch: 132, loss: 0.318743
global_step: 37243, epoch: 132, loss: 0.247651
global_step: 37244, epoch: 132, loss: 0.302110
global_step: 37245, epoch: 132, loss: 0.213462
global_step: 37246, epoch: 132, loss: 0.208710
global_step: 37247, epoch: 132, loss: 0.197990
global_step: 37248, epoch: 132, loss: 0.171043
global_step: 37249, epoch: 132, loss: 0.275413
global_step: 37250, epoch: 132, loss: 0.245201
global_step: 37251, epoch: 132, loss: 0.218087
global_step: 37252, epoch: 132, loss: 0.270654
global_step: 37253, epoch: 132, loss: 0.241277
global_step: 37254, epoch: 132, loss: 0.198119
global_step: 37255, epoch: 132, loss: 0.267973
global_step: 37256, epoch: 132, loss: 0.239020
global_step: 37257, epoch: 132, loss: 0.256638
global_step: 37258, epoch: 132, loss: 0.261886
global_step: 37259, epoch: 132, loss: 0.233057
global_step: 37260, epoch: 132, loss: 0.205561
global_step: 37261, epoch: 132, loss: 0.214964
global_step: 37262, epoch: 132, loss: 0.216539
global_step: 37263, epoch: 132, loss: 0.263090
global_step: 37264, epoch: 132, loss: 0.323072
global_step: 37265, epoch: 132, loss: 0.261709
global_step: 37266, epoch: 132, loss: 0.267886
global_step: 37267, epoch: 132, loss: 0.269209
global_step: 37268, epoch: 132, loss: 0.249292
global_step: 37269, epoch: 132, loss: 0.257919
global_step: 37270, epoch: 132, loss: 0.292852
global_step: 37271, epoch: 132, loss: 0.264467
global_step: 37272, epoch: 132, loss: 0.254326
global_step: 37273, epoch: 132, loss: 0.289951
global_step: 37274, epoch: 132, loss: 0.221738
global_step: 37275, epoch: 132, loss: 0.278763
global_step: 37276, epoch: 132, loss: 0.268775
global_step: 37277, epoch: 132, loss: 0.279143
global_step: 37278, epoch: 132, loss: 0.305960
global_step: 37279, epoch: 132, loss: 0.317547
global_step: 37280, epoch: 132, loss: 0.081086
epoch: 132
train	acc: 0.9680	macro: p 0.9728, r 0.9512, f1: 0.9615	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5221	macro: p 0.3471, r 0.3049, f1: 0.3046	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4857
test	acc: 0.5759	macro: p 0.3482, r 0.3168, f1: 0.3212	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5413
global_step: 37281, epoch: 133, loss: 0.204398
global_step: 37282, epoch: 133, loss: 0.182151
global_step: 37283, epoch: 133, loss: 0.215609
global_step: 37284, epoch: 133, loss: 0.224941
global_step: 37285, epoch: 133, loss: 0.235656
global_step: 37286, epoch: 133, loss: 0.244175
global_step: 37287, epoch: 133, loss: 0.212342
global_step: 37288, epoch: 133, loss: 0.219659
global_step: 37289, epoch: 133, loss: 0.185173
global_step: 37290, epoch: 133, loss: 0.322625
global_step: 37291, epoch: 133, loss: 0.223164
global_step: 37292, epoch: 133, loss: 0.203887
global_step: 37293, epoch: 133, loss: 0.256160
global_step: 37294, epoch: 133, loss: 0.212812
global_step: 37295, epoch: 133, loss: 0.311355
global_step: 37296, epoch: 133, loss: 0.259878
global_step: 37297, epoch: 133, loss: 0.269754
global_step: 37298, epoch: 133, loss: 0.247067
global_step: 37299, epoch: 133, loss: 0.312884
global_step: 37300, epoch: 133, loss: 0.239122
global_step: 37301, epoch: 133, loss: 0.352165
global_step: 37302, epoch: 133, loss: 0.272815
global_step: 37303, epoch: 133, loss: 0.194460
global_step: 37304, epoch: 133, loss: 0.312577
global_step: 37305, epoch: 133, loss: 0.226265
global_step: 37306, epoch: 133, loss: 0.236831
global_step: 37307, epoch: 133, loss: 0.227432
global_step: 37308, epoch: 133, loss: 0.205729
global_step: 37309, epoch: 133, loss: 0.333146
global_step: 37310, epoch: 133, loss: 0.302675
global_step: 37311, epoch: 133, loss: 0.308073
global_step: 37312, epoch: 133, loss: 0.266072
global_step: 37313, epoch: 133, loss: 0.323985
global_step: 37314, epoch: 133, loss: 0.288356
global_step: 37315, epoch: 133, loss: 0.321703
global_step: 37316, epoch: 133, loss: 0.253149
global_step: 37317, epoch: 133, loss: 0.247781
global_step: 37318, epoch: 133, loss: 0.275309
global_step: 37319, epoch: 133, loss: 0.217857
global_step: 37320, epoch: 133, loss: 0.151116
epoch: 133
train	acc: 0.9679	macro: p 0.9726, r 0.9519, f1: 0.9618	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5203	macro: p 0.3621, r 0.3041, f1: 0.3073	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4839
test	acc: 0.5793	macro: p 0.3574, r 0.3168, f1: 0.3228	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5433
global_step: 37321, epoch: 134, loss: 0.261690
global_step: 37322, epoch: 134, loss: 0.195521
global_step: 37323, epoch: 134, loss: 0.205302
global_step: 37324, epoch: 134, loss: 0.266127
global_step: 37325, epoch: 134, loss: 0.257160
global_step: 37326, epoch: 134, loss: 0.256472
global_step: 37327, epoch: 134, loss: 0.231410
global_step: 37328, epoch: 134, loss: 0.246724
global_step: 37329, epoch: 134, loss: 0.187071
global_step: 37330, epoch: 134, loss: 0.237765
global_step: 37331, epoch: 134, loss: 0.312876
global_step: 37332, epoch: 134, loss: 0.230774
global_step: 37333, epoch: 134, loss: 0.287892
global_step: 37334, epoch: 134, loss: 0.250852
global_step: 37335, epoch: 134, loss: 0.209737
global_step: 37336, epoch: 134, loss: 0.265981
global_step: 37337, epoch: 134, loss: 0.185067
global_step: 37338, epoch: 134, loss: 0.261322
global_step: 37339, epoch: 134, loss: 0.229081
global_step: 37340, epoch: 134, loss: 0.296673
global_step: 37341, epoch: 134, loss: 0.241212
global_step: 37342, epoch: 134, loss: 0.218351
global_step: 37343, epoch: 134, loss: 0.217578
global_step: 37344, epoch: 134, loss: 0.219156
global_step: 37345, epoch: 134, loss: 0.270895
global_step: 37346, epoch: 134, loss: 0.206782
global_step: 37347, epoch: 134, loss: 0.301775
global_step: 37348, epoch: 134, loss: 0.271561
global_step: 37349, epoch: 134, loss: 0.249792
global_step: 37350, epoch: 134, loss: 0.223881
global_step: 37351, epoch: 134, loss: 0.275757
global_step: 37352, epoch: 134, loss: 0.207446
global_step: 37353, epoch: 134, loss: 0.286607
global_step: 37354, epoch: 134, loss: 0.285604
global_step: 37355, epoch: 134, loss: 0.259221
global_step: 37356, epoch: 134, loss: 0.275171
global_step: 37357, epoch: 134, loss: 0.230097
global_step: 37358, epoch: 134, loss: 0.298522
global_step: 37359, epoch: 134, loss: 0.270865
global_step: 37360, epoch: 134, loss: 0.450794
epoch: 134
train	acc: 0.9673	macro: p 0.9736, r 0.9485, f1: 0.9604	micro: p 0.9673, r 0.9673, f1 0.9673	weighted_f1:0.9672
dev	acc: 0.5302	macro: p 0.3909, r 0.3017, f1: 0.3046	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4851
test	acc: 0.5824	macro: p 0.3402, r 0.3081, f1: 0.3130	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5412
global_step: 37361, epoch: 135, loss: 0.239708
global_step: 37362, epoch: 135, loss: 0.224251
global_step: 37363, epoch: 135, loss: 0.207706
global_step: 37364, epoch: 135, loss: 0.181829
global_step: 37365, epoch: 135, loss: 0.204845
global_step: 37366, epoch: 135, loss: 0.360465
global_step: 37367, epoch: 135, loss: 0.280889
global_step: 37368, epoch: 135, loss: 0.230288
global_step: 37369, epoch: 135, loss: 0.245273
global_step: 37370, epoch: 135, loss: 0.227673
global_step: 37371, epoch: 135, loss: 0.254313
global_step: 37372, epoch: 135, loss: 0.273150
global_step: 37373, epoch: 135, loss: 0.235115
global_step: 37374, epoch: 135, loss: 0.241047
global_step: 37375, epoch: 135, loss: 0.254717
global_step: 37376, epoch: 135, loss: 0.264336
global_step: 37377, epoch: 135, loss: 0.200775
global_step: 37378, epoch: 135, loss: 0.278571
global_step: 37379, epoch: 135, loss: 0.218776
global_step: 37380, epoch: 135, loss: 0.214827
global_step: 37381, epoch: 135, loss: 0.304937
global_step: 37382, epoch: 135, loss: 0.299184
global_step: 37383, epoch: 135, loss: 0.215636
global_step: 37384, epoch: 135, loss: 0.234528
global_step: 37385, epoch: 135, loss: 0.210738
global_step: 37386, epoch: 135, loss: 0.279615
global_step: 37387, epoch: 135, loss: 0.294623
global_step: 37388, epoch: 135, loss: 0.256139
global_step: 37389, epoch: 135, loss: 0.220039
global_step: 37390, epoch: 135, loss: 0.210457
global_step: 37391, epoch: 135, loss: 0.192192
global_step: 37392, epoch: 135, loss: 0.198348
global_step: 37393, epoch: 135, loss: 0.237854
global_step: 37394, epoch: 135, loss: 0.250982
global_step: 37395, epoch: 135, loss: 0.253890
global_step: 37396, epoch: 135, loss: 0.218192
global_step: 37397, epoch: 135, loss: 0.260711
global_step: 37398, epoch: 135, loss: 0.242315
global_step: 37399, epoch: 135, loss: 0.310694
global_step: 37400, epoch: 135, loss: 0.582991
epoch: 135
train	acc: 0.9668	macro: p 0.9713, r 0.9484, f1: 0.9592	micro: p 0.9668, r 0.9668, f1 0.9668	weighted_f1:0.9668
dev	acc: 0.5347	macro: p 0.3878, r 0.3095, f1: 0.3126	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4918
test	acc: 0.5778	macro: p 0.3339, r 0.3076, f1: 0.3096	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5381
global_step: 37401, epoch: 136, loss: 0.182378
global_step: 37402, epoch: 136, loss: 0.181748
global_step: 37403, epoch: 136, loss: 0.248967
global_step: 37404, epoch: 136, loss: 0.204331
global_step: 37405, epoch: 136, loss: 0.237285
global_step: 37406, epoch: 136, loss: 0.156974
global_step: 37407, epoch: 136, loss: 0.289815
global_step: 37408, epoch: 136, loss: 0.205945
global_step: 37409, epoch: 136, loss: 0.331216
global_step: 37410, epoch: 136, loss: 0.235091
global_step: 37411, epoch: 136, loss: 0.249778
global_step: 37412, epoch: 136, loss: 0.242864
global_step: 37413, epoch: 136, loss: 0.276577
global_step: 37414, epoch: 136, loss: 0.196155
global_step: 37415, epoch: 136, loss: 0.234314
global_step: 37416, epoch: 136, loss: 0.275320
global_step: 37417, epoch: 136, loss: 0.232885
global_step: 37418, epoch: 136, loss: 0.234351
global_step: 37419, epoch: 136, loss: 0.274327
global_step: 37420, epoch: 136, loss: 0.205135
global_step: 37421, epoch: 136, loss: 0.223797
global_step: 37422, epoch: 136, loss: 0.298685
global_step: 37423, epoch: 136, loss: 0.196308
global_step: 37424, epoch: 136, loss: 0.257004
global_step: 37425, epoch: 136, loss: 0.256179
global_step: 37426, epoch: 136, loss: 0.247925
global_step: 37427, epoch: 136, loss: 0.273628
global_step: 37428, epoch: 136, loss: 0.161758
global_step: 37429, epoch: 136, loss: 0.273322
global_step: 37430, epoch: 136, loss: 0.248807
global_step: 37431, epoch: 136, loss: 0.200436
global_step: 37432, epoch: 136, loss: 0.298555
global_step: 37433, epoch: 136, loss: 0.231857
global_step: 37434, epoch: 136, loss: 0.206468
global_step: 37435, epoch: 136, loss: 0.271793
global_step: 37436, epoch: 136, loss: 0.245504
global_step: 37437, epoch: 136, loss: 0.242470
global_step: 37438, epoch: 136, loss: 0.300186
global_step: 37439, epoch: 136, loss: 0.246669
global_step: 37440, epoch: 136, loss: 0.013491
epoch: 136
train	acc: 0.9683	macro: p 0.9732, r 0.9530, f1: 0.9627	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5338	macro: p 0.3630, r 0.3076, f1: 0.3074	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4925
test	acc: 0.5774	macro: p 0.3411, r 0.3084, f1: 0.3131	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5384
global_step: 37441, epoch: 137, loss: 0.205601
global_step: 37442, epoch: 137, loss: 0.212467
global_step: 37443, epoch: 137, loss: 0.195578
global_step: 37444, epoch: 137, loss: 0.231312
global_step: 37445, epoch: 137, loss: 0.239471
global_step: 37446, epoch: 137, loss: 0.146684
global_step: 37447, epoch: 137, loss: 0.178062
global_step: 37448, epoch: 137, loss: 0.243670
global_step: 37449, epoch: 137, loss: 0.260100
global_step: 37450, epoch: 137, loss: 0.274663
global_step: 37451, epoch: 137, loss: 0.284041
global_step: 37452, epoch: 137, loss: 0.186099
global_step: 37453, epoch: 137, loss: 0.215155
global_step: 37454, epoch: 137, loss: 0.271050
global_step: 37455, epoch: 137, loss: 0.272692
global_step: 37456, epoch: 137, loss: 0.196267
global_step: 37457, epoch: 137, loss: 0.199826
global_step: 37458, epoch: 137, loss: 0.223520
global_step: 37459, epoch: 137, loss: 0.210333
global_step: 37460, epoch: 137, loss: 0.213360
global_step: 37461, epoch: 137, loss: 0.184121
global_step: 37462, epoch: 137, loss: 0.262784
global_step: 37463, epoch: 137, loss: 0.131392
global_step: 37464, epoch: 137, loss: 0.197250
global_step: 37465, epoch: 137, loss: 0.228074
global_step: 37466, epoch: 137, loss: 0.223375
global_step: 37467, epoch: 137, loss: 0.182096
global_step: 37468, epoch: 137, loss: 0.305657
global_step: 37469, epoch: 137, loss: 0.276515
global_step: 37470, epoch: 137, loss: 0.252004
global_step: 37471, epoch: 137, loss: 0.258908
global_step: 37472, epoch: 137, loss: 0.250539
global_step: 37473, epoch: 137, loss: 0.269129
global_step: 37474, epoch: 137, loss: 0.244754
global_step: 37475, epoch: 137, loss: 0.392415
global_step: 37476, epoch: 137, loss: 0.256973
global_step: 37477, epoch: 137, loss: 0.195731
global_step: 37478, epoch: 137, loss: 0.427517
global_step: 37479, epoch: 137, loss: 0.284976
global_step: 37480, epoch: 137, loss: 0.595259
epoch: 137
train	acc: 0.9676	macro: p 0.9730, r 0.9511, f1: 0.9616	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5356	macro: p 0.3889, r 0.3110, f1: 0.3148	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4956
test	acc: 0.5808	macro: p 0.3460, r 0.3146, f1: 0.3192	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5437
global_step: 37481, epoch: 138, loss: 0.237050
global_step: 37482, epoch: 138, loss: 0.312702
global_step: 37483, epoch: 138, loss: 0.216240
global_step: 37484, epoch: 138, loss: 0.267173
global_step: 37485, epoch: 138, loss: 0.243364
global_step: 37486, epoch: 138, loss: 0.271768
global_step: 37487, epoch: 138, loss: 0.211743
global_step: 37488, epoch: 138, loss: 0.215706
global_step: 37489, epoch: 138, loss: 0.278702
global_step: 37490, epoch: 138, loss: 0.230640
global_step: 37491, epoch: 138, loss: 0.191134
global_step: 37492, epoch: 138, loss: 0.254324
global_step: 37493, epoch: 138, loss: 0.200115
global_step: 37494, epoch: 138, loss: 0.261423
global_step: 37495, epoch: 138, loss: 0.287971
global_step: 37496, epoch: 138, loss: 0.290155
global_step: 37497, epoch: 138, loss: 0.157464
global_step: 37498, epoch: 138, loss: 0.232219
global_step: 37499, epoch: 138, loss: 0.194106
global_step: 37500, epoch: 138, loss: 0.237681
global_step: 37501, epoch: 138, loss: 0.229105
global_step: 37502, epoch: 138, loss: 0.203006
global_step: 37503, epoch: 138, loss: 0.288582
global_step: 37504, epoch: 138, loss: 0.232737
global_step: 37505, epoch: 138, loss: 0.256880
global_step: 37506, epoch: 138, loss: 0.295810
global_step: 37507, epoch: 138, loss: 0.207276
global_step: 37508, epoch: 138, loss: 0.263973
global_step: 37509, epoch: 138, loss: 0.234962
global_step: 37510, epoch: 138, loss: 0.187937
global_step: 37511, epoch: 138, loss: 0.208868
global_step: 37512, epoch: 138, loss: 0.283224
global_step: 37513, epoch: 138, loss: 0.311905
global_step: 37514, epoch: 138, loss: 0.252066
global_step: 37515, epoch: 138, loss: 0.238931
global_step: 37516, epoch: 138, loss: 0.307881
global_step: 37517, epoch: 138, loss: 0.261740
global_step: 37518, epoch: 138, loss: 0.269402
global_step: 37519, epoch: 138, loss: 0.215391
global_step: 37520, epoch: 138, loss: 0.140104
epoch: 138
train	acc: 0.9684	macro: p 0.9739, r 0.9519, f1: 0.9624	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5347	macro: p 0.3619, r 0.3065, f1: 0.3056	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4899
test	acc: 0.5820	macro: p 0.3573, r 0.3104, f1: 0.3164	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5407
global_step: 37521, epoch: 139, loss: 0.175983
global_step: 37522, epoch: 139, loss: 0.240936
global_step: 37523, epoch: 139, loss: 0.232764
global_step: 37524, epoch: 139, loss: 0.178205
global_step: 37525, epoch: 139, loss: 0.174359
global_step: 37526, epoch: 139, loss: 0.258522
global_step: 37527, epoch: 139, loss: 0.207073
global_step: 37528, epoch: 139, loss: 0.217302
global_step: 37529, epoch: 139, loss: 0.213685
global_step: 37530, epoch: 139, loss: 0.200598
global_step: 37531, epoch: 139, loss: 0.200703
global_step: 37532, epoch: 139, loss: 0.219075
global_step: 37533, epoch: 139, loss: 0.203710
global_step: 37534, epoch: 139, loss: 0.276702
global_step: 37535, epoch: 139, loss: 0.269515
global_step: 37536, epoch: 139, loss: 0.276888
global_step: 37537, epoch: 139, loss: 0.263432
global_step: 37538, epoch: 139, loss: 0.259850
global_step: 37539, epoch: 139, loss: 0.330963
global_step: 37540, epoch: 139, loss: 0.263888
global_step: 37541, epoch: 139, loss: 0.219807
global_step: 37542, epoch: 139, loss: 0.299707
global_step: 37543, epoch: 139, loss: 0.195802
global_step: 37544, epoch: 139, loss: 0.247541
global_step: 37545, epoch: 139, loss: 0.206135
global_step: 37546, epoch: 139, loss: 0.207291
global_step: 37547, epoch: 139, loss: 0.275760
global_step: 37548, epoch: 139, loss: 0.213595
global_step: 37549, epoch: 139, loss: 0.220148
global_step: 37550, epoch: 139, loss: 0.267066
global_step: 37551, epoch: 139, loss: 0.259123
global_step: 37552, epoch: 139, loss: 0.265858
global_step: 37553, epoch: 139, loss: 0.272805
global_step: 37554, epoch: 139, loss: 0.262963
global_step: 37555, epoch: 139, loss: 0.273231
global_step: 37556, epoch: 139, loss: 0.208581
global_step: 37557, epoch: 139, loss: 0.230805
global_step: 37558, epoch: 139, loss: 0.271491
global_step: 37559, epoch: 139, loss: 0.230936
global_step: 37560, epoch: 139, loss: 0.039187
epoch: 139
train	acc: 0.9677	macro: p 0.9734, r 0.9501, f1: 0.9612	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5365	macro: p 0.4293, r 0.3112, f1: 0.3130	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4902
test	acc: 0.5816	macro: p 0.3438, r 0.3066, f1: 0.3093	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5373
global_step: 37561, epoch: 140, loss: 0.255717
global_step: 37562, epoch: 140, loss: 0.340579
global_step: 37563, epoch: 140, loss: 0.259092
global_step: 37564, epoch: 140, loss: 0.263999
global_step: 37565, epoch: 140, loss: 0.288815
global_step: 37566, epoch: 140, loss: 0.249509
global_step: 37567, epoch: 140, loss: 0.191204
global_step: 37568, epoch: 140, loss: 0.171100
global_step: 37569, epoch: 140, loss: 0.231461
global_step: 37570, epoch: 140, loss: 0.225188
global_step: 37571, epoch: 140, loss: 0.283870
global_step: 37572, epoch: 140, loss: 0.252766
global_step: 37573, epoch: 140, loss: 0.157018
global_step: 37574, epoch: 140, loss: 0.225639
global_step: 37575, epoch: 140, loss: 0.230649
global_step: 37576, epoch: 140, loss: 0.252975
global_step: 37577, epoch: 140, loss: 0.260789
global_step: 37578, epoch: 140, loss: 0.274487
global_step: 37579, epoch: 140, loss: 0.263395
global_step: 37580, epoch: 140, loss: 0.249463
global_step: 37581, epoch: 140, loss: 0.237426
global_step: 37582, epoch: 140, loss: 0.266830
global_step: 37583, epoch: 140, loss: 0.184780
global_step: 37584, epoch: 140, loss: 0.199389
global_step: 37585, epoch: 140, loss: 0.261745
global_step: 37586, epoch: 140, loss: 0.239697
global_step: 37587, epoch: 140, loss: 0.304951
global_step: 37588, epoch: 140, loss: 0.231784
global_step: 37589, epoch: 140, loss: 0.205736
global_step: 37590, epoch: 140, loss: 0.220926
global_step: 37591, epoch: 140, loss: 0.266336
global_step: 37592, epoch: 140, loss: 0.254849
global_step: 37593, epoch: 140, loss: 0.218361
global_step: 37594, epoch: 140, loss: 0.257599
global_step: 37595, epoch: 140, loss: 0.220316
global_step: 37596, epoch: 140, loss: 0.177233
global_step: 37597, epoch: 140, loss: 0.278690
global_step: 37598, epoch: 140, loss: 0.234415
global_step: 37599, epoch: 140, loss: 0.220499
global_step: 37600, epoch: 140, loss: 0.700271
epoch: 140
train	acc: 0.9683	macro: p 0.9743, r 0.9516, f1: 0.9625	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5302	macro: p 0.3942, r 0.3013, f1: 0.3045	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4819
test	acc: 0.5851	macro: p 0.3568, r 0.3044, f1: 0.3107	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5379
global_step: 37601, epoch: 141, loss: 0.228845
global_step: 37602, epoch: 141, loss: 0.315438
global_step: 37603, epoch: 141, loss: 0.252227
global_step: 37604, epoch: 141, loss: 0.202051
global_step: 37605, epoch: 141, loss: 0.228273
global_step: 37606, epoch: 141, loss: 0.177366
global_step: 37607, epoch: 141, loss: 0.200531
global_step: 37608, epoch: 141, loss: 0.207612
global_step: 37609, epoch: 141, loss: 0.221678
global_step: 37610, epoch: 141, loss: 0.236700
global_step: 37611, epoch: 141, loss: 0.187299
global_step: 37612, epoch: 141, loss: 0.255835
global_step: 37613, epoch: 141, loss: 0.251031
global_step: 37614, epoch: 141, loss: 0.228808
global_step: 37615, epoch: 141, loss: 0.271663
global_step: 37616, epoch: 141, loss: 0.185362
global_step: 37617, epoch: 141, loss: 0.234908
global_step: 37618, epoch: 141, loss: 0.220318
global_step: 37619, epoch: 141, loss: 0.247979
global_step: 37620, epoch: 141, loss: 0.214637
global_step: 37621, epoch: 141, loss: 0.216954
global_step: 37622, epoch: 141, loss: 0.247869
global_step: 37623, epoch: 141, loss: 0.179721
global_step: 37624, epoch: 141, loss: 0.213673
global_step: 37625, epoch: 141, loss: 0.321316
global_step: 37626, epoch: 141, loss: 0.288696
global_step: 37627, epoch: 141, loss: 0.253977
global_step: 37628, epoch: 141, loss: 0.253895
global_step: 37629, epoch: 141, loss: 0.236851
global_step: 37630, epoch: 141, loss: 0.308629
global_step: 37631, epoch: 141, loss: 0.273357
global_step: 37632, epoch: 141, loss: 0.204872
global_step: 37633, epoch: 141, loss: 0.250885
global_step: 37634, epoch: 141, loss: 0.246310
global_step: 37635, epoch: 141, loss: 0.202217
global_step: 37636, epoch: 141, loss: 0.229105
global_step: 37637, epoch: 141, loss: 0.219985
global_step: 37638, epoch: 141, loss: 0.224184
global_step: 37639, epoch: 141, loss: 0.293086
global_step: 37640, epoch: 141, loss: 0.266203
epoch: 141
train	acc: 0.9693	macro: p 0.9734, r 0.9556, f1: 0.9641	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5221	macro: p 0.3602, r 0.3053, f1: 0.3081	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4864
test	acc: 0.5797	macro: p 0.3439, r 0.3139, f1: 0.3167	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5425
global_step: 37641, epoch: 142, loss: 0.205379
global_step: 37642, epoch: 142, loss: 0.241045
global_step: 37643, epoch: 142, loss: 0.207054
global_step: 37644, epoch: 142, loss: 0.206808
global_step: 37645, epoch: 142, loss: 0.224672
global_step: 37646, epoch: 142, loss: 0.225888
global_step: 37647, epoch: 142, loss: 0.194809
global_step: 37648, epoch: 142, loss: 0.302011
global_step: 37649, epoch: 142, loss: 0.203506
global_step: 37650, epoch: 142, loss: 0.199578
global_step: 37651, epoch: 142, loss: 0.173318
global_step: 37652, epoch: 142, loss: 0.303397
global_step: 37653, epoch: 142, loss: 0.206190
global_step: 37654, epoch: 142, loss: 0.236410
global_step: 37655, epoch: 142, loss: 0.255068
global_step: 37656, epoch: 142, loss: 0.244960
global_step: 37657, epoch: 142, loss: 0.213368
global_step: 37658, epoch: 142, loss: 0.196123
global_step: 37659, epoch: 142, loss: 0.276743
global_step: 37660, epoch: 142, loss: 0.238290
global_step: 37661, epoch: 142, loss: 0.267893
global_step: 37662, epoch: 142, loss: 0.208306
global_step: 37663, epoch: 142, loss: 0.195927
global_step: 37664, epoch: 142, loss: 0.235527
global_step: 37665, epoch: 142, loss: 0.288050
global_step: 37666, epoch: 142, loss: 0.198805
global_step: 37667, epoch: 142, loss: 0.294493
global_step: 37668, epoch: 142, loss: 0.212974
global_step: 37669, epoch: 142, loss: 0.231620
global_step: 37670, epoch: 142, loss: 0.259335
global_step: 37671, epoch: 142, loss: 0.203347
global_step: 37672, epoch: 142, loss: 0.247749
global_step: 37673, epoch: 142, loss: 0.225948
global_step: 37674, epoch: 142, loss: 0.261419
global_step: 37675, epoch: 142, loss: 0.305421
global_step: 37676, epoch: 142, loss: 0.195105
global_step: 37677, epoch: 142, loss: 0.239599
global_step: 37678, epoch: 142, loss: 0.257196
global_step: 37679, epoch: 142, loss: 0.157893
global_step: 37680, epoch: 142, loss: 0.015721
epoch: 142
train	acc: 0.9695	macro: p 0.9734, r 0.9541, f1: 0.9634	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5338	macro: p 0.3736, r 0.3084, f1: 0.3112	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4902
test	acc: 0.5877	macro: p 0.3560, r 0.3137, f1: 0.3212	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5470
global_step: 37681, epoch: 143, loss: 0.219403
global_step: 37682, epoch: 143, loss: 0.232102
global_step: 37683, epoch: 143, loss: 0.257632
global_step: 37684, epoch: 143, loss: 0.216596
global_step: 37685, epoch: 143, loss: 0.193978
global_step: 37686, epoch: 143, loss: 0.229643
global_step: 37687, epoch: 143, loss: 0.184001
global_step: 37688, epoch: 143, loss: 0.172386
global_step: 37689, epoch: 143, loss: 0.192486
global_step: 37690, epoch: 143, loss: 0.167759
global_step: 37691, epoch: 143, loss: 0.232379
global_step: 37692, epoch: 143, loss: 0.282707
global_step: 37693, epoch: 143, loss: 0.222381
global_step: 37694, epoch: 143, loss: 0.246105
global_step: 37695, epoch: 143, loss: 0.250402
global_step: 37696, epoch: 143, loss: 0.250228
global_step: 37697, epoch: 143, loss: 0.199885
global_step: 37698, epoch: 143, loss: 0.186686
global_step: 37699, epoch: 143, loss: 0.286632
global_step: 37700, epoch: 143, loss: 0.257038
global_step: 37701, epoch: 143, loss: 0.258686
global_step: 37702, epoch: 143, loss: 0.260801
global_step: 37703, epoch: 143, loss: 0.238959
global_step: 37704, epoch: 143, loss: 0.232880
global_step: 37705, epoch: 143, loss: 0.244672
global_step: 37706, epoch: 143, loss: 0.207776
global_step: 37707, epoch: 143, loss: 0.204653
global_step: 37708, epoch: 143, loss: 0.213693
global_step: 37709, epoch: 143, loss: 0.233601
global_step: 37710, epoch: 143, loss: 0.298048
global_step: 37711, epoch: 143, loss: 0.218028
global_step: 37712, epoch: 143, loss: 0.241191
global_step: 37713, epoch: 143, loss: 0.226615
global_step: 37714, epoch: 143, loss: 0.190918
global_step: 37715, epoch: 143, loss: 0.215660
global_step: 37716, epoch: 143, loss: 0.231556
global_step: 37717, epoch: 143, loss: 0.280852
global_step: 37718, epoch: 143, loss: 0.201176
global_step: 37719, epoch: 143, loss: 0.158155
global_step: 37720, epoch: 143, loss: 0.372035
epoch: 143
train	acc: 0.9694	macro: p 0.9746, r 0.9541, f1: 0.9639	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5329	macro: p 0.3907, r 0.3085, f1: 0.3133	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4884
test	acc: 0.5877	macro: p 0.3724, r 0.3102, f1: 0.3164	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5434
global_step: 37721, epoch: 144, loss: 0.273912
global_step: 37722, epoch: 144, loss: 0.213134
global_step: 37723, epoch: 144, loss: 0.151389
global_step: 37724, epoch: 144, loss: 0.228052
global_step: 37725, epoch: 144, loss: 0.213090
global_step: 37726, epoch: 144, loss: 0.190810
global_step: 37727, epoch: 144, loss: 0.222192
global_step: 37728, epoch: 144, loss: 0.212390
global_step: 37729, epoch: 144, loss: 0.276182
global_step: 37730, epoch: 144, loss: 0.251586
global_step: 37731, epoch: 144, loss: 0.220390
global_step: 37732, epoch: 144, loss: 0.244717
global_step: 37733, epoch: 144, loss: 0.255792
global_step: 37734, epoch: 144, loss: 0.223576
global_step: 37735, epoch: 144, loss: 0.232750
global_step: 37736, epoch: 144, loss: 0.168564
global_step: 37737, epoch: 144, loss: 0.232229
global_step: 37738, epoch: 144, loss: 0.252519
global_step: 37739, epoch: 144, loss: 0.290491
global_step: 37740, epoch: 144, loss: 0.231730
global_step: 37741, epoch: 144, loss: 0.248678
global_step: 37742, epoch: 144, loss: 0.194126
global_step: 37743, epoch: 144, loss: 0.242485
global_step: 37744, epoch: 144, loss: 0.208460
global_step: 37745, epoch: 144, loss: 0.186119
global_step: 37746, epoch: 144, loss: 0.246497
global_step: 37747, epoch: 144, loss: 0.211493
global_step: 37748, epoch: 144, loss: 0.221040
global_step: 37749, epoch: 144, loss: 0.290643
global_step: 37750, epoch: 144, loss: 0.300495
global_step: 37751, epoch: 144, loss: 0.273838
global_step: 37752, epoch: 144, loss: 0.218082
global_step: 37753, epoch: 144, loss: 0.233340
global_step: 37754, epoch: 144, loss: 0.230225
global_step: 37755, epoch: 144, loss: 0.258754
global_step: 37756, epoch: 144, loss: 0.263624
global_step: 37757, epoch: 144, loss: 0.218909
global_step: 37758, epoch: 144, loss: 0.257424
global_step: 37759, epoch: 144, loss: 0.207412
global_step: 37760, epoch: 144, loss: 0.107805
epoch: 144
train	acc: 0.9694	macro: p 0.9751, r 0.9552, f1: 0.9647	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5257	macro: p 0.3484, r 0.3004, f1: 0.3015	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4807
test	acc: 0.5912	macro: p 0.3663, r 0.3122, f1: 0.3187	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5465
global_step: 37761, epoch: 145, loss: 0.251073
global_step: 37762, epoch: 145, loss: 0.158146
global_step: 37763, epoch: 145, loss: 0.271969
global_step: 37764, epoch: 145, loss: 0.223399
global_step: 37765, epoch: 145, loss: 0.293311
global_step: 37766, epoch: 145, loss: 0.238248
global_step: 37767, epoch: 145, loss: 0.232325
global_step: 37768, epoch: 145, loss: 0.262201
global_step: 37769, epoch: 145, loss: 0.229819
global_step: 37770, epoch: 145, loss: 0.220237
global_step: 37771, epoch: 145, loss: 0.201666
global_step: 37772, epoch: 145, loss: 0.231749
global_step: 37773, epoch: 145, loss: 0.211386
global_step: 37774, epoch: 145, loss: 0.201774
global_step: 37775, epoch: 145, loss: 0.268785
global_step: 37776, epoch: 145, loss: 0.217393
global_step: 37777, epoch: 145, loss: 0.274476
global_step: 37778, epoch: 145, loss: 0.159797
global_step: 37779, epoch: 145, loss: 0.226526
global_step: 37780, epoch: 145, loss: 0.192384
global_step: 37781, epoch: 145, loss: 0.254060
global_step: 37782, epoch: 145, loss: 0.247309
global_step: 37783, epoch: 145, loss: 0.195409
global_step: 37784, epoch: 145, loss: 0.309593
global_step: 37785, epoch: 145, loss: 0.209050
global_step: 37786, epoch: 145, loss: 0.296740
global_step: 37787, epoch: 145, loss: 0.195369
global_step: 37788, epoch: 145, loss: 0.214299
global_step: 37789, epoch: 145, loss: 0.237072
global_step: 37790, epoch: 145, loss: 0.160419
global_step: 37791, epoch: 145, loss: 0.195353
global_step: 37792, epoch: 145, loss: 0.269604
global_step: 37793, epoch: 145, loss: 0.297518
global_step: 37794, epoch: 145, loss: 0.203746
global_step: 37795, epoch: 145, loss: 0.253003
global_step: 37796, epoch: 145, loss: 0.306346
global_step: 37797, epoch: 145, loss: 0.249532
global_step: 37798, epoch: 145, loss: 0.288720
global_step: 37799, epoch: 145, loss: 0.236773
global_step: 37800, epoch: 145, loss: 0.040851
epoch: 145
train	acc: 0.9701	macro: p 0.9751, r 0.9575, f1: 0.9659	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5266	macro: p 0.3704, r 0.3118, f1: 0.3177	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4887
test	acc: 0.5851	macro: p 0.3432, r 0.3150, f1: 0.3191	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5468
global_step: 37801, epoch: 146, loss: 0.224453
global_step: 37802, epoch: 146, loss: 0.148379
global_step: 37803, epoch: 146, loss: 0.243572
global_step: 37804, epoch: 146, loss: 0.255793
global_step: 37805, epoch: 146, loss: 0.181398
global_step: 37806, epoch: 146, loss: 0.236312
global_step: 37807, epoch: 146, loss: 0.205026
global_step: 37808, epoch: 146, loss: 0.264781
global_step: 37809, epoch: 146, loss: 0.214456
global_step: 37810, epoch: 146, loss: 0.281324
global_step: 37811, epoch: 146, loss: 0.301860
global_step: 37812, epoch: 146, loss: 0.238851
global_step: 37813, epoch: 146, loss: 0.277489
global_step: 37814, epoch: 146, loss: 0.203115
global_step: 37815, epoch: 146, loss: 0.247760
global_step: 37816, epoch: 146, loss: 0.218331
global_step: 37817, epoch: 146, loss: 0.240162
global_step: 37818, epoch: 146, loss: 0.260798
global_step: 37819, epoch: 146, loss: 0.225709
global_step: 37820, epoch: 146, loss: 0.254099
global_step: 37821, epoch: 146, loss: 0.218912
global_step: 37822, epoch: 146, loss: 0.251610
global_step: 37823, epoch: 146, loss: 0.201060
global_step: 37824, epoch: 146, loss: 0.242025
global_step: 37825, epoch: 146, loss: 0.210706
global_step: 37826, epoch: 146, loss: 0.216201
global_step: 37827, epoch: 146, loss: 0.205517
global_step: 37828, epoch: 146, loss: 0.255879
global_step: 37829, epoch: 146, loss: 0.212432
global_step: 37830, epoch: 146, loss: 0.281326
global_step: 37831, epoch: 146, loss: 0.291335
global_step: 37832, epoch: 146, loss: 0.222740
global_step: 37833, epoch: 146, loss: 0.267196
global_step: 37834, epoch: 146, loss: 0.167295
global_step: 37835, epoch: 146, loss: 0.186724
global_step: 37836, epoch: 146, loss: 0.264839
global_step: 37837, epoch: 146, loss: 0.222379
global_step: 37838, epoch: 146, loss: 0.235211
global_step: 37839, epoch: 146, loss: 0.191996
global_step: 37840, epoch: 146, loss: 0.353092
epoch: 146
train	acc: 0.9693	macro: p 0.9745, r 0.9555, f1: 0.9646	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5185	macro: p 0.3422, r 0.3019, f1: 0.3040	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4824
test	acc: 0.5774	macro: p 0.3386, r 0.3099, f1: 0.3133	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5408
global_step: 37841, epoch: 147, loss: 0.212819
global_step: 37842, epoch: 147, loss: 0.208756
global_step: 37843, epoch: 147, loss: 0.221532
global_step: 37844, epoch: 147, loss: 0.180016
global_step: 37845, epoch: 147, loss: 0.199603
global_step: 37846, epoch: 147, loss: 0.200163
global_step: 37847, epoch: 147, loss: 0.172687
global_step: 37848, epoch: 147, loss: 0.212149
global_step: 37849, epoch: 147, loss: 0.202506
global_step: 37850, epoch: 147, loss: 0.228070
global_step: 37851, epoch: 147, loss: 0.244210
global_step: 37852, epoch: 147, loss: 0.197227
global_step: 37853, epoch: 147, loss: 0.240291
global_step: 37854, epoch: 147, loss: 0.187250
global_step: 37855, epoch: 147, loss: 0.350388
global_step: 37856, epoch: 147, loss: 0.242313
global_step: 37857, epoch: 147, loss: 0.275342
global_step: 37858, epoch: 147, loss: 0.192730
global_step: 37859, epoch: 147, loss: 0.300253
global_step: 37860, epoch: 147, loss: 0.251645
global_step: 37861, epoch: 147, loss: 0.237219
global_step: 37862, epoch: 147, loss: 0.282222
global_step: 37863, epoch: 147, loss: 0.237677
global_step: 37864, epoch: 147, loss: 0.205740
global_step: 37865, epoch: 147, loss: 0.195409
global_step: 37866, epoch: 147, loss: 0.299504
global_step: 37867, epoch: 147, loss: 0.195493
global_step: 37868, epoch: 147, loss: 0.274254
global_step: 37869, epoch: 147, loss: 0.144494
global_step: 37870, epoch: 147, loss: 0.215701
global_step: 37871, epoch: 147, loss: 0.231251
global_step: 37872, epoch: 147, loss: 0.165449
global_step: 37873, epoch: 147, loss: 0.219040
global_step: 37874, epoch: 147, loss: 0.233721
global_step: 37875, epoch: 147, loss: 0.274613
global_step: 37876, epoch: 147, loss: 0.258399
global_step: 37877, epoch: 147, loss: 0.204679
global_step: 37878, epoch: 147, loss: 0.223998
global_step: 37879, epoch: 147, loss: 0.275982
global_step: 37880, epoch: 147, loss: 0.189624
epoch: 147
train	acc: 0.9683	macro: p 0.9750, r 0.9523, f1: 0.9631	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9682
dev	acc: 0.5131	macro: p 0.3286, r 0.2873, f1: 0.2861	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4661
test	acc: 0.5808	macro: p 0.3514, r 0.3068, f1: 0.3123	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5374
global_step: 37881, epoch: 148, loss: 0.193064
global_step: 37882, epoch: 148, loss: 0.191719
global_step: 37883, epoch: 148, loss: 0.231917
global_step: 37884, epoch: 148, loss: 0.164208
global_step: 37885, epoch: 148, loss: 0.191169
global_step: 37886, epoch: 148, loss: 0.243479
global_step: 37887, epoch: 148, loss: 0.240897
global_step: 37888, epoch: 148, loss: 0.218528
global_step: 37889, epoch: 148, loss: 0.256526
global_step: 37890, epoch: 148, loss: 0.204152
global_step: 37891, epoch: 148, loss: 0.232787
global_step: 37892, epoch: 148, loss: 0.260389
global_step: 37893, epoch: 148, loss: 0.176111
global_step: 37894, epoch: 148, loss: 0.189140
global_step: 37895, epoch: 148, loss: 0.246884
global_step: 37896, epoch: 148, loss: 0.221216
global_step: 37897, epoch: 148, loss: 0.166547
global_step: 37898, epoch: 148, loss: 0.244769
global_step: 37899, epoch: 148, loss: 0.241339
global_step: 37900, epoch: 148, loss: 0.219552
global_step: 37901, epoch: 148, loss: 0.201030
global_step: 37902, epoch: 148, loss: 0.302797
global_step: 37903, epoch: 148, loss: 0.210553
global_step: 37904, epoch: 148, loss: 0.185326
global_step: 37905, epoch: 148, loss: 0.184354
global_step: 37906, epoch: 148, loss: 0.205585
global_step: 37907, epoch: 148, loss: 0.241584
global_step: 37908, epoch: 148, loss: 0.327778
global_step: 37909, epoch: 148, loss: 0.303822
global_step: 37910, epoch: 148, loss: 0.149867
global_step: 37911, epoch: 148, loss: 0.249715
global_step: 37912, epoch: 148, loss: 0.180809
global_step: 37913, epoch: 148, loss: 0.234678
global_step: 37914, epoch: 148, loss: 0.221968
global_step: 37915, epoch: 148, loss: 0.197475
global_step: 37916, epoch: 148, loss: 0.280540
global_step: 37917, epoch: 148, loss: 0.155901
global_step: 37918, epoch: 148, loss: 0.179235
global_step: 37919, epoch: 148, loss: 0.173619
global_step: 37920, epoch: 148, loss: 0.307233
epoch: 148
train	acc: 0.9697	macro: p 0.9752, r 0.9556, f1: 0.9650	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5311	macro: p 0.3791, r 0.3073, f1: 0.3120	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4880
test	acc: 0.5847	macro: p 0.3556, r 0.3121, f1: 0.3181	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5430
global_step: 37921, epoch: 149, loss: 0.246141
global_step: 37922, epoch: 149, loss: 0.179747
global_step: 37923, epoch: 149, loss: 0.200300
global_step: 37924, epoch: 149, loss: 0.240424
global_step: 37925, epoch: 149, loss: 0.283586
global_step: 37926, epoch: 149, loss: 0.216385
global_step: 37927, epoch: 149, loss: 0.248468
global_step: 37928, epoch: 149, loss: 0.249423
global_step: 37929, epoch: 149, loss: 0.151836
global_step: 37930, epoch: 149, loss: 0.151889
global_step: 37931, epoch: 149, loss: 0.205609
global_step: 37932, epoch: 149, loss: 0.206708
global_step: 37933, epoch: 149, loss: 0.160052
global_step: 37934, epoch: 149, loss: 0.155612
global_step: 37935, epoch: 149, loss: 0.230542
global_step: 37936, epoch: 149, loss: 0.224664
global_step: 37937, epoch: 149, loss: 0.169973
global_step: 37938, epoch: 149, loss: 0.199132
global_step: 37939, epoch: 149, loss: 0.207331
global_step: 37940, epoch: 149, loss: 0.139833
global_step: 37941, epoch: 149, loss: 0.233956
global_step: 37942, epoch: 149, loss: 0.272501
global_step: 37943, epoch: 149, loss: 0.217318
global_step: 37944, epoch: 149, loss: 0.298981
global_step: 37945, epoch: 149, loss: 0.227479
global_step: 37946, epoch: 149, loss: 0.245350
global_step: 37947, epoch: 149, loss: 0.210119
global_step: 37948, epoch: 149, loss: 0.214807
global_step: 37949, epoch: 149, loss: 0.195274
global_step: 37950, epoch: 149, loss: 0.236937
global_step: 37951, epoch: 149, loss: 0.282050
global_step: 37952, epoch: 149, loss: 0.253502
global_step: 37953, epoch: 149, loss: 0.204479
global_step: 37954, epoch: 149, loss: 0.236002
global_step: 37955, epoch: 149, loss: 0.230382
global_step: 37956, epoch: 149, loss: 0.270463
global_step: 37957, epoch: 149, loss: 0.230091
global_step: 37958, epoch: 149, loss: 0.272415
global_step: 37959, epoch: 149, loss: 0.273546
global_step: 37960, epoch: 149, loss: 0.021844
epoch: 149
train	acc: 0.9703	macro: p 0.9743, r 0.9585, f1: 0.9661	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5239	macro: p 0.3565, r 0.3062, f1: 0.3090	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4841
test	acc: 0.5808	macro: p 0.3445, r 0.3134, f1: 0.3174	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5432
global_step: 37961, epoch: 150, loss: 0.206808
global_step: 37962, epoch: 150, loss: 0.198772
global_step: 37963, epoch: 150, loss: 0.206041
global_step: 37964, epoch: 150, loss: 0.153074
global_step: 37965, epoch: 150, loss: 0.243586
global_step: 37966, epoch: 150, loss: 0.192938
global_step: 37967, epoch: 150, loss: 0.182887
global_step: 37968, epoch: 150, loss: 0.238273
global_step: 37969, epoch: 150, loss: 0.262991
global_step: 37970, epoch: 150, loss: 0.205124
global_step: 37971, epoch: 150, loss: 0.278619
global_step: 37972, epoch: 150, loss: 0.284109
global_step: 37973, epoch: 150, loss: 0.143424
global_step: 37974, epoch: 150, loss: 0.138644
global_step: 37975, epoch: 150, loss: 0.264511
global_step: 37976, epoch: 150, loss: 0.236951
global_step: 37977, epoch: 150, loss: 0.203287
global_step: 37978, epoch: 150, loss: 0.152031
global_step: 37979, epoch: 150, loss: 0.210350
global_step: 37980, epoch: 150, loss: 0.218470
global_step: 37981, epoch: 150, loss: 0.239731
global_step: 37982, epoch: 150, loss: 0.171367
global_step: 37983, epoch: 150, loss: 0.338803
global_step: 37984, epoch: 150, loss: 0.192424
global_step: 37985, epoch: 150, loss: 0.221822
global_step: 37986, epoch: 150, loss: 0.178162
global_step: 37987, epoch: 150, loss: 0.205443
global_step: 37988, epoch: 150, loss: 0.250716
global_step: 37989, epoch: 150, loss: 0.251035
global_step: 37990, epoch: 150, loss: 0.262038
global_step: 37991, epoch: 150, loss: 0.291543
global_step: 37992, epoch: 150, loss: 0.264050
global_step: 37993, epoch: 150, loss: 0.279665
global_step: 37994, epoch: 150, loss: 0.220337
global_step: 37995, epoch: 150, loss: 0.205954
global_step: 37996, epoch: 150, loss: 0.291022
global_step: 37997, epoch: 150, loss: 0.244663
global_step: 37998, epoch: 150, loss: 0.275269
global_step: 37999, epoch: 150, loss: 0.239258
global_step: 38000, epoch: 150, loss: 0.066472
epoch: 150
train	acc: 0.9693	macro: p 0.9732, r 0.9558, f1: 0.9641	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5311	macro: p 0.3901, r 0.3096, f1: 0.3184	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4883
test	acc: 0.5828	macro: p 0.3709, r 0.3120, f1: 0.3220	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5413
global_step: 38001, epoch: 151, loss: 0.179768
global_step: 38002, epoch: 151, loss: 0.234501
global_step: 38003, epoch: 151, loss: 0.228834
global_step: 38004, epoch: 151, loss: 0.126385
global_step: 38005, epoch: 151, loss: 0.211639
global_step: 38006, epoch: 151, loss: 0.244721
global_step: 38007, epoch: 151, loss: 0.153910
global_step: 38008, epoch: 151, loss: 0.214300
global_step: 38009, epoch: 151, loss: 0.274907
global_step: 38010, epoch: 151, loss: 0.232688
global_step: 38011, epoch: 151, loss: 0.237869
global_step: 38012, epoch: 151, loss: 0.232632
global_step: 38013, epoch: 151, loss: 0.131336
global_step: 38014, epoch: 151, loss: 0.237294
global_step: 38015, epoch: 151, loss: 0.162335
global_step: 38016, epoch: 151, loss: 0.194614
global_step: 38017, epoch: 151, loss: 0.265088
global_step: 38018, epoch: 151, loss: 0.216912
global_step: 38019, epoch: 151, loss: 0.208911
global_step: 38020, epoch: 151, loss: 0.281690
global_step: 38021, epoch: 151, loss: 0.163374
global_step: 38022, epoch: 151, loss: 0.213708
global_step: 38023, epoch: 151, loss: 0.208902
global_step: 38024, epoch: 151, loss: 0.239360
global_step: 38025, epoch: 151, loss: 0.204430
global_step: 38026, epoch: 151, loss: 0.240852
global_step: 38027, epoch: 151, loss: 0.191410
global_step: 38028, epoch: 151, loss: 0.210833
global_step: 38029, epoch: 151, loss: 0.267943
global_step: 38030, epoch: 151, loss: 0.202256
global_step: 38031, epoch: 151, loss: 0.223626
global_step: 38032, epoch: 151, loss: 0.215846
global_step: 38033, epoch: 151, loss: 0.246337
global_step: 38034, epoch: 151, loss: 0.190161
global_step: 38035, epoch: 151, loss: 0.254417
global_step: 38036, epoch: 151, loss: 0.208196
global_step: 38037, epoch: 151, loss: 0.155611
global_step: 38038, epoch: 151, loss: 0.242461
global_step: 38039, epoch: 151, loss: 0.143868
global_step: 38040, epoch: 151, loss: 0.682409
epoch: 151
train	acc: 0.9686	macro: p 0.9732, r 0.9561, f1: 0.9643	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5176	macro: p 0.3415, r 0.2908, f1: 0.2882	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4723
test	acc: 0.5831	macro: p 0.3503, r 0.3114, f1: 0.3171	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5428
global_step: 38041, epoch: 152, loss: 0.198504
global_step: 38042, epoch: 152, loss: 0.186930
global_step: 38043, epoch: 152, loss: 0.199773
global_step: 38044, epoch: 152, loss: 0.207174
global_step: 38045, epoch: 152, loss: 0.248228
global_step: 38046, epoch: 152, loss: 0.173675
global_step: 38047, epoch: 152, loss: 0.212389
global_step: 38048, epoch: 152, loss: 0.217408
global_step: 38049, epoch: 152, loss: 0.224261
global_step: 38050, epoch: 152, loss: 0.192742
global_step: 38051, epoch: 152, loss: 0.222919
global_step: 38052, epoch: 152, loss: 0.222419
global_step: 38053, epoch: 152, loss: 0.177175
global_step: 38054, epoch: 152, loss: 0.202631
global_step: 38055, epoch: 152, loss: 0.189105
global_step: 38056, epoch: 152, loss: 0.255180
global_step: 38057, epoch: 152, loss: 0.154733
global_step: 38058, epoch: 152, loss: 0.190482
global_step: 38059, epoch: 152, loss: 0.255709
global_step: 38060, epoch: 152, loss: 0.187935
global_step: 38061, epoch: 152, loss: 0.291206
global_step: 38062, epoch: 152, loss: 0.278645
global_step: 38063, epoch: 152, loss: 0.301177
global_step: 38064, epoch: 152, loss: 0.220789
global_step: 38065, epoch: 152, loss: 0.252150
global_step: 38066, epoch: 152, loss: 0.188005
global_step: 38067, epoch: 152, loss: 0.210658
global_step: 38068, epoch: 152, loss: 0.267671
global_step: 38069, epoch: 152, loss: 0.248407
global_step: 38070, epoch: 152, loss: 0.278655
global_step: 38071, epoch: 152, loss: 0.253941
global_step: 38072, epoch: 152, loss: 0.310804
global_step: 38073, epoch: 152, loss: 0.234458
global_step: 38074, epoch: 152, loss: 0.186216
global_step: 38075, epoch: 152, loss: 0.215725
global_step: 38076, epoch: 152, loss: 0.114470
global_step: 38077, epoch: 152, loss: 0.207813
global_step: 38078, epoch: 152, loss: 0.197381
global_step: 38079, epoch: 152, loss: 0.186386
global_step: 38080, epoch: 152, loss: 0.106292
epoch: 152
train	acc: 0.9693	macro: p 0.9739, r 0.9553, f1: 0.9642	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5257	macro: p 0.3483, r 0.2919, f1: 0.2920	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4757
test	acc: 0.5916	macro: p 0.3739, r 0.3121, f1: 0.3219	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5461
global_step: 38081, epoch: 153, loss: 0.193319
global_step: 38082, epoch: 153, loss: 0.209439
global_step: 38083, epoch: 153, loss: 0.200296
global_step: 38084, epoch: 153, loss: 0.255933
global_step: 38085, epoch: 153, loss: 0.192217
global_step: 38086, epoch: 153, loss: 0.230303
global_step: 38087, epoch: 153, loss: 0.225951
global_step: 38088, epoch: 153, loss: 0.189595
global_step: 38089, epoch: 153, loss: 0.165763
global_step: 38090, epoch: 153, loss: 0.178974
global_step: 38091, epoch: 153, loss: 0.260649
global_step: 38092, epoch: 153, loss: 0.163888
global_step: 38093, epoch: 153, loss: 0.260513
global_step: 38094, epoch: 153, loss: 0.174079
global_step: 38095, epoch: 153, loss: 0.299462
global_step: 38096, epoch: 153, loss: 0.178632
global_step: 38097, epoch: 153, loss: 0.176095
global_step: 38098, epoch: 153, loss: 0.252834
global_step: 38099, epoch: 153, loss: 0.208363
global_step: 38100, epoch: 153, loss: 0.167697
global_step: 38101, epoch: 153, loss: 0.204580
global_step: 38102, epoch: 153, loss: 0.235951
global_step: 38103, epoch: 153, loss: 0.218951
global_step: 38104, epoch: 153, loss: 0.201648
global_step: 38105, epoch: 153, loss: 0.228702
global_step: 38106, epoch: 153, loss: 0.186322
global_step: 38107, epoch: 153, loss: 0.223522
global_step: 38108, epoch: 153, loss: 0.183188
global_step: 38109, epoch: 153, loss: 0.185920
global_step: 38110, epoch: 153, loss: 0.224944
global_step: 38111, epoch: 153, loss: 0.267546
global_step: 38112, epoch: 153, loss: 0.160328
global_step: 38113, epoch: 153, loss: 0.194177
global_step: 38114, epoch: 153, loss: 0.248868
global_step: 38115, epoch: 153, loss: 0.172684
global_step: 38116, epoch: 153, loss: 0.191922
global_step: 38117, epoch: 153, loss: 0.261217
global_step: 38118, epoch: 153, loss: 0.184698
global_step: 38119, epoch: 153, loss: 0.192090
global_step: 38120, epoch: 153, loss: 0.131093
epoch: 153
train	acc: 0.9704	macro: p 0.9746, r 0.9577, f1: 0.9658	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5203	macro: p 0.3437, r 0.2934, f1: 0.2936	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4757
test	acc: 0.5893	macro: p 0.3798, r 0.3182, f1: 0.3271	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5468
global_step: 38121, epoch: 154, loss: 0.191421
global_step: 38122, epoch: 154, loss: 0.276269
global_step: 38123, epoch: 154, loss: 0.225137
global_step: 38124, epoch: 154, loss: 0.208675
global_step: 38125, epoch: 154, loss: 0.162948
global_step: 38126, epoch: 154, loss: 0.177857
global_step: 38127, epoch: 154, loss: 0.170525
global_step: 38128, epoch: 154, loss: 0.210389
global_step: 38129, epoch: 154, loss: 0.138709
global_step: 38130, epoch: 154, loss: 0.242905
global_step: 38131, epoch: 154, loss: 0.251770
global_step: 38132, epoch: 154, loss: 0.318972
global_step: 38133, epoch: 154, loss: 0.235821
global_step: 38134, epoch: 154, loss: 0.194578
global_step: 38135, epoch: 154, loss: 0.155614
global_step: 38136, epoch: 154, loss: 0.172194
global_step: 38137, epoch: 154, loss: 0.191381
global_step: 38138, epoch: 154, loss: 0.257856
global_step: 38139, epoch: 154, loss: 0.304764
global_step: 38140, epoch: 154, loss: 0.225666
global_step: 38141, epoch: 154, loss: 0.244317
global_step: 38142, epoch: 154, loss: 0.165053
global_step: 38143, epoch: 154, loss: 0.167922
global_step: 38144, epoch: 154, loss: 0.223180
global_step: 38145, epoch: 154, loss: 0.185992
global_step: 38146, epoch: 154, loss: 0.188556
global_step: 38147, epoch: 154, loss: 0.147881
global_step: 38148, epoch: 154, loss: 0.220622
global_step: 38149, epoch: 154, loss: 0.223220
global_step: 38150, epoch: 154, loss: 0.246503
global_step: 38151, epoch: 154, loss: 0.184887
global_step: 38152, epoch: 154, loss: 0.223976
global_step: 38153, epoch: 154, loss: 0.252833
global_step: 38154, epoch: 154, loss: 0.301827
global_step: 38155, epoch: 154, loss: 0.196021
global_step: 38156, epoch: 154, loss: 0.311689
global_step: 38157, epoch: 154, loss: 0.240608
global_step: 38158, epoch: 154, loss: 0.220868
global_step: 38159, epoch: 154, loss: 0.207558
global_step: 38160, epoch: 154, loss: 0.054365
epoch: 154
train	acc: 0.9704	macro: p 0.9758, r 0.9583, f1: 0.9667	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5248	macro: p 0.3582, r 0.3012, f1: 0.3057	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4801
test	acc: 0.5920	macro: p 0.3683, r 0.3161, f1: 0.3253	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5488
global_step: 38161, epoch: 155, loss: 0.233254
global_step: 38162, epoch: 155, loss: 0.221018
global_step: 38163, epoch: 155, loss: 0.216073
global_step: 38164, epoch: 155, loss: 0.261599
global_step: 38165, epoch: 155, loss: 0.292562
global_step: 38166, epoch: 155, loss: 0.181277
global_step: 38167, epoch: 155, loss: 0.126229
global_step: 38168, epoch: 155, loss: 0.206824
global_step: 38169, epoch: 155, loss: 0.249016
global_step: 38170, epoch: 155, loss: 0.189490
global_step: 38171, epoch: 155, loss: 0.212579
global_step: 38172, epoch: 155, loss: 0.255591
global_step: 38173, epoch: 155, loss: 0.164912
global_step: 38174, epoch: 155, loss: 0.160679
global_step: 38175, epoch: 155, loss: 0.166346
global_step: 38176, epoch: 155, loss: 0.204335
global_step: 38177, epoch: 155, loss: 0.245553
global_step: 38178, epoch: 155, loss: 0.234701
global_step: 38179, epoch: 155, loss: 0.197370
global_step: 38180, epoch: 155, loss: 0.253164
global_step: 38181, epoch: 155, loss: 0.220567
global_step: 38182, epoch: 155, loss: 0.253853
global_step: 38183, epoch: 155, loss: 0.215354
global_step: 38184, epoch: 155, loss: 0.184907
global_step: 38185, epoch: 155, loss: 0.193263
global_step: 38186, epoch: 155, loss: 0.277073
global_step: 38187, epoch: 155, loss: 0.264723
global_step: 38188, epoch: 155, loss: 0.296053
global_step: 38189, epoch: 155, loss: 0.217343
global_step: 38190, epoch: 155, loss: 0.205366
global_step: 38191, epoch: 155, loss: 0.202752
global_step: 38192, epoch: 155, loss: 0.185401
global_step: 38193, epoch: 155, loss: 0.238153
global_step: 38194, epoch: 155, loss: 0.347262
global_step: 38195, epoch: 155, loss: 0.212640
global_step: 38196, epoch: 155, loss: 0.218754
global_step: 38197, epoch: 155, loss: 0.288875
global_step: 38198, epoch: 155, loss: 0.231502
global_step: 38199, epoch: 155, loss: 0.225616
global_step: 38200, epoch: 155, loss: 0.003267
epoch: 155
train	acc: 0.9702	macro: p 0.9744, r 0.9571, f1: 0.9654	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5167	macro: p 0.3316, r 0.2923, f1: 0.2924	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4740
test	acc: 0.5889	macro: p 0.3744, r 0.3163, f1: 0.3265	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5476
global_step: 38201, epoch: 156, loss: 0.158884
global_step: 38202, epoch: 156, loss: 0.188832
global_step: 38203, epoch: 156, loss: 0.225038
global_step: 38204, epoch: 156, loss: 0.244452
global_step: 38205, epoch: 156, loss: 0.241135
global_step: 38206, epoch: 156, loss: 0.222628
global_step: 38207, epoch: 156, loss: 0.203780
global_step: 38208, epoch: 156, loss: 0.248155
global_step: 38209, epoch: 156, loss: 0.212959
global_step: 38210, epoch: 156, loss: 0.230806
global_step: 38211, epoch: 156, loss: 0.230190
global_step: 38212, epoch: 156, loss: 0.166623
global_step: 38213, epoch: 156, loss: 0.204531
global_step: 38214, epoch: 156, loss: 0.231649
global_step: 38215, epoch: 156, loss: 0.213703
global_step: 38216, epoch: 156, loss: 0.284290
global_step: 38217, epoch: 156, loss: 0.250325
global_step: 38218, epoch: 156, loss: 0.228281
global_step: 38219, epoch: 156, loss: 0.183639
global_step: 38220, epoch: 156, loss: 0.194978
global_step: 38221, epoch: 156, loss: 0.220201
global_step: 38222, epoch: 156, loss: 0.169344
global_step: 38223, epoch: 156, loss: 0.258626
global_step: 38224, epoch: 156, loss: 0.214370
global_step: 38225, epoch: 156, loss: 0.249215
global_step: 38226, epoch: 156, loss: 0.188887
global_step: 38227, epoch: 156, loss: 0.314178
global_step: 38228, epoch: 156, loss: 0.234490
global_step: 38229, epoch: 156, loss: 0.160427
global_step: 38230, epoch: 156, loss: 0.183631
global_step: 38231, epoch: 156, loss: 0.260118
global_step: 38232, epoch: 156, loss: 0.258368
global_step: 38233, epoch: 156, loss: 0.171092
global_step: 38234, epoch: 156, loss: 0.247021
global_step: 38235, epoch: 156, loss: 0.176994
global_step: 38236, epoch: 156, loss: 0.229905
global_step: 38237, epoch: 156, loss: 0.234607
global_step: 38238, epoch: 156, loss: 0.208631
global_step: 38239, epoch: 156, loss: 0.182507
global_step: 38240, epoch: 156, loss: 0.100574
epoch: 156
train	acc: 0.9693	macro: p 0.9740, r 0.9570, f1: 0.9651	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5221	macro: p 0.3503, r 0.2989, f1: 0.2985	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4772
test	acc: 0.5854	macro: p 0.3518, r 0.3141, f1: 0.3193	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5439
global_step: 38241, epoch: 157, loss: 0.167578
global_step: 38242, epoch: 157, loss: 0.224727
global_step: 38243, epoch: 157, loss: 0.191498
global_step: 38244, epoch: 157, loss: 0.187001
global_step: 38245, epoch: 157, loss: 0.187584
global_step: 38246, epoch: 157, loss: 0.289625
global_step: 38247, epoch: 157, loss: 0.221704
global_step: 38248, epoch: 157, loss: 0.182333
global_step: 38249, epoch: 157, loss: 0.217583
global_step: 38250, epoch: 157, loss: 0.185541
global_step: 38251, epoch: 157, loss: 0.245434
global_step: 38252, epoch: 157, loss: 0.200477
global_step: 38253, epoch: 157, loss: 0.165378
global_step: 38254, epoch: 157, loss: 0.172899
global_step: 38255, epoch: 157, loss: 0.257561
global_step: 38256, epoch: 157, loss: 0.269301
global_step: 38257, epoch: 157, loss: 0.180901
global_step: 38258, epoch: 157, loss: 0.171716
global_step: 38259, epoch: 157, loss: 0.191456
global_step: 38260, epoch: 157, loss: 0.282699
global_step: 38261, epoch: 157, loss: 0.205890
global_step: 38262, epoch: 157, loss: 0.197912
global_step: 38263, epoch: 157, loss: 0.282998
global_step: 38264, epoch: 157, loss: 0.270918
global_step: 38265, epoch: 157, loss: 0.218590
global_step: 38266, epoch: 157, loss: 0.163537
global_step: 38267, epoch: 157, loss: 0.259953
global_step: 38268, epoch: 157, loss: 0.133728
global_step: 38269, epoch: 157, loss: 0.198132
global_step: 38270, epoch: 157, loss: 0.220331
global_step: 38271, epoch: 157, loss: 0.172884
global_step: 38272, epoch: 157, loss: 0.205740
global_step: 38273, epoch: 157, loss: 0.321916
global_step: 38274, epoch: 157, loss: 0.268673
global_step: 38275, epoch: 157, loss: 0.171206
global_step: 38276, epoch: 157, loss: 0.260649
global_step: 38277, epoch: 157, loss: 0.234372
global_step: 38278, epoch: 157, loss: 0.192532
global_step: 38279, epoch: 157, loss: 0.159364
global_step: 38280, epoch: 157, loss: 0.058875
epoch: 157
train	acc: 0.9702	macro: p 0.9750, r 0.9578, f1: 0.9661	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5221	macro: p 0.3472, r 0.2974, f1: 0.2987	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4806
test	acc: 0.5828	macro: p 0.3441, r 0.3105, f1: 0.3161	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5421
global_step: 38281, epoch: 158, loss: 0.237775
global_step: 38282, epoch: 158, loss: 0.191277
global_step: 38283, epoch: 158, loss: 0.176605
global_step: 38284, epoch: 158, loss: 0.161887
global_step: 38285, epoch: 158, loss: 0.245724
global_step: 38286, epoch: 158, loss: 0.149229
global_step: 38287, epoch: 158, loss: 0.203954
global_step: 38288, epoch: 158, loss: 0.254753
global_step: 38289, epoch: 158, loss: 0.160559
global_step: 38290, epoch: 158, loss: 0.262211
global_step: 38291, epoch: 158, loss: 0.252988
global_step: 38292, epoch: 158, loss: 0.215153
global_step: 38293, epoch: 158, loss: 0.177100
global_step: 38294, epoch: 158, loss: 0.178915
global_step: 38295, epoch: 158, loss: 0.223823
global_step: 38296, epoch: 158, loss: 0.126935
global_step: 38297, epoch: 158, loss: 0.169606
global_step: 38298, epoch: 158, loss: 0.204335
global_step: 38299, epoch: 158, loss: 0.180620
global_step: 38300, epoch: 158, loss: 0.185709
global_step: 38301, epoch: 158, loss: 0.210096
global_step: 38302, epoch: 158, loss: 0.234315
global_step: 38303, epoch: 158, loss: 0.216872
global_step: 38304, epoch: 158, loss: 0.229932
global_step: 38305, epoch: 158, loss: 0.235511
global_step: 38306, epoch: 158, loss: 0.331871
global_step: 38307, epoch: 158, loss: 0.336146
global_step: 38308, epoch: 158, loss: 0.210088
global_step: 38309, epoch: 158, loss: 0.238669
global_step: 38310, epoch: 158, loss: 0.183382
global_step: 38311, epoch: 158, loss: 0.216094
global_step: 38312, epoch: 158, loss: 0.215402
global_step: 38313, epoch: 158, loss: 0.206916
global_step: 38314, epoch: 158, loss: 0.307570
global_step: 38315, epoch: 158, loss: 0.171462
global_step: 38316, epoch: 158, loss: 0.211879
global_step: 38317, epoch: 158, loss: 0.266773
global_step: 38318, epoch: 158, loss: 0.162516
global_step: 38319, epoch: 158, loss: 0.203751
global_step: 38320, epoch: 158, loss: 0.016623
epoch: 158
train	acc: 0.9704	macro: p 0.9733, r 0.9590, f1: 0.9658	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5320	macro: p 0.3616, r 0.3059, f1: 0.3093	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4890
test	acc: 0.5793	macro: p 0.3616, r 0.3108, f1: 0.3177	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5384
global_step: 38321, epoch: 159, loss: 0.251714
global_step: 38322, epoch: 159, loss: 0.210305
global_step: 38323, epoch: 159, loss: 0.226624
global_step: 38324, epoch: 159, loss: 0.200451
global_step: 38325, epoch: 159, loss: 0.223727
global_step: 38326, epoch: 159, loss: 0.292808
global_step: 38327, epoch: 159, loss: 0.224372
global_step: 38328, epoch: 159, loss: 0.140292
global_step: 38329, epoch: 159, loss: 0.200600
global_step: 38330, epoch: 159, loss: 0.163946
global_step: 38331, epoch: 159, loss: 0.259129
global_step: 38332, epoch: 159, loss: 0.203170
global_step: 38333, epoch: 159, loss: 0.180552
global_step: 38334, epoch: 159, loss: 0.262080
global_step: 38335, epoch: 159, loss: 0.158943
global_step: 38336, epoch: 159, loss: 0.227733
global_step: 38337, epoch: 159, loss: 0.204506
global_step: 38338, epoch: 159, loss: 0.169223
global_step: 38339, epoch: 159, loss: 0.192670
global_step: 38340, epoch: 159, loss: 0.248351
global_step: 38341, epoch: 159, loss: 0.255055
global_step: 38342, epoch: 159, loss: 0.180244
global_step: 38343, epoch: 159, loss: 0.228680
global_step: 38344, epoch: 159, loss: 0.174326
global_step: 38345, epoch: 159, loss: 0.149073
global_step: 38346, epoch: 159, loss: 0.230902
global_step: 38347, epoch: 159, loss: 0.268740
global_step: 38348, epoch: 159, loss: 0.189912
global_step: 38349, epoch: 159, loss: 0.261286
global_step: 38350, epoch: 159, loss: 0.218046
global_step: 38351, epoch: 159, loss: 0.212180
global_step: 38352, epoch: 159, loss: 0.246444
global_step: 38353, epoch: 159, loss: 0.248635
global_step: 38354, epoch: 159, loss: 0.217601
global_step: 38355, epoch: 159, loss: 0.271222
global_step: 38356, epoch: 159, loss: 0.188232
global_step: 38357, epoch: 159, loss: 0.268657
global_step: 38358, epoch: 159, loss: 0.192669
global_step: 38359, epoch: 159, loss: 0.217281
global_step: 38360, epoch: 159, loss: 0.265094
epoch: 159
train	acc: 0.9707	macro: p 0.9745, r 0.9605, f1: 0.9673	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5140	macro: p 0.3259, r 0.2955, f1: 0.2962	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4764
test	acc: 0.5732	macro: p 0.3512, r 0.3112, f1: 0.3173	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5359
global_step: 38361, epoch: 160, loss: 0.241511
global_step: 38362, epoch: 160, loss: 0.195870
global_step: 38363, epoch: 160, loss: 0.207592
global_step: 38364, epoch: 160, loss: 0.152338
global_step: 38365, epoch: 160, loss: 0.186497
global_step: 38366, epoch: 160, loss: 0.193540
global_step: 38367, epoch: 160, loss: 0.168116
global_step: 38368, epoch: 160, loss: 0.223825
global_step: 38369, epoch: 160, loss: 0.182489
global_step: 38370, epoch: 160, loss: 0.190619
global_step: 38371, epoch: 160, loss: 0.251848
global_step: 38372, epoch: 160, loss: 0.252771
global_step: 38373, epoch: 160, loss: 0.202370
global_step: 38374, epoch: 160, loss: 0.180009
global_step: 38375, epoch: 160, loss: 0.203305
global_step: 38376, epoch: 160, loss: 0.231695
global_step: 38377, epoch: 160, loss: 0.229330
global_step: 38378, epoch: 160, loss: 0.188479
global_step: 38379, epoch: 160, loss: 0.206199
global_step: 38380, epoch: 160, loss: 0.183695
global_step: 38381, epoch: 160, loss: 0.228428
global_step: 38382, epoch: 160, loss: 0.250972
global_step: 38383, epoch: 160, loss: 0.187810
global_step: 38384, epoch: 160, loss: 0.145998
global_step: 38385, epoch: 160, loss: 0.192908
global_step: 38386, epoch: 160, loss: 0.196001
global_step: 38387, epoch: 160, loss: 0.209124
global_step: 38388, epoch: 160, loss: 0.263603
global_step: 38389, epoch: 160, loss: 0.186473
global_step: 38390, epoch: 160, loss: 0.219994
global_step: 38391, epoch: 160, loss: 0.219292
global_step: 38392, epoch: 160, loss: 0.206468
global_step: 38393, epoch: 160, loss: 0.219754
global_step: 38394, epoch: 160, loss: 0.231874
global_step: 38395, epoch: 160, loss: 0.209071
global_step: 38396, epoch: 160, loss: 0.234237
global_step: 38397, epoch: 160, loss: 0.286125
global_step: 38398, epoch: 160, loss: 0.154324
global_step: 38399, epoch: 160, loss: 0.233930
global_step: 38400, epoch: 160, loss: 0.027234
epoch: 160
train	acc: 0.9709	macro: p 0.9740, r 0.9612, f1: 0.9674	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5203	macro: p 0.3540, r 0.3039, f1: 0.3076	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4823
test	acc: 0.5751	macro: p 0.3617, r 0.3127, f1: 0.3199	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5382
global_step: 38401, epoch: 161, loss: 0.232607
global_step: 38402, epoch: 161, loss: 0.174201
global_step: 38403, epoch: 161, loss: 0.168946
global_step: 38404, epoch: 161, loss: 0.235069
global_step: 38405, epoch: 161, loss: 0.200564
global_step: 38406, epoch: 161, loss: 0.236294
global_step: 38407, epoch: 161, loss: 0.186554
global_step: 38408, epoch: 161, loss: 0.279831
global_step: 38409, epoch: 161, loss: 0.199267
global_step: 38410, epoch: 161, loss: 0.214535
global_step: 38411, epoch: 161, loss: 0.184407
global_step: 38412, epoch: 161, loss: 0.148367
global_step: 38413, epoch: 161, loss: 0.163705
global_step: 38414, epoch: 161, loss: 0.225813
global_step: 38415, epoch: 161, loss: 0.308175
global_step: 38416, epoch: 161, loss: 0.218838
global_step: 38417, epoch: 161, loss: 0.177649
global_step: 38418, epoch: 161, loss: 0.217828
global_step: 38419, epoch: 161, loss: 0.232053
global_step: 38420, epoch: 161, loss: 0.246078
global_step: 38421, epoch: 161, loss: 0.253732
global_step: 38422, epoch: 161, loss: 0.193432
global_step: 38423, epoch: 161, loss: 0.211401
global_step: 38424, epoch: 161, loss: 0.187877
global_step: 38425, epoch: 161, loss: 0.170612
global_step: 38426, epoch: 161, loss: 0.199541
global_step: 38427, epoch: 161, loss: 0.231282
global_step: 38428, epoch: 161, loss: 0.195831
global_step: 38429, epoch: 161, loss: 0.245181
global_step: 38430, epoch: 161, loss: 0.215807
global_step: 38431, epoch: 161, loss: 0.202357
global_step: 38432, epoch: 161, loss: 0.198108
global_step: 38433, epoch: 161, loss: 0.252314
global_step: 38434, epoch: 161, loss: 0.239090
global_step: 38435, epoch: 161, loss: 0.248043
global_step: 38436, epoch: 161, loss: 0.244233
global_step: 38437, epoch: 161, loss: 0.183583
global_step: 38438, epoch: 161, loss: 0.178448
global_step: 38439, epoch: 161, loss: 0.188892
global_step: 38440, epoch: 161, loss: 0.990109
epoch: 161
train	acc: 0.9707	macro: p 0.9733, r 0.9609, f1: 0.9668	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5140	macro: p 0.3398, r 0.2978, f1: 0.2978	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4761
test	acc: 0.5716	macro: p 0.3443, r 0.3090, f1: 0.3132	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5354
global_step: 38441, epoch: 162, loss: 0.246872
global_step: 38442, epoch: 162, loss: 0.209321
global_step: 38443, epoch: 162, loss: 0.215831
global_step: 38444, epoch: 162, loss: 0.184508
global_step: 38445, epoch: 162, loss: 0.184925
global_step: 38446, epoch: 162, loss: 0.253144
global_step: 38447, epoch: 162, loss: 0.195213
global_step: 38448, epoch: 162, loss: 0.187997
global_step: 38449, epoch: 162, loss: 0.231130
global_step: 38450, epoch: 162, loss: 0.306935
global_step: 38451, epoch: 162, loss: 0.162756
global_step: 38452, epoch: 162, loss: 0.241443
global_step: 38453, epoch: 162, loss: 0.208740
global_step: 38454, epoch: 162, loss: 0.222455
global_step: 38455, epoch: 162, loss: 0.143997
global_step: 38456, epoch: 162, loss: 0.246985
global_step: 38457, epoch: 162, loss: 0.206988
global_step: 38458, epoch: 162, loss: 0.194720
global_step: 38459, epoch: 162, loss: 0.194101
global_step: 38460, epoch: 162, loss: 0.221199
global_step: 38461, epoch: 162, loss: 0.256393
global_step: 38462, epoch: 162, loss: 0.226398
global_step: 38463, epoch: 162, loss: 0.186676
global_step: 38464, epoch: 162, loss: 0.213887
global_step: 38465, epoch: 162, loss: 0.213607
global_step: 38466, epoch: 162, loss: 0.189194
global_step: 38467, epoch: 162, loss: 0.204379
global_step: 38468, epoch: 162, loss: 0.172646
global_step: 38469, epoch: 162, loss: 0.199785
global_step: 38470, epoch: 162, loss: 0.234958
global_step: 38471, epoch: 162, loss: 0.222314
global_step: 38472, epoch: 162, loss: 0.235062
global_step: 38473, epoch: 162, loss: 0.266799
global_step: 38474, epoch: 162, loss: 0.218742
global_step: 38475, epoch: 162, loss: 0.182563
global_step: 38476, epoch: 162, loss: 0.265970
global_step: 38477, epoch: 162, loss: 0.320327
global_step: 38478, epoch: 162, loss: 0.209897
global_step: 38479, epoch: 162, loss: 0.266741
global_step: 38480, epoch: 162, loss: 0.266333
epoch: 162
train	acc: 0.9698	macro: p 0.9740, r 0.9566, f1: 0.9650	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5185	macro: p 0.3388, r 0.2908, f1: 0.2905	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4729
test	acc: 0.5747	macro: p 0.3466, r 0.3043, f1: 0.3113	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5346
global_step: 38481, epoch: 163, loss: 0.192568
global_step: 38482, epoch: 163, loss: 0.274587
global_step: 38483, epoch: 163, loss: 0.196763
global_step: 38484, epoch: 163, loss: 0.258935
global_step: 38485, epoch: 163, loss: 0.170711
global_step: 38486, epoch: 163, loss: 0.189210
global_step: 38487, epoch: 163, loss: 0.224042
global_step: 38488, epoch: 163, loss: 0.214953
global_step: 38489, epoch: 163, loss: 0.196966
global_step: 38490, epoch: 163, loss: 0.203875
global_step: 38491, epoch: 163, loss: 0.217018
global_step: 38492, epoch: 163, loss: 0.154135
global_step: 38493, epoch: 163, loss: 0.204532
global_step: 38494, epoch: 163, loss: 0.185891
global_step: 38495, epoch: 163, loss: 0.194065
global_step: 38496, epoch: 163, loss: 0.189857
global_step: 38497, epoch: 163, loss: 0.177705
global_step: 38498, epoch: 163, loss: 0.229156
global_step: 38499, epoch: 163, loss: 0.170054
global_step: 38500, epoch: 163, loss: 0.239728
global_step: 38501, epoch: 163, loss: 0.176957
global_step: 38502, epoch: 163, loss: 0.187536
global_step: 38503, epoch: 163, loss: 0.171775
global_step: 38504, epoch: 163, loss: 0.177942
global_step: 38505, epoch: 163, loss: 0.192858
global_step: 38506, epoch: 163, loss: 0.154315
global_step: 38507, epoch: 163, loss: 0.222460
global_step: 38508, epoch: 163, loss: 0.220499
global_step: 38509, epoch: 163, loss: 0.205997
global_step: 38510, epoch: 163, loss: 0.250261
global_step: 38511, epoch: 163, loss: 0.228345
global_step: 38512, epoch: 163, loss: 0.269429
global_step: 38513, epoch: 163, loss: 0.183850
global_step: 38514, epoch: 163, loss: 0.229045
global_step: 38515, epoch: 163, loss: 0.186942
global_step: 38516, epoch: 163, loss: 0.259425
global_step: 38517, epoch: 163, loss: 0.176593
global_step: 38518, epoch: 163, loss: 0.190211
global_step: 38519, epoch: 163, loss: 0.237753
global_step: 38520, epoch: 163, loss: 0.041850
epoch: 163
train	acc: 0.9700	macro: p 0.9742, r 0.9575, f1: 0.9655	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5149	macro: p 0.3619, r 0.2930, f1: 0.2948	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4709
test	acc: 0.5782	macro: p 0.3561, r 0.3083, f1: 0.3142	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5370
global_step: 38521, epoch: 164, loss: 0.157855
global_step: 38522, epoch: 164, loss: 0.139859
global_step: 38523, epoch: 164, loss: 0.152488
global_step: 38524, epoch: 164, loss: 0.192762
global_step: 38525, epoch: 164, loss: 0.161097
global_step: 38526, epoch: 164, loss: 0.163286
global_step: 38527, epoch: 164, loss: 0.153527
global_step: 38528, epoch: 164, loss: 0.208960
global_step: 38529, epoch: 164, loss: 0.232728
global_step: 38530, epoch: 164, loss: 0.243253
global_step: 38531, epoch: 164, loss: 0.191730
global_step: 38532, epoch: 164, loss: 0.147855
global_step: 38533, epoch: 164, loss: 0.235792
global_step: 38534, epoch: 164, loss: 0.223793
global_step: 38535, epoch: 164, loss: 0.194226
global_step: 38536, epoch: 164, loss: 0.242892
global_step: 38537, epoch: 164, loss: 0.204820
global_step: 38538, epoch: 164, loss: 0.188576
global_step: 38539, epoch: 164, loss: 0.184790
global_step: 38540, epoch: 164, loss: 0.219332
global_step: 38541, epoch: 164, loss: 0.154571
global_step: 38542, epoch: 164, loss: 0.178890
global_step: 38543, epoch: 164, loss: 0.177474
global_step: 38544, epoch: 164, loss: 0.276167
global_step: 38545, epoch: 164, loss: 0.224961
global_step: 38546, epoch: 164, loss: 0.202902
global_step: 38547, epoch: 164, loss: 0.214409
global_step: 38548, epoch: 164, loss: 0.214236
global_step: 38549, epoch: 164, loss: 0.217768
global_step: 38550, epoch: 164, loss: 0.140901
global_step: 38551, epoch: 164, loss: 0.197386
global_step: 38552, epoch: 164, loss: 0.158277
global_step: 38553, epoch: 164, loss: 0.257469
global_step: 38554, epoch: 164, loss: 0.284936
global_step: 38555, epoch: 164, loss: 0.213283
global_step: 38556, epoch: 164, loss: 0.207830
global_step: 38557, epoch: 164, loss: 0.225444
global_step: 38558, epoch: 164, loss: 0.215978
global_step: 38559, epoch: 164, loss: 0.279630
global_step: 38560, epoch: 164, loss: 0.021582
epoch: 164
train	acc: 0.9708	macro: p 0.9752, r 0.9593, f1: 0.9669	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5131	macro: p 0.3345, r 0.2889, f1: 0.2872	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4674
test	acc: 0.5747	macro: p 0.3502, r 0.3070, f1: 0.3144	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5340
global_step: 38561, epoch: 165, loss: 0.224775
global_step: 38562, epoch: 165, loss: 0.143339
global_step: 38563, epoch: 165, loss: 0.172395
global_step: 38564, epoch: 165, loss: 0.235903
global_step: 38565, epoch: 165, loss: 0.159090
global_step: 38566, epoch: 165, loss: 0.210697
global_step: 38567, epoch: 165, loss: 0.210051
global_step: 38568, epoch: 165, loss: 0.149332
global_step: 38569, epoch: 165, loss: 0.170791
global_step: 38570, epoch: 165, loss: 0.157974
global_step: 38571, epoch: 165, loss: 0.213719
global_step: 38572, epoch: 165, loss: 0.209774
global_step: 38573, epoch: 165, loss: 0.197954
global_step: 38574, epoch: 165, loss: 0.245599
global_step: 38575, epoch: 165, loss: 0.189447
global_step: 38576, epoch: 165, loss: 0.170449
global_step: 38577, epoch: 165, loss: 0.185318
global_step: 38578, epoch: 165, loss: 0.239945
global_step: 38579, epoch: 165, loss: 0.190735
global_step: 38580, epoch: 165, loss: 0.173445
global_step: 38581, epoch: 165, loss: 0.218962
global_step: 38582, epoch: 165, loss: 0.180076
global_step: 38583, epoch: 165, loss: 0.186931
global_step: 38584, epoch: 165, loss: 0.148120
global_step: 38585, epoch: 165, loss: 0.194075
global_step: 38586, epoch: 165, loss: 0.256523
global_step: 38587, epoch: 165, loss: 0.221901
global_step: 38588, epoch: 165, loss: 0.266502
global_step: 38589, epoch: 165, loss: 0.178434
global_step: 38590, epoch: 165, loss: 0.199209
global_step: 38591, epoch: 165, loss: 0.246917
global_step: 38592, epoch: 165, loss: 0.172038
global_step: 38593, epoch: 165, loss: 0.200049
global_step: 38594, epoch: 165, loss: 0.206406
global_step: 38595, epoch: 165, loss: 0.210487
global_step: 38596, epoch: 165, loss: 0.207461
global_step: 38597, epoch: 165, loss: 0.274500
global_step: 38598, epoch: 165, loss: 0.138323
global_step: 38599, epoch: 165, loss: 0.248910
global_step: 38600, epoch: 165, loss: 0.004763
epoch: 165
train	acc: 0.9708	macro: p 0.9750, r 0.9592, f1: 0.9668	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5059	macro: p 0.3319, r 0.2854, f1: 0.2828	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4629
test	acc: 0.5755	macro: p 0.3600, r 0.3081, f1: 0.3153	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5355
global_step: 38601, epoch: 166, loss: 0.209079
global_step: 38602, epoch: 166, loss: 0.182055
global_step: 38603, epoch: 166, loss: 0.224613
global_step: 38604, epoch: 166, loss: 0.227815
global_step: 38605, epoch: 166, loss: 0.230916
global_step: 38606, epoch: 166, loss: 0.158049
global_step: 38607, epoch: 166, loss: 0.174045
global_step: 38608, epoch: 166, loss: 0.173938
global_step: 38609, epoch: 166, loss: 0.166457
global_step: 38610, epoch: 166, loss: 0.206557
global_step: 38611, epoch: 166, loss: 0.206996
global_step: 38612, epoch: 166, loss: 0.133817
global_step: 38613, epoch: 166, loss: 0.237175
global_step: 38614, epoch: 166, loss: 0.194478
global_step: 38615, epoch: 166, loss: 0.161253
global_step: 38616, epoch: 166, loss: 0.272419
global_step: 38617, epoch: 166, loss: 0.227482
global_step: 38618, epoch: 166, loss: 0.239734
global_step: 38619, epoch: 166, loss: 0.221217
global_step: 38620, epoch: 166, loss: 0.182152
global_step: 38621, epoch: 166, loss: 0.207293
global_step: 38622, epoch: 166, loss: 0.188721
global_step: 38623, epoch: 166, loss: 0.147141
global_step: 38624, epoch: 166, loss: 0.213686
global_step: 38625, epoch: 166, loss: 0.203666
global_step: 38626, epoch: 166, loss: 0.164065
global_step: 38627, epoch: 166, loss: 0.293186
global_step: 38628, epoch: 166, loss: 0.231039
global_step: 38629, epoch: 166, loss: 0.205933
global_step: 38630, epoch: 166, loss: 0.159403
global_step: 38631, epoch: 166, loss: 0.181215
global_step: 38632, epoch: 166, loss: 0.243793
global_step: 38633, epoch: 166, loss: 0.225283
global_step: 38634, epoch: 166, loss: 0.205452
global_step: 38635, epoch: 166, loss: 0.219305
global_step: 38636, epoch: 166, loss: 0.274851
global_step: 38637, epoch: 166, loss: 0.202548
global_step: 38638, epoch: 166, loss: 0.197010
global_step: 38639, epoch: 166, loss: 0.148172
global_step: 38640, epoch: 166, loss: 0.458418
epoch: 166
train	acc: 0.9700	macro: p 0.9757, r 0.9577, f1: 0.9664	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5230	macro: p 0.3577, r 0.2884, f1: 0.2873	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4720
test	acc: 0.5828	macro: p 0.3647, r 0.3086, f1: 0.3184	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5396
global_step: 38641, epoch: 167, loss: 0.213351
global_step: 38642, epoch: 167, loss: 0.224676
global_step: 38643, epoch: 167, loss: 0.202680
global_step: 38644, epoch: 167, loss: 0.227309
global_step: 38645, epoch: 167, loss: 0.186930
global_step: 38646, epoch: 167, loss: 0.180076
global_step: 38647, epoch: 167, loss: 0.195979
global_step: 38648, epoch: 167, loss: 0.175309
global_step: 38649, epoch: 167, loss: 0.164185
global_step: 38650, epoch: 167, loss: 0.266985
global_step: 38651, epoch: 167, loss: 0.265986
global_step: 38652, epoch: 167, loss: 0.248065
global_step: 38653, epoch: 167, loss: 0.217387
global_step: 38654, epoch: 167, loss: 0.221308
global_step: 38655, epoch: 167, loss: 0.229542
global_step: 38656, epoch: 167, loss: 0.169419
global_step: 38657, epoch: 167, loss: 0.220794
global_step: 38658, epoch: 167, loss: 0.181670
global_step: 38659, epoch: 167, loss: 0.217315
global_step: 38660, epoch: 167, loss: 0.217390
global_step: 38661, epoch: 167, loss: 0.137339
global_step: 38662, epoch: 167, loss: 0.301545
global_step: 38663, epoch: 167, loss: 0.243559
global_step: 38664, epoch: 167, loss: 0.164749
global_step: 38665, epoch: 167, loss: 0.200714
global_step: 38666, epoch: 167, loss: 0.241550
global_step: 38667, epoch: 167, loss: 0.119906
global_step: 38668, epoch: 167, loss: 0.188844
global_step: 38669, epoch: 167, loss: 0.183047
global_step: 38670, epoch: 167, loss: 0.183746
global_step: 38671, epoch: 167, loss: 0.202639
global_step: 38672, epoch: 167, loss: 0.237021
global_step: 38673, epoch: 167, loss: 0.214209
global_step: 38674, epoch: 167, loss: 0.152786
global_step: 38675, epoch: 167, loss: 0.226252
global_step: 38676, epoch: 167, loss: 0.151005
global_step: 38677, epoch: 167, loss: 0.244186
global_step: 38678, epoch: 167, loss: 0.194907
global_step: 38679, epoch: 167, loss: 0.137714
global_step: 38680, epoch: 167, loss: 0.016753
epoch: 167
train	acc: 0.9710	macro: p 0.9752, r 0.9591, f1: 0.9668	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5167	macro: p 0.3325, r 0.2933, f1: 0.2940	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4755
test	acc: 0.5759	macro: p 0.3601, r 0.3105, f1: 0.3198	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5380
global_step: 38681, epoch: 168, loss: 0.192750
global_step: 38682, epoch: 168, loss: 0.219399
global_step: 38683, epoch: 168, loss: 0.193924
global_step: 38684, epoch: 168, loss: 0.251949
global_step: 38685, epoch: 168, loss: 0.193330
global_step: 38686, epoch: 168, loss: 0.195828
global_step: 38687, epoch: 168, loss: 0.175679
global_step: 38688, epoch: 168, loss: 0.169805
global_step: 38689, epoch: 168, loss: 0.201970
global_step: 38690, epoch: 168, loss: 0.197160
global_step: 38691, epoch: 168, loss: 0.213767
global_step: 38692, epoch: 168, loss: 0.257121
global_step: 38693, epoch: 168, loss: 0.291386
global_step: 38694, epoch: 168, loss: 0.200149
global_step: 38695, epoch: 168, loss: 0.203840
global_step: 38696, epoch: 168, loss: 0.267525
global_step: 38697, epoch: 168, loss: 0.268485
global_step: 38698, epoch: 168, loss: 0.224923
global_step: 38699, epoch: 168, loss: 0.185148
global_step: 38700, epoch: 168, loss: 0.205700
global_step: 38701, epoch: 168, loss: 0.096920
global_step: 38702, epoch: 168, loss: 0.211272
global_step: 38703, epoch: 168, loss: 0.185953
global_step: 38704, epoch: 168, loss: 0.214638
global_step: 38705, epoch: 168, loss: 0.300620
global_step: 38706, epoch: 168, loss: 0.168119
global_step: 38707, epoch: 168, loss: 0.251309
global_step: 38708, epoch: 168, loss: 0.198566
global_step: 38709, epoch: 168, loss: 0.217957
global_step: 38710, epoch: 168, loss: 0.154599
global_step: 38711, epoch: 168, loss: 0.261534
global_step: 38712, epoch: 168, loss: 0.136294
global_step: 38713, epoch: 168, loss: 0.183363
global_step: 38714, epoch: 168, loss: 0.170505
global_step: 38715, epoch: 168, loss: 0.184512
global_step: 38716, epoch: 168, loss: 0.190695
global_step: 38717, epoch: 168, loss: 0.185469
global_step: 38718, epoch: 168, loss: 0.243426
global_step: 38719, epoch: 168, loss: 0.218716
global_step: 38720, epoch: 168, loss: 0.098558
epoch: 168
train	acc: 0.9703	macro: p 0.9750, r 0.9575, f1: 0.9660	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5221	macro: p 0.3403, r 0.2958, f1: 0.2965	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4782
test	acc: 0.5812	macro: p 0.3529, r 0.3098, f1: 0.3159	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5391
global_step: 38721, epoch: 169, loss: 0.162720
global_step: 38722, epoch: 169, loss: 0.202488
global_step: 38723, epoch: 169, loss: 0.215594
global_step: 38724, epoch: 169, loss: 0.204559
global_step: 38725, epoch: 169, loss: 0.158555
global_step: 38726, epoch: 169, loss: 0.183393
global_step: 38727, epoch: 169, loss: 0.212256
global_step: 38728, epoch: 169, loss: 0.202625
global_step: 38729, epoch: 169, loss: 0.192364
global_step: 38730, epoch: 169, loss: 0.153259
global_step: 38731, epoch: 169, loss: 0.202367
global_step: 38732, epoch: 169, loss: 0.263923
global_step: 38733, epoch: 169, loss: 0.196685
global_step: 38734, epoch: 169, loss: 0.217161
global_step: 38735, epoch: 169, loss: 0.174616
global_step: 38736, epoch: 169, loss: 0.203515
global_step: 38737, epoch: 169, loss: 0.180231
global_step: 38738, epoch: 169, loss: 0.166009
global_step: 38739, epoch: 169, loss: 0.159745
global_step: 38740, epoch: 169, loss: 0.217194
global_step: 38741, epoch: 169, loss: 0.215362
global_step: 38742, epoch: 169, loss: 0.201136
global_step: 38743, epoch: 169, loss: 0.213796
global_step: 38744, epoch: 169, loss: 0.188741
global_step: 38745, epoch: 169, loss: 0.236223
global_step: 38746, epoch: 169, loss: 0.177082
global_step: 38747, epoch: 169, loss: 0.207950
global_step: 38748, epoch: 169, loss: 0.233567
global_step: 38749, epoch: 169, loss: 0.173484
global_step: 38750, epoch: 169, loss: 0.231003
global_step: 38751, epoch: 169, loss: 0.210312
global_step: 38752, epoch: 169, loss: 0.210716
global_step: 38753, epoch: 169, loss: 0.205596
global_step: 38754, epoch: 169, loss: 0.220495
global_step: 38755, epoch: 169, loss: 0.163640
global_step: 38756, epoch: 169, loss: 0.173593
global_step: 38757, epoch: 169, loss: 0.204224
global_step: 38758, epoch: 169, loss: 0.168435
global_step: 38759, epoch: 169, loss: 0.217967
global_step: 38760, epoch: 169, loss: 0.005321
epoch: 169
train	acc: 0.9708	macro: p 0.9742, r 0.9601, f1: 0.9669	micro: p 0.9708, r 0.9708, f1 0.9708	weighted_f1:0.9708
dev	acc: 0.5212	macro: p 0.3655, r 0.3013, f1: 0.3044	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4810
test	acc: 0.5747	macro: p 0.3579, r 0.3110, f1: 0.3190	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5370
global_step: 38761, epoch: 170, loss: 0.130369
global_step: 38762, epoch: 170, loss: 0.151546
global_step: 38763, epoch: 170, loss: 0.268175
global_step: 38764, epoch: 170, loss: 0.167186
global_step: 38765, epoch: 170, loss: 0.192740
global_step: 38766, epoch: 170, loss: 0.166963
global_step: 38767, epoch: 170, loss: 0.211630
global_step: 38768, epoch: 170, loss: 0.157270
global_step: 38769, epoch: 170, loss: 0.147440
global_step: 38770, epoch: 170, loss: 0.195925
global_step: 38771, epoch: 170, loss: 0.231887
global_step: 38772, epoch: 170, loss: 0.249863
global_step: 38773, epoch: 170, loss: 0.165954
global_step: 38774, epoch: 170, loss: 0.212052
global_step: 38775, epoch: 170, loss: 0.161863
global_step: 38776, epoch: 170, loss: 0.196600
global_step: 38777, epoch: 170, loss: 0.228870
global_step: 38778, epoch: 170, loss: 0.170100
global_step: 38779, epoch: 170, loss: 0.195902
global_step: 38780, epoch: 170, loss: 0.168411
global_step: 38781, epoch: 170, loss: 0.168958
global_step: 38782, epoch: 170, loss: 0.194309
global_step: 38783, epoch: 170, loss: 0.299304
global_step: 38784, epoch: 170, loss: 0.252471
global_step: 38785, epoch: 170, loss: 0.209393
global_step: 38786, epoch: 170, loss: 0.184155
global_step: 38787, epoch: 170, loss: 0.224216
global_step: 38788, epoch: 170, loss: 0.255571
global_step: 38789, epoch: 170, loss: 0.211588
global_step: 38790, epoch: 170, loss: 0.213537
global_step: 38791, epoch: 170, loss: 0.207538
global_step: 38792, epoch: 170, loss: 0.209482
global_step: 38793, epoch: 170, loss: 0.224793
global_step: 38794, epoch: 170, loss: 0.211834
global_step: 38795, epoch: 170, loss: 0.254845
global_step: 38796, epoch: 170, loss: 0.185843
global_step: 38797, epoch: 170, loss: 0.189192
global_step: 38798, epoch: 170, loss: 0.148922
global_step: 38799, epoch: 170, loss: 0.193423
global_step: 38800, epoch: 170, loss: 0.696023
epoch: 170
train	acc: 0.9707	macro: p 0.9743, r 0.9599, f1: 0.9668	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5230	macro: p 0.3488, r 0.3030, f1: 0.3040	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4854
test	acc: 0.5774	macro: p 0.3543, r 0.3146, f1: 0.3206	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5418
global_step: 38801, epoch: 171, loss: 0.151339
global_step: 38802, epoch: 171, loss: 0.221192
global_step: 38803, epoch: 171, loss: 0.174590
global_step: 38804, epoch: 171, loss: 0.187500
global_step: 38805, epoch: 171, loss: 0.212975
global_step: 38806, epoch: 171, loss: 0.222055
global_step: 38807, epoch: 171, loss: 0.195998
global_step: 38808, epoch: 171, loss: 0.191153
global_step: 38809, epoch: 171, loss: 0.205913
global_step: 38810, epoch: 171, loss: 0.189959
global_step: 38811, epoch: 171, loss: 0.213856
global_step: 38812, epoch: 171, loss: 0.240402
global_step: 38813, epoch: 171, loss: 0.223354
global_step: 38814, epoch: 171, loss: 0.284213
global_step: 38815, epoch: 171, loss: 0.167317
global_step: 38816, epoch: 171, loss: 0.231317
global_step: 38817, epoch: 171, loss: 0.174218
global_step: 38818, epoch: 171, loss: 0.176267
global_step: 38819, epoch: 171, loss: 0.196588
global_step: 38820, epoch: 171, loss: 0.206307
global_step: 38821, epoch: 171, loss: 0.251624
global_step: 38822, epoch: 171, loss: 0.215816
global_step: 38823, epoch: 171, loss: 0.165653
global_step: 38824, epoch: 171, loss: 0.179815
global_step: 38825, epoch: 171, loss: 0.218433
global_step: 38826, epoch: 171, loss: 0.126485
global_step: 38827, epoch: 171, loss: 0.194947
global_step: 38828, epoch: 171, loss: 0.195350
global_step: 38829, epoch: 171, loss: 0.254013
global_step: 38830, epoch: 171, loss: 0.285027
global_step: 38831, epoch: 171, loss: 0.208962
global_step: 38832, epoch: 171, loss: 0.236576
global_step: 38833, epoch: 171, loss: 0.250826
global_step: 38834, epoch: 171, loss: 0.213222
global_step: 38835, epoch: 171, loss: 0.213630
global_step: 38836, epoch: 171, loss: 0.213274
global_step: 38837, epoch: 171, loss: 0.171490
global_step: 38838, epoch: 171, loss: 0.212050
global_step: 38839, epoch: 171, loss: 0.157850
global_step: 38840, epoch: 171, loss: 0.123972
epoch: 171
train	acc: 0.9707	macro: p 0.9755, r 0.9591, f1: 0.9670	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5185	macro: p 0.3512, r 0.2913, f1: 0.2907	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4726
test	acc: 0.5816	macro: p 0.3616, r 0.3096, f1: 0.3156	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5385
global_step: 38841, epoch: 172, loss: 0.135746
global_step: 38842, epoch: 172, loss: 0.202547
global_step: 38843, epoch: 172, loss: 0.173305
global_step: 38844, epoch: 172, loss: 0.161597
global_step: 38845, epoch: 172, loss: 0.237491
global_step: 38846, epoch: 172, loss: 0.265271
global_step: 38847, epoch: 172, loss: 0.194083
global_step: 38848, epoch: 172, loss: 0.208881
global_step: 38849, epoch: 172, loss: 0.242169
global_step: 38850, epoch: 172, loss: 0.178309
global_step: 38851, epoch: 172, loss: 0.176056
global_step: 38852, epoch: 172, loss: 0.250884
global_step: 38853, epoch: 172, loss: 0.161372
global_step: 38854, epoch: 172, loss: 0.221431
global_step: 38855, epoch: 172, loss: 0.207999
global_step: 38856, epoch: 172, loss: 0.225443
global_step: 38857, epoch: 172, loss: 0.303840
global_step: 38858, epoch: 172, loss: 0.183290
global_step: 38859, epoch: 172, loss: 0.100531
global_step: 38860, epoch: 172, loss: 0.202005
global_step: 38861, epoch: 172, loss: 0.225794
global_step: 38862, epoch: 172, loss: 0.219197
global_step: 38863, epoch: 172, loss: 0.215241
global_step: 38864, epoch: 172, loss: 0.138881
global_step: 38865, epoch: 172, loss: 0.181309
global_step: 38866, epoch: 172, loss: 0.191387
global_step: 38867, epoch: 172, loss: 0.231304
global_step: 38868, epoch: 172, loss: 0.198254
global_step: 38869, epoch: 172, loss: 0.151410
global_step: 38870, epoch: 172, loss: 0.199448
global_step: 38871, epoch: 172, loss: 0.245787
global_step: 38872, epoch: 172, loss: 0.273305
global_step: 38873, epoch: 172, loss: 0.180074
global_step: 38874, epoch: 172, loss: 0.196936
global_step: 38875, epoch: 172, loss: 0.232561
global_step: 38876, epoch: 172, loss: 0.261710
global_step: 38877, epoch: 172, loss: 0.139823
global_step: 38878, epoch: 172, loss: 0.168131
global_step: 38879, epoch: 172, loss: 0.198131
global_step: 38880, epoch: 172, loss: 0.022704
epoch: 172
train	acc: 0.9715	macro: p 0.9758, r 0.9602, f1: 0.9677	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5185	macro: p 0.3449, r 0.2968, f1: 0.2988	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4778
test	acc: 0.5785	macro: p 0.3710, r 0.3161, f1: 0.3260	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5406
global_step: 38881, epoch: 173, loss: 0.165960
global_step: 38882, epoch: 173, loss: 0.186699
global_step: 38883, epoch: 173, loss: 0.177512
global_step: 38884, epoch: 173, loss: 0.245287
global_step: 38885, epoch: 173, loss: 0.160326
global_step: 38886, epoch: 173, loss: 0.229549
global_step: 38887, epoch: 173, loss: 0.225787
global_step: 38888, epoch: 173, loss: 0.199812
global_step: 38889, epoch: 173, loss: 0.141418
global_step: 38890, epoch: 173, loss: 0.147760
global_step: 38891, epoch: 173, loss: 0.175248
global_step: 38892, epoch: 173, loss: 0.147573
global_step: 38893, epoch: 173, loss: 0.189646
global_step: 38894, epoch: 173, loss: 0.169538
global_step: 38895, epoch: 173, loss: 0.187291
global_step: 38896, epoch: 173, loss: 0.161223
global_step: 38897, epoch: 173, loss: 0.170789
global_step: 38898, epoch: 173, loss: 0.188559
global_step: 38899, epoch: 173, loss: 0.203596
global_step: 38900, epoch: 173, loss: 0.220048
global_step: 38901, epoch: 173, loss: 0.172488
global_step: 38902, epoch: 173, loss: 0.256209
global_step: 38903, epoch: 173, loss: 0.163943
global_step: 38904, epoch: 173, loss: 0.257386
global_step: 38905, epoch: 173, loss: 0.175357
global_step: 38906, epoch: 173, loss: 0.208677
global_step: 38907, epoch: 173, loss: 0.210156
global_step: 38908, epoch: 173, loss: 0.107581
global_step: 38909, epoch: 173, loss: 0.201933
global_step: 38910, epoch: 173, loss: 0.206124
global_step: 38911, epoch: 173, loss: 0.207620
global_step: 38912, epoch: 173, loss: 0.189324
global_step: 38913, epoch: 173, loss: 0.215403
global_step: 38914, epoch: 173, loss: 0.210703
global_step: 38915, epoch: 173, loss: 0.165500
global_step: 38916, epoch: 173, loss: 0.226220
global_step: 38917, epoch: 173, loss: 0.178530
global_step: 38918, epoch: 173, loss: 0.207150
global_step: 38919, epoch: 173, loss: 0.239435
global_step: 38920, epoch: 173, loss: 0.058063
epoch: 173
train	acc: 0.9709	macro: p 0.9748, r 0.9609, f1: 0.9676	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5194	macro: p 0.3398, r 0.3010, f1: 0.3020	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4814
test	acc: 0.5789	macro: p 0.3716, r 0.3172, f1: 0.3266	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5439
global_step: 38921, epoch: 174, loss: 0.165515
global_step: 38922, epoch: 174, loss: 0.165132
global_step: 38923, epoch: 174, loss: 0.185888
global_step: 38924, epoch: 174, loss: 0.241089
global_step: 38925, epoch: 174, loss: 0.171945
global_step: 38926, epoch: 174, loss: 0.209559
global_step: 38927, epoch: 174, loss: 0.172883
global_step: 38928, epoch: 174, loss: 0.202567
global_step: 38929, epoch: 174, loss: 0.228699
global_step: 38930, epoch: 174, loss: 0.167808
global_step: 38931, epoch: 174, loss: 0.162147
global_step: 38932, epoch: 174, loss: 0.146803
global_step: 38933, epoch: 174, loss: 0.241772
global_step: 38934, epoch: 174, loss: 0.123811
global_step: 38935, epoch: 174, loss: 0.232046
global_step: 38936, epoch: 174, loss: 0.184215
global_step: 38937, epoch: 174, loss: 0.178425
global_step: 38938, epoch: 174, loss: 0.205327
global_step: 38939, epoch: 174, loss: 0.146239
global_step: 38940, epoch: 174, loss: 0.191341
global_step: 38941, epoch: 174, loss: 0.228368
global_step: 38942, epoch: 174, loss: 0.206993
global_step: 38943, epoch: 174, loss: 0.213740
global_step: 38944, epoch: 174, loss: 0.246522
global_step: 38945, epoch: 174, loss: 0.125588
global_step: 38946, epoch: 174, loss: 0.221798
global_step: 38947, epoch: 174, loss: 0.163790
global_step: 38948, epoch: 174, loss: 0.290285
global_step: 38949, epoch: 174, loss: 0.178160
global_step: 38950, epoch: 174, loss: 0.185857
global_step: 38951, epoch: 174, loss: 0.174049
global_step: 38952, epoch: 174, loss: 0.170885
global_step: 38953, epoch: 174, loss: 0.162986
global_step: 38954, epoch: 174, loss: 0.155108
global_step: 38955, epoch: 174, loss: 0.226981
global_step: 38956, epoch: 174, loss: 0.125262
global_step: 38957, epoch: 174, loss: 0.275723
global_step: 38958, epoch: 174, loss: 0.189931
global_step: 38959, epoch: 174, loss: 0.200764
global_step: 38960, epoch: 174, loss: 0.502513
epoch: 174
train	acc: 0.9709	macro: p 0.9759, r 0.9598, f1: 0.9675	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5185	macro: p 0.3374, r 0.3000, f1: 0.2992	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4804
test	acc: 0.5770	macro: p 0.3537, r 0.3149, f1: 0.3204	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5407
global_step: 38961, epoch: 175, loss: 0.218766
global_step: 38962, epoch: 175, loss: 0.177920
global_step: 38963, epoch: 175, loss: 0.209046
global_step: 38964, epoch: 175, loss: 0.131881
global_step: 38965, epoch: 175, loss: 0.195624
global_step: 38966, epoch: 175, loss: 0.130335
global_step: 38967, epoch: 175, loss: 0.179767
global_step: 38968, epoch: 175, loss: 0.151515
global_step: 38969, epoch: 175, loss: 0.235292
global_step: 38970, epoch: 175, loss: 0.183542
global_step: 38971, epoch: 175, loss: 0.142385
global_step: 38972, epoch: 175, loss: 0.155767
global_step: 38973, epoch: 175, loss: 0.135278
global_step: 38974, epoch: 175, loss: 0.220610
global_step: 38975, epoch: 175, loss: 0.204480
global_step: 38976, epoch: 175, loss: 0.244984
global_step: 38977, epoch: 175, loss: 0.195772
global_step: 38978, epoch: 175, loss: 0.137716
global_step: 38979, epoch: 175, loss: 0.243930
global_step: 38980, epoch: 175, loss: 0.145158
global_step: 38981, epoch: 175, loss: 0.195927
global_step: 38982, epoch: 175, loss: 0.179044
global_step: 38983, epoch: 175, loss: 0.182913
global_step: 38984, epoch: 175, loss: 0.170925
global_step: 38985, epoch: 175, loss: 0.199755
global_step: 38986, epoch: 175, loss: 0.182941
global_step: 38987, epoch: 175, loss: 0.247241
global_step: 38988, epoch: 175, loss: 0.225471
global_step: 38989, epoch: 175, loss: 0.192854
global_step: 38990, epoch: 175, loss: 0.230082
global_step: 38991, epoch: 175, loss: 0.173431
global_step: 38992, epoch: 175, loss: 0.221898
global_step: 38993, epoch: 175, loss: 0.143982
global_step: 38994, epoch: 175, loss: 0.220814
global_step: 38995, epoch: 175, loss: 0.240114
global_step: 38996, epoch: 175, loss: 0.130975
global_step: 38997, epoch: 175, loss: 0.219984
global_step: 38998, epoch: 175, loss: 0.265059
global_step: 38999, epoch: 175, loss: 0.218903
global_step: 39000, epoch: 175, loss: 0.014033
epoch: 175
train	acc: 0.9713	macro: p 0.9750, r 0.9608, f1: 0.9677	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5266	macro: p 0.3460, r 0.3021, f1: 0.3036	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4857
test	acc: 0.5801	macro: p 0.3741, r 0.3175, f1: 0.3281	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5446
global_step: 39001, epoch: 176, loss: 0.224740
global_step: 39002, epoch: 176, loss: 0.146538
global_step: 39003, epoch: 176, loss: 0.233026
global_step: 39004, epoch: 176, loss: 0.279164
global_step: 39005, epoch: 176, loss: 0.191453
global_step: 39006, epoch: 176, loss: 0.156195
global_step: 39007, epoch: 176, loss: 0.153535
global_step: 39008, epoch: 176, loss: 0.125718
global_step: 39009, epoch: 176, loss: 0.162127
global_step: 39010, epoch: 176, loss: 0.158686
global_step: 39011, epoch: 176, loss: 0.159790
global_step: 39012, epoch: 176, loss: 0.215214
global_step: 39013, epoch: 176, loss: 0.151766
global_step: 39014, epoch: 176, loss: 0.171630
global_step: 39015, epoch: 176, loss: 0.184166
global_step: 39016, epoch: 176, loss: 0.212315
global_step: 39017, epoch: 176, loss: 0.191916
global_step: 39018, epoch: 176, loss: 0.220424
global_step: 39019, epoch: 176, loss: 0.195220
global_step: 39020, epoch: 176, loss: 0.308511
global_step: 39021, epoch: 176, loss: 0.147076
global_step: 39022, epoch: 176, loss: 0.172442
global_step: 39023, epoch: 176, loss: 0.164246
global_step: 39024, epoch: 176, loss: 0.157029
global_step: 39025, epoch: 176, loss: 0.184631
global_step: 39026, epoch: 176, loss: 0.181418
global_step: 39027, epoch: 176, loss: 0.248655
global_step: 39028, epoch: 176, loss: 0.230642
global_step: 39029, epoch: 176, loss: 0.177596
global_step: 39030, epoch: 176, loss: 0.138689
global_step: 39031, epoch: 176, loss: 0.177154
global_step: 39032, epoch: 176, loss: 0.145165
global_step: 39033, epoch: 176, loss: 0.172306
global_step: 39034, epoch: 176, loss: 0.205271
global_step: 39035, epoch: 176, loss: 0.240768
global_step: 39036, epoch: 176, loss: 0.257881
global_step: 39037, epoch: 176, loss: 0.202380
global_step: 39038, epoch: 176, loss: 0.225393
global_step: 39039, epoch: 176, loss: 0.169944
global_step: 39040, epoch: 176, loss: 0.281197
epoch: 176
train	acc: 0.9716	macro: p 0.9749, r 0.9623, f1: 0.9684	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5104	macro: p 0.3352, r 0.2885, f1: 0.2906	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4683
test	acc: 0.5785	macro: p 0.3687, r 0.3074, f1: 0.3189	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5379
global_step: 39041, epoch: 177, loss: 0.127116
global_step: 39042, epoch: 177, loss: 0.163514
global_step: 39043, epoch: 177, loss: 0.168830
global_step: 39044, epoch: 177, loss: 0.232991
global_step: 39045, epoch: 177, loss: 0.177206
global_step: 39046, epoch: 177, loss: 0.151185
global_step: 39047, epoch: 177, loss: 0.188923
global_step: 39048, epoch: 177, loss: 0.182716
global_step: 39049, epoch: 177, loss: 0.193377
global_step: 39050, epoch: 177, loss: 0.205195
global_step: 39051, epoch: 177, loss: 0.205771
global_step: 39052, epoch: 177, loss: 0.171603
global_step: 39053, epoch: 177, loss: 0.242307
global_step: 39054, epoch: 177, loss: 0.245144
global_step: 39055, epoch: 177, loss: 0.185839
global_step: 39056, epoch: 177, loss: 0.167235
global_step: 39057, epoch: 177, loss: 0.172592
global_step: 39058, epoch: 177, loss: 0.222253
global_step: 39059, epoch: 177, loss: 0.172561
global_step: 39060, epoch: 177, loss: 0.181532
global_step: 39061, epoch: 177, loss: 0.203459
global_step: 39062, epoch: 177, loss: 0.170267
global_step: 39063, epoch: 177, loss: 0.167648
global_step: 39064, epoch: 177, loss: 0.142520
global_step: 39065, epoch: 177, loss: 0.223427
global_step: 39066, epoch: 177, loss: 0.153377
global_step: 39067, epoch: 177, loss: 0.130834
global_step: 39068, epoch: 177, loss: 0.171916
global_step: 39069, epoch: 177, loss: 0.240159
global_step: 39070, epoch: 177, loss: 0.198199
global_step: 39071, epoch: 177, loss: 0.157966
global_step: 39072, epoch: 177, loss: 0.150638
global_step: 39073, epoch: 177, loss: 0.220725
global_step: 39074, epoch: 177, loss: 0.186445
global_step: 39075, epoch: 177, loss: 0.205222
global_step: 39076, epoch: 177, loss: 0.225298
global_step: 39077, epoch: 177, loss: 0.160143
global_step: 39078, epoch: 177, loss: 0.188943
global_step: 39079, epoch: 177, loss: 0.235847
global_step: 39080, epoch: 177, loss: 0.520517
epoch: 177
train	acc: 0.9720	macro: p 0.9747, r 0.9629, f1: 0.9686	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5086	macro: p 0.3311, r 0.2972, f1: 0.2995	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4755
test	acc: 0.5751	macro: p 0.3692, r 0.3190, f1: 0.3279	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5421
global_step: 39081, epoch: 178, loss: 0.254024
global_step: 39082, epoch: 178, loss: 0.209556
global_step: 39083, epoch: 178, loss: 0.169246
global_step: 39084, epoch: 178, loss: 0.190703
global_step: 39085, epoch: 178, loss: 0.172049
global_step: 39086, epoch: 178, loss: 0.124179
global_step: 39087, epoch: 178, loss: 0.223717
global_step: 39088, epoch: 178, loss: 0.140128
global_step: 39089, epoch: 178, loss: 0.267977
global_step: 39090, epoch: 178, loss: 0.217125
global_step: 39091, epoch: 178, loss: 0.180913
global_step: 39092, epoch: 178, loss: 0.249642
global_step: 39093, epoch: 178, loss: 0.160252
global_step: 39094, epoch: 178, loss: 0.193546
global_step: 39095, epoch: 178, loss: 0.154763
global_step: 39096, epoch: 178, loss: 0.155443
global_step: 39097, epoch: 178, loss: 0.230069
global_step: 39098, epoch: 178, loss: 0.135678
global_step: 39099, epoch: 178, loss: 0.217267
global_step: 39100, epoch: 178, loss: 0.194585
global_step: 39101, epoch: 178, loss: 0.189179
global_step: 39102, epoch: 178, loss: 0.157759
global_step: 39103, epoch: 178, loss: 0.228674
global_step: 39104, epoch: 178, loss: 0.218797
global_step: 39105, epoch: 178, loss: 0.202751
global_step: 39106, epoch: 178, loss: 0.212211
global_step: 39107, epoch: 178, loss: 0.201096
global_step: 39108, epoch: 178, loss: 0.155915
global_step: 39109, epoch: 178, loss: 0.179778
global_step: 39110, epoch: 178, loss: 0.157201
global_step: 39111, epoch: 178, loss: 0.211115
global_step: 39112, epoch: 178, loss: 0.212944
global_step: 39113, epoch: 178, loss: 0.227704
global_step: 39114, epoch: 178, loss: 0.167635
global_step: 39115, epoch: 178, loss: 0.178328
global_step: 39116, epoch: 178, loss: 0.188633
global_step: 39117, epoch: 178, loss: 0.271100
global_step: 39118, epoch: 178, loss: 0.202954
global_step: 39119, epoch: 178, loss: 0.187250
global_step: 39120, epoch: 178, loss: 0.562416
epoch: 178
train	acc: 0.9713	macro: p 0.9751, r 0.9620, f1: 0.9684	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5203	macro: p 0.3387, r 0.2969, f1: 0.3017	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4803
test	acc: 0.5732	macro: p 0.3659, r 0.3074, f1: 0.3193	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5356
global_step: 39121, epoch: 179, loss: 0.135541
global_step: 39122, epoch: 179, loss: 0.164206
global_step: 39123, epoch: 179, loss: 0.216247
global_step: 39124, epoch: 179, loss: 0.254455
global_step: 39125, epoch: 179, loss: 0.186031
global_step: 39126, epoch: 179, loss: 0.163067
global_step: 39127, epoch: 179, loss: 0.206193
global_step: 39128, epoch: 179, loss: 0.203294
global_step: 39129, epoch: 179, loss: 0.166397
global_step: 39130, epoch: 179, loss: 0.159893
global_step: 39131, epoch: 179, loss: 0.196227
global_step: 39132, epoch: 179, loss: 0.184921
global_step: 39133, epoch: 179, loss: 0.249612
global_step: 39134, epoch: 179, loss: 0.245489
global_step: 39135, epoch: 179, loss: 0.193448
global_step: 39136, epoch: 179, loss: 0.198674
global_step: 39137, epoch: 179, loss: 0.162048
global_step: 39138, epoch: 179, loss: 0.169193
global_step: 39139, epoch: 179, loss: 0.196222
global_step: 39140, epoch: 179, loss: 0.166205
global_step: 39141, epoch: 179, loss: 0.181023
global_step: 39142, epoch: 179, loss: 0.192394
global_step: 39143, epoch: 179, loss: 0.211169
global_step: 39144, epoch: 179, loss: 0.229284
global_step: 39145, epoch: 179, loss: 0.182221
global_step: 39146, epoch: 179, loss: 0.142525
global_step: 39147, epoch: 179, loss: 0.214456
global_step: 39148, epoch: 179, loss: 0.268999
global_step: 39149, epoch: 179, loss: 0.265351
global_step: 39150, epoch: 179, loss: 0.171050
global_step: 39151, epoch: 179, loss: 0.184986
global_step: 39152, epoch: 179, loss: 0.158426
global_step: 39153, epoch: 179, loss: 0.131739
global_step: 39154, epoch: 179, loss: 0.272655
global_step: 39155, epoch: 179, loss: 0.170297
global_step: 39156, epoch: 179, loss: 0.173725
global_step: 39157, epoch: 179, loss: 0.203859
global_step: 39158, epoch: 179, loss: 0.264843
global_step: 39159, epoch: 179, loss: 0.191855
global_step: 39160, epoch: 179, loss: 1.858035
epoch: 179
train	acc: 0.9720	macro: p 0.9755, r 0.9631, f1: 0.9691	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5158	macro: p 0.3302, r 0.2910, f1: 0.2914	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4723
test	acc: 0.5778	macro: p 0.3628, r 0.3119, f1: 0.3217	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5381
global_step: 39161, epoch: 180, loss: 0.238009
global_step: 39162, epoch: 180, loss: 0.211783
global_step: 39163, epoch: 180, loss: 0.279545
global_step: 39164, epoch: 180, loss: 0.176092
global_step: 39165, epoch: 180, loss: 0.165856
global_step: 39166, epoch: 180, loss: 0.153298
global_step: 39167, epoch: 180, loss: 0.168690
global_step: 39168, epoch: 180, loss: 0.210195
global_step: 39169, epoch: 180, loss: 0.170371
global_step: 39170, epoch: 180, loss: 0.163878
global_step: 39171, epoch: 180, loss: 0.192581
global_step: 39172, epoch: 180, loss: 0.170784
global_step: 39173, epoch: 180, loss: 0.232396
global_step: 39174, epoch: 180, loss: 0.191059
global_step: 39175, epoch: 180, loss: 0.149328
global_step: 39176, epoch: 180, loss: 0.142369
global_step: 39177, epoch: 180, loss: 0.192887
global_step: 39178, epoch: 180, loss: 0.161047
global_step: 39179, epoch: 180, loss: 0.156411
global_step: 39180, epoch: 180, loss: 0.163561
global_step: 39181, epoch: 180, loss: 0.204976
global_step: 39182, epoch: 180, loss: 0.161771
global_step: 39183, epoch: 180, loss: 0.184223
global_step: 39184, epoch: 180, loss: 0.126028
global_step: 39185, epoch: 180, loss: 0.200803
global_step: 39186, epoch: 180, loss: 0.186321
global_step: 39187, epoch: 180, loss: 0.243323
global_step: 39188, epoch: 180, loss: 0.233645
global_step: 39189, epoch: 180, loss: 0.205801
global_step: 39190, epoch: 180, loss: 0.157470
global_step: 39191, epoch: 180, loss: 0.209275
global_step: 39192, epoch: 180, loss: 0.173518
global_step: 39193, epoch: 180, loss: 0.187480
global_step: 39194, epoch: 180, loss: 0.127467
global_step: 39195, epoch: 180, loss: 0.148897
global_step: 39196, epoch: 180, loss: 0.181129
global_step: 39197, epoch: 180, loss: 0.183776
global_step: 39198, epoch: 180, loss: 0.176112
global_step: 39199, epoch: 180, loss: 0.194956
global_step: 39200, epoch: 180, loss: 0.818495
epoch: 180
train	acc: 0.9719	macro: p 0.9748, r 0.9628, f1: 0.9686	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5185	macro: p 0.3357, r 0.2971, f1: 0.2978	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4773
test	acc: 0.5736	macro: p 0.3560, r 0.3069, f1: 0.3154	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5353
global_step: 39201, epoch: 181, loss: 0.180013
global_step: 39202, epoch: 181, loss: 0.138788
global_step: 39203, epoch: 181, loss: 0.174737
global_step: 39204, epoch: 181, loss: 0.258706
global_step: 39205, epoch: 181, loss: 0.147074
global_step: 39206, epoch: 181, loss: 0.222693
global_step: 39207, epoch: 181, loss: 0.135546
global_step: 39208, epoch: 181, loss: 0.153488
global_step: 39209, epoch: 181, loss: 0.227864
global_step: 39210, epoch: 181, loss: 0.166149
global_step: 39211, epoch: 181, loss: 0.217358
global_step: 39212, epoch: 181, loss: 0.149099
global_step: 39213, epoch: 181, loss: 0.190399
global_step: 39214, epoch: 181, loss: 0.157436
global_step: 39215, epoch: 181, loss: 0.170624
global_step: 39216, epoch: 181, loss: 0.214606
global_step: 39217, epoch: 181, loss: 0.249110
global_step: 39218, epoch: 181, loss: 0.168895
global_step: 39219, epoch: 181, loss: 0.186693
global_step: 39220, epoch: 181, loss: 0.182969
global_step: 39221, epoch: 181, loss: 0.123647
global_step: 39222, epoch: 181, loss: 0.178855
global_step: 39223, epoch: 181, loss: 0.171188
global_step: 39224, epoch: 181, loss: 0.143954
global_step: 39225, epoch: 181, loss: 0.184194
global_step: 39226, epoch: 181, loss: 0.191378
global_step: 39227, epoch: 181, loss: 0.204357
global_step: 39228, epoch: 181, loss: 0.189109
global_step: 39229, epoch: 181, loss: 0.177912
global_step: 39230, epoch: 181, loss: 0.218513
global_step: 39231, epoch: 181, loss: 0.168135
global_step: 39232, epoch: 181, loss: 0.213370
global_step: 39233, epoch: 181, loss: 0.239676
global_step: 39234, epoch: 181, loss: 0.146950
global_step: 39235, epoch: 181, loss: 0.185457
global_step: 39236, epoch: 181, loss: 0.213674
global_step: 39237, epoch: 181, loss: 0.207830
global_step: 39238, epoch: 181, loss: 0.195138
global_step: 39239, epoch: 181, loss: 0.186617
global_step: 39240, epoch: 181, loss: 0.025454
epoch: 181
train	acc: 0.9720	macro: p 0.9757, r 0.9630, f1: 0.9691	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5212	macro: p 0.3402, r 0.3029, f1: 0.3047	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4851
test	acc: 0.5778	macro: p 0.3662, r 0.3148, f1: 0.3247	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5419
global_step: 39241, epoch: 182, loss: 0.192542
global_step: 39242, epoch: 182, loss: 0.212807
global_step: 39243, epoch: 182, loss: 0.193637
global_step: 39244, epoch: 182, loss: 0.178522
global_step: 39245, epoch: 182, loss: 0.215341
global_step: 39246, epoch: 182, loss: 0.198266
global_step: 39247, epoch: 182, loss: 0.163776
global_step: 39248, epoch: 182, loss: 0.169227
global_step: 39249, epoch: 182, loss: 0.160951
global_step: 39250, epoch: 182, loss: 0.157278
global_step: 39251, epoch: 182, loss: 0.110804
global_step: 39252, epoch: 182, loss: 0.129764
global_step: 39253, epoch: 182, loss: 0.146023
global_step: 39254, epoch: 182, loss: 0.231918
global_step: 39255, epoch: 182, loss: 0.238783
global_step: 39256, epoch: 182, loss: 0.199870
global_step: 39257, epoch: 182, loss: 0.173515
global_step: 39258, epoch: 182, loss: 0.212442
global_step: 39259, epoch: 182, loss: 0.168791
global_step: 39260, epoch: 182, loss: 0.174063
global_step: 39261, epoch: 182, loss: 0.228335
global_step: 39262, epoch: 182, loss: 0.179681
global_step: 39263, epoch: 182, loss: 0.189168
global_step: 39264, epoch: 182, loss: 0.203794
global_step: 39265, epoch: 182, loss: 0.187995
global_step: 39266, epoch: 182, loss: 0.158802
global_step: 39267, epoch: 182, loss: 0.230020
global_step: 39268, epoch: 182, loss: 0.201512
global_step: 39269, epoch: 182, loss: 0.194756
global_step: 39270, epoch: 182, loss: 0.192418
global_step: 39271, epoch: 182, loss: 0.186177
global_step: 39272, epoch: 182, loss: 0.185858
global_step: 39273, epoch: 182, loss: 0.228560
global_step: 39274, epoch: 182, loss: 0.233154
global_step: 39275, epoch: 182, loss: 0.142813
global_step: 39276, epoch: 182, loss: 0.159777
global_step: 39277, epoch: 182, loss: 0.166278
global_step: 39278, epoch: 182, loss: 0.139581
global_step: 39279, epoch: 182, loss: 0.194976
global_step: 39280, epoch: 182, loss: 0.064295
epoch: 182
train	acc: 0.9720	macro: p 0.9757, r 0.9623, f1: 0.9688	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5113	macro: p 0.3288, r 0.2939, f1: 0.2918	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4719
test	acc: 0.5770	macro: p 0.3725, r 0.3147, f1: 0.3233	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5401
global_step: 39281, epoch: 183, loss: 0.214416
global_step: 39282, epoch: 183, loss: 0.140676
global_step: 39283, epoch: 183, loss: 0.180092
global_step: 39284, epoch: 183, loss: 0.196363
global_step: 39285, epoch: 183, loss: 0.122213
global_step: 39286, epoch: 183, loss: 0.182299
global_step: 39287, epoch: 183, loss: 0.184836
global_step: 39288, epoch: 183, loss: 0.250090
global_step: 39289, epoch: 183, loss: 0.213832
global_step: 39290, epoch: 183, loss: 0.190830
global_step: 39291, epoch: 183, loss: 0.155010
global_step: 39292, epoch: 183, loss: 0.255647
global_step: 39293, epoch: 183, loss: 0.168616
global_step: 39294, epoch: 183, loss: 0.148165
global_step: 39295, epoch: 183, loss: 0.161912
global_step: 39296, epoch: 183, loss: 0.188682
global_step: 39297, epoch: 183, loss: 0.213578
global_step: 39298, epoch: 183, loss: 0.186251
global_step: 39299, epoch: 183, loss: 0.207825
global_step: 39300, epoch: 183, loss: 0.252868
global_step: 39301, epoch: 183, loss: 0.247330
global_step: 39302, epoch: 183, loss: 0.243008
global_step: 39303, epoch: 183, loss: 0.215339
global_step: 39304, epoch: 183, loss: 0.181280
global_step: 39305, epoch: 183, loss: 0.221110
global_step: 39306, epoch: 183, loss: 0.157323
global_step: 39307, epoch: 183, loss: 0.142985
global_step: 39308, epoch: 183, loss: 0.194994
global_step: 39309, epoch: 183, loss: 0.156392
global_step: 39310, epoch: 183, loss: 0.240565
global_step: 39311, epoch: 183, loss: 0.201140
global_step: 39312, epoch: 183, loss: 0.129994
global_step: 39313, epoch: 183, loss: 0.158799
global_step: 39314, epoch: 183, loss: 0.201259
global_step: 39315, epoch: 183, loss: 0.208810
global_step: 39316, epoch: 183, loss: 0.156530
global_step: 39317, epoch: 183, loss: 0.165065
global_step: 39318, epoch: 183, loss: 0.164863
global_step: 39319, epoch: 183, loss: 0.190793
global_step: 39320, epoch: 183, loss: 0.645016
epoch: 183
train	acc: 0.9725	macro: p 0.9756, r 0.9639, f1: 0.9695	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5131	macro: p 0.3253, r 0.2970, f1: 0.2965	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4753
test	acc: 0.5686	macro: p 0.3525, r 0.3056, f1: 0.3127	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5303
global_step: 39321, epoch: 184, loss: 0.181269
global_step: 39322, epoch: 184, loss: 0.200334
global_step: 39323, epoch: 184, loss: 0.156892
global_step: 39324, epoch: 184, loss: 0.271672
global_step: 39325, epoch: 184, loss: 0.194779
global_step: 39326, epoch: 184, loss: 0.210236
global_step: 39327, epoch: 184, loss: 0.242112
global_step: 39328, epoch: 184, loss: 0.100860
global_step: 39329, epoch: 184, loss: 0.177512
global_step: 39330, epoch: 184, loss: 0.194805
global_step: 39331, epoch: 184, loss: 0.140964
global_step: 39332, epoch: 184, loss: 0.104357
global_step: 39333, epoch: 184, loss: 0.203136
global_step: 39334, epoch: 184, loss: 0.180791
global_step: 39335, epoch: 184, loss: 0.178854
global_step: 39336, epoch: 184, loss: 0.216357
global_step: 39337, epoch: 184, loss: 0.171562
global_step: 39338, epoch: 184, loss: 0.215021
global_step: 39339, epoch: 184, loss: 0.192652
global_step: 39340, epoch: 184, loss: 0.140442
global_step: 39341, epoch: 184, loss: 0.151050
global_step: 39342, epoch: 184, loss: 0.200937
global_step: 39343, epoch: 184, loss: 0.121106
global_step: 39344, epoch: 184, loss: 0.221785
global_step: 39345, epoch: 184, loss: 0.211391
global_step: 39346, epoch: 184, loss: 0.145836
global_step: 39347, epoch: 184, loss: 0.200116
global_step: 39348, epoch: 184, loss: 0.159101
global_step: 39349, epoch: 184, loss: 0.160897
global_step: 39350, epoch: 184, loss: 0.172786
global_step: 39351, epoch: 184, loss: 0.222282
global_step: 39352, epoch: 184, loss: 0.195273
global_step: 39353, epoch: 184, loss: 0.176987
global_step: 39354, epoch: 184, loss: 0.283510
global_step: 39355, epoch: 184, loss: 0.256805
global_step: 39356, epoch: 184, loss: 0.138998
global_step: 39357, epoch: 184, loss: 0.212932
global_step: 39358, epoch: 184, loss: 0.230728
global_step: 39359, epoch: 184, loss: 0.288665
global_step: 39360, epoch: 184, loss: 0.083251
epoch: 184
train	acc: 0.9719	macro: p 0.9755, r 0.9626, f1: 0.9688	micro: p 0.9719, r 0.9719, f1 0.9719	weighted_f1:0.9719
dev	acc: 0.5167	macro: p 0.3430, r 0.2972, f1: 0.2966	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4754
test	acc: 0.5732	macro: p 0.3555, r 0.3090, f1: 0.3158	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5333
global_step: 39361, epoch: 185, loss: 0.131830
global_step: 39362, epoch: 185, loss: 0.139526
global_step: 39363, epoch: 185, loss: 0.181427
global_step: 39364, epoch: 185, loss: 0.150091
global_step: 39365, epoch: 185, loss: 0.175187
global_step: 39366, epoch: 185, loss: 0.189013
global_step: 39367, epoch: 185, loss: 0.218966
global_step: 39368, epoch: 185, loss: 0.202949
global_step: 39369, epoch: 185, loss: 0.178679
global_step: 39370, epoch: 185, loss: 0.153219
global_step: 39371, epoch: 185, loss: 0.158077
global_step: 39372, epoch: 185, loss: 0.191975
global_step: 39373, epoch: 185, loss: 0.236410
global_step: 39374, epoch: 185, loss: 0.209345
global_step: 39375, epoch: 185, loss: 0.240226
global_step: 39376, epoch: 185, loss: 0.241103
global_step: 39377, epoch: 185, loss: 0.152686
global_step: 39378, epoch: 185, loss: 0.200695
global_step: 39379, epoch: 185, loss: 0.181250
global_step: 39380, epoch: 185, loss: 0.181750
global_step: 39381, epoch: 185, loss: 0.172225
global_step: 39382, epoch: 185, loss: 0.181910
global_step: 39383, epoch: 185, loss: 0.168378
global_step: 39384, epoch: 185, loss: 0.218809
global_step: 39385, epoch: 185, loss: 0.204472
global_step: 39386, epoch: 185, loss: 0.149934
global_step: 39387, epoch: 185, loss: 0.207711
global_step: 39388, epoch: 185, loss: 0.183565
global_step: 39389, epoch: 185, loss: 0.138786
global_step: 39390, epoch: 185, loss: 0.125748
global_step: 39391, epoch: 185, loss: 0.209029
global_step: 39392, epoch: 185, loss: 0.129682
global_step: 39393, epoch: 185, loss: 0.188891
global_step: 39394, epoch: 185, loss: 0.200102
global_step: 39395, epoch: 185, loss: 0.149424
global_step: 39396, epoch: 185, loss: 0.204998
global_step: 39397, epoch: 185, loss: 0.144274
global_step: 39398, epoch: 185, loss: 0.205824
global_step: 39399, epoch: 185, loss: 0.229978
global_step: 39400, epoch: 185, loss: 0.235208
epoch: 185
train	acc: 0.9720	macro: p 0.9759, r 0.9622, f1: 0.9689	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5185	macro: p 0.3376, r 0.2927, f1: 0.2930	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4739
test	acc: 0.5785	macro: p 0.3660, r 0.3079, f1: 0.3180	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5387
global_step: 39401, epoch: 186, loss: 0.176472
global_step: 39402, epoch: 186, loss: 0.205844
global_step: 39403, epoch: 186, loss: 0.149613
global_step: 39404, epoch: 186, loss: 0.176690
global_step: 39405, epoch: 186, loss: 0.193742
global_step: 39406, epoch: 186, loss: 0.169348
global_step: 39407, epoch: 186, loss: 0.173621
global_step: 39408, epoch: 186, loss: 0.194009
global_step: 39409, epoch: 186, loss: 0.142753
global_step: 39410, epoch: 186, loss: 0.161877
global_step: 39411, epoch: 186, loss: 0.267693
global_step: 39412, epoch: 186, loss: 0.237479
global_step: 39413, epoch: 186, loss: 0.120742
global_step: 39414, epoch: 186, loss: 0.244011
global_step: 39415, epoch: 186, loss: 0.193780
global_step: 39416, epoch: 186, loss: 0.123614
global_step: 39417, epoch: 186, loss: 0.164396
global_step: 39418, epoch: 186, loss: 0.211915
global_step: 39419, epoch: 186, loss: 0.228250
global_step: 39420, epoch: 186, loss: 0.139717
global_step: 39421, epoch: 186, loss: 0.188242
global_step: 39422, epoch: 186, loss: 0.181403
global_step: 39423, epoch: 186, loss: 0.179431
global_step: 39424, epoch: 186, loss: 0.169910
global_step: 39425, epoch: 186, loss: 0.236154
global_step: 39426, epoch: 186, loss: 0.296198
global_step: 39427, epoch: 186, loss: 0.255114
global_step: 39428, epoch: 186, loss: 0.222593
global_step: 39429, epoch: 186, loss: 0.183815
global_step: 39430, epoch: 186, loss: 0.156397
global_step: 39431, epoch: 186, loss: 0.200606
global_step: 39432, epoch: 186, loss: 0.233253
global_step: 39433, epoch: 186, loss: 0.217801
global_step: 39434, epoch: 186, loss: 0.198353
global_step: 39435, epoch: 186, loss: 0.226196
global_step: 39436, epoch: 186, loss: 0.161114
global_step: 39437, epoch: 186, loss: 0.164481
global_step: 39438, epoch: 186, loss: 0.185665
global_step: 39439, epoch: 186, loss: 0.186079
global_step: 39440, epoch: 186, loss: 0.020962
epoch: 186
train	acc: 0.9725	macro: p 0.9765, r 0.9630, f1: 0.9695	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5176	macro: p 0.3325, r 0.2931, f1: 0.2931	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4750
test	acc: 0.5778	macro: p 0.3534, r 0.3078, f1: 0.3158	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5374
global_step: 39441, epoch: 187, loss: 0.237756
global_step: 39442, epoch: 187, loss: 0.168473
global_step: 39443, epoch: 187, loss: 0.152642
global_step: 39444, epoch: 187, loss: 0.118753
global_step: 39445, epoch: 187, loss: 0.168720
global_step: 39446, epoch: 187, loss: 0.220665
global_step: 39447, epoch: 187, loss: 0.179822
global_step: 39448, epoch: 187, loss: 0.122807
global_step: 39449, epoch: 187, loss: 0.157765
global_step: 39450, epoch: 187, loss: 0.162332
global_step: 39451, epoch: 187, loss: 0.201789
global_step: 39452, epoch: 187, loss: 0.163534
global_step: 39453, epoch: 187, loss: 0.169149
global_step: 39454, epoch: 187, loss: 0.226408
global_step: 39455, epoch: 187, loss: 0.202769
global_step: 39456, epoch: 187, loss: 0.190775
global_step: 39457, epoch: 187, loss: 0.191783
global_step: 39458, epoch: 187, loss: 0.186772
global_step: 39459, epoch: 187, loss: 0.168169
global_step: 39460, epoch: 187, loss: 0.175314
global_step: 39461, epoch: 187, loss: 0.218346
global_step: 39462, epoch: 187, loss: 0.150734
global_step: 39463, epoch: 187, loss: 0.171322
global_step: 39464, epoch: 187, loss: 0.198276
global_step: 39465, epoch: 187, loss: 0.153534
global_step: 39466, epoch: 187, loss: 0.157629
global_step: 39467, epoch: 187, loss: 0.244945
global_step: 39468, epoch: 187, loss: 0.270434
global_step: 39469, epoch: 187, loss: 0.188058
global_step: 39470, epoch: 187, loss: 0.256007
global_step: 39471, epoch: 187, loss: 0.195351
global_step: 39472, epoch: 187, loss: 0.198367
global_step: 39473, epoch: 187, loss: 0.157958
global_step: 39474, epoch: 187, loss: 0.185367
global_step: 39475, epoch: 187, loss: 0.202513
global_step: 39476, epoch: 187, loss: 0.185449
global_step: 39477, epoch: 187, loss: 0.201079
global_step: 39478, epoch: 187, loss: 0.164683
global_step: 39479, epoch: 187, loss: 0.179236
global_step: 39480, epoch: 187, loss: 0.012833
epoch: 187
train	acc: 0.9726	macro: p 0.9769, r 0.9626, f1: 0.9695	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5185	macro: p 0.3354, r 0.2977, f1: 0.2980	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4789
test	acc: 0.5724	macro: p 0.3393, r 0.3053, f1: 0.3106	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5338
global_step: 39481, epoch: 188, loss: 0.169460
global_step: 39482, epoch: 188, loss: 0.238085
global_step: 39483, epoch: 188, loss: 0.126434
global_step: 39484, epoch: 188, loss: 0.191148
global_step: 39485, epoch: 188, loss: 0.227587
global_step: 39486, epoch: 188, loss: 0.248613
global_step: 39487, epoch: 188, loss: 0.191431
global_step: 39488, epoch: 188, loss: 0.156044
global_step: 39489, epoch: 188, loss: 0.203074
global_step: 39490, epoch: 188, loss: 0.124163
global_step: 39491, epoch: 188, loss: 0.183232
global_step: 39492, epoch: 188, loss: 0.208519
global_step: 39493, epoch: 188, loss: 0.168095
global_step: 39494, epoch: 188, loss: 0.222038
global_step: 39495, epoch: 188, loss: 0.159860
global_step: 39496, epoch: 188, loss: 0.152585
global_step: 39497, epoch: 188, loss: 0.187464
global_step: 39498, epoch: 188, loss: 0.201966
global_step: 39499, epoch: 188, loss: 0.124787
global_step: 39500, epoch: 188, loss: 0.201311
global_step: 39501, epoch: 188, loss: 0.184250
global_step: 39502, epoch: 188, loss: 0.188526
global_step: 39503, epoch: 188, loss: 0.152504
global_step: 39504, epoch: 188, loss: 0.243323
global_step: 39505, epoch: 188, loss: 0.144792
global_step: 39506, epoch: 188, loss: 0.140344
global_step: 39507, epoch: 188, loss: 0.192738
global_step: 39508, epoch: 188, loss: 0.137856
global_step: 39509, epoch: 188, loss: 0.196491
global_step: 39510, epoch: 188, loss: 0.175959
global_step: 39511, epoch: 188, loss: 0.198444
global_step: 39512, epoch: 188, loss: 0.146886
global_step: 39513, epoch: 188, loss: 0.251821
global_step: 39514, epoch: 188, loss: 0.169195
global_step: 39515, epoch: 188, loss: 0.135668
global_step: 39516, epoch: 188, loss: 0.187127
global_step: 39517, epoch: 188, loss: 0.117221
global_step: 39518, epoch: 188, loss: 0.243391
global_step: 39519, epoch: 188, loss: 0.246139
global_step: 39520, epoch: 188, loss: 0.008231
epoch: 188
train	acc: 0.9722	macro: p 0.9760, r 0.9636, f1: 0.9696	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5185	macro: p 0.3378, r 0.2989, f1: 0.2988	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4786
test	acc: 0.5812	macro: p 0.3776, r 0.3181, f1: 0.3276	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5417
global_step: 39521, epoch: 189, loss: 0.164568
global_step: 39522, epoch: 189, loss: 0.176536
global_step: 39523, epoch: 189, loss: 0.210424
global_step: 39524, epoch: 189, loss: 0.146865
global_step: 39525, epoch: 189, loss: 0.197977
global_step: 39526, epoch: 189, loss: 0.167022
global_step: 39527, epoch: 189, loss: 0.187879
global_step: 39528, epoch: 189, loss: 0.186637
global_step: 39529, epoch: 189, loss: 0.156976
global_step: 39530, epoch: 189, loss: 0.185464
global_step: 39531, epoch: 189, loss: 0.140703
global_step: 39532, epoch: 189, loss: 0.186918
global_step: 39533, epoch: 189, loss: 0.170537
global_step: 39534, epoch: 189, loss: 0.181156
global_step: 39535, epoch: 189, loss: 0.212803
global_step: 39536, epoch: 189, loss: 0.169870
global_step: 39537, epoch: 189, loss: 0.215209
global_step: 39538, epoch: 189, loss: 0.206823
global_step: 39539, epoch: 189, loss: 0.198234
global_step: 39540, epoch: 189, loss: 0.185134
global_step: 39541, epoch: 189, loss: 0.173825
global_step: 39542, epoch: 189, loss: 0.161139
global_step: 39543, epoch: 189, loss: 0.144098
global_step: 39544, epoch: 189, loss: 0.150004
global_step: 39545, epoch: 189, loss: 0.202277
global_step: 39546, epoch: 189, loss: 0.221655
global_step: 39547, epoch: 189, loss: 0.178279
global_step: 39548, epoch: 189, loss: 0.135783
global_step: 39549, epoch: 189, loss: 0.211749
global_step: 39550, epoch: 189, loss: 0.220270
global_step: 39551, epoch: 189, loss: 0.155835
global_step: 39552, epoch: 189, loss: 0.175683
global_step: 39553, epoch: 189, loss: 0.179742
global_step: 39554, epoch: 189, loss: 0.236014
global_step: 39555, epoch: 189, loss: 0.185779
global_step: 39556, epoch: 189, loss: 0.259233
global_step: 39557, epoch: 189, loss: 0.177028
global_step: 39558, epoch: 189, loss: 0.147093
global_step: 39559, epoch: 189, loss: 0.184144
global_step: 39560, epoch: 189, loss: 0.022275
epoch: 189
train	acc: 0.9720	macro: p 0.9753, r 0.9632, f1: 0.9690	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5131	macro: p 0.3245, r 0.2916, f1: 0.2892	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4708
test	acc: 0.5847	macro: p 0.3761, r 0.3218, f1: 0.3303	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5468
global_step: 39561, epoch: 190, loss: 0.243984
global_step: 39562, epoch: 190, loss: 0.202756
global_step: 39563, epoch: 190, loss: 0.160900
global_step: 39564, epoch: 190, loss: 0.151869
global_step: 39565, epoch: 190, loss: 0.132221
global_step: 39566, epoch: 190, loss: 0.232225
global_step: 39567, epoch: 190, loss: 0.115766
global_step: 39568, epoch: 190, loss: 0.147857
global_step: 39569, epoch: 190, loss: 0.193762
global_step: 39570, epoch: 190, loss: 0.134947
global_step: 39571, epoch: 190, loss: 0.224025
global_step: 39572, epoch: 190, loss: 0.259054
global_step: 39573, epoch: 190, loss: 0.151134
global_step: 39574, epoch: 190, loss: 0.134111
global_step: 39575, epoch: 190, loss: 0.204190
global_step: 39576, epoch: 190, loss: 0.186453
global_step: 39577, epoch: 190, loss: 0.240861
global_step: 39578, epoch: 190, loss: 0.136648
global_step: 39579, epoch: 190, loss: 0.257125
global_step: 39580, epoch: 190, loss: 0.193850
global_step: 39581, epoch: 190, loss: 0.164083run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

global_step: 39582, epoch: 190, loss: 0.137042
global_step: 39583, epoch: 190, loss: 0.175863
global_step: 39584, epoch: 190, loss: 0.202797
global_step: 39585, epoch: 190, loss: 0.262740
global_step: 39586, epoch: 190, loss: 0.223320
global_step: 39587, epoch: 190, loss: 0.216721
global_step: 39588, epoch: 190, loss: 0.217813
global_step: 39589, epoch: 190, loss: 0.153650
global_step: 39590, epoch: 190, loss: 0.141764
global_step: 39591, epoch: 190, loss: 0.122519
global_step: 39592, epoch: 190, loss: 0.179836
global_step: 39593, epoch: 190, loss: 0.182420
global_step: 39594, epoch: 190, loss: 0.225979
global_step: 39595, epoch: 190, loss: 0.250035
global_step: 39596, epoch: 190, loss: 0.206166
global_step: 39597, epoch: 190, loss: 0.161346
global_step: 39598, epoch: 190, loss: 0.180931
global_step: 39599, epoch: 190, loss: 0.249601
global_step: 39600, epoch: 190, loss: 0.005813
epoch: 190
train	acc: 0.9721	macro: p 0.9756, r 0.9620, f1: 0.9685	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5176	macro: p 0.3347, r 0.3035, f1: 0.3026	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4811
test	acc: 0.5739	macro: p 0.3506, r 0.3147, f1: 0.3198	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5384
global_step: 39601, epoch: 191, loss: 0.173448
global_step: 39602, epoch: 191, loss: 0.140937
global_step: 39603, epoch: 191, loss: 0.143516
global_step: 39604, epoch: 191, loss: 0.184083
global_step: 39605, epoch: 191, loss: 0.195953
global_step: 39606, epoch: 191, loss: 0.118346
global_step: 39607, epoch: 191, loss: 0.185162
global_step: 39608, epoch: 191, loss: 0.124061
global_step: 39609, epoch: 191, loss: 0.212197
global_step: 39610, epoch: 191, loss: 0.164129
global_step: 39611, epoch: 191, loss: 0.139031
global_step: 39612, epoch: 191, loss: 0.199379
global_step: 39613, epoch: 191, loss: 0.149068
global_step: 39614, epoch: 191, loss: 0.178407
global_step: 39615, epoch: 191, loss: 0.194852
global_step: 39616, epoch: 191, loss: 0.171654
global_step: 39617, epoch: 191, loss: 0.215078
global_step: 39618, epoch: 191, loss: 0.221378
global_step: 39619, epoch: 191, loss: 0.196959
global_step: 39620, epoch: 191, loss: 0.227177
global_step: 39621, epoch: 191, loss: 0.174973
global_step: 39622, epoch: 191, loss: 0.164095
global_step: 39623, epoch: 191, loss: 0.178826
global_step: 39624, epoch: 191, loss: 0.209808
global_step: 39625, epoch: 191, loss: 0.258549
global_step: 39626, epoch: 191, loss: 0.169300
global_step: 39627, epoch: 191, loss: 0.143689
global_step: 39628, epoch: 191, loss: 0.224962
global_step: 39629, epoch: 191, loss: 0.165665
global_step: 39630, epoch: 191, loss: 0.197568
global_step: 39631, epoch: 191, loss: 0.125803
global_step: 39632, epoch: 191, loss: 0.218784
global_step: 39633, epoch: 191, loss: 0.150888
global_step: 39634, epoch: 191, loss: 0.141352
global_step: 39635, epoch: 191, loss: 0.172052
global_step: 39636, epoch: 191, loss: 0.250351
global_step: 39637, epoch: 191, loss: 0.195870
global_step: 39638, epoch: 191, loss: 0.145944
global_step: 39639, epoch: 191, loss: 0.243356
global_step: 39640, epoch: 191, loss: 0.363386
epoch: 191
train	acc: 0.9693	macro: p 0.9759, r 0.9605, f1: 0.9680	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9692
dev	acc: 0.5149	macro: p 0.3358, r 0.2846, f1: 0.2862	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4651
test	acc: 0.5766	macro: p 0.3823, r 0.3034, f1: 0.3171	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5295
global_step: 39641, epoch: 192, loss: 0.173769
global_step: 39642, epoch: 192, loss: 0.167662
global_step: 39643, epoch: 192, loss: 0.114299
global_step: 39644, epoch: 192, loss: 0.188442
global_step: 39645, epoch: 192, loss: 0.128134
global_step: 39646, epoch: 192, loss: 0.180794
global_step: 39647, epoch: 192, loss: 0.144870
global_step: 39648, epoch: 192, loss: 0.156812
global_step: 39649, epoch: 192, loss: 0.204051
global_step: 39650, epoch: 192, loss: 0.209281
global_step: 39651, epoch: 192, loss: 0.155959
global_step: 39652, epoch: 192, loss: 0.163643
global_step: 39653, epoch: 192, loss: 0.104285
global_step: 39654, epoch: 192, loss: 0.169291
global_step: 39655, epoch: 192, loss: 0.217524
global_step: 39656, epoch: 192, loss: 0.108990
global_step: 39657, epoch: 192, loss: 0.151226
global_step: 39658, epoch: 192, loss: 0.191350
global_step: 39659, epoch: 192, loss: 0.289430
global_step: 39660, epoch: 192, loss: 0.150894
global_step: 39661, epoch: 192, loss: 0.202648
global_step: 39662, epoch: 192, loss: 0.166404
global_step: 39663, epoch: 192, loss: 0.182411
global_step: 39664, epoch: 192, loss: 0.222266
global_step: 39665, epoch: 192, loss: 0.143697
global_step: 39666, epoch: 192, loss: 0.274652
global_step: 39667, epoch: 192, loss: 0.243197
global_step: 39668, epoch: 192, loss: 0.159290
global_step: 39669, epoch: 192, loss: 0.212347
global_step: 39670, epoch: 192, loss: 0.197155
global_step: 39671, epoch: 192, loss: 0.135512
global_step: 39672, epoch: 192, loss: 0.226064
global_step: 39673, epoch: 192, loss: 0.206798
global_step: 39674, epoch: 192, loss: 0.236863
global_step: 39675, epoch: 192, loss: 0.221071
global_step: 39676, epoch: 192, loss: 0.209224
global_step: 39677, epoch: 192, loss: 0.207785
global_step: 39678, epoch: 192, loss: 0.179849
global_step: 39679, epoch: 192, loss: 0.208430
global_step: 39680, epoch: 192, loss: 0.051597
epoch: 192
train	acc: 0.9729	macro: p 0.9762, r 0.9640, f1: 0.9699	micro: p 0.9729, r 0.9729, f1 0.9729	weighted_f1:0.9729
dev	acc: 0.5185	macro: p 0.3539, r 0.3029, f1: 0.3068	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4801
test	acc: 0.5751	macro: p 0.3666, r 0.3115, f1: 0.3224	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5371
global_step: 39681, epoch: 193, loss: 0.220790
global_step: 39682, epoch: 193, loss: 0.158097
global_step: 39683, epoch: 193, loss: 0.144521
global_step: 39684, epoch: 193, loss: 0.147053
global_step: 39685, epoch: 193, loss: 0.129644
global_step: 39686, epoch: 193, loss: 0.175564
global_step: 39687, epoch: 193, loss: 0.148004
global_step: 39688, epoch: 193, loss: 0.160469
global_step: 39689, epoch: 193, loss: 0.163715
global_step: 39690, epoch: 193, loss: 0.207808
global_step: 39691, epoch: 193, loss: 0.235314
global_step: 39692, epoch: 193, loss: 0.192490
global_step: 39693, epoch: 193, loss: 0.194314
global_step: 39694, epoch: 193, loss: 0.170845
global_step: 39695, epoch: 193, loss: 0.245024
global_step: 39696, epoch: 193, loss: 0.158139
global_step: 39697, epoch: 193, loss: 0.194057
global_step: 39698, epoch: 193, loss: 0.140969
global_step: 39699, epoch: 193, loss: 0.232463
global_step: 39700, epoch: 193, loss: 0.188135
global_step: 39701, epoch: 193, loss: 0.200315
global_step: 39702, epoch: 193, loss: 0.168194
global_step: 39703, epoch: 193, loss: 0.187595
global_step: 39704, epoch: 193, loss: 0.151652
global_step: 39705, epoch: 193, loss: 0.152291
global_step: 39706, epoch: 193, loss: 0.139231
global_step: 39707, epoch: 193, loss: 0.185043
global_step: 39708, epoch: 193, loss: 0.202482
global_step: 39709, epoch: 193, loss: 0.154556
global_step: 39710, epoch: 193, loss: 0.218442
global_step: 39711, epoch: 193, loss: 0.157534
global_step: 39712, epoch: 193, loss: 0.160927
global_step: 39713, epoch: 193, loss: 0.193437
global_step: 39714, epoch: 193, loss: 0.170693
global_step: 39715, epoch: 193, loss: 0.236457
global_step: 39716, epoch: 193, loss: 0.192578
global_step: 39717, epoch: 193, loss: 0.147622
global_step: 39718, epoch: 193, loss: 0.177927
global_step: 39719, epoch: 193, loss: 0.238971
global_step: 39720, epoch: 193, loss: 0.010774
epoch: 193
train	acc: 0.9725	macro: p 0.9753, r 0.9640, f1: 0.9695	micro: p 0.9725, r 0.9725, f1 0.9725	weighted_f1:0.9725
dev	acc: 0.5167	macro: p 0.3466, r 0.2998, f1: 0.3019	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4766
test	acc: 0.5824	macro: p 0.3795, r 0.3202, f1: 0.3309	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5436
global_step: 39721, epoch: 194, loss: 0.155736
global_step: 39722, epoch: 194, loss: 0.131374
global_step: 39723, epoch: 194, loss: 0.195527
global_step: 39724, epoch: 194, loss: 0.138500
global_step: 39725, epoch: 194, loss: 0.150629
global_step: 39726, epoch: 194, loss: 0.200010
global_step: 39727, epoch: 194, loss: 0.182211
global_step: 39728, epoch: 194, loss: 0.152439
global_step: 39729, epoch: 194, loss: 0.238540
global_step: 39730, epoch: 194, loss: 0.156657
global_step: 39731, epoch: 194, loss: 0.215766
global_step: 39732, epoch: 194, loss: 0.150370
global_step: 39733, epoch: 194, loss: 0.104645
global_step: 39734, epoch: 194, loss: 0.133383
global_step: 39735, epoch: 194, loss: 0.162884
global_step: 39736, epoch: 194, loss: 0.195157
global_step: 39737, epoch: 194, loss: 0.160543
global_step: 39738, epoch: 194, loss: 0.176805
global_step: 39739, epoch: 194, loss: 0.211729
global_step: 39740, epoch: 194, loss: 0.157852
global_step: 39741, epoch: 194, loss: 0.168299
global_step: 39742, epoch: 194, loss: 0.183709
global_step: 39743, epoch: 194, loss: 0.186362
global_step: 39744, epoch: 194, loss: 0.158165
global_step: 39745, epoch: 194, loss: 0.193734
global_step: 39746, epoch: 194, loss: 0.261340
global_step: 39747, epoch: 194, loss: 0.212397
global_step: 39748, epoch: 194, loss: 0.235880
global_step: 39749, epoch: 194, loss: 0.262188
global_step: 39750, epoch: 194, loss: 0.155908
global_step: 39751, epoch: 194, loss: 0.169049
global_step: 39752, epoch: 194, loss: 0.197974
global_step: 39753, epoch: 194, loss: 0.140307
global_step: 39754, epoch: 194, loss: 0.201866
global_step: 39755, epoch: 194, loss: 0.168948
global_step: 39756, epoch: 194, loss: 0.195670
global_step: 39757, epoch: 194, loss: 0.190083
global_step: 39758, epoch: 194, loss: 0.207572
global_step: 39759, epoch: 194, loss: 0.153817
global_step: 39760, epoch: 194, loss: 0.357028
epoch: 194
train	acc: 0.9721	macro: p 0.9754, r 0.9624, f1: 0.9687	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5131	macro: p 0.3326, r 0.2886, f1: 0.2884	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4691
test	acc: 0.5774	macro: p 0.3778, r 0.3056, f1: 0.3166	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5338
global_step: 39761, epoch: 195, loss: 0.099152
global_step: 39762, epoch: 195, loss: 0.133938
global_step: 39763, epoch: 195, loss: 0.162043
global_step: 39764, epoch: 195, loss: 0.186567
global_step: 39765, epoch: 195, loss: 0.152654
global_step: 39766, epoch: 195, loss: 0.174318
global_step: 39767, epoch: 195, loss: 0.153235
global_step: 39768, epoch: 195, loss: 0.272448
global_step: 39769, epoch: 195, loss: 0.165062
global_step: 39770, epoch: 195, loss: 0.204179
global_step: 39771, epoch: 195, loss: 0.201541
global_step: 39772, epoch: 195, loss: 0.231154
global_step: 39773, epoch: 195, loss: 0.178016
global_step: 39774, epoch: 195, loss: 0.183835
global_step: 39775, epoch: 195, loss: 0.205581
global_step: 39776, epoch: 195, loss: 0.195508
global_step: 39777, epoch: 195, loss: 0.203094
global_step: 39778, epoch: 195, loss: 0.188135
global_step: 39779, epoch: 195, loss: 0.180402
global_step: 39780, epoch: 195, loss: 0.150128
global_step: 39781, epoch: 195, loss: 0.174679
global_step: 39782, epoch: 195, loss: 0.240564
global_step: 39783, epoch: 195, loss: 0.225434
global_step: 39784, epoch: 195, loss: 0.208101
global_step: 39785, epoch: 195, loss: 0.148214
global_step: 39786, epoch: 195, loss: 0.212418
global_step: 39787, epoch: 195, loss: 0.135872
global_step: 39788, epoch: 195, loss: 0.231823
global_step: 39789, epoch: 195, loss: 0.180879
global_step: 39790, epoch: 195, loss: 0.177785
global_step: 39791, epoch: 195, loss: 0.180046
global_step: 39792, epoch: 195, loss: 0.113914
global_step: 39793, epoch: 195, loss: 0.254796
global_step: 39794, epoch: 195, loss: 0.140662
global_step: 39795, epoch: 195, loss: 0.148409
global_step: 39796, epoch: 195, loss: 0.154283
global_step: 39797, epoch: 195, loss: 0.179401
global_step: 39798, epoch: 195, loss: 0.234306
global_step: 39799, epoch: 195, loss: 0.145300
global_step: 39800, epoch: 195, loss: 0.091263
epoch: 195
train	acc: 0.9722	macro: p 0.9757, r 0.9622, f1: 0.9687	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5221	macro: p 0.3414, r 0.2953, f1: 0.2957	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4788
test	acc: 0.5755	macro: p 0.3770, r 0.3063, f1: 0.3185	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5335
global_step: 39801, epoch: 196, loss: 0.165252
global_step: 39802, epoch: 196, loss: 0.156758
global_step: 39803, epoch: 196, loss: 0.121471
global_step: 39804, epoch: 196, loss: 0.159399
global_step: 39805, epoch: 196, loss: 0.216949
global_step: 39806, epoch: 196, loss: 0.202272
global_step: 39807, epoch: 196, loss: 0.134780
global_step: 39808, epoch: 196, loss: 0.093879
global_step: 39809, epoch: 196, loss: 0.202551
global_step: 39810, epoch: 196, loss: 0.133611
global_step: 39811, epoch: 196, loss: 0.172351
global_step: 39812, epoch: 196, loss: 0.139290
global_step: 39813, epoch: 196, loss: 0.180097
global_step: 39814, epoch: 196, loss: 0.188097
global_step: 39815, epoch: 196, loss: 0.145583
global_step: 39816, epoch: 196, loss: 0.241842
global_step: 39817, epoch: 196, loss: 0.166166
global_step: 39818, epoch: 196, loss: 0.183563
global_step: 39819, epoch: 196, loss: 0.234022
global_step: 39820, epoch: 196, loss: 0.185940
global_step: 39821, epoch: 196, loss: 0.185267
global_step: 39822, epoch: 196, loss: 0.167399
global_step: 39823, epoch: 196, loss: 0.139072
global_step: 39824, epoch: 196, loss: 0.176386
global_step: 39825, epoch: 196, loss: 0.201953
global_step: 39826, epoch: 196, loss: 0.188756
global_step: 39827, epoch: 196, loss: 0.219867
global_step: 39828, epoch: 196, loss: 0.127485
global_step: 39829, epoch: 196, loss: 0.153518
global_step: 39830, epoch: 196, loss: 0.161355
global_step: 39831, epoch: 196, loss: 0.185759
global_step: 39832, epoch: 196, loss: 0.180885
global_step: 39833, epoch: 196, loss: 0.163545
global_step: 39834, epoch: 196, loss: 0.187183
global_step: 39835, epoch: 196, loss: 0.158672
global_step: 39836, epoch: 196, loss: 0.211813
global_step: 39837, epoch: 196, loss: 0.197616
global_step: 39838, epoch: 196, loss: 0.210830
global_step: 39839, epoch: 196, loss: 0.172850
global_step: 39840, epoch: 196, loss: 0.292540
epoch: 196
train	acc: 0.9721	macro: p 0.9750, r 0.9632, f1: 0.9689	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5131	macro: p 0.3315, r 0.2874, f1: 0.2859	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4664
test	acc: 0.5785	macro: p 0.3657, r 0.3076, f1: 0.3183	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5354
global_step: 39841, epoch: 197, loss: 0.187212
global_step: 39842, epoch: 197, loss: 0.213092
global_step: 39843, epoch: 197, loss: 0.186172
global_step: 39844, epoch: 197, loss: 0.199725
global_step: 39845, epoch: 197, loss: 0.124098
global_step: 39846, epoch: 197, loss: 0.184995
global_step: 39847, epoch: 197, loss: 0.212695
global_step: 39848, epoch: 197, loss: 0.189671
global_step: 39849, epoch: 197, loss: 0.180924
global_step: 39850, epoch: 197, loss: 0.216117
global_step: 39851, epoch: 197, loss: 0.173737
global_step: 39852, epoch: 197, loss: 0.208148
global_step: 39853, epoch: 197, loss: 0.127256
global_step: 39854, epoch: 197, loss: 0.170939
global_step: 39855, epoch: 197, loss: 0.179005
global_step: 39856, epoch: 197, loss: 0.142458
global_step: 39857, epoch: 197, loss: 0.137251
global_step: 39858, epoch: 197, loss: 0.197735
global_step: 39859, epoch: 197, loss: 0.170149
global_step: 39860, epoch: 197, loss: 0.193119
global_step: 39861, epoch: 197, loss: 0.202056
global_step: 39862, epoch: 197, loss: 0.168241
global_step: 39863, epoch: 197, loss: 0.140594
global_step: 39864, epoch: 197, loss: 0.246331
global_step: 39865, epoch: 197, loss: 0.170208
global_step: 39866, epoch: 197, loss: 0.198694
global_step: 39867, epoch: 197, loss: 0.204061
global_step: 39868, epoch: 197, loss: 0.136080
global_step: 39869, epoch: 197, loss: 0.132297
global_step: 39870, epoch: 197, loss: 0.195008
global_step: 39871, epoch: 197, loss: 0.167720
global_step: 39872, epoch: 197, loss: 0.114060
global_step: 39873, epoch: 197, loss: 0.154831
global_step: 39874, epoch: 197, loss: 0.126957
global_step: 39875, epoch: 197, loss: 0.215850
global_step: 39876, epoch: 197, loss: 0.122869
global_step: 39877, epoch: 197, loss: 0.125571
global_step: 39878, epoch: 197, loss: 0.180241
global_step: 39879, epoch: 197, loss: 0.168213
global_step: 39880, epoch: 197, loss: 0.019168
epoch: 197
train	acc: 0.9722	macro: p 0.9752, r 0.9638, f1: 0.9693	micro: p 0.9722, r 0.9722, f1 0.9722	weighted_f1:0.9722
dev	acc: 0.5203	macro: p 0.3402, r 0.2966, f1: 0.2959	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4773
test	acc: 0.5751	macro: p 0.3611, r 0.3053, f1: 0.3146	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5331
global_step: 39881, epoch: 198, loss: 0.186533
global_step: 39882, epoch: 198, loss: 0.186917
global_step: 39883, epoch: 198, loss: 0.203570
global_step: 39884, epoch: 198, loss: 0.141908
global_step: 39885, epoch: 198, loss: 0.243223
global_step: 39886, epoch: 198, loss: 0.187311
global_step: 39887, epoch: 198, loss: 0.149201
global_step: 39888, epoch: 198, loss: 0.208730
global_step: 39889, epoch: 198, loss: 0.164209
global_step: 39890, epoch: 198, loss: 0.180245
global_step: 39891, epoch: 198, loss: 0.130859
global_step: 39892, epoch: 198, loss: 0.205173
global_step: 39893, epoch: 198, loss: 0.199649
global_step: 39894, epoch: 198, loss: 0.203655
global_step: 39895, epoch: 198, loss: 0.207836
global_step: 39896, epoch: 198, loss: 0.125087
global_step: 39897, epoch: 198, loss: 0.187166
global_step: 39898, epoch: 198, loss: 0.242841
global_step: 39899, epoch: 198, loss: 0.161903
global_step: 39900, epoch: 198, loss: 0.127036
global_step: 39901, epoch: 198, loss: 0.223327
global_step: 39902, epoch: 198, loss: 0.123496
global_step: 39903, epoch: 198, loss: 0.145873
global_step: 39904, epoch: 198, loss: 0.227639
global_step: 39905, epoch: 198, loss: 0.181406
global_step: 39906, epoch: 198, loss: 0.205548
global_step: 39907, epoch: 198, loss: 0.124833
global_step: 39908, epoch: 198, loss: 0.138005
global_step: 39909, epoch: 198, loss: 0.151371
global_step: 39910, epoch: 198, loss: 0.200876
global_step: 39911, epoch: 198, loss: 0.188077
global_step: 39912, epoch: 198, loss: 0.236023
global_step: 39913, epoch: 198, loss: 0.221643
global_step: 39914, epoch: 198, loss: 0.148736
global_step: 39915, epoch: 198, loss: 0.126126
global_step: 39916, epoch: 198, loss: 0.139719
global_step: 39917, epoch: 198, loss: 0.200675
global_step: 39918, epoch: 198, loss: 0.166445
global_step: 39919, epoch: 198, loss: 0.155557
global_step: 39920, epoch: 198, loss: 0.012215
epoch: 198
train	acc: 0.9726	macro: p 0.9754, r 0.9638, f1: 0.9695	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5239	macro: p 0.3636, r 0.3045, f1: 0.3110	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4839
test	acc: 0.5716	macro: p 0.3577, r 0.3027, f1: 0.3128	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5322
global_step: 39921, epoch: 199, loss: 0.195790
global_step: 39922, epoch: 199, loss: 0.212560
global_step: 39923, epoch: 199, loss: 0.162660
global_step: 39924, epoch: 199, loss: 0.174812
global_step: 39925, epoch: 199, loss: 0.168985
global_step: 39926, epoch: 199, loss: 0.170112
global_step: 39927, epoch: 199, loss: 0.204101
global_step: 39928, epoch: 199, loss: 0.216428
global_step: 39929, epoch: 199, loss: 0.192936
global_step: 39930, epoch: 199, loss: 0.156767
global_step: 39931, epoch: 199, loss: 0.178200
global_step: 39932, epoch: 199, loss: 0.159984
global_step: 39933, epoch: 199, loss: 0.202124
global_step: 39934, epoch: 199, loss: 0.190435
global_step: 39935, epoch: 199, loss: 0.140709
global_step: 39936, epoch: 199, loss: 0.148900
global_step: 39937, epoch: 199, loss: 0.151496
global_step: 39938, epoch: 199, loss: 0.191717
global_step: 39939, epoch: 199, loss: 0.130374
global_step: 39940, epoch: 199, loss: 0.183952
global_step: 39941, epoch: 199, loss: 0.174407
global_step: 39942, epoch: 199, loss: 0.115806
global_step: 39943, epoch: 199, loss: 0.201816
global_step: 39944, epoch: 199, loss: 0.191148
global_step: 39945, epoch: 199, loss: 0.177483
global_step: 39946, epoch: 199, loss: 0.178582
global_step: 39947, epoch: 199, loss: 0.185913
global_step: 39948, epoch: 199, loss: 0.250220
global_step: 39949, epoch: 199, loss: 0.173221
global_step: 39950, epoch: 199, loss: 0.259237
global_step: 39951, epoch: 199, loss: 0.135961
global_step: 39952, epoch: 199, loss: 0.172102
global_step: 39953, epoch: 199, loss: 0.211427
global_step: 39954, epoch: 199, loss: 0.182954
global_step: 39955, epoch: 199, loss: 0.109352
global_step: 39956, epoch: 199, loss: 0.148600
global_step: 39957, epoch: 199, loss: 0.161414
global_step: 39958, epoch: 199, loss: 0.214015
global_step: 39959, epoch: 199, loss: 0.193906
global_step: 39960, epoch: 199, loss: 0.110723
epoch: 199
train	acc: 0.9723	macro: p 0.9756, r 0.9640, f1: 0.9696	micro: p 0.9723, r 0.9723, f1 0.9723	weighted_f1:0.9723
dev	acc: 0.5185	macro: p 0.3486, r 0.2961, f1: 0.2983	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4746
test	acc: 0.5770	macro: p 0.3664, r 0.3085, f1: 0.3195	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5364
global_step: 39961, epoch: 200, loss: 0.209602
global_step: 39962, epoch: 200, loss: 0.166019
global_step: 39963, epoch: 200, loss: 0.174872
global_step: 39964, epoch: 200, loss: 0.166966
global_step: 39965, epoch: 200, loss: 0.120633
global_step: 39966, epoch: 200, loss: 0.181577
global_step: 39967, epoch: 200, loss: 0.213262
global_step: 39968, epoch: 200, loss: 0.138142
global_step: 39969, epoch: 200, loss: 0.160604
global_step: 39970, epoch: 200, loss: 0.181729
global_step: 39971, epoch: 200, loss: 0.122752
global_step: 39972, epoch: 200, loss: 0.189311
global_step: 39973, epoch: 200, loss: 0.248491
global_step: 39974, epoch: 200, loss: 0.205451
global_step: 39975, epoch: 200, loss: 0.121379
global_step: 39976, epoch: 200, loss: 0.153839
global_step: 39977, epoch: 200, loss: 0.171459
global_step: 39978, epoch: 200, loss: 0.188748
global_step: 39979, epoch: 200, loss: 0.180017
global_step: 39980, epoch: 200, loss: 0.213746
global_step: 39981, epoch: 200, loss: 0.150066
global_step: 39982, epoch: 200, loss: 0.160449
global_step: 39983, epoch: 200, loss: 0.166272
global_step: 39984, epoch: 200, loss: 0.245263
global_step: 39985, epoch: 200, loss: 0.194240
global_step: 39986, epoch: 200, loss: 0.211870
global_step: 39987, epoch: 200, loss: 0.198789
global_step: 39988, epoch: 200, loss: 0.191878
global_step: 39989, epoch: 200, loss: 0.262271
global_step: 39990, epoch: 200, loss: 0.169230
global_step: 39991, epoch: 200, loss: 0.148752
global_step: 39992, epoch: 200, loss: 0.166187
global_step: 39993, epoch: 200, loss: 0.195383
global_step: 39994, epoch: 200, loss: 0.209542
global_step: 39995, epoch: 200, loss: 0.109673
global_step: 39996, epoch: 200, loss: 0.205312
global_step: 39997, epoch: 200, loss: 0.187779
global_step: 39998, epoch: 200, loss: 0.222362
global_step: 39999, epoch: 200, loss: 0.187847
global_step: 40000, epoch: 200, loss: 0.002092
epoch: 200
train	acc: 0.9726	macro: p 0.9769, r 0.9630, f1: 0.9698	micro: p 0.9726, r 0.9726, f1 0.9726	weighted_f1:0.9726
dev	acc: 0.5203	macro: p 0.3542, r 0.2968, f1: 0.3004	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4778
test	acc: 0.5755	macro: p 0.3576, r 0.3057, f1: 0.3164	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5355
BEST MODEL epoch: 54
train	acc: 0.8904 macro_p: 0.8870 macro_r: 0.7240 macro_f1: 0.7474 micro_p: 0.8904 micro_r: 0.8904 micro_f1: 0.8904 weighted_f1: 0.8819
dev	acc: 0.5491 macro_p: 0.3319 macro_r: 0.3310 macro_f1: 0.3284 micro_p: 0.5491 micro_r: 0.5491 micro_f1: 0.5491 weighted_f1: 0.5170
test	acc: 0.5862 macro_p: 0.5324 macro_r: 0.3406 macro_f1: 0.3466 micro_p: 0.5862 micro_r: 0.5862 micro_f1: 0.5862 weighted_f1: 0.5617
====================TRAINING FINISHED====================
best epoch: [54, 35, 32, 32, 54], avg test weighted f1: 0.562489
