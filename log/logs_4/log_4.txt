nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['Aw', ',', 'we-we', 'are', 'so', '?', 'So', 'umm', ',', 'well', 'I-I-I', 'like', 'you', 'and', 'I-I', 'love', 'umm', ',', 'y', '?', 'know', 'hanging', 'out', 'with', 'you', '.']   1
['Yep', ',', 'we', 'shook', 'on', 'it', '.', 'Yeah', 'but', 'believe', 'me', 'that', 'is', 'not', 'how', 'he', 'wanted', 'to', 'seal', 'the', 'deal', '.']   0

-------dev--------
1109 1109
['Y', '?', 'know', ',', 'you', 'look', 'nothing', 'like', 'I', 'would', '?', 've', 'thought', '.', 'You', '?', 're', '?', 'you', '?', 're', 'so', 'young', '.']   2
['Hey', ',', 'where', 'are', 'Monica', 'and', 'Rachel', 'anyway', '?']   0

-------test--------
2610 2610
['Hang', 'on', 'buddy', '!']   4
['Fair', 'enough', ',', 'now', 'go', 'get', 'ready', '!']   0
====================INFORMATION====================
MODEL: rand
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 50
LEARNING_RATE: 1
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
global_step: 1, epoch: 1, loss: 1.866614
global_step: 2, epoch: 1, loss: 1.617338
global_step: 3, epoch: 1, loss: 1.445319
global_step: 4, epoch: 1, loss: 1.548967
global_step: 5, epoch: 1, loss: 1.632822
global_step: 6, epoch: 1, loss: 1.599324
global_step: 7, epoch: 1, loss: 1.612724
global_step: 8, epoch: 1, loss: 1.427559
global_step: 9, epoch: 1, loss: 1.467081
global_step: 10, epoch: 1, loss: 1.582307
global_step: 11, epoch: 1, loss: 1.503292
global_step: 12, epoch: 1, loss: 1.428020
global_step: 13, epoch: 1, loss: 1.446878
global_step: 14, epoch: 1, loss: 1.389066
global_step: 15, epoch: 1, loss: 1.435093
global_step: 16, epoch: 1, loss: 1.268308
global_step: 17, epoch: 1, loss: 1.385057
global_step: 18, epoch: 1, loss: 1.375782
global_step: 19, epoch: 1, loss: 1.409515
global_step: 20, epoch: 1, loss: 1.343334
global_step: 21, epoch: 1, loss: 1.355072
global_step: 22, epoch: 1, loss: 1.354431
global_step: 23, epoch: 1, loss: 1.450558
global_step: 24, epoch: 1, loss: 1.330054
global_step: 25, epoch: 1, loss: 1.398593
global_step: 26, epoch: 1, loss: 1.414618
global_step: 27, epoch: 1, loss: 1.474153
global_step: 28, epoch: 1, loss: 1.410865
global_step: 29, epoch: 1, loss: 1.274657
global_step: 30, epoch: 1, loss: 1.300720
global_step: 31, epoch: 1, loss: 1.376679
global_step: 32, epoch: 1, loss: 1.342081
global_step: 33, epoch: 1, loss: 1.381250
global_step: 34, epoch: 1, loss: 1.408798
global_step: 35, epoch: 1, loss: 1.383865
global_step: 36, epoch: 1, loss: 1.310071
global_step: 37, epoch: 1, loss: 1.309164
global_step: 38, epoch: 1, loss: 1.437710
global_step: 39, epoch: 1, loss: 1.463105
global_step: 40, epoch: 1, loss: 0.773045
epoch: 1
train	acc: 0.5181	macro: p 0.2008, r 0.2186, f1: 0.1670	micro: p 0.5181, r 0.5181, f1 0.5181	weighted_f1:0.4016
dev	acc: 0.4815	macro: p 0.1976, r 0.2227, f1: 0.1662	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.3578
test	acc: 0.5234	macro: p 0.2014, r 0.2208, f1: 0.1683	micro: p 0.5234, r 0.5234, f1 0.5234	weighted_f1:0.4088
New best model!
global_step: 41, epoch: 2, loss: 1.577056
global_step: 42, epoch: 2, loss: 1.437878
global_step: 43, epoch: 2, loss: 1.237160
global_step: 44, epoch: 2, loss: 1.334317
global_step: 45, epoch: 2, loss: 1.369139
global_step: 46, epoch: 2, loss: 1.248585
global_step: 47, epoch: 2, loss: 1.369712
global_step: 48, epoch: 2, loss: 1.319783
global_step: 49, epoch: 2, loss: 1.505299
global_step: 50, epoch: 2, loss: 1.385182
global_step: 51, epoch: 2, loss: 1.348917
global_step: 52, epoch: 2, loss: 1.325516
global_step: 53, epoch: 2, loss: 1.208168
global_step: 54, epoch: 2, loss: 1.353411
global_step: 55, epoch: 2, loss: 1.270622
global_step: 56, epoch: 2, loss: 1.228146
global_step: 57, epoch: 2, loss: 1.205105
global_step: 58, epoch: 2, loss: 1.360345
global_step: 59, epoch: 2, loss: 1.346563
global_step: 60, epoch: 2, loss: 1.365627
global_step: 61, epoch: 2, loss: 1.339758
global_step: 62, epoch: 2, loss: 1.229793
global_step: 63, epoch: 2, loss: 1.344808
global_step: 64, epoch: 2, loss: 1.268021
global_step: 65, epoch: 2, loss: 1.332358
global_step: 66, epoch: 2, loss: 1.299608
global_step: 67, epoch: 2, loss: 1.439560
global_step: 68, epoch: 2, loss: 1.274599
global_step: 69, epoch: 2, loss: 1.271695
global_step: 70, epoch: 2, loss: 1.177794
global_step: 71, epoch: 2, loss: 1.365433
global_step: 72, epoch: 2, loss: 1.271807
global_step: 73, epoch: 2, loss: 1.456132
global_step: 74, epoch: 2, loss: 1.341118
global_step: 75, epoch: 2, loss: 1.374846
global_step: 76, epoch: 2, loss: 1.346496
global_step: 77, epoch: 2, loss: 1.339851
global_step: 78, epoch: 2, loss: 1.263994
global_step: 79, epoch: 2, loss: 1.313921
global_step: 80, epoch: 2, loss: 1.907936
epoch: 2
train	acc: 0.3402	macro: p 0.3551, r 0.2842, f1: 0.2194	micro: p 0.3402, r 0.3402, f1 0.3402	weighted_f1:0.3195
dev	acc: 0.3192	macro: p 0.3755, r 0.2639, f1: 0.2074	micro: p 0.3192, r 0.3192, f1 0.3192	weighted_f1:0.2973
test	acc: 0.3195	macro: p 0.3766, r 0.2741, f1: 0.2059	micro: p 0.3195, r 0.3195, f1 0.3195	weighted_f1:0.2974
global_step: 81, epoch: 3, loss: 1.602856
global_step: 82, epoch: 3, loss: 1.274013
global_step: 83, epoch: 3, loss: 1.152265
global_step: 84, epoch: 3, loss: 1.289175
global_step: 85, epoch: 3, loss: 1.322528
global_step: 86, epoch: 3, loss: 1.347229
global_step: 87, epoch: 3, loss: 1.137893
global_step: 88, epoch: 3, loss: 1.236816
global_step: 89, epoch: 3, loss: 1.320562
global_step: 90, epoch: 3, loss: 1.170364
global_step: 91, epoch: 3, loss: 1.292242
global_step: 92, epoch: 3, loss: 1.368735
global_step: 93, epoch: 3, loss: 1.297244
global_step: 94, epoch: 3, loss: 1.365607
global_step: 95, epoch: 3, loss: 1.261150
global_step: 96, epoch: 3, loss: 1.287433
global_step: 97, epoch: 3, loss: 1.248346
global_step: 98, epoch: 3, loss: 1.351233
global_step: 99, epoch: 3, loss: 1.169629
global_step: 100, epoch: 3, loss: 1.351056
global_step: 101, epoch: 3, loss: 1.235681
global_step: 102, epoch: 3, loss: 1.093792
global_step: 103, epoch: 3, loss: 1.218912
global_step: 104, epoch: 3, loss: 1.292454
global_step: 105, epoch: 3, loss: 1.217255
global_step: 106, epoch: 3, loss: 1.193878
global_step: 107, epoch: 3, loss: 1.310377
global_step: 108, epoch: 3, loss: 1.182865
global_step: 109, epoch: 3, loss: 1.297479
global_step: 110, epoch: 3, loss: 1.264324
global_step: 111, epoch: 3, loss: 1.284909
global_step: 112, epoch: 3, loss: 1.171549
global_step: 113, epoch: 3, loss: 1.242319
global_step: 114, epoch: 3, loss: 1.244959
global_step: 115, epoch: 3, loss: 1.361536
global_step: 116, epoch: 3, loss: 1.306371
global_step: 117, epoch: 3, loss: 1.215304
global_step: 118, epoch: 3, loss: 1.269700
global_step: 119, epoch: 3, loss: 1.349225
global_step: 120, epoch: 3, loss: 0.654296
epoch: 3
train	acc: 0.5854	macro: p 0.4386, r 0.2980, f1: 0.2864	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5199
dev	acc: 0.5401	macro: p 0.4373, r 0.2817, f1: 0.2693	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4671
test	acc: 0.5904	macro: p 0.4520, r 0.2932, f1: 0.2854	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5269
New best model!
global_step: 121, epoch: 4, loss: 1.371204
global_step: 122, epoch: 4, loss: 1.270215
global_step: 123, epoch: 4, loss: 1.292920
global_step: 124, epoch: 4, loss: 1.226039
global_step: 125, epoch: 4, loss: 1.126057
global_step: 126, epoch: 4, loss: 1.174308
global_step: 127, epoch: 4, loss: 1.114856
global_step: 128, epoch: 4, loss: 1.191082
global_step: 129, epoch: 4, loss: 1.217387
global_step: 130, epoch: 4, loss: 1.160980
global_step: 131, epoch: 4, loss: 1.251978
global_step: 132, epoch: 4, loss: 1.213495
global_step: 133, epoch: 4, loss: 1.139847
global_step: 134, epoch: 4, loss: 1.242000
global_step: 135, epoch: 4, loss: 1.187062
global_step: 136, epoch: 4, loss: 1.301043
global_step: 137, epoch: 4, loss: 1.380805
global_step: 138, epoch: 4, loss: 1.220467
global_step: 139, epoch: 4, loss: 1.217489
global_step: 140, epoch: 4, loss: 1.146450
global_step: 141, epoch: 4, loss: 1.311224
global_step: 142, epoch: 4, loss: 1.103325
global_step: 143, epoch: 4, loss: 1.102813
global_step: 144, epoch: 4, loss: 1.217111
global_step: 145, epoch: 4, loss: 1.198999
global_step: 146, epoch: 4, loss: 1.172646
global_step: 147, epoch: 4, loss: 1.142199
global_step: 148, epoch: 4, loss: 1.182553
global_step: 149, epoch: 4, loss: 1.205881
global_step: 150, epoch: 4, loss: 1.283445
global_step: 151, epoch: 4, loss: 1.327266
global_step: 152, epoch: 4, loss: 1.167362
global_step: 153, epoch: 4, loss: 1.349661
global_step: 154, epoch: 4, loss: 1.271547
global_step: 155, epoch: 4, loss: 1.194730
global_step: 156, epoch: 4, loss: 1.198222
global_step: 157, epoch: 4, loss: 1.148728
global_step: 158, epoch: 4, loss: 1.276138
global_step: 159, epoch: 4, loss: 1.241668
global_step: 160, epoch: 4, loss: 1.625832
epoch: 4
train	acc: 0.6297	macro: p 0.4060, r 0.3523, f1: 0.3586	micro: p 0.6297, r 0.6297, f1 0.6297	weighted_f1:0.5851
dev	acc: 0.5573	macro: p 0.3545, r 0.3084, f1: 0.3012	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4957
test	acc: 0.5943	macro: p 0.3597, r 0.3101, f1: 0.3092	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5445
New best model!
global_step: 161, epoch: 5, loss: 1.168822
global_step: 162, epoch: 5, loss: 1.134490
global_step: 163, epoch: 5, loss: 1.079760
global_step: 164, epoch: 5, loss: 1.229053
global_step: 165, epoch: 5, loss: 1.194223
global_step: 166, epoch: 5, loss: 1.181484
global_step: 167, epoch: 5, loss: 1.201922
global_step: 168, epoch: 5, loss: 1.219616
global_step: 169, epoch: 5, loss: 1.088856
global_step: 170, epoch: 5, loss: 1.201487
global_step: 171, epoch: 5, loss: 1.166215
global_step: 172, epoch: 5, loss: 1.120724
global_step: 173, epoch: 5, loss: 1.218764
global_step: 174, epoch: 5, loss: 1.202391
global_step: 175, epoch: 5, loss: 1.200118
global_step: 176, epoch: 5, loss: 1.215301
global_step: 177, epoch: 5, loss: 1.220738
global_step: 178, epoch: 5, loss: 1.159285
global_step: 179, epoch: 5, loss: 1.227118
global_step: 180, epoch: 5, loss: 1.134673
global_step: 181, epoch: 5, loss: 1.164266
global_step: 182, epoch: 5, loss: 1.209730
global_step: 183, epoch: 5, loss: 1.157144
global_step: 184, epoch: 5, loss: 1.235824
global_step: 185, epoch: 5, loss: 1.152667
global_step: 186, epoch: 5, loss: 1.141757
global_step: 187, epoch: 5, loss: 1.154389
global_step: 188, epoch: 5, loss: 1.109136
global_step: 189, epoch: 5, loss: 1.108071
global_step: 190, epoch: 5, loss: 1.151908
global_step: 191, epoch: 5, loss: 1.260796
global_step: 192, epoch: 5, loss: 1.093194
global_step: 193, epoch: 5, loss: 1.248970
global_step: 194, epoch: 5, loss: 1.179608
global_step: 195, epoch: 5, loss: 1.181148
global_step: 196, epoch: 5, loss: 1.102086
global_step: 197, epoch: 5, loss: 1.157740
global_step: 198, epoch: 5, loss: 1.135771
global_step: 199, epoch: 5, loss: 1.197757
global_step: 200, epoch: 5, loss: 1.301648
epoch: 5
train	acc: 0.6247	macro: p 0.4551, r 0.3208, f1: 0.3215	micro: p 0.6247, r 0.6247, f1 0.6247	weighted_f1:0.5658
dev	acc: 0.5446	macro: p 0.3858, r 0.2871, f1: 0.2632	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4650
test	acc: 0.5812	macro: p 0.4001, r 0.2844, f1: 0.2700	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5114
global_step: 201, epoch: 6, loss: 1.075596
global_step: 202, epoch: 6, loss: 1.214851
global_step: 203, epoch: 6, loss: 1.107201
global_step: 204, epoch: 6, loss: 1.224530
global_step: 205, epoch: 6, loss: 1.116529
global_step: 206, epoch: 6, loss: 1.126592
global_step: 207, epoch: 6, loss: 1.115804
global_step: 208, epoch: 6, loss: 1.166795
global_step: 209, epoch: 6, loss: 1.196755
global_step: 210, epoch: 6, loss: 1.091982
global_step: 211, epoch: 6, loss: 1.082406
global_step: 212, epoch: 6, loss: 1.105654
global_step: 213, epoch: 6, loss: 1.196856
global_step: 214, epoch: 6, loss: 1.313387
global_step: 215, epoch: 6, loss: 1.025959
global_step: 216, epoch: 6, loss: 1.235934
global_step: 217, epoch: 6, loss: 1.061350
global_step: 218, epoch: 6, loss: 1.117406
global_step: 219, epoch: 6, loss: 1.098143
global_step: 220, epoch: 6, loss: 1.077204
global_step: 221, epoch: 6, loss: 1.138135
global_step: 222, epoch: 6, loss: 1.182182
global_step: 223, epoch: 6, loss: 1.256283
global_step: 224, epoch: 6, loss: 1.187003
global_step: 225, epoch: 6, loss: 1.146458
global_step: 226, epoch: 6, loss: 1.162252
global_step: 227, epoch: 6, loss: 1.159490
global_step: 228, epoch: 6, loss: 1.090626
global_step: 229, epoch: 6, loss: 1.194653
global_step: 230, epoch: 6, loss: 1.118373
global_step: 231, epoch: 6, loss: 1.139370
global_step: 232, epoch: 6, loss: 1.149188
global_step: 233, epoch: 6, loss: 1.037435
global_step: 234, epoch: 6, loss: 1.084232
global_step: 235, epoch: 6, loss: 1.159232
global_step: 236, epoch: 6, loss: 1.105988
global_step: 237, epoch: 6, loss: 1.188925
global_step: 238, epoch: 6, loss: 1.114805
global_step: 239, epoch: 6, loss: 1.108437
global_step: 240, epoch: 6, loss: 1.749609
epoch: 6
train	acc: 0.6515	macro: p 0.4608, r 0.3631, f1: 0.3742	micro: p 0.6515, r 0.6515, f1 0.6515	weighted_f1:0.6062
dev	acc: 0.5528	macro: p 0.3585, r 0.2959, f1: 0.2915	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4896
test	acc: 0.5977	macro: p 0.3723, r 0.3045, f1: 0.3085	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5450
global_step: 241, epoch: 7, loss: 1.028945
global_step: 242, epoch: 7, loss: 0.993896
global_step: 243, epoch: 7, loss: 1.119027
global_step: 244, epoch: 7, loss: 1.033024
global_step: 245, epoch: 7, loss: 1.107796
global_step: 246, epoch: 7, loss: 1.027014
global_step: 247, epoch: 7, loss: 1.059813
global_step: 248, epoch: 7, loss: 0.960691
global_step: 249, epoch: 7, loss: 1.136211
global_step: 250, epoch: 7, loss: 1.079750
global_step: 251, epoch: 7, loss: 1.078237
global_step: 252, epoch: 7, loss: 1.014400
global_step: 253, epoch: 7, loss: 1.080592
global_step: 254, epoch: 7, loss: 1.028296
global_step: 255, epoch: 7, loss: 1.098577
global_step: 256, epoch: 7, loss: 1.219286
global_step: 257, epoch: 7, loss: 0.930953
global_step: 258, epoch: 7, loss: 1.200632
global_step: 259, epoch: 7, loss: 1.060077
global_step: 260, epoch: 7, loss: 1.031815
global_step: 261, epoch: 7, loss: 1.070420
global_step: 262, epoch: 7, loss: 1.046617
global_step: 263, epoch: 7, loss: 1.063171
global_step: 264, epoch: 7, loss: 1.064482
global_step: 265, epoch: 7, loss: 1.116229
global_step: 266, epoch: 7, loss: 1.106719
global_step: 267, epoch: 7, loss: 1.143690
global_step: 268, epoch: 7, loss: 1.021132
global_step: 269, epoch: 7, loss: 1.149523
global_step: 270, epoch: 7, loss: 0.997396
global_step: 271, epoch: 7, loss: 1.102856
global_step: 272, epoch: 7, loss: 1.158008
global_step: 273, epoch: 7, loss: 1.142339
global_step: 274, epoch: 7, loss: 1.196634
global_step: 275, epoch: 7, loss: 1.149397
global_step: 276, epoch: 7, loss: 1.158916
global_step: 277, epoch: 7, loss: 1.090257
global_step: 278, epoch: 7, loss: 1.103194
global_step: 279, epoch: 7, loss: 1.028358
global_step: 280, epoch: 7, loss: 1.027849
epoch: 7
train	acc: 0.6577	macro: p 0.4861, r 0.3759, f1: 0.3817	micro: p 0.6577, r 0.6577, f1 0.6577	weighted_f1:0.6181
dev	acc: 0.5455	macro: p 0.3699, r 0.2925, f1: 0.2889	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4872
test	acc: 0.6046	macro: p 0.4059, r 0.3131, f1: 0.3156	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5535
global_step: 281, epoch: 8, loss: 1.013379
global_step: 282, epoch: 8, loss: 0.957107
global_step: 283, epoch: 8, loss: 1.027984
global_step: 284, epoch: 8, loss: 1.031073
global_step: 285, epoch: 8, loss: 0.954274
global_step: 286, epoch: 8, loss: 1.008191
global_step: 287, epoch: 8, loss: 1.042528
global_step: 288, epoch: 8, loss: 1.092298
global_step: 289, epoch: 8, loss: 1.022075
global_step: 290, epoch: 8, loss: 1.163059
global_step: 291, epoch: 8, loss: 1.144283
global_step: 292, epoch: 8, loss: 1.092724
global_step: 293, epoch: 8, loss: 1.022920
global_step: 294, epoch: 8, loss: 0.897340
global_step: 295, epoch: 8, loss: 1.229026
global_step: 296, epoch: 8, loss: 1.151010
global_step: 297, epoch: 8, loss: 1.104261
global_step: 298, epoch: 8, loss: 1.036720
global_step: 299, epoch: 8, loss: 1.120054
global_step: 300, epoch: 8, loss: 1.091980
global_step: 301, epoch: 8, loss: 1.045149
global_step: 302, epoch: 8, loss: 1.041013
global_step: 303, epoch: 8, loss: 1.064829
global_step: 304, epoch: 8, loss: 1.076908
global_step: 305, epoch: 8, loss: 0.910831
global_step: 306, epoch: 8, loss: 1.012544
global_step: 307, epoch: 8, loss: 1.023695
global_step: 308, epoch: 8, loss: 1.157853
global_step: 309, epoch: 8, loss: 1.173859
global_step: 310, epoch: 8, loss: 1.053775
global_step: 311, epoch: 8, loss: 0.898479
global_step: 312, epoch: 8, loss: 1.003788
global_step: 313, epoch: 8, loss: 0.983277
global_step: 314, epoch: 8, loss: 1.099680
global_step: 315, epoch: 8, loss: 1.022429
global_step: 316, epoch: 8, loss: 1.114770
global_step: 317, epoch: 8, loss: 1.173919
global_step: 318, epoch: 8, loss: 1.045248
global_step: 319, epoch: 8, loss: 1.123498
global_step: 320, epoch: 8, loss: 0.570104
epoch: 8
train	acc: 0.6470	macro: p 0.6177, r 0.3607, f1: 0.3588	micro: p 0.6470, r 0.6470, f1 0.6470	weighted_f1:0.5952
dev	acc: 0.5203	macro: p 0.3555, r 0.2782, f1: 0.2552	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4472
test	acc: 0.5816	macro: p 0.3914, r 0.3020, f1: 0.2842	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5194
global_step: 321, epoch: 9, loss: 1.222664
global_step: 322, epoch: 9, loss: 1.042523
global_step: 323, epoch: 9, loss: 1.008386
global_step: 324, epoch: 9, loss: 0.909020
global_step: 325, epoch: 9, loss: 0.938974
global_step: 326, epoch: 9, loss: 0.957952
global_step: 327, epoch: 9, loss: 1.061949
global_step: 328, epoch: 9, loss: 1.036819
global_step: 329, epoch: 9, loss: 0.890548
global_step: 330, epoch: 9, loss: 0.917354
global_step: 331, epoch: 9, loss: 0.959870
global_step: 332, epoch: 9, loss: 0.819689
global_step: 333, epoch: 9, loss: 1.035140
global_step: 334, epoch: 9, loss: 0.908733
global_step: 335, epoch: 9, loss: 0.989600
global_step: 336, epoch: 9, loss: 0.945920
global_step: 337, epoch: 9, loss: 1.099132
global_step: 338, epoch: 9, loss: 0.990946
global_step: 339, epoch: 9, loss: 0.953180
global_step: 340, epoch: 9, loss: 1.095287
global_step: 341, epoch: 9, loss: 1.017047
global_step: 342, epoch: 9, loss: 0.944545
global_step: 343, epoch: 9, loss: 1.009836
global_step: 344, epoch: 9, loss: 0.989754
global_step: 345, epoch: 9, loss: 1.035771
global_step: 346, epoch: 9, loss: 0.980844
global_step: 347, epoch: 9, loss: 1.064910
global_step: 348, epoch: 9, loss: 1.029008
global_step: 349, epoch: 9, loss: 1.023850
global_step: 350, epoch: 9, loss: 0.999798
global_step: 351, epoch: 9, loss: 0.987027
global_step: 352, epoch: 9, loss: 1.063377
global_step: 353, epoch: 9, loss: 1.036546
global_step: 354, epoch: 9, loss: 1.090489
global_step: 355, epoch: 9, loss: 0.964779
global_step: 356, epoch: 9, loss: 0.977409
global_step: 357, epoch: 9, loss: 1.043882
global_step: 358, epoch: 9, loss: 1.062093
global_step: 359, epoch: 9, loss: 0.980211
global_step: 360, epoch: 9, loss: 0.542985
epoch: 9
train	acc: 0.6431	macro: p 0.5237, r 0.3420, f1: 0.3569	micro: p 0.6431, r 0.6431, f1 0.6431	weighted_f1:0.5847
dev	acc: 0.5356	macro: p 0.4382, r 0.2719, f1: 0.2683	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4578
test	acc: 0.5943	macro: p 0.4228, r 0.2831, f1: 0.2891	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5235
global_step: 361, epoch: 10, loss: 1.333263
global_step: 362, epoch: 10, loss: 1.002285
global_step: 363, epoch: 10, loss: 0.918262
global_step: 364, epoch: 10, loss: 1.018886
global_step: 365, epoch: 10, loss: 0.886426
global_step: 366, epoch: 10, loss: 0.933904
global_step: 367, epoch: 10, loss: 0.850955
global_step: 368, epoch: 10, loss: 0.915190
global_step: 369, epoch: 10, loss: 0.947795
global_step: 370, epoch: 10, loss: 0.995471
global_step: 371, epoch: 10, loss: 0.885575
global_step: 372, epoch: 10, loss: 0.996656
global_step: 373, epoch: 10, loss: 0.968651
global_step: 374, epoch: 10, loss: 1.015631
global_step: 375, epoch: 10, loss: 0.951957
global_step: 376, epoch: 10, loss: 0.885239
global_step: 377, epoch: 10, loss: 0.976440
global_step: 378, epoch: 10, loss: 0.983285
global_step: 379, epoch: 10, loss: 0.940688
global_step: 380, epoch: 10, loss: 1.001775
global_step: 381, epoch: 10, loss: 0.875604
global_step: 382, epoch: 10, loss: 0.917841
global_step: 383, epoch: 10, loss: 0.954607
global_step: 384, epoch: 10, loss: 1.019562
global_step: 385, epoch: 10, loss: 0.926850
global_step: 386, epoch: 10, loss: 1.103082
global_step: 387, epoch: 10, loss: 0.930473
global_step: 388, epoch: 10, loss: 0.872695
global_step: 389, epoch: 10, loss: 0.913811
global_step: 390, epoch: 10, loss: 1.068915
global_step: 391, epoch: 10, loss: 1.090453
global_step: 392, epoch: 10, loss: 0.967982
global_step: 393, epoch: 10, loss: 0.850258
global_step: 394, epoch: 10, loss: 1.094641
global_step: 395, epoch: 10, loss: 0.922321
global_step: 396, epoch: 10, loss: 0.976080
global_step: 397, epoch: 10, loss: 0.984223
global_step: 398, epoch: 10, loss: 1.065472
global_step: 399, epoch: 10, loss: 1.013306
global_step: 400, epoch: 10, loss: 0.560903
epoch: 10
train	acc: 0.7011	macro: p 0.6592, r 0.4008, f1: 0.4219	micro: p 0.7011, r 0.7011, f1 0.7011	weighted_f1:0.6549
dev	acc: 0.5419	macro: p 0.3860, r 0.2804, f1: 0.2703	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4674
test	acc: 0.6004	macro: p 0.4190, r 0.2935, f1: 0.2931	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5336
global_step: 401, epoch: 11, loss: 0.951953
global_step: 402, epoch: 11, loss: 0.900097
global_step: 403, epoch: 11, loss: 1.007245
global_step: 404, epoch: 11, loss: 0.918628
global_step: 405, epoch: 11, loss: 0.813054
global_step: 406, epoch: 11, loss: 0.856952
global_step: 407, epoch: 11, loss: 0.879838
global_step: 408, epoch: 11, loss: 0.980918
global_step: 409, epoch: 11, loss: 0.825455
global_step: 410, epoch: 11, loss: 1.011314
global_step: 411, epoch: 11, loss: 0.938153
global_step: 412, epoch: 11, loss: 0.897598
global_step: 413, epoch: 11, loss: 0.960367
global_step: 414, epoch: 11, loss: 0.851467
global_step: 415, epoch: 11, loss: 0.922420
global_step: 416, epoch: 11, loss: 0.915780
global_step: 417, epoch: 11, loss: 0.915996
global_step: 418, epoch: 11, loss: 0.809271
global_step: 419, epoch: 11, loss: 0.863170
global_step: 420, epoch: 11, loss: 1.000081
global_step: 421, epoch: 11, loss: 0.870255
global_step: 422, epoch: 11, loss: 0.857560
global_step: 423, epoch: 11, loss: 0.920646
global_step: 424, epoch: 11, loss: 0.979950
global_step: 425, epoch: 11, loss: 0.985525
global_step: 426, epoch: 11, loss: 0.857497
global_step: 427, epoch: 11, loss: 0.855796
global_step: 428, epoch: 11, loss: 0.862226
global_step: 429, epoch: 11, loss: 0.997768
global_step: 430, epoch: 11, loss: 0.898823
global_step: 431, epoch: 11, loss: 0.968043
global_step: 432, epoch: 11, loss: 0.901736
global_step: 433, epoch: 11, loss: 0.936069
global_step: 434, epoch: 11, loss: 0.973225
global_step: 435, epoch: 11, loss: 0.936449
global_step: 436, epoch: 11, loss: 0.884063
global_step: 437, epoch: 11, loss: 0.951156
global_step: 438, epoch: 11, loss: 0.969419
global_step: 439, epoch: 11, loss: 0.904193
global_step: 440, epoch: 11, loss: 1.031122
epoch: 11
train	acc: 0.7393	macro: p 0.7713, r 0.5177, f1: 0.5654	micro: p 0.7393, r 0.7393, f1 0.7393	weighted_f1:0.7175
dev	acc: 0.5320	macro: p 0.3922, r 0.2918, f1: 0.2739	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4676
test	acc: 0.5720	macro: p 0.3729, r 0.2929, f1: 0.2810	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5158
global_step: 441, epoch: 12, loss: 0.889194
global_step: 442, epoch: 12, loss: 0.811964
global_step: 443, epoch: 12, loss: 0.769801
global_step: 444, epoch: 12, loss: 0.773241
global_step: 445, epoch: 12, loss: 0.809538
global_step: 446, epoch: 12, loss: 0.854476
global_step: 447, epoch: 12, loss: 1.010381
global_step: 448, epoch: 12, loss: 0.865182
global_step: 449, epoch: 12, loss: 0.848258
global_step: 450, epoch: 12, loss: 0.930757
global_step: 451, epoch: 12, loss: 0.794020
global_step: 452, epoch: 12, loss: 0.864414
global_step: 453, epoch: 12, loss: 0.855223
global_step: 454, epoch: 12, loss: 0.871110
global_step: 455, epoch: 12, loss: 0.903181
global_step: 456, epoch: 12, loss: 0.835934
global_step: 457, epoch: 12, loss: 0.782699
global_step: 458, epoch: 12, loss: 1.018877
global_step: 459, epoch: 12, loss: 0.894207
global_step: 460, epoch: 12, loss: 0.745404
global_step: 461, epoch: 12, loss: 0.871202
global_step: 462, epoch: 12, loss: 0.882975
global_step: 463, epoch: 12, loss: 0.826895
global_step: 464, epoch: 12, loss: 0.943168
global_step: 465, epoch: 12, loss: 0.883320
global_step: 466, epoch: 12, loss: 0.868114
global_step: 467, epoch: 12, loss: 0.878900
global_step: 468, epoch: 12, loss: 0.914604
global_step: 469, epoch: 12, loss: 0.833980
global_step: 470, epoch: 12, loss: 0.856156
global_step: 471, epoch: 12, loss: 0.854940
global_step: 472, epoch: 12, loss: 0.826078
global_step: 473, epoch: 12, loss: 0.879991
global_step: 474, epoch: 12, loss: 0.881595
global_step: 475, epoch: 12, loss: 0.885903
global_step: 476, epoch: 12, loss: 0.952066
global_step: 477, epoch: 12, loss: 0.913651
global_step: 478, epoch: 12, loss: 0.932574
global_step: 479, epoch: 12, loss: 0.866995
global_step: 480, epoch: 12, loss: 0.340380
epoch: 12
train	acc: 0.7498	macro: p 0.7990, r 0.5109, f1: 0.5408	micro: p 0.7498, r 0.7498, f1 0.7498	weighted_f1:0.7259
dev	acc: 0.5428	macro: p 0.3330, r 0.2926, f1: 0.2928	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4853
test	acc: 0.5839	macro: p 0.3294, r 0.2925, f1: 0.2978	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5332
global_step: 481, epoch: 13, loss: 1.052032
global_step: 482, epoch: 13, loss: 0.857303
global_step: 483, epoch: 13, loss: 0.699310
global_step: 484, epoch: 13, loss: 0.788809
global_step: 485, epoch: 13, loss: 0.767616
global_step: 486, epoch: 13, loss: 0.712399
global_step: 487, epoch: 13, loss: 1.020791
global_step: 488, epoch: 13, loss: 0.834035
global_step: 489, epoch: 13, loss: 0.874278
global_step: 490, epoch: 13, loss: 0.708268
global_step: 491, epoch: 13, loss: 0.807439
global_step: 492, epoch: 13, loss: 0.784733
global_step: 493, epoch: 13, loss: 0.771694
global_step: 494, epoch: 13, loss: 0.692385
global_step: 495, epoch: 13, loss: 0.915182
global_step: 496, epoch: 13, loss: 0.844754
global_step: 497, epoch: 13, loss: 1.029800
global_step: 498, epoch: 13, loss: 0.799232
global_step: 499, epoch: 13, loss: 0.802630
global_step: 500, epoch: 13, loss: 0.816097
global_step: 501, epoch: 13, loss: 0.944598
global_step: 502, epoch: 13, loss: 0.821865
global_step: 503, epoch: 13, loss: 0.801254
global_step: 504, epoch: 13, loss: 0.751838
global_step: 505, epoch: 13, loss: 0.779839
global_step: 506, epoch: 13, loss: 0.772986
global_step: 507, epoch: 13, loss: 0.771637
global_step: 508, epoch: 13, loss: 0.731943
global_step: 509, epoch: 13, loss: 0.866666
global_step: 510, epoch: 13, loss: 0.793789
global_step: 511, epoch: 13, loss: 0.871731
global_step: 512, epoch: 13, loss: 0.875399
global_step: 513, epoch: 13, loss: 0.781529
global_step: 514, epoch: 13, loss: 0.661844
global_step: 515, epoch: 13, loss: 1.102171
global_step: 516, epoch: 13, loss: 0.928452
global_step: 517, epoch: 13, loss: 0.867750
global_step: 518, epoch: 13, loss: 0.860362
global_step: 519, epoch: 13, loss: 0.931834
global_step: 520, epoch: 13, loss: 1.013245
epoch: 13
train	acc: 0.7921	macro: p 0.7758, r 0.6421, f1: 0.6454	micro: p 0.7921, r 0.7921, f1 0.7921	weighted_f1:0.7934
dev	acc: 0.4914	macro: p 0.3173, r 0.3177, f1: 0.3093	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4833
test	acc: 0.5330	macro: p 0.3388, r 0.3283, f1: 0.3238	micro: p 0.5330, r 0.5330, f1 0.5330	weighted_f1:0.5357
global_step: 521, epoch: 14, loss: 0.901501
global_step: 522, epoch: 14, loss: 0.794015
global_step: 523, epoch: 14, loss: 0.778403
global_step: 524, epoch: 14, loss: 0.723980
global_step: 525, epoch: 14, loss: 0.859850
global_step: 526, epoch: 14, loss: 0.674886
global_step: 527, epoch: 14, loss: 0.814432
global_step: 528, epoch: 14, loss: 0.833003
global_step: 529, epoch: 14, loss: 0.810360
global_step: 530, epoch: 14, loss: 0.795141
global_step: 531, epoch: 14, loss: 0.616567
global_step: 532, epoch: 14, loss: 0.825051
global_step: 533, epoch: 14, loss: 0.878781
global_step: 534, epoch: 14, loss: 0.737407
global_step: 535, epoch: 14, loss: 0.771603
global_step: 536, epoch: 14, loss: 0.643416
global_step: 537, epoch: 14, loss: 0.947966
global_step: 538, epoch: 14, loss: 0.727872
global_step: 539, epoch: 14, loss: 0.864736
global_step: 540, epoch: 14, loss: 0.826731
global_step: 541, epoch: 14, loss: 0.812913
global_step: 542, epoch: 14, loss: 0.809480
global_step: 543, epoch: 14, loss: 0.748650
global_step: 544, epoch: 14, loss: 0.719833
global_step: 545, epoch: 14, loss: 0.725393
global_step: 546, epoch: 14, loss: 0.721646
global_step: 547, epoch: 14, loss: 0.751212
global_step: 548, epoch: 14, loss: 0.883010
global_step: 549, epoch: 14, loss: 0.713373
global_step: 550, epoch: 14, loss: 0.718777
global_step: 551, epoch: 14, loss: 0.587234
global_step: 552, epoch: 14, loss: 0.840663
global_step: 553, epoch: 14, loss: 0.966495
global_step: 554, epoch: 14, loss: 0.876989
global_step: 555, epoch: 14, loss: 0.876500
global_step: 556, epoch: 14, loss: 0.892981
global_step: 557, epoch: 14, loss: 0.845199
global_step: 558, epoch: 14, loss: 0.884526
global_step: 559, epoch: 14, loss: 0.765750
global_step: 560, epoch: 14, loss: 1.369515
epoch: 14
train	acc: 0.8060	macro: p 0.8224, r 0.6361, f1: 0.6552	micro: p 0.8060, r 0.8060, f1 0.8060	weighted_f1:0.8049
dev	acc: 0.5113	macro: p 0.3339, r 0.3169, f1: 0.3054	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4899
test	acc: 0.5264	macro: p 0.3381, r 0.3194, f1: 0.3102	micro: p 0.5264, r 0.5264, f1 0.5264	weighted_f1:0.5189
global_step: 561, epoch: 15, loss: 0.724816
global_step: 562, epoch: 15, loss: 0.612043
global_step: 563, epoch: 15, loss: 0.705230
global_step: 564, epoch: 15, loss: 0.744264
global_step: 565, epoch: 15, loss: 0.709377
global_step: 566, epoch: 15, loss: 0.769764
global_step: 567, epoch: 15, loss: 0.777887
global_step: 568, epoch: 15, loss: 0.604706
global_step: 569, epoch: 15, loss: 0.750502
global_step: 570, epoch: 15, loss: 0.578755
global_step: 571, epoch: 15, loss: 0.773643
global_step: 572, epoch: 15, loss: 0.652397
global_step: 573, epoch: 15, loss: 0.757469
global_step: 574, epoch: 15, loss: 0.840579
global_step: 575, epoch: 15, loss: 0.737967
global_step: 576, epoch: 15, loss: 0.721124
global_step: 577, epoch: 15, loss: 0.805830
global_step: 578, epoch: 15, loss: 0.764684
global_step: 579, epoch: 15, loss: 0.686582
global_step: 580, epoch: 15, loss: 0.728334
global_step: 581, epoch: 15, loss: 0.726314
global_step: 582, epoch: 15, loss: 0.846729
global_step: 583, epoch: 15, loss: 0.838293
global_step: 584, epoch: 15, loss: 0.745566
global_step: 585, epoch: 15, loss: 0.813811
global_step: 586, epoch: 15, loss: 0.861747
global_step: 587, epoch: 15, loss: 0.773119
global_step: 588, epoch: 15, loss: 0.869903
global_step: 589, epoch: 15, loss: 0.810080
global_step: 590, epoch: 15, loss: 0.826900
global_step: 591, epoch: 15, loss: 0.723868
global_step: 592, epoch: 15, loss: 0.680645
global_step: 593, epoch: 15, loss: 0.805716
global_step: 594, epoch: 15, loss: 0.718153
global_step: 595, epoch: 15, loss: 0.648430
global_step: 596, epoch: 15, loss: 0.771541
global_step: 597, epoch: 15, loss: 0.891503
global_step: 598, epoch: 15, loss: 0.799926
global_step: 599, epoch: 15, loss: 0.718896
global_step: 600, epoch: 15, loss: 0.094269
epoch: 15
train	acc: 0.8252	macro: p 0.8606, r 0.6778, f1: 0.7334	micro: p 0.8252, r 0.8252, f1 0.8252	weighted_f1:0.8207
dev	acc: 0.5212	macro: p 0.3338, r 0.2859, f1: 0.2687	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4620
test	acc: 0.5762	macro: p 0.4342, r 0.3049, f1: 0.3051	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5304
global_step: 601, epoch: 16, loss: 0.724299
global_step: 602, epoch: 16, loss: 0.668634
global_step: 603, epoch: 16, loss: 0.664075
global_step: 604, epoch: 16, loss: 0.666140
global_step: 605, epoch: 16, loss: 0.668802
global_step: 606, epoch: 16, loss: 0.670579
global_step: 607, epoch: 16, loss: 0.781458
global_step: 608, epoch: 16, loss: 0.672368
global_step: 609, epoch: 16, loss: 0.702422
global_step: 610, epoch: 16, loss: 0.661120
global_step: 611, epoch: 16, loss: 0.606002
global_step: 612, epoch: 16, loss: 0.757513
global_step: 613, epoch: 16, loss: 0.679420
global_step: 614, epoch: 16, loss: 0.712638
global_step: 615, epoch: 16, loss: 0.714801
global_step: 616, epoch: 16, loss: 0.727968
global_step: 617, epoch: 16, loss: 0.669060
global_step: 618, epoch: 16, loss: 0.690358
global_step: 619, epoch: 16, loss: 0.714336
global_step: 620, epoch: 16, loss: 0.794758
global_step: 621, epoch: 16, loss: 0.898621
global_step: 622, epoch: 16, loss: 0.661061
global_step: 623, epoch: 16, loss: 0.803790
global_step: 624, epoch: 16, loss: 0.787871
global_step: 625, epoch: 16, loss: 0.874590
global_step: 626, epoch: 16, loss: 0.825967
global_step: 627, epoch: 16, loss: 0.777843
global_step: 628, epoch: 16, loss: 0.803145
global_step: 629, epoch: 16, loss: 0.754260
global_step: 630, epoch: 16, loss: 0.637957
global_step: 631, epoch: 16, loss: 0.879682
global_step: 632, epoch: 16, loss: 0.754297
global_step: 633, epoch: 16, loss: 0.708451
global_step: 634, epoch: 16, loss: 0.727253
global_step: 635, epoch: 16, loss: 0.722791
global_step: 636, epoch: 16, loss: 0.679708
global_step: 637, epoch: 16, loss: 0.913851
global_step: 638, epoch: 16, loss: 0.700813
global_step: 639, epoch: 16, loss: 0.780001
global_step: 640, epoch: 16, loss: 1.075869
epoch: 16
train	acc: 0.8134	macro: p 0.8713, r 0.6171, f1: 0.6842	micro: p 0.8134, r 0.8134, f1 0.8134	weighted_f1:0.7985
dev	acc: 0.5203	macro: p 0.4668, r 0.2792, f1: 0.2638	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4472
test	acc: 0.5820	macro: p 0.3742, r 0.2895, f1: 0.2802	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5181
global_step: 641, epoch: 17, loss: 0.875313
global_step: 642, epoch: 17, loss: 0.734574
global_step: 643, epoch: 17, loss: 0.623795
global_step: 644, epoch: 17, loss: 0.630099
global_step: 645, epoch: 17, loss: 0.633209
global_step: 646, epoch: 17, loss: 0.694307
global_step: 647, epoch: 17, loss: 0.645550
global_step: 648, epoch: 17, loss: 0.585907
global_step: 649, epoch: 17, loss: 0.756048
global_step: 650, epoch: 17, loss: 0.577674
global_step: 651, epoch: 17, loss: 0.752395
global_step: 652, epoch: 17, loss: 0.640339
global_step: 653, epoch: 17, loss: 0.713394
global_step: 654, epoch: 17, loss: 0.736003
global_step: 655, epoch: 17, loss: 0.859917
global_step: 656, epoch: 17, loss: 0.698744
global_step: 657, epoch: 17, loss: 0.713768
global_step: 658, epoch: 17, loss: 0.695105
global_step: 659, epoch: 17, loss: 0.727046
global_step: 660, epoch: 17, loss: 0.726359
global_step: 661, epoch: 17, loss: 0.776554
global_step: 662, epoch: 17, loss: 0.703522
global_step: 663, epoch: 17, loss: 0.671974
global_step: 664, epoch: 17, loss: 0.730610
global_step: 665, epoch: 17, loss: 0.746958
global_step: 666, epoch: 17, loss: 0.633770
global_step: 667, epoch: 17, loss: 0.756136
global_step: 668, epoch: 17, loss: 0.674993
global_step: 669, epoch: 17, loss: 0.675706
global_step: 670, epoch: 17, loss: 0.586466
global_step: 671, epoch: 17, loss: 0.690607
global_step: 672, epoch: 17, loss: 0.746556
global_step: 673, epoch: 17, loss: 0.684967
global_step: 674, epoch: 17, loss: 0.590070
global_step: 675, epoch: 17, loss: 0.753413
global_step: 676, epoch: 17, loss: 0.828436
global_step: 677, epoch: 17, loss: 0.759382
global_step: 678, epoch: 17, loss: 0.741887
global_step: 679, epoch: 17, loss: 0.857222
global_step: 680, epoch: 17, loss: 0.300976
epoch: 17
train	acc: 0.8632	macro: p 0.8927, r 0.7437, f1: 0.7983	micro: p 0.8632, r 0.8632, f1 0.8632	weighted_f1:0.8590
dev	acc: 0.5257	macro: p 0.2959, r 0.2843, f1: 0.2734	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4670
test	acc: 0.5877	macro: p 0.3487, r 0.3035, f1: 0.3054	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5377
global_step: 681, epoch: 18, loss: 0.614209
global_step: 682, epoch: 18, loss: 0.689424
global_step: 683, epoch: 18, loss: 0.708438
global_step: 684, epoch: 18, loss: 0.646012
global_step: 685, epoch: 18, loss: 0.722085
global_step: 686, epoch: 18, loss: 0.650304
global_step: 687, epoch: 18, loss: 0.591307
global_step: 688, epoch: 18, loss: 0.605706
global_step: 689, epoch: 18, loss: 0.599740
global_step: 690, epoch: 18, loss: 0.632364
global_step: 691, epoch: 18, loss: 0.540913
global_step: 692, epoch: 18, loss: 0.617216
global_step: 693, epoch: 18, loss: 0.650882
global_step: 694, epoch: 18, loss: 0.696414
global_step: 695, epoch: 18, loss: 0.619110
global_step: 696, epoch: 18, loss: 0.683236
global_step: 697, epoch: 18, loss: 0.651276
global_step: 698, epoch: 18, loss: 0.546410
global_step: 699, epoch: 18, loss: 0.719152
global_step: 700, epoch: 18, loss: 0.742211
global_step: 701, epoch: 18, loss: 0.715706
global_step: 702, epoch: 18, loss: 0.668337
global_step: 703, epoch: 18, loss: 0.756314
global_step: 704, epoch: 18, loss: 0.708740
global_step: 705, epoch: 18, loss: 0.653287
global_step: 706, epoch: 18, loss: 0.689033
global_step: 707, epoch: 18, loss: 0.742494
global_step: 708, epoch: 18, loss: 0.578850
global_step: 709, epoch: 18, loss: 0.638271
global_step: 710, epoch: 18, loss: 0.774385
global_step: 711, epoch: 18, loss: 0.636464
global_step: 712, epoch: 18, loss: 0.805599
global_step: 713, epoch: 18, loss: 0.679819
global_step: 714, epoch: 18, loss: 0.703108
global_step: 715, epoch: 18, loss: 0.634410
global_step: 716, epoch: 18, loss: 0.642356
global_step: 717, epoch: 18, loss: 0.701387
global_step: 718, epoch: 18, loss: 0.787312
global_step: 719, epoch: 18, loss: 0.736531
global_step: 720, epoch: 18, loss: 0.033382
epoch: 18
train	acc: 0.8896	macro: p 0.9032, r 0.7989, f1: 0.8418	micro: p 0.8896, r 0.8896, f1 0.8896	weighted_f1:0.8872
dev	acc: 0.5338	macro: p 0.3728, r 0.3045, f1: 0.3023	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4765
test	acc: 0.5916	macro: p 0.3955, r 0.3085, f1: 0.3131	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5416
global_step: 721, epoch: 19, loss: 0.503303
global_step: 722, epoch: 19, loss: 0.623521
global_step: 723, epoch: 19, loss: 0.593238
global_step: 724, epoch: 19, loss: 0.575889
global_step: 725, epoch: 19, loss: 0.640633
global_step: 726, epoch: 19, loss: 0.680399
global_step: 727, epoch: 19, loss: 0.634669
global_step: 728, epoch: 19, loss: 0.692198
global_step: 729, epoch: 19, loss: 0.547514
global_step: 730, epoch: 19, loss: 0.561584
global_step: 731, epoch: 19, loss: 0.708215
global_step: 732, epoch: 19, loss: 0.685823
global_step: 733, epoch: 19, loss: 0.574595
global_step: 734, epoch: 19, loss: 0.679474
global_step: 735, epoch: 19, loss: 0.650673
global_step: 736, epoch: 19, loss: 0.605247
global_step: 737, epoch: 19, loss: 0.609379
global_step: 738, epoch: 19, loss: 0.722478
global_step: 739, epoch: 19, loss: 0.765090
global_step: 740, epoch: 19, loss: 0.592303
global_step: 741, epoch: 19, loss: 0.580587
global_step: 742, epoch: 19, loss: 0.664453
global_step: 743, epoch: 19, loss: 0.684869
global_step: 744, epoch: 19, loss: 0.508775
global_step: 745, epoch: 19, loss: 0.609499
global_step: 746, epoch: 19, loss: 0.656737
global_step: 747, epoch: 19, loss: 0.592937
global_step: 748, epoch: 19, loss: 0.667659
global_step: 749, epoch: 19, loss: 0.730322
global_step: 750, epoch: 19, loss: 0.634194
global_step: 751, epoch: 19, loss: 0.626907
global_step: 752, epoch: 19, loss: 0.630668
global_step: 753, epoch: 19, loss: 0.695422
global_step: 754, epoch: 19, loss: 0.691537
global_step: 755, epoch: 19, loss: 0.620338
global_step: 756, epoch: 19, loss: 0.698078
global_step: 757, epoch: 19, loss: 0.623133
global_step: 758, epoch: 19, loss: 0.649842
global_step: 759, epoch: 19, loss: 0.717415
global_step: 760, epoch: 19, loss: 0.476786
epoch: 19
train	acc: 0.8502	macro: p 0.8342, r 0.7644, f1: 0.7676	micro: p 0.8502, r 0.8502, f1 0.8502	weighted_f1:0.8539
dev	acc: 0.4689	macro: p 0.3282, r 0.3108, f1: 0.3069	micro: p 0.4689, r 0.4689, f1 0.4689	weighted_f1:0.4732
test	acc: 0.5195	macro: p 0.3269, r 0.3354, f1: 0.3248	micro: p 0.5195, r 0.5195, f1 0.5195	weighted_f1:0.5275
global_step: 761, epoch: 20, loss: 0.674730
global_step: 762, epoch: 20, loss: 0.676911
global_step: 763, epoch: 20, loss: 0.560306
global_step: 764, epoch: 20, loss: 0.555014
global_step: 765, epoch: 20, loss: 0.497145
global_step: 766, epoch: 20, loss: 0.750592
global_step: 767, epoch: 20, loss: 0.568382
global_step: 768, epoch: 20, loss: 0.558214
global_step: 769, epoch: 20, loss: 0.557704
global_step: 770, epoch: 20, loss: 0.555067
global_step: 771, epoch: 20, loss: 0.844833
global_step: 772, epoch: 20, loss: 0.643070
global_step: 773, epoch: 20, loss: 0.533532
global_step: 774, epoch: 20, loss: 0.472318
global_step: 775, epoch: 20, loss: 0.622427
global_step: 776, epoch: 20, loss: 0.578277
global_step: 777, epoch: 20, loss: 0.576658
global_step: 778, epoch: 20, loss: 0.556030
global_step: 779, epoch: 20, loss: 0.512588
global_step: 780, epoch: 20, loss: 0.628727
global_step: 781, epoch: 20, loss: 0.631389
global_step: 782, epoch: 20, loss: 0.576600
global_step: 783, epoch: 20, loss: 0.561105
global_step: 784, epoch: 20, loss: 0.728542
global_step: 785, epoch: 20, loss: 0.590801
global_step: 786, epoch: 20, loss: 0.710323
global_step: 787, epoch: 20, loss: 0.552288
global_step: 788, epoch: 20, loss: 0.607564
global_step: 789, epoch: 20, loss: 0.604343
global_step: 790, epoch: 20, loss: 0.734725
global_step: 791, epoch: 20, loss: 0.634734
global_step: 792, epoch: 20, loss: 0.691923
global_step: 793, epoch: 20, loss: 0.658455
global_step: 794, epoch: 20, loss: 0.618700
global_step: 795, epoch: 20, loss: 0.711803
global_step: 796, epoch: 20, loss: 0.566480
global_step: 797, epoch: 20, loss: 0.568140
global_step: 798, epoch: 20, loss: 0.624359
global_step: 799, epoch: 20, loss: 0.680264
global_step: 800, epoch: 20, loss: 0.228435
epoch: 20
train	acc: 0.8357	macro: p 0.9029, r 0.6859, f1: 0.7587	micro: p 0.8357, r 0.8357, f1 0.8357	weighted_f1:0.8285
dev	acc: 0.5410	macro: p 0.3566, r 0.2842, f1: 0.2807	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4733
test	acc: 0.5989	macro: p 0.4495, r 0.2934, f1: 0.3024	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5349
global_step: 801, epoch: 21, loss: 0.703539
global_step: 802, epoch: 21, loss: 0.575594
global_step: 803, epoch: 21, loss: 0.558576
global_step: 804, epoch: 21, loss: 0.647242
global_step: 805, epoch: 21, loss: 0.577939
global_step: 806, epoch: 21, loss: 0.466161
global_step: 807, epoch: 21, loss: 0.486346
global_step: 808, epoch: 21, loss: 0.530446
global_step: 809, epoch: 21, loss: 0.637020
global_step: 810, epoch: 21, loss: 0.556827
global_step: 811, epoch: 21, loss: 0.530945
global_step: 812, epoch: 21, loss: 0.499420
global_step: 813, epoch: 21, loss: 0.515532
global_step: 814, epoch: 21, loss: 0.616764
global_step: 815, epoch: 21, loss: 0.657663
global_step: 816, epoch: 21, loss: 0.593757
global_step: 817, epoch: 21, loss: 0.522096
global_step: 818, epoch: 21, loss: 0.545760
global_step: 819, epoch: 21, loss: 0.568221
global_step: 820, epoch: 21, loss: 0.566061
global_step: 821, epoch: 21, loss: 0.554447
global_step: 822, epoch: 21, loss: 0.589658
global_step: 823, epoch: 21, loss: 0.513737
global_step: 824, epoch: 21, loss: 0.633775
global_step: 825, epoch: 21, loss: 0.486064
global_step: 826, epoch: 21, loss: 0.653890
global_step: 827, epoch: 21, loss: 0.641800
global_step: 828, epoch: 21, loss: 0.582436
global_step: 829, epoch: 21, loss: 0.591254
global_step: 830, epoch: 21, loss: 0.616504
global_step: 831, epoch: 21, loss: 0.728199
global_step: 832, epoch: 21, loss: 0.696831
global_step: 833, epoch: 21, loss: 0.571589
global_step: 834, epoch: 21, loss: 0.676713
global_step: 835, epoch: 21, loss: 0.729273
global_step: 836, epoch: 21, loss: 0.607537
global_step: 837, epoch: 21, loss: 0.429947
global_step: 838, epoch: 21, loss: 0.632817
global_step: 839, epoch: 21, loss: 0.607256
global_step: 840, epoch: 21, loss: 0.152841
epoch: 21
train	acc: 0.8787	macro: p 0.9078, r 0.7825, f1: 0.8300	micro: p 0.8787, r 0.8787, f1 0.8787	weighted_f1:0.8754
dev	acc: 0.5293	macro: p 0.3749, r 0.2873, f1: 0.2819	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4720
test	acc: 0.5866	macro: p 0.3747, r 0.2955, f1: 0.2968	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5347
global_step: 841, epoch: 22, loss: 0.621356
global_step: 842, epoch: 22, loss: 0.488902
global_step: 843, epoch: 22, loss: 0.607088
global_step: 844, epoch: 22, loss: 0.585370
global_step: 845, epoch: 22, loss: 0.600714
global_step: 846, epoch: 22, loss: 0.616979
global_step: 847, epoch: 22, loss: 0.477505
global_step: 848, epoch: 22, loss: 0.528358
global_step: 849, epoch: 22, loss: 0.435259
global_step: 850, epoch: 22, loss: 0.513438
global_step: 851, epoch: 22, loss: 0.489209
global_step: 852, epoch: 22, loss: 0.568709
global_step: 853, epoch: 22, loss: 0.497891
global_step: 854, epoch: 22, loss: 0.536004
global_step: 855, epoch: 22, loss: 0.598982
global_step: 856, epoch: 22, loss: 0.540125
global_step: 857, epoch: 22, loss: 0.553485
global_step: 858, epoch: 22, loss: 0.483312
global_step: 859, epoch: 22, loss: 0.493831
global_step: 860, epoch: 22, loss: 0.634586
global_step: 861, epoch: 22, loss: 0.555895
global_step: 862, epoch: 22, loss: 0.531408
global_step: 863, epoch: 22, loss: 0.674011
global_step: 864, epoch: 22, loss: 0.582756
global_step: 865, epoch: 22, loss: 0.500070
global_step: 866, epoch: 22, loss: 0.683911
global_step: 867, epoch: 22, loss: 0.585524
global_step: 868, epoch: 22, loss: 0.557848
global_step: 869, epoch: 22, loss: 0.576013
global_step: 870, epoch: 22, loss: 0.566860
global_step: 871, epoch: 22, loss: 0.588799
global_step: 872, epoch: 22, loss: 0.615548
global_step: 873, epoch: 22, loss: 0.466190
global_step: 874, epoch: 22, loss: 0.648298
global_step: 875, epoch: 22, loss: 0.615171
global_step: 876, epoch: 22, loss: 0.580131
global_step: 877, epoch: 22, loss: 0.472026
global_step: 878, epoch: 22, loss: 0.767945
global_step: 879, epoch: 22, loss: 0.596164
global_step: 880, epoch: 22, loss: 0.692609
epoch: 22
train	acc: 0.9082	macro: p 0.9238, r 0.8326, f1: 0.8702	micro: p 0.9082, r 0.9082, f1 0.9082	weighted_f1:0.9071
dev	acc: 0.5383	macro: p 0.3572, r 0.3035, f1: 0.3076	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4923
test	acc: 0.5854	macro: p 0.3413, r 0.3057, f1: 0.3104	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5425
global_step: 881, epoch: 23, loss: 0.516700
global_step: 882, epoch: 23, loss: 0.504138
global_step: 883, epoch: 23, loss: 0.514121
global_step: 884, epoch: 23, loss: 0.596814
global_step: 885, epoch: 23, loss: 0.507588
global_step: 886, epoch: 23, loss: 0.534083
global_step: 887, epoch: 23, loss: 0.463967
global_step: 888, epoch: 23, loss: 0.608686
global_step: 889, epoch: 23, loss: 0.670301
global_step: 890, epoch: 23, loss: 0.556779
global_step: 891, epoch: 23, loss: 0.551062
global_step: 892, epoch: 23, loss: 0.437060
global_step: 893, epoch: 23, loss: 0.461550
global_step: 894, epoch: 23, loss: 0.608685
global_step: 895, epoch: 23, loss: 0.609607
global_step: 896, epoch: 23, loss: 0.498370
global_step: 897, epoch: 23, loss: 0.513904
global_step: 898, epoch: 23, loss: 0.484622
global_step: 899, epoch: 23, loss: 0.505625
global_step: 900, epoch: 23, loss: 0.526021
global_step: 901, epoch: 23, loss: 0.643814
global_step: 902, epoch: 23, loss: 0.549544
global_step: 903, epoch: 23, loss: 0.459637
global_step: 904, epoch: 23, loss: 0.590105
global_step: 905, epoch: 23, loss: 0.494722
global_step: 906, epoch: 23, loss: 0.561280
global_step: 907, epoch: 23, loss: 0.642456
global_step: 908, epoch: 23, loss: 0.579915
global_step: 909, epoch: 23, loss: 0.533034
global_step: 910, epoch: 23, loss: 0.549116
global_step: 911, epoch: 23, loss: 0.432708
global_step: 912, epoch: 23, loss: 0.583653
global_step: 913, epoch: 23, loss: 0.579401
global_step: 914, epoch: 23, loss: 0.617644
global_step: 915, epoch: 23, loss: 0.608309
global_step: 916, epoch: 23, loss: 0.553923
global_step: 917, epoch: 23, loss: 0.590308
global_step: 918, epoch: 23, loss: 0.581142
global_step: 919, epoch: 23, loss: 0.589845
global_step: 920, epoch: 23, loss: 0.396594
epoch: 23
train	acc: 0.8624	macro: p 0.8900, r 0.7860, f1: 0.8165	micro: p 0.8624, r 0.8624, f1 0.8624	weighted_f1:0.8648
dev	acc: 0.4689	macro: p 0.3517, r 0.2940, f1: 0.2792	micro: p 0.4689, r 0.4689, f1 0.4689	weighted_f1:0.4524
test	acc: 0.4900	macro: p 0.3510, r 0.3003, f1: 0.2903	micro: p 0.4900, r 0.4900, f1 0.4900	weighted_f1:0.4842
global_step: 921, epoch: 24, loss: 0.715784
global_step: 922, epoch: 24, loss: 0.563847
global_step: 923, epoch: 24, loss: 0.588351
global_step: 924, epoch: 24, loss: 0.599991
global_step: 925, epoch: 24, loss: 0.477204
global_step: 926, epoch: 24, loss: 0.532623
global_step: 927, epoch: 24, loss: 0.501853
global_step: 928, epoch: 24, loss: 0.508410
global_step: 929, epoch: 24, loss: 0.524546
global_step: 930, epoch: 24, loss: 0.571149
global_step: 931, epoch: 24, loss: 0.446173
global_step: 932, epoch: 24, loss: 0.534451
global_step: 933, epoch: 24, loss: 0.571063
global_step: 934, epoch: 24, loss: 0.636947
global_step: 935, epoch: 24, loss: 0.586101
global_step: 936, epoch: 24, loss: 0.539111
global_step: 937, epoch: 24, loss: 0.468660
global_step: 938, epoch: 24, loss: 0.616826
global_step: 939, epoch: 24, loss: 0.470421
global_step: 940, epoch: 24, loss: 0.501519
global_step: 941, epoch: 24, loss: 0.496789
global_step: 942, epoch: 24, loss: 0.500449
global_step: 943, epoch: 24, loss: 0.465034
global_step: 944, epoch: 24, loss: 0.455396
global_step: 945, epoch: 24, loss: 0.566718
global_step: 946, epoch: 24, loss: 0.596067
global_step: 947, epoch: 24, loss: 0.571886
global_step: 948, epoch: 24, loss: 0.529697
global_step: 949, epoch: 24, loss: 0.534345
global_step: 950, epoch: 24, loss: 0.571093
global_step: 951, epoch: 24, loss: 0.557428
global_step: 952, epoch: 24, loss: 0.590482
global_step: 953, epoch: 24, loss: 0.639601
global_step: 954, epoch: 24, loss: 0.577529
global_step: 955, epoch: 24, loss: 0.455373
global_step: 956, epoch: 24, loss: 0.656504
global_step: 957, epoch: 24, loss: 0.579751
global_step: 958, epoch: 24, loss: 0.534372
global_step: 959, epoch: 24, loss: 0.592248
global_step: 960, epoch: 24, loss: 0.127639
epoch: 24
train	acc: 0.9203	macro: p 0.9380, r 0.8630, f1: 0.8960	micro: p 0.9203, r 0.9203, f1 0.9203	weighted_f1:0.9195
dev	acc: 0.5230	macro: p 0.3615, r 0.2866, f1: 0.2798	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4650
test	acc: 0.5854	macro: p 0.4149, r 0.3015, f1: 0.3069	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5322
global_step: 961, epoch: 25, loss: 0.479939
global_step: 962, epoch: 25, loss: 0.556019
global_step: 963, epoch: 25, loss: 0.436335
global_step: 964, epoch: 25, loss: 0.391471
global_step: 965, epoch: 25, loss: 0.475445
global_step: 966, epoch: 25, loss: 0.430956
global_step: 967, epoch: 25, loss: 0.509383
global_step: 968, epoch: 25, loss: 0.514952
global_step: 969, epoch: 25, loss: 0.464476
global_step: 970, epoch: 25, loss: 0.497402
global_step: 971, epoch: 25, loss: 0.502273
global_step: 972, epoch: 25, loss: 0.434555
global_step: 973, epoch: 25, loss: 0.489355
global_step: 974, epoch: 25, loss: 0.414545
global_step: 975, epoch: 25, loss: 0.522739
global_step: 976, epoch: 25, loss: 0.457153
global_step: 977, epoch: 25, loss: 0.408334
global_step: 978, epoch: 25, loss: 0.491993
global_step: 979, epoch: 25, loss: 0.543434
global_step: 980, epoch: 25, loss: 0.627677
global_step: 981, epoch: 25, loss: 0.599020
global_step: 982, epoch: 25, loss: 0.491957
global_step: 983, epoch: 25, loss: 0.625349
global_step: 984, epoch: 25, loss: 0.536255
global_step: 985, epoch: 25, loss: 0.456179
global_step: 986, epoch: 25, loss: 0.442567
global_step: 987, epoch: 25, loss: 0.483020
global_step: 988, epoch: 25, loss: 0.516720
global_step: 989, epoch: 25, loss: 0.530827
global_step: 990, epoch: 25, loss: 0.515668
global_step: 991, epoch: 25, loss: 0.494665
global_step: 992, epoch: 25, loss: 0.464528
global_step: 993, epoch: 25, loss: 0.525491
global_step: 994, epoch: 25, loss: 0.592351
global_step: 995, epoch: 25, loss: 0.530625
global_step: 996, epoch: 25, loss: 0.606547
global_step: 997, epoch: 25, loss: 0.468755
global_step: 998, epoch: 25, loss: 0.484310
global_step: 999, epoch: 25, loss: 0.540122
global_step: 1000, epoch: 25, loss: 1.385794
epoch: 25
train	acc: 0.9137	macro: p 0.9118, r 0.8596, f1: 0.8790	micro: p 0.9137, r 0.9137, f1 0.9137	weighted_f1:0.9137
dev	acc: 0.5158	macro: p 0.4173, r 0.3358, f1: 0.3374	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4906
test	acc: 0.5330	macro: p 0.3359, r 0.3118, f1: 0.3005	micro: p 0.5330, r 0.5330, f1 0.5330	weighted_f1:0.5146
global_step: 1001, epoch: 26, loss: 0.517478
global_step: 1002, epoch: 26, loss: 0.507882
global_step: 1003, epoch: 26, loss: 0.465230
global_step: 1004, epoch: 26, loss: 0.428190
global_step: 1005, epoch: 26, loss: 0.462025
global_step: 1006, epoch: 26, loss: 0.375958
global_step: 1007, epoch: 26, loss: 0.372228
global_step: 1008, epoch: 26, loss: 0.489385
global_step: 1009, epoch: 26, loss: 0.540387
global_step: 1010, epoch: 26, loss: 0.470172
global_step: 1011, epoch: 26, loss: 0.406165
global_step: 1012, epoch: 26, loss: 0.380080
global_step: 1013, epoch: 26, loss: 0.535094
global_step: 1014, epoch: 26, loss: 0.523862
global_step: 1015, epoch: 26, loss: 0.543087
global_step: 1016, epoch: 26, loss: 0.501360
global_step: 1017, epoch: 26, loss: 0.566505
global_step: 1018, epoch: 26, loss: 0.476437
global_step: 1019, epoch: 26, loss: 0.468197
global_step: 1020, epoch: 26, loss: 0.494949
global_step: 1021, epoch: 26, loss: 0.459258
global_step: 1022, epoch: 26, loss: 0.584201
global_step: 1023, epoch: 26, loss: 0.447371
global_step: 1024, epoch: 26, loss: 0.442112
global_step: 1025, epoch: 26, loss: 0.526692
global_step: 1026, epoch: 26, loss: 0.537522
global_step: 1027, epoch: 26, loss: 0.613813
global_step: 1028, epoch: 26, loss: 0.629618
global_step: 1029, epoch: 26, loss: 0.386570
global_step: 1030, epoch: 26, loss: 0.483253
global_step: 1031, epoch: 26, loss: 0.431458
global_step: 1032, epoch: 26, loss: 0.410932
global_step: 1033, epoch: 26, loss: 0.596415
global_step: 1034, epoch: 26, loss: 0.502102
global_step: 1035, epoch: 26, loss: 0.472199
global_step: 1036, epoch: 26, loss: 0.562185
global_step: 1037, epoch: 26, loss: 0.626706
global_step: 1038, epoch: 26, loss: 0.481859
global_step: 1039, epoch: 26, loss: 0.495474
global_step: 1040, epoch: 26, loss: 0.474634
epoch: 26
train	acc: 0.9418	macro: p 0.9316, r 0.9133, f1: 0.9214	micro: p 0.9418, r 0.9418, f1 0.9418	weighted_f1:0.9418
dev	acc: 0.5338	macro: p 0.4073, r 0.3385, f1: 0.3511	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.5034
test	acc: 0.5567	macro: p 0.3396, r 0.3165, f1: 0.3191	micro: p 0.5567, r 0.5567, f1 0.5567	weighted_f1:0.5299
New best model!
global_step: 1041, epoch: 27, loss: 0.467827
global_step: 1042, epoch: 27, loss: 0.475380
global_step: 1043, epoch: 27, loss: 0.443371
global_step: 1044, epoch: 27, loss: 0.427566
global_step: 1045, epoch: 27, loss: 0.476758
global_step: 1046, epoch: 27, loss: 0.434467
global_step: 1047, epoch: 27, loss: 0.535181
global_step: 1048, epoch: 27, loss: 0.466569
global_step: 1049, epoch: 27, loss: 0.463691
global_step: 1050, epoch: 27, loss: 0.467068
global_step: 1051, epoch: 27, loss: 0.652821
global_step: 1052, epoch: 27, loss: 0.387260
global_step: 1053, epoch: 27, loss: 0.460050
global_step: 1054, epoch: 27, loss: 0.378820
global_step: 1055, epoch: 27, loss: 0.429100
global_step: 1056, epoch: 27, loss: 0.525632
global_step: 1057, epoch: 27, loss: 0.484568
global_step: 1058, epoch: 27, loss: 0.543921
global_step: 1059, epoch: 27, loss: 0.447553
global_step: 1060, epoch: 27, loss: 0.433834
global_step: 1061, epoch: 27, loss: 0.538900
global_step: 1062, epoch: 27, loss: 0.396515
global_step: 1063, epoch: 27, loss: 0.620906
global_step: 1064, epoch: 27, loss: 0.558667
global_step: 1065, epoch: 27, loss: 0.522224
global_step: 1066, epoch: 27, loss: 0.501159
global_step: 1067, epoch: 27, loss: 0.460027
global_step: 1068, epoch: 27, loss: 0.435527
global_step: 1069, epoch: 27, loss: 0.500815
global_step: 1070, epoch: 27, loss: 0.476788
global_step: 1071, epoch: 27, loss: 0.466868
global_step: 1072, epoch: 27, loss: 0.492196
global_step: 1073, epoch: 27, loss: 0.481828
global_step: 1074, epoch: 27, loss: 0.510449
global_step: 1075, epoch: 27, loss: 0.390121
global_step: 1076, epoch: 27, loss: 0.489786
global_step: 1077, epoch: 27, loss: 0.380157
global_step: 1078, epoch: 27, loss: 0.490891
global_step: 1079, epoch: 27, loss: 0.524905
global_step: 1080, epoch: 27, loss: 0.664995
epoch: 27
train	acc: 0.9423	macro: p 0.9297, r 0.9180, f1: 0.9233	micro: p 0.9423, r 0.9423, f1 0.9423	weighted_f1:0.9423
dev	acc: 0.5122	macro: p 0.3523, r 0.3143, f1: 0.3152	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4775
test	acc: 0.5586	macro: p 0.3461, r 0.3245, f1: 0.3265	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.5343
global_step: 1081, epoch: 28, loss: 0.473894
global_step: 1082, epoch: 28, loss: 0.342186
global_step: 1083, epoch: 28, loss: 0.500462
global_step: 1084, epoch: 28, loss: 0.474247
global_step: 1085, epoch: 28, loss: 0.421246
global_step: 1086, epoch: 28, loss: 0.405669
global_step: 1087, epoch: 28, loss: 0.505391
global_step: 1088, epoch: 28, loss: 0.455434
global_step: 1089, epoch: 28, loss: 0.431299
global_step: 1090, epoch: 28, loss: 0.377944
global_step: 1091, epoch: 28, loss: 0.548435
global_step: 1092, epoch: 28, loss: 0.566461
global_step: 1093, epoch: 28, loss: 0.460182
global_step: 1094, epoch: 28, loss: 0.397484
global_step: 1095, epoch: 28, loss: 0.440658
global_step: 1096, epoch: 28, loss: 0.527032
global_step: 1097, epoch: 28, loss: 0.371928
global_step: 1098, epoch: 28, loss: 0.423583
global_step: 1099, epoch: 28, loss: 0.357051
global_step: 1100, epoch: 28, loss: 0.468963
global_step: 1101, epoch: 28, loss: 0.474705
global_step: 1102, epoch: 28, loss: 0.546451
global_step: 1103, epoch: 28, loss: 0.461987
global_step: 1104, epoch: 28, loss: 0.526426
global_step: 1105, epoch: 28, loss: 0.427049
global_step: 1106, epoch: 28, loss: 0.405263
global_step: 1107, epoch: 28, loss: 0.419400
global_step: 1108, epoch: 28, loss: 0.472400
global_step: 1109, epoch: 28, loss: 0.468787
global_step: 1110, epoch: 28, loss: 0.451877
global_step: 1111, epoch: 28, loss: 0.496236
global_step: 1112, epoch: 28, loss: 0.593857
global_step: 1113, epoch: 28, loss: 0.486093
global_step: 1114, epoch: 28, loss: 0.579347
global_step: 1115, epoch: 28, loss: 0.378076
global_step: 1116, epoch: 28, loss: 0.508411
global_step: 1117, epoch: 28, loss: 0.427925
global_step: 1118, epoch: 28, loss: 0.521024
global_step: 1119, epoch: 28, loss: 0.571398
global_step: 1120, epoch: 28, loss: 0.231596
epoch: 28
train	acc: 0.9395	macro: p 0.9481, r 0.9012, f1: 0.9228	micro: p 0.9395, r 0.9395, f1 0.9395	weighted_f1:0.9392
dev	acc: 0.5284	macro: p 0.3747, r 0.3077, f1: 0.3140	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4843
test	acc: 0.5835	macro: p 0.3839, r 0.3191, f1: 0.3281	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5460
global_step: 1121, epoch: 29, loss: 0.476843
global_step: 1122, epoch: 29, loss: 0.469865
global_step: 1123, epoch: 29, loss: 0.395922
global_step: 1124, epoch: 29, loss: 0.421997
global_step: 1125, epoch: 29, loss: 0.571085
global_step: 1126, epoch: 29, loss: 0.453445
global_step: 1127, epoch: 29, loss: 0.465566
global_step: 1128, epoch: 29, loss: 0.536464
global_step: 1129, epoch: 29, loss: 0.459934
global_step: 1130, epoch: 29, loss: 0.386029
global_step: 1131, epoch: 29, loss: 0.500785
global_step: 1132, epoch: 29, loss: 0.498799
global_step: 1133, epoch: 29, loss: 0.475035
global_step: 1134, epoch: 29, loss: 0.436642
global_step: 1135, epoch: 29, loss: 0.407030
global_step: 1136, epoch: 29, loss: 0.437515
global_step: 1137, epoch: 29, loss: 0.298685
global_step: 1138, epoch: 29, loss: 0.386469
global_step: 1139, epoch: 29, loss: 0.400711
global_step: 1140, epoch: 29, loss: 0.472016
global_step: 1141, epoch: 29, loss: 0.430734
global_step: 1142, epoch: 29, loss: 0.385209
global_step: 1143, epoch: 29, loss: 0.349355
global_step: 1144, epoch: 29, loss: 0.576157
global_step: 1145, epoch: 29, loss: 0.444904
global_step: 1146, epoch: 29, loss: 0.440584
global_step: 1147, epoch: 29, loss: 0.562739
global_step: 1148, epoch: 29, loss: 0.469641
global_step: 1149, epoch: 29, loss: 0.501579
global_step: 1150, epoch: 29, loss: 0.483775
global_step: 1151, epoch: 29, loss: 0.488736
global_step: 1152, epoch: 29, loss: 0.605767
global_step: 1153, epoch: 29, loss: 0.488236
global_step: 1154, epoch: 29, loss: 0.565152
global_step: 1155, epoch: 29, loss: 0.446062
global_step: 1156, epoch: 29, loss: 0.455160
global_step: 1157, epoch: 29, loss: 0.561051
global_step: 1158, epoch: 29, loss: 0.459940
global_step: 1159, epoch: 29, loss: 0.572392
global_step: 1160, epoch: 29, loss: 0.152909
epoch: 29
train	acc: 0.9311	macro: p 0.9278, r 0.9044, f1: 0.9130	micro: p 0.9311, r 0.9311, f1 0.9311	weighted_f1:0.9315
dev	acc: 0.4914	macro: p 0.3700, r 0.3249, f1: 0.3202	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4788
test	acc: 0.5284	macro: p 0.3309, r 0.3292, f1: 0.3222	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.5225
global_step: 1161, epoch: 30, loss: 0.456090
global_step: 1162, epoch: 30, loss: 0.322246
global_step: 1163, epoch: 30, loss: 0.424740
global_step: 1164, epoch: 30, loss: 0.437294
global_step: 1165, epoch: 30, loss: 0.444823
global_step: 1166, epoch: 30, loss: 0.335702
global_step: 1167, epoch: 30, loss: 0.392500
global_step: 1168, epoch: 30, loss: 0.377042
global_step: 1169, epoch: 30, loss: 0.499282
global_step: 1170, epoch: 30, loss: 0.492058
global_step: 1171, epoch: 30, loss: 0.379566
global_step: 1172, epoch: 30, loss: 0.382158
global_step: 1173, epoch: 30, loss: 0.367324
global_step: 1174, epoch: 30, loss: 0.466788
global_step: 1175, epoch: 30, loss: 0.358528
global_step: 1176, epoch: 30, loss: 0.392650
global_step: 1177, epoch: 30, loss: 0.394575
global_step: 1178, epoch: 30, loss: 0.448518
global_step: 1179, epoch: 30, loss: 0.506701
global_step: 1180, epoch: 30, loss: 0.466547
global_step: 1181, epoch: 30, loss: 0.434005
global_step: 1182, epoch: 30, loss: 0.550823
global_step: 1183, epoch: 30, loss: 0.460040
global_step: 1184, epoch: 30, loss: 0.420995
global_step: 1185, epoch: 30, loss: 0.427220
global_step: 1186, epoch: 30, loss: 0.474773
global_step: 1187, epoch: 30, loss: 0.525052
global_step: 1188, epoch: 30, loss: 0.394960
global_step: 1189, epoch: 30, loss: 0.573130
global_step: 1190, epoch: 30, loss: 0.600034
global_step: 1191, epoch: 30, loss: 0.461183
global_step: 1192, epoch: 30, loss: 0.468647
global_step: 1193, epoch: 30, loss: 0.379328
global_step: 1194, epoch: 30, loss: 0.594056
global_step: 1195, epoch: 30, loss: 0.643073
global_step: 1196, epoch: 30, loss: 0.506308
global_step: 1197, epoch: 30, loss: 0.426603
global_step: 1198, epoch: 30, loss: 0.520093
global_step: 1199, epoch: 30, loss: 0.403211
global_step: 1200, epoch: 30, loss: 0.039828
epoch: 30
train	acc: 0.9405	macro: p 0.9520, r 0.9065, f1: 0.9280	micro: p 0.9405, r 0.9405, f1 0.9405	weighted_f1:0.9401
dev	acc: 0.5257	macro: p 0.4012, r 0.2991, f1: 0.3055	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4672
test	acc: 0.5797	macro: p 0.3974, r 0.3027, f1: 0.3139	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5270
global_step: 1201, epoch: 31, loss: 0.412615
global_step: 1202, epoch: 31, loss: 0.462626
global_step: 1203, epoch: 31, loss: 0.357163
global_step: 1204, epoch: 31, loss: 0.365148
global_step: 1205, epoch: 31, loss: 0.397900
global_step: 1206, epoch: 31, loss: 0.269148
global_step: 1207, epoch: 31, loss: 0.331674
global_step: 1208, epoch: 31, loss: 0.338676
global_step: 1209, epoch: 31, loss: 0.400739
global_step: 1210, epoch: 31, loss: 0.503733
global_step: 1211, epoch: 31, loss: 0.346963
global_step: 1212, epoch: 31, loss: 0.326641
global_step: 1213, epoch: 31, loss: 0.379818
global_step: 1214, epoch: 31, loss: 0.530857
global_step: 1215, epoch: 31, loss: 0.411246
global_step: 1216, epoch: 31, loss: 0.462353
global_step: 1217, epoch: 31, loss: 0.478692
global_step: 1218, epoch: 31, loss: 0.410994
global_step: 1219, epoch: 31, loss: 0.394705
global_step: 1220, epoch: 31, loss: 0.357826
global_step: 1221, epoch: 31, loss: 0.386858
global_step: 1222, epoch: 31, loss: 0.417993
global_step: 1223, epoch: 31, loss: 0.382618
global_step: 1224, epoch: 31, loss: 0.473738
global_step: 1225, epoch: 31, loss: 0.450578
global_step: 1226, epoch: 31, loss: 0.433883
global_step: 1227, epoch: 31, loss: 0.423884
global_step: 1228, epoch: 31, loss: 0.502777
global_step: 1229, epoch: 31, loss: 0.456261
global_step: 1230, epoch: 31, loss: 0.400038
global_step: 1231, epoch: 31, loss: 0.508255
global_step: 1232, epoch: 31, loss: 0.440431
global_step: 1233, epoch: 31, loss: 0.402874
global_step: 1234, epoch: 31, loss: 0.448980
global_step: 1235, epoch: 31, loss: 0.589515
global_step: 1236, epoch: 31, loss: 0.482781
global_step: 1237, epoch: 31, loss: 0.493707
global_step: 1238, epoch: 31, loss: 0.452723
global_step: 1239, epoch: 31, loss: 0.543145
global_step: 1240, epoch: 31, loss: 0.761850
epoch: 31
train	acc: 0.9302	macro: p 0.9329, r 0.9081, f1: 0.9179	micro: p 0.9302, r 0.9302, f1 0.9302	weighted_f1:0.9309
dev	acc: 0.4842	macro: p 0.3390, r 0.3040, f1: 0.2877	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.4576
test	acc: 0.5333	macro: p 0.3655, r 0.3212, f1: 0.3156	micro: p 0.5333, r 0.5333, f1 0.5333	weighted_f1:0.5132
global_step: 1241, epoch: 32, loss: 0.507408
global_step: 1242, epoch: 32, loss: 0.465395
global_step: 1243, epoch: 32, loss: 0.463251
global_step: 1244, epoch: 32, loss: 0.418275
global_step: 1245, epoch: 32, loss: 0.359773
global_step: 1246, epoch: 32, loss: 0.467367
global_step: 1247, epoch: 32, loss: 0.459351
global_step: 1248, epoch: 32, loss: 0.446661
global_step: 1249, epoch: 32, loss: 0.377614
global_step: 1250, epoch: 32, loss: 0.445165
global_step: 1251, epoch: 32, loss: 0.373397
global_step: 1252, epoch: 32, loss: 0.514755
global_step: 1253, epoch: 32, loss: 0.402089
global_step: 1254, epoch: 32, loss: 0.398174
global_step: 1255, epoch: 32, loss: 0.495435
global_step: 1256, epoch: 32, loss: 0.345560
global_step: 1257, epoch: 32, loss: 0.391487
global_step: 1258, epoch: 32, loss: 0.382961
global_step: 1259, epoch: 32, loss: 0.362438
global_step: 1260, epoch: 32, loss: 0.311014
global_step: 1261, epoch: 32, loss: 0.393196
global_step: 1262, epoch: 32, loss: 0.430228
global_step: 1263, epoch: 32, loss: 0.333952
global_step: 1264, epoch: 32, loss: 0.517067
global_step: 1265, epoch: 32, loss: 0.382787
global_step: 1266, epoch: 32, loss: 0.443369
global_step: 1267, epoch: 32, loss: 0.432231
global_step: 1268, epoch: 32, loss: 0.456677
global_step: 1269, epoch: 32, loss: 0.408851
global_step: 1270, epoch: 32, loss: 0.460471
global_step: 1271, epoch: 32, loss: 0.503432
global_step: 1272, epoch: 32, loss: 0.403854
global_step: 1273, epoch: 32, loss: 0.439641
global_step: 1274, epoch: 32, loss: 0.458954
global_step: 1275, epoch: 32, loss: 0.374233
global_step: 1276, epoch: 32, loss: 0.471050
global_step: 1277, epoch: 32, loss: 0.461527
global_step: 1278, epoch: 32, loss: 0.464952
global_step: 1279, epoch: 32, loss: 0.418775
global_step: 1280, epoch: 32, loss: 0.107999
epoch: 32
train	acc: 0.9491	macro: p 0.9446, r 0.9315, f1: 0.9376	micro: p 0.9491, r 0.9491, f1 0.9491	weighted_f1:0.9492
dev	acc: 0.4959	macro: p 0.3189, r 0.3063, f1: 0.3065	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4746
test	acc: 0.5487	macro: p 0.3469, r 0.3324, f1: 0.3345	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.5340
global_step: 1281, epoch: 33, loss: 0.406244
global_step: 1282, epoch: 33, loss: 0.396728
global_step: 1283, epoch: 33, loss: 0.379062
global_step: 1284, epoch: 33, loss: 0.423095
global_step: 1285, epoch: 33, loss: 0.328744
global_step: 1286, epoch: 33, loss: 0.371646
global_step: 1287, epoch: 33, loss: 0.318694
global_step: 1288, epoch: 33, loss: 0.325059
global_step: 1289, epoch: 33, loss: 0.399220
global_step: 1290, epoch: 33, loss: 0.401984
global_step: 1291, epoch: 33, loss: 0.434370
global_step: 1292, epoch: 33, loss: 0.237246
global_step: 1293, epoch: 33, loss: 0.484982
global_step: 1294, epoch: 33, loss: 0.408671
global_step: 1295, epoch: 33, loss: 0.410494
global_step: 1296, epoch: 33, loss: 0.358596
global_step: 1297, epoch: 33, loss: 0.448907
global_step: 1298, epoch: 33, loss: 0.484151
global_step: 1299, epoch: 33, loss: 0.428205
global_step: 1300, epoch: 33, loss: 0.368499
global_step: 1301, epoch: 33, loss: 0.383046
global_step: 1302, epoch: 33, loss: 0.416837
global_step: 1303, epoch: 33, loss: 0.307760
global_step: 1304, epoch: 33, loss: 0.347913
global_step: 1305, epoch: 33, loss: 0.354546
global_step: 1306, epoch: 33, loss: 0.346889
global_step: 1307, epoch: 33, loss: 0.490096
global_step: 1308, epoch: 33, loss: 0.423134
global_step: 1309, epoch: 33, loss: 0.418296
global_step: 1310, epoch: 33, loss: 0.437688
global_step: 1311, epoch: 33, loss: 0.453621
global_step: 1312, epoch: 33, loss: 0.389960
global_step: 1313, epoch: 33, loss: 0.356852
global_step: 1314, epoch: 33, loss: 0.451126
global_step: 1315, epoch: 33, loss: 0.524363
global_step: 1316, epoch: 33, loss: 0.393094
global_step: 1317, epoch: 33, loss: 0.553207
global_step: 1318, epoch: 33, loss: 0.463916
global_step: 1319, epoch: 33, loss: 0.417990
global_step: 1320, epoch: 33, loss: 0.474647
epoch: 33
train	acc: 0.9515	macro: p 0.9553, r 0.9266, f1: 0.9402	micro: p 0.9515, r 0.9515, f1 0.9515	weighted_f1:0.9514
dev	acc: 0.5194	macro: p 0.3731, r 0.3091, f1: 0.3182	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4826
test	acc: 0.5670	macro: p 0.3854, r 0.3162, f1: 0.3283	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5341
global_step: 1321, epoch: 34, loss: 0.340912
global_step: 1322, epoch: 34, loss: 0.344926
global_step: 1323, epoch: 34, loss: 0.529688
global_step: 1324, epoch: 34, loss: 0.299694
global_step: 1325, epoch: 34, loss: 0.458205
global_step: 1326, epoch: 34, loss: 0.398041
global_step: 1327, epoch: 34, loss: 0.390557
global_step: 1328, epoch: 34, loss: 0.371014
global_step: 1329, epoch: 34, loss: 0.443955
global_step: 1330, epoch: 34, loss: 0.423434
global_step: 1331, epoch: 34, loss: 0.486630
global_step: 1332, epoch: 34, loss: 0.411204
global_step: 1333, epoch: 34, loss: 0.402250
global_step: 1334, epoch: 34, loss: 0.402176
global_step: 1335, epoch: 34, loss: 0.299712
global_step: 1336, epoch: 34, loss: 0.359458
global_step: 1337, epoch: 34, loss: 0.447995
global_step: 1338, epoch: 34, loss: 0.369712
global_step: 1339, epoch: 34, loss: 0.397078
global_step: 1340, epoch: 34, loss: 0.376752
global_step: 1341, epoch: 34, loss: 0.413949
global_step: 1342, epoch: 34, loss: 0.395718
global_step: 1343, epoch: 34, loss: 0.382804
global_step: 1344, epoch: 34, loss: 0.467670
global_step: 1345, epoch: 34, loss: 0.346698
global_step: 1346, epoch: 34, loss: 0.424038
global_step: 1347, epoch: 34, loss: 0.586890
global_step: 1348, epoch: 34, loss: 0.530588
global_step: 1349, epoch: 34, loss: 0.347028
global_step: 1350, epoch: 34, loss: 0.430258
global_step: 1351, epoch: 34, loss: 0.487673
global_step: 1352, epoch: 34, loss: 0.435522
global_step: 1353, epoch: 34, loss: 0.378412
global_step: 1354, epoch: 34, loss: 0.456029
global_step: 1355, epoch: 34, loss: 0.464842
global_step: 1356, epoch: 34, loss: 0.364202
global_step: 1357, epoch: 34, loss: 0.358035
global_step: 1358, epoch: 34, loss: 0.496994
global_step: 1359, epoch: 34, loss: 0.390204
global_step: 1360, epoch: 34, loss: 0.186249
epoch: 34
train	acc: 0.9419	macro: p 0.9536, r 0.9137, f1: 0.9319	micro: p 0.9419, r 0.9419, f1 0.9419	weighted_f1:0.9420
dev	acc: 0.5257	macro: p 0.3782, r 0.3194, f1: 0.3216	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4859
test	acc: 0.5686	macro: p 0.3719, r 0.3110, f1: 0.3150	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5336
global_step: 1361, epoch: 35, loss: 0.484857
global_step: 1362, epoch: 35, loss: 0.372795
global_step: 1363, epoch: 35, loss: 0.286326
global_step: 1364, epoch: 35, loss: 0.343686
global_step: 1365, epoch: 35, loss: 0.422123
global_step: 1366, epoch: 35, loss: 0.383862
global_step: 1367, epoch: 35, loss: 0.358950
global_step: 1368, epoch: 35, loss: 0.526024
global_step: 1369, epoch: 35, loss: 0.335458
global_step: 1370, epoch: 35, loss: 0.376753
global_step: 1371, epoch: 35, loss: 0.289340
global_step: 1372, epoch: 35, loss: 0.383960
global_step: 1373, epoch: 35, loss: 0.440862
global_step: 1374, epoch: 35, loss: 0.420211
global_step: 1375, epoch: 35, loss: 0.542791
global_step: 1376, epoch: 35, loss: 0.298240
global_step: 1377, epoch: 35, loss: 0.295267
global_step: 1378, epoch: 35, loss: 0.357862
global_step: 1379, epoch: 35, loss: 0.401073
global_step: 1380, epoch: 35, loss: 0.344008
global_step: 1381, epoch: 35, loss: 0.419827
global_step: 1382, epoch: 35, loss: 0.469242
global_step: 1383, epoch: 35, loss: 0.314838
global_step: 1384, epoch: 35, loss: 0.317399
global_step: 1385, epoch: 35, loss: 0.332820
global_step: 1386, epoch: 35, loss: 0.410093
global_step: 1387, epoch: 35, loss: 0.441687
global_step: 1388, epoch: 35, loss: 0.393924
global_step: 1389, epoch: 35, loss: 0.357070
global_step: 1390, epoch: 35, loss: 0.336902
global_step: 1391, epoch: 35, loss: 0.582051
global_step: 1392, epoch: 35, loss: 0.423021
global_step: 1393, epoch: 35, loss: 0.391063
global_step: 1394, epoch: 35, loss: 0.429989
global_step: 1395, epoch: 35, loss: 0.508558
global_step: 1396, epoch: 35, loss: 0.413855
global_step: 1397, epoch: 35, loss: 0.395775
global_step: 1398, epoch: 35, loss: 0.498035
global_step: 1399, epoch: 35, loss: 0.414075
global_step: 1400, epoch: 35, loss: 0.891430
epoch: 35
train	acc: 0.9396	macro: p 0.9493, r 0.9053, f1: 0.9248	micro: p 0.9396, r 0.9396, f1 0.9396	weighted_f1:0.9393
dev	acc: 0.5275	macro: p 0.4513, r 0.3141, f1: 0.3161	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4835
test	acc: 0.5747	macro: p 0.3748, r 0.3078, f1: 0.3060	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5321
global_step: 1401, epoch: 36, loss: 0.427082
global_step: 1402, epoch: 36, loss: 0.387510
global_step: 1403, epoch: 36, loss: 0.371847
global_step: 1404, epoch: 36, loss: 0.347988
global_step: 1405, epoch: 36, loss: 0.356225
global_step: 1406, epoch: 36, loss: 0.389457
global_step: 1407, epoch: 36, loss: 0.362790
global_step: 1408, epoch: 36, loss: 0.408322
global_step: 1409, epoch: 36, loss: 0.328816
global_step: 1410, epoch: 36, loss: 0.358251
global_step: 1411, epoch: 36, loss: 0.338678
global_step: 1412, epoch: 36, loss: 0.397534
global_step: 1413, epoch: 36, loss: 0.328633
global_step: 1414, epoch: 36, loss: 0.445717
global_step: 1415, epoch: 36, loss: 0.380700
global_step: 1416, epoch: 36, loss: 0.362572
global_step: 1417, epoch: 36, loss: 0.373002
global_step: 1418, epoch: 36, loss: 0.504306
global_step: 1419, epoch: 36, loss: 0.419299
global_step: 1420, epoch: 36, loss: 0.343761
global_step: 1421, epoch: 36, loss: 0.471357
global_step: 1422, epoch: 36, loss: 0.290170
global_step: 1423, epoch: 36, loss: 0.427884
global_step: 1424, epoch: 36, loss: 0.389388
global_step: 1425, epoch: 36, loss: 0.364207
global_step: 1426, epoch: 36, loss: 0.368474
global_step: 1427, epoch: 36, loss: 0.422127
global_step: 1428, epoch: 36, loss: 0.396241
global_step: 1429, epoch: 36, loss: 0.437650
global_step: 1430, epoch: 36, loss: 0.329220
global_step: 1431, epoch: 36, loss: 0.342897
global_step: 1432, epoch: 36, loss: 0.341255
global_step: 1433, epoch: 36, loss: 0.438895
global_step: 1434, epoch: 36, loss: 0.361337
global_step: 1435, epoch: 36, loss: 0.413467
global_step: 1436, epoch: 36, loss: 0.413224
global_step: 1437, epoch: 36, loss: 0.414127
global_step: 1438, epoch: 36, loss: 0.313563
global_step: 1439, epoch: 36, loss: 0.405660
global_step: 1440, epoch: 36, loss: 0.017391
epoch: 36
train	acc: 0.9580	macro: p 0.9560, r 0.9470, f1: 0.9511	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9581
dev	acc: 0.5185	macro: p 0.3844, r 0.3469, f1: 0.3550	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.5002
test	acc: 0.5437	macro: p 0.3430, r 0.3295, f1: 0.3286	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5276
global_step: 1441, epoch: 37, loss: 0.384252
global_step: 1442, epoch: 37, loss: 0.339372
global_step: 1443, epoch: 37, loss: 0.366525
global_step: 1444, epoch: 37, loss: 0.294726
global_step: 1445, epoch: 37, loss: 0.371817
global_step: 1446, epoch: 37, loss: 0.368631
global_step: 1447, epoch: 37, loss: 0.386502
global_step: 1448, epoch: 37, loss: 0.279185
global_step: 1449, epoch: 37, loss: 0.296528
global_step: 1450, epoch: 37, loss: 0.360744
global_step: 1451, epoch: 37, loss: 0.339952
global_step: 1452, epoch: 37, loss: 0.409120
global_step: 1453, epoch: 37, loss: 0.349360
global_step: 1454, epoch: 37, loss: 0.378736
global_step: 1455, epoch: 37, loss: 0.359591
global_step: 1456, epoch: 37, loss: 0.459972
global_step: 1457, epoch: 37, loss: 0.410303
global_step: 1458, epoch: 37, loss: 0.392024
global_step: 1459, epoch: 37, loss: 0.366907
global_step: 1460, epoch: 37, loss: 0.350743
global_step: 1461, epoch: 37, loss: 0.312891
global_step: 1462, epoch: 37, loss: 0.325208
global_step: 1463, epoch: 37, loss: 0.388018
global_step: 1464, epoch: 37, loss: 0.331731
global_step: 1465, epoch: 37, loss: 0.369792
global_step: 1466, epoch: 37, loss: 0.427670
global_step: 1467, epoch: 37, loss: 0.319892
global_step: 1468, epoch: 37, loss: 0.319724
global_step: 1469, epoch: 37, loss: 0.262928
global_step: 1470, epoch: 37, loss: 0.323552
global_step: 1471, epoch: 37, loss: 0.294347
global_step: 1472, epoch: 37, loss: 0.371216
global_step: 1473, epoch: 37, loss: 0.399163
global_step: 1474, epoch: 37, loss: 0.433844
global_step: 1475, epoch: 37, loss: 0.400674
global_step: 1476, epoch: 37, loss: 0.406136
global_step: 1477, epoch: 37, loss: 0.352590
global_step: 1478, epoch: 37, loss: 0.313195
global_step: 1479, epoch: 37, loss: 0.369198
global_step: 1480, epoch: 37, loss: 0.018006
epoch: 37
train	acc: 0.9587	macro: p 0.9593, r 0.9414, f1: 0.9499	micro: p 0.9587, r 0.9587, f1 0.9587	weighted_f1:0.9586
dev	acc: 0.5320	macro: p 0.3842, r 0.3291, f1: 0.3383	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4955
test	acc: 0.5709	macro: p 0.3727, r 0.3252, f1: 0.3366	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5422
global_step: 1481, epoch: 38, loss: 0.279560
global_step: 1482, epoch: 38, loss: 0.288824
global_step: 1483, epoch: 38, loss: 0.463689
global_step: 1484, epoch: 38, loss: 0.329249
global_step: 1485, epoch: 38, loss: 0.364070
global_step: 1486, epoch: 38, loss: 0.352807
global_step: 1487, epoch: 38, loss: 0.363135
global_step: 1488, epoch: 38, loss: 0.391314
global_step: 1489, epoch: 38, loss: 0.291987
global_step: 1490, epoch: 38, loss: 0.328092
global_step: 1491, epoch: 38, loss: 0.262353
global_step: 1492, epoch: 38, loss: 0.340776
global_step: 1493, epoch: 38, loss: 0.288277
global_step: 1494, epoch: 38, loss: 0.270497
global_step: 1495, epoch: 38, loss: 0.339110
global_step: 1496, epoch: 38, loss: 0.405704
global_step: 1497, epoch: 38, loss: 0.421458
global_step: 1498, epoch: 38, loss: 0.274047
global_step: 1499, epoch: 38, loss: 0.380427
global_step: 1500, epoch: 38, loss: 0.312577
global_step: 1501, epoch: 38, loss: 0.314216
global_step: 1502, epoch: 38, loss: 0.384832
global_step: 1503, epoch: 38, loss: 0.421287
global_step: 1504, epoch: 38, loss: 0.360968
global_step: 1505, epoch: 38, loss: 0.353712
global_step: 1506, epoch: 38, loss: 0.395752
global_step: 1507, epoch: 38, loss: 0.289677
global_step: 1508, epoch: 38, loss: 0.364050
global_step: 1509, epoch: 38, loss: 0.408003
global_step: 1510, epoch: 38, loss: 0.401735
global_step: 1511, epoch: 38, loss: 0.429194
global_step: 1512, epoch: 38, loss: 0.440759
global_step: 1513, epoch: 38, loss: 0.362572
global_step: 1514, epoch: 38, loss: 0.385627
global_step: 1515, epoch: 38, loss: 0.384551
global_step: 1516, epoch: 38, loss: 0.393960
global_step: 1517, epoch: 38, loss: 0.274527
global_step: 1518, epoch: 38, loss: 0.371871
global_step: 1519, epoch: 38, loss: 0.459005
global_step: 1520, epoch: 38, loss: 0.180139
epoch: 38
train	acc: 0.9513	macro: p 0.9560, r 0.9318, f1: 0.9427	micro: p 0.9513, r 0.9513, f1 0.9513	weighted_f1:0.9514
dev	acc: 0.5122	macro: p 0.3473, r 0.3087, f1: 0.3012	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4757
test	acc: 0.5582	macro: p 0.3841, r 0.3251, f1: 0.3249	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5319
global_step: 1521, epoch: 39, loss: 0.431921
global_step: 1522, epoch: 39, loss: 0.399820
global_step: 1523, epoch: 39, loss: 0.362012
global_step: 1524, epoch: 39, loss: 0.356375
global_step: 1525, epoch: 39, loss: 0.340979
global_step: 1526, epoch: 39, loss: 0.407902
global_step: 1527, epoch: 39, loss: 0.398578
global_step: 1528, epoch: 39, loss: 0.297496
global_step: 1529, epoch: 39, loss: 0.365061
global_step: 1530, epoch: 39, loss: 0.339353
global_step: 1531, epoch: 39, loss: 0.427357
global_step: 1532, epoch: 39, loss: 0.417885
global_step: 1533, epoch: 39, loss: 0.345645
global_step: 1534, epoch: 39, loss: 0.377882
global_step: 1535, epoch: 39, loss: 0.340844
global_step: 1536, epoch: 39, loss: 0.350103
global_step: 1537, epoch: 39, loss: 0.257754
global_step: 1538, epoch: 39, loss: 0.314471
global_step: 1539, epoch: 39, loss: 0.412086
global_step: 1540, epoch: 39, loss: 0.298314
global_step: 1541, epoch: 39, loss: 0.390321
global_step: 1542, epoch: 39, loss: 0.349902
global_step: 1543, epoch: 39, loss: 0.352520
global_step: 1544, epoch: 39, loss: 0.346334
global_step: 1545, epoch: 39, loss: 0.377439
global_step: 1546, epoch: 39, loss: 0.414517
global_step: 1547, epoch: 39, loss: 0.431845
global_step: 1548, epoch: 39, loss: 0.406604
global_step: 1549, epoch: 39, loss: 0.249028
global_step: 1550, epoch: 39, loss: 0.382404
global_step: 1551, epoch: 39, loss: 0.313991
global_step: 1552, epoch: 39, loss: 0.325502
global_step: 1553, epoch: 39, loss: 0.425712
global_step: 1554, epoch: 39, loss: 0.377623
global_step: 1555, epoch: 39, loss: 0.249731
global_step: 1556, epoch: 39, loss: 0.408286
global_step: 1557, epoch: 39, loss: 0.425288
global_step: 1558, epoch: 39, loss: 0.309198
global_step: 1559, epoch: 39, loss: 0.323476
global_step: 1560, epoch: 39, loss: 0.019766
epoch: 39
train	acc: 0.9602	macro: p 0.9619, r 0.9453, f1: 0.9533	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9601
dev	acc: 0.5284	macro: p 0.3737, r 0.3212, f1: 0.3290	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4915
test	acc: 0.5728	macro: p 0.3681, r 0.3207, f1: 0.3319	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5427
global_step: 1561, epoch: 40, loss: 0.250616
global_step: 1562, epoch: 40, loss: 0.302287
global_step: 1563, epoch: 40, loss: 0.304002
global_step: 1564, epoch: 40, loss: 0.345856
global_step: 1565, epoch: 40, loss: 0.268010
global_step: 1566, epoch: 40, loss: 0.381878
global_step: 1567, epoch: 40, loss: 0.408060
global_step: 1568, epoch: 40, loss: 0.372331
global_step: 1569, epoch: 40, loss: 0.299859
global_step: 1570, epoch: 40, loss: 0.383356
global_step: 1571, epoch: 40, loss: 0.344714
global_step: 1572, epoch: 40, loss: 0.281536
global_step: 1573, epoch: 40, loss: 0.345528
global_step: 1574, epoch: 40, loss: 0.351709
global_step: 1575, epoch: 40, loss: 0.315590
global_step: 1576, epoch: 40, loss: 0.276782
global_step: 1577, epoch: 40, loss: 0.441506
global_step: 1578, epoch: 40, loss: 0.338237
global_step: 1579, epoch: 40, loss: 0.391156
global_step: 1580, epoch: 40, loss: 0.415883
global_step: 1581, epoch: 40, loss: 0.346125
global_step: 1582, epoch: 40, loss: 0.225745
global_step: 1583, epoch: 40, loss: 0.385470
global_step: 1584, epoch: 40, loss: 0.329975
global_step: 1585, epoch: 40, loss: 0.278728
global_step: 1586, epoch: 40, loss: 0.316623
global_step: 1587, epoch: 40, loss: 0.347081
global_step: 1588, epoch: 40, loss: 0.345171
global_step: 1589, epoch: 40, loss: 0.397759
global_step: 1590, epoch: 40, loss: 0.331490
global_step: 1591, epoch: 40, loss: 0.410941
global_step: 1592, epoch: 40, loss: 0.345485
global_step: 1593, epoch: 40, loss: 0.301507
global_step: 1594, epoch: 40, loss: 0.390903
global_step: 1595, epoch: 40, loss: 0.331126
global_step: 1596, epoch: 40, loss: 0.337255
global_step: 1597, epoch: 40, loss: 0.385549
global_step: 1598, epoch: 40, loss: 0.397307
global_step: 1599, epoch: 40, loss: 0.277149
global_step: 1600, epoch: 40, loss: 0.022443
epoch: 40
train	acc: 0.9570	macro: p 0.9629, r 0.9377, f1: 0.9497	micro: p 0.9570, r 0.9570, f1 0.9570	weighted_f1:0.9568
dev	acc: 0.5320	macro: p 0.3821, r 0.3155, f1: 0.3167	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4887
test	acc: 0.5713	macro: p 0.3802, r 0.3210, f1: 0.3284	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5373
global_step: 1601, epoch: 41, loss: 0.349415
global_step: 1602, epoch: 41, loss: 0.342041
global_step: 1603, epoch: 41, loss: 0.429060
global_step: 1604, epoch: 41, loss: 0.336263
global_step: 1605, epoch: 41, loss: 0.338403
global_step: 1606, epoch: 41, loss: 0.259132
global_step: 1607, epoch: 41, loss: 0.333934
global_step: 1608, epoch: 41, loss: 0.428340
global_step: 1609, epoch: 41, loss: 0.309808
global_step: 1610, epoch: 41, loss: 0.261329
global_step: 1611, epoch: 41, loss: 0.333177
global_step: 1612, epoch: 41, loss: 0.418875
global_step: 1613, epoch: 41, loss: 0.325565
global_step: 1614, epoch: 41, loss: 0.302048
global_step: 1615, epoch: 41, loss: 0.184983
global_step: 1616, epoch: 41, loss: 0.314801
global_step: 1617, epoch: 41, loss: 0.380815
global_step: 1618, epoch: 41, loss: 0.320122
global_step: 1619, epoch: 41, loss: 0.354938
global_step: 1620, epoch: 41, loss: 0.464497
global_step: 1621, epoch: 41, loss: 0.249389
global_step: 1622, epoch: 41, loss: 0.353143
global_step: 1623, epoch: 41, loss: 0.331143
global_step: 1624, epoch: 41, loss: 0.321865
global_step: 1625, epoch: 41, loss: 0.331080
global_step: 1626, epoch: 41, loss: 0.310041
global_step: 1627, epoch: 41, loss: 0.319132
global_step: 1628, epoch: 41, loss: 0.311175
global_step: 1629, epoch: 41, loss: 0.343899
global_step: 1630, epoch: 41, loss: 0.382770
global_step: 1631, epoch: 41, loss: 0.323294
global_step: 1632, epoch: 41, loss: 0.326672
global_step: 1633, epoch: 41, loss: 0.371735
global_step: 1634, epoch: 41, loss: 0.309137
global_step: 1635, epoch: 41, loss: 0.346244
global_step: 1636, epoch: 41, loss: 0.310376
global_step: 1637, epoch: 41, loss: 0.400849
global_step: 1638, epoch: 41, loss: 0.355634
global_step: 1639, epoch: 41, loss: 0.345733
global_step: 1640, epoch: 41, loss: 0.008789
epoch: 41
train	acc: 0.9598	macro: p 0.9601, r 0.9444, f1: 0.9518	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9598
dev	acc: 0.5293	macro: p 0.3846, r 0.3146, f1: 0.3156	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4866
test	acc: 0.5789	macro: p 0.3659, r 0.3223, f1: 0.3260	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5428
global_step: 1641, epoch: 42, loss: 0.372765
global_step: 1642, epoch: 42, loss: 0.291079
global_step: 1643, epoch: 42, loss: 0.258049
global_step: 1644, epoch: 42, loss: 0.345170
global_step: 1645, epoch: 42, loss: 0.272799
global_step: 1646, epoch: 42, loss: 0.322532
global_step: 1647, epoch: 42, loss: 0.319546
global_step: 1648, epoch: 42, loss: 0.317321
global_step: 1649, epoch: 42, loss: 0.377430
global_step: 1650, epoch: 42, loss: 0.309690
global_step: 1651, epoch: 42, loss: 0.337890
global_step: 1652, epoch: 42, loss: 0.371586
global_step: 1653, epoch: 42, loss: 0.397877
global_step: 1654, epoch: 42, loss: 0.291532
global_step: 1655, epoch: 42, loss: 0.386245
global_step: 1656, epoch: 42, loss: 0.333503
global_step: 1657, epoch: 42, loss: 0.400412
global_step: 1658, epoch: 42, loss: 0.387876
global_step: 1659, epoch: 42, loss: 0.309209
global_step: 1660, epoch: 42, loss: 0.355228
global_step: 1661, epoch: 42, loss: 0.412668
global_step: 1662, epoch: 42, loss: 0.347164
global_step: 1663, epoch: 42, loss: 0.378978
global_step: 1664, epoch: 42, loss: 0.330744
global_step: 1665, epoch: 42, loss: 0.330733
global_step: 1666, epoch: 42, loss: 0.372543
global_step: 1667, epoch: 42, loss: 0.434895
global_step: 1668, epoch: 42, loss: 0.332307
global_step: 1669, epoch: 42, loss: 0.377834
global_step: 1670, epoch: 42, loss: 0.315030
global_step: 1671, epoch: 42, loss: 0.429697
global_step: 1672, epoch: 42, loss: 0.258907
global_step: 1673, epoch: 42, loss: 0.434722
global_step: 1674, epoch: 42, loss: 0.341175
global_step: 1675, epoch: 42, loss: 0.334807
global_step: 1676, epoch: 42, loss: 0.346694
global_step: 1677, epoch: 42, loss: 0.352989
global_step: 1678, epoch: 42, loss: 0.328350
global_step: 1679, epoch: 42, loss: 0.419598
global_step: 1680, epoch: 42, loss: 0.058933
epoch: 42
train	acc: 0.9529	macro: p 0.9599, r 0.9263, f1: 0.9421	micro: p 0.9529, r 0.9529, f1 0.9529	weighted_f1:0.9527
dev	acc: 0.5401	macro: p 0.3936, r 0.3096, f1: 0.3120	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4888
test	acc: 0.5778	macro: p 0.3723, r 0.3090, f1: 0.3153	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5339
global_step: 1681, epoch: 43, loss: 0.408299
global_step: 1682, epoch: 43, loss: 0.285132
global_step: 1683, epoch: 43, loss: 0.325828
global_step: 1684, epoch: 43, loss: 0.339175
global_step: 1685, epoch: 43, loss: 0.342392
global_step: 1686, epoch: 43, loss: 0.291269
global_step: 1687, epoch: 43, loss: 0.342016
global_step: 1688, epoch: 43, loss: 0.313748
global_step: 1689, epoch: 43, loss: 0.303483
global_step: 1690, epoch: 43, loss: 0.355917
global_step: 1691, epoch: 43, loss: 0.271538
global_step: 1692, epoch: 43, loss: 0.329631
global_step: 1693, epoch: 43, loss: 0.338600
global_step: 1694, epoch: 43, loss: 0.279905
global_step: 1695, epoch: 43, loss: 0.210066
global_step: 1696, epoch: 43, loss: 0.297377
global_step: 1697, epoch: 43, loss: 0.265980
global_step: 1698, epoch: 43, loss: 0.328930
global_step: 1699, epoch: 43, loss: 0.386713
global_step: 1700, epoch: 43, loss: 0.350088
global_step: 1701, epoch: 43, loss: 0.247773
global_step: 1702, epoch: 43, loss: 0.390562
global_step: 1703, epoch: 43, loss: 0.276028
global_step: 1704, epoch: 43, loss: 0.458582
global_step: 1705, epoch: 43, loss: 0.365137
global_step: 1706, epoch: 43, loss: 0.332986
global_step: 1707, epoch: 43, loss: 0.332757
global_step: 1708, epoch: 43, loss: 0.282787
global_step: 1709, epoch: 43, loss: 0.273409
global_step: 1710, epoch: 43, loss: 0.416159
global_step: 1711, epoch: 43, loss: 0.338197
global_step: 1712, epoch: 43, loss: 0.386024
global_step: 1713, epoch: 43, loss: 0.501748
global_step: 1714, epoch: 43, loss: 0.335106
global_step: 1715, epoch: 43, loss: 0.337656
global_step: 1716, epoch: 43, loss: 0.393220
global_step: 1717, epoch: 43, loss: 0.373426
global_step: 1718, epoch: 43, loss: 0.342228
global_step: 1719, epoch: 43, loss: 0.353191
global_step: 1720, epoch: 43, loss: 0.514847
epoch: 43
train	acc: 0.9589	macro: p 0.9669, r 0.9379, f1: 0.9518	micro: p 0.9589, r 0.9589, f1 0.9589	weighted_f1:0.9586
dev	acc: 0.5248	macro: p 0.4025, r 0.3007, f1: 0.3137	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4772
test	acc: 0.5751	macro: p 0.3736, r 0.3021, f1: 0.3140	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5329
global_step: 1721, epoch: 44, loss: 0.411657
global_step: 1722, epoch: 44, loss: 0.326278
global_step: 1723, epoch: 44, loss: 0.436121
global_step: 1724, epoch: 44, loss: 0.282882
global_step: 1725, epoch: 44, loss: 0.340515
global_step: 1726, epoch: 44, loss: 0.332900
global_step: 1727, epoch: 44, loss: 0.330788
global_step: 1728, epoch: 44, loss: 0.244256
global_step: 1729, epoch: 44, loss: 0.328246
global_step: 1730, epoch: 44, loss: 0.329794
global_step: 1731, epoch: 44, loss: 0.328499
global_step: 1732, epoch: 44, loss: 0.360557
global_step: 1733, epoch: 44, loss: 0.373604
global_step: 1734, epoch: 44, loss: 0.301445
global_step: 1735, epoch: 44, loss: 0.384609
global_step: 1736, epoch: 44, loss: 0.311783
global_step: 1737, epoch: 44, loss: 0.304769
global_step: 1738, epoch: 44, loss: 0.334298
global_step: 1739, epoch: 44, loss: 0.258546
global_step: 1740, epoch: 44, loss: 0.276906
global_step: 1741, epoch: 44, loss: 0.320266
global_step: 1742, epoch: 44, loss: 0.304092
global_step: 1743, epoch: 44, loss: 0.356703
global_step: 1744, epoch: 44, loss: 0.323283
global_step: 1745, epoch: 44, loss: 0.286622
global_step: 1746, epoch: 44, loss: 0.249355
global_step: 1747, epoch: 44, loss: 0.358778
global_step: 1748, epoch: 44, loss: 0.366212
global_step: 1749, epoch: 44, loss: 0.331158
global_step: 1750, epoch: 44, loss: 0.292759
global_step: 1751, epoch: 44, loss: 0.239288
global_step: 1752, epoch: 44, loss: 0.448255
global_step: 1753, epoch: 44, loss: 0.338594
global_step: 1754, epoch: 44, loss: 0.416638
global_step: 1755, epoch: 44, loss: 0.366152
global_step: 1756, epoch: 44, loss: 0.263171
global_step: 1757, epoch: 44, loss: 0.302778
global_step: 1758, epoch: 44, loss: 0.345247
global_step: 1759, epoch: 44, loss: 0.320492
global_step: 1760, epoch: 44, loss: 0.095162
epoch: 44
train	acc: 0.9586	macro: p 0.9561, r 0.9434, f1: 0.9495	micro: p 0.9586, r 0.9586, f1 0.9586	weighted_f1:0.9586
dev	acc: 0.5203	macro: p 0.3370, r 0.2977, f1: 0.3021	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4836
test	acc: 0.5663	macro: p 0.3555, r 0.3106, f1: 0.3179	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5341
global_step: 1761, epoch: 45, loss: 0.277533
global_step: 1762, epoch: 45, loss: 0.338774
global_step: 1763, epoch: 45, loss: 0.375204
global_step: 1764, epoch: 45, loss: 0.354851
global_step: 1765, epoch: 45, loss: 0.341478
global_step: 1766, epoch: 45, loss: 0.311436
global_step: 1767, epoch: 45, loss: 0.282730
global_step: 1768, epoch: 45, loss: 0.298104
global_step: 1769, epoch: 45, loss: 0.378908
global_step: 1770, epoch: 45, loss: 0.292006
global_step: 1771, epoch: 45, loss: 0.314347
global_step: 1772, epoch: 45, loss: 0.268455
global_step: 1773, epoch: 45, loss: 0.258130
global_step: 1774, epoch: 45, loss: 0.259758
global_step: 1775, epoch: 45, loss: 0.218194
global_step: 1776, epoch: 45, loss: 0.302271
global_step: 1777, epoch: 45, loss: 0.256321
global_step: 1778, epoch: 45, loss: 0.330314
global_step: 1779, epoch: 45, loss: 0.266386
global_step: 1780, epoch: 45, loss: 0.369127
global_step: 1781, epoch: 45, loss: 0.435170
global_step: 1782, epoch: 45, loss: 0.334787
global_step: 1783, epoch: 45, loss: 0.396522
global_step: 1784, epoch: 45, loss: 0.300382
global_step: 1785, epoch: 45, loss: 0.315012
global_step: 1786, epoch: 45, loss: 0.375983
global_step: 1787, epoch: 45, loss: 0.388610
global_step: 1788, epoch: 45, loss: 0.333518
global_step: 1789, epoch: 45, loss: 0.301419
global_step: 1790, epoch: 45, loss: 0.356042
global_step: 1791, epoch: 45, loss: 0.306106
global_step: 1792, epoch: 45, loss: 0.335326
global_step: 1793, epoch: 45, loss: 0.269490
global_step: 1794, epoch: 45, loss: 0.321531
global_step: 1795, epoch: 45, loss: 0.309704
global_step: 1796, epoch: 45, loss: 0.419550
global_step: 1797, epoch: 45, loss: 0.303030
global_step: 1798, epoch: 45, loss: 0.332336
global_step: 1799, epoch: 45, loss: 0.336056
global_step: 1800, epoch: 45, loss: 0.106437
epoch: 45
train	acc: 0.9606	macro: p 0.9624, r 0.9445, f1: 0.9530	micro: p 0.9606, r 0.9606, f1 0.9606	weighted_f1:0.9606
dev	acc: 0.5257	macro: p 0.3555, r 0.3078, f1: 0.3090	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4814
test	acc: 0.5751	macro: p 0.3714, r 0.3206, f1: 0.3281	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5377
global_step: 1801, epoch: 46, loss: 0.333428
global_step: 1802, epoch: 46, loss: 0.308899
global_step: 1803, epoch: 46, loss: 0.282360
global_step: 1804, epoch: 46, loss: 0.345734
global_step: 1805, epoch: 46, loss: 0.327670
global_step: 1806, epoch: 46, loss: 0.286809
global_step: 1807, epoch: 46, loss: 0.362613
global_step: 1808, epoch: 46, loss: 0.291916
global_step: 1809, epoch: 46, loss: 0.272337
global_step: 1810, epoch: 46, loss: 0.311099
global_step: 1811, epoch: 46, loss: 0.286504
global_step: 1812, epoch: 46, loss: 0.335599
global_step: 1813, epoch: 46, loss: 0.303758
global_step: 1814, epoch: 46, loss: 0.241594
global_step: 1815, epoch: 46, loss: 0.320485
global_step: 1816, epoch: 46, loss: 0.213670
global_step: 1817, epoch: 46, loss: 0.358208
global_step: 1818, epoch: 46, loss: 0.412017
global_step: 1819, epoch: 46, loss: 0.399757
global_step: 1820, epoch: 46, loss: 0.273608
global_step: 1821, epoch: 46, loss: 0.287414
global_step: 1822, epoch: 46, loss: 0.317668
global_step: 1823, epoch: 46, loss: 0.374196
global_step: 1824, epoch: 46, loss: 0.367862
global_step: 1825, epoch: 46, loss: 0.279303
global_step: 1826, epoch: 46, loss: 0.291997
global_step: 1827, epoch: 46, loss: 0.229280
global_step: 1828, epoch: 46, loss: 0.390536
global_step: 1829, epoch: 46, loss: 0.330027
global_step: 1830, epoch: 46, loss: 0.272050
global_step: 1831, epoch: 46, loss: 0.268133
global_step: 1832, epoch: 46, loss: 0.259899
global_step: 1833, epoch: 46, loss: 0.332310
global_step: 1834, epoch: 46, loss: 0.488421
global_step: 1835, epoch: 46, loss: 0.483377
global_step: 1836, epoch: 46, loss: 0.313449
global_step: 1837, epoch: 46, loss: 0.369990
global_step: 1838, epoch: 46, loss: 0.305885
global_step: 1839, epoch: 46, loss: 0.434069
global_step: 1840, epoch: 46, loss: 1.034219
epoch: 46
train	acc: 0.9585	macro: p 0.9633, r 0.9384, f1: 0.9502	micro: p 0.9585, r 0.9585, f1 0.9585	weighted_f1:0.9583
dev	acc: 0.5302	macro: p 0.3738, r 0.3087, f1: 0.3089	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4856
test	acc: 0.5724	macro: p 0.4104, r 0.3184, f1: 0.3242	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5376
global_step: 1841, epoch: 47, loss: 0.308882
global_step: 1842, epoch: 47, loss: 0.358407
global_step: 1843, epoch: 47, loss: 0.288982
global_step: 1844, epoch: 47, loss: 0.350225
global_step: 1845, epoch: 47, loss: 0.287506
global_step: 1846, epoch: 47, loss: 0.217287
global_step: 1847, epoch: 47, loss: 0.306155
global_step: 1848, epoch: 47, loss: 0.253288
global_step: 1849, epoch: 47, loss: 0.227507
global_step: 1850, epoch: 47, loss: 0.312228
global_step: 1851, epoch: 47, loss: 0.362602
global_step: 1852, epoch: 47, loss: 0.305349
global_step: 1853, epoch: 47, loss: 0.281382
global_step: 1854, epoch: 47, loss: 0.305406
global_step: 1855, epoch: 47, loss: 0.266358
global_step: 1856, epoch: 47, loss: 0.256216
global_step: 1857, epoch: 47, loss: 0.235343
global_step: 1858, epoch: 47, loss: 0.287227
global_step: 1859, epoch: 47, loss: 0.412965
global_step: 1860, epoch: 47, loss: 0.250710
global_step: 1861, epoch: 47, loss: 0.386274
global_step: 1862, epoch: 47, loss: 0.249726
global_step: 1863, epoch: 47, loss: 0.356009
global_step: 1864, epoch: 47, loss: 0.338276
global_step: 1865, epoch: 47, loss: 0.244944
global_step: 1866, epoch: 47, loss: 0.305738
global_step: 1867, epoch: 47, loss: 0.385474
global_step: 1868, epoch: 47, loss: 0.381919
global_step: 1869, epoch: 47, loss: 0.287519
global_step: 1870, epoch: 47, loss: 0.275671
global_step: 1871, epoch: 47, loss: 0.373028
global_step: 1872, epoch: 47, loss: 0.268867
global_step: 1873, epoch: 47, loss: 0.293101
global_step: 1874, epoch: 47, loss: 0.231131
global_step: 1875, epoch: 47, loss: 0.356386
global_step: 1876, epoch: 47, loss: 0.348709
global_step: 1877, epoch: 47, loss: 0.362319
global_step: 1878, epoch: 47, loss: 0.307174
global_step: 1879, epoch: 47, loss: 0.302807
global_step: 1880, epoch: 47, loss: 0.043064
epoch: 47
train	acc: 0.9656	macro: p 0.9632, r 0.9535, f1: 0.9582	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9656
dev	acc: 0.5347	macro: p 0.3622, r 0.3149, f1: 0.3224	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4971
test	acc: 0.5697	macro: p 0.3610, r 0.3176, f1: 0.3274	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5377
global_step: 1881, epoch: 48, loss: 0.308735
global_step: 1882, epoch: 48, loss: 0.307699
global_step: 1883, epoch: 48, loss: 0.330126
global_step: 1884, epoch: 48, loss: 0.385939
global_step: 1885, epoch: 48, loss: 0.307422
global_step: 1886, epoch: 48, loss: 0.394575
global_step: 1887, epoch: 48, loss: 0.287021
global_step: 1888, epoch: 48, loss: 0.285063
global_step: 1889, epoch: 48, loss: 0.206046
global_step: 1890, epoch: 48, loss: 0.440517
global_step: 1891, epoch: 48, loss: 0.274223
global_step: 1892, epoch: 48, loss: 0.276077
global_step: 1893, epoch: 48, loss: 0.287945
global_step: 1894, epoch: 48, loss: 0.211575
global_step: 1895, epoch: 48, loss: 0.329168
global_step: 1896, epoch: 48, loss: 0.196969
global_step: 1897, epoch: 48, loss: 0.250211
global_step: 1898, epoch: 48, loss: 0.300154
global_step: 1899, epoch: 48, loss: 0.281667
global_step: 1900, epoch: 48, loss: 0.339885
global_step: 1901, epoch: 48, loss: 0.281744
global_step: 1902, epoch: 48, loss: 0.231372
global_step: 1903, epoch: 48, loss: 0.290861
global_step: 1904, epoch: 48, loss: 0.281065
global_step: 1905, epoch: 48, loss: 0.340037
global_step: 1906, epoch: 48, loss: 0.338836
global_step: 1907, epoch: 48, loss: 0.342392
global_step: 1908, epoch: 48, loss: 0.299826
global_step: 1909, epoch: 48, loss: 0.287806
global_step: 1910, epoch: 48, loss: 0.371407
global_step: 1911, epoch: 48, loss: 0.419029
global_step: 1912, epoch: 48, loss: 0.301115
global_step: 1913, epoch: 48, loss: 0.321407
global_step: 1914, epoch: 48, loss: 0.260354
global_step: 1915, epoch: 48, loss: 0.294324
global_step: 1916, epoch: 48, loss: 0.333882
global_step: 1917, epoch: 48, loss: 0.328768
global_step: 1918, epoch: 48, loss: 0.360945
global_step: 1919, epoch: 48, loss: 0.356460
global_step: 1920, epoch: 48, loss: 0.094406
epoch: 48
train	acc: 0.9574	macro: p 0.9596, r 0.9393, f1: 0.9489	micro: p 0.9574, r 0.9574, f1 0.9574	weighted_f1:0.9573
dev	acc: 0.5149	macro: p 0.3835, r 0.3267, f1: 0.3348	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4940
test	acc: 0.5318	macro: p 0.3408, r 0.3156, f1: 0.3184	micro: p 0.5318, r 0.5318, f1 0.5318	weighted_f1:0.5193
global_step: 1921, epoch: 49, loss: 0.325811
global_step: 1922, epoch: 49, loss: 0.234131
global_step: 1923, epoch: 49, loss: 0.306704
global_step: 1924, epoch: 49, loss: 0.277480
global_step: 1925, epoch: 49, loss: 0.315202
global_step: 1926, epoch: 49, loss: 0.288313
global_step: 1927, epoch: 49, loss: 0.350830
global_step: 1928, epoch: 49, loss: 0.295077
global_step: 1929, epoch: 49, loss: 0.308122
global_step: 1930, epoch: 49, loss: 0.303983
global_step: 1931, epoch: 49, loss: 0.313030
global_step: 1932, epoch: 49, loss: 0.305699
global_step: 1933, epoch: 49, loss: 0.343066
global_step: 1934, epoch: 49, loss: 0.316876
global_step: 1935, epoch: 49, loss: 0.270917
global_step: 1936, epoch: 49, loss: 0.242417
global_step: 1937, epoch: 49, loss: 0.286406
global_step: 1938, epoch: 49, loss: 0.375659
global_step: 1939, epoch: 49, loss: 0.267070
global_step: 1940, epoch: 49, loss: 0.345591
global_step: 1941, epoch: 49, loss: 0.347536
global_step: 1942, epoch: 49, loss: 0.308780
global_step: 1943, epoch: 49, loss: 0.303534
global_step: 1944, epoch: 49, loss: 0.317138
global_step: 1945, epoch: 49, loss: 0.286428
global_step: 1946, epoch: 49, loss: 0.392093
global_step: 1947, epoch: 49, loss: 0.261969
global_step: 1948, epoch: 49, loss: 0.353979
global_step: 1949, epoch: 49, loss: 0.325334
global_step: 1950, epoch: 49, loss: 0.366265
global_step: 1951, epoch: 49, loss: 0.218324
global_step: 1952, epoch: 49, loss: 0.259012
global_step: 1953, epoch: 49, loss: 0.314973
global_step: 1954, epoch: 49, loss: 0.297234
global_step: 1955, epoch: 49, loss: 0.292026
global_step: 1956, epoch: 49, loss: 0.305705
global_step: 1957, epoch: 49, loss: 0.245476
global_step: 1958, epoch: 49, loss: 0.296471
global_step: 1959, epoch: 49, loss: 0.388630
global_step: 1960, epoch: 49, loss: 0.172708
epoch: 49
train	acc: 0.9617	macro: p 0.9620, r 0.9462, f1: 0.9534	micro: p 0.9617, r 0.9617, f1 0.9617	weighted_f1:0.9618
dev	acc: 0.5077	macro: p 0.3845, r 0.3224, f1: 0.3265	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4828
test	acc: 0.5425	macro: p 0.3762, r 0.3273, f1: 0.3278	micro: p 0.5425, r 0.5425, f1 0.5425	weighted_f1:0.5258
global_step: 1961, epoch: 50, loss: 0.253113
global_step: 1962, epoch: 50, loss: 0.291820
global_step: 1963, epoch: 50, loss: 0.292877
global_step: 1964, epoch: 50, loss: 0.258347
global_step: 1965, epoch: 50, loss: 0.247385
global_step: 1966, epoch: 50, loss: 0.294343
global_step: 1967, epoch: 50, loss: 0.324711
global_step: 1968, epoch: 50, loss: 0.334576
global_step: 1969, epoch: 50, loss: 0.304806
global_step: 1970, epoch: 50, loss: 0.314225
global_step: 1971, epoch: 50, loss: 0.326991
global_step: 1972, epoch: 50, loss: 0.278875
global_step: 1973, epoch: 50, loss: 0.270220
global_step: 1974, epoch: 50, loss: 0.308976
global_step: 1975, epoch: 50, loss: 0.304966
global_step: 1976, epoch: 50, loss: 0.332169
global_step: 1977, epoch: 50, loss: 0.275724
global_step: 1978, epoch: 50, loss: 0.333918
global_step: 1979, epoch: 50, loss: 0.265401
global_step: 1980, epoch: 50, loss: 0.290293
global_step: 1981, epoch: 50, loss: 0.268295
global_step: 1982, epoch: 50, loss: 0.364080
global_step: 1983, epoch: 50, loss: 0.249205
global_step: 1984, epoch: 50, loss: 0.253713
global_step: 1985, epoch: 50, loss: 0.451045
global_step: 1986, epoch: 50, loss: 0.334608
global_step: 1987, epoch: 50, loss: 0.297340
global_step: 1988, epoch: 50, loss: 0.288485
global_step: 1989, epoch: 50, loss: 0.237611
global_step: 1990, epoch: 50, loss: 0.359807
global_step: 1991, epoch: 50, loss: 0.348999
global_step: 1992, epoch: 50, loss: 0.302972
global_step: 1993, epoch: 50, loss: 0.256420
global_step: 1994, epoch: 50, loss: 0.345582
global_step: 1995, epoch: 50, loss: 0.301901
global_step: 1996, epoch: 50, loss: 0.213713
global_step: 1997, epoch: 50, loss: 0.262304
global_step: 1998, epoch: 50, loss: 0.334069
global_step: 1999, epoch: 50, loss: 0.325786
global_step: 2000, epoch: 50, loss: 1.489270
epoch: 50
train	acc: 0.9627	macro: p 0.9654, r 0.9485, f1: 0.9565	micro: p 0.9627, r 0.9627, f1 0.9627	weighted_f1:0.9627
dev	acc: 0.5158	macro: p 0.4897, r 0.3133, f1: 0.3166	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4826
test	acc: 0.5575	macro: p 0.3885, r 0.3252, f1: 0.3307	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.5311
BEST MODEL epoch: 26
train	acc: 0.9418 macro_p: 0.9316 macro_r: 0.9133 macro_f1: 0.9214 micro_p: 0.9418 micro_r: 0.9418 micro_f1: 0.9418 weighted_f1: 0.9418
dev	acc: 0.5338 macro_p: 0.4073 macro_r: 0.3385 macro_f1: 0.3511 micro_p: 0.5338 micro_r: 0.5338 micro_f1: 0.5338 weighted_f1: 0.5034
test	acc: 0.5567 macro_p: 0.3396 macro_r: 0.3165 macro_f1: 0.3191 micro_p: 0.5567 micro_r: 0.5567 micro_f1: 0.5567 weighted_f1: 0.5299
==========ROUND 2==========
global_step: 2001, epoch: 1, loss: 2.029366
global_step: 2002, epoch: 1, loss: 1.683754
global_step: 2003, epoch: 1, loss: 1.586089
global_step: 2004, epoch: 1, loss: 1.543364
global_step: 2005, epoch: 1, loss: 1.754791
global_step: 2006, epoch: 1, loss: 1.657489
global_step: 2007, epoch: 1, loss: 1.605288
global_step: 2008, epoch: 1, loss: 1.512710
global_step: 2009, epoch: 1, loss: 1.479798
global_step: 2010, epoch: 1, loss: 1.478595
global_step: 2011, epoch: 1, loss: 1.485849
global_step: 2012, epoch: 1, loss: 1.479013
global_step: 2013, epoch: 1, loss: 1.291932
global_step: 2014, epoch: 1, loss: 1.520107
global_step: 2015, epoch: 1, loss: 1.559301
global_step: 2016, epoch: 1, loss: 1.424922
global_step: 2017, epoch: 1, loss: 1.488455
global_step: 2018, epoch: 1, loss: 1.496557
global_step: 2019, epoch: 1, loss: 1.373634
global_step: 2020, epoch: 1, loss: 1.376668
global_step: 2021, epoch: 1, loss: 1.507156
global_step: 2022, epoch: 1, loss: 1.338486
global_step: 2023, epoch: 1, loss: 1.260499
global_step: 2024, epoch: 1, loss: 1.489951
global_step: 2025, epoch: 1, loss: 1.451702
global_step: 2026, epoch: 1, loss: 1.359734
global_step: 2027, epoch: 1, loss: 1.284422
global_step: 2028, epoch: 1, loss: 1.493103
global_step: 2029, epoch: 1, loss: 1.559635
global_step: 2030, epoch: 1, loss: 1.377712
global_step: 2031, epoch: 1, loss: 1.354453
global_step: 2032, epoch: 1, loss: 1.492002
global_step: 2033, epoch: 1, loss: 1.335445
global_step: 2034, epoch: 1, loss: 1.281774
global_step: 2035, epoch: 1, loss: 1.212409
global_step: 2036, epoch: 1, loss: 1.374327
global_step: 2037, epoch: 1, loss: 1.288890
global_step: 2038, epoch: 1, loss: 1.336007
global_step: 2039, epoch: 1, loss: 1.436166
global_step: 2040, epoch: 1, loss: 1.522182
epoch: 1
train	acc: 0.5155	macro: p 0.3680, r 0.2804, f1: 0.2463	micro: p 0.5155, r 0.5155, f1 0.5155	weighted_f1:0.4708
dev	acc: 0.4617	macro: p 0.2320, r 0.2590, f1: 0.2220	micro: p 0.4617, r 0.4617, f1 0.4617	weighted_f1:0.4027
test	acc: 0.5077	macro: p 0.2484, r 0.2795, f1: 0.2372	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4645
New best model!
global_step: 2041, epoch: 2, loss: 1.482093
global_step: 2042, epoch: 2, loss: 1.388991
global_step: 2043, epoch: 2, loss: 1.376858
global_step: 2044, epoch: 2, loss: 1.293131
global_step: 2045, epoch: 2, loss: 1.260990
global_step: 2046, epoch: 2, loss: 1.409565
global_step: 2047, epoch: 2, loss: 1.299536
global_step: 2048, epoch: 2, loss: 1.375320
global_step: 2049, epoch: 2, loss: 1.308831
global_step: 2050, epoch: 2, loss: 1.377531
global_step: 2051, epoch: 2, loss: 1.429778
global_step: 2052, epoch: 2, loss: 1.410763
global_step: 2053, epoch: 2, loss: 1.266232
global_step: 2054, epoch: 2, loss: 1.306367
global_step: 2055, epoch: 2, loss: 1.234767
global_step: 2056, epoch: 2, loss: 1.207341
global_step: 2057, epoch: 2, loss: 1.222978
global_step: 2058, epoch: 2, loss: 1.229956
global_step: 2059, epoch: 2, loss: 1.248785
global_step: 2060, epoch: 2, loss: 1.299628
global_step: 2061, epoch: 2, loss: 1.354733
global_step: 2062, epoch: 2, loss: 1.250923
global_step: 2063, epoch: 2, loss: 1.306595
global_step: 2064, epoch: 2, loss: 1.362164
global_step: 2065, epoch: 2, loss: 1.396329
global_step: 2066, epoch: 2, loss: 1.352618
global_step: 2067, epoch: 2, loss: 1.378506
global_step: 2068, epoch: 2, loss: 1.311713
global_step: 2069, epoch: 2, loss: 1.224910
global_step: 2070, epoch: 2, loss: 1.262047
global_step: 2071, epoch: 2, loss: 1.395330
global_step: 2072, epoch: 2, loss: 1.279938
global_step: 2073, epoch: 2, loss: 1.308368
global_step: 2074, epoch: 2, loss: 1.262855
global_step: 2075, epoch: 2, loss: 1.295418
global_step: 2076, epoch: 2, loss: 1.388573
global_step: 2077, epoch: 2, loss: 1.403886
global_step: 2078, epoch: 2, loss: 1.367160
global_step: 2079, epoch: 2, loss: 1.357193
global_step: 2080, epoch: 2, loss: 1.562147
epoch: 2
train	acc: 0.5582	macro: p 0.3950, r 0.2710, f1: 0.2433	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4722
dev	acc: 0.5212	macro: p 0.2993, r 0.2623, f1: 0.2382	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4351
test	acc: 0.5674	macro: p 0.4356, r 0.2688, f1: 0.2507	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.4916
New best model!
global_step: 2081, epoch: 3, loss: 1.524630
global_step: 2082, epoch: 3, loss: 1.384600
global_step: 2083, epoch: 3, loss: 1.135924
global_step: 2084, epoch: 3, loss: 1.166257
global_step: 2085, epoch: 3, loss: 1.254682
global_step: 2086, epoch: 3, loss: 1.286356
global_step: 2087, epoch: 3, loss: 1.312086
global_step: 2088, epoch: 3, loss: 1.278639
global_step: 2089, epoch: 3, loss: 1.202065
global_step: 2090, epoch: 3, loss: 1.232378
global_step: 2091, epoch: 3, loss: 1.226474
global_step: 2092, epoch: 3, loss: 1.389771
global_step: 2093, epoch: 3, loss: 1.319372
global_step: 2094, epoch: 3, loss: 1.204480
global_step: 2095, epoch: 3, loss: 1.213477
global_step: 2096, epoch: 3, loss: 1.409758
global_step: 2097, epoch: 3, loss: 1.303642
global_step: 2098, epoch: 3, loss: 1.282197
global_step: 2099, epoch: 3, loss: 1.217355
global_step: 2100, epoch: 3, loss: 1.407014
global_step: 2101, epoch: 3, loss: 1.289003
global_step: 2102, epoch: 3, loss: 1.228064
global_step: 2103, epoch: 3, loss: 1.312120
global_step: 2104, epoch: 3, loss: 1.237459
global_step: 2105, epoch: 3, loss: 1.330467
global_step: 2106, epoch: 3, loss: 1.261085
global_step: 2107, epoch: 3, loss: 1.265017
global_step: 2108, epoch: 3, loss: 1.257829
global_step: 2109, epoch: 3, loss: 1.285568
global_step: 2110, epoch: 3, loss: 1.303031
global_step: 2111, epoch: 3, loss: 1.322141
global_step: 2112, epoch: 3, loss: 1.216655
global_step: 2113, epoch: 3, loss: 1.254497
global_step: 2114, epoch: 3, loss: 1.370307
global_step: 2115, epoch: 3, loss: 1.236195
global_step: 2116, epoch: 3, loss: 1.264259
global_step: 2117, epoch: 3, loss: 1.271205
global_step: 2118, epoch: 3, loss: 1.251528
global_step: 2119, epoch: 3, loss: 1.275057
global_step: 2120, epoch: 3, loss: 1.382182
epoch: 3
train	acc: 0.5923	macro: p 0.4333, r 0.3059, f1: 0.2924	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5287
dev	acc: 0.5473	macro: p 0.2971, r 0.2908, f1: 0.2774	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4774
test	acc: 0.5854	macro: p 0.4371, r 0.2927, f1: 0.2815	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5235
New best model!
global_step: 2121, epoch: 4, loss: 1.243442
global_step: 2122, epoch: 4, loss: 1.127192
global_step: 2123, epoch: 4, loss: 1.155103
global_step: 2124, epoch: 4, loss: 1.212098
global_step: 2125, epoch: 4, loss: 1.256841
global_step: 2126, epoch: 4, loss: 1.128230
global_step: 2127, epoch: 4, loss: 1.164865
global_step: 2128, epoch: 4, loss: 1.155934
global_step: 2129, epoch: 4, loss: 1.111898
global_step: 2130, epoch: 4, loss: 1.173313
global_step: 2131, epoch: 4, loss: 1.198252
global_step: 2132, epoch: 4, loss: 1.256473
global_step: 2133, epoch: 4, loss: 1.427696
global_step: 2134, epoch: 4, loss: 1.244099
global_step: 2135, epoch: 4, loss: 1.166443
global_step: 2136, epoch: 4, loss: 1.234605
global_step: 2137, epoch: 4, loss: 1.195206
global_step: 2138, epoch: 4, loss: 1.433606
global_step: 2139, epoch: 4, loss: 1.331462
global_step: 2140, epoch: 4, loss: 1.229791
global_step: 2141, epoch: 4, loss: 1.178090
global_step: 2142, epoch: 4, loss: 1.242092
global_step: 2143, epoch: 4, loss: 1.167944
global_step: 2144, epoch: 4, loss: 1.281818
global_step: 2145, epoch: 4, loss: 1.233710
global_step: 2146, epoch: 4, loss: 1.346862
global_step: 2147, epoch: 4, loss: 1.293968
global_step: 2148, epoch: 4, loss: 1.101052
global_step: 2149, epoch: 4, loss: 1.230906
global_step: 2150, epoch: 4, loss: 1.266450
global_step: 2151, epoch: 4, loss: 1.188487
global_step: 2152, epoch: 4, loss: 1.184028
global_step: 2153, epoch: 4, loss: 1.164939
global_step: 2154, epoch: 4, loss: 1.195112
global_step: 2155, epoch: 4, loss: 1.322428
global_step: 2156, epoch: 4, loss: 1.170346
global_step: 2157, epoch: 4, loss: 1.224717
global_step: 2158, epoch: 4, loss: 1.304267
global_step: 2159, epoch: 4, loss: 1.204131
global_step: 2160, epoch: 4, loss: 1.362511
epoch: 4
train	acc: 0.5919	macro: p 0.4670, r 0.2744, f1: 0.2678	micro: p 0.5919, r 0.5919, f1 0.5919	weighted_f1:0.5127
dev	acc: 0.5194	macro: p 0.2171, r 0.2536, f1: 0.2198	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4182
test	acc: 0.5789	macro: p 0.4336, r 0.2668, f1: 0.2498	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.4915
global_step: 2161, epoch: 5, loss: 1.232123
global_step: 2162, epoch: 5, loss: 1.148640
global_step: 2163, epoch: 5, loss: 1.196698
global_step: 2164, epoch: 5, loss: 1.223430
global_step: 2165, epoch: 5, loss: 1.183411
global_step: 2166, epoch: 5, loss: 1.126618
global_step: 2167, epoch: 5, loss: 1.155923
global_step: 2168, epoch: 5, loss: 1.147616
global_step: 2169, epoch: 5, loss: 1.258340
global_step: 2170, epoch: 5, loss: 1.141641
global_step: 2171, epoch: 5, loss: 1.177235
global_step: 2172, epoch: 5, loss: 1.245364
global_step: 2173, epoch: 5, loss: 1.169633
global_step: 2174, epoch: 5, loss: 1.096755
global_step: 2175, epoch: 5, loss: 1.062529
global_step: 2176, epoch: 5, loss: 1.275949
global_step: 2177, epoch: 5, loss: 1.202596
global_step: 2178, epoch: 5, loss: 1.123449
global_step: 2179, epoch: 5, loss: 1.174794
global_step: 2180, epoch: 5, loss: 1.187951
global_step: 2181, epoch: 5, loss: 1.097188
global_step: 2182, epoch: 5, loss: 1.264910
global_step: 2183, epoch: 5, loss: 1.229502
global_step: 2184, epoch: 5, loss: 1.043579
global_step: 2185, epoch: 5, loss: 1.134638
global_step: 2186, epoch: 5, loss: 1.046677
global_step: 2187, epoch: 5, loss: 1.235652
global_step: 2188, epoch: 5, loss: 1.193686
global_step: 2189, epoch: 5, loss: 1.124732
global_step: 2190, epoch: 5, loss: 1.160872
global_step: 2191, epoch: 5, loss: 1.321144
global_step: 2192, epoch: 5, loss: 1.194733
global_step: 2193, epoch: 5, loss: 1.140819
global_step: 2194, epoch: 5, loss: 1.323874
global_step: 2195, epoch: 5, loss: 1.245958
global_step: 2196, epoch: 5, loss: 1.246361
global_step: 2197, epoch: 5, loss: 1.225413
global_step: 2198, epoch: 5, loss: 1.128328
global_step: 2199, epoch: 5, loss: 1.233639
global_step: 2200, epoch: 5, loss: 0.400727
epoch: 5
train	acc: 0.6038	macro: p 0.4470, r 0.3460, f1: 0.3301	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5577
dev	acc: 0.5275	macro: p 0.4028, r 0.2982, f1: 0.2863	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4747
test	acc: 0.5839	macro: p 0.4202, r 0.3204, f1: 0.3064	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5385
global_step: 2201, epoch: 6, loss: 1.155674
global_step: 2202, epoch: 6, loss: 1.168411
global_step: 2203, epoch: 6, loss: 1.051053
global_step: 2204, epoch: 6, loss: 1.219458
global_step: 2205, epoch: 6, loss: 1.095580
global_step: 2206, epoch: 6, loss: 1.099078
global_step: 2207, epoch: 6, loss: 1.104383
global_step: 2208, epoch: 6, loss: 1.153354
global_step: 2209, epoch: 6, loss: 1.228107
global_step: 2210, epoch: 6, loss: 1.022944
global_step: 2211, epoch: 6, loss: 1.139214
global_step: 2212, epoch: 6, loss: 1.191647
global_step: 2213, epoch: 6, loss: 1.039842
global_step: 2214, epoch: 6, loss: 1.191096
global_step: 2215, epoch: 6, loss: 1.157558
global_step: 2216, epoch: 6, loss: 1.188082
global_step: 2217, epoch: 6, loss: 1.025438
global_step: 2218, epoch: 6, loss: 1.091311
global_step: 2219, epoch: 6, loss: 1.295072
global_step: 2220, epoch: 6, loss: 1.103659
global_step: 2221, epoch: 6, loss: 1.179953
global_step: 2222, epoch: 6, loss: 1.108159
global_step: 2223, epoch: 6, loss: 1.082048
global_step: 2224, epoch: 6, loss: 1.168596
global_step: 2225, epoch: 6, loss: 1.064307
global_step: 2226, epoch: 6, loss: 1.105785
global_step: 2227, epoch: 6, loss: 1.198114
global_step: 2228, epoch: 6, loss: 1.242823
global_step: 2229, epoch: 6, loss: 1.099863
global_step: 2230, epoch: 6, loss: 1.160775
global_step: 2231, epoch: 6, loss: 1.021531
global_step: 2232, epoch: 6, loss: 1.239523
global_step: 2233, epoch: 6, loss: 1.171134
global_step: 2234, epoch: 6, loss: 1.089686
global_step: 2235, epoch: 6, loss: 1.145786
global_step: 2236, epoch: 6, loss: 1.101835
global_step: 2237, epoch: 6, loss: 1.023047
global_step: 2238, epoch: 6, loss: 1.224771
global_step: 2239, epoch: 6, loss: 1.282012
global_step: 2240, epoch: 6, loss: 0.695209
epoch: 6
train	acc: 0.6133	macro: p 0.4930, r 0.3030, f1: 0.3001	micro: p 0.6133, r 0.6133, f1 0.6133	weighted_f1:0.5452
dev	acc: 0.5275	macro: p 0.3856, r 0.2690, f1: 0.2387	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4395
test	acc: 0.5835	macro: p 0.4195, r 0.2785, f1: 0.2629	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5086
global_step: 2241, epoch: 7, loss: 1.336728
global_step: 2242, epoch: 7, loss: 1.150160
global_step: 2243, epoch: 7, loss: 1.060130
global_step: 2244, epoch: 7, loss: 1.094202
global_step: 2245, epoch: 7, loss: 1.003981
global_step: 2246, epoch: 7, loss: 1.047257
global_step: 2247, epoch: 7, loss: 1.104092
global_step: 2248, epoch: 7, loss: 1.039469
global_step: 2249, epoch: 7, loss: 1.137047
global_step: 2250, epoch: 7, loss: 1.137334
global_step: 2251, epoch: 7, loss: 1.092456
global_step: 2252, epoch: 7, loss: 1.064882
global_step: 2253, epoch: 7, loss: 1.062847
global_step: 2254, epoch: 7, loss: 1.107269
global_step: 2255, epoch: 7, loss: 1.077531
global_step: 2256, epoch: 7, loss: 1.069184
global_step: 2257, epoch: 7, loss: 1.122164
global_step: 2258, epoch: 7, loss: 1.045006
global_step: 2259, epoch: 7, loss: 1.122449
global_step: 2260, epoch: 7, loss: 1.090016
global_step: 2261, epoch: 7, loss: 1.165223
global_step: 2262, epoch: 7, loss: 1.147797
global_step: 2263, epoch: 7, loss: 1.017857
global_step: 2264, epoch: 7, loss: 1.052893
global_step: 2265, epoch: 7, loss: 1.127837
global_step: 2266, epoch: 7, loss: 1.029317
global_step: 2267, epoch: 7, loss: 1.135385
global_step: 2268, epoch: 7, loss: 1.008104
global_step: 2269, epoch: 7, loss: 1.080325
global_step: 2270, epoch: 7, loss: 1.075058
global_step: 2271, epoch: 7, loss: 1.014378
global_step: 2272, epoch: 7, loss: 1.156793
global_step: 2273, epoch: 7, loss: 1.157543
global_step: 2274, epoch: 7, loss: 1.126075
global_step: 2275, epoch: 7, loss: 1.001569
global_step: 2276, epoch: 7, loss: 1.222474
global_step: 2277, epoch: 7, loss: 1.100564
global_step: 2278, epoch: 7, loss: 1.089746
global_step: 2279, epoch: 7, loss: 1.109046
global_step: 2280, epoch: 7, loss: 0.415356
epoch: 7
train	acc: 0.6419	macro: p 0.4930, r 0.3318, f1: 0.3297	micro: p 0.6419, r 0.6419, f1 0.6419	weighted_f1:0.5747
dev	acc: 0.5374	macro: p 0.4190, r 0.2774, f1: 0.2527	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4489
test	acc: 0.5858	macro: p 0.3803, r 0.2799, f1: 0.2597	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5029
global_step: 2281, epoch: 8, loss: 1.240705
global_step: 2282, epoch: 8, loss: 1.060323
global_step: 2283, epoch: 8, loss: 0.960638
global_step: 2284, epoch: 8, loss: 0.963189
global_step: 2285, epoch: 8, loss: 1.097410
global_step: 2286, epoch: 8, loss: 1.115970
global_step: 2287, epoch: 8, loss: 1.100847
global_step: 2288, epoch: 8, loss: 0.984525
global_step: 2289, epoch: 8, loss: 0.992401
global_step: 2290, epoch: 8, loss: 1.044291
global_step: 2291, epoch: 8, loss: 0.963626
global_step: 2292, epoch: 8, loss: 1.080845
global_step: 2293, epoch: 8, loss: 1.122009
global_step: 2294, epoch: 8, loss: 1.034955
global_step: 2295, epoch: 8, loss: 0.983364
global_step: 2296, epoch: 8, loss: 1.004337
global_step: 2297, epoch: 8, loss: 1.002861
global_step: 2298, epoch: 8, loss: 1.134127
global_step: 2299, epoch: 8, loss: 1.088793
global_step: 2300, epoch: 8, loss: 0.902304
global_step: 2301, epoch: 8, loss: 0.906490
global_step: 2302, epoch: 8, loss: 1.112710
global_step: 2303, epoch: 8, loss: 1.144724
global_step: 2304, epoch: 8, loss: 1.044142
global_step: 2305, epoch: 8, loss: 1.057439
global_step: 2306, epoch: 8, loss: 0.966454
global_step: 2307, epoch: 8, loss: 0.982231
global_step: 2308, epoch: 8, loss: 1.024889
global_step: 2309, epoch: 8, loss: 1.080007
global_step: 2310, epoch: 8, loss: 1.004144
global_step: 2311, epoch: 8, loss: 1.085085
global_step: 2312, epoch: 8, loss: 1.065362
global_step: 2313, epoch: 8, loss: 1.041124
global_step: 2314, epoch: 8, loss: 1.096049
global_step: 2315, epoch: 8, loss: 1.115474
global_step: 2316, epoch: 8, loss: 1.036439
global_step: 2317, epoch: 8, loss: 1.021983
global_step: 2318, epoch: 8, loss: 1.188376
global_step: 2319, epoch: 8, loss: 0.951814
global_step: 2320, epoch: 8, loss: 1.588222
epoch: 8
train	acc: 0.6588	macro: p 0.5754, r 0.3924, f1: 0.3888	micro: p 0.6588, r 0.6588, f1 0.6588	weighted_f1:0.6236
dev	acc: 0.5257	macro: p 0.3590, r 0.2868, f1: 0.2799	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4739
test	acc: 0.5847	macro: p 0.4055, r 0.3071, f1: 0.3052	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5400
global_step: 2321, epoch: 9, loss: 1.061901
global_step: 2322, epoch: 9, loss: 1.024171
global_step: 2323, epoch: 9, loss: 0.881653
global_step: 2324, epoch: 9, loss: 1.015508
global_step: 2325, epoch: 9, loss: 1.026519
global_step: 2326, epoch: 9, loss: 0.972303
global_step: 2327, epoch: 9, loss: 0.954659
global_step: 2328, epoch: 9, loss: 1.011449
global_step: 2329, epoch: 9, loss: 0.944777
global_step: 2330, epoch: 9, loss: 0.931920
global_step: 2331, epoch: 9, loss: 0.861185
global_step: 2332, epoch: 9, loss: 0.986811
global_step: 2333, epoch: 9, loss: 1.133846
global_step: 2334, epoch: 9, loss: 1.026274
global_step: 2335, epoch: 9, loss: 0.935395
global_step: 2336, epoch: 9, loss: 0.871262
global_step: 2337, epoch: 9, loss: 1.065238
global_step: 2338, epoch: 9, loss: 1.049923
global_step: 2339, epoch: 9, loss: 0.939834
global_step: 2340, epoch: 9, loss: 0.910629
global_step: 2341, epoch: 9, loss: 1.066650
global_step: 2342, epoch: 9, loss: 1.075765
global_step: 2343, epoch: 9, loss: 0.916608
global_step: 2344, epoch: 9, loss: 1.035637
global_step: 2345, epoch: 9, loss: 1.012804
global_step: 2346, epoch: 9, loss: 0.949933
global_step: 2347, epoch: 9, loss: 1.003486
global_step: 2348, epoch: 9, loss: 0.954502
global_step: 2349, epoch: 9, loss: 1.124118
global_step: 2350, epoch: 9, loss: 1.161830
global_step: 2351, epoch: 9, loss: 1.196948
global_step: 2352, epoch: 9, loss: 1.040201
global_step: 2353, epoch: 9, loss: 1.047959
global_step: 2354, epoch: 9, loss: 1.048746
global_step: 2355, epoch: 9, loss: 0.936237
global_step: 2356, epoch: 9, loss: 0.812682
global_step: 2357, epoch: 9, loss: 1.060442
global_step: 2358, epoch: 9, loss: 1.038643
global_step: 2359, epoch: 9, loss: 1.104815
global_step: 2360, epoch: 9, loss: 1.081163
epoch: 9
train	acc: 0.7223	macro: p 0.6815, r 0.4340, f1: 0.4319	micro: p 0.7223, r 0.7223, f1 0.7223	weighted_f1:0.6783
dev	acc: 0.5365	macro: p 0.3741, r 0.2988, f1: 0.2847	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4789
test	acc: 0.5885	macro: p 0.4094, r 0.3090, f1: 0.3010	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5390
New best model!
global_step: 2361, epoch: 10, loss: 1.016140
global_step: 2362, epoch: 10, loss: 0.967413
global_step: 2363, epoch: 10, loss: 0.959632
global_step: 2364, epoch: 10, loss: 0.949370
global_step: 2365, epoch: 10, loss: 0.837835
global_step: 2366, epoch: 10, loss: 0.880935
global_step: 2367, epoch: 10, loss: 0.885340
global_step: 2368, epoch: 10, loss: 0.863792
global_step: 2369, epoch: 10, loss: 0.888720
global_step: 2370, epoch: 10, loss: 0.801598
global_step: 2371, epoch: 10, loss: 1.005462
global_step: 2372, epoch: 10, loss: 0.905557
global_step: 2373, epoch: 10, loss: 0.834512
global_step: 2374, epoch: 10, loss: 0.974756
global_step: 2375, epoch: 10, loss: 0.997958
global_step: 2376, epoch: 10, loss: 0.970796
global_step: 2377, epoch: 10, loss: 0.964189
global_step: 2378, epoch: 10, loss: 0.947126
global_step: 2379, epoch: 10, loss: 0.772326
global_step: 2380, epoch: 10, loss: 0.905808
global_step: 2381, epoch: 10, loss: 0.981325
global_step: 2382, epoch: 10, loss: 0.879031
global_step: 2383, epoch: 10, loss: 1.045278
global_step: 2384, epoch: 10, loss: 0.950585
global_step: 2385, epoch: 10, loss: 0.894483
global_step: 2386, epoch: 10, loss: 0.934718
global_step: 2387, epoch: 10, loss: 0.919779
global_step: 2388, epoch: 10, loss: 0.937418
global_step: 2389, epoch: 10, loss: 0.917826
global_step: 2390, epoch: 10, loss: 0.927862
global_step: 2391, epoch: 10, loss: 1.001677
global_step: 2392, epoch: 10, loss: 0.910447
global_step: 2393, epoch: 10, loss: 1.033187
global_step: 2394, epoch: 10, loss: 0.975575
global_step: 2395, epoch: 10, loss: 1.054880
global_step: 2396, epoch: 10, loss: 0.965375
global_step: 2397, epoch: 10, loss: 0.946917
global_step: 2398, epoch: 10, loss: 0.979454
global_step: 2399, epoch: 10, loss: 1.078292
global_step: 2400, epoch: 10, loss: 0.646489
epoch: 10
train	acc: 0.7181	macro: p 0.7875, r 0.4295, f1: 0.4618	micro: p 0.7181, r 0.7181, f1 0.7181	weighted_f1:0.6755
dev	acc: 0.5248	macro: p 0.3723, r 0.2760, f1: 0.2672	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4538
test	acc: 0.5866	macro: p 0.3848, r 0.2878, f1: 0.2868	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5193
global_step: 2401, epoch: 11, loss: 0.951459
global_step: 2402, epoch: 11, loss: 0.926022
global_step: 2403, epoch: 11, loss: 0.763809
global_step: 2404, epoch: 11, loss: 0.942136
global_step: 2405, epoch: 11, loss: 0.906345
global_step: 2406, epoch: 11, loss: 0.949525
global_step: 2407, epoch: 11, loss: 0.935800
global_step: 2408, epoch: 11, loss: 0.837493
global_step: 2409, epoch: 11, loss: 0.844807
global_step: 2410, epoch: 11, loss: 0.789049
global_step: 2411, epoch: 11, loss: 0.995751
global_step: 2412, epoch: 11, loss: 0.944659
global_step: 2413, epoch: 11, loss: 0.927448
global_step: 2414, epoch: 11, loss: 0.889247
global_step: 2415, epoch: 11, loss: 0.851697
global_step: 2416, epoch: 11, loss: 0.858592
global_step: 2417, epoch: 11, loss: 1.043024
global_step: 2418, epoch: 11, loss: 0.948975
global_step: 2419, epoch: 11, loss: 0.911693
global_step: 2420, epoch: 11, loss: 0.900500
global_step: 2421, epoch: 11, loss: 1.035462
global_step: 2422, epoch: 11, loss: 0.963964
global_step: 2423, epoch: 11, loss: 0.939604
global_step: 2424, epoch: 11, loss: 0.993888
global_step: 2425, epoch: 11, loss: 0.878760
global_step: 2426, epoch: 11, loss: 0.989709
global_step: 2427, epoch: 11, loss: 0.941089
global_step: 2428, epoch: 11, loss: 0.882907
global_step: 2429, epoch: 11, loss: 0.834684
global_step: 2430, epoch: 11, loss: 0.975720
global_step: 2431, epoch: 11, loss: 0.959718
global_step: 2432, epoch: 11, loss: 0.818685
global_step: 2433, epoch: 11, loss: 0.793044
global_step: 2434, epoch: 11, loss: 0.919823
global_step: 2435, epoch: 11, loss: 0.972234
global_step: 2436, epoch: 11, loss: 0.949968
global_step: 2437, epoch: 11, loss: 0.993506
global_step: 2438, epoch: 11, loss: 0.993443
global_step: 2439, epoch: 11, loss: 1.051423
global_step: 2440, epoch: 11, loss: 0.630446
epoch: 11
train	acc: 0.7610	macro: p 0.7837, r 0.5425, f1: 0.5786	micro: p 0.7610, r 0.7610, f1 0.7610	weighted_f1:0.7400
dev	acc: 0.5464	macro: p 0.3358, r 0.3121, f1: 0.3031	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4970
test	acc: 0.5923	macro: p 0.3812, r 0.3222, f1: 0.3222	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5510
New best model!
global_step: 2441, epoch: 12, loss: 0.793898
global_step: 2442, epoch: 12, loss: 0.874893
global_step: 2443, epoch: 12, loss: 0.808580
global_step: 2444, epoch: 12, loss: 0.910623
global_step: 2445, epoch: 12, loss: 0.806723
global_step: 2446, epoch: 12, loss: 0.870921
global_step: 2447, epoch: 12, loss: 0.787755
global_step: 2448, epoch: 12, loss: 0.880848
global_step: 2449, epoch: 12, loss: 0.878525
global_step: 2450, epoch: 12, loss: 0.800803
global_step: 2451, epoch: 12, loss: 0.727549
global_step: 2452, epoch: 12, loss: 0.839811
global_step: 2453, epoch: 12, loss: 0.840679
global_step: 2454, epoch: 12, loss: 0.820258
global_step: 2455, epoch: 12, loss: 0.745096
global_step: 2456, epoch: 12, loss: 0.903221
global_step: 2457, epoch: 12, loss: 0.846186
global_step: 2458, epoch: 12, loss: 0.821267
global_step: 2459, epoch: 12, loss: 0.889592
global_step: 2460, epoch: 12, loss: 0.989898
global_step: 2461, epoch: 12, loss: 0.956875
global_step: 2462, epoch: 12, loss: 0.797913
global_step: 2463, epoch: 12, loss: 0.833634
global_step: 2464, epoch: 12, loss: 0.764536
global_step: 2465, epoch: 12, loss: 0.952312
global_step: 2466, epoch: 12, loss: 0.885381
global_step: 2467, epoch: 12, loss: 0.900129
global_step: 2468, epoch: 12, loss: 0.933922
global_step: 2469, epoch: 12, loss: 0.964430
global_step: 2470, epoch: 12, loss: 0.898691
global_step: 2471, epoch: 12, loss: 0.909392
global_step: 2472, epoch: 12, loss: 0.845030
global_step: 2473, epoch: 12, loss: 0.696577
global_step: 2474, epoch: 12, loss: 0.793762
global_step: 2475, epoch: 12, loss: 0.937696
global_step: 2476, epoch: 12, loss: 0.965069
global_step: 2477, epoch: 12, loss: 0.954468
global_step: 2478, epoch: 12, loss: 1.039348
global_step: 2479, epoch: 12, loss: 0.852905
global_step: 2480, epoch: 12, loss: 0.597557
epoch: 12
train	acc: 0.8249	macro: p 0.8433, r 0.6375, f1: 0.6732	micro: p 0.8249, r 0.8249, f1 0.8249	weighted_f1:0.8125
dev	acc: 0.5302	macro: p 0.3090, r 0.3036, f1: 0.2849	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4772
test	acc: 0.5766	macro: p 0.3434, r 0.3175, f1: 0.3027	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5321
global_step: 2481, epoch: 13, loss: 0.640811
global_step: 2482, epoch: 13, loss: 0.791074
global_step: 2483, epoch: 13, loss: 0.711534
global_step: 2484, epoch: 13, loss: 0.835275
global_step: 2485, epoch: 13, loss: 0.671938
global_step: 2486, epoch: 13, loss: 0.908669
global_step: 2487, epoch: 13, loss: 0.821566
global_step: 2488, epoch: 13, loss: 0.745619
global_step: 2489, epoch: 13, loss: 0.791256
global_step: 2490, epoch: 13, loss: 0.806259
global_step: 2491, epoch: 13, loss: 0.739312
global_step: 2492, epoch: 13, loss: 0.732420
global_step: 2493, epoch: 13, loss: 0.635659
global_step: 2494, epoch: 13, loss: 0.796648
global_step: 2495, epoch: 13, loss: 0.737916
global_step: 2496, epoch: 13, loss: 0.872049
global_step: 2497, epoch: 13, loss: 0.757855
global_step: 2498, epoch: 13, loss: 0.923091
global_step: 2499, epoch: 13, loss: 0.952084
global_step: 2500, epoch: 13, loss: 0.980620
global_step: 2501, epoch: 13, loss: 0.786346
global_step: 2502, epoch: 13, loss: 0.755205
global_step: 2503, epoch: 13, loss: 0.817923
global_step: 2504, epoch: 13, loss: 0.783231
global_step: 2505, epoch: 13, loss: 0.896045
global_step: 2506, epoch: 13, loss: 0.965887
global_step: 2507, epoch: 13, loss: 0.796219
global_step: 2508, epoch: 13, loss: 0.922191
global_step: 2509, epoch: 13, loss: 0.802752
global_step: 2510, epoch: 13, loss: 0.888624
global_step: 2511, epoch: 13, loss: 0.824120
global_step: 2512, epoch: 13, loss: 0.886911
global_step: 2513, epoch: 13, loss: 0.935258
global_step: 2514, epoch: 13, loss: 0.855300
global_step: 2515, epoch: 13, loss: 0.774574
global_step: 2516, epoch: 13, loss: 0.910326
global_step: 2517, epoch: 13, loss: 0.911652
global_step: 2518, epoch: 13, loss: 1.053789
global_step: 2519, epoch: 13, loss: 0.939123
global_step: 2520, epoch: 13, loss: 0.738963
epoch: 13
train	acc: 0.7628	macro: p 0.8416, r 0.5235, f1: 0.5601	micro: p 0.7628, r 0.7628, f1 0.7628	weighted_f1:0.7299
dev	acc: 0.5419	macro: p 0.3825, r 0.3000, f1: 0.2821	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4769
test	acc: 0.5866	macro: p 0.3834, r 0.3012, f1: 0.2865	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5257
global_step: 2521, epoch: 14, loss: 0.782617
global_step: 2522, epoch: 14, loss: 0.753723
global_step: 2523, epoch: 14, loss: 0.706268
global_step: 2524, epoch: 14, loss: 0.864986
global_step: 2525, epoch: 14, loss: 0.804306
global_step: 2526, epoch: 14, loss: 0.758880
global_step: 2527, epoch: 14, loss: 0.735401
global_step: 2528, epoch: 14, loss: 0.748731
global_step: 2529, epoch: 14, loss: 0.715235
global_step: 2530, epoch: 14, loss: 0.752951
global_step: 2531, epoch: 14, loss: 0.677159
global_step: 2532, epoch: 14, loss: 0.739511
global_step: 2533, epoch: 14, loss: 0.783301
global_step: 2534, epoch: 14, loss: 0.839409
global_step: 2535, epoch: 14, loss: 0.762987
global_step: 2536, epoch: 14, loss: 0.615973
global_step: 2537, epoch: 14, loss: 0.848891
global_step: 2538, epoch: 14, loss: 0.863337
global_step: 2539, epoch: 14, loss: 0.706743
global_step: 2540, epoch: 14, loss: 0.796105
global_step: 2541, epoch: 14, loss: 0.874497
global_step: 2542, epoch: 14, loss: 0.773602
global_step: 2543, epoch: 14, loss: 0.733916
global_step: 2544, epoch: 14, loss: 0.832217
global_step: 2545, epoch: 14, loss: 0.732573
global_step: 2546, epoch: 14, loss: 0.832974
global_step: 2547, epoch: 14, loss: 0.794575
global_step: 2548, epoch: 14, loss: 0.808341
global_step: 2549, epoch: 14, loss: 0.804225
global_step: 2550, epoch: 14, loss: 0.794154
global_step: 2551, epoch: 14, loss: 0.768414
global_step: 2552, epoch: 14, loss: 0.832666
global_step: 2553, epoch: 14, loss: 0.749275
global_step: 2554, epoch: 14, loss: 0.873063
global_step: 2555, epoch: 14, loss: 0.908624
global_step: 2556, epoch: 14, loss: 0.858994
global_step: 2557, epoch: 14, loss: 0.923720
global_step: 2558, epoch: 14, loss: 0.802231
global_step: 2559, epoch: 14, loss: 0.817322
global_step: 2560, epoch: 14, loss: 0.357001
epoch: 14
train	acc: 0.7594	macro: p 0.8535, r 0.5456, f1: 0.5947	micro: p 0.7594, r 0.7594, f1 0.7594	weighted_f1:0.7383
dev	acc: 0.5032	macro: p 0.2999, r 0.2718, f1: 0.2363	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.4322
test	acc: 0.5625	macro: p 0.3736, r 0.2957, f1: 0.2645	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.4986
global_step: 2561, epoch: 15, loss: 0.841920
global_step: 2562, epoch: 15, loss: 0.737257
global_step: 2563, epoch: 15, loss: 0.620907
global_step: 2564, epoch: 15, loss: 0.687300
global_step: 2565, epoch: 15, loss: 0.714988
global_step: 2566, epoch: 15, loss: 0.813686
global_step: 2567, epoch: 15, loss: 0.836374
global_step: 2568, epoch: 15, loss: 0.785018
global_step: 2569, epoch: 15, loss: 0.706818
global_step: 2570, epoch: 15, loss: 0.688872
global_step: 2571, epoch: 15, loss: 0.676648
global_step: 2572, epoch: 15, loss: 0.740939
global_step: 2573, epoch: 15, loss: 0.677482
global_step: 2574, epoch: 15, loss: 0.776883
global_step: 2575, epoch: 15, loss: 0.752520
global_step: 2576, epoch: 15, loss: 0.763314
global_step: 2577, epoch: 15, loss: 0.744316
global_step: 2578, epoch: 15, loss: 0.813643
global_step: 2579, epoch: 15, loss: 0.771657
global_step: 2580, epoch: 15, loss: 0.851768
global_step: 2581, epoch: 15, loss: 0.689194
global_step: 2582, epoch: 15, loss: 0.869152
global_step: 2583, epoch: 15, loss: 0.730032
global_step: 2584, epoch: 15, loss: 0.599501
global_step: 2585, epoch: 15, loss: 0.813259
global_step: 2586, epoch: 15, loss: 0.690838
global_step: 2587, epoch: 15, loss: 0.826417
global_step: 2588, epoch: 15, loss: 0.728835
global_step: 2589, epoch: 15, loss: 0.738213
global_step: 2590, epoch: 15, loss: 0.778269
global_step: 2591, epoch: 15, loss: 0.764174
global_step: 2592, epoch: 15, loss: 0.770638
global_step: 2593, epoch: 15, loss: 0.727643
global_step: 2594, epoch: 15, loss: 0.782246
global_step: 2595, epoch: 15, loss: 0.785050
global_step: 2596, epoch: 15, loss: 0.747050
global_step: 2597, epoch: 15, loss: 0.783158
global_step: 2598, epoch: 15, loss: 0.754689
global_step: 2599, epoch: 15, loss: 0.799588
global_step: 2600, epoch: 15, loss: 1.038690
epoch: 15
train	acc: 0.8031	macro: p 0.8620, r 0.5991, f1: 0.6389	micro: p 0.8031, r 0.8031, f1 0.8031	weighted_f1:0.7930
dev	acc: 0.5347	macro: p 0.3468, r 0.3040, f1: 0.2947	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4899
test	acc: 0.5877	macro: p 0.3973, r 0.3163, f1: 0.3140	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5486
global_step: 2601, epoch: 16, loss: 0.818066
global_step: 2602, epoch: 16, loss: 0.722674
global_step: 2603, epoch: 16, loss: 0.589897
global_step: 2604, epoch: 16, loss: 0.788788
global_step: 2605, epoch: 16, loss: 0.693761
global_step: 2606, epoch: 16, loss: 0.661991
global_step: 2607, epoch: 16, loss: 0.687997
global_step: 2608, epoch: 16, loss: 0.647633
global_step: 2609, epoch: 16, loss: 0.709877
global_step: 2610, epoch: 16, loss: 0.625133
global_step: 2611, epoch: 16, loss: 0.623650
global_step: 2612, epoch: 16, loss: 0.810195
global_step: 2613, epoch: 16, loss: 0.695630
global_step: 2614, epoch: 16, loss: 0.690300
global_step: 2615, epoch: 16, loss: 0.711991
global_step: 2616, epoch: 16, loss: 0.749925
global_step: 2617, epoch: 16, loss: 0.690344
global_step: 2618, epoch: 16, loss: 0.738502
global_step: 2619, epoch: 16, loss: 0.674096
global_step: 2620, epoch: 16, loss: 0.765880
global_step: 2621, epoch: 16, loss: 0.758067
global_step: 2622, epoch: 16, loss: 0.710053
global_step: 2623, epoch: 16, loss: 0.701750
global_step: 2624, epoch: 16, loss: 0.706715
global_step: 2625, epoch: 16, loss: 0.684875
global_step: 2626, epoch: 16, loss: 0.643883
global_step: 2627, epoch: 16, loss: 0.823797
global_step: 2628, epoch: 16, loss: 0.651152
global_step: 2629, epoch: 16, loss: 0.670582
global_step: 2630, epoch: 16, loss: 0.784433
global_step: 2631, epoch: 16, loss: 0.813653
global_step: 2632, epoch: 16, loss: 0.789551
global_step: 2633, epoch: 16, loss: 0.728582
global_step: 2634, epoch: 16, loss: 0.714368
global_step: 2635, epoch: 16, loss: 0.735535
global_step: 2636, epoch: 16, loss: 0.707851
global_step: 2637, epoch: 16, loss: 0.632050
global_step: 2638, epoch: 16, loss: 0.834953
global_step: 2639, epoch: 16, loss: 0.778768
global_step: 2640, epoch: 16, loss: 0.841333
epoch: 16
train	acc: 0.8702	macro: p 0.8885, r 0.7717, f1: 0.8180	micro: p 0.8702, r 0.8702, f1 0.8702	weighted_f1:0.8676
dev	acc: 0.5293	macro: p 0.3252, r 0.2899, f1: 0.2807	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4759
test	acc: 0.5889	macro: p 0.3657, r 0.3117, f1: 0.3143	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5449
global_step: 2641, epoch: 17, loss: 0.630489
global_step: 2642, epoch: 17, loss: 0.723102
global_step: 2643, epoch: 17, loss: 0.647104
global_step: 2644, epoch: 17, loss: 0.689391
global_step: 2645, epoch: 17, loss: 0.522619
global_step: 2646, epoch: 17, loss: 0.661482
global_step: 2647, epoch: 17, loss: 0.685014
global_step: 2648, epoch: 17, loss: 0.633492
global_step: 2649, epoch: 17, loss: 0.681638
global_step: 2650, epoch: 17, loss: 0.668351
global_step: 2651, epoch: 17, loss: 0.593989
global_step: 2652, epoch: 17, loss: 0.630475
global_step: 2653, epoch: 17, loss: 0.676006
global_step: 2654, epoch: 17, loss: 0.580001
global_step: 2655, epoch: 17, loss: 0.727729
global_step: 2656, epoch: 17, loss: 0.712277
global_step: 2657, epoch: 17, loss: 0.770716
global_step: 2658, epoch: 17, loss: 0.803136
global_step: 2659, epoch: 17, loss: 0.666864
global_step: 2660, epoch: 17, loss: 0.715728
global_step: 2661, epoch: 17, loss: 0.597582
global_step: 2662, epoch: 17, loss: 0.704910
global_step: 2663, epoch: 17, loss: 0.582231
global_step: 2664, epoch: 17, loss: 0.637556
global_step: 2665, epoch: 17, loss: 0.710297
global_step: 2666, epoch: 17, loss: 0.663844
global_step: 2667, epoch: 17, loss: 0.784460
global_step: 2668, epoch: 17, loss: 0.703089
global_step: 2669, epoch: 17, loss: 0.804750
global_step: 2670, epoch: 17, loss: 0.607304
global_step: 2671, epoch: 17, loss: 0.622581
global_step: 2672, epoch: 17, loss: 0.668000
global_step: 2673, epoch: 17, loss: 0.742524
global_step: 2674, epoch: 17, loss: 0.684462
global_step: 2675, epoch: 17, loss: 0.706452
global_step: 2676, epoch: 17, loss: 0.696132
global_step: 2677, epoch: 17, loss: 0.727735
global_step: 2678, epoch: 17, loss: 0.718446
global_step: 2679, epoch: 17, loss: 0.707217
global_step: 2680, epoch: 17, loss: 0.446337
epoch: 17
train	acc: 0.8581	macro: p 0.8985, r 0.7332, f1: 0.7881	micro: p 0.8581, r 0.8581, f1 0.8581	weighted_f1:0.8531
dev	acc: 0.5248	macro: p 0.3401, r 0.2915, f1: 0.2726	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4664
test	acc: 0.5736	macro: p 0.4164, r 0.3049, f1: 0.2875	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5205
global_step: 2681, epoch: 18, loss: 0.628319
global_step: 2682, epoch: 18, loss: 0.604332
global_step: 2683, epoch: 18, loss: 0.560788
global_step: 2684, epoch: 18, loss: 0.605915
global_step: 2685, epoch: 18, loss: 0.603026
global_step: 2686, epoch: 18, loss: 0.655558
global_step: 2687, epoch: 18, loss: 0.702994
global_step: 2688, epoch: 18, loss: 0.614056
global_step: 2689, epoch: 18, loss: 0.611806
global_step: 2690, epoch: 18, loss: 0.574254
global_step: 2691, epoch: 18, loss: 0.771546
global_step: 2692, epoch: 18, loss: 0.607087
global_step: 2693, epoch: 18, loss: 0.661670
global_step: 2694, epoch: 18, loss: 0.682646
global_step: 2695, epoch: 18, loss: 0.613176
global_step: 2696, epoch: 18, loss: 0.758688
global_step: 2697, epoch: 18, loss: 0.694635
global_step: 2698, epoch: 18, loss: 0.727650
global_step: 2699, epoch: 18, loss: 0.710867
global_step: 2700, epoch: 18, loss: 0.689130
global_step: 2701, epoch: 18, loss: 0.600350
global_step: 2702, epoch: 18, loss: 0.637691
global_step: 2703, epoch: 18, loss: 0.747769
global_step: 2704, epoch: 18, loss: 0.674691
global_step: 2705, epoch: 18, loss: 0.649820
global_step: 2706, epoch: 18, loss: 0.673776
global_step: 2707, epoch: 18, loss: 0.745141
global_step: 2708, epoch: 18, loss: 0.667264
global_step: 2709, epoch: 18, loss: 0.679694
global_step: 2710, epoch: 18, loss: 0.710363
global_step: 2711, epoch: 18, loss: 0.668729
global_step: 2712, epoch: 18, loss: 0.607497
global_step: 2713, epoch: 18, loss: 0.757050
global_step: 2714, epoch: 18, loss: 0.644332
global_step: 2715, epoch: 18, loss: 0.533943
global_step: 2716, epoch: 18, loss: 0.580060
global_step: 2717, epoch: 18, loss: 0.645627
global_step: 2718, epoch: 18, loss: 0.717792
global_step: 2719, epoch: 18, loss: 0.700416
global_step: 2720, epoch: 18, loss: 1.269635
epoch: 18
train	acc: 0.8853	macro: p 0.8276, r 0.8421, f1: 0.8283	micro: p 0.8853, r 0.8853, f1 0.8853	weighted_f1:0.8872
dev	acc: 0.4932	macro: p 0.3528, r 0.3271, f1: 0.3216	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.4856
test	acc: 0.5395	macro: p 0.3670, r 0.3449, f1: 0.3401	micro: p 0.5395, r 0.5395, f1 0.5395	weighted_f1:0.5417
global_step: 2721, epoch: 19, loss: 0.751900
global_step: 2722, epoch: 19, loss: 0.658534
global_step: 2723, epoch: 19, loss: 0.659734
global_step: 2724, epoch: 19, loss: 0.644881
global_step: 2725, epoch: 19, loss: 0.608926
global_step: 2726, epoch: 19, loss: 0.594234
global_step: 2727, epoch: 19, loss: 0.598900
global_step: 2728, epoch: 19, loss: 0.488154
global_step: 2729, epoch: 19, loss: 0.598240
global_step: 2730, epoch: 19, loss: 0.717997
global_step: 2731, epoch: 19, loss: 0.601351
global_step: 2732, epoch: 19, loss: 0.568347
global_step: 2733, epoch: 19, loss: 0.647097
global_step: 2734, epoch: 19, loss: 0.580172
global_step: 2735, epoch: 19, loss: 0.463537
global_step: 2736, epoch: 19, loss: 0.841482
global_step: 2737, epoch: 19, loss: 0.675144
global_step: 2738, epoch: 19, loss: 0.716674
global_step: 2739, epoch: 19, loss: 0.742938
global_step: 2740, epoch: 19, loss: 0.625078
global_step: 2741, epoch: 19, loss: 0.656091
global_step: 2742, epoch: 19, loss: 0.659264
global_step: 2743, epoch: 19, loss: 0.704970
global_step: 2744, epoch: 19, loss: 0.704703
global_step: 2745, epoch: 19, loss: 0.591284
global_step: 2746, epoch: 19, loss: 0.636711
global_step: 2747, epoch: 19, loss: 0.691446
global_step: 2748, epoch: 19, loss: 0.635620
global_step: 2749, epoch: 19, loss: 0.558748
global_step: 2750, epoch: 19, loss: 0.618187
global_step: 2751, epoch: 19, loss: 0.844968
global_step: 2752, epoch: 19, loss: 0.574439
global_step: 2753, epoch: 19, loss: 0.551923
global_step: 2754, epoch: 19, loss: 0.721677
global_step: 2755, epoch: 19, loss: 0.759787
global_step: 2756, epoch: 19, loss: 0.558318
global_step: 2757, epoch: 19, loss: 0.767044
global_step: 2758, epoch: 19, loss: 0.738710
global_step: 2759, epoch: 19, loss: 0.580003
global_step: 2760, epoch: 19, loss: 0.057186
epoch: 19
train	acc: 0.8962	macro: p 0.9164, r 0.8057, f1: 0.8484	micro: p 0.8962, r 0.8962, f1 0.8962	weighted_f1:0.8941
dev	acc: 0.5356	macro: p 0.3846, r 0.3039, f1: 0.3054	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4891
test	acc: 0.5939	macro: p 0.4208, r 0.3175, f1: 0.3197	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5499
global_step: 2761, epoch: 20, loss: 0.696549
global_step: 2762, epoch: 20, loss: 0.532493
global_step: 2763, epoch: 20, loss: 0.588384
global_step: 2764, epoch: 20, loss: 0.607844
global_step: 2765, epoch: 20, loss: 0.604452
global_step: 2766, epoch: 20, loss: 0.605451
global_step: 2767, epoch: 20, loss: 0.635652
global_step: 2768, epoch: 20, loss: 0.594157
global_step: 2769, epoch: 20, loss: 0.580641
global_step: 2770, epoch: 20, loss: 0.570435
global_step: 2771, epoch: 20, loss: 0.513558
global_step: 2772, epoch: 20, loss: 0.518926
global_step: 2773, epoch: 20, loss: 0.654647
global_step: 2774, epoch: 20, loss: 0.599319
global_step: 2775, epoch: 20, loss: 0.507120
global_step: 2776, epoch: 20, loss: 0.558071
global_step: 2777, epoch: 20, loss: 0.546053
global_step: 2778, epoch: 20, loss: 0.634861
global_step: 2779, epoch: 20, loss: 0.614315
global_step: 2780, epoch: 20, loss: 0.720585
global_step: 2781, epoch: 20, loss: 0.700187
global_step: 2782, epoch: 20, loss: 0.665867
global_step: 2783, epoch: 20, loss: 0.660669
global_step: 2784, epoch: 20, loss: 0.708338
global_step: 2785, epoch: 20, loss: 0.718981
global_step: 2786, epoch: 20, loss: 0.661060
global_step: 2787, epoch: 20, loss: 0.619170
global_step: 2788, epoch: 20, loss: 0.647127
global_step: 2789, epoch: 20, loss: 0.541308
global_step: 2790, epoch: 20, loss: 0.560109
global_step: 2791, epoch: 20, loss: 0.677694
global_step: 2792, epoch: 20, loss: 0.582161
global_step: 2793, epoch: 20, loss: 0.640642
global_step: 2794, epoch: 20, loss: 0.796909
global_step: 2795, epoch: 20, loss: 0.614775
global_step: 2796, epoch: 20, loss: 0.611797
global_step: 2797, epoch: 20, loss: 0.697648
global_step: 2798, epoch: 20, loss: 0.606479
global_step: 2799, epoch: 20, loss: 0.539854
global_step: 2800, epoch: 20, loss: 1.226074
epoch: 20
train	acc: 0.8893	macro: p 0.9205, r 0.8047, f1: 0.8521	micro: p 0.8893, r 0.8893, f1 0.8893	weighted_f1:0.8872
dev	acc: 0.5320	macro: p 0.3316, r 0.2895, f1: 0.2755	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4674
test	acc: 0.5747	macro: p 0.3636, r 0.2906, f1: 0.2797	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5147
global_step: 2801, epoch: 21, loss: 0.620360
global_step: 2802, epoch: 21, loss: 0.558394
global_step: 2803, epoch: 21, loss: 0.536204
global_step: 2804, epoch: 21, loss: 0.665324
global_step: 2805, epoch: 21, loss: 0.684412
global_step: 2806, epoch: 21, loss: 0.492983
global_step: 2807, epoch: 21, loss: 0.506731
global_step: 2808, epoch: 21, loss: 0.472019
global_step: 2809, epoch: 21, loss: 0.669634
global_step: 2810, epoch: 21, loss: 0.519629
global_step: 2811, epoch: 21, loss: 0.600401
global_step: 2812, epoch: 21, loss: 0.530440
global_step: 2813, epoch: 21, loss: 0.544508
global_step: 2814, epoch: 21, loss: 0.553608
global_step: 2815, epoch: 21, loss: 0.578372
global_step: 2816, epoch: 21, loss: 0.582279
global_step: 2817, epoch: 21, loss: 0.634629
global_step: 2818, epoch: 21, loss: 0.575089
global_step: 2819, epoch: 21, loss: 0.610786
global_step: 2820, epoch: 21, loss: 0.603704
global_step: 2821, epoch: 21, loss: 0.624322
global_step: 2822, epoch: 21, loss: 0.530834
global_step: 2823, epoch: 21, loss: 0.584511
global_step: 2824, epoch: 21, loss: 0.540238
global_step: 2825, epoch: 21, loss: 0.669357
global_step: 2826, epoch: 21, loss: 0.647909
global_step: 2827, epoch: 21, loss: 0.681717
global_step: 2828, epoch: 21, loss: 0.721681
global_step: 2829, epoch: 21, loss: 0.618379
global_step: 2830, epoch: 21, loss: 0.528306
global_step: 2831, epoch: 21, loss: 0.639636
global_step: 2832, epoch: 21, loss: 0.605503
global_step: 2833, epoch: 21, loss: 0.607056
global_step: 2834, epoch: 21, loss: 0.689462
global_step: 2835, epoch: 21, loss: 0.623436
global_step: 2836, epoch: 21, loss: 0.609598
global_step: 2837, epoch: 21, loss: 0.667159
global_step: 2838, epoch: 21, loss: 0.576794
global_step: 2839, epoch: 21, loss: 0.484508
global_step: 2840, epoch: 21, loss: 1.732927
epoch: 21
train	acc: 0.8737	macro: p 0.8869, r 0.8094, f1: 0.8358	micro: p 0.8737, r 0.8737, f1 0.8737	weighted_f1:0.8722
dev	acc: 0.5176	macro: p 0.3705, r 0.3040, f1: 0.2929	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4654
test	acc: 0.5602	macro: p 0.3664, r 0.3126, f1: 0.3017	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5173
global_step: 2841, epoch: 22, loss: 0.802209
global_step: 2842, epoch: 22, loss: 0.576744
global_step: 2843, epoch: 22, loss: 0.511664
global_step: 2844, epoch: 22, loss: 0.546729
global_step: 2845, epoch: 22, loss: 0.619631
global_step: 2846, epoch: 22, loss: 0.615939
global_step: 2847, epoch: 22, loss: 0.474875
global_step: 2848, epoch: 22, loss: 0.551951
global_step: 2849, epoch: 22, loss: 0.499695
global_step: 2850, epoch: 22, loss: 0.560951
global_step: 2851, epoch: 22, loss: 0.579003
global_step: 2852, epoch: 22, loss: 0.609220
global_step: 2853, epoch: 22, loss: 0.633062
global_step: 2854, epoch: 22, loss: 0.499156
global_step: 2855, epoch: 22, loss: 0.557589
global_step: 2856, epoch: 22, loss: 0.495382
global_step: 2857, epoch: 22, loss: 0.493433
global_step: 2858, epoch: 22, loss: 0.609402
global_step: 2859, epoch: 22, loss: 0.614426
global_step: 2860, epoch: 22, loss: 0.614532
global_step: 2861, epoch: 22, loss: 0.486531
global_step: 2862, epoch: 22, loss: 0.776275
global_step: 2863, epoch: 22, loss: 0.486960
global_step: 2864, epoch: 22, loss: 0.618208
global_step: 2865, epoch: 22, loss: 0.560836
global_step: 2866, epoch: 22, loss: 0.544805
global_step: 2867, epoch: 22, loss: 0.610708
global_step: 2868, epoch: 22, loss: 0.619178
global_step: 2869, epoch: 22, loss: 0.636875
global_step: 2870, epoch: 22, loss: 0.529331
global_step: 2871, epoch: 22, loss: 0.539342
global_step: 2872, epoch: 22, loss: 0.651060
global_step: 2873, epoch: 22, loss: 0.605209
global_step: 2874, epoch: 22, loss: 0.470652
global_step: 2875, epoch: 22, loss: 0.623390
global_step: 2876, epoch: 22, loss: 0.542838
global_step: 2877, epoch: 22, loss: 0.662089
global_step: 2878, epoch: 22, loss: 0.625149
global_step: 2879, epoch: 22, loss: 0.488813
global_step: 2880, epoch: 22, loss: 0.200591
epoch: 22
train	acc: 0.9079	macro: p 0.9215, r 0.8382, f1: 0.8714	micro: p 0.9079, r 0.9079, f1 0.9079	weighted_f1:0.9073
dev	acc: 0.5365	macro: p 0.4065, r 0.3091, f1: 0.3114	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4921
test	acc: 0.5851	macro: p 0.3467, r 0.3145, f1: 0.3133	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5471
global_step: 2881, epoch: 23, loss: 0.680330
global_step: 2882, epoch: 23, loss: 0.526004
global_step: 2883, epoch: 23, loss: 0.378477
global_step: 2884, epoch: 23, loss: 0.581139
global_step: 2885, epoch: 23, loss: 0.490835
global_step: 2886, epoch: 23, loss: 0.531895
global_step: 2887, epoch: 23, loss: 0.645857
global_step: 2888, epoch: 23, loss: 0.457785
global_step: 2889, epoch: 23, loss: 0.464819
global_step: 2890, epoch: 23, loss: 0.462798
global_step: 2891, epoch: 23, loss: 0.439824
global_step: 2892, epoch: 23, loss: 0.520687
global_step: 2893, epoch: 23, loss: 0.477635
global_step: 2894, epoch: 23, loss: 0.561281
global_step: 2895, epoch: 23, loss: 0.633972
global_step: 2896, epoch: 23, loss: 0.506480
global_step: 2897, epoch: 23, loss: 0.444792
global_step: 2898, epoch: 23, loss: 0.597479
global_step: 2899, epoch: 23, loss: 0.379144
global_step: 2900, epoch: 23, loss: 0.614059
global_step: 2901, epoch: 23, loss: 0.599449
global_step: 2902, epoch: 23, loss: 0.462226
global_step: 2903, epoch: 23, loss: 0.584813
global_step: 2904, epoch: 23, loss: 0.668770
global_step: 2905, epoch: 23, loss: 0.420626
global_step: 2906, epoch: 23, loss: 0.499019
global_step: 2907, epoch: 23, loss: 0.450823
global_step: 2908, epoch: 23, loss: 0.618984
global_step: 2909, epoch: 23, loss: 0.577580
global_step: 2910, epoch: 23, loss: 0.533551
global_step: 2911, epoch: 23, loss: 0.703734
global_step: 2912, epoch: 23, loss: 0.504163
global_step: 2913, epoch: 23, loss: 0.537307
global_step: 2914, epoch: 23, loss: 0.644738
global_step: 2915, epoch: 23, loss: 0.597298
global_step: 2916, epoch: 23, loss: 0.582103
global_step: 2917, epoch: 23, loss: 0.569322
global_step: 2918, epoch: 23, loss: 0.557022
global_step: 2919, epoch: 23, loss: 0.748215
global_step: 2920, epoch: 23, loss: 0.940167
epoch: 23
train	acc: 0.9265	macro: p 0.9333, r 0.8749, f1: 0.8997	micro: p 0.9265, r 0.9265, f1 0.9265	weighted_f1:0.9260
dev	acc: 0.5203	macro: p 0.3568, r 0.2978, f1: 0.3009	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4818
test	acc: 0.5828	macro: p 0.3533, r 0.3214, f1: 0.3290	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5513
global_step: 2921, epoch: 24, loss: 0.480954
global_step: 2922, epoch: 24, loss: 0.525267
global_step: 2923, epoch: 24, loss: 0.538601
global_step: 2924, epoch: 24, loss: 0.489364
global_step: 2925, epoch: 24, loss: 0.479764
global_step: 2926, epoch: 24, loss: 0.632621
global_step: 2927, epoch: 24, loss: 0.612267
global_step: 2928, epoch: 24, loss: 0.516415
global_step: 2929, epoch: 24, loss: 0.491090
global_step: 2930, epoch: 24, loss: 0.444102
global_step: 2931, epoch: 24, loss: 0.400069
global_step: 2932, epoch: 24, loss: 0.452245
global_step: 2933, epoch: 24, loss: 0.484380
global_step: 2934, epoch: 24, loss: 0.417126
global_step: 2935, epoch: 24, loss: 0.519624
global_step: 2936, epoch: 24, loss: 0.495783
global_step: 2937, epoch: 24, loss: 0.498466
global_step: 2938, epoch: 24, loss: 0.520835
global_step: 2939, epoch: 24, loss: 0.545898
global_step: 2940, epoch: 24, loss: 0.566996
global_step: 2941, epoch: 24, loss: 0.565591
global_step: 2942, epoch: 24, loss: 0.490198
global_step: 2943, epoch: 24, loss: 0.519619
global_step: 2944, epoch: 24, loss: 0.514552
global_step: 2945, epoch: 24, loss: 0.504515
global_step: 2946, epoch: 24, loss: 0.592620
global_step: 2947, epoch: 24, loss: 0.553322
global_step: 2948, epoch: 24, loss: 0.580213
global_step: 2949, epoch: 24, loss: 0.469271
global_step: 2950, epoch: 24, loss: 0.657017
global_step: 2951, epoch: 24, loss: 0.494344
global_step: 2952, epoch: 24, loss: 0.568373
global_step: 2953, epoch: 24, loss: 0.543327
global_step: 2954, epoch: 24, loss: 0.688678
global_step: 2955, epoch: 24, loss: 0.549653
global_step: 2956, epoch: 24, loss: 0.554464
global_step: 2957, epoch: 24, loss: 0.632215
global_step: 2958, epoch: 24, loss: 0.554821
global_step: 2959, epoch: 24, loss: 0.557271
global_step: 2960, epoch: 24, loss: 0.018214
epoch: 24
train	acc: 0.9216	macro: p 0.9336, r 0.8842, f1: 0.9062	micro: p 0.9216, r 0.9216, f1 0.9216	weighted_f1:0.9218
dev	acc: 0.5203	macro: p 0.3780, r 0.3085, f1: 0.3114	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4829
test	acc: 0.5709	macro: p 0.3714, r 0.3183, f1: 0.3199	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5360
global_step: 2961, epoch: 25, loss: 0.405951
global_step: 2962, epoch: 25, loss: 0.456395
global_step: 2963, epoch: 25, loss: 0.456060
global_step: 2964, epoch: 25, loss: 0.531886
global_step: 2965, epoch: 25, loss: 0.440080
global_step: 2966, epoch: 25, loss: 0.487059
global_step: 2967, epoch: 25, loss: 0.533118
global_step: 2968, epoch: 25, loss: 0.480168
global_step: 2969, epoch: 25, loss: 0.458808
global_step: 2970, epoch: 25, loss: 0.492887
global_step: 2971, epoch: 25, loss: 0.434896
global_step: 2972, epoch: 25, loss: 0.327551
global_step: 2973, epoch: 25, loss: 0.483075
global_step: 2974, epoch: 25, loss: 0.478396
global_step: 2975, epoch: 25, loss: 0.518270
global_step: 2976, epoch: 25, loss: 0.566104
global_step: 2977, epoch: 25, loss: 0.531819
global_step: 2978, epoch: 25, loss: 0.535440
global_step: 2979, epoch: 25, loss: 0.569490
global_step: 2980, epoch: 25, loss: 0.462976
global_step: 2981, epoch: 25, loss: 0.511890
global_step: 2982, epoch: 25, loss: 0.525647
global_step: 2983, epoch: 25, loss: 0.556527
global_step: 2984, epoch: 25, loss: 0.672580
global_step: 2985, epoch: 25, loss: 0.474182
global_step: 2986, epoch: 25, loss: 0.568569
global_step: 2987, epoch: 25, loss: 0.467261
global_step: 2988, epoch: 25, loss: 0.520969
global_step: 2989, epoch: 25, loss: 0.522835
global_step: 2990, epoch: 25, loss: 0.520450
global_step: 2991, epoch: 25, loss: 0.545784
global_step: 2992, epoch: 25, loss: 0.642383
global_step: 2993, epoch: 25, loss: 0.666925
global_step: 2994, epoch: 25, loss: 0.640757
global_step: 2995, epoch: 25, loss: 0.458612
global_step: 2996, epoch: 25, loss: 0.538661
global_step: 2997, epoch: 25, loss: 0.504111
global_step: 2998, epoch: 25, loss: 0.532547
global_step: 2999, epoch: 25, loss: 0.516376
global_step: 3000, epoch: 25, loss: 0.160661
epoch: 25
train	acc: 0.9269	macro: p 0.9340, r 0.8770, f1: 0.9017	micro: p 0.9269, r 0.9269, f1 0.9269	weighted_f1:0.9263
dev	acc: 0.5266	macro: p 0.3723, r 0.3006, f1: 0.3024	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4827
test	acc: 0.5805	macro: p 0.3561, r 0.3112, f1: 0.3154	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5391
global_step: 3001, epoch: 26, loss: 0.429201
global_step: 3002, epoch: 26, loss: 0.451289
global_step: 3003, epoch: 26, loss: 0.508415
global_step: 3004, epoch: 26, loss: 0.398524
global_step: 3005, epoch: 26, loss: 0.460497
global_step: 3006, epoch: 26, loss: 0.421734
global_step: 3007, epoch: 26, loss: 0.456521
global_step: 3008, epoch: 26, loss: 0.540270
global_step: 3009, epoch: 26, loss: 0.568015
global_step: 3010, epoch: 26, loss: 0.506268
global_step: 3011, epoch: 26, loss: 0.432408
global_step: 3012, epoch: 26, loss: 0.625273
global_step: 3013, epoch: 26, loss: 0.568473
global_step: 3014, epoch: 26, loss: 0.473043
global_step: 3015, epoch: 26, loss: 0.393103
global_step: 3016, epoch: 26, loss: 0.458094
global_step: 3017, epoch: 26, loss: 0.474788
global_step: 3018, epoch: 26, loss: 0.493425
global_step: 3019, epoch: 26, loss: 0.517504
global_step: 3020, epoch: 26, loss: 0.494307
global_step: 3021, epoch: 26, loss: 0.533926
global_step: 3022, epoch: 26, loss: 0.459154
global_step: 3023, epoch: 26, loss: 0.472729
global_step: 3024, epoch: 26, loss: 0.413232
global_step: 3025, epoch: 26, loss: 0.454617
global_step: 3026, epoch: 26, loss: 0.478070
global_step: 3027, epoch: 26, loss: 0.450338
global_step: 3028, epoch: 26, loss: 0.596316
global_step: 3029, epoch: 26, loss: 0.542230
global_step: 3030, epoch: 26, loss: 0.505105
global_step: 3031, epoch: 26, loss: 0.567923
global_step: 3032, epoch: 26, loss: 0.566429
global_step: 3033, epoch: 26, loss: 0.517994
global_step: 3034, epoch: 26, loss: 0.514877
global_step: 3035, epoch: 26, loss: 0.655105
global_step: 3036, epoch: 26, loss: 0.509772
global_step: 3037, epoch: 26, loss: 0.555135
global_step: 3038, epoch: 26, loss: 0.517063
global_step: 3039, epoch: 26, loss: 0.596919
global_step: 3040, epoch: 26, loss: 0.550374
epoch: 26
train	acc: 0.9092	macro: p 0.9257, r 0.8752, f1: 0.8964	micro: p 0.9092, r 0.9092, f1 0.9092	weighted_f1:0.9099
dev	acc: 0.4968	macro: p 0.3735, r 0.2967, f1: 0.2886	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.4624
test	acc: 0.5452	macro: p 0.3819, r 0.3056, f1: 0.2969	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5104
global_step: 3041, epoch: 27, loss: 0.571273
global_step: 3042, epoch: 27, loss: 0.435523
global_step: 3043, epoch: 27, loss: 0.436698
global_step: 3044, epoch: 27, loss: 0.491242
global_step: 3045, epoch: 27, loss: 0.450495
global_step: 3046, epoch: 27, loss: 0.440566
global_step: 3047, epoch: 27, loss: 0.553805
global_step: 3048, epoch: 27, loss: 0.493678
global_step: 3049, epoch: 27, loss: 0.423198
global_step: 3050, epoch: 27, loss: 0.461679
global_step: 3051, epoch: 27, loss: 0.524883
global_step: 3052, epoch: 27, loss: 0.482542
global_step: 3053, epoch: 27, loss: 0.401128
global_step: 3054, epoch: 27, loss: 0.546711
global_step: 3055, epoch: 27, loss: 0.433956
global_step: 3056, epoch: 27, loss: 0.516003
global_step: 3057, epoch: 27, loss: 0.359950
global_step: 3058, epoch: 27, loss: 0.517831
global_step: 3059, epoch: 27, loss: 0.373776
global_step: 3060, epoch: 27, loss: 0.407329
global_step: 3061, epoch: 27, loss: 0.526017
global_step: 3062, epoch: 27, loss: 0.410704
global_step: 3063, epoch: 27, loss: 0.453004
global_step: 3064, epoch: 27, loss: 0.570931
global_step: 3065, epoch: 27, loss: 0.462578
global_step: 3066, epoch: 27, loss: 0.496413
global_step: 3067, epoch: 27, loss: 0.450225
global_step: 3068, epoch: 27, loss: 0.419339
global_step: 3069, epoch: 27, loss: 0.494231
global_step: 3070, epoch: 27, loss: 0.514324
global_step: 3071, epoch: 27, loss: 0.474468
global_step: 3072, epoch: 27, loss: 0.547661
global_step: 3073, epoch: 27, loss: 0.513632
global_step: 3074, epoch: 27, loss: 0.468699
global_step: 3075, epoch: 27, loss: 0.589740
global_step: 3076, epoch: 27, loss: 0.478551
global_step: 3077, epoch: 27, loss: 0.447460
global_step: 3078, epoch: 27, loss: 0.569735
global_step: 3079, epoch: 27, loss: 0.455734
global_step: 3080, epoch: 27, loss: 0.660405
epoch: 27
train	acc: 0.9343	macro: p 0.9271, r 0.9072, f1: 0.9158	micro: p 0.9343, r 0.9343, f1 0.9343	weighted_f1:0.9345
dev	acc: 0.5068	macro: p 0.3517, r 0.3134, f1: 0.3176	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4828
test	acc: 0.5548	macro: p 0.3345, r 0.3213, f1: 0.3205	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5351
global_step: 3081, epoch: 28, loss: 0.402753
global_step: 3082, epoch: 28, loss: 0.353809
global_step: 3083, epoch: 28, loss: 0.429118
global_step: 3084, epoch: 28, loss: 0.560233
global_step: 3085, epoch: 28, loss: 0.571466
global_step: 3086, epoch: 28, loss: 0.379869
global_step: 3087, epoch: 28, loss: 0.387543
global_step: 3088, epoch: 28, loss: 0.542249
global_step: 3089, epoch: 28, loss: 0.337693
global_step: 3090, epoch: 28, loss: 0.453972
global_step: 3091, epoch: 28, loss: 0.369415
global_step: 3092, epoch: 28, loss: 0.629654
global_step: 3093, epoch: 28, loss: 0.476862
global_step: 3094, epoch: 28, loss: 0.468571
global_step: 3095, epoch: 28, loss: 0.526136
global_step: 3096, epoch: 28, loss: 0.552957
global_step: 3097, epoch: 28, loss: 0.445439
global_step: 3098, epoch: 28, loss: 0.413211
global_step: 3099, epoch: 28, loss: 0.383684
global_step: 3100, epoch: 28, loss: 0.414185
global_step: 3101, epoch: 28, loss: 0.411215
global_step: 3102, epoch: 28, loss: 0.422906
global_step: 3103, epoch: 28, loss: 0.508996
global_step: 3104, epoch: 28, loss: 0.442717
global_step: 3105, epoch: 28, loss: 0.384445
global_step: 3106, epoch: 28, loss: 0.425377
global_step: 3107, epoch: 28, loss: 0.497750
global_step: 3108, epoch: 28, loss: 0.458592
global_step: 3109, epoch: 28, loss: 0.519360
global_step: 3110, epoch: 28, loss: 0.479800
global_step: 3111, epoch: 28, loss: 0.364716
global_step: 3112, epoch: 28, loss: 0.447302
global_step: 3113, epoch: 28, loss: 0.366924
global_step: 3114, epoch: 28, loss: 0.432863
global_step: 3115, epoch: 28, loss: 0.367800
global_step: 3116, epoch: 28, loss: 0.450709
global_step: 3117, epoch: 28, loss: 0.472560
global_step: 3118, epoch: 28, loss: 0.571223
global_step: 3119, epoch: 28, loss: 0.389903
global_step: 3120, epoch: 28, loss: 0.481013
epoch: 28
train	acc: 0.9454	macro: p 0.9466, r 0.9196, f1: 0.9323	micro: p 0.9454, r 0.9454, f1 0.9454	weighted_f1:0.9451
dev	acc: 0.5266	macro: p 0.3422, r 0.2965, f1: 0.3058	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4852
test	acc: 0.5628	macro: p 0.3636, r 0.3098, f1: 0.3246	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5290
global_step: 3121, epoch: 29, loss: 0.496789
global_step: 3122, epoch: 29, loss: 0.435153
global_step: 3123, epoch: 29, loss: 0.306959
global_step: 3124, epoch: 29, loss: 0.358624
global_step: 3125, epoch: 29, loss: 0.567555
global_step: 3126, epoch: 29, loss: 0.540154
global_step: 3127, epoch: 29, loss: 0.402304
global_step: 3128, epoch: 29, loss: 0.506480
global_step: 3129, epoch: 29, loss: 0.300457
global_step: 3130, epoch: 29, loss: 0.365838
global_step: 3131, epoch: 29, loss: 0.419270
global_step: 3132, epoch: 29, loss: 0.515658
global_step: 3133, epoch: 29, loss: 0.403635
global_step: 3134, epoch: 29, loss: 0.496307
global_step: 3135, epoch: 29, loss: 0.410396
global_step: 3136, epoch: 29, loss: 0.427702
global_step: 3137, epoch: 29, loss: 0.457684
global_step: 3138, epoch: 29, loss: 0.398449
global_step: 3139, epoch: 29, loss: 0.431327
global_step: 3140, epoch: 29, loss: 0.440343
global_step: 3141, epoch: 29, loss: 0.483629
global_step: 3142, epoch: 29, loss: 0.454894
global_step: 3143, epoch: 29, loss: 0.572042
global_step: 3144, epoch: 29, loss: 0.429004
global_step: 3145, epoch: 29, loss: 0.430492
global_step: 3146, epoch: 29, loss: 0.517013
global_step: 3147, epoch: 29, loss: 0.438607
global_step: 3148, epoch: 29, loss: 0.456356
global_step: 3149, epoch: 29, loss: 0.494034
global_step: 3150, epoch: 29, loss: 0.399316
global_step: 3151, epoch: 29, loss: 0.442405
global_step: 3152, epoch: 29, loss: 0.439927
global_step: 3153, epoch: 29, loss: 0.509897
global_step: 3154, epoch: 29, loss: 0.429272
global_step: 3155, epoch: 29, loss: 0.411520
global_step: 3156, epoch: 29, loss: 0.599310
global_step: 3157, epoch: 29, loss: 0.477886
global_step: 3158, epoch: 29, loss: 0.498277
global_step: 3159, epoch: 29, loss: 0.370612
global_step: 3160, epoch: 29, loss: 0.543942
epoch: 29
train	acc: 0.9210	macro: p 0.9394, r 0.8786, f1: 0.9044	micro: p 0.9210, r 0.9210, f1 0.9210	weighted_f1:0.9214
dev	acc: 0.5050	macro: p 0.3599, r 0.2874, f1: 0.2744	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4568
test	acc: 0.5743	macro: p 0.4091, r 0.3205, f1: 0.3115	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5332
global_step: 3161, epoch: 30, loss: 0.591560
global_step: 3162, epoch: 30, loss: 0.389713
global_step: 3163, epoch: 30, loss: 0.520851
global_step: 3164, epoch: 30, loss: 0.455309
global_step: 3165, epoch: 30, loss: 0.522171
global_step: 3166, epoch: 30, loss: 0.494903
global_step: 3167, epoch: 30, loss: 0.451513
global_step: 3168, epoch: 30, loss: 0.381661
global_step: 3169, epoch: 30, loss: 0.436032
global_step: 3170, epoch: 30, loss: 0.455551
global_step: 3171, epoch: 30, loss: 0.500606
global_step: 3172, epoch: 30, loss: 0.388864
global_step: 3173, epoch: 30, loss: 0.408558
global_step: 3174, epoch: 30, loss: 0.360992
global_step: 3175, epoch: 30, loss: 0.369508
global_step: 3176, epoch: 30, loss: 0.422047
global_step: 3177, epoch: 30, loss: 0.505126
global_step: 3178, epoch: 30, loss: 0.457491
global_step: 3179, epoch: 30, loss: 0.472545
global_step: 3180, epoch: 30, loss: 0.450860
global_step: 3181, epoch: 30, loss: 0.412350
global_step: 3182, epoch: 30, loss: 0.401505
global_step: 3183, epoch: 30, loss: 0.522202
global_step: 3184, epoch: 30, loss: 0.381850
global_step: 3185, epoch: 30, loss: 0.446780
global_step: 3186, epoch: 30, loss: 0.418746
global_step: 3187, epoch: 30, loss: 0.458749
global_step: 3188, epoch: 30, loss: 0.403714
global_step: 3189, epoch: 30, loss: 0.401981
global_step: 3190, epoch: 30, loss: 0.440698
global_step: 3191, epoch: 30, loss: 0.494831
global_step: 3192, epoch: 30, loss: 0.392592
global_step: 3193, epoch: 30, loss: 0.454019
global_step: 3194, epoch: 30, loss: 0.486672
global_step: 3195, epoch: 30, loss: 0.419690
global_step: 3196, epoch: 30, loss: 0.417932
global_step: 3197, epoch: 30, loss: 0.445837
global_step: 3198, epoch: 30, loss: 0.564972
global_step: 3199, epoch: 30, loss: 0.441094
global_step: 3200, epoch: 30, loss: 0.129424
epoch: 30
train	acc: 0.9425	macro: p 0.9543, r 0.9096, f1: 0.9307	micro: p 0.9425, r 0.9425, f1 0.9425	weighted_f1:0.9422
dev	acc: 0.5392	macro: p 0.3773, r 0.3046, f1: 0.3099	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4873
test	acc: 0.5812	macro: p 0.3693, r 0.3105, f1: 0.3194	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5371
global_step: 3201, epoch: 31, loss: 0.414716
global_step: 3202, epoch: 31, loss: 0.342622
global_step: 3203, epoch: 31, loss: 0.400631
global_step: 3204, epoch: 31, loss: 0.358994
global_step: 3205, epoch: 31, loss: 0.425556
global_step: 3206, epoch: 31, loss: 0.427010
global_step: 3207, epoch: 31, loss: 0.369042
global_step: 3208, epoch: 31, loss: 0.313086
global_step: 3209, epoch: 31, loss: 0.495196
global_step: 3210, epoch: 31, loss: 0.393185
global_step: 3211, epoch: 31, loss: 0.428696
global_step: 3212, epoch: 31, loss: 0.402812
global_step: 3213, epoch: 31, loss: 0.571159
global_step: 3214, epoch: 31, loss: 0.499339
global_step: 3215, epoch: 31, loss: 0.524229
global_step: 3216, epoch: 31, loss: 0.457213
global_step: 3217, epoch: 31, loss: 0.403229
global_step: 3218, epoch: 31, loss: 0.425237
global_step: 3219, epoch: 31, loss: 0.421627
global_step: 3220, epoch: 31, loss: 0.433335
global_step: 3221, epoch: 31, loss: 0.379783
global_step: 3222, epoch: 31, loss: 0.411669
global_step: 3223, epoch: 31, loss: 0.465489
global_step: 3224, epoch: 31, loss: 0.400518
global_step: 3225, epoch: 31, loss: 0.432047
global_step: 3226, epoch: 31, loss: 0.491296
global_step: 3227, epoch: 31, loss: 0.468621
global_step: 3228, epoch: 31, loss: 0.521767
global_step: 3229, epoch: 31, loss: 0.344314
global_step: 3230, epoch: 31, loss: 0.329441
global_step: 3231, epoch: 31, loss: 0.446264
global_step: 3232, epoch: 31, loss: 0.488788
global_step: 3233, epoch: 31, loss: 0.499652
global_step: 3234, epoch: 31, loss: 0.442806
global_step: 3235, epoch: 31, loss: 0.394491
global_step: 3236, epoch: 31, loss: 0.435921
global_step: 3237, epoch: 31, loss: 0.598073
global_step: 3238, epoch: 31, loss: 0.453740
global_step: 3239, epoch: 31, loss: 0.416440
global_step: 3240, epoch: 31, loss: 2.092721
epoch: 31
train	acc: 0.9349	macro: p 0.9322, r 0.9225, f1: 0.9258	micro: p 0.9349, r 0.9349, f1 0.9349	weighted_f1:0.9354
dev	acc: 0.4914	macro: p 0.3237, r 0.3169, f1: 0.3145	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4809
test	acc: 0.5042	macro: p 0.3120, r 0.3137, f1: 0.3078	micro: p 0.5042, r 0.5042, f1 0.5042	weighted_f1:0.5016
global_step: 3241, epoch: 32, loss: 0.562687
global_step: 3242, epoch: 32, loss: 0.421519
global_step: 3243, epoch: 32, loss: 0.398275
global_step: 3244, epoch: 32, loss: 0.369442
global_step: 3245, epoch: 32, loss: 0.358694
global_step: 3246, epoch: 32, loss: 0.473805
global_step: 3247, epoch: 32, loss: 0.458180
global_step: 3248, epoch: 32, loss: 0.425441
global_step: 3249, epoch: 32, loss: 0.478324
global_step: 3250, epoch: 32, loss: 0.323137
global_step: 3251, epoch: 32, loss: 0.446582
global_step: 3252, epoch: 32, loss: 0.479477
global_step: 3253, epoch: 32, loss: 0.384539
global_step: 3254, epoch: 32, loss: 0.401796
global_step: 3255, epoch: 32, loss: 0.437478
global_step: 3256, epoch: 32, loss: 0.454465
global_step: 3257, epoch: 32, loss: 0.355776
global_step: 3258, epoch: 32, loss: 0.327988
global_step: 3259, epoch: 32, loss: 0.506807
global_step: 3260, epoch: 32, loss: 0.375601
global_step: 3261, epoch: 32, loss: 0.450076
global_step: 3262, epoch: 32, loss: 0.394220
global_step: 3263, epoch: 32, loss: 0.420479
global_step: 3264, epoch: 32, loss: 0.394948
global_step: 3265, epoch: 32, loss: 0.419877
global_step: 3266, epoch: 32, loss: 0.447545
global_step: 3267, epoch: 32, loss: 0.496594
global_step: 3268, epoch: 32, loss: 0.445831
global_step: 3269, epoch: 32, loss: 0.365265
global_step: 3270, epoch: 32, loss: 0.366586
global_step: 3271, epoch: 32, loss: 0.340179
global_step: 3272, epoch: 32, loss: 0.410154
global_step: 3273, epoch: 32, loss: 0.395319
global_step: 3274, epoch: 32, loss: 0.407790
global_step: 3275, epoch: 32, loss: 0.484158
global_step: 3276, epoch: 32, loss: 0.407713
global_step: 3277, epoch: 32, loss: 0.504812
global_step: 3278, epoch: 32, loss: 0.499096
global_step: 3279, epoch: 32, loss: 0.489137
global_step: 3280, epoch: 32, loss: 0.808659
epoch: 32
train	acc: 0.9142	macro: p 0.9213, r 0.9151, f1: 0.9156	micro: p 0.9142, r 0.9142, f1 0.9142	weighted_f1:0.9162
dev	acc: 0.4518	macro: p 0.3477, r 0.3052, f1: 0.2971	micro: p 0.4518, r 0.4518, f1 0.4518	weighted_f1:0.4481
test	acc: 0.4789	macro: p 0.3337, r 0.3085, f1: 0.2966	micro: p 0.4789, r 0.4789, f1 0.4789	weighted_f1:0.4792
global_step: 3281, epoch: 33, loss: 0.547698
global_step: 3282, epoch: 33, loss: 0.393618
global_step: 3283, epoch: 33, loss: 0.443597
global_step: 3284, epoch: 33, loss: 0.363355
global_step: 3285, epoch: 33, loss: 0.422976
global_step: 3286, epoch: 33, loss: 0.364471
global_step: 3287, epoch: 33, loss: 0.385975
global_step: 3288, epoch: 33, loss: 0.471355
global_step: 3289, epoch: 33, loss: 0.340221
global_step: 3290, epoch: 33, loss: 0.385233
global_step: 3291, epoch: 33, loss: 0.393831
global_step: 3292, epoch: 33, loss: 0.392573
global_step: 3293, epoch: 33, loss: 0.420474
global_step: 3294, epoch: 33, loss: 0.429126
global_step: 3295, epoch: 33, loss: 0.510367
global_step: 3296, epoch: 33, loss: 0.454450
global_step: 3297, epoch: 33, loss: 0.480600
global_step: 3298, epoch: 33, loss: 0.479434
global_step: 3299, epoch: 33, loss: 0.410928
global_step: 3300, epoch: 33, loss: 0.400139
global_step: 3301, epoch: 33, loss: 0.389607
global_step: 3302, epoch: 33, loss: 0.469957
global_step: 3303, epoch: 33, loss: 0.395477
global_step: 3304, epoch: 33, loss: 0.382915
global_step: 3305, epoch: 33, loss: 0.423111
global_step: 3306, epoch: 33, loss: 0.380894
global_step: 3307, epoch: 33, loss: 0.441693
global_step: 3308, epoch: 33, loss: 0.290669
global_step: 3309, epoch: 33, loss: 0.441527
global_step: 3310, epoch: 33, loss: 0.339229
global_step: 3311, epoch: 33, loss: 0.437878
global_step: 3312, epoch: 33, loss: 0.436418
global_step: 3313, epoch: 33, loss: 0.449482
global_step: 3314, epoch: 33, loss: 0.323861
global_step: 3315, epoch: 33, loss: 0.423969
global_step: 3316, epoch: 33, loss: 0.501324
global_step: 3317, epoch: 33, loss: 0.368066
global_step: 3318, epoch: 33, loss: 0.382286
global_step: 3319, epoch: 33, loss: 0.396250
global_step: 3320, epoch: 33, loss: 0.278941
epoch: 33
train	acc: 0.9515	macro: p 0.9597, r 0.9264, f1: 0.9421	micro: p 0.9515, r 0.9515, f1 0.9515	weighted_f1:0.9514
dev	acc: 0.5338	macro: p 0.3571, r 0.2959, f1: 0.2978	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4812
test	acc: 0.5831	macro: p 0.4047, r 0.3189, f1: 0.3301	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5393
global_step: 3321, epoch: 34, loss: 0.375156
global_step: 3322, epoch: 34, loss: 0.497876
global_step: 3323, epoch: 34, loss: 0.394058
global_step: 3324, epoch: 34, loss: 0.313496
global_step: 3325, epoch: 34, loss: 0.438378
global_step: 3326, epoch: 34, loss: 0.399336
global_step: 3327, epoch: 34, loss: 0.323899
global_step: 3328, epoch: 34, loss: 0.358507
global_step: 3329, epoch: 34, loss: 0.330039
global_step: 3330, epoch: 34, loss: 0.335667
global_step: 3331, epoch: 34, loss: 0.358240
global_step: 3332, epoch: 34, loss: 0.350937
global_step: 3333, epoch: 34, loss: 0.345641
global_step: 3334, epoch: 34, loss: 0.309551
global_step: 3335, epoch: 34, loss: 0.417482
global_step: 3336, epoch: 34, loss: 0.395212
global_step: 3337, epoch: 34, loss: 0.448426
global_step: 3338, epoch: 34, loss: 0.367360
global_step: 3339, epoch: 34, loss: 0.406901
global_step: 3340, epoch: 34, loss: 0.417695
global_step: 3341, epoch: 34, loss: 0.494838
global_step: 3342, epoch: 34, loss: 0.480333
global_step: 3343, epoch: 34, loss: 0.408036
global_step: 3344, epoch: 34, loss: 0.397599
global_step: 3345, epoch: 34, loss: 0.352299
global_step: 3346, epoch: 34, loss: 0.352606
global_step: 3347, epoch: 34, loss: 0.391384
global_step: 3348, epoch: 34, loss: 0.349803
global_step: 3349, epoch: 34, loss: 0.306483
global_step: 3350, epoch: 34, loss: 0.347986
global_step: 3351, epoch: 34, loss: 0.529925
global_step: 3352, epoch: 34, loss: 0.390909
global_step: 3353, epoch: 34, loss: 0.385983
global_step: 3354, epoch: 34, loss: 0.298410
global_step: 3355, epoch: 34, loss: 0.362533
global_step: 3356, epoch: 34, loss: 0.361210
global_step: 3357, epoch: 34, loss: 0.297810
global_step: 3358, epoch: 34, loss: 0.403418
global_step: 3359, epoch: 34, loss: 0.359442
global_step: 3360, epoch: 34, loss: 0.263639
epoch: 34
train	acc: 0.9532	macro: p 0.9583, r 0.9299, f1: 0.9430	micro: p 0.9532, r 0.9532, f1 0.9532	weighted_f1:0.9533
dev	acc: 0.5320	macro: p 0.3505, r 0.3139, f1: 0.3131	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4935
test	acc: 0.5701	macro: p 0.3743, r 0.3214, f1: 0.3256	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5333
global_step: 3361, epoch: 35, loss: 0.321113
global_step: 3362, epoch: 35, loss: 0.390375
global_step: 3363, epoch: 35, loss: 0.295736
global_step: 3364, epoch: 35, loss: 0.337622
global_step: 3365, epoch: 35, loss: 0.423816
global_step: 3366, epoch: 35, loss: 0.329390
global_step: 3367, epoch: 35, loss: 0.295359
global_step: 3368, epoch: 35, loss: 0.395201
global_step: 3369, epoch: 35, loss: 0.391639
global_step: 3370, epoch: 35, loss: 0.292981
global_step: 3371, epoch: 35, loss: 0.351617
global_step: 3372, epoch: 35, loss: 0.395096
global_step: 3373, epoch: 35, loss: 0.349945
global_step: 3374, epoch: 35, loss: 0.402255
global_step: 3375, epoch: 35, loss: 0.363983
global_step: 3376, epoch: 35, loss: 0.360834
global_step: 3377, epoch: 35, loss: 0.379236
global_step: 3378, epoch: 35, loss: 0.360289
global_step: 3379, epoch: 35, loss: 0.400568
global_step: 3380, epoch: 35, loss: 0.366808
global_step: 3381, epoch: 35, loss: 0.345679
global_step: 3382, epoch: 35, loss: 0.375986
global_step: 3383, epoch: 35, loss: 0.356496
global_step: 3384, epoch: 35, loss: 0.284343
global_step: 3385, epoch: 35, loss: 0.312591
global_step: 3386, epoch: 35, loss: 0.460207
global_step: 3387, epoch: 35, loss: 0.497421
global_step: 3388, epoch: 35, loss: 0.273696
global_step: 3389, epoch: 35, loss: 0.527915
global_step: 3390, epoch: 35, loss: 0.543985
global_step: 3391, epoch: 35, loss: 0.445868
global_step: 3392, epoch: 35, loss: 0.391918
global_step: 3393, epoch: 35, loss: 0.496743
global_step: 3394, epoch: 35, loss: 0.483252
global_step: 3395, epoch: 35, loss: 0.509030
global_step: 3396, epoch: 35, loss: 0.399923
global_step: 3397, epoch: 35, loss: 0.396679
global_step: 3398, epoch: 35, loss: 0.476642
global_step: 3399, epoch: 35, loss: 0.398159
global_step: 3400, epoch: 35, loss: 0.110904
epoch: 35
train	acc: 0.9492	macro: p 0.9469, r 0.9295, f1: 0.9373	micro: p 0.9492, r 0.9492, f1 0.9492	weighted_f1:0.9494
dev	acc: 0.5194	macro: p 0.3983, r 0.3391, f1: 0.3431	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4961
test	acc: 0.5460	macro: p 0.3533, r 0.3246, f1: 0.3257	micro: p 0.5460, r 0.5460, f1 0.5460	weighted_f1:0.5287
global_step: 3401, epoch: 36, loss: 0.390303
global_step: 3402, epoch: 36, loss: 0.490818
global_step: 3403, epoch: 36, loss: 0.378082
global_step: 3404, epoch: 36, loss: 0.458287
global_step: 3405, epoch: 36, loss: 0.377725
global_step: 3406, epoch: 36, loss: 0.338920
global_step: 3407, epoch: 36, loss: 0.353353
global_step: 3408, epoch: 36, loss: 0.344516
global_step: 3409, epoch: 36, loss: 0.382947
global_step: 3410, epoch: 36, loss: 0.344180
global_step: 3411, epoch: 36, loss: 0.305052
global_step: 3412, epoch: 36, loss: 0.368679
global_step: 3413, epoch: 36, loss: 0.450572
global_step: 3414, epoch: 36, loss: 0.328238
global_step: 3415, epoch: 36, loss: 0.400556
global_step: 3416, epoch: 36, loss: 0.313987
global_step: 3417, epoch: 36, loss: 0.354494
global_step: 3418, epoch: 36, loss: 0.356393
global_step: 3419, epoch: 36, loss: 0.402205
global_step: 3420, epoch: 36, loss: 0.470021
global_step: 3421, epoch: 36, loss: 0.486144
global_step: 3422, epoch: 36, loss: 0.406719
global_step: 3423, epoch: 36, loss: 0.315509
global_step: 3424, epoch: 36, loss: 0.355213
global_step: 3425, epoch: 36, loss: 0.511916
global_step: 3426, epoch: 36, loss: 0.524654
global_step: 3427, epoch: 36, loss: 0.404424
global_step: 3428, epoch: 36, loss: 0.429551
global_step: 3429, epoch: 36, loss: 0.386913
global_step: 3430, epoch: 36, loss: 0.417033
global_step: 3431, epoch: 36, loss: 0.430488
global_step: 3432, epoch: 36, loss: 0.341577
global_step: 3433, epoch: 36, loss: 0.445491
global_step: 3434, epoch: 36, loss: 0.406713
global_step: 3435, epoch: 36, loss: 0.510983
global_step: 3436, epoch: 36, loss: 0.403404
global_step: 3437, epoch: 36, loss: 0.403585
global_step: 3438, epoch: 36, loss: 0.391758
global_step: 3439, epoch: 36, loss: 0.487170
global_step: 3440, epoch: 36, loss: 0.664454
epoch: 36
train	acc: 0.9471	macro: p 0.9464, r 0.9301, f1: 0.9375	micro: p 0.9471, r 0.9471, f1 0.9471	weighted_f1:0.9472
dev	acc: 0.4851	macro: p 0.3350, r 0.3092, f1: 0.3102	micro: p 0.4851, r 0.4851, f1 0.4851	weighted_f1:0.4645
test	acc: 0.5337	macro: p 0.3311, r 0.3217, f1: 0.3180	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.5189
global_step: 3441, epoch: 37, loss: 0.419592
global_step: 3442, epoch: 37, loss: 0.282239
global_step: 3443, epoch: 37, loss: 0.364380
global_step: 3444, epoch: 37, loss: 0.371125
global_step: 3445, epoch: 37, loss: 0.354636
global_step: 3446, epoch: 37, loss: 0.386971
global_step: 3447, epoch: 37, loss: 0.295365
global_step: 3448, epoch: 37, loss: 0.320239
global_step: 3449, epoch: 37, loss: 0.384412
global_step: 3450, epoch: 37, loss: 0.361537
global_step: 3451, epoch: 37, loss: 0.300521
global_step: 3452, epoch: 37, loss: 0.347728
global_step: 3453, epoch: 37, loss: 0.422765
global_step: 3454, epoch: 37, loss: 0.416144
global_step: 3455, epoch: 37, loss: 0.378651
global_step: 3456, epoch: 37, loss: 0.355364
global_step: 3457, epoch: 37, loss: 0.382858
global_step: 3458, epoch: 37, loss: 0.414985
global_step: 3459, epoch: 37, loss: 0.368053
global_step: 3460, epoch: 37, loss: 0.413023
global_step: 3461, epoch: 37, loss: 0.383384
global_step: 3462, epoch: 37, loss: 0.490234
global_step: 3463, epoch: 37, loss: 0.480791
global_step: 3464, epoch: 37, loss: 0.364229
global_step: 3465, epoch: 37, loss: 0.406576
global_step: 3466, epoch: 37, loss: 0.415331
global_step: 3467, epoch: 37, loss: 0.422925
global_step: 3468, epoch: 37, loss: 0.429850
global_step: 3469, epoch: 37, loss: 0.419099
global_step: 3470, epoch: 37, loss: 0.409761
global_step: 3471, epoch: 37, loss: 0.365868
global_step: 3472, epoch: 37, loss: 0.425738
global_step: 3473, epoch: 37, loss: 0.462247
global_step: 3474, epoch: 37, loss: 0.471099
global_step: 3475, epoch: 37, loss: 0.407806
global_step: 3476, epoch: 37, loss: 0.387013
global_step: 3477, epoch: 37, loss: 0.359212
global_step: 3478, epoch: 37, loss: 0.321264
global_step: 3479, epoch: 37, loss: 0.453579
global_step: 3480, epoch: 37, loss: 0.040624
epoch: 37
train	acc: 0.9541	macro: p 0.9577, r 0.9331, f1: 0.9446	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9542
dev	acc: 0.5077	macro: p 0.3297, r 0.2986, f1: 0.2974	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4782
test	acc: 0.5609	macro: p 0.3659, r 0.3246, f1: 0.3267	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5377
global_step: 3481, epoch: 38, loss: 0.376513
global_step: 3482, epoch: 38, loss: 0.358161
global_step: 3483, epoch: 38, loss: 0.416212
global_step: 3484, epoch: 38, loss: 0.420608
global_step: 3485, epoch: 38, loss: 0.366818
global_step: 3486, epoch: 38, loss: 0.320752
global_step: 3487, epoch: 38, loss: 0.408896
global_step: 3488, epoch: 38, loss: 0.353408
global_step: 3489, epoch: 38, loss: 0.354907
global_step: 3490, epoch: 38, loss: 0.314448
global_step: 3491, epoch: 38, loss: 0.427522
global_step: 3492, epoch: 38, loss: 0.243370
global_step: 3493, epoch: 38, loss: 0.279926
global_step: 3494, epoch: 38, loss: 0.345896
global_step: 3495, epoch: 38, loss: 0.380499
global_step: 3496, epoch: 38, loss: 0.378617
global_step: 3497, epoch: 38, loss: 0.446689
global_step: 3498, epoch: 38, loss: 0.345819
global_step: 3499, epoch: 38, loss: 0.426244
global_step: 3500, epoch: 38, loss: 0.346155
global_step: 3501, epoch: 38, loss: 0.363916
global_step: 3502, epoch: 38, loss: 0.373591
global_step: 3503, epoch: 38, loss: 0.413880
global_step: 3504, epoch: 38, loss: 0.333221
global_step: 3505, epoch: 38, loss: 0.372536
global_step: 3506, epoch: 38, loss: 0.368438
global_step: 3507, epoch: 38, loss: 0.364419
global_step: 3508, epoch: 38, loss: 0.428682
global_step: 3509, epoch: 38, loss: 0.446231
global_step: 3510, epoch: 38, loss: 0.236908
global_step: 3511, epoch: 38, loss: 0.493471
global_step: 3512, epoch: 38, loss: 0.478316
global_step: 3513, epoch: 38, loss: 0.396041
global_step: 3514, epoch: 38, loss: 0.402257
global_step: 3515, epoch: 38, loss: 0.314238
global_step: 3516, epoch: 38, loss: 0.482030
global_step: 3517, epoch: 38, loss: 0.482822
global_step: 3518, epoch: 38, loss: 0.392900
global_step: 3519, epoch: 38, loss: 0.390200
global_step: 3520, epoch: 38, loss: 0.438840
epoch: 38
train	acc: 0.9519	macro: p 0.9610, r 0.9266, f1: 0.9431	micro: p 0.9519, r 0.9519, f1 0.9519	weighted_f1:0.9517
dev	acc: 0.5338	macro: p 0.3765, r 0.3065, f1: 0.3140	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4883
test	acc: 0.5805	macro: p 0.3999, r 0.3169, f1: 0.3319	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5382
global_step: 3521, epoch: 39, loss: 0.296435
global_step: 3522, epoch: 39, loss: 0.368711
global_step: 3523, epoch: 39, loss: 0.295682
global_step: 3524, epoch: 39, loss: 0.395211
global_step: 3525, epoch: 39, loss: 0.220940
global_step: 3526, epoch: 39, loss: 0.362417
global_step: 3527, epoch: 39, loss: 0.361320
global_step: 3528, epoch: 39, loss: 0.360898
global_step: 3529, epoch: 39, loss: 0.312781
global_step: 3530, epoch: 39, loss: 0.425385
global_step: 3531, epoch: 39, loss: 0.288474
global_step: 3532, epoch: 39, loss: 0.235251
global_step: 3533, epoch: 39, loss: 0.339230
global_step: 3534, epoch: 39, loss: 0.364673
global_step: 3535, epoch: 39, loss: 0.360554
global_step: 3536, epoch: 39, loss: 0.464625
global_step: 3537, epoch: 39, loss: 0.407423
global_step: 3538, epoch: 39, loss: 0.371844
global_step: 3539, epoch: 39, loss: 0.394123
global_step: 3540, epoch: 39, loss: 0.416694
global_step: 3541, epoch: 39, loss: 0.360881
global_step: 3542, epoch: 39, loss: 0.347958
global_step: 3543, epoch: 39, loss: 0.350133
global_step: 3544, epoch: 39, loss: 0.320367
global_step: 3545, epoch: 39, loss: 0.331547
global_step: 3546, epoch: 39, loss: 0.431334
global_step: 3547, epoch: 39, loss: 0.335788
global_step: 3548, epoch: 39, loss: 0.380695
global_step: 3549, epoch: 39, loss: 0.452447
global_step: 3550, epoch: 39, loss: 0.505599
global_step: 3551, epoch: 39, loss: 0.334205
global_step: 3552, epoch: 39, loss: 0.342473
global_step: 3553, epoch: 39, loss: 0.389062
global_step: 3554, epoch: 39, loss: 0.484825
global_step: 3555, epoch: 39, loss: 0.430661
global_step: 3556, epoch: 39, loss: 0.327320
global_step: 3557, epoch: 39, loss: 0.413933
global_step: 3558, epoch: 39, loss: 0.462818
global_step: 3559, epoch: 39, loss: 0.377000
global_step: 3560, epoch: 39, loss: 0.032685
epoch: 39
train	acc: 0.9584	macro: p 0.9635, r 0.9369, f1: 0.9496	micro: p 0.9584, r 0.9584, f1 0.9584	weighted_f1:0.9583
dev	acc: 0.5203	macro: p 0.3334, r 0.2944, f1: 0.2978	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4793
test	acc: 0.5701	macro: p 0.4044, r 0.3171, f1: 0.3315	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5352
global_step: 3561, epoch: 40, loss: 0.333022
global_step: 3562, epoch: 40, loss: 0.391589
global_step: 3563, epoch: 40, loss: 0.235207
global_step: 3564, epoch: 40, loss: 0.337810
global_step: 3565, epoch: 40, loss: 0.375420
global_step: 3566, epoch: 40, loss: 0.324753
global_step: 3567, epoch: 40, loss: 0.271647
global_step: 3568, epoch: 40, loss: 0.356307
global_step: 3569, epoch: 40, loss: 0.371824
global_step: 3570, epoch: 40, loss: 0.332013
global_step: 3571, epoch: 40, loss: 0.366600
global_step: 3572, epoch: 40, loss: 0.364136
global_step: 3573, epoch: 40, loss: 0.334944
global_step: 3574, epoch: 40, loss: 0.310358
global_step: 3575, epoch: 40, loss: 0.386003
global_step: 3576, epoch: 40, loss: 0.320973
global_step: 3577, epoch: 40, loss: 0.296162
global_step: 3578, epoch: 40, loss: 0.501642
global_step: 3579, epoch: 40, loss: 0.255193
global_step: 3580, epoch: 40, loss: 0.400066
global_step: 3581, epoch: 40, loss: 0.374617
global_step: 3582, epoch: 40, loss: 0.372635
global_step: 3583, epoch: 40, loss: 0.326655
global_step: 3584, epoch: 40, loss: 0.421912
global_step: 3585, epoch: 40, loss: 0.414222
global_step: 3586, epoch: 40, loss: 0.316858
global_step: 3587, epoch: 40, loss: 0.334908
global_step: 3588, epoch: 40, loss: 0.392855
global_step: 3589, epoch: 40, loss: 0.385000
global_step: 3590, epoch: 40, loss: 0.410184
global_step: 3591, epoch: 40, loss: 0.276732
global_step: 3592, epoch: 40, loss: 0.410352
global_step: 3593, epoch: 40, loss: 0.371116
global_step: 3594, epoch: 40, loss: 0.395088
global_step: 3595, epoch: 40, loss: 0.274666
global_step: 3596, epoch: 40, loss: 0.463455
global_step: 3597, epoch: 40, loss: 0.381975
global_step: 3598, epoch: 40, loss: 0.444169
global_step: 3599, epoch: 40, loss: 0.403268
global_step: 3600, epoch: 40, loss: 0.192482
epoch: 40
train	acc: 0.9557	macro: p 0.9619, r 0.9356, f1: 0.9481	micro: p 0.9557, r 0.9557, f1 0.9557	weighted_f1:0.9555
dev	acc: 0.5122	macro: p 0.3203, r 0.2981, f1: 0.2974	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4817
test	acc: 0.5544	macro: p 0.3704, r 0.3229, f1: 0.3303	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.5339
global_step: 3601, epoch: 41, loss: 0.342170
global_step: 3602, epoch: 41, loss: 0.380915
global_step: 3603, epoch: 41, loss: 0.242188
global_step: 3604, epoch: 41, loss: 0.368252
global_step: 3605, epoch: 41, loss: 0.404862
global_step: 3606, epoch: 41, loss: 0.263462
global_step: 3607, epoch: 41, loss: 0.407614
global_step: 3608, epoch: 41, loss: 0.297830
global_step: 3609, epoch: 41, loss: 0.306364
global_step: 3610, epoch: 41, loss: 0.309858
global_step: 3611, epoch: 41, loss: 0.299527
global_step: 3612, epoch: 41, loss: 0.344770
global_step: 3613, epoch: 41, loss: 0.390561
global_step: 3614, epoch: 41, loss: 0.438898
global_step: 3615, epoch: 41, loss: 0.305488
global_step: 3616, epoch: 41, loss: 0.338288
global_step: 3617, epoch: 41, loss: 0.365059
global_step: 3618, epoch: 41, loss: 0.369339
global_step: 3619, epoch: 41, loss: 0.386043
global_step: 3620, epoch: 41, loss: 0.265622
global_step: 3621, epoch: 41, loss: 0.288051
global_step: 3622, epoch: 41, loss: 0.381601
global_step: 3623, epoch: 41, loss: 0.322439
global_step: 3624, epoch: 41, loss: 0.383195
global_step: 3625, epoch: 41, loss: 0.460662
global_step: 3626, epoch: 41, loss: 0.428355
global_step: 3627, epoch: 41, loss: 0.334483
global_step: 3628, epoch: 41, loss: 0.372229
global_step: 3629, epoch: 41, loss: 0.278912
global_step: 3630, epoch: 41, loss: 0.444461
global_step: 3631, epoch: 41, loss: 0.353509
global_step: 3632, epoch: 41, loss: 0.324498
global_step: 3633, epoch: 41, loss: 0.491872
global_step: 3634, epoch: 41, loss: 0.362913
global_step: 3635, epoch: 41, loss: 0.363343
global_step: 3636, epoch: 41, loss: 0.369988
global_step: 3637, epoch: 41, loss: 0.365733
global_step: 3638, epoch: 41, loss: 0.408031
global_step: 3639, epoch: 41, loss: 0.488632
global_step: 3640, epoch: 41, loss: 0.190784
epoch: 41
train	acc: 0.9588	macro: p 0.9532, r 0.9455, f1: 0.9492	micro: p 0.9588, r 0.9588, f1 0.9588	weighted_f1:0.9588
dev	acc: 0.5077	macro: p 0.3376, r 0.3145, f1: 0.3155	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4846
test	acc: 0.5322	macro: p 0.3309, r 0.3135, f1: 0.3146	micro: p 0.5322, r 0.5322, f1 0.5322	weighted_f1:0.5172
global_step: 3641, epoch: 42, loss: 0.300064
global_step: 3642, epoch: 42, loss: 0.322382
global_step: 3643, epoch: 42, loss: 0.334205
global_step: 3644, epoch: 42, loss: 0.298236
global_step: 3645, epoch: 42, loss: 0.307282
global_step: 3646, epoch: 42, loss: 0.389726
global_step: 3647, epoch: 42, loss: 0.274571
global_step: 3648, epoch: 42, loss: 0.348741
global_step: 3649, epoch: 42, loss: 0.261337
global_step: 3650, epoch: 42, loss: 0.351620
global_step: 3651, epoch: 42, loss: 0.317027
global_step: 3652, epoch: 42, loss: 0.239345
global_step: 3653, epoch: 42, loss: 0.252778
global_step: 3654, epoch: 42, loss: 0.284971
global_step: 3655, epoch: 42, loss: 0.356671
global_step: 3656, epoch: 42, loss: 0.311472
global_step: 3657, epoch: 42, loss: 0.312776
global_step: 3658, epoch: 42, loss: 0.354239
global_step: 3659, epoch: 42, loss: 0.347100
global_step: 3660, epoch: 42, loss: 0.412468
global_step: 3661, epoch: 42, loss: 0.400920
global_step: 3662, epoch: 42, loss: 0.331252
global_step: 3663, epoch: 42, loss: 0.320599
global_step: 3664, epoch: 42, loss: 0.251717
global_step: 3665, epoch: 42, loss: 0.390161
global_step: 3666, epoch: 42, loss: 0.327134
global_step: 3667, epoch: 42, loss: 0.470804
global_step: 3668, epoch: 42, loss: 0.390913
global_step: 3669, epoch: 42, loss: 0.371733
global_step: 3670, epoch: 42, loss: 0.382887
global_step: 3671, epoch: 42, loss: 0.347528
global_step: 3672, epoch: 42, loss: 0.376190
global_step: 3673, epoch: 42, loss: 0.238764
global_step: 3674, epoch: 42, loss: 0.397411
global_step: 3675, epoch: 42, loss: 0.342458
global_step: 3676, epoch: 42, loss: 0.331349
global_step: 3677, epoch: 42, loss: 0.267532
global_step: 3678, epoch: 42, loss: 0.403709
global_step: 3679, epoch: 42, loss: 0.445546
global_step: 3680, epoch: 42, loss: 0.020401
epoch: 42
train	acc: 0.9613	macro: p 0.9630, r 0.9440, f1: 0.9530	micro: p 0.9613, r 0.9613, f1 0.9613	weighted_f1:0.9613
dev	acc: 0.5158	macro: p 0.3644, r 0.3178, f1: 0.3231	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4849
test	acc: 0.5590	macro: p 0.3721, r 0.3256, f1: 0.3308	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5315
global_step: 3681, epoch: 43, loss: 0.306017
global_step: 3682, epoch: 43, loss: 0.284864
global_step: 3683, epoch: 43, loss: 0.362172
global_step: 3684, epoch: 43, loss: 0.283974
global_step: 3685, epoch: 43, loss: 0.205732
global_step: 3686, epoch: 43, loss: 0.337366
global_step: 3687, epoch: 43, loss: 0.245206
global_step: 3688, epoch: 43, loss: 0.289286
global_step: 3689, epoch: 43, loss: 0.330055
global_step: 3690, epoch: 43, loss: 0.371789
global_step: 3691, epoch: 43, loss: 0.434869
global_step: 3692, epoch: 43, loss: 0.342452
global_step: 3693, epoch: 43, loss: 0.359143
global_step: 3694, epoch: 43, loss: 0.302135
global_step: 3695, epoch: 43, loss: 0.291540
global_step: 3696, epoch: 43, loss: 0.375518
global_step: 3697, epoch: 43, loss: 0.330216
global_step: 3698, epoch: 43, loss: 0.397326
global_step: 3699, epoch: 43, loss: 0.254281
global_step: 3700, epoch: 43, loss: 0.376496
global_step: 3701, epoch: 43, loss: 0.295317
global_step: 3702, epoch: 43, loss: 0.330223
global_step: 3703, epoch: 43, loss: 0.284350
global_step: 3704, epoch: 43, loss: 0.334876
global_step: 3705, epoch: 43, loss: 0.384774
global_step: 3706, epoch: 43, loss: 0.353189
global_step: 3707, epoch: 43, loss: 0.375172
global_step: 3708, epoch: 43, loss: 0.360320
global_step: 3709, epoch: 43, loss: 0.282789
global_step: 3710, epoch: 43, loss: 0.346120
global_step: 3711, epoch: 43, loss: 0.401747
global_step: 3712, epoch: 43, loss: 0.370461
global_step: 3713, epoch: 43, loss: 0.377103
global_step: 3714, epoch: 43, loss: 0.371918
global_step: 3715, epoch: 43, loss: 0.418029
global_step: 3716, epoch: 43, loss: 0.334097
global_step: 3717, epoch: 43, loss: 0.356106
global_step: 3718, epoch: 43, loss: 0.325339
global_step: 3719, epoch: 43, loss: 0.298114
global_step: 3720, epoch: 43, loss: 0.528437
epoch: 43
train	acc: 0.9566	macro: p 0.9569, r 0.9455, f1: 0.9507	micro: p 0.9566, r 0.9566, f1 0.9566	weighted_f1:0.9567
dev	acc: 0.4815	macro: p 0.3195, r 0.3041, f1: 0.2978	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.4603
test	acc: 0.5253	macro: p 0.3414, r 0.3201, f1: 0.3187	micro: p 0.5253, r 0.5253, f1 0.5253	weighted_f1:0.5146
global_step: 3721, epoch: 44, loss: 0.421326
global_step: 3722, epoch: 44, loss: 0.297981
global_step: 3723, epoch: 44, loss: 0.337739
global_step: 3724, epoch: 44, loss: 0.251656
global_step: 3725, epoch: 44, loss: 0.312684
global_step: 3726, epoch: 44, loss: 0.280861
global_step: 3727, epoch: 44, loss: 0.307016
global_step: 3728, epoch: 44, loss: 0.261872
global_step: 3729, epoch: 44, loss: 0.350081
global_step: 3730, epoch: 44, loss: 0.311175
global_step: 3731, epoch: 44, loss: 0.356662
global_step: 3732, epoch: 44, loss: 0.379230
global_step: 3733, epoch: 44, loss: 0.393120
global_step: 3734, epoch: 44, loss: 0.317241
global_step: 3735, epoch: 44, loss: 0.325894
global_step: 3736, epoch: 44, loss: 0.299309
global_step: 3737, epoch: 44, loss: 0.385419
global_step: 3738, epoch: 44, loss: 0.292968
global_step: 3739, epoch: 44, loss: 0.281637
global_step: 3740, epoch: 44, loss: 0.255102
global_step: 3741, epoch: 44, loss: 0.348941
global_step: 3742, epoch: 44, loss: 0.384513
global_step: 3743, epoch: 44, loss: 0.327798
global_step: 3744, epoch: 44, loss: 0.361291
global_step: 3745, epoch: 44, loss: 0.404077
global_step: 3746, epoch: 44, loss: 0.334135
global_step: 3747, epoch: 44, loss: 0.248076
global_step: 3748, epoch: 44, loss: 0.402583
global_step: 3749, epoch: 44, loss: 0.348305
global_step: 3750, epoch: 44, loss: 0.360580
global_step: 3751, epoch: 44, loss: 0.333291
global_step: 3752, epoch: 44, loss: 0.359696
global_step: 3753, epoch: 44, loss: 0.273102
global_step: 3754, epoch: 44, loss: 0.272113
global_step: 3755, epoch: 44, loss: 0.363065
global_step: 3756, epoch: 44, loss: 0.375171
global_step: 3757, epoch: 44, loss: 0.297448
global_step: 3758, epoch: 44, loss: 0.394262
global_step: 3759, epoch: 44, loss: 0.504994
global_step: 3760, epoch: 44, loss: 0.219501
epoch: 44
train	acc: 0.9609	macro: p 0.9607, r 0.9517, f1: 0.9557	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9611
dev	acc: 0.5050	macro: p 0.3459, r 0.3164, f1: 0.3191	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4776
test	acc: 0.5513	macro: p 0.3469, r 0.3206, f1: 0.3219	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5267
global_step: 3761, epoch: 45, loss: 0.428124
global_step: 3762, epoch: 45, loss: 0.305570
global_step: 3763, epoch: 45, loss: 0.284004
global_step: 3764, epoch: 45, loss: 0.267445
global_step: 3765, epoch: 45, loss: 0.298354
global_step: 3766, epoch: 45, loss: 0.289215
global_step: 3767, epoch: 45, loss: 0.234028
global_step: 3768, epoch: 45, loss: 0.331247
global_step: 3769, epoch: 45, loss: 0.282228
global_step: 3770, epoch: 45, loss: 0.289016
global_step: 3771, epoch: 45, loss: 0.242234
global_step: 3772, epoch: 45, loss: 0.406796
global_step: 3773, epoch: 45, loss: 0.305356
global_step: 3774, epoch: 45, loss: 0.276304
global_step: 3775, epoch: 45, loss: 0.322515
global_step: 3776, epoch: 45, loss: 0.289793
global_step: 3777, epoch: 45, loss: 0.369330
global_step: 3778, epoch: 45, loss: 0.332684
global_step: 3779, epoch: 45, loss: 0.399881
global_step: 3780, epoch: 45, loss: 0.341597
global_step: 3781, epoch: 45, loss: 0.417788
global_step: 3782, epoch: 45, loss: 0.340704
global_step: 3783, epoch: 45, loss: 0.420361
global_step: 3784, epoch: 45, loss: 0.402738
global_step: 3785, epoch: 45, loss: 0.301737
global_step: 3786, epoch: 45, loss: 0.328268
global_step: 3787, epoch: 45, loss: 0.276698
global_step: 3788, epoch: 45, loss: 0.312795
global_step: 3789, epoch: 45, loss: 0.437380
global_step: 3790, epoch: 45, loss: 0.310770
global_step: 3791, epoch: 45, loss: 0.354407
global_step: 3792, epoch: 45, loss: 0.397428
global_step: 3793, epoch: 45, loss: 0.386643
global_step: 3794, epoch: 45, loss: 0.325617
global_step: 3795, epoch: 45, loss: 0.385209
global_step: 3796, epoch: 45, loss: 0.269525
global_step: 3797, epoch: 45, loss: 0.277216
global_step: 3798, epoch: 45, loss: 0.335712
global_step: 3799, epoch: 45, loss: 0.312795
global_step: 3800, epoch: 45, loss: 0.228069
epoch: 45
train	acc: 0.9522	macro: p 0.9580, r 0.9296, f1: 0.9425	micro: p 0.9522, r 0.9522, f1 0.9522	weighted_f1:0.9522
dev	acc: 0.5329	macro: p 0.4051, r 0.3170, f1: 0.3136	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4835
test	acc: 0.5812	macro: p 0.3905, r 0.3141, f1: 0.3158	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5333
global_step: 3801, epoch: 46, loss: 0.384750
global_step: 3802, epoch: 46, loss: 0.327659
global_step: 3803, epoch: 46, loss: 0.332475
global_step: 3804, epoch: 46, loss: 0.287068
global_step: 3805, epoch: 46, loss: 0.286115
global_step: 3806, epoch: 46, loss: 0.289335
global_step: 3807, epoch: 46, loss: 0.348907
global_step: 3808, epoch: 46, loss: 0.316622
global_step: 3809, epoch: 46, loss: 0.268053
global_step: 3810, epoch: 46, loss: 0.287299
global_step: 3811, epoch: 46, loss: 0.342553
global_step: 3812, epoch: 46, loss: 0.318671
global_step: 3813, epoch: 46, loss: 0.324712
global_step: 3814, epoch: 46, loss: 0.256428
global_step: 3815, epoch: 46, loss: 0.290150
global_step: 3816, epoch: 46, loss: 0.394197
global_step: 3817, epoch: 46, loss: 0.397367
global_step: 3818, epoch: 46, loss: 0.315720
global_step: 3819, epoch: 46, loss: 0.297016
global_step: 3820, epoch: 46, loss: 0.232515
global_step: 3821, epoch: 46, loss: 0.380264
global_step: 3822, epoch: 46, loss: 0.277171
global_step: 3823, epoch: 46, loss: 0.293091
global_step: 3824, epoch: 46, loss: 0.348849
global_step: 3825, epoch: 46, loss: 0.301843
global_step: 3826, epoch: 46, loss: 0.397440
global_step: 3827, epoch: 46, loss: 0.232196
global_step: 3828, epoch: 46, loss: 0.331053
global_step: 3829, epoch: 46, loss: 0.269649
global_step: 3830, epoch: 46, loss: 0.365312
global_step: 3831, epoch: 46, loss: 0.259343
global_step: 3832, epoch: 46, loss: 0.407428
global_step: 3833, epoch: 46, loss: 0.343952
global_step: 3834, epoch: 46, loss: 0.329024
global_step: 3835, epoch: 46, loss: 0.430427
global_step: 3836, epoch: 46, loss: 0.329589
global_step: 3837, epoch: 46, loss: 0.300201
global_step: 3838, epoch: 46, loss: 0.368927
global_step: 3839, epoch: 46, loss: 0.337579
global_step: 3840, epoch: 46, loss: 0.025104
epoch: 46
train	acc: 0.9619	macro: p 0.9661, r 0.9467, f1: 0.9559	micro: p 0.9619, r 0.9619, f1 0.9619	weighted_f1:0.9619
dev	acc: 0.5077	macro: p 0.3677, r 0.3088, f1: 0.3081	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4732
test	acc: 0.5590	macro: p 0.3775, r 0.3269, f1: 0.3278	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5325
global_step: 3841, epoch: 47, loss: 0.201929
global_step: 3842, epoch: 47, loss: 0.297541
global_step: 3843, epoch: 47, loss: 0.313287
global_step: 3844, epoch: 47, loss: 0.318721
global_step: 3845, epoch: 47, loss: 0.331802
global_step: 3846, epoch: 47, loss: 0.290099
global_step: 3847, epoch: 47, loss: 0.309024
global_step: 3848, epoch: 47, loss: 0.228268
global_step: 3849, epoch: 47, loss: 0.371704
global_step: 3850, epoch: 47, loss: 0.341705
global_step: 3851, epoch: 47, loss: 0.323705
global_step: 3852, epoch: 47, loss: 0.310523
global_step: 3853, epoch: 47, loss: 0.287539
global_step: 3854, epoch: 47, loss: 0.284488
global_step: 3855, epoch: 47, loss: 0.306259
global_step: 3856, epoch: 47, loss: 0.269988
global_step: 3857, epoch: 47, loss: 0.354133
global_step: 3858, epoch: 47, loss: 0.367789
global_step: 3859, epoch: 47, loss: 0.297279
global_step: 3860, epoch: 47, loss: 0.288482
global_step: 3861, epoch: 47, loss: 0.305145
global_step: 3862, epoch: 47, loss: 0.343046
global_step: 3863, epoch: 47, loss: 0.220444
global_step: 3864, epoch: 47, loss: 0.293833
global_step: 3865, epoch: 47, loss: 0.304909
global_step: 3866, epoch: 47, loss: 0.346455
global_step: 3867, epoch: 47, loss: 0.390822
global_step: 3868, epoch: 47, loss: 0.333430
global_step: 3869, epoch: 47, loss: 0.303578
global_step: 3870, epoch: 47, loss: 0.234490
global_step: 3871, epoch: 47, loss: 0.288126
global_step: 3872, epoch: 47, loss: 0.298530
global_step: 3873, epoch: 47, loss: 0.336730
global_step: 3874, epoch: 47, loss: 0.380480
global_step: 3875, epoch: 47, loss: 0.361192
global_step: 3876, epoch: 47, loss: 0.486920
global_step: 3877, epoch: 47, loss: 0.341352
global_step: 3878, epoch: 47, loss: 0.348514
global_step: 3879, epoch: 47, loss: 0.400149
global_step: 3880, epoch: 47, loss: 0.569465
epoch: 47
train	acc: 0.9579	macro: p 0.9621, r 0.9439, f1: 0.9522	micro: p 0.9579, r 0.9579, f1 0.9579	weighted_f1:0.9581
dev	acc: 0.4932	macro: p 0.3390, r 0.2984, f1: 0.2946	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.4610
test	acc: 0.5544	macro: p 0.3587, r 0.3265, f1: 0.3272	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.5309
global_step: 3881, epoch: 48, loss: 0.322046
global_step: 3882, epoch: 48, loss: 0.305403
global_step: 3883, epoch: 48, loss: 0.300180
global_step: 3884, epoch: 48, loss: 0.259263
global_step: 3885, epoch: 48, loss: 0.292044
global_step: 3886, epoch: 48, loss: 0.264754
global_step: 3887, epoch: 48, loss: 0.190340
global_step: 3888, epoch: 48, loss: 0.219611
global_step: 3889, epoch: 48, loss: 0.373551
global_step: 3890, epoch: 48, loss: 0.236217
global_step: 3891, epoch: 48, loss: 0.351179
global_step: 3892, epoch: 48, loss: 0.291145
global_step: 3893, epoch: 48, loss: 0.312008
global_step: 3894, epoch: 48, loss: 0.279779
global_step: 3895, epoch: 48, loss: 0.284716
global_step: 3896, epoch: 48, loss: 0.320603
global_step: 3897, epoch: 48, loss: 0.281888
global_step: 3898, epoch: 48, loss: 0.302399
global_step: 3899, epoch: 48, loss: 0.282370
global_step: 3900, epoch: 48, loss: 0.327196
global_step: 3901, epoch: 48, loss: 0.307528
global_step: 3902, epoch: 48, loss: 0.274650
global_step: 3903, epoch: 48, loss: 0.297010
global_step: 3904, epoch: 48, loss: 0.352769
global_step: 3905, epoch: 48, loss: 0.311723
global_step: 3906, epoch: 48, loss: 0.329882
global_step: 3907, epoch: 48, loss: 0.305987
global_step: 3908, epoch: 48, loss: 0.322040
global_step: 3909, epoch: 48, loss: 0.233031
global_step: 3910, epoch: 48, loss: 0.279077
global_step: 3911, epoch: 48, loss: 0.428142
global_step: 3912, epoch: 48, loss: 0.302113
global_step: 3913, epoch: 48, loss: 0.384036
global_step: 3914, epoch: 48, loss: 0.384220
global_step: 3915, epoch: 48, loss: 0.318455
global_step: 3916, epoch: 48, loss: 0.262046
global_step: 3917, epoch: 48, loss: 0.316338
global_step: 3918, epoch: 48, loss: 0.358438
global_step: 3919, epoch: 48, loss: 0.324586
global_step: 3920, epoch: 48, loss: 0.398388
epoch: 48
train	acc: 0.9594	macro: p 0.9564, r 0.9491, f1: 0.9521	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9596
dev	acc: 0.5059	macro: p 0.3216, r 0.2998, f1: 0.3035	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4772
test	acc: 0.5582	macro: p 0.3696, r 0.3229, f1: 0.3311	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5313
global_step: 3921, epoch: 49, loss: 0.265300
global_step: 3922, epoch: 49, loss: 0.321312
global_step: 3923, epoch: 49, loss: 0.377886
global_step: 3924, epoch: 49, loss: 0.334361
global_step: 3925, epoch: 49, loss: 0.327913
global_step: 3926, epoch: 49, loss: 0.343548
global_step: 3927, epoch: 49, loss: 0.282425
global_step: 3928, epoch: 49, loss: 0.340120
global_step: 3929, epoch: 49, loss: 0.327962
global_step: 3930, epoch: 49, loss: 0.284303
global_step: 3931, epoch: 49, loss: 0.233662
global_step: 3932, epoch: 49, loss: 0.297911
global_step: 3933, epoch: 49, loss: 0.242450
global_step: 3934, epoch: 49, loss: 0.246821
global_step: 3935, epoch: 49, loss: 0.278826
global_step: 3936, epoch: 49, loss: 0.337475
global_step: 3937, epoch: 49, loss: 0.379018
global_step: 3938, epoch: 49, loss: 0.381558
global_step: 3939, epoch: 49, loss: 0.259618
global_step: 3940, epoch: 49, loss: 0.345385
global_step: 3941, epoch: 49, loss: 0.377509
global_step: 3942, epoch: 49, loss: 0.299055
global_step: 3943, epoch: 49, loss: 0.390597
global_step: 3944, epoch: 49, loss: 0.311349
global_step: 3945, epoch: 49, loss: 0.288030
global_step: 3946, epoch: 49, loss: 0.317935
global_step: 3947, epoch: 49, loss: 0.309026
global_step: 3948, epoch: 49, loss: 0.379775
global_step: 3949, epoch: 49, loss: 0.365868
global_step: 3950, epoch: 49, loss: 0.266576
global_step: 3951, epoch: 49, loss: 0.349919
global_step: 3952, epoch: 49, loss: 0.349863
global_step: 3953, epoch: 49, loss: 0.328081
global_step: 3954, epoch: 49, loss: 0.361307
global_step: 3955, epoch: 49, loss: 0.253900
global_step: 3956, epoch: 49, loss: 0.303821
global_step: 3957, epoch: 49, loss: 0.256763
global_step: 3958, epoch: 49, loss: 0.219972
global_step: 3959, epoch: 49, loss: 0.279257
global_step: 3960, epoch: 49, loss: 0.265059
epoch: 49
train	acc: 0.9599	macro: p 0.9582, r 0.9472, f1: 0.9522	micro: p 0.9599, r 0.9599, f1 0.9599	weighted_f1:0.9600
dev	acc: 0.5077	macro: p 0.3326, r 0.3054, f1: 0.3061	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4806
test	acc: 0.5529	macro: p 0.3520, r 0.3211, f1: 0.3233	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.5331
global_step: 3961, epoch: 50, loss: 0.230263
global_step: 3962, epoch: 50, loss: 0.276492
global_step: 3963, epoch: 50, loss: 0.183375
global_step: 3964, epoch: 50, loss: 0.359019
global_step: 3965, epoch: 50, loss: 0.304262
global_step: 3966, epoch: 50, loss: 0.336391
global_step: 3967, epoch: 50, loss: 0.262415
global_step: 3968, epoch: 50, loss: 0.253002
global_step: 3969, epoch: 50, loss: 0.283497
global_step: 3970, epoch: 50, loss: 0.271330
global_step: 3971, epoch: 50, loss: 0.282785
global_step: 3972, epoch: 50, loss: 0.315984
global_step: 3973, epoch: 50, loss: 0.316694
global_step: 3974, epoch: 50, loss: 0.305344
global_step: 3975, epoch: 50, loss: 0.305773
global_step: 3976, epoch: 50, loss: 0.229778
global_step: 3977, epoch: 50, loss: 0.309907
global_step: 3978, epoch: 50, loss: 0.288651
global_step: 3979, epoch: 50, loss: 0.300443
global_step: 3980, epoch: 50, loss: 0.338060
global_step: 3981, epoch: 50, loss: 0.344391
global_step: 3982, epoch: 50, loss: 0.258519
global_step: 3983, epoch: 50, loss: 0.321528
global_step: 3984, epoch: 50, loss: 0.369203
global_step: 3985, epoch: 50, loss: 0.307715
global_step: 3986, epoch: 50, loss: 0.325135
global_step: 3987, epoch: 50, loss: 0.279810
global_step: 3988, epoch: 50, loss: 0.318918
global_step: 3989, epoch: 50, loss: 0.270056
global_step: 3990, epoch: 50, loss: 0.321345
global_step: 3991, epoch: 50, loss: 0.405228
global_step: 3992, epoch: 50, loss: 0.315084
global_step: 3993, epoch: 50, loss: 0.286633
global_step: 3994, epoch: 50, loss: 0.398784
global_step: 3995, epoch: 50, loss: 0.324794
global_step: 3996, epoch: 50, loss: 0.364590
global_step: 3997, epoch: 50, loss: 0.310710
global_step: 3998, epoch: 50, loss: 0.357404
global_step: 3999, epoch: 50, loss: 0.295357
global_step: 4000, epoch: 50, loss: 0.050429
epoch: 50
train	acc: 0.9627	macro: p 0.9633, r 0.9487, f1: 0.9555	micro: p 0.9627, r 0.9627, f1 0.9627	weighted_f1:0.9627
dev	acc: 0.5050	macro: p 0.3492, r 0.3123, f1: 0.3148	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4754
test	acc: 0.5559	macro: p 0.3733, r 0.3299, f1: 0.3321	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.5318
BEST MODEL epoch: 11
train	acc: 0.7610 macro_p: 0.7837 macro_r: 0.5425 macro_f1: 0.5786 micro_p: 0.7610 micro_r: 0.7610 micro_f1: 0.7610 weighted_f1: 0.7400
dev	acc: 0.5464 macro_p: 0.3358 macro_r: 0.3121 macro_f1: 0.3031 micro_p: 0.5464 micro_r: 0.5464 micro_f1: 0.5464 weighted_f1: 0.4970
test	acc: 0.5923 macro_p: 0.3812 macro_r: 0.3222 macro_f1: 0.3222 micro_p: 0.5923 micro_r: 0.5923 micro_f1: 0.5923 weighted_f1: 0.5510
==========ROUND 3==========
global_step: 4001, epoch: 1, loss: 1.954030
global_step: 4002, epoch: 1, loss: 1.582149
global_step: 4003, epoch: 1, loss: 1.739798
global_step: 4004, epoch: 1, loss: 1.569496
global_step: 4005, epoch: 1, loss: 1.568238
global_step: 4006, epoch: 1, loss: 1.519655
global_step: 4007, epoch: 1, loss: 1.453766
global_step: 4008, epoch: 1, loss: 1.484687
global_step: 4009, epoch: 1, loss: 1.455930
global_step: 4010, epoch: 1, loss: 1.544413
global_step: 4011, epoch: 1, loss: 1.506031
global_step: 4012, epoch: 1, loss: 1.459473
global_step: 4013, epoch: 1, loss: 1.509629
global_step: 4014, epoch: 1, loss: 1.465442
global_step: 4015, epoch: 1, loss: 1.450315
global_step: 4016, epoch: 1, loss: 1.516147
global_step: 4017, epoch: 1, loss: 1.457533
global_step: 4018, epoch: 1, loss: 1.523299
global_step: 4019, epoch: 1, loss: 1.432512
global_step: 4020, epoch: 1, loss: 1.435600
global_step: 4021, epoch: 1, loss: 1.294752
global_step: 4022, epoch: 1, loss: 1.401096
global_step: 4023, epoch: 1, loss: 1.313101
global_step: 4024, epoch: 1, loss: 1.443396
global_step: 4025, epoch: 1, loss: 1.451458
global_step: 4026, epoch: 1, loss: 1.274531
global_step: 4027, epoch: 1, loss: 1.391895
global_step: 4028, epoch: 1, loss: 1.377935
global_step: 4029, epoch: 1, loss: 1.344294
global_step: 4030, epoch: 1, loss: 1.289127
global_step: 4031, epoch: 1, loss: 1.401165
global_step: 4032, epoch: 1, loss: 1.271689
global_step: 4033, epoch: 1, loss: 1.398614
global_step: 4034, epoch: 1, loss: 1.340873
global_step: 4035, epoch: 1, loss: 1.463121
global_step: 4036, epoch: 1, loss: 1.421873
global_step: 4037, epoch: 1, loss: 1.468038
global_step: 4038, epoch: 1, loss: 1.425386
global_step: 4039, epoch: 1, loss: 1.314152
global_step: 4040, epoch: 1, loss: 0.900072
epoch: 1
train	acc: 0.5264	macro: p 0.2044, r 0.2454, f1: 0.2020	micro: p 0.5264, r 0.5264, f1 0.5264	weighted_f1:0.4454
dev	acc: 0.4815	macro: p 0.1916, r 0.2421, f1: 0.1956	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.3885
test	acc: 0.5291	macro: p 0.2046, r 0.2518, f1: 0.2054	micro: p 0.5291, r 0.5291, f1 0.5291	weighted_f1:0.4496
New best model!
global_step: 4041, epoch: 2, loss: 1.349650
global_step: 4042, epoch: 2, loss: 1.324272
global_step: 4043, epoch: 2, loss: 1.218657
global_step: 4044, epoch: 2, loss: 1.366947
global_step: 4045, epoch: 2, loss: 1.262672
global_step: 4046, epoch: 2, loss: 1.403963
global_step: 4047, epoch: 2, loss: 1.389236
global_step: 4048, epoch: 2, loss: 1.432549
global_step: 4049, epoch: 2, loss: 1.270980
global_step: 4050, epoch: 2, loss: 1.432778
global_step: 4051, epoch: 2, loss: 1.411635
global_step: 4052, epoch: 2, loss: 1.267216
global_step: 4053, epoch: 2, loss: 1.323929
global_step: 4054, epoch: 2, loss: 1.296902
global_step: 4055, epoch: 2, loss: 1.155232
global_step: 4056, epoch: 2, loss: 1.353207
global_step: 4057, epoch: 2, loss: 1.286116
global_step: 4058, epoch: 2, loss: 1.371981
global_step: 4059, epoch: 2, loss: 1.238913
global_step: 4060, epoch: 2, loss: 1.371540
global_step: 4061, epoch: 2, loss: 1.389278
global_step: 4062, epoch: 2, loss: 1.370786
global_step: 4063, epoch: 2, loss: 1.277621
global_step: 4064, epoch: 2, loss: 1.316287
global_step: 4065, epoch: 2, loss: 1.335763
global_step: 4066, epoch: 2, loss: 1.427770
global_step: 4067, epoch: 2, loss: 1.392689
global_step: 4068, epoch: 2, loss: 1.299426
global_step: 4069, epoch: 2, loss: 1.279329
global_step: 4070, epoch: 2, loss: 1.325440
global_step: 4071, epoch: 2, loss: 1.257528
global_step: 4072, epoch: 2, loss: 1.321943
global_step: 4073, epoch: 2, loss: 1.215693
global_step: 4074, epoch: 2, loss: 1.343225
global_step: 4075, epoch: 2, loss: 1.349867
global_step: 4076, epoch: 2, loss: 1.350131
global_step: 4077, epoch: 2, loss: 1.385434
global_step: 4078, epoch: 2, loss: 1.310493
global_step: 4079, epoch: 2, loss: 1.325738
global_step: 4080, epoch: 2, loss: 1.103133
epoch: 2
train	acc: 0.5917	macro: p 0.3784, r 0.2983, f1: 0.3017	micro: p 0.5917, r 0.5917, f1 0.5917	weighted_f1:0.5351
dev	acc: 0.5248	macro: p 0.2689, r 0.2692, f1: 0.2577	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4542
test	acc: 0.5770	macro: p 0.3377, r 0.2828, f1: 0.2833	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5192
New best model!
global_step: 4081, epoch: 3, loss: 1.377252
global_step: 4082, epoch: 3, loss: 1.220650
global_step: 4083, epoch: 3, loss: 1.228132
global_step: 4084, epoch: 3, loss: 1.267457
global_step: 4085, epoch: 3, loss: 1.229282
global_step: 4086, epoch: 3, loss: 1.296758
global_step: 4087, epoch: 3, loss: 1.289723
global_step: 4088, epoch: 3, loss: 1.216619
global_step: 4089, epoch: 3, loss: 1.311286
global_step: 4090, epoch: 3, loss: 1.179530
global_step: 4091, epoch: 3, loss: 1.407885
global_step: 4092, epoch: 3, loss: 1.249207
global_step: 4093, epoch: 3, loss: 1.141681
global_step: 4094, epoch: 3, loss: 1.286914
global_step: 4095, epoch: 3, loss: 1.183210
global_step: 4096, epoch: 3, loss: 1.178743
global_step: 4097, epoch: 3, loss: 1.249899
global_step: 4098, epoch: 3, loss: 1.338966
global_step: 4099, epoch: 3, loss: 1.169648
global_step: 4100, epoch: 3, loss: 1.299314
global_step: 4101, epoch: 3, loss: 1.293511
global_step: 4102, epoch: 3, loss: 1.224816
global_step: 4103, epoch: 3, loss: 1.204215
global_step: 4104, epoch: 3, loss: 1.303084
global_step: 4105, epoch: 3, loss: 1.335152
global_step: 4106, epoch: 3, loss: 1.353457
global_step: 4107, epoch: 3, loss: 1.323918
global_step: 4108, epoch: 3, loss: 1.265640
global_step: 4109, epoch: 3, loss: 1.324430
global_step: 4110, epoch: 3, loss: 1.227360
global_step: 4111, epoch: 3, loss: 1.336656
global_step: 4112, epoch: 3, loss: 1.225465
global_step: 4113, epoch: 3, loss: 1.225865
global_step: 4114, epoch: 3, loss: 1.230976
global_step: 4115, epoch: 3, loss: 1.239418
global_step: 4116, epoch: 3, loss: 1.333900
global_step: 4117, epoch: 3, loss: 1.327022
global_step: 4118, epoch: 3, loss: 1.249815
global_step: 4119, epoch: 3, loss: 1.290534
global_step: 4120, epoch: 3, loss: 1.934249
epoch: 3
train	acc: 0.5398	macro: p 0.4092, r 0.3298, f1: 0.2835	micro: p 0.5398, r 0.5398, f1 0.5398	weighted_f1:0.5091
dev	acc: 0.4545	macro: p 0.2448, r 0.2794, f1: 0.2442	micro: p 0.4545, r 0.4545, f1 0.4545	weighted_f1:0.4201
test	acc: 0.5080	macro: p 0.4116, r 0.3096, f1: 0.2681	micro: p 0.5080, r 0.5080, f1 0.5080	weighted_f1:0.4849
global_step: 4121, epoch: 4, loss: 1.396927
global_step: 4122, epoch: 4, loss: 1.279308
global_step: 4123, epoch: 4, loss: 1.177779
global_step: 4124, epoch: 4, loss: 1.301411
global_step: 4125, epoch: 4, loss: 1.368949
global_step: 4126, epoch: 4, loss: 1.213860
global_step: 4127, epoch: 4, loss: 1.225181
global_step: 4128, epoch: 4, loss: 1.181251
global_step: 4129, epoch: 4, loss: 1.286796
global_step: 4130, epoch: 4, loss: 1.280271
global_step: 4131, epoch: 4, loss: 1.265726
global_step: 4132, epoch: 4, loss: 1.186783
global_step: 4133, epoch: 4, loss: 1.133362
global_step: 4134, epoch: 4, loss: 1.177118
global_step: 4135, epoch: 4, loss: 1.292758
global_step: 4136, epoch: 4, loss: 1.198254
global_step: 4137, epoch: 4, loss: 1.350954
global_step: 4138, epoch: 4, loss: 1.244697
global_step: 4139, epoch: 4, loss: 1.203308
global_step: 4140, epoch: 4, loss: 1.178586
global_step: 4141, epoch: 4, loss: 1.106842
global_step: 4142, epoch: 4, loss: 1.071866
global_step: 4143, epoch: 4, loss: 1.404970
global_step: 4144, epoch: 4, loss: 1.265206
global_step: 4145, epoch: 4, loss: 1.229115
global_step: 4146, epoch: 4, loss: 1.158318
global_step: 4147, epoch: 4, loss: 1.201020
global_step: 4148, epoch: 4, loss: 1.144969
global_step: 4149, epoch: 4, loss: 1.170514
global_step: 4150, epoch: 4, loss: 1.234629
global_step: 4151, epoch: 4, loss: 1.271275
global_step: 4152, epoch: 4, loss: 1.219648
global_step: 4153, epoch: 4, loss: 1.203757
global_step: 4154, epoch: 4, loss: 1.199135
global_step: 4155, epoch: 4, loss: 1.168482
global_step: 4156, epoch: 4, loss: 1.222457
global_step: 4157, epoch: 4, loss: 1.220363
global_step: 4158, epoch: 4, loss: 1.140676
global_step: 4159, epoch: 4, loss: 1.214407
global_step: 4160, epoch: 4, loss: 0.405270
epoch: 4
train	acc: 0.5969	macro: p 0.4682, r 0.2817, f1: 0.2810	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5253
dev	acc: 0.5302	macro: p 0.4343, r 0.2632, f1: 0.2358	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4374
test	acc: 0.5789	macro: p 0.4101, r 0.2652, f1: 0.2511	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.4987
global_step: 4161, epoch: 5, loss: 1.266057
global_step: 4162, epoch: 5, loss: 1.156875
global_step: 4163, epoch: 5, loss: 1.240565
global_step: 4164, epoch: 5, loss: 1.234015
global_step: 4165, epoch: 5, loss: 1.170796
global_step: 4166, epoch: 5, loss: 1.160027
global_step: 4167, epoch: 5, loss: 1.198508
global_step: 4168, epoch: 5, loss: 1.118482
global_step: 4169, epoch: 5, loss: 1.186340
global_step: 4170, epoch: 5, loss: 1.111248
global_step: 4171, epoch: 5, loss: 1.154322
global_step: 4172, epoch: 5, loss: 1.141243
global_step: 4173, epoch: 5, loss: 1.314661
global_step: 4174, epoch: 5, loss: 1.020422
global_step: 4175, epoch: 5, loss: 1.156916
global_step: 4176, epoch: 5, loss: 1.217341
global_step: 4177, epoch: 5, loss: 1.075185
global_step: 4178, epoch: 5, loss: 1.253851
global_step: 4179, epoch: 5, loss: 1.309732
global_step: 4180, epoch: 5, loss: 1.244196
global_step: 4181, epoch: 5, loss: 1.119526
global_step: 4182, epoch: 5, loss: 1.148432
global_step: 4183, epoch: 5, loss: 1.179515
global_step: 4184, epoch: 5, loss: 1.241027
global_step: 4185, epoch: 5, loss: 1.168830
global_step: 4186, epoch: 5, loss: 1.282909
global_step: 4187, epoch: 5, loss: 1.199850
global_step: 4188, epoch: 5, loss: 1.034941
global_step: 4189, epoch: 5, loss: 1.199808
global_step: 4190, epoch: 5, loss: 1.149173
global_step: 4191, epoch: 5, loss: 1.161635
global_step: 4192, epoch: 5, loss: 1.162662
global_step: 4193, epoch: 5, loss: 1.247090
global_step: 4194, epoch: 5, loss: 1.262926
global_step: 4195, epoch: 5, loss: 1.319122
global_step: 4196, epoch: 5, loss: 1.177835
global_step: 4197, epoch: 5, loss: 1.012331
global_step: 4198, epoch: 5, loss: 1.124664
global_step: 4199, epoch: 5, loss: 1.191410
global_step: 4200, epoch: 5, loss: 1.270130
epoch: 5
train	acc: 0.6189	macro: p 0.4491, r 0.3385, f1: 0.3344	micro: p 0.6189, r 0.6189, f1 0.6189	weighted_f1:0.5544
dev	acc: 0.5266	macro: p 0.3443, r 0.2768, f1: 0.2615	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4514
test	acc: 0.5785	macro: p 0.3690, r 0.2919, f1: 0.2836	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5121
global_step: 4201, epoch: 6, loss: 1.152173
global_step: 4202, epoch: 6, loss: 1.154322
global_step: 4203, epoch: 6, loss: 1.135301
global_step: 4204, epoch: 6, loss: 0.986161
global_step: 4205, epoch: 6, loss: 1.238548
global_step: 4206, epoch: 6, loss: 1.163382
global_step: 4207, epoch: 6, loss: 1.001078
global_step: 4208, epoch: 6, loss: 1.143181
global_step: 4209, epoch: 6, loss: 1.054263
global_step: 4210, epoch: 6, loss: 1.153374
global_step: 4211, epoch: 6, loss: 1.176964
global_step: 4212, epoch: 6, loss: 0.977815
global_step: 4213, epoch: 6, loss: 1.055441
global_step: 4214, epoch: 6, loss: 0.980440
global_step: 4215, epoch: 6, loss: 1.006281
global_step: 4216, epoch: 6, loss: 1.112697
global_step: 4217, epoch: 6, loss: 1.063562
global_step: 4218, epoch: 6, loss: 1.182488
global_step: 4219, epoch: 6, loss: 1.207154
global_step: 4220, epoch: 6, loss: 1.180161
global_step: 4221, epoch: 6, loss: 1.014463
global_step: 4222, epoch: 6, loss: 1.362639
global_step: 4223, epoch: 6, loss: 1.222082
global_step: 4224, epoch: 6, loss: 1.234939
global_step: 4225, epoch: 6, loss: 1.227583
global_step: 4226, epoch: 6, loss: 1.097292
global_step: 4227, epoch: 6, loss: 1.031581
global_step: 4228, epoch: 6, loss: 1.092724
global_step: 4229, epoch: 6, loss: 1.202810
global_step: 4230, epoch: 6, loss: 1.231403
global_step: 4231, epoch: 6, loss: 1.269447
global_step: 4232, epoch: 6, loss: 1.122813
global_step: 4233, epoch: 6, loss: 1.241210
global_step: 4234, epoch: 6, loss: 1.089839
global_step: 4235, epoch: 6, loss: 1.122885
global_step: 4236, epoch: 6, loss: 1.117422
global_step: 4237, epoch: 6, loss: 1.140968
global_step: 4238, epoch: 6, loss: 1.159781
global_step: 4239, epoch: 6, loss: 1.141849
global_step: 4240, epoch: 6, loss: 1.092561
epoch: 6
train	acc: 0.6112	macro: p 0.4753, r 0.3298, f1: 0.3173	micro: p 0.6112, r 0.6112, f1 0.6112	weighted_f1:0.5526
dev	acc: 0.5338	macro: p 0.4496, r 0.2787, f1: 0.2684	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4663
test	acc: 0.5920	macro: p 0.4180, r 0.2987, f1: 0.2901	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5316
New best model!
global_step: 4241, epoch: 7, loss: 1.188459
global_step: 4242, epoch: 7, loss: 1.157442
global_step: 4243, epoch: 7, loss: 1.158031
global_step: 4244, epoch: 7, loss: 1.172084
global_step: 4245, epoch: 7, loss: 1.058987
global_step: 4246, epoch: 7, loss: 0.942256
global_step: 4247, epoch: 7, loss: 1.233845
global_step: 4248, epoch: 7, loss: 1.115285
global_step: 4249, epoch: 7, loss: 1.122878
global_step: 4250, epoch: 7, loss: 1.139778
global_step: 4251, epoch: 7, loss: 1.149549
global_step: 4252, epoch: 7, loss: 1.024668
global_step: 4253, epoch: 7, loss: 1.015948
global_step: 4254, epoch: 7, loss: 1.132489
global_step: 4255, epoch: 7, loss: 1.047572
global_step: 4256, epoch: 7, loss: 1.174127
global_step: 4257, epoch: 7, loss: 1.049581
global_step: 4258, epoch: 7, loss: 1.147108
global_step: 4259, epoch: 7, loss: 1.092343
global_step: 4260, epoch: 7, loss: 1.043735
global_step: 4261, epoch: 7, loss: 1.265727
global_step: 4262, epoch: 7, loss: 1.062858
global_step: 4263, epoch: 7, loss: 1.223747
global_step: 4264, epoch: 7, loss: 1.055961
global_step: 4265, epoch: 7, loss: 0.929770
global_step: 4266, epoch: 7, loss: 1.031911
global_step: 4267, epoch: 7, loss: 1.034721
global_step: 4268, epoch: 7, loss: 0.982361
global_step: 4269, epoch: 7, loss: 1.126991
global_step: 4270, epoch: 7, loss: 1.123071
global_step: 4271, epoch: 7, loss: 1.181539
global_step: 4272, epoch: 7, loss: 1.066561
global_step: 4273, epoch: 7, loss: 1.052703
global_step: 4274, epoch: 7, loss: 1.168292
global_step: 4275, epoch: 7, loss: 1.064757
global_step: 4276, epoch: 7, loss: 0.977003
global_step: 4277, epoch: 7, loss: 1.022834
global_step: 4278, epoch: 7, loss: 1.155146
global_step: 4279, epoch: 7, loss: 1.200520
global_step: 4280, epoch: 7, loss: 0.859195
epoch: 7
train	acc: 0.5939	macro: p 0.5481, r 0.2855, f1: 0.2510	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5177
dev	acc: 0.4932	macro: p 0.3775, r 0.2546, f1: 0.2096	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.4090
test	acc: 0.5337	macro: p 0.3618, r 0.2540, f1: 0.2174	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.4612
global_step: 4281, epoch: 8, loss: 1.473891
global_step: 4282, epoch: 8, loss: 0.954400
global_step: 4283, epoch: 8, loss: 1.070389
global_step: 4284, epoch: 8, loss: 1.056830
global_step: 4285, epoch: 8, loss: 0.961008
global_step: 4286, epoch: 8, loss: 0.963944
global_step: 4287, epoch: 8, loss: 1.062476
global_step: 4288, epoch: 8, loss: 1.021773
global_step: 4289, epoch: 8, loss: 1.028167
global_step: 4290, epoch: 8, loss: 1.125198
global_step: 4291, epoch: 8, loss: 1.154359
global_step: 4292, epoch: 8, loss: 1.149776
global_step: 4293, epoch: 8, loss: 0.854227
global_step: 4294, epoch: 8, loss: 1.064057
global_step: 4295, epoch: 8, loss: 1.061054
global_step: 4296, epoch: 8, loss: 0.963548
global_step: 4297, epoch: 8, loss: 1.077911
global_step: 4298, epoch: 8, loss: 1.075195
global_step: 4299, epoch: 8, loss: 1.079674
global_step: 4300, epoch: 8, loss: 1.039931
global_step: 4301, epoch: 8, loss: 1.104372
global_step: 4302, epoch: 8, loss: 1.081725
global_step: 4303, epoch: 8, loss: 1.013695
global_step: 4304, epoch: 8, loss: 1.130489
global_step: 4305, epoch: 8, loss: 1.025173
global_step: 4306, epoch: 8, loss: 1.076260
global_step: 4307, epoch: 8, loss: 1.059925
global_step: 4308, epoch: 8, loss: 0.996774
global_step: 4309, epoch: 8, loss: 1.033362
global_step: 4310, epoch: 8, loss: 0.992161
global_step: 4311, epoch: 8, loss: 1.050911
global_step: 4312, epoch: 8, loss: 1.059035
global_step: 4313, epoch: 8, loss: 1.032726
global_step: 4314, epoch: 8, loss: 1.028522
global_step: 4315, epoch: 8, loss: 1.058077
global_step: 4316, epoch: 8, loss: 1.073350
global_step: 4317, epoch: 8, loss: 1.142922
global_step: 4318, epoch: 8, loss: 1.088310
global_step: 4319, epoch: 8, loss: 1.023982
global_step: 4320, epoch: 8, loss: 1.806712
epoch: 8
train	acc: 0.6886	macro: p 0.5719, r 0.4287, f1: 0.4259	micro: p 0.6886, r 0.6886, f1 0.6886	weighted_f1:0.6635
dev	acc: 0.5257	macro: p 0.3468, r 0.2971, f1: 0.2907	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4840
test	acc: 0.5812	macro: p 0.3918, r 0.3170, f1: 0.3148	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5474
New best model!
global_step: 4321, epoch: 9, loss: 0.985307
global_step: 4322, epoch: 9, loss: 1.053472
global_step: 4323, epoch: 9, loss: 1.054898
global_step: 4324, epoch: 9, loss: 0.961603
global_step: 4325, epoch: 9, loss: 0.995631
global_step: 4326, epoch: 9, loss: 0.999855
global_step: 4327, epoch: 9, loss: 0.952213
global_step: 4328, epoch: 9, loss: 1.042757
global_step: 4329, epoch: 9, loss: 1.010581
global_step: 4330, epoch: 9, loss: 1.037984
global_step: 4331, epoch: 9, loss: 0.948850
global_step: 4332, epoch: 9, loss: 1.144241
global_step: 4333, epoch: 9, loss: 1.053774
global_step: 4334, epoch: 9, loss: 0.911902
global_step: 4335, epoch: 9, loss: 1.035682
global_step: 4336, epoch: 9, loss: 1.030731
global_step: 4337, epoch: 9, loss: 0.872402
global_step: 4338, epoch: 9, loss: 1.023685
global_step: 4339, epoch: 9, loss: 0.971632
global_step: 4340, epoch: 9, loss: 0.913035
global_step: 4341, epoch: 9, loss: 1.008449
global_step: 4342, epoch: 9, loss: 0.999928
global_step: 4343, epoch: 9, loss: 0.901049
global_step: 4344, epoch: 9, loss: 1.064739
global_step: 4345, epoch: 9, loss: 0.998735
global_step: 4346, epoch: 9, loss: 1.002946
global_step: 4347, epoch: 9, loss: 1.020381
global_step: 4348, epoch: 9, loss: 1.012105
global_step: 4349, epoch: 9, loss: 1.058095
global_step: 4350, epoch: 9, loss: 0.943540
global_step: 4351, epoch: 9, loss: 1.042050
global_step: 4352, epoch: 9, loss: 0.932154
global_step: 4353, epoch: 9, loss: 1.041309
global_step: 4354, epoch: 9, loss: 0.980516
global_step: 4355, epoch: 9, loss: 1.045452
global_step: 4356, epoch: 9, loss: 1.145641
global_step: 4357, epoch: 9, loss: 1.109661
global_step: 4358, epoch: 9, loss: 0.937537
global_step: 4359, epoch: 9, loss: 1.006437
global_step: 4360, epoch: 9, loss: 0.790299
epoch: 9
train	acc: 0.7316	macro: p 0.6622, r 0.4766, f1: 0.4624	micro: p 0.7316, r 0.7316, f1 0.7316	weighted_f1:0.7077
dev	acc: 0.5212	macro: p 0.3434, r 0.3022, f1: 0.2872	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4832
test	acc: 0.5709	macro: p 0.3843, r 0.3269, f1: 0.3177	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5439
global_step: 4361, epoch: 10, loss: 1.046276
global_step: 4362, epoch: 10, loss: 0.957130
global_step: 4363, epoch: 10, loss: 1.021908
global_step: 4364, epoch: 10, loss: 0.881163
global_step: 4365, epoch: 10, loss: 0.915097
global_step: 4366, epoch: 10, loss: 0.899898
global_step: 4367, epoch: 10, loss: 0.892057
global_step: 4368, epoch: 10, loss: 0.873941
global_step: 4369, epoch: 10, loss: 0.926538
global_step: 4370, epoch: 10, loss: 0.895194
global_step: 4371, epoch: 10, loss: 0.904486
global_step: 4372, epoch: 10, loss: 0.949736
global_step: 4373, epoch: 10, loss: 0.941312
global_step: 4374, epoch: 10, loss: 0.925447
global_step: 4375, epoch: 10, loss: 1.048206
global_step: 4376, epoch: 10, loss: 1.043657
global_step: 4377, epoch: 10, loss: 1.005629
global_step: 4378, epoch: 10, loss: 0.995281
global_step: 4379, epoch: 10, loss: 0.980874
global_step: 4380, epoch: 10, loss: 0.978414
global_step: 4381, epoch: 10, loss: 0.996417
global_step: 4382, epoch: 10, loss: 0.983185
global_step: 4383, epoch: 10, loss: 0.891688
global_step: 4384, epoch: 10, loss: 0.857475
global_step: 4385, epoch: 10, loss: 1.089084
global_step: 4386, epoch: 10, loss: 1.015058
global_step: 4387, epoch: 10, loss: 1.044264
global_step: 4388, epoch: 10, loss: 1.028622
global_step: 4389, epoch: 10, loss: 0.872247
global_step: 4390, epoch: 10, loss: 1.102508
global_step: 4391, epoch: 10, loss: 0.837575
global_step: 4392, epoch: 10, loss: 1.033299
global_step: 4393, epoch: 10, loss: 0.988354
global_step: 4394, epoch: 10, loss: 0.921224
global_step: 4395, epoch: 10, loss: 0.981236
global_step: 4396, epoch: 10, loss: 0.984586
global_step: 4397, epoch: 10, loss: 1.047106
global_step: 4398, epoch: 10, loss: 1.030622
global_step: 4399, epoch: 10, loss: 0.993749
global_step: 4400, epoch: 10, loss: 1.581473
epoch: 10
train	acc: 0.7259	macro: p 0.6374, r 0.4497, f1: 0.4539	micro: p 0.7259, r 0.7259, f1 0.7259	weighted_f1:0.6856
dev	acc: 0.5555	macro: p 0.4086, r 0.3044, f1: 0.2989	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4969
test	acc: 0.6050	macro: p 0.5562, r 0.3171, f1: 0.3184	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5536
New best model!
global_step: 4401, epoch: 11, loss: 1.022125
global_step: 4402, epoch: 11, loss: 0.959234
global_step: 4403, epoch: 11, loss: 0.908412
global_step: 4404, epoch: 11, loss: 0.950446
global_step: 4405, epoch: 11, loss: 0.908342
global_step: 4406, epoch: 11, loss: 0.891130
global_step: 4407, epoch: 11, loss: 0.914480
global_step: 4408, epoch: 11, loss: 0.860841
global_step: 4409, epoch: 11, loss: 1.021225
global_step: 4410, epoch: 11, loss: 0.887819
global_step: 4411, epoch: 11, loss: 0.841911
global_step: 4412, epoch: 11, loss: 0.816863
global_step: 4413, epoch: 11, loss: 0.869532
global_step: 4414, epoch: 11, loss: 0.944935
global_step: 4415, epoch: 11, loss: 0.811788
global_step: 4416, epoch: 11, loss: 0.904560
global_step: 4417, epoch: 11, loss: 0.976281
global_step: 4418, epoch: 11, loss: 0.987045
global_step: 4419, epoch: 11, loss: 0.940014
global_step: 4420, epoch: 11, loss: 0.894242
global_step: 4421, epoch: 11, loss: 0.905932
global_step: 4422, epoch: 11, loss: 0.835357
global_step: 4423, epoch: 11, loss: 0.941084
global_step: 4424, epoch: 11, loss: 0.842384
global_step: 4425, epoch: 11, loss: 1.106885
global_step: 4426, epoch: 11, loss: 1.001086
global_step: 4427, epoch: 11, loss: 0.982206
global_step: 4428, epoch: 11, loss: 0.912632
global_step: 4429, epoch: 11, loss: 1.001492
global_step: 4430, epoch: 11, loss: 0.980016
global_step: 4431, epoch: 11, loss: 0.846728
global_step: 4432, epoch: 11, loss: 1.002799
global_step: 4433, epoch: 11, loss: 0.917975
global_step: 4434, epoch: 11, loss: 0.842558
global_step: 4435, epoch: 11, loss: 0.908639
global_step: 4436, epoch: 11, loss: 0.881110
global_step: 4437, epoch: 11, loss: 0.916676
global_step: 4438, epoch: 11, loss: 0.970677
global_step: 4439, epoch: 11, loss: 0.955132
global_step: 4440, epoch: 11, loss: 2.481224
epoch: 11
train	acc: 0.7584	macro: p 0.7112, r 0.5519, f1: 0.5836	micro: p 0.7584, r 0.7584, f1 0.7584	weighted_f1:0.7427
dev	acc: 0.5275	macro: p 0.3395, r 0.2773, f1: 0.2746	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4729
test	acc: 0.5946	macro: p 0.4124, r 0.3154, f1: 0.3292	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5551
global_step: 4441, epoch: 12, loss: 0.823765
global_step: 4442, epoch: 12, loss: 0.887334
global_step: 4443, epoch: 12, loss: 0.794424
global_step: 4444, epoch: 12, loss: 0.942578
global_step: 4445, epoch: 12, loss: 0.861997
global_step: 4446, epoch: 12, loss: 0.829818
global_step: 4447, epoch: 12, loss: 0.861502
global_step: 4448, epoch: 12, loss: 1.017235
global_step: 4449, epoch: 12, loss: 0.874175
global_step: 4450, epoch: 12, loss: 0.972020
global_step: 4451, epoch: 12, loss: 0.873381
global_step: 4452, epoch: 12, loss: 0.849299
global_step: 4453, epoch: 12, loss: 0.898823
global_step: 4454, epoch: 12, loss: 0.869755
global_step: 4455, epoch: 12, loss: 0.832881
global_step: 4456, epoch: 12, loss: 1.000837
global_step: 4457, epoch: 12, loss: 0.812517
global_step: 4458, epoch: 12, loss: 0.835594
global_step: 4459, epoch: 12, loss: 0.915855
global_step: 4460, epoch: 12, loss: 0.835539
global_step: 4461, epoch: 12, loss: 0.869359
global_step: 4462, epoch: 12, loss: 0.802622
global_step: 4463, epoch: 12, loss: 0.865105
global_step: 4464, epoch: 12, loss: 0.848600
global_step: 4465, epoch: 12, loss: 0.851122
global_step: 4466, epoch: 12, loss: 0.980407
global_step: 4467, epoch: 12, loss: 0.866992
global_step: 4468, epoch: 12, loss: 0.873369
global_step: 4469, epoch: 12, loss: 0.853330
global_step: 4470, epoch: 12, loss: 0.753646
global_step: 4471, epoch: 12, loss: 0.797074
global_step: 4472, epoch: 12, loss: 0.828191
global_step: 4473, epoch: 12, loss: 0.836733
global_step: 4474, epoch: 12, loss: 0.896880
global_step: 4475, epoch: 12, loss: 1.021331
global_step: 4476, epoch: 12, loss: 0.850788
global_step: 4477, epoch: 12, loss: 0.839595
global_step: 4478, epoch: 12, loss: 0.971786
global_step: 4479, epoch: 12, loss: 1.024494
global_step: 4480, epoch: 12, loss: 1.184288
epoch: 12
train	acc: 0.7685	macro: p 0.7368, r 0.6182, f1: 0.6368	micro: p 0.7685, r 0.7685, f1 0.7685	weighted_f1:0.7632
dev	acc: 0.4986	macro: p 0.3518, r 0.3032, f1: 0.2696	micro: p 0.4986, r 0.4986, f1 0.4986	weighted_f1:0.4543
test	acc: 0.5153	macro: p 0.3246, r 0.3027, f1: 0.2657	micro: p 0.5153, r 0.5153, f1 0.5153	weighted_f1:0.4860
global_step: 4481, epoch: 13, loss: 0.838434
global_step: 4482, epoch: 13, loss: 0.726378
global_step: 4483, epoch: 13, loss: 0.929843
global_step: 4484, epoch: 13, loss: 0.824248
global_step: 4485, epoch: 13, loss: 0.943816
global_step: 4486, epoch: 13, loss: 0.870387
global_step: 4487, epoch: 13, loss: 0.825749
global_step: 4488, epoch: 13, loss: 0.818298
global_step: 4489, epoch: 13, loss: 0.730425
global_step: 4490, epoch: 13, loss: 0.882342
global_step: 4491, epoch: 13, loss: 0.808607
global_step: 4492, epoch: 13, loss: 0.758269
global_step: 4493, epoch: 13, loss: 0.835842
global_step: 4494, epoch: 13, loss: 0.868042
global_step: 4495, epoch: 13, loss: 0.847628
global_step: 4496, epoch: 13, loss: 0.775962
global_step: 4497, epoch: 13, loss: 0.882161
global_step: 4498, epoch: 13, loss: 0.756491
global_step: 4499, epoch: 13, loss: 0.932753
global_step: 4500, epoch: 13, loss: 0.800847
global_step: 4501, epoch: 13, loss: 0.825120
global_step: 4502, epoch: 13, loss: 0.759886
global_step: 4503, epoch: 13, loss: 0.808123
global_step: 4504, epoch: 13, loss: 0.874589
global_step: 4505, epoch: 13, loss: 0.889883
global_step: 4506, epoch: 13, loss: 0.932965
global_step: 4507, epoch: 13, loss: 0.750699
global_step: 4508, epoch: 13, loss: 0.990181
global_step: 4509, epoch: 13, loss: 0.767795
global_step: 4510, epoch: 13, loss: 0.745599
global_step: 4511, epoch: 13, loss: 0.840921
global_step: 4512, epoch: 13, loss: 0.867511
global_step: 4513, epoch: 13, loss: 0.701596
global_step: 4514, epoch: 13, loss: 0.814215
global_step: 4515, epoch: 13, loss: 0.857359
global_step: 4516, epoch: 13, loss: 0.808179
global_step: 4517, epoch: 13, loss: 0.849631
global_step: 4518, epoch: 13, loss: 0.875476
global_step: 4519, epoch: 13, loss: 0.816401
global_step: 4520, epoch: 13, loss: 0.270864
epoch: 13
train	acc: 0.7713	macro: p 0.7989, r 0.5725, f1: 0.5797	micro: p 0.7713, r 0.7713, f1 0.7713	weighted_f1:0.7669
dev	acc: 0.5014	macro: p 0.3197, r 0.3032, f1: 0.2871	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4760
test	acc: 0.5479	macro: p 0.3610, r 0.3364, f1: 0.3213	micro: p 0.5479, r 0.5479, f1 0.5479	weighted_f1:0.5362
global_step: 4521, epoch: 14, loss: 0.865133
global_step: 4522, epoch: 14, loss: 0.708605
global_step: 4523, epoch: 14, loss: 0.842420
global_step: 4524, epoch: 14, loss: 0.832421
global_step: 4525, epoch: 14, loss: 0.896002
global_step: 4526, epoch: 14, loss: 0.690176
global_step: 4527, epoch: 14, loss: 0.799384
global_step: 4528, epoch: 14, loss: 0.782150
global_step: 4529, epoch: 14, loss: 0.616766
global_step: 4530, epoch: 14, loss: 0.914506
global_step: 4531, epoch: 14, loss: 0.807953
global_step: 4532, epoch: 14, loss: 0.779668
global_step: 4533, epoch: 14, loss: 0.888428
global_step: 4534, epoch: 14, loss: 0.718460
global_step: 4535, epoch: 14, loss: 0.833751
global_step: 4536, epoch: 14, loss: 0.869928
global_step: 4537, epoch: 14, loss: 0.857741
global_step: 4538, epoch: 14, loss: 0.839398
global_step: 4539, epoch: 14, loss: 0.894927
global_step: 4540, epoch: 14, loss: 0.792156
global_step: 4541, epoch: 14, loss: 0.716428
global_step: 4542, epoch: 14, loss: 0.881155
global_step: 4543, epoch: 14, loss: 0.731597
global_step: 4544, epoch: 14, loss: 0.843952
global_step: 4545, epoch: 14, loss: 0.792045
global_step: 4546, epoch: 14, loss: 0.814806
global_step: 4547, epoch: 14, loss: 0.773929
global_step: 4548, epoch: 14, loss: 0.875140
global_step: 4549, epoch: 14, loss: 0.840185
global_step: 4550, epoch: 14, loss: 0.766912
global_step: 4551, epoch: 14, loss: 0.860863
global_step: 4552, epoch: 14, loss: 0.810847
global_step: 4553, epoch: 14, loss: 0.829436
global_step: 4554, epoch: 14, loss: 0.886229
global_step: 4555, epoch: 14, loss: 0.818902
global_step: 4556, epoch: 14, loss: 0.812309
global_step: 4557, epoch: 14, loss: 0.787244
global_step: 4558, epoch: 14, loss: 0.755873
global_step: 4559, epoch: 14, loss: 0.855002
global_step: 4560, epoch: 14, loss: 1.786903
epoch: 14
train	acc: 0.8054	macro: p 0.7925, r 0.6739, f1: 0.7086	micro: p 0.8054, r 0.8054, f1 0.8054	weighted_f1:0.8059
dev	acc: 0.4824	macro: p 0.3245, r 0.2941, f1: 0.2767	micro: p 0.4824, r 0.4824, f1 0.4824	weighted_f1:0.4504
test	acc: 0.5249	macro: p 0.3915, r 0.3188, f1: 0.3154	micro: p 0.5249, r 0.5249, f1 0.5249	weighted_f1:0.5106
global_step: 4561, epoch: 15, loss: 0.843809
global_step: 4562, epoch: 15, loss: 0.609999
global_step: 4563, epoch: 15, loss: 0.861766
global_step: 4564, epoch: 15, loss: 0.665932
global_step: 4565, epoch: 15, loss: 0.682591
global_step: 4566, epoch: 15, loss: 0.827079
global_step: 4567, epoch: 15, loss: 0.827102
global_step: 4568, epoch: 15, loss: 0.627413
global_step: 4569, epoch: 15, loss: 0.749532
global_step: 4570, epoch: 15, loss: 0.740035
global_step: 4571, epoch: 15, loss: 0.743492
global_step: 4572, epoch: 15, loss: 0.754535
global_step: 4573, epoch: 15, loss: 0.793338
global_step: 4574, epoch: 15, loss: 0.783557
global_step: 4575, epoch: 15, loss: 0.715085
global_step: 4576, epoch: 15, loss: 0.756014
global_step: 4577, epoch: 15, loss: 0.793802
global_step: 4578, epoch: 15, loss: 0.908558
global_step: 4579, epoch: 15, loss: 0.818749
global_step: 4580, epoch: 15, loss: 0.836311
global_step: 4581, epoch: 15, loss: 0.923388
global_step: 4582, epoch: 15, loss: 0.725293
global_step: 4583, epoch: 15, loss: 0.817749
global_step: 4584, epoch: 15, loss: 0.870310
global_step: 4585, epoch: 15, loss: 0.789725
global_step: 4586, epoch: 15, loss: 0.826494
global_step: 4587, epoch: 15, loss: 0.699962
global_step: 4588, epoch: 15, loss: 0.677605
global_step: 4589, epoch: 15, loss: 0.858980
global_step: 4590, epoch: 15, loss: 0.741224
global_step: 4591, epoch: 15, loss: 0.880418
global_step: 4592, epoch: 15, loss: 0.805888
global_step: 4593, epoch: 15, loss: 0.774441
global_step: 4594, epoch: 15, loss: 0.811730
global_step: 4595, epoch: 15, loss: 0.707716
global_step: 4596, epoch: 15, loss: 0.679241
global_step: 4597, epoch: 15, loss: 0.807977
global_step: 4598, epoch: 15, loss: 0.697444
global_step: 4599, epoch: 15, loss: 0.812454
global_step: 4600, epoch: 15, loss: 0.940275
epoch: 15
train	acc: 0.7818	macro: p 0.8083, r 0.6299, f1: 0.6465	micro: p 0.7818, r 0.7818, f1 0.7818	weighted_f1:0.7780
dev	acc: 0.4977	macro: p 0.3255, r 0.2964, f1: 0.2789	micro: p 0.4977, r 0.4977, f1 0.4977	weighted_f1:0.4648
test	acc: 0.5341	macro: p 0.3537, r 0.3153, f1: 0.2929	micro: p 0.5341, r 0.5341, f1 0.5341	weighted_f1:0.5098
global_step: 4601, epoch: 16, loss: 0.865102
global_step: 4602, epoch: 16, loss: 0.736753
global_step: 4603, epoch: 16, loss: 0.721196
global_step: 4604, epoch: 16, loss: 0.628787
global_step: 4605, epoch: 16, loss: 0.766672
global_step: 4606, epoch: 16, loss: 0.671718
global_step: 4607, epoch: 16, loss: 0.744940
global_step: 4608, epoch: 16, loss: 0.633784
global_step: 4609, epoch: 16, loss: 0.672345
global_step: 4610, epoch: 16, loss: 0.646544
global_step: 4611, epoch: 16, loss: 0.850057
global_step: 4612, epoch: 16, loss: 0.751723
global_step: 4613, epoch: 16, loss: 0.764402
global_step: 4614, epoch: 16, loss: 0.684308
global_step: 4615, epoch: 16, loss: 0.698613
global_step: 4616, epoch: 16, loss: 0.626071
global_step: 4617, epoch: 16, loss: 0.701722
global_step: 4618, epoch: 16, loss: 0.729377
global_step: 4619, epoch: 16, loss: 0.682982
global_step: 4620, epoch: 16, loss: 0.747993
global_step: 4621, epoch: 16, loss: 0.923244
global_step: 4622, epoch: 16, loss: 0.701969
global_step: 4623, epoch: 16, loss: 0.751791
global_step: 4624, epoch: 16, loss: 0.801620
global_step: 4625, epoch: 16, loss: 0.806849
global_step: 4626, epoch: 16, loss: 0.743677
global_step: 4627, epoch: 16, loss: 0.729113
global_step: 4628, epoch: 16, loss: 0.758429
global_step: 4629, epoch: 16, loss: 0.748490
global_step: 4630, epoch: 16, loss: 0.780973
global_step: 4631, epoch: 16, loss: 0.724236
global_step: 4632, epoch: 16, loss: 0.694348
global_step: 4633, epoch: 16, loss: 0.787243
global_step: 4634, epoch: 16, loss: 0.767432
global_step: 4635, epoch: 16, loss: 0.652221
global_step: 4636, epoch: 16, loss: 0.688385
global_step: 4637, epoch: 16, loss: 0.783031
global_step: 4638, epoch: 16, loss: 0.795514
global_step: 4639, epoch: 16, loss: 0.894288
global_step: 4640, epoch: 16, loss: 1.039293
epoch: 16
train	acc: 0.8257	macro: p 0.8000, r 0.6713, f1: 0.6830	micro: p 0.8257, r 0.8257, f1 0.8257	weighted_f1:0.8156
dev	acc: 0.5113	macro: p 0.5140, r 0.3185, f1: 0.3049	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4786
test	acc: 0.5322	macro: p 0.3596, r 0.3131, f1: 0.2909	micro: p 0.5322, r 0.5322, f1 0.5322	weighted_f1:0.5119
global_step: 4641, epoch: 17, loss: 0.720979
global_step: 4642, epoch: 17, loss: 0.750630
global_step: 4643, epoch: 17, loss: 0.690697
global_step: 4644, epoch: 17, loss: 0.744437
global_step: 4645, epoch: 17, loss: 0.518610
global_step: 4646, epoch: 17, loss: 0.750202
global_step: 4647, epoch: 17, loss: 0.746155
global_step: 4648, epoch: 17, loss: 0.785348
global_step: 4649, epoch: 17, loss: 0.719230
global_step: 4650, epoch: 17, loss: 0.628863
global_step: 4651, epoch: 17, loss: 0.718156
global_step: 4652, epoch: 17, loss: 0.651439
global_step: 4653, epoch: 17, loss: 0.711917
global_step: 4654, epoch: 17, loss: 0.656686
global_step: 4655, epoch: 17, loss: 0.681750
global_step: 4656, epoch: 17, loss: 0.765532
global_step: 4657, epoch: 17, loss: 0.640834
global_step: 4658, epoch: 17, loss: 0.715008
global_step: 4659, epoch: 17, loss: 0.818333
global_step: 4660, epoch: 17, loss: 0.694238
global_step: 4661, epoch: 17, loss: 0.792828
global_step: 4662, epoch: 17, loss: 0.741849
global_step: 4663, epoch: 17, loss: 0.633566
global_step: 4664, epoch: 17, loss: 0.650153
global_step: 4665, epoch: 17, loss: 0.754677
global_step: 4666, epoch: 17, loss: 0.661472
global_step: 4667, epoch: 17, loss: 0.713546
global_step: 4668, epoch: 17, loss: 0.668518
global_step: 4669, epoch: 17, loss: 0.686477
global_step: 4670, epoch: 17, loss: 0.769690
global_step: 4671, epoch: 17, loss: 0.595886
global_step: 4672, epoch: 17, loss: 0.803375
global_step: 4673, epoch: 17, loss: 0.776590
global_step: 4674, epoch: 17, loss: 0.716103
global_step: 4675, epoch: 17, loss: 0.794960
global_step: 4676, epoch: 17, loss: 0.750054
global_step: 4677, epoch: 17, loss: 0.821416
global_step: 4678, epoch: 17, loss: 0.703723
global_step: 4679, epoch: 17, loss: 0.865488
global_step: 4680, epoch: 17, loss: 0.531237
epoch: 17
train	acc: 0.8651	macro: p 0.8849, r 0.7416, f1: 0.7853	micro: p 0.8651, r 0.8651, f1 0.8651	weighted_f1:0.8620
dev	acc: 0.5095	macro: p 0.3755, r 0.2952, f1: 0.2860	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4686
test	acc: 0.5697	macro: p 0.3395, r 0.3202, f1: 0.3142	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5402
global_step: 4681, epoch: 18, loss: 0.810967
global_step: 4682, epoch: 18, loss: 0.767123
global_step: 4683, epoch: 18, loss: 0.633446
global_step: 4684, epoch: 18, loss: 0.612864
global_step: 4685, epoch: 18, loss: 0.660303
global_step: 4686, epoch: 18, loss: 0.646836
global_step: 4687, epoch: 18, loss: 0.618554
global_step: 4688, epoch: 18, loss: 0.692633
global_step: 4689, epoch: 18, loss: 0.597666
global_step: 4690, epoch: 18, loss: 0.719363
global_step: 4691, epoch: 18, loss: 0.743306
global_step: 4692, epoch: 18, loss: 0.764091
global_step: 4693, epoch: 18, loss: 0.674527
global_step: 4694, epoch: 18, loss: 0.692993
global_step: 4695, epoch: 18, loss: 0.677227
global_step: 4696, epoch: 18, loss: 0.674664
global_step: 4697, epoch: 18, loss: 0.622303
global_step: 4698, epoch: 18, loss: 0.644183
global_step: 4699, epoch: 18, loss: 0.700878
global_step: 4700, epoch: 18, loss: 0.704822
global_step: 4701, epoch: 18, loss: 0.625728
global_step: 4702, epoch: 18, loss: 0.610141
global_step: 4703, epoch: 18, loss: 0.591004
global_step: 4704, epoch: 18, loss: 0.724727
global_step: 4705, epoch: 18, loss: 0.674295
global_step: 4706, epoch: 18, loss: 0.697438
global_step: 4707, epoch: 18, loss: 0.662212
global_step: 4708, epoch: 18, loss: 0.654354
global_step: 4709, epoch: 18, loss: 0.662228
global_step: 4710, epoch: 18, loss: 0.744823
global_step: 4711, epoch: 18, loss: 0.799492
global_step: 4712, epoch: 18, loss: 0.677532
global_step: 4713, epoch: 18, loss: 0.564450
global_step: 4714, epoch: 18, loss: 0.726432
global_step: 4715, epoch: 18, loss: 0.672724
global_step: 4716, epoch: 18, loss: 0.682834
global_step: 4717, epoch: 18, loss: 0.694583
global_step: 4718, epoch: 18, loss: 0.663593
global_step: 4719, epoch: 18, loss: 0.763834
global_step: 4720, epoch: 18, loss: 0.071059
epoch: 18
train	acc: 0.8679	macro: p 0.8614, r 0.7593, f1: 0.7869	micro: p 0.8679, r 0.8679, f1 0.8679	weighted_f1:0.8622
dev	acc: 0.5320	macro: p 0.3392, r 0.3039, f1: 0.3077	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4866
test	acc: 0.5904	macro: p 0.4216, r 0.3269, f1: 0.3422	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5538
global_step: 4721, epoch: 19, loss: 0.734536
global_step: 4722, epoch: 19, loss: 0.621585
global_step: 4723, epoch: 19, loss: 0.760852
global_step: 4724, epoch: 19, loss: 0.589521
global_step: 4725, epoch: 19, loss: 0.472576
global_step: 4726, epoch: 19, loss: 0.670443
global_step: 4727, epoch: 19, loss: 0.744524
global_step: 4728, epoch: 19, loss: 0.686812
global_step: 4729, epoch: 19, loss: 0.592176
global_step: 4730, epoch: 19, loss: 0.605846
global_step: 4731, epoch: 19, loss: 0.540499
global_step: 4732, epoch: 19, loss: 0.619901
global_step: 4733, epoch: 19, loss: 0.688259
global_step: 4734, epoch: 19, loss: 0.677879
global_step: 4735, epoch: 19, loss: 0.703182
global_step: 4736, epoch: 19, loss: 0.664269
global_step: 4737, epoch: 19, loss: 0.624870
global_step: 4738, epoch: 19, loss: 0.570851
global_step: 4739, epoch: 19, loss: 0.621182
global_step: 4740, epoch: 19, loss: 0.588015
global_step: 4741, epoch: 19, loss: 0.681185
global_step: 4742, epoch: 19, loss: 0.669326
global_step: 4743, epoch: 19, loss: 0.678068
global_step: 4744, epoch: 19, loss: 0.634499
global_step: 4745, epoch: 19, loss: 0.738050
global_step: 4746, epoch: 19, loss: 0.716979
global_step: 4747, epoch: 19, loss: 0.869556
global_step: 4748, epoch: 19, loss: 0.730132
global_step: 4749, epoch: 19, loss: 0.677014
global_step: 4750, epoch: 19, loss: 0.657903
global_step: 4751, epoch: 19, loss: 0.553350
global_step: 4752, epoch: 19, loss: 0.730103
global_step: 4753, epoch: 19, loss: 0.666577
global_step: 4754, epoch: 19, loss: 0.753394
global_step: 4755, epoch: 19, loss: 0.678314
global_step: 4756, epoch: 19, loss: 0.704328
global_step: 4757, epoch: 19, loss: 0.671411
global_step: 4758, epoch: 19, loss: 0.698803
global_step: 4759, epoch: 19, loss: 0.707119
global_step: 4760, epoch: 19, loss: 1.304211
epoch: 19
train	acc: 0.8819	macro: p 0.8822, r 0.7628, f1: 0.7948	micro: p 0.8819, r 0.8819, f1 0.8819	weighted_f1:0.8783
dev	acc: 0.5221	macro: p 0.4478, r 0.3090, f1: 0.3093	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4938
test	acc: 0.5617	macro: p 0.3592, r 0.3294, f1: 0.3319	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5435
global_step: 4761, epoch: 20, loss: 0.738379
global_step: 4762, epoch: 20, loss: 0.749419
global_step: 4763, epoch: 20, loss: 0.640725
global_step: 4764, epoch: 20, loss: 0.709176
global_step: 4765, epoch: 20, loss: 0.588210
global_step: 4766, epoch: 20, loss: 0.483035
global_step: 4767, epoch: 20, loss: 0.520440
global_step: 4768, epoch: 20, loss: 0.662240
global_step: 4769, epoch: 20, loss: 0.592431
global_step: 4770, epoch: 20, loss: 0.708335
global_step: 4771, epoch: 20, loss: 0.581150
global_step: 4772, epoch: 20, loss: 0.649819
global_step: 4773, epoch: 20, loss: 0.491025
global_step: 4774, epoch: 20, loss: 0.559990
global_step: 4775, epoch: 20, loss: 0.489917
global_step: 4776, epoch: 20, loss: 0.573849
global_step: 4777, epoch: 20, loss: 0.599057
global_step: 4778, epoch: 20, loss: 0.671663
global_step: 4779, epoch: 20, loss: 0.624704
global_step: 4780, epoch: 20, loss: 0.787747
global_step: 4781, epoch: 20, loss: 0.557800
global_step: 4782, epoch: 20, loss: 0.661124
global_step: 4783, epoch: 20, loss: 0.673912
global_step: 4784, epoch: 20, loss: 0.674623
global_step: 4785, epoch: 20, loss: 0.597860
global_step: 4786, epoch: 20, loss: 0.659168
global_step: 4787, epoch: 20, loss: 0.631891
global_step: 4788, epoch: 20, loss: 0.751930
global_step: 4789, epoch: 20, loss: 0.724811
global_step: 4790, epoch: 20, loss: 0.822897
global_step: 4791, epoch: 20, loss: 0.760177
global_step: 4792, epoch: 20, loss: 0.656368
global_step: 4793, epoch: 20, loss: 0.675097
global_step: 4794, epoch: 20, loss: 0.672407
global_step: 4795, epoch: 20, loss: 0.702571
global_step: 4796, epoch: 20, loss: 0.677633
global_step: 4797, epoch: 20, loss: 0.597541
global_step: 4798, epoch: 20, loss: 0.789532
global_step: 4799, epoch: 20, loss: 0.663841
global_step: 4800, epoch: 20, loss: 1.007014
epoch: 20
train	acc: 0.8433	macro: p 0.8452, r 0.7635, f1: 0.7738	micro: p 0.8433, r 0.8433, f1 0.8433	weighted_f1:0.8476
dev	acc: 0.4680	macro: p 0.3681, r 0.3076, f1: 0.3064	micro: p 0.4680, r 0.4680, f1 0.4680	weighted_f1:0.4640
test	acc: 0.5169	macro: p 0.3578, r 0.3341, f1: 0.3233	micro: p 0.5169, r 0.5169, f1 0.5169	weighted_f1:0.5185
global_step: 4801, epoch: 21, loss: 0.617556
global_step: 4802, epoch: 21, loss: 0.685870
global_step: 4803, epoch: 21, loss: 0.713678
global_step: 4804, epoch: 21, loss: 0.646574
global_step: 4805, epoch: 21, loss: 0.606234
global_step: 4806, epoch: 21, loss: 0.664494
global_step: 4807, epoch: 21, loss: 0.636414
global_step: 4808, epoch: 21, loss: 0.523691
global_step: 4809, epoch: 21, loss: 0.661755
global_step: 4810, epoch: 21, loss: 0.572820
global_step: 4811, epoch: 21, loss: 0.578403
global_step: 4812, epoch: 21, loss: 0.630264
global_step: 4813, epoch: 21, loss: 0.628158
global_step: 4814, epoch: 21, loss: 0.578157
global_step: 4815, epoch: 21, loss: 0.568511
global_step: 4816, epoch: 21, loss: 0.566189
global_step: 4817, epoch: 21, loss: 0.552967
global_step: 4818, epoch: 21, loss: 0.545559
global_step: 4819, epoch: 21, loss: 0.617688
global_step: 4820, epoch: 21, loss: 0.562657
global_step: 4821, epoch: 21, loss: 0.593149
global_step: 4822, epoch: 21, loss: 0.747626
global_step: 4823, epoch: 21, loss: 0.707098
global_step: 4824, epoch: 21, loss: 0.662459
global_step: 4825, epoch: 21, loss: 0.736723
global_step: 4826, epoch: 21, loss: 0.669081
global_step: 4827, epoch: 21, loss: 0.663521
global_step: 4828, epoch: 21, loss: 0.585562
global_step: 4829, epoch: 21, loss: 0.580429
global_step: 4830, epoch: 21, loss: 0.552544
global_step: 4831, epoch: 21, loss: 0.624316
global_step: 4832, epoch: 21, loss: 0.602703
global_step: 4833, epoch: 21, loss: 0.607545
global_step: 4834, epoch: 21, loss: 0.564445
global_step: 4835, epoch: 21, loss: 0.660661
global_step: 4836, epoch: 21, loss: 0.521176
global_step: 4837, epoch: 21, loss: 0.578059
global_step: 4838, epoch: 21, loss: 0.854689
global_step: 4839, epoch: 21, loss: 0.686285
global_step: 4840, epoch: 21, loss: 0.322650
epoch: 21
train	acc: 0.9076	macro: p 0.9035, r 0.8325, f1: 0.8559	micro: p 0.9076, r 0.9076, f1 0.9076	weighted_f1:0.9062
dev	acc: 0.5284	macro: p 0.3611, r 0.3155, f1: 0.3175	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4949
test	acc: 0.5640	macro: p 0.3664, r 0.3265, f1: 0.3244	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5411
global_step: 4841, epoch: 22, loss: 0.485830
global_step: 4842, epoch: 22, loss: 0.661998
global_step: 4843, epoch: 22, loss: 0.428221
global_step: 4844, epoch: 22, loss: 0.633928
global_step: 4845, epoch: 22, loss: 0.505561
global_step: 4846, epoch: 22, loss: 0.452053
global_step: 4847, epoch: 22, loss: 0.623733
global_step: 4848, epoch: 22, loss: 0.494885
global_step: 4849, epoch: 22, loss: 0.539362
global_step: 4850, epoch: 22, loss: 0.592179
global_step: 4851, epoch: 22, loss: 0.645592
global_step: 4852, epoch: 22, loss: 0.649619
global_step: 4853, epoch: 22, loss: 0.648465
global_step: 4854, epoch: 22, loss: 0.601730
global_step: 4855, epoch: 22, loss: 0.466120
global_step: 4856, epoch: 22, loss: 0.607929
global_step: 4857, epoch: 22, loss: 0.587029
global_step: 4858, epoch: 22, loss: 0.562339
global_step: 4859, epoch: 22, loss: 0.582621
global_step: 4860, epoch: 22, loss: 0.593800
global_step: 4861, epoch: 22, loss: 0.568032
global_step: 4862, epoch: 22, loss: 0.634590
global_step: 4863, epoch: 22, loss: 0.602045
global_step: 4864, epoch: 22, loss: 0.532468
global_step: 4865, epoch: 22, loss: 0.578116
global_step: 4866, epoch: 22, loss: 0.556739
global_step: 4867, epoch: 22, loss: 0.579475
global_step: 4868, epoch: 22, loss: 0.748461
global_step: 4869, epoch: 22, loss: 0.601799
global_step: 4870, epoch: 22, loss: 0.684559
global_step: 4871, epoch: 22, loss: 0.638266
global_step: 4872, epoch: 22, loss: 0.620535
global_step: 4873, epoch: 22, loss: 0.658033
global_step: 4874, epoch: 22, loss: 0.606076
global_step: 4875, epoch: 22, loss: 0.558316
global_step: 4876, epoch: 22, loss: 0.710309
global_step: 4877, epoch: 22, loss: 0.583842
global_step: 4878, epoch: 22, loss: 0.638108
global_step: 4879, epoch: 22, loss: 0.595157
global_step: 4880, epoch: 22, loss: 0.797502
epoch: 22
train	acc: 0.8474	macro: p 0.8640, r 0.7888, f1: 0.8087	micro: p 0.8474, r 0.8474, f1 0.8474	weighted_f1:0.8547
dev	acc: 0.4409	macro: p 0.3350, r 0.2692, f1: 0.2642	micro: p 0.4409, r 0.4409, f1 0.4409	weighted_f1:0.4249
test	acc: 0.5011	macro: p 0.3648, r 0.3007, f1: 0.2953	micro: p 0.5011, r 0.5011, f1 0.5011	weighted_f1:0.4933
global_step: 4881, epoch: 23, loss: 0.766558
global_step: 4882, epoch: 23, loss: 0.691649
global_step: 4883, epoch: 23, loss: 0.717012
global_step: 4884, epoch: 23, loss: 0.528033
global_step: 4885, epoch: 23, loss: 0.420515
global_step: 4886, epoch: 23, loss: 0.487869
global_step: 4887, epoch: 23, loss: 0.540312
global_step: 4888, epoch: 23, loss: 0.496411
global_step: 4889, epoch: 23, loss: 0.611796
global_step: 4890, epoch: 23, loss: 0.537365
global_step: 4891, epoch: 23, loss: 0.593684
global_step: 4892, epoch: 23, loss: 0.558873
global_step: 4893, epoch: 23, loss: 0.712153
global_step: 4894, epoch: 23, loss: 0.503778
global_step: 4895, epoch: 23, loss: 0.468956
global_step: 4896, epoch: 23, loss: 0.480396
global_step: 4897, epoch: 23, loss: 0.545614
global_step: 4898, epoch: 23, loss: 0.639791
global_step: 4899, epoch: 23, loss: 0.598744
global_step: 4900, epoch: 23, loss: 0.652465
global_step: 4901, epoch: 23, loss: 0.571368
global_step: 4902, epoch: 23, loss: 0.556258
global_step: 4903, epoch: 23, loss: 0.531782
global_step: 4904, epoch: 23, loss: 0.482425
global_step: 4905, epoch: 23, loss: 0.530298
global_step: 4906, epoch: 23, loss: 0.613625
global_step: 4907, epoch: 23, loss: 0.580340
global_step: 4908, epoch: 23, loss: 0.568347
global_step: 4909, epoch: 23, loss: 0.568419
global_step: 4910, epoch: 23, loss: 0.649138
global_step: 4911, epoch: 23, loss: 0.663562
global_step: 4912, epoch: 23, loss: 0.585556
global_step: 4913, epoch: 23, loss: 0.618467
global_step: 4914, epoch: 23, loss: 0.702194
global_step: 4915, epoch: 23, loss: 0.600119
global_step: 4916, epoch: 23, loss: 0.569449
global_step: 4917, epoch: 23, loss: 0.488076
global_step: 4918, epoch: 23, loss: 0.621078
global_step: 4919, epoch: 23, loss: 0.540064
global_step: 4920, epoch: 23, loss: 1.052280
epoch: 23
train	acc: 0.9005	macro: p 0.8826, r 0.8567, f1: 0.8634	micro: p 0.9005, r 0.9005, f1 0.9005	weighted_f1:0.9013
dev	acc: 0.4923	macro: p 0.3489, r 0.3114, f1: 0.3064	micro: p 0.4923, r 0.4923, f1 0.4923	weighted_f1:0.4662
test	acc: 0.5287	macro: p 0.3458, r 0.3227, f1: 0.3139	micro: p 0.5287, r 0.5287, f1 0.5287	weighted_f1:0.5155
global_step: 4921, epoch: 24, loss: 0.509655
global_step: 4922, epoch: 24, loss: 0.642995
global_step: 4923, epoch: 24, loss: 0.561577
global_step: 4924, epoch: 24, loss: 0.523819
global_step: 4925, epoch: 24, loss: 0.573771
global_step: 4926, epoch: 24, loss: 0.515500
global_step: 4927, epoch: 24, loss: 0.655189
global_step: 4928, epoch: 24, loss: 0.521430
global_step: 4929, epoch: 24, loss: 0.474049
global_step: 4930, epoch: 24, loss: 0.536687
global_step: 4931, epoch: 24, loss: 0.445007
global_step: 4932, epoch: 24, loss: 0.551814
global_step: 4933, epoch: 24, loss: 0.634215
global_step: 4934, epoch: 24, loss: 0.482496
global_step: 4935, epoch: 24, loss: 0.503452
global_step: 4936, epoch: 24, loss: 0.612324
global_step: 4937, epoch: 24, loss: 0.500959
global_step: 4938, epoch: 24, loss: 0.544861
global_step: 4939, epoch: 24, loss: 0.458100
global_step: 4940, epoch: 24, loss: 0.579071
global_step: 4941, epoch: 24, loss: 0.630147
global_step: 4942, epoch: 24, loss: 0.659886
global_step: 4943, epoch: 24, loss: 0.645733
global_step: 4944, epoch: 24, loss: 0.559043
global_step: 4945, epoch: 24, loss: 0.515051
global_step: 4946, epoch: 24, loss: 0.543017
global_step: 4947, epoch: 24, loss: 0.504673
global_step: 4948, epoch: 24, loss: 0.546542
global_step: 4949, epoch: 24, loss: 0.565286
global_step: 4950, epoch: 24, loss: 0.548396
global_step: 4951, epoch: 24, loss: 0.554533
global_step: 4952, epoch: 24, loss: 0.574403
global_step: 4953, epoch: 24, loss: 0.619897
global_step: 4954, epoch: 24, loss: 0.542754
global_step: 4955, epoch: 24, loss: 0.585142
global_step: 4956, epoch: 24, loss: 0.539153
global_step: 4957, epoch: 24, loss: 0.540846
global_step: 4958, epoch: 24, loss: 0.531038
global_step: 4959, epoch: 24, loss: 0.480932
global_step: 4960, epoch: 24, loss: 1.849468
epoch: 24
train	acc: 0.9067	macro: p 0.8337, r 0.8894, f1: 0.8558	micro: p 0.9067, r 0.9067, f1 0.9067	weighted_f1:0.9087
dev	acc: 0.4824	macro: p 0.3388, r 0.3253, f1: 0.3178	micro: p 0.4824, r 0.4824, f1 0.4824	weighted_f1:0.4752
test	acc: 0.5011	macro: p 0.3475, r 0.3248, f1: 0.3209	micro: p 0.5011, r 0.5011, f1 0.5011	weighted_f1:0.5093
global_step: 4961, epoch: 25, loss: 0.582401
global_step: 4962, epoch: 25, loss: 0.566382
global_step: 4963, epoch: 25, loss: 0.465667
global_step: 4964, epoch: 25, loss: 0.521053
global_step: 4965, epoch: 25, loss: 0.483708
global_step: 4966, epoch: 25, loss: 0.586313
global_step: 4967, epoch: 25, loss: 0.565733
global_step: 4968, epoch: 25, loss: 0.446282
global_step: 4969, epoch: 25, loss: 0.586436
global_step: 4970, epoch: 25, loss: 0.481957
global_step: 4971, epoch: 25, loss: 0.624498
global_step: 4972, epoch: 25, loss: 0.539997
global_step: 4973, epoch: 25, loss: 0.460891
global_step: 4974, epoch: 25, loss: 0.530907
global_step: 4975, epoch: 25, loss: 0.526631
global_step: 4976, epoch: 25, loss: 0.529063
global_step: 4977, epoch: 25, loss: 0.409127
global_step: 4978, epoch: 25, loss: 0.502598
global_step: 4979, epoch: 25, loss: 0.528575
global_step: 4980, epoch: 25, loss: 0.507645
global_step: 4981, epoch: 25, loss: 0.447947
global_step: 4982, epoch: 25, loss: 0.521012
global_step: 4983, epoch: 25, loss: 0.491830
global_step: 4984, epoch: 25, loss: 0.742397
global_step: 4985, epoch: 25, loss: 0.536726
global_step: 4986, epoch: 25, loss: 0.440244
global_step: 4987, epoch: 25, loss: 0.439666
global_step: 4988, epoch: 25, loss: 0.687232
global_step: 4989, epoch: 25, loss: 0.485766
global_step: 4990, epoch: 25, loss: 0.473396
global_step: 4991, epoch: 25, loss: 0.557766
global_step: 4992, epoch: 25, loss: 0.488293
global_step: 4993, epoch: 25, loss: 0.603811
global_step: 4994, epoch: 25, loss: 0.526453
global_step: 4995, epoch: 25, loss: 0.506867
global_step: 4996, epoch: 25, loss: 0.614501
global_step: 4997, epoch: 25, loss: 0.540372
global_step: 4998, epoch: 25, loss: 0.578956
global_step: 4999, epoch: 25, loss: 0.497532
global_step: 5000, epoch: 25, loss: 1.091602
epoch: 25
train	acc: 0.9271	macro: p 0.9269, r 0.8882, f1: 0.9042	micro: p 0.9271, r 0.9271, f1 0.9271	weighted_f1:0.9272
dev	acc: 0.5086	macro: p 0.3948, r 0.3229, f1: 0.3283	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4835
test	acc: 0.5429	macro: p 0.3544, r 0.3249, f1: 0.3268	micro: p 0.5429, r 0.5429, f1 0.5429	weighted_f1:0.5314
global_step: 5001, epoch: 26, loss: 0.447689
global_step: 5002, epoch: 26, loss: 0.467150
global_step: 5003, epoch: 26, loss: 0.498343
global_step: 5004, epoch: 26, loss: 0.545742
global_step: 5005, epoch: 26, loss: 0.497762
global_step: 5006, epoch: 26, loss: 0.512718
global_step: 5007, epoch: 26, loss: 0.532883
global_step: 5008, epoch: 26, loss: 0.380014
global_step: 5009, epoch: 26, loss: 0.586956
global_step: 5010, epoch: 26, loss: 0.505736
global_step: 5011, epoch: 26, loss: 0.494254
global_step: 5012, epoch: 26, loss: 0.499635
global_step: 5013, epoch: 26, loss: 0.544063
global_step: 5014, epoch: 26, loss: 0.512349
global_step: 5015, epoch: 26, loss: 0.549931
global_step: 5016, epoch: 26, loss: 0.460895
global_step: 5017, epoch: 26, loss: 0.501578
global_step: 5018, epoch: 26, loss: 0.514888
global_step: 5019, epoch: 26, loss: 0.405786
global_step: 5020, epoch: 26, loss: 0.521122
global_step: 5021, epoch: 26, loss: 0.561983
global_step: 5022, epoch: 26, loss: 0.513996
global_step: 5023, epoch: 26, loss: 0.459212
global_step: 5024, epoch: 26, loss: 0.484944
global_step: 5025, epoch: 26, loss: 0.476295
global_step: 5026, epoch: 26, loss: 0.506399
global_step: 5027, epoch: 26, loss: 0.474038
global_step: 5028, epoch: 26, loss: 0.472111
global_step: 5029, epoch: 26, loss: 0.486464
global_step: 5030, epoch: 26, loss: 0.563683
global_step: 5031, epoch: 26, loss: 0.493436
global_step: 5032, epoch: 26, loss: 0.503098
global_step: 5033, epoch: 26, loss: 0.600447
global_step: 5034, epoch: 26, loss: 0.567767
global_step: 5035, epoch: 26, loss: 0.525748
global_step: 5036, epoch: 26, loss: 0.475808
global_step: 5037, epoch: 26, loss: 0.674754
global_step: 5038, epoch: 26, loss: 0.442493
global_step: 5039, epoch: 26, loss: 0.559956
global_step: 5040, epoch: 26, loss: 1.097721
epoch: 26
train	acc: 0.9268	macro: p 0.9315, r 0.8931, f1: 0.9096	micro: p 0.9268, r 0.9268, f1 0.9268	weighted_f1:0.9271
dev	acc: 0.5095	macro: p 0.4009, r 0.3122, f1: 0.3169	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4683
test	acc: 0.5651	macro: p 0.3584, r 0.3171, f1: 0.3112	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.5285
global_step: 5041, epoch: 27, loss: 0.592736
global_step: 5042, epoch: 27, loss: 0.531834
global_step: 5043, epoch: 27, loss: 0.446440
global_step: 5044, epoch: 27, loss: 0.416208
global_step: 5045, epoch: 27, loss: 0.524318
global_step: 5046, epoch: 27, loss: 0.572423
global_step: 5047, epoch: 27, loss: 0.612573
global_step: 5048, epoch: 27, loss: 0.484256
global_step: 5049, epoch: 27, loss: 0.469974
global_step: 5050, epoch: 27, loss: 0.450196
global_step: 5051, epoch: 27, loss: 0.544344
global_step: 5052, epoch: 27, loss: 0.438321
global_step: 5053, epoch: 27, loss: 0.504022
global_step: 5054, epoch: 27, loss: 0.524083
global_step: 5055, epoch: 27, loss: 0.445442
global_step: 5056, epoch: 27, loss: 0.536915
global_step: 5057, epoch: 27, loss: 0.502220
global_step: 5058, epoch: 27, loss: 0.385929
global_step: 5059, epoch: 27, loss: 0.481064
global_step: 5060, epoch: 27, loss: 0.467818
global_step: 5061, epoch: 27, loss: 0.470302
global_step: 5062, epoch: 27, loss: 0.472629
global_step: 5063, epoch: 27, loss: 0.459580
global_step: 5064, epoch: 27, loss: 0.507379
global_step: 5065, epoch: 27, loss: 0.557443
global_step: 5066, epoch: 27, loss: 0.567262
global_step: 5067, epoch: 27, loss: 0.363987
global_step: 5068, epoch: 27, loss: 0.487385
global_step: 5069, epoch: 27, loss: 0.418173
global_step: 5070, epoch: 27, loss: 0.491034
global_step: 5071, epoch: 27, loss: 0.469862
global_step: 5072, epoch: 27, loss: 0.538025
global_step: 5073, epoch: 27, loss: 0.541687
global_step: 5074, epoch: 27, loss: 0.458571
global_step: 5075, epoch: 27, loss: 0.591663
global_step: 5076, epoch: 27, loss: 0.500824
global_step: 5077, epoch: 27, loss: 0.606270
global_step: 5078, epoch: 27, loss: 0.509373
global_step: 5079, epoch: 27, loss: 0.607973
global_step: 5080, epoch: 27, loss: 0.030080
epoch: 27
train	acc: 0.9416	macro: p 0.9367, r 0.9136, f1: 0.9242	micro: p 0.9416, r 0.9416, f1 0.9416	weighted_f1:0.9417
dev	acc: 0.5140	macro: p 0.3610, r 0.3365, f1: 0.3395	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4923
test	acc: 0.5533	macro: p 0.3553, r 0.3376, f1: 0.3410	micro: p 0.5533, r 0.5533, f1 0.5533	weighted_f1:0.5420
global_step: 5081, epoch: 28, loss: 0.473383
global_step: 5082, epoch: 28, loss: 0.455400
global_step: 5083, epoch: 28, loss: 0.606033
global_step: 5084, epoch: 28, loss: 0.475719
global_step: 5085, epoch: 28, loss: 0.395195
global_step: 5086, epoch: 28, loss: 0.410278
global_step: 5087, epoch: 28, loss: 0.463514
global_step: 5088, epoch: 28, loss: 0.372652
global_step: 5089, epoch: 28, loss: 0.490350
global_step: 5090, epoch: 28, loss: 0.458504
global_step: 5091, epoch: 28, loss: 0.426294
global_step: 5092, epoch: 28, loss: 0.613343
global_step: 5093, epoch: 28, loss: 0.458796
global_step: 5094, epoch: 28, loss: 0.435083
global_step: 5095, epoch: 28, loss: 0.426200
global_step: 5096, epoch: 28, loss: 0.450193
global_step: 5097, epoch: 28, loss: 0.574478
global_step: 5098, epoch: 28, loss: 0.504172
global_step: 5099, epoch: 28, loss: 0.413740
global_step: 5100, epoch: 28, loss: 0.494988
global_step: 5101, epoch: 28, loss: 0.575044
global_step: 5102, epoch: 28, loss: 0.515540
global_step: 5103, epoch: 28, loss: 0.434831
global_step: 5104, epoch: 28, loss: 0.481761
global_step: 5105, epoch: 28, loss: 0.536746
global_step: 5106, epoch: 28, loss: 0.429227
global_step: 5107, epoch: 28, loss: 0.462900
global_step: 5108, epoch: 28, loss: 0.535235
global_step: 5109, epoch: 28, loss: 0.450378
global_step: 5110, epoch: 28, loss: 0.556968
global_step: 5111, epoch: 28, loss: 0.535992
global_step: 5112, epoch: 28, loss: 0.467489
global_step: 5113, epoch: 28, loss: 0.597773
global_step: 5114, epoch: 28, loss: 0.589260
global_step: 5115, epoch: 28, loss: 0.474893
global_step: 5116, epoch: 28, loss: 0.512305
global_step: 5117, epoch: 28, loss: 0.571401
global_step: 5118, epoch: 28, loss: 0.546993
global_step: 5119, epoch: 28, loss: 0.666732
global_step: 5120, epoch: 28, loss: 0.388960
epoch: 28
train	acc: 0.9270	macro: p 0.9336, r 0.8858, f1: 0.9063	micro: p 0.9270, r 0.9270, f1 0.9270	weighted_f1:0.9270
dev	acc: 0.5104	macro: p 0.3406, r 0.2933, f1: 0.2866	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4630
test	acc: 0.5594	macro: p 0.3359, r 0.3005, f1: 0.2954	micro: p 0.5594, r 0.5594, f1 0.5594	weighted_f1:0.5185
global_step: 5121, epoch: 29, loss: 0.458301
global_step: 5122, epoch: 29, loss: 0.481105
global_step: 5123, epoch: 29, loss: 0.453074
global_step: 5124, epoch: 29, loss: 0.386863
global_step: 5125, epoch: 29, loss: 0.507776
global_step: 5126, epoch: 29, loss: 0.424641
global_step: 5127, epoch: 29, loss: 0.554425
global_step: 5128, epoch: 29, loss: 0.466692
global_step: 5129, epoch: 29, loss: 0.423145
global_step: 5130, epoch: 29, loss: 0.585277
global_step: 5131, epoch: 29, loss: 0.415588
global_step: 5132, epoch: 29, loss: 0.596101
global_step: 5133, epoch: 29, loss: 0.436427
global_step: 5134, epoch: 29, loss: 0.609444
global_step: 5135, epoch: 29, loss: 0.477531
global_step: 5136, epoch: 29, loss: 0.418626
global_step: 5137, epoch: 29, loss: 0.608321
global_step: 5138, epoch: 29, loss: 0.471165
global_step: 5139, epoch: 29, loss: 0.492195
global_step: 5140, epoch: 29, loss: 0.437662
global_step: 5141, epoch: 29, loss: 0.475932
global_step: 5142, epoch: 29, loss: 0.537876
global_step: 5143, epoch: 29, loss: 0.608929
global_step: 5144, epoch: 29, loss: 0.453291
global_step: 5145, epoch: 29, loss: 0.465476
global_step: 5146, epoch: 29, loss: 0.521057
global_step: 5147, epoch: 29, loss: 0.516374
global_step: 5148, epoch: 29, loss: 0.461129
global_step: 5149, epoch: 29, loss: 0.469869
global_step: 5150, epoch: 29, loss: 0.504217
global_step: 5151, epoch: 29, loss: 0.437921
global_step: 5152, epoch: 29, loss: 0.599956
global_step: 5153, epoch: 29, loss: 0.491914
global_step: 5154, epoch: 29, loss: 0.544905
global_step: 5155, epoch: 29, loss: 0.507696
global_step: 5156, epoch: 29, loss: 0.424732
global_step: 5157, epoch: 29, loss: 0.578024
global_step: 5158, epoch: 29, loss: 0.571492
global_step: 5159, epoch: 29, loss: 0.475126
global_step: 5160, epoch: 29, loss: 0.088853
epoch: 29
train	acc: 0.9352	macro: p 0.9369, r 0.9035, f1: 0.9187	micro: p 0.9352, r 0.9352, f1 0.9352	weighted_f1:0.9352
dev	acc: 0.5221	macro: p 0.3678, r 0.3105, f1: 0.3145	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4894
test	acc: 0.5728	macro: p 0.3790, r 0.3225, f1: 0.3290	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5471
global_step: 5161, epoch: 30, loss: 0.435897
global_step: 5162, epoch: 30, loss: 0.454405
global_step: 5163, epoch: 30, loss: 0.427473
global_step: 5164, epoch: 30, loss: 0.429728
global_step: 5165, epoch: 30, loss: 0.448025
global_step: 5166, epoch: 30, loss: 0.536599
global_step: 5167, epoch: 30, loss: 0.614828
global_step: 5168, epoch: 30, loss: 0.460792
global_step: 5169, epoch: 30, loss: 0.380705
global_step: 5170, epoch: 30, loss: 0.439314
global_step: 5171, epoch: 30, loss: 0.387676
global_step: 5172, epoch: 30, loss: 0.415166
global_step: 5173, epoch: 30, loss: 0.440625
global_step: 5174, epoch: 30, loss: 0.557247
global_step: 5175, epoch: 30, loss: 0.536232
global_step: 5176, epoch: 30, loss: 0.348762
global_step: 5177, epoch: 30, loss: 0.418936
global_step: 5178, epoch: 30, loss: 0.441185
global_step: 5179, epoch: 30, loss: 0.446762
global_step: 5180, epoch: 30, loss: 0.408298
global_step: 5181, epoch: 30, loss: 0.509541
global_step: 5182, epoch: 30, loss: 0.458324
global_step: 5183, epoch: 30, loss: 0.510724
global_step: 5184, epoch: 30, loss: 0.537554
global_step: 5185, epoch: 30, loss: 0.498379
global_step: 5186, epoch: 30, loss: 0.540114
global_step: 5187, epoch: 30, loss: 0.630611
global_step: 5188, epoch: 30, loss: 0.497241
global_step: 5189, epoch: 30, loss: 0.567034
global_step: 5190, epoch: 30, loss: 0.424803
global_step: 5191, epoch: 30, loss: 0.421628
global_step: 5192, epoch: 30, loss: 0.405191
global_step: 5193, epoch: 30, loss: 0.449809
global_step: 5194, epoch: 30, loss: 0.612346
global_step: 5195, epoch: 30, loss: 0.600398
global_step: 5196, epoch: 30, loss: 0.557932
global_step: 5197, epoch: 30, loss: 0.562062
global_step: 5198, epoch: 30, loss: 0.599325
global_step: 5199, epoch: 30, loss: 0.476166
global_step: 5200, epoch: 30, loss: 0.950158
epoch: 30
train	acc: 0.9306	macro: p 0.9299, r 0.8978, f1: 0.9110	micro: p 0.9306, r 0.9306, f1 0.9306	weighted_f1:0.9309
dev	acc: 0.4824	macro: p 0.3378, r 0.2902, f1: 0.2926	micro: p 0.4824, r 0.4824, f1 0.4824	weighted_f1:0.4523
test	acc: 0.5521	macro: p 0.3509, r 0.3180, f1: 0.3208	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.5307
global_step: 5201, epoch: 31, loss: 0.488412
global_step: 5202, epoch: 31, loss: 0.442730
global_step: 5203, epoch: 31, loss: 0.389217
global_step: 5204, epoch: 31, loss: 0.437825
global_step: 5205, epoch: 31, loss: 0.425890
global_step: 5206, epoch: 31, loss: 0.494086
global_step: 5207, epoch: 31, loss: 0.546664
global_step: 5208, epoch: 31, loss: 0.476322
global_step: 5209, epoch: 31, loss: 0.406557
global_step: 5210, epoch: 31, loss: 0.422585
global_step: 5211, epoch: 31, loss: 0.460236
global_step: 5212, epoch: 31, loss: 0.450219
global_step: 5213, epoch: 31, loss: 0.387050
global_step: 5214, epoch: 31, loss: 0.568225
global_step: 5215, epoch: 31, loss: 0.518713
global_step: 5216, epoch: 31, loss: 0.473994
global_step: 5217, epoch: 31, loss: 0.408236
global_step: 5218, epoch: 31, loss: 0.426165
global_step: 5219, epoch: 31, loss: 0.547718
global_step: 5220, epoch: 31, loss: 0.479403
global_step: 5221, epoch: 31, loss: 0.504376
global_step: 5222, epoch: 31, loss: 0.554765
global_step: 5223, epoch: 31, loss: 0.391466
global_step: 5224, epoch: 31, loss: 0.373467
global_step: 5225, epoch: 31, loss: 0.421525
global_step: 5226, epoch: 31, loss: 0.493695
global_step: 5227, epoch: 31, loss: 0.499087
global_step: 5228, epoch: 31, loss: 0.471397
global_step: 5229, epoch: 31, loss: 0.661477
global_step: 5230, epoch: 31, loss: 0.465444
global_step: 5231, epoch: 31, loss: 0.445703
global_step: 5232, epoch: 31, loss: 0.488568
global_step: 5233, epoch: 31, loss: 0.443636
global_step: 5234, epoch: 31, loss: 0.487459
global_step: 5235, epoch: 31, loss: 0.463229
global_step: 5236, epoch: 31, loss: 0.511399
global_step: 5237, epoch: 31, loss: 0.425587
global_step: 5238, epoch: 31, loss: 0.501487
global_step: 5239, epoch: 31, loss: 0.533660
global_step: 5240, epoch: 31, loss: 1.144922
epoch: 31
train	acc: 0.9402	macro: p 0.9430, r 0.9130, f1: 0.9266	micro: p 0.9402, r 0.9402, f1 0.9402	weighted_f1:0.9403
dev	acc: 0.5104	macro: p 0.3487, r 0.3085, f1: 0.3094	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4785
test	acc: 0.5556	macro: p 0.3528, r 0.3245, f1: 0.3264	micro: p 0.5556, r 0.5556, f1 0.5556	weighted_f1:0.5365
global_step: 5241, epoch: 32, loss: 0.560589
global_step: 5242, epoch: 32, loss: 0.474948
global_step: 5243, epoch: 32, loss: 0.449757
global_step: 5244, epoch: 32, loss: 0.448666
global_step: 5245, epoch: 32, loss: 0.403185
global_step: 5246, epoch: 32, loss: 0.431007
global_step: 5247, epoch: 32, loss: 0.402524
global_step: 5248, epoch: 32, loss: 0.420974
global_step: 5249, epoch: 32, loss: 0.497172
global_step: 5250, epoch: 32, loss: 0.463311
global_step: 5251, epoch: 32, loss: 0.444251
global_step: 5252, epoch: 32, loss: 0.474710
global_step: 5253, epoch: 32, loss: 0.472576
global_step: 5254, epoch: 32, loss: 0.376763
global_step: 5255, epoch: 32, loss: 0.489519
global_step: 5256, epoch: 32, loss: 0.426637
global_step: 5257, epoch: 32, loss: 0.422886
global_step: 5258, epoch: 32, loss: 0.472560
global_step: 5259, epoch: 32, loss: 0.438207
global_step: 5260, epoch: 32, loss: 0.540074
global_step: 5261, epoch: 32, loss: 0.428632
global_step: 5262, epoch: 32, loss: 0.351299
global_step: 5263, epoch: 32, loss: 0.494737
global_step: 5264, epoch: 32, loss: 0.500498
global_step: 5265, epoch: 32, loss: 0.407371
global_step: 5266, epoch: 32, loss: 0.339146
global_step: 5267, epoch: 32, loss: 0.363951
global_step: 5268, epoch: 32, loss: 0.460430
global_step: 5269, epoch: 32, loss: 0.434488
global_step: 5270, epoch: 32, loss: 0.445196
global_step: 5271, epoch: 32, loss: 0.519562
global_step: 5272, epoch: 32, loss: 0.518848
global_step: 5273, epoch: 32, loss: 0.525717
global_step: 5274, epoch: 32, loss: 0.438040
global_step: 5275, epoch: 32, loss: 0.564287
global_step: 5276, epoch: 32, loss: 0.475352
global_step: 5277, epoch: 32, loss: 0.497758
global_step: 5278, epoch: 32, loss: 0.472330
global_step: 5279, epoch: 32, loss: 0.481577
global_step: 5280, epoch: 32, loss: 0.042891
epoch: 32
train	acc: 0.9445	macro: p 0.9564, r 0.9114, f1: 0.9324	micro: p 0.9445, r 0.9445, f1 0.9445	weighted_f1:0.9442
dev	acc: 0.5203	macro: p 0.3228, r 0.2890, f1: 0.2898	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4714
test	acc: 0.5648	macro: p 0.3648, r 0.3067, f1: 0.3179	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5301
global_step: 5281, epoch: 33, loss: 0.431328
global_step: 5282, epoch: 33, loss: 0.393119
global_step: 5283, epoch: 33, loss: 0.415518
global_step: 5284, epoch: 33, loss: 0.369463
global_step: 5285, epoch: 33, loss: 0.548219
global_step: 5286, epoch: 33, loss: 0.383839
global_step: 5287, epoch: 33, loss: 0.355156
global_step: 5288, epoch: 33, loss: 0.477479
global_step: 5289, epoch: 33, loss: 0.431710
global_step: 5290, epoch: 33, loss: 0.389589
global_step: 5291, epoch: 33, loss: 0.407096
global_step: 5292, epoch: 33, loss: 0.491574
global_step: 5293, epoch: 33, loss: 0.436944
global_step: 5294, epoch: 33, loss: 0.481776
global_step: 5295, epoch: 33, loss: 0.457452
global_step: 5296, epoch: 33, loss: 0.506185
global_step: 5297, epoch: 33, loss: 0.387692
global_step: 5298, epoch: 33, loss: 0.441458
global_step: 5299, epoch: 33, loss: 0.547080
global_step: 5300, epoch: 33, loss: 0.429414
global_step: 5301, epoch: 33, loss: 0.441250
global_step: 5302, epoch: 33, loss: 0.442174
global_step: 5303, epoch: 33, loss: 0.389057
global_step: 5304, epoch: 33, loss: 0.512733
global_step: 5305, epoch: 33, loss: 0.530897
global_step: 5306, epoch: 33, loss: 0.487467
global_step: 5307, epoch: 33, loss: 0.407597
global_step: 5308, epoch: 33, loss: 0.445730
global_step: 5309, epoch: 33, loss: 0.391722
global_step: 5310, epoch: 33, loss: 0.522811
global_step: 5311, epoch: 33, loss: 0.498056
global_step: 5312, epoch: 33, loss: 0.511314
global_step: 5313, epoch: 33, loss: 0.474470
global_step: 5314, epoch: 33, loss: 0.393686
global_step: 5315, epoch: 33, loss: 0.590249
global_step: 5316, epoch: 33, loss: 0.538788
global_step: 5317, epoch: 33, loss: 0.509404
global_step: 5318, epoch: 33, loss: 0.461510
global_step: 5319, epoch: 33, loss: 0.571227
global_step: 5320, epoch: 33, loss: 0.077151
epoch: 33
train	acc: 0.9469	macro: p 0.9458, r 0.9184, f1: 0.9313	micro: p 0.9469, r 0.9469, f1 0.9469	weighted_f1:0.9468
dev	acc: 0.5275	macro: p 0.3486, r 0.3207, f1: 0.3143	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4859
test	acc: 0.5709	macro: p 0.3534, r 0.3150, f1: 0.3208	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5385
global_step: 5321, epoch: 34, loss: 0.459394
global_step: 5322, epoch: 34, loss: 0.386201
global_step: 5323, epoch: 34, loss: 0.393458
global_step: 5324, epoch: 34, loss: 0.461587
global_step: 5325, epoch: 34, loss: 0.372950
global_step: 5326, epoch: 34, loss: 0.395761
global_step: 5327, epoch: 34, loss: 0.348448
global_step: 5328, epoch: 34, loss: 0.424794
global_step: 5329, epoch: 34, loss: 0.388621
global_step: 5330, epoch: 34, loss: 0.329659
global_step: 5331, epoch: 34, loss: 0.363809
global_step: 5332, epoch: 34, loss: 0.357816
global_step: 5333, epoch: 34, loss: 0.399818
global_step: 5334, epoch: 34, loss: 0.502694
global_step: 5335, epoch: 34, loss: 0.413777
global_step: 5336, epoch: 34, loss: 0.367946
global_step: 5337, epoch: 34, loss: 0.436081
global_step: 5338, epoch: 34, loss: 0.412870
global_step: 5339, epoch: 34, loss: 0.443155
global_step: 5340, epoch: 34, loss: 0.478408
global_step: 5341, epoch: 34, loss: 0.479375
global_step: 5342, epoch: 34, loss: 0.486018
global_step: 5343, epoch: 34, loss: 0.590319
global_step: 5344, epoch: 34, loss: 0.414676
global_step: 5345, epoch: 34, loss: 0.478706
global_step: 5346, epoch: 34, loss: 0.391302
global_step: 5347, epoch: 34, loss: 0.410903
global_step: 5348, epoch: 34, loss: 0.485314
global_step: 5349, epoch: 34, loss: 0.371771
global_step: 5350, epoch: 34, loss: 0.454158
global_step: 5351, epoch: 34, loss: 0.523047
global_step: 5352, epoch: 34, loss: 0.420545
global_step: 5353, epoch: 34, loss: 0.385936
global_step: 5354, epoch: 34, loss: 0.376063
global_step: 5355, epoch: 34, loss: 0.552589
global_step: 5356, epoch: 34, loss: 0.455297
global_step: 5357, epoch: 34, loss: 0.345526
global_step: 5358, epoch: 34, loss: 0.473051
global_step: 5359, epoch: 34, loss: 0.486291
global_step: 5360, epoch: 34, loss: 0.349283
epoch: 34
train	acc: 0.9501	macro: p 0.9558, r 0.9191, f1: 0.9358	micro: p 0.9501, r 0.9501, f1 0.9501	weighted_f1:0.9500
dev	acc: 0.5194	macro: p 0.3666, r 0.3104, f1: 0.3098	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4816
test	acc: 0.5510	macro: p 0.3410, r 0.3119, f1: 0.3133	micro: p 0.5510, r 0.5510, f1 0.5510	weighted_f1:0.5271
global_step: 5361, epoch: 35, loss: 0.481000
global_step: 5362, epoch: 35, loss: 0.317436
global_step: 5363, epoch: 35, loss: 0.408565
global_step: 5364, epoch: 35, loss: 0.409095
global_step: 5365, epoch: 35, loss: 0.339095
global_step: 5366, epoch: 35, loss: 0.555721
global_step: 5367, epoch: 35, loss: 0.448601
global_step: 5368, epoch: 35, loss: 0.455119
global_step: 5369, epoch: 35, loss: 0.409104
global_step: 5370, epoch: 35, loss: 0.339841
global_step: 5371, epoch: 35, loss: 0.414336
global_step: 5372, epoch: 35, loss: 0.451341
global_step: 5373, epoch: 35, loss: 0.395525
global_step: 5374, epoch: 35, loss: 0.393793
global_step: 5375, epoch: 35, loss: 0.368545
global_step: 5376, epoch: 35, loss: 0.439048
global_step: 5377, epoch: 35, loss: 0.413570
global_step: 5378, epoch: 35, loss: 0.381195
global_step: 5379, epoch: 35, loss: 0.468927
global_step: 5380, epoch: 35, loss: 0.520680
global_step: 5381, epoch: 35, loss: 0.472651
global_step: 5382, epoch: 35, loss: 0.283507
global_step: 5383, epoch: 35, loss: 0.528056
global_step: 5384, epoch: 35, loss: 0.487801
global_step: 5385, epoch: 35, loss: 0.422871
global_step: 5386, epoch: 35, loss: 0.482039
global_step: 5387, epoch: 35, loss: 0.361377
global_step: 5388, epoch: 35, loss: 0.538513
global_step: 5389, epoch: 35, loss: 0.381746
global_step: 5390, epoch: 35, loss: 0.405784
global_step: 5391, epoch: 35, loss: 0.432549
global_step: 5392, epoch: 35, loss: 0.425611
global_step: 5393, epoch: 35, loss: 0.374824
global_step: 5394, epoch: 35, loss: 0.428739
global_step: 5395, epoch: 35, loss: 0.432534
global_step: 5396, epoch: 35, loss: 0.509218
global_step: 5397, epoch: 35, loss: 0.424063
global_step: 5398, epoch: 35, loss: 0.423196
global_step: 5399, epoch: 35, loss: 0.415500
global_step: 5400, epoch: 35, loss: 0.026242
epoch: 35
train	acc: 0.9513	macro: p 0.9590, r 0.9246, f1: 0.9408	micro: p 0.9513, r 0.9513, f1 0.9513	weighted_f1:0.9512
dev	acc: 0.5347	macro: p 0.3903, r 0.3070, f1: 0.3141	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4828
test	acc: 0.5820	macro: p 0.3874, r 0.3103, f1: 0.3231	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5406
global_step: 5401, epoch: 36, loss: 0.410132
global_step: 5402, epoch: 36, loss: 0.278825
global_step: 5403, epoch: 36, loss: 0.393495
global_step: 5404, epoch: 36, loss: 0.320545
global_step: 5405, epoch: 36, loss: 0.312151
global_step: 5406, epoch: 36, loss: 0.351623
global_step: 5407, epoch: 36, loss: 0.463527
global_step: 5408, epoch: 36, loss: 0.338928
global_step: 5409, epoch: 36, loss: 0.334846
global_step: 5410, epoch: 36, loss: 0.341026
global_step: 5411, epoch: 36, loss: 0.489010
global_step: 5412, epoch: 36, loss: 0.312936
global_step: 5413, epoch: 36, loss: 0.497067
global_step: 5414, epoch: 36, loss: 0.428080
global_step: 5415, epoch: 36, loss: 0.417923
global_step: 5416, epoch: 36, loss: 0.478821
global_step: 5417, epoch: 36, loss: 0.380752
global_step: 5418, epoch: 36, loss: 0.391729
global_step: 5419, epoch: 36, loss: 0.513104
global_step: 5420, epoch: 36, loss: 0.501584
global_step: 5421, epoch: 36, loss: 0.392093
global_step: 5422, epoch: 36, loss: 0.358938
global_step: 5423, epoch: 36, loss: 0.456253
global_step: 5424, epoch: 36, loss: 0.438867
global_step: 5425, epoch: 36, loss: 0.379881
global_step: 5426, epoch: 36, loss: 0.431591
global_step: 5427, epoch: 36, loss: 0.492902
global_step: 5428, epoch: 36, loss: 0.440543
global_step: 5429, epoch: 36, loss: 0.339697
global_step: 5430, epoch: 36, loss: 0.432263
global_step: 5431, epoch: 36, loss: 0.444076
global_step: 5432, epoch: 36, loss: 0.445484
global_step: 5433, epoch: 36, loss: 0.370751
global_step: 5434, epoch: 36, loss: 0.385540
global_step: 5435, epoch: 36, loss: 0.384149
global_step: 5436, epoch: 36, loss: 0.351815
global_step: 5437, epoch: 36, loss: 0.389132
global_step: 5438, epoch: 36, loss: 0.408732
global_step: 5439, epoch: 36, loss: 0.557936
global_step: 5440, epoch: 36, loss: 0.336965
epoch: 36
train	acc: 0.9450	macro: p 0.9437, r 0.9253, f1: 0.9338	micro: p 0.9450, r 0.9450, f1 0.9450	weighted_f1:0.9451
dev	acc: 0.5338	macro: p 0.3867, r 0.3144, f1: 0.3187	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4932
test	acc: 0.5709	macro: p 0.3739, r 0.3188, f1: 0.3264	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5413
global_step: 5441, epoch: 37, loss: 0.353263
global_step: 5442, epoch: 37, loss: 0.359648
global_step: 5443, epoch: 37, loss: 0.416617
global_step: 5444, epoch: 37, loss: 0.494727
global_step: 5445, epoch: 37, loss: 0.418891
global_step: 5446, epoch: 37, loss: 0.361361
global_step: 5447, epoch: 37, loss: 0.514337
global_step: 5448, epoch: 37, loss: 0.446970
global_step: 5449, epoch: 37, loss: 0.365538
global_step: 5450, epoch: 37, loss: 0.363136
global_step: 5451, epoch: 37, loss: 0.333548
global_step: 5452, epoch: 37, loss: 0.373503
global_step: 5453, epoch: 37, loss: 0.333912
global_step: 5454, epoch: 37, loss: 0.410159
global_step: 5455, epoch: 37, loss: 0.390930
global_step: 5456, epoch: 37, loss: 0.450294
global_step: 5457, epoch: 37, loss: 0.413014
global_step: 5458, epoch: 37, loss: 0.376504
global_step: 5459, epoch: 37, loss: 0.421661
global_step: 5460, epoch: 37, loss: 0.389473
global_step: 5461, epoch: 37, loss: 0.476269
global_step: 5462, epoch: 37, loss: 0.432755
global_step: 5463, epoch: 37, loss: 0.424309
global_step: 5464, epoch: 37, loss: 0.378702
global_step: 5465, epoch: 37, loss: 0.404296
global_step: 5466, epoch: 37, loss: 0.443350
global_step: 5467, epoch: 37, loss: 0.446132
global_step: 5468, epoch: 37, loss: 0.402200
global_step: 5469, epoch: 37, loss: 0.434402
global_step: 5470, epoch: 37, loss: 0.398679
global_step: 5471, epoch: 37, loss: 0.381296
global_step: 5472, epoch: 37, loss: 0.368934
global_step: 5473, epoch: 37, loss: 0.415442
global_step: 5474, epoch: 37, loss: 0.448997
global_step: 5475, epoch: 37, loss: 0.446139
global_step: 5476, epoch: 37, loss: 0.381850
global_step: 5477, epoch: 37, loss: 0.419991
global_step: 5478, epoch: 37, loss: 0.365759
global_step: 5479, epoch: 37, loss: 0.415960
global_step: 5480, epoch: 37, loss: 0.468181
epoch: 37
train	acc: 0.9458	macro: p 0.9501, r 0.9292, f1: 0.9378	micro: p 0.9458, r 0.9458, f1 0.9458	weighted_f1:0.9465
dev	acc: 0.5203	macro: p 0.3898, r 0.3201, f1: 0.3218	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4771
test	acc: 0.5682	macro: p 0.3721, r 0.3218, f1: 0.3218	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5361
global_step: 5481, epoch: 38, loss: 0.367883
global_step: 5482, epoch: 38, loss: 0.435442
global_step: 5483, epoch: 38, loss: 0.336460
global_step: 5484, epoch: 38, loss: 0.370592
global_step: 5485, epoch: 38, loss: 0.362311
global_step: 5486, epoch: 38, loss: 0.374115
global_step: 5487, epoch: 38, loss: 0.345750
global_step: 5488, epoch: 38, loss: 0.448546
global_step: 5489, epoch: 38, loss: 0.377910
global_step: 5490, epoch: 38, loss: 0.365997
global_step: 5491, epoch: 38, loss: 0.443097
global_step: 5492, epoch: 38, loss: 0.385913
global_step: 5493, epoch: 38, loss: 0.407441
global_step: 5494, epoch: 38, loss: 0.382644
global_step: 5495, epoch: 38, loss: 0.373631
global_step: 5496, epoch: 38, loss: 0.439954
global_step: 5497, epoch: 38, loss: 0.475489
global_step: 5498, epoch: 38, loss: 0.346582
global_step: 5499, epoch: 38, loss: 0.445064
global_step: 5500, epoch: 38, loss: 0.393157
global_step: 5501, epoch: 38, loss: 0.400270
global_step: 5502, epoch: 38, loss: 0.407049
global_step: 5503, epoch: 38, loss: 0.317641
global_step: 5504, epoch: 38, loss: 0.383397
global_step: 5505, epoch: 38, loss: 0.410798
global_step: 5506, epoch: 38, loss: 0.422631
global_step: 5507, epoch: 38, loss: 0.435259
global_step: 5508, epoch: 38, loss: 0.396575
global_step: 5509, epoch: 38, loss: 0.337187
global_step: 5510, epoch: 38, loss: 0.476885
global_step: 5511, epoch: 38, loss: 0.434978
global_step: 5512, epoch: 38, loss: 0.479687
global_step: 5513, epoch: 38, loss: 0.391709
global_step: 5514, epoch: 38, loss: 0.338228
global_step: 5515, epoch: 38, loss: 0.403817
global_step: 5516, epoch: 38, loss: 0.456071
global_step: 5517, epoch: 38, loss: 0.427739
global_step: 5518, epoch: 38, loss: 0.464489
global_step: 5519, epoch: 38, loss: 0.414416
global_step: 5520, epoch: 38, loss: 0.370632
epoch: 38
train	acc: 0.9459	macro: p 0.9449, r 0.9232, f1: 0.9327	micro: p 0.9459, r 0.9459, f1 0.9459	weighted_f1:0.9462
dev	acc: 0.5230	macro: p 0.3979, r 0.3163, f1: 0.3190	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4936
test	acc: 0.5690	macro: p 0.3794, r 0.3333, f1: 0.3374	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5499
global_step: 5521, epoch: 39, loss: 0.388417
global_step: 5522, epoch: 39, loss: 0.433051
global_step: 5523, epoch: 39, loss: 0.370812
global_step: 5524, epoch: 39, loss: 0.346921
global_step: 5525, epoch: 39, loss: 0.317125
global_step: 5526, epoch: 39, loss: 0.355559
global_step: 5527, epoch: 39, loss: 0.356334
global_step: 5528, epoch: 39, loss: 0.394210
global_step: 5529, epoch: 39, loss: 0.341278
global_step: 5530, epoch: 39, loss: 0.404404
global_step: 5531, epoch: 39, loss: 0.382964
global_step: 5532, epoch: 39, loss: 0.366192
global_step: 5533, epoch: 39, loss: 0.414010
global_step: 5534, epoch: 39, loss: 0.424391
global_step: 5535, epoch: 39, loss: 0.452986
global_step: 5536, epoch: 39, loss: 0.424774
global_step: 5537, epoch: 39, loss: 0.361370
global_step: 5538, epoch: 39, loss: 0.322452
global_step: 5539, epoch: 39, loss: 0.452132
global_step: 5540, epoch: 39, loss: 0.376193
global_step: 5541, epoch: 39, loss: 0.319664
global_step: 5542, epoch: 39, loss: 0.415887
global_step: 5543, epoch: 39, loss: 0.417051
global_step: 5544, epoch: 39, loss: 0.485059
global_step: 5545, epoch: 39, loss: 0.457064
global_step: 5546, epoch: 39, loss: 0.367251
global_step: 5547, epoch: 39, loss: 0.291373
global_step: 5548, epoch: 39, loss: 0.403038
global_step: 5549, epoch: 39, loss: 0.333022
global_step: 5550, epoch: 39, loss: 0.319749
global_step: 5551, epoch: 39, loss: 0.307374
global_step: 5552, epoch: 39, loss: 0.454910
global_step: 5553, epoch: 39, loss: 0.420026
global_step: 5554, epoch: 39, loss: 0.457470
global_step: 5555, epoch: 39, loss: 0.488578
global_step: 5556, epoch: 39, loss: 0.352742
global_step: 5557, epoch: 39, loss: 0.366810
global_step: 5558, epoch: 39, loss: 0.365180
global_step: 5559, epoch: 39, loss: 0.439977
global_step: 5560, epoch: 39, loss: 0.164896
epoch: 39
train	acc: 0.9563	macro: p 0.9613, r 0.9328, f1: 0.9462	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9562
dev	acc: 0.5257	macro: p 0.3593, r 0.3185, f1: 0.3240	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4855
test	acc: 0.5732	macro: p 0.3617, r 0.3163, f1: 0.3241	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5409
global_step: 5561, epoch: 40, loss: 0.327803
global_step: 5562, epoch: 40, loss: 0.386860
global_step: 5563, epoch: 40, loss: 0.261805
global_step: 5564, epoch: 40, loss: 0.337454
global_step: 5565, epoch: 40, loss: 0.320520
global_step: 5566, epoch: 40, loss: 0.421940
global_step: 5567, epoch: 40, loss: 0.370443
global_step: 5568, epoch: 40, loss: 0.320358
global_step: 5569, epoch: 40, loss: 0.372730
global_step: 5570, epoch: 40, loss: 0.317689
global_step: 5571, epoch: 40, loss: 0.434211
global_step: 5572, epoch: 40, loss: 0.405201
global_step: 5573, epoch: 40, loss: 0.317142
global_step: 5574, epoch: 40, loss: 0.395952
global_step: 5575, epoch: 40, loss: 0.320720
global_step: 5576, epoch: 40, loss: 0.340228
global_step: 5577, epoch: 40, loss: 0.428883
global_step: 5578, epoch: 40, loss: 0.414757
global_step: 5579, epoch: 40, loss: 0.426148
global_step: 5580, epoch: 40, loss: 0.397200
global_step: 5581, epoch: 40, loss: 0.358998
global_step: 5582, epoch: 40, loss: 0.546389
global_step: 5583, epoch: 40, loss: 0.368770
global_step: 5584, epoch: 40, loss: 0.321241
global_step: 5585, epoch: 40, loss: 0.305702
global_step: 5586, epoch: 40, loss: 0.334605
global_step: 5587, epoch: 40, loss: 0.395862
global_step: 5588, epoch: 40, loss: 0.429649
global_step: 5589, epoch: 40, loss: 0.328628
global_step: 5590, epoch: 40, loss: 0.390437
global_step: 5591, epoch: 40, loss: 0.436090
global_step: 5592, epoch: 40, loss: 0.329508
global_step: 5593, epoch: 40, loss: 0.355806
global_step: 5594, epoch: 40, loss: 0.383250
global_step: 5595, epoch: 40, loss: 0.349873
global_step: 5596, epoch: 40, loss: 0.453763
global_step: 5597, epoch: 40, loss: 0.394803
global_step: 5598, epoch: 40, loss: 0.412162
global_step: 5599, epoch: 40, loss: 0.456052
global_step: 5600, epoch: 40, loss: 0.015041
epoch: 40
train	acc: 0.9584	macro: p 0.9613, r 0.9382, f1: 0.9493	micro: p 0.9584, r 0.9584, f1 0.9584	weighted_f1:0.9583
dev	acc: 0.5257	macro: p 0.3648, r 0.3220, f1: 0.3263	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4843
test	acc: 0.5655	macro: p 0.3685, r 0.3170, f1: 0.3272	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5327
global_step: 5601, epoch: 41, loss: 0.429695
global_step: 5602, epoch: 41, loss: 0.308637
global_step: 5603, epoch: 41, loss: 0.331280
global_step: 5604, epoch: 41, loss: 0.280130
global_step: 5605, epoch: 41, loss: 0.354403
global_step: 5606, epoch: 41, loss: 0.329580
global_step: 5607, epoch: 41, loss: 0.360007
global_step: 5608, epoch: 41, loss: 0.322818
global_step: 5609, epoch: 41, loss: 0.436938
global_step: 5610, epoch: 41, loss: 0.429978
global_step: 5611, epoch: 41, loss: 0.298969
global_step: 5612, epoch: 41, loss: 0.356682
global_step: 5613, epoch: 41, loss: 0.321847
global_step: 5614, epoch: 41, loss: 0.384506
global_step: 5615, epoch: 41, loss: 0.356169
global_step: 5616, epoch: 41, loss: 0.471094
global_step: 5617, epoch: 41, loss: 0.389018
global_step: 5618, epoch: 41, loss: 0.327406
global_step: 5619, epoch: 41, loss: 0.354098
global_step: 5620, epoch: 41, loss: 0.404609
global_step: 5621, epoch: 41, loss: 0.475798
global_step: 5622, epoch: 41, loss: 0.337007
global_step: 5623, epoch: 41, loss: 0.399066
global_step: 5624, epoch: 41, loss: 0.348290
global_step: 5625, epoch: 41, loss: 0.369165
global_step: 5626, epoch: 41, loss: 0.369201
global_step: 5627, epoch: 41, loss: 0.285834
global_step: 5628, epoch: 41, loss: 0.449095
global_step: 5629, epoch: 41, loss: 0.394562
global_step: 5630, epoch: 41, loss: 0.305381
global_step: 5631, epoch: 41, loss: 0.344559
global_step: 5632, epoch: 41, loss: 0.360498
global_step: 5633, epoch: 41, loss: 0.452146
global_step: 5634, epoch: 41, loss: 0.436635
global_step: 5635, epoch: 41, loss: 0.384710
global_step: 5636, epoch: 41, loss: 0.421350
global_step: 5637, epoch: 41, loss: 0.410810
global_step: 5638, epoch: 41, loss: 0.404966
global_step: 5639, epoch: 41, loss: 0.469715
global_step: 5640, epoch: 41, loss: 0.030007
epoch: 41
train	acc: 0.9578	macro: p 0.9627, r 0.9407, f1: 0.9512	micro: p 0.9578, r 0.9578, f1 0.9578	weighted_f1:0.9577
dev	acc: 0.5176	macro: p 0.3732, r 0.3095, f1: 0.3174	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4818
test	acc: 0.5678	macro: p 0.3726, r 0.3188, f1: 0.3301	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5402
global_step: 5641, epoch: 42, loss: 0.323550
global_step: 5642, epoch: 42, loss: 0.246084
global_step: 5643, epoch: 42, loss: 0.285327
global_step: 5644, epoch: 42, loss: 0.384054
global_step: 5645, epoch: 42, loss: 0.317360
global_step: 5646, epoch: 42, loss: 0.459066
global_step: 5647, epoch: 42, loss: 0.302862
global_step: 5648, epoch: 42, loss: 0.394713
global_step: 5649, epoch: 42, loss: 0.408464
global_step: 5650, epoch: 42, loss: 0.355620
global_step: 5651, epoch: 42, loss: 0.294539
global_step: 5652, epoch: 42, loss: 0.358562
global_step: 5653, epoch: 42, loss: 0.305129
global_step: 5654, epoch: 42, loss: 0.426602
global_step: 5655, epoch: 42, loss: 0.367843
global_step: 5656, epoch: 42, loss: 0.295630
global_step: 5657, epoch: 42, loss: 0.342184
global_step: 5658, epoch: 42, loss: 0.368314
global_step: 5659, epoch: 42, loss: 0.382843
global_step: 5660, epoch: 42, loss: 0.441311
global_step: 5661, epoch: 42, loss: 0.538678
global_step: 5662, epoch: 42, loss: 0.340715
global_step: 5663, epoch: 42, loss: 0.377770
global_step: 5664, epoch: 42, loss: 0.390018
global_step: 5665, epoch: 42, loss: 0.253942
global_step: 5666, epoch: 42, loss: 0.357331
global_step: 5667, epoch: 42, loss: 0.395475
global_step: 5668, epoch: 42, loss: 0.394638
global_step: 5669, epoch: 42, loss: 0.363620
global_step: 5670, epoch: 42, loss: 0.419327
global_step: 5671, epoch: 42, loss: 0.341184
global_step: 5672, epoch: 42, loss: 0.535725
global_step: 5673, epoch: 42, loss: 0.480278
global_step: 5674, epoch: 42, loss: 0.345680
global_step: 5675, epoch: 42, loss: 0.350685
global_step: 5676, epoch: 42, loss: 0.421006
global_step: 5677, epoch: 42, loss: 0.460396
global_step: 5678, epoch: 42, loss: 0.431951
global_step: 5679, epoch: 42, loss: 0.312206
global_step: 5680, epoch: 42, loss: 0.315172
epoch: 42
train	acc: 0.9563	macro: p 0.9624, r 0.9339, f1: 0.9474	micro: p 0.9563, r 0.9563, f1 0.9563	weighted_f1:0.9562
dev	acc: 0.5275	macro: p 0.3745, r 0.3136, f1: 0.3197	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4805
test	acc: 0.5770	macro: p 0.3556, r 0.3066, f1: 0.3136	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5337
global_step: 5681, epoch: 43, loss: 0.405021
global_step: 5682, epoch: 43, loss: 0.338764
global_step: 5683, epoch: 43, loss: 0.363531
global_step: 5684, epoch: 43, loss: 0.458749
global_step: 5685, epoch: 43, loss: 0.361880
global_step: 5686, epoch: 43, loss: 0.339828
global_step: 5687, epoch: 43, loss: 0.321862
global_step: 5688, epoch: 43, loss: 0.302591
global_step: 5689, epoch: 43, loss: 0.392554
global_step: 5690, epoch: 43, loss: 0.430592
global_step: 5691, epoch: 43, loss: 0.332077
global_step: 5692, epoch: 43, loss: 0.395310
global_step: 5693, epoch: 43, loss: 0.265201
global_step: 5694, epoch: 43, loss: 0.466648
global_step: 5695, epoch: 43, loss: 0.257676
global_step: 5696, epoch: 43, loss: 0.362898
global_step: 5697, epoch: 43, loss: 0.290522
global_step: 5698, epoch: 43, loss: 0.296577
global_step: 5699, epoch: 43, loss: 0.312781
global_step: 5700, epoch: 43, loss: 0.273409
global_step: 5701, epoch: 43, loss: 0.386705
global_step: 5702, epoch: 43, loss: 0.348783
global_step: 5703, epoch: 43, loss: 0.375521
global_step: 5704, epoch: 43, loss: 0.356970
global_step: 5705, epoch: 43, loss: 0.311191
global_step: 5706, epoch: 43, loss: 0.373240
global_step: 5707, epoch: 43, loss: 0.400454
global_step: 5708, epoch: 43, loss: 0.293048
global_step: 5709, epoch: 43, loss: 0.289168
global_step: 5710, epoch: 43, loss: 0.354752
global_step: 5711, epoch: 43, loss: 0.258318
global_step: 5712, epoch: 43, loss: 0.334346
global_step: 5713, epoch: 43, loss: 0.272401
global_step: 5714, epoch: 43, loss: 0.416797
global_step: 5715, epoch: 43, loss: 0.302424
global_step: 5716, epoch: 43, loss: 0.368231
global_step: 5717, epoch: 43, loss: 0.351468
global_step: 5718, epoch: 43, loss: 0.353348
global_step: 5719, epoch: 43, loss: 0.402658
global_step: 5720, epoch: 43, loss: 0.177597
epoch: 43
train	acc: 0.9568	macro: p 0.9577, r 0.9428, f1: 0.9497	micro: p 0.9568, r 0.9568, f1 0.9568	weighted_f1:0.9568
dev	acc: 0.5122	macro: p 0.3696, r 0.3168, f1: 0.3195	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4817
test	acc: 0.5448	macro: p 0.3527, r 0.3185, f1: 0.3218	micro: p 0.5448, r 0.5448, f1 0.5448	weighted_f1:0.5271
global_step: 5721, epoch: 44, loss: 0.345253
global_step: 5722, epoch: 44, loss: 0.296363
global_step: 5723, epoch: 44, loss: 0.357501
global_step: 5724, epoch: 44, loss: 0.441259
global_step: 5725, epoch: 44, loss: 0.455221
global_step: 5726, epoch: 44, loss: 0.305102
global_step: 5727, epoch: 44, loss: 0.332108
global_step: 5728, epoch: 44, loss: 0.258914
global_step: 5729, epoch: 44, loss: 0.324303
global_step: 5730, epoch: 44, loss: 0.338510
global_step: 5731, epoch: 44, loss: 0.451913
global_step: 5732, epoch: 44, loss: 0.449506
global_step: 5733, epoch: 44, loss: 0.345235
global_step: 5734, epoch: 44, loss: 0.400105
global_step: 5735, epoch: 44, loss: 0.370281
global_step: 5736, epoch: 44, loss: 0.369021
global_step: 5737, epoch: 44, loss: 0.406775
global_step: 5738, epoch: 44, loss: 0.406251
global_step: 5739, epoch: 44, loss: 0.271629
global_step: 5740, epoch: 44, loss: 0.231426
global_step: 5741, epoch: 44, loss: 0.460713
global_step: 5742, epoch: 44, loss: 0.353631
global_step: 5743, epoch: 44, loss: 0.395235
global_step: 5744, epoch: 44, loss: 0.399521
global_step: 5745, epoch: 44, loss: 0.324303
global_step: 5746, epoch: 44, loss: 0.334971
global_step: 5747, epoch: 44, loss: 0.425387
global_step: 5748, epoch: 44, loss: 0.408760
global_step: 5749, epoch: 44, loss: 0.364419
global_step: 5750, epoch: 44, loss: 0.352039
global_step: 5751, epoch: 44, loss: 0.356205
global_step: 5752, epoch: 44, loss: 0.377963
global_step: 5753, epoch: 44, loss: 0.427504
global_step: 5754, epoch: 44, loss: 0.420658
global_step: 5755, epoch: 44, loss: 0.376440
global_step: 5756, epoch: 44, loss: 0.290655
global_step: 5757, epoch: 44, loss: 0.373745
global_step: 5758, epoch: 44, loss: 0.320967
global_step: 5759, epoch: 44, loss: 0.431541
global_step: 5760, epoch: 44, loss: 0.123874
epoch: 44
train	acc: 0.9554	macro: p 0.9593, r 0.9395, f1: 0.9484	micro: p 0.9554, r 0.9554, f1 0.9554	weighted_f1:0.9556
dev	acc: 0.5248	macro: p 0.3920, r 0.3219, f1: 0.3274	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4876
test	acc: 0.5755	macro: p 0.3608, r 0.3207, f1: 0.3223	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5431
global_step: 5761, epoch: 45, loss: 0.295356
global_step: 5762, epoch: 45, loss: 0.288291
global_step: 5763, epoch: 45, loss: 0.364285
global_step: 5764, epoch: 45, loss: 0.353910
global_step: 5765, epoch: 45, loss: 0.326120
global_step: 5766, epoch: 45, loss: 0.325120
global_step: 5767, epoch: 45, loss: 0.276992
global_step: 5768, epoch: 45, loss: 0.331738
global_step: 5769, epoch: 45, loss: 0.411602
global_step: 5770, epoch: 45, loss: 0.403973
global_step: 5771, epoch: 45, loss: 0.238145
global_step: 5772, epoch: 45, loss: 0.390597
global_step: 5773, epoch: 45, loss: 0.368240
global_step: 5774, epoch: 45, loss: 0.320027
global_step: 5775, epoch: 45, loss: 0.277969
global_step: 5776, epoch: 45, loss: 0.416606
global_step: 5777, epoch: 45, loss: 0.248315
global_step: 5778, epoch: 45, loss: 0.262628
global_step: 5779, epoch: 45, loss: 0.270511
global_step: 5780, epoch: 45, loss: 0.377376
global_step: 5781, epoch: 45, loss: 0.355107
global_step: 5782, epoch: 45, loss: 0.368090
global_step: 5783, epoch: 45, loss: 0.337774
global_step: 5784, epoch: 45, loss: 0.323065
global_step: 5785, epoch: 45, loss: 0.394140
global_step: 5786, epoch: 45, loss: 0.342649
global_step: 5787, epoch: 45, loss: 0.367631
global_step: 5788, epoch: 45, loss: 0.265184
global_step: 5789, epoch: 45, loss: 0.309111
global_step: 5790, epoch: 45, loss: 0.346133
global_step: 5791, epoch: 45, loss: 0.333789
global_step: 5792, epoch: 45, loss: 0.369069
global_step: 5793, epoch: 45, loss: 0.378905
global_step: 5794, epoch: 45, loss: 0.346280
global_step: 5795, epoch: 45, loss: 0.304373
global_step: 5796, epoch: 45, loss: 0.399398
global_step: 5797, epoch: 45, loss: 0.371139
global_step: 5798, epoch: 45, loss: 0.401182
global_step: 5799, epoch: 45, loss: 0.355305
global_step: 5800, epoch: 45, loss: 0.069773
epoch: 45
train	acc: 0.9590	macro: p 0.9586, r 0.9473, f1: 0.9526	micro: p 0.9590, r 0.9590, f1 0.9590	weighted_f1:0.9591
dev	acc: 0.5113	macro: p 0.3684, r 0.3311, f1: 0.3362	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4868
test	acc: 0.5433	macro: p 0.3294, r 0.3168, f1: 0.3162	micro: p 0.5433, r 0.5433, f1 0.5433	weighted_f1:0.5273
global_step: 5801, epoch: 46, loss: 0.336169
global_step: 5802, epoch: 46, loss: 0.330147
global_step: 5803, epoch: 46, loss: 0.295443
global_step: 5804, epoch: 46, loss: 0.316704
global_step: 5805, epoch: 46, loss: 0.362950
global_step: 5806, epoch: 46, loss: 0.300652
global_step: 5807, epoch: 46, loss: 0.312067
global_step: 5808, epoch: 46, loss: 0.415807
global_step: 5809, epoch: 46, loss: 0.308119
global_step: 5810, epoch: 46, loss: 0.287400
global_step: 5811, epoch: 46, loss: 0.343920
global_step: 5812, epoch: 46, loss: 0.280934
global_step: 5813, epoch: 46, loss: 0.306266
global_step: 5814, epoch: 46, loss: 0.333256
global_step: 5815, epoch: 46, loss: 0.324211
global_step: 5816, epoch: 46, loss: 0.308211
global_step: 5817, epoch: 46, loss: 0.353776
global_step: 5818, epoch: 46, loss: 0.401811
global_step: 5819, epoch: 46, loss: 0.339647
global_step: 5820, epoch: 46, loss: 0.366710
global_step: 5821, epoch: 46, loss: 0.326364
global_step: 5822, epoch: 46, loss: 0.390302
global_step: 5823, epoch: 46, loss: 0.313036
global_step: 5824, epoch: 46, loss: 0.365324
global_step: 5825, epoch: 46, loss: 0.341155
global_step: 5826, epoch: 46, loss: 0.423108
global_step: 5827, epoch: 46, loss: 0.336841
global_step: 5828, epoch: 46, loss: 0.344310
global_step: 5829, epoch: 46, loss: 0.422675
global_step: 5830, epoch: 46, loss: 0.364455
global_step: 5831, epoch: 46, loss: 0.419096
global_step: 5832, epoch: 46, loss: 0.329074
global_step: 5833, epoch: 46, loss: 0.341109
global_step: 5834, epoch: 46, loss: 0.398576
global_step: 5835, epoch: 46, loss: 0.333741
global_step: 5836, epoch: 46, loss: 0.305676
global_step: 5837, epoch: 46, loss: 0.312954
global_step: 5838, epoch: 46, loss: 0.289164
global_step: 5839, epoch: 46, loss: 0.326443
global_step: 5840, epoch: 46, loss: 0.009058
epoch: 46
train	acc: 0.9615	macro: p 0.9644, r 0.9471, f1: 0.9554	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9615
dev	acc: 0.4950	macro: p 0.3483, r 0.2954, f1: 0.3003	micro: p 0.4950, r 0.4950, f1 0.4950	weighted_f1:0.4658
test	acc: 0.5670	macro: p 0.3712, r 0.3271, f1: 0.3359	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5461
global_step: 5841, epoch: 47, loss: 0.267363
global_step: 5842, epoch: 47, loss: 0.258663
global_step: 5843, epoch: 47, loss: 0.335538
global_step: 5844, epoch: 47, loss: 0.375720
global_step: 5845, epoch: 47, loss: 0.252959
global_step: 5846, epoch: 47, loss: 0.378016
global_step: 5847, epoch: 47, loss: 0.424811
global_step: 5848, epoch: 47, loss: 0.381688
global_step: 5849, epoch: 47, loss: 0.274975
global_step: 5850, epoch: 47, loss: 0.229533
global_step: 5851, epoch: 47, loss: 0.343325
global_step: 5852, epoch: 47, loss: 0.281044
global_step: 5853, epoch: 47, loss: 0.304611
global_step: 5854, epoch: 47, loss: 0.336890
global_step: 5855, epoch: 47, loss: 0.337584
global_step: 5856, epoch: 47, loss: 0.373894
global_step: 5857, epoch: 47, loss: 0.356653
global_step: 5858, epoch: 47, loss: 0.257048
global_step: 5859, epoch: 47, loss: 0.416551
global_step: 5860, epoch: 47, loss: 0.348994
global_step: 5861, epoch: 47, loss: 0.321632
global_step: 5862, epoch: 47, loss: 0.340656
global_step: 5863, epoch: 47, loss: 0.367769
global_step: 5864, epoch: 47, loss: 0.360015
global_step: 5865, epoch: 47, loss: 0.361977
global_step: 5866, epoch: 47, loss: 0.333327
global_step: 5867, epoch: 47, loss: 0.366770
global_step: 5868, epoch: 47, loss: 0.389237
global_step: 5869, epoch: 47, loss: 0.331197
global_step: 5870, epoch: 47, loss: 0.269369
global_step: 5871, epoch: 47, loss: 0.288528
global_step: 5872, epoch: 47, loss: 0.306554
global_step: 5873, epoch: 47, loss: 0.311053
global_step: 5874, epoch: 47, loss: 0.374280
global_step: 5875, epoch: 47, loss: 0.277088
global_step: 5876, epoch: 47, loss: 0.326627
global_step: 5877, epoch: 47, loss: 0.419863
global_step: 5878, epoch: 47, loss: 0.448493
global_step: 5879, epoch: 47, loss: 0.327358
global_step: 5880, epoch: 47, loss: 0.131340
epoch: 47
train	acc: 0.9615	macro: p 0.9634, r 0.9453, f1: 0.9540	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9615
dev	acc: 0.5068	macro: p 0.3630, r 0.2951, f1: 0.2996	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4585
test	acc: 0.5805	macro: p 0.3835, r 0.3093, f1: 0.3177	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5375
global_step: 5881, epoch: 48, loss: 0.379000
global_step: 5882, epoch: 48, loss: 0.297115
global_step: 5883, epoch: 48, loss: 0.422934
global_step: 5884, epoch: 48, loss: 0.308636
global_step: 5885, epoch: 48, loss: 0.362751
global_step: 5886, epoch: 48, loss: 0.277442
global_step: 5887, epoch: 48, loss: 0.268976
global_step: 5888, epoch: 48, loss: 0.344938
global_step: 5889, epoch: 48, loss: 0.305681
global_step: 5890, epoch: 48, loss: 0.317161
global_step: 5891, epoch: 48, loss: 0.361743
global_step: 5892, epoch: 48, loss: 0.238059
global_step: 5893, epoch: 48, loss: 0.296733
global_step: 5894, epoch: 48, loss: 0.312853
global_step: 5895, epoch: 48, loss: 0.383321
global_step: 5896, epoch: 48, loss: 0.347680
global_step: 5897, epoch: 48, loss: 0.276296
global_step: 5898, epoch: 48, loss: 0.344899
global_step: 5899, epoch: 48, loss: 0.300622
global_step: 5900, epoch: 48, loss: 0.320613
global_step: 5901, epoch: 48, loss: 0.321208
global_step: 5902, epoch: 48, loss: 0.330476
global_step: 5903, epoch: 48, loss: 0.311906
global_step: 5904, epoch: 48, loss: 0.285507
global_step: 5905, epoch: 48, loss: 0.281974
global_step: 5906, epoch: 48, loss: 0.299448
global_step: 5907, epoch: 48, loss: 0.354925
global_step: 5908, epoch: 48, loss: 0.286190
global_step: 5909, epoch: 48, loss: 0.347103
global_step: 5910, epoch: 48, loss: 0.336542
global_step: 5911, epoch: 48, loss: 0.323728
global_step: 5912, epoch: 48, loss: 0.426203
global_step: 5913, epoch: 48, loss: 0.306013
global_step: 5914, epoch: 48, loss: 0.426384
global_step: 5915, epoch: 48, loss: 0.265212
global_step: 5916, epoch: 48, loss: 0.318341
global_step: 5917, epoch: 48, loss: 0.344019
global_step: 5918, epoch: 48, loss: 0.361891
global_step: 5919, epoch: 48, loss: 0.347435
global_step: 5920, epoch: 48, loss: 0.095636
epoch: 48
train	acc: 0.9580	macro: p 0.9622, r 0.9405, f1: 0.9506	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9581
dev	acc: 0.5032	macro: p 0.3522, r 0.3070, f1: 0.3064	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.4723
test	acc: 0.5513	macro: p 0.3711, r 0.3145, f1: 0.3142	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5288
global_step: 5921, epoch: 49, loss: 0.362613
global_step: 5922, epoch: 49, loss: 0.205889
global_step: 5923, epoch: 49, loss: 0.307409
global_step: 5924, epoch: 49, loss: 0.215831
global_step: 5925, epoch: 49, loss: 0.239870
global_step: 5926, epoch: 49, loss: 0.257841
global_step: 5927, epoch: 49, loss: 0.255727
global_step: 5928, epoch: 49, loss: 0.273562
global_step: 5929, epoch: 49, loss: 0.362979
global_step: 5930, epoch: 49, loss: 0.326075
global_step: 5931, epoch: 49, loss: 0.312739
global_step: 5932, epoch: 49, loss: 0.342322
global_step: 5933, epoch: 49, loss: 0.364451
global_step: 5934, epoch: 49, loss: 0.325842
global_step: 5935, epoch: 49, loss: 0.334008
global_step: 5936, epoch: 49, loss: 0.433616
global_step: 5937, epoch: 49, loss: 0.363048
global_step: 5938, epoch: 49, loss: 0.356375
global_step: 5939, epoch: 49, loss: 0.268628
global_step: 5940, epoch: 49, loss: 0.299406
global_step: 5941, epoch: 49, loss: 0.387226
global_step: 5942, epoch: 49, loss: 0.257015
global_step: 5943, epoch: 49, loss: 0.318524
global_step: 5944, epoch: 49, loss: 0.287384
global_step: 5945, epoch: 49, loss: 0.300467
global_step: 5946, epoch: 49, loss: 0.370056
global_step: 5947, epoch: 49, loss: 0.423525
global_step: 5948, epoch: 49, loss: 0.328477
global_step: 5949, epoch: 49, loss: 0.297279
global_step: 5950, epoch: 49, loss: 0.428083
global_step: 5951, epoch: 49, loss: 0.379114
global_step: 5952, epoch: 49, loss: 0.325223
global_step: 5953, epoch: 49, loss: 0.254612
global_step: 5954, epoch: 49, loss: 0.463850
global_step: 5955, epoch: 49, loss: 0.355223
global_step: 5956, epoch: 49, loss: 0.307762
global_step: 5957, epoch: 49, loss: 0.267556
global_step: 5958, epoch: 49, loss: 0.247412
global_step: 5959, epoch: 49, loss: 0.469198
global_step: 5960, epoch: 49, loss: 0.003980
epoch: 49
train	acc: 0.9633	macro: p 0.9645, r 0.9491, f1: 0.9563	micro: p 0.9633, r 0.9633, f1 0.9633	weighted_f1:0.9633
dev	acc: 0.5158	macro: p 0.3879, r 0.3223, f1: 0.3282	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4788
test	acc: 0.5705	macro: p 0.3737, r 0.3269, f1: 0.3337	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5414
global_step: 5961, epoch: 50, loss: 0.331671
global_step: 5962, epoch: 50, loss: 0.316501
global_step: 5963, epoch: 50, loss: 0.283831
global_step: 5964, epoch: 50, loss: 0.290760
global_step: 5965, epoch: 50, loss: 0.269286
global_step: 5966, epoch: 50, loss: 0.322020
global_step: 5967, epoch: 50, loss: 0.315796
global_step: 5968, epoch: 50, loss: 0.263316
global_step: 5969, epoch: 50, loss: 0.266384
global_step: 5970, epoch: 50, loss: 0.316528
global_step: 5971, epoch: 50, loss: 0.268949
global_step: 5972, epoch: 50, loss: 0.319917
global_step: 5973, epoch: 50, loss: 0.398088
global_step: 5974, epoch: 50, loss: 0.347699
global_step: 5975, epoch: 50, loss: 0.332661
global_step: 5976, epoch: 50, loss: 0.294282
global_step: 5977, epoch: 50, loss: 0.342856
global_step: 5978, epoch: 50, loss: 0.332270
global_step: 5979, epoch: 50, loss: 0.307943
global_step: 5980, epoch: 50, loss: 0.331101
global_step: 5981, epoch: 50, loss: 0.365432
global_step: 5982, epoch: 50, loss: 0.300827
global_step: 5983, epoch: 50, loss: 0.361066
global_step: 5984, epoch: 50, loss: 0.326283
global_step: 5985, epoch: 50, loss: 0.370043
global_step: 5986, epoch: 50, loss: 0.254720
global_step: 5987, epoch: 50, loss: 0.287626
global_step: 5988, epoch: 50, loss: 0.332022
global_step: 5989, epoch: 50, loss: 0.364991
global_step: 5990, epoch: 50, loss: 0.349622
global_step: 5991, epoch: 50, loss: 0.287911
global_step: 5992, epoch: 50, loss: 0.402972
global_step: 5993, epoch: 50, loss: 0.382623
global_step: 5994, epoch: 50, loss: 0.237687
global_step: 5995, epoch: 50, loss: 0.299485
global_step: 5996, epoch: 50, loss: 0.327409
global_step: 5997, epoch: 50, loss: 0.335715
global_step: 5998, epoch: 50, loss: 0.219241
global_step: 5999, epoch: 50, loss: 0.288431
global_step: 6000, epoch: 50, loss: 0.007250
epoch: 50
train	acc: 0.9633	macro: p 0.9654, r 0.9462, f1: 0.9554	micro: p 0.9633, r 0.9633, f1 0.9633	weighted_f1:0.9633
dev	acc: 0.5077	macro: p 0.3660, r 0.3023, f1: 0.3037	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4656
test	acc: 0.5755	macro: p 0.3909, r 0.3169, f1: 0.3251	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5405
BEST MODEL epoch: 10
train	acc: 0.7259 macro_p: 0.6374 macro_r: 0.4497 macro_f1: 0.4539 micro_p: 0.7259 micro_r: 0.7259 micro_f1: 0.7259 weighted_f1: 0.6856
dev	acc: 0.5555 macro_p: 0.4086 macro_r: 0.3044 macro_f1: 0.2989 micro_p: 0.5555 micro_r: 0.5555 micro_f1: 0.5555 weighted_f1: 0.4969
test	acc: 0.6050 macro_p: 0.5562 macro_r: 0.3171 macro_f1: 0.3184 micro_p: 0.6050 micro_r: 0.6050 micro_f1: 0.6050 weighted_f1: 0.5536
==========ROUND 4==========
global_step: 6001, epoch: 1, loss: 2.029124
global_step: 6002, epoch: 1, loss: 1.669115
global_step: 6003, epoch: 1, loss: 1.663795
global_step: 6004, epoch: 1, loss: 1.581805
global_step: 6005, epoch: 1, loss: 1.623866
global_step: 6006, epoch: 1, loss: 1.598609
global_step: 6007, epoch: 1, loss: 1.507103
global_step: 6008, epoch: 1, loss: 1.519221
global_step: 6009, epoch: 1, loss: 1.478460
global_step: 6010, epoch: 1, loss: 1.519953
global_step: 6011, epoch: 1, loss: 1.515951
global_step: 6012, epoch: 1, loss: 1.474062
global_step: 6013, epoch: 1, loss: 1.435400
global_step: 6014, epoch: 1, loss: 1.458394
global_step: 6015, epoch: 1, loss: 1.435311
global_step: 6016, epoch: 1, loss: 1.426159
global_step: 6017, epoch: 1, loss: 1.442901
global_step: 6018, epoch: 1, loss: 1.422240
global_step: 6019, epoch: 1, loss: 1.443747
global_step: 6020, epoch: 1, loss: 1.466199
global_step: 6021, epoch: 1, loss: 1.413747
global_step: 6022, epoch: 1, loss: 1.404349
global_step: 6023, epoch: 1, loss: 1.412406
global_step: 6024, epoch: 1, loss: 1.456384
global_step: 6025, epoch: 1, loss: 1.454224
global_step: 6026, epoch: 1, loss: 1.305156
global_step: 6027, epoch: 1, loss: 1.340109
global_step: 6028, epoch: 1, loss: 1.360223
global_step: 6029, epoch: 1, loss: 1.328938
global_step: 6030, epoch: 1, loss: 1.375503
global_step: 6031, epoch: 1, loss: 1.375677
global_step: 6032, epoch: 1, loss: 1.302364
global_step: 6033, epoch: 1, loss: 1.299964
global_step: 6034, epoch: 1, loss: 1.384763
global_step: 6035, epoch: 1, loss: 1.451920
global_step: 6036, epoch: 1, loss: 1.454759
global_step: 6037, epoch: 1, loss: 1.479079
global_step: 6038, epoch: 1, loss: 1.427701
global_step: 6039, epoch: 1, loss: 1.342424
global_step: 6040, epoch: 1, loss: 1.436857
epoch: 1
train	acc: 0.5485	macro: p 0.3061, r 0.2252, f1: 0.2113	micro: p 0.5485, r 0.5485, f1 0.5485	weighted_f1:0.4500
dev	acc: 0.4842	macro: p 0.2822, r 0.2179, f1: 0.1929	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.3779
test	acc: 0.5460	macro: p 0.3065, r 0.2240, f1: 0.2051	micro: p 0.5460, r 0.5460, f1 0.5460	weighted_f1:0.4423
New best model!
global_step: 6041, epoch: 2, loss: 1.454574
global_step: 6042, epoch: 2, loss: 1.477764
global_step: 6043, epoch: 2, loss: 1.348426
global_step: 6044, epoch: 2, loss: 1.386725
global_step: 6045, epoch: 2, loss: 1.302663
global_step: 6046, epoch: 2, loss: 1.252434
global_step: 6047, epoch: 2, loss: 1.358934
global_step: 6048, epoch: 2, loss: 1.347972
global_step: 6049, epoch: 2, loss: 1.372937
global_step: 6050, epoch: 2, loss: 1.257059
global_step: 6051, epoch: 2, loss: 1.150075
global_step: 6052, epoch: 2, loss: 1.306764
global_step: 6053, epoch: 2, loss: 1.248547
global_step: 6054, epoch: 2, loss: 1.451047
global_step: 6055, epoch: 2, loss: 1.344948
global_step: 6056, epoch: 2, loss: 1.431633
global_step: 6057, epoch: 2, loss: 1.450361
global_step: 6058, epoch: 2, loss: 1.365712
global_step: 6059, epoch: 2, loss: 1.336882
global_step: 6060, epoch: 2, loss: 1.297427
global_step: 6061, epoch: 2, loss: 1.388802
global_step: 6062, epoch: 2, loss: 1.160653
global_step: 6063, epoch: 2, loss: 1.306250
global_step: 6064, epoch: 2, loss: 1.281061
global_step: 6065, epoch: 2, loss: 1.294294
global_step: 6066, epoch: 2, loss: 1.378860
global_step: 6067, epoch: 2, loss: 1.276327
global_step: 6068, epoch: 2, loss: 1.281752
global_step: 6069, epoch: 2, loss: 1.236655
global_step: 6070, epoch: 2, loss: 1.432911
global_step: 6071, epoch: 2, loss: 1.317441
global_step: 6072, epoch: 2, loss: 1.348878
global_step: 6073, epoch: 2, loss: 1.363654
global_step: 6074, epoch: 2, loss: 1.349920
global_step: 6075, epoch: 2, loss: 1.325563
global_step: 6076, epoch: 2, loss: 1.361407
global_step: 6077, epoch: 2, loss: 1.327712
global_step: 6078, epoch: 2, loss: 1.251814
global_step: 6079, epoch: 2, loss: 1.282862
global_step: 6080, epoch: 2, loss: 1.673375
epoch: 2
train	acc: 0.5653	macro: p 0.3376, r 0.2862, f1: 0.2706	micro: p 0.5653, r 0.5653, f1 0.5653	weighted_f1:0.5019
dev	acc: 0.5185	macro: p 0.2974, r 0.2720, f1: 0.2434	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4381
test	acc: 0.5544	macro: p 0.3142, r 0.2752, f1: 0.2551	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.4913
New best model!
global_step: 6081, epoch: 3, loss: 1.312210
global_step: 6082, epoch: 3, loss: 1.314077
global_step: 6083, epoch: 3, loss: 1.283771
global_step: 6084, epoch: 3, loss: 1.230885
global_step: 6085, epoch: 3, loss: 1.268226
global_step: 6086, epoch: 3, loss: 1.245469
global_step: 6087, epoch: 3, loss: 1.307108
global_step: 6088, epoch: 3, loss: 1.317715
global_step: 6089, epoch: 3, loss: 1.284001
global_step: 6090, epoch: 3, loss: 1.197413
global_step: 6091, epoch: 3, loss: 1.241779
global_step: 6092, epoch: 3, loss: 1.357463
global_step: 6093, epoch: 3, loss: 1.457175
global_step: 6094, epoch: 3, loss: 1.174772
global_step: 6095, epoch: 3, loss: 1.314291
global_step: 6096, epoch: 3, loss: 1.145059
global_step: 6097, epoch: 3, loss: 1.272165
global_step: 6098, epoch: 3, loss: 1.227725
global_step: 6099, epoch: 3, loss: 1.252903
global_step: 6100, epoch: 3, loss: 1.247050
global_step: 6101, epoch: 3, loss: 1.180617
global_step: 6102, epoch: 3, loss: 1.379326
global_step: 6103, epoch: 3, loss: 1.278141
global_step: 6104, epoch: 3, loss: 1.126687
global_step: 6105, epoch: 3, loss: 1.102054
global_step: 6106, epoch: 3, loss: 1.327950
global_step: 6107, epoch: 3, loss: 1.349357
global_step: 6108, epoch: 3, loss: 1.259075
global_step: 6109, epoch: 3, loss: 1.371863
global_step: 6110, epoch: 3, loss: 1.348798
global_step: 6111, epoch: 3, loss: 1.236136
global_step: 6112, epoch: 3, loss: 1.226079
global_step: 6113, epoch: 3, loss: 1.254324
global_step: 6114, epoch: 3, loss: 1.244583
global_step: 6115, epoch: 3, loss: 1.350177
global_step: 6116, epoch: 3, loss: 1.310894
global_step: 6117, epoch: 3, loss: 1.369223
global_step: 6118, epoch: 3, loss: 1.274829
global_step: 6119, epoch: 3, loss: 1.150849
global_step: 6120, epoch: 3, loss: 0.681472
epoch: 3
train	acc: 0.5708	macro: p 0.3324, r 0.2506, f1: 0.2368	micro: p 0.5708, r 0.5708, f1 0.5708	weighted_f1:0.4784
dev	acc: 0.5050	macro: p 0.3432, r 0.2377, f1: 0.2106	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4002
test	acc: 0.5636	macro: p 0.3065, r 0.2475, f1: 0.2277	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.4653
global_step: 6121, epoch: 4, loss: 1.516433
global_step: 6122, epoch: 4, loss: 1.336116
global_step: 6123, epoch: 4, loss: 1.240979
global_step: 6124, epoch: 4, loss: 1.222795
global_step: 6125, epoch: 4, loss: 1.157269
global_step: 6126, epoch: 4, loss: 1.205228
global_step: 6127, epoch: 4, loss: 1.406373
global_step: 6128, epoch: 4, loss: 1.262977
global_step: 6129, epoch: 4, loss: 1.125167
global_step: 6130, epoch: 4, loss: 1.161507
global_step: 6131, epoch: 4, loss: 1.093922
global_step: 6132, epoch: 4, loss: 1.186311
global_step: 6133, epoch: 4, loss: 1.184131
global_step: 6134, epoch: 4, loss: 1.252584
global_step: 6135, epoch: 4, loss: 1.275170
global_step: 6136, epoch: 4, loss: 1.161552
global_step: 6137, epoch: 4, loss: 1.241286
global_step: 6138, epoch: 4, loss: 1.238922
global_step: 6139, epoch: 4, loss: 1.182684
global_step: 6140, epoch: 4, loss: 1.209833
global_step: 6141, epoch: 4, loss: 1.165928
global_step: 6142, epoch: 4, loss: 1.260311
global_step: 6143, epoch: 4, loss: 1.309075
global_step: 6144, epoch: 4, loss: 1.135556
global_step: 6145, epoch: 4, loss: 1.242821
global_step: 6146, epoch: 4, loss: 1.199168
global_step: 6147, epoch: 4, loss: 1.100135
global_step: 6148, epoch: 4, loss: 1.100449
global_step: 6149, epoch: 4, loss: 1.338983
global_step: 6150, epoch: 4, loss: 1.287324
global_step: 6151, epoch: 4, loss: 1.328225
global_step: 6152, epoch: 4, loss: 1.231065
global_step: 6153, epoch: 4, loss: 1.258234
global_step: 6154, epoch: 4, loss: 1.148505
global_step: 6155, epoch: 4, loss: 1.268427
global_step: 6156, epoch: 4, loss: 1.261399
global_step: 6157, epoch: 4, loss: 1.404614
global_step: 6158, epoch: 4, loss: 1.195742
global_step: 6159, epoch: 4, loss: 1.226370
global_step: 6160, epoch: 4, loss: 0.932574
epoch: 4
train	acc: 0.6104	macro: p 0.4422, r 0.3107, f1: 0.3258	micro: p 0.6104, r 0.6104, f1 0.6104	weighted_f1:0.5526
dev	acc: 0.5356	macro: p 0.3697, r 0.2707, f1: 0.2668	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4614
test	acc: 0.5954	macro: p 0.3877, r 0.2855, f1: 0.2943	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5317
New best model!
global_step: 6161, epoch: 5, loss: 1.287103
global_step: 6162, epoch: 5, loss: 1.288695
global_step: 6163, epoch: 5, loss: 1.182054
global_step: 6164, epoch: 5, loss: 1.145372
global_step: 6165, epoch: 5, loss: 1.172432
global_step: 6166, epoch: 5, loss: 1.131191
global_step: 6167, epoch: 5, loss: 1.233530
global_step: 6168, epoch: 5, loss: 1.112737
global_step: 6169, epoch: 5, loss: 1.094504
global_step: 6170, epoch: 5, loss: 1.227663
global_step: 6171, epoch: 5, loss: 1.221574
global_step: 6172, epoch: 5, loss: 1.061741
global_step: 6173, epoch: 5, loss: 1.167763
global_step: 6174, epoch: 5, loss: 1.115010
global_step: 6175, epoch: 5, loss: 1.222882
global_step: 6176, epoch: 5, loss: 1.132277
global_step: 6177, epoch: 5, loss: 1.113853
global_step: 6178, epoch: 5, loss: 1.158209
global_step: 6179, epoch: 5, loss: 1.193150
global_step: 6180, epoch: 5, loss: 1.252162
global_step: 6181, epoch: 5, loss: 1.203746
global_step: 6182, epoch: 5, loss: 1.134396
global_step: 6183, epoch: 5, loss: 1.170341
global_step: 6184, epoch: 5, loss: 1.183263
global_step: 6185, epoch: 5, loss: 1.193543
global_step: 6186, epoch: 5, loss: 1.009268
global_step: 6187, epoch: 5, loss: 1.217657
global_step: 6188, epoch: 5, loss: 1.180844
global_step: 6189, epoch: 5, loss: 1.181546
global_step: 6190, epoch: 5, loss: 1.105116
global_step: 6191, epoch: 5, loss: 1.180246
global_step: 6192, epoch: 5, loss: 1.151685
global_step: 6193, epoch: 5, loss: 1.212590
global_step: 6194, epoch: 5, loss: 1.263038
global_step: 6195, epoch: 5, loss: 1.163533
global_step: 6196, epoch: 5, loss: 1.199759
global_step: 6197, epoch: 5, loss: 1.207947
global_step: 6198, epoch: 5, loss: 1.188210
global_step: 6199, epoch: 5, loss: 1.237201
global_step: 6200, epoch: 5, loss: 1.644775
epoch: 5
train	acc: 0.6051	macro: p 0.4567, r 0.3110, f1: 0.2999	micro: p 0.6051, r 0.6051, f1 0.6051	weighted_f1:0.5519
dev	acc: 0.4869	macro: p 0.3708, r 0.2564, f1: 0.2248	micro: p 0.4869, r 0.4869, f1 0.4869	weighted_f1:0.4213
test	acc: 0.5456	macro: p 0.4020, r 0.2724, f1: 0.2538	micro: p 0.5456, r 0.5456, f1 0.5456	weighted_f1:0.4954
global_step: 6201, epoch: 6, loss: 1.393267
global_step: 6202, epoch: 6, loss: 1.230108
global_step: 6203, epoch: 6, loss: 1.106450
global_step: 6204, epoch: 6, loss: 1.150572
global_step: 6205, epoch: 6, loss: 1.177242
global_step: 6206, epoch: 6, loss: 1.124762
global_step: 6207, epoch: 6, loss: 1.104420
global_step: 6208, epoch: 6, loss: 1.159818
global_step: 6209, epoch: 6, loss: 1.096085
global_step: 6210, epoch: 6, loss: 1.059782
global_step: 6211, epoch: 6, loss: 0.965513
global_step: 6212, epoch: 6, loss: 1.152833
global_step: 6213, epoch: 6, loss: 1.183063
global_step: 6214, epoch: 6, loss: 1.159688
global_step: 6215, epoch: 6, loss: 1.188672
global_step: 6216, epoch: 6, loss: 1.131859
global_step: 6217, epoch: 6, loss: 1.185628
global_step: 6218, epoch: 6, loss: 1.108613
global_step: 6219, epoch: 6, loss: 1.190135
global_step: 6220, epoch: 6, loss: 1.193337
global_step: 6221, epoch: 6, loss: 1.143831
global_step: 6222, epoch: 6, loss: 1.165847
global_step: 6223, epoch: 6, loss: 1.077965
global_step: 6224, epoch: 6, loss: 1.134475
global_step: 6225, epoch: 6, loss: 1.123600
global_step: 6226, epoch: 6, loss: 1.076860
global_step: 6227, epoch: 6, loss: 1.056447
global_step: 6228, epoch: 6, loss: 1.165590
global_step: 6229, epoch: 6, loss: 1.109145
global_step: 6230, epoch: 6, loss: 1.159246
global_step: 6231, epoch: 6, loss: 1.254843
global_step: 6232, epoch: 6, loss: 0.969579
global_step: 6233, epoch: 6, loss: 1.137695
global_step: 6234, epoch: 6, loss: 1.068636
global_step: 6235, epoch: 6, loss: 1.181389
global_step: 6236, epoch: 6, loss: 1.186892
global_step: 6237, epoch: 6, loss: 1.083869
global_step: 6238, epoch: 6, loss: 1.106867
global_step: 6239, epoch: 6, loss: 1.076288
global_step: 6240, epoch: 6, loss: 0.715375
epoch: 6
train	acc: 0.6554	macro: p 0.4610, r 0.3668, f1: 0.3648	micro: p 0.6554, r 0.6554, f1 0.6554	weighted_f1:0.6045
dev	acc: 0.5302	macro: p 0.3435, r 0.2861, f1: 0.2590	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4547
test	acc: 0.5843	macro: p 0.3659, r 0.3040, f1: 0.2876	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5228
global_step: 6241, epoch: 7, loss: 1.104278
global_step: 6242, epoch: 7, loss: 1.125044
global_step: 6243, epoch: 7, loss: 1.062448
global_step: 6244, epoch: 7, loss: 1.103814
global_step: 6245, epoch: 7, loss: 1.015919
global_step: 6246, epoch: 7, loss: 1.078516
global_step: 6247, epoch: 7, loss: 1.069327
global_step: 6248, epoch: 7, loss: 1.152322
global_step: 6249, epoch: 7, loss: 1.150238
global_step: 6250, epoch: 7, loss: 0.934056
global_step: 6251, epoch: 7, loss: 1.093471
global_step: 6252, epoch: 7, loss: 1.015145
global_step: 6253, epoch: 7, loss: 1.210370
global_step: 6254, epoch: 7, loss: 1.104737
global_step: 6255, epoch: 7, loss: 1.117629
global_step: 6256, epoch: 7, loss: 1.151179
global_step: 6257, epoch: 7, loss: 1.047575
global_step: 6258, epoch: 7, loss: 1.044554
global_step: 6259, epoch: 7, loss: 0.966932
global_step: 6260, epoch: 7, loss: 1.193075
global_step: 6261, epoch: 7, loss: 1.091916
global_step: 6262, epoch: 7, loss: 1.057103
global_step: 6263, epoch: 7, loss: 1.117761
global_step: 6264, epoch: 7, loss: 1.050840
global_step: 6265, epoch: 7, loss: 1.064139
global_step: 6266, epoch: 7, loss: 1.131384
global_step: 6267, epoch: 7, loss: 1.120268
global_step: 6268, epoch: 7, loss: 1.107441
global_step: 6269, epoch: 7, loss: 1.081198
global_step: 6270, epoch: 7, loss: 1.058062
global_step: 6271, epoch: 7, loss: 1.263226
global_step: 6272, epoch: 7, loss: 1.020310
global_step: 6273, epoch: 7, loss: 1.122452
global_step: 6274, epoch: 7, loss: 1.053002
global_step: 6275, epoch: 7, loss: 1.049755
global_step: 6276, epoch: 7, loss: 1.077029
global_step: 6277, epoch: 7, loss: 1.136028
global_step: 6278, epoch: 7, loss: 1.022923
global_step: 6279, epoch: 7, loss: 1.122581
global_step: 6280, epoch: 7, loss: 0.680025
epoch: 7
train	acc: 0.6133	macro: p 0.4723, r 0.3550, f1: 0.3256	micro: p 0.6133, r 0.6133, f1 0.6133	weighted_f1:0.5589
dev	acc: 0.5158	macro: p 0.3921, r 0.2767, f1: 0.2612	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4557
test	acc: 0.5713	macro: p 0.4151, r 0.3023, f1: 0.2821	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5170
global_step: 6281, epoch: 8, loss: 1.339232
global_step: 6282, epoch: 8, loss: 1.058246
global_step: 6283, epoch: 8, loss: 1.016934
global_step: 6284, epoch: 8, loss: 1.011198
global_step: 6285, epoch: 8, loss: 1.059007
global_step: 6286, epoch: 8, loss: 1.023676
global_step: 6287, epoch: 8, loss: 1.008067
global_step: 6288, epoch: 8, loss: 1.032061
global_step: 6289, epoch: 8, loss: 1.140141
global_step: 6290, epoch: 8, loss: 0.943533
global_step: 6291, epoch: 8, loss: 1.158994
global_step: 6292, epoch: 8, loss: 0.983893
global_step: 6293, epoch: 8, loss: 1.028001
global_step: 6294, epoch: 8, loss: 0.986330
global_step: 6295, epoch: 8, loss: 1.036806
global_step: 6296, epoch: 8, loss: 1.088426
global_step: 6297, epoch: 8, loss: 0.993753
global_step: 6298, epoch: 8, loss: 1.003253
global_step: 6299, epoch: 8, loss: 0.945499
global_step: 6300, epoch: 8, loss: 1.097505
global_step: 6301, epoch: 8, loss: 0.949152
global_step: 6302, epoch: 8, loss: 1.089572
global_step: 6303, epoch: 8, loss: 1.123742
global_step: 6304, epoch: 8, loss: 1.159486
global_step: 6305, epoch: 8, loss: 1.172005
global_step: 6306, epoch: 8, loss: 1.090564
global_step: 6307, epoch: 8, loss: 1.094246
global_step: 6308, epoch: 8, loss: 0.980021
global_step: 6309, epoch: 8, loss: 1.042824
global_step: 6310, epoch: 8, loss: 0.939116
global_step: 6311, epoch: 8, loss: 1.069974
global_step: 6312, epoch: 8, loss: 1.025440
global_step: 6313, epoch: 8, loss: 1.103581
global_step: 6314, epoch: 8, loss: 1.100651
global_step: 6315, epoch: 8, loss: 0.995648
global_step: 6316, epoch: 8, loss: 0.993334
global_step: 6317, epoch: 8, loss: 0.978610
global_step: 6318, epoch: 8, loss: 1.198620
global_step: 6319, epoch: 8, loss: 1.114985
global_step: 6320, epoch: 8, loss: 1.359679
epoch: 8
train	acc: 0.6185	macro: p 0.4574, r 0.4248, f1: 0.3832	micro: p 0.6185, r 0.6185, f1 0.6185	weighted_f1:0.6185
dev	acc: 0.4761	macro: p 0.3297, r 0.3049, f1: 0.2818	micro: p 0.4761, r 0.4761, f1 0.4761	weighted_f1:0.4571
test	acc: 0.4966	macro: p 0.3491, r 0.3134, f1: 0.2878	micro: p 0.4966, r 0.4966, f1 0.4966	weighted_f1:0.4960
global_step: 6321, epoch: 9, loss: 1.107652
global_step: 6322, epoch: 9, loss: 1.062265
global_step: 6323, epoch: 9, loss: 1.059845
global_step: 6324, epoch: 9, loss: 1.097247
global_step: 6325, epoch: 9, loss: 1.016241
global_step: 6326, epoch: 9, loss: 0.961122
global_step: 6327, epoch: 9, loss: 0.867128
global_step: 6328, epoch: 9, loss: 0.971119
global_step: 6329, epoch: 9, loss: 0.988298
global_step: 6330, epoch: 9, loss: 0.979444
global_step: 6331, epoch: 9, loss: 0.878919
global_step: 6332, epoch: 9, loss: 1.017233
global_step: 6333, epoch: 9, loss: 0.868360
global_step: 6334, epoch: 9, loss: 0.989032
global_step: 6335, epoch: 9, loss: 0.898454
global_step: 6336, epoch: 9, loss: 0.918980
global_step: 6337, epoch: 9, loss: 0.982016
global_step: 6338, epoch: 9, loss: 0.939580
global_step: 6339, epoch: 9, loss: 1.076926
global_step: 6340, epoch: 9, loss: 1.118081
global_step: 6341, epoch: 9, loss: 1.002520
global_step: 6342, epoch: 9, loss: 1.005744
global_step: 6343, epoch: 9, loss: 1.009195
global_step: 6344, epoch: 9, loss: 1.034577
global_step: 6345, epoch: 9, loss: 1.069305
global_step: 6346, epoch: 9, loss: 0.836999
global_step: 6347, epoch: 9, loss: 1.029535
global_step: 6348, epoch: 9, loss: 1.008479
global_step: 6349, epoch: 9, loss: 0.939910
global_step: 6350, epoch: 9, loss: 0.977705
global_step: 6351, epoch: 9, loss: 1.096921
global_step: 6352, epoch: 9, loss: 0.995030
global_step: 6353, epoch: 9, loss: 1.068159
global_step: 6354, epoch: 9, loss: 1.078411
global_step: 6355, epoch: 9, loss: 1.050245
global_step: 6356, epoch: 9, loss: 1.011179
global_step: 6357, epoch: 9, loss: 0.939004
global_step: 6358, epoch: 9, loss: 1.026619
global_step: 6359, epoch: 9, loss: 0.934244
global_step: 6360, epoch: 9, loss: 0.426522
epoch: 9
train	acc: 0.6841	macro: p 0.5020, r 0.3874, f1: 0.3992	micro: p 0.6841, r 0.6841, f1 0.6841	weighted_f1:0.6374
dev	acc: 0.5338	macro: p 0.3902, r 0.2798, f1: 0.2689	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4639
test	acc: 0.5989	macro: p 0.4036, r 0.2972, f1: 0.2961	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5381
New best model!
global_step: 6361, epoch: 10, loss: 1.058416
global_step: 6362, epoch: 10, loss: 0.973948
global_step: 6363, epoch: 10, loss: 0.886237
global_step: 6364, epoch: 10, loss: 0.904428
global_step: 6365, epoch: 10, loss: 1.052778
global_step: 6366, epoch: 10, loss: 0.964434
global_step: 6367, epoch: 10, loss: 0.928991
global_step: 6368, epoch: 10, loss: 1.074539
global_step: 6369, epoch: 10, loss: 0.964342
global_step: 6370, epoch: 10, loss: 0.837843
global_step: 6371, epoch: 10, loss: 0.854036
global_step: 6372, epoch: 10, loss: 0.941923
global_step: 6373, epoch: 10, loss: 0.913597
global_step: 6374, epoch: 10, loss: 0.931541
global_step: 6375, epoch: 10, loss: 0.896676
global_step: 6376, epoch: 10, loss: 1.048534
global_step: 6377, epoch: 10, loss: 0.939405
global_step: 6378, epoch: 10, loss: 1.098257
global_step: 6379, epoch: 10, loss: 1.014111
global_step: 6380, epoch: 10, loss: 1.175249
global_step: 6381, epoch: 10, loss: 0.955584
global_step: 6382, epoch: 10, loss: 0.831851
global_step: 6383, epoch: 10, loss: 0.964000
global_step: 6384, epoch: 10, loss: 0.956511
global_step: 6385, epoch: 10, loss: 0.962234
global_step: 6386, epoch: 10, loss: 1.110970
global_step: 6387, epoch: 10, loss: 0.935356
global_step: 6388, epoch: 10, loss: 1.023192
global_step: 6389, epoch: 10, loss: 1.064536
global_step: 6390, epoch: 10, loss: 0.927666
global_step: 6391, epoch: 10, loss: 0.824867
global_step: 6392, epoch: 10, loss: 0.853994
global_step: 6393, epoch: 10, loss: 0.933772
global_step: 6394, epoch: 10, loss: 0.983123
global_step: 6395, epoch: 10, loss: 1.016052
global_step: 6396, epoch: 10, loss: 0.989275
global_step: 6397, epoch: 10, loss: 1.077288
global_step: 6398, epoch: 10, loss: 0.860761
global_step: 6399, epoch: 10, loss: 0.831423
global_step: 6400, epoch: 10, loss: 0.732483
epoch: 10
train	acc: 0.6927	macro: p 0.5021, r 0.4193, f1: 0.4043	micro: p 0.6927, r 0.6927, f1 0.6927	weighted_f1:0.6451
dev	acc: 0.5311	macro: p 0.3961, r 0.2961, f1: 0.2840	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4764
test	acc: 0.5897	macro: p 0.4208, r 0.3190, f1: 0.3043	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5417
New best model!
global_step: 6401, epoch: 11, loss: 1.014588
global_step: 6402, epoch: 11, loss: 0.944094
global_step: 6403, epoch: 11, loss: 0.881667
global_step: 6404, epoch: 11, loss: 0.954378
global_step: 6405, epoch: 11, loss: 0.891161
global_step: 6406, epoch: 11, loss: 0.867162
global_step: 6407, epoch: 11, loss: 0.804376
global_step: 6408, epoch: 11, loss: 0.876273
global_step: 6409, epoch: 11, loss: 0.850894
global_step: 6410, epoch: 11, loss: 0.805565
global_step: 6411, epoch: 11, loss: 0.852175
global_step: 6412, epoch: 11, loss: 0.817131
global_step: 6413, epoch: 11, loss: 0.998253
global_step: 6414, epoch: 11, loss: 0.872580
global_step: 6415, epoch: 11, loss: 0.905427
global_step: 6416, epoch: 11, loss: 0.891886
global_step: 6417, epoch: 11, loss: 0.835202
global_step: 6418, epoch: 11, loss: 0.921875
global_step: 6419, epoch: 11, loss: 1.000438
global_step: 6420, epoch: 11, loss: 0.925518
global_step: 6421, epoch: 11, loss: 0.909602
global_step: 6422, epoch: 11, loss: 0.905918
global_step: 6423, epoch: 11, loss: 1.074490
global_step: 6424, epoch: 11, loss: 1.011500
global_step: 6425, epoch: 11, loss: 0.868784
global_step: 6426, epoch: 11, loss: 0.881392
global_step: 6427, epoch: 11, loss: 0.803372
global_step: 6428, epoch: 11, loss: 0.863639
global_step: 6429, epoch: 11, loss: 0.959866
global_step: 6430, epoch: 11, loss: 0.946762
global_step: 6431, epoch: 11, loss: 0.928320
global_step: 6432, epoch: 11, loss: 1.043136
global_step: 6433, epoch: 11, loss: 0.814697
global_step: 6434, epoch: 11, loss: 0.967809
global_step: 6435, epoch: 11, loss: 0.938793
global_step: 6436, epoch: 11, loss: 0.950620
global_step: 6437, epoch: 11, loss: 0.994412
global_step: 6438, epoch: 11, loss: 0.855582
global_step: 6439, epoch: 11, loss: 0.994628
global_step: 6440, epoch: 11, loss: 0.597982
epoch: 11
train	acc: 0.7064	macro: p 0.7728, r 0.4581, f1: 0.4723	micro: p 0.7064, r 0.7064, f1 0.7064	weighted_f1:0.6770
dev	acc: 0.5383	macro: p 0.3445, r 0.2924, f1: 0.2994	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4859
test	acc: 0.5866	macro: p 0.3677, r 0.2984, f1: 0.3125	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5420
New best model!
global_step: 6441, epoch: 12, loss: 1.177434
global_step: 6442, epoch: 12, loss: 0.915637
global_step: 6443, epoch: 12, loss: 0.884317
global_step: 6444, epoch: 12, loss: 0.832768
global_step: 6445, epoch: 12, loss: 0.797434
global_step: 6446, epoch: 12, loss: 0.847101
global_step: 6447, epoch: 12, loss: 0.874784
global_step: 6448, epoch: 12, loss: 0.821433
global_step: 6449, epoch: 12, loss: 0.756382
global_step: 6450, epoch: 12, loss: 0.860691
global_step: 6451, epoch: 12, loss: 0.813025
global_step: 6452, epoch: 12, loss: 0.795405
global_step: 6453, epoch: 12, loss: 0.869487
global_step: 6454, epoch: 12, loss: 0.760742
global_step: 6455, epoch: 12, loss: 0.697962
global_step: 6456, epoch: 12, loss: 0.777212
global_step: 6457, epoch: 12, loss: 0.917727
global_step: 6458, epoch: 12, loss: 0.848009
global_step: 6459, epoch: 12, loss: 0.828159
global_step: 6460, epoch: 12, loss: 0.968105
global_step: 6461, epoch: 12, loss: 0.902874
global_step: 6462, epoch: 12, loss: 0.851586
global_step: 6463, epoch: 12, loss: 0.849548
global_step: 6464, epoch: 12, loss: 0.755104
global_step: 6465, epoch: 12, loss: 0.848183
global_step: 6466, epoch: 12, loss: 0.799496
global_step: 6467, epoch: 12, loss: 0.819482
global_step: 6468, epoch: 12, loss: 0.914472
global_step: 6469, epoch: 12, loss: 0.895168
global_step: 6470, epoch: 12, loss: 0.762908
global_step: 6471, epoch: 12, loss: 1.015507
global_step: 6472, epoch: 12, loss: 0.913107
global_step: 6473, epoch: 12, loss: 0.920671
global_step: 6474, epoch: 12, loss: 0.849861
global_step: 6475, epoch: 12, loss: 0.951604
global_step: 6476, epoch: 12, loss: 0.833332
global_step: 6477, epoch: 12, loss: 1.041563
global_step: 6478, epoch: 12, loss: 0.893958
global_step: 6479, epoch: 12, loss: 0.934775
global_step: 6480, epoch: 12, loss: 1.149363
epoch: 12
train	acc: 0.7473	macro: p 0.7970, r 0.5076, f1: 0.5395	micro: p 0.7473, r 0.7473, f1 0.7473	weighted_f1:0.7225
dev	acc: 0.5248	macro: p 0.3069, r 0.2753, f1: 0.2734	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4629
test	acc: 0.5889	macro: p 0.3437, r 0.2955, f1: 0.3016	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5337
global_step: 6481, epoch: 13, loss: 0.794719
global_step: 6482, epoch: 13, loss: 0.929271
global_step: 6483, epoch: 13, loss: 0.828178
global_step: 6484, epoch: 13, loss: 0.958184
global_step: 6485, epoch: 13, loss: 0.864298
global_step: 6486, epoch: 13, loss: 0.711708
global_step: 6487, epoch: 13, loss: 0.690740
global_step: 6488, epoch: 13, loss: 0.758749
global_step: 6489, epoch: 13, loss: 0.692692
global_step: 6490, epoch: 13, loss: 0.712834
global_step: 6491, epoch: 13, loss: 0.928869
global_step: 6492, epoch: 13, loss: 0.771146
global_step: 6493, epoch: 13, loss: 0.838224
global_step: 6494, epoch: 13, loss: 0.841143
global_step: 6495, epoch: 13, loss: 0.850593
global_step: 6496, epoch: 13, loss: 0.826190
global_step: 6497, epoch: 13, loss: 0.741877
global_step: 6498, epoch: 13, loss: 0.890667
global_step: 6499, epoch: 13, loss: 0.876199
global_step: 6500, epoch: 13, loss: 0.783953
global_step: 6501, epoch: 13, loss: 0.769882
global_step: 6502, epoch: 13, loss: 1.018958
global_step: 6503, epoch: 13, loss: 0.850888
global_step: 6504, epoch: 13, loss: 0.719257
global_step: 6505, epoch: 13, loss: 0.911384
global_step: 6506, epoch: 13, loss: 0.659250
global_step: 6507, epoch: 13, loss: 0.826208
global_step: 6508, epoch: 13, loss: 0.864423
global_step: 6509, epoch: 13, loss: 0.757181
global_step: 6510, epoch: 13, loss: 0.913887
global_step: 6511, epoch: 13, loss: 0.813601
global_step: 6512, epoch: 13, loss: 0.760183
global_step: 6513, epoch: 13, loss: 0.856791
global_step: 6514, epoch: 13, loss: 0.925038
global_step: 6515, epoch: 13, loss: 0.967399
global_step: 6516, epoch: 13, loss: 0.823855
global_step: 6517, epoch: 13, loss: 0.808482
global_step: 6518, epoch: 13, loss: 0.741352
global_step: 6519, epoch: 13, loss: 0.957605
global_step: 6520, epoch: 13, loss: 0.388602
epoch: 13
train	acc: 0.7918	macro: p 0.8335, r 0.5769, f1: 0.6167	micro: p 0.7918, r 0.7918, f1 0.7918	weighted_f1:0.7732
dev	acc: 0.5329	macro: p 0.3813, r 0.2923, f1: 0.2760	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4681
test	acc: 0.5851	macro: p 0.3679, r 0.3027, f1: 0.2938	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5298
global_step: 6521, epoch: 14, loss: 0.615041
global_step: 6522, epoch: 14, loss: 0.833855
global_step: 6523, epoch: 14, loss: 0.821326
global_step: 6524, epoch: 14, loss: 0.718818
global_step: 6525, epoch: 14, loss: 0.759132
global_step: 6526, epoch: 14, loss: 0.782589
global_step: 6527, epoch: 14, loss: 0.745832
global_step: 6528, epoch: 14, loss: 0.771437
global_step: 6529, epoch: 14, loss: 0.808086
global_step: 6530, epoch: 14, loss: 0.731068
global_step: 6531, epoch: 14, loss: 0.784829
global_step: 6532, epoch: 14, loss: 0.736576
global_step: 6533, epoch: 14, loss: 0.823739
global_step: 6534, epoch: 14, loss: 0.784436
global_step: 6535, epoch: 14, loss: 0.693763
global_step: 6536, epoch: 14, loss: 0.628407
global_step: 6537, epoch: 14, loss: 0.838099
global_step: 6538, epoch: 14, loss: 0.774588
global_step: 6539, epoch: 14, loss: 0.690649
global_step: 6540, epoch: 14, loss: 0.770462
global_step: 6541, epoch: 14, loss: 0.744299
global_step: 6542, epoch: 14, loss: 0.934028
global_step: 6543, epoch: 14, loss: 0.779637
global_step: 6544, epoch: 14, loss: 0.715887
global_step: 6545, epoch: 14, loss: 0.776259
global_step: 6546, epoch: 14, loss: 0.741467
global_step: 6547, epoch: 14, loss: 0.788978
global_step: 6548, epoch: 14, loss: 0.799080
global_step: 6549, epoch: 14, loss: 0.805802
global_step: 6550, epoch: 14, loss: 0.785854
global_step: 6551, epoch: 14, loss: 0.847566
global_step: 6552, epoch: 14, loss: 0.787814
global_step: 6553, epoch: 14, loss: 0.761873
global_step: 6554, epoch: 14, loss: 0.793683
global_step: 6555, epoch: 14, loss: 0.852072
global_step: 6556, epoch: 14, loss: 0.860142
global_step: 6557, epoch: 14, loss: 0.764179
global_step: 6558, epoch: 14, loss: 0.811602
global_step: 6559, epoch: 14, loss: 0.862344
global_step: 6560, epoch: 14, loss: 0.723453
epoch: 14
train	acc: 0.7935	macro: p 0.8391, r 0.5540, f1: 0.5711	micro: p 0.7935, r 0.7935, f1 0.7935	weighted_f1:0.7738
dev	acc: 0.5401	macro: p 0.3688, r 0.3063, f1: 0.2983	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4954
test	acc: 0.5789	macro: p 0.4037, r 0.3147, f1: 0.3064	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5427
New best model!
global_step: 6561, epoch: 15, loss: 0.854674
global_step: 6562, epoch: 15, loss: 0.626852
global_step: 6563, epoch: 15, loss: 0.684541
global_step: 6564, epoch: 15, loss: 0.799317
global_step: 6565, epoch: 15, loss: 0.723130
global_step: 6566, epoch: 15, loss: 0.727663
global_step: 6567, epoch: 15, loss: 0.791208
global_step: 6568, epoch: 15, loss: 0.755471
global_step: 6569, epoch: 15, loss: 0.647292
global_step: 6570, epoch: 15, loss: 0.676182
global_step: 6571, epoch: 15, loss: 0.663117
global_step: 6572, epoch: 15, loss: 0.700734
global_step: 6573, epoch: 15, loss: 0.743866
global_step: 6574, epoch: 15, loss: 0.736471
global_step: 6575, epoch: 15, loss: 0.651125
global_step: 6576, epoch: 15, loss: 0.766803
global_step: 6577, epoch: 15, loss: 0.705631
global_step: 6578, epoch: 15, loss: 0.671556
global_step: 6579, epoch: 15, loss: 0.790328
global_step: 6580, epoch: 15, loss: 0.873646
global_step: 6581, epoch: 15, loss: 0.836605
global_step: 6582, epoch: 15, loss: 0.609076
global_step: 6583, epoch: 15, loss: 0.694732
global_step: 6584, epoch: 15, loss: 0.775613
global_step: 6585, epoch: 15, loss: 0.718937
global_step: 6586, epoch: 15, loss: 0.839454
global_step: 6587, epoch: 15, loss: 0.838996
global_step: 6588, epoch: 15, loss: 0.781874
global_step: 6589, epoch: 15, loss: 0.676951
global_step: 6590, epoch: 15, loss: 0.831131
global_step: 6591, epoch: 15, loss: 0.745463
global_step: 6592, epoch: 15, loss: 0.734567
global_step: 6593, epoch: 15, loss: 0.779449
global_step: 6594, epoch: 15, loss: 0.810873
global_step: 6595, epoch: 15, loss: 0.683589
global_step: 6596, epoch: 15, loss: 0.790052
global_step: 6597, epoch: 15, loss: 0.818488
global_step: 6598, epoch: 15, loss: 0.913994
global_step: 6599, epoch: 15, loss: 0.731961
global_step: 6600, epoch: 15, loss: 0.451742
epoch: 15
train	acc: 0.8078	macro: p 0.8732, r 0.6114, f1: 0.6854	micro: p 0.8078, r 0.8078, f1 0.8078	weighted_f1:0.7935
dev	acc: 0.5248	macro: p 0.4361, r 0.2710, f1: 0.2648	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4535
test	acc: 0.5881	macro: p 0.3722, r 0.2850, f1: 0.2866	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5244
global_step: 6601, epoch: 16, loss: 0.742369
global_step: 6602, epoch: 16, loss: 0.611305
global_step: 6603, epoch: 16, loss: 0.734867
global_step: 6604, epoch: 16, loss: 0.731293
global_step: 6605, epoch: 16, loss: 0.728757
global_step: 6606, epoch: 16, loss: 0.694176
global_step: 6607, epoch: 16, loss: 0.783459
global_step: 6608, epoch: 16, loss: 0.705424
global_step: 6609, epoch: 16, loss: 0.668018
global_step: 6610, epoch: 16, loss: 0.564252
global_step: 6611, epoch: 16, loss: 0.754625
global_step: 6612, epoch: 16, loss: 0.731838
global_step: 6613, epoch: 16, loss: 0.824469
global_step: 6614, epoch: 16, loss: 0.686116
global_step: 6615, epoch: 16, loss: 0.742956
global_step: 6616, epoch: 16, loss: 0.831124
global_step: 6617, epoch: 16, loss: 0.742590
global_step: 6618, epoch: 16, loss: 0.770562
global_step: 6619, epoch: 16, loss: 0.804625
global_step: 6620, epoch: 16, loss: 0.727839
global_step: 6621, epoch: 16, loss: 0.793434
global_step: 6622, epoch: 16, loss: 0.752482
global_step: 6623, epoch: 16, loss: 0.682935
global_step: 6624, epoch: 16, loss: 0.836875
global_step: 6625, epoch: 16, loss: 0.656856
global_step: 6626, epoch: 16, loss: 0.728504
global_step: 6627, epoch: 16, loss: 0.742528
global_step: 6628, epoch: 16, loss: 0.808303
global_step: 6629, epoch: 16, loss: 0.744602
global_step: 6630, epoch: 16, loss: 0.798729
global_step: 6631, epoch: 16, loss: 0.757566
global_step: 6632, epoch: 16, loss: 0.692243
global_step: 6633, epoch: 16, loss: 0.827913
global_step: 6634, epoch: 16, loss: 0.887414
global_step: 6635, epoch: 16, loss: 0.867707
global_step: 6636, epoch: 16, loss: 0.823465
global_step: 6637, epoch: 16, loss: 0.823348
global_step: 6638, epoch: 16, loss: 0.842790
global_step: 6639, epoch: 16, loss: 0.765993
global_step: 6640, epoch: 16, loss: 1.519284
epoch: 16
train	acc: 0.8354	macro: p 0.7629, r 0.7573, f1: 0.7340	micro: p 0.8354, r 0.8354, f1 0.8354	weighted_f1:0.8410
dev	acc: 0.4644	macro: p 0.3828, r 0.3068, f1: 0.3113	micro: p 0.4644, r 0.4644, f1 0.4644	weighted_f1:0.4614
test	acc: 0.5226	macro: p 0.3661, r 0.3271, f1: 0.3157	micro: p 0.5226, r 0.5226, f1 0.5226	weighted_f1:0.5196
global_step: 6641, epoch: 17, loss: 0.769264
global_step: 6642, epoch: 17, loss: 0.656097
global_step: 6643, epoch: 17, loss: 0.757369
global_step: 6644, epoch: 17, loss: 0.719810
global_step: 6645, epoch: 17, loss: 0.710289
global_step: 6646, epoch: 17, loss: 0.683740
global_step: 6647, epoch: 17, loss: 0.665333
global_step: 6648, epoch: 17, loss: 0.585825
global_step: 6649, epoch: 17, loss: 0.657066
global_step: 6650, epoch: 17, loss: 0.717327
global_step: 6651, epoch: 17, loss: 0.642055
global_step: 6652, epoch: 17, loss: 0.735907
global_step: 6653, epoch: 17, loss: 0.722722
global_step: 6654, epoch: 17, loss: 0.637766
global_step: 6655, epoch: 17, loss: 0.634110
global_step: 6656, epoch: 17, loss: 0.688843
global_step: 6657, epoch: 17, loss: 0.806190
global_step: 6658, epoch: 17, loss: 0.721285
global_step: 6659, epoch: 17, loss: 0.786587
global_step: 6660, epoch: 17, loss: 0.758184
global_step: 6661, epoch: 17, loss: 0.631773
global_step: 6662, epoch: 17, loss: 0.674155
global_step: 6663, epoch: 17, loss: 0.719185
global_step: 6664, epoch: 17, loss: 0.720360
global_step: 6665, epoch: 17, loss: 0.714313
global_step: 6666, epoch: 17, loss: 0.821240
global_step: 6667, epoch: 17, loss: 0.704212
global_step: 6668, epoch: 17, loss: 0.679786
global_step: 6669, epoch: 17, loss: 0.694690
global_step: 6670, epoch: 17, loss: 0.745127
global_step: 6671, epoch: 17, loss: 0.707753
global_step: 6672, epoch: 17, loss: 0.710005
global_step: 6673, epoch: 17, loss: 0.675915
global_step: 6674, epoch: 17, loss: 0.696934
global_step: 6675, epoch: 17, loss: 0.637905
global_step: 6676, epoch: 17, loss: 0.701636
global_step: 6677, epoch: 17, loss: 0.720465
global_step: 6678, epoch: 17, loss: 0.765354
global_step: 6679, epoch: 17, loss: 0.632409
global_step: 6680, epoch: 17, loss: 1.463086
epoch: 17
train	acc: 0.8351	macro: p 0.8542, r 0.7139, f1: 0.7452	micro: p 0.8351, r 0.8351, f1 0.8351	weighted_f1:0.8372
dev	acc: 0.4797	macro: p 0.3345, r 0.2899, f1: 0.2669	micro: p 0.4797, r 0.4797, f1 0.4797	weighted_f1:0.4420
test	acc: 0.5268	macro: p 0.3300, r 0.3022, f1: 0.2737	micro: p 0.5268, r 0.5268, f1 0.5268	weighted_f1:0.5017
global_step: 6681, epoch: 18, loss: 0.802188
global_step: 6682, epoch: 18, loss: 0.640165
global_step: 6683, epoch: 18, loss: 0.565858
global_step: 6684, epoch: 18, loss: 0.634380
global_step: 6685, epoch: 18, loss: 0.606349
global_step: 6686, epoch: 18, loss: 0.729670
global_step: 6687, epoch: 18, loss: 0.673880
global_step: 6688, epoch: 18, loss: 0.651251
global_step: 6689, epoch: 18, loss: 0.656974
global_step: 6690, epoch: 18, loss: 0.625687
global_step: 6691, epoch: 18, loss: 0.654470
global_step: 6692, epoch: 18, loss: 0.632748
global_step: 6693, epoch: 18, loss: 0.704565
global_step: 6694, epoch: 18, loss: 0.655301
global_step: 6695, epoch: 18, loss: 0.608095
global_step: 6696, epoch: 18, loss: 0.668761
global_step: 6697, epoch: 18, loss: 0.674847
global_step: 6698, epoch: 18, loss: 0.847542
global_step: 6699, epoch: 18, loss: 0.587351
global_step: 6700, epoch: 18, loss: 0.650197
global_step: 6701, epoch: 18, loss: 0.620478
global_step: 6702, epoch: 18, loss: 0.676918
global_step: 6703, epoch: 18, loss: 0.716272
global_step: 6704, epoch: 18, loss: 0.619700
global_step: 6705, epoch: 18, loss: 0.590626
global_step: 6706, epoch: 18, loss: 0.719930
global_step: 6707, epoch: 18, loss: 0.584926
global_step: 6708, epoch: 18, loss: 0.636864
global_step: 6709, epoch: 18, loss: 0.613756
global_step: 6710, epoch: 18, loss: 0.575889
global_step: 6711, epoch: 18, loss: 0.690868
global_step: 6712, epoch: 18, loss: 0.660154
global_step: 6713, epoch: 18, loss: 0.601451
global_step: 6714, epoch: 18, loss: 0.737013
global_step: 6715, epoch: 18, loss: 0.526447
global_step: 6716, epoch: 18, loss: 0.774373
global_step: 6717, epoch: 18, loss: 0.754525
global_step: 6718, epoch: 18, loss: 0.699636
global_step: 6719, epoch: 18, loss: 0.704543
global_step: 6720, epoch: 18, loss: 1.212116
epoch: 18
train	acc: 0.8643	macro: p 0.8961, r 0.7376, f1: 0.7948	micro: p 0.8643, r 0.8643, f1 0.8643	weighted_f1:0.8594
dev	acc: 0.5311	macro: p 0.3340, r 0.2884, f1: 0.2749	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4685
test	acc: 0.5900	macro: p 0.4344, r 0.3046, f1: 0.3032	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5341
global_step: 6721, epoch: 19, loss: 0.629907
global_step: 6722, epoch: 19, loss: 0.656689
global_step: 6723, epoch: 19, loss: 0.605456
global_step: 6724, epoch: 19, loss: 0.527692
global_step: 6725, epoch: 19, loss: 0.551264
global_step: 6726, epoch: 19, loss: 0.607325
global_step: 6727, epoch: 19, loss: 0.583421
global_step: 6728, epoch: 19, loss: 0.521801
global_step: 6729, epoch: 19, loss: 0.497217
global_step: 6730, epoch: 19, loss: 0.618059
global_step: 6731, epoch: 19, loss: 0.644780
global_step: 6732, epoch: 19, loss: 0.607135
global_step: 6733, epoch: 19, loss: 0.670666
global_step: 6734, epoch: 19, loss: 0.734440
global_step: 6735, epoch: 19, loss: 0.499182
global_step: 6736, epoch: 19, loss: 0.671198
global_step: 6737, epoch: 19, loss: 0.670009
global_step: 6738, epoch: 19, loss: 0.537025
global_step: 6739, epoch: 19, loss: 0.647570
global_step: 6740, epoch: 19, loss: 0.669440
global_step: 6741, epoch: 19, loss: 0.641262
global_step: 6742, epoch: 19, loss: 0.624707
global_step: 6743, epoch: 19, loss: 0.661442
global_step: 6744, epoch: 19, loss: 0.602132
global_step: 6745, epoch: 19, loss: 0.554825
global_step: 6746, epoch: 19, loss: 0.682735
global_step: 6747, epoch: 19, loss: 0.599895
global_step: 6748, epoch: 19, loss: 0.599480
global_step: 6749, epoch: 19, loss: 0.516393
global_step: 6750, epoch: 19, loss: 0.633756
global_step: 6751, epoch: 19, loss: 0.702708
global_step: 6752, epoch: 19, loss: 0.578288
global_step: 6753, epoch: 19, loss: 0.742109
global_step: 6754, epoch: 19, loss: 0.552156
global_step: 6755, epoch: 19, loss: 0.670374
global_step: 6756, epoch: 19, loss: 0.610578
global_step: 6757, epoch: 19, loss: 0.704947
global_step: 6758, epoch: 19, loss: 0.717053
global_step: 6759, epoch: 19, loss: 0.675071
global_step: 6760, epoch: 19, loss: 0.444527
epoch: 19
train	acc: 0.8973	macro: p 0.9102, r 0.8231, f1: 0.8592	micro: p 0.8973, r 0.8973, f1 0.8973	weighted_f1:0.8954
dev	acc: 0.5365	macro: p 0.4161, r 0.3073, f1: 0.3132	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4881
test	acc: 0.5858	macro: p 0.3668, r 0.3089, f1: 0.3132	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5410
global_step: 6761, epoch: 20, loss: 0.643643
global_step: 6762, epoch: 20, loss: 0.490987
global_step: 6763, epoch: 20, loss: 0.546273
global_step: 6764, epoch: 20, loss: 0.635316
global_step: 6765, epoch: 20, loss: 0.532374
global_step: 6766, epoch: 20, loss: 0.465527
global_step: 6767, epoch: 20, loss: 0.577924
global_step: 6768, epoch: 20, loss: 0.655481
global_step: 6769, epoch: 20, loss: 0.664747
global_step: 6770, epoch: 20, loss: 0.591855
global_step: 6771, epoch: 20, loss: 0.542070
global_step: 6772, epoch: 20, loss: 0.577684
global_step: 6773, epoch: 20, loss: 0.611478
global_step: 6774, epoch: 20, loss: 0.706785
global_step: 6775, epoch: 20, loss: 0.600907
global_step: 6776, epoch: 20, loss: 0.640038
global_step: 6777, epoch: 20, loss: 0.597619
global_step: 6778, epoch: 20, loss: 0.572484
global_step: 6779, epoch: 20, loss: 0.596972
global_step: 6780, epoch: 20, loss: 0.528571
global_step: 6781, epoch: 20, loss: 0.594152
global_step: 6782, epoch: 20, loss: 0.558189
global_step: 6783, epoch: 20, loss: 0.620473
global_step: 6784, epoch: 20, loss: 0.617110
global_step: 6785, epoch: 20, loss: 0.623387
global_step: 6786, epoch: 20, loss: 0.539209
global_step: 6787, epoch: 20, loss: 0.616375
global_step: 6788, epoch: 20, loss: 0.660720
global_step: 6789, epoch: 20, loss: 0.584544
global_step: 6790, epoch: 20, loss: 0.643997
global_step: 6791, epoch: 20, loss: 0.633283
global_step: 6792, epoch: 20, loss: 0.586269
global_step: 6793, epoch: 20, loss: 0.640166
global_step: 6794, epoch: 20, loss: 0.677440
global_step: 6795, epoch: 20, loss: 0.625986
global_step: 6796, epoch: 20, loss: 0.694658
global_step: 6797, epoch: 20, loss: 0.637849
global_step: 6798, epoch: 20, loss: 0.641461
global_step: 6799, epoch: 20, loss: 0.560712
global_step: 6800, epoch: 20, loss: 0.177312
epoch: 20
train	acc: 0.8913	macro: p 0.8865, r 0.8201, f1: 0.8433	micro: p 0.8913, r 0.8913, f1 0.8913	weighted_f1:0.8914
dev	acc: 0.5041	macro: p 0.4584, r 0.3252, f1: 0.3242	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4838
test	acc: 0.5352	macro: p 0.3128, r 0.3132, f1: 0.2951	micro: p 0.5352, r 0.5352, f1 0.5352	weighted_f1:0.5179
global_step: 6801, epoch: 21, loss: 0.620037
global_step: 6802, epoch: 21, loss: 0.584135
global_step: 6803, epoch: 21, loss: 0.554411
global_step: 6804, epoch: 21, loss: 0.540660
global_step: 6805, epoch: 21, loss: 0.527630
global_step: 6806, epoch: 21, loss: 0.531355
global_step: 6807, epoch: 21, loss: 0.547899
global_step: 6808, epoch: 21, loss: 0.732626
global_step: 6809, epoch: 21, loss: 0.635419
global_step: 6810, epoch: 21, loss: 0.694036
global_step: 6811, epoch: 21, loss: 0.592526
global_step: 6812, epoch: 21, loss: 0.561192
global_step: 6813, epoch: 21, loss: 0.706040
global_step: 6814, epoch: 21, loss: 0.579301
global_step: 6815, epoch: 21, loss: 0.502909
global_step: 6816, epoch: 21, loss: 0.625390
global_step: 6817, epoch: 21, loss: 0.523964
global_step: 6818, epoch: 21, loss: 0.545370
global_step: 6819, epoch: 21, loss: 0.606467
global_step: 6820, epoch: 21, loss: 0.542778
global_step: 6821, epoch: 21, loss: 0.647209
global_step: 6822, epoch: 21, loss: 0.605878
global_step: 6823, epoch: 21, loss: 0.615550
global_step: 6824, epoch: 21, loss: 0.570036
global_step: 6825, epoch: 21, loss: 0.563196
global_step: 6826, epoch: 21, loss: 0.754955
global_step: 6827, epoch: 21, loss: 0.659561
global_step: 6828, epoch: 21, loss: 0.538625
global_step: 6829, epoch: 21, loss: 0.663966
global_step: 6830, epoch: 21, loss: 0.621939
global_step: 6831, epoch: 21, loss: 0.585033
global_step: 6832, epoch: 21, loss: 0.555554
global_step: 6833, epoch: 21, loss: 0.643711
global_step: 6834, epoch: 21, loss: 0.673451
global_step: 6835, epoch: 21, loss: 0.654852
global_step: 6836, epoch: 21, loss: 0.626609
global_step: 6837, epoch: 21, loss: 0.539612
global_step: 6838, epoch: 21, loss: 0.467940
global_step: 6839, epoch: 21, loss: 0.656901
global_step: 6840, epoch: 21, loss: 0.252191
epoch: 21
train	acc: 0.9063	macro: p 0.8966, r 0.8589, f1: 0.8722	micro: p 0.9063, r 0.9063, f1 0.9063	weighted_f1:0.9067
dev	acc: 0.5086	macro: p 0.3720, r 0.3110, f1: 0.3016	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4700
test	acc: 0.5510	macro: p 0.3420, r 0.3130, f1: 0.2955	micro: p 0.5510, r 0.5510, f1 0.5510	weighted_f1:0.5180
global_step: 6841, epoch: 22, loss: 0.616442
global_step: 6842, epoch: 22, loss: 0.553111
global_step: 6843, epoch: 22, loss: 0.508777
global_step: 6844, epoch: 22, loss: 0.520239
global_step: 6845, epoch: 22, loss: 0.460657
global_step: 6846, epoch: 22, loss: 0.563425
global_step: 6847, epoch: 22, loss: 0.588883
global_step: 6848, epoch: 22, loss: 0.577239
global_step: 6849, epoch: 22, loss: 0.563758
global_step: 6850, epoch: 22, loss: 0.485297
global_step: 6851, epoch: 22, loss: 0.588123
global_step: 6852, epoch: 22, loss: 0.588528
global_step: 6853, epoch: 22, loss: 0.572894
global_step: 6854, epoch: 22, loss: 0.536070
global_step: 6855, epoch: 22, loss: 0.594253
global_step: 6856, epoch: 22, loss: 0.572882
global_step: 6857, epoch: 22, loss: 0.577051
global_step: 6858, epoch: 22, loss: 0.506448
global_step: 6859, epoch: 22, loss: 0.562396
global_step: 6860, epoch: 22, loss: 0.632721
global_step: 6861, epoch: 22, loss: 0.611683
global_step: 6862, epoch: 22, loss: 0.489690
global_step: 6863, epoch: 22, loss: 0.593784
global_step: 6864, epoch: 22, loss: 0.585933
global_step: 6865, epoch: 22, loss: 0.711007
global_step: 6866, epoch: 22, loss: 0.655411
global_step: 6867, epoch: 22, loss: 0.634623
global_step: 6868, epoch: 22, loss: 0.611455
global_step: 6869, epoch: 22, loss: 0.550262
global_step: 6870, epoch: 22, loss: 0.567520
global_step: 6871, epoch: 22, loss: 0.602013
global_step: 6872, epoch: 22, loss: 0.476870
global_step: 6873, epoch: 22, loss: 0.497236
global_step: 6874, epoch: 22, loss: 0.701842
global_step: 6875, epoch: 22, loss: 0.650499
global_step: 6876, epoch: 22, loss: 0.534541
global_step: 6877, epoch: 22, loss: 0.674919
global_step: 6878, epoch: 22, loss: 0.592276
global_step: 6879, epoch: 22, loss: 0.688278
global_step: 6880, epoch: 22, loss: 0.398833
epoch: 22
train	acc: 0.9056	macro: p 0.8905, r 0.8657, f1: 0.8735	micro: p 0.9056, r 0.9056, f1 0.9056	weighted_f1:0.9065
dev	acc: 0.4887	macro: p 0.3163, r 0.3150, f1: 0.3077	micro: p 0.4887, r 0.4887, f1 0.4887	weighted_f1:0.4736
test	acc: 0.5364	macro: p 0.3142, r 0.3348, f1: 0.3200	micro: p 0.5364, r 0.5364, f1 0.5364	weighted_f1:0.5295
global_step: 6881, epoch: 23, loss: 0.562328
global_step: 6882, epoch: 23, loss: 0.611943
global_step: 6883, epoch: 23, loss: 0.483006
global_step: 6884, epoch: 23, loss: 0.492601
global_step: 6885, epoch: 23, loss: 0.595919
global_step: 6886, epoch: 23, loss: 0.541590
global_step: 6887, epoch: 23, loss: 0.573391
global_step: 6888, epoch: 23, loss: 0.538778
global_step: 6889, epoch: 23, loss: 0.463492
global_step: 6890, epoch: 23, loss: 0.544982
global_step: 6891, epoch: 23, loss: 0.520434
global_step: 6892, epoch: 23, loss: 0.478511
global_step: 6893, epoch: 23, loss: 0.653405
global_step: 6894, epoch: 23, loss: 0.535380
global_step: 6895, epoch: 23, loss: 0.586820
global_step: 6896, epoch: 23, loss: 0.510549
global_step: 6897, epoch: 23, loss: 0.510365
global_step: 6898, epoch: 23, loss: 0.630367
global_step: 6899, epoch: 23, loss: 0.581028
global_step: 6900, epoch: 23, loss: 0.547793
global_step: 6901, epoch: 23, loss: 0.597135
global_step: 6902, epoch: 23, loss: 0.572241
global_step: 6903, epoch: 23, loss: 0.531811
global_step: 6904, epoch: 23, loss: 0.569239
global_step: 6905, epoch: 23, loss: 0.445275
global_step: 6906, epoch: 23, loss: 0.598029
global_step: 6907, epoch: 23, loss: 0.670607
global_step: 6908, epoch: 23, loss: 0.613703
global_step: 6909, epoch: 23, loss: 0.619169
global_step: 6910, epoch: 23, loss: 0.606259
global_step: 6911, epoch: 23, loss: 0.630475
global_step: 6912, epoch: 23, loss: 0.652005
global_step: 6913, epoch: 23, loss: 0.579030
global_step: 6914, epoch: 23, loss: 0.580802
global_step: 6915, epoch: 23, loss: 0.596078
global_step: 6916, epoch: 23, loss: 0.583949
global_step: 6917, epoch: 23, loss: 0.531610
global_step: 6918, epoch: 23, loss: 0.615829
global_step: 6919, epoch: 23, loss: 0.593923
global_step: 6920, epoch: 23, loss: 0.712875
epoch: 23
train	acc: 0.8956	macro: p 0.9277, r 0.8258, f1: 0.8694	micro: p 0.8956, r 0.8956, f1 0.8956	weighted_f1:0.8942
dev	acc: 0.5185	macro: p 0.3506, r 0.2772, f1: 0.2765	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4571
test	acc: 0.5816	macro: p 0.3406, r 0.2871, f1: 0.2854	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5197
global_step: 6921, epoch: 24, loss: 0.600356
global_step: 6922, epoch: 24, loss: 0.517625
global_step: 6923, epoch: 24, loss: 0.544392
global_step: 6924, epoch: 24, loss: 0.453381
global_step: 6925, epoch: 24, loss: 0.439853
global_step: 6926, epoch: 24, loss: 0.528448
global_step: 6927, epoch: 24, loss: 0.500359
global_step: 6928, epoch: 24, loss: 0.621317
global_step: 6929, epoch: 24, loss: 0.497685
global_step: 6930, epoch: 24, loss: 0.476258
global_step: 6931, epoch: 24, loss: 0.634510
global_step: 6932, epoch: 24, loss: 0.506661
global_step: 6933, epoch: 24, loss: 0.544897
global_step: 6934, epoch: 24, loss: 0.581088
global_step: 6935, epoch: 24, loss: 0.454515
global_step: 6936, epoch: 24, loss: 0.544558
global_step: 6937, epoch: 24, loss: 0.512850
global_step: 6938, epoch: 24, loss: 0.495525
global_step: 6939, epoch: 24, loss: 0.600694
global_step: 6940, epoch: 24, loss: 0.550201
global_step: 6941, epoch: 24, loss: 0.555265
global_step: 6942, epoch: 24, loss: 0.672081
global_step: 6943, epoch: 24, loss: 0.587498
global_step: 6944, epoch: 24, loss: 0.588729
global_step: 6945, epoch: 24, loss: 0.552809
global_step: 6946, epoch: 24, loss: 0.583330
global_step: 6947, epoch: 24, loss: 0.467154
global_step: 6948, epoch: 24, loss: 0.503206
global_step: 6949, epoch: 24, loss: 0.579030
global_step: 6950, epoch: 24, loss: 0.554735
global_step: 6951, epoch: 24, loss: 0.481941
global_step: 6952, epoch: 24, loss: 0.604698
global_step: 6953, epoch: 24, loss: 0.537661
global_step: 6954, epoch: 24, loss: 0.558512
global_step: 6955, epoch: 24, loss: 0.591712
global_step: 6956, epoch: 24, loss: 0.607372
global_step: 6957, epoch: 24, loss: 0.516947
global_step: 6958, epoch: 24, loss: 0.670155
global_step: 6959, epoch: 24, loss: 0.695474
global_step: 6960, epoch: 24, loss: 1.066004
epoch: 24
train	acc: 0.9148	macro: p 0.9164, r 0.8704, f1: 0.8908	micro: p 0.9148, r 0.9148, f1 0.9148	weighted_f1:0.9137
dev	acc: 0.5023	macro: p 0.3465, r 0.2788, f1: 0.2875	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4588
test	acc: 0.5686	macro: p 0.3606, r 0.2951, f1: 0.3054	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5285
global_step: 6961, epoch: 25, loss: 0.577284
global_step: 6962, epoch: 25, loss: 0.461975
global_step: 6963, epoch: 25, loss: 0.578150
global_step: 6964, epoch: 25, loss: 0.467799
global_step: 6965, epoch: 25, loss: 0.569254
global_step: 6966, epoch: 25, loss: 0.481460
global_step: 6967, epoch: 25, loss: 0.363286
global_step: 6968, epoch: 25, loss: 0.447079
global_step: 6969, epoch: 25, loss: 0.604799
global_step: 6970, epoch: 25, loss: 0.412784
global_step: 6971, epoch: 25, loss: 0.512138
global_step: 6972, epoch: 25, loss: 0.599304
global_step: 6973, epoch: 25, loss: 0.515200
global_step: 6974, epoch: 25, loss: 0.514046
global_step: 6975, epoch: 25, loss: 0.423672
global_step: 6976, epoch: 25, loss: 0.601709
global_step: 6977, epoch: 25, loss: 0.505303
global_step: 6978, epoch: 25, loss: 0.560853
global_step: 6979, epoch: 25, loss: 0.493035
global_step: 6980, epoch: 25, loss: 0.602914
global_step: 6981, epoch: 25, loss: 0.505387
global_step: 6982, epoch: 25, loss: 0.613223
global_step: 6983, epoch: 25, loss: 0.502362
global_step: 6984, epoch: 25, loss: 0.510329
global_step: 6985, epoch: 25, loss: 0.491197
global_step: 6986, epoch: 25, loss: 0.526863
global_step: 6987, epoch: 25, loss: 0.671932
global_step: 6988, epoch: 25, loss: 0.633676
global_step: 6989, epoch: 25, loss: 0.531124
global_step: 6990, epoch: 25, loss: 0.403830
global_step: 6991, epoch: 25, loss: 0.562528
global_step: 6992, epoch: 25, loss: 0.553125
global_step: 6993, epoch: 25, loss: 0.661623
global_step: 6994, epoch: 25, loss: 0.465824
global_step: 6995, epoch: 25, loss: 0.481994
global_step: 6996, epoch: 25, loss: 0.601848
global_step: 6997, epoch: 25, loss: 0.500469
global_step: 6998, epoch: 25, loss: 0.502614
global_step: 6999, epoch: 25, loss: 0.522093
global_step: 7000, epoch: 25, loss: 0.387130
epoch: 25
train	acc: 0.9214	macro: p 0.9283, r 0.8798, f1: 0.9007	micro: p 0.9214, r 0.9214, f1 0.9214	weighted_f1:0.9214
dev	acc: 0.5302	macro: p 0.3879, r 0.3180, f1: 0.3209	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4984
test	acc: 0.5678	macro: p 0.3350, r 0.3145, f1: 0.3115	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5368
New best model!
global_step: 7001, epoch: 26, loss: 0.471533
global_step: 7002, epoch: 26, loss: 0.544572
global_step: 7003, epoch: 26, loss: 0.432309
global_step: 7004, epoch: 26, loss: 0.496325
global_step: 7005, epoch: 26, loss: 0.392031
global_step: 7006, epoch: 26, loss: 0.489668
global_step: 7007, epoch: 26, loss: 0.450874
global_step: 7008, epoch: 26, loss: 0.514158
global_step: 7009, epoch: 26, loss: 0.467677
global_step: 7010, epoch: 26, loss: 0.388467
global_step: 7011, epoch: 26, loss: 0.436730
global_step: 7012, epoch: 26, loss: 0.467090
global_step: 7013, epoch: 26, loss: 0.442486
global_step: 7014, epoch: 26, loss: 0.501106
global_step: 7015, epoch: 26, loss: 0.545738
global_step: 7016, epoch: 26, loss: 0.436160
global_step: 7017, epoch: 26, loss: 0.512354
global_step: 7018, epoch: 26, loss: 0.519163
global_step: 7019, epoch: 26, loss: 0.483662
global_step: 7020, epoch: 26, loss: 0.436971
global_step: 7021, epoch: 26, loss: 0.417379
global_step: 7022, epoch: 26, loss: 0.459789
global_step: 7023, epoch: 26, loss: 0.497457
global_step: 7024, epoch: 26, loss: 0.506591
global_step: 7025, epoch: 26, loss: 0.428516
global_step: 7026, epoch: 26, loss: 0.458747
global_step: 7027, epoch: 26, loss: 0.575919
global_step: 7028, epoch: 26, loss: 0.543357
global_step: 7029, epoch: 26, loss: 0.558860
global_step: 7030, epoch: 26, loss: 0.514265
global_step: 7031, epoch: 26, loss: 0.445066
global_step: 7032, epoch: 26, loss: 0.512496
global_step: 7033, epoch: 26, loss: 0.468601
global_step: 7034, epoch: 26, loss: 0.564515
global_step: 7035, epoch: 26, loss: 0.532430
global_step: 7036, epoch: 26, loss: 0.497380
global_step: 7037, epoch: 26, loss: 0.543871
global_step: 7038, epoch: 26, loss: 0.524664
global_step: 7039, epoch: 26, loss: 0.536075
global_step: 7040, epoch: 26, loss: 1.169805
epoch: 26
train	acc: 0.9150	macro: p 0.9222, r 0.8651, f1: 0.8892	micro: p 0.9150, r 0.9150, f1 0.9150	weighted_f1:0.9139
dev	acc: 0.5275	macro: p 0.4006, r 0.2982, f1: 0.3023	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4831
test	acc: 0.5862	macro: p 0.4131, r 0.3191, f1: 0.3220	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5445
global_step: 7041, epoch: 27, loss: 0.516324
global_step: 7042, epoch: 27, loss: 0.458293
global_step: 7043, epoch: 27, loss: 0.483987
global_step: 7044, epoch: 27, loss: 0.444925
global_step: 7045, epoch: 27, loss: 0.505801
global_step: 7046, epoch: 27, loss: 0.436250
global_step: 7047, epoch: 27, loss: 0.421020
global_step: 7048, epoch: 27, loss: 0.549842
global_step: 7049, epoch: 27, loss: 0.424008
global_step: 7050, epoch: 27, loss: 0.451322
global_step: 7051, epoch: 27, loss: 0.418076
global_step: 7052, epoch: 27, loss: 0.528500
global_step: 7053, epoch: 27, loss: 0.481933
global_step: 7054, epoch: 27, loss: 0.492373
global_step: 7055, epoch: 27, loss: 0.471977
global_step: 7056, epoch: 27, loss: 0.446890
global_step: 7057, epoch: 27, loss: 0.449507
global_step: 7058, epoch: 27, loss: 0.485066
global_step: 7059, epoch: 27, loss: 0.402006
global_step: 7060, epoch: 27, loss: 0.582374
global_step: 7061, epoch: 27, loss: 0.548526
global_step: 7062, epoch: 27, loss: 0.376825
global_step: 7063, epoch: 27, loss: 0.502172
global_step: 7064, epoch: 27, loss: 0.432711
global_step: 7065, epoch: 27, loss: 0.529545
global_step: 7066, epoch: 27, loss: 0.578644
global_step: 7067, epoch: 27, loss: 0.593041
global_step: 7068, epoch: 27, loss: 0.486033
global_step: 7069, epoch: 27, loss: 0.469681
global_step: 7070, epoch: 27, loss: 0.467023
global_step: 7071, epoch: 27, loss: 0.624832
global_step: 7072, epoch: 27, loss: 0.420205
global_step: 7073, epoch: 27, loss: 0.474585
global_step: 7074, epoch: 27, loss: 0.493046
global_step: 7075, epoch: 27, loss: 0.514714
global_step: 7076, epoch: 27, loss: 0.427075
global_step: 7077, epoch: 27, loss: 0.556162
global_step: 7078, epoch: 27, loss: 0.617535
global_step: 7079, epoch: 27, loss: 0.558007
global_step: 7080, epoch: 27, loss: 0.531968
epoch: 27
train	acc: 0.9241	macro: p 0.9249, r 0.8869, f1: 0.9036	micro: p 0.9241, r 0.9241, f1 0.9241	weighted_f1:0.9235
dev	acc: 0.5104	macro: p 0.3298, r 0.2833, f1: 0.2884	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4671
test	acc: 0.5701	macro: p 0.3584, r 0.2940, f1: 0.3059	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5319
global_step: 7081, epoch: 28, loss: 0.414363
global_step: 7082, epoch: 28, loss: 0.514274
global_step: 7083, epoch: 28, loss: 0.407832
global_step: 7084, epoch: 28, loss: 0.398388
global_step: 7085, epoch: 28, loss: 0.470427
global_step: 7086, epoch: 28, loss: 0.469534
global_step: 7087, epoch: 28, loss: 0.521782
global_step: 7088, epoch: 28, loss: 0.589299
global_step: 7089, epoch: 28, loss: 0.401131
global_step: 7090, epoch: 28, loss: 0.534393
global_step: 7091, epoch: 28, loss: 0.458333
global_step: 7092, epoch: 28, loss: 0.451565
global_step: 7093, epoch: 28, loss: 0.326037
global_step: 7094, epoch: 28, loss: 0.500559
global_step: 7095, epoch: 28, loss: 0.392584
global_step: 7096, epoch: 28, loss: 0.440252
global_step: 7097, epoch: 28, loss: 0.522710
global_step: 7098, epoch: 28, loss: 0.410940
global_step: 7099, epoch: 28, loss: 0.522109
global_step: 7100, epoch: 28, loss: 0.537524
global_step: 7101, epoch: 28, loss: 0.440942
global_step: 7102, epoch: 28, loss: 0.506043
global_step: 7103, epoch: 28, loss: 0.512172
global_step: 7104, epoch: 28, loss: 0.392801
global_step: 7105, epoch: 28, loss: 0.434559
global_step: 7106, epoch: 28, loss: 0.542737
global_step: 7107, epoch: 28, loss: 0.558435
global_step: 7108, epoch: 28, loss: 0.372529
global_step: 7109, epoch: 28, loss: 0.526630
global_step: 7110, epoch: 28, loss: 0.486510
global_step: 7111, epoch: 28, loss: 0.532705
global_step: 7112, epoch: 28, loss: 0.519976
global_step: 7113, epoch: 28, loss: 0.435096
global_step: 7114, epoch: 28, loss: 0.458835
global_step: 7115, epoch: 28, loss: 0.516363
global_step: 7116, epoch: 28, loss: 0.458748
global_step: 7117, epoch: 28, loss: 0.447195
global_step: 7118, epoch: 28, loss: 0.474500
global_step: 7119, epoch: 28, loss: 0.420612
global_step: 7120, epoch: 28, loss: 0.089878
epoch: 28
train	acc: 0.9419	macro: p 0.9431, r 0.9198, f1: 0.9302	micro: p 0.9419, r 0.9419, f1 0.9419	weighted_f1:0.9421
dev	acc: 0.5014	macro: p 0.3461, r 0.3092, f1: 0.3086	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4806
test	acc: 0.5452	macro: p 0.3392, r 0.3227, f1: 0.3219	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5305
global_step: 7121, epoch: 29, loss: 0.396245
global_step: 7122, epoch: 29, loss: 0.512302
global_step: 7123, epoch: 29, loss: 0.333567
global_step: 7124, epoch: 29, loss: 0.481220
global_step: 7125, epoch: 29, loss: 0.459503
global_step: 7126, epoch: 29, loss: 0.370037
global_step: 7127, epoch: 29, loss: 0.540415
global_step: 7128, epoch: 29, loss: 0.362778
global_step: 7129, epoch: 29, loss: 0.552517
global_step: 7130, epoch: 29, loss: 0.397967
global_step: 7131, epoch: 29, loss: 0.381038
global_step: 7132, epoch: 29, loss: 0.447554
global_step: 7133, epoch: 29, loss: 0.360707
global_step: 7134, epoch: 29, loss: 0.404826
global_step: 7135, epoch: 29, loss: 0.442542
global_step: 7136, epoch: 29, loss: 0.406042
global_step: 7137, epoch: 29, loss: 0.443447
global_step: 7138, epoch: 29, loss: 0.441197
global_step: 7139, epoch: 29, loss: 0.499044
global_step: 7140, epoch: 29, loss: 0.463770
global_step: 7141, epoch: 29, loss: 0.321659
global_step: 7142, epoch: 29, loss: 0.537871
global_step: 7143, epoch: 29, loss: 0.414512
global_step: 7144, epoch: 29, loss: 0.391330
global_step: 7145, epoch: 29, loss: 0.416176
global_step: 7146, epoch: 29, loss: 0.488470
global_step: 7147, epoch: 29, loss: 0.408255
global_step: 7148, epoch: 29, loss: 0.516077
global_step: 7149, epoch: 29, loss: 0.424619
global_step: 7150, epoch: 29, loss: 0.431010
global_step: 7151, epoch: 29, loss: 0.454470
global_step: 7152, epoch: 29, loss: 0.411620
global_step: 7153, epoch: 29, loss: 0.450405
global_step: 7154, epoch: 29, loss: 0.450631
global_step: 7155, epoch: 29, loss: 0.505482
global_step: 7156, epoch: 29, loss: 0.428634
global_step: 7157, epoch: 29, loss: 0.638399
global_step: 7158, epoch: 29, loss: 0.538954
global_step: 7159, epoch: 29, loss: 0.474228
global_step: 7160, epoch: 29, loss: 0.230057
epoch: 29
train	acc: 0.9252	macro: p 0.9425, r 0.8888, f1: 0.9129	micro: p 0.9252, r 0.9252, f1 0.9252	weighted_f1:0.9249
dev	acc: 0.5122	macro: p 0.3386, r 0.2891, f1: 0.2891	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4642
test	acc: 0.5720	macro: p 0.3646, r 0.2945, f1: 0.3008	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5261
global_step: 7161, epoch: 30, loss: 0.408036
global_step: 7162, epoch: 30, loss: 0.593306
global_step: 7163, epoch: 30, loss: 0.506167
global_step: 7164, epoch: 30, loss: 0.419286
global_step: 7165, epoch: 30, loss: 0.497131
global_step: 7166, epoch: 30, loss: 0.504010
global_step: 7167, epoch: 30, loss: 0.491607
global_step: 7168, epoch: 30, loss: 0.385930
global_step: 7169, epoch: 30, loss: 0.376490
global_step: 7170, epoch: 30, loss: 0.391341
global_step: 7171, epoch: 30, loss: 0.396742
global_step: 7172, epoch: 30, loss: 0.468148
global_step: 7173, epoch: 30, loss: 0.336520
global_step: 7174, epoch: 30, loss: 0.504800
global_step: 7175, epoch: 30, loss: 0.487562
global_step: 7176, epoch: 30, loss: 0.465617
global_step: 7177, epoch: 30, loss: 0.497109
global_step: 7178, epoch: 30, loss: 0.325300
global_step: 7179, epoch: 30, loss: 0.449087
global_step: 7180, epoch: 30, loss: 0.436115
global_step: 7181, epoch: 30, loss: 0.467273
global_step: 7182, epoch: 30, loss: 0.553091
global_step: 7183, epoch: 30, loss: 0.423514
global_step: 7184, epoch: 30, loss: 0.542073
global_step: 7185, epoch: 30, loss: 0.529837
global_step: 7186, epoch: 30, loss: 0.496327
global_step: 7187, epoch: 30, loss: 0.437385
global_step: 7188, epoch: 30, loss: 0.439892
global_step: 7189, epoch: 30, loss: 0.609820
global_step: 7190, epoch: 30, loss: 0.319977
global_step: 7191, epoch: 30, loss: 0.495717
global_step: 7192, epoch: 30, loss: 0.502756
global_step: 7193, epoch: 30, loss: 0.554956
global_step: 7194, epoch: 30, loss: 0.419321
global_step: 7195, epoch: 30, loss: 0.538501
global_step: 7196, epoch: 30, loss: 0.387248
global_step: 7197, epoch: 30, loss: 0.429019
global_step: 7198, epoch: 30, loss: 0.546412
global_step: 7199, epoch: 30, loss: 0.509558
global_step: 7200, epoch: 30, loss: 0.116411
epoch: 30
train	acc: 0.9446	macro: p 0.9489, r 0.9225, f1: 0.9348	micro: p 0.9446, r 0.9446, f1 0.9446	weighted_f1:0.9447
dev	acc: 0.5104	macro: p 0.3269, r 0.3033, f1: 0.3037	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4806
test	acc: 0.5716	macro: p 0.3434, r 0.3234, f1: 0.3240	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5472
global_step: 7201, epoch: 31, loss: 0.435659
global_step: 7202, epoch: 31, loss: 0.348802
global_step: 7203, epoch: 31, loss: 0.415547
global_step: 7204, epoch: 31, loss: 0.440881
global_step: 7205, epoch: 31, loss: 0.453181
global_step: 7206, epoch: 31, loss: 0.363929
global_step: 7207, epoch: 31, loss: 0.381193
global_step: 7208, epoch: 31, loss: 0.376788
global_step: 7209, epoch: 31, loss: 0.503094
global_step: 7210, epoch: 31, loss: 0.476138
global_step: 7211, epoch: 31, loss: 0.436594
global_step: 7212, epoch: 31, loss: 0.458718
global_step: 7213, epoch: 31, loss: 0.406726
global_step: 7214, epoch: 31, loss: 0.465309
global_step: 7215, epoch: 31, loss: 0.348382
global_step: 7216, epoch: 31, loss: 0.378196
global_step: 7217, epoch: 31, loss: 0.364544
global_step: 7218, epoch: 31, loss: 0.473990
global_step: 7219, epoch: 31, loss: 0.461953
global_step: 7220, epoch: 31, loss: 0.500859
global_step: 7221, epoch: 31, loss: 0.443042
global_step: 7222, epoch: 31, loss: 0.461881
global_step: 7223, epoch: 31, loss: 0.441311
global_step: 7224, epoch: 31, loss: 0.401922
global_step: 7225, epoch: 31, loss: 0.384176
global_step: 7226, epoch: 31, loss: 0.423657
global_step: 7227, epoch: 31, loss: 0.472645
global_step: 7228, epoch: 31, loss: 0.436583
global_step: 7229, epoch: 31, loss: 0.463218
global_step: 7230, epoch: 31, loss: 0.461242
global_step: 7231, epoch: 31, loss: 0.584369
global_step: 7232, epoch: 31, loss: 0.510190
global_step: 7233, epoch: 31, loss: 0.483735
global_step: 7234, epoch: 31, loss: 0.553618
global_step: 7235, epoch: 31, loss: 0.467801
global_step: 7236, epoch: 31, loss: 0.442124
global_step: 7237, epoch: 31, loss: 0.467253
global_step: 7238, epoch: 31, loss: 0.481286
global_step: 7239, epoch: 31, loss: 0.514344
global_step: 7240, epoch: 31, loss: 0.215973
epoch: 31
train	acc: 0.9448	macro: p 0.9512, r 0.9205, f1: 0.9347	micro: p 0.9448, r 0.9448, f1 0.9448	weighted_f1:0.9449
dev	acc: 0.5104	macro: p 0.3423, r 0.2977, f1: 0.2983	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4763
test	acc: 0.5674	macro: p 0.3421, r 0.3077, f1: 0.3096	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5362
global_step: 7241, epoch: 32, loss: 0.277985
global_step: 7242, epoch: 32, loss: 0.412579
global_step: 7243, epoch: 32, loss: 0.390371
global_step: 7244, epoch: 32, loss: 0.462149
global_step: 7245, epoch: 32, loss: 0.308361
global_step: 7246, epoch: 32, loss: 0.445174
global_step: 7247, epoch: 32, loss: 0.394892
global_step: 7248, epoch: 32, loss: 0.311988
global_step: 7249, epoch: 32, loss: 0.346038
global_step: 7250, epoch: 32, loss: 0.399951
global_step: 7251, epoch: 32, loss: 0.476409
global_step: 7252, epoch: 32, loss: 0.413805
global_step: 7253, epoch: 32, loss: 0.404465
global_step: 7254, epoch: 32, loss: 0.395654
global_step: 7255, epoch: 32, loss: 0.408833
global_step: 7256, epoch: 32, loss: 0.395650
global_step: 7257, epoch: 32, loss: 0.535501
global_step: 7258, epoch: 32, loss: 0.450303
global_step: 7259, epoch: 32, loss: 0.456842
global_step: 7260, epoch: 32, loss: 0.641422
global_step: 7261, epoch: 32, loss: 0.494648
global_step: 7262, epoch: 32, loss: 0.434553
global_step: 7263, epoch: 32, loss: 0.431039
global_step: 7264, epoch: 32, loss: 0.606301
global_step: 7265, epoch: 32, loss: 0.321677
global_step: 7266, epoch: 32, loss: 0.393930
global_step: 7267, epoch: 32, loss: 0.426225
global_step: 7268, epoch: 32, loss: 0.534928
global_step: 7269, epoch: 32, loss: 0.485977
global_step: 7270, epoch: 32, loss: 0.571733
global_step: 7271, epoch: 32, loss: 0.517827
global_step: 7272, epoch: 32, loss: 0.525747
global_step: 7273, epoch: 32, loss: 0.535914
global_step: 7274, epoch: 32, loss: 0.538509
global_step: 7275, epoch: 32, loss: 0.494917
global_step: 7276, epoch: 32, loss: 0.470901
global_step: 7277, epoch: 32, loss: 0.447448
global_step: 7278, epoch: 32, loss: 0.415212
global_step: 7279, epoch: 32, loss: 0.474130
global_step: 7280, epoch: 32, loss: 0.030740
epoch: 32
train	acc: 0.9475	macro: p 0.9514, r 0.9243, f1: 0.9369	micro: p 0.9475, r 0.9475, f1 0.9475	weighted_f1:0.9476
dev	acc: 0.5347	macro: p 0.3652, r 0.3183, f1: 0.3244	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.5005
test	acc: 0.5655	macro: p 0.3343, r 0.3099, f1: 0.3146	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5367
New best model!
global_step: 7281, epoch: 33, loss: 0.336775
global_step: 7282, epoch: 33, loss: 0.414520
global_step: 7283, epoch: 33, loss: 0.335548
global_step: 7284, epoch: 33, loss: 0.406060
global_step: 7285, epoch: 33, loss: 0.346064
global_step: 7286, epoch: 33, loss: 0.392629
global_step: 7287, epoch: 33, loss: 0.342418
global_step: 7288, epoch: 33, loss: 0.420999
global_step: 7289, epoch: 33, loss: 0.332750
global_step: 7290, epoch: 33, loss: 0.412454
global_step: 7291, epoch: 33, loss: 0.362154
global_step: 7292, epoch: 33, loss: 0.464064
global_step: 7293, epoch: 33, loss: 0.360198
global_step: 7294, epoch: 33, loss: 0.431175
global_step: 7295, epoch: 33, loss: 0.416430
global_step: 7296, epoch: 33, loss: 0.500551
global_step: 7297, epoch: 33, loss: 0.423554
global_step: 7298, epoch: 33, loss: 0.527251
global_step: 7299, epoch: 33, loss: 0.435674
global_step: 7300, epoch: 33, loss: 0.451086
global_step: 7301, epoch: 33, loss: 0.431330
global_step: 7302, epoch: 33, loss: 0.494574
global_step: 7303, epoch: 33, loss: 0.512255
global_step: 7304, epoch: 33, loss: 0.438733
global_step: 7305, epoch: 33, loss: 0.445522
global_step: 7306, epoch: 33, loss: 0.372269
global_step: 7307, epoch: 33, loss: 0.438766
global_step: 7308, epoch: 33, loss: 0.443173
global_step: 7309, epoch: 33, loss: 0.397474
global_step: 7310, epoch: 33, loss: 0.419526
global_step: 7311, epoch: 33, loss: 0.426503
global_step: 7312, epoch: 33, loss: 0.471462
global_step: 7313, epoch: 33, loss: 0.393500
global_step: 7314, epoch: 33, loss: 0.425246
global_step: 7315, epoch: 33, loss: 0.529737
global_step: 7316, epoch: 33, loss: 0.430644
global_step: 7317, epoch: 33, loss: 0.472632
global_step: 7318, epoch: 33, loss: 0.453613
global_step: 7319, epoch: 33, loss: 0.465682
global_step: 7320, epoch: 33, loss: 0.551377
epoch: 33
train	acc: 0.9324	macro: p 0.9524, r 0.8952, f1: 0.9212	micro: p 0.9324, r 0.9324, f1 0.9324	weighted_f1:0.9316
dev	acc: 0.5302	macro: p 0.4431, r 0.2837, f1: 0.2925	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4731
test	acc: 0.5801	macro: p 0.3886, r 0.2887, f1: 0.2985	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5244
global_step: 7321, epoch: 34, loss: 0.497643
global_step: 7322, epoch: 34, loss: 0.456267
global_step: 7323, epoch: 34, loss: 0.387536
global_step: 7324, epoch: 34, loss: 0.436496
global_step: 7325, epoch: 34, loss: 0.470015
global_step: 7326, epoch: 34, loss: 0.363722
global_step: 7327, epoch: 34, loss: 0.472416
global_step: 7328, epoch: 34, loss: 0.345624
global_step: 7329, epoch: 34, loss: 0.384934
global_step: 7330, epoch: 34, loss: 0.493020
global_step: 7331, epoch: 34, loss: 0.288931
global_step: 7332, epoch: 34, loss: 0.453592
global_step: 7333, epoch: 34, loss: 0.345973
global_step: 7334, epoch: 34, loss: 0.405188
global_step: 7335, epoch: 34, loss: 0.332565
global_step: 7336, epoch: 34, loss: 0.408015
global_step: 7337, epoch: 34, loss: 0.424061
global_step: 7338, epoch: 34, loss: 0.366186
global_step: 7339, epoch: 34, loss: 0.472487
global_step: 7340, epoch: 34, loss: 0.460852
global_step: 7341, epoch: 34, loss: 0.410120
global_step: 7342, epoch: 34, loss: 0.394250
global_step: 7343, epoch: 34, loss: 0.430024
global_step: 7344, epoch: 34, loss: 0.482674
global_step: 7345, epoch: 34, loss: 0.350437
global_step: 7346, epoch: 34, loss: 0.411290
global_step: 7347, epoch: 34, loss: 0.336460
global_step: 7348, epoch: 34, loss: 0.467365
global_step: 7349, epoch: 34, loss: 0.418467
global_step: 7350, epoch: 34, loss: 0.400013
global_step: 7351, epoch: 34, loss: 0.364635
global_step: 7352, epoch: 34, loss: 0.502127
global_step: 7353, epoch: 34, loss: 0.411066
global_step: 7354, epoch: 34, loss: 0.421984
global_step: 7355, epoch: 34, loss: 0.395342
global_step: 7356, epoch: 34, loss: 0.442988
global_step: 7357, epoch: 34, loss: 0.444892
global_step: 7358, epoch: 34, loss: 0.454650
global_step: 7359, epoch: 34, loss: 0.382357
global_step: 7360, epoch: 34, loss: 0.521406
epoch: 34
train	acc: 0.9525	macro: p 0.9572, r 0.9324, f1: 0.9441	micro: p 0.9525, r 0.9525, f1 0.9525	weighted_f1:0.9525
dev	acc: 0.5041	macro: p 0.3747, r 0.2879, f1: 0.2919	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4647
test	acc: 0.5697	macro: p 0.3578, r 0.3137, f1: 0.3146	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5344
global_step: 7361, epoch: 35, loss: 0.384016
global_step: 7362, epoch: 35, loss: 0.290650
global_step: 7363, epoch: 35, loss: 0.370048
global_step: 7364, epoch: 35, loss: 0.388804
global_step: 7365, epoch: 35, loss: 0.410274
global_step: 7366, epoch: 35, loss: 0.313695
global_step: 7367, epoch: 35, loss: 0.409632
global_step: 7368, epoch: 35, loss: 0.402903
global_step: 7369, epoch: 35, loss: 0.380913
global_step: 7370, epoch: 35, loss: 0.301565
global_step: 7371, epoch: 35, loss: 0.320393
global_step: 7372, epoch: 35, loss: 0.453643
global_step: 7373, epoch: 35, loss: 0.329626
global_step: 7374, epoch: 35, loss: 0.421082
global_step: 7375, epoch: 35, loss: 0.386923
global_step: 7376, epoch: 35, loss: 0.447687
global_step: 7377, epoch: 35, loss: 0.362639
global_step: 7378, epoch: 35, loss: 0.284375
global_step: 7379, epoch: 35, loss: 0.374980
global_step: 7380, epoch: 35, loss: 0.395515
global_step: 7381, epoch: 35, loss: 0.339851
global_step: 7382, epoch: 35, loss: 0.408575
global_step: 7383, epoch: 35, loss: 0.395447
global_step: 7384, epoch: 35, loss: 0.307899
global_step: 7385, epoch: 35, loss: 0.360269
global_step: 7386, epoch: 35, loss: 0.404108
global_step: 7387, epoch: 35, loss: 0.387813
global_step: 7388, epoch: 35, loss: 0.344142
global_step: 7389, epoch: 35, loss: 0.395345
global_step: 7390, epoch: 35, loss: 0.444961
global_step: 7391, epoch: 35, loss: 0.494753
global_step: 7392, epoch: 35, loss: 0.424893
global_step: 7393, epoch: 35, loss: 0.422627
global_step: 7394, epoch: 35, loss: 0.408413
global_step: 7395, epoch: 35, loss: 0.433464
global_step: 7396, epoch: 35, loss: 0.290622
global_step: 7397, epoch: 35, loss: 0.409529
global_step: 7398, epoch: 35, loss: 0.454249
global_step: 7399, epoch: 35, loss: 0.335327
global_step: 7400, epoch: 35, loss: 0.497323
epoch: 35
train	acc: 0.9515	macro: p 0.9563, r 0.9337, f1: 0.9444	micro: p 0.9515, r 0.9515, f1 0.9515	weighted_f1:0.9516
dev	acc: 0.5050	macro: p 0.3485, r 0.2965, f1: 0.2966	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4708
test	acc: 0.5605	macro: p 0.3422, r 0.3114, f1: 0.3096	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5320
global_step: 7401, epoch: 36, loss: 0.353231
global_step: 7402, epoch: 36, loss: 0.339946
global_step: 7403, epoch: 36, loss: 0.380679
global_step: 7404, epoch: 36, loss: 0.352171
global_step: 7405, epoch: 36, loss: 0.421259
global_step: 7406, epoch: 36, loss: 0.246252
global_step: 7407, epoch: 36, loss: 0.301590
global_step: 7408, epoch: 36, loss: 0.417711
global_step: 7409, epoch: 36, loss: 0.420106
global_step: 7410, epoch: 36, loss: 0.365997
global_step: 7411, epoch: 36, loss: 0.465061
global_step: 7412, epoch: 36, loss: 0.406336
global_step: 7413, epoch: 36, loss: 0.405620
global_step: 7414, epoch: 36, loss: 0.411125
global_step: 7415, epoch: 36, loss: 0.422327
global_step: 7416, epoch: 36, loss: 0.371469
global_step: 7417, epoch: 36, loss: 0.319935
global_step: 7418, epoch: 36, loss: 0.270246
global_step: 7419, epoch: 36, loss: 0.439921
global_step: 7420, epoch: 36, loss: 0.357665
global_step: 7421, epoch: 36, loss: 0.391584
global_step: 7422, epoch: 36, loss: 0.431649
global_step: 7423, epoch: 36, loss: 0.336352
global_step: 7424, epoch: 36, loss: 0.343209
global_step: 7425, epoch: 36, loss: 0.390844
global_step: 7426, epoch: 36, loss: 0.360425
global_step: 7427, epoch: 36, loss: 0.328869
global_step: 7428, epoch: 36, loss: 0.342722
global_step: 7429, epoch: 36, loss: 0.434714
global_step: 7430, epoch: 36, loss: 0.390572
global_step: 7431, epoch: 36, loss: 0.335148
global_step: 7432, epoch: 36, loss: 0.425008
global_step: 7433, epoch: 36, loss: 0.474605
global_step: 7434, epoch: 36, loss: 0.322874
global_step: 7435, epoch: 36, loss: 0.426614
global_step: 7436, epoch: 36, loss: 0.455247
global_step: 7437, epoch: 36, loss: 0.430260
global_step: 7438, epoch: 36, loss: 0.336546
global_step: 7439, epoch: 36, loss: 0.511002
global_step: 7440, epoch: 36, loss: 0.852680
epoch: 36
train	acc: 0.9560	macro: p 0.9588, r 0.9336, f1: 0.9454	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9559
dev	acc: 0.5212	macro: p 0.3820, r 0.2953, f1: 0.2983	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4796
test	acc: 0.5759	macro: p 0.3723, r 0.3148, f1: 0.3200	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5400
global_step: 7441, epoch: 37, loss: 0.383963
global_step: 7442, epoch: 37, loss: 0.333711
global_step: 7443, epoch: 37, loss: 0.356401
global_step: 7444, epoch: 37, loss: 0.343557
global_step: 7445, epoch: 37, loss: 0.319127
global_step: 7446, epoch: 37, loss: 0.475468
global_step: 7447, epoch: 37, loss: 0.529348
global_step: 7448, epoch: 37, loss: 0.402157
global_step: 7449, epoch: 37, loss: 0.276616
global_step: 7450, epoch: 37, loss: 0.451195
global_step: 7451, epoch: 37, loss: 0.349198
global_step: 7452, epoch: 37, loss: 0.329800
global_step: 7453, epoch: 37, loss: 0.471140
global_step: 7454, epoch: 37, loss: 0.330155
global_step: 7455, epoch: 37, loss: 0.347586
global_step: 7456, epoch: 37, loss: 0.290814
global_step: 7457, epoch: 37, loss: 0.351471
global_step: 7458, epoch: 37, loss: 0.299846
global_step: 7459, epoch: 37, loss: 0.362306
global_step: 7460, epoch: 37, loss: 0.319259
global_step: 7461, epoch: 37, loss: 0.412023
global_step: 7462, epoch: 37, loss: 0.370893
global_step: 7463, epoch: 37, loss: 0.370444
global_step: 7464, epoch: 37, loss: 0.403242
global_step: 7465, epoch: 37, loss: 0.408573
global_step: 7466, epoch: 37, loss: 0.423893
global_step: 7467, epoch: 37, loss: 0.294709
global_step: 7468, epoch: 37, loss: 0.308771
global_step: 7469, epoch: 37, loss: 0.360031
global_step: 7470, epoch: 37, loss: 0.401868
global_step: 7471, epoch: 37, loss: 0.409511
global_step: 7472, epoch: 37, loss: 0.475943
global_step: 7473, epoch: 37, loss: 0.412446
global_step: 7474, epoch: 37, loss: 0.414446
global_step: 7475, epoch: 37, loss: 0.457719
global_step: 7476, epoch: 37, loss: 0.481226
global_step: 7477, epoch: 37, loss: 0.338073
global_step: 7478, epoch: 37, loss: 0.413897
global_step: 7479, epoch: 37, loss: 0.404732
global_step: 7480, epoch: 37, loss: 0.038695
epoch: 37
train	acc: 0.9504	macro: p 0.9646, r 0.9249, f1: 0.9436	micro: p 0.9504, r 0.9504, f1 0.9504	weighted_f1:0.9502
dev	acc: 0.5257	macro: p 0.3753, r 0.2894, f1: 0.2920	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4744
test	acc: 0.5782	macro: p 0.3687, r 0.2981, f1: 0.3021	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5313
global_step: 7481, epoch: 38, loss: 0.313724
global_step: 7482, epoch: 38, loss: 0.384957
global_step: 7483, epoch: 38, loss: 0.343348
global_step: 7484, epoch: 38, loss: 0.379489
global_step: 7485, epoch: 38, loss: 0.280598
global_step: 7486, epoch: 38, loss: 0.387361
global_step: 7487, epoch: 38, loss: 0.351321
global_step: 7488, epoch: 38, loss: 0.329609
global_step: 7489, epoch: 38, loss: 0.360259
global_step: 7490, epoch: 38, loss: 0.333573
global_step: 7491, epoch: 38, loss: 0.299573
global_step: 7492, epoch: 38, loss: 0.336136
global_step: 7493, epoch: 38, loss: 0.364074
global_step: 7494, epoch: 38, loss: 0.358960
global_step: 7495, epoch: 38, loss: 0.283919
global_step: 7496, epoch: 38, loss: 0.302688
global_step: 7497, epoch: 38, loss: 0.385776
global_step: 7498, epoch: 38, loss: 0.425250
global_step: 7499, epoch: 38, loss: 0.345390
global_step: 7500, epoch: 38, loss: 0.319749
global_step: 7501, epoch: 38, loss: 0.319298
global_step: 7502, epoch: 38, loss: 0.314348
global_step: 7503, epoch: 38, loss: 0.313331
global_step: 7504, epoch: 38, loss: 0.410530
global_step: 7505, epoch: 38, loss: 0.345392
global_step: 7506, epoch: 38, loss: 0.414458
global_step: 7507, epoch: 38, loss: 0.346579
global_step: 7508, epoch: 38, loss: 0.381129
global_step: 7509, epoch: 38, loss: 0.382946
global_step: 7510, epoch: 38, loss: 0.368360
global_step: 7511, epoch: 38, loss: 0.384029
global_step: 7512, epoch: 38, loss: 0.348305
global_step: 7513, epoch: 38, loss: 0.469582
global_step: 7514, epoch: 38, loss: 0.305803
global_step: 7515, epoch: 38, loss: 0.391413
global_step: 7516, epoch: 38, loss: 0.383385
global_step: 7517, epoch: 38, loss: 0.439171
global_step: 7518, epoch: 38, loss: 0.479039
global_step: 7519, epoch: 38, loss: 0.433687
global_step: 7520, epoch: 38, loss: 0.541812
epoch: 38
train	acc: 0.9486	macro: p 0.9510, r 0.9318, f1: 0.9397	micro: p 0.9486, r 0.9486, f1 0.9486	weighted_f1:0.9493
dev	acc: 0.5356	macro: p 0.3653, r 0.3253, f1: 0.3239	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.5026
test	acc: 0.5517	macro: p 0.3166, r 0.3064, f1: 0.3018	micro: p 0.5517, r 0.5517, f1 0.5517	weighted_f1:0.5239
New best model!
global_step: 7521, epoch: 39, loss: 0.337285
global_step: 7522, epoch: 39, loss: 0.294670
global_step: 7523, epoch: 39, loss: 0.300960
global_step: 7524, epoch: 39, loss: 0.374716
global_step: 7525, epoch: 39, loss: 0.255257
global_step: 7526, epoch: 39, loss: 0.307051
global_step: 7527, epoch: 39, loss: 0.375801
global_step: 7528, epoch: 39, loss: 0.378557
global_step: 7529, epoch: 39, loss: 0.339482
global_step: 7530, epoch: 39, loss: 0.368472
global_step: 7531, epoch: 39, loss: 0.336640
global_step: 7532, epoch: 39, loss: 0.371749
global_step: 7533, epoch: 39, loss: 0.368533
global_step: 7534, epoch: 39, loss: 0.323213
global_step: 7535, epoch: 39, loss: 0.326026
global_step: 7536, epoch: 39, loss: 0.381671
global_step: 7537, epoch: 39, loss: 0.299642
global_step: 7538, epoch: 39, loss: 0.331234
global_step: 7539, epoch: 39, loss: 0.367582
global_step: 7540, epoch: 39, loss: 0.310041
global_step: 7541, epoch: 39, loss: 0.438744
global_step: 7542, epoch: 39, loss: 0.413931
global_step: 7543, epoch: 39, loss: 0.407052
global_step: 7544, epoch: 39, loss: 0.394068
global_step: 7545, epoch: 39, loss: 0.347717
global_step: 7546, epoch: 39, loss: 0.411741
global_step: 7547, epoch: 39, loss: 0.330888
global_step: 7548, epoch: 39, loss: 0.347764
global_step: 7549, epoch: 39, loss: 0.344449
global_step: 7550, epoch: 39, loss: 0.422869
global_step: 7551, epoch: 39, loss: 0.422727
global_step: 7552, epoch: 39, loss: 0.366948
global_step: 7553, epoch: 39, loss: 0.361891
global_step: 7554, epoch: 39, loss: 0.384092
global_step: 7555, epoch: 39, loss: 0.380141
global_step: 7556, epoch: 39, loss: 0.320074
global_step: 7557, epoch: 39, loss: 0.285205
global_step: 7558, epoch: 39, loss: 0.420066
global_step: 7559, epoch: 39, loss: 0.386095
global_step: 7560, epoch: 39, loss: 0.054917
epoch: 39
train	acc: 0.9596	macro: p 0.9654, r 0.9441, f1: 0.9543	micro: p 0.9596, r 0.9596, f1 0.9596	weighted_f1:0.9596
dev	acc: 0.5302	macro: p 0.3731, r 0.3011, f1: 0.3063	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4828
test	acc: 0.5785	macro: p 0.3859, r 0.3134, f1: 0.3229	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5347
global_step: 7561, epoch: 40, loss: 0.381624
global_step: 7562, epoch: 40, loss: 0.412157
global_step: 7563, epoch: 40, loss: 0.283418
global_step: 7564, epoch: 40, loss: 0.340463
global_step: 7565, epoch: 40, loss: 0.308206
global_step: 7566, epoch: 40, loss: 0.388352
global_step: 7567, epoch: 40, loss: 0.333476
global_step: 7568, epoch: 40, loss: 0.412049
global_step: 7569, epoch: 40, loss: 0.386978
global_step: 7570, epoch: 40, loss: 0.396004
global_step: 7571, epoch: 40, loss: 0.284454
global_step: 7572, epoch: 40, loss: 0.299751
global_step: 7573, epoch: 40, loss: 0.312953
global_step: 7574, epoch: 40, loss: 0.348715
global_step: 7575, epoch: 40, loss: 0.306090
global_step: 7576, epoch: 40, loss: 0.362536
global_step: 7577, epoch: 40, loss: 0.378044
global_step: 7578, epoch: 40, loss: 0.299086
global_step: 7579, epoch: 40, loss: 0.478227
global_step: 7580, epoch: 40, loss: 0.354694
global_step: 7581, epoch: 40, loss: 0.385663
global_step: 7582, epoch: 40, loss: 0.326535
global_step: 7583, epoch: 40, loss: 0.381071
global_step: 7584, epoch: 40, loss: 0.353694
global_step: 7585, epoch: 40, loss: 0.388991
global_step: 7586, epoch: 40, loss: 0.329501
global_step: 7587, epoch: 40, loss: 0.347766
global_step: 7588, epoch: 40, loss: 0.336426
global_step: 7589, epoch: 40, loss: 0.379772
global_step: 7590, epoch: 40, loss: 0.360776
global_step: 7591, epoch: 40, loss: 0.374001
global_step: 7592, epoch: 40, loss: 0.344274
global_step: 7593, epoch: 40, loss: 0.312853
global_step: 7594, epoch: 40, loss: 0.467792
global_step: 7595, epoch: 40, loss: 0.280161
global_step: 7596, epoch: 40, loss: 0.470516
global_step: 7597, epoch: 40, loss: 0.358947
global_step: 7598, epoch: 40, loss: 0.362807
global_step: 7599, epoch: 40, loss: 0.393810
global_step: 7600, epoch: 40, loss: 0.026538
epoch: 40
train	acc: 0.9573	macro: p 0.9646, r 0.9391, f1: 0.9514	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9572
dev	acc: 0.5194	macro: p 0.3431, r 0.2874, f1: 0.2909	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4699
test	acc: 0.5762	macro: p 0.3797, r 0.3074, f1: 0.3185	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5340
global_step: 7601, epoch: 41, loss: 0.267216
global_step: 7602, epoch: 41, loss: 0.335145
global_step: 7603, epoch: 41, loss: 0.286463
global_step: 7604, epoch: 41, loss: 0.382198
global_step: 7605, epoch: 41, loss: 0.312754
global_step: 7606, epoch: 41, loss: 0.386035
global_step: 7607, epoch: 41, loss: 0.392906
global_step: 7608, epoch: 41, loss: 0.323922
global_step: 7609, epoch: 41, loss: 0.318649
global_step: 7610, epoch: 41, loss: 0.370462
global_step: 7611, epoch: 41, loss: 0.312924
global_step: 7612, epoch: 41, loss: 0.305702
global_step: 7613, epoch: 41, loss: 0.320616
global_step: 7614, epoch: 41, loss: 0.355875
global_step: 7615, epoch: 41, loss: 0.414461
global_step: 7616, epoch: 41, loss: 0.369135
global_step: 7617, epoch: 41, loss: 0.304367
global_step: 7618, epoch: 41, loss: 0.267522
global_step: 7619, epoch: 41, loss: 0.387554
global_step: 7620, epoch: 41, loss: 0.322259
global_step: 7621, epoch: 41, loss: 0.479763
global_step: 7622, epoch: 41, loss: 0.406568
global_step: 7623, epoch: 41, loss: 0.345726
global_step: 7624, epoch: 41, loss: 0.314560
global_step: 7625, epoch: 41, loss: 0.328156
global_step: 7626, epoch: 41, loss: 0.423463
global_step: 7627, epoch: 41, loss: 0.355418
global_step: 7628, epoch: 41, loss: 0.478661
global_step: 7629, epoch: 41, loss: 0.395443
global_step: 7630, epoch: 41, loss: 0.367707
global_step: 7631, epoch: 41, loss: 0.403860
global_step: 7632, epoch: 41, loss: 0.355333
global_step: 7633, epoch: 41, loss: 0.448117
global_step: 7634, epoch: 41, loss: 0.419248
global_step: 7635, epoch: 41, loss: 0.376050
global_step: 7636, epoch: 41, loss: 0.382628
global_step: 7637, epoch: 41, loss: 0.350508
global_step: 7638, epoch: 41, loss: 0.429552
global_step: 7639, epoch: 41, loss: 0.455963
global_step: 7640, epoch: 41, loss: 0.104378
epoch: 41
train	acc: 0.9494	macro: p 0.9542, r 0.9338, f1: 0.9431	micro: p 0.9494, r 0.9494, f1 0.9494	weighted_f1:0.9497
dev	acc: 0.5248	macro: p 0.3637, r 0.3087, f1: 0.3100	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4900
test	acc: 0.5590	macro: p 0.3629, r 0.3111, f1: 0.3146	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5307
global_step: 7641, epoch: 42, loss: 0.440775
global_step: 7642, epoch: 42, loss: 0.282241
global_step: 7643, epoch: 42, loss: 0.341420
global_step: 7644, epoch: 42, loss: 0.262744
global_step: 7645, epoch: 42, loss: 0.346191
global_step: 7646, epoch: 42, loss: 0.390599
global_step: 7647, epoch: 42, loss: 0.415221
global_step: 7648, epoch: 42, loss: 0.373284
global_step: 7649, epoch: 42, loss: 0.394414
global_step: 7650, epoch: 42, loss: 0.303384
global_step: 7651, epoch: 42, loss: 0.283943
global_step: 7652, epoch: 42, loss: 0.360179
global_step: 7653, epoch: 42, loss: 0.270604
global_step: 7654, epoch: 42, loss: 0.306054
global_step: 7655, epoch: 42, loss: 0.331584
global_step: 7656, epoch: 42, loss: 0.304514
global_step: 7657, epoch: 42, loss: 0.331406
global_step: 7658, epoch: 42, loss: 0.341927
global_step: 7659, epoch: 42, loss: 0.427928
global_step: 7660, epoch: 42, loss: 0.383113
global_step: 7661, epoch: 42, loss: 0.309999
global_step: 7662, epoch: 42, loss: 0.377532
global_step: 7663, epoch: 42, loss: 0.508339
global_step: 7664, epoch: 42, loss: 0.446370
global_step: 7665, epoch: 42, loss: 0.317177
global_step: 7666, epoch: 42, loss: 0.417791
global_step: 7667, epoch: 42, loss: 0.290742
global_step: 7668, epoch: 42, loss: 0.292537
global_step: 7669, epoch: 42, loss: 0.384289
global_step: 7670, epoch: 42, loss: 0.360219
global_step: 7671, epoch: 42, loss: 0.358011
global_step: 7672, epoch: 42, loss: 0.380346
global_step: 7673, epoch: 42, loss: 0.364002
global_step: 7674, epoch: 42, loss: 0.341618
global_step: 7675, epoch: 42, loss: 0.273779
global_step: 7676, epoch: 42, loss: 0.324136
global_step: 7677, epoch: 42, loss: 0.399675
global_step: 7678, epoch: 42, loss: 0.285000
global_step: 7679, epoch: 42, loss: 0.399195
global_step: 7680, epoch: 42, loss: 0.258675
epoch: 42
train	acc: 0.9560	macro: p 0.9622, r 0.9375, f1: 0.9493	micro: p 0.9560, r 0.9560, f1 0.9560	weighted_f1:0.9559
dev	acc: 0.5302	macro: p 0.3606, r 0.3061, f1: 0.3088	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4853
test	acc: 0.5728	macro: p 0.3791, r 0.3129, f1: 0.3209	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5332
global_step: 7681, epoch: 43, loss: 0.421580
global_step: 7682, epoch: 43, loss: 0.298222
global_step: 7683, epoch: 43, loss: 0.388275
global_step: 7684, epoch: 43, loss: 0.326345
global_step: 7685, epoch: 43, loss: 0.280002
global_step: 7686, epoch: 43, loss: 0.296644
global_step: 7687, epoch: 43, loss: 0.332386
global_step: 7688, epoch: 43, loss: 0.324829
global_step: 7689, epoch: 43, loss: 0.380211
global_step: 7690, epoch: 43, loss: 0.279505
global_step: 7691, epoch: 43, loss: 0.317621
global_step: 7692, epoch: 43, loss: 0.342685
global_step: 7693, epoch: 43, loss: 0.319099
global_step: 7694, epoch: 43, loss: 0.321661
global_step: 7695, epoch: 43, loss: 0.299859
global_step: 7696, epoch: 43, loss: 0.323698
global_step: 7697, epoch: 43, loss: 0.328634
global_step: 7698, epoch: 43, loss: 0.347018
global_step: 7699, epoch: 43, loss: 0.276724
global_step: 7700, epoch: 43, loss: 0.366830
global_step: 7701, epoch: 43, loss: 0.380703
global_step: 7702, epoch: 43, loss: 0.360241
global_step: 7703, epoch: 43, loss: 0.443864
global_step: 7704, epoch: 43, loss: 0.316665
global_step: 7705, epoch: 43, loss: 0.343634
global_step: 7706, epoch: 43, loss: 0.347089
global_step: 7707, epoch: 43, loss: 0.331928
global_step: 7708, epoch: 43, loss: 0.302613
global_step: 7709, epoch: 43, loss: 0.378206
global_step: 7710, epoch: 43, loss: 0.303443
global_step: 7711, epoch: 43, loss: 0.305342
global_step: 7712, epoch: 43, loss: 0.286616
global_step: 7713, epoch: 43, loss: 0.423049
global_step: 7714, epoch: 43, loss: 0.440495
global_step: 7715, epoch: 43, loss: 0.333549
global_step: 7716, epoch: 43, loss: 0.341085
global_step: 7717, epoch: 43, loss: 0.331043
global_step: 7718, epoch: 43, loss: 0.247073
global_step: 7719, epoch: 43, loss: 0.306347
global_step: 7720, epoch: 43, loss: 0.110133
epoch: 43
train	acc: 0.9553	macro: p 0.9603, r 0.9337, f1: 0.9462	micro: p 0.9553, r 0.9553, f1 0.9553	weighted_f1:0.9552
dev	acc: 0.5203	macro: p 0.3562, r 0.2951, f1: 0.2982	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4723
test	acc: 0.5686	macro: p 0.3835, r 0.3018, f1: 0.3145	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5257
global_step: 7721, epoch: 44, loss: 0.329606
global_step: 7722, epoch: 44, loss: 0.387300
global_step: 7723, epoch: 44, loss: 0.331586
global_step: 7724, epoch: 44, loss: 0.282681
global_step: 7725, epoch: 44, loss: 0.399860
global_step: 7726, epoch: 44, loss: 0.298414
global_step: 7727, epoch: 44, loss: 0.437495
global_step: 7728, epoch: 44, loss: 0.347748
global_step: 7729, epoch: 44, loss: 0.348085
global_step: 7730, epoch: 44, loss: 0.281483
global_step: 7731, epoch: 44, loss: 0.313981
global_step: 7732, epoch: 44, loss: 0.394680
global_step: 7733, epoch: 44, loss: 0.358790
global_step: 7734, epoch: 44, loss: 0.278008
global_step: 7735, epoch: 44, loss: 0.358945
global_step: 7736, epoch: 44, loss: 0.390191
global_step: 7737, epoch: 44, loss: 0.288449
global_step: 7738, epoch: 44, loss: 0.316700
global_step: 7739, epoch: 44, loss: 0.349789
global_step: 7740, epoch: 44, loss: 0.392302
global_step: 7741, epoch: 44, loss: 0.369329
global_step: 7742, epoch: 44, loss: 0.262800
global_step: 7743, epoch: 44, loss: 0.284430
global_step: 7744, epoch: 44, loss: 0.360499
global_step: 7745, epoch: 44, loss: 0.309605
global_step: 7746, epoch: 44, loss: 0.318983
global_step: 7747, epoch: 44, loss: 0.311082
global_step: 7748, epoch: 44, loss: 0.380791
global_step: 7749, epoch: 44, loss: 0.531355
global_step: 7750, epoch: 44, loss: 0.353351
global_step: 7751, epoch: 44, loss: 0.328497
global_step: 7752, epoch: 44, loss: 0.281628
global_step: 7753, epoch: 44, loss: 0.405708
global_step: 7754, epoch: 44, loss: 0.377976
global_step: 7755, epoch: 44, loss: 0.388210
global_step: 7756, epoch: 44, loss: 0.320694
global_step: 7757, epoch: 44, loss: 0.400889
global_step: 7758, epoch: 44, loss: 0.453820
global_step: 7759, epoch: 44, loss: 0.374677
global_step: 7760, epoch: 44, loss: 0.120794
epoch: 44
train	acc: 0.9442	macro: p 0.9549, r 0.9245, f1: 0.9377	micro: p 0.9442, r 0.9442, f1 0.9442	weighted_f1:0.9449
dev	acc: 0.5059	macro: p 0.3344, r 0.2967, f1: 0.2893	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4649
test	acc: 0.5433	macro: p 0.3449, r 0.2965, f1: 0.2910	micro: p 0.5433, r 0.5433, f1 0.5433	weighted_f1:0.5080
global_step: 7761, epoch: 45, loss: 0.396874
global_step: 7762, epoch: 45, loss: 0.439125
global_step: 7763, epoch: 45, loss: 0.258277
global_step: 7764, epoch: 45, loss: 0.242231
global_step: 7765, epoch: 45, loss: 0.403328
global_step: 7766, epoch: 45, loss: 0.328381
global_step: 7767, epoch: 45, loss: 0.300844
global_step: 7768, epoch: 45, loss: 0.339640
global_step: 7769, epoch: 45, loss: 0.282819
global_step: 7770, epoch: 45, loss: 0.203114
global_step: 7771, epoch: 45, loss: 0.319250
global_step: 7772, epoch: 45, loss: 0.365215
global_step: 7773, epoch: 45, loss: 0.337487
global_step: 7774, epoch: 45, loss: 0.460541
global_step: 7775, epoch: 45, loss: 0.353869
global_step: 7776, epoch: 45, loss: 0.404344
global_step: 7777, epoch: 45, loss: 0.288279
global_step: 7778, epoch: 45, loss: 0.362550
global_step: 7779, epoch: 45, loss: 0.374360
global_step: 7780, epoch: 45, loss: 0.299262
global_step: 7781, epoch: 45, loss: 0.322972
global_step: 7782, epoch: 45, loss: 0.373865
global_step: 7783, epoch: 45, loss: 0.231387
global_step: 7784, epoch: 45, loss: 0.401584
global_step: 7785, epoch: 45, loss: 0.407510
global_step: 7786, epoch: 45, loss: 0.320679
global_step: 7787, epoch: 45, loss: 0.383172
global_step: 7788, epoch: 45, loss: 0.378929
global_step: 7789, epoch: 45, loss: 0.373940
global_step: 7790, epoch: 45, loss: 0.401782
global_step: 7791, epoch: 45, loss: 0.352681
global_step: 7792, epoch: 45, loss: 0.364641
global_step: 7793, epoch: 45, loss: 0.311158
global_step: 7794, epoch: 45, loss: 0.342167
global_step: 7795, epoch: 45, loss: 0.322122
global_step: 7796, epoch: 45, loss: 0.393973
global_step: 7797, epoch: 45, loss: 0.356996
global_step: 7798, epoch: 45, loss: 0.223412
global_step: 7799, epoch: 45, loss: 0.248658
global_step: 7800, epoch: 45, loss: 0.100496
epoch: 45
train	acc: 0.9596	macro: p 0.9650, r 0.9435, f1: 0.9537	micro: p 0.9596, r 0.9596, f1 0.9596	weighted_f1:0.9596
dev	acc: 0.5077	macro: p 0.3610, r 0.3059, f1: 0.3083	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4769
test	acc: 0.5521	macro: p 0.3331, r 0.3058, f1: 0.3081	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.5272
global_step: 7801, epoch: 46, loss: 0.356793
global_step: 7802, epoch: 46, loss: 0.296822
global_step: 7803, epoch: 46, loss: 0.257768
global_step: 7804, epoch: 46, loss: 0.305643
global_step: 7805, epoch: 46, loss: 0.398040
global_step: 7806, epoch: 46, loss: 0.376243
global_step: 7807, epoch: 46, loss: 0.351408
global_step: 7808, epoch: 46, loss: 0.322612
global_step: 7809, epoch: 46, loss: 0.398025
global_step: 7810, epoch: 46, loss: 0.357008
global_step: 7811, epoch: 46, loss: 0.233507
global_step: 7812, epoch: 46, loss: 0.287570
global_step: 7813, epoch: 46, loss: 0.324434
global_step: 7814, epoch: 46, loss: 0.347306
global_step: 7815, epoch: 46, loss: 0.364499
global_step: 7816, epoch: 46, loss: 0.312571
global_step: 7817, epoch: 46, loss: 0.375416
global_step: 7818, epoch: 46, loss: 0.266529
global_step: 7819, epoch: 46, loss: 0.253616
global_step: 7820, epoch: 46, loss: 0.340568
global_step: 7821, epoch: 46, loss: 0.439567
global_step: 7822, epoch: 46, loss: 0.338317
global_step: 7823, epoch: 46, loss: 0.380488
global_step: 7824, epoch: 46, loss: 0.366605
global_step: 7825, epoch: 46, loss: 0.392112
global_step: 7826, epoch: 46, loss: 0.277030
global_step: 7827, epoch: 46, loss: 0.314696
global_step: 7828, epoch: 46, loss: 0.417968
global_step: 7829, epoch: 46, loss: 0.376233
global_step: 7830, epoch: 46, loss: 0.326723
global_step: 7831, epoch: 46, loss: 0.280248
global_step: 7832, epoch: 46, loss: 0.369423
global_step: 7833, epoch: 46, loss: 0.264223
global_step: 7834, epoch: 46, loss: 0.329975
global_step: 7835, epoch: 46, loss: 0.328886
global_step: 7836, epoch: 46, loss: 0.264619
global_step: 7837, epoch: 46, loss: 0.317914
global_step: 7838, epoch: 46, loss: 0.355075
global_step: 7839, epoch: 46, loss: 0.394055
global_step: 7840, epoch: 46, loss: 0.069041
epoch: 46
train	acc: 0.9604	macro: p 0.9649, r 0.9473, f1: 0.9556	micro: p 0.9604, r 0.9604, f1 0.9604	weighted_f1:0.9604
dev	acc: 0.5149	macro: p 0.3782, r 0.3044, f1: 0.3133	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4817
test	acc: 0.5678	macro: p 0.3576, r 0.3169, f1: 0.3229	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5402
global_step: 7841, epoch: 47, loss: 0.493605
global_step: 7842, epoch: 47, loss: 0.235459
global_step: 7843, epoch: 47, loss: 0.309493
global_step: 7844, epoch: 47, loss: 0.214176
global_step: 7845, epoch: 47, loss: 0.305296
global_step: 7846, epoch: 47, loss: 0.383081
global_step: 7847, epoch: 47, loss: 0.364141
global_step: 7848, epoch: 47, loss: 0.319934
global_step: 7849, epoch: 47, loss: 0.234957
global_step: 7850, epoch: 47, loss: 0.283712
global_step: 7851, epoch: 47, loss: 0.290679
global_step: 7852, epoch: 47, loss: 0.257418
global_step: 7853, epoch: 47, loss: 0.240973
global_step: 7854, epoch: 47, loss: 0.319997
global_step: 7855, epoch: 47, loss: 0.321955
global_step: 7856, epoch: 47, loss: 0.380347
global_step: 7857, epoch: 47, loss: 0.303535
global_step: 7858, epoch: 47, loss: 0.209313
global_step: 7859, epoch: 47, loss: 0.332772
global_step: 7860, epoch: 47, loss: 0.313637
global_step: 7861, epoch: 47, loss: 0.286378
global_step: 7862, epoch: 47, loss: 0.329564
global_step: 7863, epoch: 47, loss: 0.331234
global_step: 7864, epoch: 47, loss: 0.270186
global_step: 7865, epoch: 47, loss: 0.327132
global_step: 7866, epoch: 47, loss: 0.420039
global_step: 7867, epoch: 47, loss: 0.392531
global_step: 7868, epoch: 47, loss: 0.417161
global_step: 7869, epoch: 47, loss: 0.376048
global_step: 7870, epoch: 47, loss: 0.452483
global_step: 7871, epoch: 47, loss: 0.374988
global_step: 7872, epoch: 47, loss: 0.365232
global_step: 7873, epoch: 47, loss: 0.330158
global_step: 7874, epoch: 47, loss: 0.329452
global_step: 7875, epoch: 47, loss: 0.421931
global_step: 7876, epoch: 47, loss: 0.302252
global_step: 7877, epoch: 47, loss: 0.363686
global_step: 7878, epoch: 47, loss: 0.247826
global_step: 7879, epoch: 47, loss: 0.290696
global_step: 7880, epoch: 47, loss: 0.040034
epoch: 47
train	acc: 0.9605	macro: p 0.9699, r 0.9446, f1: 0.9569	micro: p 0.9605, r 0.9605, f1 0.9605	weighted_f1:0.9604
dev	acc: 0.5068	macro: p 0.3384, r 0.2883, f1: 0.2919	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4665
test	acc: 0.5690	macro: p 0.4076, r 0.3111, f1: 0.3230	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5304
global_step: 7881, epoch: 48, loss: 0.345546
global_step: 7882, epoch: 48, loss: 0.205173
global_step: 7883, epoch: 48, loss: 0.309658
global_step: 7884, epoch: 48, loss: 0.216002
global_step: 7885, epoch: 48, loss: 0.323148
global_step: 7886, epoch: 48, loss: 0.276330
global_step: 7887, epoch: 48, loss: 0.269165
global_step: 7888, epoch: 48, loss: 0.227371
global_step: 7889, epoch: 48, loss: 0.335133
global_step: 7890, epoch: 48, loss: 0.241437
global_step: 7891, epoch: 48, loss: 0.419829
global_step: 7892, epoch: 48, loss: 0.265746
global_step: 7893, epoch: 48, loss: 0.315148
global_step: 7894, epoch: 48, loss: 0.238768
global_step: 7895, epoch: 48, loss: 0.325257
global_step: 7896, epoch: 48, loss: 0.389553
global_step: 7897, epoch: 48, loss: 0.369573
global_step: 7898, epoch: 48, loss: 0.333083
global_step: 7899, epoch: 48, loss: 0.266328
global_step: 7900, epoch: 48, loss: 0.322387
global_step: 7901, epoch: 48, loss: 0.229792
global_step: 7902, epoch: 48, loss: 0.295786
global_step: 7903, epoch: 48, loss: 0.287918
global_step: 7904, epoch: 48, loss: 0.269951
global_step: 7905, epoch: 48, loss: 0.273823
global_step: 7906, epoch: 48, loss: 0.356891
global_step: 7907, epoch: 48, loss: 0.378430
global_step: 7908, epoch: 48, loss: 0.332790
global_step: 7909, epoch: 48, loss: 0.287988
global_step: 7910, epoch: 48, loss: 0.342828
global_step: 7911, epoch: 48, loss: 0.297687
global_step: 7912, epoch: 48, loss: 0.275768
global_step: 7913, epoch: 48, loss: 0.314746
global_step: 7914, epoch: 48, loss: 0.274766
global_step: 7915, epoch: 48, loss: 0.337573
global_step: 7916, epoch: 48, loss: 0.363200
global_step: 7917, epoch: 48, loss: 0.396629
global_step: 7918, epoch: 48, loss: 0.458851
global_step: 7919, epoch: 48, loss: 0.340287
global_step: 7920, epoch: 48, loss: 0.683669
epoch: 48
train	acc: 0.9482	macro: p 0.9509, r 0.9475, f1: 0.9484	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9488
dev	acc: 0.4680	macro: p 0.3207, r 0.3163, f1: 0.3095	micro: p 0.4680, r 0.4680, f1 0.4680	weighted_f1:0.4634
test	acc: 0.4904	macro: p 0.3124, r 0.3139, f1: 0.3011	micro: p 0.4904, r 0.4904, f1 0.4904	weighted_f1:0.4904
global_step: 7921, epoch: 49, loss: 0.331024
global_step: 7922, epoch: 49, loss: 0.345094
global_step: 7923, epoch: 49, loss: 0.288606
global_step: 7924, epoch: 49, loss: 0.285884
global_step: 7925, epoch: 49, loss: 0.213761
global_step: 7926, epoch: 49, loss: 0.252934
global_step: 7927, epoch: 49, loss: 0.259476
global_step: 7928, epoch: 49, loss: 0.322662
global_step: 7929, epoch: 49, loss: 0.320096
global_step: 7930, epoch: 49, loss: 0.335172
global_step: 7931, epoch: 49, loss: 0.281576
global_step: 7932, epoch: 49, loss: 0.211855
global_step: 7933, epoch: 49, loss: 0.275600
global_step: 7934, epoch: 49, loss: 0.346738
global_step: 7935, epoch: 49, loss: 0.294265
global_step: 7936, epoch: 49, loss: 0.278518
global_step: 7937, epoch: 49, loss: 0.249402
global_step: 7938, epoch: 49, loss: 0.294114
global_step: 7939, epoch: 49, loss: 0.276017
global_step: 7940, epoch: 49, loss: 0.398036
global_step: 7941, epoch: 49, loss: 0.241114
global_step: 7942, epoch: 49, loss: 0.284703
global_step: 7943, epoch: 49, loss: 0.283522
global_step: 7944, epoch: 49, loss: 0.263602
global_step: 7945, epoch: 49, loss: 0.276551
global_step: 7946, epoch: 49, loss: 0.258558
global_step: 7947, epoch: 49, loss: 0.296694
global_step: 7948, epoch: 49, loss: 0.299005
global_step: 7949, epoch: 49, loss: 0.399530
global_step: 7950, epoch: 49, loss: 0.322653
global_step: 7951, epoch: 49, loss: 0.287480
global_step: 7952, epoch: 49, loss: 0.327049
global_step: 7953, epoch: 49, loss: 0.326238
global_step: 7954, epoch: 49, loss: 0.246001
global_step: 7955, epoch: 49, loss: 0.309515
global_step: 7956, epoch: 49, loss: 0.264952
global_step: 7957, epoch: 49, loss: 0.364908
global_step: 7958, epoch: 49, loss: 0.370901
global_step: 7959, epoch: 49, loss: 0.364727
global_step: 7960, epoch: 49, loss: 0.154130
epoch: 49
train	acc: 0.9608	macro: p 0.9669, r 0.9456, f1: 0.9557	micro: p 0.9608, r 0.9608, f1 0.9608	weighted_f1:0.9608
dev	acc: 0.5212	macro: p 0.3696, r 0.2973, f1: 0.2967	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4741
test	acc: 0.5736	macro: p 0.3676, r 0.3074, f1: 0.3112	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5275
global_step: 7961, epoch: 50, loss: 0.254344
global_step: 7962, epoch: 50, loss: 0.347102
global_step: 7963, epoch: 50, loss: 0.328544
global_step: 7964, epoch: 50, loss: 0.329524
global_step: 7965, epoch: 50, loss: 0.315362
global_step: 7966, epoch: 50, loss: 0.283344
global_step: 7967, epoch: 50, loss: 0.265428
global_step: 7968, epoch: 50, loss: 0.267657
global_step: 7969, epoch: 50, loss: 0.288935
global_step: 7970, epoch: 50, loss: 0.250173
global_step: 7971, epoch: 50, loss: 0.224340
global_step: 7972, epoch: 50, loss: 0.266404
global_step: 7973, epoch: 50, loss: 0.345281
global_step: 7974, epoch: 50, loss: 0.388042
global_step: 7975, epoch: 50, loss: 0.311192
global_step: 7976, epoch: 50, loss: 0.338523
global_step: 7977, epoch: 50, loss: 0.383979
global_step: 7978, epoch: 50, loss: 0.266836
global_step: 7979, epoch: 50, loss: 0.311158
global_step: 7980, epoch: 50, loss: 0.268667
global_step: 7981, epoch: 50, loss: 0.248919
global_step: 7982, epoch: 50, loss: 0.302253
global_step: 7983, epoch: 50, loss: 0.316136
global_step: 7984, epoch: 50, loss: 0.298750
global_step: 7985, epoch: 50, loss: 0.277827
global_step: 7986, epoch: 50, loss: 0.315726
global_step: 7987, epoch: 50, loss: 0.277088
global_step: 7988, epoch: 50, loss: 0.235548
global_step: 7989, epoch: 50, loss: 0.279178
global_step: 7990, epoch: 50, loss: 0.382365
global_step: 7991, epoch: 50, loss: 0.285703
global_step: 7992, epoch: 50, loss: 0.302770
global_step: 7993, epoch: 50, loss: 0.332950
global_step: 7994, epoch: 50, loss: 0.420328
global_step: 7995, epoch: 50, loss: 0.343528
global_step: 7996, epoch: 50, loss: 0.516744
global_step: 7997, epoch: 50, loss: 0.400340
global_step: 7998, epoch: 50, loss: 0.385654
global_step: 7999, epoch: 50, loss: 0.340671
global_step: 8000, epoch: 50, loss: 0.076118
epoch: 50
train	acc: 0.9644	macro: p 0.9668, r 0.9514, f1: 0.9589	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.5266	macro: p 0.3454, r 0.3091, f1: 0.3128	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4901
test	acc: 0.5663	macro: p 0.3445, r 0.3126, f1: 0.3174	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5354
BEST MODEL epoch: 38
train	acc: 0.9486 macro_p: 0.9510 macro_r: 0.9318 macro_f1: 0.9397 micro_p: 0.9486 micro_r: 0.9486 micro_f1: 0.9486 weighted_f1: 0.9493
dev	acc: 0.5356 macro_p: 0.3653 macro_r: 0.3253 macro_f1: 0.3239 micro_p: 0.5356 micro_r: 0.5356 micro_f1: 0.5356 weighted_f1: 0.5026
test	acc: 0.5517 macro_p: 0.3166 macro_r: 0.3064 macro_f1: 0.3018 micro_p: 0.5517 micro_r: 0.5517 micro_f1: 0.5517 weighted_f1: 0.5239
==========ROUND 5==========
global_step: 8001, epoch: 1, loss: 1.998783
global_step: 8002, epoch: 1, loss: 1.618148
global_step: 8003, epoch: 1, loss: 1.614145
global_step: 8004, epoch: 1, loss: 1.559093
global_step: 8005, epoch: 1, loss: 1.531831
global_step: 8006, epoch: 1, loss: 1.612271
global_step: 8007, epoch: 1, loss: 1.512133
global_step: 8008, epoch: 1, loss: 1.506956
global_step: 8009, epoch: 1, loss: 1.461868
global_step: 8010, epoch: 1, loss: 1.535458
global_step: 8011, epoch: 1, loss: 1.459290
global_step: 8012, epoch: 1, loss: 1.460137
global_step: 8013, epoch: 1, loss: 1.410990
global_step: 8014, epoch: 1, loss: 1.322793
global_step: 8015, epoch: 1, loss: 1.464681
global_step: 8016, epoch: 1, loss: 1.569709
global_step: 8017, epoch: 1, loss: 1.611592
global_step: 8018, epoch: 1, loss: 1.461063
global_step: 8019, epoch: 1, loss: 1.508876
global_step: 8020, epoch: 1, loss: 1.423710
global_step: 8021, epoch: 1, loss: 1.358366
global_step: 8022, epoch: 1, loss: 1.396525
global_step: 8023, epoch: 1, loss: 1.292318
global_step: 8024, epoch: 1, loss: 1.423659
global_step: 8025, epoch: 1, loss: 1.397446
global_step: 8026, epoch: 1, loss: 1.412530
global_step: 8027, epoch: 1, loss: 1.314205
global_step: 8028, epoch: 1, loss: 1.492386
global_step: 8029, epoch: 1, loss: 1.420012
global_step: 8030, epoch: 1, loss: 1.516514
global_step: 8031, epoch: 1, loss: 1.474945
global_step: 8032, epoch: 1, loss: 1.322354
global_step: 8033, epoch: 1, loss: 1.390208
global_step: 8034, epoch: 1, loss: 1.489511
global_step: 8035, epoch: 1, loss: 1.411410
global_step: 8036, epoch: 1, loss: 1.360163
global_step: 8037, epoch: 1, loss: 1.349487
global_step: 8038, epoch: 1, loss: 1.313883
global_step: 8039, epoch: 1, loss: 1.352026
global_step: 8040, epoch: 1, loss: 1.276476
epoch: 1
train	acc: 0.5409	macro: p 0.3408, r 0.2124, f1: 0.1797	micro: p 0.5409, r 0.5409, f1 0.5409	weighted_f1:0.4290
dev	acc: 0.4815	macro: p 0.3460, r 0.2092, f1: 0.1630	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.3577
test	acc: 0.5437	macro: p 0.3294, r 0.2142, f1: 0.1770	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4295
New best model!
global_step: 8041, epoch: 2, loss: 1.611091
global_step: 8042, epoch: 2, loss: 1.376774
global_step: 8043, epoch: 2, loss: 1.372190
global_step: 8044, epoch: 2, loss: 1.414278
global_step: 8045, epoch: 2, loss: 1.252596
global_step: 8046, epoch: 2, loss: 1.279429
global_step: 8047, epoch: 2, loss: 1.363943
global_step: 8048, epoch: 2, loss: 1.396084
global_step: 8049, epoch: 2, loss: 1.323869
global_step: 8050, epoch: 2, loss: 1.412457
global_step: 8051, epoch: 2, loss: 1.221120
global_step: 8052, epoch: 2, loss: 1.245860
global_step: 8053, epoch: 2, loss: 1.364410
global_step: 8054, epoch: 2, loss: 1.334516
global_step: 8055, epoch: 2, loss: 1.240577
global_step: 8056, epoch: 2, loss: 1.234149
global_step: 8057, epoch: 2, loss: 1.140863
global_step: 8058, epoch: 2, loss: 1.423306
global_step: 8059, epoch: 2, loss: 1.316220
global_step: 8060, epoch: 2, loss: 1.409997
global_step: 8061, epoch: 2, loss: 1.374525
global_step: 8062, epoch: 2, loss: 1.364062
global_step: 8063, epoch: 2, loss: 1.435856
global_step: 8064, epoch: 2, loss: 1.344319
global_step: 8065, epoch: 2, loss: 1.285143
global_step: 8066, epoch: 2, loss: 1.240321
global_step: 8067, epoch: 2, loss: 1.359288
global_step: 8068, epoch: 2, loss: 1.223029
global_step: 8069, epoch: 2, loss: 1.237729
global_step: 8070, epoch: 2, loss: 1.367710
global_step: 8071, epoch: 2, loss: 1.257535
global_step: 8072, epoch: 2, loss: 1.259881
global_step: 8073, epoch: 2, loss: 1.252132
global_step: 8074, epoch: 2, loss: 1.441612
global_step: 8075, epoch: 2, loss: 1.339558
global_step: 8076, epoch: 2, loss: 1.400600
global_step: 8077, epoch: 2, loss: 1.297613
global_step: 8078, epoch: 2, loss: 1.145423
global_step: 8079, epoch: 2, loss: 1.297838
global_step: 8080, epoch: 2, loss: 1.742224
epoch: 2
train	acc: 0.4481	macro: p 0.4563, r 0.2303, f1: 0.1862	micro: p 0.4481, r 0.4481, f1 0.4481	weighted_f1:0.4022
dev	acc: 0.3950	macro: p 0.2406, r 0.2255, f1: 0.1677	micro: p 0.3950, r 0.3950, f1 0.3950	weighted_f1:0.3421
test	acc: 0.4253	macro: p 0.4022, r 0.2326, f1: 0.1846	micro: p 0.4253, r 0.4253, f1 0.4253	weighted_f1:0.3868
global_step: 8081, epoch: 3, loss: 1.463583
global_step: 8082, epoch: 3, loss: 1.279188
global_step: 8083, epoch: 3, loss: 1.290531
global_step: 8084, epoch: 3, loss: 1.245396
global_step: 8085, epoch: 3, loss: 1.256390
global_step: 8086, epoch: 3, loss: 1.281230
global_step: 8087, epoch: 3, loss: 1.229344
global_step: 8088, epoch: 3, loss: 1.276832
global_step: 8089, epoch: 3, loss: 1.287266
global_step: 8090, epoch: 3, loss: 1.285539
global_step: 8091, epoch: 3, loss: 1.266438
global_step: 8092, epoch: 3, loss: 1.338282
global_step: 8093, epoch: 3, loss: 1.140541
global_step: 8094, epoch: 3, loss: 1.243838
global_step: 8095, epoch: 3, loss: 1.299820
global_step: 8096, epoch: 3, loss: 1.236431
global_step: 8097, epoch: 3, loss: 1.285331
global_step: 8098, epoch: 3, loss: 1.331268
global_step: 8099, epoch: 3, loss: 1.163382
global_step: 8100, epoch: 3, loss: 1.229153
global_step: 8101, epoch: 3, loss: 1.273195
global_step: 8102, epoch: 3, loss: 1.244892
global_step: 8103, epoch: 3, loss: 1.244724
global_step: 8104, epoch: 3, loss: 1.266281
global_step: 8105, epoch: 3, loss: 1.457988
global_step: 8106, epoch: 3, loss: 1.416128
global_step: 8107, epoch: 3, loss: 1.144341
global_step: 8108, epoch: 3, loss: 1.307413
global_step: 8109, epoch: 3, loss: 1.256735
global_step: 8110, epoch: 3, loss: 1.283727
global_step: 8111, epoch: 3, loss: 1.218631
global_step: 8112, epoch: 3, loss: 1.172442
global_step: 8113, epoch: 3, loss: 1.267859
global_step: 8114, epoch: 3, loss: 1.235952
global_step: 8115, epoch: 3, loss: 1.121899
global_step: 8116, epoch: 3, loss: 1.132528
global_step: 8117, epoch: 3, loss: 1.270488
global_step: 8118, epoch: 3, loss: 1.305069
global_step: 8119, epoch: 3, loss: 1.358124
global_step: 8120, epoch: 3, loss: 1.639256
epoch: 3
train	acc: 0.5908	macro: p 0.3813, r 0.3321, f1: 0.3317	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5545
dev	acc: 0.5185	macro: p 0.3305, r 0.2827, f1: 0.2833	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4708
test	acc: 0.5670	macro: p 0.3415, r 0.2951, f1: 0.3019	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5329
New best model!
global_step: 8121, epoch: 4, loss: 1.279928
global_step: 8122, epoch: 4, loss: 1.199142
global_step: 8123, epoch: 4, loss: 1.255239
global_step: 8124, epoch: 4, loss: 1.246808
global_step: 8125, epoch: 4, loss: 1.237676
global_step: 8126, epoch: 4, loss: 1.197534
global_step: 8127, epoch: 4, loss: 1.232421
global_step: 8128, epoch: 4, loss: 1.255214
global_step: 8129, epoch: 4, loss: 1.176848
global_step: 8130, epoch: 4, loss: 1.295565
global_step: 8131, epoch: 4, loss: 1.294832
global_step: 8132, epoch: 4, loss: 1.369395
global_step: 8133, epoch: 4, loss: 1.186325
global_step: 8134, epoch: 4, loss: 1.279656
global_step: 8135, epoch: 4, loss: 1.205791
global_step: 8136, epoch: 4, loss: 1.263971
global_step: 8137, epoch: 4, loss: 1.279407
global_step: 8138, epoch: 4, loss: 1.136467
global_step: 8139, epoch: 4, loss: 1.274654
global_step: 8140, epoch: 4, loss: 1.133224
global_step: 8141, epoch: 4, loss: 1.114479
global_step: 8142, epoch: 4, loss: 1.173896
global_step: 8143, epoch: 4, loss: 1.288774
global_step: 8144, epoch: 4, loss: 1.222808
global_step: 8145, epoch: 4, loss: 1.234447
global_step: 8146, epoch: 4, loss: 1.224888
global_step: 8147, epoch: 4, loss: 1.169864
global_step: 8148, epoch: 4, loss: 1.118844
global_step: 8149, epoch: 4, loss: 1.095223
global_step: 8150, epoch: 4, loss: 1.216536
global_step: 8151, epoch: 4, loss: 1.331624
global_step: 8152, epoch: 4, loss: 1.221501
global_step: 8153, epoch: 4, loss: 1.302251
global_step: 8154, epoch: 4, loss: 1.210765
global_step: 8155, epoch: 4, loss: 1.259429
global_step: 8156, epoch: 4, loss: 1.296014
global_step: 8157, epoch: 4, loss: 1.139483
global_step: 8158, epoch: 4, loss: 1.118737
global_step: 8159, epoch: 4, loss: 1.279027
global_step: 8160, epoch: 4, loss: 1.017706
epoch: 4
train	acc: 0.6228	macro: p 0.4026, r 0.3288, f1: 0.3406	micro: p 0.6228, r 0.6228, f1 0.6228	weighted_f1:0.5694
dev	acc: 0.5347	macro: p 0.3257, r 0.2815, f1: 0.2713	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4634
test	acc: 0.5789	macro: p 0.3207, r 0.2818, f1: 0.2786	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5150
global_step: 8161, epoch: 5, loss: 1.107743
global_step: 8162, epoch: 5, loss: 1.099017
global_step: 8163, epoch: 5, loss: 1.111541
global_step: 8164, epoch: 5, loss: 1.192724
global_step: 8165, epoch: 5, loss: 1.250497
global_step: 8166, epoch: 5, loss: 1.152992
global_step: 8167, epoch: 5, loss: 1.225279
global_step: 8168, epoch: 5, loss: 1.083209
global_step: 8169, epoch: 5, loss: 1.129828
global_step: 8170, epoch: 5, loss: 1.154887
global_step: 8171, epoch: 5, loss: 1.141540
global_step: 8172, epoch: 5, loss: 1.216169
global_step: 8173, epoch: 5, loss: 1.184781
global_step: 8174, epoch: 5, loss: 1.146343
global_step: 8175, epoch: 5, loss: 1.103310
global_step: 8176, epoch: 5, loss: 1.254588
global_step: 8177, epoch: 5, loss: 1.182369
global_step: 8178, epoch: 5, loss: 1.072389
global_step: 8179, epoch: 5, loss: 1.242478
global_step: 8180, epoch: 5, loss: 1.190242
global_step: 8181, epoch: 5, loss: 1.121734
global_step: 8182, epoch: 5, loss: 1.176832
global_step: 8183, epoch: 5, loss: 1.134063
global_step: 8184, epoch: 5, loss: 1.214630
global_step: 8185, epoch: 5, loss: 1.114361
global_step: 8186, epoch: 5, loss: 1.264888
global_step: 8187, epoch: 5, loss: 1.192604
global_step: 8188, epoch: 5, loss: 1.220474
global_step: 8189, epoch: 5, loss: 1.114564
global_step: 8190, epoch: 5, loss: 1.328738
global_step: 8191, epoch: 5, loss: 1.179902
global_step: 8192, epoch: 5, loss: 1.255929
global_step: 8193, epoch: 5, loss: 1.109647
global_step: 8194, epoch: 5, loss: 1.184843
global_step: 8195, epoch: 5, loss: 1.243500
global_step: 8196, epoch: 5, loss: 1.199939
global_step: 8197, epoch: 5, loss: 1.198294
global_step: 8198, epoch: 5, loss: 1.180020
global_step: 8199, epoch: 5, loss: 1.151988
global_step: 8200, epoch: 5, loss: 1.507692
epoch: 5
train	acc: 0.6465	macro: p 0.4321, r 0.3758, f1: 0.3887	micro: p 0.6465, r 0.6465, f1 0.6465	weighted_f1:0.6107
dev	acc: 0.5518	macro: p 0.3515, r 0.3084, f1: 0.3138	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5048
test	acc: 0.5923	macro: p 0.3474, r 0.3034, f1: 0.3116	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5476
New best model!
global_step: 8201, epoch: 6, loss: 1.132832
global_step: 8202, epoch: 6, loss: 1.051994
global_step: 8203, epoch: 6, loss: 1.089350
global_step: 8204, epoch: 6, loss: 1.183161
global_step: 8205, epoch: 6, loss: 1.141263
global_step: 8206, epoch: 6, loss: 1.120725
global_step: 8207, epoch: 6, loss: 1.090247
global_step: 8208, epoch: 6, loss: 1.088556
global_step: 8209, epoch: 6, loss: 1.111294
global_step: 8210, epoch: 6, loss: 1.204425
global_step: 8211, epoch: 6, loss: 1.001916
global_step: 8212, epoch: 6, loss: 1.079813
global_step: 8213, epoch: 6, loss: 1.075243
global_step: 8214, epoch: 6, loss: 1.093522
global_step: 8215, epoch: 6, loss: 1.078734
global_step: 8216, epoch: 6, loss: 1.220502
global_step: 8217, epoch: 6, loss: 1.110641
global_step: 8218, epoch: 6, loss: 1.097598
global_step: 8219, epoch: 6, loss: 1.033088
global_step: 8220, epoch: 6, loss: 1.118765
global_step: 8221, epoch: 6, loss: 1.124165
global_step: 8222, epoch: 6, loss: 1.305988
global_step: 8223, epoch: 6, loss: 1.047880
global_step: 8224, epoch: 6, loss: 1.119917
global_step: 8225, epoch: 6, loss: 1.128292
global_step: 8226, epoch: 6, loss: 1.178582
global_step: 8227, epoch: 6, loss: 1.106103
global_step: 8228, epoch: 6, loss: 1.140163
global_step: 8229, epoch: 6, loss: 1.154960
global_step: 8230, epoch: 6, loss: 1.133520
global_step: 8231, epoch: 6, loss: 1.118151
global_step: 8232, epoch: 6, loss: 1.173061
global_step: 8233, epoch: 6, loss: 1.107402
global_step: 8234, epoch: 6, loss: 1.193123
global_step: 8235, epoch: 6, loss: 1.066709
global_step: 8236, epoch: 6, loss: 1.130783
global_step: 8237, epoch: 6, loss: 1.027042
global_step: 8238, epoch: 6, loss: 1.128064
global_step: 8239, epoch: 6, loss: 1.149416
global_step: 8240, epoch: 6, loss: 1.147256
epoch: 6
train	acc: 0.6252	macro: p 0.4752, r 0.3213, f1: 0.3296	micro: p 0.6252, r 0.6252, f1 0.6252	weighted_f1:0.5684
dev	acc: 0.5230	macro: p 0.3523, r 0.2655, f1: 0.2402	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4400
test	acc: 0.5831	macro: p 0.4131, r 0.2801, f1: 0.2716	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5146
global_step: 8241, epoch: 7, loss: 1.194557
global_step: 8242, epoch: 7, loss: 1.000471
global_step: 8243, epoch: 7, loss: 0.979946
global_step: 8244, epoch: 7, loss: 1.021181
global_step: 8245, epoch: 7, loss: 1.061527
global_step: 8246, epoch: 7, loss: 1.051446
global_step: 8247, epoch: 7, loss: 1.183651
global_step: 8248, epoch: 7, loss: 0.995165
global_step: 8249, epoch: 7, loss: 0.992623
global_step: 8250, epoch: 7, loss: 0.969821
global_step: 8251, epoch: 7, loss: 1.077785
global_step: 8252, epoch: 7, loss: 1.124916
global_step: 8253, epoch: 7, loss: 1.200208
global_step: 8254, epoch: 7, loss: 1.011397
global_step: 8255, epoch: 7, loss: 1.133423
global_step: 8256, epoch: 7, loss: 1.238791
global_step: 8257, epoch: 7, loss: 1.272007
global_step: 8258, epoch: 7, loss: 1.108299
global_step: 8259, epoch: 7, loss: 1.017435
global_step: 8260, epoch: 7, loss: 0.990307
global_step: 8261, epoch: 7, loss: 0.952675
global_step: 8262, epoch: 7, loss: 0.988524
global_step: 8263, epoch: 7, loss: 1.047562
global_step: 8264, epoch: 7, loss: 1.064090
global_step: 8265, epoch: 7, loss: 1.219620
global_step: 8266, epoch: 7, loss: 1.149544
global_step: 8267, epoch: 7, loss: 1.102026
global_step: 8268, epoch: 7, loss: 1.094833
global_step: 8269, epoch: 7, loss: 1.073620
global_step: 8270, epoch: 7, loss: 1.100188
global_step: 8271, epoch: 7, loss: 1.144240
global_step: 8272, epoch: 7, loss: 1.074166
global_step: 8273, epoch: 7, loss: 1.162909
global_step: 8274, epoch: 7, loss: 1.164211
global_step: 8275, epoch: 7, loss: 1.043524
global_step: 8276, epoch: 7, loss: 1.118487
global_step: 8277, epoch: 7, loss: 1.021813
global_step: 8278, epoch: 7, loss: 1.069662
global_step: 8279, epoch: 7, loss: 1.114072
global_step: 8280, epoch: 7, loss: 0.644245
epoch: 7
train	acc: 0.6069	macro: p 0.4819, r 0.3026, f1: 0.3279	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5435
dev	acc: 0.5185	macro: p 0.4280, r 0.2512, f1: 0.2496	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4333
test	acc: 0.5751	macro: p 0.3718, r 0.2588, f1: 0.2672	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.4962
global_step: 8281, epoch: 8, loss: 1.296355
global_step: 8282, epoch: 8, loss: 1.022934
global_step: 8283, epoch: 8, loss: 1.026436
global_step: 8284, epoch: 8, loss: 1.005875
global_step: 8285, epoch: 8, loss: 1.110014
global_step: 8286, epoch: 8, loss: 1.060895
global_step: 8287, epoch: 8, loss: 1.003639
global_step: 8288, epoch: 8, loss: 1.032973
global_step: 8289, epoch: 8, loss: 1.137807
global_step: 8290, epoch: 8, loss: 1.051137
global_step: 8291, epoch: 8, loss: 1.051964
global_step: 8292, epoch: 8, loss: 1.075240
global_step: 8293, epoch: 8, loss: 0.995370
global_step: 8294, epoch: 8, loss: 1.024567
global_step: 8295, epoch: 8, loss: 1.040354
global_step: 8296, epoch: 8, loss: 0.993244
global_step: 8297, epoch: 8, loss: 0.995015
global_step: 8298, epoch: 8, loss: 0.919164
global_step: 8299, epoch: 8, loss: 0.941508
global_step: 8300, epoch: 8, loss: 1.104548
global_step: 8301, epoch: 8, loss: 1.130781
global_step: 8302, epoch: 8, loss: 0.985036
global_step: 8303, epoch: 8, loss: 1.090345
global_step: 8304, epoch: 8, loss: 1.075024
global_step: 8305, epoch: 8, loss: 1.049568
global_step: 8306, epoch: 8, loss: 0.964538
global_step: 8307, epoch: 8, loss: 1.094949
global_step: 8308, epoch: 8, loss: 1.091843
global_step: 8309, epoch: 8, loss: 1.092967
global_step: 8310, epoch: 8, loss: 1.007423
global_step: 8311, epoch: 8, loss: 1.098197
global_step: 8312, epoch: 8, loss: 0.906231
global_step: 8313, epoch: 8, loss: 0.958939
global_step: 8314, epoch: 8, loss: 1.001146
global_step: 8315, epoch: 8, loss: 1.002079
global_step: 8316, epoch: 8, loss: 1.044772
global_step: 8317, epoch: 8, loss: 0.920009
global_step: 8318, epoch: 8, loss: 0.996603
global_step: 8319, epoch: 8, loss: 1.148929
global_step: 8320, epoch: 8, loss: 0.942085
epoch: 8
train	acc: 0.6726	macro: p 0.4625, r 0.4065, f1: 0.4088	micro: p 0.6726, r 0.6726, f1 0.6726	weighted_f1:0.6400
dev	acc: 0.5275	macro: p 0.3141, r 0.2849, f1: 0.2762	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4685
test	acc: 0.5724	macro: p 0.3423, r 0.2907, f1: 0.2903	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5235
global_step: 8321, epoch: 9, loss: 1.041639
global_step: 8322, epoch: 9, loss: 0.967666
global_step: 8323, epoch: 9, loss: 0.986484
global_step: 8324, epoch: 9, loss: 0.892389
global_step: 8325, epoch: 9, loss: 0.893714
global_step: 8326, epoch: 9, loss: 0.976764
global_step: 8327, epoch: 9, loss: 1.047207
global_step: 8328, epoch: 9, loss: 0.971529
global_step: 8329, epoch: 9, loss: 0.891128
global_step: 8330, epoch: 9, loss: 1.115688
global_step: 8331, epoch: 9, loss: 1.058685
global_step: 8332, epoch: 9, loss: 1.075640
global_step: 8333, epoch: 9, loss: 0.995173
global_step: 8334, epoch: 9, loss: 1.030991
global_step: 8335, epoch: 9, loss: 1.086699
global_step: 8336, epoch: 9, loss: 0.894515
global_step: 8337, epoch: 9, loss: 1.005107
global_step: 8338, epoch: 9, loss: 1.060152
global_step: 8339, epoch: 9, loss: 1.009906
global_step: 8340, epoch: 9, loss: 0.923344
global_step: 8341, epoch: 9, loss: 0.966643
global_step: 8342, epoch: 9, loss: 0.939324
global_step: 8343, epoch: 9, loss: 1.098782
global_step: 8344, epoch: 9, loss: 1.008291
global_step: 8345, epoch: 9, loss: 1.042245
global_step: 8346, epoch: 9, loss: 0.989003
global_step: 8347, epoch: 9, loss: 0.900527
global_step: 8348, epoch: 9, loss: 0.931853
global_step: 8349, epoch: 9, loss: 0.997185
global_step: 8350, epoch: 9, loss: 0.998429
global_step: 8351, epoch: 9, loss: 0.955310
global_step: 8352, epoch: 9, loss: 1.105287
global_step: 8353, epoch: 9, loss: 0.925310
global_step: 8354, epoch: 9, loss: 1.016456
global_step: 8355, epoch: 9, loss: 1.111239
global_step: 8356, epoch: 9, loss: 1.009441
global_step: 8357, epoch: 9, loss: 1.070882
global_step: 8358, epoch: 9, loss: 0.934592
global_step: 8359, epoch: 9, loss: 0.983783
global_step: 8360, epoch: 9, loss: 2.212314
epoch: 9
train	acc: 0.5735	macro: p 0.6487, r 0.3429, f1: 0.3257	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5542
dev	acc: 0.4040	macro: p 0.2708, r 0.2477, f1: 0.2072	micro: p 0.4040, r 0.4040, f1 0.4040	weighted_f1:0.3735
test	acc: 0.4471	macro: p 0.4159, r 0.2588, f1: 0.2269	micro: p 0.4471, r 0.4471, f1 0.4471	weighted_f1:0.4291
global_step: 8361, epoch: 10, loss: 1.163514
global_step: 8362, epoch: 10, loss: 0.947952
global_step: 8363, epoch: 10, loss: 0.968886
global_step: 8364, epoch: 10, loss: 0.814950
global_step: 8365, epoch: 10, loss: 0.934508
global_step: 8366, epoch: 10, loss: 0.958918
global_step: 8367, epoch: 10, loss: 0.944360
global_step: 8368, epoch: 10, loss: 0.995748
global_step: 8369, epoch: 10, loss: 0.975810
global_step: 8370, epoch: 10, loss: 0.839002
global_step: 8371, epoch: 10, loss: 0.945470
global_step: 8372, epoch: 10, loss: 0.936316
global_step: 8373, epoch: 10, loss: 1.060045
global_step: 8374, epoch: 10, loss: 0.856455
global_step: 8375, epoch: 10, loss: 1.030898
global_step: 8376, epoch: 10, loss: 0.893930
global_step: 8377, epoch: 10, loss: 0.839312
global_step: 8378, epoch: 10, loss: 0.899675
global_step: 8379, epoch: 10, loss: 0.891244
global_step: 8380, epoch: 10, loss: 0.865784
global_step: 8381, epoch: 10, loss: 0.912468
global_step: 8382, epoch: 10, loss: 0.920189
global_step: 8383, epoch: 10, loss: 0.973625
global_step: 8384, epoch: 10, loss: 0.984658
global_step: 8385, epoch: 10, loss: 0.936808
global_step: 8386, epoch: 10, loss: 0.898182
global_step: 8387, epoch: 10, loss: 0.882654
global_step: 8388, epoch: 10, loss: 0.958821
global_step: 8389, epoch: 10, loss: 0.858171
global_step: 8390, epoch: 10, loss: 0.906244
global_step: 8391, epoch: 10, loss: 0.997206
global_step: 8392, epoch: 10, loss: 0.919424
global_step: 8393, epoch: 10, loss: 1.038140
global_step: 8394, epoch: 10, loss: 0.979500
global_step: 8395, epoch: 10, loss: 0.992372
global_step: 8396, epoch: 10, loss: 1.007105
global_step: 8397, epoch: 10, loss: 1.047973
global_step: 8398, epoch: 10, loss: 0.939171
global_step: 8399, epoch: 10, loss: 1.069301
global_step: 8400, epoch: 10, loss: 0.657885
epoch: 10
train	acc: 0.7092	macro: p 0.5335, r 0.4329, f1: 0.4355	micro: p 0.7092, r 0.7092, f1 0.7092	weighted_f1:0.6668
dev	acc: 0.5446	macro: p 0.4291, r 0.2925, f1: 0.2857	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4802
test	acc: 0.5969	macro: p 0.3969, r 0.3037, f1: 0.3040	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5422
global_step: 8401, epoch: 11, loss: 1.012324
global_step: 8402, epoch: 11, loss: 0.936820
global_step: 8403, epoch: 11, loss: 0.914428
global_step: 8404, epoch: 11, loss: 0.821237
global_step: 8405, epoch: 11, loss: 0.811782
global_step: 8406, epoch: 11, loss: 0.909782
global_step: 8407, epoch: 11, loss: 0.890905
global_step: 8408, epoch: 11, loss: 0.958622
global_step: 8409, epoch: 11, loss: 0.835966
global_step: 8410, epoch: 11, loss: 0.886129
global_step: 8411, epoch: 11, loss: 0.963413
global_step: 8412, epoch: 11, loss: 0.933801
global_step: 8413, epoch: 11, loss: 0.840093
global_step: 8414, epoch: 11, loss: 0.945720
global_step: 8415, epoch: 11, loss: 0.880072
global_step: 8416, epoch: 11, loss: 0.940341
global_step: 8417, epoch: 11, loss: 0.955175
global_step: 8418, epoch: 11, loss: 1.006402
global_step: 8419, epoch: 11, loss: 0.953451
global_step: 8420, epoch: 11, loss: 1.041133
global_step: 8421, epoch: 11, loss: 0.858317
global_step: 8422, epoch: 11, loss: 0.980352
global_step: 8423, epoch: 11, loss: 0.920272
global_step: 8424, epoch: 11, loss: 0.852450
global_step: 8425, epoch: 11, loss: 0.840935
global_step: 8426, epoch: 11, loss: 0.960621
global_step: 8427, epoch: 11, loss: 0.941808
global_step: 8428, epoch: 11, loss: 0.846335
global_step: 8429, epoch: 11, loss: 0.825726
global_step: 8430, epoch: 11, loss: 0.897548
global_step: 8431, epoch: 11, loss: 0.934202
global_step: 8432, epoch: 11, loss: 0.982378
global_step: 8433, epoch: 11, loss: 0.790758
global_step: 8434, epoch: 11, loss: 0.789167
global_step: 8435, epoch: 11, loss: 0.806859
global_step: 8436, epoch: 11, loss: 0.849305
global_step: 8437, epoch: 11, loss: 0.979504
global_step: 8438, epoch: 11, loss: 0.933839
global_step: 8439, epoch: 11, loss: 0.910669
global_step: 8440, epoch: 11, loss: 2.267282
epoch: 11
train	acc: 0.7812	macro: p 0.7937, r 0.5555, f1: 0.5575	micro: p 0.7812, r 0.7812, f1 0.7812	weighted_f1:0.7637
dev	acc: 0.5095	macro: p 0.3192, r 0.3002, f1: 0.2857	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4719
test	acc: 0.5563	macro: p 0.3389, r 0.3121, f1: 0.3027	micro: p 0.5563, r 0.5563, f1 0.5563	weighted_f1:0.5264
global_step: 8441, epoch: 12, loss: 0.737120
global_step: 8442, epoch: 12, loss: 0.804002
global_step: 8443, epoch: 12, loss: 0.789363
global_step: 8444, epoch: 12, loss: 0.875307
global_step: 8445, epoch: 12, loss: 0.768827
global_step: 8446, epoch: 12, loss: 0.832115
global_step: 8447, epoch: 12, loss: 0.793633
global_step: 8448, epoch: 12, loss: 0.955291
global_step: 8449, epoch: 12, loss: 0.778434
global_step: 8450, epoch: 12, loss: 0.904031
global_step: 8451, epoch: 12, loss: 0.902630
global_step: 8452, epoch: 12, loss: 0.809813
global_step: 8453, epoch: 12, loss: 0.743353
global_step: 8454, epoch: 12, loss: 0.901633
global_step: 8455, epoch: 12, loss: 0.849956
global_step: 8456, epoch: 12, loss: 0.790865
global_step: 8457, epoch: 12, loss: 0.842707
global_step: 8458, epoch: 12, loss: 0.829713
global_step: 8459, epoch: 12, loss: 0.792262
global_step: 8460, epoch: 12, loss: 0.821169
global_step: 8461, epoch: 12, loss: 0.815740
global_step: 8462, epoch: 12, loss: 0.812892
global_step: 8463, epoch: 12, loss: 0.765359
global_step: 8464, epoch: 12, loss: 0.916727
global_step: 8465, epoch: 12, loss: 0.842986
global_step: 8466, epoch: 12, loss: 0.752848
global_step: 8467, epoch: 12, loss: 0.787529
global_step: 8468, epoch: 12, loss: 0.901281
global_step: 8469, epoch: 12, loss: 0.830367
global_step: 8470, epoch: 12, loss: 0.892412
global_step: 8471, epoch: 12, loss: 0.889296
global_step: 8472, epoch: 12, loss: 0.888602
global_step: 8473, epoch: 12, loss: 0.890684
global_step: 8474, epoch: 12, loss: 0.883901
global_step: 8475, epoch: 12, loss: 0.818983
global_step: 8476, epoch: 12, loss: 0.805317
global_step: 8477, epoch: 12, loss: 0.895150
global_step: 8478, epoch: 12, loss: 0.808645
global_step: 8479, epoch: 12, loss: 0.925075
global_step: 8480, epoch: 12, loss: 1.191521
epoch: 12
train	acc: 0.7342	macro: p 0.7826, r 0.5324, f1: 0.5352	micro: p 0.7342, r 0.7342, f1 0.7342	weighted_f1:0.7234
dev	acc: 0.4752	macro: p 0.3200, r 0.2902, f1: 0.2684	micro: p 0.4752, r 0.4752, f1 0.4752	weighted_f1:0.4481
test	acc: 0.5100	macro: p 0.3398, r 0.2920, f1: 0.2771	micro: p 0.5100, r 0.5100, f1 0.5100	weighted_f1:0.4934
global_step: 8481, epoch: 13, loss: 0.931874
global_step: 8482, epoch: 13, loss: 0.828329
global_step: 8483, epoch: 13, loss: 0.808477
global_step: 8484, epoch: 13, loss: 0.809071
global_step: 8485, epoch: 13, loss: 0.750163
global_step: 8486, epoch: 13, loss: 0.856985
global_step: 8487, epoch: 13, loss: 0.762107
global_step: 8488, epoch: 13, loss: 0.815721
global_step: 8489, epoch: 13, loss: 0.797651
global_step: 8490, epoch: 13, loss: 0.762541
global_step: 8491, epoch: 13, loss: 0.896048
global_step: 8492, epoch: 13, loss: 0.717673
global_step: 8493, epoch: 13, loss: 0.721094
global_step: 8494, epoch: 13, loss: 0.792985
global_step: 8495, epoch: 13, loss: 0.852342
global_step: 8496, epoch: 13, loss: 0.862541
global_step: 8497, epoch: 13, loss: 0.805571
global_step: 8498, epoch: 13, loss: 0.656211
global_step: 8499, epoch: 13, loss: 0.729816
global_step: 8500, epoch: 13, loss: 0.763429
global_step: 8501, epoch: 13, loss: 0.861997
global_step: 8502, epoch: 13, loss: 0.795449
global_step: 8503, epoch: 13, loss: 0.708402
global_step: 8504, epoch: 13, loss: 0.845144
global_step: 8505, epoch: 13, loss: 0.816677
global_step: 8506, epoch: 13, loss: 0.859705
global_step: 8507, epoch: 13, loss: 0.736449
global_step: 8508, epoch: 13, loss: 0.767306
global_step: 8509, epoch: 13, loss: 0.901952
global_step: 8510, epoch: 13, loss: 0.806597
global_step: 8511, epoch: 13, loss: 0.845480
global_step: 8512, epoch: 13, loss: 0.743117
global_step: 8513, epoch: 13, loss: 0.734480
global_step: 8514, epoch: 13, loss: 0.960207
global_step: 8515, epoch: 13, loss: 0.889999
global_step: 8516, epoch: 13, loss: 0.886883
global_step: 8517, epoch: 13, loss: 0.737979
global_step: 8518, epoch: 13, loss: 0.824417
global_step: 8519, epoch: 13, loss: 0.804822
global_step: 8520, epoch: 13, loss: 0.644054
epoch: 13
train	acc: 0.8383	macro: p 0.8694, r 0.6737, f1: 0.7230	micro: p 0.8383, r 0.8383, f1 0.8383	weighted_f1:0.8299
dev	acc: 0.5347	macro: p 0.3865, r 0.3100, f1: 0.2926	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4792
test	acc: 0.5701	macro: p 0.3308, r 0.3093, f1: 0.2938	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5267
global_step: 8521, epoch: 14, loss: 0.657624
global_step: 8522, epoch: 14, loss: 0.796106
global_step: 8523, epoch: 14, loss: 0.684660
global_step: 8524, epoch: 14, loss: 0.750065
global_step: 8525, epoch: 14, loss: 0.702670
global_step: 8526, epoch: 14, loss: 0.728162
global_step: 8527, epoch: 14, loss: 0.891582
global_step: 8528, epoch: 14, loss: 0.662788
global_step: 8529, epoch: 14, loss: 0.702873
global_step: 8530, epoch: 14, loss: 0.771490
global_step: 8531, epoch: 14, loss: 0.754206
global_step: 8532, epoch: 14, loss: 0.676095
global_step: 8533, epoch: 14, loss: 0.769756
global_step: 8534, epoch: 14, loss: 0.749789
global_step: 8535, epoch: 14, loss: 0.902980
global_step: 8536, epoch: 14, loss: 0.707420
global_step: 8537, epoch: 14, loss: 0.844785
global_step: 8538, epoch: 14, loss: 0.763089
global_step: 8539, epoch: 14, loss: 0.659001
global_step: 8540, epoch: 14, loss: 0.872226
global_step: 8541, epoch: 14, loss: 0.739782
global_step: 8542, epoch: 14, loss: 0.736471
global_step: 8543, epoch: 14, loss: 0.706838
global_step: 8544, epoch: 14, loss: 0.730266
global_step: 8545, epoch: 14, loss: 0.742217
global_step: 8546, epoch: 14, loss: 0.891139
global_step: 8547, epoch: 14, loss: 0.830829
global_step: 8548, epoch: 14, loss: 0.845241
global_step: 8549, epoch: 14, loss: 0.742878
global_step: 8550, epoch: 14, loss: 0.836656
global_step: 8551, epoch: 14, loss: 0.860457
global_step: 8552, epoch: 14, loss: 0.794096
global_step: 8553, epoch: 14, loss: 0.926966
global_step: 8554, epoch: 14, loss: 0.894602
global_step: 8555, epoch: 14, loss: 0.760470
global_step: 8556, epoch: 14, loss: 0.855278
global_step: 8557, epoch: 14, loss: 0.860508
global_step: 8558, epoch: 14, loss: 0.784609
global_step: 8559, epoch: 14, loss: 0.889160
global_step: 8560, epoch: 14, loss: 0.202150
epoch: 14
train	acc: 0.8095	macro: p 0.8616, r 0.6197, f1: 0.6850	micro: p 0.8095, r 0.8095, f1 0.8095	weighted_f1:0.7984
dev	acc: 0.5437	macro: p 0.3618, r 0.2942, f1: 0.2880	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4815
test	acc: 0.5897	macro: p 0.3564, r 0.2931, f1: 0.2933	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5320
global_step: 8561, epoch: 15, loss: 0.791327
global_step: 8562, epoch: 15, loss: 0.720038
global_step: 8563, epoch: 15, loss: 0.698666
global_step: 8564, epoch: 15, loss: 0.694748
global_step: 8565, epoch: 15, loss: 0.746709
global_step: 8566, epoch: 15, loss: 0.852188
global_step: 8567, epoch: 15, loss: 0.710457
global_step: 8568, epoch: 15, loss: 0.807776
global_step: 8569, epoch: 15, loss: 0.754631
global_step: 8570, epoch: 15, loss: 0.761834
global_step: 8571, epoch: 15, loss: 0.783895
global_step: 8572, epoch: 15, loss: 0.673601
global_step: 8573, epoch: 15, loss: 0.750234
global_step: 8574, epoch: 15, loss: 0.706220
global_step: 8575, epoch: 15, loss: 0.777669
global_step: 8576, epoch: 15, loss: 0.741560
global_step: 8577, epoch: 15, loss: 0.743532
global_step: 8578, epoch: 15, loss: 0.629793
global_step: 8579, epoch: 15, loss: 0.879615
global_step: 8580, epoch: 15, loss: 0.814506
global_step: 8581, epoch: 15, loss: 0.718752
global_step: 8582, epoch: 15, loss: 0.822711
global_step: 8583, epoch: 15, loss: 0.753042
global_step: 8584, epoch: 15, loss: 0.761466
global_step: 8585, epoch: 15, loss: 0.599628
global_step: 8586, epoch: 15, loss: 0.728868
global_step: 8587, epoch: 15, loss: 0.710224
global_step: 8588, epoch: 15, loss: 0.780446
global_step: 8589, epoch: 15, loss: 0.776421
global_step: 8590, epoch: 15, loss: 0.792706
global_step: 8591, epoch: 15, loss: 0.821354
global_step: 8592, epoch: 15, loss: 0.782149
global_step: 8593, epoch: 15, loss: 0.730188
global_step: 8594, epoch: 15, loss: 0.784844
global_step: 8595, epoch: 15, loss: 0.780505
global_step: 8596, epoch: 15, loss: 0.720958
global_step: 8597, epoch: 15, loss: 0.717604
global_step: 8598, epoch: 15, loss: 0.823915
global_step: 8599, epoch: 15, loss: 0.862093
global_step: 8600, epoch: 15, loss: 0.664823
epoch: 15
train	acc: 0.8417	macro: p 0.8723, r 0.6735, f1: 0.7226	micro: p 0.8417, r 0.8417, f1 0.8417	weighted_f1:0.8329
dev	acc: 0.5365	macro: p 0.3856, r 0.3051, f1: 0.3028	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4812
test	acc: 0.5897	macro: p 0.3699, r 0.3135, f1: 0.3152	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5429
global_step: 8601, epoch: 16, loss: 0.628966
global_step: 8602, epoch: 16, loss: 0.802071
global_step: 8603, epoch: 16, loss: 0.723590
global_step: 8604, epoch: 16, loss: 0.673401
global_step: 8605, epoch: 16, loss: 0.799125
global_step: 8606, epoch: 16, loss: 0.717931
global_step: 8607, epoch: 16, loss: 0.663794
global_step: 8608, epoch: 16, loss: 0.636473
global_step: 8609, epoch: 16, loss: 0.698619
global_step: 8610, epoch: 16, loss: 0.703356
global_step: 8611, epoch: 16, loss: 0.641574
global_step: 8612, epoch: 16, loss: 0.617828
global_step: 8613, epoch: 16, loss: 0.706428
global_step: 8614, epoch: 16, loss: 0.594624
global_step: 8615, epoch: 16, loss: 0.784672
global_step: 8616, epoch: 16, loss: 0.647428
global_step: 8617, epoch: 16, loss: 0.884799
global_step: 8618, epoch: 16, loss: 0.800196
global_step: 8619, epoch: 16, loss: 0.682677
global_step: 8620, epoch: 16, loss: 0.702453
global_step: 8621, epoch: 16, loss: 0.728276
global_step: 8622, epoch: 16, loss: 0.736487
global_step: 8623, epoch: 16, loss: 0.748922
global_step: 8624, epoch: 16, loss: 0.648889
global_step: 8625, epoch: 16, loss: 0.726820
global_step: 8626, epoch: 16, loss: 0.748517
global_step: 8627, epoch: 16, loss: 0.706716
global_step: 8628, epoch: 16, loss: 0.780728
global_step: 8629, epoch: 16, loss: 0.697803
global_step: 8630, epoch: 16, loss: 0.718934
global_step: 8631, epoch: 16, loss: 0.741161
global_step: 8632, epoch: 16, loss: 0.679581
global_step: 8633, epoch: 16, loss: 0.861322
global_step: 8634, epoch: 16, loss: 0.737730
global_step: 8635, epoch: 16, loss: 0.845579
global_step: 8636, epoch: 16, loss: 0.879629
global_step: 8637, epoch: 16, loss: 0.724545
global_step: 8638, epoch: 16, loss: 0.778606
global_step: 8639, epoch: 16, loss: 0.853855
global_step: 8640, epoch: 16, loss: 1.362791
epoch: 16
train	acc: 0.8008	macro: p 0.8317, r 0.6646, f1: 0.6876	micro: p 0.8008, r 0.8008, f1 0.8008	weighted_f1:0.8019
dev	acc: 0.4716	macro: p 0.3087, r 0.2886, f1: 0.2651	micro: p 0.4716, r 0.4716, f1 0.4716	weighted_f1:0.4417
test	acc: 0.5199	macro: p 0.3482, r 0.3151, f1: 0.2915	micro: p 0.5199, r 0.5199, f1 0.5199	weighted_f1:0.5067
global_step: 8641, epoch: 17, loss: 0.857144
global_step: 8642, epoch: 17, loss: 0.702464
global_step: 8643, epoch: 17, loss: 0.677589
global_step: 8644, epoch: 17, loss: 0.741814
global_step: 8645, epoch: 17, loss: 0.677534
global_step: 8646, epoch: 17, loss: 0.602150
global_step: 8647, epoch: 17, loss: 0.668965
global_step: 8648, epoch: 17, loss: 0.642444
global_step: 8649, epoch: 17, loss: 0.669095
global_step: 8650, epoch: 17, loss: 0.676188
global_step: 8651, epoch: 17, loss: 0.645016
global_step: 8652, epoch: 17, loss: 0.686237
global_step: 8653, epoch: 17, loss: 0.698982
global_step: 8654, epoch: 17, loss: 0.574629
global_step: 8655, epoch: 17, loss: 0.722615
global_step: 8656, epoch: 17, loss: 0.790549
global_step: 8657, epoch: 17, loss: 0.648387
global_step: 8658, epoch: 17, loss: 0.654880
global_step: 8659, epoch: 17, loss: 0.736938
global_step: 8660, epoch: 17, loss: 0.710928
global_step: 8661, epoch: 17, loss: 0.611690
global_step: 8662, epoch: 17, loss: 0.663411
global_step: 8663, epoch: 17, loss: 0.542298
global_step: 8664, epoch: 17, loss: 0.644412
global_step: 8665, epoch: 17, loss: 0.751462
global_step: 8666, epoch: 17, loss: 0.609070
global_step: 8667, epoch: 17, loss: 0.750906
global_step: 8668, epoch: 17, loss: 0.778441
global_step: 8669, epoch: 17, loss: 0.645233
global_step: 8670, epoch: 17, loss: 0.647114
global_step: 8671, epoch: 17, loss: 0.728372
global_step: 8672, epoch: 17, loss: 0.624736
global_step: 8673, epoch: 17, loss: 0.726828
global_step: 8674, epoch: 17, loss: 0.793855
global_step: 8675, epoch: 17, loss: 0.671915
global_step: 8676, epoch: 17, loss: 0.737392
global_step: 8677, epoch: 17, loss: 0.698985
global_step: 8678, epoch: 17, loss: 0.664396
global_step: 8679, epoch: 17, loss: 0.691348
global_step: 8680, epoch: 17, loss: 0.615049
epoch: 17
train	acc: 0.8574	macro: p 0.8918, r 0.7263, f1: 0.7843	micro: p 0.8574, r 0.8574, f1 0.8574	weighted_f1:0.8523
dev	acc: 0.5347	macro: p 0.3274, r 0.2847, f1: 0.2809	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4705
test	acc: 0.5824	macro: p 0.3418, r 0.2901, f1: 0.2955	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5283
global_step: 8681, epoch: 18, loss: 0.825253
global_step: 8682, epoch: 18, loss: 0.676763
global_step: 8683, epoch: 18, loss: 0.607272
global_step: 8684, epoch: 18, loss: 0.660821
global_step: 8685, epoch: 18, loss: 0.577389
global_step: 8686, epoch: 18, loss: 0.560255
global_step: 8687, epoch: 18, loss: 0.712658
global_step: 8688, epoch: 18, loss: 0.749956
global_step: 8689, epoch: 18, loss: 0.596981
global_step: 8690, epoch: 18, loss: 0.581268
global_step: 8691, epoch: 18, loss: 0.603291
global_step: 8692, epoch: 18, loss: 0.569472
global_step: 8693, epoch: 18, loss: 0.704956
global_step: 8694, epoch: 18, loss: 0.691072
global_step: 8695, epoch: 18, loss: 0.659211
global_step: 8696, epoch: 18, loss: 0.769485
global_step: 8697, epoch: 18, loss: 0.639606
global_step: 8698, epoch: 18, loss: 0.568061
global_step: 8699, epoch: 18, loss: 0.643709
global_step: 8700, epoch: 18, loss: 0.645341
global_step: 8701, epoch: 18, loss: 0.624450
global_step: 8702, epoch: 18, loss: 0.674746
global_step: 8703, epoch: 18, loss: 0.665425
global_step: 8704, epoch: 18, loss: 0.750766
global_step: 8705, epoch: 18, loss: 0.655634
global_step: 8706, epoch: 18, loss: 0.663802
global_step: 8707, epoch: 18, loss: 0.664261
global_step: 8708, epoch: 18, loss: 0.641745
global_step: 8709, epoch: 18, loss: 0.593433
global_step: 8710, epoch: 18, loss: 0.697151
global_step: 8711, epoch: 18, loss: 0.623470
global_step: 8712, epoch: 18, loss: 0.625259
global_step: 8713, epoch: 18, loss: 0.649912
global_step: 8714, epoch: 18, loss: 0.779722
global_step: 8715, epoch: 18, loss: 0.770591
global_step: 8716, epoch: 18, loss: 0.696223
global_step: 8717, epoch: 18, loss: 0.640827
global_step: 8718, epoch: 18, loss: 0.765726
global_step: 8719, epoch: 18, loss: 0.579447
global_step: 8720, epoch: 18, loss: 0.427476
epoch: 18
train	acc: 0.8926	macro: p 0.9205, r 0.7977, f1: 0.8480	micro: p 0.8926, r 0.8926, f1 0.8926	weighted_f1:0.8902
dev	acc: 0.5374	macro: p 0.3648, r 0.2886, f1: 0.2886	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4772
test	acc: 0.5759	macro: p 0.3571, r 0.2929, f1: 0.3018	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5278
global_step: 8721, epoch: 19, loss: 0.566647
global_step: 8722, epoch: 19, loss: 0.597354
global_step: 8723, epoch: 19, loss: 0.615399
global_step: 8724, epoch: 19, loss: 0.625679
global_step: 8725, epoch: 19, loss: 0.545301
global_step: 8726, epoch: 19, loss: 0.593030
global_step: 8727, epoch: 19, loss: 0.577562
global_step: 8728, epoch: 19, loss: 0.516326
global_step: 8729, epoch: 19, loss: 0.607649
global_step: 8730, epoch: 19, loss: 0.545656
global_step: 8731, epoch: 19, loss: 0.540377
global_step: 8732, epoch: 19, loss: 0.623474
global_step: 8733, epoch: 19, loss: 0.657102
global_step: 8734, epoch: 19, loss: 0.517597
global_step: 8735, epoch: 19, loss: 0.654959
global_step: 8736, epoch: 19, loss: 0.784344
global_step: 8737, epoch: 19, loss: 0.552818
global_step: 8738, epoch: 19, loss: 0.668378
global_step: 8739, epoch: 19, loss: 0.584023
global_step: 8740, epoch: 19, loss: 0.690417
global_step: 8741, epoch: 19, loss: 0.597431
global_step: 8742, epoch: 19, loss: 0.645992
global_step: 8743, epoch: 19, loss: 0.656903
global_step: 8744, epoch: 19, loss: 0.652937
global_step: 8745, epoch: 19, loss: 0.702827
global_step: 8746, epoch: 19, loss: 0.631651
global_step: 8747, epoch: 19, loss: 0.603671
global_step: 8748, epoch: 19, loss: 0.693632
global_step: 8749, epoch: 19, loss: 0.560860
global_step: 8750, epoch: 19, loss: 0.640082
global_step: 8751, epoch: 19, loss: 0.660145
global_step: 8752, epoch: 19, loss: 0.583821
global_step: 8753, epoch: 19, loss: 0.644995
global_step: 8754, epoch: 19, loss: 0.704873
global_step: 8755, epoch: 19, loss: 0.694246
global_step: 8756, epoch: 19, loss: 0.664553
global_step: 8757, epoch: 19, loss: 0.628794
global_step: 8758, epoch: 19, loss: 0.757107
global_step: 8759, epoch: 19, loss: 0.650513
global_step: 8760, epoch: 19, loss: 0.490631
epoch: 19
train	acc: 0.8133	macro: p 0.8569, r 0.6708, f1: 0.7335	micro: p 0.8133, r 0.8133, f1 0.8133	weighted_f1:0.8054
dev	acc: 0.5284	macro: p 0.3458, r 0.2734, f1: 0.2762	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4646
test	acc: 0.5954	macro: p 0.3828, r 0.3008, f1: 0.3155	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5455
global_step: 8761, epoch: 20, loss: 0.763448
global_step: 8762, epoch: 20, loss: 0.580749
global_step: 8763, epoch: 20, loss: 0.628891
global_step: 8764, epoch: 20, loss: 0.641682
global_step: 8765, epoch: 20, loss: 0.598856
global_step: 8766, epoch: 20, loss: 0.755313
global_step: 8767, epoch: 20, loss: 0.683357
global_step: 8768, epoch: 20, loss: 0.592035
global_step: 8769, epoch: 20, loss: 0.677546
global_step: 8770, epoch: 20, loss: 0.566298
global_step: 8771, epoch: 20, loss: 0.609105
global_step: 8772, epoch: 20, loss: 0.569977
global_step: 8773, epoch: 20, loss: 0.546224
global_step: 8774, epoch: 20, loss: 0.603380
global_step: 8775, epoch: 20, loss: 0.529783
global_step: 8776, epoch: 20, loss: 0.612636
global_step: 8777, epoch: 20, loss: 0.543711
global_step: 8778, epoch: 20, loss: 0.661056
global_step: 8779, epoch: 20, loss: 0.551634
global_step: 8780, epoch: 20, loss: 0.600978
global_step: 8781, epoch: 20, loss: 0.630986
global_step: 8782, epoch: 20, loss: 0.554434
global_step: 8783, epoch: 20, loss: 0.717678
global_step: 8784, epoch: 20, loss: 0.591713
global_step: 8785, epoch: 20, loss: 0.656497
global_step: 8786, epoch: 20, loss: 0.704652
global_step: 8787, epoch: 20, loss: 0.709004
global_step: 8788, epoch: 20, loss: 0.574164
global_step: 8789, epoch: 20, loss: 0.666411
global_step: 8790, epoch: 20, loss: 0.592215
global_step: 8791, epoch: 20, loss: 0.569187
global_step: 8792, epoch: 20, loss: 0.645087
global_step: 8793, epoch: 20, loss: 0.540559
global_step: 8794, epoch: 20, loss: 0.641176
global_step: 8795, epoch: 20, loss: 0.566683
global_step: 8796, epoch: 20, loss: 0.666120
global_step: 8797, epoch: 20, loss: 0.588968
global_step: 8798, epoch: 20, loss: 0.604600
global_step: 8799, epoch: 20, loss: 0.710948
global_step: 8800, epoch: 20, loss: 0.361746
epoch: 20
train	acc: 0.8963	macro: p 0.9224, r 0.8089, f1: 0.8544	micro: p 0.8963, r 0.8963, f1 0.8963	weighted_f1:0.8947
dev	acc: 0.5338	macro: p 0.4066, r 0.2954, f1: 0.2853	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4709
test	acc: 0.5824	macro: p 0.3423, r 0.3026, f1: 0.3000	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5317
global_step: 8801, epoch: 21, loss: 0.616429
global_step: 8802, epoch: 21, loss: 0.536565
global_step: 8803, epoch: 21, loss: 0.568548
global_step: 8804, epoch: 21, loss: 0.531702
global_step: 8805, epoch: 21, loss: 0.546245
global_step: 8806, epoch: 21, loss: 0.620284
global_step: 8807, epoch: 21, loss: 0.615247
global_step: 8808, epoch: 21, loss: 0.584648
global_step: 8809, epoch: 21, loss: 0.504472
global_step: 8810, epoch: 21, loss: 0.507665
global_step: 8811, epoch: 21, loss: 0.568668
global_step: 8812, epoch: 21, loss: 0.606506
global_step: 8813, epoch: 21, loss: 0.506566
global_step: 8814, epoch: 21, loss: 0.515631
global_step: 8815, epoch: 21, loss: 0.584969
global_step: 8816, epoch: 21, loss: 0.596383
global_step: 8817, epoch: 21, loss: 0.659743
global_step: 8818, epoch: 21, loss: 0.586567
global_step: 8819, epoch: 21, loss: 0.668638
global_step: 8820, epoch: 21, loss: 0.733717
global_step: 8821, epoch: 21, loss: 0.541373
global_step: 8822, epoch: 21, loss: 0.629445
global_step: 8823, epoch: 21, loss: 0.446702
global_step: 8824, epoch: 21, loss: 0.503407
global_step: 8825, epoch: 21, loss: 0.534255
global_step: 8826, epoch: 21, loss: 0.717658
global_step: 8827, epoch: 21, loss: 0.628704
global_step: 8828, epoch: 21, loss: 0.589525
global_step: 8829, epoch: 21, loss: 0.633973
global_step: 8830, epoch: 21, loss: 0.525201
global_step: 8831, epoch: 21, loss: 0.606325
global_step: 8832, epoch: 21, loss: 0.782373
global_step: 8833, epoch: 21, loss: 0.713261
global_step: 8834, epoch: 21, loss: 0.590263
global_step: 8835, epoch: 21, loss: 0.527272
global_step: 8836, epoch: 21, loss: 0.499425
global_step: 8837, epoch: 21, loss: 0.659970
global_step: 8838, epoch: 21, loss: 0.584344
global_step: 8839, epoch: 21, loss: 0.664790
global_step: 8840, epoch: 21, loss: 1.864360
epoch: 21
train	acc: 0.8899	macro: p 0.8816, r 0.8238, f1: 0.8411	micro: p 0.8899, r 0.8899, f1 0.8899	weighted_f1:0.8899
dev	acc: 0.5005	macro: p 0.3563, r 0.3112, f1: 0.3172	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.4858
test	acc: 0.5464	macro: p 0.3710, r 0.3290, f1: 0.3308	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5396
global_step: 8841, epoch: 22, loss: 0.656591
global_step: 8842, epoch: 22, loss: 0.709502
global_step: 8843, epoch: 22, loss: 0.535388
global_step: 8844, epoch: 22, loss: 0.485055
global_step: 8845, epoch: 22, loss: 0.565236
global_step: 8846, epoch: 22, loss: 0.569969
global_step: 8847, epoch: 22, loss: 0.445175
global_step: 8848, epoch: 22, loss: 0.549507
global_step: 8849, epoch: 22, loss: 0.613057
global_step: 8850, epoch: 22, loss: 0.587992
global_step: 8851, epoch: 22, loss: 0.474777
global_step: 8852, epoch: 22, loss: 0.522980
global_step: 8853, epoch: 22, loss: 0.470194
global_step: 8854, epoch: 22, loss: 0.588987
global_step: 8855, epoch: 22, loss: 0.488259
global_step: 8856, epoch: 22, loss: 0.548605
global_step: 8857, epoch: 22, loss: 0.463941
global_step: 8858, epoch: 22, loss: 0.572398
global_step: 8859, epoch: 22, loss: 0.569441
global_step: 8860, epoch: 22, loss: 0.515690
global_step: 8861, epoch: 22, loss: 0.616555
global_step: 8862, epoch: 22, loss: 0.558148
global_step: 8863, epoch: 22, loss: 0.561274
global_step: 8864, epoch: 22, loss: 0.606442
global_step: 8865, epoch: 22, loss: 0.576634
global_step: 8866, epoch: 22, loss: 0.568577
global_step: 8867, epoch: 22, loss: 0.604587
global_step: 8868, epoch: 22, loss: 0.637299
global_step: 8869, epoch: 22, loss: 0.554211
global_step: 8870, epoch: 22, loss: 0.568723
global_step: 8871, epoch: 22, loss: 0.577297
global_step: 8872, epoch: 22, loss: 0.563277
global_step: 8873, epoch: 22, loss: 0.578100
global_step: 8874, epoch: 22, loss: 0.571199
global_step: 8875, epoch: 22, loss: 0.568507
global_step: 8876, epoch: 22, loss: 0.606660
global_step: 8877, epoch: 22, loss: 0.677710
global_step: 8878, epoch: 22, loss: 0.568527
global_step: 8879, epoch: 22, loss: 0.714635
global_step: 8880, epoch: 22, loss: 1.538509
epoch: 22
train	acc: 0.9113	macro: p 0.9058, r 0.8790, f1: 0.8890	micro: p 0.9113, r 0.9113, f1 0.9113	weighted_f1:0.9120
dev	acc: 0.4896	macro: p 0.3226, r 0.3109, f1: 0.3006	micro: p 0.4896, r 0.4896, f1 0.4896	weighted_f1:0.4714
test	acc: 0.5245	macro: p 0.3213, r 0.3245, f1: 0.3143	micro: p 0.5245, r 0.5245, f1 0.5245	weighted_f1:0.5145
global_step: 8881, epoch: 23, loss: 0.616074
global_step: 8882, epoch: 23, loss: 0.683106
global_step: 8883, epoch: 23, loss: 0.610410
global_step: 8884, epoch: 23, loss: 0.468570
global_step: 8885, epoch: 23, loss: 0.436681
global_step: 8886, epoch: 23, loss: 0.506305
global_step: 8887, epoch: 23, loss: 0.527133
global_step: 8888, epoch: 23, loss: 0.531713
global_step: 8889, epoch: 23, loss: 0.487646
global_step: 8890, epoch: 23, loss: 0.568498
global_step: 8891, epoch: 23, loss: 0.456430
global_step: 8892, epoch: 23, loss: 0.640097
global_step: 8893, epoch: 23, loss: 0.581235
global_step: 8894, epoch: 23, loss: 0.469966
global_step: 8895, epoch: 23, loss: 0.502977
global_step: 8896, epoch: 23, loss: 0.735827
global_step: 8897, epoch: 23, loss: 0.527131
global_step: 8898, epoch: 23, loss: 0.483719
global_step: 8899, epoch: 23, loss: 0.649789
global_step: 8900, epoch: 23, loss: 0.561604
global_step: 8901, epoch: 23, loss: 0.466769
global_step: 8902, epoch: 23, loss: 0.600928
global_step: 8903, epoch: 23, loss: 0.495459
global_step: 8904, epoch: 23, loss: 0.498103
global_step: 8905, epoch: 23, loss: 0.503344
global_step: 8906, epoch: 23, loss: 0.634647
global_step: 8907, epoch: 23, loss: 0.506047
global_step: 8908, epoch: 23, loss: 0.554843
global_step: 8909, epoch: 23, loss: 0.661218
global_step: 8910, epoch: 23, loss: 0.529054
global_step: 8911, epoch: 23, loss: 0.535137
global_step: 8912, epoch: 23, loss: 0.575867
global_step: 8913, epoch: 23, loss: 0.610626
global_step: 8914, epoch: 23, loss: 0.483953
global_step: 8915, epoch: 23, loss: 0.617671
global_step: 8916, epoch: 23, loss: 0.571718
global_step: 8917, epoch: 23, loss: 0.567142
global_step: 8918, epoch: 23, loss: 0.574842
global_step: 8919, epoch: 23, loss: 0.504148
global_step: 8920, epoch: 23, loss: 0.382510
epoch: 23
train	acc: 0.9273	macro: p 0.9133, r 0.8929, f1: 0.9009	micro: p 0.9273, r 0.9273, f1 0.9273	weighted_f1:0.9273
dev	acc: 0.5248	macro: p 0.3340, r 0.3128, f1: 0.3145	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4936
test	acc: 0.5502	macro: p 0.3329, r 0.3109, f1: 0.3138	micro: p 0.5502, r 0.5502, f1 0.5502	weighted_f1:0.5261
global_step: 8921, epoch: 24, loss: 0.534384
global_step: 8922, epoch: 24, loss: 0.546440
global_step: 8923, epoch: 24, loss: 0.637576
global_step: 8924, epoch: 24, loss: 0.572772
global_step: 8925, epoch: 24, loss: 0.540244
global_step: 8926, epoch: 24, loss: 0.452901
global_step: 8927, epoch: 24, loss: 0.467230
global_step: 8928, epoch: 24, loss: 0.483922
global_step: 8929, epoch: 24, loss: 0.444523
global_step: 8930, epoch: 24, loss: 0.533697
global_step: 8931, epoch: 24, loss: 0.436624
global_step: 8932, epoch: 24, loss: 0.579894
global_step: 8933, epoch: 24, loss: 0.478168
global_step: 8934, epoch: 24, loss: 0.475113
global_step: 8935, epoch: 24, loss: 0.505862
global_step: 8936, epoch: 24, loss: 0.632065
global_step: 8937, epoch: 24, loss: 0.516374
global_step: 8938, epoch: 24, loss: 0.392044
global_step: 8939, epoch: 24, loss: 0.649723
global_step: 8940, epoch: 24, loss: 0.492822
global_step: 8941, epoch: 24, loss: 0.496228
global_step: 8942, epoch: 24, loss: 0.448074
global_step: 8943, epoch: 24, loss: 0.512628
global_step: 8944, epoch: 24, loss: 0.453176
global_step: 8945, epoch: 24, loss: 0.666477
global_step: 8946, epoch: 24, loss: 0.446890
global_step: 8947, epoch: 24, loss: 0.544360
global_step: 8948, epoch: 24, loss: 0.598380
global_step: 8949, epoch: 24, loss: 0.718505
global_step: 8950, epoch: 24, loss: 0.574465
global_step: 8951, epoch: 24, loss: 0.545719
global_step: 8952, epoch: 24, loss: 0.489485
global_step: 8953, epoch: 24, loss: 0.498029
global_step: 8954, epoch: 24, loss: 0.497295
global_step: 8955, epoch: 24, loss: 0.577425
global_step: 8956, epoch: 24, loss: 0.511515
global_step: 8957, epoch: 24, loss: 0.595378
global_step: 8958, epoch: 24, loss: 0.492715
global_step: 8959, epoch: 24, loss: 0.500783
global_step: 8960, epoch: 24, loss: 0.413438
epoch: 24
train	acc: 0.8879	macro: p 0.9199, r 0.7720, f1: 0.8208	micro: p 0.8879, r 0.8879, f1 0.8879	weighted_f1:0.8834
dev	acc: 0.5284	macro: p 0.3129, r 0.2839, f1: 0.2762	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4664
test	acc: 0.5851	macro: p 0.3396, r 0.3051, f1: 0.3068	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5360
global_step: 8961, epoch: 25, loss: 0.647374
global_step: 8962, epoch: 25, loss: 0.619170
global_step: 8963, epoch: 25, loss: 0.549075
global_step: 8964, epoch: 25, loss: 0.440096
global_step: 8965, epoch: 25, loss: 0.455522
global_step: 8966, epoch: 25, loss: 0.517096
global_step: 8967, epoch: 25, loss: 0.569754
global_step: 8968, epoch: 25, loss: 0.523958
global_step: 8969, epoch: 25, loss: 0.501392
global_step: 8970, epoch: 25, loss: 0.414814
global_step: 8971, epoch: 25, loss: 0.484504
global_step: 8972, epoch: 25, loss: 0.546678
global_step: 8973, epoch: 25, loss: 0.456132
global_step: 8974, epoch: 25, loss: 0.394878
global_step: 8975, epoch: 25, loss: 0.489371
global_step: 8976, epoch: 25, loss: 0.546336
global_step: 8977, epoch: 25, loss: 0.540928
global_step: 8978, epoch: 25, loss: 0.501786
global_step: 8979, epoch: 25, loss: 0.488174
global_step: 8980, epoch: 25, loss: 0.529538
global_step: 8981, epoch: 25, loss: 0.493967
global_step: 8982, epoch: 25, loss: 0.471089
global_step: 8983, epoch: 25, loss: 0.434434
global_step: 8984, epoch: 25, loss: 0.501415
global_step: 8985, epoch: 25, loss: 0.491004
global_step: 8986, epoch: 25, loss: 0.529528
global_step: 8987, epoch: 25, loss: 0.622319
global_step: 8988, epoch: 25, loss: 0.475614
global_step: 8989, epoch: 25, loss: 0.392259
global_step: 8990, epoch: 25, loss: 0.583103
global_step: 8991, epoch: 25, loss: 0.512707
global_step: 8992, epoch: 25, loss: 0.471770
global_step: 8993, epoch: 25, loss: 0.562659
global_step: 8994, epoch: 25, loss: 0.572936
global_step: 8995, epoch: 25, loss: 0.599312
global_step: 8996, epoch: 25, loss: 0.482873
global_step: 8997, epoch: 25, loss: 0.548514
global_step: 8998, epoch: 25, loss: 0.480752
global_step: 8999, epoch: 25, loss: 0.492104
global_step: 9000, epoch: 25, loss: 0.167644
epoch: 25
train	acc: 0.9333	macro: p 0.9411, r 0.8862, f1: 0.9106	micro: p 0.9333, r 0.9333, f1 0.9333	weighted_f1:0.9330
dev	acc: 0.5221	macro: p 0.3996, r 0.3100, f1: 0.3077	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4854
test	acc: 0.5575	macro: p 0.3613, r 0.3140, f1: 0.3141	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.5312
global_step: 9001, epoch: 26, loss: 0.427996
global_step: 9002, epoch: 26, loss: 0.480046
global_step: 9003, epoch: 26, loss: 0.462703
global_step: 9004, epoch: 26, loss: 0.456240
global_step: 9005, epoch: 26, loss: 0.438787
global_step: 9006, epoch: 26, loss: 0.383913
global_step: 9007, epoch: 26, loss: 0.437029
global_step: 9008, epoch: 26, loss: 0.493863
global_step: 9009, epoch: 26, loss: 0.385111
global_step: 9010, epoch: 26, loss: 0.524372
global_step: 9011, epoch: 26, loss: 0.413405
global_step: 9012, epoch: 26, loss: 0.461987
global_step: 9013, epoch: 26, loss: 0.437374
global_step: 9014, epoch: 26, loss: 0.439648
global_step: 9015, epoch: 26, loss: 0.375420
global_step: 9016, epoch: 26, loss: 0.499555
global_step: 9017, epoch: 26, loss: 0.472287
global_step: 9018, epoch: 26, loss: 0.393733
global_step: 9019, epoch: 26, loss: 0.557775
global_step: 9020, epoch: 26, loss: 0.411034
global_step: 9021, epoch: 26, loss: 0.544984
global_step: 9022, epoch: 26, loss: 0.566698
global_step: 9023, epoch: 26, loss: 0.447566
global_step: 9024, epoch: 26, loss: 0.456339
global_step: 9025, epoch: 26, loss: 0.445575
global_step: 9026, epoch: 26, loss: 0.460426
global_step: 9027, epoch: 26, loss: 0.430400
global_step: 9028, epoch: 26, loss: 0.501408
global_step: 9029, epoch: 26, loss: 0.428745
global_step: 9030, epoch: 26, loss: 0.513488
global_step: 9031, epoch: 26, loss: 0.538569
global_step: 9032, epoch: 26, loss: 0.605487
global_step: 9033, epoch: 26, loss: 0.509830
global_step: 9034, epoch: 26, loss: 0.532300
global_step: 9035, epoch: 26, loss: 0.387778
global_step: 9036, epoch: 26, loss: 0.507957
global_step: 9037, epoch: 26, loss: 0.485322
global_step: 9038, epoch: 26, loss: 0.434875
global_step: 9039, epoch: 26, loss: 0.497021
global_step: 9040, epoch: 26, loss: 0.092539
epoch: 26
train	acc: 0.9141	macro: p 0.9442, r 0.8466, f1: 0.8884	micro: p 0.9141, r 0.9141, f1 0.9141	weighted_f1:0.9129
dev	acc: 0.5302	macro: p 0.3803, r 0.2825, f1: 0.2783	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4652
test	acc: 0.5854	macro: p 0.3806, r 0.2971, f1: 0.3030	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5332
global_step: 9041, epoch: 27, loss: 0.363254
global_step: 9042, epoch: 27, loss: 0.391761
global_step: 9043, epoch: 27, loss: 0.453316
global_step: 9044, epoch: 27, loss: 0.537347
global_step: 9045, epoch: 27, loss: 0.497370
global_step: 9046, epoch: 27, loss: 0.452513
global_step: 9047, epoch: 27, loss: 0.411217
global_step: 9048, epoch: 27, loss: 0.466777
global_step: 9049, epoch: 27, loss: 0.488901
global_step: 9050, epoch: 27, loss: 0.492253
global_step: 9051, epoch: 27, loss: 0.458319
global_step: 9052, epoch: 27, loss: 0.571650
global_step: 9053, epoch: 27, loss: 0.539225
global_step: 9054, epoch: 27, loss: 0.592885
global_step: 9055, epoch: 27, loss: 0.488546
global_step: 9056, epoch: 27, loss: 0.451489
global_step: 9057, epoch: 27, loss: 0.478727
global_step: 9058, epoch: 27, loss: 0.423270
global_step: 9059, epoch: 27, loss: 0.368191
global_step: 9060, epoch: 27, loss: 0.598983
global_step: 9061, epoch: 27, loss: 0.611123
global_step: 9062, epoch: 27, loss: 0.467842
global_step: 9063, epoch: 27, loss: 0.363341
global_step: 9064, epoch: 27, loss: 0.435886
global_step: 9065, epoch: 27, loss: 0.372796
global_step: 9066, epoch: 27, loss: 0.424242
global_step: 9067, epoch: 27, loss: 0.481870
global_step: 9068, epoch: 27, loss: 0.569779
global_step: 9069, epoch: 27, loss: 0.517616
global_step: 9070, epoch: 27, loss: 0.545199
global_step: 9071, epoch: 27, loss: 0.579163
global_step: 9072, epoch: 27, loss: 0.433241
global_step: 9073, epoch: 27, loss: 0.437254
global_step: 9074, epoch: 27, loss: 0.501396
global_step: 9075, epoch: 27, loss: 0.477052
global_step: 9076, epoch: 27, loss: 0.444917
global_step: 9077, epoch: 27, loss: 0.559864
global_step: 9078, epoch: 27, loss: 0.585385
global_step: 9079, epoch: 27, loss: 0.655427
global_step: 9080, epoch: 27, loss: 0.416092
epoch: 27
train	acc: 0.9096	macro: p 0.9151, r 0.8809, f1: 0.8922	micro: p 0.9096, r 0.9096, f1 0.9096	weighted_f1:0.9117
dev	acc: 0.4626	macro: p 0.3526, r 0.2857, f1: 0.2845	micro: p 0.4626, r 0.4626, f1 0.4626	weighted_f1:0.4505
test	acc: 0.5238	macro: p 0.3336, r 0.3180, f1: 0.3107	micro: p 0.5238, r 0.5238, f1 0.5238	weighted_f1:0.5168
global_step: 9081, epoch: 28, loss: 0.610494
global_step: 9082, epoch: 28, loss: 0.557654
global_step: 9083, epoch: 28, loss: 0.447303
global_step: 9084, epoch: 28, loss: 0.460386
global_step: 9085, epoch: 28, loss: 0.503790
global_step: 9086, epoch: 28, loss: 0.386867
global_step: 9087, epoch: 28, loss: 0.466550
global_step: 9088, epoch: 28, loss: 0.423482
global_step: 9089, epoch: 28, loss: 0.376545
global_step: 9090, epoch: 28, loss: 0.405790
global_step: 9091, epoch: 28, loss: 0.438450
global_step: 9092, epoch: 28, loss: 0.463167
global_step: 9093, epoch: 28, loss: 0.463201
global_step: 9094, epoch: 28, loss: 0.494819
global_step: 9095, epoch: 28, loss: 0.562228
global_step: 9096, epoch: 28, loss: 0.459416
global_step: 9097, epoch: 28, loss: 0.490977
global_step: 9098, epoch: 28, loss: 0.423852
global_step: 9099, epoch: 28, loss: 0.536409
global_step: 9100, epoch: 28, loss: 0.498591
global_step: 9101, epoch: 28, loss: 0.568730
global_step: 9102, epoch: 28, loss: 0.528100
global_step: 9103, epoch: 28, loss: 0.362524
global_step: 9104, epoch: 28, loss: 0.401468
global_step: 9105, epoch: 28, loss: 0.490659
global_step: 9106, epoch: 28, loss: 0.397388
global_step: 9107, epoch: 28, loss: 0.450412
global_step: 9108, epoch: 28, loss: 0.373543
global_step: 9109, epoch: 28, loss: 0.564615
global_step: 9110, epoch: 28, loss: 0.427332
global_step: 9111, epoch: 28, loss: 0.502164
global_step: 9112, epoch: 28, loss: 0.455620
global_step: 9113, epoch: 28, loss: 0.322649
global_step: 9114, epoch: 28, loss: 0.452803
global_step: 9115, epoch: 28, loss: 0.416307
global_step: 9116, epoch: 28, loss: 0.426766
global_step: 9117, epoch: 28, loss: 0.499281
global_step: 9118, epoch: 28, loss: 0.476390
global_step: 9119, epoch: 28, loss: 0.507988
global_step: 9120, epoch: 28, loss: 0.786385
epoch: 28
train	acc: 0.9305	macro: p 0.9127, r 0.9032, f1: 0.9060	micro: p 0.9305, r 0.9305, f1 0.9305	weighted_f1:0.9308
dev	acc: 0.4770	macro: p 0.3598, r 0.3169, f1: 0.3212	micro: p 0.4770, r 0.4770, f1 0.4770	weighted_f1:0.4673
test	acc: 0.5341	macro: p 0.3362, r 0.3306, f1: 0.3280	micro: p 0.5341, r 0.5341, f1 0.5341	weighted_f1:0.5301
global_step: 9121, epoch: 29, loss: 0.500077
global_step: 9122, epoch: 29, loss: 0.412517
global_step: 9123, epoch: 29, loss: 0.534071
global_step: 9124, epoch: 29, loss: 0.359612
global_step: 9125, epoch: 29, loss: 0.456925
global_step: 9126, epoch: 29, loss: 0.427556
global_step: 9127, epoch: 29, loss: 0.517871
global_step: 9128, epoch: 29, loss: 0.419822
global_step: 9129, epoch: 29, loss: 0.420822
global_step: 9130, epoch: 29, loss: 0.394203
global_step: 9131, epoch: 29, loss: 0.419865
global_step: 9132, epoch: 29, loss: 0.416708
global_step: 9133, epoch: 29, loss: 0.406701
global_step: 9134, epoch: 29, loss: 0.408513
global_step: 9135, epoch: 29, loss: 0.363819
global_step: 9136, epoch: 29, loss: 0.442573
global_step: 9137, epoch: 29, loss: 0.495753
global_step: 9138, epoch: 29, loss: 0.373895
global_step: 9139, epoch: 29, loss: 0.502330
global_step: 9140, epoch: 29, loss: 0.520685
global_step: 9141, epoch: 29, loss: 0.391998
global_step: 9142, epoch: 29, loss: 0.476534
global_step: 9143, epoch: 29, loss: 0.433251
global_step: 9144, epoch: 29, loss: 0.516858
global_step: 9145, epoch: 29, loss: 0.443176
global_step: 9146, epoch: 29, loss: 0.444868
global_step: 9147, epoch: 29, loss: 0.425257
global_step: 9148, epoch: 29, loss: 0.340349
global_step: 9149, epoch: 29, loss: 0.415487
global_step: 9150, epoch: 29, loss: 0.555265
global_step: 9151, epoch: 29, loss: 0.406333
global_step: 9152, epoch: 29, loss: 0.505861
global_step: 9153, epoch: 29, loss: 0.396419
global_step: 9154, epoch: 29, loss: 0.437305
global_step: 9155, epoch: 29, loss: 0.403245
global_step: 9156, epoch: 29, loss: 0.393771
global_step: 9157, epoch: 29, loss: 0.474718
global_step: 9158, epoch: 29, loss: 0.340822
global_step: 9159, epoch: 29, loss: 0.492242
global_step: 9160, epoch: 29, loss: 0.371991
epoch: 29
train	acc: 0.9394	macro: p 0.9315, r 0.9104, f1: 0.9185	micro: p 0.9394, r 0.9394, f1 0.9394	weighted_f1:0.9393
dev	acc: 0.5239	macro: p 0.3787, r 0.3102, f1: 0.3067	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4764
test	acc: 0.5693	macro: p 0.3587, r 0.3083, f1: 0.3100	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5295
global_step: 9161, epoch: 30, loss: 0.481340
global_step: 9162, epoch: 30, loss: 0.365667
global_step: 9163, epoch: 30, loss: 0.428341
global_step: 9164, epoch: 30, loss: 0.463545
global_step: 9165, epoch: 30, loss: 0.338449
global_step: 9166, epoch: 30, loss: 0.417642
global_step: 9167, epoch: 30, loss: 0.331134
global_step: 9168, epoch: 30, loss: 0.298035
global_step: 9169, epoch: 30, loss: 0.421410
global_step: 9170, epoch: 30, loss: 0.339996
global_step: 9171, epoch: 30, loss: 0.402583
global_step: 9172, epoch: 30, loss: 0.384790
global_step: 9173, epoch: 30, loss: 0.416668
global_step: 9174, epoch: 30, loss: 0.436452
global_step: 9175, epoch: 30, loss: 0.482926
global_step: 9176, epoch: 30, loss: 0.412320
global_step: 9177, epoch: 30, loss: 0.427563
global_step: 9178, epoch: 30, loss: 0.470802
global_step: 9179, epoch: 30, loss: 0.518268
global_step: 9180, epoch: 30, loss: 0.435845
global_step: 9181, epoch: 30, loss: 0.472445
global_step: 9182, epoch: 30, loss: 0.535221
global_step: 9183, epoch: 30, loss: 0.345631
global_step: 9184, epoch: 30, loss: 0.494687
global_step: 9185, epoch: 30, loss: 0.397994
global_step: 9186, epoch: 30, loss: 0.514735
global_step: 9187, epoch: 30, loss: 0.537355
global_step: 9188, epoch: 30, loss: 0.495234
global_step: 9189, epoch: 30, loss: 0.406789
global_step: 9190, epoch: 30, loss: 0.391195
global_step: 9191, epoch: 30, loss: 0.360559
global_step: 9192, epoch: 30, loss: 0.433379
global_step: 9193, epoch: 30, loss: 0.347933
global_step: 9194, epoch: 30, loss: 0.437092
global_step: 9195, epoch: 30, loss: 0.537016
global_step: 9196, epoch: 30, loss: 0.429811
global_step: 9197, epoch: 30, loss: 0.512374
global_step: 9198, epoch: 30, loss: 0.432851
global_step: 9199, epoch: 30, loss: 0.486370
global_step: 9200, epoch: 30, loss: 0.048962
epoch: 30
train	acc: 0.9464	macro: p 0.9556, r 0.9111, f1: 0.9316	micro: p 0.9464, r 0.9464, f1 0.9464	weighted_f1:0.9462
dev	acc: 0.5131	macro: p 0.3565, r 0.2946, f1: 0.2945	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4721
test	acc: 0.5747	macro: p 0.3561, r 0.3135, f1: 0.3137	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5385
global_step: 9201, epoch: 31, loss: 0.345310
global_step: 9202, epoch: 31, loss: 0.375015
global_step: 9203, epoch: 31, loss: 0.390083
global_step: 9204, epoch: 31, loss: 0.345638
global_step: 9205, epoch: 31, loss: 0.327142
global_step: 9206, epoch: 31, loss: 0.540118
global_step: 9207, epoch: 31, loss: 0.475845
global_step: 9208, epoch: 31, loss: 0.317207
global_step: 9209, epoch: 31, loss: 0.479379
global_step: 9210, epoch: 31, loss: 0.364262
global_step: 9211, epoch: 31, loss: 0.391167
global_step: 9212, epoch: 31, loss: 0.383224
global_step: 9213, epoch: 31, loss: 0.326647
global_step: 9214, epoch: 31, loss: 0.464912
global_step: 9215, epoch: 31, loss: 0.456192
global_step: 9216, epoch: 31, loss: 0.407344
global_step: 9217, epoch: 31, loss: 0.422547
global_step: 9218, epoch: 31, loss: 0.572756
global_step: 9219, epoch: 31, loss: 0.384801
global_step: 9220, epoch: 31, loss: 0.396895
global_step: 9221, epoch: 31, loss: 0.341411
global_step: 9222, epoch: 31, loss: 0.465953
global_step: 9223, epoch: 31, loss: 0.489961
global_step: 9224, epoch: 31, loss: 0.461326
global_step: 9225, epoch: 31, loss: 0.342605
global_step: 9226, epoch: 31, loss: 0.438591
global_step: 9227, epoch: 31, loss: 0.450949
global_step: 9228, epoch: 31, loss: 0.365968
global_step: 9229, epoch: 31, loss: 0.516907
global_step: 9230, epoch: 31, loss: 0.462097
global_step: 9231, epoch: 31, loss: 0.447072
global_step: 9232, epoch: 31, loss: 0.480737
global_step: 9233, epoch: 31, loss: 0.420474
global_step: 9234, epoch: 31, loss: 0.380220
global_step: 9235, epoch: 31, loss: 0.425011
global_step: 9236, epoch: 31, loss: 0.463869
global_step: 9237, epoch: 31, loss: 0.524734
global_step: 9238, epoch: 31, loss: 0.567346
global_step: 9239, epoch: 31, loss: 0.423432
global_step: 9240, epoch: 31, loss: 0.410186
epoch: 31
train	acc: 0.9472	macro: p 0.9305, r 0.9254, f1: 0.9275	micro: p 0.9472, r 0.9472, f1 0.9472	weighted_f1:0.9472
dev	acc: 0.5068	macro: p 0.3359, r 0.2968, f1: 0.3004	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4772
test	acc: 0.5548	macro: p 0.3403, r 0.3100, f1: 0.3164	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5353
global_step: 9241, epoch: 32, loss: 0.447695
global_step: 9242, epoch: 32, loss: 0.374760
global_step: 9243, epoch: 32, loss: 0.478728
global_step: 9244, epoch: 32, loss: 0.407539
global_step: 9245, epoch: 32, loss: 0.325710
global_step: 9246, epoch: 32, loss: 0.397155
global_step: 9247, epoch: 32, loss: 0.377784
global_step: 9248, epoch: 32, loss: 0.370090
global_step: 9249, epoch: 32, loss: 0.441044
global_step: 9250, epoch: 32, loss: 0.445030
global_step: 9251, epoch: 32, loss: 0.472780
global_step: 9252, epoch: 32, loss: 0.275706
global_step: 9253, epoch: 32, loss: 0.396584
global_step: 9254, epoch: 32, loss: 0.371153
global_step: 9255, epoch: 32, loss: 0.386627
global_step: 9256, epoch: 32, loss: 0.426727
global_step: 9257, epoch: 32, loss: 0.459938
global_step: 9258, epoch: 32, loss: 0.455444
global_step: 9259, epoch: 32, loss: 0.439536
global_step: 9260, epoch: 32, loss: 0.443697
global_step: 9261, epoch: 32, loss: 0.472688
global_step: 9262, epoch: 32, loss: 0.474132
global_step: 9263, epoch: 32, loss: 0.497825
global_step: 9264, epoch: 32, loss: 0.412222
global_step: 9265, epoch: 32, loss: 0.458759
global_step: 9266, epoch: 32, loss: 0.592870
global_step: 9267, epoch: 32, loss: 0.496940
global_step: 9268, epoch: 32, loss: 0.372482
global_step: 9269, epoch: 32, loss: 0.373041
global_step: 9270, epoch: 32, loss: 0.410178
global_step: 9271, epoch: 32, loss: 0.443755
global_step: 9272, epoch: 32, loss: 0.305596
global_step: 9273, epoch: 32, loss: 0.487092
global_step: 9274, epoch: 32, loss: 0.423124
global_step: 9275, epoch: 32, loss: 0.494918
global_step: 9276, epoch: 32, loss: 0.558755
global_step: 9277, epoch: 32, loss: 0.426413
global_step: 9278, epoch: 32, loss: 0.463837
global_step: 9279, epoch: 32, loss: 0.593482
global_step: 9280, epoch: 32, loss: 0.148276
epoch: 32
train	acc: 0.9346	macro: p 0.9446, r 0.9118, f1: 0.9262	micro: p 0.9346, r 0.9346, f1 0.9346	weighted_f1:0.9354
dev	acc: 0.4914	macro: p 0.3259, r 0.3000, f1: 0.2907	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4675
test	acc: 0.5307	macro: p 0.3344, r 0.3093, f1: 0.3064	micro: p 0.5307, r 0.5307, f1 0.5307	weighted_f1:0.5176
global_step: 9281, epoch: 33, loss: 0.537811
global_step: 9282, epoch: 33, loss: 0.376140
global_step: 9283, epoch: 33, loss: 0.338202
global_step: 9284, epoch: 33, loss: 0.388695
global_step: 9285, epoch: 33, loss: 0.415930
global_step: 9286, epoch: 33, loss: 0.421258
global_step: 9287, epoch: 33, loss: 0.445517
global_step: 9288, epoch: 33, loss: 0.436886
global_step: 9289, epoch: 33, loss: 0.456978
global_step: 9290, epoch: 33, loss: 0.454721
global_step: 9291, epoch: 33, loss: 0.401006
global_step: 9292, epoch: 33, loss: 0.357707
global_step: 9293, epoch: 33, loss: 0.480837
global_step: 9294, epoch: 33, loss: 0.357001
global_step: 9295, epoch: 33, loss: 0.503187
global_step: 9296, epoch: 33, loss: 0.330983
global_step: 9297, epoch: 33, loss: 0.373413
global_step: 9298, epoch: 33, loss: 0.366230
global_step: 9299, epoch: 33, loss: 0.360024
global_step: 9300, epoch: 33, loss: 0.326779
global_step: 9301, epoch: 33, loss: 0.469460
global_step: 9302, epoch: 33, loss: 0.441067
global_step: 9303, epoch: 33, loss: 0.385022
global_step: 9304, epoch: 33, loss: 0.391294
global_step: 9305, epoch: 33, loss: 0.540502
global_step: 9306, epoch: 33, loss: 0.407967
global_step: 9307, epoch: 33, loss: 0.542588
global_step: 9308, epoch: 33, loss: 0.431904
global_step: 9309, epoch: 33, loss: 0.513713
global_step: 9310, epoch: 33, loss: 0.449915
global_step: 9311, epoch: 33, loss: 0.354103
global_step: 9312, epoch: 33, loss: 0.449975
global_step: 9313, epoch: 33, loss: 0.414054
global_step: 9314, epoch: 33, loss: 0.422366
global_step: 9315, epoch: 33, loss: 0.475224
global_step: 9316, epoch: 33, loss: 0.479045
global_step: 9317, epoch: 33, loss: 0.396690
global_step: 9318, epoch: 33, loss: 0.324614
global_step: 9319, epoch: 33, loss: 0.332894
global_step: 9320, epoch: 33, loss: 0.885410
epoch: 33
train	acc: 0.9428	macro: p 0.9300, r 0.9160, f1: 0.9212	micro: p 0.9428, r 0.9428, f1 0.9428	weighted_f1:0.9429
dev	acc: 0.5149	macro: p 0.3531, r 0.2985, f1: 0.2905	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4636
test	acc: 0.5648	macro: p 0.3522, r 0.3110, f1: 0.3106	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5292
global_step: 9321, epoch: 34, loss: 0.402262
global_step: 9322, epoch: 34, loss: 0.527015
global_step: 9323, epoch: 34, loss: 0.377055
global_step: 9324, epoch: 34, loss: 0.401754
global_step: 9325, epoch: 34, loss: 0.412439
global_step: 9326, epoch: 34, loss: 0.337932
global_step: 9327, epoch: 34, loss: 0.399798
global_step: 9328, epoch: 34, loss: 0.350920
global_step: 9329, epoch: 34, loss: 0.374952
global_step: 9330, epoch: 34, loss: 0.403200
global_step: 9331, epoch: 34, loss: 0.361684
global_step: 9332, epoch: 34, loss: 0.590963
global_step: 9333, epoch: 34, loss: 0.418517
global_step: 9334, epoch: 34, loss: 0.353923
global_step: 9335, epoch: 34, loss: 0.334083
global_step: 9336, epoch: 34, loss: 0.443729
global_step: 9337, epoch: 34, loss: 0.322996
global_step: 9338, epoch: 34, loss: 0.339204
global_step: 9339, epoch: 34, loss: 0.396402
global_step: 9340, epoch: 34, loss: 0.359647
global_step: 9341, epoch: 34, loss: 0.379738
global_step: 9342, epoch: 34, loss: 0.334428
global_step: 9343, epoch: 34, loss: 0.488760
global_step: 9344, epoch: 34, loss: 0.480157
global_step: 9345, epoch: 34, loss: 0.347385
global_step: 9346, epoch: 34, loss: 0.433231
global_step: 9347, epoch: 34, loss: 0.364655
global_step: 9348, epoch: 34, loss: 0.424384
global_step: 9349, epoch: 34, loss: 0.491348
global_step: 9350, epoch: 34, loss: 0.401997
global_step: 9351, epoch: 34, loss: 0.446911
global_step: 9352, epoch: 34, loss: 0.405407
global_step: 9353, epoch: 34, loss: 0.527754
global_step: 9354, epoch: 34, loss: 0.575358
global_step: 9355, epoch: 34, loss: 0.481147
global_step: 9356, epoch: 34, loss: 0.477125
global_step: 9357, epoch: 34, loss: 0.425394
global_step: 9358, epoch: 34, loss: 0.392086
global_step: 9359, epoch: 34, loss: 0.385547
global_step: 9360, epoch: 34, loss: 0.087743
epoch: 34
train	acc: 0.9454	macro: p 0.9516, r 0.9152, f1: 0.9320	micro: p 0.9454, r 0.9454, f1 0.9454	weighted_f1:0.9454
dev	acc: 0.4959	macro: p 0.3287, r 0.2939, f1: 0.2912	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4655
test	acc: 0.5625	macro: p 0.3537, r 0.3164, f1: 0.3163	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.5376
global_step: 9361, epoch: 35, loss: 0.421366
global_step: 9362, epoch: 35, loss: 0.271821
global_step: 9363, epoch: 35, loss: 0.384314
global_step: 9364, epoch: 35, loss: 0.434886
global_step: 9365, epoch: 35, loss: 0.312018
global_step: 9366, epoch: 35, loss: 0.380151
global_step: 9367, epoch: 35, loss: 0.468608
global_step: 9368, epoch: 35, loss: 0.296446
global_step: 9369, epoch: 35, loss: 0.473360
global_step: 9370, epoch: 35, loss: 0.302661
global_step: 9371, epoch: 35, loss: 0.390301
global_step: 9372, epoch: 35, loss: 0.292925
global_step: 9373, epoch: 35, loss: 0.384720
global_step: 9374, epoch: 35, loss: 0.344205
global_step: 9375, epoch: 35, loss: 0.304865
global_step: 9376, epoch: 35, loss: 0.364921
global_step: 9377, epoch: 35, loss: 0.458529
global_step: 9378, epoch: 35, loss: 0.392515
global_step: 9379, epoch: 35, loss: 0.406322
global_step: 9380, epoch: 35, loss: 0.414092
global_step: 9381, epoch: 35, loss: 0.381545
global_step: 9382, epoch: 35, loss: 0.428837
global_step: 9383, epoch: 35, loss: 0.481996
global_step: 9384, epoch: 35, loss: 0.434200
global_step: 9385, epoch: 35, loss: 0.413723
global_step: 9386, epoch: 35, loss: 0.406481
global_step: 9387, epoch: 35, loss: 0.301552
global_step: 9388, epoch: 35, loss: 0.513219
global_step: 9389, epoch: 35, loss: 0.355615
global_step: 9390, epoch: 35, loss: 0.422727
global_step: 9391, epoch: 35, loss: 0.462666
global_step: 9392, epoch: 35, loss: 0.425904
global_step: 9393, epoch: 35, loss: 0.419771
global_step: 9394, epoch: 35, loss: 0.372977
global_step: 9395, epoch: 35, loss: 0.492865
global_step: 9396, epoch: 35, loss: 0.414548
global_step: 9397, epoch: 35, loss: 0.486305
global_step: 9398, epoch: 35, loss: 0.405388
global_step: 9399, epoch: 35, loss: 0.457575
global_step: 9400, epoch: 35, loss: 0.095011
epoch: 35
train	acc: 0.9443	macro: p 0.9594, r 0.9193, f1: 0.9379	micro: p 0.9443, r 0.9443, f1 0.9443	weighted_f1:0.9438
dev	acc: 0.4923	macro: p 0.3444, r 0.2662, f1: 0.2723	micro: p 0.4923, r 0.4923, f1 0.4923	weighted_f1:0.4431
test	acc: 0.5579	macro: p 0.3401, r 0.2911, f1: 0.3023	micro: p 0.5579, r 0.5579, f1 0.5579	weighted_f1:0.5200
global_step: 9401, epoch: 36, loss: 0.336154
global_step: 9402, epoch: 36, loss: 0.336889
global_step: 9403, epoch: 36, loss: 0.346416
global_step: 9404, epoch: 36, loss: 0.357112
global_step: 9405, epoch: 36, loss: 0.304287
global_step: 9406, epoch: 36, loss: 0.312527
global_step: 9407, epoch: 36, loss: 0.402781
global_step: 9408, epoch: 36, loss: 0.435118
global_step: 9409, epoch: 36, loss: 0.384198
global_step: 9410, epoch: 36, loss: 0.399926
global_step: 9411, epoch: 36, loss: 0.353902
global_step: 9412, epoch: 36, loss: 0.432356
global_step: 9413, epoch: 36, loss: 0.309512
global_step: 9414, epoch: 36, loss: 0.406274
global_step: 9415, epoch: 36, loss: 0.358134
global_step: 9416, epoch: 36, loss: 0.384347
global_step: 9417, epoch: 36, loss: 0.525065
global_step: 9418, epoch: 36, loss: 0.313479
global_step: 9419, epoch: 36, loss: 0.376153
global_step: 9420, epoch: 36, loss: 0.432376
global_step: 9421, epoch: 36, loss: 0.365505
global_step: 9422, epoch: 36, loss: 0.417074
global_step: 9423, epoch: 36, loss: 0.322011
global_step: 9424, epoch: 36, loss: 0.380275
global_step: 9425, epoch: 36, loss: 0.376965
global_step: 9426, epoch: 36, loss: 0.327595
global_step: 9427, epoch: 36, loss: 0.413114
global_step: 9428, epoch: 36, loss: 0.353353
global_step: 9429, epoch: 36, loss: 0.503766
global_step: 9430, epoch: 36, loss: 0.448689
global_step: 9431, epoch: 36, loss: 0.421874
global_step: 9432, epoch: 36, loss: 0.480487
global_step: 9433, epoch: 36, loss: 0.348583
global_step: 9434, epoch: 36, loss: 0.587124
global_step: 9435, epoch: 36, loss: 0.475003
global_step: 9436, epoch: 36, loss: 0.381681
global_step: 9437, epoch: 36, loss: 0.445020
global_step: 9438, epoch: 36, loss: 0.368946
global_step: 9439, epoch: 36, loss: 0.392567
global_step: 9440, epoch: 36, loss: 0.169075
epoch: 36
train	acc: 0.9433	macro: p 0.9469, r 0.9169, f1: 0.9297	micro: p 0.9433, r 0.9433, f1 0.9433	weighted_f1:0.9437
dev	acc: 0.4923	macro: p 0.3277, r 0.2933, f1: 0.2864	micro: p 0.4923, r 0.4923, f1 0.4923	weighted_f1:0.4606
test	acc: 0.5448	macro: p 0.3231, r 0.3173, f1: 0.3078	micro: p 0.5448, r 0.5448, f1 0.5448	weighted_f1:0.5228
global_step: 9441, epoch: 37, loss: 0.405983
global_step: 9442, epoch: 37, loss: 0.316905
global_step: 9443, epoch: 37, loss: 0.371553
global_step: 9444, epoch: 37, loss: 0.352075
global_step: 9445, epoch: 37, loss: 0.326337
global_step: 9446, epoch: 37, loss: 0.414846
global_step: 9447, epoch: 37, loss: 0.242654
global_step: 9448, epoch: 37, loss: 0.312032
global_step: 9449, epoch: 37, loss: 0.312060
global_step: 9450, epoch: 37, loss: 0.373762
global_step: 9451, epoch: 37, loss: 0.303899
global_step: 9452, epoch: 37, loss: 0.318282
global_step: 9453, epoch: 37, loss: 0.323540
global_step: 9454, epoch: 37, loss: 0.401769
global_step: 9455, epoch: 37, loss: 0.409141
global_step: 9456, epoch: 37, loss: 0.344677
global_step: 9457, epoch: 37, loss: 0.438194
global_step: 9458, epoch: 37, loss: 0.493602
global_step: 9459, epoch: 37, loss: 0.389388
global_step: 9460, epoch: 37, loss: 0.348417
global_step: 9461, epoch: 37, loss: 0.442925
global_step: 9462, epoch: 37, loss: 0.399810
global_step: 9463, epoch: 37, loss: 0.325560
global_step: 9464, epoch: 37, loss: 0.433933
global_step: 9465, epoch: 37, loss: 0.389380
global_step: 9466, epoch: 37, loss: 0.390316
global_step: 9467, epoch: 37, loss: 0.342574
global_step: 9468, epoch: 37, loss: 0.333635
global_step: 9469, epoch: 37, loss: 0.328915
global_step: 9470, epoch: 37, loss: 0.338693
global_step: 9471, epoch: 37, loss: 0.439456
global_step: 9472, epoch: 37, loss: 0.459217
global_step: 9473, epoch: 37, loss: 0.478375
global_step: 9474, epoch: 37, loss: 0.488737
global_step: 9475, epoch: 37, loss: 0.497856
global_step: 9476, epoch: 37, loss: 0.401274
global_step: 9477, epoch: 37, loss: 0.299865
global_step: 9478, epoch: 37, loss: 0.390112
global_step: 9479, epoch: 37, loss: 0.361921
global_step: 9480, epoch: 37, loss: 0.068109
epoch: 37
train	acc: 0.9572	macro: p 0.9636, r 0.9369, f1: 0.9496	micro: p 0.9572, r 0.9572, f1 0.9572	weighted_f1:0.9571
dev	acc: 0.5095	macro: p 0.3410, r 0.2951, f1: 0.2971	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4688
test	acc: 0.5628	macro: p 0.3416, r 0.3133, f1: 0.3170	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5315
global_step: 9481, epoch: 38, loss: 0.365469
global_step: 9482, epoch: 38, loss: 0.352586
global_step: 9483, epoch: 38, loss: 0.381792
global_step: 9484, epoch: 38, loss: 0.321501
global_step: 9485, epoch: 38, loss: 0.356077
global_step: 9486, epoch: 38, loss: 0.367825
global_step: 9487, epoch: 38, loss: 0.306715
global_step: 9488, epoch: 38, loss: 0.342841
global_step: 9489, epoch: 38, loss: 0.353289
global_step: 9490, epoch: 38, loss: 0.360933
global_step: 9491, epoch: 38, loss: 0.379675
global_step: 9492, epoch: 38, loss: 0.385072
global_step: 9493, epoch: 38, loss: 0.295576
global_step: 9494, epoch: 38, loss: 0.408530
global_step: 9495, epoch: 38, loss: 0.308540
global_step: 9496, epoch: 38, loss: 0.429243
global_step: 9497, epoch: 38, loss: 0.438282
global_step: 9498, epoch: 38, loss: 0.368042
global_step: 9499, epoch: 38, loss: 0.270524
global_step: 9500, epoch: 38, loss: 0.316932
global_step: 9501, epoch: 38, loss: 0.359134
global_step: 9502, epoch: 38, loss: 0.407897
global_step: 9503, epoch: 38, loss: 0.394427
global_step: 9504, epoch: 38, loss: 0.476662
global_step: 9505, epoch: 38, loss: 0.341951
global_step: 9506, epoch: 38, loss: 0.413234
global_step: 9507, epoch: 38, loss: 0.373261
global_step: 9508, epoch: 38, loss: 0.453790
global_step: 9509, epoch: 38, loss: 0.369142
global_step: 9510, epoch: 38, loss: 0.457540
global_step: 9511, epoch: 38, loss: 0.407526
global_step: 9512, epoch: 38, loss: 0.410548
global_step: 9513, epoch: 38, loss: 0.342173
global_step: 9514, epoch: 38, loss: 0.414785
global_step: 9515, epoch: 38, loss: 0.378460
global_step: 9516, epoch: 38, loss: 0.350206
global_step: 9517, epoch: 38, loss: 0.398060
global_step: 9518, epoch: 38, loss: 0.461348
global_step: 9519, epoch: 38, loss: 0.477277
global_step: 9520, epoch: 38, loss: 0.200725
epoch: 38
train	acc: 0.9499	macro: p 0.9559, r 0.9263, f1: 0.9397	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9501
dev	acc: 0.4977	macro: p 0.3893, r 0.3017, f1: 0.2948	micro: p 0.4977, r 0.4977, f1 0.4977	weighted_f1:0.4637
test	acc: 0.5456	macro: p 0.3282, r 0.3131, f1: 0.3038	micro: p 0.5456, r 0.5456, f1 0.5456	weighted_f1:0.5206
global_step: 9521, epoch: 39, loss: 0.336589
global_step: 9522, epoch: 39, loss: 0.368504
global_step: 9523, epoch: 39, loss: 0.338490
global_step: 9524, epoch: 39, loss: 0.465481
global_step: 9525, epoch: 39, loss: 0.391092
global_step: 9526, epoch: 39, loss: 0.431180
global_step: 9527, epoch: 39, loss: 0.258476
global_step: 9528, epoch: 39, loss: 0.356726
global_step: 9529, epoch: 39, loss: 0.323433
global_step: 9530, epoch: 39, loss: 0.279054
global_step: 9531, epoch: 39, loss: 0.391377
global_step: 9532, epoch: 39, loss: 0.365157
global_step: 9533, epoch: 39, loss: 0.324631
global_step: 9534, epoch: 39, loss: 0.432369
global_step: 9535, epoch: 39, loss: 0.340208
global_step: 9536, epoch: 39, loss: 0.426771
global_step: 9537, epoch: 39, loss: 0.395854
global_step: 9538, epoch: 39, loss: 0.324630
global_step: 9539, epoch: 39, loss: 0.275759
global_step: 9540, epoch: 39, loss: 0.375028
global_step: 9541, epoch: 39, loss: 0.441410
global_step: 9542, epoch: 39, loss: 0.435121
global_step: 9543, epoch: 39, loss: 0.327939
global_step: 9544, epoch: 39, loss: 0.326456
global_step: 9545, epoch: 39, loss: 0.522066
global_step: 9546, epoch: 39, loss: 0.311696
global_step: 9547, epoch: 39, loss: 0.484473
global_step: 9548, epoch: 39, loss: 0.356261
global_step: 9549, epoch: 39, loss: 0.388770
global_step: 9550, epoch: 39, loss: 0.353246
global_step: 9551, epoch: 39, loss: 0.374283
global_step: 9552, epoch: 39, loss: 0.338862
global_step: 9553, epoch: 39, loss: 0.382018
global_step: 9554, epoch: 39, loss: 0.330728
global_step: 9555, epoch: 39, loss: 0.369668
global_step: 9556, epoch: 39, loss: 0.466239
global_step: 9557, epoch: 39, loss: 0.369529
global_step: 9558, epoch: 39, loss: 0.410106
global_step: 9559, epoch: 39, loss: 0.376808
global_step: 9560, epoch: 39, loss: 0.176541
epoch: 39
train	acc: 0.9490	macro: p 0.9511, r 0.9365, f1: 0.9429	micro: p 0.9490, r 0.9490, f1 0.9490	weighted_f1:0.9494
dev	acc: 0.4815	macro: p 0.3566, r 0.3060, f1: 0.3033	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.4668
test	acc: 0.5218	macro: p 0.3298, r 0.3177, f1: 0.3136	micro: p 0.5218, r 0.5218, f1 0.5218	weighted_f1:0.5163
global_step: 9561, epoch: 40, loss: 0.336152
global_step: 9562, epoch: 40, loss: 0.418746
global_step: 9563, epoch: 40, loss: 0.257507
global_step: 9564, epoch: 40, loss: 0.443093
global_step: 9565, epoch: 40, loss: 0.343453
global_step: 9566, epoch: 40, loss: 0.342744
global_step: 9567, epoch: 40, loss: 0.341907
global_step: 9568, epoch: 40, loss: 0.423525
global_step: 9569, epoch: 40, loss: 0.322032
global_step: 9570, epoch: 40, loss: 0.312060
global_step: 9571, epoch: 40, loss: 0.248159
global_step: 9572, epoch: 40, loss: 0.341717
global_step: 9573, epoch: 40, loss: 0.321714
global_step: 9574, epoch: 40, loss: 0.442283
global_step: 9575, epoch: 40, loss: 0.312891
global_step: 9576, epoch: 40, loss: 0.324249
global_step: 9577, epoch: 40, loss: 0.363077
global_step: 9578, epoch: 40, loss: 0.320652
global_step: 9579, epoch: 40, loss: 0.377117
global_step: 9580, epoch: 40, loss: 0.335743
global_step: 9581, epoch: 40, loss: 0.426200
global_step: 9582, epoch: 40, loss: 0.314726
global_step: 9583, epoch: 40, loss: 0.399265
global_step: 9584, epoch: 40, loss: 0.348997
global_step: 9585, epoch: 40, loss: 0.349110
global_step: 9586, epoch: 40, loss: 0.252501
global_step: 9587, epoch: 40, loss: 0.473687
global_step: 9588, epoch: 40, loss: 0.377164
global_step: 9589, epoch: 40, loss: 0.382918
global_step: 9590, epoch: 40, loss: 0.291249
global_step: 9591, epoch: 40, loss: 0.381463
global_step: 9592, epoch: 40, loss: 0.373641
global_step: 9593, epoch: 40, loss: 0.463044
global_step: 9594, epoch: 40, loss: 0.432877
global_step: 9595, epoch: 40, loss: 0.355742
global_step: 9596, epoch: 40, loss: 0.330795
global_step: 9597, epoch: 40, loss: 0.333200
global_step: 9598, epoch: 40, loss: 0.363588
global_step: 9599, epoch: 40, loss: 0.276308
global_step: 9600, epoch: 40, loss: 1.097119
epoch: 40
train	acc: 0.9566	macro: p 0.9579, r 0.9409, f1: 0.9490	micro: p 0.9566, r 0.9566, f1 0.9566	weighted_f1:0.9566
dev	acc: 0.5041	macro: p 0.3779, r 0.3017, f1: 0.3075	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4690
test	acc: 0.5548	macro: p 0.3352, r 0.3089, f1: 0.3108	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5253
global_step: 9601, epoch: 41, loss: 0.281144
global_step: 9602, epoch: 41, loss: 0.298545
global_step: 9603, epoch: 41, loss: 0.339018
global_step: 9604, epoch: 41, loss: 0.379489
global_step: 9605, epoch: 41, loss: 0.320398
global_step: 9606, epoch: 41, loss: 0.282919
global_step: 9607, epoch: 41, loss: 0.327531
global_step: 9608, epoch: 41, loss: 0.413925
global_step: 9609, epoch: 41, loss: 0.359323
global_step: 9610, epoch: 41, loss: 0.316442
global_step: 9611, epoch: 41, loss: 0.396214
global_step: 9612, epoch: 41, loss: 0.416543
global_step: 9613, epoch: 41, loss: 0.383586
global_step: 9614, epoch: 41, loss: 0.418439
global_step: 9615, epoch: 41, loss: 0.379333
global_step: 9616, epoch: 41, loss: 0.267328
global_step: 9617, epoch: 41, loss: 0.350940
global_step: 9618, epoch: 41, loss: 0.363631
global_step: 9619, epoch: 41, loss: 0.430435
global_step: 9620, epoch: 41, loss: 0.269138
global_step: 9621, epoch: 41, loss: 0.303049
global_step: 9622, epoch: 41, loss: 0.287506
global_step: 9623, epoch: 41, loss: 0.385998
global_step: 9624, epoch: 41, loss: 0.439982
global_step: 9625, epoch: 41, loss: 0.355409
global_step: 9626, epoch: 41, loss: 0.325094
global_step: 9627, epoch: 41, loss: 0.317921
global_step: 9628, epoch: 41, loss: 0.307420
global_step: 9629, epoch: 41, loss: 0.397673
global_step: 9630, epoch: 41, loss: 0.353988
global_step: 9631, epoch: 41, loss: 0.454062
global_step: 9632, epoch: 41, loss: 0.351473
global_step: 9633, epoch: 41, loss: 0.393981
global_step: 9634, epoch: 41, loss: 0.393302
global_step: 9635, epoch: 41, loss: 0.352514
global_step: 9636, epoch: 41, loss: 0.308830
global_step: 9637, epoch: 41, loss: 0.342297
global_step: 9638, epoch: 41, loss: 0.393235
global_step: 9639, epoch: 41, loss: 0.328070
global_step: 9640, epoch: 41, loss: 0.298245
epoch: 41
train	acc: 0.9527	macro: p 0.9578, r 0.9345, f1: 0.9452	micro: p 0.9527, r 0.9527, f1 0.9527	weighted_f1:0.9525
dev	acc: 0.5014	macro: p 0.3079, r 0.2749, f1: 0.2711	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4529
test	acc: 0.5640	macro: p 0.3472, r 0.2984, f1: 0.3049	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5292
global_step: 9641, epoch: 42, loss: 0.416912
global_step: 9642, epoch: 42, loss: 0.298096
global_step: 9643, epoch: 42, loss: 0.302875
global_step: 9644, epoch: 42, loss: 0.315451
global_step: 9645, epoch: 42, loss: 0.381504
global_step: 9646, epoch: 42, loss: 0.295585
global_step: 9647, epoch: 42, loss: 0.277941
global_step: 9648, epoch: 42, loss: 0.376811
global_step: 9649, epoch: 42, loss: 0.309867
global_step: 9650, epoch: 42, loss: 0.434403
global_step: 9651, epoch: 42, loss: 0.299364
global_step: 9652, epoch: 42, loss: 0.368596
global_step: 9653, epoch: 42, loss: 0.304116
global_step: 9654, epoch: 42, loss: 0.381722
global_step: 9655, epoch: 42, loss: 0.299773
global_step: 9656, epoch: 42, loss: 0.323669run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

global_step: 9657, epoch: 42, loss: 0.342232
global_step: 9658, epoch: 42, loss: 0.291337
global_step: 9659, epoch: 42, loss: 0.398568
global_step: 9660, epoch: 42, loss: 0.358029
global_step: 9661, epoch: 42, loss: 0.236324
global_step: 9662, epoch: 42, loss: 0.307853
global_step: 9663, epoch: 42, loss: 0.286975
global_step: 9664, epoch: 42, loss: 0.320002
global_step: 9665, epoch: 42, loss: 0.405018
global_step: 9666, epoch: 42, loss: 0.369504
global_step: 9667, epoch: 42, loss: 0.402217
global_step: 9668, epoch: 42, loss: 0.412897
global_step: 9669, epoch: 42, loss: 0.297818
global_step: 9670, epoch: 42, loss: 0.357319
global_step: 9671, epoch: 42, loss: 0.306856
global_step: 9672, epoch: 42, loss: 0.370653
global_step: 9673, epoch: 42, loss: 0.412926
global_step: 9674, epoch: 42, loss: 0.364878
global_step: 9675, epoch: 42, loss: 0.388009
global_step: 9676, epoch: 42, loss: 0.418964
global_step: 9677, epoch: 42, loss: 0.318744
global_step: 9678, epoch: 42, loss: 0.448240
global_step: 9679, epoch: 42, loss: 0.411451
global_step: 9680, epoch: 42, loss: 0.275203
epoch: 42
train	acc: 0.9607	macro: p 0.9631, r 0.9426, f1: 0.9524	micro: p 0.9607, r 0.9607, f1 0.9607	weighted_f1:0.9606
dev	acc: 0.4959	macro: p 0.4672, r 0.2963, f1: 0.3042	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4636
test	acc: 0.5586	macro: p 0.3285, r 0.3102, f1: 0.3129	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.5333
global_step: 9681, epoch: 43, loss: 0.266205
global_step: 9682, epoch: 43, loss: 0.329326
global_step: 9683, epoch: 43, loss: 0.254413
global_step: 9684, epoch: 43, loss: 0.376829
global_step: 9685, epoch: 43, loss: 0.328766
global_step: 9686, epoch: 43, loss: 0.301352
global_step: 9687, epoch: 43, loss: 0.366513
global_step: 9688, epoch: 43, loss: 0.285843
global_step: 9689, epoch: 43, loss: 0.380185
global_step: 9690, epoch: 43, loss: 0.398208
global_step: 9691, epoch: 43, loss: 0.299523
global_step: 9692, epoch: 43, loss: 0.320918
global_step: 9693, epoch: 43, loss: 0.236456
global_step: 9694, epoch: 43, loss: 0.280551
global_step: 9695, epoch: 43, loss: 0.340174
global_step: 9696, epoch: 43, loss: 0.355434
global_step: 9697, epoch: 43, loss: 0.332926
global_step: 9698, epoch: 43, loss: 0.375304
global_step: 9699, epoch: 43, loss: 0.331815
global_step: 9700, epoch: 43, loss: 0.344559
global_step: 9701, epoch: 43, loss: 0.420425
global_step: 9702, epoch: 43, loss: 0.327478
global_step: 9703, epoch: 43, loss: 0.383698
global_step: 9704, epoch: 43, loss: 0.356813
global_step: 9705, epoch: 43, loss: 0.344795
global_step: 9706, epoch: 43, loss: 0.364913
global_step: 9707, epoch: 43, loss: 0.355576
global_step: 9708, epoch: 43, loss: 0.258800
global_step: 9709, epoch: 43, loss: 0.340686
global_step: 9710, epoch: 43, loss: 0.283551
global_step: 9711, epoch: 43, loss: 0.387431
global_step: 9712, epoch: 43, loss: 0.341997
global_step: 9713, epoch: 43, loss: 0.310014
global_step: 9714, epoch: 43, loss: 0.316345
global_step: 9715, epoch: 43, loss: 0.356227
global_step: 9716, epoch: 43, loss: 0.372884
global_step: 9717, epoch: 43, loss: 0.383071
global_step: 9718, epoch: 43, loss: 0.415437
global_step: 9719, epoch: 43, loss: 0.389165
global_step: 9720, epoch: 43, loss: 0.953616
epoch: 43
train	acc: 0.9573	macro: p 0.9627, r 0.9381, f1: 0.9499	micro: p 0.9573, r 0.9573, f1 0.9573	weighted_f1:0.9572
dev	acc: 0.5140	macro: p 0.3501, r 0.2951, f1: 0.2977	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4660
test	acc: 0.5628	macro: p 0.3289, r 0.2971, f1: 0.3024	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5256
global_step: 9721, epoch: 44, loss: 0.374834
global_step: 9722, epoch: 44, loss: 0.436986
global_step: 9723, epoch: 44, loss: 0.339215
global_step: 9724, epoch: 44, loss: 0.306918
global_step: 9725, epoch: 44, loss: 0.324668
global_step: 9726, epoch: 44, loss: 0.273585
global_step: 9727, epoch: 44, loss: 0.280221
global_step: 9728, epoch: 44, loss: 0.199953
global_step: 9729, epoch: 44, loss: 0.370473
global_step: 9730, epoch: 44, loss: 0.406658
global_step: 9731, epoch: 44, loss: 0.359041
global_step: 9732, epoch: 44, loss: 0.362860
global_step: 9733, epoch: 44, loss: 0.310798
global_step: 9734, epoch: 44, loss: 0.272162
global_step: 9735, epoch: 44, loss: 0.254311
global_step: 9736, epoch: 44, loss: 0.359426
global_step: 9737, epoch: 44, loss: 0.329445
global_step: 9738, epoch: 44, loss: 0.478337
global_step: 9739, epoch: 44, loss: 0.275843
global_step: 9740, epoch: 44, loss: 0.262434
global_step: 9741, epoch: 44, loss: 0.406007
global_step: 9742, epoch: 44, loss: 0.316789
global_step: 9743, epoch: 44, loss: 0.369009
global_step: 9744, epoch: 44, loss: 0.338728
global_step: 9745, epoch: 44, loss: 0.421372
global_step: 9746, epoch: 44, loss: 0.353651
global_step: 9747, epoch: 44, loss: 0.371030
global_step: 9748, epoch: 44, loss: 0.288309
global_step: 9749, epoch: 44, loss: 0.293162
global_step: 9750, epoch: 44, loss: 0.446861
global_step: 9751, epoch: 44, loss: 0.279238
global_step: 9752, epoch: 44, loss: 0.336454
global_step: 9753, epoch: 44, loss: 0.301041
global_step: 9754, epoch: 44, loss: 0.304682
global_step: 9755, epoch: 44, loss: 0.299206
global_step: 9756, epoch: 44, loss: 0.283836
global_step: 9757, epoch: 44, loss: 0.365848
global_step: 9758, epoch: 44, loss: 0.404118
global_step: 9759, epoch: 44, loss: 0.277851
global_step: 9760, epoch: 44, loss: 0.286243
epoch: 44
train	acc: 0.9493	macro: p 0.9537, r 0.9319, f1: 0.9420	micro: p 0.9493, r 0.9493, f1 0.9493	weighted_f1:0.9494
dev	acc: 0.4680	macro: p 0.3715, r 0.3035, f1: 0.3055	micro: p 0.4680, r 0.4680, f1 0.4680	weighted_f1:0.4532
test	acc: 0.5337	macro: p 0.3309, r 0.3181, f1: 0.3142	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.5272
global_step: 9761, epoch: 45, loss: 0.357927
global_step: 9762, epoch: 45, loss: 0.357415
global_step: 9763, epoch: 45, loss: 0.339025
global_step: 9764, epoch: 45, loss: 0.320555
global_step: 9765, epoch: 45, loss: 0.381333
global_step: 9766, epoch: 45, loss: 0.299272
global_step: 9767, epoch: 45, loss: 0.353438
global_step: 9768, epoch: 45, loss: 0.309867
global_step: 9769, epoch: 45, loss: 0.434222
global_step: 9770, epoch: 45, loss: 0.344717
global_step: 9771, epoch: 45, loss: 0.297686
global_step: 9772, epoch: 45, loss: 0.346866
global_step: 9773, epoch: 45, loss: 0.370833
global_step: 9774, epoch: 45, loss: 0.314474
global_step: 9775, epoch: 45, loss: 0.303830
global_step: 9776, epoch: 45, loss: 0.324861
global_step: 9777, epoch: 45, loss: 0.293270
global_step: 9778, epoch: 45, loss: 0.284985
global_step: 9779, epoch: 45, loss: 0.330070
global_step: 9780, epoch: 45, loss: 0.329906
global_step: 9781, epoch: 45, loss: 0.308550
global_step: 9782, epoch: 45, loss: 0.353650
global_step: 9783, epoch: 45, loss: 0.336365
global_step: 9784, epoch: 45, loss: 0.234541
global_step: 9785, epoch: 45, loss: 0.318476
global_step: 9786, epoch: 45, loss: 0.330576
global_step: 9787, epoch: 45, loss: 0.292542
global_step: 9788, epoch: 45, loss: 0.403045
global_step: 9789, epoch: 45, loss: 0.354098
global_step: 9790, epoch: 45, loss: 0.284574
global_step: 9791, epoch: 45, loss: 0.241244
global_step: 9792, epoch: 45, loss: 0.319714
global_step: 9793, epoch: 45, loss: 0.363591
global_step: 9794, epoch: 45, loss: 0.249293
global_step: 9795, epoch: 45, loss: 0.297180
global_step: 9796, epoch: 45, loss: 0.222393
global_step: 9797, epoch: 45, loss: 0.406357
global_step: 9798, epoch: 45, loss: 0.347398
global_step: 9799, epoch: 45, loss: 0.315067
global_step: 9800, epoch: 45, loss: 0.158529
epoch: 45
train	acc: 0.9614	macro: p 0.9632, r 0.9459, f1: 0.9541	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9614
dev	acc: 0.4986	macro: p 0.3348, r 0.2971, f1: 0.2942	micro: p 0.4986, r 0.4986, f1 0.4986	weighted_f1:0.4614
test	acc: 0.5628	macro: p 0.3551, r 0.3279, f1: 0.3313	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5403
global_step: 9801, epoch: 46, loss: 0.298554
global_step: 9802, epoch: 46, loss: 0.234919
global_step: 9803, epoch: 46, loss: 0.404690
global_step: 9804, epoch: 46, loss: 0.357891
global_step: 9805, epoch: 46, loss: 0.254091
global_step: 9806, epoch: 46, loss: 0.300874
global_step: 9807, epoch: 46, loss: 0.296955
global_step: 9808, epoch: 46, loss: 0.260310
global_step: 9809, epoch: 46, loss: 0.320070
global_step: 9810, epoch: 46, loss: 0.312531
global_step: 9811, epoch: 46, loss: 0.324639
global_step: 9812, epoch: 46, loss: 0.321045
global_step: 9813, epoch: 46, loss: 0.351556
global_step: 9814, epoch: 46, loss: 0.282263
global_step: 9815, epoch: 46, loss: 0.293316
global_step: 9816, epoch: 46, loss: 0.290807
global_step: 9817, epoch: 46, loss: 0.380532
global_step: 9818, epoch: 46, loss: 0.333071
global_step: 9819, epoch: 46, loss: 0.302925
global_step: 9820, epoch: 46, loss: 0.295713
global_step: 9821, epoch: 46, loss: 0.262738
global_step: 9822, epoch: 46, loss: 0.307905
global_step: 9823, epoch: 46, loss: 0.321202
global_step: 9824, epoch: 46, loss: 0.361516
global_step: 9825, epoch: 46, loss: 0.294903
global_step: 9826, epoch: 46, loss: 0.279569
global_step: 9827, epoch: 46, loss: 0.260648
global_step: 9828, epoch: 46, loss: 0.339564
global_step: 9829, epoch: 46, loss: 0.271490
global_step: 9830, epoch: 46, loss: 0.246845
global_step: 9831, epoch: 46, loss: 0.378463
global_step: 9832, epoch: 46, loss: 0.269860
global_step: 9833, epoch: 46, loss: 0.336090
global_step: 9834, epoch: 46, loss: 0.308884
global_step: 9835, epoch: 46, loss: 0.334895
global_step: 9836, epoch: 46, loss: 0.399595
global_step: 9837, epoch: 46, loss: 0.296572
global_step: 9838, epoch: 46, loss: 0.402196
global_step: 9839, epoch: 46, loss: 0.408685
global_step: 9840, epoch: 46, loss: 0.585240
epoch: 46
train	acc: 0.9581	macro: p 0.9599, r 0.9454, f1: 0.9519	micro: p 0.9581, r 0.9581, f1 0.9581	weighted_f1:0.9583
dev	acc: 0.4860	macro: p 0.3553, r 0.3083, f1: 0.3020	micro: p 0.4860, r 0.4860, f1 0.4860	weighted_f1:0.4526
test	acc: 0.5448	macro: p 0.3342, r 0.3168, f1: 0.3071	micro: p 0.5448, r 0.5448, f1 0.5448	weighted_f1:0.5204
global_step: 9841, epoch: 47, loss: 0.349551
global_step: 9842, epoch: 47, loss: 0.275482
global_step: 9843, epoch: 47, loss: 0.366579
global_step: 9844, epoch: 47, loss: 0.285205
global_step: 9845, epoch: 47, loss: 0.321989
global_step: 9846, epoch: 47, loss: 0.343482
global_step: 9847, epoch: 47, loss: 0.337674
global_step: 9848, epoch: 47, loss: 0.322544
global_step: 9849, epoch: 47, loss: 0.293184
global_step: 9850, epoch: 47, loss: 0.330300
global_step: 9851, epoch: 47, loss: 0.234144
global_step: 9852, epoch: 47, loss: 0.287689
global_step: 9853, epoch: 47, loss: 0.286370
global_step: 9854, epoch: 47, loss: 0.268852
global_step: 9855, epoch: 47, loss: 0.315518
global_step: 9856, epoch: 47, loss: 0.358613
global_step: 9857, epoch: 47, loss: 0.278584
global_step: 9858, epoch: 47, loss: 0.248780
global_step: 9859, epoch: 47, loss: 0.247122
global_step: 9860, epoch: 47, loss: 0.242476
global_step: 9861, epoch: 47, loss: 0.295230
global_step: 9862, epoch: 47, loss: 0.347494
global_step: 9863, epoch: 47, loss: 0.272765
global_step: 9864, epoch: 47, loss: 0.334776
global_step: 9865, epoch: 47, loss: 0.358345
global_step: 9866, epoch: 47, loss: 0.354597
global_step: 9867, epoch: 47, loss: 0.363430
global_step: 9868, epoch: 47, loss: 0.237947
global_step: 9869, epoch: 47, loss: 0.357247
global_step: 9870, epoch: 47, loss: 0.263034
global_step: 9871, epoch: 47, loss: 0.307126
global_step: 9872, epoch: 47, loss: 0.352271
global_step: 9873, epoch: 47, loss: 0.387380
global_step: 9874, epoch: 47, loss: 0.363131
global_step: 9875, epoch: 47, loss: 0.264329
global_step: 9876, epoch: 47, loss: 0.316725
global_step: 9877, epoch: 47, loss: 0.339475
global_step: 9878, epoch: 47, loss: 0.267805
global_step: 9879, epoch: 47, loss: 0.241115
global_step: 9880, epoch: 47, loss: 0.024973
epoch: 47
train	acc: 0.9621	macro: p 0.9697, r 0.9421, f1: 0.9553	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9620
dev	acc: 0.5239	macro: p 0.4030, r 0.2978, f1: 0.3017	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4739
test	acc: 0.5720	macro: p 0.3509, r 0.3056, f1: 0.3113	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5312
global_step: 9881, epoch: 48, loss: 0.362063
global_step: 9882, epoch: 48, loss: 0.305334
global_step: 9883, epoch: 48, loss: 0.292616
global_step: 9884, epoch: 48, loss: 0.203145
global_step: 9885, epoch: 48, loss: 0.283788
global_step: 9886, epoch: 48, loss: 0.224331
global_step: 9887, epoch: 48, loss: 0.320327
global_step: 9888, epoch: 48, loss: 0.281150
global_step: 9889, epoch: 48, loss: 0.290964
global_step: 9890, epoch: 48, loss: 0.280970
global_step: 9891, epoch: 48, loss: 0.305259
global_step: 9892, epoch: 48, loss: 0.324724
global_step: 9893, epoch: 48, loss: 0.291343
global_step: 9894, epoch: 48, loss: 0.216496
global_step: 9895, epoch: 48, loss: 0.213979
global_step: 9896, epoch: 48, loss: 0.262544
global_step: 9897, epoch: 48, loss: 0.287224
global_step: 9898, epoch: 48, loss: 0.274047
global_step: 9899, epoch: 48, loss: 0.349516
global_step: 9900, epoch: 48, loss: 0.342639
global_step: 9901, epoch: 48, loss: 0.342706
global_step: 9902, epoch: 48, loss: 0.257479
global_step: 9903, epoch: 48, loss: 0.301028
global_step: 9904, epoch: 48, loss: 0.297779
global_step: 9905, epoch: 48, loss: 0.370578
global_step: 9906, epoch: 48, loss: 0.303339
global_step: 9907, epoch: 48, loss: 0.234379
global_step: 9908, epoch: 48, loss: 0.400236
global_step: 9909, epoch: 48, loss: 0.306403
global_step: 9910, epoch: 48, loss: 0.304519
global_step: 9911, epoch: 48, loss: 0.289612
global_step: 9912, epoch: 48, loss: 0.306868
global_step: 9913, epoch: 48, loss: 0.357996
global_step: 9914, epoch: 48, loss: 0.251552
global_step: 9915, epoch: 48, loss: 0.292260
global_step: 9916, epoch: 48, loss: 0.338122
global_step: 9917, epoch: 48, loss: 0.280505
global_step: 9918, epoch: 48, loss: 0.343721
global_step: 9919, epoch: 48, loss: 0.313002
global_step: 9920, epoch: 48, loss: 0.396645
epoch: 48
train	acc: 0.9541	macro: p 0.9680, r 0.9333, f1: 0.9498	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9539
dev	acc: 0.5014	macro: p 0.3115, r 0.2636, f1: 0.2640	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4414
test	acc: 0.5724	macro: p 0.4036, r 0.2977, f1: 0.3157	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5220
global_step: 9921, epoch: 49, loss: 0.453008
global_step: 9922, epoch: 49, loss: 0.350682
global_step: 9923, epoch: 49, loss: 0.305347
global_step: 9924, epoch: 49, loss: 0.218702
global_step: 9925, epoch: 49, loss: 0.271508
global_step: 9926, epoch: 49, loss: 0.264740
global_step: 9927, epoch: 49, loss: 0.295137
global_step: 9928, epoch: 49, loss: 0.321596
global_step: 9929, epoch: 49, loss: 0.218767
global_step: 9930, epoch: 49, loss: 0.287083
global_step: 9931, epoch: 49, loss: 0.296350
global_step: 9932, epoch: 49, loss: 0.302140
global_step: 9933, epoch: 49, loss: 0.319276
global_step: 9934, epoch: 49, loss: 0.257532
global_step: 9935, epoch: 49, loss: 0.226274
global_step: 9936, epoch: 49, loss: 0.316334
global_step: 9937, epoch: 49, loss: 0.329528
global_step: 9938, epoch: 49, loss: 0.234511
global_step: 9939, epoch: 49, loss: 0.279646
global_step: 9940, epoch: 49, loss: 0.337786
global_step: 9941, epoch: 49, loss: 0.208476
global_step: 9942, epoch: 49, loss: 0.254566
global_step: 9943, epoch: 49, loss: 0.247782
global_step: 9944, epoch: 49, loss: 0.264864
global_step: 9945, epoch: 49, loss: 0.319867
global_step: 9946, epoch: 49, loss: 0.305827
global_step: 9947, epoch: 49, loss: 0.242410
global_step: 9948, epoch: 49, loss: 0.374642
global_step: 9949, epoch: 49, loss: 0.295729
global_step: 9950, epoch: 49, loss: 0.393352
global_step: 9951, epoch: 49, loss: 0.250960
global_step: 9952, epoch: 49, loss: 0.325012
global_step: 9953, epoch: 49, loss: 0.291066
global_step: 9954, epoch: 49, loss: 0.302857
global_step: 9955, epoch: 49, loss: 0.325626
global_step: 9956, epoch: 49, loss: 0.324609
global_step: 9957, epoch: 49, loss: 0.354319
global_step: 9958, epoch: 49, loss: 0.346651
global_step: 9959, epoch: 49, loss: 0.285691
global_step: 9960, epoch: 49, loss: 0.064487
epoch: 49
train	acc: 0.9618	macro: p 0.9616, r 0.9492, f1: 0.9550	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9618
dev	acc: 0.4986	macro: p 0.4004, r 0.3162, f1: 0.3241	micro: p 0.4986, r 0.4986, f1 0.4986	weighted_f1:0.4763
test	acc: 0.5471	macro: p 0.3231, r 0.3175, f1: 0.3154	micro: p 0.5471, r 0.5471, f1 0.5471	weighted_f1:0.5308
global_step: 9961, epoch: 50, loss: 0.285681
global_step: 9962, epoch: 50, loss: 0.286644
global_step: 9963, epoch: 50, loss: 0.267801
global_step: 9964, epoch: 50, loss: 0.236903
global_step: 9965, epoch: 50, loss: 0.299151
global_step: 9966, epoch: 50, loss: 0.320514
global_step: 9967, epoch: 50, loss: 0.361877
global_step: 9968, epoch: 50, loss: 0.215701
global_step: 9969, epoch: 50, loss: 0.263821
global_step: 9970, epoch: 50, loss: 0.307209
global_step: 9971, epoch: 50, loss: 0.322432
global_step: 9972, epoch: 50, loss: 0.291358
global_step: 9973, epoch: 50, loss: 0.302427
global_step: 9974, epoch: 50, loss: 0.194194
global_step: 9975, epoch: 50, loss: 0.269030
global_step: 9976, epoch: 50, loss: 0.349458
global_step: 9977, epoch: 50, loss: 0.365071
global_step: 9978, epoch: 50, loss: 0.277604
global_step: 9979, epoch: 50, loss: 0.392585
global_step: 9980, epoch: 50, loss: 0.367670
global_step: 9981, epoch: 50, loss: 0.405246
global_step: 9982, epoch: 50, loss: 0.259672
global_step: 9983, epoch: 50, loss: 0.248907
global_step: 9984, epoch: 50, loss: 0.275545
global_step: 9985, epoch: 50, loss: 0.315648
global_step: 9986, epoch: 50, loss: 0.357356
global_step: 9987, epoch: 50, loss: 0.355941
global_step: 9988, epoch: 50, loss: 0.280276
global_step: 9989, epoch: 50, loss: 0.403491
global_step: 9990, epoch: 50, loss: 0.362175
global_step: 9991, epoch: 50, loss: 0.231815
global_step: 9992, epoch: 50, loss: 0.433869
global_step: 9993, epoch: 50, loss: 0.333490
global_step: 9994, epoch: 50, loss: 0.294685
global_step: 9995, epoch: 50, loss: 0.260382
global_step: 9996, epoch: 50, loss: 0.392178
global_step: 9997, epoch: 50, loss: 0.258757
global_step: 9998, epoch: 50, loss: 0.235658
global_step: 9999, epoch: 50, loss: 0.316328
global_step: 10000, epoch: 50, loss: 0.203226
epoch: 50
train	acc: 0.9625	macro: p 0.9634, r 0.9488, f1: 0.9557	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9625
dev	acc: 0.4806	macro: p 0.3309, r 0.3098, f1: 0.3034	micro: p 0.4806, r 0.4806, f1 0.4806	weighted_f1:0.4589
test	acc: 0.5452	macro: p 0.3438, r 0.3240, f1: 0.3241	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5279
BEST MODEL epoch: 5
train	acc: 0.6465 macro_p: 0.4321 macro_r: 0.3758 macro_f1: 0.3887 micro_p: 0.6465 micro_r: 0.6465 micro_f1: 0.6465 weighted_f1: 0.6107
dev	acc: 0.5518 macro_p: 0.3515 macro_r: 0.3084 macro_f1: 0.3138 micro_p: 0.5518 micro_r: 0.5518 micro_f1: 0.5518 weighted_f1: 0.5048
test	acc: 0.5923 macro_p: 0.3474 macro_r: 0.3034 macro_f1: 0.3116 micro_p: 0.5923 micro_r: 0.5923 micro_f1: 0.5923 weighted_f1: 0.5476
====================TRAINING FINISHED====================
best epoch: [26, 11, 10, 38, 5], avg test weighted f1: 0.541206
