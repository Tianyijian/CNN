nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['Oh', 'God', ',', 'Ross', 'I', 'am', 'so', 'sorry', '.']   1
['Wow', ',', 'that', 'feels', 'so', 'good', 'to', 'get', 'off', 'my', 'chest', '!']   1

-------dev--------
1109 1109
['Stop', 'it', ',', 'stop', 'it', '!', 'He', 'talks', 'slow', 'but', 'he', 'might', 'pee', 'fast', '!', 'Ok', ',', 'let', "'s", 'go', '!', '!']   1
['Where', '?', 's', 'Ben', '?']   0

-------test--------
2610 2610
['Damn', 'you', '15s', '!']   4
['Okay', '?']   0
====================INFORMATION====================
MODEL: rand
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 100
LEARNING_RATE: 0.5
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
global_step: 1, epoch: 1, loss: 2.133476
global_step: 2, epoch: 1, loss: 1.871513
global_step: 3, epoch: 1, loss: 1.740711
global_step: 4, epoch: 1, loss: 1.631084
global_step: 5, epoch: 1, loss: 1.573984
global_step: 6, epoch: 1, loss: 1.482794
global_step: 7, epoch: 1, loss: 1.560135
global_step: 8, epoch: 1, loss: 1.519653
global_step: 9, epoch: 1, loss: 1.468606
global_step: 10, epoch: 1, loss: 1.475602
global_step: 11, epoch: 1, loss: 1.448257
global_step: 12, epoch: 1, loss: 1.486248
global_step: 13, epoch: 1, loss: 1.417669
global_step: 14, epoch: 1, loss: 1.420440
global_step: 15, epoch: 1, loss: 1.399762
global_step: 16, epoch: 1, loss: 1.348740
global_step: 17, epoch: 1, loss: 1.433288
global_step: 18, epoch: 1, loss: 1.384830
global_step: 19, epoch: 1, loss: 1.426636
global_step: 20, epoch: 1, loss: 1.485956
global_step: 21, epoch: 1, loss: 1.380038
global_step: 22, epoch: 1, loss: 1.329372
global_step: 23, epoch: 1, loss: 1.596272
global_step: 24, epoch: 1, loss: 1.430415
global_step: 25, epoch: 1, loss: 1.404032
global_step: 26, epoch: 1, loss: 1.467959
global_step: 27, epoch: 1, loss: 1.490235
global_step: 28, epoch: 1, loss: 1.421444
global_step: 29, epoch: 1, loss: 1.277609
global_step: 30, epoch: 1, loss: 1.387410
global_step: 31, epoch: 1, loss: 1.271603
global_step: 32, epoch: 1, loss: 1.342337
global_step: 33, epoch: 1, loss: 1.295924
global_step: 34, epoch: 1, loss: 1.459405
global_step: 35, epoch: 1, loss: 1.437378
global_step: 36, epoch: 1, loss: 1.444803
global_step: 37, epoch: 1, loss: 1.484485
global_step: 38, epoch: 1, loss: 1.330315
global_step: 39, epoch: 1, loss: 1.488112
global_step: 40, epoch: 1, loss: 1.278586
epoch: 1
train	acc: 0.5505	macro: p 0.3191, r 0.2491, f1: 0.2304	micro: p 0.5505, r 0.5505, f1 0.5505	weighted_f1:0.4646
dev	acc: 0.5032	macro: p 0.2958, r 0.2363, f1: 0.2129	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.4086
test	acc: 0.5644	macro: p 0.3126, r 0.2497, f1: 0.2402	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.4835
New best model!
global_step: 41, epoch: 2, loss: 1.447769
global_step: 42, epoch: 2, loss: 1.357334
global_step: 43, epoch: 2, loss: 1.278214
global_step: 44, epoch: 2, loss: 1.359346
global_step: 45, epoch: 2, loss: 1.431129
global_step: 46, epoch: 2, loss: 1.416652
global_step: 47, epoch: 2, loss: 1.264117
global_step: 48, epoch: 2, loss: 1.403955
global_step: 49, epoch: 2, loss: 1.352792
global_step: 50, epoch: 2, loss: 1.303487
global_step: 51, epoch: 2, loss: 1.281088
global_step: 52, epoch: 2, loss: 1.343107
global_step: 53, epoch: 2, loss: 1.306207
global_step: 54, epoch: 2, loss: 1.405787
global_step: 55, epoch: 2, loss: 1.357899
global_step: 56, epoch: 2, loss: 1.270907
global_step: 57, epoch: 2, loss: 1.385849
global_step: 58, epoch: 2, loss: 1.398137
global_step: 59, epoch: 2, loss: 1.363696
global_step: 60, epoch: 2, loss: 1.294534
global_step: 61, epoch: 2, loss: 1.323279
global_step: 62, epoch: 2, loss: 1.237401
global_step: 63, epoch: 2, loss: 1.212995
global_step: 64, epoch: 2, loss: 1.392097
global_step: 65, epoch: 2, loss: 1.405748
global_step: 66, epoch: 2, loss: 1.299949
global_step: 67, epoch: 2, loss: 1.350070
global_step: 68, epoch: 2, loss: 1.258168
global_step: 69, epoch: 2, loss: 1.415275
global_step: 70, epoch: 2, loss: 1.369536
global_step: 71, epoch: 2, loss: 1.326472
global_step: 72, epoch: 2, loss: 1.322020
global_step: 73, epoch: 2, loss: 1.383702
global_step: 74, epoch: 2, loss: 1.356481
global_step: 75, epoch: 2, loss: 1.303448
global_step: 76, epoch: 2, loss: 1.227772
global_step: 77, epoch: 2, loss: 1.328314
global_step: 78, epoch: 2, loss: 1.271518
global_step: 79, epoch: 2, loss: 1.338877
global_step: 80, epoch: 2, loss: 1.598583
epoch: 2
train	acc: 0.5469	macro: p 0.4589, r 0.2588, f1: 0.2353	micro: p 0.5469, r 0.5469, f1 0.5469	weighted_f1:0.4733
dev	acc: 0.5014	macro: p 0.2871, r 0.2433, f1: 0.2207	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4201
test	acc: 0.5682	macro: p 0.3194, r 0.2663, f1: 0.2521	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.4985
New best model!
global_step: 81, epoch: 3, loss: 1.338833
global_step: 82, epoch: 3, loss: 1.318314
global_step: 83, epoch: 3, loss: 1.248298
global_step: 84, epoch: 3, loss: 1.275207
global_step: 85, epoch: 3, loss: 1.251970
global_step: 86, epoch: 3, loss: 1.313676
global_step: 87, epoch: 3, loss: 1.249284
global_step: 88, epoch: 3, loss: 1.247254
global_step: 89, epoch: 3, loss: 1.332227
global_step: 90, epoch: 3, loss: 1.264168
global_step: 91, epoch: 3, loss: 1.259353
global_step: 92, epoch: 3, loss: 1.247811
global_step: 93, epoch: 3, loss: 1.261595
global_step: 94, epoch: 3, loss: 1.312664
global_step: 95, epoch: 3, loss: 1.219993
global_step: 96, epoch: 3, loss: 1.285562
global_step: 97, epoch: 3, loss: 1.285017
global_step: 98, epoch: 3, loss: 1.308990
global_step: 99, epoch: 3, loss: 1.300831
global_step: 100, epoch: 3, loss: 1.312342
global_step: 101, epoch: 3, loss: 1.285740
global_step: 102, epoch: 3, loss: 1.146232
global_step: 103, epoch: 3, loss: 1.400089
global_step: 104, epoch: 3, loss: 1.299445
global_step: 105, epoch: 3, loss: 1.245832
global_step: 106, epoch: 3, loss: 1.258984
global_step: 107, epoch: 3, loss: 1.260684
global_step: 108, epoch: 3, loss: 1.316291
global_step: 109, epoch: 3, loss: 1.176019
global_step: 110, epoch: 3, loss: 1.276372
global_step: 111, epoch: 3, loss: 1.361067
global_step: 112, epoch: 3, loss: 1.243600
global_step: 113, epoch: 3, loss: 1.299624
global_step: 114, epoch: 3, loss: 1.369475
global_step: 115, epoch: 3, loss: 1.272057
global_step: 116, epoch: 3, loss: 1.319520
global_step: 117, epoch: 3, loss: 1.369795
global_step: 118, epoch: 3, loss: 1.239211
global_step: 119, epoch: 3, loss: 1.347202
global_step: 120, epoch: 3, loss: 1.692127
epoch: 3
train	acc: 0.5785	macro: p 0.4618, r 0.2631, f1: 0.2692	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5022
dev	acc: 0.5050	macro: p 0.2741, r 0.2382, f1: 0.2251	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4147
test	acc: 0.5736	macro: p 0.3571, r 0.2552, f1: 0.2550	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.4931
global_step: 121, epoch: 4, loss: 1.419090
global_step: 122, epoch: 4, loss: 1.239931
global_step: 123, epoch: 4, loss: 1.255130
global_step: 124, epoch: 4, loss: 1.290534
global_step: 125, epoch: 4, loss: 1.193829
global_step: 126, epoch: 4, loss: 1.210378
global_step: 127, epoch: 4, loss: 1.213570
global_step: 128, epoch: 4, loss: 1.215852
global_step: 129, epoch: 4, loss: 1.241477
global_step: 130, epoch: 4, loss: 1.112417
global_step: 131, epoch: 4, loss: 1.220807
global_step: 132, epoch: 4, loss: 1.346256
global_step: 133, epoch: 4, loss: 1.228085
global_step: 134, epoch: 4, loss: 1.216599
global_step: 135, epoch: 4, loss: 1.255470
global_step: 136, epoch: 4, loss: 1.230100
global_step: 137, epoch: 4, loss: 1.125613
global_step: 138, epoch: 4, loss: 1.161049
global_step: 139, epoch: 4, loss: 1.126722
global_step: 140, epoch: 4, loss: 1.374953
global_step: 141, epoch: 4, loss: 1.193187
global_step: 142, epoch: 4, loss: 1.180970
global_step: 143, epoch: 4, loss: 1.253788
global_step: 144, epoch: 4, loss: 1.184866
global_step: 145, epoch: 4, loss: 1.316222
global_step: 146, epoch: 4, loss: 1.170153
global_step: 147, epoch: 4, loss: 1.286490
global_step: 148, epoch: 4, loss: 1.264179
global_step: 149, epoch: 4, loss: 1.172452
global_step: 150, epoch: 4, loss: 1.201869
global_step: 151, epoch: 4, loss: 1.311129
global_step: 152, epoch: 4, loss: 1.337910
global_step: 153, epoch: 4, loss: 1.283279
global_step: 154, epoch: 4, loss: 1.316394
global_step: 155, epoch: 4, loss: 1.327591
global_step: 156, epoch: 4, loss: 1.190416
global_step: 157, epoch: 4, loss: 1.300709
global_step: 158, epoch: 4, loss: 1.288336
global_step: 159, epoch: 4, loss: 1.205413
global_step: 160, epoch: 4, loss: 1.345458
epoch: 4
train	acc: 0.6059	macro: p 0.4223, r 0.3063, f1: 0.3140	micro: p 0.6059, r 0.6059, f1 0.6059	weighted_f1:0.5479
dev	acc: 0.5392	macro: p 0.3481, r 0.2849, f1: 0.2695	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4667
test	acc: 0.5805	macro: p 0.3546, r 0.2831, f1: 0.2762	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5156
New best model!
global_step: 161, epoch: 5, loss: 1.201168
global_step: 162, epoch: 5, loss: 1.286229
global_step: 163, epoch: 5, loss: 1.318856
global_step: 164, epoch: 5, loss: 1.222442
global_step: 165, epoch: 5, loss: 1.208755
global_step: 166, epoch: 5, loss: 1.256010
global_step: 167, epoch: 5, loss: 1.304903
global_step: 168, epoch: 5, loss: 1.123592
global_step: 169, epoch: 5, loss: 1.255958
global_step: 170, epoch: 5, loss: 1.085027
global_step: 171, epoch: 5, loss: 1.123574
global_step: 172, epoch: 5, loss: 1.221859
global_step: 173, epoch: 5, loss: 1.129987
global_step: 174, epoch: 5, loss: 1.271438
global_step: 175, epoch: 5, loss: 1.222190
global_step: 176, epoch: 5, loss: 1.286747
global_step: 177, epoch: 5, loss: 1.139437
global_step: 178, epoch: 5, loss: 1.190383
global_step: 179, epoch: 5, loss: 1.167428
global_step: 180, epoch: 5, loss: 1.127317
global_step: 181, epoch: 5, loss: 1.246205
global_step: 182, epoch: 5, loss: 1.106869
global_step: 183, epoch: 5, loss: 1.266507
global_step: 184, epoch: 5, loss: 1.182870
global_step: 185, epoch: 5, loss: 1.159359
global_step: 186, epoch: 5, loss: 1.216722
global_step: 187, epoch: 5, loss: 1.189818
global_step: 188, epoch: 5, loss: 1.125568
global_step: 189, epoch: 5, loss: 1.301335
global_step: 190, epoch: 5, loss: 1.255838
global_step: 191, epoch: 5, loss: 1.181330
global_step: 192, epoch: 5, loss: 1.278254
global_step: 193, epoch: 5, loss: 1.198509
global_step: 194, epoch: 5, loss: 1.096989
global_step: 195, epoch: 5, loss: 1.100304
global_step: 196, epoch: 5, loss: 1.155614
global_step: 197, epoch: 5, loss: 1.225477
global_step: 198, epoch: 5, loss: 1.235175
global_step: 199, epoch: 5, loss: 1.221748
global_step: 200, epoch: 5, loss: 0.897542
epoch: 5
train	acc: 0.6169	macro: p 0.4175, r 0.3388, f1: 0.3374	micro: p 0.6169, r 0.6169, f1 0.6169	weighted_f1:0.5722
dev	acc: 0.5041	macro: p 0.3320, r 0.2829, f1: 0.2633	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4514
test	acc: 0.5513	macro: p 0.3434, r 0.2867, f1: 0.2750	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5050
global_step: 201, epoch: 6, loss: 1.191422
global_step: 202, epoch: 6, loss: 1.315055
global_step: 203, epoch: 6, loss: 1.119934
global_step: 204, epoch: 6, loss: 1.173816
global_step: 205, epoch: 6, loss: 1.145131
global_step: 206, epoch: 6, loss: 1.207102
global_step: 207, epoch: 6, loss: 1.130461
global_step: 208, epoch: 6, loss: 1.169542
global_step: 209, epoch: 6, loss: 1.158303
global_step: 210, epoch: 6, loss: 1.136727
global_step: 211, epoch: 6, loss: 1.108225
global_step: 212, epoch: 6, loss: 1.129155
global_step: 213, epoch: 6, loss: 1.064086
global_step: 214, epoch: 6, loss: 1.159544
global_step: 215, epoch: 6, loss: 1.212872
global_step: 216, epoch: 6, loss: 1.172810
global_step: 217, epoch: 6, loss: 1.068649
global_step: 218, epoch: 6, loss: 1.035380
global_step: 219, epoch: 6, loss: 1.172326
global_step: 220, epoch: 6, loss: 1.211255
global_step: 221, epoch: 6, loss: 1.185008
global_step: 222, epoch: 6, loss: 1.309226
global_step: 223, epoch: 6, loss: 1.213800
global_step: 224, epoch: 6, loss: 1.188132
global_step: 225, epoch: 6, loss: 1.262502
global_step: 226, epoch: 6, loss: 1.193372
global_step: 227, epoch: 6, loss: 1.128902
global_step: 228, epoch: 6, loss: 1.170906
global_step: 229, epoch: 6, loss: 1.089423
global_step: 230, epoch: 6, loss: 1.231004
global_step: 231, epoch: 6, loss: 1.096841
global_step: 232, epoch: 6, loss: 1.105898
global_step: 233, epoch: 6, loss: 1.197853
global_step: 234, epoch: 6, loss: 1.142176
global_step: 235, epoch: 6, loss: 1.117069
global_step: 236, epoch: 6, loss: 1.076400
global_step: 237, epoch: 6, loss: 1.202570
global_step: 238, epoch: 6, loss: 1.142105
global_step: 239, epoch: 6, loss: 1.071441
global_step: 240, epoch: 6, loss: 1.428495
epoch: 6
train	acc: 0.6420	macro: p 0.4470, r 0.3463, f1: 0.3612	micro: p 0.6420, r 0.6420, f1 0.6420	weighted_f1:0.5915
dev	acc: 0.5356	macro: p 0.3451, r 0.2795, f1: 0.2745	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4677
test	acc: 0.5989	macro: p 0.3806, r 0.3018, f1: 0.3079	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5411
New best model!
global_step: 241, epoch: 7, loss: 1.121423
global_step: 242, epoch: 7, loss: 1.059753
global_step: 243, epoch: 7, loss: 1.063375
global_step: 244, epoch: 7, loss: 1.103502
global_step: 245, epoch: 7, loss: 1.194824
global_step: 246, epoch: 7, loss: 1.096170
global_step: 247, epoch: 7, loss: 1.118875
global_step: 248, epoch: 7, loss: 1.098676
global_step: 249, epoch: 7, loss: 1.137771
global_step: 250, epoch: 7, loss: 1.127299
global_step: 251, epoch: 7, loss: 1.084065
global_step: 252, epoch: 7, loss: 1.122136
global_step: 253, epoch: 7, loss: 1.158263
global_step: 254, epoch: 7, loss: 1.047125
global_step: 255, epoch: 7, loss: 1.085854
global_step: 256, epoch: 7, loss: 1.296816
global_step: 257, epoch: 7, loss: 1.274868
global_step: 258, epoch: 7, loss: 1.170574
global_step: 259, epoch: 7, loss: 1.067330
global_step: 260, epoch: 7, loss: 1.182032
global_step: 261, epoch: 7, loss: 1.083226
global_step: 262, epoch: 7, loss: 1.291839
global_step: 263, epoch: 7, loss: 1.082202
global_step: 264, epoch: 7, loss: 1.185553
global_step: 265, epoch: 7, loss: 1.115453
global_step: 266, epoch: 7, loss: 1.094840
global_step: 267, epoch: 7, loss: 1.024043
global_step: 268, epoch: 7, loss: 1.067192
global_step: 269, epoch: 7, loss: 1.133288
global_step: 270, epoch: 7, loss: 1.155970
global_step: 271, epoch: 7, loss: 1.101464
global_step: 272, epoch: 7, loss: 1.083974
global_step: 273, epoch: 7, loss: 1.244298
global_step: 274, epoch: 7, loss: 1.126901
global_step: 275, epoch: 7, loss: 1.172232
global_step: 276, epoch: 7, loss: 1.146254
global_step: 277, epoch: 7, loss: 1.085915
global_step: 278, epoch: 7, loss: 1.060457
global_step: 279, epoch: 7, loss: 0.975508
global_step: 280, epoch: 7, loss: 0.862361
epoch: 7
train	acc: 0.6250	macro: p 0.4513, r 0.3369, f1: 0.3397	micro: p 0.6250, r 0.6250, f1 0.6250	weighted_f1:0.5693
dev	acc: 0.5446	macro: p 0.3677, r 0.2878, f1: 0.2765	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4733
test	acc: 0.5820	macro: p 0.3666, r 0.2860, f1: 0.2807	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5197
New best model!
global_step: 281, epoch: 8, loss: 1.153969
global_step: 282, epoch: 8, loss: 1.193747
global_step: 283, epoch: 8, loss: 1.058812
global_step: 284, epoch: 8, loss: 1.171985
global_step: 285, epoch: 8, loss: 1.045151
global_step: 286, epoch: 8, loss: 1.122116
global_step: 287, epoch: 8, loss: 1.102634
global_step: 288, epoch: 8, loss: 1.013013
global_step: 289, epoch: 8, loss: 1.058153
global_step: 290, epoch: 8, loss: 1.010398
global_step: 291, epoch: 8, loss: 1.071906
global_step: 292, epoch: 8, loss: 1.085878
global_step: 293, epoch: 8, loss: 1.061357
global_step: 294, epoch: 8, loss: 1.109377
global_step: 295, epoch: 8, loss: 1.067131
global_step: 296, epoch: 8, loss: 1.185304
global_step: 297, epoch: 8, loss: 1.044724
global_step: 298, epoch: 8, loss: 1.090143
global_step: 299, epoch: 8, loss: 1.150805
global_step: 300, epoch: 8, loss: 1.142027
global_step: 301, epoch: 8, loss: 0.970346
global_step: 302, epoch: 8, loss: 1.087449
global_step: 303, epoch: 8, loss: 1.178265
global_step: 304, epoch: 8, loss: 1.096313
global_step: 305, epoch: 8, loss: 1.083672
global_step: 306, epoch: 8, loss: 1.027525
global_step: 307, epoch: 8, loss: 1.017555
global_step: 308, epoch: 8, loss: 0.996186
global_step: 309, epoch: 8, loss: 1.089690
global_step: 310, epoch: 8, loss: 1.077101
global_step: 311, epoch: 8, loss: 0.968838
global_step: 312, epoch: 8, loss: 0.937023
global_step: 313, epoch: 8, loss: 1.236356
global_step: 314, epoch: 8, loss: 1.105876
global_step: 315, epoch: 8, loss: 1.071165
global_step: 316, epoch: 8, loss: 1.181947
global_step: 317, epoch: 8, loss: 1.058852
global_step: 318, epoch: 8, loss: 0.985570
global_step: 319, epoch: 8, loss: 1.130859
global_step: 320, epoch: 8, loss: 0.874136
epoch: 8
train	acc: 0.6406	macro: p 0.4804, r 0.3564, f1: 0.3599	micro: p 0.6406, r 0.6406, f1 0.6406	weighted_f1:0.5925
dev	acc: 0.5347	macro: p 0.3762, r 0.2806, f1: 0.2739	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4699
test	acc: 0.5912	macro: p 0.4035, r 0.2972, f1: 0.2995	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5358
global_step: 321, epoch: 9, loss: 1.175293
global_step: 322, epoch: 9, loss: 0.948850
global_step: 323, epoch: 9, loss: 0.965450
global_step: 324, epoch: 9, loss: 1.087604
global_step: 325, epoch: 9, loss: 1.065761
global_step: 326, epoch: 9, loss: 1.001533
global_step: 327, epoch: 9, loss: 1.071347
global_step: 328, epoch: 9, loss: 0.991137
global_step: 329, epoch: 9, loss: 1.052003
global_step: 330, epoch: 9, loss: 1.014394
global_step: 331, epoch: 9, loss: 1.076266
global_step: 332, epoch: 9, loss: 1.098587
global_step: 333, epoch: 9, loss: 1.029985
global_step: 334, epoch: 9, loss: 1.105047
global_step: 335, epoch: 9, loss: 0.971048
global_step: 336, epoch: 9, loss: 0.937770
global_step: 337, epoch: 9, loss: 0.986576
global_step: 338, epoch: 9, loss: 1.069257
global_step: 339, epoch: 9, loss: 1.029173
global_step: 340, epoch: 9, loss: 0.952392
global_step: 341, epoch: 9, loss: 1.005855
global_step: 342, epoch: 9, loss: 1.017698
global_step: 343, epoch: 9, loss: 0.880525
global_step: 344, epoch: 9, loss: 1.050410
global_step: 345, epoch: 9, loss: 0.963691
global_step: 346, epoch: 9, loss: 1.125090
global_step: 347, epoch: 9, loss: 1.097094
global_step: 348, epoch: 9, loss: 1.070349
global_step: 349, epoch: 9, loss: 1.096161
global_step: 350, epoch: 9, loss: 1.038726
global_step: 351, epoch: 9, loss: 1.055837
global_step: 352, epoch: 9, loss: 1.032037
global_step: 353, epoch: 9, loss: 1.024697
global_step: 354, epoch: 9, loss: 0.976340
global_step: 355, epoch: 9, loss: 1.003423
global_step: 356, epoch: 9, loss: 1.115598
global_step: 357, epoch: 9, loss: 1.076695
global_step: 358, epoch: 9, loss: 1.031796
global_step: 359, epoch: 9, loss: 1.049583
global_step: 360, epoch: 9, loss: 1.454440
epoch: 9
train	acc: 0.6727	macro: p 0.4900, r 0.3801, f1: 0.4004	micro: p 0.6727, r 0.6727, f1 0.6727	weighted_f1:0.6294
dev	acc: 0.5401	macro: p 0.3616, r 0.2839, f1: 0.2777	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4733
test	acc: 0.6000	macro: p 0.3869, r 0.2994, f1: 0.3065	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5433
global_step: 361, epoch: 10, loss: 0.980571
global_step: 362, epoch: 10, loss: 0.901907
global_step: 363, epoch: 10, loss: 1.069613
global_step: 364, epoch: 10, loss: 1.052583
global_step: 365, epoch: 10, loss: 1.099568
global_step: 366, epoch: 10, loss: 0.973703
global_step: 367, epoch: 10, loss: 1.018122
global_step: 368, epoch: 10, loss: 1.026869
global_step: 369, epoch: 10, loss: 1.092991
global_step: 370, epoch: 10, loss: 0.952711
global_step: 371, epoch: 10, loss: 1.001267
global_step: 372, epoch: 10, loss: 0.976586
global_step: 373, epoch: 10, loss: 0.986588
global_step: 374, epoch: 10, loss: 0.924517
global_step: 375, epoch: 10, loss: 1.001346
global_step: 376, epoch: 10, loss: 1.020469
global_step: 377, epoch: 10, loss: 0.965943
global_step: 378, epoch: 10, loss: 0.932320
global_step: 379, epoch: 10, loss: 0.913279
global_step: 380, epoch: 10, loss: 0.841563
global_step: 381, epoch: 10, loss: 0.917525
global_step: 382, epoch: 10, loss: 0.955690
global_step: 383, epoch: 10, loss: 0.973819
global_step: 384, epoch: 10, loss: 1.096790
global_step: 385, epoch: 10, loss: 0.995923
global_step: 386, epoch: 10, loss: 0.987924
global_step: 387, epoch: 10, loss: 1.063299
global_step: 388, epoch: 10, loss: 1.064601
global_step: 389, epoch: 10, loss: 1.034397
global_step: 390, epoch: 10, loss: 1.000081
global_step: 391, epoch: 10, loss: 0.962566
global_step: 392, epoch: 10, loss: 0.982210
global_step: 393, epoch: 10, loss: 1.045016
global_step: 394, epoch: 10, loss: 1.093109
global_step: 395, epoch: 10, loss: 1.014440
global_step: 396, epoch: 10, loss: 1.077673
global_step: 397, epoch: 10, loss: 0.960647
global_step: 398, epoch: 10, loss: 0.979366
global_step: 399, epoch: 10, loss: 0.953623
global_step: 400, epoch: 10, loss: 0.796204
epoch: 10
train	acc: 0.6925	macro: p 0.4862, r 0.4473, f1: 0.4196	micro: p 0.6925, r 0.6925, f1 0.6925	weighted_f1:0.6640
dev	acc: 0.5131	macro: p 0.3377, r 0.3109, f1: 0.2850	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4691
test	acc: 0.5391	macro: p 0.3388, r 0.3124, f1: 0.2881	micro: p 0.5391, r 0.5391, f1 0.5391	weighted_f1:0.5074
global_step: 401, epoch: 11, loss: 1.000789
global_step: 402, epoch: 11, loss: 0.903744
global_step: 403, epoch: 11, loss: 0.962762
global_step: 404, epoch: 11, loss: 1.011549
global_step: 405, epoch: 11, loss: 0.893479
global_step: 406, epoch: 11, loss: 1.004290
global_step: 407, epoch: 11, loss: 0.985112
global_step: 408, epoch: 11, loss: 0.839023
global_step: 409, epoch: 11, loss: 0.900200
global_step: 410, epoch: 11, loss: 1.037277
global_step: 411, epoch: 11, loss: 0.970033
global_step: 412, epoch: 11, loss: 0.877137
global_step: 413, epoch: 11, loss: 1.026372
global_step: 414, epoch: 11, loss: 1.090653
global_step: 415, epoch: 11, loss: 0.992963
global_step: 416, epoch: 11, loss: 0.994385
global_step: 417, epoch: 11, loss: 0.891523
global_step: 418, epoch: 11, loss: 0.941306
global_step: 419, epoch: 11, loss: 1.032812
global_step: 420, epoch: 11, loss: 0.909297
global_step: 421, epoch: 11, loss: 1.029745
global_step: 422, epoch: 11, loss: 0.978834
global_step: 423, epoch: 11, loss: 0.903341
global_step: 424, epoch: 11, loss: 0.921642
global_step: 425, epoch: 11, loss: 0.849210
global_step: 426, epoch: 11, loss: 0.924959
global_step: 427, epoch: 11, loss: 0.992272
global_step: 428, epoch: 11, loss: 0.996516
global_step: 429, epoch: 11, loss: 0.969376
global_step: 430, epoch: 11, loss: 0.988470
global_step: 431, epoch: 11, loss: 0.947281
global_step: 432, epoch: 11, loss: 0.948069
global_step: 433, epoch: 11, loss: 1.055353
global_step: 434, epoch: 11, loss: 0.938175
global_step: 435, epoch: 11, loss: 0.931128
global_step: 436, epoch: 11, loss: 0.870729
global_step: 437, epoch: 11, loss: 0.916707
global_step: 438, epoch: 11, loss: 0.946789
global_step: 439, epoch: 11, loss: 0.937781
global_step: 440, epoch: 11, loss: 1.602170
epoch: 11
train	acc: 0.7475	macro: p 0.6624, r 0.4930, f1: 0.4941	micro: p 0.7475, r 0.7475, f1 0.7475	weighted_f1:0.7178
dev	acc: 0.5338	macro: p 0.3505, r 0.2998, f1: 0.2887	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4797
test	acc: 0.5912	macro: p 0.3580, r 0.3232, f1: 0.3138	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5471
New best model!
global_step: 441, epoch: 12, loss: 0.952272
global_step: 442, epoch: 12, loss: 0.873926
global_step: 443, epoch: 12, loss: 0.865968
global_step: 444, epoch: 12, loss: 0.797094
global_step: 445, epoch: 12, loss: 0.845780
global_step: 446, epoch: 12, loss: 0.839575
global_step: 447, epoch: 12, loss: 0.918107
global_step: 448, epoch: 12, loss: 0.974206
global_step: 449, epoch: 12, loss: 0.907974
global_step: 450, epoch: 12, loss: 0.923540
global_step: 451, epoch: 12, loss: 0.941284
global_step: 452, epoch: 12, loss: 0.930312
global_step: 453, epoch: 12, loss: 0.882461
global_step: 454, epoch: 12, loss: 0.919154
global_step: 455, epoch: 12, loss: 1.045093
global_step: 456, epoch: 12, loss: 0.895281
global_step: 457, epoch: 12, loss: 0.913886
global_step: 458, epoch: 12, loss: 0.913164
global_step: 459, epoch: 12, loss: 0.868015
global_step: 460, epoch: 12, loss: 0.928964
global_step: 461, epoch: 12, loss: 1.013581
global_step: 462, epoch: 12, loss: 0.993478
global_step: 463, epoch: 12, loss: 0.899898
global_step: 464, epoch: 12, loss: 0.811154
global_step: 465, epoch: 12, loss: 0.924094
global_step: 466, epoch: 12, loss: 0.869254
global_step: 467, epoch: 12, loss: 0.883256
global_step: 468, epoch: 12, loss: 0.986721
global_step: 469, epoch: 12, loss: 0.969975
global_step: 470, epoch: 12, loss: 0.967199
global_step: 471, epoch: 12, loss: 1.017625
global_step: 472, epoch: 12, loss: 0.882798
global_step: 473, epoch: 12, loss: 1.021997
global_step: 474, epoch: 12, loss: 0.866967
global_step: 475, epoch: 12, loss: 0.959010
global_step: 476, epoch: 12, loss: 0.968808
global_step: 477, epoch: 12, loss: 0.874618
global_step: 478, epoch: 12, loss: 1.007007
global_step: 479, epoch: 12, loss: 0.814780
global_step: 480, epoch: 12, loss: 0.508659
epoch: 12
train	acc: 0.7109	macro: p 0.6691, r 0.4229, f1: 0.4266	micro: p 0.7109, r 0.7109, f1 0.7109	weighted_f1:0.6637
dev	acc: 0.5428	macro: p 0.4193, r 0.2915, f1: 0.2796	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4726
test	acc: 0.5874	macro: p 0.3807, r 0.2960, f1: 0.2877	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5246
global_step: 481, epoch: 13, loss: 1.045025
global_step: 482, epoch: 13, loss: 0.746794
global_step: 483, epoch: 13, loss: 0.907480
global_step: 484, epoch: 13, loss: 0.904186
global_step: 485, epoch: 13, loss: 0.889516
global_step: 486, epoch: 13, loss: 0.781138
global_step: 487, epoch: 13, loss: 0.958573
global_step: 488, epoch: 13, loss: 0.886390
global_step: 489, epoch: 13, loss: 0.964669
global_step: 490, epoch: 13, loss: 0.870797
global_step: 491, epoch: 13, loss: 0.875716
global_step: 492, epoch: 13, loss: 0.869348
global_step: 493, epoch: 13, loss: 0.871327
global_step: 494, epoch: 13, loss: 0.998276
global_step: 495, epoch: 13, loss: 0.898079
global_step: 496, epoch: 13, loss: 0.812639
global_step: 497, epoch: 13, loss: 0.753604
global_step: 498, epoch: 13, loss: 0.776793
global_step: 499, epoch: 13, loss: 1.002691
global_step: 500, epoch: 13, loss: 0.790671
global_step: 501, epoch: 13, loss: 0.826724
global_step: 502, epoch: 13, loss: 0.815418
global_step: 503, epoch: 13, loss: 0.895916
global_step: 504, epoch: 13, loss: 0.924871
global_step: 505, epoch: 13, loss: 0.779728
global_step: 506, epoch: 13, loss: 0.927432
global_step: 507, epoch: 13, loss: 0.863451
global_step: 508, epoch: 13, loss: 0.861545
global_step: 509, epoch: 13, loss: 0.886581
global_step: 510, epoch: 13, loss: 0.881701
global_step: 511, epoch: 13, loss: 0.833710
global_step: 512, epoch: 13, loss: 0.823882
global_step: 513, epoch: 13, loss: 0.929082
global_step: 514, epoch: 13, loss: 0.957890
global_step: 515, epoch: 13, loss: 0.816961
global_step: 516, epoch: 13, loss: 0.956411
global_step: 517, epoch: 13, loss: 1.008166
global_step: 518, epoch: 13, loss: 0.989507
global_step: 519, epoch: 13, loss: 0.992415
global_step: 520, epoch: 13, loss: 0.713775
epoch: 13
train	acc: 0.7871	macro: p 0.8141, r 0.5688, f1: 0.5761	micro: p 0.7871, r 0.7871, f1 0.7871	weighted_f1:0.7680
dev	acc: 0.5347	macro: p 0.3178, r 0.3030, f1: 0.2997	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4869
test	acc: 0.5897	macro: p 0.3447, r 0.3310, f1: 0.3284	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5534
New best model!
global_step: 521, epoch: 14, loss: 0.838636
global_step: 522, epoch: 14, loss: 0.836485
global_step: 523, epoch: 14, loss: 0.809406
global_step: 524, epoch: 14, loss: 0.850248
global_step: 525, epoch: 14, loss: 0.899173
global_step: 526, epoch: 14, loss: 0.748327
global_step: 527, epoch: 14, loss: 0.821088
global_step: 528, epoch: 14, loss: 0.849055
global_step: 529, epoch: 14, loss: 0.833467
global_step: 530, epoch: 14, loss: 0.918329
global_step: 531, epoch: 14, loss: 0.759391
global_step: 532, epoch: 14, loss: 0.850447
global_step: 533, epoch: 14, loss: 0.768249
global_step: 534, epoch: 14, loss: 0.858300
global_step: 535, epoch: 14, loss: 0.841082
global_step: 536, epoch: 14, loss: 0.867497
global_step: 537, epoch: 14, loss: 0.753129
global_step: 538, epoch: 14, loss: 0.960463
global_step: 539, epoch: 14, loss: 0.912938
global_step: 540, epoch: 14, loss: 0.837013
global_step: 541, epoch: 14, loss: 0.823299
global_step: 542, epoch: 14, loss: 0.858672
global_step: 543, epoch: 14, loss: 0.912106
global_step: 544, epoch: 14, loss: 0.943722
global_step: 545, epoch: 14, loss: 0.821052
global_step: 546, epoch: 14, loss: 0.692444
global_step: 547, epoch: 14, loss: 0.837997
global_step: 548, epoch: 14, loss: 0.836469
global_step: 549, epoch: 14, loss: 0.813070
global_step: 550, epoch: 14, loss: 0.803278
global_step: 551, epoch: 14, loss: 0.934508
global_step: 552, epoch: 14, loss: 0.894544
global_step: 553, epoch: 14, loss: 0.851460
global_step: 554, epoch: 14, loss: 0.864744
global_step: 555, epoch: 14, loss: 0.879528
global_step: 556, epoch: 14, loss: 0.817580
global_step: 557, epoch: 14, loss: 0.888972
global_step: 558, epoch: 14, loss: 0.888335
global_step: 559, epoch: 14, loss: 0.879939
global_step: 560, epoch: 14, loss: 0.555505
epoch: 14
train	acc: 0.7393	macro: p 0.8387, r 0.4802, f1: 0.4951	micro: p 0.7393, r 0.7393, f1 0.7393	weighted_f1:0.7194
dev	acc: 0.4932	macro: p 0.3483, r 0.2851, f1: 0.2591	micro: p 0.4932, r 0.4932, f1 0.4932	weighted_f1:0.4475
test	acc: 0.5372	macro: p 0.3574, r 0.2897, f1: 0.2688	micro: p 0.5372, r 0.5372, f1 0.5372	weighted_f1:0.4971
global_step: 561, epoch: 15, loss: 0.816552
global_step: 562, epoch: 15, loss: 0.804149
global_step: 563, epoch: 15, loss: 0.887130
global_step: 564, epoch: 15, loss: 0.886049
global_step: 565, epoch: 15, loss: 0.772328
global_step: 566, epoch: 15, loss: 0.792891
global_step: 567, epoch: 15, loss: 0.693370
global_step: 568, epoch: 15, loss: 0.856051
global_step: 569, epoch: 15, loss: 0.826936
global_step: 570, epoch: 15, loss: 0.809036
global_step: 571, epoch: 15, loss: 0.777420
global_step: 572, epoch: 15, loss: 0.899501
global_step: 573, epoch: 15, loss: 0.869163
global_step: 574, epoch: 15, loss: 0.901460
global_step: 575, epoch: 15, loss: 0.866060
global_step: 576, epoch: 15, loss: 0.822557
global_step: 577, epoch: 15, loss: 0.867102
global_step: 578, epoch: 15, loss: 0.707314
global_step: 579, epoch: 15, loss: 0.815695
global_step: 580, epoch: 15, loss: 0.755510
global_step: 581, epoch: 15, loss: 0.769305
global_step: 582, epoch: 15, loss: 0.734341
global_step: 583, epoch: 15, loss: 0.788591
global_step: 584, epoch: 15, loss: 0.842978
global_step: 585, epoch: 15, loss: 0.890791
global_step: 586, epoch: 15, loss: 0.775770
global_step: 587, epoch: 15, loss: 0.844343
global_step: 588, epoch: 15, loss: 0.726580
global_step: 589, epoch: 15, loss: 0.762219
global_step: 590, epoch: 15, loss: 0.914684
global_step: 591, epoch: 15, loss: 0.799821
global_step: 592, epoch: 15, loss: 0.756251
global_step: 593, epoch: 15, loss: 0.905476
global_step: 594, epoch: 15, loss: 0.685479
global_step: 595, epoch: 15, loss: 0.712345
global_step: 596, epoch: 15, loss: 0.870194
global_step: 597, epoch: 15, loss: 0.783614
global_step: 598, epoch: 15, loss: 1.018978
global_step: 599, epoch: 15, loss: 0.847474
global_step: 600, epoch: 15, loss: 0.551197
epoch: 15
train	acc: 0.7539	macro: p 0.8496, r 0.4946, f1: 0.5358	micro: p 0.7539, r 0.7539, f1 0.7539	weighted_f1:0.7303
dev	acc: 0.5230	macro: p 0.5351, r 0.2851, f1: 0.2654	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4580
test	acc: 0.5686	macro: p 0.3970, r 0.2857, f1: 0.2749	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5135
global_step: 601, epoch: 16, loss: 0.906674
global_step: 602, epoch: 16, loss: 0.730680
global_step: 603, epoch: 16, loss: 0.670713
global_step: 604, epoch: 16, loss: 0.787391
global_step: 605, epoch: 16, loss: 0.786454
global_step: 606, epoch: 16, loss: 0.792195
global_step: 607, epoch: 16, loss: 0.775604
global_step: 608, epoch: 16, loss: 0.826966
global_step: 609, epoch: 16, loss: 0.658004
global_step: 610, epoch: 16, loss: 0.827029
global_step: 611, epoch: 16, loss: 0.862566
global_step: 612, epoch: 16, loss: 0.696493
global_step: 613, epoch: 16, loss: 0.736146
global_step: 614, epoch: 16, loss: 0.722168
global_step: 615, epoch: 16, loss: 0.795544
global_step: 616, epoch: 16, loss: 0.788292
global_step: 617, epoch: 16, loss: 0.844624
global_step: 618, epoch: 16, loss: 0.810603
global_step: 619, epoch: 16, loss: 0.869131
global_step: 620, epoch: 16, loss: 0.811667
global_step: 621, epoch: 16, loss: 0.767688
global_step: 622, epoch: 16, loss: 0.753253
global_step: 623, epoch: 16, loss: 0.795975
global_step: 624, epoch: 16, loss: 0.839771
global_step: 625, epoch: 16, loss: 0.731943
global_step: 626, epoch: 16, loss: 0.744267
global_step: 627, epoch: 16, loss: 0.801334
global_step: 628, epoch: 16, loss: 0.797312
global_step: 629, epoch: 16, loss: 0.880117
global_step: 630, epoch: 16, loss: 0.713524
global_step: 631, epoch: 16, loss: 0.927980
global_step: 632, epoch: 16, loss: 0.809348
global_step: 633, epoch: 16, loss: 0.693529
global_step: 634, epoch: 16, loss: 0.715986
global_step: 635, epoch: 16, loss: 0.816211
global_step: 636, epoch: 16, loss: 0.757706
global_step: 637, epoch: 16, loss: 0.667303
global_step: 638, epoch: 16, loss: 0.748790
global_step: 639, epoch: 16, loss: 0.788294
global_step: 640, epoch: 16, loss: 0.880446
epoch: 16
train	acc: 0.8135	macro: p 0.7530, r 0.6917, f1: 0.6737	micro: p 0.8135, r 0.8135, f1 0.8135	weighted_f1:0.8159
dev	acc: 0.4743	macro: p 0.3164, r 0.3035, f1: 0.2958	micro: p 0.4743, r 0.4743, f1 0.4743	weighted_f1:0.4721
test	acc: 0.5287	macro: p 0.3585, r 0.3401, f1: 0.3341	micro: p 0.5287, r 0.5287, f1 0.5287	weighted_f1:0.5394
global_step: 641, epoch: 17, loss: 0.798704
global_step: 642, epoch: 17, loss: 0.833957
global_step: 643, epoch: 17, loss: 0.623258
global_step: 644, epoch: 17, loss: 0.794122
global_step: 645, epoch: 17, loss: 0.638553
global_step: 646, epoch: 17, loss: 0.646051
global_step: 647, epoch: 17, loss: 0.646624
global_step: 648, epoch: 17, loss: 0.667348
global_step: 649, epoch: 17, loss: 0.658410
global_step: 650, epoch: 17, loss: 0.687377
global_step: 651, epoch: 17, loss: 0.704531
global_step: 652, epoch: 17, loss: 0.726340
global_step: 653, epoch: 17, loss: 0.790285
global_step: 654, epoch: 17, loss: 0.750805
global_step: 655, epoch: 17, loss: 0.713653
global_step: 656, epoch: 17, loss: 0.771559
global_step: 657, epoch: 17, loss: 0.662146
global_step: 658, epoch: 17, loss: 0.619812
global_step: 659, epoch: 17, loss: 0.650385
global_step: 660, epoch: 17, loss: 0.678978
global_step: 661, epoch: 17, loss: 0.908903
global_step: 662, epoch: 17, loss: 0.740551
global_step: 663, epoch: 17, loss: 0.729880
global_step: 664, epoch: 17, loss: 0.785117
global_step: 665, epoch: 17, loss: 0.850221
global_step: 666, epoch: 17, loss: 0.653350
global_step: 667, epoch: 17, loss: 0.783953
global_step: 668, epoch: 17, loss: 0.776846
global_step: 669, epoch: 17, loss: 0.698687
global_step: 670, epoch: 17, loss: 0.880052
global_step: 671, epoch: 17, loss: 0.784830
global_step: 672, epoch: 17, loss: 0.805422
global_step: 673, epoch: 17, loss: 0.773111
global_step: 674, epoch: 17, loss: 0.804505
global_step: 675, epoch: 17, loss: 0.801101
global_step: 676, epoch: 17, loss: 0.797356
global_step: 677, epoch: 17, loss: 0.771285
global_step: 678, epoch: 17, loss: 0.879888
global_step: 679, epoch: 17, loss: 0.752449
global_step: 680, epoch: 17, loss: 0.674535
epoch: 17
train	acc: 0.8570	macro: p 0.8592, r 0.7280, f1: 0.7725	micro: p 0.8570, r 0.8570, f1 0.8570	weighted_f1:0.8518
dev	acc: 0.5221	macro: p 0.3995, r 0.2810, f1: 0.2914	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4739
test	acc: 0.5912	macro: p 0.3687, r 0.3116, f1: 0.3227	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5511
global_step: 681, epoch: 18, loss: 0.831727
global_step: 682, epoch: 18, loss: 0.704690
global_step: 683, epoch: 18, loss: 0.608694
global_step: 684, epoch: 18, loss: 0.624605
global_step: 685, epoch: 18, loss: 0.606077
global_step: 686, epoch: 18, loss: 0.682064
global_step: 687, epoch: 18, loss: 0.694729
global_step: 688, epoch: 18, loss: 0.588314
global_step: 689, epoch: 18, loss: 0.718967
global_step: 690, epoch: 18, loss: 0.699091
global_step: 691, epoch: 18, loss: 0.731548
global_step: 692, epoch: 18, loss: 0.749859
global_step: 693, epoch: 18, loss: 0.741950
global_step: 694, epoch: 18, loss: 0.689341
global_step: 695, epoch: 18, loss: 0.686622
global_step: 696, epoch: 18, loss: 0.745832
global_step: 697, epoch: 18, loss: 0.722898
global_step: 698, epoch: 18, loss: 0.715105
global_step: 699, epoch: 18, loss: 0.788215
global_step: 700, epoch: 18, loss: 0.727084
global_step: 701, epoch: 18, loss: 0.663727
global_step: 702, epoch: 18, loss: 0.787610
global_step: 703, epoch: 18, loss: 0.715962
global_step: 704, epoch: 18, loss: 0.710282
global_step: 705, epoch: 18, loss: 0.703707
global_step: 706, epoch: 18, loss: 0.649943
global_step: 707, epoch: 18, loss: 0.609505
global_step: 708, epoch: 18, loss: 0.746668
global_step: 709, epoch: 18, loss: 0.718641
global_step: 710, epoch: 18, loss: 0.732450
global_step: 711, epoch: 18, loss: 0.778339
global_step: 712, epoch: 18, loss: 0.768164
global_step: 713, epoch: 18, loss: 0.767584
global_step: 714, epoch: 18, loss: 0.782528
global_step: 715, epoch: 18, loss: 0.808872
global_step: 716, epoch: 18, loss: 0.791696
global_step: 717, epoch: 18, loss: 0.807152
global_step: 718, epoch: 18, loss: 0.756893
global_step: 719, epoch: 18, loss: 0.745005
global_step: 720, epoch: 18, loss: 0.107310
epoch: 18
train	acc: 0.8533	macro: p 0.9054, r 0.6970, f1: 0.7645	micro: p 0.8533, r 0.8533, f1 0.8533	weighted_f1:0.8463
dev	acc: 0.5482	macro: p 0.4761, r 0.3021, f1: 0.2962	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4839
test	acc: 0.5908	macro: p 0.3686, r 0.2959, f1: 0.2934	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5322
global_step: 721, epoch: 19, loss: 0.659432
global_step: 722, epoch: 19, loss: 0.587908
global_step: 723, epoch: 19, loss: 0.652560
global_step: 724, epoch: 19, loss: 0.609886
global_step: 725, epoch: 19, loss: 0.602052
global_step: 726, epoch: 19, loss: 0.715553
global_step: 727, epoch: 19, loss: 0.738884
global_step: 728, epoch: 19, loss: 0.640118
global_step: 729, epoch: 19, loss: 0.670536
global_step: 730, epoch: 19, loss: 0.646939
global_step: 731, epoch: 19, loss: 0.736894
global_step: 732, epoch: 19, loss: 0.719449
global_step: 733, epoch: 19, loss: 0.677860
global_step: 734, epoch: 19, loss: 0.727647
global_step: 735, epoch: 19, loss: 0.744556
global_step: 736, epoch: 19, loss: 0.593685
global_step: 737, epoch: 19, loss: 0.743296
global_step: 738, epoch: 19, loss: 0.677180
global_step: 739, epoch: 19, loss: 0.687983
global_step: 740, epoch: 19, loss: 0.673998
global_step: 741, epoch: 19, loss: 0.690954
global_step: 742, epoch: 19, loss: 0.676455
global_step: 743, epoch: 19, loss: 0.661307
global_step: 744, epoch: 19, loss: 0.632204
global_step: 745, epoch: 19, loss: 0.771117
global_step: 746, epoch: 19, loss: 0.700056
global_step: 747, epoch: 19, loss: 0.630528
global_step: 748, epoch: 19, loss: 0.716532
global_step: 749, epoch: 19, loss: 0.721799
global_step: 750, epoch: 19, loss: 0.732706
global_step: 751, epoch: 19, loss: 0.562997
global_step: 752, epoch: 19, loss: 0.695463
global_step: 753, epoch: 19, loss: 0.738806
global_step: 754, epoch: 19, loss: 0.659103
global_step: 755, epoch: 19, loss: 0.704538
global_step: 756, epoch: 19, loss: 0.778773
global_step: 757, epoch: 19, loss: 0.690915
global_step: 758, epoch: 19, loss: 0.647829
global_step: 759, epoch: 19, loss: 0.766812
global_step: 760, epoch: 19, loss: 0.752298
epoch: 19
train	acc: 0.8535	macro: p 0.8873, r 0.7143, f1: 0.7609	micro: p 0.8535, r 0.8535, f1 0.8535	weighted_f1:0.8481
dev	acc: 0.5068	macro: p 0.4657, r 0.3113, f1: 0.3012	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4622
test	acc: 0.5452	macro: p 0.3287, r 0.3027, f1: 0.2853	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5084
global_step: 761, epoch: 20, loss: 0.588016
global_step: 762, epoch: 20, loss: 0.667431
global_step: 763, epoch: 20, loss: 0.679482
global_step: 764, epoch: 20, loss: 0.623134
global_step: 765, epoch: 20, loss: 0.602136
global_step: 766, epoch: 20, loss: 0.642737
global_step: 767, epoch: 20, loss: 0.609977
global_step: 768, epoch: 20, loss: 0.669927
global_step: 769, epoch: 20, loss: 0.604781
global_step: 770, epoch: 20, loss: 0.663240
global_step: 771, epoch: 20, loss: 0.665793
global_step: 772, epoch: 20, loss: 0.582567
global_step: 773, epoch: 20, loss: 0.661876
global_step: 774, epoch: 20, loss: 0.630661
global_step: 775, epoch: 20, loss: 0.630328
global_step: 776, epoch: 20, loss: 0.718791
global_step: 777, epoch: 20, loss: 0.651026
global_step: 778, epoch: 20, loss: 0.611044
global_step: 779, epoch: 20, loss: 0.666001
global_step: 780, epoch: 20, loss: 0.649261
global_step: 781, epoch: 20, loss: 0.669270
global_step: 782, epoch: 20, loss: 0.722873
global_step: 783, epoch: 20, loss: 0.652045
global_step: 784, epoch: 20, loss: 0.630148
global_step: 785, epoch: 20, loss: 0.647522
global_step: 786, epoch: 20, loss: 0.706322
global_step: 787, epoch: 20, loss: 0.803055
global_step: 788, epoch: 20, loss: 0.743889
global_step: 789, epoch: 20, loss: 0.642702
global_step: 790, epoch: 20, loss: 0.570093
global_step: 791, epoch: 20, loss: 0.599422
global_step: 792, epoch: 20, loss: 0.693266
global_step: 793, epoch: 20, loss: 0.679162
global_step: 794, epoch: 20, loss: 0.698329
global_step: 795, epoch: 20, loss: 0.661061
global_step: 796, epoch: 20, loss: 0.701464
global_step: 797, epoch: 20, loss: 0.810501
global_step: 798, epoch: 20, loss: 0.669427
global_step: 799, epoch: 20, loss: 0.715746
global_step: 800, epoch: 20, loss: 0.474012
epoch: 20
train	acc: 0.8643	macro: p 0.9048, r 0.7299, f1: 0.7917	micro: p 0.8643, r 0.8643, f1 0.8643	weighted_f1:0.8587
dev	acc: 0.5392	macro: p 0.3620, r 0.2888, f1: 0.2802	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4726
test	acc: 0.5920	macro: p 0.3724, r 0.2988, f1: 0.2971	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5313
global_step: 801, epoch: 21, loss: 0.674283
global_step: 802, epoch: 21, loss: 0.596795
global_step: 803, epoch: 21, loss: 0.624583
global_step: 804, epoch: 21, loss: 0.558727
global_step: 805, epoch: 21, loss: 0.654221
global_step: 806, epoch: 21, loss: 0.506304
global_step: 807, epoch: 21, loss: 0.570939
global_step: 808, epoch: 21, loss: 0.613642
global_step: 809, epoch: 21, loss: 0.560107
global_step: 810, epoch: 21, loss: 0.652483
global_step: 811, epoch: 21, loss: 0.631132
global_step: 812, epoch: 21, loss: 0.652141
global_step: 813, epoch: 21, loss: 0.669745
global_step: 814, epoch: 21, loss: 0.602655
global_step: 815, epoch: 21, loss: 0.704558
global_step: 816, epoch: 21, loss: 0.619222
global_step: 817, epoch: 21, loss: 0.575511
global_step: 818, epoch: 21, loss: 0.642085
global_step: 819, epoch: 21, loss: 0.636579
global_step: 820, epoch: 21, loss: 0.646648
global_step: 821, epoch: 21, loss: 0.607886
global_step: 822, epoch: 21, loss: 0.658386
global_step: 823, epoch: 21, loss: 0.603309
global_step: 824, epoch: 21, loss: 0.529591
global_step: 825, epoch: 21, loss: 0.622336
global_step: 826, epoch: 21, loss: 0.587017
global_step: 827, epoch: 21, loss: 0.622092
global_step: 828, epoch: 21, loss: 0.532169
global_step: 829, epoch: 21, loss: 0.684048
global_step: 830, epoch: 21, loss: 0.672649
global_step: 831, epoch: 21, loss: 0.619776
global_step: 832, epoch: 21, loss: 0.658136
global_step: 833, epoch: 21, loss: 0.604686
global_step: 834, epoch: 21, loss: 0.732242
global_step: 835, epoch: 21, loss: 0.738434
global_step: 836, epoch: 21, loss: 0.611898
global_step: 837, epoch: 21, loss: 0.690286
global_step: 838, epoch: 21, loss: 0.668072
global_step: 839, epoch: 21, loss: 0.649120
global_step: 840, epoch: 21, loss: 1.163561
epoch: 21
train	acc: 0.8892	macro: p 0.8862, r 0.7700, f1: 0.7902	micro: p 0.8892, r 0.8892, f1 0.8892	weighted_f1:0.8865
dev	acc: 0.5068	macro: p 0.3583, r 0.3226, f1: 0.3186	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4905
test	acc: 0.5563	macro: p 0.3375, r 0.3427, f1: 0.3359	micro: p 0.5563, r 0.5563, f1 0.5563	weighted_f1:0.5493
New best model!
global_step: 841, epoch: 22, loss: 0.607579
global_step: 842, epoch: 22, loss: 0.544427
global_step: 843, epoch: 22, loss: 0.458821
global_step: 844, epoch: 22, loss: 0.508420
global_step: 845, epoch: 22, loss: 0.598711
global_step: 846, epoch: 22, loss: 0.566506
global_step: 847, epoch: 22, loss: 0.518693
global_step: 848, epoch: 22, loss: 0.620321
global_step: 849, epoch: 22, loss: 0.643155
global_step: 850, epoch: 22, loss: 0.572393
global_step: 851, epoch: 22, loss: 0.571142
global_step: 852, epoch: 22, loss: 0.615458
global_step: 853, epoch: 22, loss: 0.624498
global_step: 854, epoch: 22, loss: 0.549457
global_step: 855, epoch: 22, loss: 0.456663
global_step: 856, epoch: 22, loss: 0.607385
global_step: 857, epoch: 22, loss: 0.467007
global_step: 858, epoch: 22, loss: 0.614332
global_step: 859, epoch: 22, loss: 0.592387
global_step: 860, epoch: 22, loss: 0.614610
global_step: 861, epoch: 22, loss: 0.562305
global_step: 862, epoch: 22, loss: 0.593668
global_step: 863, epoch: 22, loss: 0.651338
global_step: 864, epoch: 22, loss: 0.539963
global_step: 865, epoch: 22, loss: 0.652787
global_step: 866, epoch: 22, loss: 0.555980
global_step: 867, epoch: 22, loss: 0.627242
global_step: 868, epoch: 22, loss: 0.555666
global_step: 869, epoch: 22, loss: 0.606456
global_step: 870, epoch: 22, loss: 0.508655
global_step: 871, epoch: 22, loss: 0.670128
global_step: 872, epoch: 22, loss: 0.648047
global_step: 873, epoch: 22, loss: 0.694964
global_step: 874, epoch: 22, loss: 0.516377
global_step: 875, epoch: 22, loss: 0.696797
global_step: 876, epoch: 22, loss: 0.548436
global_step: 877, epoch: 22, loss: 0.789564
global_step: 878, epoch: 22, loss: 0.658272
global_step: 879, epoch: 22, loss: 0.634125
global_step: 880, epoch: 22, loss: 0.640000
epoch: 22
train	acc: 0.9075	macro: p 0.8827, r 0.8508, f1: 0.8619	micro: p 0.9075, r 0.9075, f1 0.9075	weighted_f1:0.9070
dev	acc: 0.5185	macro: p 0.3875, r 0.3236, f1: 0.3255	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4887
test	acc: 0.5648	macro: p 0.3386, r 0.3246, f1: 0.3201	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5421
global_step: 881, epoch: 23, loss: 0.468311
global_step: 882, epoch: 23, loss: 0.448278
global_step: 883, epoch: 23, loss: 0.564175
global_step: 884, epoch: 23, loss: 0.580780
global_step: 885, epoch: 23, loss: 0.541280
global_step: 886, epoch: 23, loss: 0.496497
global_step: 887, epoch: 23, loss: 0.546907
global_step: 888, epoch: 23, loss: 0.573994
global_step: 889, epoch: 23, loss: 0.515271
global_step: 890, epoch: 23, loss: 0.580020
global_step: 891, epoch: 23, loss: 0.579462
global_step: 892, epoch: 23, loss: 0.524078
global_step: 893, epoch: 23, loss: 0.610402
global_step: 894, epoch: 23, loss: 0.557983
global_step: 895, epoch: 23, loss: 0.530783
global_step: 896, epoch: 23, loss: 0.663255
global_step: 897, epoch: 23, loss: 0.561412
global_step: 898, epoch: 23, loss: 0.557534
global_step: 899, epoch: 23, loss: 0.535866
global_step: 900, epoch: 23, loss: 0.577888
global_step: 901, epoch: 23, loss: 0.636240
global_step: 902, epoch: 23, loss: 0.576363
global_step: 903, epoch: 23, loss: 0.489769
global_step: 904, epoch: 23, loss: 0.512288
global_step: 905, epoch: 23, loss: 0.600315
global_step: 906, epoch: 23, loss: 0.617786
global_step: 907, epoch: 23, loss: 0.547991
global_step: 908, epoch: 23, loss: 0.545252
global_step: 909, epoch: 23, loss: 0.637511
global_step: 910, epoch: 23, loss: 0.598896
global_step: 911, epoch: 23, loss: 0.598379
global_step: 912, epoch: 23, loss: 0.564983
global_step: 913, epoch: 23, loss: 0.587455
global_step: 914, epoch: 23, loss: 0.682060
global_step: 915, epoch: 23, loss: 0.572114
global_step: 916, epoch: 23, loss: 0.577325
global_step: 917, epoch: 23, loss: 0.593455
global_step: 918, epoch: 23, loss: 0.662265
global_step: 919, epoch: 23, loss: 0.771314
global_step: 920, epoch: 23, loss: 0.176278
epoch: 23
train	acc: 0.8986	macro: p 0.9254, r 0.7975, f1: 0.8482	micro: p 0.8986, r 0.8986, f1 0.8986	weighted_f1:0.8960
dev	acc: 0.5356	macro: p 0.4485, r 0.3000, f1: 0.3094	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4808
test	acc: 0.5985	macro: p 0.3848, r 0.3071, f1: 0.3189	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5486
global_step: 921, epoch: 24, loss: 0.557222
global_step: 922, epoch: 24, loss: 0.556468
global_step: 923, epoch: 24, loss: 0.612250
global_step: 924, epoch: 24, loss: 0.630260
global_step: 925, epoch: 24, loss: 0.505671
global_step: 926, epoch: 24, loss: 0.480504
global_step: 927, epoch: 24, loss: 0.532167
global_step: 928, epoch: 24, loss: 0.490646
global_step: 929, epoch: 24, loss: 0.516382
global_step: 930, epoch: 24, loss: 0.615077
global_step: 931, epoch: 24, loss: 0.520189
global_step: 932, epoch: 24, loss: 0.457948
global_step: 933, epoch: 24, loss: 0.667680
global_step: 934, epoch: 24, loss: 0.588579
global_step: 935, epoch: 24, loss: 0.557565
global_step: 936, epoch: 24, loss: 0.533851
global_step: 937, epoch: 24, loss: 0.619893
global_step: 938, epoch: 24, loss: 0.528940
global_step: 939, epoch: 24, loss: 0.460989
global_step: 940, epoch: 24, loss: 0.557043
global_step: 941, epoch: 24, loss: 0.520849
global_step: 942, epoch: 24, loss: 0.559378
global_step: 943, epoch: 24, loss: 0.604214
global_step: 944, epoch: 24, loss: 0.564706
global_step: 945, epoch: 24, loss: 0.551423
global_step: 946, epoch: 24, loss: 0.539900
global_step: 947, epoch: 24, loss: 0.664898
global_step: 948, epoch: 24, loss: 0.590528
global_step: 949, epoch: 24, loss: 0.589247
global_step: 950, epoch: 24, loss: 0.705779
global_step: 951, epoch: 24, loss: 0.639898
global_step: 952, epoch: 24, loss: 0.654040
global_step: 953, epoch: 24, loss: 0.594965
global_step: 954, epoch: 24, loss: 0.627978
global_step: 955, epoch: 24, loss: 0.532920
global_step: 956, epoch: 24, loss: 0.550885
global_step: 957, epoch: 24, loss: 0.585934
global_step: 958, epoch: 24, loss: 0.693930
global_step: 959, epoch: 24, loss: 0.652234
global_step: 960, epoch: 24, loss: 0.253865
epoch: 24
train	acc: 0.8929	macro: p 0.9216, r 0.8153, f1: 0.8600	micro: p 0.8929, r 0.8929, f1 0.8929	weighted_f1:0.8909
dev	acc: 0.5275	macro: p 0.3894, r 0.2831, f1: 0.2868	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4701
test	acc: 0.5939	macro: p 0.3667, r 0.3047, f1: 0.3152	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5456
global_step: 961, epoch: 25, loss: 0.618177
global_step: 962, epoch: 25, loss: 0.559619
global_step: 963, epoch: 25, loss: 0.494574
global_step: 964, epoch: 25, loss: 0.542690
global_step: 965, epoch: 25, loss: 0.620095
global_step: 966, epoch: 25, loss: 0.530372
global_step: 967, epoch: 25, loss: 0.715410
global_step: 968, epoch: 25, loss: 0.605838
global_step: 969, epoch: 25, loss: 0.503658
global_step: 970, epoch: 25, loss: 0.483868
global_step: 971, epoch: 25, loss: 0.506209
global_step: 972, epoch: 25, loss: 0.596077
global_step: 973, epoch: 25, loss: 0.499737
global_step: 974, epoch: 25, loss: 0.619511
global_step: 975, epoch: 25, loss: 0.514848
global_step: 976, epoch: 25, loss: 0.485584
global_step: 977, epoch: 25, loss: 0.395109
global_step: 978, epoch: 25, loss: 0.598070
global_step: 979, epoch: 25, loss: 0.548339
global_step: 980, epoch: 25, loss: 0.588998
global_step: 981, epoch: 25, loss: 0.640898
global_step: 982, epoch: 25, loss: 0.560794
global_step: 983, epoch: 25, loss: 0.527686
global_step: 984, epoch: 25, loss: 0.605748
global_step: 985, epoch: 25, loss: 0.517817
global_step: 986, epoch: 25, loss: 0.689436
global_step: 987, epoch: 25, loss: 0.483130
global_step: 988, epoch: 25, loss: 0.587613
global_step: 989, epoch: 25, loss: 0.516493
global_step: 990, epoch: 25, loss: 0.601749
global_step: 991, epoch: 25, loss: 0.554133
global_step: 992, epoch: 25, loss: 0.719693
global_step: 993, epoch: 25, loss: 0.587244
global_step: 994, epoch: 25, loss: 0.661269
global_step: 995, epoch: 25, loss: 0.508362
global_step: 996, epoch: 25, loss: 0.546405
global_step: 997, epoch: 25, loss: 0.591999
global_step: 998, epoch: 25, loss: 0.565932
global_step: 999, epoch: 25, loss: 0.555180
global_step: 1000, epoch: 25, loss: 0.235414
epoch: 25
train	acc: 0.9132	macro: p 0.9360, r 0.8401, f1: 0.8815	micro: p 0.9132, r 0.9132, f1 0.9132	weighted_f1:0.9119
dev	acc: 0.5455	macro: p 0.3926, r 0.3046, f1: 0.3121	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4938
test	acc: 0.5935	macro: p 0.3824, r 0.3094, f1: 0.3212	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5478
New best model!
global_step: 1001, epoch: 26, loss: 0.430700
global_step: 1002, epoch: 26, loss: 0.545047
global_step: 1003, epoch: 26, loss: 0.487982
global_step: 1004, epoch: 26, loss: 0.468806
global_step: 1005, epoch: 26, loss: 0.596974
global_step: 1006, epoch: 26, loss: 0.522856
global_step: 1007, epoch: 26, loss: 0.578265
global_step: 1008, epoch: 26, loss: 0.604655
global_step: 1009, epoch: 26, loss: 0.570139
global_step: 1010, epoch: 26, loss: 0.590566
global_step: 1011, epoch: 26, loss: 0.601115
global_step: 1012, epoch: 26, loss: 0.505642
global_step: 1013, epoch: 26, loss: 0.571738
global_step: 1014, epoch: 26, loss: 0.532479
global_step: 1015, epoch: 26, loss: 0.484829
global_step: 1016, epoch: 26, loss: 0.432071
global_step: 1017, epoch: 26, loss: 0.549945
global_step: 1018, epoch: 26, loss: 0.496612
global_step: 1019, epoch: 26, loss: 0.491683
global_step: 1020, epoch: 26, loss: 0.477840
global_step: 1021, epoch: 26, loss: 0.595785
global_step: 1022, epoch: 26, loss: 0.515582
global_step: 1023, epoch: 26, loss: 0.529796
global_step: 1024, epoch: 26, loss: 0.500556
global_step: 1025, epoch: 26, loss: 0.613452
global_step: 1026, epoch: 26, loss: 0.547524
global_step: 1027, epoch: 26, loss: 0.705673
global_step: 1028, epoch: 26, loss: 0.566056
global_step: 1029, epoch: 26, loss: 0.648204
global_step: 1030, epoch: 26, loss: 0.583935
global_step: 1031, epoch: 26, loss: 0.647695
global_step: 1032, epoch: 26, loss: 0.524261
global_step: 1033, epoch: 26, loss: 0.662498
global_step: 1034, epoch: 26, loss: 0.665470
global_step: 1035, epoch: 26, loss: 0.570423
global_step: 1036, epoch: 26, loss: 0.551401
global_step: 1037, epoch: 26, loss: 0.592685
global_step: 1038, epoch: 26, loss: 0.506033
global_step: 1039, epoch: 26, loss: 0.450113
global_step: 1040, epoch: 26, loss: 0.362441
epoch: 26
train	acc: 0.9277	macro: p 0.9405, r 0.8717, f1: 0.9012	micro: p 0.9277, r 0.9277, f1 0.9277	weighted_f1:0.9272
dev	acc: 0.5203	macro: p 0.3696, r 0.3065, f1: 0.3039	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4804
test	acc: 0.5785	macro: p 0.3539, r 0.3192, f1: 0.3180	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5447
global_step: 1041, epoch: 27, loss: 0.572962
global_step: 1042, epoch: 27, loss: 0.424254
global_step: 1043, epoch: 27, loss: 0.537140
global_step: 1044, epoch: 27, loss: 0.587562
global_step: 1045, epoch: 27, loss: 0.451533
global_step: 1046, epoch: 27, loss: 0.421976
global_step: 1047, epoch: 27, loss: 0.554009
global_step: 1048, epoch: 27, loss: 0.580902
global_step: 1049, epoch: 27, loss: 0.453452
global_step: 1050, epoch: 27, loss: 0.453795
global_step: 1051, epoch: 27, loss: 0.458693
global_step: 1052, epoch: 27, loss: 0.498342
global_step: 1053, epoch: 27, loss: 0.452003
global_step: 1054, epoch: 27, loss: 0.528432
global_step: 1055, epoch: 27, loss: 0.562885
global_step: 1056, epoch: 27, loss: 0.433627
global_step: 1057, epoch: 27, loss: 0.472478
global_step: 1058, epoch: 27, loss: 0.466315
global_step: 1059, epoch: 27, loss: 0.487532
global_step: 1060, epoch: 27, loss: 0.461569
global_step: 1061, epoch: 27, loss: 0.389062
global_step: 1062, epoch: 27, loss: 0.587365
global_step: 1063, epoch: 27, loss: 0.518900
global_step: 1064, epoch: 27, loss: 0.578033
global_step: 1065, epoch: 27, loss: 0.520909
global_step: 1066, epoch: 27, loss: 0.511467
global_step: 1067, epoch: 27, loss: 0.596625
global_step: 1068, epoch: 27, loss: 0.507496
global_step: 1069, epoch: 27, loss: 0.499651
global_step: 1070, epoch: 27, loss: 0.460896
global_step: 1071, epoch: 27, loss: 0.558215
global_step: 1072, epoch: 27, loss: 0.553408
global_step: 1073, epoch: 27, loss: 0.647680
global_step: 1074, epoch: 27, loss: 0.492533
global_step: 1075, epoch: 27, loss: 0.527439
global_step: 1076, epoch: 27, loss: 0.452430
global_step: 1077, epoch: 27, loss: 0.668763
global_step: 1078, epoch: 27, loss: 0.544006
global_step: 1079, epoch: 27, loss: 0.455225
global_step: 1080, epoch: 27, loss: 0.034970
epoch: 27
train	acc: 0.9208	macro: p 0.9402, r 0.8590, f1: 0.8945	micro: p 0.9208, r 0.9208, f1 0.9208	weighted_f1:0.9199
dev	acc: 0.5338	macro: p 0.3616, r 0.2933, f1: 0.2954	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4825
test	acc: 0.5950	macro: p 0.3614, r 0.3120, f1: 0.3191	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5498
global_step: 1081, epoch: 28, loss: 0.440252
global_step: 1082, epoch: 28, loss: 0.534822
global_step: 1083, epoch: 28, loss: 0.421562
global_step: 1084, epoch: 28, loss: 0.522954
global_step: 1085, epoch: 28, loss: 0.430558
global_step: 1086, epoch: 28, loss: 0.541105
global_step: 1087, epoch: 28, loss: 0.438289
global_step: 1088, epoch: 28, loss: 0.401179
global_step: 1089, epoch: 28, loss: 0.472663
global_step: 1090, epoch: 28, loss: 0.511537
global_step: 1091, epoch: 28, loss: 0.426562
global_step: 1092, epoch: 28, loss: 0.566742
global_step: 1093, epoch: 28, loss: 0.516571
global_step: 1094, epoch: 28, loss: 0.488783
global_step: 1095, epoch: 28, loss: 0.430947
global_step: 1096, epoch: 28, loss: 0.436642
global_step: 1097, epoch: 28, loss: 0.534788
global_step: 1098, epoch: 28, loss: 0.401445
global_step: 1099, epoch: 28, loss: 0.502249
global_step: 1100, epoch: 28, loss: 0.442720
global_step: 1101, epoch: 28, loss: 0.539312
global_step: 1102, epoch: 28, loss: 0.416571
global_step: 1103, epoch: 28, loss: 0.467926
global_step: 1104, epoch: 28, loss: 0.671284
global_step: 1105, epoch: 28, loss: 0.485125
global_step: 1106, epoch: 28, loss: 0.549269
global_step: 1107, epoch: 28, loss: 0.544364
global_step: 1108, epoch: 28, loss: 0.554908
global_step: 1109, epoch: 28, loss: 0.607935
global_step: 1110, epoch: 28, loss: 0.533765
global_step: 1111, epoch: 28, loss: 0.471757
global_step: 1112, epoch: 28, loss: 0.545273
global_step: 1113, epoch: 28, loss: 0.616753
global_step: 1114, epoch: 28, loss: 0.619436
global_step: 1115, epoch: 28, loss: 0.583403
global_step: 1116, epoch: 28, loss: 0.521563
global_step: 1117, epoch: 28, loss: 0.567318
global_step: 1118, epoch: 28, loss: 0.578125
global_step: 1119, epoch: 28, loss: 0.506416
global_step: 1120, epoch: 28, loss: 0.546157
epoch: 28
train	acc: 0.9229	macro: p 0.9244, r 0.8865, f1: 0.9019	micro: p 0.9229, r 0.9229, f1 0.9229	weighted_f1:0.9234
dev	acc: 0.4959	macro: p 0.3825, r 0.3102, f1: 0.3060	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4776
test	acc: 0.5502	macro: p 0.3399, r 0.3312, f1: 0.3218	micro: p 0.5502, r 0.5502, f1 0.5502	weighted_f1:0.5365
global_step: 1121, epoch: 29, loss: 0.502045
global_step: 1122, epoch: 29, loss: 0.488331
global_step: 1123, epoch: 29, loss: 0.521327
global_step: 1124, epoch: 29, loss: 0.458597
global_step: 1125, epoch: 29, loss: 0.445650
global_step: 1126, epoch: 29, loss: 0.518930
global_step: 1127, epoch: 29, loss: 0.397068
global_step: 1128, epoch: 29, loss: 0.479405
global_step: 1129, epoch: 29, loss: 0.496125
global_step: 1130, epoch: 29, loss: 0.518160
global_step: 1131, epoch: 29, loss: 0.481936
global_step: 1132, epoch: 29, loss: 0.515725
global_step: 1133, epoch: 29, loss: 0.617146
global_step: 1134, epoch: 29, loss: 0.532982
global_step: 1135, epoch: 29, loss: 0.489089
global_step: 1136, epoch: 29, loss: 0.559280
global_step: 1137, epoch: 29, loss: 0.465314
global_step: 1138, epoch: 29, loss: 0.564316
global_step: 1139, epoch: 29, loss: 0.440338
global_step: 1140, epoch: 29, loss: 0.456491
global_step: 1141, epoch: 29, loss: 0.433800
global_step: 1142, epoch: 29, loss: 0.449124
global_step: 1143, epoch: 29, loss: 0.472017
global_step: 1144, epoch: 29, loss: 0.469817
global_step: 1145, epoch: 29, loss: 0.560523
global_step: 1146, epoch: 29, loss: 0.497590
global_step: 1147, epoch: 29, loss: 0.397470
global_step: 1148, epoch: 29, loss: 0.441293
global_step: 1149, epoch: 29, loss: 0.412726
global_step: 1150, epoch: 29, loss: 0.498985
global_step: 1151, epoch: 29, loss: 0.522785
global_step: 1152, epoch: 29, loss: 0.526683
global_step: 1153, epoch: 29, loss: 0.565845
global_step: 1154, epoch: 29, loss: 0.509538
global_step: 1155, epoch: 29, loss: 0.484880
global_step: 1156, epoch: 29, loss: 0.503378
global_step: 1157, epoch: 29, loss: 0.482812
global_step: 1158, epoch: 29, loss: 0.511512
global_step: 1159, epoch: 29, loss: 0.512327
global_step: 1160, epoch: 29, loss: 0.023269
epoch: 29
train	acc: 0.9365	macro: p 0.9484, r 0.8959, f1: 0.9197	micro: p 0.9365, r 0.9365, f1 0.9365	weighted_f1:0.9362
dev	acc: 0.5374	macro: p 0.4328, r 0.3203, f1: 0.3307	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4967
test	acc: 0.5851	macro: p 0.3626, r 0.3193, f1: 0.3261	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5489
New best model!
global_step: 1161, epoch: 30, loss: 0.349775
global_step: 1162, epoch: 30, loss: 0.418870
global_step: 1163, epoch: 30, loss: 0.431964
global_step: 1164, epoch: 30, loss: 0.465653
global_step: 1165, epoch: 30, loss: 0.475961
global_step: 1166, epoch: 30, loss: 0.450628
global_step: 1167, epoch: 30, loss: 0.469293
global_step: 1168, epoch: 30, loss: 0.364268
global_step: 1169, epoch: 30, loss: 0.385999
global_step: 1170, epoch: 30, loss: 0.337650
global_step: 1171, epoch: 30, loss: 0.365425
global_step: 1172, epoch: 30, loss: 0.420987
global_step: 1173, epoch: 30, loss: 0.488755
global_step: 1174, epoch: 30, loss: 0.517350
global_step: 1175, epoch: 30, loss: 0.571466
global_step: 1176, epoch: 30, loss: 0.449530
global_step: 1177, epoch: 30, loss: 0.558867
global_step: 1178, epoch: 30, loss: 0.446291
global_step: 1179, epoch: 30, loss: 0.369844
global_step: 1180, epoch: 30, loss: 0.557564
global_step: 1181, epoch: 30, loss: 0.469188
global_step: 1182, epoch: 30, loss: 0.477627
global_step: 1183, epoch: 30, loss: 0.471384
global_step: 1184, epoch: 30, loss: 0.462370
global_step: 1185, epoch: 30, loss: 0.423440
global_step: 1186, epoch: 30, loss: 0.422904
global_step: 1187, epoch: 30, loss: 0.429517
global_step: 1188, epoch: 30, loss: 0.473549
global_step: 1189, epoch: 30, loss: 0.451420
global_step: 1190, epoch: 30, loss: 0.342747
global_step: 1191, epoch: 30, loss: 0.532473
global_step: 1192, epoch: 30, loss: 0.454783
global_step: 1193, epoch: 30, loss: 0.470582
global_step: 1194, epoch: 30, loss: 0.505864
global_step: 1195, epoch: 30, loss: 0.511486
global_step: 1196, epoch: 30, loss: 0.505862
global_step: 1197, epoch: 30, loss: 0.446891
global_step: 1198, epoch: 30, loss: 0.448356
global_step: 1199, epoch: 30, loss: 0.425664
global_step: 1200, epoch: 30, loss: 0.454492
epoch: 30
train	acc: 0.9372	macro: p 0.9471, r 0.8934, f1: 0.9180	micro: p 0.9372, r 0.9372, f1 0.9372	weighted_f1:0.9368
dev	acc: 0.5257	macro: p 0.3624, r 0.2992, f1: 0.3065	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4816
test	acc: 0.5858	macro: p 0.3806, r 0.3132, f1: 0.3224	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5472
global_step: 1201, epoch: 31, loss: 0.488641
global_step: 1202, epoch: 31, loss: 0.389173
global_step: 1203, epoch: 31, loss: 0.502875
global_step: 1204, epoch: 31, loss: 0.464742
global_step: 1205, epoch: 31, loss: 0.401452
global_step: 1206, epoch: 31, loss: 0.378890
global_step: 1207, epoch: 31, loss: 0.476185
global_step: 1208, epoch: 31, loss: 0.377110
global_step: 1209, epoch: 31, loss: 0.417488
global_step: 1210, epoch: 31, loss: 0.396823
global_step: 1211, epoch: 31, loss: 0.463017
global_step: 1212, epoch: 31, loss: 0.485772
global_step: 1213, epoch: 31, loss: 0.445835
global_step: 1214, epoch: 31, loss: 0.457651
global_step: 1215, epoch: 31, loss: 0.479658
global_step: 1216, epoch: 31, loss: 0.401925
global_step: 1217, epoch: 31, loss: 0.425934
global_step: 1218, epoch: 31, loss: 0.409036
global_step: 1219, epoch: 31, loss: 0.365558
global_step: 1220, epoch: 31, loss: 0.438731
global_step: 1221, epoch: 31, loss: 0.395024
global_step: 1222, epoch: 31, loss: 0.463537
global_step: 1223, epoch: 31, loss: 0.520408
global_step: 1224, epoch: 31, loss: 0.441885
global_step: 1225, epoch: 31, loss: 0.491094
global_step: 1226, epoch: 31, loss: 0.389443
global_step: 1227, epoch: 31, loss: 0.603290
global_step: 1228, epoch: 31, loss: 0.440998
global_step: 1229, epoch: 31, loss: 0.480934
global_step: 1230, epoch: 31, loss: 0.572706
global_step: 1231, epoch: 31, loss: 0.437587
global_step: 1232, epoch: 31, loss: 0.468009
global_step: 1233, epoch: 31, loss: 0.508134
global_step: 1234, epoch: 31, loss: 0.447078
global_step: 1235, epoch: 31, loss: 0.504083
global_step: 1236, epoch: 31, loss: 0.483781
global_step: 1237, epoch: 31, loss: 0.513864
global_step: 1238, epoch: 31, loss: 0.563293
global_step: 1239, epoch: 31, loss: 0.553291
global_step: 1240, epoch: 31, loss: 1.457144
epoch: 31
train	acc: 0.9384	macro: p 0.9432, r 0.9059, f1: 0.9236	micro: p 0.9384, r 0.9384, f1 0.9384	weighted_f1:0.9381
dev	acc: 0.5257	macro: p 0.3590, r 0.3147, f1: 0.3253	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4920
test	acc: 0.5751	macro: p 0.3643, r 0.3158, f1: 0.3292	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5438
global_step: 1241, epoch: 32, loss: 0.447082
global_step: 1242, epoch: 32, loss: 0.455798
global_step: 1243, epoch: 32, loss: 0.418371
global_step: 1244, epoch: 32, loss: 0.472868
global_step: 1245, epoch: 32, loss: 0.415117
global_step: 1246, epoch: 32, loss: 0.383125
global_step: 1247, epoch: 32, loss: 0.447339
global_step: 1248, epoch: 32, loss: 0.510723
global_step: 1249, epoch: 32, loss: 0.391184
global_step: 1250, epoch: 32, loss: 0.437981
global_step: 1251, epoch: 32, loss: 0.498577
global_step: 1252, epoch: 32, loss: 0.448381
global_step: 1253, epoch: 32, loss: 0.506504
global_step: 1254, epoch: 32, loss: 0.425675
global_step: 1255, epoch: 32, loss: 0.409965
global_step: 1256, epoch: 32, loss: 0.513747
global_step: 1257, epoch: 32, loss: 0.442556
global_step: 1258, epoch: 32, loss: 0.432575
global_step: 1259, epoch: 32, loss: 0.409995
global_step: 1260, epoch: 32, loss: 0.449043
global_step: 1261, epoch: 32, loss: 0.445448
global_step: 1262, epoch: 32, loss: 0.457083
global_step: 1263, epoch: 32, loss: 0.444676
global_step: 1264, epoch: 32, loss: 0.403978
global_step: 1265, epoch: 32, loss: 0.402224
global_step: 1266, epoch: 32, loss: 0.421643
global_step: 1267, epoch: 32, loss: 0.486569
global_step: 1268, epoch: 32, loss: 0.363474
global_step: 1269, epoch: 32, loss: 0.563269
global_step: 1270, epoch: 32, loss: 0.467647
global_step: 1271, epoch: 32, loss: 0.464350
global_step: 1272, epoch: 32, loss: 0.493960
global_step: 1273, epoch: 32, loss: 0.421174
global_step: 1274, epoch: 32, loss: 0.455211
global_step: 1275, epoch: 32, loss: 0.437556
global_step: 1276, epoch: 32, loss: 0.525456
global_step: 1277, epoch: 32, loss: 0.450242
global_step: 1278, epoch: 32, loss: 0.422004
global_step: 1279, epoch: 32, loss: 0.425692
global_step: 1280, epoch: 32, loss: 1.376120
epoch: 32
train	acc: 0.9360	macro: p 0.9473, r 0.8911, f1: 0.9162	micro: p 0.9360, r 0.9360, f1 0.9360	weighted_f1:0.9356
dev	acc: 0.5356	macro: p 0.3676, r 0.3064, f1: 0.3112	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4942
test	acc: 0.5904	macro: p 0.3811, r 0.3223, f1: 0.3342	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5556
global_step: 1281, epoch: 33, loss: 0.510605
global_step: 1282, epoch: 33, loss: 0.451902
global_step: 1283, epoch: 33, loss: 0.426817
global_step: 1284, epoch: 33, loss: 0.492686
global_step: 1285, epoch: 33, loss: 0.397476
global_step: 1286, epoch: 33, loss: 0.455419
global_step: 1287, epoch: 33, loss: 0.460415
global_step: 1288, epoch: 33, loss: 0.465665
global_step: 1289, epoch: 33, loss: 0.428352
global_step: 1290, epoch: 33, loss: 0.407245
global_step: 1291, epoch: 33, loss: 0.506856
global_step: 1292, epoch: 33, loss: 0.455025
global_step: 1293, epoch: 33, loss: 0.429244
global_step: 1294, epoch: 33, loss: 0.402685
global_step: 1295, epoch: 33, loss: 0.421955
global_step: 1296, epoch: 33, loss: 0.408996
global_step: 1297, epoch: 33, loss: 0.469223
global_step: 1298, epoch: 33, loss: 0.432445
global_step: 1299, epoch: 33, loss: 0.410155
global_step: 1300, epoch: 33, loss: 0.388200
global_step: 1301, epoch: 33, loss: 0.357105
global_step: 1302, epoch: 33, loss: 0.381504
global_step: 1303, epoch: 33, loss: 0.374184
global_step: 1304, epoch: 33, loss: 0.455807
global_step: 1305, epoch: 33, loss: 0.348935
global_step: 1306, epoch: 33, loss: 0.426020
global_step: 1307, epoch: 33, loss: 0.420616
global_step: 1308, epoch: 33, loss: 0.394510
global_step: 1309, epoch: 33, loss: 0.410863
global_step: 1310, epoch: 33, loss: 0.330269
global_step: 1311, epoch: 33, loss: 0.420738
global_step: 1312, epoch: 33, loss: 0.395412
global_step: 1313, epoch: 33, loss: 0.408344
global_step: 1314, epoch: 33, loss: 0.530167
global_step: 1315, epoch: 33, loss: 0.408545
global_step: 1316, epoch: 33, loss: 0.414711
global_step: 1317, epoch: 33, loss: 0.461675
global_step: 1318, epoch: 33, loss: 0.462421
global_step: 1319, epoch: 33, loss: 0.432535
global_step: 1320, epoch: 33, loss: 0.018654
epoch: 33
train	acc: 0.9482	macro: p 0.9588, r 0.9182, f1: 0.9370	micro: p 0.9482, r 0.9482, f1 0.9482	weighted_f1:0.9481
dev	acc: 0.5239	macro: p 0.3908, r 0.3094, f1: 0.3167	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4863
test	acc: 0.5805	macro: p 0.3722, r 0.3216, f1: 0.3282	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5475
global_step: 1321, epoch: 34, loss: 0.340031
global_step: 1322, epoch: 34, loss: 0.341524
global_step: 1323, epoch: 34, loss: 0.375623
global_step: 1324, epoch: 34, loss: 0.370463
global_step: 1325, epoch: 34, loss: 0.361423
global_step: 1326, epoch: 34, loss: 0.350614
global_step: 1327, epoch: 34, loss: 0.409987
global_step: 1328, epoch: 34, loss: 0.392346
global_step: 1329, epoch: 34, loss: 0.344304
global_step: 1330, epoch: 34, loss: 0.413090
global_step: 1331, epoch: 34, loss: 0.280712
global_step: 1332, epoch: 34, loss: 0.414475
global_step: 1333, epoch: 34, loss: 0.356299
global_step: 1334, epoch: 34, loss: 0.414011
global_step: 1335, epoch: 34, loss: 0.319460
global_step: 1336, epoch: 34, loss: 0.431718
global_step: 1337, epoch: 34, loss: 0.418436
global_step: 1338, epoch: 34, loss: 0.350692
global_step: 1339, epoch: 34, loss: 0.466820
global_step: 1340, epoch: 34, loss: 0.452928
global_step: 1341, epoch: 34, loss: 0.459397
global_step: 1342, epoch: 34, loss: 0.482198
global_step: 1343, epoch: 34, loss: 0.460010
global_step: 1344, epoch: 34, loss: 0.444605
global_step: 1345, epoch: 34, loss: 0.361795
global_step: 1346, epoch: 34, loss: 0.418415
global_step: 1347, epoch: 34, loss: 0.427822
global_step: 1348, epoch: 34, loss: 0.374000
global_step: 1349, epoch: 34, loss: 0.433961
global_step: 1350, epoch: 34, loss: 0.512072
global_step: 1351, epoch: 34, loss: 0.431695
global_step: 1352, epoch: 34, loss: 0.363403
global_step: 1353, epoch: 34, loss: 0.435668
global_step: 1354, epoch: 34, loss: 0.376532
global_step: 1355, epoch: 34, loss: 0.412148
global_step: 1356, epoch: 34, loss: 0.442942
global_step: 1357, epoch: 34, loss: 0.384695
global_step: 1358, epoch: 34, loss: 0.400245
global_step: 1359, epoch: 34, loss: 0.436536
global_step: 1360, epoch: 34, loss: 0.074908
epoch: 34
train	acc: 0.9463	macro: p 0.9537, r 0.9253, f1: 0.9384	micro: p 0.9463, r 0.9463, f1 0.9463	weighted_f1:0.9465
dev	acc: 0.5050	macro: p 0.3900, r 0.3194, f1: 0.3231	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4834
test	acc: 0.5494	macro: p 0.3454, r 0.3198, f1: 0.3192	micro: p 0.5494, r 0.5494, f1 0.5494	weighted_f1:0.5319
global_step: 1361, epoch: 35, loss: 0.436929
global_step: 1362, epoch: 35, loss: 0.340903
global_step: 1363, epoch: 35, loss: 0.472400
global_step: 1364, epoch: 35, loss: 0.366200
global_step: 1365, epoch: 35, loss: 0.367525
global_step: 1366, epoch: 35, loss: 0.349131
global_step: 1367, epoch: 35, loss: 0.372064
global_step: 1368, epoch: 35, loss: 0.394420
global_step: 1369, epoch: 35, loss: 0.398486
global_step: 1370, epoch: 35, loss: 0.326470
global_step: 1371, epoch: 35, loss: 0.388682
global_step: 1372, epoch: 35, loss: 0.469464
global_step: 1373, epoch: 35, loss: 0.409546
global_step: 1374, epoch: 35, loss: 0.401959
global_step: 1375, epoch: 35, loss: 0.523636
global_step: 1376, epoch: 35, loss: 0.487587
global_step: 1377, epoch: 35, loss: 0.372813
global_step: 1378, epoch: 35, loss: 0.420809
global_step: 1379, epoch: 35, loss: 0.342959
global_step: 1380, epoch: 35, loss: 0.395553
global_step: 1381, epoch: 35, loss: 0.445780
global_step: 1382, epoch: 35, loss: 0.364447
global_step: 1383, epoch: 35, loss: 0.426505
global_step: 1384, epoch: 35, loss: 0.380122
global_step: 1385, epoch: 35, loss: 0.488367
global_step: 1386, epoch: 35, loss: 0.381556
global_step: 1387, epoch: 35, loss: 0.443002
global_step: 1388, epoch: 35, loss: 0.500954
global_step: 1389, epoch: 35, loss: 0.421803
global_step: 1390, epoch: 35, loss: 0.386025
global_step: 1391, epoch: 35, loss: 0.483977
global_step: 1392, epoch: 35, loss: 0.369288
global_step: 1393, epoch: 35, loss: 0.439560
global_step: 1394, epoch: 35, loss: 0.446801
global_step: 1395, epoch: 35, loss: 0.431971
global_step: 1396, epoch: 35, loss: 0.425206
global_step: 1397, epoch: 35, loss: 0.446266
global_step: 1398, epoch: 35, loss: 0.555246
global_step: 1399, epoch: 35, loss: 0.389419
global_step: 1400, epoch: 35, loss: 0.029388
epoch: 35
train	acc: 0.9467	macro: p 0.9596, r 0.9108, f1: 0.9329	micro: p 0.9467, r 0.9467, f1 0.9467	weighted_f1:0.9465
dev	acc: 0.5401	macro: p 0.4607, r 0.3180, f1: 0.3199	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4920
test	acc: 0.5755	macro: p 0.3633, r 0.3108, f1: 0.3093	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5350
global_step: 1401, epoch: 36, loss: 0.372228
global_step: 1402, epoch: 36, loss: 0.318584
global_step: 1403, epoch: 36, loss: 0.364615
global_step: 1404, epoch: 36, loss: 0.473315
global_step: 1405, epoch: 36, loss: 0.437059
global_step: 1406, epoch: 36, loss: 0.415958
global_step: 1407, epoch: 36, loss: 0.356799
global_step: 1408, epoch: 36, loss: 0.417194
global_step: 1409, epoch: 36, loss: 0.331616
global_step: 1410, epoch: 36, loss: 0.405015
global_step: 1411, epoch: 36, loss: 0.379482
global_step: 1412, epoch: 36, loss: 0.400507
global_step: 1413, epoch: 36, loss: 0.406198
global_step: 1414, epoch: 36, loss: 0.403491
global_step: 1415, epoch: 36, loss: 0.459470
global_step: 1416, epoch: 36, loss: 0.424295
global_step: 1417, epoch: 36, loss: 0.434873
global_step: 1418, epoch: 36, loss: 0.357407
global_step: 1419, epoch: 36, loss: 0.273003
global_step: 1420, epoch: 36, loss: 0.359756
global_step: 1421, epoch: 36, loss: 0.369996
global_step: 1422, epoch: 36, loss: 0.410290
global_step: 1423, epoch: 36, loss: 0.465513
global_step: 1424, epoch: 36, loss: 0.415529
global_step: 1425, epoch: 36, loss: 0.398277
global_step: 1426, epoch: 36, loss: 0.490494
global_step: 1427, epoch: 36, loss: 0.455327
global_step: 1428, epoch: 36, loss: 0.438826
global_step: 1429, epoch: 36, loss: 0.357180
global_step: 1430, epoch: 36, loss: 0.408391
global_step: 1431, epoch: 36, loss: 0.405715
global_step: 1432, epoch: 36, loss: 0.415341
global_step: 1433, epoch: 36, loss: 0.496630
global_step: 1434, epoch: 36, loss: 0.444974
global_step: 1435, epoch: 36, loss: 0.326401
global_step: 1436, epoch: 36, loss: 0.370647
global_step: 1437, epoch: 36, loss: 0.323375
global_step: 1438, epoch: 36, loss: 0.582892
global_step: 1439, epoch: 36, loss: 0.452991
global_step: 1440, epoch: 36, loss: 0.386364
epoch: 36
train	acc: 0.9431	macro: p 0.9484, r 0.9063, f1: 0.9244	micro: p 0.9431, r 0.9431, f1 0.9431	weighted_f1:0.9432
dev	acc: 0.5050	macro: p 0.4145, r 0.3107, f1: 0.3100	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4854
test	acc: 0.5467	macro: p 0.3474, r 0.3181, f1: 0.3118	micro: p 0.5467, r 0.5467, f1 0.5467	weighted_f1:0.5307
global_step: 1441, epoch: 37, loss: 0.396535
global_step: 1442, epoch: 37, loss: 0.261581
global_step: 1443, epoch: 37, loss: 0.371231
global_step: 1444, epoch: 37, loss: 0.465544
global_step: 1445, epoch: 37, loss: 0.444610
global_step: 1446, epoch: 37, loss: 0.355918
global_step: 1447, epoch: 37, loss: 0.455859
global_step: 1448, epoch: 37, loss: 0.372377
global_step: 1449, epoch: 37, loss: 0.319190
global_step: 1450, epoch: 37, loss: 0.331302
global_step: 1451, epoch: 37, loss: 0.343448
global_step: 1452, epoch: 37, loss: 0.350879
global_step: 1453, epoch: 37, loss: 0.404948
global_step: 1454, epoch: 37, loss: 0.420764
global_step: 1455, epoch: 37, loss: 0.377225
global_step: 1456, epoch: 37, loss: 0.405669
global_step: 1457, epoch: 37, loss: 0.389138
global_step: 1458, epoch: 37, loss: 0.403774
global_step: 1459, epoch: 37, loss: 0.449378
global_step: 1460, epoch: 37, loss: 0.372257
global_step: 1461, epoch: 37, loss: 0.382487
global_step: 1462, epoch: 37, loss: 0.408015
global_step: 1463, epoch: 37, loss: 0.391907
global_step: 1464, epoch: 37, loss: 0.433077
global_step: 1465, epoch: 37, loss: 0.514882
global_step: 1466, epoch: 37, loss: 0.387702
global_step: 1467, epoch: 37, loss: 0.310732
global_step: 1468, epoch: 37, loss: 0.407228
global_step: 1469, epoch: 37, loss: 0.418533
global_step: 1470, epoch: 37, loss: 0.494164
global_step: 1471, epoch: 37, loss: 0.349059
global_step: 1472, epoch: 37, loss: 0.489105
global_step: 1473, epoch: 37, loss: 0.404596
global_step: 1474, epoch: 37, loss: 0.371844
global_step: 1475, epoch: 37, loss: 0.411388
global_step: 1476, epoch: 37, loss: 0.397002
global_step: 1477, epoch: 37, loss: 0.416381
global_step: 1478, epoch: 37, loss: 0.490588
global_step: 1479, epoch: 37, loss: 0.405184
global_step: 1480, epoch: 37, loss: 0.668240
epoch: 37
train	acc: 0.9505	macro: p 0.9581, r 0.9193, f1: 0.9373	micro: p 0.9505, r 0.9505, f1 0.9505	weighted_f1:0.9504
dev	acc: 0.5356	macro: p 0.4547, r 0.3146, f1: 0.3278	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4953
test	acc: 0.5870	macro: p 0.4074, r 0.3171, f1: 0.3238	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5483
global_step: 1481, epoch: 38, loss: 0.464246
global_step: 1482, epoch: 38, loss: 0.397515
global_step: 1483, epoch: 38, loss: 0.328588
global_step: 1484, epoch: 38, loss: 0.319273
global_step: 1485, epoch: 38, loss: 0.376670
global_step: 1486, epoch: 38, loss: 0.342089
global_step: 1487, epoch: 38, loss: 0.386208
global_step: 1488, epoch: 38, loss: 0.403139
global_step: 1489, epoch: 38, loss: 0.332180
global_step: 1490, epoch: 38, loss: 0.480041
global_step: 1491, epoch: 38, loss: 0.481300
global_step: 1492, epoch: 38, loss: 0.370257
global_step: 1493, epoch: 38, loss: 0.372096
global_step: 1494, epoch: 38, loss: 0.383738
global_step: 1495, epoch: 38, loss: 0.417936
global_step: 1496, epoch: 38, loss: 0.372923
global_step: 1497, epoch: 38, loss: 0.383182
global_step: 1498, epoch: 38, loss: 0.402300
global_step: 1499, epoch: 38, loss: 0.420991
global_step: 1500, epoch: 38, loss: 0.467385
global_step: 1501, epoch: 38, loss: 0.391108
global_step: 1502, epoch: 38, loss: 0.419272
global_step: 1503, epoch: 38, loss: 0.342083
global_step: 1504, epoch: 38, loss: 0.351294
global_step: 1505, epoch: 38, loss: 0.327008
global_step: 1506, epoch: 38, loss: 0.466334
global_step: 1507, epoch: 38, loss: 0.321157
global_step: 1508, epoch: 38, loss: 0.297348
global_step: 1509, epoch: 38, loss: 0.387525
global_step: 1510, epoch: 38, loss: 0.406850
global_step: 1511, epoch: 38, loss: 0.412870
global_step: 1512, epoch: 38, loss: 0.397511
global_step: 1513, epoch: 38, loss: 0.364179
global_step: 1514, epoch: 38, loss: 0.398984
global_step: 1515, epoch: 38, loss: 0.398609
global_step: 1516, epoch: 38, loss: 0.407180
global_step: 1517, epoch: 38, loss: 0.536751
global_step: 1518, epoch: 38, loss: 0.421957
global_step: 1519, epoch: 38, loss: 0.429250
global_step: 1520, epoch: 38, loss: 0.026640
epoch: 38
train	acc: 0.9518	macro: p 0.9649, r 0.9224, f1: 0.9423	micro: p 0.9518, r 0.9518, f1 0.9518	weighted_f1:0.9517
dev	acc: 0.5419	macro: p 0.4513, r 0.3175, f1: 0.3343	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4922
test	acc: 0.5885	macro: p 0.3808, r 0.3093, f1: 0.3179	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5426
global_step: 1521, epoch: 39, loss: 0.331685
global_step: 1522, epoch: 39, loss: 0.346486
global_step: 1523, epoch: 39, loss: 0.413338
global_step: 1524, epoch: 39, loss: 0.338458
global_step: 1525, epoch: 39, loss: 0.346693
global_step: 1526, epoch: 39, loss: 0.327604
global_step: 1527, epoch: 39, loss: 0.349308
global_step: 1528, epoch: 39, loss: 0.356651
global_step: 1529, epoch: 39, loss: 0.316151
global_step: 1530, epoch: 39, loss: 0.357722
global_step: 1531, epoch: 39, loss: 0.363523
global_step: 1532, epoch: 39, loss: 0.356525
global_step: 1533, epoch: 39, loss: 0.322075
global_step: 1534, epoch: 39, loss: 0.457623
global_step: 1535, epoch: 39, loss: 0.291494
global_step: 1536, epoch: 39, loss: 0.389020
global_step: 1537, epoch: 39, loss: 0.383482
global_step: 1538, epoch: 39, loss: 0.459687
global_step: 1539, epoch: 39, loss: 0.306984
global_step: 1540, epoch: 39, loss: 0.413936
global_step: 1541, epoch: 39, loss: 0.300642
global_step: 1542, epoch: 39, loss: 0.404645
global_step: 1543, epoch: 39, loss: 0.393383
global_step: 1544, epoch: 39, loss: 0.353543
global_step: 1545, epoch: 39, loss: 0.439424
global_step: 1546, epoch: 39, loss: 0.382165
global_step: 1547, epoch: 39, loss: 0.435907
global_step: 1548, epoch: 39, loss: 0.360593
global_step: 1549, epoch: 39, loss: 0.311884
global_step: 1550, epoch: 39, loss: 0.402487
global_step: 1551, epoch: 39, loss: 0.535756
global_step: 1552, epoch: 39, loss: 0.384590
global_step: 1553, epoch: 39, loss: 0.375999
global_step: 1554, epoch: 39, loss: 0.359036
global_step: 1555, epoch: 39, loss: 0.387847
global_step: 1556, epoch: 39, loss: 0.437592
global_step: 1557, epoch: 39, loss: 0.384167
global_step: 1558, epoch: 39, loss: 0.333903
global_step: 1559, epoch: 39, loss: 0.440094
global_step: 1560, epoch: 39, loss: 0.114702
epoch: 39
train	acc: 0.9495	macro: p 0.9565, r 0.9190, f1: 0.9360	micro: p 0.9495, r 0.9495, f1 0.9495	weighted_f1:0.9495
dev	acc: 0.5266	macro: p 0.4204, r 0.3163, f1: 0.3247	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4932
test	acc: 0.5701	macro: p 0.3447, r 0.3164, f1: 0.3168	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5420
global_step: 1561, epoch: 40, loss: 0.377868
global_step: 1562, epoch: 40, loss: 0.381303
global_step: 1563, epoch: 40, loss: 0.374070
global_step: 1564, epoch: 40, loss: 0.322628
global_step: 1565, epoch: 40, loss: 0.312160
global_step: 1566, epoch: 40, loss: 0.391465
global_step: 1567, epoch: 40, loss: 0.472707
global_step: 1568, epoch: 40, loss: 0.335289
global_step: 1569, epoch: 40, loss: 0.355799
global_step: 1570, epoch: 40, loss: 0.303184
global_step: 1571, epoch: 40, loss: 0.379709
global_step: 1572, epoch: 40, loss: 0.392226
global_step: 1573, epoch: 40, loss: 0.360474
global_step: 1574, epoch: 40, loss: 0.339083
global_step: 1575, epoch: 40, loss: 0.335691
global_step: 1576, epoch: 40, loss: 0.343440
global_step: 1577, epoch: 40, loss: 0.456307
global_step: 1578, epoch: 40, loss: 0.449592
global_step: 1579, epoch: 40, loss: 0.392438
global_step: 1580, epoch: 40, loss: 0.339497
global_step: 1581, epoch: 40, loss: 0.361024
global_step: 1582, epoch: 40, loss: 0.364970
global_step: 1583, epoch: 40, loss: 0.333562
global_step: 1584, epoch: 40, loss: 0.438129
global_step: 1585, epoch: 40, loss: 0.378661
global_step: 1586, epoch: 40, loss: 0.307023
global_step: 1587, epoch: 40, loss: 0.366854
global_step: 1588, epoch: 40, loss: 0.416861
global_step: 1589, epoch: 40, loss: 0.406009
global_step: 1590, epoch: 40, loss: 0.298909
global_step: 1591, epoch: 40, loss: 0.433355
global_step: 1592, epoch: 40, loss: 0.401987
global_step: 1593, epoch: 40, loss: 0.517744
global_step: 1594, epoch: 40, loss: 0.377022
global_step: 1595, epoch: 40, loss: 0.358557
global_step: 1596, epoch: 40, loss: 0.352617
global_step: 1597, epoch: 40, loss: 0.484696
global_step: 1598, epoch: 40, loss: 0.489316
global_step: 1599, epoch: 40, loss: 0.278255
global_step: 1600, epoch: 40, loss: 0.390942
epoch: 40
train	acc: 0.9405	macro: p 0.9559, r 0.8956, f1: 0.9220	micro: p 0.9405, r 0.9405, f1 0.9405	weighted_f1:0.9404
dev	acc: 0.5122	macro: p 0.4851, r 0.3036, f1: 0.3047	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4735
test	acc: 0.5621	macro: p 0.3872, r 0.3067, f1: 0.3032	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.5284
global_step: 1601, epoch: 41, loss: 0.435625
global_step: 1602, epoch: 41, loss: 0.326185
global_step: 1603, epoch: 41, loss: 0.367694
global_step: 1604, epoch: 41, loss: 0.332438
global_step: 1605, epoch: 41, loss: 0.316915
global_step: 1606, epoch: 41, loss: 0.347833
global_step: 1607, epoch: 41, loss: 0.389782
global_step: 1608, epoch: 41, loss: 0.312355
global_step: 1609, epoch: 41, loss: 0.318458
global_step: 1610, epoch: 41, loss: 0.266260
global_step: 1611, epoch: 41, loss: 0.291667
global_step: 1612, epoch: 41, loss: 0.311685
global_step: 1613, epoch: 41, loss: 0.465851
global_step: 1614, epoch: 41, loss: 0.373186
global_step: 1615, epoch: 41, loss: 0.378694
global_step: 1616, epoch: 41, loss: 0.392782
global_step: 1617, epoch: 41, loss: 0.333689
global_step: 1618, epoch: 41, loss: 0.408965
global_step: 1619, epoch: 41, loss: 0.358921
global_step: 1620, epoch: 41, loss: 0.411241
global_step: 1621, epoch: 41, loss: 0.335791
global_step: 1622, epoch: 41, loss: 0.352970
global_step: 1623, epoch: 41, loss: 0.383155
global_step: 1624, epoch: 41, loss: 0.464103
global_step: 1625, epoch: 41, loss: 0.495038
global_step: 1626, epoch: 41, loss: 0.399710
global_step: 1627, epoch: 41, loss: 0.352247
global_step: 1628, epoch: 41, loss: 0.408246
global_step: 1629, epoch: 41, loss: 0.332623
global_step: 1630, epoch: 41, loss: 0.520809
global_step: 1631, epoch: 41, loss: 0.311428
global_step: 1632, epoch: 41, loss: 0.399702
global_step: 1633, epoch: 41, loss: 0.355349
global_step: 1634, epoch: 41, loss: 0.445912
global_step: 1635, epoch: 41, loss: 0.425997
global_step: 1636, epoch: 41, loss: 0.392490
global_step: 1637, epoch: 41, loss: 0.422246
global_step: 1638, epoch: 41, loss: 0.397879
global_step: 1639, epoch: 41, loss: 0.389239
global_step: 1640, epoch: 41, loss: 1.022675
epoch: 41
train	acc: 0.9555	macro: p 0.9615, r 0.9324, f1: 0.9456	micro: p 0.9555, r 0.9555, f1 0.9555	weighted_f1:0.9555
dev	acc: 0.5284	macro: p 0.3883, r 0.3270, f1: 0.3344	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4945
test	acc: 0.5709	macro: p 0.3529, r 0.3260, f1: 0.3271	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5414
global_step: 1641, epoch: 42, loss: 0.376547
global_step: 1642, epoch: 42, loss: 0.380111
global_step: 1643, epoch: 42, loss: 0.369764
global_step: 1644, epoch: 42, loss: 0.354312
global_step: 1645, epoch: 42, loss: 0.346579
global_step: 1646, epoch: 42, loss: 0.313105
global_step: 1647, epoch: 42, loss: 0.401955
global_step: 1648, epoch: 42, loss: 0.348004
global_step: 1649, epoch: 42, loss: 0.404882
global_step: 1650, epoch: 42, loss: 0.361984
global_step: 1651, epoch: 42, loss: 0.452979
global_step: 1652, epoch: 42, loss: 0.402106
global_step: 1653, epoch: 42, loss: 0.329435
global_step: 1654, epoch: 42, loss: 0.381732
global_step: 1655, epoch: 42, loss: 0.327767
global_step: 1656, epoch: 42, loss: 0.313192
global_step: 1657, epoch: 42, loss: 0.458724
global_step: 1658, epoch: 42, loss: 0.434407
global_step: 1659, epoch: 42, loss: 0.282372
global_step: 1660, epoch: 42, loss: 0.351860
global_step: 1661, epoch: 42, loss: 0.376946
global_step: 1662, epoch: 42, loss: 0.358906
global_step: 1663, epoch: 42, loss: 0.369531
global_step: 1664, epoch: 42, loss: 0.499958
global_step: 1665, epoch: 42, loss: 0.348342
global_step: 1666, epoch: 42, loss: 0.400833
global_step: 1667, epoch: 42, loss: 0.305677
global_step: 1668, epoch: 42, loss: 0.397306
global_step: 1669, epoch: 42, loss: 0.280877
global_step: 1670, epoch: 42, loss: 0.340115
global_step: 1671, epoch: 42, loss: 0.388846
global_step: 1672, epoch: 42, loss: 0.434978
global_step: 1673, epoch: 42, loss: 0.352794
global_step: 1674, epoch: 42, loss: 0.435977
global_step: 1675, epoch: 42, loss: 0.493537
global_step: 1676, epoch: 42, loss: 0.394448
global_step: 1677, epoch: 42, loss: 0.411372
global_step: 1678, epoch: 42, loss: 0.419792
global_step: 1679, epoch: 42, loss: 0.350960
global_step: 1680, epoch: 42, loss: 1.240687
epoch: 42
train	acc: 0.9416	macro: p 0.9622, r 0.9111, f1: 0.9346	micro: p 0.9416, r 0.9416, f1 0.9416	weighted_f1:0.9412
dev	acc: 0.5275	macro: p 0.4499, r 0.2932, f1: 0.3098	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4726
test	acc: 0.5885	macro: p 0.4146, r 0.3020, f1: 0.3161	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5359
global_step: 1681, epoch: 43, loss: 0.418106
global_step: 1682, epoch: 43, loss: 0.337479
global_step: 1683, epoch: 43, loss: 0.399400
global_step: 1684, epoch: 43, loss: 0.363905
global_step: 1685, epoch: 43, loss: 0.397432
global_step: 1686, epoch: 43, loss: 0.358174
global_step: 1687, epoch: 43, loss: 0.372190
global_step: 1688, epoch: 43, loss: 0.327600
global_step: 1689, epoch: 43, loss: 0.334194
global_step: 1690, epoch: 43, loss: 0.255711
global_step: 1691, epoch: 43, loss: 0.370531
global_step: 1692, epoch: 43, loss: 0.412554
global_step: 1693, epoch: 43, loss: 0.310132
global_step: 1694, epoch: 43, loss: 0.355184
global_step: 1695, epoch: 43, loss: 0.301512
global_step: 1696, epoch: 43, loss: 0.371953
global_step: 1697, epoch: 43, loss: 0.371497
global_step: 1698, epoch: 43, loss: 0.411831
global_step: 1699, epoch: 43, loss: 0.375245
global_step: 1700, epoch: 43, loss: 0.356373
global_step: 1701, epoch: 43, loss: 0.268135
global_step: 1702, epoch: 43, loss: 0.337658
global_step: 1703, epoch: 43, loss: 0.342922
global_step: 1704, epoch: 43, loss: 0.387283
global_step: 1705, epoch: 43, loss: 0.306577
global_step: 1706, epoch: 43, loss: 0.296511
global_step: 1707, epoch: 43, loss: 0.270639
global_step: 1708, epoch: 43, loss: 0.361883
global_step: 1709, epoch: 43, loss: 0.348531
global_step: 1710, epoch: 43, loss: 0.496990
global_step: 1711, epoch: 43, loss: 0.353963
global_step: 1712, epoch: 43, loss: 0.411729
global_step: 1713, epoch: 43, loss: 0.421414
global_step: 1714, epoch: 43, loss: 0.484697
global_step: 1715, epoch: 43, loss: 0.273972
global_step: 1716, epoch: 43, loss: 0.265729
global_step: 1717, epoch: 43, loss: 0.432109
global_step: 1718, epoch: 43, loss: 0.444833
global_step: 1719, epoch: 43, loss: 0.348127
global_step: 1720, epoch: 43, loss: 0.376011
epoch: 43
train	acc: 0.9570	macro: p 0.9603, r 0.9384, f1: 0.9489	micro: p 0.9570, r 0.9570, f1 0.9570	weighted_f1:0.9569
dev	acc: 0.5311	macro: p 0.4270, r 0.3347, f1: 0.3525	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4985
test	acc: 0.5690	macro: p 0.3733, r 0.3197, f1: 0.3308	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5415
New best model!
global_step: 1721, epoch: 44, loss: 0.285491
global_step: 1722, epoch: 44, loss: 0.283193
global_step: 1723, epoch: 44, loss: 0.328373
global_step: 1724, epoch: 44, loss: 0.290627
global_step: 1725, epoch: 44, loss: 0.351725
global_step: 1726, epoch: 44, loss: 0.377593
global_step: 1727, epoch: 44, loss: 0.255870
global_step: 1728, epoch: 44, loss: 0.341920
global_step: 1729, epoch: 44, loss: 0.323237
global_step: 1730, epoch: 44, loss: 0.382846
global_step: 1731, epoch: 44, loss: 0.424837
global_step: 1732, epoch: 44, loss: 0.363930
global_step: 1733, epoch: 44, loss: 0.303342
global_step: 1734, epoch: 44, loss: 0.375512
global_step: 1735, epoch: 44, loss: 0.316665
global_step: 1736, epoch: 44, loss: 0.409598
global_step: 1737, epoch: 44, loss: 0.375103
global_step: 1738, epoch: 44, loss: 0.296438
global_step: 1739, epoch: 44, loss: 0.318384
global_step: 1740, epoch: 44, loss: 0.389530
global_step: 1741, epoch: 44, loss: 0.306789
global_step: 1742, epoch: 44, loss: 0.402911
global_step: 1743, epoch: 44, loss: 0.339116
global_step: 1744, epoch: 44, loss: 0.326883
global_step: 1745, epoch: 44, loss: 0.429087
global_step: 1746, epoch: 44, loss: 0.336797
global_step: 1747, epoch: 44, loss: 0.279413
global_step: 1748, epoch: 44, loss: 0.399834
global_step: 1749, epoch: 44, loss: 0.312764
global_step: 1750, epoch: 44, loss: 0.376372
global_step: 1751, epoch: 44, loss: 0.489088
global_step: 1752, epoch: 44, loss: 0.367821
global_step: 1753, epoch: 44, loss: 0.365871
global_step: 1754, epoch: 44, loss: 0.246618
global_step: 1755, epoch: 44, loss: 0.380284
global_step: 1756, epoch: 44, loss: 0.372685
global_step: 1757, epoch: 44, loss: 0.350128
global_step: 1758, epoch: 44, loss: 0.304214
global_step: 1759, epoch: 44, loss: 0.301416
global_step: 1760, epoch: 44, loss: 0.438700
epoch: 44
train	acc: 0.9495	macro: p 0.9671, r 0.9157, f1: 0.9396	micro: p 0.9495, r 0.9495, f1 0.9495	weighted_f1:0.9492
dev	acc: 0.5419	macro: p 0.4263, r 0.2993, f1: 0.3056	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4840
test	acc: 0.5954	macro: p 0.3911, r 0.3053, f1: 0.3128	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5446
global_step: 1761, epoch: 45, loss: 0.402947
global_step: 1762, epoch: 45, loss: 0.282782
global_step: 1763, epoch: 45, loss: 0.342436
global_step: 1764, epoch: 45, loss: 0.362060
global_step: 1765, epoch: 45, loss: 0.312390
global_step: 1766, epoch: 45, loss: 0.301343
global_step: 1767, epoch: 45, loss: 0.323611
global_step: 1768, epoch: 45, loss: 0.329928
global_step: 1769, epoch: 45, loss: 0.276751
global_step: 1770, epoch: 45, loss: 0.290146
global_step: 1771, epoch: 45, loss: 0.228209
global_step: 1772, epoch: 45, loss: 0.316427
global_step: 1773, epoch: 45, loss: 0.330302
global_step: 1774, epoch: 45, loss: 0.354571
global_step: 1775, epoch: 45, loss: 0.378950
global_step: 1776, epoch: 45, loss: 0.316277
global_step: 1777, epoch: 45, loss: 0.282487
global_step: 1778, epoch: 45, loss: 0.288346
global_step: 1779, epoch: 45, loss: 0.301791
global_step: 1780, epoch: 45, loss: 0.395497
global_step: 1781, epoch: 45, loss: 0.341510
global_step: 1782, epoch: 45, loss: 0.356974
global_step: 1783, epoch: 45, loss: 0.255406
global_step: 1784, epoch: 45, loss: 0.295658
global_step: 1785, epoch: 45, loss: 0.310279
global_step: 1786, epoch: 45, loss: 0.411744
global_step: 1787, epoch: 45, loss: 0.319029
global_step: 1788, epoch: 45, loss: 0.375291
global_step: 1789, epoch: 45, loss: 0.294424
global_step: 1790, epoch: 45, loss: 0.363995
global_step: 1791, epoch: 45, loss: 0.305712
global_step: 1792, epoch: 45, loss: 0.398006
global_step: 1793, epoch: 45, loss: 0.348265
global_step: 1794, epoch: 45, loss: 0.343648
global_step: 1795, epoch: 45, loss: 0.404891
global_step: 1796, epoch: 45, loss: 0.342261
global_step: 1797, epoch: 45, loss: 0.365496
global_step: 1798, epoch: 45, loss: 0.534391
global_step: 1799, epoch: 45, loss: 0.360958
global_step: 1800, epoch: 45, loss: 0.437364
epoch: 45
train	acc: 0.9607	macro: p 0.9607, r 0.9457, f1: 0.9529	micro: p 0.9607, r 0.9607, f1 0.9607	weighted_f1:0.9607
dev	acc: 0.5176	macro: p 0.4834, r 0.3307, f1: 0.3466	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4950
test	acc: 0.5414	macro: p 0.3313, r 0.3116, f1: 0.3154	micro: p 0.5414, r 0.5414, f1 0.5414	weighted_f1:0.5240
global_step: 1801, epoch: 46, loss: 0.279225
global_step: 1802, epoch: 46, loss: 0.357537
global_step: 1803, epoch: 46, loss: 0.264470
global_step: 1804, epoch: 46, loss: 0.305138
global_step: 1805, epoch: 46, loss: 0.339411
global_step: 1806, epoch: 46, loss: 0.301749
global_step: 1807, epoch: 46, loss: 0.410667
global_step: 1808, epoch: 46, loss: 0.306798
global_step: 1809, epoch: 46, loss: 0.319004
global_step: 1810, epoch: 46, loss: 0.356545
global_step: 1811, epoch: 46, loss: 0.344615
global_step: 1812, epoch: 46, loss: 0.305157
global_step: 1813, epoch: 46, loss: 0.324388
global_step: 1814, epoch: 46, loss: 0.392982
global_step: 1815, epoch: 46, loss: 0.356581
global_step: 1816, epoch: 46, loss: 0.243363
global_step: 1817, epoch: 46, loss: 0.358105
global_step: 1818, epoch: 46, loss: 0.416530
global_step: 1819, epoch: 46, loss: 0.341611
global_step: 1820, epoch: 46, loss: 0.311030
global_step: 1821, epoch: 46, loss: 0.379939
global_step: 1822, epoch: 46, loss: 0.273262
global_step: 1823, epoch: 46, loss: 0.326944
global_step: 1824, epoch: 46, loss: 0.295322
global_step: 1825, epoch: 46, loss: 0.332795
global_step: 1826, epoch: 46, loss: 0.253087
global_step: 1827, epoch: 46, loss: 0.249110
global_step: 1828, epoch: 46, loss: 0.333689
global_step: 1829, epoch: 46, loss: 0.345607
global_step: 1830, epoch: 46, loss: 0.238616
global_step: 1831, epoch: 46, loss: 0.319089
global_step: 1832, epoch: 46, loss: 0.349534
global_step: 1833, epoch: 46, loss: 0.435847
global_step: 1834, epoch: 46, loss: 0.306986
global_step: 1835, epoch: 46, loss: 0.410603
global_step: 1836, epoch: 46, loss: 0.401313
global_step: 1837, epoch: 46, loss: 0.338076
global_step: 1838, epoch: 46, loss: 0.351421
global_step: 1839, epoch: 46, loss: 0.270563
global_step: 1840, epoch: 46, loss: 0.502286
epoch: 46
train	acc: 0.9543	macro: p 0.9531, r 0.9363, f1: 0.9440	micro: p 0.9543, r 0.9543, f1 0.9543	weighted_f1:0.9545
dev	acc: 0.5311	macro: p 0.4550, r 0.3323, f1: 0.3418	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4984
test	acc: 0.5613	macro: p 0.3650, r 0.3210, f1: 0.3233	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5341
global_step: 1841, epoch: 47, loss: 0.345447
global_step: 1842, epoch: 47, loss: 0.309718
global_step: 1843, epoch: 47, loss: 0.342847
global_step: 1844, epoch: 47, loss: 0.353392
global_step: 1845, epoch: 47, loss: 0.399097
global_step: 1846, epoch: 47, loss: 0.301560
global_step: 1847, epoch: 47, loss: 0.312059
global_step: 1848, epoch: 47, loss: 0.268230
global_step: 1849, epoch: 47, loss: 0.380674
global_step: 1850, epoch: 47, loss: 0.310522
global_step: 1851, epoch: 47, loss: 0.379538
global_step: 1852, epoch: 47, loss: 0.280019
global_step: 1853, epoch: 47, loss: 0.292678
global_step: 1854, epoch: 47, loss: 0.310138
global_step: 1855, epoch: 47, loss: 0.201986
global_step: 1856, epoch: 47, loss: 0.280652
global_step: 1857, epoch: 47, loss: 0.317401
global_step: 1858, epoch: 47, loss: 0.364025
global_step: 1859, epoch: 47, loss: 0.374064
global_step: 1860, epoch: 47, loss: 0.287678
global_step: 1861, epoch: 47, loss: 0.307195
global_step: 1862, epoch: 47, loss: 0.327156
global_step: 1863, epoch: 47, loss: 0.378670
global_step: 1864, epoch: 47, loss: 0.347506
global_step: 1865, epoch: 47, loss: 0.298690
global_step: 1866, epoch: 47, loss: 0.313451
global_step: 1867, epoch: 47, loss: 0.255990
global_step: 1868, epoch: 47, loss: 0.421917
global_step: 1869, epoch: 47, loss: 0.352769
global_step: 1870, epoch: 47, loss: 0.261392
global_step: 1871, epoch: 47, loss: 0.318899
global_step: 1872, epoch: 47, loss: 0.327797
global_step: 1873, epoch: 47, loss: 0.279992
global_step: 1874, epoch: 47, loss: 0.386183
global_step: 1875, epoch: 47, loss: 0.338393
global_step: 1876, epoch: 47, loss: 0.296047
global_step: 1877, epoch: 47, loss: 0.297212
global_step: 1878, epoch: 47, loss: 0.346165
global_step: 1879, epoch: 47, loss: 0.335242
global_step: 1880, epoch: 47, loss: 0.159991
epoch: 47
train	acc: 0.9600	macro: p 0.9649, r 0.9416, f1: 0.9525	micro: p 0.9600, r 0.9600, f1 0.9600	weighted_f1:0.9600
dev	acc: 0.5293	macro: p 0.4100, r 0.3373, f1: 0.3494	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.5004
test	acc: 0.5598	macro: p 0.3575, r 0.3183, f1: 0.3267	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.5355
New best model!
global_step: 1881, epoch: 48, loss: 0.304185
global_step: 1882, epoch: 48, loss: 0.292489
global_step: 1883, epoch: 48, loss: 0.359618
global_step: 1884, epoch: 48, loss: 0.321756
global_step: 1885, epoch: 48, loss: 0.317486
global_step: 1886, epoch: 48, loss: 0.299570
global_step: 1887, epoch: 48, loss: 0.322492
global_step: 1888, epoch: 48, loss: 0.221064
global_step: 1889, epoch: 48, loss: 0.292147
global_step: 1890, epoch: 48, loss: 0.377920
global_step: 1891, epoch: 48, loss: 0.318468
global_step: 1892, epoch: 48, loss: 0.283001
global_step: 1893, epoch: 48, loss: 0.346741
global_step: 1894, epoch: 48, loss: 0.330064
global_step: 1895, epoch: 48, loss: 0.337677
global_step: 1896, epoch: 48, loss: 0.347125
global_step: 1897, epoch: 48, loss: 0.278650
global_step: 1898, epoch: 48, loss: 0.300901
global_step: 1899, epoch: 48, loss: 0.292679
global_step: 1900, epoch: 48, loss: 0.238212
global_step: 1901, epoch: 48, loss: 0.321476
global_step: 1902, epoch: 48, loss: 0.281440
global_step: 1903, epoch: 48, loss: 0.381143
global_step: 1904, epoch: 48, loss: 0.413328
global_step: 1905, epoch: 48, loss: 0.408535
global_step: 1906, epoch: 48, loss: 0.341237
global_step: 1907, epoch: 48, loss: 0.305581
global_step: 1908, epoch: 48, loss: 0.420459
global_step: 1909, epoch: 48, loss: 0.312733
global_step: 1910, epoch: 48, loss: 0.306614
global_step: 1911, epoch: 48, loss: 0.327690
global_step: 1912, epoch: 48, loss: 0.342896
global_step: 1913, epoch: 48, loss: 0.331420
global_step: 1914, epoch: 48, loss: 0.378943
global_step: 1915, epoch: 48, loss: 0.344264
global_step: 1916, epoch: 48, loss: 0.280757
global_step: 1917, epoch: 48, loss: 0.221150
global_step: 1918, epoch: 48, loss: 0.296454
global_step: 1919, epoch: 48, loss: 0.270815
global_step: 1920, epoch: 48, loss: 0.012919
epoch: 48
train	acc: 0.9612	macro: p 0.9660, r 0.9417, f1: 0.9532	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9611
dev	acc: 0.5347	macro: p 0.4078, r 0.3226, f1: 0.3333	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4945
test	acc: 0.5766	macro: p 0.3843, r 0.3246, f1: 0.3345	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5440
global_step: 1921, epoch: 49, loss: 0.284940
global_step: 1922, epoch: 49, loss: 0.327136
global_step: 1923, epoch: 49, loss: 0.353370
global_step: 1924, epoch: 49, loss: 0.302078
global_step: 1925, epoch: 49, loss: 0.352119
global_step: 1926, epoch: 49, loss: 0.263785
global_step: 1927, epoch: 49, loss: 0.267083
global_step: 1928, epoch: 49, loss: 0.290316
global_step: 1929, epoch: 49, loss: 0.343745
global_step: 1930, epoch: 49, loss: 0.361903
global_step: 1931, epoch: 49, loss: 0.320153
global_step: 1932, epoch: 49, loss: 0.277459
global_step: 1933, epoch: 49, loss: 0.276101
global_step: 1934, epoch: 49, loss: 0.282592
global_step: 1935, epoch: 49, loss: 0.341039
global_step: 1936, epoch: 49, loss: 0.281999
global_step: 1937, epoch: 49, loss: 0.293393
global_step: 1938, epoch: 49, loss: 0.309371
global_step: 1939, epoch: 49, loss: 0.352534
global_step: 1940, epoch: 49, loss: 0.347332
global_step: 1941, epoch: 49, loss: 0.302082
global_step: 1942, epoch: 49, loss: 0.369700
global_step: 1943, epoch: 49, loss: 0.345411
global_step: 1944, epoch: 49, loss: 0.377168
global_step: 1945, epoch: 49, loss: 0.308924
global_step: 1946, epoch: 49, loss: 0.386409
global_step: 1947, epoch: 49, loss: 0.315384
global_step: 1948, epoch: 49, loss: 0.291764
global_step: 1949, epoch: 49, loss: 0.433930
global_step: 1950, epoch: 49, loss: 0.319034
global_step: 1951, epoch: 49, loss: 0.316672
global_step: 1952, epoch: 49, loss: 0.301364
global_step: 1953, epoch: 49, loss: 0.341618
global_step: 1954, epoch: 49, loss: 0.405992
global_step: 1955, epoch: 49, loss: 0.340993
global_step: 1956, epoch: 49, loss: 0.362977
global_step: 1957, epoch: 49, loss: 0.320531
global_step: 1958, epoch: 49, loss: 0.355685
global_step: 1959, epoch: 49, loss: 0.271872
global_step: 1960, epoch: 49, loss: 0.140698
epoch: 49
train	acc: 0.9595	macro: p 0.9656, r 0.9377, f1: 0.9508	micro: p 0.9595, r 0.9595, f1 0.9595	weighted_f1:0.9594
dev	acc: 0.5284	macro: p 0.4339, r 0.3017, f1: 0.3137	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4751
test	acc: 0.5854	macro: p 0.4069, r 0.3137, f1: 0.3263	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5390
global_step: 1961, epoch: 50, loss: 0.313629
global_step: 1962, epoch: 50, loss: 0.353592
global_step: 1963, epoch: 50, loss: 0.277947
global_step: 1964, epoch: 50, loss: 0.304653
global_step: 1965, epoch: 50, loss: 0.355757
global_step: 1966, epoch: 50, loss: 0.403702
global_step: 1967, epoch: 50, loss: 0.377999
global_step: 1968, epoch: 50, loss: 0.332661
global_step: 1969, epoch: 50, loss: 0.438943
global_step: 1970, epoch: 50, loss: 0.323635
global_step: 1971, epoch: 50, loss: 0.329965
global_step: 1972, epoch: 50, loss: 0.356178
global_step: 1973, epoch: 50, loss: 0.365071
global_step: 1974, epoch: 50, loss: 0.290792
global_step: 1975, epoch: 50, loss: 0.334234
global_step: 1976, epoch: 50, loss: 0.310369
global_step: 1977, epoch: 50, loss: 0.277516
global_step: 1978, epoch: 50, loss: 0.253810
global_step: 1979, epoch: 50, loss: 0.344200
global_step: 1980, epoch: 50, loss: 0.301218
global_step: 1981, epoch: 50, loss: 0.373098
global_step: 1982, epoch: 50, loss: 0.323029
global_step: 1983, epoch: 50, loss: 0.266928
global_step: 1984, epoch: 50, loss: 0.298764
global_step: 1985, epoch: 50, loss: 0.383682
global_step: 1986, epoch: 50, loss: 0.427510
global_step: 1987, epoch: 50, loss: 0.301074
global_step: 1988, epoch: 50, loss: 0.325320
global_step: 1989, epoch: 50, loss: 0.237731
global_step: 1990, epoch: 50, loss: 0.368943
global_step: 1991, epoch: 50, loss: 0.320881
global_step: 1992, epoch: 50, loss: 0.215308
global_step: 1993, epoch: 50, loss: 0.341295
global_step: 1994, epoch: 50, loss: 0.285977
global_step: 1995, epoch: 50, loss: 0.267286
global_step: 1996, epoch: 50, loss: 0.371229
global_step: 1997, epoch: 50, loss: 0.348031
global_step: 1998, epoch: 50, loss: 0.305480
global_step: 1999, epoch: 50, loss: 0.320494
global_step: 2000, epoch: 50, loss: 0.219921
epoch: 50
train	acc: 0.9622	macro: p 0.9665, r 0.9460, f1: 0.9557	micro: p 0.9622, r 0.9622, f1 0.9622	weighted_f1:0.9622
dev	acc: 0.5284	macro: p 0.4325, r 0.3243, f1: 0.3401	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4935
test	acc: 0.5709	macro: p 0.3783, r 0.3231, f1: 0.3291	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5410
global_step: 2001, epoch: 51, loss: 0.299548
global_step: 2002, epoch: 51, loss: 0.218916
global_step: 2003, epoch: 51, loss: 0.398308
global_step: 2004, epoch: 51, loss: 0.287974
global_step: 2005, epoch: 51, loss: 0.348287
global_step: 2006, epoch: 51, loss: 0.301151
global_step: 2007, epoch: 51, loss: 0.368273
global_step: 2008, epoch: 51, loss: 0.313086
global_step: 2009, epoch: 51, loss: 0.299517
global_step: 2010, epoch: 51, loss: 0.243516
global_step: 2011, epoch: 51, loss: 0.297019
global_step: 2012, epoch: 51, loss: 0.286113
global_step: 2013, epoch: 51, loss: 0.253813
global_step: 2014, epoch: 51, loss: 0.432292
global_step: 2015, epoch: 51, loss: 0.439457
global_step: 2016, epoch: 51, loss: 0.304119
global_step: 2017, epoch: 51, loss: 0.351641
global_step: 2018, epoch: 51, loss: 0.273573
global_step: 2019, epoch: 51, loss: 0.292120
global_step: 2020, epoch: 51, loss: 0.324913
global_step: 2021, epoch: 51, loss: 0.245814
global_step: 2022, epoch: 51, loss: 0.238872
global_step: 2023, epoch: 51, loss: 0.269476
global_step: 2024, epoch: 51, loss: 0.324310
global_step: 2025, epoch: 51, loss: 0.324924
global_step: 2026, epoch: 51, loss: 0.316114
global_step: 2027, epoch: 51, loss: 0.261585
global_step: 2028, epoch: 51, loss: 0.292564
global_step: 2029, epoch: 51, loss: 0.358575
global_step: 2030, epoch: 51, loss: 0.376088
global_step: 2031, epoch: 51, loss: 0.319318
global_step: 2032, epoch: 51, loss: 0.316783
global_step: 2033, epoch: 51, loss: 0.271905
global_step: 2034, epoch: 51, loss: 0.348620
global_step: 2035, epoch: 51, loss: 0.425271
global_step: 2036, epoch: 51, loss: 0.252669
global_step: 2037, epoch: 51, loss: 0.395698
global_step: 2038, epoch: 51, loss: 0.380456
global_step: 2039, epoch: 51, loss: 0.399134
global_step: 2040, epoch: 51, loss: 0.272624
epoch: 51
train	acc: 0.9552	macro: p 0.9705, r 0.9303, f1: 0.9494	micro: p 0.9552, r 0.9552, f1 0.9552	weighted_f1:0.9549
dev	acc: 0.5212	macro: p 0.3535, r 0.2801, f1: 0.2846	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4671
test	acc: 0.5805	macro: p 0.4120, r 0.3068, f1: 0.3186	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5366
global_step: 2041, epoch: 52, loss: 0.297739
global_step: 2042, epoch: 52, loss: 0.257575
global_step: 2043, epoch: 52, loss: 0.311035
global_step: 2044, epoch: 52, loss: 0.275106
global_step: 2045, epoch: 52, loss: 0.318482
global_step: 2046, epoch: 52, loss: 0.290910
global_step: 2047, epoch: 52, loss: 0.353380
global_step: 2048, epoch: 52, loss: 0.311021
global_step: 2049, epoch: 52, loss: 0.394785
global_step: 2050, epoch: 52, loss: 0.213563
global_step: 2051, epoch: 52, loss: 0.267693
global_step: 2052, epoch: 52, loss: 0.273503
global_step: 2053, epoch: 52, loss: 0.303800
global_step: 2054, epoch: 52, loss: 0.206794
global_step: 2055, epoch: 52, loss: 0.321215
global_step: 2056, epoch: 52, loss: 0.341223
global_step: 2057, epoch: 52, loss: 0.318551
global_step: 2058, epoch: 52, loss: 0.323666
global_step: 2059, epoch: 52, loss: 0.454149
global_step: 2060, epoch: 52, loss: 0.317109
global_step: 2061, epoch: 52, loss: 0.278277
global_step: 2062, epoch: 52, loss: 0.271931
global_step: 2063, epoch: 52, loss: 0.361723
global_step: 2064, epoch: 52, loss: 0.333529
global_step: 2065, epoch: 52, loss: 0.291241
global_step: 2066, epoch: 52, loss: 0.342422
global_step: 2067, epoch: 52, loss: 0.406409
global_step: 2068, epoch: 52, loss: 0.269290
global_step: 2069, epoch: 52, loss: 0.317073
global_step: 2070, epoch: 52, loss: 0.363859
global_step: 2071, epoch: 52, loss: 0.366494
global_step: 2072, epoch: 52, loss: 0.287097
global_step: 2073, epoch: 52, loss: 0.313378
global_step: 2074, epoch: 52, loss: 0.327557
global_step: 2075, epoch: 52, loss: 0.298698
global_step: 2076, epoch: 52, loss: 0.397492
global_step: 2077, epoch: 52, loss: 0.308019
global_step: 2078, epoch: 52, loss: 0.249174
global_step: 2079, epoch: 52, loss: 0.363863
global_step: 2080, epoch: 52, loss: 0.207211
epoch: 52
train	acc: 0.9618	macro: p 0.9660, r 0.9412, f1: 0.9530	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9617
dev	acc: 0.5338	macro: p 0.3897, r 0.3119, f1: 0.3218	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4966
test	acc: 0.5682	macro: p 0.3463, r 0.3112, f1: 0.3173	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5399
global_step: 2081, epoch: 53, loss: 0.353588
global_step: 2082, epoch: 53, loss: 0.360219
global_step: 2083, epoch: 53, loss: 0.230268
global_step: 2084, epoch: 53, loss: 0.266475
global_step: 2085, epoch: 53, loss: 0.339900
global_step: 2086, epoch: 53, loss: 0.359225
global_step: 2087, epoch: 53, loss: 0.372736
global_step: 2088, epoch: 53, loss: 0.336784
global_step: 2089, epoch: 53, loss: 0.290584
global_step: 2090, epoch: 53, loss: 0.317611
global_step: 2091, epoch: 53, loss: 0.429389
global_step: 2092, epoch: 53, loss: 0.337222
global_step: 2093, epoch: 53, loss: 0.278157
global_step: 2094, epoch: 53, loss: 0.270212
global_step: 2095, epoch: 53, loss: 0.272744
global_step: 2096, epoch: 53, loss: 0.377037
global_step: 2097, epoch: 53, loss: 0.359663
global_step: 2098, epoch: 53, loss: 0.319270
global_step: 2099, epoch: 53, loss: 0.358916
global_step: 2100, epoch: 53, loss: 0.298187
global_step: 2101, epoch: 53, loss: 0.349796
global_step: 2102, epoch: 53, loss: 0.267518
global_step: 2103, epoch: 53, loss: 0.345069
global_step: 2104, epoch: 53, loss: 0.353148
global_step: 2105, epoch: 53, loss: 0.356478
global_step: 2106, epoch: 53, loss: 0.337753
global_step: 2107, epoch: 53, loss: 0.326042
global_step: 2108, epoch: 53, loss: 0.318187
global_step: 2109, epoch: 53, loss: 0.277839
global_step: 2110, epoch: 53, loss: 0.263785
global_step: 2111, epoch: 53, loss: 0.259821
global_step: 2112, epoch: 53, loss: 0.387680
global_step: 2113, epoch: 53, loss: 0.278131
global_step: 2114, epoch: 53, loss: 0.311521
global_step: 2115, epoch: 53, loss: 0.311435
global_step: 2116, epoch: 53, loss: 0.373824
global_step: 2117, epoch: 53, loss: 0.359559
global_step: 2118, epoch: 53, loss: 0.385830
global_step: 2119, epoch: 53, loss: 0.337161
global_step: 2120, epoch: 53, loss: 0.496291
epoch: 53
train	acc: 0.9614	macro: p 0.9672, r 0.9427, f1: 0.9543	micro: p 0.9614, r 0.9614, f1 0.9614	weighted_f1:0.9614
dev	acc: 0.5311	macro: p 0.4036, r 0.3078, f1: 0.3158	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4857
test	acc: 0.5797	macro: p 0.4012, r 0.3162, f1: 0.3257	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5419
global_step: 2121, epoch: 54, loss: 0.360432
global_step: 2122, epoch: 54, loss: 0.280023
global_step: 2123, epoch: 54, loss: 0.270607
global_step: 2124, epoch: 54, loss: 0.283419
global_step: 2125, epoch: 54, loss: 0.314152
global_step: 2126, epoch: 54, loss: 0.349515
global_step: 2127, epoch: 54, loss: 0.303983
global_step: 2128, epoch: 54, loss: 0.321839
global_step: 2129, epoch: 54, loss: 0.259909
global_step: 2130, epoch: 54, loss: 0.294645
global_step: 2131, epoch: 54, loss: 0.254883
global_step: 2132, epoch: 54, loss: 0.287664
global_step: 2133, epoch: 54, loss: 0.352205
global_step: 2134, epoch: 54, loss: 0.331207
global_step: 2135, epoch: 54, loss: 0.273245
global_step: 2136, epoch: 54, loss: 0.316993
global_step: 2137, epoch: 54, loss: 0.285935
global_step: 2138, epoch: 54, loss: 0.311353
global_step: 2139, epoch: 54, loss: 0.320531
global_step: 2140, epoch: 54, loss: 0.401151
global_step: 2141, epoch: 54, loss: 0.359886
global_step: 2142, epoch: 54, loss: 0.320818
global_step: 2143, epoch: 54, loss: 0.366730
global_step: 2144, epoch: 54, loss: 0.323592
global_step: 2145, epoch: 54, loss: 0.298040
global_step: 2146, epoch: 54, loss: 0.313910
global_step: 2147, epoch: 54, loss: 0.222584
global_step: 2148, epoch: 54, loss: 0.267780
global_step: 2149, epoch: 54, loss: 0.221748
global_step: 2150, epoch: 54, loss: 0.289850
global_step: 2151, epoch: 54, loss: 0.309871
global_step: 2152, epoch: 54, loss: 0.231652
global_step: 2153, epoch: 54, loss: 0.303381
global_step: 2154, epoch: 54, loss: 0.273349
global_step: 2155, epoch: 54, loss: 0.289824
global_step: 2156, epoch: 54, loss: 0.341889
global_step: 2157, epoch: 54, loss: 0.361416
global_step: 2158, epoch: 54, loss: 0.280420
global_step: 2159, epoch: 54, loss: 0.284258
global_step: 2160, epoch: 54, loss: 0.404022
epoch: 54
train	acc: 0.9586	macro: p 0.9671, r 0.9413, f1: 0.9535	micro: p 0.9586, r 0.9586, f1 0.9586	weighted_f1:0.9586
dev	acc: 0.5194	macro: p 0.4108, r 0.3123, f1: 0.3199	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4813
test	acc: 0.5605	macro: p 0.3663, r 0.3121, f1: 0.3189	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5319
global_step: 2161, epoch: 55, loss: 0.363655
global_step: 2162, epoch: 55, loss: 0.344161
global_step: 2163, epoch: 55, loss: 0.304023
global_step: 2164, epoch: 55, loss: 0.321753
global_step: 2165, epoch: 55, loss: 0.261303
global_step: 2166, epoch: 55, loss: 0.251524
global_step: 2167, epoch: 55, loss: 0.357216
global_step: 2168, epoch: 55, loss: 0.381345
global_step: 2169, epoch: 55, loss: 0.286545
global_step: 2170, epoch: 55, loss: 0.338435
global_step: 2171, epoch: 55, loss: 0.289560
global_step: 2172, epoch: 55, loss: 0.303162
global_step: 2173, epoch: 55, loss: 0.226329
global_step: 2174, epoch: 55, loss: 0.279059
global_step: 2175, epoch: 55, loss: 0.268986
global_step: 2176, epoch: 55, loss: 0.283313
global_step: 2177, epoch: 55, loss: 0.247934
global_step: 2178, epoch: 55, loss: 0.335114
global_step: 2179, epoch: 55, loss: 0.328701
global_step: 2180, epoch: 55, loss: 0.399944
global_step: 2181, epoch: 55, loss: 0.300236
global_step: 2182, epoch: 55, loss: 0.244884
global_step: 2183, epoch: 55, loss: 0.363371
global_step: 2184, epoch: 55, loss: 0.314957
global_step: 2185, epoch: 55, loss: 0.279427
global_step: 2186, epoch: 55, loss: 0.353435
global_step: 2187, epoch: 55, loss: 0.306330
global_step: 2188, epoch: 55, loss: 0.289459
global_step: 2189, epoch: 55, loss: 0.356637
global_step: 2190, epoch: 55, loss: 0.334675
global_step: 2191, epoch: 55, loss: 0.311192
global_step: 2192, epoch: 55, loss: 0.292543
global_step: 2193, epoch: 55, loss: 0.344075
global_step: 2194, epoch: 55, loss: 0.307020
global_step: 2195, epoch: 55, loss: 0.378902
global_step: 2196, epoch: 55, loss: 0.407824
global_step: 2197, epoch: 55, loss: 0.326739
global_step: 2198, epoch: 55, loss: 0.243512
global_step: 2199, epoch: 55, loss: 0.251482
global_step: 2200, epoch: 55, loss: 0.075320
epoch: 55
train	acc: 0.9599	macro: p 0.9702, r 0.9387, f1: 0.9537	micro: p 0.9599, r 0.9599, f1 0.9599	weighted_f1:0.9598
dev	acc: 0.5356	macro: p 0.4226, r 0.3120, f1: 0.3227	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4881
test	acc: 0.5858	macro: p 0.4026, r 0.3209, f1: 0.3340	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5469
global_step: 2201, epoch: 56, loss: 0.325450
global_step: 2202, epoch: 56, loss: 0.259617
global_step: 2203, epoch: 56, loss: 0.249430
global_step: 2204, epoch: 56, loss: 0.341183
global_step: 2205, epoch: 56, loss: 0.230899
global_step: 2206, epoch: 56, loss: 0.273392
global_step: 2207, epoch: 56, loss: 0.268247
global_step: 2208, epoch: 56, loss: 0.228115
global_step: 2209, epoch: 56, loss: 0.329646
global_step: 2210, epoch: 56, loss: 0.273033
global_step: 2211, epoch: 56, loss: 0.271071
global_step: 2212, epoch: 56, loss: 0.305065
global_step: 2213, epoch: 56, loss: 0.277065
global_step: 2214, epoch: 56, loss: 0.276828
global_step: 2215, epoch: 56, loss: 0.272892
global_step: 2216, epoch: 56, loss: 0.299438
global_step: 2217, epoch: 56, loss: 0.338138
global_step: 2218, epoch: 56, loss: 0.308396
global_step: 2219, epoch: 56, loss: 0.238319
global_step: 2220, epoch: 56, loss: 0.265131
global_step: 2221, epoch: 56, loss: 0.227921
global_step: 2222, epoch: 56, loss: 0.307618
global_step: 2223, epoch: 56, loss: 0.226831
global_step: 2224, epoch: 56, loss: 0.331337
global_step: 2225, epoch: 56, loss: 0.308582
global_step: 2226, epoch: 56, loss: 0.291540
global_step: 2227, epoch: 56, loss: 0.296981
global_step: 2228, epoch: 56, loss: 0.290058
global_step: 2229, epoch: 56, loss: 0.351097
global_step: 2230, epoch: 56, loss: 0.353271
global_step: 2231, epoch: 56, loss: 0.270290
global_step: 2232, epoch: 56, loss: 0.327018
global_step: 2233, epoch: 56, loss: 0.320307
global_step: 2234, epoch: 56, loss: 0.311699
global_step: 2235, epoch: 56, loss: 0.266431
global_step: 2236, epoch: 56, loss: 0.368422
global_step: 2237, epoch: 56, loss: 0.311590
global_step: 2238, epoch: 56, loss: 0.298438
global_step: 2239, epoch: 56, loss: 0.317788
global_step: 2240, epoch: 56, loss: 0.655777
epoch: 56
train	acc: 0.9639	macro: p 0.9688, r 0.9489, f1: 0.9584	micro: p 0.9639, r 0.9639, f1 0.9639	weighted_f1:0.9639
dev	acc: 0.5302	macro: p 0.3822, r 0.3141, f1: 0.3234	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4914
test	acc: 0.5805	macro: p 0.3796, r 0.3239, f1: 0.3341	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5488
global_step: 2241, epoch: 57, loss: 0.277652
global_step: 2242, epoch: 57, loss: 0.290449
global_step: 2243, epoch: 57, loss: 0.338077
global_step: 2244, epoch: 57, loss: 0.383653
global_step: 2245, epoch: 57, loss: 0.206403
global_step: 2246, epoch: 57, loss: 0.182903
global_step: 2247, epoch: 57, loss: 0.311633
global_step: 2248, epoch: 57, loss: 0.258493
global_step: 2249, epoch: 57, loss: 0.315534
global_step: 2250, epoch: 57, loss: 0.326897
global_step: 2251, epoch: 57, loss: 0.262675
global_step: 2252, epoch: 57, loss: 0.296689
global_step: 2253, epoch: 57, loss: 0.280794
global_step: 2254, epoch: 57, loss: 0.342756
global_step: 2255, epoch: 57, loss: 0.261008
global_step: 2256, epoch: 57, loss: 0.293245
global_step: 2257, epoch: 57, loss: 0.341850
global_step: 2258, epoch: 57, loss: 0.274244
global_step: 2259, epoch: 57, loss: 0.297652
global_step: 2260, epoch: 57, loss: 0.264377
global_step: 2261, epoch: 57, loss: 0.283272
global_step: 2262, epoch: 57, loss: 0.272541
global_step: 2263, epoch: 57, loss: 0.274747
global_step: 2264, epoch: 57, loss: 0.315471
global_step: 2265, epoch: 57, loss: 0.437958
global_step: 2266, epoch: 57, loss: 0.360778
global_step: 2267, epoch: 57, loss: 0.324846
global_step: 2268, epoch: 57, loss: 0.258564
global_step: 2269, epoch: 57, loss: 0.291861
global_step: 2270, epoch: 57, loss: 0.298201
global_step: 2271, epoch: 57, loss: 0.284080
global_step: 2272, epoch: 57, loss: 0.373252
global_step: 2273, epoch: 57, loss: 0.296171
global_step: 2274, epoch: 57, loss: 0.309140
global_step: 2275, epoch: 57, loss: 0.370426
global_step: 2276, epoch: 57, loss: 0.363191
global_step: 2277, epoch: 57, loss: 0.380660
global_step: 2278, epoch: 57, loss: 0.361216
global_step: 2279, epoch: 57, loss: 0.247538
global_step: 2280, epoch: 57, loss: 0.019482
epoch: 57
train	acc: 0.9634	macro: p 0.9682, r 0.9481, f1: 0.9577	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9634
dev	acc: 0.5176	macro: p 0.3893, r 0.3118, f1: 0.3175	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4857
test	acc: 0.5613	macro: p 0.3574, r 0.3178, f1: 0.3216	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5366
global_step: 2281, epoch: 58, loss: 0.297913
global_step: 2282, epoch: 58, loss: 0.281968
global_step: 2283, epoch: 58, loss: 0.239630
global_step: 2284, epoch: 58, loss: 0.268638
global_step: 2285, epoch: 58, loss: 0.282006
global_step: 2286, epoch: 58, loss: 0.348391
global_step: 2287, epoch: 58, loss: 0.244813
global_step: 2288, epoch: 58, loss: 0.299928
global_step: 2289, epoch: 58, loss: 0.345797
global_step: 2290, epoch: 58, loss: 0.223023
global_step: 2291, epoch: 58, loss: 0.271770
global_step: 2292, epoch: 58, loss: 0.321257
global_step: 2293, epoch: 58, loss: 0.359362
global_step: 2294, epoch: 58, loss: 0.273638
global_step: 2295, epoch: 58, loss: 0.261961
global_step: 2296, epoch: 58, loss: 0.237373
global_step: 2297, epoch: 58, loss: 0.266303
global_step: 2298, epoch: 58, loss: 0.274785
global_step: 2299, epoch: 58, loss: 0.269960
global_step: 2300, epoch: 58, loss: 0.256531
global_step: 2301, epoch: 58, loss: 0.271193
global_step: 2302, epoch: 58, loss: 0.364752
global_step: 2303, epoch: 58, loss: 0.335020
global_step: 2304, epoch: 58, loss: 0.229331
global_step: 2305, epoch: 58, loss: 0.341183
global_step: 2306, epoch: 58, loss: 0.249163
global_step: 2307, epoch: 58, loss: 0.280186
global_step: 2308, epoch: 58, loss: 0.362083
global_step: 2309, epoch: 58, loss: 0.314652
global_step: 2310, epoch: 58, loss: 0.293668
global_step: 2311, epoch: 58, loss: 0.304695
global_step: 2312, epoch: 58, loss: 0.343925
global_step: 2313, epoch: 58, loss: 0.337772
global_step: 2314, epoch: 58, loss: 0.283162
global_step: 2315, epoch: 58, loss: 0.299649
global_step: 2316, epoch: 58, loss: 0.305438
global_step: 2317, epoch: 58, loss: 0.326945
global_step: 2318, epoch: 58, loss: 0.349173
global_step: 2319, epoch: 58, loss: 0.307432
global_step: 2320, epoch: 58, loss: 0.037927
epoch: 58
train	acc: 0.9611	macro: p 0.9695, r 0.9427, f1: 0.9555	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9610
dev	acc: 0.5401	macro: p 0.3775, r 0.3062, f1: 0.3164	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4943
test	acc: 0.5835	macro: p 0.3715, r 0.3117, f1: 0.3242	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5435
global_step: 2321, epoch: 59, loss: 0.193743
global_step: 2322, epoch: 59, loss: 0.326507
global_step: 2323, epoch: 59, loss: 0.323900
global_step: 2324, epoch: 59, loss: 0.303212
global_step: 2325, epoch: 59, loss: 0.226552
global_step: 2326, epoch: 59, loss: 0.315763
global_step: 2327, epoch: 59, loss: 0.318908
global_step: 2328, epoch: 59, loss: 0.259828
global_step: 2329, epoch: 59, loss: 0.206892
global_step: 2330, epoch: 59, loss: 0.222834
global_step: 2331, epoch: 59, loss: 0.292929
global_step: 2332, epoch: 59, loss: 0.269455
global_step: 2333, epoch: 59, loss: 0.274988
global_step: 2334, epoch: 59, loss: 0.258314
global_step: 2335, epoch: 59, loss: 0.268066
global_step: 2336, epoch: 59, loss: 0.307421
global_step: 2337, epoch: 59, loss: 0.359801
global_step: 2338, epoch: 59, loss: 0.282634
global_step: 2339, epoch: 59, loss: 0.240418
global_step: 2340, epoch: 59, loss: 0.271232
global_step: 2341, epoch: 59, loss: 0.299322
global_step: 2342, epoch: 59, loss: 0.201495
global_step: 2343, epoch: 59, loss: 0.336710
global_step: 2344, epoch: 59, loss: 0.291939
global_step: 2345, epoch: 59, loss: 0.326208
global_step: 2346, epoch: 59, loss: 0.282529
global_step: 2347, epoch: 59, loss: 0.394861
global_step: 2348, epoch: 59, loss: 0.312023
global_step: 2349, epoch: 59, loss: 0.306967
global_step: 2350, epoch: 59, loss: 0.342684
global_step: 2351, epoch: 59, loss: 0.329538
global_step: 2352, epoch: 59, loss: 0.361595
global_step: 2353, epoch: 59, loss: 0.318943
global_step: 2354, epoch: 59, loss: 0.295746
global_step: 2355, epoch: 59, loss: 0.284741
global_step: 2356, epoch: 59, loss: 0.331305
global_step: 2357, epoch: 59, loss: 0.302657
global_step: 2358, epoch: 59, loss: 0.283391
global_step: 2359, epoch: 59, loss: 0.252447
global_step: 2360, epoch: 59, loss: 0.071625
epoch: 59
train	acc: 0.9610	macro: p 0.9706, r 0.9400, f1: 0.9546	micro: p 0.9610, r 0.9610, f1 0.9610	weighted_f1:0.9608
dev	acc: 0.5293	macro: p 0.4406, r 0.3046, f1: 0.3175	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4831
test	acc: 0.5766	macro: p 0.3857, r 0.3086, f1: 0.3198	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5364
global_step: 2361, epoch: 60, loss: 0.230927
global_step: 2362, epoch: 60, loss: 0.364099
global_step: 2363, epoch: 60, loss: 0.287890
global_step: 2364, epoch: 60, loss: 0.317093
global_step: 2365, epoch: 60, loss: 0.266360
global_step: 2366, epoch: 60, loss: 0.179447
global_step: 2367, epoch: 60, loss: 0.278609
global_step: 2368, epoch: 60, loss: 0.321325
global_step: 2369, epoch: 60, loss: 0.325760
global_step: 2370, epoch: 60, loss: 0.231046
global_step: 2371, epoch: 60, loss: 0.221241
global_step: 2372, epoch: 60, loss: 0.272736
global_step: 2373, epoch: 60, loss: 0.254430
global_step: 2374, epoch: 60, loss: 0.368063
global_step: 2375, epoch: 60, loss: 0.274076
global_step: 2376, epoch: 60, loss: 0.222448
global_step: 2377, epoch: 60, loss: 0.342124
global_step: 2378, epoch: 60, loss: 0.243384
global_step: 2379, epoch: 60, loss: 0.312868
global_step: 2380, epoch: 60, loss: 0.308695
global_step: 2381, epoch: 60, loss: 0.334411
global_step: 2382, epoch: 60, loss: 0.219514
global_step: 2383, epoch: 60, loss: 0.295675
global_step: 2384, epoch: 60, loss: 0.297229
global_step: 2385, epoch: 60, loss: 0.270145
global_step: 2386, epoch: 60, loss: 0.341374
global_step: 2387, epoch: 60, loss: 0.276467
global_step: 2388, epoch: 60, loss: 0.245703
global_step: 2389, epoch: 60, loss: 0.286860
global_step: 2390, epoch: 60, loss: 0.298562
global_step: 2391, epoch: 60, loss: 0.275510
global_step: 2392, epoch: 60, loss: 0.323620
global_step: 2393, epoch: 60, loss: 0.288907
global_step: 2394, epoch: 60, loss: 0.398163
global_step: 2395, epoch: 60, loss: 0.311355
global_step: 2396, epoch: 60, loss: 0.229554
global_step: 2397, epoch: 60, loss: 0.273010
global_step: 2398, epoch: 60, loss: 0.378705
global_step: 2399, epoch: 60, loss: 0.236495
global_step: 2400, epoch: 60, loss: 0.250353
epoch: 60
train	acc: 0.9624	macro: p 0.9699, r 0.9393, f1: 0.9536	micro: p 0.9624, r 0.9624, f1 0.9624	weighted_f1:0.9623
dev	acc: 0.5239	macro: p 0.3958, r 0.3025, f1: 0.3081	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4821
test	acc: 0.5739	macro: p 0.3778, r 0.3196, f1: 0.3249	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5407
global_step: 2401, epoch: 61, loss: 0.238212
global_step: 2402, epoch: 61, loss: 0.267037
global_step: 2403, epoch: 61, loss: 0.226497
global_step: 2404, epoch: 61, loss: 0.264692
global_step: 2405, epoch: 61, loss: 0.275213
global_step: 2406, epoch: 61, loss: 0.284053
global_step: 2407, epoch: 61, loss: 0.306820
global_step: 2408, epoch: 61, loss: 0.298201
global_step: 2409, epoch: 61, loss: 0.318813
global_step: 2410, epoch: 61, loss: 0.284860
global_step: 2411, epoch: 61, loss: 0.312036
global_step: 2412, epoch: 61, loss: 0.252948
global_step: 2413, epoch: 61, loss: 0.238183
global_step: 2414, epoch: 61, loss: 0.261261
global_step: 2415, epoch: 61, loss: 0.304526
global_step: 2416, epoch: 61, loss: 0.247115
global_step: 2417, epoch: 61, loss: 0.312351
global_step: 2418, epoch: 61, loss: 0.311420
global_step: 2419, epoch: 61, loss: 0.269473
global_step: 2420, epoch: 61, loss: 0.358559
global_step: 2421, epoch: 61, loss: 0.277757
global_step: 2422, epoch: 61, loss: 0.329714
global_step: 2423, epoch: 61, loss: 0.269340
global_step: 2424, epoch: 61, loss: 0.234013
global_step: 2425, epoch: 61, loss: 0.291848
global_step: 2426, epoch: 61, loss: 0.293931
global_step: 2427, epoch: 61, loss: 0.355132
global_step: 2428, epoch: 61, loss: 0.303264
global_step: 2429, epoch: 61, loss: 0.365046
global_step: 2430, epoch: 61, loss: 0.327066
global_step: 2431, epoch: 61, loss: 0.309625
global_step: 2432, epoch: 61, loss: 0.240129
global_step: 2433, epoch: 61, loss: 0.371760
global_step: 2434, epoch: 61, loss: 0.300317
global_step: 2435, epoch: 61, loss: 0.315729
global_step: 2436, epoch: 61, loss: 0.267742
global_step: 2437, epoch: 61, loss: 0.315645
global_step: 2438, epoch: 61, loss: 0.286219
global_step: 2439, epoch: 61, loss: 0.465979
global_step: 2440, epoch: 61, loss: 0.001809
epoch: 61
train	acc: 0.9660	macro: p 0.9706, r 0.9510, f1: 0.9603	micro: p 0.9660, r 0.9660, f1 0.9660	weighted_f1:0.9660
dev	acc: 0.5086	macro: p 0.3498, r 0.2955, f1: 0.2973	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4692
test	acc: 0.5648	macro: p 0.3592, r 0.3170, f1: 0.3227	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5335
global_step: 2441, epoch: 62, loss: 0.304676
global_step: 2442, epoch: 62, loss: 0.204187
global_step: 2443, epoch: 62, loss: 0.231146
global_step: 2444, epoch: 62, loss: 0.275341
global_step: 2445, epoch: 62, loss: 0.225058
global_step: 2446, epoch: 62, loss: 0.352122
global_step: 2447, epoch: 62, loss: 0.321568
global_step: 2448, epoch: 62, loss: 0.291243
global_step: 2449, epoch: 62, loss: 0.229265
global_step: 2450, epoch: 62, loss: 0.218482
global_step: 2451, epoch: 62, loss: 0.183874
global_step: 2452, epoch: 62, loss: 0.270984
global_step: 2453, epoch: 62, loss: 0.311930
global_step: 2454, epoch: 62, loss: 0.371085
global_step: 2455, epoch: 62, loss: 0.299682
global_step: 2456, epoch: 62, loss: 0.323449
global_step: 2457, epoch: 62, loss: 0.158931
global_step: 2458, epoch: 62, loss: 0.320244
global_step: 2459, epoch: 62, loss: 0.309994
global_step: 2460, epoch: 62, loss: 0.292667
global_step: 2461, epoch: 62, loss: 0.363447
global_step: 2462, epoch: 62, loss: 0.296001
global_step: 2463, epoch: 62, loss: 0.256618
global_step: 2464, epoch: 62, loss: 0.303338
global_step: 2465, epoch: 62, loss: 0.261828
global_step: 2466, epoch: 62, loss: 0.228895
global_step: 2467, epoch: 62, loss: 0.262747
global_step: 2468, epoch: 62, loss: 0.271084
global_step: 2469, epoch: 62, loss: 0.264227
global_step: 2470, epoch: 62, loss: 0.300625
global_step: 2471, epoch: 62, loss: 0.237272
global_step: 2472, epoch: 62, loss: 0.329953
global_step: 2473, epoch: 62, loss: 0.296566
global_step: 2474, epoch: 62, loss: 0.286513
global_step: 2475, epoch: 62, loss: 0.263834
global_step: 2476, epoch: 62, loss: 0.276362
global_step: 2477, epoch: 62, loss: 0.326723
global_step: 2478, epoch: 62, loss: 0.261111
global_step: 2479, epoch: 62, loss: 0.227187
global_step: 2480, epoch: 62, loss: 1.218987
epoch: 62
train	acc: 0.9619	macro: p 0.9736, r 0.9402, f1: 0.9561	micro: p 0.9619, r 0.9619, f1 0.9619	weighted_f1:0.9616
dev	acc: 0.5212	macro: p 0.4024, r 0.2888, f1: 0.3021	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4681
test	acc: 0.5843	macro: p 0.3903, r 0.3018, f1: 0.3168	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5377
global_step: 2481, epoch: 63, loss: 0.334669
global_step: 2482, epoch: 63, loss: 0.322787
global_step: 2483, epoch: 63, loss: 0.255253
global_step: 2484, epoch: 63, loss: 0.211565
global_step: 2485, epoch: 63, loss: 0.284407
global_step: 2486, epoch: 63, loss: 0.249982
global_step: 2487, epoch: 63, loss: 0.294795
global_step: 2488, epoch: 63, loss: 0.240313
global_step: 2489, epoch: 63, loss: 0.258417
global_step: 2490, epoch: 63, loss: 0.235126
global_step: 2491, epoch: 63, loss: 0.246168
global_step: 2492, epoch: 63, loss: 0.283409
global_step: 2493, epoch: 63, loss: 0.195375
global_step: 2494, epoch: 63, loss: 0.260858
global_step: 2495, epoch: 63, loss: 0.304072
global_step: 2496, epoch: 63, loss: 0.280017
global_step: 2497, epoch: 63, loss: 0.263836
global_step: 2498, epoch: 63, loss: 0.349881
global_step: 2499, epoch: 63, loss: 0.248028
global_step: 2500, epoch: 63, loss: 0.318087
global_step: 2501, epoch: 63, loss: 0.214893
global_step: 2502, epoch: 63, loss: 0.253664
global_step: 2503, epoch: 63, loss: 0.263418
global_step: 2504, epoch: 63, loss: 0.292084
global_step: 2505, epoch: 63, loss: 0.291197
global_step: 2506, epoch: 63, loss: 0.212639
global_step: 2507, epoch: 63, loss: 0.329111
global_step: 2508, epoch: 63, loss: 0.383210
global_step: 2509, epoch: 63, loss: 0.276135
global_step: 2510, epoch: 63, loss: 0.237975
global_step: 2511, epoch: 63, loss: 0.275861
global_step: 2512, epoch: 63, loss: 0.340004
global_step: 2513, epoch: 63, loss: 0.344680
global_step: 2514, epoch: 63, loss: 0.278261
global_step: 2515, epoch: 63, loss: 0.310629
global_step: 2516, epoch: 63, loss: 0.306858
global_step: 2517, epoch: 63, loss: 0.346628
global_step: 2518, epoch: 63, loss: 0.319986
global_step: 2519, epoch: 63, loss: 0.248871
global_step: 2520, epoch: 63, loss: 0.107201
epoch: 63
train	acc: 0.9629	macro: p 0.9702, r 0.9468, f1: 0.9578	micro: p 0.9629, r 0.9629, f1 0.9629	weighted_f1:0.9629
dev	acc: 0.5221	macro: p 0.4060, r 0.3093, f1: 0.3186	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4810
test	acc: 0.5648	macro: p 0.3580, r 0.3115, f1: 0.3167	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5309
global_step: 2521, epoch: 64, loss: 0.296789
global_step: 2522, epoch: 64, loss: 0.234025
global_step: 2523, epoch: 64, loss: 0.198325
global_step: 2524, epoch: 64, loss: 0.297348
global_step: 2525, epoch: 64, loss: 0.272683
global_step: 2526, epoch: 64, loss: 0.216176
global_step: 2527, epoch: 64, loss: 0.230468
global_step: 2528, epoch: 64, loss: 0.339038
global_step: 2529, epoch: 64, loss: 0.289387
global_step: 2530, epoch: 64, loss: 0.295430
global_step: 2531, epoch: 64, loss: 0.297990
global_step: 2532, epoch: 64, loss: 0.235438
global_step: 2533, epoch: 64, loss: 0.224191
global_step: 2534, epoch: 64, loss: 0.267193
global_step: 2535, epoch: 64, loss: 0.295384
global_step: 2536, epoch: 64, loss: 0.269937
global_step: 2537, epoch: 64, loss: 0.268063
global_step: 2538, epoch: 64, loss: 0.283101
global_step: 2539, epoch: 64, loss: 0.253741
global_step: 2540, epoch: 64, loss: 0.303911
global_step: 2541, epoch: 64, loss: 0.277934
global_step: 2542, epoch: 64, loss: 0.271665
global_step: 2543, epoch: 64, loss: 0.288049
global_step: 2544, epoch: 64, loss: 0.290531
global_step: 2545, epoch: 64, loss: 0.254045
global_step: 2546, epoch: 64, loss: 0.337947
global_step: 2547, epoch: 64, loss: 0.312291
global_step: 2548, epoch: 64, loss: 0.290377
global_step: 2549, epoch: 64, loss: 0.329686
global_step: 2550, epoch: 64, loss: 0.226360
global_step: 2551, epoch: 64, loss: 0.239588
global_step: 2552, epoch: 64, loss: 0.353164
global_step: 2553, epoch: 64, loss: 0.203129
global_step: 2554, epoch: 64, loss: 0.280501
global_step: 2555, epoch: 64, loss: 0.324177
global_step: 2556, epoch: 64, loss: 0.209246
global_step: 2557, epoch: 64, loss: 0.265485
global_step: 2558, epoch: 64, loss: 0.305561
global_step: 2559, epoch: 64, loss: 0.178951
global_step: 2560, epoch: 64, loss: 0.196141
epoch: 64
train	acc: 0.9625	macro: p 0.9721, r 0.9456, f1: 0.9582	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9624
dev	acc: 0.5194	macro: p 0.3752, r 0.2960, f1: 0.2979	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4694
test	acc: 0.5613	macro: p 0.3514, r 0.2995, f1: 0.3014	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5193
global_step: 2561, epoch: 65, loss: 0.205287
global_step: 2562, epoch: 65, loss: 0.291786
global_step: 2563, epoch: 65, loss: 0.270216
global_step: 2564, epoch: 65, loss: 0.277510
global_step: 2565, epoch: 65, loss: 0.252401
global_step: 2566, epoch: 65, loss: 0.153731
global_step: 2567, epoch: 65, loss: 0.261687
global_step: 2568, epoch: 65, loss: 0.229108
global_step: 2569, epoch: 65, loss: 0.252592
global_step: 2570, epoch: 65, loss: 0.170307
global_step: 2571, epoch: 65, loss: 0.287594
global_step: 2572, epoch: 65, loss: 0.335910
global_step: 2573, epoch: 65, loss: 0.294702
global_step: 2574, epoch: 65, loss: 0.267375
global_step: 2575, epoch: 65, loss: 0.281551
global_step: 2576, epoch: 65, loss: 0.254127
global_step: 2577, epoch: 65, loss: 0.230956
global_step: 2578, epoch: 65, loss: 0.257292
global_step: 2579, epoch: 65, loss: 0.205119
global_step: 2580, epoch: 65, loss: 0.201035
global_step: 2581, epoch: 65, loss: 0.416867
global_step: 2582, epoch: 65, loss: 0.299107
global_step: 2583, epoch: 65, loss: 0.301026
global_step: 2584, epoch: 65, loss: 0.294486
global_step: 2585, epoch: 65, loss: 0.275232
global_step: 2586, epoch: 65, loss: 0.268747
global_step: 2587, epoch: 65, loss: 0.323001
global_step: 2588, epoch: 65, loss: 0.217388
global_step: 2589, epoch: 65, loss: 0.252209
global_step: 2590, epoch: 65, loss: 0.344856
global_step: 2591, epoch: 65, loss: 0.282779
global_step: 2592, epoch: 65, loss: 0.207980
global_step: 2593, epoch: 65, loss: 0.298672
global_step: 2594, epoch: 65, loss: 0.266330
global_step: 2595, epoch: 65, loss: 0.385673
global_step: 2596, epoch: 65, loss: 0.275924
global_step: 2597, epoch: 65, loss: 0.261352
global_step: 2598, epoch: 65, loss: 0.173738
global_step: 2599, epoch: 65, loss: 0.262567
global_step: 2600, epoch: 65, loss: 0.359220
epoch: 65
train	acc: 0.9623	macro: p 0.9739, r 0.9409, f1: 0.9567	micro: p 0.9623, r 0.9623, f1 0.9623	weighted_f1:0.9621
dev	acc: 0.5284	macro: p 0.3877, r 0.2931, f1: 0.3003	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4747
test	acc: 0.5866	macro: p 0.3806, r 0.3105, f1: 0.3191	micro: p 0.5866, r 0.5866, f1 0.5866	weighted_f1:0.5423
global_step: 2601, epoch: 66, loss: 0.350216
global_step: 2602, epoch: 66, loss: 0.243493
global_step: 2603, epoch: 66, loss: 0.212674
global_step: 2604, epoch: 66, loss: 0.214746
global_step: 2605, epoch: 66, loss: 0.226689
global_step: 2606, epoch: 66, loss: 0.291717
global_step: 2607, epoch: 66, loss: 0.234886
global_step: 2608, epoch: 66, loss: 0.200760
global_step: 2609, epoch: 66, loss: 0.223300
global_step: 2610, epoch: 66, loss: 0.230339
global_step: 2611, epoch: 66, loss: 0.253576
global_step: 2612, epoch: 66, loss: 0.274460
global_step: 2613, epoch: 66, loss: 0.311330
global_step: 2614, epoch: 66, loss: 0.255678
global_step: 2615, epoch: 66, loss: 0.290968
global_step: 2616, epoch: 66, loss: 0.318550
global_step: 2617, epoch: 66, loss: 0.282380
global_step: 2618, epoch: 66, loss: 0.175456
global_step: 2619, epoch: 66, loss: 0.226017
global_step: 2620, epoch: 66, loss: 0.229130
global_step: 2621, epoch: 66, loss: 0.302460
global_step: 2622, epoch: 66, loss: 0.218719
global_step: 2623, epoch: 66, loss: 0.236095
global_step: 2624, epoch: 66, loss: 0.256039
global_step: 2625, epoch: 66, loss: 0.234045
global_step: 2626, epoch: 66, loss: 0.284244
global_step: 2627, epoch: 66, loss: 0.235717
global_step: 2628, epoch: 66, loss: 0.372907
global_step: 2629, epoch: 66, loss: 0.211698
global_step: 2630, epoch: 66, loss: 0.252123
global_step: 2631, epoch: 66, loss: 0.283613
global_step: 2632, epoch: 66, loss: 0.317893
global_step: 2633, epoch: 66, loss: 0.277131
global_step: 2634, epoch: 66, loss: 0.209206
global_step: 2635, epoch: 66, loss: 0.286277
global_step: 2636, epoch: 66, loss: 0.274212
global_step: 2637, epoch: 66, loss: 0.309083
global_step: 2638, epoch: 66, loss: 0.204052
global_step: 2639, epoch: 66, loss: 0.246390
global_step: 2640, epoch: 66, loss: 0.035243
epoch: 66
train	acc: 0.9675	macro: p 0.9716, r 0.9543, f1: 0.9626	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5221	macro: p 0.3410, r 0.2968, f1: 0.2992	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4774
test	acc: 0.5774	macro: p 0.3699, r 0.3200, f1: 0.3302	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5443
global_step: 2641, epoch: 67, loss: 0.198922
global_step: 2642, epoch: 67, loss: 0.240637
global_step: 2643, epoch: 67, loss: 0.268067
global_step: 2644, epoch: 67, loss: 0.271753
global_step: 2645, epoch: 67, loss: 0.242872
global_step: 2646, epoch: 67, loss: 0.230265
global_step: 2647, epoch: 67, loss: 0.236101
global_step: 2648, epoch: 67, loss: 0.251184
global_step: 2649, epoch: 67, loss: 0.177290
global_step: 2650, epoch: 67, loss: 0.328707
global_step: 2651, epoch: 67, loss: 0.286021
global_step: 2652, epoch: 67, loss: 0.241286
global_step: 2653, epoch: 67, loss: 0.189665
global_step: 2654, epoch: 67, loss: 0.287352
global_step: 2655, epoch: 67, loss: 0.244408
global_step: 2656, epoch: 67, loss: 0.249814
global_step: 2657, epoch: 67, loss: 0.256577
global_step: 2658, epoch: 67, loss: 0.304524
global_step: 2659, epoch: 67, loss: 0.353561
global_step: 2660, epoch: 67, loss: 0.188937
global_step: 2661, epoch: 67, loss: 0.256650
global_step: 2662, epoch: 67, loss: 0.262499
global_step: 2663, epoch: 67, loss: 0.277350
global_step: 2664, epoch: 67, loss: 0.253345
global_step: 2665, epoch: 67, loss: 0.239873
global_step: 2666, epoch: 67, loss: 0.216618
global_step: 2667, epoch: 67, loss: 0.225800
global_step: 2668, epoch: 67, loss: 0.213734
global_step: 2669, epoch: 67, loss: 0.202908
global_step: 2670, epoch: 67, loss: 0.376549
global_step: 2671, epoch: 67, loss: 0.320859
global_step: 2672, epoch: 67, loss: 0.200452
global_step: 2673, epoch: 67, loss: 0.247773
global_step: 2674, epoch: 67, loss: 0.239240
global_step: 2675, epoch: 67, loss: 0.322686
global_step: 2676, epoch: 67, loss: 0.333226
global_step: 2677, epoch: 67, loss: 0.283807
global_step: 2678, epoch: 67, loss: 0.325930
global_step: 2679, epoch: 67, loss: 0.314404
global_step: 2680, epoch: 67, loss: 0.033591
epoch: 67
train	acc: 0.9660	macro: p 0.9707, r 0.9525, f1: 0.9611	micro: p 0.9660, r 0.9660, f1 0.9660	weighted_f1:0.9660
dev	acc: 0.5302	macro: p 0.3650, r 0.3139, f1: 0.3166	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4896
test	acc: 0.5663	macro: p 0.3641, r 0.3176, f1: 0.3250	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5360
global_step: 2681, epoch: 68, loss: 0.207686
global_step: 2682, epoch: 68, loss: 0.273131
global_step: 2683, epoch: 68, loss: 0.210841
global_step: 2684, epoch: 68, loss: 0.170763
global_step: 2685, epoch: 68, loss: 0.316559
global_step: 2686, epoch: 68, loss: 0.238064
global_step: 2687, epoch: 68, loss: 0.184726
global_step: 2688, epoch: 68, loss: 0.255630
global_step: 2689, epoch: 68, loss: 0.268260
global_step: 2690, epoch: 68, loss: 0.204570
global_step: 2691, epoch: 68, loss: 0.184398
global_step: 2692, epoch: 68, loss: 0.201945
global_step: 2693, epoch: 68, loss: 0.356456
global_step: 2694, epoch: 68, loss: 0.317288
global_step: 2695, epoch: 68, loss: 0.241657
global_step: 2696, epoch: 68, loss: 0.325270
global_step: 2697, epoch: 68, loss: 0.301719
global_step: 2698, epoch: 68, loss: 0.191270
global_step: 2699, epoch: 68, loss: 0.219261
global_step: 2700, epoch: 68, loss: 0.209616
global_step: 2701, epoch: 68, loss: 0.261457
global_step: 2702, epoch: 68, loss: 0.269623
global_step: 2703, epoch: 68, loss: 0.204091
global_step: 2704, epoch: 68, loss: 0.216105
global_step: 2705, epoch: 68, loss: 0.307748
global_step: 2706, epoch: 68, loss: 0.289468
global_step: 2707, epoch: 68, loss: 0.321064
global_step: 2708, epoch: 68, loss: 0.277063
global_step: 2709, epoch: 68, loss: 0.219637
global_step: 2710, epoch: 68, loss: 0.289660
global_step: 2711, epoch: 68, loss: 0.260145
global_step: 2712, epoch: 68, loss: 0.261755
global_step: 2713, epoch: 68, loss: 0.257007
global_step: 2714, epoch: 68, loss: 0.252464
global_step: 2715, epoch: 68, loss: 0.286338
global_step: 2716, epoch: 68, loss: 0.206842
global_step: 2717, epoch: 68, loss: 0.171855
global_step: 2718, epoch: 68, loss: 0.303982
global_step: 2719, epoch: 68, loss: 0.272891
global_step: 2720, epoch: 68, loss: 0.202614
epoch: 68
train	acc: 0.9640	macro: p 0.9674, r 0.9518, f1: 0.9593	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9640
dev	acc: 0.5311	macro: p 0.4424, r 0.3288, f1: 0.3464	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4973
test	acc: 0.5716	macro: p 0.3696, r 0.3248, f1: 0.3332	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5448
global_step: 2721, epoch: 69, loss: 0.229994
global_step: 2722, epoch: 69, loss: 0.249416
global_step: 2723, epoch: 69, loss: 0.188140
global_step: 2724, epoch: 69, loss: 0.247707
global_step: 2725, epoch: 69, loss: 0.176910
global_step: 2726, epoch: 69, loss: 0.276639
global_step: 2727, epoch: 69, loss: 0.237581
global_step: 2728, epoch: 69, loss: 0.238209
global_step: 2729, epoch: 69, loss: 0.356085
global_step: 2730, epoch: 69, loss: 0.164117
global_step: 2731, epoch: 69, loss: 0.236208
global_step: 2732, epoch: 69, loss: 0.258033
global_step: 2733, epoch: 69, loss: 0.236369
global_step: 2734, epoch: 69, loss: 0.260098
global_step: 2735, epoch: 69, loss: 0.316714
global_step: 2736, epoch: 69, loss: 0.262736
global_step: 2737, epoch: 69, loss: 0.375628
global_step: 2738, epoch: 69, loss: 0.317451
global_step: 2739, epoch: 69, loss: 0.233683
global_step: 2740, epoch: 69, loss: 0.287381
global_step: 2741, epoch: 69, loss: 0.221813
global_step: 2742, epoch: 69, loss: 0.318800
global_step: 2743, epoch: 69, loss: 0.257819
global_step: 2744, epoch: 69, loss: 0.310163
global_step: 2745, epoch: 69, loss: 0.271544
global_step: 2746, epoch: 69, loss: 0.277459
global_step: 2747, epoch: 69, loss: 0.363515
global_step: 2748, epoch: 69, loss: 0.279431
global_step: 2749, epoch: 69, loss: 0.293257
global_step: 2750, epoch: 69, loss: 0.316715
global_step: 2751, epoch: 69, loss: 0.207342
global_step: 2752, epoch: 69, loss: 0.266940
global_step: 2753, epoch: 69, loss: 0.263013
global_step: 2754, epoch: 69, loss: 0.323872
global_step: 2755, epoch: 69, loss: 0.249338
global_step: 2756, epoch: 69, loss: 0.201674
global_step: 2757, epoch: 69, loss: 0.229193
global_step: 2758, epoch: 69, loss: 0.313206
global_step: 2759, epoch: 69, loss: 0.181910
global_step: 2760, epoch: 69, loss: 0.116543
epoch: 69
train	acc: 0.9681	macro: p 0.9709, r 0.9573, f1: 0.9639	micro: p 0.9681, r 0.9681, f1 0.9681	weighted_f1:0.9681
dev	acc: 0.5329	macro: p 0.4000, r 0.3237, f1: 0.3369	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4949
test	acc: 0.5762	macro: p 0.3718, r 0.3227, f1: 0.3322	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5446
global_step: 2761, epoch: 70, loss: 0.202413
global_step: 2762, epoch: 70, loss: 0.254983
global_step: 2763, epoch: 70, loss: 0.290149
global_step: 2764, epoch: 70, loss: 0.223429
global_step: 2765, epoch: 70, loss: 0.275600
global_step: 2766, epoch: 70, loss: 0.287130
global_step: 2767, epoch: 70, loss: 0.288939
global_step: 2768, epoch: 70, loss: 0.230413
global_step: 2769, epoch: 70, loss: 0.227167
global_step: 2770, epoch: 70, loss: 0.322382
global_step: 2771, epoch: 70, loss: 0.268189
global_step: 2772, epoch: 70, loss: 0.269433
global_step: 2773, epoch: 70, loss: 0.307186
global_step: 2774, epoch: 70, loss: 0.197258
global_step: 2775, epoch: 70, loss: 0.283904
global_step: 2776, epoch: 70, loss: 0.299976
global_step: 2777, epoch: 70, loss: 0.369924
global_step: 2778, epoch: 70, loss: 0.227953
global_step: 2779, epoch: 70, loss: 0.189707
global_step: 2780, epoch: 70, loss: 0.224300
global_step: 2781, epoch: 70, loss: 0.264521
global_step: 2782, epoch: 70, loss: 0.233457
global_step: 2783, epoch: 70, loss: 0.199923
global_step: 2784, epoch: 70, loss: 0.194608
global_step: 2785, epoch: 70, loss: 0.291922
global_step: 2786, epoch: 70, loss: 0.291791
global_step: 2787, epoch: 70, loss: 0.296479
global_step: 2788, epoch: 70, loss: 0.273530
global_step: 2789, epoch: 70, loss: 0.230731
global_step: 2790, epoch: 70, loss: 0.294079
global_step: 2791, epoch: 70, loss: 0.322856
global_step: 2792, epoch: 70, loss: 0.266467
global_step: 2793, epoch: 70, loss: 0.187718
global_step: 2794, epoch: 70, loss: 0.175207
global_step: 2795, epoch: 70, loss: 0.170583
global_step: 2796, epoch: 70, loss: 0.268771
global_step: 2797, epoch: 70, loss: 0.225274
global_step: 2798, epoch: 70, loss: 0.333221
global_step: 2799, epoch: 70, loss: 0.316450
global_step: 2800, epoch: 70, loss: 0.427030
epoch: 70
train	acc: 0.9658	macro: p 0.9689, r 0.9497, f1: 0.9588	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9658
dev	acc: 0.5374	macro: p 0.4045, r 0.3157, f1: 0.3202	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4895
test	acc: 0.5693	macro: p 0.3809, r 0.3111, f1: 0.3196	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5319
global_step: 2801, epoch: 71, loss: 0.211476
global_step: 2802, epoch: 71, loss: 0.288601
global_step: 2803, epoch: 71, loss: 0.232363
global_step: 2804, epoch: 71, loss: 0.221220
global_step: 2805, epoch: 71, loss: 0.255566
global_step: 2806, epoch: 71, loss: 0.210530
global_step: 2807, epoch: 71, loss: 0.326347
global_step: 2808, epoch: 71, loss: 0.265654
global_step: 2809, epoch: 71, loss: 0.233908
global_step: 2810, epoch: 71, loss: 0.340031
global_step: 2811, epoch: 71, loss: 0.288180
global_step: 2812, epoch: 71, loss: 0.235280
global_step: 2813, epoch: 71, loss: 0.222100
global_step: 2814, epoch: 71, loss: 0.268434
global_step: 2815, epoch: 71, loss: 0.316014
global_step: 2816, epoch: 71, loss: 0.254369
global_step: 2817, epoch: 71, loss: 0.233956
global_step: 2818, epoch: 71, loss: 0.269433
global_step: 2819, epoch: 71, loss: 0.197358
global_step: 2820, epoch: 71, loss: 0.213489
global_step: 2821, epoch: 71, loss: 0.227481
global_step: 2822, epoch: 71, loss: 0.320937
global_step: 2823, epoch: 71, loss: 0.318927
global_step: 2824, epoch: 71, loss: 0.291732
global_step: 2825, epoch: 71, loss: 0.289889
global_step: 2826, epoch: 71, loss: 0.291194
global_step: 2827, epoch: 71, loss: 0.266410
global_step: 2828, epoch: 71, loss: 0.294446
global_step: 2829, epoch: 71, loss: 0.247815
global_step: 2830, epoch: 71, loss: 0.231527
global_step: 2831, epoch: 71, loss: 0.305761
global_step: 2832, epoch: 71, loss: 0.237539
global_step: 2833, epoch: 71, loss: 0.341468
global_step: 2834, epoch: 71, loss: 0.288685
global_step: 2835, epoch: 71, loss: 0.292593
global_step: 2836, epoch: 71, loss: 0.345794
global_step: 2837, epoch: 71, loss: 0.287907
global_step: 2838, epoch: 71, loss: 0.219310
global_step: 2839, epoch: 71, loss: 0.238908
global_step: 2840, epoch: 71, loss: 0.052147
epoch: 71
train	acc: 0.9684	macro: p 0.9720, r 0.9558, f1: 0.9636	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5293	macro: p 0.3997, r 0.3247, f1: 0.3311	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4994
test	acc: 0.5582	macro: p 0.3388, r 0.3158, f1: 0.3141	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5327
global_step: 2841, epoch: 72, loss: 0.219838
global_step: 2842, epoch: 72, loss: 0.265636
global_step: 2843, epoch: 72, loss: 0.266107
global_step: 2844, epoch: 72, loss: 0.254117
global_step: 2845, epoch: 72, loss: 0.224994
global_step: 2846, epoch: 72, loss: 0.205052
global_step: 2847, epoch: 72, loss: 0.185870
global_step: 2848, epoch: 72, loss: 0.230313
global_step: 2849, epoch: 72, loss: 0.189537
global_step: 2850, epoch: 72, loss: 0.260065
global_step: 2851, epoch: 72, loss: 0.289472
global_step: 2852, epoch: 72, loss: 0.174907
global_step: 2853, epoch: 72, loss: 0.340442
global_step: 2854, epoch: 72, loss: 0.283092
global_step: 2855, epoch: 72, loss: 0.191545
global_step: 2856, epoch: 72, loss: 0.206668
global_step: 2857, epoch: 72, loss: 0.266450
global_step: 2858, epoch: 72, loss: 0.325697
global_step: 2859, epoch: 72, loss: 0.187615
global_step: 2860, epoch: 72, loss: 0.175210
global_step: 2861, epoch: 72, loss: 0.204058
global_step: 2862, epoch: 72, loss: 0.219948
global_step: 2863, epoch: 72, loss: 0.270436
global_step: 2864, epoch: 72, loss: 0.203809
global_step: 2865, epoch: 72, loss: 0.274370
global_step: 2866, epoch: 72, loss: 0.249450
global_step: 2867, epoch: 72, loss: 0.332102
global_step: 2868, epoch: 72, loss: 0.287140
global_step: 2869, epoch: 72, loss: 0.187722
global_step: 2870, epoch: 72, loss: 0.305366
global_step: 2871, epoch: 72, loss: 0.314044
global_step: 2872, epoch: 72, loss: 0.249440
global_step: 2873, epoch: 72, loss: 0.249634
global_step: 2874, epoch: 72, loss: 0.331433
global_step: 2875, epoch: 72, loss: 0.270546
global_step: 2876, epoch: 72, loss: 0.225992
global_step: 2877, epoch: 72, loss: 0.271129
global_step: 2878, epoch: 72, loss: 0.245073
global_step: 2879, epoch: 72, loss: 0.369578
global_step: 2880, epoch: 72, loss: 0.038550
epoch: 72
train	acc: 0.9675	macro: p 0.9730, r 0.9534, f1: 0.9628	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5293	macro: p 0.3923, r 0.3113, f1: 0.3198	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4894
test	acc: 0.5759	macro: p 0.3642, r 0.3178, f1: 0.3217	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5408
global_step: 2881, epoch: 73, loss: 0.213168
global_step: 2882, epoch: 73, loss: 0.208648
global_step: 2883, epoch: 73, loss: 0.260689
global_step: 2884, epoch: 73, loss: 0.189531
global_step: 2885, epoch: 73, loss: 0.198674
global_step: 2886, epoch: 73, loss: 0.196493
global_step: 2887, epoch: 73, loss: 0.224618
global_step: 2888, epoch: 73, loss: 0.321511
global_step: 2889, epoch: 73, loss: 0.226685
global_step: 2890, epoch: 73, loss: 0.138865
global_step: 2891, epoch: 73, loss: 0.246165
global_step: 2892, epoch: 73, loss: 0.292402
global_step: 2893, epoch: 73, loss: 0.284067
global_step: 2894, epoch: 73, loss: 0.268490
global_step: 2895, epoch: 73, loss: 0.236910
global_step: 2896, epoch: 73, loss: 0.265510
global_step: 2897, epoch: 73, loss: 0.237034
global_step: 2898, epoch: 73, loss: 0.292007
global_step: 2899, epoch: 73, loss: 0.244950
global_step: 2900, epoch: 73, loss: 0.260911
global_step: 2901, epoch: 73, loss: 0.298458
global_step: 2902, epoch: 73, loss: 0.243956
global_step: 2903, epoch: 73, loss: 0.212334
global_step: 2904, epoch: 73, loss: 0.187861
global_step: 2905, epoch: 73, loss: 0.251499
global_step: 2906, epoch: 73, loss: 0.273683
global_step: 2907, epoch: 73, loss: 0.299825
global_step: 2908, epoch: 73, loss: 0.265930
global_step: 2909, epoch: 73, loss: 0.257609
global_step: 2910, epoch: 73, loss: 0.269908
global_step: 2911, epoch: 73, loss: 0.305215
global_step: 2912, epoch: 73, loss: 0.340173
global_step: 2913, epoch: 73, loss: 0.215920
global_step: 2914, epoch: 73, loss: 0.279691
global_step: 2915, epoch: 73, loss: 0.242254
global_step: 2916, epoch: 73, loss: 0.266199
global_step: 2917, epoch: 73, loss: 0.305072
global_step: 2918, epoch: 73, loss: 0.339489
global_step: 2919, epoch: 73, loss: 0.275921
global_step: 2920, epoch: 73, loss: 0.202017
epoch: 73
train	acc: 0.9646	macro: p 0.9710, r 0.9511, f1: 0.9607	micro: p 0.9646, r 0.9646, f1 0.9646	weighted_f1:0.9645
dev	acc: 0.5338	macro: p 0.4404, r 0.3090, f1: 0.3218	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4827
test	acc: 0.5828	macro: p 0.3866, r 0.3117, f1: 0.3229	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5383
global_step: 2921, epoch: 74, loss: 0.235132
global_step: 2922, epoch: 74, loss: 0.197868
global_step: 2923, epoch: 74, loss: 0.260380
global_step: 2924, epoch: 74, loss: 0.215784
global_step: 2925, epoch: 74, loss: 0.150345
global_step: 2926, epoch: 74, loss: 0.183234
global_step: 2927, epoch: 74, loss: 0.185909
global_step: 2928, epoch: 74, loss: 0.270846
global_step: 2929, epoch: 74, loss: 0.304048
global_step: 2930, epoch: 74, loss: 0.187293
global_step: 2931, epoch: 74, loss: 0.347816
global_step: 2932, epoch: 74, loss: 0.348083
global_step: 2933, epoch: 74, loss: 0.319763
global_step: 2934, epoch: 74, loss: 0.353900
global_step: 2935, epoch: 74, loss: 0.219427
global_step: 2936, epoch: 74, loss: 0.207303
global_step: 2937, epoch: 74, loss: 0.259230
global_step: 2938, epoch: 74, loss: 0.223460
global_step: 2939, epoch: 74, loss: 0.262326
global_step: 2940, epoch: 74, loss: 0.186304
global_step: 2941, epoch: 74, loss: 0.204342
global_step: 2942, epoch: 74, loss: 0.245251
global_step: 2943, epoch: 74, loss: 0.196310
global_step: 2944, epoch: 74, loss: 0.295266
global_step: 2945, epoch: 74, loss: 0.270554
global_step: 2946, epoch: 74, loss: 0.225854
global_step: 2947, epoch: 74, loss: 0.269509
global_step: 2948, epoch: 74, loss: 0.245980
global_step: 2949, epoch: 74, loss: 0.304296
global_step: 2950, epoch: 74, loss: 0.265116
global_step: 2951, epoch: 74, loss: 0.373392
global_step: 2952, epoch: 74, loss: 0.331776
global_step: 2953, epoch: 74, loss: 0.199331
global_step: 2954, epoch: 74, loss: 0.268354
global_step: 2955, epoch: 74, loss: 0.225914
global_step: 2956, epoch: 74, loss: 0.290059
global_step: 2957, epoch: 74, loss: 0.333300
global_step: 2958, epoch: 74, loss: 0.198407
global_step: 2959, epoch: 74, loss: 0.247683
global_step: 2960, epoch: 74, loss: 0.041237
epoch: 74
train	acc: 0.9686	macro: p 0.9714, r 0.9578, f1: 0.9644	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5230	macro: p 0.3790, r 0.3077, f1: 0.3198	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4814
test	acc: 0.5828	macro: p 0.3771, r 0.3208, f1: 0.3336	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5471
global_step: 2961, epoch: 75, loss: 0.361958
global_step: 2962, epoch: 75, loss: 0.252316
global_step: 2963, epoch: 75, loss: 0.216561
global_step: 2964, epoch: 75, loss: 0.264232
global_step: 2965, epoch: 75, loss: 0.257729
global_step: 2966, epoch: 75, loss: 0.225475
global_step: 2967, epoch: 75, loss: 0.256048
global_step: 2968, epoch: 75, loss: 0.234011
global_step: 2969, epoch: 75, loss: 0.226984
global_step: 2970, epoch: 75, loss: 0.251141
global_step: 2971, epoch: 75, loss: 0.291164
global_step: 2972, epoch: 75, loss: 0.250104
global_step: 2973, epoch: 75, loss: 0.246497
global_step: 2974, epoch: 75, loss: 0.260233
global_step: 2975, epoch: 75, loss: 0.238819
global_step: 2976, epoch: 75, loss: 0.239764
global_step: 2977, epoch: 75, loss: 0.209443
global_step: 2978, epoch: 75, loss: 0.307497
global_step: 2979, epoch: 75, loss: 0.304290
global_step: 2980, epoch: 75, loss: 0.201399
global_step: 2981, epoch: 75, loss: 0.238255
global_step: 2982, epoch: 75, loss: 0.223198
global_step: 2983, epoch: 75, loss: 0.233428
global_step: 2984, epoch: 75, loss: 0.228795
global_step: 2985, epoch: 75, loss: 0.262890
global_step: 2986, epoch: 75, loss: 0.208026
global_step: 2987, epoch: 75, loss: 0.214665
global_step: 2988, epoch: 75, loss: 0.212549
global_step: 2989, epoch: 75, loss: 0.225883
global_step: 2990, epoch: 75, loss: 0.243722
global_step: 2991, epoch: 75, loss: 0.221463
global_step: 2992, epoch: 75, loss: 0.212858
global_step: 2993, epoch: 75, loss: 0.214892
global_step: 2994, epoch: 75, loss: 0.299709
global_step: 2995, epoch: 75, loss: 0.197393
global_step: 2996, epoch: 75, loss: 0.187650
global_step: 2997, epoch: 75, loss: 0.282573
global_step: 2998, epoch: 75, loss: 0.293165
global_step: 2999, epoch: 75, loss: 0.261993
global_step: 3000, epoch: 75, loss: 0.005165
epoch: 75
train	acc: 0.9689	macro: p 0.9713, r 0.9576, f1: 0.9642	micro: p 0.9689, r 0.9689, f1 0.9689	weighted_f1:0.9689
dev	acc: 0.5275	macro: p 0.4543, r 0.3285, f1: 0.3467	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4943
test	acc: 0.5701	macro: p 0.3726, r 0.3193, f1: 0.3278	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5380
global_step: 3001, epoch: 76, loss: 0.234293
global_step: 3002, epoch: 76, loss: 0.183446
global_step: 3003, epoch: 76, loss: 0.207514
global_step: 3004, epoch: 76, loss: 0.247425
global_step: 3005, epoch: 76, loss: 0.286146
global_step: 3006, epoch: 76, loss: 0.294137
global_step: 3007, epoch: 76, loss: 0.251954
global_step: 3008, epoch: 76, loss: 0.352435
global_step: 3009, epoch: 76, loss: 0.211151
global_step: 3010, epoch: 76, loss: 0.191702
global_step: 3011, epoch: 76, loss: 0.196996
global_step: 3012, epoch: 76, loss: 0.171454
global_step: 3013, epoch: 76, loss: 0.245178
global_step: 3014, epoch: 76, loss: 0.163081
global_step: 3015, epoch: 76, loss: 0.300635
global_step: 3016, epoch: 76, loss: 0.203023
global_step: 3017, epoch: 76, loss: 0.250449
global_step: 3018, epoch: 76, loss: 0.251476
global_step: 3019, epoch: 76, loss: 0.216112
global_step: 3020, epoch: 76, loss: 0.181503
global_step: 3021, epoch: 76, loss: 0.188225
global_step: 3022, epoch: 76, loss: 0.227970
global_step: 3023, epoch: 76, loss: 0.185651
global_step: 3024, epoch: 76, loss: 0.245433
global_step: 3025, epoch: 76, loss: 0.202354
global_step: 3026, epoch: 76, loss: 0.316258
global_step: 3027, epoch: 76, loss: 0.212223
global_step: 3028, epoch: 76, loss: 0.192518
global_step: 3029, epoch: 76, loss: 0.252841
global_step: 3030, epoch: 76, loss: 0.245840
global_step: 3031, epoch: 76, loss: 0.270896
global_step: 3032, epoch: 76, loss: 0.308776
global_step: 3033, epoch: 76, loss: 0.312010
global_step: 3034, epoch: 76, loss: 0.240221
global_step: 3035, epoch: 76, loss: 0.199815
global_step: 3036, epoch: 76, loss: 0.239535
global_step: 3037, epoch: 76, loss: 0.230580
global_step: 3038, epoch: 76, loss: 0.313697
global_step: 3039, epoch: 76, loss: 0.267563
global_step: 3040, epoch: 76, loss: 0.018516
epoch: 76
train	acc: 0.9672	macro: p 0.9744, r 0.9510, f1: 0.9623	micro: p 0.9672, r 0.9672, f1 0.9672	weighted_f1:0.9670
dev	acc: 0.5320	macro: p 0.4489, r 0.3171, f1: 0.3354	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4861
test	acc: 0.5766	macro: p 0.3829, r 0.3101, f1: 0.3249	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5372
global_step: 3041, epoch: 77, loss: 0.200095
global_step: 3042, epoch: 77, loss: 0.179640
global_step: 3043, epoch: 77, loss: 0.233382
global_step: 3044, epoch: 77, loss: 0.226537
global_step: 3045, epoch: 77, loss: 0.173022
global_step: 3046, epoch: 77, loss: 0.159709
global_step: 3047, epoch: 77, loss: 0.156692
global_step: 3048, epoch: 77, loss: 0.162858
global_step: 3049, epoch: 77, loss: 0.357234
global_step: 3050, epoch: 77, loss: 0.234093
global_step: 3051, epoch: 77, loss: 0.200068
global_step: 3052, epoch: 77, loss: 0.297793
global_step: 3053, epoch: 77, loss: 0.263008
global_step: 3054, epoch: 77, loss: 0.246546
global_step: 3055, epoch: 77, loss: 0.198982
global_step: 3056, epoch: 77, loss: 0.219402
global_step: 3057, epoch: 77, loss: 0.323351
global_step: 3058, epoch: 77, loss: 0.191653
global_step: 3059, epoch: 77, loss: 0.262704
global_step: 3060, epoch: 77, loss: 0.262808
global_step: 3061, epoch: 77, loss: 0.275591
global_step: 3062, epoch: 77, loss: 0.218719
global_step: 3063, epoch: 77, loss: 0.205479
global_step: 3064, epoch: 77, loss: 0.261286
global_step: 3065, epoch: 77, loss: 0.171367
global_step: 3066, epoch: 77, loss: 0.211857
global_step: 3067, epoch: 77, loss: 0.304778
global_step: 3068, epoch: 77, loss: 0.308553
global_step: 3069, epoch: 77, loss: 0.329825
global_step: 3070, epoch: 77, loss: 0.231019
global_step: 3071, epoch: 77, loss: 0.245036
global_step: 3072, epoch: 77, loss: 0.196615
global_step: 3073, epoch: 77, loss: 0.206318
global_step: 3074, epoch: 77, loss: 0.246335
global_step: 3075, epoch: 77, loss: 0.256649
global_step: 3076, epoch: 77, loss: 0.255310
global_step: 3077, epoch: 77, loss: 0.303738
global_step: 3078, epoch: 77, loss: 0.264064
global_step: 3079, epoch: 77, loss: 0.309956
global_step: 3080, epoch: 77, loss: 0.175957
epoch: 77
train	acc: 0.9653	macro: p 0.9692, r 0.9523, f1: 0.9602	micro: p 0.9653, r 0.9653, f1 0.9653	weighted_f1:0.9654
dev	acc: 0.5122	macro: p 0.4151, r 0.3176, f1: 0.3248	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4801
test	acc: 0.5613	macro: p 0.3558, r 0.3196, f1: 0.3208	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5352
global_step: 3081, epoch: 78, loss: 0.183919
global_step: 3082, epoch: 78, loss: 0.212123
global_step: 3083, epoch: 78, loss: 0.234121
global_step: 3084, epoch: 78, loss: 0.226659
global_step: 3085, epoch: 78, loss: 0.203626
global_step: 3086, epoch: 78, loss: 0.247566
global_step: 3087, epoch: 78, loss: 0.165612
global_step: 3088, epoch: 78, loss: 0.284653
global_step: 3089, epoch: 78, loss: 0.207518
global_step: 3090, epoch: 78, loss: 0.189981
global_step: 3091, epoch: 78, loss: 0.186936
global_step: 3092, epoch: 78, loss: 0.223185
global_step: 3093, epoch: 78, loss: 0.222113
global_step: 3094, epoch: 78, loss: 0.250944
global_step: 3095, epoch: 78, loss: 0.271344
global_step: 3096, epoch: 78, loss: 0.235547
global_step: 3097, epoch: 78, loss: 0.247481
global_step: 3098, epoch: 78, loss: 0.321511
global_step: 3099, epoch: 78, loss: 0.234745
global_step: 3100, epoch: 78, loss: 0.248054
global_step: 3101, epoch: 78, loss: 0.190267
global_step: 3102, epoch: 78, loss: 0.204728
global_step: 3103, epoch: 78, loss: 0.348331
global_step: 3104, epoch: 78, loss: 0.222427
global_step: 3105, epoch: 78, loss: 0.257409
global_step: 3106, epoch: 78, loss: 0.143471
global_step: 3107, epoch: 78, loss: 0.193621
global_step: 3108, epoch: 78, loss: 0.317767
global_step: 3109, epoch: 78, loss: 0.331509
global_step: 3110, epoch: 78, loss: 0.297267
global_step: 3111, epoch: 78, loss: 0.242396
global_step: 3112, epoch: 78, loss: 0.269950
global_step: 3113, epoch: 78, loss: 0.208648
global_step: 3114, epoch: 78, loss: 0.188177
global_step: 3115, epoch: 78, loss: 0.204187
global_step: 3116, epoch: 78, loss: 0.261143
global_step: 3117, epoch: 78, loss: 0.216484
global_step: 3118, epoch: 78, loss: 0.223365
global_step: 3119, epoch: 78, loss: 0.163522
global_step: 3120, epoch: 78, loss: 0.135804
epoch: 78
train	acc: 0.9655	macro: p 0.9713, r 0.9544, f1: 0.9624	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5203	macro: p 0.4522, r 0.3182, f1: 0.3342	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4790
test	acc: 0.5728	macro: p 0.3766, r 0.3173, f1: 0.3239	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5348
global_step: 3121, epoch: 79, loss: 0.243380
global_step: 3122, epoch: 79, loss: 0.220160
global_step: 3123, epoch: 79, loss: 0.272561
global_step: 3124, epoch: 79, loss: 0.179869
global_step: 3125, epoch: 79, loss: 0.228013
global_step: 3126, epoch: 79, loss: 0.210889
global_step: 3127, epoch: 79, loss: 0.237056
global_step: 3128, epoch: 79, loss: 0.223931
global_step: 3129, epoch: 79, loss: 0.234906
global_step: 3130, epoch: 79, loss: 0.263500
global_step: 3131, epoch: 79, loss: 0.261574
global_step: 3132, epoch: 79, loss: 0.246786
global_step: 3133, epoch: 79, loss: 0.305571
global_step: 3134, epoch: 79, loss: 0.252279
global_step: 3135, epoch: 79, loss: 0.257832
global_step: 3136, epoch: 79, loss: 0.252093
global_step: 3137, epoch: 79, loss: 0.205658
global_step: 3138, epoch: 79, loss: 0.208078
global_step: 3139, epoch: 79, loss: 0.271229
global_step: 3140, epoch: 79, loss: 0.225118
global_step: 3141, epoch: 79, loss: 0.309043
global_step: 3142, epoch: 79, loss: 0.263454
global_step: 3143, epoch: 79, loss: 0.253122
global_step: 3144, epoch: 79, loss: 0.251443
global_step: 3145, epoch: 79, loss: 0.290062
global_step: 3146, epoch: 79, loss: 0.307124
global_step: 3147, epoch: 79, loss: 0.213760
global_step: 3148, epoch: 79, loss: 0.186891
global_step: 3149, epoch: 79, loss: 0.282328
global_step: 3150, epoch: 79, loss: 0.244983
global_step: 3151, epoch: 79, loss: 0.202157
global_step: 3152, epoch: 79, loss: 0.254354
global_step: 3153, epoch: 79, loss: 0.245955
global_step: 3154, epoch: 79, loss: 0.276528
global_step: 3155, epoch: 79, loss: 0.417078
global_step: 3156, epoch: 79, loss: 0.231154
global_step: 3157, epoch: 79, loss: 0.219994
global_step: 3158, epoch: 79, loss: 0.271453
global_step: 3159, epoch: 79, loss: 0.303811
global_step: 3160, epoch: 79, loss: 0.153453
epoch: 79
train	acc: 0.9692	macro: p 0.9723, r 0.9569, f1: 0.9644	micro: p 0.9692, r 0.9692, f1 0.9692	weighted_f1:0.9692
dev	acc: 0.5203	macro: p 0.4361, r 0.3177, f1: 0.3352	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4820
test	acc: 0.5759	macro: p 0.3751, r 0.3203, f1: 0.3294	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5423
global_step: 3161, epoch: 80, loss: 0.228208
global_step: 3162, epoch: 80, loss: 0.249362
global_step: 3163, epoch: 80, loss: 0.255913
global_step: 3164, epoch: 80, loss: 0.251875
global_step: 3165, epoch: 80, loss: 0.194647
global_step: 3166, epoch: 80, loss: 0.206940
global_step: 3167, epoch: 80, loss: 0.240271
global_step: 3168, epoch: 80, loss: 0.222901
global_step: 3169, epoch: 80, loss: 0.208179
global_step: 3170, epoch: 80, loss: 0.229212
global_step: 3171, epoch: 80, loss: 0.262212
global_step: 3172, epoch: 80, loss: 0.250400
global_step: 3173, epoch: 80, loss: 0.218706
global_step: 3174, epoch: 80, loss: 0.221447
global_step: 3175, epoch: 80, loss: 0.285691
global_step: 3176, epoch: 80, loss: 0.250815
global_step: 3177, epoch: 80, loss: 0.188635
global_step: 3178, epoch: 80, loss: 0.260532
global_step: 3179, epoch: 80, loss: 0.247665
global_step: 3180, epoch: 80, loss: 0.229468
global_step: 3181, epoch: 80, loss: 0.242968
global_step: 3182, epoch: 80, loss: 0.220957
global_step: 3183, epoch: 80, loss: 0.184132
global_step: 3184, epoch: 80, loss: 0.196897
global_step: 3185, epoch: 80, loss: 0.246679
global_step: 3186, epoch: 80, loss: 0.281215
global_step: 3187, epoch: 80, loss: 0.218921
global_step: 3188, epoch: 80, loss: 0.264141
global_step: 3189, epoch: 80, loss: 0.194984
global_step: 3190, epoch: 80, loss: 0.266344
global_step: 3191, epoch: 80, loss: 0.288654
global_step: 3192, epoch: 80, loss: 0.224345
global_step: 3193, epoch: 80, loss: 0.202665
global_step: 3194, epoch: 80, loss: 0.290419
global_step: 3195, epoch: 80, loss: 0.357154
global_step: 3196, epoch: 80, loss: 0.360368
global_step: 3197, epoch: 80, loss: 0.204262
global_step: 3198, epoch: 80, loss: 0.240251
global_step: 3199, epoch: 80, loss: 0.252880
global_step: 3200, epoch: 80, loss: 1.875962
epoch: 80
train	acc: 0.9706	macro: p 0.9717, r 0.9613, f1: 0.9664	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5095	macro: p 0.3928, r 0.3323, f1: 0.3453	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4883
test	acc: 0.5452	macro: p 0.3320, r 0.3157, f1: 0.3198	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5295
global_step: 3201, epoch: 81, loss: 0.318838
global_step: 3202, epoch: 81, loss: 0.244434
global_step: 3203, epoch: 81, loss: 0.227307
global_step: 3204, epoch: 81, loss: 0.152993
global_step: 3205, epoch: 81, loss: 0.200370
global_step: 3206, epoch: 81, loss: 0.205932
global_step: 3207, epoch: 81, loss: 0.200506
global_step: 3208, epoch: 81, loss: 0.213345
global_step: 3209, epoch: 81, loss: 0.215780
global_step: 3210, epoch: 81, loss: 0.180794
global_step: 3211, epoch: 81, loss: 0.252722
global_step: 3212, epoch: 81, loss: 0.203882
global_step: 3213, epoch: 81, loss: 0.160454
global_step: 3214, epoch: 81, loss: 0.161907
global_step: 3215, epoch: 81, loss: 0.206542
global_step: 3216, epoch: 81, loss: 0.221228
global_step: 3217, epoch: 81, loss: 0.237943
global_step: 3218, epoch: 81, loss: 0.333076
global_step: 3219, epoch: 81, loss: 0.226006
global_step: 3220, epoch: 81, loss: 0.175984
global_step: 3221, epoch: 81, loss: 0.148917
global_step: 3222, epoch: 81, loss: 0.225736
global_step: 3223, epoch: 81, loss: 0.238360
global_step: 3224, epoch: 81, loss: 0.285415
global_step: 3225, epoch: 81, loss: 0.259673
global_step: 3226, epoch: 81, loss: 0.260375
global_step: 3227, epoch: 81, loss: 0.265103
global_step: 3228, epoch: 81, loss: 0.327348
global_step: 3229, epoch: 81, loss: 0.278582
global_step: 3230, epoch: 81, loss: 0.257822
global_step: 3231, epoch: 81, loss: 0.281132
global_step: 3232, epoch: 81, loss: 0.237050
global_step: 3233, epoch: 81, loss: 0.347187
global_step: 3234, epoch: 81, loss: 0.251704
global_step: 3235, epoch: 81, loss: 0.214969
global_step: 3236, epoch: 81, loss: 0.232311
global_step: 3237, epoch: 81, loss: 0.225686
global_step: 3238, epoch: 81, loss: 0.228470
global_step: 3239, epoch: 81, loss: 0.226455
global_step: 3240, epoch: 81, loss: 0.051985
epoch: 81
train	acc: 0.9686	macro: p 0.9708, r 0.9562, f1: 0.9633	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5338	macro: p 0.4362, r 0.3290, f1: 0.3426	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4915
test	acc: 0.5782	macro: p 0.3661, r 0.3156, f1: 0.3211	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5405
global_step: 3241, epoch: 82, loss: 0.220378
global_step: 3242, epoch: 82, loss: 0.172631
global_step: 3243, epoch: 82, loss: 0.246729
global_step: 3244, epoch: 82, loss: 0.206144
global_step: 3245, epoch: 82, loss: 0.242677
global_step: 3246, epoch: 82, loss: 0.238988
global_step: 3247, epoch: 82, loss: 0.169624
global_step: 3248, epoch: 82, loss: 0.279829
global_step: 3249, epoch: 82, loss: 0.182196
global_step: 3250, epoch: 82, loss: 0.257277
global_step: 3251, epoch: 82, loss: 0.230859
global_step: 3252, epoch: 82, loss: 0.217499
global_step: 3253, epoch: 82, loss: 0.177004
global_step: 3254, epoch: 82, loss: 0.194287
global_step: 3255, epoch: 82, loss: 0.236630
global_step: 3256, epoch: 82, loss: 0.259958
global_step: 3257, epoch: 82, loss: 0.220796
global_step: 3258, epoch: 82, loss: 0.244459
global_step: 3259, epoch: 82, loss: 0.253731
global_step: 3260, epoch: 82, loss: 0.164053
global_step: 3261, epoch: 82, loss: 0.200578
global_step: 3262, epoch: 82, loss: 0.300687
global_step: 3263, epoch: 82, loss: 0.209702
global_step: 3264, epoch: 82, loss: 0.218996
global_step: 3265, epoch: 82, loss: 0.289952
global_step: 3266, epoch: 82, loss: 0.196282
global_step: 3267, epoch: 82, loss: 0.181008
global_step: 3268, epoch: 82, loss: 0.316803
global_step: 3269, epoch: 82, loss: 0.212468
global_step: 3270, epoch: 82, loss: 0.202884
global_step: 3271, epoch: 82, loss: 0.298639
global_step: 3272, epoch: 82, loss: 0.243425
global_step: 3273, epoch: 82, loss: 0.241383
global_step: 3274, epoch: 82, loss: 0.210959
global_step: 3275, epoch: 82, loss: 0.269936
global_step: 3276, epoch: 82, loss: 0.192728
global_step: 3277, epoch: 82, loss: 0.238323
global_step: 3278, epoch: 82, loss: 0.215256
global_step: 3279, epoch: 82, loss: 0.272129
global_step: 3280, epoch: 82, loss: 0.041894
epoch: 82
train	acc: 0.9677	macro: p 0.9746, r 0.9528, f1: 0.9633	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9676
dev	acc: 0.5329	macro: p 0.4862, r 0.3081, f1: 0.3223	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4813
test	acc: 0.5732	macro: p 0.3831, r 0.2980, f1: 0.3075	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5262
global_step: 3281, epoch: 83, loss: 0.198128
global_step: 3282, epoch: 83, loss: 0.224247
global_step: 3283, epoch: 83, loss: 0.258589
global_step: 3284, epoch: 83, loss: 0.212444
global_step: 3285, epoch: 83, loss: 0.235967
global_step: 3286, epoch: 83, loss: 0.229128
global_step: 3287, epoch: 83, loss: 0.244547
global_step: 3288, epoch: 83, loss: 0.175020
global_step: 3289, epoch: 83, loss: 0.245939
global_step: 3290, epoch: 83, loss: 0.191146
global_step: 3291, epoch: 83, loss: 0.288052
global_step: 3292, epoch: 83, loss: 0.291129
global_step: 3293, epoch: 83, loss: 0.249683
global_step: 3294, epoch: 83, loss: 0.186568
global_step: 3295, epoch: 83, loss: 0.217819
global_step: 3296, epoch: 83, loss: 0.252739
global_step: 3297, epoch: 83, loss: 0.243240
global_step: 3298, epoch: 83, loss: 0.212431
global_step: 3299, epoch: 83, loss: 0.281627
global_step: 3300, epoch: 83, loss: 0.185332
global_step: 3301, epoch: 83, loss: 0.255127
global_step: 3302, epoch: 83, loss: 0.233338
global_step: 3303, epoch: 83, loss: 0.217234
global_step: 3304, epoch: 83, loss: 0.215332
global_step: 3305, epoch: 83, loss: 0.236824
global_step: 3306, epoch: 83, loss: 0.292879
global_step: 3307, epoch: 83, loss: 0.346043
global_step: 3308, epoch: 83, loss: 0.265572
global_step: 3309, epoch: 83, loss: 0.175099
global_step: 3310, epoch: 83, loss: 0.261846
global_step: 3311, epoch: 83, loss: 0.192115
global_step: 3312, epoch: 83, loss: 0.214188
global_step: 3313, epoch: 83, loss: 0.256640
global_step: 3314, epoch: 83, loss: 0.226542
global_step: 3315, epoch: 83, loss: 0.254415
global_step: 3316, epoch: 83, loss: 0.218174
global_step: 3317, epoch: 83, loss: 0.279293
global_step: 3318, epoch: 83, loss: 0.236648
global_step: 3319, epoch: 83, loss: 0.286497
global_step: 3320, epoch: 83, loss: 0.039836
epoch: 83
train	acc: 0.9691	macro: p 0.9724, r 0.9566, f1: 0.9643	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5347	macro: p 0.4735, r 0.3391, f1: 0.3630	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4978
test	acc: 0.5693	macro: p 0.3990, r 0.3148, f1: 0.3247	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5361
global_step: 3321, epoch: 84, loss: 0.170381
global_step: 3322, epoch: 84, loss: 0.216377
global_step: 3323, epoch: 84, loss: 0.210219
global_step: 3324, epoch: 84, loss: 0.193750
global_step: 3325, epoch: 84, loss: 0.269664
global_step: 3326, epoch: 84, loss: 0.204564
global_step: 3327, epoch: 84, loss: 0.163978
global_step: 3328, epoch: 84, loss: 0.201723
global_step: 3329, epoch: 84, loss: 0.245219
global_step: 3330, epoch: 84, loss: 0.246561
global_step: 3331, epoch: 84, loss: 0.259182
global_step: 3332, epoch: 84, loss: 0.240506
global_step: 3333, epoch: 84, loss: 0.235248
global_step: 3334, epoch: 84, loss: 0.262449
global_step: 3335, epoch: 84, loss: 0.239925
global_step: 3336, epoch: 84, loss: 0.186820
global_step: 3337, epoch: 84, loss: 0.237944
global_step: 3338, epoch: 84, loss: 0.285738
global_step: 3339, epoch: 84, loss: 0.263041
global_step: 3340, epoch: 84, loss: 0.249246
global_step: 3341, epoch: 84, loss: 0.224789
global_step: 3342, epoch: 84, loss: 0.346707
global_step: 3343, epoch: 84, loss: 0.288549
global_step: 3344, epoch: 84, loss: 0.270403
global_step: 3345, epoch: 84, loss: 0.270733
global_step: 3346, epoch: 84, loss: 0.191557
global_step: 3347, epoch: 84, loss: 0.264786
global_step: 3348, epoch: 84, loss: 0.279960
global_step: 3349, epoch: 84, loss: 0.255028
global_step: 3350, epoch: 84, loss: 0.209638
global_step: 3351, epoch: 84, loss: 0.183192
global_step: 3352, epoch: 84, loss: 0.237475
global_step: 3353, epoch: 84, loss: 0.223901
global_step: 3354, epoch: 84, loss: 0.215555
global_step: 3355, epoch: 84, loss: 0.183037
global_step: 3356, epoch: 84, loss: 0.173557
global_step: 3357, epoch: 84, loss: 0.283883
global_step: 3358, epoch: 84, loss: 0.172217
global_step: 3359, epoch: 84, loss: 0.297510
global_step: 3360, epoch: 84, loss: 0.002265
epoch: 84
train	acc: 0.9702	macro: p 0.9724, r 0.9615, f1: 0.9668	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5185	macro: p 0.4335, r 0.3298, f1: 0.3439	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4916
test	acc: 0.5525	macro: p 0.3472, r 0.3140, f1: 0.3158	micro: p 0.5525, r 0.5525, f1 0.5525	weighted_f1:0.5296
global_step: 3361, epoch: 85, loss: 0.167130
global_step: 3362, epoch: 85, loss: 0.161957
global_step: 3363, epoch: 85, loss: 0.229291
global_step: 3364, epoch: 85, loss: 0.240796
global_step: 3365, epoch: 85, loss: 0.170279
global_step: 3366, epoch: 85, loss: 0.179477
global_step: 3367, epoch: 85, loss: 0.193356
global_step: 3368, epoch: 85, loss: 0.266100
global_step: 3369, epoch: 85, loss: 0.164122
global_step: 3370, epoch: 85, loss: 0.284978
global_step: 3371, epoch: 85, loss: 0.187802
global_step: 3372, epoch: 85, loss: 0.177772
global_step: 3373, epoch: 85, loss: 0.169073
global_step: 3374, epoch: 85, loss: 0.167263
global_step: 3375, epoch: 85, loss: 0.204032
global_step: 3376, epoch: 85, loss: 0.207796
global_step: 3377, epoch: 85, loss: 0.267844
global_step: 3378, epoch: 85, loss: 0.213339
global_step: 3379, epoch: 85, loss: 0.224073
global_step: 3380, epoch: 85, loss: 0.171959
global_step: 3381, epoch: 85, loss: 0.203285
global_step: 3382, epoch: 85, loss: 0.208117
global_step: 3383, epoch: 85, loss: 0.307976
global_step: 3384, epoch: 85, loss: 0.366085
global_step: 3385, epoch: 85, loss: 0.123287
global_step: 3386, epoch: 85, loss: 0.191354
global_step: 3387, epoch: 85, loss: 0.238569
global_step: 3388, epoch: 85, loss: 0.242315
global_step: 3389, epoch: 85, loss: 0.232868
global_step: 3390, epoch: 85, loss: 0.179274
global_step: 3391, epoch: 85, loss: 0.184429
global_step: 3392, epoch: 85, loss: 0.180732
global_step: 3393, epoch: 85, loss: 0.258385
global_step: 3394, epoch: 85, loss: 0.221829
global_step: 3395, epoch: 85, loss: 0.280139
global_step: 3396, epoch: 85, loss: 0.245986
global_step: 3397, epoch: 85, loss: 0.283023
global_step: 3398, epoch: 85, loss: 0.214293
global_step: 3399, epoch: 85, loss: 0.278850
global_step: 3400, epoch: 85, loss: 0.121907
epoch: 85
train	acc: 0.9706	macro: p 0.9720, r 0.9614, f1: 0.9665	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5212	macro: p 0.4035, r 0.3324, f1: 0.3496	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4909
test	acc: 0.5640	macro: p 0.3551, r 0.3199, f1: 0.3292	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5376
global_step: 3401, epoch: 86, loss: 0.281200
global_step: 3402, epoch: 86, loss: 0.192568
global_step: 3403, epoch: 86, loss: 0.237821
global_step: 3404, epoch: 86, loss: 0.201793
global_step: 3405, epoch: 86, loss: 0.174040
global_step: 3406, epoch: 86, loss: 0.201278
global_step: 3407, epoch: 86, loss: 0.254775
global_step: 3408, epoch: 86, loss: 0.172171
global_step: 3409, epoch: 86, loss: 0.270411
global_step: 3410, epoch: 86, loss: 0.189288
global_step: 3411, epoch: 86, loss: 0.165279
global_step: 3412, epoch: 86, loss: 0.270932
global_step: 3413, epoch: 86, loss: 0.173104
global_step: 3414, epoch: 86, loss: 0.226304
global_step: 3415, epoch: 86, loss: 0.260421
global_step: 3416, epoch: 86, loss: 0.208168
global_step: 3417, epoch: 86, loss: 0.216151
global_step: 3418, epoch: 86, loss: 0.205619
global_step: 3419, epoch: 86, loss: 0.237499
global_step: 3420, epoch: 86, loss: 0.289575
global_step: 3421, epoch: 86, loss: 0.250674
global_step: 3422, epoch: 86, loss: 0.201711
global_step: 3423, epoch: 86, loss: 0.314895
global_step: 3424, epoch: 86, loss: 0.201322
global_step: 3425, epoch: 86, loss: 0.239782
global_step: 3426, epoch: 86, loss: 0.236923
global_step: 3427, epoch: 86, loss: 0.130500
global_step: 3428, epoch: 86, loss: 0.182361
global_step: 3429, epoch: 86, loss: 0.180811
global_step: 3430, epoch: 86, loss: 0.158411
global_step: 3431, epoch: 86, loss: 0.222585
global_step: 3432, epoch: 86, loss: 0.284646
global_step: 3433, epoch: 86, loss: 0.226386
global_step: 3434, epoch: 86, loss: 0.221586
global_step: 3435, epoch: 86, loss: 0.212502
global_step: 3436, epoch: 86, loss: 0.252719
global_step: 3437, epoch: 86, loss: 0.175517
global_step: 3438, epoch: 86, loss: 0.256694
global_step: 3439, epoch: 86, loss: 0.267904
global_step: 3440, epoch: 86, loss: 0.099590
epoch: 86
train	acc: 0.9690	macro: p 0.9718, r 0.9578, f1: 0.9645	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5230	macro: p 0.4343, r 0.3204, f1: 0.3361	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4793
test	acc: 0.5724	macro: p 0.3713, r 0.3130, f1: 0.3201	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5330
global_step: 3441, epoch: 87, loss: 0.262053
global_step: 3442, epoch: 87, loss: 0.162252
global_step: 3443, epoch: 87, loss: 0.192030
global_step: 3444, epoch: 87, loss: 0.235203
global_step: 3445, epoch: 87, loss: 0.251479
global_step: 3446, epoch: 87, loss: 0.271693
global_step: 3447, epoch: 87, loss: 0.289491
global_step: 3448, epoch: 87, loss: 0.158664
global_step: 3449, epoch: 87, loss: 0.197207
global_step: 3450, epoch: 87, loss: 0.166331
global_step: 3451, epoch: 87, loss: 0.204075
global_step: 3452, epoch: 87, loss: 0.214691
global_step: 3453, epoch: 87, loss: 0.215293
global_step: 3454, epoch: 87, loss: 0.230787
global_step: 3455, epoch: 87, loss: 0.269714
global_step: 3456, epoch: 87, loss: 0.264461
global_step: 3457, epoch: 87, loss: 0.217278
global_step: 3458, epoch: 87, loss: 0.189113
global_step: 3459, epoch: 87, loss: 0.184864
global_step: 3460, epoch: 87, loss: 0.277296
global_step: 3461, epoch: 87, loss: 0.200379
global_step: 3462, epoch: 87, loss: 0.266322
global_step: 3463, epoch: 87, loss: 0.194034
global_step: 3464, epoch: 87, loss: 0.290197
global_step: 3465, epoch: 87, loss: 0.213300
global_step: 3466, epoch: 87, loss: 0.192140
global_step: 3467, epoch: 87, loss: 0.178608
global_step: 3468, epoch: 87, loss: 0.223330
global_step: 3469, epoch: 87, loss: 0.239637
global_step: 3470, epoch: 87, loss: 0.218702
global_step: 3471, epoch: 87, loss: 0.201159
global_step: 3472, epoch: 87, loss: 0.185980
global_step: 3473, epoch: 87, loss: 0.160309
global_step: 3474, epoch: 87, loss: 0.210738
global_step: 3475, epoch: 87, loss: 0.201225
global_step: 3476, epoch: 87, loss: 0.198365
global_step: 3477, epoch: 87, loss: 0.202550
global_step: 3478, epoch: 87, loss: 0.255652
global_step: 3479, epoch: 87, loss: 0.207986
global_step: 3480, epoch: 87, loss: 0.473878
epoch: 87
train	acc: 0.9692	macro: p 0.9720, r 0.9581, f1: 0.9648	micro: p 0.9692, r 0.9692, f1 0.9692	weighted_f1:0.9692
dev	acc: 0.5329	macro: p 0.4796, r 0.3304, f1: 0.3449	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4954
test	acc: 0.5766	macro: p 0.3738, r 0.3236, f1: 0.3254	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5424
global_step: 3481, epoch: 88, loss: 0.250296
global_step: 3482, epoch: 88, loss: 0.264430
global_step: 3483, epoch: 88, loss: 0.205216
global_step: 3484, epoch: 88, loss: 0.209185
global_step: 3485, epoch: 88, loss: 0.183770
global_step: 3486, epoch: 88, loss: 0.207585
global_step: 3487, epoch: 88, loss: 0.186752
global_step: 3488, epoch: 88, loss: 0.226415
global_step: 3489, epoch: 88, loss: 0.169773
global_step: 3490, epoch: 88, loss: 0.242939
global_step: 3491, epoch: 88, loss: 0.220316
global_step: 3492, epoch: 88, loss: 0.274171
global_step: 3493, epoch: 88, loss: 0.292725
global_step: 3494, epoch: 88, loss: 0.154077
global_step: 3495, epoch: 88, loss: 0.259498
global_step: 3496, epoch: 88, loss: 0.215036
global_step: 3497, epoch: 88, loss: 0.240962
global_step: 3498, epoch: 88, loss: 0.311744
global_step: 3499, epoch: 88, loss: 0.172677
global_step: 3500, epoch: 88, loss: 0.311985
global_step: 3501, epoch: 88, loss: 0.254007
global_step: 3502, epoch: 88, loss: 0.161616
global_step: 3503, epoch: 88, loss: 0.175371
global_step: 3504, epoch: 88, loss: 0.233721
global_step: 3505, epoch: 88, loss: 0.262939
global_step: 3506, epoch: 88, loss: 0.223873
global_step: 3507, epoch: 88, loss: 0.204135
global_step: 3508, epoch: 88, loss: 0.271275
global_step: 3509, epoch: 88, loss: 0.237473
global_step: 3510, epoch: 88, loss: 0.242009
global_step: 3511, epoch: 88, loss: 0.258038
global_step: 3512, epoch: 88, loss: 0.196627
global_step: 3513, epoch: 88, loss: 0.215819
global_step: 3514, epoch: 88, loss: 0.134900
global_step: 3515, epoch: 88, loss: 0.195407
global_step: 3516, epoch: 88, loss: 0.229699
global_step: 3517, epoch: 88, loss: 0.224392
global_step: 3518, epoch: 88, loss: 0.191723
global_step: 3519, epoch: 88, loss: 0.207927
global_step: 3520, epoch: 88, loss: 0.192933
epoch: 88
train	acc: 0.9677	macro: p 0.9752, r 0.9531, f1: 0.9639	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9676
dev	acc: 0.5401	macro: p 0.4529, r 0.3235, f1: 0.3451	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4958
test	acc: 0.5759	macro: p 0.3705, r 0.3090, f1: 0.3200	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5385
global_step: 3521, epoch: 89, loss: 0.254768
global_step: 3522, epoch: 89, loss: 0.210330
global_step: 3523, epoch: 89, loss: 0.247864
global_step: 3524, epoch: 89, loss: 0.213002
global_step: 3525, epoch: 89, loss: 0.185680
global_step: 3526, epoch: 89, loss: 0.237347
global_step: 3527, epoch: 89, loss: 0.209777
global_step: 3528, epoch: 89, loss: 0.225510
global_step: 3529, epoch: 89, loss: 0.206161
global_step: 3530, epoch: 89, loss: 0.200441
global_step: 3531, epoch: 89, loss: 0.204831
global_step: 3532, epoch: 89, loss: 0.236183
global_step: 3533, epoch: 89, loss: 0.193310
global_step: 3534, epoch: 89, loss: 0.222764
global_step: 3535, epoch: 89, loss: 0.171964
global_step: 3536, epoch: 89, loss: 0.162572
global_step: 3537, epoch: 89, loss: 0.231092
global_step: 3538, epoch: 89, loss: 0.280882
global_step: 3539, epoch: 89, loss: 0.164118
global_step: 3540, epoch: 89, loss: 0.310847
global_step: 3541, epoch: 89, loss: 0.223107
global_step: 3542, epoch: 89, loss: 0.202574
global_step: 3543, epoch: 89, loss: 0.202183
global_step: 3544, epoch: 89, loss: 0.164547
global_step: 3545, epoch: 89, loss: 0.252355
global_step: 3546, epoch: 89, loss: 0.217790
global_step: 3547, epoch: 89, loss: 0.173320
global_step: 3548, epoch: 89, loss: 0.196663
global_step: 3549, epoch: 89, loss: 0.205938
global_step: 3550, epoch: 89, loss: 0.227670
global_step: 3551, epoch: 89, loss: 0.209656
global_step: 3552, epoch: 89, loss: 0.258538
global_step: 3553, epoch: 89, loss: 0.164437
global_step: 3554, epoch: 89, loss: 0.251226
global_step: 3555, epoch: 89, loss: 0.247806
global_step: 3556, epoch: 89, loss: 0.146194
global_step: 3557, epoch: 89, loss: 0.213103
global_step: 3558, epoch: 89, loss: 0.226507
global_step: 3559, epoch: 89, loss: 0.263639
global_step: 3560, epoch: 89, loss: 1.496725
epoch: 89
train	acc: 0.9695	macro: p 0.9706, r 0.9579, f1: 0.9639	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5293	macro: p 0.4549, r 0.3282, f1: 0.3439	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4953
test	acc: 0.5682	macro: p 0.3676, r 0.3149, f1: 0.3178	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5357
global_step: 3561, epoch: 90, loss: 0.312156
global_step: 3562, epoch: 90, loss: 0.264535
global_step: 3563, epoch: 90, loss: 0.147006
global_step: 3564, epoch: 90, loss: 0.218552
global_step: 3565, epoch: 90, loss: 0.173519
global_step: 3566, epoch: 90, loss: 0.268348
global_step: 3567, epoch: 90, loss: 0.209621
global_step: 3568, epoch: 90, loss: 0.191916
global_step: 3569, epoch: 90, loss: 0.350563
global_step: 3570, epoch: 90, loss: 0.218436
global_step: 3571, epoch: 90, loss: 0.241311
global_step: 3572, epoch: 90, loss: 0.208802
global_step: 3573, epoch: 90, loss: 0.247898
global_step: 3574, epoch: 90, loss: 0.161091
global_step: 3575, epoch: 90, loss: 0.209799
global_step: 3576, epoch: 90, loss: 0.215511
global_step: 3577, epoch: 90, loss: 0.210776
global_step: 3578, epoch: 90, loss: 0.227494
global_step: 3579, epoch: 90, loss: 0.181521
global_step: 3580, epoch: 90, loss: 0.195496
global_step: 3581, epoch: 90, loss: 0.168205
global_step: 3582, epoch: 90, loss: 0.216707
global_step: 3583, epoch: 90, loss: 0.283425
global_step: 3584, epoch: 90, loss: 0.140452
global_step: 3585, epoch: 90, loss: 0.197621
global_step: 3586, epoch: 90, loss: 0.177918
global_step: 3587, epoch: 90, loss: 0.277797
global_step: 3588, epoch: 90, loss: 0.191327
global_step: 3589, epoch: 90, loss: 0.161689
global_step: 3590, epoch: 90, loss: 0.275667
global_step: 3591, epoch: 90, loss: 0.268580
global_step: 3592, epoch: 90, loss: 0.182207
global_step: 3593, epoch: 90, loss: 0.187835
global_step: 3594, epoch: 90, loss: 0.233572
global_step: 3595, epoch: 90, loss: 0.124359
global_step: 3596, epoch: 90, loss: 0.235766
global_step: 3597, epoch: 90, loss: 0.270104
global_step: 3598, epoch: 90, loss: 0.258167
global_step: 3599, epoch: 90, loss: 0.250907
global_step: 3600, epoch: 90, loss: 0.004305
epoch: 90
train	acc: 0.9710	macro: p 0.9742, r 0.9590, f1: 0.9663	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5194	macro: p 0.4381, r 0.3086, f1: 0.3229	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4801
test	acc: 0.5690	macro: p 0.3661, r 0.3127, f1: 0.3215	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5346
global_step: 3601, epoch: 91, loss: 0.166520
global_step: 3602, epoch: 91, loss: 0.152828
global_step: 3603, epoch: 91, loss: 0.223747
global_step: 3604, epoch: 91, loss: 0.179095
global_step: 3605, epoch: 91, loss: 0.216559
global_step: 3606, epoch: 91, loss: 0.187439
global_step: 3607, epoch: 91, loss: 0.220927
global_step: 3608, epoch: 91, loss: 0.238508
global_step: 3609, epoch: 91, loss: 0.241417
global_step: 3610, epoch: 91, loss: 0.178866
global_step: 3611, epoch: 91, loss: 0.258929
global_step: 3612, epoch: 91, loss: 0.243131
global_step: 3613, epoch: 91, loss: 0.157246
global_step: 3614, epoch: 91, loss: 0.248066
global_step: 3615, epoch: 91, loss: 0.182202
global_step: 3616, epoch: 91, loss: 0.199279
global_step: 3617, epoch: 91, loss: 0.179614
global_step: 3618, epoch: 91, loss: 0.259040
global_step: 3619, epoch: 91, loss: 0.276348
global_step: 3620, epoch: 91, loss: 0.217422
global_step: 3621, epoch: 91, loss: 0.263393
global_step: 3622, epoch: 91, loss: 0.219002
global_step: 3623, epoch: 91, loss: 0.244316
global_step: 3624, epoch: 91, loss: 0.249045
global_step: 3625, epoch: 91, loss: 0.174969
global_step: 3626, epoch: 91, loss: 0.193485
global_step: 3627, epoch: 91, loss: 0.245062
global_step: 3628, epoch: 91, loss: 0.253298
global_step: 3629, epoch: 91, loss: 0.165655
global_step: 3630, epoch: 91, loss: 0.198730
global_step: 3631, epoch: 91, loss: 0.191488
global_step: 3632, epoch: 91, loss: 0.193453
global_step: 3633, epoch: 91, loss: 0.246697
global_step: 3634, epoch: 91, loss: 0.201423
global_step: 3635, epoch: 91, loss: 0.250343
global_step: 3636, epoch: 91, loss: 0.255299
global_step: 3637, epoch: 91, loss: 0.156686
global_step: 3638, epoch: 91, loss: 0.185264
global_step: 3639, epoch: 91, loss: 0.280531
global_step: 3640, epoch: 91, loss: 0.014002
epoch: 91
train	acc: 0.9704	macro: p 0.9741, r 0.9595, f1: 0.9666	micro: p 0.9704, r 0.9704, f1 0.9704	weighted_f1:0.9704
dev	acc: 0.5284	macro: p 0.3865, r 0.3124, f1: 0.3223	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4859
test	acc: 0.5663	macro: p 0.3477, r 0.3088, f1: 0.3131	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5295
global_step: 3641, epoch: 92, loss: 0.210134
global_step: 3642, epoch: 92, loss: 0.248315
global_step: 3643, epoch: 92, loss: 0.158793
global_step: 3644, epoch: 92, loss: 0.175320
global_step: 3645, epoch: 92, loss: 0.277190
global_step: 3646, epoch: 92, loss: 0.208790
global_step: 3647, epoch: 92, loss: 0.253705
global_step: 3648, epoch: 92, loss: 0.233316
global_step: 3649, epoch: 92, loss: 0.238276
global_step: 3650, epoch: 92, loss: 0.222781
global_step: 3651, epoch: 92, loss: 0.201079
global_step: 3652, epoch: 92, loss: 0.172843
global_step: 3653, epoch: 92, loss: 0.162881
global_step: 3654, epoch: 92, loss: 0.135666
global_step: 3655, epoch: 92, loss: 0.225505
global_step: 3656, epoch: 92, loss: 0.282178
global_step: 3657, epoch: 92, loss: 0.189618
global_step: 3658, epoch: 92, loss: 0.217178
global_step: 3659, epoch: 92, loss: 0.242515
global_step: 3660, epoch: 92, loss: 0.227702
global_step: 3661, epoch: 92, loss: 0.243596
global_step: 3662, epoch: 92, loss: 0.307683
global_step: 3663, epoch: 92, loss: 0.198685
global_step: 3664, epoch: 92, loss: 0.214434
global_step: 3665, epoch: 92, loss: 0.202273
global_step: 3666, epoch: 92, loss: 0.203324
global_step: 3667, epoch: 92, loss: 0.203714
global_step: 3668, epoch: 92, loss: 0.229244
global_step: 3669, epoch: 92, loss: 0.282746
global_step: 3670, epoch: 92, loss: 0.189036
global_step: 3671, epoch: 92, loss: 0.276154
global_step: 3672, epoch: 92, loss: 0.180905
global_step: 3673, epoch: 92, loss: 0.199420
global_step: 3674, epoch: 92, loss: 0.306514
global_step: 3675, epoch: 92, loss: 0.231669
global_step: 3676, epoch: 92, loss: 0.226657
global_step: 3677, epoch: 92, loss: 0.177189
global_step: 3678, epoch: 92, loss: 0.171252
global_step: 3679, epoch: 92, loss: 0.267267
global_step: 3680, epoch: 92, loss: 0.005072
epoch: 92
train	acc: 0.9720	macro: p 0.9751, r 0.9613, f1: 0.9679	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5113	macro: p 0.4337, r 0.3141, f1: 0.3304	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4782
test	acc: 0.5670	macro: p 0.3524, r 0.3146, f1: 0.3211	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5362
global_step: 3681, epoch: 93, loss: 0.247501
global_step: 3682, epoch: 93, loss: 0.155661
global_step: 3683, epoch: 93, loss: 0.200665
global_step: 3684, epoch: 93, loss: 0.172261
global_step: 3685, epoch: 93, loss: 0.174833
global_step: 3686, epoch: 93, loss: 0.174068
global_step: 3687, epoch: 93, loss: 0.212056
global_step: 3688, epoch: 93, loss: 0.190986
global_step: 3689, epoch: 93, loss: 0.191745
global_step: 3690, epoch: 93, loss: 0.187013
global_step: 3691, epoch: 93, loss: 0.234164
global_step: 3692, epoch: 93, loss: 0.280328
global_step: 3693, epoch: 93, loss: 0.298491
global_step: 3694, epoch: 93, loss: 0.214327
global_step: 3695, epoch: 93, loss: 0.253734
global_step: 3696, epoch: 93, loss: 0.222914
global_step: 3697, epoch: 93, loss: 0.183045
global_step: 3698, epoch: 93, loss: 0.168861
global_step: 3699, epoch: 93, loss: 0.215621
global_step: 3700, epoch: 93, loss: 0.259952
global_step: 3701, epoch: 93, loss: 0.147686
global_step: 3702, epoch: 93, loss: 0.279978
global_step: 3703, epoch: 93, loss: 0.222477
global_step: 3704, epoch: 93, loss: 0.222785
global_step: 3705, epoch: 93, loss: 0.162588
global_step: 3706, epoch: 93, loss: 0.192767
global_step: 3707, epoch: 93, loss: 0.189193
global_step: 3708, epoch: 93, loss: 0.159720
global_step: 3709, epoch: 93, loss: 0.250378
global_step: 3710, epoch: 93, loss: 0.211258
global_step: 3711, epoch: 93, loss: 0.306595
global_step: 3712, epoch: 93, loss: 0.100987
global_step: 3713, epoch: 93, loss: 0.201439
global_step: 3714, epoch: 93, loss: 0.227740
global_step: 3715, epoch: 93, loss: 0.334177
global_step: 3716, epoch: 93, loss: 0.234394
global_step: 3717, epoch: 93, loss: 0.245048
global_step: 3718, epoch: 93, loss: 0.272056
global_step: 3719, epoch: 93, loss: 0.195661
global_step: 3720, epoch: 93, loss: 0.000795
epoch: 93
train	acc: 0.9696	macro: p 0.9744, r 0.9574, f1: 0.9656	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5266	macro: p 0.4337, r 0.3210, f1: 0.3367	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4880
test	acc: 0.5716	macro: p 0.3682, r 0.3094, f1: 0.3173	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5354
global_step: 3721, epoch: 94, loss: 0.158828
global_step: 3722, epoch: 94, loss: 0.227040
global_step: 3723, epoch: 94, loss: 0.173374
global_step: 3724, epoch: 94, loss: 0.214841
global_step: 3725, epoch: 94, loss: 0.194845
global_step: 3726, epoch: 94, loss: 0.180197
global_step: 3727, epoch: 94, loss: 0.182941
global_step: 3728, epoch: 94, loss: 0.145208
global_step: 3729, epoch: 94, loss: 0.209003
global_step: 3730, epoch: 94, loss: 0.217413
global_step: 3731, epoch: 94, loss: 0.222512
global_step: 3732, epoch: 94, loss: 0.212644
global_step: 3733, epoch: 94, loss: 0.147388
global_step: 3734, epoch: 94, loss: 0.160071
global_step: 3735, epoch: 94, loss: 0.153067
global_step: 3736, epoch: 94, loss: 0.210101
global_step: 3737, epoch: 94, loss: 0.218861
global_step: 3738, epoch: 94, loss: 0.214885
global_step: 3739, epoch: 94, loss: 0.211649
global_step: 3740, epoch: 94, loss: 0.171771
global_step: 3741, epoch: 94, loss: 0.314967
global_step: 3742, epoch: 94, loss: 0.217474
global_step: 3743, epoch: 94, loss: 0.203966
global_step: 3744, epoch: 94, loss: 0.194523
global_step: 3745, epoch: 94, loss: 0.186734
global_step: 3746, epoch: 94, loss: 0.226378
global_step: 3747, epoch: 94, loss: 0.175440
global_step: 3748, epoch: 94, loss: 0.196606
global_step: 3749, epoch: 94, loss: 0.261127
global_step: 3750, epoch: 94, loss: 0.209359
global_step: 3751, epoch: 94, loss: 0.203579
global_step: 3752, epoch: 94, loss: 0.205968
global_step: 3753, epoch: 94, loss: 0.231675
global_step: 3754, epoch: 94, loss: 0.234321
global_step: 3755, epoch: 94, loss: 0.266613
global_step: 3756, epoch: 94, loss: 0.216547
global_step: 3757, epoch: 94, loss: 0.213668
global_step: 3758, epoch: 94, loss: 0.246776
global_step: 3759, epoch: 94, loss: 0.210948
global_step: 3760, epoch: 94, loss: 0.206430
epoch: 94
train	acc: 0.9698	macro: p 0.9740, r 0.9591, f1: 0.9664	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5383	macro: p 0.4494, r 0.3190, f1: 0.3361	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4946
test	acc: 0.5774	macro: p 0.3749, r 0.3091, f1: 0.3183	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5363
global_step: 3761, epoch: 95, loss: 0.217388
global_step: 3762, epoch: 95, loss: 0.137484
global_step: 3763, epoch: 95, loss: 0.180232
global_step: 3764, epoch: 95, loss: 0.211363
global_step: 3765, epoch: 95, loss: 0.205754
global_step: 3766, epoch: 95, loss: 0.180391
global_step: 3767, epoch: 95, loss: 0.202074
global_step: 3768, epoch: 95, loss: 0.186402
global_step: 3769, epoch: 95, loss: 0.278577
global_step: 3770, epoch: 95, loss: 0.151738
global_step: 3771, epoch: 95, loss: 0.188552
global_step: 3772, epoch: 95, loss: 0.195262
global_step: 3773, epoch: 95, loss: 0.233378
global_step: 3774, epoch: 95, loss: 0.314256
global_step: 3775, epoch: 95, loss: 0.197725
global_step: 3776, epoch: 95, loss: 0.178740
global_step: 3777, epoch: 95, loss: 0.234385
global_step: 3778, epoch: 95, loss: 0.209120
global_step: 3779, epoch: 95, loss: 0.219719
global_step: 3780, epoch: 95, loss: 0.225884
global_step: 3781, epoch: 95, loss: 0.270019
global_step: 3782, epoch: 95, loss: 0.198521
global_step: 3783, epoch: 95, loss: 0.310206
global_step: 3784, epoch: 95, loss: 0.272050
global_step: 3785, epoch: 95, loss: 0.196340
global_step: 3786, epoch: 95, loss: 0.215446
global_step: 3787, epoch: 95, loss: 0.229459
global_step: 3788, epoch: 95, loss: 0.215114
global_step: 3789, epoch: 95, loss: 0.209310
global_step: 3790, epoch: 95, loss: 0.290229
global_step: 3791, epoch: 95, loss: 0.219949
global_step: 3792, epoch: 95, loss: 0.167764
global_step: 3793, epoch: 95, loss: 0.170544
global_step: 3794, epoch: 95, loss: 0.218874
global_step: 3795, epoch: 95, loss: 0.265059
global_step: 3796, epoch: 95, loss: 0.239976
global_step: 3797, epoch: 95, loss: 0.242564
global_step: 3798, epoch: 95, loss: 0.274348
global_step: 3799, epoch: 95, loss: 0.215054
global_step: 3800, epoch: 95, loss: 0.129833
epoch: 95
train	acc: 0.9715	macro: p 0.9758, r 0.9593, f1: 0.9672	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5167	macro: p 0.4307, r 0.3120, f1: 0.3287	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4794
test	acc: 0.5789	macro: p 0.3731, r 0.3176, f1: 0.3265	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5442
global_step: 3801, epoch: 96, loss: 0.234431
global_step: 3802, epoch: 96, loss: 0.210355
global_step: 3803, epoch: 96, loss: 0.210492
global_step: 3804, epoch: 96, loss: 0.146995
global_step: 3805, epoch: 96, loss: 0.189646
global_step: 3806, epoch: 96, loss: 0.166446
global_step: 3807, epoch: 96, loss: 0.261481
global_step: 3808, epoch: 96, loss: 0.207575
global_step: 3809, epoch: 96, loss: 0.186056
global_step: 3810, epoch: 96, loss: 0.214658
global_step: 3811, epoch: 96, loss: 0.240003
global_step: 3812, epoch: 96, loss: 0.197543
global_step: 3813, epoch: 96, loss: 0.254109
global_step: 3814, epoch: 96, loss: 0.200654
global_step: 3815, epoch: 96, loss: 0.155948
global_step: 3816, epoch: 96, loss: 0.192363
global_step: 3817, epoch: 96, loss: 0.184054
global_step: 3818, epoch: 96, loss: 0.192381
global_step: 3819, epoch: 96, loss: 0.149218
global_step: 3820, epoch: 96, loss: 0.206549
global_step: 3821, epoch: 96, loss: 0.262898
global_step: 3822, epoch: 96, loss: 0.181822
global_step: 3823, epoch: 96, loss: 0.259314
global_step: 3824, epoch: 96, loss: 0.217061
global_step: 3825, epoch: 96, loss: 0.270627
global_step: 3826, epoch: 96, loss: 0.172110
global_step: 3827, epoch: 96, loss: 0.183011
global_step: 3828, epoch: 96, loss: 0.243341
global_step: 3829, epoch: 96, loss: 0.170673
global_step: 3830, epoch: 96, loss: 0.193820
global_step: 3831, epoch: 96, loss: 0.328884
global_step: 3832, epoch: 96, loss: 0.227542
global_step: 3833, epoch: 96, loss: 0.153295
global_step: 3834, epoch: 96, loss: 0.212301
global_step: 3835, epoch: 96, loss: 0.237146
global_step: 3836, epoch: 96, loss: 0.171311
global_step: 3837, epoch: 96, loss: 0.159341
global_step: 3838, epoch: 96, loss: 0.179595
global_step: 3839, epoch: 96, loss: 0.179650
global_step: 3840, epoch: 96, loss: 0.835119
epoch: 96
train	acc: 0.9696	macro: p 0.9746, r 0.9569, f1: 0.9655	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9695
dev	acc: 0.5230	macro: p 0.4774, r 0.3153, f1: 0.3333	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4794
test	acc: 0.5720	macro: p 0.3679, r 0.3085, f1: 0.3156	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5357
global_step: 3841, epoch: 97, loss: 0.132040
global_step: 3842, epoch: 97, loss: 0.211358
global_step: 3843, epoch: 97, loss: 0.167728
global_step: 3844, epoch: 97, loss: 0.173770
global_step: 3845, epoch: 97, loss: 0.217465
global_step: 3846, epoch: 97, loss: 0.251281
global_step: 3847, epoch: 97, loss: 0.265773
global_step: 3848, epoch: 97, loss: 0.213962
global_step: 3849, epoch: 97, loss: 0.231088
global_step: 3850, epoch: 97, loss: 0.261811
global_step: 3851, epoch: 97, loss: 0.258467
global_step: 3852, epoch: 97, loss: 0.186520
global_step: 3853, epoch: 97, loss: 0.172038
global_step: 3854, epoch: 97, loss: 0.205906
global_step: 3855, epoch: 97, loss: 0.173851
global_step: 3856, epoch: 97, loss: 0.215008
global_step: 3857, epoch: 97, loss: 0.204610
global_step: 3858, epoch: 97, loss: 0.225854
global_step: 3859, epoch: 97, loss: 0.211240
global_step: 3860, epoch: 97, loss: 0.170568
global_step: 3861, epoch: 97, loss: 0.263832
global_step: 3862, epoch: 97, loss: 0.238220
global_step: 3863, epoch: 97, loss: 0.202555
global_step: 3864, epoch: 97, loss: 0.196214
global_step: 3865, epoch: 97, loss: 0.170520
global_step: 3866, epoch: 97, loss: 0.237942
global_step: 3867, epoch: 97, loss: 0.163212
global_step: 3868, epoch: 97, loss: 0.257826
global_step: 3869, epoch: 97, loss: 0.191789
global_step: 3870, epoch: 97, loss: 0.139436
global_step: 3871, epoch: 97, loss: 0.317200
global_step: 3872, epoch: 97, loss: 0.280233
global_step: 3873, epoch: 97, loss: 0.139356
global_step: 3874, epoch: 97, loss: 0.233273
global_step: 3875, epoch: 97, loss: 0.224310
global_step: 3876, epoch: 97, loss: 0.227216
global_step: 3877, epoch: 97, loss: 0.298678
global_step: 3878, epoch: 97, loss: 0.142407
global_step: 3879, epoch: 97, loss: 0.211626
global_step: 3880, epoch: 97, loss: 0.576113
epoch: 97
train	acc: 0.9692	macro: p 0.9748, r 0.9563, f1: 0.9653	micro: p 0.9692, r 0.9692, f1 0.9692	weighted_f1:0.9691
dev	acc: 0.5167	macro: p 0.4538, r 0.3245, f1: 0.3429	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4803
test	acc: 0.5628	macro: p 0.3558, r 0.3089, f1: 0.3155	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5315
global_step: 3881, epoch: 98, loss: 0.149760
global_step: 3882, epoch: 98, loss: 0.203198
global_step: 3883, epoch: 98, loss: 0.173203
global_step: 3884, epoch: 98, loss: 0.150803
global_step: 3885, epoch: 98, loss: 0.248790
global_step: 3886, epoch: 98, loss: 0.204479
global_step: 3887, epoch: 98, loss: 0.189550
global_step: 3888, epoch: 98, loss: 0.253965
global_step: 3889, epoch: 98, loss: 0.214606
global_step: 3890, epoch: 98, loss: 0.176664
global_step: 3891, epoch: 98, loss: 0.260625
global_step: 3892, epoch: 98, loss: 0.221362
global_step: 3893, epoch: 98, loss: 0.174369
global_step: 3894, epoch: 98, loss: 0.153081
global_step: 3895, epoch: 98, loss: 0.157440
global_step: 3896, epoch: 98, loss: 0.231788
global_step: 3897, epoch: 98, loss: 0.180426
global_step: 3898, epoch: 98, loss: 0.216839
global_step: 3899, epoch: 98, loss: 0.205806
global_step: 3900, epoch: 98, loss: 0.220309
global_step: 3901, epoch: 98, loss: 0.175217
global_step: 3902, epoch: 98, loss: 0.155458
global_step: 3903, epoch: 98, loss: 0.189934
global_step: 3904, epoch: 98, loss: 0.187051
global_step: 3905, epoch: 98, loss: 0.262700
global_step: 3906, epoch: 98, loss: 0.164284
global_step: 3907, epoch: 98, loss: 0.210810
global_step: 3908, epoch: 98, loss: 0.190375
global_step: 3909, epoch: 98, loss: 0.142932
global_step: 3910, epoch: 98, loss: 0.209485
global_step: 3911, epoch: 98, loss: 0.157438
global_step: 3912, epoch: 98, loss: 0.230339
global_step: 3913, epoch: 98, loss: 0.126056
global_step: 3914, epoch: 98, loss: 0.207455
global_step: 3915, epoch: 98, loss: 0.238647
global_step: 3916, epoch: 98, loss: 0.204511
global_step: 3917, epoch: 98, loss: 0.234313
global_step: 3918, epoch: 98, loss: 0.144556
global_step: 3919, epoch: 98, loss: 0.218317
global_step: 3920, epoch: 98, loss: 0.615919
epoch: 98
train	acc: 0.9706	macro: p 0.9738, r 0.9617, f1: 0.9675	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5158	macro: p 0.4500, r 0.3197, f1: 0.3342	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4811
test	acc: 0.5590	macro: p 0.3660, r 0.3154, f1: 0.3196	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5288
global_step: 3921, epoch: 99, loss: 0.210573
global_step: 3922, epoch: 99, loss: 0.135648
global_step: 3923, epoch: 99, loss: 0.173126
global_step: 3924, epoch: 99, loss: 0.183663
global_step: 3925, epoch: 99, loss: 0.154431
global_step: 3926, epoch: 99, loss: 0.184836
global_step: 3927, epoch: 99, loss: 0.175501
global_step: 3928, epoch: 99, loss: 0.163827
global_step: 3929, epoch: 99, loss: 0.166129
global_step: 3930, epoch: 99, loss: 0.157412
global_step: 3931, epoch: 99, loss: 0.189868
global_step: 3932, epoch: 99, loss: 0.157391
global_step: 3933, epoch: 99, loss: 0.211365
global_step: 3934, epoch: 99, loss: 0.213770
global_step: 3935, epoch: 99, loss: 0.155727
global_step: 3936, epoch: 99, loss: 0.232822
global_step: 3937, epoch: 99, loss: 0.263300
global_step: 3938, epoch: 99, loss: 0.175921
global_step: 3939, epoch: 99, loss: 0.205053
global_step: 3940, epoch: 99, loss: 0.191981
global_step: 3941, epoch: 99, loss: 0.224644
global_step: 3942, epoch: 99, loss: 0.155848
global_step: 3943, epoch: 99, loss: 0.235920
global_step: 3944, epoch: 99, loss: 0.220016
global_step: 3945, epoch: 99, loss: 0.159636
global_step: 3946, epoch: 99, loss: 0.338859
global_step: 3947, epoch: 99, loss: 0.211379
global_step: 3948, epoch: 99, loss: 0.224842
global_step: 3949, epoch: 99, loss: 0.161717
global_step: 3950, epoch: 99, loss: 0.197240
global_step: 3951, epoch: 99, loss: 0.223796
global_step: 3952, epoch: 99, loss: 0.167788
global_step: 3953, epoch: 99, loss: 0.178805
global_step: 3954, epoch: 99, loss: 0.208356
global_step: 3955, epoch: 99, loss: 0.218824
global_step: 3956, epoch: 99, loss: 0.244915
global_step: 3957, epoch: 99, loss: 0.260135
global_step: 3958, epoch: 99, loss: 0.202691
global_step: 3959, epoch: 99, loss: 0.173839
global_step: 3960, epoch: 99, loss: 0.126213
epoch: 99
train	acc: 0.9709	macro: p 0.9731, r 0.9613, f1: 0.9670	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5293	macro: p 0.4202, r 0.3192, f1: 0.3344	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4905
test	acc: 0.5713	macro: p 0.3581, r 0.3121, f1: 0.3208	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5372
global_step: 3961, epoch: 100, loss: 0.098743
global_step: 3962, epoch: 100, loss: 0.167346
global_step: 3963, epoch: 100, loss: 0.124704
global_step: 3964, epoch: 100, loss: 0.149448
global_step: 3965, epoch: 100, loss: 0.160609
global_step: 3966, epoch: 100, loss: 0.163111
global_step: 3967, epoch: 100, loss: 0.210963
global_step: 3968, epoch: 100, loss: 0.384286
global_step: 3969, epoch: 100, loss: 0.177936
global_step: 3970, epoch: 100, loss: 0.171071
global_step: 3971, epoch: 100, loss: 0.239911
global_step: 3972, epoch: 100, loss: 0.182772
global_step: 3973, epoch: 100, loss: 0.209174
global_step: 3974, epoch: 100, loss: 0.226812
global_step: 3975, epoch: 100, loss: 0.213259
global_step: 3976, epoch: 100, loss: 0.173563
global_step: 3977, epoch: 100, loss: 0.219294
global_step: 3978, epoch: 100, loss: 0.207902
global_step: 3979, epoch: 100, loss: 0.134494
global_step: 3980, epoch: 100, loss: 0.235115
global_step: 3981, epoch: 100, loss: 0.212796
global_step: 3982, epoch: 100, loss: 0.211601
global_step: 3983, epoch: 100, loss: 0.213624
global_step: 3984, epoch: 100, loss: 0.191370
global_step: 3985, epoch: 100, loss: 0.177796
global_step: 3986, epoch: 100, loss: 0.181253
global_step: 3987, epoch: 100, loss: 0.230828
global_step: 3988, epoch: 100, loss: 0.171997
global_step: 3989, epoch: 100, loss: 0.202903
global_step: 3990, epoch: 100, loss: 0.193011
global_step: 3991, epoch: 100, loss: 0.217384
global_step: 3992, epoch: 100, loss: 0.248505
global_step: 3993, epoch: 100, loss: 0.203655
global_step: 3994, epoch: 100, loss: 0.251701
global_step: 3995, epoch: 100, loss: 0.206696
global_step: 3996, epoch: 100, loss: 0.169800
global_step: 3997, epoch: 100, loss: 0.218957
global_step: 3998, epoch: 100, loss: 0.232325
global_step: 3999, epoch: 100, loss: 0.201040
global_step: 4000, epoch: 100, loss: 0.333505
epoch: 100
train	acc: 0.9710	macro: p 0.9733, r 0.9614, f1: 0.9671	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5257	macro: p 0.4063, r 0.3105, f1: 0.3230	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4830
test	acc: 0.5774	macro: p 0.3622, r 0.3104, f1: 0.3183	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.5371
BEST MODEL epoch: 47
train	acc: 0.9600 macro_p: 0.9649 macro_r: 0.9416 macro_f1: 0.9525 micro_p: 0.9600 micro_r: 0.9600 micro_f1: 0.9600 weighted_f1: 0.9600
dev	acc: 0.5293 macro_p: 0.4100 macro_r: 0.3373 macro_f1: 0.3494 micro_p: 0.5293 micro_r: 0.5293 micro_f1: 0.5293 weighted_f1: 0.5004
test	acc: 0.5598 macro_p: 0.3575 macro_r: 0.3183 macro_f1: 0.3267 micro_p: 0.5598 micro_r: 0.5598 micro_f1: 0.5598 weighted_f1: 0.5355
==========ROUND 2==========
global_step: 4001, epoch: 1, loss: 2.025532
global_step: 4002, epoch: 1, loss: 1.794937
global_step: 4003, epoch: 1, loss: 1.648564
global_step: 4004, epoch: 1, loss: 1.523999
global_step: 4005, epoch: 1, loss: 1.491714
global_step: 4006, epoch: 1, loss: 1.498537
global_step: 4007, epoch: 1, loss: 1.548102
global_step: 4008, epoch: 1, loss: 1.531183
global_step: 4009, epoch: 1, loss: 1.406851
global_step: 4010, epoch: 1, loss: 1.461053
global_step: 4011, epoch: 1, loss: 1.434729
global_step: 4012, epoch: 1, loss: 1.500616
global_step: 4013, epoch: 1, loss: 1.434377
global_step: 4014, epoch: 1, loss: 1.340780
global_step: 4015, epoch: 1, loss: 1.456178
global_step: 4016, epoch: 1, loss: 1.471474
global_step: 4017, epoch: 1, loss: 1.516448
global_step: 4018, epoch: 1, loss: 1.481859
global_step: 4019, epoch: 1, loss: 1.380353
global_step: 4020, epoch: 1, loss: 1.409124
global_step: 4021, epoch: 1, loss: 1.457441
global_step: 4022, epoch: 1, loss: 1.444337
global_step: 4023, epoch: 1, loss: 1.376835
global_step: 4024, epoch: 1, loss: 1.274094
global_step: 4025, epoch: 1, loss: 1.444473
global_step: 4026, epoch: 1, loss: 1.435584
global_step: 4027, epoch: 1, loss: 1.393488
global_step: 4028, epoch: 1, loss: 1.402521
global_step: 4029, epoch: 1, loss: 1.352626
global_step: 4030, epoch: 1, loss: 1.404604
global_step: 4031, epoch: 1, loss: 1.193423
global_step: 4032, epoch: 1, loss: 1.425386
global_step: 4033, epoch: 1, loss: 1.413637
global_step: 4034, epoch: 1, loss: 1.353971
global_step: 4035, epoch: 1, loss: 1.365052
global_step: 4036, epoch: 1, loss: 1.365582
global_step: 4037, epoch: 1, loss: 1.468688
global_step: 4038, epoch: 1, loss: 1.402620
global_step: 4039, epoch: 1, loss: 1.385075
global_step: 4040, epoch: 1, loss: 1.416168
epoch: 1
train	acc: 0.5697	macro: p 0.2755, r 0.2716, f1: 0.2552	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5016
dev	acc: 0.5158	macro: p 0.2446, r 0.2614, f1: 0.2307	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4294
test	acc: 0.5659	macro: p 0.2582, r 0.2714, f1: 0.2466	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.4931
New best model!
global_step: 4041, epoch: 2, loss: 1.317255
global_step: 4042, epoch: 2, loss: 1.377879
global_step: 4043, epoch: 2, loss: 1.290506
global_step: 4044, epoch: 2, loss: 1.303949
global_step: 4045, epoch: 2, loss: 1.336159
global_step: 4046, epoch: 2, loss: 1.289854
global_step: 4047, epoch: 2, loss: 1.291404
global_step: 4048, epoch: 2, loss: 1.273409
global_step: 4049, epoch: 2, loss: 1.312005
global_step: 4050, epoch: 2, loss: 1.326767
global_step: 4051, epoch: 2, loss: 1.394907
global_step: 4052, epoch: 2, loss: 1.339697
global_step: 4053, epoch: 2, loss: 1.319169
global_step: 4054, epoch: 2, loss: 1.372559
global_step: 4055, epoch: 2, loss: 1.352086
global_step: 4056, epoch: 2, loss: 1.310498
global_step: 4057, epoch: 2, loss: 1.351765
global_step: 4058, epoch: 2, loss: 1.338711
global_step: 4059, epoch: 2, loss: 1.322791
global_step: 4060, epoch: 2, loss: 1.380476
global_step: 4061, epoch: 2, loss: 1.335896
global_step: 4062, epoch: 2, loss: 1.341055
global_step: 4063, epoch: 2, loss: 1.277488
global_step: 4064, epoch: 2, loss: 1.281507
global_step: 4065, epoch: 2, loss: 1.391611
global_step: 4066, epoch: 2, loss: 1.257198
global_step: 4067, epoch: 2, loss: 1.437083
global_step: 4068, epoch: 2, loss: 1.436263
global_step: 4069, epoch: 2, loss: 1.309265
global_step: 4070, epoch: 2, loss: 1.203727
global_step: 4071, epoch: 2, loss: 1.326567
global_step: 4072, epoch: 2, loss: 1.287589
global_step: 4073, epoch: 2, loss: 1.356587
global_step: 4074, epoch: 2, loss: 1.260103
global_step: 4075, epoch: 2, loss: 1.406570
global_step: 4076, epoch: 2, loss: 1.370344
global_step: 4077, epoch: 2, loss: 1.342987
global_step: 4078, epoch: 2, loss: 1.323287
global_step: 4079, epoch: 2, loss: 1.301441
global_step: 4080, epoch: 2, loss: 1.201822
epoch: 2
train	acc: 0.5603	macro: p 0.3915, r 0.2657, f1: 0.2326	micro: p 0.5603, r 0.5603, f1 0.5603	weighted_f1:0.4891
dev	acc: 0.4923	macro: p 0.2204, r 0.2586, f1: 0.2097	micro: p 0.4923, r 0.4923, f1 0.4923	weighted_f1:0.4109
test	acc: 0.5398	macro: p 0.2313, r 0.2620, f1: 0.2243	micro: p 0.5398, r 0.5398, f1 0.5398	weighted_f1:0.4690
global_step: 4081, epoch: 3, loss: 1.285797
global_step: 4082, epoch: 3, loss: 1.442877
global_step: 4083, epoch: 3, loss: 1.287034
global_step: 4084, epoch: 3, loss: 1.317336
global_step: 4085, epoch: 3, loss: 1.320357
global_step: 4086, epoch: 3, loss: 1.196606
global_step: 4087, epoch: 3, loss: 1.314768
global_step: 4088, epoch: 3, loss: 1.274735
global_step: 4089, epoch: 3, loss: 1.239788
global_step: 4090, epoch: 3, loss: 1.364435
global_step: 4091, epoch: 3, loss: 1.252379
global_step: 4092, epoch: 3, loss: 1.255089
global_step: 4093, epoch: 3, loss: 1.193663
global_step: 4094, epoch: 3, loss: 1.313426
global_step: 4095, epoch: 3, loss: 1.251236
global_step: 4096, epoch: 3, loss: 1.316996
global_step: 4097, epoch: 3, loss: 1.228861
global_step: 4098, epoch: 3, loss: 1.298971
global_step: 4099, epoch: 3, loss: 1.291496
global_step: 4100, epoch: 3, loss: 1.233065
global_step: 4101, epoch: 3, loss: 1.215182
global_step: 4102, epoch: 3, loss: 1.282609
global_step: 4103, epoch: 3, loss: 1.281896
global_step: 4104, epoch: 3, loss: 1.321296
global_step: 4105, epoch: 3, loss: 1.348991
global_step: 4106, epoch: 3, loss: 1.316438
global_step: 4107, epoch: 3, loss: 1.229910
global_step: 4108, epoch: 3, loss: 1.272397
global_step: 4109, epoch: 3, loss: 1.301771
global_step: 4110, epoch: 3, loss: 1.178289
global_step: 4111, epoch: 3, loss: 1.263512
global_step: 4112, epoch: 3, loss: 1.254837
global_step: 4113, epoch: 3, loss: 1.435004
global_step: 4114, epoch: 3, loss: 1.224805
global_step: 4115, epoch: 3, loss: 1.262637
global_step: 4116, epoch: 3, loss: 1.297098
global_step: 4117, epoch: 3, loss: 1.333302
global_step: 4118, epoch: 3, loss: 1.120560
global_step: 4119, epoch: 3, loss: 1.423329
global_step: 4120, epoch: 3, loss: 1.795702
epoch: 3
train	acc: 0.4008	macro: p 0.2919, r 0.2933, f1: 0.2464	micro: p 0.4008, r 0.4008, f1 0.4008	weighted_f1:0.4139
dev	acc: 0.3517	macro: p 0.2745, r 0.2678, f1: 0.2278	micro: p 0.3517, r 0.3517, f1 0.3517	weighted_f1:0.3485
test	acc: 0.3579	macro: p 0.2660, r 0.2721, f1: 0.2207	micro: p 0.3579, r 0.3579, f1 0.3579	weighted_f1:0.3707
global_step: 4121, epoch: 4, loss: 1.517402
global_step: 4122, epoch: 4, loss: 1.348614
global_step: 4123, epoch: 4, loss: 1.181460
global_step: 4124, epoch: 4, loss: 1.215880
global_step: 4125, epoch: 4, loss: 1.300069
global_step: 4126, epoch: 4, loss: 1.266277
global_step: 4127, epoch: 4, loss: 1.143461
global_step: 4128, epoch: 4, loss: 1.231111
global_step: 4129, epoch: 4, loss: 1.269745
global_step: 4130, epoch: 4, loss: 1.246751
global_step: 4131, epoch: 4, loss: 1.207567
global_step: 4132, epoch: 4, loss: 1.296815
global_step: 4133, epoch: 4, loss: 1.254885
global_step: 4134, epoch: 4, loss: 1.220601
global_step: 4135, epoch: 4, loss: 1.240748
global_step: 4136, epoch: 4, loss: 1.244321
global_step: 4137, epoch: 4, loss: 1.208419
global_step: 4138, epoch: 4, loss: 1.223963
global_step: 4139, epoch: 4, loss: 1.176378
global_step: 4140, epoch: 4, loss: 1.245853
global_step: 4141, epoch: 4, loss: 1.290234
global_step: 4142, epoch: 4, loss: 1.177748
global_step: 4143, epoch: 4, loss: 1.204935
global_step: 4144, epoch: 4, loss: 1.319218
global_step: 4145, epoch: 4, loss: 1.257008
global_step: 4146, epoch: 4, loss: 1.165674
global_step: 4147, epoch: 4, loss: 1.255041
global_step: 4148, epoch: 4, loss: 1.111333
global_step: 4149, epoch: 4, loss: 1.353618
global_step: 4150, epoch: 4, loss: 1.281782
global_step: 4151, epoch: 4, loss: 1.354549
global_step: 4152, epoch: 4, loss: 1.180418
global_step: 4153, epoch: 4, loss: 1.237723
global_step: 4154, epoch: 4, loss: 1.180228
global_step: 4155, epoch: 4, loss: 1.314422
global_step: 4156, epoch: 4, loss: 1.302615
global_step: 4157, epoch: 4, loss: 1.250533
global_step: 4158, epoch: 4, loss: 1.324576
global_step: 4159, epoch: 4, loss: 1.302622
global_step: 4160, epoch: 4, loss: 1.308271
epoch: 4
train	acc: 0.6041	macro: p 0.4511, r 0.3124, f1: 0.3097	micro: p 0.6041, r 0.6041, f1 0.6041	weighted_f1:0.5490
dev	acc: 0.5347	macro: p 0.4312, r 0.2764, f1: 0.2668	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4672
test	acc: 0.5966	macro: p 0.4221, r 0.2940, f1: 0.2910	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5373
New best model!
global_step: 4161, epoch: 5, loss: 1.149892
global_step: 4162, epoch: 5, loss: 1.124052
global_step: 4163, epoch: 5, loss: 1.174076
global_step: 4164, epoch: 5, loss: 1.156488
global_step: 4165, epoch: 5, loss: 1.239111
global_step: 4166, epoch: 5, loss: 1.274933
global_step: 4167, epoch: 5, loss: 1.245660
global_step: 4168, epoch: 5, loss: 1.139480
global_step: 4169, epoch: 5, loss: 1.238180
global_step: 4170, epoch: 5, loss: 1.096981
global_step: 4171, epoch: 5, loss: 1.174893
global_step: 4172, epoch: 5, loss: 1.249024
global_step: 4173, epoch: 5, loss: 1.221831
global_step: 4174, epoch: 5, loss: 1.212416
global_step: 4175, epoch: 5, loss: 1.143218
global_step: 4176, epoch: 5, loss: 1.234762
global_step: 4177, epoch: 5, loss: 1.171258
global_step: 4178, epoch: 5, loss: 1.195013
global_step: 4179, epoch: 5, loss: 1.178592
global_step: 4180, epoch: 5, loss: 1.189523
global_step: 4181, epoch: 5, loss: 1.328308
global_step: 4182, epoch: 5, loss: 1.256951
global_step: 4183, epoch: 5, loss: 1.224159
global_step: 4184, epoch: 5, loss: 1.234264
global_step: 4185, epoch: 5, loss: 1.179738
global_step: 4186, epoch: 5, loss: 1.136355
global_step: 4187, epoch: 5, loss: 1.204415
global_step: 4188, epoch: 5, loss: 1.276515
global_step: 4189, epoch: 5, loss: 1.236653
global_step: 4190, epoch: 5, loss: 1.210857
global_step: 4191, epoch: 5, loss: 1.249248
global_step: 4192, epoch: 5, loss: 1.145772
global_step: 4193, epoch: 5, loss: 1.199101
global_step: 4194, epoch: 5, loss: 1.209540
global_step: 4195, epoch: 5, loss: 1.093887
global_step: 4196, epoch: 5, loss: 1.357687
global_step: 4197, epoch: 5, loss: 1.182203
global_step: 4198, epoch: 5, loss: 1.352504
global_step: 4199, epoch: 5, loss: 1.262088
global_step: 4200, epoch: 5, loss: 0.525214
epoch: 5
train	acc: 0.6027	macro: p 0.4720, r 0.2886, f1: 0.2898	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5339
dev	acc: 0.5365	macro: p 0.4493, r 0.2731, f1: 0.2558	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4531
test	acc: 0.5835	macro: p 0.4511, r 0.2719, f1: 0.2625	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5076
global_step: 4201, epoch: 6, loss: 1.402939
global_step: 4202, epoch: 6, loss: 1.132757
global_step: 4203, epoch: 6, loss: 1.066924
global_step: 4204, epoch: 6, loss: 1.065175
global_step: 4205, epoch: 6, loss: 1.134286
global_step: 4206, epoch: 6, loss: 1.184555
global_step: 4207, epoch: 6, loss: 1.251281
global_step: 4208, epoch: 6, loss: 1.282310
global_step: 4209, epoch: 6, loss: 1.130707
global_step: 4210, epoch: 6, loss: 1.065863
global_step: 4211, epoch: 6, loss: 1.143212
global_step: 4212, epoch: 6, loss: 1.134541
global_step: 4213, epoch: 6, loss: 1.142045
global_step: 4214, epoch: 6, loss: 1.105272
global_step: 4215, epoch: 6, loss: 1.142971
global_step: 4216, epoch: 6, loss: 1.200432
global_step: 4217, epoch: 6, loss: 1.192389
global_step: 4218, epoch: 6, loss: 1.169666
global_step: 4219, epoch: 6, loss: 1.038202
global_step: 4220, epoch: 6, loss: 1.122501
global_step: 4221, epoch: 6, loss: 1.183891
global_step: 4222, epoch: 6, loss: 1.165557
global_step: 4223, epoch: 6, loss: 1.230908
global_step: 4224, epoch: 6, loss: 1.252969
global_step: 4225, epoch: 6, loss: 1.126332
global_step: 4226, epoch: 6, loss: 1.292129
global_step: 4227, epoch: 6, loss: 1.130949
global_step: 4228, epoch: 6, loss: 1.137621
global_step: 4229, epoch: 6, loss: 1.225394
global_step: 4230, epoch: 6, loss: 1.084165
global_step: 4231, epoch: 6, loss: 1.180294
global_step: 4232, epoch: 6, loss: 1.233036
global_step: 4233, epoch: 6, loss: 1.205167
global_step: 4234, epoch: 6, loss: 1.152006
global_step: 4235, epoch: 6, loss: 1.067845
global_step: 4236, epoch: 6, loss: 1.200236
global_step: 4237, epoch: 6, loss: 1.225575
global_step: 4238, epoch: 6, loss: 1.296696
global_step: 4239, epoch: 6, loss: 1.279433
global_step: 4240, epoch: 6, loss: 0.741294
epoch: 6
train	acc: 0.6215	macro: p 0.4494, r 0.3403, f1: 0.3270	micro: p 0.6215, r 0.6215, f1 0.6215	weighted_f1:0.5637
dev	acc: 0.5374	macro: p 0.4297, r 0.2909, f1: 0.2736	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4684
test	acc: 0.5801	macro: p 0.3973, r 0.2958, f1: 0.2804	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5205
New best model!
global_step: 4241, epoch: 7, loss: 1.236556
global_step: 4242, epoch: 7, loss: 1.072282
global_step: 4243, epoch: 7, loss: 1.232749
global_step: 4244, epoch: 7, loss: 1.089868
global_step: 4245, epoch: 7, loss: 1.119139
global_step: 4246, epoch: 7, loss: 1.086570
global_step: 4247, epoch: 7, loss: 1.167030
global_step: 4248, epoch: 7, loss: 1.072326
global_step: 4249, epoch: 7, loss: 1.113946
global_step: 4250, epoch: 7, loss: 1.037030
global_step: 4251, epoch: 7, loss: 1.112659
global_step: 4252, epoch: 7, loss: 1.131161
global_step: 4253, epoch: 7, loss: 1.138299
global_step: 4254, epoch: 7, loss: 1.121464
global_step: 4255, epoch: 7, loss: 1.079705
global_step: 4256, epoch: 7, loss: 1.129804
global_step: 4257, epoch: 7, loss: 1.212720
global_step: 4258, epoch: 7, loss: 1.116064
global_step: 4259, epoch: 7, loss: 1.140394
global_step: 4260, epoch: 7, loss: 1.139633
global_step: 4261, epoch: 7, loss: 1.166598
global_step: 4262, epoch: 7, loss: 1.118567
global_step: 4263, epoch: 7, loss: 1.131629
global_step: 4264, epoch: 7, loss: 1.120260
global_step: 4265, epoch: 7, loss: 1.142934
global_step: 4266, epoch: 7, loss: 1.065591
global_step: 4267, epoch: 7, loss: 1.127555
global_step: 4268, epoch: 7, loss: 1.211713
global_step: 4269, epoch: 7, loss: 1.104137
global_step: 4270, epoch: 7, loss: 1.093368
global_step: 4271, epoch: 7, loss: 1.145703
global_step: 4272, epoch: 7, loss: 1.051826
global_step: 4273, epoch: 7, loss: 1.133040
global_step: 4274, epoch: 7, loss: 1.231578
global_step: 4275, epoch: 7, loss: 0.999509
global_step: 4276, epoch: 7, loss: 1.153941
global_step: 4277, epoch: 7, loss: 1.157223
global_step: 4278, epoch: 7, loss: 1.159819
global_step: 4279, epoch: 7, loss: 1.194637
global_step: 4280, epoch: 7, loss: 1.224120
epoch: 7
train	acc: 0.6441	macro: p 0.4782, r 0.3414, f1: 0.3459	micro: p 0.6441, r 0.6441, f1 0.6441	weighted_f1:0.5867
dev	acc: 0.5338	macro: p 0.4146, r 0.2781, f1: 0.2592	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4550
test	acc: 0.5881	macro: p 0.3898, r 0.2875, f1: 0.2767	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5187
global_step: 4281, epoch: 8, loss: 1.278935
global_step: 4282, epoch: 8, loss: 1.082734
global_step: 4283, epoch: 8, loss: 0.953871
global_step: 4284, epoch: 8, loss: 1.038579
global_step: 4285, epoch: 8, loss: 1.085793
global_step: 4286, epoch: 8, loss: 1.162274
global_step: 4287, epoch: 8, loss: 1.103979
global_step: 4288, epoch: 8, loss: 1.154354
global_step: 4289, epoch: 8, loss: 1.120383
global_step: 4290, epoch: 8, loss: 0.972731
global_step: 4291, epoch: 8, loss: 1.037078
global_step: 4292, epoch: 8, loss: 1.031130
global_step: 4293, epoch: 8, loss: 1.029787
global_step: 4294, epoch: 8, loss: 1.106519
global_step: 4295, epoch: 8, loss: 1.023786
global_step: 4296, epoch: 8, loss: 0.978609
global_step: 4297, epoch: 8, loss: 1.079445
global_step: 4298, epoch: 8, loss: 1.086248
global_step: 4299, epoch: 8, loss: 1.174434
global_step: 4300, epoch: 8, loss: 1.065464
global_step: 4301, epoch: 8, loss: 1.107147
global_step: 4302, epoch: 8, loss: 1.196728
global_step: 4303, epoch: 8, loss: 0.998810
global_step: 4304, epoch: 8, loss: 1.019622
global_step: 4305, epoch: 8, loss: 1.109103
global_step: 4306, epoch: 8, loss: 1.025567
global_step: 4307, epoch: 8, loss: 1.177598
global_step: 4308, epoch: 8, loss: 1.108362
global_step: 4309, epoch: 8, loss: 1.081749
global_step: 4310, epoch: 8, loss: 0.999678
global_step: 4311, epoch: 8, loss: 1.158130
global_step: 4312, epoch: 8, loss: 1.065425
global_step: 4313, epoch: 8, loss: 1.146500
global_step: 4314, epoch: 8, loss: 1.088587
global_step: 4315, epoch: 8, loss: 1.062504
global_step: 4316, epoch: 8, loss: 1.070552
global_step: 4317, epoch: 8, loss: 1.149641
global_step: 4318, epoch: 8, loss: 1.048684
global_step: 4319, epoch: 8, loss: 1.115733
global_step: 4320, epoch: 8, loss: 1.207526
epoch: 8
train	acc: 0.6947	macro: p 0.4613, r 0.4210, f1: 0.4290	micro: p 0.6947, r 0.6947, f1 0.6947	weighted_f1:0.6604
dev	acc: 0.5311	macro: p 0.3087, r 0.2933, f1: 0.2777	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4718
test	acc: 0.5935	macro: p 0.3475, r 0.3181, f1: 0.3133	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5462
New best model!
global_step: 4321, epoch: 9, loss: 0.972383
global_step: 4322, epoch: 9, loss: 1.006348
global_step: 4323, epoch: 9, loss: 0.987271
global_step: 4324, epoch: 9, loss: 1.067825
global_step: 4325, epoch: 9, loss: 1.073957
global_step: 4326, epoch: 9, loss: 1.098787
global_step: 4327, epoch: 9, loss: 1.089563
global_step: 4328, epoch: 9, loss: 1.012576
global_step: 4329, epoch: 9, loss: 1.127920
global_step: 4330, epoch: 9, loss: 1.013228
global_step: 4331, epoch: 9, loss: 1.135833
global_step: 4332, epoch: 9, loss: 1.003997
global_step: 4333, epoch: 9, loss: 1.178655
global_step: 4334, epoch: 9, loss: 1.122627
global_step: 4335, epoch: 9, loss: 0.888415
global_step: 4336, epoch: 9, loss: 1.091025
global_step: 4337, epoch: 9, loss: 1.057459
global_step: 4338, epoch: 9, loss: 1.124188
global_step: 4339, epoch: 9, loss: 1.048729
global_step: 4340, epoch: 9, loss: 1.045886
global_step: 4341, epoch: 9, loss: 0.898509
global_step: 4342, epoch: 9, loss: 1.057621
global_step: 4343, epoch: 9, loss: 1.115793
global_step: 4344, epoch: 9, loss: 1.085216
global_step: 4345, epoch: 9, loss: 1.118096
global_step: 4346, epoch: 9, loss: 1.133325
global_step: 4347, epoch: 9, loss: 0.972290
global_step: 4348, epoch: 9, loss: 1.011698
global_step: 4349, epoch: 9, loss: 1.207525
global_step: 4350, epoch: 9, loss: 1.102617
global_step: 4351, epoch: 9, loss: 1.096406
global_step: 4352, epoch: 9, loss: 1.060005
global_step: 4353, epoch: 9, loss: 0.981487
global_step: 4354, epoch: 9, loss: 1.066891
global_step: 4355, epoch: 9, loss: 0.973040
global_step: 4356, epoch: 9, loss: 0.939744
global_step: 4357, epoch: 9, loss: 1.017740
global_step: 4358, epoch: 9, loss: 0.946027
global_step: 4359, epoch: 9, loss: 1.077710
global_step: 4360, epoch: 9, loss: 0.569477
epoch: 9
train	acc: 0.6372	macro: p 0.4729, r 0.3443, f1: 0.3573	micro: p 0.6372, r 0.6372, f1 0.6372	weighted_f1:0.5868
dev	acc: 0.5320	macro: p 0.3560, r 0.2730, f1: 0.2663	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4617
test	acc: 0.6000	macro: p 0.4027, r 0.2961, f1: 0.3022	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5411
global_step: 4361, epoch: 10, loss: 1.103745
global_step: 4362, epoch: 10, loss: 0.992623
global_step: 4363, epoch: 10, loss: 0.956265
global_step: 4364, epoch: 10, loss: 0.954713
global_step: 4365, epoch: 10, loss: 0.943619
global_step: 4366, epoch: 10, loss: 1.062903
global_step: 4367, epoch: 10, loss: 0.961365
global_step: 4368, epoch: 10, loss: 1.083732
global_step: 4369, epoch: 10, loss: 0.962777
global_step: 4370, epoch: 10, loss: 0.944005
global_step: 4371, epoch: 10, loss: 0.933181
global_step: 4372, epoch: 10, loss: 0.998040
global_step: 4373, epoch: 10, loss: 1.026501
global_step: 4374, epoch: 10, loss: 1.018675
global_step: 4375, epoch: 10, loss: 1.100053
global_step: 4376, epoch: 10, loss: 0.939581
global_step: 4377, epoch: 10, loss: 1.013100
global_step: 4378, epoch: 10, loss: 1.030082
global_step: 4379, epoch: 10, loss: 0.941115
global_step: 4380, epoch: 10, loss: 1.045002
global_step: 4381, epoch: 10, loss: 0.964299
global_step: 4382, epoch: 10, loss: 1.114902
global_step: 4383, epoch: 10, loss: 1.039585
global_step: 4384, epoch: 10, loss: 1.015938
global_step: 4385, epoch: 10, loss: 0.947071
global_step: 4386, epoch: 10, loss: 1.135365
global_step: 4387, epoch: 10, loss: 1.054593
global_step: 4388, epoch: 10, loss: 0.997730
global_step: 4389, epoch: 10, loss: 0.989752
global_step: 4390, epoch: 10, loss: 0.978416
global_step: 4391, epoch: 10, loss: 1.049891
global_step: 4392, epoch: 10, loss: 1.098024
global_step: 4393, epoch: 10, loss: 1.024582
global_step: 4394, epoch: 10, loss: 1.045261
global_step: 4395, epoch: 10, loss: 0.938099
global_step: 4396, epoch: 10, loss: 1.099222
global_step: 4397, epoch: 10, loss: 1.094742
global_step: 4398, epoch: 10, loss: 0.992919
global_step: 4399, epoch: 10, loss: 1.008887
global_step: 4400, epoch: 10, loss: 0.979735
epoch: 10
train	acc: 0.7021	macro: p 0.4813, r 0.4593, f1: 0.4386	micro: p 0.7021, r 0.7021, f1 0.7021	weighted_f1:0.6796
dev	acc: 0.5176	macro: p 0.3303, r 0.2992, f1: 0.2831	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4723
test	acc: 0.5479	macro: p 0.3396, r 0.3077, f1: 0.2951	micro: p 0.5479, r 0.5479, f1 0.5479	weighted_f1:0.5196
New best model!
global_step: 4401, epoch: 11, loss: 0.993987
global_step: 4402, epoch: 11, loss: 0.974797
global_step: 4403, epoch: 11, loss: 0.892449
global_step: 4404, epoch: 11, loss: 1.019296
global_step: 4405, epoch: 11, loss: 0.900225
global_step: 4406, epoch: 11, loss: 1.067552
global_step: 4407, epoch: 11, loss: 1.005671
global_step: 4408, epoch: 11, loss: 0.990982
global_step: 4409, epoch: 11, loss: 0.952521
global_step: 4410, epoch: 11, loss: 0.918875
global_step: 4411, epoch: 11, loss: 1.024411
global_step: 4412, epoch: 11, loss: 1.002883
global_step: 4413, epoch: 11, loss: 0.876471
global_step: 4414, epoch: 11, loss: 0.998595
global_step: 4415, epoch: 11, loss: 0.927065
global_step: 4416, epoch: 11, loss: 0.935190
global_step: 4417, epoch: 11, loss: 0.982281
global_step: 4418, epoch: 11, loss: 0.987211
global_step: 4419, epoch: 11, loss: 1.008476
global_step: 4420, epoch: 11, loss: 1.022649
global_step: 4421, epoch: 11, loss: 0.948142
global_step: 4422, epoch: 11, loss: 1.020468
global_step: 4423, epoch: 11, loss: 1.015679
global_step: 4424, epoch: 11, loss: 0.859950
global_step: 4425, epoch: 11, loss: 1.103876
global_step: 4426, epoch: 11, loss: 1.020314
global_step: 4427, epoch: 11, loss: 0.994793
global_step: 4428, epoch: 11, loss: 0.974154
global_step: 4429, epoch: 11, loss: 0.969989
global_step: 4430, epoch: 11, loss: 0.934633
global_step: 4431, epoch: 11, loss: 0.889286
global_step: 4432, epoch: 11, loss: 0.915262
global_step: 4433, epoch: 11, loss: 0.849566
global_step: 4434, epoch: 11, loss: 0.853857
global_step: 4435, epoch: 11, loss: 1.037777
global_step: 4436, epoch: 11, loss: 0.987251
global_step: 4437, epoch: 11, loss: 1.035384
global_step: 4438, epoch: 11, loss: 0.910780
global_step: 4439, epoch: 11, loss: 0.964084
global_step: 4440, epoch: 11, loss: 1.312552
epoch: 11
train	acc: 0.7395	macro: p 0.7676, r 0.5326, f1: 0.5032	micro: p 0.7395, r 0.7395, f1 0.7395	weighted_f1:0.7253
dev	acc: 0.4896	macro: p 0.2961, r 0.3153, f1: 0.2979	micro: p 0.4896, r 0.4896, f1 0.4896	weighted_f1:0.4731
test	acc: 0.5333	macro: p 0.3128, r 0.3431, f1: 0.3198	micro: p 0.5333, r 0.5333, f1 0.5333	weighted_f1:0.5263
New best model!
global_step: 4441, epoch: 12, loss: 0.970345
global_step: 4442, epoch: 12, loss: 0.882193
global_step: 4443, epoch: 12, loss: 0.902452
global_step: 4444, epoch: 12, loss: 0.931937
global_step: 4445, epoch: 12, loss: 0.871893
global_step: 4446, epoch: 12, loss: 0.907563
global_step: 4447, epoch: 12, loss: 0.923758
global_step: 4448, epoch: 12, loss: 0.844600
global_step: 4449, epoch: 12, loss: 0.940164
global_step: 4450, epoch: 12, loss: 0.970599
global_step: 4451, epoch: 12, loss: 1.014238
global_step: 4452, epoch: 12, loss: 0.906165
global_step: 4453, epoch: 12, loss: 0.821604
global_step: 4454, epoch: 12, loss: 0.883850
global_step: 4455, epoch: 12, loss: 0.879756
global_step: 4456, epoch: 12, loss: 0.952360
global_step: 4457, epoch: 12, loss: 0.894812
global_step: 4458, epoch: 12, loss: 0.826057
global_step: 4459, epoch: 12, loss: 0.956261
global_step: 4460, epoch: 12, loss: 0.984849
global_step: 4461, epoch: 12, loss: 0.864180
global_step: 4462, epoch: 12, loss: 0.807952
global_step: 4463, epoch: 12, loss: 1.010679
global_step: 4464, epoch: 12, loss: 0.891357
global_step: 4465, epoch: 12, loss: 0.876010
global_step: 4466, epoch: 12, loss: 1.087352
global_step: 4467, epoch: 12, loss: 0.823047
global_step: 4468, epoch: 12, loss: 0.940388
global_step: 4469, epoch: 12, loss: 0.934928
global_step: 4470, epoch: 12, loss: 0.830744
global_step: 4471, epoch: 12, loss: 1.014444
global_step: 4472, epoch: 12, loss: 1.017152
global_step: 4473, epoch: 12, loss: 1.124611
global_step: 4474, epoch: 12, loss: 1.012970
global_step: 4475, epoch: 12, loss: 0.905420
global_step: 4476, epoch: 12, loss: 0.923363
global_step: 4477, epoch: 12, loss: 0.888904
global_step: 4478, epoch: 12, loss: 0.933203
global_step: 4479, epoch: 12, loss: 0.871784
global_step: 4480, epoch: 12, loss: 1.808897
epoch: 12
train	acc: 0.7876	macro: p 0.6673, r 0.6802, f1: 0.6629	micro: p 0.7876, r 0.7876, f1 0.7876	weighted_f1:0.7905
dev	acc: 0.5140	macro: p 0.3555, r 0.3306, f1: 0.3335	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.5009
test	acc: 0.5437	macro: p 0.3490, r 0.3308, f1: 0.3321	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5417
New best model!
global_step: 4481, epoch: 13, loss: 0.929176
global_step: 4482, epoch: 13, loss: 0.862639
global_step: 4483, epoch: 13, loss: 0.843751
global_step: 4484, epoch: 13, loss: 0.920939
global_step: 4485, epoch: 13, loss: 0.925202
global_step: 4486, epoch: 13, loss: 1.002121
global_step: 4487, epoch: 13, loss: 0.840500
global_step: 4488, epoch: 13, loss: 0.913132
global_step: 4489, epoch: 13, loss: 0.922535
global_step: 4490, epoch: 13, loss: 1.000121
global_step: 4491, epoch: 13, loss: 0.962459
global_step: 4492, epoch: 13, loss: 0.847943
global_step: 4493, epoch: 13, loss: 0.875996
global_step: 4494, epoch: 13, loss: 0.809410
global_step: 4495, epoch: 13, loss: 1.022408
global_step: 4496, epoch: 13, loss: 0.886680
global_step: 4497, epoch: 13, loss: 0.834079
global_step: 4498, epoch: 13, loss: 0.974516
global_step: 4499, epoch: 13, loss: 0.876253
global_step: 4500, epoch: 13, loss: 0.969203
global_step: 4501, epoch: 13, loss: 0.913754
global_step: 4502, epoch: 13, loss: 0.798188
global_step: 4503, epoch: 13, loss: 0.872385
global_step: 4504, epoch: 13, loss: 0.965443
global_step: 4505, epoch: 13, loss: 0.885279
global_step: 4506, epoch: 13, loss: 0.887746
global_step: 4507, epoch: 13, loss: 0.820882
global_step: 4508, epoch: 13, loss: 0.944323
global_step: 4509, epoch: 13, loss: 0.878778
global_step: 4510, epoch: 13, loss: 0.901008
global_step: 4511, epoch: 13, loss: 0.785990
global_step: 4512, epoch: 13, loss: 0.836026
global_step: 4513, epoch: 13, loss: 0.922867
global_step: 4514, epoch: 13, loss: 0.845566
global_step: 4515, epoch: 13, loss: 0.856730
global_step: 4516, epoch: 13, loss: 0.819230
global_step: 4517, epoch: 13, loss: 0.898871
global_step: 4518, epoch: 13, loss: 0.908656
global_step: 4519, epoch: 13, loss: 0.933175
global_step: 4520, epoch: 13, loss: 1.026755
epoch: 13
train	acc: 0.7649	macro: p 0.8123, r 0.5115, f1: 0.5346	micro: p 0.7649, r 0.7649, f1 0.7649	weighted_f1:0.7382
dev	acc: 0.5374	macro: p 0.3316, r 0.2911, f1: 0.2900	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4773
test	acc: 0.5927	macro: p 0.3473, r 0.3048, f1: 0.3088	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5390
global_step: 4521, epoch: 14, loss: 0.913470
global_step: 4522, epoch: 14, loss: 0.849861
global_step: 4523, epoch: 14, loss: 0.892244
global_step: 4524, epoch: 14, loss: 0.876901
global_step: 4525, epoch: 14, loss: 0.859908
global_step: 4526, epoch: 14, loss: 0.845407
global_step: 4527, epoch: 14, loss: 0.695721
global_step: 4528, epoch: 14, loss: 0.888920
global_step: 4529, epoch: 14, loss: 0.855443
global_step: 4530, epoch: 14, loss: 0.832176
global_step: 4531, epoch: 14, loss: 0.701745
global_step: 4532, epoch: 14, loss: 0.822579
global_step: 4533, epoch: 14, loss: 0.720768
global_step: 4534, epoch: 14, loss: 0.869143
global_step: 4535, epoch: 14, loss: 0.848760
global_step: 4536, epoch: 14, loss: 0.884943
global_step: 4537, epoch: 14, loss: 0.904176
global_step: 4538, epoch: 14, loss: 0.879681
global_step: 4539, epoch: 14, loss: 0.899513
global_step: 4540, epoch: 14, loss: 0.790038
global_step: 4541, epoch: 14, loss: 0.988753
global_step: 4542, epoch: 14, loss: 0.829359
global_step: 4543, epoch: 14, loss: 0.888677
global_step: 4544, epoch: 14, loss: 0.898284
global_step: 4545, epoch: 14, loss: 0.797563
global_step: 4546, epoch: 14, loss: 0.821835
global_step: 4547, epoch: 14, loss: 0.834081
global_step: 4548, epoch: 14, loss: 0.941454
global_step: 4549, epoch: 14, loss: 1.013473
global_step: 4550, epoch: 14, loss: 0.814530
global_step: 4551, epoch: 14, loss: 0.912377
global_step: 4552, epoch: 14, loss: 0.890498
global_step: 4553, epoch: 14, loss: 0.811268
global_step: 4554, epoch: 14, loss: 0.805477
global_step: 4555, epoch: 14, loss: 0.924796
global_step: 4556, epoch: 14, loss: 0.938186
global_step: 4557, epoch: 14, loss: 0.726824
global_step: 4558, epoch: 14, loss: 0.793299
global_step: 4559, epoch: 14, loss: 0.799640
global_step: 4560, epoch: 14, loss: 1.538955
epoch: 14
train	acc: 0.7571	macro: p 0.7085, r 0.5809, f1: 0.5732	micro: p 0.7571, r 0.7571, f1 0.7571	weighted_f1:0.7587
dev	acc: 0.4914	macro: p 0.3192, r 0.3032, f1: 0.2947	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4745
test	acc: 0.5303	macro: p 0.3555, r 0.3226, f1: 0.3172	micro: p 0.5303, r 0.5303, f1 0.5303	weighted_f1:0.5302
global_step: 4561, epoch: 15, loss: 0.897153
global_step: 4562, epoch: 15, loss: 0.801498
global_step: 4563, epoch: 15, loss: 0.777835
global_step: 4564, epoch: 15, loss: 0.837704
global_step: 4565, epoch: 15, loss: 0.758537
global_step: 4566, epoch: 15, loss: 0.940085
global_step: 4567, epoch: 15, loss: 0.796386
global_step: 4568, epoch: 15, loss: 0.814674
global_step: 4569, epoch: 15, loss: 0.759304
global_step: 4570, epoch: 15, loss: 0.689765
global_step: 4571, epoch: 15, loss: 0.826626
global_step: 4572, epoch: 15, loss: 0.761549
global_step: 4573, epoch: 15, loss: 0.784639
global_step: 4574, epoch: 15, loss: 0.742483
global_step: 4575, epoch: 15, loss: 0.849361
global_step: 4576, epoch: 15, loss: 0.762432
global_step: 4577, epoch: 15, loss: 0.802845
global_step: 4578, epoch: 15, loss: 0.977790
global_step: 4579, epoch: 15, loss: 0.933068
global_step: 4580, epoch: 15, loss: 0.869832
global_step: 4581, epoch: 15, loss: 0.824558
global_step: 4582, epoch: 15, loss: 0.927356
global_step: 4583, epoch: 15, loss: 0.831194
global_step: 4584, epoch: 15, loss: 0.744067
global_step: 4585, epoch: 15, loss: 0.829448
global_step: 4586, epoch: 15, loss: 0.696429
global_step: 4587, epoch: 15, loss: 0.805149
global_step: 4588, epoch: 15, loss: 0.783671
global_step: 4589, epoch: 15, loss: 0.822248
global_step: 4590, epoch: 15, loss: 0.833242
global_step: 4591, epoch: 15, loss: 0.787442
global_step: 4592, epoch: 15, loss: 0.947889
global_step: 4593, epoch: 15, loss: 0.757633
global_step: 4594, epoch: 15, loss: 0.780339
global_step: 4595, epoch: 15, loss: 0.905745
global_step: 4596, epoch: 15, loss: 0.860715
global_step: 4597, epoch: 15, loss: 0.893847
global_step: 4598, epoch: 15, loss: 0.813493
global_step: 4599, epoch: 15, loss: 0.850505
global_step: 4600, epoch: 15, loss: 0.573848
epoch: 15
train	acc: 0.7879	macro: p 0.8427, r 0.5616, f1: 0.6027	micro: p 0.7879, r 0.7879, f1 0.7879	weighted_f1:0.7698
dev	acc: 0.5347	macro: p 0.3349, r 0.2835, f1: 0.2685	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4698
test	acc: 0.5912	macro: p 0.4201, r 0.3051, f1: 0.3098	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5454
global_step: 4601, epoch: 16, loss: 0.749856
global_step: 4602, epoch: 16, loss: 0.761511
global_step: 4603, epoch: 16, loss: 0.694959
global_step: 4604, epoch: 16, loss: 0.667709
global_step: 4605, epoch: 16, loss: 0.573249
global_step: 4606, epoch: 16, loss: 0.726446
global_step: 4607, epoch: 16, loss: 0.784750
global_step: 4608, epoch: 16, loss: 0.775169
global_step: 4609, epoch: 16, loss: 0.739804
global_step: 4610, epoch: 16, loss: 0.838602
global_step: 4611, epoch: 16, loss: 0.808400
global_step: 4612, epoch: 16, loss: 0.887468
global_step: 4613, epoch: 16, loss: 0.660584
global_step: 4614, epoch: 16, loss: 0.788035
global_step: 4615, epoch: 16, loss: 0.796514
global_step: 4616, epoch: 16, loss: 0.693541
global_step: 4617, epoch: 16, loss: 0.816886
global_step: 4618, epoch: 16, loss: 0.759725
global_step: 4619, epoch: 16, loss: 0.883760
global_step: 4620, epoch: 16, loss: 0.785741
global_step: 4621, epoch: 16, loss: 0.780623
global_step: 4622, epoch: 16, loss: 0.808266
global_step: 4623, epoch: 16, loss: 0.721684
global_step: 4624, epoch: 16, loss: 0.758277
global_step: 4625, epoch: 16, loss: 0.841270
global_step: 4626, epoch: 16, loss: 0.729479
global_step: 4627, epoch: 16, loss: 0.773481
global_step: 4628, epoch: 16, loss: 0.737728
global_step: 4629, epoch: 16, loss: 0.856617
global_step: 4630, epoch: 16, loss: 0.811534
global_step: 4631, epoch: 16, loss: 0.794634
global_step: 4632, epoch: 16, loss: 0.958110
global_step: 4633, epoch: 16, loss: 0.826065
global_step: 4634, epoch: 16, loss: 0.830056
global_step: 4635, epoch: 16, loss: 0.727503
global_step: 4636, epoch: 16, loss: 0.713335
global_step: 4637, epoch: 16, loss: 0.887096
global_step: 4638, epoch: 16, loss: 0.886916
global_step: 4639, epoch: 16, loss: 0.855084
global_step: 4640, epoch: 16, loss: 0.847910
epoch: 16
train	acc: 0.8154	macro: p 0.8333, r 0.6647, f1: 0.6893	micro: p 0.8154, r 0.8154, f1 0.8154	weighted_f1:0.8135
dev	acc: 0.5068	macro: p 0.3179, r 0.3149, f1: 0.3001	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4815
test	acc: 0.5345	macro: p 0.3395, r 0.3247, f1: 0.3079	micro: p 0.5345, r 0.5345, f1 0.5345	weighted_f1:0.5223
global_step: 4641, epoch: 17, loss: 0.739676
global_step: 4642, epoch: 17, loss: 0.746392
global_step: 4643, epoch: 17, loss: 0.685772
global_step: 4644, epoch: 17, loss: 0.770356
global_step: 4645, epoch: 17, loss: 0.718369
global_step: 4646, epoch: 17, loss: 0.758888
global_step: 4647, epoch: 17, loss: 0.737805
global_step: 4648, epoch: 17, loss: 0.845641
global_step: 4649, epoch: 17, loss: 0.686808
global_step: 4650, epoch: 17, loss: 0.855901
global_step: 4651, epoch: 17, loss: 0.770641
global_step: 4652, epoch: 17, loss: 0.777002
global_step: 4653, epoch: 17, loss: 0.697206
global_step: 4654, epoch: 17, loss: 0.767535
global_step: 4655, epoch: 17, loss: 0.759275
global_step: 4656, epoch: 17, loss: 0.675858
global_step: 4657, epoch: 17, loss: 0.804621
global_step: 4658, epoch: 17, loss: 0.810913
global_step: 4659, epoch: 17, loss: 0.693199
global_step: 4660, epoch: 17, loss: 0.788710
global_step: 4661, epoch: 17, loss: 0.711151
global_step: 4662, epoch: 17, loss: 0.750531
global_step: 4663, epoch: 17, loss: 0.651394
global_step: 4664, epoch: 17, loss: 0.950426
global_step: 4665, epoch: 17, loss: 0.777993
global_step: 4666, epoch: 17, loss: 0.793341
global_step: 4667, epoch: 17, loss: 0.820786
global_step: 4668, epoch: 17, loss: 0.754018
global_step: 4669, epoch: 17, loss: 0.826056
global_step: 4670, epoch: 17, loss: 0.756816
global_step: 4671, epoch: 17, loss: 0.791175
global_step: 4672, epoch: 17, loss: 0.692087
global_step: 4673, epoch: 17, loss: 0.841014
global_step: 4674, epoch: 17, loss: 0.879190
global_step: 4675, epoch: 17, loss: 0.659221
global_step: 4676, epoch: 17, loss: 0.731887
global_step: 4677, epoch: 17, loss: 0.845732
global_step: 4678, epoch: 17, loss: 0.796403
global_step: 4679, epoch: 17, loss: 0.829913
global_step: 4680, epoch: 17, loss: 0.276552
epoch: 17
train	acc: 0.8137	macro: p 0.8547, r 0.6075, f1: 0.6413	micro: p 0.8137, r 0.8137, f1 0.8137	weighted_f1:0.8023
dev	acc: 0.5428	macro: p 0.3422, r 0.2983, f1: 0.2945	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4912
test	acc: 0.5996	macro: p 0.5173, r 0.3259, f1: 0.3301	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5583
global_step: 4681, epoch: 18, loss: 0.831204
global_step: 4682, epoch: 18, loss: 0.828620
global_step: 4683, epoch: 18, loss: 0.809349
global_step: 4684, epoch: 18, loss: 0.695067
global_step: 4685, epoch: 18, loss: 0.705285
global_step: 4686, epoch: 18, loss: 0.740434
global_step: 4687, epoch: 18, loss: 0.675453
global_step: 4688, epoch: 18, loss: 0.647512
global_step: 4689, epoch: 18, loss: 0.841138
global_step: 4690, epoch: 18, loss: 0.688706
global_step: 4691, epoch: 18, loss: 0.726477
global_step: 4692, epoch: 18, loss: 0.739048
global_step: 4693, epoch: 18, loss: 0.837385
global_step: 4694, epoch: 18, loss: 0.664138
global_step: 4695, epoch: 18, loss: 0.685057
global_step: 4696, epoch: 18, loss: 0.798324
global_step: 4697, epoch: 18, loss: 0.649609
global_step: 4698, epoch: 18, loss: 0.644485
global_step: 4699, epoch: 18, loss: 0.737450
global_step: 4700, epoch: 18, loss: 0.719003
global_step: 4701, epoch: 18, loss: 0.710667
global_step: 4702, epoch: 18, loss: 0.730705
global_step: 4703, epoch: 18, loss: 0.700055
global_step: 4704, epoch: 18, loss: 0.686044
global_step: 4705, epoch: 18, loss: 0.700471
global_step: 4706, epoch: 18, loss: 0.763086
global_step: 4707, epoch: 18, loss: 0.660517
global_step: 4708, epoch: 18, loss: 0.725339
global_step: 4709, epoch: 18, loss: 0.772292
global_step: 4710, epoch: 18, loss: 0.800321
global_step: 4711, epoch: 18, loss: 0.851926
global_step: 4712, epoch: 18, loss: 0.732168
global_step: 4713, epoch: 18, loss: 0.795583
global_step: 4714, epoch: 18, loss: 0.806194
global_step: 4715, epoch: 18, loss: 0.849276
global_step: 4716, epoch: 18, loss: 0.663766
global_step: 4717, epoch: 18, loss: 0.709431
global_step: 4718, epoch: 18, loss: 0.798074
global_step: 4719, epoch: 18, loss: 0.681452
global_step: 4720, epoch: 18, loss: 0.560387
epoch: 18
train	acc: 0.8027	macro: p 0.8379, r 0.6138, f1: 0.6527	micro: p 0.8027, r 0.8027, f1 0.8027	weighted_f1:0.7912
dev	acc: 0.5284	macro: p 0.3234, r 0.2841, f1: 0.2869	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4758
test	acc: 0.5736	macro: p 0.4122, r 0.3019, f1: 0.3101	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5349
global_step: 4721, epoch: 19, loss: 0.796562
global_step: 4722, epoch: 19, loss: 0.579517
global_step: 4723, epoch: 19, loss: 0.690206
global_step: 4724, epoch: 19, loss: 0.609406
global_step: 4725, epoch: 19, loss: 0.601927
global_step: 4726, epoch: 19, loss: 0.596642
global_step: 4727, epoch: 19, loss: 0.662235
global_step: 4728, epoch: 19, loss: 0.675637
global_step: 4729, epoch: 19, loss: 0.684584
global_step: 4730, epoch: 19, loss: 0.679716
global_step: 4731, epoch: 19, loss: 0.571143
global_step: 4732, epoch: 19, loss: 0.759036
global_step: 4733, epoch: 19, loss: 0.675760
global_step: 4734, epoch: 19, loss: 0.784422
global_step: 4735, epoch: 19, loss: 0.767782
global_step: 4736, epoch: 19, loss: 0.753240
global_step: 4737, epoch: 19, loss: 0.795382
global_step: 4738, epoch: 19, loss: 0.643350
global_step: 4739, epoch: 19, loss: 0.650875
global_step: 4740, epoch: 19, loss: 0.736707
global_step: 4741, epoch: 19, loss: 0.648727
global_step: 4742, epoch: 19, loss: 0.759054
global_step: 4743, epoch: 19, loss: 0.719941
global_step: 4744, epoch: 19, loss: 0.691560
global_step: 4745, epoch: 19, loss: 0.624109
global_step: 4746, epoch: 19, loss: 0.689106
global_step: 4747, epoch: 19, loss: 0.808769
global_step: 4748, epoch: 19, loss: 0.754632
global_step: 4749, epoch: 19, loss: 0.756584
global_step: 4750, epoch: 19, loss: 0.885968
global_step: 4751, epoch: 19, loss: 0.677426
global_step: 4752, epoch: 19, loss: 0.736446
global_step: 4753, epoch: 19, loss: 0.726873
global_step: 4754, epoch: 19, loss: 0.643196
global_step: 4755, epoch: 19, loss: 0.678741
global_step: 4756, epoch: 19, loss: 0.649690
global_step: 4757, epoch: 19, loss: 0.786437
global_step: 4758, epoch: 19, loss: 0.694517
global_step: 4759, epoch: 19, loss: 0.741427
global_step: 4760, epoch: 19, loss: 0.165181
epoch: 19
train	acc: 0.8391	macro: p 0.8902, r 0.6593, f1: 0.7209	micro: p 0.8391, r 0.8391, f1 0.8391	weighted_f1:0.8291
dev	acc: 0.5419	macro: p 0.3524, r 0.2934, f1: 0.2897	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4825
test	acc: 0.5989	macro: p 0.3962, r 0.3062, f1: 0.3150	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5473
global_step: 4761, epoch: 20, loss: 0.729202
global_step: 4762, epoch: 20, loss: 0.561057
global_step: 4763, epoch: 20, loss: 0.642102
global_step: 4764, epoch: 20, loss: 0.586216
global_step: 4765, epoch: 20, loss: 0.848807
global_step: 4766, epoch: 20, loss: 0.681874
global_step: 4767, epoch: 20, loss: 0.706171
global_step: 4768, epoch: 20, loss: 0.627374
global_step: 4769, epoch: 20, loss: 0.660107
global_step: 4770, epoch: 20, loss: 0.676437
global_step: 4771, epoch: 20, loss: 0.685778
global_step: 4772, epoch: 20, loss: 0.596202
global_step: 4773, epoch: 20, loss: 0.634426
global_step: 4774, epoch: 20, loss: 0.681292
global_step: 4775, epoch: 20, loss: 0.611936
global_step: 4776, epoch: 20, loss: 0.664531
global_step: 4777, epoch: 20, loss: 0.641182
global_step: 4778, epoch: 20, loss: 0.631151
global_step: 4779, epoch: 20, loss: 0.656940
global_step: 4780, epoch: 20, loss: 0.618529
global_step: 4781, epoch: 20, loss: 0.689820
global_step: 4782, epoch: 20, loss: 0.677400
global_step: 4783, epoch: 20, loss: 0.740695
global_step: 4784, epoch: 20, loss: 0.768968
global_step: 4785, epoch: 20, loss: 0.741153
global_step: 4786, epoch: 20, loss: 0.693456
global_step: 4787, epoch: 20, loss: 0.611173
global_step: 4788, epoch: 20, loss: 0.728274
global_step: 4789, epoch: 20, loss: 0.632359
global_step: 4790, epoch: 20, loss: 0.687428
global_step: 4791, epoch: 20, loss: 0.761073
global_step: 4792, epoch: 20, loss: 0.641704
global_step: 4793, epoch: 20, loss: 0.716767
global_step: 4794, epoch: 20, loss: 0.719058
global_step: 4795, epoch: 20, loss: 0.753808
global_step: 4796, epoch: 20, loss: 0.664594
global_step: 4797, epoch: 20, loss: 0.669627
global_step: 4798, epoch: 20, loss: 0.783248
global_step: 4799, epoch: 20, loss: 0.881640
global_step: 4800, epoch: 20, loss: 0.582519
epoch: 20
train	acc: 0.8198	macro: p 0.8773, r 0.6370, f1: 0.6793	micro: p 0.8198, r 0.8198, f1 0.8198	weighted_f1:0.8194
dev	acc: 0.5122	macro: p 0.4774, r 0.2931, f1: 0.2815	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4684
test	acc: 0.5705	macro: p 0.4579, r 0.3144, f1: 0.3041	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5342
global_step: 4801, epoch: 21, loss: 0.821201
global_step: 4802, epoch: 21, loss: 0.628267
global_step: 4803, epoch: 21, loss: 0.713123
global_step: 4804, epoch: 21, loss: 0.639944
global_step: 4805, epoch: 21, loss: 0.685814
global_step: 4806, epoch: 21, loss: 0.598679
global_step: 4807, epoch: 21, loss: 0.665172
global_step: 4808, epoch: 21, loss: 0.710111
global_step: 4809, epoch: 21, loss: 0.633846
global_step: 4810, epoch: 21, loss: 0.734966
global_step: 4811, epoch: 21, loss: 0.684592
global_step: 4812, epoch: 21, loss: 0.605442
global_step: 4813, epoch: 21, loss: 0.533177
global_step: 4814, epoch: 21, loss: 0.657588
global_step: 4815, epoch: 21, loss: 0.667303
global_step: 4816, epoch: 21, loss: 0.606263
global_step: 4817, epoch: 21, loss: 0.611227
global_step: 4818, epoch: 21, loss: 0.651298
global_step: 4819, epoch: 21, loss: 0.573778
global_step: 4820, epoch: 21, loss: 0.680031
global_step: 4821, epoch: 21, loss: 0.745885
global_step: 4822, epoch: 21, loss: 0.628033
global_step: 4823, epoch: 21, loss: 0.570676
global_step: 4824, epoch: 21, loss: 0.801604
global_step: 4825, epoch: 21, loss: 0.691577
global_step: 4826, epoch: 21, loss: 0.639000
global_step: 4827, epoch: 21, loss: 0.726194
global_step: 4828, epoch: 21, loss: 0.585766
global_step: 4829, epoch: 21, loss: 0.749938
global_step: 4830, epoch: 21, loss: 0.727581
global_step: 4831, epoch: 21, loss: 0.663343
global_step: 4832, epoch: 21, loss: 0.581885
global_step: 4833, epoch: 21, loss: 0.574827
global_step: 4834, epoch: 21, loss: 0.671279
global_step: 4835, epoch: 21, loss: 0.738956
global_step: 4836, epoch: 21, loss: 0.721412
global_step: 4837, epoch: 21, loss: 0.698386
global_step: 4838, epoch: 21, loss: 0.650281
global_step: 4839, epoch: 21, loss: 0.749027
global_step: 4840, epoch: 21, loss: 0.779450
epoch: 21
train	acc: 0.9038	macro: p 0.8992, r 0.8248, f1: 0.8553	micro: p 0.9038, r 0.9038, f1 0.9038	weighted_f1:0.9020
dev	acc: 0.5248	macro: p 0.3536, r 0.3086, f1: 0.3117	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4835
test	acc: 0.5847	macro: p 0.3751, r 0.3248, f1: 0.3369	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5494
global_step: 4841, epoch: 22, loss: 0.586630
global_step: 4842, epoch: 22, loss: 0.602428
global_step: 4843, epoch: 22, loss: 0.623398
global_step: 4844, epoch: 22, loss: 0.491900
global_step: 4845, epoch: 22, loss: 0.457771
global_step: 4846, epoch: 22, loss: 0.506959
global_step: 4847, epoch: 22, loss: 0.595190
global_step: 4848, epoch: 22, loss: 0.520561
global_step: 4849, epoch: 22, loss: 0.607016
global_step: 4850, epoch: 22, loss: 0.623256
global_step: 4851, epoch: 22, loss: 0.638666
global_step: 4852, epoch: 22, loss: 0.695733
global_step: 4853, epoch: 22, loss: 0.732555
global_step: 4854, epoch: 22, loss: 0.602942
global_step: 4855, epoch: 22, loss: 0.710173
global_step: 4856, epoch: 22, loss: 0.592125
global_step: 4857, epoch: 22, loss: 0.531494
global_step: 4858, epoch: 22, loss: 0.616741
global_step: 4859, epoch: 22, loss: 0.723177
global_step: 4860, epoch: 22, loss: 0.555489
global_step: 4861, epoch: 22, loss: 0.656988
global_step: 4862, epoch: 22, loss: 0.589103
global_step: 4863, epoch: 22, loss: 0.696374
global_step: 4864, epoch: 22, loss: 0.654628
global_step: 4865, epoch: 22, loss: 0.731461
global_step: 4866, epoch: 22, loss: 0.548232
global_step: 4867, epoch: 22, loss: 0.620269
global_step: 4868, epoch: 22, loss: 0.592638
global_step: 4869, epoch: 22, loss: 0.615040
global_step: 4870, epoch: 22, loss: 0.600924
global_step: 4871, epoch: 22, loss: 0.707693
global_step: 4872, epoch: 22, loss: 0.690259
global_step: 4873, epoch: 22, loss: 0.707792
global_step: 4874, epoch: 22, loss: 0.624610
global_step: 4875, epoch: 22, loss: 0.712789
global_step: 4876, epoch: 22, loss: 0.590137
global_step: 4877, epoch: 22, loss: 0.738247
global_step: 4878, epoch: 22, loss: 0.615718
global_step: 4879, epoch: 22, loss: 0.735325
global_step: 4880, epoch: 22, loss: 0.731405
epoch: 22
train	acc: 0.8805	macro: p 0.8863, r 0.7776, f1: 0.8166	micro: p 0.8805, r 0.8805, f1 0.8805	weighted_f1:0.8754
dev	acc: 0.5194	macro: p 0.3100, r 0.2747, f1: 0.2650	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4530
test	acc: 0.5858	macro: p 0.4324, r 0.3169, f1: 0.3256	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5328
global_step: 4881, epoch: 23, loss: 0.655868
global_step: 4882, epoch: 23, loss: 0.705924
global_step: 4883, epoch: 23, loss: 0.539143
global_step: 4884, epoch: 23, loss: 0.567443
global_step: 4885, epoch: 23, loss: 0.620082
global_step: 4886, epoch: 23, loss: 0.632945
global_step: 4887, epoch: 23, loss: 0.533551
global_step: 4888, epoch: 23, loss: 0.561129
global_step: 4889, epoch: 23, loss: 0.577224
global_step: 4890, epoch: 23, loss: 0.666053
global_step: 4891, epoch: 23, loss: 0.634335
global_step: 4892, epoch: 23, loss: 0.564949
global_step: 4893, epoch: 23, loss: 0.572352
global_step: 4894, epoch: 23, loss: 0.606770
global_step: 4895, epoch: 23, loss: 0.678100
global_step: 4896, epoch: 23, loss: 0.674406
global_step: 4897, epoch: 23, loss: 0.637857
global_step: 4898, epoch: 23, loss: 0.641579
global_step: 4899, epoch: 23, loss: 0.649653
global_step: 4900, epoch: 23, loss: 0.590216
global_step: 4901, epoch: 23, loss: 0.616623
global_step: 4902, epoch: 23, loss: 0.607794
global_step: 4903, epoch: 23, loss: 0.519789
global_step: 4904, epoch: 23, loss: 0.739371
global_step: 4905, epoch: 23, loss: 0.713725
global_step: 4906, epoch: 23, loss: 0.619833
global_step: 4907, epoch: 23, loss: 0.572865
global_step: 4908, epoch: 23, loss: 0.696470
global_step: 4909, epoch: 23, loss: 0.617279
global_step: 4910, epoch: 23, loss: 0.609419
global_step: 4911, epoch: 23, loss: 0.698020
global_step: 4912, epoch: 23, loss: 0.651952
global_step: 4913, epoch: 23, loss: 0.659922
global_step: 4914, epoch: 23, loss: 0.591383
global_step: 4915, epoch: 23, loss: 0.604452
global_step: 4916, epoch: 23, loss: 0.673156
global_step: 4917, epoch: 23, loss: 0.625463
global_step: 4918, epoch: 23, loss: 0.691919
global_step: 4919, epoch: 23, loss: 0.619989
global_step: 4920, epoch: 23, loss: 0.511905
epoch: 23
train	acc: 0.8991	macro: p 0.9249, r 0.7857, f1: 0.8369	micro: p 0.8991, r 0.8991, f1 0.8991	weighted_f1:0.8960
dev	acc: 0.5347	macro: p 0.3760, r 0.2892, f1: 0.2892	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4765
test	acc: 0.5931	macro: p 0.4095, r 0.3060, f1: 0.3114	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5435
global_step: 4921, epoch: 24, loss: 0.633605
global_step: 4922, epoch: 24, loss: 0.525404
global_step: 4923, epoch: 24, loss: 0.447428
global_step: 4924, epoch: 24, loss: 0.567818
global_step: 4925, epoch: 24, loss: 0.447272
global_step: 4926, epoch: 24, loss: 0.505025
global_step: 4927, epoch: 24, loss: 0.600822
global_step: 4928, epoch: 24, loss: 0.683527
global_step: 4929, epoch: 24, loss: 0.582849
global_step: 4930, epoch: 24, loss: 0.524115
global_step: 4931, epoch: 24, loss: 0.557689
global_step: 4932, epoch: 24, loss: 0.551987
global_step: 4933, epoch: 24, loss: 0.600879
global_step: 4934, epoch: 24, loss: 0.639980
global_step: 4935, epoch: 24, loss: 0.536333
global_step: 4936, epoch: 24, loss: 0.516647
global_step: 4937, epoch: 24, loss: 0.596357
global_step: 4938, epoch: 24, loss: 0.625622
global_step: 4939, epoch: 24, loss: 0.530289
global_step: 4940, epoch: 24, loss: 0.547325
global_step: 4941, epoch: 24, loss: 0.591237
global_step: 4942, epoch: 24, loss: 0.489913
global_step: 4943, epoch: 24, loss: 0.547809
global_step: 4944, epoch: 24, loss: 0.559358
global_step: 4945, epoch: 24, loss: 0.543928
global_step: 4946, epoch: 24, loss: 0.565678
global_step: 4947, epoch: 24, loss: 0.560074
global_step: 4948, epoch: 24, loss: 0.509404
global_step: 4949, epoch: 24, loss: 0.713434
global_step: 4950, epoch: 24, loss: 0.567914
global_step: 4951, epoch: 24, loss: 0.622038
global_step: 4952, epoch: 24, loss: 0.577491
global_step: 4953, epoch: 24, loss: 0.579000
global_step: 4954, epoch: 24, loss: 0.566329
global_step: 4955, epoch: 24, loss: 0.611362
global_step: 4956, epoch: 24, loss: 0.574434
global_step: 4957, epoch: 24, loss: 0.682576
global_step: 4958, epoch: 24, loss: 0.585247
global_step: 4959, epoch: 24, loss: 0.582770
global_step: 4960, epoch: 24, loss: 1.022195
epoch: 24
train	acc: 0.9111	macro: p 0.9273, r 0.8392, f1: 0.8740	micro: p 0.9111, r 0.9111, f1 0.9111	weighted_f1:0.9106
dev	acc: 0.5005	macro: p 0.3278, r 0.2928, f1: 0.2821	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.4640
test	acc: 0.5602	macro: p 0.3957, r 0.3218, f1: 0.3192	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5346
global_step: 4961, epoch: 25, loss: 0.496186
global_step: 4962, epoch: 25, loss: 0.493283
global_step: 4963, epoch: 25, loss: 0.430933
global_step: 4964, epoch: 25, loss: 0.479843
global_step: 4965, epoch: 25, loss: 0.593877
global_step: 4966, epoch: 25, loss: 0.477493
global_step: 4967, epoch: 25, loss: 0.521319
global_step: 4968, epoch: 25, loss: 0.599573
global_step: 4969, epoch: 25, loss: 0.565400
global_step: 4970, epoch: 25, loss: 0.558796
global_step: 4971, epoch: 25, loss: 0.518797
global_step: 4972, epoch: 25, loss: 0.550873
global_step: 4973, epoch: 25, loss: 0.596250
global_step: 4974, epoch: 25, loss: 0.538616
global_step: 4975, epoch: 25, loss: 0.450923
global_step: 4976, epoch: 25, loss: 0.556137
global_step: 4977, epoch: 25, loss: 0.621979
global_step: 4978, epoch: 25, loss: 0.561508
global_step: 4979, epoch: 25, loss: 0.461445
global_step: 4980, epoch: 25, loss: 0.500482
global_step: 4981, epoch: 25, loss: 0.624863
global_step: 4982, epoch: 25, loss: 0.607171
global_step: 4983, epoch: 25, loss: 0.653865
global_step: 4984, epoch: 25, loss: 0.625630
global_step: 4985, epoch: 25, loss: 0.580853
global_step: 4986, epoch: 25, loss: 0.699873
global_step: 4987, epoch: 25, loss: 0.635927
global_step: 4988, epoch: 25, loss: 0.632892
global_step: 4989, epoch: 25, loss: 0.510181
global_step: 4990, epoch: 25, loss: 0.509709
global_step: 4991, epoch: 25, loss: 0.577318
global_step: 4992, epoch: 25, loss: 0.473207
global_step: 4993, epoch: 25, loss: 0.648062
global_step: 4994, epoch: 25, loss: 0.597626
global_step: 4995, epoch: 25, loss: 0.566345
global_step: 4996, epoch: 25, loss: 0.624409
global_step: 4997, epoch: 25, loss: 0.565540
global_step: 4998, epoch: 25, loss: 0.631270
global_step: 4999, epoch: 25, loss: 0.517050
global_step: 5000, epoch: 25, loss: 1.454646
epoch: 25
train	acc: 0.9046	macro: p 0.8955, r 0.8354, f1: 0.8480	micro: p 0.9046, r 0.9046, f1 0.9046	weighted_f1:0.9052
dev	acc: 0.4914	macro: p 0.4516, r 0.3152, f1: 0.3116	micro: p 0.4914, r 0.4914, f1 0.4914	weighted_f1:0.4820
test	acc: 0.5398	macro: p 0.3540, r 0.3421, f1: 0.3388	micro: p 0.5398, r 0.5398, f1 0.5398	weighted_f1:0.5417
global_step: 5001, epoch: 26, loss: 0.583026
global_step: 5002, epoch: 26, loss: 0.607514
global_step: 5003, epoch: 26, loss: 0.557454
global_step: 5004, epoch: 26, loss: 0.515055
global_step: 5005, epoch: 26, loss: 0.429031
global_step: 5006, epoch: 26, loss: 0.450072
global_step: 5007, epoch: 26, loss: 0.450998
global_step: 5008, epoch: 26, loss: 0.519937
global_step: 5009, epoch: 26, loss: 0.535810
global_step: 5010, epoch: 26, loss: 0.577061
global_step: 5011, epoch: 26, loss: 0.494414
global_step: 5012, epoch: 26, loss: 0.696200
global_step: 5013, epoch: 26, loss: 0.552409
global_step: 5014, epoch: 26, loss: 0.572285
global_step: 5015, epoch: 26, loss: 0.571111
global_step: 5016, epoch: 26, loss: 0.533971
global_step: 5017, epoch: 26, loss: 0.466712
global_step: 5018, epoch: 26, loss: 0.528118
global_step: 5019, epoch: 26, loss: 0.514349
global_step: 5020, epoch: 26, loss: 0.499556
global_step: 5021, epoch: 26, loss: 0.642384
global_step: 5022, epoch: 26, loss: 0.501894
global_step: 5023, epoch: 26, loss: 0.522188
global_step: 5024, epoch: 26, loss: 0.562023
global_step: 5025, epoch: 26, loss: 0.459770
global_step: 5026, epoch: 26, loss: 0.492193
global_step: 5027, epoch: 26, loss: 0.608126
global_step: 5028, epoch: 26, loss: 0.671907
global_step: 5029, epoch: 26, loss: 0.550866
global_step: 5030, epoch: 26, loss: 0.615770
global_step: 5031, epoch: 26, loss: 0.629512
global_step: 5032, epoch: 26, loss: 0.513408
global_step: 5033, epoch: 26, loss: 0.584868
global_step: 5034, epoch: 26, loss: 0.505068
global_step: 5035, epoch: 26, loss: 0.581261
global_step: 5036, epoch: 26, loss: 0.563057
global_step: 5037, epoch: 26, loss: 0.565192
global_step: 5038, epoch: 26, loss: 0.692311
global_step: 5039, epoch: 26, loss: 0.509479
global_step: 5040, epoch: 26, loss: 0.397608
epoch: 26
train	acc: 0.9240	macro: p 0.9359, r 0.8515, f1: 0.8865	micro: p 0.9240, r 0.9240, f1 0.9240	weighted_f1:0.9229
dev	acc: 0.5302	macro: p 0.4027, r 0.3064, f1: 0.3088	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4863
test	acc: 0.5801	macro: p 0.3378, r 0.3103, f1: 0.3140	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5407
global_step: 5041, epoch: 27, loss: 0.565096
global_step: 5042, epoch: 27, loss: 0.469501
global_step: 5043, epoch: 27, loss: 0.418964
global_step: 5044, epoch: 27, loss: 0.506988
global_step: 5045, epoch: 27, loss: 0.491751
global_step: 5046, epoch: 27, loss: 0.484643
global_step: 5047, epoch: 27, loss: 0.460039
global_step: 5048, epoch: 27, loss: 0.600107
global_step: 5049, epoch: 27, loss: 0.490743
global_step: 5050, epoch: 27, loss: 0.563357
global_step: 5051, epoch: 27, loss: 0.470598
global_step: 5052, epoch: 27, loss: 0.516367
global_step: 5053, epoch: 27, loss: 0.426927
global_step: 5054, epoch: 27, loss: 0.471126
global_step: 5055, epoch: 27, loss: 0.519832
global_step: 5056, epoch: 27, loss: 0.620015
global_step: 5057, epoch: 27, loss: 0.547695
global_step: 5058, epoch: 27, loss: 0.477492
global_step: 5059, epoch: 27, loss: 0.539301
global_step: 5060, epoch: 27, loss: 0.484617
global_step: 5061, epoch: 27, loss: 0.618160
global_step: 5062, epoch: 27, loss: 0.473731
global_step: 5063, epoch: 27, loss: 0.477040
global_step: 5064, epoch: 27, loss: 0.549149
global_step: 5065, epoch: 27, loss: 0.506881
global_step: 5066, epoch: 27, loss: 0.529661
global_step: 5067, epoch: 27, loss: 0.514345
global_step: 5068, epoch: 27, loss: 0.488315
global_step: 5069, epoch: 27, loss: 0.543310
global_step: 5070, epoch: 27, loss: 0.511414
global_step: 5071, epoch: 27, loss: 0.681540
global_step: 5072, epoch: 27, loss: 0.560711
global_step: 5073, epoch: 27, loss: 0.620930
global_step: 5074, epoch: 27, loss: 0.499537
global_step: 5075, epoch: 27, loss: 0.564745
global_step: 5076, epoch: 27, loss: 0.565473
global_step: 5077, epoch: 27, loss: 0.678052
global_step: 5078, epoch: 27, loss: 0.626220
global_step: 5079, epoch: 27, loss: 0.594404
global_step: 5080, epoch: 27, loss: 0.186971
epoch: 27
train	acc: 0.9060	macro: p 0.9389, r 0.8160, f1: 0.8661	micro: p 0.9060, r 0.9060, f1 0.9060	weighted_f1:0.9038
dev	acc: 0.5356	macro: p 0.4060, r 0.2898, f1: 0.2860	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4713
test	acc: 0.5946	macro: p 0.4121, r 0.3016, f1: 0.3068	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5383
global_step: 5081, epoch: 28, loss: 0.586505
global_step: 5082, epoch: 28, loss: 0.572443
global_step: 5083, epoch: 28, loss: 0.520697
global_step: 5084, epoch: 28, loss: 0.550367
global_step: 5085, epoch: 28, loss: 0.469021
global_step: 5086, epoch: 28, loss: 0.577296
global_step: 5087, epoch: 28, loss: 0.475426
global_step: 5088, epoch: 28, loss: 0.474790
global_step: 5089, epoch: 28, loss: 0.409950
global_step: 5090, epoch: 28, loss: 0.551312
global_step: 5091, epoch: 28, loss: 0.496935
global_step: 5092, epoch: 28, loss: 0.511961
global_step: 5093, epoch: 28, loss: 0.510933
global_step: 5094, epoch: 28, loss: 0.636817
global_step: 5095, epoch: 28, loss: 0.528267
global_step: 5096, epoch: 28, loss: 0.475662
global_step: 5097, epoch: 28, loss: 0.627499
global_step: 5098, epoch: 28, loss: 0.518108
global_step: 5099, epoch: 28, loss: 0.489301
global_step: 5100, epoch: 28, loss: 0.458431
global_step: 5101, epoch: 28, loss: 0.537506
global_step: 5102, epoch: 28, loss: 0.439191
global_step: 5103, epoch: 28, loss: 0.554498
global_step: 5104, epoch: 28, loss: 0.547142
global_step: 5105, epoch: 28, loss: 0.522702
global_step: 5106, epoch: 28, loss: 0.547572
global_step: 5107, epoch: 28, loss: 0.503446
global_step: 5108, epoch: 28, loss: 0.447575
global_step: 5109, epoch: 28, loss: 0.531101
global_step: 5110, epoch: 28, loss: 0.506328
global_step: 5111, epoch: 28, loss: 0.514490
global_step: 5112, epoch: 28, loss: 0.611246
global_step: 5113, epoch: 28, loss: 0.550960
global_step: 5114, epoch: 28, loss: 0.526196
global_step: 5115, epoch: 28, loss: 0.461115
global_step: 5116, epoch: 28, loss: 0.549213
global_step: 5117, epoch: 28, loss: 0.520437
global_step: 5118, epoch: 28, loss: 0.420013
global_step: 5119, epoch: 28, loss: 0.601477
global_step: 5120, epoch: 28, loss: 0.256473
epoch: 28
train	acc: 0.9283	macro: p 0.9348, r 0.8872, f1: 0.9077	micro: p 0.9283, r 0.9283, f1 0.9283	weighted_f1:0.9282
dev	acc: 0.5131	macro: p 0.3396, r 0.3138, f1: 0.3090	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4875
test	acc: 0.5513	macro: p 0.3732, r 0.3348, f1: 0.3336	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5368
global_step: 5121, epoch: 29, loss: 0.513099
global_step: 5122, epoch: 29, loss: 0.431620
global_step: 5123, epoch: 29, loss: 0.447200
global_step: 5124, epoch: 29, loss: 0.462061
global_step: 5125, epoch: 29, loss: 0.483066
global_step: 5126, epoch: 29, loss: 0.571814
global_step: 5127, epoch: 29, loss: 0.427927
global_step: 5128, epoch: 29, loss: 0.565508
global_step: 5129, epoch: 29, loss: 0.505445
global_step: 5130, epoch: 29, loss: 0.424149
global_step: 5131, epoch: 29, loss: 0.475441
global_step: 5132, epoch: 29, loss: 0.579678
global_step: 5133, epoch: 29, loss: 0.510388
global_step: 5134, epoch: 29, loss: 0.462095
global_step: 5135, epoch: 29, loss: 0.481605
global_step: 5136, epoch: 29, loss: 0.527677
global_step: 5137, epoch: 29, loss: 0.485298
global_step: 5138, epoch: 29, loss: 0.575939
global_step: 5139, epoch: 29, loss: 0.510411
global_step: 5140, epoch: 29, loss: 0.575435
global_step: 5141, epoch: 29, loss: 0.473566
global_step: 5142, epoch: 29, loss: 0.434878
global_step: 5143, epoch: 29, loss: 0.507260
global_step: 5144, epoch: 29, loss: 0.487660
global_step: 5145, epoch: 29, loss: 0.638330
global_step: 5146, epoch: 29, loss: 0.654800
global_step: 5147, epoch: 29, loss: 0.448133
global_step: 5148, epoch: 29, loss: 0.457749
global_step: 5149, epoch: 29, loss: 0.549994
global_step: 5150, epoch: 29, loss: 0.499154
global_step: 5151, epoch: 29, loss: 0.490061
global_step: 5152, epoch: 29, loss: 0.558495
global_step: 5153, epoch: 29, loss: 0.443174
global_step: 5154, epoch: 29, loss: 0.594420
global_step: 5155, epoch: 29, loss: 0.504819
global_step: 5156, epoch: 29, loss: 0.485365
global_step: 5157, epoch: 29, loss: 0.595977
global_step: 5158, epoch: 29, loss: 0.415729
global_step: 5159, epoch: 29, loss: 0.655727
global_step: 5160, epoch: 29, loss: 1.293626
epoch: 29
train	acc: 0.8946	macro: p 0.9290, r 0.8313, f1: 0.8693	micro: p 0.8946, r 0.8946, f1 0.8946	weighted_f1:0.8921
dev	acc: 0.5212	macro: p 0.3776, r 0.2869, f1: 0.2825	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4657
test	acc: 0.5739	macro: p 0.3456, r 0.2967, f1: 0.2881	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5181
global_step: 5161, epoch: 30, loss: 0.560962
global_step: 5162, epoch: 30, loss: 0.421999
global_step: 5163, epoch: 30, loss: 0.480659
global_step: 5164, epoch: 30, loss: 0.481104
global_step: 5165, epoch: 30, loss: 0.537942
global_step: 5166, epoch: 30, loss: 0.422327
global_step: 5167, epoch: 30, loss: 0.497274
global_step: 5168, epoch: 30, loss: 0.467551
global_step: 5169, epoch: 30, loss: 0.348309
global_step: 5170, epoch: 30, loss: 0.425844
global_step: 5171, epoch: 30, loss: 0.512521
global_step: 5172, epoch: 30, loss: 0.461006
global_step: 5173, epoch: 30, loss: 0.435684
global_step: 5174, epoch: 30, loss: 0.456843
global_step: 5175, epoch: 30, loss: 0.541412
global_step: 5176, epoch: 30, loss: 0.452512
global_step: 5177, epoch: 30, loss: 0.435099
global_step: 5178, epoch: 30, loss: 0.456568
global_step: 5179, epoch: 30, loss: 0.416113
global_step: 5180, epoch: 30, loss: 0.445209
global_step: 5181, epoch: 30, loss: 0.412631
global_step: 5182, epoch: 30, loss: 0.542080
global_step: 5183, epoch: 30, loss: 0.486028
global_step: 5184, epoch: 30, loss: 0.478925
global_step: 5185, epoch: 30, loss: 0.546342
global_step: 5186, epoch: 30, loss: 0.464218
global_step: 5187, epoch: 30, loss: 0.499362
global_step: 5188, epoch: 30, loss: 0.478601
global_step: 5189, epoch: 30, loss: 0.510803
global_step: 5190, epoch: 30, loss: 0.474969
global_step: 5191, epoch: 30, loss: 0.445702
global_step: 5192, epoch: 30, loss: 0.500925
global_step: 5193, epoch: 30, loss: 0.568522
global_step: 5194, epoch: 30, loss: 0.447809
global_step: 5195, epoch: 30, loss: 0.407911
global_step: 5196, epoch: 30, loss: 0.479483
global_step: 5197, epoch: 30, loss: 0.578983
global_step: 5198, epoch: 30, loss: 0.516729
global_step: 5199, epoch: 30, loss: 0.507735
global_step: 5200, epoch: 30, loss: 0.715799
epoch: 30
train	acc: 0.9313	macro: p 0.9190, r 0.8879, f1: 0.8999	micro: p 0.9313, r 0.9313, f1 0.9313	weighted_f1:0.9313
dev	acc: 0.5104	macro: p 0.3236, r 0.3117, f1: 0.3054	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4842
test	acc: 0.5571	macro: p 0.3294, r 0.3285, f1: 0.3184	micro: p 0.5571, r 0.5571, f1 0.5571	weighted_f1:0.5372
global_step: 5201, epoch: 31, loss: 0.472501
global_step: 5202, epoch: 31, loss: 0.443283
global_step: 5203, epoch: 31, loss: 0.332544
global_step: 5204, epoch: 31, loss: 0.479735
global_step: 5205, epoch: 31, loss: 0.405526
global_step: 5206, epoch: 31, loss: 0.384529
global_step: 5207, epoch: 31, loss: 0.437770
global_step: 5208, epoch: 31, loss: 0.417796
global_step: 5209, epoch: 31, loss: 0.454386
global_step: 5210, epoch: 31, loss: 0.462038
global_step: 5211, epoch: 31, loss: 0.576760
global_step: 5212, epoch: 31, loss: 0.532737
global_step: 5213, epoch: 31, loss: 0.488045
global_step: 5214, epoch: 31, loss: 0.516047
global_step: 5215, epoch: 31, loss: 0.460062
global_step: 5216, epoch: 31, loss: 0.514793
global_step: 5217, epoch: 31, loss: 0.562575
global_step: 5218, epoch: 31, loss: 0.459427
global_step: 5219, epoch: 31, loss: 0.519577
global_step: 5220, epoch: 31, loss: 0.518169
global_step: 5221, epoch: 31, loss: 0.492386
global_step: 5222, epoch: 31, loss: 0.431279
global_step: 5223, epoch: 31, loss: 0.391037
global_step: 5224, epoch: 31, loss: 0.472041
global_step: 5225, epoch: 31, loss: 0.442552
global_step: 5226, epoch: 31, loss: 0.434716
global_step: 5227, epoch: 31, loss: 0.541164
global_step: 5228, epoch: 31, loss: 0.467706
global_step: 5229, epoch: 31, loss: 0.558439
global_step: 5230, epoch: 31, loss: 0.367816
global_step: 5231, epoch: 31, loss: 0.425672
global_step: 5232, epoch: 31, loss: 0.521446
global_step: 5233, epoch: 31, loss: 0.486975
global_step: 5234, epoch: 31, loss: 0.463040
global_step: 5235, epoch: 31, loss: 0.499626
global_step: 5236, epoch: 31, loss: 0.450465
global_step: 5237, epoch: 31, loss: 0.454491
global_step: 5238, epoch: 31, loss: 0.444669
global_step: 5239, epoch: 31, loss: 0.489851
global_step: 5240, epoch: 31, loss: 0.058321
epoch: 31
train	acc: 0.9367	macro: p 0.9399, r 0.8990, f1: 0.9169	micro: p 0.9367, r 0.9367, f1 0.9367	weighted_f1:0.9368
dev	acc: 0.5212	macro: p 0.3603, r 0.3281, f1: 0.3273	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4906
test	acc: 0.5701	macro: p 0.3700, r 0.3356, f1: 0.3366	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5464
global_step: 5241, epoch: 32, loss: 0.462865
global_step: 5242, epoch: 32, loss: 0.446595
global_step: 5243, epoch: 32, loss: 0.400777
global_step: 5244, epoch: 32, loss: 0.418394
global_step: 5245, epoch: 32, loss: 0.450595
global_step: 5246, epoch: 32, loss: 0.406947
global_step: 5247, epoch: 32, loss: 0.369666
global_step: 5248, epoch: 32, loss: 0.410207
global_step: 5249, epoch: 32, loss: 0.439790
global_step: 5250, epoch: 32, loss: 0.342251
global_step: 5251, epoch: 32, loss: 0.456721
global_step: 5252, epoch: 32, loss: 0.462546
global_step: 5253, epoch: 32, loss: 0.443602
global_step: 5254, epoch: 32, loss: 0.448724
global_step: 5255, epoch: 32, loss: 0.374113
global_step: 5256, epoch: 32, loss: 0.424455
global_step: 5257, epoch: 32, loss: 0.398847
global_step: 5258, epoch: 32, loss: 0.458176
global_step: 5259, epoch: 32, loss: 0.476337
global_step: 5260, epoch: 32, loss: 0.421535
global_step: 5261, epoch: 32, loss: 0.607502
global_step: 5262, epoch: 32, loss: 0.456880
global_step: 5263, epoch: 32, loss: 0.448690
global_step: 5264, epoch: 32, loss: 0.548063
global_step: 5265, epoch: 32, loss: 0.411130
global_step: 5266, epoch: 32, loss: 0.449582
global_step: 5267, epoch: 32, loss: 0.431595
global_step: 5268, epoch: 32, loss: 0.446647
global_step: 5269, epoch: 32, loss: 0.497031
global_step: 5270, epoch: 32, loss: 0.423411
global_step: 5271, epoch: 32, loss: 0.493046
global_step: 5272, epoch: 32, loss: 0.527019
global_step: 5273, epoch: 32, loss: 0.532163
global_step: 5274, epoch: 32, loss: 0.521680
global_step: 5275, epoch: 32, loss: 0.461638
global_step: 5276, epoch: 32, loss: 0.475272
global_step: 5277, epoch: 32, loss: 0.493318
global_step: 5278, epoch: 32, loss: 0.534873
global_step: 5279, epoch: 32, loss: 0.488062
global_step: 5280, epoch: 32, loss: 0.140619
epoch: 32
train	acc: 0.9324	macro: p 0.9487, r 0.8776, f1: 0.9091	micro: p 0.9324, r 0.9324, f1 0.9324	weighted_f1:0.9317
dev	acc: 0.5275	macro: p 0.3697, r 0.2897, f1: 0.2901	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4714
test	acc: 0.5877	macro: p 0.4008, r 0.3100, f1: 0.3205	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5403
global_step: 5281, epoch: 33, loss: 0.459465
global_step: 5282, epoch: 33, loss: 0.464356
global_step: 5283, epoch: 33, loss: 0.463192
global_step: 5284, epoch: 33, loss: 0.526663
global_step: 5285, epoch: 33, loss: 0.479833
global_step: 5286, epoch: 33, loss: 0.541028
global_step: 5287, epoch: 33, loss: 0.492075
global_step: 5288, epoch: 33, loss: 0.443204
global_step: 5289, epoch: 33, loss: 0.372725
global_step: 5290, epoch: 33, loss: 0.502038
global_step: 5291, epoch: 33, loss: 0.376623
global_step: 5292, epoch: 33, loss: 0.407125
global_step: 5293, epoch: 33, loss: 0.472177
global_step: 5294, epoch: 33, loss: 0.413805
global_step: 5295, epoch: 33, loss: 0.405148
global_step: 5296, epoch: 33, loss: 0.488641
global_step: 5297, epoch: 33, loss: 0.548971
global_step: 5298, epoch: 33, loss: 0.434273
global_step: 5299, epoch: 33, loss: 0.355649
global_step: 5300, epoch: 33, loss: 0.543158
global_step: 5301, epoch: 33, loss: 0.532993
global_step: 5302, epoch: 33, loss: 0.490445
global_step: 5303, epoch: 33, loss: 0.469768
global_step: 5304, epoch: 33, loss: 0.479211
global_step: 5305, epoch: 33, loss: 0.542759
global_step: 5306, epoch: 33, loss: 0.445277
global_step: 5307, epoch: 33, loss: 0.478973
global_step: 5308, epoch: 33, loss: 0.448532
global_step: 5309, epoch: 33, loss: 0.479923
global_step: 5310, epoch: 33, loss: 0.402507
global_step: 5311, epoch: 33, loss: 0.430596
global_step: 5312, epoch: 33, loss: 0.503810
global_step: 5313, epoch: 33, loss: 0.454142
global_step: 5314, epoch: 33, loss: 0.545277
global_step: 5315, epoch: 33, loss: 0.547719
global_step: 5316, epoch: 33, loss: 0.508053
global_step: 5317, epoch: 33, loss: 0.491968
global_step: 5318, epoch: 33, loss: 0.455061
global_step: 5319, epoch: 33, loss: 0.554175
global_step: 5320, epoch: 33, loss: 0.166412
epoch: 33
train	acc: 0.9291	macro: p 0.9497, r 0.8866, f1: 0.9152	micro: p 0.9291, r 0.9291, f1 0.9291	weighted_f1:0.9280
dev	acc: 0.5302	macro: p 0.3525, r 0.2808, f1: 0.2853	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4722
test	acc: 0.5858	macro: p 0.3935, r 0.2967, f1: 0.3120	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5367
global_step: 5321, epoch: 34, loss: 0.459787
global_step: 5322, epoch: 34, loss: 0.399932
global_step: 5323, epoch: 34, loss: 0.340585
global_step: 5324, epoch: 34, loss: 0.388916
global_step: 5325, epoch: 34, loss: 0.423353
global_step: 5326, epoch: 34, loss: 0.407717
global_step: 5327, epoch: 34, loss: 0.413331
global_step: 5328, epoch: 34, loss: 0.495963
global_step: 5329, epoch: 34, loss: 0.409322
global_step: 5330, epoch: 34, loss: 0.492142
global_step: 5331, epoch: 34, loss: 0.422957
global_step: 5332, epoch: 34, loss: 0.509329
global_step: 5333, epoch: 34, loss: 0.379891
global_step: 5334, epoch: 34, loss: 0.560481
global_step: 5335, epoch: 34, loss: 0.496053
global_step: 5336, epoch: 34, loss: 0.471028
global_step: 5337, epoch: 34, loss: 0.549753
global_step: 5338, epoch: 34, loss: 0.397584
global_step: 5339, epoch: 34, loss: 0.465482
global_step: 5340, epoch: 34, loss: 0.474147
global_step: 5341, epoch: 34, loss: 0.465599
global_step: 5342, epoch: 34, loss: 0.440286
global_step: 5343, epoch: 34, loss: 0.378513
global_step: 5344, epoch: 34, loss: 0.408459
global_step: 5345, epoch: 34, loss: 0.390773
global_step: 5346, epoch: 34, loss: 0.382754
global_step: 5347, epoch: 34, loss: 0.440179
global_step: 5348, epoch: 34, loss: 0.367339
global_step: 5349, epoch: 34, loss: 0.432743
global_step: 5350, epoch: 34, loss: 0.406564
global_step: 5351, epoch: 34, loss: 0.473381
global_step: 5352, epoch: 34, loss: 0.524533
global_step: 5353, epoch: 34, loss: 0.480557
global_step: 5354, epoch: 34, loss: 0.432494
global_step: 5355, epoch: 34, loss: 0.599509
global_step: 5356, epoch: 34, loss: 0.525595
global_step: 5357, epoch: 34, loss: 0.480371
global_step: 5358, epoch: 34, loss: 0.461388
global_step: 5359, epoch: 34, loss: 0.491777
global_step: 5360, epoch: 34, loss: 0.072791
epoch: 34
train	acc: 0.9451	macro: p 0.9528, r 0.9116, f1: 0.9306	micro: p 0.9451, r 0.9451, f1 0.9451	weighted_f1:0.9450
dev	acc: 0.5140	macro: p 0.4033, r 0.3150, f1: 0.3150	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4780
test	acc: 0.5766	macro: p 0.3872, r 0.3325, f1: 0.3379	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5482
global_step: 5361, epoch: 35, loss: 0.472451
global_step: 5362, epoch: 35, loss: 0.399732
global_step: 5363, epoch: 35, loss: 0.461286
global_step: 5364, epoch: 35, loss: 0.391818
global_step: 5365, epoch: 35, loss: 0.444166
global_step: 5366, epoch: 35, loss: 0.391498
global_step: 5367, epoch: 35, loss: 0.357896
global_step: 5368, epoch: 35, loss: 0.328118
global_step: 5369, epoch: 35, loss: 0.404138
global_step: 5370, epoch: 35, loss: 0.472478
global_step: 5371, epoch: 35, loss: 0.467080
global_step: 5372, epoch: 35, loss: 0.451943
global_step: 5373, epoch: 35, loss: 0.413204
global_step: 5374, epoch: 35, loss: 0.510746
global_step: 5375, epoch: 35, loss: 0.392143
global_step: 5376, epoch: 35, loss: 0.343342
global_step: 5377, epoch: 35, loss: 0.482414
global_step: 5378, epoch: 35, loss: 0.412975
global_step: 5379, epoch: 35, loss: 0.516117
global_step: 5380, epoch: 35, loss: 0.419796
global_step: 5381, epoch: 35, loss: 0.573523
global_step: 5382, epoch: 35, loss: 0.456235
global_step: 5383, epoch: 35, loss: 0.341774
global_step: 5384, epoch: 35, loss: 0.418206
global_step: 5385, epoch: 35, loss: 0.378499
global_step: 5386, epoch: 35, loss: 0.386100
global_step: 5387, epoch: 35, loss: 0.492192
global_step: 5388, epoch: 35, loss: 0.416890
global_step: 5389, epoch: 35, loss: 0.449959
global_step: 5390, epoch: 35, loss: 0.445230
global_step: 5391, epoch: 35, loss: 0.419794
global_step: 5392, epoch: 35, loss: 0.450055
global_step: 5393, epoch: 35, loss: 0.497422
global_step: 5394, epoch: 35, loss: 0.490087
global_step: 5395, epoch: 35, loss: 0.578280
global_step: 5396, epoch: 35, loss: 0.486737
global_step: 5397, epoch: 35, loss: 0.576951
global_step: 5398, epoch: 35, loss: 0.391409
global_step: 5399, epoch: 35, loss: 0.448097
global_step: 5400, epoch: 35, loss: 0.445316
epoch: 35
train	acc: 0.9453	macro: p 0.9476, r 0.9188, f1: 0.9319	micro: p 0.9453, r 0.9453, f1 0.9453	weighted_f1:0.9454
dev	acc: 0.5023	macro: p 0.3378, r 0.3193, f1: 0.3165	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4796
test	acc: 0.5552	macro: p 0.3487, r 0.3309, f1: 0.3293	micro: p 0.5552, r 0.5552, f1 0.5552	weighted_f1:0.5359
global_step: 5401, epoch: 36, loss: 0.434483
global_step: 5402, epoch: 36, loss: 0.393307
global_step: 5403, epoch: 36, loss: 0.412183
global_step: 5404, epoch: 36, loss: 0.423672
global_step: 5405, epoch: 36, loss: 0.467297
global_step: 5406, epoch: 36, loss: 0.416865
global_step: 5407, epoch: 36, loss: 0.418132
global_step: 5408, epoch: 36, loss: 0.411249
global_step: 5409, epoch: 36, loss: 0.373450
global_step: 5410, epoch: 36, loss: 0.476953
global_step: 5411, epoch: 36, loss: 0.468223
global_step: 5412, epoch: 36, loss: 0.397053
global_step: 5413, epoch: 36, loss: 0.359899
global_step: 5414, epoch: 36, loss: 0.464861
global_step: 5415, epoch: 36, loss: 0.473218
global_step: 5416, epoch: 36, loss: 0.415622
global_step: 5417, epoch: 36, loss: 0.390080
global_step: 5418, epoch: 36, loss: 0.322536
global_step: 5419, epoch: 36, loss: 0.543419
global_step: 5420, epoch: 36, loss: 0.352210
global_step: 5421, epoch: 36, loss: 0.405061
global_step: 5422, epoch: 36, loss: 0.563639
global_step: 5423, epoch: 36, loss: 0.392332
global_step: 5424, epoch: 36, loss: 0.462172
global_step: 5425, epoch: 36, loss: 0.374856
global_step: 5426, epoch: 36, loss: 0.376274
global_step: 5427, epoch: 36, loss: 0.419685
global_step: 5428, epoch: 36, loss: 0.421437
global_step: 5429, epoch: 36, loss: 0.547374
global_step: 5430, epoch: 36, loss: 0.435530
global_step: 5431, epoch: 36, loss: 0.484288
global_step: 5432, epoch: 36, loss: 0.490372
global_step: 5433, epoch: 36, loss: 0.447180
global_step: 5434, epoch: 36, loss: 0.428518
global_step: 5435, epoch: 36, loss: 0.426659
global_step: 5436, epoch: 36, loss: 0.406799
global_step: 5437, epoch: 36, loss: 0.446344
global_step: 5438, epoch: 36, loss: 0.559664
global_step: 5439, epoch: 36, loss: 0.476207
global_step: 5440, epoch: 36, loss: 0.642643
epoch: 36
train	acc: 0.9446	macro: p 0.9473, r 0.9083, f1: 0.9258	micro: p 0.9446, r 0.9446, f1 0.9446	weighted_f1:0.9446
dev	acc: 0.5095	macro: p 0.3380, r 0.3039, f1: 0.3025	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4793
test	acc: 0.5766	macro: p 0.3680, r 0.3272, f1: 0.3301	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5500
global_step: 5441, epoch: 37, loss: 0.496683
global_step: 5442, epoch: 37, loss: 0.411443
global_step: 5443, epoch: 37, loss: 0.367453
global_step: 5444, epoch: 37, loss: 0.333850
global_step: 5445, epoch: 37, loss: 0.421091
global_step: 5446, epoch: 37, loss: 0.361771
global_step: 5447, epoch: 37, loss: 0.485890
global_step: 5448, epoch: 37, loss: 0.414151
global_step: 5449, epoch: 37, loss: 0.428519
global_step: 5450, epoch: 37, loss: 0.393583
global_step: 5451, epoch: 37, loss: 0.350731
global_step: 5452, epoch: 37, loss: 0.338931
global_step: 5453, epoch: 37, loss: 0.354824
global_step: 5454, epoch: 37, loss: 0.412328
global_step: 5455, epoch: 37, loss: 0.436399
global_step: 5456, epoch: 37, loss: 0.431120
global_step: 5457, epoch: 37, loss: 0.547536
global_step: 5458, epoch: 37, loss: 0.348416
global_step: 5459, epoch: 37, loss: 0.415540
global_step: 5460, epoch: 37, loss: 0.352900
global_step: 5461, epoch: 37, loss: 0.426269
global_step: 5462, epoch: 37, loss: 0.455408
global_step: 5463, epoch: 37, loss: 0.456034
global_step: 5464, epoch: 37, loss: 0.464426
global_step: 5465, epoch: 37, loss: 0.510769
global_step: 5466, epoch: 37, loss: 0.396874
global_step: 5467, epoch: 37, loss: 0.437570
global_step: 5468, epoch: 37, loss: 0.463271
global_step: 5469, epoch: 37, loss: 0.357555
global_step: 5470, epoch: 37, loss: 0.435920
global_step: 5471, epoch: 37, loss: 0.438006
global_step: 5472, epoch: 37, loss: 0.398176
global_step: 5473, epoch: 37, loss: 0.465675
global_step: 5474, epoch: 37, loss: 0.400761
global_step: 5475, epoch: 37, loss: 0.441077
global_step: 5476, epoch: 37, loss: 0.377433
global_step: 5477, epoch: 37, loss: 0.476255
global_step: 5478, epoch: 37, loss: 0.478544
global_step: 5479, epoch: 37, loss: 0.477154
global_step: 5480, epoch: 37, loss: 0.349976
epoch: 37
train	acc: 0.9467	macro: p 0.9523, r 0.9210, f1: 0.9351	micro: p 0.9467, r 0.9467, f1 0.9467	weighted_f1:0.9469
dev	acc: 0.4860	macro: p 0.3361, r 0.2988, f1: 0.2948	micro: p 0.4860, r 0.4860, f1 0.4860	weighted_f1:0.4583
test	acc: 0.5502	macro: p 0.3694, r 0.3253, f1: 0.3253	micro: p 0.5502, r 0.5502, f1 0.5502	weighted_f1:0.5308
global_step: 5481, epoch: 38, loss: 0.377112
global_step: 5482, epoch: 38, loss: 0.464341
global_step: 5483, epoch: 38, loss: 0.422312
global_step: 5484, epoch: 38, loss: 0.394322
global_step: 5485, epoch: 38, loss: 0.450205
global_step: 5486, epoch: 38, loss: 0.377746
global_step: 5487, epoch: 38, loss: 0.342905
global_step: 5488, epoch: 38, loss: 0.318689
global_step: 5489, epoch: 38, loss: 0.292611
global_step: 5490, epoch: 38, loss: 0.436770
global_step: 5491, epoch: 38, loss: 0.329787
global_step: 5492, epoch: 38, loss: 0.394525
global_step: 5493, epoch: 38, loss: 0.460393
global_step: 5494, epoch: 38, loss: 0.391880
global_step: 5495, epoch: 38, loss: 0.565542
global_step: 5496, epoch: 38, loss: 0.430739
global_step: 5497, epoch: 38, loss: 0.376072
global_step: 5498, epoch: 38, loss: 0.325543
global_step: 5499, epoch: 38, loss: 0.446819
global_step: 5500, epoch: 38, loss: 0.368028
global_step: 5501, epoch: 38, loss: 0.406334
global_step: 5502, epoch: 38, loss: 0.461681
global_step: 5503, epoch: 38, loss: 0.297800
global_step: 5504, epoch: 38, loss: 0.419754
global_step: 5505, epoch: 38, loss: 0.427674
global_step: 5506, epoch: 38, loss: 0.340421
global_step: 5507, epoch: 38, loss: 0.451205
global_step: 5508, epoch: 38, loss: 0.449444
global_step: 5509, epoch: 38, loss: 0.455661
global_step: 5510, epoch: 38, loss: 0.487072
global_step: 5511, epoch: 38, loss: 0.422864
global_step: 5512, epoch: 38, loss: 0.390648
global_step: 5513, epoch: 38, loss: 0.311859
global_step: 5514, epoch: 38, loss: 0.474299
global_step: 5515, epoch: 38, loss: 0.395617
global_step: 5516, epoch: 38, loss: 0.462078
global_step: 5517, epoch: 38, loss: 0.492787
global_step: 5518, epoch: 38, loss: 0.445775
global_step: 5519, epoch: 38, loss: 0.457068
global_step: 5520, epoch: 38, loss: 0.229257
epoch: 38
train	acc: 0.9499	macro: p 0.9566, r 0.9231, f1: 0.9387	micro: p 0.9499, r 0.9499, f1 0.9499	weighted_f1:0.9499
dev	acc: 0.5266	macro: p 0.3454, r 0.3030, f1: 0.3077	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4851
test	acc: 0.5843	macro: p 0.3759, r 0.3258, f1: 0.3365	micro: p 0.5843, r 0.5843, f1 0.5843	weighted_f1:0.5515
global_step: 5521, epoch: 39, loss: 0.431970
global_step: 5522, epoch: 39, loss: 0.354413
global_step: 5523, epoch: 39, loss: 0.321678
global_step: 5524, epoch: 39, loss: 0.342317
global_step: 5525, epoch: 39, loss: 0.333104
global_step: 5526, epoch: 39, loss: 0.459239
global_step: 5527, epoch: 39, loss: 0.378555
global_step: 5528, epoch: 39, loss: 0.291897
global_step: 5529, epoch: 39, loss: 0.463464
global_step: 5530, epoch: 39, loss: 0.377833
global_step: 5531, epoch: 39, loss: 0.426656
global_step: 5532, epoch: 39, loss: 0.365019
global_step: 5533, epoch: 39, loss: 0.345425
global_step: 5534, epoch: 39, loss: 0.359921
global_step: 5535, epoch: 39, loss: 0.359319
global_step: 5536, epoch: 39, loss: 0.334801
global_step: 5537, epoch: 39, loss: 0.397440
global_step: 5538, epoch: 39, loss: 0.454937
global_step: 5539, epoch: 39, loss: 0.353321
global_step: 5540, epoch: 39, loss: 0.421690
global_step: 5541, epoch: 39, loss: 0.402501
global_step: 5542, epoch: 39, loss: 0.305882
global_step: 5543, epoch: 39, loss: 0.377522
global_step: 5544, epoch: 39, loss: 0.348552
global_step: 5545, epoch: 39, loss: 0.285682
global_step: 5546, epoch: 39, loss: 0.343073
global_step: 5547, epoch: 39, loss: 0.299754
global_step: 5548, epoch: 39, loss: 0.531691
global_step: 5549, epoch: 39, loss: 0.496538
global_step: 5550, epoch: 39, loss: 0.399907
global_step: 5551, epoch: 39, loss: 0.415076
global_step: 5552, epoch: 39, loss: 0.442802
global_step: 5553, epoch: 39, loss: 0.330368
global_step: 5554, epoch: 39, loss: 0.419802
global_step: 5555, epoch: 39, loss: 0.363527
global_step: 5556, epoch: 39, loss: 0.424054
global_step: 5557, epoch: 39, loss: 0.381956
global_step: 5558, epoch: 39, loss: 0.482552
global_step: 5559, epoch: 39, loss: 0.402556
global_step: 5560, epoch: 39, loss: 0.457869
epoch: 39
train	acc: 0.9483	macro: p 0.9422, r 0.9292, f1: 0.9349	micro: p 0.9483, r 0.9483, f1 0.9483	weighted_f1:0.9485
dev	acc: 0.5077	macro: p 0.3215, r 0.3025, f1: 0.3043	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4821
test	acc: 0.5644	macro: p 0.3521, r 0.3289, f1: 0.3320	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5423
global_step: 5561, epoch: 40, loss: 0.390928
global_step: 5562, epoch: 40, loss: 0.328108
global_step: 5563, epoch: 40, loss: 0.376965
global_step: 5564, epoch: 40, loss: 0.405256
global_step: 5565, epoch: 40, loss: 0.359837
global_step: 5566, epoch: 40, loss: 0.390375
global_step: 5567, epoch: 40, loss: 0.380410
global_step: 5568, epoch: 40, loss: 0.383786
global_step: 5569, epoch: 40, loss: 0.408143
global_step: 5570, epoch: 40, loss: 0.322374
global_step: 5571, epoch: 40, loss: 0.384280
global_step: 5572, epoch: 40, loss: 0.352965
global_step: 5573, epoch: 40, loss: 0.417331
global_step: 5574, epoch: 40, loss: 0.344542
global_step: 5575, epoch: 40, loss: 0.430616
global_step: 5576, epoch: 40, loss: 0.418043
global_step: 5577, epoch: 40, loss: 0.289358
global_step: 5578, epoch: 40, loss: 0.480655
global_step: 5579, epoch: 40, loss: 0.432816
global_step: 5580, epoch: 40, loss: 0.316667
global_step: 5581, epoch: 40, loss: 0.354762
global_step: 5582, epoch: 40, loss: 0.480652
global_step: 5583, epoch: 40, loss: 0.355037
global_step: 5584, epoch: 40, loss: 0.468423
global_step: 5585, epoch: 40, loss: 0.447371
global_step: 5586, epoch: 40, loss: 0.442336
global_step: 5587, epoch: 40, loss: 0.344172
global_step: 5588, epoch: 40, loss: 0.297655
global_step: 5589, epoch: 40, loss: 0.409928
global_step: 5590, epoch: 40, loss: 0.396694
global_step: 5591, epoch: 40, loss: 0.470986
global_step: 5592, epoch: 40, loss: 0.394637
global_step: 5593, epoch: 40, loss: 0.404930
global_step: 5594, epoch: 40, loss: 0.433806
global_step: 5595, epoch: 40, loss: 0.360858
global_step: 5596, epoch: 40, loss: 0.413593
global_step: 5597, epoch: 40, loss: 0.324984
global_step: 5598, epoch: 40, loss: 0.548335
global_step: 5599, epoch: 40, loss: 0.421680
global_step: 5600, epoch: 40, loss: 0.344936
epoch: 40
train	acc: 0.9542	macro: p 0.9578, r 0.9288, f1: 0.9424	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9542
dev	acc: 0.5131	macro: p 0.3276, r 0.2992, f1: 0.3037	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4794
test	acc: 0.5778	macro: p 0.3764, r 0.3338, f1: 0.3440	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5533
global_step: 5601, epoch: 41, loss: 0.439137
global_step: 5602, epoch: 41, loss: 0.411647
global_step: 5603, epoch: 41, loss: 0.320116
global_step: 5604, epoch: 41, loss: 0.396686
global_step: 5605, epoch: 41, loss: 0.421717
global_step: 5606, epoch: 41, loss: 0.318205
global_step: 5607, epoch: 41, loss: 0.423193
global_step: 5608, epoch: 41, loss: 0.387388
global_step: 5609, epoch: 41, loss: 0.418067
global_step: 5610, epoch: 41, loss: 0.358798
global_step: 5611, epoch: 41, loss: 0.273006
global_step: 5612, epoch: 41, loss: 0.343912
global_step: 5613, epoch: 41, loss: 0.409157
global_step: 5614, epoch: 41, loss: 0.394256
global_step: 5615, epoch: 41, loss: 0.346747
global_step: 5616, epoch: 41, loss: 0.422119
global_step: 5617, epoch: 41, loss: 0.396145
global_step: 5618, epoch: 41, loss: 0.354129
global_step: 5619, epoch: 41, loss: 0.357759
global_step: 5620, epoch: 41, loss: 0.383374
global_step: 5621, epoch: 41, loss: 0.432861
global_step: 5622, epoch: 41, loss: 0.402905
global_step: 5623, epoch: 41, loss: 0.442419
global_step: 5624, epoch: 41, loss: 0.377370
global_step: 5625, epoch: 41, loss: 0.333915
global_step: 5626, epoch: 41, loss: 0.329735
global_step: 5627, epoch: 41, loss: 0.446796
global_step: 5628, epoch: 41, loss: 0.425671
global_step: 5629, epoch: 41, loss: 0.412430
global_step: 5630, epoch: 41, loss: 0.402508
global_step: 5631, epoch: 41, loss: 0.348544
global_step: 5632, epoch: 41, loss: 0.423513
global_step: 5633, epoch: 41, loss: 0.327950
global_step: 5634, epoch: 41, loss: 0.355624
global_step: 5635, epoch: 41, loss: 0.479415
global_step: 5636, epoch: 41, loss: 0.436275
global_step: 5637, epoch: 41, loss: 0.414762
global_step: 5638, epoch: 41, loss: 0.439411
global_step: 5639, epoch: 41, loss: 0.523459
global_step: 5640, epoch: 41, loss: 0.176335
epoch: 41
train	acc: 0.9556	macro: p 0.9576, r 0.9344, f1: 0.9454	micro: p 0.9556, r 0.9556, f1 0.9556	weighted_f1:0.9556
dev	acc: 0.4959	macro: p 0.3214, r 0.3007, f1: 0.3001	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4680
test	acc: 0.5655	macro: p 0.3657, r 0.3298, f1: 0.3352	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5420
global_step: 5641, epoch: 42, loss: 0.393082
global_step: 5642, epoch: 42, loss: 0.387895
global_step: 5643, epoch: 42, loss: 0.386273
global_step: 5644, epoch: 42, loss: 0.401838
global_step: 5645, epoch: 42, loss: 0.319058
global_step: 5646, epoch: 42, loss: 0.324277
global_step: 5647, epoch: 42, loss: 0.346997
global_step: 5648, epoch: 42, loss: 0.375519
global_step: 5649, epoch: 42, loss: 0.299034
global_step: 5650, epoch: 42, loss: 0.388360
global_step: 5651, epoch: 42, loss: 0.440126
global_step: 5652, epoch: 42, loss: 0.412249
global_step: 5653, epoch: 42, loss: 0.324577
global_step: 5654, epoch: 42, loss: 0.372318
global_step: 5655, epoch: 42, loss: 0.344751
global_step: 5656, epoch: 42, loss: 0.444811
global_step: 5657, epoch: 42, loss: 0.421498
global_step: 5658, epoch: 42, loss: 0.343837
global_step: 5659, epoch: 42, loss: 0.357387
global_step: 5660, epoch: 42, loss: 0.426215
global_step: 5661, epoch: 42, loss: 0.301865
global_step: 5662, epoch: 42, loss: 0.374506
global_step: 5663, epoch: 42, loss: 0.426295
global_step: 5664, epoch: 42, loss: 0.350677
global_step: 5665, epoch: 42, loss: 0.314915
global_step: 5666, epoch: 42, loss: 0.317646
global_step: 5667, epoch: 42, loss: 0.377343
global_step: 5668, epoch: 42, loss: 0.436940
global_step: 5669, epoch: 42, loss: 0.496120
global_step: 5670, epoch: 42, loss: 0.382060
global_step: 5671, epoch: 42, loss: 0.333776
global_step: 5672, epoch: 42, loss: 0.319673
global_step: 5673, epoch: 42, loss: 0.395625
global_step: 5674, epoch: 42, loss: 0.341499
global_step: 5675, epoch: 42, loss: 0.263624
global_step: 5676, epoch: 42, loss: 0.304074
global_step: 5677, epoch: 42, loss: 0.413546
global_step: 5678, epoch: 42, loss: 0.399222
global_step: 5679, epoch: 42, loss: 0.347577
global_step: 5680, epoch: 42, loss: 0.001706
epoch: 42
train	acc: 0.9562	macro: p 0.9619, r 0.9314, f1: 0.9457	micro: p 0.9562, r 0.9562, f1 0.9562	weighted_f1:0.9561
dev	acc: 0.5167	macro: p 0.3660, r 0.3005, f1: 0.3037	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4766
test	acc: 0.5831	macro: p 0.3827, r 0.3249, f1: 0.3303	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5488
global_step: 5681, epoch: 43, loss: 0.322169
global_step: 5682, epoch: 43, loss: 0.298749
global_step: 5683, epoch: 43, loss: 0.384914
global_step: 5684, epoch: 43, loss: 0.299502
global_step: 5685, epoch: 43, loss: 0.296906
global_step: 5686, epoch: 43, loss: 0.345518
global_step: 5687, epoch: 43, loss: 0.350443
global_step: 5688, epoch: 43, loss: 0.322745
global_step: 5689, epoch: 43, loss: 0.339591
global_step: 5690, epoch: 43, loss: 0.337302
global_step: 5691, epoch: 43, loss: 0.371595
global_step: 5692, epoch: 43, loss: 0.371336
global_step: 5693, epoch: 43, loss: 0.348813
global_step: 5694, epoch: 43, loss: 0.288089
global_step: 5695, epoch: 43, loss: 0.360967
global_step: 5696, epoch: 43, loss: 0.412817
global_step: 5697, epoch: 43, loss: 0.406146
global_step: 5698, epoch: 43, loss: 0.385775
global_step: 5699, epoch: 43, loss: 0.442254
global_step: 5700, epoch: 43, loss: 0.420932
global_step: 5701, epoch: 43, loss: 0.390655
global_step: 5702, epoch: 43, loss: 0.402343
global_step: 5703, epoch: 43, loss: 0.338709
global_step: 5704, epoch: 43, loss: 0.380663
global_step: 5705, epoch: 43, loss: 0.307169
global_step: 5706, epoch: 43, loss: 0.484854
global_step: 5707, epoch: 43, loss: 0.444063
global_step: 5708, epoch: 43, loss: 0.339570
global_step: 5709, epoch: 43, loss: 0.407168
global_step: 5710, epoch: 43, loss: 0.363479
global_step: 5711, epoch: 43, loss: 0.367660
global_step: 5712, epoch: 43, loss: 0.408898
global_step: 5713, epoch: 43, loss: 0.364770
global_step: 5714, epoch: 43, loss: 0.423458
global_step: 5715, epoch: 43, loss: 0.448047
global_step: 5716, epoch: 43, loss: 0.307791
global_step: 5717, epoch: 43, loss: 0.445936
global_step: 5718, epoch: 43, loss: 0.350144
global_step: 5719, epoch: 43, loss: 0.409070
global_step: 5720, epoch: 43, loss: 0.455215
epoch: 43
train	acc: 0.9510	macro: p 0.9575, r 0.9279, f1: 0.9417	micro: p 0.9510, r 0.9510, f1 0.9510	weighted_f1:0.9511
dev	acc: 0.5095	macro: p 0.3186, r 0.2800, f1: 0.2761	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4612
test	acc: 0.5793	macro: p 0.3972, r 0.3248, f1: 0.3344	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5432
global_step: 5721, epoch: 44, loss: 0.303770
global_step: 5722, epoch: 44, loss: 0.405814
global_step: 5723, epoch: 44, loss: 0.328302
global_step: 5724, epoch: 44, loss: 0.409311
global_step: 5725, epoch: 44, loss: 0.413675
global_step: 5726, epoch: 44, loss: 0.401479
global_step: 5727, epoch: 44, loss: 0.303372
global_step: 5728, epoch: 44, loss: 0.243122
global_step: 5729, epoch: 44, loss: 0.341746
global_step: 5730, epoch: 44, loss: 0.356180
global_step: 5731, epoch: 44, loss: 0.341748
global_step: 5732, epoch: 44, loss: 0.439112
global_step: 5733, epoch: 44, loss: 0.310901
global_step: 5734, epoch: 44, loss: 0.350790
global_step: 5735, epoch: 44, loss: 0.351149
global_step: 5736, epoch: 44, loss: 0.272471
global_step: 5737, epoch: 44, loss: 0.432555
global_step: 5738, epoch: 44, loss: 0.473452
global_step: 5739, epoch: 44, loss: 0.353187
global_step: 5740, epoch: 44, loss: 0.394816
global_step: 5741, epoch: 44, loss: 0.368490
global_step: 5742, epoch: 44, loss: 0.394398
global_step: 5743, epoch: 44, loss: 0.320344
global_step: 5744, epoch: 44, loss: 0.323958
global_step: 5745, epoch: 44, loss: 0.403707
global_step: 5746, epoch: 44, loss: 0.376342
global_step: 5747, epoch: 44, loss: 0.353998
global_step: 5748, epoch: 44, loss: 0.380706
global_step: 5749, epoch: 44, loss: 0.413603
global_step: 5750, epoch: 44, loss: 0.337899
global_step: 5751, epoch: 44, loss: 0.370811
global_step: 5752, epoch: 44, loss: 0.318116
global_step: 5753, epoch: 44, loss: 0.400832
global_step: 5754, epoch: 44, loss: 0.306507
global_step: 5755, epoch: 44, loss: 0.396240
global_step: 5756, epoch: 44, loss: 0.328739
global_step: 5757, epoch: 44, loss: 0.374110
global_step: 5758, epoch: 44, loss: 0.445941
global_step: 5759, epoch: 44, loss: 0.502476
global_step: 5760, epoch: 44, loss: 0.288429
epoch: 44
train	acc: 0.9541	macro: p 0.9592, r 0.9347, f1: 0.9459	micro: p 0.9541, r 0.9541, f1 0.9541	weighted_f1:0.9543
dev	acc: 0.4950	macro: p 0.3226, r 0.2940, f1: 0.2867	micro: p 0.4950, r 0.4950, f1 0.4950	weighted_f1:0.4599
test	acc: 0.5613	macro: p 0.3625, r 0.3311, f1: 0.3286	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5379
global_step: 5761, epoch: 45, loss: 0.283014
global_step: 5762, epoch: 45, loss: 0.339706
global_step: 5763, epoch: 45, loss: 0.336378
global_step: 5764, epoch: 45, loss: 0.373102
global_step: 5765, epoch: 45, loss: 0.363881
global_step: 5766, epoch: 45, loss: 0.375195
global_step: 5767, epoch: 45, loss: 0.330732
global_step: 5768, epoch: 45, loss: 0.400419
global_step: 5769, epoch: 45, loss: 0.311688
global_step: 5770, epoch: 45, loss: 0.344122
global_step: 5771, epoch: 45, loss: 0.352891
global_step: 5772, epoch: 45, loss: 0.433946
global_step: 5773, epoch: 45, loss: 0.301859
global_step: 5774, epoch: 45, loss: 0.351256
global_step: 5775, epoch: 45, loss: 0.308820
global_step: 5776, epoch: 45, loss: 0.301528
global_step: 5777, epoch: 45, loss: 0.421003
global_step: 5778, epoch: 45, loss: 0.371553
global_step: 5779, epoch: 45, loss: 0.334134
global_step: 5780, epoch: 45, loss: 0.344601
global_step: 5781, epoch: 45, loss: 0.299158
global_step: 5782, epoch: 45, loss: 0.413168
global_step: 5783, epoch: 45, loss: 0.310469
global_step: 5784, epoch: 45, loss: 0.372547
global_step: 5785, epoch: 45, loss: 0.377785
global_step: 5786, epoch: 45, loss: 0.417019
global_step: 5787, epoch: 45, loss: 0.333319
global_step: 5788, epoch: 45, loss: 0.332274
global_step: 5789, epoch: 45, loss: 0.354767
global_step: 5790, epoch: 45, loss: 0.311495
global_step: 5791, epoch: 45, loss: 0.361309
global_step: 5792, epoch: 45, loss: 0.382201
global_step: 5793, epoch: 45, loss: 0.358072
global_step: 5794, epoch: 45, loss: 0.302617
global_step: 5795, epoch: 45, loss: 0.298800
global_step: 5796, epoch: 45, loss: 0.442233
global_step: 5797, epoch: 45, loss: 0.434270
global_step: 5798, epoch: 45, loss: 0.372196
global_step: 5799, epoch: 45, loss: 0.359323
global_step: 5800, epoch: 45, loss: 0.416527
epoch: 45
train	acc: 0.9515	macro: p 0.9640, r 0.9222, f1: 0.9417	micro: p 0.9515, r 0.9515, f1 0.9515	weighted_f1:0.9514
dev	acc: 0.5185	macro: p 0.3751, r 0.2893, f1: 0.2917	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4680
test	acc: 0.5858	macro: p 0.3654, r 0.3077, f1: 0.3149	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5434
global_step: 5801, epoch: 46, loss: 0.313392
global_step: 5802, epoch: 46, loss: 0.306080
global_step: 5803, epoch: 46, loss: 0.370485
global_step: 5804, epoch: 46, loss: 0.322250
global_step: 5805, epoch: 46, loss: 0.271473
global_step: 5806, epoch: 46, loss: 0.289409
global_step: 5807, epoch: 46, loss: 0.438381
global_step: 5808, epoch: 46, loss: 0.425687
global_step: 5809, epoch: 46, loss: 0.356253
global_step: 5810, epoch: 46, loss: 0.331578
global_step: 5811, epoch: 46, loss: 0.263045
global_step: 5812, epoch: 46, loss: 0.275703
global_step: 5813, epoch: 46, loss: 0.367671
global_step: 5814, epoch: 46, loss: 0.283143
global_step: 5815, epoch: 46, loss: 0.307665
global_step: 5816, epoch: 46, loss: 0.386548
global_step: 5817, epoch: 46, loss: 0.360417
global_step: 5818, epoch: 46, loss: 0.319647
global_step: 5819, epoch: 46, loss: 0.320293
global_step: 5820, epoch: 46, loss: 0.334449
global_step: 5821, epoch: 46, loss: 0.258809
global_step: 5822, epoch: 46, loss: 0.262314
global_step: 5823, epoch: 46, loss: 0.327386
global_step: 5824, epoch: 46, loss: 0.410150
global_step: 5825, epoch: 46, loss: 0.456945
global_step: 5826, epoch: 46, loss: 0.364688
global_step: 5827, epoch: 46, loss: 0.349784
global_step: 5828, epoch: 46, loss: 0.485345
global_step: 5829, epoch: 46, loss: 0.336424
global_step: 5830, epoch: 46, loss: 0.396414
global_step: 5831, epoch: 46, loss: 0.403796
global_step: 5832, epoch: 46, loss: 0.304007
global_step: 5833, epoch: 46, loss: 0.389204
global_step: 5834, epoch: 46, loss: 0.297159
global_step: 5835, epoch: 46, loss: 0.406414
global_step: 5836, epoch: 46, loss: 0.246554
global_step: 5837, epoch: 46, loss: 0.296122
global_step: 5838, epoch: 46, loss: 0.345883
global_step: 5839, epoch: 46, loss: 0.392086
global_step: 5840, epoch: 46, loss: 0.049820
epoch: 46
train	acc: 0.9584	macro: p 0.9674, r 0.9374, f1: 0.9518	micro: p 0.9584, r 0.9584, f1 0.9584	weighted_f1:0.9583
dev	acc: 0.5176	macro: p 0.3121, r 0.2836, f1: 0.2824	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4692
test	acc: 0.5912	macro: p 0.3783, r 0.3220, f1: 0.3316	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5530
global_step: 5841, epoch: 47, loss: 0.274736
global_step: 5842, epoch: 47, loss: 0.298354
global_step: 5843, epoch: 47, loss: 0.289050
global_step: 5844, epoch: 47, loss: 0.326198
global_step: 5845, epoch: 47, loss: 0.286026
global_step: 5846, epoch: 47, loss: 0.308081
global_step: 5847, epoch: 47, loss: 0.362381
global_step: 5848, epoch: 47, loss: 0.380840
global_step: 5849, epoch: 47, loss: 0.274131
global_step: 5850, epoch: 47, loss: 0.295306
global_step: 5851, epoch: 47, loss: 0.398580
global_step: 5852, epoch: 47, loss: 0.343404
global_step: 5853, epoch: 47, loss: 0.338841
global_step: 5854, epoch: 47, loss: 0.326215
global_step: 5855, epoch: 47, loss: 0.315649
global_step: 5856, epoch: 47, loss: 0.235033
global_step: 5857, epoch: 47, loss: 0.458970
global_step: 5858, epoch: 47, loss: 0.329779
global_step: 5859, epoch: 47, loss: 0.270310
global_step: 5860, epoch: 47, loss: 0.312053
global_step: 5861, epoch: 47, loss: 0.309255
global_step: 5862, epoch: 47, loss: 0.311258
global_step: 5863, epoch: 47, loss: 0.258695
global_step: 5864, epoch: 47, loss: 0.330283
global_step: 5865, epoch: 47, loss: 0.287036
global_step: 5866, epoch: 47, loss: 0.433719
global_step: 5867, epoch: 47, loss: 0.365143
global_step: 5868, epoch: 47, loss: 0.279502
global_step: 5869, epoch: 47, loss: 0.380124
global_step: 5870, epoch: 47, loss: 0.450149
global_step: 5871, epoch: 47, loss: 0.370281
global_step: 5872, epoch: 47, loss: 0.457511
global_step: 5873, epoch: 47, loss: 0.370826
global_step: 5874, epoch: 47, loss: 0.404667
global_step: 5875, epoch: 47, loss: 0.342179
global_step: 5876, epoch: 47, loss: 0.319250
global_step: 5877, epoch: 47, loss: 0.450362
global_step: 5878, epoch: 47, loss: 0.389879
global_step: 5879, epoch: 47, loss: 0.367254
global_step: 5880, epoch: 47, loss: 0.077385
epoch: 47
train	acc: 0.9540	macro: p 0.9610, r 0.9309, f1: 0.9452	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9539
dev	acc: 0.5203	macro: p 0.3676, r 0.2999, f1: 0.3061	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4790
test	acc: 0.5820	macro: p 0.3871, r 0.3207, f1: 0.3304	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5469
global_step: 5881, epoch: 48, loss: 0.405467
global_step: 5882, epoch: 48, loss: 0.359829
global_step: 5883, epoch: 48, loss: 0.377764
global_step: 5884, epoch: 48, loss: 0.337314
global_step: 5885, epoch: 48, loss: 0.313367
global_step: 5886, epoch: 48, loss: 0.225174
global_step: 5887, epoch: 48, loss: 0.299776
global_step: 5888, epoch: 48, loss: 0.309826
global_step: 5889, epoch: 48, loss: 0.302138
global_step: 5890, epoch: 48, loss: 0.247572
global_step: 5891, epoch: 48, loss: 0.365682
global_step: 5892, epoch: 48, loss: 0.370225
global_step: 5893, epoch: 48, loss: 0.372463
global_step: 5894, epoch: 48, loss: 0.467988
global_step: 5895, epoch: 48, loss: 0.326575
global_step: 5896, epoch: 48, loss: 0.294117
global_step: 5897, epoch: 48, loss: 0.346692
global_step: 5898, epoch: 48, loss: 0.323996
global_step: 5899, epoch: 48, loss: 0.250762
global_step: 5900, epoch: 48, loss: 0.270607
global_step: 5901, epoch: 48, loss: 0.277422
global_step: 5902, epoch: 48, loss: 0.337870
global_step: 5903, epoch: 48, loss: 0.281435
global_step: 5904, epoch: 48, loss: 0.379101
global_step: 5905, epoch: 48, loss: 0.324645
global_step: 5906, epoch: 48, loss: 0.226662
global_step: 5907, epoch: 48, loss: 0.344982
global_step: 5908, epoch: 48, loss: 0.250039
global_step: 5909, epoch: 48, loss: 0.361409
global_step: 5910, epoch: 48, loss: 0.298965
global_step: 5911, epoch: 48, loss: 0.324961
global_step: 5912, epoch: 48, loss: 0.470607
global_step: 5913, epoch: 48, loss: 0.461653
global_step: 5914, epoch: 48, loss: 0.330816
global_step: 5915, epoch: 48, loss: 0.351491
global_step: 5916, epoch: 48, loss: 0.254422
global_step: 5917, epoch: 48, loss: 0.322285
global_step: 5918, epoch: 48, loss: 0.421193
global_step: 5919, epoch: 48, loss: 0.421872
global_step: 5920, epoch: 48, loss: 0.045462
epoch: 48
train	acc: 0.9530	macro: p 0.9593, r 0.9273, f1: 0.9417	micro: p 0.9530, r 0.9530, f1 0.9530	weighted_f1:0.9533
dev	acc: 0.5167	macro: p 0.3805, r 0.3041, f1: 0.3055	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4733
test	acc: 0.5782	macro: p 0.4056, r 0.3242, f1: 0.3292	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5413
global_step: 5921, epoch: 49, loss: 0.342891
global_step: 5922, epoch: 49, loss: 0.309020
global_step: 5923, epoch: 49, loss: 0.357186
global_step: 5924, epoch: 49, loss: 0.296872
global_step: 5925, epoch: 49, loss: 0.371421
global_step: 5926, epoch: 49, loss: 0.326901
global_step: 5927, epoch: 49, loss: 0.323474
global_step: 5928, epoch: 49, loss: 0.257177
global_step: 5929, epoch: 49, loss: 0.397319
global_step: 5930, epoch: 49, loss: 0.276096
global_step: 5931, epoch: 49, loss: 0.366896
global_step: 5932, epoch: 49, loss: 0.449924
global_step: 5933, epoch: 49, loss: 0.327691
global_step: 5934, epoch: 49, loss: 0.379693
global_step: 5935, epoch: 49, loss: 0.255840
global_step: 5936, epoch: 49, loss: 0.282320
global_step: 5937, epoch: 49, loss: 0.291461
global_step: 5938, epoch: 49, loss: 0.332639
global_step: 5939, epoch: 49, loss: 0.294186
global_step: 5940, epoch: 49, loss: 0.339276
global_step: 5941, epoch: 49, loss: 0.400420
global_step: 5942, epoch: 49, loss: 0.333459
global_step: 5943, epoch: 49, loss: 0.366157
global_step: 5944, epoch: 49, loss: 0.345900
global_step: 5945, epoch: 49, loss: 0.309176
global_step: 5946, epoch: 49, loss: 0.366028
global_step: 5947, epoch: 49, loss: 0.324224
global_step: 5948, epoch: 49, loss: 0.329887
global_step: 5949, epoch: 49, loss: 0.459920
global_step: 5950, epoch: 49, loss: 0.419133
global_step: 5951, epoch: 49, loss: 0.379087
global_step: 5952, epoch: 49, loss: 0.342515
global_step: 5953, epoch: 49, loss: 0.436905
global_step: 5954, epoch: 49, loss: 0.468890
global_step: 5955, epoch: 49, loss: 0.396058
global_step: 5956, epoch: 49, loss: 0.342077
global_step: 5957, epoch: 49, loss: 0.332620
global_step: 5958, epoch: 49, loss: 0.356943
global_step: 5959, epoch: 49, loss: 0.337522
global_step: 5960, epoch: 49, loss: 0.942365
epoch: 49
train	acc: 0.9542	macro: p 0.9692, r 0.9281, f1: 0.9477	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9541
dev	acc: 0.4968	macro: p 0.3610, r 0.2834, f1: 0.2883	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.4556
test	acc: 0.5713	macro: p 0.3998, r 0.3147, f1: 0.3250	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5342
global_step: 5961, epoch: 50, loss: 0.297743
global_step: 5962, epoch: 50, loss: 0.417214
global_step: 5963, epoch: 50, loss: 0.273426
global_step: 5964, epoch: 50, loss: 0.440275
global_step: 5965, epoch: 50, loss: 0.346829
global_step: 5966, epoch: 50, loss: 0.245561
global_step: 5967, epoch: 50, loss: 0.352743
global_step: 5968, epoch: 50, loss: 0.234102
global_step: 5969, epoch: 50, loss: 0.319471
global_step: 5970, epoch: 50, loss: 0.362857
global_step: 5971, epoch: 50, loss: 0.324641
global_step: 5972, epoch: 50, loss: 0.303616
global_step: 5973, epoch: 50, loss: 0.369867
global_step: 5974, epoch: 50, loss: 0.324992
global_step: 5975, epoch: 50, loss: 0.394383
global_step: 5976, epoch: 50, loss: 0.381930
global_step: 5977, epoch: 50, loss: 0.293616
global_step: 5978, epoch: 50, loss: 0.254673
global_step: 5979, epoch: 50, loss: 0.327360
global_step: 5980, epoch: 50, loss: 0.284777
global_step: 5981, epoch: 50, loss: 0.325455
global_step: 5982, epoch: 50, loss: 0.349159
global_step: 5983, epoch: 50, loss: 0.308669
global_step: 5984, epoch: 50, loss: 0.369185
global_step: 5985, epoch: 50, loss: 0.374353
global_step: 5986, epoch: 50, loss: 0.313645
global_step: 5987, epoch: 50, loss: 0.346777
global_step: 5988, epoch: 50, loss: 0.348426
global_step: 5989, epoch: 50, loss: 0.343053
global_step: 5990, epoch: 50, loss: 0.401208
global_step: 5991, epoch: 50, loss: 0.467624
global_step: 5992, epoch: 50, loss: 0.380557
global_step: 5993, epoch: 50, loss: 0.362173
global_step: 5994, epoch: 50, loss: 0.302964
global_step: 5995, epoch: 50, loss: 0.263475
global_step: 5996, epoch: 50, loss: 0.371980
global_step: 5997, epoch: 50, loss: 0.274656
global_step: 5998, epoch: 50, loss: 0.318895
global_step: 5999, epoch: 50, loss: 0.320731
global_step: 6000, epoch: 50, loss: 0.251820
epoch: 50
train	acc: 0.9608	macro: p 0.9664, r 0.9418, f1: 0.9535	micro: p 0.9608, r 0.9608, f1 0.9608	weighted_f1:0.9608
dev	acc: 0.5149	macro: p 0.3471, r 0.3092, f1: 0.3140	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4835
test	acc: 0.5747	macro: p 0.3556, r 0.3222, f1: 0.3264	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5455
global_step: 6001, epoch: 51, loss: 0.268130
global_step: 6002, epoch: 51, loss: 0.317990
global_step: 6003, epoch: 51, loss: 0.267219
global_step: 6004, epoch: 51, loss: 0.281061
global_step: 6005, epoch: 51, loss: 0.282785
global_step: 6006, epoch: 51, loss: 0.347920
global_step: 6007, epoch: 51, loss: 0.251487
global_step: 6008, epoch: 51, loss: 0.369406
global_step: 6009, epoch: 51, loss: 0.243732
global_step: 6010, epoch: 51, loss: 0.350688
global_step: 6011, epoch: 51, loss: 0.334054
global_step: 6012, epoch: 51, loss: 0.414287
global_step: 6013, epoch: 51, loss: 0.377922
global_step: 6014, epoch: 51, loss: 0.328542
global_step: 6015, epoch: 51, loss: 0.407107
global_step: 6016, epoch: 51, loss: 0.364059
global_step: 6017, epoch: 51, loss: 0.278277
global_step: 6018, epoch: 51, loss: 0.286243
global_step: 6019, epoch: 51, loss: 0.392450
global_step: 6020, epoch: 51, loss: 0.347110
global_step: 6021, epoch: 51, loss: 0.418986
global_step: 6022, epoch: 51, loss: 0.336642
global_step: 6023, epoch: 51, loss: 0.440224
global_step: 6024, epoch: 51, loss: 0.276165
global_step: 6025, epoch: 51, loss: 0.276782
global_step: 6026, epoch: 51, loss: 0.270498
global_step: 6027, epoch: 51, loss: 0.402193
global_step: 6028, epoch: 51, loss: 0.350576
global_step: 6029, epoch: 51, loss: 0.369247
global_step: 6030, epoch: 51, loss: 0.257755
global_step: 6031, epoch: 51, loss: 0.489941
global_step: 6032, epoch: 51, loss: 0.296840
global_step: 6033, epoch: 51, loss: 0.297423
global_step: 6034, epoch: 51, loss: 0.315487
global_step: 6035, epoch: 51, loss: 0.361287
global_step: 6036, epoch: 51, loss: 0.320382
global_step: 6037, epoch: 51, loss: 0.351787
global_step: 6038, epoch: 51, loss: 0.382974
global_step: 6039, epoch: 51, loss: 0.304387
global_step: 6040, epoch: 51, loss: 0.076320
epoch: 51
train	acc: 0.9609	macro: p 0.9665, r 0.9379, f1: 0.9513	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9609
dev	acc: 0.5104	macro: p 0.3513, r 0.3086, f1: 0.3109	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4760
test	acc: 0.5736	macro: p 0.3735, r 0.3276, f1: 0.3286	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5435
global_step: 6041, epoch: 52, loss: 0.412447
global_step: 6042, epoch: 52, loss: 0.352276
global_step: 6043, epoch: 52, loss: 0.284436
global_step: 6044, epoch: 52, loss: 0.282861
global_step: 6045, epoch: 52, loss: 0.306369
global_step: 6046, epoch: 52, loss: 0.196053
global_step: 6047, epoch: 52, loss: 0.290656
global_step: 6048, epoch: 52, loss: 0.346730
global_step: 6049, epoch: 52, loss: 0.254515
global_step: 6050, epoch: 52, loss: 0.365391
global_step: 6051, epoch: 52, loss: 0.355345
global_step: 6052, epoch: 52, loss: 0.300742
global_step: 6053, epoch: 52, loss: 0.275643
global_step: 6054, epoch: 52, loss: 0.314410
global_step: 6055, epoch: 52, loss: 0.322284
global_step: 6056, epoch: 52, loss: 0.328543
global_step: 6057, epoch: 52, loss: 0.246887
global_step: 6058, epoch: 52, loss: 0.269759
global_step: 6059, epoch: 52, loss: 0.301267
global_step: 6060, epoch: 52, loss: 0.256879
global_step: 6061, epoch: 52, loss: 0.270758
global_step: 6062, epoch: 52, loss: 0.400697
global_step: 6063, epoch: 52, loss: 0.287241
global_step: 6064, epoch: 52, loss: 0.288205
global_step: 6065, epoch: 52, loss: 0.276092
global_step: 6066, epoch: 52, loss: 0.306525
global_step: 6067, epoch: 52, loss: 0.323504
global_step: 6068, epoch: 52, loss: 0.374799
global_step: 6069, epoch: 52, loss: 0.329429
global_step: 6070, epoch: 52, loss: 0.345954
global_step: 6071, epoch: 52, loss: 0.370481
global_step: 6072, epoch: 52, loss: 0.325671
global_step: 6073, epoch: 52, loss: 0.379053
global_step: 6074, epoch: 52, loss: 0.353463
global_step: 6075, epoch: 52, loss: 0.304035
global_step: 6076, epoch: 52, loss: 0.305077
global_step: 6077, epoch: 52, loss: 0.386449
global_step: 6078, epoch: 52, loss: 0.438724
global_step: 6079, epoch: 52, loss: 0.294455
global_step: 6080, epoch: 52, loss: 0.116395
epoch: 52
train	acc: 0.9603	macro: p 0.9672, r 0.9372, f1: 0.9514	micro: p 0.9603, r 0.9603, f1 0.9603	weighted_f1:0.9602
dev	acc: 0.5248	macro: p 0.3374, r 0.2915, f1: 0.2902	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4750
test	acc: 0.5912	macro: p 0.3789, r 0.3184, f1: 0.3232	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5493
global_step: 6081, epoch: 53, loss: 0.212610
global_step: 6082, epoch: 53, loss: 0.262661
global_step: 6083, epoch: 53, loss: 0.238142
global_step: 6084, epoch: 53, loss: 0.208628
global_step: 6085, epoch: 53, loss: 0.240866
global_step: 6086, epoch: 53, loss: 0.234287
global_step: 6087, epoch: 53, loss: 0.347551
global_step: 6088, epoch: 53, loss: 0.325968
global_step: 6089, epoch: 53, loss: 0.287080
global_step: 6090, epoch: 53, loss: 0.261658
global_step: 6091, epoch: 53, loss: 0.279025
global_step: 6092, epoch: 53, loss: 0.325611
global_step: 6093, epoch: 53, loss: 0.343629
global_step: 6094, epoch: 53, loss: 0.301767
global_step: 6095, epoch: 53, loss: 0.303270
global_step: 6096, epoch: 53, loss: 0.275244
global_step: 6097, epoch: 53, loss: 0.250801
global_step: 6098, epoch: 53, loss: 0.298964
global_step: 6099, epoch: 53, loss: 0.346872
global_step: 6100, epoch: 53, loss: 0.315209
global_step: 6101, epoch: 53, loss: 0.356620
global_step: 6102, epoch: 53, loss: 0.274265
global_step: 6103, epoch: 53, loss: 0.237003
global_step: 6104, epoch: 53, loss: 0.340292
global_step: 6105, epoch: 53, loss: 0.377972
global_step: 6106, epoch: 53, loss: 0.265239
global_step: 6107, epoch: 53, loss: 0.299581
global_step: 6108, epoch: 53, loss: 0.368278
global_step: 6109, epoch: 53, loss: 0.256722
global_step: 6110, epoch: 53, loss: 0.342541
global_step: 6111, epoch: 53, loss: 0.293570
global_step: 6112, epoch: 53, loss: 0.362813
global_step: 6113, epoch: 53, loss: 0.483825
global_step: 6114, epoch: 53, loss: 0.364540
global_step: 6115, epoch: 53, loss: 0.264440
global_step: 6116, epoch: 53, loss: 0.264043
global_step: 6117, epoch: 53, loss: 0.300378
global_step: 6118, epoch: 53, loss: 0.300111
global_step: 6119, epoch: 53, loss: 0.177400
global_step: 6120, epoch: 53, loss: 0.373679
epoch: 53
train	acc: 0.9514	macro: p 0.9627, r 0.9291, f1: 0.9444	micro: p 0.9514, r 0.9514, f1 0.9514	weighted_f1:0.9518
dev	acc: 0.5185	macro: p 0.3284, r 0.2924, f1: 0.2845	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4708
test	acc: 0.5701	macro: p 0.3546, r 0.3058, f1: 0.3044	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5313
global_step: 6121, epoch: 54, loss: 0.380854
global_step: 6122, epoch: 54, loss: 0.342362
global_step: 6123, epoch: 54, loss: 0.220882
global_step: 6124, epoch: 54, loss: 0.327998
global_step: 6125, epoch: 54, loss: 0.295114
global_step: 6126, epoch: 54, loss: 0.259523
global_step: 6127, epoch: 54, loss: 0.337785
global_step: 6128, epoch: 54, loss: 0.385367
global_step: 6129, epoch: 54, loss: 0.329605
global_step: 6130, epoch: 54, loss: 0.202422
global_step: 6131, epoch: 54, loss: 0.356486
global_step: 6132, epoch: 54, loss: 0.289409
global_step: 6133, epoch: 54, loss: 0.312471
global_step: 6134, epoch: 54, loss: 0.317489
global_step: 6135, epoch: 54, loss: 0.241011
global_step: 6136, epoch: 54, loss: 0.346720
global_step: 6137, epoch: 54, loss: 0.214800
global_step: 6138, epoch: 54, loss: 0.304348
global_step: 6139, epoch: 54, loss: 0.295374
global_step: 6140, epoch: 54, loss: 0.346193
global_step: 6141, epoch: 54, loss: 0.401468
global_step: 6142, epoch: 54, loss: 0.239128
global_step: 6143, epoch: 54, loss: 0.318193
global_step: 6144, epoch: 54, loss: 0.289070
global_step: 6145, epoch: 54, loss: 0.326860
global_step: 6146, epoch: 54, loss: 0.429383
global_step: 6147, epoch: 54, loss: 0.360588
global_step: 6148, epoch: 54, loss: 0.276363
global_step: 6149, epoch: 54, loss: 0.331612
global_step: 6150, epoch: 54, loss: 0.383738
global_step: 6151, epoch: 54, loss: 0.293978
global_step: 6152, epoch: 54, loss: 0.322919
global_step: 6153, epoch: 54, loss: 0.343624
global_step: 6154, epoch: 54, loss: 0.267746
global_step: 6155, epoch: 54, loss: 0.244545
global_step: 6156, epoch: 54, loss: 0.341248
global_step: 6157, epoch: 54, loss: 0.271328
global_step: 6158, epoch: 54, loss: 0.446975
global_step: 6159, epoch: 54, loss: 0.288462
global_step: 6160, epoch: 54, loss: 0.911418
epoch: 54
train	acc: 0.9635	macro: p 0.9643, r 0.9431, f1: 0.9531	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9635
dev	acc: 0.5068	macro: p 0.3222, r 0.2924, f1: 0.2936	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4706
test	acc: 0.5697	macro: p 0.3608, r 0.3161, f1: 0.3200	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5398
global_step: 6161, epoch: 55, loss: 0.350320
global_step: 6162, epoch: 55, loss: 0.244033
global_step: 6163, epoch: 55, loss: 0.365355
global_step: 6164, epoch: 55, loss: 0.271664
global_step: 6165, epoch: 55, loss: 0.327741
global_step: 6166, epoch: 55, loss: 0.371950
global_step: 6167, epoch: 55, loss: 0.328373
global_step: 6168, epoch: 55, loss: 0.309762
global_step: 6169, epoch: 55, loss: 0.272051
global_step: 6170, epoch: 55, loss: 0.320927
global_step: 6171, epoch: 55, loss: 0.214488
global_step: 6172, epoch: 55, loss: 0.208976
global_step: 6173, epoch: 55, loss: 0.267487
global_step: 6174, epoch: 55, loss: 0.281330
global_step: 6175, epoch: 55, loss: 0.231571
global_step: 6176, epoch: 55, loss: 0.405360
global_step: 6177, epoch: 55, loss: 0.247231
global_step: 6178, epoch: 55, loss: 0.398794
global_step: 6179, epoch: 55, loss: 0.352797
global_step: 6180, epoch: 55, loss: 0.360405
global_step: 6181, epoch: 55, loss: 0.287024
global_step: 6182, epoch: 55, loss: 0.253629
global_step: 6183, epoch: 55, loss: 0.338872
global_step: 6184, epoch: 55, loss: 0.276198
global_step: 6185, epoch: 55, loss: 0.247412
global_step: 6186, epoch: 55, loss: 0.321923
global_step: 6187, epoch: 55, loss: 0.398820
global_step: 6188, epoch: 55, loss: 0.285953
global_step: 6189, epoch: 55, loss: 0.351400
global_step: 6190, epoch: 55, loss: 0.468087
global_step: 6191, epoch: 55, loss: 0.274824
global_step: 6192, epoch: 55, loss: 0.278764
global_step: 6193, epoch: 55, loss: 0.294660
global_step: 6194, epoch: 55, loss: 0.395673
global_step: 6195, epoch: 55, loss: 0.310676
global_step: 6196, epoch: 55, loss: 0.241421
global_step: 6197, epoch: 55, loss: 0.325849
global_step: 6198, epoch: 55, loss: 0.245219
global_step: 6199, epoch: 55, loss: 0.334655
global_step: 6200, epoch: 55, loss: 0.162695
epoch: 55
train	acc: 0.9544	macro: p 0.9608, r 0.9352, f1: 0.9463	micro: p 0.9544, r 0.9544, f1 0.9544	weighted_f1:0.9550
dev	acc: 0.5167	macro: p 0.3225, r 0.2927, f1: 0.2874	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4714
test	acc: 0.5720	macro: p 0.3694, r 0.3142, f1: 0.3158	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5330
global_step: 6201, epoch: 56, loss: 0.278496
global_step: 6202, epoch: 56, loss: 0.450989
global_step: 6203, epoch: 56, loss: 0.355253
global_step: 6204, epoch: 56, loss: 0.249077
global_step: 6205, epoch: 56, loss: 0.364735
global_step: 6206, epoch: 56, loss: 0.245645
global_step: 6207, epoch: 56, loss: 0.357584
global_step: 6208, epoch: 56, loss: 0.297403
global_step: 6209, epoch: 56, loss: 0.272706
global_step: 6210, epoch: 56, loss: 0.304365
global_step: 6211, epoch: 56, loss: 0.288999
global_step: 6212, epoch: 56, loss: 0.298370
global_step: 6213, epoch: 56, loss: 0.290711
global_step: 6214, epoch: 56, loss: 0.303818
global_step: 6215, epoch: 56, loss: 0.286888
global_step: 6216, epoch: 56, loss: 0.268779
global_step: 6217, epoch: 56, loss: 0.202596
global_step: 6218, epoch: 56, loss: 0.286522
global_step: 6219, epoch: 56, loss: 0.318381
global_step: 6220, epoch: 56, loss: 0.321211
global_step: 6221, epoch: 56, loss: 0.410590
global_step: 6222, epoch: 56, loss: 0.342619
global_step: 6223, epoch: 56, loss: 0.270468
global_step: 6224, epoch: 56, loss: 0.357744
global_step: 6225, epoch: 56, loss: 0.354391
global_step: 6226, epoch: 56, loss: 0.339820
global_step: 6227, epoch: 56, loss: 0.298062
global_step: 6228, epoch: 56, loss: 0.316317
global_step: 6229, epoch: 56, loss: 0.287461
global_step: 6230, epoch: 56, loss: 0.236711
global_step: 6231, epoch: 56, loss: 0.260815
global_step: 6232, epoch: 56, loss: 0.398442
global_step: 6233, epoch: 56, loss: 0.300428
global_step: 6234, epoch: 56, loss: 0.389350
global_step: 6235, epoch: 56, loss: 0.353590
global_step: 6236, epoch: 56, loss: 0.346549
global_step: 6237, epoch: 56, loss: 0.194910
global_step: 6238, epoch: 56, loss: 0.362262
global_step: 6239, epoch: 56, loss: 0.387984
global_step: 6240, epoch: 56, loss: 0.028334
epoch: 56
train	acc: 0.9644	macro: p 0.9641, r 0.9536, f1: 0.9585	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.4959	macro: p 0.3486, r 0.3154, f1: 0.3223	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.4813
test	acc: 0.5429	macro: p 0.3573, r 0.3338, f1: 0.3362	micro: p 0.5429, r 0.5429, f1 0.5429	weighted_f1:0.5322
global_step: 6241, epoch: 57, loss: 0.302475
global_step: 6242, epoch: 57, loss: 0.359910
global_step: 6243, epoch: 57, loss: 0.251133
global_step: 6244, epoch: 57, loss: 0.320111
global_step: 6245, epoch: 57, loss: 0.251676
global_step: 6246, epoch: 57, loss: 0.231195
global_step: 6247, epoch: 57, loss: 0.261661
global_step: 6248, epoch: 57, loss: 0.308489
global_step: 6249, epoch: 57, loss: 0.228488
global_step: 6250, epoch: 57, loss: 0.292807
global_step: 6251, epoch: 57, loss: 0.297152
global_step: 6252, epoch: 57, loss: 0.386747
global_step: 6253, epoch: 57, loss: 0.268092
global_step: 6254, epoch: 57, loss: 0.285645
global_step: 6255, epoch: 57, loss: 0.305635
global_step: 6256, epoch: 57, loss: 0.424877
global_step: 6257, epoch: 57, loss: 0.345008
global_step: 6258, epoch: 57, loss: 0.365802
global_step: 6259, epoch: 57, loss: 0.308740
global_step: 6260, epoch: 57, loss: 0.288256
global_step: 6261, epoch: 57, loss: 0.337671
global_step: 6262, epoch: 57, loss: 0.306344
global_step: 6263, epoch: 57, loss: 0.319406
global_step: 6264, epoch: 57, loss: 0.235157
global_step: 6265, epoch: 57, loss: 0.275138
global_step: 6266, epoch: 57, loss: 0.215273
global_step: 6267, epoch: 57, loss: 0.306845
global_step: 6268, epoch: 57, loss: 0.266277
global_step: 6269, epoch: 57, loss: 0.296730
global_step: 6270, epoch: 57, loss: 0.293543
global_step: 6271, epoch: 57, loss: 0.299919
global_step: 6272, epoch: 57, loss: 0.340942
global_step: 6273, epoch: 57, loss: 0.423191
global_step: 6274, epoch: 57, loss: 0.346163
global_step: 6275, epoch: 57, loss: 0.303742
global_step: 6276, epoch: 57, loss: 0.387475
global_step: 6277, epoch: 57, loss: 0.370783
global_step: 6278, epoch: 57, loss: 0.304713
global_step: 6279, epoch: 57, loss: 0.343003
global_step: 6280, epoch: 57, loss: 0.132188
epoch: 57
train	acc: 0.9613	macro: p 0.9731, r 0.9387, f1: 0.9551	micro: p 0.9613, r 0.9613, f1 0.9613	weighted_f1:0.9610
dev	acc: 0.5176	macro: p 0.3229, r 0.2828, f1: 0.2836	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4688
test	acc: 0.5847	macro: p 0.3731, r 0.3127, f1: 0.3212	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5438
global_step: 6281, epoch: 58, loss: 0.273276
global_step: 6282, epoch: 58, loss: 0.294784
global_step: 6283, epoch: 58, loss: 0.318518
global_step: 6284, epoch: 58, loss: 0.246137
global_step: 6285, epoch: 58, loss: 0.283097
global_step: 6286, epoch: 58, loss: 0.311603
global_step: 6287, epoch: 58, loss: 0.311648
global_step: 6288, epoch: 58, loss: 0.254266
global_step: 6289, epoch: 58, loss: 0.332044
global_step: 6290, epoch: 58, loss: 0.322569
global_step: 6291, epoch: 58, loss: 0.270957
global_step: 6292, epoch: 58, loss: 0.324340
global_step: 6293, epoch: 58, loss: 0.273808
global_step: 6294, epoch: 58, loss: 0.283439
global_step: 6295, epoch: 58, loss: 0.312282
global_step: 6296, epoch: 58, loss: 0.265962
global_step: 6297, epoch: 58, loss: 0.348514
global_step: 6298, epoch: 58, loss: 0.200836
global_step: 6299, epoch: 58, loss: 0.277542
global_step: 6300, epoch: 58, loss: 0.380544
global_step: 6301, epoch: 58, loss: 0.285025
global_step: 6302, epoch: 58, loss: 0.281864
global_step: 6303, epoch: 58, loss: 0.232698
global_step: 6304, epoch: 58, loss: 0.315258
global_step: 6305, epoch: 58, loss: 0.282869
global_step: 6306, epoch: 58, loss: 0.299328
global_step: 6307, epoch: 58, loss: 0.405214
global_step: 6308, epoch: 58, loss: 0.275459
global_step: 6309, epoch: 58, loss: 0.303135
global_step: 6310, epoch: 58, loss: 0.320058
global_step: 6311, epoch: 58, loss: 0.302045
global_step: 6312, epoch: 58, loss: 0.283964
global_step: 6313, epoch: 58, loss: 0.368443
global_step: 6314, epoch: 58, loss: 0.304288
global_step: 6315, epoch: 58, loss: 0.330076
global_step: 6316, epoch: 58, loss: 0.343072
global_step: 6317, epoch: 58, loss: 0.367102
global_step: 6318, epoch: 58, loss: 0.296714
global_step: 6319, epoch: 58, loss: 0.223680
global_step: 6320, epoch: 58, loss: 1.319654
epoch: 58
train	acc: 0.9615	macro: p 0.9684, r 0.9438, f1: 0.9557	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9613
dev	acc: 0.5167	macro: p 0.3462, r 0.2906, f1: 0.2962	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4702
test	acc: 0.5801	macro: p 0.3759, r 0.3234, f1: 0.3359	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5454
global_step: 6321, epoch: 59, loss: 0.387940
global_step: 6322, epoch: 59, loss: 0.237303
global_step: 6323, epoch: 59, loss: 0.370260
global_step: 6324, epoch: 59, loss: 0.287480
global_step: 6325, epoch: 59, loss: 0.264936
global_step: 6326, epoch: 59, loss: 0.246191
global_step: 6327, epoch: 59, loss: 0.281782
global_step: 6328, epoch: 59, loss: 0.273628
global_step: 6329, epoch: 59, loss: 0.208784
global_step: 6330, epoch: 59, loss: 0.343587
global_step: 6331, epoch: 59, loss: 0.276263
global_step: 6332, epoch: 59, loss: 0.287718
global_step: 6333, epoch: 59, loss: 0.210762
global_step: 6334, epoch: 59, loss: 0.256309
global_step: 6335, epoch: 59, loss: 0.301805
global_step: 6336, epoch: 59, loss: 0.344988
global_step: 6337, epoch: 59, loss: 0.210375
global_step: 6338, epoch: 59, loss: 0.277307
global_step: 6339, epoch: 59, loss: 0.284560
global_step: 6340, epoch: 59, loss: 0.245759
global_step: 6341, epoch: 59, loss: 0.348932
global_step: 6342, epoch: 59, loss: 0.375302
global_step: 6343, epoch: 59, loss: 0.262857
global_step: 6344, epoch: 59, loss: 0.333034
global_step: 6345, epoch: 59, loss: 0.254770
global_step: 6346, epoch: 59, loss: 0.371013
global_step: 6347, epoch: 59, loss: 0.266861
global_step: 6348, epoch: 59, loss: 0.332954
global_step: 6349, epoch: 59, loss: 0.231940
global_step: 6350, epoch: 59, loss: 0.380087
global_step: 6351, epoch: 59, loss: 0.309288
global_step: 6352, epoch: 59, loss: 0.271239
global_step: 6353, epoch: 59, loss: 0.287091
global_step: 6354, epoch: 59, loss: 0.263225
global_step: 6355, epoch: 59, loss: 0.254618
global_step: 6356, epoch: 59, loss: 0.317672
global_step: 6357, epoch: 59, loss: 0.348232
global_step: 6358, epoch: 59, loss: 0.366311
global_step: 6359, epoch: 59, loss: 0.280616
global_step: 6360, epoch: 59, loss: 0.706806
epoch: 59
train	acc: 0.9653	macro: p 0.9680, r 0.9523, f1: 0.9598	micro: p 0.9653, r 0.9653, f1 0.9653	weighted_f1:0.9653
dev	acc: 0.5176	macro: p 0.3378, r 0.3163, f1: 0.3198	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4923
test	acc: 0.5659	macro: p 0.3576, r 0.3394, f1: 0.3418	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5490
global_step: 6361, epoch: 60, loss: 0.282067
global_step: 6362, epoch: 60, loss: 0.252999
global_step: 6363, epoch: 60, loss: 0.225673
global_step: 6364, epoch: 60, loss: 0.273157
global_step: 6365, epoch: 60, loss: 0.261351
global_step: 6366, epoch: 60, loss: 0.218124
global_step: 6367, epoch: 60, loss: 0.231068
global_step: 6368, epoch: 60, loss: 0.283141
global_step: 6369, epoch: 60, loss: 0.284492
global_step: 6370, epoch: 60, loss: 0.254021
global_step: 6371, epoch: 60, loss: 0.340395
global_step: 6372, epoch: 60, loss: 0.362169
global_step: 6373, epoch: 60, loss: 0.258772
global_step: 6374, epoch: 60, loss: 0.266798
global_step: 6375, epoch: 60, loss: 0.276349
global_step: 6376, epoch: 60, loss: 0.245574
global_step: 6377, epoch: 60, loss: 0.235576
global_step: 6378, epoch: 60, loss: 0.304622
global_step: 6379, epoch: 60, loss: 0.248424
global_step: 6380, epoch: 60, loss: 0.233706
global_step: 6381, epoch: 60, loss: 0.245414
global_step: 6382, epoch: 60, loss: 0.319640
global_step: 6383, epoch: 60, loss: 0.278981
global_step: 6384, epoch: 60, loss: 0.261655
global_step: 6385, epoch: 60, loss: 0.258644
global_step: 6386, epoch: 60, loss: 0.287761
global_step: 6387, epoch: 60, loss: 0.216383
global_step: 6388, epoch: 60, loss: 0.232263
global_step: 6389, epoch: 60, loss: 0.350981
global_step: 6390, epoch: 60, loss: 0.278710
global_step: 6391, epoch: 60, loss: 0.198929
global_step: 6392, epoch: 60, loss: 0.277747
global_step: 6393, epoch: 60, loss: 0.229602
global_step: 6394, epoch: 60, loss: 0.275999
global_step: 6395, epoch: 60, loss: 0.252776
global_step: 6396, epoch: 60, loss: 0.282713
global_step: 6397, epoch: 60, loss: 0.268543
global_step: 6398, epoch: 60, loss: 0.352017
global_step: 6399, epoch: 60, loss: 0.234406
global_step: 6400, epoch: 60, loss: 0.465649
epoch: 60
train	acc: 0.9648	macro: p 0.9686, r 0.9500, f1: 0.9588	micro: p 0.9648, r 0.9648, f1 0.9648	weighted_f1:0.9648
dev	acc: 0.5140	macro: p 0.3525, r 0.3054, f1: 0.3100	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4772
test	acc: 0.5701	macro: p 0.3693, r 0.3311, f1: 0.3376	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5423
global_step: 6401, epoch: 61, loss: 0.270595
global_step: 6402, epoch: 61, loss: 0.250836
global_step: 6403, epoch: 61, loss: 0.276603
global_step: 6404, epoch: 61, loss: 0.266783
global_step: 6405, epoch: 61, loss: 0.283880
global_step: 6406, epoch: 61, loss: 0.341569
global_step: 6407, epoch: 61, loss: 0.224761
global_step: 6408, epoch: 61, loss: 0.257600
global_step: 6409, epoch: 61, loss: 0.282286
global_step: 6410, epoch: 61, loss: 0.250493
global_step: 6411, epoch: 61, loss: 0.200245
global_step: 6412, epoch: 61, loss: 0.251923
global_step: 6413, epoch: 61, loss: 0.255280
global_step: 6414, epoch: 61, loss: 0.339942
global_step: 6415, epoch: 61, loss: 0.243959
global_step: 6416, epoch: 61, loss: 0.342174
global_step: 6417, epoch: 61, loss: 0.243549
global_step: 6418, epoch: 61, loss: 0.264902
global_step: 6419, epoch: 61, loss: 0.202698
global_step: 6420, epoch: 61, loss: 0.253713
global_step: 6421, epoch: 61, loss: 0.189222
global_step: 6422, epoch: 61, loss: 0.295036
global_step: 6423, epoch: 61, loss: 0.240547
global_step: 6424, epoch: 61, loss: 0.251576
global_step: 6425, epoch: 61, loss: 0.386266
global_step: 6426, epoch: 61, loss: 0.385521
global_step: 6427, epoch: 61, loss: 0.178276
global_step: 6428, epoch: 61, loss: 0.284481
global_step: 6429, epoch: 61, loss: 0.224749
global_step: 6430, epoch: 61, loss: 0.260190
global_step: 6431, epoch: 61, loss: 0.313493
global_step: 6432, epoch: 61, loss: 0.232442
global_step: 6433, epoch: 61, loss: 0.322199
global_step: 6434, epoch: 61, loss: 0.333136
global_step: 6435, epoch: 61, loss: 0.334528
global_step: 6436, epoch: 61, loss: 0.295554
global_step: 6437, epoch: 61, loss: 0.258288
global_step: 6438, epoch: 61, loss: 0.269288
global_step: 6439, epoch: 61, loss: 0.305834
global_step: 6440, epoch: 61, loss: 0.404837
epoch: 61
train	acc: 0.9641	macro: p 0.9693, r 0.9506, f1: 0.9595	micro: p 0.9641, r 0.9641, f1 0.9641	weighted_f1:0.9641
dev	acc: 0.5104	macro: p 0.3614, r 0.3103, f1: 0.3126	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4757
test	acc: 0.5536	macro: p 0.3731, r 0.3210, f1: 0.3255	micro: p 0.5536, r 0.5536, f1 0.5536	weighted_f1:0.5280
global_step: 6441, epoch: 62, loss: 0.281977
global_step: 6442, epoch: 62, loss: 0.237478
global_step: 6443, epoch: 62, loss: 0.341519
global_step: 6444, epoch: 62, loss: 0.250970
global_step: 6445, epoch: 62, loss: 0.199940
global_step: 6446, epoch: 62, loss: 0.263273
global_step: 6447, epoch: 62, loss: 0.256784
global_step: 6448, epoch: 62, loss: 0.327491
global_step: 6449, epoch: 62, loss: 0.227989
global_step: 6450, epoch: 62, loss: 0.255620
global_step: 6451, epoch: 62, loss: 0.185607
global_step: 6452, epoch: 62, loss: 0.245602
global_step: 6453, epoch: 62, loss: 0.232030
global_step: 6454, epoch: 62, loss: 0.162372
global_step: 6455, epoch: 62, loss: 0.232963
global_step: 6456, epoch: 62, loss: 0.319722
global_step: 6457, epoch: 62, loss: 0.254910
global_step: 6458, epoch: 62, loss: 0.331639
global_step: 6459, epoch: 62, loss: 0.344283
global_step: 6460, epoch: 62, loss: 0.258176
global_step: 6461, epoch: 62, loss: 0.302673
global_step: 6462, epoch: 62, loss: 0.314624
global_step: 6463, epoch: 62, loss: 0.316058
global_step: 6464, epoch: 62, loss: 0.238335
global_step: 6465, epoch: 62, loss: 0.261323
global_step: 6466, epoch: 62, loss: 0.266118
global_step: 6467, epoch: 62, loss: 0.306360
global_step: 6468, epoch: 62, loss: 0.356046
global_step: 6469, epoch: 62, loss: 0.282691
global_step: 6470, epoch: 62, loss: 0.213866
global_step: 6471, epoch: 62, loss: 0.301712
global_step: 6472, epoch: 62, loss: 0.275965
global_step: 6473, epoch: 62, loss: 0.245915
global_step: 6474, epoch: 62, loss: 0.274492
global_step: 6475, epoch: 62, loss: 0.263301
global_step: 6476, epoch: 62, loss: 0.318038
global_step: 6477, epoch: 62, loss: 0.343352
global_step: 6478, epoch: 62, loss: 0.297069
global_step: 6479, epoch: 62, loss: 0.173128
global_step: 6480, epoch: 62, loss: 0.008401
epoch: 62
train	acc: 0.9666	macro: p 0.9697, r 0.9531, f1: 0.9611	micro: p 0.9666, r 0.9666, f1 0.9666	weighted_f1:0.9666
dev	acc: 0.5275	macro: p 0.3694, r 0.3081, f1: 0.3144	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4867
test	acc: 0.5908	macro: p 0.4006, r 0.3375, f1: 0.3517	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5581
global_step: 6481, epoch: 63, loss: 0.273405
global_step: 6482, epoch: 63, loss: 0.185313
global_step: 6483, epoch: 63, loss: 0.234949
global_step: 6484, epoch: 63, loss: 0.351723
global_step: 6485, epoch: 63, loss: 0.244428
global_step: 6486, epoch: 63, loss: 0.203465
global_step: 6487, epoch: 63, loss: 0.202399
global_step: 6488, epoch: 63, loss: 0.255233
global_step: 6489, epoch: 63, loss: 0.274923
global_step: 6490, epoch: 63, loss: 0.256397
global_step: 6491, epoch: 63, loss: 0.328333
global_step: 6492, epoch: 63, loss: 0.181842
global_step: 6493, epoch: 63, loss: 0.318560
global_step: 6494, epoch: 63, loss: 0.255121
global_step: 6495, epoch: 63, loss: 0.181720
global_step: 6496, epoch: 63, loss: 0.247399
global_step: 6497, epoch: 63, loss: 0.232746
global_step: 6498, epoch: 63, loss: 0.283823
global_step: 6499, epoch: 63, loss: 0.244019
global_step: 6500, epoch: 63, loss: 0.359526
global_step: 6501, epoch: 63, loss: 0.221956
global_step: 6502, epoch: 63, loss: 0.229747
global_step: 6503, epoch: 63, loss: 0.328121
global_step: 6504, epoch: 63, loss: 0.326088
global_step: 6505, epoch: 63, loss: 0.276263
global_step: 6506, epoch: 63, loss: 0.222728
global_step: 6507, epoch: 63, loss: 0.211696
global_step: 6508, epoch: 63, loss: 0.301231
global_step: 6509, epoch: 63, loss: 0.221100
global_step: 6510, epoch: 63, loss: 0.225240
global_step: 6511, epoch: 63, loss: 0.254948
global_step: 6512, epoch: 63, loss: 0.302557
global_step: 6513, epoch: 63, loss: 0.299415
global_step: 6514, epoch: 63, loss: 0.224769
global_step: 6515, epoch: 63, loss: 0.285056
global_step: 6516, epoch: 63, loss: 0.429526
global_step: 6517, epoch: 63, loss: 0.326726
global_step: 6518, epoch: 63, loss: 0.285465
global_step: 6519, epoch: 63, loss: 0.282975
global_step: 6520, epoch: 63, loss: 0.392517
epoch: 63
train	acc: 0.9578	macro: p 0.9699, r 0.9408, f1: 0.9546	micro: p 0.9578, r 0.9578, f1 0.9578	weighted_f1:0.9576
dev	acc: 0.5194	macro: p 0.3785, r 0.2936, f1: 0.3048	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4704
test	acc: 0.5770	macro: p 0.3978, r 0.3071, f1: 0.3219	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5290
global_step: 6521, epoch: 64, loss: 0.361000
global_step: 6522, epoch: 64, loss: 0.260605
global_step: 6523, epoch: 64, loss: 0.238007
global_step: 6524, epoch: 64, loss: 0.312328
global_step: 6525, epoch: 64, loss: 0.275876
global_step: 6526, epoch: 64, loss: 0.232121
global_step: 6527, epoch: 64, loss: 0.191684
global_step: 6528, epoch: 64, loss: 0.284275
global_step: 6529, epoch: 64, loss: 0.260430
global_step: 6530, epoch: 64, loss: 0.214442
global_step: 6531, epoch: 64, loss: 0.176185
global_step: 6532, epoch: 64, loss: 0.192594
global_step: 6533, epoch: 64, loss: 0.214745
global_step: 6534, epoch: 64, loss: 0.312263
global_step: 6535, epoch: 64, loss: 0.307401
global_step: 6536, epoch: 64, loss: 0.259877
global_step: 6537, epoch: 64, loss: 0.268560
global_step: 6538, epoch: 64, loss: 0.260227
global_step: 6539, epoch: 64, loss: 0.240934
global_step: 6540, epoch: 64, loss: 0.274889
global_step: 6541, epoch: 64, loss: 0.255391
global_step: 6542, epoch: 64, loss: 0.248455
global_step: 6543, epoch: 64, loss: 0.221444
global_step: 6544, epoch: 64, loss: 0.224025
global_step: 6545, epoch: 64, loss: 0.292409
global_step: 6546, epoch: 64, loss: 0.279581
global_step: 6547, epoch: 64, loss: 0.263663
global_step: 6548, epoch: 64, loss: 0.245029
global_step: 6549, epoch: 64, loss: 0.244127
global_step: 6550, epoch: 64, loss: 0.230572
global_step: 6551, epoch: 64, loss: 0.331671
global_step: 6552, epoch: 64, loss: 0.352473
global_step: 6553, epoch: 64, loss: 0.326592
global_step: 6554, epoch: 64, loss: 0.279675
global_step: 6555, epoch: 64, loss: 0.295419
global_step: 6556, epoch: 64, loss: 0.210730
global_step: 6557, epoch: 64, loss: 0.291758
global_step: 6558, epoch: 64, loss: 0.313703
global_step: 6559, epoch: 64, loss: 0.283479
global_step: 6560, epoch: 64, loss: 0.077543
epoch: 64
train	acc: 0.9675	macro: p 0.9709, r 0.9548, f1: 0.9625	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5185	macro: p 0.3529, r 0.3081, f1: 0.3114	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4830
test	acc: 0.5831	macro: p 0.4124, r 0.3463, f1: 0.3588	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5553
global_step: 6561, epoch: 65, loss: 0.226134
global_step: 6562, epoch: 65, loss: 0.272479
global_step: 6563, epoch: 65, loss: 0.290954
global_step: 6564, epoch: 65, loss: 0.308791
global_step: 6565, epoch: 65, loss: 0.250081
global_step: 6566, epoch: 65, loss: 0.180982
global_step: 6567, epoch: 65, loss: 0.343431
global_step: 6568, epoch: 65, loss: 0.369538
global_step: 6569, epoch: 65, loss: 0.160916
global_step: 6570, epoch: 65, loss: 0.191571
global_step: 6571, epoch: 65, loss: 0.244415
global_step: 6572, epoch: 65, loss: 0.215146
global_step: 6573, epoch: 65, loss: 0.279718
global_step: 6574, epoch: 65, loss: 0.317382
global_step: 6575, epoch: 65, loss: 0.246794
global_step: 6576, epoch: 65, loss: 0.262615
global_step: 6577, epoch: 65, loss: 0.255126
global_step: 6578, epoch: 65, loss: 0.298198
global_step: 6579, epoch: 65, loss: 0.226372
global_step: 6580, epoch: 65, loss: 0.263083
global_step: 6581, epoch: 65, loss: 0.287314
global_step: 6582, epoch: 65, loss: 0.262379
global_step: 6583, epoch: 65, loss: 0.269907
global_step: 6584, epoch: 65, loss: 0.259028
global_step: 6585, epoch: 65, loss: 0.229784
global_step: 6586, epoch: 65, loss: 0.302315
global_step: 6587, epoch: 65, loss: 0.189054
global_step: 6588, epoch: 65, loss: 0.264719
global_step: 6589, epoch: 65, loss: 0.348654
global_step: 6590, epoch: 65, loss: 0.267299
global_step: 6591, epoch: 65, loss: 0.234377
global_step: 6592, epoch: 65, loss: 0.246995
global_step: 6593, epoch: 65, loss: 0.275326
global_step: 6594, epoch: 65, loss: 0.274908
global_step: 6595, epoch: 65, loss: 0.225904
global_step: 6596, epoch: 65, loss: 0.213213
global_step: 6597, epoch: 65, loss: 0.239007
global_step: 6598, epoch: 65, loss: 0.291125
global_step: 6599, epoch: 65, loss: 0.277115
global_step: 6600, epoch: 65, loss: 0.535752
epoch: 65
train	acc: 0.9652	macro: p 0.9679, r 0.9538, f1: 0.9605	micro: p 0.9652, r 0.9652, f1 0.9652	weighted_f1:0.9652
dev	acc: 0.5104	macro: p 0.3445, r 0.3126, f1: 0.3155	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4834
test	acc: 0.5625	macro: p 0.3922, r 0.3348, f1: 0.3440	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.5417
global_step: 6601, epoch: 66, loss: 0.215496
global_step: 6602, epoch: 66, loss: 0.221610
global_step: 6603, epoch: 66, loss: 0.263903
global_step: 6604, epoch: 66, loss: 0.241277
global_step: 6605, epoch: 66, loss: 0.223998
global_step: 6606, epoch: 66, loss: 0.218294
global_step: 6607, epoch: 66, loss: 0.283426
global_step: 6608, epoch: 66, loss: 0.257423
global_step: 6609, epoch: 66, loss: 0.244197
global_step: 6610, epoch: 66, loss: 0.258406
global_step: 6611, epoch: 66, loss: 0.214591
global_step: 6612, epoch: 66, loss: 0.215859
global_step: 6613, epoch: 66, loss: 0.346654
global_step: 6614, epoch: 66, loss: 0.265616
global_step: 6615, epoch: 66, loss: 0.221668
global_step: 6616, epoch: 66, loss: 0.246214
global_step: 6617, epoch: 66, loss: 0.267589
global_step: 6618, epoch: 66, loss: 0.183443
global_step: 6619, epoch: 66, loss: 0.383399
global_step: 6620, epoch: 66, loss: 0.325648
global_step: 6621, epoch: 66, loss: 0.240184
global_step: 6622, epoch: 66, loss: 0.209148
global_step: 6623, epoch: 66, loss: 0.270292
global_step: 6624, epoch: 66, loss: 0.284553
global_step: 6625, epoch: 66, loss: 0.225003
global_step: 6626, epoch: 66, loss: 0.283118
global_step: 6627, epoch: 66, loss: 0.264211
global_step: 6628, epoch: 66, loss: 0.239854
global_step: 6629, epoch: 66, loss: 0.249658
global_step: 6630, epoch: 66, loss: 0.223146
global_step: 6631, epoch: 66, loss: 0.259456
global_step: 6632, epoch: 66, loss: 0.240658
global_step: 6633, epoch: 66, loss: 0.232765
global_step: 6634, epoch: 66, loss: 0.323227
global_step: 6635, epoch: 66, loss: 0.190768
global_step: 6636, epoch: 66, loss: 0.184431
global_step: 6637, epoch: 66, loss: 0.373480
global_step: 6638, epoch: 66, loss: 0.303570
global_step: 6639, epoch: 66, loss: 0.302153
global_step: 6640, epoch: 66, loss: 0.060977
epoch: 66
train	acc: 0.9673	macro: p 0.9702, r 0.9556, f1: 0.9626	micro: p 0.9673, r 0.9673, f1 0.9673	weighted_f1:0.9673
dev	acc: 0.5230	macro: p 0.3465, r 0.3080, f1: 0.3127	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4881
test	acc: 0.5851	macro: p 0.4043, r 0.3394, f1: 0.3494	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5566
global_step: 6641, epoch: 67, loss: 0.289987
global_step: 6642, epoch: 67, loss: 0.196984
global_step: 6643, epoch: 67, loss: 0.278007
global_step: 6644, epoch: 67, loss: 0.264730
global_step: 6645, epoch: 67, loss: 0.190685
global_step: 6646, epoch: 67, loss: 0.285187
global_step: 6647, epoch: 67, loss: 0.279243
global_step: 6648, epoch: 67, loss: 0.218851
global_step: 6649, epoch: 67, loss: 0.228412
global_step: 6650, epoch: 67, loss: 0.220808
global_step: 6651, epoch: 67, loss: 0.228631
global_step: 6652, epoch: 67, loss: 0.304802
global_step: 6653, epoch: 67, loss: 0.234982
global_step: 6654, epoch: 67, loss: 0.329202
global_step: 6655, epoch: 67, loss: 0.316286
global_step: 6656, epoch: 67, loss: 0.213253
global_step: 6657, epoch: 67, loss: 0.245539
global_step: 6658, epoch: 67, loss: 0.283500
global_step: 6659, epoch: 67, loss: 0.362416
global_step: 6660, epoch: 67, loss: 0.263066
global_step: 6661, epoch: 67, loss: 0.283425
global_step: 6662, epoch: 67, loss: 0.318623
global_step: 6663, epoch: 67, loss: 0.223443
global_step: 6664, epoch: 67, loss: 0.244561
global_step: 6665, epoch: 67, loss: 0.286676
global_step: 6666, epoch: 67, loss: 0.205027
global_step: 6667, epoch: 67, loss: 0.258760
global_step: 6668, epoch: 67, loss: 0.199070
global_step: 6669, epoch: 67, loss: 0.270229
global_step: 6670, epoch: 67, loss: 0.241378
global_step: 6671, epoch: 67, loss: 0.257252
global_step: 6672, epoch: 67, loss: 0.289703
global_step: 6673, epoch: 67, loss: 0.197308
global_step: 6674, epoch: 67, loss: 0.234849
global_step: 6675, epoch: 67, loss: 0.252252
global_step: 6676, epoch: 67, loss: 0.263121
global_step: 6677, epoch: 67, loss: 0.290592
global_step: 6678, epoch: 67, loss: 0.300444
global_step: 6679, epoch: 67, loss: 0.223848
global_step: 6680, epoch: 67, loss: 0.310424
epoch: 67
train	acc: 0.9645	macro: p 0.9709, r 0.9446, f1: 0.9571	micro: p 0.9645, r 0.9645, f1 0.9645	weighted_f1:0.9644
dev	acc: 0.5203	macro: p 0.3474, r 0.2864, f1: 0.2861	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4677
test	acc: 0.5893	macro: p 0.4272, r 0.3221, f1: 0.3303	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5453
global_step: 6681, epoch: 68, loss: 0.246124
global_step: 6682, epoch: 68, loss: 0.232089
global_step: 6683, epoch: 68, loss: 0.254205
global_step: 6684, epoch: 68, loss: 0.228737
global_step: 6685, epoch: 68, loss: 0.158350
global_step: 6686, epoch: 68, loss: 0.168967
global_step: 6687, epoch: 68, loss: 0.254910
global_step: 6688, epoch: 68, loss: 0.237330
global_step: 6689, epoch: 68, loss: 0.267378
global_step: 6690, epoch: 68, loss: 0.287424
global_step: 6691, epoch: 68, loss: 0.183326
global_step: 6692, epoch: 68, loss: 0.243369
global_step: 6693, epoch: 68, loss: 0.254529
global_step: 6694, epoch: 68, loss: 0.244971
global_step: 6695, epoch: 68, loss: 0.272559
global_step: 6696, epoch: 68, loss: 0.233445
global_step: 6697, epoch: 68, loss: 0.288009
global_step: 6698, epoch: 68, loss: 0.283616
global_step: 6699, epoch: 68, loss: 0.250270
global_step: 6700, epoch: 68, loss: 0.259834
global_step: 6701, epoch: 68, loss: 0.272863
global_step: 6702, epoch: 68, loss: 0.258969
global_step: 6703, epoch: 68, loss: 0.214928
global_step: 6704, epoch: 68, loss: 0.305202
global_step: 6705, epoch: 68, loss: 0.270488
global_step: 6706, epoch: 68, loss: 0.211555
global_step: 6707, epoch: 68, loss: 0.219486
global_step: 6708, epoch: 68, loss: 0.244496
global_step: 6709, epoch: 68, loss: 0.243288
global_step: 6710, epoch: 68, loss: 0.239281
global_step: 6711, epoch: 68, loss: 0.304355
global_step: 6712, epoch: 68, loss: 0.277130
global_step: 6713, epoch: 68, loss: 0.399650
global_step: 6714, epoch: 68, loss: 0.306456
global_step: 6715, epoch: 68, loss: 0.268005
global_step: 6716, epoch: 68, loss: 0.246530
global_step: 6717, epoch: 68, loss: 0.270006
global_step: 6718, epoch: 68, loss: 0.249657
global_step: 6719, epoch: 68, loss: 0.207218
global_step: 6720, epoch: 68, loss: 0.198718
epoch: 68
train	acc: 0.9624	macro: p 0.9671, r 0.9413, f1: 0.9532	micro: p 0.9624, r 0.9624, f1 0.9624	weighted_f1:0.9625
dev	acc: 0.5230	macro: p 0.3504, r 0.2934, f1: 0.2897	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4714
test	acc: 0.5812	macro: p 0.4134, r 0.3192, f1: 0.3219	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5398
global_step: 6721, epoch: 69, loss: 0.195372
global_step: 6722, epoch: 69, loss: 0.215555
global_step: 6723, epoch: 69, loss: 0.203488
global_step: 6724, epoch: 69, loss: 0.303993
global_step: 6725, epoch: 69, loss: 0.249578
global_step: 6726, epoch: 69, loss: 0.239622
global_step: 6727, epoch: 69, loss: 0.343883
global_step: 6728, epoch: 69, loss: 0.272054
global_step: 6729, epoch: 69, loss: 0.204841
global_step: 6730, epoch: 69, loss: 0.190893
global_step: 6731, epoch: 69, loss: 0.258797
global_step: 6732, epoch: 69, loss: 0.289166
global_step: 6733, epoch: 69, loss: 0.251958
global_step: 6734, epoch: 69, loss: 0.248837
global_step: 6735, epoch: 69, loss: 0.259457
global_step: 6736, epoch: 69, loss: 0.255984
global_step: 6737, epoch: 69, loss: 0.229907
global_step: 6738, epoch: 69, loss: 0.208576
global_step: 6739, epoch: 69, loss: 0.264903
global_step: 6740, epoch: 69, loss: 0.242845
global_step: 6741, epoch: 69, loss: 0.292110
global_step: 6742, epoch: 69, loss: 0.194807
global_step: 6743, epoch: 69, loss: 0.282859
global_step: 6744, epoch: 69, loss: 0.361787
global_step: 6745, epoch: 69, loss: 0.328532
global_step: 6746, epoch: 69, loss: 0.221250
global_step: 6747, epoch: 69, loss: 0.306745
global_step: 6748, epoch: 69, loss: 0.284181
global_step: 6749, epoch: 69, loss: 0.318656
global_step: 6750, epoch: 69, loss: 0.335344
global_step: 6751, epoch: 69, loss: 0.303749
global_step: 6752, epoch: 69, loss: 0.214064
global_step: 6753, epoch: 69, loss: 0.315483
global_step: 6754, epoch: 69, loss: 0.257963
global_step: 6755, epoch: 69, loss: 0.295193
global_step: 6756, epoch: 69, loss: 0.223506
global_step: 6757, epoch: 69, loss: 0.280530
global_step: 6758, epoch: 69, loss: 0.293887
global_step: 6759, epoch: 69, loss: 0.282398
global_step: 6760, epoch: 69, loss: 0.143924
epoch: 69
train	acc: 0.9643	macro: p 0.9686, r 0.9491, f1: 0.9582	micro: p 0.9643, r 0.9643, f1 0.9643	weighted_f1:0.9644
dev	acc: 0.5095	macro: p 0.3209, r 0.2904, f1: 0.2825	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4650
test	acc: 0.5636	macro: p 0.3588, r 0.3110, f1: 0.3092	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5282
global_step: 6761, epoch: 70, loss: 0.196350
global_step: 6762, epoch: 70, loss: 0.316490
global_step: 6763, epoch: 70, loss: 0.192531
global_step: 6764, epoch: 70, loss: 0.220479
global_step: 6765, epoch: 70, loss: 0.228430
global_step: 6766, epoch: 70, loss: 0.245639
global_step: 6767, epoch: 70, loss: 0.245276
global_step: 6768, epoch: 70, loss: 0.320169
global_step: 6769, epoch: 70, loss: 0.292595
global_step: 6770, epoch: 70, loss: 0.212918
global_step: 6771, epoch: 70, loss: 0.258256
global_step: 6772, epoch: 70, loss: 0.207721
global_step: 6773, epoch: 70, loss: 0.272261
global_step: 6774, epoch: 70, loss: 0.253417
global_step: 6775, epoch: 70, loss: 0.188369
global_step: 6776, epoch: 70, loss: 0.369169
global_step: 6777, epoch: 70, loss: 0.253887
global_step: 6778, epoch: 70, loss: 0.187726
global_step: 6779, epoch: 70, loss: 0.261147
global_step: 6780, epoch: 70, loss: 0.268268
global_step: 6781, epoch: 70, loss: 0.222278
global_step: 6782, epoch: 70, loss: 0.266485
global_step: 6783, epoch: 70, loss: 0.260197
global_step: 6784, epoch: 70, loss: 0.218725
global_step: 6785, epoch: 70, loss: 0.208604
global_step: 6786, epoch: 70, loss: 0.259128
global_step: 6787, epoch: 70, loss: 0.263932
global_step: 6788, epoch: 70, loss: 0.310164
global_step: 6789, epoch: 70, loss: 0.228164
global_step: 6790, epoch: 70, loss: 0.282289
global_step: 6791, epoch: 70, loss: 0.267699
global_step: 6792, epoch: 70, loss: 0.289060
global_step: 6793, epoch: 70, loss: 0.225370
global_step: 6794, epoch: 70, loss: 0.334891
global_step: 6795, epoch: 70, loss: 0.249595
global_step: 6796, epoch: 70, loss: 0.249188
global_step: 6797, epoch: 70, loss: 0.228558
global_step: 6798, epoch: 70, loss: 0.218765
global_step: 6799, epoch: 70, loss: 0.276221
global_step: 6800, epoch: 70, loss: 0.933087
epoch: 70
train	acc: 0.9649	macro: p 0.9714, r 0.9491, f1: 0.9598	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5212	macro: p 0.3365, r 0.2885, f1: 0.2855	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4712
test	acc: 0.5793	macro: p 0.4196, r 0.3201, f1: 0.3288	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5395
global_step: 6801, epoch: 71, loss: 0.206593
global_step: 6802, epoch: 71, loss: 0.215676
global_step: 6803, epoch: 71, loss: 0.271152
global_step: 6804, epoch: 71, loss: 0.298467
global_step: 6805, epoch: 71, loss: 0.242645
global_step: 6806, epoch: 71, loss: 0.250461
global_step: 6807, epoch: 71, loss: 0.326565
global_step: 6808, epoch: 71, loss: 0.251999
global_step: 6809, epoch: 71, loss: 0.258275
global_step: 6810, epoch: 71, loss: 0.238968
global_step: 6811, epoch: 71, loss: 0.288757
global_step: 6812, epoch: 71, loss: 0.192585
global_step: 6813, epoch: 71, loss: 0.255889
global_step: 6814, epoch: 71, loss: 0.269987
global_step: 6815, epoch: 71, loss: 0.259291
global_step: 6816, epoch: 71, loss: 0.143122
global_step: 6817, epoch: 71, loss: 0.206874
global_step: 6818, epoch: 71, loss: 0.239590
global_step: 6819, epoch: 71, loss: 0.342498
global_step: 6820, epoch: 71, loss: 0.232243
global_step: 6821, epoch: 71, loss: 0.274882
global_step: 6822, epoch: 71, loss: 0.281727
global_step: 6823, epoch: 71, loss: 0.325355
global_step: 6824, epoch: 71, loss: 0.180199
global_step: 6825, epoch: 71, loss: 0.211259
global_step: 6826, epoch: 71, loss: 0.236620
global_step: 6827, epoch: 71, loss: 0.354550
global_step: 6828, epoch: 71, loss: 0.205695
global_step: 6829, epoch: 71, loss: 0.395197
global_step: 6830, epoch: 71, loss: 0.336811
global_step: 6831, epoch: 71, loss: 0.236641
global_step: 6832, epoch: 71, loss: 0.222787
global_step: 6833, epoch: 71, loss: 0.326756
global_step: 6834, epoch: 71, loss: 0.254595
global_step: 6835, epoch: 71, loss: 0.259760
global_step: 6836, epoch: 71, loss: 0.285964
global_step: 6837, epoch: 71, loss: 0.326930
global_step: 6838, epoch: 71, loss: 0.219193
global_step: 6839, epoch: 71, loss: 0.307144
global_step: 6840, epoch: 71, loss: 0.043536
epoch: 71
train	acc: 0.9654	macro: p 0.9666, r 0.9533, f1: 0.9597	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9654
dev	acc: 0.5257	macro: p 0.3463, r 0.2928, f1: 0.3003	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4812
test	acc: 0.5743	macro: p 0.3708, r 0.3084, f1: 0.3202	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5351
global_step: 6841, epoch: 72, loss: 0.268470
global_step: 6842, epoch: 72, loss: 0.316624
global_step: 6843, epoch: 72, loss: 0.231412
global_step: 6844, epoch: 72, loss: 0.217385
global_step: 6845, epoch: 72, loss: 0.249584
global_step: 6846, epoch: 72, loss: 0.244119
global_step: 6847, epoch: 72, loss: 0.149171
global_step: 6848, epoch: 72, loss: 0.266519
global_step: 6849, epoch: 72, loss: 0.190615
global_step: 6850, epoch: 72, loss: 0.217452
global_step: 6851, epoch: 72, loss: 0.273253
global_step: 6852, epoch: 72, loss: 0.257626
global_step: 6853, epoch: 72, loss: 0.274915
global_step: 6854, epoch: 72, loss: 0.299530
global_step: 6855, epoch: 72, loss: 0.263546
global_step: 6856, epoch: 72, loss: 0.228716
global_step: 6857, epoch: 72, loss: 0.246262
global_step: 6858, epoch: 72, loss: 0.309155
global_step: 6859, epoch: 72, loss: 0.301118
global_step: 6860, epoch: 72, loss: 0.285600
global_step: 6861, epoch: 72, loss: 0.244349
global_step: 6862, epoch: 72, loss: 0.247380
global_step: 6863, epoch: 72, loss: 0.269570
global_step: 6864, epoch: 72, loss: 0.359345
global_step: 6865, epoch: 72, loss: 0.290514
global_step: 6866, epoch: 72, loss: 0.259854
global_step: 6867, epoch: 72, loss: 0.204576
global_step: 6868, epoch: 72, loss: 0.332733
global_step: 6869, epoch: 72, loss: 0.237116
global_step: 6870, epoch: 72, loss: 0.212409
global_step: 6871, epoch: 72, loss: 0.219486
global_step: 6872, epoch: 72, loss: 0.145642
global_step: 6873, epoch: 72, loss: 0.277281
global_step: 6874, epoch: 72, loss: 0.221254
global_step: 6875, epoch: 72, loss: 0.278675
global_step: 6876, epoch: 72, loss: 0.197267
global_step: 6877, epoch: 72, loss: 0.267094
global_step: 6878, epoch: 72, loss: 0.373100
global_step: 6879, epoch: 72, loss: 0.401359
global_step: 6880, epoch: 72, loss: 0.106418
epoch: 72
train	acc: 0.9695	macro: p 0.9720, r 0.9582, f1: 0.9649	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5167	macro: p 0.3335, r 0.2944, f1: 0.2960	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4763
test	acc: 0.5701	macro: p 0.3666, r 0.3120, f1: 0.3186	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5354
global_step: 6881, epoch: 73, loss: 0.208117
global_step: 6882, epoch: 73, loss: 0.269754
global_step: 6883, epoch: 73, loss: 0.257275
global_step: 6884, epoch: 73, loss: 0.269898
global_step: 6885, epoch: 73, loss: 0.261379
global_step: 6886, epoch: 73, loss: 0.187375
global_step: 6887, epoch: 73, loss: 0.176508
global_step: 6888, epoch: 73, loss: 0.232131
global_step: 6889, epoch: 73, loss: 0.209198
global_step: 6890, epoch: 73, loss: 0.320719
global_step: 6891, epoch: 73, loss: 0.218113
global_step: 6892, epoch: 73, loss: 0.193783
global_step: 6893, epoch: 73, loss: 0.194926
global_step: 6894, epoch: 73, loss: 0.161614
global_step: 6895, epoch: 73, loss: 0.185253
global_step: 6896, epoch: 73, loss: 0.279639
global_step: 6897, epoch: 73, loss: 0.268426
global_step: 6898, epoch: 73, loss: 0.221077
global_step: 6899, epoch: 73, loss: 0.250491
global_step: 6900, epoch: 73, loss: 0.174729
global_step: 6901, epoch: 73, loss: 0.233144
global_step: 6902, epoch: 73, loss: 0.234832
global_step: 6903, epoch: 73, loss: 0.293494
global_step: 6904, epoch: 73, loss: 0.277680
global_step: 6905, epoch: 73, loss: 0.220411
global_step: 6906, epoch: 73, loss: 0.184907
global_step: 6907, epoch: 73, loss: 0.253575
global_step: 6908, epoch: 73, loss: 0.355447
global_step: 6909, epoch: 73, loss: 0.297199
global_step: 6910, epoch: 73, loss: 0.269367
global_step: 6911, epoch: 73, loss: 0.232685
global_step: 6912, epoch: 73, loss: 0.284972
global_step: 6913, epoch: 73, loss: 0.257569
global_step: 6914, epoch: 73, loss: 0.250623
global_step: 6915, epoch: 73, loss: 0.181153
global_step: 6916, epoch: 73, loss: 0.196222
global_step: 6917, epoch: 73, loss: 0.213660
global_step: 6918, epoch: 73, loss: 0.231684
global_step: 6919, epoch: 73, loss: 0.208289
global_step: 6920, epoch: 73, loss: 0.054852
epoch: 73
train	acc: 0.9694	macro: p 0.9700, r 0.9609, f1: 0.9653	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5149	macro: p 0.3386, r 0.3029, f1: 0.3094	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4800
test	acc: 0.5716	macro: p 0.3780, r 0.3330, f1: 0.3461	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5468
global_step: 6921, epoch: 74, loss: 0.169799
global_step: 6922, epoch: 74, loss: 0.362190
global_step: 6923, epoch: 74, loss: 0.214835
global_step: 6924, epoch: 74, loss: 0.226135
global_step: 6925, epoch: 74, loss: 0.304936
global_step: 6926, epoch: 74, loss: 0.262893
global_step: 6927, epoch: 74, loss: 0.253125
global_step: 6928, epoch: 74, loss: 0.242764
global_step: 6929, epoch: 74, loss: 0.295724
global_step: 6930, epoch: 74, loss: 0.171972
global_step: 6931, epoch: 74, loss: 0.276085
global_step: 6932, epoch: 74, loss: 0.145634
global_step: 6933, epoch: 74, loss: 0.182413
global_step: 6934, epoch: 74, loss: 0.264427
global_step: 6935, epoch: 74, loss: 0.270058
global_step: 6936, epoch: 74, loss: 0.254998
global_step: 6937, epoch: 74, loss: 0.298247
global_step: 6938, epoch: 74, loss: 0.190788
global_step: 6939, epoch: 74, loss: 0.269168
global_step: 6940, epoch: 74, loss: 0.249882
global_step: 6941, epoch: 74, loss: 0.263183
global_step: 6942, epoch: 74, loss: 0.280388
global_step: 6943, epoch: 74, loss: 0.202559
global_step: 6944, epoch: 74, loss: 0.200636
global_step: 6945, epoch: 74, loss: 0.295916
global_step: 6946, epoch: 74, loss: 0.224067
global_step: 6947, epoch: 74, loss: 0.308182
global_step: 6948, epoch: 74, loss: 0.214366
global_step: 6949, epoch: 74, loss: 0.240959
global_step: 6950, epoch: 74, loss: 0.243225
global_step: 6951, epoch: 74, loss: 0.290809
global_step: 6952, epoch: 74, loss: 0.317167
global_step: 6953, epoch: 74, loss: 0.157199
global_step: 6954, epoch: 74, loss: 0.198853
global_step: 6955, epoch: 74, loss: 0.255279
global_step: 6956, epoch: 74, loss: 0.220950
global_step: 6957, epoch: 74, loss: 0.278911
global_step: 6958, epoch: 74, loss: 0.294347
global_step: 6959, epoch: 74, loss: 0.237007
global_step: 6960, epoch: 74, loss: 0.077063
epoch: 74
train	acc: 0.9640	macro: p 0.9718, r 0.9490, f1: 0.9599	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9638
dev	acc: 0.5176	macro: p 0.3287, r 0.2889, f1: 0.2853	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4686
test	acc: 0.5674	macro: p 0.3875, r 0.3150, f1: 0.3269	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5321
global_step: 6961, epoch: 75, loss: 0.269700
global_step: 6962, epoch: 75, loss: 0.245682
global_step: 6963, epoch: 75, loss: 0.239890
global_step: 6964, epoch: 75, loss: 0.252421
global_step: 6965, epoch: 75, loss: 0.322768
global_step: 6966, epoch: 75, loss: 0.204050
global_step: 6967, epoch: 75, loss: 0.227718
global_step: 6968, epoch: 75, loss: 0.226160
global_step: 6969, epoch: 75, loss: 0.283014
global_step: 6970, epoch: 75, loss: 0.182520
global_step: 6971, epoch: 75, loss: 0.257011
global_step: 6972, epoch: 75, loss: 0.202254
global_step: 6973, epoch: 75, loss: 0.189099
global_step: 6974, epoch: 75, loss: 0.269374
global_step: 6975, epoch: 75, loss: 0.269152
global_step: 6976, epoch: 75, loss: 0.223220
global_step: 6977, epoch: 75, loss: 0.267277
global_step: 6978, epoch: 75, loss: 0.240279
global_step: 6979, epoch: 75, loss: 0.227799
global_step: 6980, epoch: 75, loss: 0.267132
global_step: 6981, epoch: 75, loss: 0.252314
global_step: 6982, epoch: 75, loss: 0.199762
global_step: 6983, epoch: 75, loss: 0.213439
global_step: 6984, epoch: 75, loss: 0.291572
global_step: 6985, epoch: 75, loss: 0.183165
global_step: 6986, epoch: 75, loss: 0.270492
global_step: 6987, epoch: 75, loss: 0.238274
global_step: 6988, epoch: 75, loss: 0.326265
global_step: 6989, epoch: 75, loss: 0.223378
global_step: 6990, epoch: 75, loss: 0.177663
global_step: 6991, epoch: 75, loss: 0.217180
global_step: 6992, epoch: 75, loss: 0.289626
global_step: 6993, epoch: 75, loss: 0.249766
global_step: 6994, epoch: 75, loss: 0.336049
global_step: 6995, epoch: 75, loss: 0.285138
global_step: 6996, epoch: 75, loss: 0.223832
global_step: 6997, epoch: 75, loss: 0.272661
global_step: 6998, epoch: 75, loss: 0.290165
global_step: 6999, epoch: 75, loss: 0.299781
global_step: 7000, epoch: 75, loss: 0.109735
epoch: 75
train	acc: 0.9623	macro: p 0.9663, r 0.9506, f1: 0.9575	micro: p 0.9623, r 0.9623, f1 0.9623	weighted_f1:0.9625
dev	acc: 0.5149	macro: p 0.3353, r 0.2969, f1: 0.2963	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4725
test	acc: 0.5575	macro: p 0.3770, r 0.3164, f1: 0.3218	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.5254
global_step: 7001, epoch: 76, loss: 0.227675
global_step: 7002, epoch: 76, loss: 0.314805
global_step: 7003, epoch: 76, loss: 0.223868
global_step: 7004, epoch: 76, loss: 0.239094
global_step: 7005, epoch: 76, loss: 0.280761
global_step: 7006, epoch: 76, loss: 0.166261
global_step: 7007, epoch: 76, loss: 0.191168
global_step: 7008, epoch: 76, loss: 0.158003
global_step: 7009, epoch: 76, loss: 0.219805
global_step: 7010, epoch: 76, loss: 0.213547
global_step: 7011, epoch: 76, loss: 0.253404
global_step: 7012, epoch: 76, loss: 0.206055
global_step: 7013, epoch: 76, loss: 0.354011
global_step: 7014, epoch: 76, loss: 0.250635
global_step: 7015, epoch: 76, loss: 0.191073
global_step: 7016, epoch: 76, loss: 0.224176
global_step: 7017, epoch: 76, loss: 0.262609
global_step: 7018, epoch: 76, loss: 0.204868
global_step: 7019, epoch: 76, loss: 0.374519
global_step: 7020, epoch: 76, loss: 0.305143
global_step: 7021, epoch: 76, loss: 0.202667
global_step: 7022, epoch: 76, loss: 0.220895
global_step: 7023, epoch: 76, loss: 0.223644
global_step: 7024, epoch: 76, loss: 0.171298
global_step: 7025, epoch: 76, loss: 0.276079
global_step: 7026, epoch: 76, loss: 0.375720
global_step: 7027, epoch: 76, loss: 0.232603
global_step: 7028, epoch: 76, loss: 0.259021
global_step: 7029, epoch: 76, loss: 0.227994
global_step: 7030, epoch: 76, loss: 0.294618
global_step: 7031, epoch: 76, loss: 0.255745
global_step: 7032, epoch: 76, loss: 0.240627
global_step: 7033, epoch: 76, loss: 0.239438
global_step: 7034, epoch: 76, loss: 0.218357
global_step: 7035, epoch: 76, loss: 0.342125
global_step: 7036, epoch: 76, loss: 0.317356
global_step: 7037, epoch: 76, loss: 0.273695
global_step: 7038, epoch: 76, loss: 0.251258
global_step: 7039, epoch: 76, loss: 0.324545
global_step: 7040, epoch: 76, loss: 0.280952
epoch: 76
train	acc: 0.9650	macro: p 0.9717, r 0.9518, f1: 0.9613	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9650
dev	acc: 0.5113	macro: p 0.3174, r 0.2859, f1: 0.2852	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4683
test	acc: 0.5801	macro: p 0.3946, r 0.3188, f1: 0.3296	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5433
global_step: 7041, epoch: 77, loss: 0.214196
global_step: 7042, epoch: 77, loss: 0.224776
global_step: 7043, epoch: 77, loss: 0.354802
global_step: 7044, epoch: 77, loss: 0.227126
global_step: 7045, epoch: 77, loss: 0.347538
global_step: 7046, epoch: 77, loss: 0.183499
global_step: 7047, epoch: 77, loss: 0.260721
global_step: 7048, epoch: 77, loss: 0.247281
global_step: 7049, epoch: 77, loss: 0.307825
global_step: 7050, epoch: 77, loss: 0.203116
global_step: 7051, epoch: 77, loss: 0.205332
global_step: 7052, epoch: 77, loss: 0.244210
global_step: 7053, epoch: 77, loss: 0.213428
global_step: 7054, epoch: 77, loss: 0.260987
global_step: 7055, epoch: 77, loss: 0.162106
global_step: 7056, epoch: 77, loss: 0.243688
global_step: 7057, epoch: 77, loss: 0.200158
global_step: 7058, epoch: 77, loss: 0.206094
global_step: 7059, epoch: 77, loss: 0.311300
global_step: 7060, epoch: 77, loss: 0.183651
global_step: 7061, epoch: 77, loss: 0.211832
global_step: 7062, epoch: 77, loss: 0.345936
global_step: 7063, epoch: 77, loss: 0.201890
global_step: 7064, epoch: 77, loss: 0.247373
global_step: 7065, epoch: 77, loss: 0.233843
global_step: 7066, epoch: 77, loss: 0.206436
global_step: 7067, epoch: 77, loss: 0.219527
global_step: 7068, epoch: 77, loss: 0.182893
global_step: 7069, epoch: 77, loss: 0.229788
global_step: 7070, epoch: 77, loss: 0.215071
global_step: 7071, epoch: 77, loss: 0.371031
global_step: 7072, epoch: 77, loss: 0.207524
global_step: 7073, epoch: 77, loss: 0.262854
global_step: 7074, epoch: 77, loss: 0.263557
global_step: 7075, epoch: 77, loss: 0.262351
global_step: 7076, epoch: 77, loss: 0.237405
global_step: 7077, epoch: 77, loss: 0.268805
global_step: 7078, epoch: 77, loss: 0.187717
global_step: 7079, epoch: 77, loss: 0.286729
global_step: 7080, epoch: 77, loss: 0.154829
epoch: 77
train	acc: 0.9677	macro: p 0.9690, r 0.9574, f1: 0.9629	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5203	macro: p 0.3249, r 0.2979, f1: 0.2970	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4795
test	acc: 0.5709	macro: p 0.3749, r 0.3201, f1: 0.3244	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5374
global_step: 7081, epoch: 78, loss: 0.190594
global_step: 7082, epoch: 78, loss: 0.252998
global_step: 7083, epoch: 78, loss: 0.198442
global_step: 7084, epoch: 78, loss: 0.265263
global_step: 7085, epoch: 78, loss: 0.211641
global_step: 7086, epoch: 78, loss: 0.264687
global_step: 7087, epoch: 78, loss: 0.171484
global_step: 7088, epoch: 78, loss: 0.236362
global_step: 7089, epoch: 78, loss: 0.329453
global_step: 7090, epoch: 78, loss: 0.218634
global_step: 7091, epoch: 78, loss: 0.252993
global_step: 7092, epoch: 78, loss: 0.172438
global_step: 7093, epoch: 78, loss: 0.318391
global_step: 7094, epoch: 78, loss: 0.234904
global_step: 7095, epoch: 78, loss: 0.199833
global_step: 7096, epoch: 78, loss: 0.272523
global_step: 7097, epoch: 78, loss: 0.231823
global_step: 7098, epoch: 78, loss: 0.282633
global_step: 7099, epoch: 78, loss: 0.258235
global_step: 7100, epoch: 78, loss: 0.271991
global_step: 7101, epoch: 78, loss: 0.229944
global_step: 7102, epoch: 78, loss: 0.203196
global_step: 7103, epoch: 78, loss: 0.213877
global_step: 7104, epoch: 78, loss: 0.297540
global_step: 7105, epoch: 78, loss: 0.288629
global_step: 7106, epoch: 78, loss: 0.254274
global_step: 7107, epoch: 78, loss: 0.253673
global_step: 7108, epoch: 78, loss: 0.327018
global_step: 7109, epoch: 78, loss: 0.244387
global_step: 7110, epoch: 78, loss: 0.235212
global_step: 7111, epoch: 78, loss: 0.232005
global_step: 7112, epoch: 78, loss: 0.249962
global_step: 7113, epoch: 78, loss: 0.180334
global_step: 7114, epoch: 78, loss: 0.221503
global_step: 7115, epoch: 78, loss: 0.305728
global_step: 7116, epoch: 78, loss: 0.210935
global_step: 7117, epoch: 78, loss: 0.262496
global_step: 7118, epoch: 78, loss: 0.284282
global_step: 7119, epoch: 78, loss: 0.339642
global_step: 7120, epoch: 78, loss: 0.656791
epoch: 78
train	acc: 0.9657	macro: p 0.9672, r 0.9558, f1: 0.9611	micro: p 0.9657, r 0.9657, f1 0.9657	weighted_f1:0.9658
dev	acc: 0.5104	macro: p 0.3490, r 0.3043, f1: 0.3044	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4743
test	acc: 0.5506	macro: p 0.3439, r 0.3116, f1: 0.3133	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.5244
global_step: 7121, epoch: 79, loss: 0.252135
global_step: 7122, epoch: 79, loss: 0.200946
global_step: 7123, epoch: 79, loss: 0.175538
global_step: 7124, epoch: 79, loss: 0.228579
global_step: 7125, epoch: 79, loss: 0.158891
global_step: 7126, epoch: 79, loss: 0.215619
global_step: 7127, epoch: 79, loss: 0.272792
global_step: 7128, epoch: 79, loss: 0.208402
global_step: 7129, epoch: 79, loss: 0.236112
global_step: 7130, epoch: 79, loss: 0.243831
global_step: 7131, epoch: 79, loss: 0.237593
global_step: 7132, epoch: 79, loss: 0.314067
global_step: 7133, epoch: 79, loss: 0.262522
global_step: 7134, epoch: 79, loss: 0.230268
global_step: 7135, epoch: 79, loss: 0.307238
global_step: 7136, epoch: 79, loss: 0.238225
global_step: 7137, epoch: 79, loss: 0.206606
global_step: 7138, epoch: 79, loss: 0.166947
global_step: 7139, epoch: 79, loss: 0.286144
global_step: 7140, epoch: 79, loss: 0.236507
global_step: 7141, epoch: 79, loss: 0.296958
global_step: 7142, epoch: 79, loss: 0.252933
global_step: 7143, epoch: 79, loss: 0.254954
global_step: 7144, epoch: 79, loss: 0.224311
global_step: 7145, epoch: 79, loss: 0.260540
global_step: 7146, epoch: 79, loss: 0.230349
global_step: 7147, epoch: 79, loss: 0.204974
global_step: 7148, epoch: 79, loss: 0.148818
global_step: 7149, epoch: 79, loss: 0.268259
global_step: 7150, epoch: 79, loss: 0.248827
global_step: 7151, epoch: 79, loss: 0.322273
global_step: 7152, epoch: 79, loss: 0.188150
global_step: 7153, epoch: 79, loss: 0.233432
global_step: 7154, epoch: 79, loss: 0.290879
global_step: 7155, epoch: 79, loss: 0.180675
global_step: 7156, epoch: 79, loss: 0.254551
global_step: 7157, epoch: 79, loss: 0.255558
global_step: 7158, epoch: 79, loss: 0.241051
global_step: 7159, epoch: 79, loss: 0.214664
global_step: 7160, epoch: 79, loss: 0.053203
epoch: 79
train	acc: 0.9693	macro: p 0.9728, r 0.9565, f1: 0.9644	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5176	macro: p 0.3605, r 0.3052, f1: 0.3105	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4814
test	acc: 0.5670	macro: p 0.3657, r 0.3218, f1: 0.3286	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5396
global_step: 7161, epoch: 80, loss: 0.175543
global_step: 7162, epoch: 80, loss: 0.176075
global_step: 7163, epoch: 80, loss: 0.187111
global_step: 7164, epoch: 80, loss: 0.244650
global_step: 7165, epoch: 80, loss: 0.229282
global_step: 7166, epoch: 80, loss: 0.267524
global_step: 7167, epoch: 80, loss: 0.280221
global_step: 7168, epoch: 80, loss: 0.244477
global_step: 7169, epoch: 80, loss: 0.216425
global_step: 7170, epoch: 80, loss: 0.215469
global_step: 7171, epoch: 80, loss: 0.192772
global_step: 7172, epoch: 80, loss: 0.312129
global_step: 7173, epoch: 80, loss: 0.180072
global_step: 7174, epoch: 80, loss: 0.173223
global_step: 7175, epoch: 80, loss: 0.255369
global_step: 7176, epoch: 80, loss: 0.247684
global_step: 7177, epoch: 80, loss: 0.198825
global_step: 7178, epoch: 80, loss: 0.183203
global_step: 7179, epoch: 80, loss: 0.213925
global_step: 7180, epoch: 80, loss: 0.211823
global_step: 7181, epoch: 80, loss: 0.285225
global_step: 7182, epoch: 80, loss: 0.248418
global_step: 7183, epoch: 80, loss: 0.160904
global_step: 7184, epoch: 80, loss: 0.191840
global_step: 7185, epoch: 80, loss: 0.245981
global_step: 7186, epoch: 80, loss: 0.264602
global_step: 7187, epoch: 80, loss: 0.305548
global_step: 7188, epoch: 80, loss: 0.321278
global_step: 7189, epoch: 80, loss: 0.201173
global_step: 7190, epoch: 80, loss: 0.203502
global_step: 7191, epoch: 80, loss: 0.225053
global_step: 7192, epoch: 80, loss: 0.223796
global_step: 7193, epoch: 80, loss: 0.202847
global_step: 7194, epoch: 80, loss: 0.200910
global_step: 7195, epoch: 80, loss: 0.258281
global_step: 7196, epoch: 80, loss: 0.331808
global_step: 7197, epoch: 80, loss: 0.242672
global_step: 7198, epoch: 80, loss: 0.233714
global_step: 7199, epoch: 80, loss: 0.212013
global_step: 7200, epoch: 80, loss: 0.254957
epoch: 80
train	acc: 0.9680	macro: p 0.9720, r 0.9544, f1: 0.9629	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5239	macro: p 0.4331, r 0.3117, f1: 0.3242	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4859
test	acc: 0.5728	macro: p 0.3798, r 0.3193, f1: 0.3311	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5423
global_step: 7201, epoch: 81, loss: 0.338990
global_step: 7202, epoch: 81, loss: 0.256451
global_step: 7203, epoch: 81, loss: 0.223346
global_step: 7204, epoch: 81, loss: 0.239377
global_step: 7205, epoch: 81, loss: 0.266349
global_step: 7206, epoch: 81, loss: 0.232738
global_step: 7207, epoch: 81, loss: 0.232503
global_step: 7208, epoch: 81, loss: 0.167195
global_step: 7209, epoch: 81, loss: 0.242736
global_step: 7210, epoch: 81, loss: 0.201661
global_step: 7211, epoch: 81, loss: 0.263389
global_step: 7212, epoch: 81, loss: 0.232323
global_step: 7213, epoch: 81, loss: 0.226359
global_step: 7214, epoch: 81, loss: 0.201806
global_step: 7215, epoch: 81, loss: 0.202601
global_step: 7216, epoch: 81, loss: 0.212399
global_step: 7217, epoch: 81, loss: 0.172056
global_step: 7218, epoch: 81, loss: 0.238782
global_step: 7219, epoch: 81, loss: 0.286676
global_step: 7220, epoch: 81, loss: 0.223219
global_step: 7221, epoch: 81, loss: 0.264551
global_step: 7222, epoch: 81, loss: 0.261246
global_step: 7223, epoch: 81, loss: 0.246808
global_step: 7224, epoch: 81, loss: 0.239348
global_step: 7225, epoch: 81, loss: 0.278223
global_step: 7226, epoch: 81, loss: 0.316632
global_step: 7227, epoch: 81, loss: 0.265228
global_step: 7228, epoch: 81, loss: 0.268038
global_step: 7229, epoch: 81, loss: 0.213412
global_step: 7230, epoch: 81, loss: 0.186627
global_step: 7231, epoch: 81, loss: 0.207341
global_step: 7232, epoch: 81, loss: 0.285159
global_step: 7233, epoch: 81, loss: 0.233187
global_step: 7234, epoch: 81, loss: 0.279988
global_step: 7235, epoch: 81, loss: 0.252720
global_step: 7236, epoch: 81, loss: 0.275284
global_step: 7237, epoch: 81, loss: 0.196665
global_step: 7238, epoch: 81, loss: 0.211741
global_step: 7239, epoch: 81, loss: 0.309871
global_step: 7240, epoch: 81, loss: 0.477180
epoch: 81
train	acc: 0.9632	macro: p 0.9724, r 0.9457, f1: 0.9584	micro: p 0.9632, r 0.9632, f1 0.9632	weighted_f1:0.9630
dev	acc: 0.5230	macro: p 0.3628, r 0.2867, f1: 0.2871	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4723
test	acc: 0.5778	macro: p 0.4296, r 0.3109, f1: 0.3213	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5381
global_step: 7241, epoch: 82, loss: 0.325692
global_step: 7242, epoch: 82, loss: 0.282311
global_step: 7243, epoch: 82, loss: 0.182010
global_step: 7244, epoch: 82, loss: 0.282057
global_step: 7245, epoch: 82, loss: 0.232061
global_step: 7246, epoch: 82, loss: 0.248161
global_step: 7247, epoch: 82, loss: 0.269074
global_step: 7248, epoch: 82, loss: 0.229974
global_step: 7249, epoch: 82, loss: 0.161665
global_step: 7250, epoch: 82, loss: 0.189919
global_step: 7251, epoch: 82, loss: 0.184897
global_step: 7252, epoch: 82, loss: 0.194172
global_step: 7253, epoch: 82, loss: 0.171645
global_step: 7254, epoch: 82, loss: 0.232082
global_step: 7255, epoch: 82, loss: 0.173123
global_step: 7256, epoch: 82, loss: 0.190251
global_step: 7257, epoch: 82, loss: 0.287742
global_step: 7258, epoch: 82, loss: 0.215922
global_step: 7259, epoch: 82, loss: 0.164461
global_step: 7260, epoch: 82, loss: 0.266310
global_step: 7261, epoch: 82, loss: 0.227402
global_step: 7262, epoch: 82, loss: 0.200918
global_step: 7263, epoch: 82, loss: 0.231936
global_step: 7264, epoch: 82, loss: 0.254267
global_step: 7265, epoch: 82, loss: 0.301489
global_step: 7266, epoch: 82, loss: 0.176177
global_step: 7267, epoch: 82, loss: 0.288491
global_step: 7268, epoch: 82, loss: 0.181685
global_step: 7269, epoch: 82, loss: 0.299692
global_step: 7270, epoch: 82, loss: 0.235870
global_step: 7271, epoch: 82, loss: 0.316443
global_step: 7272, epoch: 82, loss: 0.238223
global_step: 7273, epoch: 82, loss: 0.246117
global_step: 7274, epoch: 82, loss: 0.282398
global_step: 7275, epoch: 82, loss: 0.257500
global_step: 7276, epoch: 82, loss: 0.197706
global_step: 7277, epoch: 82, loss: 0.204651
global_step: 7278, epoch: 82, loss: 0.273460
global_step: 7279, epoch: 82, loss: 0.205220
global_step: 7280, epoch: 82, loss: 0.166397
epoch: 82
train	acc: 0.9698	macro: p 0.9726, r 0.9576, f1: 0.9648	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5113	macro: p 0.3464, r 0.2969, f1: 0.2969	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4746
test	acc: 0.5628	macro: p 0.3812, r 0.3267, f1: 0.3326	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5391
global_step: 7281, epoch: 83, loss: 0.182919
global_step: 7282, epoch: 83, loss: 0.240368
global_step: 7283, epoch: 83, loss: 0.215850
global_step: 7284, epoch: 83, loss: 0.217338
global_step: 7285, epoch: 83, loss: 0.298551
global_step: 7286, epoch: 83, loss: 0.192337
global_step: 7287, epoch: 83, loss: 0.264891
global_step: 7288, epoch: 83, loss: 0.177412
global_step: 7289, epoch: 83, loss: 0.248618
global_step: 7290, epoch: 83, loss: 0.211427
global_step: 7291, epoch: 83, loss: 0.211790
global_step: 7292, epoch: 83, loss: 0.169475
global_step: 7293, epoch: 83, loss: 0.257134
global_step: 7294, epoch: 83, loss: 0.281826
global_step: 7295, epoch: 83, loss: 0.224437
global_step: 7296, epoch: 83, loss: 0.173847
global_step: 7297, epoch: 83, loss: 0.159298
global_step: 7298, epoch: 83, loss: 0.152473
global_step: 7299, epoch: 83, loss: 0.231909
global_step: 7300, epoch: 83, loss: 0.201355
global_step: 7301, epoch: 83, loss: 0.193799
global_step: 7302, epoch: 83, loss: 0.192984
global_step: 7303, epoch: 83, loss: 0.198525
global_step: 7304, epoch: 83, loss: 0.222568
global_step: 7305, epoch: 83, loss: 0.198003
global_step: 7306, epoch: 83, loss: 0.195714
global_step: 7307, epoch: 83, loss: 0.238462
global_step: 7308, epoch: 83, loss: 0.232653
global_step: 7309, epoch: 83, loss: 0.314660
global_step: 7310, epoch: 83, loss: 0.331972
global_step: 7311, epoch: 83, loss: 0.253563
global_step: 7312, epoch: 83, loss: 0.203966
global_step: 7313, epoch: 83, loss: 0.263605
global_step: 7314, epoch: 83, loss: 0.223444
global_step: 7315, epoch: 83, loss: 0.219697
global_step: 7316, epoch: 83, loss: 0.335552
global_step: 7317, epoch: 83, loss: 0.261939
global_step: 7318, epoch: 83, loss: 0.255345
global_step: 7319, epoch: 83, loss: 0.167985
global_step: 7320, epoch: 83, loss: 0.122180
epoch: 83
train	acc: 0.9694	macro: p 0.9699, r 0.9616, f1: 0.9656	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5131	macro: p 0.3303, r 0.3053, f1: 0.3079	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4821
test	acc: 0.5636	macro: p 0.3797, r 0.3369, f1: 0.3476	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5439
global_step: 7321, epoch: 84, loss: 0.245334
global_step: 7322, epoch: 84, loss: 0.239829
global_step: 7323, epoch: 84, loss: 0.250950
global_step: 7324, epoch: 84, loss: 0.262882
global_step: 7325, epoch: 84, loss: 0.207569
global_step: 7326, epoch: 84, loss: 0.200557
global_step: 7327, epoch: 84, loss: 0.211554
global_step: 7328, epoch: 84, loss: 0.226232
global_step: 7329, epoch: 84, loss: 0.202607
global_step: 7330, epoch: 84, loss: 0.176974
global_step: 7331, epoch: 84, loss: 0.193070
global_step: 7332, epoch: 84, loss: 0.193015
global_step: 7333, epoch: 84, loss: 0.184590
global_step: 7334, epoch: 84, loss: 0.239197
global_step: 7335, epoch: 84, loss: 0.288493
global_step: 7336, epoch: 84, loss: 0.103395
global_step: 7337, epoch: 84, loss: 0.191782
global_step: 7338, epoch: 84, loss: 0.256970
global_step: 7339, epoch: 84, loss: 0.204801
global_step: 7340, epoch: 84, loss: 0.304885
global_step: 7341, epoch: 84, loss: 0.255974
global_step: 7342, epoch: 84, loss: 0.291400
global_step: 7343, epoch: 84, loss: 0.163815
global_step: 7344, epoch: 84, loss: 0.162406
global_step: 7345, epoch: 84, loss: 0.205193
global_step: 7346, epoch: 84, loss: 0.268618
global_step: 7347, epoch: 84, loss: 0.289986
global_step: 7348, epoch: 84, loss: 0.295924
global_step: 7349, epoch: 84, loss: 0.207118
global_step: 7350, epoch: 84, loss: 0.215997
global_step: 7351, epoch: 84, loss: 0.225265
global_step: 7352, epoch: 84, loss: 0.313694
global_step: 7353, epoch: 84, loss: 0.209145
global_step: 7354, epoch: 84, loss: 0.236704
global_step: 7355, epoch: 84, loss: 0.285765
global_step: 7356, epoch: 84, loss: 0.219525
global_step: 7357, epoch: 84, loss: 0.229780
global_step: 7358, epoch: 84, loss: 0.219142
global_step: 7359, epoch: 84, loss: 0.268308
global_step: 7360, epoch: 84, loss: 0.014237
epoch: 84
train	acc: 0.9694	macro: p 0.9730, r 0.9594, f1: 0.9660	micro: p 0.9694, r 0.9694, f1 0.9694	weighted_f1:0.9694
dev	acc: 0.5212	macro: p 0.3424, r 0.2939, f1: 0.2952	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4781
test	acc: 0.5816	macro: p 0.4221, r 0.3319, f1: 0.3433	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5488
global_step: 7361, epoch: 85, loss: 0.240228
global_step: 7362, epoch: 85, loss: 0.250489
global_step: 7363, epoch: 85, loss: 0.149480
global_step: 7364, epoch: 85, loss: 0.195989
global_step: 7365, epoch: 85, loss: 0.215056
global_step: 7366, epoch: 85, loss: 0.208295
global_step: 7367, epoch: 85, loss: 0.211095
global_step: 7368, epoch: 85, loss: 0.243861
global_step: 7369, epoch: 85, loss: 0.169940
global_step: 7370, epoch: 85, loss: 0.242888
global_step: 7371, epoch: 85, loss: 0.243591
global_step: 7372, epoch: 85, loss: 0.274875
global_step: 7373, epoch: 85, loss: 0.195392
global_step: 7374, epoch: 85, loss: 0.231983
global_step: 7375, epoch: 85, loss: 0.305437
global_step: 7376, epoch: 85, loss: 0.261967
global_step: 7377, epoch: 85, loss: 0.363525
global_step: 7378, epoch: 85, loss: 0.142936
global_step: 7379, epoch: 85, loss: 0.204851
global_step: 7380, epoch: 85, loss: 0.199819
global_step: 7381, epoch: 85, loss: 0.268924
global_step: 7382, epoch: 85, loss: 0.225398
global_step: 7383, epoch: 85, loss: 0.253406
global_step: 7384, epoch: 85, loss: 0.235964
global_step: 7385, epoch: 85, loss: 0.280197
global_step: 7386, epoch: 85, loss: 0.201119
global_step: 7387, epoch: 85, loss: 0.221973
global_step: 7388, epoch: 85, loss: 0.201847
global_step: 7389, epoch: 85, loss: 0.251115
global_step: 7390, epoch: 85, loss: 0.208769
global_step: 7391, epoch: 85, loss: 0.222680
global_step: 7392, epoch: 85, loss: 0.242010
global_step: 7393, epoch: 85, loss: 0.202294
global_step: 7394, epoch: 85, loss: 0.210682
global_step: 7395, epoch: 85, loss: 0.219676
global_step: 7396, epoch: 85, loss: 0.296634
global_step: 7397, epoch: 85, loss: 0.300977
global_step: 7398, epoch: 85, loss: 0.251103
global_step: 7399, epoch: 85, loss: 0.293009
global_step: 7400, epoch: 85, loss: 0.722671
epoch: 85
train	acc: 0.9679	macro: p 0.9726, r 0.9564, f1: 0.9641	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5185	macro: p 0.3789, r 0.3029, f1: 0.3103	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4766
test	acc: 0.5716	macro: p 0.3920, r 0.3248, f1: 0.3355	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5389
global_step: 7401, epoch: 86, loss: 0.199131
global_step: 7402, epoch: 86, loss: 0.236208
global_step: 7403, epoch: 86, loss: 0.203969
global_step: 7404, epoch: 86, loss: 0.148193
global_step: 7405, epoch: 86, loss: 0.234262
global_step: 7406, epoch: 86, loss: 0.206391
global_step: 7407, epoch: 86, loss: 0.219678
global_step: 7408, epoch: 86, loss: 0.219142
global_step: 7409, epoch: 86, loss: 0.148150
global_step: 7410, epoch: 86, loss: 0.192423
global_step: 7411, epoch: 86, loss: 0.167743
global_step: 7412, epoch: 86, loss: 0.154656
global_step: 7413, epoch: 86, loss: 0.227487
global_step: 7414, epoch: 86, loss: 0.175855
global_step: 7415, epoch: 86, loss: 0.234654
global_step: 7416, epoch: 86, loss: 0.283900
global_step: 7417, epoch: 86, loss: 0.162572
global_step: 7418, epoch: 86, loss: 0.300196
global_step: 7419, epoch: 86, loss: 0.142060
global_step: 7420, epoch: 86, loss: 0.229990
global_step: 7421, epoch: 86, loss: 0.166112
global_step: 7422, epoch: 86, loss: 0.256359
global_step: 7423, epoch: 86, loss: 0.263614
global_step: 7424, epoch: 86, loss: 0.213751
global_step: 7425, epoch: 86, loss: 0.244548
global_step: 7426, epoch: 86, loss: 0.137900
global_step: 7427, epoch: 86, loss: 0.323846
global_step: 7428, epoch: 86, loss: 0.254272
global_step: 7429, epoch: 86, loss: 0.227308
global_step: 7430, epoch: 86, loss: 0.168784
global_step: 7431, epoch: 86, loss: 0.269616
global_step: 7432, epoch: 86, loss: 0.177721
global_step: 7433, epoch: 86, loss: 0.237205
global_step: 7434, epoch: 86, loss: 0.271164
global_step: 7435, epoch: 86, loss: 0.181532
global_step: 7436, epoch: 86, loss: 0.263661
global_step: 7437, epoch: 86, loss: 0.318066
global_step: 7438, epoch: 86, loss: 0.287784
global_step: 7439, epoch: 86, loss: 0.195407
global_step: 7440, epoch: 86, loss: 0.006691
epoch: 86
train	acc: 0.9705	macro: p 0.9737, r 0.9613, f1: 0.9673	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5167	macro: p 0.3543, r 0.2952, f1: 0.3002	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4740
test	acc: 0.5816	macro: p 0.3911, r 0.3241, f1: 0.3336	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5472
global_step: 7441, epoch: 87, loss: 0.182073
global_step: 7442, epoch: 87, loss: 0.203735
global_step: 7443, epoch: 87, loss: 0.256689
global_step: 7444, epoch: 87, loss: 0.188195
global_step: 7445, epoch: 87, loss: 0.139723
global_step: 7446, epoch: 87, loss: 0.192838
global_step: 7447, epoch: 87, loss: 0.223883
global_step: 7448, epoch: 87, loss: 0.211642
global_step: 7449, epoch: 87, loss: 0.172919
global_step: 7450, epoch: 87, loss: 0.199802
global_step: 7451, epoch: 87, loss: 0.227503
global_step: 7452, epoch: 87, loss: 0.249115
global_step: 7453, epoch: 87, loss: 0.259044
global_step: 7454, epoch: 87, loss: 0.215899
global_step: 7455, epoch: 87, loss: 0.212352
global_step: 7456, epoch: 87, loss: 0.315422
global_step: 7457, epoch: 87, loss: 0.254756
global_step: 7458, epoch: 87, loss: 0.204398
global_step: 7459, epoch: 87, loss: 0.171583
global_step: 7460, epoch: 87, loss: 0.205320
global_step: 7461, epoch: 87, loss: 0.187432
global_step: 7462, epoch: 87, loss: 0.335410
global_step: 7463, epoch: 87, loss: 0.343653
global_step: 7464, epoch: 87, loss: 0.232964
global_step: 7465, epoch: 87, loss: 0.260430
global_step: 7466, epoch: 87, loss: 0.214538
global_step: 7467, epoch: 87, loss: 0.193656
global_step: 7468, epoch: 87, loss: 0.244402
global_step: 7469, epoch: 87, loss: 0.281839
global_step: 7470, epoch: 87, loss: 0.215399
global_step: 7471, epoch: 87, loss: 0.193358
global_step: 7472, epoch: 87, loss: 0.223711
global_step: 7473, epoch: 87, loss: 0.196588
global_step: 7474, epoch: 87, loss: 0.248585
global_step: 7475, epoch: 87, loss: 0.278123
global_step: 7476, epoch: 87, loss: 0.272403
global_step: 7477, epoch: 87, loss: 0.209916
global_step: 7478, epoch: 87, loss: 0.152360
global_step: 7479, epoch: 87, loss: 0.236287
global_step: 7480, epoch: 87, loss: 0.004817
epoch: 87
train	acc: 0.9705	macro: p 0.9718, r 0.9620, f1: 0.9668	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5131	macro: p 0.3571, r 0.2997, f1: 0.3061	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4746
test	acc: 0.5820	macro: p 0.3898, r 0.3322, f1: 0.3445	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5517
global_step: 7481, epoch: 88, loss: 0.160112
global_step: 7482, epoch: 88, loss: 0.184252
global_step: 7483, epoch: 88, loss: 0.214938
global_step: 7484, epoch: 88, loss: 0.204509
global_step: 7485, epoch: 88, loss: 0.202627
global_step: 7486, epoch: 88, loss: 0.185133
global_step: 7487, epoch: 88, loss: 0.283415
global_step: 7488, epoch: 88, loss: 0.187301
global_step: 7489, epoch: 88, loss: 0.172681
global_step: 7490, epoch: 88, loss: 0.191717
global_step: 7491, epoch: 88, loss: 0.190905
global_step: 7492, epoch: 88, loss: 0.246025
global_step: 7493, epoch: 88, loss: 0.196345
global_step: 7494, epoch: 88, loss: 0.219400
global_step: 7495, epoch: 88, loss: 0.228547
global_step: 7496, epoch: 88, loss: 0.368305
global_step: 7497, epoch: 88, loss: 0.220313
global_step: 7498, epoch: 88, loss: 0.190015
global_step: 7499, epoch: 88, loss: 0.199691
global_step: 7500, epoch: 88, loss: 0.215020
global_step: 7501, epoch: 88, loss: 0.239664
global_step: 7502, epoch: 88, loss: 0.248429
global_step: 7503, epoch: 88, loss: 0.228711
global_step: 7504, epoch: 88, loss: 0.270317
global_step: 7505, epoch: 88, loss: 0.242255
global_step: 7506, epoch: 88, loss: 0.215403
global_step: 7507, epoch: 88, loss: 0.247471
global_step: 7508, epoch: 88, loss: 0.189385
global_step: 7509, epoch: 88, loss: 0.188122
global_step: 7510, epoch: 88, loss: 0.180172
global_step: 7511, epoch: 88, loss: 0.274344
global_step: 7512, epoch: 88, loss: 0.208284
global_step: 7513, epoch: 88, loss: 0.247962
global_step: 7514, epoch: 88, loss: 0.176924
global_step: 7515, epoch: 88, loss: 0.246198
global_step: 7516, epoch: 88, loss: 0.197998
global_step: 7517, epoch: 88, loss: 0.210579
global_step: 7518, epoch: 88, loss: 0.171140
global_step: 7519, epoch: 88, loss: 0.278519
global_step: 7520, epoch: 88, loss: 0.046384
epoch: 88
train	acc: 0.9675	macro: p 0.9719, r 0.9566, f1: 0.9641	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9674
dev	acc: 0.5275	macro: p 0.4421, r 0.3132, f1: 0.3284	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4867
test	acc: 0.5812	macro: p 0.4171, r 0.3220, f1: 0.3367	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5441
global_step: 7521, epoch: 89, loss: 0.209479
global_step: 7522, epoch: 89, loss: 0.226184
global_step: 7523, epoch: 89, loss: 0.223980
global_step: 7524, epoch: 89, loss: 0.232737
global_step: 7525, epoch: 89, loss: 0.222394
global_step: 7526, epoch: 89, loss: 0.183766
global_step: 7527, epoch: 89, loss: 0.174340
global_step: 7528, epoch: 89, loss: 0.172354
global_step: 7529, epoch: 89, loss: 0.191883
global_step: 7530, epoch: 89, loss: 0.186739
global_step: 7531, epoch: 89, loss: 0.192006
global_step: 7532, epoch: 89, loss: 0.199832
global_step: 7533, epoch: 89, loss: 0.262019
global_step: 7534, epoch: 89, loss: 0.274792
global_step: 7535, epoch: 89, loss: 0.261844
global_step: 7536, epoch: 89, loss: 0.235660
global_step: 7537, epoch: 89, loss: 0.249402
global_step: 7538, epoch: 89, loss: 0.243282
global_step: 7539, epoch: 89, loss: 0.243904
global_step: 7540, epoch: 89, loss: 0.237199
global_step: 7541, epoch: 89, loss: 0.276302
global_step: 7542, epoch: 89, loss: 0.202559
global_step: 7543, epoch: 89, loss: 0.195928
global_step: 7544, epoch: 89, loss: 0.182264
global_step: 7545, epoch: 89, loss: 0.179048
global_step: 7546, epoch: 89, loss: 0.231983
global_step: 7547, epoch: 89, loss: 0.247197
global_step: 7548, epoch: 89, loss: 0.200608
global_step: 7549, epoch: 89, loss: 0.249258
global_step: 7550, epoch: 89, loss: 0.192317
global_step: 7551, epoch: 89, loss: 0.187634
global_step: 7552, epoch: 89, loss: 0.255322
global_step: 7553, epoch: 89, loss: 0.247761
global_step: 7554, epoch: 89, loss: 0.196457
global_step: 7555, epoch: 89, loss: 0.185825
global_step: 7556, epoch: 89, loss: 0.388260
global_step: 7557, epoch: 89, loss: 0.260031
global_step: 7558, epoch: 89, loss: 0.182474
global_step: 7559, epoch: 89, loss: 0.217244
global_step: 7560, epoch: 89, loss: 0.053808
epoch: 89
train	acc: 0.9693	macro: p 0.9701, r 0.9603, f1: 0.9650	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5068	macro: p 0.3332, r 0.2981, f1: 0.2961	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4704
test	acc: 0.5697	macro: p 0.4026, r 0.3315, f1: 0.3379	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5432
global_step: 7561, epoch: 90, loss: 0.162492
global_step: 7562, epoch: 90, loss: 0.215327
global_step: 7563, epoch: 90, loss: 0.209136
global_step: 7564, epoch: 90, loss: 0.197981
global_step: 7565, epoch: 90, loss: 0.174732
global_step: 7566, epoch: 90, loss: 0.178938
global_step: 7567, epoch: 90, loss: 0.174360
global_step: 7568, epoch: 90, loss: 0.181125
global_step: 7569, epoch: 90, loss: 0.190642
global_step: 7570, epoch: 90, loss: 0.214037
global_step: 7571, epoch: 90, loss: 0.197891
global_step: 7572, epoch: 90, loss: 0.197701
global_step: 7573, epoch: 90, loss: 0.202135
global_step: 7574, epoch: 90, loss: 0.199801
global_step: 7575, epoch: 90, loss: 0.214542
global_step: 7576, epoch: 90, loss: 0.204608
global_step: 7577, epoch: 90, loss: 0.217529
global_step: 7578, epoch: 90, loss: 0.175322
global_step: 7579, epoch: 90, loss: 0.216964
global_step: 7580, epoch: 90, loss: 0.186745
global_step: 7581, epoch: 90, loss: 0.211011
global_step: 7582, epoch: 90, loss: 0.249606
global_step: 7583, epoch: 90, loss: 0.224621
global_step: 7584, epoch: 90, loss: 0.242012
global_step: 7585, epoch: 90, loss: 0.212457
global_step: 7586, epoch: 90, loss: 0.224567
global_step: 7587, epoch: 90, loss: 0.205009
global_step: 7588, epoch: 90, loss: 0.221684
global_step: 7589, epoch: 90, loss: 0.239101
global_step: 7590, epoch: 90, loss: 0.216207
global_step: 7591, epoch: 90, loss: 0.123892
global_step: 7592, epoch: 90, loss: 0.216896
global_step: 7593, epoch: 90, loss: 0.207806
global_step: 7594, epoch: 90, loss: 0.284640
global_step: 7595, epoch: 90, loss: 0.206114
global_step: 7596, epoch: 90, loss: 0.264938
global_step: 7597, epoch: 90, loss: 0.125776
global_step: 7598, epoch: 90, loss: 0.220731
global_step: 7599, epoch: 90, loss: 0.207508
global_step: 7600, epoch: 90, loss: 0.229497
epoch: 90
train	acc: 0.9697	macro: p 0.9726, r 0.9621, f1: 0.9672	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5185	macro: p 0.3802, r 0.3050, f1: 0.3126	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4805
test	acc: 0.5778	macro: p 0.3850, r 0.3356, f1: 0.3429	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5496
global_step: 7601, epoch: 91, loss: 0.253297
global_step: 7602, epoch: 91, loss: 0.275686
global_step: 7603, epoch: 91, loss: 0.270966
global_step: 7604, epoch: 91, loss: 0.220065
global_step: 7605, epoch: 91, loss: 0.244386
global_step: 7606, epoch: 91, loss: 0.165310
global_step: 7607, epoch: 91, loss: 0.221805
global_step: 7608, epoch: 91, loss: 0.215847
global_step: 7609, epoch: 91, loss: 0.236128
global_step: 7610, epoch: 91, loss: 0.212001
global_step: 7611, epoch: 91, loss: 0.200540
global_step: 7612, epoch: 91, loss: 0.232907
global_step: 7613, epoch: 91, loss: 0.206825
global_step: 7614, epoch: 91, loss: 0.229408
global_step: 7615, epoch: 91, loss: 0.269763
global_step: 7616, epoch: 91, loss: 0.238753
global_step: 7617, epoch: 91, loss: 0.192102
global_step: 7618, epoch: 91, loss: 0.327131
global_step: 7619, epoch: 91, loss: 0.197350
global_step: 7620, epoch: 91, loss: 0.264284
global_step: 7621, epoch: 91, loss: 0.275283
global_step: 7622, epoch: 91, loss: 0.174015
global_step: 7623, epoch: 91, loss: 0.179354
global_step: 7624, epoch: 91, loss: 0.243217
global_step: 7625, epoch: 91, loss: 0.177733
global_step: 7626, epoch: 91, loss: 0.244698
global_step: 7627, epoch: 91, loss: 0.178976
global_step: 7628, epoch: 91, loss: 0.173020
global_step: 7629, epoch: 91, loss: 0.194335
global_step: 7630, epoch: 91, loss: 0.218862
global_step: 7631, epoch: 91, loss: 0.231882
global_step: 7632, epoch: 91, loss: 0.198437
global_step: 7633, epoch: 91, loss: 0.168691
global_step: 7634, epoch: 91, loss: 0.220124
global_step: 7635, epoch: 91, loss: 0.292322
global_step: 7636, epoch: 91, loss: 0.240619
global_step: 7637, epoch: 91, loss: 0.253005
global_step: 7638, epoch: 91, loss: 0.241888
global_step: 7639, epoch: 91, loss: 0.283444
global_step: 7640, epoch: 91, loss: 0.185200
epoch: 91
train	acc: 0.9700	macro: p 0.9729, r 0.9614, f1: 0.9670	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5149	macro: p 0.3597, r 0.2970, f1: 0.3002	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4727
test	acc: 0.5881	macro: p 0.4175, r 0.3357, f1: 0.3479	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5554
global_step: 7641, epoch: 92, loss: 0.215743
global_step: 7642, epoch: 92, loss: 0.206602
global_step: 7643, epoch: 92, loss: 0.190236
global_step: 7644, epoch: 92, loss: 0.241522
global_step: 7645, epoch: 92, loss: 0.163177
global_step: 7646, epoch: 92, loss: 0.234868
global_step: 7647, epoch: 92, loss: 0.216740
global_step: 7648, epoch: 92, loss: 0.177562
global_step: 7649, epoch: 92, loss: 0.176694
global_step: 7650, epoch: 92, loss: 0.188416
global_step: 7651, epoch: 92, loss: 0.212778
global_step: 7652, epoch: 92, loss: 0.297411
global_step: 7653, epoch: 92, loss: 0.209142
global_step: 7654, epoch: 92, loss: 0.153599
global_step: 7655, epoch: 92, loss: 0.247179
global_step: 7656, epoch: 92, loss: 0.167533
global_step: 7657, epoch: 92, loss: 0.152961
global_step: 7658, epoch: 92, loss: 0.200261
global_step: 7659, epoch: 92, loss: 0.242071
global_step: 7660, epoch: 92, loss: 0.176767
global_step: 7661, epoch: 92, loss: 0.150841
global_step: 7662, epoch: 92, loss: 0.222500
global_step: 7663, epoch: 92, loss: 0.171169
global_step: 7664, epoch: 92, loss: 0.185145
global_step: 7665, epoch: 92, loss: 0.206875
global_step: 7666, epoch: 92, loss: 0.180332
global_step: 7667, epoch: 92, loss: 0.293301
global_step: 7668, epoch: 92, loss: 0.215748
global_step: 7669, epoch: 92, loss: 0.231779
global_step: 7670, epoch: 92, loss: 0.171981
global_step: 7671, epoch: 92, loss: 0.243577
global_step: 7672, epoch: 92, loss: 0.237068
global_step: 7673, epoch: 92, loss: 0.159811
global_step: 7674, epoch: 92, loss: 0.275905
global_step: 7675, epoch: 92, loss: 0.248556
global_step: 7676, epoch: 92, loss: 0.256550
global_step: 7677, epoch: 92, loss: 0.251042
global_step: 7678, epoch: 92, loss: 0.237932
global_step: 7679, epoch: 92, loss: 0.146608
global_step: 7680, epoch: 92, loss: 0.000337
epoch: 92
train	acc: 0.9707	macro: p 0.9728, r 0.9610, f1: 0.9667	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5221	macro: p 0.3815, r 0.3013, f1: 0.3068	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4791
test	acc: 0.5835	macro: p 0.4021, r 0.3259, f1: 0.3370	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5485
global_step: 7681, epoch: 93, loss: 0.167663
global_step: 7682, epoch: 93, loss: 0.199620
global_step: 7683, epoch: 93, loss: 0.134650
global_step: 7684, epoch: 93, loss: 0.225725
global_step: 7685, epoch: 93, loss: 0.243340
global_step: 7686, epoch: 93, loss: 0.136540
global_step: 7687, epoch: 93, loss: 0.197144
global_step: 7688, epoch: 93, loss: 0.244978
global_step: 7689, epoch: 93, loss: 0.188522
global_step: 7690, epoch: 93, loss: 0.175749
global_step: 7691, epoch: 93, loss: 0.224225
global_step: 7692, epoch: 93, loss: 0.157406
global_step: 7693, epoch: 93, loss: 0.199547
global_step: 7694, epoch: 93, loss: 0.195978
global_step: 7695, epoch: 93, loss: 0.239604
global_step: 7696, epoch: 93, loss: 0.182461
global_step: 7697, epoch: 93, loss: 0.189122
global_step: 7698, epoch: 93, loss: 0.201912
global_step: 7699, epoch: 93, loss: 0.270918
global_step: 7700, epoch: 93, loss: 0.133918
global_step: 7701, epoch: 93, loss: 0.237308
global_step: 7702, epoch: 93, loss: 0.202460
global_step: 7703, epoch: 93, loss: 0.247306
global_step: 7704, epoch: 93, loss: 0.291184
global_step: 7705, epoch: 93, loss: 0.207225
global_step: 7706, epoch: 93, loss: 0.284596
global_step: 7707, epoch: 93, loss: 0.204408
global_step: 7708, epoch: 93, loss: 0.230916
global_step: 7709, epoch: 93, loss: 0.205450
global_step: 7710, epoch: 93, loss: 0.191595
global_step: 7711, epoch: 93, loss: 0.194520
global_step: 7712, epoch: 93, loss: 0.178915
global_step: 7713, epoch: 93, loss: 0.202461
global_step: 7714, epoch: 93, loss: 0.240185
global_step: 7715, epoch: 93, loss: 0.234721
global_step: 7716, epoch: 93, loss: 0.253494
global_step: 7717, epoch: 93, loss: 0.249960
global_step: 7718, epoch: 93, loss: 0.261373
global_step: 7719, epoch: 93, loss: 0.301579
global_step: 7720, epoch: 93, loss: 0.159547
epoch: 93
train	acc: 0.9698	macro: p 0.9722, r 0.9608, f1: 0.9663	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5185	macro: p 0.4033, r 0.3138, f1: 0.3229	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4819
test	acc: 0.5778	macro: p 0.4078, r 0.3239, f1: 0.3321	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5437
global_step: 7721, epoch: 94, loss: 0.203279
global_step: 7722, epoch: 94, loss: 0.210827
global_step: 7723, epoch: 94, loss: 0.207410
global_step: 7724, epoch: 94, loss: 0.120264
global_step: 7725, epoch: 94, loss: 0.213044
global_step: 7726, epoch: 94, loss: 0.184474
global_step: 7727, epoch: 94, loss: 0.221399
global_step: 7728, epoch: 94, loss: 0.190631
global_step: 7729, epoch: 94, loss: 0.225143
global_step: 7730, epoch: 94, loss: 0.239597
global_step: 7731, epoch: 94, loss: 0.212635
global_step: 7732, epoch: 94, loss: 0.240445
global_step: 7733, epoch: 94, loss: 0.146545
global_step: 7734, epoch: 94, loss: 0.190641
global_step: 7735, epoch: 94, loss: 0.253727
global_step: 7736, epoch: 94, loss: 0.226140
global_step: 7737, epoch: 94, loss: 0.296200
global_step: 7738, epoch: 94, loss: 0.175984
global_step: 7739, epoch: 94, loss: 0.167948
global_step: 7740, epoch: 94, loss: 0.229297
global_step: 7741, epoch: 94, loss: 0.212959
global_step: 7742, epoch: 94, loss: 0.275630
global_step: 7743, epoch: 94, loss: 0.204543
global_step: 7744, epoch: 94, loss: 0.211934
global_step: 7745, epoch: 94, loss: 0.168084
global_step: 7746, epoch: 94, loss: 0.172917
global_step: 7747, epoch: 94, loss: 0.225561
global_step: 7748, epoch: 94, loss: 0.264333
global_step: 7749, epoch: 94, loss: 0.277031
global_step: 7750, epoch: 94, loss: 0.233068
global_step: 7751, epoch: 94, loss: 0.298992
global_step: 7752, epoch: 94, loss: 0.242893
global_step: 7753, epoch: 94, loss: 0.260846
global_step: 7754, epoch: 94, loss: 0.218481
global_step: 7755, epoch: 94, loss: 0.213493
global_step: 7756, epoch: 94, loss: 0.205827
global_step: 7757, epoch: 94, loss: 0.275537
global_step: 7758, epoch: 94, loss: 0.207149
global_step: 7759, epoch: 94, loss: 0.159427
global_step: 7760, epoch: 94, loss: 0.043412
epoch: 94
train	acc: 0.9690	macro: p 0.9736, r 0.9581, f1: 0.9655	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5104	macro: p 0.3635, r 0.2997, f1: 0.3011	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4722
test	acc: 0.5739	macro: p 0.3940, r 0.3296, f1: 0.3374	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5457
global_step: 7761, epoch: 95, loss: 0.210121
global_step: 7762, epoch: 95, loss: 0.269552
global_step: 7763, epoch: 95, loss: 0.149768
global_step: 7764, epoch: 95, loss: 0.200684
global_step: 7765, epoch: 95, loss: 0.200425
global_step: 7766, epoch: 95, loss: 0.130116
global_step: 7767, epoch: 95, loss: 0.173859
global_step: 7768, epoch: 95, loss: 0.162875
global_step: 7769, epoch: 95, loss: 0.201901
global_step: 7770, epoch: 95, loss: 0.187018
global_step: 7771, epoch: 95, loss: 0.200234
global_step: 7772, epoch: 95, loss: 0.159364
global_step: 7773, epoch: 95, loss: 0.223494
global_step: 7774, epoch: 95, loss: 0.264253
global_step: 7775, epoch: 95, loss: 0.273273
global_step: 7776, epoch: 95, loss: 0.193654
global_step: 7777, epoch: 95, loss: 0.240993
global_step: 7778, epoch: 95, loss: 0.227900
global_step: 7779, epoch: 95, loss: 0.211842
global_step: 7780, epoch: 95, loss: 0.195815
global_step: 7781, epoch: 95, loss: 0.195718
global_step: 7782, epoch: 95, loss: 0.164460
global_step: 7783, epoch: 95, loss: 0.267866
global_step: 7784, epoch: 95, loss: 0.286012
global_step: 7785, epoch: 95, loss: 0.203841
global_step: 7786, epoch: 95, loss: 0.233956
global_step: 7787, epoch: 95, loss: 0.200818
global_step: 7788, epoch: 95, loss: 0.147015
global_step: 7789, epoch: 95, loss: 0.237737
global_step: 7790, epoch: 95, loss: 0.196085
global_step: 7791, epoch: 95, loss: 0.292283
global_step: 7792, epoch: 95, loss: 0.248336
global_step: 7793, epoch: 95, loss: 0.148559
global_step: 7794, epoch: 95, loss: 0.174437
global_step: 7795, epoch: 95, loss: 0.226462
global_step: 7796, epoch: 95, loss: 0.240910
global_step: 7797, epoch: 95, loss: 0.329772
global_step: 7798, epoch: 95, loss: 0.239431
global_step: 7799, epoch: 95, loss: 0.191207
global_step: 7800, epoch: 95, loss: 0.017304
epoch: 95
train	acc: 0.9698	macro: p 0.9720, r 0.9601, f1: 0.9658	micro: p 0.9698, r 0.9698, f1 0.9698	weighted_f1:0.9698
dev	acc: 0.5221	macro: p 0.3635, r 0.3132, f1: 0.3187	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4844
test	acc: 0.5759	macro: p 0.3830, r 0.3265, f1: 0.3360	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5427
global_step: 7801, epoch: 96, loss: 0.210604
global_step: 7802, epoch: 96, loss: 0.154656
global_step: 7803, epoch: 96, loss: 0.151039
global_step: 7804, epoch: 96, loss: 0.163032
global_step: 7805, epoch: 96, loss: 0.252548
global_step: 7806, epoch: 96, loss: 0.232542
global_step: 7807, epoch: 96, loss: 0.212570
global_step: 7808, epoch: 96, loss: 0.202520
global_step: 7809, epoch: 96, loss: 0.204683
global_step: 7810, epoch: 96, loss: 0.223283
global_step: 7811, epoch: 96, loss: 0.345917
global_step: 7812, epoch: 96, loss: 0.189355
global_step: 7813, epoch: 96, loss: 0.220653
global_step: 7814, epoch: 96, loss: 0.215394
global_step: 7815, epoch: 96, loss: 0.338343
global_step: 7816, epoch: 96, loss: 0.249635
global_step: 7817, epoch: 96, loss: 0.260142
global_step: 7818, epoch: 96, loss: 0.177876
global_step: 7819, epoch: 96, loss: 0.297737
global_step: 7820, epoch: 96, loss: 0.265142
global_step: 7821, epoch: 96, loss: 0.189377
global_step: 7822, epoch: 96, loss: 0.200637
global_step: 7823, epoch: 96, loss: 0.226028
global_step: 7824, epoch: 96, loss: 0.239800
global_step: 7825, epoch: 96, loss: 0.175627
global_step: 7826, epoch: 96, loss: 0.235831
global_step: 7827, epoch: 96, loss: 0.186801
global_step: 7828, epoch: 96, loss: 0.212308
global_step: 7829, epoch: 96, loss: 0.196632
global_step: 7830, epoch: 96, loss: 0.188337
global_step: 7831, epoch: 96, loss: 0.291244
global_step: 7832, epoch: 96, loss: 0.269072
global_step: 7833, epoch: 96, loss: 0.275972
global_step: 7834, epoch: 96, loss: 0.259221
global_step: 7835, epoch: 96, loss: 0.210420
global_step: 7836, epoch: 96, loss: 0.183453
global_step: 7837, epoch: 96, loss: 0.187727
global_step: 7838, epoch: 96, loss: 0.226945
global_step: 7839, epoch: 96, loss: 0.250847
global_step: 7840, epoch: 96, loss: 0.062198
epoch: 96
train	acc: 0.9693	macro: p 0.9724, r 0.9585, f1: 0.9652	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5257	macro: p 0.3754, r 0.3075, f1: 0.3112	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4833
test	acc: 0.5816	macro: p 0.3980, r 0.3244, f1: 0.3323	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5438
global_step: 7841, epoch: 97, loss: 0.210743
global_step: 7842, epoch: 97, loss: 0.168270
global_step: 7843, epoch: 97, loss: 0.205436
global_step: 7844, epoch: 97, loss: 0.200923
global_step: 7845, epoch: 97, loss: 0.215684
global_step: 7846, epoch: 97, loss: 0.220879
global_step: 7847, epoch: 97, loss: 0.136488
global_step: 7848, epoch: 97, loss: 0.203472
global_step: 7849, epoch: 97, loss: 0.183007
global_step: 7850, epoch: 97, loss: 0.135810
global_step: 7851, epoch: 97, loss: 0.204886
global_step: 7852, epoch: 97, loss: 0.170708
global_step: 7853, epoch: 97, loss: 0.225611
global_step: 7854, epoch: 97, loss: 0.286177
global_step: 7855, epoch: 97, loss: 0.241533
global_step: 7856, epoch: 97, loss: 0.230266
global_step: 7857, epoch: 97, loss: 0.247003
global_step: 7858, epoch: 97, loss: 0.184187
global_step: 7859, epoch: 97, loss: 0.144824
global_step: 7860, epoch: 97, loss: 0.215277
global_step: 7861, epoch: 97, loss: 0.212664
global_step: 7862, epoch: 97, loss: 0.199177
global_step: 7863, epoch: 97, loss: 0.177398
global_step: 7864, epoch: 97, loss: 0.200008
global_step: 7865, epoch: 97, loss: 0.134386
global_step: 7866, epoch: 97, loss: 0.160471
global_step: 7867, epoch: 97, loss: 0.249842
global_step: 7868, epoch: 97, loss: 0.195963
global_step: 7869, epoch: 97, loss: 0.122338
global_step: 7870, epoch: 97, loss: 0.195871
global_step: 7871, epoch: 97, loss: 0.180927
global_step: 7872, epoch: 97, loss: 0.313144
global_step: 7873, epoch: 97, loss: 0.194201
global_step: 7874, epoch: 97, loss: 0.243182
global_step: 7875, epoch: 97, loss: 0.287168
global_step: 7876, epoch: 97, loss: 0.233551
global_step: 7877, epoch: 97, loss: 0.249262
global_step: 7878, epoch: 97, loss: 0.217938
global_step: 7879, epoch: 97, loss: 0.211284
global_step: 7880, epoch: 97, loss: 0.001113
epoch: 97
train	acc: 0.9691	macro: p 0.9708, r 0.9596, f1: 0.9650	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5221	macro: p 0.3758, r 0.3076, f1: 0.3128	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4831
test	acc: 0.5820	macro: p 0.3876, r 0.3265, f1: 0.3327	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5463
global_step: 7881, epoch: 98, loss: 0.228213
global_step: 7882, epoch: 98, loss: 0.240587
global_step: 7883, epoch: 98, loss: 0.237835
global_step: 7884, epoch: 98, loss: 0.176234
global_step: 7885, epoch: 98, loss: 0.197960
global_step: 7886, epoch: 98, loss: 0.296404
global_step: 7887, epoch: 98, loss: 0.175187
global_step: 7888, epoch: 98, loss: 0.167651
global_step: 7889, epoch: 98, loss: 0.202969
global_step: 7890, epoch: 98, loss: 0.202077
global_step: 7891, epoch: 98, loss: 0.239834
global_step: 7892, epoch: 98, loss: 0.151725
global_step: 7893, epoch: 98, loss: 0.171262
global_step: 7894, epoch: 98, loss: 0.335020
global_step: 7895, epoch: 98, loss: 0.276681
global_step: 7896, epoch: 98, loss: 0.162711
global_step: 7897, epoch: 98, loss: 0.220197
global_step: 7898, epoch: 98, loss: 0.242037
global_step: 7899, epoch: 98, loss: 0.235681
global_step: 7900, epoch: 98, loss: 0.255332
global_step: 7901, epoch: 98, loss: 0.155561
global_step: 7902, epoch: 98, loss: 0.174815
global_step: 7903, epoch: 98, loss: 0.260250
global_step: 7904, epoch: 98, loss: 0.185411
global_step: 7905, epoch: 98, loss: 0.193444
global_step: 7906, epoch: 98, loss: 0.193226
global_step: 7907, epoch: 98, loss: 0.174549
global_step: 7908, epoch: 98, loss: 0.236645
global_step: 7909, epoch: 98, loss: 0.264616
global_step: 7910, epoch: 98, loss: 0.149717
global_step: 7911, epoch: 98, loss: 0.248849
global_step: 7912, epoch: 98, loss: 0.293058
global_step: 7913, epoch: 98, loss: 0.184324
global_step: 7914, epoch: 98, loss: 0.131258
global_step: 7915, epoch: 98, loss: 0.236745
global_step: 7916, epoch: 98, loss: 0.225816
global_step: 7917, epoch: 98, loss: 0.166599
global_step: 7918, epoch: 98, loss: 0.201530
global_step: 7919, epoch: 98, loss: 0.217813
global_step: 7920, epoch: 98, loss: 0.381532
epoch: 98
train	acc: 0.9702	macro: p 0.9731, r 0.9601, f1: 0.9664	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5131	macro: p 0.3952, r 0.2922, f1: 0.3006	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4658
test	acc: 0.5851	macro: p 0.3919, r 0.3174, f1: 0.3256	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5422
global_step: 7921, epoch: 99, loss: 0.194717
global_step: 7922, epoch: 99, loss: 0.169382
global_step: 7923, epoch: 99, loss: 0.185893
global_step: 7924, epoch: 99, loss: 0.383967
global_step: 7925, epoch: 99, loss: 0.215741
global_step: 7926, epoch: 99, loss: 0.159979
global_step: 7927, epoch: 99, loss: 0.208844
global_step: 7928, epoch: 99, loss: 0.194111
global_step: 7929, epoch: 99, loss: 0.288716
global_step: 7930, epoch: 99, loss: 0.229065
global_step: 7931, epoch: 99, loss: 0.221569
global_step: 7932, epoch: 99, loss: 0.187602
global_step: 7933, epoch: 99, loss: 0.159039
global_step: 7934, epoch: 99, loss: 0.131503
global_step: 7935, epoch: 99, loss: 0.179047
global_step: 7936, epoch: 99, loss: 0.146006
global_step: 7937, epoch: 99, loss: 0.192845
global_step: 7938, epoch: 99, loss: 0.212975
global_step: 7939, epoch: 99, loss: 0.184544
global_step: 7940, epoch: 99, loss: 0.197616
global_step: 7941, epoch: 99, loss: 0.281630
global_step: 7942, epoch: 99, loss: 0.219592
global_step: 7943, epoch: 99, loss: 0.213602
global_step: 7944, epoch: 99, loss: 0.244387
global_step: 7945, epoch: 99, loss: 0.217811
global_step: 7946, epoch: 99, loss: 0.154113
global_step: 7947, epoch: 99, loss: 0.119147
global_step: 7948, epoch: 99, loss: 0.217746
global_step: 7949, epoch: 99, loss: 0.244728
global_step: 7950, epoch: 99, loss: 0.178588
global_step: 7951, epoch: 99, loss: 0.240569
global_step: 7952, epoch: 99, loss: 0.264250
global_step: 7953, epoch: 99, loss: 0.250153
global_step: 7954, epoch: 99, loss: 0.214692
global_step: 7955, epoch: 99, loss: 0.262786
global_step: 7956, epoch: 99, loss: 0.186359
global_step: 7957, epoch: 99, loss: 0.213156
global_step: 7958, epoch: 99, loss: 0.183172
global_step: 7959, epoch: 99, loss: 0.203844
global_step: 7960, epoch: 99, loss: 2.312444
epoch: 99
train	acc: 0.9699	macro: p 0.9729, r 0.9604, f1: 0.9664	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5257	macro: p 0.3881, r 0.3094, f1: 0.3182	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4835
test	acc: 0.5782	macro: p 0.3920, r 0.3239, f1: 0.3364	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5417
global_step: 7961, epoch: 100, loss: 0.219608
global_step: 7962, epoch: 100, loss: 0.175759
global_step: 7963, epoch: 100, loss: 0.206400
global_step: 7964, epoch: 100, loss: 0.165498
global_step: 7965, epoch: 100, loss: 0.187410
global_step: 7966, epoch: 100, loss: 0.198797
global_step: 7967, epoch: 100, loss: 0.227816
global_step: 7968, epoch: 100, loss: 0.255213
global_step: 7969, epoch: 100, loss: 0.182142
global_step: 7970, epoch: 100, loss: 0.112267
global_step: 7971, epoch: 100, loss: 0.164947
global_step: 7972, epoch: 100, loss: 0.213659
global_step: 7973, epoch: 100, loss: 0.193302
global_step: 7974, epoch: 100, loss: 0.132077
global_step: 7975, epoch: 100, loss: 0.172659
global_step: 7976, epoch: 100, loss: 0.220164
global_step: 7977, epoch: 100, loss: 0.185908
global_step: 7978, epoch: 100, loss: 0.206596
global_step: 7979, epoch: 100, loss: 0.189474
global_step: 7980, epoch: 100, loss: 0.150925
global_step: 7981, epoch: 100, loss: 0.220143
global_step: 7982, epoch: 100, loss: 0.233027
global_step: 7983, epoch: 100, loss: 0.138934
global_step: 7984, epoch: 100, loss: 0.239177
global_step: 7985, epoch: 100, loss: 0.198787
global_step: 7986, epoch: 100, loss: 0.203083
global_step: 7987, epoch: 100, loss: 0.221299
global_step: 7988, epoch: 100, loss: 0.163128
global_step: 7989, epoch: 100, loss: 0.169794
global_step: 7990, epoch: 100, loss: 0.245228
global_step: 7991, epoch: 100, loss: 0.218940
global_step: 7992, epoch: 100, loss: 0.209411
global_step: 7993, epoch: 100, loss: 0.212699
global_step: 7994, epoch: 100, loss: 0.210209
global_step: 7995, epoch: 100, loss: 0.270142
global_step: 7996, epoch: 100, loss: 0.211326
global_step: 7997, epoch: 100, loss: 0.171263
global_step: 7998, epoch: 100, loss: 0.147100
global_step: 7999, epoch: 100, loss: 0.286148
global_step: 8000, epoch: 100, loss: 0.139579
epoch: 100
train	acc: 0.9700	macro: p 0.9734, r 0.9602, f1: 0.9666	micro: p 0.9700, r 0.9700, f1 0.9700	weighted_f1:0.9700
dev	acc: 0.5086	macro: p 0.3699, r 0.3222, f1: 0.3289	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4855
test	acc: 0.5640	macro: p 0.3457, r 0.3272, f1: 0.3290	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5439
BEST MODEL epoch: 12
train	acc: 0.7876 macro_p: 0.6673 macro_r: 0.6802 macro_f1: 0.6629 micro_p: 0.7876 micro_r: 0.7876 micro_f1: 0.7876 weighted_f1: 0.7905
dev	acc: 0.5140 macro_p: 0.3555 macro_r: 0.3306 macro_f1: 0.3335 micro_p: 0.5140 micro_r: 0.5140 micro_f1: 0.5140 weighted_f1: 0.5009
test	acc: 0.5437 macro_p: 0.3490 macro_r: 0.3308 macro_f1: 0.3321 micro_p: 0.5437 micro_r: 0.5437 micro_f1: 0.5437 weighted_f1: 0.5417
==========ROUND 3==========
global_step: 8001, epoch: 1, loss: 1.923114
global_step: 8002, epoch: 1, loss: 1.735209
global_step: 8003, epoch: 1, loss: 1.704681
global_step: 8004, epoch: 1, loss: 1.558207
global_step: 8005, epoch: 1, loss: 1.543664
global_step: 8006, epoch: 1, loss: 1.471671
global_step: 8007, epoch: 1, loss: 1.520633
global_step: 8008, epoch: 1, loss: 1.479358
global_step: 8009, epoch: 1, loss: 1.447423
global_step: 8010, epoch: 1, loss: 1.453727
global_step: 8011, epoch: 1, loss: 1.456284
global_step: 8012, epoch: 1, loss: 1.339529
global_step: 8013, epoch: 1, loss: 1.437652
global_step: 8014, epoch: 1, loss: 1.479522
global_step: 8015, epoch: 1, loss: 1.466536
global_step: 8016, epoch: 1, loss: 1.413731
global_step: 8017, epoch: 1, loss: 1.416210
global_step: 8018, epoch: 1, loss: 1.451202
global_step: 8019, epoch: 1, loss: 1.357573
global_step: 8020, epoch: 1, loss: 1.299118
global_step: 8021, epoch: 1, loss: 1.406993
global_step: 8022, epoch: 1, loss: 1.465268
global_step: 8023, epoch: 1, loss: 1.494781
global_step: 8024, epoch: 1, loss: 1.425697
global_step: 8025, epoch: 1, loss: 1.429676
global_step: 8026, epoch: 1, loss: 1.324870
global_step: 8027, epoch: 1, loss: 1.367411
global_step: 8028, epoch: 1, loss: 1.324072
global_step: 8029, epoch: 1, loss: 1.386112
global_step: 8030, epoch: 1, loss: 1.356692
global_step: 8031, epoch: 1, loss: 1.487959
global_step: 8032, epoch: 1, loss: 1.370449
global_step: 8033, epoch: 1, loss: 1.321513
global_step: 8034, epoch: 1, loss: 1.417413
global_step: 8035, epoch: 1, loss: 1.365404
global_step: 8036, epoch: 1, loss: 1.467802
global_step: 8037, epoch: 1, loss: 1.405600
global_step: 8038, epoch: 1, loss: 1.380403
global_step: 8039, epoch: 1, loss: 1.516010
global_step: 8040, epoch: 1, loss: 2.074656
epoch: 1
train	acc: 0.5647	macro: p 0.3525, r 0.2668, f1: 0.2540	micro: p 0.5647, r 0.5647, f1 0.5647	weighted_f1:0.4953
dev	acc: 0.5140	macro: p 0.3601, r 0.2541, f1: 0.2362	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4343
test	acc: 0.5743	macro: p 0.3443, r 0.2659, f1: 0.2565	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5062
New best model!
global_step: 8041, epoch: 2, loss: 1.392645
global_step: 8042, epoch: 2, loss: 1.354485
global_step: 8043, epoch: 2, loss: 1.399589
global_step: 8044, epoch: 2, loss: 1.312050
global_step: 8045, epoch: 2, loss: 1.436886
global_step: 8046, epoch: 2, loss: 1.390360
global_step: 8047, epoch: 2, loss: 1.273623
global_step: 8048, epoch: 2, loss: 1.340975
global_step: 8049, epoch: 2, loss: 1.436836
global_step: 8050, epoch: 2, loss: 1.430134
global_step: 8051, epoch: 2, loss: 1.153792
global_step: 8052, epoch: 2, loss: 1.362197
global_step: 8053, epoch: 2, loss: 1.334306
global_step: 8054, epoch: 2, loss: 1.352678
global_step: 8055, epoch: 2, loss: 1.319143
global_step: 8056, epoch: 2, loss: 1.451734
global_step: 8057, epoch: 2, loss: 1.305447
global_step: 8058, epoch: 2, loss: 1.237910
global_step: 8059, epoch: 2, loss: 1.230908
global_step: 8060, epoch: 2, loss: 1.311953
global_step: 8061, epoch: 2, loss: 1.296581
global_step: 8062, epoch: 2, loss: 1.346846
global_step: 8063, epoch: 2, loss: 1.316440
global_step: 8064, epoch: 2, loss: 1.296469
global_step: 8065, epoch: 2, loss: 1.439814
global_step: 8066, epoch: 2, loss: 1.338264
global_step: 8067, epoch: 2, loss: 1.318712
global_step: 8068, epoch: 2, loss: 1.346829
global_step: 8069, epoch: 2, loss: 1.342120
global_step: 8070, epoch: 2, loss: 1.296735
global_step: 8071, epoch: 2, loss: 1.349402
global_step: 8072, epoch: 2, loss: 1.375852
global_step: 8073, epoch: 2, loss: 1.267705
global_step: 8074, epoch: 2, loss: 1.229293
global_step: 8075, epoch: 2, loss: 1.206472
global_step: 8076, epoch: 2, loss: 1.383740
global_step: 8077, epoch: 2, loss: 1.311881
global_step: 8078, epoch: 2, loss: 1.402641
global_step: 8079, epoch: 2, loss: 1.368609
global_step: 8080, epoch: 2, loss: 1.456099
epoch: 2
train	acc: 0.5833	macro: p 0.3251, r 0.2670, f1: 0.2515	micro: p 0.5833, r 0.5833, f1 0.5833	weighted_f1:0.5026
dev	acc: 0.5293	macro: p 0.2818, r 0.2662, f1: 0.2317	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4330
test	acc: 0.5774	macro: p 0.2921, r 0.2660, f1: 0.2432	micro: p 0.5774, r 0.5774, f1 0.5774	weighted_f1:0.4920
global_step: 8081, epoch: 3, loss: 1.315670
global_step: 8082, epoch: 3, loss: 1.160053
global_step: 8083, epoch: 3, loss: 1.551730
global_step: 8084, epoch: 3, loss: 1.281516
global_step: 8085, epoch: 3, loss: 1.452346
global_step: 8086, epoch: 3, loss: 1.309031
global_step: 8087, epoch: 3, loss: 1.302140
global_step: 8088, epoch: 3, loss: 1.337751
global_step: 8089, epoch: 3, loss: 1.215950
global_step: 8090, epoch: 3, loss: 1.173621
global_step: 8091, epoch: 3, loss: 1.318611
global_step: 8092, epoch: 3, loss: 1.306040
global_step: 8093, epoch: 3, loss: 1.336460
global_step: 8094, epoch: 3, loss: 1.303669
global_step: 8095, epoch: 3, loss: 1.243241
global_step: 8096, epoch: 3, loss: 1.308911
global_step: 8097, epoch: 3, loss: 1.258014
global_step: 8098, epoch: 3, loss: 1.195782
global_step: 8099, epoch: 3, loss: 1.193952
global_step: 8100, epoch: 3, loss: 1.268306
global_step: 8101, epoch: 3, loss: 1.215194
global_step: 8102, epoch: 3, loss: 1.334163
global_step: 8103, epoch: 3, loss: 1.311480
global_step: 8104, epoch: 3, loss: 1.315309
global_step: 8105, epoch: 3, loss: 1.314660
global_step: 8106, epoch: 3, loss: 1.369747
global_step: 8107, epoch: 3, loss: 1.273590
global_step: 8108, epoch: 3, loss: 1.236061
global_step: 8109, epoch: 3, loss: 1.207439
global_step: 8110, epoch: 3, loss: 1.190082
global_step: 8111, epoch: 3, loss: 1.373207
global_step: 8112, epoch: 3, loss: 1.310127
global_step: 8113, epoch: 3, loss: 1.246901
global_step: 8114, epoch: 3, loss: 1.192052
global_step: 8115, epoch: 3, loss: 1.262043
global_step: 8116, epoch: 3, loss: 1.295516
global_step: 8117, epoch: 3, loss: 1.174474
global_step: 8118, epoch: 3, loss: 1.171599
global_step: 8119, epoch: 3, loss: 1.452607
global_step: 8120, epoch: 3, loss: 0.606891
epoch: 3
train	acc: 0.5813	macro: p 0.4382, r 0.2641, f1: 0.2554	micro: p 0.5813, r 0.5813, f1 0.5813	weighted_f1:0.5028
dev	acc: 0.5311	macro: p 0.2932, r 0.2630, f1: 0.2335	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4355
test	acc: 0.5801	macro: p 0.3077, r 0.2649, f1: 0.2486	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.4972
New best model!
global_step: 8121, epoch: 4, loss: 1.202590
global_step: 8122, epoch: 4, loss: 1.363031
global_step: 8123, epoch: 4, loss: 1.300901
global_step: 8124, epoch: 4, loss: 1.257845
global_step: 8125, epoch: 4, loss: 1.281329
global_step: 8126, epoch: 4, loss: 1.228273
global_step: 8127, epoch: 4, loss: 1.218937
global_step: 8128, epoch: 4, loss: 1.201060
global_step: 8129, epoch: 4, loss: 1.208288
global_step: 8130, epoch: 4, loss: 1.270341
global_step: 8131, epoch: 4, loss: 1.149713
global_step: 8132, epoch: 4, loss: 1.294634
global_step: 8133, epoch: 4, loss: 1.202667
global_step: 8134, epoch: 4, loss: 1.206607
global_step: 8135, epoch: 4, loss: 1.171932
global_step: 8136, epoch: 4, loss: 1.232683
global_step: 8137, epoch: 4, loss: 1.271894
global_step: 8138, epoch: 4, loss: 1.241640
global_step: 8139, epoch: 4, loss: 1.167567
global_step: 8140, epoch: 4, loss: 1.272855
global_step: 8141, epoch: 4, loss: 1.229394
global_step: 8142, epoch: 4, loss: 1.221800
global_step: 8143, epoch: 4, loss: 1.230671
global_step: 8144, epoch: 4, loss: 1.293304
global_step: 8145, epoch: 4, loss: 1.218309
global_step: 8146, epoch: 4, loss: 1.289882
global_step: 8147, epoch: 4, loss: 1.190506
global_step: 8148, epoch: 4, loss: 1.209488
global_step: 8149, epoch: 4, loss: 1.203604
global_step: 8150, epoch: 4, loss: 1.288957
global_step: 8151, epoch: 4, loss: 1.172007
global_step: 8152, epoch: 4, loss: 1.227885
global_step: 8153, epoch: 4, loss: 1.311162
global_step: 8154, epoch: 4, loss: 1.381175
global_step: 8155, epoch: 4, loss: 1.219568
global_step: 8156, epoch: 4, loss: 1.231302
global_step: 8157, epoch: 4, loss: 1.247230
global_step: 8158, epoch: 4, loss: 1.273112
global_step: 8159, epoch: 4, loss: 1.200401
global_step: 8160, epoch: 4, loss: 0.295176
epoch: 4
train	acc: 0.5983	macro: p 0.3451, r 0.2865, f1: 0.2925	micro: p 0.5983, r 0.5983, f1 0.5983	weighted_f1:0.5293
dev	acc: 0.5230	macro: p 0.2771, r 0.2573, f1: 0.2462	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4405
test	acc: 0.5789	macro: p 0.3028, r 0.2632, f1: 0.2621	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5026
New best model!
global_step: 8161, epoch: 5, loss: 1.516688
global_step: 8162, epoch: 5, loss: 1.179353
global_step: 8163, epoch: 5, loss: 1.181031
global_step: 8164, epoch: 5, loss: 1.206346
global_step: 8165, epoch: 5, loss: 1.183858
global_step: 8166, epoch: 5, loss: 1.103982
global_step: 8167, epoch: 5, loss: 1.211589
global_step: 8168, epoch: 5, loss: 1.277914
global_step: 8169, epoch: 5, loss: 1.174483
global_step: 8170, epoch: 5, loss: 1.104648
global_step: 8171, epoch: 5, loss: 1.258913
global_step: 8172, epoch: 5, loss: 1.258941
global_step: 8173, epoch: 5, loss: 1.220804
global_step: 8174, epoch: 5, loss: 1.151145
global_step: 8175, epoch: 5, loss: 1.251031
global_step: 8176, epoch: 5, loss: 1.069675
global_step: 8177, epoch: 5, loss: 1.134235
global_step: 8178, epoch: 5, loss: 1.145923
global_step: 8179, epoch: 5, loss: 1.190250
global_step: 8180, epoch: 5, loss: 1.294574
global_step: 8181, epoch: 5, loss: 1.187729
global_step: 8182, epoch: 5, loss: 1.192847
global_step: 8183, epoch: 5, loss: 1.121671
global_step: 8184, epoch: 5, loss: 1.291163
global_step: 8185, epoch: 5, loss: 1.209702
global_step: 8186, epoch: 5, loss: 1.181077
global_step: 8187, epoch: 5, loss: 1.181869
global_step: 8188, epoch: 5, loss: 1.271026
global_step: 8189, epoch: 5, loss: 1.202772
global_step: 8190, epoch: 5, loss: 1.242542
global_step: 8191, epoch: 5, loss: 1.145369
global_step: 8192, epoch: 5, loss: 1.132691
global_step: 8193, epoch: 5, loss: 1.101077
global_step: 8194, epoch: 5, loss: 1.223297
global_step: 8195, epoch: 5, loss: 1.182618
global_step: 8196, epoch: 5, loss: 1.228416
global_step: 8197, epoch: 5, loss: 1.201934
global_step: 8198, epoch: 5, loss: 1.225622
global_step: 8199, epoch: 5, loss: 1.236845
global_step: 8200, epoch: 5, loss: 0.875457
epoch: 5
train	acc: 0.6153	macro: p 0.4504, r 0.3096, f1: 0.3053	micro: p 0.6153, r 0.6153, f1 0.6153	weighted_f1:0.5483
dev	acc: 0.5455	macro: p 0.4188, r 0.2867, f1: 0.2579	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4572
test	acc: 0.5835	macro: p 0.3782, r 0.2824, f1: 0.2624	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5062
New best model!
global_step: 8201, epoch: 6, loss: 1.170043
global_step: 8202, epoch: 6, loss: 1.110843
global_step: 8203, epoch: 6, loss: 1.122781
global_step: 8204, epoch: 6, loss: 1.165846
global_step: 8205, epoch: 6, loss: 1.249189
global_step: 8206, epoch: 6, loss: 1.212864
global_step: 8207, epoch: 6, loss: 1.101952
global_step: 8208, epoch: 6, loss: 1.139038
global_step: 8209, epoch: 6, loss: 1.098660
global_step: 8210, epoch: 6, loss: 1.168829
global_step: 8211, epoch: 6, loss: 1.201932
global_step: 8212, epoch: 6, loss: 1.086073
global_step: 8213, epoch: 6, loss: 1.019431
global_step: 8214, epoch: 6, loss: 1.239828
global_step: 8215, epoch: 6, loss: 1.084008
global_step: 8216, epoch: 6, loss: 1.241784
global_step: 8217, epoch: 6, loss: 1.197670
global_step: 8218, epoch: 6, loss: 1.196818
global_step: 8219, epoch: 6, loss: 1.164074
global_step: 8220, epoch: 6, loss: 1.142762
global_step: 8221, epoch: 6, loss: 1.074985
global_step: 8222, epoch: 6, loss: 1.160491
global_step: 8223, epoch: 6, loss: 1.144147
global_step: 8224, epoch: 6, loss: 1.243258
global_step: 8225, epoch: 6, loss: 1.174000
global_step: 8226, epoch: 6, loss: 1.125257
global_step: 8227, epoch: 6, loss: 1.203297
global_step: 8228, epoch: 6, loss: 1.151986
global_step: 8229, epoch: 6, loss: 1.160148
global_step: 8230, epoch: 6, loss: 1.148563
global_step: 8231, epoch: 6, loss: 1.292806
global_step: 8232, epoch: 6, loss: 1.191173
global_step: 8233, epoch: 6, loss: 0.997909
global_step: 8234, epoch: 6, loss: 1.195559
global_step: 8235, epoch: 6, loss: 1.119217
global_step: 8236, epoch: 6, loss: 1.235964
global_step: 8237, epoch: 6, loss: 1.226948
global_step: 8238, epoch: 6, loss: 1.138174
global_step: 8239, epoch: 6, loss: 1.176461
global_step: 8240, epoch: 6, loss: 1.615916
epoch: 6
train	acc: 0.5735	macro: p 0.3901, r 0.3934, f1: 0.3641	micro: p 0.5735, r 0.5735, f1 0.5735	weighted_f1:0.5716
dev	acc: 0.4238	macro: p 0.2917, r 0.2780, f1: 0.2543	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.4187
test	acc: 0.4556	macro: p 0.3096, r 0.3006, f1: 0.2779	micro: p 0.4556, r 0.4556, f1 0.4556	weighted_f1:0.4612
global_step: 8241, epoch: 7, loss: 1.261261
global_step: 8242, epoch: 7, loss: 1.135591
global_step: 8243, epoch: 7, loss: 1.170674
global_step: 8244, epoch: 7, loss: 1.022597
global_step: 8245, epoch: 7, loss: 1.134544
global_step: 8246, epoch: 7, loss: 1.191231
global_step: 8247, epoch: 7, loss: 1.147496
global_step: 8248, epoch: 7, loss: 1.112844
global_step: 8249, epoch: 7, loss: 1.141801
global_step: 8250, epoch: 7, loss: 1.114559
global_step: 8251, epoch: 7, loss: 1.044083
global_step: 8252, epoch: 7, loss: 1.016688
global_step: 8253, epoch: 7, loss: 1.078812
global_step: 8254, epoch: 7, loss: 1.189730
global_step: 8255, epoch: 7, loss: 1.057626
global_step: 8256, epoch: 7, loss: 1.026276
global_step: 8257, epoch: 7, loss: 1.135876
global_step: 8258, epoch: 7, loss: 1.180274
global_step: 8259, epoch: 7, loss: 1.154513
global_step: 8260, epoch: 7, loss: 1.132353
global_step: 8261, epoch: 7, loss: 1.191270
global_step: 8262, epoch: 7, loss: 1.113314
global_step: 8263, epoch: 7, loss: 1.015705
global_step: 8264, epoch: 7, loss: 1.131646
global_step: 8265, epoch: 7, loss: 1.053512
global_step: 8266, epoch: 7, loss: 1.196878
global_step: 8267, epoch: 7, loss: 1.070668
global_step: 8268, epoch: 7, loss: 1.123364
global_step: 8269, epoch: 7, loss: 1.124173
global_step: 8270, epoch: 7, loss: 1.181639
global_step: 8271, epoch: 7, loss: 1.109073
global_step: 8272, epoch: 7, loss: 1.028114
global_step: 8273, epoch: 7, loss: 1.219773
global_step: 8274, epoch: 7, loss: 1.066636
global_step: 8275, epoch: 7, loss: 1.059559
global_step: 8276, epoch: 7, loss: 1.096530
global_step: 8277, epoch: 7, loss: 1.134311
global_step: 8278, epoch: 7, loss: 1.044874
global_step: 8279, epoch: 7, loss: 1.187565
global_step: 8280, epoch: 7, loss: 0.614352
epoch: 7
train	acc: 0.6595	macro: p 0.4449, r 0.3964, f1: 0.3847	micro: p 0.6595, r 0.6595, f1 0.6595	weighted_f1:0.6261
dev	acc: 0.5338	macro: p 0.3475, r 0.3048, f1: 0.2943	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4870
test	acc: 0.5904	macro: p 0.3720, r 0.3262, f1: 0.3174	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5532
New best model!
global_step: 8281, epoch: 8, loss: 1.125660
global_step: 8282, epoch: 8, loss: 0.988334
global_step: 8283, epoch: 8, loss: 0.971472
global_step: 8284, epoch: 8, loss: 1.084594
global_step: 8285, epoch: 8, loss: 1.098552
global_step: 8286, epoch: 8, loss: 1.028402
global_step: 8287, epoch: 8, loss: 1.004351
global_step: 8288, epoch: 8, loss: 0.967278
global_step: 8289, epoch: 8, loss: 0.970517
global_step: 8290, epoch: 8, loss: 1.016879
global_step: 8291, epoch: 8, loss: 1.218253
global_step: 8292, epoch: 8, loss: 1.147027
global_step: 8293, epoch: 8, loss: 1.048175
global_step: 8294, epoch: 8, loss: 0.993356
global_step: 8295, epoch: 8, loss: 1.046788
global_step: 8296, epoch: 8, loss: 1.037234
global_step: 8297, epoch: 8, loss: 1.207904
global_step: 8298, epoch: 8, loss: 1.108953
global_step: 8299, epoch: 8, loss: 1.055527
global_step: 8300, epoch: 8, loss: 1.028255
global_step: 8301, epoch: 8, loss: 1.179288
global_step: 8302, epoch: 8, loss: 1.033435
global_step: 8303, epoch: 8, loss: 1.142150
global_step: 8304, epoch: 8, loss: 1.032164
global_step: 8305, epoch: 8, loss: 1.051589
global_step: 8306, epoch: 8, loss: 1.102850
global_step: 8307, epoch: 8, loss: 1.089230
global_step: 8308, epoch: 8, loss: 1.116535
global_step: 8309, epoch: 8, loss: 1.010248
global_step: 8310, epoch: 8, loss: 1.117580
global_step: 8311, epoch: 8, loss: 1.093578
global_step: 8312, epoch: 8, loss: 1.177250
global_step: 8313, epoch: 8, loss: 1.080358
global_step: 8314, epoch: 8, loss: 1.034082
global_step: 8315, epoch: 8, loss: 1.128061
global_step: 8316, epoch: 8, loss: 1.175393
global_step: 8317, epoch: 8, loss: 1.171914
global_step: 8318, epoch: 8, loss: 1.049880
global_step: 8319, epoch: 8, loss: 1.249618
global_step: 8320, epoch: 8, loss: 1.306864
epoch: 8
train	acc: 0.7161	macro: p 0.6184, r 0.4550, f1: 0.4514	micro: p 0.7161, r 0.7161, f1 0.7161	weighted_f1:0.6867
dev	acc: 0.5329	macro: p 0.3253, r 0.3105, f1: 0.2908	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4841
test	acc: 0.5766	macro: p 0.3388, r 0.3211, f1: 0.3084	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5395
global_step: 8321, epoch: 9, loss: 1.037563
global_step: 8322, epoch: 9, loss: 0.990445
global_step: 8323, epoch: 9, loss: 0.956961
global_step: 8324, epoch: 9, loss: 1.139923
global_step: 8325, epoch: 9, loss: 1.011236
global_step: 8326, epoch: 9, loss: 1.009737
global_step: 8327, epoch: 9, loss: 0.949162
global_step: 8328, epoch: 9, loss: 1.103314
global_step: 8329, epoch: 9, loss: 1.057161
global_step: 8330, epoch: 9, loss: 0.985676
global_step: 8331, epoch: 9, loss: 1.088060
global_step: 8332, epoch: 9, loss: 1.065818
global_step: 8333, epoch: 9, loss: 1.027649
global_step: 8334, epoch: 9, loss: 1.108032
global_step: 8335, epoch: 9, loss: 0.965904
global_step: 8336, epoch: 9, loss: 1.035268
global_step: 8337, epoch: 9, loss: 1.045086
global_step: 8338, epoch: 9, loss: 0.954558
global_step: 8339, epoch: 9, loss: 0.948302
global_step: 8340, epoch: 9, loss: 1.069892
global_step: 8341, epoch: 9, loss: 0.944038
global_step: 8342, epoch: 9, loss: 1.069929
global_step: 8343, epoch: 9, loss: 1.078528
global_step: 8344, epoch: 9, loss: 0.992447
global_step: 8345, epoch: 9, loss: 1.109074
global_step: 8346, epoch: 9, loss: 0.966712
global_step: 8347, epoch: 9, loss: 1.045678
global_step: 8348, epoch: 9, loss: 1.041021
global_step: 8349, epoch: 9, loss: 1.142308
global_step: 8350, epoch: 9, loss: 1.156745
global_step: 8351, epoch: 9, loss: 1.009627
global_step: 8352, epoch: 9, loss: 1.078954
global_step: 8353, epoch: 9, loss: 1.075640
global_step: 8354, epoch: 9, loss: 1.078462
global_step: 8355, epoch: 9, loss: 1.119577
global_step: 8356, epoch: 9, loss: 0.963495
global_step: 8357, epoch: 9, loss: 1.095070
global_step: 8358, epoch: 9, loss: 1.119893
global_step: 8359, epoch: 9, loss: 1.007118
global_step: 8360, epoch: 9, loss: 0.447825
epoch: 9
train	acc: 0.6735	macro: p 0.6237, r 0.4102, f1: 0.3998	micro: p 0.6735, r 0.6735, f1 0.6735	weighted_f1:0.6333
dev	acc: 0.5338	macro: p 0.3747, r 0.3063, f1: 0.2909	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4808
test	acc: 0.5847	macro: p 0.3725, r 0.3249, f1: 0.3078	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5417
global_step: 8361, epoch: 10, loss: 1.161728
global_step: 8362, epoch: 10, loss: 0.843707
global_step: 8363, epoch: 10, loss: 1.031377
global_step: 8364, epoch: 10, loss: 1.051253
global_step: 8365, epoch: 10, loss: 0.998935
global_step: 8366, epoch: 10, loss: 0.915037
global_step: 8367, epoch: 10, loss: 0.950680
global_step: 8368, epoch: 10, loss: 1.058750
global_step: 8369, epoch: 10, loss: 1.081610
global_step: 8370, epoch: 10, loss: 1.025564
global_step: 8371, epoch: 10, loss: 1.056430
global_step: 8372, epoch: 10, loss: 1.097996
global_step: 8373, epoch: 10, loss: 1.001812
global_step: 8374, epoch: 10, loss: 1.036289
global_step: 8375, epoch: 10, loss: 0.988689
global_step: 8376, epoch: 10, loss: 0.913764
global_step: 8377, epoch: 10, loss: 0.868030
global_step: 8378, epoch: 10, loss: 1.124379
global_step: 8379, epoch: 10, loss: 0.888611
global_step: 8380, epoch: 10, loss: 0.885214
global_step: 8381, epoch: 10, loss: 0.955510
global_step: 8382, epoch: 10, loss: 1.059687
global_step: 8383, epoch: 10, loss: 1.020862
global_step: 8384, epoch: 10, loss: 1.004164
global_step: 8385, epoch: 10, loss: 0.979221
global_step: 8386, epoch: 10, loss: 1.011997
global_step: 8387, epoch: 10, loss: 0.976592
global_step: 8388, epoch: 10, loss: 1.010520
global_step: 8389, epoch: 10, loss: 1.073832
global_step: 8390, epoch: 10, loss: 0.864444
global_step: 8391, epoch: 10, loss: 0.880210
global_step: 8392, epoch: 10, loss: 1.013798
global_step: 8393, epoch: 10, loss: 1.009201
global_step: 8394, epoch: 10, loss: 1.050675
global_step: 8395, epoch: 10, loss: 0.970586
global_step: 8396, epoch: 10, loss: 1.053984
global_step: 8397, epoch: 10, loss: 1.025893
global_step: 8398, epoch: 10, loss: 0.905507
global_step: 8399, epoch: 10, loss: 1.094669
global_step: 8400, epoch: 10, loss: 0.971539
epoch: 10
train	acc: 0.6986	macro: p 0.6582, r 0.4189, f1: 0.4307	micro: p 0.6986, r 0.6986, f1 0.6986	weighted_f1:0.6566
dev	acc: 0.5509	macro: p 0.4034, r 0.2978, f1: 0.2910	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4866
test	acc: 0.6000	macro: p 0.3847, r 0.3065, f1: 0.3064	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5445
global_step: 8401, epoch: 11, loss: 0.903532
global_step: 8402, epoch: 11, loss: 0.880935
global_step: 8403, epoch: 11, loss: 0.962752
global_step: 8404, epoch: 11, loss: 0.920313
global_step: 8405, epoch: 11, loss: 0.898905
global_step: 8406, epoch: 11, loss: 0.806068
global_step: 8407, epoch: 11, loss: 0.931287
global_step: 8408, epoch: 11, loss: 0.932257
global_step: 8409, epoch: 11, loss: 1.058294
global_step: 8410, epoch: 11, loss: 0.914763
global_step: 8411, epoch: 11, loss: 1.053791
global_step: 8412, epoch: 11, loss: 0.865334
global_step: 8413, epoch: 11, loss: 0.828927
global_step: 8414, epoch: 11, loss: 1.007783
global_step: 8415, epoch: 11, loss: 0.822823
global_step: 8416, epoch: 11, loss: 1.135445
global_step: 8417, epoch: 11, loss: 1.021792
global_step: 8418, epoch: 11, loss: 0.919192
global_step: 8419, epoch: 11, loss: 0.917896
global_step: 8420, epoch: 11, loss: 1.051565
global_step: 8421, epoch: 11, loss: 0.922397
global_step: 8422, epoch: 11, loss: 0.963906
global_step: 8423, epoch: 11, loss: 0.997166
global_step: 8424, epoch: 11, loss: 0.972647
global_step: 8425, epoch: 11, loss: 0.836011
global_step: 8426, epoch: 11, loss: 0.991542
global_step: 8427, epoch: 11, loss: 1.065204
global_step: 8428, epoch: 11, loss: 1.094039
global_step: 8429, epoch: 11, loss: 0.938530
global_step: 8430, epoch: 11, loss: 0.957806
global_step: 8431, epoch: 11, loss: 1.023215
global_step: 8432, epoch: 11, loss: 0.881948
global_step: 8433, epoch: 11, loss: 0.971343
global_step: 8434, epoch: 11, loss: 0.943424
global_step: 8435, epoch: 11, loss: 1.145247
global_step: 8436, epoch: 11, loss: 1.021104
global_step: 8437, epoch: 11, loss: 0.999611
global_step: 8438, epoch: 11, loss: 0.975964
global_step: 8439, epoch: 11, loss: 0.977813
global_step: 8440, epoch: 11, loss: 1.044062
epoch: 11
train	acc: 0.7563	macro: p 0.6641, r 0.5143, f1: 0.5019	micro: p 0.7563, r 0.7563, f1 0.7563	weighted_f1:0.7358
dev	acc: 0.5221	macro: p 0.3225, r 0.3055, f1: 0.2919	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4842
test	acc: 0.5759	macro: p 0.3534, r 0.3370, f1: 0.3206	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5499
global_step: 8441, epoch: 12, loss: 1.046515
global_step: 8442, epoch: 12, loss: 0.956993
global_step: 8443, epoch: 12, loss: 0.866353
global_step: 8444, epoch: 12, loss: 0.907523
global_step: 8445, epoch: 12, loss: 0.804363
global_step: 8446, epoch: 12, loss: 0.904457
global_step: 8447, epoch: 12, loss: 0.802901
global_step: 8448, epoch: 12, loss: 0.769189
global_step: 8449, epoch: 12, loss: 0.785851
global_step: 8450, epoch: 12, loss: 0.780500
global_step: 8451, epoch: 12, loss: 0.943847
global_step: 8452, epoch: 12, loss: 0.890624
global_step: 8453, epoch: 12, loss: 0.754495
global_step: 8454, epoch: 12, loss: 0.967170
global_step: 8455, epoch: 12, loss: 0.954946
global_step: 8456, epoch: 12, loss: 0.814943
global_step: 8457, epoch: 12, loss: 0.875558
global_step: 8458, epoch: 12, loss: 1.018859
global_step: 8459, epoch: 12, loss: 1.002424
global_step: 8460, epoch: 12, loss: 0.993480
global_step: 8461, epoch: 12, loss: 0.947915
global_step: 8462, epoch: 12, loss: 0.846607
global_step: 8463, epoch: 12, loss: 0.964946
global_step: 8464, epoch: 12, loss: 0.995741
global_step: 8465, epoch: 12, loss: 0.872991
global_step: 8466, epoch: 12, loss: 0.977761
global_step: 8467, epoch: 12, loss: 0.954711
global_step: 8468, epoch: 12, loss: 0.890247
global_step: 8469, epoch: 12, loss: 0.810581
global_step: 8470, epoch: 12, loss: 0.999193
global_step: 8471, epoch: 12, loss: 0.920968
global_step: 8472, epoch: 12, loss: 0.814465
global_step: 8473, epoch: 12, loss: 0.929019
global_step: 8474, epoch: 12, loss: 0.874655
global_step: 8475, epoch: 12, loss: 0.985006
global_step: 8476, epoch: 12, loss: 0.913186
global_step: 8477, epoch: 12, loss: 0.928801
global_step: 8478, epoch: 12, loss: 0.930946
global_step: 8479, epoch: 12, loss: 1.004852
global_step: 8480, epoch: 12, loss: 0.352916
epoch: 12
train	acc: 0.7290	macro: p 0.8282, r 0.4479, f1: 0.4777	micro: p 0.7290, r 0.7290, f1 0.7290	weighted_f1:0.6943
dev	acc: 0.5410	macro: p 0.3778, r 0.2881, f1: 0.2777	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4734
test	acc: 0.5985	macro: p 0.3793, r 0.2979, f1: 0.2980	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5372
global_step: 8481, epoch: 13, loss: 0.876189
global_step: 8482, epoch: 13, loss: 0.757518
global_step: 8483, epoch: 13, loss: 0.992768
global_step: 8484, epoch: 13, loss: 0.878554
global_step: 8485, epoch: 13, loss: 0.810892
global_step: 8486, epoch: 13, loss: 0.859187
global_step: 8487, epoch: 13, loss: 0.886537
global_step: 8488, epoch: 13, loss: 1.003001
global_step: 8489, epoch: 13, loss: 0.949353
global_step: 8490, epoch: 13, loss: 0.826734
global_step: 8491, epoch: 13, loss: 0.965610
global_step: 8492, epoch: 13, loss: 0.860671
global_step: 8493, epoch: 13, loss: 0.894177
global_step: 8494, epoch: 13, loss: 0.885731
global_step: 8495, epoch: 13, loss: 0.826864
global_step: 8496, epoch: 13, loss: 0.967158
global_step: 8497, epoch: 13, loss: 0.902005
global_step: 8498, epoch: 13, loss: 0.797053
global_step: 8499, epoch: 13, loss: 0.936124
global_step: 8500, epoch: 13, loss: 0.911971
global_step: 8501, epoch: 13, loss: 0.954894
global_step: 8502, epoch: 13, loss: 0.976305
global_step: 8503, epoch: 13, loss: 0.888999
global_step: 8504, epoch: 13, loss: 0.906282
global_step: 8505, epoch: 13, loss: 0.878168
global_step: 8506, epoch: 13, loss: 0.855844
global_step: 8507, epoch: 13, loss: 0.838914
global_step: 8508, epoch: 13, loss: 0.948332
global_step: 8509, epoch: 13, loss: 0.943765
global_step: 8510, epoch: 13, loss: 0.832689
global_step: 8511, epoch: 13, loss: 0.904890
global_step: 8512, epoch: 13, loss: 0.913854
global_step: 8513, epoch: 13, loss: 1.093308
global_step: 8514, epoch: 13, loss: 0.838125
global_step: 8515, epoch: 13, loss: 0.841975
global_step: 8516, epoch: 13, loss: 0.928976
global_step: 8517, epoch: 13, loss: 0.843386
global_step: 8518, epoch: 13, loss: 0.890143
global_step: 8519, epoch: 13, loss: 0.938698
global_step: 8520, epoch: 13, loss: 1.540303
epoch: 13
train	acc: 0.7516	macro: p 0.7772, r 0.5777, f1: 0.5840	micro: p 0.7516, r 0.7516, f1 0.7516	weighted_f1:0.7508
dev	acc: 0.4887	macro: p 0.3445, r 0.3173, f1: 0.3017	micro: p 0.4887, r 0.4887, f1 0.4887	weighted_f1:0.4674
test	acc: 0.5153	macro: p 0.3126, r 0.3197, f1: 0.2948	micro: p 0.5153, r 0.5153, f1 0.5153	weighted_f1:0.5068
global_step: 8521, epoch: 14, loss: 1.022902
global_step: 8522, epoch: 14, loss: 0.817061
global_step: 8523, epoch: 14, loss: 0.793773
global_step: 8524, epoch: 14, loss: 0.818077
global_step: 8525, epoch: 14, loss: 0.868467
global_step: 8526, epoch: 14, loss: 0.866566
global_step: 8527, epoch: 14, loss: 0.799449
global_step: 8528, epoch: 14, loss: 0.792393
global_step: 8529, epoch: 14, loss: 0.791145
global_step: 8530, epoch: 14, loss: 0.769594
global_step: 8531, epoch: 14, loss: 0.816824
global_step: 8532, epoch: 14, loss: 0.754948
global_step: 8533, epoch: 14, loss: 0.797123
global_step: 8534, epoch: 14, loss: 0.808080
global_step: 8535, epoch: 14, loss: 0.810698
global_step: 8536, epoch: 14, loss: 0.901570
global_step: 8537, epoch: 14, loss: 0.799376
global_step: 8538, epoch: 14, loss: 0.801444
global_step: 8539, epoch: 14, loss: 0.789766
global_step: 8540, epoch: 14, loss: 0.958733
global_step: 8541, epoch: 14, loss: 0.858909
global_step: 8542, epoch: 14, loss: 0.845302
global_step: 8543, epoch: 14, loss: 0.832561
global_step: 8544, epoch: 14, loss: 0.837984
global_step: 8545, epoch: 14, loss: 0.903336
global_step: 8546, epoch: 14, loss: 0.881217
global_step: 8547, epoch: 14, loss: 0.836142
global_step: 8548, epoch: 14, loss: 0.830766
global_step: 8549, epoch: 14, loss: 0.906787
global_step: 8550, epoch: 14, loss: 0.879613
global_step: 8551, epoch: 14, loss: 0.832896
global_step: 8552, epoch: 14, loss: 0.906458
global_step: 8553, epoch: 14, loss: 0.703942
global_step: 8554, epoch: 14, loss: 0.854159
global_step: 8555, epoch: 14, loss: 0.776467
global_step: 8556, epoch: 14, loss: 0.870092
global_step: 8557, epoch: 14, loss: 0.866443
global_step: 8558, epoch: 14, loss: 0.773824
global_step: 8559, epoch: 14, loss: 0.956842
global_step: 8560, epoch: 14, loss: 1.167172
epoch: 14
train	acc: 0.8120	macro: p 0.8201, r 0.6010, f1: 0.6114	micro: p 0.8120, r 0.8120, f1 0.8120	weighted_f1:0.8018
dev	acc: 0.5203	macro: p 0.3299, r 0.3103, f1: 0.3062	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4925
test	acc: 0.5720	macro: p 0.3601, r 0.3295, f1: 0.3288	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5509
New best model!
global_step: 8561, epoch: 15, loss: 0.891466
global_step: 8562, epoch: 15, loss: 0.716606
global_step: 8563, epoch: 15, loss: 0.811946
global_step: 8564, epoch: 15, loss: 0.746035
global_step: 8565, epoch: 15, loss: 0.861345
global_step: 8566, epoch: 15, loss: 0.795721
global_step: 8567, epoch: 15, loss: 0.742140
global_step: 8568, epoch: 15, loss: 0.721571
global_step: 8569, epoch: 15, loss: 0.716129
global_step: 8570, epoch: 15, loss: 0.710231
global_step: 8571, epoch: 15, loss: 0.688337
global_step: 8572, epoch: 15, loss: 0.740834
global_step: 8573, epoch: 15, loss: 0.776846
global_step: 8574, epoch: 15, loss: 0.801230
global_step: 8575, epoch: 15, loss: 0.707217
global_step: 8576, epoch: 15, loss: 0.861203
global_step: 8577, epoch: 15, loss: 0.847741
global_step: 8578, epoch: 15, loss: 0.659069
global_step: 8579, epoch: 15, loss: 0.885696
global_step: 8580, epoch: 15, loss: 0.776306
global_step: 8581, epoch: 15, loss: 0.719246
global_step: 8582, epoch: 15, loss: 0.761708
global_step: 8583, epoch: 15, loss: 0.844409
global_step: 8584, epoch: 15, loss: 0.801457
global_step: 8585, epoch: 15, loss: 0.858178
global_step: 8586, epoch: 15, loss: 0.865777
global_step: 8587, epoch: 15, loss: 0.906959
global_step: 8588, epoch: 15, loss: 0.744010
global_step: 8589, epoch: 15, loss: 0.874993
global_step: 8590, epoch: 15, loss: 0.747868
global_step: 8591, epoch: 15, loss: 0.933722
global_step: 8592, epoch: 15, loss: 0.722858
global_step: 8593, epoch: 15, loss: 0.843660
global_step: 8594, epoch: 15, loss: 0.971129
global_step: 8595, epoch: 15, loss: 0.871437
global_step: 8596, epoch: 15, loss: 0.904806
global_step: 8597, epoch: 15, loss: 0.827696
global_step: 8598, epoch: 15, loss: 0.853172
global_step: 8599, epoch: 15, loss: 0.776476
global_step: 8600, epoch: 15, loss: 0.419660
epoch: 15
train	acc: 0.7654	macro: p 0.8677, r 0.5081, f1: 0.5554	micro: p 0.7654, r 0.7654, f1 0.7654	weighted_f1:0.7345
dev	acc: 0.5383	macro: p 0.3780, r 0.2838, f1: 0.2690	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4642
test	acc: 0.5954	macro: p 0.4046, r 0.2929, f1: 0.2901	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5286
global_step: 8601, epoch: 16, loss: 0.791369
global_step: 8602, epoch: 16, loss: 0.781514
global_step: 8603, epoch: 16, loss: 0.765824
global_step: 8604, epoch: 16, loss: 0.745381
global_step: 8605, epoch: 16, loss: 0.767330
global_step: 8606, epoch: 16, loss: 0.755058
global_step: 8607, epoch: 16, loss: 0.750623
global_step: 8608, epoch: 16, loss: 0.745956
global_step: 8609, epoch: 16, loss: 0.756684
global_step: 8610, epoch: 16, loss: 0.777732
global_step: 8611, epoch: 16, loss: 0.749327
global_step: 8612, epoch: 16, loss: 0.874425
global_step: 8613, epoch: 16, loss: 0.827296
global_step: 8614, epoch: 16, loss: 0.744667
global_step: 8615, epoch: 16, loss: 0.758442
global_step: 8616, epoch: 16, loss: 0.728282
global_step: 8617, epoch: 16, loss: 0.756144
global_step: 8618, epoch: 16, loss: 0.819062
global_step: 8619, epoch: 16, loss: 0.739555
global_step: 8620, epoch: 16, loss: 0.768239
global_step: 8621, epoch: 16, loss: 0.714386
global_step: 8622, epoch: 16, loss: 0.701931
global_step: 8623, epoch: 16, loss: 0.826487
global_step: 8624, epoch: 16, loss: 0.831296
global_step: 8625, epoch: 16, loss: 0.759300
global_step: 8626, epoch: 16, loss: 0.851297
global_step: 8627, epoch: 16, loss: 0.611146
global_step: 8628, epoch: 16, loss: 0.764671
global_step: 8629, epoch: 16, loss: 0.798946
global_step: 8630, epoch: 16, loss: 0.730642
global_step: 8631, epoch: 16, loss: 0.893254
global_step: 8632, epoch: 16, loss: 0.828783
global_step: 8633, epoch: 16, loss: 0.741387
global_step: 8634, epoch: 16, loss: 0.789746
global_step: 8635, epoch: 16, loss: 0.866749
global_step: 8636, epoch: 16, loss: 0.701393
global_step: 8637, epoch: 16, loss: 0.846360
global_step: 8638, epoch: 16, loss: 0.900783
global_step: 8639, epoch: 16, loss: 0.703902
global_step: 8640, epoch: 16, loss: 0.670656
epoch: 16
train	acc: 0.7579	macro: p 0.8195, r 0.5411, f1: 0.5742	micro: p 0.7579, r 0.7579, f1 0.7579	weighted_f1:0.7525
dev	acc: 0.4445	macro: p 0.3075, r 0.2633, f1: 0.2396	micro: p 0.4445, r 0.4445, f1 0.4445	weighted_f1:0.4168
test	acc: 0.5080	macro: p 0.3538, r 0.2857, f1: 0.2698	micro: p 0.5080, r 0.5080, f1 0.5080	weighted_f1:0.4890
global_step: 8641, epoch: 17, loss: 0.872065
global_step: 8642, epoch: 17, loss: 0.709658
global_step: 8643, epoch: 17, loss: 0.586093
global_step: 8644, epoch: 17, loss: 0.726920
global_step: 8645, epoch: 17, loss: 0.728719
global_step: 8646, epoch: 17, loss: 0.784481
global_step: 8647, epoch: 17, loss: 0.683881
global_step: 8648, epoch: 17, loss: 0.770737
global_step: 8649, epoch: 17, loss: 0.776515
global_step: 8650, epoch: 17, loss: 0.831092
global_step: 8651, epoch: 17, loss: 0.791399
global_step: 8652, epoch: 17, loss: 0.705932
global_step: 8653, epoch: 17, loss: 0.615001
global_step: 8654, epoch: 17, loss: 0.690183
global_step: 8655, epoch: 17, loss: 0.712880
global_step: 8656, epoch: 17, loss: 0.586399
global_step: 8657, epoch: 17, loss: 0.764607
global_step: 8658, epoch: 17, loss: 0.649555
global_step: 8659, epoch: 17, loss: 0.812295
global_step: 8660, epoch: 17, loss: 0.780953
global_step: 8661, epoch: 17, loss: 0.838551
global_step: 8662, epoch: 17, loss: 0.780549
global_step: 8663, epoch: 17, loss: 0.687268
global_step: 8664, epoch: 17, loss: 0.763826
global_step: 8665, epoch: 17, loss: 0.730992
global_step: 8666, epoch: 17, loss: 0.650991
global_step: 8667, epoch: 17, loss: 0.815814
global_step: 8668, epoch: 17, loss: 0.797863
global_step: 8669, epoch: 17, loss: 0.747275
global_step: 8670, epoch: 17, loss: 0.695585
global_step: 8671, epoch: 17, loss: 0.763650
global_step: 8672, epoch: 17, loss: 0.626377
global_step: 8673, epoch: 17, loss: 0.675027
global_step: 8674, epoch: 17, loss: 0.756517
global_step: 8675, epoch: 17, loss: 0.777817
global_step: 8676, epoch: 17, loss: 0.755838
global_step: 8677, epoch: 17, loss: 0.693488
global_step: 8678, epoch: 17, loss: 0.657160
global_step: 8679, epoch: 17, loss: 0.680447
global_step: 8680, epoch: 17, loss: 0.290134
epoch: 17
train	acc: 0.8368	macro: p 0.8756, r 0.6821, f1: 0.7240	micro: p 0.8368, r 0.8368, f1 0.8368	weighted_f1:0.8329
dev	acc: 0.4977	macro: p 0.3327, r 0.3007, f1: 0.2818	micro: p 0.4977, r 0.4977, f1 0.4977	weighted_f1:0.4664
test	acc: 0.5368	macro: p 0.3313, r 0.3094, f1: 0.2927	micro: p 0.5368, r 0.5368, f1 0.5368	weighted_f1:0.5136
global_step: 8681, epoch: 18, loss: 0.765889
global_step: 8682, epoch: 18, loss: 0.601100
global_step: 8683, epoch: 18, loss: 0.616539
global_step: 8684, epoch: 18, loss: 0.791571
global_step: 8685, epoch: 18, loss: 0.640067
global_step: 8686, epoch: 18, loss: 0.718254
global_step: 8687, epoch: 18, loss: 0.701203
global_step: 8688, epoch: 18, loss: 0.649155
global_step: 8689, epoch: 18, loss: 0.668560
global_step: 8690, epoch: 18, loss: 0.720699
global_step: 8691, epoch: 18, loss: 0.696347
global_step: 8692, epoch: 18, loss: 0.747756
global_step: 8693, epoch: 18, loss: 0.635009
global_step: 8694, epoch: 18, loss: 0.746444
global_step: 8695, epoch: 18, loss: 0.564081
global_step: 8696, epoch: 18, loss: 0.672900
global_step: 8697, epoch: 18, loss: 0.686125
global_step: 8698, epoch: 18, loss: 0.628074
global_step: 8699, epoch: 18, loss: 0.652065
global_step: 8700, epoch: 18, loss: 0.764495
global_step: 8701, epoch: 18, loss: 0.675703
global_step: 8702, epoch: 18, loss: 0.682305
global_step: 8703, epoch: 18, loss: 0.795640
global_step: 8704, epoch: 18, loss: 0.671700
global_step: 8705, epoch: 18, loss: 0.664915
global_step: 8706, epoch: 18, loss: 0.723653
global_step: 8707, epoch: 18, loss: 0.760388
global_step: 8708, epoch: 18, loss: 0.819743
global_step: 8709, epoch: 18, loss: 0.647729
global_step: 8710, epoch: 18, loss: 0.711263
global_step: 8711, epoch: 18, loss: 0.649561
global_step: 8712, epoch: 18, loss: 0.716630
global_step: 8713, epoch: 18, loss: 0.670298
global_step: 8714, epoch: 18, loss: 0.708282
global_step: 8715, epoch: 18, loss: 0.763442
global_step: 8716, epoch: 18, loss: 0.786009
global_step: 8717, epoch: 18, loss: 0.808737
global_step: 8718, epoch: 18, loss: 0.732615
global_step: 8719, epoch: 18, loss: 0.607827
global_step: 8720, epoch: 18, loss: 1.488510
epoch: 18
train	acc: 0.8467	macro: p 0.8497, r 0.7493, f1: 0.7622	micro: p 0.8467, r 0.8467, f1 0.8467	weighted_f1:0.8470
dev	acc: 0.4680	macro: p 0.4263, r 0.3118, f1: 0.2931	micro: p 0.4680, r 0.4680, f1 0.4680	weighted_f1:0.4556
test	acc: 0.5126	macro: p 0.3148, r 0.3389, f1: 0.3115	micro: p 0.5126, r 0.5126, f1 0.5126	weighted_f1:0.5115
global_step: 8721, epoch: 19, loss: 0.769460
global_step: 8722, epoch: 19, loss: 0.673560
global_step: 8723, epoch: 19, loss: 0.742366
global_step: 8724, epoch: 19, loss: 0.645776
global_step: 8725, epoch: 19, loss: 0.699399
global_step: 8726, epoch: 19, loss: 0.658084
global_step: 8727, epoch: 19, loss: 0.779822
global_step: 8728, epoch: 19, loss: 0.569468
global_step: 8729, epoch: 19, loss: 0.727343
global_step: 8730, epoch: 19, loss: 0.626547
global_step: 8731, epoch: 19, loss: 0.629508
global_step: 8732, epoch: 19, loss: 0.668492
global_step: 8733, epoch: 19, loss: 0.658309
global_step: 8734, epoch: 19, loss: 0.617418
global_step: 8735, epoch: 19, loss: 0.629700
global_step: 8736, epoch: 19, loss: 0.619457
global_step: 8737, epoch: 19, loss: 0.732452
global_step: 8738, epoch: 19, loss: 0.642167
global_step: 8739, epoch: 19, loss: 0.742011
global_step: 8740, epoch: 19, loss: 0.767745
global_step: 8741, epoch: 19, loss: 0.571729
global_step: 8742, epoch: 19, loss: 0.556034
global_step: 8743, epoch: 19, loss: 0.615619
global_step: 8744, epoch: 19, loss: 0.777804
global_step: 8745, epoch: 19, loss: 0.637674
global_step: 8746, epoch: 19, loss: 0.667755
global_step: 8747, epoch: 19, loss: 0.717880
global_step: 8748, epoch: 19, loss: 0.614396
global_step: 8749, epoch: 19, loss: 0.654384
global_step: 8750, epoch: 19, loss: 0.577567
global_step: 8751, epoch: 19, loss: 0.736339
global_step: 8752, epoch: 19, loss: 0.703565
global_step: 8753, epoch: 19, loss: 0.705505
global_step: 8754, epoch: 19, loss: 0.668620
global_step: 8755, epoch: 19, loss: 0.639962
global_step: 8756, epoch: 19, loss: 0.676191
global_step: 8757, epoch: 19, loss: 0.774870
global_step: 8758, epoch: 19, loss: 0.831315
global_step: 8759, epoch: 19, loss: 0.662824
global_step: 8760, epoch: 19, loss: 1.172239
epoch: 19
train	acc: 0.8842	macro: p 0.9016, r 0.7782, f1: 0.8257	micro: p 0.8842, r 0.8842, f1 0.8842	weighted_f1:0.8811
dev	acc: 0.5428	macro: p 0.3355, r 0.3038, f1: 0.3010	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4928
test	acc: 0.5870	macro: p 0.3751, r 0.3165, f1: 0.3245	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5464
New best model!
global_step: 8761, epoch: 20, loss: 0.623892
global_step: 8762, epoch: 20, loss: 0.636964
global_step: 8763, epoch: 20, loss: 0.611368
global_step: 8764, epoch: 20, loss: 0.577251
global_step: 8765, epoch: 20, loss: 0.563391
global_step: 8766, epoch: 20, loss: 0.680019
global_step: 8767, epoch: 20, loss: 0.615881
global_step: 8768, epoch: 20, loss: 0.604738
global_step: 8769, epoch: 20, loss: 0.669244
global_step: 8770, epoch: 20, loss: 0.754255
global_step: 8771, epoch: 20, loss: 0.526865
global_step: 8772, epoch: 20, loss: 0.617196
global_step: 8773, epoch: 20, loss: 0.601946
global_step: 8774, epoch: 20, loss: 0.661180
global_step: 8775, epoch: 20, loss: 0.601463
global_step: 8776, epoch: 20, loss: 0.644285
global_step: 8777, epoch: 20, loss: 0.680401
global_step: 8778, epoch: 20, loss: 0.562989
global_step: 8779, epoch: 20, loss: 0.572855
global_step: 8780, epoch: 20, loss: 0.695838
global_step: 8781, epoch: 20, loss: 0.659033
global_step: 8782, epoch: 20, loss: 0.549927
global_step: 8783, epoch: 20, loss: 0.651143
global_step: 8784, epoch: 20, loss: 0.642209
global_step: 8785, epoch: 20, loss: 0.640873
global_step: 8786, epoch: 20, loss: 0.656232
global_step: 8787, epoch: 20, loss: 0.646438
global_step: 8788, epoch: 20, loss: 0.726071
global_step: 8789, epoch: 20, loss: 0.663032
global_step: 8790, epoch: 20, loss: 0.690531
global_step: 8791, epoch: 20, loss: 0.678617
global_step: 8792, epoch: 20, loss: 0.789500
global_step: 8793, epoch: 20, loss: 0.666005
global_step: 8794, epoch: 20, loss: 0.697438
global_step: 8795, epoch: 20, loss: 0.609802
global_step: 8796, epoch: 20, loss: 0.843645
global_step: 8797, epoch: 20, loss: 0.763797
global_step: 8798, epoch: 20, loss: 0.557639
global_step: 8799, epoch: 20, loss: 0.647465
global_step: 8800, epoch: 20, loss: 0.600747
epoch: 20
train	acc: 0.8844	macro: p 0.8953, r 0.7737, f1: 0.8114	micro: p 0.8844, r 0.8844, f1 0.8844	weighted_f1:0.8809
dev	acc: 0.5392	macro: p 0.4239, r 0.3196, f1: 0.3079	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4957
test	acc: 0.5693	macro: p 0.4582, r 0.3227, f1: 0.3148	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5363
New best model!
global_step: 8801, epoch: 21, loss: 0.654015
global_step: 8802, epoch: 21, loss: 0.694051
global_step: 8803, epoch: 21, loss: 0.575595
global_step: 8804, epoch: 21, loss: 0.555079
global_step: 8805, epoch: 21, loss: 0.448146
global_step: 8806, epoch: 21, loss: 0.634885
global_step: 8807, epoch: 21, loss: 0.642130
global_step: 8808, epoch: 21, loss: 0.560602
global_step: 8809, epoch: 21, loss: 0.597510
global_step: 8810, epoch: 21, loss: 0.574045
global_step: 8811, epoch: 21, loss: 0.569770
global_step: 8812, epoch: 21, loss: 0.555461
global_step: 8813, epoch: 21, loss: 0.607708
global_step: 8814, epoch: 21, loss: 0.681563
global_step: 8815, epoch: 21, loss: 0.627866
global_step: 8816, epoch: 21, loss: 0.673074
global_step: 8817, epoch: 21, loss: 0.678739
global_step: 8818, epoch: 21, loss: 0.642280
global_step: 8819, epoch: 21, loss: 0.607974
global_step: 8820, epoch: 21, loss: 0.664827
global_step: 8821, epoch: 21, loss: 0.670501
global_step: 8822, epoch: 21, loss: 0.697369
global_step: 8823, epoch: 21, loss: 0.647546
global_step: 8824, epoch: 21, loss: 0.598875
global_step: 8825, epoch: 21, loss: 0.641829
global_step: 8826, epoch: 21, loss: 0.581809
global_step: 8827, epoch: 21, loss: 0.595611
global_step: 8828, epoch: 21, loss: 0.593877
global_step: 8829, epoch: 21, loss: 0.589306
global_step: 8830, epoch: 21, loss: 0.676730
global_step: 8831, epoch: 21, loss: 0.529879
global_step: 8832, epoch: 21, loss: 0.622739
global_step: 8833, epoch: 21, loss: 0.696502
global_step: 8834, epoch: 21, loss: 0.606637
global_step: 8835, epoch: 21, loss: 0.582891
global_step: 8836, epoch: 21, loss: 0.660938
global_step: 8837, epoch: 21, loss: 0.519154
global_step: 8838, epoch: 21, loss: 0.658597
global_step: 8839, epoch: 21, loss: 0.680216
global_step: 8840, epoch: 21, loss: 0.443184
epoch: 21
train	acc: 0.8830	macro: p 0.8938, r 0.7616, f1: 0.7984	micro: p 0.8830, r 0.8830, f1 0.8830	weighted_f1:0.8801
dev	acc: 0.5221	macro: p 0.4894, r 0.3055, f1: 0.2999	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4869
test	acc: 0.5759	macro: p 0.3840, r 0.3308, f1: 0.3289	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5492
global_step: 8841, epoch: 22, loss: 0.606947
global_step: 8842, epoch: 22, loss: 0.631399
global_step: 8843, epoch: 22, loss: 0.553656
global_step: 8844, epoch: 22, loss: 0.528290
global_step: 8845, epoch: 22, loss: 0.483859
global_step: 8846, epoch: 22, loss: 0.612590
global_step: 8847, epoch: 22, loss: 0.552659
global_step: 8848, epoch: 22, loss: 0.532516
global_step: 8849, epoch: 22, loss: 0.454730
global_step: 8850, epoch: 22, loss: 0.587697
global_step: 8851, epoch: 22, loss: 0.562717
global_step: 8852, epoch: 22, loss: 0.561049
global_step: 8853, epoch: 22, loss: 0.616623
global_step: 8854, epoch: 22, loss: 0.495005
global_step: 8855, epoch: 22, loss: 0.681948
global_step: 8856, epoch: 22, loss: 0.639751
global_step: 8857, epoch: 22, loss: 0.604367
global_step: 8858, epoch: 22, loss: 0.598255
global_step: 8859, epoch: 22, loss: 0.557688
global_step: 8860, epoch: 22, loss: 0.626359
global_step: 8861, epoch: 22, loss: 0.539663
global_step: 8862, epoch: 22, loss: 0.572267
global_step: 8863, epoch: 22, loss: 0.657108
global_step: 8864, epoch: 22, loss: 0.540946
global_step: 8865, epoch: 22, loss: 0.622450
global_step: 8866, epoch: 22, loss: 0.587781
global_step: 8867, epoch: 22, loss: 0.539116
global_step: 8868, epoch: 22, loss: 0.474659
global_step: 8869, epoch: 22, loss: 0.638106
global_step: 8870, epoch: 22, loss: 0.634722
global_step: 8871, epoch: 22, loss: 0.610182
global_step: 8872, epoch: 22, loss: 0.555457
global_step: 8873, epoch: 22, loss: 0.698481
global_step: 8874, epoch: 22, loss: 0.669579
global_step: 8875, epoch: 22, loss: 0.585374
global_step: 8876, epoch: 22, loss: 0.570464
global_step: 8877, epoch: 22, loss: 0.600804
global_step: 8878, epoch: 22, loss: 0.549454
global_step: 8879, epoch: 22, loss: 0.595709
global_step: 8880, epoch: 22, loss: 0.468770
epoch: 22
train	acc: 0.8532	macro: p 0.9193, r 0.6884, f1: 0.7574	micro: p 0.8532, r 0.8532, f1 0.8532	weighted_f1:0.8451
dev	acc: 0.5266	macro: p 0.3672, r 0.2741, f1: 0.2726	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4528
test	acc: 0.5762	macro: p 0.3470, r 0.2784, f1: 0.2809	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5074
global_step: 8881, epoch: 23, loss: 0.814525
global_step: 8882, epoch: 23, loss: 0.551162
global_step: 8883, epoch: 23, loss: 0.508206
global_step: 8884, epoch: 23, loss: 0.603896
global_step: 8885, epoch: 23, loss: 0.510873
global_step: 8886, epoch: 23, loss: 0.613805
global_step: 8887, epoch: 23, loss: 0.527051
global_step: 8888, epoch: 23, loss: 0.549027
global_step: 8889, epoch: 23, loss: 0.440042
global_step: 8890, epoch: 23, loss: 0.506179
global_step: 8891, epoch: 23, loss: 0.626513
global_step: 8892, epoch: 23, loss: 0.622949
global_step: 8893, epoch: 23, loss: 0.555999
global_step: 8894, epoch: 23, loss: 0.581883
global_step: 8895, epoch: 23, loss: 0.567981
global_step: 8896, epoch: 23, loss: 0.510309
global_step: 8897, epoch: 23, loss: 0.550372
global_step: 8898, epoch: 23, loss: 0.593594
global_step: 8899, epoch: 23, loss: 0.565189
global_step: 8900, epoch: 23, loss: 0.580050
global_step: 8901, epoch: 23, loss: 0.558655
global_step: 8902, epoch: 23, loss: 0.491644
global_step: 8903, epoch: 23, loss: 0.664490
global_step: 8904, epoch: 23, loss: 0.507636
global_step: 8905, epoch: 23, loss: 0.593528
global_step: 8906, epoch: 23, loss: 0.506588
global_step: 8907, epoch: 23, loss: 0.597949
global_step: 8908, epoch: 23, loss: 0.659373
global_step: 8909, epoch: 23, loss: 0.565551
global_step: 8910, epoch: 23, loss: 0.577356
global_step: 8911, epoch: 23, loss: 0.521386
global_step: 8912, epoch: 23, loss: 0.549044
global_step: 8913, epoch: 23, loss: 0.515215
global_step: 8914, epoch: 23, loss: 0.626213
global_step: 8915, epoch: 23, loss: 0.592659
global_step: 8916, epoch: 23, loss: 0.512932
global_step: 8917, epoch: 23, loss: 0.575500
global_step: 8918, epoch: 23, loss: 0.562998
global_step: 8919, epoch: 23, loss: 0.728583
global_step: 8920, epoch: 23, loss: 0.818440
epoch: 23
train	acc: 0.8434	macro: p 0.9137, r 0.6815, f1: 0.7547	micro: p 0.8434, r 0.8434, f1 0.8434	weighted_f1:0.8345
dev	acc: 0.5311	macro: p 0.3784, r 0.2726, f1: 0.2681	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4584
test	acc: 0.5908	macro: p 0.3667, r 0.2845, f1: 0.2903	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5256
global_step: 8921, epoch: 24, loss: 0.845528
global_step: 8922, epoch: 24, loss: 0.678277
global_step: 8923, epoch: 24, loss: 0.541423
global_step: 8924, epoch: 24, loss: 0.569937
global_step: 8925, epoch: 24, loss: 0.523789
global_step: 8926, epoch: 24, loss: 0.555481
global_step: 8927, epoch: 24, loss: 0.559113
global_step: 8928, epoch: 24, loss: 0.557373
global_step: 8929, epoch: 24, loss: 0.581797
global_step: 8930, epoch: 24, loss: 0.551805
global_step: 8931, epoch: 24, loss: 0.559841
global_step: 8932, epoch: 24, loss: 0.535500
global_step: 8933, epoch: 24, loss: 0.498690
global_step: 8934, epoch: 24, loss: 0.477666
global_step: 8935, epoch: 24, loss: 0.477038
global_step: 8936, epoch: 24, loss: 0.584442
global_step: 8937, epoch: 24, loss: 0.482322
global_step: 8938, epoch: 24, loss: 0.540529
global_step: 8939, epoch: 24, loss: 0.537290
global_step: 8940, epoch: 24, loss: 0.521212
global_step: 8941, epoch: 24, loss: 0.560067
global_step: 8942, epoch: 24, loss: 0.541434
global_step: 8943, epoch: 24, loss: 0.543601
global_step: 8944, epoch: 24, loss: 0.421306
global_step: 8945, epoch: 24, loss: 0.493345
global_step: 8946, epoch: 24, loss: 0.658139
global_step: 8947, epoch: 24, loss: 0.567102
global_step: 8948, epoch: 24, loss: 0.524556
global_step: 8949, epoch: 24, loss: 0.502071
global_step: 8950, epoch: 24, loss: 0.545770
global_step: 8951, epoch: 24, loss: 0.455660
global_step: 8952, epoch: 24, loss: 0.577100
global_step: 8953, epoch: 24, loss: 0.525399
global_step: 8954, epoch: 24, loss: 0.679647
global_step: 8955, epoch: 24, loss: 0.632543
global_step: 8956, epoch: 24, loss: 0.473065
global_step: 8957, epoch: 24, loss: 0.592363
global_step: 8958, epoch: 24, loss: 0.628722
global_step: 8959, epoch: 24, loss: 0.593888
global_step: 8960, epoch: 24, loss: 0.612537
epoch: 24
train	acc: 0.9105	macro: p 0.9304, r 0.8356, f1: 0.8744	micro: p 0.9105, r 0.9105, f1 0.9105	weighted_f1:0.9091
dev	acc: 0.5347	macro: p 0.3252, r 0.2936, f1: 0.2912	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4808
test	acc: 0.5816	macro: p 0.3733, r 0.3015, f1: 0.3099	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5358
global_step: 8961, epoch: 25, loss: 0.391011
global_step: 8962, epoch: 25, loss: 0.559262
global_step: 8963, epoch: 25, loss: 0.564670
global_step: 8964, epoch: 25, loss: 0.476429
global_step: 8965, epoch: 25, loss: 0.493779
global_step: 8966, epoch: 25, loss: 0.495891
global_step: 8967, epoch: 25, loss: 0.484751
global_step: 8968, epoch: 25, loss: 0.462080
global_step: 8969, epoch: 25, loss: 0.448928
global_step: 8970, epoch: 25, loss: 0.501619
global_step: 8971, epoch: 25, loss: 0.455597
global_step: 8972, epoch: 25, loss: 0.449301
global_step: 8973, epoch: 25, loss: 0.525568
global_step: 8974, epoch: 25, loss: 0.573367
global_step: 8975, epoch: 25, loss: 0.445084
global_step: 8976, epoch: 25, loss: 0.500493
global_step: 8977, epoch: 25, loss: 0.504236
global_step: 8978, epoch: 25, loss: 0.582667
global_step: 8979, epoch: 25, loss: 0.609962
global_step: 8980, epoch: 25, loss: 0.562112
global_step: 8981, epoch: 25, loss: 0.601494
global_step: 8982, epoch: 25, loss: 0.547577
global_step: 8983, epoch: 25, loss: 0.562135
global_step: 8984, epoch: 25, loss: 0.670976
global_step: 8985, epoch: 25, loss: 0.559653
global_step: 8986, epoch: 25, loss: 0.579501
global_step: 8987, epoch: 25, loss: 0.566032
global_step: 8988, epoch: 25, loss: 0.418145
global_step: 8989, epoch: 25, loss: 0.537626
global_step: 8990, epoch: 25, loss: 0.498212
global_step: 8991, epoch: 25, loss: 0.532835
global_step: 8992, epoch: 25, loss: 0.702308
global_step: 8993, epoch: 25, loss: 0.518409
global_step: 8994, epoch: 25, loss: 0.646593
global_step: 8995, epoch: 25, loss: 0.554573
global_step: 8996, epoch: 25, loss: 0.535387
global_step: 8997, epoch: 25, loss: 0.510132
global_step: 8998, epoch: 25, loss: 0.525389
global_step: 8999, epoch: 25, loss: 0.679809
global_step: 9000, epoch: 25, loss: 0.356674
epoch: 25
train	acc: 0.9243	macro: p 0.9050, r 0.8862, f1: 0.8929	micro: p 0.9243, r 0.9243, f1 0.9243	weighted_f1:0.9242
dev	acc: 0.5329	macro: p 0.3852, r 0.3153, f1: 0.3262	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4948
test	acc: 0.5778	macro: p 0.3808, r 0.3121, f1: 0.3247	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5434
global_step: 9001, epoch: 26, loss: 0.570591
global_step: 9002, epoch: 26, loss: 0.484105
global_step: 9003, epoch: 26, loss: 0.427800
global_step: 9004, epoch: 26, loss: 0.471989
global_step: 9005, epoch: 26, loss: 0.418978
global_step: 9006, epoch: 26, loss: 0.441590
global_step: 9007, epoch: 26, loss: 0.513020
global_step: 9008, epoch: 26, loss: 0.442388
global_step: 9009, epoch: 26, loss: 0.429796
global_step: 9010, epoch: 26, loss: 0.528235
global_step: 9011, epoch: 26, loss: 0.663257
global_step: 9012, epoch: 26, loss: 0.469336
global_step: 9013, epoch: 26, loss: 0.506657
global_step: 9014, epoch: 26, loss: 0.573588
global_step: 9015, epoch: 26, loss: 0.501343
global_step: 9016, epoch: 26, loss: 0.481697
global_step: 9017, epoch: 26, loss: 0.492258
global_step: 9018, epoch: 26, loss: 0.510062
global_step: 9019, epoch: 26, loss: 0.469210
global_step: 9020, epoch: 26, loss: 0.480364
global_step: 9021, epoch: 26, loss: 0.558406
global_step: 9022, epoch: 26, loss: 0.457196
global_step: 9023, epoch: 26, loss: 0.616418
global_step: 9024, epoch: 26, loss: 0.555954
global_step: 9025, epoch: 26, loss: 0.594010
global_step: 9026, epoch: 26, loss: 0.577324
global_step: 9027, epoch: 26, loss: 0.408453
global_step: 9028, epoch: 26, loss: 0.621338
global_step: 9029, epoch: 26, loss: 0.545055
global_step: 9030, epoch: 26, loss: 0.489433
global_step: 9031, epoch: 26, loss: 0.555744
global_step: 9032, epoch: 26, loss: 0.434755
global_step: 9033, epoch: 26, loss: 0.538281
global_step: 9034, epoch: 26, loss: 0.436197
global_step: 9035, epoch: 26, loss: 0.639956
global_step: 9036, epoch: 26, loss: 0.526203
global_step: 9037, epoch: 26, loss: 0.649115
global_step: 9038, epoch: 26, loss: 0.655849
global_step: 9039, epoch: 26, loss: 0.609332
global_step: 9040, epoch: 26, loss: 0.265779
epoch: 26
train	acc: 0.9289	macro: p 0.9264, r 0.8818, f1: 0.9000	micro: p 0.9289, r 0.9289, f1 0.9289	weighted_f1:0.9287
dev	acc: 0.5113	macro: p 0.3781, r 0.3018, f1: 0.3004	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4812
test	acc: 0.5544	macro: p 0.3539, r 0.3233, f1: 0.3273	micro: p 0.5544, r 0.5544, f1 0.5544	weighted_f1:0.5349
global_step: 9041, epoch: 27, loss: 0.485527
global_step: 9042, epoch: 27, loss: 0.512569
global_step: 9043, epoch: 27, loss: 0.520913
global_step: 9044, epoch: 27, loss: 0.459614
global_step: 9045, epoch: 27, loss: 0.500082
global_step: 9046, epoch: 27, loss: 0.421205
global_step: 9047, epoch: 27, loss: 0.430725
global_step: 9048, epoch: 27, loss: 0.487895
global_step: 9049, epoch: 27, loss: 0.494656
global_step: 9050, epoch: 27, loss: 0.508336
global_step: 9051, epoch: 27, loss: 0.554502
global_step: 9052, epoch: 27, loss: 0.505499
global_step: 9053, epoch: 27, loss: 0.552837
global_step: 9054, epoch: 27, loss: 0.471084
global_step: 9055, epoch: 27, loss: 0.435169
global_step: 9056, epoch: 27, loss: 0.523734
global_step: 9057, epoch: 27, loss: 0.465366
global_step: 9058, epoch: 27, loss: 0.559455
global_step: 9059, epoch: 27, loss: 0.486894
global_step: 9060, epoch: 27, loss: 0.507300
global_step: 9061, epoch: 27, loss: 0.462423
global_step: 9062, epoch: 27, loss: 0.478704
global_step: 9063, epoch: 27, loss: 0.573168
global_step: 9064, epoch: 27, loss: 0.463497
global_step: 9065, epoch: 27, loss: 0.422050
global_step: 9066, epoch: 27, loss: 0.472537
global_step: 9067, epoch: 27, loss: 0.527357
global_step: 9068, epoch: 27, loss: 0.544372
global_step: 9069, epoch: 27, loss: 0.430870
global_step: 9070, epoch: 27, loss: 0.468530
global_step: 9071, epoch: 27, loss: 0.497457
global_step: 9072, epoch: 27, loss: 0.531981
global_step: 9073, epoch: 27, loss: 0.453343
global_step: 9074, epoch: 27, loss: 0.531709
global_step: 9075, epoch: 27, loss: 0.521061
global_step: 9076, epoch: 27, loss: 0.499493
global_step: 9077, epoch: 27, loss: 0.591805
global_step: 9078, epoch: 27, loss: 0.660248
global_step: 9079, epoch: 27, loss: 0.532688
global_step: 9080, epoch: 27, loss: 0.815266
epoch: 27
train	acc: 0.9274	macro: p 0.9320, r 0.8584, f1: 0.8872	micro: p 0.9274, r 0.9274, f1 0.9274	weighted_f1:0.9265
dev	acc: 0.5266	macro: p 0.3861, r 0.3092, f1: 0.3126	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4949
test	acc: 0.5743	macro: p 0.3624, r 0.3222, f1: 0.3283	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5496
global_step: 9081, epoch: 28, loss: 0.437146
global_step: 9082, epoch: 28, loss: 0.531999
global_step: 9083, epoch: 28, loss: 0.448325
global_step: 9084, epoch: 28, loss: 0.429086
global_step: 9085, epoch: 28, loss: 0.513030
global_step: 9086, epoch: 28, loss: 0.421383
global_step: 9087, epoch: 28, loss: 0.417504
global_step: 9088, epoch: 28, loss: 0.516179
global_step: 9089, epoch: 28, loss: 0.417353
global_step: 9090, epoch: 28, loss: 0.492497
global_step: 9091, epoch: 28, loss: 0.481711
global_step: 9092, epoch: 28, loss: 0.502432
global_step: 9093, epoch: 28, loss: 0.413712
global_step: 9094, epoch: 28, loss: 0.555420
global_step: 9095, epoch: 28, loss: 0.487858
global_step: 9096, epoch: 28, loss: 0.495645
global_step: 9097, epoch: 28, loss: 0.535431
global_step: 9098, epoch: 28, loss: 0.422636
global_step: 9099, epoch: 28, loss: 0.450668
global_step: 9100, epoch: 28, loss: 0.339611
global_step: 9101, epoch: 28, loss: 0.594703
global_step: 9102, epoch: 28, loss: 0.516327
global_step: 9103, epoch: 28, loss: 0.521260
global_step: 9104, epoch: 28, loss: 0.465335
global_step: 9105, epoch: 28, loss: 0.458069
global_step: 9106, epoch: 28, loss: 0.478876
global_step: 9107, epoch: 28, loss: 0.599211
global_step: 9108, epoch: 28, loss: 0.517644
global_step: 9109, epoch: 28, loss: 0.536101
global_step: 9110, epoch: 28, loss: 0.529267
global_step: 9111, epoch: 28, loss: 0.478757
global_step: 9112, epoch: 28, loss: 0.481528
global_step: 9113, epoch: 28, loss: 0.502804
global_step: 9114, epoch: 28, loss: 0.534141
global_step: 9115, epoch: 28, loss: 0.405250
global_step: 9116, epoch: 28, loss: 0.544443
global_step: 9117, epoch: 28, loss: 0.456812
global_step: 9118, epoch: 28, loss: 0.523918
global_step: 9119, epoch: 28, loss: 0.450887
global_step: 9120, epoch: 28, loss: 0.333624
epoch: 28
train	acc: 0.9201	macro: p 0.9416, r 0.8656, f1: 0.8989	micro: p 0.9201, r 0.9201, f1 0.9201	weighted_f1:0.9196
dev	acc: 0.5365	macro: p 0.3814, r 0.2971, f1: 0.2947	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4812
test	acc: 0.5847	macro: p 0.3937, r 0.3040, f1: 0.3130	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5375
global_step: 9121, epoch: 29, loss: 0.572846
global_step: 9122, epoch: 29, loss: 0.472190
global_step: 9123, epoch: 29, loss: 0.448818
global_step: 9124, epoch: 29, loss: 0.459684
global_step: 9125, epoch: 29, loss: 0.513420
global_step: 9126, epoch: 29, loss: 0.471316
global_step: 9127, epoch: 29, loss: 0.589259
global_step: 9128, epoch: 29, loss: 0.569642
global_step: 9129, epoch: 29, loss: 0.346332
global_step: 9130, epoch: 29, loss: 0.487545
global_step: 9131, epoch: 29, loss: 0.498292
global_step: 9132, epoch: 29, loss: 0.528579
global_step: 9133, epoch: 29, loss: 0.429395
global_step: 9134, epoch: 29, loss: 0.414520
global_step: 9135, epoch: 29, loss: 0.435864
global_step: 9136, epoch: 29, loss: 0.381173
global_step: 9137, epoch: 29, loss: 0.499624
global_step: 9138, epoch: 29, loss: 0.461372
global_step: 9139, epoch: 29, loss: 0.476694
global_step: 9140, epoch: 29, loss: 0.489426
global_step: 9141, epoch: 29, loss: 0.560484
global_step: 9142, epoch: 29, loss: 0.426639
global_step: 9143, epoch: 29, loss: 0.618511
global_step: 9144, epoch: 29, loss: 0.475812
global_step: 9145, epoch: 29, loss: 0.458465
global_step: 9146, epoch: 29, loss: 0.467968
global_step: 9147, epoch: 29, loss: 0.448813
global_step: 9148, epoch: 29, loss: 0.455709
global_step: 9149, epoch: 29, loss: 0.390962
global_step: 9150, epoch: 29, loss: 0.580935
global_step: 9151, epoch: 29, loss: 0.540936
global_step: 9152, epoch: 29, loss: 0.502782
global_step: 9153, epoch: 29, loss: 0.440159
global_step: 9154, epoch: 29, loss: 0.474571
global_step: 9155, epoch: 29, loss: 0.502118
global_step: 9156, epoch: 29, loss: 0.455605
global_step: 9157, epoch: 29, loss: 0.483225
global_step: 9158, epoch: 29, loss: 0.526723
global_step: 9159, epoch: 29, loss: 0.397282
global_step: 9160, epoch: 29, loss: 0.183097
epoch: 29
train	acc: 0.9350	macro: p 0.9411, r 0.9057, f1: 0.9211	micro: p 0.9350, r 0.9350, f1 0.9350	weighted_f1:0.9353
dev	acc: 0.4977	macro: p 0.3308, r 0.3032, f1: 0.2961	micro: p 0.4977, r 0.4977, f1 0.4977	weighted_f1:0.4726
test	acc: 0.5360	macro: p 0.3508, r 0.3184, f1: 0.3129	micro: p 0.5360, r 0.5360, f1 0.5360	weighted_f1:0.5208
global_step: 9161, epoch: 30, loss: 0.493283
global_step: 9162, epoch: 30, loss: 0.431718
global_step: 9163, epoch: 30, loss: 0.364080
global_step: 9164, epoch: 30, loss: 0.419940
global_step: 9165, epoch: 30, loss: 0.479039
global_step: 9166, epoch: 30, loss: 0.462189
global_step: 9167, epoch: 30, loss: 0.448425
global_step: 9168, epoch: 30, loss: 0.439025
global_step: 9169, epoch: 30, loss: 0.459298
global_step: 9170, epoch: 30, loss: 0.439025
global_step: 9171, epoch: 30, loss: 0.418312
global_step: 9172, epoch: 30, loss: 0.408511
global_step: 9173, epoch: 30, loss: 0.501390
global_step: 9174, epoch: 30, loss: 0.419734
global_step: 9175, epoch: 30, loss: 0.401828
global_step: 9176, epoch: 30, loss: 0.466164
global_step: 9177, epoch: 30, loss: 0.477990
global_step: 9178, epoch: 30, loss: 0.512795
global_step: 9179, epoch: 30, loss: 0.459808
global_step: 9180, epoch: 30, loss: 0.497358
global_step: 9181, epoch: 30, loss: 0.391264
global_step: 9182, epoch: 30, loss: 0.590835
global_step: 9183, epoch: 30, loss: 0.458941
global_step: 9184, epoch: 30, loss: 0.436840
global_step: 9185, epoch: 30, loss: 0.420233
global_step: 9186, epoch: 30, loss: 0.508486
global_step: 9187, epoch: 30, loss: 0.478313
global_step: 9188, epoch: 30, loss: 0.515079
global_step: 9189, epoch: 30, loss: 0.536006
global_step: 9190, epoch: 30, loss: 0.454600
global_step: 9191, epoch: 30, loss: 0.444385
global_step: 9192, epoch: 30, loss: 0.504627
global_step: 9193, epoch: 30, loss: 0.403581
global_step: 9194, epoch: 30, loss: 0.472042
global_step: 9195, epoch: 30, loss: 0.453170
global_step: 9196, epoch: 30, loss: 0.561037
global_step: 9197, epoch: 30, loss: 0.552628
global_step: 9198, epoch: 30, loss: 0.453445
global_step: 9199, epoch: 30, loss: 0.469662
global_step: 9200, epoch: 30, loss: 0.096071
epoch: 30
train	acc: 0.9371	macro: p 0.9489, r 0.8938, f1: 0.9189	micro: p 0.9371, r 0.9371, f1 0.9371	weighted_f1:0.9368
dev	acc: 0.5455	macro: p 0.4639, r 0.3101, f1: 0.3153	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4932
test	acc: 0.5912	macro: p 0.3639, r 0.3078, f1: 0.3134	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5440
global_step: 9201, epoch: 31, loss: 0.448297
global_step: 9202, epoch: 31, loss: 0.399236
global_step: 9203, epoch: 31, loss: 0.439309
global_step: 9204, epoch: 31, loss: 0.348850
global_step: 9205, epoch: 31, loss: 0.483508
global_step: 9206, epoch: 31, loss: 0.428917
global_step: 9207, epoch: 31, loss: 0.472066
global_step: 9208, epoch: 31, loss: 0.422507
global_step: 9209, epoch: 31, loss: 0.342076
global_step: 9210, epoch: 31, loss: 0.510663
global_step: 9211, epoch: 31, loss: 0.439123
global_step: 9212, epoch: 31, loss: 0.490591
global_step: 9213, epoch: 31, loss: 0.402880
global_step: 9214, epoch: 31, loss: 0.394404
global_step: 9215, epoch: 31, loss: 0.431785
global_step: 9216, epoch: 31, loss: 0.462834
global_step: 9217, epoch: 31, loss: 0.487357
global_step: 9218, epoch: 31, loss: 0.467257
global_step: 9219, epoch: 31, loss: 0.410206
global_step: 9220, epoch: 31, loss: 0.489456
global_step: 9221, epoch: 31, loss: 0.485659
global_step: 9222, epoch: 31, loss: 0.593401
global_step: 9223, epoch: 31, loss: 0.507694
global_step: 9224, epoch: 31, loss: 0.503514
global_step: 9225, epoch: 31, loss: 0.500259
global_step: 9226, epoch: 31, loss: 0.519207
global_step: 9227, epoch: 31, loss: 0.546311
global_step: 9228, epoch: 31, loss: 0.612299
global_step: 9229, epoch: 31, loss: 0.493300
global_step: 9230, epoch: 31, loss: 0.479039
global_step: 9231, epoch: 31, loss: 0.532213
global_step: 9232, epoch: 31, loss: 0.427078
global_step: 9233, epoch: 31, loss: 0.388926
global_step: 9234, epoch: 31, loss: 0.484075
global_step: 9235, epoch: 31, loss: 0.539500
global_step: 9236, epoch: 31, loss: 0.494913
global_step: 9237, epoch: 31, loss: 0.417038
global_step: 9238, epoch: 31, loss: 0.428595
global_step: 9239, epoch: 31, loss: 0.459506
global_step: 9240, epoch: 31, loss: 0.049652
epoch: 31
train	acc: 0.9381	macro: p 0.9479, r 0.8939, f1: 0.9178	micro: p 0.9381, r 0.9381, f1 0.9381	weighted_f1:0.9378
dev	acc: 0.5410	macro: p 0.4090, r 0.3031, f1: 0.3022	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4891
test	acc: 0.5877	macro: p 0.3559, r 0.3133, f1: 0.3124	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5412
global_step: 9241, epoch: 32, loss: 0.444054
global_step: 9242, epoch: 32, loss: 0.534984
global_step: 9243, epoch: 32, loss: 0.408231
global_step: 9244, epoch: 32, loss: 0.475786
global_step: 9245, epoch: 32, loss: 0.420426
global_step: 9246, epoch: 32, loss: 0.453496
global_step: 9247, epoch: 32, loss: 0.469537
global_step: 9248, epoch: 32, loss: 0.442648
global_step: 9249, epoch: 32, loss: 0.432169
global_step: 9250, epoch: 32, loss: 0.482999
global_step: 9251, epoch: 32, loss: 0.463975
global_step: 9252, epoch: 32, loss: 0.497526
global_step: 9253, epoch: 32, loss: 0.362467
global_step: 9254, epoch: 32, loss: 0.417031
global_step: 9255, epoch: 32, loss: 0.430664
global_step: 9256, epoch: 32, loss: 0.323633
global_step: 9257, epoch: 32, loss: 0.419060
global_step: 9258, epoch: 32, loss: 0.431817
global_step: 9259, epoch: 32, loss: 0.393321
global_step: 9260, epoch: 32, loss: 0.481690
global_step: 9261, epoch: 32, loss: 0.513389
global_step: 9262, epoch: 32, loss: 0.443808
global_step: 9263, epoch: 32, loss: 0.449257
global_step: 9264, epoch: 32, loss: 0.470815
global_step: 9265, epoch: 32, loss: 0.430907
global_step: 9266, epoch: 32, loss: 0.456706
global_step: 9267, epoch: 32, loss: 0.364290
global_step: 9268, epoch: 32, loss: 0.462087
global_step: 9269, epoch: 32, loss: 0.417940
global_step: 9270, epoch: 32, loss: 0.593440
global_step: 9271, epoch: 32, loss: 0.539230
global_step: 9272, epoch: 32, loss: 0.498614
global_step: 9273, epoch: 32, loss: 0.487674
global_step: 9274, epoch: 32, loss: 0.427255
global_step: 9275, epoch: 32, loss: 0.558043
global_step: 9276, epoch: 32, loss: 0.493180
global_step: 9277, epoch: 32, loss: 0.530457
global_step: 9278, epoch: 32, loss: 0.484370
global_step: 9279, epoch: 32, loss: 0.513581
global_step: 9280, epoch: 32, loss: 0.076056
epoch: 32
train	acc: 0.9403	macro: p 0.9489, r 0.9037, f1: 0.9241	micro: p 0.9403, r 0.9403, f1 0.9403	weighted_f1:0.9402
dev	acc: 0.5392	macro: p 0.3660, r 0.3075, f1: 0.3056	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4915
test	acc: 0.5736	macro: p 0.3487, r 0.3108, f1: 0.3069	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.5325
global_step: 9281, epoch: 33, loss: 0.451241
global_step: 9282, epoch: 33, loss: 0.370284
global_step: 9283, epoch: 33, loss: 0.314169
global_step: 9284, epoch: 33, loss: 0.393039
global_step: 9285, epoch: 33, loss: 0.390817
global_step: 9286, epoch: 33, loss: 0.524776
global_step: 9287, epoch: 33, loss: 0.429050
global_step: 9288, epoch: 33, loss: 0.490444
global_step: 9289, epoch: 33, loss: 0.411909
global_step: 9290, epoch: 33, loss: 0.519587
global_step: 9291, epoch: 33, loss: 0.369378
global_step: 9292, epoch: 33, loss: 0.471509
global_step: 9293, epoch: 33, loss: 0.425074
global_step: 9294, epoch: 33, loss: 0.437869
global_step: 9295, epoch: 33, loss: 0.477911
global_step: 9296, epoch: 33, loss: 0.472120
global_step: 9297, epoch: 33, loss: 0.497218
global_step: 9298, epoch: 33, loss: 0.510279
global_step: 9299, epoch: 33, loss: 0.427626
global_step: 9300, epoch: 33, loss: 0.536429
global_step: 9301, epoch: 33, loss: 0.412441
global_step: 9302, epoch: 33, loss: 0.360953
global_step: 9303, epoch: 33, loss: 0.417221
global_step: 9304, epoch: 33, loss: 0.545273
global_step: 9305, epoch: 33, loss: 0.489671
global_step: 9306, epoch: 33, loss: 0.463281
global_step: 9307, epoch: 33, loss: 0.443082
global_step: 9308, epoch: 33, loss: 0.503191
global_step: 9309, epoch: 33, loss: 0.515365
global_step: 9310, epoch: 33, loss: 0.525191
global_step: 9311, epoch: 33, loss: 0.412563
global_step: 9312, epoch: 33, loss: 0.521406
global_step: 9313, epoch: 33, loss: 0.349237
global_step: 9314, epoch: 33, loss: 0.540793
global_step: 9315, epoch: 33, loss: 0.437885
global_step: 9316, epoch: 33, loss: 0.509148
global_step: 9317, epoch: 33, loss: 0.477841
global_step: 9318, epoch: 33, loss: 0.407394
global_step: 9319, epoch: 33, loss: 0.419856
global_step: 9320, epoch: 33, loss: 0.480333
epoch: 33
train	acc: 0.9419	macro: p 0.9431, r 0.9137, f1: 0.9271	micro: p 0.9419, r 0.9419, f1 0.9419	weighted_f1:0.9419
dev	acc: 0.5419	macro: p 0.3938, r 0.3240, f1: 0.3254	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4978
test	acc: 0.5709	macro: p 0.3511, r 0.3147, f1: 0.3186	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5367
New best model!
global_step: 9321, epoch: 34, loss: 0.421172
global_step: 9322, epoch: 34, loss: 0.396939
global_step: 9323, epoch: 34, loss: 0.420671
global_step: 9324, epoch: 34, loss: 0.368505
global_step: 9325, epoch: 34, loss: 0.409305
global_step: 9326, epoch: 34, loss: 0.401962
global_step: 9327, epoch: 34, loss: 0.451933
global_step: 9328, epoch: 34, loss: 0.362522
global_step: 9329, epoch: 34, loss: 0.336511
global_step: 9330, epoch: 34, loss: 0.454754
global_step: 9331, epoch: 34, loss: 0.343061
global_step: 9332, epoch: 34, loss: 0.467541
global_step: 9333, epoch: 34, loss: 0.414007
global_step: 9334, epoch: 34, loss: 0.460548
global_step: 9335, epoch: 34, loss: 0.482727
global_step: 9336, epoch: 34, loss: 0.444591
global_step: 9337, epoch: 34, loss: 0.483021
global_step: 9338, epoch: 34, loss: 0.417403
global_step: 9339, epoch: 34, loss: 0.490992
global_step: 9340, epoch: 34, loss: 0.340025
global_step: 9341, epoch: 34, loss: 0.560037
global_step: 9342, epoch: 34, loss: 0.443364
global_step: 9343, epoch: 34, loss: 0.467105
global_step: 9344, epoch: 34, loss: 0.424430
global_step: 9345, epoch: 34, loss: 0.474115
global_step: 9346, epoch: 34, loss: 0.413668
global_step: 9347, epoch: 34, loss: 0.476357
global_step: 9348, epoch: 34, loss: 0.516974
global_step: 9349, epoch: 34, loss: 0.442946
global_step: 9350, epoch: 34, loss: 0.452716
global_step: 9351, epoch: 34, loss: 0.445111
global_step: 9352, epoch: 34, loss: 0.507384
global_step: 9353, epoch: 34, loss: 0.498293
global_step: 9354, epoch: 34, loss: 0.464118
global_step: 9355, epoch: 34, loss: 0.576891
global_step: 9356, epoch: 34, loss: 0.475680
global_step: 9357, epoch: 34, loss: 0.310758
global_step: 9358, epoch: 34, loss: 0.405041
global_step: 9359, epoch: 34, loss: 0.662255
global_step: 9360, epoch: 34, loss: 0.118605
epoch: 34
train	acc: 0.9333	macro: p 0.9362, r 0.9018, f1: 0.9153	micro: p 0.9333, r 0.9333, f1 0.9333	weighted_f1:0.9341
dev	acc: 0.5140	macro: p 0.3385, r 0.3178, f1: 0.3092	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4869
test	acc: 0.5418	macro: p 0.3465, r 0.3290, f1: 0.3179	micro: p 0.5418, r 0.5418, f1 0.5418	weighted_f1:0.5275
global_step: 9361, epoch: 35, loss: 0.481391
global_step: 9362, epoch: 35, loss: 0.387800
global_step: 9363, epoch: 35, loss: 0.345637
global_step: 9364, epoch: 35, loss: 0.450879
global_step: 9365, epoch: 35, loss: 0.437527
global_step: 9366, epoch: 35, loss: 0.410763
global_step: 9367, epoch: 35, loss: 0.408606
global_step: 9368, epoch: 35, loss: 0.368394
global_step: 9369, epoch: 35, loss: 0.461123
global_step: 9370, epoch: 35, loss: 0.482548
global_step: 9371, epoch: 35, loss: 0.378221
global_step: 9372, epoch: 35, loss: 0.310299
global_step: 9373, epoch: 35, loss: 0.507603
global_step: 9374, epoch: 35, loss: 0.473787
global_step: 9375, epoch: 35, loss: 0.419148
global_step: 9376, epoch: 35, loss: 0.489567
global_step: 9377, epoch: 35, loss: 0.519253
global_step: 9378, epoch: 35, loss: 0.386328
global_step: 9379, epoch: 35, loss: 0.378378
global_step: 9380, epoch: 35, loss: 0.416297
global_step: 9381, epoch: 35, loss: 0.361895
global_step: 9382, epoch: 35, loss: 0.408649
global_step: 9383, epoch: 35, loss: 0.438880
global_step: 9384, epoch: 35, loss: 0.411916
global_step: 9385, epoch: 35, loss: 0.486331
global_step: 9386, epoch: 35, loss: 0.400092
global_step: 9387, epoch: 35, loss: 0.502046
global_step: 9388, epoch: 35, loss: 0.469375
global_step: 9389, epoch: 35, loss: 0.419373
global_step: 9390, epoch: 35, loss: 0.448401
global_step: 9391, epoch: 35, loss: 0.517474
global_step: 9392, epoch: 35, loss: 0.515038
global_step: 9393, epoch: 35, loss: 0.469544
global_step: 9394, epoch: 35, loss: 0.405928
global_step: 9395, epoch: 35, loss: 0.440502
global_step: 9396, epoch: 35, loss: 0.391722
global_step: 9397, epoch: 35, loss: 0.385746
global_step: 9398, epoch: 35, loss: 0.478312
global_step: 9399, epoch: 35, loss: 0.415432
global_step: 9400, epoch: 35, loss: 0.307245
epoch: 35
train	acc: 0.9333	macro: p 0.9498, r 0.8878, f1: 0.9154	micro: p 0.9333, r 0.9333, f1 0.9333	weighted_f1:0.9330
dev	acc: 0.5365	macro: p 0.3561, r 0.2969, f1: 0.2899	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4782
test	acc: 0.5785	macro: p 0.3615, r 0.3009, f1: 0.2967	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5249
global_step: 9401, epoch: 36, loss: 0.497177
global_step: 9402, epoch: 36, loss: 0.440713
global_step: 9403, epoch: 36, loss: 0.381515
global_step: 9404, epoch: 36, loss: 0.456221
global_step: 9405, epoch: 36, loss: 0.370475
global_step: 9406, epoch: 36, loss: 0.425202
global_step: 9407, epoch: 36, loss: 0.545910
global_step: 9408, epoch: 36, loss: 0.457765
global_step: 9409, epoch: 36, loss: 0.461570
global_step: 9410, epoch: 36, loss: 0.379915
global_step: 9411, epoch: 36, loss: 0.390249
global_step: 9412, epoch: 36, loss: 0.385466
global_step: 9413, epoch: 36, loss: 0.341796
global_step: 9414, epoch: 36, loss: 0.440343
global_step: 9415, epoch: 36, loss: 0.464701
global_step: 9416, epoch: 36, loss: 0.456202
global_step: 9417, epoch: 36, loss: 0.454876
global_step: 9418, epoch: 36, loss: 0.338726
global_step: 9419, epoch: 36, loss: 0.417123
global_step: 9420, epoch: 36, loss: 0.441579
global_step: 9421, epoch: 36, loss: 0.497502
global_step: 9422, epoch: 36, loss: 0.456246
global_step: 9423, epoch: 36, loss: 0.309922
global_step: 9424, epoch: 36, loss: 0.434752
global_step: 9425, epoch: 36, loss: 0.370274
global_step: 9426, epoch: 36, loss: 0.401872
global_step: 9427, epoch: 36, loss: 0.350183
global_step: 9428, epoch: 36, loss: 0.352569
global_step: 9429, epoch: 36, loss: 0.339063
global_step: 9430, epoch: 36, loss: 0.397683
global_step: 9431, epoch: 36, loss: 0.440620
global_step: 9432, epoch: 36, loss: 0.417109
global_step: 9433, epoch: 36, loss: 0.505422
global_step: 9434, epoch: 36, loss: 0.466381
global_step: 9435, epoch: 36, loss: 0.447179
global_step: 9436, epoch: 36, loss: 0.405761
global_step: 9437, epoch: 36, loss: 0.459002
global_step: 9438, epoch: 36, loss: 0.467300
global_step: 9439, epoch: 36, loss: 0.400567
global_step: 9440, epoch: 36, loss: 0.016813
epoch: 36
train	acc: 0.9501	macro: p 0.9542, r 0.9218, f1: 0.9370	micro: p 0.9501, r 0.9501, f1 0.9501	weighted_f1:0.9500
dev	acc: 0.5455	macro: p 0.4467, r 0.3120, f1: 0.3228	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4983
test	acc: 0.5897	macro: p 0.3808, r 0.3139, f1: 0.3220	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5477
New best model!
global_step: 9441, epoch: 37, loss: 0.326387
global_step: 9442, epoch: 37, loss: 0.332508
global_step: 9443, epoch: 37, loss: 0.336096
global_step: 9444, epoch: 37, loss: 0.385600
global_step: 9445, epoch: 37, loss: 0.359595
global_step: 9446, epoch: 37, loss: 0.440745
global_step: 9447, epoch: 37, loss: 0.429707
global_step: 9448, epoch: 37, loss: 0.396444
global_step: 9449, epoch: 37, loss: 0.337971
global_step: 9450, epoch: 37, loss: 0.373386
global_step: 9451, epoch: 37, loss: 0.423028
global_step: 9452, epoch: 37, loss: 0.424213
global_step: 9453, epoch: 37, loss: 0.449318
global_step: 9454, epoch: 37, loss: 0.316443
global_step: 9455, epoch: 37, loss: 0.396058
global_step: 9456, epoch: 37, loss: 0.373524
global_step: 9457, epoch: 37, loss: 0.435068
global_step: 9458, epoch: 37, loss: 0.477915
global_step: 9459, epoch: 37, loss: 0.418932
global_step: 9460, epoch: 37, loss: 0.350481
global_step: 9461, epoch: 37, loss: 0.337412
global_step: 9462, epoch: 37, loss: 0.405790
global_step: 9463, epoch: 37, loss: 0.523431
global_step: 9464, epoch: 37, loss: 0.497407
global_step: 9465, epoch: 37, loss: 0.414281
global_step: 9466, epoch: 37, loss: 0.361275
global_step: 9467, epoch: 37, loss: 0.430275
global_step: 9468, epoch: 37, loss: 0.378008
global_step: 9469, epoch: 37, loss: 0.327029
global_step: 9470, epoch: 37, loss: 0.425178
global_step: 9471, epoch: 37, loss: 0.393976
global_step: 9472, epoch: 37, loss: 0.460487
global_step: 9473, epoch: 37, loss: 0.339392
global_step: 9474, epoch: 37, loss: 0.386178
global_step: 9475, epoch: 37, loss: 0.369532
global_step: 9476, epoch: 37, loss: 0.481633
global_step: 9477, epoch: 37, loss: 0.514762
global_step: 9478, epoch: 37, loss: 0.528884
global_step: 9479, epoch: 37, loss: 0.364803
global_step: 9480, epoch: 37, loss: 0.420065
epoch: 37
train	acc: 0.9465	macro: p 0.9539, r 0.9164, f1: 0.9338	micro: p 0.9465, r 0.9465, f1 0.9465	weighted_f1:0.9464
dev	acc: 0.5356	macro: p 0.4087, r 0.3015, f1: 0.3047	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4817
test	acc: 0.5820	macro: p 0.3604, r 0.3054, f1: 0.3079	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5323
global_step: 9481, epoch: 38, loss: 0.375306
global_step: 9482, epoch: 38, loss: 0.379108
global_step: 9483, epoch: 38, loss: 0.393594
global_step: 9484, epoch: 38, loss: 0.379034
global_step: 9485, epoch: 38, loss: 0.284928
global_step: 9486, epoch: 38, loss: 0.276027
global_step: 9487, epoch: 38, loss: 0.441194
global_step: 9488, epoch: 38, loss: 0.341748
global_step: 9489, epoch: 38, loss: 0.357339
global_step: 9490, epoch: 38, loss: 0.283223
global_step: 9491, epoch: 38, loss: 0.395538
global_step: 9492, epoch: 38, loss: 0.304574
global_step: 9493, epoch: 38, loss: 0.417903
global_step: 9494, epoch: 38, loss: 0.442814
global_step: 9495, epoch: 38, loss: 0.357515
global_step: 9496, epoch: 38, loss: 0.352863
global_step: 9497, epoch: 38, loss: 0.341880
global_step: 9498, epoch: 38, loss: 0.336725
global_step: 9499, epoch: 38, loss: 0.407828
global_step: 9500, epoch: 38, loss: 0.360879
global_step: 9501, epoch: 38, loss: 0.387366
global_step: 9502, epoch: 38, loss: 0.362227
global_step: 9503, epoch: 38, loss: 0.433856
global_step: 9504, epoch: 38, loss: 0.335557
global_step: 9505, epoch: 38, loss: 0.552087
global_step: 9506, epoch: 38, loss: 0.391823
global_step: 9507, epoch: 38, loss: 0.394754
global_step: 9508, epoch: 38, loss: 0.452352
global_step: 9509, epoch: 38, loss: 0.502259
global_step: 9510, epoch: 38, loss: 0.400012
global_step: 9511, epoch: 38, loss: 0.472972
global_step: 9512, epoch: 38, loss: 0.409742
global_step: 9513, epoch: 38, loss: 0.391581
global_step: 9514, epoch: 38, loss: 0.348819
global_step: 9515, epoch: 38, loss: 0.435865
global_step: 9516, epoch: 38, loss: 0.416938
global_step: 9517, epoch: 38, loss: 0.368922
global_step: 9518, epoch: 38, loss: 0.453824
global_step: 9519, epoch: 38, loss: 0.389065
global_step: 9520, epoch: 38, loss: 1.574583
epoch: 38
train	acc: 0.9519	macro: p 0.9532, r 0.9289, f1: 0.9402	micro: p 0.9519, r 0.9519, f1 0.9519	weighted_f1:0.9520
dev	acc: 0.5338	macro: p 0.3444, r 0.3097, f1: 0.3128	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4954
test	acc: 0.5655	macro: p 0.3390, r 0.3141, f1: 0.3177	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5353
global_step: 9521, epoch: 39, loss: 0.354449
global_step: 9522, epoch: 39, loss: 0.356031
global_step: 9523, epoch: 39, loss: 0.383308
global_step: 9524, epoch: 39, loss: 0.293015
global_step: 9525, epoch: 39, loss: 0.285640
global_step: 9526, epoch: 39, loss: 0.386272
global_step: 9527, epoch: 39, loss: 0.412799
global_step: 9528, epoch: 39, loss: 0.407647
global_step: 9529, epoch: 39, loss: 0.378212
global_step: 9530, epoch: 39, loss: 0.390263
global_step: 9531, epoch: 39, loss: 0.371328
global_step: 9532, epoch: 39, loss: 0.409671
global_step: 9533, epoch: 39, loss: 0.320262
global_step: 9534, epoch: 39, loss: 0.385857
global_step: 9535, epoch: 39, loss: 0.402020
global_step: 9536, epoch: 39, loss: 0.558584
global_step: 9537, epoch: 39, loss: 0.453297
global_step: 9538, epoch: 39, loss: 0.308263
global_step: 9539, epoch: 39, loss: 0.328144
global_step: 9540, epoch: 39, loss: 0.442650
global_step: 9541, epoch: 39, loss: 0.455378
global_step: 9542, epoch: 39, loss: 0.382491
global_step: 9543, epoch: 39, loss: 0.389896
global_step: 9544, epoch: 39, loss: 0.317524
global_step: 9545, epoch: 39, loss: 0.477712
global_step: 9546, epoch: 39, loss: 0.336264
global_step: 9547, epoch: 39, loss: 0.309348
global_step: 9548, epoch: 39, loss: 0.384185
global_step: 9549, epoch: 39, loss: 0.406946
global_step: 9550, epoch: 39, loss: 0.497976
global_step: 9551, epoch: 39, loss: 0.388824
global_step: 9552, epoch: 39, loss: 0.389573
global_step: 9553, epoch: 39, loss: 0.469937
global_step: 9554, epoch: 39, loss: 0.342480
global_step: 9555, epoch: 39, loss: 0.344089
global_step: 9556, epoch: 39, loss: 0.457405
global_step: 9557, epoch: 39, loss: 0.454729
global_step: 9558, epoch: 39, loss: 0.357722
global_step: 9559, epoch: 39, loss: 0.340969
global_step: 9560, epoch: 39, loss: 0.341360
epoch: 39
train	acc: 0.9540	macro: p 0.9571, r 0.9321, f1: 0.9438	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9541
dev	acc: 0.5122	macro: p 0.3305, r 0.2957, f1: 0.2925	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4757
test	acc: 0.5579	macro: p 0.3594, r 0.3145, f1: 0.3173	micro: p 0.5579, r 0.5579, f1 0.5579	weighted_f1:0.5297
global_step: 9561, epoch: 40, loss: 0.367093
global_step: 9562, epoch: 40, loss: 0.297121
global_step: 9563, epoch: 40, loss: 0.308879
global_step: 9564, epoch: 40, loss: 0.314479
global_step: 9565, epoch: 40, loss: 0.403626
global_step: 9566, epoch: 40, loss: 0.333037
global_step: 9567, epoch: 40, loss: 0.329023
global_step: 9568, epoch: 40, loss: 0.352313
global_step: 9569, epoch: 40, loss: 0.326209
global_step: 9570, epoch: 40, loss: 0.399486
global_step: 9571, epoch: 40, loss: 0.400981
global_step: 9572, epoch: 40, loss: 0.294630
global_step: 9573, epoch: 40, loss: 0.401034
global_step: 9574, epoch: 40, loss: 0.411878
global_step: 9575, epoch: 40, loss: 0.367422
global_step: 9576, epoch: 40, loss: 0.349107
global_step: 9577, epoch: 40, loss: 0.448401
global_step: 9578, epoch: 40, loss: 0.377150
global_step: 9579, epoch: 40, loss: 0.394319
global_step: 9580, epoch: 40, loss: 0.344452
global_step: 9581, epoch: 40, loss: 0.440416
global_step: 9582, epoch: 40, loss: 0.445484
global_step: 9583, epoch: 40, loss: 0.313187
global_step: 9584, epoch: 40, loss: 0.386403
global_step: 9585, epoch: 40, loss: 0.354756
global_step: 9586, epoch: 40, loss: 0.291635
global_step: 9587, epoch: 40, loss: 0.320611
global_step: 9588, epoch: 40, loss: 0.304831
global_step: 9589, epoch: 40, loss: 0.407792
global_step: 9590, epoch: 40, loss: 0.455088
global_step: 9591, epoch: 40, loss: 0.296011
global_step: 9592, epoch: 40, loss: 0.338197
global_step: 9593, epoch: 40, loss: 0.317410
global_step: 9594, epoch: 40, loss: 0.423093
global_step: 9595, epoch: 40, loss: 0.361073
global_step: 9596, epoch: 40, loss: 0.383082
global_step: 9597, epoch: 40, loss: 0.397632
global_step: 9598, epoch: 40, loss: 0.297975
global_step: 9599, epoch: 40, loss: 0.389592
global_step: 9600, epoch: 40, loss: 0.012164
epoch: 40
train	acc: 0.9565	macro: p 0.9632, r 0.9336, f1: 0.9476	micro: p 0.9565, r 0.9565, f1 0.9565	weighted_f1:0.9564
dev	acc: 0.5365	macro: p 0.3528, r 0.3111, f1: 0.3139	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4972
test	acc: 0.5663	macro: p 0.3395, r 0.3079, f1: 0.3128	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5331
global_step: 9601, epoch: 41, loss: 0.352831
global_step: 9602, epoch: 41, loss: 0.234489
global_step: 9603, epoch: 41, loss: 0.304602
global_step: 9604, epoch: 41, loss: 0.278922
global_step: 9605, epoch: 41, loss: 0.418328
global_step: 9606, epoch: 41, loss: 0.383370
global_step: 9607, epoch: 41, loss: 0.327475
global_step: 9608, epoch: 41, loss: 0.320314
global_step: 9609, epoch: 41, loss: 0.347830
global_step: 9610, epoch: 41, loss: 0.367007
global_step: 9611, epoch: 41, loss: 0.360623
global_step: 9612, epoch: 41, loss: 0.415074
global_step: 9613, epoch: 41, loss: 0.342448
global_step: 9614, epoch: 41, loss: 0.332766
global_step: 9615, epoch: 41, loss: 0.262273
global_step: 9616, epoch: 41, loss: 0.360747
global_step: 9617, epoch: 41, loss: 0.325269
global_step: 9618, epoch: 41, loss: 0.347409
global_step: 9619, epoch: 41, loss: 0.329904
global_step: 9620, epoch: 41, loss: 0.338595
global_step: 9621, epoch: 41, loss: 0.341408
global_step: 9622, epoch: 41, loss: 0.544971
global_step: 9623, epoch: 41, loss: 0.410011
global_step: 9624, epoch: 41, loss: 0.404288
global_step: 9625, epoch: 41, loss: 0.326569
global_step: 9626, epoch: 41, loss: 0.393171
global_step: 9627, epoch: 41, loss: 0.400735
global_step: 9628, epoch: 41, loss: 0.442448
global_step: 9629, epoch: 41, loss: 0.412533
global_step: 9630, epoch: 41, loss: 0.359136
global_step: 9631, epoch: 41, loss: 0.400031
global_step: 9632, epoch: 41, loss: 0.380022
global_step: 9633, epoch: 41, loss: 0.362384
global_step: 9634, epoch: 41, loss: 0.359931
global_step: 9635, epoch: 41, loss: 0.434911
global_step: 9636, epoch: 41, loss: 0.368858
global_step: 9637, epoch: 41, loss: 0.379975
global_step: 9638, epoch: 41, loss: 0.409051
global_step: 9639, epoch: 41, loss: 0.389467
global_step: 9640, epoch: 41, loss: 1.081022
epoch: 41
train	acc: 0.9511	macro: p 0.9527, r 0.9311, f1: 0.9408	micro: p 0.9511, r 0.9511, f1 0.9511	weighted_f1:0.9513
dev	acc: 0.5257	macro: p 0.3738, r 0.3156, f1: 0.3171	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4903
test	acc: 0.5464	macro: p 0.3394, r 0.3113, f1: 0.3109	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5210
global_step: 9641, epoch: 42, loss: 0.337437
global_step: 9642, epoch: 42, loss: 0.299334
global_step: 9643, epoch: 42, loss: 0.326877
global_step: 9644, epoch: 42, loss: 0.340325
global_step: 9645, epoch: 42, loss: 0.320344
global_step: 9646, epoch: 42, loss: 0.273833
global_step: 9647, epoch: 42, loss: 0.378390
global_step: 9648, epoch: 42, loss: 0.375891
global_step: 9649, epoch: 42, loss: 0.393400
global_step: 9650, epoch: 42, loss: 0.360666
global_step: 9651, epoch: 42, loss: 0.333691
global_step: 9652, epoch: 42, loss: 0.351191
global_step: 9653, epoch: 42, loss: 0.315864
global_step: 9654, epoch: 42, loss: 0.293099
global_step: 9655, epoch: 42, loss: 0.388949
global_step: 9656, epoch: 42, loss: 0.290733
global_step: 9657, epoch: 42, loss: 0.319586
global_step: 9658, epoch: 42, loss: 0.385479
global_step: 9659, epoch: 42, loss: 0.318482
global_step: 9660, epoch: 42, loss: 0.414479
global_step: 9661, epoch: 42, loss: 0.530936
global_step: 9662, epoch: 42, loss: 0.308026
global_step: 9663, epoch: 42, loss: 0.300488
global_step: 9664, epoch: 42, loss: 0.397164
global_step: 9665, epoch: 42, loss: 0.301331
global_step: 9666, epoch: 42, loss: 0.372484
global_step: 9667, epoch: 42, loss: 0.342505
global_step: 9668, epoch: 42, loss: 0.348596
global_step: 9669, epoch: 42, loss: 0.313904
global_step: 9670, epoch: 42, loss: 0.361774
global_step: 9671, epoch: 42, loss: 0.347577
global_step: 9672, epoch: 42, loss: 0.389571
global_step: 9673, epoch: 42, loss: 0.385361
global_step: 9674, epoch: 42, loss: 0.388905
global_step: 9675, epoch: 42, loss: 0.368294
global_step: 9676, epoch: 42, loss: 0.417713
global_step: 9677, epoch: 42, loss: 0.353932
global_step: 9678, epoch: 42, loss: 0.364098
global_step: 9679, epoch: 42, loss: 0.470997
global_step: 9680, epoch: 42, loss: 0.029260
epoch: 42
train	acc: 0.9585	macro: p 0.9655, r 0.9383, f1: 0.9512	micro: p 0.9585, r 0.9585, f1 0.9585	weighted_f1:0.9585
dev	acc: 0.5437	macro: p 0.4406, r 0.3270, f1: 0.3428	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.5030
test	acc: 0.5686	macro: p 0.3462, r 0.3105, f1: 0.3183	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5351
New best model!
global_step: 9681, epoch: 43, loss: 0.333143
global_step: 9682, epoch: 43, loss: 0.350806
global_step: 9683, epoch: 43, loss: 0.341951
global_step: 9684, epoch: 43, loss: 0.285535
global_step: 9685, epoch: 43, loss: 0.235757
global_step: 9686, epoch: 43, loss: 0.392202
global_step: 9687, epoch: 43, loss: 0.358419
global_step: 9688, epoch: 43, loss: 0.329579
global_step: 9689, epoch: 43, loss: 0.306087
global_step: 9690, epoch: 43, loss: 0.318250
global_step: 9691, epoch: 43, loss: 0.347862
global_step: 9692, epoch: 43, loss: 0.276634
global_step: 9693, epoch: 43, loss: 0.271275
global_step: 9694, epoch: 43, loss: 0.389729
global_step: 9695, epoch: 43, loss: 0.300427
global_step: 9696, epoch: 43, loss: 0.348903
global_step: 9697, epoch: 43, loss: 0.319786
global_step: 9698, epoch: 43, loss: 0.346171
global_step: 9699, epoch: 43, loss: 0.320218
global_step: 9700, epoch: 43, loss: 0.349887
global_step: 9701, epoch: 43, loss: 0.384941
global_step: 9702, epoch: 43, loss: 0.359412
global_step: 9703, epoch: 43, loss: 0.403402
global_step: 9704, epoch: 43, loss: 0.351399
global_step: 9705, epoch: 43, loss: 0.371199
global_step: 9706, epoch: 43, loss: 0.373751
global_step: 9707, epoch: 43, loss: 0.282519
global_step: 9708, epoch: 43, loss: 0.440962
global_step: 9709, epoch: 43, loss: 0.332945
global_step: 9710, epoch: 43, loss: 0.422298
global_step: 9711, epoch: 43, loss: 0.377294
global_step: 9712, epoch: 43, loss: 0.444661
global_step: 9713, epoch: 43, loss: 0.427712
global_step: 9714, epoch: 43, loss: 0.421425
global_step: 9715, epoch: 43, loss: 0.337051
global_step: 9716, epoch: 43, loss: 0.363772
global_step: 9717, epoch: 43, loss: 0.314596
global_step: 9718, epoch: 43, loss: 0.359720
global_step: 9719, epoch: 43, loss: 0.363041
global_step: 9720, epoch: 43, loss: 0.381116
epoch: 43
train	acc: 0.9596	macro: p 0.9649, r 0.9411, f1: 0.9524	micro: p 0.9596, r 0.9596, f1 0.9596	weighted_f1:0.9596
dev	acc: 0.5356	macro: p 0.3727, r 0.3136, f1: 0.3193	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4974
test	acc: 0.5632	macro: p 0.3468, r 0.3109, f1: 0.3159	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.5332
global_step: 9721, epoch: 44, loss: 0.360740
global_step: 9722, epoch: 44, loss: 0.312125
global_step: 9723, epoch: 44, loss: 0.375788
global_step: 9724, epoch: 44, loss: 0.271976
global_step: 9725, epoch: 44, loss: 0.299849
global_step: 9726, epoch: 44, loss: 0.275460
global_step: 9727, epoch: 44, loss: 0.301716
global_step: 9728, epoch: 44, loss: 0.289357
global_step: 9729, epoch: 44, loss: 0.351644
global_step: 9730, epoch: 44, loss: 0.329511
global_step: 9731, epoch: 44, loss: 0.313688
global_step: 9732, epoch: 44, loss: 0.368032
global_step: 9733, epoch: 44, loss: 0.277350
global_step: 9734, epoch: 44, loss: 0.305215
global_step: 9735, epoch: 44, loss: 0.274750
global_step: 9736, epoch: 44, loss: 0.396016
global_step: 9737, epoch: 44, loss: 0.279149
global_step: 9738, epoch: 44, loss: 0.375784
global_step: 9739, epoch: 44, loss: 0.392680
global_step: 9740, epoch: 44, loss: 0.341504
global_step: 9741, epoch: 44, loss: 0.311912
global_step: 9742, epoch: 44, loss: 0.362611
global_step: 9743, epoch: 44, loss: 0.435463
global_step: 9744, epoch: 44, loss: 0.315237
global_step: 9745, epoch: 44, loss: 0.453562
global_step: 9746, epoch: 44, loss: 0.363620
global_step: 9747, epoch: 44, loss: 0.468036
global_step: 9748, epoch: 44, loss: 0.379308
global_step: 9749, epoch: 44, loss: 0.370124
global_step: 9750, epoch: 44, loss: 0.387868
global_step: 9751, epoch: 44, loss: 0.328639
global_step: 9752, epoch: 44, loss: 0.388299
global_step: 9753, epoch: 44, loss: 0.394704
global_step: 9754, epoch: 44, loss: 0.414213
global_step: 9755, epoch: 44, loss: 0.341028
global_step: 9756, epoch: 44, loss: 0.331736
global_step: 9757, epoch: 44, loss: 0.314708
global_step: 9758, epoch: 44, loss: 0.384665
global_step: 9759, epoch: 44, loss: 0.360221
global_step: 9760, epoch: 44, loss: 0.575265
epoch: 44
train	acc: 0.9553	macro: p 0.9542, r 0.9422, f1: 0.9477	micro: p 0.9553, r 0.9553, f1 0.9553	weighted_f1:0.9554
dev	acc: 0.4869	macro: p 0.3491, r 0.3084, f1: 0.3115	micro: p 0.4869, r 0.4869, f1 0.4869	weighted_f1:0.4642
test	acc: 0.5337	macro: p 0.3397, r 0.3144, f1: 0.3154	micro: p 0.5337, r 0.5337, f1 0.5337	weighted_f1:0.5193
global_step: 9761, epoch: 45, loss: 0.382372
global_step: 9762, epoch: 45, loss: 0.314791
global_step: 9763, epoch: 45, loss: 0.347608
global_step: 9764, epoch: 45, loss: 0.260543
global_step: 9765, epoch: 45, loss: 0.345089
global_step: 9766, epoch: 45, loss: 0.261407
global_step: 9767, epoch: 45, loss: 0.367607
global_step: 9768, epoch: 45, loss: 0.293624
global_step: 9769, epoch: 45, loss: 0.305985
global_step: 9770, epoch: 45, loss: 0.250066
global_step: 9771, epoch: 45, loss: 0.337848
global_step: 9772, epoch: 45, loss: 0.390573
global_step: 9773, epoch: 45, loss: 0.332463
global_step: 9774, epoch: 45, loss: 0.366649
global_step: 9775, epoch: 45, loss: 0.409511
global_step: 9776, epoch: 45, loss: 0.313368
global_step: 9777, epoch: 45, loss: 0.329004
global_step: 9778, epoch: 45, loss: 0.273993
global_step: 9779, epoch: 45, loss: 0.384052
global_step: 9780, epoch: 45, loss: 0.359289
global_step: 9781, epoch: 45, loss: 0.378907
global_step: 9782, epoch: 45, loss: 0.276331
global_step: 9783, epoch: 45, loss: 0.309792
global_step: 9784, epoch: 45, loss: 0.290113
global_step: 9785, epoch: 45, loss: 0.366764
global_step: 9786, epoch: 45, loss: 0.415550
global_step: 9787, epoch: 45, loss: 0.273807
global_step: 9788, epoch: 45, loss: 0.357606
global_step: 9789, epoch: 45, loss: 0.421905
global_step: 9790, epoch: 45, loss: 0.310070
global_step: 9791, epoch: 45, loss: 0.314676
global_step: 9792, epoch: 45, loss: 0.329740
global_step: 9793, epoch: 45, loss: 0.398933
global_step: 9794, epoch: 45, loss: 0.328451
global_step: 9795, epoch: 45, loss: 0.298202
global_step: 9796, epoch: 45, loss: 0.394483
global_step: 9797, epoch: 45, loss: 0.337091
global_step: 9798, epoch: 45, loss: 0.313341
global_step: 9799, epoch: 45, loss: 0.380705
global_step: 9800, epoch: 45, loss: 0.870779
epoch: 45
train	acc: 0.9542	macro: p 0.9603, r 0.9369, f1: 0.9475	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9545
dev	acc: 0.5320	macro: p 0.3714, r 0.3048, f1: 0.3069	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4829
test	acc: 0.5659	macro: p 0.3549, r 0.3071, f1: 0.3110	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5266
global_step: 9801, epoch: 46, loss: 0.346780
global_step: 9802, epoch: 46, loss: 0.294570
global_step: 9803, epoch: 46, loss: 0.324689
global_step: 9804, epoch: 46, loss: 0.326266
global_step: 9805, epoch: 46, loss: 0.230980
global_step: 9806, epoch: 46, loss: 0.265769
global_step: 9807, epoch: 46, loss: 0.321605
global_step: 9808, epoch: 46, loss: 0.304425
global_step: 9809, epoch: 46, loss: 0.422442
global_step: 9810, epoch: 46, loss: 0.354757
global_step: 9811, epoch: 46, loss: 0.255593
global_step: 9812, epoch: 46, loss: 0.256595
global_step: 9813, epoch: 46, loss: 0.330346
global_step: 9814, epoch: 46, loss: 0.327620
global_step: 9815, epoch: 46, loss: 0.372814
global_step: 9816, epoch: 46, loss: 0.391757
global_step: 9817, epoch: 46, loss: 0.301118
global_step: 9818, epoch: 46, loss: 0.391755
global_step: 9819, epoch: 46, loss: 0.294574
global_step: 9820, epoch: 46, loss: 0.340750
global_step: 9821, epoch: 46, loss: 0.341627
global_step: 9822, epoch: 46, loss: 0.374753
global_step: 9823, epoch: 46, loss: 0.421745
global_step: 9824, epoch: 46, loss: 0.366364
global_step: 9825, epoch: 46, loss: 0.433624
global_step: 9826, epoch: 46, loss: 0.301338
global_step: 9827, epoch: 46, loss: 0.403643
global_step: 9828, epoch: 46, loss: 0.371641
global_step: 9829, epoch: 46, loss: 0.292879
global_step: 9830, epoch: 46, loss: 0.398032
global_step: 9831, epoch: 46, loss: 0.338302
global_step: 9832, epoch: 46, loss: 0.377109
global_step: 9833, epoch: 46, loss: 0.454170
global_step: 9834, epoch: 46, loss: 0.319576
global_step: 9835, epoch: 46, loss: 0.293608
global_step: 9836, epoch: 46, loss: 0.291038
global_step: 9837, epoch: 46, loss: 0.332635
global_step: 9838, epoch: 46, loss: 0.334797
global_step: 9839, epoch: 46, loss: 0.430674
global_step: 9840, epoch: 46, loss: 0.734081
epoch: 46
train	acc: 0.9520	macro: p 0.9579, r 0.9314, f1: 0.9435	micro: p 0.9520, r 0.9520, f1 0.9520	weighted_f1:0.9522
dev	acc: 0.5140	macro: p 0.4004, r 0.2997, f1: 0.3030	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4811
test	acc: 0.5648	macro: p 0.3482, r 0.3136, f1: 0.3182	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5397
global_step: 9841, epoch: 47, loss: 0.385736
global_step: 9842, epoch: 47, loss: 0.332100
global_step: 9843, epoch: 47, loss: 0.351232
global_step: 9844, epoch: 47, loss: 0.333251
global_step: 9845, epoch: 47, loss: 0.377675
global_step: 9846, epoch: 47, loss: 0.340186
global_step: 9847, epoch: 47, loss: 0.379210
global_step: 9848, epoch: 47, loss: 0.409805
global_step: 9849, epoch: 47, loss: 0.304900
global_step: 9850, epoch: 47, loss: 0.287116
global_step: 9851, epoch: 47, loss: 0.397198
global_step: 9852, epoch: 47, loss: 0.313729
global_step: 9853, epoch: 47, loss: 0.360745
global_step: 9854, epoch: 47, loss: 0.234848
global_step: 9855, epoch: 47, loss: 0.331315
global_step: 9856, epoch: 47, loss: 0.313499
global_step: 9857, epoch: 47, loss: 0.257693
global_step: 9858, epoch: 47, loss: 0.312681
global_step: 9859, epoch: 47, loss: 0.258265
global_step: 9860, epoch: 47, loss: 0.350401
global_step: 9861, epoch: 47, loss: 0.395856
global_step: 9862, epoch: 47, loss: 0.307336
global_step: 9863, epoch: 47, loss: 0.317876
global_step: 9864, epoch: 47, loss: 0.373871
global_step: 9865, epoch: 47, loss: 0.241681
global_step: 9866, epoch: 47, loss: 0.421022
global_step: 9867, epoch: 47, loss: 0.346007
global_step: 9868, epoch: 47, loss: 0.285289
global_step: 9869, epoch: 47, loss: 0.383706
global_step: 9870, epoch: 47, loss: 0.321948
global_step: 9871, epoch: 47, loss: 0.359523
global_step: 9872, epoch: 47, loss: 0.364490
global_step: 9873, epoch: 47, loss: 0.326574
global_step: 9874, epoch: 47, loss: 0.326043
global_step: 9875, epoch: 47, loss: 0.358921
global_step: 9876, epoch: 47, loss: 0.322865
global_step: 9877, epoch: 47, loss: 0.373654
global_step: 9878, epoch: 47, loss: 0.329056
global_step: 9879, epoch: 47, loss: 0.425855
global_step: 9880, epoch: 47, loss: 0.023027
epoch: 47
train	acc: 0.9550	macro: p 0.9609, r 0.9364, f1: 0.9472	micro: p 0.9550, r 0.9550, f1 0.9550	weighted_f1:0.9553
dev	acc: 0.5266	macro: p 0.3554, r 0.3039, f1: 0.3052	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4855
test	acc: 0.5648	macro: p 0.3611, r 0.3108, f1: 0.3143	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5329
global_step: 9881, epoch: 48, loss: 0.338341
global_step: 9882, epoch: 48, loss: 0.277350
global_step: 9883, epoch: 48, loss: 0.421709
global_step: 9884, epoch: 48, loss: 0.322582
global_step: 9885, epoch: 48, loss: 0.230810
global_step: 9886, epoch: 48, loss: 0.329651
global_step: 9887, epoch: 48, loss: 0.295659
global_step: 9888, epoch: 48, loss: 0.254913
global_step: 9889, epoch: 48, loss: 0.251445
global_step: 9890, epoch: 48, loss: 0.316621
global_step: 9891, epoch: 48, loss: 0.252114
global_step: 9892, epoch: 48, loss: 0.300618
global_step: 9893, epoch: 48, loss: 0.317814
global_step: 9894, epoch: 48, loss: 0.441340
global_step: 9895, epoch: 48, loss: 0.359152
global_step: 9896, epoch: 48, loss: 0.283577
global_step: 9897, epoch: 48, loss: 0.292642
global_step: 9898, epoch: 48, loss: 0.333549
global_step: 9899, epoch: 48, loss: 0.343133
global_step: 9900, epoch: 48, loss: 0.363111
global_step: 9901, epoch: 48, loss: 0.336382
global_step: 9902, epoch: 48, loss: 0.371752
global_step: 9903, epoch: 48, loss: 0.291518
global_step: 9904, epoch: 48, loss: 0.414076
global_step: 9905, epoch: 48, loss: 0.305949
global_step: 9906, epoch: 48, loss: 0.335671
global_step: 9907, epoch: 48, loss: 0.336053
global_step: 9908, epoch: 48, loss: 0.436107
global_step: 9909, epoch: 48, loss: 0.349663
global_step: 9910, epoch: 48, loss: 0.344862
global_step: 9911, epoch: 48, loss: 0.374719
global_step: 9912, epoch: 48, loss: 0.329297
global_step: 9913, epoch: 48, loss: 0.280432
global_step: 9914, epoch: 48, loss: 0.273961
global_step: 9915, epoch: 48, loss: 0.431486
global_step: 9916, epoch: 48, loss: 0.292611
global_step: 9917, epoch: 48, loss: 0.357164
global_step: 9918, epoch: 48, loss: 0.340656
global_step: 9919, epoch: 48, loss: 0.360439
global_step: 9920, epoch: 48, loss: 0.011186
epoch: 48
train	acc: 0.9615	macro: p 0.9684, r 0.9440, f1: 0.9557	micro: p 0.9615, r 0.9615, f1 0.9615	weighted_f1:0.9614
dev	acc: 0.5248	macro: p 0.3494, r 0.3020, f1: 0.3049	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4838
test	acc: 0.5674	macro: p 0.3390, r 0.3033, f1: 0.3070	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5314
global_step: 9921, epoch: 49, loss: 0.330409
global_step: 9922, epoch: 49, loss: 0.297759
global_step: 9923, epoch: 49, loss: 0.300655
global_step: 9924, epoch: 49, loss: 0.334463
global_step: 9925, epoch: 49, loss: 0.389700
global_step: 9926, epoch: 49, loss: 0.307254
global_step: 9927, epoch: 49, loss: 0.305323
global_step: 9928, epoch: 49, loss: 0.307107
global_step: 9929, epoch: 49, loss: 0.376198
global_step: 9930, epoch: 49, loss: 0.314511
global_step: 9931, epoch: 49, loss: 0.335361
global_step: 9932, epoch: 49, loss: 0.253430
global_step: 9933, epoch: 49, loss: 0.365739
global_step: 9934, epoch: 49, loss: 0.321597
global_step: 9935, epoch: 49, loss: 0.309939
global_step: 9936, epoch: 49, loss: 0.298660
global_step: 9937, epoch: 49, loss: 0.377162
global_step: 9938, epoch: 49, loss: 0.402199
global_step: 9939, epoch: 49, loss: 0.354598
global_step: 9940, epoch: 49, loss: 0.297726
global_step: 9941, epoch: 49, loss: 0.339175
global_step: 9942, epoch: 49, loss: 0.320018
global_step: 9943, epoch: 49, loss: 0.389027
global_step: 9944, epoch: 49, loss: 0.259348
global_step: 9945, epoch: 49, loss: 0.331838
global_step: 9946, epoch: 49, loss: 0.425559
global_step: 9947, epoch: 49, loss: 0.268279
global_step: 9948, epoch: 49, loss: 0.408807
global_step: 9949, epoch: 49, loss: 0.330344
global_step: 9950, epoch: 49, loss: 0.328695
global_step: 9951, epoch: 49, loss: 0.409402
global_step: 9952, epoch: 49, loss: 0.279048
global_step: 9953, epoch: 49, loss: 0.372080
global_step: 9954, epoch: 49, loss: 0.401042
global_step: 9955, epoch: 49, loss: 0.415168
global_step: 9956, epoch: 49, loss: 0.322780
global_step: 9957, epoch: 49, loss: 0.271496
global_step: 9958, epoch: 49, loss: 0.309789
global_step: 9959, epoch: 49, loss: 0.328302
global_step: 9960, epoch: 49, loss: 0.361373
epoch: 49
train	acc: 0.9489	macro: p 0.9630, r 0.9227, f1: 0.9413	micro: p 0.9489, r 0.9489, f1 0.9489	weighted_f1:0.9489
dev	acc: 0.5203	macro: p 0.4637, r 0.2950, f1: 0.2920	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4759
test	acc: 0.5743	macro: p 0.3765, r 0.3111, f1: 0.3139	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5395
global_step: 9961, epoch: 50, loss: 0.443061
global_step: 9962, epoch: 50, loss: 0.303867
global_step: 9963, epoch: 50, loss: 0.279095
global_step: 9964, epoch: 50, loss: 0.243898
global_step: 9965, epoch: 50, loss: 0.308819
global_step: 9966, epoch: 50, loss: 0.352425
global_step: 9967, epoch: 50, loss: 0.368795
global_step: 9968, epoch: 50, loss: 0.342482
global_step: 9969, epoch: 50, loss: 0.312588
global_step: 9970, epoch: 50, loss: 0.325818
global_step: 9971, epoch: 50, loss: 0.418177
global_step: 9972, epoch: 50, loss: 0.279785
global_step: 9973, epoch: 50, loss: 0.294710
global_step: 9974, epoch: 50, loss: 0.234012
global_step: 9975, epoch: 50, loss: 0.297884
global_step: 9976, epoch: 50, loss: 0.312705
global_step: 9977, epoch: 50, loss: 0.392187
global_step: 9978, epoch: 50, loss: 0.385349
global_step: 9979, epoch: 50, loss: 0.277449
global_step: 9980, epoch: 50, loss: 0.300689
global_step: 9981, epoch: 50, loss: 0.387764
global_step: 9982, epoch: 50, loss: 0.314643
global_step: 9983, epoch: 50, loss: 0.353571
global_step: 9984, epoch: 50, loss: 0.298523
global_step: 9985, epoch: 50, loss: 0.315517
global_step: 9986, epoch: 50, loss: 0.316415
global_step: 9987, epoch: 50, loss: 0.243879
global_step: 9988, epoch: 50, loss: 0.353475
global_step: 9989, epoch: 50, loss: 0.279730
global_step: 9990, epoch: 50, loss: 0.285982
global_step: 9991, epoch: 50, loss: 0.297300
global_step: 9992, epoch: 50, loss: 0.279469
global_step: 9993, epoch: 50, loss: 0.403901
global_step: 9994, epoch: 50, loss: 0.327929
global_step: 9995, epoch: 50, loss: 0.303916
global_step: 9996, epoch: 50, loss: 0.343005
global_step: 9997, epoch: 50, loss: 0.326682
global_step: 9998, epoch: 50, loss: 0.353195
global_step: 9999, epoch: 50, loss: 0.348580
global_step: 10000, epoch: 50, loss: 0.516179
epoch: 50
train	acc: 0.9581	macro: p 0.9647, r 0.9348, f1: 0.9488	micro: p 0.9581, r 0.9581, f1 0.9581	weighted_f1:0.9580
dev	acc: 0.5158	macro: p 0.3680, r 0.2836, f1: 0.2853	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4646
test	acc: 0.5625	macro: p 0.3419, r 0.2919, f1: 0.2967	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.5188
global_step: 10001, epoch: 51, loss: 0.310659
global_step: 10002, epoch: 51, loss: 0.360277
global_step: 10003, epoch: 51, loss: 0.290465
global_step: 10004, epoch: 51, loss: 0.283618
global_step: 10005, epoch: 51, loss: 0.287730
global_step: 10006, epoch: 51, loss: 0.276076
global_step: 10007, epoch: 51, loss: 0.342657
global_step: 10008, epoch: 51, loss: 0.390475
global_step: 10009, epoch: 51, loss: 0.347394
global_step: 10010, epoch: 51, loss: 0.321399
global_step: 10011, epoch: 51, loss: 0.333144
global_step: 10012, epoch: 51, loss: 0.311972
global_step: 10013, epoch: 51, loss: 0.282542
global_step: 10014, epoch: 51, loss: 0.288878
global_step: 10015, epoch: 51, loss: 0.289576
global_step: 10016, epoch: 51, loss: 0.301569
global_step: 10017, epoch: 51, loss: 0.445298
global_step: 10018, epoch: 51, loss: 0.275420
global_step: 10019, epoch: 51, loss: 0.231700
global_step: 10020, epoch: 51, loss: 0.315428
global_step: 10021, epoch: 51, loss: 0.345451
global_step: 10022, epoch: 51, loss: 0.291652
global_step: 10023, epoch: 51, loss: 0.342512
global_step: 10024, epoch: 51, loss: 0.218134
global_step: 10025, epoch: 51, loss: 0.293369
global_step: 10026, epoch: 51, loss: 0.265174
global_step: 10027, epoch: 51, loss: 0.328890
global_step: 10028, epoch: 51, loss: 0.287260
global_step: 10029, epoch: 51, loss: 0.263352
global_step: 10030, epoch: 51, loss: 0.322947
global_step: 10031, epoch: 51, loss: 0.288587
global_step: 10032, epoch: 51, loss: 0.293443
global_step: 10033, epoch: 51, loss: 0.310692
global_step: 10034, epoch: 51, loss: 0.329448
global_step: 10035, epoch: 51, loss: 0.318037
global_step: 10036, epoch: 51, loss: 0.263384
global_step: 10037, epoch: 51, loss: 0.239466
global_step: 10038, epoch: 51, loss: 0.312251
global_step: 10039, epoch: 51, loss: 0.493529
global_step: 10040, epoch: 51, loss: 0.199876
epoch: 51
train	acc: 0.9601	macro: p 0.9666, r 0.9417, f1: 0.9534	micro: p 0.9601, r 0.9601, f1 0.9601	weighted_f1:0.9601
dev	acc: 0.5284	macro: p 0.4211, r 0.3130, f1: 0.3213	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4896
test	acc: 0.5663	macro: p 0.3477, r 0.3145, f1: 0.3185	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5363
global_step: 10041, epoch: 52, loss: 0.289356
global_step: 10042, epoch: 52, loss: 0.273703
global_step: 10043, epoch: 52, loss: 0.329869
global_step: 10044, epoch: 52, loss: 0.259954
global_step: 10045, epoch: 52, loss: 0.279612
global_step: 10046, epoch: 52, loss: 0.359441
global_step: 10047, epoch: 52, loss: 0.216565
global_step: 10048, epoch: 52, loss: 0.356028
global_step: 10049, epoch: 52, loss: 0.291625
global_step: 10050, epoch: 52, loss: 0.307663
global_step: 10051, epoch: 52, loss: 0.176403
global_step: 10052, epoch: 52, loss: 0.245993
global_step: 10053, epoch: 52, loss: 0.288164
global_step: 10054, epoch: 52, loss: 0.300084
global_step: 10055, epoch: 52, loss: 0.329626
global_step: 10056, epoch: 52, loss: 0.321292
global_step: 10057, epoch: 52, loss: 0.292735
global_step: 10058, epoch: 52, loss: 0.274915
global_step: 10059, epoch: 52, loss: 0.361573
global_step: 10060, epoch: 52, loss: 0.344461
global_step: 10061, epoch: 52, loss: 0.420650
global_step: 10062, epoch: 52, loss: 0.310240
global_step: 10063, epoch: 52, loss: 0.329283
global_step: 10064, epoch: 52, loss: 0.313233
global_step: 10065, epoch: 52, loss: 0.318900
global_step: 10066, epoch: 52, loss: 0.362879
global_step: 10067, epoch: 52, loss: 0.274534
global_step: 10068, epoch: 52, loss: 0.269616
global_step: 10069, epoch: 52, loss: 0.315967
global_step: 10070, epoch: 52, loss: 0.290755
global_step: 10071, epoch: 52, loss: 0.311900
global_step: 10072, epoch: 52, loss: 0.267029
global_step: 10073, epoch: 52, loss: 0.314780
global_step: 10074, epoch: 52, loss: 0.372438
global_step: 10075, epoch: 52, loss: 0.279938
global_step: 10076, epoch: 52, loss: 0.245939
global_step: 10077, epoch: 52, loss: 0.263724
global_step: 10078, epoch: 52, loss: 0.269102
global_step: 10079, epoch: 52, loss: 0.301529
global_step: 10080, epoch: 52, loss: 0.283716
epoch: 52
train	acc: 0.9621	macro: p 0.9698, r 0.9460, f1: 0.9574	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9620
dev	acc: 0.5320	macro: p 0.3831, r 0.3200, f1: 0.3262	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4903
test	acc: 0.5628	macro: p 0.3341, r 0.2986, f1: 0.3046	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5240
global_step: 10081, epoch: 53, loss: 0.304755
global_step: 10082, epoch: 53, loss: 0.227451
global_step: 10083, epoch: 53, loss: 0.240231
global_step: 10084, epoch: 53, loss: 0.360626
global_step: 10085, epoch: 53, loss: 0.301394
global_step: 10086, epoch: 53, loss: 0.348419
global_step: 10087, epoch: 53, loss: 0.411177
global_step: 10088, epoch: 53, loss: 0.293287
global_step: 10089, epoch: 53, loss: 0.256594
global_step: 10090, epoch: 53, loss: 0.240955
global_step: 10091, epoch: 53, loss: 0.364082
global_step: 10092, epoch: 53, loss: 0.307856
global_step: 10093, epoch: 53, loss: 0.313406
global_step: 10094, epoch: 53, loss: 0.284209
global_step: 10095, epoch: 53, loss: 0.341271
global_step: 10096, epoch: 53, loss: 0.271555
global_step: 10097, epoch: 53, loss: 0.347372
global_step: 10098, epoch: 53, loss: 0.293689
global_step: 10099, epoch: 53, loss: 0.359047
global_step: 10100, epoch: 53, loss: 0.264122
global_step: 10101, epoch: 53, loss: 0.338493
global_step: 10102, epoch: 53, loss: 0.195964
global_step: 10103, epoch: 53, loss: 0.298147
global_step: 10104, epoch: 53, loss: 0.378035
global_step: 10105, epoch: 53, loss: 0.313577
global_step: 10106, epoch: 53, loss: 0.363426
global_step: 10107, epoch: 53, loss: 0.245412
global_step: 10108, epoch: 53, loss: 0.266150
global_step: 10109, epoch: 53, loss: 0.356909
global_step: 10110, epoch: 53, loss: 0.313361
global_step: 10111, epoch: 53, loss: 0.296577
global_step: 10112, epoch: 53, loss: 0.404435
global_step: 10113, epoch: 53, loss: 0.303631
global_step: 10114, epoch: 53, loss: 0.362761
global_step: 10115, epoch: 53, loss: 0.329094
global_step: 10116, epoch: 53, loss: 0.271849
global_step: 10117, epoch: 53, loss: 0.349118
global_step: 10118, epoch: 53, loss: 0.354101
global_step: 10119, epoch: 53, loss: 0.285630
global_step: 10120, epoch: 53, loss: 0.062674
epoch: 53
train	acc: 0.9637	macro: p 0.9675, r 0.9505, f1: 0.9586	micro: p 0.9637, r 0.9637, f1 0.9637	weighted_f1:0.9637
dev	acc: 0.5158	macro: p 0.3786, r 0.3046, f1: 0.3107	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4801
test	acc: 0.5659	macro: p 0.3426, r 0.3092, f1: 0.3151	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5330
global_step: 10121, epoch: 54, loss: 0.284225
global_step: 10122, epoch: 54, loss: 0.261416
global_step: 10123, epoch: 54, loss: 0.199808
global_step: 10124, epoch: 54, loss: 0.303106
global_step: 10125, epoch: 54, loss: 0.322490
global_step: 10126, epoch: 54, loss: 0.265901
global_step: 10127, epoch: 54, loss: 0.309629
global_step: 10128, epoch: 54, loss: 0.356597
global_step: 10129, epoch: 54, loss: 0.332212
global_step: 10130, epoch: 54, loss: 0.340249
global_step: 10131, epoch: 54, loss: 0.344706
global_step: 10132, epoch: 54, loss: 0.252866
global_step: 10133, epoch: 54, loss: 0.258214
global_step: 10134, epoch: 54, loss: 0.252258
global_step: 10135, epoch: 54, loss: 0.287066
global_step: 10136, epoch: 54, loss: 0.335594
global_step: 10137, epoch: 54, loss: 0.238326
global_step: 10138, epoch: 54, loss: 0.264907
global_step: 10139, epoch: 54, loss: 0.265765
global_step: 10140, epoch: 54, loss: 0.248386
global_step: 10141, epoch: 54, loss: 0.340662
global_step: 10142, epoch: 54, loss: 0.372028
global_step: 10143, epoch: 54, loss: 0.297207
global_step: 10144, epoch: 54, loss: 0.297136
global_step: 10145, epoch: 54, loss: 0.307245
global_step: 10146, epoch: 54, loss: 0.319444
global_step: 10147, epoch: 54, loss: 0.236187
global_step: 10148, epoch: 54, loss: 0.287896
global_step: 10149, epoch: 54, loss: 0.334640
global_step: 10150, epoch: 54, loss: 0.254445
global_step: 10151, epoch: 54, loss: 0.324588
global_step: 10152, epoch: 54, loss: 0.361178
global_step: 10153, epoch: 54, loss: 0.363848
global_step: 10154, epoch: 54, loss: 0.339063
global_step: 10155, epoch: 54, loss: 0.294229
global_step: 10156, epoch: 54, loss: 0.350681
global_step: 10157, epoch: 54, loss: 0.329695
global_step: 10158, epoch: 54, loss: 0.324363
global_step: 10159, epoch: 54, loss: 0.430746
global_step: 10160, epoch: 54, loss: 0.572367
epoch: 54
train	acc: 0.9559	macro: p 0.9661, r 0.9362, f1: 0.9505	micro: p 0.9559, r 0.9559, f1 0.9559	weighted_f1:0.9557
dev	acc: 0.5284	macro: p 0.4390, r 0.2968, f1: 0.3126	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4716
test	acc: 0.5667	macro: p 0.3672, r 0.2853, f1: 0.2954	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5125
global_step: 10161, epoch: 55, loss: 0.319971
global_step: 10162, epoch: 55, loss: 0.304095
global_step: 10163, epoch: 55, loss: 0.318242
global_step: 10164, epoch: 55, loss: 0.305393
global_step: 10165, epoch: 55, loss: 0.343867
global_step: 10166, epoch: 55, loss: 0.335362
global_step: 10167, epoch: 55, loss: 0.291984
global_step: 10168, epoch: 55, loss: 0.374221
global_step: 10169, epoch: 55, loss: 0.315231
global_step: 10170, epoch: 55, loss: 0.266061
global_step: 10171, epoch: 55, loss: 0.403622
global_step: 10172, epoch: 55, loss: 0.298909
global_step: 10173, epoch: 55, loss: 0.303592
global_step: 10174, epoch: 55, loss: 0.478564
global_step: 10175, epoch: 55, loss: 0.244777
global_step: 10176, epoch: 55, loss: 0.216572
global_step: 10177, epoch: 55, loss: 0.400146
global_step: 10178, epoch: 55, loss: 0.289968
global_step: 10179, epoch: 55, loss: 0.217108
global_step: 10180, epoch: 55, loss: 0.324213
global_step: 10181, epoch: 55, loss: 0.231261
global_step: 10182, epoch: 55, loss: 0.255867
global_step: 10183, epoch: 55, loss: 0.375874
global_step: 10184, epoch: 55, loss: 0.311780
global_step: 10185, epoch: 55, loss: 0.312180
global_step: 10186, epoch: 55, loss: 0.258231
global_step: 10187, epoch: 55, loss: 0.288444
global_step: 10188, epoch: 55, loss: 0.251382
global_step: 10189, epoch: 55, loss: 0.349833
global_step: 10190, epoch: 55, loss: 0.406986
global_step: 10191, epoch: 55, loss: 0.330700
global_step: 10192, epoch: 55, loss: 0.333537
global_step: 10193, epoch: 55, loss: 0.369494
global_step: 10194, epoch: 55, loss: 0.201258
global_step: 10195, epoch: 55, loss: 0.247700
global_step: 10196, epoch: 55, loss: 0.206463
global_step: 10197, epoch: 55, loss: 0.320447
global_step: 10198, epoch: 55, loss: 0.320271
global_step: 10199, epoch: 55, loss: 0.199521
global_step: 10200, epoch: 55, loss: 0.126080
epoch: 55
train	acc: 0.9598	macro: p 0.9692, r 0.9397, f1: 0.9538	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9596
dev	acc: 0.5356	macro: p 0.3922, r 0.3079, f1: 0.3182	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4927
test	acc: 0.5716	macro: p 0.3625, r 0.3033, f1: 0.3137	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5333
global_step: 10201, epoch: 56, loss: 0.222836
global_step: 10202, epoch: 56, loss: 0.297733
global_step: 10203, epoch: 56, loss: 0.257497
global_step: 10204, epoch: 56, loss: 0.305001
global_step: 10205, epoch: 56, loss: 0.255603
global_step: 10206, epoch: 56, loss: 0.345083
global_step: 10207, epoch: 56, loss: 0.271857
global_step: 10208, epoch: 56, loss: 0.234330
global_step: 10209, epoch: 56, loss: 0.305121
global_step: 10210, epoch: 56, loss: 0.257759
global_step: 10211, epoch: 56, loss: 0.211348
global_step: 10212, epoch: 56, loss: 0.340472
global_step: 10213, epoch: 56, loss: 0.297991
global_step: 10214, epoch: 56, loss: 0.289007
global_step: 10215, epoch: 56, loss: 0.330552
global_step: 10216, epoch: 56, loss: 0.286073
global_step: 10217, epoch: 56, loss: 0.284687
global_step: 10218, epoch: 56, loss: 0.286021
global_step: 10219, epoch: 56, loss: 0.321803
global_step: 10220, epoch: 56, loss: 0.330799
global_step: 10221, epoch: 56, loss: 0.311525
global_step: 10222, epoch: 56, loss: 0.228183
global_step: 10223, epoch: 56, loss: 0.382756
global_step: 10224, epoch: 56, loss: 0.336845
global_step: 10225, epoch: 56, loss: 0.353180
global_step: 10226, epoch: 56, loss: 0.309713
global_step: 10227, epoch: 56, loss: 0.333790
global_step: 10228, epoch: 56, loss: 0.272599
global_step: 10229, epoch: 56, loss: 0.330052
global_step: 10230, epoch: 56, loss: 0.285311
global_step: 10231, epoch: 56, loss: 0.240655
global_step: 10232, epoch: 56, loss: 0.293147
global_step: 10233, epoch: 56, loss: 0.299134
global_step: 10234, epoch: 56, loss: 0.426650
global_step: 10235, epoch: 56, loss: 0.330989
global_step: 10236, epoch: 56, loss: 0.252154
global_step: 10237, epoch: 56, loss: 0.332905
global_step: 10238, epoch: 56, loss: 0.347911
global_step: 10239, epoch: 56, loss: 0.307817
global_step: 10240, epoch: 56, loss: 0.721912
epoch: 56
train	acc: 0.9621	macro: p 0.9651, r 0.9507, f1: 0.9572	micro: p 0.9621, r 0.9621, f1 0.9621	weighted_f1:0.9623
dev	acc: 0.5248	macro: p 0.3600, r 0.3158, f1: 0.3187	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4921
test	acc: 0.5456	macro: p 0.3417, r 0.3154, f1: 0.3137	micro: p 0.5456, r 0.5456, f1 0.5456	weighted_f1:0.5199
global_step: 10241, epoch: 57, loss: 0.294368
global_step: 10242, epoch: 57, loss: 0.260539
global_step: 10243, epoch: 57, loss: 0.337339
global_step: 10244, epoch: 57, loss: 0.329969
global_step: 10245, epoch: 57, loss: 0.315672
global_step: 10246, epoch: 57, loss: 0.282651
global_step: 10247, epoch: 57, loss: 0.286561
global_step: 10248, epoch: 57, loss: 0.248678
global_step: 10249, epoch: 57, loss: 0.295223
global_step: 10250, epoch: 57, loss: 0.293619
global_step: 10251, epoch: 57, loss: 0.310253
global_step: 10252, epoch: 57, loss: 0.308009
global_step: 10253, epoch: 57, loss: 0.325405
global_step: 10254, epoch: 57, loss: 0.278029
global_step: 10255, epoch: 57, loss: 0.301558
global_step: 10256, epoch: 57, loss: 0.233070
global_step: 10257, epoch: 57, loss: 0.301422
global_step: 10258, epoch: 57, loss: 0.258334
global_step: 10259, epoch: 57, loss: 0.252789
global_step: 10260, epoch: 57, loss: 0.415714
global_step: 10261, epoch: 57, loss: 0.374884
global_step: 10262, epoch: 57, loss: 0.289652
global_step: 10263, epoch: 57, loss: 0.216426
global_step: 10264, epoch: 57, loss: 0.303899
global_step: 10265, epoch: 57, loss: 0.313266
global_step: 10266, epoch: 57, loss: 0.305925
global_step: 10267, epoch: 57, loss: 0.308825
global_step: 10268, epoch: 57, loss: 0.242058
global_step: 10269, epoch: 57, loss: 0.328715
global_step: 10270, epoch: 57, loss: 0.317987
global_step: 10271, epoch: 57, loss: 0.288611
global_step: 10272, epoch: 57, loss: 0.227848
global_step: 10273, epoch: 57, loss: 0.229651
global_step: 10274, epoch: 57, loss: 0.273247
global_step: 10275, epoch: 57, loss: 0.309700
global_step: 10276, epoch: 57, loss: 0.282973
global_step: 10277, epoch: 57, loss: 0.343069
global_step: 10278, epoch: 57, loss: 0.267548
global_step: 10279, epoch: 57, loss: 0.277180
global_step: 10280, epoch: 57, loss: 0.272109
epoch: 57
train	acc: 0.9634	macro: p 0.9668, r 0.9496, f1: 0.9579	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9634
dev	acc: 0.5221	macro: p 0.3864, r 0.3078, f1: 0.3198	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4815
test	acc: 0.5625	macro: p 0.3444, r 0.2966, f1: 0.3046	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.5234
global_step: 10281, epoch: 58, loss: 0.328377
global_step: 10282, epoch: 58, loss: 0.304152
global_step: 10283, epoch: 58, loss: 0.289607
global_step: 10284, epoch: 58, loss: 0.253984
global_step: 10285, epoch: 58, loss: 0.254260
global_step: 10286, epoch: 58, loss: 0.300027
global_step: 10287, epoch: 58, loss: 0.229606
global_step: 10288, epoch: 58, loss: 0.272097
global_step: 10289, epoch: 58, loss: 0.327338
global_step: 10290, epoch: 58, loss: 0.313511
global_step: 10291, epoch: 58, loss: 0.305681
global_step: 10292, epoch: 58, loss: 0.217296
global_step: 10293, epoch: 58, loss: 0.262384
global_step: 10294, epoch: 58, loss: 0.315041
global_step: 10295, epoch: 58, loss: 0.307681
global_step: 10296, epoch: 58, loss: 0.313916
global_step: 10297, epoch: 58, loss: 0.282680
global_step: 10298, epoch: 58, loss: 0.179260
global_step: 10299, epoch: 58, loss: 0.292310
global_step: 10300, epoch: 58, loss: 0.227653
global_step: 10301, epoch: 58, loss: 0.291497
global_step: 10302, epoch: 58, loss: 0.352900
global_step: 10303, epoch: 58, loss: 0.289590
global_step: 10304, epoch: 58, loss: 0.252314
global_step: 10305, epoch: 58, loss: 0.295789
global_step: 10306, epoch: 58, loss: 0.244831
global_step: 10307, epoch: 58, loss: 0.284448
global_step: 10308, epoch: 58, loss: 0.251759
global_step: 10309, epoch: 58, loss: 0.296463
global_step: 10310, epoch: 58, loss: 0.330797
global_step: 10311, epoch: 58, loss: 0.312104
global_step: 10312, epoch: 58, loss: 0.352253
global_step: 10313, epoch: 58, loss: 0.332212
global_step: 10314, epoch: 58, loss: 0.283217
global_step: 10315, epoch: 58, loss: 0.262912
global_step: 10316, epoch: 58, loss: 0.272043
global_step: 10317, epoch: 58, loss: 0.222914
global_step: 10318, epoch: 58, loss: 0.244593
global_step: 10319, epoch: 58, loss: 0.317185
global_step: 10320, epoch: 58, loss: 0.005310
epoch: 58
train	acc: 0.9644	macro: p 0.9684, r 0.9497, f1: 0.9587	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.5284	macro: p 0.3860, r 0.3214, f1: 0.3324	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4941
test	acc: 0.5605	macro: p 0.3685, r 0.3126, f1: 0.3229	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5301
global_step: 10321, epoch: 59, loss: 0.279455
global_step: 10322, epoch: 59, loss: 0.209693
global_step: 10323, epoch: 59, loss: 0.239684
global_step: 10324, epoch: 59, loss: 0.247637
global_step: 10325, epoch: 59, loss: 0.235845
global_step: 10326, epoch: 59, loss: 0.262401
global_step: 10327, epoch: 59, loss: 0.268463
global_step: 10328, epoch: 59, loss: 0.309214
global_step: 10329, epoch: 59, loss: 0.281736
global_step: 10330, epoch: 59, loss: 0.244739
global_step: 10331, epoch: 59, loss: 0.263566
global_step: 10332, epoch: 59, loss: 0.229983
global_step: 10333, epoch: 59, loss: 0.254752
global_step: 10334, epoch: 59, loss: 0.234092
global_step: 10335, epoch: 59, loss: 0.300509
global_step: 10336, epoch: 59, loss: 0.287561
global_step: 10337, epoch: 59, loss: 0.384303
global_step: 10338, epoch: 59, loss: 0.351649
global_step: 10339, epoch: 59, loss: 0.221884
global_step: 10340, epoch: 59, loss: 0.268578
global_step: 10341, epoch: 59, loss: 0.327878
global_step: 10342, epoch: 59, loss: 0.271519
global_step: 10343, epoch: 59, loss: 0.402378
global_step: 10344, epoch: 59, loss: 0.273956
global_step: 10345, epoch: 59, loss: 0.237805
global_step: 10346, epoch: 59, loss: 0.357853
global_step: 10347, epoch: 59, loss: 0.226375
global_step: 10348, epoch: 59, loss: 0.232705
global_step: 10349, epoch: 59, loss: 0.313120
global_step: 10350, epoch: 59, loss: 0.275731
global_step: 10351, epoch: 59, loss: 0.365432
global_step: 10352, epoch: 59, loss: 0.368775
global_step: 10353, epoch: 59, loss: 0.262921
global_step: 10354, epoch: 59, loss: 0.251829
global_step: 10355, epoch: 59, loss: 0.239614
global_step: 10356, epoch: 59, loss: 0.266920
global_step: 10357, epoch: 59, loss: 0.387282
global_step: 10358, epoch: 59, loss: 0.323867
global_step: 10359, epoch: 59, loss: 0.273001
global_step: 10360, epoch: 59, loss: 0.052851
epoch: 59
train	acc: 0.9632	macro: p 0.9691, r 0.9454, f1: 0.9568	micro: p 0.9632, r 0.9632, f1 0.9632	weighted_f1:0.9632
dev	acc: 0.5257	macro: p 0.3714, r 0.3044, f1: 0.3123	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4846
test	acc: 0.5705	macro: p 0.3550, r 0.3071, f1: 0.3144	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5337
global_step: 10361, epoch: 60, loss: 0.264830
global_step: 10362, epoch: 60, loss: 0.191285
global_step: 10363, epoch: 60, loss: 0.195551
global_step: 10364, epoch: 60, loss: 0.248795
global_step: 10365, epoch: 60, loss: 0.344974
global_step: 10366, epoch: 60, loss: 0.209013
global_step: 10367, epoch: 60, loss: 0.320750
global_step: 10368, epoch: 60, loss: 0.220950
global_step: 10369, epoch: 60, loss: 0.287706
global_step: 10370, epoch: 60, loss: 0.182958
global_step: 10371, epoch: 60, loss: 0.344130
global_step: 10372, epoch: 60, loss: 0.295190
global_step: 10373, epoch: 60, loss: 0.231798
global_step: 10374, epoch: 60, loss: 0.356866
global_step: 10375, epoch: 60, loss: 0.173038
global_step: 10376, epoch: 60, loss: 0.243684
global_step: 10377, epoch: 60, loss: 0.306702
global_step: 10378, epoch: 60, loss: 0.240558
global_step: 10379, epoch: 60, loss: 0.308094
global_step: 10380, epoch: 60, loss: 0.172257
global_step: 10381, epoch: 60, loss: 0.312238
global_step: 10382, epoch: 60, loss: 0.299997
global_step: 10383, epoch: 60, loss: 0.336154
global_step: 10384, epoch: 60, loss: 0.249495
global_step: 10385, epoch: 60, loss: 0.288046
global_step: 10386, epoch: 60, loss: 0.316446
global_step: 10387, epoch: 60, loss: 0.216637
global_step: 10388, epoch: 60, loss: 0.297587
global_step: 10389, epoch: 60, loss: 0.328229
global_step: 10390, epoch: 60, loss: 0.255550
global_step: 10391, epoch: 60, loss: 0.250774
global_step: 10392, epoch: 60, loss: 0.279724
global_step: 10393, epoch: 60, loss: 0.251468
global_step: 10394, epoch: 60, loss: 0.290942
global_step: 10395, epoch: 60, loss: 0.346673
global_step: 10396, epoch: 60, loss: 0.318378
global_step: 10397, epoch: 60, loss: 0.287602
global_step: 10398, epoch: 60, loss: 0.345278
global_step: 10399, epoch: 60, loss: 0.297533
global_step: 10400, epoch: 60, loss: 0.002582
epoch: 60
train	acc: 0.9623	macro: p 0.9725, r 0.9444, f1: 0.9579	micro: p 0.9623, r 0.9623, f1 0.9623	weighted_f1:0.9621
dev	acc: 0.5329	macro: p 0.3910, r 0.2999, f1: 0.3113	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4793
test	acc: 0.5720	macro: p 0.3586, r 0.2908, f1: 0.3025	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5212
global_step: 10401, epoch: 61, loss: 0.226518
global_step: 10402, epoch: 61, loss: 0.274789
global_step: 10403, epoch: 61, loss: 0.284498
global_step: 10404, epoch: 61, loss: 0.285433
global_step: 10405, epoch: 61, loss: 0.259786
global_step: 10406, epoch: 61, loss: 0.230603
global_step: 10407, epoch: 61, loss: 0.253396
global_step: 10408, epoch: 61, loss: 0.258342
global_step: 10409, epoch: 61, loss: 0.287763
global_step: 10410, epoch: 61, loss: 0.222103
global_step: 10411, epoch: 61, loss: 0.333505
global_step: 10412, epoch: 61, loss: 0.289872
global_step: 10413, epoch: 61, loss: 0.421890
global_step: 10414, epoch: 61, loss: 0.237691
global_step: 10415, epoch: 61, loss: 0.304305
global_step: 10416, epoch: 61, loss: 0.226980
global_step: 10417, epoch: 61, loss: 0.196093
global_step: 10418, epoch: 61, loss: 0.230414
global_step: 10419, epoch: 61, loss: 0.234247
global_step: 10420, epoch: 61, loss: 0.269743
global_step: 10421, epoch: 61, loss: 0.216428
global_step: 10422, epoch: 61, loss: 0.232469
global_step: 10423, epoch: 61, loss: 0.323919
global_step: 10424, epoch: 61, loss: 0.354023
global_step: 10425, epoch: 61, loss: 0.271949
global_step: 10426, epoch: 61, loss: 0.211540
global_step: 10427, epoch: 61, loss: 0.355404
global_step: 10428, epoch: 61, loss: 0.299552
global_step: 10429, epoch: 61, loss: 0.273927
global_step: 10430, epoch: 61, loss: 0.317161
global_step: 10431, epoch: 61, loss: 0.278293
global_step: 10432, epoch: 61, loss: 0.302660
global_step: 10433, epoch: 61, loss: 0.299204
global_step: 10434, epoch: 61, loss: 0.268786
global_step: 10435, epoch: 61, loss: 0.320343
global_step: 10436, epoch: 61, loss: 0.213389
global_step: 10437, epoch: 61, loss: 0.317999
global_step: 10438, epoch: 61, loss: 0.343158
global_step: 10439, epoch: 61, loss: 0.282247
global_step: 10440, epoch: 61, loss: 0.081761
epoch: 61
train	acc: 0.9653	macro: p 0.9724, r 0.9490, f1: 0.9602	micro: p 0.9653, r 0.9653, f1 0.9653	weighted_f1:0.9652
dev	acc: 0.5320	macro: p 0.3879, r 0.2983, f1: 0.3027	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4824
test	acc: 0.5759	macro: p 0.3727, r 0.2939, f1: 0.2988	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5255
global_step: 10441, epoch: 62, loss: 0.264304
global_step: 10442, epoch: 62, loss: 0.242489
global_step: 10443, epoch: 62, loss: 0.231013
global_step: 10444, epoch: 62, loss: 0.210741
global_step: 10445, epoch: 62, loss: 0.291666
global_step: 10446, epoch: 62, loss: 0.201940
global_step: 10447, epoch: 62, loss: 0.367972
global_step: 10448, epoch: 62, loss: 0.279595
global_step: 10449, epoch: 62, loss: 0.230827
global_step: 10450, epoch: 62, loss: 0.217745
global_step: 10451, epoch: 62, loss: 0.258093
global_step: 10452, epoch: 62, loss: 0.261904
global_step: 10453, epoch: 62, loss: 0.263455
global_step: 10454, epoch: 62, loss: 0.309138
global_step: 10455, epoch: 62, loss: 0.285044
global_step: 10456, epoch: 62, loss: 0.326427
global_step: 10457, epoch: 62, loss: 0.260870
global_step: 10458, epoch: 62, loss: 0.208104
global_step: 10459, epoch: 62, loss: 0.229834
global_step: 10460, epoch: 62, loss: 0.353987
global_step: 10461, epoch: 62, loss: 0.302945
global_step: 10462, epoch: 62, loss: 0.202848
global_step: 10463, epoch: 62, loss: 0.356436
global_step: 10464, epoch: 62, loss: 0.205550
global_step: 10465, epoch: 62, loss: 0.277923
global_step: 10466, epoch: 62, loss: 0.223707
global_step: 10467, epoch: 62, loss: 0.243963
global_step: 10468, epoch: 62, loss: 0.272419
global_step: 10469, epoch: 62, loss: 0.289500
global_step: 10470, epoch: 62, loss: 0.330785
global_step: 10471, epoch: 62, loss: 0.313487
global_step: 10472, epoch: 62, loss: 0.305693
global_step: 10473, epoch: 62, loss: 0.288337
global_step: 10474, epoch: 62, loss: 0.319828
global_step: 10475, epoch: 62, loss: 0.361311
global_step: 10476, epoch: 62, loss: 0.313299
global_step: 10477, epoch: 62, loss: 0.301379
global_step: 10478, epoch: 62, loss: 0.249034
global_step: 10479, epoch: 62, loss: 0.378672
global_step: 10480, epoch: 62, loss: 0.035616
epoch: 62
train	acc: 0.9653	macro: p 0.9712, r 0.9512, f1: 0.9608	micro: p 0.9653, r 0.9653, f1 0.9653	weighted_f1:0.9653
dev	acc: 0.5230	macro: p 0.3783, r 0.3016, f1: 0.3118	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4800
test	acc: 0.5655	macro: p 0.3519, r 0.3037, f1: 0.3137	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5275
global_step: 10481, epoch: 63, loss: 0.201023
global_step: 10482, epoch: 63, loss: 0.235727
global_step: 10483, epoch: 63, loss: 0.282028
global_step: 10484, epoch: 63, loss: 0.189121
global_step: 10485, epoch: 63, loss: 0.334751
global_step: 10486, epoch: 63, loss: 0.333132
global_step: 10487, epoch: 63, loss: 0.223847
global_step: 10488, epoch: 63, loss: 0.207902
global_step: 10489, epoch: 63, loss: 0.323803
global_step: 10490, epoch: 63, loss: 0.303772
global_step: 10491, epoch: 63, loss: 0.278328
global_step: 10492, epoch: 63, loss: 0.350186
global_step: 10493, epoch: 63, loss: 0.246656
global_step: 10494, epoch: 63, loss: 0.247950
global_step: 10495, epoch: 63, loss: 0.186292
global_step: 10496, epoch: 63, loss: 0.295911
global_step: 10497, epoch: 63, loss: 0.269865
global_step: 10498, epoch: 63, loss: 0.257760
global_step: 10499, epoch: 63, loss: 0.304479
global_step: 10500, epoch: 63, loss: 0.262366
global_step: 10501, epoch: 63, loss: 0.297544
global_step: 10502, epoch: 63, loss: 0.276368
global_step: 10503, epoch: 63, loss: 0.325928
global_step: 10504, epoch: 63, loss: 0.299947
global_step: 10505, epoch: 63, loss: 0.309986
global_step: 10506, epoch: 63, loss: 0.283004
global_step: 10507, epoch: 63, loss: 0.263150
global_step: 10508, epoch: 63, loss: 0.216095
global_step: 10509, epoch: 63, loss: 0.279922
global_step: 10510, epoch: 63, loss: 0.306562
global_step: 10511, epoch: 63, loss: 0.259698
global_step: 10512, epoch: 63, loss: 0.165270
global_step: 10513, epoch: 63, loss: 0.307494
global_step: 10514, epoch: 63, loss: 0.390986
global_step: 10515, epoch: 63, loss: 0.224416
global_step: 10516, epoch: 63, loss: 0.289766
global_step: 10517, epoch: 63, loss: 0.237572
global_step: 10518, epoch: 63, loss: 0.302509
global_step: 10519, epoch: 63, loss: 0.236212
global_step: 10520, epoch: 63, loss: 0.201358
epoch: 63
train	acc: 0.9670	macro: p 0.9682, r 0.9559, f1: 0.9618	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5176	macro: p 0.3383, r 0.3012, f1: 0.3029	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4804
test	acc: 0.5625	macro: p 0.3614, r 0.3088, f1: 0.3167	micro: p 0.5625, r 0.5625, f1 0.5625	weighted_f1:0.5324
global_step: 10521, epoch: 64, loss: 0.217731
global_step: 10522, epoch: 64, loss: 0.288999
global_step: 10523, epoch: 64, loss: 0.220705
global_step: 10524, epoch: 64, loss: 0.301537
global_step: 10525, epoch: 64, loss: 0.270976
global_step: 10526, epoch: 64, loss: 0.244273
global_step: 10527, epoch: 64, loss: 0.183455
global_step: 10528, epoch: 64, loss: 0.360190
global_step: 10529, epoch: 64, loss: 0.272231
global_step: 10530, epoch: 64, loss: 0.353240
global_step: 10531, epoch: 64, loss: 0.218524
global_step: 10532, epoch: 64, loss: 0.315136
global_step: 10533, epoch: 64, loss: 0.377423
global_step: 10534, epoch: 64, loss: 0.231113
global_step: 10535, epoch: 64, loss: 0.264435
global_step: 10536, epoch: 64, loss: 0.237567
global_step: 10537, epoch: 64, loss: 0.247370
global_step: 10538, epoch: 64, loss: 0.364361
global_step: 10539, epoch: 64, loss: 0.216406
global_step: 10540, epoch: 64, loss: 0.284550
global_step: 10541, epoch: 64, loss: 0.190026
global_step: 10542, epoch: 64, loss: 0.285581
global_step: 10543, epoch: 64, loss: 0.237744
global_step: 10544, epoch: 64, loss: 0.374445
global_step: 10545, epoch: 64, loss: 0.278211
global_step: 10546, epoch: 64, loss: 0.368451
global_step: 10547, epoch: 64, loss: 0.219149
global_step: 10548, epoch: 64, loss: 0.270252
global_step: 10549, epoch: 64, loss: 0.370825
global_step: 10550, epoch: 64, loss: 0.311829
global_step: 10551, epoch: 64, loss: 0.267076
global_step: 10552, epoch: 64, loss: 0.254437
global_step: 10553, epoch: 64, loss: 0.231981
global_step: 10554, epoch: 64, loss: 0.251387
global_step: 10555, epoch: 64, loss: 0.267744
global_step: 10556, epoch: 64, loss: 0.250847
global_step: 10557, epoch: 64, loss: 0.278696
global_step: 10558, epoch: 64, loss: 0.264638
global_step: 10559, epoch: 64, loss: 0.292470
global_step: 10560, epoch: 64, loss: 0.179173
epoch: 64
train	acc: 0.9639	macro: p 0.9719, r 0.9457, f1: 0.9582	micro: p 0.9639, r 0.9639, f1 0.9639	weighted_f1:0.9639
dev	acc: 0.5329	macro: p 0.3906, r 0.2886, f1: 0.2911	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4739
test	acc: 0.5778	macro: p 0.3700, r 0.2961, f1: 0.3020	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5251
global_step: 10561, epoch: 65, loss: 0.337637
global_step: 10562, epoch: 65, loss: 0.257678
global_step: 10563, epoch: 65, loss: 0.276154
global_step: 10564, epoch: 65, loss: 0.252384
global_step: 10565, epoch: 65, loss: 0.219739
global_step: 10566, epoch: 65, loss: 0.301663
global_step: 10567, epoch: 65, loss: 0.305078
global_step: 10568, epoch: 65, loss: 0.278768
global_step: 10569, epoch: 65, loss: 0.220534
global_step: 10570, epoch: 65, loss: 0.182609
global_step: 10571, epoch: 65, loss: 0.326292
global_step: 10572, epoch: 65, loss: 0.189672
global_step: 10573, epoch: 65, loss: 0.245826
global_step: 10574, epoch: 65, loss: 0.281461
global_step: 10575, epoch: 65, loss: 0.275609
global_step: 10576, epoch: 65, loss: 0.238768
global_step: 10577, epoch: 65, loss: 0.260644
global_step: 10578, epoch: 65, loss: 0.248078
global_step: 10579, epoch: 65, loss: 0.270526
global_step: 10580, epoch: 65, loss: 0.248621
global_step: 10581, epoch: 65, loss: 0.308096
global_step: 10582, epoch: 65, loss: 0.223779
global_step: 10583, epoch: 65, loss: 0.210277
global_step: 10584, epoch: 65, loss: 0.257911
global_step: 10585, epoch: 65, loss: 0.258083
global_step: 10586, epoch: 65, loss: 0.297587
global_step: 10587, epoch: 65, loss: 0.339010
global_step: 10588, epoch: 65, loss: 0.214456
global_step: 10589, epoch: 65, loss: 0.259318
global_step: 10590, epoch: 65, loss: 0.267849
global_step: 10591, epoch: 65, loss: 0.389413
global_step: 10592, epoch: 65, loss: 0.229214
global_step: 10593, epoch: 65, loss: 0.261065
global_step: 10594, epoch: 65, loss: 0.381891
global_step: 10595, epoch: 65, loss: 0.287846
global_step: 10596, epoch: 65, loss: 0.241306
global_step: 10597, epoch: 65, loss: 0.206531
global_step: 10598, epoch: 65, loss: 0.309082
global_step: 10599, epoch: 65, loss: 0.262629
global_step: 10600, epoch: 65, loss: 0.027601
epoch: 65
train	acc: 0.9649	macro: p 0.9724, r 0.9491, f1: 0.9602	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5131	macro: p 0.3315, r 0.2888, f1: 0.2880	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4684
test	acc: 0.5644	macro: p 0.3656, r 0.3079, f1: 0.3143	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5270
global_step: 10601, epoch: 66, loss: 0.196465
global_step: 10602, epoch: 66, loss: 0.207448
global_step: 10603, epoch: 66, loss: 0.243299
global_step: 10604, epoch: 66, loss: 0.270249
global_step: 10605, epoch: 66, loss: 0.257532
global_step: 10606, epoch: 66, loss: 0.226522
global_step: 10607, epoch: 66, loss: 0.260587
global_step: 10608, epoch: 66, loss: 0.342987
global_step: 10609, epoch: 66, loss: 0.220078
global_step: 10610, epoch: 66, loss: 0.246063
global_step: 10611, epoch: 66, loss: 0.233083
global_step: 10612, epoch: 66, loss: 0.238772
global_step: 10613, epoch: 66, loss: 0.206053
global_step: 10614, epoch: 66, loss: 0.260935
global_step: 10615, epoch: 66, loss: 0.204560
global_step: 10616, epoch: 66, loss: 0.220596
global_step: 10617, epoch: 66, loss: 0.239127
global_step: 10618, epoch: 66, loss: 0.214155
global_step: 10619, epoch: 66, loss: 0.186163
global_step: 10620, epoch: 66, loss: 0.247118
global_step: 10621, epoch: 66, loss: 0.348962
global_step: 10622, epoch: 66, loss: 0.297825
global_step: 10623, epoch: 66, loss: 0.283992
global_step: 10624, epoch: 66, loss: 0.304992
global_step: 10625, epoch: 66, loss: 0.264739
global_step: 10626, epoch: 66, loss: 0.282187
global_step: 10627, epoch: 66, loss: 0.255125
global_step: 10628, epoch: 66, loss: 0.297550
global_step: 10629, epoch: 66, loss: 0.266441
global_step: 10630, epoch: 66, loss: 0.222530
global_step: 10631, epoch: 66, loss: 0.261364
global_step: 10632, epoch: 66, loss: 0.330283
global_step: 10633, epoch: 66, loss: 0.358023
global_step: 10634, epoch: 66, loss: 0.256860
global_step: 10635, epoch: 66, loss: 0.312317
global_step: 10636, epoch: 66, loss: 0.271149
global_step: 10637, epoch: 66, loss: 0.225264
global_step: 10638, epoch: 66, loss: 0.291354
global_step: 10639, epoch: 66, loss: 0.269476
global_step: 10640, epoch: 66, loss: 0.013430
epoch: 66
train	acc: 0.9670	macro: p 0.9728, r 0.9525, f1: 0.9622	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5194	macro: p 0.3634, r 0.3016, f1: 0.3079	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4783
test	acc: 0.5693	macro: p 0.3564, r 0.3098, f1: 0.3151	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5334
global_step: 10641, epoch: 67, loss: 0.234819
global_step: 10642, epoch: 67, loss: 0.248922
global_step: 10643, epoch: 67, loss: 0.251953
global_step: 10644, epoch: 67, loss: 0.259750
global_step: 10645, epoch: 67, loss: 0.335590
global_step: 10646, epoch: 67, loss: 0.238650
global_step: 10647, epoch: 67, loss: 0.224276
global_step: 10648, epoch: 67, loss: 0.258467
global_step: 10649, epoch: 67, loss: 0.233192
global_step: 10650, epoch: 67, loss: 0.275644
global_step: 10651, epoch: 67, loss: 0.332533
global_step: 10652, epoch: 67, loss: 0.238101
global_step: 10653, epoch: 67, loss: 0.298288
global_step: 10654, epoch: 67, loss: 0.152157
global_step: 10655, epoch: 67, loss: 0.272855
global_step: 10656, epoch: 67, loss: 0.367928
global_step: 10657, epoch: 67, loss: 0.251590
global_step: 10658, epoch: 67, loss: 0.290076
global_step: 10659, epoch: 67, loss: 0.272871
global_step: 10660, epoch: 67, loss: 0.203267
global_step: 10661, epoch: 67, loss: 0.293115
global_step: 10662, epoch: 67, loss: 0.250101
global_step: 10663, epoch: 67, loss: 0.306892
global_step: 10664, epoch: 67, loss: 0.296457
global_step: 10665, epoch: 67, loss: 0.231899
global_step: 10666, epoch: 67, loss: 0.179958
global_step: 10667, epoch: 67, loss: 0.248835
global_step: 10668, epoch: 67, loss: 0.263631
global_step: 10669, epoch: 67, loss: 0.269271
global_step: 10670, epoch: 67, loss: 0.263126
global_step: 10671, epoch: 67, loss: 0.202858
global_step: 10672, epoch: 67, loss: 0.274681
global_step: 10673, epoch: 67, loss: 0.244367
global_step: 10674, epoch: 67, loss: 0.311748
global_step: 10675, epoch: 67, loss: 0.189602
global_step: 10676, epoch: 67, loss: 0.261493
global_step: 10677, epoch: 67, loss: 0.253746
global_step: 10678, epoch: 67, loss: 0.239690
global_step: 10679, epoch: 67, loss: 0.326898
global_step: 10680, epoch: 67, loss: 0.077277
epoch: 67
train	acc: 0.9668	macro: p 0.9733, r 0.9540, f1: 0.9632	micro: p 0.9668, r 0.9668, f1 0.9668	weighted_f1:0.9668
dev	acc: 0.5203	macro: p 0.3574, r 0.3043, f1: 0.3082	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4805
test	acc: 0.5667	macro: p 0.3605, r 0.3063, f1: 0.3123	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5293
global_step: 10681, epoch: 68, loss: 0.251480
global_step: 10682, epoch: 68, loss: 0.233639
global_step: 10683, epoch: 68, loss: 0.281783
global_step: 10684, epoch: 68, loss: 0.256994
global_step: 10685, epoch: 68, loss: 0.294349
global_step: 10686, epoch: 68, loss: 0.340359
global_step: 10687, epoch: 68, loss: 0.239337
global_step: 10688, epoch: 68, loss: 0.251905
global_step: 10689, epoch: 68, loss: 0.275227
global_step: 10690, epoch: 68, loss: 0.215793
global_step: 10691, epoch: 68, loss: 0.297327
global_step: 10692, epoch: 68, loss: 0.251473
global_step: 10693, epoch: 68, loss: 0.231438
global_step: 10694, epoch: 68, loss: 0.215001
global_step: 10695, epoch: 68, loss: 0.179773
global_step: 10696, epoch: 68, loss: 0.309886
global_step: 10697, epoch: 68, loss: 0.275066
global_step: 10698, epoch: 68, loss: 0.284077
global_step: 10699, epoch: 68, loss: 0.261497
global_step: 10700, epoch: 68, loss: 0.218149
global_step: 10701, epoch: 68, loss: 0.285915
global_step: 10702, epoch: 68, loss: 0.298096
global_step: 10703, epoch: 68, loss: 0.284525
global_step: 10704, epoch: 68, loss: 0.245694
global_step: 10705, epoch: 68, loss: 0.243824
global_step: 10706, epoch: 68, loss: 0.267313
global_step: 10707, epoch: 68, loss: 0.248915
global_step: 10708, epoch: 68, loss: 0.217878
global_step: 10709, epoch: 68, loss: 0.291792
global_step: 10710, epoch: 68, loss: 0.324308
global_step: 10711, epoch: 68, loss: 0.251480
global_step: 10712, epoch: 68, loss: 0.284163
global_step: 10713, epoch: 68, loss: 0.250011
global_step: 10714, epoch: 68, loss: 0.301819
global_step: 10715, epoch: 68, loss: 0.298488
global_step: 10716, epoch: 68, loss: 0.342376
global_step: 10717, epoch: 68, loss: 0.347790
global_step: 10718, epoch: 68, loss: 0.264114
global_step: 10719, epoch: 68, loss: 0.317914
global_step: 10720, epoch: 68, loss: 0.163873
epoch: 68
train	acc: 0.9676	macro: p 0.9709, r 0.9547, f1: 0.9625	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5041	macro: p 0.3544, r 0.3022, f1: 0.3053	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4714
test	acc: 0.5498	macro: p 0.3448, r 0.3072, f1: 0.3107	micro: p 0.5498, r 0.5498, f1 0.5498	weighted_f1:0.5232
global_step: 10721, epoch: 69, loss: 0.226059
global_step: 10722, epoch: 69, loss: 0.342878
global_step: 10723, epoch: 69, loss: 0.355037
global_step: 10724, epoch: 69, loss: 0.205746
global_step: 10725, epoch: 69, loss: 0.274004
global_step: 10726, epoch: 69, loss: 0.230421
global_step: 10727, epoch: 69, loss: 0.299755
global_step: 10728, epoch: 69, loss: 0.241667
global_step: 10729, epoch: 69, loss: 0.318518
global_step: 10730, epoch: 69, loss: 0.276334
global_step: 10731, epoch: 69, loss: 0.195680
global_step: 10732, epoch: 69, loss: 0.282706
global_step: 10733, epoch: 69, loss: 0.246965
global_step: 10734, epoch: 69, loss: 0.235059
global_step: 10735, epoch: 69, loss: 0.286225
global_step: 10736, epoch: 69, loss: 0.339771
global_step: 10737, epoch: 69, loss: 0.203762
global_step: 10738, epoch: 69, loss: 0.297011
global_step: 10739, epoch: 69, loss: 0.206179
global_step: 10740, epoch: 69, loss: 0.282564
global_step: 10741, epoch: 69, loss: 0.324486
global_step: 10742, epoch: 69, loss: 0.272376
global_step: 10743, epoch: 69, loss: 0.225760
global_step: 10744, epoch: 69, loss: 0.315976
global_step: 10745, epoch: 69, loss: 0.192224
global_step: 10746, epoch: 69, loss: 0.354928
global_step: 10747, epoch: 69, loss: 0.195637
global_step: 10748, epoch: 69, loss: 0.220291
global_step: 10749, epoch: 69, loss: 0.263471
global_step: 10750, epoch: 69, loss: 0.294024
global_step: 10751, epoch: 69, loss: 0.234486
global_step: 10752, epoch: 69, loss: 0.272783
global_step: 10753, epoch: 69, loss: 0.299079
global_step: 10754, epoch: 69, loss: 0.220502
global_step: 10755, epoch: 69, loss: 0.299707
global_step: 10756, epoch: 69, loss: 0.178651
global_step: 10757, epoch: 69, loss: 0.265133
global_step: 10758, epoch: 69, loss: 0.349041
global_step: 10759, epoch: 69, loss: 0.250673
global_step: 10760, epoch: 69, loss: 0.000876
epoch: 69
train	acc: 0.9676	macro: p 0.9740, r 0.9546, f1: 0.9639	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5266	macro: p 0.3759, r 0.3064, f1: 0.3168	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4830
test	acc: 0.5747	macro: p 0.3703, r 0.3063, f1: 0.3190	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5336
global_step: 10761, epoch: 70, loss: 0.272942
global_step: 10762, epoch: 70, loss: 0.220263
global_step: 10763, epoch: 70, loss: 0.178405
global_step: 10764, epoch: 70, loss: 0.238600
global_step: 10765, epoch: 70, loss: 0.244163
global_step: 10766, epoch: 70, loss: 0.286909
global_step: 10767, epoch: 70, loss: 0.240389
global_step: 10768, epoch: 70, loss: 0.205799
global_step: 10769, epoch: 70, loss: 0.210363
global_step: 10770, epoch: 70, loss: 0.274162
global_step: 10771, epoch: 70, loss: 0.183680
global_step: 10772, epoch: 70, loss: 0.218774
global_step: 10773, epoch: 70, loss: 0.149401
global_step: 10774, epoch: 70, loss: 0.207000
global_step: 10775, epoch: 70, loss: 0.274381
global_step: 10776, epoch: 70, loss: 0.163780
global_step: 10777, epoch: 70, loss: 0.279664
global_step: 10778, epoch: 70, loss: 0.283654
global_step: 10779, epoch: 70, loss: 0.323389
global_step: 10780, epoch: 70, loss: 0.227020
global_step: 10781, epoch: 70, loss: 0.290609
global_step: 10782, epoch: 70, loss: 0.239201
global_step: 10783, epoch: 70, loss: 0.205319
global_step: 10784, epoch: 70, loss: 0.233762
global_step: 10785, epoch: 70, loss: 0.221093
global_step: 10786, epoch: 70, loss: 0.288748
global_step: 10787, epoch: 70, loss: 0.219665
global_step: 10788, epoch: 70, loss: 0.259486
global_step: 10789, epoch: 70, loss: 0.271121
global_step: 10790, epoch: 70, loss: 0.362596
global_step: 10791, epoch: 70, loss: 0.337481
global_step: 10792, epoch: 70, loss: 0.304902
global_step: 10793, epoch: 70, loss: 0.251663
global_step: 10794, epoch: 70, loss: 0.225667
global_step: 10795, epoch: 70, loss: 0.271104
global_step: 10796, epoch: 70, loss: 0.239144
global_step: 10797, epoch: 70, loss: 0.290964
global_step: 10798, epoch: 70, loss: 0.323216
global_step: 10799, epoch: 70, loss: 0.245000
global_step: 10800, epoch: 70, loss: 0.260327
epoch: 70
train	acc: 0.9612	macro: p 0.9684, r 0.9448, f1: 0.9559	micro: p 0.9612, r 0.9612, f1 0.9612	weighted_f1:0.9613
dev	acc: 0.5176	macro: p 0.3542, r 0.2950, f1: 0.2959	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4776
test	acc: 0.5682	macro: p 0.3720, r 0.3114, f1: 0.3185	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5354
global_step: 10801, epoch: 71, loss: 0.220294
global_step: 10802, epoch: 71, loss: 0.223482
global_step: 10803, epoch: 71, loss: 0.228271
global_step: 10804, epoch: 71, loss: 0.230955
global_step: 10805, epoch: 71, loss: 0.196945
global_step: 10806, epoch: 71, loss: 0.157951
global_step: 10807, epoch: 71, loss: 0.190624
global_step: 10808, epoch: 71, loss: 0.238384
global_step: 10809, epoch: 71, loss: 0.240536
global_step: 10810, epoch: 71, loss: 0.217048
global_step: 10811, epoch: 71, loss: 0.195142
global_step: 10812, epoch: 71, loss: 0.189152
global_step: 10813, epoch: 71, loss: 0.240720
global_step: 10814, epoch: 71, loss: 0.285749
global_step: 10815, epoch: 71, loss: 0.262918
global_step: 10816, epoch: 71, loss: 0.218244
global_step: 10817, epoch: 71, loss: 0.266364
global_step: 10818, epoch: 71, loss: 0.242443
global_step: 10819, epoch: 71, loss: 0.248000
global_step: 10820, epoch: 71, loss: 0.264835
global_step: 10821, epoch: 71, loss: 0.225594
global_step: 10822, epoch: 71, loss: 0.259976
global_step: 10823, epoch: 71, loss: 0.229603
global_step: 10824, epoch: 71, loss: 0.268022
global_step: 10825, epoch: 71, loss: 0.371053
global_step: 10826, epoch: 71, loss: 0.188677
global_step: 10827, epoch: 71, loss: 0.272623
global_step: 10828, epoch: 71, loss: 0.299854
global_step: 10829, epoch: 71, loss: 0.227708
global_step: 10830, epoch: 71, loss: 0.340295
global_step: 10831, epoch: 71, loss: 0.284915
global_step: 10832, epoch: 71, loss: 0.341967
global_step: 10833, epoch: 71, loss: 0.262951
global_step: 10834, epoch: 71, loss: 0.325422
global_step: 10835, epoch: 71, loss: 0.294214
global_step: 10836, epoch: 71, loss: 0.202652
global_step: 10837, epoch: 71, loss: 0.230259
global_step: 10838, epoch: 71, loss: 0.230952
global_step: 10839, epoch: 71, loss: 0.388601
global_step: 10840, epoch: 71, loss: 1.588709
epoch: 71
train	acc: 0.9645	macro: p 0.9660, r 0.9545, f1: 0.9599	micro: p 0.9645, r 0.9645, f1 0.9645	weighted_f1:0.9645
dev	acc: 0.5023	macro: p 0.3789, r 0.3253, f1: 0.3278	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4769
test	acc: 0.5349	macro: p 0.3344, r 0.3045, f1: 0.3084	micro: p 0.5349, r 0.5349, f1 0.5349	weighted_f1:0.5155
global_step: 10841, epoch: 72, loss: 0.297281
global_step: 10842, epoch: 72, loss: 0.268831
global_step: 10843, epoch: 72, loss: 0.268331
global_step: 10844, epoch: 72, loss: 0.225630
global_step: 10845, epoch: 72, loss: 0.233990
global_step: 10846, epoch: 72, loss: 0.275585
global_step: 10847, epoch: 72, loss: 0.247216
global_step: 10848, epoch: 72, loss: 0.266714
global_step: 10849, epoch: 72, loss: 0.290742
global_step: 10850, epoch: 72, loss: 0.178251
global_step: 10851, epoch: 72, loss: 0.184252
global_step: 10852, epoch: 72, loss: 0.311010
global_step: 10853, epoch: 72, loss: 0.314177
global_step: 10854, epoch: 72, loss: 0.252081
global_step: 10855, epoch: 72, loss: 0.371787
global_step: 10856, epoch: 72, loss: 0.205569
global_step: 10857, epoch: 72, loss: 0.330462
global_step: 10858, epoch: 72, loss: 0.191540
global_step: 10859, epoch: 72, loss: 0.233207
global_step: 10860, epoch: 72, loss: 0.233914
global_step: 10861, epoch: 72, loss: 0.245251
global_step: 10862, epoch: 72, loss: 0.210543
global_step: 10863, epoch: 72, loss: 0.327233
global_step: 10864, epoch: 72, loss: 0.261059
global_step: 10865, epoch: 72, loss: 0.192118
global_step: 10866, epoch: 72, loss: 0.183618
global_step: 10867, epoch: 72, loss: 0.209787
global_step: 10868, epoch: 72, loss: 0.225831
global_step: 10869, epoch: 72, loss: 0.283209
global_step: 10870, epoch: 72, loss: 0.250440
global_step: 10871, epoch: 72, loss: 0.281899
global_step: 10872, epoch: 72, loss: 0.359594
global_step: 10873, epoch: 72, loss: 0.260917
global_step: 10874, epoch: 72, loss: 0.221673
global_step: 10875, epoch: 72, loss: 0.318491
global_step: 10876, epoch: 72, loss: 0.253472
global_step: 10877, epoch: 72, loss: 0.269844
global_step: 10878, epoch: 72, loss: 0.202720
global_step: 10879, epoch: 72, loss: 0.201083
global_step: 10880, epoch: 72, loss: 0.945226
epoch: 72
train	acc: 0.9617	macro: p 0.9694, r 0.9469, f1: 0.9576	micro: p 0.9617, r 0.9617, f1 0.9617	weighted_f1:0.9616
dev	acc: 0.5032	macro: p 0.3810, r 0.2922, f1: 0.3040	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.4633
test	acc: 0.5563	macro: p 0.3398, r 0.2931, f1: 0.2986	micro: p 0.5563, r 0.5563, f1 0.5563	weighted_f1:0.5176
global_step: 10881, epoch: 73, loss: 0.195541
global_step: 10882, epoch: 73, loss: 0.271648
global_step: 10883, epoch: 73, loss: 0.254922
global_step: 10884, epoch: 73, loss: 0.228945
global_step: 10885, epoch: 73, loss: 0.210634
global_step: 10886, epoch: 73, loss: 0.249707
global_step: 10887, epoch: 73, loss: 0.178064
global_step: 10888, epoch: 73, loss: 0.312428
global_step: 10889, epoch: 73, loss: 0.308431
global_step: 10890, epoch: 73, loss: 0.213264
global_step: 10891, epoch: 73, loss: 0.169480
global_step: 10892, epoch: 73, loss: 0.232427
global_step: 10893, epoch: 73, loss: 0.317498
global_step: 10894, epoch: 73, loss: 0.187853
global_step: 10895, epoch: 73, loss: 0.232616
global_step: 10896, epoch: 73, loss: 0.263776
global_step: 10897, epoch: 73, loss: 0.186876
global_step: 10898, epoch: 73, loss: 0.220882
global_step: 10899, epoch: 73, loss: 0.306643
global_step: 10900, epoch: 73, loss: 0.188968
global_step: 10901, epoch: 73, loss: 0.230830
global_step: 10902, epoch: 73, loss: 0.210289
global_step: 10903, epoch: 73, loss: 0.231624
global_step: 10904, epoch: 73, loss: 0.313928
global_step: 10905, epoch: 73, loss: 0.297340
global_step: 10906, epoch: 73, loss: 0.290737
global_step: 10907, epoch: 73, loss: 0.260750
global_step: 10908, epoch: 73, loss: 0.254132
global_step: 10909, epoch: 73, loss: 0.235794
global_step: 10910, epoch: 73, loss: 0.244249
global_step: 10911, epoch: 73, loss: 0.199703
global_step: 10912, epoch: 73, loss: 0.278042
global_step: 10913, epoch: 73, loss: 0.202815
global_step: 10914, epoch: 73, loss: 0.234891
global_step: 10915, epoch: 73, loss: 0.215896
global_step: 10916, epoch: 73, loss: 0.237982
global_step: 10917, epoch: 73, loss: 0.242641
global_step: 10918, epoch: 73, loss: 0.256715
global_step: 10919, epoch: 73, loss: 0.232834
global_step: 10920, epoch: 73, loss: 0.022738
epoch: 73
train	acc: 0.9670	macro: p 0.9695, r 0.9569, f1: 0.9630	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5221	macro: p 0.3491, r 0.3026, f1: 0.3062	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4812
test	acc: 0.5697	macro: p 0.3521, r 0.3103, f1: 0.3176	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5338
global_step: 10921, epoch: 74, loss: 0.144663
global_step: 10922, epoch: 74, loss: 0.214997
global_step: 10923, epoch: 74, loss: 0.189925
global_step: 10924, epoch: 74, loss: 0.265873
global_step: 10925, epoch: 74, loss: 0.225335
global_step: 10926, epoch: 74, loss: 0.223144
global_step: 10927, epoch: 74, loss: 0.291773
global_step: 10928, epoch: 74, loss: 0.269666
global_step: 10929, epoch: 74, loss: 0.220386
global_step: 10930, epoch: 74, loss: 0.230966
global_step: 10931, epoch: 74, loss: 0.215536
global_step: 10932, epoch: 74, loss: 0.230120
global_step: 10933, epoch: 74, loss: 0.333259
global_step: 10934, epoch: 74, loss: 0.289150
global_step: 10935, epoch: 74, loss: 0.261401
global_step: 10936, epoch: 74, loss: 0.197889
global_step: 10937, epoch: 74, loss: 0.247444
global_step: 10938, epoch: 74, loss: 0.256876
global_step: 10939, epoch: 74, loss: 0.245922
global_step: 10940, epoch: 74, loss: 0.276762
global_step: 10941, epoch: 74, loss: 0.222775
global_step: 10942, epoch: 74, loss: 0.245015
global_step: 10943, epoch: 74, loss: 0.246632
global_step: 10944, epoch: 74, loss: 0.233110
global_step: 10945, epoch: 74, loss: 0.207129
global_step: 10946, epoch: 74, loss: 0.229177
global_step: 10947, epoch: 74, loss: 0.271463
global_step: 10948, epoch: 74, loss: 0.180437
global_step: 10949, epoch: 74, loss: 0.267104
global_step: 10950, epoch: 74, loss: 0.263925
global_step: 10951, epoch: 74, loss: 0.258435
global_step: 10952, epoch: 74, loss: 0.311215
global_step: 10953, epoch: 74, loss: 0.269995
global_step: 10954, epoch: 74, loss: 0.184017
global_step: 10955, epoch: 74, loss: 0.230892
global_step: 10956, epoch: 74, loss: 0.272258
global_step: 10957, epoch: 74, loss: 0.320575
global_step: 10958, epoch: 74, loss: 0.187923
global_step: 10959, epoch: 74, loss: 0.257217
global_step: 10960, epoch: 74, loss: 0.119200
epoch: 74
train	acc: 0.9670	macro: p 0.9686, r 0.9559, f1: 0.9620	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5239	macro: p 0.3489, r 0.3051, f1: 0.3123	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4851
test	acc: 0.5617	macro: p 0.3498, r 0.3063, f1: 0.3148	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5274
global_step: 10961, epoch: 75, loss: 0.211551
global_step: 10962, epoch: 75, loss: 0.276286
global_step: 10963, epoch: 75, loss: 0.325753
global_step: 10964, epoch: 75, loss: 0.281329
global_step: 10965, epoch: 75, loss: 0.274821
global_step: 10966, epoch: 75, loss: 0.213855
global_step: 10967, epoch: 75, loss: 0.177799
global_step: 10968, epoch: 75, loss: 0.248367
global_step: 10969, epoch: 75, loss: 0.237839
global_step: 10970, epoch: 75, loss: 0.230560
global_step: 10971, epoch: 75, loss: 0.213888
global_step: 10972, epoch: 75, loss: 0.257257
global_step: 10973, epoch: 75, loss: 0.227048
global_step: 10974, epoch: 75, loss: 0.207805
global_step: 10975, epoch: 75, loss: 0.220121
global_step: 10976, epoch: 75, loss: 0.171042
global_step: 10977, epoch: 75, loss: 0.184162
global_step: 10978, epoch: 75, loss: 0.259216
global_step: 10979, epoch: 75, loss: 0.198719
global_step: 10980, epoch: 75, loss: 0.239431
global_step: 10981, epoch: 75, loss: 0.202868
global_step: 10982, epoch: 75, loss: 0.225944
global_step: 10983, epoch: 75, loss: 0.257964
global_step: 10984, epoch: 75, loss: 0.228326
global_step: 10985, epoch: 75, loss: 0.212858
global_step: 10986, epoch: 75, loss: 0.304267
global_step: 10987, epoch: 75, loss: 0.282955
global_step: 10988, epoch: 75, loss: 0.251525
global_step: 10989, epoch: 75, loss: 0.302514
global_step: 10990, epoch: 75, loss: 0.247744
global_step: 10991, epoch: 75, loss: 0.227258
global_step: 10992, epoch: 75, loss: 0.170199
global_step: 10993, epoch: 75, loss: 0.338314
global_step: 10994, epoch: 75, loss: 0.253904
global_step: 10995, epoch: 75, loss: 0.317010
global_step: 10996, epoch: 75, loss: 0.280147
global_step: 10997, epoch: 75, loss: 0.216134
global_step: 10998, epoch: 75, loss: 0.210392
global_step: 10999, epoch: 75, loss: 0.266439
global_step: 11000, epoch: 75, loss: 0.571702
epoch: 75
train	acc: 0.9671	macro: p 0.9723, r 0.9541, f1: 0.9629	micro: p 0.9671, r 0.9671, f1 0.9671	weighted_f1:0.9671
dev	acc: 0.5266	macro: p 0.3405, r 0.2947, f1: 0.3006	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4822
test	acc: 0.5659	macro: p 0.3631, r 0.3036, f1: 0.3167	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5271
global_step: 11001, epoch: 76, loss: 0.187908
global_step: 11002, epoch: 76, loss: 0.218606
global_step: 11003, epoch: 76, loss: 0.213516
global_step: 11004, epoch: 76, loss: 0.220360
global_step: 11005, epoch: 76, loss: 0.227696
global_step: 11006, epoch: 76, loss: 0.239444
global_step: 11007, epoch: 76, loss: 0.174090
global_step: 11008, epoch: 76, loss: 0.196456
global_step: 11009, epoch: 76, loss: 0.219634
global_step: 11010, epoch: 76, loss: 0.196057
global_step: 11011, epoch: 76, loss: 0.238935
global_step: 11012, epoch: 76, loss: 0.215388
global_step: 11013, epoch: 76, loss: 0.204622
global_step: 11014, epoch: 76, loss: 0.221401
global_step: 11015, epoch: 76, loss: 0.254799
global_step: 11016, epoch: 76, loss: 0.211939
global_step: 11017, epoch: 76, loss: 0.228447
global_step: 11018, epoch: 76, loss: 0.228443
global_step: 11019, epoch: 76, loss: 0.225020
global_step: 11020, epoch: 76, loss: 0.230332
global_step: 11021, epoch: 76, loss: 0.258862
global_step: 11022, epoch: 76, loss: 0.269145
global_step: 11023, epoch: 76, loss: 0.336347
global_step: 11024, epoch: 76, loss: 0.204993
global_step: 11025, epoch: 76, loss: 0.217547
global_step: 11026, epoch: 76, loss: 0.264691
global_step: 11027, epoch: 76, loss: 0.212203
global_step: 11028, epoch: 76, loss: 0.246011
global_step: 11029, epoch: 76, loss: 0.221019
global_step: 11030, epoch: 76, loss: 0.251421
global_step: 11031, epoch: 76, loss: 0.284863
global_step: 11032, epoch: 76, loss: 0.243507
global_step: 11033, epoch: 76, loss: 0.349947
global_step: 11034, epoch: 76, loss: 0.267615
global_step: 11035, epoch: 76, loss: 0.307866
global_step: 11036, epoch: 76, loss: 0.290278
global_step: 11037, epoch: 76, loss: 0.266212
global_step: 11038, epoch: 76, loss: 0.185015
global_step: 11039, epoch: 76, loss: 0.251810
global_step: 11040, epoch: 76, loss: 0.023440
epoch: 76
train	acc: 0.9689	macro: p 0.9716, r 0.9593, f1: 0.9651	micro: p 0.9689, r 0.9689, f1 0.9689	weighted_f1:0.9689
dev	acc: 0.5293	macro: p 0.3858, r 0.3275, f1: 0.3351	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4944
test	acc: 0.5663	macro: p 0.3382, r 0.3157, f1: 0.3181	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5351
global_step: 11041, epoch: 77, loss: 0.197623
global_step: 11042, epoch: 77, loss: 0.153663
global_step: 11043, epoch: 77, loss: 0.284916
global_step: 11044, epoch: 77, loss: 0.202961
global_step: 11045, epoch: 77, loss: 0.233182
global_step: 11046, epoch: 77, loss: 0.292510
global_step: 11047, epoch: 77, loss: 0.207022
global_step: 11048, epoch: 77, loss: 0.266342
global_step: 11049, epoch: 77, loss: 0.196901
global_step: 11050, epoch: 77, loss: 0.218866
global_step: 11051, epoch: 77, loss: 0.224190
global_step: 11052, epoch: 77, loss: 0.207005
global_step: 11053, epoch: 77, loss: 0.246257
global_step: 11054, epoch: 77, loss: 0.260509
global_step: 11055, epoch: 77, loss: 0.186282
global_step: 11056, epoch: 77, loss: 0.251245
global_step: 11057, epoch: 77, loss: 0.185526
global_step: 11058, epoch: 77, loss: 0.211635
global_step: 11059, epoch: 77, loss: 0.227654
global_step: 11060, epoch: 77, loss: 0.214896
global_step: 11061, epoch: 77, loss: 0.219613
global_step: 11062, epoch: 77, loss: 0.290701
global_step: 11063, epoch: 77, loss: 0.218311
global_step: 11064, epoch: 77, loss: 0.208163
global_step: 11065, epoch: 77, loss: 0.246867
global_step: 11066, epoch: 77, loss: 0.267458
global_step: 11067, epoch: 77, loss: 0.206265
global_step: 11068, epoch: 77, loss: 0.223256
global_step: 11069, epoch: 77, loss: 0.262876
global_step: 11070, epoch: 77, loss: 0.161141
global_step: 11071, epoch: 77, loss: 0.211055
global_step: 11072, epoch: 77, loss: 0.232320
global_step: 11073, epoch: 77, loss: 0.282824
global_step: 11074, epoch: 77, loss: 0.246830
global_step: 11075, epoch: 77, loss: 0.272665
global_step: 11076, epoch: 77, loss: 0.257324
global_step: 11077, epoch: 77, loss: 0.200674
global_step: 11078, epoch: 77, loss: 0.285991
global_step: 11079, epoch: 77, loss: 0.283999
global_step: 11080, epoch: 77, loss: 0.083349
epoch: 77
train	acc: 0.9662	macro: p 0.9709, r 0.9542, f1: 0.9622	micro: p 0.9662, r 0.9662, f1 0.9662	weighted_f1:0.9662
dev	acc: 0.5176	macro: p 0.3666, r 0.3042, f1: 0.3093	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4831
test	acc: 0.5636	macro: p 0.3531, r 0.3098, f1: 0.3168	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5359
global_step: 11081, epoch: 78, loss: 0.220600
global_step: 11082, epoch: 78, loss: 0.325018
global_step: 11083, epoch: 78, loss: 0.235592
global_step: 11084, epoch: 78, loss: 0.253701
global_step: 11085, epoch: 78, loss: 0.216279
global_step: 11086, epoch: 78, loss: 0.202313
global_step: 11087, epoch: 78, loss: 0.319385
global_step: 11088, epoch: 78, loss: 0.204195
global_step: 11089, epoch: 78, loss: 0.295425
global_step: 11090, epoch: 78, loss: 0.142800
global_step: 11091, epoch: 78, loss: 0.191737
global_step: 11092, epoch: 78, loss: 0.220876
global_step: 11093, epoch: 78, loss: 0.254986
global_step: 11094, epoch: 78, loss: 0.264689
global_step: 11095, epoch: 78, loss: 0.287272
global_step: 11096, epoch: 78, loss: 0.186201
global_step: 11097, epoch: 78, loss: 0.201377
global_step: 11098, epoch: 78, loss: 0.234474
global_step: 11099, epoch: 78, loss: 0.216340
global_step: 11100, epoch: 78, loss: 0.255541
global_step: 11101, epoch: 78, loss: 0.223075
global_step: 11102, epoch: 78, loss: 0.271492
global_step: 11103, epoch: 78, loss: 0.348622
global_step: 11104, epoch: 78, loss: 0.190819
global_step: 11105, epoch: 78, loss: 0.228865
global_step: 11106, epoch: 78, loss: 0.305820
global_step: 11107, epoch: 78, loss: 0.269067
global_step: 11108, epoch: 78, loss: 0.260113
global_step: 11109, epoch: 78, loss: 0.263496
global_step: 11110, epoch: 78, loss: 0.185328
global_step: 11111, epoch: 78, loss: 0.211326
global_step: 11112, epoch: 78, loss: 0.309855
global_step: 11113, epoch: 78, loss: 0.247651
global_step: 11114, epoch: 78, loss: 0.224432
global_step: 11115, epoch: 78, loss: 0.235996
global_step: 11116, epoch: 78, loss: 0.203646
global_step: 11117, epoch: 78, loss: 0.247088
global_step: 11118, epoch: 78, loss: 0.203304
global_step: 11119, epoch: 78, loss: 0.337141
global_step: 11120, epoch: 78, loss: 0.439963
epoch: 78
train	acc: 0.9663	macro: p 0.9733, r 0.9502, f1: 0.9612	micro: p 0.9663, r 0.9663, f1 0.9663	weighted_f1:0.9663
dev	acc: 0.5212	macro: p 0.3891, r 0.3042, f1: 0.3113	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4750
test	acc: 0.5739	macro: p 0.3791, r 0.3048, f1: 0.3122	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5282
global_step: 11121, epoch: 79, loss: 0.240049
global_step: 11122, epoch: 79, loss: 0.190392
global_step: 11123, epoch: 79, loss: 0.184687
global_step: 11124, epoch: 79, loss: 0.293843
global_step: 11125, epoch: 79, loss: 0.248796
global_step: 11126, epoch: 79, loss: 0.165809
global_step: 11127, epoch: 79, loss: 0.161596
global_step: 11128, epoch: 79, loss: 0.160624
global_step: 11129, epoch: 79, loss: 0.241949
global_step: 11130, epoch: 79, loss: 0.196755
global_step: 11131, epoch: 79, loss: 0.249066
global_step: 11132, epoch: 79, loss: 0.253163
global_step: 11133, epoch: 79, loss: 0.238371
global_step: 11134, epoch: 79, loss: 0.175313
global_step: 11135, epoch: 79, loss: 0.159656
global_step: 11136, epoch: 79, loss: 0.285918
global_step: 11137, epoch: 79, loss: 0.247203
global_step: 11138, epoch: 79, loss: 0.267052
global_step: 11139, epoch: 79, loss: 0.211229
global_step: 11140, epoch: 79, loss: 0.212210
global_step: 11141, epoch: 79, loss: 0.245086
global_step: 11142, epoch: 79, loss: 0.275297
global_step: 11143, epoch: 79, loss: 0.225966
global_step: 11144, epoch: 79, loss: 0.165632
global_step: 11145, epoch: 79, loss: 0.256891
global_step: 11146, epoch: 79, loss: 0.377685
global_step: 11147, epoch: 79, loss: 0.169325
global_step: 11148, epoch: 79, loss: 0.296930
global_step: 11149, epoch: 79, loss: 0.277097
global_step: 11150, epoch: 79, loss: 0.246321
global_step: 11151, epoch: 79, loss: 0.218812
global_step: 11152, epoch: 79, loss: 0.277027
global_step: 11153, epoch: 79, loss: 0.260053
global_step: 11154, epoch: 79, loss: 0.268292
global_step: 11155, epoch: 79, loss: 0.239315
global_step: 11156, epoch: 79, loss: 0.233997
global_step: 11157, epoch: 79, loss: 0.170338
global_step: 11158, epoch: 79, loss: 0.240079
global_step: 11159, epoch: 79, loss: 0.250502
global_step: 11160, epoch: 79, loss: 0.117546
epoch: 79
train	acc: 0.9658	macro: p 0.9747, r 0.9525, f1: 0.9632	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9656
dev	acc: 0.5230	macro: p 0.3937, r 0.3053, f1: 0.3145	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4815
test	acc: 0.5640	macro: p 0.3716, r 0.3020, f1: 0.3115	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5259
global_step: 11161, epoch: 80, loss: 0.242185
global_step: 11162, epoch: 80, loss: 0.249876
global_step: 11163, epoch: 80, loss: 0.215810
global_step: 11164, epoch: 80, loss: 0.175174
global_step: 11165, epoch: 80, loss: 0.279965
global_step: 11166, epoch: 80, loss: 0.190485
global_step: 11167, epoch: 80, loss: 0.245090
global_step: 11168, epoch: 80, loss: 0.163305
global_step: 11169, epoch: 80, loss: 0.163356
global_step: 11170, epoch: 80, loss: 0.244736
global_step: 11171, epoch: 80, loss: 0.315980
global_step: 11172, epoch: 80, loss: 0.210510
global_step: 11173, epoch: 80, loss: 0.232707
global_step: 11174, epoch: 80, loss: 0.233433
global_step: 11175, epoch: 80, loss: 0.197364
global_step: 11176, epoch: 80, loss: 0.195997
global_step: 11177, epoch: 80, loss: 0.233164
global_step: 11178, epoch: 80, loss: 0.263936
global_step: 11179, epoch: 80, loss: 0.244686
global_step: 11180, epoch: 80, loss: 0.226342
global_step: 11181, epoch: 80, loss: 0.274443
global_step: 11182, epoch: 80, loss: 0.205608
global_step: 11183, epoch: 80, loss: 0.239923
global_step: 11184, epoch: 80, loss: 0.220612
global_step: 11185, epoch: 80, loss: 0.204007
global_step: 11186, epoch: 80, loss: 0.278482
global_step: 11187, epoch: 80, loss: 0.260028
global_step: 11188, epoch: 80, loss: 0.161086
global_step: 11189, epoch: 80, loss: 0.302797
global_step: 11190, epoch: 80, loss: 0.229713
global_step: 11191, epoch: 80, loss: 0.294514
global_step: 11192, epoch: 80, loss: 0.190471
global_step: 11193, epoch: 80, loss: 0.253039
global_step: 11194, epoch: 80, loss: 0.207424
global_step: 11195, epoch: 80, loss: 0.270279
global_step: 11196, epoch: 80, loss: 0.175938
global_step: 11197, epoch: 80, loss: 0.238824
global_step: 11198, epoch: 80, loss: 0.272919
global_step: 11199, epoch: 80, loss: 0.185119
global_step: 11200, epoch: 80, loss: 0.000434
epoch: 80
train	acc: 0.9691	macro: p 0.9727, r 0.9592, f1: 0.9657	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5230	macro: p 0.3391, r 0.3008, f1: 0.3034	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4828
test	acc: 0.5655	macro: p 0.3452, r 0.3067, f1: 0.3129	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5323
global_step: 11201, epoch: 81, loss: 0.212752
global_step: 11202, epoch: 81, loss: 0.281926
global_step: 11203, epoch: 81, loss: 0.286842
global_step: 11204, epoch: 81, loss: 0.220707
global_step: 11205, epoch: 81, loss: 0.208842
global_step: 11206, epoch: 81, loss: 0.249347
global_step: 11207, epoch: 81, loss: 0.246817
global_step: 11208, epoch: 81, loss: 0.173688
global_step: 11209, epoch: 81, loss: 0.250565
global_step: 11210, epoch: 81, loss: 0.169769
global_step: 11211, epoch: 81, loss: 0.206185
global_step: 11212, epoch: 81, loss: 0.239765
global_step: 11213, epoch: 81, loss: 0.225405
global_step: 11214, epoch: 81, loss: 0.221450
global_step: 11215, epoch: 81, loss: 0.259278
global_step: 11216, epoch: 81, loss: 0.285771
global_step: 11217, epoch: 81, loss: 0.273945
global_step: 11218, epoch: 81, loss: 0.193244
global_step: 11219, epoch: 81, loss: 0.146590
global_step: 11220, epoch: 81, loss: 0.195088
global_step: 11221, epoch: 81, loss: 0.203768
global_step: 11222, epoch: 81, loss: 0.203772
global_step: 11223, epoch: 81, loss: 0.265860
global_step: 11224, epoch: 81, loss: 0.200883
global_step: 11225, epoch: 81, loss: 0.287043
global_step: 11226, epoch: 81, loss: 0.175787
global_step: 11227, epoch: 81, loss: 0.235882
global_step: 11228, epoch: 81, loss: 0.174554
global_step: 11229, epoch: 81, loss: 0.261982
global_step: 11230, epoch: 81, loss: 0.221211
global_step: 11231, epoch: 81, loss: 0.217538
global_step: 11232, epoch: 81, loss: 0.180721
global_step: 11233, epoch: 81, loss: 0.169172
global_step: 11234, epoch: 81, loss: 0.216248
global_step: 11235, epoch: 81, loss: 0.183730
global_step: 11236, epoch: 81, loss: 0.296816
global_step: 11237, epoch: 81, loss: 0.259700
global_step: 11238, epoch: 81, loss: 0.254392
global_step: 11239, epoch: 81, loss: 0.201871
global_step: 11240, epoch: 81, loss: 0.152963
epoch: 81
train	acc: 0.9659	macro: p 0.9736, r 0.9544, f1: 0.9636	micro: p 0.9659, r 0.9659, f1 0.9659	weighted_f1:0.9658
dev	acc: 0.5203	macro: p 0.3886, r 0.2951, f1: 0.3042	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4735
test	acc: 0.5617	macro: p 0.3627, r 0.2938, f1: 0.3051	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5194
global_step: 11241, epoch: 82, loss: 0.292908
global_step: 11242, epoch: 82, loss: 0.243378
global_step: 11243, epoch: 82, loss: 0.175378
global_step: 11244, epoch: 82, loss: 0.281239
global_step: 11245, epoch: 82, loss: 0.224567
global_step: 11246, epoch: 82, loss: 0.233347
global_step: 11247, epoch: 82, loss: 0.199736
global_step: 11248, epoch: 82, loss: 0.239127
global_step: 11249, epoch: 82, loss: 0.172782
global_step: 11250, epoch: 82, loss: 0.155753
global_step: 11251, epoch: 82, loss: 0.174721
global_step: 11252, epoch: 82, loss: 0.278633
global_step: 11253, epoch: 82, loss: 0.233024
global_step: 11254, epoch: 82, loss: 0.244187
global_step: 11255, epoch: 82, loss: 0.177480
global_step: 11256, epoch: 82, loss: 0.220675
global_step: 11257, epoch: 82, loss: 0.236705
global_step: 11258, epoch: 82, loss: 0.278977
global_step: 11259, epoch: 82, loss: 0.217423
global_step: 11260, epoch: 82, loss: 0.223485
global_step: 11261, epoch: 82, loss: 0.204877
global_step: 11262, epoch: 82, loss: 0.281205
global_step: 11263, epoch: 82, loss: 0.199033
global_step: 11264, epoch: 82, loss: 0.252170
global_step: 11265, epoch: 82, loss: 0.168382
global_step: 11266, epoch: 82, loss: 0.166280
global_step: 11267, epoch: 82, loss: 0.217898
global_step: 11268, epoch: 82, loss: 0.248443
global_step: 11269, epoch: 82, loss: 0.366331
global_step: 11270, epoch: 82, loss: 0.319961
global_step: 11271, epoch: 82, loss: 0.334305
global_step: 11272, epoch: 82, loss: 0.222407
global_step: 11273, epoch: 82, loss: 0.234187
global_step: 11274, epoch: 82, loss: 0.158600
global_step: 11275, epoch: 82, loss: 0.219039
global_step: 11276, epoch: 82, loss: 0.185538
global_step: 11277, epoch: 82, loss: 0.278373
global_step: 11278, epoch: 82, loss: 0.182150
global_step: 11279, epoch: 82, loss: 0.220178
global_step: 11280, epoch: 82, loss: 0.140297
epoch: 82
train	acc: 0.9691	macro: p 0.9723, r 0.9597, f1: 0.9658	micro: p 0.9691, r 0.9691, f1 0.9691	weighted_f1:0.9691
dev	acc: 0.5275	macro: p 0.3437, r 0.3019, f1: 0.3034	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4843
test	acc: 0.5655	macro: p 0.3437, r 0.3045, f1: 0.3099	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.5290
global_step: 11281, epoch: 83, loss: 0.269177
global_step: 11282, epoch: 83, loss: 0.195409
global_step: 11283, epoch: 83, loss: 0.230988
global_step: 11284, epoch: 83, loss: 0.166612
global_step: 11285, epoch: 83, loss: 0.377325
global_step: 11286, epoch: 83, loss: 0.292667
global_step: 11287, epoch: 83, loss: 0.189469
global_step: 11288, epoch: 83, loss: 0.264507
global_step: 11289, epoch: 83, loss: 0.254217
global_step: 11290, epoch: 83, loss: 0.249718
global_step: 11291, epoch: 83, loss: 0.221134
global_step: 11292, epoch: 83, loss: 0.171111
global_step: 11293, epoch: 83, loss: 0.266388
global_step: 11294, epoch: 83, loss: 0.289361
global_step: 11295, epoch: 83, loss: 0.230535
global_step: 11296, epoch: 83, loss: 0.245720
global_step: 11297, epoch: 83, loss: 0.175834
global_step: 11298, epoch: 83, loss: 0.262604
global_step: 11299, epoch: 83, loss: 0.176936
global_step: 11300, epoch: 83, loss: 0.226225
global_step: 11301, epoch: 83, loss: 0.160795
global_step: 11302, epoch: 83, loss: 0.175815
global_step: 11303, epoch: 83, loss: 0.211162
global_step: 11304, epoch: 83, loss: 0.305617
global_step: 11305, epoch: 83, loss: 0.202929
global_step: 11306, epoch: 83, loss: 0.284237
global_step: 11307, epoch: 83, loss: 0.203141
global_step: 11308, epoch: 83, loss: 0.159279
global_step: 11309, epoch: 83, loss: 0.190582
global_step: 11310, epoch: 83, loss: 0.271077
global_step: 11311, epoch: 83, loss: 0.287892
global_step: 11312, epoch: 83, loss: 0.256316
global_step: 11313, epoch: 83, loss: 0.279619
global_step: 11314, epoch: 83, loss: 0.304561
global_step: 11315, epoch: 83, loss: 0.183207
global_step: 11316, epoch: 83, loss: 0.221542
global_step: 11317, epoch: 83, loss: 0.187681
global_step: 11318, epoch: 83, loss: 0.247314
global_step: 11319, epoch: 83, loss: 0.171604
global_step: 11320, epoch: 83, loss: 0.465824
epoch: 83
train	acc: 0.9667	macro: p 0.9724, r 0.9539, f1: 0.9626	micro: p 0.9667, r 0.9667, f1 0.9667	weighted_f1:0.9668
dev	acc: 0.5167	macro: p 0.3577, r 0.2969, f1: 0.2942	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4737
test	acc: 0.5559	macro: p 0.3464, r 0.2978, f1: 0.2979	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.5177
global_step: 11321, epoch: 84, loss: 0.264793
global_step: 11322, epoch: 84, loss: 0.171670
global_step: 11323, epoch: 84, loss: 0.217993
global_step: 11324, epoch: 84, loss: 0.148499
global_step: 11325, epoch: 84, loss: 0.189286
global_step: 11326, epoch: 84, loss: 0.220321
global_step: 11327, epoch: 84, loss: 0.190771
global_step: 11328, epoch: 84, loss: 0.238835
global_step: 11329, epoch: 84, loss: 0.237822
global_step: 11330, epoch: 84, loss: 0.197940
global_step: 11331, epoch: 84, loss: 0.261543
global_step: 11332, epoch: 84, loss: 0.211783
global_step: 11333, epoch: 84, loss: 0.172426
global_step: 11334, epoch: 84, loss: 0.232352
global_step: 11335, epoch: 84, loss: 0.202845
global_step: 11336, epoch: 84, loss: 0.186951
global_step: 11337, epoch: 84, loss: 0.246713
global_step: 11338, epoch: 84, loss: 0.186827
global_step: 11339, epoch: 84, loss: 0.206451
global_step: 11340, epoch: 84, loss: 0.200727
global_step: 11341, epoch: 84, loss: 0.216929
global_step: 11342, epoch: 84, loss: 0.256224
global_step: 11343, epoch: 84, loss: 0.220960
global_step: 11344, epoch: 84, loss: 0.219379
global_step: 11345, epoch: 84, loss: 0.222826
global_step: 11346, epoch: 84, loss: 0.229291
global_step: 11347, epoch: 84, loss: 0.269768
global_step: 11348, epoch: 84, loss: 0.209293
global_step: 11349, epoch: 84, loss: 0.205733
global_step: 11350, epoch: 84, loss: 0.162404
global_step: 11351, epoch: 84, loss: 0.226476
global_step: 11352, epoch: 84, loss: 0.281424
global_step: 11353, epoch: 84, loss: 0.173374
global_step: 11354, epoch: 84, loss: 0.209128
global_step: 11355, epoch: 84, loss: 0.299322
global_step: 11356, epoch: 84, loss: 0.249853
global_step: 11357, epoch: 84, loss: 0.201695
global_step: 11358, epoch: 84, loss: 0.252131
global_step: 11359, epoch: 84, loss: 0.342210
global_step: 11360, epoch: 84, loss: 0.913631
epoch: 84
train	acc: 0.9696	macro: p 0.9723, r 0.9604, f1: 0.9662	micro: p 0.9696, r 0.9696, f1 0.9696	weighted_f1:0.9696
dev	acc: 0.5068	macro: p 0.3086, r 0.2868, f1: 0.2870	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4681
test	acc: 0.5582	macro: p 0.3609, r 0.3130, f1: 0.3200	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5261
global_step: 11361, epoch: 85, loss: 0.188521
global_step: 11362, epoch: 85, loss: 0.307887
global_step: 11363, epoch: 85, loss: 0.235454
global_step: 11364, epoch: 85, loss: 0.247509
global_step: 11365, epoch: 85, loss: 0.187746
global_step: 11366, epoch: 85, loss: 0.227916
global_step: 11367, epoch: 85, loss: 0.232596
global_step: 11368, epoch: 85, loss: 0.251342
global_step: 11369, epoch: 85, loss: 0.185224
global_step: 11370, epoch: 85, loss: 0.193302
global_step: 11371, epoch: 85, loss: 0.267774
global_step: 11372, epoch: 85, loss: 0.292637
global_step: 11373, epoch: 85, loss: 0.167506
global_step: 11374, epoch: 85, loss: 0.199139
global_step: 11375, epoch: 85, loss: 0.282129
global_step: 11376, epoch: 85, loss: 0.228298
global_step: 11377, epoch: 85, loss: 0.196165
global_step: 11378, epoch: 85, loss: 0.212657
global_step: 11379, epoch: 85, loss: 0.237652
global_step: 11380, epoch: 85, loss: 0.207548
global_step: 11381, epoch: 85, loss: 0.196887
global_step: 11382, epoch: 85, loss: 0.162641
global_step: 11383, epoch: 85, loss: 0.227719
global_step: 11384, epoch: 85, loss: 0.323315
global_step: 11385, epoch: 85, loss: 0.186179
global_step: 11386, epoch: 85, loss: 0.221195
global_step: 11387, epoch: 85, loss: 0.259008
global_step: 11388, epoch: 85, loss: 0.231850
global_step: 11389, epoch: 85, loss: 0.248521
global_step: 11390, epoch: 85, loss: 0.245967
global_step: 11391, epoch: 85, loss: 0.193236
global_step: 11392, epoch: 85, loss: 0.177855
global_step: 11393, epoch: 85, loss: 0.182949
global_step: 11394, epoch: 85, loss: 0.173028
global_step: 11395, epoch: 85, loss: 0.237164
global_step: 11396, epoch: 85, loss: 0.250596
global_step: 11397, epoch: 85, loss: 0.293492
global_step: 11398, epoch: 85, loss: 0.324318
global_step: 11399, epoch: 85, loss: 0.192206
global_step: 11400, epoch: 85, loss: 0.474854
epoch: 85
train	acc: 0.9699	macro: p 0.9733, r 0.9600, f1: 0.9664	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5248	macro: p 0.3345, r 0.2988, f1: 0.2990	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4811
test	acc: 0.5651	macro: p 0.3619, r 0.3077, f1: 0.3124	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.5283
global_step: 11401, epoch: 86, loss: 0.238909
global_step: 11402, epoch: 86, loss: 0.168793
global_step: 11403, epoch: 86, loss: 0.224957
global_step: 11404, epoch: 86, loss: 0.193659
global_step: 11405, epoch: 86, loss: 0.250055
global_step: 11406, epoch: 86, loss: 0.174057
global_step: 11407, epoch: 86, loss: 0.182264
global_step: 11408, epoch: 86, loss: 0.233465
global_step: 11409, epoch: 86, loss: 0.278156
global_step: 11410, epoch: 86, loss: 0.303442
global_step: 11411, epoch: 86, loss: 0.236629
global_step: 11412, epoch: 86, loss: 0.274703
global_step: 11413, epoch: 86, loss: 0.263096
global_step: 11414, epoch: 86, loss: 0.219961
global_step: 11415, epoch: 86, loss: 0.305038
global_step: 11416, epoch: 86, loss: 0.246420
global_step: 11417, epoch: 86, loss: 0.246891
global_step: 11418, epoch: 86, loss: 0.234394
global_step: 11419, epoch: 86, loss: 0.310914
global_step: 11420, epoch: 86, loss: 0.193619
global_step: 11421, epoch: 86, loss: 0.145239
global_step: 11422, epoch: 86, loss: 0.238229
global_step: 11423, epoch: 86, loss: 0.263587
global_step: 11424, epoch: 86, loss: 0.212709
global_step: 11425, epoch: 86, loss: 0.218054
global_step: 11426, epoch: 86, loss: 0.258179
global_step: 11427, epoch: 86, loss: 0.234265
global_step: 11428, epoch: 86, loss: 0.245461
global_step: 11429, epoch: 86, loss: 0.250276
global_step: 11430, epoch: 86, loss: 0.170783
global_step: 11431, epoch: 86, loss: 0.205348
global_step: 11432, epoch: 86, loss: 0.186138
global_step: 11433, epoch: 86, loss: 0.209330
global_step: 11434, epoch: 86, loss: 0.199017
global_step: 11435, epoch: 86, loss: 0.166788
global_step: 11436, epoch: 86, loss: 0.276991
global_step: 11437, epoch: 86, loss: 0.198709
global_step: 11438, epoch: 86, loss: 0.172566
global_step: 11439, epoch: 86, loss: 0.178557
global_step: 11440, epoch: 86, loss: 0.005235
epoch: 86
train	acc: 0.9695	macro: p 0.9743, r 0.9585, f1: 0.9661	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5266	macro: p 0.3457, r 0.3000, f1: 0.3033	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4844
test	acc: 0.5690	macro: p 0.3675, r 0.3089, f1: 0.3166	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5309
global_step: 11441, epoch: 87, loss: 0.249220
global_step: 11442, epoch: 87, loss: 0.275127
global_step: 11443, epoch: 87, loss: 0.152228
global_step: 11444, epoch: 87, loss: 0.204228
global_step: 11445, epoch: 87, loss: 0.248157
global_step: 11446, epoch: 87, loss: 0.248683
global_step: 11447, epoch: 87, loss: 0.210302
global_step: 11448, epoch: 87, loss: 0.224832
global_step: 11449, epoch: 87, loss: 0.212385
global_step: 11450, epoch: 87, loss: 0.211780
global_step: 11451, epoch: 87, loss: 0.245221
global_step: 11452, epoch: 87, loss: 0.193954
global_step: 11453, epoch: 87, loss: 0.273981
global_step: 11454, epoch: 87, loss: 0.173055
global_step: 11455, epoch: 87, loss: 0.155099
global_step: 11456, epoch: 87, loss: 0.191558
global_step: 11457, epoch: 87, loss: 0.200262
global_step: 11458, epoch: 87, loss: 0.249056
global_step: 11459, epoch: 87, loss: 0.217086
global_step: 11460, epoch: 87, loss: 0.269766
global_step: 11461, epoch: 87, loss: 0.193728
global_step: 11462, epoch: 87, loss: 0.312066
global_step: 11463, epoch: 87, loss: 0.212592
global_step: 11464, epoch: 87, loss: 0.244692
global_step: 11465, epoch: 87, loss: 0.302510
global_step: 11466, epoch: 87, loss: 0.199630
global_step: 11467, epoch: 87, loss: 0.267987
global_step: 11468, epoch: 87, loss: 0.139936
global_step: 11469, epoch: 87, loss: 0.262443
global_step: 11470, epoch: 87, loss: 0.157591
global_step: 11471, epoch: 87, loss: 0.181550
global_step: 11472, epoch: 87, loss: 0.181983
global_step: 11473, epoch: 87, loss: 0.213049
global_step: 11474, epoch: 87, loss: 0.252930
global_step: 11475, epoch: 87, loss: 0.251654
global_step: 11476, epoch: 87, loss: 0.263072
global_step: 11477, epoch: 87, loss: 0.203596
global_step: 11478, epoch: 87, loss: 0.237952
global_step: 11479, epoch: 87, loss: 0.276520
global_step: 11480, epoch: 87, loss: 0.005516
epoch: 87
train	acc: 0.9659	macro: p 0.9668, r 0.9571, f1: 0.9616	micro: p 0.9659, r 0.9659, f1 0.9659	weighted_f1:0.9660
dev	acc: 0.5113	macro: p 0.3409, r 0.2915, f1: 0.2966	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4728
test	acc: 0.5602	macro: p 0.3621, r 0.3031, f1: 0.3123	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5265
global_step: 11481, epoch: 88, loss: 0.275114
global_step: 11482, epoch: 88, loss: 0.216330
global_step: 11483, epoch: 88, loss: 0.242938
global_step: 11484, epoch: 88, loss: 0.176543
global_step: 11485, epoch: 88, loss: 0.157813
global_step: 11486, epoch: 88, loss: 0.201352
global_step: 11487, epoch: 88, loss: 0.288682
global_step: 11488, epoch: 88, loss: 0.200401
global_step: 11489, epoch: 88, loss: 0.272741
global_step: 11490, epoch: 88, loss: 0.105710
global_step: 11491, epoch: 88, loss: 0.230479
global_step: 11492, epoch: 88, loss: 0.229624
global_step: 11493, epoch: 88, loss: 0.297372
global_step: 11494, epoch: 88, loss: 0.240059
global_step: 11495, epoch: 88, loss: 0.210839
global_step: 11496, epoch: 88, loss: 0.190471
global_step: 11497, epoch: 88, loss: 0.277685
global_step: 11498, epoch: 88, loss: 0.129579
global_step: 11499, epoch: 88, loss: 0.292048
global_step: 11500, epoch: 88, loss: 0.301812
global_step: 11501, epoch: 88, loss: 0.226057
global_step: 11502, epoch: 88, loss: 0.191922
global_step: 11503, epoch: 88, loss: 0.215429
global_step: 11504, epoch: 88, loss: 0.239640
global_step: 11505, epoch: 88, loss: 0.217297
global_step: 11506, epoch: 88, loss: 0.212549
global_step: 11507, epoch: 88, loss: 0.239341
global_step: 11508, epoch: 88, loss: 0.195771
global_step: 11509, epoch: 88, loss: 0.175826
global_step: 11510, epoch: 88, loss: 0.166877
global_step: 11511, epoch: 88, loss: 0.162986
global_step: 11512, epoch: 88, loss: 0.271082
global_step: 11513, epoch: 88, loss: 0.234153
global_step: 11514, epoch: 88, loss: 0.236175
global_step: 11515, epoch: 88, loss: 0.197187
global_step: 11516, epoch: 88, loss: 0.170730
global_step: 11517, epoch: 88, loss: 0.257907
global_step: 11518, epoch: 88, loss: 0.250716
global_step: 11519, epoch: 88, loss: 0.216894
global_step: 11520, epoch: 88, loss: 1.013180
epoch: 88
train	acc: 0.9686	macro: p 0.9724, r 0.9588, f1: 0.9654	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5221	macro: p 0.3474, r 0.2978, f1: 0.3025	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4806
test	acc: 0.5659	macro: p 0.3899, r 0.3057, f1: 0.3179	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5314
global_step: 11521, epoch: 89, loss: 0.221431
global_step: 11522, epoch: 89, loss: 0.180844
global_step: 11523, epoch: 89, loss: 0.225932
global_step: 11524, epoch: 89, loss: 0.218161
global_step: 11525, epoch: 89, loss: 0.217722
global_step: 11526, epoch: 89, loss: 0.275879
global_step: 11527, epoch: 89, loss: 0.250346
global_step: 11528, epoch: 89, loss: 0.169723
global_step: 11529, epoch: 89, loss: 0.142853
global_step: 11530, epoch: 89, loss: 0.178986
global_step: 11531, epoch: 89, loss: 0.214431
global_step: 11532, epoch: 89, loss: 0.278712
global_step: 11533, epoch: 89, loss: 0.255141
global_step: 11534, epoch: 89, loss: 0.253104
global_step: 11535, epoch: 89, loss: 0.245595
global_step: 11536, epoch: 89, loss: 0.209425
global_step: 11537, epoch: 89, loss: 0.228466
global_step: 11538, epoch: 89, loss: 0.216225
global_step: 11539, epoch: 89, loss: 0.249735
global_step: 11540, epoch: 89, loss: 0.157343
global_step: 11541, epoch: 89, loss: 0.203275
global_step: 11542, epoch: 89, loss: 0.245603
global_step: 11543, epoch: 89, loss: 0.221079
global_step: 11544, epoch: 89, loss: 0.263623
global_step: 11545, epoch: 89, loss: 0.202754
global_step: 11546, epoch: 89, loss: 0.215135
global_step: 11547, epoch: 89, loss: 0.156448
global_step: 11548, epoch: 89, loss: 0.256937
global_step: 11549, epoch: 89, loss: 0.285600
global_step: 11550, epoch: 89, loss: 0.233711
global_step: 11551, epoch: 89, loss: 0.323037
global_step: 11552, epoch: 89, loss: 0.222500
global_step: 11553, epoch: 89, loss: 0.311821
global_step: 11554, epoch: 89, loss: 0.201082
global_step: 11555, epoch: 89, loss: 0.228129
global_step: 11556, epoch: 89, loss: 0.229592
global_step: 11557, epoch: 89, loss: 0.209011
global_step: 11558, epoch: 89, loss: 0.172015
global_step: 11559, epoch: 89, loss: 0.207128
global_step: 11560, epoch: 89, loss: 0.303089
epoch: 89
train	acc: 0.9697	macro: p 0.9747, r 0.9587, f1: 0.9664	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5212	macro: p 0.3599, r 0.3019, f1: 0.3030	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4759
test	acc: 0.5617	macro: p 0.3334, r 0.3045, f1: 0.3059	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5233
global_step: 11561, epoch: 90, loss: 0.190110
global_step: 11562, epoch: 90, loss: 0.157565
global_step: 11563, epoch: 90, loss: 0.240017
global_step: 11564, epoch: 90, loss: 0.174833
global_step: 11565, epoch: 90, loss: 0.194492
global_step: 11566, epoch: 90, loss: 0.170536
global_step: 11567, epoch: 90, loss: 0.204221
global_step: 11568, epoch: 90, loss: 0.262153
global_step: 11569, epoch: 90, loss: 0.234954
global_step: 11570, epoch: 90, loss: 0.189502
global_step: 11571, epoch: 90, loss: 0.251564
global_step: 11572, epoch: 90, loss: 0.206847
global_step: 11573, epoch: 90, loss: 0.202776
global_step: 11574, epoch: 90, loss: 0.204600
global_step: 11575, epoch: 90, loss: 0.294714
global_step: 11576, epoch: 90, loss: 0.194598
global_step: 11577, epoch: 90, loss: 0.212718
global_step: 11578, epoch: 90, loss: 0.171966
global_step: 11579, epoch: 90, loss: 0.199623
global_step: 11580, epoch: 90, loss: 0.196987
global_step: 11581, epoch: 90, loss: 0.299273
global_step: 11582, epoch: 90, loss: 0.191457
global_step: 11583, epoch: 90, loss: 0.184365
global_step: 11584, epoch: 90, loss: 0.177008
global_step: 11585, epoch: 90, loss: 0.170523
global_step: 11586, epoch: 90, loss: 0.199608
global_step: 11587, epoch: 90, loss: 0.235751
global_step: 11588, epoch: 90, loss: 0.159935
global_step: 11589, epoch: 90, loss: 0.241794
global_step: 11590, epoch: 90, loss: 0.171948
global_step: 11591, epoch: 90, loss: 0.173548
global_step: 11592, epoch: 90, loss: 0.211878
global_step: 11593, epoch: 90, loss: 0.155952
global_step: 11594, epoch: 90, loss: 0.182176
global_step: 11595, epoch: 90, loss: 0.241955
global_step: 11596, epoch: 90, loss: 0.210001
global_step: 11597, epoch: 90, loss: 0.226657
global_step: 11598, epoch: 90, loss: 0.208941
global_step: 11599, epoch: 90, loss: 0.308213
global_step: 11600, epoch: 90, loss: 0.021074
epoch: 90
train	acc: 0.9702	macro: p 0.9748, r 0.9594, f1: 0.9668	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9702
dev	acc: 0.5257	macro: p 0.3525, r 0.2974, f1: 0.3010	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4805
test	acc: 0.5678	macro: p 0.3607, r 0.3005, f1: 0.3080	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5265
global_step: 11601, epoch: 91, loss: 0.188144
global_step: 11602, epoch: 91, loss: 0.203582
global_step: 11603, epoch: 91, loss: 0.175452
global_step: 11604, epoch: 91, loss: 0.140510
global_step: 11605, epoch: 91, loss: 0.222006
global_step: 11606, epoch: 91, loss: 0.225807
global_step: 11607, epoch: 91, loss: 0.177105
global_step: 11608, epoch: 91, loss: 0.131089
global_step: 11609, epoch: 91, loss: 0.202215
global_step: 11610, epoch: 91, loss: 0.140258
global_step: 11611, epoch: 91, loss: 0.192293
global_step: 11612, epoch: 91, loss: 0.265046
global_step: 11613, epoch: 91, loss: 0.265280
global_step: 11614, epoch: 91, loss: 0.219773
global_step: 11615, epoch: 91, loss: 0.188124
global_step: 11616, epoch: 91, loss: 0.130865
global_step: 11617, epoch: 91, loss: 0.215243
global_step: 11618, epoch: 91, loss: 0.219724
global_step: 11619, epoch: 91, loss: 0.213159
global_step: 11620, epoch: 91, loss: 0.151883
global_step: 11621, epoch: 91, loss: 0.161206
global_step: 11622, epoch: 91, loss: 0.213268
global_step: 11623, epoch: 91, loss: 0.249382
global_step: 11624, epoch: 91, loss: 0.170178
global_step: 11625, epoch: 91, loss: 0.298533
global_step: 11626, epoch: 91, loss: 0.202635
global_step: 11627, epoch: 91, loss: 0.254124
global_step: 11628, epoch: 91, loss: 0.225972
global_step: 11629, epoch: 91, loss: 0.149814
global_step: 11630, epoch: 91, loss: 0.213012
global_step: 11631, epoch: 91, loss: 0.204769
global_step: 11632, epoch: 91, loss: 0.184921
global_step: 11633, epoch: 91, loss: 0.159886
global_step: 11634, epoch: 91, loss: 0.171240
global_step: 11635, epoch: 91, loss: 0.202964
global_step: 11636, epoch: 91, loss: 0.237513
global_step: 11637, epoch: 91, loss: 0.260944
global_step: 11638, epoch: 91, loss: 0.192956
global_step: 11639, epoch: 91, loss: 0.232306
global_step: 11640, epoch: 91, loss: 0.146385
epoch: 91
train	acc: 0.9701	macro: p 0.9729, r 0.9613, f1: 0.9668	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5230	macro: p 0.3810, r 0.3005, f1: 0.3067	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4756
test	acc: 0.5648	macro: p 0.3363, r 0.3018, f1: 0.3041	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5239
global_step: 11641, epoch: 92, loss: 0.258961
global_step: 11642, epoch: 92, loss: 0.184272
global_step: 11643, epoch: 92, loss: 0.242386
global_step: 11644, epoch: 92, loss: 0.118246
global_step: 11645, epoch: 92, loss: 0.230550
global_step: 11646, epoch: 92, loss: 0.203957
global_step: 11647, epoch: 92, loss: 0.282977
global_step: 11648, epoch: 92, loss: 0.175218
global_step: 11649, epoch: 92, loss: 0.258555
global_step: 11650, epoch: 92, loss: 0.182716
global_step: 11651, epoch: 92, loss: 0.139121
global_step: 11652, epoch: 92, loss: 0.179092
global_step: 11653, epoch: 92, loss: 0.198586
global_step: 11654, epoch: 92, loss: 0.153104
global_step: 11655, epoch: 92, loss: 0.261927
global_step: 11656, epoch: 92, loss: 0.174849
global_step: 11657, epoch: 92, loss: 0.249082
global_step: 11658, epoch: 92, loss: 0.236839
global_step: 11659, epoch: 92, loss: 0.241709
global_step: 11660, epoch: 92, loss: 0.249200
global_step: 11661, epoch: 92, loss: 0.144269
global_step: 11662, epoch: 92, loss: 0.178882
global_step: 11663, epoch: 92, loss: 0.286377
global_step: 11664, epoch: 92, loss: 0.214461
global_step: 11665, epoch: 92, loss: 0.132544
global_step: 11666, epoch: 92, loss: 0.211743
global_step: 11667, epoch: 92, loss: 0.254896
global_step: 11668, epoch: 92, loss: 0.274362
global_step: 11669, epoch: 92, loss: 0.245420
global_step: 11670, epoch: 92, loss: 0.264190
global_step: 11671, epoch: 92, loss: 0.244295
global_step: 11672, epoch: 92, loss: 0.200050
global_step: 11673, epoch: 92, loss: 0.146061
global_step: 11674, epoch: 92, loss: 0.142091
global_step: 11675, epoch: 92, loss: 0.287520
global_step: 11676, epoch: 92, loss: 0.158363
global_step: 11677, epoch: 92, loss: 0.237581
global_step: 11678, epoch: 92, loss: 0.289117
global_step: 11679, epoch: 92, loss: 0.268333
global_step: 11680, epoch: 92, loss: 0.453711
epoch: 92
train	acc: 0.9710	macro: p 0.9721, r 0.9630, f1: 0.9674	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5167	macro: p 0.3370, r 0.3069, f1: 0.3099	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4872
test	acc: 0.5360	macro: p 0.3444, r 0.3072, f1: 0.3140	micro: p 0.5360, r 0.5360, f1 0.5360	weighted_f1:0.5151
global_step: 11681, epoch: 93, loss: 0.237985
global_step: 11682, epoch: 93, loss: 0.156542
global_step: 11683, epoch: 93, loss: 0.232703
global_step: 11684, epoch: 93, loss: 0.235852
global_step: 11685, epoch: 93, loss: 0.187253
global_step: 11686, epoch: 93, loss: 0.262287
global_step: 11687, epoch: 93, loss: 0.189830
global_step: 11688, epoch: 93, loss: 0.186640
global_step: 11689, epoch: 93, loss: 0.213522
global_step: 11690, epoch: 93, loss: 0.235359
global_step: 11691, epoch: 93, loss: 0.253575
global_step: 11692, epoch: 93, loss: 0.187218
global_step: 11693, epoch: 93, loss: 0.202044
global_step: 11694, epoch: 93, loss: 0.249118
global_step: 11695, epoch: 93, loss: 0.173643
global_step: 11696, epoch: 93, loss: 0.217013
global_step: 11697, epoch: 93, loss: 0.230016
global_step: 11698, epoch: 93, loss: 0.174193
global_step: 11699, epoch: 93, loss: 0.227051
global_step: 11700, epoch: 93, loss: 0.188600
global_step: 11701, epoch: 93, loss: 0.293818
global_step: 11702, epoch: 93, loss: 0.167012
global_step: 11703, epoch: 93, loss: 0.279330
global_step: 11704, epoch: 93, loss: 0.163744
global_step: 11705, epoch: 93, loss: 0.195430
global_step: 11706, epoch: 93, loss: 0.350515
global_step: 11707, epoch: 93, loss: 0.167165
global_step: 11708, epoch: 93, loss: 0.210553
global_step: 11709, epoch: 93, loss: 0.208875
global_step: 11710, epoch: 93, loss: 0.145688
global_step: 11711, epoch: 93, loss: 0.205647
global_step: 11712, epoch: 93, loss: 0.130044
global_step: 11713, epoch: 93, loss: 0.241123
global_step: 11714, epoch: 93, loss: 0.234589
global_step: 11715, epoch: 93, loss: 0.235726
global_step: 11716, epoch: 93, loss: 0.133618
global_step: 11717, epoch: 93, loss: 0.283807
global_step: 11718, epoch: 93, loss: 0.199026
global_step: 11719, epoch: 93, loss: 0.215857
global_step: 11720, epoch: 93, loss: 0.126216
epoch: 93
train	acc: 0.9699	macro: p 0.9743, r 0.9592, f1: 0.9664	micro: p 0.9699, r 0.9699, f1 0.9699	weighted_f1:0.9699
dev	acc: 0.5302	macro: p 0.3664, r 0.2990, f1: 0.2998	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4829
test	acc: 0.5617	macro: p 0.3390, r 0.2991, f1: 0.3001	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5204
global_step: 11721, epoch: 94, loss: 0.190577
global_step: 11722, epoch: 94, loss: 0.128345
global_step: 11723, epoch: 94, loss: 0.205577
global_step: 11724, epoch: 94, loss: 0.142474
global_step: 11725, epoch: 94, loss: 0.224110
global_step: 11726, epoch: 94, loss: 0.159794
global_step: 11727, epoch: 94, loss: 0.159614
global_step: 11728, epoch: 94, loss: 0.235275
global_step: 11729, epoch: 94, loss: 0.277815
global_step: 11730, epoch: 94, loss: 0.122035
global_step: 11731, epoch: 94, loss: 0.176522
global_step: 11732, epoch: 94, loss: 0.142671
global_step: 11733, epoch: 94, loss: 0.206026
global_step: 11734, epoch: 94, loss: 0.136973
global_step: 11735, epoch: 94, loss: 0.235903
global_step: 11736, epoch: 94, loss: 0.214693
global_step: 11737, epoch: 94, loss: 0.207016
global_step: 11738, epoch: 94, loss: 0.248284
global_step: 11739, epoch: 94, loss: 0.171302
global_step: 11740, epoch: 94, loss: 0.218736
global_step: 11741, epoch: 94, loss: 0.209161
global_step: 11742, epoch: 94, loss: 0.228497
global_step: 11743, epoch: 94, loss: 0.164328
global_step: 11744, epoch: 94, loss: 0.283655
global_step: 11745, epoch: 94, loss: 0.165596
global_step: 11746, epoch: 94, loss: 0.198030
global_step: 11747, epoch: 94, loss: 0.231160
global_step: 11748, epoch: 94, loss: 0.242410
global_step: 11749, epoch: 94, loss: 0.286526
global_step: 11750, epoch: 94, loss: 0.176056
global_step: 11751, epoch: 94, loss: 0.230126
global_step: 11752, epoch: 94, loss: 0.195478
global_step: 11753, epoch: 94, loss: 0.173740
global_step: 11754, epoch: 94, loss: 0.177958
global_step: 11755, epoch: 94, loss: 0.238627
global_step: 11756, epoch: 94, loss: 0.227226
global_step: 11757, epoch: 94, loss: 0.205599
global_step: 11758, epoch: 94, loss: 0.251176
global_step: 11759, epoch: 94, loss: 0.172636
global_step: 11760, epoch: 94, loss: 0.129680
epoch: 94
train	acc: 0.9710	macro: p 0.9761, r 0.9606, f1: 0.9682	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5338	macro: p 0.3520, r 0.2986, f1: 0.3036	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4859
test	acc: 0.5705	macro: p 0.3630, r 0.3053, f1: 0.3168	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5293
global_step: 11761, epoch: 95, loss: 0.177168
global_step: 11762, epoch: 95, loss: 0.152430
global_step: 11763, epoch: 95, loss: 0.214824
global_step: 11764, epoch: 95, loss: 0.245741
global_step: 11765, epoch: 95, loss: 0.167364
global_step: 11766, epoch: 95, loss: 0.124336
global_step: 11767, epoch: 95, loss: 0.249654
global_step: 11768, epoch: 95, loss: 0.197184
global_step: 11769, epoch: 95, loss: 0.203395
global_step: 11770, epoch: 95, loss: 0.194636
global_step: 11771, epoch: 95, loss: 0.222356
global_step: 11772, epoch: 95, loss: 0.306268
global_step: 11773, epoch: 95, loss: 0.178335
global_step: 11774, epoch: 95, loss: 0.276013
global_step: 11775, epoch: 95, loss: 0.216041
global_step: 11776, epoch: 95, loss: 0.142408
global_step: 11777, epoch: 95, loss: 0.173691
global_step: 11778, epoch: 95, loss: 0.191220
global_step: 11779, epoch: 95, loss: 0.270210
global_step: 11780, epoch: 95, loss: 0.187244
global_step: 11781, epoch: 95, loss: 0.210036
global_step: 11782, epoch: 95, loss: 0.214221
global_step: 11783, epoch: 95, loss: 0.179841
global_step: 11784, epoch: 95, loss: 0.264967
global_step: 11785, epoch: 95, loss: 0.147614
global_step: 11786, epoch: 95, loss: 0.141437
global_step: 11787, epoch: 95, loss: 0.141323
global_step: 11788, epoch: 95, loss: 0.194379
global_step: 11789, epoch: 95, loss: 0.248475
global_step: 11790, epoch: 95, loss: 0.256285
global_step: 11791, epoch: 95, loss: 0.211849
global_step: 11792, epoch: 95, loss: 0.176704
global_step: 11793, epoch: 95, loss: 0.294406
global_step: 11794, epoch: 95, loss: 0.211762
global_step: 11795, epoch: 95, loss: 0.203043
global_step: 11796, epoch: 95, loss: 0.292659
global_step: 11797, epoch: 95, loss: 0.184206
global_step: 11798, epoch: 95, loss: 0.206778
global_step: 11799, epoch: 95, loss: 0.206700
global_step: 11800, epoch: 95, loss: 1.002932
epoch: 95
train	acc: 0.9707	macro: p 0.9743, r 0.9617, f1: 0.9678	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5329	macro: p 0.3989, r 0.2983, f1: 0.3030	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4815
test	acc: 0.5713	macro: p 0.3824, r 0.3008, f1: 0.3089	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5250
global_step: 11801, epoch: 96, loss: 0.207222
global_step: 11802, epoch: 96, loss: 0.281838
global_step: 11803, epoch: 96, loss: 0.236340
global_step: 11804, epoch: 96, loss: 0.272704
global_step: 11805, epoch: 96, loss: 0.146673
global_step: 11806, epoch: 96, loss: 0.146180
global_step: 11807, epoch: 96, loss: 0.173678
global_step: 11808, epoch: 96, loss: 0.172962
global_step: 11809, epoch: 96, loss: 0.186711
global_step: 11810, epoch: 96, loss: 0.135050
global_step: 11811, epoch: 96, loss: 0.112703
global_step: 11812, epoch: 96, loss: 0.153133
global_step: 11813, epoch: 96, loss: 0.120934
global_step: 11814, epoch: 96, loss: 0.172111
global_step: 11815, epoch: 96, loss: 0.210118
global_step: 11816, epoch: 96, loss: 0.217660
global_step: 11817, epoch: 96, loss: 0.238698
global_step: 11818, epoch: 96, loss: 0.219082
global_step: 11819, epoch: 96, loss: 0.142980
global_step: 11820, epoch: 96, loss: 0.171813
global_step: 11821, epoch: 96, loss: 0.160299
global_step: 11822, epoch: 96, loss: 0.153206
global_step: 11823, epoch: 96, loss: 0.134073
global_step: 11824, epoch: 96, loss: 0.172557
global_step: 11825, epoch: 96, loss: 0.208814
global_step: 11826, epoch: 96, loss: 0.177999
global_step: 11827, epoch: 96, loss: 0.256908
global_step: 11828, epoch: 96, loss: 0.263242
global_step: 11829, epoch: 96, loss: 0.236400
global_step: 11830, epoch: 96, loss: 0.182691
global_step: 11831, epoch: 96, loss: 0.194110
global_step: 11832, epoch: 96, loss: 0.204454
global_step: 11833, epoch: 96, loss: 0.253066
global_step: 11834, epoch: 96, loss: 0.263342
global_step: 11835, epoch: 96, loss: 0.292331
global_step: 11836, epoch: 96, loss: 0.208463
global_step: 11837, epoch: 96, loss: 0.241307
global_step: 11838, epoch: 96, loss: 0.224731
global_step: 11839, epoch: 96, loss: 0.296951
global_step: 11840, epoch: 96, loss: 0.290062
epoch: 96
train	acc: 0.9717	macro: p 0.9752, r 0.9609, f1: 0.9678	micro: p 0.9717, r 0.9717, f1 0.9717	weighted_f1:0.9717
dev	acc: 0.5248	macro: p 0.3836, r 0.2962, f1: 0.3026	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4772
test	acc: 0.5667	macro: p 0.3571, r 0.2966, f1: 0.3035	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5256
global_step: 11841, epoch: 97, loss: 0.174528
global_step: 11842, epoch: 97, loss: 0.121689
global_step: 11843, epoch: 97, loss: 0.136476
global_step: 11844, epoch: 97, loss: 0.225768
global_step: 11845, epoch: 97, loss: 0.292662
global_step: 11846, epoch: 97, loss: 0.128270
global_step: 11847, epoch: 97, loss: 0.159184
global_step: 11848, epoch: 97, loss: 0.154172
global_step: 11849, epoch: 97, loss: 0.221696
global_step: 11850, epoch: 97, loss: 0.183459
global_step: 11851, epoch: 97, loss: 0.217547
global_step: 11852, epoch: 97, loss: 0.193364
global_step: 11853, epoch: 97, loss: 0.229928
global_step: 11854, epoch: 97, loss: 0.157335
global_step: 11855, epoch: 97, loss: 0.230969
global_step: 11856, epoch: 97, loss: 0.168231
global_step: 11857, epoch: 97, loss: 0.208442
global_step: 11858, epoch: 97, loss: 0.153881
global_step: 11859, epoch: 97, loss: 0.208401
global_step: 11860, epoch: 97, loss: 0.175475
global_step: 11861, epoch: 97, loss: 0.124426
global_step: 11862, epoch: 97, loss: 0.186978
global_step: 11863, epoch: 97, loss: 0.187127
global_step: 11864, epoch: 97, loss: 0.194647
global_step: 11865, epoch: 97, loss: 0.208078
global_step: 11866, epoch: 97, loss: 0.190557
global_step: 11867, epoch: 97, loss: 0.180011
global_step: 11868, epoch: 97, loss: 0.182841
global_step: 11869, epoch: 97, loss: 0.265873
global_step: 11870, epoch: 97, loss: 0.243076
global_step: 11871, epoch: 97, loss: 0.215899
global_step: 11872, epoch: 97, loss: 0.193845
global_step: 11873, epoch: 97, loss: 0.209318
global_step: 11874, epoch: 97, loss: 0.185960
global_step: 11875, epoch: 97, loss: 0.274138
global_step: 11876, epoch: 97, loss: 0.197812
global_step: 11877, epoch: 97, loss: 0.233859
global_step: 11878, epoch: 97, loss: 0.174210
global_step: 11879, epoch: 97, loss: 0.156897
global_step: 11880, epoch: 97, loss: 0.071876
epoch: 97
train	acc: 0.9716	macro: p 0.9756, r 0.9617, f1: 0.9684	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5284	macro: p 0.3548, r 0.2974, f1: 0.3023	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4821
test	acc: 0.5724	macro: p 0.3691, r 0.3054, f1: 0.3150	micro: p 0.5724, r 0.5724, f1 0.5724	weighted_f1:0.5321
global_step: 11881, epoch: 98, loss: 0.215023
global_step: 11882, epoch: 98, loss: 0.127697
global_step: 11883, epoch: 98, loss: 0.248148
global_step: 11884, epoch: 98, loss: 0.187472
global_step: 11885, epoch: 98, loss: 0.232606
global_step: 11886, epoch: 98, loss: 0.137425
global_step: 11887, epoch: 98, loss: 0.190667
global_step: 11888, epoch: 98, loss: 0.280296
global_step: 11889, epoch: 98, loss: 0.186437
global_step: 11890, epoch: 98, loss: 0.238535
global_step: 11891, epoch: 98, loss: 0.190379
global_step: 11892, epoch: 98, loss: 0.194276
global_step: 11893, epoch: 98, loss: 0.248848
global_step: 11894, epoch: 98, loss: 0.189690
global_step: 11895, epoch: 98, loss: 0.185066
global_step: 11896, epoch: 98, loss: 0.179999
global_step: 11897, epoch: 98, loss: 0.213669
global_step: 11898, epoch: 98, loss: 0.177990
global_step: 11899, epoch: 98, loss: 0.198921
global_step: 11900, epoch: 98, loss: 0.162403
global_step: 11901, epoch: 98, loss: 0.186893
global_step: 11902, epoch: 98, loss: 0.229659
global_step: 11903, epoch: 98, loss: 0.215155
global_step: 11904, epoch: 98, loss: 0.220204
global_step: 11905, epoch: 98, loss: 0.206579
global_step: 11906, epoch: 98, loss: 0.134243
global_step: 11907, epoch: 98, loss: 0.154344
global_step: 11908, epoch: 98, loss: 0.171261
global_step: 11909, epoch: 98, loss: 0.185456
global_step: 11910, epoch: 98, loss: 0.183113
global_step: 11911, epoch: 98, loss: 0.166700
global_step: 11912, epoch: 98, loss: 0.233738
global_step: 11913, epoch: 98, loss: 0.150778
global_step: 11914, epoch: 98, loss: 0.246241
global_step: 11915, epoch: 98, loss: 0.243649
global_step: 11916, epoch: 98, loss: 0.195622
global_step: 11917, epoch: 98, loss: 0.140974
global_step: 11918, epoch: 98, loss: 0.162855
global_step: 11919, epoch: 98, loss: 0.220005
global_step: 11920, epoch: 98, loss: 0.689738
epoch: 98
train	acc: 0.9715	macro: p 0.9737, r 0.9611, f1: 0.9672	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5428	macro: p 0.4285, r 0.3270, f1: 0.3426	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.5051
test	acc: 0.5613	macro: p 0.3420, r 0.3021, f1: 0.3079	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5260
New best model!
global_step: 11921, epoch: 99, loss: 0.151332
global_step: 11922, epoch: 99, loss: 0.149175
global_step: 11923, epoch: 99, loss: 0.198210
global_step: 11924, epoch: 99, loss: 0.180854
global_step: 11925, epoch: 99, loss: 0.186735
global_step: 11926, epoch: 99, loss: 0.153567
global_step: 11927, epoch: 99, loss: 0.191422
global_step: 11928, epoch: 99, loss: 0.130514
global_step: 11929, epoch: 99, loss: 0.188968
global_step: 11930, epoch: 99, loss: 0.196841
global_step: 11931, epoch: 99, loss: 0.180423
global_step: 11932, epoch: 99, loss: 0.256251
global_step: 11933, epoch: 99, loss: 0.175631
global_step: 11934, epoch: 99, loss: 0.215331
global_step: 11935, epoch: 99, loss: 0.168362
global_step: 11936, epoch: 99, loss: 0.164989
global_step: 11937, epoch: 99, loss: 0.243661
global_step: 11938, epoch: 99, loss: 0.200276
global_step: 11939, epoch: 99, loss: 0.165670
global_step: 11940, epoch: 99, loss: 0.191572
global_step: 11941, epoch: 99, loss: 0.187933
global_step: 11942, epoch: 99, loss: 0.154898
global_step: 11943, epoch: 99, loss: 0.269109
global_step: 11944, epoch: 99, loss: 0.183651
global_step: 11945, epoch: 99, loss: 0.198780
global_step: 11946, epoch: 99, loss: 0.235341
global_step: 11947, epoch: 99, loss: 0.218627
global_step: 11948, epoch: 99, loss: 0.182504
global_step: 11949, epoch: 99, loss: 0.188357
global_step: 11950, epoch: 99, loss: 0.245856
global_step: 11951, epoch: 99, loss: 0.114522
global_step: 11952, epoch: 99, loss: 0.190836
global_step: 11953, epoch: 99, loss: 0.174937
global_step: 11954, epoch: 99, loss: 0.191219
global_step: 11955, epoch: 99, loss: 0.207654
global_step: 11956, epoch: 99, loss: 0.167209
global_step: 11957, epoch: 99, loss: 0.204294
global_step: 11958, epoch: 99, loss: 0.160652
global_step: 11959, epoch: 99, loss: 0.246370
global_step: 11960, epoch: 99, loss: 0.356415
epoch: 99
train	acc: 0.9706	macro: p 0.9724, r 0.9628, f1: 0.9675	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5311	macro: p 0.4234, r 0.3190, f1: 0.3278	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4964
test	acc: 0.5586	macro: p 0.3527, r 0.3150, f1: 0.3217	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.5312
global_step: 11961, epoch: 100, loss: 0.170300
global_step: 11962, epoch: 100, loss: 0.196094
global_step: 11963, epoch: 100, loss: 0.206612
global_step: 11964, epoch: 100, loss: 0.191852
global_step: 11965, epoch: 100, loss: 0.256188
global_step: 11966, epoch: 100, loss: 0.222427
global_step: 11967, epoch: 100, loss: 0.172661
global_step: 11968, epoch: 100, loss: 0.157986
global_step: 11969, epoch: 100, loss: 0.184185
global_step: 11970, epoch: 100, loss: 0.275492
global_step: 11971, epoch: 100, loss: 0.179834
global_step: 11972, epoch: 100, loss: 0.206748
global_step: 11973, epoch: 100, loss: 0.207273
global_step: 11974, epoch: 100, loss: 0.182082
global_step: 11975, epoch: 100, loss: 0.212962
global_step: 11976, epoch: 100, loss: 0.149396
global_step: 11977, epoch: 100, loss: 0.186460
global_step: 11978, epoch: 100, loss: 0.176081
global_step: 11979, epoch: 100, loss: 0.190000
global_step: 11980, epoch: 100, loss: 0.151673
global_step: 11981, epoch: 100, loss: 0.181108
global_step: 11982, epoch: 100, loss: 0.194061
global_step: 11983, epoch: 100, loss: 0.133692
global_step: 11984, epoch: 100, loss: 0.249601
global_step: 11985, epoch: 100, loss: 0.207386
global_step: 11986, epoch: 100, loss: 0.270018
global_step: 11987, epoch: 100, loss: 0.264321
global_step: 11988, epoch: 100, loss: 0.204184
global_step: 11989, epoch: 100, loss: 0.166776
global_step: 11990, epoch: 100, loss: 0.141462
global_step: 11991, epoch: 100, loss: 0.116169
global_step: 11992, epoch: 100, loss: 0.167214
global_step: 11993, epoch: 100, loss: 0.196495
global_step: 11994, epoch: 100, loss: 0.239403
global_step: 11995, epoch: 100, loss: 0.197216
global_step: 11996, epoch: 100, loss: 0.128404
global_step: 11997, epoch: 100, loss: 0.197145
global_step: 11998, epoch: 100, loss: 0.103404
global_step: 11999, epoch: 100, loss: 0.115699
global_step: 12000, epoch: 100, loss: 0.000352
epoch: 100
train	acc: 0.9716	macro: p 0.9751, r 0.9619, f1: 0.9683	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5383	macro: p 0.3919, r 0.3129, f1: 0.3194	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4961
test	acc: 0.5598	macro: p 0.3419, r 0.3012, f1: 0.3061	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.5241
BEST MODEL epoch: 98
train	acc: 0.9715 macro_p: 0.9737 macro_r: 0.9611 macro_f1: 0.9672 micro_p: 0.9715 micro_r: 0.9715 micro_f1: 0.9715 weighted_f1: 0.9715
dev	acc: 0.5428 macro_p: 0.4285 macro_r: 0.3270 macro_f1: 0.3426 micro_p: 0.5428 micro_r: 0.5428 micro_f1: 0.5428 weighted_f1: 0.5051
test	acc: 0.5613 macro_p: 0.3420 macro_r: 0.3021 macro_f1: 0.3079 micro_p: 0.5613 micro_r: 0.5613 micro_f1: 0.5613 weighted_f1: 0.5260
==========ROUND 4==========
global_step: 12001, epoch: 1, loss: 1.976625
global_step: 12002, epoch: 1, loss: 1.781817
global_step: 12003, epoch: 1, loss: 1.658166
global_step: 12004, epoch: 1, loss: 1.702757
global_step: 12005, epoch: 1, loss: 1.530618
global_step: 12006, epoch: 1, loss: 1.470677
global_step: 12007, epoch: 1, loss: 1.528426
global_step: 12008, epoch: 1, loss: 1.441100
global_step: 12009, epoch: 1, loss: 1.564715
global_step: 12010, epoch: 1, loss: 1.646371
global_step: 12011, epoch: 1, loss: 1.531103
global_step: 12012, epoch: 1, loss: 1.412670
global_step: 12013, epoch: 1, loss: 1.498061
global_step: 12014, epoch: 1, loss: 1.451414
global_step: 12015, epoch: 1, loss: 1.444393
global_step: 12016, epoch: 1, loss: 1.422076
global_step: 12017, epoch: 1, loss: 1.409623
global_step: 12018, epoch: 1, loss: 1.465755
global_step: 12019, epoch: 1, loss: 1.517487
global_step: 12020, epoch: 1, loss: 1.354082
global_step: 12021, epoch: 1, loss: 1.339327
global_step: 12022, epoch: 1, loss: 1.511491
global_step: 12023, epoch: 1, loss: 1.388856
global_step: 12024, epoch: 1, loss: 1.287268
global_step: 12025, epoch: 1, loss: 1.299617
global_step: 12026, epoch: 1, loss: 1.478682
global_step: 12027, epoch: 1, loss: 1.338220
global_step: 12028, epoch: 1, loss: 1.310299
global_step: 12029, epoch: 1, loss: 1.392456
global_step: 12030, epoch: 1, loss: 1.465775
global_step: 12031, epoch: 1, loss: 1.298143
global_step: 12032, epoch: 1, loss: 1.393019
global_step: 12033, epoch: 1, loss: 1.402995
global_step: 12034, epoch: 1, loss: 1.407606
global_step: 12035, epoch: 1, loss: 1.401477
global_step: 12036, epoch: 1, loss: 1.314510
global_step: 12037, epoch: 1, loss: 1.297171
global_step: 12038, epoch: 1, loss: 1.395163
global_step: 12039, epoch: 1, loss: 1.406497
global_step: 12040, epoch: 1, loss: 1.566845
epoch: 1
train	acc: 0.5035	macro: p 0.2603, r 0.2738, f1: 0.2322	micro: p 0.5035, r 0.5035, f1 0.5035	weighted_f1:0.4542
dev	acc: 0.4581	macro: p 0.2354, r 0.2538, f1: 0.2214	micro: p 0.4581, r 0.4581, f1 0.4581	weighted_f1:0.4019
test	acc: 0.5092	macro: p 0.2646, r 0.2765, f1: 0.2426	micro: p 0.5092, r 0.5092, f1 0.5092	weighted_f1:0.4684
New best model!
global_step: 12041, epoch: 2, loss: 1.428503
global_step: 12042, epoch: 2, loss: 1.266334
global_step: 12043, epoch: 2, loss: 1.366412
global_step: 12044, epoch: 2, loss: 1.480169
global_step: 12045, epoch: 2, loss: 1.283790
global_step: 12046, epoch: 2, loss: 1.416681
global_step: 12047, epoch: 2, loss: 1.339877
global_step: 12048, epoch: 2, loss: 1.304452
global_step: 12049, epoch: 2, loss: 1.385089
global_step: 12050, epoch: 2, loss: 1.350665
global_step: 12051, epoch: 2, loss: 1.340516
global_step: 12052, epoch: 2, loss: 1.257371
global_step: 12053, epoch: 2, loss: 1.289531
global_step: 12054, epoch: 2, loss: 1.290105
global_step: 12055, epoch: 2, loss: 1.274095
global_step: 12056, epoch: 2, loss: 1.364457
global_step: 12057, epoch: 2, loss: 1.297537
global_step: 12058, epoch: 2, loss: 1.394197
global_step: 12059, epoch: 2, loss: 1.372433
global_step: 12060, epoch: 2, loss: 1.326902
global_step: 12061, epoch: 2, loss: 1.183762
global_step: 12062, epoch: 2, loss: 1.313934
global_step: 12063, epoch: 2, loss: 1.247066
global_step: 12064, epoch: 2, loss: 1.219131
global_step: 12065, epoch: 2, loss: 1.391186
global_step: 12066, epoch: 2, loss: 1.358393
global_step: 12067, epoch: 2, loss: 1.373361
global_step: 12068, epoch: 2, loss: 1.356623
global_step: 12069, epoch: 2, loss: 1.416290
global_step: 12070, epoch: 2, loss: 1.179283
global_step: 12071, epoch: 2, loss: 1.248271
global_step: 12072, epoch: 2, loss: 1.358178
global_step: 12073, epoch: 2, loss: 1.332643
global_step: 12074, epoch: 2, loss: 1.287691
global_step: 12075, epoch: 2, loss: 1.383338
global_step: 12076, epoch: 2, loss: 1.280600
global_step: 12077, epoch: 2, loss: 1.376530
global_step: 12078, epoch: 2, loss: 1.356093
global_step: 12079, epoch: 2, loss: 1.339401
global_step: 12080, epoch: 2, loss: 1.842927
epoch: 2
train	acc: 0.4575	macro: p 0.4000, r 0.2602, f1: 0.2291	micro: p 0.4575, r 0.4575, f1 0.4575	weighted_f1:0.4343
dev	acc: 0.3904	macro: p 0.3292, r 0.2433, f1: 0.1948	micro: p 0.3904, r 0.3904, f1 0.3904	weighted_f1:0.3583
test	acc: 0.4004	macro: p 0.3274, r 0.2397, f1: 0.1973	micro: p 0.4004, r 0.4004, f1 0.4004	weighted_f1:0.3809
global_step: 12081, epoch: 3, loss: 1.486197
global_step: 12082, epoch: 3, loss: 1.303672
global_step: 12083, epoch: 3, loss: 1.440722
global_step: 12084, epoch: 3, loss: 1.349044
global_step: 12085, epoch: 3, loss: 1.160765
global_step: 12086, epoch: 3, loss: 1.281013
global_step: 12087, epoch: 3, loss: 1.187895
global_step: 12088, epoch: 3, loss: 1.304870
global_step: 12089, epoch: 3, loss: 1.202660
global_step: 12090, epoch: 3, loss: 1.233758
global_step: 12091, epoch: 3, loss: 1.441690
global_step: 12092, epoch: 3, loss: 1.262016
global_step: 12093, epoch: 3, loss: 1.228332
global_step: 12094, epoch: 3, loss: 1.283725
global_step: 12095, epoch: 3, loss: 1.248575
global_step: 12096, epoch: 3, loss: 1.309080
global_step: 12097, epoch: 3, loss: 1.296109
global_step: 12098, epoch: 3, loss: 1.275249
global_step: 12099, epoch: 3, loss: 1.345206
global_step: 12100, epoch: 3, loss: 1.330166
global_step: 12101, epoch: 3, loss: 1.306014
global_step: 12102, epoch: 3, loss: 1.292329
global_step: 12103, epoch: 3, loss: 1.281508
global_step: 12104, epoch: 3, loss: 1.246315
global_step: 12105, epoch: 3, loss: 1.313168
global_step: 12106, epoch: 3, loss: 1.257653
global_step: 12107, epoch: 3, loss: 1.414713
global_step: 12108, epoch: 3, loss: 1.234183
global_step: 12109, epoch: 3, loss: 1.353310
global_step: 12110, epoch: 3, loss: 1.305441
global_step: 12111, epoch: 3, loss: 1.319266
global_step: 12112, epoch: 3, loss: 1.296032
global_step: 12113, epoch: 3, loss: 1.212041
global_step: 12114, epoch: 3, loss: 1.180663
global_step: 12115, epoch: 3, loss: 1.232692
global_step: 12116, epoch: 3, loss: 1.268338
global_step: 12117, epoch: 3, loss: 1.134672
global_step: 12118, epoch: 3, loss: 1.198237
global_step: 12119, epoch: 3, loss: 1.229807
global_step: 12120, epoch: 3, loss: 2.028413
epoch: 3
train	acc: 0.5868	macro: p 0.4009, r 0.2990, f1: 0.3049	micro: p 0.5868, r 0.5868, f1 0.5868	weighted_f1:0.5312
dev	acc: 0.5320	macro: p 0.3456, r 0.2756, f1: 0.2726	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4667
test	acc: 0.5816	macro: p 0.3658, r 0.2853, f1: 0.2904	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5260
New best model!
global_step: 12121, epoch: 4, loss: 1.309273
global_step: 12122, epoch: 4, loss: 1.275440
global_step: 12123, epoch: 4, loss: 1.250884
global_step: 12124, epoch: 4, loss: 1.245759
global_step: 12125, epoch: 4, loss: 1.340546
global_step: 12126, epoch: 4, loss: 1.200522
global_step: 12127, epoch: 4, loss: 1.183100
global_step: 12128, epoch: 4, loss: 1.244560
global_step: 12129, epoch: 4, loss: 1.235024
global_step: 12130, epoch: 4, loss: 1.195076
global_step: 12131, epoch: 4, loss: 1.160304
global_step: 12132, epoch: 4, loss: 1.321707
global_step: 12133, epoch: 4, loss: 1.233542
global_step: 12134, epoch: 4, loss: 1.219054
global_step: 12135, epoch: 4, loss: 1.224549
global_step: 12136, epoch: 4, loss: 1.221896
global_step: 12137, epoch: 4, loss: 1.339183
global_step: 12138, epoch: 4, loss: 1.241746
global_step: 12139, epoch: 4, loss: 1.225150
global_step: 12140, epoch: 4, loss: 1.280592
global_step: 12141, epoch: 4, loss: 1.198799
global_step: 12142, epoch: 4, loss: 1.223195
global_step: 12143, epoch: 4, loss: 1.357049
global_step: 12144, epoch: 4, loss: 1.204502
global_step: 12145, epoch: 4, loss: 1.200634
global_step: 12146, epoch: 4, loss: 1.154577
global_step: 12147, epoch: 4, loss: 1.408844
global_step: 12148, epoch: 4, loss: 1.283624
global_step: 12149, epoch: 4, loss: 1.230328
global_step: 12150, epoch: 4, loss: 1.107665
global_step: 12151, epoch: 4, loss: 1.319113
global_step: 12152, epoch: 4, loss: 1.214214
global_step: 12153, epoch: 4, loss: 1.271865
global_step: 12154, epoch: 4, loss: 1.126545
global_step: 12155, epoch: 4, loss: 1.235667
global_step: 12156, epoch: 4, loss: 1.196678
global_step: 12157, epoch: 4, loss: 1.227372
global_step: 12158, epoch: 4, loss: 1.237798
global_step: 12159, epoch: 4, loss: 1.221278
global_step: 12160, epoch: 4, loss: 1.296588
epoch: 4
train	acc: 0.6109	macro: p 0.4219, r 0.3213, f1: 0.3130	micro: p 0.6109, r 0.6109, f1 0.6109	weighted_f1:0.5580
dev	acc: 0.5104	macro: p 0.2967, r 0.2761, f1: 0.2434	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4404
test	acc: 0.5651	macro: p 0.3791, r 0.2951, f1: 0.2752	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.5110
global_step: 12161, epoch: 5, loss: 1.299238
global_step: 12162, epoch: 5, loss: 1.248841
global_step: 12163, epoch: 5, loss: 1.142537
global_step: 12164, epoch: 5, loss: 1.147808
global_step: 12165, epoch: 5, loss: 1.236204
global_step: 12166, epoch: 5, loss: 1.262023
global_step: 12167, epoch: 5, loss: 1.255421
global_step: 12168, epoch: 5, loss: 1.207810
global_step: 12169, epoch: 5, loss: 1.139212
global_step: 12170, epoch: 5, loss: 1.065121
global_step: 12171, epoch: 5, loss: 1.148474
global_step: 12172, epoch: 5, loss: 1.229701
global_step: 12173, epoch: 5, loss: 1.173980
global_step: 12174, epoch: 5, loss: 1.155395
global_step: 12175, epoch: 5, loss: 1.259952
global_step: 12176, epoch: 5, loss: 1.205390
global_step: 12177, epoch: 5, loss: 1.147850
global_step: 12178, epoch: 5, loss: 1.190512
global_step: 12179, epoch: 5, loss: 1.254919
global_step: 12180, epoch: 5, loss: 1.229505
global_step: 12181, epoch: 5, loss: 1.192778
global_step: 12182, epoch: 5, loss: 1.128042
global_step: 12183, epoch: 5, loss: 1.273353
global_step: 12184, epoch: 5, loss: 1.330966
global_step: 12185, epoch: 5, loss: 1.175772
global_step: 12186, epoch: 5, loss: 1.142585
global_step: 12187, epoch: 5, loss: 1.113967
global_step: 12188, epoch: 5, loss: 1.192431
global_step: 12189, epoch: 5, loss: 1.200049
global_step: 12190, epoch: 5, loss: 1.307918
global_step: 12191, epoch: 5, loss: 1.183902
global_step: 12192, epoch: 5, loss: 1.243671
global_step: 12193, epoch: 5, loss: 1.125829
global_step: 12194, epoch: 5, loss: 1.250394
global_step: 12195, epoch: 5, loss: 1.211399
global_step: 12196, epoch: 5, loss: 1.186648
global_step: 12197, epoch: 5, loss: 1.136208
global_step: 12198, epoch: 5, loss: 1.241378
global_step: 12199, epoch: 5, loss: 1.200025
global_step: 12200, epoch: 5, loss: 1.503282
epoch: 5
train	acc: 0.6015	macro: p 0.4061, r 0.3541, f1: 0.3334	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5564
dev	acc: 0.5194	macro: p 0.3464, r 0.2921, f1: 0.2771	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4672
test	acc: 0.5762	macro: p 0.3710, r 0.3197, f1: 0.3039	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5341
New best model!
global_step: 12201, epoch: 6, loss: 1.085935
global_step: 12202, epoch: 6, loss: 1.119483
global_step: 12203, epoch: 6, loss: 1.137228
global_step: 12204, epoch: 6, loss: 1.207135
global_step: 12205, epoch: 6, loss: 1.168491
global_step: 12206, epoch: 6, loss: 1.181589
global_step: 12207, epoch: 6, loss: 1.141111
global_step: 12208, epoch: 6, loss: 1.206761
global_step: 12209, epoch: 6, loss: 1.094095
global_step: 12210, epoch: 6, loss: 1.037288
global_step: 12211, epoch: 6, loss: 1.145023
global_step: 12212, epoch: 6, loss: 1.185942
global_step: 12213, epoch: 6, loss: 1.254315
global_step: 12214, epoch: 6, loss: 1.076691
global_step: 12215, epoch: 6, loss: 1.121552
global_step: 12216, epoch: 6, loss: 1.175143
global_step: 12217, epoch: 6, loss: 1.081371
global_step: 12218, epoch: 6, loss: 1.159957
global_step: 12219, epoch: 6, loss: 1.093682
global_step: 12220, epoch: 6, loss: 1.110844
global_step: 12221, epoch: 6, loss: 1.162741
global_step: 12222, epoch: 6, loss: 1.172950
global_step: 12223, epoch: 6, loss: 1.250299
global_step: 12224, epoch: 6, loss: 1.221565
global_step: 12225, epoch: 6, loss: 1.300578
global_step: 12226, epoch: 6, loss: 1.300393
global_step: 12227, epoch: 6, loss: 1.142257
global_step: 12228, epoch: 6, loss: 1.149922
global_step: 12229, epoch: 6, loss: 1.201369
global_step: 12230, epoch: 6, loss: 1.163355
global_step: 12231, epoch: 6, loss: 1.287935
global_step: 12232, epoch: 6, loss: 1.148931
global_step: 12233, epoch: 6, loss: 1.205993
global_step: 12234, epoch: 6, loss: 1.241896
global_step: 12235, epoch: 6, loss: 1.234501
global_step: 12236, epoch: 6, loss: 1.093386
global_step: 12237, epoch: 6, loss: 1.255370
global_step: 12238, epoch: 6, loss: 1.175310
global_step: 12239, epoch: 6, loss: 1.109644
global_step: 12240, epoch: 6, loss: 0.169720
epoch: 6
train	acc: 0.6346	macro: p 0.4525, r 0.3339, f1: 0.3368	micro: p 0.6346, r 0.6346, f1 0.6346	weighted_f1:0.5757
dev	acc: 0.5455	macro: p 0.3874, r 0.2893, f1: 0.2652	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4637
test	acc: 0.5889	macro: p 0.3737, r 0.2914, f1: 0.2768	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5186
global_step: 12241, epoch: 7, loss: 1.239040
global_step: 12242, epoch: 7, loss: 1.147118
global_step: 12243, epoch: 7, loss: 1.212250
global_step: 12244, epoch: 7, loss: 1.052149
global_step: 12245, epoch: 7, loss: 1.121569
global_step: 12246, epoch: 7, loss: 1.196372
global_step: 12247, epoch: 7, loss: 1.245255
global_step: 12248, epoch: 7, loss: 1.173087
global_step: 12249, epoch: 7, loss: 1.184620
global_step: 12250, epoch: 7, loss: 1.044860
global_step: 12251, epoch: 7, loss: 1.135554
global_step: 12252, epoch: 7, loss: 1.123573
global_step: 12253, epoch: 7, loss: 1.145308
global_step: 12254, epoch: 7, loss: 1.149019
global_step: 12255, epoch: 7, loss: 0.980452
global_step: 12256, epoch: 7, loss: 1.127612
global_step: 12257, epoch: 7, loss: 1.086600
global_step: 12258, epoch: 7, loss: 1.125490
global_step: 12259, epoch: 7, loss: 1.144897
global_step: 12260, epoch: 7, loss: 1.198003
global_step: 12261, epoch: 7, loss: 1.078594
global_step: 12262, epoch: 7, loss: 1.218071
global_step: 12263, epoch: 7, loss: 1.235485
global_step: 12264, epoch: 7, loss: 1.009099
global_step: 12265, epoch: 7, loss: 1.023111
global_step: 12266, epoch: 7, loss: 1.178041
global_step: 12267, epoch: 7, loss: 1.162961
global_step: 12268, epoch: 7, loss: 1.101156
global_step: 12269, epoch: 7, loss: 1.060142
global_step: 12270, epoch: 7, loss: 1.080005
global_step: 12271, epoch: 7, loss: 1.221659
global_step: 12272, epoch: 7, loss: 1.061412
global_step: 12273, epoch: 7, loss: 1.150399
global_step: 12274, epoch: 7, loss: 1.090071
global_step: 12275, epoch: 7, loss: 1.103605
global_step: 12276, epoch: 7, loss: 1.154567
global_step: 12277, epoch: 7, loss: 1.131314
global_step: 12278, epoch: 7, loss: 0.997452
global_step: 12279, epoch: 7, loss: 1.174722
global_step: 12280, epoch: 7, loss: 1.531838
epoch: 7
train	acc: 0.6202	macro: p 0.4387, r 0.3875, f1: 0.3636	micro: p 0.6202, r 0.6202, f1 0.6202	weighted_f1:0.6035
dev	acc: 0.5014	macro: p 0.3507, r 0.3053, f1: 0.2891	micro: p 0.5014, r 0.5014, f1 0.5014	weighted_f1:0.4729
test	acc: 0.5429	macro: p 0.3653, r 0.3202, f1: 0.3018	micro: p 0.5429, r 0.5429, f1 0.5429	weighted_f1:0.5245
New best model!
global_step: 12281, epoch: 8, loss: 1.131311
global_step: 12282, epoch: 8, loss: 0.947011
global_step: 12283, epoch: 8, loss: 1.131110
global_step: 12284, epoch: 8, loss: 1.066830
global_step: 12285, epoch: 8, loss: 1.076072
global_step: 12286, epoch: 8, loss: 1.086024
global_step: 12287, epoch: 8, loss: 1.081161
global_step: 12288, epoch: 8, loss: 1.144314
global_step: 12289, epoch: 8, loss: 1.066173
global_step: 12290, epoch: 8, loss: 1.211197
global_step: 12291, epoch: 8, loss: 1.158831
global_step: 12292, epoch: 8, loss: 0.977438
global_step: 12293, epoch: 8, loss: 1.055334
global_step: 12294, epoch: 8, loss: 1.075070
global_step: 12295, epoch: 8, loss: 1.092281
global_step: 12296, epoch: 8, loss: 1.126240
global_step: 12297, epoch: 8, loss: 1.105886
global_step: 12298, epoch: 8, loss: 1.006376
global_step: 12299, epoch: 8, loss: 1.159252
global_step: 12300, epoch: 8, loss: 1.037783
global_step: 12301, epoch: 8, loss: 1.140000
global_step: 12302, epoch: 8, loss: 1.102797
global_step: 12303, epoch: 8, loss: 1.135672
global_step: 12304, epoch: 8, loss: 1.038786
global_step: 12305, epoch: 8, loss: 1.068023
global_step: 12306, epoch: 8, loss: 1.066038
global_step: 12307, epoch: 8, loss: 1.057084
global_step: 12308, epoch: 8, loss: 1.137631
global_step: 12309, epoch: 8, loss: 1.189666
global_step: 12310, epoch: 8, loss: 1.119506
global_step: 12311, epoch: 8, loss: 1.130565
global_step: 12312, epoch: 8, loss: 0.962671
global_step: 12313, epoch: 8, loss: 1.043965
global_step: 12314, epoch: 8, loss: 1.118354
global_step: 12315, epoch: 8, loss: 1.028512
global_step: 12316, epoch: 8, loss: 1.102361
global_step: 12317, epoch: 8, loss: 1.004208
global_step: 12318, epoch: 8, loss: 1.034303
global_step: 12319, epoch: 8, loss: 1.054576
global_step: 12320, epoch: 8, loss: 0.263135
epoch: 8
train	acc: 0.6207	macro: p 0.4805, r 0.3105, f1: 0.3317	micro: p 0.6207, r 0.6207, f1 0.6207	weighted_f1:0.5594
dev	acc: 0.5257	macro: p 0.3638, r 0.2583, f1: 0.2533	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4446
test	acc: 0.5858	macro: p 0.3968, r 0.2710, f1: 0.2794	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5135
global_step: 12321, epoch: 9, loss: 1.394078
global_step: 12322, epoch: 9, loss: 1.028206
global_step: 12323, epoch: 9, loss: 1.103577
global_step: 12324, epoch: 9, loss: 1.056579
global_step: 12325, epoch: 9, loss: 0.999466
global_step: 12326, epoch: 9, loss: 1.024023
global_step: 12327, epoch: 9, loss: 0.969932
global_step: 12328, epoch: 9, loss: 0.937851
global_step: 12329, epoch: 9, loss: 0.931929
global_step: 12330, epoch: 9, loss: 0.997407
global_step: 12331, epoch: 9, loss: 1.008177
global_step: 12332, epoch: 9, loss: 1.115212
global_step: 12333, epoch: 9, loss: 0.967292
global_step: 12334, epoch: 9, loss: 1.034834
global_step: 12335, epoch: 9, loss: 1.153523
global_step: 12336, epoch: 9, loss: 1.050544
global_step: 12337, epoch: 9, loss: 1.065691
global_step: 12338, epoch: 9, loss: 1.036415
global_step: 12339, epoch: 9, loss: 1.060321
global_step: 12340, epoch: 9, loss: 1.071199
global_step: 12341, epoch: 9, loss: 1.084858
global_step: 12342, epoch: 9, loss: 0.921817
global_step: 12343, epoch: 9, loss: 1.093510
global_step: 12344, epoch: 9, loss: 1.088603
global_step: 12345, epoch: 9, loss: 1.076414
global_step: 12346, epoch: 9, loss: 1.061280
global_step: 12347, epoch: 9, loss: 1.064250
global_step: 12348, epoch: 9, loss: 0.979498
global_step: 12349, epoch: 9, loss: 1.093772
global_step: 12350, epoch: 9, loss: 1.045521
global_step: 12351, epoch: 9, loss: 1.024516
global_step: 12352, epoch: 9, loss: 1.128827
global_step: 12353, epoch: 9, loss: 1.115730
global_step: 12354, epoch: 9, loss: 1.038766
global_step: 12355, epoch: 9, loss: 1.017477
global_step: 12356, epoch: 9, loss: 1.035821
global_step: 12357, epoch: 9, loss: 0.971699
global_step: 12358, epoch: 9, loss: 1.107067
global_step: 12359, epoch: 9, loss: 1.056600
global_step: 12360, epoch: 9, loss: 0.831984
epoch: 9
train	acc: 0.6533	macro: p 0.4813, r 0.3712, f1: 0.3565	micro: p 0.6533, r 0.6533, f1 0.6533	weighted_f1:0.6012
dev	acc: 0.5176	macro: p 0.3313, r 0.2809, f1: 0.2471	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4417
test	acc: 0.5648	macro: p 0.3609, r 0.2920, f1: 0.2615	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.5015
global_step: 12361, epoch: 10, loss: 1.080757
global_step: 12362, epoch: 10, loss: 0.956275
global_step: 12363, epoch: 10, loss: 0.986345
global_step: 12364, epoch: 10, loss: 0.970887
global_step: 12365, epoch: 10, loss: 0.976029
global_step: 12366, epoch: 10, loss: 1.000857
global_step: 12367, epoch: 10, loss: 0.924636
global_step: 12368, epoch: 10, loss: 0.880242
global_step: 12369, epoch: 10, loss: 1.015421
global_step: 12370, epoch: 10, loss: 0.997533
global_step: 12371, epoch: 10, loss: 0.984442
global_step: 12372, epoch: 10, loss: 0.958652
global_step: 12373, epoch: 10, loss: 1.019281
global_step: 12374, epoch: 10, loss: 0.993259
global_step: 12375, epoch: 10, loss: 1.081359
global_step: 12376, epoch: 10, loss: 0.922923
global_step: 12377, epoch: 10, loss: 1.003771
global_step: 12378, epoch: 10, loss: 0.947481
global_step: 12379, epoch: 10, loss: 1.203582
global_step: 12380, epoch: 10, loss: 1.094754
global_step: 12381, epoch: 10, loss: 0.991183
global_step: 12382, epoch: 10, loss: 0.947020
global_step: 12383, epoch: 10, loss: 0.947817
global_step: 12384, epoch: 10, loss: 1.029747
global_step: 12385, epoch: 10, loss: 1.089031
global_step: 12386, epoch: 10, loss: 1.070562
global_step: 12387, epoch: 10, loss: 1.079456
global_step: 12388, epoch: 10, loss: 1.015891
global_step: 12389, epoch: 10, loss: 1.134504
global_step: 12390, epoch: 10, loss: 0.977413
global_step: 12391, epoch: 10, loss: 1.068732
global_step: 12392, epoch: 10, loss: 1.066406
global_step: 12393, epoch: 10, loss: 0.987253
global_step: 12394, epoch: 10, loss: 1.041692
global_step: 12395, epoch: 10, loss: 1.002095
global_step: 12396, epoch: 10, loss: 1.143894
global_step: 12397, epoch: 10, loss: 0.988867
global_step: 12398, epoch: 10, loss: 0.977476
global_step: 12399, epoch: 10, loss: 0.925397
global_step: 12400, epoch: 10, loss: 0.698629
epoch: 10
train	acc: 0.5572	macro: p 0.5067, r 0.3525, f1: 0.3353	micro: p 0.5572, r 0.5572, f1 0.5572	weighted_f1:0.5479
dev	acc: 0.3922	macro: p 0.3359, r 0.2536, f1: 0.2112	micro: p 0.3922, r 0.3922, f1 0.3922	weighted_f1:0.3687
test	acc: 0.4238	macro: p 0.3612, r 0.2685, f1: 0.2290	micro: p 0.4238, r 0.4238, f1 0.4238	weighted_f1:0.4090
global_step: 12401, epoch: 11, loss: 1.377733
global_step: 12402, epoch: 11, loss: 0.971845
global_step: 12403, epoch: 11, loss: 0.955049
global_step: 12404, epoch: 11, loss: 0.892014
global_step: 12405, epoch: 11, loss: 0.901296
global_step: 12406, epoch: 11, loss: 0.906828
global_step: 12407, epoch: 11, loss: 0.965302
global_step: 12408, epoch: 11, loss: 0.930793
global_step: 12409, epoch: 11, loss: 0.915686
global_step: 12410, epoch: 11, loss: 0.956729
global_step: 12411, epoch: 11, loss: 0.991587
global_step: 12412, epoch: 11, loss: 0.940321
global_step: 12413, epoch: 11, loss: 0.929568
global_step: 12414, epoch: 11, loss: 1.011773
global_step: 12415, epoch: 11, loss: 1.023147
global_step: 12416, epoch: 11, loss: 1.065353
global_step: 12417, epoch: 11, loss: 0.943381
global_step: 12418, epoch: 11, loss: 0.957842
global_step: 12419, epoch: 11, loss: 0.976827
global_step: 12420, epoch: 11, loss: 0.909215
global_step: 12421, epoch: 11, loss: 1.031645
global_step: 12422, epoch: 11, loss: 1.008738
global_step: 12423, epoch: 11, loss: 0.926988
global_step: 12424, epoch: 11, loss: 0.905035
global_step: 12425, epoch: 11, loss: 0.931640
global_step: 12426, epoch: 11, loss: 0.812079
global_step: 12427, epoch: 11, loss: 0.931772
global_step: 12428, epoch: 11, loss: 1.011009
global_step: 12429, epoch: 11, loss: 1.059409
global_step: 12430, epoch: 11, loss: 1.061701
global_step: 12431, epoch: 11, loss: 0.997453
global_step: 12432, epoch: 11, loss: 0.922783
global_step: 12433, epoch: 11, loss: 0.919565
global_step: 12434, epoch: 11, loss: 0.906152
global_step: 12435, epoch: 11, loss: 1.052680
global_step: 12436, epoch: 11, loss: 1.030144
global_step: 12437, epoch: 11, loss: 0.912773
global_step: 12438, epoch: 11, loss: 1.096264
global_step: 12439, epoch: 11, loss: 1.009673
global_step: 12440, epoch: 11, loss: 0.674010
epoch: 11
train	acc: 0.7264	macro: p 0.8065, r 0.4703, f1: 0.4765	micro: p 0.7264, r 0.7264, f1 0.7264	weighted_f1:0.7062
dev	acc: 0.5005	macro: p 0.3317, r 0.2917, f1: 0.2707	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.4611
test	acc: 0.5487	macro: p 0.3606, r 0.3043, f1: 0.2947	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.5224
global_step: 12441, epoch: 12, loss: 1.009735
global_step: 12442, epoch: 12, loss: 0.924888
global_step: 12443, epoch: 12, loss: 0.890437
global_step: 12444, epoch: 12, loss: 0.952056
global_step: 12445, epoch: 12, loss: 0.858747
global_step: 12446, epoch: 12, loss: 0.835435
global_step: 12447, epoch: 12, loss: 0.913864
global_step: 12448, epoch: 12, loss: 0.854355
global_step: 12449, epoch: 12, loss: 0.937006
global_step: 12450, epoch: 12, loss: 0.809216
global_step: 12451, epoch: 12, loss: 0.985701
global_step: 12452, epoch: 12, loss: 0.995021
global_step: 12453, epoch: 12, loss: 0.810856
global_step: 12454, epoch: 12, loss: 0.863793
global_step: 12455, epoch: 12, loss: 0.840567
global_step: 12456, epoch: 12, loss: 0.937808
global_step: 12457, epoch: 12, loss: 0.985625
global_step: 12458, epoch: 12, loss: 0.825481
global_step: 12459, epoch: 12, loss: 0.981782
global_step: 12460, epoch: 12, loss: 0.876456
global_step: 12461, epoch: 12, loss: 0.890620
global_step: 12462, epoch: 12, loss: 0.842724
global_step: 12463, epoch: 12, loss: 0.844908
global_step: 12464, epoch: 12, loss: 0.982071
global_step: 12465, epoch: 12, loss: 0.937446
global_step: 12466, epoch: 12, loss: 0.968854
global_step: 12467, epoch: 12, loss: 0.983919
global_step: 12468, epoch: 12, loss: 0.851878
global_step: 12469, epoch: 12, loss: 0.893492
global_step: 12470, epoch: 12, loss: 0.943220
global_step: 12471, epoch: 12, loss: 0.879896
global_step: 12472, epoch: 12, loss: 1.063738
global_step: 12473, epoch: 12, loss: 0.903257
global_step: 12474, epoch: 12, loss: 0.894525
global_step: 12475, epoch: 12, loss: 0.905121
global_step: 12476, epoch: 12, loss: 0.961208
global_step: 12477, epoch: 12, loss: 1.001309
global_step: 12478, epoch: 12, loss: 0.901224
global_step: 12479, epoch: 12, loss: 1.004426
global_step: 12480, epoch: 12, loss: 0.311561
epoch: 12
train	acc: 0.7060	macro: p 0.5346, r 0.4155, f1: 0.4392	micro: p 0.7060, r 0.7060, f1 0.7060	weighted_f1:0.6649
dev	acc: 0.5419	macro: p 0.3478, r 0.2846, f1: 0.2817	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4741
test	acc: 0.5931	macro: p 0.3793, r 0.2889, f1: 0.2942	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5307
New best model!
global_step: 12481, epoch: 13, loss: 0.929847
global_step: 12482, epoch: 13, loss: 0.795386
global_step: 12483, epoch: 13, loss: 0.811286
global_step: 12484, epoch: 13, loss: 0.811375
global_step: 12485, epoch: 13, loss: 0.703754
global_step: 12486, epoch: 13, loss: 0.972160
global_step: 12487, epoch: 13, loss: 0.834812
global_step: 12488, epoch: 13, loss: 0.938945
global_step: 12489, epoch: 13, loss: 0.947936
global_step: 12490, epoch: 13, loss: 0.907449
global_step: 12491, epoch: 13, loss: 0.764988
global_step: 12492, epoch: 13, loss: 0.920781
global_step: 12493, epoch: 13, loss: 0.893854
global_step: 12494, epoch: 13, loss: 0.848177
global_step: 12495, epoch: 13, loss: 0.858568
global_step: 12496, epoch: 13, loss: 0.925436
global_step: 12497, epoch: 13, loss: 0.851572
global_step: 12498, epoch: 13, loss: 0.890114
global_step: 12499, epoch: 13, loss: 0.831174
global_step: 12500, epoch: 13, loss: 0.786851
global_step: 12501, epoch: 13, loss: 0.954294
global_step: 12502, epoch: 13, loss: 0.889669
global_step: 12503, epoch: 13, loss: 0.835557
global_step: 12504, epoch: 13, loss: 0.913379
global_step: 12505, epoch: 13, loss: 0.850590
global_step: 12506, epoch: 13, loss: 0.898651
global_step: 12507, epoch: 13, loss: 0.904378
global_step: 12508, epoch: 13, loss: 0.833502
global_step: 12509, epoch: 13, loss: 0.892787
global_step: 12510, epoch: 13, loss: 0.936272
global_step: 12511, epoch: 13, loss: 0.810413
global_step: 12512, epoch: 13, loss: 0.872035
global_step: 12513, epoch: 13, loss: 0.979935
global_step: 12514, epoch: 13, loss: 0.782268
global_step: 12515, epoch: 13, loss: 0.857865
global_step: 12516, epoch: 13, loss: 0.948927
global_step: 12517, epoch: 13, loss: 0.960128
global_step: 12518, epoch: 13, loss: 0.991026
global_step: 12519, epoch: 13, loss: 0.921901
global_step: 12520, epoch: 13, loss: 1.681932
epoch: 13
train	acc: 0.7819	macro: p 0.7892, r 0.5839, f1: 0.6214	micro: p 0.7819, r 0.7819, f1 0.7819	weighted_f1:0.7744
dev	acc: 0.4968	macro: p 0.3030, r 0.2868, f1: 0.2664	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.4561
test	acc: 0.5498	macro: p 0.3423, r 0.3082, f1: 0.2989	micro: p 0.5498, r 0.5498, f1 0.5498	weighted_f1:0.5234
global_step: 12521, epoch: 14, loss: 0.926669
global_step: 12522, epoch: 14, loss: 0.838923
global_step: 12523, epoch: 14, loss: 0.824465
global_step: 12524, epoch: 14, loss: 0.871677
global_step: 12525, epoch: 14, loss: 0.924639
global_step: 12526, epoch: 14, loss: 0.827362
global_step: 12527, epoch: 14, loss: 0.809528
global_step: 12528, epoch: 14, loss: 0.840184
global_step: 12529, epoch: 14, loss: 0.850385
global_step: 12530, epoch: 14, loss: 0.789974
global_step: 12531, epoch: 14, loss: 0.720913
global_step: 12532, epoch: 14, loss: 0.816366
global_step: 12533, epoch: 14, loss: 0.753462
global_step: 12534, epoch: 14, loss: 0.837399
global_step: 12535, epoch: 14, loss: 0.763286
global_step: 12536, epoch: 14, loss: 0.924336
global_step: 12537, epoch: 14, loss: 0.824798
global_step: 12538, epoch: 14, loss: 0.841708
global_step: 12539, epoch: 14, loss: 0.818686
global_step: 12540, epoch: 14, loss: 0.922326
global_step: 12541, epoch: 14, loss: 0.825558
global_step: 12542, epoch: 14, loss: 0.783011
global_step: 12543, epoch: 14, loss: 0.872746
global_step: 12544, epoch: 14, loss: 0.874560
global_step: 12545, epoch: 14, loss: 0.914116
global_step: 12546, epoch: 14, loss: 0.850644
global_step: 12547, epoch: 14, loss: 0.744046
global_step: 12548, epoch: 14, loss: 0.846802
global_step: 12549, epoch: 14, loss: 0.823883
global_step: 12550, epoch: 14, loss: 0.887922
global_step: 12551, epoch: 14, loss: 0.855240
global_step: 12552, epoch: 14, loss: 0.852890
global_step: 12553, epoch: 14, loss: 0.858029
global_step: 12554, epoch: 14, loss: 0.915850
global_step: 12555, epoch: 14, loss: 0.775313
global_step: 12556, epoch: 14, loss: 0.875682
global_step: 12557, epoch: 14, loss: 0.909847
global_step: 12558, epoch: 14, loss: 0.944592
global_step: 12559, epoch: 14, loss: 0.849254
global_step: 12560, epoch: 14, loss: 0.527516
epoch: 14
train	acc: 0.7691	macro: p 0.8197, r 0.5359, f1: 0.5449	micro: p 0.7691, r 0.7691, f1 0.7691	weighted_f1:0.7455
dev	acc: 0.5239	macro: p 0.3056, r 0.2958, f1: 0.2642	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4558
test	acc: 0.5590	macro: p 0.3150, r 0.2994, f1: 0.2724	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5059
global_step: 12561, epoch: 15, loss: 0.852937
global_step: 12562, epoch: 15, loss: 0.849137
global_step: 12563, epoch: 15, loss: 0.793771
global_step: 12564, epoch: 15, loss: 0.789876
global_step: 12565, epoch: 15, loss: 0.739536
global_step: 12566, epoch: 15, loss: 0.792607
global_step: 12567, epoch: 15, loss: 0.736333
global_step: 12568, epoch: 15, loss: 0.837180
global_step: 12569, epoch: 15, loss: 0.856404
global_step: 12570, epoch: 15, loss: 0.849025
global_step: 12571, epoch: 15, loss: 0.849963
global_step: 12572, epoch: 15, loss: 0.829619
global_step: 12573, epoch: 15, loss: 0.751728
global_step: 12574, epoch: 15, loss: 0.723748
global_step: 12575, epoch: 15, loss: 0.767911
global_step: 12576, epoch: 15, loss: 0.913100
global_step: 12577, epoch: 15, loss: 0.689682
global_step: 12578, epoch: 15, loss: 0.746834
global_step: 12579, epoch: 15, loss: 0.738085
global_step: 12580, epoch: 15, loss: 0.921359
global_step: 12581, epoch: 15, loss: 0.827568
global_step: 12582, epoch: 15, loss: 0.804065
global_step: 12583, epoch: 15, loss: 0.911437
global_step: 12584, epoch: 15, loss: 0.765033
global_step: 12585, epoch: 15, loss: 0.864465
global_step: 12586, epoch: 15, loss: 0.793036
global_step: 12587, epoch: 15, loss: 0.794759
global_step: 12588, epoch: 15, loss: 0.789661
global_step: 12589, epoch: 15, loss: 0.775213
global_step: 12590, epoch: 15, loss: 0.919126
global_step: 12591, epoch: 15, loss: 0.809642
global_step: 12592, epoch: 15, loss: 0.827432
global_step: 12593, epoch: 15, loss: 0.788151
global_step: 12594, epoch: 15, loss: 0.720958
global_step: 12595, epoch: 15, loss: 0.805417
global_step: 12596, epoch: 15, loss: 0.838422
global_step: 12597, epoch: 15, loss: 0.777918
global_step: 12598, epoch: 15, loss: 0.659643
global_step: 12599, epoch: 15, loss: 0.937180
global_step: 12600, epoch: 15, loss: 0.599760
epoch: 15
train	acc: 0.8272	macro: p 0.8546, r 0.6370, f1: 0.6814	micro: p 0.8272, r 0.8272, f1 0.8272	weighted_f1:0.8143
dev	acc: 0.5338	macro: p 0.3040, r 0.2931, f1: 0.2816	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4755
test	acc: 0.5931	macro: p 0.3573, r 0.3174, f1: 0.3176	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5480
New best model!
global_step: 12601, epoch: 16, loss: 0.728693
global_step: 12602, epoch: 16, loss: 0.748750
global_step: 12603, epoch: 16, loss: 0.705357
global_step: 12604, epoch: 16, loss: 0.731942
global_step: 12605, epoch: 16, loss: 0.756243
global_step: 12606, epoch: 16, loss: 0.756663
global_step: 12607, epoch: 16, loss: 0.664348
global_step: 12608, epoch: 16, loss: 0.803891
global_step: 12609, epoch: 16, loss: 0.704902
global_step: 12610, epoch: 16, loss: 0.870168
global_step: 12611, epoch: 16, loss: 0.853439
global_step: 12612, epoch: 16, loss: 0.760251
global_step: 12613, epoch: 16, loss: 0.687801
global_step: 12614, epoch: 16, loss: 0.834374
global_step: 12615, epoch: 16, loss: 0.754333
global_step: 12616, epoch: 16, loss: 0.830611
global_step: 12617, epoch: 16, loss: 0.917448
global_step: 12618, epoch: 16, loss: 0.815172
global_step: 12619, epoch: 16, loss: 0.641211
global_step: 12620, epoch: 16, loss: 0.772384
global_step: 12621, epoch: 16, loss: 0.752998
global_step: 12622, epoch: 16, loss: 0.629397
global_step: 12623, epoch: 16, loss: 0.755736
global_step: 12624, epoch: 16, loss: 0.772207
global_step: 12625, epoch: 16, loss: 0.761504
global_step: 12626, epoch: 16, loss: 0.943313
global_step: 12627, epoch: 16, loss: 0.781304
global_step: 12628, epoch: 16, loss: 0.822105
global_step: 12629, epoch: 16, loss: 0.788547
global_step: 12630, epoch: 16, loss: 0.788647
global_step: 12631, epoch: 16, loss: 0.835062
global_step: 12632, epoch: 16, loss: 0.906510
global_step: 12633, epoch: 16, loss: 0.770576
global_step: 12634, epoch: 16, loss: 0.781534
global_step: 12635, epoch: 16, loss: 0.944847
global_step: 12636, epoch: 16, loss: 0.753555
global_step: 12637, epoch: 16, loss: 0.810884
global_step: 12638, epoch: 16, loss: 0.913724
global_step: 12639, epoch: 16, loss: 0.840923
global_step: 12640, epoch: 16, loss: 0.361413
epoch: 16
train	acc: 0.8158	macro: p 0.8755, r 0.5962, f1: 0.6411	micro: p 0.8158, r 0.8158, f1 0.8158	weighted_f1:0.7992
dev	acc: 0.5491	macro: p 0.3389, r 0.2924, f1: 0.2911	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4877
test	acc: 0.5977	macro: p 0.3725, r 0.3026, f1: 0.3110	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5457
New best model!
global_step: 12641, epoch: 17, loss: 0.750064
global_step: 12642, epoch: 17, loss: 0.611061
global_step: 12643, epoch: 17, loss: 0.644667
global_step: 12644, epoch: 17, loss: 0.665653
global_step: 12645, epoch: 17, loss: 0.737104
global_step: 12646, epoch: 17, loss: 0.711380
global_step: 12647, epoch: 17, loss: 0.663843
global_step: 12648, epoch: 17, loss: 0.716614
global_step: 12649, epoch: 17, loss: 0.712670
global_step: 12650, epoch: 17, loss: 0.729731
global_step: 12651, epoch: 17, loss: 0.803341
global_step: 12652, epoch: 17, loss: 0.687323
global_step: 12653, epoch: 17, loss: 0.661037
global_step: 12654, epoch: 17, loss: 0.718873
global_step: 12655, epoch: 17, loss: 0.725127
global_step: 12656, epoch: 17, loss: 0.681872
global_step: 12657, epoch: 17, loss: 0.784367
global_step: 12658, epoch: 17, loss: 0.742672
global_step: 12659, epoch: 17, loss: 0.829081
global_step: 12660, epoch: 17, loss: 0.770795
global_step: 12661, epoch: 17, loss: 0.704055
global_step: 12662, epoch: 17, loss: 0.736252
global_step: 12663, epoch: 17, loss: 0.683960
global_step: 12664, epoch: 17, loss: 0.730054
global_step: 12665, epoch: 17, loss: 0.716894
global_step: 12666, epoch: 17, loss: 0.682083
global_step: 12667, epoch: 17, loss: 0.742048
global_step: 12668, epoch: 17, loss: 0.874373
global_step: 12669, epoch: 17, loss: 0.813432
global_step: 12670, epoch: 17, loss: 0.787048
global_step: 12671, epoch: 17, loss: 0.679975
global_step: 12672, epoch: 17, loss: 0.803856
global_step: 12673, epoch: 17, loss: 0.922427
global_step: 12674, epoch: 17, loss: 0.741419
global_step: 12675, epoch: 17, loss: 0.805246
global_step: 12676, epoch: 17, loss: 0.821053
global_step: 12677, epoch: 17, loss: 0.794191
global_step: 12678, epoch: 17, loss: 0.675670
global_step: 12679, epoch: 17, loss: 0.766366
global_step: 12680, epoch: 17, loss: 1.020785
epoch: 17
train	acc: 0.8279	macro: p 0.8582, r 0.6228, f1: 0.6574	micro: p 0.8279, r 0.8279, f1 0.8279	weighted_f1:0.8127
dev	acc: 0.5509	macro: p 0.3355, r 0.3056, f1: 0.2953	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4910
test	acc: 0.5904	macro: p 0.3522, r 0.3106, f1: 0.3055	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5422
New best model!
global_step: 12681, epoch: 18, loss: 0.684902
global_step: 12682, epoch: 18, loss: 0.633731
global_step: 12683, epoch: 18, loss: 0.641482
global_step: 12684, epoch: 18, loss: 0.743728
global_step: 12685, epoch: 18, loss: 0.779032
global_step: 12686, epoch: 18, loss: 0.618261
global_step: 12687, epoch: 18, loss: 0.781729
global_step: 12688, epoch: 18, loss: 0.747180
global_step: 12689, epoch: 18, loss: 0.598928
global_step: 12690, epoch: 18, loss: 0.682730
global_step: 12691, epoch: 18, loss: 0.675648
global_step: 12692, epoch: 18, loss: 0.791510
global_step: 12693, epoch: 18, loss: 0.656990
global_step: 12694, epoch: 18, loss: 0.804611
global_step: 12695, epoch: 18, loss: 0.736292
global_step: 12696, epoch: 18, loss: 0.782265
global_step: 12697, epoch: 18, loss: 0.770464
global_step: 12698, epoch: 18, loss: 0.777213
global_step: 12699, epoch: 18, loss: 0.729620
global_step: 12700, epoch: 18, loss: 0.656149
global_step: 12701, epoch: 18, loss: 0.575377
global_step: 12702, epoch: 18, loss: 0.707324
global_step: 12703, epoch: 18, loss: 0.715656
global_step: 12704, epoch: 18, loss: 0.777209
global_step: 12705, epoch: 18, loss: 0.830338
global_step: 12706, epoch: 18, loss: 0.735974
global_step: 12707, epoch: 18, loss: 0.789254
global_step: 12708, epoch: 18, loss: 0.744436
global_step: 12709, epoch: 18, loss: 0.692287
global_step: 12710, epoch: 18, loss: 0.848551
global_step: 12711, epoch: 18, loss: 0.750679
global_step: 12712, epoch: 18, loss: 0.717654
global_step: 12713, epoch: 18, loss: 0.787391
global_step: 12714, epoch: 18, loss: 0.745020
global_step: 12715, epoch: 18, loss: 0.707761
global_step: 12716, epoch: 18, loss: 0.782573
global_step: 12717, epoch: 18, loss: 0.755030
global_step: 12718, epoch: 18, loss: 0.672252
global_step: 12719, epoch: 18, loss: 0.866525
global_step: 12720, epoch: 18, loss: 0.549008
epoch: 18
train	acc: 0.8734	macro: p 0.8854, r 0.7696, f1: 0.8099	micro: p 0.8734, r 0.8734, f1 0.8734	weighted_f1:0.8713
dev	acc: 0.5428	macro: p 0.3576, r 0.3125, f1: 0.3066	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4937
test	acc: 0.5828	macro: p 0.3837, r 0.3231, f1: 0.3217	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5441
New best model!
global_step: 12721, epoch: 19, loss: 0.585469
global_step: 12722, epoch: 19, loss: 0.698646
global_step: 12723, epoch: 19, loss: 0.675400
global_step: 12724, epoch: 19, loss: 0.573137
global_step: 12725, epoch: 19, loss: 0.594933
global_step: 12726, epoch: 19, loss: 0.659503
global_step: 12727, epoch: 19, loss: 0.672217
global_step: 12728, epoch: 19, loss: 0.642918
global_step: 12729, epoch: 19, loss: 0.712294
global_step: 12730, epoch: 19, loss: 0.587739
global_step: 12731, epoch: 19, loss: 0.683446
global_step: 12732, epoch: 19, loss: 0.659654
global_step: 12733, epoch: 19, loss: 0.608876
global_step: 12734, epoch: 19, loss: 0.612551
global_step: 12735, epoch: 19, loss: 0.651619
global_step: 12736, epoch: 19, loss: 0.641528
global_step: 12737, epoch: 19, loss: 0.665514
global_step: 12738, epoch: 19, loss: 0.644168
global_step: 12739, epoch: 19, loss: 0.749438
global_step: 12740, epoch: 19, loss: 0.657853
global_step: 12741, epoch: 19, loss: 0.672626
global_step: 12742, epoch: 19, loss: 0.753642
global_step: 12743, epoch: 19, loss: 0.709065
global_step: 12744, epoch: 19, loss: 0.677506
global_step: 12745, epoch: 19, loss: 0.739607
global_step: 12746, epoch: 19, loss: 0.749404
global_step: 12747, epoch: 19, loss: 0.644083
global_step: 12748, epoch: 19, loss: 0.765454
global_step: 12749, epoch: 19, loss: 0.630553
global_step: 12750, epoch: 19, loss: 0.854633
global_step: 12751, epoch: 19, loss: 0.696819
global_step: 12752, epoch: 19, loss: 0.695957
global_step: 12753, epoch: 19, loss: 0.797507
global_step: 12754, epoch: 19, loss: 0.707843
global_step: 12755, epoch: 19, loss: 0.695409
global_step: 12756, epoch: 19, loss: 0.852568
global_step: 12757, epoch: 19, loss: 0.719523
global_step: 12758, epoch: 19, loss: 0.812629
global_step: 12759, epoch: 19, loss: 0.653885
global_step: 12760, epoch: 19, loss: 0.281986
epoch: 19
train	acc: 0.8672	macro: p 0.8991, r 0.7187, f1: 0.7664	micro: p 0.8672, r 0.8672, f1 0.8672	weighted_f1:0.8602
dev	acc: 0.5392	macro: p 0.4595, r 0.2980, f1: 0.2834	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4763
test	acc: 0.5874	macro: p 0.3464, r 0.3090, f1: 0.2974	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5370
global_step: 12761, epoch: 20, loss: 0.645110
global_step: 12762, epoch: 20, loss: 0.658332
global_step: 12763, epoch: 20, loss: 0.761054
global_step: 12764, epoch: 20, loss: 0.802030
global_step: 12765, epoch: 20, loss: 0.659717
global_step: 12766, epoch: 20, loss: 0.572325
global_step: 12767, epoch: 20, loss: 0.637766
global_step: 12768, epoch: 20, loss: 0.586915
global_step: 12769, epoch: 20, loss: 0.656908
global_step: 12770, epoch: 20, loss: 0.642786
global_step: 12771, epoch: 20, loss: 0.648333
global_step: 12772, epoch: 20, loss: 0.600400
global_step: 12773, epoch: 20, loss: 0.625963
global_step: 12774, epoch: 20, loss: 0.623570
global_step: 12775, epoch: 20, loss: 0.629460
global_step: 12776, epoch: 20, loss: 0.681423
global_step: 12777, epoch: 20, loss: 0.702091
global_step: 12778, epoch: 20, loss: 0.695332
global_step: 12779, epoch: 20, loss: 0.536178
global_step: 12780, epoch: 20, loss: 0.546956
global_step: 12781, epoch: 20, loss: 0.640279
global_step: 12782, epoch: 20, loss: 0.600788
global_step: 12783, epoch: 20, loss: 0.804595
global_step: 12784, epoch: 20, loss: 0.590040
global_step: 12785, epoch: 20, loss: 0.780938
global_step: 12786, epoch: 20, loss: 0.604692
global_step: 12787, epoch: 20, loss: 0.715238
global_step: 12788, epoch: 20, loss: 0.656150
global_step: 12789, epoch: 20, loss: 0.610317
global_step: 12790, epoch: 20, loss: 0.630604
global_step: 12791, epoch: 20, loss: 0.661718
global_step: 12792, epoch: 20, loss: 0.531247
global_step: 12793, epoch: 20, loss: 0.640482
global_step: 12794, epoch: 20, loss: 0.675833
global_step: 12795, epoch: 20, loss: 0.716919
global_step: 12796, epoch: 20, loss: 0.733808
global_step: 12797, epoch: 20, loss: 0.811746
global_step: 12798, epoch: 20, loss: 0.664025
global_step: 12799, epoch: 20, loss: 0.677246
global_step: 12800, epoch: 20, loss: 1.223270
epoch: 20
train	acc: 0.8673	macro: p 0.8568, r 0.7808, f1: 0.7994	micro: p 0.8673, r 0.8673, f1 0.8673	weighted_f1:0.8683
dev	acc: 0.4905	macro: p 0.3454, r 0.3086, f1: 0.3087	micro: p 0.4905, r 0.4905, f1 0.4905	weighted_f1:0.4791
test	acc: 0.5291	macro: p 0.3714, r 0.3308, f1: 0.3303	micro: p 0.5291, r 0.5291, f1 0.5291	weighted_f1:0.5296
global_step: 12801, epoch: 21, loss: 0.659641
global_step: 12802, epoch: 21, loss: 0.675535
global_step: 12803, epoch: 21, loss: 0.617821
global_step: 12804, epoch: 21, loss: 0.620895
global_step: 12805, epoch: 21, loss: 0.500410
global_step: 12806, epoch: 21, loss: 0.655965
global_step: 12807, epoch: 21, loss: 0.655981
global_step: 12808, epoch: 21, loss: 0.686369
global_step: 12809, epoch: 21, loss: 0.664547
global_step: 12810, epoch: 21, loss: 0.641140
global_step: 12811, epoch: 21, loss: 0.497734
global_step: 12812, epoch: 21, loss: 0.614737
global_step: 12813, epoch: 21, loss: 0.625035
global_step: 12814, epoch: 21, loss: 0.559884
global_step: 12815, epoch: 21, loss: 0.619865
global_step: 12816, epoch: 21, loss: 0.567042
global_step: 12817, epoch: 21, loss: 0.655011
global_step: 12818, epoch: 21, loss: 0.752730
global_step: 12819, epoch: 21, loss: 0.694613
global_step: 12820, epoch: 21, loss: 0.584830
global_step: 12821, epoch: 21, loss: 0.657188
global_step: 12822, epoch: 21, loss: 0.590851
global_step: 12823, epoch: 21, loss: 0.725213
global_step: 12824, epoch: 21, loss: 0.613008
global_step: 12825, epoch: 21, loss: 0.632759
global_step: 12826, epoch: 21, loss: 0.693876
global_step: 12827, epoch: 21, loss: 0.714736
global_step: 12828, epoch: 21, loss: 0.690914
global_step: 12829, epoch: 21, loss: 0.695051
global_step: 12830, epoch: 21, loss: 0.757813
global_step: 12831, epoch: 21, loss: 0.613184
global_step: 12832, epoch: 21, loss: 0.670818
global_step: 12833, epoch: 21, loss: 0.715552
global_step: 12834, epoch: 21, loss: 0.643049
global_step: 12835, epoch: 21, loss: 0.669361
global_step: 12836, epoch: 21, loss: 0.718453
global_step: 12837, epoch: 21, loss: 0.680698
global_step: 12838, epoch: 21, loss: 0.561723
global_step: 12839, epoch: 21, loss: 0.752725
global_step: 12840, epoch: 21, loss: 0.462687
epoch: 21
train	acc: 0.8450	macro: p 0.8495, r 0.7605, f1: 0.7674	micro: p 0.8450, r 0.8450, f1 0.8450	weighted_f1:0.8525
dev	acc: 0.4752	macro: p 0.3931, r 0.3286, f1: 0.3135	micro: p 0.4752, r 0.4752, f1 0.4752	weighted_f1:0.4707
test	acc: 0.4962	macro: p 0.3446, r 0.3341, f1: 0.3071	micro: p 0.4962, r 0.4962, f1 0.4962	weighted_f1:0.5050
global_step: 12841, epoch: 22, loss: 0.756767
global_step: 12842, epoch: 22, loss: 0.615166
global_step: 12843, epoch: 22, loss: 0.490551
global_step: 12844, epoch: 22, loss: 0.517851
global_step: 12845, epoch: 22, loss: 0.694544
global_step: 12846, epoch: 22, loss: 0.549349
global_step: 12847, epoch: 22, loss: 0.590564
global_step: 12848, epoch: 22, loss: 0.557979
global_step: 12849, epoch: 22, loss: 0.588665
global_step: 12850, epoch: 22, loss: 0.582182
global_step: 12851, epoch: 22, loss: 0.520507
global_step: 12852, epoch: 22, loss: 0.660858
global_step: 12853, epoch: 22, loss: 0.502000
global_step: 12854, epoch: 22, loss: 0.516582
global_step: 12855, epoch: 22, loss: 0.541554
global_step: 12856, epoch: 22, loss: 0.551647
global_step: 12857, epoch: 22, loss: 0.659179
global_step: 12858, epoch: 22, loss: 0.700278
global_step: 12859, epoch: 22, loss: 0.597179
global_step: 12860, epoch: 22, loss: 0.577534
global_step: 12861, epoch: 22, loss: 0.792881
global_step: 12862, epoch: 22, loss: 0.565720
global_step: 12863, epoch: 22, loss: 0.630219
global_step: 12864, epoch: 22, loss: 0.644026
global_step: 12865, epoch: 22, loss: 0.540729
global_step: 12866, epoch: 22, loss: 0.699078
global_step: 12867, epoch: 22, loss: 0.577124
global_step: 12868, epoch: 22, loss: 0.700265
global_step: 12869, epoch: 22, loss: 0.576586
global_step: 12870, epoch: 22, loss: 0.531620
global_step: 12871, epoch: 22, loss: 0.611760
global_step: 12872, epoch: 22, loss: 0.572533
global_step: 12873, epoch: 22, loss: 0.553303
global_step: 12874, epoch: 22, loss: 0.632937
global_step: 12875, epoch: 22, loss: 0.587615
global_step: 12876, epoch: 22, loss: 0.560661
global_step: 12877, epoch: 22, loss: 0.570753
global_step: 12878, epoch: 22, loss: 0.685816
global_step: 12879, epoch: 22, loss: 0.620186
global_step: 12880, epoch: 22, loss: 1.196258
epoch: 22
train	acc: 0.8946	macro: p 0.9022, r 0.8048, f1: 0.8381	micro: p 0.8946, r 0.8946, f1 0.8946	weighted_f1:0.8922
dev	acc: 0.5230	macro: p 0.3973, r 0.3063, f1: 0.3103	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4841
test	acc: 0.5716	macro: p 0.3584, r 0.3133, f1: 0.3154	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5346
global_step: 12881, epoch: 23, loss: 0.597177
global_step: 12882, epoch: 23, loss: 0.480973
global_step: 12883, epoch: 23, loss: 0.627215
global_step: 12884, epoch: 23, loss: 0.607289
global_step: 12885, epoch: 23, loss: 0.610698
global_step: 12886, epoch: 23, loss: 0.604323
global_step: 12887, epoch: 23, loss: 0.618823
global_step: 12888, epoch: 23, loss: 0.478718
global_step: 12889, epoch: 23, loss: 0.531163
global_step: 12890, epoch: 23, loss: 0.612561
global_step: 12891, epoch: 23, loss: 0.562359
global_step: 12892, epoch: 23, loss: 0.545084
global_step: 12893, epoch: 23, loss: 0.560144
global_step: 12894, epoch: 23, loss: 0.545669
global_step: 12895, epoch: 23, loss: 0.587823
global_step: 12896, epoch: 23, loss: 0.515616
global_step: 12897, epoch: 23, loss: 0.572715
global_step: 12898, epoch: 23, loss: 0.618830
global_step: 12899, epoch: 23, loss: 0.632498
global_step: 12900, epoch: 23, loss: 0.649971
global_step: 12901, epoch: 23, loss: 0.598121
global_step: 12902, epoch: 23, loss: 0.418147
global_step: 12903, epoch: 23, loss: 0.626159
global_step: 12904, epoch: 23, loss: 0.581352
global_step: 12905, epoch: 23, loss: 0.581210
global_step: 12906, epoch: 23, loss: 0.653126
global_step: 12907, epoch: 23, loss: 0.583902
global_step: 12908, epoch: 23, loss: 0.567262
global_step: 12909, epoch: 23, loss: 0.473120
global_step: 12910, epoch: 23, loss: 0.598597
global_step: 12911, epoch: 23, loss: 0.588313
global_step: 12912, epoch: 23, loss: 0.563153
global_step: 12913, epoch: 23, loss: 0.775979
global_step: 12914, epoch: 23, loss: 0.589703
global_step: 12915, epoch: 23, loss: 0.563157
global_step: 12916, epoch: 23, loss: 0.693823
global_step: 12917, epoch: 23, loss: 0.646134
global_step: 12918, epoch: 23, loss: 0.562812
global_step: 12919, epoch: 23, loss: 0.634945
global_step: 12920, epoch: 23, loss: 0.131325
epoch: 23
train	acc: 0.9101	macro: p 0.9269, r 0.8312, f1: 0.8689	micro: p 0.9101, r 0.9101, f1 0.9101	weighted_f1:0.9088
dev	acc: 0.5338	macro: p 0.3894, r 0.3053, f1: 0.3031	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4854
test	acc: 0.5820	macro: p 0.4114, r 0.3139, f1: 0.3163	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5399
global_step: 12921, epoch: 24, loss: 0.702711
global_step: 12922, epoch: 24, loss: 0.522470
global_step: 12923, epoch: 24, loss: 0.494492
global_step: 12924, epoch: 24, loss: 0.605367
global_step: 12925, epoch: 24, loss: 0.557456
global_step: 12926, epoch: 24, loss: 0.604187
global_step: 12927, epoch: 24, loss: 0.521638
global_step: 12928, epoch: 24, loss: 0.516902
global_step: 12929, epoch: 24, loss: 0.556315
global_step: 12930, epoch: 24, loss: 0.602626
global_step: 12931, epoch: 24, loss: 0.650312
global_step: 12932, epoch: 24, loss: 0.536727
global_step: 12933, epoch: 24, loss: 0.596209
global_step: 12934, epoch: 24, loss: 0.557414
global_step: 12935, epoch: 24, loss: 0.495381
global_step: 12936, epoch: 24, loss: 0.619396
global_step: 12937, epoch: 24, loss: 0.567770
global_step: 12938, epoch: 24, loss: 0.571734
global_step: 12939, epoch: 24, loss: 0.562667
global_step: 12940, epoch: 24, loss: 0.661871
global_step: 12941, epoch: 24, loss: 0.523905
global_step: 12942, epoch: 24, loss: 0.627789
global_step: 12943, epoch: 24, loss: 0.605537
global_step: 12944, epoch: 24, loss: 0.581210
global_step: 12945, epoch: 24, loss: 0.596209
global_step: 12946, epoch: 24, loss: 0.538041
global_step: 12947, epoch: 24, loss: 0.602043
global_step: 12948, epoch: 24, loss: 0.619227
global_step: 12949, epoch: 24, loss: 0.618810
global_step: 12950, epoch: 24, loss: 0.522090
global_step: 12951, epoch: 24, loss: 0.536656
global_step: 12952, epoch: 24, loss: 0.553563
global_step: 12953, epoch: 24, loss: 0.565847
global_step: 12954, epoch: 24, loss: 0.491258
global_step: 12955, epoch: 24, loss: 0.536758
global_step: 12956, epoch: 24, loss: 0.590701
global_step: 12957, epoch: 24, loss: 0.571835
global_step: 12958, epoch: 24, loss: 0.517925
global_step: 12959, epoch: 24, loss: 0.717011
global_step: 12960, epoch: 24, loss: 0.602008
epoch: 24
train	acc: 0.8897	macro: p 0.9084, r 0.8097, f1: 0.8444	micro: p 0.8897, r 0.8897, f1 0.8897	weighted_f1:0.8895
dev	acc: 0.5032	macro: p 0.4918, r 0.3095, f1: 0.2985	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.4652
test	acc: 0.5617	macro: p 0.3596, r 0.3274, f1: 0.3091	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5300
global_step: 12961, epoch: 25, loss: 0.546009
global_step: 12962, epoch: 25, loss: 0.469235
global_step: 12963, epoch: 25, loss: 0.597680
global_step: 12964, epoch: 25, loss: 0.479853
global_step: 12965, epoch: 25, loss: 0.520952
global_step: 12966, epoch: 25, loss: 0.567385
global_step: 12967, epoch: 25, loss: 0.463532
global_step: 12968, epoch: 25, loss: 0.550794
global_step: 12969, epoch: 25, loss: 0.583694
global_step: 12970, epoch: 25, loss: 0.541741
global_step: 12971, epoch: 25, loss: 0.558515
global_step: 12972, epoch: 25, loss: 0.545398
global_step: 12973, epoch: 25, loss: 0.503239
global_step: 12974, epoch: 25, loss: 0.476829
global_step: 12975, epoch: 25, loss: 0.512062
global_step: 12976, epoch: 25, loss: 0.514071
global_step: 12977, epoch: 25, loss: 0.539862
global_step: 12978, epoch: 25, loss: 0.498883
global_step: 12979, epoch: 25, loss: 0.466752
global_step: 12980, epoch: 25, loss: 0.527541
global_step: 12981, epoch: 25, loss: 0.480240
global_step: 12982, epoch: 25, loss: 0.594592
global_step: 12983, epoch: 25, loss: 0.497832
global_step: 12984, epoch: 25, loss: 0.514268
global_step: 12985, epoch: 25, loss: 0.536952
global_step: 12986, epoch: 25, loss: 0.658901
global_step: 12987, epoch: 25, loss: 0.518611
global_step: 12988, epoch: 25, loss: 0.610051
global_step: 12989, epoch: 25, loss: 0.641538
global_step: 12990, epoch: 25, loss: 0.602313
global_step: 12991, epoch: 25, loss: 0.569812
global_step: 12992, epoch: 25, loss: 0.573614
global_step: 12993, epoch: 25, loss: 0.516239
global_step: 12994, epoch: 25, loss: 0.576339
global_step: 12995, epoch: 25, loss: 0.445604
global_step: 12996, epoch: 25, loss: 0.613405
global_step: 12997, epoch: 25, loss: 0.525608
global_step: 12998, epoch: 25, loss: 0.721133
global_step: 12999, epoch: 25, loss: 0.638777
global_step: 13000, epoch: 25, loss: 0.548986
epoch: 25
train	acc: 0.9211	macro: p 0.9248, r 0.8625, f1: 0.8867	micro: p 0.9211, r 0.9211, f1 0.9211	weighted_f1:0.9211
dev	acc: 0.5005	macro: p 0.3894, r 0.3160, f1: 0.3111	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.4707
test	acc: 0.5471	macro: p 0.3369, r 0.3177, f1: 0.3052	micro: p 0.5471, r 0.5471, f1 0.5471	weighted_f1:0.5210
global_step: 13001, epoch: 26, loss: 0.529016
global_step: 13002, epoch: 26, loss: 0.557484
global_step: 13003, epoch: 26, loss: 0.500605
global_step: 13004, epoch: 26, loss: 0.542938
global_step: 13005, epoch: 26, loss: 0.537512
global_step: 13006, epoch: 26, loss: 0.538126
global_step: 13007, epoch: 26, loss: 0.443405
global_step: 13008, epoch: 26, loss: 0.444856
global_step: 13009, epoch: 26, loss: 0.576410
global_step: 13010, epoch: 26, loss: 0.542737
global_step: 13011, epoch: 26, loss: 0.479614
global_step: 13012, epoch: 26, loss: 0.468832
global_step: 13013, epoch: 26, loss: 0.509074
global_step: 13014, epoch: 26, loss: 0.521359
global_step: 13015, epoch: 26, loss: 0.528326
global_step: 13016, epoch: 26, loss: 0.582870
global_step: 13017, epoch: 26, loss: 0.532690
global_step: 13018, epoch: 26, loss: 0.421610
global_step: 13019, epoch: 26, loss: 0.477310
global_step: 13020, epoch: 26, loss: 0.490593
global_step: 13021, epoch: 26, loss: 0.424575
global_step: 13022, epoch: 26, loss: 0.525561
global_step: 13023, epoch: 26, loss: 0.494253
global_step: 13024, epoch: 26, loss: 0.583157
global_step: 13025, epoch: 26, loss: 0.496194
global_step: 13026, epoch: 26, loss: 0.560450
global_step: 13027, epoch: 26, loss: 0.570333
global_step: 13028, epoch: 26, loss: 0.430992
global_step: 13029, epoch: 26, loss: 0.490707
global_step: 13030, epoch: 26, loss: 0.658224
global_step: 13031, epoch: 26, loss: 0.540182
global_step: 13032, epoch: 26, loss: 0.443919
global_step: 13033, epoch: 26, loss: 0.545488
global_step: 13034, epoch: 26, loss: 0.575498
global_step: 13035, epoch: 26, loss: 0.601103
global_step: 13036, epoch: 26, loss: 0.559105
global_step: 13037, epoch: 26, loss: 0.521235
global_step: 13038, epoch: 26, loss: 0.614276
global_step: 13039, epoch: 26, loss: 0.629318
global_step: 13040, epoch: 26, loss: 0.764718
epoch: 26
train	acc: 0.9280	macro: p 0.9362, r 0.8854, f1: 0.9074	micro: p 0.9280, r 0.9280, f1 0.9280	weighted_f1:0.9279
dev	acc: 0.5365	macro: p 0.4009, r 0.3220, f1: 0.3310	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4993
test	acc: 0.5770	macro: p 0.3594, r 0.3185, f1: 0.3239	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5420
New best model!
global_step: 13041, epoch: 27, loss: 0.481966
global_step: 13042, epoch: 27, loss: 0.532663
global_step: 13043, epoch: 27, loss: 0.499693
global_step: 13044, epoch: 27, loss: 0.503654
global_step: 13045, epoch: 27, loss: 0.529475
global_step: 13046, epoch: 27, loss: 0.552882
global_step: 13047, epoch: 27, loss: 0.482356
global_step: 13048, epoch: 27, loss: 0.566638
global_step: 13049, epoch: 27, loss: 0.557603
global_step: 13050, epoch: 27, loss: 0.573134
global_step: 13051, epoch: 27, loss: 0.492167
global_step: 13052, epoch: 27, loss: 0.477907
global_step: 13053, epoch: 27, loss: 0.396310
global_step: 13054, epoch: 27, loss: 0.508765
global_step: 13055, epoch: 27, loss: 0.562455
global_step: 13056, epoch: 27, loss: 0.552009
global_step: 13057, epoch: 27, loss: 0.568457
global_step: 13058, epoch: 27, loss: 0.529639
global_step: 13059, epoch: 27, loss: 0.623310
global_step: 13060, epoch: 27, loss: 0.578404
global_step: 13061, epoch: 27, loss: 0.560820
global_step: 13062, epoch: 27, loss: 0.570902
global_step: 13063, epoch: 27, loss: 0.599694
global_step: 13064, epoch: 27, loss: 0.535420
global_step: 13065, epoch: 27, loss: 0.537035
global_step: 13066, epoch: 27, loss: 0.494061
global_step: 13067, epoch: 27, loss: 0.526874
global_step: 13068, epoch: 27, loss: 0.531071
global_step: 13069, epoch: 27, loss: 0.541552
global_step: 13070, epoch: 27, loss: 0.476304
global_step: 13071, epoch: 27, loss: 0.409205
global_step: 13072, epoch: 27, loss: 0.473443
global_step: 13073, epoch: 27, loss: 0.604563
global_step: 13074, epoch: 27, loss: 0.509282
global_step: 13075, epoch: 27, loss: 0.548296
global_step: 13076, epoch: 27, loss: 0.480639
global_step: 13077, epoch: 27, loss: 0.484692
global_step: 13078, epoch: 27, loss: 0.561028
global_step: 13079, epoch: 27, loss: 0.573942
global_step: 13080, epoch: 27, loss: 0.788673
epoch: 27
train	acc: 0.9139	macro: p 0.9299, r 0.8657, f1: 0.8920	micro: p 0.9139, r 0.9139, f1 0.9139	weighted_f1:0.9149
dev	acc: 0.4986	macro: p 0.4155, r 0.3081, f1: 0.3110	micro: p 0.4986, r 0.4986, f1 0.4986	weighted_f1:0.4727
test	acc: 0.5483	macro: p 0.3453, r 0.3122, f1: 0.3078	micro: p 0.5483, r 0.5483, f1 0.5483	weighted_f1:0.5267
global_step: 13081, epoch: 28, loss: 0.529322
global_step: 13082, epoch: 28, loss: 0.473469
global_step: 13083, epoch: 28, loss: 0.421198
global_step: 13084, epoch: 28, loss: 0.462410
global_step: 13085, epoch: 28, loss: 0.508892
global_step: 13086, epoch: 28, loss: 0.401875
global_step: 13087, epoch: 28, loss: 0.427367
global_step: 13088, epoch: 28, loss: 0.625955
global_step: 13089, epoch: 28, loss: 0.493814
global_step: 13090, epoch: 28, loss: 0.377957
global_step: 13091, epoch: 28, loss: 0.600886
global_step: 13092, epoch: 28, loss: 0.565303
global_step: 13093, epoch: 28, loss: 0.528732
global_step: 13094, epoch: 28, loss: 0.453011
global_step: 13095, epoch: 28, loss: 0.531746
global_step: 13096, epoch: 28, loss: 0.463081
global_step: 13097, epoch: 28, loss: 0.488600
global_step: 13098, epoch: 28, loss: 0.457688
global_step: 13099, epoch: 28, loss: 0.389951
global_step: 13100, epoch: 28, loss: 0.484767
global_step: 13101, epoch: 28, loss: 0.492707
global_step: 13102, epoch: 28, loss: 0.465128
global_step: 13103, epoch: 28, loss: 0.419525
global_step: 13104, epoch: 28, loss: 0.431172
global_step: 13105, epoch: 28, loss: 0.523545
global_step: 13106, epoch: 28, loss: 0.505860
global_step: 13107, epoch: 28, loss: 0.513807
global_step: 13108, epoch: 28, loss: 0.515630
global_step: 13109, epoch: 28, loss: 0.469723
global_step: 13110, epoch: 28, loss: 0.437027
global_step: 13111, epoch: 28, loss: 0.468740
global_step: 13112, epoch: 28, loss: 0.495245
global_step: 13113, epoch: 28, loss: 0.560009
global_step: 13114, epoch: 28, loss: 0.510069
global_step: 13115, epoch: 28, loss: 0.598419
global_step: 13116, epoch: 28, loss: 0.464231
global_step: 13117, epoch: 28, loss: 0.572997
global_step: 13118, epoch: 28, loss: 0.604481
global_step: 13119, epoch: 28, loss: 0.711834
global_step: 13120, epoch: 28, loss: 1.224272
epoch: 28
train	acc: 0.9319	macro: p 0.9349, r 0.8878, f1: 0.9077	micro: p 0.9319, r 0.9319, f1 0.9319	weighted_f1:0.9320
dev	acc: 0.5140	macro: p 0.3726, r 0.3171, f1: 0.3154	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4883
test	acc: 0.5533	macro: p 0.3506, r 0.3173, f1: 0.3143	micro: p 0.5533, r 0.5533, f1 0.5533	weighted_f1:0.5333
global_step: 13121, epoch: 29, loss: 0.403973
global_step: 13122, epoch: 29, loss: 0.469714
global_step: 13123, epoch: 29, loss: 0.521531
global_step: 13124, epoch: 29, loss: 0.476249
global_step: 13125, epoch: 29, loss: 0.431903
global_step: 13126, epoch: 29, loss: 0.392813
global_step: 13127, epoch: 29, loss: 0.367030
global_step: 13128, epoch: 29, loss: 0.525743
global_step: 13129, epoch: 29, loss: 0.515161
global_step: 13130, epoch: 29, loss: 0.495564
global_step: 13131, epoch: 29, loss: 0.465447
global_step: 13132, epoch: 29, loss: 0.454130
global_step: 13133, epoch: 29, loss: 0.418952
global_step: 13134, epoch: 29, loss: 0.408263
global_step: 13135, epoch: 29, loss: 0.429823
global_step: 13136, epoch: 29, loss: 0.401531
global_step: 13137, epoch: 29, loss: 0.471877
global_step: 13138, epoch: 29, loss: 0.523773
global_step: 13139, epoch: 29, loss: 0.493993
global_step: 13140, epoch: 29, loss: 0.482812
global_step: 13141, epoch: 29, loss: 0.412666
global_step: 13142, epoch: 29, loss: 0.460421
global_step: 13143, epoch: 29, loss: 0.525350
global_step: 13144, epoch: 29, loss: 0.489614
global_step: 13145, epoch: 29, loss: 0.467534
global_step: 13146, epoch: 29, loss: 0.499417
global_step: 13147, epoch: 29, loss: 0.448559
global_step: 13148, epoch: 29, loss: 0.462257
global_step: 13149, epoch: 29, loss: 0.473549
global_step: 13150, epoch: 29, loss: 0.553974
global_step: 13151, epoch: 29, loss: 0.584249
global_step: 13152, epoch: 29, loss: 0.534209
global_step: 13153, epoch: 29, loss: 0.512643
global_step: 13154, epoch: 29, loss: 0.500368
global_step: 13155, epoch: 29, loss: 0.435919
global_step: 13156, epoch: 29, loss: 0.457223
global_step: 13157, epoch: 29, loss: 0.472322
global_step: 13158, epoch: 29, loss: 0.500367
global_step: 13159, epoch: 29, loss: 0.528152
global_step: 13160, epoch: 29, loss: 0.038339
epoch: 29
train	acc: 0.9404	macro: p 0.9487, r 0.9024, f1: 0.9234	micro: p 0.9404, r 0.9404, f1 0.9404	weighted_f1:0.9402
dev	acc: 0.5320	macro: p 0.4280, r 0.3103, f1: 0.3203	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4911
test	acc: 0.5828	macro: p 0.3938, r 0.3259, f1: 0.3345	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5493
global_step: 13161, epoch: 30, loss: 0.424027
global_step: 13162, epoch: 30, loss: 0.464228
global_step: 13163, epoch: 30, loss: 0.418431
global_step: 13164, epoch: 30, loss: 0.398696
global_step: 13165, epoch: 30, loss: 0.386727
global_step: 13166, epoch: 30, loss: 0.465716
global_step: 13167, epoch: 30, loss: 0.493831
global_step: 13168, epoch: 30, loss: 0.536300
global_step: 13169, epoch: 30, loss: 0.349161
global_step: 13170, epoch: 30, loss: 0.429733
global_step: 13171, epoch: 30, loss: 0.570343
global_step: 13172, epoch: 30, loss: 0.509013
global_step: 13173, epoch: 30, loss: 0.501125
global_step: 13174, epoch: 30, loss: 0.425385
global_step: 13175, epoch: 30, loss: 0.420556
global_step: 13176, epoch: 30, loss: 0.454410
global_step: 13177, epoch: 30, loss: 0.474021
global_step: 13178, epoch: 30, loss: 0.386767
global_step: 13179, epoch: 30, loss: 0.426898
global_step: 13180, epoch: 30, loss: 0.518706
global_step: 13181, epoch: 30, loss: 0.504344
global_step: 13182, epoch: 30, loss: 0.427260
global_step: 13183, epoch: 30, loss: 0.430543
global_step: 13184, epoch: 30, loss: 0.454604
global_step: 13185, epoch: 30, loss: 0.411836
global_step: 13186, epoch: 30, loss: 0.464502
global_step: 13187, epoch: 30, loss: 0.471553
global_step: 13188, epoch: 30, loss: 0.547502
global_step: 13189, epoch: 30, loss: 0.448452
global_step: 13190, epoch: 30, loss: 0.482976
global_step: 13191, epoch: 30, loss: 0.368505
global_step: 13192, epoch: 30, loss: 0.438608
global_step: 13193, epoch: 30, loss: 0.462037
global_step: 13194, epoch: 30, loss: 0.510242
global_step: 13195, epoch: 30, loss: 0.498036
global_step: 13196, epoch: 30, loss: 0.507698
global_step: 13197, epoch: 30, loss: 0.563069
global_step: 13198, epoch: 30, loss: 0.494489
global_step: 13199, epoch: 30, loss: 0.510046
global_step: 13200, epoch: 30, loss: 1.395190
epoch: 30
train	acc: 0.9399	macro: p 0.9453, r 0.9078, f1: 0.9250	micro: p 0.9399, r 0.9399, f1 0.9399	weighted_f1:0.9399
dev	acc: 0.5149	macro: p 0.3638, r 0.3179, f1: 0.3170	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4804
test	acc: 0.5678	macro: p 0.3610, r 0.3265, f1: 0.3288	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5381
global_step: 13201, epoch: 31, loss: 0.446593
global_step: 13202, epoch: 31, loss: 0.485904
global_step: 13203, epoch: 31, loss: 0.474085
global_step: 13204, epoch: 31, loss: 0.477306
global_step: 13205, epoch: 31, loss: 0.467968
global_step: 13206, epoch: 31, loss: 0.384066
global_step: 13207, epoch: 31, loss: 0.491984
global_step: 13208, epoch: 31, loss: 0.474151
global_step: 13209, epoch: 31, loss: 0.380386
global_step: 13210, epoch: 31, loss: 0.425500
global_step: 13211, epoch: 31, loss: 0.514439
global_step: 13212, epoch: 31, loss: 0.451800
global_step: 13213, epoch: 31, loss: 0.382746
global_step: 13214, epoch: 31, loss: 0.404227
global_step: 13215, epoch: 31, loss: 0.432820
global_step: 13216, epoch: 31, loss: 0.456997
global_step: 13217, epoch: 31, loss: 0.357212
global_step: 13218, epoch: 31, loss: 0.436837
global_step: 13219, epoch: 31, loss: 0.396572
global_step: 13220, epoch: 31, loss: 0.496495
global_step: 13221, epoch: 31, loss: 0.422177
global_step: 13222, epoch: 31, loss: 0.471287
global_step: 13223, epoch: 31, loss: 0.408915
global_step: 13224, epoch: 31, loss: 0.410412
global_step: 13225, epoch: 31, loss: 0.467242
global_step: 13226, epoch: 31, loss: 0.443249
global_step: 13227, epoch: 31, loss: 0.620347
global_step: 13228, epoch: 31, loss: 0.470308
global_step: 13229, epoch: 31, loss: 0.523250
global_step: 13230, epoch: 31, loss: 0.413870
global_step: 13231, epoch: 31, loss: 0.474697
global_step: 13232, epoch: 31, loss: 0.454884
global_step: 13233, epoch: 31, loss: 0.604372
global_step: 13234, epoch: 31, loss: 0.603862
global_step: 13235, epoch: 31, loss: 0.448043
global_step: 13236, epoch: 31, loss: 0.494494
global_step: 13237, epoch: 31, loss: 0.524589
global_step: 13238, epoch: 31, loss: 0.395476
global_step: 13239, epoch: 31, loss: 0.488103
global_step: 13240, epoch: 31, loss: 0.403602
epoch: 31
train	acc: 0.9322	macro: p 0.9417, r 0.8894, f1: 0.9115	micro: p 0.9322, r 0.9322, f1 0.9322	weighted_f1:0.9324
dev	acc: 0.5275	macro: p 0.4297, r 0.3177, f1: 0.3208	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4848
test	acc: 0.5739	macro: p 0.3821, r 0.3203, f1: 0.3135	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5384
global_step: 13241, epoch: 32, loss: 0.485542
global_step: 13242, epoch: 32, loss: 0.463759
global_step: 13243, epoch: 32, loss: 0.457231
global_step: 13244, epoch: 32, loss: 0.388961
global_step: 13245, epoch: 32, loss: 0.431870
global_step: 13246, epoch: 32, loss: 0.455573
global_step: 13247, epoch: 32, loss: 0.462997
global_step: 13248, epoch: 32, loss: 0.400245
global_step: 13249, epoch: 32, loss: 0.462868
global_step: 13250, epoch: 32, loss: 0.439174
global_step: 13251, epoch: 32, loss: 0.415054
global_step: 13252, epoch: 32, loss: 0.294081
global_step: 13253, epoch: 32, loss: 0.444499
global_step: 13254, epoch: 32, loss: 0.366390
global_step: 13255, epoch: 32, loss: 0.376952
global_step: 13256, epoch: 32, loss: 0.410054
global_step: 13257, epoch: 32, loss: 0.464262
global_step: 13258, epoch: 32, loss: 0.407074
global_step: 13259, epoch: 32, loss: 0.449381
global_step: 13260, epoch: 32, loss: 0.434410
global_step: 13261, epoch: 32, loss: 0.401173
global_step: 13262, epoch: 32, loss: 0.474835
global_step: 13263, epoch: 32, loss: 0.415650
global_step: 13264, epoch: 32, loss: 0.406942
global_step: 13265, epoch: 32, loss: 0.461331
global_step: 13266, epoch: 32, loss: 0.418078
global_step: 13267, epoch: 32, loss: 0.415903
global_step: 13268, epoch: 32, loss: 0.467241
global_step: 13269, epoch: 32, loss: 0.503292
global_step: 13270, epoch: 32, loss: 0.531304
global_step: 13271, epoch: 32, loss: 0.464894
global_step: 13272, epoch: 32, loss: 0.467017
global_step: 13273, epoch: 32, loss: 0.518300
global_step: 13274, epoch: 32, loss: 0.444124
global_step: 13275, epoch: 32, loss: 0.388469
global_step: 13276, epoch: 32, loss: 0.383541
global_step: 13277, epoch: 32, loss: 0.381875
global_step: 13278, epoch: 32, loss: 0.491874
global_step: 13279, epoch: 32, loss: 0.481398
global_step: 13280, epoch: 32, loss: 0.150506
epoch: 32
train	acc: 0.9360	macro: p 0.9492, r 0.8953, f1: 0.9194	micro: p 0.9360, r 0.9360, f1 0.9360	weighted_f1:0.9359
dev	acc: 0.5320	macro: p 0.3911, r 0.3209, f1: 0.3234	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4901
test	acc: 0.5762	macro: p 0.3511, r 0.3131, f1: 0.3122	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5368
global_step: 13281, epoch: 33, loss: 0.346242
global_step: 13282, epoch: 33, loss: 0.370674
global_step: 13283, epoch: 33, loss: 0.476496
global_step: 13284, epoch: 33, loss: 0.423366
global_step: 13285, epoch: 33, loss: 0.382638
global_step: 13286, epoch: 33, loss: 0.337655
global_step: 13287, epoch: 33, loss: 0.453200
global_step: 13288, epoch: 33, loss: 0.386474
global_step: 13289, epoch: 33, loss: 0.429492
global_step: 13290, epoch: 33, loss: 0.558458
global_step: 13291, epoch: 33, loss: 0.450707
global_step: 13292, epoch: 33, loss: 0.316108
global_step: 13293, epoch: 33, loss: 0.382651
global_step: 13294, epoch: 33, loss: 0.528421
global_step: 13295, epoch: 33, loss: 0.413100
global_step: 13296, epoch: 33, loss: 0.419357
global_step: 13297, epoch: 33, loss: 0.420528
global_step: 13298, epoch: 33, loss: 0.499083
global_step: 13299, epoch: 33, loss: 0.493668
global_step: 13300, epoch: 33, loss: 0.477366
global_step: 13301, epoch: 33, loss: 0.454159
global_step: 13302, epoch: 33, loss: 0.481585
global_step: 13303, epoch: 33, loss: 0.481865
global_step: 13304, epoch: 33, loss: 0.494731
global_step: 13305, epoch: 33, loss: 0.411762
global_step: 13306, epoch: 33, loss: 0.486702
global_step: 13307, epoch: 33, loss: 0.415989
global_step: 13308, epoch: 33, loss: 0.484905
global_step: 13309, epoch: 33, loss: 0.422049
global_step: 13310, epoch: 33, loss: 0.480560
global_step: 13311, epoch: 33, loss: 0.487148
global_step: 13312, epoch: 33, loss: 0.500016
global_step: 13313, epoch: 33, loss: 0.444663
global_step: 13314, epoch: 33, loss: 0.440137
global_step: 13315, epoch: 33, loss: 0.512473
global_step: 13316, epoch: 33, loss: 0.372561
global_step: 13317, epoch: 33, loss: 0.469327
global_step: 13318, epoch: 33, loss: 0.413558
global_step: 13319, epoch: 33, loss: 0.445167
global_step: 13320, epoch: 33, loss: 0.138311
epoch: 33
train	acc: 0.9351	macro: p 0.9501, r 0.8996, f1: 0.9223	micro: p 0.9351, r 0.9351, f1 0.9351	weighted_f1:0.9351
dev	acc: 0.5167	macro: p 0.3946, r 0.3049, f1: 0.3036	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4706
test	acc: 0.5697	macro: p 0.3632, r 0.3035, f1: 0.2999	micro: p 0.5697, r 0.5697, f1 0.5697	weighted_f1:0.5263
global_step: 13321, epoch: 34, loss: 0.406094
global_step: 13322, epoch: 34, loss: 0.403313
global_step: 13323, epoch: 34, loss: 0.482934
global_step: 13324, epoch: 34, loss: 0.346512
global_step: 13325, epoch: 34, loss: 0.427028
global_step: 13326, epoch: 34, loss: 0.353966
global_step: 13327, epoch: 34, loss: 0.398294
global_step: 13328, epoch: 34, loss: 0.423544
global_step: 13329, epoch: 34, loss: 0.374378
global_step: 13330, epoch: 34, loss: 0.352981
global_step: 13331, epoch: 34, loss: 0.437358
global_step: 13332, epoch: 34, loss: 0.361233
global_step: 13333, epoch: 34, loss: 0.496155
global_step: 13334, epoch: 34, loss: 0.325504
global_step: 13335, epoch: 34, loss: 0.483942
global_step: 13336, epoch: 34, loss: 0.396493
global_step: 13337, epoch: 34, loss: 0.330506
global_step: 13338, epoch: 34, loss: 0.445277
global_step: 13339, epoch: 34, loss: 0.508634
global_step: 13340, epoch: 34, loss: 0.555580
global_step: 13341, epoch: 34, loss: 0.437598
global_step: 13342, epoch: 34, loss: 0.514696
global_step: 13343, epoch: 34, loss: 0.526059
global_step: 13344, epoch: 34, loss: 0.452712
global_step: 13345, epoch: 34, loss: 0.508853
global_step: 13346, epoch: 34, loss: 0.401284
global_step: 13347, epoch: 34, loss: 0.489410
global_step: 13348, epoch: 34, loss: 0.466539
global_step: 13349, epoch: 34, loss: 0.464894
global_step: 13350, epoch: 34, loss: 0.399940
global_step: 13351, epoch: 34, loss: 0.405408
global_step: 13352, epoch: 34, loss: 0.449460
global_step: 13353, epoch: 34, loss: 0.494968
global_step: 13354, epoch: 34, loss: 0.447097
global_step: 13355, epoch: 34, loss: 0.470421
global_step: 13356, epoch: 34, loss: 0.454621
global_step: 13357, epoch: 34, loss: 0.447779
global_step: 13358, epoch: 34, loss: 0.487071
global_step: 13359, epoch: 34, loss: 0.512574
global_step: 13360, epoch: 34, loss: 0.840387
epoch: 34
train	acc: 0.9388	macro: p 0.9519, r 0.9012, f1: 0.9243	micro: p 0.9388, r 0.9388, f1 0.9388	weighted_f1:0.9385
dev	acc: 0.5311	macro: p 0.3720, r 0.2944, f1: 0.2941	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4774
test	acc: 0.5874	macro: p 0.3919, r 0.3091, f1: 0.3146	micro: p 0.5874, r 0.5874, f1 0.5874	weighted_f1:0.5381
global_step: 13361, epoch: 35, loss: 0.330358
global_step: 13362, epoch: 35, loss: 0.420771
global_step: 13363, epoch: 35, loss: 0.362678
global_step: 13364, epoch: 35, loss: 0.454237
global_step: 13365, epoch: 35, loss: 0.459037
global_step: 13366, epoch: 35, loss: 0.392848
global_step: 13367, epoch: 35, loss: 0.341630
global_step: 13368, epoch: 35, loss: 0.435569
global_step: 13369, epoch: 35, loss: 0.397704
global_step: 13370, epoch: 35, loss: 0.338287
global_step: 13371, epoch: 35, loss: 0.394908
global_step: 13372, epoch: 35, loss: 0.361870
global_step: 13373, epoch: 35, loss: 0.392582
global_step: 13374, epoch: 35, loss: 0.485478
global_step: 13375, epoch: 35, loss: 0.415469
global_step: 13376, epoch: 35, loss: 0.523524
global_step: 13377, epoch: 35, loss: 0.390560
global_step: 13378, epoch: 35, loss: 0.456858
global_step: 13379, epoch: 35, loss: 0.436333
global_step: 13380, epoch: 35, loss: 0.347163
global_step: 13381, epoch: 35, loss: 0.341240
global_step: 13382, epoch: 35, loss: 0.442207
global_step: 13383, epoch: 35, loss: 0.429395
global_step: 13384, epoch: 35, loss: 0.392245
global_step: 13385, epoch: 35, loss: 0.492349
global_step: 13386, epoch: 35, loss: 0.407607
global_step: 13387, epoch: 35, loss: 0.386268
global_step: 13388, epoch: 35, loss: 0.424088
global_step: 13389, epoch: 35, loss: 0.467590
global_step: 13390, epoch: 35, loss: 0.380916
global_step: 13391, epoch: 35, loss: 0.503815
global_step: 13392, epoch: 35, loss: 0.408632
global_step: 13393, epoch: 35, loss: 0.460667
global_step: 13394, epoch: 35, loss: 0.498396
global_step: 13395, epoch: 35, loss: 0.424412
global_step: 13396, epoch: 35, loss: 0.471274
global_step: 13397, epoch: 35, loss: 0.461838
global_step: 13398, epoch: 35, loss: 0.391236
global_step: 13399, epoch: 35, loss: 0.461959
global_step: 13400, epoch: 35, loss: 0.140435
epoch: 35
train	acc: 0.9432	macro: p 0.9518, r 0.9099, f1: 0.9290	micro: p 0.9432, r 0.9432, f1 0.9432	weighted_f1:0.9431
dev	acc: 0.5239	macro: p 0.3657, r 0.3053, f1: 0.3091	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4818
test	acc: 0.5693	macro: p 0.3552, r 0.3119, f1: 0.3161	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.5308
global_step: 13401, epoch: 36, loss: 0.388367
global_step: 13402, epoch: 36, loss: 0.498203
global_step: 13403, epoch: 36, loss: 0.413219
global_step: 13404, epoch: 36, loss: 0.337235
global_step: 13405, epoch: 36, loss: 0.395111
global_step: 13406, epoch: 36, loss: 0.385704
global_step: 13407, epoch: 36, loss: 0.371989
global_step: 13408, epoch: 36, loss: 0.435025
global_step: 13409, epoch: 36, loss: 0.349108
global_step: 13410, epoch: 36, loss: 0.360231
global_step: 13411, epoch: 36, loss: 0.344940
global_step: 13412, epoch: 36, loss: 0.367970
global_step: 13413, epoch: 36, loss: 0.381289
global_step: 13414, epoch: 36, loss: 0.420356
global_step: 13415, epoch: 36, loss: 0.338618
global_step: 13416, epoch: 36, loss: 0.465488
global_step: 13417, epoch: 36, loss: 0.461215
global_step: 13418, epoch: 36, loss: 0.329137
global_step: 13419, epoch: 36, loss: 0.448776
global_step: 13420, epoch: 36, loss: 0.398838
global_step: 13421, epoch: 36, loss: 0.509813
global_step: 13422, epoch: 36, loss: 0.406975
global_step: 13423, epoch: 36, loss: 0.356878
global_step: 13424, epoch: 36, loss: 0.360269
global_step: 13425, epoch: 36, loss: 0.499467
global_step: 13426, epoch: 36, loss: 0.480291
global_step: 13427, epoch: 36, loss: 0.392422
global_step: 13428, epoch: 36, loss: 0.405803
global_step: 13429, epoch: 36, loss: 0.392160
global_step: 13430, epoch: 36, loss: 0.454547
global_step: 13431, epoch: 36, loss: 0.413721
global_step: 13432, epoch: 36, loss: 0.403170
global_step: 13433, epoch: 36, loss: 0.481922
global_step: 13434, epoch: 36, loss: 0.535577
global_step: 13435, epoch: 36, loss: 0.375434
global_step: 13436, epoch: 36, loss: 0.385085
global_step: 13437, epoch: 36, loss: 0.462472
global_step: 13438, epoch: 36, loss: 0.455850
global_step: 13439, epoch: 36, loss: 0.426021
global_step: 13440, epoch: 36, loss: 0.749926
epoch: 36
train	acc: 0.9375	macro: p 0.9452, r 0.9076, f1: 0.9247	micro: p 0.9375, r 0.9375, f1 0.9375	weighted_f1:0.9374
dev	acc: 0.5293	macro: p 0.3642, r 0.3028, f1: 0.3024	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4829
test	acc: 0.5782	macro: p 0.3879, r 0.3141, f1: 0.3191	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5382
global_step: 13441, epoch: 37, loss: 0.409934
global_step: 13442, epoch: 37, loss: 0.477059
global_step: 13443, epoch: 37, loss: 0.416458
global_step: 13444, epoch: 37, loss: 0.354983
global_step: 13445, epoch: 37, loss: 0.420751
global_step: 13446, epoch: 37, loss: 0.347599
global_step: 13447, epoch: 37, loss: 0.409699
global_step: 13448, epoch: 37, loss: 0.347706
global_step: 13449, epoch: 37, loss: 0.364407
global_step: 13450, epoch: 37, loss: 0.312400
global_step: 13451, epoch: 37, loss: 0.392985
global_step: 13452, epoch: 37, loss: 0.390426
global_step: 13453, epoch: 37, loss: 0.360620
global_step: 13454, epoch: 37, loss: 0.445343
global_step: 13455, epoch: 37, loss: 0.495577
global_step: 13456, epoch: 37, loss: 0.389855
global_step: 13457, epoch: 37, loss: 0.376370
global_step: 13458, epoch: 37, loss: 0.338515
global_step: 13459, epoch: 37, loss: 0.395764
global_step: 13460, epoch: 37, loss: 0.340516
global_step: 13461, epoch: 37, loss: 0.343476
global_step: 13462, epoch: 37, loss: 0.379289
global_step: 13463, epoch: 37, loss: 0.423836
global_step: 13464, epoch: 37, loss: 0.537082
global_step: 13465, epoch: 37, loss: 0.398083
global_step: 13466, epoch: 37, loss: 0.447341
global_step: 13467, epoch: 37, loss: 0.312563
global_step: 13468, epoch: 37, loss: 0.468125
global_step: 13469, epoch: 37, loss: 0.443824
global_step: 13470, epoch: 37, loss: 0.382901
global_step: 13471, epoch: 37, loss: 0.325273
global_step: 13472, epoch: 37, loss: 0.404127
global_step: 13473, epoch: 37, loss: 0.481696
global_step: 13474, epoch: 37, loss: 0.393716
global_step: 13475, epoch: 37, loss: 0.475798
global_step: 13476, epoch: 37, loss: 0.532058
global_step: 13477, epoch: 37, loss: 0.352449
global_step: 13478, epoch: 37, loss: 0.496015
global_step: 13479, epoch: 37, loss: 0.532905
global_step: 13480, epoch: 37, loss: 0.838864
epoch: 37
train	acc: 0.9508	macro: p 0.9512, r 0.9234, f1: 0.9362	micro: p 0.9508, r 0.9508, f1 0.9508	weighted_f1:0.9508
dev	acc: 0.5302	macro: p 0.3951, r 0.3219, f1: 0.3269	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4973
test	acc: 0.5739	macro: p 0.3730, r 0.3289, f1: 0.3335	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5462
global_step: 13481, epoch: 38, loss: 0.338429
global_step: 13482, epoch: 38, loss: 0.310630
global_step: 13483, epoch: 38, loss: 0.443700
global_step: 13484, epoch: 38, loss: 0.364446
global_step: 13485, epoch: 38, loss: 0.421257
global_step: 13486, epoch: 38, loss: 0.349582
global_step: 13487, epoch: 38, loss: 0.296907
global_step: 13488, epoch: 38, loss: 0.400749
global_step: 13489, epoch: 38, loss: 0.422528
global_step: 13490, epoch: 38, loss: 0.372922
global_step: 13491, epoch: 38, loss: 0.382703
global_step: 13492, epoch: 38, loss: 0.464227
global_step: 13493, epoch: 38, loss: 0.472159
global_step: 13494, epoch: 38, loss: 0.434661
global_step: 13495, epoch: 38, loss: 0.364452
global_step: 13496, epoch: 38, loss: 0.398989
global_step: 13497, epoch: 38, loss: 0.292833
global_step: 13498, epoch: 38, loss: 0.452076
global_step: 13499, epoch: 38, loss: 0.391398
global_step: 13500, epoch: 38, loss: 0.329932
global_step: 13501, epoch: 38, loss: 0.398676
global_step: 13502, epoch: 38, loss: 0.433559
global_step: 13503, epoch: 38, loss: 0.394825
global_step: 13504, epoch: 38, loss: 0.522139
global_step: 13505, epoch: 38, loss: 0.386750
global_step: 13506, epoch: 38, loss: 0.331207
global_step: 13507, epoch: 38, loss: 0.317732
global_step: 13508, epoch: 38, loss: 0.363529
global_step: 13509, epoch: 38, loss: 0.372323
global_step: 13510, epoch: 38, loss: 0.447052
global_step: 13511, epoch: 38, loss: 0.382437
global_step: 13512, epoch: 38, loss: 0.423787
global_step: 13513, epoch: 38, loss: 0.461232
global_step: 13514, epoch: 38, loss: 0.354587
global_step: 13515, epoch: 38, loss: 0.390200
global_step: 13516, epoch: 38, loss: 0.397690
global_step: 13517, epoch: 38, loss: 0.407624
global_step: 13518, epoch: 38, loss: 0.402699
global_step: 13519, epoch: 38, loss: 0.491724
global_step: 13520, epoch: 38, loss: 1.377113
epoch: 38
train	acc: 0.9449	macro: p 0.9494, r 0.9214, f1: 0.9334	micro: p 0.9449, r 0.9449, f1 0.9449	weighted_f1:0.9455
dev	acc: 0.5203	macro: p 0.3901, r 0.3226, f1: 0.3235	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4853
test	acc: 0.5536	macro: p 0.3476, r 0.3177, f1: 0.3124	micro: p 0.5536, r 0.5536, f1 0.5536	weighted_f1:0.5231
global_step: 13521, epoch: 39, loss: 0.394988
global_step: 13522, epoch: 39, loss: 0.300344
global_step: 13523, epoch: 39, loss: 0.329120
global_step: 13524, epoch: 39, loss: 0.381701
global_step: 13525, epoch: 39, loss: 0.338229
global_step: 13526, epoch: 39, loss: 0.365634
global_step: 13527, epoch: 39, loss: 0.360033
global_step: 13528, epoch: 39, loss: 0.379915
global_step: 13529, epoch: 39, loss: 0.368415
global_step: 13530, epoch: 39, loss: 0.309347
global_step: 13531, epoch: 39, loss: 0.306444
global_step: 13532, epoch: 39, loss: 0.389498
global_step: 13533, epoch: 39, loss: 0.308436
global_step: 13534, epoch: 39, loss: 0.496008
global_step: 13535, epoch: 39, loss: 0.438853
global_step: 13536, epoch: 39, loss: 0.301487
global_step: 13537, epoch: 39, loss: 0.417759
global_step: 13538, epoch: 39, loss: 0.351351
global_step: 13539, epoch: 39, loss: 0.431698
global_step: 13540, epoch: 39, loss: 0.431394
global_step: 13541, epoch: 39, loss: 0.384912
global_step: 13542, epoch: 39, loss: 0.418429
global_step: 13543, epoch: 39, loss: 0.341815
global_step: 13544, epoch: 39, loss: 0.387355
global_step: 13545, epoch: 39, loss: 0.469043
global_step: 13546, epoch: 39, loss: 0.403509
global_step: 13547, epoch: 39, loss: 0.391683
global_step: 13548, epoch: 39, loss: 0.428856
global_step: 13549, epoch: 39, loss: 0.402139
global_step: 13550, epoch: 39, loss: 0.349352
global_step: 13551, epoch: 39, loss: 0.379722
global_step: 13552, epoch: 39, loss: 0.432577
global_step: 13553, epoch: 39, loss: 0.461019
global_step: 13554, epoch: 39, loss: 0.444871
global_step: 13555, epoch: 39, loss: 0.405298
global_step: 13556, epoch: 39, loss: 0.390303
global_step: 13557, epoch: 39, loss: 0.505291
global_step: 13558, epoch: 39, loss: 0.397935
global_step: 13559, epoch: 39, loss: 0.389404
global_step: 13560, epoch: 39, loss: 0.033039
epoch: 39
train	acc: 0.9529	macro: p 0.9572, r 0.9292, f1: 0.9423	micro: p 0.9529, r 0.9529, f1 0.9529	weighted_f1:0.9529
dev	acc: 0.5392	macro: p 0.3953, r 0.3291, f1: 0.3374	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.5069
test	acc: 0.5732	macro: p 0.3928, r 0.3247, f1: 0.3341	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5463
New best model!
global_step: 13561, epoch: 40, loss: 0.289901
global_step: 13562, epoch: 40, loss: 0.369349
global_step: 13563, epoch: 40, loss: 0.385137
global_step: 13564, epoch: 40, loss: 0.442282
global_step: 13565, epoch: 40, loss: 0.364699
global_step: 13566, epoch: 40, loss: 0.346753
global_step: 13567, epoch: 40, loss: 0.393728
global_step: 13568, epoch: 40, loss: 0.342212
global_step: 13569, epoch: 40, loss: 0.432484
global_step: 13570, epoch: 40, loss: 0.360364
global_step: 13571, epoch: 40, loss: 0.392417
global_step: 13572, epoch: 40, loss: 0.465444
global_step: 13573, epoch: 40, loss: 0.375803
global_step: 13574, epoch: 40, loss: 0.325137
global_step: 13575, epoch: 40, loss: 0.332617
global_step: 13576, epoch: 40, loss: 0.481593
global_step: 13577, epoch: 40, loss: 0.479287
global_step: 13578, epoch: 40, loss: 0.455014
global_step: 13579, epoch: 40, loss: 0.335403
global_step: 13580, epoch: 40, loss: 0.439621
global_step: 13581, epoch: 40, loss: 0.437572
global_step: 13582, epoch: 40, loss: 0.325039
global_step: 13583, epoch: 40, loss: 0.303494
global_step: 13584, epoch: 40, loss: 0.303532
global_step: 13585, epoch: 40, loss: 0.378068
global_step: 13586, epoch: 40, loss: 0.334545
global_step: 13587, epoch: 40, loss: 0.340150
global_step: 13588, epoch: 40, loss: 0.340261
global_step: 13589, epoch: 40, loss: 0.394273
global_step: 13590, epoch: 40, loss: 0.286707
global_step: 13591, epoch: 40, loss: 0.342521
global_step: 13592, epoch: 40, loss: 0.435496
global_step: 13593, epoch: 40, loss: 0.331717
global_step: 13594, epoch: 40, loss: 0.438580
global_step: 13595, epoch: 40, loss: 0.430679
global_step: 13596, epoch: 40, loss: 0.489079
global_step: 13597, epoch: 40, loss: 0.373776
global_step: 13598, epoch: 40, loss: 0.451100
global_step: 13599, epoch: 40, loss: 0.396499
global_step: 13600, epoch: 40, loss: 0.591073
epoch: 40
train	acc: 0.9511	macro: p 0.9542, r 0.9300, f1: 0.9413	micro: p 0.9511, r 0.9511, f1 0.9511	weighted_f1:0.9512
dev	acc: 0.5104	macro: p 0.3646, r 0.3210, f1: 0.3264	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4889
test	acc: 0.5487	macro: p 0.3550, r 0.3227, f1: 0.3247	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.5322
global_step: 13601, epoch: 41, loss: 0.392226
global_step: 13602, epoch: 41, loss: 0.299671
global_step: 13603, epoch: 41, loss: 0.470534
global_step: 13604, epoch: 41, loss: 0.361281
global_step: 13605, epoch: 41, loss: 0.427783
global_step: 13606, epoch: 41, loss: 0.383438
global_step: 13607, epoch: 41, loss: 0.414347
global_step: 13608, epoch: 41, loss: 0.354756
global_step: 13609, epoch: 41, loss: 0.336713
global_step: 13610, epoch: 41, loss: 0.420177
global_step: 13611, epoch: 41, loss: 0.356859
global_step: 13612, epoch: 41, loss: 0.430694
global_step: 13613, epoch: 41, loss: 0.379590
global_step: 13614, epoch: 41, loss: 0.497630
global_step: 13615, epoch: 41, loss: 0.292576
global_step: 13616, epoch: 41, loss: 0.479015
global_step: 13617, epoch: 41, loss: 0.306073
global_step: 13618, epoch: 41, loss: 0.344338
global_step: 13619, epoch: 41, loss: 0.397593
global_step: 13620, epoch: 41, loss: 0.334365
global_step: 13621, epoch: 41, loss: 0.448134
global_step: 13622, epoch: 41, loss: 0.350674
global_step: 13623, epoch: 41, loss: 0.452315
global_step: 13624, epoch: 41, loss: 0.313147
global_step: 13625, epoch: 41, loss: 0.401056
global_step: 13626, epoch: 41, loss: 0.434531
global_step: 13627, epoch: 41, loss: 0.313664
global_step: 13628, epoch: 41, loss: 0.306144
global_step: 13629, epoch: 41, loss: 0.369121
global_step: 13630, epoch: 41, loss: 0.368537
global_step: 13631, epoch: 41, loss: 0.370806
global_step: 13632, epoch: 41, loss: 0.357807
global_step: 13633, epoch: 41, loss: 0.449494
global_step: 13634, epoch: 41, loss: 0.340915
global_step: 13635, epoch: 41, loss: 0.380275
global_step: 13636, epoch: 41, loss: 0.456309
global_step: 13637, epoch: 41, loss: 0.450114
global_step: 13638, epoch: 41, loss: 0.369754
global_step: 13639, epoch: 41, loss: 0.285703
global_step: 13640, epoch: 41, loss: 0.008905
epoch: 41
train	acc: 0.9532	macro: p 0.9614, r 0.9256, f1: 0.9424	micro: p 0.9532, r 0.9532, f1 0.9532	weighted_f1:0.9531
dev	acc: 0.5356	macro: p 0.4155, r 0.3253, f1: 0.3353	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4947
test	acc: 0.5812	macro: p 0.3911, r 0.3183, f1: 0.3306	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5461
global_step: 13641, epoch: 42, loss: 0.301527
global_step: 13642, epoch: 42, loss: 0.261600
global_step: 13643, epoch: 42, loss: 0.452742
global_step: 13644, epoch: 42, loss: 0.321577
global_step: 13645, epoch: 42, loss: 0.292188
global_step: 13646, epoch: 42, loss: 0.337876
global_step: 13647, epoch: 42, loss: 0.250845
global_step: 13648, epoch: 42, loss: 0.343457
global_step: 13649, epoch: 42, loss: 0.408509
global_step: 13650, epoch: 42, loss: 0.446390
global_step: 13651, epoch: 42, loss: 0.367919
global_step: 13652, epoch: 42, loss: 0.295858
global_step: 13653, epoch: 42, loss: 0.262734
global_step: 13654, epoch: 42, loss: 0.362969
global_step: 13655, epoch: 42, loss: 0.376228
global_step: 13656, epoch: 42, loss: 0.471032
global_step: 13657, epoch: 42, loss: 0.337599
global_step: 13658, epoch: 42, loss: 0.443913
global_step: 13659, epoch: 42, loss: 0.428823
global_step: 13660, epoch: 42, loss: 0.354381
global_step: 13661, epoch: 42, loss: 0.435248
global_step: 13662, epoch: 42, loss: 0.470657
global_step: 13663, epoch: 42, loss: 0.337860
global_step: 13664, epoch: 42, loss: 0.277620
global_step: 13665, epoch: 42, loss: 0.313711
global_step: 13666, epoch: 42, loss: 0.497391
global_step: 13667, epoch: 42, loss: 0.402344
global_step: 13668, epoch: 42, loss: 0.442099
global_step: 13669, epoch: 42, loss: 0.320993
global_step: 13670, epoch: 42, loss: 0.336540
global_step: 13671, epoch: 42, loss: 0.344440
global_step: 13672, epoch: 42, loss: 0.422265
global_step: 13673, epoch: 42, loss: 0.460408
global_step: 13674, epoch: 42, loss: 0.394699
global_step: 13675, epoch: 42, loss: 0.408252
global_step: 13676, epoch: 42, loss: 0.505754
global_step: 13677, epoch: 42, loss: 0.472388
global_step: 13678, epoch: 42, loss: 0.363410
global_step: 13679, epoch: 42, loss: 0.373289
global_step: 13680, epoch: 42, loss: 0.264264
epoch: 42
train	acc: 0.9267	macro: p 0.9483, r 0.8873, f1: 0.9131	micro: p 0.9267, r 0.9267, f1 0.9267	weighted_f1:0.9275
dev	acc: 0.5050	macro: p 0.3759, r 0.2909, f1: 0.2802	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4584
test	acc: 0.5506	macro: p 0.3936, r 0.3019, f1: 0.2995	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.5152
global_step: 13681, epoch: 43, loss: 0.387013
global_step: 13682, epoch: 43, loss: 0.313425
global_step: 13683, epoch: 43, loss: 0.314218
global_step: 13684, epoch: 43, loss: 0.429884
global_step: 13685, epoch: 43, loss: 0.409338
global_step: 13686, epoch: 43, loss: 0.332121
global_step: 13687, epoch: 43, loss: 0.392802
global_step: 13688, epoch: 43, loss: 0.287371
global_step: 13689, epoch: 43, loss: 0.332331
global_step: 13690, epoch: 43, loss: 0.332434
global_step: 13691, epoch: 43, loss: 0.421950
global_step: 13692, epoch: 43, loss: 0.408073
global_step: 13693, epoch: 43, loss: 0.292062
global_step: 13694, epoch: 43, loss: 0.408096
global_step: 13695, epoch: 43, loss: 0.444049
global_step: 13696, epoch: 43, loss: 0.457398
global_step: 13697, epoch: 43, loss: 0.356170
global_step: 13698, epoch: 43, loss: 0.294531
global_step: 13699, epoch: 43, loss: 0.415526
global_step: 13700, epoch: 43, loss: 0.293627
global_step: 13701, epoch: 43, loss: 0.404263
global_step: 13702, epoch: 43, loss: 0.368498
global_step: 13703, epoch: 43, loss: 0.402662
global_step: 13704, epoch: 43, loss: 0.327716
global_step: 13705, epoch: 43, loss: 0.341756
global_step: 13706, epoch: 43, loss: 0.362214
global_step: 13707, epoch: 43, loss: 0.419392
global_step: 13708, epoch: 43, loss: 0.335925
global_step: 13709, epoch: 43, loss: 0.451335
global_step: 13710, epoch: 43, loss: 0.374433
global_step: 13711, epoch: 43, loss: 0.306790
global_step: 13712, epoch: 43, loss: 0.364197
global_step: 13713, epoch: 43, loss: 0.365931
global_step: 13714, epoch: 43, loss: 0.423265
global_step: 13715, epoch: 43, loss: 0.381628
global_step: 13716, epoch: 43, loss: 0.407637
global_step: 13717, epoch: 43, loss: 0.348873
global_step: 13718, epoch: 43, loss: 0.340203
global_step: 13719, epoch: 43, loss: 0.340374
global_step: 13720, epoch: 43, loss: 0.123753
epoch: 43
train	acc: 0.9542	macro: p 0.9616, r 0.9322, f1: 0.9460	micro: p 0.9542, r 0.9542, f1 0.9542	weighted_f1:0.9543
dev	acc: 0.5347	macro: p 0.3883, r 0.3071, f1: 0.3110	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4896
test	acc: 0.5793	macro: p 0.4025, r 0.3119, f1: 0.3186	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5400
global_step: 13721, epoch: 44, loss: 0.340415
global_step: 13722, epoch: 44, loss: 0.346162
global_step: 13723, epoch: 44, loss: 0.369489
global_step: 13724, epoch: 44, loss: 0.419314
global_step: 13725, epoch: 44, loss: 0.393280
global_step: 13726, epoch: 44, loss: 0.214914
global_step: 13727, epoch: 44, loss: 0.283330
global_step: 13728, epoch: 44, loss: 0.319828
global_step: 13729, epoch: 44, loss: 0.320175
global_step: 13730, epoch: 44, loss: 0.374048
global_step: 13731, epoch: 44, loss: 0.376943
global_step: 13732, epoch: 44, loss: 0.344450
global_step: 13733, epoch: 44, loss: 0.262475
global_step: 13734, epoch: 44, loss: 0.365518
global_step: 13735, epoch: 44, loss: 0.365178
global_step: 13736, epoch: 44, loss: 0.366972
global_step: 13737, epoch: 44, loss: 0.393329
global_step: 13738, epoch: 44, loss: 0.377462
global_step: 13739, epoch: 44, loss: 0.359379
global_step: 13740, epoch: 44, loss: 0.395180
global_step: 13741, epoch: 44, loss: 0.358082
global_step: 13742, epoch: 44, loss: 0.390478
global_step: 13743, epoch: 44, loss: 0.409978
global_step: 13744, epoch: 44, loss: 0.401034
global_step: 13745, epoch: 44, loss: 0.409501
global_step: 13746, epoch: 44, loss: 0.278407
global_step: 13747, epoch: 44, loss: 0.360406
global_step: 13748, epoch: 44, loss: 0.395122
global_step: 13749, epoch: 44, loss: 0.366595
global_step: 13750, epoch: 44, loss: 0.359751
global_step: 13751, epoch: 44, loss: 0.301648
global_step: 13752, epoch: 44, loss: 0.291768
global_step: 13753, epoch: 44, loss: 0.430678
global_step: 13754, epoch: 44, loss: 0.360507
global_step: 13755, epoch: 44, loss: 0.275455
global_step: 13756, epoch: 44, loss: 0.445119
global_step: 13757, epoch: 44, loss: 0.415856
global_step: 13758, epoch: 44, loss: 0.389196
global_step: 13759, epoch: 44, loss: 0.298869
global_step: 13760, epoch: 44, loss: 0.399642
epoch: 44
train	acc: 0.9540	macro: p 0.9629, r 0.9306, f1: 0.9456	micro: p 0.9540, r 0.9540, f1 0.9540	weighted_f1:0.9541
dev	acc: 0.5221	macro: p 0.3941, r 0.3057, f1: 0.3091	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4753
test	acc: 0.5690	macro: p 0.3546, r 0.3058, f1: 0.3057	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.5252
global_step: 13761, epoch: 45, loss: 0.405094
global_step: 13762, epoch: 45, loss: 0.267284
global_step: 13763, epoch: 45, loss: 0.325304
global_step: 13764, epoch: 45, loss: 0.311050
global_step: 13765, epoch: 45, loss: 0.343579
global_step: 13766, epoch: 45, loss: 0.347631
global_step: 13767, epoch: 45, loss: 0.393590
global_step: 13768, epoch: 45, loss: 0.338436
global_step: 13769, epoch: 45, loss: 0.321119
global_step: 13770, epoch: 45, loss: 0.330163
global_step: 13771, epoch: 45, loss: 0.237273
global_step: 13772, epoch: 45, loss: 0.448951
global_step: 13773, epoch: 45, loss: 0.406783
global_step: 13774, epoch: 45, loss: 0.285272
global_step: 13775, epoch: 45, loss: 0.318869
global_step: 13776, epoch: 45, loss: 0.441905
global_step: 13777, epoch: 45, loss: 0.373381
global_step: 13778, epoch: 45, loss: 0.323926
global_step: 13779, epoch: 45, loss: 0.268569
global_step: 13780, epoch: 45, loss: 0.347419
global_step: 13781, epoch: 45, loss: 0.413857
global_step: 13782, epoch: 45, loss: 0.291579
global_step: 13783, epoch: 45, loss: 0.280937
global_step: 13784, epoch: 45, loss: 0.391621
global_step: 13785, epoch: 45, loss: 0.369013
global_step: 13786, epoch: 45, loss: 0.394097
global_step: 13787, epoch: 45, loss: 0.304251
global_step: 13788, epoch: 45, loss: 0.410242
global_step: 13789, epoch: 45, loss: 0.327927
global_step: 13790, epoch: 45, loss: 0.306579
global_step: 13791, epoch: 45, loss: 0.409664
global_step: 13792, epoch: 45, loss: 0.358533
global_step: 13793, epoch: 45, loss: 0.261434
global_step: 13794, epoch: 45, loss: 0.379856
global_step: 13795, epoch: 45, loss: 0.408503
global_step: 13796, epoch: 45, loss: 0.310838
global_step: 13797, epoch: 45, loss: 0.365068
global_step: 13798, epoch: 45, loss: 0.373746
global_step: 13799, epoch: 45, loss: 0.370382
global_step: 13800, epoch: 45, loss: 0.002829
epoch: 45
train	acc: 0.9593	macro: p 0.9625, r 0.9414, f1: 0.9514	micro: p 0.9593, r 0.9593, f1 0.9593	weighted_f1:0.9593
dev	acc: 0.5266	macro: p 0.3884, r 0.3076, f1: 0.3163	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4846
test	acc: 0.5705	macro: p 0.3651, r 0.3162, f1: 0.3254	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5350
global_step: 13801, epoch: 46, loss: 0.239142
global_step: 13802, epoch: 46, loss: 0.343599
global_step: 13803, epoch: 46, loss: 0.309719
global_step: 13804, epoch: 46, loss: 0.361690
global_step: 13805, epoch: 46, loss: 0.295147
global_step: 13806, epoch: 46, loss: 0.258677
global_step: 13807, epoch: 46, loss: 0.270795
global_step: 13808, epoch: 46, loss: 0.380013
global_step: 13809, epoch: 46, loss: 0.315449
global_step: 13810, epoch: 46, loss: 0.326169
global_step: 13811, epoch: 46, loss: 0.373047
global_step: 13812, epoch: 46, loss: 0.417585
global_step: 13813, epoch: 46, loss: 0.406843
global_step: 13814, epoch: 46, loss: 0.379219
global_step: 13815, epoch: 46, loss: 0.262529
global_step: 13816, epoch: 46, loss: 0.452181
global_step: 13817, epoch: 46, loss: 0.392642
global_step: 13818, epoch: 46, loss: 0.296595
global_step: 13819, epoch: 46, loss: 0.281609
global_step: 13820, epoch: 46, loss: 0.309130
global_step: 13821, epoch: 46, loss: 0.287499
global_step: 13822, epoch: 46, loss: 0.358861
global_step: 13823, epoch: 46, loss: 0.287352
global_step: 13824, epoch: 46, loss: 0.378417
global_step: 13825, epoch: 46, loss: 0.364768
global_step: 13826, epoch: 46, loss: 0.325078
global_step: 13827, epoch: 46, loss: 0.338509
global_step: 13828, epoch: 46, loss: 0.323253
global_step: 13829, epoch: 46, loss: 0.404754
global_step: 13830, epoch: 46, loss: 0.452091
global_step: 13831, epoch: 46, loss: 0.327677
global_step: 13832, epoch: 46, loss: 0.472285
global_step: 13833, epoch: 46, loss: 0.395892
global_step: 13834, epoch: 46, loss: 0.330894
global_step: 13835, epoch: 46, loss: 0.311711
global_step: 13836, epoch: 46, loss: 0.382425
global_step: 13837, epoch: 46, loss: 0.368450
global_step: 13838, epoch: 46, loss: 0.484081
global_step: 13839, epoch: 46, loss: 0.348605
global_step: 13840, epoch: 46, loss: 0.015972
epoch: 46
train	acc: 0.9575	macro: p 0.9606, r 0.9406, f1: 0.9496	micro: p 0.9575, r 0.9575, f1 0.9575	weighted_f1:0.9576
dev	acc: 0.5230	macro: p 0.3703, r 0.3130, f1: 0.3148	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4840
test	acc: 0.5636	macro: p 0.3517, r 0.3168, f1: 0.3189	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5332
global_step: 13841, epoch: 47, loss: 0.286253
global_step: 13842, epoch: 47, loss: 0.306996
global_step: 13843, epoch: 47, loss: 0.301254
global_step: 13844, epoch: 47, loss: 0.345547
global_step: 13845, epoch: 47, loss: 0.271278
global_step: 13846, epoch: 47, loss: 0.282704
global_step: 13847, epoch: 47, loss: 0.359045
global_step: 13848, epoch: 47, loss: 0.297698
global_step: 13849, epoch: 47, loss: 0.233171
global_step: 13850, epoch: 47, loss: 0.369317
global_step: 13851, epoch: 47, loss: 0.377009
global_step: 13852, epoch: 47, loss: 0.426549
global_step: 13853, epoch: 47, loss: 0.329161
global_step: 13854, epoch: 47, loss: 0.408041
global_step: 13855, epoch: 47, loss: 0.338929
global_step: 13856, epoch: 47, loss: 0.327077
global_step: 13857, epoch: 47, loss: 0.384497
global_step: 13858, epoch: 47, loss: 0.285785
global_step: 13859, epoch: 47, loss: 0.359464
global_step: 13860, epoch: 47, loss: 0.392414
global_step: 13861, epoch: 47, loss: 0.300118
global_step: 13862, epoch: 47, loss: 0.412808
global_step: 13863, epoch: 47, loss: 0.271813
global_step: 13864, epoch: 47, loss: 0.373796
global_step: 13865, epoch: 47, loss: 0.385452
global_step: 13866, epoch: 47, loss: 0.373420
global_step: 13867, epoch: 47, loss: 0.323977
global_step: 13868, epoch: 47, loss: 0.320507
global_step: 13869, epoch: 47, loss: 0.292183
global_step: 13870, epoch: 47, loss: 0.480031
global_step: 13871, epoch: 47, loss: 0.291418
global_step: 13872, epoch: 47, loss: 0.321097
global_step: 13873, epoch: 47, loss: 0.327539
global_step: 13874, epoch: 47, loss: 0.366294
global_step: 13875, epoch: 47, loss: 0.292752
global_step: 13876, epoch: 47, loss: 0.333913
global_step: 13877, epoch: 47, loss: 0.418023
global_step: 13878, epoch: 47, loss: 0.440461
global_step: 13879, epoch: 47, loss: 0.359443
global_step: 13880, epoch: 47, loss: 0.337122
epoch: 47
train	acc: 0.9504	macro: p 0.9551, r 0.9237, f1: 0.9382	micro: p 0.9504, r 0.9504, f1 0.9504	weighted_f1:0.9503
dev	acc: 0.5239	macro: p 0.4114, r 0.3077, f1: 0.3239	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4825
test	acc: 0.5747	macro: p 0.4286, r 0.3097, f1: 0.3284	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5370
global_step: 13881, epoch: 48, loss: 0.391781
global_step: 13882, epoch: 48, loss: 0.453833
global_step: 13883, epoch: 48, loss: 0.364219
global_step: 13884, epoch: 48, loss: 0.452821
global_step: 13885, epoch: 48, loss: 0.396608
global_step: 13886, epoch: 48, loss: 0.354759
global_step: 13887, epoch: 48, loss: 0.271401
global_step: 13888, epoch: 48, loss: 0.375757
global_step: 13889, epoch: 48, loss: 0.427749
global_step: 13890, epoch: 48, loss: 0.322455
global_step: 13891, epoch: 48, loss: 0.323576
global_step: 13892, epoch: 48, loss: 0.285949
global_step: 13893, epoch: 48, loss: 0.373201
global_step: 13894, epoch: 48, loss: 0.331793
global_step: 13895, epoch: 48, loss: 0.373873
global_step: 13896, epoch: 48, loss: 0.309954
global_step: 13897, epoch: 48, loss: 0.368166
global_step: 13898, epoch: 48, loss: 0.293224
global_step: 13899, epoch: 48, loss: 0.265645
global_step: 13900, epoch: 48, loss: 0.347845
global_step: 13901, epoch: 48, loss: 0.308992
global_step: 13902, epoch: 48, loss: 0.347879
global_step: 13903, epoch: 48, loss: 0.296778
global_step: 13904, epoch: 48, loss: 0.253004
global_step: 13905, epoch: 48, loss: 0.244428
global_step: 13906, epoch: 48, loss: 0.309116
global_step: 13907, epoch: 48, loss: 0.292805
global_step: 13908, epoch: 48, loss: 0.388106
global_step: 13909, epoch: 48, loss: 0.313718
global_step: 13910, epoch: 48, loss: 0.284367
global_step: 13911, epoch: 48, loss: 0.300699
global_step: 13912, epoch: 48, loss: 0.432664
global_step: 13913, epoch: 48, loss: 0.270533
global_step: 13914, epoch: 48, loss: 0.338737
global_step: 13915, epoch: 48, loss: 0.285761
global_step: 13916, epoch: 48, loss: 0.376774
global_step: 13917, epoch: 48, loss: 0.397228
global_step: 13918, epoch: 48, loss: 0.289949
global_step: 13919, epoch: 48, loss: 0.340551
global_step: 13920, epoch: 48, loss: 0.471004
epoch: 48
train	acc: 0.9580	macro: p 0.9639, r 0.9396, f1: 0.9512	micro: p 0.9580, r 0.9580, f1 0.9580	weighted_f1:0.9579
dev	acc: 0.5338	macro: p 0.4483, r 0.3111, f1: 0.3226	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4843
test	acc: 0.5793	macro: p 0.3847, r 0.3022, f1: 0.3071	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5297
global_step: 13921, epoch: 49, loss: 0.314864
global_step: 13922, epoch: 49, loss: 0.366899
global_step: 13923, epoch: 49, loss: 0.299050
global_step: 13924, epoch: 49, loss: 0.298885
global_step: 13925, epoch: 49, loss: 0.269580
global_step: 13926, epoch: 49, loss: 0.320206
global_step: 13927, epoch: 49, loss: 0.255127
global_step: 13928, epoch: 49, loss: 0.387974
global_step: 13929, epoch: 49, loss: 0.335601
global_step: 13930, epoch: 49, loss: 0.249278
global_step: 13931, epoch: 49, loss: 0.311237
global_step: 13932, epoch: 49, loss: 0.326158
global_step: 13933, epoch: 49, loss: 0.306914
global_step: 13934, epoch: 49, loss: 0.353688
global_step: 13935, epoch: 49, loss: 0.359362
global_step: 13936, epoch: 49, loss: 0.298719
global_step: 13937, epoch: 49, loss: 0.313924
global_step: 13938, epoch: 49, loss: 0.356031
global_step: 13939, epoch: 49, loss: 0.229046
global_step: 13940, epoch: 49, loss: 0.382092
global_step: 13941, epoch: 49, loss: 0.317067
global_step: 13942, epoch: 49, loss: 0.225429
global_step: 13943, epoch: 49, loss: 0.350588
global_step: 13944, epoch: 49, loss: 0.360656
global_step: 13945, epoch: 49, loss: 0.434760
global_step: 13946, epoch: 49, loss: 0.289106
global_step: 13947, epoch: 49, loss: 0.297193
global_step: 13948, epoch: 49, loss: 0.342032
global_step: 13949, epoch: 49, loss: 0.378075
global_step: 13950, epoch: 49, loss: 0.311207
global_step: 13951, epoch: 49, loss: 0.332869
global_step: 13952, epoch: 49, loss: 0.294579
global_step: 13953, epoch: 49, loss: 0.337405
global_step: 13954, epoch: 49, loss: 0.312048
global_step: 13955, epoch: 49, loss: 0.328174
global_step: 13956, epoch: 49, loss: 0.311561
global_step: 13957, epoch: 49, loss: 0.295461
global_step: 13958, epoch: 49, loss: 0.325119
global_step: 13959, epoch: 49, loss: 0.331414
global_step: 13960, epoch: 49, loss: 0.000874
epoch: 49
train	acc: 0.9623	macro: p 0.9647, r 0.9476, f1: 0.9556	micro: p 0.9623, r 0.9623, f1 0.9623	weighted_f1:0.9623
dev	acc: 0.5239	macro: p 0.3659, r 0.3130, f1: 0.3192	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4870
test	acc: 0.5732	macro: p 0.3573, r 0.3183, f1: 0.3233	micro: p 0.5732, r 0.5732, f1 0.5732	weighted_f1:0.5411
global_step: 13961, epoch: 50, loss: 0.361327
global_step: 13962, epoch: 50, loss: 0.172881
global_step: 13963, epoch: 50, loss: 0.289313
global_step: 13964, epoch: 50, loss: 0.331388
global_step: 13965, epoch: 50, loss: 0.247092
global_step: 13966, epoch: 50, loss: 0.311865
global_step: 13967, epoch: 50, loss: 0.338631
global_step: 13968, epoch: 50, loss: 0.324324
global_step: 13969, epoch: 50, loss: 0.297120
global_step: 13970, epoch: 50, loss: 0.261489
global_step: 13971, epoch: 50, loss: 0.236863
global_step: 13972, epoch: 50, loss: 0.239796
global_step: 13973, epoch: 50, loss: 0.273897
global_step: 13974, epoch: 50, loss: 0.242270
global_step: 13975, epoch: 50, loss: 0.270071
global_step: 13976, epoch: 50, loss: 0.339252
global_step: 13977, epoch: 50, loss: 0.251676
global_step: 13978, epoch: 50, loss: 0.322731
global_step: 13979, epoch: 50, loss: 0.320899
global_step: 13980, epoch: 50, loss: 0.189634
global_step: 13981, epoch: 50, loss: 0.303900
global_step: 13982, epoch: 50, loss: 0.294830
global_step: 13983, epoch: 50, loss: 0.407409
global_step: 13984, epoch: 50, loss: 0.424658
global_step: 13985, epoch: 50, loss: 0.357705
global_step: 13986, epoch: 50, loss: 0.295866
global_step: 13987, epoch: 50, loss: 0.395290
global_step: 13988, epoch: 50, loss: 0.325816
global_step: 13989, epoch: 50, loss: 0.393245
global_step: 13990, epoch: 50, loss: 0.296161
global_step: 13991, epoch: 50, loss: 0.402956
global_step: 13992, epoch: 50, loss: 0.312421
global_step: 13993, epoch: 50, loss: 0.369378
global_step: 13994, epoch: 50, loss: 0.335930
global_step: 13995, epoch: 50, loss: 0.275561
global_step: 13996, epoch: 50, loss: 0.350388
global_step: 13997, epoch: 50, loss: 0.289922
global_step: 13998, epoch: 50, loss: 0.281755
global_step: 13999, epoch: 50, loss: 0.296697
global_step: 14000, epoch: 50, loss: 0.176449
epoch: 50
train	acc: 0.9609	macro: p 0.9654, r 0.9479, f1: 0.9563	micro: p 0.9609, r 0.9609, f1 0.9609	weighted_f1:0.9608
dev	acc: 0.5140	macro: p 0.3517, r 0.3092, f1: 0.3176	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4838
test	acc: 0.5529	macro: p 0.3343, r 0.3081, f1: 0.3143	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.5284
global_step: 14001, epoch: 51, loss: 0.376793
global_step: 14002, epoch: 51, loss: 0.304333
global_step: 14003, epoch: 51, loss: 0.216723
global_step: 14004, epoch: 51, loss: 0.343033
global_step: 14005, epoch: 51, loss: 0.230525
global_step: 14006, epoch: 51, loss: 0.199161
global_step: 14007, epoch: 51, loss: 0.323039
global_step: 14008, epoch: 51, loss: 0.298722
global_step: 14009, epoch: 51, loss: 0.230547
global_step: 14010, epoch: 51, loss: 0.302564
global_step: 14011, epoch: 51, loss: 0.355169
global_step: 14012, epoch: 51, loss: 0.321179
global_step: 14013, epoch: 51, loss: 0.316942
global_step: 14014, epoch: 51, loss: 0.310480
global_step: 14015, epoch: 51, loss: 0.313381
global_step: 14016, epoch: 51, loss: 0.314722
global_step: 14017, epoch: 51, loss: 0.306516
global_step: 14018, epoch: 51, loss: 0.347489
global_step: 14019, epoch: 51, loss: 0.247041
global_step: 14020, epoch: 51, loss: 0.273434
global_step: 14021, epoch: 51, loss: 0.317837
global_step: 14022, epoch: 51, loss: 0.279535
global_step: 14023, epoch: 51, loss: 0.377181
global_step: 14024, epoch: 51, loss: 0.353698
global_step: 14025, epoch: 51, loss: 0.359073
global_step: 14026, epoch: 51, loss: 0.280449
global_step: 14027, epoch: 51, loss: 0.340188
global_step: 14028, epoch: 51, loss: 0.332707
global_step: 14029, epoch: 51, loss: 0.427412
global_step: 14030, epoch: 51, loss: 0.350910
global_step: 14031, epoch: 51, loss: 0.321467
global_step: 14032, epoch: 51, loss: 0.268811
global_step: 14033, epoch: 51, loss: 0.242470
global_step: 14034, epoch: 51, loss: 0.255522
global_step: 14035, epoch: 51, loss: 0.350896
global_step: 14036, epoch: 51, loss: 0.295891
global_step: 14037, epoch: 51, loss: 0.289030
global_step: 14038, epoch: 51, loss: 0.327607
global_step: 14039, epoch: 51, loss: 0.394661
global_step: 14040, epoch: 51, loss: 1.872042
epoch: 51
train	acc: 0.9523	macro: p 0.9638, r 0.9338, f1: 0.9478	micro: p 0.9523, r 0.9523, f1 0.9523	weighted_f1:0.9524
dev	acc: 0.5095	macro: p 0.3943, r 0.3116, f1: 0.3116	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4806
test	acc: 0.5395	macro: p 0.4102, r 0.3134, f1: 0.3163	micro: p 0.5395, r 0.5395, f1 0.5395	weighted_f1:0.5203
global_step: 14041, epoch: 52, loss: 0.411166
global_step: 14042, epoch: 52, loss: 0.318144
global_step: 14043, epoch: 52, loss: 0.277113
global_step: 14044, epoch: 52, loss: 0.345472
global_step: 14045, epoch: 52, loss: 0.268823
global_step: 14046, epoch: 52, loss: 0.314519
global_step: 14047, epoch: 52, loss: 0.265204
global_step: 14048, epoch: 52, loss: 0.290696
global_step: 14049, epoch: 52, loss: 0.296696
global_step: 14050, epoch: 52, loss: 0.303594
global_step: 14051, epoch: 52, loss: 0.250312
global_step: 14052, epoch: 52, loss: 0.344133
global_step: 14053, epoch: 52, loss: 0.244247
global_step: 14054, epoch: 52, loss: 0.273673
global_step: 14055, epoch: 52, loss: 0.399809
global_step: 14056, epoch: 52, loss: 0.287607
global_step: 14057, epoch: 52, loss: 0.331741
global_step: 14058, epoch: 52, loss: 0.295245
global_step: 14059, epoch: 52, loss: 0.276426
global_step: 14060, epoch: 52, loss: 0.291296
global_step: 14061, epoch: 52, loss: 0.259967
global_step: 14062, epoch: 52, loss: 0.295167
global_step: 14063, epoch: 52, loss: 0.285021
global_step: 14064, epoch: 52, loss: 0.282992
global_step: 14065, epoch: 52, loss: 0.382605
global_step: 14066, epoch: 52, loss: 0.275568
global_step: 14067, epoch: 52, loss: 0.263591
global_step: 14068, epoch: 52, loss: 0.273544
global_step: 14069, epoch: 52, loss: 0.315851
global_step: 14070, epoch: 52, loss: 0.285865
global_step: 14071, epoch: 52, loss: 0.365432
global_step: 14072, epoch: 52, loss: 0.320719
global_step: 14073, epoch: 52, loss: 0.412883
global_step: 14074, epoch: 52, loss: 0.324655
global_step: 14075, epoch: 52, loss: 0.260290
global_step: 14076, epoch: 52, loss: 0.334001
global_step: 14077, epoch: 52, loss: 0.299103
global_step: 14078, epoch: 52, loss: 0.354821
global_step: 14079, epoch: 52, loss: 0.414462
global_step: 14080, epoch: 52, loss: 0.135102
epoch: 52
train	acc: 0.9594	macro: p 0.9670, r 0.9401, f1: 0.9527	micro: p 0.9594, r 0.9594, f1 0.9594	weighted_f1:0.9594
dev	acc: 0.5383	macro: p 0.4046, r 0.3188, f1: 0.3226	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4994
test	acc: 0.5713	macro: p 0.3755, r 0.3177, f1: 0.3224	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5396
global_step: 14081, epoch: 53, loss: 0.265938
global_step: 14082, epoch: 53, loss: 0.233570
global_step: 14083, epoch: 53, loss: 0.320923
global_step: 14084, epoch: 53, loss: 0.329923
global_step: 14085, epoch: 53, loss: 0.278892
global_step: 14086, epoch: 53, loss: 0.323323
global_step: 14087, epoch: 53, loss: 0.245348
global_step: 14088, epoch: 53, loss: 0.182043
global_step: 14089, epoch: 53, loss: 0.285028
global_step: 14090, epoch: 53, loss: 0.274106
global_step: 14091, epoch: 53, loss: 0.225950
global_step: 14092, epoch: 53, loss: 0.264125
global_step: 14093, epoch: 53, loss: 0.367956
global_step: 14094, epoch: 53, loss: 0.270860
global_step: 14095, epoch: 53, loss: 0.292290
global_step: 14096, epoch: 53, loss: 0.315575
global_step: 14097, epoch: 53, loss: 0.298454
global_step: 14098, epoch: 53, loss: 0.335076
global_step: 14099, epoch: 53, loss: 0.301269
global_step: 14100, epoch: 53, loss: 0.327444
global_step: 14101, epoch: 53, loss: 0.401052
global_step: 14102, epoch: 53, loss: 0.233844
global_step: 14103, epoch: 53, loss: 0.267625
global_step: 14104, epoch: 53, loss: 0.357981
global_step: 14105, epoch: 53, loss: 0.301659
global_step: 14106, epoch: 53, loss: 0.231064
global_step: 14107, epoch: 53, loss: 0.311854
global_step: 14108, epoch: 53, loss: 0.350386
global_step: 14109, epoch: 53, loss: 0.265802
global_step: 14110, epoch: 53, loss: 0.264357
global_step: 14111, epoch: 53, loss: 0.330058
global_step: 14112, epoch: 53, loss: 0.319983
global_step: 14113, epoch: 53, loss: 0.438633
global_step: 14114, epoch: 53, loss: 0.333446
global_step: 14115, epoch: 53, loss: 0.307510
global_step: 14116, epoch: 53, loss: 0.301365
global_step: 14117, epoch: 53, loss: 0.222518
global_step: 14118, epoch: 53, loss: 0.317128
global_step: 14119, epoch: 53, loss: 0.343731
global_step: 14120, epoch: 53, loss: 0.469934
epoch: 53
train	acc: 0.9598	macro: p 0.9673, r 0.9406, f1: 0.9533	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9597
dev	acc: 0.5410	macro: p 0.4392, r 0.3118, f1: 0.3210	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4871
test	acc: 0.5805	macro: p 0.3699, r 0.3062, f1: 0.3124	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5328
global_step: 14121, epoch: 54, loss: 0.338136
global_step: 14122, epoch: 54, loss: 0.307726
global_step: 14123, epoch: 54, loss: 0.260852
global_step: 14124, epoch: 54, loss: 0.270414
global_step: 14125, epoch: 54, loss: 0.336959
global_step: 14126, epoch: 54, loss: 0.256211
global_step: 14127, epoch: 54, loss: 0.279243
global_step: 14128, epoch: 54, loss: 0.256800
global_step: 14129, epoch: 54, loss: 0.322464
global_step: 14130, epoch: 54, loss: 0.301578
global_step: 14131, epoch: 54, loss: 0.298681
global_step: 14132, epoch: 54, loss: 0.297857
global_step: 14133, epoch: 54, loss: 0.300468
global_step: 14134, epoch: 54, loss: 0.231919
global_step: 14135, epoch: 54, loss: 0.204022
global_step: 14136, epoch: 54, loss: 0.335683
global_step: 14137, epoch: 54, loss: 0.309035
global_step: 14138, epoch: 54, loss: 0.196447
global_step: 14139, epoch: 54, loss: 0.260277
global_step: 14140, epoch: 54, loss: 0.245838
global_step: 14141, epoch: 54, loss: 0.258174
global_step: 14142, epoch: 54, loss: 0.275248
global_step: 14143, epoch: 54, loss: 0.346801
global_step: 14144, epoch: 54, loss: 0.308847
global_step: 14145, epoch: 54, loss: 0.264937
global_step: 14146, epoch: 54, loss: 0.278265
global_step: 14147, epoch: 54, loss: 0.262643
global_step: 14148, epoch: 54, loss: 0.281056
global_step: 14149, epoch: 54, loss: 0.265426
global_step: 14150, epoch: 54, loss: 0.282337
global_step: 14151, epoch: 54, loss: 0.327631
global_step: 14152, epoch: 54, loss: 0.315197
global_step: 14153, epoch: 54, loss: 0.289230
global_step: 14154, epoch: 54, loss: 0.334050
global_step: 14155, epoch: 54, loss: 0.329520
global_step: 14156, epoch: 54, loss: 0.272999
global_step: 14157, epoch: 54, loss: 0.334916
global_step: 14158, epoch: 54, loss: 0.363963
global_step: 14159, epoch: 54, loss: 0.347727
global_step: 14160, epoch: 54, loss: 0.317469
epoch: 54
train	acc: 0.9602	macro: p 0.9708, r 0.9407, f1: 0.9551	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9600
dev	acc: 0.5221	macro: p 0.4308, r 0.3037, f1: 0.3178	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4778
test	acc: 0.5678	macro: p 0.3345, r 0.2979, f1: 0.3053	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.5252
global_step: 14161, epoch: 55, loss: 0.240850
global_step: 14162, epoch: 55, loss: 0.281775
global_step: 14163, epoch: 55, loss: 0.274832
global_step: 14164, epoch: 55, loss: 0.252259
global_step: 14165, epoch: 55, loss: 0.332070
global_step: 14166, epoch: 55, loss: 0.207529
global_step: 14167, epoch: 55, loss: 0.395877
global_step: 14168, epoch: 55, loss: 0.283515
global_step: 14169, epoch: 55, loss: 0.315052
global_step: 14170, epoch: 55, loss: 0.250858
global_step: 14171, epoch: 55, loss: 0.297738
global_step: 14172, epoch: 55, loss: 0.214886
global_step: 14173, epoch: 55, loss: 0.213177
global_step: 14174, epoch: 55, loss: 0.309479
global_step: 14175, epoch: 55, loss: 0.276155
global_step: 14176, epoch: 55, loss: 0.298949
global_step: 14177, epoch: 55, loss: 0.331735
global_step: 14178, epoch: 55, loss: 0.296322
global_step: 14179, epoch: 55, loss: 0.355200
global_step: 14180, epoch: 55, loss: 0.378454
global_step: 14181, epoch: 55, loss: 0.247191
global_step: 14182, epoch: 55, loss: 0.304106
global_step: 14183, epoch: 55, loss: 0.214831
global_step: 14184, epoch: 55, loss: 0.225476
global_step: 14185, epoch: 55, loss: 0.232060
global_step: 14186, epoch: 55, loss: 0.270755
global_step: 14187, epoch: 55, loss: 0.306310
global_step: 14188, epoch: 55, loss: 0.290132
global_step: 14189, epoch: 55, loss: 0.284062
global_step: 14190, epoch: 55, loss: 0.276182
global_step: 14191, epoch: 55, loss: 0.312850
global_step: 14192, epoch: 55, loss: 0.284952
global_step: 14193, epoch: 55, loss: 0.263657
global_step: 14194, epoch: 55, loss: 0.247105
global_step: 14195, epoch: 55, loss: 0.315485
global_step: 14196, epoch: 55, loss: 0.216694
global_step: 14197, epoch: 55, loss: 0.254224
global_step: 14198, epoch: 55, loss: 0.309016
global_step: 14199, epoch: 55, loss: 0.326879
global_step: 14200, epoch: 55, loss: 0.047929
epoch: 55
train	acc: 0.9632	macro: p 0.9663, r 0.9461, f1: 0.9557	micro: p 0.9632, r 0.9632, f1 0.9632	weighted_f1:0.9632
dev	acc: 0.5329	macro: p 0.3635, r 0.3090, f1: 0.3152	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4943
test	acc: 0.5713	macro: p 0.3606, r 0.3137, f1: 0.3210	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5384
global_step: 14201, epoch: 56, loss: 0.302356
global_step: 14202, epoch: 56, loss: 0.319515
global_step: 14203, epoch: 56, loss: 0.354699
global_step: 14204, epoch: 56, loss: 0.294445
global_step: 14205, epoch: 56, loss: 0.283522
global_step: 14206, epoch: 56, loss: 0.256606
global_step: 14207, epoch: 56, loss: 0.256024
global_step: 14208, epoch: 56, loss: 0.273273
global_step: 14209, epoch: 56, loss: 0.300076
global_step: 14210, epoch: 56, loss: 0.289376
global_step: 14211, epoch: 56, loss: 0.207977
global_step: 14212, epoch: 56, loss: 0.240204
global_step: 14213, epoch: 56, loss: 0.328381
global_step: 14214, epoch: 56, loss: 0.295315
global_step: 14215, epoch: 56, loss: 0.272296
global_step: 14216, epoch: 56, loss: 0.242191
global_step: 14217, epoch: 56, loss: 0.277115
global_step: 14218, epoch: 56, loss: 0.323798
global_step: 14219, epoch: 56, loss: 0.236262
global_step: 14220, epoch: 56, loss: 0.336354
global_step: 14221, epoch: 56, loss: 0.384178
global_step: 14222, epoch: 56, loss: 0.333563
global_step: 14223, epoch: 56, loss: 0.287471
global_step: 14224, epoch: 56, loss: 0.315724
global_step: 14225, epoch: 56, loss: 0.219835
global_step: 14226, epoch: 56, loss: 0.372394
global_step: 14227, epoch: 56, loss: 0.281480
global_step: 14228, epoch: 56, loss: 0.216651
global_step: 14229, epoch: 56, loss: 0.276226
global_step: 14230, epoch: 56, loss: 0.337017
global_step: 14231, epoch: 56, loss: 0.299267
global_step: 14232, epoch: 56, loss: 0.259395
global_step: 14233, epoch: 56, loss: 0.309069
global_step: 14234, epoch: 56, loss: 0.364938
global_step: 14235, epoch: 56, loss: 0.262583
global_step: 14236, epoch: 56, loss: 0.324617
global_step: 14237, epoch: 56, loss: 0.343641
global_step: 14238, epoch: 56, loss: 0.301698
global_step: 14239, epoch: 56, loss: 0.332536
global_step: 14240, epoch: 56, loss: 0.848469
epoch: 56
train	acc: 0.9535	macro: p 0.9578, r 0.9393, f1: 0.9469	micro: p 0.9535, r 0.9535, f1 0.9535	weighted_f1:0.9540
dev	acc: 0.5257	macro: p 0.4080, r 0.3043, f1: 0.3049	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4793
test	acc: 0.5617	macro: p 0.3625, r 0.3053, f1: 0.3033	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5227
global_step: 14241, epoch: 57, loss: 0.368830
global_step: 14242, epoch: 57, loss: 0.363560
global_step: 14243, epoch: 57, loss: 0.327560
global_step: 14244, epoch: 57, loss: 0.252180
global_step: 14245, epoch: 57, loss: 0.309581
global_step: 14246, epoch: 57, loss: 0.228432
global_step: 14247, epoch: 57, loss: 0.325023
global_step: 14248, epoch: 57, loss: 0.266571
global_step: 14249, epoch: 57, loss: 0.284709
global_step: 14250, epoch: 57, loss: 0.247368
global_step: 14251, epoch: 57, loss: 0.293879
global_step: 14252, epoch: 57, loss: 0.324237
global_step: 14253, epoch: 57, loss: 0.274784
global_step: 14254, epoch: 57, loss: 0.324737
global_step: 14255, epoch: 57, loss: 0.260360
global_step: 14256, epoch: 57, loss: 0.223039
global_step: 14257, epoch: 57, loss: 0.275535
global_step: 14258, epoch: 57, loss: 0.272311
global_step: 14259, epoch: 57, loss: 0.330083
global_step: 14260, epoch: 57, loss: 0.329981
global_step: 14261, epoch: 57, loss: 0.406504
global_step: 14262, epoch: 57, loss: 0.289142
global_step: 14263, epoch: 57, loss: 0.286469
global_step: 14264, epoch: 57, loss: 0.223185
global_step: 14265, epoch: 57, loss: 0.341254
global_step: 14266, epoch: 57, loss: 0.310345
global_step: 14267, epoch: 57, loss: 0.300753
global_step: 14268, epoch: 57, loss: 0.335033
global_step: 14269, epoch: 57, loss: 0.297361
global_step: 14270, epoch: 57, loss: 0.253784
global_step: 14271, epoch: 57, loss: 0.338680
global_step: 14272, epoch: 57, loss: 0.266838
global_step: 14273, epoch: 57, loss: 0.247674
global_step: 14274, epoch: 57, loss: 0.397940
global_step: 14275, epoch: 57, loss: 0.308564
global_step: 14276, epoch: 57, loss: 0.268425
global_step: 14277, epoch: 57, loss: 0.332408
global_step: 14278, epoch: 57, loss: 0.294711
global_step: 14279, epoch: 57, loss: 0.278770
global_step: 14280, epoch: 57, loss: 0.030188
epoch: 57
train	acc: 0.9618	macro: p 0.9707, r 0.9439, f1: 0.9569	micro: p 0.9618, r 0.9618, f1 0.9618	weighted_f1:0.9616
dev	acc: 0.5347	macro: p 0.4018, r 0.3138, f1: 0.3281	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4899
test	acc: 0.5778	macro: p 0.3738, r 0.3128, f1: 0.3260	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5394
global_step: 14281, epoch: 58, loss: 0.186894
global_step: 14282, epoch: 58, loss: 0.318778
global_step: 14283, epoch: 58, loss: 0.289601
global_step: 14284, epoch: 58, loss: 0.298284
global_step: 14285, epoch: 58, loss: 0.234588
global_step: 14286, epoch: 58, loss: 0.285327
global_step: 14287, epoch: 58, loss: 0.200330
global_step: 14288, epoch: 58, loss: 0.213785
global_step: 14289, epoch: 58, loss: 0.356617
global_step: 14290, epoch: 58, loss: 0.175204
global_step: 14291, epoch: 58, loss: 0.216105
global_step: 14292, epoch: 58, loss: 0.246673
global_step: 14293, epoch: 58, loss: 0.232805
global_step: 14294, epoch: 58, loss: 0.343569
global_step: 14295, epoch: 58, loss: 0.282852
global_step: 14296, epoch: 58, loss: 0.225609
global_step: 14297, epoch: 58, loss: 0.297189
global_step: 14298, epoch: 58, loss: 0.251259
global_step: 14299, epoch: 58, loss: 0.324779
global_step: 14300, epoch: 58, loss: 0.249660
global_step: 14301, epoch: 58, loss: 0.271088
global_step: 14302, epoch: 58, loss: 0.268800
global_step: 14303, epoch: 58, loss: 0.283672
global_step: 14304, epoch: 58, loss: 0.334050
global_step: 14305, epoch: 58, loss: 0.340890
global_step: 14306, epoch: 58, loss: 0.207707
global_step: 14307, epoch: 58, loss: 0.269323
global_step: 14308, epoch: 58, loss: 0.318331
global_step: 14309, epoch: 58, loss: 0.292932
global_step: 14310, epoch: 58, loss: 0.358023
global_step: 14311, epoch: 58, loss: 0.364568
global_step: 14312, epoch: 58, loss: 0.304409
global_step: 14313, epoch: 58, loss: 0.396893
global_step: 14314, epoch: 58, loss: 0.296388
global_step: 14315, epoch: 58, loss: 0.290094
global_step: 14316, epoch: 58, loss: 0.243744
global_step: 14317, epoch: 58, loss: 0.306825
global_step: 14318, epoch: 58, loss: 0.289887
global_step: 14319, epoch: 58, loss: 0.315954
global_step: 14320, epoch: 58, loss: 1.057838
epoch: 58
train	acc: 0.9635	macro: p 0.9691, r 0.9485, f1: 0.9584	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9634
dev	acc: 0.5311	macro: p 0.3807, r 0.3120, f1: 0.3197	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4886
test	acc: 0.5801	macro: p 0.3673, r 0.3127, f1: 0.3204	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5409
global_step: 14321, epoch: 59, loss: 0.310477
global_step: 14322, epoch: 59, loss: 0.309246
global_step: 14323, epoch: 59, loss: 0.215429
global_step: 14324, epoch: 59, loss: 0.226745
global_step: 14325, epoch: 59, loss: 0.342720
global_step: 14326, epoch: 59, loss: 0.276036
global_step: 14327, epoch: 59, loss: 0.297451
global_step: 14328, epoch: 59, loss: 0.310124
global_step: 14329, epoch: 59, loss: 0.240975
global_step: 14330, epoch: 59, loss: 0.240172
global_step: 14331, epoch: 59, loss: 0.313181
global_step: 14332, epoch: 59, loss: 0.277879
global_step: 14333, epoch: 59, loss: 0.232711
global_step: 14334, epoch: 59, loss: 0.316296
global_step: 14335, epoch: 59, loss: 0.270396
global_step: 14336, epoch: 59, loss: 0.363405
global_step: 14337, epoch: 59, loss: 0.269813
global_step: 14338, epoch: 59, loss: 0.218358
global_step: 14339, epoch: 59, loss: 0.218316
global_step: 14340, epoch: 59, loss: 0.277794
global_step: 14341, epoch: 59, loss: 0.255714
global_step: 14342, epoch: 59, loss: 0.363232
global_step: 14343, epoch: 59, loss: 0.261066
global_step: 14344, epoch: 59, loss: 0.311540
global_step: 14345, epoch: 59, loss: 0.301454
global_step: 14346, epoch: 59, loss: 0.361371
global_step: 14347, epoch: 59, loss: 0.235083
global_step: 14348, epoch: 59, loss: 0.323753
global_step: 14349, epoch: 59, loss: 0.302574
global_step: 14350, epoch: 59, loss: 0.253020
global_step: 14351, epoch: 59, loss: 0.236941
global_step: 14352, epoch: 59, loss: 0.328493
global_step: 14353, epoch: 59, loss: 0.287998
global_step: 14354, epoch: 59, loss: 0.269744
global_step: 14355, epoch: 59, loss: 0.420164
global_step: 14356, epoch: 59, loss: 0.274027
global_step: 14357, epoch: 59, loss: 0.302832
global_step: 14358, epoch: 59, loss: 0.253358
global_step: 14359, epoch: 59, loss: 0.294943
global_step: 14360, epoch: 59, loss: 0.060633
epoch: 59
train	acc: 0.9654	macro: p 0.9706, r 0.9514, f1: 0.9607	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9654
dev	acc: 0.5302	macro: p 0.4218, r 0.3189, f1: 0.3316	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4901
test	acc: 0.5793	macro: p 0.3758, r 0.3144, f1: 0.3216	micro: p 0.5793, r 0.5793, f1 0.5793	weighted_f1:0.5396
global_step: 14361, epoch: 60, loss: 0.288942
global_step: 14362, epoch: 60, loss: 0.251460
global_step: 14363, epoch: 60, loss: 0.233490
global_step: 14364, epoch: 60, loss: 0.228952
global_step: 14365, epoch: 60, loss: 0.208663
global_step: 14366, epoch: 60, loss: 0.275280
global_step: 14367, epoch: 60, loss: 0.305937
global_step: 14368, epoch: 60, loss: 0.317384
global_step: 14369, epoch: 60, loss: 0.288036
global_step: 14370, epoch: 60, loss: 0.273859
global_step: 14371, epoch: 60, loss: 0.336580
global_step: 14372, epoch: 60, loss: 0.286786
global_step: 14373, epoch: 60, loss: 0.213095
global_step: 14374, epoch: 60, loss: 0.304879
global_step: 14375, epoch: 60, loss: 0.296262
global_step: 14376, epoch: 60, loss: 0.353800
global_step: 14377, epoch: 60, loss: 0.259170
global_step: 14378, epoch: 60, loss: 0.257975
global_step: 14379, epoch: 60, loss: 0.278753
global_step: 14380, epoch: 60, loss: 0.316600
global_step: 14381, epoch: 60, loss: 0.290769
global_step: 14382, epoch: 60, loss: 0.265780
global_step: 14383, epoch: 60, loss: 0.327124
global_step: 14384, epoch: 60, loss: 0.279163
global_step: 14385, epoch: 60, loss: 0.254344
global_step: 14386, epoch: 60, loss: 0.291991
global_step: 14387, epoch: 60, loss: 0.299849
global_step: 14388, epoch: 60, loss: 0.242170
global_step: 14389, epoch: 60, loss: 0.286814
global_step: 14390, epoch: 60, loss: 0.270913
global_step: 14391, epoch: 60, loss: 0.285418
global_step: 14392, epoch: 60, loss: 0.231450
global_step: 14393, epoch: 60, loss: 0.228771
global_step: 14394, epoch: 60, loss: 0.357797
global_step: 14395, epoch: 60, loss: 0.314223
global_step: 14396, epoch: 60, loss: 0.246139
global_step: 14397, epoch: 60, loss: 0.245167
global_step: 14398, epoch: 60, loss: 0.331437
global_step: 14399, epoch: 60, loss: 0.215121
global_step: 14400, epoch: 60, loss: 0.229513
epoch: 60
train	acc: 0.9661	macro: p 0.9664, r 0.9555, f1: 0.9608	micro: p 0.9661, r 0.9661, f1 0.9661	weighted_f1:0.9661
dev	acc: 0.5158	macro: p 0.3801, r 0.3335, f1: 0.3472	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4930
test	acc: 0.5602	macro: p 0.3691, r 0.3224, f1: 0.3336	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5396
global_step: 14401, epoch: 61, loss: 0.290854
global_step: 14402, epoch: 61, loss: 0.230299
global_step: 14403, epoch: 61, loss: 0.396042
global_step: 14404, epoch: 61, loss: 0.375253
global_step: 14405, epoch: 61, loss: 0.266443
global_step: 14406, epoch: 61, loss: 0.334001
global_step: 14407, epoch: 61, loss: 0.327024
global_step: 14408, epoch: 61, loss: 0.353521
global_step: 14409, epoch: 61, loss: 0.223225
global_step: 14410, epoch: 61, loss: 0.293384
global_step: 14411, epoch: 61, loss: 0.235061
global_step: 14412, epoch: 61, loss: 0.255861
global_step: 14413, epoch: 61, loss: 0.210555
global_step: 14414, epoch: 61, loss: 0.268196
global_step: 14415, epoch: 61, loss: 0.334141
global_step: 14416, epoch: 61, loss: 0.274624
global_step: 14417, epoch: 61, loss: 0.331960
global_step: 14418, epoch: 61, loss: 0.297759
global_step: 14419, epoch: 61, loss: 0.310790
global_step: 14420, epoch: 61, loss: 0.266347
global_step: 14421, epoch: 61, loss: 0.318412
global_step: 14422, epoch: 61, loss: 0.285773
global_step: 14423, epoch: 61, loss: 0.351484
global_step: 14424, epoch: 61, loss: 0.274829
global_step: 14425, epoch: 61, loss: 0.258470
global_step: 14426, epoch: 61, loss: 0.286088
global_step: 14427, epoch: 61, loss: 0.262100
global_step: 14428, epoch: 61, loss: 0.241538
global_step: 14429, epoch: 61, loss: 0.237763
global_step: 14430, epoch: 61, loss: 0.291121
global_step: 14431, epoch: 61, loss: 0.366869
global_step: 14432, epoch: 61, loss: 0.228371
global_step: 14433, epoch: 61, loss: 0.328934
global_step: 14434, epoch: 61, loss: 0.212737
global_step: 14435, epoch: 61, loss: 0.365929
global_step: 14436, epoch: 61, loss: 0.316262
global_step: 14437, epoch: 61, loss: 0.219964
global_step: 14438, epoch: 61, loss: 0.221954
global_step: 14439, epoch: 61, loss: 0.364660
global_step: 14440, epoch: 61, loss: 0.301095
epoch: 61
train	acc: 0.9592	macro: p 0.9589, r 0.9502, f1: 0.9539	micro: p 0.9592, r 0.9592, f1 0.9592	weighted_f1:0.9595
dev	acc: 0.5212	macro: p 0.4137, r 0.3400, f1: 0.3474	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4898
test	acc: 0.5605	macro: p 0.3605, r 0.3210, f1: 0.3168	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5303
global_step: 14441, epoch: 62, loss: 0.293936
global_step: 14442, epoch: 62, loss: 0.248371
global_step: 14443, epoch: 62, loss: 0.277650
global_step: 14444, epoch: 62, loss: 0.175279
global_step: 14445, epoch: 62, loss: 0.293550
global_step: 14446, epoch: 62, loss: 0.296708
global_step: 14447, epoch: 62, loss: 0.160241
global_step: 14448, epoch: 62, loss: 0.253131
global_step: 14449, epoch: 62, loss: 0.215860
global_step: 14450, epoch: 62, loss: 0.300819
global_step: 14451, epoch: 62, loss: 0.193458
global_step: 14452, epoch: 62, loss: 0.352945
global_step: 14453, epoch: 62, loss: 0.255611
global_step: 14454, epoch: 62, loss: 0.320996
global_step: 14455, epoch: 62, loss: 0.203126
global_step: 14456, epoch: 62, loss: 0.242876
global_step: 14457, epoch: 62, loss: 0.309865
global_step: 14458, epoch: 62, loss: 0.325314
global_step: 14459, epoch: 62, loss: 0.211192
global_step: 14460, epoch: 62, loss: 0.324976
global_step: 14461, epoch: 62, loss: 0.262364
global_step: 14462, epoch: 62, loss: 0.222477
global_step: 14463, epoch: 62, loss: 0.280404
global_step: 14464, epoch: 62, loss: 0.308900
global_step: 14465, epoch: 62, loss: 0.236864
global_step: 14466, epoch: 62, loss: 0.259935
global_step: 14467, epoch: 62, loss: 0.284926
global_step: 14468, epoch: 62, loss: 0.387342
global_step: 14469, epoch: 62, loss: 0.205602
global_step: 14470, epoch: 62, loss: 0.240945
global_step: 14471, epoch: 62, loss: 0.268925
global_step: 14472, epoch: 62, loss: 0.321105
global_step: 14473, epoch: 62, loss: 0.215868
global_step: 14474, epoch: 62, loss: 0.347033
global_step: 14475, epoch: 62, loss: 0.291858
global_step: 14476, epoch: 62, loss: 0.205262
global_step: 14477, epoch: 62, loss: 0.178188
global_step: 14478, epoch: 62, loss: 0.448707
global_step: 14479, epoch: 62, loss: 0.274618
global_step: 14480, epoch: 62, loss: 0.947727
epoch: 62
train	acc: 0.9654	macro: p 0.9696, r 0.9510, f1: 0.9599	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9654
dev	acc: 0.5365	macro: p 0.4021, r 0.3239, f1: 0.3362	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4961
test	acc: 0.5728	macro: p 0.4169, r 0.3129, f1: 0.3209	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.5344
global_step: 14481, epoch: 63, loss: 0.317835
global_step: 14482, epoch: 63, loss: 0.247122
global_step: 14483, epoch: 63, loss: 0.255193
global_step: 14484, epoch: 63, loss: 0.378874
global_step: 14485, epoch: 63, loss: 0.266286
global_step: 14486, epoch: 63, loss: 0.296879
global_step: 14487, epoch: 63, loss: 0.247109
global_step: 14488, epoch: 63, loss: 0.225760
global_step: 14489, epoch: 63, loss: 0.371919
global_step: 14490, epoch: 63, loss: 0.208755
global_step: 14491, epoch: 63, loss: 0.221774
global_step: 14492, epoch: 63, loss: 0.291012
global_step: 14493, epoch: 63, loss: 0.257914
global_step: 14494, epoch: 63, loss: 0.286734
global_step: 14495, epoch: 63, loss: 0.237179
global_step: 14496, epoch: 63, loss: 0.240619
global_step: 14497, epoch: 63, loss: 0.264715
global_step: 14498, epoch: 63, loss: 0.198154
global_step: 14499, epoch: 63, loss: 0.340144
global_step: 14500, epoch: 63, loss: 0.270412
global_step: 14501, epoch: 63, loss: 0.215044
global_step: 14502, epoch: 63, loss: 0.258169
global_step: 14503, epoch: 63, loss: 0.313763
global_step: 14504, epoch: 63, loss: 0.222502
global_step: 14505, epoch: 63, loss: 0.306964
global_step: 14506, epoch: 63, loss: 0.296399
global_step: 14507, epoch: 63, loss: 0.327327
global_step: 14508, epoch: 63, loss: 0.276918
global_step: 14509, epoch: 63, loss: 0.236786
global_step: 14510, epoch: 63, loss: 0.255683
global_step: 14511, epoch: 63, loss: 0.277986
global_step: 14512, epoch: 63, loss: 0.255991
global_step: 14513, epoch: 63, loss: 0.304060
global_step: 14514, epoch: 63, loss: 0.250013
global_step: 14515, epoch: 63, loss: 0.229789
global_step: 14516, epoch: 63, loss: 0.248711
global_step: 14517, epoch: 63, loss: 0.380464
global_step: 14518, epoch: 63, loss: 0.265613
global_step: 14519, epoch: 63, loss: 0.301635
global_step: 14520, epoch: 63, loss: 0.082030
epoch: 63
train	acc: 0.9655	macro: p 0.9690, r 0.9533, f1: 0.9608	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5239	macro: p 0.3780, r 0.3214, f1: 0.3305	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4922
test	acc: 0.5640	macro: p 0.3739, r 0.3136, f1: 0.3202	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5336
global_step: 14521, epoch: 64, loss: 0.211896
global_step: 14522, epoch: 64, loss: 0.315730
global_step: 14523, epoch: 64, loss: 0.168962
global_step: 14524, epoch: 64, loss: 0.213421
global_step: 14525, epoch: 64, loss: 0.218310
global_step: 14526, epoch: 64, loss: 0.288047
global_step: 14527, epoch: 64, loss: 0.281795
global_step: 14528, epoch: 64, loss: 0.261428
global_step: 14529, epoch: 64, loss: 0.281802
global_step: 14530, epoch: 64, loss: 0.299237
global_step: 14531, epoch: 64, loss: 0.182656
global_step: 14532, epoch: 64, loss: 0.224040
global_step: 14533, epoch: 64, loss: 0.267330
global_step: 14534, epoch: 64, loss: 0.227286
global_step: 14535, epoch: 64, loss: 0.265735
global_step: 14536, epoch: 64, loss: 0.279431
global_step: 14537, epoch: 64, loss: 0.246443
global_step: 14538, epoch: 64, loss: 0.276276
global_step: 14539, epoch: 64, loss: 0.288956
global_step: 14540, epoch: 64, loss: 0.315670
global_step: 14541, epoch: 64, loss: 0.270979
global_step: 14542, epoch: 64, loss: 0.300221
global_step: 14543, epoch: 64, loss: 0.318355
global_step: 14544, epoch: 64, loss: 0.248889
global_step: 14545, epoch: 64, loss: 0.258843
global_step: 14546, epoch: 64, loss: 0.298804
global_step: 14547, epoch: 64, loss: 0.243823
global_step: 14548, epoch: 64, loss: 0.209373
global_step: 14549, epoch: 64, loss: 0.288849
global_step: 14550, epoch: 64, loss: 0.216132
global_step: 14551, epoch: 64, loss: 0.258300
global_step: 14552, epoch: 64, loss: 0.362800
global_step: 14553, epoch: 64, loss: 0.269720
global_step: 14554, epoch: 64, loss: 0.203400
global_step: 14555, epoch: 64, loss: 0.212690
global_step: 14556, epoch: 64, loss: 0.315201
global_step: 14557, epoch: 64, loss: 0.286448
global_step: 14558, epoch: 64, loss: 0.275664
global_step: 14559, epoch: 64, loss: 0.254161
global_step: 14560, epoch: 64, loss: 0.266057
epoch: 64
train	acc: 0.9649	macro: p 0.9698, r 0.9475, f1: 0.9581	micro: p 0.9649, r 0.9649, f1 0.9649	weighted_f1:0.9649
dev	acc: 0.5329	macro: p 0.3997, r 0.3105, f1: 0.3168	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4896
test	acc: 0.5789	macro: p 0.4154, r 0.3153, f1: 0.3233	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5407
global_step: 14561, epoch: 65, loss: 0.269372
global_step: 14562, epoch: 65, loss: 0.207372
global_step: 14563, epoch: 65, loss: 0.249138
global_step: 14564, epoch: 65, loss: 0.203996
global_step: 14565, epoch: 65, loss: 0.259999
global_step: 14566, epoch: 65, loss: 0.216892
global_step: 14567, epoch: 65, loss: 0.264567
global_step: 14568, epoch: 65, loss: 0.225726
global_step: 14569, epoch: 65, loss: 0.298018
global_step: 14570, epoch: 65, loss: 0.305792
global_step: 14571, epoch: 65, loss: 0.357349
global_step: 14572, epoch: 65, loss: 0.293501
global_step: 14573, epoch: 65, loss: 0.311725
global_step: 14574, epoch: 65, loss: 0.296384
global_step: 14575, epoch: 65, loss: 0.222139
global_step: 14576, epoch: 65, loss: 0.264015
global_step: 14577, epoch: 65, loss: 0.215730
global_step: 14578, epoch: 65, loss: 0.285430
global_step: 14579, epoch: 65, loss: 0.247090
global_step: 14580, epoch: 65, loss: 0.290555
global_step: 14581, epoch: 65, loss: 0.226656
global_step: 14582, epoch: 65, loss: 0.201165
global_step: 14583, epoch: 65, loss: 0.227510
global_step: 14584, epoch: 65, loss: 0.249717
global_step: 14585, epoch: 65, loss: 0.241385
global_step: 14586, epoch: 65, loss: 0.304795
global_step: 14587, epoch: 65, loss: 0.333019
global_step: 14588, epoch: 65, loss: 0.206197
global_step: 14589, epoch: 65, loss: 0.252708
global_step: 14590, epoch: 65, loss: 0.266315
global_step: 14591, epoch: 65, loss: 0.314869
global_step: 14592, epoch: 65, loss: 0.267868
global_step: 14593, epoch: 65, loss: 0.226171
global_step: 14594, epoch: 65, loss: 0.268196
global_step: 14595, epoch: 65, loss: 0.295177
global_step: 14596, epoch: 65, loss: 0.293646
global_step: 14597, epoch: 65, loss: 0.351840
global_step: 14598, epoch: 65, loss: 0.278629
global_step: 14599, epoch: 65, loss: 0.364315
global_step: 14600, epoch: 65, loss: 0.199824
epoch: 65
train	acc: 0.9670	macro: p 0.9701, r 0.9524, f1: 0.9609	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5284	macro: p 0.3771, r 0.3119, f1: 0.3187	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4927
test	acc: 0.5682	macro: p 0.3870, r 0.3172, f1: 0.3257	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5377
global_step: 14601, epoch: 66, loss: 0.242684
global_step: 14602, epoch: 66, loss: 0.219885
global_step: 14603, epoch: 66, loss: 0.263764
global_step: 14604, epoch: 66, loss: 0.251769
global_step: 14605, epoch: 66, loss: 0.284815
global_step: 14606, epoch: 66, loss: 0.237925
global_step: 14607, epoch: 66, loss: 0.194364
global_step: 14608, epoch: 66, loss: 0.284047
global_step: 14609, epoch: 66, loss: 0.206997
global_step: 14610, epoch: 66, loss: 0.338502
global_step: 14611, epoch: 66, loss: 0.293814
global_step: 14612, epoch: 66, loss: 0.290655
global_step: 14613, epoch: 66, loss: 0.311463
global_step: 14614, epoch: 66, loss: 0.256616
global_step: 14615, epoch: 66, loss: 0.277382
global_step: 14616, epoch: 66, loss: 0.309913
global_step: 14617, epoch: 66, loss: 0.248096
global_step: 14618, epoch: 66, loss: 0.280141
global_step: 14619, epoch: 66, loss: 0.238221
global_step: 14620, epoch: 66, loss: 0.261352
global_step: 14621, epoch: 66, loss: 0.187988
global_step: 14622, epoch: 66, loss: 0.307665
global_step: 14623, epoch: 66, loss: 0.252299
global_step: 14624, epoch: 66, loss: 0.265947
global_step: 14625, epoch: 66, loss: 0.282863
global_step: 14626, epoch: 66, loss: 0.278710
global_step: 14627, epoch: 66, loss: 0.272097
global_step: 14628, epoch: 66, loss: 0.259973
global_step: 14629, epoch: 66, loss: 0.302375
global_step: 14630, epoch: 66, loss: 0.196318
global_step: 14631, epoch: 66, loss: 0.282977
global_step: 14632, epoch: 66, loss: 0.305606
global_step: 14633, epoch: 66, loss: 0.274098
global_step: 14634, epoch: 66, loss: 0.276697
global_step: 14635, epoch: 66, loss: 0.265260
global_step: 14636, epoch: 66, loss: 0.305926
global_step: 14637, epoch: 66, loss: 0.308118
global_step: 14638, epoch: 66, loss: 0.324936
global_step: 14639, epoch: 66, loss: 0.220628
global_step: 14640, epoch: 66, loss: 0.161906
epoch: 66
train	acc: 0.9664	macro: p 0.9710, r 0.9513, f1: 0.9607	micro: p 0.9664, r 0.9664, f1 0.9664	weighted_f1:0.9664
dev	acc: 0.5329	macro: p 0.3723, r 0.3019, f1: 0.3062	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4877
test	acc: 0.5766	macro: p 0.3875, r 0.3103, f1: 0.3186	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5374
global_step: 14641, epoch: 67, loss: 0.317892
global_step: 14642, epoch: 67, loss: 0.208530
global_step: 14643, epoch: 67, loss: 0.229041
global_step: 14644, epoch: 67, loss: 0.302931
global_step: 14645, epoch: 67, loss: 0.179496
global_step: 14646, epoch: 67, loss: 0.275028
global_step: 14647, epoch: 67, loss: 0.224006
global_step: 14648, epoch: 67, loss: 0.304777
global_step: 14649, epoch: 67, loss: 0.209398
global_step: 14650, epoch: 67, loss: 0.275849
global_step: 14651, epoch: 67, loss: 0.294685
global_step: 14652, epoch: 67, loss: 0.258565
global_step: 14653, epoch: 67, loss: 0.256952
global_step: 14654, epoch: 67, loss: 0.233261
global_step: 14655, epoch: 67, loss: 0.297403
global_step: 14656, epoch: 67, loss: 0.348104
global_step: 14657, epoch: 67, loss: 0.285854
global_step: 14658, epoch: 67, loss: 0.218888
global_step: 14659, epoch: 67, loss: 0.187537
global_step: 14660, epoch: 67, loss: 0.256683
global_step: 14661, epoch: 67, loss: 0.292906
global_step: 14662, epoch: 67, loss: 0.279632
global_step: 14663, epoch: 67, loss: 0.218184
global_step: 14664, epoch: 67, loss: 0.249103
global_step: 14665, epoch: 67, loss: 0.233618
global_step: 14666, epoch: 67, loss: 0.263565
global_step: 14667, epoch: 67, loss: 0.256702
global_step: 14668, epoch: 67, loss: 0.230562
global_step: 14669, epoch: 67, loss: 0.218880
global_step: 14670, epoch: 67, loss: 0.198719
global_step: 14671, epoch: 67, loss: 0.261522
global_step: 14672, epoch: 67, loss: 0.311934
global_step: 14673, epoch: 67, loss: 0.318734
global_step: 14674, epoch: 67, loss: 0.350635
global_step: 14675, epoch: 67, loss: 0.328000
global_step: 14676, epoch: 67, loss: 0.259385
global_step: 14677, epoch: 67, loss: 0.309405
global_step: 14678, epoch: 67, loss: 0.303034
global_step: 14679, epoch: 67, loss: 0.385215
global_step: 14680, epoch: 67, loss: 0.375763
epoch: 67
train	acc: 0.9619	macro: p 0.9687, r 0.9468, f1: 0.9570	micro: p 0.9619, r 0.9619, f1 0.9619	weighted_f1:0.9619
dev	acc: 0.5167	macro: p 0.3201, r 0.2812, f1: 0.2722	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4597
test	acc: 0.5705	macro: p 0.3834, r 0.3044, f1: 0.3071	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5216
global_step: 14681, epoch: 68, loss: 0.350734
global_step: 14682, epoch: 68, loss: 0.305984
global_step: 14683, epoch: 68, loss: 0.219290
global_step: 14684, epoch: 68, loss: 0.241583
global_step: 14685, epoch: 68, loss: 0.137948
global_step: 14686, epoch: 68, loss: 0.270636
global_step: 14687, epoch: 68, loss: 0.170072
global_step: 14688, epoch: 68, loss: 0.207391
global_step: 14689, epoch: 68, loss: 0.272324
global_step: 14690, epoch: 68, loss: 0.249414
global_step: 14691, epoch: 68, loss: 0.262626
global_step: 14692, epoch: 68, loss: 0.248961
global_step: 14693, epoch: 68, loss: 0.211950
global_step: 14694, epoch: 68, loss: 0.256295
global_step: 14695, epoch: 68, loss: 0.316955
global_step: 14696, epoch: 68, loss: 0.251404
global_step: 14697, epoch: 68, loss: 0.192988
global_step: 14698, epoch: 68, loss: 0.238814
global_step: 14699, epoch: 68, loss: 0.288812
global_step: 14700, epoch: 68, loss: 0.174129
global_step: 14701, epoch: 68, loss: 0.243468
global_step: 14702, epoch: 68, loss: 0.305722
global_step: 14703, epoch: 68, loss: 0.221359
global_step: 14704, epoch: 68, loss: 0.344668
global_step: 14705, epoch: 68, loss: 0.227231
global_step: 14706, epoch: 68, loss: 0.272807
global_step: 14707, epoch: 68, loss: 0.242693
global_step: 14708, epoch: 68, loss: 0.190306
global_step: 14709, epoch: 68, loss: 0.287631
global_step: 14710, epoch: 68, loss: 0.195540
global_step: 14711, epoch: 68, loss: 0.248738
global_step: 14712, epoch: 68, loss: 0.231414
global_step: 14713, epoch: 68, loss: 0.296162
global_step: 14714, epoch: 68, loss: 0.273429
global_step: 14715, epoch: 68, loss: 0.250216
global_step: 14716, epoch: 68, loss: 0.229364
global_step: 14717, epoch: 68, loss: 0.247885
global_step: 14718, epoch: 68, loss: 0.316888
global_step: 14719, epoch: 68, loss: 0.313914
global_step: 14720, epoch: 68, loss: 1.213337
epoch: 68
train	acc: 0.9657	macro: p 0.9669, r 0.9537, f1: 0.9600	micro: p 0.9657, r 0.9657, f1 0.9657	weighted_f1:0.9657
dev	acc: 0.5239	macro: p 0.3774, r 0.3092, f1: 0.3183	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4860
test	acc: 0.5766	macro: p 0.3833, r 0.3191, f1: 0.3306	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5435
global_step: 14721, epoch: 69, loss: 0.263789
global_step: 14722, epoch: 69, loss: 0.197378
global_step: 14723, epoch: 69, loss: 0.241948
global_step: 14724, epoch: 69, loss: 0.328944
global_step: 14725, epoch: 69, loss: 0.254162
global_step: 14726, epoch: 69, loss: 0.223756
global_step: 14727, epoch: 69, loss: 0.217022
global_step: 14728, epoch: 69, loss: 0.227979
global_step: 14729, epoch: 69, loss: 0.174975
global_step: 14730, epoch: 69, loss: 0.236376
global_step: 14731, epoch: 69, loss: 0.185280
global_step: 14732, epoch: 69, loss: 0.267053
global_step: 14733, epoch: 69, loss: 0.306105
global_step: 14734, epoch: 69, loss: 0.212095
global_step: 14735, epoch: 69, loss: 0.188357
global_step: 14736, epoch: 69, loss: 0.208941
global_step: 14737, epoch: 69, loss: 0.176596
global_step: 14738, epoch: 69, loss: 0.281675
global_step: 14739, epoch: 69, loss: 0.338007
global_step: 14740, epoch: 69, loss: 0.291725
global_step: 14741, epoch: 69, loss: 0.223130
global_step: 14742, epoch: 69, loss: 0.294172
global_step: 14743, epoch: 69, loss: 0.153174
global_step: 14744, epoch: 69, loss: 0.278952
global_step: 14745, epoch: 69, loss: 0.272056
global_step: 14746, epoch: 69, loss: 0.360790
global_step: 14747, epoch: 69, loss: 0.293453
global_step: 14748, epoch: 69, loss: 0.220258
global_step: 14749, epoch: 69, loss: 0.206049
global_step: 14750, epoch: 69, loss: 0.280658
global_step: 14751, epoch: 69, loss: 0.222142
global_step: 14752, epoch: 69, loss: 0.262963
global_step: 14753, epoch: 69, loss: 0.221529
global_step: 14754, epoch: 69, loss: 0.162357
global_step: 14755, epoch: 69, loss: 0.302100
global_step: 14756, epoch: 69, loss: 0.229229
global_step: 14757, epoch: 69, loss: 0.267124
global_step: 14758, epoch: 69, loss: 0.266344
global_step: 14759, epoch: 69, loss: 0.273655
global_step: 14760, epoch: 69, loss: 0.329893
epoch: 69
train	acc: 0.9635	macro: p 0.9696, r 0.9487, f1: 0.9587	micro: p 0.9635, r 0.9635, f1 0.9635	weighted_f1:0.9633
dev	acc: 0.5320	macro: p 0.3836, r 0.2950, f1: 0.3067	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4825
test	acc: 0.5789	macro: p 0.3881, r 0.3021, f1: 0.3185	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5355
global_step: 14761, epoch: 70, loss: 0.232200
global_step: 14762, epoch: 70, loss: 0.173181
global_step: 14763, epoch: 70, loss: 0.242738
global_step: 14764, epoch: 70, loss: 0.282664
global_step: 14765, epoch: 70, loss: 0.218162
global_step: 14766, epoch: 70, loss: 0.248361
global_step: 14767, epoch: 70, loss: 0.292889
global_step: 14768, epoch: 70, loss: 0.210392
global_step: 14769, epoch: 70, loss: 0.244867
global_step: 14770, epoch: 70, loss: 0.226705
global_step: 14771, epoch: 70, loss: 0.265189
global_step: 14772, epoch: 70, loss: 0.208415
global_step: 14773, epoch: 70, loss: 0.297252
global_step: 14774, epoch: 70, loss: 0.303802
global_step: 14775, epoch: 70, loss: 0.212009
global_step: 14776, epoch: 70, loss: 0.241027
global_step: 14777, epoch: 70, loss: 0.214335
global_step: 14778, epoch: 70, loss: 0.234211
global_step: 14779, epoch: 70, loss: 0.231341
global_step: 14780, epoch: 70, loss: 0.263821
global_step: 14781, epoch: 70, loss: 0.220545
global_step: 14782, epoch: 70, loss: 0.218311
global_step: 14783, epoch: 70, loss: 0.236592
global_step: 14784, epoch: 70, loss: 0.238197
global_step: 14785, epoch: 70, loss: 0.220421
global_step: 14786, epoch: 70, loss: 0.230762
global_step: 14787, epoch: 70, loss: 0.281752
global_step: 14788, epoch: 70, loss: 0.229767
global_step: 14789, epoch: 70, loss: 0.288268
global_step: 14790, epoch: 70, loss: 0.281568
global_step: 14791, epoch: 70, loss: 0.271058
global_step: 14792, epoch: 70, loss: 0.268191
global_step: 14793, epoch: 70, loss: 0.274631
global_step: 14794, epoch: 70, loss: 0.288940
global_step: 14795, epoch: 70, loss: 0.249538
global_step: 14796, epoch: 70, loss: 0.252796
global_step: 14797, epoch: 70, loss: 0.293516
global_step: 14798, epoch: 70, loss: 0.219208
global_step: 14799, epoch: 70, loss: 0.258364
global_step: 14800, epoch: 70, loss: 0.193252
epoch: 70
train	acc: 0.9670	macro: p 0.9723, r 0.9527, f1: 0.9621	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5302	macro: p 0.4129, r 0.3058, f1: 0.3156	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4785
test	acc: 0.5797	macro: p 0.3958, r 0.3065, f1: 0.3182	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5315
global_step: 14801, epoch: 71, loss: 0.239438
global_step: 14802, epoch: 71, loss: 0.214121
global_step: 14803, epoch: 71, loss: 0.194698
global_step: 14804, epoch: 71, loss: 0.193758
global_step: 14805, epoch: 71, loss: 0.194545
global_step: 14806, epoch: 71, loss: 0.253818
global_step: 14807, epoch: 71, loss: 0.176812
global_step: 14808, epoch: 71, loss: 0.283157
global_step: 14809, epoch: 71, loss: 0.294157
global_step: 14810, epoch: 71, loss: 0.304205
global_step: 14811, epoch: 71, loss: 0.241496
global_step: 14812, epoch: 71, loss: 0.212916
global_step: 14813, epoch: 71, loss: 0.240454
global_step: 14814, epoch: 71, loss: 0.256719
global_step: 14815, epoch: 71, loss: 0.195549
global_step: 14816, epoch: 71, loss: 0.234616
global_step: 14817, epoch: 71, loss: 0.266193
global_step: 14818, epoch: 71, loss: 0.242957
global_step: 14819, epoch: 71, loss: 0.207655
global_step: 14820, epoch: 71, loss: 0.265007
global_step: 14821, epoch: 71, loss: 0.208165
global_step: 14822, epoch: 71, loss: 0.288740
global_step: 14823, epoch: 71, loss: 0.285193
global_step: 14824, epoch: 71, loss: 0.219688
global_step: 14825, epoch: 71, loss: 0.251741
global_step: 14826, epoch: 71, loss: 0.256837
global_step: 14827, epoch: 71, loss: 0.232174
global_step: 14828, epoch: 71, loss: 0.225219
global_step: 14829, epoch: 71, loss: 0.279136
global_step: 14830, epoch: 71, loss: 0.189283
global_step: 14831, epoch: 71, loss: 0.202512
global_step: 14832, epoch: 71, loss: 0.273368
global_step: 14833, epoch: 71, loss: 0.243034
global_step: 14834, epoch: 71, loss: 0.192744
global_step: 14835, epoch: 71, loss: 0.322533
global_step: 14836, epoch: 71, loss: 0.280576
global_step: 14837, epoch: 71, loss: 0.323676
global_step: 14838, epoch: 71, loss: 0.231280
global_step: 14839, epoch: 71, loss: 0.236685
global_step: 14840, epoch: 71, loss: 0.616616
epoch: 71
train	acc: 0.9686	macro: p 0.9724, r 0.9563, f1: 0.9640	micro: p 0.9686, r 0.9686, f1 0.9686	weighted_f1:0.9686
dev	acc: 0.5257	macro: p 0.3531, r 0.2974, f1: 0.2990	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4833
test	acc: 0.5785	macro: p 0.4200, r 0.3160, f1: 0.3281	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5399
global_step: 14841, epoch: 72, loss: 0.284603
global_step: 14842, epoch: 72, loss: 0.200251
global_step: 14843, epoch: 72, loss: 0.202624
global_step: 14844, epoch: 72, loss: 0.248408
global_step: 14845, epoch: 72, loss: 0.283477
global_step: 14846, epoch: 72, loss: 0.262539
global_step: 14847, epoch: 72, loss: 0.226001
global_step: 14848, epoch: 72, loss: 0.256345
global_step: 14849, epoch: 72, loss: 0.235616
global_step: 14850, epoch: 72, loss: 0.207668
global_step: 14851, epoch: 72, loss: 0.205756
global_step: 14852, epoch: 72, loss: 0.270897
global_step: 14853, epoch: 72, loss: 0.272355
global_step: 14854, epoch: 72, loss: 0.213864
global_step: 14855, epoch: 72, loss: 0.221091
global_step: 14856, epoch: 72, loss: 0.309688
global_step: 14857, epoch: 72, loss: 0.243669
global_step: 14858, epoch: 72, loss: 0.349273
global_step: 14859, epoch: 72, loss: 0.184348
global_step: 14860, epoch: 72, loss: 0.356894
global_step: 14861, epoch: 72, loss: 0.260469
global_step: 14862, epoch: 72, loss: 0.302498
global_step: 14863, epoch: 72, loss: 0.235006
global_step: 14864, epoch: 72, loss: 0.305433
global_step: 14865, epoch: 72, loss: 0.243965
global_step: 14866, epoch: 72, loss: 0.223065
global_step: 14867, epoch: 72, loss: 0.261023
global_step: 14868, epoch: 72, loss: 0.163294
global_step: 14869, epoch: 72, loss: 0.212427
global_step: 14870, epoch: 72, loss: 0.175397
global_step: 14871, epoch: 72, loss: 0.289920
global_step: 14872, epoch: 72, loss: 0.271221
global_step: 14873, epoch: 72, loss: 0.228659
global_step: 14874, epoch: 72, loss: 0.288303
global_step: 14875, epoch: 72, loss: 0.270129
global_step: 14876, epoch: 72, loss: 0.310008
global_step: 14877, epoch: 72, loss: 0.309449
global_step: 14878, epoch: 72, loss: 0.270276
global_step: 14879, epoch: 72, loss: 0.302008
global_step: 14880, epoch: 72, loss: 0.450675
epoch: 72
train	acc: 0.9625	macro: p 0.9716, r 0.9440, f1: 0.9569	micro: p 0.9625, r 0.9625, f1 0.9625	weighted_f1:0.9625
dev	acc: 0.5257	macro: p 0.3826, r 0.3012, f1: 0.2964	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4763
test	acc: 0.5651	macro: p 0.4015, r 0.3037, f1: 0.3038	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.5219
global_step: 14881, epoch: 73, loss: 0.328635
global_step: 14882, epoch: 73, loss: 0.295163
global_step: 14883, epoch: 73, loss: 0.286106
global_step: 14884, epoch: 73, loss: 0.204195
global_step: 14885, epoch: 73, loss: 0.278998
global_step: 14886, epoch: 73, loss: 0.289294
global_step: 14887, epoch: 73, loss: 0.284662
global_step: 14888, epoch: 73, loss: 0.254486
global_step: 14889, epoch: 73, loss: 0.265951
global_step: 14890, epoch: 73, loss: 0.237010
global_step: 14891, epoch: 73, loss: 0.215783
global_step: 14892, epoch: 73, loss: 0.287073
global_step: 14893, epoch: 73, loss: 0.208805
global_step: 14894, epoch: 73, loss: 0.319703
global_step: 14895, epoch: 73, loss: 0.312012
global_step: 14896, epoch: 73, loss: 0.296995
global_step: 14897, epoch: 73, loss: 0.365915
global_step: 14898, epoch: 73, loss: 0.270326
global_step: 14899, epoch: 73, loss: 0.294369
global_step: 14900, epoch: 73, loss: 0.261886
global_step: 14901, epoch: 73, loss: 0.283791
global_step: 14902, epoch: 73, loss: 0.186334
global_step: 14903, epoch: 73, loss: 0.287798
global_step: 14904, epoch: 73, loss: 0.215429
global_step: 14905, epoch: 73, loss: 0.276730
global_step: 14906, epoch: 73, loss: 0.192812
global_step: 14907, epoch: 73, loss: 0.276950
global_step: 14908, epoch: 73, loss: 0.251781
global_step: 14909, epoch: 73, loss: 0.193573
global_step: 14910, epoch: 73, loss: 0.253613
global_step: 14911, epoch: 73, loss: 0.309029
global_step: 14912, epoch: 73, loss: 0.232767
global_step: 14913, epoch: 73, loss: 0.265268
global_step: 14914, epoch: 73, loss: 0.230704
global_step: 14915, epoch: 73, loss: 0.204592
global_step: 14916, epoch: 73, loss: 0.258398
global_step: 14917, epoch: 73, loss: 0.294894
global_step: 14918, epoch: 73, loss: 0.226081
global_step: 14919, epoch: 73, loss: 0.272204
global_step: 14920, epoch: 73, loss: 0.419472
epoch: 73
train	acc: 0.9670	macro: p 0.9736, r 0.9541, f1: 0.9636	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9669
dev	acc: 0.5176	macro: p 0.3571, r 0.2911, f1: 0.2958	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4654
test	acc: 0.5713	macro: p 0.3601, r 0.3002, f1: 0.3084	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5217
global_step: 14921, epoch: 74, loss: 0.247666
global_step: 14922, epoch: 74, loss: 0.257639
global_step: 14923, epoch: 74, loss: 0.223982
global_step: 14924, epoch: 74, loss: 0.290819
global_step: 14925, epoch: 74, loss: 0.287441
global_step: 14926, epoch: 74, loss: 0.182572
global_step: 14927, epoch: 74, loss: 0.250774
global_step: 14928, epoch: 74, loss: 0.294365
global_step: 14929, epoch: 74, loss: 0.245552
global_step: 14930, epoch: 74, loss: 0.292676
global_step: 14931, epoch: 74, loss: 0.246486
global_step: 14932, epoch: 74, loss: 0.223015
global_step: 14933, epoch: 74, loss: 0.342983
global_step: 14934, epoch: 74, loss: 0.278742
global_step: 14935, epoch: 74, loss: 0.253060
global_step: 14936, epoch: 74, loss: 0.248721
global_step: 14937, epoch: 74, loss: 0.243396
global_step: 14938, epoch: 74, loss: 0.303338
global_step: 14939, epoch: 74, loss: 0.348128
global_step: 14940, epoch: 74, loss: 0.356044
global_step: 14941, epoch: 74, loss: 0.223906
global_step: 14942, epoch: 74, loss: 0.211089
global_step: 14943, epoch: 74, loss: 0.183617
global_step: 14944, epoch: 74, loss: 0.286357
global_step: 14945, epoch: 74, loss: 0.211747
global_step: 14946, epoch: 74, loss: 0.190104
global_step: 14947, epoch: 74, loss: 0.207261
global_step: 14948, epoch: 74, loss: 0.254969
global_step: 14949, epoch: 74, loss: 0.215636
global_step: 14950, epoch: 74, loss: 0.185181
global_step: 14951, epoch: 74, loss: 0.231582
global_step: 14952, epoch: 74, loss: 0.177273
global_step: 14953, epoch: 74, loss: 0.246271
global_step: 14954, epoch: 74, loss: 0.259043
global_step: 14955, epoch: 74, loss: 0.218573
global_step: 14956, epoch: 74, loss: 0.202478
global_step: 14957, epoch: 74, loss: 0.258715
global_step: 14958, epoch: 74, loss: 0.266690
global_step: 14959, epoch: 74, loss: 0.348655
global_step: 14960, epoch: 74, loss: 0.487768
epoch: 74
train	acc: 0.9679	macro: p 0.9706, r 0.9571, f1: 0.9636	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5059	macro: p 0.3197, r 0.3005, f1: 0.3015	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4796
test	acc: 0.5475	macro: p 0.3764, r 0.3206, f1: 0.3265	micro: p 0.5475, r 0.5475, f1 0.5475	weighted_f1:0.5291
global_step: 14961, epoch: 75, loss: 0.353119
global_step: 14962, epoch: 75, loss: 0.212327
global_step: 14963, epoch: 75, loss: 0.182733
global_step: 14964, epoch: 75, loss: 0.194569
global_step: 14965, epoch: 75, loss: 0.230165
global_step: 14966, epoch: 75, loss: 0.174048
global_step: 14967, epoch: 75, loss: 0.236463
global_step: 14968, epoch: 75, loss: 0.214807
global_step: 14969, epoch: 75, loss: 0.284970
global_step: 14970, epoch: 75, loss: 0.254207
global_step: 14971, epoch: 75, loss: 0.229802
global_step: 14972, epoch: 75, loss: 0.238802
global_step: 14973, epoch: 75, loss: 0.235792
global_step: 14974, epoch: 75, loss: 0.206938
global_step: 14975, epoch: 75, loss: 0.245405
global_step: 14976, epoch: 75, loss: 0.218285
global_step: 14977, epoch: 75, loss: 0.252002
global_step: 14978, epoch: 75, loss: 0.241228
global_step: 14979, epoch: 75, loss: 0.165027
global_step: 14980, epoch: 75, loss: 0.193812
global_step: 14981, epoch: 75, loss: 0.195731
global_step: 14982, epoch: 75, loss: 0.231303
global_step: 14983, epoch: 75, loss: 0.225206
global_step: 14984, epoch: 75, loss: 0.188001
global_step: 14985, epoch: 75, loss: 0.253603
global_step: 14986, epoch: 75, loss: 0.206226
global_step: 14987, epoch: 75, loss: 0.232052
global_step: 14988, epoch: 75, loss: 0.316978
global_step: 14989, epoch: 75, loss: 0.232924
global_step: 14990, epoch: 75, loss: 0.262727
global_step: 14991, epoch: 75, loss: 0.230555
global_step: 14992, epoch: 75, loss: 0.211247
global_step: 14993, epoch: 75, loss: 0.203328
global_step: 14994, epoch: 75, loss: 0.272529
global_step: 14995, epoch: 75, loss: 0.221829
global_step: 14996, epoch: 75, loss: 0.301906
global_step: 14997, epoch: 75, loss: 0.246011
global_step: 14998, epoch: 75, loss: 0.226973
global_step: 14999, epoch: 75, loss: 0.226193
global_step: 15000, epoch: 75, loss: 0.098844
epoch: 75
train	acc: 0.9679	macro: p 0.9729, r 0.9562, f1: 0.9643	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5185	macro: p 0.3379, r 0.2912, f1: 0.2880	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4733
test	acc: 0.5747	macro: p 0.4098, r 0.3143, f1: 0.3217	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5350
global_step: 15001, epoch: 76, loss: 0.251218
global_step: 15002, epoch: 76, loss: 0.207912
global_step: 15003, epoch: 76, loss: 0.259446
global_step: 15004, epoch: 76, loss: 0.225556
global_step: 15005, epoch: 76, loss: 0.209134
global_step: 15006, epoch: 76, loss: 0.200072
global_step: 15007, epoch: 76, loss: 0.153347
global_step: 15008, epoch: 76, loss: 0.239927
global_step: 15009, epoch: 76, loss: 0.293721
global_step: 15010, epoch: 76, loss: 0.317649
global_step: 15011, epoch: 76, loss: 0.337985
global_step: 15012, epoch: 76, loss: 0.188706
global_step: 15013, epoch: 76, loss: 0.165772
global_step: 15014, epoch: 76, loss: 0.190503
global_step: 15015, epoch: 76, loss: 0.188027
global_step: 15016, epoch: 76, loss: 0.222466
global_step: 15017, epoch: 76, loss: 0.326731
global_step: 15018, epoch: 76, loss: 0.271230
global_step: 15019, epoch: 76, loss: 0.231895
global_step: 15020, epoch: 76, loss: 0.224935
global_step: 15021, epoch: 76, loss: 0.255705
global_step: 15022, epoch: 76, loss: 0.207877
global_step: 15023, epoch: 76, loss: 0.211752
global_step: 15024, epoch: 76, loss: 0.193091
global_step: 15025, epoch: 76, loss: 0.270699
global_step: 15026, epoch: 76, loss: 0.227842
global_step: 15027, epoch: 76, loss: 0.285042
global_step: 15028, epoch: 76, loss: 0.253390
global_step: 15029, epoch: 76, loss: 0.240109
global_step: 15030, epoch: 76, loss: 0.234093
global_step: 15031, epoch: 76, loss: 0.244169
global_step: 15032, epoch: 76, loss: 0.205775
global_step: 15033, epoch: 76, loss: 0.226969
global_step: 15034, epoch: 76, loss: 0.255744
global_step: 15035, epoch: 76, loss: 0.274136
global_step: 15036, epoch: 76, loss: 0.200727
global_step: 15037, epoch: 76, loss: 0.253849
global_step: 15038, epoch: 76, loss: 0.197911
global_step: 15039, epoch: 76, loss: 0.208533
global_step: 15040, epoch: 76, loss: 0.309379
epoch: 76
train	acc: 0.9677	macro: p 0.9707, r 0.9554, f1: 0.9628	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5239	macro: p 0.3289, r 0.2910, f1: 0.2909	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4753
test	acc: 0.5835	macro: p 0.3983, r 0.3186, f1: 0.3313	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5427
global_step: 15041, epoch: 77, loss: 0.179898
global_step: 15042, epoch: 77, loss: 0.252814
global_step: 15043, epoch: 77, loss: 0.227973
global_step: 15044, epoch: 77, loss: 0.239615
global_step: 15045, epoch: 77, loss: 0.320191
global_step: 15046, epoch: 77, loss: 0.350625
global_step: 15047, epoch: 77, loss: 0.217842
global_step: 15048, epoch: 77, loss: 0.200607
global_step: 15049, epoch: 77, loss: 0.218254
global_step: 15050, epoch: 77, loss: 0.283141
global_step: 15051, epoch: 77, loss: 0.229997
global_step: 15052, epoch: 77, loss: 0.255724
global_step: 15053, epoch: 77, loss: 0.232460
global_step: 15054, epoch: 77, loss: 0.264112
global_step: 15055, epoch: 77, loss: 0.163714
global_step: 15056, epoch: 77, loss: 0.156843
global_step: 15057, epoch: 77, loss: 0.155171
global_step: 15058, epoch: 77, loss: 0.340364
global_step: 15059, epoch: 77, loss: 0.309385
global_step: 15060, epoch: 77, loss: 0.216098
global_step: 15061, epoch: 77, loss: 0.212440
global_step: 15062, epoch: 77, loss: 0.260133
global_step: 15063, epoch: 77, loss: 0.264218
global_step: 15064, epoch: 77, loss: 0.230369
global_step: 15065, epoch: 77, loss: 0.196640
global_step: 15066, epoch: 77, loss: 0.248780
global_step: 15067, epoch: 77, loss: 0.226578
global_step: 15068, epoch: 77, loss: 0.203605
global_step: 15069, epoch: 77, loss: 0.250567
global_step: 15070, epoch: 77, loss: 0.227915
global_step: 15071, epoch: 77, loss: 0.234338
global_step: 15072, epoch: 77, loss: 0.282214
global_step: 15073, epoch: 77, loss: 0.250991
global_step: 15074, epoch: 77, loss: 0.302751
global_step: 15075, epoch: 77, loss: 0.189823
global_step: 15076, epoch: 77, loss: 0.305800
global_step: 15077, epoch: 77, loss: 0.193183
global_step: 15078, epoch: 77, loss: 0.208308
global_step: 15079, epoch: 77, loss: 0.273616
global_step: 15080, epoch: 77, loss: 0.001891
epoch: 77
train	acc: 0.9684	macro: p 0.9722, r 0.9564, f1: 0.9640	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5221	macro: p 0.3265, r 0.2991, f1: 0.2959	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4810
test	acc: 0.5663	macro: p 0.3692, r 0.3171, f1: 0.3210	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5337
global_step: 15081, epoch: 78, loss: 0.164901
global_step: 15082, epoch: 78, loss: 0.230449
global_step: 15083, epoch: 78, loss: 0.303186
global_step: 15084, epoch: 78, loss: 0.203502
global_step: 15085, epoch: 78, loss: 0.229214
global_step: 15086, epoch: 78, loss: 0.169178
global_step: 15087, epoch: 78, loss: 0.222695
global_step: 15088, epoch: 78, loss: 0.211232
global_step: 15089, epoch: 78, loss: 0.190629
global_step: 15090, epoch: 78, loss: 0.179299
global_step: 15091, epoch: 78, loss: 0.250636
global_step: 15092, epoch: 78, loss: 0.273903
global_step: 15093, epoch: 78, loss: 0.302901
global_step: 15094, epoch: 78, loss: 0.228512
global_step: 15095, epoch: 78, loss: 0.208932
global_step: 15096, epoch: 78, loss: 0.241606
global_step: 15097, epoch: 78, loss: 0.274646
global_step: 15098, epoch: 78, loss: 0.318843
global_step: 15099, epoch: 78, loss: 0.277813
global_step: 15100, epoch: 78, loss: 0.224428
global_step: 15101, epoch: 78, loss: 0.240355
global_step: 15102, epoch: 78, loss: 0.232672
global_step: 15103, epoch: 78, loss: 0.323841
global_step: 15104, epoch: 78, loss: 0.207325
global_step: 15105, epoch: 78, loss: 0.180360
global_step: 15106, epoch: 78, loss: 0.220209
global_step: 15107, epoch: 78, loss: 0.303305
global_step: 15108, epoch: 78, loss: 0.270101
global_step: 15109, epoch: 78, loss: 0.197408
global_step: 15110, epoch: 78, loss: 0.233265
global_step: 15111, epoch: 78, loss: 0.211271
global_step: 15112, epoch: 78, loss: 0.232705
global_step: 15113, epoch: 78, loss: 0.273778
global_step: 15114, epoch: 78, loss: 0.287417
global_step: 15115, epoch: 78, loss: 0.228903
global_step: 15116, epoch: 78, loss: 0.312281
global_step: 15117, epoch: 78, loss: 0.227208
global_step: 15118, epoch: 78, loss: 0.262492
global_step: 15119, epoch: 78, loss: 0.294640
global_step: 15120, epoch: 78, loss: 0.059339
epoch: 78
train	acc: 0.9685	macro: p 0.9707, r 0.9560, f1: 0.9630	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5185	macro: p 0.3286, r 0.3010, f1: 0.3001	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4801
test	acc: 0.5720	macro: p 0.3725, r 0.3183, f1: 0.3225	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5374
global_step: 15121, epoch: 79, loss: 0.258287
global_step: 15122, epoch: 79, loss: 0.178895
global_step: 15123, epoch: 79, loss: 0.237628
global_step: 15124, epoch: 79, loss: 0.170221
global_step: 15125, epoch: 79, loss: 0.228321
global_step: 15126, epoch: 79, loss: 0.209732
global_step: 15127, epoch: 79, loss: 0.173620
global_step: 15128, epoch: 79, loss: 0.290968
global_step: 15129, epoch: 79, loss: 0.198088
global_step: 15130, epoch: 79, loss: 0.235823
global_step: 15131, epoch: 79, loss: 0.297142
global_step: 15132, epoch: 79, loss: 0.252465
global_step: 15133, epoch: 79, loss: 0.191678
global_step: 15134, epoch: 79, loss: 0.187618
global_step: 15135, epoch: 79, loss: 0.270274
global_step: 15136, epoch: 79, loss: 0.250413
global_step: 15137, epoch: 79, loss: 0.268895
global_step: 15138, epoch: 79, loss: 0.213205
global_step: 15139, epoch: 79, loss: 0.288330
global_step: 15140, epoch: 79, loss: 0.201747
global_step: 15141, epoch: 79, loss: 0.293353
global_step: 15142, epoch: 79, loss: 0.222545
global_step: 15143, epoch: 79, loss: 0.193355
global_step: 15144, epoch: 79, loss: 0.265263
global_step: 15145, epoch: 79, loss: 0.239636
global_step: 15146, epoch: 79, loss: 0.236071
global_step: 15147, epoch: 79, loss: 0.157423
global_step: 15148, epoch: 79, loss: 0.213165
global_step: 15149, epoch: 79, loss: 0.172853
global_step: 15150, epoch: 79, loss: 0.194657
global_step: 15151, epoch: 79, loss: 0.248488
global_step: 15152, epoch: 79, loss: 0.257013
global_step: 15153, epoch: 79, loss: 0.299383
global_step: 15154, epoch: 79, loss: 0.170373
global_step: 15155, epoch: 79, loss: 0.271782
global_step: 15156, epoch: 79, loss: 0.299588
global_step: 15157, epoch: 79, loss: 0.357063
global_step: 15158, epoch: 79, loss: 0.266508
global_step: 15159, epoch: 79, loss: 0.334612
global_step: 15160, epoch: 79, loss: 0.091613
epoch: 79
train	acc: 0.9690	macro: p 0.9724, r 0.9570, f1: 0.9645	micro: p 0.9690, r 0.9690, f1 0.9690	weighted_f1:0.9690
dev	acc: 0.5338	macro: p 0.3543, r 0.3078, f1: 0.3086	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4935
test	acc: 0.5720	macro: p 0.3992, r 0.3177, f1: 0.3241	micro: p 0.5720, r 0.5720, f1 0.5720	weighted_f1:0.5379
global_step: 15161, epoch: 80, loss: 0.258450
global_step: 15162, epoch: 80, loss: 0.160264
global_step: 15163, epoch: 80, loss: 0.263665
global_step: 15164, epoch: 80, loss: 0.220380
global_step: 15165, epoch: 80, loss: 0.244657
global_step: 15166, epoch: 80, loss: 0.326669
global_step: 15167, epoch: 80, loss: 0.236083
global_step: 15168, epoch: 80, loss: 0.228321
global_step: 15169, epoch: 80, loss: 0.155984
global_step: 15170, epoch: 80, loss: 0.242925
global_step: 15171, epoch: 80, loss: 0.272907
global_step: 15172, epoch: 80, loss: 0.253309
global_step: 15173, epoch: 80, loss: 0.170276
global_step: 15174, epoch: 80, loss: 0.214911
global_step: 15175, epoch: 80, loss: 0.240720
global_step: 15176, epoch: 80, loss: 0.234753
global_step: 15177, epoch: 80, loss: 0.246800
global_step: 15178, epoch: 80, loss: 0.195960
global_step: 15179, epoch: 80, loss: 0.260578
global_step: 15180, epoch: 80, loss: 0.257615
global_step: 15181, epoch: 80, loss: 0.288732
global_step: 15182, epoch: 80, loss: 0.264322
global_step: 15183, epoch: 80, loss: 0.212347
global_step: 15184, epoch: 80, loss: 0.191756
global_step: 15185, epoch: 80, loss: 0.224119
global_step: 15186, epoch: 80, loss: 0.204008
global_step: 15187, epoch: 80, loss: 0.226355
global_step: 15188, epoch: 80, loss: 0.271992
global_step: 15189, epoch: 80, loss: 0.335508
global_step: 15190, epoch: 80, loss: 0.277222
global_step: 15191, epoch: 80, loss: 0.252461
global_step: 15192, epoch: 80, loss: 0.232583
global_step: 15193, epoch: 80, loss: 0.272539
global_step: 15194, epoch: 80, loss: 0.296686
global_step: 15195, epoch: 80, loss: 0.241782
global_step: 15196, epoch: 80, loss: 0.215964
global_step: 15197, epoch: 80, loss: 0.256753
global_step: 15198, epoch: 80, loss: 0.217933
global_step: 15199, epoch: 80, loss: 0.204419
global_step: 15200, epoch: 80, loss: 0.015599
epoch: 80
train	acc: 0.9676	macro: p 0.9713, r 0.9569, f1: 0.9638	micro: p 0.9676, r 0.9676, f1 0.9676	weighted_f1:0.9676
dev	acc: 0.5239	macro: p 0.3810, r 0.3041, f1: 0.3073	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4819
test	acc: 0.5686	macro: p 0.3751, r 0.3096, f1: 0.3147	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5316
global_step: 15201, epoch: 81, loss: 0.244943
global_step: 15202, epoch: 81, loss: 0.199230
global_step: 15203, epoch: 81, loss: 0.200580
global_step: 15204, epoch: 81, loss: 0.177194
global_step: 15205, epoch: 81, loss: 0.229354
global_step: 15206, epoch: 81, loss: 0.254135
global_step: 15207, epoch: 81, loss: 0.226664
global_step: 15208, epoch: 81, loss: 0.256930
global_step: 15209, epoch: 81, loss: 0.237627
global_step: 15210, epoch: 81, loss: 0.228159
global_step: 15211, epoch: 81, loss: 0.238584
global_step: 15212, epoch: 81, loss: 0.290543
global_step: 15213, epoch: 81, loss: 0.221100
global_step: 15214, epoch: 81, loss: 0.187365
global_step: 15215, epoch: 81, loss: 0.209738
global_step: 15216, epoch: 81, loss: 0.209026
global_step: 15217, epoch: 81, loss: 0.198691
global_step: 15218, epoch: 81, loss: 0.225261
global_step: 15219, epoch: 81, loss: 0.236525
global_step: 15220, epoch: 81, loss: 0.224274
global_step: 15221, epoch: 81, loss: 0.193741
global_step: 15222, epoch: 81, loss: 0.222089
global_step: 15223, epoch: 81, loss: 0.188268
global_step: 15224, epoch: 81, loss: 0.232813
global_step: 15225, epoch: 81, loss: 0.219238
global_step: 15226, epoch: 81, loss: 0.292269
global_step: 15227, epoch: 81, loss: 0.310731
global_step: 15228, epoch: 81, loss: 0.258035
global_step: 15229, epoch: 81, loss: 0.184251
global_step: 15230, epoch: 81, loss: 0.289330
global_step: 15231, epoch: 81, loss: 0.175358
global_step: 15232, epoch: 81, loss: 0.215309
global_step: 15233, epoch: 81, loss: 0.222076
global_step: 15234, epoch: 81, loss: 0.295729
global_step: 15235, epoch: 81, loss: 0.176912
global_step: 15236, epoch: 81, loss: 0.263077
global_step: 15237, epoch: 81, loss: 0.243938
global_step: 15238, epoch: 81, loss: 0.271824
global_step: 15239, epoch: 81, loss: 0.177275
global_step: 15240, epoch: 81, loss: 0.110082
epoch: 81
train	acc: 0.9685	macro: p 0.9706, r 0.9569, f1: 0.9634	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5176	macro: p 0.3289, r 0.2936, f1: 0.2862	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4700
test	acc: 0.5621	macro: p 0.3879, r 0.3153, f1: 0.3178	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.5233
global_step: 15241, epoch: 82, loss: 0.234862
global_step: 15242, epoch: 82, loss: 0.336424
global_step: 15243, epoch: 82, loss: 0.191801
global_step: 15244, epoch: 82, loss: 0.191550
global_step: 15245, epoch: 82, loss: 0.258460
global_step: 15246, epoch: 82, loss: 0.243261
global_step: 15247, epoch: 82, loss: 0.306173
global_step: 15248, epoch: 82, loss: 0.177570
global_step: 15249, epoch: 82, loss: 0.194337
global_step: 15250, epoch: 82, loss: 0.190517
global_step: 15251, epoch: 82, loss: 0.194316
global_step: 15252, epoch: 82, loss: 0.311293
global_step: 15253, epoch: 82, loss: 0.138760
global_step: 15254, epoch: 82, loss: 0.263969
global_step: 15255, epoch: 82, loss: 0.263365
global_step: 15256, epoch: 82, loss: 0.242495
global_step: 15257, epoch: 82, loss: 0.241324
global_step: 15258, epoch: 82, loss: 0.221218
global_step: 15259, epoch: 82, loss: 0.286967
global_step: 15260, epoch: 82, loss: 0.226263
global_step: 15261, epoch: 82, loss: 0.211046
global_step: 15262, epoch: 82, loss: 0.181207
global_step: 15263, epoch: 82, loss: 0.213031
global_step: 15264, epoch: 82, loss: 0.239320
global_step: 15265, epoch: 82, loss: 0.370470
global_step: 15266, epoch: 82, loss: 0.299639
global_step: 15267, epoch: 82, loss: 0.268140
global_step: 15268, epoch: 82, loss: 0.226352
global_step: 15269, epoch: 82, loss: 0.198886
global_step: 15270, epoch: 82, loss: 0.247962
global_step: 15271, epoch: 82, loss: 0.193955
global_step: 15272, epoch: 82, loss: 0.189143
global_step: 15273, epoch: 82, loss: 0.306458
global_step: 15274, epoch: 82, loss: 0.284736
global_step: 15275, epoch: 82, loss: 0.222539
global_step: 15276, epoch: 82, loss: 0.230652
global_step: 15277, epoch: 82, loss: 0.200554
global_step: 15278, epoch: 82, loss: 0.229608
global_step: 15279, epoch: 82, loss: 0.244971
global_step: 15280, epoch: 82, loss: 0.013467
epoch: 82
train	acc: 0.9695	macro: p 0.9734, r 0.9583, f1: 0.9657	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5212	macro: p 0.3712, r 0.3100, f1: 0.3183	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4845
test	acc: 0.5667	macro: p 0.3789, r 0.3136, f1: 0.3244	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5331
global_step: 15281, epoch: 83, loss: 0.235517
global_step: 15282, epoch: 83, loss: 0.203623
global_step: 15283, epoch: 83, loss: 0.255867
global_step: 15284, epoch: 83, loss: 0.198959
global_step: 15285, epoch: 83, loss: 0.197379
global_step: 15286, epoch: 83, loss: 0.208657
global_step: 15287, epoch: 83, loss: 0.172353
global_step: 15288, epoch: 83, loss: 0.237270
global_step: 15289, epoch: 83, loss: 0.198265
global_step: 15290, epoch: 83, loss: 0.166969
global_step: 15291, epoch: 83, loss: 0.167070
global_step: 15292, epoch: 83, loss: 0.254782
global_step: 15293, epoch: 83, loss: 0.204760
global_step: 15294, epoch: 83, loss: 0.178363
global_step: 15295, epoch: 83, loss: 0.192099
global_step: 15296, epoch: 83, loss: 0.191800
global_step: 15297, epoch: 83, loss: 0.256640
global_step: 15298, epoch: 83, loss: 0.236624
global_step: 15299, epoch: 83, loss: 0.157237
global_step: 15300, epoch: 83, loss: 0.185743
global_step: 15301, epoch: 83, loss: 0.240127
global_step: 15302, epoch: 83, loss: 0.261340
global_step: 15303, epoch: 83, loss: 0.308006
global_step: 15304, epoch: 83, loss: 0.227245
global_step: 15305, epoch: 83, loss: 0.281067
global_step: 15306, epoch: 83, loss: 0.263145
global_step: 15307, epoch: 83, loss: 0.266307
global_step: 15308, epoch: 83, loss: 0.288487
global_step: 15309, epoch: 83, loss: 0.173358
global_step: 15310, epoch: 83, loss: 0.175260
global_step: 15311, epoch: 83, loss: 0.266244
global_step: 15312, epoch: 83, loss: 0.183397
global_step: 15313, epoch: 83, loss: 0.242846
global_step: 15314, epoch: 83, loss: 0.237870
global_step: 15315, epoch: 83, loss: 0.209005
global_step: 15316, epoch: 83, loss: 0.179365
global_step: 15317, epoch: 83, loss: 0.171548
global_step: 15318, epoch: 83, loss: 0.289021
global_step: 15319, epoch: 83, loss: 0.265310
global_step: 15320, epoch: 83, loss: 0.041293
epoch: 83
train	acc: 0.9664	macro: p 0.9752, r 0.9512, f1: 0.9628	micro: p 0.9664, r 0.9664, f1 0.9664	weighted_f1:0.9663
dev	acc: 0.5266	macro: p 0.3781, r 0.3011, f1: 0.3081	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4781
test	acc: 0.5762	macro: p 0.3893, r 0.3057, f1: 0.3162	micro: p 0.5762, r 0.5762, f1 0.5762	weighted_f1:0.5334
global_step: 15321, epoch: 84, loss: 0.198731
global_step: 15322, epoch: 84, loss: 0.228980
global_step: 15323, epoch: 84, loss: 0.204444
global_step: 15324, epoch: 84, loss: 0.222798
global_step: 15325, epoch: 84, loss: 0.188222
global_step: 15326, epoch: 84, loss: 0.204079
global_step: 15327, epoch: 84, loss: 0.189012
global_step: 15328, epoch: 84, loss: 0.226893
global_step: 15329, epoch: 84, loss: 0.185854
global_step: 15330, epoch: 84, loss: 0.305635
global_step: 15331, epoch: 84, loss: 0.279103
global_step: 15332, epoch: 84, loss: 0.208159
global_step: 15333, epoch: 84, loss: 0.222773
global_step: 15334, epoch: 84, loss: 0.230219
global_step: 15335, epoch: 84, loss: 0.320523
global_step: 15336, epoch: 84, loss: 0.207466
global_step: 15337, epoch: 84, loss: 0.254505
global_step: 15338, epoch: 84, loss: 0.226350
global_step: 15339, epoch: 84, loss: 0.209691
global_step: 15340, epoch: 84, loss: 0.342569
global_step: 15341, epoch: 84, loss: 0.223965
global_step: 15342, epoch: 84, loss: 0.269407
global_step: 15343, epoch: 84, loss: 0.299755
global_step: 15344, epoch: 84, loss: 0.170582
global_step: 15345, epoch: 84, loss: 0.191428
global_step: 15346, epoch: 84, loss: 0.224965
global_step: 15347, epoch: 84, loss: 0.231180
global_step: 15348, epoch: 84, loss: 0.251846
global_step: 15349, epoch: 84, loss: 0.245441
global_step: 15350, epoch: 84, loss: 0.246709
global_step: 15351, epoch: 84, loss: 0.252587
global_step: 15352, epoch: 84, loss: 0.193056
global_step: 15353, epoch: 84, loss: 0.266374
global_step: 15354, epoch: 84, loss: 0.310463
global_step: 15355, epoch: 84, loss: 0.230149
global_step: 15356, epoch: 84, loss: 0.183690
global_step: 15357, epoch: 84, loss: 0.210990
global_step: 15358, epoch: 84, loss: 0.260901
global_step: 15359, epoch: 84, loss: 0.231036
global_step: 15360, epoch: 84, loss: 0.553726
epoch: 84
train	acc: 0.9688	macro: p 0.9730, r 0.9565, f1: 0.9644	micro: p 0.9688, r 0.9688, f1 0.9688	weighted_f1:0.9688
dev	acc: 0.5239	macro: p 0.3746, r 0.3049, f1: 0.3075	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4811
test	acc: 0.5747	macro: p 0.3853, r 0.3174, f1: 0.3220	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5373
global_step: 15361, epoch: 85, loss: 0.229843
global_step: 15362, epoch: 85, loss: 0.226075
global_step: 15363, epoch: 85, loss: 0.201823
global_step: 15364, epoch: 85, loss: 0.242961
global_step: 15365, epoch: 85, loss: 0.154042
global_step: 15366, epoch: 85, loss: 0.176978
global_step: 15367, epoch: 85, loss: 0.166579
global_step: 15368, epoch: 85, loss: 0.197239
global_step: 15369, epoch: 85, loss: 0.248207
global_step: 15370, epoch: 85, loss: 0.216586
global_step: 15371, epoch: 85, loss: 0.300056
global_step: 15372, epoch: 85, loss: 0.257545
global_step: 15373, epoch: 85, loss: 0.263184
global_step: 15374, epoch: 85, loss: 0.213319
global_step: 15375, epoch: 85, loss: 0.208366
global_step: 15376, epoch: 85, loss: 0.169749
global_step: 15377, epoch: 85, loss: 0.187870
global_step: 15378, epoch: 85, loss: 0.203508
global_step: 15379, epoch: 85, loss: 0.279166
global_step: 15380, epoch: 85, loss: 0.234063
global_step: 15381, epoch: 85, loss: 0.193576
global_step: 15382, epoch: 85, loss: 0.225252
global_step: 15383, epoch: 85, loss: 0.218638
global_step: 15384, epoch: 85, loss: 0.147852
global_step: 15385, epoch: 85, loss: 0.244575
global_step: 15386, epoch: 85, loss: 0.210985
global_step: 15387, epoch: 85, loss: 0.264430
global_step: 15388, epoch: 85, loss: 0.240464
global_step: 15389, epoch: 85, loss: 0.163415
global_step: 15390, epoch: 85, loss: 0.255068
global_step: 15391, epoch: 85, loss: 0.202612
global_step: 15392, epoch: 85, loss: 0.366671
global_step: 15393, epoch: 85, loss: 0.329970
global_step: 15394, epoch: 85, loss: 0.250098
global_step: 15395, epoch: 85, loss: 0.220420
global_step: 15396, epoch: 85, loss: 0.263229
global_step: 15397, epoch: 85, loss: 0.218272
global_step: 15398, epoch: 85, loss: 0.278550
global_step: 15399, epoch: 85, loss: 0.279043
global_step: 15400, epoch: 85, loss: 0.213588
epoch: 85
train	acc: 0.9677	macro: p 0.9760, r 0.9531, f1: 0.9642	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9675
dev	acc: 0.5275	macro: p 0.4077, r 0.2998, f1: 0.3082	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4800
test	acc: 0.5831	macro: p 0.4146, r 0.3134, f1: 0.3253	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5405
global_step: 15401, epoch: 86, loss: 0.201893
global_step: 15402, epoch: 86, loss: 0.215796
global_step: 15403, epoch: 86, loss: 0.201901
global_step: 15404, epoch: 86, loss: 0.295478
global_step: 15405, epoch: 86, loss: 0.230048
global_step: 15406, epoch: 86, loss: 0.281149
global_step: 15407, epoch: 86, loss: 0.161290
global_step: 15408, epoch: 86, loss: 0.244859
global_step: 15409, epoch: 86, loss: 0.231807
global_step: 15410, epoch: 86, loss: 0.147263
global_step: 15411, epoch: 86, loss: 0.284020
global_step: 15412, epoch: 86, loss: 0.251374
global_step: 15413, epoch: 86, loss: 0.159563
global_step: 15414, epoch: 86, loss: 0.134341
global_step: 15415, epoch: 86, loss: 0.247027
global_step: 15416, epoch: 86, loss: 0.225526
global_step: 15417, epoch: 86, loss: 0.207448
global_step: 15418, epoch: 86, loss: 0.223685
global_step: 15419, epoch: 86, loss: 0.106158
global_step: 15420, epoch: 86, loss: 0.166937
global_step: 15421, epoch: 86, loss: 0.249228
global_step: 15422, epoch: 86, loss: 0.239884
global_step: 15423, epoch: 86, loss: 0.260603
global_step: 15424, epoch: 86, loss: 0.158857
global_step: 15425, epoch: 86, loss: 0.205582
global_step: 15426, epoch: 86, loss: 0.185794
global_step: 15427, epoch: 86, loss: 0.204518
global_step: 15428, epoch: 86, loss: 0.309101
global_step: 15429, epoch: 86, loss: 0.241388
global_step: 15430, epoch: 86, loss: 0.263313
global_step: 15431, epoch: 86, loss: 0.252554
global_step: 15432, epoch: 86, loss: 0.159350
global_step: 15433, epoch: 86, loss: 0.143565
global_step: 15434, epoch: 86, loss: 0.153625
global_step: 15435, epoch: 86, loss: 0.204174
global_step: 15436, epoch: 86, loss: 0.122746
global_step: 15437, epoch: 86, loss: 0.270090
global_step: 15438, epoch: 86, loss: 0.256242
global_step: 15439, epoch: 86, loss: 0.171364
global_step: 15440, epoch: 86, loss: 0.023138
epoch: 86
train	acc: 0.9707	macro: p 0.9727, r 0.9618, f1: 0.9671	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5194	macro: p 0.3286, r 0.3006, f1: 0.3023	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4829
test	acc: 0.5709	macro: p 0.4235, r 0.3241, f1: 0.3340	micro: p 0.5709, r 0.5709, f1 0.5709	weighted_f1:0.5401
global_step: 15441, epoch: 87, loss: 0.189863
global_step: 15442, epoch: 87, loss: 0.137055
global_step: 15443, epoch: 87, loss: 0.134082
global_step: 15444, epoch: 87, loss: 0.233569
global_step: 15445, epoch: 87, loss: 0.196017
global_step: 15446, epoch: 87, loss: 0.358170
global_step: 15447, epoch: 87, loss: 0.170954
global_step: 15448, epoch: 87, loss: 0.281339
global_step: 15449, epoch: 87, loss: 0.292984
global_step: 15450, epoch: 87, loss: 0.220620
global_step: 15451, epoch: 87, loss: 0.209964
global_step: 15452, epoch: 87, loss: 0.257825
global_step: 15453, epoch: 87, loss: 0.201413
global_step: 15454, epoch: 87, loss: 0.202629
global_step: 15455, epoch: 87, loss: 0.220175
global_step: 15456, epoch: 87, loss: 0.263108
global_step: 15457, epoch: 87, loss: 0.317408
global_step: 15458, epoch: 87, loss: 0.214649
global_step: 15459, epoch: 87, loss: 0.177451
global_step: 15460, epoch: 87, loss: 0.214888
global_step: 15461, epoch: 87, loss: 0.186198
global_step: 15462, epoch: 87, loss: 0.246580
global_step: 15463, epoch: 87, loss: 0.238202
global_step: 15464, epoch: 87, loss: 0.196339
global_step: 15465, epoch: 87, loss: 0.262803
global_step: 15466, epoch: 87, loss: 0.224816
global_step: 15467, epoch: 87, loss: 0.215632
global_step: 15468, epoch: 87, loss: 0.199017
global_step: 15469, epoch: 87, loss: 0.184967
global_step: 15470, epoch: 87, loss: 0.261126
global_step: 15471, epoch: 87, loss: 0.183539
global_step: 15472, epoch: 87, loss: 0.289609
global_step: 15473, epoch: 87, loss: 0.232787
global_step: 15474, epoch: 87, loss: 0.282427
global_step: 15475, epoch: 87, loss: 0.219470
global_step: 15476, epoch: 87, loss: 0.217369
global_step: 15477, epoch: 87, loss: 0.188800
global_step: 15478, epoch: 87, loss: 0.238547
global_step: 15479, epoch: 87, loss: 0.175802
global_step: 15480, epoch: 87, loss: 0.058586
epoch: 87
train	acc: 0.9685	macro: p 0.9715, r 0.9572, f1: 0.9640	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5194	macro: p 0.3225, r 0.2925, f1: 0.2860	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4752
test	acc: 0.5674	macro: p 0.3873, r 0.3168, f1: 0.3223	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5281
global_step: 15481, epoch: 88, loss: 0.214790
global_step: 15482, epoch: 88, loss: 0.181488
global_step: 15483, epoch: 88, loss: 0.251415
global_step: 15484, epoch: 88, loss: 0.196490
global_step: 15485, epoch: 88, loss: 0.191484
global_step: 15486, epoch: 88, loss: 0.194661
global_step: 15487, epoch: 88, loss: 0.228106
global_step: 15488, epoch: 88, loss: 0.167393
global_step: 15489, epoch: 88, loss: 0.165635
global_step: 15490, epoch: 88, loss: 0.246533
global_step: 15491, epoch: 88, loss: 0.317852
global_step: 15492, epoch: 88, loss: 0.244040
global_step: 15493, epoch: 88, loss: 0.241690
global_step: 15494, epoch: 88, loss: 0.222433
global_step: 15495, epoch: 88, loss: 0.189053
global_step: 15496, epoch: 88, loss: 0.135141
global_step: 15497, epoch: 88, loss: 0.239586
global_step: 15498, epoch: 88, loss: 0.182078
global_step: 15499, epoch: 88, loss: 0.208414
global_step: 15500, epoch: 88, loss: 0.192047
global_step: 15501, epoch: 88, loss: 0.231529
global_step: 15502, epoch: 88, loss: 0.199301
global_step: 15503, epoch: 88, loss: 0.217326
global_step: 15504, epoch: 88, loss: 0.204705
global_step: 15505, epoch: 88, loss: 0.247686
global_step: 15506, epoch: 88, loss: 0.151502
global_step: 15507, epoch: 88, loss: 0.160286
global_step: 15508, epoch: 88, loss: 0.225876
global_step: 15509, epoch: 88, loss: 0.240012
global_step: 15510, epoch: 88, loss: 0.357236
global_step: 15511, epoch: 88, loss: 0.228765
global_step: 15512, epoch: 88, loss: 0.177016
global_step: 15513, epoch: 88, loss: 0.220266
global_step: 15514, epoch: 88, loss: 0.232185
global_step: 15515, epoch: 88, loss: 0.229625
global_step: 15516, epoch: 88, loss: 0.216279
global_step: 15517, epoch: 88, loss: 0.282687
global_step: 15518, epoch: 88, loss: 0.306525
global_step: 15519, epoch: 88, loss: 0.308801
global_step: 15520, epoch: 88, loss: 0.011552
epoch: 88
train	acc: 0.9707	macro: p 0.9746, r 0.9599, f1: 0.9671	micro: p 0.9707, r 0.9707, f1 0.9707	weighted_f1:0.9707
dev	acc: 0.5185	macro: p 0.3238, r 0.2879, f1: 0.2867	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4719
test	acc: 0.5858	macro: p 0.4430, r 0.3197, f1: 0.3318	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5452
global_step: 15521, epoch: 89, loss: 0.216127
global_step: 15522, epoch: 89, loss: 0.194260
global_step: 15523, epoch: 89, loss: 0.121297
global_step: 15524, epoch: 89, loss: 0.253184
global_step: 15525, epoch: 89, loss: 0.178528
global_step: 15526, epoch: 89, loss: 0.232753
global_step: 15527, epoch: 89, loss: 0.228122
global_step: 15528, epoch: 89, loss: 0.107492
global_step: 15529, epoch: 89, loss: 0.243787
global_step: 15530, epoch: 89, loss: 0.167023
global_step: 15531, epoch: 89, loss: 0.296647
global_step: 15532, epoch: 89, loss: 0.268536
global_step: 15533, epoch: 89, loss: 0.167474
global_step: 15534, epoch: 89, loss: 0.193629
global_step: 15535, epoch: 89, loss: 0.170072
global_step: 15536, epoch: 89, loss: 0.232024
global_step: 15537, epoch: 89, loss: 0.242343
global_step: 15538, epoch: 89, loss: 0.187179
global_step: 15539, epoch: 89, loss: 0.149319
global_step: 15540, epoch: 89, loss: 0.273602
global_step: 15541, epoch: 89, loss: 0.190247
global_step: 15542, epoch: 89, loss: 0.200093
global_step: 15543, epoch: 89, loss: 0.162874
global_step: 15544, epoch: 89, loss: 0.224892
global_step: 15545, epoch: 89, loss: 0.174834
global_step: 15546, epoch: 89, loss: 0.290812
global_step: 15547, epoch: 89, loss: 0.160621
global_step: 15548, epoch: 89, loss: 0.239532
global_step: 15549, epoch: 89, loss: 0.200006
global_step: 15550, epoch: 89, loss: 0.252161
global_step: 15551, epoch: 89, loss: 0.271299
global_step: 15552, epoch: 89, loss: 0.201299
global_step: 15553, epoch: 89, loss: 0.215955
global_step: 15554, epoch: 89, loss: 0.218293
global_step: 15555, epoch: 89, loss: 0.230816
global_step: 15556, epoch: 89, loss: 0.228679
global_step: 15557, epoch: 89, loss: 0.158460
global_step: 15558, epoch: 89, loss: 0.275212
global_step: 15559, epoch: 89, loss: 0.287267
global_step: 15560, epoch: 89, loss: 1.493987
epoch: 89
train	acc: 0.9677	macro: p 0.9722, r 0.9591, f1: 0.9654	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5167	macro: p 0.3449, r 0.3007, f1: 0.3023	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4800
test	acc: 0.5613	macro: p 0.3809, r 0.3177, f1: 0.3253	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5332
global_step: 15561, epoch: 90, loss: 0.264727
global_step: 15562, epoch: 90, loss: 0.295174
global_step: 15563, epoch: 90, loss: 0.293850
global_step: 15564, epoch: 90, loss: 0.256479
global_step: 15565, epoch: 90, loss: 0.208607
global_step: 15566, epoch: 90, loss: 0.217473
global_step: 15567, epoch: 90, loss: 0.253853
global_step: 15568, epoch: 90, loss: 0.241202
global_step: 15569, epoch: 90, loss: 0.236495
global_step: 15570, epoch: 90, loss: 0.197493
global_step: 15571, epoch: 90, loss: 0.199201
global_step: 15572, epoch: 90, loss: 0.220989
global_step: 15573, epoch: 90, loss: 0.261223
global_step: 15574, epoch: 90, loss: 0.229190
global_step: 15575, epoch: 90, loss: 0.146785
global_step: 15576, epoch: 90, loss: 0.155000
global_step: 15577, epoch: 90, loss: 0.188013
global_step: 15578, epoch: 90, loss: 0.241027
global_step: 15579, epoch: 90, loss: 0.195609
global_step: 15580, epoch: 90, loss: 0.153241
global_step: 15581, epoch: 90, loss: 0.347694
global_step: 15582, epoch: 90, loss: 0.201725
global_step: 15583, epoch: 90, loss: 0.201143
global_step: 15584, epoch: 90, loss: 0.215337
global_step: 15585, epoch: 90, loss: 0.231591
global_step: 15586, epoch: 90, loss: 0.193837
global_step: 15587, epoch: 90, loss: 0.135645
global_step: 15588, epoch: 90, loss: 0.134011
global_step: 15589, epoch: 90, loss: 0.192358
global_step: 15590, epoch: 90, loss: 0.205692
global_step: 15591, epoch: 90, loss: 0.186938
global_step: 15592, epoch: 90, loss: 0.177406
global_step: 15593, epoch: 90, loss: 0.224905
global_step: 15594, epoch: 90, loss: 0.182223
global_step: 15595, epoch: 90, loss: 0.233407
global_step: 15596, epoch: 90, loss: 0.250694
global_step: 15597, epoch: 90, loss: 0.206232
global_step: 15598, epoch: 90, loss: 0.282512
global_step: 15599, epoch: 90, loss: 0.169746
global_step: 15600, epoch: 90, loss: 0.002597
epoch: 90
train	acc: 0.9715	macro: p 0.9736, r 0.9622, f1: 0.9677	micro: p 0.9715, r 0.9715, f1 0.9715	weighted_f1:0.9715
dev	acc: 0.5212	macro: p 0.3796, r 0.3159, f1: 0.3257	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4870
test	acc: 0.5659	macro: p 0.3829, r 0.3153, f1: 0.3218	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5348
global_step: 15601, epoch: 91, loss: 0.171829
global_step: 15602, epoch: 91, loss: 0.216030
global_step: 15603, epoch: 91, loss: 0.235968
global_step: 15604, epoch: 91, loss: 0.211777
global_step: 15605, epoch: 91, loss: 0.189821
global_step: 15606, epoch: 91, loss: 0.207491
global_step: 15607, epoch: 91, loss: 0.169818
global_step: 15608, epoch: 91, loss: 0.199332
global_step: 15609, epoch: 91, loss: 0.155443
global_step: 15610, epoch: 91, loss: 0.209008
global_step: 15611, epoch: 91, loss: 0.226471
global_step: 15612, epoch: 91, loss: 0.253692
global_step: 15613, epoch: 91, loss: 0.222997
global_step: 15614, epoch: 91, loss: 0.272894
global_step: 15615, epoch: 91, loss: 0.237650
global_step: 15616, epoch: 91, loss: 0.204073
global_step: 15617, epoch: 91, loss: 0.236503
global_step: 15618, epoch: 91, loss: 0.202310
global_step: 15619, epoch: 91, loss: 0.185334
global_step: 15620, epoch: 91, loss: 0.142527
global_step: 15621, epoch: 91, loss: 0.224761
global_step: 15622, epoch: 91, loss: 0.202791
global_step: 15623, epoch: 91, loss: 0.181836
global_step: 15624, epoch: 91, loss: 0.195337
global_step: 15625, epoch: 91, loss: 0.163842
global_step: 15626, epoch: 91, loss: 0.201743
global_step: 15627, epoch: 91, loss: 0.284879
global_step: 15628, epoch: 91, loss: 0.234894
global_step: 15629, epoch: 91, loss: 0.173976
global_step: 15630, epoch: 91, loss: 0.174022
global_step: 15631, epoch: 91, loss: 0.223800
global_step: 15632, epoch: 91, loss: 0.267801
global_step: 15633, epoch: 91, loss: 0.178791
global_step: 15634, epoch: 91, loss: 0.241972
global_step: 15635, epoch: 91, loss: 0.223700
global_step: 15636, epoch: 91, loss: 0.220370
global_step: 15637, epoch: 91, loss: 0.275718
global_step: 15638, epoch: 91, loss: 0.227977
global_step: 15639, epoch: 91, loss: 0.218662
global_step: 15640, epoch: 91, loss: 0.014883
epoch: 91
train	acc: 0.9720	macro: p 0.9742, r 0.9634, f1: 0.9686	micro: p 0.9720, r 0.9720, f1 0.9720	weighted_f1:0.9720
dev	acc: 0.5176	macro: p 0.3646, r 0.3109, f1: 0.3196	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4807
test	acc: 0.5674	macro: p 0.3706, r 0.3152, f1: 0.3255	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5346
global_step: 15641, epoch: 92, loss: 0.226603
global_step: 15642, epoch: 92, loss: 0.191975
global_step: 15643, epoch: 92, loss: 0.191139
global_step: 15644, epoch: 92, loss: 0.192898
global_step: 15645, epoch: 92, loss: 0.179630
global_step: 15646, epoch: 92, loss: 0.215504
global_step: 15647, epoch: 92, loss: 0.191077
global_step: 15648, epoch: 92, loss: 0.263192
global_step: 15649, epoch: 92, loss: 0.184244
global_step: 15650, epoch: 92, loss: 0.208573
global_step: 15651, epoch: 92, loss: 0.204355
global_step: 15652, epoch: 92, loss: 0.166059
global_step: 15653, epoch: 92, loss: 0.170026
global_step: 15654, epoch: 92, loss: 0.145000
global_step: 15655, epoch: 92, loss: 0.257677
global_step: 15656, epoch: 92, loss: 0.214883
global_step: 15657, epoch: 92, loss: 0.190599
global_step: 15658, epoch: 92, loss: 0.223805
global_step: 15659, epoch: 92, loss: 0.215966
global_step: 15660, epoch: 92, loss: 0.204564
global_step: 15661, epoch: 92, loss: 0.207401
global_step: 15662, epoch: 92, loss: 0.163489
global_step: 15663, epoch: 92, loss: 0.235386
global_step: 15664, epoch: 92, loss: 0.171163
global_step: 15665, epoch: 92, loss: 0.212885
global_step: 15666, epoch: 92, loss: 0.242251
global_step: 15667, epoch: 92, loss: 0.207845
global_step: 15668, epoch: 92, loss: 0.142414
global_step: 15669, epoch: 92, loss: 0.174384
global_step: 15670, epoch: 92, loss: 0.193274
global_step: 15671, epoch: 92, loss: 0.195846
global_step: 15672, epoch: 92, loss: 0.231920
global_step: 15673, epoch: 92, loss: 0.320255
global_step: 15674, epoch: 92, loss: 0.250885
global_step: 15675, epoch: 92, loss: 0.185384
global_step: 15676, epoch: 92, loss: 0.175598
global_step: 15677, epoch: 92, loss: 0.173794
global_step: 15678, epoch: 92, loss: 0.210789
global_step: 15679, epoch: 92, loss: 0.251261
global_step: 15680, epoch: 92, loss: 0.145817
epoch: 92
train	acc: 0.9697	macro: p 0.9735, r 0.9593, f1: 0.9661	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5023	macro: p 0.3389, r 0.3071, f1: 0.3048	micro: p 0.5023, r 0.5023, f1 0.5023	weighted_f1:0.4750
test	acc: 0.5475	macro: p 0.3706, r 0.3137, f1: 0.3146	micro: p 0.5475, r 0.5475, f1 0.5475	weighted_f1:0.5234
global_step: 15681, epoch: 93, loss: 0.198079
global_step: 15682, epoch: 93, loss: 0.277447
global_step: 15683, epoch: 93, loss: 0.255753
global_step: 15684, epoch: 93, loss: 0.166826
global_step: 15685, epoch: 93, loss: 0.238485
global_step: 15686, epoch: 93, loss: 0.181749
global_step: 15687, epoch: 93, loss: 0.238984
global_step: 15688, epoch: 93, loss: 0.300724
global_step: 15689, epoch: 93, loss: 0.299862
global_step: 15690, epoch: 93, loss: 0.235916
global_step: 15691, epoch: 93, loss: 0.164244
global_step: 15692, epoch: 93, loss: 0.239504
global_step: 15693, epoch: 93, loss: 0.185994
global_step: 15694, epoch: 93, loss: 0.216771
global_step: 15695, epoch: 93, loss: 0.176182
global_step: 15696, epoch: 93, loss: 0.178757
global_step: 15697, epoch: 93, loss: 0.206819
global_step: 15698, epoch: 93, loss: 0.235675
global_step: 15699, epoch: 93, loss: 0.291205
global_step: 15700, epoch: 93, loss: 0.284400
global_step: 15701, epoch: 93, loss: 0.182215
global_step: 15702, epoch: 93, loss: 0.202925
global_step: 15703, epoch: 93, loss: 0.244877
global_step: 15704, epoch: 93, loss: 0.223861
global_step: 15705, epoch: 93, loss: 0.143481
global_step: 15706, epoch: 93, loss: 0.233190
global_step: 15707, epoch: 93, loss: 0.244887
global_step: 15708, epoch: 93, loss: 0.202751
global_step: 15709, epoch: 93, loss: 0.205686
global_step: 15710, epoch: 93, loss: 0.230339
global_step: 15711, epoch: 93, loss: 0.223591
global_step: 15712, epoch: 93, loss: 0.311690
global_step: 15713, epoch: 93, loss: 0.280374
global_step: 15714, epoch: 93, loss: 0.275479
global_step: 15715, epoch: 93, loss: 0.241516
global_step: 15716, epoch: 93, loss: 0.210354
global_step: 15717, epoch: 93, loss: 0.187223
global_step: 15718, epoch: 93, loss: 0.236936
global_step: 15719, epoch: 93, loss: 0.210070
global_step: 15720, epoch: 93, loss: 0.170348
epoch: 93
train	acc: 0.9705	macro: p 0.9737, r 0.9604, f1: 0.9668	micro: p 0.9705, r 0.9705, f1 0.9705	weighted_f1:0.9705
dev	acc: 0.5221	macro: p 0.3520, r 0.3130, f1: 0.3161	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4896
test	acc: 0.5586	macro: p 0.4095, r 0.3204, f1: 0.3267	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.5316
global_step: 15721, epoch: 94, loss: 0.207398
global_step: 15722, epoch: 94, loss: 0.220568
global_step: 15723, epoch: 94, loss: 0.210037
global_step: 15724, epoch: 94, loss: 0.142394
global_step: 15725, epoch: 94, loss: 0.172770
global_step: 15726, epoch: 94, loss: 0.232597
global_step: 15727, epoch: 94, loss: 0.139726
global_step: 15728, epoch: 94, loss: 0.260485
global_step: 15729, epoch: 94, loss: 0.186042
global_step: 15730, epoch: 94, loss: 0.198351
global_step: 15731, epoch: 94, loss: 0.169051
global_step: 15732, epoch: 94, loss: 0.256633
global_step: 15733, epoch: 94, loss: 0.203272
global_step: 15734, epoch: 94, loss: 0.131291
global_step: 15735, epoch: 94, loss: 0.207602
global_step: 15736, epoch: 94, loss: 0.217856
global_step: 15737, epoch: 94, loss: 0.215193
global_step: 15738, epoch: 94, loss: 0.244743
global_step: 15739, epoch: 94, loss: 0.254772
global_step: 15740, epoch: 94, loss: 0.183441
global_step: 15741, epoch: 94, loss: 0.300034
global_step: 15742, epoch: 94, loss: 0.209832
global_step: 15743, epoch: 94, loss: 0.190861
global_step: 15744, epoch: 94, loss: 0.248058
global_step: 15745, epoch: 94, loss: 0.230928
global_step: 15746, epoch: 94, loss: 0.266616
global_step: 15747, epoch: 94, loss: 0.204780
global_step: 15748, epoch: 94, loss: 0.206753
global_step: 15749, epoch: 94, loss: 0.228810
global_step: 15750, epoch: 94, loss: 0.332130
global_step: 15751, epoch: 94, loss: 0.205364
global_step: 15752, epoch: 94, loss: 0.173007
global_step: 15753, epoch: 94, loss: 0.218488
global_step: 15754, epoch: 94, loss: 0.166241
global_step: 15755, epoch: 94, loss: 0.160457
global_step: 15756, epoch: 94, loss: 0.172183
global_step: 15757, epoch: 94, loss: 0.236274
global_step: 15758, epoch: 94, loss: 0.274425
global_step: 15759, epoch: 94, loss: 0.256924
global_step: 15760, epoch: 94, loss: 0.264495
epoch: 94
train	acc: 0.9687	macro: p 0.9723, r 0.9580, f1: 0.9649	micro: p 0.9687, r 0.9687, f1 0.9687	weighted_f1:0.9687
dev	acc: 0.5302	macro: p 0.3858, r 0.3166, f1: 0.3221	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4879
test	acc: 0.5674	macro: p 0.3829, r 0.3183, f1: 0.3252	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5317
global_step: 15761, epoch: 95, loss: 0.237542
global_step: 15762, epoch: 95, loss: 0.198264
global_step: 15763, epoch: 95, loss: 0.231803
global_step: 15764, epoch: 95, loss: 0.170266
global_step: 15765, epoch: 95, loss: 0.156929
global_step: 15766, epoch: 95, loss: 0.225070
global_step: 15767, epoch: 95, loss: 0.178860
global_step: 15768, epoch: 95, loss: 0.166643
global_step: 15769, epoch: 95, loss: 0.195330
global_step: 15770, epoch: 95, loss: 0.153285
global_step: 15771, epoch: 95, loss: 0.226072
global_step: 15772, epoch: 95, loss: 0.239172
global_step: 15773, epoch: 95, loss: 0.237233
global_step: 15774, epoch: 95, loss: 0.254199
global_step: 15775, epoch: 95, loss: 0.155893
global_step: 15776, epoch: 95, loss: 0.288215
global_step: 15777, epoch: 95, loss: 0.286918
global_step: 15778, epoch: 95, loss: 0.187579
global_step: 15779, epoch: 95, loss: 0.198845
global_step: 15780, epoch: 95, loss: 0.211196
global_step: 15781, epoch: 95, loss: 0.182235
global_step: 15782, epoch: 95, loss: 0.194011
global_step: 15783, epoch: 95, loss: 0.161076
global_step: 15784, epoch: 95, loss: 0.200043
global_step: 15785, epoch: 95, loss: 0.243100
global_step: 15786, epoch: 95, loss: 0.219077
global_step: 15787, epoch: 95, loss: 0.162871
global_step: 15788, epoch: 95, loss: 0.241752
global_step: 15789, epoch: 95, loss: 0.153856
global_step: 15790, epoch: 95, loss: 0.199785
global_step: 15791, epoch: 95, loss: 0.219536
global_step: 15792, epoch: 95, loss: 0.248297
global_step: 15793, epoch: 95, loss: 0.215777
global_step: 15794, epoch: 95, loss: 0.223770
global_step: 15795, epoch: 95, loss: 0.176505
global_step: 15796, epoch: 95, loss: 0.236484
global_step: 15797, epoch: 95, loss: 0.270106
global_step: 15798, epoch: 95, loss: 0.222712
global_step: 15799, epoch: 95, loss: 0.207676
global_step: 15800, epoch: 95, loss: 0.145284
epoch: 95
train	acc: 0.9702	macro: p 0.9746, r 0.9579, f1: 0.9660	micro: p 0.9702, r 0.9702, f1 0.9702	weighted_f1:0.9701
dev	acc: 0.5266	macro: p 0.3768, r 0.3129, f1: 0.3180	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4818
test	acc: 0.5797	macro: p 0.4117, r 0.3196, f1: 0.3270	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5410
global_step: 15801, epoch: 96, loss: 0.199556
global_step: 15802, epoch: 96, loss: 0.157972
global_step: 15803, epoch: 96, loss: 0.153380
global_step: 15804, epoch: 96, loss: 0.204300
global_step: 15805, epoch: 96, loss: 0.217380
global_step: 15806, epoch: 96, loss: 0.187455
global_step: 15807, epoch: 96, loss: 0.214293
global_step: 15808, epoch: 96, loss: 0.191423
global_step: 15809, epoch: 96, loss: 0.198702
global_step: 15810, epoch: 96, loss: 0.272749
global_step: 15811, epoch: 96, loss: 0.182506
global_step: 15812, epoch: 96, loss: 0.238006
global_step: 15813, epoch: 96, loss: 0.215113
global_step: 15814, epoch: 96, loss: 0.241952
global_step: 15815, epoch: 96, loss: 0.195747
global_step: 15816, epoch: 96, loss: 0.182559
global_step: 15817, epoch: 96, loss: 0.186668
global_step: 15818, epoch: 96, loss: 0.207662
global_step: 15819, epoch: 96, loss: 0.187201
global_step: 15820, epoch: 96, loss: 0.241606
global_step: 15821, epoch: 96, loss: 0.251888
global_step: 15822, epoch: 96, loss: 0.202657
global_step: 15823, epoch: 96, loss: 0.252587
global_step: 15824, epoch: 96, loss: 0.151741
global_step: 15825, epoch: 96, loss: 0.147236
global_step: 15826, epoch: 96, loss: 0.183982
global_step: 15827, epoch: 96, loss: 0.198361
global_step: 15828, epoch: 96, loss: 0.253045
global_step: 15829, epoch: 96, loss: 0.179889
global_step: 15830, epoch: 96, loss: 0.235732
global_step: 15831, epoch: 96, loss: 0.234741
global_step: 15832, epoch: 96, loss: 0.199922
global_step: 15833, epoch: 96, loss: 0.177639
global_step: 15834, epoch: 96, loss: 0.168226
global_step: 15835, epoch: 96, loss: 0.219953
global_step: 15836, epoch: 96, loss: 0.242352
global_step: 15837, epoch: 96, loss: 0.164497
global_step: 15838, epoch: 96, loss: 0.256890
global_step: 15839, epoch: 96, loss: 0.188905
global_step: 15840, epoch: 96, loss: 0.118467
epoch: 96
train	acc: 0.9716	macro: p 0.9747, r 0.9634, f1: 0.9689	micro: p 0.9716, r 0.9716, f1 0.9716	weighted_f1:0.9716
dev	acc: 0.5221	macro: p 0.3692, r 0.3155, f1: 0.3204	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4860
test	acc: 0.5701	macro: p 0.3868, r 0.3273, f1: 0.3367	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5399
global_step: 15841, epoch: 97, loss: 0.186056
global_step: 15842, epoch: 97, loss: 0.256311
global_step: 15843, epoch: 97, loss: 0.159678
global_step: 15844, epoch: 97, loss: 0.170258
global_step: 15845, epoch: 97, loss: 0.216896
global_step: 15846, epoch: 97, loss: 0.160554
global_step: 15847, epoch: 97, loss: 0.200707
global_step: 15848, epoch: 97, loss: 0.196466
global_step: 15849, epoch: 97, loss: 0.206171
global_step: 15850, epoch: 97, loss: 0.208532
global_step: 15851, epoch: 97, loss: 0.318961
global_step: 15852, epoch: 97, loss: 0.158388
global_step: 15853, epoch: 97, loss: 0.203339
global_step: 15854, epoch: 97, loss: 0.163515
global_step: 15855, epoch: 97, loss: 0.202356
global_step: 15856, epoch: 97, loss: 0.261488
global_step: 15857, epoch: 97, loss: 0.168180
global_step: 15858, epoch: 97, loss: 0.192447
global_step: 15859, epoch: 97, loss: 0.222900
global_step: 15860, epoch: 97, loss: 0.236058
global_step: 15861, epoch: 97, loss: 0.213454
global_step: 15862, epoch: 97, loss: 0.153283
global_step: 15863, epoch: 97, loss: 0.183626
global_step: 15864, epoch: 97, loss: 0.166362
global_step: 15865, epoch: 97, loss: 0.152190
global_step: 15866, epoch: 97, loss: 0.206648
global_step: 15867, epoch: 97, loss: 0.230479
global_step: 15868, epoch: 97, loss: 0.131494
global_step: 15869, epoch: 97, loss: 0.180188
global_step: 15870, epoch: 97, loss: 0.234238
global_step: 15871, epoch: 97, loss: 0.218650
global_step: 15872, epoch: 97, loss: 0.204514
global_step: 15873, epoch: 97, loss: 0.247577
global_step: 15874, epoch: 97, loss: 0.224119
global_step: 15875, epoch: 97, loss: 0.116540
global_step: 15876, epoch: 97, loss: 0.245433
global_step: 15877, epoch: 97, loss: 0.227535
global_step: 15878, epoch: 97, loss: 0.263939
global_step: 15879, epoch: 97, loss: 0.212607
global_step: 15880, epoch: 97, loss: 0.036218
epoch: 97
train	acc: 0.9713	macro: p 0.9755, r 0.9609, f1: 0.9680	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5275	macro: p 0.3415, r 0.3057, f1: 0.3075	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4865
test	acc: 0.5805	macro: p 0.4231, r 0.3253, f1: 0.3359	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5465
global_step: 15881, epoch: 98, loss: 0.175902
global_step: 15882, epoch: 98, loss: 0.258173
global_step: 15883, epoch: 98, loss: 0.174685
global_step: 15884, epoch: 98, loss: 0.174306
global_step: 15885, epoch: 98, loss: 0.295019
global_step: 15886, epoch: 98, loss: 0.194922
global_step: 15887, epoch: 98, loss: 0.127148
global_step: 15888, epoch: 98, loss: 0.293218
global_step: 15889, epoch: 98, loss: 0.142459
global_step: 15890, epoch: 98, loss: 0.242331
global_step: 15891, epoch: 98, loss: 0.181715
global_step: 15892, epoch: 98, loss: 0.220131
global_step: 15893, epoch: 98, loss: 0.145217
global_step: 15894, epoch: 98, loss: 0.227888
global_step: 15895, epoch: 98, loss: 0.206551
global_step: 15896, epoch: 98, loss: 0.163798
global_step: 15897, epoch: 98, loss: 0.224548
global_step: 15898, epoch: 98, loss: 0.211245
global_step: 15899, epoch: 98, loss: 0.185946
global_step: 15900, epoch: 98, loss: 0.182262
global_step: 15901, epoch: 98, loss: 0.245231
global_step: 15902, epoch: 98, loss: 0.216655
global_step: 15903, epoch: 98, loss: 0.184694
global_step: 15904, epoch: 98, loss: 0.212491
global_step: 15905, epoch: 98, loss: 0.262013
global_step: 15906, epoch: 98, loss: 0.269818
global_step: 15907, epoch: 98, loss: 0.221186
global_step: 15908, epoch: 98, loss: 0.209674
global_step: 15909, epoch: 98, loss: 0.204024
global_step: 15910, epoch: 98, loss: 0.131397
global_step: 15911, epoch: 98, loss: 0.279113
global_step: 15912, epoch: 98, loss: 0.192597
global_step: 15913, epoch: 98, loss: 0.203668
global_step: 15914, epoch: 98, loss: 0.287892
global_step: 15915, epoch: 98, loss: 0.159175
global_step: 15916, epoch: 98, loss: 0.200759
global_step: 15917, epoch: 98, loss: 0.244544
global_step: 15918, epoch: 98, loss: 0.213248
global_step: 15919, epoch: 98, loss: 0.257793
global_step: 15920, epoch: 98, loss: 0.023365
epoch: 98
train	acc: 0.9713	macro: p 0.9739, r 0.9624, f1: 0.9680	micro: p 0.9713, r 0.9713, f1 0.9713	weighted_f1:0.9713
dev	acc: 0.5140	macro: p 0.3551, r 0.3038, f1: 0.3059	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4733
test	acc: 0.5716	macro: p 0.3780, r 0.3149, f1: 0.3223	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5358
global_step: 15921, epoch: 99, loss: 0.174182
global_step: 15922, epoch: 99, loss: 0.220613
global_step: 15923, epoch: 99, loss: 0.186316
global_step: 15924, epoch: 99, loss: 0.145419
global_step: 15925, epoch: 99, loss: 0.227072
global_step: 15926, epoch: 99, loss: 0.194533
global_step: 15927, epoch: 99, loss: 0.170057
global_step: 15928, epoch: 99, loss: 0.192947
global_step: 15929, epoch: 99, loss: 0.237248
global_step: 15930, epoch: 99, loss: 0.197236
global_step: 15931, epoch: 99, loss: 0.248352
global_step: 15932, epoch: 99, loss: 0.179134
global_step: 15933, epoch: 99, loss: 0.215940
global_step: 15934, epoch: 99, loss: 0.211887
global_step: 15935, epoch: 99, loss: 0.180689
global_step: 15936, epoch: 99, loss: 0.285765
global_step: 15937, epoch: 99, loss: 0.224055
global_step: 15938, epoch: 99, loss: 0.180946
global_step: 15939, epoch: 99, loss: 0.150937
global_step: 15940, epoch: 99, loss: 0.194366
global_step: 15941, epoch: 99, loss: 0.332769
global_step: 15942, epoch: 99, loss: 0.206856
global_step: 15943, epoch: 99, loss: 0.247681
global_step: 15944, epoch: 99, loss: 0.250600
global_step: 15945, epoch: 99, loss: 0.259789
global_step: 15946, epoch: 99, loss: 0.191017
global_step: 15947, epoch: 99, loss: 0.174685
global_step: 15948, epoch: 99, loss: 0.269929
global_step: 15949, epoch: 99, loss: 0.260833
global_step: 15950, epoch: 99, loss: 0.179724
global_step: 15951, epoch: 99, loss: 0.211389
global_step: 15952, epoch: 99, loss: 0.171147
global_step: 15953, epoch: 99, loss: 0.192848
global_step: 15954, epoch: 99, loss: 0.241981
global_step: 15955, epoch: 99, loss: 0.222497
global_step: 15956, epoch: 99, loss: 0.244963
global_step: 15957, epoch: 99, loss: 0.227020
global_step: 15958, epoch: 99, loss: 0.218918
global_step: 15959, epoch: 99, loss: 0.214845
global_step: 15960, epoch: 99, loss: 0.351851
epoch: 99
train	acc: 0.9683	macro: p 0.9732, r 0.9575, f1: 0.9652	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9681
dev	acc: 0.5356	macro: p 0.3955, r 0.3131, f1: 0.3253	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4908
test	acc: 0.5847	macro: p 0.3967, r 0.3185, f1: 0.3329	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5449
global_step: 15961, epoch: 100, loss: 0.241112
global_step: 15962, epoch: 100, loss: 0.231318
global_step: 15963, epoch: 100, loss: 0.218791
global_step: 15964, epoch: 100, loss: 0.169457
global_step: 15965, epoch: 100, loss: 0.180458
global_step: 15966, epoch: 100, loss: 0.155820
global_step: 15967, epoch: 100, loss: 0.158126
global_step: 15968, epoch: 100, loss: 0.141272
global_step: 15969, epoch: 100, loss: 0.199177
global_step: 15970, epoch: 100, loss: 0.126232
global_step: 15971, epoch: 100, loss: 0.270832
global_step: 15972, epoch: 100, loss: 0.187560
global_step: 15973, epoch: 100, loss: 0.216391
global_step: 15974, epoch: 100, loss: 0.263700
global_step: 15975, epoch: 100, loss: 0.203327
global_step: 15976, epoch: 100, loss: 0.228211
global_step: 15977, epoch: 100, loss: 0.165880
global_step: 15978, epoch: 100, loss: 0.183179
global_step: 15979, epoch: 100, loss: 0.147729
global_step: 15980, epoch: 100, loss: 0.144375
global_step: 15981, epoch: 100, loss: 0.223930
global_step: 15982, epoch: 100, loss: 0.154031
global_step: 15983, epoch: 100, loss: 0.249269
global_step: 15984, epoch: 100, loss: 0.197489
global_step: 15985, epoch: 100, loss: 0.121587
global_step: 15986, epoch: 100, loss: 0.187601
global_step: 15987, epoch: 100, loss: 0.134917
global_step: 15988, epoch: 100, loss: 0.138261
global_step: 15989, epoch: 100, loss: 0.252337
global_step: 15990, epoch: 100, loss: 0.173251
global_step: 15991, epoch: 100, loss: 0.204418
global_step: 15992, epoch: 100, loss: 0.178435
global_step: 15993, epoch: 100, loss: 0.220847
global_step: 15994, epoch: 100, loss: 0.212775
global_step: 15995, epoch: 100, loss: 0.159842
global_step: 15996, epoch: 100, loss: 0.260159
global_step: 15997, epoch: 100, loss: 0.207065
global_step: 15998, epoch: 100, loss: 0.276705
global_step: 15999, epoch: 100, loss: 0.206738
global_step: 16000, epoch: 100, loss: 0.202361
epoch: 100
train	acc: 0.9721	macro: p 0.9731, r 0.9634, f1: 0.9681	micro: p 0.9721, r 0.9721, f1 0.9721	weighted_f1:0.9721
dev	acc: 0.5302	macro: p 0.3872, r 0.3206, f1: 0.3304	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4960
test	acc: 0.5705	macro: p 0.3807, r 0.3191, f1: 0.3269	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5408
BEST MODEL epoch: 39
train	acc: 0.9529 macro_p: 0.9572 macro_r: 0.9292 macro_f1: 0.9423 micro_p: 0.9529 micro_r: 0.9529 micro_f1: 0.9529 weighted_f1: 0.9529
dev	acc: 0.5392 macro_p: 0.3953 macro_r: 0.3291 macro_f1: 0.3374 micro_p: 0.5392 micro_r: 0.5392 micro_f1: 0.5392 weighted_f1: 0.5069
test	acc: 0.5732 macro_p: 0.3928 macro_r: 0.3247 macro_f1: 0.3341 micro_p: 0.5732 micro_r: 0.5732 micro_f1: 0.5732 weighted_f1: 0.5463
==========ROUND 5==========
global_step: 16001, epoch: 1, loss: 2.057294
global_step: 16002, epoch: 1, loss: 1.834445
global_step: 16003, epoch: 1, loss: 1.637121
global_step: 16004, epoch: 1, loss: 1.593850
global_step: 16005, epoch: 1, loss: 1.529163
global_step: 16006, epoch: 1, loss: 1.575394
global_step: 16007, epoch: 1, loss: 1.532120
global_step: 16008, epoch: 1, loss: 1.454265
global_step: 16009, epoch: 1, loss: 1.346637
global_step: 16010, epoch: 1, loss: 1.489991
global_step: 16011, epoch: 1, loss: 1.491049
global_step: 16012, epoch: 1, loss: 1.433741
global_step: 16013, epoch: 1, loss: 1.411038
global_step: 16014, epoch: 1, loss: 1.591107
global_step: 16015, epoch: 1, loss: 1.410107
global_step: 16016, epoch: 1, loss: 1.492551
global_step: 16017, epoch: 1, loss: 1.526858
global_step: 16018, epoch: 1, loss: 1.373947
global_step: 16019, epoch: 1, loss: 1.474965
global_step: 16020, epoch: 1, loss: 1.410177
global_step: 16021, epoch: 1, loss: 1.394923
global_step: 16022, epoch: 1, loss: 1.374442
global_step: 16023, epoch: 1, loss: 1.290997
global_step: 16024, epoch: 1, loss: 1.456819
global_step: 16025, epoch: 1, loss: 1.483341
global_step: 16026, epoch: 1, loss: 1.295080
global_step: 16027, epoch: 1, loss: 1.374390
global_step: 16028, epoch: 1, loss: 1.413518
global_step: 16029, epoch: 1, loss: 1.412009
global_step: 16030, epoch: 1, loss: 1.345386
global_step: 16031, epoch: 1, loss: 1.467494
global_step: 16032, epoch: 1, loss: 1.310337
global_step: 16033, epoch: 1, loss: 1.432887
global_step: 16034, epoch: 1, loss: 1.455322
global_step: 16035, epoch: 1, loss: 1.453333
global_step: 16036, epoch: 1, loss: 1.378839
global_step: 16037, epoch: 1, loss: 1.461880
global_step: 16038, epoch: 1, loss: 1.414726
global_step: 16039, epoch: 1, loss: 1.258056
global_step: 16040, epoch: 1, loss: 1.205678
epoch: 1
train	acc: 0.5624	macro: p 0.3190, r 0.2430, f1: 0.2357	micro: p 0.5624, r 0.5624, f1 0.5624	weighted_f1:0.4770
dev	acc: 0.5158	macro: p 0.3170, r 0.2461, f1: 0.2254	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4202
test	acc: 0.5678	macro: p 0.3123, r 0.2451, f1: 0.2349	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.4807
New best model!
global_step: 16041, epoch: 2, loss: 1.488215
global_step: 16042, epoch: 2, loss: 1.307448
global_step: 16043, epoch: 2, loss: 1.278293
global_step: 16044, epoch: 2, loss: 1.256757
global_step: 16045, epoch: 2, loss: 1.407744
global_step: 16046, epoch: 2, loss: 1.266981
global_step: 16047, epoch: 2, loss: 1.516334
global_step: 16048, epoch: 2, loss: 1.339567
global_step: 16049, epoch: 2, loss: 1.148354
global_step: 16050, epoch: 2, loss: 1.452356
global_step: 16051, epoch: 2, loss: 1.427630
global_step: 16052, epoch: 2, loss: 1.319928
global_step: 16053, epoch: 2, loss: 1.327358
global_step: 16054, epoch: 2, loss: 1.241625
global_step: 16055, epoch: 2, loss: 1.399008
global_step: 16056, epoch: 2, loss: 1.313300
global_step: 16057, epoch: 2, loss: 1.271750
global_step: 16058, epoch: 2, loss: 1.311235
global_step: 16059, epoch: 2, loss: 1.414203
global_step: 16060, epoch: 2, loss: 1.417164
global_step: 16061, epoch: 2, loss: 1.373651
global_step: 16062, epoch: 2, loss: 1.259925
global_step: 16063, epoch: 2, loss: 1.393712
global_step: 16064, epoch: 2, loss: 1.305563
global_step: 16065, epoch: 2, loss: 1.402127
global_step: 16066, epoch: 2, loss: 1.305772
global_step: 16067, epoch: 2, loss: 1.360144
global_step: 16068, epoch: 2, loss: 1.419373
global_step: 16069, epoch: 2, loss: 1.250648
global_step: 16070, epoch: 2, loss: 1.338727
global_step: 16071, epoch: 2, loss: 1.358449
global_step: 16072, epoch: 2, loss: 1.391898
global_step: 16073, epoch: 2, loss: 1.276338
global_step: 16074, epoch: 2, loss: 1.333418
global_step: 16075, epoch: 2, loss: 1.294773
global_step: 16076, epoch: 2, loss: 1.316970
global_step: 16077, epoch: 2, loss: 1.431983
global_step: 16078, epoch: 2, loss: 1.255715
global_step: 16079, epoch: 2, loss: 1.343959
global_step: 16080, epoch: 2, loss: 1.081312
epoch: 2
train	acc: 0.5665	macro: p 0.4269, r 0.2649, f1: 0.2553	micro: p 0.5665, r 0.5665, f1 0.5665	weighted_f1:0.4892
dev	acc: 0.5149	macro: p 0.2528, r 0.2514, f1: 0.2331	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4280
test	acc: 0.5648	macro: p 0.2718, r 0.2570, f1: 0.2461	micro: p 0.5648, r 0.5648, f1 0.5648	weighted_f1:0.4877
New best model!
global_step: 16081, epoch: 3, loss: 1.302323
global_step: 16082, epoch: 3, loss: 1.260618
global_step: 16083, epoch: 3, loss: 1.361042
global_step: 16084, epoch: 3, loss: 1.232084
global_step: 16085, epoch: 3, loss: 1.273440
global_step: 16086, epoch: 3, loss: 1.379006
global_step: 16087, epoch: 3, loss: 1.269841
global_step: 16088, epoch: 3, loss: 1.236806
global_step: 16089, epoch: 3, loss: 1.331096
global_step: 16090, epoch: 3, loss: 1.274608
global_step: 16091, epoch: 3, loss: 1.282353
global_step: 16092, epoch: 3, loss: 1.252581
global_step: 16093, epoch: 3, loss: 1.275264
global_step: 16094, epoch: 3, loss: 1.210016
global_step: 16095, epoch: 3, loss: 1.216503
global_step: 16096, epoch: 3, loss: 1.279925
global_step: 16097, epoch: 3, loss: 1.230991
global_step: 16098, epoch: 3, loss: 1.292892
global_step: 16099, epoch: 3, loss: 1.296569
global_step: 16100, epoch: 3, loss: 1.358956
global_step: 16101, epoch: 3, loss: 1.157858
global_step: 16102, epoch: 3, loss: 1.333773
global_step: 16103, epoch: 3, loss: 1.205081
global_step: 16104, epoch: 3, loss: 1.303940
global_step: 16105, epoch: 3, loss: 1.305999
global_step: 16106, epoch: 3, loss: 1.250584
global_step: 16107, epoch: 3, loss: 1.217013
global_step: 16108, epoch: 3, loss: 1.306518
global_step: 16109, epoch: 3, loss: 1.332341
global_step: 16110, epoch: 3, loss: 1.171328
global_step: 16111, epoch: 3, loss: 1.407698
global_step: 16112, epoch: 3, loss: 1.281058
global_step: 16113, epoch: 3, loss: 1.240025
global_step: 16114, epoch: 3, loss: 1.269351
global_step: 16115, epoch: 3, loss: 1.308809
global_step: 16116, epoch: 3, loss: 1.185364
global_step: 16117, epoch: 3, loss: 1.359027
global_step: 16118, epoch: 3, loss: 1.320148
global_step: 16119, epoch: 3, loss: 1.343251
global_step: 16120, epoch: 3, loss: 0.684989
epoch: 3
train	acc: 0.5736	macro: p 0.4316, r 0.2810, f1: 0.2462	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.4962
dev	acc: 0.5257	macro: p 0.3465, r 0.2762, f1: 0.2368	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4350
test	acc: 0.5602	macro: p 0.3710, r 0.2756, f1: 0.2329	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.4796
New best model!
global_step: 16121, epoch: 4, loss: 1.369683
global_step: 16122, epoch: 4, loss: 1.352640
global_step: 16123, epoch: 4, loss: 1.248975
global_step: 16124, epoch: 4, loss: 1.275965
global_step: 16125, epoch: 4, loss: 1.247988
global_step: 16126, epoch: 4, loss: 1.274458
global_step: 16127, epoch: 4, loss: 1.207825
global_step: 16128, epoch: 4, loss: 1.122617
global_step: 16129, epoch: 4, loss: 1.197724
global_step: 16130, epoch: 4, loss: 1.154863
global_step: 16131, epoch: 4, loss: 1.348155
global_step: 16132, epoch: 4, loss: 1.197045
global_step: 16133, epoch: 4, loss: 1.205301
global_step: 16134, epoch: 4, loss: 1.245794
global_step: 16135, epoch: 4, loss: 1.238134
global_step: 16136, epoch: 4, loss: 1.271757
global_step: 16137, epoch: 4, loss: 1.160542
global_step: 16138, epoch: 4, loss: 1.221639
global_step: 16139, epoch: 4, loss: 1.270410
global_step: 16140, epoch: 4, loss: 1.119740
global_step: 16141, epoch: 4, loss: 1.345753
global_step: 16142, epoch: 4, loss: 1.343238
global_step: 16143, epoch: 4, loss: 1.268927
global_step: 16144, epoch: 4, loss: 1.298374
global_step: 16145, epoch: 4, loss: 1.284203
global_step: 16146, epoch: 4, loss: 1.217318
global_step: 16147, epoch: 4, loss: 1.174870
global_step: 16148, epoch: 4, loss: 1.188384
global_step: 16149, epoch: 4, loss: 1.261621
global_step: 16150, epoch: 4, loss: 1.154562
global_step: 16151, epoch: 4, loss: 1.353160
global_step: 16152, epoch: 4, loss: 1.265117
global_step: 16153, epoch: 4, loss: 1.223155
global_step: 16154, epoch: 4, loss: 1.313306
global_step: 16155, epoch: 4, loss: 1.190348
global_step: 16156, epoch: 4, loss: 1.194802
global_step: 16157, epoch: 4, loss: 1.209102
global_step: 16158, epoch: 4, loss: 1.140856
global_step: 16159, epoch: 4, loss: 1.293453
global_step: 16160, epoch: 4, loss: 1.682201
epoch: 4
train	acc: 0.5739	macro: p 0.4198, r 0.2932, f1: 0.2801	micro: p 0.5739, r 0.5739, f1 0.5739	weighted_f1:0.5133
dev	acc: 0.5104	macro: p 0.3550, r 0.2582, f1: 0.2447	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4421
test	acc: 0.5835	macro: p 0.4244, r 0.2879, f1: 0.2823	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5238
New best model!
global_step: 16161, epoch: 5, loss: 1.383171
global_step: 16162, epoch: 5, loss: 1.059743
global_step: 16163, epoch: 5, loss: 1.149560
global_step: 16164, epoch: 5, loss: 1.235036
global_step: 16165, epoch: 5, loss: 1.298591
global_step: 16166, epoch: 5, loss: 1.191471
global_step: 16167, epoch: 5, loss: 1.037509
global_step: 16168, epoch: 5, loss: 1.133774
global_step: 16169, epoch: 5, loss: 1.212123
global_step: 16170, epoch: 5, loss: 1.329343
global_step: 16171, epoch: 5, loss: 1.246555
global_step: 16172, epoch: 5, loss: 1.239646
global_step: 16173, epoch: 5, loss: 1.150418
global_step: 16174, epoch: 5, loss: 1.137220
global_step: 16175, epoch: 5, loss: 1.170484
global_step: 16176, epoch: 5, loss: 1.290224
global_step: 16177, epoch: 5, loss: 1.159510
global_step: 16178, epoch: 5, loss: 1.153548
global_step: 16179, epoch: 5, loss: 1.223494
global_step: 16180, epoch: 5, loss: 1.102003
global_step: 16181, epoch: 5, loss: 1.277024
global_step: 16182, epoch: 5, loss: 1.154666
global_step: 16183, epoch: 5, loss: 1.159126
global_step: 16184, epoch: 5, loss: 1.147356
global_step: 16185, epoch: 5, loss: 1.313282
global_step: 16186, epoch: 5, loss: 1.287125
global_step: 16187, epoch: 5, loss: 1.212163
global_step: 16188, epoch: 5, loss: 1.060240
global_step: 16189, epoch: 5, loss: 1.260713
global_step: 16190, epoch: 5, loss: 1.202996
global_step: 16191, epoch: 5, loss: 1.151315
global_step: 16192, epoch: 5, loss: 1.280083
global_step: 16193, epoch: 5, loss: 1.198976
global_step: 16194, epoch: 5, loss: 1.024024
global_step: 16195, epoch: 5, loss: 1.191749
global_step: 16196, epoch: 5, loss: 1.240359
global_step: 16197, epoch: 5, loss: 1.196737
global_step: 16198, epoch: 5, loss: 1.188779
global_step: 16199, epoch: 5, loss: 1.227250
global_step: 16200, epoch: 5, loss: 1.153551
epoch: 5
train	acc: 0.6178	macro: p 0.4409, r 0.3201, f1: 0.3333	micro: p 0.6178, r 0.6178, f1 0.6178	weighted_f1:0.5646
dev	acc: 0.5347	macro: p 0.3510, r 0.2758, f1: 0.2624	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4605
test	acc: 0.5954	macro: p 0.3945, r 0.2947, f1: 0.2993	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5370
New best model!
global_step: 16201, epoch: 6, loss: 1.112197
global_step: 16202, epoch: 6, loss: 1.153869
global_step: 16203, epoch: 6, loss: 1.264270
global_step: 16204, epoch: 6, loss: 1.127265
global_step: 16205, epoch: 6, loss: 1.136847
global_step: 16206, epoch: 6, loss: 1.196020
global_step: 16207, epoch: 6, loss: 1.273034
global_step: 16208, epoch: 6, loss: 1.107363
global_step: 16209, epoch: 6, loss: 1.081315
global_step: 16210, epoch: 6, loss: 1.078452
global_step: 16211, epoch: 6, loss: 1.206429
global_step: 16212, epoch: 6, loss: 1.166273
global_step: 16213, epoch: 6, loss: 1.248504
global_step: 16214, epoch: 6, loss: 1.059176
global_step: 16215, epoch: 6, loss: 1.126852
global_step: 16216, epoch: 6, loss: 1.244048
global_step: 16217, epoch: 6, loss: 1.200593
global_step: 16218, epoch: 6, loss: 1.181295
global_step: 16219, epoch: 6, loss: 1.188977
global_step: 16220, epoch: 6, loss: 1.156684
global_step: 16221, epoch: 6, loss: 1.141832
global_step: 16222, epoch: 6, loss: 1.160102
global_step: 16223, epoch: 6, loss: 1.245552
global_step: 16224, epoch: 6, loss: 1.012130
global_step: 16225, epoch: 6, loss: 1.144482
global_step: 16226, epoch: 6, loss: 1.155511
global_step: 16227, epoch: 6, loss: 1.266313
global_step: 16228, epoch: 6, loss: 1.127474
global_step: 16229, epoch: 6, loss: 1.200271
global_step: 16230, epoch: 6, loss: 1.161029
global_step: 16231, epoch: 6, loss: 0.959364
global_step: 16232, epoch: 6, loss: 1.199303
global_step: 16233, epoch: 6, loss: 1.086896
global_step: 16234, epoch: 6, loss: 1.099150
global_step: 16235, epoch: 6, loss: 1.101724
global_step: 16236, epoch: 6, loss: 1.196706
global_step: 16237, epoch: 6, loss: 1.179884
global_step: 16238, epoch: 6, loss: 1.205008
global_step: 16239, epoch: 6, loss: 1.084545
global_step: 16240, epoch: 6, loss: 1.015103
epoch: 6
train	acc: 0.6397	macro: p 0.4288, r 0.3492, f1: 0.3598	micro: p 0.6397, r 0.6397, f1 0.6397	weighted_f1:0.5893
dev	acc: 0.5410	macro: p 0.3218, r 0.2876, f1: 0.2690	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4649
test	acc: 0.5900	macro: p 0.3443, r 0.2980, f1: 0.2928	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5283
New best model!
global_step: 16241, epoch: 7, loss: 1.268786
global_step: 16242, epoch: 7, loss: 1.070276
global_step: 16243, epoch: 7, loss: 1.095211
global_step: 16244, epoch: 7, loss: 1.063165
global_step: 16245, epoch: 7, loss: 1.177590
global_step: 16246, epoch: 7, loss: 1.154727
global_step: 16247, epoch: 7, loss: 1.086100
global_step: 16248, epoch: 7, loss: 1.068373
global_step: 16249, epoch: 7, loss: 1.001899
global_step: 16250, epoch: 7, loss: 1.076326
global_step: 16251, epoch: 7, loss: 1.073902
global_step: 16252, epoch: 7, loss: 1.133940
global_step: 16253, epoch: 7, loss: 1.176179
global_step: 16254, epoch: 7, loss: 1.092216
global_step: 16255, epoch: 7, loss: 1.122108
global_step: 16256, epoch: 7, loss: 1.121931
global_step: 16257, epoch: 7, loss: 1.011618
global_step: 16258, epoch: 7, loss: 1.141225
global_step: 16259, epoch: 7, loss: 1.137920
global_step: 16260, epoch: 7, loss: 1.078544
global_step: 16261, epoch: 7, loss: 1.191187
global_step: 16262, epoch: 7, loss: 1.139611
global_step: 16263, epoch: 7, loss: 1.304749
global_step: 16264, epoch: 7, loss: 1.098324
global_step: 16265, epoch: 7, loss: 1.012185
global_step: 16266, epoch: 7, loss: 0.999955
global_step: 16267, epoch: 7, loss: 1.139242
global_step: 16268, epoch: 7, loss: 1.117746
global_step: 16269, epoch: 7, loss: 1.090925
global_step: 16270, epoch: 7, loss: 1.247070
global_step: 16271, epoch: 7, loss: 1.129913
global_step: 16272, epoch: 7, loss: 1.187106
global_step: 16273, epoch: 7, loss: 1.186111
global_step: 16274, epoch: 7, loss: 1.007675
global_step: 16275, epoch: 7, loss: 1.056239
global_step: 16276, epoch: 7, loss: 1.099513
global_step: 16277, epoch: 7, loss: 1.120086
global_step: 16278, epoch: 7, loss: 1.161298
global_step: 16279, epoch: 7, loss: 1.106424
global_step: 16280, epoch: 7, loss: 0.999920
epoch: 7
train	acc: 0.6126	macro: p 0.4799, r 0.3030, f1: 0.3224	micro: p 0.6126, r 0.6126, f1 0.6126	weighted_f1:0.5494
dev	acc: 0.5230	macro: p 0.4306, r 0.2520, f1: 0.2422	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4340
test	acc: 0.5870	macro: p 0.4091, r 0.2705, f1: 0.2779	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5126
global_step: 16281, epoch: 8, loss: 1.361366
global_step: 16282, epoch: 8, loss: 1.048690
global_step: 16283, epoch: 8, loss: 1.178433
global_step: 16284, epoch: 8, loss: 1.154935
global_step: 16285, epoch: 8, loss: 1.017934
global_step: 16286, epoch: 8, loss: 1.039074
global_step: 16287, epoch: 8, loss: 0.949986
global_step: 16288, epoch: 8, loss: 1.031353
global_step: 16289, epoch: 8, loss: 0.931010
global_step: 16290, epoch: 8, loss: 1.026066
global_step: 16291, epoch: 8, loss: 1.090885
global_step: 16292, epoch: 8, loss: 0.984591
global_step: 16293, epoch: 8, loss: 1.132959
global_step: 16294, epoch: 8, loss: 1.081261
global_step: 16295, epoch: 8, loss: 1.029550
global_step: 16296, epoch: 8, loss: 1.107273
global_step: 16297, epoch: 8, loss: 1.166135
global_step: 16298, epoch: 8, loss: 1.083062
global_step: 16299, epoch: 8, loss: 1.064948
global_step: 16300, epoch: 8, loss: 1.074615
global_step: 16301, epoch: 8, loss: 1.275501
global_step: 16302, epoch: 8, loss: 1.117510
global_step: 16303, epoch: 8, loss: 1.120015
global_step: 16304, epoch: 8, loss: 1.088071
global_step: 16305, epoch: 8, loss: 1.115034
global_step: 16306, epoch: 8, loss: 1.088970
global_step: 16307, epoch: 8, loss: 1.161375
global_step: 16308, epoch: 8, loss: 1.108771
global_step: 16309, epoch: 8, loss: 1.048365
global_step: 16310, epoch: 8, loss: 0.993953
global_step: 16311, epoch: 8, loss: 1.018359
global_step: 16312, epoch: 8, loss: 1.062514
global_step: 16313, epoch: 8, loss: 1.070103
global_step: 16314, epoch: 8, loss: 1.137045
global_step: 16315, epoch: 8, loss: 1.070604
global_step: 16316, epoch: 8, loss: 1.030611
global_step: 16317, epoch: 8, loss: 1.114978
global_step: 16318, epoch: 8, loss: 0.996017
global_step: 16319, epoch: 8, loss: 0.933376
global_step: 16320, epoch: 8, loss: 0.843637
epoch: 8
train	acc: 0.7000	macro: p 0.4840, r 0.4238, f1: 0.4247	micro: p 0.7000, r 0.7000, f1 0.7000	weighted_f1:0.6654
dev	acc: 0.5428	macro: p 0.3523, r 0.3018, f1: 0.2951	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4918
test	acc: 0.5992	macro: p 0.3821, r 0.3209, f1: 0.3219	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5574
New best model!
global_step: 16321, epoch: 9, loss: 0.980440
global_step: 16322, epoch: 9, loss: 1.100291
global_step: 16323, epoch: 9, loss: 1.030454
global_step: 16324, epoch: 9, loss: 0.969416
global_step: 16325, epoch: 9, loss: 0.983061
global_step: 16326, epoch: 9, loss: 1.000087
global_step: 16327, epoch: 9, loss: 0.974440
global_step: 16328, epoch: 9, loss: 1.099597
global_step: 16329, epoch: 9, loss: 0.987168
global_step: 16330, epoch: 9, loss: 1.043225
global_step: 16331, epoch: 9, loss: 1.099828
global_step: 16332, epoch: 9, loss: 1.114325
global_step: 16333, epoch: 9, loss: 0.987750
global_step: 16334, epoch: 9, loss: 0.998034
global_step: 16335, epoch: 9, loss: 0.985246
global_step: 16336, epoch: 9, loss: 1.105569
global_step: 16337, epoch: 9, loss: 1.021392
global_step: 16338, epoch: 9, loss: 1.000201
global_step: 16339, epoch: 9, loss: 1.069551
global_step: 16340, epoch: 9, loss: 0.941648
global_step: 16341, epoch: 9, loss: 0.992354
global_step: 16342, epoch: 9, loss: 1.101144
global_step: 16343, epoch: 9, loss: 1.071712
global_step: 16344, epoch: 9, loss: 0.956734
global_step: 16345, epoch: 9, loss: 1.025483
global_step: 16346, epoch: 9, loss: 1.025770
global_step: 16347, epoch: 9, loss: 1.051661
global_step: 16348, epoch: 9, loss: 1.003776
global_step: 16349, epoch: 9, loss: 1.058767
global_step: 16350, epoch: 9, loss: 0.954514
global_step: 16351, epoch: 9, loss: 1.138872
global_step: 16352, epoch: 9, loss: 1.115677
global_step: 16353, epoch: 9, loss: 1.024751
global_step: 16354, epoch: 9, loss: 1.104233
global_step: 16355, epoch: 9, loss: 1.033057
global_step: 16356, epoch: 9, loss: 0.933467
global_step: 16357, epoch: 9, loss: 1.029161
global_step: 16358, epoch: 9, loss: 1.046706
global_step: 16359, epoch: 9, loss: 1.078893
global_step: 16360, epoch: 9, loss: 0.198488
epoch: 9
train	acc: 0.6652	macro: p 0.5004, r 0.3732, f1: 0.3913	micro: p 0.6652, r 0.6652, f1 0.6652	weighted_f1:0.6166
dev	acc: 0.5464	macro: p 0.4268, r 0.2855, f1: 0.2799	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4738
test	acc: 0.5969	macro: p 0.3876, r 0.2943, f1: 0.2992	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5335
global_step: 16361, epoch: 10, loss: 0.981931
global_step: 16362, epoch: 10, loss: 1.000694
global_step: 16363, epoch: 10, loss: 0.923828
global_step: 16364, epoch: 10, loss: 1.010489
global_step: 16365, epoch: 10, loss: 0.875489
global_step: 16366, epoch: 10, loss: 1.059152
global_step: 16367, epoch: 10, loss: 0.984414
global_step: 16368, epoch: 10, loss: 0.954126
global_step: 16369, epoch: 10, loss: 0.938666
global_step: 16370, epoch: 10, loss: 0.939170
global_step: 16371, epoch: 10, loss: 0.843211
global_step: 16372, epoch: 10, loss: 0.856927
global_step: 16373, epoch: 10, loss: 0.890357
global_step: 16374, epoch: 10, loss: 1.005374
global_step: 16375, epoch: 10, loss: 0.959151
global_step: 16376, epoch: 10, loss: 1.039786
global_step: 16377, epoch: 10, loss: 1.143201
global_step: 16378, epoch: 10, loss: 1.045256
global_step: 16379, epoch: 10, loss: 1.044979
global_step: 16380, epoch: 10, loss: 0.959668
global_step: 16381, epoch: 10, loss: 1.068214
global_step: 16382, epoch: 10, loss: 0.890220
global_step: 16383, epoch: 10, loss: 1.111410
global_step: 16384, epoch: 10, loss: 1.117177
global_step: 16385, epoch: 10, loss: 1.017570
global_step: 16386, epoch: 10, loss: 1.044209
global_step: 16387, epoch: 10, loss: 0.981686
global_step: 16388, epoch: 10, loss: 1.044360
global_step: 16389, epoch: 10, loss: 1.013216
global_step: 16390, epoch: 10, loss: 1.070339
global_step: 16391, epoch: 10, loss: 1.047350
global_step: 16392, epoch: 10, loss: 0.974965
global_step: 16393, epoch: 10, loss: 1.025567
global_step: 16394, epoch: 10, loss: 1.087012
global_step: 16395, epoch: 10, loss: 0.908331
global_step: 16396, epoch: 10, loss: 0.925176
global_step: 16397, epoch: 10, loss: 0.976662
global_step: 16398, epoch: 10, loss: 1.007913
global_step: 16399, epoch: 10, loss: 1.099373
global_step: 16400, epoch: 10, loss: 1.463806
epoch: 10
train	acc: 0.6899	macro: p 0.6005, r 0.5049, f1: 0.4589	micro: p 0.6899, r 0.6899, f1 0.6899	weighted_f1:0.6804
dev	acc: 0.4923	macro: p 0.3246, r 0.3243, f1: 0.3110	micro: p 0.4923, r 0.4923, f1 0.4923	weighted_f1:0.4822
test	acc: 0.5245	macro: p 0.3347, r 0.3439, f1: 0.3227	micro: p 0.5245, r 0.5245, f1 0.5245	weighted_f1:0.5241
global_step: 16401, epoch: 11, loss: 1.056573
global_step: 16402, epoch: 11, loss: 1.033111
global_step: 16403, epoch: 11, loss: 0.897953
global_step: 16404, epoch: 11, loss: 0.961111
global_step: 16405, epoch: 11, loss: 0.915130
global_step: 16406, epoch: 11, loss: 1.074505
global_step: 16407, epoch: 11, loss: 0.923094
global_step: 16408, epoch: 11, loss: 0.977162
global_step: 16409, epoch: 11, loss: 0.975866
global_step: 16410, epoch: 11, loss: 0.977688
global_step: 16411, epoch: 11, loss: 1.001800
global_step: 16412, epoch: 11, loss: 0.999933
global_step: 16413, epoch: 11, loss: 0.895599
global_step: 16414, epoch: 11, loss: 0.906247
global_step: 16415, epoch: 11, loss: 0.893148
global_step: 16416, epoch: 11, loss: 0.973416
global_step: 16417, epoch: 11, loss: 0.993023
global_step: 16418, epoch: 11, loss: 0.823567
global_step: 16419, epoch: 11, loss: 1.011574
global_step: 16420, epoch: 11, loss: 0.932939
global_step: 16421, epoch: 11, loss: 0.990857
global_step: 16422, epoch: 11, loss: 0.771545
global_step: 16423, epoch: 11, loss: 0.894123
global_step: 16424, epoch: 11, loss: 0.913126
global_step: 16425, epoch: 11, loss: 0.975593
global_step: 16426, epoch: 11, loss: 0.838695
global_step: 16427, epoch: 11, loss: 0.930647
global_step: 16428, epoch: 11, loss: 0.923176
global_step: 16429, epoch: 11, loss: 0.887479
global_step: 16430, epoch: 11, loss: 0.998447
global_step: 16431, epoch: 11, loss: 0.883789
global_step: 16432, epoch: 11, loss: 0.945055
global_step: 16433, epoch: 11, loss: 1.036014
global_step: 16434, epoch: 11, loss: 1.114164
global_step: 16435, epoch: 11, loss: 1.033177
global_step: 16436, epoch: 11, loss: 0.963033
global_step: 16437, epoch: 11, loss: 1.004151
global_step: 16438, epoch: 11, loss: 0.945431
global_step: 16439, epoch: 11, loss: 0.939376
global_step: 16440, epoch: 11, loss: 0.512831
epoch: 11
train	acc: 0.7599	macro: p 0.7876, r 0.5210, f1: 0.5164	micro: p 0.7599, r 0.7599, f1 0.7599	weighted_f1:0.7356
dev	acc: 0.5365	macro: p 0.3380, r 0.3134, f1: 0.2993	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4883
test	acc: 0.5847	macro: p 0.3534, r 0.3331, f1: 0.3228	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5501
global_step: 16441, epoch: 12, loss: 0.941208
global_step: 16442, epoch: 12, loss: 1.078936
global_step: 16443, epoch: 12, loss: 0.945908
global_step: 16444, epoch: 12, loss: 0.961226
global_step: 16445, epoch: 12, loss: 0.764139
global_step: 16446, epoch: 12, loss: 0.835945
global_step: 16447, epoch: 12, loss: 0.796420
global_step: 16448, epoch: 12, loss: 0.869332
global_step: 16449, epoch: 12, loss: 0.936080
global_step: 16450, epoch: 12, loss: 0.940615
global_step: 16451, epoch: 12, loss: 0.873875
global_step: 16452, epoch: 12, loss: 0.886055
global_step: 16453, epoch: 12, loss: 0.902492
global_step: 16454, epoch: 12, loss: 0.844606
global_step: 16455, epoch: 12, loss: 0.878224
global_step: 16456, epoch: 12, loss: 0.921004
global_step: 16457, epoch: 12, loss: 0.917718
global_step: 16458, epoch: 12, loss: 0.862264
global_step: 16459, epoch: 12, loss: 1.048630
global_step: 16460, epoch: 12, loss: 0.845958
global_step: 16461, epoch: 12, loss: 0.892837
global_step: 16462, epoch: 12, loss: 0.914251
global_step: 16463, epoch: 12, loss: 0.882696
global_step: 16464, epoch: 12, loss: 0.995992
global_step: 16465, epoch: 12, loss: 1.014267
global_step: 16466, epoch: 12, loss: 0.882887
global_step: 16467, epoch: 12, loss: 0.955293
global_step: 16468, epoch: 12, loss: 0.852753
global_step: 16469, epoch: 12, loss: 0.984173
global_step: 16470, epoch: 12, loss: 0.810083
global_step: 16471, epoch: 12, loss: 0.865205
global_step: 16472, epoch: 12, loss: 1.065163
global_step: 16473, epoch: 12, loss: 0.803109
global_step: 16474, epoch: 12, loss: 0.846714
global_step: 16475, epoch: 12, loss: 0.930971
global_step: 16476, epoch: 12, loss: 0.831912
global_step: 16477, epoch: 12, loss: 0.934176
global_step: 16478, epoch: 12, loss: 0.892426
global_step: 16479, epoch: 12, loss: 0.860666
global_step: 16480, epoch: 12, loss: 1.598161
epoch: 12
train	acc: 0.7224	macro: p 0.6283, r 0.5816, f1: 0.5701	micro: p 0.7224, r 0.7224, f1 0.7224	weighted_f1:0.7328
dev	acc: 0.5005	macro: p 0.3627, r 0.3383, f1: 0.3320	micro: p 0.5005, r 0.5005, f1 0.5005	weighted_f1:0.4938
test	acc: 0.5080	macro: p 0.3579, r 0.3359, f1: 0.3278	micro: p 0.5080, r 0.5080, f1 0.5080	weighted_f1:0.5203
New best model!
global_step: 16481, epoch: 13, loss: 1.040006
global_step: 16482, epoch: 13, loss: 0.839596
global_step: 16483, epoch: 13, loss: 0.891849
global_step: 16484, epoch: 13, loss: 0.859807
global_step: 16485, epoch: 13, loss: 0.899118
global_step: 16486, epoch: 13, loss: 0.805675
global_step: 16487, epoch: 13, loss: 0.766586
global_step: 16488, epoch: 13, loss: 0.859048
global_step: 16489, epoch: 13, loss: 0.910381
global_step: 16490, epoch: 13, loss: 0.932363
global_step: 16491, epoch: 13, loss: 0.932131
global_step: 16492, epoch: 13, loss: 0.823218
global_step: 16493, epoch: 13, loss: 0.721527
global_step: 16494, epoch: 13, loss: 0.849593
global_step: 16495, epoch: 13, loss: 0.888751
global_step: 16496, epoch: 13, loss: 0.932152
global_step: 16497, epoch: 13, loss: 0.727730
global_step: 16498, epoch: 13, loss: 0.870778
global_step: 16499, epoch: 13, loss: 0.862066
global_step: 16500, epoch: 13, loss: 0.932502
global_step: 16501, epoch: 13, loss: 0.749636
global_step: 16502, epoch: 13, loss: 0.929570
global_step: 16503, epoch: 13, loss: 0.795760
global_step: 16504, epoch: 13, loss: 0.846422
global_step: 16505, epoch: 13, loss: 0.843457
global_step: 16506, epoch: 13, loss: 0.839739
global_step: 16507, epoch: 13, loss: 0.830481
global_step: 16508, epoch: 13, loss: 0.853538
global_step: 16509, epoch: 13, loss: 0.875909
global_step: 16510, epoch: 13, loss: 0.839146
global_step: 16511, epoch: 13, loss: 0.880422
global_step: 16512, epoch: 13, loss: 0.797884
global_step: 16513, epoch: 13, loss: 0.981196
global_step: 16514, epoch: 13, loss: 0.897435
global_step: 16515, epoch: 13, loss: 0.894655
global_step: 16516, epoch: 13, loss: 0.904729
global_step: 16517, epoch: 13, loss: 0.902421
global_step: 16518, epoch: 13, loss: 0.903981
global_step: 16519, epoch: 13, loss: 0.772337
global_step: 16520, epoch: 13, loss: 0.125957
epoch: 13
train	acc: 0.7779	macro: p 0.8382, r 0.5296, f1: 0.5645	micro: p 0.7779, r 0.7779, f1 0.7779	weighted_f1:0.7547
dev	acc: 0.5365	macro: p 0.3347, r 0.2902, f1: 0.2732	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4686
test	acc: 0.5881	macro: p 0.3630, r 0.3032, f1: 0.2993	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5332
global_step: 16521, epoch: 14, loss: 0.941344
global_step: 16522, epoch: 14, loss: 0.855059
global_step: 16523, epoch: 14, loss: 0.749526
global_step: 16524, epoch: 14, loss: 0.874437
global_step: 16525, epoch: 14, loss: 0.765336
global_step: 16526, epoch: 14, loss: 0.796901
global_step: 16527, epoch: 14, loss: 0.771528
global_step: 16528, epoch: 14, loss: 0.749925
global_step: 16529, epoch: 14, loss: 0.820934
global_step: 16530, epoch: 14, loss: 0.903399
global_step: 16531, epoch: 14, loss: 0.832331
global_step: 16532, epoch: 14, loss: 0.748613
global_step: 16533, epoch: 14, loss: 0.849916
global_step: 16534, epoch: 14, loss: 0.879074
global_step: 16535, epoch: 14, loss: 0.857328
global_step: 16536, epoch: 14, loss: 0.814645
global_step: 16537, epoch: 14, loss: 0.720943
global_step: 16538, epoch: 14, loss: 0.927896
global_step: 16539, epoch: 14, loss: 0.866202
global_step: 16540, epoch: 14, loss: 0.737532
global_step: 16541, epoch: 14, loss: 0.873331
global_step: 16542, epoch: 14, loss: 0.765366
global_step: 16543, epoch: 14, loss: 0.849343
global_step: 16544, epoch: 14, loss: 0.756862
global_step: 16545, epoch: 14, loss: 0.881498
global_step: 16546, epoch: 14, loss: 0.733932
global_step: 16547, epoch: 14, loss: 0.907446
global_step: 16548, epoch: 14, loss: 0.868678
global_step: 16549, epoch: 14, loss: 0.903251
global_step: 16550, epoch: 14, loss: 0.838189
global_step: 16551, epoch: 14, loss: 0.911642
global_step: 16552, epoch: 14, loss: 0.785210
global_step: 16553, epoch: 14, loss: 0.833506
global_step: 16554, epoch: 14, loss: 0.952856
global_step: 16555, epoch: 14, loss: 0.926187
global_step: 16556, epoch: 14, loss: 0.865110
global_step: 16557, epoch: 14, loss: 0.732021
global_step: 16558, epoch: 14, loss: 0.973486
global_step: 16559, epoch: 14, loss: 0.844558
global_step: 16560, epoch: 14, loss: 0.263496
epoch: 14
train	acc: 0.7404	macro: p 0.8345, r 0.4782, f1: 0.5210	micro: p 0.7404, r 0.7404, f1 0.7404	weighted_f1:0.7098
dev	acc: 0.5347	macro: p 0.3817, r 0.2818, f1: 0.2559	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4541
test	acc: 0.5820	macro: p 0.3793, r 0.2840, f1: 0.2666	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5071
global_step: 16561, epoch: 15, loss: 0.955424
global_step: 16562, epoch: 15, loss: 0.738227
global_step: 16563, epoch: 15, loss: 0.710543
global_step: 16564, epoch: 15, loss: 0.811385
global_step: 16565, epoch: 15, loss: 0.804629
global_step: 16566, epoch: 15, loss: 0.730828
global_step: 16567, epoch: 15, loss: 0.729057
global_step: 16568, epoch: 15, loss: 0.817723
global_step: 16569, epoch: 15, loss: 0.769327
global_step: 16570, epoch: 15, loss: 0.812305
global_step: 16571, epoch: 15, loss: 0.828939
global_step: 16572, epoch: 15, loss: 0.729086
global_step: 16573, epoch: 15, loss: 0.745592
global_step: 16574, epoch: 15, loss: 0.697114
global_step: 16575, epoch: 15, loss: 0.842934
global_step: 16576, epoch: 15, loss: 0.893376
global_step: 16577, epoch: 15, loss: 0.842506
global_step: 16578, epoch: 15, loss: 0.719640
global_step: 16579, epoch: 15, loss: 0.752786
global_step: 16580, epoch: 15, loss: 0.815690
global_step: 16581, epoch: 15, loss: 0.796702
global_step: 16582, epoch: 15, loss: 0.759301
global_step: 16583, epoch: 15, loss: 0.779829
global_step: 16584, epoch: 15, loss: 0.804775
global_step: 16585, epoch: 15, loss: 0.789183
global_step: 16586, epoch: 15, loss: 0.767164
global_step: 16587, epoch: 15, loss: 0.848892
global_step: 16588, epoch: 15, loss: 0.794567
global_step: 16589, epoch: 15, loss: 0.831521
global_step: 16590, epoch: 15, loss: 0.933339
global_step: 16591, epoch: 15, loss: 0.833154
global_step: 16592, epoch: 15, loss: 0.796207
global_step: 16593, epoch: 15, loss: 0.907315
global_step: 16594, epoch: 15, loss: 0.832372
global_step: 16595, epoch: 15, loss: 0.810973
global_step: 16596, epoch: 15, loss: 0.870521
global_step: 16597, epoch: 15, loss: 0.831913
global_step: 16598, epoch: 15, loss: 0.824052
global_step: 16599, epoch: 15, loss: 0.826123
global_step: 16600, epoch: 15, loss: 0.509011
epoch: 15
train	acc: 0.8389	macro: p 0.8562, r 0.6782, f1: 0.7215	micro: p 0.8389, r 0.8389, f1 0.8389	weighted_f1:0.8320
dev	acc: 0.5140	macro: p 0.3844, r 0.3001, f1: 0.2883	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4714
test	acc: 0.5701	macro: p 0.3681, r 0.3192, f1: 0.3124	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5379
global_step: 16601, epoch: 16, loss: 0.742488
global_step: 16602, epoch: 16, loss: 0.794720
global_step: 16603, epoch: 16, loss: 0.784306
global_step: 16604, epoch: 16, loss: 0.627675
global_step: 16605, epoch: 16, loss: 0.705658
global_step: 16606, epoch: 16, loss: 0.703925
global_step: 16607, epoch: 16, loss: 0.665794
global_step: 16608, epoch: 16, loss: 0.612643
global_step: 16609, epoch: 16, loss: 0.713717
global_step: 16610, epoch: 16, loss: 0.801413
global_step: 16611, epoch: 16, loss: 0.726371
global_step: 16612, epoch: 16, loss: 0.877797
global_step: 16613, epoch: 16, loss: 0.799658
global_step: 16614, epoch: 16, loss: 0.819409
global_step: 16615, epoch: 16, loss: 0.615899
global_step: 16616, epoch: 16, loss: 0.734809
global_step: 16617, epoch: 16, loss: 0.782383
global_step: 16618, epoch: 16, loss: 0.842399
global_step: 16619, epoch: 16, loss: 0.788113
global_step: 16620, epoch: 16, loss: 0.847749
global_step: 16621, epoch: 16, loss: 0.831173
global_step: 16622, epoch: 16, loss: 0.761466
global_step: 16623, epoch: 16, loss: 0.835164
global_step: 16624, epoch: 16, loss: 0.790764
global_step: 16625, epoch: 16, loss: 0.891157
global_step: 16626, epoch: 16, loss: 0.723685
global_step: 16627, epoch: 16, loss: 0.648675
global_step: 16628, epoch: 16, loss: 0.888488
global_step: 16629, epoch: 16, loss: 0.748583
global_step: 16630, epoch: 16, loss: 0.805843
global_step: 16631, epoch: 16, loss: 0.807028
global_step: 16632, epoch: 16, loss: 0.702295
global_step: 16633, epoch: 16, loss: 0.733187
global_step: 16634, epoch: 16, loss: 0.770438
global_step: 16635, epoch: 16, loss: 0.841282
global_step: 16636, epoch: 16, loss: 0.858318
global_step: 16637, epoch: 16, loss: 0.829119
global_step: 16638, epoch: 16, loss: 0.752934
global_step: 16639, epoch: 16, loss: 0.796908
global_step: 16640, epoch: 16, loss: 0.778683
epoch: 16
train	acc: 0.8418	macro: p 0.8567, r 0.6570, f1: 0.6851	micro: p 0.8418, r 0.8418, f1 0.8418	weighted_f1:0.8299
dev	acc: 0.5185	macro: p 0.3155, r 0.2955, f1: 0.2845	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4684
test	acc: 0.5816	macro: p 0.4781, r 0.3249, f1: 0.3212	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5433
global_step: 16641, epoch: 17, loss: 0.819481
global_step: 16642, epoch: 17, loss: 0.658580
global_step: 16643, epoch: 17, loss: 0.648009
global_step: 16644, epoch: 17, loss: 0.593250
global_step: 16645, epoch: 17, loss: 0.667372
global_step: 16646, epoch: 17, loss: 0.824846
global_step: 16647, epoch: 17, loss: 0.732435
global_step: 16648, epoch: 17, loss: 0.814007
global_step: 16649, epoch: 17, loss: 0.605099
global_step: 16650, epoch: 17, loss: 0.697343
global_step: 16651, epoch: 17, loss: 0.759811
global_step: 16652, epoch: 17, loss: 0.758483
global_step: 16653, epoch: 17, loss: 0.623369
global_step: 16654, epoch: 17, loss: 0.756892
global_step: 16655, epoch: 17, loss: 0.598882
global_step: 16656, epoch: 17, loss: 0.792290
global_step: 16657, epoch: 17, loss: 0.822364
global_step: 16658, epoch: 17, loss: 0.753095
global_step: 16659, epoch: 17, loss: 0.726309
global_step: 16660, epoch: 17, loss: 0.796187
global_step: 16661, epoch: 17, loss: 0.679403
global_step: 16662, epoch: 17, loss: 0.772067
global_step: 16663, epoch: 17, loss: 0.625337
global_step: 16664, epoch: 17, loss: 0.689401
global_step: 16665, epoch: 17, loss: 0.705844
global_step: 16666, epoch: 17, loss: 0.769562
global_step: 16667, epoch: 17, loss: 0.727079
global_step: 16668, epoch: 17, loss: 0.772839
global_step: 16669, epoch: 17, loss: 0.716729
global_step: 16670, epoch: 17, loss: 0.696126
global_step: 16671, epoch: 17, loss: 0.686606
global_step: 16672, epoch: 17, loss: 0.693070
global_step: 16673, epoch: 17, loss: 0.704977
global_step: 16674, epoch: 17, loss: 0.740018
global_step: 16675, epoch: 17, loss: 0.854825
global_step: 16676, epoch: 17, loss: 0.745031
global_step: 16677, epoch: 17, loss: 0.718620
global_step: 16678, epoch: 17, loss: 0.789263
global_step: 16679, epoch: 17, loss: 0.769418
global_step: 16680, epoch: 17, loss: 0.573919
epoch: 17
train	acc: 0.8320	macro: p 0.8468, r 0.7038, f1: 0.7340	micro: p 0.8320, r 0.8320, f1 0.8320	weighted_f1:0.8290
dev	acc: 0.5095	macro: p 0.4717, r 0.2984, f1: 0.2823	micro: p 0.5095, r 0.5095, f1 0.5095	weighted_f1:0.4610
test	acc: 0.5510	macro: p 0.3459, r 0.3124, f1: 0.2980	micro: p 0.5510, r 0.5510, f1 0.5510	weighted_f1:0.5191
global_step: 16681, epoch: 18, loss: 0.711010
global_step: 16682, epoch: 18, loss: 0.794812
global_step: 16683, epoch: 18, loss: 0.702562
global_step: 16684, epoch: 18, loss: 0.627849
global_step: 16685, epoch: 18, loss: 0.700548
global_step: 16686, epoch: 18, loss: 0.675425
global_step: 16687, epoch: 18, loss: 0.610754
global_step: 16688, epoch: 18, loss: 0.662715
global_step: 16689, epoch: 18, loss: 0.535643
global_step: 16690, epoch: 18, loss: 0.649632
global_step: 16691, epoch: 18, loss: 0.645764
global_step: 16692, epoch: 18, loss: 0.700985
global_step: 16693, epoch: 18, loss: 0.652271
global_step: 16694, epoch: 18, loss: 0.793567
global_step: 16695, epoch: 18, loss: 0.703930
global_step: 16696, epoch: 18, loss: 0.617828
global_step: 16697, epoch: 18, loss: 0.717904
global_step: 16698, epoch: 18, loss: 0.681133
global_step: 16699, epoch: 18, loss: 0.579276
global_step: 16700, epoch: 18, loss: 0.704525
global_step: 16701, epoch: 18, loss: 0.739646
global_step: 16702, epoch: 18, loss: 0.621844
global_step: 16703, epoch: 18, loss: 0.748722
global_step: 16704, epoch: 18, loss: 0.714517
global_step: 16705, epoch: 18, loss: 0.650055
global_step: 16706, epoch: 18, loss: 0.691985
global_step: 16707, epoch: 18, loss: 0.677620
global_step: 16708, epoch: 18, loss: 0.644954
global_step: 16709, epoch: 18, loss: 0.745128
global_step: 16710, epoch: 18, loss: 0.762112
global_step: 16711, epoch: 18, loss: 0.739129
global_step: 16712, epoch: 18, loss: 0.776051
global_step: 16713, epoch: 18, loss: 0.682913
global_step: 16714, epoch: 18, loss: 0.787064
global_step: 16715, epoch: 18, loss: 0.694075
global_step: 16716, epoch: 18, loss: 0.764163
global_step: 16717, epoch: 18, loss: 0.629582
global_step: 16718, epoch: 18, loss: 0.651942
global_step: 16719, epoch: 18, loss: 0.624695
global_step: 16720, epoch: 18, loss: 0.823488
epoch: 18
train	acc: 0.8522	macro: p 0.8532, r 0.7101, f1: 0.7477	micro: p 0.8522, r 0.8522, f1 0.8522	weighted_f1:0.8466
dev	acc: 0.5131	macro: p 0.3876, r 0.2989, f1: 0.2834	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4685
test	acc: 0.5548	macro: p 0.3534, r 0.3030, f1: 0.2913	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5223
global_step: 16721, epoch: 19, loss: 0.730307
global_step: 16722, epoch: 19, loss: 0.781024
global_step: 16723, epoch: 19, loss: 0.655406
global_step: 16724, epoch: 19, loss: 0.642170
global_step: 16725, epoch: 19, loss: 0.682342
global_step: 16726, epoch: 19, loss: 0.739731
global_step: 16727, epoch: 19, loss: 0.650961
global_step: 16728, epoch: 19, loss: 0.594985
global_step: 16729, epoch: 19, loss: 0.669839
global_step: 16730, epoch: 19, loss: 0.703106
global_step: 16731, epoch: 19, loss: 0.626354
global_step: 16732, epoch: 19, loss: 0.534903
global_step: 16733, epoch: 19, loss: 0.633741
global_step: 16734, epoch: 19, loss: 0.672043
global_step: 16735, epoch: 19, loss: 0.732228
global_step: 16736, epoch: 19, loss: 0.705311
global_step: 16737, epoch: 19, loss: 0.738053
global_step: 16738, epoch: 19, loss: 0.621492
global_step: 16739, epoch: 19, loss: 0.749104
global_step: 16740, epoch: 19, loss: 0.650408
global_step: 16741, epoch: 19, loss: 0.725376
global_step: 16742, epoch: 19, loss: 0.575493
global_step: 16743, epoch: 19, loss: 0.732942
global_step: 16744, epoch: 19, loss: 0.659458
global_step: 16745, epoch: 19, loss: 0.672797
global_step: 16746, epoch: 19, loss: 0.668325
global_step: 16747, epoch: 19, loss: 0.670779
global_step: 16748, epoch: 19, loss: 0.728056
global_step: 16749, epoch: 19, loss: 0.694417
global_step: 16750, epoch: 19, loss: 0.636691
global_step: 16751, epoch: 19, loss: 0.569897
global_step: 16752, epoch: 19, loss: 0.585578
global_step: 16753, epoch: 19, loss: 0.777604
global_step: 16754, epoch: 19, loss: 0.710465
global_step: 16755, epoch: 19, loss: 0.713286
global_step: 16756, epoch: 19, loss: 0.802413
global_step: 16757, epoch: 19, loss: 0.761459
global_step: 16758, epoch: 19, loss: 0.634797
global_step: 16759, epoch: 19, loss: 0.749508
global_step: 16760, epoch: 19, loss: 0.639601
epoch: 19
train	acc: 0.8963	macro: p 0.8923, r 0.7939, f1: 0.8293	micro: p 0.8963, r 0.8963, f1 0.8963	weighted_f1:0.8940
dev	acc: 0.5338	macro: p 0.3636, r 0.3108, f1: 0.3099	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4927
test	acc: 0.5847	macro: p 0.3943, r 0.3271, f1: 0.3313	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5500
global_step: 16761, epoch: 20, loss: 0.557283
global_step: 16762, epoch: 20, loss: 0.627547
global_step: 16763, epoch: 20, loss: 0.664104
global_step: 16764, epoch: 20, loss: 0.650921
global_step: 16765, epoch: 20, loss: 0.672269
global_step: 16766, epoch: 20, loss: 0.638350
global_step: 16767, epoch: 20, loss: 0.580014
global_step: 16768, epoch: 20, loss: 0.486075
global_step: 16769, epoch: 20, loss: 0.598860
global_step: 16770, epoch: 20, loss: 0.610292
global_step: 16771, epoch: 20, loss: 0.714289
global_step: 16772, epoch: 20, loss: 0.578098
global_step: 16773, epoch: 20, loss: 0.607530
global_step: 16774, epoch: 20, loss: 0.685129
global_step: 16775, epoch: 20, loss: 0.623722
global_step: 16776, epoch: 20, loss: 0.673232
global_step: 16777, epoch: 20, loss: 0.577434
global_step: 16778, epoch: 20, loss: 0.562922
global_step: 16779, epoch: 20, loss: 0.706054
global_step: 16780, epoch: 20, loss: 0.582325
global_step: 16781, epoch: 20, loss: 0.746216
global_step: 16782, epoch: 20, loss: 0.714827
global_step: 16783, epoch: 20, loss: 0.717498
global_step: 16784, epoch: 20, loss: 0.612306
global_step: 16785, epoch: 20, loss: 0.620514
global_step: 16786, epoch: 20, loss: 0.656036
global_step: 16787, epoch: 20, loss: 0.761048
global_step: 16788, epoch: 20, loss: 0.714475
global_step: 16789, epoch: 20, loss: 0.683289
global_step: 16790, epoch: 20, loss: 0.626601
global_step: 16791, epoch: 20, loss: 0.685970
global_step: 16792, epoch: 20, loss: 0.752446
global_step: 16793, epoch: 20, loss: 0.724007
global_step: 16794, epoch: 20, loss: 0.593532
global_step: 16795, epoch: 20, loss: 0.660866
global_step: 16796, epoch: 20, loss: 0.633255
global_step: 16797, epoch: 20, loss: 0.680949
global_step: 16798, epoch: 20, loss: 0.646812
global_step: 16799, epoch: 20, loss: 0.704210
global_step: 16800, epoch: 20, loss: 0.318042
epoch: 20
train	acc: 0.8324	macro: p 0.8415, r 0.6871, f1: 0.6960	micro: p 0.8324, r 0.8324, f1 0.8324	weighted_f1:0.8320
dev	acc: 0.4851	macro: p 0.3050, r 0.2982, f1: 0.2901	micro: p 0.4851, r 0.4851, f1 0.4851	weighted_f1:0.4724
test	acc: 0.5199	macro: p 0.4321, r 0.3289, f1: 0.3221	micro: p 0.5199, r 0.5199, f1 0.5199	weighted_f1:0.5225
global_step: 16801, epoch: 21, loss: 0.839078
global_step: 16802, epoch: 21, loss: 0.609502
global_step: 16803, epoch: 21, loss: 0.708570
global_step: 16804, epoch: 21, loss: 0.544405
global_step: 16805, epoch: 21, loss: 0.739081
global_step: 16806, epoch: 21, loss: 0.561507
global_step: 16807, epoch: 21, loss: 0.597882
global_step: 16808, epoch: 21, loss: 0.569113
global_step: 16809, epoch: 21, loss: 0.603941
global_step: 16810, epoch: 21, loss: 0.561831
global_step: 16811, epoch: 21, loss: 0.591971
global_step: 16812, epoch: 21, loss: 0.613350
global_step: 16813, epoch: 21, loss: 0.629650
global_step: 16814, epoch: 21, loss: 0.631071
global_step: 16815, epoch: 21, loss: 0.618132
global_step: 16816, epoch: 21, loss: 0.631764
global_step: 16817, epoch: 21, loss: 0.670838
global_step: 16818, epoch: 21, loss: 0.658331
global_step: 16819, epoch: 21, loss: 0.526233
global_step: 16820, epoch: 21, loss: 0.736279
global_step: 16821, epoch: 21, loss: 0.709940
global_step: 16822, epoch: 21, loss: 0.648522
global_step: 16823, epoch: 21, loss: 0.671856
global_step: 16824, epoch: 21, loss: 0.622482
global_step: 16825, epoch: 21, loss: 0.682865
global_step: 16826, epoch: 21, loss: 0.549925
global_step: 16827, epoch: 21, loss: 0.693203
global_step: 16828, epoch: 21, loss: 0.579819
global_step: 16829, epoch: 21, loss: 0.609158
global_step: 16830, epoch: 21, loss: 0.751604
global_step: 16831, epoch: 21, loss: 0.738740
global_step: 16832, epoch: 21, loss: 0.560962
global_step: 16833, epoch: 21, loss: 0.594700
global_step: 16834, epoch: 21, loss: 0.676271
global_step: 16835, epoch: 21, loss: 0.598039
global_step: 16836, epoch: 21, loss: 0.590442
global_step: 16837, epoch: 21, loss: 0.619260
global_step: 16838, epoch: 21, loss: 0.687366
global_step: 16839, epoch: 21, loss: 0.713037
global_step: 16840, epoch: 21, loss: 0.936626
epoch: 21
train	acc: 0.8514	macro: p 0.8799, r 0.7443, f1: 0.7808	micro: p 0.8514, r 0.8514, f1 0.8514	weighted_f1:0.8552
dev	acc: 0.4752	macro: p 0.3619, r 0.2912, f1: 0.2700	micro: p 0.4752, r 0.4752, f1 0.4752	weighted_f1:0.4419
test	acc: 0.5130	macro: p 0.3413, r 0.3066, f1: 0.2790	micro: p 0.5130, r 0.5130, f1 0.5130	weighted_f1:0.4965
global_step: 16841, epoch: 22, loss: 0.776986
global_step: 16842, epoch: 22, loss: 0.620238
global_step: 16843, epoch: 22, loss: 0.610813
global_step: 16844, epoch: 22, loss: 0.586948
global_step: 16845, epoch: 22, loss: 0.611627
global_step: 16846, epoch: 22, loss: 0.562173
global_step: 16847, epoch: 22, loss: 0.578400
global_step: 16848, epoch: 22, loss: 0.563046
global_step: 16849, epoch: 22, loss: 0.580433
global_step: 16850, epoch: 22, loss: 0.545949
global_step: 16851, epoch: 22, loss: 0.675381
global_step: 16852, epoch: 22, loss: 0.555731
global_step: 16853, epoch: 22, loss: 0.603832
global_step: 16854, epoch: 22, loss: 0.658043
global_step: 16855, epoch: 22, loss: 0.628167
global_step: 16856, epoch: 22, loss: 0.636415
global_step: 16857, epoch: 22, loss: 0.582446
global_step: 16858, epoch: 22, loss: 0.566087
global_step: 16859, epoch: 22, loss: 0.614584
global_step: 16860, epoch: 22, loss: 0.609488
global_step: 16861, epoch: 22, loss: 0.482888
global_step: 16862, epoch: 22, loss: 0.556860
global_step: 16863, epoch: 22, loss: 0.629994
global_step: 16864, epoch: 22, loss: 0.662750
global_step: 16865, epoch: 22, loss: 0.647301
global_step: 16866, epoch: 22, loss: 0.653722
global_step: 16867, epoch: 22, loss: 0.664857
global_step: 16868, epoch: 22, loss: 0.658679
global_step: 16869, epoch: 22, loss: 0.670646
global_step: 16870, epoch: 22, loss: 0.632538
global_step: 16871, epoch: 22, loss: 0.624602
global_step: 16872, epoch: 22, loss: 0.594657
global_step: 16873, epoch: 22, loss: 0.671460
global_step: 16874, epoch: 22, loss: 0.606462
global_step: 16875, epoch: 22, loss: 0.461033
global_step: 16876, epoch: 22, loss: 0.552485
global_step: 16877, epoch: 22, loss: 0.581309
global_step: 16878, epoch: 22, loss: 0.741307
global_step: 16879, epoch: 22, loss: 0.773460
global_step: 16880, epoch: 22, loss: 0.747459
epoch: 22
train	acc: 0.8960	macro: p 0.8916, r 0.7848, f1: 0.8110	micro: p 0.8960, r 0.8960, f1 0.8960	weighted_f1:0.8936
dev	acc: 0.5248	macro: p 0.3207, r 0.3177, f1: 0.3147	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.5026
test	acc: 0.5533	macro: p 0.3782, r 0.3319, f1: 0.3324	micro: p 0.5533, r 0.5533, f1 0.5533	weighted_f1:0.5430
New best model!
global_step: 16881, epoch: 23, loss: 0.628892
global_step: 16882, epoch: 23, loss: 0.516550
global_step: 16883, epoch: 23, loss: 0.598913
global_step: 16884, epoch: 23, loss: 0.584859
global_step: 16885, epoch: 23, loss: 0.410239
global_step: 16886, epoch: 23, loss: 0.514951
global_step: 16887, epoch: 23, loss: 0.545134
global_step: 16888, epoch: 23, loss: 0.649681
global_step: 16889, epoch: 23, loss: 0.663669
global_step: 16890, epoch: 23, loss: 0.692784
global_step: 16891, epoch: 23, loss: 0.563006
global_step: 16892, epoch: 23, loss: 0.555347
global_step: 16893, epoch: 23, loss: 0.585565
global_step: 16894, epoch: 23, loss: 0.511007
global_step: 16895, epoch: 23, loss: 0.482481
global_step: 16896, epoch: 23, loss: 0.550435
global_step: 16897, epoch: 23, loss: 0.548410
global_step: 16898, epoch: 23, loss: 0.553749
global_step: 16899, epoch: 23, loss: 0.492316
global_step: 16900, epoch: 23, loss: 0.619786
global_step: 16901, epoch: 23, loss: 0.600276
global_step: 16902, epoch: 23, loss: 0.607503
global_step: 16903, epoch: 23, loss: 0.660584
global_step: 16904, epoch: 23, loss: 0.643858
global_step: 16905, epoch: 23, loss: 0.486881
global_step: 16906, epoch: 23, loss: 0.577567
global_step: 16907, epoch: 23, loss: 0.572955
global_step: 16908, epoch: 23, loss: 0.630345
global_step: 16909, epoch: 23, loss: 0.477650
global_step: 16910, epoch: 23, loss: 0.714461
global_step: 16911, epoch: 23, loss: 0.604531
global_step: 16912, epoch: 23, loss: 0.628694
global_step: 16913, epoch: 23, loss: 0.614984
global_step: 16914, epoch: 23, loss: 0.694827
global_step: 16915, epoch: 23, loss: 0.583719
global_step: 16916, epoch: 23, loss: 0.549649
global_step: 16917, epoch: 23, loss: 0.595787
global_step: 16918, epoch: 23, loss: 0.557175
global_step: 16919, epoch: 23, loss: 0.595013
global_step: 16920, epoch: 23, loss: 0.714568
epoch: 23
train	acc: 0.9115	macro: p 0.9269, r 0.8270, f1: 0.8668	micro: p 0.9115, r 0.9115, f1 0.9115	weighted_f1:0.9096
dev	acc: 0.5284	macro: p 0.3929, r 0.2888, f1: 0.2909	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4741
test	acc: 0.5766	macro: p 0.3851, r 0.3010, f1: 0.3125	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5295
global_step: 16921, epoch: 24, loss: 0.503232
global_step: 16922, epoch: 24, loss: 0.659917
global_step: 16923, epoch: 24, loss: 0.525527
global_step: 16924, epoch: 24, loss: 0.603699
global_step: 16925, epoch: 24, loss: 0.622155
global_step: 16926, epoch: 24, loss: 0.512185
global_step: 16927, epoch: 24, loss: 0.487778
global_step: 16928, epoch: 24, loss: 0.497245
global_step: 16929, epoch: 24, loss: 0.504230
global_step: 16930, epoch: 24, loss: 0.526224
global_step: 16931, epoch: 24, loss: 0.606878
global_step: 16932, epoch: 24, loss: 0.505172
global_step: 16933, epoch: 24, loss: 0.537664
global_step: 16934, epoch: 24, loss: 0.531321
global_step: 16935, epoch: 24, loss: 0.645432
global_step: 16936, epoch: 24, loss: 0.585396
global_step: 16937, epoch: 24, loss: 0.581580
global_step: 16938, epoch: 24, loss: 0.574425
global_step: 16939, epoch: 24, loss: 0.577942
global_step: 16940, epoch: 24, loss: 0.596918
global_step: 16941, epoch: 24, loss: 0.612836
global_step: 16942, epoch: 24, loss: 0.510654
global_step: 16943, epoch: 24, loss: 0.519614
global_step: 16944, epoch: 24, loss: 0.589372
global_step: 16945, epoch: 24, loss: 0.567566
global_step: 16946, epoch: 24, loss: 0.542832
global_step: 16947, epoch: 24, loss: 0.569965
global_step: 16948, epoch: 24, loss: 0.611268
global_step: 16949, epoch: 24, loss: 0.687032
global_step: 16950, epoch: 24, loss: 0.657445
global_step: 16951, epoch: 24, loss: 0.527206
global_step: 16952, epoch: 24, loss: 0.634507
global_step: 16953, epoch: 24, loss: 0.486127
global_step: 16954, epoch: 24, loss: 0.657992
global_step: 16955, epoch: 24, loss: 0.710433
global_step: 16956, epoch: 24, loss: 0.512021
global_step: 16957, epoch: 24, loss: 0.669290
global_step: 16958, epoch: 24, loss: 0.577805
global_step: 16959, epoch: 24, loss: 0.515634
global_step: 16960, epoch: 24, loss: 0.342456
epoch: 24
train	acc: 0.9176	macro: p 0.9136, r 0.8616, f1: 0.8801	micro: p 0.9176, r 0.9176, f1 0.9176	weighted_f1:0.9172
dev	acc: 0.4968	macro: p 0.3436, r 0.3125, f1: 0.3072	micro: p 0.4968, r 0.4968, f1 0.4968	weighted_f1:0.4769
test	acc: 0.5349	macro: p 0.3210, r 0.3232, f1: 0.3163	micro: p 0.5349, r 0.5349, f1 0.5349	weighted_f1:0.5246
global_step: 16961, epoch: 25, loss: 0.528329
global_step: 16962, epoch: 25, loss: 0.475900
global_step: 16963, epoch: 25, loss: 0.536519
global_step: 16964, epoch: 25, loss: 0.619529
global_step: 16965, epoch: 25, loss: 0.579027
global_step: 16966, epoch: 25, loss: 0.410840
global_step: 16967, epoch: 25, loss: 0.436449
global_step: 16968, epoch: 25, loss: 0.634717
global_step: 16969, epoch: 25, loss: 0.531411
global_step: 16970, epoch: 25, loss: 0.507998
global_step: 16971, epoch: 25, loss: 0.489065
global_step: 16972, epoch: 25, loss: 0.475995
global_step: 16973, epoch: 25, loss: 0.581524
global_step: 16974, epoch: 25, loss: 0.498038
global_step: 16975, epoch: 25, loss: 0.595743
global_step: 16976, epoch: 25, loss: 0.528510
global_step: 16977, epoch: 25, loss: 0.506141
global_step: 16978, epoch: 25, loss: 0.534547
global_step: 16979, epoch: 25, loss: 0.494724
global_step: 16980, epoch: 25, loss: 0.559758
global_step: 16981, epoch: 25, loss: 0.572073
global_step: 16982, epoch: 25, loss: 0.644074
global_step: 16983, epoch: 25, loss: 0.547060
global_step: 16984, epoch: 25, loss: 0.558276
global_step: 16985, epoch: 25, loss: 0.540980
global_step: 16986, epoch: 25, loss: 0.515441
global_step: 16987, epoch: 25, loss: 0.524321
global_step: 16988, epoch: 25, loss: 0.510595
global_step: 16989, epoch: 25, loss: 0.540047
global_step: 16990, epoch: 25, loss: 0.610848
global_step: 16991, epoch: 25, loss: 0.750249
global_step: 16992, epoch: 25, loss: 0.544341
global_step: 16993, epoch: 25, loss: 0.683373
global_step: 16994, epoch: 25, loss: 0.662326
global_step: 16995, epoch: 25, loss: 0.593099
global_step: 16996, epoch: 25, loss: 0.578707
global_step: 16997, epoch: 25, loss: 0.549750
global_step: 16998, epoch: 25, loss: 0.547317
global_step: 16999, epoch: 25, loss: 0.441891
global_step: 17000, epoch: 25, loss: 0.057851
epoch: 25
train	acc: 0.9170	macro: p 0.9352, r 0.8494, f1: 0.8856	micro: p 0.9170, r 0.9170, f1 0.9170	weighted_f1:0.9161
dev	acc: 0.5365	macro: p 0.3486, r 0.3027, f1: 0.2960	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4828
test	acc: 0.5808	macro: p 0.3735, r 0.3114, f1: 0.3111	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5360
global_step: 17001, epoch: 26, loss: 0.468113
global_step: 17002, epoch: 26, loss: 0.481599
global_step: 17003, epoch: 26, loss: 0.502602
global_step: 17004, epoch: 26, loss: 0.496813
global_step: 17005, epoch: 26, loss: 0.489687
global_step: 17006, epoch: 26, loss: 0.463595
global_step: 17007, epoch: 26, loss: 0.497326
global_step: 17008, epoch: 26, loss: 0.545202
global_step: 17009, epoch: 26, loss: 0.590879
global_step: 17010, epoch: 26, loss: 0.515762
global_step: 17011, epoch: 26, loss: 0.625934
global_step: 17012, epoch: 26, loss: 0.427071
global_step: 17013, epoch: 26, loss: 0.592065
global_step: 17014, epoch: 26, loss: 0.632393
global_step: 17015, epoch: 26, loss: 0.441487
global_step: 17016, epoch: 26, loss: 0.536120
global_step: 17017, epoch: 26, loss: 0.518326
global_step: 17018, epoch: 26, loss: 0.489346
global_step: 17019, epoch: 26, loss: 0.463549
global_step: 17020, epoch: 26, loss: 0.536450
global_step: 17021, epoch: 26, loss: 0.502790
global_step: 17022, epoch: 26, loss: 0.453259
global_step: 17023, epoch: 26, loss: 0.548224
global_step: 17024, epoch: 26, loss: 0.657764
global_step: 17025, epoch: 26, loss: 0.535242
global_step: 17026, epoch: 26, loss: 0.550534
global_step: 17027, epoch: 26, loss: 0.647738
global_step: 17028, epoch: 26, loss: 0.498396
global_step: 17029, epoch: 26, loss: 0.500997
global_step: 17030, epoch: 26, loss: 0.436190
global_step: 17031, epoch: 26, loss: 0.548596
global_step: 17032, epoch: 26, loss: 0.533900
global_step: 17033, epoch: 26, loss: 0.512786
global_step: 17034, epoch: 26, loss: 0.510217
global_step: 17035, epoch: 26, loss: 0.548454
global_step: 17036, epoch: 26, loss: 0.542776
global_step: 17037, epoch: 26, loss: 0.687762
global_step: 17038, epoch: 26, loss: 0.559405
global_step: 17039, epoch: 26, loss: 0.618628
global_step: 17040, epoch: 26, loss: 0.705030
epoch: 26
train	acc: 0.8993	macro: p 0.9242, r 0.8149, f1: 0.8571	micro: p 0.8993, r 0.8993, f1 0.8993	weighted_f1:0.8968
dev	acc: 0.5437	macro: p 0.5149, r 0.3137, f1: 0.3165	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4871
test	acc: 0.5916	macro: p 0.4137, r 0.3104, f1: 0.3035	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5359
global_step: 17041, epoch: 27, loss: 0.592790
global_step: 17042, epoch: 27, loss: 0.463249
global_step: 17043, epoch: 27, loss: 0.550820
global_step: 17044, epoch: 27, loss: 0.521203
global_step: 17045, epoch: 27, loss: 0.525036
global_step: 17046, epoch: 27, loss: 0.531272
global_step: 17047, epoch: 27, loss: 0.440266
global_step: 17048, epoch: 27, loss: 0.560378
global_step: 17049, epoch: 27, loss: 0.464856
global_step: 17050, epoch: 27, loss: 0.495676
global_step: 17051, epoch: 27, loss: 0.481021
global_step: 17052, epoch: 27, loss: 0.530482
global_step: 17053, epoch: 27, loss: 0.477423
global_step: 17054, epoch: 27, loss: 0.531614
global_step: 17055, epoch: 27, loss: 0.517991
global_step: 17056, epoch: 27, loss: 0.528267
global_step: 17057, epoch: 27, loss: 0.477613
global_step: 17058, epoch: 27, loss: 0.484267
global_step: 17059, epoch: 27, loss: 0.493676
global_step: 17060, epoch: 27, loss: 0.426493
global_step: 17061, epoch: 27, loss: 0.574200
global_step: 17062, epoch: 27, loss: 0.529539
global_step: 17063, epoch: 27, loss: 0.523189
global_step: 17064, epoch: 27, loss: 0.626280
global_step: 17065, epoch: 27, loss: 0.566555
global_step: 17066, epoch: 27, loss: 0.496692
global_step: 17067, epoch: 27, loss: 0.575781
global_step: 17068, epoch: 27, loss: 0.613820
global_step: 17069, epoch: 27, loss: 0.524850
global_step: 17070, epoch: 27, loss: 0.489875
global_step: 17071, epoch: 27, loss: 0.487259
global_step: 17072, epoch: 27, loss: 0.452820
global_step: 17073, epoch: 27, loss: 0.577522
global_step: 17074, epoch: 27, loss: 0.484175
global_step: 17075, epoch: 27, loss: 0.532274
global_step: 17076, epoch: 27, loss: 0.550895
global_step: 17077, epoch: 27, loss: 0.573125
global_step: 17078, epoch: 27, loss: 0.528026
global_step: 17079, epoch: 27, loss: 0.599886
global_step: 17080, epoch: 27, loss: 0.181678
epoch: 27
train	acc: 0.9207	macro: p 0.9322, r 0.8538, f1: 0.8851	micro: p 0.9207, r 0.9207, f1 0.9207	weighted_f1:0.9201
dev	acc: 0.5383	macro: p 0.4749, r 0.3023, f1: 0.3027	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4907
test	acc: 0.5831	macro: p 0.3752, r 0.3167, f1: 0.3222	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5469
global_step: 17081, epoch: 28, loss: 0.442670
global_step: 17082, epoch: 28, loss: 0.540899
global_step: 17083, epoch: 28, loss: 0.492894
global_step: 17084, epoch: 28, loss: 0.557380
global_step: 17085, epoch: 28, loss: 0.488646
global_step: 17086, epoch: 28, loss: 0.544129
global_step: 17087, epoch: 28, loss: 0.585548
global_step: 17088, epoch: 28, loss: 0.399481
global_step: 17089, epoch: 28, loss: 0.530302
global_step: 17090, epoch: 28, loss: 0.482701
global_step: 17091, epoch: 28, loss: 0.438433
global_step: 17092, epoch: 28, loss: 0.485137
global_step: 17093, epoch: 28, loss: 0.511887
global_step: 17094, epoch: 28, loss: 0.500931
global_step: 17095, epoch: 28, loss: 0.469803
global_step: 17096, epoch: 28, loss: 0.521390
global_step: 17097, epoch: 28, loss: 0.521663
global_step: 17098, epoch: 28, loss: 0.511163
global_step: 17099, epoch: 28, loss: 0.460224
global_step: 17100, epoch: 28, loss: 0.459961
global_step: 17101, epoch: 28, loss: 0.552009
global_step: 17102, epoch: 28, loss: 0.454318
global_step: 17103, epoch: 28, loss: 0.498917
global_step: 17104, epoch: 28, loss: 0.571877
global_step: 17105, epoch: 28, loss: 0.475903
global_step: 17106, epoch: 28, loss: 0.502627
global_step: 17107, epoch: 28, loss: 0.557711
global_step: 17108, epoch: 28, loss: 0.495356
global_step: 17109, epoch: 28, loss: 0.462898
global_step: 17110, epoch: 28, loss: 0.507051
global_step: 17111, epoch: 28, loss: 0.586366
global_step: 17112, epoch: 28, loss: 0.578221
global_step: 17113, epoch: 28, loss: 0.518855
global_step: 17114, epoch: 28, loss: 0.552897
global_step: 17115, epoch: 28, loss: 0.465745
global_step: 17116, epoch: 28, loss: 0.482054
global_step: 17117, epoch: 28, loss: 0.516728
global_step: 17118, epoch: 28, loss: 0.512848
global_step: 17119, epoch: 28, loss: 0.530638
global_step: 17120, epoch: 28, loss: 1.047583
epoch: 28
train	acc: 0.9297	macro: p 0.9317, r 0.8747, f1: 0.8978	micro: p 0.9297, r 0.9297, f1 0.9297	weighted_f1:0.9294
dev	acc: 0.5131	macro: p 0.3563, r 0.3154, f1: 0.3123	micro: p 0.5131, r 0.5131, f1 0.5131	weighted_f1:0.4864
test	acc: 0.5452	macro: p 0.3433, r 0.3216, f1: 0.3199	micro: p 0.5452, r 0.5452, f1 0.5452	weighted_f1:0.5295
global_step: 17121, epoch: 29, loss: 0.604745
global_step: 17122, epoch: 29, loss: 0.441731
global_step: 17123, epoch: 29, loss: 0.503635
global_step: 17124, epoch: 29, loss: 0.509925
global_step: 17125, epoch: 29, loss: 0.535018
global_step: 17126, epoch: 29, loss: 0.472966
global_step: 17127, epoch: 29, loss: 0.551000
global_step: 17128, epoch: 29, loss: 0.493159
global_step: 17129, epoch: 29, loss: 0.524217
global_step: 17130, epoch: 29, loss: 0.519411
global_step: 17131, epoch: 29, loss: 0.430849
global_step: 17132, epoch: 29, loss: 0.442567
global_step: 17133, epoch: 29, loss: 0.541131
global_step: 17134, epoch: 29, loss: 0.431177
global_step: 17135, epoch: 29, loss: 0.447444
global_step: 17136, epoch: 29, loss: 0.546160
global_step: 17137, epoch: 29, loss: 0.545728
global_step: 17138, epoch: 29, loss: 0.448089
global_step: 17139, epoch: 29, loss: 0.430657
global_step: 17140, epoch: 29, loss: 0.543601
global_step: 17141, epoch: 29, loss: 0.432290
global_step: 17142, epoch: 29, loss: 0.419621
global_step: 17143, epoch: 29, loss: 0.539339
global_step: 17144, epoch: 29, loss: 0.377059
global_step: 17145, epoch: 29, loss: 0.416188
global_step: 17146, epoch: 29, loss: 0.535482
global_step: 17147, epoch: 29, loss: 0.437098
global_step: 17148, epoch: 29, loss: 0.402760
global_step: 17149, epoch: 29, loss: 0.521476
global_step: 17150, epoch: 29, loss: 0.555914
global_step: 17151, epoch: 29, loss: 0.478219
global_step: 17152, epoch: 29, loss: 0.555283
global_step: 17153, epoch: 29, loss: 0.532347
global_step: 17154, epoch: 29, loss: 0.457483
global_step: 17155, epoch: 29, loss: 0.479314
global_step: 17156, epoch: 29, loss: 0.383298
global_step: 17157, epoch: 29, loss: 0.419641
global_step: 17158, epoch: 29, loss: 0.516018
global_step: 17159, epoch: 29, loss: 0.464394
global_step: 17160, epoch: 29, loss: 0.908161
epoch: 29
train	acc: 0.9283	macro: p 0.9323, r 0.8757, f1: 0.9000	micro: p 0.9283, r 0.9283, f1 0.9283	weighted_f1:0.9278
dev	acc: 0.5374	macro: p 0.3791, r 0.3125, f1: 0.3125	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4925
test	acc: 0.5713	macro: p 0.3685, r 0.3171, f1: 0.3168	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.5345
global_step: 17161, epoch: 30, loss: 0.520830
global_step: 17162, epoch: 30, loss: 0.520341
global_step: 17163, epoch: 30, loss: 0.442559
global_step: 17164, epoch: 30, loss: 0.409334
global_step: 17165, epoch: 30, loss: 0.451536
global_step: 17166, epoch: 30, loss: 0.398475
global_step: 17167, epoch: 30, loss: 0.421398
global_step: 17168, epoch: 30, loss: 0.417916
global_step: 17169, epoch: 30, loss: 0.501951
global_step: 17170, epoch: 30, loss: 0.433151
global_step: 17171, epoch: 30, loss: 0.458241
global_step: 17172, epoch: 30, loss: 0.496149
global_step: 17173, epoch: 30, loss: 0.363884
global_step: 17174, epoch: 30, loss: 0.511866
global_step: 17175, epoch: 30, loss: 0.429820
global_step: 17176, epoch: 30, loss: 0.371991
global_step: 17177, epoch: 30, loss: 0.403653
global_step: 17178, epoch: 30, loss: 0.371043
global_step: 17179, epoch: 30, loss: 0.446239
global_step: 17180, epoch: 30, loss: 0.505445
global_step: 17181, epoch: 30, loss: 0.461233
global_step: 17182, epoch: 30, loss: 0.445366
global_step: 17183, epoch: 30, loss: 0.530999
global_step: 17184, epoch: 30, loss: 0.494556
global_step: 17185, epoch: 30, loss: 0.575488
global_step: 17186, epoch: 30, loss: 0.424047
global_step: 17187, epoch: 30, loss: 0.526130
global_step: 17188, epoch: 30, loss: 0.556244
global_step: 17189, epoch: 30, loss: 0.494138
global_step: 17190, epoch: 30, loss: 0.530252
global_step: 17191, epoch: 30, loss: 0.443974
global_step: 17192, epoch: 30, loss: 0.550503
global_step: 17193, epoch: 30, loss: 0.430588
global_step: 17194, epoch: 30, loss: 0.443066
global_step: 17195, epoch: 30, loss: 0.463696
global_step: 17196, epoch: 30, loss: 0.590266
global_step: 17197, epoch: 30, loss: 0.430477
global_step: 17198, epoch: 30, loss: 0.446743
global_step: 17199, epoch: 30, loss: 0.494560
global_step: 17200, epoch: 30, loss: 0.596853
epoch: 30
train	acc: 0.9360	macro: p 0.9378, r 0.8938, f1: 0.9129	micro: p 0.9360, r 0.9360, f1 0.9360	weighted_f1:0.9357
dev	acc: 0.5257	macro: p 0.4127, r 0.3023, f1: 0.2983	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4786
test	acc: 0.5674	macro: p 0.3474, r 0.3051, f1: 0.3026	micro: p 0.5674, r 0.5674, f1 0.5674	weighted_f1:0.5265
global_step: 17201, epoch: 31, loss: 0.426106
global_step: 17202, epoch: 31, loss: 0.389753
global_step: 17203, epoch: 31, loss: 0.389372
global_step: 17204, epoch: 31, loss: 0.443971
global_step: 17205, epoch: 31, loss: 0.495297
global_step: 17206, epoch: 31, loss: 0.358874
global_step: 17207, epoch: 31, loss: 0.408179
global_step: 17208, epoch: 31, loss: 0.380515
global_step: 17209, epoch: 31, loss: 0.470869
global_step: 17210, epoch: 31, loss: 0.444516
global_step: 17211, epoch: 31, loss: 0.384197
global_step: 17212, epoch: 31, loss: 0.483636
global_step: 17213, epoch: 31, loss: 0.455610
global_step: 17214, epoch: 31, loss: 0.385166
global_step: 17215, epoch: 31, loss: 0.409725
global_step: 17216, epoch: 31, loss: 0.412078
global_step: 17217, epoch: 31, loss: 0.416371
global_step: 17218, epoch: 31, loss: 0.404206
global_step: 17219, epoch: 31, loss: 0.437938
global_step: 17220, epoch: 31, loss: 0.481611
global_step: 17221, epoch: 31, loss: 0.387345
global_step: 17222, epoch: 31, loss: 0.426643
global_step: 17223, epoch: 31, loss: 0.460031
global_step: 17224, epoch: 31, loss: 0.450852
global_step: 17225, epoch: 31, loss: 0.421539
global_step: 17226, epoch: 31, loss: 0.510923
global_step: 17227, epoch: 31, loss: 0.414048
global_step: 17228, epoch: 31, loss: 0.422450
global_step: 17229, epoch: 31, loss: 0.495704
global_step: 17230, epoch: 31, loss: 0.512629
global_step: 17231, epoch: 31, loss: 0.448134
global_step: 17232, epoch: 31, loss: 0.396290
global_step: 17233, epoch: 31, loss: 0.439024
global_step: 17234, epoch: 31, loss: 0.398400
global_step: 17235, epoch: 31, loss: 0.380033
global_step: 17236, epoch: 31, loss: 0.533406
global_step: 17237, epoch: 31, loss: 0.380094
global_step: 17238, epoch: 31, loss: 0.511117
global_step: 17239, epoch: 31, loss: 0.508826
global_step: 17240, epoch: 31, loss: 0.895249
epoch: 31
train	acc: 0.9445	macro: p 0.9446, r 0.9150, f1: 0.9282	micro: p 0.9445, r 0.9445, f1 0.9445	weighted_f1:0.9446
dev	acc: 0.5140	macro: p 0.3514, r 0.3187, f1: 0.3194	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4911
test	acc: 0.5498	macro: p 0.3332, r 0.3277, f1: 0.3266	micro: p 0.5498, r 0.5498, f1 0.5498	weighted_f1:0.5354
global_step: 17241, epoch: 32, loss: 0.357984
global_step: 17242, epoch: 32, loss: 0.360408
global_step: 17243, epoch: 32, loss: 0.305588
global_step: 17244, epoch: 32, loss: 0.382087
global_step: 17245, epoch: 32, loss: 0.382602
global_step: 17246, epoch: 32, loss: 0.442426
global_step: 17247, epoch: 32, loss: 0.397940
global_step: 17248, epoch: 32, loss: 0.438954
global_step: 17249, epoch: 32, loss: 0.304395
global_step: 17250, epoch: 32, loss: 0.357979
global_step: 17251, epoch: 32, loss: 0.424766
global_step: 17252, epoch: 32, loss: 0.539861
global_step: 17253, epoch: 32, loss: 0.525150
global_step: 17254, epoch: 32, loss: 0.408378
global_step: 17255, epoch: 32, loss: 0.376152
global_step: 17256, epoch: 32, loss: 0.410847
global_step: 17257, epoch: 32, loss: 0.485166
global_step: 17258, epoch: 32, loss: 0.420458
global_step: 17259, epoch: 32, loss: 0.439617
global_step: 17260, epoch: 32, loss: 0.512164
global_step: 17261, epoch: 32, loss: 0.531006
global_step: 17262, epoch: 32, loss: 0.452275
global_step: 17263, epoch: 32, loss: 0.374899
global_step: 17264, epoch: 32, loss: 0.434447
global_step: 17265, epoch: 32, loss: 0.436146
global_step: 17266, epoch: 32, loss: 0.480913
global_step: 17267, epoch: 32, loss: 0.388824
global_step: 17268, epoch: 32, loss: 0.418269
global_step: 17269, epoch: 32, loss: 0.419562
global_step: 17270, epoch: 32, loss: 0.500327
global_step: 17271, epoch: 32, loss: 0.462722
global_step: 17272, epoch: 32, loss: 0.343054
global_step: 17273, epoch: 32, loss: 0.353611
global_step: 17274, epoch: 32, loss: 0.466359
global_step: 17275, epoch: 32, loss: 0.528400
global_step: 17276, epoch: 32, loss: 0.480441
global_step: 17277, epoch: 32, loss: 0.373392
global_step: 17278, epoch: 32, loss: 0.502567
global_step: 17279, epoch: 32, loss: 0.461358
global_step: 17280, epoch: 32, loss: 0.655257
epoch: 32
train	acc: 0.9438	macro: p 0.9493, r 0.9138, f1: 0.9296	micro: p 0.9438, r 0.9438, f1 0.9438	weighted_f1:0.9439
dev	acc: 0.5086	macro: p 0.4735, r 0.3177, f1: 0.3148	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4816
test	acc: 0.5494	macro: p 0.3331, r 0.3173, f1: 0.3171	micro: p 0.5494, r 0.5494, f1 0.5494	weighted_f1:0.5322
global_step: 17281, epoch: 33, loss: 0.436475
global_step: 17282, epoch: 33, loss: 0.356164
global_step: 17283, epoch: 33, loss: 0.422557
global_step: 17284, epoch: 33, loss: 0.371413
global_step: 17285, epoch: 33, loss: 0.386816
global_step: 17286, epoch: 33, loss: 0.360341
global_step: 17287, epoch: 33, loss: 0.426806
global_step: 17288, epoch: 33, loss: 0.405785
global_step: 17289, epoch: 33, loss: 0.464578
global_step: 17290, epoch: 33, loss: 0.399646
global_step: 17291, epoch: 33, loss: 0.532536
global_step: 17292, epoch: 33, loss: 0.440842
global_step: 17293, epoch: 33, loss: 0.539888
global_step: 17294, epoch: 33, loss: 0.480306
global_step: 17295, epoch: 33, loss: 0.453002
global_step: 17296, epoch: 33, loss: 0.463618
global_step: 17297, epoch: 33, loss: 0.453184
global_step: 17298, epoch: 33, loss: 0.480283
global_step: 17299, epoch: 33, loss: 0.489914
global_step: 17300, epoch: 33, loss: 0.439275
global_step: 17301, epoch: 33, loss: 0.408931
global_step: 17302, epoch: 33, loss: 0.406504
global_step: 17303, epoch: 33, loss: 0.431058
global_step: 17304, epoch: 33, loss: 0.410245
global_step: 17305, epoch: 33, loss: 0.409286
global_step: 17306, epoch: 33, loss: 0.484992
global_step: 17307, epoch: 33, loss: 0.513552
global_step: 17308, epoch: 33, loss: 0.476771
global_step: 17309, epoch: 33, loss: 0.420823
global_step: 17310, epoch: 33, loss: 0.457426
global_step: 17311, epoch: 33, loss: 0.365681
global_step: 17312, epoch: 33, loss: 0.414583
global_step: 17313, epoch: 33, loss: 0.564719
global_step: 17314, epoch: 33, loss: 0.375636
global_step: 17315, epoch: 33, loss: 0.491506
global_step: 17316, epoch: 33, loss: 0.519024
global_step: 17317, epoch: 33, loss: 0.426276
global_step: 17318, epoch: 33, loss: 0.466308
global_step: 17319, epoch: 33, loss: 0.494713
global_step: 17320, epoch: 33, loss: 0.215338
epoch: 33
train	acc: 0.9424	macro: p 0.9466, r 0.9095, f1: 0.9258	micro: p 0.9424, r 0.9424, f1 0.9424	weighted_f1:0.9425
dev	acc: 0.5059	macro: p 0.3512, r 0.3096, f1: 0.3060	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4825
test	acc: 0.5387	macro: p 0.3423, r 0.3177, f1: 0.3147	micro: p 0.5387, r 0.5387, f1 0.5387	weighted_f1:0.5267
global_step: 17321, epoch: 34, loss: 0.471253
global_step: 17322, epoch: 34, loss: 0.442174
global_step: 17323, epoch: 34, loss: 0.357528
global_step: 17324, epoch: 34, loss: 0.388507
global_step: 17325, epoch: 34, loss: 0.419536
global_step: 17326, epoch: 34, loss: 0.396240
global_step: 17327, epoch: 34, loss: 0.400137
global_step: 17328, epoch: 34, loss: 0.400729
global_step: 17329, epoch: 34, loss: 0.378308
global_step: 17330, epoch: 34, loss: 0.362749
global_step: 17331, epoch: 34, loss: 0.396370
global_step: 17332, epoch: 34, loss: 0.461324
global_step: 17333, epoch: 34, loss: 0.372015
global_step: 17334, epoch: 34, loss: 0.486475
global_step: 17335, epoch: 34, loss: 0.353323
global_step: 17336, epoch: 34, loss: 0.437105
global_step: 17337, epoch: 34, loss: 0.400851
global_step: 17338, epoch: 34, loss: 0.383547
global_step: 17339, epoch: 34, loss: 0.450487
global_step: 17340, epoch: 34, loss: 0.414671
global_step: 17341, epoch: 34, loss: 0.401463
global_step: 17342, epoch: 34, loss: 0.398433
global_step: 17343, epoch: 34, loss: 0.534642
global_step: 17344, epoch: 34, loss: 0.514710
global_step: 17345, epoch: 34, loss: 0.414090
global_step: 17346, epoch: 34, loss: 0.413355
global_step: 17347, epoch: 34, loss: 0.431717
global_step: 17348, epoch: 34, loss: 0.398689
global_step: 17349, epoch: 34, loss: 0.418639
global_step: 17350, epoch: 34, loss: 0.310324
global_step: 17351, epoch: 34, loss: 0.514288
global_step: 17352, epoch: 34, loss: 0.417471
global_step: 17353, epoch: 34, loss: 0.407176
global_step: 17354, epoch: 34, loss: 0.496189
global_step: 17355, epoch: 34, loss: 0.426598
global_step: 17356, epoch: 34, loss: 0.397981
global_step: 17357, epoch: 34, loss: 0.436553
global_step: 17358, epoch: 34, loss: 0.442689
global_step: 17359, epoch: 34, loss: 0.583181
global_step: 17360, epoch: 34, loss: 0.020810
epoch: 34
train	acc: 0.9485	macro: p 0.9551, r 0.9192, f1: 0.9357	micro: p 0.9485, r 0.9485, f1 0.9485	weighted_f1:0.9484
dev	acc: 0.5356	macro: p 0.3980, r 0.3134, f1: 0.3204	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4939
test	acc: 0.5682	macro: p 0.3535, r 0.3109, f1: 0.3161	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5327
global_step: 17361, epoch: 35, loss: 0.379228
global_step: 17362, epoch: 35, loss: 0.322707
global_step: 17363, epoch: 35, loss: 0.475193
global_step: 17364, epoch: 35, loss: 0.364023
global_step: 17365, epoch: 35, loss: 0.385790
global_step: 17366, epoch: 35, loss: 0.452956
global_step: 17367, epoch: 35, loss: 0.428328
global_step: 17368, epoch: 35, loss: 0.493328
global_step: 17369, epoch: 35, loss: 0.408290
global_step: 17370, epoch: 35, loss: 0.404264
global_step: 17371, epoch: 35, loss: 0.363691
global_step: 17372, epoch: 35, loss: 0.381939
global_step: 17373, epoch: 35, loss: 0.490921
global_step: 17374, epoch: 35, loss: 0.372921
global_step: 17375, epoch: 35, loss: 0.347475
global_step: 17376, epoch: 35, loss: 0.473332
global_step: 17377, epoch: 35, loss: 0.525527
global_step: 17378, epoch: 35, loss: 0.424780
global_step: 17379, epoch: 35, loss: 0.476043
global_step: 17380, epoch: 35, loss: 0.382620
global_step: 17381, epoch: 35, loss: 0.474254
global_step: 17382, epoch: 35, loss: 0.420394
global_step: 17383, epoch: 35, loss: 0.407199
global_step: 17384, epoch: 35, loss: 0.371654
global_step: 17385, epoch: 35, loss: 0.405706
global_step: 17386, epoch: 35, loss: 0.364978
global_step: 17387, epoch: 35, loss: 0.420784
global_step: 17388, epoch: 35, loss: 0.415115
global_step: 17389, epoch: 35, loss: 0.408412
global_step: 17390, epoch: 35, loss: 0.534891
global_step: 17391, epoch: 35, loss: 0.399086
global_step: 17392, epoch: 35, loss: 0.380988
global_step: 17393, epoch: 35, loss: 0.394607
global_step: 17394, epoch: 35, loss: 0.428669
global_step: 17395, epoch: 35, loss: 0.568011
global_step: 17396, epoch: 35, loss: 0.375412
global_step: 17397, epoch: 35, loss: 0.513711
global_step: 17398, epoch: 35, loss: 0.472246
global_step: 17399, epoch: 35, loss: 0.363707
global_step: 17400, epoch: 35, loss: 0.098449
epoch: 35
train	acc: 0.9436	macro: p 0.9566, r 0.9047, f1: 0.9286	micro: p 0.9436, r 0.9436, f1 0.9436	weighted_f1:0.9433
dev	acc: 0.5329	macro: p 0.3802, r 0.2996, f1: 0.3011	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4768
test	acc: 0.5812	macro: p 0.3701, r 0.2998, f1: 0.3065	micro: p 0.5812, r 0.5812, f1 0.5812	weighted_f1:0.5306
global_step: 17401, epoch: 36, loss: 0.351770
global_step: 17402, epoch: 36, loss: 0.322200
global_step: 17403, epoch: 36, loss: 0.351629
global_step: 17404, epoch: 36, loss: 0.441561
global_step: 17405, epoch: 36, loss: 0.421242
global_step: 17406, epoch: 36, loss: 0.467394
global_step: 17407, epoch: 36, loss: 0.390527
global_step: 17408, epoch: 36, loss: 0.361047
global_step: 17409, epoch: 36, loss: 0.425631
global_step: 17410, epoch: 36, loss: 0.394301
global_step: 17411, epoch: 36, loss: 0.395065
global_step: 17412, epoch: 36, loss: 0.433256
global_step: 17413, epoch: 36, loss: 0.467132
global_step: 17414, epoch: 36, loss: 0.371302
global_step: 17415, epoch: 36, loss: 0.383694
global_step: 17416, epoch: 36, loss: 0.450934
global_step: 17417, epoch: 36, loss: 0.421606
global_step: 17418, epoch: 36, loss: 0.372764
global_step: 17419, epoch: 36, loss: 0.476126
global_step: 17420, epoch: 36, loss: 0.369351
global_step: 17421, epoch: 36, loss: 0.396688
global_step: 17422, epoch: 36, loss: 0.506244
global_step: 17423, epoch: 36, loss: 0.419751
global_step: 17424, epoch: 36, loss: 0.440409
global_step: 17425, epoch: 36, loss: 0.333389
global_step: 17426, epoch: 36, loss: 0.475428
global_step: 17427, epoch: 36, loss: 0.522957
global_step: 17428, epoch: 36, loss: 0.500369
global_step: 17429, epoch: 36, loss: 0.325068
global_step: 17430, epoch: 36, loss: 0.368715
global_step: 17431, epoch: 36, loss: 0.423760
global_step: 17432, epoch: 36, loss: 0.386193
global_step: 17433, epoch: 36, loss: 0.483028
global_step: 17434, epoch: 36, loss: 0.408808
global_step: 17435, epoch: 36, loss: 0.490819
global_step: 17436, epoch: 36, loss: 0.522755
global_step: 17437, epoch: 36, loss: 0.475785
global_step: 17438, epoch: 36, loss: 0.457690
global_step: 17439, epoch: 36, loss: 0.426206
global_step: 17440, epoch: 36, loss: 0.243306
epoch: 36
train	acc: 0.9426	macro: p 0.9534, r 0.9027, f1: 0.9254	micro: p 0.9426, r 0.9426, f1 0.9426	weighted_f1:0.9424
dev	acc: 0.5365	macro: p 0.3831, r 0.2995, f1: 0.2959	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4795
test	acc: 0.5797	macro: p 0.3887, r 0.3046, f1: 0.3074	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5314
global_step: 17441, epoch: 37, loss: 0.418458
global_step: 17442, epoch: 37, loss: 0.409478
global_step: 17443, epoch: 37, loss: 0.324748
global_step: 17444, epoch: 37, loss: 0.371168
global_step: 17445, epoch: 37, loss: 0.420848
global_step: 17446, epoch: 37, loss: 0.354789
global_step: 17447, epoch: 37, loss: 0.501163
global_step: 17448, epoch: 37, loss: 0.384959
global_step: 17449, epoch: 37, loss: 0.481226
global_step: 17450, epoch: 37, loss: 0.377070
global_step: 17451, epoch: 37, loss: 0.331540
global_step: 17452, epoch: 37, loss: 0.347009
global_step: 17453, epoch: 37, loss: 0.364248
global_step: 17454, epoch: 37, loss: 0.370383
global_step: 17455, epoch: 37, loss: 0.481657
global_step: 17456, epoch: 37, loss: 0.564106
global_step: 17457, epoch: 37, loss: 0.381290
global_step: 17458, epoch: 37, loss: 0.337501
global_step: 17459, epoch: 37, loss: 0.362875
global_step: 17460, epoch: 37, loss: 0.394302
global_step: 17461, epoch: 37, loss: 0.418550
global_step: 17462, epoch: 37, loss: 0.400732
global_step: 17463, epoch: 37, loss: 0.420014
global_step: 17464, epoch: 37, loss: 0.439131
global_step: 17465, epoch: 37, loss: 0.455542
global_step: 17466, epoch: 37, loss: 0.417839
global_step: 17467, epoch: 37, loss: 0.462971
global_step: 17468, epoch: 37, loss: 0.511218
global_step: 17469, epoch: 37, loss: 0.442417
global_step: 17470, epoch: 37, loss: 0.468126
global_step: 17471, epoch: 37, loss: 0.514827
global_step: 17472, epoch: 37, loss: 0.346300
global_step: 17473, epoch: 37, loss: 0.501109
global_step: 17474, epoch: 37, loss: 0.414714
global_step: 17475, epoch: 37, loss: 0.342171
global_step: 17476, epoch: 37, loss: 0.464388
global_step: 17477, epoch: 37, loss: 0.432645
global_step: 17478, epoch: 37, loss: 0.427967
global_step: 17479, epoch: 37, loss: 0.328320
global_step: 17480, epoch: 37, loss: 1.006243
epoch: 37
train	acc: 0.9435	macro: p 0.9481, r 0.9145, f1: 0.9298	micro: p 0.9435, r 0.9435, f1 0.9435	weighted_f1:0.9437
dev	acc: 0.5185	macro: p 0.3739, r 0.3094, f1: 0.3089	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4810
test	acc: 0.5621	macro: p 0.3649, r 0.3162, f1: 0.3222	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.5353
global_step: 17481, epoch: 38, loss: 0.420141
global_step: 17482, epoch: 38, loss: 0.320883
global_step: 17483, epoch: 38, loss: 0.387161
global_step: 17484, epoch: 38, loss: 0.315185
global_step: 17485, epoch: 38, loss: 0.297171
global_step: 17486, epoch: 38, loss: 0.376073
global_step: 17487, epoch: 38, loss: 0.444354
global_step: 17488, epoch: 38, loss: 0.366032
global_step: 17489, epoch: 38, loss: 0.355791
global_step: 17490, epoch: 38, loss: 0.442496
global_step: 17491, epoch: 38, loss: 0.301282
global_step: 17492, epoch: 38, loss: 0.321207
global_step: 17493, epoch: 38, loss: 0.472981
global_step: 17494, epoch: 38, loss: 0.313726
global_step: 17495, epoch: 38, loss: 0.350019
global_step: 17496, epoch: 38, loss: 0.321287
global_step: 17497, epoch: 38, loss: 0.348867
global_step: 17498, epoch: 38, loss: 0.498195
global_step: 17499, epoch: 38, loss: 0.398692
global_step: 17500, epoch: 38, loss: 0.440587
global_step: 17501, epoch: 38, loss: 0.414111
global_step: 17502, epoch: 38, loss: 0.436734
global_step: 17503, epoch: 38, loss: 0.470218
global_step: 17504, epoch: 38, loss: 0.348929
global_step: 17505, epoch: 38, loss: 0.343876
global_step: 17506, epoch: 38, loss: 0.484628
global_step: 17507, epoch: 38, loss: 0.386183
global_step: 17508, epoch: 38, loss: 0.501864
global_step: 17509, epoch: 38, loss: 0.529164
global_step: 17510, epoch: 38, loss: 0.396792
global_step: 17511, epoch: 38, loss: 0.434107
global_step: 17512, epoch: 38, loss: 0.448320
global_step: 17513, epoch: 38, loss: 0.446533
global_step: 17514, epoch: 38, loss: 0.487693
global_step: 17515, epoch: 38, loss: 0.312927
global_step: 17516, epoch: 38, loss: 0.365235
global_step: 17517, epoch: 38, loss: 0.433496
global_step: 17518, epoch: 38, loss: 0.437125
global_step: 17519, epoch: 38, loss: 0.385957
global_step: 17520, epoch: 38, loss: 0.210949
epoch: 38
train	acc: 0.9517	macro: p 0.9571, r 0.9200, f1: 0.9370	micro: p 0.9517, r 0.9517, f1 0.9517	weighted_f1:0.9516
dev	acc: 0.5203	macro: p 0.3351, r 0.3022, f1: 0.2961	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4792
test	acc: 0.5644	macro: p 0.3611, r 0.3133, f1: 0.3142	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5352
global_step: 17521, epoch: 39, loss: 0.303926
global_step: 17522, epoch: 39, loss: 0.423798
global_step: 17523, epoch: 39, loss: 0.373843
global_step: 17524, epoch: 39, loss: 0.378702
global_step: 17525, epoch: 39, loss: 0.360445
global_step: 17526, epoch: 39, loss: 0.349987
global_step: 17527, epoch: 39, loss: 0.344054
global_step: 17528, epoch: 39, loss: 0.365347
global_step: 17529, epoch: 39, loss: 0.297074
global_step: 17530, epoch: 39, loss: 0.413174
global_step: 17531, epoch: 39, loss: 0.383812
global_step: 17532, epoch: 39, loss: 0.362430
global_step: 17533, epoch: 39, loss: 0.358482
global_step: 17534, epoch: 39, loss: 0.315875
global_step: 17535, epoch: 39, loss: 0.443767
global_step: 17536, epoch: 39, loss: 0.398856
global_step: 17537, epoch: 39, loss: 0.459890
global_step: 17538, epoch: 39, loss: 0.382618
global_step: 17539, epoch: 39, loss: 0.497837
global_step: 17540, epoch: 39, loss: 0.379991
global_step: 17541, epoch: 39, loss: 0.380279
global_step: 17542, epoch: 39, loss: 0.362274
global_step: 17543, epoch: 39, loss: 0.328225
global_step: 17544, epoch: 39, loss: 0.295058
global_step: 17545, epoch: 39, loss: 0.399349
global_step: 17546, epoch: 39, loss: 0.500805
global_step: 17547, epoch: 39, loss: 0.427141
global_step: 17548, epoch: 39, loss: 0.321790
global_step: 17549, epoch: 39, loss: 0.356450
global_step: 17550, epoch: 39, loss: 0.370820
global_step: 17551, epoch: 39, loss: 0.456456
global_step: 17552, epoch: 39, loss: 0.404289
global_step: 17553, epoch: 39, loss: 0.409515
global_step: 17554, epoch: 39, loss: 0.403176
global_step: 17555, epoch: 39, loss: 0.366819
global_step: 17556, epoch: 39, loss: 0.380161
global_step: 17557, epoch: 39, loss: 0.521123
global_step: 17558, epoch: 39, loss: 0.388500
global_step: 17559, epoch: 39, loss: 0.390481
global_step: 17560, epoch: 39, loss: 0.110677
epoch: 39
train	acc: 0.9500	macro: p 0.9539, r 0.9247, f1: 0.9381	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9502
dev	acc: 0.5266	macro: p 0.4112, r 0.3214, f1: 0.3263	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4894
test	acc: 0.5575	macro: p 0.3473, r 0.3109, f1: 0.3125	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.5282
global_step: 17561, epoch: 40, loss: 0.388153
global_step: 17562, epoch: 40, loss: 0.304084
global_step: 17563, epoch: 40, loss: 0.369251
global_step: 17564, epoch: 40, loss: 0.364503
global_step: 17565, epoch: 40, loss: 0.289663
global_step: 17566, epoch: 40, loss: 0.431614
global_step: 17567, epoch: 40, loss: 0.394501
global_step: 17568, epoch: 40, loss: 0.372695
global_step: 17569, epoch: 40, loss: 0.286965
global_step: 17570, epoch: 40, loss: 0.309221
global_step: 17571, epoch: 40, loss: 0.308050
global_step: 17572, epoch: 40, loss: 0.324920
global_step: 17573, epoch: 40, loss: 0.340461
global_step: 17574, epoch: 40, loss: 0.436009
global_step: 17575, epoch: 40, loss: 0.351524
global_step: 17576, epoch: 40, loss: 0.399638
global_step: 17577, epoch: 40, loss: 0.420784
global_step: 17578, epoch: 40, loss: 0.391640
global_step: 17579, epoch: 40, loss: 0.484283
global_step: 17580, epoch: 40, loss: 0.423755
global_step: 17581, epoch: 40, loss: 0.515057
global_step: 17582, epoch: 40, loss: 0.459031
global_step: 17583, epoch: 40, loss: 0.384364
global_step: 17584, epoch: 40, loss: 0.358303
global_step: 17585, epoch: 40, loss: 0.387270
global_step: 17586, epoch: 40, loss: 0.490593
global_step: 17587, epoch: 40, loss: 0.264700
global_step: 17588, epoch: 40, loss: 0.347686
global_step: 17589, epoch: 40, loss: 0.391458
global_step: 17590, epoch: 40, loss: 0.436620
global_step: 17591, epoch: 40, loss: 0.444317
global_step: 17592, epoch: 40, loss: 0.307509
global_step: 17593, epoch: 40, loss: 0.424999
global_step: 17594, epoch: 40, loss: 0.362524
global_step: 17595, epoch: 40, loss: 0.306972
global_step: 17596, epoch: 40, loss: 0.357836
global_step: 17597, epoch: 40, loss: 0.377505
global_step: 17598, epoch: 40, loss: 0.367225
global_step: 17599, epoch: 40, loss: 0.384255
global_step: 17600, epoch: 40, loss: 0.088435
epoch: 40
train	acc: 0.9497	macro: p 0.9609, r 0.9171, f1: 0.9372	micro: p 0.9497, r 0.9497, f1 0.9497	weighted_f1:0.9496
dev	acc: 0.5284	macro: p 0.4007, r 0.3138, f1: 0.3127	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4940
test	acc: 0.5640	macro: p 0.3464, r 0.3148, f1: 0.3155	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5364
global_step: 17601, epoch: 41, loss: 0.362035
global_step: 17602, epoch: 41, loss: 0.392429
global_step: 17603, epoch: 41, loss: 0.364412
global_step: 17604, epoch: 41, loss: 0.391456
global_step: 17605, epoch: 41, loss: 0.429403
global_step: 17606, epoch: 41, loss: 0.325735
global_step: 17607, epoch: 41, loss: 0.491998
global_step: 17608, epoch: 41, loss: 0.278188
global_step: 17609, epoch: 41, loss: 0.392441
global_step: 17610, epoch: 41, loss: 0.323882
global_step: 17611, epoch: 41, loss: 0.283661
global_step: 17612, epoch: 41, loss: 0.403529
global_step: 17613, epoch: 41, loss: 0.412046
global_step: 17614, epoch: 41, loss: 0.282488
global_step: 17615, epoch: 41, loss: 0.294688
global_step: 17616, epoch: 41, loss: 0.387687
global_step: 17617, epoch: 41, loss: 0.529310
global_step: 17618, epoch: 41, loss: 0.347856
global_step: 17619, epoch: 41, loss: 0.422784
global_step: 17620, epoch: 41, loss: 0.349125
global_step: 17621, epoch: 41, loss: 0.449775
global_step: 17622, epoch: 41, loss: 0.533791
global_step: 17623, epoch: 41, loss: 0.353641
global_step: 17624, epoch: 41, loss: 0.392680
global_step: 17625, epoch: 41, loss: 0.413188
global_step: 17626, epoch: 41, loss: 0.362456
global_step: 17627, epoch: 41, loss: 0.454822
global_step: 17628, epoch: 41, loss: 0.367290
global_step: 17629, epoch: 41, loss: 0.400064
global_step: 17630, epoch: 41, loss: 0.373032
global_step: 17631, epoch: 41, loss: 0.416732
global_step: 17632, epoch: 41, loss: 0.474140
global_step: 17633, epoch: 41, loss: 0.446323
global_step: 17634, epoch: 41, loss: 0.411819
global_step: 17635, epoch: 41, loss: 0.369350
global_step: 17636, epoch: 41, loss: 0.484380
global_step: 17637, epoch: 41, loss: 0.371783
global_step: 17638, epoch: 41, loss: 0.345448
global_step: 17639, epoch: 41, loss: 0.362215
global_step: 17640, epoch: 41, loss: 0.570827
epoch: 41
train	acc: 0.9500	macro: p 0.9541, r 0.9217, f1: 0.9361	micro: p 0.9500, r 0.9500, f1 0.9500	weighted_f1:0.9501
dev	acc: 0.5347	macro: p 0.3858, r 0.3299, f1: 0.3359	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.5057
test	acc: 0.5521	macro: p 0.3297, r 0.3164, f1: 0.3176	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.5302
New best model!
global_step: 17641, epoch: 42, loss: 0.369415
global_step: 17642, epoch: 42, loss: 0.327684
global_step: 17643, epoch: 42, loss: 0.314690
global_step: 17644, epoch: 42, loss: 0.373329
global_step: 17645, epoch: 42, loss: 0.392323
global_step: 17646, epoch: 42, loss: 0.372083
global_step: 17647, epoch: 42, loss: 0.431857
global_step: 17648, epoch: 42, loss: 0.306221
global_step: 17649, epoch: 42, loss: 0.403543
global_step: 17650, epoch: 42, loss: 0.370085
global_step: 17651, epoch: 42, loss: 0.355631
global_step: 17652, epoch: 42, loss: 0.361347
global_step: 17653, epoch: 42, loss: 0.350344
global_step: 17654, epoch: 42, loss: 0.306971
global_step: 17655, epoch: 42, loss: 0.353541
global_step: 17656, epoch: 42, loss: 0.415808
global_step: 17657, epoch: 42, loss: 0.315377
global_step: 17658, epoch: 42, loss: 0.443857
global_step: 17659, epoch: 42, loss: 0.405918
global_step: 17660, epoch: 42, loss: 0.292198
global_step: 17661, epoch: 42, loss: 0.426512
global_step: 17662, epoch: 42, loss: 0.340070
global_step: 17663, epoch: 42, loss: 0.290072
global_step: 17664, epoch: 42, loss: 0.327152
global_step: 17665, epoch: 42, loss: 0.392721
global_step: 17666, epoch: 42, loss: 0.305905
global_step: 17667, epoch: 42, loss: 0.324829
global_step: 17668, epoch: 42, loss: 0.509772
global_step: 17669, epoch: 42, loss: 0.344741
global_step: 17670, epoch: 42, loss: 0.524457
global_step: 17671, epoch: 42, loss: 0.327634
global_step: 17672, epoch: 42, loss: 0.467571
global_step: 17673, epoch: 42, loss: 0.289027
global_step: 17674, epoch: 42, loss: 0.537969
global_step: 17675, epoch: 42, loss: 0.289170
global_step: 17676, epoch: 42, loss: 0.412186
global_step: 17677, epoch: 42, loss: 0.531748
global_step: 17678, epoch: 42, loss: 0.429912
global_step: 17679, epoch: 42, loss: 0.429679
global_step: 17680, epoch: 42, loss: 0.125415
epoch: 42
train	acc: 0.9525	macro: p 0.9606, r 0.9230, f1: 0.9401	micro: p 0.9525, r 0.9525, f1 0.9525	weighted_f1:0.9525
dev	acc: 0.5374	macro: p 0.4115, r 0.3092, f1: 0.3074	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4898
test	acc: 0.5808	macro: p 0.3703, r 0.3147, f1: 0.3150	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5389
global_step: 17681, epoch: 43, loss: 0.287558
global_step: 17682, epoch: 43, loss: 0.344126
global_step: 17683, epoch: 43, loss: 0.296783
global_step: 17684, epoch: 43, loss: 0.378683
global_step: 17685, epoch: 43, loss: 0.355148
global_step: 17686, epoch: 43, loss: 0.370794
global_step: 17687, epoch: 43, loss: 0.359673
global_step: 17688, epoch: 43, loss: 0.289986
global_step: 17689, epoch: 43, loss: 0.403200
global_step: 17690, epoch: 43, loss: 0.432343
global_step: 17691, epoch: 43, loss: 0.340308
global_step: 17692, epoch: 43, loss: 0.451414
global_step: 17693, epoch: 43, loss: 0.349524
global_step: 17694, epoch: 43, loss: 0.356647
global_step: 17695, epoch: 43, loss: 0.248641
global_step: 17696, epoch: 43, loss: 0.396834
global_step: 17697, epoch: 43, loss: 0.271360
global_step: 17698, epoch: 43, loss: 0.364305
global_step: 17699, epoch: 43, loss: 0.469686
global_step: 17700, epoch: 43, loss: 0.472125
global_step: 17701, epoch: 43, loss: 0.358495
global_step: 17702, epoch: 43, loss: 0.340000
global_step: 17703, epoch: 43, loss: 0.443380
global_step: 17704, epoch: 43, loss: 0.347039
global_step: 17705, epoch: 43, loss: 0.402479
global_step: 17706, epoch: 43, loss: 0.444946
global_step: 17707, epoch: 43, loss: 0.506935
global_step: 17708, epoch: 43, loss: 0.288468
global_step: 17709, epoch: 43, loss: 0.374302
global_step: 17710, epoch: 43, loss: 0.510262
global_step: 17711, epoch: 43, loss: 0.483225
global_step: 17712, epoch: 43, loss: 0.451370
global_step: 17713, epoch: 43, loss: 0.344801
global_step: 17714, epoch: 43, loss: 0.379874
global_step: 17715, epoch: 43, loss: 0.458308
global_step: 17716, epoch: 43, loss: 0.446670
global_step: 17717, epoch: 43, loss: 0.337349
global_step: 17718, epoch: 43, loss: 0.384420
global_step: 17719, epoch: 43, loss: 0.379377
global_step: 17720, epoch: 43, loss: 0.184077
epoch: 43
train	acc: 0.9427	macro: p 0.9578, r 0.9067, f1: 0.9301	micro: p 0.9427, r 0.9427, f1 0.9427	weighted_f1:0.9424
dev	acc: 0.5410	macro: p 0.3523, r 0.2961, f1: 0.2931	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4808
test	acc: 0.5801	macro: p 0.3900, r 0.2995, f1: 0.3077	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5269
global_step: 17721, epoch: 44, loss: 0.469436
global_step: 17722, epoch: 44, loss: 0.379273
global_step: 17723, epoch: 44, loss: 0.371318
global_step: 17724, epoch: 44, loss: 0.343699
global_step: 17725, epoch: 44, loss: 0.408905
global_step: 17726, epoch: 44, loss: 0.297065
global_step: 17727, epoch: 44, loss: 0.395655
global_step: 17728, epoch: 44, loss: 0.337329
global_step: 17729, epoch: 44, loss: 0.375750
global_step: 17730, epoch: 44, loss: 0.259047
global_step: 17731, epoch: 44, loss: 0.329753
global_step: 17732, epoch: 44, loss: 0.309964
global_step: 17733, epoch: 44, loss: 0.304892
global_step: 17734, epoch: 44, loss: 0.253437
global_step: 17735, epoch: 44, loss: 0.312476
global_step: 17736, epoch: 44, loss: 0.394355
global_step: 17737, epoch: 44, loss: 0.310143
global_step: 17738, epoch: 44, loss: 0.431186
global_step: 17739, epoch: 44, loss: 0.425660
global_step: 17740, epoch: 44, loss: 0.421642
global_step: 17741, epoch: 44, loss: 0.320103
global_step: 17742, epoch: 44, loss: 0.394445
global_step: 17743, epoch: 44, loss: 0.458800
global_step: 17744, epoch: 44, loss: 0.341308
global_step: 17745, epoch: 44, loss: 0.322946
global_step: 17746, epoch: 44, loss: 0.420622
global_step: 17747, epoch: 44, loss: 0.354753
global_step: 17748, epoch: 44, loss: 0.414857
global_step: 17749, epoch: 44, loss: 0.347686
global_step: 17750, epoch: 44, loss: 0.323164
global_step: 17751, epoch: 44, loss: 0.362189
global_step: 17752, epoch: 44, loss: 0.431313
global_step: 17753, epoch: 44, loss: 0.344289
global_step: 17754, epoch: 44, loss: 0.534158
global_step: 17755, epoch: 44, loss: 0.358102
global_step: 17756, epoch: 44, loss: 0.455347
global_step: 17757, epoch: 44, loss: 0.394462
global_step: 17758, epoch: 44, loss: 0.393918
global_step: 17759, epoch: 44, loss: 0.361301
global_step: 17760, epoch: 44, loss: 0.616392
epoch: 44
train	acc: 0.9537	macro: p 0.9673, r 0.9270, f1: 0.9461	micro: p 0.9537, r 0.9537, f1 0.9537	weighted_f1:0.9534
dev	acc: 0.5320	macro: p 0.4853, r 0.3119, f1: 0.3296	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4856
test	acc: 0.5682	macro: p 0.3560, r 0.2892, f1: 0.2985	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5223
global_step: 17761, epoch: 45, loss: 0.426375
global_step: 17762, epoch: 45, loss: 0.341624
global_step: 17763, epoch: 45, loss: 0.345118
global_step: 17764, epoch: 45, loss: 0.373097
global_step: 17765, epoch: 45, loss: 0.423104
global_step: 17766, epoch: 45, loss: 0.403185
global_step: 17767, epoch: 45, loss: 0.365761
global_step: 17768, epoch: 45, loss: 0.274140
global_step: 17769, epoch: 45, loss: 0.384270
global_step: 17770, epoch: 45, loss: 0.280690
global_step: 17771, epoch: 45, loss: 0.292295
global_step: 17772, epoch: 45, loss: 0.449302
global_step: 17773, epoch: 45, loss: 0.318152
global_step: 17774, epoch: 45, loss: 0.350578
global_step: 17775, epoch: 45, loss: 0.348763
global_step: 17776, epoch: 45, loss: 0.361191
global_step: 17777, epoch: 45, loss: 0.342500
global_step: 17778, epoch: 45, loss: 0.347236
global_step: 17779, epoch: 45, loss: 0.344733
global_step: 17780, epoch: 45, loss: 0.328982
global_step: 17781, epoch: 45, loss: 0.348883
global_step: 17782, epoch: 45, loss: 0.315348
global_step: 17783, epoch: 45, loss: 0.364205
global_step: 17784, epoch: 45, loss: 0.363308
global_step: 17785, epoch: 45, loss: 0.347120
global_step: 17786, epoch: 45, loss: 0.428595
global_step: 17787, epoch: 45, loss: 0.358806
global_step: 17788, epoch: 45, loss: 0.441369
global_step: 17789, epoch: 45, loss: 0.342398
global_step: 17790, epoch: 45, loss: 0.353598
global_step: 17791, epoch: 45, loss: 0.442174
global_step: 17792, epoch: 45, loss: 0.291037
global_step: 17793, epoch: 45, loss: 0.270141
global_step: 17794, epoch: 45, loss: 0.341296
global_step: 17795, epoch: 45, loss: 0.405033
global_step: 17796, epoch: 45, loss: 0.335778
global_step: 17797, epoch: 45, loss: 0.352284
global_step: 17798, epoch: 45, loss: 0.352737
global_step: 17799, epoch: 45, loss: 0.496357
global_step: 17800, epoch: 45, loss: 0.476223
epoch: 45
train	acc: 0.9583	macro: p 0.9649, r 0.9357, f1: 0.9492	micro: p 0.9583, r 0.9583, f1 0.9583	weighted_f1:0.9582
dev	acc: 0.5410	macro: p 0.4183, r 0.3314, f1: 0.3352	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4996
test	acc: 0.5670	macro: p 0.3621, r 0.3133, f1: 0.3189	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.5313
global_step: 17801, epoch: 46, loss: 0.342109
global_step: 17802, epoch: 46, loss: 0.294610
global_step: 17803, epoch: 46, loss: 0.333763
global_step: 17804, epoch: 46, loss: 0.384949
global_step: 17805, epoch: 46, loss: 0.291777
global_step: 17806, epoch: 46, loss: 0.277810
global_step: 17807, epoch: 46, loss: 0.459327
global_step: 17808, epoch: 46, loss: 0.264131
global_step: 17809, epoch: 46, loss: 0.333821
global_step: 17810, epoch: 46, loss: 0.238449
global_step: 17811, epoch: 46, loss: 0.359781
global_step: 17812, epoch: 46, loss: 0.312837
global_step: 17813, epoch: 46, loss: 0.405062
global_step: 17814, epoch: 46, loss: 0.370906
global_step: 17815, epoch: 46, loss: 0.328516
global_step: 17816, epoch: 46, loss: 0.336427
global_step: 17817, epoch: 46, loss: 0.366003
global_step: 17818, epoch: 46, loss: 0.318727
global_step: 17819, epoch: 46, loss: 0.448959
global_step: 17820, epoch: 46, loss: 0.359647
global_step: 17821, epoch: 46, loss: 0.327941
global_step: 17822, epoch: 46, loss: 0.283384
global_step: 17823, epoch: 46, loss: 0.295774
global_step: 17824, epoch: 46, loss: 0.332429
global_step: 17825, epoch: 46, loss: 0.349339
global_step: 17826, epoch: 46, loss: 0.303511
global_step: 17827, epoch: 46, loss: 0.300984
global_step: 17828, epoch: 46, loss: 0.289634
global_step: 17829, epoch: 46, loss: 0.369134
global_step: 17830, epoch: 46, loss: 0.368972
global_step: 17831, epoch: 46, loss: 0.350058
global_step: 17832, epoch: 46, loss: 0.401400
global_step: 17833, epoch: 46, loss: 0.366517
global_step: 17834, epoch: 46, loss: 0.400221
global_step: 17835, epoch: 46, loss: 0.337622
global_step: 17836, epoch: 46, loss: 0.393339
global_step: 17837, epoch: 46, loss: 0.291136
global_step: 17838, epoch: 46, loss: 0.273769
global_step: 17839, epoch: 46, loss: 0.234950
global_step: 17840, epoch: 46, loss: 0.483777
epoch: 46
train	acc: 0.9598	macro: p 0.9604, r 0.9442, f1: 0.9518	micro: p 0.9598, r 0.9598, f1 0.9598	weighted_f1:0.9599
dev	acc: 0.5176	macro: p 0.3927, r 0.3217, f1: 0.3274	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4863
test	acc: 0.5605	macro: p 0.3452, r 0.3141, f1: 0.3135	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5337
global_step: 17841, epoch: 47, loss: 0.344426
global_step: 17842, epoch: 47, loss: 0.314427
global_step: 17843, epoch: 47, loss: 0.288068
global_step: 17844, epoch: 47, loss: 0.341255
global_step: 17845, epoch: 47, loss: 0.256653
global_step: 17846, epoch: 47, loss: 0.427924
global_step: 17847, epoch: 47, loss: 0.342961
global_step: 17848, epoch: 47, loss: 0.302891
global_step: 17849, epoch: 47, loss: 0.316061
global_step: 17850, epoch: 47, loss: 0.339702
global_step: 17851, epoch: 47, loss: 0.311613
global_step: 17852, epoch: 47, loss: 0.254100
global_step: 17853, epoch: 47, loss: 0.335354
global_step: 17854, epoch: 47, loss: 0.346125
global_step: 17855, epoch: 47, loss: 0.345889
global_step: 17856, epoch: 47, loss: 0.309159
global_step: 17857, epoch: 47, loss: 0.387339
global_step: 17858, epoch: 47, loss: 0.380944
global_step: 17859, epoch: 47, loss: 0.353872
global_step: 17860, epoch: 47, loss: 0.360536
global_step: 17861, epoch: 47, loss: 0.273432
global_step: 17862, epoch: 47, loss: 0.394044
global_step: 17863, epoch: 47, loss: 0.357802
global_step: 17864, epoch: 47, loss: 0.312584
global_step: 17865, epoch: 47, loss: 0.285439
global_step: 17866, epoch: 47, loss: 0.369141
global_step: 17867, epoch: 47, loss: 0.468176
global_step: 17868, epoch: 47, loss: 0.248984
global_step: 17869, epoch: 47, loss: 0.364513
global_step: 17870, epoch: 47, loss: 0.318453
global_step: 17871, epoch: 47, loss: 0.241811
global_step: 17872, epoch: 47, loss: 0.367193
global_step: 17873, epoch: 47, loss: 0.392545
global_step: 17874, epoch: 47, loss: 0.273309
global_step: 17875, epoch: 47, loss: 0.402369
global_step: 17876, epoch: 47, loss: 0.383822
global_step: 17877, epoch: 47, loss: 0.299251
global_step: 17878, epoch: 47, loss: 0.396084
global_step: 17879, epoch: 47, loss: 0.377766
global_step: 17880, epoch: 47, loss: 0.358667
epoch: 47
train	acc: 0.9605	macro: p 0.9646, r 0.9419, f1: 0.9524	micro: p 0.9605, r 0.9605, f1 0.9605	weighted_f1:0.9605
dev	acc: 0.5203	macro: p 0.3752, r 0.3157, f1: 0.3166	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4877
test	acc: 0.5498	macro: p 0.3360, r 0.3088, f1: 0.3102	micro: p 0.5498, r 0.5498, f1 0.5498	weighted_f1:0.5257
global_step: 17881, epoch: 48, loss: 0.277034
global_step: 17882, epoch: 48, loss: 0.328828
global_step: 17883, epoch: 48, loss: 0.272669
global_step: 17884, epoch: 48, loss: 0.233677
global_step: 17885, epoch: 48, loss: 0.339588
global_step: 17886, epoch: 48, loss: 0.374662
global_step: 17887, epoch: 48, loss: 0.265438
global_step: 17888, epoch: 48, loss: 0.415920
global_step: 17889, epoch: 48, loss: 0.280713
global_step: 17890, epoch: 48, loss: 0.406440
global_step: 17891, epoch: 48, loss: 0.408612
global_step: 17892, epoch: 48, loss: 0.396121
global_step: 17893, epoch: 48, loss: 0.277103
global_step: 17894, epoch: 48, loss: 0.265105
global_step: 17895, epoch: 48, loss: 0.395690
global_step: 17896, epoch: 48, loss: 0.219664
global_step: 17897, epoch: 48, loss: 0.309373
global_step: 17898, epoch: 48, loss: 0.278060
global_step: 17899, epoch: 48, loss: 0.339358
global_step: 17900, epoch: 48, loss: 0.317584
global_step: 17901, epoch: 48, loss: 0.295299
global_step: 17902, epoch: 48, loss: 0.356060
global_step: 17903, epoch: 48, loss: 0.303631
global_step: 17904, epoch: 48, loss: 0.362685
global_step: 17905, epoch: 48, loss: 0.309244
global_step: 17906, epoch: 48, loss: 0.344482
global_step: 17907, epoch: 48, loss: 0.400961
global_step: 17908, epoch: 48, loss: 0.335823
global_step: 17909, epoch: 48, loss: 0.302211
global_step: 17910, epoch: 48, loss: 0.327217
global_step: 17911, epoch: 48, loss: 0.318417
global_step: 17912, epoch: 48, loss: 0.360545
global_step: 17913, epoch: 48, loss: 0.411538
global_step: 17914, epoch: 48, loss: 0.380045
global_step: 17915, epoch: 48, loss: 0.262778
global_step: 17916, epoch: 48, loss: 0.404547
global_step: 17917, epoch: 48, loss: 0.405692
global_step: 17918, epoch: 48, loss: 0.369110
global_step: 17919, epoch: 48, loss: 0.322957
global_step: 17920, epoch: 48, loss: 0.510474
epoch: 48
train	acc: 0.9584	macro: p 0.9636, r 0.9361, f1: 0.9490	micro: p 0.9584, r 0.9584, f1 0.9584	weighted_f1:0.9583
dev	acc: 0.5383	macro: p 0.4258, r 0.3221, f1: 0.3367	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4990
test	acc: 0.5640	macro: p 0.3356, r 0.3016, f1: 0.3076	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.5280
global_step: 17921, epoch: 49, loss: 0.406193
global_step: 17922, epoch: 49, loss: 0.383835
global_step: 17923, epoch: 49, loss: 0.282451
global_step: 17924, epoch: 49, loss: 0.365950
global_step: 17925, epoch: 49, loss: 0.339029
global_step: 17926, epoch: 49, loss: 0.331792
global_step: 17927, epoch: 49, loss: 0.342751
global_step: 17928, epoch: 49, loss: 0.315305
global_step: 17929, epoch: 49, loss: 0.313989
global_step: 17930, epoch: 49, loss: 0.286988
global_step: 17931, epoch: 49, loss: 0.377946
global_step: 17932, epoch: 49, loss: 0.312339
global_step: 17933, epoch: 49, loss: 0.331243
global_step: 17934, epoch: 49, loss: 0.247755
global_step: 17935, epoch: 49, loss: 0.321842
global_step: 17936, epoch: 49, loss: 0.267381
global_step: 17937, epoch: 49, loss: 0.348043
global_step: 17938, epoch: 49, loss: 0.268972
global_step: 17939, epoch: 49, loss: 0.334881
global_step: 17940, epoch: 49, loss: 0.392128
global_step: 17941, epoch: 49, loss: 0.277307
global_step: 17942, epoch: 49, loss: 0.286908
global_step: 17943, epoch: 49, loss: 0.343096
global_step: 17944, epoch: 49, loss: 0.275577
global_step: 17945, epoch: 49, loss: 0.361219
global_step: 17946, epoch: 49, loss: 0.333869
global_step: 17947, epoch: 49, loss: 0.327278
global_step: 17948, epoch: 49, loss: 0.385739
global_step: 17949, epoch: 49, loss: 0.377871
global_step: 17950, epoch: 49, loss: 0.319133
global_step: 17951, epoch: 49, loss: 0.343334
global_step: 17952, epoch: 49, loss: 0.335462
global_step: 17953, epoch: 49, loss: 0.349549
global_step: 17954, epoch: 49, loss: 0.255899
global_step: 17955, epoch: 49, loss: 0.408568
global_step: 17956, epoch: 49, loss: 0.348350
global_step: 17957, epoch: 49, loss: 0.328197
global_step: 17958, epoch: 49, loss: 0.372919
global_step: 17959, epoch: 49, loss: 0.290200
global_step: 17960, epoch: 49, loss: 0.292614
epoch: 49
train	acc: 0.9602	macro: p 0.9620, r 0.9418, f1: 0.9515	micro: p 0.9602, r 0.9602, f1 0.9602	weighted_f1:0.9601
dev	acc: 0.5275	macro: p 0.4006, r 0.3257, f1: 0.3371	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4905
test	acc: 0.5559	macro: p 0.3413, r 0.2992, f1: 0.3059	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.5229
global_step: 17961, epoch: 50, loss: 0.275544
global_step: 17962, epoch: 50, loss: 0.291817
global_step: 17963, epoch: 50, loss: 0.272716
global_step: 17964, epoch: 50, loss: 0.351477
global_step: 17965, epoch: 50, loss: 0.246450
global_step: 17966, epoch: 50, loss: 0.337001
global_step: 17967, epoch: 50, loss: 0.303959
global_step: 17968, epoch: 50, loss: 0.267214
global_step: 17969, epoch: 50, loss: 0.280009
global_step: 17970, epoch: 50, loss: 0.359045
global_step: 17971, epoch: 50, loss: 0.314262
global_step: 17972, epoch: 50, loss: 0.261014
global_step: 17973, epoch: 50, loss: 0.260699
global_step: 17974, epoch: 50, loss: 0.296276
global_step: 17975, epoch: 50, loss: 0.280306
global_step: 17976, epoch: 50, loss: 0.377033
global_step: 17977, epoch: 50, loss: 0.318062
global_step: 17978, epoch: 50, loss: 0.259409
global_step: 17979, epoch: 50, loss: 0.265318
global_step: 17980, epoch: 50, loss: 0.261932
global_step: 17981, epoch: 50, loss: 0.297760
global_step: 17982, epoch: 50, loss: 0.394883
global_step: 17983, epoch: 50, loss: 0.304791
global_step: 17984, epoch: 50, loss: 0.350182
global_step: 17985, epoch: 50, loss: 0.361322
global_step: 17986, epoch: 50, loss: 0.439108
global_step: 17987, epoch: 50, loss: 0.299814
global_step: 17988, epoch: 50, loss: 0.325388
global_step: 17989, epoch: 50, loss: 0.401597
global_step: 17990, epoch: 50, loss: 0.367480
global_step: 17991, epoch: 50, loss: 0.368511
global_step: 17992, epoch: 50, loss: 0.311616
global_step: 17993, epoch: 50, loss: 0.288626
global_step: 17994, epoch: 50, loss: 0.304093
global_step: 17995, epoch: 50, loss: 0.361156
global_step: 17996, epoch: 50, loss: 0.273992
global_step: 17997, epoch: 50, loss: 0.262699
global_step: 17998, epoch: 50, loss: 0.355875
global_step: 17999, epoch: 50, loss: 0.284315
global_step: 18000, epoch: 50, loss: 0.189897
epoch: 50
train	acc: 0.9597	macro: p 0.9632, r 0.9437, f1: 0.9530	micro: p 0.9597, r 0.9597, f1 0.9597	weighted_f1:0.9597
dev	acc: 0.5302	macro: p 0.4376, r 0.3282, f1: 0.3394	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4979
test	acc: 0.5575	macro: p 0.3461, r 0.3110, f1: 0.3133	micro: p 0.5575, r 0.5575, f1 0.5575	weighted_f1:0.5314
global_step: 18001, epoch: 51, loss: 0.321098
global_step: 18002, epoch: 51, loss: 0.301568
global_step: 18003, epoch: 51, loss: 0.348551
global_step: 18004, epoch: 51, loss: 0.325070
global_step: 18005, epoch: 51, loss: 0.338576
global_step: 18006, epoch: 51, loss: 0.212335
global_step: 18007, epoch: 51, loss: 0.273221
global_step: 18008, epoch: 51, loss: 0.298505
global_step: 18009, epoch: 51, loss: 0.281909
global_step: 18010, epoch: 51, loss: 0.273946
global_step: 18011, epoch: 51, loss: 0.292772
global_step: 18012, epoch: 51, loss: 0.302652
global_step: 18013, epoch: 51, loss: 0.271293
global_step: 18014, epoch: 51, loss: 0.385828
global_step: 18015, epoch: 51, loss: 0.286402
global_step: 18016, epoch: 51, loss: 0.304948
global_step: 18017, epoch: 51, loss: 0.275524
global_step: 18018, epoch: 51, loss: 0.314656
global_step: 18019, epoch: 51, loss: 0.372638
global_step: 18020, epoch: 51, loss: 0.366132
global_step: 18021, epoch: 51, loss: 0.356375
global_step: 18022, epoch: 51, loss: 0.275937
global_step: 18023, epoch: 51, loss: 0.332285
global_step: 18024, epoch: 51, loss: 0.324338
global_step: 18025, epoch: 51, loss: 0.373481
global_step: 18026, epoch: 51, loss: 0.408377
global_step: 18027, epoch: 51, loss: 0.324615
global_step: 18028, epoch: 51, loss: 0.298795
global_step: 18029, epoch: 51, loss: 0.305073
global_step: 18030, epoch: 51, loss: 0.317556
global_step: 18031, epoch: 51, loss: 0.238161
global_step: 18032, epoch: 51, loss: 0.305776
global_step: 18033, epoch: 51, loss: 0.437018
global_step: 18034, epoch: 51, loss: 0.290993
global_step: 18035, epoch: 51, loss: 0.408348
global_step: 18036, epoch: 51, loss: 0.486091
global_step: 18037, epoch: 51, loss: 0.386944
global_step: 18038, epoch: 51, loss: 0.268686
global_step: 18039, epoch: 51, loss: 0.344167
global_step: 18040, epoch: 51, loss: 0.290793
epoch: 51
train	acc: 0.9630	macro: p 0.9639, r 0.9488, f1: 0.9560	micro: p 0.9630, r 0.9630, f1 0.9630	weighted_f1:0.9630
dev	acc: 0.5320	macro: p 0.4214, r 0.3246, f1: 0.3385	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4954
test	acc: 0.5602	macro: p 0.3558, r 0.3091, f1: 0.3153	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5283
global_step: 18041, epoch: 52, loss: 0.263234
global_step: 18042, epoch: 52, loss: 0.298040
global_step: 18043, epoch: 52, loss: 0.218417
global_step: 18044, epoch: 52, loss: 0.276750
global_step: 18045, epoch: 52, loss: 0.279983
global_step: 18046, epoch: 52, loss: 0.348899
global_step: 18047, epoch: 52, loss: 0.324722
global_step: 18048, epoch: 52, loss: 0.319354
global_step: 18049, epoch: 52, loss: 0.251598
global_step: 18050, epoch: 52, loss: 0.267441
global_step: 18051, epoch: 52, loss: 0.354502
global_step: 18052, epoch: 52, loss: 0.315474
global_step: 18053, epoch: 52, loss: 0.300079
global_step: 18054, epoch: 52, loss: 0.376043
global_step: 18055, epoch: 52, loss: 0.346608
global_step: 18056, epoch: 52, loss: 0.294268
global_step: 18057, epoch: 52, loss: 0.362968
global_step: 18058, epoch: 52, loss: 0.313493
global_step: 18059, epoch: 52, loss: 0.349625
global_step: 18060, epoch: 52, loss: 0.441601
global_step: 18061, epoch: 52, loss: 0.229544
global_step: 18062, epoch: 52, loss: 0.340085
global_step: 18063, epoch: 52, loss: 0.447937
global_step: 18064, epoch: 52, loss: 0.319363
global_step: 18065, epoch: 52, loss: 0.380550
global_step: 18066, epoch: 52, loss: 0.286209
global_step: 18067, epoch: 52, loss: 0.364771
global_step: 18068, epoch: 52, loss: 0.261946
global_step: 18069, epoch: 52, loss: 0.295528
global_step: 18070, epoch: 52, loss: 0.345902
global_step: 18071, epoch: 52, loss: 0.358935
global_step: 18072, epoch: 52, loss: 0.372277
global_step: 18073, epoch: 52, loss: 0.263699
global_step: 18074, epoch: 52, loss: 0.389339
global_step: 18075, epoch: 52, loss: 0.300370
global_step: 18076, epoch: 52, loss: 0.321566
global_step: 18077, epoch: 52, loss: 0.327531
global_step: 18078, epoch: 52, loss: 0.257207
global_step: 18079, epoch: 52, loss: 0.252618
global_step: 18080, epoch: 52, loss: 0.007683
epoch: 52
train	acc: 0.9626	macro: p 0.9667, r 0.9463, f1: 0.9560	micro: p 0.9626, r 0.9626, f1 0.9626	weighted_f1:0.9626
dev	acc: 0.5266	macro: p 0.4423, r 0.3250, f1: 0.3389	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4911
test	acc: 0.5602	macro: p 0.3553, r 0.3092, f1: 0.3126	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5301
global_step: 18081, epoch: 53, loss: 0.276624
global_step: 18082, epoch: 53, loss: 0.263671
global_step: 18083, epoch: 53, loss: 0.318309
global_step: 18084, epoch: 53, loss: 0.264407
global_step: 18085, epoch: 53, loss: 0.248405
global_step: 18086, epoch: 53, loss: 0.324628
global_step: 18087, epoch: 53, loss: 0.238872
global_step: 18088, epoch: 53, loss: 0.353482
global_step: 18089, epoch: 53, loss: 0.266127
global_step: 18090, epoch: 53, loss: 0.360432
global_step: 18091, epoch: 53, loss: 0.248721
global_step: 18092, epoch: 53, loss: 0.305318
global_step: 18093, epoch: 53, loss: 0.212463
global_step: 18094, epoch: 53, loss: 0.249358
global_step: 18095, epoch: 53, loss: 0.309858
global_step: 18096, epoch: 53, loss: 0.302435
global_step: 18097, epoch: 53, loss: 0.301069
global_step: 18098, epoch: 53, loss: 0.272943
global_step: 18099, epoch: 53, loss: 0.392172
global_step: 18100, epoch: 53, loss: 0.284037
global_step: 18101, epoch: 53, loss: 0.341354
global_step: 18102, epoch: 53, loss: 0.316054
global_step: 18103, epoch: 53, loss: 0.318559
global_step: 18104, epoch: 53, loss: 0.273385
global_step: 18105, epoch: 53, loss: 0.256329
global_step: 18106, epoch: 53, loss: 0.349309
global_step: 18107, epoch: 53, loss: 0.333492
global_step: 18108, epoch: 53, loss: 0.298943
global_step: 18109, epoch: 53, loss: 0.375328
global_step: 18110, epoch: 53, loss: 0.326827
global_step: 18111, epoch: 53, loss: 0.360972
global_step: 18112, epoch: 53, loss: 0.371309
global_step: 18113, epoch: 53, loss: 0.282974
global_step: 18114, epoch: 53, loss: 0.309820
global_step: 18115, epoch: 53, loss: 0.301264
global_step: 18116, epoch: 53, loss: 0.370202
global_step: 18117, epoch: 53, loss: 0.400248
global_step: 18118, epoch: 53, loss: 0.302976
global_step: 18119, epoch: 53, loss: 0.354365
global_step: 18120, epoch: 53, loss: 0.159769
epoch: 53
train	acc: 0.9611	macro: p 0.9656, r 0.9452, f1: 0.9547	micro: p 0.9611, r 0.9611, f1 0.9611	weighted_f1:0.9612
dev	acc: 0.4995	macro: p 0.4049, r 0.3239, f1: 0.3259	micro: p 0.4995, r 0.4995, f1 0.4995	weighted_f1:0.4792
test	acc: 0.5418	macro: p 0.3339, r 0.3132, f1: 0.3086	micro: p 0.5418, r 0.5418, f1 0.5418	weighted_f1:0.5212
global_step: 18121, epoch: 54, loss: 0.312848
global_step: 18122, epoch: 54, loss: 0.282966
global_step: 18123, epoch: 54, loss: 0.255299
global_step: 18124, epoch: 54, loss: 0.295607
global_step: 18125, epoch: 54, loss: 0.286215
global_step: 18126, epoch: 54, loss: 0.307249
global_step: 18127, epoch: 54, loss: 0.227138
global_step: 18128, epoch: 54, loss: 0.307586
global_step: 18129, epoch: 54, loss: 0.334620
global_step: 18130, epoch: 54, loss: 0.367092
global_step: 18131, epoch: 54, loss: 0.246373
global_step: 18132, epoch: 54, loss: 0.311286
global_step: 18133, epoch: 54, loss: 0.312161
global_step: 18134, epoch: 54, loss: 0.259156
global_step: 18135, epoch: 54, loss: 0.262780
global_step: 18136, epoch: 54, loss: 0.313630
global_step: 18137, epoch: 54, loss: 0.321112
global_step: 18138, epoch: 54, loss: 0.344343
global_step: 18139, epoch: 54, loss: 0.277559
global_step: 18140, epoch: 54, loss: 0.290689
global_step: 18141, epoch: 54, loss: 0.367736
global_step: 18142, epoch: 54, loss: 0.315939
global_step: 18143, epoch: 54, loss: 0.335538
global_step: 18144, epoch: 54, loss: 0.336832
global_step: 18145, epoch: 54, loss: 0.311268
global_step: 18146, epoch: 54, loss: 0.287207
global_step: 18147, epoch: 54, loss: 0.267234
global_step: 18148, epoch: 54, loss: 0.362335
global_step: 18149, epoch: 54, loss: 0.344618
global_step: 18150, epoch: 54, loss: 0.252132
global_step: 18151, epoch: 54, loss: 0.239342
global_step: 18152, epoch: 54, loss: 0.371859
global_step: 18153, epoch: 54, loss: 0.287393
global_step: 18154, epoch: 54, loss: 0.289294
global_step: 18155, epoch: 54, loss: 0.291119
global_step: 18156, epoch: 54, loss: 0.342535
global_step: 18157, epoch: 54, loss: 0.281383
global_step: 18158, epoch: 54, loss: 0.313754
global_step: 18159, epoch: 54, loss: 0.248283
global_step: 18160, epoch: 54, loss: 0.325194
epoch: 54
train	acc: 0.9619	macro: p 0.9666, r 0.9417, f1: 0.9533	micro: p 0.9619, r 0.9619, f1 0.9619	weighted_f1:0.9619
dev	acc: 0.5185	macro: p 0.4890, r 0.3161, f1: 0.3163	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4833
test	acc: 0.5487	macro: p 0.3571, r 0.3051, f1: 0.3038	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.5187
global_step: 18161, epoch: 55, loss: 0.336100
global_step: 18162, epoch: 55, loss: 0.376666
global_step: 18163, epoch: 55, loss: 0.205344
global_step: 18164, epoch: 55, loss: 0.264396
global_step: 18165, epoch: 55, loss: 0.378639
global_step: 18166, epoch: 55, loss: 0.228286
global_step: 18167, epoch: 55, loss: 0.345743
global_step: 18168, epoch: 55, loss: 0.355357
global_step: 18169, epoch: 55, loss: 0.331500
global_step: 18170, epoch: 55, loss: 0.282727
global_step: 18171, epoch: 55, loss: 0.306466
global_step: 18172, epoch: 55, loss: 0.419941
global_step: 18173, epoch: 55, loss: 0.246078
global_step: 18174, epoch: 55, loss: 0.296893
global_step: 18175, epoch: 55, loss: 0.296022
global_step: 18176, epoch: 55, loss: 0.347808
global_step: 18177, epoch: 55, loss: 0.294963
global_step: 18178, epoch: 55, loss: 0.294870
global_step: 18179, epoch: 55, loss: 0.313017
global_step: 18180, epoch: 55, loss: 0.364686
global_step: 18181, epoch: 55, loss: 0.340267
global_step: 18182, epoch: 55, loss: 0.310915
global_step: 18183, epoch: 55, loss: 0.269253
global_step: 18184, epoch: 55, loss: 0.281927
global_step: 18185, epoch: 55, loss: 0.264298
global_step: 18186, epoch: 55, loss: 0.370838
global_step: 18187, epoch: 55, loss: 0.331722
global_step: 18188, epoch: 55, loss: 0.305131
global_step: 18189, epoch: 55, loss: 0.380049
global_step: 18190, epoch: 55, loss: 0.316704
global_step: 18191, epoch: 55, loss: 0.367169
global_step: 18192, epoch: 55, loss: 0.321026
global_step: 18193, epoch: 55, loss: 0.286231
global_step: 18194, epoch: 55, loss: 0.272453
global_step: 18195, epoch: 55, loss: 0.305962
global_step: 18196, epoch: 55, loss: 0.239315
global_step: 18197, epoch: 55, loss: 0.246219
global_step: 18198, epoch: 55, loss: 0.252520
global_step: 18199, epoch: 55, loss: 0.355253
global_step: 18200, epoch: 55, loss: 0.572495
epoch: 55
train	acc: 0.9644	macro: p 0.9678, r 0.9493, f1: 0.9581	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.5257	macro: p 0.3977, r 0.3206, f1: 0.3238	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4875
test	acc: 0.5613	macro: p 0.3436, r 0.3074, f1: 0.3088	micro: p 0.5613, r 0.5613, f1 0.5613	weighted_f1:0.5280
global_step: 18201, epoch: 56, loss: 0.278926
global_step: 18202, epoch: 56, loss: 0.266581
global_step: 18203, epoch: 56, loss: 0.308971
global_step: 18204, epoch: 56, loss: 0.213672
global_step: 18205, epoch: 56, loss: 0.252459
global_step: 18206, epoch: 56, loss: 0.356915
global_step: 18207, epoch: 56, loss: 0.267619
global_step: 18208, epoch: 56, loss: 0.278338
global_step: 18209, epoch: 56, loss: 0.262020
global_step: 18210, epoch: 56, loss: 0.233985
global_step: 18211, epoch: 56, loss: 0.230327
global_step: 18212, epoch: 56, loss: 0.219978
global_step: 18213, epoch: 56, loss: 0.262653
global_step: 18214, epoch: 56, loss: 0.361481
global_step: 18215, epoch: 56, loss: 0.355207
global_step: 18216, epoch: 56, loss: 0.321083
global_step: 18217, epoch: 56, loss: 0.257266
global_step: 18218, epoch: 56, loss: 0.265428
global_step: 18219, epoch: 56, loss: 0.200234
global_step: 18220, epoch: 56, loss: 0.366553
global_step: 18221, epoch: 56, loss: 0.306143
global_step: 18222, epoch: 56, loss: 0.270128
global_step: 18223, epoch: 56, loss: 0.278836
global_step: 18224, epoch: 56, loss: 0.461783
global_step: 18225, epoch: 56, loss: 0.285804
global_step: 18226, epoch: 56, loss: 0.312860
global_step: 18227, epoch: 56, loss: 0.340084
global_step: 18228, epoch: 56, loss: 0.191592
global_step: 18229, epoch: 56, loss: 0.241645
global_step: 18230, epoch: 56, loss: 0.279310
global_step: 18231, epoch: 56, loss: 0.282710
global_step: 18232, epoch: 56, loss: 0.307111
global_step: 18233, epoch: 56, loss: 0.288343
global_step: 18234, epoch: 56, loss: 0.324882
global_step: 18235, epoch: 56, loss: 0.247614
global_step: 18236, epoch: 56, loss: 0.344749
global_step: 18237, epoch: 56, loss: 0.262130
global_step: 18238, epoch: 56, loss: 0.316618
global_step: 18239, epoch: 56, loss: 0.252743
global_step: 18240, epoch: 56, loss: 0.139050
epoch: 56
train	acc: 0.9640	macro: p 0.9658, r 0.9490, f1: 0.9569	micro: p 0.9640, r 0.9640, f1 0.9640	weighted_f1:0.9640
dev	acc: 0.5239	macro: p 0.4210, r 0.3232, f1: 0.3358	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4920
test	acc: 0.5628	macro: p 0.3448, r 0.3102, f1: 0.3139	micro: p 0.5628, r 0.5628, f1 0.5628	weighted_f1:0.5326
global_step: 18241, epoch: 57, loss: 0.357784
global_step: 18242, epoch: 57, loss: 0.227821
global_step: 18243, epoch: 57, loss: 0.277004
global_step: 18244, epoch: 57, loss: 0.308794
global_step: 18245, epoch: 57, loss: 0.253594
global_step: 18246, epoch: 57, loss: 0.187295
global_step: 18247, epoch: 57, loss: 0.247890
global_step: 18248, epoch: 57, loss: 0.161407
global_step: 18249, epoch: 57, loss: 0.310739
global_step: 18250, epoch: 57, loss: 0.259607
global_step: 18251, epoch: 57, loss: 0.291411
global_step: 18252, epoch: 57, loss: 0.386504
global_step: 18253, epoch: 57, loss: 0.290544
global_step: 18254, epoch: 57, loss: 0.296178
global_step: 18255, epoch: 57, loss: 0.248457
global_step: 18256, epoch: 57, loss: 0.258373
global_step: 18257, epoch: 57, loss: 0.344561
global_step: 18258, epoch: 57, loss: 0.239017
global_step: 18259, epoch: 57, loss: 0.235145
global_step: 18260, epoch: 57, loss: 0.208434
global_step: 18261, epoch: 57, loss: 0.324074
global_step: 18262, epoch: 57, loss: 0.332005
global_step: 18263, epoch: 57, loss: 0.352931
global_step: 18264, epoch: 57, loss: 0.363030
global_step: 18265, epoch: 57, loss: 0.311952
global_step: 18266, epoch: 57, loss: 0.272358
global_step: 18267, epoch: 57, loss: 0.320394
global_step: 18268, epoch: 57, loss: 0.248126
global_step: 18269, epoch: 57, loss: 0.325730
global_step: 18270, epoch: 57, loss: 0.258701
global_step: 18271, epoch: 57, loss: 0.336344
global_step: 18272, epoch: 57, loss: 0.279996
global_step: 18273, epoch: 57, loss: 0.323469
global_step: 18274, epoch: 57, loss: 0.345074
global_step: 18275, epoch: 57, loss: 0.396371
global_step: 18276, epoch: 57, loss: 0.374302
global_step: 18277, epoch: 57, loss: 0.320749
global_step: 18278, epoch: 57, loss: 0.278428
global_step: 18279, epoch: 57, loss: 0.319687
global_step: 18280, epoch: 57, loss: 0.052091
epoch: 57
train	acc: 0.9644	macro: p 0.9687, r 0.9482, f1: 0.9580	micro: p 0.9644, r 0.9644, f1 0.9644	weighted_f1:0.9644
dev	acc: 0.5239	macro: p 0.3995, r 0.3234, f1: 0.3313	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4917
test	acc: 0.5540	macro: p 0.3501, r 0.3090, f1: 0.3127	micro: p 0.5540, r 0.5540, f1 0.5540	weighted_f1:0.5286
global_step: 18281, epoch: 58, loss: 0.281949
global_step: 18282, epoch: 58, loss: 0.248915
global_step: 18283, epoch: 58, loss: 0.278824
global_step: 18284, epoch: 58, loss: 0.215395
global_step: 18285, epoch: 58, loss: 0.282926
global_step: 18286, epoch: 58, loss: 0.349466
global_step: 18287, epoch: 58, loss: 0.384485
global_step: 18288, epoch: 58, loss: 0.275601
global_step: 18289, epoch: 58, loss: 0.261091
global_step: 18290, epoch: 58, loss: 0.326856
global_step: 18291, epoch: 58, loss: 0.240415
global_step: 18292, epoch: 58, loss: 0.323337
global_step: 18293, epoch: 58, loss: 0.306670
global_step: 18294, epoch: 58, loss: 0.324348
global_step: 18295, epoch: 58, loss: 0.282372
global_step: 18296, epoch: 58, loss: 0.325320
global_step: 18297, epoch: 58, loss: 0.286870
global_step: 18298, epoch: 58, loss: 0.256697
global_step: 18299, epoch: 58, loss: 0.251754
global_step: 18300, epoch: 58, loss: 0.308905
global_step: 18301, epoch: 58, loss: 0.340740
global_step: 18302, epoch: 58, loss: 0.214136
global_step: 18303, epoch: 58, loss: 0.401022
global_step: 18304, epoch: 58, loss: 0.235639
global_step: 18305, epoch: 58, loss: 0.368427
global_step: 18306, epoch: 58, loss: 0.258226
global_step: 18307, epoch: 58, loss: 0.319727
global_step: 18308, epoch: 58, loss: 0.272486
global_step: 18309, epoch: 58, loss: 0.291678
global_step: 18310, epoch: 58, loss: 0.287971
global_step: 18311, epoch: 58, loss: 0.342007
global_step: 18312, epoch: 58, loss: 0.183692
global_step: 18313, epoch: 58, loss: 0.256982
global_step: 18314, epoch: 58, loss: 0.241244
global_step: 18315, epoch: 58, loss: 0.333136
global_step: 18316, epoch: 58, loss: 0.402196
global_step: 18317, epoch: 58, loss: 0.332751
global_step: 18318, epoch: 58, loss: 0.349142
global_step: 18319, epoch: 58, loss: 0.294782
global_step: 18320, epoch: 58, loss: 0.007899
epoch: 58
train	acc: 0.9641	macro: p 0.9678, r 0.9498, f1: 0.9583	micro: p 0.9641, r 0.9641, f1 0.9641	weighted_f1:0.9641
dev	acc: 0.5185	macro: p 0.4145, r 0.3214, f1: 0.3295	micro: p 0.5185, r 0.5185, f1 0.5185	weighted_f1:0.4866
test	acc: 0.5533	macro: p 0.3320, r 0.3130, f1: 0.3131	micro: p 0.5533, r 0.5533, f1 0.5533	weighted_f1:0.5290
global_step: 18321, epoch: 59, loss: 0.377451
global_step: 18322, epoch: 59, loss: 0.305699
global_step: 18323, epoch: 59, loss: 0.212158
global_step: 18324, epoch: 59, loss: 0.272049
global_step: 18325, epoch: 59, loss: 0.267688
global_step: 18326, epoch: 59, loss: 0.283044
global_step: 18327, epoch: 59, loss: 0.272181
global_step: 18328, epoch: 59, loss: 0.296438
global_step: 18329, epoch: 59, loss: 0.322710
global_step: 18330, epoch: 59, loss: 0.295799
global_step: 18331, epoch: 59, loss: 0.234680
global_step: 18332, epoch: 59, loss: 0.295888
global_step: 18333, epoch: 59, loss: 0.246022
global_step: 18334, epoch: 59, loss: 0.249399
global_step: 18335, epoch: 59, loss: 0.280213
global_step: 18336, epoch: 59, loss: 0.203087
global_step: 18337, epoch: 59, loss: 0.254854
global_step: 18338, epoch: 59, loss: 0.227013
global_step: 18339, epoch: 59, loss: 0.314714
global_step: 18340, epoch: 59, loss: 0.280336
global_step: 18341, epoch: 59, loss: 0.211633
global_step: 18342, epoch: 59, loss: 0.325127
global_step: 18343, epoch: 59, loss: 0.240766
global_step: 18344, epoch: 59, loss: 0.240644
global_step: 18345, epoch: 59, loss: 0.251520
global_step: 18346, epoch: 59, loss: 0.226574
global_step: 18347, epoch: 59, loss: 0.329858
global_step: 18348, epoch: 59, loss: 0.181457
global_step: 18349, epoch: 59, loss: 0.383170
global_step: 18350, epoch: 59, loss: 0.240879
global_step: 18351, epoch: 59, loss: 0.297576
global_step: 18352, epoch: 59, loss: 0.426213
global_step: 18353, epoch: 59, loss: 0.239881
global_step: 18354, epoch: 59, loss: 0.313974
global_step: 18355, epoch: 59, loss: 0.399908
global_step: 18356, epoch: 59, loss: 0.256157
global_step: 18357, epoch: 59, loss: 0.350794
global_step: 18358, epoch: 59, loss: 0.275237
global_step: 18359, epoch: 59, loss: 0.283526
global_step: 18360, epoch: 59, loss: 0.047367
epoch: 59
train	acc: 0.9655	macro: p 0.9689, r 0.9516, f1: 0.9599	micro: p 0.9655, r 0.9655, f1 0.9655	weighted_f1:0.9655
dev	acc: 0.5257	macro: p 0.4658, r 0.3215, f1: 0.3338	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4899
test	acc: 0.5617	macro: p 0.3516, r 0.3080, f1: 0.3127	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5308
global_step: 18361, epoch: 60, loss: 0.287675
global_step: 18362, epoch: 60, loss: 0.330661
global_step: 18363, epoch: 60, loss: 0.203215
global_step: 18364, epoch: 60, loss: 0.285295
global_step: 18365, epoch: 60, loss: 0.252592
global_step: 18366, epoch: 60, loss: 0.271997
global_step: 18367, epoch: 60, loss: 0.286148
global_step: 18368, epoch: 60, loss: 0.279267
global_step: 18369, epoch: 60, loss: 0.217636
global_step: 18370, epoch: 60, loss: 0.236540
global_step: 18371, epoch: 60, loss: 0.234242
global_step: 18372, epoch: 60, loss: 0.330405
global_step: 18373, epoch: 60, loss: 0.248370
global_step: 18374, epoch: 60, loss: 0.369544
global_step: 18375, epoch: 60, loss: 0.279372
global_step: 18376, epoch: 60, loss: 0.271478
global_step: 18377, epoch: 60, loss: 0.239269
global_step: 18378, epoch: 60, loss: 0.268170
global_step: 18379, epoch: 60, loss: 0.331193
global_step: 18380, epoch: 60, loss: 0.302775
global_step: 18381, epoch: 60, loss: 0.273311
global_step: 18382, epoch: 60, loss: 0.374551
global_step: 18383, epoch: 60, loss: 0.378306
global_step: 18384, epoch: 60, loss: 0.300507
global_step: 18385, epoch: 60, loss: 0.300138
global_step: 18386, epoch: 60, loss: 0.311631
global_step: 18387, epoch: 60, loss: 0.275275
global_step: 18388, epoch: 60, loss: 0.451567
global_step: 18389, epoch: 60, loss: 0.256182
global_step: 18390, epoch: 60, loss: 0.330107
global_step: 18391, epoch: 60, loss: 0.282770
global_step: 18392, epoch: 60, loss: 0.287542
global_step: 18393, epoch: 60, loss: 0.410884
global_step: 18394, epoch: 60, loss: 0.359826
global_step: 18395, epoch: 60, loss: 0.200803
global_step: 18396, epoch: 60, loss: 0.315452
global_step: 18397, epoch: 60, loss: 0.269194
global_step: 18398, epoch: 60, loss: 0.278396
global_step: 18399, epoch: 60, loss: 0.210905
global_step: 18400, epoch: 60, loss: 0.095657
epoch: 60
train	acc: 0.9663	macro: p 0.9685, r 0.9523, f1: 0.9599	micro: p 0.9663, r 0.9663, f1 0.9663	weighted_f1:0.9663
dev	acc: 0.5167	macro: p 0.3829, r 0.3206, f1: 0.3294	micro: p 0.5167, r 0.5167, f1 0.5167	weighted_f1:0.4859
test	acc: 0.5590	macro: p 0.3483, r 0.3153, f1: 0.3214	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5320
global_step: 18401, epoch: 61, loss: 0.239363
global_step: 18402, epoch: 61, loss: 0.265411
global_step: 18403, epoch: 61, loss: 0.272736
global_step: 18404, epoch: 61, loss: 0.320718
global_step: 18405, epoch: 61, loss: 0.243791
global_step: 18406, epoch: 61, loss: 0.236776
global_step: 18407, epoch: 61, loss: 0.335445
global_step: 18408, epoch: 61, loss: 0.248313
global_step: 18409, epoch: 61, loss: 0.464894
global_step: 18410, epoch: 61, loss: 0.302463
global_step: 18411, epoch: 61, loss: 0.306242
global_step: 18412, epoch: 61, loss: 0.252847
global_step: 18413, epoch: 61, loss: 0.311560
global_step: 18414, epoch: 61, loss: 0.232758
global_step: 18415, epoch: 61, loss: 0.300141
global_step: 18416, epoch: 61, loss: 0.240741
global_step: 18417, epoch: 61, loss: 0.300165
global_step: 18418, epoch: 61, loss: 0.331145
global_step: 18419, epoch: 61, loss: 0.324550
global_step: 18420, epoch: 61, loss: 0.209084
global_step: 18421, epoch: 61, loss: 0.231219
global_step: 18422, epoch: 61, loss: 0.244089
global_step: 18423, epoch: 61, loss: 0.255477
global_step: 18424, epoch: 61, loss: 0.276529
global_step: 18425, epoch: 61, loss: 0.307699
global_step: 18426, epoch: 61, loss: 0.372569
global_step: 18427, epoch: 61, loss: 0.259392
global_step: 18428, epoch: 61, loss: 0.286013
global_step: 18429, epoch: 61, loss: 0.279495
global_step: 18430, epoch: 61, loss: 0.300052
global_step: 18431, epoch: 61, loss: 0.319513
global_step: 18432, epoch: 61, loss: 0.228108
global_step: 18433, epoch: 61, loss: 0.419341
global_step: 18434, epoch: 61, loss: 0.342839
global_step: 18435, epoch: 61, loss: 0.321091
global_step: 18436, epoch: 61, loss: 0.332074
global_step: 18437, epoch: 61, loss: 0.257110
global_step: 18438, epoch: 61, loss: 0.383205
global_step: 18439, epoch: 61, loss: 0.394016
global_step: 18440, epoch: 61, loss: 0.156821
epoch: 61
train	acc: 0.9654	macro: p 0.9710, r 0.9495, f1: 0.9596	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9654
dev	acc: 0.5176	macro: p 0.4160, r 0.3208, f1: 0.3263	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.4834
test	acc: 0.5510	macro: p 0.3505, r 0.3111, f1: 0.3141	micro: p 0.5510, r 0.5510, f1 0.5510	weighted_f1:0.5221
global_step: 18441, epoch: 62, loss: 0.326100
global_step: 18442, epoch: 62, loss: 0.268257
global_step: 18443, epoch: 62, loss: 0.235718
global_step: 18444, epoch: 62, loss: 0.271090
global_step: 18445, epoch: 62, loss: 0.252832
global_step: 18446, epoch: 62, loss: 0.293810
global_step: 18447, epoch: 62, loss: 0.225192
global_step: 18448, epoch: 62, loss: 0.273972
global_step: 18449, epoch: 62, loss: 0.279566
global_step: 18450, epoch: 62, loss: 0.388592
global_step: 18451, epoch: 62, loss: 0.262282
global_step: 18452, epoch: 62, loss: 0.213849
global_step: 18453, epoch: 62, loss: 0.305041
global_step: 18454, epoch: 62, loss: 0.239043
global_step: 18455, epoch: 62, loss: 0.266072
global_step: 18456, epoch: 62, loss: 0.295427
global_step: 18457, epoch: 62, loss: 0.277676
global_step: 18458, epoch: 62, loss: 0.275383
global_step: 18459, epoch: 62, loss: 0.282467
global_step: 18460, epoch: 62, loss: 0.245954
global_step: 18461, epoch: 62, loss: 0.313012
global_step: 18462, epoch: 62, loss: 0.255274
global_step: 18463, epoch: 62, loss: 0.358028
global_step: 18464, epoch: 62, loss: 0.302156
global_step: 18465, epoch: 62, loss: 0.233244
global_step: 18466, epoch: 62, loss: 0.239647
global_step: 18467, epoch: 62, loss: 0.399305
global_step: 18468, epoch: 62, loss: 0.249730
global_step: 18469, epoch: 62, loss: 0.377481
global_step: 18470, epoch: 62, loss: 0.368115
global_step: 18471, epoch: 62, loss: 0.283304
global_step: 18472, epoch: 62, loss: 0.276577
global_step: 18473, epoch: 62, loss: 0.270388
global_step: 18474, epoch: 62, loss: 0.286700
global_step: 18475, epoch: 62, loss: 0.288735
global_step: 18476, epoch: 62, loss: 0.273632
global_step: 18477, epoch: 62, loss: 0.374535
global_step: 18478, epoch: 62, loss: 0.271510
global_step: 18479, epoch: 62, loss: 0.315890
global_step: 18480, epoch: 62, loss: 0.388703
epoch: 62
train	acc: 0.9631	macro: p 0.9704, r 0.9455, f1: 0.9573	micro: p 0.9631, r 0.9631, f1 0.9631	weighted_f1:0.9631
dev	acc: 0.5077	macro: p 0.5052, r 0.3177, f1: 0.3230	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4738
test	acc: 0.5490	macro: p 0.3744, r 0.3036, f1: 0.3030	micro: p 0.5490, r 0.5490, f1 0.5490	weighted_f1:0.5190
global_step: 18481, epoch: 63, loss: 0.272602
global_step: 18482, epoch: 63, loss: 0.198106
global_step: 18483, epoch: 63, loss: 0.221717
global_step: 18484, epoch: 63, loss: 0.231343
global_step: 18485, epoch: 63, loss: 0.190304
global_step: 18486, epoch: 63, loss: 0.307423
global_step: 18487, epoch: 63, loss: 0.284725
global_step: 18488, epoch: 63, loss: 0.254168
global_step: 18489, epoch: 63, loss: 0.266190
global_step: 18490, epoch: 63, loss: 0.234956
global_step: 18491, epoch: 63, loss: 0.272809
global_step: 18492, epoch: 63, loss: 0.334889
global_step: 18493, epoch: 63, loss: 0.304077
global_step: 18494, epoch: 63, loss: 0.305944
global_step: 18495, epoch: 63, loss: 0.268476
global_step: 18496, epoch: 63, loss: 0.203860
global_step: 18497, epoch: 63, loss: 0.329604
global_step: 18498, epoch: 63, loss: 0.219433
global_step: 18499, epoch: 63, loss: 0.291554
global_step: 18500, epoch: 63, loss: 0.254557
global_step: 18501, epoch: 63, loss: 0.375279
global_step: 18502, epoch: 63, loss: 0.286755
global_step: 18503, epoch: 63, loss: 0.331626
global_step: 18504, epoch: 63, loss: 0.285850
global_step: 18505, epoch: 63, loss: 0.257559
global_step: 18506, epoch: 63, loss: 0.240242
global_step: 18507, epoch: 63, loss: 0.322375
global_step: 18508, epoch: 63, loss: 0.341583
global_step: 18509, epoch: 63, loss: 0.283497
global_step: 18510, epoch: 63, loss: 0.229499
global_step: 18511, epoch: 63, loss: 0.308450
global_step: 18512, epoch: 63, loss: 0.313704
global_step: 18513, epoch: 63, loss: 0.268175
global_step: 18514, epoch: 63, loss: 0.313531
global_step: 18515, epoch: 63, loss: 0.293350
global_step: 18516, epoch: 63, loss: 0.283164
global_step: 18517, epoch: 63, loss: 0.231472
global_step: 18518, epoch: 63, loss: 0.214388
global_step: 18519, epoch: 63, loss: 0.307591
global_step: 18520, epoch: 63, loss: 0.104918
epoch: 63
train	acc: 0.9654	macro: p 0.9690, r 0.9489, f1: 0.9586	micro: p 0.9654, r 0.9654, f1 0.9654	weighted_f1:0.9654
dev	acc: 0.5266	macro: p 0.5372, r 0.3133, f1: 0.3300	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4868
test	acc: 0.5659	macro: p 0.3687, r 0.3042, f1: 0.3113	micro: p 0.5659, r 0.5659, f1 0.5659	weighted_f1:0.5292
global_step: 18521, epoch: 64, loss: 0.215524
global_step: 18522, epoch: 64, loss: 0.240612
global_step: 18523, epoch: 64, loss: 0.339830
global_step: 18524, epoch: 64, loss: 0.208083
global_step: 18525, epoch: 64, loss: 0.271857
global_step: 18526, epoch: 64, loss: 0.323374
global_step: 18527, epoch: 64, loss: 0.201733
global_step: 18528, epoch: 64, loss: 0.296471
global_step: 18529, epoch: 64, loss: 0.237482
global_step: 18530, epoch: 64, loss: 0.150380
global_step: 18531, epoch: 64, loss: 0.269452
global_step: 18532, epoch: 64, loss: 0.314216
global_step: 18533, epoch: 64, loss: 0.243605
global_step: 18534, epoch: 64, loss: 0.219758
global_step: 18535, epoch: 64, loss: 0.284382
global_step: 18536, epoch: 64, loss: 0.224796
global_step: 18537, epoch: 64, loss: 0.329270
global_step: 18538, epoch: 64, loss: 0.301334
global_step: 18539, epoch: 64, loss: 0.309391
global_step: 18540, epoch: 64, loss: 0.211008
global_step: 18541, epoch: 64, loss: 0.297345
global_step: 18542, epoch: 64, loss: 0.297363
global_step: 18543, epoch: 64, loss: 0.231527
global_step: 18544, epoch: 64, loss: 0.280208
global_step: 18545, epoch: 64, loss: 0.305589
global_step: 18546, epoch: 64, loss: 0.262343
global_step: 18547, epoch: 64, loss: 0.336063
global_step: 18548, epoch: 64, loss: 0.302176
global_step: 18549, epoch: 64, loss: 0.250607
global_step: 18550, epoch: 64, loss: 0.240797
global_step: 18551, epoch: 64, loss: 0.334615
global_step: 18552, epoch: 64, loss: 0.333113
global_step: 18553, epoch: 64, loss: 0.277719
global_step: 18554, epoch: 64, loss: 0.272217
global_step: 18555, epoch: 64, loss: 0.307686
global_step: 18556, epoch: 64, loss: 0.232825
global_step: 18557, epoch: 64, loss: 0.284237
global_step: 18558, epoch: 64, loss: 0.232672
global_step: 18559, epoch: 64, loss: 0.281780
global_step: 18560, epoch: 64, loss: 0.003142
epoch: 64
train	acc: 0.9658	macro: p 0.9713, r 0.9508, f1: 0.9606	micro: p 0.9658, r 0.9658, f1 0.9658	weighted_f1:0.9658
dev	acc: 0.5392	macro: p 0.4214, r 0.3173, f1: 0.3245	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4934
test	acc: 0.5701	macro: p 0.3939, r 0.3037, f1: 0.3107	micro: p 0.5701, r 0.5701, f1 0.5701	weighted_f1:0.5271
global_step: 18561, epoch: 65, loss: 0.223709
global_step: 18562, epoch: 65, loss: 0.231321
global_step: 18563, epoch: 65, loss: 0.217686
global_step: 18564, epoch: 65, loss: 0.318605
global_step: 18565, epoch: 65, loss: 0.250692
global_step: 18566, epoch: 65, loss: 0.226365
global_step: 18567, epoch: 65, loss: 0.234856
global_step: 18568, epoch: 65, loss: 0.302119
global_step: 18569, epoch: 65, loss: 0.241049
global_step: 18570, epoch: 65, loss: 0.255341
global_step: 18571, epoch: 65, loss: 0.272897
global_step: 18572, epoch: 65, loss: 0.180476
global_step: 18573, epoch: 65, loss: 0.262524
global_step: 18574, epoch: 65, loss: 0.269656
global_step: 18575, epoch: 65, loss: 0.203327
global_step: 18576, epoch: 65, loss: 0.253494
global_step: 18577, epoch: 65, loss: 0.290906
global_step: 18578, epoch: 65, loss: 0.289921
global_step: 18579, epoch: 65, loss: 0.331172
global_step: 18580, epoch: 65, loss: 0.262282
global_step: 18581, epoch: 65, loss: 0.276356
global_step: 18582, epoch: 65, loss: 0.201005
global_step: 18583, epoch: 65, loss: 0.383628
global_step: 18584, epoch: 65, loss: 0.301100
global_step: 18585, epoch: 65, loss: 0.248665
global_step: 18586, epoch: 65, loss: 0.226745
global_step: 18587, epoch: 65, loss: 0.270980
global_step: 18588, epoch: 65, loss: 0.281891
global_step: 18589, epoch: 65, loss: 0.298036
global_step: 18590, epoch: 65, loss: 0.282168
global_step: 18591, epoch: 65, loss: 0.318513
global_step: 18592, epoch: 65, loss: 0.288370
global_step: 18593, epoch: 65, loss: 0.331966
global_step: 18594, epoch: 65, loss: 0.204620
global_step: 18595, epoch: 65, loss: 0.211531
global_step: 18596, epoch: 65, loss: 0.306126
global_step: 18597, epoch: 65, loss: 0.323572
global_step: 18598, epoch: 65, loss: 0.203261
global_step: 18599, epoch: 65, loss: 0.339945
global_step: 18600, epoch: 65, loss: 0.100386
epoch: 65
train	acc: 0.9652	macro: p 0.9673, r 0.9503, f1: 0.9583	micro: p 0.9652, r 0.9652, f1 0.9652	weighted_f1:0.9652
dev	acc: 0.5050	macro: p 0.4245, r 0.3052, f1: 0.3061	micro: p 0.5050, r 0.5050, f1 0.5050	weighted_f1:0.4727
test	acc: 0.5529	macro: p 0.3610, r 0.3086, f1: 0.3102	micro: p 0.5529, r 0.5529, f1 0.5529	weighted_f1:0.5237
global_step: 18601, epoch: 66, loss: 0.215488
global_step: 18602, epoch: 66, loss: 0.290036
global_step: 18603, epoch: 66, loss: 0.257479
global_step: 18604, epoch: 66, loss: 0.239563
global_step: 18605, epoch: 66, loss: 0.238684
global_step: 18606, epoch: 66, loss: 0.218088
global_step: 18607, epoch: 66, loss: 0.213615
global_step: 18608, epoch: 66, loss: 0.307750
global_step: 18609, epoch: 66, loss: 0.231552
global_step: 18610, epoch: 66, loss: 0.278931
global_step: 18611, epoch: 66, loss: 0.277066
global_step: 18612, epoch: 66, loss: 0.323138
global_step: 18613, epoch: 66, loss: 0.191728
global_step: 18614, epoch: 66, loss: 0.295154
global_step: 18615, epoch: 66, loss: 0.245298
global_step: 18616, epoch: 66, loss: 0.243112
global_step: 18617, epoch: 66, loss: 0.304418
global_step: 18618, epoch: 66, loss: 0.287337
global_step: 18619, epoch: 66, loss: 0.289993
global_step: 18620, epoch: 66, loss: 0.255643
global_step: 18621, epoch: 66, loss: 0.296136
global_step: 18622, epoch: 66, loss: 0.219287
global_step: 18623, epoch: 66, loss: 0.286480
global_step: 18624, epoch: 66, loss: 0.293534
global_step: 18625, epoch: 66, loss: 0.271819
global_step: 18626, epoch: 66, loss: 0.294751
global_step: 18627, epoch: 66, loss: 0.258810
global_step: 18628, epoch: 66, loss: 0.262254
global_step: 18629, epoch: 66, loss: 0.267011
global_step: 18630, epoch: 66, loss: 0.351774
global_step: 18631, epoch: 66, loss: 0.368451
global_step: 18632, epoch: 66, loss: 0.265499
global_step: 18633, epoch: 66, loss: 0.294541
global_step: 18634, epoch: 66, loss: 0.187299
global_step: 18635, epoch: 66, loss: 0.289931
global_step: 18636, epoch: 66, loss: 0.231137
global_step: 18637, epoch: 66, loss: 0.235954
global_step: 18638, epoch: 66, loss: 0.277779
global_step: 18639, epoch: 66, loss: 0.249685
global_step: 18640, epoch: 66, loss: 0.377809
epoch: 66
train	acc: 0.9650	macro: p 0.9715, r 0.9482, f1: 0.9593	micro: p 0.9650, r 0.9650, f1 0.9650	weighted_f1:0.9650
dev	acc: 0.5257	macro: p 0.5363, r 0.3067, f1: 0.3209	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4753
test	acc: 0.5686	macro: p 0.3539, r 0.2945, f1: 0.2997	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.5226
global_step: 18641, epoch: 67, loss: 0.297053
global_step: 18642, epoch: 67, loss: 0.219440
global_step: 18643, epoch: 67, loss: 0.272392
global_step: 18644, epoch: 67, loss: 0.264208
global_step: 18645, epoch: 67, loss: 0.263706
global_step: 18646, epoch: 67, loss: 0.256006
global_step: 18647, epoch: 67, loss: 0.225455
global_step: 18648, epoch: 67, loss: 0.234062
global_step: 18649, epoch: 67, loss: 0.292324
global_step: 18650, epoch: 67, loss: 0.265272
global_step: 18651, epoch: 67, loss: 0.302207
global_step: 18652, epoch: 67, loss: 0.297190
global_step: 18653, epoch: 67, loss: 0.242246
global_step: 18654, epoch: 67, loss: 0.371594
global_step: 18655, epoch: 67, loss: 0.323006
global_step: 18656, epoch: 67, loss: 0.259356
global_step: 18657, epoch: 67, loss: 0.215649
global_step: 18658, epoch: 67, loss: 0.215819
global_step: 18659, epoch: 67, loss: 0.268377
global_step: 18660, epoch: 67, loss: 0.276258
global_step: 18661, epoch: 67, loss: 0.219741
global_step: 18662, epoch: 67, loss: 0.296465
global_step: 18663, epoch: 67, loss: 0.185779
global_step: 18664, epoch: 67, loss: 0.236736
global_step: 18665, epoch: 67, loss: 0.241106
global_step: 18666, epoch: 67, loss: 0.367801
global_step: 18667, epoch: 67, loss: 0.222299
global_step: 18668, epoch: 67, loss: 0.259893
global_step: 18669, epoch: 67, loss: 0.291410
global_step: 18670, epoch: 67, loss: 0.257177
global_step: 18671, epoch: 67, loss: 0.167788
global_step: 18672, epoch: 67, loss: 0.267385
global_step: 18673, epoch: 67, loss: 0.338424
global_step: 18674, epoch: 67, loss: 0.430676
global_step: 18675, epoch: 67, loss: 0.291340
global_step: 18676, epoch: 67, loss: 0.371924
global_step: 18677, epoch: 67, loss: 0.339580
global_step: 18678, epoch: 67, loss: 0.367940
global_step: 18679, epoch: 67, loss: 0.317279
global_step: 18680, epoch: 67, loss: 0.644062
epoch: 67
train	acc: 0.9656	macro: p 0.9699, r 0.9530, f1: 0.9611	micro: p 0.9656, r 0.9656, f1 0.9656	weighted_f1:0.9656
dev	acc: 0.5158	macro: p 0.4796, r 0.3132, f1: 0.3248	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4801
test	acc: 0.5636	macro: p 0.3746, r 0.3071, f1: 0.3100	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5294
global_step: 18681, epoch: 68, loss: 0.232318
global_step: 18682, epoch: 68, loss: 0.267763
global_step: 18683, epoch: 68, loss: 0.202040
global_step: 18684, epoch: 68, loss: 0.271390
global_step: 18685, epoch: 68, loss: 0.220649
global_step: 18686, epoch: 68, loss: 0.219897
global_step: 18687, epoch: 68, loss: 0.269827
global_step: 18688, epoch: 68, loss: 0.220942
global_step: 18689, epoch: 68, loss: 0.202540
global_step: 18690, epoch: 68, loss: 0.265360
global_step: 18691, epoch: 68, loss: 0.202187
global_step: 18692, epoch: 68, loss: 0.324847
global_step: 18693, epoch: 68, loss: 0.229619
global_step: 18694, epoch: 68, loss: 0.281137
global_step: 18695, epoch: 68, loss: 0.286664
global_step: 18696, epoch: 68, loss: 0.247709
global_step: 18697, epoch: 68, loss: 0.333921
global_step: 18698, epoch: 68, loss: 0.170532
global_step: 18699, epoch: 68, loss: 0.239146
global_step: 18700, epoch: 68, loss: 0.316467
global_step: 18701, epoch: 68, loss: 0.227030
global_step: 18702, epoch: 68, loss: 0.202301
global_step: 18703, epoch: 68, loss: 0.231656
global_step: 18704, epoch: 68, loss: 0.243651
global_step: 18705, epoch: 68, loss: 0.261331
global_step: 18706, epoch: 68, loss: 0.202106
global_step: 18707, epoch: 68, loss: 0.241100
global_step: 18708, epoch: 68, loss: 0.279293
global_step: 18709, epoch: 68, loss: 0.263642
global_step: 18710, epoch: 68, loss: 0.243339
global_step: 18711, epoch: 68, loss: 0.389537
global_step: 18712, epoch: 68, loss: 0.244949
global_step: 18713, epoch: 68, loss: 0.286883
global_step: 18714, epoch: 68, loss: 0.338255
global_step: 18715, epoch: 68, loss: 0.253913
global_step: 18716, epoch: 68, loss: 0.289614
global_step: 18717, epoch: 68, loss: 0.293144
global_step: 18718, epoch: 68, loss: 0.299162
global_step: 18719, epoch: 68, loss: 0.229181
global_step: 18720, epoch: 68, loss: 0.520056
epoch: 68
train	acc: 0.9634	macro: p 0.9700, r 0.9479, f1: 0.9582	micro: p 0.9634, r 0.9634, f1 0.9634	weighted_f1:0.9635
dev	acc: 0.5068	macro: p 0.3424, r 0.3031, f1: 0.3029	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4759
test	acc: 0.5475	macro: p 0.3339, r 0.3005, f1: 0.2968	micro: p 0.5475, r 0.5475, f1 0.5475	weighted_f1:0.5185
global_step: 18721, epoch: 69, loss: 0.289649
global_step: 18722, epoch: 69, loss: 0.241387
global_step: 18723, epoch: 69, loss: 0.314783
global_step: 18724, epoch: 69, loss: 0.190816
global_step: 18725, epoch: 69, loss: 0.278395
global_step: 18726, epoch: 69, loss: 0.267852
global_step: 18727, epoch: 69, loss: 0.253634
global_step: 18728, epoch: 69, loss: 0.258635
global_step: 18729, epoch: 69, loss: 0.211594
global_step: 18730, epoch: 69, loss: 0.290553
global_step: 18731, epoch: 69, loss: 0.218759
global_step: 18732, epoch: 69, loss: 0.269612
global_step: 18733, epoch: 69, loss: 0.233230
global_step: 18734, epoch: 69, loss: 0.247258
global_step: 18735, epoch: 69, loss: 0.238919
global_step: 18736, epoch: 69, loss: 0.279675
global_step: 18737, epoch: 69, loss: 0.351255
global_step: 18738, epoch: 69, loss: 0.265201
global_step: 18739, epoch: 69, loss: 0.258972
global_step: 18740, epoch: 69, loss: 0.212084
global_step: 18741, epoch: 69, loss: 0.269439
global_step: 18742, epoch: 69, loss: 0.244686
global_step: 18743, epoch: 69, loss: 0.161550
global_step: 18744, epoch: 69, loss: 0.278359
global_step: 18745, epoch: 69, loss: 0.334274
global_step: 18746, epoch: 69, loss: 0.295728
global_step: 18747, epoch: 69, loss: 0.303603
global_step: 18748, epoch: 69, loss: 0.232960
global_step: 18749, epoch: 69, loss: 0.192939
global_step: 18750, epoch: 69, loss: 0.290989
global_step: 18751, epoch: 69, loss: 0.244246
global_step: 18752, epoch: 69, loss: 0.283763
global_step: 18753, epoch: 69, loss: 0.251906
global_step: 18754, epoch: 69, loss: 0.208099
global_step: 18755, epoch: 69, loss: 0.215170
global_step: 18756, epoch: 69, loss: 0.306396
global_step: 18757, epoch: 69, loss: 0.248725
global_step: 18758, epoch: 69, loss: 0.261567
global_step: 18759, epoch: 69, loss: 0.235903
global_step: 18760, epoch: 69, loss: 1.426921
epoch: 69
train	acc: 0.9657	macro: p 0.9689, r 0.9526, f1: 0.9604	micro: p 0.9657, r 0.9657, f1 0.9657	weighted_f1:0.9657
dev	acc: 0.5266	macro: p 0.4087, r 0.2998, f1: 0.3108	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4762
test	acc: 0.5644	macro: p 0.3776, r 0.2920, f1: 0.3018	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5170
global_step: 18761, epoch: 70, loss: 0.283115
global_step: 18762, epoch: 70, loss: 0.261514
global_step: 18763, epoch: 70, loss: 0.214826
global_step: 18764, epoch: 70, loss: 0.263833
global_step: 18765, epoch: 70, loss: 0.226787
global_step: 18766, epoch: 70, loss: 0.297695
global_step: 18767, epoch: 70, loss: 0.231291
global_step: 18768, epoch: 70, loss: 0.210138
global_step: 18769, epoch: 70, loss: 0.254057
global_step: 18770, epoch: 70, loss: 0.290075
global_step: 18771, epoch: 70, loss: 0.246602
global_step: 18772, epoch: 70, loss: 0.154613
global_step: 18773, epoch: 70, loss: 0.197739
global_step: 18774, epoch: 70, loss: 0.354003
global_step: 18775, epoch: 70, loss: 0.220582
global_step: 18776, epoch: 70, loss: 0.239148
global_step: 18777, epoch: 70, loss: 0.289578
global_step: 18778, epoch: 70, loss: 0.347170
global_step: 18779, epoch: 70, loss: 0.226627
global_step: 18780, epoch: 70, loss: 0.274421
global_step: 18781, epoch: 70, loss: 0.279331
global_step: 18782, epoch: 70, loss: 0.275814
global_step: 18783, epoch: 70, loss: 0.185467
global_step: 18784, epoch: 70, loss: 0.249678
global_step: 18785, epoch: 70, loss: 0.227943
global_step: 18786, epoch: 70, loss: 0.214026
global_step: 18787, epoch: 70, loss: 0.242723
global_step: 18788, epoch: 70, loss: 0.408298
global_step: 18789, epoch: 70, loss: 0.248463
global_step: 18790, epoch: 70, loss: 0.283118
global_step: 18791, epoch: 70, loss: 0.221351
global_step: 18792, epoch: 70, loss: 0.292740
global_step: 18793, epoch: 70, loss: 0.201684
global_step: 18794, epoch: 70, loss: 0.308121
global_step: 18795, epoch: 70, loss: 0.199919
global_step: 18796, epoch: 70, loss: 0.186574
global_step: 18797, epoch: 70, loss: 0.257246
global_step: 18798, epoch: 70, loss: 0.304057
global_step: 18799, epoch: 70, loss: 0.274469
global_step: 18800, epoch: 70, loss: 0.210206
epoch: 70
train	acc: 0.9670	macro: p 0.9704, r 0.9542, f1: 0.9620	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5329	macro: p 0.4400, r 0.3129, f1: 0.3277	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4871
test	acc: 0.5667	macro: p 0.3448, r 0.2986, f1: 0.3051	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5267
global_step: 18801, epoch: 71, loss: 0.315546
global_step: 18802, epoch: 71, loss: 0.294863
global_step: 18803, epoch: 71, loss: 0.188873
global_step: 18804, epoch: 71, loss: 0.284907
global_step: 18805, epoch: 71, loss: 0.163895
global_step: 18806, epoch: 71, loss: 0.200642
global_step: 18807, epoch: 71, loss: 0.147072
global_step: 18808, epoch: 71, loss: 0.253981
global_step: 18809, epoch: 71, loss: 0.244209
global_step: 18810, epoch: 71, loss: 0.256461
global_step: 18811, epoch: 71, loss: 0.231960
global_step: 18812, epoch: 71, loss: 0.247387
global_step: 18813, epoch: 71, loss: 0.225254
global_step: 18814, epoch: 71, loss: 0.231948
global_step: 18815, epoch: 71, loss: 0.219590
global_step: 18816, epoch: 71, loss: 0.285243
global_step: 18817, epoch: 71, loss: 0.315324
global_step: 18818, epoch: 71, loss: 0.264608
global_step: 18819, epoch: 71, loss: 0.332401
global_step: 18820, epoch: 71, loss: 0.232797
global_step: 18821, epoch: 71, loss: 0.298918
global_step: 18822, epoch: 71, loss: 0.186380
global_step: 18823, epoch: 71, loss: 0.210912
global_step: 18824, epoch: 71, loss: 0.264399
global_step: 18825, epoch: 71, loss: 0.242552
global_step: 18826, epoch: 71, loss: 0.230163
global_step: 18827, epoch: 71, loss: 0.232660
global_step: 18828, epoch: 71, loss: 0.264852
global_step: 18829, epoch: 71, loss: 0.279792
global_step: 18830, epoch: 71, loss: 0.306296
global_step: 18831, epoch: 71, loss: 0.206421
global_step: 18832, epoch: 71, loss: 0.216709
global_step: 18833, epoch: 71, loss: 0.229630
global_step: 18834, epoch: 71, loss: 0.294225
global_step: 18835, epoch: 71, loss: 0.298575
global_step: 18836, epoch: 71, loss: 0.291005
global_step: 18837, epoch: 71, loss: 0.313903
global_step: 18838, epoch: 71, loss: 0.216810
global_step: 18839, epoch: 71, loss: 0.254513
global_step: 18840, epoch: 71, loss: 0.039651
epoch: 71
train	acc: 0.9669	macro: p 0.9706, r 0.9554, f1: 0.9626	micro: p 0.9669, r 0.9669, f1 0.9669	weighted_f1:0.9670
dev	acc: 0.5248	macro: p 0.3954, r 0.3206, f1: 0.3322	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4914
test	acc: 0.5548	macro: p 0.3462, r 0.3100, f1: 0.3164	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.5278
global_step: 18841, epoch: 72, loss: 0.235832
global_step: 18842, epoch: 72, loss: 0.210222
global_step: 18843, epoch: 72, loss: 0.224897
global_step: 18844, epoch: 72, loss: 0.206455
global_step: 18845, epoch: 72, loss: 0.189883
global_step: 18846, epoch: 72, loss: 0.200395
global_step: 18847, epoch: 72, loss: 0.222150
global_step: 18848, epoch: 72, loss: 0.332294
global_step: 18849, epoch: 72, loss: 0.230990
global_step: 18850, epoch: 72, loss: 0.243269
global_step: 18851, epoch: 72, loss: 0.203904
global_step: 18852, epoch: 72, loss: 0.272769
global_step: 18853, epoch: 72, loss: 0.250073
global_step: 18854, epoch: 72, loss: 0.210125
global_step: 18855, epoch: 72, loss: 0.329891
global_step: 18856, epoch: 72, loss: 0.197270
global_step: 18857, epoch: 72, loss: 0.333016
global_step: 18858, epoch: 72, loss: 0.197255
global_step: 18859, epoch: 72, loss: 0.231290
global_step: 18860, epoch: 72, loss: 0.255277
global_step: 18861, epoch: 72, loss: 0.250678
global_step: 18862, epoch: 72, loss: 0.264931
global_step: 18863, epoch: 72, loss: 0.204275
global_step: 18864, epoch: 72, loss: 0.250031
global_step: 18865, epoch: 72, loss: 0.262057
global_step: 18866, epoch: 72, loss: 0.277119
global_step: 18867, epoch: 72, loss: 0.311165
global_step: 18868, epoch: 72, loss: 0.305080
global_step: 18869, epoch: 72, loss: 0.321999
global_step: 18870, epoch: 72, loss: 0.305241
global_step: 18871, epoch: 72, loss: 0.326584
global_step: 18872, epoch: 72, loss: 0.222785
global_step: 18873, epoch: 72, loss: 0.211264
global_step: 18874, epoch: 72, loss: 0.243531
global_step: 18875, epoch: 72, loss: 0.199493
global_step: 18876, epoch: 72, loss: 0.188840
global_step: 18877, epoch: 72, loss: 0.233979
global_step: 18878, epoch: 72, loss: 0.235070
global_step: 18879, epoch: 72, loss: 0.317185
global_step: 18880, epoch: 72, loss: 0.560836
epoch: 72
train	acc: 0.9675	macro: p 0.9713, r 0.9544, f1: 0.9625	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9675
dev	acc: 0.5293	macro: p 0.4532, r 0.3211, f1: 0.3349	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4891
test	acc: 0.5644	macro: p 0.3582, r 0.3081, f1: 0.3187	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.5304
global_step: 18881, epoch: 73, loss: 0.220994
global_step: 18882, epoch: 73, loss: 0.275310
global_step: 18883, epoch: 73, loss: 0.180779
global_step: 18884, epoch: 73, loss: 0.229329
global_step: 18885, epoch: 73, loss: 0.244209
global_step: 18886, epoch: 73, loss: 0.173183
global_step: 18887, epoch: 73, loss: 0.211519
global_step: 18888, epoch: 73, loss: 0.191316
global_step: 18889, epoch: 73, loss: 0.213502
global_step: 18890, epoch: 73, loss: 0.262922
global_step: 18891, epoch: 73, loss: 0.204794
global_step: 18892, epoch: 73, loss: 0.222438
global_step: 18893, epoch: 73, loss: 0.222324
global_step: 18894, epoch: 73, loss: 0.150141
global_step: 18895, epoch: 73, loss: 0.194477
global_step: 18896, epoch: 73, loss: 0.282820
global_step: 18897, epoch: 73, loss: 0.278446
global_step: 18898, epoch: 73, loss: 0.262090
global_step: 18899, epoch: 73, loss: 0.250971
global_step: 18900, epoch: 73, loss: 0.315471
global_step: 18901, epoch: 73, loss: 0.246469
global_step: 18902, epoch: 73, loss: 0.309193
global_step: 18903, epoch: 73, loss: 0.224939
global_step: 18904, epoch: 73, loss: 0.207044
global_step: 18905, epoch: 73, loss: 0.252645
global_step: 18906, epoch: 73, loss: 0.225310
global_step: 18907, epoch: 73, loss: 0.300611
global_step: 18908, epoch: 73, loss: 0.198150
global_step: 18909, epoch: 73, loss: 0.216455
global_step: 18910, epoch: 73, loss: 0.254824
global_step: 18911, epoch: 73, loss: 0.242338
global_step: 18912, epoch: 73, loss: 0.228750
global_step: 18913, epoch: 73, loss: 0.192624
global_step: 18914, epoch: 73, loss: 0.279527
global_step: 18915, epoch: 73, loss: 0.209747
global_step: 18916, epoch: 73, loss: 0.301262
global_step: 18917, epoch: 73, loss: 0.328493
global_step: 18918, epoch: 73, loss: 0.271261
global_step: 18919, epoch: 73, loss: 0.239094
global_step: 18920, epoch: 73, loss: 0.289076
epoch: 73
train	acc: 0.9680	macro: p 0.9723, r 0.9552, f1: 0.9633	micro: p 0.9680, r 0.9680, f1 0.9680	weighted_f1:0.9680
dev	acc: 0.5329	macro: p 0.4305, r 0.3232, f1: 0.3367	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4921
test	acc: 0.5598	macro: p 0.3627, r 0.3034, f1: 0.3105	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.5245
global_step: 18921, epoch: 74, loss: 0.185869
global_step: 18922, epoch: 74, loss: 0.180709
global_step: 18923, epoch: 74, loss: 0.220108
global_step: 18924, epoch: 74, loss: 0.248916
global_step: 18925, epoch: 74, loss: 0.152427
global_step: 18926, epoch: 74, loss: 0.255035
global_step: 18927, epoch: 74, loss: 0.213678
global_step: 18928, epoch: 74, loss: 0.201815
global_step: 18929, epoch: 74, loss: 0.220460
global_step: 18930, epoch: 74, loss: 0.214773
global_step: 18931, epoch: 74, loss: 0.247944
global_step: 18932, epoch: 74, loss: 0.205370
global_step: 18933, epoch: 74, loss: 0.121860
global_step: 18934, epoch: 74, loss: 0.252947
global_step: 18935, epoch: 74, loss: 0.191341
global_step: 18936, epoch: 74, loss: 0.275348
global_step: 18937, epoch: 74, loss: 0.243449
global_step: 18938, epoch: 74, loss: 0.267478
global_step: 18939, epoch: 74, loss: 0.293336
global_step: 18940, epoch: 74, loss: 0.193115
global_step: 18941, epoch: 74, loss: 0.261782
global_step: 18942, epoch: 74, loss: 0.273594
global_step: 18943, epoch: 74, loss: 0.345267
global_step: 18944, epoch: 74, loss: 0.228675
global_step: 18945, epoch: 74, loss: 0.246134
global_step: 18946, epoch: 74, loss: 0.225284
global_step: 18947, epoch: 74, loss: 0.221906
global_step: 18948, epoch: 74, loss: 0.191974
global_step: 18949, epoch: 74, loss: 0.234601
global_step: 18950, epoch: 74, loss: 0.233168
global_step: 18951, epoch: 74, loss: 0.264213
global_step: 18952, epoch: 74, loss: 0.246181
global_step: 18953, epoch: 74, loss: 0.197981
global_step: 18954, epoch: 74, loss: 0.348890
global_step: 18955, epoch: 74, loss: 0.383376
global_step: 18956, epoch: 74, loss: 0.307679
global_step: 18957, epoch: 74, loss: 0.215370
global_step: 18958, epoch: 74, loss: 0.228205
global_step: 18959, epoch: 74, loss: 0.207597
global_step: 18960, epoch: 74, loss: 0.215655
epoch: 74
train	acc: 0.9670	macro: p 0.9702, r 0.9535, f1: 0.9615	micro: p 0.9670, r 0.9670, f1 0.9670	weighted_f1:0.9670
dev	acc: 0.5302	macro: p 0.4394, r 0.3266, f1: 0.3412	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4959
test	acc: 0.5506	macro: p 0.3387, r 0.3012, f1: 0.3060	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.5225
global_step: 18961, epoch: 75, loss: 0.231715
global_step: 18962, epoch: 75, loss: 0.249718
global_step: 18963, epoch: 75, loss: 0.198340
global_step: 18964, epoch: 75, loss: 0.270551
global_step: 18965, epoch: 75, loss: 0.176838
global_step: 18966, epoch: 75, loss: 0.231892
global_step: 18967, epoch: 75, loss: 0.146919
global_step: 18968, epoch: 75, loss: 0.228839
global_step: 18969, epoch: 75, loss: 0.264585
global_step: 18970, epoch: 75, loss: 0.289646
global_step: 18971, epoch: 75, loss: 0.346289
global_step: 18972, epoch: 75, loss: 0.197113
global_step: 18973, epoch: 75, loss: 0.243178
global_step: 18974, epoch: 75, loss: 0.309110
global_step: 18975, epoch: 75, loss: 0.269018
global_step: 18976, epoch: 75, loss: 0.235432
global_step: 18977, epoch: 75, loss: 0.242485
global_step: 18978, epoch: 75, loss: 0.201174
global_step: 18979, epoch: 75, loss: 0.350861
global_step: 18980, epoch: 75, loss: 0.179630
global_step: 18981, epoch: 75, loss: 0.302197
global_step: 18982, epoch: 75, loss: 0.252470
global_step: 18983, epoch: 75, loss: 0.177840
global_step: 18984, epoch: 75, loss: 0.267909
global_step: 18985, epoch: 75, loss: 0.242780
global_step: 18986, epoch: 75, loss: 0.257683
global_step: 18987, epoch: 75, loss: 0.301585
global_step: 18988, epoch: 75, loss: 0.256529
global_step: 18989, epoch: 75, loss: 0.156916
global_step: 18990, epoch: 75, loss: 0.181110
global_step: 18991, epoch: 75, loss: 0.264815
global_step: 18992, epoch: 75, loss: 0.270283
global_step: 18993, epoch: 75, loss: 0.217272
global_step: 18994, epoch: 75, loss: 0.299694
global_step: 18995, epoch: 75, loss: 0.210362
global_step: 18996, epoch: 75, loss: 0.219470
global_step: 18997, epoch: 75, loss: 0.251736
global_step: 18998, epoch: 75, loss: 0.254921
global_step: 18999, epoch: 75, loss: 0.221430
global_step: 19000, epoch: 75, loss: 0.251294
epoch: 75
train	acc: 0.9674	macro: p 0.9706, r 0.9550, f1: 0.9624	micro: p 0.9674, r 0.9674, f1 0.9674	weighted_f1:0.9675
dev	acc: 0.5104	macro: p 0.3938, r 0.3124, f1: 0.3163	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4781
test	acc: 0.5494	macro: p 0.3529, r 0.3105, f1: 0.3145	micro: p 0.5494, r 0.5494, f1 0.5494	weighted_f1:0.5219
global_step: 19001, epoch: 76, loss: 0.303446
global_step: 19002, epoch: 76, loss: 0.211054
global_step: 19003, epoch: 76, loss: 0.231049
global_step: 19004, epoch: 76, loss: 0.261143
global_step: 19005, epoch: 76, loss: 0.172039
global_step: 19006, epoch: 76, loss: 0.242045
global_step: 19007, epoch: 76, loss: 0.230633
global_step: 19008, epoch: 76, loss: 0.238741
global_step: 19009, epoch: 76, loss: 0.277610
global_step: 19010, epoch: 76, loss: 0.194841
global_step: 19011, epoch: 76, loss: 0.186346
global_step: 19012, epoch: 76, loss: 0.286902
global_step: 19013, epoch: 76, loss: 0.187016
global_step: 19014, epoch: 76, loss: 0.237776
global_step: 19015, epoch: 76, loss: 0.196572
global_step: 19016, epoch: 76, loss: 0.272265
global_step: 19017, epoch: 76, loss: 0.257517
global_step: 19018, epoch: 76, loss: 0.215806
global_step: 19019, epoch: 76, loss: 0.256632
global_step: 19020, epoch: 76, loss: 0.266044
global_step: 19021, epoch: 76, loss: 0.202847
global_step: 19022, epoch: 76, loss: 0.218117
global_step: 19023, epoch: 76, loss: 0.388565
global_step: 19024, epoch: 76, loss: 0.208661
global_step: 19025, epoch: 76, loss: 0.281354
global_step: 19026, epoch: 76, loss: 0.312041
global_step: 19027, epoch: 76, loss: 0.259806
global_step: 19028, epoch: 76, loss: 0.263372
global_step: 19029, epoch: 76, loss: 0.239327
global_step: 19030, epoch: 76, loss: 0.245654
global_step: 19031, epoch: 76, loss: 0.239764
global_step: 19032, epoch: 76, loss: 0.233716
global_step: 19033, epoch: 76, loss: 0.293464
global_step: 19034, epoch: 76, loss: 0.247767
global_step: 19035, epoch: 76, loss: 0.246182
global_step: 19036, epoch: 76, loss: 0.251300
global_step: 19037, epoch: 76, loss: 0.288058
global_step: 19038, epoch: 76, loss: 0.263849
global_step: 19039, epoch: 76, loss: 0.223263
global_step: 19040, epoch: 76, loss: 0.043326
epoch: 76
train	acc: 0.9683	macro: p 0.9728, r 0.9529, f1: 0.9623	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5203	macro: p 0.3915, r 0.3054, f1: 0.3101	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4785
test	acc: 0.5590	macro: p 0.3419, r 0.3018, f1: 0.3070	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5230
global_step: 19041, epoch: 77, loss: 0.194956
global_step: 19042, epoch: 77, loss: 0.260256
global_step: 19043, epoch: 77, loss: 0.257503
global_step: 19044, epoch: 77, loss: 0.250425
global_step: 19045, epoch: 77, loss: 0.290262
global_step: 19046, epoch: 77, loss: 0.218923
global_step: 19047, epoch: 77, loss: 0.316813
global_step: 19048, epoch: 77, loss: 0.223201
global_step: 19049, epoch: 77, loss: 0.268308
global_step: 19050, epoch: 77, loss: 0.273027
global_step: 19051, epoch: 77, loss: 0.174655
global_step: 19052, epoch: 77, loss: 0.163240
global_step: 19053, epoch: 77, loss: 0.253318
global_step: 19054, epoch: 77, loss: 0.219946
global_step: 19055, epoch: 77, loss: 0.231140
global_step: 19056, epoch: 77, loss: 0.181263
global_step: 19057, epoch: 77, loss: 0.240101
global_step: 19058, epoch: 77, loss: 0.322384
global_step: 19059, epoch: 77, loss: 0.223794
global_step: 19060, epoch: 77, loss: 0.239869
global_step: 19061, epoch: 77, loss: 0.283768
global_step: 19062, epoch: 77, loss: 0.281351
global_step: 19063, epoch: 77, loss: 0.215734
global_step: 19064, epoch: 77, loss: 0.266833
global_step: 19065, epoch: 77, loss: 0.242289
global_step: 19066, epoch: 77, loss: 0.272216
global_step: 19067, epoch: 77, loss: 0.194826
global_step: 19068, epoch: 77, loss: 0.198861
global_step: 19069, epoch: 77, loss: 0.352063
global_step: 19070, epoch: 77, loss: 0.229804
global_step: 19071, epoch: 77, loss: 0.295787
global_step: 19072, epoch: 77, loss: 0.165456
global_step: 19073, epoch: 77, loss: 0.291540
global_step: 19074, epoch: 77, loss: 0.208756
global_step: 19075, epoch: 77, loss: 0.239863
global_step: 19076, epoch: 77, loss: 0.276014
global_step: 19077, epoch: 77, loss: 0.285773
global_step: 19078, epoch: 77, loss: 0.240370
global_step: 19079, epoch: 77, loss: 0.245968
global_step: 19080, epoch: 77, loss: 0.033285
epoch: 77
train	acc: 0.9687	macro: p 0.9716, r 0.9564, f1: 0.9637	micro: p 0.9687, r 0.9687, f1 0.9687	weighted_f1:0.9687
dev	acc: 0.5140	macro: p 0.4263, r 0.3048, f1: 0.3145	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4763
test	acc: 0.5594	macro: p 0.3751, r 0.3126, f1: 0.3217	micro: p 0.5594, r 0.5594, f1 0.5594	weighted_f1:0.5282
global_step: 19081, epoch: 78, loss: 0.248439
global_step: 19082, epoch: 78, loss: 0.178686
global_step: 19083, epoch: 78, loss: 0.177155
global_step: 19084, epoch: 78, loss: 0.207535
global_step: 19085, epoch: 78, loss: 0.238526
global_step: 19086, epoch: 78, loss: 0.202738
global_step: 19087, epoch: 78, loss: 0.226699
global_step: 19088, epoch: 78, loss: 0.267124
global_step: 19089, epoch: 78, loss: 0.270968
global_step: 19090, epoch: 78, loss: 0.306590
global_step: 19091, epoch: 78, loss: 0.157244
global_step: 19092, epoch: 78, loss: 0.205993
global_step: 19093, epoch: 78, loss: 0.360909
global_step: 19094, epoch: 78, loss: 0.202918
global_step: 19095, epoch: 78, loss: 0.261739
global_step: 19096, epoch: 78, loss: 0.239076
global_step: 19097, epoch: 78, loss: 0.247636
global_step: 19098, epoch: 78, loss: 0.240115
global_step: 19099, epoch: 78, loss: 0.192851
global_step: 19100, epoch: 78, loss: 0.271292
global_step: 19101, epoch: 78, loss: 0.190947
global_step: 19102, epoch: 78, loss: 0.286036
global_step: 19103, epoch: 78, loss: 0.191452
global_step: 19104, epoch: 78, loss: 0.128096
global_step: 19105, epoch: 78, loss: 0.322138
global_step: 19106, epoch: 78, loss: 0.203870
global_step: 19107, epoch: 78, loss: 0.206691
global_step: 19108, epoch: 78, loss: 0.199982
global_step: 19109, epoch: 78, loss: 0.239066
global_step: 19110, epoch: 78, loss: 0.238022
global_step: 19111, epoch: 78, loss: 0.200238
global_step: 19112, epoch: 78, loss: 0.221383
global_step: 19113, epoch: 78, loss: 0.249966
global_step: 19114, epoch: 78, loss: 0.250348
global_step: 19115, epoch: 78, loss: 0.164640
global_step: 19116, epoch: 78, loss: 0.216004
global_step: 19117, epoch: 78, loss: 0.240072
global_step: 19118, epoch: 78, loss: 0.279015
global_step: 19119, epoch: 78, loss: 0.293479
global_step: 19120, epoch: 78, loss: 0.779814
epoch: 78
train	acc: 0.9679	macro: p 0.9715, r 0.9570, f1: 0.9639	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9680
dev	acc: 0.5284	macro: p 0.3963, r 0.3165, f1: 0.3214	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4907
test	acc: 0.5605	macro: p 0.3517, r 0.3099, f1: 0.3156	micro: p 0.5605, r 0.5605, f1 0.5605	weighted_f1:0.5293
global_step: 19121, epoch: 79, loss: 0.253980
global_step: 19122, epoch: 79, loss: 0.252642
global_step: 19123, epoch: 79, loss: 0.255930
global_step: 19124, epoch: 79, loss: 0.206838
global_step: 19125, epoch: 79, loss: 0.266247
global_step: 19126, epoch: 79, loss: 0.294765
global_step: 19127, epoch: 79, loss: 0.243887
global_step: 19128, epoch: 79, loss: 0.229947
global_step: 19129, epoch: 79, loss: 0.263982
global_step: 19130, epoch: 79, loss: 0.238179
global_step: 19131, epoch: 79, loss: 0.230263
global_step: 19132, epoch: 79, loss: 0.268217
global_step: 19133, epoch: 79, loss: 0.199802
global_step: 19134, epoch: 79, loss: 0.234968
global_step: 19135, epoch: 79, loss: 0.166552
global_step: 19136, epoch: 79, loss: 0.157574
global_step: 19137, epoch: 79, loss: 0.192148
global_step: 19138, epoch: 79, loss: 0.264828
global_step: 19139, epoch: 79, loss: 0.355160
global_step: 19140, epoch: 79, loss: 0.252567
global_step: 19141, epoch: 79, loss: 0.200877
global_step: 19142, epoch: 79, loss: 0.372497
global_step: 19143, epoch: 79, loss: 0.190590
global_step: 19144, epoch: 79, loss: 0.297101
global_step: 19145, epoch: 79, loss: 0.319791
global_step: 19146, epoch: 79, loss: 0.241935
global_step: 19147, epoch: 79, loss: 0.221932
global_step: 19148, epoch: 79, loss: 0.249993
global_step: 19149, epoch: 79, loss: 0.260703
global_step: 19150, epoch: 79, loss: 0.259894
global_step: 19151, epoch: 79, loss: 0.220077
global_step: 19152, epoch: 79, loss: 0.198245
global_step: 19153, epoch: 79, loss: 0.197240
global_step: 19154, epoch: 79, loss: 0.231391
global_step: 19155, epoch: 79, loss: 0.245855
global_step: 19156, epoch: 79, loss: 0.256822
global_step: 19157, epoch: 79, loss: 0.223216
global_step: 19158, epoch: 79, loss: 0.329161
global_step: 19159, epoch: 79, loss: 0.396402
global_step: 19160, epoch: 79, loss: 1.147823
epoch: 79
train	acc: 0.9672	macro: p 0.9685, r 0.9567, f1: 0.9624	micro: p 0.9672, r 0.9672, f1 0.9672	weighted_f1:0.9672
dev	acc: 0.5194	macro: p 0.3875, r 0.3113, f1: 0.3222	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4840
test	acc: 0.5598	macro: p 0.3676, r 0.3107, f1: 0.3225	micro: p 0.5598, r 0.5598, f1 0.5598	weighted_f1:0.5303
global_step: 19161, epoch: 80, loss: 0.298574
global_step: 19162, epoch: 80, loss: 0.217019
global_step: 19163, epoch: 80, loss: 0.262442
global_step: 19164, epoch: 80, loss: 0.318728
global_step: 19165, epoch: 80, loss: 0.184492
global_step: 19166, epoch: 80, loss: 0.204387
global_step: 19167, epoch: 80, loss: 0.262639
global_step: 19168, epoch: 80, loss: 0.163767
global_step: 19169, epoch: 80, loss: 0.194287
global_step: 19170, epoch: 80, loss: 0.186432
global_step: 19171, epoch: 80, loss: 0.236596
global_step: 19172, epoch: 80, loss: 0.144861
global_step: 19173, epoch: 80, loss: 0.244003
global_step: 19174, epoch: 80, loss: 0.244759
global_step: 19175, epoch: 80, loss: 0.217682
global_step: 19176, epoch: 80, loss: 0.267911
global_step: 19177, epoch: 80, loss: 0.163520
global_step: 19178, epoch: 80, loss: 0.232337
global_step: 19179, epoch: 80, loss: 0.272594
global_step: 19180, epoch: 80, loss: 0.169066
global_step: 19181, epoch: 80, loss: 0.180788
global_step: 19182, epoch: 80, loss: 0.245697
global_step: 19183, epoch: 80, loss: 0.262147
global_step: 19184, epoch: 80, loss: 0.196448
global_step: 19185, epoch: 80, loss: 0.295752
global_step: 19186, epoch: 80, loss: 0.265898
global_step: 19187, epoch: 80, loss: 0.170173
global_step: 19188, epoch: 80, loss: 0.265524
global_step: 19189, epoch: 80, loss: 0.315589
global_step: 19190, epoch: 80, loss: 0.252268
global_step: 19191, epoch: 80, loss: 0.184567
global_step: 19192, epoch: 80, loss: 0.258131
global_step: 19193, epoch: 80, loss: 0.225363
global_step: 19194, epoch: 80, loss: 0.244604
global_step: 19195, epoch: 80, loss: 0.330086
global_step: 19196, epoch: 80, loss: 0.238111
global_step: 19197, epoch: 80, loss: 0.231358
global_step: 19198, epoch: 80, loss: 0.257381
global_step: 19199, epoch: 80, loss: 0.290575
global_step: 19200, epoch: 80, loss: 0.264111
epoch: 80
train	acc: 0.9684	macro: p 0.9713, r 0.9572, f1: 0.9640	micro: p 0.9684, r 0.9684, f1 0.9684	weighted_f1:0.9684
dev	acc: 0.5329	macro: p 0.5022, r 0.3198, f1: 0.3329	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4852
test	acc: 0.5705	macro: p 0.3464, r 0.3019, f1: 0.3051	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.5310
global_step: 19201, epoch: 81, loss: 0.258406
global_step: 19202, epoch: 81, loss: 0.260635
global_step: 19203, epoch: 81, loss: 0.151785
global_step: 19204, epoch: 81, loss: 0.210662
global_step: 19205, epoch: 81, loss: 0.221393
global_step: 19206, epoch: 81, loss: 0.186654
global_step: 19207, epoch: 81, loss: 0.250967
global_step: 19208, epoch: 81, loss: 0.308460
global_step: 19209, epoch: 81, loss: 0.167480
global_step: 19210, epoch: 81, loss: 0.237265
global_step: 19211, epoch: 81, loss: 0.133298
global_step: 19212, epoch: 81, loss: 0.155481
global_step: 19213, epoch: 81, loss: 0.179696
global_step: 19214, epoch: 81, loss: 0.180769
global_step: 19215, epoch: 81, loss: 0.235159
global_step: 19216, epoch: 81, loss: 0.163173
global_step: 19217, epoch: 81, loss: 0.172800
global_step: 19218, epoch: 81, loss: 0.248778
global_step: 19219, epoch: 81, loss: 0.222193
global_step: 19220, epoch: 81, loss: 0.206876
global_step: 19221, epoch: 81, loss: 0.217244
global_step: 19222, epoch: 81, loss: 0.224810
global_step: 19223, epoch: 81, loss: 0.316594
global_step: 19224, epoch: 81, loss: 0.237590
global_step: 19225, epoch: 81, loss: 0.252832
global_step: 19226, epoch: 81, loss: 0.226519
global_step: 19227, epoch: 81, loss: 0.261206
global_step: 19228, epoch: 81, loss: 0.243374
global_step: 19229, epoch: 81, loss: 0.227446
global_step: 19230, epoch: 81, loss: 0.218940
global_step: 19231, epoch: 81, loss: 0.225747
global_step: 19232, epoch: 81, loss: 0.164417
global_step: 19233, epoch: 81, loss: 0.294911
global_step: 19234, epoch: 81, loss: 0.184047
global_step: 19235, epoch: 81, loss: 0.216555
global_step: 19236, epoch: 81, loss: 0.291979
global_step: 19237, epoch: 81, loss: 0.176926
global_step: 19238, epoch: 81, loss: 0.277620
global_step: 19239, epoch: 81, loss: 0.204760
global_step: 19240, epoch: 81, loss: 0.037368
epoch: 81
train	acc: 0.9675	macro: p 0.9707, r 0.9562, f1: 0.9629	micro: p 0.9675, r 0.9675, f1 0.9675	weighted_f1:0.9676
dev	acc: 0.5230	macro: p 0.5030, r 0.3143, f1: 0.3220	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4835
test	acc: 0.5636	macro: p 0.3550, r 0.3100, f1: 0.3136	micro: p 0.5636, r 0.5636, f1 0.5636	weighted_f1:0.5306
global_step: 19241, epoch: 82, loss: 0.181719
global_step: 19242, epoch: 82, loss: 0.294843
global_step: 19243, epoch: 82, loss: 0.214226
global_step: 19244, epoch: 82, loss: 0.283649
global_step: 19245, epoch: 82, loss: 0.184460
global_step: 19246, epoch: 82, loss: 0.229071
global_step: 19247, epoch: 82, loss: 0.156683
global_step: 19248, epoch: 82, loss: 0.265172
global_step: 19249, epoch: 82, loss: 0.310369
global_step: 19250, epoch: 82, loss: 0.300182
global_step: 19251, epoch: 82, loss: 0.226545
global_step: 19252, epoch: 82, loss: 0.262126
global_step: 19253, epoch: 82, loss: 0.310303
global_step: 19254, epoch: 82, loss: 0.216662
global_step: 19255, epoch: 82, loss: 0.196396
global_step: 19256, epoch: 82, loss: 0.208379
global_step: 19257, epoch: 82, loss: 0.248649
global_step: 19258, epoch: 82, loss: 0.161325
global_step: 19259, epoch: 82, loss: 0.209094
global_step: 19260, epoch: 82, loss: 0.293191
global_step: 19261, epoch: 82, loss: 0.199567
global_step: 19262, epoch: 82, loss: 0.286018
global_step: 19263, epoch: 82, loss: 0.190190
global_step: 19264, epoch: 82, loss: 0.288596
global_step: 19265, epoch: 82, loss: 0.272219
global_step: 19266, epoch: 82, loss: 0.214419
global_step: 19267, epoch: 82, loss: 0.192777
global_step: 19268, epoch: 82, loss: 0.234232
global_step: 19269, epoch: 82, loss: 0.253813
global_step: 19270, epoch: 82, loss: 0.237047
global_step: 19271, epoch: 82, loss: 0.285515
global_step: 19272, epoch: 82, loss: 0.221915
global_step: 19273, epoch: 82, loss: 0.153294
global_step: 19274, epoch: 82, loss: 0.241394
global_step: 19275, epoch: 82, loss: 0.168258
global_step: 19276, epoch: 82, loss: 0.165625
global_step: 19277, epoch: 82, loss: 0.209805
global_step: 19278, epoch: 82, loss: 0.225117
global_step: 19279, epoch: 82, loss: 0.215308
global_step: 19280, epoch: 82, loss: 0.050858
epoch: 82
train	acc: 0.9683	macro: p 0.9741, r 0.9525, f1: 0.9628	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5212	macro: p 0.5059, r 0.3019, f1: 0.3078	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4766
test	acc: 0.5663	macro: p 0.3548, r 0.3009, f1: 0.3049	micro: p 0.5663, r 0.5663, f1 0.5663	weighted_f1:0.5259
global_step: 19281, epoch: 83, loss: 0.273402
global_step: 19282, epoch: 83, loss: 0.169385
global_step: 19283, epoch: 83, loss: 0.189521
global_step: 19284, epoch: 83, loss: 0.172142
global_step: 19285, epoch: 83, loss: 0.198790
global_step: 19286, epoch: 83, loss: 0.250697
global_step: 19287, epoch: 83, loss: 0.238196
global_step: 19288, epoch: 83, loss: 0.222008
global_step: 19289, epoch: 83, loss: 0.213975
global_step: 19290, epoch: 83, loss: 0.226463
global_step: 19291, epoch: 83, loss: 0.253872
global_step: 19292, epoch: 83, loss: 0.237782
global_step: 19293, epoch: 83, loss: 0.277081
global_step: 19294, epoch: 83, loss: 0.214528
global_step: 19295, epoch: 83, loss: 0.232225
global_step: 19296, epoch: 83, loss: 0.239485
global_step: 19297, epoch: 83, loss: 0.265669
global_step: 19298, epoch: 83, loss: 0.183544
global_step: 19299, epoch: 83, loss: 0.287512
global_step: 19300, epoch: 83, loss: 0.215206
global_step: 19301, epoch: 83, loss: 0.299279
global_step: 19302, epoch: 83, loss: 0.201815
global_step: 19303, epoch: 83, loss: 0.227628
global_step: 19304, epoch: 83, loss: 0.214888
global_step: 19305, epoch: 83, loss: 0.197840
global_step: 19306, epoch: 83, loss: 0.254524
global_step: 19307, epoch: 83, loss: 0.204283
global_step: 19308, epoch: 83, loss: 0.195994
global_step: 19309, epoch: 83, loss: 0.164209
global_step: 19310, epoch: 83, loss: 0.253371
global_step: 19311, epoch: 83, loss: 0.213239
global_step: 19312, epoch: 83, loss: 0.254434
global_step: 19313, epoch: 83, loss: 0.271680
global_step: 19314, epoch: 83, loss: 0.236839
global_step: 19315, epoch: 83, loss: 0.259720
global_step: 19316, epoch: 83, loss: 0.168530
global_step: 19317, epoch: 83, loss: 0.203983
global_step: 19318, epoch: 83, loss: 0.164578
global_step: 19319, epoch: 83, loss: 0.192536
global_step: 19320, epoch: 83, loss: 0.136913
epoch: 83
train	acc: 0.9685	macro: p 0.9718, r 0.9559, f1: 0.9634	micro: p 0.9685, r 0.9685, f1 0.9685	weighted_f1:0.9685
dev	acc: 0.5104	macro: p 0.4279, r 0.3054, f1: 0.3076	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4737
test	acc: 0.5464	macro: p 0.3421, r 0.3009, f1: 0.3005	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.5166
global_step: 19321, epoch: 84, loss: 0.192442
global_step: 19322, epoch: 84, loss: 0.192258
global_step: 19323, epoch: 84, loss: 0.188105
global_step: 19324, epoch: 84, loss: 0.176141
global_step: 19325, epoch: 84, loss: 0.198225
global_step: 19326, epoch: 84, loss: 0.174570
global_step: 19327, epoch: 84, loss: 0.236943
global_step: 19328, epoch: 84, loss: 0.165673
global_step: 19329, epoch: 84, loss: 0.191869
global_step: 19330, epoch: 84, loss: 0.191623
global_step: 19331, epoch: 84, loss: 0.298708
global_step: 19332, epoch: 84, loss: 0.240924
global_step: 19333, epoch: 84, loss: 0.195000
global_step: 19334, epoch: 84, loss: 0.267436
global_step: 19335, epoch: 84, loss: 0.242057
global_step: 19336, epoch: 84, loss: 0.178317
global_step: 19337, epoch: 84, loss: 0.233141
global_step: 19338, epoch: 84, loss: 0.181148
global_step: 19339, epoch: 84, loss: 0.208860
global_step: 19340, epoch: 84, loss: 0.263932
global_step: 19341, epoch: 84, loss: 0.237162
global_step: 19342, epoch: 84, loss: 0.183533
global_step: 19343, epoch: 84, loss: 0.246173
global_step: 19344, epoch: 84, loss: 0.268345
global_step: 19345, epoch: 84, loss: 0.315259
global_step: 19346, epoch: 84, loss: 0.191941
global_step: 19347, epoch: 84, loss: 0.174237
global_step: 19348, epoch: 84, loss: 0.227150
global_step: 19349, epoch: 84, loss: 0.262629
global_step: 19350, epoch: 84, loss: 0.256360
global_step: 19351, epoch: 84, loss: 0.199905
global_step: 19352, epoch: 84, loss: 0.189785
global_step: 19353, epoch: 84, loss: 0.232530
global_step: 19354, epoch: 84, loss: 0.206367
global_step: 19355, epoch: 84, loss: 0.193657
global_step: 19356, epoch: 84, loss: 0.189573
global_step: 19357, epoch: 84, loss: 0.273595
global_step: 19358, epoch: 84, loss: 0.242587
global_step: 19359, epoch: 84, loss: 0.158613
global_step: 19360, epoch: 84, loss: 0.040884
epoch: 84
train	acc: 0.9693	macro: p 0.9718, r 0.9580, f1: 0.9646	micro: p 0.9693, r 0.9693, f1 0.9693	weighted_f1:0.9693
dev	acc: 0.5266	macro: p 0.4598, r 0.3066, f1: 0.3137	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4808
test	acc: 0.5667	macro: p 0.3750, r 0.3080, f1: 0.3173	micro: p 0.5667, r 0.5667, f1 0.5667	weighted_f1:0.5284
global_step: 19361, epoch: 85, loss: 0.160384
global_step: 19362, epoch: 85, loss: 0.203239
global_step: 19363, epoch: 85, loss: 0.177358
global_step: 19364, epoch: 85, loss: 0.239470
global_step: 19365, epoch: 85, loss: 0.258803
global_step: 19366, epoch: 85, loss: 0.162315
global_step: 19367, epoch: 85, loss: 0.208835
global_step: 19368, epoch: 85, loss: 0.208401
global_step: 19369, epoch: 85, loss: 0.258163
global_step: 19370, epoch: 85, loss: 0.263258
global_step: 19371, epoch: 85, loss: 0.158272
global_step: 19372, epoch: 85, loss: 0.200068
global_step: 19373, epoch: 85, loss: 0.280707
global_step: 19374, epoch: 85, loss: 0.216137
global_step: 19375, epoch: 85, loss: 0.326054
global_step: 19376, epoch: 85, loss: 0.134920
global_step: 19377, epoch: 85, loss: 0.136836
global_step: 19378, epoch: 85, loss: 0.257601
global_step: 19379, epoch: 85, loss: 0.216912
global_step: 19380, epoch: 85, loss: 0.215004
global_step: 19381, epoch: 85, loss: 0.186831
global_step: 19382, epoch: 85, loss: 0.293544
global_step: 19383, epoch: 85, loss: 0.224622
global_step: 19384, epoch: 85, loss: 0.238258
global_step: 19385, epoch: 85, loss: 0.213884
global_step: 19386, epoch: 85, loss: 0.221723
global_step: 19387, epoch: 85, loss: 0.289749
global_step: 19388, epoch: 85, loss: 0.274202
global_step: 19389, epoch: 85, loss: 0.296569
global_step: 19390, epoch: 85, loss: 0.202218
global_step: 19391, epoch: 85, loss: 0.186130
global_step: 19392, epoch: 85, loss: 0.160971
global_step: 19393, epoch: 85, loss: 0.215659
global_step: 19394, epoch: 85, loss: 0.229290
global_step: 19395, epoch: 85, loss: 0.214818
global_step: 19396, epoch: 85, loss: 0.197712
global_step: 19397, epoch: 85, loss: 0.232641
global_step: 19398, epoch: 85, loss: 0.238046
global_step: 19399, epoch: 85, loss: 0.179312
global_step: 19400, epoch: 85, loss: 0.003742
epoch: 85
train	acc: 0.9682	macro: p 0.9718, r 0.9565, f1: 0.9638	micro: p 0.9682, r 0.9682, f1 0.9682	weighted_f1:0.9682
dev	acc: 0.5293	macro: p 0.5100, r 0.3221, f1: 0.3368	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4931
test	acc: 0.5602	macro: p 0.3380, r 0.3078, f1: 0.3121	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5294
global_step: 19401, epoch: 86, loss: 0.160184
global_step: 19402, epoch: 86, loss: 0.134476
global_step: 19403, epoch: 86, loss: 0.280983
global_step: 19404, epoch: 86, loss: 0.210728
global_step: 19405, epoch: 86, loss: 0.185685
global_step: 19406, epoch: 86, loss: 0.200653
global_step: 19407, epoch: 86, loss: 0.163915
global_step: 19408, epoch: 86, loss: 0.209089
global_step: 19409, epoch: 86, loss: 0.191002
global_step: 19410, epoch: 86, loss: 0.214004
global_step: 19411, epoch: 86, loss: 0.214516
global_step: 19412, epoch: 86, loss: 0.179552
global_step: 19413, epoch: 86, loss: 0.242268
global_step: 19414, epoch: 86, loss: 0.212923
global_step: 19415, epoch: 86, loss: 0.179091
global_step: 19416, epoch: 86, loss: 0.199570
global_step: 19417, epoch: 86, loss: 0.202433
global_step: 19418, epoch: 86, loss: 0.247579
global_step: 19419, epoch: 86, loss: 0.246530
global_step: 19420, epoch: 86, loss: 0.258802
global_step: 19421, epoch: 86, loss: 0.190237
global_step: 19422, epoch: 86, loss: 0.273980
global_step: 19423, epoch: 86, loss: 0.178598
global_step: 19424, epoch: 86, loss: 0.239441
global_step: 19425, epoch: 86, loss: 0.263086
global_step: 19426, epoch: 86, loss: 0.258365
global_step: 19427, epoch: 86, loss: 0.278134
global_step: 19428, epoch: 86, loss: 0.258433
global_step: 19429, epoch: 86, loss: 0.199929
global_step: 19430, epoch: 86, loss: 0.269419
global_step: 19431, epoch: 86, loss: 0.301908
global_step: 19432, epoch: 86, loss: 0.340003
global_step: 19433, epoch: 86, loss: 0.276228
global_step: 19434, epoch: 86, loss: 0.188720
global_step: 19435, epoch: 86, loss: 0.200670
global_step: 19436, epoch: 86, loss: 0.239064
global_step: 19437, epoch: 86, loss: 0.194309
global_step: 19438, epoch: 86, loss: 0.265670
global_step: 19439, epoch: 86, loss: 0.347332
global_step: 19440, epoch: 86, loss: 0.018278
epoch: 86
train	acc: 0.9701	macro: p 0.9740, r 0.9566, f1: 0.9649	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5230	macro: p 0.4324, r 0.3056, f1: 0.3128	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4799
test	acc: 0.5590	macro: p 0.3449, r 0.3027, f1: 0.3083	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.5228
global_step: 19441, epoch: 87, loss: 0.206172
global_step: 19442, epoch: 87, loss: 0.253872
global_step: 19443, epoch: 87, loss: 0.199442
global_step: 19444, epoch: 87, loss: 0.128572
global_step: 19445, epoch: 87, loss: 0.248092
global_step: 19446, epoch: 87, loss: 0.283065
global_step: 19447, epoch: 87, loss: 0.240377
global_step: 19448, epoch: 87, loss: 0.174684
global_step: 19449, epoch: 87, loss: 0.331692
global_step: 19450, epoch: 87, loss: 0.156097
global_step: 19451, epoch: 87, loss: 0.170195
global_step: 19452, epoch: 87, loss: 0.230343
global_step: 19453, epoch: 87, loss: 0.222089
global_step: 19454, epoch: 87, loss: 0.155854
global_step: 19455, epoch: 87, loss: 0.288204
global_step: 19456, epoch: 87, loss: 0.225421
global_step: 19457, epoch: 87, loss: 0.155618
global_step: 19458, epoch: 87, loss: 0.205759
global_step: 19459, epoch: 87, loss: 0.189071
global_step: 19460, epoch: 87, loss: 0.188625
global_step: 19461, epoch: 87, loss: 0.195859
global_step: 19462, epoch: 87, loss: 0.220668
global_step: 19463, epoch: 87, loss: 0.187851
global_step: 19464, epoch: 87, loss: 0.269781
global_step: 19465, epoch: 87, loss: 0.273386
global_step: 19466, epoch: 87, loss: 0.160078
global_step: 19467, epoch: 87, loss: 0.200580
global_step: 19468, epoch: 87, loss: 0.191058
global_step: 19469, epoch: 87, loss: 0.230829
global_step: 19470, epoch: 87, loss: 0.206167
global_step: 19471, epoch: 87, loss: 0.250629
global_step: 19472, epoch: 87, loss: 0.203274
global_step: 19473, epoch: 87, loss: 0.233853
global_step: 19474, epoch: 87, loss: 0.252730
global_step: 19475, epoch: 87, loss: 0.184762
global_step: 19476, epoch: 87, loss: 0.322738
global_step: 19477, epoch: 87, loss: 0.213513
global_step: 19478, epoch: 87, loss: 0.244626
global_step: 19479, epoch: 87, loss: 0.293011
global_step: 19480, epoch: 87, loss: 0.522608
epoch: 87
train	acc: 0.9679	macro: p 0.9706, r 0.9544, f1: 0.9621	micro: p 0.9679, r 0.9679, f1 0.9679	weighted_f1:0.9679
dev	acc: 0.5212	macro: p 0.4710, r 0.3147, f1: 0.3272	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4809
test	acc: 0.5682	macro: p 0.3449, r 0.3064, f1: 0.3111	micro: p 0.5682, r 0.5682, f1 0.5682	weighted_f1:0.5334
global_step: 19481, epoch: 88, loss: 0.253114
global_step: 19482, epoch: 88, loss: 0.257383
global_step: 19483, epoch: 88, loss: 0.206390
global_step: 19484, epoch: 88, loss: 0.241445
global_step: 19485, epoch: 88, loss: 0.243571
global_step: 19486, epoch: 88, loss: 0.217355
global_step: 19487, epoch: 88, loss: 0.200833
global_step: 19488, epoch: 88, loss: 0.297889
global_step: 19489, epoch: 88, loss: 0.211806
global_step: 19490, epoch: 88, loss: 0.226318
global_step: 19491, epoch: 88, loss: 0.266015
global_step: 19492, epoch: 88, loss: 0.224346
global_step: 19493, epoch: 88, loss: 0.234841
global_step: 19494, epoch: 88, loss: 0.174747
global_step: 19495, epoch: 88, loss: 0.257132
global_step: 19496, epoch: 88, loss: 0.148949
global_step: 19497, epoch: 88, loss: 0.178009
global_step: 19498, epoch: 88, loss: 0.231658
global_step: 19499, epoch: 88, loss: 0.162379
global_step: 19500, epoch: 88, loss: 0.237080
global_step: 19501, epoch: 88, loss: 0.206680
global_step: 19502, epoch: 88, loss: 0.250601
global_step: 19503, epoch: 88, loss: 0.255751
global_step: 19504, epoch: 88, loss: 0.267167
global_step: 19505, epoch: 88, loss: 0.206877
global_step: 19506, epoch: 88, loss: 0.308199
global_step: 19507, epoch: 88, loss: 0.227766
global_step: 19508, epoch: 88, loss: 0.348682
global_step: 19509, epoch: 88, loss: 0.199118
global_step: 19510, epoch: 88, loss: 0.207156
global_step: 19511, epoch: 88, loss: 0.194760
global_step: 19512, epoch: 88, loss: 0.243555
global_step: 19513, epoch: 88, loss: 0.262645
global_step: 19514, epoch: 88, loss: 0.227258
global_step: 19515, epoch: 88, loss: 0.170637
global_step: 19516, epoch: 88, loss: 0.196148
global_step: 19517, epoch: 88, loss: 0.147181
global_step: 19518, epoch: 88, loss: 0.205603
global_step: 19519, epoch: 88, loss: 0.234237
global_step: 19520, epoch: 88, loss: 0.720798
epoch: 88
train	acc: 0.9677	macro: p 0.9722, r 0.9526, f1: 0.9619	micro: p 0.9677, r 0.9677, f1 0.9677	weighted_f1:0.9677
dev	acc: 0.5122	macro: p 0.4197, r 0.3122, f1: 0.3199	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4762
test	acc: 0.5556	macro: p 0.3380, r 0.3097, f1: 0.3097	micro: p 0.5556, r 0.5556, f1 0.5556	weighted_f1:0.5271
global_step: 19521, epoch: 89, loss: 0.226562
global_step: 19522, epoch: 89, loss: 0.170641
global_step: 19523, epoch: 89, loss: 0.223716
global_step: 19524, epoch: 89, loss: 0.233006
global_step: 19525, epoch: 89, loss: 0.182151
global_step: 19526, epoch: 89, loss: 0.229315
global_step: 19527, epoch: 89, loss: 0.252486
global_step: 19528, epoch: 89, loss: 0.136014
global_step: 19529, epoch: 89, loss: 0.223656
global_step: 19530, epoch: 89, loss: 0.241586
global_step: 19531, epoch: 89, loss: 0.227665
global_step: 19532, epoch: 89, loss: 0.168840
global_step: 19533, epoch: 89, loss: 0.190902
global_step: 19534, epoch: 89, loss: 0.136990
global_step: 19535, epoch: 89, loss: 0.234394
global_step: 19536, epoch: 89, loss: 0.161281
global_step: 19537, epoch: 89, loss: 0.196479
global_step: 19538, epoch: 89, loss: 0.165419
global_step: 19539, epoch: 89, loss: 0.310858
global_step: 19540, epoch: 89, loss: 0.217592
global_step: 19541, epoch: 89, loss: 0.231519
global_step: 19542, epoch: 89, loss: 0.267321
global_step: 19543, epoch: 89, loss: 0.273619
global_step: 19544, epoch: 89, loss: 0.240738
global_step: 19545, epoch: 89, loss: 0.164897
global_step: 19546, epoch: 89, loss: 0.241916
global_step: 19547, epoch: 89, loss: 0.294723
global_step: 19548, epoch: 89, loss: 0.256150
global_step: 19549, epoch: 89, loss: 0.206288
global_step: 19550, epoch: 89, loss: 0.231047
global_step: 19551, epoch: 89, loss: 0.282128
global_step: 19552, epoch: 89, loss: 0.266302
global_step: 19553, epoch: 89, loss: 0.211514
global_step: 19554, epoch: 89, loss: 0.286642
global_step: 19555, epoch: 89, loss: 0.172650
global_step: 19556, epoch: 89, loss: 0.233215
global_step: 19557, epoch: 89, loss: 0.235929
global_step: 19558, epoch: 89, loss: 0.147548
global_step: 19559, epoch: 89, loss: 0.252524
global_step: 19560, epoch: 89, loss: 0.401884
epoch: 89
train	acc: 0.9706	macro: p 0.9727, r 0.9599, f1: 0.9661	micro: p 0.9706, r 0.9706, f1 0.9706	weighted_f1:0.9706
dev	acc: 0.5149	macro: p 0.3892, r 0.3129, f1: 0.3246	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4831
test	acc: 0.5506	macro: p 0.3409, r 0.3081, f1: 0.3169	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.5250
global_step: 19561, epoch: 90, loss: 0.186853
global_step: 19562, epoch: 90, loss: 0.142879
global_step: 19563, epoch: 90, loss: 0.233303
global_step: 19564, epoch: 90, loss: 0.247610
global_step: 19565, epoch: 90, loss: 0.192338
global_step: 19566, epoch: 90, loss: 0.237329
global_step: 19567, epoch: 90, loss: 0.143804
global_step: 19568, epoch: 90, loss: 0.217627
global_step: 19569, epoch: 90, loss: 0.193148
global_step: 19570, epoch: 90, loss: 0.140831
global_step: 19571, epoch: 90, loss: 0.239853
global_step: 19572, epoch: 90, loss: 0.164139
global_step: 19573, epoch: 90, loss: 0.198596
global_step: 19574, epoch: 90, loss: 0.237520
global_step: 19575, epoch: 90, loss: 0.252232
global_step: 19576, epoch: 90, loss: 0.204418
global_step: 19577, epoch: 90, loss: 0.167234
global_step: 19578, epoch: 90, loss: 0.224675
global_step: 19579, epoch: 90, loss: 0.211756
global_step: 19580, epoch: 90, loss: 0.155330
global_step: 19581, epoch: 90, loss: 0.206565
global_step: 19582, epoch: 90, loss: 0.210086
global_step: 19583, epoch: 90, loss: 0.190482
global_step: 19584, epoch: 90, loss: 0.262877
global_step: 19585, epoch: 90, loss: 0.240870
global_step: 19586, epoch: 90, loss: 0.185586
global_step: 19587, epoch: 90, loss: 0.158250
global_step: 19588, epoch: 90, loss: 0.130552
global_step: 19589, epoch: 90, loss: 0.251839
global_step: 19590, epoch: 90, loss: 0.212111
global_step: 19591, epoch: 90, loss: 0.256287
global_step: 19592, epoch: 90, loss: 0.236481
global_step: 19593, epoch: 90, loss: 0.235224
global_step: 19594, epoch: 90, loss: 0.236794
global_step: 19595, epoch: 90, loss: 0.222920
global_step: 19596, epoch: 90, loss: 0.175381
global_step: 19597, epoch: 90, loss: 0.250887
global_step: 19598, epoch: 90, loss: 0.229046
global_step: 19599, epoch: 90, loss: 0.179688
global_step: 19600, epoch: 90, loss: 0.242585run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

epoch: 90
train	acc: 0.9701	macro: p 0.9716, r 0.9608, f1: 0.9660	micro: p 0.9701, r 0.9701, f1 0.9701	weighted_f1:0.9701
dev	acc: 0.5149	macro: p 0.4290, r 0.3133, f1: 0.3259	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4818
test	acc: 0.5513	macro: p 0.3321, r 0.3049, f1: 0.3084	micro: p 0.5513, r 0.5513, f1 0.5513	weighted_f1:0.5245
global_step: 19601, epoch: 91, loss: 0.189113
global_step: 19602, epoch: 91, loss: 0.199550
global_step: 19603, epoch: 91, loss: 0.243158
global_step: 19604, epoch: 91, loss: 0.252336
global_step: 19605, epoch: 91, loss: 0.188316
global_step: 19606, epoch: 91, loss: 0.279128
global_step: 19607, epoch: 91, loss: 0.218728
global_step: 19608, epoch: 91, loss: 0.219563
global_step: 19609, epoch: 91, loss: 0.185443
global_step: 19610, epoch: 91, loss: 0.185020
global_step: 19611, epoch: 91, loss: 0.263730
global_step: 19612, epoch: 91, loss: 0.203838
global_step: 19613, epoch: 91, loss: 0.171236
global_step: 19614, epoch: 91, loss: 0.196522
global_step: 19615, epoch: 91, loss: 0.270257
global_step: 19616, epoch: 91, loss: 0.257247
global_step: 19617, epoch: 91, loss: 0.204715
global_step: 19618, epoch: 91, loss: 0.175165
global_step: 19619, epoch: 91, loss: 0.290699
global_step: 19620, epoch: 91, loss: 0.253332
global_step: 19621, epoch: 91, loss: 0.191979
global_step: 19622, epoch: 91, loss: 0.139285
global_step: 19623, epoch: 91, loss: 0.196787
global_step: 19624, epoch: 91, loss: 0.226763
global_step: 19625, epoch: 91, loss: 0.188485
global_step: 19626, epoch: 91, loss: 0.203010
global_step: 19627, epoch: 91, loss: 0.231742
global_step: 19628, epoch: 91, loss: 0.230642
global_step: 19629, epoch: 91, loss: 0.328053
global_step: 19630, epoch: 91, loss: 0.214479
global_step: 19631, epoch: 91, loss: 0.161723
global_step: 19632, epoch: 91, loss: 0.196055
global_step: 19633, epoch: 91, loss: 0.193017
global_step: 19634, epoch: 91, loss: 0.163373
global_step: 19635, epoch: 91, loss: 0.249877
global_step: 19636, epoch: 91, loss: 0.222385
global_step: 19637, epoch: 91, loss: 0.178719
global_step: 19638, epoch: 91, loss: 0.224740
global_step: 19639, epoch: 91, loss: 0.246137
global_step: 19640, epoch: 91, loss: 0.791639
epoch: 91
train	acc: 0.9667	macro: p 0.9736, r 0.9546, f1: 0.9637	micro: p 0.9667, r 0.9667, f1 0.9667	weighted_f1:0.9666
dev	acc: 0.5230	macro: p 0.4552, r 0.3202, f1: 0.3302	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4845
test	acc: 0.5479	macro: p 0.3278, r 0.2968, f1: 0.2992	micro: p 0.5479, r 0.5479, f1 0.5479	weighted_f1:0.5167
global_step: 19641, epoch: 92, loss: 0.190505
global_step: 19642, epoch: 92, loss: 0.215910
global_step: 19643, epoch: 92, loss: 0.254854
global_step: 19644, epoch: 92, loss: 0.124142
global_step: 19645, epoch: 92, loss: 0.241827
global_step: 19646, epoch: 92, loss: 0.190972
global_step: 19647, epoch: 92, loss: 0.167796
global_step: 19648, epoch: 92, loss: 0.213650
global_step: 19649, epoch: 92, loss: 0.242354
global_step: 19650, epoch: 92, loss: 0.258557
global_step: 19651, epoch: 92, loss: 0.224710
global_step: 19652, epoch: 92, loss: 0.220405
global_step: 19653, epoch: 92, loss: 0.199866
global_step: 19654, epoch: 92, loss: 0.163827
global_step: 19655, epoch: 92, loss: 0.232526
global_step: 19656, epoch: 92, loss: 0.204310
global_step: 19657, epoch: 92, loss: 0.214938
global_step: 19658, epoch: 92, loss: 0.232260
global_step: 19659, epoch: 92, loss: 0.181265
global_step: 19660, epoch: 92, loss: 0.185617
global_step: 19661, epoch: 92, loss: 0.152280
global_step: 19662, epoch: 92, loss: 0.191186
global_step: 19663, epoch: 92, loss: 0.214133
global_step: 19664, epoch: 92, loss: 0.225905
global_step: 19665, epoch: 92, loss: 0.193837
global_step: 19666, epoch: 92, loss: 0.191120
global_step: 19667, epoch: 92, loss: 0.238828
global_step: 19668, epoch: 92, loss: 0.226558
global_step: 19669, epoch: 92, loss: 0.277488
global_step: 19670, epoch: 92, loss: 0.215570
global_step: 19671, epoch: 92, loss: 0.178705
global_step: 19672, epoch: 92, loss: 0.198559
global_step: 19673, epoch: 92, loss: 0.240977
global_step: 19674, epoch: 92, loss: 0.192054
global_step: 19675, epoch: 92, loss: 0.198040
global_step: 19676, epoch: 92, loss: 0.169432
global_step: 19677, epoch: 92, loss: 0.286740
global_step: 19678, epoch: 92, loss: 0.230328
global_step: 19679, epoch: 92, loss: 0.271147
global_step: 19680, epoch: 92, loss: 0.012964
epoch: 92
train	acc: 0.9703	macro: p 0.9725, r 0.9616, f1: 0.9668	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5086	macro: p 0.3832, r 0.3218, f1: 0.3274	micro: p 0.5086, r 0.5086, f1 0.5086	weighted_f1:0.4852
test	acc: 0.5330	macro: p 0.3239, r 0.3090, f1: 0.3101	micro: p 0.5330, r 0.5330, f1 0.5330	weighted_f1:0.5167
global_step: 19681, epoch: 93, loss: 0.335834
global_step: 19682, epoch: 93, loss: 0.148536
global_step: 19683, epoch: 93, loss: 0.225015
global_step: 19684, epoch: 93, loss: 0.197327
global_step: 19685, epoch: 93, loss: 0.248744
global_step: 19686, epoch: 93, loss: 0.183096
global_step: 19687, epoch: 93, loss: 0.205533
global_step: 19688, epoch: 93, loss: 0.227239
global_step: 19689, epoch: 93, loss: 0.174660
global_step: 19690, epoch: 93, loss: 0.165384
global_step: 19691, epoch: 93, loss: 0.201353
global_step: 19692, epoch: 93, loss: 0.200094
global_step: 19693, epoch: 93, loss: 0.234155
global_step: 19694, epoch: 93, loss: 0.171282
global_step: 19695, epoch: 93, loss: 0.193641
global_step: 19696, epoch: 93, loss: 0.182533
global_step: 19697, epoch: 93, loss: 0.240941
global_step: 19698, epoch: 93, loss: 0.245545
global_step: 19699, epoch: 93, loss: 0.175363
global_step: 19700, epoch: 93, loss: 0.211365
global_step: 19701, epoch: 93, loss: 0.170850
global_step: 19702, epoch: 93, loss: 0.236195
global_step: 19703, epoch: 93, loss: 0.214928
global_step: 19704, epoch: 93, loss: 0.236796
global_step: 19705, epoch: 93, loss: 0.261977
global_step: 19706, epoch: 93, loss: 0.151296
global_step: 19707, epoch: 93, loss: 0.244629
global_step: 19708, epoch: 93, loss: 0.250315
global_step: 19709, epoch: 93, loss: 0.210035
global_step: 19710, epoch: 93, loss: 0.161667
global_step: 19711, epoch: 93, loss: 0.227044
global_step: 19712, epoch: 93, loss: 0.216897
global_step: 19713, epoch: 93, loss: 0.163295
global_step: 19714, epoch: 93, loss: 0.218111
global_step: 19715, epoch: 93, loss: 0.245769
global_step: 19716, epoch: 93, loss: 0.179644
global_step: 19717, epoch: 93, loss: 0.160352
global_step: 19718, epoch: 93, loss: 0.252008
global_step: 19719, epoch: 93, loss: 0.229647
global_step: 19720, epoch: 93, loss: 0.014238
epoch: 93
train	acc: 0.9697	macro: p 0.9733, r 0.9577, f1: 0.9651	micro: p 0.9697, r 0.9697, f1 0.9697	weighted_f1:0.9697
dev	acc: 0.5140	macro: p 0.4090, r 0.3030, f1: 0.3054	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4792
test	acc: 0.5487	macro: p 0.3292, r 0.3053, f1: 0.3046	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.5199
global_step: 19721, epoch: 94, loss: 0.168085
global_step: 19722, epoch: 94, loss: 0.192539
global_step: 19723, epoch: 94, loss: 0.191478
global_step: 19724, epoch: 94, loss: 0.261853
global_step: 19725, epoch: 94, loss: 0.200609
global_step: 19726, epoch: 94, loss: 0.243283
global_step: 19727, epoch: 94, loss: 0.244508
global_step: 19728, epoch: 94, loss: 0.233227
global_step: 19729, epoch: 94, loss: 0.257150
global_step: 19730, epoch: 94, loss: 0.208028
global_step: 19731, epoch: 94, loss: 0.240705
global_step: 19732, epoch: 94, loss: 0.177346
global_step: 19733, epoch: 94, loss: 0.184876
global_step: 19734, epoch: 94, loss: 0.189198
global_step: 19735, epoch: 94, loss: 0.164315
global_step: 19736, epoch: 94, loss: 0.258393
global_step: 19737, epoch: 94, loss: 0.238408
global_step: 19738, epoch: 94, loss: 0.213941
global_step: 19739, epoch: 94, loss: 0.159294
global_step: 19740, epoch: 94, loss: 0.249748
global_step: 19741, epoch: 94, loss: 0.159884
global_step: 19742, epoch: 94, loss: 0.210016
global_step: 19743, epoch: 94, loss: 0.236116
global_step: 19744, epoch: 94, loss: 0.226325
global_step: 19745, epoch: 94, loss: 0.215475
global_step: 19746, epoch: 94, loss: 0.195947
global_step: 19747, epoch: 94, loss: 0.214668
global_step: 19748, epoch: 94, loss: 0.252414
global_step: 19749, epoch: 94, loss: 0.202088
global_step: 19750, epoch: 94, loss: 0.216389
global_step: 19751, epoch: 94, loss: 0.200285
global_step: 19752, epoch: 94, loss: 0.182199
global_step: 19753, epoch: 94, loss: 0.213813
global_step: 19754, epoch: 94, loss: 0.195628
global_step: 19755, epoch: 94, loss: 0.179751
global_step: 19756, epoch: 94, loss: 0.215128
global_step: 19757, epoch: 94, loss: 0.174261
global_step: 19758, epoch: 94, loss: 0.184926
global_step: 19759, epoch: 94, loss: 0.250380
global_step: 19760, epoch: 94, loss: 0.364416
epoch: 94
train	acc: 0.9695	macro: p 0.9719, r 0.9587, f1: 0.9650	micro: p 0.9695, r 0.9695, f1 0.9695	weighted_f1:0.9695
dev	acc: 0.5221	macro: p 0.4096, r 0.3171, f1: 0.3241	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4897
test	acc: 0.5441	macro: p 0.3274, r 0.3063, f1: 0.3070	micro: p 0.5441, r 0.5441, f1 0.5441	weighted_f1:0.5180
global_step: 19761, epoch: 95, loss: 0.240750
global_step: 19762, epoch: 95, loss: 0.202769
global_step: 19763, epoch: 95, loss: 0.247388
global_step: 19764, epoch: 95, loss: 0.215298
global_step: 19765, epoch: 95, loss: 0.183465
global_step: 19766, epoch: 95, loss: 0.145188
global_step: 19767, epoch: 95, loss: 0.219393
global_step: 19768, epoch: 95, loss: 0.207889
global_step: 19769, epoch: 95, loss: 0.157485
global_step: 19770, epoch: 95, loss: 0.200899
global_step: 19771, epoch: 95, loss: 0.269349
global_step: 19772, epoch: 95, loss: 0.164404
global_step: 19773, epoch: 95, loss: 0.158201
global_step: 19774, epoch: 95, loss: 0.244819
global_step: 19775, epoch: 95, loss: 0.142600
global_step: 19776, epoch: 95, loss: 0.195063
global_step: 19777, epoch: 95, loss: 0.165282
global_step: 19778, epoch: 95, loss: 0.160993
global_step: 19779, epoch: 95, loss: 0.190115
global_step: 19780, epoch: 95, loss: 0.314864
global_step: 19781, epoch: 95, loss: 0.203424
global_step: 19782, epoch: 95, loss: 0.237878
global_step: 19783, epoch: 95, loss: 0.195798
global_step: 19784, epoch: 95, loss: 0.197785
global_step: 19785, epoch: 95, loss: 0.195053
global_step: 19786, epoch: 95, loss: 0.255020
global_step: 19787, epoch: 95, loss: 0.212148
global_step: 19788, epoch: 95, loss: 0.239381
global_step: 19789, epoch: 95, loss: 0.169982
global_step: 19790, epoch: 95, loss: 0.200147
global_step: 19791, epoch: 95, loss: 0.248798
global_step: 19792, epoch: 95, loss: 0.226405
global_step: 19793, epoch: 95, loss: 0.145968
global_step: 19794, epoch: 95, loss: 0.187910
global_step: 19795, epoch: 95, loss: 0.248511
global_step: 19796, epoch: 95, loss: 0.245269
global_step: 19797, epoch: 95, loss: 0.169790
global_step: 19798, epoch: 95, loss: 0.254607
global_step: 19799, epoch: 95, loss: 0.256372
global_step: 19800, epoch: 95, loss: 0.430726
epoch: 95
train	acc: 0.9703	macro: p 0.9740, r 0.9590, f1: 0.9662	micro: p 0.9703, r 0.9703, f1 0.9703	weighted_f1:0.9703
dev	acc: 0.5149	macro: p 0.3704, r 0.3058, f1: 0.3092	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4779
test	acc: 0.5506	macro: p 0.3417, r 0.3037, f1: 0.3066	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.5215
global_step: 19801, epoch: 96, loss: 0.201301
global_step: 19802, epoch: 96, loss: 0.156883
global_step: 19803, epoch: 96, loss: 0.196970
global_step: 19804, epoch: 96, loss: 0.243267
global_step: 19805, epoch: 96, loss: 0.108290
global_step: 19806, epoch: 96, loss: 0.189581
global_step: 19807, epoch: 96, loss: 0.165668
global_step: 19808, epoch: 96, loss: 0.248773
global_step: 19809, epoch: 96, loss: 0.201137
global_step: 19810, epoch: 96, loss: 0.173006
global_step: 19811, epoch: 96, loss: 0.200382
global_step: 19812, epoch: 96, loss: 0.159607
global_step: 19813, epoch: 96, loss: 0.223602
global_step: 19814, epoch: 96, loss: 0.221969
global_step: 19815, epoch: 96, loss: 0.189318
global_step: 19816, epoch: 96, loss: 0.204378
global_step: 19817, epoch: 96, loss: 0.205646
global_step: 19818, epoch: 96, loss: 0.179019
global_step: 19819, epoch: 96, loss: 0.237739
global_step: 19820, epoch: 96, loss: 0.168215
global_step: 19821, epoch: 96, loss: 0.276727
global_step: 19822, epoch: 96, loss: 0.277626
global_step: 19823, epoch: 96, loss: 0.212036
global_step: 19824, epoch: 96, loss: 0.286206
global_step: 19825, epoch: 96, loss: 0.210006
global_step: 19826, epoch: 96, loss: 0.298524
global_step: 19827, epoch: 96, loss: 0.228287
global_step: 19828, epoch: 96, loss: 0.130863
global_step: 19829, epoch: 96, loss: 0.170527
global_step: 19830, epoch: 96, loss: 0.223726
global_step: 19831, epoch: 96, loss: 0.239392
global_step: 19832, epoch: 96, loss: 0.200958
global_step: 19833, epoch: 96, loss: 0.235019
global_step: 19834, epoch: 96, loss: 0.272129
global_step: 19835, epoch: 96, loss: 0.211344
global_step: 19836, epoch: 96, loss: 0.207205
global_step: 19837, epoch: 96, loss: 0.234164
global_step: 19838, epoch: 96, loss: 0.171254
global_step: 19839, epoch: 96, loss: 0.172998
global_step: 19840, epoch: 96, loss: 0.364969
epoch: 96
train	acc: 0.9683	macro: p 0.9718, r 0.9549, f1: 0.9630	micro: p 0.9683, r 0.9683, f1 0.9683	weighted_f1:0.9683
dev	acc: 0.5230	macro: p 0.4488, r 0.3051, f1: 0.3135	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4814
test	acc: 0.5609	macro: p 0.3299, r 0.2992, f1: 0.3024	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5254
global_step: 19841, epoch: 97, loss: 0.163923
global_step: 19842, epoch: 97, loss: 0.230079
global_step: 19843, epoch: 97, loss: 0.249118
global_step: 19844, epoch: 97, loss: 0.185256
global_step: 19845, epoch: 97, loss: 0.175359
global_step: 19846, epoch: 97, loss: 0.168760
global_step: 19847, epoch: 97, loss: 0.170878
global_step: 19848, epoch: 97, loss: 0.164032
global_step: 19849, epoch: 97, loss: 0.220373
global_step: 19850, epoch: 97, loss: 0.160437
global_step: 19851, epoch: 97, loss: 0.182677
global_step: 19852, epoch: 97, loss: 0.265143
global_step: 19853, epoch: 97, loss: 0.203758
global_step: 19854, epoch: 97, loss: 0.167500
global_step: 19855, epoch: 97, loss: 0.162026
global_step: 19856, epoch: 97, loss: 0.224246
global_step: 19857, epoch: 97, loss: 0.219880
global_step: 19858, epoch: 97, loss: 0.251689
global_step: 19859, epoch: 97, loss: 0.229083
global_step: 19860, epoch: 97, loss: 0.301794
global_step: 19861, epoch: 97, loss: 0.193314
global_step: 19862, epoch: 97, loss: 0.183131
global_step: 19863, epoch: 97, loss: 0.251949
global_step: 19864, epoch: 97, loss: 0.178873
global_step: 19865, epoch: 97, loss: 0.203846
global_step: 19866, epoch: 97, loss: 0.210993
global_step: 19867, epoch: 97, loss: 0.261263
global_step: 19868, epoch: 97, loss: 0.167400
global_step: 19869, epoch: 97, loss: 0.239137
global_step: 19870, epoch: 97, loss: 0.193704
global_step: 19871, epoch: 97, loss: 0.265975
global_step: 19872, epoch: 97, loss: 0.207747
global_step: 19873, epoch: 97, loss: 0.204737
global_step: 19874, epoch: 97, loss: 0.251743
global_step: 19875, epoch: 97, loss: 0.220607
global_step: 19876, epoch: 97, loss: 0.156351
global_step: 19877, epoch: 97, loss: 0.226615
global_step: 19878, epoch: 97, loss: 0.222482
global_step: 19879, epoch: 97, loss: 0.248765
global_step: 19880, epoch: 97, loss: 0.002670
epoch: 97
train	acc: 0.9712	macro: p 0.9730, r 0.9606, f1: 0.9666	micro: p 0.9712, r 0.9712, f1 0.9712	weighted_f1:0.9712
dev	acc: 0.5311	macro: p 0.4527, r 0.3194, f1: 0.3262	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4943
test	acc: 0.5471	macro: p 0.3115, r 0.2973, f1: 0.2972	micro: p 0.5471, r 0.5471, f1 0.5471	weighted_f1:0.5173
global_step: 19881, epoch: 98, loss: 0.205788
global_step: 19882, epoch: 98, loss: 0.206085
global_step: 19883, epoch: 98, loss: 0.212140
global_step: 19884, epoch: 98, loss: 0.211533
global_step: 19885, epoch: 98, loss: 0.181929
global_step: 19886, epoch: 98, loss: 0.157637
global_step: 19887, epoch: 98, loss: 0.178923
global_step: 19888, epoch: 98, loss: 0.149140
global_step: 19889, epoch: 98, loss: 0.257758
global_step: 19890, epoch: 98, loss: 0.173871
global_step: 19891, epoch: 98, loss: 0.245158
global_step: 19892, epoch: 98, loss: 0.263382
global_step: 19893, epoch: 98, loss: 0.172806
global_step: 19894, epoch: 98, loss: 0.165655
global_step: 19895, epoch: 98, loss: 0.198919
global_step: 19896, epoch: 98, loss: 0.239957
global_step: 19897, epoch: 98, loss: 0.264982
global_step: 19898, epoch: 98, loss: 0.211022
global_step: 19899, epoch: 98, loss: 0.194400
global_step: 19900, epoch: 98, loss: 0.198918
global_step: 19901, epoch: 98, loss: 0.122790
global_step: 19902, epoch: 98, loss: 0.243713
global_step: 19903, epoch: 98, loss: 0.220288
global_step: 19904, epoch: 98, loss: 0.167613
global_step: 19905, epoch: 98, loss: 0.241901
global_step: 19906, epoch: 98, loss: 0.184200
global_step: 19907, epoch: 98, loss: 0.168515
global_step: 19908, epoch: 98, loss: 0.248474
global_step: 19909, epoch: 98, loss: 0.171759
global_step: 19910, epoch: 98, loss: 0.140438
global_step: 19911, epoch: 98, loss: 0.136944
global_step: 19912, epoch: 98, loss: 0.154981
global_step: 19913, epoch: 98, loss: 0.238474
global_step: 19914, epoch: 98, loss: 0.185752
global_step: 19915, epoch: 98, loss: 0.229183
global_step: 19916, epoch: 98, loss: 0.204907
global_step: 19917, epoch: 98, loss: 0.250069
global_step: 19918, epoch: 98, loss: 0.242552
global_step: 19919, epoch: 98, loss: 0.218369
global_step: 19920, epoch: 98, loss: 0.345425
epoch: 98
train	acc: 0.9662	macro: p 0.9688, r 0.9542, f1: 0.9607	micro: p 0.9662, r 0.9662, f1 0.9662	weighted_f1:0.9664
dev	acc: 0.5311	macro: p 0.4296, r 0.3052, f1: 0.3065	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4828
test	acc: 0.5602	macro: p 0.3391, r 0.2946, f1: 0.2934	micro: p 0.5602, r 0.5602, f1 0.5602	weighted_f1:0.5171
global_step: 19921, epoch: 99, loss: 0.262062
global_step: 19922, epoch: 99, loss: 0.197527
global_step: 19923, epoch: 99, loss: 0.257431
global_step: 19924, epoch: 99, loss: 0.267549
global_step: 19925, epoch: 99, loss: 0.231837
global_step: 19926, epoch: 99, loss: 0.223712
global_step: 19927, epoch: 99, loss: 0.184285
global_step: 19928, epoch: 99, loss: 0.198238
global_step: 19929, epoch: 99, loss: 0.210534
global_step: 19930, epoch: 99, loss: 0.123143
global_step: 19931, epoch: 99, loss: 0.237236
global_step: 19932, epoch: 99, loss: 0.210034
global_step: 19933, epoch: 99, loss: 0.191332
global_step: 19934, epoch: 99, loss: 0.161182
global_step: 19935, epoch: 99, loss: 0.181955
global_step: 19936, epoch: 99, loss: 0.221801
global_step: 19937, epoch: 99, loss: 0.203997
global_step: 19938, epoch: 99, loss: 0.214153
global_step: 19939, epoch: 99, loss: 0.210498
global_step: 19940, epoch: 99, loss: 0.172730
global_step: 19941, epoch: 99, loss: 0.235125
global_step: 19942, epoch: 99, loss: 0.194014
global_step: 19943, epoch: 99, loss: 0.160037
global_step: 19944, epoch: 99, loss: 0.225989
global_step: 19945, epoch: 99, loss: 0.236314
global_step: 19946, epoch: 99, loss: 0.242865
global_step: 19947, epoch: 99, loss: 0.246248
global_step: 19948, epoch: 99, loss: 0.165008
global_step: 19949, epoch: 99, loss: 0.203444
global_step: 19950, epoch: 99, loss: 0.276132
global_step: 19951, epoch: 99, loss: 0.247870
global_step: 19952, epoch: 99, loss: 0.181630
global_step: 19953, epoch: 99, loss: 0.240171
global_step: 19954, epoch: 99, loss: 0.231579
global_step: 19955, epoch: 99, loss: 0.211351
global_step: 19956, epoch: 99, loss: 0.192276
global_step: 19957, epoch: 99, loss: 0.177017
global_step: 19958, epoch: 99, loss: 0.169219
global_step: 19959, epoch: 99, loss: 0.281775
global_step: 19960, epoch: 99, loss: 0.146001
epoch: 99
train	acc: 0.9709	macro: p 0.9745, r 0.9605, f1: 0.9672	micro: p 0.9709, r 0.9709, f1 0.9709	weighted_f1:0.9709
dev	acc: 0.5365	macro: p 0.4258, r 0.3050, f1: 0.3079	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4864
test	acc: 0.5617	macro: p 0.3689, r 0.2938, f1: 0.2983	micro: p 0.5617, r 0.5617, f1 0.5617	weighted_f1:0.5186
global_step: 19961, epoch: 100, loss: 0.277670
global_step: 19962, epoch: 100, loss: 0.179016
global_step: 19963, epoch: 100, loss: 0.216610
global_step: 19964, epoch: 100, loss: 0.120636
global_step: 19965, epoch: 100, loss: 0.231036
global_step: 19966, epoch: 100, loss: 0.202253
global_step: 19967, epoch: 100, loss: 0.168067
global_step: 19968, epoch: 100, loss: 0.242209
global_step: 19969, epoch: 100, loss: 0.217141
global_step: 19970, epoch: 100, loss: 0.206097
global_step: 19971, epoch: 100, loss: 0.122276
global_step: 19972, epoch: 100, loss: 0.241272
global_step: 19973, epoch: 100, loss: 0.133899
global_step: 19974, epoch: 100, loss: 0.172544
global_step: 19975, epoch: 100, loss: 0.175203
global_step: 19976, epoch: 100, loss: 0.175701
global_step: 19977, epoch: 100, loss: 0.180655
global_step: 19978, epoch: 100, loss: 0.191096
global_step: 19979, epoch: 100, loss: 0.159263
global_step: 19980, epoch: 100, loss: 0.159472
global_step: 19981, epoch: 100, loss: 0.163548
global_step: 19982, epoch: 100, loss: 0.157252
global_step: 19983, epoch: 100, loss: 0.199539
global_step: 19984, epoch: 100, loss: 0.160224
global_step: 19985, epoch: 100, loss: 0.216085
global_step: 19986, epoch: 100, loss: 0.180896
global_step: 19987, epoch: 100, loss: 0.211608
global_step: 19988, epoch: 100, loss: 0.237312
global_step: 19989, epoch: 100, loss: 0.245875
global_step: 19990, epoch: 100, loss: 0.214514
global_step: 19991, epoch: 100, loss: 0.231654
global_step: 19992, epoch: 100, loss: 0.257455
global_step: 19993, epoch: 100, loss: 0.242442
global_step: 19994, epoch: 100, loss: 0.195567
global_step: 19995, epoch: 100, loss: 0.207654
global_step: 19996, epoch: 100, loss: 0.184938
global_step: 19997, epoch: 100, loss: 0.145754
global_step: 19998, epoch: 100, loss: 0.209236
global_step: 19999, epoch: 100, loss: 0.169426
global_step: 20000, epoch: 100, loss: 0.545786
epoch: 100
train	acc: 0.9710	macro: p 0.9735, r 0.9623, f1: 0.9677	micro: p 0.9710, r 0.9710, f1 0.9710	weighted_f1:0.9710
dev	acc: 0.5059	macro: p 0.3926, r 0.3069, f1: 0.3128	micro: p 0.5059, r 0.5059, f1 0.5059	weighted_f1:0.4782
test	acc: 0.5521	macro: p 0.3413, r 0.3153, f1: 0.3183	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.5299
BEST MODEL epoch: 41
train	acc: 0.9500 macro_p: 0.9541 macro_r: 0.9217 macro_f1: 0.9361 micro_p: 0.9500 micro_r: 0.9500 micro_f1: 0.9500 weighted_f1: 0.9501
dev	acc: 0.5347 macro_p: 0.3858 macro_r: 0.3299 macro_f1: 0.3359 micro_p: 0.5347 micro_r: 0.5347 micro_f1: 0.5347 weighted_f1: 0.5057
test	acc: 0.5521 macro_p: 0.3297 macro_r: 0.3164 macro_f1: 0.3176 micro_p: 0.5521 micro_r: 0.5521 micro_f1: 0.5521 weighted_f1: 0.5302
====================TRAINING FINISHED====================
best epoch: [47, 12, 98, 39, 41], avg test weighted f1: 0.535958
