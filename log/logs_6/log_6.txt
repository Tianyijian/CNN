nohup: ignoring input
dict_keys(['train_x', 'train_y', 'dev_x', 'dev_y', 'test_x', 'test_y'])
max_sent_length:91 

-------train--------
9989 9989
['Okay', '.']   0
['So', 'you', 'risked', 'your', 'life', ',', 'for', 'a', 'sandwich', '!']   1

-------dev--------
1109 1109
['Good', '.']   4
['Ross', '!', 'Get', 'a', 'shot', 'of', 'this', '.', '(', 'He', "'s", 'carrying', 'an', 'issue', 'of', 'the']   2

-------test--------
2610 2610
['Okay', '!']   1
['Okay', 'now', 'Joey', ',', "y'know", 'that', 'since', 'you', "'re", 'returning', 'all', 'of', 'this', 'stuff', 'right', 'after', 'the', 'audition', 'you', "'re", 'gon', 'na', 'have', 'to', 'wear', 'underwear', '?']   0
====================INFORMATION====================
MODEL: rand
DATASET: MELD
VOCAB_SIZE: 7687
EPOCH: 100
LEARNING_RATE: 0.05
EARLY_STOPPING: False
SAVE_MODEL: False
MAX_SENT_LEN: 91
CLASS_SIZE: 7
FILTERS: [3, 4, 5]
FILTER_NUM: [50, 50, 50]
====================INFORMATION====================
====================TRAINING STARTED====================
==========ROUND 1==========
global_step: 1, epoch: 1, loss: 1.980917
global_step: 2, epoch: 1, loss: 1.982876
global_step: 3, epoch: 1, loss: 1.943618
global_step: 4, epoch: 1, loss: 1.904119
global_step: 5, epoch: 1, loss: 1.914236
global_step: 6, epoch: 1, loss: 1.882148
global_step: 7, epoch: 1, loss: 1.837450
global_step: 8, epoch: 1, loss: 1.849702
global_step: 9, epoch: 1, loss: 1.828898
global_step: 10, epoch: 1, loss: 1.817478
global_step: 11, epoch: 1, loss: 1.764115
global_step: 12, epoch: 1, loss: 1.777584
global_step: 13, epoch: 1, loss: 1.714152
global_step: 14, epoch: 1, loss: 1.759070
global_step: 15, epoch: 1, loss: 1.719955
global_step: 16, epoch: 1, loss: 1.696747
global_step: 17, epoch: 1, loss: 1.636723
global_step: 18, epoch: 1, loss: 1.692784
global_step: 19, epoch: 1, loss: 1.665823
global_step: 20, epoch: 1, loss: 1.654368
global_step: 21, epoch: 1, loss: 1.657759
global_step: 22, epoch: 1, loss: 1.650034
global_step: 23, epoch: 1, loss: 1.558169
global_step: 24, epoch: 1, loss: 1.715205
global_step: 25, epoch: 1, loss: 1.546318
global_step: 26, epoch: 1, loss: 1.597542
global_step: 27, epoch: 1, loss: 1.668620
global_step: 28, epoch: 1, loss: 1.644536
global_step: 29, epoch: 1, loss: 1.535022
global_step: 30, epoch: 1, loss: 1.536294
global_step: 31, epoch: 1, loss: 1.606211
global_step: 32, epoch: 1, loss: 1.551821
global_step: 33, epoch: 1, loss: 1.554802
global_step: 34, epoch: 1, loss: 1.489040
global_step: 35, epoch: 1, loss: 1.465101
global_step: 36, epoch: 1, loss: 1.606073
global_step: 37, epoch: 1, loss: 1.505048
global_step: 38, epoch: 1, loss: 1.571745
global_step: 39, epoch: 1, loss: 1.577362
global_step: 40, epoch: 1, loss: 0.936706
epoch: 1
train	acc: 0.4961	macro: p 0.2582, r 0.1677, f1: 0.1369	micro: p 0.4961, r 0.4961, f1 0.4961	weighted_f1:0.3594
dev	acc: 0.4545	macro: p 0.2565, r 0.1740, f1: 0.1376	micro: p 0.4545, r 0.4545, f1 0.4545	weighted_f1:0.3138
test	acc: 0.5073	macro: p 0.2617, r 0.1737, f1: 0.1468	micro: p 0.5073, r 0.5073, f1 0.5073	weighted_f1:0.3729
New best model!
global_step: 41, epoch: 2, loss: 1.574246
global_step: 42, epoch: 2, loss: 1.551129
global_step: 43, epoch: 2, loss: 1.575271
global_step: 44, epoch: 2, loss: 1.685239
global_step: 45, epoch: 2, loss: 1.457277
global_step: 46, epoch: 2, loss: 1.473650
global_step: 47, epoch: 2, loss: 1.516192
global_step: 48, epoch: 2, loss: 1.352268
global_step: 49, epoch: 2, loss: 1.466257
global_step: 50, epoch: 2, loss: 1.529432
global_step: 51, epoch: 2, loss: 1.472847
global_step: 52, epoch: 2, loss: 1.592919
global_step: 53, epoch: 2, loss: 1.516612
global_step: 54, epoch: 2, loss: 1.542902
global_step: 55, epoch: 2, loss: 1.449123
global_step: 56, epoch: 2, loss: 1.422622
global_step: 57, epoch: 2, loss: 1.580602
global_step: 58, epoch: 2, loss: 1.452312
global_step: 59, epoch: 2, loss: 1.432526
global_step: 60, epoch: 2, loss: 1.414677
global_step: 61, epoch: 2, loss: 1.387093
global_step: 62, epoch: 2, loss: 1.552886
global_step: 63, epoch: 2, loss: 1.486674
global_step: 64, epoch: 2, loss: 1.491403
global_step: 65, epoch: 2, loss: 1.613132
global_step: 66, epoch: 2, loss: 1.462431
global_step: 67, epoch: 2, loss: 1.446404
global_step: 68, epoch: 2, loss: 1.453994
global_step: 69, epoch: 2, loss: 1.429620
global_step: 70, epoch: 2, loss: 1.502983
global_step: 71, epoch: 2, loss: 1.474111
global_step: 72, epoch: 2, loss: 1.505156
global_step: 73, epoch: 2, loss: 1.454768
global_step: 74, epoch: 2, loss: 1.473043
global_step: 75, epoch: 2, loss: 1.451194
global_step: 76, epoch: 2, loss: 1.466545
global_step: 77, epoch: 2, loss: 1.440838
global_step: 78, epoch: 2, loss: 1.401743
global_step: 79, epoch: 2, loss: 1.462006
global_step: 80, epoch: 2, loss: 1.124360
epoch: 2
train	acc: 0.5355	macro: p 0.2152, r 0.2088, f1: 0.1886	micro: p 0.5355, r 0.5355, f1 0.5355	weighted_f1:0.4269
dev	acc: 0.4806	macro: p 0.1934, r 0.2068, f1: 0.1763	micro: p 0.4806, r 0.4806, f1 0.4806	weighted_f1:0.3623
test	acc: 0.5425	macro: p 0.2085, r 0.2148, f1: 0.1935	micro: p 0.5425, r 0.5425, f1 0.5425	weighted_f1:0.4312
New best model!
global_step: 81, epoch: 3, loss: 1.474671
global_step: 82, epoch: 3, loss: 1.482558
global_step: 83, epoch: 3, loss: 1.316398
global_step: 84, epoch: 3, loss: 1.483768
global_step: 85, epoch: 3, loss: 1.332907
global_step: 86, epoch: 3, loss: 1.432740
global_step: 87, epoch: 3, loss: 1.396257
global_step: 88, epoch: 3, loss: 1.474269
global_step: 89, epoch: 3, loss: 1.447587
global_step: 90, epoch: 3, loss: 1.448629
global_step: 91, epoch: 3, loss: 1.425182
global_step: 92, epoch: 3, loss: 1.369636
global_step: 93, epoch: 3, loss: 1.583418
global_step: 94, epoch: 3, loss: 1.441224
global_step: 95, epoch: 3, loss: 1.458144
global_step: 96, epoch: 3, loss: 1.471312
global_step: 97, epoch: 3, loss: 1.444539
global_step: 98, epoch: 3, loss: 1.443753
global_step: 99, epoch: 3, loss: 1.342665
global_step: 100, epoch: 3, loss: 1.529766
global_step: 101, epoch: 3, loss: 1.435405
global_step: 102, epoch: 3, loss: 1.394002
global_step: 103, epoch: 3, loss: 1.349616
global_step: 104, epoch: 3, loss: 1.534346
global_step: 105, epoch: 3, loss: 1.488881
global_step: 106, epoch: 3, loss: 1.437550
global_step: 107, epoch: 3, loss: 1.395719
global_step: 108, epoch: 3, loss: 1.415899
global_step: 109, epoch: 3, loss: 1.515035
global_step: 110, epoch: 3, loss: 1.478009
global_step: 111, epoch: 3, loss: 1.436982
global_step: 112, epoch: 3, loss: 1.448820
global_step: 113, epoch: 3, loss: 1.340836
global_step: 114, epoch: 3, loss: 1.401285
global_step: 115, epoch: 3, loss: 1.461267
global_step: 116, epoch: 3, loss: 1.400248
global_step: 117, epoch: 3, loss: 1.357126
global_step: 118, epoch: 3, loss: 1.425462
global_step: 119, epoch: 3, loss: 1.375638
global_step: 120, epoch: 3, loss: 1.314934
epoch: 3
train	acc: 0.5490	macro: p 0.2836, r 0.2249, f1: 0.2034	micro: p 0.5490, r 0.5490, f1 0.5490	weighted_f1:0.4496
dev	acc: 0.4995	macro: p 0.2493, r 0.2289, f1: 0.1981	micro: p 0.4995, r 0.4995, f1 0.4995	weighted_f1:0.3919
test	acc: 0.5559	macro: p 0.2632, r 0.2333, f1: 0.2078	micro: p 0.5559, r 0.5559, f1 0.5559	weighted_f1:0.4535
New best model!
global_step: 121, epoch: 4, loss: 1.406350
global_step: 122, epoch: 4, loss: 1.403577
global_step: 123, epoch: 4, loss: 1.498487
global_step: 124, epoch: 4, loss: 1.469932
global_step: 125, epoch: 4, loss: 1.468930
global_step: 126, epoch: 4, loss: 1.428410
global_step: 127, epoch: 4, loss: 1.410397
global_step: 128, epoch: 4, loss: 1.465505
global_step: 129, epoch: 4, loss: 1.415951
global_step: 130, epoch: 4, loss: 1.258029
global_step: 131, epoch: 4, loss: 1.404780
global_step: 132, epoch: 4, loss: 1.476514
global_step: 133, epoch: 4, loss: 1.440131
global_step: 134, epoch: 4, loss: 1.382850
global_step: 135, epoch: 4, loss: 1.473786
global_step: 136, epoch: 4, loss: 1.324078
global_step: 137, epoch: 4, loss: 1.404921
global_step: 138, epoch: 4, loss: 1.452948
global_step: 139, epoch: 4, loss: 1.464314
global_step: 140, epoch: 4, loss: 1.479630
global_step: 141, epoch: 4, loss: 1.377654
global_step: 142, epoch: 4, loss: 1.295324
global_step: 143, epoch: 4, loss: 1.377298
global_step: 144, epoch: 4, loss: 1.366293
global_step: 145, epoch: 4, loss: 1.333566
global_step: 146, epoch: 4, loss: 1.500500
global_step: 147, epoch: 4, loss: 1.315473
global_step: 148, epoch: 4, loss: 1.332669
global_step: 149, epoch: 4, loss: 1.350563
global_step: 150, epoch: 4, loss: 1.331315
global_step: 151, epoch: 4, loss: 1.416342
global_step: 152, epoch: 4, loss: 1.336612
global_step: 153, epoch: 4, loss: 1.466822
global_step: 154, epoch: 4, loss: 1.528015
global_step: 155, epoch: 4, loss: 1.376507
global_step: 156, epoch: 4, loss: 1.288914
global_step: 157, epoch: 4, loss: 1.349132
global_step: 158, epoch: 4, loss: 1.450171
global_step: 159, epoch: 4, loss: 1.375376
global_step: 160, epoch: 4, loss: 1.166694
epoch: 4
train	acc: 0.5615	macro: p 0.2928, r 0.2419, f1: 0.2311	micro: p 0.5615, r 0.5615, f1 0.5615	weighted_f1:0.4760
dev	acc: 0.5077	macro: p 0.2600, r 0.2386, f1: 0.2139	micro: p 0.5077, r 0.5077, f1 0.5077	weighted_f1:0.4108
test	acc: 0.5651	macro: p 0.2739, r 0.2451, f1: 0.2289	micro: p 0.5651, r 0.5651, f1 0.5651	weighted_f1:0.4770
New best model!
global_step: 161, epoch: 5, loss: 1.331660
global_step: 162, epoch: 5, loss: 1.524368
global_step: 163, epoch: 5, loss: 1.345204
global_step: 164, epoch: 5, loss: 1.367826
global_step: 165, epoch: 5, loss: 1.451756
global_step: 166, epoch: 5, loss: 1.486995
global_step: 167, epoch: 5, loss: 1.414978
global_step: 168, epoch: 5, loss: 1.312464
global_step: 169, epoch: 5, loss: 1.253440
global_step: 170, epoch: 5, loss: 1.421812
global_step: 171, epoch: 5, loss: 1.341725
global_step: 172, epoch: 5, loss: 1.421332
global_step: 173, epoch: 5, loss: 1.413544
global_step: 174, epoch: 5, loss: 1.350544
global_step: 175, epoch: 5, loss: 1.339782
global_step: 176, epoch: 5, loss: 1.468905
global_step: 177, epoch: 5, loss: 1.384149
global_step: 178, epoch: 5, loss: 1.441479
global_step: 179, epoch: 5, loss: 1.303667
global_step: 180, epoch: 5, loss: 1.346832
global_step: 181, epoch: 5, loss: 1.340263
global_step: 182, epoch: 5, loss: 1.518657
global_step: 183, epoch: 5, loss: 1.295776
global_step: 184, epoch: 5, loss: 1.350287
global_step: 185, epoch: 5, loss: 1.373333
global_step: 186, epoch: 5, loss: 1.335038
global_step: 187, epoch: 5, loss: 1.455678
global_step: 188, epoch: 5, loss: 1.442786
global_step: 189, epoch: 5, loss: 1.327999
global_step: 190, epoch: 5, loss: 1.450059
global_step: 191, epoch: 5, loss: 1.309617
global_step: 192, epoch: 5, loss: 1.304302
global_step: 193, epoch: 5, loss: 1.419313
global_step: 194, epoch: 5, loss: 1.360537
global_step: 195, epoch: 5, loss: 1.341782
global_step: 196, epoch: 5, loss: 1.387664
global_step: 197, epoch: 5, loss: 1.405786
global_step: 198, epoch: 5, loss: 1.334796
global_step: 199, epoch: 5, loss: 1.360968
global_step: 200, epoch: 5, loss: 1.325067
epoch: 5
train	acc: 0.5634	macro: p 0.2880, r 0.2444, f1: 0.2282	micro: p 0.5634, r 0.5634, f1 0.5634	weighted_f1:0.4771
dev	acc: 0.5149	macro: p 0.2696, r 0.2476, f1: 0.2174	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4161
test	acc: 0.5640	macro: p 0.2641, r 0.2470, f1: 0.2244	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.4743
New best model!
global_step: 201, epoch: 6, loss: 1.434310
global_step: 202, epoch: 6, loss: 1.410966
global_step: 203, epoch: 6, loss: 1.432419
global_step: 204, epoch: 6, loss: 1.389909
global_step: 205, epoch: 6, loss: 1.338120
global_step: 206, epoch: 6, loss: 1.369451
global_step: 207, epoch: 6, loss: 1.323324
global_step: 208, epoch: 6, loss: 1.398212
global_step: 209, epoch: 6, loss: 1.359598
global_step: 210, epoch: 6, loss: 1.286373
global_step: 211, epoch: 6, loss: 1.329990
global_step: 212, epoch: 6, loss: 1.380848
global_step: 213, epoch: 6, loss: 1.392469
global_step: 214, epoch: 6, loss: 1.395737
global_step: 215, epoch: 6, loss: 1.305770
global_step: 216, epoch: 6, loss: 1.343499
global_step: 217, epoch: 6, loss: 1.410968
global_step: 218, epoch: 6, loss: 1.478348
global_step: 219, epoch: 6, loss: 1.425663
global_step: 220, epoch: 6, loss: 1.250792
global_step: 221, epoch: 6, loss: 1.389353
global_step: 222, epoch: 6, loss: 1.354845
global_step: 223, epoch: 6, loss: 1.325336
global_step: 224, epoch: 6, loss: 1.354108
global_step: 225, epoch: 6, loss: 1.529691
global_step: 226, epoch: 6, loss: 1.439218
global_step: 227, epoch: 6, loss: 1.344311
global_step: 228, epoch: 6, loss: 1.319027
global_step: 229, epoch: 6, loss: 1.416957
global_step: 230, epoch: 6, loss: 1.459038
global_step: 231, epoch: 6, loss: 1.321276
global_step: 232, epoch: 6, loss: 1.325996
global_step: 233, epoch: 6, loss: 1.432297
global_step: 234, epoch: 6, loss: 1.310472
global_step: 235, epoch: 6, loss: 1.335167
global_step: 236, epoch: 6, loss: 1.301181
global_step: 237, epoch: 6, loss: 1.308195
global_step: 238, epoch: 6, loss: 1.366935
global_step: 239, epoch: 6, loss: 1.280142
global_step: 240, epoch: 6, loss: 1.219221
epoch: 6
train	acc: 0.5733	macro: p 0.3023, r 0.2575, f1: 0.2493	micro: p 0.5733, r 0.5733, f1 0.5733	weighted_f1:0.4952
dev	acc: 0.5194	macro: p 0.2720, r 0.2523, f1: 0.2299	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4292
test	acc: 0.5705	macro: p 0.2820, r 0.2548, f1: 0.2405	micro: p 0.5705, r 0.5705, f1 0.5705	weighted_f1:0.4901
New best model!
global_step: 241, epoch: 7, loss: 1.435116
global_step: 242, epoch: 7, loss: 1.380816
global_step: 243, epoch: 7, loss: 1.426938
global_step: 244, epoch: 7, loss: 1.407067
global_step: 245, epoch: 7, loss: 1.381441
global_step: 246, epoch: 7, loss: 1.382561
global_step: 247, epoch: 7, loss: 1.369085
global_step: 248, epoch: 7, loss: 1.452339
global_step: 249, epoch: 7, loss: 1.253741
global_step: 250, epoch: 7, loss: 1.381649
global_step: 251, epoch: 7, loss: 1.301314
global_step: 252, epoch: 7, loss: 1.405897
global_step: 253, epoch: 7, loss: 1.343216
global_step: 254, epoch: 7, loss: 1.408047
global_step: 255, epoch: 7, loss: 1.299983
global_step: 256, epoch: 7, loss: 1.252790
global_step: 257, epoch: 7, loss: 1.236968
global_step: 258, epoch: 7, loss: 1.327533
global_step: 259, epoch: 7, loss: 1.324383
global_step: 260, epoch: 7, loss: 1.403374
global_step: 261, epoch: 7, loss: 1.370575
global_step: 262, epoch: 7, loss: 1.294765
global_step: 263, epoch: 7, loss: 1.371534
global_step: 264, epoch: 7, loss: 1.241400
global_step: 265, epoch: 7, loss: 1.334226
global_step: 266, epoch: 7, loss: 1.399505
global_step: 267, epoch: 7, loss: 1.327687
global_step: 268, epoch: 7, loss: 1.415103
global_step: 269, epoch: 7, loss: 1.339628
global_step: 270, epoch: 7, loss: 1.395559
global_step: 271, epoch: 7, loss: 1.309316
global_step: 272, epoch: 7, loss: 1.404014
global_step: 273, epoch: 7, loss: 1.302013
global_step: 274, epoch: 7, loss: 1.270543
global_step: 275, epoch: 7, loss: 1.247680
global_step: 276, epoch: 7, loss: 1.283110
global_step: 277, epoch: 7, loss: 1.279222
global_step: 278, epoch: 7, loss: 1.427320
global_step: 279, epoch: 7, loss: 1.354911
global_step: 280, epoch: 7, loss: 1.771362
epoch: 7
train	acc: 0.5816	macro: p 0.2987, r 0.2741, f1: 0.2688	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5133
dev	acc: 0.5248	macro: p 0.2640, r 0.2638, f1: 0.2435	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4428
test	acc: 0.5743	macro: p 0.2726, r 0.2670, f1: 0.2537	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5016
New best model!
global_step: 281, epoch: 8, loss: 1.428424
global_step: 282, epoch: 8, loss: 1.303402
global_step: 283, epoch: 8, loss: 1.233113
global_step: 284, epoch: 8, loss: 1.428836
global_step: 285, epoch: 8, loss: 1.318583
global_step: 286, epoch: 8, loss: 1.269478
global_step: 287, epoch: 8, loss: 1.314999
global_step: 288, epoch: 8, loss: 1.364801
global_step: 289, epoch: 8, loss: 1.255241
global_step: 290, epoch: 8, loss: 1.258962
global_step: 291, epoch: 8, loss: 1.349158
global_step: 292, epoch: 8, loss: 1.337613
global_step: 293, epoch: 8, loss: 1.414894
global_step: 294, epoch: 8, loss: 1.322977
global_step: 295, epoch: 8, loss: 1.381893
global_step: 296, epoch: 8, loss: 1.207136
global_step: 297, epoch: 8, loss: 1.362988
global_step: 298, epoch: 8, loss: 1.348747
global_step: 299, epoch: 8, loss: 1.453741
global_step: 300, epoch: 8, loss: 1.386940
global_step: 301, epoch: 8, loss: 1.246256
global_step: 302, epoch: 8, loss: 1.240354
global_step: 303, epoch: 8, loss: 1.386072
global_step: 304, epoch: 8, loss: 1.382235
global_step: 305, epoch: 8, loss: 1.372096
global_step: 306, epoch: 8, loss: 1.447624
global_step: 307, epoch: 8, loss: 1.348236
global_step: 308, epoch: 8, loss: 1.309793
global_step: 309, epoch: 8, loss: 1.421116
global_step: 310, epoch: 8, loss: 1.322286
global_step: 311, epoch: 8, loss: 1.286007
global_step: 312, epoch: 8, loss: 1.337251
global_step: 313, epoch: 8, loss: 1.242163
global_step: 314, epoch: 8, loss: 1.345540
global_step: 315, epoch: 8, loss: 1.293086
global_step: 316, epoch: 8, loss: 1.347200
global_step: 317, epoch: 8, loss: 1.322158
global_step: 318, epoch: 8, loss: 1.376289
global_step: 319, epoch: 8, loss: 1.304199
global_step: 320, epoch: 8, loss: 0.995996
epoch: 8
train	acc: 0.5855	macro: p 0.3076, r 0.2763, f1: 0.2733	micro: p 0.5855, r 0.5855, f1 0.5855	weighted_f1:0.5171
dev	acc: 0.5230	macro: p 0.2651, r 0.2609, f1: 0.2428	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4415
test	acc: 0.5755	macro: p 0.2838, r 0.2662, f1: 0.2569	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5037
global_step: 321, epoch: 9, loss: 1.301230
global_step: 322, epoch: 9, loss: 1.392117
global_step: 323, epoch: 9, loss: 1.380335
global_step: 324, epoch: 9, loss: 1.294644
global_step: 325, epoch: 9, loss: 1.312847
global_step: 326, epoch: 9, loss: 1.286377
global_step: 327, epoch: 9, loss: 1.293375
global_step: 328, epoch: 9, loss: 1.286873
global_step: 329, epoch: 9, loss: 1.312157
global_step: 330, epoch: 9, loss: 1.316757
global_step: 331, epoch: 9, loss: 1.252645
global_step: 332, epoch: 9, loss: 1.471611
global_step: 333, epoch: 9, loss: 1.193813
global_step: 334, epoch: 9, loss: 1.343806
global_step: 335, epoch: 9, loss: 1.361841
global_step: 336, epoch: 9, loss: 1.382944
global_step: 337, epoch: 9, loss: 1.391506
global_step: 338, epoch: 9, loss: 1.234454
global_step: 339, epoch: 9, loss: 1.252739
global_step: 340, epoch: 9, loss: 1.297661
global_step: 341, epoch: 9, loss: 1.255906
global_step: 342, epoch: 9, loss: 1.390048
global_step: 343, epoch: 9, loss: 1.280309
global_step: 344, epoch: 9, loss: 1.293944
global_step: 345, epoch: 9, loss: 1.396701
global_step: 346, epoch: 9, loss: 1.318859
global_step: 347, epoch: 9, loss: 1.373186
global_step: 348, epoch: 9, loss: 1.272502
global_step: 349, epoch: 9, loss: 1.345619
global_step: 350, epoch: 9, loss: 1.408648
global_step: 351, epoch: 9, loss: 1.359636
global_step: 352, epoch: 9, loss: 1.381315
global_step: 353, epoch: 9, loss: 1.357352
global_step: 354, epoch: 9, loss: 1.385768
global_step: 355, epoch: 9, loss: 1.326356
global_step: 356, epoch: 9, loss: 1.205808
global_step: 357, epoch: 9, loss: 1.321150
global_step: 358, epoch: 9, loss: 1.311721
global_step: 359, epoch: 9, loss: 1.342120
global_step: 360, epoch: 9, loss: 1.016327
epoch: 9
train	acc: 0.5856	macro: p 0.2968, r 0.2828, f1: 0.2802	micro: p 0.5856, r 0.5856, f1 0.5856	weighted_f1:0.5215
dev	acc: 0.5311	macro: p 0.2692, r 0.2711, f1: 0.2581	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4560
test	acc: 0.5801	macro: p 0.2798, r 0.2754, f1: 0.2689	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5139
New best model!
global_step: 361, epoch: 10, loss: 1.220994
global_step: 362, epoch: 10, loss: 1.243075
global_step: 363, epoch: 10, loss: 1.423385
global_step: 364, epoch: 10, loss: 1.334723
global_step: 365, epoch: 10, loss: 1.415678
global_step: 366, epoch: 10, loss: 1.319835
global_step: 367, epoch: 10, loss: 1.352221
global_step: 368, epoch: 10, loss: 1.345259
global_step: 369, epoch: 10, loss: 1.251449
global_step: 370, epoch: 10, loss: 1.376421
global_step: 371, epoch: 10, loss: 1.308004
global_step: 372, epoch: 10, loss: 1.284553
global_step: 373, epoch: 10, loss: 1.359091
global_step: 374, epoch: 10, loss: 1.371965
global_step: 375, epoch: 10, loss: 1.448181
global_step: 376, epoch: 10, loss: 1.249478
global_step: 377, epoch: 10, loss: 1.279312
global_step: 378, epoch: 10, loss: 1.378907
global_step: 379, epoch: 10, loss: 1.454844
global_step: 380, epoch: 10, loss: 1.262935
global_step: 381, epoch: 10, loss: 1.226197
global_step: 382, epoch: 10, loss: 1.337068
global_step: 383, epoch: 10, loss: 1.255094
global_step: 384, epoch: 10, loss: 1.329405
global_step: 385, epoch: 10, loss: 1.361070
global_step: 386, epoch: 10, loss: 1.390243
global_step: 387, epoch: 10, loss: 1.347782
global_step: 388, epoch: 10, loss: 1.285904
global_step: 389, epoch: 10, loss: 1.320634
global_step: 390, epoch: 10, loss: 1.261498
global_step: 391, epoch: 10, loss: 1.306487
global_step: 392, epoch: 10, loss: 1.238811
global_step: 393, epoch: 10, loss: 1.242596
global_step: 394, epoch: 10, loss: 1.244818
global_step: 395, epoch: 10, loss: 1.361539
global_step: 396, epoch: 10, loss: 1.288849
global_step: 397, epoch: 10, loss: 1.405591
global_step: 398, epoch: 10, loss: 1.216443
global_step: 399, epoch: 10, loss: 1.331606
global_step: 400, epoch: 10, loss: 1.164787
epoch: 10
train	acc: 0.5816	macro: p 0.4557, r 0.2705, f1: 0.2617	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5087
dev	acc: 0.5194	macro: p 0.2595, r 0.2584, f1: 0.2296	micro: p 0.5194, r 0.5194, f1 0.5194	weighted_f1:0.4296
test	acc: 0.5736	macro: p 0.2771, r 0.2645, f1: 0.2460	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.4949
global_step: 401, epoch: 11, loss: 1.292226
global_step: 402, epoch: 11, loss: 1.417931
global_step: 403, epoch: 11, loss: 1.297693
global_step: 404, epoch: 11, loss: 1.301456
global_step: 405, epoch: 11, loss: 1.357342
global_step: 406, epoch: 11, loss: 1.277718
global_step: 407, epoch: 11, loss: 1.435774
global_step: 408, epoch: 11, loss: 1.326320
global_step: 409, epoch: 11, loss: 1.318285
global_step: 410, epoch: 11, loss: 1.246700
global_step: 411, epoch: 11, loss: 1.251663
global_step: 412, epoch: 11, loss: 1.364067
global_step: 413, epoch: 11, loss: 1.326639
global_step: 414, epoch: 11, loss: 1.198483
global_step: 415, epoch: 11, loss: 1.211260
global_step: 416, epoch: 11, loss: 1.249499
global_step: 417, epoch: 11, loss: 1.243995
global_step: 418, epoch: 11, loss: 1.269684
global_step: 419, epoch: 11, loss: 1.289546
global_step: 420, epoch: 11, loss: 1.337844
global_step: 421, epoch: 11, loss: 1.394379
global_step: 422, epoch: 11, loss: 1.390181
global_step: 423, epoch: 11, loss: 1.338819
global_step: 424, epoch: 11, loss: 1.247579
global_step: 425, epoch: 11, loss: 1.312253
global_step: 426, epoch: 11, loss: 1.262459
global_step: 427, epoch: 11, loss: 1.296501
global_step: 428, epoch: 11, loss: 1.383905
global_step: 429, epoch: 11, loss: 1.408220
global_step: 430, epoch: 11, loss: 1.212180
global_step: 431, epoch: 11, loss: 1.232164
global_step: 432, epoch: 11, loss: 1.279743
global_step: 433, epoch: 11, loss: 1.221745
global_step: 434, epoch: 11, loss: 1.432953
global_step: 435, epoch: 11, loss: 1.175811
global_step: 436, epoch: 11, loss: 1.321718
global_step: 437, epoch: 11, loss: 1.309426
global_step: 438, epoch: 11, loss: 1.260785
global_step: 439, epoch: 11, loss: 1.350172
global_step: 440, epoch: 11, loss: 1.590571
epoch: 11
train	acc: 0.5928	macro: p 0.4575, r 0.2872, f1: 0.2857	micro: p 0.5928, r 0.5928, f1 0.5928	weighted_f1:0.5284
dev	acc: 0.5293	macro: p 0.2711, r 0.2686, f1: 0.2522	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4520
test	acc: 0.5847	macro: p 0.2930, r 0.2773, f1: 0.2698	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5169
global_step: 441, epoch: 12, loss: 1.263637
global_step: 442, epoch: 12, loss: 1.402266
global_step: 443, epoch: 12, loss: 1.328885
global_step: 444, epoch: 12, loss: 1.415868
global_step: 445, epoch: 12, loss: 1.224331
global_step: 446, epoch: 12, loss: 1.278604
global_step: 447, epoch: 12, loss: 1.283379
global_step: 448, epoch: 12, loss: 1.302664
global_step: 449, epoch: 12, loss: 1.349043
global_step: 450, epoch: 12, loss: 1.362034
global_step: 451, epoch: 12, loss: 1.262338
global_step: 452, epoch: 12, loss: 1.236075
global_step: 453, epoch: 12, loss: 1.234569
global_step: 454, epoch: 12, loss: 1.250705
global_step: 455, epoch: 12, loss: 1.271779
global_step: 456, epoch: 12, loss: 1.255135
global_step: 457, epoch: 12, loss: 1.323477
global_step: 458, epoch: 12, loss: 1.289430
global_step: 459, epoch: 12, loss: 1.289839
global_step: 460, epoch: 12, loss: 1.283406
global_step: 461, epoch: 12, loss: 1.331752
global_step: 462, epoch: 12, loss: 1.327624
global_step: 463, epoch: 12, loss: 1.264087
global_step: 464, epoch: 12, loss: 1.212592
global_step: 465, epoch: 12, loss: 1.322178
global_step: 466, epoch: 12, loss: 1.420482
global_step: 467, epoch: 12, loss: 1.312420
global_step: 468, epoch: 12, loss: 1.344342
global_step: 469, epoch: 12, loss: 1.292018
global_step: 470, epoch: 12, loss: 1.191480
global_step: 471, epoch: 12, loss: 1.384491
global_step: 472, epoch: 12, loss: 1.259163
global_step: 473, epoch: 12, loss: 1.394845
global_step: 474, epoch: 12, loss: 1.195928
global_step: 475, epoch: 12, loss: 1.231403
global_step: 476, epoch: 12, loss: 1.308410
global_step: 477, epoch: 12, loss: 1.286024
global_step: 478, epoch: 12, loss: 1.280764
global_step: 479, epoch: 12, loss: 1.292073
global_step: 480, epoch: 12, loss: 1.494712
epoch: 12
train	acc: 0.5930	macro: p 0.4609, r 0.2863, f1: 0.2831	micro: p 0.5930, r 0.5930, f1 0.5930	weighted_f1:0.5275
dev	acc: 0.5275	macro: p 0.2724, r 0.2682, f1: 0.2450	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4449
test	acc: 0.5782	macro: p 0.2822, r 0.2723, f1: 0.2589	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5062
global_step: 481, epoch: 13, loss: 1.314754
global_step: 482, epoch: 13, loss: 1.289480
global_step: 483, epoch: 13, loss: 1.261117
global_step: 484, epoch: 13, loss: 1.234271
global_step: 485, epoch: 13, loss: 1.338657
global_step: 486, epoch: 13, loss: 1.253354
global_step: 487, epoch: 13, loss: 1.220588
global_step: 488, epoch: 13, loss: 1.231928
global_step: 489, epoch: 13, loss: 1.480801
global_step: 490, epoch: 13, loss: 1.302850
global_step: 491, epoch: 13, loss: 1.373830
global_step: 492, epoch: 13, loss: 1.318462
global_step: 493, epoch: 13, loss: 1.247990
global_step: 494, epoch: 13, loss: 1.301530
global_step: 495, epoch: 13, loss: 1.231152
global_step: 496, epoch: 13, loss: 1.453192
global_step: 497, epoch: 13, loss: 1.294965
global_step: 498, epoch: 13, loss: 1.301200
global_step: 499, epoch: 13, loss: 1.286795
global_step: 500, epoch: 13, loss: 1.307817
global_step: 501, epoch: 13, loss: 1.356779
global_step: 502, epoch: 13, loss: 1.203156
global_step: 503, epoch: 13, loss: 1.260292
global_step: 504, epoch: 13, loss: 1.125365
global_step: 505, epoch: 13, loss: 1.175290
global_step: 506, epoch: 13, loss: 1.288948
global_step: 507, epoch: 13, loss: 1.217183
global_step: 508, epoch: 13, loss: 1.298592
global_step: 509, epoch: 13, loss: 1.223009
global_step: 510, epoch: 13, loss: 1.188772
global_step: 511, epoch: 13, loss: 1.217579
global_step: 512, epoch: 13, loss: 1.365818
global_step: 513, epoch: 13, loss: 1.245939
global_step: 514, epoch: 13, loss: 1.346641
global_step: 515, epoch: 13, loss: 1.295800
global_step: 516, epoch: 13, loss: 1.412415
global_step: 517, epoch: 13, loss: 1.246923
global_step: 518, epoch: 13, loss: 1.329009
global_step: 519, epoch: 13, loss: 1.172649
global_step: 520, epoch: 13, loss: 0.989888
epoch: 13
train	acc: 0.5947	macro: p 0.4630, r 0.2887, f1: 0.2865	micro: p 0.5947, r 0.5947, f1 0.5947	weighted_f1:0.5302
dev	acc: 0.5293	macro: p 0.2743, r 0.2696, f1: 0.2491	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4492
test	acc: 0.5801	macro: p 0.2859, r 0.2741, f1: 0.2619	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5092
global_step: 521, epoch: 14, loss: 1.278411
global_step: 522, epoch: 14, loss: 1.328529
global_step: 523, epoch: 14, loss: 1.227444
global_step: 524, epoch: 14, loss: 1.353421
global_step: 525, epoch: 14, loss: 1.307406
global_step: 526, epoch: 14, loss: 1.276552
global_step: 527, epoch: 14, loss: 1.299826
global_step: 528, epoch: 14, loss: 1.211620
global_step: 529, epoch: 14, loss: 1.332521
global_step: 530, epoch: 14, loss: 1.249943
global_step: 531, epoch: 14, loss: 1.304007
global_step: 532, epoch: 14, loss: 1.375094
global_step: 533, epoch: 14, loss: 1.260780
global_step: 534, epoch: 14, loss: 1.158662
global_step: 535, epoch: 14, loss: 1.227302
global_step: 536, epoch: 14, loss: 1.250424
global_step: 537, epoch: 14, loss: 1.219569
global_step: 538, epoch: 14, loss: 1.324923
global_step: 539, epoch: 14, loss: 1.302340
global_step: 540, epoch: 14, loss: 1.421515
global_step: 541, epoch: 14, loss: 1.139152
global_step: 542, epoch: 14, loss: 1.318190
global_step: 543, epoch: 14, loss: 1.272831
global_step: 544, epoch: 14, loss: 1.269888
global_step: 545, epoch: 14, loss: 1.276657
global_step: 546, epoch: 14, loss: 1.244046
global_step: 547, epoch: 14, loss: 1.354026
global_step: 548, epoch: 14, loss: 1.301607
global_step: 549, epoch: 14, loss: 1.347949
global_step: 550, epoch: 14, loss: 1.333538
global_step: 551, epoch: 14, loss: 1.335651
global_step: 552, epoch: 14, loss: 1.328858
global_step: 553, epoch: 14, loss: 1.316330
global_step: 554, epoch: 14, loss: 1.321325
global_step: 555, epoch: 14, loss: 1.379364
global_step: 556, epoch: 14, loss: 1.205029
global_step: 557, epoch: 14, loss: 1.263756
global_step: 558, epoch: 14, loss: 1.273593
global_step: 559, epoch: 14, loss: 1.200332
global_step: 560, epoch: 14, loss: 0.638819
epoch: 14
train	acc: 0.5942	macro: p 0.4654, r 0.2852, f1: 0.2837	micro: p 0.5942, r 0.5942, f1 0.5942	weighted_f1:0.5275
dev	acc: 0.5329	macro: p 0.2826, r 0.2707, f1: 0.2519	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4521
test	acc: 0.5847	macro: p 0.2982, r 0.2763, f1: 0.2668	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5137
global_step: 561, epoch: 15, loss: 1.249181
global_step: 562, epoch: 15, loss: 1.258368
global_step: 563, epoch: 15, loss: 1.220735
global_step: 564, epoch: 15, loss: 1.168624
global_step: 565, epoch: 15, loss: 1.238527
global_step: 566, epoch: 15, loss: 1.320314
global_step: 567, epoch: 15, loss: 1.319535
global_step: 568, epoch: 15, loss: 1.233074
global_step: 569, epoch: 15, loss: 1.300797
global_step: 570, epoch: 15, loss: 1.252377
global_step: 571, epoch: 15, loss: 1.319454
global_step: 572, epoch: 15, loss: 1.309584
global_step: 573, epoch: 15, loss: 1.207257
global_step: 574, epoch: 15, loss: 1.250003
global_step: 575, epoch: 15, loss: 1.335104
global_step: 576, epoch: 15, loss: 1.116320
global_step: 577, epoch: 15, loss: 1.303012
global_step: 578, epoch: 15, loss: 1.370875
global_step: 579, epoch: 15, loss: 1.274350
global_step: 580, epoch: 15, loss: 1.338306
global_step: 581, epoch: 15, loss: 1.247202
global_step: 582, epoch: 15, loss: 1.307415
global_step: 583, epoch: 15, loss: 1.235533
global_step: 584, epoch: 15, loss: 1.312291
global_step: 585, epoch: 15, loss: 1.233607
global_step: 586, epoch: 15, loss: 1.282693
global_step: 587, epoch: 15, loss: 1.313042
global_step: 588, epoch: 15, loss: 1.224308
global_step: 589, epoch: 15, loss: 1.254419
global_step: 590, epoch: 15, loss: 1.303771
global_step: 591, epoch: 15, loss: 1.200032
global_step: 592, epoch: 15, loss: 1.215440
global_step: 593, epoch: 15, loss: 1.316041
global_step: 594, epoch: 15, loss: 1.285997
global_step: 595, epoch: 15, loss: 1.305017
global_step: 596, epoch: 15, loss: 1.233900
global_step: 597, epoch: 15, loss: 1.373682
global_step: 598, epoch: 15, loss: 1.289026
global_step: 599, epoch: 15, loss: 1.237622
global_step: 600, epoch: 15, loss: 0.937037
epoch: 15
train	acc: 0.6011	macro: p 0.4410, r 0.2977, f1: 0.2978	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5392
dev	acc: 0.5338	macro: p 0.2784, r 0.2746, f1: 0.2602	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4596
test	acc: 0.5889	macro: p 0.3000, r 0.2834, f1: 0.2775	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5238
New best model!
global_step: 601, epoch: 16, loss: 1.215179
global_step: 602, epoch: 16, loss: 1.257675
global_step: 603, epoch: 16, loss: 1.322931
global_step: 604, epoch: 16, loss: 1.192258
global_step: 605, epoch: 16, loss: 1.255890
global_step: 606, epoch: 16, loss: 1.329839
global_step: 607, epoch: 16, loss: 1.207143
global_step: 608, epoch: 16, loss: 1.269140
global_step: 609, epoch: 16, loss: 1.298059
global_step: 610, epoch: 16, loss: 1.291382
global_step: 611, epoch: 16, loss: 1.285421
global_step: 612, epoch: 16, loss: 1.353916
global_step: 613, epoch: 16, loss: 1.248610
global_step: 614, epoch: 16, loss: 1.279507
global_step: 615, epoch: 16, loss: 1.171649
global_step: 616, epoch: 16, loss: 1.309276
global_step: 617, epoch: 16, loss: 1.166628
global_step: 618, epoch: 16, loss: 1.266288
global_step: 619, epoch: 16, loss: 1.229487
global_step: 620, epoch: 16, loss: 1.382999
global_step: 621, epoch: 16, loss: 1.151335
global_step: 622, epoch: 16, loss: 1.308080
global_step: 623, epoch: 16, loss: 1.240813
global_step: 624, epoch: 16, loss: 1.336527
global_step: 625, epoch: 16, loss: 1.209138
global_step: 626, epoch: 16, loss: 1.284212
global_step: 627, epoch: 16, loss: 1.345385
global_step: 628, epoch: 16, loss: 1.203139
global_step: 629, epoch: 16, loss: 1.302926
global_step: 630, epoch: 16, loss: 1.251763
global_step: 631, epoch: 16, loss: 1.278170
global_step: 632, epoch: 16, loss: 1.300902
global_step: 633, epoch: 16, loss: 1.328440
global_step: 634, epoch: 16, loss: 1.189993
global_step: 635, epoch: 16, loss: 1.284269
global_step: 636, epoch: 16, loss: 1.167614
global_step: 637, epoch: 16, loss: 1.407540
global_step: 638, epoch: 16, loss: 1.127441
global_step: 639, epoch: 16, loss: 1.281203
global_step: 640, epoch: 16, loss: 1.139996
epoch: 16
train	acc: 0.5977	macro: p 0.4140, r 0.3003, f1: 0.3006	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5390
dev	acc: 0.5437	macro: p 0.3543, r 0.2850, f1: 0.2748	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4740
test	acc: 0.5904	macro: p 0.3902, r 0.2886, f1: 0.2859	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5298
New best model!
global_step: 641, epoch: 17, loss: 1.174556
global_step: 642, epoch: 17, loss: 1.333128
global_step: 643, epoch: 17, loss: 1.253327
global_step: 644, epoch: 17, loss: 1.347248
global_step: 645, epoch: 17, loss: 1.199378
global_step: 646, epoch: 17, loss: 1.218454
global_step: 647, epoch: 17, loss: 1.247028
global_step: 648, epoch: 17, loss: 1.240032
global_step: 649, epoch: 17, loss: 1.284638
global_step: 650, epoch: 17, loss: 1.203723
global_step: 651, epoch: 17, loss: 1.247913
global_step: 652, epoch: 17, loss: 1.331652
global_step: 653, epoch: 17, loss: 1.270506
global_step: 654, epoch: 17, loss: 1.208249
global_step: 655, epoch: 17, loss: 1.159735
global_step: 656, epoch: 17, loss: 1.321333
global_step: 657, epoch: 17, loss: 1.307919
global_step: 658, epoch: 17, loss: 1.259275
global_step: 659, epoch: 17, loss: 1.232742
global_step: 660, epoch: 17, loss: 1.251936
global_step: 661, epoch: 17, loss: 1.296482
global_step: 662, epoch: 17, loss: 1.198961
global_step: 663, epoch: 17, loss: 1.144171
global_step: 664, epoch: 17, loss: 1.375857
global_step: 665, epoch: 17, loss: 1.270944
global_step: 666, epoch: 17, loss: 1.225094
global_step: 667, epoch: 17, loss: 1.286348
global_step: 668, epoch: 17, loss: 1.247630
global_step: 669, epoch: 17, loss: 1.122364
global_step: 670, epoch: 17, loss: 1.340165
global_step: 671, epoch: 17, loss: 1.250733
global_step: 672, epoch: 17, loss: 1.073901
global_step: 673, epoch: 17, loss: 1.340836
global_step: 674, epoch: 17, loss: 1.249913
global_step: 675, epoch: 17, loss: 1.245632
global_step: 676, epoch: 17, loss: 1.281363
global_step: 677, epoch: 17, loss: 1.186883
global_step: 678, epoch: 17, loss: 1.243461
global_step: 679, epoch: 17, loss: 1.226824
global_step: 680, epoch: 17, loss: 0.956423
epoch: 17
train	acc: 0.6008	macro: p 0.4188, r 0.3043, f1: 0.3055	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5432
dev	acc: 0.5410	macro: p 0.3470, r 0.2829, f1: 0.2718	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4710
test	acc: 0.5881	macro: p 0.3835, r 0.2870, f1: 0.2832	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5273
global_step: 681, epoch: 18, loss: 1.217853
global_step: 682, epoch: 18, loss: 1.169155
global_step: 683, epoch: 18, loss: 1.206931
global_step: 684, epoch: 18, loss: 1.255195
global_step: 685, epoch: 18, loss: 1.182034
global_step: 686, epoch: 18, loss: 1.163493
global_step: 687, epoch: 18, loss: 1.253407
global_step: 688, epoch: 18, loss: 1.279464
global_step: 689, epoch: 18, loss: 1.250579
global_step: 690, epoch: 18, loss: 1.212263
global_step: 691, epoch: 18, loss: 1.231402
global_step: 692, epoch: 18, loss: 1.228647
global_step: 693, epoch: 18, loss: 1.253831
global_step: 694, epoch: 18, loss: 1.304707
global_step: 695, epoch: 18, loss: 1.317684
global_step: 696, epoch: 18, loss: 1.238281
global_step: 697, epoch: 18, loss: 1.302041
global_step: 698, epoch: 18, loss: 1.169540
global_step: 699, epoch: 18, loss: 1.149140
global_step: 700, epoch: 18, loss: 1.184915
global_step: 701, epoch: 18, loss: 1.197343
global_step: 702, epoch: 18, loss: 1.448575
global_step: 703, epoch: 18, loss: 1.137882
global_step: 704, epoch: 18, loss: 1.243229
global_step: 705, epoch: 18, loss: 1.290585
global_step: 706, epoch: 18, loss: 1.209617
global_step: 707, epoch: 18, loss: 1.215328
global_step: 708, epoch: 18, loss: 1.323130
global_step: 709, epoch: 18, loss: 1.337315
global_step: 710, epoch: 18, loss: 1.268189
global_step: 711, epoch: 18, loss: 1.183771
global_step: 712, epoch: 18, loss: 1.284633
global_step: 713, epoch: 18, loss: 1.197098
global_step: 714, epoch: 18, loss: 1.307718
global_step: 715, epoch: 18, loss: 1.205228
global_step: 716, epoch: 18, loss: 1.399330
global_step: 717, epoch: 18, loss: 1.334774
global_step: 718, epoch: 18, loss: 1.240398
global_step: 719, epoch: 18, loss: 1.173136
global_step: 720, epoch: 18, loss: 0.952545
epoch: 18
train	acc: 0.6091	macro: p 0.4237, r 0.3104, f1: 0.3149	micro: p 0.6091, r 0.6091, f1 0.6091	weighted_f1:0.5526
dev	acc: 0.5401	macro: p 0.3624, r 0.2847, f1: 0.2703	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4685
test	acc: 0.5839	macro: p 0.3815, r 0.2839, f1: 0.2762	micro: p 0.5839, r 0.5839, f1 0.5839	weighted_f1:0.5196
global_step: 721, epoch: 19, loss: 1.297318
global_step: 722, epoch: 19, loss: 1.323947
global_step: 723, epoch: 19, loss: 1.324157
global_step: 724, epoch: 19, loss: 1.324924
global_step: 725, epoch: 19, loss: 1.228209
global_step: 726, epoch: 19, loss: 1.226892
global_step: 727, epoch: 19, loss: 1.221768
global_step: 728, epoch: 19, loss: 1.179161
global_step: 729, epoch: 19, loss: 1.202108
global_step: 730, epoch: 19, loss: 1.133123
global_step: 731, epoch: 19, loss: 1.207275
global_step: 732, epoch: 19, loss: 1.342281
global_step: 733, epoch: 19, loss: 1.238258
global_step: 734, epoch: 19, loss: 1.259636
global_step: 735, epoch: 19, loss: 1.383775
global_step: 736, epoch: 19, loss: 1.238550
global_step: 737, epoch: 19, loss: 1.192271
global_step: 738, epoch: 19, loss: 1.114436
global_step: 739, epoch: 19, loss: 1.259672
global_step: 740, epoch: 19, loss: 1.083938
global_step: 741, epoch: 19, loss: 1.152739
global_step: 742, epoch: 19, loss: 1.211763
global_step: 743, epoch: 19, loss: 1.256749
global_step: 744, epoch: 19, loss: 1.262994
global_step: 745, epoch: 19, loss: 1.228777
global_step: 746, epoch: 19, loss: 1.342185
global_step: 747, epoch: 19, loss: 1.199272
global_step: 748, epoch: 19, loss: 1.239474
global_step: 749, epoch: 19, loss: 1.157706
global_step: 750, epoch: 19, loss: 1.272959
global_step: 751, epoch: 19, loss: 1.305990
global_step: 752, epoch: 19, loss: 1.308649
global_step: 753, epoch: 19, loss: 1.184417
global_step: 754, epoch: 19, loss: 1.320121
global_step: 755, epoch: 19, loss: 1.242921
global_step: 756, epoch: 19, loss: 1.193226
global_step: 757, epoch: 19, loss: 1.247663
global_step: 758, epoch: 19, loss: 1.169715
global_step: 759, epoch: 19, loss: 1.195032
global_step: 760, epoch: 19, loss: 1.596623
epoch: 19
train	acc: 0.6069	macro: p 0.4266, r 0.3065, f1: 0.3122	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5497
dev	acc: 0.5365	macro: p 0.3517, r 0.2798, f1: 0.2632	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4620
test	acc: 0.5881	macro: p 0.4019, r 0.2882, f1: 0.2831	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5248
global_step: 761, epoch: 20, loss: 1.283728
global_step: 762, epoch: 20, loss: 1.210438
global_step: 763, epoch: 20, loss: 1.326160
global_step: 764, epoch: 20, loss: 1.169230
global_step: 765, epoch: 20, loss: 1.142280
global_step: 766, epoch: 20, loss: 1.223496
global_step: 767, epoch: 20, loss: 1.214380
global_step: 768, epoch: 20, loss: 1.276249
global_step: 769, epoch: 20, loss: 1.149031
global_step: 770, epoch: 20, loss: 1.263003
global_step: 771, epoch: 20, loss: 1.285446
global_step: 772, epoch: 20, loss: 1.223610
global_step: 773, epoch: 20, loss: 1.269861
global_step: 774, epoch: 20, loss: 1.200435
global_step: 775, epoch: 20, loss: 1.204535
global_step: 776, epoch: 20, loss: 1.166531
global_step: 777, epoch: 20, loss: 1.201560
global_step: 778, epoch: 20, loss: 1.244388
global_step: 779, epoch: 20, loss: 1.146182
global_step: 780, epoch: 20, loss: 1.283372
global_step: 781, epoch: 20, loss: 1.331738
global_step: 782, epoch: 20, loss: 1.269051
global_step: 783, epoch: 20, loss: 1.231345
global_step: 784, epoch: 20, loss: 1.272618
global_step: 785, epoch: 20, loss: 1.217875
global_step: 786, epoch: 20, loss: 1.187967
global_step: 787, epoch: 20, loss: 1.235453
global_step: 788, epoch: 20, loss: 1.210926
global_step: 789, epoch: 20, loss: 1.130845
global_step: 790, epoch: 20, loss: 1.216314
global_step: 791, epoch: 20, loss: 1.141284
global_step: 792, epoch: 20, loss: 1.263850
global_step: 793, epoch: 20, loss: 1.307008
global_step: 794, epoch: 20, loss: 1.345653
global_step: 795, epoch: 20, loss: 1.331810
global_step: 796, epoch: 20, loss: 1.239058
global_step: 797, epoch: 20, loss: 1.226416
global_step: 798, epoch: 20, loss: 1.299702
global_step: 799, epoch: 20, loss: 1.201519
global_step: 800, epoch: 20, loss: 0.820795
epoch: 20
train	acc: 0.6115	macro: p 0.4316, r 0.3119, f1: 0.3179	micro: p 0.6115, r 0.6115, f1 0.6115	weighted_f1:0.5549
dev	acc: 0.5401	macro: p 0.3630, r 0.2832, f1: 0.2682	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4663
test	acc: 0.5862	macro: p 0.3781, r 0.2853, f1: 0.2791	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5224
global_step: 801, epoch: 21, loss: 1.146196
global_step: 802, epoch: 21, loss: 1.195587
global_step: 803, epoch: 21, loss: 1.273017
global_step: 804, epoch: 21, loss: 1.192533
global_step: 805, epoch: 21, loss: 1.145784
global_step: 806, epoch: 21, loss: 1.337561
global_step: 807, epoch: 21, loss: 1.324320
global_step: 808, epoch: 21, loss: 1.248298
global_step: 809, epoch: 21, loss: 1.195303
global_step: 810, epoch: 21, loss: 1.281541
global_step: 811, epoch: 21, loss: 1.228863
global_step: 812, epoch: 21, loss: 1.208505
global_step: 813, epoch: 21, loss: 1.238405
global_step: 814, epoch: 21, loss: 1.114352
global_step: 815, epoch: 21, loss: 1.185233
global_step: 816, epoch: 21, loss: 1.247648
global_step: 817, epoch: 21, loss: 1.244375
global_step: 818, epoch: 21, loss: 1.246552
global_step: 819, epoch: 21, loss: 1.233210
global_step: 820, epoch: 21, loss: 1.261967
global_step: 821, epoch: 21, loss: 1.235053
global_step: 822, epoch: 21, loss: 1.211878
global_step: 823, epoch: 21, loss: 1.200475
global_step: 824, epoch: 21, loss: 1.096018
global_step: 825, epoch: 21, loss: 1.231697
global_step: 826, epoch: 21, loss: 1.269660
global_step: 827, epoch: 21, loss: 1.196588
global_step: 828, epoch: 21, loss: 1.182300
global_step: 829, epoch: 21, loss: 1.242146
global_step: 830, epoch: 21, loss: 1.241620
global_step: 831, epoch: 21, loss: 1.341756
global_step: 832, epoch: 21, loss: 1.143241
global_step: 833, epoch: 21, loss: 1.202957
global_step: 834, epoch: 21, loss: 1.304427
global_step: 835, epoch: 21, loss: 1.198103
global_step: 836, epoch: 21, loss: 1.163824
global_step: 837, epoch: 21, loss: 1.275002
global_step: 838, epoch: 21, loss: 1.082935
global_step: 839, epoch: 21, loss: 1.253360
global_step: 840, epoch: 21, loss: 1.461051
epoch: 21
train	acc: 0.6187	macro: p 0.4133, r 0.3282, f1: 0.3353	micro: p 0.6187, r 0.6187, f1 0.6187	weighted_f1:0.5690
dev	acc: 0.5437	macro: p 0.3528, r 0.2910, f1: 0.2833	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4802
test	acc: 0.5973	macro: p 0.3792, r 0.3035, f1: 0.3044	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5436
New best model!
global_step: 841, epoch: 22, loss: 1.248769
global_step: 842, epoch: 22, loss: 1.261898
global_step: 843, epoch: 22, loss: 1.302954
global_step: 844, epoch: 22, loss: 1.169752
global_step: 845, epoch: 22, loss: 1.298525
global_step: 846, epoch: 22, loss: 1.183568
global_step: 847, epoch: 22, loss: 1.183885
global_step: 848, epoch: 22, loss: 1.195356
global_step: 849, epoch: 22, loss: 1.333599
global_step: 850, epoch: 22, loss: 1.200302
global_step: 851, epoch: 22, loss: 1.251050
global_step: 852, epoch: 22, loss: 1.198225
global_step: 853, epoch: 22, loss: 1.227572
global_step: 854, epoch: 22, loss: 1.308210
global_step: 855, epoch: 22, loss: 1.288113
global_step: 856, epoch: 22, loss: 1.124504
global_step: 857, epoch: 22, loss: 1.211638
global_step: 858, epoch: 22, loss: 1.169254
global_step: 859, epoch: 22, loss: 1.156976
global_step: 860, epoch: 22, loss: 1.188135
global_step: 861, epoch: 22, loss: 1.157643
global_step: 862, epoch: 22, loss: 1.315830
global_step: 863, epoch: 22, loss: 1.253123
global_step: 864, epoch: 22, loss: 1.160466
global_step: 865, epoch: 22, loss: 1.180653
global_step: 866, epoch: 22, loss: 1.215664
global_step: 867, epoch: 22, loss: 1.263732
global_step: 868, epoch: 22, loss: 1.122444
global_step: 869, epoch: 22, loss: 1.274463
global_step: 870, epoch: 22, loss: 1.234855
global_step: 871, epoch: 22, loss: 1.110157
global_step: 872, epoch: 22, loss: 1.221068
global_step: 873, epoch: 22, loss: 1.293193
global_step: 874, epoch: 22, loss: 1.252245
global_step: 875, epoch: 22, loss: 1.165762
global_step: 876, epoch: 22, loss: 1.132025
global_step: 877, epoch: 22, loss: 1.095242
global_step: 878, epoch: 22, loss: 1.173068
global_step: 879, epoch: 22, loss: 1.240036
global_step: 880, epoch: 22, loss: 1.649726
epoch: 22
train	acc: 0.6193	macro: p 0.4277, r 0.3254, f1: 0.3324	micro: p 0.6193, r 0.6193, f1 0.6193	weighted_f1:0.5673
dev	acc: 0.5446	macro: p 0.3546, r 0.2896, f1: 0.2807	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4785
test	acc: 0.5973	macro: p 0.3921, r 0.3002, f1: 0.3014	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5414
global_step: 881, epoch: 23, loss: 1.220919
global_step: 882, epoch: 23, loss: 1.341144
global_step: 883, epoch: 23, loss: 1.172863
global_step: 884, epoch: 23, loss: 1.325086
global_step: 885, epoch: 23, loss: 1.194342
global_step: 886, epoch: 23, loss: 1.235807
global_step: 887, epoch: 23, loss: 1.136272
global_step: 888, epoch: 23, loss: 1.194315
global_step: 889, epoch: 23, loss: 1.217503
global_step: 890, epoch: 23, loss: 1.127653
global_step: 891, epoch: 23, loss: 1.212275
global_step: 892, epoch: 23, loss: 1.264837
global_step: 893, epoch: 23, loss: 1.155849
global_step: 894, epoch: 23, loss: 1.268914
global_step: 895, epoch: 23, loss: 1.309782
global_step: 896, epoch: 23, loss: 1.172858
global_step: 897, epoch: 23, loss: 1.176833
global_step: 898, epoch: 23, loss: 1.184014
global_step: 899, epoch: 23, loss: 1.206162
global_step: 900, epoch: 23, loss: 1.291717
global_step: 901, epoch: 23, loss: 1.260026
global_step: 902, epoch: 23, loss: 1.186957
global_step: 903, epoch: 23, loss: 1.176299
global_step: 904, epoch: 23, loss: 1.205347
global_step: 905, epoch: 23, loss: 1.165793
global_step: 906, epoch: 23, loss: 1.185110
global_step: 907, epoch: 23, loss: 1.156737
global_step: 908, epoch: 23, loss: 1.225901
global_step: 909, epoch: 23, loss: 1.227526
global_step: 910, epoch: 23, loss: 1.021160
global_step: 911, epoch: 23, loss: 1.307926
global_step: 912, epoch: 23, loss: 1.276685
global_step: 913, epoch: 23, loss: 1.214816
global_step: 914, epoch: 23, loss: 1.227926
global_step: 915, epoch: 23, loss: 1.106817
global_step: 916, epoch: 23, loss: 1.158931
global_step: 917, epoch: 23, loss: 1.235014
global_step: 918, epoch: 23, loss: 1.206718
global_step: 919, epoch: 23, loss: 1.148282
global_step: 920, epoch: 23, loss: 0.764557
epoch: 23
train	acc: 0.6136	macro: p 0.4395, r 0.3132, f1: 0.3221	micro: p 0.6136, r 0.6136, f1 0.6136	weighted_f1:0.5576
dev	acc: 0.5428	macro: p 0.3723, r 0.2845, f1: 0.2697	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4686
test	acc: 0.5885	macro: p 0.3920, r 0.2870, f1: 0.2834	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5253
global_step: 921, epoch: 24, loss: 1.222422
global_step: 922, epoch: 24, loss: 1.170410
global_step: 923, epoch: 24, loss: 1.219717
global_step: 924, epoch: 24, loss: 1.049817
global_step: 925, epoch: 24, loss: 1.121424
global_step: 926, epoch: 24, loss: 1.252384
global_step: 927, epoch: 24, loss: 1.310947
global_step: 928, epoch: 24, loss: 1.186537
global_step: 929, epoch: 24, loss: 1.181115
global_step: 930, epoch: 24, loss: 1.186655
global_step: 931, epoch: 24, loss: 1.264330
global_step: 932, epoch: 24, loss: 1.209381
global_step: 933, epoch: 24, loss: 1.283701
global_step: 934, epoch: 24, loss: 1.188943
global_step: 935, epoch: 24, loss: 1.141632
global_step: 936, epoch: 24, loss: 1.131783
global_step: 937, epoch: 24, loss: 1.235880
global_step: 938, epoch: 24, loss: 1.220523
global_step: 939, epoch: 24, loss: 1.285514
global_step: 940, epoch: 24, loss: 1.208443
global_step: 941, epoch: 24, loss: 1.323242
global_step: 942, epoch: 24, loss: 1.234851
global_step: 943, epoch: 24, loss: 1.192346
global_step: 944, epoch: 24, loss: 1.248763
global_step: 945, epoch: 24, loss: 1.237791
global_step: 946, epoch: 24, loss: 1.181116
global_step: 947, epoch: 24, loss: 1.163883
global_step: 948, epoch: 24, loss: 1.182126
global_step: 949, epoch: 24, loss: 1.214058
global_step: 950, epoch: 24, loss: 1.291514
global_step: 951, epoch: 24, loss: 1.225277
global_step: 952, epoch: 24, loss: 1.028128
global_step: 953, epoch: 24, loss: 1.153649
global_step: 954, epoch: 24, loss: 1.173586
global_step: 955, epoch: 24, loss: 1.221554
global_step: 956, epoch: 24, loss: 1.102999
global_step: 957, epoch: 24, loss: 1.209682
global_step: 958, epoch: 24, loss: 1.199030
global_step: 959, epoch: 24, loss: 1.157277
global_step: 960, epoch: 24, loss: 3.139652
epoch: 24
train	acc: 0.6258	macro: p 0.4313, r 0.3336, f1: 0.3445	micro: p 0.6258, r 0.6258, f1 0.6258	weighted_f1:0.5765
dev	acc: 0.5455	macro: p 0.3573, r 0.2912, f1: 0.2818	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4791
test	acc: 0.5946	macro: p 0.3845, r 0.2984, f1: 0.2988	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5381
global_step: 961, epoch: 25, loss: 1.332543
global_step: 962, epoch: 25, loss: 1.239509
global_step: 963, epoch: 25, loss: 1.121076
global_step: 964, epoch: 25, loss: 1.157800
global_step: 965, epoch: 25, loss: 1.138973
global_step: 966, epoch: 25, loss: 1.091092
global_step: 967, epoch: 25, loss: 1.147129
global_step: 968, epoch: 25, loss: 1.173542
global_step: 969, epoch: 25, loss: 1.188523
global_step: 970, epoch: 25, loss: 1.191456
global_step: 971, epoch: 25, loss: 1.189440
global_step: 972, epoch: 25, loss: 1.119403
global_step: 973, epoch: 25, loss: 1.262008
global_step: 974, epoch: 25, loss: 1.250838
global_step: 975, epoch: 25, loss: 1.183040
global_step: 976, epoch: 25, loss: 1.154005
global_step: 977, epoch: 25, loss: 1.152799
global_step: 978, epoch: 25, loss: 1.144831
global_step: 979, epoch: 25, loss: 1.167776
global_step: 980, epoch: 25, loss: 1.080063
global_step: 981, epoch: 25, loss: 1.235176
global_step: 982, epoch: 25, loss: 1.218911
global_step: 983, epoch: 25, loss: 1.252994
global_step: 984, epoch: 25, loss: 1.192129
global_step: 985, epoch: 25, loss: 1.213066
global_step: 986, epoch: 25, loss: 1.204047
global_step: 987, epoch: 25, loss: 1.205808
global_step: 988, epoch: 25, loss: 1.145360
global_step: 989, epoch: 25, loss: 1.186211
global_step: 990, epoch: 25, loss: 1.224883
global_step: 991, epoch: 25, loss: 1.331094
global_step: 992, epoch: 25, loss: 1.146833
global_step: 993, epoch: 25, loss: 1.249533
global_step: 994, epoch: 25, loss: 1.102153
global_step: 995, epoch: 25, loss: 1.088353
global_step: 996, epoch: 25, loss: 1.242749
global_step: 997, epoch: 25, loss: 1.240075
global_step: 998, epoch: 25, loss: 1.224932
global_step: 999, epoch: 25, loss: 1.160439
global_step: 1000, epoch: 25, loss: 0.790260
epoch: 25
train	acc: 0.6253	macro: p 0.4342, r 0.3316, f1: 0.3405	micro: p 0.6253, r 0.6253, f1 0.6253	weighted_f1:0.5744
dev	acc: 0.5491	macro: p 0.3693, r 0.2932, f1: 0.2858	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4836
test	acc: 0.5958	macro: p 0.3971, r 0.2981, f1: 0.3000	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5397
New best model!
global_step: 1001, epoch: 26, loss: 1.296945
global_step: 1002, epoch: 26, loss: 1.152429
global_step: 1003, epoch: 26, loss: 1.178755
global_step: 1004, epoch: 26, loss: 1.184751
global_step: 1005, epoch: 26, loss: 1.126859
global_step: 1006, epoch: 26, loss: 1.136640
global_step: 1007, epoch: 26, loss: 1.248075
global_step: 1008, epoch: 26, loss: 1.275182
global_step: 1009, epoch: 26, loss: 1.218662
global_step: 1010, epoch: 26, loss: 1.171268
global_step: 1011, epoch: 26, loss: 1.239681
global_step: 1012, epoch: 26, loss: 1.294755
global_step: 1013, epoch: 26, loss: 1.115046
global_step: 1014, epoch: 26, loss: 1.175241
global_step: 1015, epoch: 26, loss: 1.099404
global_step: 1016, epoch: 26, loss: 1.227794
global_step: 1017, epoch: 26, loss: 1.199566
global_step: 1018, epoch: 26, loss: 1.184655
global_step: 1019, epoch: 26, loss: 1.127144
global_step: 1020, epoch: 26, loss: 1.184032
global_step: 1021, epoch: 26, loss: 1.369693
global_step: 1022, epoch: 26, loss: 1.137271
global_step: 1023, epoch: 26, loss: 1.215859
global_step: 1024, epoch: 26, loss: 1.132930
global_step: 1025, epoch: 26, loss: 1.200053
global_step: 1026, epoch: 26, loss: 1.178557
global_step: 1027, epoch: 26, loss: 1.137594
global_step: 1028, epoch: 26, loss: 1.159312
global_step: 1029, epoch: 26, loss: 1.102189
global_step: 1030, epoch: 26, loss: 1.095155
global_step: 1031, epoch: 26, loss: 1.207484
global_step: 1032, epoch: 26, loss: 1.209391
global_step: 1033, epoch: 26, loss: 1.151816
global_step: 1034, epoch: 26, loss: 1.161473
global_step: 1035, epoch: 26, loss: 1.203331
global_step: 1036, epoch: 26, loss: 1.141722
global_step: 1037, epoch: 26, loss: 1.174886
global_step: 1038, epoch: 26, loss: 1.306843
global_step: 1039, epoch: 26, loss: 1.202184
global_step: 1040, epoch: 26, loss: 0.855452
epoch: 26
train	acc: 0.6252	macro: p 0.4427, r 0.3292, f1: 0.3397	micro: p 0.6252, r 0.6252, f1 0.6252	weighted_f1:0.5737
dev	acc: 0.5437	macro: p 0.3668, r 0.2877, f1: 0.2757	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4736
test	acc: 0.5908	macro: p 0.3934, r 0.2917, f1: 0.2910	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5315
global_step: 1041, epoch: 27, loss: 1.129075
global_step: 1042, epoch: 27, loss: 1.277486
global_step: 1043, epoch: 27, loss: 1.052995
global_step: 1044, epoch: 27, loss: 1.140427
global_step: 1045, epoch: 27, loss: 1.167104
global_step: 1046, epoch: 27, loss: 1.244157
global_step: 1047, epoch: 27, loss: 1.190775
global_step: 1048, epoch: 27, loss: 1.096420
global_step: 1049, epoch: 27, loss: 1.184731
global_step: 1050, epoch: 27, loss: 1.133610
global_step: 1051, epoch: 27, loss: 1.228170
global_step: 1052, epoch: 27, loss: 1.216655
global_step: 1053, epoch: 27, loss: 1.164023
global_step: 1054, epoch: 27, loss: 1.169267
global_step: 1055, epoch: 27, loss: 1.112294
global_step: 1056, epoch: 27, loss: 1.195438
global_step: 1057, epoch: 27, loss: 1.284784
global_step: 1058, epoch: 27, loss: 1.233734
global_step: 1059, epoch: 27, loss: 1.139680
global_step: 1060, epoch: 27, loss: 1.235974
global_step: 1061, epoch: 27, loss: 1.272880
global_step: 1062, epoch: 27, loss: 1.137428
global_step: 1063, epoch: 27, loss: 1.229332
global_step: 1064, epoch: 27, loss: 1.187845
global_step: 1065, epoch: 27, loss: 1.269756
global_step: 1066, epoch: 27, loss: 1.204286
global_step: 1067, epoch: 27, loss: 1.138293
global_step: 1068, epoch: 27, loss: 1.193799
global_step: 1069, epoch: 27, loss: 1.248381
global_step: 1070, epoch: 27, loss: 1.088706
global_step: 1071, epoch: 27, loss: 1.125443
global_step: 1072, epoch: 27, loss: 1.274269
global_step: 1073, epoch: 27, loss: 1.125637
global_step: 1074, epoch: 27, loss: 1.164506
global_step: 1075, epoch: 27, loss: 1.067631
global_step: 1076, epoch: 27, loss: 1.098191
global_step: 1077, epoch: 27, loss: 1.147385
global_step: 1078, epoch: 27, loss: 1.153349
global_step: 1079, epoch: 27, loss: 1.128590
global_step: 1080, epoch: 27, loss: 1.070112
epoch: 27
train	acc: 0.6258	macro: p 0.4416, r 0.3294, f1: 0.3382	micro: p 0.6258, r 0.6258, f1 0.6258	weighted_f1:0.5739
dev	acc: 0.5473	macro: p 0.3774, r 0.2924, f1: 0.2753	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4739
test	acc: 0.5912	macro: p 0.3833, r 0.2947, f1: 0.2875	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5285
global_step: 1081, epoch: 28, loss: 1.083764
global_step: 1082, epoch: 28, loss: 1.068668
global_step: 1083, epoch: 28, loss: 1.194002
global_step: 1084, epoch: 28, loss: 1.240717
global_step: 1085, epoch: 28, loss: 1.057188
global_step: 1086, epoch: 28, loss: 1.187575
global_step: 1087, epoch: 28, loss: 1.090658
global_step: 1088, epoch: 28, loss: 1.208634
global_step: 1089, epoch: 28, loss: 1.225452
global_step: 1090, epoch: 28, loss: 1.282577
global_step: 1091, epoch: 28, loss: 1.080257
global_step: 1092, epoch: 28, loss: 1.158864
global_step: 1093, epoch: 28, loss: 1.165814
global_step: 1094, epoch: 28, loss: 1.166389
global_step: 1095, epoch: 28, loss: 1.165370
global_step: 1096, epoch: 28, loss: 1.151579
global_step: 1097, epoch: 28, loss: 1.103035
global_step: 1098, epoch: 28, loss: 1.059980
global_step: 1099, epoch: 28, loss: 1.179080
global_step: 1100, epoch: 28, loss: 1.139839
global_step: 1101, epoch: 28, loss: 1.047141
global_step: 1102, epoch: 28, loss: 1.251529
global_step: 1103, epoch: 28, loss: 1.168221
global_step: 1104, epoch: 28, loss: 1.097624
global_step: 1105, epoch: 28, loss: 1.169779
global_step: 1106, epoch: 28, loss: 1.258283
global_step: 1107, epoch: 28, loss: 1.101224
global_step: 1108, epoch: 28, loss: 1.182118
global_step: 1109, epoch: 28, loss: 1.152919
global_step: 1110, epoch: 28, loss: 1.233648
global_step: 1111, epoch: 28, loss: 1.198976
global_step: 1112, epoch: 28, loss: 1.294984
global_step: 1113, epoch: 28, loss: 1.252855
global_step: 1114, epoch: 28, loss: 1.103365
global_step: 1115, epoch: 28, loss: 1.223401
global_step: 1116, epoch: 28, loss: 1.144368
global_step: 1117, epoch: 28, loss: 1.205167
global_step: 1118, epoch: 28, loss: 1.238655
global_step: 1119, epoch: 28, loss: 1.141908
global_step: 1120, epoch: 28, loss: 0.983695
epoch: 28
train	acc: 0.6399	macro: p 0.4362, r 0.3544, f1: 0.3651	micro: p 0.6399, r 0.6399, f1 0.6399	weighted_f1:0.5955
dev	acc: 0.5528	macro: p 0.3713, r 0.3004, f1: 0.2949	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4917
test	acc: 0.6008	macro: p 0.3761, r 0.3100, f1: 0.3128	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5499
New best model!
global_step: 1121, epoch: 29, loss: 1.126992
global_step: 1122, epoch: 29, loss: 1.154482
global_step: 1123, epoch: 29, loss: 1.225851
global_step: 1124, epoch: 29, loss: 1.100108
global_step: 1125, epoch: 29, loss: 1.150562
global_step: 1126, epoch: 29, loss: 1.126672
global_step: 1127, epoch: 29, loss: 1.019539
global_step: 1128, epoch: 29, loss: 1.285496
global_step: 1129, epoch: 29, loss: 1.066285
global_step: 1130, epoch: 29, loss: 1.056639
global_step: 1131, epoch: 29, loss: 1.191600
global_step: 1132, epoch: 29, loss: 1.150846
global_step: 1133, epoch: 29, loss: 1.152112
global_step: 1134, epoch: 29, loss: 1.184724
global_step: 1135, epoch: 29, loss: 1.133800
global_step: 1136, epoch: 29, loss: 1.082014
global_step: 1137, epoch: 29, loss: 1.254790
global_step: 1138, epoch: 29, loss: 1.149049
global_step: 1139, epoch: 29, loss: 1.182056
global_step: 1140, epoch: 29, loss: 1.212363
global_step: 1141, epoch: 29, loss: 1.102289
global_step: 1142, epoch: 29, loss: 1.083768
global_step: 1143, epoch: 29, loss: 1.100042
global_step: 1144, epoch: 29, loss: 1.121992
global_step: 1145, epoch: 29, loss: 1.230677
global_step: 1146, epoch: 29, loss: 1.152204
global_step: 1147, epoch: 29, loss: 1.227765
global_step: 1148, epoch: 29, loss: 1.100058
global_step: 1149, epoch: 29, loss: 1.290821
global_step: 1150, epoch: 29, loss: 1.169611
global_step: 1151, epoch: 29, loss: 1.280272
global_step: 1152, epoch: 29, loss: 1.148573
global_step: 1153, epoch: 29, loss: 1.135000
global_step: 1154, epoch: 29, loss: 1.241339
global_step: 1155, epoch: 29, loss: 1.090314
global_step: 1156, epoch: 29, loss: 1.167959
global_step: 1157, epoch: 29, loss: 1.180181
global_step: 1158, epoch: 29, loss: 1.134579
global_step: 1159, epoch: 29, loss: 1.148214
global_step: 1160, epoch: 29, loss: 0.985197
epoch: 29
train	acc: 0.6395	macro: p 0.4406, r 0.3494, f1: 0.3623	micro: p 0.6395, r 0.6395, f1 0.6395	weighted_f1:0.5935
dev	acc: 0.5491	macro: p 0.3557, r 0.2954, f1: 0.2858	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4837
test	acc: 0.5989	macro: p 0.3683, r 0.3044, f1: 0.3054	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5443
global_step: 1161, epoch: 30, loss: 1.208291
global_step: 1162, epoch: 30, loss: 1.233834
global_step: 1163, epoch: 30, loss: 1.151127
global_step: 1164, epoch: 30, loss: 1.143117
global_step: 1165, epoch: 30, loss: 1.170524
global_step: 1166, epoch: 30, loss: 1.095843
global_step: 1167, epoch: 30, loss: 1.029749
global_step: 1168, epoch: 30, loss: 1.150725
global_step: 1169, epoch: 30, loss: 1.187619
global_step: 1170, epoch: 30, loss: 1.212060
global_step: 1171, epoch: 30, loss: 1.211047
global_step: 1172, epoch: 30, loss: 1.231642
global_step: 1173, epoch: 30, loss: 1.258286
global_step: 1174, epoch: 30, loss: 1.109804
global_step: 1175, epoch: 30, loss: 1.167047
global_step: 1176, epoch: 30, loss: 1.176900
global_step: 1177, epoch: 30, loss: 1.038056
global_step: 1178, epoch: 30, loss: 1.143478
global_step: 1179, epoch: 30, loss: 1.180056
global_step: 1180, epoch: 30, loss: 1.094686
global_step: 1181, epoch: 30, loss: 1.110520
global_step: 1182, epoch: 30, loss: 1.013288
global_step: 1183, epoch: 30, loss: 1.181913
global_step: 1184, epoch: 30, loss: 1.185989
global_step: 1185, epoch: 30, loss: 1.074036
global_step: 1186, epoch: 30, loss: 1.231361
global_step: 1187, epoch: 30, loss: 1.275522
global_step: 1188, epoch: 30, loss: 1.181171
global_step: 1189, epoch: 30, loss: 1.069362
global_step: 1190, epoch: 30, loss: 1.104393
global_step: 1191, epoch: 30, loss: 1.060865
global_step: 1192, epoch: 30, loss: 1.091625
global_step: 1193, epoch: 30, loss: 1.153665
global_step: 1194, epoch: 30, loss: 1.131650
global_step: 1195, epoch: 30, loss: 1.140247
global_step: 1196, epoch: 30, loss: 1.232651
global_step: 1197, epoch: 30, loss: 1.068908
global_step: 1198, epoch: 30, loss: 1.132793
global_step: 1199, epoch: 30, loss: 1.121868
global_step: 1200, epoch: 30, loss: 1.388851
epoch: 30
train	acc: 0.6449	macro: p 0.4384, r 0.3603, f1: 0.3737	micro: p 0.6449, r 0.6449, f1 0.6449	weighted_f1:0.6023
dev	acc: 0.5482	macro: p 0.3403, r 0.2974, f1: 0.2914	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4881
test	acc: 0.6008	macro: p 0.3674, r 0.3101, f1: 0.3143	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5509
global_step: 1201, epoch: 31, loss: 1.221312
global_step: 1202, epoch: 31, loss: 1.181424
global_step: 1203, epoch: 31, loss: 1.131104
global_step: 1204, epoch: 31, loss: 1.222376
global_step: 1205, epoch: 31, loss: 1.132839
global_step: 1206, epoch: 31, loss: 1.094409
global_step: 1207, epoch: 31, loss: 1.118631
global_step: 1208, epoch: 31, loss: 1.179131
global_step: 1209, epoch: 31, loss: 1.130151
global_step: 1210, epoch: 31, loss: 1.148636
global_step: 1211, epoch: 31, loss: 1.158863
global_step: 1212, epoch: 31, loss: 1.105951
global_step: 1213, epoch: 31, loss: 1.125772
global_step: 1214, epoch: 31, loss: 1.109917
global_step: 1215, epoch: 31, loss: 1.137093
global_step: 1216, epoch: 31, loss: 1.102347
global_step: 1217, epoch: 31, loss: 1.178146
global_step: 1218, epoch: 31, loss: 1.123894
global_step: 1219, epoch: 31, loss: 1.102435
global_step: 1220, epoch: 31, loss: 1.094224
global_step: 1221, epoch: 31, loss: 1.173959
global_step: 1222, epoch: 31, loss: 1.152529
global_step: 1223, epoch: 31, loss: 1.158347
global_step: 1224, epoch: 31, loss: 1.259104
global_step: 1225, epoch: 31, loss: 1.087937
global_step: 1226, epoch: 31, loss: 1.082188
global_step: 1227, epoch: 31, loss: 1.146437
global_step: 1228, epoch: 31, loss: 1.158370
global_step: 1229, epoch: 31, loss: 1.173369
global_step: 1230, epoch: 31, loss: 1.131029
global_step: 1231, epoch: 31, loss: 1.151508
global_step: 1232, epoch: 31, loss: 1.098449
global_step: 1233, epoch: 31, loss: 1.058112
global_step: 1234, epoch: 31, loss: 1.137740
global_step: 1235, epoch: 31, loss: 1.204161
global_step: 1236, epoch: 31, loss: 1.126966
global_step: 1237, epoch: 31, loss: 1.123665
global_step: 1238, epoch: 31, loss: 1.197387
global_step: 1239, epoch: 31, loss: 1.138344
global_step: 1240, epoch: 31, loss: 0.964743
epoch: 31
train	acc: 0.6446	macro: p 0.4441, r 0.3572, f1: 0.3689	micro: p 0.6446, r 0.6446, f1 0.6446	weighted_f1:0.5994
dev	acc: 0.5555	macro: p 0.3678, r 0.3013, f1: 0.2960	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4933
test	acc: 0.6015	macro: p 0.3689, r 0.3084, f1: 0.3102	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5486
New best model!
global_step: 1241, epoch: 32, loss: 1.166948
global_step: 1242, epoch: 32, loss: 1.179881
global_step: 1243, epoch: 32, loss: 1.063392
global_step: 1244, epoch: 32, loss: 1.197629
global_step: 1245, epoch: 32, loss: 1.147335
global_step: 1246, epoch: 32, loss: 1.089722
global_step: 1247, epoch: 32, loss: 1.128538
global_step: 1248, epoch: 32, loss: 1.065442
global_step: 1249, epoch: 32, loss: 1.181284
global_step: 1250, epoch: 32, loss: 1.044263
global_step: 1251, epoch: 32, loss: 1.214684
global_step: 1252, epoch: 32, loss: 1.142229
global_step: 1253, epoch: 32, loss: 1.203936
global_step: 1254, epoch: 32, loss: 1.140078
global_step: 1255, epoch: 32, loss: 1.126611
global_step: 1256, epoch: 32, loss: 1.022298
global_step: 1257, epoch: 32, loss: 1.058224
global_step: 1258, epoch: 32, loss: 1.098416
global_step: 1259, epoch: 32, loss: 0.996867
global_step: 1260, epoch: 32, loss: 1.131552
global_step: 1261, epoch: 32, loss: 1.192700
global_step: 1262, epoch: 32, loss: 1.145007
global_step: 1263, epoch: 32, loss: 1.157743
global_step: 1264, epoch: 32, loss: 1.127505
global_step: 1265, epoch: 32, loss: 1.112038
global_step: 1266, epoch: 32, loss: 1.062744
global_step: 1267, epoch: 32, loss: 1.169636
global_step: 1268, epoch: 32, loss: 1.074222
global_step: 1269, epoch: 32, loss: 1.024723
global_step: 1270, epoch: 32, loss: 1.058714
global_step: 1271, epoch: 32, loss: 1.214110
global_step: 1272, epoch: 32, loss: 1.204992
global_step: 1273, epoch: 32, loss: 1.119462
global_step: 1274, epoch: 32, loss: 1.100518
global_step: 1275, epoch: 32, loss: 1.180924
global_step: 1276, epoch: 32, loss: 1.090869
global_step: 1277, epoch: 32, loss: 1.214980
global_step: 1278, epoch: 32, loss: 1.192457
global_step: 1279, epoch: 32, loss: 1.245198
global_step: 1280, epoch: 32, loss: 0.752081
epoch: 32
train	acc: 0.6429	macro: p 0.4536, r 0.3495, f1: 0.3634	micro: p 0.6429, r 0.6429, f1 0.6429	weighted_f1:0.5956
dev	acc: 0.5482	macro: p 0.3522, r 0.2948, f1: 0.2816	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4797
test	acc: 0.5954	macro: p 0.3687, r 0.2999, f1: 0.2975	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5370
global_step: 1281, epoch: 33, loss: 1.127062
global_step: 1282, epoch: 33, loss: 1.116122
global_step: 1283, epoch: 33, loss: 1.159277
global_step: 1284, epoch: 33, loss: 1.185583
global_step: 1285, epoch: 33, loss: 1.167215
global_step: 1286, epoch: 33, loss: 1.122254
global_step: 1287, epoch: 33, loss: 1.102833
global_step: 1288, epoch: 33, loss: 1.254470
global_step: 1289, epoch: 33, loss: 0.990960
global_step: 1290, epoch: 33, loss: 1.025241
global_step: 1291, epoch: 33, loss: 1.274235
global_step: 1292, epoch: 33, loss: 1.159605
global_step: 1293, epoch: 33, loss: 1.112396
global_step: 1294, epoch: 33, loss: 1.137476
global_step: 1295, epoch: 33, loss: 1.100606
global_step: 1296, epoch: 33, loss: 1.103295
global_step: 1297, epoch: 33, loss: 1.169068
global_step: 1298, epoch: 33, loss: 0.998260
global_step: 1299, epoch: 33, loss: 1.192231
global_step: 1300, epoch: 33, loss: 1.079816
global_step: 1301, epoch: 33, loss: 1.168437
global_step: 1302, epoch: 33, loss: 1.139653
global_step: 1303, epoch: 33, loss: 1.137298
global_step: 1304, epoch: 33, loss: 1.241156
global_step: 1305, epoch: 33, loss: 1.053504
global_step: 1306, epoch: 33, loss: 1.176903
global_step: 1307, epoch: 33, loss: 1.046557
global_step: 1308, epoch: 33, loss: 1.152030
global_step: 1309, epoch: 33, loss: 1.081305
global_step: 1310, epoch: 33, loss: 1.033225
global_step: 1311, epoch: 33, loss: 1.048231
global_step: 1312, epoch: 33, loss: 1.164524
global_step: 1313, epoch: 33, loss: 1.205744
global_step: 1314, epoch: 33, loss: 1.079985
global_step: 1315, epoch: 33, loss: 1.178062
global_step: 1316, epoch: 33, loss: 1.002576
global_step: 1317, epoch: 33, loss: 1.183447
global_step: 1318, epoch: 33, loss: 1.153792
global_step: 1319, epoch: 33, loss: 1.089069
global_step: 1320, epoch: 33, loss: 1.482327
epoch: 33
train	acc: 0.6576	macro: p 0.4504, r 0.3717, f1: 0.3838	micro: p 0.6576, r 0.6576, f1 0.6576	weighted_f1:0.6153
dev	acc: 0.5537	macro: p 0.3519, r 0.3027, f1: 0.2956	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4929
test	acc: 0.6034	macro: p 0.3659, r 0.3130, f1: 0.3151	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5530
global_step: 1321, epoch: 34, loss: 1.030556
global_step: 1322, epoch: 34, loss: 1.067005
global_step: 1323, epoch: 34, loss: 1.114082
global_step: 1324, epoch: 34, loss: 1.123719
global_step: 1325, epoch: 34, loss: 0.994278
global_step: 1326, epoch: 34, loss: 0.985341
global_step: 1327, epoch: 34, loss: 1.165393
global_step: 1328, epoch: 34, loss: 1.147932
global_step: 1329, epoch: 34, loss: 1.178113
global_step: 1330, epoch: 34, loss: 1.090266
global_step: 1331, epoch: 34, loss: 1.122233
global_step: 1332, epoch: 34, loss: 1.076419
global_step: 1333, epoch: 34, loss: 1.048748
global_step: 1334, epoch: 34, loss: 1.101053
global_step: 1335, epoch: 34, loss: 1.134779
global_step: 1336, epoch: 34, loss: 1.131730
global_step: 1337, epoch: 34, loss: 1.162799
global_step: 1338, epoch: 34, loss: 1.076623
global_step: 1339, epoch: 34, loss: 1.133186
global_step: 1340, epoch: 34, loss: 1.242720
global_step: 1341, epoch: 34, loss: 1.098559
global_step: 1342, epoch: 34, loss: 1.094814
global_step: 1343, epoch: 34, loss: 1.106751
global_step: 1344, epoch: 34, loss: 1.036255
global_step: 1345, epoch: 34, loss: 1.076549
global_step: 1346, epoch: 34, loss: 1.093511
global_step: 1347, epoch: 34, loss: 1.115265
global_step: 1348, epoch: 34, loss: 1.133406
global_step: 1349, epoch: 34, loss: 1.139517
global_step: 1350, epoch: 34, loss: 1.073968
global_step: 1351, epoch: 34, loss: 1.124944
global_step: 1352, epoch: 34, loss: 1.175001
global_step: 1353, epoch: 34, loss: 1.041864
global_step: 1354, epoch: 34, loss: 1.151553
global_step: 1355, epoch: 34, loss: 1.216741
global_step: 1356, epoch: 34, loss: 1.208156
global_step: 1357, epoch: 34, loss: 1.073774
global_step: 1358, epoch: 34, loss: 1.114130
global_step: 1359, epoch: 34, loss: 1.253701
global_step: 1360, epoch: 34, loss: 1.436239
epoch: 34
train	acc: 0.6643	macro: p 0.4515, r 0.3819, f1: 0.3918	micro: p 0.6643, r 0.6643, f1 0.6643	weighted_f1:0.6237
dev	acc: 0.5546	macro: p 0.3430, r 0.3080, f1: 0.2995	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4965
test	acc: 0.6023	macro: p 0.3620, r 0.3159, f1: 0.3166	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5539
New best model!
global_step: 1361, epoch: 35, loss: 1.103517
global_step: 1362, epoch: 35, loss: 1.150015
global_step: 1363, epoch: 35, loss: 1.192272
global_step: 1364, epoch: 35, loss: 1.111818
global_step: 1365, epoch: 35, loss: 1.065236
global_step: 1366, epoch: 35, loss: 1.229910
global_step: 1367, epoch: 35, loss: 1.205396
global_step: 1368, epoch: 35, loss: 1.103829
global_step: 1369, epoch: 35, loss: 1.025230
global_step: 1370, epoch: 35, loss: 1.112481
global_step: 1371, epoch: 35, loss: 1.116553
global_step: 1372, epoch: 35, loss: 1.181009
global_step: 1373, epoch: 35, loss: 1.143708
global_step: 1374, epoch: 35, loss: 1.147685
global_step: 1375, epoch: 35, loss: 1.159392
global_step: 1376, epoch: 35, loss: 1.118806
global_step: 1377, epoch: 35, loss: 1.123467
global_step: 1378, epoch: 35, loss: 1.048499
global_step: 1379, epoch: 35, loss: 1.090179
global_step: 1380, epoch: 35, loss: 1.158620
global_step: 1381, epoch: 35, loss: 1.126487
global_step: 1382, epoch: 35, loss: 1.156457
global_step: 1383, epoch: 35, loss: 1.138670
global_step: 1384, epoch: 35, loss: 1.087162
global_step: 1385, epoch: 35, loss: 1.046616
global_step: 1386, epoch: 35, loss: 1.142608
global_step: 1387, epoch: 35, loss: 1.119975
global_step: 1388, epoch: 35, loss: 1.063216
global_step: 1389, epoch: 35, loss: 1.060058
global_step: 1390, epoch: 35, loss: 1.157296
global_step: 1391, epoch: 35, loss: 1.088341
global_step: 1392, epoch: 35, loss: 1.134814
global_step: 1393, epoch: 35, loss: 1.086928
global_step: 1394, epoch: 35, loss: 1.146596
global_step: 1395, epoch: 35, loss: 1.045884
global_step: 1396, epoch: 35, loss: 1.021463
global_step: 1397, epoch: 35, loss: 1.147179
global_step: 1398, epoch: 35, loss: 1.084575
global_step: 1399, epoch: 35, loss: 1.223292
global_step: 1400, epoch: 35, loss: 1.018819
epoch: 35
train	acc: 0.6690	macro: p 0.4544, r 0.3873, f1: 0.3984	micro: p 0.6690, r 0.6690, f1 0.6690	weighted_f1:0.6299
dev	acc: 0.5546	macro: p 0.3435, r 0.3081, f1: 0.2983	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4958
test	acc: 0.6008	macro: p 0.3639, r 0.3162, f1: 0.3168	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5531
global_step: 1401, epoch: 36, loss: 1.103600
global_step: 1402, epoch: 36, loss: 1.119312
global_step: 1403, epoch: 36, loss: 1.109039
global_step: 1404, epoch: 36, loss: 1.057720
global_step: 1405, epoch: 36, loss: 1.188424
global_step: 1406, epoch: 36, loss: 1.086956
global_step: 1407, epoch: 36, loss: 1.077653
global_step: 1408, epoch: 36, loss: 1.156120
global_step: 1409, epoch: 36, loss: 1.111009
global_step: 1410, epoch: 36, loss: 1.087082
global_step: 1411, epoch: 36, loss: 1.073265
global_step: 1412, epoch: 36, loss: 1.215936
global_step: 1413, epoch: 36, loss: 1.080941
global_step: 1414, epoch: 36, loss: 1.143932
global_step: 1415, epoch: 36, loss: 1.043100
global_step: 1416, epoch: 36, loss: 1.115960
global_step: 1417, epoch: 36, loss: 1.040613
global_step: 1418, epoch: 36, loss: 1.068132
global_step: 1419, epoch: 36, loss: 1.031661
global_step: 1420, epoch: 36, loss: 1.068607
global_step: 1421, epoch: 36, loss: 1.089693
global_step: 1422, epoch: 36, loss: 1.131759
global_step: 1423, epoch: 36, loss: 1.124055
global_step: 1424, epoch: 36, loss: 1.061037
global_step: 1425, epoch: 36, loss: 1.017050
global_step: 1426, epoch: 36, loss: 1.104780
global_step: 1427, epoch: 36, loss: 1.142711
global_step: 1428, epoch: 36, loss: 1.145701
global_step: 1429, epoch: 36, loss: 1.045113
global_step: 1430, epoch: 36, loss: 1.128046
global_step: 1431, epoch: 36, loss: 1.096150
global_step: 1432, epoch: 36, loss: 1.081554
global_step: 1433, epoch: 36, loss: 1.149388
global_step: 1434, epoch: 36, loss: 1.095560
global_step: 1435, epoch: 36, loss: 1.058340
global_step: 1436, epoch: 36, loss: 1.085466
global_step: 1437, epoch: 36, loss: 1.179455
global_step: 1438, epoch: 36, loss: 1.047448
global_step: 1439, epoch: 36, loss: 1.057197
global_step: 1440, epoch: 36, loss: 1.163941
epoch: 36
train	acc: 0.6636	macro: p 0.4596, r 0.3763, f1: 0.3893	micro: p 0.6636, r 0.6636, f1 0.6636	weighted_f1:0.6212
dev	acc: 0.5537	macro: p 0.3553, r 0.3007, f1: 0.2930	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4911
test	acc: 0.6046	macro: p 0.3711, r 0.3131, f1: 0.3159	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5536
global_step: 1441, epoch: 37, loss: 1.084997
global_step: 1442, epoch: 37, loss: 1.045518
global_step: 1443, epoch: 37, loss: 0.988084
global_step: 1444, epoch: 37, loss: 0.980013
global_step: 1445, epoch: 37, loss: 1.151150
global_step: 1446, epoch: 37, loss: 1.145054
global_step: 1447, epoch: 37, loss: 1.073274
global_step: 1448, epoch: 37, loss: 1.197719
global_step: 1449, epoch: 37, loss: 1.102703
global_step: 1450, epoch: 37, loss: 1.186834
global_step: 1451, epoch: 37, loss: 1.130448
global_step: 1452, epoch: 37, loss: 1.252180
global_step: 1453, epoch: 37, loss: 1.211710
global_step: 1454, epoch: 37, loss: 1.199803
global_step: 1455, epoch: 37, loss: 1.125203
global_step: 1456, epoch: 37, loss: 1.089390
global_step: 1457, epoch: 37, loss: 1.199688
global_step: 1458, epoch: 37, loss: 1.158279
global_step: 1459, epoch: 37, loss: 1.028244
global_step: 1460, epoch: 37, loss: 1.127436
global_step: 1461, epoch: 37, loss: 1.082957
global_step: 1462, epoch: 37, loss: 1.003947
global_step: 1463, epoch: 37, loss: 0.991968
global_step: 1464, epoch: 37, loss: 1.127870
global_step: 1465, epoch: 37, loss: 1.151731
global_step: 1466, epoch: 37, loss: 1.086203
global_step: 1467, epoch: 37, loss: 0.996801
global_step: 1468, epoch: 37, loss: 1.023573
global_step: 1469, epoch: 37, loss: 0.993379
global_step: 1470, epoch: 37, loss: 1.206967
global_step: 1471, epoch: 37, loss: 1.059585
global_step: 1472, epoch: 37, loss: 0.992448
global_step: 1473, epoch: 37, loss: 1.014466
global_step: 1474, epoch: 37, loss: 1.090312
global_step: 1475, epoch: 37, loss: 1.084694
global_step: 1476, epoch: 37, loss: 1.103767
global_step: 1477, epoch: 37, loss: 1.122045
global_step: 1478, epoch: 37, loss: 1.024506
global_step: 1479, epoch: 37, loss: 1.100563
global_step: 1480, epoch: 37, loss: 0.415003
epoch: 37
train	acc: 0.6603	macro: p 0.4583, r 0.3705, f1: 0.3849	micro: p 0.6603, r 0.6603, f1 0.6603	weighted_f1:0.6164
dev	acc: 0.5537	macro: p 0.3589, r 0.3006, f1: 0.2924	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4899
test	acc: 0.6027	macro: p 0.3720, r 0.3089, f1: 0.3118	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5497
global_step: 1481, epoch: 38, loss: 1.107084
global_step: 1482, epoch: 38, loss: 1.030927
global_step: 1483, epoch: 38, loss: 1.027053
global_step: 1484, epoch: 38, loss: 1.124520
global_step: 1485, epoch: 38, loss: 1.164010
global_step: 1486, epoch: 38, loss: 1.046218
global_step: 1487, epoch: 38, loss: 1.110784
global_step: 1488, epoch: 38, loss: 1.017156
global_step: 1489, epoch: 38, loss: 1.003812
global_step: 1490, epoch: 38, loss: 1.121893
global_step: 1491, epoch: 38, loss: 1.171953
global_step: 1492, epoch: 38, loss: 1.116080
global_step: 1493, epoch: 38, loss: 1.031074
global_step: 1494, epoch: 38, loss: 1.020793
global_step: 1495, epoch: 38, loss: 1.125442
global_step: 1496, epoch: 38, loss: 1.042876
global_step: 1497, epoch: 38, loss: 1.111433
global_step: 1498, epoch: 38, loss: 1.163845
global_step: 1499, epoch: 38, loss: 1.036732
global_step: 1500, epoch: 38, loss: 1.035827
global_step: 1501, epoch: 38, loss: 1.167558
global_step: 1502, epoch: 38, loss: 1.048067
global_step: 1503, epoch: 38, loss: 1.038273
global_step: 1504, epoch: 38, loss: 1.123330
global_step: 1505, epoch: 38, loss: 1.116630
global_step: 1506, epoch: 38, loss: 1.125158
global_step: 1507, epoch: 38, loss: 1.041056
global_step: 1508, epoch: 38, loss: 1.127973
global_step: 1509, epoch: 38, loss: 0.989504
global_step: 1510, epoch: 38, loss: 1.217961
global_step: 1511, epoch: 38, loss: 1.005074
global_step: 1512, epoch: 38, loss: 1.100253
global_step: 1513, epoch: 38, loss: 1.201000
global_step: 1514, epoch: 38, loss: 1.133669
global_step: 1515, epoch: 38, loss: 1.169556
global_step: 1516, epoch: 38, loss: 1.163288
global_step: 1517, epoch: 38, loss: 1.134825
global_step: 1518, epoch: 38, loss: 1.106907
global_step: 1519, epoch: 38, loss: 1.128780
global_step: 1520, epoch: 38, loss: 0.774004
epoch: 38
train	acc: 0.6619	macro: p 0.4620, r 0.3772, f1: 0.3923	micro: p 0.6619, r 0.6619, f1 0.6619	weighted_f1:0.6207
dev	acc: 0.5546	macro: p 0.3527, r 0.3028, f1: 0.2991	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4954
test	acc: 0.6019	macro: p 0.3661, r 0.3092, f1: 0.3146	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5518
global_step: 1521, epoch: 39, loss: 1.241418
global_step: 1522, epoch: 39, loss: 1.014663
global_step: 1523, epoch: 39, loss: 1.146161
global_step: 1524, epoch: 39, loss: 1.014457
global_step: 1525, epoch: 39, loss: 1.004384
global_step: 1526, epoch: 39, loss: 1.039888
global_step: 1527, epoch: 39, loss: 1.001611
global_step: 1528, epoch: 39, loss: 0.928376
global_step: 1529, epoch: 39, loss: 1.078029
global_step: 1530, epoch: 39, loss: 1.105273
global_step: 1531, epoch: 39, loss: 1.116826
global_step: 1532, epoch: 39, loss: 1.147685
global_step: 1533, epoch: 39, loss: 1.160904
global_step: 1534, epoch: 39, loss: 1.115062
global_step: 1535, epoch: 39, loss: 1.027775
global_step: 1536, epoch: 39, loss: 1.142248
global_step: 1537, epoch: 39, loss: 1.029471
global_step: 1538, epoch: 39, loss: 1.014663
global_step: 1539, epoch: 39, loss: 1.061842
global_step: 1540, epoch: 39, loss: 1.016132
global_step: 1541, epoch: 39, loss: 1.139794
global_step: 1542, epoch: 39, loss: 1.076084
global_step: 1543, epoch: 39, loss: 1.081786
global_step: 1544, epoch: 39, loss: 1.114881
global_step: 1545, epoch: 39, loss: 1.158587
global_step: 1546, epoch: 39, loss: 1.130062
global_step: 1547, epoch: 39, loss: 1.193436
global_step: 1548, epoch: 39, loss: 1.030945
global_step: 1549, epoch: 39, loss: 1.124347
global_step: 1550, epoch: 39, loss: 1.133148
global_step: 1551, epoch: 39, loss: 1.027188
global_step: 1552, epoch: 39, loss: 1.128163
global_step: 1553, epoch: 39, loss: 1.034429
global_step: 1554, epoch: 39, loss: 1.123280
global_step: 1555, epoch: 39, loss: 1.036110
global_step: 1556, epoch: 39, loss: 1.012474
global_step: 1557, epoch: 39, loss: 0.977361
global_step: 1558, epoch: 39, loss: 1.048623
global_step: 1559, epoch: 39, loss: 1.001276
global_step: 1560, epoch: 39, loss: 1.348287
epoch: 39
train	acc: 0.6781	macro: p 0.4702, r 0.3940, f1: 0.4078	micro: p 0.6781, r 0.6781, f1 0.6781	weighted_f1:0.6389
dev	acc: 0.5564	macro: p 0.3523, r 0.3053, f1: 0.2977	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4955
test	acc: 0.6065	macro: p 0.3704, r 0.3155, f1: 0.3183	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5567
global_step: 1561, epoch: 40, loss: 1.061437
global_step: 1562, epoch: 40, loss: 1.060892
global_step: 1563, epoch: 40, loss: 1.054742
global_step: 1564, epoch: 40, loss: 1.043010
global_step: 1565, epoch: 40, loss: 0.986033
global_step: 1566, epoch: 40, loss: 1.164726
global_step: 1567, epoch: 40, loss: 1.039010
global_step: 1568, epoch: 40, loss: 1.105990
global_step: 1569, epoch: 40, loss: 1.221176
global_step: 1570, epoch: 40, loss: 1.060357
global_step: 1571, epoch: 40, loss: 1.191262
global_step: 1572, epoch: 40, loss: 1.033591
global_step: 1573, epoch: 40, loss: 1.124567
global_step: 1574, epoch: 40, loss: 1.032645
global_step: 1575, epoch: 40, loss: 1.137796
global_step: 1576, epoch: 40, loss: 1.045965
global_step: 1577, epoch: 40, loss: 1.034692
global_step: 1578, epoch: 40, loss: 1.047939
global_step: 1579, epoch: 40, loss: 1.165093
global_step: 1580, epoch: 40, loss: 1.069167
global_step: 1581, epoch: 40, loss: 1.062617
global_step: 1582, epoch: 40, loss: 1.052645
global_step: 1583, epoch: 40, loss: 1.103686
global_step: 1584, epoch: 40, loss: 1.068778
global_step: 1585, epoch: 40, loss: 0.979258
global_step: 1586, epoch: 40, loss: 1.051515
global_step: 1587, epoch: 40, loss: 1.140400
global_step: 1588, epoch: 40, loss: 1.006017
global_step: 1589, epoch: 40, loss: 1.159377
global_step: 1590, epoch: 40, loss: 1.133768
global_step: 1591, epoch: 40, loss: 0.994200
global_step: 1592, epoch: 40, loss: 1.016232
global_step: 1593, epoch: 40, loss: 1.085972
global_step: 1594, epoch: 40, loss: 1.025599
global_step: 1595, epoch: 40, loss: 0.966252
global_step: 1596, epoch: 40, loss: 1.022939
global_step: 1597, epoch: 40, loss: 1.026105
global_step: 1598, epoch: 40, loss: 1.084464
global_step: 1599, epoch: 40, loss: 1.058862
global_step: 1600, epoch: 40, loss: 1.322574
epoch: 40
train	acc: 0.6745	macro: p 0.4693, r 0.3899, f1: 0.4032	micro: p 0.6745, r 0.6745, f1 0.6745	weighted_f1:0.6341
dev	acc: 0.5564	macro: p 0.3541, r 0.3053, f1: 0.3011	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4976
test	acc: 0.6046	macro: p 0.3679, r 0.3130, f1: 0.3172	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5547
New best model!
global_step: 1601, epoch: 41, loss: 1.094760
global_step: 1602, epoch: 41, loss: 1.051914
global_step: 1603, epoch: 41, loss: 1.061244
global_step: 1604, epoch: 41, loss: 1.082951
global_step: 1605, epoch: 41, loss: 1.049955
global_step: 1606, epoch: 41, loss: 1.059884
global_step: 1607, epoch: 41, loss: 1.024257
global_step: 1608, epoch: 41, loss: 1.046959
global_step: 1609, epoch: 41, loss: 1.047154
global_step: 1610, epoch: 41, loss: 1.023462
global_step: 1611, epoch: 41, loss: 1.122735
global_step: 1612, epoch: 41, loss: 1.069518
global_step: 1613, epoch: 41, loss: 1.107300
global_step: 1614, epoch: 41, loss: 1.055145
global_step: 1615, epoch: 41, loss: 1.014689
global_step: 1616, epoch: 41, loss: 1.039725
global_step: 1617, epoch: 41, loss: 1.053607
global_step: 1618, epoch: 41, loss: 1.113137
global_step: 1619, epoch: 41, loss: 1.013175
global_step: 1620, epoch: 41, loss: 1.183496
global_step: 1621, epoch: 41, loss: 1.067663
global_step: 1622, epoch: 41, loss: 1.046569
global_step: 1623, epoch: 41, loss: 1.102211
global_step: 1624, epoch: 41, loss: 1.123467
global_step: 1625, epoch: 41, loss: 1.018104
global_step: 1626, epoch: 41, loss: 0.983662
global_step: 1627, epoch: 41, loss: 0.948793
global_step: 1628, epoch: 41, loss: 1.032574
global_step: 1629, epoch: 41, loss: 1.107489
global_step: 1630, epoch: 41, loss: 1.093872
global_step: 1631, epoch: 41, loss: 0.966510
global_step: 1632, epoch: 41, loss: 1.149052
global_step: 1633, epoch: 41, loss: 0.910279
global_step: 1634, epoch: 41, loss: 1.085403
global_step: 1635, epoch: 41, loss: 1.102285
global_step: 1636, epoch: 41, loss: 1.049306
global_step: 1637, epoch: 41, loss: 0.979642
global_step: 1638, epoch: 41, loss: 1.020982
global_step: 1639, epoch: 41, loss: 1.021004
global_step: 1640, epoch: 41, loss: 0.891687
epoch: 41
train	acc: 0.6813	macro: p 0.4718, r 0.3976, f1: 0.4124	micro: p 0.6813, r 0.6813, f1 0.6813	weighted_f1:0.6425
dev	acc: 0.5537	macro: p 0.3465, r 0.3020, f1: 0.2949	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4924
test	acc: 0.6027	macro: p 0.3647, r 0.3128, f1: 0.3151	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5528
global_step: 1641, epoch: 42, loss: 1.045007
global_step: 1642, epoch: 42, loss: 0.952474
global_step: 1643, epoch: 42, loss: 1.123929
global_step: 1644, epoch: 42, loss: 1.148016
global_step: 1645, epoch: 42, loss: 1.041357
global_step: 1646, epoch: 42, loss: 1.142531
global_step: 1647, epoch: 42, loss: 1.128200
global_step: 1648, epoch: 42, loss: 1.014262
global_step: 1649, epoch: 42, loss: 0.977853
global_step: 1650, epoch: 42, loss: 1.004471
global_step: 1651, epoch: 42, loss: 0.962700
global_step: 1652, epoch: 42, loss: 1.069823
global_step: 1653, epoch: 42, loss: 1.105386
global_step: 1654, epoch: 42, loss: 1.025797
global_step: 1655, epoch: 42, loss: 1.149529
global_step: 1656, epoch: 42, loss: 1.085014
global_step: 1657, epoch: 42, loss: 1.022969
global_step: 1658, epoch: 42, loss: 1.046535
global_step: 1659, epoch: 42, loss: 1.054775
global_step: 1660, epoch: 42, loss: 0.978993
global_step: 1661, epoch: 42, loss: 1.029022
global_step: 1662, epoch: 42, loss: 1.149055
global_step: 1663, epoch: 42, loss: 0.972906
global_step: 1664, epoch: 42, loss: 1.066366
global_step: 1665, epoch: 42, loss: 1.051137
global_step: 1666, epoch: 42, loss: 1.043299
global_step: 1667, epoch: 42, loss: 1.052793
global_step: 1668, epoch: 42, loss: 1.064991
global_step: 1669, epoch: 42, loss: 1.048935
global_step: 1670, epoch: 42, loss: 0.956172
global_step: 1671, epoch: 42, loss: 1.129191
global_step: 1672, epoch: 42, loss: 1.155702
global_step: 1673, epoch: 42, loss: 1.084715
global_step: 1674, epoch: 42, loss: 1.099594
global_step: 1675, epoch: 42, loss: 1.032747
global_step: 1676, epoch: 42, loss: 1.052474
global_step: 1677, epoch: 42, loss: 1.044346
global_step: 1678, epoch: 42, loss: 1.111307
global_step: 1679, epoch: 42, loss: 1.116397
global_step: 1680, epoch: 42, loss: 0.194762
epoch: 42
train	acc: 0.6835	macro: p 0.4738, r 0.4019, f1: 0.4155	micro: p 0.6835, r 0.6835, f1 0.6835	weighted_f1:0.6454
dev	acc: 0.5555	macro: p 0.3490, r 0.3044, f1: 0.3001	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4972
test	acc: 0.6031	macro: p 0.3676, r 0.3142, f1: 0.3187	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5551
global_step: 1681, epoch: 43, loss: 0.994345
global_step: 1682, epoch: 43, loss: 0.934188
global_step: 1683, epoch: 43, loss: 1.083648
global_step: 1684, epoch: 43, loss: 1.099189
global_step: 1685, epoch: 43, loss: 1.069316
global_step: 1686, epoch: 43, loss: 1.031614
global_step: 1687, epoch: 43, loss: 1.051037
global_step: 1688, epoch: 43, loss: 0.988533
global_step: 1689, epoch: 43, loss: 1.058912
global_step: 1690, epoch: 43, loss: 1.061708
global_step: 1691, epoch: 43, loss: 0.984449
global_step: 1692, epoch: 43, loss: 0.918791
global_step: 1693, epoch: 43, loss: 0.985036
global_step: 1694, epoch: 43, loss: 1.065624
global_step: 1695, epoch: 43, loss: 1.038298
global_step: 1696, epoch: 43, loss: 0.997488
global_step: 1697, epoch: 43, loss: 1.061430
global_step: 1698, epoch: 43, loss: 0.960536
global_step: 1699, epoch: 43, loss: 1.076549
global_step: 1700, epoch: 43, loss: 1.039196
global_step: 1701, epoch: 43, loss: 0.996614
global_step: 1702, epoch: 43, loss: 1.042071
global_step: 1703, epoch: 43, loss: 1.082056
global_step: 1704, epoch: 43, loss: 1.017249
global_step: 1705, epoch: 43, loss: 1.014564
global_step: 1706, epoch: 43, loss: 1.137421
global_step: 1707, epoch: 43, loss: 1.077696
global_step: 1708, epoch: 43, loss: 1.030642
global_step: 1709, epoch: 43, loss: 1.055665
global_step: 1710, epoch: 43, loss: 1.038265
global_step: 1711, epoch: 43, loss: 1.107100
global_step: 1712, epoch: 43, loss: 1.049426
global_step: 1713, epoch: 43, loss: 1.059086
global_step: 1714, epoch: 43, loss: 1.023787
global_step: 1715, epoch: 43, loss: 1.081091
global_step: 1716, epoch: 43, loss: 1.064435
global_step: 1717, epoch: 43, loss: 1.078433
global_step: 1718, epoch: 43, loss: 1.079758
global_step: 1719, epoch: 43, loss: 1.039295
global_step: 1720, epoch: 43, loss: 0.662934
epoch: 43
train	acc: 0.6956	macro: p 0.4807, r 0.4164, f1: 0.4263	micro: p 0.6956, r 0.6956, f1 0.6956	weighted_f1:0.6588
dev	acc: 0.5546	macro: p 0.3474, r 0.3059, f1: 0.3007	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4973
test	acc: 0.6027	macro: p 0.3671, r 0.3176, f1: 0.3200	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5560
global_step: 1721, epoch: 44, loss: 0.952642
global_step: 1722, epoch: 44, loss: 0.994417
global_step: 1723, epoch: 44, loss: 1.072362
global_step: 1724, epoch: 44, loss: 0.940517
global_step: 1725, epoch: 44, loss: 1.116540
global_step: 1726, epoch: 44, loss: 1.068380
global_step: 1727, epoch: 44, loss: 1.153965
global_step: 1728, epoch: 44, loss: 1.113297
global_step: 1729, epoch: 44, loss: 0.972771
global_step: 1730, epoch: 44, loss: 1.085170
global_step: 1731, epoch: 44, loss: 1.062587
global_step: 1732, epoch: 44, loss: 1.047215
global_step: 1733, epoch: 44, loss: 0.981283
global_step: 1734, epoch: 44, loss: 0.944243
global_step: 1735, epoch: 44, loss: 1.139905
global_step: 1736, epoch: 44, loss: 1.013594
global_step: 1737, epoch: 44, loss: 1.012861
global_step: 1738, epoch: 44, loss: 1.051145
global_step: 1739, epoch: 44, loss: 1.095288
global_step: 1740, epoch: 44, loss: 1.028747
global_step: 1741, epoch: 44, loss: 1.110315
global_step: 1742, epoch: 44, loss: 0.960963
global_step: 1743, epoch: 44, loss: 0.999918
global_step: 1744, epoch: 44, loss: 1.011357
global_step: 1745, epoch: 44, loss: 0.965365
global_step: 1746, epoch: 44, loss: 0.970816
global_step: 1747, epoch: 44, loss: 1.072949
global_step: 1748, epoch: 44, loss: 1.012809
global_step: 1749, epoch: 44, loss: 1.009024
global_step: 1750, epoch: 44, loss: 0.994617
global_step: 1751, epoch: 44, loss: 1.038782
global_step: 1752, epoch: 44, loss: 1.031133
global_step: 1753, epoch: 44, loss: 1.002020
global_step: 1754, epoch: 44, loss: 1.051441
global_step: 1755, epoch: 44, loss: 1.139873
global_step: 1756, epoch: 44, loss: 1.030396
global_step: 1757, epoch: 44, loss: 1.014624
global_step: 1758, epoch: 44, loss: 1.062212
global_step: 1759, epoch: 44, loss: 1.003077
global_step: 1760, epoch: 44, loss: 1.431202
epoch: 44
train	acc: 0.7075	macro: p 0.4853, r 0.4365, f1: 0.4502	micro: p 0.7075, r 0.7075, f1 0.7075	weighted_f1:0.6757
dev	acc: 0.5582	macro: p 0.3497, r 0.3150, f1: 0.3122	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5069
test	acc: 0.6042	macro: p 0.3678, r 0.3214, f1: 0.3259	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5602
New best model!
global_step: 1761, epoch: 45, loss: 1.104859
global_step: 1762, epoch: 45, loss: 0.907353
global_step: 1763, epoch: 45, loss: 1.035066
global_step: 1764, epoch: 45, loss: 1.075887
global_step: 1765, epoch: 45, loss: 1.004102
global_step: 1766, epoch: 45, loss: 1.061588
global_step: 1767, epoch: 45, loss: 1.116747
global_step: 1768, epoch: 45, loss: 1.023856
global_step: 1769, epoch: 45, loss: 0.970395
global_step: 1770, epoch: 45, loss: 1.002820
global_step: 1771, epoch: 45, loss: 1.056582
global_step: 1772, epoch: 45, loss: 1.137569
global_step: 1773, epoch: 45, loss: 1.018810
global_step: 1774, epoch: 45, loss: 1.060904
global_step: 1775, epoch: 45, loss: 1.000665
global_step: 1776, epoch: 45, loss: 0.979644
global_step: 1777, epoch: 45, loss: 1.055202
global_step: 1778, epoch: 45, loss: 1.036410
global_step: 1779, epoch: 45, loss: 1.083119
global_step: 1780, epoch: 45, loss: 1.115180
global_step: 1781, epoch: 45, loss: 1.084642
global_step: 1782, epoch: 45, loss: 1.096396
global_step: 1783, epoch: 45, loss: 1.027906
global_step: 1784, epoch: 45, loss: 1.050012
global_step: 1785, epoch: 45, loss: 0.965474
global_step: 1786, epoch: 45, loss: 1.007239
global_step: 1787, epoch: 45, loss: 0.948253
global_step: 1788, epoch: 45, loss: 1.011269
global_step: 1789, epoch: 45, loss: 0.933229
global_step: 1790, epoch: 45, loss: 1.022417
global_step: 1791, epoch: 45, loss: 1.025944
global_step: 1792, epoch: 45, loss: 1.061548
global_step: 1793, epoch: 45, loss: 1.012182
global_step: 1794, epoch: 45, loss: 0.933637
global_step: 1795, epoch: 45, loss: 1.024713
global_step: 1796, epoch: 45, loss: 1.015609
global_step: 1797, epoch: 45, loss: 1.036306
global_step: 1798, epoch: 45, loss: 0.849172
global_step: 1799, epoch: 45, loss: 1.053367
global_step: 1800, epoch: 45, loss: 0.970076
epoch: 45
train	acc: 0.7088	macro: p 0.4901, r 0.4340, f1: 0.4485	micro: p 0.7088, r 0.7088, f1 0.7088	weighted_f1:0.6755
dev	acc: 0.5564	macro: p 0.3440, r 0.3115, f1: 0.3065	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5018
test	acc: 0.6069	macro: p 0.3731, r 0.3237, f1: 0.3276	micro: p 0.6069, r 0.6069, f1 0.6069	weighted_f1:0.5614
global_step: 1801, epoch: 46, loss: 0.918013
global_step: 1802, epoch: 46, loss: 1.199601
global_step: 1803, epoch: 46, loss: 1.040910
global_step: 1804, epoch: 46, loss: 1.054366
global_step: 1805, epoch: 46, loss: 1.062093
global_step: 1806, epoch: 46, loss: 1.087466
global_step: 1807, epoch: 46, loss: 0.952089
global_step: 1808, epoch: 46, loss: 0.996718
global_step: 1809, epoch: 46, loss: 0.914799
global_step: 1810, epoch: 46, loss: 1.051661
global_step: 1811, epoch: 46, loss: 1.098297
global_step: 1812, epoch: 46, loss: 1.069997
global_step: 1813, epoch: 46, loss: 0.912729
global_step: 1814, epoch: 46, loss: 1.071458
global_step: 1815, epoch: 46, loss: 1.157816
global_step: 1816, epoch: 46, loss: 1.087095
global_step: 1817, epoch: 46, loss: 1.032207
global_step: 1818, epoch: 46, loss: 0.969755
global_step: 1819, epoch: 46, loss: 1.044590
global_step: 1820, epoch: 46, loss: 1.033214
global_step: 1821, epoch: 46, loss: 1.024502
global_step: 1822, epoch: 46, loss: 0.923276
global_step: 1823, epoch: 46, loss: 1.076367
global_step: 1824, epoch: 46, loss: 1.028460
global_step: 1825, epoch: 46, loss: 0.955846
global_step: 1826, epoch: 46, loss: 1.035672
global_step: 1827, epoch: 46, loss: 1.073102
global_step: 1828, epoch: 46, loss: 1.015155
global_step: 1829, epoch: 46, loss: 1.005994
global_step: 1830, epoch: 46, loss: 0.993543
global_step: 1831, epoch: 46, loss: 0.981054
global_step: 1832, epoch: 46, loss: 0.913701
global_step: 1833, epoch: 46, loss: 1.057153
global_step: 1834, epoch: 46, loss: 0.958793
global_step: 1835, epoch: 46, loss: 1.063381
global_step: 1836, epoch: 46, loss: 1.030517
global_step: 1837, epoch: 46, loss: 0.977459
global_step: 1838, epoch: 46, loss: 0.966704
global_step: 1839, epoch: 46, loss: 0.911161
global_step: 1840, epoch: 46, loss: 0.741599
epoch: 46
train	acc: 0.6939	macro: p 0.4898, r 0.4101, f1: 0.4286	micro: p 0.6939, r 0.6939, f1 0.6939	weighted_f1:0.6561
dev	acc: 0.5582	macro: p 0.3540, r 0.3042, f1: 0.2986	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4959
test	acc: 0.6046	macro: p 0.3713, r 0.3121, f1: 0.3172	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5536
global_step: 1841, epoch: 47, loss: 1.018520
global_step: 1842, epoch: 47, loss: 0.968954
global_step: 1843, epoch: 47, loss: 0.937651
global_step: 1844, epoch: 47, loss: 0.970252
global_step: 1845, epoch: 47, loss: 1.020342
global_step: 1846, epoch: 47, loss: 0.911114
global_step: 1847, epoch: 47, loss: 1.085298
global_step: 1848, epoch: 47, loss: 0.975923
global_step: 1849, epoch: 47, loss: 0.970044
global_step: 1850, epoch: 47, loss: 1.093060
global_step: 1851, epoch: 47, loss: 0.965582
global_step: 1852, epoch: 47, loss: 1.055164
global_step: 1853, epoch: 47, loss: 0.993681
global_step: 1854, epoch: 47, loss: 1.020828
global_step: 1855, epoch: 47, loss: 0.978336
global_step: 1856, epoch: 47, loss: 1.060473
global_step: 1857, epoch: 47, loss: 0.956030
global_step: 1858, epoch: 47, loss: 0.982640
global_step: 1859, epoch: 47, loss: 1.032424
global_step: 1860, epoch: 47, loss: 1.049366
global_step: 1861, epoch: 47, loss: 1.140248
global_step: 1862, epoch: 47, loss: 1.054053
global_step: 1863, epoch: 47, loss: 1.002031
global_step: 1864, epoch: 47, loss: 0.904115
global_step: 1865, epoch: 47, loss: 1.119347
global_step: 1866, epoch: 47, loss: 0.924891
global_step: 1867, epoch: 47, loss: 0.922538
global_step: 1868, epoch: 47, loss: 1.084487
global_step: 1869, epoch: 47, loss: 1.032798
global_step: 1870, epoch: 47, loss: 1.001027
global_step: 1871, epoch: 47, loss: 1.072399
global_step: 1872, epoch: 47, loss: 1.026125
global_step: 1873, epoch: 47, loss: 1.085617
global_step: 1874, epoch: 47, loss: 1.022828
global_step: 1875, epoch: 47, loss: 0.973365
global_step: 1876, epoch: 47, loss: 1.080106
global_step: 1877, epoch: 47, loss: 1.046233
global_step: 1878, epoch: 47, loss: 0.906849
global_step: 1879, epoch: 47, loss: 1.061092
global_step: 1880, epoch: 47, loss: 0.850302
epoch: 47
train	acc: 0.7132	macro: p 0.4940, r 0.4418, f1: 0.4565	micro: p 0.7132, r 0.7132, f1 0.7132	weighted_f1:0.6811
dev	acc: 0.5528	macro: p 0.3403, r 0.3071, f1: 0.3053	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5002
test	acc: 0.6034	macro: p 0.3637, r 0.3189, f1: 0.3242	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5584
global_step: 1881, epoch: 48, loss: 0.896541
global_step: 1882, epoch: 48, loss: 1.059566
global_step: 1883, epoch: 48, loss: 0.969301
global_step: 1884, epoch: 48, loss: 1.037768
global_step: 1885, epoch: 48, loss: 1.015474
global_step: 1886, epoch: 48, loss: 1.060431
global_step: 1887, epoch: 48, loss: 0.890502
global_step: 1888, epoch: 48, loss: 0.916654
global_step: 1889, epoch: 48, loss: 1.081952
global_step: 1890, epoch: 48, loss: 0.986007
global_step: 1891, epoch: 48, loss: 0.979160
global_step: 1892, epoch: 48, loss: 0.956367
global_step: 1893, epoch: 48, loss: 1.048775
global_step: 1894, epoch: 48, loss: 1.007462
global_step: 1895, epoch: 48, loss: 0.928056
global_step: 1896, epoch: 48, loss: 1.036520
global_step: 1897, epoch: 48, loss: 0.949606
global_step: 1898, epoch: 48, loss: 1.047967
global_step: 1899, epoch: 48, loss: 1.034044
global_step: 1900, epoch: 48, loss: 0.914915
global_step: 1901, epoch: 48, loss: 1.112112
global_step: 1902, epoch: 48, loss: 0.936415
global_step: 1903, epoch: 48, loss: 0.997057
global_step: 1904, epoch: 48, loss: 1.000269
global_step: 1905, epoch: 48, loss: 0.933008
global_step: 1906, epoch: 48, loss: 1.059655
global_step: 1907, epoch: 48, loss: 0.839384
global_step: 1908, epoch: 48, loss: 1.123258
global_step: 1909, epoch: 48, loss: 1.065627
global_step: 1910, epoch: 48, loss: 0.966312
global_step: 1911, epoch: 48, loss: 1.100050
global_step: 1912, epoch: 48, loss: 0.968964
global_step: 1913, epoch: 48, loss: 0.985059
global_step: 1914, epoch: 48, loss: 0.987574
global_step: 1915, epoch: 48, loss: 0.994975
global_step: 1916, epoch: 48, loss: 0.879792
global_step: 1917, epoch: 48, loss: 0.991818
global_step: 1918, epoch: 48, loss: 1.002071
global_step: 1919, epoch: 48, loss: 1.019103
global_step: 1920, epoch: 48, loss: 0.906531
epoch: 48
train	acc: 0.7174	macro: p 0.4982, r 0.4459, f1: 0.4611	micro: p 0.7174, r 0.7174, f1 0.7174	weighted_f1:0.6860
dev	acc: 0.5528	macro: p 0.3455, r 0.3077, f1: 0.3035	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4983
test	acc: 0.6042	macro: p 0.3662, r 0.3202, f1: 0.3252	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5592
global_step: 1921, epoch: 49, loss: 0.838770
global_step: 1922, epoch: 49, loss: 1.003127
global_step: 1923, epoch: 49, loss: 1.042737
global_step: 1924, epoch: 49, loss: 1.022584
global_step: 1925, epoch: 49, loss: 0.986162
global_step: 1926, epoch: 49, loss: 0.981843
global_step: 1927, epoch: 49, loss: 0.972499
global_step: 1928, epoch: 49, loss: 1.069565
global_step: 1929, epoch: 49, loss: 0.944672
global_step: 1930, epoch: 49, loss: 1.055450
global_step: 1931, epoch: 49, loss: 0.808443
global_step: 1932, epoch: 49, loss: 1.112947
global_step: 1933, epoch: 49, loss: 1.128029
global_step: 1934, epoch: 49, loss: 1.017705
global_step: 1935, epoch: 49, loss: 1.023480
global_step: 1936, epoch: 49, loss: 1.114670
global_step: 1937, epoch: 49, loss: 1.058810
global_step: 1938, epoch: 49, loss: 0.923774
global_step: 1939, epoch: 49, loss: 0.913444
global_step: 1940, epoch: 49, loss: 0.957335
global_step: 1941, epoch: 49, loss: 1.027924
global_step: 1942, epoch: 49, loss: 0.865920
global_step: 1943, epoch: 49, loss: 0.852066
global_step: 1944, epoch: 49, loss: 1.003844
global_step: 1945, epoch: 49, loss: 0.900707
global_step: 1946, epoch: 49, loss: 0.948573
global_step: 1947, epoch: 49, loss: 1.051591
global_step: 1948, epoch: 49, loss: 1.086361
global_step: 1949, epoch: 49, loss: 0.934859
global_step: 1950, epoch: 49, loss: 1.085618
global_step: 1951, epoch: 49, loss: 1.087948
global_step: 1952, epoch: 49, loss: 1.025197
global_step: 1953, epoch: 49, loss: 0.909287
global_step: 1954, epoch: 49, loss: 0.970488
global_step: 1955, epoch: 49, loss: 0.981023
global_step: 1956, epoch: 49, loss: 0.996375
global_step: 1957, epoch: 49, loss: 1.043934
global_step: 1958, epoch: 49, loss: 1.015040
global_step: 1959, epoch: 49, loss: 1.106507
global_step: 1960, epoch: 49, loss: 1.102819
epoch: 49
train	acc: 0.7180	macro: p 0.5061, r 0.4415, f1: 0.4572	micro: p 0.7180, r 0.7180, f1 0.7180	weighted_f1:0.6853
dev	acc: 0.5509	macro: p 0.3382, r 0.3047, f1: 0.2939	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4914
test	acc: 0.5996	macro: p 0.3707, r 0.3153, f1: 0.3165	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5513
global_step: 1961, epoch: 50, loss: 1.014353
global_step: 1962, epoch: 50, loss: 0.956226
global_step: 1963, epoch: 50, loss: 0.918960
global_step: 1964, epoch: 50, loss: 1.004376
global_step: 1965, epoch: 50, loss: 0.993058
global_step: 1966, epoch: 50, loss: 0.933431
global_step: 1967, epoch: 50, loss: 0.986963
global_step: 1968, epoch: 50, loss: 1.076507
global_step: 1969, epoch: 50, loss: 1.141681
global_step: 1970, epoch: 50, loss: 0.939156
global_step: 1971, epoch: 50, loss: 1.098816
global_step: 1972, epoch: 50, loss: 0.953001
global_step: 1973, epoch: 50, loss: 0.980244
global_step: 1974, epoch: 50, loss: 1.053548
global_step: 1975, epoch: 50, loss: 0.987902
global_step: 1976, epoch: 50, loss: 1.042334
global_step: 1977, epoch: 50, loss: 0.885146
global_step: 1978, epoch: 50, loss: 0.996079
global_step: 1979, epoch: 50, loss: 0.964751
global_step: 1980, epoch: 50, loss: 0.841494
global_step: 1981, epoch: 50, loss: 1.042794
global_step: 1982, epoch: 50, loss: 1.033871
global_step: 1983, epoch: 50, loss: 0.974808
global_step: 1984, epoch: 50, loss: 0.980769
global_step: 1985, epoch: 50, loss: 0.953258
global_step: 1986, epoch: 50, loss: 1.035436
global_step: 1987, epoch: 50, loss: 1.043035
global_step: 1988, epoch: 50, loss: 1.082460
global_step: 1989, epoch: 50, loss: 0.904201
global_step: 1990, epoch: 50, loss: 1.037299
global_step: 1991, epoch: 50, loss: 0.963737
global_step: 1992, epoch: 50, loss: 1.135341
global_step: 1993, epoch: 50, loss: 0.951633
global_step: 1994, epoch: 50, loss: 1.066229
global_step: 1995, epoch: 50, loss: 0.891966
global_step: 1996, epoch: 50, loss: 0.917779
global_step: 1997, epoch: 50, loss: 0.825904
global_step: 1998, epoch: 50, loss: 1.002402
global_step: 1999, epoch: 50, loss: 1.006884
global_step: 2000, epoch: 50, loss: 0.703966
epoch: 50
train	acc: 0.7296	macro: p 0.5057, r 0.4591, f1: 0.4675	micro: p 0.7296, r 0.7296, f1 0.7296	weighted_f1:0.6980
dev	acc: 0.5546	macro: p 0.3421, r 0.3088, f1: 0.3029	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5005
test	acc: 0.6042	macro: p 0.3734, r 0.3225, f1: 0.3259	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5606
global_step: 2001, epoch: 51, loss: 0.943921
global_step: 2002, epoch: 51, loss: 1.002353
global_step: 2003, epoch: 51, loss: 1.018654
global_step: 2004, epoch: 51, loss: 0.877099
global_step: 2005, epoch: 51, loss: 0.940796
global_step: 2006, epoch: 51, loss: 0.956967
global_step: 2007, epoch: 51, loss: 1.049482
global_step: 2008, epoch: 51, loss: 1.108828
global_step: 2009, epoch: 51, loss: 1.053032
global_step: 2010, epoch: 51, loss: 0.915146
global_step: 2011, epoch: 51, loss: 0.956338
global_step: 2012, epoch: 51, loss: 0.970824
global_step: 2013, epoch: 51, loss: 0.907435
global_step: 2014, epoch: 51, loss: 0.961551
global_step: 2015, epoch: 51, loss: 0.914860
global_step: 2016, epoch: 51, loss: 0.906453
global_step: 2017, epoch: 51, loss: 0.960388
global_step: 2018, epoch: 51, loss: 0.931098
global_step: 2019, epoch: 51, loss: 0.970404
global_step: 2020, epoch: 51, loss: 1.100789
global_step: 2021, epoch: 51, loss: 1.034124
global_step: 2022, epoch: 51, loss: 0.972723
global_step: 2023, epoch: 51, loss: 0.936638
global_step: 2024, epoch: 51, loss: 1.174846
global_step: 2025, epoch: 51, loss: 0.895899
global_step: 2026, epoch: 51, loss: 0.935787
global_step: 2027, epoch: 51, loss: 1.007657
global_step: 2028, epoch: 51, loss: 1.094154
global_step: 2029, epoch: 51, loss: 1.075539
global_step: 2030, epoch: 51, loss: 0.943314
global_step: 2031, epoch: 51, loss: 0.876986
global_step: 2032, epoch: 51, loss: 1.000106
global_step: 2033, epoch: 51, loss: 0.979504
global_step: 2034, epoch: 51, loss: 1.050748
global_step: 2035, epoch: 51, loss: 1.019857
global_step: 2036, epoch: 51, loss: 0.934958
global_step: 2037, epoch: 51, loss: 1.018138
global_step: 2038, epoch: 51, loss: 0.947379
global_step: 2039, epoch: 51, loss: 0.971755
global_step: 2040, epoch: 51, loss: 1.346161
epoch: 51
train	acc: 0.7414	macro: p 0.5042, r 0.4783, f1: 0.4857	micro: p 0.7414, r 0.7414, f1 0.7414	weighted_f1:0.7133
dev	acc: 0.5528	macro: p 0.3356, r 0.3143, f1: 0.3104	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5049
test	acc: 0.6004	macro: p 0.3629, r 0.3246, f1: 0.3287	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5601
global_step: 2041, epoch: 52, loss: 0.992936
global_step: 2042, epoch: 52, loss: 0.926895
global_step: 2043, epoch: 52, loss: 1.019964
global_step: 2044, epoch: 52, loss: 0.982366
global_step: 2045, epoch: 52, loss: 0.902701
global_step: 2046, epoch: 52, loss: 0.831753
global_step: 2047, epoch: 52, loss: 0.904377
global_step: 2048, epoch: 52, loss: 0.999001
global_step: 2049, epoch: 52, loss: 1.003941
global_step: 2050, epoch: 52, loss: 0.951189
global_step: 2051, epoch: 52, loss: 0.857178
global_step: 2052, epoch: 52, loss: 1.062821
global_step: 2053, epoch: 52, loss: 0.927397
global_step: 2054, epoch: 52, loss: 1.045911
global_step: 2055, epoch: 52, loss: 1.029891
global_step: 2056, epoch: 52, loss: 0.950022
global_step: 2057, epoch: 52, loss: 0.984967
global_step: 2058, epoch: 52, loss: 1.058849
global_step: 2059, epoch: 52, loss: 0.975648
global_step: 2060, epoch: 52, loss: 0.934410
global_step: 2061, epoch: 52, loss: 1.072502
global_step: 2062, epoch: 52, loss: 0.911965
global_step: 2063, epoch: 52, loss: 0.985196
global_step: 2064, epoch: 52, loss: 0.931427
global_step: 2065, epoch: 52, loss: 0.943174
global_step: 2066, epoch: 52, loss: 0.977598
global_step: 2067, epoch: 52, loss: 0.908635
global_step: 2068, epoch: 52, loss: 1.009856
global_step: 2069, epoch: 52, loss: 0.902150
global_step: 2070, epoch: 52, loss: 0.973227
global_step: 2071, epoch: 52, loss: 0.954249
global_step: 2072, epoch: 52, loss: 0.982600
global_step: 2073, epoch: 52, loss: 0.924903
global_step: 2074, epoch: 52, loss: 0.965297
global_step: 2075, epoch: 52, loss: 0.979865
global_step: 2076, epoch: 52, loss: 1.026761
global_step: 2077, epoch: 52, loss: 0.987616
global_step: 2078, epoch: 52, loss: 1.063803
global_step: 2079, epoch: 52, loss: 0.916148
global_step: 2080, epoch: 52, loss: 0.873657
epoch: 52
train	acc: 0.7338	macro: p 0.5122, r 0.4623, f1: 0.4763	micro: p 0.7338, r 0.7338, f1 0.7338	weighted_f1:0.7029
dev	acc: 0.5537	macro: p 0.3436, r 0.3095, f1: 0.3025	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4978
test	acc: 0.5981	macro: p 0.3652, r 0.3157, f1: 0.3187	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5517
global_step: 2081, epoch: 53, loss: 0.979371
global_step: 2082, epoch: 53, loss: 0.876981
global_step: 2083, epoch: 53, loss: 0.903801
global_step: 2084, epoch: 53, loss: 0.940867
global_step: 2085, epoch: 53, loss: 0.915310
global_step: 2086, epoch: 53, loss: 0.935223
global_step: 2087, epoch: 53, loss: 0.938333
global_step: 2088, epoch: 53, loss: 0.924842
global_step: 2089, epoch: 53, loss: 1.102615
global_step: 2090, epoch: 53, loss: 0.907965
global_step: 2091, epoch: 53, loss: 0.954080
global_step: 2092, epoch: 53, loss: 1.019232
global_step: 2093, epoch: 53, loss: 0.842111
global_step: 2094, epoch: 53, loss: 0.976899
global_step: 2095, epoch: 53, loss: 0.981331
global_step: 2096, epoch: 53, loss: 0.996406
global_step: 2097, epoch: 53, loss: 0.951546
global_step: 2098, epoch: 53, loss: 1.003222
global_step: 2099, epoch: 53, loss: 0.983858
global_step: 2100, epoch: 53, loss: 0.993841
global_step: 2101, epoch: 53, loss: 0.943610
global_step: 2102, epoch: 53, loss: 1.094845
global_step: 2103, epoch: 53, loss: 0.952565
global_step: 2104, epoch: 53, loss: 0.975528
global_step: 2105, epoch: 53, loss: 0.940403
global_step: 2106, epoch: 53, loss: 0.937346
global_step: 2107, epoch: 53, loss: 0.957141
global_step: 2108, epoch: 53, loss: 0.998661
global_step: 2109, epoch: 53, loss: 0.923865
global_step: 2110, epoch: 53, loss: 0.916995
global_step: 2111, epoch: 53, loss: 1.051535
global_step: 2112, epoch: 53, loss: 1.012785
global_step: 2113, epoch: 53, loss: 0.823877
global_step: 2114, epoch: 53, loss: 1.013436
global_step: 2115, epoch: 53, loss: 1.036844
global_step: 2116, epoch: 53, loss: 0.956696
global_step: 2117, epoch: 53, loss: 0.852636
global_step: 2118, epoch: 53, loss: 0.970919
global_step: 2119, epoch: 53, loss: 0.937936
global_step: 2120, epoch: 53, loss: 0.961005
epoch: 53
train	acc: 0.7478	macro: p 0.5159, r 0.4789, f1: 0.4860	micro: p 0.7478, r 0.7478, f1 0.7478	weighted_f1:0.7173
dev	acc: 0.5491	macro: p 0.3407, r 0.3113, f1: 0.3025	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4966
test	acc: 0.5996	macro: p 0.3635, r 0.3233, f1: 0.3214	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5558
global_step: 2121, epoch: 54, loss: 0.922387
global_step: 2122, epoch: 54, loss: 0.874954
global_step: 2123, epoch: 54, loss: 0.924218
global_step: 2124, epoch: 54, loss: 0.950930
global_step: 2125, epoch: 54, loss: 0.956073
global_step: 2126, epoch: 54, loss: 0.904829
global_step: 2127, epoch: 54, loss: 1.065485
global_step: 2128, epoch: 54, loss: 0.874108
global_step: 2129, epoch: 54, loss: 0.951677
global_step: 2130, epoch: 54, loss: 0.857245
global_step: 2131, epoch: 54, loss: 0.850170
global_step: 2132, epoch: 54, loss: 0.918612
global_step: 2133, epoch: 54, loss: 1.027016
global_step: 2134, epoch: 54, loss: 0.965019
global_step: 2135, epoch: 54, loss: 0.828123
global_step: 2136, epoch: 54, loss: 0.881214
global_step: 2137, epoch: 54, loss: 0.884607
global_step: 2138, epoch: 54, loss: 0.924858
global_step: 2139, epoch: 54, loss: 0.930860
global_step: 2140, epoch: 54, loss: 1.074616
global_step: 2141, epoch: 54, loss: 0.959015
global_step: 2142, epoch: 54, loss: 1.046419
global_step: 2143, epoch: 54, loss: 0.935194
global_step: 2144, epoch: 54, loss: 0.927792
global_step: 2145, epoch: 54, loss: 0.987139
global_step: 2146, epoch: 54, loss: 1.023974
global_step: 2147, epoch: 54, loss: 0.984104
global_step: 2148, epoch: 54, loss: 1.014048
global_step: 2149, epoch: 54, loss: 0.960262
global_step: 2150, epoch: 54, loss: 1.122007
global_step: 2151, epoch: 54, loss: 0.887146
global_step: 2152, epoch: 54, loss: 0.966265
global_step: 2153, epoch: 54, loss: 1.015959
global_step: 2154, epoch: 54, loss: 0.860211
global_step: 2155, epoch: 54, loss: 0.982469
global_step: 2156, epoch: 54, loss: 1.029109
global_step: 2157, epoch: 54, loss: 1.044438
global_step: 2158, epoch: 54, loss: 0.996423
global_step: 2159, epoch: 54, loss: 0.917425
global_step: 2160, epoch: 54, loss: 1.172271
epoch: 54
train	acc: 0.7489	macro: p 0.5151, r 0.4861, f1: 0.4955	micro: p 0.7489, r 0.7489, f1 0.7489	weighted_f1:0.7211
dev	acc: 0.5528	macro: p 0.3426, r 0.3108, f1: 0.3093	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5030
test	acc: 0.6023	macro: p 0.3635, r 0.3232, f1: 0.3290	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5608
global_step: 2161, epoch: 55, loss: 0.976636
global_step: 2162, epoch: 55, loss: 1.007815
global_step: 2163, epoch: 55, loss: 0.884600
global_step: 2164, epoch: 55, loss: 0.897846
global_step: 2165, epoch: 55, loss: 0.916683
global_step: 2166, epoch: 55, loss: 1.028368
global_step: 2167, epoch: 55, loss: 0.970386
global_step: 2168, epoch: 55, loss: 1.021558
global_step: 2169, epoch: 55, loss: 0.958987
global_step: 2170, epoch: 55, loss: 0.851074
global_step: 2171, epoch: 55, loss: 1.004389
global_step: 2172, epoch: 55, loss: 0.916139
global_step: 2173, epoch: 55, loss: 0.844661
global_step: 2174, epoch: 55, loss: 0.920663
global_step: 2175, epoch: 55, loss: 1.071023
global_step: 2176, epoch: 55, loss: 0.976650
global_step: 2177, epoch: 55, loss: 0.995138
global_step: 2178, epoch: 55, loss: 0.944730
global_step: 2179, epoch: 55, loss: 0.942271
global_step: 2180, epoch: 55, loss: 0.884787
global_step: 2181, epoch: 55, loss: 0.947449
global_step: 2182, epoch: 55, loss: 1.089920
global_step: 2183, epoch: 55, loss: 0.960221
global_step: 2184, epoch: 55, loss: 0.876206
global_step: 2185, epoch: 55, loss: 0.890782
global_step: 2186, epoch: 55, loss: 0.873765
global_step: 2187, epoch: 55, loss: 0.939215
global_step: 2188, epoch: 55, loss: 0.968015
global_step: 2189, epoch: 55, loss: 0.904747
global_step: 2190, epoch: 55, loss: 0.863536
global_step: 2191, epoch: 55, loss: 0.968042
global_step: 2192, epoch: 55, loss: 0.994853
global_step: 2193, epoch: 55, loss: 0.998758
global_step: 2194, epoch: 55, loss: 0.890418
global_step: 2195, epoch: 55, loss: 0.936953
global_step: 2196, epoch: 55, loss: 0.862860
global_step: 2197, epoch: 55, loss: 0.922261
global_step: 2198, epoch: 55, loss: 0.969951
global_step: 2199, epoch: 55, loss: 0.935392
global_step: 2200, epoch: 55, loss: 0.763051
epoch: 55
train	acc: 0.7428	macro: p 0.5238, r 0.4684, f1: 0.4818	micro: p 0.7428, r 0.7428, f1 0.7428	weighted_f1:0.7108
dev	acc: 0.5528	macro: p 0.3411, r 0.3042, f1: 0.2942	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4918
test	acc: 0.6004	macro: p 0.3686, r 0.3150, f1: 0.3163	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5518
global_step: 2201, epoch: 56, loss: 0.963095
global_step: 2202, epoch: 56, loss: 0.970387
global_step: 2203, epoch: 56, loss: 0.948807
global_step: 2204, epoch: 56, loss: 0.980912
global_step: 2205, epoch: 56, loss: 0.861345
global_step: 2206, epoch: 56, loss: 0.875895
global_step: 2207, epoch: 56, loss: 0.868602
global_step: 2208, epoch: 56, loss: 0.973359
global_step: 2209, epoch: 56, loss: 0.822398
global_step: 2210, epoch: 56, loss: 0.938331
global_step: 2211, epoch: 56, loss: 0.885079
global_step: 2212, epoch: 56, loss: 1.030669
global_step: 2213, epoch: 56, loss: 0.953694
global_step: 2214, epoch: 56, loss: 0.915307
global_step: 2215, epoch: 56, loss: 0.888108
global_step: 2216, epoch: 56, loss: 0.892703
global_step: 2217, epoch: 56, loss: 0.954229
global_step: 2218, epoch: 56, loss: 0.880398
global_step: 2219, epoch: 56, loss: 0.926668
global_step: 2220, epoch: 56, loss: 0.886230
global_step: 2221, epoch: 56, loss: 0.927136
global_step: 2222, epoch: 56, loss: 1.048281
global_step: 2223, epoch: 56, loss: 0.914878
global_step: 2224, epoch: 56, loss: 0.936465
global_step: 2225, epoch: 56, loss: 0.970235
global_step: 2226, epoch: 56, loss: 0.912680
global_step: 2227, epoch: 56, loss: 0.980793
global_step: 2228, epoch: 56, loss: 0.918285
global_step: 2229, epoch: 56, loss: 1.011217
global_step: 2230, epoch: 56, loss: 0.939023
global_step: 2231, epoch: 56, loss: 0.992053
global_step: 2232, epoch: 56, loss: 1.062969
global_step: 2233, epoch: 56, loss: 0.922374
global_step: 2234, epoch: 56, loss: 0.967715
global_step: 2235, epoch: 56, loss: 0.855222
global_step: 2236, epoch: 56, loss: 0.981275
global_step: 2237, epoch: 56, loss: 0.865626
global_step: 2238, epoch: 56, loss: 0.932139
global_step: 2239, epoch: 56, loss: 0.929422
global_step: 2240, epoch: 56, loss: 0.667553
epoch: 56
train	acc: 0.7511	macro: p 0.5260, r 0.4842, f1: 0.4964	micro: p 0.7511, r 0.7511, f1 0.7511	weighted_f1:0.7222
dev	acc: 0.5473	macro: p 0.3312, r 0.3010, f1: 0.2967	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4926
test	acc: 0.6042	macro: p 0.3696, r 0.3211, f1: 0.3268	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5602
global_step: 2241, epoch: 57, loss: 0.914871
global_step: 2242, epoch: 57, loss: 0.912329
global_step: 2243, epoch: 57, loss: 0.915236
global_step: 2244, epoch: 57, loss: 0.946872
global_step: 2245, epoch: 57, loss: 0.936642
global_step: 2246, epoch: 57, loss: 0.967738
global_step: 2247, epoch: 57, loss: 0.948605
global_step: 2248, epoch: 57, loss: 0.945319
global_step: 2249, epoch: 57, loss: 0.939062
global_step: 2250, epoch: 57, loss: 0.958283
global_step: 2251, epoch: 57, loss: 0.936203
global_step: 2252, epoch: 57, loss: 0.953649
global_step: 2253, epoch: 57, loss: 0.946070
global_step: 2254, epoch: 57, loss: 0.899692
global_step: 2255, epoch: 57, loss: 0.859964
global_step: 2256, epoch: 57, loss: 0.976596
global_step: 2257, epoch: 57, loss: 0.965085
global_step: 2258, epoch: 57, loss: 0.896134
global_step: 2259, epoch: 57, loss: 1.000057
global_step: 2260, epoch: 57, loss: 0.867305
global_step: 2261, epoch: 57, loss: 0.900145
global_step: 2262, epoch: 57, loss: 0.925945
global_step: 2263, epoch: 57, loss: 0.877337
global_step: 2264, epoch: 57, loss: 0.825098
global_step: 2265, epoch: 57, loss: 0.950229
global_step: 2266, epoch: 57, loss: 0.891346
global_step: 2267, epoch: 57, loss: 0.863468
global_step: 2268, epoch: 57, loss: 0.903853
global_step: 2269, epoch: 57, loss: 0.945606
global_step: 2270, epoch: 57, loss: 1.064101
global_step: 2271, epoch: 57, loss: 0.866812
global_step: 2272, epoch: 57, loss: 0.871447
global_step: 2273, epoch: 57, loss: 0.963426
global_step: 2274, epoch: 57, loss: 0.921059
global_step: 2275, epoch: 57, loss: 1.020917
global_step: 2276, epoch: 57, loss: 0.850915
global_step: 2277, epoch: 57, loss: 0.979286
global_step: 2278, epoch: 57, loss: 0.853455
global_step: 2279, epoch: 57, loss: 0.879202
global_step: 2280, epoch: 57, loss: 1.112301
epoch: 57
train	acc: 0.7624	macro: p 0.5266, r 0.4983, f1: 0.5057	micro: p 0.7624, r 0.7624, f1 0.7624	weighted_f1:0.7336
dev	acc: 0.5564	macro: p 0.3406, r 0.3131, f1: 0.3090	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.5039
test	acc: 0.6008	macro: p 0.3602, r 0.3208, f1: 0.3235	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5569
global_step: 2281, epoch: 58, loss: 0.889547
global_step: 2282, epoch: 58, loss: 0.846052
global_step: 2283, epoch: 58, loss: 0.942793
global_step: 2284, epoch: 58, loss: 0.894008
global_step: 2285, epoch: 58, loss: 0.844029
global_step: 2286, epoch: 58, loss: 0.981955
global_step: 2287, epoch: 58, loss: 0.865006
global_step: 2288, epoch: 58, loss: 0.926144
global_step: 2289, epoch: 58, loss: 0.847607
global_step: 2290, epoch: 58, loss: 0.873086
global_step: 2291, epoch: 58, loss: 0.948946
global_step: 2292, epoch: 58, loss: 1.068215
global_step: 2293, epoch: 58, loss: 0.902005
global_step: 2294, epoch: 58, loss: 0.999568
global_step: 2295, epoch: 58, loss: 0.918667
global_step: 2296, epoch: 58, loss: 0.842892
global_step: 2297, epoch: 58, loss: 0.899100
global_step: 2298, epoch: 58, loss: 0.838535
global_step: 2299, epoch: 58, loss: 0.915899
global_step: 2300, epoch: 58, loss: 0.901562
global_step: 2301, epoch: 58, loss: 0.917365
global_step: 2302, epoch: 58, loss: 0.907703
global_step: 2303, epoch: 58, loss: 0.935525
global_step: 2304, epoch: 58, loss: 0.827094
global_step: 2305, epoch: 58, loss: 0.951718
global_step: 2306, epoch: 58, loss: 0.826979
global_step: 2307, epoch: 58, loss: 0.977358
global_step: 2308, epoch: 58, loss: 0.926691
global_step: 2309, epoch: 58, loss: 0.965385
global_step: 2310, epoch: 58, loss: 0.973446
global_step: 2311, epoch: 58, loss: 0.835013
global_step: 2312, epoch: 58, loss: 1.019587
global_step: 2313, epoch: 58, loss: 0.932897
global_step: 2314, epoch: 58, loss: 0.966615
global_step: 2315, epoch: 58, loss: 0.989458
global_step: 2316, epoch: 58, loss: 0.961636
global_step: 2317, epoch: 58, loss: 0.888098
global_step: 2318, epoch: 58, loss: 0.938383
global_step: 2319, epoch: 58, loss: 0.856685
global_step: 2320, epoch: 58, loss: 0.760828
epoch: 58
train	acc: 0.7400	macro: p 0.5307, r 0.4635, f1: 0.4816	micro: p 0.7400, r 0.7400, f1 0.7400	weighted_f1:0.7074
dev	acc: 0.5500	macro: p 0.3403, r 0.2981, f1: 0.2923	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4886
test	acc: 0.6046	macro: p 0.3796, r 0.3150, f1: 0.3212	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5551
global_step: 2321, epoch: 59, loss: 0.943369
global_step: 2322, epoch: 59, loss: 1.011786
global_step: 2323, epoch: 59, loss: 0.941776
global_step: 2324, epoch: 59, loss: 0.800565
global_step: 2325, epoch: 59, loss: 0.941956
global_step: 2326, epoch: 59, loss: 0.912412
global_step: 2327, epoch: 59, loss: 0.956720
global_step: 2328, epoch: 59, loss: 0.921605
global_step: 2329, epoch: 59, loss: 0.942638
global_step: 2330, epoch: 59, loss: 0.848517
global_step: 2331, epoch: 59, loss: 0.749786
global_step: 2332, epoch: 59, loss: 0.961244
global_step: 2333, epoch: 59, loss: 0.927004
global_step: 2334, epoch: 59, loss: 0.871283
global_step: 2335, epoch: 59, loss: 0.815256
global_step: 2336, epoch: 59, loss: 0.976906
global_step: 2337, epoch: 59, loss: 0.855202
global_step: 2338, epoch: 59, loss: 0.901672
global_step: 2339, epoch: 59, loss: 0.869249
global_step: 2340, epoch: 59, loss: 0.816797
global_step: 2341, epoch: 59, loss: 0.912042
global_step: 2342, epoch: 59, loss: 0.982866
global_step: 2343, epoch: 59, loss: 0.940907
global_step: 2344, epoch: 59, loss: 0.944475
global_step: 2345, epoch: 59, loss: 0.947461
global_step: 2346, epoch: 59, loss: 0.921991
global_step: 2347, epoch: 59, loss: 0.874961
global_step: 2348, epoch: 59, loss: 0.871746
global_step: 2349, epoch: 59, loss: 0.803818
global_step: 2350, epoch: 59, loss: 0.980304
global_step: 2351, epoch: 59, loss: 0.897057
global_step: 2352, epoch: 59, loss: 0.884203
global_step: 2353, epoch: 59, loss: 0.996803
global_step: 2354, epoch: 59, loss: 0.960620
global_step: 2355, epoch: 59, loss: 0.916524
global_step: 2356, epoch: 59, loss: 0.793514
global_step: 2357, epoch: 59, loss: 0.990016
global_step: 2358, epoch: 59, loss: 0.943756
global_step: 2359, epoch: 59, loss: 0.858987
global_step: 2360, epoch: 59, loss: 1.099534
epoch: 59
train	acc: 0.7602	macro: p 0.5321, r 0.4940, f1: 0.5056	micro: p 0.7602, r 0.7602, f1 0.7602	weighted_f1:0.7319
dev	acc: 0.5518	macro: p 0.3415, r 0.3070, f1: 0.3019	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4970
test	acc: 0.6008	macro: p 0.3657, r 0.3180, f1: 0.3209	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5549
global_step: 2361, epoch: 60, loss: 1.009497
global_step: 2362, epoch: 60, loss: 0.874634
global_step: 2363, epoch: 60, loss: 0.931903
global_step: 2364, epoch: 60, loss: 0.918772
global_step: 2365, epoch: 60, loss: 0.979315
global_step: 2366, epoch: 60, loss: 0.925244
global_step: 2367, epoch: 60, loss: 0.849504
global_step: 2368, epoch: 60, loss: 0.895890
global_step: 2369, epoch: 60, loss: 0.882908
global_step: 2370, epoch: 60, loss: 0.853440
global_step: 2371, epoch: 60, loss: 0.896859
global_step: 2372, epoch: 60, loss: 0.802149
global_step: 2373, epoch: 60, loss: 0.833331
global_step: 2374, epoch: 60, loss: 0.836868
global_step: 2375, epoch: 60, loss: 0.841352
global_step: 2376, epoch: 60, loss: 0.923803
global_step: 2377, epoch: 60, loss: 0.942681
global_step: 2378, epoch: 60, loss: 0.911311
global_step: 2379, epoch: 60, loss: 0.843841
global_step: 2380, epoch: 60, loss: 0.892396
global_step: 2381, epoch: 60, loss: 0.961293
global_step: 2382, epoch: 60, loss: 0.844393
global_step: 2383, epoch: 60, loss: 0.910821
global_step: 2384, epoch: 60, loss: 0.910606
global_step: 2385, epoch: 60, loss: 0.915696
global_step: 2386, epoch: 60, loss: 0.920878
global_step: 2387, epoch: 60, loss: 0.896001
global_step: 2388, epoch: 60, loss: 0.885902
global_step: 2389, epoch: 60, loss: 0.844396
global_step: 2390, epoch: 60, loss: 0.837227
global_step: 2391, epoch: 60, loss: 0.889915
global_step: 2392, epoch: 60, loss: 0.860951
global_step: 2393, epoch: 60, loss: 0.817112
global_step: 2394, epoch: 60, loss: 0.933226
global_step: 2395, epoch: 60, loss: 0.918243
global_step: 2396, epoch: 60, loss: 0.849970
global_step: 2397, epoch: 60, loss: 0.758456
global_step: 2398, epoch: 60, loss: 0.893193
global_step: 2399, epoch: 60, loss: 0.822653
global_step: 2400, epoch: 60, loss: 0.353452
epoch: 60
train	acc: 0.7522	macro: p 0.5364, r 0.4800, f1: 0.4967	micro: p 0.7522, r 0.7522, f1 0.7522	weighted_f1:0.7217
dev	acc: 0.5500	macro: p 0.3316, r 0.2978, f1: 0.2903	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4878
test	acc: 0.6027	macro: p 0.3751, r 0.3153, f1: 0.3204	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5541
global_step: 2401, epoch: 61, loss: 0.866269
global_step: 2402, epoch: 61, loss: 1.006622
global_step: 2403, epoch: 61, loss: 0.869032
global_step: 2404, epoch: 61, loss: 0.817383
global_step: 2405, epoch: 61, loss: 0.835176
global_step: 2406, epoch: 61, loss: 0.880728
global_step: 2407, epoch: 61, loss: 0.790459
global_step: 2408, epoch: 61, loss: 1.001688
global_step: 2409, epoch: 61, loss: 0.999015
global_step: 2410, epoch: 61, loss: 0.905473
global_step: 2411, epoch: 61, loss: 0.850032
global_step: 2412, epoch: 61, loss: 0.892204
global_step: 2413, epoch: 61, loss: 0.897208
global_step: 2414, epoch: 61, loss: 0.769906
global_step: 2415, epoch: 61, loss: 0.862115
global_step: 2416, epoch: 61, loss: 0.906528
global_step: 2417, epoch: 61, loss: 0.865978
global_step: 2418, epoch: 61, loss: 0.915546
global_step: 2419, epoch: 61, loss: 0.796662
global_step: 2420, epoch: 61, loss: 0.801221
global_step: 2421, epoch: 61, loss: 0.899505
global_step: 2422, epoch: 61, loss: 0.919849
global_step: 2423, epoch: 61, loss: 0.915545
global_step: 2424, epoch: 61, loss: 0.828283
global_step: 2425, epoch: 61, loss: 0.848166
global_step: 2426, epoch: 61, loss: 0.932690
global_step: 2427, epoch: 61, loss: 0.772985
global_step: 2428, epoch: 61, loss: 0.951127
global_step: 2429, epoch: 61, loss: 0.951344
global_step: 2430, epoch: 61, loss: 0.818168
global_step: 2431, epoch: 61, loss: 0.957252
global_step: 2432, epoch: 61, loss: 0.831205
global_step: 2433, epoch: 61, loss: 0.838143
global_step: 2434, epoch: 61, loss: 0.995046
global_step: 2435, epoch: 61, loss: 0.909380
global_step: 2436, epoch: 61, loss: 0.993902
global_step: 2437, epoch: 61, loss: 0.887995
global_step: 2438, epoch: 61, loss: 0.861769
global_step: 2439, epoch: 61, loss: 0.982534
global_step: 2440, epoch: 61, loss: 0.484883
epoch: 61
train	acc: 0.7683	macro: p 0.5402, r 0.4999, f1: 0.5099	micro: p 0.7683, r 0.7683, f1 0.7683	weighted_f1:0.7396
dev	acc: 0.5482	macro: p 0.3401, r 0.3013, f1: 0.2938	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4905
test	acc: 0.6004	macro: p 0.3708, r 0.3162, f1: 0.3189	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5544
global_step: 2441, epoch: 62, loss: 0.868739
global_step: 2442, epoch: 62, loss: 0.976549
global_step: 2443, epoch: 62, loss: 0.985870
global_step: 2444, epoch: 62, loss: 0.769624
global_step: 2445, epoch: 62, loss: 0.884014
global_step: 2446, epoch: 62, loss: 0.934433
global_step: 2447, epoch: 62, loss: 0.812456
global_step: 2448, epoch: 62, loss: 0.959854
global_step: 2449, epoch: 62, loss: 0.859783
global_step: 2450, epoch: 62, loss: 0.864390
global_step: 2451, epoch: 62, loss: 1.035145
global_step: 2452, epoch: 62, loss: 0.990666
global_step: 2453, epoch: 62, loss: 0.889310
global_step: 2454, epoch: 62, loss: 0.778080
global_step: 2455, epoch: 62, loss: 0.957462
global_step: 2456, epoch: 62, loss: 0.860623
global_step: 2457, epoch: 62, loss: 0.863955
global_step: 2458, epoch: 62, loss: 0.889431
global_step: 2459, epoch: 62, loss: 0.860989
global_step: 2460, epoch: 62, loss: 0.896998
global_step: 2461, epoch: 62, loss: 0.806467
global_step: 2462, epoch: 62, loss: 0.812948
global_step: 2463, epoch: 62, loss: 0.901986
global_step: 2464, epoch: 62, loss: 0.918212
global_step: 2465, epoch: 62, loss: 0.809020
global_step: 2466, epoch: 62, loss: 0.926594
global_step: 2467, epoch: 62, loss: 0.897987
global_step: 2468, epoch: 62, loss: 0.882686
global_step: 2469, epoch: 62, loss: 0.880053
global_step: 2470, epoch: 62, loss: 0.813725
global_step: 2471, epoch: 62, loss: 1.031057
global_step: 2472, epoch: 62, loss: 0.895661
global_step: 2473, epoch: 62, loss: 0.891715
global_step: 2474, epoch: 62, loss: 1.024797
global_step: 2475, epoch: 62, loss: 0.821949
global_step: 2476, epoch: 62, loss: 0.795416
global_step: 2477, epoch: 62, loss: 0.881824
global_step: 2478, epoch: 62, loss: 0.944983
global_step: 2479, epoch: 62, loss: 0.942627
global_step: 2480, epoch: 62, loss: 1.101274
epoch: 62
train	acc: 0.7865	macro: p 0.5411, r 0.5306, f1: 0.5326	micro: p 0.7865, r 0.7865, f1 0.7865	weighted_f1:0.7612
dev	acc: 0.5455	macro: p 0.3348, r 0.3110, f1: 0.3045	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4968
test	acc: 0.6004	macro: p 0.3679, r 0.3245, f1: 0.3268	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5591
global_step: 2481, epoch: 63, loss: 0.849734
global_step: 2482, epoch: 63, loss: 0.932338
global_step: 2483, epoch: 63, loss: 0.879538
global_step: 2484, epoch: 63, loss: 0.897819
global_step: 2485, epoch: 63, loss: 0.912438
global_step: 2486, epoch: 63, loss: 0.810582
global_step: 2487, epoch: 63, loss: 0.782729
global_step: 2488, epoch: 63, loss: 0.861599
global_step: 2489, epoch: 63, loss: 0.927231
global_step: 2490, epoch: 63, loss: 0.840097
global_step: 2491, epoch: 63, loss: 0.873171
global_step: 2492, epoch: 63, loss: 0.875420
global_step: 2493, epoch: 63, loss: 0.876397
global_step: 2494, epoch: 63, loss: 0.871010
global_step: 2495, epoch: 63, loss: 0.811282
global_step: 2496, epoch: 63, loss: 0.923150
global_step: 2497, epoch: 63, loss: 0.939488
global_step: 2498, epoch: 63, loss: 0.801392
global_step: 2499, epoch: 63, loss: 0.834747
global_step: 2500, epoch: 63, loss: 0.954220
global_step: 2501, epoch: 63, loss: 0.886553
global_step: 2502, epoch: 63, loss: 0.939026
global_step: 2503, epoch: 63, loss: 0.951283
global_step: 2504, epoch: 63, loss: 0.922977
global_step: 2505, epoch: 63, loss: 0.774896
global_step: 2506, epoch: 63, loss: 0.911871
global_step: 2507, epoch: 63, loss: 0.841808
global_step: 2508, epoch: 63, loss: 0.896771
global_step: 2509, epoch: 63, loss: 0.846822
global_step: 2510, epoch: 63, loss: 0.859385
global_step: 2511, epoch: 63, loss: 0.940991
global_step: 2512, epoch: 63, loss: 0.836732
global_step: 2513, epoch: 63, loss: 0.855086
global_step: 2514, epoch: 63, loss: 0.776054
global_step: 2515, epoch: 63, loss: 0.894318
global_step: 2516, epoch: 63, loss: 0.883852
global_step: 2517, epoch: 63, loss: 0.901437
global_step: 2518, epoch: 63, loss: 0.845151
global_step: 2519, epoch: 63, loss: 0.939574
global_step: 2520, epoch: 63, loss: 0.395640
epoch: 63
train	acc: 0.7849	macro: p 0.5417, r 0.5264, f1: 0.5310	micro: p 0.7849, r 0.7849, f1 0.7849	weighted_f1:0.7587
dev	acc: 0.5482	macro: p 0.3388, r 0.3075, f1: 0.3032	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4967
test	acc: 0.5996	macro: p 0.3617, r 0.3199, f1: 0.3239	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5561
global_step: 2521, epoch: 64, loss: 0.843672
global_step: 2522, epoch: 64, loss: 0.875423
global_step: 2523, epoch: 64, loss: 0.774632
global_step: 2524, epoch: 64, loss: 1.005165
global_step: 2525, epoch: 64, loss: 0.858440
global_step: 2526, epoch: 64, loss: 0.700688
global_step: 2527, epoch: 64, loss: 0.805293
global_step: 2528, epoch: 64, loss: 0.802259
global_step: 2529, epoch: 64, loss: 0.945945
global_step: 2530, epoch: 64, loss: 0.888768
global_step: 2531, epoch: 64, loss: 0.849515
global_step: 2532, epoch: 64, loss: 0.919793
global_step: 2533, epoch: 64, loss: 0.901597
global_step: 2534, epoch: 64, loss: 0.813540
global_step: 2535, epoch: 64, loss: 0.871015
global_step: 2536, epoch: 64, loss: 0.915992
global_step: 2537, epoch: 64, loss: 0.831859
global_step: 2538, epoch: 64, loss: 0.989675
global_step: 2539, epoch: 64, loss: 0.933926
global_step: 2540, epoch: 64, loss: 0.922145
global_step: 2541, epoch: 64, loss: 0.868954
global_step: 2542, epoch: 64, loss: 0.911818
global_step: 2543, epoch: 64, loss: 0.798956
global_step: 2544, epoch: 64, loss: 0.935312
global_step: 2545, epoch: 64, loss: 0.781656
global_step: 2546, epoch: 64, loss: 0.699693
global_step: 2547, epoch: 64, loss: 0.764817
global_step: 2548, epoch: 64, loss: 0.948007
global_step: 2549, epoch: 64, loss: 0.916908
global_step: 2550, epoch: 64, loss: 0.912545
global_step: 2551, epoch: 64, loss: 0.842310
global_step: 2552, epoch: 64, loss: 0.926612
global_step: 2553, epoch: 64, loss: 0.972639
global_step: 2554, epoch: 64, loss: 0.855998
global_step: 2555, epoch: 64, loss: 0.908567
global_step: 2556, epoch: 64, loss: 0.959921
global_step: 2557, epoch: 64, loss: 0.835305
global_step: 2558, epoch: 64, loss: 0.872539
global_step: 2559, epoch: 64, loss: 0.900937
global_step: 2560, epoch: 64, loss: 0.421387
epoch: 64
train	acc: 0.7864	macro: p 0.5498, r 0.5248, f1: 0.5311	micro: p 0.7864, r 0.7864, f1 0.7864	weighted_f1:0.7591
dev	acc: 0.5473	macro: p 0.3383, r 0.3021, f1: 0.2996	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4947
test	acc: 0.6034	macro: p 0.3678, r 0.3214, f1: 0.3259	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5593
global_step: 2561, epoch: 65, loss: 0.906389
global_step: 2562, epoch: 65, loss: 0.847888
global_step: 2563, epoch: 65, loss: 0.763580
global_step: 2564, epoch: 65, loss: 0.818721
global_step: 2565, epoch: 65, loss: 0.863558
global_step: 2566, epoch: 65, loss: 0.775123
global_step: 2567, epoch: 65, loss: 0.832276
global_step: 2568, epoch: 65, loss: 0.751239
global_step: 2569, epoch: 65, loss: 0.976470
global_step: 2570, epoch: 65, loss: 0.854338
global_step: 2571, epoch: 65, loss: 0.846642
global_step: 2572, epoch: 65, loss: 0.915616
global_step: 2573, epoch: 65, loss: 0.881939
global_step: 2574, epoch: 65, loss: 0.797076
global_step: 2575, epoch: 65, loss: 1.003369
global_step: 2576, epoch: 65, loss: 0.747471
global_step: 2577, epoch: 65, loss: 0.916197
global_step: 2578, epoch: 65, loss: 0.820462
global_step: 2579, epoch: 65, loss: 0.869944
global_step: 2580, epoch: 65, loss: 0.851334
global_step: 2581, epoch: 65, loss: 1.006643
global_step: 2582, epoch: 65, loss: 0.772748
global_step: 2583, epoch: 65, loss: 0.889605
global_step: 2584, epoch: 65, loss: 0.904047
global_step: 2585, epoch: 65, loss: 0.813541
global_step: 2586, epoch: 65, loss: 0.908396
global_step: 2587, epoch: 65, loss: 0.740993
global_step: 2588, epoch: 65, loss: 0.858319
global_step: 2589, epoch: 65, loss: 0.835834
global_step: 2590, epoch: 65, loss: 0.826381
global_step: 2591, epoch: 65, loss: 0.800987
global_step: 2592, epoch: 65, loss: 0.892495
global_step: 2593, epoch: 65, loss: 0.898216
global_step: 2594, epoch: 65, loss: 0.876300
global_step: 2595, epoch: 65, loss: 0.914047
global_step: 2596, epoch: 65, loss: 0.824208
global_step: 2597, epoch: 65, loss: 0.884116
global_step: 2598, epoch: 65, loss: 1.007808
global_step: 2599, epoch: 65, loss: 0.862455
global_step: 2600, epoch: 65, loss: 1.220436
epoch: 65
train	acc: 0.8021	macro: p 0.5456, r 0.5535, f1: 0.5485	micro: p 0.8021, r 0.8021, f1 0.8021	weighted_f1:0.7780
dev	acc: 0.5455	macro: p 0.3285, r 0.3111, f1: 0.3056	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4989
test	acc: 0.5985	macro: p 0.3586, r 0.3269, f1: 0.3292	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5605
global_step: 2601, epoch: 66, loss: 0.913975
global_step: 2602, epoch: 66, loss: 0.837168
global_step: 2603, epoch: 66, loss: 0.869447
global_step: 2604, epoch: 66, loss: 0.829527
global_step: 2605, epoch: 66, loss: 0.841151
global_step: 2606, epoch: 66, loss: 0.820959
global_step: 2607, epoch: 66, loss: 0.869906
global_step: 2608, epoch: 66, loss: 0.902209
global_step: 2609, epoch: 66, loss: 0.914411
global_step: 2610, epoch: 66, loss: 0.777118
global_step: 2611, epoch: 66, loss: 0.871195
global_step: 2612, epoch: 66, loss: 0.856303
global_step: 2613, epoch: 66, loss: 0.754514
global_step: 2614, epoch: 66, loss: 0.912520
global_step: 2615, epoch: 66, loss: 0.827574
global_step: 2616, epoch: 66, loss: 0.887885
global_step: 2617, epoch: 66, loss: 0.864214
global_step: 2618, epoch: 66, loss: 0.861933
global_step: 2619, epoch: 66, loss: 0.853539
global_step: 2620, epoch: 66, loss: 0.864691
global_step: 2621, epoch: 66, loss: 0.867028
global_step: 2622, epoch: 66, loss: 0.860021
global_step: 2623, epoch: 66, loss: 0.718415
global_step: 2624, epoch: 66, loss: 0.872695
global_step: 2625, epoch: 66, loss: 0.759532
global_step: 2626, epoch: 66, loss: 0.860267
global_step: 2627, epoch: 66, loss: 1.004096
global_step: 2628, epoch: 66, loss: 0.950642
global_step: 2629, epoch: 66, loss: 0.887506
global_step: 2630, epoch: 66, loss: 0.844222
global_step: 2631, epoch: 66, loss: 0.920810
global_step: 2632, epoch: 66, loss: 0.770982
global_step: 2633, epoch: 66, loss: 0.873805
global_step: 2634, epoch: 66, loss: 0.900831
global_step: 2635, epoch: 66, loss: 0.941356
global_step: 2636, epoch: 66, loss: 0.842588
global_step: 2637, epoch: 66, loss: 0.851715
global_step: 2638, epoch: 66, loss: 0.873491
global_step: 2639, epoch: 66, loss: 0.846443
global_step: 2640, epoch: 66, loss: 0.319601
epoch: 66
train	acc: 0.7882	macro: p 0.7002, r 0.5228, f1: 0.5331	micro: p 0.7882, r 0.7882, f1 0.7882	weighted_f1:0.7602
dev	acc: 0.5464	macro: p 0.3473, r 0.2992, f1: 0.2925	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4877
test	acc: 0.6031	macro: p 0.3755, r 0.3172, f1: 0.3209	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5559
global_step: 2641, epoch: 67, loss: 0.832855
global_step: 2642, epoch: 67, loss: 0.786596
global_step: 2643, epoch: 67, loss: 0.840287
global_step: 2644, epoch: 67, loss: 0.857532
global_step: 2645, epoch: 67, loss: 0.843024
global_step: 2646, epoch: 67, loss: 0.810609
global_step: 2647, epoch: 67, loss: 0.775727
global_step: 2648, epoch: 67, loss: 0.807516
global_step: 2649, epoch: 67, loss: 0.786518
global_step: 2650, epoch: 67, loss: 0.992825
global_step: 2651, epoch: 67, loss: 0.883253
global_step: 2652, epoch: 67, loss: 0.933527
global_step: 2653, epoch: 67, loss: 0.883647
global_step: 2654, epoch: 67, loss: 0.797988
global_step: 2655, epoch: 67, loss: 0.867874
global_step: 2656, epoch: 67, loss: 0.820985
global_step: 2657, epoch: 67, loss: 0.887988
global_step: 2658, epoch: 67, loss: 0.907892
global_step: 2659, epoch: 67, loss: 0.780319
global_step: 2660, epoch: 67, loss: 0.963512
global_step: 2661, epoch: 67, loss: 0.737678
global_step: 2662, epoch: 67, loss: 0.857018
global_step: 2663, epoch: 67, loss: 0.890936
global_step: 2664, epoch: 67, loss: 0.834819
global_step: 2665, epoch: 67, loss: 0.885297
global_step: 2666, epoch: 67, loss: 0.852656
global_step: 2667, epoch: 67, loss: 0.756160
global_step: 2668, epoch: 67, loss: 0.787241
global_step: 2669, epoch: 67, loss: 0.830040
global_step: 2670, epoch: 67, loss: 0.885848
global_step: 2671, epoch: 67, loss: 0.856717
global_step: 2672, epoch: 67, loss: 0.801686
global_step: 2673, epoch: 67, loss: 0.931476
global_step: 2674, epoch: 67, loss: 0.855439
global_step: 2675, epoch: 67, loss: 0.780465
global_step: 2676, epoch: 67, loss: 0.906554
global_step: 2677, epoch: 67, loss: 0.826095
global_step: 2678, epoch: 67, loss: 0.824629
global_step: 2679, epoch: 67, loss: 0.678989
global_step: 2680, epoch: 67, loss: 1.074449
epoch: 67
train	acc: 0.7883	macro: p 0.6999, r 0.5240, f1: 0.5359	micro: p 0.7883, r 0.7883, f1 0.7883	weighted_f1:0.7606
dev	acc: 0.5473	macro: p 0.3407, r 0.2974, f1: 0.2915	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4871
test	acc: 0.6004	macro: p 0.3701, r 0.3128, f1: 0.3185	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5510
global_step: 2681, epoch: 68, loss: 0.856789
global_step: 2682, epoch: 68, loss: 0.924074
global_step: 2683, epoch: 68, loss: 0.837762
global_step: 2684, epoch: 68, loss: 0.806052
global_step: 2685, epoch: 68, loss: 0.809568
global_step: 2686, epoch: 68, loss: 0.840852
global_step: 2687, epoch: 68, loss: 0.852323
global_step: 2688, epoch: 68, loss: 0.735738
global_step: 2689, epoch: 68, loss: 0.845543
global_step: 2690, epoch: 68, loss: 0.895975
global_step: 2691, epoch: 68, loss: 0.824190
global_step: 2692, epoch: 68, loss: 0.859823
global_step: 2693, epoch: 68, loss: 0.877117
global_step: 2694, epoch: 68, loss: 0.825115
global_step: 2695, epoch: 68, loss: 0.874741
global_step: 2696, epoch: 68, loss: 0.731283
global_step: 2697, epoch: 68, loss: 0.831630
global_step: 2698, epoch: 68, loss: 0.756196
global_step: 2699, epoch: 68, loss: 0.816067
global_step: 2700, epoch: 68, loss: 0.794562
global_step: 2701, epoch: 68, loss: 0.832349
global_step: 2702, epoch: 68, loss: 0.869876
global_step: 2703, epoch: 68, loss: 0.914395
global_step: 2704, epoch: 68, loss: 0.891224
global_step: 2705, epoch: 68, loss: 0.847838
global_step: 2706, epoch: 68, loss: 0.810110
global_step: 2707, epoch: 68, loss: 0.825556
global_step: 2708, epoch: 68, loss: 0.873747
global_step: 2709, epoch: 68, loss: 0.890774
global_step: 2710, epoch: 68, loss: 0.850792
global_step: 2711, epoch: 68, loss: 0.891359
global_step: 2712, epoch: 68, loss: 0.736094
global_step: 2713, epoch: 68, loss: 0.791673
global_step: 2714, epoch: 68, loss: 0.861840
global_step: 2715, epoch: 68, loss: 0.822534
global_step: 2716, epoch: 68, loss: 0.886891
global_step: 2717, epoch: 68, loss: 0.822431
global_step: 2718, epoch: 68, loss: 0.830881
global_step: 2719, epoch: 68, loss: 0.812087
global_step: 2720, epoch: 68, loss: 0.487980
epoch: 68
train	acc: 0.7946	macro: p 0.7011, r 0.5326, f1: 0.5409	micro: p 0.7946, r 0.7946, f1 0.7946	weighted_f1:0.7677
dev	acc: 0.5464	macro: p 0.3383, r 0.2990, f1: 0.2936	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4894
test	acc: 0.6038	macro: p 0.3733, r 0.3197, f1: 0.3247	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5585
global_step: 2721, epoch: 69, loss: 0.799449
global_step: 2722, epoch: 69, loss: 0.764059
global_step: 2723, epoch: 69, loss: 0.847419
global_step: 2724, epoch: 69, loss: 0.745707
global_step: 2725, epoch: 69, loss: 0.918923
global_step: 2726, epoch: 69, loss: 0.895915
global_step: 2727, epoch: 69, loss: 0.808874
global_step: 2728, epoch: 69, loss: 0.780826
global_step: 2729, epoch: 69, loss: 0.779651
global_step: 2730, epoch: 69, loss: 0.749885
global_step: 2731, epoch: 69, loss: 0.867401
global_step: 2732, epoch: 69, loss: 0.894368
global_step: 2733, epoch: 69, loss: 0.768039
global_step: 2734, epoch: 69, loss: 0.936600
global_step: 2735, epoch: 69, loss: 0.797709
global_step: 2736, epoch: 69, loss: 0.758525
global_step: 2737, epoch: 69, loss: 0.774999
global_step: 2738, epoch: 69, loss: 0.817672
global_step: 2739, epoch: 69, loss: 0.853442
global_step: 2740, epoch: 69, loss: 0.760061
global_step: 2741, epoch: 69, loss: 0.799099
global_step: 2742, epoch: 69, loss: 0.868956
global_step: 2743, epoch: 69, loss: 0.814794
global_step: 2744, epoch: 69, loss: 0.944121
global_step: 2745, epoch: 69, loss: 0.844295
global_step: 2746, epoch: 69, loss: 0.790856
global_step: 2747, epoch: 69, loss: 0.853655
global_step: 2748, epoch: 69, loss: 0.864375
global_step: 2749, epoch: 69, loss: 0.836821
global_step: 2750, epoch: 69, loss: 0.789722
global_step: 2751, epoch: 69, loss: 0.849004
global_step: 2752, epoch: 69, loss: 0.861974
global_step: 2753, epoch: 69, loss: 0.835556
global_step: 2754, epoch: 69, loss: 0.797613
global_step: 2755, epoch: 69, loss: 0.837122
global_step: 2756, epoch: 69, loss: 0.899554
global_step: 2757, epoch: 69, loss: 0.833280
global_step: 2758, epoch: 69, loss: 0.860074
global_step: 2759, epoch: 69, loss: 0.769656
global_step: 2760, epoch: 69, loss: 0.984310
epoch: 69
train	acc: 0.8126	macro: p 0.7008, r 0.5641, f1: 0.5611	micro: p 0.8126, r 0.8126, f1 0.8126	weighted_f1:0.7878
dev	acc: 0.5491	macro: p 0.3365, r 0.3112, f1: 0.3093	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5009
test	acc: 0.5992	macro: p 0.3557, r 0.3229, f1: 0.3273	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5584
global_step: 2761, epoch: 70, loss: 0.731685
global_step: 2762, epoch: 70, loss: 0.838105
global_step: 2763, epoch: 70, loss: 0.849512
global_step: 2764, epoch: 70, loss: 0.810201
global_step: 2765, epoch: 70, loss: 0.682846
global_step: 2766, epoch: 70, loss: 0.921324
global_step: 2767, epoch: 70, loss: 0.752262
global_step: 2768, epoch: 70, loss: 0.836071
global_step: 2769, epoch: 70, loss: 0.666836
global_step: 2770, epoch: 70, loss: 0.794974
global_step: 2771, epoch: 70, loss: 0.782007
global_step: 2772, epoch: 70, loss: 0.836690
global_step: 2773, epoch: 70, loss: 0.789600
global_step: 2774, epoch: 70, loss: 0.860462
global_step: 2775, epoch: 70, loss: 0.782153
global_step: 2776, epoch: 70, loss: 0.838791
global_step: 2777, epoch: 70, loss: 0.838380
global_step: 2778, epoch: 70, loss: 0.729306
global_step: 2779, epoch: 70, loss: 0.809096
global_step: 2780, epoch: 70, loss: 0.730599
global_step: 2781, epoch: 70, loss: 0.819258
global_step: 2782, epoch: 70, loss: 0.825609
global_step: 2783, epoch: 70, loss: 0.725463
global_step: 2784, epoch: 70, loss: 0.765383
global_step: 2785, epoch: 70, loss: 0.754815
global_step: 2786, epoch: 70, loss: 0.844596
global_step: 2787, epoch: 70, loss: 0.878326
global_step: 2788, epoch: 70, loss: 0.820020
global_step: 2789, epoch: 70, loss: 0.804187
global_step: 2790, epoch: 70, loss: 0.868179
global_step: 2791, epoch: 70, loss: 0.870182
global_step: 2792, epoch: 70, loss: 0.809225
global_step: 2793, epoch: 70, loss: 0.897489
global_step: 2794, epoch: 70, loss: 0.837032
global_step: 2795, epoch: 70, loss: 0.924502
global_step: 2796, epoch: 70, loss: 0.814235
global_step: 2797, epoch: 70, loss: 0.753063
global_step: 2798, epoch: 70, loss: 0.852354
global_step: 2799, epoch: 70, loss: 0.871466
global_step: 2800, epoch: 70, loss: 0.295270
epoch: 70
train	acc: 0.8080	macro: p 0.7078, r 0.5506, f1: 0.5556	micro: p 0.8080, r 0.8080, f1 0.8080	weighted_f1:0.7817
dev	acc: 0.5455	macro: p 0.3219, r 0.2992, f1: 0.2916	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4878
test	acc: 0.6019	macro: p 0.3719, r 0.3196, f1: 0.3231	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5568
global_step: 2801, epoch: 71, loss: 0.744115
global_step: 2802, epoch: 71, loss: 0.819205
global_step: 2803, epoch: 71, loss: 0.773045
global_step: 2804, epoch: 71, loss: 0.742992
global_step: 2805, epoch: 71, loss: 0.850256
global_step: 2806, epoch: 71, loss: 0.871052
global_step: 2807, epoch: 71, loss: 0.704435
global_step: 2808, epoch: 71, loss: 0.732287
global_step: 2809, epoch: 71, loss: 0.852259
global_step: 2810, epoch: 71, loss: 0.832027
global_step: 2811, epoch: 71, loss: 0.871985
global_step: 2812, epoch: 71, loss: 0.793235
global_step: 2813, epoch: 71, loss: 0.882625
global_step: 2814, epoch: 71, loss: 0.797018
global_step: 2815, epoch: 71, loss: 0.769567
global_step: 2816, epoch: 71, loss: 0.892591
global_step: 2817, epoch: 71, loss: 0.849977
global_step: 2818, epoch: 71, loss: 0.750666
global_step: 2819, epoch: 71, loss: 0.819186
global_step: 2820, epoch: 71, loss: 0.856565
global_step: 2821, epoch: 71, loss: 0.909721
global_step: 2822, epoch: 71, loss: 0.781231
global_step: 2823, epoch: 71, loss: 0.764590
global_step: 2824, epoch: 71, loss: 0.829124
global_step: 2825, epoch: 71, loss: 0.721008
global_step: 2826, epoch: 71, loss: 0.766929
global_step: 2827, epoch: 71, loss: 0.728773
global_step: 2828, epoch: 71, loss: 0.789576
global_step: 2829, epoch: 71, loss: 0.781617
global_step: 2830, epoch: 71, loss: 0.867374
global_step: 2831, epoch: 71, loss: 0.788225
global_step: 2832, epoch: 71, loss: 0.835573
global_step: 2833, epoch: 71, loss: 0.737372
global_step: 2834, epoch: 71, loss: 0.840877
global_step: 2835, epoch: 71, loss: 0.848799
global_step: 2836, epoch: 71, loss: 0.834008
global_step: 2837, epoch: 71, loss: 0.822501
global_step: 2838, epoch: 71, loss: 0.814498
global_step: 2839, epoch: 71, loss: 0.766746
global_step: 2840, epoch: 71, loss: 0.492172
epoch: 71
train	acc: 0.8160	macro: p 0.8523, r 0.5635, f1: 0.5666	micro: p 0.8160, r 0.8160, f1 0.8160	weighted_f1:0.7910
dev	acc: 0.5500	macro: p 0.3385, r 0.3084, f1: 0.3033	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4977
test	acc: 0.6023	macro: p 0.3716, r 0.3242, f1: 0.3287	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5605
global_step: 2841, epoch: 72, loss: 0.809553
global_step: 2842, epoch: 72, loss: 0.802537
global_step: 2843, epoch: 72, loss: 0.787266
global_step: 2844, epoch: 72, loss: 0.846916
global_step: 2845, epoch: 72, loss: 0.758668
global_step: 2846, epoch: 72, loss: 0.824514
global_step: 2847, epoch: 72, loss: 0.872304
global_step: 2848, epoch: 72, loss: 0.821403
global_step: 2849, epoch: 72, loss: 0.759707
global_step: 2850, epoch: 72, loss: 0.765749
global_step: 2851, epoch: 72, loss: 0.794570
global_step: 2852, epoch: 72, loss: 0.846863
global_step: 2853, epoch: 72, loss: 0.883550
global_step: 2854, epoch: 72, loss: 0.791162
global_step: 2855, epoch: 72, loss: 0.801676
global_step: 2856, epoch: 72, loss: 0.690561
global_step: 2857, epoch: 72, loss: 0.866459
global_step: 2858, epoch: 72, loss: 0.835153
global_step: 2859, epoch: 72, loss: 0.827058
global_step: 2860, epoch: 72, loss: 0.834663
global_step: 2861, epoch: 72, loss: 0.730338
global_step: 2862, epoch: 72, loss: 0.887433
global_step: 2863, epoch: 72, loss: 0.950050
global_step: 2864, epoch: 72, loss: 0.872141
global_step: 2865, epoch: 72, loss: 0.756534
global_step: 2866, epoch: 72, loss: 0.752463
global_step: 2867, epoch: 72, loss: 0.824686
global_step: 2868, epoch: 72, loss: 0.933532
global_step: 2869, epoch: 72, loss: 0.761463
global_step: 2870, epoch: 72, loss: 0.666044
global_step: 2871, epoch: 72, loss: 0.783280
global_step: 2872, epoch: 72, loss: 0.812042
global_step: 2873, epoch: 72, loss: 0.863738
global_step: 2874, epoch: 72, loss: 0.785225
global_step: 2875, epoch: 72, loss: 0.900302
global_step: 2876, epoch: 72, loss: 0.778580
global_step: 2877, epoch: 72, loss: 0.796827
global_step: 2878, epoch: 72, loss: 0.766847
global_step: 2879, epoch: 72, loss: 0.720769
global_step: 2880, epoch: 72, loss: 1.509985
epoch: 72
train	acc: 0.8302	macro: p 0.8508, r 0.5904, f1: 0.5863	micro: p 0.8302, r 0.8302, f1 0.8302	weighted_f1:0.8080
dev	acc: 0.5392	macro: p 0.3260, r 0.3084, f1: 0.3041	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4946
test	acc: 0.5969	macro: p 0.3579, r 0.3270, f1: 0.3292	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5596
global_step: 2881, epoch: 73, loss: 0.760901
global_step: 2882, epoch: 73, loss: 0.727556
global_step: 2883, epoch: 73, loss: 0.748683
global_step: 2884, epoch: 73, loss: 0.752062
global_step: 2885, epoch: 73, loss: 0.803661
global_step: 2886, epoch: 73, loss: 0.838683
global_step: 2887, epoch: 73, loss: 0.814685
global_step: 2888, epoch: 73, loss: 0.722693
global_step: 2889, epoch: 73, loss: 0.634607
global_step: 2890, epoch: 73, loss: 0.732643
global_step: 2891, epoch: 73, loss: 0.780683
global_step: 2892, epoch: 73, loss: 0.808399
global_step: 2893, epoch: 73, loss: 0.787525
global_step: 2894, epoch: 73, loss: 0.878770
global_step: 2895, epoch: 73, loss: 0.791715
global_step: 2896, epoch: 73, loss: 0.814695
global_step: 2897, epoch: 73, loss: 0.809151
global_step: 2898, epoch: 73, loss: 0.695707
global_step: 2899, epoch: 73, loss: 0.755921
global_step: 2900, epoch: 73, loss: 0.787057
global_step: 2901, epoch: 73, loss: 0.793786
global_step: 2902, epoch: 73, loss: 0.806489
global_step: 2903, epoch: 73, loss: 0.792085
global_step: 2904, epoch: 73, loss: 0.838951
global_step: 2905, epoch: 73, loss: 0.901976
global_step: 2906, epoch: 73, loss: 0.877751
global_step: 2907, epoch: 73, loss: 0.826961
global_step: 2908, epoch: 73, loss: 0.785236
global_step: 2909, epoch: 73, loss: 0.721729
global_step: 2910, epoch: 73, loss: 0.863743
global_step: 2911, epoch: 73, loss: 0.668388
global_step: 2912, epoch: 73, loss: 0.749133
global_step: 2913, epoch: 73, loss: 0.869818
global_step: 2914, epoch: 73, loss: 0.919744
global_step: 2915, epoch: 73, loss: 0.734364
global_step: 2916, epoch: 73, loss: 0.918858
global_step: 2917, epoch: 73, loss: 0.805875
global_step: 2918, epoch: 73, loss: 0.725133
global_step: 2919, epoch: 73, loss: 0.734885
global_step: 2920, epoch: 73, loss: 1.220397
epoch: 73
train	acc: 0.8276	macro: p 0.8567, r 0.5854, f1: 0.5904	micro: p 0.8276, r 0.8276, f1 0.8276	weighted_f1:0.8052
dev	acc: 0.5437	macro: p 0.3308, r 0.3052, f1: 0.3004	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4936
test	acc: 0.6023	macro: p 0.3651, r 0.3251, f1: 0.3286	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5612
global_step: 2921, epoch: 74, loss: 0.790660
global_step: 2922, epoch: 74, loss: 0.726847
global_step: 2923, epoch: 74, loss: 0.739094
global_step: 2924, epoch: 74, loss: 0.712642
global_step: 2925, epoch: 74, loss: 0.803846
global_step: 2926, epoch: 74, loss: 0.760493
global_step: 2927, epoch: 74, loss: 0.755766
global_step: 2928, epoch: 74, loss: 0.668787
global_step: 2929, epoch: 74, loss: 0.876960
global_step: 2930, epoch: 74, loss: 0.796913
global_step: 2931, epoch: 74, loss: 0.818462
global_step: 2932, epoch: 74, loss: 0.738381
global_step: 2933, epoch: 74, loss: 0.763722
global_step: 2934, epoch: 74, loss: 0.775004
global_step: 2935, epoch: 74, loss: 0.766011
global_step: 2936, epoch: 74, loss: 0.823998
global_step: 2937, epoch: 74, loss: 0.855047
global_step: 2938, epoch: 74, loss: 0.839127
global_step: 2939, epoch: 74, loss: 0.794707
global_step: 2940, epoch: 74, loss: 0.871933
global_step: 2941, epoch: 74, loss: 0.802854
global_step: 2942, epoch: 74, loss: 0.760903
global_step: 2943, epoch: 74, loss: 0.777012
global_step: 2944, epoch: 74, loss: 0.787964
global_step: 2945, epoch: 74, loss: 0.715359
global_step: 2946, epoch: 74, loss: 0.738673
global_step: 2947, epoch: 74, loss: 0.859576
global_step: 2948, epoch: 74, loss: 0.741479
global_step: 2949, epoch: 74, loss: 0.786173
global_step: 2950, epoch: 74, loss: 0.736094
global_step: 2951, epoch: 74, loss: 0.729819
global_step: 2952, epoch: 74, loss: 0.781889
global_step: 2953, epoch: 74, loss: 0.742093
global_step: 2954, epoch: 74, loss: 0.778709
global_step: 2955, epoch: 74, loss: 0.802008
global_step: 2956, epoch: 74, loss: 0.797460
global_step: 2957, epoch: 74, loss: 0.933790
global_step: 2958, epoch: 74, loss: 0.850914
global_step: 2959, epoch: 74, loss: 0.763506
global_step: 2960, epoch: 74, loss: 0.988842
epoch: 74
train	acc: 0.8332	macro: p 0.8548, r 0.5948, f1: 0.5913	micro: p 0.8332, r 0.8332, f1 0.8332	weighted_f1:0.8111
dev	acc: 0.5365	macro: p 0.3250, r 0.3036, f1: 0.3015	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4925
test	acc: 0.5969	macro: p 0.3553, r 0.3227, f1: 0.3264	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5582
global_step: 2961, epoch: 75, loss: 0.748951
global_step: 2962, epoch: 75, loss: 0.761497
global_step: 2963, epoch: 75, loss: 0.677921
global_step: 2964, epoch: 75, loss: 0.744611
global_step: 2965, epoch: 75, loss: 0.823400
global_step: 2966, epoch: 75, loss: 0.868598
global_step: 2967, epoch: 75, loss: 0.885517
global_step: 2968, epoch: 75, loss: 0.688308
global_step: 2969, epoch: 75, loss: 0.776307
global_step: 2970, epoch: 75, loss: 0.836200
global_step: 2971, epoch: 75, loss: 0.648387
global_step: 2972, epoch: 75, loss: 0.812626
global_step: 2973, epoch: 75, loss: 0.739421
global_step: 2974, epoch: 75, loss: 0.811244
global_step: 2975, epoch: 75, loss: 0.857641
global_step: 2976, epoch: 75, loss: 0.832090
global_step: 2977, epoch: 75, loss: 0.792948
global_step: 2978, epoch: 75, loss: 0.773144
global_step: 2979, epoch: 75, loss: 0.793444
global_step: 2980, epoch: 75, loss: 0.780649
global_step: 2981, epoch: 75, loss: 0.643993
global_step: 2982, epoch: 75, loss: 0.768977
global_step: 2983, epoch: 75, loss: 0.807340
global_step: 2984, epoch: 75, loss: 0.719586
global_step: 2985, epoch: 75, loss: 0.746592
global_step: 2986, epoch: 75, loss: 0.889187
global_step: 2987, epoch: 75, loss: 0.753529
global_step: 2988, epoch: 75, loss: 0.883954
global_step: 2989, epoch: 75, loss: 0.706608
global_step: 2990, epoch: 75, loss: 0.702163
global_step: 2991, epoch: 75, loss: 0.709078
global_step: 2992, epoch: 75, loss: 0.873614
global_step: 2993, epoch: 75, loss: 0.849610
global_step: 2994, epoch: 75, loss: 0.829019
global_step: 2995, epoch: 75, loss: 0.707688
global_step: 2996, epoch: 75, loss: 0.790959
global_step: 2997, epoch: 75, loss: 0.769633
global_step: 2998, epoch: 75, loss: 0.750700
global_step: 2999, epoch: 75, loss: 0.728993
global_step: 3000, epoch: 75, loss: 0.724058
epoch: 75
train	acc: 0.8312	macro: p 0.8629, r 0.5863, f1: 0.5913	micro: p 0.8312, r 0.8312, f1 0.8312	weighted_f1:0.8085
dev	acc: 0.5392	macro: p 0.3211, r 0.2982, f1: 0.2883	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4833
test	acc: 0.6004	macro: p 0.3728, r 0.3229, f1: 0.3267	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5580
global_step: 3001, epoch: 76, loss: 0.767839
global_step: 3002, epoch: 76, loss: 0.758458
global_step: 3003, epoch: 76, loss: 0.767661
global_step: 3004, epoch: 76, loss: 0.797546
global_step: 3005, epoch: 76, loss: 0.755697
global_step: 3006, epoch: 76, loss: 0.741710
global_step: 3007, epoch: 76, loss: 0.770387
global_step: 3008, epoch: 76, loss: 0.739545
global_step: 3009, epoch: 76, loss: 0.790396
global_step: 3010, epoch: 76, loss: 0.655092
global_step: 3011, epoch: 76, loss: 0.762946
global_step: 3012, epoch: 76, loss: 0.897654
global_step: 3013, epoch: 76, loss: 0.760491
global_step: 3014, epoch: 76, loss: 0.737370
global_step: 3015, epoch: 76, loss: 0.803222
global_step: 3016, epoch: 76, loss: 0.888034
global_step: 3017, epoch: 76, loss: 0.761183
global_step: 3018, epoch: 76, loss: 0.759891
global_step: 3019, epoch: 76, loss: 0.838277
global_step: 3020, epoch: 76, loss: 0.746126
global_step: 3021, epoch: 76, loss: 0.857451
global_step: 3022, epoch: 76, loss: 0.757650
global_step: 3023, epoch: 76, loss: 0.861886
global_step: 3024, epoch: 76, loss: 0.756166
global_step: 3025, epoch: 76, loss: 0.812299
global_step: 3026, epoch: 76, loss: 0.728163
global_step: 3027, epoch: 76, loss: 0.768168
global_step: 3028, epoch: 76, loss: 0.775400
global_step: 3029, epoch: 76, loss: 0.824962
global_step: 3030, epoch: 76, loss: 0.774518
global_step: 3031, epoch: 76, loss: 0.617791
global_step: 3032, epoch: 76, loss: 0.790567
global_step: 3033, epoch: 76, loss: 0.805575
global_step: 3034, epoch: 76, loss: 0.777634
global_step: 3035, epoch: 76, loss: 0.838950
global_step: 3036, epoch: 76, loss: 0.789005
global_step: 3037, epoch: 76, loss: 0.734663
global_step: 3038, epoch: 76, loss: 0.717472
global_step: 3039, epoch: 76, loss: 0.744323
global_step: 3040, epoch: 76, loss: 1.239799
epoch: 76
train	acc: 0.8345	macro: p 0.8616, r 0.5960, f1: 0.6001	micro: p 0.8345, r 0.8345, f1 0.8345	weighted_f1:0.8130
dev	acc: 0.5383	macro: p 0.3180, r 0.2986, f1: 0.2913	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4857
test	acc: 0.5966	macro: p 0.3618, r 0.3208, f1: 0.3249	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5558
global_step: 3041, epoch: 77, loss: 0.758496
global_step: 3042, epoch: 77, loss: 0.812410
global_step: 3043, epoch: 77, loss: 0.733243
global_step: 3044, epoch: 77, loss: 0.729561
global_step: 3045, epoch: 77, loss: 0.728351
global_step: 3046, epoch: 77, loss: 0.656128
global_step: 3047, epoch: 77, loss: 0.820430
global_step: 3048, epoch: 77, loss: 0.850846
global_step: 3049, epoch: 77, loss: 0.800399
global_step: 3050, epoch: 77, loss: 0.746416
global_step: 3051, epoch: 77, loss: 0.808769
global_step: 3052, epoch: 77, loss: 0.707197
global_step: 3053, epoch: 77, loss: 0.772370
global_step: 3054, epoch: 77, loss: 0.710732
global_step: 3055, epoch: 77, loss: 0.677761
global_step: 3056, epoch: 77, loss: 0.820343
global_step: 3057, epoch: 77, loss: 0.755632
global_step: 3058, epoch: 77, loss: 0.780287
global_step: 3059, epoch: 77, loss: 0.745111
global_step: 3060, epoch: 77, loss: 0.788217
global_step: 3061, epoch: 77, loss: 0.870710
global_step: 3062, epoch: 77, loss: 0.730732
global_step: 3063, epoch: 77, loss: 0.734141
global_step: 3064, epoch: 77, loss: 0.726696
global_step: 3065, epoch: 77, loss: 0.784574
global_step: 3066, epoch: 77, loss: 0.786000
global_step: 3067, epoch: 77, loss: 0.745616
global_step: 3068, epoch: 77, loss: 0.763144
global_step: 3069, epoch: 77, loss: 0.746625
global_step: 3070, epoch: 77, loss: 0.702992
global_step: 3071, epoch: 77, loss: 0.680449
global_step: 3072, epoch: 77, loss: 0.802023
global_step: 3073, epoch: 77, loss: 0.732804
global_step: 3074, epoch: 77, loss: 0.800460
global_step: 3075, epoch: 77, loss: 0.805764
global_step: 3076, epoch: 77, loss: 0.800270
global_step: 3077, epoch: 77, loss: 0.660712
global_step: 3078, epoch: 77, loss: 0.698364
global_step: 3079, epoch: 77, loss: 0.721490
global_step: 3080, epoch: 77, loss: 1.175280
epoch: 77
train	acc: 0.8315	macro: p 0.8643, r 0.5863, f1: 0.5914	micro: p 0.8315, r 0.8315, f1 0.8315	weighted_f1:0.8079
dev	acc: 0.5419	macro: p 0.3175, r 0.2998, f1: 0.2896	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4839
test	acc: 0.5950	macro: p 0.3626, r 0.3161, f1: 0.3171	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5497
global_step: 3081, epoch: 78, loss: 0.698278
global_step: 3082, epoch: 78, loss: 0.708993
global_step: 3083, epoch: 78, loss: 0.725112
global_step: 3084, epoch: 78, loss: 0.791244
global_step: 3085, epoch: 78, loss: 0.812088
global_step: 3086, epoch: 78, loss: 0.711308
global_step: 3087, epoch: 78, loss: 0.801912
global_step: 3088, epoch: 78, loss: 0.771560
global_step: 3089, epoch: 78, loss: 0.616165
global_step: 3090, epoch: 78, loss: 0.797210
global_step: 3091, epoch: 78, loss: 0.802911
global_step: 3092, epoch: 78, loss: 0.772251
global_step: 3093, epoch: 78, loss: 0.741845
global_step: 3094, epoch: 78, loss: 0.639508
global_step: 3095, epoch: 78, loss: 0.714801
global_step: 3096, epoch: 78, loss: 0.581206
global_step: 3097, epoch: 78, loss: 0.732985
global_step: 3098, epoch: 78, loss: 0.673175
global_step: 3099, epoch: 78, loss: 0.790473
global_step: 3100, epoch: 78, loss: 0.779960
global_step: 3101, epoch: 78, loss: 0.701932
global_step: 3102, epoch: 78, loss: 0.680964
global_step: 3103, epoch: 78, loss: 0.682097
global_step: 3104, epoch: 78, loss: 0.834428
global_step: 3105, epoch: 78, loss: 0.781113
global_step: 3106, epoch: 78, loss: 0.851308
global_step: 3107, epoch: 78, loss: 0.701241
global_step: 3108, epoch: 78, loss: 0.801014
global_step: 3109, epoch: 78, loss: 0.753412
global_step: 3110, epoch: 78, loss: 0.780235
global_step: 3111, epoch: 78, loss: 0.760813
global_step: 3112, epoch: 78, loss: 0.874324
global_step: 3113, epoch: 78, loss: 0.820894
global_step: 3114, epoch: 78, loss: 0.813357
global_step: 3115, epoch: 78, loss: 0.831463
global_step: 3116, epoch: 78, loss: 0.711685
global_step: 3117, epoch: 78, loss: 0.894938
global_step: 3118, epoch: 78, loss: 0.732281
global_step: 3119, epoch: 78, loss: 0.830713
global_step: 3120, epoch: 78, loss: 0.854963
epoch: 78
train	acc: 0.8437	macro: p 0.8678, r 0.6108, f1: 0.6177	micro: p 0.8437, r 0.8437, f1 0.8437	weighted_f1:0.8231
dev	acc: 0.5356	macro: p 0.3100, r 0.2959, f1: 0.2895	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4834
test	acc: 0.5996	macro: p 0.3646, r 0.3209, f1: 0.3246	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5572
global_step: 3121, epoch: 79, loss: 0.734677
global_step: 3122, epoch: 79, loss: 0.583633
global_step: 3123, epoch: 79, loss: 0.717850
global_step: 3124, epoch: 79, loss: 0.771812
global_step: 3125, epoch: 79, loss: 0.718270
global_step: 3126, epoch: 79, loss: 0.709366
global_step: 3127, epoch: 79, loss: 0.744823
global_step: 3128, epoch: 79, loss: 0.744286
global_step: 3129, epoch: 79, loss: 0.684670
global_step: 3130, epoch: 79, loss: 0.674136
global_step: 3131, epoch: 79, loss: 0.760643
global_step: 3132, epoch: 79, loss: 0.739763
global_step: 3133, epoch: 79, loss: 0.745684
global_step: 3134, epoch: 79, loss: 0.752426
global_step: 3135, epoch: 79, loss: 0.709113
global_step: 3136, epoch: 79, loss: 0.743043
global_step: 3137, epoch: 79, loss: 0.823376
global_step: 3138, epoch: 79, loss: 0.690865
global_step: 3139, epoch: 79, loss: 0.774786
global_step: 3140, epoch: 79, loss: 0.773221
global_step: 3141, epoch: 79, loss: 0.721680
global_step: 3142, epoch: 79, loss: 0.762863
global_step: 3143, epoch: 79, loss: 0.702784
global_step: 3144, epoch: 79, loss: 0.850568
global_step: 3145, epoch: 79, loss: 0.742288
global_step: 3146, epoch: 79, loss: 0.780598
global_step: 3147, epoch: 79, loss: 0.746168
global_step: 3148, epoch: 79, loss: 0.921954
global_step: 3149, epoch: 79, loss: 0.749540
global_step: 3150, epoch: 79, loss: 0.763679
global_step: 3151, epoch: 79, loss: 0.703131
global_step: 3152, epoch: 79, loss: 0.822517
global_step: 3153, epoch: 79, loss: 0.720141
global_step: 3154, epoch: 79, loss: 0.801236
global_step: 3155, epoch: 79, loss: 0.796952
global_step: 3156, epoch: 79, loss: 0.631765
global_step: 3157, epoch: 79, loss: 0.742128
global_step: 3158, epoch: 79, loss: 0.746885
global_step: 3159, epoch: 79, loss: 0.818618
global_step: 3160, epoch: 79, loss: 0.768692
epoch: 79
train	acc: 0.8458	macro: p 0.8680, r 0.6119, f1: 0.6146	micro: p 0.8458, r 0.8458, f1 0.8458	weighted_f1:0.8249
dev	acc: 0.5392	macro: p 0.3199, r 0.3029, f1: 0.2972	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4899
test	acc: 0.6000	macro: p 0.3658, r 0.3248, f1: 0.3294	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5605
global_step: 3161, epoch: 80, loss: 0.703601
global_step: 3162, epoch: 80, loss: 0.793318
global_step: 3163, epoch: 80, loss: 0.798588
global_step: 3164, epoch: 80, loss: 0.721358
global_step: 3165, epoch: 80, loss: 0.734324
global_step: 3166, epoch: 80, loss: 0.727778
global_step: 3167, epoch: 80, loss: 0.645918
global_step: 3168, epoch: 80, loss: 0.747262
global_step: 3169, epoch: 80, loss: 0.704251
global_step: 3170, epoch: 80, loss: 0.658089
global_step: 3171, epoch: 80, loss: 0.668925
global_step: 3172, epoch: 80, loss: 0.756031
global_step: 3173, epoch: 80, loss: 0.636059
global_step: 3174, epoch: 80, loss: 0.811925
global_step: 3175, epoch: 80, loss: 0.764689
global_step: 3176, epoch: 80, loss: 0.740238
global_step: 3177, epoch: 80, loss: 0.711511
global_step: 3178, epoch: 80, loss: 0.700303
global_step: 3179, epoch: 80, loss: 0.670943
global_step: 3180, epoch: 80, loss: 0.782901
global_step: 3181, epoch: 80, loss: 0.737581
global_step: 3182, epoch: 80, loss: 0.688171
global_step: 3183, epoch: 80, loss: 0.803315
global_step: 3184, epoch: 80, loss: 0.837189
global_step: 3185, epoch: 80, loss: 0.698543
global_step: 3186, epoch: 80, loss: 0.771575
global_step: 3187, epoch: 80, loss: 0.742499
global_step: 3188, epoch: 80, loss: 0.730015
global_step: 3189, epoch: 80, loss: 0.797088
global_step: 3190, epoch: 80, loss: 0.861705
global_step: 3191, epoch: 80, loss: 0.812810
global_step: 3192, epoch: 80, loss: 0.780043
global_step: 3193, epoch: 80, loss: 0.691613
global_step: 3194, epoch: 80, loss: 0.795867
global_step: 3195, epoch: 80, loss: 0.723021
global_step: 3196, epoch: 80, loss: 0.713586
global_step: 3197, epoch: 80, loss: 0.806702
global_step: 3198, epoch: 80, loss: 0.685078
global_step: 3199, epoch: 80, loss: 0.719182
global_step: 3200, epoch: 80, loss: 0.627177
epoch: 80
train	acc: 0.8507	macro: p 0.8687, r 0.6196, f1: 0.6209	micro: p 0.8507, r 0.8507, f1 0.8507	weighted_f1:0.8301
dev	acc: 0.5356	macro: p 0.3141, r 0.2998, f1: 0.2943	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4864
test	acc: 0.5946	macro: p 0.3535, r 0.3230, f1: 0.3255	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5558
global_step: 3201, epoch: 81, loss: 0.726817
global_step: 3202, epoch: 81, loss: 0.730906
global_step: 3203, epoch: 81, loss: 0.742986
global_step: 3204, epoch: 81, loss: 0.714960
global_step: 3205, epoch: 81, loss: 0.722474
global_step: 3206, epoch: 81, loss: 0.803961
global_step: 3207, epoch: 81, loss: 0.725529
global_step: 3208, epoch: 81, loss: 0.696588
global_step: 3209, epoch: 81, loss: 0.736724
global_step: 3210, epoch: 81, loss: 0.714644
global_step: 3211, epoch: 81, loss: 0.652733
global_step: 3212, epoch: 81, loss: 0.732995
global_step: 3213, epoch: 81, loss: 0.722848
global_step: 3214, epoch: 81, loss: 0.646838
global_step: 3215, epoch: 81, loss: 0.635927
global_step: 3216, epoch: 81, loss: 0.743832
global_step: 3217, epoch: 81, loss: 0.687568
global_step: 3218, epoch: 81, loss: 0.689715
global_step: 3219, epoch: 81, loss: 0.736555
global_step: 3220, epoch: 81, loss: 0.827990
global_step: 3221, epoch: 81, loss: 0.694333
global_step: 3222, epoch: 81, loss: 0.642436
global_step: 3223, epoch: 81, loss: 0.757533
global_step: 3224, epoch: 81, loss: 0.809995
global_step: 3225, epoch: 81, loss: 0.822092
global_step: 3226, epoch: 81, loss: 0.769530
global_step: 3227, epoch: 81, loss: 0.768568
global_step: 3228, epoch: 81, loss: 0.604011
global_step: 3229, epoch: 81, loss: 0.696734
global_step: 3230, epoch: 81, loss: 0.766662
global_step: 3231, epoch: 81, loss: 0.737062
global_step: 3232, epoch: 81, loss: 0.710452
global_step: 3233, epoch: 81, loss: 0.773473
global_step: 3234, epoch: 81, loss: 0.734226
global_step: 3235, epoch: 81, loss: 0.656523
global_step: 3236, epoch: 81, loss: 0.703191
global_step: 3237, epoch: 81, loss: 0.781049
global_step: 3238, epoch: 81, loss: 0.679371
global_step: 3239, epoch: 81, loss: 0.785428
global_step: 3240, epoch: 81, loss: 0.789799
epoch: 81
train	acc: 0.8539	macro: p 0.8728, r 0.6241, f1: 0.6273	micro: p 0.8539, r 0.8539, f1 0.8539	weighted_f1:0.8338
dev	acc: 0.5329	macro: p 0.3127, r 0.2964, f1: 0.2893	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4811
test	acc: 0.5946	macro: p 0.3563, r 0.3219, f1: 0.3248	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5548
global_step: 3241, epoch: 82, loss: 0.643206
global_step: 3242, epoch: 82, loss: 0.697237
global_step: 3243, epoch: 82, loss: 0.724689
global_step: 3244, epoch: 82, loss: 0.810149
global_step: 3245, epoch: 82, loss: 0.840462
global_step: 3246, epoch: 82, loss: 0.764684
global_step: 3247, epoch: 82, loss: 0.778551
global_step: 3248, epoch: 82, loss: 0.717851
global_step: 3249, epoch: 82, loss: 0.675327
global_step: 3250, epoch: 82, loss: 0.791697
global_step: 3251, epoch: 82, loss: 0.649385
global_step: 3252, epoch: 82, loss: 0.701559
global_step: 3253, epoch: 82, loss: 0.767052
global_step: 3254, epoch: 82, loss: 0.795955
global_step: 3255, epoch: 82, loss: 0.628228
global_step: 3256, epoch: 82, loss: 0.715428
global_step: 3257, epoch: 82, loss: 0.731881
global_step: 3258, epoch: 82, loss: 0.654347
global_step: 3259, epoch: 82, loss: 0.760880
global_step: 3260, epoch: 82, loss: 0.680747
global_step: 3261, epoch: 82, loss: 0.701185
global_step: 3262, epoch: 82, loss: 0.771843
global_step: 3263, epoch: 82, loss: 0.816220
global_step: 3264, epoch: 82, loss: 0.781369
global_step: 3265, epoch: 82, loss: 0.643469
global_step: 3266, epoch: 82, loss: 0.777848
global_step: 3267, epoch: 82, loss: 0.724263
global_step: 3268, epoch: 82, loss: 0.655987
global_step: 3269, epoch: 82, loss: 0.671541
global_step: 3270, epoch: 82, loss: 0.844140
global_step: 3271, epoch: 82, loss: 0.708810
global_step: 3272, epoch: 82, loss: 0.659478
global_step: 3273, epoch: 82, loss: 0.723217
global_step: 3274, epoch: 82, loss: 0.711985
global_step: 3275, epoch: 82, loss: 0.640392
global_step: 3276, epoch: 82, loss: 0.754176
global_step: 3277, epoch: 82, loss: 0.798639
global_step: 3278, epoch: 82, loss: 0.692462
global_step: 3279, epoch: 82, loss: 0.720659
global_step: 3280, epoch: 82, loss: 0.276271
epoch: 82
train	acc: 0.8523	macro: p 0.8723, r 0.6210, f1: 0.6255	micro: p 0.8523, r 0.8523, f1 0.8523	weighted_f1:0.8320
dev	acc: 0.5338	macro: p 0.3143, r 0.2977, f1: 0.2919	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4844
test	acc: 0.5943	macro: p 0.3579, r 0.3192, f1: 0.3210	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5533
global_step: 3281, epoch: 83, loss: 0.782838
global_step: 3282, epoch: 83, loss: 0.690370
global_step: 3283, epoch: 83, loss: 0.701579
global_step: 3284, epoch: 83, loss: 0.697530
global_step: 3285, epoch: 83, loss: 0.706678
global_step: 3286, epoch: 83, loss: 0.585387
global_step: 3287, epoch: 83, loss: 0.720716
global_step: 3288, epoch: 83, loss: 0.730218
global_step: 3289, epoch: 83, loss: 0.733366
global_step: 3290, epoch: 83, loss: 0.766740
global_step: 3291, epoch: 83, loss: 0.732373
global_step: 3292, epoch: 83, loss: 0.602364
global_step: 3293, epoch: 83, loss: 0.722703
global_step: 3294, epoch: 83, loss: 0.734185
global_step: 3295, epoch: 83, loss: 0.729443
global_step: 3296, epoch: 83, loss: 0.723959
global_step: 3297, epoch: 83, loss: 0.676428
global_step: 3298, epoch: 83, loss: 0.716043
global_step: 3299, epoch: 83, loss: 0.711875
global_step: 3300, epoch: 83, loss: 0.751665
global_step: 3301, epoch: 83, loss: 0.828273
global_step: 3302, epoch: 83, loss: 0.656150
global_step: 3303, epoch: 83, loss: 0.669842
global_step: 3304, epoch: 83, loss: 0.714315
global_step: 3305, epoch: 83, loss: 0.724198
global_step: 3306, epoch: 83, loss: 0.659825
global_step: 3307, epoch: 83, loss: 0.808585
global_step: 3308, epoch: 83, loss: 0.649898
global_step: 3309, epoch: 83, loss: 0.666328
global_step: 3310, epoch: 83, loss: 0.630117
global_step: 3311, epoch: 83, loss: 0.769869
global_step: 3312, epoch: 83, loss: 0.676680
global_step: 3313, epoch: 83, loss: 0.764455
global_step: 3314, epoch: 83, loss: 0.695499
global_step: 3315, epoch: 83, loss: 0.699778
global_step: 3316, epoch: 83, loss: 0.688999
global_step: 3317, epoch: 83, loss: 0.707331
global_step: 3318, epoch: 83, loss: 0.742005
global_step: 3319, epoch: 83, loss: 0.688999
global_step: 3320, epoch: 83, loss: 0.067300
epoch: 83
train	acc: 0.8539	macro: p 0.8750, r 0.6259, f1: 0.6344	micro: p 0.8539, r 0.8539, f1 0.8539	weighted_f1:0.8343
dev	acc: 0.5401	macro: p 0.3202, r 0.2999, f1: 0.2932	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4871
test	acc: 0.5954	macro: p 0.3587, r 0.3188, f1: 0.3204	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5524
global_step: 3321, epoch: 84, loss: 0.710104
global_step: 3322, epoch: 84, loss: 0.767287
global_step: 3323, epoch: 84, loss: 0.709068
global_step: 3324, epoch: 84, loss: 0.750355
global_step: 3325, epoch: 84, loss: 0.604489
global_step: 3326, epoch: 84, loss: 0.662553
global_step: 3327, epoch: 84, loss: 0.628366
global_step: 3328, epoch: 84, loss: 0.702805
global_step: 3329, epoch: 84, loss: 0.712258
global_step: 3330, epoch: 84, loss: 0.759019
global_step: 3331, epoch: 84, loss: 0.765296
global_step: 3332, epoch: 84, loss: 0.735768
global_step: 3333, epoch: 84, loss: 0.720559
global_step: 3334, epoch: 84, loss: 0.707873
global_step: 3335, epoch: 84, loss: 0.696235
global_step: 3336, epoch: 84, loss: 0.683616
global_step: 3337, epoch: 84, loss: 0.765723
global_step: 3338, epoch: 84, loss: 0.762066
global_step: 3339, epoch: 84, loss: 0.733419
global_step: 3340, epoch: 84, loss: 0.671827
global_step: 3341, epoch: 84, loss: 0.806071
global_step: 3342, epoch: 84, loss: 0.669108
global_step: 3343, epoch: 84, loss: 0.725227
global_step: 3344, epoch: 84, loss: 0.658242
global_step: 3345, epoch: 84, loss: 0.624291
global_step: 3346, epoch: 84, loss: 0.696487
global_step: 3347, epoch: 84, loss: 0.685036
global_step: 3348, epoch: 84, loss: 0.804871
global_step: 3349, epoch: 84, loss: 0.736602
global_step: 3350, epoch: 84, loss: 0.711026
global_step: 3351, epoch: 84, loss: 0.796530
global_step: 3352, epoch: 84, loss: 0.652131
global_step: 3353, epoch: 84, loss: 0.767762
global_step: 3354, epoch: 84, loss: 0.624914
global_step: 3355, epoch: 84, loss: 0.684169
global_step: 3356, epoch: 84, loss: 0.654061
global_step: 3357, epoch: 84, loss: 0.532454
global_step: 3358, epoch: 84, loss: 0.775874
global_step: 3359, epoch: 84, loss: 0.751121
global_step: 3360, epoch: 84, loss: 0.235387
epoch: 84
train	acc: 0.8441	macro: p 0.8785, r 0.6119, f1: 0.6316	micro: p 0.8441, r 0.8441, f1 0.8441	weighted_f1:0.8241
dev	acc: 0.5446	macro: p 0.3242, r 0.2960, f1: 0.2898	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4853
test	acc: 0.5989	macro: p 0.3628, r 0.3115, f1: 0.3140	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5486
global_step: 3361, epoch: 85, loss: 0.736893
global_step: 3362, epoch: 85, loss: 0.594294
global_step: 3363, epoch: 85, loss: 0.641166
global_step: 3364, epoch: 85, loss: 0.753416
global_step: 3365, epoch: 85, loss: 0.689373
global_step: 3366, epoch: 85, loss: 0.643650
global_step: 3367, epoch: 85, loss: 0.719137
global_step: 3368, epoch: 85, loss: 0.696390
global_step: 3369, epoch: 85, loss: 0.684246
global_step: 3370, epoch: 85, loss: 0.773781
global_step: 3371, epoch: 85, loss: 0.743778
global_step: 3372, epoch: 85, loss: 0.734590
global_step: 3373, epoch: 85, loss: 0.652976
global_step: 3374, epoch: 85, loss: 0.697784
global_step: 3375, epoch: 85, loss: 0.824105
global_step: 3376, epoch: 85, loss: 0.762123
global_step: 3377, epoch: 85, loss: 0.711738
global_step: 3378, epoch: 85, loss: 0.685818
global_step: 3379, epoch: 85, loss: 0.715639
global_step: 3380, epoch: 85, loss: 0.623436
global_step: 3381, epoch: 85, loss: 0.722523
global_step: 3382, epoch: 85, loss: 0.633519
global_step: 3383, epoch: 85, loss: 0.634200
global_step: 3384, epoch: 85, loss: 0.719189
global_step: 3385, epoch: 85, loss: 0.821291
global_step: 3386, epoch: 85, loss: 0.641998
global_step: 3387, epoch: 85, loss: 0.676668
global_step: 3388, epoch: 85, loss: 0.727772
global_step: 3389, epoch: 85, loss: 0.733695
global_step: 3390, epoch: 85, loss: 0.670383
global_step: 3391, epoch: 85, loss: 0.772067
global_step: 3392, epoch: 85, loss: 0.672412
global_step: 3393, epoch: 85, loss: 0.757084
global_step: 3394, epoch: 85, loss: 0.708442
global_step: 3395, epoch: 85, loss: 0.687837
global_step: 3396, epoch: 85, loss: 0.584698
global_step: 3397, epoch: 85, loss: 0.680061
global_step: 3398, epoch: 85, loss: 0.688236
global_step: 3399, epoch: 85, loss: 0.780036
global_step: 3400, epoch: 85, loss: 0.548443
epoch: 85
train	acc: 0.8579	macro: p 0.8798, r 0.6372, f1: 0.6530	micro: p 0.8579, r 0.8579, f1 0.8579	weighted_f1:0.8402
dev	acc: 0.5374	macro: p 0.3319, r 0.3005, f1: 0.2905	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4836
test	acc: 0.5916	macro: p 0.3552, r 0.3171, f1: 0.3145	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5483
global_step: 3401, epoch: 86, loss: 0.727230
global_step: 3402, epoch: 86, loss: 0.773582
global_step: 3403, epoch: 86, loss: 0.626521
global_step: 3404, epoch: 86, loss: 0.764907
global_step: 3405, epoch: 86, loss: 0.580601
global_step: 3406, epoch: 86, loss: 0.788577
global_step: 3407, epoch: 86, loss: 0.578246
global_step: 3408, epoch: 86, loss: 0.692973
global_step: 3409, epoch: 86, loss: 0.734903
global_step: 3410, epoch: 86, loss: 0.670694
global_step: 3411, epoch: 86, loss: 0.733331
global_step: 3412, epoch: 86, loss: 0.646761
global_step: 3413, epoch: 86, loss: 0.795547
global_step: 3414, epoch: 86, loss: 0.700656
global_step: 3415, epoch: 86, loss: 0.627976
global_step: 3416, epoch: 86, loss: 0.738699
global_step: 3417, epoch: 86, loss: 0.764620
global_step: 3418, epoch: 86, loss: 0.691961
global_step: 3419, epoch: 86, loss: 0.660302
global_step: 3420, epoch: 86, loss: 0.667434
global_step: 3421, epoch: 86, loss: 0.715745
global_step: 3422, epoch: 86, loss: 0.780362
global_step: 3423, epoch: 86, loss: 0.659851
global_step: 3424, epoch: 86, loss: 0.783441
global_step: 3425, epoch: 86, loss: 0.659242
global_step: 3426, epoch: 86, loss: 0.691376
global_step: 3427, epoch: 86, loss: 0.614928
global_step: 3428, epoch: 86, loss: 0.713800
global_step: 3429, epoch: 86, loss: 0.806230
global_step: 3430, epoch: 86, loss: 0.627286
global_step: 3431, epoch: 86, loss: 0.660217
global_step: 3432, epoch: 86, loss: 0.684167
global_step: 3433, epoch: 86, loss: 0.712676
global_step: 3434, epoch: 86, loss: 0.605037
global_step: 3435, epoch: 86, loss: 0.784231
global_step: 3436, epoch: 86, loss: 0.690360
global_step: 3437, epoch: 86, loss: 0.712883
global_step: 3438, epoch: 86, loss: 0.680645
global_step: 3439, epoch: 86, loss: 0.720763
global_step: 3440, epoch: 86, loss: 0.264255
epoch: 86
train	acc: 0.8672	macro: p 0.8808, r 0.6542, f1: 0.6649	micro: p 0.8672, r 0.8672, f1 0.8672	weighted_f1:0.8505
dev	acc: 0.5338	macro: p 0.3194, r 0.3028, f1: 0.2984	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4883
test	acc: 0.5939	macro: p 0.3480, r 0.3224, f1: 0.3239	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5554
global_step: 3441, epoch: 87, loss: 0.737033
global_step: 3442, epoch: 87, loss: 0.613521
global_step: 3443, epoch: 87, loss: 0.702374
global_step: 3444, epoch: 87, loss: 0.770963
global_step: 3445, epoch: 87, loss: 0.735970
global_step: 3446, epoch: 87, loss: 0.638032
global_step: 3447, epoch: 87, loss: 0.584555
global_step: 3448, epoch: 87, loss: 0.740784
global_step: 3449, epoch: 87, loss: 0.664692
global_step: 3450, epoch: 87, loss: 0.729404
global_step: 3451, epoch: 87, loss: 0.722646
global_step: 3452, epoch: 87, loss: 0.720871
global_step: 3453, epoch: 87, loss: 0.668797
global_step: 3454, epoch: 87, loss: 0.694531
global_step: 3455, epoch: 87, loss: 0.705216
global_step: 3456, epoch: 87, loss: 0.681787
global_step: 3457, epoch: 87, loss: 0.750664
global_step: 3458, epoch: 87, loss: 0.658416
global_step: 3459, epoch: 87, loss: 0.633147
global_step: 3460, epoch: 87, loss: 0.714109
global_step: 3461, epoch: 87, loss: 0.631150
global_step: 3462, epoch: 87, loss: 0.715558
global_step: 3463, epoch: 87, loss: 0.670285
global_step: 3464, epoch: 87, loss: 0.600522
global_step: 3465, epoch: 87, loss: 0.721141
global_step: 3466, epoch: 87, loss: 0.696855
global_step: 3467, epoch: 87, loss: 0.600326
global_step: 3468, epoch: 87, loss: 0.755488
global_step: 3469, epoch: 87, loss: 0.760071
global_step: 3470, epoch: 87, loss: 0.632094
global_step: 3471, epoch: 87, loss: 0.698614
global_step: 3472, epoch: 87, loss: 0.661980
global_step: 3473, epoch: 87, loss: 0.665302
global_step: 3474, epoch: 87, loss: 0.752693
global_step: 3475, epoch: 87, loss: 0.593216
global_step: 3476, epoch: 87, loss: 0.786700
global_step: 3477, epoch: 87, loss: 0.671473
global_step: 3478, epoch: 87, loss: 0.599209
global_step: 3479, epoch: 87, loss: 0.674145
global_step: 3480, epoch: 87, loss: 1.062373
epoch: 87
train	acc: 0.8604	macro: p 0.8769, r 0.6423, f1: 0.6614	micro: p 0.8604, r 0.8604, f1 0.8604	weighted_f1:0.8433
dev	acc: 0.5419	macro: p 0.3190, r 0.2968, f1: 0.2904	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4852
test	acc: 0.5962	macro: p 0.3603, r 0.3145, f1: 0.3189	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5504
global_step: 3481, epoch: 88, loss: 0.675139
global_step: 3482, epoch: 88, loss: 0.651251
global_step: 3483, epoch: 88, loss: 0.610427
global_step: 3484, epoch: 88, loss: 0.667245
global_step: 3485, epoch: 88, loss: 0.683890
global_step: 3486, epoch: 88, loss: 0.743706
global_step: 3487, epoch: 88, loss: 0.606001
global_step: 3488, epoch: 88, loss: 0.663824
global_step: 3489, epoch: 88, loss: 0.755982
global_step: 3490, epoch: 88, loss: 0.703548
global_step: 3491, epoch: 88, loss: 0.725756
global_step: 3492, epoch: 88, loss: 0.589088
global_step: 3493, epoch: 88, loss: 0.727736
global_step: 3494, epoch: 88, loss: 0.749111
global_step: 3495, epoch: 88, loss: 0.686310
global_step: 3496, epoch: 88, loss: 0.733074
global_step: 3497, epoch: 88, loss: 0.673024
global_step: 3498, epoch: 88, loss: 0.763852
global_step: 3499, epoch: 88, loss: 0.717518
global_step: 3500, epoch: 88, loss: 0.701595
global_step: 3501, epoch: 88, loss: 0.692772
global_step: 3502, epoch: 88, loss: 0.744643
global_step: 3503, epoch: 88, loss: 0.607642
global_step: 3504, epoch: 88, loss: 0.686166
global_step: 3505, epoch: 88, loss: 0.709875
global_step: 3506, epoch: 88, loss: 0.635689
global_step: 3507, epoch: 88, loss: 0.741613
global_step: 3508, epoch: 88, loss: 0.691271
global_step: 3509, epoch: 88, loss: 0.649235
global_step: 3510, epoch: 88, loss: 0.700939
global_step: 3511, epoch: 88, loss: 0.610582
global_step: 3512, epoch: 88, loss: 0.634793
global_step: 3513, epoch: 88, loss: 0.693706
global_step: 3514, epoch: 88, loss: 0.713736
global_step: 3515, epoch: 88, loss: 0.614942
global_step: 3516, epoch: 88, loss: 0.728682
global_step: 3517, epoch: 88, loss: 0.667079
global_step: 3518, epoch: 88, loss: 0.696929
global_step: 3519, epoch: 88, loss: 0.596024
global_step: 3520, epoch: 88, loss: 0.631518
epoch: 88
train	acc: 0.8686	macro: p 0.8851, r 0.6674, f1: 0.6880	micro: p 0.8686, r 0.8686, f1 0.8686	weighted_f1:0.8541
dev	acc: 0.5338	macro: p 0.3174, r 0.2948, f1: 0.2915	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4842
test	acc: 0.5977	macro: p 0.3593, r 0.3218, f1: 0.3260	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5565
global_step: 3521, epoch: 89, loss: 0.648421
global_step: 3522, epoch: 89, loss: 0.649238
global_step: 3523, epoch: 89, loss: 0.695397
global_step: 3524, epoch: 89, loss: 0.658169
global_step: 3525, epoch: 89, loss: 0.745140
global_step: 3526, epoch: 89, loss: 0.732470
global_step: 3527, epoch: 89, loss: 0.654498
global_step: 3528, epoch: 89, loss: 0.573591
global_step: 3529, epoch: 89, loss: 0.691475
global_step: 3530, epoch: 89, loss: 0.685506
global_step: 3531, epoch: 89, loss: 0.633395
global_step: 3532, epoch: 89, loss: 0.663993
global_step: 3533, epoch: 89, loss: 0.670018
global_step: 3534, epoch: 89, loss: 0.675246
global_step: 3535, epoch: 89, loss: 0.642370
global_step: 3536, epoch: 89, loss: 0.656008
global_step: 3537, epoch: 89, loss: 0.590518
global_step: 3538, epoch: 89, loss: 0.702345
global_step: 3539, epoch: 89, loss: 0.710651
global_step: 3540, epoch: 89, loss: 0.736392
global_step: 3541, epoch: 89, loss: 0.706250
global_step: 3542, epoch: 89, loss: 0.693416
global_step: 3543, epoch: 89, loss: 0.619522
global_step: 3544, epoch: 89, loss: 0.692575
global_step: 3545, epoch: 89, loss: 0.677011
global_step: 3546, epoch: 89, loss: 0.654788
global_step: 3547, epoch: 89, loss: 0.741146
global_step: 3548, epoch: 89, loss: 0.651185
global_step: 3549, epoch: 89, loss: 0.682306
global_step: 3550, epoch: 89, loss: 0.580153
global_step: 3551, epoch: 89, loss: 0.679359
global_step: 3552, epoch: 89, loss: 0.598896
global_step: 3553, epoch: 89, loss: 0.752786
global_step: 3554, epoch: 89, loss: 0.662916
global_step: 3555, epoch: 89, loss: 0.707702
global_step: 3556, epoch: 89, loss: 0.677942
global_step: 3557, epoch: 89, loss: 0.651150
global_step: 3558, epoch: 89, loss: 0.698191
global_step: 3559, epoch: 89, loss: 0.553030
global_step: 3560, epoch: 89, loss: 1.358426
epoch: 89
train	acc: 0.8736	macro: p 0.8865, r 0.6768, f1: 0.7045	micro: p 0.8736, r 0.8736, f1 0.8736	weighted_f1:0.8604
dev	acc: 0.5383	macro: p 0.3240, r 0.2998, f1: 0.2936	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4870
test	acc: 0.5954	macro: p 0.3615, r 0.3180, f1: 0.3212	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5535
global_step: 3561, epoch: 90, loss: 0.637371
global_step: 3562, epoch: 90, loss: 0.672839
global_step: 3563, epoch: 90, loss: 0.588997
global_step: 3564, epoch: 90, loss: 0.655075
global_step: 3565, epoch: 90, loss: 0.645327
global_step: 3566, epoch: 90, loss: 0.647978
global_step: 3567, epoch: 90, loss: 0.687694
global_step: 3568, epoch: 90, loss: 0.635346
global_step: 3569, epoch: 90, loss: 0.596514
global_step: 3570, epoch: 90, loss: 0.706592
global_step: 3571, epoch: 90, loss: 0.846573
global_step: 3572, epoch: 90, loss: 0.632611
global_step: 3573, epoch: 90, loss: 0.622880
global_step: 3574, epoch: 90, loss: 0.577294
global_step: 3575, epoch: 90, loss: 0.685855
global_step: 3576, epoch: 90, loss: 0.597902
global_step: 3577, epoch: 90, loss: 0.634349
global_step: 3578, epoch: 90, loss: 0.703892
global_step: 3579, epoch: 90, loss: 0.726513
global_step: 3580, epoch: 90, loss: 0.691752
global_step: 3581, epoch: 90, loss: 0.682481
global_step: 3582, epoch: 90, loss: 0.581141
global_step: 3583, epoch: 90, loss: 0.622941
global_step: 3584, epoch: 90, loss: 0.747747
global_step: 3585, epoch: 90, loss: 0.608627
global_step: 3586, epoch: 90, loss: 0.679556
global_step: 3587, epoch: 90, loss: 0.675076
global_step: 3588, epoch: 90, loss: 0.692681
global_step: 3589, epoch: 90, loss: 0.772127
global_step: 3590, epoch: 90, loss: 0.662729
global_step: 3591, epoch: 90, loss: 0.705724
global_step: 3592, epoch: 90, loss: 0.655595
global_step: 3593, epoch: 90, loss: 0.638168
global_step: 3594, epoch: 90, loss: 0.697424
global_step: 3595, epoch: 90, loss: 0.703486
global_step: 3596, epoch: 90, loss: 0.671078
global_step: 3597, epoch: 90, loss: 0.685212
global_step: 3598, epoch: 90, loss: 0.736864
global_step: 3599, epoch: 90, loss: 0.604583
global_step: 3600, epoch: 90, loss: 0.664227
epoch: 90
train	acc: 0.8792	macro: p 0.8883, r 0.6850, f1: 0.7033	micro: p 0.8792, r 0.8792, f1 0.8792	weighted_f1:0.8659
dev	acc: 0.5338	macro: p 0.3188, r 0.3032, f1: 0.2988	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4904
test	acc: 0.5900	macro: p 0.3455, r 0.3223, f1: 0.3226	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5534
global_step: 3601, epoch: 91, loss: 0.655093
global_step: 3602, epoch: 91, loss: 0.663041
global_step: 3603, epoch: 91, loss: 0.657592
global_step: 3604, epoch: 91, loss: 0.630398
global_step: 3605, epoch: 91, loss: 0.690462
global_step: 3606, epoch: 91, loss: 0.692014
global_step: 3607, epoch: 91, loss: 0.641326
global_step: 3608, epoch: 91, loss: 0.630319
global_step: 3609, epoch: 91, loss: 0.696739
global_step: 3610, epoch: 91, loss: 0.657152
global_step: 3611, epoch: 91, loss: 0.638420
global_step: 3612, epoch: 91, loss: 0.584000
global_step: 3613, epoch: 91, loss: 0.732080
global_step: 3614, epoch: 91, loss: 0.625869
global_step: 3615, epoch: 91, loss: 0.713395
global_step: 3616, epoch: 91, loss: 0.705174
global_step: 3617, epoch: 91, loss: 0.670618
global_step: 3618, epoch: 91, loss: 0.631983
global_step: 3619, epoch: 91, loss: 0.753420
global_step: 3620, epoch: 91, loss: 0.757227
global_step: 3621, epoch: 91, loss: 0.681782
global_step: 3622, epoch: 91, loss: 0.729022
global_step: 3623, epoch: 91, loss: 0.679674
global_step: 3624, epoch: 91, loss: 0.592586
global_step: 3625, epoch: 91, loss: 0.712042
global_step: 3626, epoch: 91, loss: 0.584464
global_step: 3627, epoch: 91, loss: 0.619179
global_step: 3628, epoch: 91, loss: 0.607406
global_step: 3629, epoch: 91, loss: 0.622790
global_step: 3630, epoch: 91, loss: 0.674474
global_step: 3631, epoch: 91, loss: 0.643148
global_step: 3632, epoch: 91, loss: 0.698455
global_step: 3633, epoch: 91, loss: 0.712358
global_step: 3634, epoch: 91, loss: 0.720024
global_step: 3635, epoch: 91, loss: 0.739172
global_step: 3636, epoch: 91, loss: 0.599786
global_step: 3637, epoch: 91, loss: 0.697408
global_step: 3638, epoch: 91, loss: 0.615629
global_step: 3639, epoch: 91, loss: 0.720070
global_step: 3640, epoch: 91, loss: 0.609803
epoch: 91
train	acc: 0.8716	macro: p 0.8904, r 0.6701, f1: 0.6939	micro: p 0.8716, r 0.8716, f1 0.8716	weighted_f1:0.8571
dev	acc: 0.5401	macro: p 0.3277, r 0.2981, f1: 0.2940	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4871
test	acc: 0.5958	macro: p 0.3555, r 0.3176, f1: 0.3202	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5523
global_step: 3641, epoch: 92, loss: 0.704339
global_step: 3642, epoch: 92, loss: 0.648587
global_step: 3643, epoch: 92, loss: 0.619624
global_step: 3644, epoch: 92, loss: 0.567067
global_step: 3645, epoch: 92, loss: 0.651697
global_step: 3646, epoch: 92, loss: 0.538744
global_step: 3647, epoch: 92, loss: 0.652719
global_step: 3648, epoch: 92, loss: 0.648897
global_step: 3649, epoch: 92, loss: 0.716972
global_step: 3650, epoch: 92, loss: 0.726096
global_step: 3651, epoch: 92, loss: 0.718341
global_step: 3652, epoch: 92, loss: 0.625434
global_step: 3653, epoch: 92, loss: 0.641577
global_step: 3654, epoch: 92, loss: 0.753008
global_step: 3655, epoch: 92, loss: 0.588101
global_step: 3656, epoch: 92, loss: 0.573281
global_step: 3657, epoch: 92, loss: 0.575033
global_step: 3658, epoch: 92, loss: 0.674678
global_step: 3659, epoch: 92, loss: 0.679289
global_step: 3660, epoch: 92, loss: 0.752387
global_step: 3661, epoch: 92, loss: 0.685378
global_step: 3662, epoch: 92, loss: 0.612804
global_step: 3663, epoch: 92, loss: 0.629891
global_step: 3664, epoch: 92, loss: 0.692676
global_step: 3665, epoch: 92, loss: 0.665386
global_step: 3666, epoch: 92, loss: 0.704994
global_step: 3667, epoch: 92, loss: 0.656148
global_step: 3668, epoch: 92, loss: 0.606879
global_step: 3669, epoch: 92, loss: 0.663948
global_step: 3670, epoch: 92, loss: 0.670184
global_step: 3671, epoch: 92, loss: 0.642254
global_step: 3672, epoch: 92, loss: 0.660457
global_step: 3673, epoch: 92, loss: 0.674317
global_step: 3674, epoch: 92, loss: 0.629558
global_step: 3675, epoch: 92, loss: 0.647367
global_step: 3676, epoch: 92, loss: 0.701772
global_step: 3677, epoch: 92, loss: 0.645205
global_step: 3678, epoch: 92, loss: 0.689363
global_step: 3679, epoch: 92, loss: 0.574224
global_step: 3680, epoch: 92, loss: 0.577659
epoch: 92
train	acc: 0.8805	macro: p 0.8905, r 0.6825, f1: 0.6994	micro: p 0.8805, r 0.8805, f1 0.8805	weighted_f1:0.8665
dev	acc: 0.5356	macro: p 0.3235, r 0.3022, f1: 0.2993	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4902
test	acc: 0.5954	macro: p 0.3533, r 0.3224, f1: 0.3241	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5564
global_step: 3681, epoch: 93, loss: 0.703256
global_step: 3682, epoch: 93, loss: 0.652281
global_step: 3683, epoch: 93, loss: 0.586817
global_step: 3684, epoch: 93, loss: 0.608188
global_step: 3685, epoch: 93, loss: 0.543689
global_step: 3686, epoch: 93, loss: 0.712461
global_step: 3687, epoch: 93, loss: 0.622881
global_step: 3688, epoch: 93, loss: 0.688731
global_step: 3689, epoch: 93, loss: 0.684031
global_step: 3690, epoch: 93, loss: 0.601298
global_step: 3691, epoch: 93, loss: 0.672147
global_step: 3692, epoch: 93, loss: 0.736152
global_step: 3693, epoch: 93, loss: 0.610756
global_step: 3694, epoch: 93, loss: 0.635573
global_step: 3695, epoch: 93, loss: 0.676918
global_step: 3696, epoch: 93, loss: 0.660637
global_step: 3697, epoch: 93, loss: 0.676960
global_step: 3698, epoch: 93, loss: 0.835551
global_step: 3699, epoch: 93, loss: 0.692169
global_step: 3700, epoch: 93, loss: 0.803851
global_step: 3701, epoch: 93, loss: 0.642984
global_step: 3702, epoch: 93, loss: 0.599678
global_step: 3703, epoch: 93, loss: 0.630153
global_step: 3704, epoch: 93, loss: 0.671999
global_step: 3705, epoch: 93, loss: 0.634066
global_step: 3706, epoch: 93, loss: 0.683348
global_step: 3707, epoch: 93, loss: 0.720413
global_step: 3708, epoch: 93, loss: 0.652717
global_step: 3709, epoch: 93, loss: 0.593890
global_step: 3710, epoch: 93, loss: 0.603953
global_step: 3711, epoch: 93, loss: 0.596918
global_step: 3712, epoch: 93, loss: 0.544967
global_step: 3713, epoch: 93, loss: 0.544186
global_step: 3714, epoch: 93, loss: 0.662746
global_step: 3715, epoch: 93, loss: 0.612178
global_step: 3716, epoch: 93, loss: 0.484849
global_step: 3717, epoch: 93, loss: 0.665175
global_step: 3718, epoch: 93, loss: 0.685788
global_step: 3719, epoch: 93, loss: 0.785414
global_step: 3720, epoch: 93, loss: 0.564470
epoch: 93
train	acc: 0.8793	macro: p 0.8848, r 0.6839, f1: 0.7030	micro: p 0.8793, r 0.8793, f1 0.8793	weighted_f1:0.8658
dev	acc: 0.5392	macro: p 0.3259, r 0.3064, f1: 0.3011	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4921
test	acc: 0.5950	macro: p 0.3503, r 0.3235, f1: 0.3237	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5556
global_step: 3721, epoch: 94, loss: 0.703019
global_step: 3722, epoch: 94, loss: 0.640013
global_step: 3723, epoch: 94, loss: 0.512656
global_step: 3724, epoch: 94, loss: 0.725904
global_step: 3725, epoch: 94, loss: 0.661508
global_step: 3726, epoch: 94, loss: 0.631374
global_step: 3727, epoch: 94, loss: 0.648608
global_step: 3728, epoch: 94, loss: 0.690985
global_step: 3729, epoch: 94, loss: 0.673704
global_step: 3730, epoch: 94, loss: 0.631785
global_step: 3731, epoch: 94, loss: 0.684554
global_step: 3732, epoch: 94, loss: 0.681487
global_step: 3733, epoch: 94, loss: 0.592630
global_step: 3734, epoch: 94, loss: 0.655509
global_step: 3735, epoch: 94, loss: 0.606330
global_step: 3736, epoch: 94, loss: 0.681233
global_step: 3737, epoch: 94, loss: 0.588623
global_step: 3738, epoch: 94, loss: 0.527808
global_step: 3739, epoch: 94, loss: 0.642675
global_step: 3740, epoch: 94, loss: 0.628865
global_step: 3741, epoch: 94, loss: 0.608923
global_step: 3742, epoch: 94, loss: 0.684084
global_step: 3743, epoch: 94, loss: 0.656132
global_step: 3744, epoch: 94, loss: 0.620140
global_step: 3745, epoch: 94, loss: 0.659899
global_step: 3746, epoch: 94, loss: 0.578914
global_step: 3747, epoch: 94, loss: 0.685697
global_step: 3748, epoch: 94, loss: 0.647600
global_step: 3749, epoch: 94, loss: 0.636805
global_step: 3750, epoch: 94, loss: 0.649139
global_step: 3751, epoch: 94, loss: 0.617548
global_step: 3752, epoch: 94, loss: 0.656439
global_step: 3753, epoch: 94, loss: 0.695146
global_step: 3754, epoch: 94, loss: 0.639410
global_step: 3755, epoch: 94, loss: 0.704206
global_step: 3756, epoch: 94, loss: 0.660387
global_step: 3757, epoch: 94, loss: 0.597012
global_step: 3758, epoch: 94, loss: 0.660329
global_step: 3759, epoch: 94, loss: 0.658750
global_step: 3760, epoch: 94, loss: 0.303199
epoch: 94
train	acc: 0.8834	macro: p 0.8934, r 0.6931, f1: 0.7142	micro: p 0.8834, r 0.8834, f1 0.8834	weighted_f1:0.8707
dev	acc: 0.5383	macro: p 0.3260, r 0.3048, f1: 0.2985	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4904
test	acc: 0.5950	macro: p 0.3558, r 0.3241, f1: 0.3236	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5557
global_step: 3761, epoch: 95, loss: 0.704775
global_step: 3762, epoch: 95, loss: 0.665050
global_step: 3763, epoch: 95, loss: 0.570888
global_step: 3764, epoch: 95, loss: 0.689093
global_step: 3765, epoch: 95, loss: 0.615659
global_step: 3766, epoch: 95, loss: 0.666829
global_step: 3767, epoch: 95, loss: 0.587001
global_step: 3768, epoch: 95, loss: 0.589171
global_step: 3769, epoch: 95, loss: 0.685559
global_step: 3770, epoch: 95, loss: 0.663333
global_step: 3771, epoch: 95, loss: 0.601952
global_step: 3772, epoch: 95, loss: 0.645483
global_step: 3773, epoch: 95, loss: 0.629455
global_step: 3774, epoch: 95, loss: 0.615061
global_step: 3775, epoch: 95, loss: 0.559137
global_step: 3776, epoch: 95, loss: 0.585930
global_step: 3777, epoch: 95, loss: 0.584258
global_step: 3778, epoch: 95, loss: 0.620656
global_step: 3779, epoch: 95, loss: 0.619218
global_step: 3780, epoch: 95, loss: 0.620606
global_step: 3781, epoch: 95, loss: 0.671858
global_step: 3782, epoch: 95, loss: 0.605103
global_step: 3783, epoch: 95, loss: 0.733243
global_step: 3784, epoch: 95, loss: 0.634687
global_step: 3785, epoch: 95, loss: 0.636604
global_step: 3786, epoch: 95, loss: 0.728614
global_step: 3787, epoch: 95, loss: 0.500925
global_step: 3788, epoch: 95, loss: 0.668047
global_step: 3789, epoch: 95, loss: 0.694791
global_step: 3790, epoch: 95, loss: 0.571952
global_step: 3791, epoch: 95, loss: 0.563971
global_step: 3792, epoch: 95, loss: 0.601087
global_step: 3793, epoch: 95, loss: 0.701972
global_step: 3794, epoch: 95, loss: 0.700807
global_step: 3795, epoch: 95, loss: 0.737075
global_step: 3796, epoch: 95, loss: 0.618362
global_step: 3797, epoch: 95, loss: 0.739586
global_step: 3798, epoch: 95, loss: 0.706506
global_step: 3799, epoch: 95, loss: 0.682047
global_step: 3800, epoch: 95, loss: 0.059537
epoch: 95
train	acc: 0.8880	macro: p 0.8942, r 0.7060, f1: 0.7322	micro: p 0.8880, r 0.8880, f1 0.8880	weighted_f1:0.8767
dev	acc: 0.5392	macro: p 0.3257, r 0.3026, f1: 0.2999	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4904
test	acc: 0.5923	macro: p 0.3457, r 0.3156, f1: 0.3184	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5502
global_step: 3801, epoch: 96, loss: 0.582925
global_step: 3802, epoch: 96, loss: 0.621309
global_step: 3803, epoch: 96, loss: 0.680130
global_step: 3804, epoch: 96, loss: 0.638912
global_step: 3805, epoch: 96, loss: 0.622621
global_step: 3806, epoch: 96, loss: 0.580803
global_step: 3807, epoch: 96, loss: 0.719228
global_step: 3808, epoch: 96, loss: 0.581948
global_step: 3809, epoch: 96, loss: 0.556661
global_step: 3810, epoch: 96, loss: 0.552960
global_step: 3811, epoch: 96, loss: 0.590535
global_step: 3812, epoch: 96, loss: 0.611590
global_step: 3813, epoch: 96, loss: 0.686278
global_step: 3814, epoch: 96, loss: 0.577507
global_step: 3815, epoch: 96, loss: 0.633998
global_step: 3816, epoch: 96, loss: 0.591931
global_step: 3817, epoch: 96, loss: 0.557042
global_step: 3818, epoch: 96, loss: 0.582059
global_step: 3819, epoch: 96, loss: 0.659766
global_step: 3820, epoch: 96, loss: 0.694881
global_step: 3821, epoch: 96, loss: 0.587600
global_step: 3822, epoch: 96, loss: 0.587631
global_step: 3823, epoch: 96, loss: 0.673782
global_step: 3824, epoch: 96, loss: 0.619066
global_step: 3825, epoch: 96, loss: 0.609666
global_step: 3826, epoch: 96, loss: 0.551284
global_step: 3827, epoch: 96, loss: 0.680106
global_step: 3828, epoch: 96, loss: 0.608394
global_step: 3829, epoch: 96, loss: 0.579844
global_step: 3830, epoch: 96, loss: 0.643384
global_step: 3831, epoch: 96, loss: 0.681673
global_step: 3832, epoch: 96, loss: 0.604291
global_step: 3833, epoch: 96, loss: 0.621960
global_step: 3834, epoch: 96, loss: 0.619145
global_step: 3835, epoch: 96, loss: 0.687184
global_step: 3836, epoch: 96, loss: 0.783313
global_step: 3837, epoch: 96, loss: 0.704999
global_step: 3838, epoch: 96, loss: 0.731177
global_step: 3839, epoch: 96, loss: 0.632380
global_step: 3840, epoch: 96, loss: 0.929904
epoch: 96
train	acc: 0.8887	macro: p 0.8918, r 0.7053, f1: 0.7274	micro: p 0.8887, r 0.8887, f1 0.8887	weighted_f1:0.8770
dev	acc: 0.5365	macro: p 0.3190, r 0.3008, f1: 0.2972	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4889
test	acc: 0.5931	macro: p 0.3514, r 0.3191, f1: 0.3220	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5528
global_step: 3841, epoch: 97, loss: 0.526067
global_step: 3842, epoch: 97, loss: 0.584942
global_step: 3843, epoch: 97, loss: 0.648244
global_step: 3844, epoch: 97, loss: 0.632345
global_step: 3845, epoch: 97, loss: 0.631376
global_step: 3846, epoch: 97, loss: 0.589217
global_step: 3847, epoch: 97, loss: 0.631784
global_step: 3848, epoch: 97, loss: 0.701172
global_step: 3849, epoch: 97, loss: 0.646031
global_step: 3850, epoch: 97, loss: 0.573529
global_step: 3851, epoch: 97, loss: 0.653652
global_step: 3852, epoch: 97, loss: 0.555060
global_step: 3853, epoch: 97, loss: 0.564333
global_step: 3854, epoch: 97, loss: 0.611956
global_step: 3855, epoch: 97, loss: 0.682836
global_step: 3856, epoch: 97, loss: 0.646688
global_step: 3857, epoch: 97, loss: 0.581975
global_step: 3858, epoch: 97, loss: 0.714211
global_step: 3859, epoch: 97, loss: 0.550649
global_step: 3860, epoch: 97, loss: 0.674364
global_step: 3861, epoch: 97, loss: 0.684167
global_step: 3862, epoch: 97, loss: 0.638915
global_step: 3863, epoch: 97, loss: 0.668440
global_step: 3864, epoch: 97, loss: 0.575195
global_step: 3865, epoch: 97, loss: 0.592619
global_step: 3866, epoch: 97, loss: 0.604534
global_step: 3867, epoch: 97, loss: 0.700220
global_step: 3868, epoch: 97, loss: 0.572720
global_step: 3869, epoch: 97, loss: 0.619064
global_step: 3870, epoch: 97, loss: 0.680501
global_step: 3871, epoch: 97, loss: 0.601485
global_step: 3872, epoch: 97, loss: 0.520038
global_step: 3873, epoch: 97, loss: 0.610364
global_step: 3874, epoch: 97, loss: 0.683554
global_step: 3875, epoch: 97, loss: 0.718643
global_step: 3876, epoch: 97, loss: 0.613921
global_step: 3877, epoch: 97, loss: 0.632372
global_step: 3878, epoch: 97, loss: 0.677565
global_step: 3879, epoch: 97, loss: 0.677995
global_step: 3880, epoch: 97, loss: 0.964780
epoch: 97
train	acc: 0.8894	macro: p 0.8942, r 0.7131, f1: 0.7436	micro: p 0.8894, r 0.8894, f1 0.8894	weighted_f1:0.8792
dev	acc: 0.5383	macro: p 0.3265, r 0.2998, f1: 0.2959	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4869
test	acc: 0.5939	macro: p 0.3517, r 0.3162, f1: 0.3188	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5501
global_step: 3881, epoch: 98, loss: 0.604264
global_step: 3882, epoch: 98, loss: 0.614257
global_step: 3883, epoch: 98, loss: 0.616109
global_step: 3884, epoch: 98, loss: 0.573486
global_step: 3885, epoch: 98, loss: 0.667951
global_step: 3886, epoch: 98, loss: 0.650826
global_step: 3887, epoch: 98, loss: 0.542695
global_step: 3888, epoch: 98, loss: 0.603828
global_step: 3889, epoch: 98, loss: 0.636925
global_step: 3890, epoch: 98, loss: 0.648996
global_step: 3891, epoch: 98, loss: 0.597449
global_step: 3892, epoch: 98, loss: 0.610312
global_step: 3893, epoch: 98, loss: 0.592876
global_step: 3894, epoch: 98, loss: 0.611693
global_step: 3895, epoch: 98, loss: 0.587275
global_step: 3896, epoch: 98, loss: 0.504776
global_step: 3897, epoch: 98, loss: 0.642214
global_step: 3898, epoch: 98, loss: 0.597075
global_step: 3899, epoch: 98, loss: 0.646055
global_step: 3900, epoch: 98, loss: 0.626281
global_step: 3901, epoch: 98, loss: 0.618596
global_step: 3902, epoch: 98, loss: 0.521617
global_step: 3903, epoch: 98, loss: 0.644509
global_step: 3904, epoch: 98, loss: 0.656729
global_step: 3905, epoch: 98, loss: 0.701754
global_step: 3906, epoch: 98, loss: 0.761681
global_step: 3907, epoch: 98, loss: 0.572897
global_step: 3908, epoch: 98, loss: 0.523680
global_step: 3909, epoch: 98, loss: 0.644371
global_step: 3910, epoch: 98, loss: 0.571658
global_step: 3911, epoch: 98, loss: 0.640697
global_step: 3912, epoch: 98, loss: 0.642586
global_step: 3913, epoch: 98, loss: 0.562983
global_step: 3914, epoch: 98, loss: 0.610342
global_step: 3915, epoch: 98, loss: 0.576930
global_step: 3916, epoch: 98, loss: 0.588049
global_step: 3917, epoch: 98, loss: 0.623886
global_step: 3918, epoch: 98, loss: 0.740344
global_step: 3919, epoch: 98, loss: 0.599717
global_step: 3920, epoch: 98, loss: 0.355476
epoch: 98
train	acc: 0.8923	macro: p 0.8936, r 0.7189, f1: 0.7465	micro: p 0.8923, r 0.8923, f1 0.8923	weighted_f1:0.8824
dev	acc: 0.5329	macro: p 0.3130, r 0.2979, f1: 0.2932	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4853
test	acc: 0.5900	macro: p 0.3441, r 0.3198, f1: 0.3201	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5507
global_step: 3921, epoch: 99, loss: 0.635685
global_step: 3922, epoch: 99, loss: 0.582379
global_step: 3923, epoch: 99, loss: 0.654366
global_step: 3924, epoch: 99, loss: 0.627128
global_step: 3925, epoch: 99, loss: 0.586358
global_step: 3926, epoch: 99, loss: 0.648071
global_step: 3927, epoch: 99, loss: 0.565955
global_step: 3928, epoch: 99, loss: 0.640366
global_step: 3929, epoch: 99, loss: 0.563608
global_step: 3930, epoch: 99, loss: 0.554575
global_step: 3931, epoch: 99, loss: 0.577401
global_step: 3932, epoch: 99, loss: 0.562119
global_step: 3933, epoch: 99, loss: 0.559369
global_step: 3934, epoch: 99, loss: 0.678642
global_step: 3935, epoch: 99, loss: 0.638872
global_step: 3936, epoch: 99, loss: 0.670592
global_step: 3937, epoch: 99, loss: 0.757221
global_step: 3938, epoch: 99, loss: 0.627108
global_step: 3939, epoch: 99, loss: 0.646167
global_step: 3940, epoch: 99, loss: 0.607840
global_step: 3941, epoch: 99, loss: 0.585776
global_step: 3942, epoch: 99, loss: 0.643954
global_step: 3943, epoch: 99, loss: 0.534655
global_step: 3944, epoch: 99, loss: 0.591015
global_step: 3945, epoch: 99, loss: 0.656300
global_step: 3946, epoch: 99, loss: 0.660101
global_step: 3947, epoch: 99, loss: 0.565427
global_step: 3948, epoch: 99, loss: 0.623050
global_step: 3949, epoch: 99, loss: 0.584477
global_step: 3950, epoch: 99, loss: 0.639229
global_step: 3951, epoch: 99, loss: 0.654592
global_step: 3952, epoch: 99, loss: 0.621861
global_step: 3953, epoch: 99, loss: 0.608600
global_step: 3954, epoch: 99, loss: 0.590625
global_step: 3955, epoch: 99, loss: 0.611093
global_step: 3956, epoch: 99, loss: 0.601390
global_step: 3957, epoch: 99, loss: 0.542404
global_step: 3958, epoch: 99, loss: 0.617330
global_step: 3959, epoch: 99, loss: 0.690323
global_step: 3960, epoch: 99, loss: 1.008880
epoch: 99
train	acc: 0.8936	macro: p 0.8974, r 0.7247, f1: 0.7504	micro: p 0.8936, r 0.8936, f1 0.8936	weighted_f1:0.8841
dev	acc: 0.5365	macro: p 0.3287, r 0.3095, f1: 0.3073	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4950
test	acc: 0.5854	macro: p 0.3376, r 0.3210, f1: 0.3209	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5508
global_step: 3961, epoch: 100, loss: 0.528595
global_step: 3962, epoch: 100, loss: 0.629474
global_step: 3963, epoch: 100, loss: 0.580007
global_step: 3964, epoch: 100, loss: 0.662265
global_step: 3965, epoch: 100, loss: 0.590487
global_step: 3966, epoch: 100, loss: 0.571378
global_step: 3967, epoch: 100, loss: 0.673559
global_step: 3968, epoch: 100, loss: 0.639116
global_step: 3969, epoch: 100, loss: 0.594844
global_step: 3970, epoch: 100, loss: 0.550392
global_step: 3971, epoch: 100, loss: 0.614043
global_step: 3972, epoch: 100, loss: 0.616626
global_step: 3973, epoch: 100, loss: 0.561235
global_step: 3974, epoch: 100, loss: 0.669458
global_step: 3975, epoch: 100, loss: 0.530314
global_step: 3976, epoch: 100, loss: 0.651186
global_step: 3977, epoch: 100, loss: 0.592059
global_step: 3978, epoch: 100, loss: 0.608447
global_step: 3979, epoch: 100, loss: 0.559117
global_step: 3980, epoch: 100, loss: 0.560644
global_step: 3981, epoch: 100, loss: 0.574158
global_step: 3982, epoch: 100, loss: 0.591359
global_step: 3983, epoch: 100, loss: 0.580433
global_step: 3984, epoch: 100, loss: 0.601106
global_step: 3985, epoch: 100, loss: 0.607305
global_step: 3986, epoch: 100, loss: 0.506961
global_step: 3987, epoch: 100, loss: 0.683441
global_step: 3988, epoch: 100, loss: 0.547666
global_step: 3989, epoch: 100, loss: 0.592394
global_step: 3990, epoch: 100, loss: 0.606191
global_step: 3991, epoch: 100, loss: 0.606838
global_step: 3992, epoch: 100, loss: 0.590285
global_step: 3993, epoch: 100, loss: 0.613917
global_step: 3994, epoch: 100, loss: 0.531977
global_step: 3995, epoch: 100, loss: 0.606184
global_step: 3996, epoch: 100, loss: 0.627500
global_step: 3997, epoch: 100, loss: 0.600095
global_step: 3998, epoch: 100, loss: 0.652032
global_step: 3999, epoch: 100, loss: 0.583027
global_step: 4000, epoch: 100, loss: 0.352749
epoch: 100
train	acc: 0.8915	macro: p 0.8981, r 0.7233, f1: 0.7586	micro: p 0.8915, r 0.8915, f1 0.8915	weighted_f1:0.8826
dev	acc: 0.5410	macro: p 0.3291, r 0.3017, f1: 0.2975	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4897
test	acc: 0.5954	macro: p 0.3532, r 0.3159, f1: 0.3187	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5511
BEST MODEL epoch: 44
train	acc: 0.7075 macro_p: 0.4853 macro_r: 0.4365 macro_f1: 0.4502 micro_p: 0.7075 micro_r: 0.7075 micro_f1: 0.7075 weighted_f1: 0.6757
dev	acc: 0.5582 macro_p: 0.3497 macro_r: 0.3150 macro_f1: 0.3122 micro_p: 0.5582 micro_r: 0.5582 micro_f1: 0.5582 weighted_f1: 0.5069
test	acc: 0.6042 macro_p: 0.3678 macro_r: 0.3214 macro_f1: 0.3259 micro_p: 0.6042 micro_r: 0.6042 micro_f1: 0.6042 weighted_f1: 0.5602
==========ROUND 2==========
global_step: 4001, epoch: 1, loss: 2.018334
global_step: 4002, epoch: 1, loss: 2.008883
global_step: 4003, epoch: 1, loss: 1.992380
global_step: 4004, epoch: 1, loss: 1.981577
global_step: 4005, epoch: 1, loss: 1.949196
global_step: 4006, epoch: 1, loss: 1.929559
global_step: 4007, epoch: 1, loss: 1.907377
global_step: 4008, epoch: 1, loss: 1.877583
global_step: 4009, epoch: 1, loss: 1.878684
global_step: 4010, epoch: 1, loss: 1.825723
global_step: 4011, epoch: 1, loss: 1.856660
global_step: 4012, epoch: 1, loss: 1.802850
global_step: 4013, epoch: 1, loss: 1.794378
global_step: 4014, epoch: 1, loss: 1.752717
global_step: 4015, epoch: 1, loss: 1.767767
global_step: 4016, epoch: 1, loss: 1.768082
global_step: 4017, epoch: 1, loss: 1.668956
global_step: 4018, epoch: 1, loss: 1.682653
global_step: 4019, epoch: 1, loss: 1.733638
global_step: 4020, epoch: 1, loss: 1.668250
global_step: 4021, epoch: 1, loss: 1.680799
global_step: 4022, epoch: 1, loss: 1.641354
global_step: 4023, epoch: 1, loss: 1.642805
global_step: 4024, epoch: 1, loss: 1.636880
global_step: 4025, epoch: 1, loss: 1.660743
global_step: 4026, epoch: 1, loss: 1.669793
global_step: 4027, epoch: 1, loss: 1.672397
global_step: 4028, epoch: 1, loss: 1.606966
global_step: 4029, epoch: 1, loss: 1.632082
global_step: 4030, epoch: 1, loss: 1.595188
global_step: 4031, epoch: 1, loss: 1.585150
global_step: 4032, epoch: 1, loss: 1.594329
global_step: 4033, epoch: 1, loss: 1.586372
global_step: 4034, epoch: 1, loss: 1.544235
global_step: 4035, epoch: 1, loss: 1.597423
global_step: 4036, epoch: 1, loss: 1.583612
global_step: 4037, epoch: 1, loss: 1.548916
global_step: 4038, epoch: 1, loss: 1.594016
global_step: 4039, epoch: 1, loss: 1.583618
global_step: 4040, epoch: 1, loss: 1.851814
epoch: 1
train	acc: 0.4864	macro: p 0.1419, r 0.1578, f1: 0.1200	micro: p 0.4864, r 0.4864, f1 0.4864	weighted_f1:0.3400
dev	acc: 0.4355	macro: p 0.1096, r 0.1560, f1: 0.1088	micro: p 0.4355, r 0.4355, f1 0.4355	weighted_f1:0.2809
test	acc: 0.5008	macro: p 0.1468, r 0.1644, f1: 0.1302	micro: p 0.5008, r 0.5008, f1 0.5008	weighted_f1:0.3575
New best model!
global_step: 4041, epoch: 2, loss: 1.531044
global_step: 4042, epoch: 2, loss: 1.554431
global_step: 4043, epoch: 2, loss: 1.542061
global_step: 4044, epoch: 2, loss: 1.547732
global_step: 4045, epoch: 2, loss: 1.490056
global_step: 4046, epoch: 2, loss: 1.529272
global_step: 4047, epoch: 2, loss: 1.664499
global_step: 4048, epoch: 2, loss: 1.538836
global_step: 4049, epoch: 2, loss: 1.493780
global_step: 4050, epoch: 2, loss: 1.458499
global_step: 4051, epoch: 2, loss: 1.429778
global_step: 4052, epoch: 2, loss: 1.462887
global_step: 4053, epoch: 2, loss: 1.621707
global_step: 4054, epoch: 2, loss: 1.560003
global_step: 4055, epoch: 2, loss: 1.428972
global_step: 4056, epoch: 2, loss: 1.466615
global_step: 4057, epoch: 2, loss: 1.618018
global_step: 4058, epoch: 2, loss: 1.562663
global_step: 4059, epoch: 2, loss: 1.559033
global_step: 4060, epoch: 2, loss: 1.518924
global_step: 4061, epoch: 2, loss: 1.522637
global_step: 4062, epoch: 2, loss: 1.520744
global_step: 4063, epoch: 2, loss: 1.470258
global_step: 4064, epoch: 2, loss: 1.479660
global_step: 4065, epoch: 2, loss: 1.547426
global_step: 4066, epoch: 2, loss: 1.549554
global_step: 4067, epoch: 2, loss: 1.477683
global_step: 4068, epoch: 2, loss: 1.547950
global_step: 4069, epoch: 2, loss: 1.531274
global_step: 4070, epoch: 2, loss: 1.495522
global_step: 4071, epoch: 2, loss: 1.642331
global_step: 4072, epoch: 2, loss: 1.462792
global_step: 4073, epoch: 2, loss: 1.491522
global_step: 4074, epoch: 2, loss: 1.418730
global_step: 4075, epoch: 2, loss: 1.559478
global_step: 4076, epoch: 2, loss: 1.473940
global_step: 4077, epoch: 2, loss: 1.549188
global_step: 4078, epoch: 2, loss: 1.411760
global_step: 4079, epoch: 2, loss: 1.437348
global_step: 4080, epoch: 2, loss: 0.969882
epoch: 2
train	acc: 0.5122	macro: p 0.2626, r 0.1825, f1: 0.1522	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.3852
dev	acc: 0.4626	macro: p 0.2599, r 0.1844, f1: 0.1441	micro: p 0.4626, r 0.4626, f1 0.4626	weighted_f1:0.3252
test	acc: 0.5176	macro: p 0.2726, r 0.1843, f1: 0.1533	micro: p 0.5176, r 0.5176, f1 0.5176	weighted_f1:0.3886
New best model!
global_step: 4081, epoch: 3, loss: 1.442813
global_step: 4082, epoch: 3, loss: 1.462968
global_step: 4083, epoch: 3, loss: 1.467722
global_step: 4084, epoch: 3, loss: 1.398139
global_step: 4085, epoch: 3, loss: 1.314775
global_step: 4086, epoch: 3, loss: 1.583525
global_step: 4087, epoch: 3, loss: 1.368946
global_step: 4088, epoch: 3, loss: 1.446099
global_step: 4089, epoch: 3, loss: 1.558769
global_step: 4090, epoch: 3, loss: 1.384013
global_step: 4091, epoch: 3, loss: 1.450226
global_step: 4092, epoch: 3, loss: 1.455021
global_step: 4093, epoch: 3, loss: 1.412237
global_step: 4094, epoch: 3, loss: 1.570160
global_step: 4095, epoch: 3, loss: 1.454633
global_step: 4096, epoch: 3, loss: 1.447818
global_step: 4097, epoch: 3, loss: 1.518217
global_step: 4098, epoch: 3, loss: 1.397527
global_step: 4099, epoch: 3, loss: 1.437944
global_step: 4100, epoch: 3, loss: 1.505132
global_step: 4101, epoch: 3, loss: 1.523498
global_step: 4102, epoch: 3, loss: 1.355177
global_step: 4103, epoch: 3, loss: 1.513761
global_step: 4104, epoch: 3, loss: 1.468792
global_step: 4105, epoch: 3, loss: 1.504805
global_step: 4106, epoch: 3, loss: 1.434804
global_step: 4107, epoch: 3, loss: 1.509748
global_step: 4108, epoch: 3, loss: 1.415375
global_step: 4109, epoch: 3, loss: 1.515524
global_step: 4110, epoch: 3, loss: 1.424361
global_step: 4111, epoch: 3, loss: 1.445312
global_step: 4112, epoch: 3, loss: 1.591251
global_step: 4113, epoch: 3, loss: 1.457989
global_step: 4114, epoch: 3, loss: 1.409879
global_step: 4115, epoch: 3, loss: 1.452811
global_step: 4116, epoch: 3, loss: 1.554584
global_step: 4117, epoch: 3, loss: 1.409905
global_step: 4118, epoch: 3, loss: 1.427679
global_step: 4119, epoch: 3, loss: 1.501391
global_step: 4120, epoch: 3, loss: 1.615514
epoch: 3
train	acc: 0.5433	macro: p 0.2285, r 0.2157, f1: 0.1899	micro: p 0.5433, r 0.5433, f1 0.5433	weighted_f1:0.4359
dev	acc: 0.4860	macro: p 0.2077, r 0.2160, f1: 0.1819	micro: p 0.4860, r 0.4860, f1 0.4860	weighted_f1:0.3729
test	acc: 0.5506	macro: p 0.2278, r 0.2237, f1: 0.1964	micro: p 0.5506, r 0.5506, f1 0.5506	weighted_f1:0.4415
New best model!
global_step: 4121, epoch: 4, loss: 1.487120
global_step: 4122, epoch: 4, loss: 1.461647
global_step: 4123, epoch: 4, loss: 1.468681
global_step: 4124, epoch: 4, loss: 1.509214
global_step: 4125, epoch: 4, loss: 1.427597
global_step: 4126, epoch: 4, loss: 1.420711
global_step: 4127, epoch: 4, loss: 1.386898
global_step: 4128, epoch: 4, loss: 1.606812
global_step: 4129, epoch: 4, loss: 1.478033
global_step: 4130, epoch: 4, loss: 1.462216
global_step: 4131, epoch: 4, loss: 1.421639
global_step: 4132, epoch: 4, loss: 1.419451
global_step: 4133, epoch: 4, loss: 1.367342
global_step: 4134, epoch: 4, loss: 1.540808
global_step: 4135, epoch: 4, loss: 1.370656
global_step: 4136, epoch: 4, loss: 1.367734
global_step: 4137, epoch: 4, loss: 1.499622
global_step: 4138, epoch: 4, loss: 1.552825
global_step: 4139, epoch: 4, loss: 1.414870
global_step: 4140, epoch: 4, loss: 1.436632
global_step: 4141, epoch: 4, loss: 1.461382
global_step: 4142, epoch: 4, loss: 1.396137
global_step: 4143, epoch: 4, loss: 1.352746
global_step: 4144, epoch: 4, loss: 1.404646
global_step: 4145, epoch: 4, loss: 1.399113
global_step: 4146, epoch: 4, loss: 1.352256
global_step: 4147, epoch: 4, loss: 1.393905
global_step: 4148, epoch: 4, loss: 1.473495
global_step: 4149, epoch: 4, loss: 1.440989
global_step: 4150, epoch: 4, loss: 1.424168
global_step: 4151, epoch: 4, loss: 1.377964
global_step: 4152, epoch: 4, loss: 1.393092
global_step: 4153, epoch: 4, loss: 1.385922
global_step: 4154, epoch: 4, loss: 1.361094
global_step: 4155, epoch: 4, loss: 1.332763
global_step: 4156, epoch: 4, loss: 1.393441
global_step: 4157, epoch: 4, loss: 1.370298
global_step: 4158, epoch: 4, loss: 1.390525
global_step: 4159, epoch: 4, loss: 1.398522
global_step: 4160, epoch: 4, loss: 1.413424
epoch: 4
train	acc: 0.5499	macro: p 0.3189, r 0.2256, f1: 0.1969	micro: p 0.5499, r 0.5499, f1 0.5499	weighted_f1:0.4485
dev	acc: 0.4941	macro: p 0.2097, r 0.2283, f1: 0.1877	micro: p 0.4941, r 0.4941, f1 0.4941	weighted_f1:0.3844
test	acc: 0.5548	macro: p 0.2312, r 0.2348, f1: 0.2030	micro: p 0.5548, r 0.5548, f1 0.5548	weighted_f1:0.4528
New best model!
global_step: 4161, epoch: 5, loss: 1.518868
global_step: 4162, epoch: 5, loss: 1.509102
global_step: 4163, epoch: 5, loss: 1.388634
global_step: 4164, epoch: 5, loss: 1.444650
global_step: 4165, epoch: 5, loss: 1.342505
global_step: 4166, epoch: 5, loss: 1.394126
global_step: 4167, epoch: 5, loss: 1.503548
global_step: 4168, epoch: 5, loss: 1.444109
global_step: 4169, epoch: 5, loss: 1.468987
global_step: 4170, epoch: 5, loss: 1.472681
global_step: 4171, epoch: 5, loss: 1.429090
global_step: 4172, epoch: 5, loss: 1.356167
global_step: 4173, epoch: 5, loss: 1.327643
global_step: 4174, epoch: 5, loss: 1.361444
global_step: 4175, epoch: 5, loss: 1.395131
global_step: 4176, epoch: 5, loss: 1.399369
global_step: 4177, epoch: 5, loss: 1.459305
global_step: 4178, epoch: 5, loss: 1.363233
global_step: 4179, epoch: 5, loss: 1.377299
global_step: 4180, epoch: 5, loss: 1.323798
global_step: 4181, epoch: 5, loss: 1.420760
global_step: 4182, epoch: 5, loss: 1.457756
global_step: 4183, epoch: 5, loss: 1.354453
global_step: 4184, epoch: 5, loss: 1.411515
global_step: 4185, epoch: 5, loss: 1.405316
global_step: 4186, epoch: 5, loss: 1.313834
global_step: 4187, epoch: 5, loss: 1.319944
global_step: 4188, epoch: 5, loss: 1.313546
global_step: 4189, epoch: 5, loss: 1.447374
global_step: 4190, epoch: 5, loss: 1.382948
global_step: 4191, epoch: 5, loss: 1.458252
global_step: 4192, epoch: 5, loss: 1.323722
global_step: 4193, epoch: 5, loss: 1.327348
global_step: 4194, epoch: 5, loss: 1.431294
global_step: 4195, epoch: 5, loss: 1.578370
global_step: 4196, epoch: 5, loss: 1.335248
global_step: 4197, epoch: 5, loss: 1.354364
global_step: 4198, epoch: 5, loss: 1.425685
global_step: 4199, epoch: 5, loss: 1.305979
global_step: 4200, epoch: 5, loss: 1.188998
epoch: 5
train	acc: 0.5615	macro: p 0.3054, r 0.2421, f1: 0.2226	micro: p 0.5615, r 0.5615, f1 0.5615	weighted_f1:0.4727
dev	acc: 0.5041	macro: p 0.2508, r 0.2431, f1: 0.2065	micro: p 0.5041, r 0.5041, f1 0.5041	weighted_f1:0.4034
test	acc: 0.5556	macro: p 0.2639, r 0.2421, f1: 0.2154	micro: p 0.5556, r 0.5556, f1 0.5556	weighted_f1:0.4641
New best model!
global_step: 4201, epoch: 6, loss: 1.371539
global_step: 4202, epoch: 6, loss: 1.420492
global_step: 4203, epoch: 6, loss: 1.385398
global_step: 4204, epoch: 6, loss: 1.425286
global_step: 4205, epoch: 6, loss: 1.412942
global_step: 4206, epoch: 6, loss: 1.495863
global_step: 4207, epoch: 6, loss: 1.407632
global_step: 4208, epoch: 6, loss: 1.360989
global_step: 4209, epoch: 6, loss: 1.445952
global_step: 4210, epoch: 6, loss: 1.385005
global_step: 4211, epoch: 6, loss: 1.276326
global_step: 4212, epoch: 6, loss: 1.414341
global_step: 4213, epoch: 6, loss: 1.366745
global_step: 4214, epoch: 6, loss: 1.370066
global_step: 4215, epoch: 6, loss: 1.415205
global_step: 4216, epoch: 6, loss: 1.415020
global_step: 4217, epoch: 6, loss: 1.378449
global_step: 4218, epoch: 6, loss: 1.366670
global_step: 4219, epoch: 6, loss: 1.444495
global_step: 4220, epoch: 6, loss: 1.300995
global_step: 4221, epoch: 6, loss: 1.413329
global_step: 4222, epoch: 6, loss: 1.407076
global_step: 4223, epoch: 6, loss: 1.335047
global_step: 4224, epoch: 6, loss: 1.361777
global_step: 4225, epoch: 6, loss: 1.500629
global_step: 4226, epoch: 6, loss: 1.368889
global_step: 4227, epoch: 6, loss: 1.308640
global_step: 4228, epoch: 6, loss: 1.422788
global_step: 4229, epoch: 6, loss: 1.227342
global_step: 4230, epoch: 6, loss: 1.303590
global_step: 4231, epoch: 6, loss: 1.450751
global_step: 4232, epoch: 6, loss: 1.327799
global_step: 4233, epoch: 6, loss: 1.330798
global_step: 4234, epoch: 6, loss: 1.473959
global_step: 4235, epoch: 6, loss: 1.323185
global_step: 4236, epoch: 6, loss: 1.375522
global_step: 4237, epoch: 6, loss: 1.359883
global_step: 4238, epoch: 6, loss: 1.453925
global_step: 4239, epoch: 6, loss: 1.330387
global_step: 4240, epoch: 6, loss: 1.485085
epoch: 6
train	acc: 0.5743	macro: p 0.3001, r 0.2621, f1: 0.2547	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5002
dev	acc: 0.5158	macro: p 0.2670, r 0.2552, f1: 0.2367	micro: p 0.5158, r 0.5158, f1 0.5158	weighted_f1:0.4338
test	acc: 0.5678	macro: p 0.2785, r 0.2571, f1: 0.2451	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.4932
New best model!
global_step: 4241, epoch: 7, loss: 1.429582
global_step: 4242, epoch: 7, loss: 1.382860
global_step: 4243, epoch: 7, loss: 1.488260
global_step: 4244, epoch: 7, loss: 1.431272
global_step: 4245, epoch: 7, loss: 1.313340
global_step: 4246, epoch: 7, loss: 1.379812
global_step: 4247, epoch: 7, loss: 1.342940
global_step: 4248, epoch: 7, loss: 1.372390
global_step: 4249, epoch: 7, loss: 1.355637
global_step: 4250, epoch: 7, loss: 1.387049
global_step: 4251, epoch: 7, loss: 1.371565
global_step: 4252, epoch: 7, loss: 1.529873
global_step: 4253, epoch: 7, loss: 1.505315
global_step: 4254, epoch: 7, loss: 1.337584
global_step: 4255, epoch: 7, loss: 1.307179
global_step: 4256, epoch: 7, loss: 1.353875
global_step: 4257, epoch: 7, loss: 1.433197
global_step: 4258, epoch: 7, loss: 1.265273
global_step: 4259, epoch: 7, loss: 1.400774
global_step: 4260, epoch: 7, loss: 1.389383
global_step: 4261, epoch: 7, loss: 1.288160
global_step: 4262, epoch: 7, loss: 1.318792
global_step: 4263, epoch: 7, loss: 1.360667
global_step: 4264, epoch: 7, loss: 1.346850
global_step: 4265, epoch: 7, loss: 1.433486
global_step: 4266, epoch: 7, loss: 1.338241
global_step: 4267, epoch: 7, loss: 1.363715
global_step: 4268, epoch: 7, loss: 1.454517
global_step: 4269, epoch: 7, loss: 1.294793
global_step: 4270, epoch: 7, loss: 1.479615
global_step: 4271, epoch: 7, loss: 1.315146
global_step: 4272, epoch: 7, loss: 1.328297
global_step: 4273, epoch: 7, loss: 1.393817
global_step: 4274, epoch: 7, loss: 1.391537
global_step: 4275, epoch: 7, loss: 1.319339
global_step: 4276, epoch: 7, loss: 1.355355
global_step: 4277, epoch: 7, loss: 1.331652
global_step: 4278, epoch: 7, loss: 1.205353
global_step: 4279, epoch: 7, loss: 1.328839
global_step: 4280, epoch: 7, loss: 1.032922
epoch: 7
train	acc: 0.5764	macro: p 0.2983, r 0.2644, f1: 0.2578	micro: p 0.5764, r 0.5764, f1 0.5764	weighted_f1:0.5032
dev	acc: 0.5212	macro: p 0.2677, r 0.2599, f1: 0.2397	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4379
test	acc: 0.5686	macro: p 0.2713, r 0.2585, f1: 0.2452	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.4934
New best model!
global_step: 4281, epoch: 8, loss: 1.356838
global_step: 4282, epoch: 8, loss: 1.367492
global_step: 4283, epoch: 8, loss: 1.389271
global_step: 4284, epoch: 8, loss: 1.396938
global_step: 4285, epoch: 8, loss: 1.416165
global_step: 4286, epoch: 8, loss: 1.405467
global_step: 4287, epoch: 8, loss: 1.364013
global_step: 4288, epoch: 8, loss: 1.281953
global_step: 4289, epoch: 8, loss: 1.239944
global_step: 4290, epoch: 8, loss: 1.288528
global_step: 4291, epoch: 8, loss: 1.279656
global_step: 4292, epoch: 8, loss: 1.392144
global_step: 4293, epoch: 8, loss: 1.347599
global_step: 4294, epoch: 8, loss: 1.392977
global_step: 4295, epoch: 8, loss: 1.249979
global_step: 4296, epoch: 8, loss: 1.383863
global_step: 4297, epoch: 8, loss: 1.337983
global_step: 4298, epoch: 8, loss: 1.290870
global_step: 4299, epoch: 8, loss: 1.391416
global_step: 4300, epoch: 8, loss: 1.356874
global_step: 4301, epoch: 8, loss: 1.319968
global_step: 4302, epoch: 8, loss: 1.366591
global_step: 4303, epoch: 8, loss: 1.374198
global_step: 4304, epoch: 8, loss: 1.429888
global_step: 4305, epoch: 8, loss: 1.293996
global_step: 4306, epoch: 8, loss: 1.370888
global_step: 4307, epoch: 8, loss: 1.369897
global_step: 4308, epoch: 8, loss: 1.396359
global_step: 4309, epoch: 8, loss: 1.422276
global_step: 4310, epoch: 8, loss: 1.343359
global_step: 4311, epoch: 8, loss: 1.388843
global_step: 4312, epoch: 8, loss: 1.316582
global_step: 4313, epoch: 8, loss: 1.344025
global_step: 4314, epoch: 8, loss: 1.385702
global_step: 4315, epoch: 8, loss: 1.362277
global_step: 4316, epoch: 8, loss: 1.393547
global_step: 4317, epoch: 8, loss: 1.351671
global_step: 4318, epoch: 8, loss: 1.245105
global_step: 4319, epoch: 8, loss: 1.359813
global_step: 4320, epoch: 8, loss: 2.020485
epoch: 8
train	acc: 0.5811	macro: p 0.3039, r 0.2783, f1: 0.2731	micro: p 0.5811, r 0.5811, f1 0.5811	weighted_f1:0.5162
dev	acc: 0.5320	macro: p 0.2765, r 0.2722, f1: 0.2585	micro: p 0.5320, r 0.5320, f1 0.5320	weighted_f1:0.4572
test	acc: 0.5785	macro: p 0.2912, r 0.2725, f1: 0.2666	micro: p 0.5785, r 0.5785, f1 0.5785	weighted_f1:0.5135
New best model!
global_step: 4321, epoch: 9, loss: 1.342344
global_step: 4322, epoch: 9, loss: 1.404747
global_step: 4323, epoch: 9, loss: 1.448989
global_step: 4324, epoch: 9, loss: 1.313905
global_step: 4325, epoch: 9, loss: 1.250063
global_step: 4326, epoch: 9, loss: 1.392578
global_step: 4327, epoch: 9, loss: 1.369769
global_step: 4328, epoch: 9, loss: 1.292562
global_step: 4329, epoch: 9, loss: 1.404725
global_step: 4330, epoch: 9, loss: 1.245901
global_step: 4331, epoch: 9, loss: 1.386131
global_step: 4332, epoch: 9, loss: 1.353218
global_step: 4333, epoch: 9, loss: 1.335638
global_step: 4334, epoch: 9, loss: 1.356380
global_step: 4335, epoch: 9, loss: 1.318764
global_step: 4336, epoch: 9, loss: 1.241271
global_step: 4337, epoch: 9, loss: 1.315702
global_step: 4338, epoch: 9, loss: 1.375176
global_step: 4339, epoch: 9, loss: 1.313374
global_step: 4340, epoch: 9, loss: 1.342230
global_step: 4341, epoch: 9, loss: 1.367347
global_step: 4342, epoch: 9, loss: 1.414838
global_step: 4343, epoch: 9, loss: 1.325673
global_step: 4344, epoch: 9, loss: 1.344723
global_step: 4345, epoch: 9, loss: 1.342118
global_step: 4346, epoch: 9, loss: 1.418306
global_step: 4347, epoch: 9, loss: 1.362666
global_step: 4348, epoch: 9, loss: 1.416283
global_step: 4349, epoch: 9, loss: 1.225713
global_step: 4350, epoch: 9, loss: 1.356280
global_step: 4351, epoch: 9, loss: 1.318155
global_step: 4352, epoch: 9, loss: 1.318452
global_step: 4353, epoch: 9, loss: 1.260659
global_step: 4354, epoch: 9, loss: 1.313981
global_step: 4355, epoch: 9, loss: 1.194227
global_step: 4356, epoch: 9, loss: 1.426735
global_step: 4357, epoch: 9, loss: 1.394627
global_step: 4358, epoch: 9, loss: 1.314727
global_step: 4359, epoch: 9, loss: 1.376974
global_step: 4360, epoch: 9, loss: 0.606286
epoch: 9
train	acc: 0.5836	macro: p 0.3029, r 0.2789, f1: 0.2750	micro: p 0.5836, r 0.5836, f1 0.5836	weighted_f1:0.5181
dev	acc: 0.5293	macro: p 0.2721, r 0.2693, f1: 0.2546	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4533
test	acc: 0.5770	macro: p 0.2828, r 0.2693, f1: 0.2619	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5093
global_step: 4361, epoch: 10, loss: 1.333726
global_step: 4362, epoch: 10, loss: 1.260159
global_step: 4363, epoch: 10, loss: 1.376437
global_step: 4364, epoch: 10, loss: 1.305853
global_step: 4365, epoch: 10, loss: 1.342527
global_step: 4366, epoch: 10, loss: 1.361012
global_step: 4367, epoch: 10, loss: 1.306951
global_step: 4368, epoch: 10, loss: 1.436783
global_step: 4369, epoch: 10, loss: 1.325348
global_step: 4370, epoch: 10, loss: 1.361270
global_step: 4371, epoch: 10, loss: 1.345567
global_step: 4372, epoch: 10, loss: 1.323057
global_step: 4373, epoch: 10, loss: 1.284223
global_step: 4374, epoch: 10, loss: 1.411840
global_step: 4375, epoch: 10, loss: 1.243045
global_step: 4376, epoch: 10, loss: 1.332704
global_step: 4377, epoch: 10, loss: 1.374032
global_step: 4378, epoch: 10, loss: 1.389326
global_step: 4379, epoch: 10, loss: 1.262540
global_step: 4380, epoch: 10, loss: 1.342818
global_step: 4381, epoch: 10, loss: 1.241827
global_step: 4382, epoch: 10, loss: 1.254418
global_step: 4383, epoch: 10, loss: 1.265904
global_step: 4384, epoch: 10, loss: 1.400541
global_step: 4385, epoch: 10, loss: 1.245482
global_step: 4386, epoch: 10, loss: 1.386769
global_step: 4387, epoch: 10, loss: 1.225464
global_step: 4388, epoch: 10, loss: 1.324684
global_step: 4389, epoch: 10, loss: 1.492979
global_step: 4390, epoch: 10, loss: 1.342020
global_step: 4391, epoch: 10, loss: 1.301744
global_step: 4392, epoch: 10, loss: 1.339249
global_step: 4393, epoch: 10, loss: 1.324437
global_step: 4394, epoch: 10, loss: 1.353799
global_step: 4395, epoch: 10, loss: 1.178199
global_step: 4396, epoch: 10, loss: 1.291996
global_step: 4397, epoch: 10, loss: 1.339358
global_step: 4398, epoch: 10, loss: 1.355507
global_step: 4399, epoch: 10, loss: 1.404405
global_step: 4400, epoch: 10, loss: 1.269588
epoch: 10
train	acc: 0.5871	macro: p 0.3003, r 0.2833, f1: 0.2798	micro: p 0.5871, r 0.5871, f1 0.5871	weighted_f1:0.5231
dev	acc: 0.5257	macro: p 0.2619, r 0.2656, f1: 0.2490	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4483
test	acc: 0.5759	macro: p 0.4151, r 0.2706, f1: 0.2618	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5089
global_step: 4401, epoch: 11, loss: 1.373480
global_step: 4402, epoch: 11, loss: 1.268391
global_step: 4403, epoch: 11, loss: 1.315052
global_step: 4404, epoch: 11, loss: 1.309084
global_step: 4405, epoch: 11, loss: 1.265425
global_step: 4406, epoch: 11, loss: 1.384449
global_step: 4407, epoch: 11, loss: 1.342288
global_step: 4408, epoch: 11, loss: 1.389699
global_step: 4409, epoch: 11, loss: 1.274131
global_step: 4410, epoch: 11, loss: 1.289466
global_step: 4411, epoch: 11, loss: 1.369742
global_step: 4412, epoch: 11, loss: 1.235035
global_step: 4413, epoch: 11, loss: 1.328070
global_step: 4414, epoch: 11, loss: 1.212717
global_step: 4415, epoch: 11, loss: 1.401801
global_step: 4416, epoch: 11, loss: 1.510187
global_step: 4417, epoch: 11, loss: 1.474172
global_step: 4418, epoch: 11, loss: 1.438499
global_step: 4419, epoch: 11, loss: 1.360109
global_step: 4420, epoch: 11, loss: 1.211238
global_step: 4421, epoch: 11, loss: 1.192888
global_step: 4422, epoch: 11, loss: 1.333276
global_step: 4423, epoch: 11, loss: 1.336996
global_step: 4424, epoch: 11, loss: 1.351134
global_step: 4425, epoch: 11, loss: 1.265308
global_step: 4426, epoch: 11, loss: 1.248162
global_step: 4427, epoch: 11, loss: 1.379772
global_step: 4428, epoch: 11, loss: 1.290888
global_step: 4429, epoch: 11, loss: 1.332591
global_step: 4430, epoch: 11, loss: 1.319268
global_step: 4431, epoch: 11, loss: 1.308909
global_step: 4432, epoch: 11, loss: 1.240470
global_step: 4433, epoch: 11, loss: 1.189900
global_step: 4434, epoch: 11, loss: 1.242677
global_step: 4435, epoch: 11, loss: 1.311556
global_step: 4436, epoch: 11, loss: 1.353466
global_step: 4437, epoch: 11, loss: 1.277054
global_step: 4438, epoch: 11, loss: 1.315420
global_step: 4439, epoch: 11, loss: 1.323535
global_step: 4440, epoch: 11, loss: 1.715242
epoch: 11
train	acc: 0.5878	macro: p 0.4514, r 0.2842, f1: 0.2809	micro: p 0.5878, r 0.5878, f1 0.5878	weighted_f1:0.5241
dev	acc: 0.5302	macro: p 0.2710, r 0.2703, f1: 0.2548	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4548
test	acc: 0.5797	macro: p 0.4303, r 0.2738, f1: 0.2671	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5139
global_step: 4441, epoch: 12, loss: 1.170656
global_step: 4442, epoch: 12, loss: 1.304068
global_step: 4443, epoch: 12, loss: 1.332101
global_step: 4444, epoch: 12, loss: 1.217405
global_step: 4445, epoch: 12, loss: 1.357418
global_step: 4446, epoch: 12, loss: 1.241846
global_step: 4447, epoch: 12, loss: 1.323078
global_step: 4448, epoch: 12, loss: 1.185316
global_step: 4449, epoch: 12, loss: 1.372916
global_step: 4450, epoch: 12, loss: 1.459224
global_step: 4451, epoch: 12, loss: 1.422518
global_step: 4452, epoch: 12, loss: 1.240773
global_step: 4453, epoch: 12, loss: 1.263968
global_step: 4454, epoch: 12, loss: 1.349765
global_step: 4455, epoch: 12, loss: 1.291849
global_step: 4456, epoch: 12, loss: 1.336393
global_step: 4457, epoch: 12, loss: 1.269712
global_step: 4458, epoch: 12, loss: 1.328135
global_step: 4459, epoch: 12, loss: 1.356401
global_step: 4460, epoch: 12, loss: 1.291559
global_step: 4461, epoch: 12, loss: 1.479047
global_step: 4462, epoch: 12, loss: 1.330466
global_step: 4463, epoch: 12, loss: 1.349070
global_step: 4464, epoch: 12, loss: 1.263119
global_step: 4465, epoch: 12, loss: 1.278351
global_step: 4466, epoch: 12, loss: 1.271710
global_step: 4467, epoch: 12, loss: 1.460997
global_step: 4468, epoch: 12, loss: 1.314744
global_step: 4469, epoch: 12, loss: 1.243956
global_step: 4470, epoch: 12, loss: 1.325308
global_step: 4471, epoch: 12, loss: 1.262775
global_step: 4472, epoch: 12, loss: 1.285744
global_step: 4473, epoch: 12, loss: 1.237421
global_step: 4474, epoch: 12, loss: 1.292238
global_step: 4475, epoch: 12, loss: 1.381771
global_step: 4476, epoch: 12, loss: 1.296546
global_step: 4477, epoch: 12, loss: 1.306851
global_step: 4478, epoch: 12, loss: 1.243802
global_step: 4479, epoch: 12, loss: 1.282724
global_step: 4480, epoch: 12, loss: 0.654817
epoch: 12
train	acc: 0.5881	macro: p 0.4426, r 0.2880, f1: 0.2848	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5266
dev	acc: 0.5302	macro: p 0.2675, r 0.2712, f1: 0.2573	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4564
test	acc: 0.5770	macro: p 0.4168, r 0.2754, f1: 0.2690	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5144
global_step: 4481, epoch: 13, loss: 1.246650
global_step: 4482, epoch: 13, loss: 1.309127
global_step: 4483, epoch: 13, loss: 1.206338
global_step: 4484, epoch: 13, loss: 1.334784
global_step: 4485, epoch: 13, loss: 1.216632
global_step: 4486, epoch: 13, loss: 1.382517
global_step: 4487, epoch: 13, loss: 1.392832
global_step: 4488, epoch: 13, loss: 1.379141
global_step: 4489, epoch: 13, loss: 1.223096
global_step: 4490, epoch: 13, loss: 1.324844
global_step: 4491, epoch: 13, loss: 1.411885
global_step: 4492, epoch: 13, loss: 1.325553
global_step: 4493, epoch: 13, loss: 1.260967
global_step: 4494, epoch: 13, loss: 1.309472
global_step: 4495, epoch: 13, loss: 1.254764
global_step: 4496, epoch: 13, loss: 1.201340
global_step: 4497, epoch: 13, loss: 1.370535
global_step: 4498, epoch: 13, loss: 1.367458
global_step: 4499, epoch: 13, loss: 1.338504
global_step: 4500, epoch: 13, loss: 1.337286
global_step: 4501, epoch: 13, loss: 1.304581
global_step: 4502, epoch: 13, loss: 1.217773
global_step: 4503, epoch: 13, loss: 1.309694
global_step: 4504, epoch: 13, loss: 1.247931
global_step: 4505, epoch: 13, loss: 1.260814
global_step: 4506, epoch: 13, loss: 1.365767
global_step: 4507, epoch: 13, loss: 1.235746
global_step: 4508, epoch: 13, loss: 1.370998
global_step: 4509, epoch: 13, loss: 1.308990
global_step: 4510, epoch: 13, loss: 1.405011
global_step: 4511, epoch: 13, loss: 1.258870
global_step: 4512, epoch: 13, loss: 1.303675
global_step: 4513, epoch: 13, loss: 1.313926
global_step: 4514, epoch: 13, loss: 1.277860
global_step: 4515, epoch: 13, loss: 1.224937
global_step: 4516, epoch: 13, loss: 1.261101
global_step: 4517, epoch: 13, loss: 1.368353
global_step: 4518, epoch: 13, loss: 1.286253
global_step: 4519, epoch: 13, loss: 1.197096
global_step: 4520, epoch: 13, loss: 0.774839
epoch: 13
train	acc: 0.5860	macro: p 0.4503, r 0.2859, f1: 0.2824	micro: p 0.5860, r 0.5860, f1 0.5860	weighted_f1:0.5234
dev	acc: 0.5338	macro: p 0.2767, r 0.2740, f1: 0.2617	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4608
test	acc: 0.5828	macro: p 0.4356, r 0.2787, f1: 0.2754	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5201
New best model!
global_step: 4521, epoch: 14, loss: 1.388812
global_step: 4522, epoch: 14, loss: 1.371255
global_step: 4523, epoch: 14, loss: 1.334313
global_step: 4524, epoch: 14, loss: 1.369174
global_step: 4525, epoch: 14, loss: 1.286216
global_step: 4526, epoch: 14, loss: 1.265541
global_step: 4527, epoch: 14, loss: 1.247067
global_step: 4528, epoch: 14, loss: 1.358072
global_step: 4529, epoch: 14, loss: 1.342840
global_step: 4530, epoch: 14, loss: 1.346398
global_step: 4531, epoch: 14, loss: 1.414590
global_step: 4532, epoch: 14, loss: 1.236462
global_step: 4533, epoch: 14, loss: 1.250102
global_step: 4534, epoch: 14, loss: 1.397201
global_step: 4535, epoch: 14, loss: 1.270693
global_step: 4536, epoch: 14, loss: 1.365165
global_step: 4537, epoch: 14, loss: 1.310328
global_step: 4538, epoch: 14, loss: 1.346383
global_step: 4539, epoch: 14, loss: 1.277949
global_step: 4540, epoch: 14, loss: 1.310364
global_step: 4541, epoch: 14, loss: 1.248961
global_step: 4542, epoch: 14, loss: 1.316993
global_step: 4543, epoch: 14, loss: 1.243745
global_step: 4544, epoch: 14, loss: 1.249859
global_step: 4545, epoch: 14, loss: 1.257660
global_step: 4546, epoch: 14, loss: 1.351394
global_step: 4547, epoch: 14, loss: 1.194688
global_step: 4548, epoch: 14, loss: 1.337783
global_step: 4549, epoch: 14, loss: 1.181734
global_step: 4550, epoch: 14, loss: 1.189675
global_step: 4551, epoch: 14, loss: 1.220552
global_step: 4552, epoch: 14, loss: 1.159889
global_step: 4553, epoch: 14, loss: 1.150053
global_step: 4554, epoch: 14, loss: 1.246680
global_step: 4555, epoch: 14, loss: 1.425720
global_step: 4556, epoch: 14, loss: 1.135849
global_step: 4557, epoch: 14, loss: 1.291502
global_step: 4558, epoch: 14, loss: 1.324688
global_step: 4559, epoch: 14, loss: 1.300590
global_step: 4560, epoch: 14, loss: 2.104765
epoch: 14
train	acc: 0.5894	macro: p 0.4098, r 0.2947, f1: 0.2905	micro: p 0.5894, r 0.5894, f1 0.5894	weighted_f1:0.5306
dev	acc: 0.5338	macro: p 0.2711, r 0.2768, f1: 0.2647	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4638
test	acc: 0.5797	macro: p 0.4211, r 0.2821, f1: 0.2769	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5205
New best model!
global_step: 4561, epoch: 15, loss: 1.291494
global_step: 4562, epoch: 15, loss: 1.066494
global_step: 4563, epoch: 15, loss: 1.382879
global_step: 4564, epoch: 15, loss: 1.215670
global_step: 4565, epoch: 15, loss: 1.245333
global_step: 4566, epoch: 15, loss: 1.371243
global_step: 4567, epoch: 15, loss: 1.311363
global_step: 4568, epoch: 15, loss: 1.352481
global_step: 4569, epoch: 15, loss: 1.268613
global_step: 4570, epoch: 15, loss: 1.369333
global_step: 4571, epoch: 15, loss: 1.304955
global_step: 4572, epoch: 15, loss: 1.292302
global_step: 4573, epoch: 15, loss: 1.261054
global_step: 4574, epoch: 15, loss: 1.406401
global_step: 4575, epoch: 15, loss: 1.168612
global_step: 4576, epoch: 15, loss: 1.315987
global_step: 4577, epoch: 15, loss: 1.226816
global_step: 4578, epoch: 15, loss: 1.294886
global_step: 4579, epoch: 15, loss: 1.299118
global_step: 4580, epoch: 15, loss: 1.275654
global_step: 4581, epoch: 15, loss: 1.170425
global_step: 4582, epoch: 15, loss: 1.364099
global_step: 4583, epoch: 15, loss: 1.291402
global_step: 4584, epoch: 15, loss: 1.226736
global_step: 4585, epoch: 15, loss: 1.335688
global_step: 4586, epoch: 15, loss: 1.218145
global_step: 4587, epoch: 15, loss: 1.306869
global_step: 4588, epoch: 15, loss: 1.218289
global_step: 4589, epoch: 15, loss: 1.175862
global_step: 4590, epoch: 15, loss: 1.270929
global_step: 4591, epoch: 15, loss: 1.274816
global_step: 4592, epoch: 15, loss: 1.299836
global_step: 4593, epoch: 15, loss: 1.303336
global_step: 4594, epoch: 15, loss: 1.331292
global_step: 4595, epoch: 15, loss: 1.246529
global_step: 4596, epoch: 15, loss: 1.151203
global_step: 4597, epoch: 15, loss: 1.242673
global_step: 4598, epoch: 15, loss: 1.302227
global_step: 4599, epoch: 15, loss: 1.330002
global_step: 4600, epoch: 15, loss: 1.127904
epoch: 15
train	acc: 0.5964	macro: p 0.4263, r 0.2989, f1: 0.2978	micro: p 0.5964, r 0.5964, f1 0.5964	weighted_f1:0.5384
dev	acc: 0.5356	macro: p 0.4146, r 0.2784, f1: 0.2662	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4650
test	acc: 0.5824	macro: p 0.4241, r 0.2834, f1: 0.2781	micro: p 0.5824, r 0.5824, f1 0.5824	weighted_f1:0.5224
New best model!
global_step: 4601, epoch: 16, loss: 1.228907
global_step: 4602, epoch: 16, loss: 1.207354
global_step: 4603, epoch: 16, loss: 1.159294
global_step: 4604, epoch: 16, loss: 1.190848
global_step: 4605, epoch: 16, loss: 1.341576
global_step: 4606, epoch: 16, loss: 1.313342
global_step: 4607, epoch: 16, loss: 1.254255
global_step: 4608, epoch: 16, loss: 1.231795
global_step: 4609, epoch: 16, loss: 1.250510
global_step: 4610, epoch: 16, loss: 1.263057
global_step: 4611, epoch: 16, loss: 1.291655
global_step: 4612, epoch: 16, loss: 1.242185
global_step: 4613, epoch: 16, loss: 1.316022
global_step: 4614, epoch: 16, loss: 1.161710
global_step: 4615, epoch: 16, loss: 1.191495
global_step: 4616, epoch: 16, loss: 1.315292
global_step: 4617, epoch: 16, loss: 1.304430
global_step: 4618, epoch: 16, loss: 1.277651
global_step: 4619, epoch: 16, loss: 1.284625
global_step: 4620, epoch: 16, loss: 1.389296
global_step: 4621, epoch: 16, loss: 1.288828
global_step: 4622, epoch: 16, loss: 1.235237
global_step: 4623, epoch: 16, loss: 1.202611
global_step: 4624, epoch: 16, loss: 1.367037
global_step: 4625, epoch: 16, loss: 1.388413
global_step: 4626, epoch: 16, loss: 1.320831
global_step: 4627, epoch: 16, loss: 1.341683
global_step: 4628, epoch: 16, loss: 1.334623
global_step: 4629, epoch: 16, loss: 1.283405
global_step: 4630, epoch: 16, loss: 1.260932
global_step: 4631, epoch: 16, loss: 1.177968
global_step: 4632, epoch: 16, loss: 1.305695
global_step: 4633, epoch: 16, loss: 1.233866
global_step: 4634, epoch: 16, loss: 1.209617
global_step: 4635, epoch: 16, loss: 1.256738
global_step: 4636, epoch: 16, loss: 1.154565
global_step: 4637, epoch: 16, loss: 1.210120
global_step: 4638, epoch: 16, loss: 1.281577
global_step: 4639, epoch: 16, loss: 1.327661
global_step: 4640, epoch: 16, loss: 1.127400
epoch: 16
train	acc: 0.5997	macro: p 0.4185, r 0.2995, f1: 0.3013	micro: p 0.5997, r 0.5997, f1 0.5997	weighted_f1:0.5411
dev	acc: 0.5356	macro: p 0.3798, r 0.2800, f1: 0.2690	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4663
test	acc: 0.5870	macro: p 0.4341, r 0.2851, f1: 0.2814	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5254
New best model!
global_step: 4641, epoch: 17, loss: 1.298792
global_step: 4642, epoch: 17, loss: 1.297403
global_step: 4643, epoch: 17, loss: 1.257241
global_step: 4644, epoch: 17, loss: 1.218110
global_step: 4645, epoch: 17, loss: 1.338211
global_step: 4646, epoch: 17, loss: 1.232874
global_step: 4647, epoch: 17, loss: 1.269511
global_step: 4648, epoch: 17, loss: 1.212945
global_step: 4649, epoch: 17, loss: 1.213580
global_step: 4650, epoch: 17, loss: 1.217033
global_step: 4651, epoch: 17, loss: 1.291403
global_step: 4652, epoch: 17, loss: 1.321348
global_step: 4653, epoch: 17, loss: 1.289458
global_step: 4654, epoch: 17, loss: 1.222423
global_step: 4655, epoch: 17, loss: 1.277733
global_step: 4656, epoch: 17, loss: 1.214192
global_step: 4657, epoch: 17, loss: 1.239697
global_step: 4658, epoch: 17, loss: 1.250366
global_step: 4659, epoch: 17, loss: 1.284775
global_step: 4660, epoch: 17, loss: 1.171435
global_step: 4661, epoch: 17, loss: 1.261981
global_step: 4662, epoch: 17, loss: 1.295019
global_step: 4663, epoch: 17, loss: 1.372237
global_step: 4664, epoch: 17, loss: 1.274886
global_step: 4665, epoch: 17, loss: 1.245951
global_step: 4666, epoch: 17, loss: 1.262449
global_step: 4667, epoch: 17, loss: 1.211088
global_step: 4668, epoch: 17, loss: 1.204826
global_step: 4669, epoch: 17, loss: 1.236964
global_step: 4670, epoch: 17, loss: 1.194704
global_step: 4671, epoch: 17, loss: 1.307818
global_step: 4672, epoch: 17, loss: 1.295206
global_step: 4673, epoch: 17, loss: 1.244843
global_step: 4674, epoch: 17, loss: 1.342198
global_step: 4675, epoch: 17, loss: 1.290053
global_step: 4676, epoch: 17, loss: 1.283602
global_step: 4677, epoch: 17, loss: 1.281739
global_step: 4678, epoch: 17, loss: 1.190258
global_step: 4679, epoch: 17, loss: 1.290163
global_step: 4680, epoch: 17, loss: 1.526818
epoch: 17
train	acc: 0.6020	macro: p 0.4194, r 0.3040, f1: 0.3056	micro: p 0.6020, r 0.6020, f1 0.6020	weighted_f1:0.5450
dev	acc: 0.5347	macro: p 0.3764, r 0.2794, f1: 0.2687	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4660
test	acc: 0.5877	macro: p 0.4286, r 0.2884, f1: 0.2841	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5276
global_step: 4681, epoch: 18, loss: 1.249777
global_step: 4682, epoch: 18, loss: 1.347039
global_step: 4683, epoch: 18, loss: 1.265550
global_step: 4684, epoch: 18, loss: 1.208106
global_step: 4685, epoch: 18, loss: 1.263516
global_step: 4686, epoch: 18, loss: 1.331761
global_step: 4687, epoch: 18, loss: 1.258058
global_step: 4688, epoch: 18, loss: 1.300148
global_step: 4689, epoch: 18, loss: 1.123395
global_step: 4690, epoch: 18, loss: 1.276613
global_step: 4691, epoch: 18, loss: 1.221279
global_step: 4692, epoch: 18, loss: 1.285181
global_step: 4693, epoch: 18, loss: 1.244877
global_step: 4694, epoch: 18, loss: 1.232903
global_step: 4695, epoch: 18, loss: 1.166677
global_step: 4696, epoch: 18, loss: 1.453188
global_step: 4697, epoch: 18, loss: 1.249664
global_step: 4698, epoch: 18, loss: 1.168013
global_step: 4699, epoch: 18, loss: 1.281447
global_step: 4700, epoch: 18, loss: 1.182195
global_step: 4701, epoch: 18, loss: 1.188714
global_step: 4702, epoch: 18, loss: 1.171505
global_step: 4703, epoch: 18, loss: 1.220801
global_step: 4704, epoch: 18, loss: 1.277261
global_step: 4705, epoch: 18, loss: 1.326433
global_step: 4706, epoch: 18, loss: 1.228937
global_step: 4707, epoch: 18, loss: 1.260339
global_step: 4708, epoch: 18, loss: 1.309567
global_step: 4709, epoch: 18, loss: 1.339919
global_step: 4710, epoch: 18, loss: 1.154410
global_step: 4711, epoch: 18, loss: 1.217681
global_step: 4712, epoch: 18, loss: 1.287024
global_step: 4713, epoch: 18, loss: 1.217790
global_step: 4714, epoch: 18, loss: 1.095448
global_step: 4715, epoch: 18, loss: 1.186989
global_step: 4716, epoch: 18, loss: 1.261568
global_step: 4717, epoch: 18, loss: 1.249362
global_step: 4718, epoch: 18, loss: 1.415203
global_step: 4719, epoch: 18, loss: 1.371316
global_step: 4720, epoch: 18, loss: 1.499445
epoch: 18
train	acc: 0.6070	macro: p 0.4195, r 0.3088, f1: 0.3125	micro: p 0.6070, r 0.6070, f1 0.6070	weighted_f1:0.5512
dev	acc: 0.5356	macro: p 0.3794, r 0.2802, f1: 0.2692	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4671
test	acc: 0.5862	macro: p 0.4018, r 0.2887, f1: 0.2861	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5277
New best model!
global_step: 4721, epoch: 19, loss: 1.254195
global_step: 4722, epoch: 19, loss: 1.203549
global_step: 4723, epoch: 19, loss: 1.198326
global_step: 4724, epoch: 19, loss: 1.256161
global_step: 4725, epoch: 19, loss: 1.376564
global_step: 4726, epoch: 19, loss: 1.245609
global_step: 4727, epoch: 19, loss: 1.198626
global_step: 4728, epoch: 19, loss: 1.287422
global_step: 4729, epoch: 19, loss: 1.225914
global_step: 4730, epoch: 19, loss: 1.258157
global_step: 4731, epoch: 19, loss: 1.399511
global_step: 4732, epoch: 19, loss: 1.352722
global_step: 4733, epoch: 19, loss: 1.207247
global_step: 4734, epoch: 19, loss: 1.310269
global_step: 4735, epoch: 19, loss: 1.214522
global_step: 4736, epoch: 19, loss: 1.277712
global_step: 4737, epoch: 19, loss: 1.247267
global_step: 4738, epoch: 19, loss: 1.324746
global_step: 4739, epoch: 19, loss: 1.210941
global_step: 4740, epoch: 19, loss: 1.176175
global_step: 4741, epoch: 19, loss: 1.214591
global_step: 4742, epoch: 19, loss: 1.252098
global_step: 4743, epoch: 19, loss: 1.241975
global_step: 4744, epoch: 19, loss: 1.272470
global_step: 4745, epoch: 19, loss: 1.176130
global_step: 4746, epoch: 19, loss: 1.219206
global_step: 4747, epoch: 19, loss: 1.303615
global_step: 4748, epoch: 19, loss: 1.254487
global_step: 4749, epoch: 19, loss: 1.193060
global_step: 4750, epoch: 19, loss: 1.231971
global_step: 4751, epoch: 19, loss: 1.179953
global_step: 4752, epoch: 19, loss: 1.287453
global_step: 4753, epoch: 19, loss: 1.250510
global_step: 4754, epoch: 19, loss: 1.328480
global_step: 4755, epoch: 19, loss: 1.277500
global_step: 4756, epoch: 19, loss: 1.171816
global_step: 4757, epoch: 19, loss: 1.223135
global_step: 4758, epoch: 19, loss: 1.207153
global_step: 4759, epoch: 19, loss: 1.251263
global_step: 4760, epoch: 19, loss: 0.949288
epoch: 19
train	acc: 0.6046	macro: p 0.4317, r 0.3025, f1: 0.3054	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5453
dev	acc: 0.5374	macro: p 0.3795, r 0.2801, f1: 0.2678	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4659
test	acc: 0.5897	macro: p 0.4342, r 0.2864, f1: 0.2823	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5265
global_step: 4761, epoch: 20, loss: 1.319109
global_step: 4762, epoch: 20, loss: 1.236557
global_step: 4763, epoch: 20, loss: 1.223346
global_step: 4764, epoch: 20, loss: 1.343769
global_step: 4765, epoch: 20, loss: 1.214689
global_step: 4766, epoch: 20, loss: 1.242733
global_step: 4767, epoch: 20, loss: 1.250574
global_step: 4768, epoch: 20, loss: 1.271890
global_step: 4769, epoch: 20, loss: 1.321581
global_step: 4770, epoch: 20, loss: 1.226073
global_step: 4771, epoch: 20, loss: 1.183556
global_step: 4772, epoch: 20, loss: 1.414996
global_step: 4773, epoch: 20, loss: 1.240752
global_step: 4774, epoch: 20, loss: 1.176003
global_step: 4775, epoch: 20, loss: 1.236763
global_step: 4776, epoch: 20, loss: 1.179298
global_step: 4777, epoch: 20, loss: 1.149793
global_step: 4778, epoch: 20, loss: 1.264456
global_step: 4779, epoch: 20, loss: 1.199798
global_step: 4780, epoch: 20, loss: 1.292318
global_step: 4781, epoch: 20, loss: 1.280383
global_step: 4782, epoch: 20, loss: 1.245128
global_step: 4783, epoch: 20, loss: 1.216555
global_step: 4784, epoch: 20, loss: 1.359122
global_step: 4785, epoch: 20, loss: 1.173053
global_step: 4786, epoch: 20, loss: 1.327892
global_step: 4787, epoch: 20, loss: 1.235215
global_step: 4788, epoch: 20, loss: 1.217531
global_step: 4789, epoch: 20, loss: 1.315792
global_step: 4790, epoch: 20, loss: 1.177142
global_step: 4791, epoch: 20, loss: 1.162131
global_step: 4792, epoch: 20, loss: 1.329675
global_step: 4793, epoch: 20, loss: 1.305683
global_step: 4794, epoch: 20, loss: 1.174788
global_step: 4795, epoch: 20, loss: 1.257633
global_step: 4796, epoch: 20, loss: 1.093766
global_step: 4797, epoch: 20, loss: 1.235438
global_step: 4798, epoch: 20, loss: 1.274370
global_step: 4799, epoch: 20, loss: 1.253221
global_step: 4800, epoch: 20, loss: 1.066158
epoch: 20
train	acc: 0.6109	macro: p 0.4207, r 0.3155, f1: 0.3216	micro: p 0.6109, r 0.6109, f1 0.6109	weighted_f1:0.5580
dev	acc: 0.5392	macro: p 0.3706, r 0.2844, f1: 0.2759	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4732
test	acc: 0.5931	macro: p 0.3937, r 0.2954, f1: 0.2962	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5369
New best model!
global_step: 4801, epoch: 21, loss: 1.311863
global_step: 4802, epoch: 21, loss: 1.211053
global_step: 4803, epoch: 21, loss: 1.249626
global_step: 4804, epoch: 21, loss: 1.240012
global_step: 4805, epoch: 21, loss: 1.245291
global_step: 4806, epoch: 21, loss: 1.151997
global_step: 4807, epoch: 21, loss: 1.150561
global_step: 4808, epoch: 21, loss: 1.187129
global_step: 4809, epoch: 21, loss: 1.262605
global_step: 4810, epoch: 21, loss: 1.134841
global_step: 4811, epoch: 21, loss: 1.228638
global_step: 4812, epoch: 21, loss: 1.315590
global_step: 4813, epoch: 21, loss: 1.147385
global_step: 4814, epoch: 21, loss: 1.151783
global_step: 4815, epoch: 21, loss: 1.304479
global_step: 4816, epoch: 21, loss: 1.159771
global_step: 4817, epoch: 21, loss: 1.311199
global_step: 4818, epoch: 21, loss: 1.155632
global_step: 4819, epoch: 21, loss: 1.343390
global_step: 4820, epoch: 21, loss: 1.253324
global_step: 4821, epoch: 21, loss: 1.291916
global_step: 4822, epoch: 21, loss: 1.226856
global_step: 4823, epoch: 21, loss: 1.261158
global_step: 4824, epoch: 21, loss: 1.192758
global_step: 4825, epoch: 21, loss: 1.176590
global_step: 4826, epoch: 21, loss: 1.240546
global_step: 4827, epoch: 21, loss: 1.176746
global_step: 4828, epoch: 21, loss: 1.229522
global_step: 4829, epoch: 21, loss: 1.183469
global_step: 4830, epoch: 21, loss: 1.199720
global_step: 4831, epoch: 21, loss: 1.273311
global_step: 4832, epoch: 21, loss: 1.336515
global_step: 4833, epoch: 21, loss: 1.275321
global_step: 4834, epoch: 21, loss: 1.244693
global_step: 4835, epoch: 21, loss: 1.124002
global_step: 4836, epoch: 21, loss: 1.250217
global_step: 4837, epoch: 21, loss: 1.215201
global_step: 4838, epoch: 21, loss: 1.306339
global_step: 4839, epoch: 21, loss: 1.181694
global_step: 4840, epoch: 21, loss: 0.831229
epoch: 21
train	acc: 0.6087	macro: p 0.4269, r 0.3092, f1: 0.3149	micro: p 0.6087, r 0.6087, f1 0.6087	weighted_f1:0.5520
dev	acc: 0.5410	macro: p 0.3840, r 0.2841, f1: 0.2742	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4722
test	acc: 0.5912	macro: p 0.3943, r 0.2886, f1: 0.2852	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5292
global_step: 4841, epoch: 22, loss: 1.243898
global_step: 4842, epoch: 22, loss: 1.183995
global_step: 4843, epoch: 22, loss: 1.317041
global_step: 4844, epoch: 22, loss: 1.197912
global_step: 4845, epoch: 22, loss: 1.176180
global_step: 4846, epoch: 22, loss: 1.178562
global_step: 4847, epoch: 22, loss: 1.270498
global_step: 4848, epoch: 22, loss: 1.236324
global_step: 4849, epoch: 22, loss: 1.282395
global_step: 4850, epoch: 22, loss: 1.224335
global_step: 4851, epoch: 22, loss: 1.235233
global_step: 4852, epoch: 22, loss: 1.301925
global_step: 4853, epoch: 22, loss: 1.279041
global_step: 4854, epoch: 22, loss: 1.295640
global_step: 4855, epoch: 22, loss: 1.321367
global_step: 4856, epoch: 22, loss: 1.221859
global_step: 4857, epoch: 22, loss: 1.251025
global_step: 4858, epoch: 22, loss: 1.335944
global_step: 4859, epoch: 22, loss: 1.247303
global_step: 4860, epoch: 22, loss: 1.238915
global_step: 4861, epoch: 22, loss: 1.187436
global_step: 4862, epoch: 22, loss: 1.129893
global_step: 4863, epoch: 22, loss: 1.291309
global_step: 4864, epoch: 22, loss: 1.291395
global_step: 4865, epoch: 22, loss: 1.129526
global_step: 4866, epoch: 22, loss: 1.146459
global_step: 4867, epoch: 22, loss: 1.151373
global_step: 4868, epoch: 22, loss: 1.154842
global_step: 4869, epoch: 22, loss: 1.348364
global_step: 4870, epoch: 22, loss: 1.150480
global_step: 4871, epoch: 22, loss: 1.202107
global_step: 4872, epoch: 22, loss: 1.203792
global_step: 4873, epoch: 22, loss: 1.140870
global_step: 4874, epoch: 22, loss: 1.207780
global_step: 4875, epoch: 22, loss: 1.209198
global_step: 4876, epoch: 22, loss: 1.209392
global_step: 4877, epoch: 22, loss: 1.111826
global_step: 4878, epoch: 22, loss: 1.162996
global_step: 4879, epoch: 22, loss: 1.338261
global_step: 4880, epoch: 22, loss: 1.266314
epoch: 22
train	acc: 0.6140	macro: p 0.4283, r 0.3216, f1: 0.3269	micro: p 0.6140, r 0.6140, f1 0.6140	weighted_f1:0.5627
dev	acc: 0.5410	macro: p 0.3701, r 0.2866, f1: 0.2789	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4764
test	acc: 0.5950	macro: p 0.3951, r 0.2985, f1: 0.2994	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5405
New best model!
global_step: 4881, epoch: 23, loss: 1.270539
global_step: 4882, epoch: 23, loss: 1.332256
global_step: 4883, epoch: 23, loss: 1.099269
global_step: 4884, epoch: 23, loss: 1.226781
global_step: 4885, epoch: 23, loss: 1.113994
global_step: 4886, epoch: 23, loss: 1.055660
global_step: 4887, epoch: 23, loss: 1.141710
global_step: 4888, epoch: 23, loss: 1.283093
global_step: 4889, epoch: 23, loss: 1.263729
global_step: 4890, epoch: 23, loss: 1.273153
global_step: 4891, epoch: 23, loss: 1.254648
global_step: 4892, epoch: 23, loss: 1.243603
global_step: 4893, epoch: 23, loss: 1.128543
global_step: 4894, epoch: 23, loss: 1.244444
global_step: 4895, epoch: 23, loss: 1.286316
global_step: 4896, epoch: 23, loss: 1.203782
global_step: 4897, epoch: 23, loss: 1.190097
global_step: 4898, epoch: 23, loss: 1.243320
global_step: 4899, epoch: 23, loss: 1.205426
global_step: 4900, epoch: 23, loss: 1.213130
global_step: 4901, epoch: 23, loss: 1.216095
global_step: 4902, epoch: 23, loss: 1.234143
global_step: 4903, epoch: 23, loss: 1.220195
global_step: 4904, epoch: 23, loss: 1.154160
global_step: 4905, epoch: 23, loss: 1.288452
global_step: 4906, epoch: 23, loss: 1.201080
global_step: 4907, epoch: 23, loss: 1.218468
global_step: 4908, epoch: 23, loss: 1.231367
global_step: 4909, epoch: 23, loss: 1.244033
global_step: 4910, epoch: 23, loss: 1.173695
global_step: 4911, epoch: 23, loss: 1.161859
global_step: 4912, epoch: 23, loss: 1.099494
global_step: 4913, epoch: 23, loss: 1.262642
global_step: 4914, epoch: 23, loss: 1.256016
global_step: 4915, epoch: 23, loss: 1.182904
global_step: 4916, epoch: 23, loss: 1.195675
global_step: 4917, epoch: 23, loss: 1.200905
global_step: 4918, epoch: 23, loss: 1.219301
global_step: 4919, epoch: 23, loss: 1.247535
global_step: 4920, epoch: 23, loss: 0.993324
epoch: 23
train	acc: 0.6183	macro: p 0.4255, r 0.3225, f1: 0.3298	micro: p 0.6183, r 0.6183, f1 0.6183	weighted_f1:0.5660
dev	acc: 0.5419	macro: p 0.3577, r 0.2865, f1: 0.2770	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4750
test	acc: 0.5920	macro: p 0.3917, r 0.2935, f1: 0.2919	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5335
global_step: 4921, epoch: 24, loss: 1.187316
global_step: 4922, epoch: 24, loss: 1.200688
global_step: 4923, epoch: 24, loss: 1.235950
global_step: 4924, epoch: 24, loss: 1.304556
global_step: 4925, epoch: 24, loss: 1.228657
global_step: 4926, epoch: 24, loss: 1.190746
global_step: 4927, epoch: 24, loss: 1.110036
global_step: 4928, epoch: 24, loss: 1.191119
global_step: 4929, epoch: 24, loss: 1.175434
global_step: 4930, epoch: 24, loss: 1.104136
global_step: 4931, epoch: 24, loss: 1.098661
global_step: 4932, epoch: 24, loss: 1.263346
global_step: 4933, epoch: 24, loss: 1.324319
global_step: 4934, epoch: 24, loss: 1.286839
global_step: 4935, epoch: 24, loss: 1.219294
global_step: 4936, epoch: 24, loss: 1.172934
global_step: 4937, epoch: 24, loss: 1.132959
global_step: 4938, epoch: 24, loss: 1.236493
global_step: 4939, epoch: 24, loss: 1.198928
global_step: 4940, epoch: 24, loss: 1.179719
global_step: 4941, epoch: 24, loss: 1.302055
global_step: 4942, epoch: 24, loss: 1.273665
global_step: 4943, epoch: 24, loss: 1.269603
global_step: 4944, epoch: 24, loss: 1.274818
global_step: 4945, epoch: 24, loss: 1.167670
global_step: 4946, epoch: 24, loss: 1.271341
global_step: 4947, epoch: 24, loss: 1.224586
global_step: 4948, epoch: 24, loss: 1.083820
global_step: 4949, epoch: 24, loss: 1.229316
global_step: 4950, epoch: 24, loss: 1.259206
global_step: 4951, epoch: 24, loss: 1.186502
global_step: 4952, epoch: 24, loss: 1.139991
global_step: 4953, epoch: 24, loss: 1.210514
global_step: 4954, epoch: 24, loss: 1.203820
global_step: 4955, epoch: 24, loss: 1.146577
global_step: 4956, epoch: 24, loss: 1.263222
global_step: 4957, epoch: 24, loss: 1.118074
global_step: 4958, epoch: 24, loss: 1.231175
global_step: 4959, epoch: 24, loss: 1.230780
global_step: 4960, epoch: 24, loss: 2.093981
epoch: 24
train	acc: 0.6248	macro: p 0.4236, r 0.3365, f1: 0.3440	micro: p 0.6248, r 0.6248, f1 0.6248	weighted_f1:0.5782
dev	acc: 0.5419	macro: p 0.3387, r 0.2889, f1: 0.2809	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4791
test	acc: 0.5897	macro: p 0.3740, r 0.2998, f1: 0.3011	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5393
New best model!
global_step: 4961, epoch: 25, loss: 1.138311
global_step: 4962, epoch: 25, loss: 1.160533
global_step: 4963, epoch: 25, loss: 1.213621
global_step: 4964, epoch: 25, loss: 1.273528
global_step: 4965, epoch: 25, loss: 1.161503
global_step: 4966, epoch: 25, loss: 1.173319
global_step: 4967, epoch: 25, loss: 1.143562
global_step: 4968, epoch: 25, loss: 1.273098
global_step: 4969, epoch: 25, loss: 1.224432
global_step: 4970, epoch: 25, loss: 1.166704
global_step: 4971, epoch: 25, loss: 1.164695
global_step: 4972, epoch: 25, loss: 1.212337
global_step: 4973, epoch: 25, loss: 1.267478
global_step: 4974, epoch: 25, loss: 1.267574
global_step: 4975, epoch: 25, loss: 1.257825
global_step: 4976, epoch: 25, loss: 1.190519
global_step: 4977, epoch: 25, loss: 1.228640
global_step: 4978, epoch: 25, loss: 1.072381
global_step: 4979, epoch: 25, loss: 1.245162
global_step: 4980, epoch: 25, loss: 1.219900
global_step: 4981, epoch: 25, loss: 1.168250
global_step: 4982, epoch: 25, loss: 1.193673
global_step: 4983, epoch: 25, loss: 1.256677
global_step: 4984, epoch: 25, loss: 1.181914
global_step: 4985, epoch: 25, loss: 1.165430
global_step: 4986, epoch: 25, loss: 1.135947
global_step: 4987, epoch: 25, loss: 1.264892
global_step: 4988, epoch: 25, loss: 1.178579
global_step: 4989, epoch: 25, loss: 1.151189
global_step: 4990, epoch: 25, loss: 1.217317
global_step: 4991, epoch: 25, loss: 1.237887
global_step: 4992, epoch: 25, loss: 1.248399
global_step: 4993, epoch: 25, loss: 1.214755
global_step: 4994, epoch: 25, loss: 1.115725
global_step: 4995, epoch: 25, loss: 1.245620
global_step: 4996, epoch: 25, loss: 1.050889
global_step: 4997, epoch: 25, loss: 1.175175
global_step: 4998, epoch: 25, loss: 1.302609
global_step: 4999, epoch: 25, loss: 1.128860
global_step: 5000, epoch: 25, loss: 0.465139
epoch: 25
train	acc: 0.6197	macro: p 0.4358, r 0.3251, f1: 0.3331	micro: p 0.6197, r 0.6197, f1 0.6197	weighted_f1:0.5677
dev	acc: 0.5428	macro: p 0.3701, r 0.2872, f1: 0.2795	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4768
test	acc: 0.5946	macro: p 0.3949, r 0.2955, f1: 0.2968	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5380
global_step: 5001, epoch: 26, loss: 1.167478
global_step: 5002, epoch: 26, loss: 1.187766
global_step: 5003, epoch: 26, loss: 1.165375
global_step: 5004, epoch: 26, loss: 1.167446
global_step: 5005, epoch: 26, loss: 1.145808
global_step: 5006, epoch: 26, loss: 1.180694
global_step: 5007, epoch: 26, loss: 1.217728
global_step: 5008, epoch: 26, loss: 1.225700
global_step: 5009, epoch: 26, loss: 1.172968
global_step: 5010, epoch: 26, loss: 1.339917
global_step: 5011, epoch: 26, loss: 1.225064
global_step: 5012, epoch: 26, loss: 1.084577
global_step: 5013, epoch: 26, loss: 1.229339
global_step: 5014, epoch: 26, loss: 1.304465
global_step: 5015, epoch: 26, loss: 1.241485
global_step: 5016, epoch: 26, loss: 1.105447
global_step: 5017, epoch: 26, loss: 1.113586
global_step: 5018, epoch: 26, loss: 1.294960
global_step: 5019, epoch: 26, loss: 1.180075
global_step: 5020, epoch: 26, loss: 1.143096
global_step: 5021, epoch: 26, loss: 1.170330
global_step: 5022, epoch: 26, loss: 1.206091
global_step: 5023, epoch: 26, loss: 1.226174
global_step: 5024, epoch: 26, loss: 1.232932
global_step: 5025, epoch: 26, loss: 1.178018
global_step: 5026, epoch: 26, loss: 1.130361
global_step: 5027, epoch: 26, loss: 1.142372
global_step: 5028, epoch: 26, loss: 1.228576
global_step: 5029, epoch: 26, loss: 1.146017
global_step: 5030, epoch: 26, loss: 1.199915
global_step: 5031, epoch: 26, loss: 1.143788
global_step: 5032, epoch: 26, loss: 1.184733
global_step: 5033, epoch: 26, loss: 1.181124
global_step: 5034, epoch: 26, loss: 1.179904
global_step: 5035, epoch: 26, loss: 1.237700
global_step: 5036, epoch: 26, loss: 1.118553
global_step: 5037, epoch: 26, loss: 1.298728
global_step: 5038, epoch: 26, loss: 1.196488
global_step: 5039, epoch: 26, loss: 1.095590
global_step: 5040, epoch: 26, loss: 1.764687
epoch: 26
train	acc: 0.6347	macro: p 0.4301, r 0.3419, f1: 0.3507	micro: p 0.6347, r 0.6347, f1 0.6347	weighted_f1:0.5869
dev	acc: 0.5401	macro: p 0.3306, r 0.2876, f1: 0.2756	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4746
test	acc: 0.5816	macro: p 0.3547, r 0.2919, f1: 0.2880	micro: p 0.5816, r 0.5816, f1 0.5816	weighted_f1:0.5269
global_step: 5041, epoch: 27, loss: 1.294816
global_step: 5042, epoch: 27, loss: 1.163409
global_step: 5043, epoch: 27, loss: 1.078869
global_step: 5044, epoch: 27, loss: 1.250478
global_step: 5045, epoch: 27, loss: 1.142713
global_step: 5046, epoch: 27, loss: 1.110411
global_step: 5047, epoch: 27, loss: 1.170632
global_step: 5048, epoch: 27, loss: 1.245691
global_step: 5049, epoch: 27, loss: 1.178365
global_step: 5050, epoch: 27, loss: 1.308009
global_step: 5051, epoch: 27, loss: 1.198410
global_step: 5052, epoch: 27, loss: 1.233558
global_step: 5053, epoch: 27, loss: 1.299803
global_step: 5054, epoch: 27, loss: 1.199400
global_step: 5055, epoch: 27, loss: 1.082494
global_step: 5056, epoch: 27, loss: 1.090590
global_step: 5057, epoch: 27, loss: 1.178632
global_step: 5058, epoch: 27, loss: 1.209138
global_step: 5059, epoch: 27, loss: 1.114558
global_step: 5060, epoch: 27, loss: 1.055301
global_step: 5061, epoch: 27, loss: 1.156684
global_step: 5062, epoch: 27, loss: 1.177699
global_step: 5063, epoch: 27, loss: 1.111397
global_step: 5064, epoch: 27, loss: 1.222366
global_step: 5065, epoch: 27, loss: 1.214668
global_step: 5066, epoch: 27, loss: 1.162181
global_step: 5067, epoch: 27, loss: 1.063052
global_step: 5068, epoch: 27, loss: 1.206500
global_step: 5069, epoch: 27, loss: 1.142116
global_step: 5070, epoch: 27, loss: 1.203224
global_step: 5071, epoch: 27, loss: 1.208611
global_step: 5072, epoch: 27, loss: 1.172331
global_step: 5073, epoch: 27, loss: 1.192555
global_step: 5074, epoch: 27, loss: 1.285725
global_step: 5075, epoch: 27, loss: 1.149071
global_step: 5076, epoch: 27, loss: 1.165866
global_step: 5077, epoch: 27, loss: 1.318158
global_step: 5078, epoch: 27, loss: 1.247627
global_step: 5079, epoch: 27, loss: 1.118045
global_step: 5080, epoch: 27, loss: 0.720349
epoch: 27
train	acc: 0.6301	macro: p 0.4348, r 0.3376, f1: 0.3466	micro: p 0.6301, r 0.6301, f1 0.6301	weighted_f1:0.5819
dev	acc: 0.5482	macro: p 0.3546, r 0.2942, f1: 0.2855	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4841
test	acc: 0.5950	macro: p 0.3847, r 0.3004, f1: 0.3017	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5414
New best model!
global_step: 5081, epoch: 28, loss: 1.235798
global_step: 5082, epoch: 28, loss: 1.180913
global_step: 5083, epoch: 28, loss: 1.175758
global_step: 5084, epoch: 28, loss: 1.237535
global_step: 5085, epoch: 28, loss: 1.164249
global_step: 5086, epoch: 28, loss: 1.138550
global_step: 5087, epoch: 28, loss: 1.211886
global_step: 5088, epoch: 28, loss: 1.186962
global_step: 5089, epoch: 28, loss: 1.142141
global_step: 5090, epoch: 28, loss: 1.104530
global_step: 5091, epoch: 28, loss: 1.222712
global_step: 5092, epoch: 28, loss: 1.172435
global_step: 5093, epoch: 28, loss: 1.240938
global_step: 5094, epoch: 28, loss: 1.207755
global_step: 5095, epoch: 28, loss: 1.201356
global_step: 5096, epoch: 28, loss: 1.197312
global_step: 5097, epoch: 28, loss: 1.100647
global_step: 5098, epoch: 28, loss: 1.195735
global_step: 5099, epoch: 28, loss: 1.124458
global_step: 5100, epoch: 28, loss: 1.100243
global_step: 5101, epoch: 28, loss: 1.170227
global_step: 5102, epoch: 28, loss: 1.343224
global_step: 5103, epoch: 28, loss: 1.136575
global_step: 5104, epoch: 28, loss: 1.185166
global_step: 5105, epoch: 28, loss: 1.160061
global_step: 5106, epoch: 28, loss: 1.186669
global_step: 5107, epoch: 28, loss: 1.149074
global_step: 5108, epoch: 28, loss: 1.178403
global_step: 5109, epoch: 28, loss: 1.238295
global_step: 5110, epoch: 28, loss: 1.195450
global_step: 5111, epoch: 28, loss: 1.170234
global_step: 5112, epoch: 28, loss: 1.227766
global_step: 5113, epoch: 28, loss: 1.156546
global_step: 5114, epoch: 28, loss: 1.102643
global_step: 5115, epoch: 28, loss: 1.190078
global_step: 5116, epoch: 28, loss: 1.133876
global_step: 5117, epoch: 28, loss: 1.072102
global_step: 5118, epoch: 28, loss: 1.142450
global_step: 5119, epoch: 28, loss: 1.200229
global_step: 5120, epoch: 28, loss: 1.119154
epoch: 28
train	acc: 0.6367	macro: p 0.4321, r 0.3439, f1: 0.3521	micro: p 0.6367, r 0.6367, f1 0.6367	weighted_f1:0.5882
dev	acc: 0.5419	macro: p 0.3326, r 0.2883, f1: 0.2735	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4742
test	acc: 0.5847	macro: p 0.3683, r 0.2953, f1: 0.2897	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5285
global_step: 5121, epoch: 29, loss: 1.155312
global_step: 5122, epoch: 29, loss: 1.113209
global_step: 5123, epoch: 29, loss: 1.140343
global_step: 5124, epoch: 29, loss: 1.071025
global_step: 5125, epoch: 29, loss: 1.172433
global_step: 5126, epoch: 29, loss: 1.147364
global_step: 5127, epoch: 29, loss: 1.170540
global_step: 5128, epoch: 29, loss: 1.218579
global_step: 5129, epoch: 29, loss: 1.217097
global_step: 5130, epoch: 29, loss: 1.192904
global_step: 5131, epoch: 29, loss: 1.146536
global_step: 5132, epoch: 29, loss: 1.132737
global_step: 5133, epoch: 29, loss: 1.207903
global_step: 5134, epoch: 29, loss: 1.238752
global_step: 5135, epoch: 29, loss: 1.172130
global_step: 5136, epoch: 29, loss: 1.163383
global_step: 5137, epoch: 29, loss: 1.202849
global_step: 5138, epoch: 29, loss: 1.097894
global_step: 5139, epoch: 29, loss: 1.163714
global_step: 5140, epoch: 29, loss: 1.058440
global_step: 5141, epoch: 29, loss: 1.092469
global_step: 5142, epoch: 29, loss: 1.279377
global_step: 5143, epoch: 29, loss: 1.221926
global_step: 5144, epoch: 29, loss: 1.250202
global_step: 5145, epoch: 29, loss: 1.120084
global_step: 5146, epoch: 29, loss: 1.267307
global_step: 5147, epoch: 29, loss: 1.213612
global_step: 5148, epoch: 29, loss: 1.223902
global_step: 5149, epoch: 29, loss: 1.217801
global_step: 5150, epoch: 29, loss: 1.118063
global_step: 5151, epoch: 29, loss: 1.140169
global_step: 5152, epoch: 29, loss: 1.133216
global_step: 5153, epoch: 29, loss: 1.163929
global_step: 5154, epoch: 29, loss: 1.170686
global_step: 5155, epoch: 29, loss: 1.194452
global_step: 5156, epoch: 29, loss: 1.154696
global_step: 5157, epoch: 29, loss: 1.131184
global_step: 5158, epoch: 29, loss: 1.154619
global_step: 5159, epoch: 29, loss: 1.131897
global_step: 5160, epoch: 29, loss: 1.551342
epoch: 29
train	acc: 0.6473	macro: p 0.4286, r 0.3604, f1: 0.3688	micro: p 0.6473, r 0.6473, f1 0.6473	weighted_f1:0.6043
dev	acc: 0.5401	macro: p 0.3269, r 0.2925, f1: 0.2797	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4791
test	acc: 0.5801	macro: p 0.3541, r 0.2962, f1: 0.2928	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5296
global_step: 5161, epoch: 30, loss: 1.201806
global_step: 5162, epoch: 30, loss: 1.227732
global_step: 5163, epoch: 30, loss: 1.217151
global_step: 5164, epoch: 30, loss: 1.187099
global_step: 5165, epoch: 30, loss: 1.208949
global_step: 5166, epoch: 30, loss: 1.190259
global_step: 5167, epoch: 30, loss: 1.160907
global_step: 5168, epoch: 30, loss: 1.185019
global_step: 5169, epoch: 30, loss: 1.085835
global_step: 5170, epoch: 30, loss: 1.159799
global_step: 5171, epoch: 30, loss: 1.185242
global_step: 5172, epoch: 30, loss: 1.147002
global_step: 5173, epoch: 30, loss: 1.186318
global_step: 5174, epoch: 30, loss: 1.284334
global_step: 5175, epoch: 30, loss: 1.169913
global_step: 5176, epoch: 30, loss: 1.106174
global_step: 5177, epoch: 30, loss: 1.206751
global_step: 5178, epoch: 30, loss: 1.269025
global_step: 5179, epoch: 30, loss: 1.103836
global_step: 5180, epoch: 30, loss: 1.089098
global_step: 5181, epoch: 30, loss: 1.235915
global_step: 5182, epoch: 30, loss: 0.985548
global_step: 5183, epoch: 30, loss: 1.161626
global_step: 5184, epoch: 30, loss: 1.162635
global_step: 5185, epoch: 30, loss: 1.079686
global_step: 5186, epoch: 30, loss: 1.132997
global_step: 5187, epoch: 30, loss: 1.167132
global_step: 5188, epoch: 30, loss: 1.208522
global_step: 5189, epoch: 30, loss: 1.006636
global_step: 5190, epoch: 30, loss: 1.241440
global_step: 5191, epoch: 30, loss: 1.237615
global_step: 5192, epoch: 30, loss: 1.186832
global_step: 5193, epoch: 30, loss: 1.056399
global_step: 5194, epoch: 30, loss: 1.073927
global_step: 5195, epoch: 30, loss: 1.196297
global_step: 5196, epoch: 30, loss: 1.134061
global_step: 5197, epoch: 30, loss: 1.144517
global_step: 5198, epoch: 30, loss: 1.112927
global_step: 5199, epoch: 30, loss: 1.160028
global_step: 5200, epoch: 30, loss: 0.705554
epoch: 30
train	acc: 0.6358	macro: p 0.4426, r 0.3412, f1: 0.3523	micro: p 0.6358, r 0.6358, f1 0.6358	weighted_f1:0.5868
dev	acc: 0.5473	macro: p 0.3447, r 0.2909, f1: 0.2828	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4816
test	acc: 0.5966	macro: p 0.3854, r 0.2997, f1: 0.3027	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5420
global_step: 5201, epoch: 31, loss: 1.132122
global_step: 5202, epoch: 31, loss: 1.056221
global_step: 5203, epoch: 31, loss: 1.234201
global_step: 5204, epoch: 31, loss: 1.270487
global_step: 5205, epoch: 31, loss: 1.070478
global_step: 5206, epoch: 31, loss: 1.137104
global_step: 5207, epoch: 31, loss: 1.145719
global_step: 5208, epoch: 31, loss: 1.147322
global_step: 5209, epoch: 31, loss: 1.128395
global_step: 5210, epoch: 31, loss: 1.251290
global_step: 5211, epoch: 31, loss: 1.197821
global_step: 5212, epoch: 31, loss: 1.160160
global_step: 5213, epoch: 31, loss: 1.142896
global_step: 5214, epoch: 31, loss: 1.056069
global_step: 5215, epoch: 31, loss: 1.082136
global_step: 5216, epoch: 31, loss: 1.145859
global_step: 5217, epoch: 31, loss: 1.065392
global_step: 5218, epoch: 31, loss: 1.141956
global_step: 5219, epoch: 31, loss: 1.196262
global_step: 5220, epoch: 31, loss: 1.142002
global_step: 5221, epoch: 31, loss: 1.119983
global_step: 5222, epoch: 31, loss: 1.160346
global_step: 5223, epoch: 31, loss: 1.310207
global_step: 5224, epoch: 31, loss: 1.136740
global_step: 5225, epoch: 31, loss: 1.238586
global_step: 5226, epoch: 31, loss: 1.112268
global_step: 5227, epoch: 31, loss: 1.015440
global_step: 5228, epoch: 31, loss: 1.261386
global_step: 5229, epoch: 31, loss: 1.029838
global_step: 5230, epoch: 31, loss: 1.001850
global_step: 5231, epoch: 31, loss: 1.283765
global_step: 5232, epoch: 31, loss: 1.079977
global_step: 5233, epoch: 31, loss: 1.144465
global_step: 5234, epoch: 31, loss: 1.223313
global_step: 5235, epoch: 31, loss: 1.340525
global_step: 5236, epoch: 31, loss: 1.112758
global_step: 5237, epoch: 31, loss: 1.057411
global_step: 5238, epoch: 31, loss: 1.055119
global_step: 5239, epoch: 31, loss: 1.315408
global_step: 5240, epoch: 31, loss: 0.910207
epoch: 31
train	acc: 0.6445	macro: p 0.4325, r 0.3544, f1: 0.3652	micro: p 0.6445, r 0.6445, f1 0.6445	weighted_f1:0.5994
dev	acc: 0.5428	macro: p 0.3373, r 0.2912, f1: 0.2810	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4793
test	acc: 0.5904	macro: p 0.3678, r 0.3007, f1: 0.3007	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5378
global_step: 5241, epoch: 32, loss: 1.128900
global_step: 5242, epoch: 32, loss: 1.171739
global_step: 5243, epoch: 32, loss: 1.143782
global_step: 5244, epoch: 32, loss: 0.975662
global_step: 5245, epoch: 32, loss: 1.119528
global_step: 5246, epoch: 32, loss: 1.226290
global_step: 5247, epoch: 32, loss: 1.074487
global_step: 5248, epoch: 32, loss: 1.056094
global_step: 5249, epoch: 32, loss: 1.185258
global_step: 5250, epoch: 32, loss: 1.176742
global_step: 5251, epoch: 32, loss: 1.303698
global_step: 5252, epoch: 32, loss: 1.101738
global_step: 5253, epoch: 32, loss: 1.068284
global_step: 5254, epoch: 32, loss: 1.237185
global_step: 5255, epoch: 32, loss: 1.250540
global_step: 5256, epoch: 32, loss: 1.171002
global_step: 5257, epoch: 32, loss: 1.143432
global_step: 5258, epoch: 32, loss: 1.100141
global_step: 5259, epoch: 32, loss: 1.164085
global_step: 5260, epoch: 32, loss: 1.248371
global_step: 5261, epoch: 32, loss: 1.143229
global_step: 5262, epoch: 32, loss: 1.084324
global_step: 5263, epoch: 32, loss: 1.168235
global_step: 5264, epoch: 32, loss: 1.185168
global_step: 5265, epoch: 32, loss: 1.146899
global_step: 5266, epoch: 32, loss: 1.186551
global_step: 5267, epoch: 32, loss: 1.291687
global_step: 5268, epoch: 32, loss: 1.072295
global_step: 5269, epoch: 32, loss: 1.077411
global_step: 5270, epoch: 32, loss: 1.136318
global_step: 5271, epoch: 32, loss: 1.135935
global_step: 5272, epoch: 32, loss: 1.150396
global_step: 5273, epoch: 32, loss: 1.108574
global_step: 5274, epoch: 32, loss: 1.128102
global_step: 5275, epoch: 32, loss: 1.142688
global_step: 5276, epoch: 32, loss: 1.084065
global_step: 5277, epoch: 32, loss: 1.166586
global_step: 5278, epoch: 32, loss: 1.145187
global_step: 5279, epoch: 32, loss: 1.151393
global_step: 5280, epoch: 32, loss: 1.802668
epoch: 32
train	acc: 0.6559	macro: p 0.4352, r 0.3733, f1: 0.3843	micro: p 0.6559, r 0.6559, f1 0.6559	weighted_f1:0.6156
dev	acc: 0.5509	macro: p 0.3371, r 0.3027, f1: 0.2950	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4930
test	acc: 0.5912	macro: p 0.3617, r 0.3071, f1: 0.3090	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5438
New best model!
global_step: 5281, epoch: 33, loss: 1.224614
global_step: 5282, epoch: 33, loss: 1.142258
global_step: 5283, epoch: 33, loss: 1.163009
global_step: 5284, epoch: 33, loss: 1.039521
global_step: 5285, epoch: 33, loss: 1.139995
global_step: 5286, epoch: 33, loss: 1.170975
global_step: 5287, epoch: 33, loss: 1.132680
global_step: 5288, epoch: 33, loss: 1.302936
global_step: 5289, epoch: 33, loss: 1.102591
global_step: 5290, epoch: 33, loss: 1.116835
global_step: 5291, epoch: 33, loss: 1.215737
global_step: 5292, epoch: 33, loss: 1.152478
global_step: 5293, epoch: 33, loss: 1.189912
global_step: 5294, epoch: 33, loss: 1.118011
global_step: 5295, epoch: 33, loss: 1.055089
global_step: 5296, epoch: 33, loss: 1.089813
global_step: 5297, epoch: 33, loss: 1.205228
global_step: 5298, epoch: 33, loss: 1.084098
global_step: 5299, epoch: 33, loss: 1.145917
global_step: 5300, epoch: 33, loss: 1.146945
global_step: 5301, epoch: 33, loss: 1.187857
global_step: 5302, epoch: 33, loss: 1.138566
global_step: 5303, epoch: 33, loss: 1.143066
global_step: 5304, epoch: 33, loss: 1.117730
global_step: 5305, epoch: 33, loss: 1.126300
global_step: 5306, epoch: 33, loss: 1.066341
global_step: 5307, epoch: 33, loss: 1.294654
global_step: 5308, epoch: 33, loss: 1.136564
global_step: 5309, epoch: 33, loss: 1.165436
global_step: 5310, epoch: 33, loss: 1.158770
global_step: 5311, epoch: 33, loss: 1.095549
global_step: 5312, epoch: 33, loss: 1.087626
global_step: 5313, epoch: 33, loss: 1.151918
global_step: 5314, epoch: 33, loss: 1.089266
global_step: 5315, epoch: 33, loss: 1.111976
global_step: 5316, epoch: 33, loss: 1.023784
global_step: 5317, epoch: 33, loss: 1.168721
global_step: 5318, epoch: 33, loss: 1.109409
global_step: 5319, epoch: 33, loss: 1.116057
global_step: 5320, epoch: 33, loss: 0.301241
epoch: 33
train	acc: 0.6483	macro: p 0.4396, r 0.3564, f1: 0.3679	micro: p 0.6483, r 0.6483, f1 0.6483	weighted_f1:0.6022
dev	acc: 0.5419	macro: p 0.3418, r 0.2880, f1: 0.2789	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4770
test	acc: 0.5935	macro: p 0.3733, r 0.3009, f1: 0.3014	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5397
global_step: 5321, epoch: 34, loss: 1.171351
global_step: 5322, epoch: 34, loss: 1.111019
global_step: 5323, epoch: 34, loss: 1.006058
global_step: 5324, epoch: 34, loss: 1.192671
global_step: 5325, epoch: 34, loss: 1.188594
global_step: 5326, epoch: 34, loss: 1.138686
global_step: 5327, epoch: 34, loss: 1.131236
global_step: 5328, epoch: 34, loss: 1.185877
global_step: 5329, epoch: 34, loss: 1.165875
global_step: 5330, epoch: 34, loss: 1.212102
global_step: 5331, epoch: 34, loss: 0.905850
global_step: 5332, epoch: 34, loss: 1.136200
global_step: 5333, epoch: 34, loss: 1.155504
global_step: 5334, epoch: 34, loss: 1.134793
global_step: 5335, epoch: 34, loss: 1.084511
global_step: 5336, epoch: 34, loss: 1.115292
global_step: 5337, epoch: 34, loss: 1.225635
global_step: 5338, epoch: 34, loss: 1.070284
global_step: 5339, epoch: 34, loss: 1.018652
global_step: 5340, epoch: 34, loss: 1.202243
global_step: 5341, epoch: 34, loss: 1.100177
global_step: 5342, epoch: 34, loss: 1.012462
global_step: 5343, epoch: 34, loss: 1.246346
global_step: 5344, epoch: 34, loss: 1.188848
global_step: 5345, epoch: 34, loss: 1.075045
global_step: 5346, epoch: 34, loss: 1.184194
global_step: 5347, epoch: 34, loss: 1.223274
global_step: 5348, epoch: 34, loss: 1.132977
global_step: 5349, epoch: 34, loss: 1.143551
global_step: 5350, epoch: 34, loss: 1.079066
global_step: 5351, epoch: 34, loss: 1.043504
global_step: 5352, epoch: 34, loss: 1.056922
global_step: 5353, epoch: 34, loss: 1.306492
global_step: 5354, epoch: 34, loss: 1.155881
global_step: 5355, epoch: 34, loss: 1.144871
global_step: 5356, epoch: 34, loss: 1.124303
global_step: 5357, epoch: 34, loss: 1.137861
global_step: 5358, epoch: 34, loss: 1.172319
global_step: 5359, epoch: 34, loss: 1.081935
global_step: 5360, epoch: 34, loss: 1.478757
epoch: 34
train	acc: 0.6606	macro: p 0.4452, r 0.3752, f1: 0.3853	micro: p 0.6606, r 0.6606, f1 0.6606	weighted_f1:0.6198
dev	acc: 0.5528	macro: p 0.3481, r 0.3053, f1: 0.2969	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4954
test	acc: 0.5893	macro: p 0.3596, r 0.3039, f1: 0.3050	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5415
New best model!
global_step: 5361, epoch: 35, loss: 1.133677
global_step: 5362, epoch: 35, loss: 1.090728
global_step: 5363, epoch: 35, loss: 1.201112
global_step: 5364, epoch: 35, loss: 0.969193
global_step: 5365, epoch: 35, loss: 1.046973
global_step: 5366, epoch: 35, loss: 1.123149
global_step: 5367, epoch: 35, loss: 1.090854
global_step: 5368, epoch: 35, loss: 1.075425
global_step: 5369, epoch: 35, loss: 1.125928
global_step: 5370, epoch: 35, loss: 1.113002
global_step: 5371, epoch: 35, loss: 1.084440
global_step: 5372, epoch: 35, loss: 1.140299
global_step: 5373, epoch: 35, loss: 1.120851
global_step: 5374, epoch: 35, loss: 1.113866
global_step: 5375, epoch: 35, loss: 1.182817
global_step: 5376, epoch: 35, loss: 1.202559
global_step: 5377, epoch: 35, loss: 1.079463
global_step: 5378, epoch: 35, loss: 1.103673
global_step: 5379, epoch: 35, loss: 1.128804
global_step: 5380, epoch: 35, loss: 1.144871
global_step: 5381, epoch: 35, loss: 1.128269
global_step: 5382, epoch: 35, loss: 1.109973
global_step: 5383, epoch: 35, loss: 1.150556
global_step: 5384, epoch: 35, loss: 1.079435
global_step: 5385, epoch: 35, loss: 1.149520
global_step: 5386, epoch: 35, loss: 1.195207
global_step: 5387, epoch: 35, loss: 1.074435
global_step: 5388, epoch: 35, loss: 1.154614
global_step: 5389, epoch: 35, loss: 1.198242
global_step: 5390, epoch: 35, loss: 1.143312
global_step: 5391, epoch: 35, loss: 1.171065
global_step: 5392, epoch: 35, loss: 1.082100
global_step: 5393, epoch: 35, loss: 1.124245
global_step: 5394, epoch: 35, loss: 1.131015
global_step: 5395, epoch: 35, loss: 1.160453
global_step: 5396, epoch: 35, loss: 1.036436
global_step: 5397, epoch: 35, loss: 1.165450
global_step: 5398, epoch: 35, loss: 1.102146
global_step: 5399, epoch: 35, loss: 1.028004
global_step: 5400, epoch: 35, loss: 0.493790
epoch: 35
train	acc: 0.6526	macro: p 0.4492, r 0.3576, f1: 0.3692	micro: p 0.6526, r 0.6526, f1 0.6526	weighted_f1:0.6050
dev	acc: 0.5455	macro: p 0.3486, r 0.2910, f1: 0.2814	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4791
test	acc: 0.5927	macro: p 0.3728, r 0.2985, f1: 0.2980	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5367
global_step: 5401, epoch: 36, loss: 1.158999
global_step: 5402, epoch: 36, loss: 1.120691
global_step: 5403, epoch: 36, loss: 0.996571
global_step: 5404, epoch: 36, loss: 1.142635
global_step: 5405, epoch: 36, loss: 1.108729
global_step: 5406, epoch: 36, loss: 1.174186
global_step: 5407, epoch: 36, loss: 1.113328
global_step: 5408, epoch: 36, loss: 1.091234
global_step: 5409, epoch: 36, loss: 1.068823
global_step: 5410, epoch: 36, loss: 1.000322
global_step: 5411, epoch: 36, loss: 1.258481
global_step: 5412, epoch: 36, loss: 1.197547
global_step: 5413, epoch: 36, loss: 1.039157
global_step: 5414, epoch: 36, loss: 1.169297
global_step: 5415, epoch: 36, loss: 1.065380
global_step: 5416, epoch: 36, loss: 1.067801
global_step: 5417, epoch: 36, loss: 1.083277
global_step: 5418, epoch: 36, loss: 0.911398
global_step: 5419, epoch: 36, loss: 1.050118
global_step: 5420, epoch: 36, loss: 1.024266
global_step: 5421, epoch: 36, loss: 1.022025
global_step: 5422, epoch: 36, loss: 1.171343
global_step: 5423, epoch: 36, loss: 1.087090
global_step: 5424, epoch: 36, loss: 1.216974
global_step: 5425, epoch: 36, loss: 1.151611
global_step: 5426, epoch: 36, loss: 1.263106
global_step: 5427, epoch: 36, loss: 1.148161
global_step: 5428, epoch: 36, loss: 1.149185
global_step: 5429, epoch: 36, loss: 1.092183
global_step: 5430, epoch: 36, loss: 1.102545
global_step: 5431, epoch: 36, loss: 1.053203
global_step: 5432, epoch: 36, loss: 1.068953
global_step: 5433, epoch: 36, loss: 1.118856
global_step: 5434, epoch: 36, loss: 1.102376
global_step: 5435, epoch: 36, loss: 1.222137
global_step: 5436, epoch: 36, loss: 1.080079
global_step: 5437, epoch: 36, loss: 1.068668
global_step: 5438, epoch: 36, loss: 1.111439
global_step: 5439, epoch: 36, loss: 1.156864
global_step: 5440, epoch: 36, loss: 0.514171
epoch: 36
train	acc: 0.6669	macro: p 0.4522, r 0.3818, f1: 0.3937	micro: p 0.6669, r 0.6669, f1 0.6669	weighted_f1:0.6267
dev	acc: 0.5455	macro: p 0.3366, r 0.2969, f1: 0.2866	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4858
test	acc: 0.5893	macro: p 0.3642, r 0.3038, f1: 0.3032	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5393
global_step: 5441, epoch: 37, loss: 1.257971
global_step: 5442, epoch: 37, loss: 1.089884
global_step: 5443, epoch: 37, loss: 1.041963
global_step: 5444, epoch: 37, loss: 1.021632
global_step: 5445, epoch: 37, loss: 1.097366
global_step: 5446, epoch: 37, loss: 1.021941
global_step: 5447, epoch: 37, loss: 1.068235
global_step: 5448, epoch: 37, loss: 1.163547
global_step: 5449, epoch: 37, loss: 1.134826
global_step: 5450, epoch: 37, loss: 1.077717
global_step: 5451, epoch: 37, loss: 1.171277
global_step: 5452, epoch: 37, loss: 1.116707
global_step: 5453, epoch: 37, loss: 1.043548
global_step: 5454, epoch: 37, loss: 1.125304
global_step: 5455, epoch: 37, loss: 1.127949
global_step: 5456, epoch: 37, loss: 1.095603
global_step: 5457, epoch: 37, loss: 1.058405
global_step: 5458, epoch: 37, loss: 1.114667
global_step: 5459, epoch: 37, loss: 1.114442
global_step: 5460, epoch: 37, loss: 1.099649
global_step: 5461, epoch: 37, loss: 1.203942
global_step: 5462, epoch: 37, loss: 1.011575
global_step: 5463, epoch: 37, loss: 1.093062
global_step: 5464, epoch: 37, loss: 1.093228
global_step: 5465, epoch: 37, loss: 1.120005
global_step: 5466, epoch: 37, loss: 1.102226
global_step: 5467, epoch: 37, loss: 1.044608
global_step: 5468, epoch: 37, loss: 1.241347
global_step: 5469, epoch: 37, loss: 1.153152
global_step: 5470, epoch: 37, loss: 1.151232
global_step: 5471, epoch: 37, loss: 1.074794
global_step: 5472, epoch: 37, loss: 1.124189
global_step: 5473, epoch: 37, loss: 1.076823
global_step: 5474, epoch: 37, loss: 1.095874
global_step: 5475, epoch: 37, loss: 1.142226
global_step: 5476, epoch: 37, loss: 1.141732
global_step: 5477, epoch: 37, loss: 1.017000
global_step: 5478, epoch: 37, loss: 1.071967
global_step: 5479, epoch: 37, loss: 1.061669
global_step: 5480, epoch: 37, loss: 1.290590
epoch: 37
train	acc: 0.6799	macro: p 0.4512, r 0.4025, f1: 0.4122	micro: p 0.6799, r 0.6799, f1 0.6799	weighted_f1:0.6440
dev	acc: 0.5455	macro: p 0.3408, r 0.3044, f1: 0.2931	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4906
test	acc: 0.5847	macro: p 0.3546, r 0.3069, f1: 0.3060	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5387
global_step: 5481, epoch: 38, loss: 1.125655
global_step: 5482, epoch: 38, loss: 1.214900
global_step: 5483, epoch: 38, loss: 1.091402
global_step: 5484, epoch: 38, loss: 1.076664
global_step: 5485, epoch: 38, loss: 1.098347
global_step: 5486, epoch: 38, loss: 1.077669
global_step: 5487, epoch: 38, loss: 1.270786
global_step: 5488, epoch: 38, loss: 1.174060
global_step: 5489, epoch: 38, loss: 1.154742
global_step: 5490, epoch: 38, loss: 0.984254
global_step: 5491, epoch: 38, loss: 1.094638
global_step: 5492, epoch: 38, loss: 1.185975
global_step: 5493, epoch: 38, loss: 1.074266
global_step: 5494, epoch: 38, loss: 0.998871
global_step: 5495, epoch: 38, loss: 1.128922
global_step: 5496, epoch: 38, loss: 1.094246
global_step: 5497, epoch: 38, loss: 1.015157
global_step: 5498, epoch: 38, loss: 1.082108
global_step: 5499, epoch: 38, loss: 0.957343
global_step: 5500, epoch: 38, loss: 1.199740
global_step: 5501, epoch: 38, loss: 1.120105
global_step: 5502, epoch: 38, loss: 1.143646
global_step: 5503, epoch: 38, loss: 1.088603
global_step: 5504, epoch: 38, loss: 1.131118
global_step: 5505, epoch: 38, loss: 0.994376
global_step: 5506, epoch: 38, loss: 1.047412
global_step: 5507, epoch: 38, loss: 1.067290
global_step: 5508, epoch: 38, loss: 0.995222
global_step: 5509, epoch: 38, loss: 1.076798
global_step: 5510, epoch: 38, loss: 1.145518
global_step: 5511, epoch: 38, loss: 1.034534
global_step: 5512, epoch: 38, loss: 1.029874
global_step: 5513, epoch: 38, loss: 1.154172
global_step: 5514, epoch: 38, loss: 1.199917
global_step: 5515, epoch: 38, loss: 1.056383
global_step: 5516, epoch: 38, loss: 1.031989
global_step: 5517, epoch: 38, loss: 1.084920
global_step: 5518, epoch: 38, loss: 1.074687
global_step: 5519, epoch: 38, loss: 1.064160
global_step: 5520, epoch: 38, loss: 0.451493
epoch: 38
train	acc: 0.6675	macro: p 0.4584, r 0.3808, f1: 0.3941	micro: p 0.6675, r 0.6675, f1 0.6675	weighted_f1:0.6264
dev	acc: 0.5518	macro: p 0.3497, r 0.2997, f1: 0.2943	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4921
test	acc: 0.5943	macro: p 0.3677, r 0.3049, f1: 0.3084	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5445
global_step: 5521, epoch: 39, loss: 1.107671
global_step: 5522, epoch: 39, loss: 1.085643
global_step: 5523, epoch: 39, loss: 0.901200
global_step: 5524, epoch: 39, loss: 1.082595
global_step: 5525, epoch: 39, loss: 1.232246
global_step: 5526, epoch: 39, loss: 1.097088
global_step: 5527, epoch: 39, loss: 1.113662
global_step: 5528, epoch: 39, loss: 1.210102
global_step: 5529, epoch: 39, loss: 1.064869
global_step: 5530, epoch: 39, loss: 1.156507
global_step: 5531, epoch: 39, loss: 1.037859
global_step: 5532, epoch: 39, loss: 1.068385
global_step: 5533, epoch: 39, loss: 1.001549
global_step: 5534, epoch: 39, loss: 0.985456
global_step: 5535, epoch: 39, loss: 1.079653
global_step: 5536, epoch: 39, loss: 1.011939
global_step: 5537, epoch: 39, loss: 1.143486
global_step: 5538, epoch: 39, loss: 1.018923
global_step: 5539, epoch: 39, loss: 1.090641
global_step: 5540, epoch: 39, loss: 1.035047
global_step: 5541, epoch: 39, loss: 1.100888
global_step: 5542, epoch: 39, loss: 1.040186
global_step: 5543, epoch: 39, loss: 1.004329
global_step: 5544, epoch: 39, loss: 1.109161
global_step: 5545, epoch: 39, loss: 1.093400
global_step: 5546, epoch: 39, loss: 1.131732
global_step: 5547, epoch: 39, loss: 0.963015
global_step: 5548, epoch: 39, loss: 1.077505
global_step: 5549, epoch: 39, loss: 1.104581
global_step: 5550, epoch: 39, loss: 1.172596
global_step: 5551, epoch: 39, loss: 1.033665
global_step: 5552, epoch: 39, loss: 1.126368
global_step: 5553, epoch: 39, loss: 1.158584
global_step: 5554, epoch: 39, loss: 1.095655
global_step: 5555, epoch: 39, loss: 1.013642
global_step: 5556, epoch: 39, loss: 1.171124
global_step: 5557, epoch: 39, loss: 1.168838
global_step: 5558, epoch: 39, loss: 1.018376
global_step: 5559, epoch: 39, loss: 1.065293
global_step: 5560, epoch: 39, loss: 1.537286
epoch: 39
train	acc: 0.6881	macro: p 0.4573, r 0.4115, f1: 0.4220	micro: p 0.6881, r 0.6881, f1 0.6881	weighted_f1:0.6530
dev	acc: 0.5555	macro: p 0.3534, r 0.3114, f1: 0.3054	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5025
test	acc: 0.5885	macro: p 0.3550, r 0.3087, f1: 0.3104	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5435
New best model!
global_step: 5561, epoch: 40, loss: 1.105791
global_step: 5562, epoch: 40, loss: 1.087746
global_step: 5563, epoch: 40, loss: 1.118840
global_step: 5564, epoch: 40, loss: 1.050977
global_step: 5565, epoch: 40, loss: 1.046577
global_step: 5566, epoch: 40, loss: 1.026063
global_step: 5567, epoch: 40, loss: 1.103076
global_step: 5568, epoch: 40, loss: 1.162771
global_step: 5569, epoch: 40, loss: 1.119720
global_step: 5570, epoch: 40, loss: 1.186105
global_step: 5571, epoch: 40, loss: 0.989377
global_step: 5572, epoch: 40, loss: 1.092517
global_step: 5573, epoch: 40, loss: 1.100655
global_step: 5574, epoch: 40, loss: 1.073152
global_step: 5575, epoch: 40, loss: 1.018714
global_step: 5576, epoch: 40, loss: 1.102137
global_step: 5577, epoch: 40, loss: 1.074645
global_step: 5578, epoch: 40, loss: 0.952522
global_step: 5579, epoch: 40, loss: 1.073692
global_step: 5580, epoch: 40, loss: 1.039882
global_step: 5581, epoch: 40, loss: 0.952787
global_step: 5582, epoch: 40, loss: 1.091067
global_step: 5583, epoch: 40, loss: 1.031760
global_step: 5584, epoch: 40, loss: 1.048711
global_step: 5585, epoch: 40, loss: 1.080693
global_step: 5586, epoch: 40, loss: 0.901550
global_step: 5587, epoch: 40, loss: 1.078952
global_step: 5588, epoch: 40, loss: 1.200646
global_step: 5589, epoch: 40, loss: 1.059536
global_step: 5590, epoch: 40, loss: 0.988160
global_step: 5591, epoch: 40, loss: 1.191177
global_step: 5592, epoch: 40, loss: 1.191913
global_step: 5593, epoch: 40, loss: 1.022600
global_step: 5594, epoch: 40, loss: 1.057021
global_step: 5595, epoch: 40, loss: 1.160346
global_step: 5596, epoch: 40, loss: 1.063473
global_step: 5597, epoch: 40, loss: 1.063093
global_step: 5598, epoch: 40, loss: 1.121760
global_step: 5599, epoch: 40, loss: 1.005471
global_step: 5600, epoch: 40, loss: 1.432896
epoch: 40
train	acc: 0.6817	macro: p 0.4655, r 0.4002, f1: 0.4117	micro: p 0.6817, r 0.6817, f1 0.6817	weighted_f1:0.6441
dev	acc: 0.5546	macro: p 0.3583, r 0.3066, f1: 0.3005	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4981
test	acc: 0.5920	macro: p 0.3626, r 0.3067, f1: 0.3086	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5445
global_step: 5601, epoch: 41, loss: 1.104325
global_step: 5602, epoch: 41, loss: 1.219017
global_step: 5603, epoch: 41, loss: 1.133668
global_step: 5604, epoch: 41, loss: 1.179392
global_step: 5605, epoch: 41, loss: 1.055958
global_step: 5606, epoch: 41, loss: 1.085709
global_step: 5607, epoch: 41, loss: 1.112924
global_step: 5608, epoch: 41, loss: 1.071690
global_step: 5609, epoch: 41, loss: 0.952528
global_step: 5610, epoch: 41, loss: 1.171315
global_step: 5611, epoch: 41, loss: 1.018392
global_step: 5612, epoch: 41, loss: 0.930978
global_step: 5613, epoch: 41, loss: 1.024185
global_step: 5614, epoch: 41, loss: 1.063771
global_step: 5615, epoch: 41, loss: 0.995269
global_step: 5616, epoch: 41, loss: 1.142399
global_step: 5617, epoch: 41, loss: 1.028339
global_step: 5618, epoch: 41, loss: 0.942413
global_step: 5619, epoch: 41, loss: 1.102085
global_step: 5620, epoch: 41, loss: 1.070993
global_step: 5621, epoch: 41, loss: 1.155012
global_step: 5622, epoch: 41, loss: 1.156430
global_step: 5623, epoch: 41, loss: 1.061204
global_step: 5624, epoch: 41, loss: 1.165165
global_step: 5625, epoch: 41, loss: 0.988543
global_step: 5626, epoch: 41, loss: 1.051653
global_step: 5627, epoch: 41, loss: 1.070509
global_step: 5628, epoch: 41, loss: 1.039680
global_step: 5629, epoch: 41, loss: 1.116070
global_step: 5630, epoch: 41, loss: 0.953376
global_step: 5631, epoch: 41, loss: 1.027115
global_step: 5632, epoch: 41, loss: 0.960901
global_step: 5633, epoch: 41, loss: 1.143475
global_step: 5634, epoch: 41, loss: 0.996498
global_step: 5635, epoch: 41, loss: 0.976450
global_step: 5636, epoch: 41, loss: 0.982757
global_step: 5637, epoch: 41, loss: 1.002108
global_step: 5638, epoch: 41, loss: 1.114672
global_step: 5639, epoch: 41, loss: 0.996480
global_step: 5640, epoch: 41, loss: 1.205287
epoch: 41
train	acc: 0.6905	macro: p 0.4693, r 0.4116, f1: 0.4217	micro: p 0.6905, r 0.6905, f1 0.6905	weighted_f1:0.6541
dev	acc: 0.5528	macro: p 0.3530, r 0.3071, f1: 0.3008	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4986
test	acc: 0.5912	macro: p 0.3645, r 0.3088, f1: 0.3110	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5455
global_step: 5641, epoch: 42, loss: 1.041471
global_step: 5642, epoch: 42, loss: 0.958703
global_step: 5643, epoch: 42, loss: 0.953656
global_step: 5644, epoch: 42, loss: 1.175058
global_step: 5645, epoch: 42, loss: 1.029718
global_step: 5646, epoch: 42, loss: 0.981053
global_step: 5647, epoch: 42, loss: 0.967824
global_step: 5648, epoch: 42, loss: 0.967961
global_step: 5649, epoch: 42, loss: 1.107415
global_step: 5650, epoch: 42, loss: 1.094226
global_step: 5651, epoch: 42, loss: 1.089121
global_step: 5652, epoch: 42, loss: 1.094702
global_step: 5653, epoch: 42, loss: 1.140513
global_step: 5654, epoch: 42, loss: 0.996418
global_step: 5655, epoch: 42, loss: 0.998532
global_step: 5656, epoch: 42, loss: 1.150713
global_step: 5657, epoch: 42, loss: 1.114417
global_step: 5658, epoch: 42, loss: 1.040213
global_step: 5659, epoch: 42, loss: 1.051115
global_step: 5660, epoch: 42, loss: 1.106889
global_step: 5661, epoch: 42, loss: 1.117530
global_step: 5662, epoch: 42, loss: 0.958890
global_step: 5663, epoch: 42, loss: 0.984821
global_step: 5664, epoch: 42, loss: 0.990644
global_step: 5665, epoch: 42, loss: 1.169763
global_step: 5666, epoch: 42, loss: 0.994026
global_step: 5667, epoch: 42, loss: 1.031125
global_step: 5668, epoch: 42, loss: 1.001204
global_step: 5669, epoch: 42, loss: 1.107818
global_step: 5670, epoch: 42, loss: 1.057358
global_step: 5671, epoch: 42, loss: 1.145115
global_step: 5672, epoch: 42, loss: 0.988291
global_step: 5673, epoch: 42, loss: 0.984404
global_step: 5674, epoch: 42, loss: 0.984304
global_step: 5675, epoch: 42, loss: 1.148740
global_step: 5676, epoch: 42, loss: 1.161088
global_step: 5677, epoch: 42, loss: 1.103403
global_step: 5678, epoch: 42, loss: 1.094109
global_step: 5679, epoch: 42, loss: 1.085988
global_step: 5680, epoch: 42, loss: 0.366173
epoch: 42
train	acc: 0.6899	macro: p 0.4724, r 0.4097, f1: 0.4210	micro: p 0.6899, r 0.6899, f1 0.6899	weighted_f1:0.6530
dev	acc: 0.5555	macro: p 0.3575, r 0.3088, f1: 0.3039	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5008
test	acc: 0.5935	macro: p 0.3648, r 0.3089, f1: 0.3116	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5468
global_step: 5681, epoch: 43, loss: 1.061911
global_step: 5682, epoch: 43, loss: 1.056144
global_step: 5683, epoch: 43, loss: 0.973842
global_step: 5684, epoch: 43, loss: 0.972866
global_step: 5685, epoch: 43, loss: 1.030741
global_step: 5686, epoch: 43, loss: 1.020529
global_step: 5687, epoch: 43, loss: 1.034860
global_step: 5688, epoch: 43, loss: 1.001058
global_step: 5689, epoch: 43, loss: 1.081318
global_step: 5690, epoch: 43, loss: 1.063490
global_step: 5691, epoch: 43, loss: 1.078788
global_step: 5692, epoch: 43, loss: 1.042017
global_step: 5693, epoch: 43, loss: 0.997837
global_step: 5694, epoch: 43, loss: 1.142703
global_step: 5695, epoch: 43, loss: 1.038995
global_step: 5696, epoch: 43, loss: 1.064295
global_step: 5697, epoch: 43, loss: 0.936447
global_step: 5698, epoch: 43, loss: 1.099473
global_step: 5699, epoch: 43, loss: 1.056499
global_step: 5700, epoch: 43, loss: 0.989150
global_step: 5701, epoch: 43, loss: 1.129192
global_step: 5702, epoch: 43, loss: 1.127574
global_step: 5703, epoch: 43, loss: 1.119901
global_step: 5704, epoch: 43, loss: 0.995135
global_step: 5705, epoch: 43, loss: 1.039742
global_step: 5706, epoch: 43, loss: 1.023652
global_step: 5707, epoch: 43, loss: 0.972341
global_step: 5708, epoch: 43, loss: 1.003420
global_step: 5709, epoch: 43, loss: 1.094589
global_step: 5710, epoch: 43, loss: 1.141317
global_step: 5711, epoch: 43, loss: 1.054368
global_step: 5712, epoch: 43, loss: 1.113404
global_step: 5713, epoch: 43, loss: 1.051602
global_step: 5714, epoch: 43, loss: 1.010414
global_step: 5715, epoch: 43, loss: 1.148103
global_step: 5716, epoch: 43, loss: 1.069792
global_step: 5717, epoch: 43, loss: 1.066952
global_step: 5718, epoch: 43, loss: 1.009206
global_step: 5719, epoch: 43, loss: 1.091709
global_step: 5720, epoch: 43, loss: 1.478630
epoch: 43
train	acc: 0.6954	macro: p 0.4737, r 0.4178, f1: 0.4278	micro: p 0.6954, r 0.6954, f1 0.6954	weighted_f1:0.6605
dev	acc: 0.5555	macro: p 0.3597, r 0.3091, f1: 0.3048	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5024
test	acc: 0.5920	macro: p 0.3652, r 0.3087, f1: 0.3122	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5468
global_step: 5721, epoch: 44, loss: 1.004400
global_step: 5722, epoch: 44, loss: 1.001834
global_step: 5723, epoch: 44, loss: 1.046112
global_step: 5724, epoch: 44, loss: 1.065780
global_step: 5725, epoch: 44, loss: 1.064038
global_step: 5726, epoch: 44, loss: 0.968649
global_step: 5727, epoch: 44, loss: 1.033465
global_step: 5728, epoch: 44, loss: 1.152110
global_step: 5729, epoch: 44, loss: 1.143056
global_step: 5730, epoch: 44, loss: 1.018277
global_step: 5731, epoch: 44, loss: 1.100558
global_step: 5732, epoch: 44, loss: 1.080222
global_step: 5733, epoch: 44, loss: 1.004344
global_step: 5734, epoch: 44, loss: 1.099215
global_step: 5735, epoch: 44, loss: 1.049414
global_step: 5736, epoch: 44, loss: 1.109763
global_step: 5737, epoch: 44, loss: 1.019744
global_step: 5738, epoch: 44, loss: 1.001941
global_step: 5739, epoch: 44, loss: 1.047351
global_step: 5740, epoch: 44, loss: 1.035087
global_step: 5741, epoch: 44, loss: 0.984825
global_step: 5742, epoch: 44, loss: 1.019598
global_step: 5743, epoch: 44, loss: 1.029739
global_step: 5744, epoch: 44, loss: 1.084497
global_step: 5745, epoch: 44, loss: 1.045831
global_step: 5746, epoch: 44, loss: 1.172671
global_step: 5747, epoch: 44, loss: 1.004514
global_step: 5748, epoch: 44, loss: 0.973965
global_step: 5749, epoch: 44, loss: 1.022439
global_step: 5750, epoch: 44, loss: 1.014204
global_step: 5751, epoch: 44, loss: 1.021784
global_step: 5752, epoch: 44, loss: 1.079760
global_step: 5753, epoch: 44, loss: 0.890586
global_step: 5754, epoch: 44, loss: 1.094221
global_step: 5755, epoch: 44, loss: 1.095812
global_step: 5756, epoch: 44, loss: 0.999801
global_step: 5757, epoch: 44, loss: 1.079287
global_step: 5758, epoch: 44, loss: 1.171464
global_step: 5759, epoch: 44, loss: 1.018237
global_step: 5760, epoch: 44, loss: 1.171634
epoch: 44
train	acc: 0.6939	macro: p 0.4803, r 0.4093, f1: 0.4229	micro: p 0.6939, r 0.6939, f1 0.6939	weighted_f1:0.6560
dev	acc: 0.5528	macro: p 0.3481, r 0.3011, f1: 0.2934	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4934
test	acc: 0.5939	macro: p 0.3668, r 0.3063, f1: 0.3087	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5442
global_step: 5761, epoch: 45, loss: 1.019140
global_step: 5762, epoch: 45, loss: 0.927847
global_step: 5763, epoch: 45, loss: 0.929852
global_step: 5764, epoch: 45, loss: 1.142464
global_step: 5765, epoch: 45, loss: 0.998581
global_step: 5766, epoch: 45, loss: 1.079422
global_step: 5767, epoch: 45, loss: 1.064813
global_step: 5768, epoch: 45, loss: 1.083859
global_step: 5769, epoch: 45, loss: 1.001526
global_step: 5770, epoch: 45, loss: 1.039303
global_step: 5771, epoch: 45, loss: 1.113000
global_step: 5772, epoch: 45, loss: 1.030259
global_step: 5773, epoch: 45, loss: 1.037869
global_step: 5774, epoch: 45, loss: 1.022001
global_step: 5775, epoch: 45, loss: 1.078956
global_step: 5776, epoch: 45, loss: 1.013821
global_step: 5777, epoch: 45, loss: 0.945611
global_step: 5778, epoch: 45, loss: 0.976221
global_step: 5779, epoch: 45, loss: 1.108398
global_step: 5780, epoch: 45, loss: 1.071489
global_step: 5781, epoch: 45, loss: 1.079864
global_step: 5782, epoch: 45, loss: 1.124451
global_step: 5783, epoch: 45, loss: 0.967950
global_step: 5784, epoch: 45, loss: 1.035029
global_step: 5785, epoch: 45, loss: 1.109804
global_step: 5786, epoch: 45, loss: 1.013563
global_step: 5787, epoch: 45, loss: 1.040027
global_step: 5788, epoch: 45, loss: 0.982673
global_step: 5789, epoch: 45, loss: 1.011971
global_step: 5790, epoch: 45, loss: 0.993867
global_step: 5791, epoch: 45, loss: 1.068790
global_step: 5792, epoch: 45, loss: 1.018748
global_step: 5793, epoch: 45, loss: 1.055461
global_step: 5794, epoch: 45, loss: 0.898868
global_step: 5795, epoch: 45, loss: 1.038005
global_step: 5796, epoch: 45, loss: 1.071073
global_step: 5797, epoch: 45, loss: 0.967707
global_step: 5798, epoch: 45, loss: 0.986534
global_step: 5799, epoch: 45, loss: 1.046363
global_step: 5800, epoch: 45, loss: 1.026695
epoch: 45
train	acc: 0.7052	macro: p 0.4807, r 0.4244, f1: 0.4337	micro: p 0.7052, r 0.7052, f1 0.7052	weighted_f1:0.6681
dev	acc: 0.5537	macro: p 0.3510, r 0.3082, f1: 0.2977	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4957
test	acc: 0.5877	macro: p 0.3570, r 0.3055, f1: 0.3040	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5393
global_step: 5801, epoch: 46, loss: 0.957438
global_step: 5802, epoch: 46, loss: 1.136128
global_step: 5803, epoch: 46, loss: 1.018476
global_step: 5804, epoch: 46, loss: 1.000442
global_step: 5805, epoch: 46, loss: 0.985875
global_step: 5806, epoch: 46, loss: 1.024714
global_step: 5807, epoch: 46, loss: 1.031357
global_step: 5808, epoch: 46, loss: 1.115141
global_step: 5809, epoch: 46, loss: 0.981414
global_step: 5810, epoch: 46, loss: 1.010823
global_step: 5811, epoch: 46, loss: 1.001403
global_step: 5812, epoch: 46, loss: 1.052012
global_step: 5813, epoch: 46, loss: 1.045059
global_step: 5814, epoch: 46, loss: 1.099381
global_step: 5815, epoch: 46, loss: 0.973516
global_step: 5816, epoch: 46, loss: 1.037584
global_step: 5817, epoch: 46, loss: 1.061500
global_step: 5818, epoch: 46, loss: 1.037268
global_step: 5819, epoch: 46, loss: 1.016882
global_step: 5820, epoch: 46, loss: 1.085516
global_step: 5821, epoch: 46, loss: 0.996166
global_step: 5822, epoch: 46, loss: 1.048456
global_step: 5823, epoch: 46, loss: 1.023169
global_step: 5824, epoch: 46, loss: 0.987842
global_step: 5825, epoch: 46, loss: 1.089489
global_step: 5826, epoch: 46, loss: 0.984634
global_step: 5827, epoch: 46, loss: 1.044160
global_step: 5828, epoch: 46, loss: 0.985274
global_step: 5829, epoch: 46, loss: 1.002117
global_step: 5830, epoch: 46, loss: 1.038598
global_step: 5831, epoch: 46, loss: 0.951933
global_step: 5832, epoch: 46, loss: 0.968892
global_step: 5833, epoch: 46, loss: 1.012390
global_step: 5834, epoch: 46, loss: 1.119645
global_step: 5835, epoch: 46, loss: 1.056227
global_step: 5836, epoch: 46, loss: 0.993869
global_step: 5837, epoch: 46, loss: 0.986550
global_step: 5838, epoch: 46, loss: 1.001859
global_step: 5839, epoch: 46, loss: 0.921293
global_step: 5840, epoch: 46, loss: 0.589893
epoch: 46
train	acc: 0.7044	macro: p 0.4821, r 0.4231, f1: 0.4343	micro: p 0.7044, r 0.7044, f1 0.7044	weighted_f1:0.6682
dev	acc: 0.5464	macro: p 0.3504, r 0.3004, f1: 0.2898	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4873
test	acc: 0.5885	macro: p 0.3619, r 0.3066, f1: 0.3056	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5399
global_step: 5841, epoch: 47, loss: 0.976699
global_step: 5842, epoch: 47, loss: 1.037321
global_step: 5843, epoch: 47, loss: 1.041311
global_step: 5844, epoch: 47, loss: 1.042984
global_step: 5845, epoch: 47, loss: 1.103304
global_step: 5846, epoch: 47, loss: 0.978431
global_step: 5847, epoch: 47, loss: 0.956771
global_step: 5848, epoch: 47, loss: 0.981447
global_step: 5849, epoch: 47, loss: 0.960762
global_step: 5850, epoch: 47, loss: 0.989188
global_step: 5851, epoch: 47, loss: 0.974020
global_step: 5852, epoch: 47, loss: 1.009388
global_step: 5853, epoch: 47, loss: 1.059243
global_step: 5854, epoch: 47, loss: 1.016472
global_step: 5855, epoch: 47, loss: 1.093456
global_step: 5856, epoch: 47, loss: 1.087174
global_step: 5857, epoch: 47, loss: 1.002058
global_step: 5858, epoch: 47, loss: 0.891470
global_step: 5859, epoch: 47, loss: 1.107350
global_step: 5860, epoch: 47, loss: 0.903303
global_step: 5861, epoch: 47, loss: 1.054140
global_step: 5862, epoch: 47, loss: 0.930356
global_step: 5863, epoch: 47, loss: 0.999345
global_step: 5864, epoch: 47, loss: 1.104615
global_step: 5865, epoch: 47, loss: 0.984955
global_step: 5866, epoch: 47, loss: 1.102871
global_step: 5867, epoch: 47, loss: 0.989020
global_step: 5868, epoch: 47, loss: 1.023204
global_step: 5869, epoch: 47, loss: 1.054296
global_step: 5870, epoch: 47, loss: 0.989564
global_step: 5871, epoch: 47, loss: 1.101509
global_step: 5872, epoch: 47, loss: 1.017631
global_step: 5873, epoch: 47, loss: 1.018773
global_step: 5874, epoch: 47, loss: 1.040692
global_step: 5875, epoch: 47, loss: 1.028014
global_step: 5876, epoch: 47, loss: 0.954892
global_step: 5877, epoch: 47, loss: 1.025499
global_step: 5878, epoch: 47, loss: 1.020433
global_step: 5879, epoch: 47, loss: 1.080847
global_step: 5880, epoch: 47, loss: 0.582063
epoch: 47
train	acc: 0.7121	macro: p 0.4907, r 0.4305, f1: 0.4400	micro: p 0.7121, r 0.7121, f1 0.7121	weighted_f1:0.6746
dev	acc: 0.5528	macro: p 0.3515, r 0.3073, f1: 0.2958	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4933
test	acc: 0.5854	macro: p 0.3548, r 0.3037, f1: 0.3012	micro: p 0.5854, r 0.5854, f1 0.5854	weighted_f1:0.5362
global_step: 5881, epoch: 48, loss: 0.934308
global_step: 5882, epoch: 48, loss: 1.015998
global_step: 5883, epoch: 48, loss: 1.035961
global_step: 5884, epoch: 48, loss: 1.044801
global_step: 5885, epoch: 48, loss: 0.988148
global_step: 5886, epoch: 48, loss: 0.906935
global_step: 5887, epoch: 48, loss: 1.045718
global_step: 5888, epoch: 48, loss: 0.990220
global_step: 5889, epoch: 48, loss: 1.003406
global_step: 5890, epoch: 48, loss: 1.012941
global_step: 5891, epoch: 48, loss: 1.024491
global_step: 5892, epoch: 48, loss: 1.087430
global_step: 5893, epoch: 48, loss: 1.039774
global_step: 5894, epoch: 48, loss: 1.038419
global_step: 5895, epoch: 48, loss: 1.000558
global_step: 5896, epoch: 48, loss: 0.988039
global_step: 5897, epoch: 48, loss: 1.016524
global_step: 5898, epoch: 48, loss: 1.116122
global_step: 5899, epoch: 48, loss: 0.870908
global_step: 5900, epoch: 48, loss: 1.028119
global_step: 5901, epoch: 48, loss: 1.068404
global_step: 5902, epoch: 48, loss: 0.982363
global_step: 5903, epoch: 48, loss: 1.017160
global_step: 5904, epoch: 48, loss: 0.964370
global_step: 5905, epoch: 48, loss: 1.017517
global_step: 5906, epoch: 48, loss: 0.961911
global_step: 5907, epoch: 48, loss: 1.072253
global_step: 5908, epoch: 48, loss: 1.056718
global_step: 5909, epoch: 48, loss: 0.985438
global_step: 5910, epoch: 48, loss: 1.020839
global_step: 5911, epoch: 48, loss: 1.004831
global_step: 5912, epoch: 48, loss: 1.015887
global_step: 5913, epoch: 48, loss: 0.957523
global_step: 5914, epoch: 48, loss: 0.918190
global_step: 5915, epoch: 48, loss: 0.953884
global_step: 5916, epoch: 48, loss: 1.025419
global_step: 5917, epoch: 48, loss: 0.886596
global_step: 5918, epoch: 48, loss: 0.948453
global_step: 5919, epoch: 48, loss: 1.061937
global_step: 5920, epoch: 48, loss: 1.623796
epoch: 48
train	acc: 0.7303	macro: p 0.4929, r 0.4620, f1: 0.4678	micro: p 0.7303, r 0.7303, f1 0.7303	weighted_f1:0.7001
dev	acc: 0.5482	macro: p 0.3486, r 0.3097, f1: 0.3034	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4985
test	acc: 0.5893	macro: p 0.3497, r 0.3131, f1: 0.3120	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5464
global_step: 5921, epoch: 49, loss: 0.961424
global_step: 5922, epoch: 49, loss: 1.164107
global_step: 5923, epoch: 49, loss: 0.949391
global_step: 5924, epoch: 49, loss: 1.032929
global_step: 5925, epoch: 49, loss: 0.939368
global_step: 5926, epoch: 49, loss: 1.034748
global_step: 5927, epoch: 49, loss: 0.953980
global_step: 5928, epoch: 49, loss: 0.939115
global_step: 5929, epoch: 49, loss: 0.921157
global_step: 5930, epoch: 49, loss: 0.928209
global_step: 5931, epoch: 49, loss: 1.086737
global_step: 5932, epoch: 49, loss: 0.945061
global_step: 5933, epoch: 49, loss: 1.006617
global_step: 5934, epoch: 49, loss: 1.034998
global_step: 5935, epoch: 49, loss: 1.105037
global_step: 5936, epoch: 49, loss: 0.976255
global_step: 5937, epoch: 49, loss: 0.987565
global_step: 5938, epoch: 49, loss: 0.979879
global_step: 5939, epoch: 49, loss: 0.990208
global_step: 5940, epoch: 49, loss: 1.069887
global_step: 5941, epoch: 49, loss: 1.010247
global_step: 5942, epoch: 49, loss: 0.877735
global_step: 5943, epoch: 49, loss: 1.014850
global_step: 5944, epoch: 49, loss: 0.939517
global_step: 5945, epoch: 49, loss: 1.046200
global_step: 5946, epoch: 49, loss: 1.019001
global_step: 5947, epoch: 49, loss: 0.945817
global_step: 5948, epoch: 49, loss: 1.056888
global_step: 5949, epoch: 49, loss: 1.060750
global_step: 5950, epoch: 49, loss: 1.152112
global_step: 5951, epoch: 49, loss: 1.026255
global_step: 5952, epoch: 49, loss: 1.000310
global_step: 5953, epoch: 49, loss: 0.873350
global_step: 5954, epoch: 49, loss: 0.937570
global_step: 5955, epoch: 49, loss: 1.024063
global_step: 5956, epoch: 49, loss: 1.035882
global_step: 5957, epoch: 49, loss: 0.910573
global_step: 5958, epoch: 49, loss: 1.019063
global_step: 5959, epoch: 49, loss: 0.921748
global_step: 5960, epoch: 49, loss: 1.816404
epoch: 49
train	acc: 0.7193	macro: p 0.4922, r 0.4398, f1: 0.4514	micro: p 0.7193, r 0.7193, f1 0.7193	weighted_f1:0.6847
dev	acc: 0.5482	macro: p 0.3483, r 0.3034, f1: 0.2941	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4905
test	acc: 0.5885	macro: p 0.3556, r 0.3062, f1: 0.3056	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5400
global_step: 5961, epoch: 50, loss: 1.042217
global_step: 5962, epoch: 50, loss: 0.973599
global_step: 5963, epoch: 50, loss: 1.074568
global_step: 5964, epoch: 50, loss: 0.997332
global_step: 5965, epoch: 50, loss: 0.979014
global_step: 5966, epoch: 50, loss: 1.004262
global_step: 5967, epoch: 50, loss: 1.048985
global_step: 5968, epoch: 50, loss: 0.962780
global_step: 5969, epoch: 50, loss: 1.058860
global_step: 5970, epoch: 50, loss: 1.010488
global_step: 5971, epoch: 50, loss: 0.930546
global_step: 5972, epoch: 50, loss: 1.015524
global_step: 5973, epoch: 50, loss: 0.985027
global_step: 5974, epoch: 50, loss: 1.041342
global_step: 5975, epoch: 50, loss: 0.864791
global_step: 5976, epoch: 50, loss: 0.970438
global_step: 5977, epoch: 50, loss: 1.087188
global_step: 5978, epoch: 50, loss: 1.022546
global_step: 5979, epoch: 50, loss: 0.938128
global_step: 5980, epoch: 50, loss: 0.912614
global_step: 5981, epoch: 50, loss: 0.935892
global_step: 5982, epoch: 50, loss: 1.129670
global_step: 5983, epoch: 50, loss: 1.051383
global_step: 5984, epoch: 50, loss: 1.190000
global_step: 5985, epoch: 50, loss: 0.907189
global_step: 5986, epoch: 50, loss: 0.919317
global_step: 5987, epoch: 50, loss: 1.037025
global_step: 5988, epoch: 50, loss: 1.013248
global_step: 5989, epoch: 50, loss: 0.916299
global_step: 5990, epoch: 50, loss: 1.067142
global_step: 5991, epoch: 50, loss: 0.923313
global_step: 5992, epoch: 50, loss: 0.908280
global_step: 5993, epoch: 50, loss: 1.011822
global_step: 5994, epoch: 50, loss: 0.853748
global_step: 5995, epoch: 50, loss: 0.996590
global_step: 5996, epoch: 50, loss: 0.959447
global_step: 5997, epoch: 50, loss: 1.079409
global_step: 5998, epoch: 50, loss: 1.101363
global_step: 5999, epoch: 50, loss: 0.925095
global_step: 6000, epoch: 50, loss: 0.741593
epoch: 50
train	acc: 0.7159	macro: p 0.4990, r 0.4320, f1: 0.4453	micro: p 0.7159, r 0.7159, f1 0.7159	weighted_f1:0.6795
dev	acc: 0.5482	macro: p 0.3550, r 0.3009, f1: 0.2929	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4899
test	acc: 0.5931	macro: p 0.3653, r 0.3070, f1: 0.3074	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5430
global_step: 6001, epoch: 51, loss: 0.865792
global_step: 6002, epoch: 51, loss: 1.034832
global_step: 6003, epoch: 51, loss: 0.994472
global_step: 6004, epoch: 51, loss: 0.929361
global_step: 6005, epoch: 51, loss: 0.969184
global_step: 6006, epoch: 51, loss: 0.965783
global_step: 6007, epoch: 51, loss: 1.088777
global_step: 6008, epoch: 51, loss: 1.061074
global_step: 6009, epoch: 51, loss: 1.085722
global_step: 6010, epoch: 51, loss: 1.093121
global_step: 6011, epoch: 51, loss: 0.948519
global_step: 6012, epoch: 51, loss: 0.987187
global_step: 6013, epoch: 51, loss: 0.936891
global_step: 6014, epoch: 51, loss: 0.988620
global_step: 6015, epoch: 51, loss: 1.007401
global_step: 6016, epoch: 51, loss: 1.073844
global_step: 6017, epoch: 51, loss: 0.954928
global_step: 6018, epoch: 51, loss: 1.042637
global_step: 6019, epoch: 51, loss: 0.965985
global_step: 6020, epoch: 51, loss: 0.885357
global_step: 6021, epoch: 51, loss: 0.889617
global_step: 6022, epoch: 51, loss: 1.085974
global_step: 6023, epoch: 51, loss: 0.899823
global_step: 6024, epoch: 51, loss: 0.929104
global_step: 6025, epoch: 51, loss: 0.969158
global_step: 6026, epoch: 51, loss: 1.069636
global_step: 6027, epoch: 51, loss: 0.983130
global_step: 6028, epoch: 51, loss: 1.070673
global_step: 6029, epoch: 51, loss: 0.966237
global_step: 6030, epoch: 51, loss: 1.144922
global_step: 6031, epoch: 51, loss: 1.019048
global_step: 6032, epoch: 51, loss: 1.012140
global_step: 6033, epoch: 51, loss: 0.930413
global_step: 6034, epoch: 51, loss: 1.053189
global_step: 6035, epoch: 51, loss: 1.025239
global_step: 6036, epoch: 51, loss: 1.028704
global_step: 6037, epoch: 51, loss: 0.978049
global_step: 6038, epoch: 51, loss: 0.903017
global_step: 6039, epoch: 51, loss: 1.029033
global_step: 6040, epoch: 51, loss: 0.679313
epoch: 51
train	acc: 0.7267	macro: p 0.5038, r 0.4475, f1: 0.4593	micro: p 0.7267, r 0.7267, f1 0.7267	weighted_f1:0.6929
dev	acc: 0.5500	macro: p 0.3543, r 0.3029, f1: 0.2966	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4939
test	acc: 0.5923	macro: p 0.3612, r 0.3083, f1: 0.3103	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5455
global_step: 6041, epoch: 52, loss: 1.052602
global_step: 6042, epoch: 52, loss: 1.016612
global_step: 6043, epoch: 52, loss: 1.028262
global_step: 6044, epoch: 52, loss: 0.891070
global_step: 6045, epoch: 52, loss: 1.038691
global_step: 6046, epoch: 52, loss: 1.028961
global_step: 6047, epoch: 52, loss: 1.037673
global_step: 6048, epoch: 52, loss: 1.026824
global_step: 6049, epoch: 52, loss: 1.071366
global_step: 6050, epoch: 52, loss: 0.936672
global_step: 6051, epoch: 52, loss: 0.935239
global_step: 6052, epoch: 52, loss: 1.031088
global_step: 6053, epoch: 52, loss: 1.021945
global_step: 6054, epoch: 52, loss: 0.992544
global_step: 6055, epoch: 52, loss: 0.824181
global_step: 6056, epoch: 52, loss: 0.939424
global_step: 6057, epoch: 52, loss: 1.016501
global_step: 6058, epoch: 52, loss: 1.044036
global_step: 6059, epoch: 52, loss: 0.960717
global_step: 6060, epoch: 52, loss: 0.998286
global_step: 6061, epoch: 52, loss: 1.084049
global_step: 6062, epoch: 52, loss: 0.949233
global_step: 6063, epoch: 52, loss: 0.898701
global_step: 6064, epoch: 52, loss: 1.005770
global_step: 6065, epoch: 52, loss: 0.899803
global_step: 6066, epoch: 52, loss: 0.930901
global_step: 6067, epoch: 52, loss: 0.895147
global_step: 6068, epoch: 52, loss: 1.037461
global_step: 6069, epoch: 52, loss: 1.029778
global_step: 6070, epoch: 52, loss: 0.931577
global_step: 6071, epoch: 52, loss: 0.899852
global_step: 6072, epoch: 52, loss: 0.926726
global_step: 6073, epoch: 52, loss: 1.115961
global_step: 6074, epoch: 52, loss: 1.065179
global_step: 6075, epoch: 52, loss: 0.935759
global_step: 6076, epoch: 52, loss: 0.992595
global_step: 6077, epoch: 52, loss: 1.010013
global_step: 6078, epoch: 52, loss: 0.923361
global_step: 6079, epoch: 52, loss: 0.918591
global_step: 6080, epoch: 52, loss: 0.357166
epoch: 52
train	acc: 0.7345	macro: p 0.5094, r 0.4566, f1: 0.4665	micro: p 0.7345, r 0.7345, f1 0.7345	weighted_f1:0.6999
dev	acc: 0.5528	macro: p 0.3536, r 0.3069, f1: 0.2991	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4956
test	acc: 0.5908	macro: p 0.3534, r 0.3072, f1: 0.3062	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5418
global_step: 6081, epoch: 53, loss: 1.124078
global_step: 6082, epoch: 53, loss: 0.943084
global_step: 6083, epoch: 53, loss: 0.967327
global_step: 6084, epoch: 53, loss: 0.880253
global_step: 6085, epoch: 53, loss: 1.058631
global_step: 6086, epoch: 53, loss: 1.038387
global_step: 6087, epoch: 53, loss: 0.936490
global_step: 6088, epoch: 53, loss: 0.942382
global_step: 6089, epoch: 53, loss: 0.913703
global_step: 6090, epoch: 53, loss: 0.945790
global_step: 6091, epoch: 53, loss: 0.881591
global_step: 6092, epoch: 53, loss: 0.884533
global_step: 6093, epoch: 53, loss: 0.923664
global_step: 6094, epoch: 53, loss: 0.930137
global_step: 6095, epoch: 53, loss: 0.973185
global_step: 6096, epoch: 53, loss: 0.958907
global_step: 6097, epoch: 53, loss: 1.141491
global_step: 6098, epoch: 53, loss: 1.020363
global_step: 6099, epoch: 53, loss: 0.922629
global_step: 6100, epoch: 53, loss: 0.988982
global_step: 6101, epoch: 53, loss: 1.019325
global_step: 6102, epoch: 53, loss: 1.000959
global_step: 6103, epoch: 53, loss: 0.965231
global_step: 6104, epoch: 53, loss: 0.913086
global_step: 6105, epoch: 53, loss: 0.999575
global_step: 6106, epoch: 53, loss: 0.964347
global_step: 6107, epoch: 53, loss: 0.919912
global_step: 6108, epoch: 53, loss: 0.986299
global_step: 6109, epoch: 53, loss: 0.963162
global_step: 6110, epoch: 53, loss: 0.972178
global_step: 6111, epoch: 53, loss: 0.948163
global_step: 6112, epoch: 53, loss: 0.968140
global_step: 6113, epoch: 53, loss: 1.027497
global_step: 6114, epoch: 53, loss: 1.026337
global_step: 6115, epoch: 53, loss: 0.976953
global_step: 6116, epoch: 53, loss: 0.914177
global_step: 6117, epoch: 53, loss: 0.950368
global_step: 6118, epoch: 53, loss: 0.938960
global_step: 6119, epoch: 53, loss: 0.986732
global_step: 6120, epoch: 53, loss: 1.058958
epoch: 53
train	acc: 0.7360	macro: p 0.5127, r 0.4575, f1: 0.4686	micro: p 0.7360, r 0.7360, f1 0.7360	weighted_f1:0.7017
dev	acc: 0.5473	macro: p 0.3442, r 0.3010, f1: 0.2905	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4879
test	acc: 0.5904	macro: p 0.3566, r 0.3064, f1: 0.3052	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5408
global_step: 6121, epoch: 54, loss: 0.948722
global_step: 6122, epoch: 54, loss: 0.944552
global_step: 6123, epoch: 54, loss: 1.018358
global_step: 6124, epoch: 54, loss: 1.042596
global_step: 6125, epoch: 54, loss: 1.027006
global_step: 6126, epoch: 54, loss: 0.947918
global_step: 6127, epoch: 54, loss: 0.964056
global_step: 6128, epoch: 54, loss: 0.883903
global_step: 6129, epoch: 54, loss: 0.986338
global_step: 6130, epoch: 54, loss: 1.025434
global_step: 6131, epoch: 54, loss: 0.975576
global_step: 6132, epoch: 54, loss: 0.922383
global_step: 6133, epoch: 54, loss: 0.933352
global_step: 6134, epoch: 54, loss: 1.023595
global_step: 6135, epoch: 54, loss: 0.928801
global_step: 6136, epoch: 54, loss: 0.908577
global_step: 6137, epoch: 54, loss: 0.967323
global_step: 6138, epoch: 54, loss: 0.896268
global_step: 6139, epoch: 54, loss: 0.869854
global_step: 6140, epoch: 54, loss: 1.038508
global_step: 6141, epoch: 54, loss: 0.962134
global_step: 6142, epoch: 54, loss: 0.970382
global_step: 6143, epoch: 54, loss: 0.911113
global_step: 6144, epoch: 54, loss: 0.968456
global_step: 6145, epoch: 54, loss: 0.942665
global_step: 6146, epoch: 54, loss: 0.893636
global_step: 6147, epoch: 54, loss: 1.067682
global_step: 6148, epoch: 54, loss: 0.944755
global_step: 6149, epoch: 54, loss: 0.981505
global_step: 6150, epoch: 54, loss: 1.004620
global_step: 6151, epoch: 54, loss: 0.958251
global_step: 6152, epoch: 54, loss: 0.921064
global_step: 6153, epoch: 54, loss: 1.034158
global_step: 6154, epoch: 54, loss: 1.129439
global_step: 6155, epoch: 54, loss: 0.945583
global_step: 6156, epoch: 54, loss: 0.946245
global_step: 6157, epoch: 54, loss: 1.046195
global_step: 6158, epoch: 54, loss: 0.818972
global_step: 6159, epoch: 54, loss: 0.956495
global_step: 6160, epoch: 54, loss: 0.505620
epoch: 54
train	acc: 0.7447	macro: p 0.5131, r 0.4727, f1: 0.4817	micro: p 0.7447, r 0.7447, f1 0.7447	weighted_f1:0.7141
dev	acc: 0.5482	macro: p 0.3529, r 0.3066, f1: 0.3008	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4959
test	acc: 0.5920	macro: p 0.3547, r 0.3097, f1: 0.3107	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5462
global_step: 6161, epoch: 55, loss: 1.011081
global_step: 6162, epoch: 55, loss: 0.903495
global_step: 6163, epoch: 55, loss: 0.923004
global_step: 6164, epoch: 55, loss: 0.959792
global_step: 6165, epoch: 55, loss: 0.881914
global_step: 6166, epoch: 55, loss: 0.863923
global_step: 6167, epoch: 55, loss: 1.026989
global_step: 6168, epoch: 55, loss: 1.065748
global_step: 6169, epoch: 55, loss: 0.915409
global_step: 6170, epoch: 55, loss: 1.055703
global_step: 6171, epoch: 55, loss: 0.998694
global_step: 6172, epoch: 55, loss: 0.944164
global_step: 6173, epoch: 55, loss: 0.991162
global_step: 6174, epoch: 55, loss: 0.871506
global_step: 6175, epoch: 55, loss: 0.964496
global_step: 6176, epoch: 55, loss: 0.922425
global_step: 6177, epoch: 55, loss: 0.871511
global_step: 6178, epoch: 55, loss: 1.006937
global_step: 6179, epoch: 55, loss: 1.004383
global_step: 6180, epoch: 55, loss: 0.989203
global_step: 6181, epoch: 55, loss: 0.915705
global_step: 6182, epoch: 55, loss: 1.030651
global_step: 6183, epoch: 55, loss: 0.937042
global_step: 6184, epoch: 55, loss: 1.040467
global_step: 6185, epoch: 55, loss: 0.959813
global_step: 6186, epoch: 55, loss: 0.854314
global_step: 6187, epoch: 55, loss: 0.904797
global_step: 6188, epoch: 55, loss: 0.999376
global_step: 6189, epoch: 55, loss: 1.020443
global_step: 6190, epoch: 55, loss: 0.956099
global_step: 6191, epoch: 55, loss: 0.959892
global_step: 6192, epoch: 55, loss: 0.975056
global_step: 6193, epoch: 55, loss: 0.952148
global_step: 6194, epoch: 55, loss: 0.982117
global_step: 6195, epoch: 55, loss: 0.966001
global_step: 6196, epoch: 55, loss: 0.961603
global_step: 6197, epoch: 55, loss: 0.990692
global_step: 6198, epoch: 55, loss: 0.886285
global_step: 6199, epoch: 55, loss: 0.967810
global_step: 6200, epoch: 55, loss: 0.404876
epoch: 55
train	acc: 0.7456	macro: p 0.5180, r 0.4737, f1: 0.4862	micro: p 0.7456, r 0.7456, f1 0.7456	weighted_f1:0.7150
dev	acc: 0.5491	macro: p 0.3522, r 0.3043, f1: 0.2983	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4947
test	acc: 0.5935	macro: p 0.3575, r 0.3089, f1: 0.3110	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5455
global_step: 6201, epoch: 56, loss: 0.943854
global_step: 6202, epoch: 56, loss: 0.894352
global_step: 6203, epoch: 56, loss: 0.935611
global_step: 6204, epoch: 56, loss: 1.027706
global_step: 6205, epoch: 56, loss: 0.962466
global_step: 6206, epoch: 56, loss: 0.922849
global_step: 6207, epoch: 56, loss: 0.925376
global_step: 6208, epoch: 56, loss: 0.942734
global_step: 6209, epoch: 56, loss: 0.970730
global_step: 6210, epoch: 56, loss: 1.021097
global_step: 6211, epoch: 56, loss: 0.981516
global_step: 6212, epoch: 56, loss: 0.983994
global_step: 6213, epoch: 56, loss: 0.944120
global_step: 6214, epoch: 56, loss: 0.957364
global_step: 6215, epoch: 56, loss: 0.995502
global_step: 6216, epoch: 56, loss: 0.926719
global_step: 6217, epoch: 56, loss: 0.889973
global_step: 6218, epoch: 56, loss: 0.996001
global_step: 6219, epoch: 56, loss: 0.930904
global_step: 6220, epoch: 56, loss: 0.881187
global_step: 6221, epoch: 56, loss: 0.953713
global_step: 6222, epoch: 56, loss: 0.967215
global_step: 6223, epoch: 56, loss: 0.884885
global_step: 6224, epoch: 56, loss: 0.936854
global_step: 6225, epoch: 56, loss: 0.912036
global_step: 6226, epoch: 56, loss: 0.925461
global_step: 6227, epoch: 56, loss: 0.805162
global_step: 6228, epoch: 56, loss: 0.988596
global_step: 6229, epoch: 56, loss: 0.945053
global_step: 6230, epoch: 56, loss: 1.008535
global_step: 6231, epoch: 56, loss: 0.872037
global_step: 6232, epoch: 56, loss: 0.879344
global_step: 6233, epoch: 56, loss: 0.892344
global_step: 6234, epoch: 56, loss: 1.017081
global_step: 6235, epoch: 56, loss: 0.956280
global_step: 6236, epoch: 56, loss: 1.044085
global_step: 6237, epoch: 56, loss: 0.981243
global_step: 6238, epoch: 56, loss: 0.950114
global_step: 6239, epoch: 56, loss: 0.846134
global_step: 6240, epoch: 56, loss: 1.016926
epoch: 56
train	acc: 0.7487	macro: p 0.5206, r 0.4756, f1: 0.4857	micro: p 0.7487, r 0.7487, f1 0.7487	weighted_f1:0.7168
dev	acc: 0.5491	macro: p 0.3454, r 0.3031, f1: 0.2940	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4914
test	acc: 0.5916	macro: p 0.3569, r 0.3093, f1: 0.3091	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5440
global_step: 6241, epoch: 57, loss: 0.890125
global_step: 6242, epoch: 57, loss: 0.984313
global_step: 6243, epoch: 57, loss: 0.923521
global_step: 6244, epoch: 57, loss: 1.040548
global_step: 6245, epoch: 57, loss: 0.882558
global_step: 6246, epoch: 57, loss: 0.837536
global_step: 6247, epoch: 57, loss: 0.934562
global_step: 6248, epoch: 57, loss: 0.933473
global_step: 6249, epoch: 57, loss: 0.985490
global_step: 6250, epoch: 57, loss: 1.035597
global_step: 6251, epoch: 57, loss: 0.897980
global_step: 6252, epoch: 57, loss: 0.869456
global_step: 6253, epoch: 57, loss: 0.887593
global_step: 6254, epoch: 57, loss: 0.973314
global_step: 6255, epoch: 57, loss: 0.958621
global_step: 6256, epoch: 57, loss: 0.893385
global_step: 6257, epoch: 57, loss: 1.047320
global_step: 6258, epoch: 57, loss: 0.994112
global_step: 6259, epoch: 57, loss: 0.867296
global_step: 6260, epoch: 57, loss: 0.803434
global_step: 6261, epoch: 57, loss: 0.897422
global_step: 6262, epoch: 57, loss: 1.003166
global_step: 6263, epoch: 57, loss: 0.889397
global_step: 6264, epoch: 57, loss: 0.972346
global_step: 6265, epoch: 57, loss: 0.972393
global_step: 6266, epoch: 57, loss: 0.923202
global_step: 6267, epoch: 57, loss: 0.972430
global_step: 6268, epoch: 57, loss: 0.948275
global_step: 6269, epoch: 57, loss: 0.959376
global_step: 6270, epoch: 57, loss: 0.988053
global_step: 6271, epoch: 57, loss: 0.895051
global_step: 6272, epoch: 57, loss: 0.958252
global_step: 6273, epoch: 57, loss: 0.914333
global_step: 6274, epoch: 57, loss: 0.877216
global_step: 6275, epoch: 57, loss: 0.910267
global_step: 6276, epoch: 57, loss: 0.894540
global_step: 6277, epoch: 57, loss: 0.906144
global_step: 6278, epoch: 57, loss: 1.100996
global_step: 6279, epoch: 57, loss: 0.835683
global_step: 6280, epoch: 57, loss: 1.398032
epoch: 57
train	acc: 0.7558	macro: p 0.6675, r 0.4904, f1: 0.4969	micro: p 0.7558, r 0.7558, f1 0.7558	weighted_f1:0.7273
dev	acc: 0.5546	macro: p 0.3502, r 0.3120, f1: 0.3073	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5032
test	acc: 0.5958	macro: p 0.3621, r 0.3152, f1: 0.3182	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5527
New best model!
global_step: 6281, epoch: 58, loss: 0.985993
global_step: 6282, epoch: 58, loss: 0.864559
global_step: 6283, epoch: 58, loss: 1.026346
global_step: 6284, epoch: 58, loss: 0.956133
global_step: 6285, epoch: 58, loss: 0.931027
global_step: 6286, epoch: 58, loss: 0.887602
global_step: 6287, epoch: 58, loss: 0.967194
global_step: 6288, epoch: 58, loss: 0.928780
global_step: 6289, epoch: 58, loss: 0.915672
global_step: 6290, epoch: 58, loss: 0.970864
global_step: 6291, epoch: 58, loss: 0.831017
global_step: 6292, epoch: 58, loss: 0.937172
global_step: 6293, epoch: 58, loss: 0.931305
global_step: 6294, epoch: 58, loss: 0.931188
global_step: 6295, epoch: 58, loss: 0.947757
global_step: 6296, epoch: 58, loss: 0.968348
global_step: 6297, epoch: 58, loss: 0.935454
global_step: 6298, epoch: 58, loss: 0.841221
global_step: 6299, epoch: 58, loss: 0.947980
global_step: 6300, epoch: 58, loss: 0.920050
global_step: 6301, epoch: 58, loss: 0.960217
global_step: 6302, epoch: 58, loss: 0.824929
global_step: 6303, epoch: 58, loss: 0.863810
global_step: 6304, epoch: 58, loss: 0.917011
global_step: 6305, epoch: 58, loss: 0.962603
global_step: 6306, epoch: 58, loss: 0.907066
global_step: 6307, epoch: 58, loss: 1.086619
global_step: 6308, epoch: 58, loss: 1.006668
global_step: 6309, epoch: 58, loss: 0.838363
global_step: 6310, epoch: 58, loss: 0.987408
global_step: 6311, epoch: 58, loss: 0.917402
global_step: 6312, epoch: 58, loss: 0.869708
global_step: 6313, epoch: 58, loss: 0.865925
global_step: 6314, epoch: 58, loss: 0.979850
global_step: 6315, epoch: 58, loss: 0.934298
global_step: 6316, epoch: 58, loss: 0.917959
global_step: 6317, epoch: 58, loss: 1.000738
global_step: 6318, epoch: 58, loss: 0.891484
global_step: 6319, epoch: 58, loss: 0.953955
global_step: 6320, epoch: 58, loss: 0.725083
epoch: 58
train	acc: 0.7588	macro: p 0.6677, r 0.4931, f1: 0.5028	micro: p 0.7588, r 0.7588, f1 0.7588	weighted_f1:0.7305
dev	acc: 0.5500	macro: p 0.3425, r 0.3063, f1: 0.3029	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4975
test	acc: 0.5973	macro: p 0.3616, r 0.3134, f1: 0.3181	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5521
global_step: 6321, epoch: 59, loss: 1.017180
global_step: 6322, epoch: 59, loss: 0.841747
global_step: 6323, epoch: 59, loss: 1.060728
global_step: 6324, epoch: 59, loss: 0.849071
global_step: 6325, epoch: 59, loss: 0.950951
global_step: 6326, epoch: 59, loss: 0.929752
global_step: 6327, epoch: 59, loss: 0.827163
global_step: 6328, epoch: 59, loss: 0.921991
global_step: 6329, epoch: 59, loss: 1.001719
global_step: 6330, epoch: 59, loss: 0.821245
global_step: 6331, epoch: 59, loss: 0.952003
global_step: 6332, epoch: 59, loss: 0.881148
global_step: 6333, epoch: 59, loss: 0.952052
global_step: 6334, epoch: 59, loss: 0.919681
global_step: 6335, epoch: 59, loss: 0.927738
global_step: 6336, epoch: 59, loss: 0.985213
global_step: 6337, epoch: 59, loss: 0.944447
global_step: 6338, epoch: 59, loss: 0.877720
global_step: 6339, epoch: 59, loss: 0.897352
global_step: 6340, epoch: 59, loss: 0.920023
global_step: 6341, epoch: 59, loss: 0.994634
global_step: 6342, epoch: 59, loss: 0.872056
global_step: 6343, epoch: 59, loss: 0.926306
global_step: 6344, epoch: 59, loss: 0.978497
global_step: 6345, epoch: 59, loss: 0.969414
global_step: 6346, epoch: 59, loss: 0.920005
global_step: 6347, epoch: 59, loss: 0.960191
global_step: 6348, epoch: 59, loss: 0.940566
global_step: 6349, epoch: 59, loss: 0.867391
global_step: 6350, epoch: 59, loss: 0.875525
global_step: 6351, epoch: 59, loss: 0.884295
global_step: 6352, epoch: 59, loss: 0.960522
global_step: 6353, epoch: 59, loss: 0.794048
global_step: 6354, epoch: 59, loss: 0.953484
global_step: 6355, epoch: 59, loss: 0.894864
global_step: 6356, epoch: 59, loss: 0.914741
global_step: 6357, epoch: 59, loss: 0.925757
global_step: 6358, epoch: 59, loss: 0.935119
global_step: 6359, epoch: 59, loss: 0.930256
global_step: 6360, epoch: 59, loss: 0.269117
epoch: 59
train	acc: 0.7600	macro: p 0.5309, r 0.4876, f1: 0.4969	micro: p 0.7600, r 0.7600, f1 0.7600	weighted_f1:0.7297
dev	acc: 0.5383	macro: p 0.3367, r 0.2951, f1: 0.2828	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4799
test	acc: 0.5912	macro: p 0.3640, r 0.3090, f1: 0.3080	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5433
global_step: 6361, epoch: 60, loss: 0.868160
global_step: 6362, epoch: 60, loss: 0.920905
global_step: 6363, epoch: 60, loss: 0.991601
global_step: 6364, epoch: 60, loss: 0.906850
global_step: 6365, epoch: 60, loss: 0.919114
global_step: 6366, epoch: 60, loss: 0.996404
global_step: 6367, epoch: 60, loss: 0.895786
global_step: 6368, epoch: 60, loss: 0.931009
global_step: 6369, epoch: 60, loss: 0.900381
global_step: 6370, epoch: 60, loss: 0.952557
global_step: 6371, epoch: 60, loss: 0.762421
global_step: 6372, epoch: 60, loss: 0.874154
global_step: 6373, epoch: 60, loss: 0.885890
global_step: 6374, epoch: 60, loss: 0.918616
global_step: 6375, epoch: 60, loss: 0.892627
global_step: 6376, epoch: 60, loss: 0.859030
global_step: 6377, epoch: 60, loss: 0.786896
global_step: 6378, epoch: 60, loss: 0.893396
global_step: 6379, epoch: 60, loss: 0.971840
global_step: 6380, epoch: 60, loss: 0.958225
global_step: 6381, epoch: 60, loss: 1.013325
global_step: 6382, epoch: 60, loss: 0.993383
global_step: 6383, epoch: 60, loss: 0.904508
global_step: 6384, epoch: 60, loss: 0.887931
global_step: 6385, epoch: 60, loss: 0.987645
global_step: 6386, epoch: 60, loss: 0.843565
global_step: 6387, epoch: 60, loss: 0.872926
global_step: 6388, epoch: 60, loss: 0.861328
global_step: 6389, epoch: 60, loss: 0.849545
global_step: 6390, epoch: 60, loss: 0.824090
global_step: 6391, epoch: 60, loss: 0.920488
global_step: 6392, epoch: 60, loss: 0.955915
global_step: 6393, epoch: 60, loss: 0.895567
global_step: 6394, epoch: 60, loss: 0.947061
global_step: 6395, epoch: 60, loss: 0.880853
global_step: 6396, epoch: 60, loss: 0.845670
global_step: 6397, epoch: 60, loss: 0.941059
global_step: 6398, epoch: 60, loss: 0.952586
global_step: 6399, epoch: 60, loss: 0.914966
global_step: 6400, epoch: 60, loss: 0.589406
epoch: 60
train	acc: 0.7768	macro: p 0.5347, r 0.5120, f1: 0.5148	micro: p 0.7768, r 0.7768, f1 0.7768	weighted_f1:0.7483
dev	acc: 0.5455	macro: p 0.3370, r 0.3059, f1: 0.2929	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4903
test	acc: 0.5916	macro: p 0.3569, r 0.3162, f1: 0.3128	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5473
global_step: 6401, epoch: 61, loss: 0.873141
global_step: 6402, epoch: 61, loss: 0.868501
global_step: 6403, epoch: 61, loss: 0.876424
global_step: 6404, epoch: 61, loss: 0.974154
global_step: 6405, epoch: 61, loss: 0.962599
global_step: 6406, epoch: 61, loss: 0.824960
global_step: 6407, epoch: 61, loss: 0.825817
global_step: 6408, epoch: 61, loss: 0.837411
global_step: 6409, epoch: 61, loss: 0.852685
global_step: 6410, epoch: 61, loss: 0.870913
global_step: 6411, epoch: 61, loss: 0.856122
global_step: 6412, epoch: 61, loss: 0.898936
global_step: 6413, epoch: 61, loss: 0.817602
global_step: 6414, epoch: 61, loss: 0.949114
global_step: 6415, epoch: 61, loss: 0.933175
global_step: 6416, epoch: 61, loss: 0.823569
global_step: 6417, epoch: 61, loss: 0.881727
global_step: 6418, epoch: 61, loss: 0.918198
global_step: 6419, epoch: 61, loss: 1.000619
global_step: 6420, epoch: 61, loss: 0.947053
global_step: 6421, epoch: 61, loss: 0.924012
global_step: 6422, epoch: 61, loss: 0.920968
global_step: 6423, epoch: 61, loss: 0.882258
global_step: 6424, epoch: 61, loss: 0.975696
global_step: 6425, epoch: 61, loss: 0.915586
global_step: 6426, epoch: 61, loss: 0.980097
global_step: 6427, epoch: 61, loss: 0.852379
global_step: 6428, epoch: 61, loss: 0.846170
global_step: 6429, epoch: 61, loss: 1.023685
global_step: 6430, epoch: 61, loss: 0.945778
global_step: 6431, epoch: 61, loss: 1.124137
global_step: 6432, epoch: 61, loss: 0.875917
global_step: 6433, epoch: 61, loss: 0.983172
global_step: 6434, epoch: 61, loss: 0.878778
global_step: 6435, epoch: 61, loss: 0.967209
global_step: 6436, epoch: 61, loss: 0.836843
global_step: 6437, epoch: 61, loss: 0.939863
global_step: 6438, epoch: 61, loss: 0.796223
global_step: 6439, epoch: 61, loss: 0.917868
global_step: 6440, epoch: 61, loss: 1.042652
epoch: 61
train	acc: 0.7765	macro: p 0.6816, r 0.5127, f1: 0.5205	micro: p 0.7765, r 0.7765, f1 0.7765	weighted_f1:0.7490
dev	acc: 0.5500	macro: p 0.3463, r 0.3089, f1: 0.3038	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4981
test	acc: 0.5946	macro: p 0.3609, r 0.3126, f1: 0.3148	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5499
global_step: 6441, epoch: 62, loss: 0.863332
global_step: 6442, epoch: 62, loss: 0.843199
global_step: 6443, epoch: 62, loss: 0.870775
global_step: 6444, epoch: 62, loss: 0.844795
global_step: 6445, epoch: 62, loss: 0.937689
global_step: 6446, epoch: 62, loss: 0.878619
global_step: 6447, epoch: 62, loss: 0.910654
global_step: 6448, epoch: 62, loss: 0.909976
global_step: 6449, epoch: 62, loss: 0.821911
global_step: 6450, epoch: 62, loss: 0.842841
global_step: 6451, epoch: 62, loss: 0.994859
global_step: 6452, epoch: 62, loss: 1.023254
global_step: 6453, epoch: 62, loss: 0.838373
global_step: 6454, epoch: 62, loss: 0.842151
global_step: 6455, epoch: 62, loss: 0.906317
global_step: 6456, epoch: 62, loss: 0.898351
global_step: 6457, epoch: 62, loss: 1.015489
global_step: 6458, epoch: 62, loss: 0.908126
global_step: 6459, epoch: 62, loss: 0.866274
global_step: 6460, epoch: 62, loss: 0.847651
global_step: 6461, epoch: 62, loss: 0.870390
global_step: 6462, epoch: 62, loss: 0.834458
global_step: 6463, epoch: 62, loss: 0.961660
global_step: 6464, epoch: 62, loss: 0.867536
global_step: 6465, epoch: 62, loss: 0.933649
global_step: 6466, epoch: 62, loss: 0.788238
global_step: 6467, epoch: 62, loss: 1.038410
global_step: 6468, epoch: 62, loss: 0.938836
global_step: 6469, epoch: 62, loss: 0.985797
global_step: 6470, epoch: 62, loss: 0.895978
global_step: 6471, epoch: 62, loss: 0.954898
global_step: 6472, epoch: 62, loss: 0.790631
global_step: 6473, epoch: 62, loss: 0.977027
global_step: 6474, epoch: 62, loss: 0.825727
global_step: 6475, epoch: 62, loss: 0.943649
global_step: 6476, epoch: 62, loss: 0.905595
global_step: 6477, epoch: 62, loss: 0.833913
global_step: 6478, epoch: 62, loss: 0.904892
global_step: 6479, epoch: 62, loss: 0.928603
global_step: 6480, epoch: 62, loss: 1.046818
epoch: 62
train	acc: 0.7889	macro: p 0.6822, r 0.5327, f1: 0.5333	micro: p 0.7889, r 0.7889, f1 0.7889	weighted_f1:0.7634
dev	acc: 0.5528	macro: p 0.3466, r 0.3171, f1: 0.3110	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5059
test	acc: 0.5939	macro: p 0.3502, r 0.3178, f1: 0.3174	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5529
New best model!
global_step: 6481, epoch: 63, loss: 0.803021
global_step: 6482, epoch: 63, loss: 0.880831
global_step: 6483, epoch: 63, loss: 0.863767
global_step: 6484, epoch: 63, loss: 0.919855
global_step: 6485, epoch: 63, loss: 0.853723
global_step: 6486, epoch: 63, loss: 0.952801
global_step: 6487, epoch: 63, loss: 1.020078
global_step: 6488, epoch: 63, loss: 0.861368
global_step: 6489, epoch: 63, loss: 0.849263
global_step: 6490, epoch: 63, loss: 0.826509
global_step: 6491, epoch: 63, loss: 0.852483
global_step: 6492, epoch: 63, loss: 0.812489
global_step: 6493, epoch: 63, loss: 0.888689
global_step: 6494, epoch: 63, loss: 0.910901
global_step: 6495, epoch: 63, loss: 0.863610
global_step: 6496, epoch: 63, loss: 0.883541
global_step: 6497, epoch: 63, loss: 0.827431
global_step: 6498, epoch: 63, loss: 0.885336
global_step: 6499, epoch: 63, loss: 0.839221
global_step: 6500, epoch: 63, loss: 0.842612
global_step: 6501, epoch: 63, loss: 0.911046
global_step: 6502, epoch: 63, loss: 0.724428
global_step: 6503, epoch: 63, loss: 0.919590
global_step: 6504, epoch: 63, loss: 0.900271
global_step: 6505, epoch: 63, loss: 0.857249
global_step: 6506, epoch: 63, loss: 0.905047
global_step: 6507, epoch: 63, loss: 0.981029
global_step: 6508, epoch: 63, loss: 0.869696
global_step: 6509, epoch: 63, loss: 0.888800
global_step: 6510, epoch: 63, loss: 1.016461
global_step: 6511, epoch: 63, loss: 0.916708
global_step: 6512, epoch: 63, loss: 0.812659
global_step: 6513, epoch: 63, loss: 0.888540
global_step: 6514, epoch: 63, loss: 0.962394
global_step: 6515, epoch: 63, loss: 0.870292
global_step: 6516, epoch: 63, loss: 0.952166
global_step: 6517, epoch: 63, loss: 0.904997
global_step: 6518, epoch: 63, loss: 0.906496
global_step: 6519, epoch: 63, loss: 0.949777
global_step: 6520, epoch: 63, loss: 0.870858
epoch: 63
train	acc: 0.7944	macro: p 0.6805, r 0.5426, f1: 0.5419	micro: p 0.7944, r 0.7944, f1 0.7944	weighted_f1:0.7700
dev	acc: 0.5491	macro: p 0.3449, r 0.3162, f1: 0.3113	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.5047
test	acc: 0.5916	macro: p 0.3501, r 0.3206, f1: 0.3215	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5531
global_step: 6521, epoch: 64, loss: 0.969092
global_step: 6522, epoch: 64, loss: 0.837089
global_step: 6523, epoch: 64, loss: 0.974680
global_step: 6524, epoch: 64, loss: 0.823207
global_step: 6525, epoch: 64, loss: 0.849304
global_step: 6526, epoch: 64, loss: 0.900860
global_step: 6527, epoch: 64, loss: 0.904935
global_step: 6528, epoch: 64, loss: 0.850734
global_step: 6529, epoch: 64, loss: 0.742339
global_step: 6530, epoch: 64, loss: 0.822649
global_step: 6531, epoch: 64, loss: 0.933984
global_step: 6532, epoch: 64, loss: 0.876899
global_step: 6533, epoch: 64, loss: 0.810528
global_step: 6534, epoch: 64, loss: 0.781225
global_step: 6535, epoch: 64, loss: 0.842974
global_step: 6536, epoch: 64, loss: 0.921011
global_step: 6537, epoch: 64, loss: 0.931177
global_step: 6538, epoch: 64, loss: 0.884550
global_step: 6539, epoch: 64, loss: 0.829670
global_step: 6540, epoch: 64, loss: 0.908173
global_step: 6541, epoch: 64, loss: 0.884511
global_step: 6542, epoch: 64, loss: 0.862866
global_step: 6543, epoch: 64, loss: 0.909413
global_step: 6544, epoch: 64, loss: 0.852763
global_step: 6545, epoch: 64, loss: 0.896620
global_step: 6546, epoch: 64, loss: 1.030164
global_step: 6547, epoch: 64, loss: 0.926157
global_step: 6548, epoch: 64, loss: 0.968606
global_step: 6549, epoch: 64, loss: 0.827473
global_step: 6550, epoch: 64, loss: 0.859938
global_step: 6551, epoch: 64, loss: 0.865874
global_step: 6552, epoch: 64, loss: 0.869235
global_step: 6553, epoch: 64, loss: 0.839568
global_step: 6554, epoch: 64, loss: 0.946089
global_step: 6555, epoch: 64, loss: 0.784844
global_step: 6556, epoch: 64, loss: 0.918887
global_step: 6557, epoch: 64, loss: 0.937147
global_step: 6558, epoch: 64, loss: 0.842998
global_step: 6559, epoch: 64, loss: 0.986438
global_step: 6560, epoch: 64, loss: 0.363475
epoch: 64
train	acc: 0.7895	macro: p 0.6896, r 0.5284, f1: 0.5358	micro: p 0.7895, r 0.7895, f1 0.7895	weighted_f1:0.7629
dev	acc: 0.5482	macro: p 0.3501, r 0.3063, f1: 0.2982	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4944
test	acc: 0.5977	macro: p 0.3683, r 0.3168, f1: 0.3181	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5532
global_step: 6561, epoch: 65, loss: 0.900479
global_step: 6562, epoch: 65, loss: 0.899678
global_step: 6563, epoch: 65, loss: 0.915595
global_step: 6564, epoch: 65, loss: 0.898640
global_step: 6565, epoch: 65, loss: 0.768612
global_step: 6566, epoch: 65, loss: 0.946116
global_step: 6567, epoch: 65, loss: 0.803521
global_step: 6568, epoch: 65, loss: 0.887869
global_step: 6569, epoch: 65, loss: 0.808152
global_step: 6570, epoch: 65, loss: 0.962276
global_step: 6571, epoch: 65, loss: 0.948497
global_step: 6572, epoch: 65, loss: 0.934099
global_step: 6573, epoch: 65, loss: 0.824537
global_step: 6574, epoch: 65, loss: 0.874098
global_step: 6575, epoch: 65, loss: 0.968310
global_step: 6576, epoch: 65, loss: 0.924062
global_step: 6577, epoch: 65, loss: 0.924137
global_step: 6578, epoch: 65, loss: 0.879745
global_step: 6579, epoch: 65, loss: 0.947026
global_step: 6580, epoch: 65, loss: 0.891387
global_step: 6581, epoch: 65, loss: 0.907499
global_step: 6582, epoch: 65, loss: 0.924543
global_step: 6583, epoch: 65, loss: 0.940662
global_step: 6584, epoch: 65, loss: 0.785760
global_step: 6585, epoch: 65, loss: 0.855307
global_step: 6586, epoch: 65, loss: 0.896395
global_step: 6587, epoch: 65, loss: 0.778853
global_step: 6588, epoch: 65, loss: 0.835705
global_step: 6589, epoch: 65, loss: 0.830495
global_step: 6590, epoch: 65, loss: 0.763317
global_step: 6591, epoch: 65, loss: 0.775393
global_step: 6592, epoch: 65, loss: 0.924928
global_step: 6593, epoch: 65, loss: 0.914082
global_step: 6594, epoch: 65, loss: 0.821482
global_step: 6595, epoch: 65, loss: 0.898921
global_step: 6596, epoch: 65, loss: 0.826537
global_step: 6597, epoch: 65, loss: 0.936211
global_step: 6598, epoch: 65, loss: 0.844882
global_step: 6599, epoch: 65, loss: 0.851006
global_step: 6600, epoch: 65, loss: 0.636986
epoch: 65
train	acc: 0.7886	macro: p 0.8347, r 0.5300, f1: 0.5410	micro: p 0.7886, r 0.7886, f1 0.7886	weighted_f1:0.7621
dev	acc: 0.5473	macro: p 0.3465, r 0.3048, f1: 0.2991	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4934
test	acc: 0.5985	macro: p 0.3613, r 0.3157, f1: 0.3170	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5526
global_step: 6601, epoch: 66, loss: 0.888497
global_step: 6602, epoch: 66, loss: 0.890734
global_step: 6603, epoch: 66, loss: 0.893405
global_step: 6604, epoch: 66, loss: 0.784852
global_step: 6605, epoch: 66, loss: 0.961035
global_step: 6606, epoch: 66, loss: 0.825496
global_step: 6607, epoch: 66, loss: 0.837844
global_step: 6608, epoch: 66, loss: 0.906123
global_step: 6609, epoch: 66, loss: 0.882391
global_step: 6610, epoch: 66, loss: 0.770444
global_step: 6611, epoch: 66, loss: 0.848936
global_step: 6612, epoch: 66, loss: 0.872850
global_step: 6613, epoch: 66, loss: 0.817525
global_step: 6614, epoch: 66, loss: 0.862253
global_step: 6615, epoch: 66, loss: 0.885560
global_step: 6616, epoch: 66, loss: 0.897104
global_step: 6617, epoch: 66, loss: 0.925315
global_step: 6618, epoch: 66, loss: 0.779426
global_step: 6619, epoch: 66, loss: 0.906157
global_step: 6620, epoch: 66, loss: 0.828806
global_step: 6621, epoch: 66, loss: 0.977863
global_step: 6622, epoch: 66, loss: 0.841152
global_step: 6623, epoch: 66, loss: 0.809840
global_step: 6624, epoch: 66, loss: 0.912704
global_step: 6625, epoch: 66, loss: 0.866156
global_step: 6626, epoch: 66, loss: 0.977028
global_step: 6627, epoch: 66, loss: 0.870143
global_step: 6628, epoch: 66, loss: 0.907772
global_step: 6629, epoch: 66, loss: 0.894683
global_step: 6630, epoch: 66, loss: 0.812753
global_step: 6631, epoch: 66, loss: 0.784868
global_step: 6632, epoch: 66, loss: 0.894268
global_step: 6633, epoch: 66, loss: 0.859144
global_step: 6634, epoch: 66, loss: 0.805638
global_step: 6635, epoch: 66, loss: 0.836228
global_step: 6636, epoch: 66, loss: 0.828068
global_step: 6637, epoch: 66, loss: 0.936350
global_step: 6638, epoch: 66, loss: 0.882956
global_step: 6639, epoch: 66, loss: 0.873847
global_step: 6640, epoch: 66, loss: 0.462492
epoch: 66
train	acc: 0.7953	macro: p 0.6950, r 0.5370, f1: 0.5444	micro: p 0.7953, r 0.7953, f1 0.7953	weighted_f1:0.7691
dev	acc: 0.5500	macro: p 0.3428, r 0.3076, f1: 0.3017	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4967
test	acc: 0.5996	macro: p 0.3625, r 0.3165, f1: 0.3189	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5545
global_step: 6641, epoch: 67, loss: 0.799167
global_step: 6642, epoch: 67, loss: 0.846018
global_step: 6643, epoch: 67, loss: 0.840194
global_step: 6644, epoch: 67, loss: 0.882277
global_step: 6645, epoch: 67, loss: 0.834720
global_step: 6646, epoch: 67, loss: 0.818985
global_step: 6647, epoch: 67, loss: 0.762392
global_step: 6648, epoch: 67, loss: 0.849933
global_step: 6649, epoch: 67, loss: 0.837061
global_step: 6650, epoch: 67, loss: 0.801286
global_step: 6651, epoch: 67, loss: 0.857216
global_step: 6652, epoch: 67, loss: 0.874026
global_step: 6653, epoch: 67, loss: 0.886557
global_step: 6654, epoch: 67, loss: 0.868319
global_step: 6655, epoch: 67, loss: 0.858572
global_step: 6656, epoch: 67, loss: 0.917082
global_step: 6657, epoch: 67, loss: 1.048931
global_step: 6658, epoch: 67, loss: 0.914747
global_step: 6659, epoch: 67, loss: 0.868944
global_step: 6660, epoch: 67, loss: 0.855183
global_step: 6661, epoch: 67, loss: 0.865158
global_step: 6662, epoch: 67, loss: 0.844627
global_step: 6663, epoch: 67, loss: 0.808450
global_step: 6664, epoch: 67, loss: 0.843711
global_step: 6665, epoch: 67, loss: 0.846039
global_step: 6666, epoch: 67, loss: 0.875572
global_step: 6667, epoch: 67, loss: 0.866653
global_step: 6668, epoch: 67, loss: 0.883176
global_step: 6669, epoch: 67, loss: 0.842068
global_step: 6670, epoch: 67, loss: 0.832158
global_step: 6671, epoch: 67, loss: 0.943969
global_step: 6672, epoch: 67, loss: 0.926202
global_step: 6673, epoch: 67, loss: 0.794423
global_step: 6674, epoch: 67, loss: 0.830070
global_step: 6675, epoch: 67, loss: 0.852980
global_step: 6676, epoch: 67, loss: 0.938460
global_step: 6677, epoch: 67, loss: 0.877645
global_step: 6678, epoch: 67, loss: 0.741543
global_step: 6679, epoch: 67, loss: 0.905326
global_step: 6680, epoch: 67, loss: 0.245814
epoch: 67
train	acc: 0.7973	macro: p 0.8410, r 0.5387, f1: 0.5478	micro: p 0.7973, r 0.7973, f1 0.7973	weighted_f1:0.7710
dev	acc: 0.5446	macro: p 0.3370, r 0.3039, f1: 0.2981	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4913
test	acc: 0.5977	macro: p 0.3590, r 0.3139, f1: 0.3167	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5518
global_step: 6681, epoch: 68, loss: 0.863714
global_step: 6682, epoch: 68, loss: 0.860920
global_step: 6683, epoch: 68, loss: 0.913371
global_step: 6684, epoch: 68, loss: 0.837105
global_step: 6685, epoch: 68, loss: 0.885240
global_step: 6686, epoch: 68, loss: 0.917877
global_step: 6687, epoch: 68, loss: 0.899388
global_step: 6688, epoch: 68, loss: 0.821213
global_step: 6689, epoch: 68, loss: 0.847438
global_step: 6690, epoch: 68, loss: 0.816602
global_step: 6691, epoch: 68, loss: 0.843211
global_step: 6692, epoch: 68, loss: 0.937559
global_step: 6693, epoch: 68, loss: 0.915716
global_step: 6694, epoch: 68, loss: 0.840808
global_step: 6695, epoch: 68, loss: 0.807979
global_step: 6696, epoch: 68, loss: 0.758786
global_step: 6697, epoch: 68, loss: 0.850766
global_step: 6698, epoch: 68, loss: 0.773447
global_step: 6699, epoch: 68, loss: 0.849223
global_step: 6700, epoch: 68, loss: 0.873512
global_step: 6701, epoch: 68, loss: 0.850432
global_step: 6702, epoch: 68, loss: 0.861723
global_step: 6703, epoch: 68, loss: 0.867473
global_step: 6704, epoch: 68, loss: 0.839260
global_step: 6705, epoch: 68, loss: 0.869198
global_step: 6706, epoch: 68, loss: 0.780390
global_step: 6707, epoch: 68, loss: 0.813582
global_step: 6708, epoch: 68, loss: 0.891927
global_step: 6709, epoch: 68, loss: 0.918984
global_step: 6710, epoch: 68, loss: 0.754533
global_step: 6711, epoch: 68, loss: 0.861245
global_step: 6712, epoch: 68, loss: 0.857506
global_step: 6713, epoch: 68, loss: 0.843398
global_step: 6714, epoch: 68, loss: 0.878257
global_step: 6715, epoch: 68, loss: 0.897344
global_step: 6716, epoch: 68, loss: 0.749175
global_step: 6717, epoch: 68, loss: 0.859289
global_step: 6718, epoch: 68, loss: 0.886132
global_step: 6719, epoch: 68, loss: 0.804129
global_step: 6720, epoch: 68, loss: 0.463223
epoch: 68
train	acc: 0.7997	macro: p 0.8439, r 0.5391, f1: 0.5480	micro: p 0.7997, r 0.7997, f1 0.7997	weighted_f1:0.7731
dev	acc: 0.5455	macro: p 0.3576, r 0.3045, f1: 0.2994	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4922
test	acc: 0.5973	macro: p 0.3655, r 0.3141, f1: 0.3157	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5507
global_step: 6721, epoch: 69, loss: 0.744650
global_step: 6722, epoch: 69, loss: 0.827244
global_step: 6723, epoch: 69, loss: 0.760432
global_step: 6724, epoch: 69, loss: 0.774531
global_step: 6725, epoch: 69, loss: 0.899118
global_step: 6726, epoch: 69, loss: 0.779877
global_step: 6727, epoch: 69, loss: 0.776305
global_step: 6728, epoch: 69, loss: 0.738319
global_step: 6729, epoch: 69, loss: 0.888613
global_step: 6730, epoch: 69, loss: 0.830502
global_step: 6731, epoch: 69, loss: 0.921770
global_step: 6732, epoch: 69, loss: 0.798358
global_step: 6733, epoch: 69, loss: 0.785449
global_step: 6734, epoch: 69, loss: 0.757836
global_step: 6735, epoch: 69, loss: 0.778701
global_step: 6736, epoch: 69, loss: 0.840718
global_step: 6737, epoch: 69, loss: 0.864339
global_step: 6738, epoch: 69, loss: 0.747907
global_step: 6739, epoch: 69, loss: 0.779678
global_step: 6740, epoch: 69, loss: 0.755202
global_step: 6741, epoch: 69, loss: 0.822329
global_step: 6742, epoch: 69, loss: 0.861764
global_step: 6743, epoch: 69, loss: 0.923937
global_step: 6744, epoch: 69, loss: 0.906898
global_step: 6745, epoch: 69, loss: 0.792408
global_step: 6746, epoch: 69, loss: 0.867922
global_step: 6747, epoch: 69, loss: 0.846581
global_step: 6748, epoch: 69, loss: 0.906437
global_step: 6749, epoch: 69, loss: 0.798011
global_step: 6750, epoch: 69, loss: 0.833018
global_step: 6751, epoch: 69, loss: 0.885671
global_step: 6752, epoch: 69, loss: 0.795590
global_step: 6753, epoch: 69, loss: 0.760912
global_step: 6754, epoch: 69, loss: 0.822587
global_step: 6755, epoch: 69, loss: 0.930286
global_step: 6756, epoch: 69, loss: 0.863732
global_step: 6757, epoch: 69, loss: 0.876013
global_step: 6758, epoch: 69, loss: 0.834224
global_step: 6759, epoch: 69, loss: 0.802999
global_step: 6760, epoch: 69, loss: 0.427831
epoch: 69
train	acc: 0.8048	macro: p 0.8435, r 0.5476, f1: 0.5565	micro: p 0.8048, r 0.8048, f1 0.8048	weighted_f1:0.7797
dev	acc: 0.5383	macro: p 0.3405, r 0.2980, f1: 0.2856	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4822
test	acc: 0.5897	macro: p 0.3631, r 0.3107, f1: 0.3101	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5436
global_step: 6761, epoch: 70, loss: 0.824207
global_step: 6762, epoch: 70, loss: 0.803641
global_step: 6763, epoch: 70, loss: 0.747425
global_step: 6764, epoch: 70, loss: 0.746678
global_step: 6765, epoch: 70, loss: 0.768367
global_step: 6766, epoch: 70, loss: 0.840588
global_step: 6767, epoch: 70, loss: 0.830280
global_step: 6768, epoch: 70, loss: 0.782852
global_step: 6769, epoch: 70, loss: 0.766788
global_step: 6770, epoch: 70, loss: 0.788055
global_step: 6771, epoch: 70, loss: 0.911868
global_step: 6772, epoch: 70, loss: 0.879630
global_step: 6773, epoch: 70, loss: 0.776196
global_step: 6774, epoch: 70, loss: 0.886359
global_step: 6775, epoch: 70, loss: 0.868699
global_step: 6776, epoch: 70, loss: 0.829167
global_step: 6777, epoch: 70, loss: 0.912552
global_step: 6778, epoch: 70, loss: 0.901584
global_step: 6779, epoch: 70, loss: 0.837573
global_step: 6780, epoch: 70, loss: 0.739004
global_step: 6781, epoch: 70, loss: 0.865118
global_step: 6782, epoch: 70, loss: 0.866122
global_step: 6783, epoch: 70, loss: 0.956487
global_step: 6784, epoch: 70, loss: 0.795172
global_step: 6785, epoch: 70, loss: 0.821535
global_step: 6786, epoch: 70, loss: 0.785557
global_step: 6787, epoch: 70, loss: 0.851945
global_step: 6788, epoch: 70, loss: 0.860992
global_step: 6789, epoch: 70, loss: 0.857656
global_step: 6790, epoch: 70, loss: 0.841955
global_step: 6791, epoch: 70, loss: 0.747389
global_step: 6792, epoch: 70, loss: 0.773468
global_step: 6793, epoch: 70, loss: 0.848288
global_step: 6794, epoch: 70, loss: 0.820012
global_step: 6795, epoch: 70, loss: 0.774690
global_step: 6796, epoch: 70, loss: 0.828298
global_step: 6797, epoch: 70, loss: 0.830087
global_step: 6798, epoch: 70, loss: 0.809013
global_step: 6799, epoch: 70, loss: 0.822555
global_step: 6800, epoch: 70, loss: 0.441390
epoch: 70
train	acc: 0.8045	macro: p 0.8505, r 0.5463, f1: 0.5600	micro: p 0.8045, r 0.8045, f1 0.8045	weighted_f1:0.7788
dev	acc: 0.5455	macro: p 0.3528, r 0.3013, f1: 0.2966	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4905
test	acc: 0.5985	macro: p 0.3677, r 0.3111, f1: 0.3146	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5492
global_step: 6801, epoch: 71, loss: 0.809005
global_step: 6802, epoch: 71, loss: 0.822123
global_step: 6803, epoch: 71, loss: 0.836374
global_step: 6804, epoch: 71, loss: 0.704413
global_step: 6805, epoch: 71, loss: 0.807907
global_step: 6806, epoch: 71, loss: 0.736319
global_step: 6807, epoch: 71, loss: 0.755924
global_step: 6808, epoch: 71, loss: 0.860390
global_step: 6809, epoch: 71, loss: 0.946577
global_step: 6810, epoch: 71, loss: 0.809470
global_step: 6811, epoch: 71, loss: 0.759554
global_step: 6812, epoch: 71, loss: 0.719783
global_step: 6813, epoch: 71, loss: 0.818038
global_step: 6814, epoch: 71, loss: 0.859558
global_step: 6815, epoch: 71, loss: 0.888680
global_step: 6816, epoch: 71, loss: 0.814611
global_step: 6817, epoch: 71, loss: 0.863331
global_step: 6818, epoch: 71, loss: 0.747877
global_step: 6819, epoch: 71, loss: 0.715299
global_step: 6820, epoch: 71, loss: 0.787300
global_step: 6821, epoch: 71, loss: 0.742218
global_step: 6822, epoch: 71, loss: 0.638077
global_step: 6823, epoch: 71, loss: 0.937018
global_step: 6824, epoch: 71, loss: 0.994836
global_step: 6825, epoch: 71, loss: 0.782895
global_step: 6826, epoch: 71, loss: 0.839078
global_step: 6827, epoch: 71, loss: 0.806456
global_step: 6828, epoch: 71, loss: 0.849757
global_step: 6829, epoch: 71, loss: 0.759269
global_step: 6830, epoch: 71, loss: 0.865693
global_step: 6831, epoch: 71, loss: 0.832082
global_step: 6832, epoch: 71, loss: 0.715119
global_step: 6833, epoch: 71, loss: 0.841826
global_step: 6834, epoch: 71, loss: 0.747169
global_step: 6835, epoch: 71, loss: 0.829120
global_step: 6836, epoch: 71, loss: 0.835405
global_step: 6837, epoch: 71, loss: 0.883055
global_step: 6838, epoch: 71, loss: 0.836199
global_step: 6839, epoch: 71, loss: 0.857627
global_step: 6840, epoch: 71, loss: 1.835062
epoch: 71
train	acc: 0.8163	macro: p 0.8454, r 0.5699, f1: 0.5786	micro: p 0.8163, r 0.8163, f1 0.8163	weighted_f1:0.7938
dev	acc: 0.5410	macro: p 0.3382, r 0.3031, f1: 0.2974	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4912
test	acc: 0.5931	macro: p 0.3533, r 0.3142, f1: 0.3169	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5502
global_step: 6841, epoch: 72, loss: 0.791594
global_step: 6842, epoch: 72, loss: 0.750388
global_step: 6843, epoch: 72, loss: 0.772108
global_step: 6844, epoch: 72, loss: 0.796954
global_step: 6845, epoch: 72, loss: 0.850570
global_step: 6846, epoch: 72, loss: 0.849521
global_step: 6847, epoch: 72, loss: 0.860576
global_step: 6848, epoch: 72, loss: 0.799512
global_step: 6849, epoch: 72, loss: 0.855931
global_step: 6850, epoch: 72, loss: 0.850248
global_step: 6851, epoch: 72, loss: 0.794722
global_step: 6852, epoch: 72, loss: 0.823834
global_step: 6853, epoch: 72, loss: 0.777182
global_step: 6854, epoch: 72, loss: 0.862913
global_step: 6855, epoch: 72, loss: 0.825448
global_step: 6856, epoch: 72, loss: 0.771540
global_step: 6857, epoch: 72, loss: 0.836505
global_step: 6858, epoch: 72, loss: 0.867155
global_step: 6859, epoch: 72, loss: 0.835990
global_step: 6860, epoch: 72, loss: 0.813591
global_step: 6861, epoch: 72, loss: 0.752026
global_step: 6862, epoch: 72, loss: 0.827909
global_step: 6863, epoch: 72, loss: 0.823783
global_step: 6864, epoch: 72, loss: 0.807189
global_step: 6865, epoch: 72, loss: 0.848334
global_step: 6866, epoch: 72, loss: 0.808455
global_step: 6867, epoch: 72, loss: 0.743345
global_step: 6868, epoch: 72, loss: 0.835586
global_step: 6869, epoch: 72, loss: 0.874268
global_step: 6870, epoch: 72, loss: 0.765900
global_step: 6871, epoch: 72, loss: 0.782342
global_step: 6872, epoch: 72, loss: 0.885444
global_step: 6873, epoch: 72, loss: 0.901120
global_step: 6874, epoch: 72, loss: 0.934079
global_step: 6875, epoch: 72, loss: 0.894252
global_step: 6876, epoch: 72, loss: 0.785984
global_step: 6877, epoch: 72, loss: 0.755346
global_step: 6878, epoch: 72, loss: 0.815089
global_step: 6879, epoch: 72, loss: 0.686290
global_step: 6880, epoch: 72, loss: 1.759219
epoch: 72
train	acc: 0.8136	macro: p 0.8537, r 0.5609, f1: 0.5768	micro: p 0.8136, r 0.8136, f1 0.8136	weighted_f1:0.7894
dev	acc: 0.5428	macro: p 0.3485, r 0.2994, f1: 0.2916	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4867
test	acc: 0.5950	macro: p 0.3665, r 0.3117, f1: 0.3131	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5469
global_step: 6881, epoch: 73, loss: 0.753150
global_step: 6882, epoch: 73, loss: 0.722301
global_step: 6883, epoch: 73, loss: 0.741354
global_step: 6884, epoch: 73, loss: 0.805375
global_step: 6885, epoch: 73, loss: 0.755717
global_step: 6886, epoch: 73, loss: 0.751579
global_step: 6887, epoch: 73, loss: 0.860235
global_step: 6888, epoch: 73, loss: 0.833676
global_step: 6889, epoch: 73, loss: 0.928019
global_step: 6890, epoch: 73, loss: 0.903124
global_step: 6891, epoch: 73, loss: 0.764231
global_step: 6892, epoch: 73, loss: 0.760162
global_step: 6893, epoch: 73, loss: 0.853895
global_step: 6894, epoch: 73, loss: 0.822815
global_step: 6895, epoch: 73, loss: 0.727383
global_step: 6896, epoch: 73, loss: 0.786047
global_step: 6897, epoch: 73, loss: 0.802766
global_step: 6898, epoch: 73, loss: 0.871759
global_step: 6899, epoch: 73, loss: 0.783531
global_step: 6900, epoch: 73, loss: 0.827022
global_step: 6901, epoch: 73, loss: 0.783848
global_step: 6902, epoch: 73, loss: 0.823475
global_step: 6903, epoch: 73, loss: 0.848884
global_step: 6904, epoch: 73, loss: 0.739532
global_step: 6905, epoch: 73, loss: 0.893712
global_step: 6906, epoch: 73, loss: 0.727473
global_step: 6907, epoch: 73, loss: 0.784833
global_step: 6908, epoch: 73, loss: 0.762168
global_step: 6909, epoch: 73, loss: 0.703865
global_step: 6910, epoch: 73, loss: 0.728356
global_step: 6911, epoch: 73, loss: 0.858151
global_step: 6912, epoch: 73, loss: 0.801763
global_step: 6913, epoch: 73, loss: 0.824308
global_step: 6914, epoch: 73, loss: 0.915778
global_step: 6915, epoch: 73, loss: 0.816188
global_step: 6916, epoch: 73, loss: 0.813041
global_step: 6917, epoch: 73, loss: 0.810925
global_step: 6918, epoch: 73, loss: 0.795841
global_step: 6919, epoch: 73, loss: 0.780806
global_step: 6920, epoch: 73, loss: 0.254804
epoch: 73
train	acc: 0.8191	macro: p 0.8497, r 0.5703, f1: 0.5848	micro: p 0.8191, r 0.8191, f1 0.8191	weighted_f1:0.7957
dev	acc: 0.5419	macro: p 0.3376, r 0.3010, f1: 0.2929	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4877
test	acc: 0.5958	macro: p 0.3650, r 0.3134, f1: 0.3143	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5485
global_step: 6921, epoch: 74, loss: 0.775882
global_step: 6922, epoch: 74, loss: 0.755694
global_step: 6923, epoch: 74, loss: 0.878428
global_step: 6924, epoch: 74, loss: 0.799446
global_step: 6925, epoch: 74, loss: 0.832462
global_step: 6926, epoch: 74, loss: 0.821748
global_step: 6927, epoch: 74, loss: 0.797292
global_step: 6928, epoch: 74, loss: 0.749955
global_step: 6929, epoch: 74, loss: 0.741323
global_step: 6930, epoch: 74, loss: 0.868016
global_step: 6931, epoch: 74, loss: 0.707325
global_step: 6932, epoch: 74, loss: 0.744211
global_step: 6933, epoch: 74, loss: 0.722247
global_step: 6934, epoch: 74, loss: 0.809327
global_step: 6935, epoch: 74, loss: 0.809708
global_step: 6936, epoch: 74, loss: 0.797607
global_step: 6937, epoch: 74, loss: 0.871644
global_step: 6938, epoch: 74, loss: 0.773522
global_step: 6939, epoch: 74, loss: 0.831429
global_step: 6940, epoch: 74, loss: 0.810196
global_step: 6941, epoch: 74, loss: 0.650727
global_step: 6942, epoch: 74, loss: 0.830824
global_step: 6943, epoch: 74, loss: 0.745513
global_step: 6944, epoch: 74, loss: 0.846452
global_step: 6945, epoch: 74, loss: 0.780337
global_step: 6946, epoch: 74, loss: 0.837281
global_step: 6947, epoch: 74, loss: 0.731825
global_step: 6948, epoch: 74, loss: 0.841049
global_step: 6949, epoch: 74, loss: 0.847673
global_step: 6950, epoch: 74, loss: 0.862195
global_step: 6951, epoch: 74, loss: 0.727079
global_step: 6952, epoch: 74, loss: 0.865682
global_step: 6953, epoch: 74, loss: 0.870925
global_step: 6954, epoch: 74, loss: 0.657089
global_step: 6955, epoch: 74, loss: 0.961441
global_step: 6956, epoch: 74, loss: 0.804511
global_step: 6957, epoch: 74, loss: 0.800953
global_step: 6958, epoch: 74, loss: 0.762102
global_step: 6959, epoch: 74, loss: 0.776899
global_step: 6960, epoch: 74, loss: 0.752021
epoch: 74
train	acc: 0.8332	macro: p 0.8550, r 0.5984, f1: 0.6058	micro: p 0.8332, r 0.8332, f1 0.8332	weighted_f1:0.8127
dev	acc: 0.5347	macro: p 0.3237, r 0.3020, f1: 0.2937	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4865
test	acc: 0.5893	macro: p 0.3473, r 0.3171, f1: 0.3175	micro: p 0.5893, r 0.5893, f1 0.5893	weighted_f1:0.5487
global_step: 6961, epoch: 75, loss: 0.763531
global_step: 6962, epoch: 75, loss: 0.783984
global_step: 6963, epoch: 75, loss: 0.788286
global_step: 6964, epoch: 75, loss: 0.817012
global_step: 6965, epoch: 75, loss: 0.704310
global_step: 6966, epoch: 75, loss: 0.768540
global_step: 6967, epoch: 75, loss: 0.731803
global_step: 6968, epoch: 75, loss: 0.818685
global_step: 6969, epoch: 75, loss: 0.763344
global_step: 6970, epoch: 75, loss: 0.862756
global_step: 6971, epoch: 75, loss: 0.848392
global_step: 6972, epoch: 75, loss: 0.704120
global_step: 6973, epoch: 75, loss: 0.781928
global_step: 6974, epoch: 75, loss: 0.730452
global_step: 6975, epoch: 75, loss: 0.825120
global_step: 6976, epoch: 75, loss: 0.854659
global_step: 6977, epoch: 75, loss: 0.805478
global_step: 6978, epoch: 75, loss: 0.804740
global_step: 6979, epoch: 75, loss: 0.805087
global_step: 6980, epoch: 75, loss: 0.803960
global_step: 6981, epoch: 75, loss: 0.848970
global_step: 6982, epoch: 75, loss: 0.717618
global_step: 6983, epoch: 75, loss: 0.755237
global_step: 6984, epoch: 75, loss: 0.902608
global_step: 6985, epoch: 75, loss: 0.806494
global_step: 6986, epoch: 75, loss: 0.727656
global_step: 6987, epoch: 75, loss: 0.782787
global_step: 6988, epoch: 75, loss: 0.817516
global_step: 6989, epoch: 75, loss: 0.696453
global_step: 6990, epoch: 75, loss: 0.770056
global_step: 6991, epoch: 75, loss: 0.886689
global_step: 6992, epoch: 75, loss: 0.747217
global_step: 6993, epoch: 75, loss: 0.740085
global_step: 6994, epoch: 75, loss: 0.760280
global_step: 6995, epoch: 75, loss: 0.833763
global_step: 6996, epoch: 75, loss: 0.775651
global_step: 6997, epoch: 75, loss: 0.730191
global_step: 6998, epoch: 75, loss: 0.896983
global_step: 6999, epoch: 75, loss: 0.762152
global_step: 7000, epoch: 75, loss: 0.835805
epoch: 75
train	acc: 0.8325	macro: p 0.8580, r 0.5920, f1: 0.6003	micro: p 0.8325, r 0.8325, f1 0.8325	weighted_f1:0.8111
dev	acc: 0.5410	macro: p 0.3430, r 0.3060, f1: 0.3017	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4938
test	acc: 0.5943	macro: p 0.3545, r 0.3182, f1: 0.3201	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5531
global_step: 7001, epoch: 76, loss: 0.775562
global_step: 7002, epoch: 76, loss: 0.830223
global_step: 7003, epoch: 76, loss: 0.769798
global_step: 7004, epoch: 76, loss: 0.798892
global_step: 7005, epoch: 76, loss: 0.715586
global_step: 7006, epoch: 76, loss: 0.810159
global_step: 7007, epoch: 76, loss: 0.737344
global_step: 7008, epoch: 76, loss: 0.778418
global_step: 7009, epoch: 76, loss: 0.725097
global_step: 7010, epoch: 76, loss: 0.697144
global_step: 7011, epoch: 76, loss: 0.688177
global_step: 7012, epoch: 76, loss: 0.883922
global_step: 7013, epoch: 76, loss: 0.709930
global_step: 7014, epoch: 76, loss: 0.880892
global_step: 7015, epoch: 76, loss: 0.803653
global_step: 7016, epoch: 76, loss: 0.835275
global_step: 7017, epoch: 76, loss: 0.756034
global_step: 7018, epoch: 76, loss: 0.832868
global_step: 7019, epoch: 76, loss: 0.908224
global_step: 7020, epoch: 76, loss: 0.827113
global_step: 7021, epoch: 76, loss: 0.855537
global_step: 7022, epoch: 76, loss: 0.850163
global_step: 7023, epoch: 76, loss: 0.773294
global_step: 7024, epoch: 76, loss: 0.700976
global_step: 7025, epoch: 76, loss: 0.848094
global_step: 7026, epoch: 76, loss: 0.819087
global_step: 7027, epoch: 76, loss: 0.775143
global_step: 7028, epoch: 76, loss: 0.843930
global_step: 7029, epoch: 76, loss: 0.741227
global_step: 7030, epoch: 76, loss: 0.762320
global_step: 7031, epoch: 76, loss: 0.833513
global_step: 7032, epoch: 76, loss: 0.818887
global_step: 7033, epoch: 76, loss: 0.764202
global_step: 7034, epoch: 76, loss: 0.855590
global_step: 7035, epoch: 76, loss: 0.743560
global_step: 7036, epoch: 76, loss: 0.788982
global_step: 7037, epoch: 76, loss: 0.836849
global_step: 7038, epoch: 76, loss: 0.751113
global_step: 7039, epoch: 76, loss: 0.785160
global_step: 7040, epoch: 76, loss: 0.429009
epoch: 76
train	acc: 0.8376	macro: p 0.8595, r 0.5999, f1: 0.6081	micro: p 0.8376, r 0.8376, f1 0.8376	weighted_f1:0.8165
dev	acc: 0.5401	macro: p 0.3339, r 0.3049, f1: 0.2972	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4908
test	acc: 0.5954	macro: p 0.3591, r 0.3213, f1: 0.3208	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5541
global_step: 7041, epoch: 77, loss: 0.611757
global_step: 7042, epoch: 77, loss: 0.829282
global_step: 7043, epoch: 77, loss: 0.894061
global_step: 7044, epoch: 77, loss: 0.728175
global_step: 7045, epoch: 77, loss: 0.815567
global_step: 7046, epoch: 77, loss: 0.903461
global_step: 7047, epoch: 77, loss: 0.738417
global_step: 7048, epoch: 77, loss: 0.755157
global_step: 7049, epoch: 77, loss: 0.666321
global_step: 7050, epoch: 77, loss: 0.738242
global_step: 7051, epoch: 77, loss: 0.906044
global_step: 7052, epoch: 77, loss: 0.735824
global_step: 7053, epoch: 77, loss: 0.718011
global_step: 7054, epoch: 77, loss: 0.740566
global_step: 7055, epoch: 77, loss: 0.744350
global_step: 7056, epoch: 77, loss: 0.855503
global_step: 7057, epoch: 77, loss: 0.714720
global_step: 7058, epoch: 77, loss: 0.784113
global_step: 7059, epoch: 77, loss: 0.795758
global_step: 7060, epoch: 77, loss: 0.804074
global_step: 7061, epoch: 77, loss: 0.820534
global_step: 7062, epoch: 77, loss: 0.821685
global_step: 7063, epoch: 77, loss: 0.730874
global_step: 7064, epoch: 77, loss: 0.713923
global_step: 7065, epoch: 77, loss: 0.657938
global_step: 7066, epoch: 77, loss: 0.734733
global_step: 7067, epoch: 77, loss: 0.742464
global_step: 7068, epoch: 77, loss: 0.739072
global_step: 7069, epoch: 77, loss: 0.850558
global_step: 7070, epoch: 77, loss: 0.888715
global_step: 7071, epoch: 77, loss: 0.815765
global_step: 7072, epoch: 77, loss: 0.777106
global_step: 7073, epoch: 77, loss: 0.735466
global_step: 7074, epoch: 77, loss: 0.826012
global_step: 7075, epoch: 77, loss: 0.627896
global_step: 7076, epoch: 77, loss: 0.769216
global_step: 7077, epoch: 77, loss: 0.840947
global_step: 7078, epoch: 77, loss: 0.765116
global_step: 7079, epoch: 77, loss: 0.817612
global_step: 7080, epoch: 77, loss: 0.734992
epoch: 77
train	acc: 0.8376	macro: p 0.8620, r 0.6008, f1: 0.6107	micro: p 0.8376, r 0.8376, f1 0.8376	weighted_f1:0.8169
dev	acc: 0.5437	macro: p 0.3359, r 0.3055, f1: 0.3008	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4944
test	acc: 0.5943	macro: p 0.3573, r 0.3162, f1: 0.3189	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5517
global_step: 7081, epoch: 78, loss: 0.761527
global_step: 7082, epoch: 78, loss: 0.853960
global_step: 7083, epoch: 78, loss: 0.744308
global_step: 7084, epoch: 78, loss: 0.769939
global_step: 7085, epoch: 78, loss: 0.785258
global_step: 7086, epoch: 78, loss: 0.760135
global_step: 7087, epoch: 78, loss: 0.842357
global_step: 7088, epoch: 78, loss: 0.796302
global_step: 7089, epoch: 78, loss: 0.794243
global_step: 7090, epoch: 78, loss: 0.702647
global_step: 7091, epoch: 78, loss: 0.801585
global_step: 7092, epoch: 78, loss: 0.713412
global_step: 7093, epoch: 78, loss: 0.817060
global_step: 7094, epoch: 78, loss: 0.784498
global_step: 7095, epoch: 78, loss: 0.830642
global_step: 7096, epoch: 78, loss: 0.757175
global_step: 7097, epoch: 78, loss: 0.784947
global_step: 7098, epoch: 78, loss: 0.761069
global_step: 7099, epoch: 78, loss: 0.699665
global_step: 7100, epoch: 78, loss: 0.818062
global_step: 7101, epoch: 78, loss: 0.664012
global_step: 7102, epoch: 78, loss: 0.831538
global_step: 7103, epoch: 78, loss: 0.801413
global_step: 7104, epoch: 78, loss: 0.745528
global_step: 7105, epoch: 78, loss: 0.821297
global_step: 7106, epoch: 78, loss: 0.745822
global_step: 7107, epoch: 78, loss: 0.789745
global_step: 7108, epoch: 78, loss: 0.710304
global_step: 7109, epoch: 78, loss: 0.799579
global_step: 7110, epoch: 78, loss: 0.696024
global_step: 7111, epoch: 78, loss: 0.773807
global_step: 7112, epoch: 78, loss: 0.794523
global_step: 7113, epoch: 78, loss: 0.779393
global_step: 7114, epoch: 78, loss: 0.697378
global_step: 7115, epoch: 78, loss: 0.812868
global_step: 7116, epoch: 78, loss: 0.751440
global_step: 7117, epoch: 78, loss: 0.814255
global_step: 7118, epoch: 78, loss: 0.783480
global_step: 7119, epoch: 78, loss: 0.828926
global_step: 7120, epoch: 78, loss: 0.372768
epoch: 78
train	acc: 0.8370	macro: p 0.8641, r 0.6025, f1: 0.6233	micro: p 0.8370, r 0.8370, f1 0.8370	weighted_f1:0.8174
dev	acc: 0.5374	macro: p 0.3412, r 0.3004, f1: 0.2914	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4853
test	acc: 0.5954	macro: p 0.3730, r 0.3175, f1: 0.3184	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5511
global_step: 7121, epoch: 79, loss: 0.825986
global_step: 7122, epoch: 79, loss: 0.687289
global_step: 7123, epoch: 79, loss: 0.784379
global_step: 7124, epoch: 79, loss: 0.756388
global_step: 7125, epoch: 79, loss: 0.761027
global_step: 7126, epoch: 79, loss: 0.762377
global_step: 7127, epoch: 79, loss: 0.685425
global_step: 7128, epoch: 79, loss: 0.562946
global_step: 7129, epoch: 79, loss: 0.716148
global_step: 7130, epoch: 79, loss: 0.793080
global_step: 7131, epoch: 79, loss: 0.805746
global_step: 7132, epoch: 79, loss: 0.760417
global_step: 7133, epoch: 79, loss: 0.767745
global_step: 7134, epoch: 79, loss: 0.795950
global_step: 7135, epoch: 79, loss: 0.807917
global_step: 7136, epoch: 79, loss: 0.670006
global_step: 7137, epoch: 79, loss: 0.756363
global_step: 7138, epoch: 79, loss: 0.699767
global_step: 7139, epoch: 79, loss: 0.728811
global_step: 7140, epoch: 79, loss: 0.818862
global_step: 7141, epoch: 79, loss: 0.790964
global_step: 7142, epoch: 79, loss: 0.633709
global_step: 7143, epoch: 79, loss: 0.847169
global_step: 7144, epoch: 79, loss: 0.800906
global_step: 7145, epoch: 79, loss: 0.806873
global_step: 7146, epoch: 79, loss: 0.739238
global_step: 7147, epoch: 79, loss: 0.819155
global_step: 7148, epoch: 79, loss: 0.728749
global_step: 7149, epoch: 79, loss: 0.736631
global_step: 7150, epoch: 79, loss: 0.737957
global_step: 7151, epoch: 79, loss: 0.787691
global_step: 7152, epoch: 79, loss: 0.734543
global_step: 7153, epoch: 79, loss: 0.768606
global_step: 7154, epoch: 79, loss: 0.815526
global_step: 7155, epoch: 79, loss: 0.802100
global_step: 7156, epoch: 79, loss: 0.804019
global_step: 7157, epoch: 79, loss: 0.840408
global_step: 7158, epoch: 79, loss: 0.624588
global_step: 7159, epoch: 79, loss: 0.796659
global_step: 7160, epoch: 79, loss: 1.046916
epoch: 79
train	acc: 0.8381	macro: p 0.8654, r 0.6012, f1: 0.6190	micro: p 0.8381, r 0.8381, f1 0.8381	weighted_f1:0.8180
dev	acc: 0.5428	macro: p 0.3458, r 0.3001, f1: 0.2951	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4894
test	acc: 0.5946	macro: p 0.3636, r 0.3133, f1: 0.3170	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5504
global_step: 7161, epoch: 80, loss: 0.853997
global_step: 7162, epoch: 80, loss: 0.788559
global_step: 7163, epoch: 80, loss: 0.746170
global_step: 7164, epoch: 80, loss: 0.677152
global_step: 7165, epoch: 80, loss: 0.823376
global_step: 7166, epoch: 80, loss: 0.712864
global_step: 7167, epoch: 80, loss: 0.732853
global_step: 7168, epoch: 80, loss: 0.841669
global_step: 7169, epoch: 80, loss: 0.749355
global_step: 7170, epoch: 80, loss: 0.804600
global_step: 7171, epoch: 80, loss: 0.756679
global_step: 7172, epoch: 80, loss: 0.715938
global_step: 7173, epoch: 80, loss: 0.641450
global_step: 7174, epoch: 80, loss: 0.755390
global_step: 7175, epoch: 80, loss: 0.808298
global_step: 7176, epoch: 80, loss: 0.737492
global_step: 7177, epoch: 80, loss: 0.685839
global_step: 7178, epoch: 80, loss: 0.712828
global_step: 7179, epoch: 80, loss: 0.700189
global_step: 7180, epoch: 80, loss: 0.724991
global_step: 7181, epoch: 80, loss: 0.693339
global_step: 7182, epoch: 80, loss: 0.802408
global_step: 7183, epoch: 80, loss: 0.743104
global_step: 7184, epoch: 80, loss: 0.800871
global_step: 7185, epoch: 80, loss: 0.769492
global_step: 7186, epoch: 80, loss: 0.623149
global_step: 7187, epoch: 80, loss: 0.728098
global_step: 7188, epoch: 80, loss: 0.747439
global_step: 7189, epoch: 80, loss: 0.674940
global_step: 7190, epoch: 80, loss: 0.638147
global_step: 7191, epoch: 80, loss: 0.785477
global_step: 7192, epoch: 80, loss: 0.832890
global_step: 7193, epoch: 80, loss: 0.777580
global_step: 7194, epoch: 80, loss: 0.823614
global_step: 7195, epoch: 80, loss: 0.733900
global_step: 7196, epoch: 80, loss: 0.850273
global_step: 7197, epoch: 80, loss: 0.736632
global_step: 7198, epoch: 80, loss: 0.779756
global_step: 7199, epoch: 80, loss: 0.754116
global_step: 7200, epoch: 80, loss: 0.436618
epoch: 80
train	acc: 0.8473	macro: p 0.8698, r 0.6179, f1: 0.6303	micro: p 0.8473, r 0.8473, f1 0.8473	weighted_f1:0.8277
dev	acc: 0.5446	macro: p 0.3373, r 0.3059, f1: 0.2999	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4932
test	acc: 0.5939	macro: p 0.3533, r 0.3156, f1: 0.3166	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5506
global_step: 7201, epoch: 81, loss: 0.811126
global_step: 7202, epoch: 81, loss: 0.781245
global_step: 7203, epoch: 81, loss: 0.836088
global_step: 7204, epoch: 81, loss: 0.766455
global_step: 7205, epoch: 81, loss: 0.740792
global_step: 7206, epoch: 81, loss: 0.761458
global_step: 7207, epoch: 81, loss: 0.691627
global_step: 7208, epoch: 81, loss: 0.694623
global_step: 7209, epoch: 81, loss: 0.761892
global_step: 7210, epoch: 81, loss: 0.707668
global_step: 7211, epoch: 81, loss: 0.720227
global_step: 7212, epoch: 81, loss: 0.721791
global_step: 7213, epoch: 81, loss: 0.656742
global_step: 7214, epoch: 81, loss: 0.816807
global_step: 7215, epoch: 81, loss: 0.761703
global_step: 7216, epoch: 81, loss: 0.704507
global_step: 7217, epoch: 81, loss: 0.729670
global_step: 7218, epoch: 81, loss: 0.692246
global_step: 7219, epoch: 81, loss: 0.813711
global_step: 7220, epoch: 81, loss: 0.813305
global_step: 7221, epoch: 81, loss: 0.793865
global_step: 7222, epoch: 81, loss: 0.671693
global_step: 7223, epoch: 81, loss: 0.756597
global_step: 7224, epoch: 81, loss: 0.855194
global_step: 7225, epoch: 81, loss: 0.743645
global_step: 7226, epoch: 81, loss: 0.796945
global_step: 7227, epoch: 81, loss: 0.733427
global_step: 7228, epoch: 81, loss: 0.645147
global_step: 7229, epoch: 81, loss: 0.780622
global_step: 7230, epoch: 81, loss: 0.723597
global_step: 7231, epoch: 81, loss: 0.854905
global_step: 7232, epoch: 81, loss: 0.753517
global_step: 7233, epoch: 81, loss: 0.825088
global_step: 7234, epoch: 81, loss: 0.810307
global_step: 7235, epoch: 81, loss: 0.769541
global_step: 7236, epoch: 81, loss: 0.750869
global_step: 7237, epoch: 81, loss: 0.712129
global_step: 7238, epoch: 81, loss: 0.833267
global_step: 7239, epoch: 81, loss: 0.807558
global_step: 7240, epoch: 81, loss: 1.085126
epoch: 81
train	acc: 0.8540	macro: p 0.8721, r 0.6358, f1: 0.6548	micro: p 0.8540, r 0.8540, f1 0.8540	weighted_f1:0.8368
dev	acc: 0.5392	macro: p 0.3314, r 0.3011, f1: 0.2959	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4881
test	acc: 0.5931	macro: p 0.3513, r 0.3155, f1: 0.3181	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5510
global_step: 7241, epoch: 82, loss: 0.802415
global_step: 7242, epoch: 82, loss: 0.718434
global_step: 7243, epoch: 82, loss: 0.714840
global_step: 7244, epoch: 82, loss: 0.697267
global_step: 7245, epoch: 82, loss: 0.685001
global_step: 7246, epoch: 82, loss: 0.706620
global_step: 7247, epoch: 82, loss: 0.710684
global_step: 7248, epoch: 82, loss: 0.674550
global_step: 7249, epoch: 82, loss: 0.696593
global_step: 7250, epoch: 82, loss: 0.813992
global_step: 7251, epoch: 82, loss: 0.708666
global_step: 7252, epoch: 82, loss: 0.721923
global_step: 7253, epoch: 82, loss: 0.733519
global_step: 7254, epoch: 82, loss: 0.721848
global_step: 7255, epoch: 82, loss: 0.684138
global_step: 7256, epoch: 82, loss: 0.725717
global_step: 7257, epoch: 82, loss: 0.735265
global_step: 7258, epoch: 82, loss: 0.844586
global_step: 7259, epoch: 82, loss: 0.851970
global_step: 7260, epoch: 82, loss: 0.651307
global_step: 7261, epoch: 82, loss: 0.763384
global_step: 7262, epoch: 82, loss: 0.763055
global_step: 7263, epoch: 82, loss: 0.743937
global_step: 7264, epoch: 82, loss: 0.795632
global_step: 7265, epoch: 82, loss: 0.763930
global_step: 7266, epoch: 82, loss: 0.696135
global_step: 7267, epoch: 82, loss: 0.712164
global_step: 7268, epoch: 82, loss: 0.737936
global_step: 7269, epoch: 82, loss: 0.707426
global_step: 7270, epoch: 82, loss: 0.760307
global_step: 7271, epoch: 82, loss: 0.776870
global_step: 7272, epoch: 82, loss: 0.787249
global_step: 7273, epoch: 82, loss: 0.770899
global_step: 7274, epoch: 82, loss: 0.644646
global_step: 7275, epoch: 82, loss: 0.731051
global_step: 7276, epoch: 82, loss: 0.832631
global_step: 7277, epoch: 82, loss: 0.773158
global_step: 7278, epoch: 82, loss: 0.616399
global_step: 7279, epoch: 82, loss: 0.787271
global_step: 7280, epoch: 82, loss: 0.983322
epoch: 82
train	acc: 0.8554	macro: p 0.8689, r 0.6359, f1: 0.6492	micro: p 0.8554, r 0.8554, f1 0.8554	weighted_f1:0.8379
dev	acc: 0.5419	macro: p 0.3361, r 0.3072, f1: 0.2988	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4922
test	acc: 0.5935	macro: p 0.3551, r 0.3216, f1: 0.3220	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5535
global_step: 7281, epoch: 83, loss: 0.722946
global_step: 7282, epoch: 83, loss: 0.716288
global_step: 7283, epoch: 83, loss: 0.804787
global_step: 7284, epoch: 83, loss: 0.647970
global_step: 7285, epoch: 83, loss: 0.778208
global_step: 7286, epoch: 83, loss: 0.621844
global_step: 7287, epoch: 83, loss: 0.632402
global_step: 7288, epoch: 83, loss: 0.838454
global_step: 7289, epoch: 83, loss: 0.742682
global_step: 7290, epoch: 83, loss: 0.731300
global_step: 7291, epoch: 83, loss: 0.710345
global_step: 7292, epoch: 83, loss: 0.644890
global_step: 7293, epoch: 83, loss: 0.705624
global_step: 7294, epoch: 83, loss: 0.666178
global_step: 7295, epoch: 83, loss: 0.659813
global_step: 7296, epoch: 83, loss: 0.721921
global_step: 7297, epoch: 83, loss: 0.674659
global_step: 7298, epoch: 83, loss: 0.651435
global_step: 7299, epoch: 83, loss: 0.729367
global_step: 7300, epoch: 83, loss: 0.764860
global_step: 7301, epoch: 83, loss: 0.797583
global_step: 7302, epoch: 83, loss: 0.758377
global_step: 7303, epoch: 83, loss: 0.732886
global_step: 7304, epoch: 83, loss: 0.695828
global_step: 7305, epoch: 83, loss: 0.676410
global_step: 7306, epoch: 83, loss: 0.755794
global_step: 7307, epoch: 83, loss: 0.786820
global_step: 7308, epoch: 83, loss: 0.721813
global_step: 7309, epoch: 83, loss: 0.728209
global_step: 7310, epoch: 83, loss: 0.884303
global_step: 7311, epoch: 83, loss: 0.738748
global_step: 7312, epoch: 83, loss: 0.764314
global_step: 7313, epoch: 83, loss: 0.837875
global_step: 7314, epoch: 83, loss: 0.759809
global_step: 7315, epoch: 83, loss: 0.723972
global_step: 7316, epoch: 83, loss: 0.735169
global_step: 7317, epoch: 83, loss: 0.709359
global_step: 7318, epoch: 83, loss: 0.735143
global_step: 7319, epoch: 83, loss: 0.623317
global_step: 7320, epoch: 83, loss: 0.577089
epoch: 83
train	acc: 0.8519	macro: p 0.8771, r 0.6340, f1: 0.6595	micro: p 0.8519, r 0.8519, f1 0.8519	weighted_f1:0.8349
dev	acc: 0.5437	macro: p 0.3361, r 0.3018, f1: 0.2960	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4891
test	acc: 0.5950	macro: p 0.3527, r 0.3119, f1: 0.3141	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5486
global_step: 7321, epoch: 84, loss: 0.750735
global_step: 7322, epoch: 84, loss: 0.673959
global_step: 7323, epoch: 84, loss: 0.773900
global_step: 7324, epoch: 84, loss: 0.825691
global_step: 7325, epoch: 84, loss: 0.686475
global_step: 7326, epoch: 84, loss: 0.675776
global_step: 7327, epoch: 84, loss: 0.693293
global_step: 7328, epoch: 84, loss: 0.823328
global_step: 7329, epoch: 84, loss: 0.681686
global_step: 7330, epoch: 84, loss: 0.719286
global_step: 7331, epoch: 84, loss: 0.722443
global_step: 7332, epoch: 84, loss: 0.645492
global_step: 7333, epoch: 84, loss: 0.798717
global_step: 7334, epoch: 84, loss: 0.710269
global_step: 7335, epoch: 84, loss: 0.649031
global_step: 7336, epoch: 84, loss: 0.672732
global_step: 7337, epoch: 84, loss: 0.711623
global_step: 7338, epoch: 84, loss: 0.649403
global_step: 7339, epoch: 84, loss: 0.704945
global_step: 7340, epoch: 84, loss: 0.686774
global_step: 7341, epoch: 84, loss: 0.710312
global_step: 7342, epoch: 84, loss: 0.790895
global_step: 7343, epoch: 84, loss: 0.751350
global_step: 7344, epoch: 84, loss: 0.799587
global_step: 7345, epoch: 84, loss: 0.743289
global_step: 7346, epoch: 84, loss: 0.652961
global_step: 7347, epoch: 84, loss: 0.778325
global_step: 7348, epoch: 84, loss: 0.728652
global_step: 7349, epoch: 84, loss: 0.711382
global_step: 7350, epoch: 84, loss: 0.723775
global_step: 7351, epoch: 84, loss: 0.737404
global_step: 7352, epoch: 84, loss: 0.721116
global_step: 7353, epoch: 84, loss: 0.706991
global_step: 7354, epoch: 84, loss: 0.730491
global_step: 7355, epoch: 84, loss: 0.792735
global_step: 7356, epoch: 84, loss: 0.660452
global_step: 7357, epoch: 84, loss: 0.791575
global_step: 7358, epoch: 84, loss: 0.720816
global_step: 7359, epoch: 84, loss: 0.741406
global_step: 7360, epoch: 84, loss: 0.778640
epoch: 84
train	acc: 0.8540	macro: p 0.8675, r 0.6415, f1: 0.6659	micro: p 0.8540, r 0.8540, f1 0.8540	weighted_f1:0.8386
dev	acc: 0.5383	macro: p 0.3410, r 0.3043, f1: 0.2953	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4884
test	acc: 0.5916	macro: p 0.3629, r 0.3186, f1: 0.3192	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5501
global_step: 7361, epoch: 85, loss: 0.637369
global_step: 7362, epoch: 85, loss: 0.587897
global_step: 7363, epoch: 85, loss: 0.735283
global_step: 7364, epoch: 85, loss: 0.744048
global_step: 7365, epoch: 85, loss: 0.663411
global_step: 7366, epoch: 85, loss: 0.660462
global_step: 7367, epoch: 85, loss: 0.755935
global_step: 7368, epoch: 85, loss: 0.635163
global_step: 7369, epoch: 85, loss: 0.813167
global_step: 7370, epoch: 85, loss: 0.747325
global_step: 7371, epoch: 85, loss: 0.732756
global_step: 7372, epoch: 85, loss: 0.679382
global_step: 7373, epoch: 85, loss: 0.816427
global_step: 7374, epoch: 85, loss: 0.789822
global_step: 7375, epoch: 85, loss: 0.748173
global_step: 7376, epoch: 85, loss: 0.655186
global_step: 7377, epoch: 85, loss: 0.604801
global_step: 7378, epoch: 85, loss: 0.724421
global_step: 7379, epoch: 85, loss: 0.673058
global_step: 7380, epoch: 85, loss: 0.691592
global_step: 7381, epoch: 85, loss: 0.802870
global_step: 7382, epoch: 85, loss: 0.725785
global_step: 7383, epoch: 85, loss: 0.622400
global_step: 7384, epoch: 85, loss: 0.676772
global_step: 7385, epoch: 85, loss: 0.761892
global_step: 7386, epoch: 85, loss: 0.685090
global_step: 7387, epoch: 85, loss: 0.757523
global_step: 7388, epoch: 85, loss: 0.795883
global_step: 7389, epoch: 85, loss: 0.738125
global_step: 7390, epoch: 85, loss: 0.606942
global_step: 7391, epoch: 85, loss: 0.681181
global_step: 7392, epoch: 85, loss: 0.744792
global_step: 7393, epoch: 85, loss: 0.793843
global_step: 7394, epoch: 85, loss: 0.688629
global_step: 7395, epoch: 85, loss: 0.746912
global_step: 7396, epoch: 85, loss: 0.665289
global_step: 7397, epoch: 85, loss: 0.674008
global_step: 7398, epoch: 85, loss: 0.785533
global_step: 7399, epoch: 85, loss: 0.769685
global_step: 7400, epoch: 85, loss: 0.527470
epoch: 85
train	acc: 0.8556	macro: p 0.8708, r 0.6358, f1: 0.6605	micro: p 0.8556, r 0.8556, f1 0.8556	weighted_f1:0.8386
dev	acc: 0.5419	macro: p 0.3336, r 0.3005, f1: 0.2931	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4874
test	acc: 0.5985	macro: p 0.3630, r 0.3156, f1: 0.3180	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5524
global_step: 7401, epoch: 86, loss: 0.600550
global_step: 7402, epoch: 86, loss: 0.787887
global_step: 7403, epoch: 86, loss: 0.703046
global_step: 7404, epoch: 86, loss: 0.650654
global_step: 7405, epoch: 86, loss: 0.750709
global_step: 7406, epoch: 86, loss: 0.809997
global_step: 7407, epoch: 86, loss: 0.618659
global_step: 7408, epoch: 86, loss: 0.710634
global_step: 7409, epoch: 86, loss: 0.573394
global_step: 7410, epoch: 86, loss: 0.665873
global_step: 7411, epoch: 86, loss: 0.657510
global_step: 7412, epoch: 86, loss: 0.609662
global_step: 7413, epoch: 86, loss: 0.665324
global_step: 7414, epoch: 86, loss: 0.613430
global_step: 7415, epoch: 86, loss: 0.727303
global_step: 7416, epoch: 86, loss: 0.647122
global_step: 7417, epoch: 86, loss: 0.662716
global_step: 7418, epoch: 86, loss: 0.650288
global_step: 7419, epoch: 86, loss: 0.720218
global_step: 7420, epoch: 86, loss: 0.713118
global_step: 7421, epoch: 86, loss: 0.688372
global_step: 7422, epoch: 86, loss: 0.746142
global_step: 7423, epoch: 86, loss: 0.725509
global_step: 7424, epoch: 86, loss: 0.678203
global_step: 7425, epoch: 86, loss: 0.700498
global_step: 7426, epoch: 86, loss: 0.724970
global_step: 7427, epoch: 86, loss: 0.677489
global_step: 7428, epoch: 86, loss: 0.730332
global_step: 7429, epoch: 86, loss: 0.760331
global_step: 7430, epoch: 86, loss: 0.684420
global_step: 7431, epoch: 86, loss: 0.775486
global_step: 7432, epoch: 86, loss: 0.827463
global_step: 7433, epoch: 86, loss: 0.725932
global_step: 7434, epoch: 86, loss: 0.713872
global_step: 7435, epoch: 86, loss: 0.702547
global_step: 7436, epoch: 86, loss: 0.729455
global_step: 7437, epoch: 86, loss: 0.672453
global_step: 7438, epoch: 86, loss: 0.658723
global_step: 7439, epoch: 86, loss: 0.820327
global_step: 7440, epoch: 86, loss: 1.497032
epoch: 86
train	acc: 0.8688	macro: p 0.8803, r 0.6714, f1: 0.6938	micro: p 0.8688, r 0.8688, f1 0.8688	weighted_f1:0.8549
dev	acc: 0.5446	macro: p 0.3407, r 0.3088, f1: 0.3039	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4962
test	acc: 0.5954	macro: p 0.3546, r 0.3218, f1: 0.3242	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5552
global_step: 7441, epoch: 87, loss: 0.683222
global_step: 7442, epoch: 87, loss: 0.655945
global_step: 7443, epoch: 87, loss: 0.693323
global_step: 7444, epoch: 87, loss: 0.717758
global_step: 7445, epoch: 87, loss: 0.810863
global_step: 7446, epoch: 87, loss: 0.727895
global_step: 7447, epoch: 87, loss: 0.675659
global_step: 7448, epoch: 87, loss: 0.719862
global_step: 7449, epoch: 87, loss: 0.582857
global_step: 7450, epoch: 87, loss: 0.595196
global_step: 7451, epoch: 87, loss: 0.730915
global_step: 7452, epoch: 87, loss: 0.672369
global_step: 7453, epoch: 87, loss: 0.656343
global_step: 7454, epoch: 87, loss: 0.691270
global_step: 7455, epoch: 87, loss: 0.776414
global_step: 7456, epoch: 87, loss: 0.622777
global_step: 7457, epoch: 87, loss: 0.668024
global_step: 7458, epoch: 87, loss: 0.729514
global_step: 7459, epoch: 87, loss: 0.761473
global_step: 7460, epoch: 87, loss: 0.743881
global_step: 7461, epoch: 87, loss: 0.741664
global_step: 7462, epoch: 87, loss: 0.653637
global_step: 7463, epoch: 87, loss: 0.735185
global_step: 7464, epoch: 87, loss: 0.641696
global_step: 7465, epoch: 87, loss: 0.684502
global_step: 7466, epoch: 87, loss: 0.694106
global_step: 7467, epoch: 87, loss: 0.679783
global_step: 7468, epoch: 87, loss: 0.641894
global_step: 7469, epoch: 87, loss: 0.702352
global_step: 7470, epoch: 87, loss: 0.799511
global_step: 7471, epoch: 87, loss: 0.740099
global_step: 7472, epoch: 87, loss: 0.710109
global_step: 7473, epoch: 87, loss: 0.722161
global_step: 7474, epoch: 87, loss: 0.776297
global_step: 7475, epoch: 87, loss: 0.721826
global_step: 7476, epoch: 87, loss: 0.779506
global_step: 7477, epoch: 87, loss: 0.744283
global_step: 7478, epoch: 87, loss: 0.647470
global_step: 7479, epoch: 87, loss: 0.686755
global_step: 7480, epoch: 87, loss: 0.702524
epoch: 87
train	acc: 0.8659	macro: p 0.8740, r 0.6556, f1: 0.6760	micro: p 0.8659, r 0.8659, f1 0.8659	weighted_f1:0.8499
dev	acc: 0.5401	macro: p 0.3310, r 0.3028, f1: 0.2964	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4888
test	acc: 0.5935	macro: p 0.3454, r 0.3139, f1: 0.3154	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5499
global_step: 7481, epoch: 88, loss: 0.746065
global_step: 7482, epoch: 88, loss: 0.689409
global_step: 7483, epoch: 88, loss: 0.597096
global_step: 7484, epoch: 88, loss: 0.645535
global_step: 7485, epoch: 88, loss: 0.586469
global_step: 7486, epoch: 88, loss: 0.749170
global_step: 7487, epoch: 88, loss: 0.668539
global_step: 7488, epoch: 88, loss: 0.681278
global_step: 7489, epoch: 88, loss: 0.664189
global_step: 7490, epoch: 88, loss: 0.597042
global_step: 7491, epoch: 88, loss: 0.783088
global_step: 7492, epoch: 88, loss: 0.686250
global_step: 7493, epoch: 88, loss: 0.656863
global_step: 7494, epoch: 88, loss: 0.733298
global_step: 7495, epoch: 88, loss: 0.639869
global_step: 7496, epoch: 88, loss: 0.807661
global_step: 7497, epoch: 88, loss: 0.665936
global_step: 7498, epoch: 88, loss: 0.873081
global_step: 7499, epoch: 88, loss: 0.655307
global_step: 7500, epoch: 88, loss: 0.826094
global_step: 7501, epoch: 88, loss: 0.673897
global_step: 7502, epoch: 88, loss: 0.715140
global_step: 7503, epoch: 88, loss: 0.623644
global_step: 7504, epoch: 88, loss: 0.678923
global_step: 7505, epoch: 88, loss: 0.704089
global_step: 7506, epoch: 88, loss: 0.699900
global_step: 7507, epoch: 88, loss: 0.716621
global_step: 7508, epoch: 88, loss: 0.705111
global_step: 7509, epoch: 88, loss: 0.734006
global_step: 7510, epoch: 88, loss: 0.645958
global_step: 7511, epoch: 88, loss: 0.756677
global_step: 7512, epoch: 88, loss: 0.674851
global_step: 7513, epoch: 88, loss: 0.720513
global_step: 7514, epoch: 88, loss: 0.828385
global_step: 7515, epoch: 88, loss: 0.712684
global_step: 7516, epoch: 88, loss: 0.701978
global_step: 7517, epoch: 88, loss: 0.653400
global_step: 7518, epoch: 88, loss: 0.702451
global_step: 7519, epoch: 88, loss: 0.707850
global_step: 7520, epoch: 88, loss: 0.624744
epoch: 88
train	acc: 0.8689	macro: p 0.8843, r 0.6651, f1: 0.6889	micro: p 0.8689, r 0.8689, f1 0.8689	weighted_f1:0.8544
dev	acc: 0.5437	macro: p 0.3341, r 0.3044, f1: 0.2970	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4918
test	acc: 0.5920	macro: p 0.3582, r 0.3156, f1: 0.3184	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5505
global_step: 7521, epoch: 89, loss: 0.646003
global_step: 7522, epoch: 89, loss: 0.667103
global_step: 7523, epoch: 89, loss: 0.678699
global_step: 7524, epoch: 89, loss: 0.738519
global_step: 7525, epoch: 89, loss: 0.747410
global_step: 7526, epoch: 89, loss: 0.692314
global_step: 7527, epoch: 89, loss: 0.607440
global_step: 7528, epoch: 89, loss: 0.666313
global_step: 7529, epoch: 89, loss: 0.695968
global_step: 7530, epoch: 89, loss: 0.681711
global_step: 7531, epoch: 89, loss: 0.705640
global_step: 7532, epoch: 89, loss: 0.670326
global_step: 7533, epoch: 89, loss: 0.585136
global_step: 7534, epoch: 89, loss: 0.657567
global_step: 7535, epoch: 89, loss: 0.630308
global_step: 7536, epoch: 89, loss: 0.696963
global_step: 7537, epoch: 89, loss: 0.741279
global_step: 7538, epoch: 89, loss: 0.670585
global_step: 7539, epoch: 89, loss: 0.707288
global_step: 7540, epoch: 89, loss: 0.625744
global_step: 7541, epoch: 89, loss: 0.657601
global_step: 7542, epoch: 89, loss: 0.668976
global_step: 7543, epoch: 89, loss: 0.801057
global_step: 7544, epoch: 89, loss: 0.714476
global_step: 7545, epoch: 89, loss: 0.666382
global_step: 7546, epoch: 89, loss: 0.790648
global_step: 7547, epoch: 89, loss: 0.666318
global_step: 7548, epoch: 89, loss: 0.735930
global_step: 7549, epoch: 89, loss: 0.740138
global_step: 7550, epoch: 89, loss: 0.623759
global_step: 7551, epoch: 89, loss: 0.709930
global_step: 7552, epoch: 89, loss: 0.706587
global_step: 7553, epoch: 89, loss: 0.692498
global_step: 7554, epoch: 89, loss: 0.764431
global_step: 7555, epoch: 89, loss: 0.696423
global_step: 7556, epoch: 89, loss: 0.671792
global_step: 7557, epoch: 89, loss: 0.719283
global_step: 7558, epoch: 89, loss: 0.768409
global_step: 7559, epoch: 89, loss: 0.697096
global_step: 7560, epoch: 89, loss: 0.631077
epoch: 89
train	acc: 0.8691	macro: p 0.8797, r 0.6670, f1: 0.6851	micro: p 0.8691, r 0.8691, f1 0.8691	weighted_f1:0.8546
dev	acc: 0.5419	macro: p 0.3384, r 0.3109, f1: 0.3074	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4962
test	acc: 0.5958	macro: p 0.3579, r 0.3257, f1: 0.3283	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5572
global_step: 7561, epoch: 90, loss: 0.678414
global_step: 7562, epoch: 90, loss: 0.677303
global_step: 7563, epoch: 90, loss: 0.673081
global_step: 7564, epoch: 90, loss: 0.676233
global_step: 7565, epoch: 90, loss: 0.678669
global_step: 7566, epoch: 90, loss: 0.682732
global_step: 7567, epoch: 90, loss: 0.748158
global_step: 7568, epoch: 90, loss: 0.714236
global_step: 7569, epoch: 90, loss: 0.692497
global_step: 7570, epoch: 90, loss: 0.686672
global_step: 7571, epoch: 90, loss: 0.707726
global_step: 7572, epoch: 90, loss: 0.637376
global_step: 7573, epoch: 90, loss: 0.755722
global_step: 7574, epoch: 90, loss: 0.637929
global_step: 7575, epoch: 90, loss: 0.646617
global_step: 7576, epoch: 90, loss: 0.767329
global_step: 7577, epoch: 90, loss: 0.739121
global_step: 7578, epoch: 90, loss: 0.681539
global_step: 7579, epoch: 90, loss: 0.599101
global_step: 7580, epoch: 90, loss: 0.639824
global_step: 7581, epoch: 90, loss: 0.607437
global_step: 7582, epoch: 90, loss: 0.673689
global_step: 7583, epoch: 90, loss: 0.748985
global_step: 7584, epoch: 90, loss: 0.762658
global_step: 7585, epoch: 90, loss: 0.604757
global_step: 7586, epoch: 90, loss: 0.730732
global_step: 7587, epoch: 90, loss: 0.804362
global_step: 7588, epoch: 90, loss: 0.595477
global_step: 7589, epoch: 90, loss: 0.807157
global_step: 7590, epoch: 90, loss: 0.775842
global_step: 7591, epoch: 90, loss: 0.679514
global_step: 7592, epoch: 90, loss: 0.643025
global_step: 7593, epoch: 90, loss: 0.715901
global_step: 7594, epoch: 90, loss: 0.712747
global_step: 7595, epoch: 90, loss: 0.692835
global_step: 7596, epoch: 90, loss: 0.707538
global_step: 7597, epoch: 90, loss: 0.652746
global_step: 7598, epoch: 90, loss: 0.654280
global_step: 7599, epoch: 90, loss: 0.672663
global_step: 7600, epoch: 90, loss: 0.753668
epoch: 90
train	acc: 0.8740	macro: p 0.8876, r 0.6789, f1: 0.7023	micro: p 0.8740, r 0.8740, f1 0.8740	weighted_f1:0.8607
dev	acc: 0.5383	macro: p 0.3258, r 0.3049, f1: 0.2969	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4903
test	acc: 0.5946	macro: p 0.3638, r 0.3253, f1: 0.3285	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5577
global_step: 7601, epoch: 91, loss: 0.691724
global_step: 7602, epoch: 91, loss: 0.739178
global_step: 7603, epoch: 91, loss: 0.657123
global_step: 7604, epoch: 91, loss: 0.664139
global_step: 7605, epoch: 91, loss: 0.657054
global_step: 7606, epoch: 91, loss: 0.663564
global_step: 7607, epoch: 91, loss: 0.741398
global_step: 7608, epoch: 91, loss: 0.625948
global_step: 7609, epoch: 91, loss: 0.664335
global_step: 7610, epoch: 91, loss: 0.706106
global_step: 7611, epoch: 91, loss: 0.667691
global_step: 7612, epoch: 91, loss: 0.655185
global_step: 7613, epoch: 91, loss: 0.691434
global_step: 7614, epoch: 91, loss: 0.695761
global_step: 7615, epoch: 91, loss: 0.661825
global_step: 7616, epoch: 91, loss: 0.698177
global_step: 7617, epoch: 91, loss: 0.707313
global_step: 7618, epoch: 91, loss: 0.685113
global_step: 7619, epoch: 91, loss: 0.688683
global_step: 7620, epoch: 91, loss: 0.649523
global_step: 7621, epoch: 91, loss: 0.727628
global_step: 7622, epoch: 91, loss: 0.614362
global_step: 7623, epoch: 91, loss: 0.668059
global_step: 7624, epoch: 91, loss: 0.666800
global_step: 7625, epoch: 91, loss: 0.648995
global_step: 7626, epoch: 91, loss: 0.673599
global_step: 7627, epoch: 91, loss: 0.660462
global_step: 7628, epoch: 91, loss: 0.766092
global_step: 7629, epoch: 91, loss: 0.625689
global_step: 7630, epoch: 91, loss: 0.714398
global_step: 7631, epoch: 91, loss: 0.647502
global_step: 7632, epoch: 91, loss: 0.521880
global_step: 7633, epoch: 91, loss: 0.598239
global_step: 7634, epoch: 91, loss: 0.634692
global_step: 7635, epoch: 91, loss: 0.655486
global_step: 7636, epoch: 91, loss: 0.660200
global_step: 7637, epoch: 91, loss: 0.746877
global_step: 7638, epoch: 91, loss: 0.694920
global_step: 7639, epoch: 91, loss: 0.716447
global_step: 7640, epoch: 91, loss: 1.221524
epoch: 91
train	acc: 0.8736	macro: p 0.8856, r 0.6809, f1: 0.7034	micro: p 0.8736, r 0.8736, f1 0.8736	weighted_f1:0.8606
dev	acc: 0.5410	macro: p 0.3330, r 0.3101, f1: 0.3014	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4951
test	acc: 0.5946	macro: p 0.3614, r 0.3305, f1: 0.3300	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5588
global_step: 7641, epoch: 92, loss: 0.618024
global_step: 7642, epoch: 92, loss: 0.634230
global_step: 7643, epoch: 92, loss: 0.691662
global_step: 7644, epoch: 92, loss: 0.740370
global_step: 7645, epoch: 92, loss: 0.670935
global_step: 7646, epoch: 92, loss: 0.701868
global_step: 7647, epoch: 92, loss: 0.711066
global_step: 7648, epoch: 92, loss: 0.723872
global_step: 7649, epoch: 92, loss: 0.726450
global_step: 7650, epoch: 92, loss: 0.693558
global_step: 7651, epoch: 92, loss: 0.753460
global_step: 7652, epoch: 92, loss: 0.713581
global_step: 7653, epoch: 92, loss: 0.682604
global_step: 7654, epoch: 92, loss: 0.642575
global_step: 7655, epoch: 92, loss: 0.599330
global_step: 7656, epoch: 92, loss: 0.650424
global_step: 7657, epoch: 92, loss: 0.654706
global_step: 7658, epoch: 92, loss: 0.634291
global_step: 7659, epoch: 92, loss: 0.678141
global_step: 7660, epoch: 92, loss: 0.657917
global_step: 7661, epoch: 92, loss: 0.687340
global_step: 7662, epoch: 92, loss: 0.760319
global_step: 7663, epoch: 92, loss: 0.725656
global_step: 7664, epoch: 92, loss: 0.657744
global_step: 7665, epoch: 92, loss: 0.701714
global_step: 7666, epoch: 92, loss: 0.695287
global_step: 7667, epoch: 92, loss: 0.635446
global_step: 7668, epoch: 92, loss: 0.650606
global_step: 7669, epoch: 92, loss: 0.655885
global_step: 7670, epoch: 92, loss: 0.690779
global_step: 7671, epoch: 92, loss: 0.615330
global_step: 7672, epoch: 92, loss: 0.574160
global_step: 7673, epoch: 92, loss: 0.620915
global_step: 7674, epoch: 92, loss: 0.686261
global_step: 7675, epoch: 92, loss: 0.625133
global_step: 7676, epoch: 92, loss: 0.703645
global_step: 7677, epoch: 92, loss: 0.674811
global_step: 7678, epoch: 92, loss: 0.583477
global_step: 7679, epoch: 92, loss: 0.692491
global_step: 7680, epoch: 92, loss: 0.233088
epoch: 92
train	acc: 0.8736	macro: p 0.8885, r 0.6760, f1: 0.7058	micro: p 0.8736, r 0.8736, f1 0.8736	weighted_f1:0.8603
dev	acc: 0.5464	macro: p 0.3441, r 0.3068, f1: 0.2989	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4937
test	acc: 0.5985	macro: p 0.3664, r 0.3199, f1: 0.3221	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5548
global_step: 7681, epoch: 93, loss: 0.648536
global_step: 7682, epoch: 93, loss: 0.707506
global_step: 7683, epoch: 93, loss: 0.716661
global_step: 7684, epoch: 93, loss: 0.668033
global_step: 7685, epoch: 93, loss: 0.672991
global_step: 7686, epoch: 93, loss: 0.609760
global_step: 7687, epoch: 93, loss: 0.702755
global_step: 7688, epoch: 93, loss: 0.657305
global_step: 7689, epoch: 93, loss: 0.632782
global_step: 7690, epoch: 93, loss: 0.665384
global_step: 7691, epoch: 93, loss: 0.651924
global_step: 7692, epoch: 93, loss: 0.621397
global_step: 7693, epoch: 93, loss: 0.719370
global_step: 7694, epoch: 93, loss: 0.593258
global_step: 7695, epoch: 93, loss: 0.668218
global_step: 7696, epoch: 93, loss: 0.802587
global_step: 7697, epoch: 93, loss: 0.647826
global_step: 7698, epoch: 93, loss: 0.567805
global_step: 7699, epoch: 93, loss: 0.738742
global_step: 7700, epoch: 93, loss: 0.675631
global_step: 7701, epoch: 93, loss: 0.653397
global_step: 7702, epoch: 93, loss: 0.698416
global_step: 7703, epoch: 93, loss: 0.582746
global_step: 7704, epoch: 93, loss: 0.599016
global_step: 7705, epoch: 93, loss: 0.590122
global_step: 7706, epoch: 93, loss: 0.640364
global_step: 7707, epoch: 93, loss: 0.677091
global_step: 7708, epoch: 93, loss: 0.717844
global_step: 7709, epoch: 93, loss: 0.813669
global_step: 7710, epoch: 93, loss: 0.681797
global_step: 7711, epoch: 93, loss: 0.649721
global_step: 7712, epoch: 93, loss: 0.677839
global_step: 7713, epoch: 93, loss: 0.732621
global_step: 7714, epoch: 93, loss: 0.647062
global_step: 7715, epoch: 93, loss: 0.682583
global_step: 7716, epoch: 93, loss: 0.647335
global_step: 7717, epoch: 93, loss: 0.537091
global_step: 7718, epoch: 93, loss: 0.633499
global_step: 7719, epoch: 93, loss: 0.641199
global_step: 7720, epoch: 93, loss: 1.697209
epoch: 93
train	acc: 0.8773	macro: p 0.8879, r 0.6851, f1: 0.7129	micro: p 0.8773, r 0.8773, f1 0.8773	weighted_f1:0.8649
dev	acc: 0.5437	macro: p 0.3435, r 0.3062, f1: 0.3014	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4947
test	acc: 0.5958	macro: p 0.3579, r 0.3196, f1: 0.3218	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5551
global_step: 7721, epoch: 94, loss: 0.639553
global_step: 7722, epoch: 94, loss: 0.600260
global_step: 7723, epoch: 94, loss: 0.650540
global_step: 7724, epoch: 94, loss: 0.694573
global_step: 7725, epoch: 94, loss: 0.591224
global_step: 7726, epoch: 94, loss: 0.669532
global_step: 7727, epoch: 94, loss: 0.662770
global_step: 7728, epoch: 94, loss: 0.793819
global_step: 7729, epoch: 94, loss: 0.655068
global_step: 7730, epoch: 94, loss: 0.585220
global_step: 7731, epoch: 94, loss: 0.688809
global_step: 7732, epoch: 94, loss: 0.581508
global_step: 7733, epoch: 94, loss: 0.594998
global_step: 7734, epoch: 94, loss: 0.677044
global_step: 7735, epoch: 94, loss: 0.682268
global_step: 7736, epoch: 94, loss: 0.592515
global_step: 7737, epoch: 94, loss: 0.603188
global_step: 7738, epoch: 94, loss: 0.661930
global_step: 7739, epoch: 94, loss: 0.727416
global_step: 7740, epoch: 94, loss: 0.634835
global_step: 7741, epoch: 94, loss: 0.681295
global_step: 7742, epoch: 94, loss: 0.633282
global_step: 7743, epoch: 94, loss: 0.669555
global_step: 7744, epoch: 94, loss: 0.619048
global_step: 7745, epoch: 94, loss: 0.609724
global_step: 7746, epoch: 94, loss: 0.597771
global_step: 7747, epoch: 94, loss: 0.650668
global_step: 7748, epoch: 94, loss: 0.639769
global_step: 7749, epoch: 94, loss: 0.738387
global_step: 7750, epoch: 94, loss: 0.701451
global_step: 7751, epoch: 94, loss: 0.764108
global_step: 7752, epoch: 94, loss: 0.708342
global_step: 7753, epoch: 94, loss: 0.621604
global_step: 7754, epoch: 94, loss: 0.812120
global_step: 7755, epoch: 94, loss: 0.693769
global_step: 7756, epoch: 94, loss: 0.646344
global_step: 7757, epoch: 94, loss: 0.535210
global_step: 7758, epoch: 94, loss: 0.654880
global_step: 7759, epoch: 94, loss: 0.735257
global_step: 7760, epoch: 94, loss: 0.293255
epoch: 94
train	acc: 0.8785	macro: p 0.8936, r 0.6884, f1: 0.7166	micro: p 0.8785, r 0.8785, f1 0.8785	weighted_f1:0.8661
dev	acc: 0.5428	macro: p 0.3368, r 0.3048, f1: 0.2986	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4930
test	acc: 0.5958	macro: p 0.3589, r 0.3211, f1: 0.3232	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5552
global_step: 7761, epoch: 95, loss: 0.575064
global_step: 7762, epoch: 95, loss: 0.701075
global_step: 7763, epoch: 95, loss: 0.654268
global_step: 7764, epoch: 95, loss: 0.611972
global_step: 7765, epoch: 95, loss: 0.622845
global_step: 7766, epoch: 95, loss: 0.672697
global_step: 7767, epoch: 95, loss: 0.695352
global_step: 7768, epoch: 95, loss: 0.621553
global_step: 7769, epoch: 95, loss: 0.652322
global_step: 7770, epoch: 95, loss: 0.613155
global_step: 7771, epoch: 95, loss: 0.668283
global_step: 7772, epoch: 95, loss: 0.684863
global_step: 7773, epoch: 95, loss: 0.622544
global_step: 7774, epoch: 95, loss: 0.770634
global_step: 7775, epoch: 95, loss: 0.670767
global_step: 7776, epoch: 95, loss: 0.574524
global_step: 7777, epoch: 95, loss: 0.630366
global_step: 7778, epoch: 95, loss: 0.545111
global_step: 7779, epoch: 95, loss: 0.705895
global_step: 7780, epoch: 95, loss: 0.646922
global_step: 7781, epoch: 95, loss: 0.572657
global_step: 7782, epoch: 95, loss: 0.635155
global_step: 7783, epoch: 95, loss: 0.612889
global_step: 7784, epoch: 95, loss: 0.682843
global_step: 7785, epoch: 95, loss: 0.744548
global_step: 7786, epoch: 95, loss: 0.754776
global_step: 7787, epoch: 95, loss: 0.603687
global_step: 7788, epoch: 95, loss: 0.703061
global_step: 7789, epoch: 95, loss: 0.599971
global_step: 7790, epoch: 95, loss: 0.701986
global_step: 7791, epoch: 95, loss: 0.652587
global_step: 7792, epoch: 95, loss: 0.736569
global_step: 7793, epoch: 95, loss: 0.657314
global_step: 7794, epoch: 95, loss: 0.641151
global_step: 7795, epoch: 95, loss: 0.602494
global_step: 7796, epoch: 95, loss: 0.605311
global_step: 7797, epoch: 95, loss: 0.628979
global_step: 7798, epoch: 95, loss: 0.616974
global_step: 7799, epoch: 95, loss: 0.595386
global_step: 7800, epoch: 95, loss: 0.741286
epoch: 95
train	acc: 0.8811	macro: p 0.8965, r 0.6945, f1: 0.7255	micro: p 0.8811, r 0.8811, f1 0.8811	weighted_f1:0.8693
dev	acc: 0.5419	macro: p 0.3285, r 0.3024, f1: 0.2934	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4882
test	acc: 0.5992	macro: p 0.3672, r 0.3214, f1: 0.3229	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5559
global_step: 7801, epoch: 96, loss: 0.692158
global_step: 7802, epoch: 96, loss: 0.733250
global_step: 7803, epoch: 96, loss: 0.669816
global_step: 7804, epoch: 96, loss: 0.614541
global_step: 7805, epoch: 96, loss: 0.718222
global_step: 7806, epoch: 96, loss: 0.588446
global_step: 7807, epoch: 96, loss: 0.589122
global_step: 7808, epoch: 96, loss: 0.585785
global_step: 7809, epoch: 96, loss: 0.660615
global_step: 7810, epoch: 96, loss: 0.516811
global_step: 7811, epoch: 96, loss: 0.594646
global_step: 7812, epoch: 96, loss: 0.659750
global_step: 7813, epoch: 96, loss: 0.753184
global_step: 7814, epoch: 96, loss: 0.663335
global_step: 7815, epoch: 96, loss: 0.655780
global_step: 7816, epoch: 96, loss: 0.599759
global_step: 7817, epoch: 96, loss: 0.641584
global_step: 7818, epoch: 96, loss: 0.743949
global_step: 7819, epoch: 96, loss: 0.657645
global_step: 7820, epoch: 96, loss: 0.584057
global_step: 7821, epoch: 96, loss: 0.549773
global_step: 7822, epoch: 96, loss: 0.765480
global_step: 7823, epoch: 96, loss: 0.591401
global_step: 7824, epoch: 96, loss: 0.671008
global_step: 7825, epoch: 96, loss: 0.629720
global_step: 7826, epoch: 96, loss: 0.673833
global_step: 7827, epoch: 96, loss: 0.680575
global_step: 7828, epoch: 96, loss: 0.587164
global_step: 7829, epoch: 96, loss: 0.589310
global_step: 7830, epoch: 96, loss: 0.531738
global_step: 7831, epoch: 96, loss: 0.693158
global_step: 7832, epoch: 96, loss: 0.643247
global_step: 7833, epoch: 96, loss: 0.601086
global_step: 7834, epoch: 96, loss: 0.703588
global_step: 7835, epoch: 96, loss: 0.670672
global_step: 7836, epoch: 96, loss: 0.616260
global_step: 7837, epoch: 96, loss: 0.645694
global_step: 7838, epoch: 96, loss: 0.719591
global_step: 7839, epoch: 96, loss: 0.702637
global_step: 7840, epoch: 96, loss: 0.567897
epoch: 96
train	acc: 0.8822	macro: p 0.8960, r 0.6976, f1: 0.7257	micro: p 0.8822, r 0.8822, f1 0.8822	weighted_f1:0.8704
dev	acc: 0.5446	macro: p 0.3351, r 0.3076, f1: 0.3040	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4963
test	acc: 0.5977	macro: p 0.3569, r 0.3215, f1: 0.3252	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5568
global_step: 7841, epoch: 97, loss: 0.582021
global_step: 7842, epoch: 97, loss: 0.580926
global_step: 7843, epoch: 97, loss: 0.478126
global_step: 7844, epoch: 97, loss: 0.657696
global_step: 7845, epoch: 97, loss: 0.671529
global_step: 7846, epoch: 97, loss: 0.669442
global_step: 7847, epoch: 97, loss: 0.667392
global_step: 7848, epoch: 97, loss: 0.617567
global_step: 7849, epoch: 97, loss: 0.651065
global_step: 7850, epoch: 97, loss: 0.631896
global_step: 7851, epoch: 97, loss: 0.629993
global_step: 7852, epoch: 97, loss: 0.580563
global_step: 7853, epoch: 97, loss: 0.705494
global_step: 7854, epoch: 97, loss: 0.581876
global_step: 7855, epoch: 97, loss: 0.716052
global_step: 7856, epoch: 97, loss: 0.595817
global_step: 7857, epoch: 97, loss: 0.696170
global_step: 7858, epoch: 97, loss: 0.622913
global_step: 7859, epoch: 97, loss: 0.598124
global_step: 7860, epoch: 97, loss: 0.581557
global_step: 7861, epoch: 97, loss: 0.626451
global_step: 7862, epoch: 97, loss: 0.791394
global_step: 7863, epoch: 97, loss: 0.700537
global_step: 7864, epoch: 97, loss: 0.786429
global_step: 7865, epoch: 97, loss: 0.608348
global_step: 7866, epoch: 97, loss: 0.584997
global_step: 7867, epoch: 97, loss: 0.541489
global_step: 7868, epoch: 97, loss: 0.577429
global_step: 7869, epoch: 97, loss: 0.613933
global_step: 7870, epoch: 97, loss: 0.605703
global_step: 7871, epoch: 97, loss: 0.630498
global_step: 7872, epoch: 97, loss: 0.594508
global_step: 7873, epoch: 97, loss: 0.624385
global_step: 7874, epoch: 97, loss: 0.534945
global_step: 7875, epoch: 97, loss: 0.599957
global_step: 7876, epoch: 97, loss: 0.674127
global_step: 7877, epoch: 97, loss: 0.624188
global_step: 7878, epoch: 97, loss: 0.656175
global_step: 7879, epoch: 97, loss: 0.753441
global_step: 7880, epoch: 97, loss: 0.396459
epoch: 97
train	acc: 0.8857	macro: p 0.9023, r 0.7094, f1: 0.7453	micro: p 0.8857, r 0.8857, f1 0.8857	weighted_f1:0.8757
dev	acc: 0.5401	macro: p 0.3354, r 0.3003, f1: 0.2929	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4880
test	acc: 0.5962	macro: p 0.3708, r 0.3212, f1: 0.3237	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5555
global_step: 7881, epoch: 98, loss: 0.604561
global_step: 7882, epoch: 98, loss: 0.739722
global_step: 7883, epoch: 98, loss: 0.684502
global_step: 7884, epoch: 98, loss: 0.679476
global_step: 7885, epoch: 98, loss: 0.542257
global_step: 7886, epoch: 98, loss: 0.677507
global_step: 7887, epoch: 98, loss: 0.647712
global_step: 7888, epoch: 98, loss: 0.704388
global_step: 7889, epoch: 98, loss: 0.687175
global_step: 7890, epoch: 98, loss: 0.654815
global_step: 7891, epoch: 98, loss: 0.590105
global_step: 7892, epoch: 98, loss: 0.596361
global_step: 7893, epoch: 98, loss: 0.624565
global_step: 7894, epoch: 98, loss: 0.641915
global_step: 7895, epoch: 98, loss: 0.759124
global_step: 7896, epoch: 98, loss: 0.664946
global_step: 7897, epoch: 98, loss: 0.686985
global_step: 7898, epoch: 98, loss: 0.736820
global_step: 7899, epoch: 98, loss: 0.729059
global_step: 7900, epoch: 98, loss: 0.646781
global_step: 7901, epoch: 98, loss: 0.564035
global_step: 7902, epoch: 98, loss: 0.583622
global_step: 7903, epoch: 98, loss: 0.550492
global_step: 7904, epoch: 98, loss: 0.650233
global_step: 7905, epoch: 98, loss: 0.629826
global_step: 7906, epoch: 98, loss: 0.679684
global_step: 7907, epoch: 98, loss: 0.700833
global_step: 7908, epoch: 98, loss: 0.610417
global_step: 7909, epoch: 98, loss: 0.587061
global_step: 7910, epoch: 98, loss: 0.563624
global_step: 7911, epoch: 98, loss: 0.624117
global_step: 7912, epoch: 98, loss: 0.578477
global_step: 7913, epoch: 98, loss: 0.564049
global_step: 7914, epoch: 98, loss: 0.583611
global_step: 7915, epoch: 98, loss: 0.673645
global_step: 7916, epoch: 98, loss: 0.608857
global_step: 7917, epoch: 98, loss: 0.582942
global_step: 7918, epoch: 98, loss: 0.667426
global_step: 7919, epoch: 98, loss: 0.632449
global_step: 7920, epoch: 98, loss: 0.424380
epoch: 98
train	acc: 0.8826	macro: p 0.8966, r 0.7022, f1: 0.7334	micro: p 0.8826, r 0.8826, f1 0.8826	weighted_f1:0.8716
dev	acc: 0.5428	macro: p 0.3458, r 0.3058, f1: 0.2986	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4906
test	acc: 0.5943	macro: p 0.3612, r 0.3189, f1: 0.3214	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5515
global_step: 7921, epoch: 99, loss: 0.600175
global_step: 7922, epoch: 99, loss: 0.672505
global_step: 7923, epoch: 99, loss: 0.578457
global_step: 7924, epoch: 99, loss: 0.632081
global_step: 7925, epoch: 99, loss: 0.656860
global_step: 7926, epoch: 99, loss: 0.680863
global_step: 7927, epoch: 99, loss: 0.602673
global_step: 7928, epoch: 99, loss: 0.612363
global_step: 7929, epoch: 99, loss: 0.660088
global_step: 7930, epoch: 99, loss: 0.726839
global_step: 7931, epoch: 99, loss: 0.602913
global_step: 7932, epoch: 99, loss: 0.587513
global_step: 7933, epoch: 99, loss: 0.605520
global_step: 7934, epoch: 99, loss: 0.636136
global_step: 7935, epoch: 99, loss: 0.592343
global_step: 7936, epoch: 99, loss: 0.575871
global_step: 7937, epoch: 99, loss: 0.736169
global_step: 7938, epoch: 99, loss: 0.686616
global_step: 7939, epoch: 99, loss: 0.658335
global_step: 7940, epoch: 99, loss: 0.526116
global_step: 7941, epoch: 99, loss: 0.676854
global_step: 7942, epoch: 99, loss: 0.611148
global_step: 7943, epoch: 99, loss: 0.669078
global_step: 7944, epoch: 99, loss: 0.768200
global_step: 7945, epoch: 99, loss: 0.634312
global_step: 7946, epoch: 99, loss: 0.606835
global_step: 7947, epoch: 99, loss: 0.595907
global_step: 7948, epoch: 99, loss: 0.643324
global_step: 7949, epoch: 99, loss: 0.598266
global_step: 7950, epoch: 99, loss: 0.574507
global_step: 7951, epoch: 99, loss: 0.575727
global_step: 7952, epoch: 99, loss: 0.609130
global_step: 7953, epoch: 99, loss: 0.669338
global_step: 7954, epoch: 99, loss: 0.562259
global_step: 7955, epoch: 99, loss: 0.667501
global_step: 7956, epoch: 99, loss: 0.711064
global_step: 7957, epoch: 99, loss: 0.579942
global_step: 7958, epoch: 99, loss: 0.668090
global_step: 7959, epoch: 99, loss: 0.681409
global_step: 7960, epoch: 99, loss: 1.389666
epoch: 99
train	acc: 0.8922	macro: p 0.9050, r 0.7297, f1: 0.7683	micro: p 0.8922, r 0.8922, f1 0.8922	weighted_f1:0.8841
dev	acc: 0.5383	macro: p 0.3335, r 0.3004, f1: 0.2985	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4894
test	acc: 0.5946	macro: p 0.3589, r 0.3168, f1: 0.3227	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5528
global_step: 7961, epoch: 100, loss: 0.592495
global_step: 7962, epoch: 100, loss: 0.730507
global_step: 7963, epoch: 100, loss: 0.644570
global_step: 7964, epoch: 100, loss: 0.568952
global_step: 7965, epoch: 100, loss: 0.701865
global_step: 7966, epoch: 100, loss: 0.574148
global_step: 7967, epoch: 100, loss: 0.561123
global_step: 7968, epoch: 100, loss: 0.625176
global_step: 7969, epoch: 100, loss: 0.657506
global_step: 7970, epoch: 100, loss: 0.593057
global_step: 7971, epoch: 100, loss: 0.583037
global_step: 7972, epoch: 100, loss: 0.600742
global_step: 7973, epoch: 100, loss: 0.484014
global_step: 7974, epoch: 100, loss: 0.645113
global_step: 7975, epoch: 100, loss: 0.661621
global_step: 7976, epoch: 100, loss: 0.592986
global_step: 7977, epoch: 100, loss: 0.639212
global_step: 7978, epoch: 100, loss: 0.631699
global_step: 7979, epoch: 100, loss: 0.670183
global_step: 7980, epoch: 100, loss: 0.597739
global_step: 7981, epoch: 100, loss: 0.611208
global_step: 7982, epoch: 100, loss: 0.650398
global_step: 7983, epoch: 100, loss: 0.702327
global_step: 7984, epoch: 100, loss: 0.645881
global_step: 7985, epoch: 100, loss: 0.602828
global_step: 7986, epoch: 100, loss: 0.613771
global_step: 7987, epoch: 100, loss: 0.708844
global_step: 7988, epoch: 100, loss: 0.637029
global_step: 7989, epoch: 100, loss: 0.538893
global_step: 7990, epoch: 100, loss: 0.622366
global_step: 7991, epoch: 100, loss: 0.585009
global_step: 7992, epoch: 100, loss: 0.589831
global_step: 7993, epoch: 100, loss: 0.598095
global_step: 7994, epoch: 100, loss: 0.663712
global_step: 7995, epoch: 100, loss: 0.556359
global_step: 7996, epoch: 100, loss: 0.562806
global_step: 7997, epoch: 100, loss: 0.631365
global_step: 7998, epoch: 100, loss: 0.639950
global_step: 7999, epoch: 100, loss: 0.610196
global_step: 8000, epoch: 100, loss: 0.175498
epoch: 100
train	acc: 0.8891	macro: p 0.9061, r 0.7215, f1: 0.7622	micro: p 0.8891, r 0.8891, f1 0.8891	weighted_f1:0.8802
dev	acc: 0.5374	macro: p 0.3228, r 0.2972, f1: 0.2883	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4821
test	acc: 0.5969	macro: p 0.3662, r 0.3159, f1: 0.3193	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5510
BEST MODEL epoch: 62
train	acc: 0.7889 macro_p: 0.6822 macro_r: 0.5327 macro_f1: 0.5333 micro_p: 0.7889 micro_r: 0.7889 micro_f1: 0.7889 weighted_f1: 0.7634
dev	acc: 0.5528 macro_p: 0.3466 macro_r: 0.3171 macro_f1: 0.3110 micro_p: 0.5528 micro_r: 0.5528 micro_f1: 0.5528 weighted_f1: 0.5059
test	acc: 0.5939 macro_p: 0.3502 macro_r: 0.3178 macro_f1: 0.3174 micro_p: 0.5939 micro_r: 0.5939 micro_f1: 0.5939 weighted_f1: 0.5529
==========ROUND 3==========
global_step: 8001, epoch: 1, loss: 1.901882
global_step: 8002, epoch: 1, loss: 1.887196
global_step: 8003, epoch: 1, loss: 1.842046
global_step: 8004, epoch: 1, loss: 1.839720
global_step: 8005, epoch: 1, loss: 1.858812
global_step: 8006, epoch: 1, loss: 1.823295
global_step: 8007, epoch: 1, loss: 1.790987
global_step: 8008, epoch: 1, loss: 1.769257
global_step: 8009, epoch: 1, loss: 1.757125
global_step: 8010, epoch: 1, loss: 1.691995
global_step: 8011, epoch: 1, loss: 1.764955
global_step: 8012, epoch: 1, loss: 1.758304
global_step: 8013, epoch: 1, loss: 1.756357
global_step: 8014, epoch: 1, loss: 1.726008
global_step: 8015, epoch: 1, loss: 1.726620
global_step: 8016, epoch: 1, loss: 1.645902
global_step: 8017, epoch: 1, loss: 1.631336
global_step: 8018, epoch: 1, loss: 1.681423
global_step: 8019, epoch: 1, loss: 1.653397
global_step: 8020, epoch: 1, loss: 1.694159
global_step: 8021, epoch: 1, loss: 1.639870
global_step: 8022, epoch: 1, loss: 1.629138
global_step: 8023, epoch: 1, loss: 1.588308
global_step: 8024, epoch: 1, loss: 1.655498
global_step: 8025, epoch: 1, loss: 1.644436
global_step: 8026, epoch: 1, loss: 1.553807
global_step: 8027, epoch: 1, loss: 1.606055
global_step: 8028, epoch: 1, loss: 1.601501
global_step: 8029, epoch: 1, loss: 1.584834
global_step: 8030, epoch: 1, loss: 1.509323
global_step: 8031, epoch: 1, loss: 1.603257
global_step: 8032, epoch: 1, loss: 1.587726
global_step: 8033, epoch: 1, loss: 1.548843
global_step: 8034, epoch: 1, loss: 1.614914
global_step: 8035, epoch: 1, loss: 1.529559
global_step: 8036, epoch: 1, loss: 1.571900
global_step: 8037, epoch: 1, loss: 1.498134
global_step: 8038, epoch: 1, loss: 1.598475
global_step: 8039, epoch: 1, loss: 1.602479
global_step: 8040, epoch: 1, loss: 2.032744
epoch: 1
train	acc: 0.4840	macro: p 0.1275, r 0.1552, f1: 0.1154	micro: p 0.4840, r 0.4840, f1 0.4840	weighted_f1:0.3350
dev	acc: 0.4355	macro: p 0.1018, r 0.1548, f1: 0.1064	micro: p 0.4355, r 0.4355, f1 0.4355	weighted_f1:0.2795
test	acc: 0.4927	macro: p 0.1286, r 0.1569, f1: 0.1191	micro: p 0.4927, r 0.4927, f1 0.4927	weighted_f1:0.3447
New best model!
global_step: 8041, epoch: 2, loss: 1.413652
global_step: 8042, epoch: 2, loss: 1.503181
global_step: 8043, epoch: 2, loss: 1.609885
global_step: 8044, epoch: 2, loss: 1.479672
global_step: 8045, epoch: 2, loss: 1.522534
global_step: 8046, epoch: 2, loss: 1.594576
global_step: 8047, epoch: 2, loss: 1.628627
global_step: 8048, epoch: 2, loss: 1.545871
global_step: 8049, epoch: 2, loss: 1.582974
global_step: 8050, epoch: 2, loss: 1.529906
global_step: 8051, epoch: 2, loss: 1.611710
global_step: 8052, epoch: 2, loss: 1.549281
global_step: 8053, epoch: 2, loss: 1.472142
global_step: 8054, epoch: 2, loss: 1.490896
global_step: 8055, epoch: 2, loss: 1.541895
global_step: 8056, epoch: 2, loss: 1.503366
global_step: 8057, epoch: 2, loss: 1.543886
global_step: 8058, epoch: 2, loss: 1.521545
global_step: 8059, epoch: 2, loss: 1.534614
global_step: 8060, epoch: 2, loss: 1.509765
global_step: 8061, epoch: 2, loss: 1.524941
global_step: 8062, epoch: 2, loss: 1.483874
global_step: 8063, epoch: 2, loss: 1.517634
global_step: 8064, epoch: 2, loss: 1.482476
global_step: 8065, epoch: 2, loss: 1.530302
global_step: 8066, epoch: 2, loss: 1.503023
global_step: 8067, epoch: 2, loss: 1.526746
global_step: 8068, epoch: 2, loss: 1.462359
global_step: 8069, epoch: 2, loss: 1.585203
global_step: 8070, epoch: 2, loss: 1.433405
global_step: 8071, epoch: 2, loss: 1.514705
global_step: 8072, epoch: 2, loss: 1.533515
global_step: 8073, epoch: 2, loss: 1.558876
global_step: 8074, epoch: 2, loss: 1.308699
global_step: 8075, epoch: 2, loss: 1.463666
global_step: 8076, epoch: 2, loss: 1.623295
global_step: 8077, epoch: 2, loss: 1.535448
global_step: 8078, epoch: 2, loss: 1.449997
global_step: 8079, epoch: 2, loss: 1.484817
global_step: 8080, epoch: 2, loss: 1.205149
epoch: 2
train	acc: 0.5114	macro: p 0.3372, r 0.1822, f1: 0.1550	micro: p 0.5114, r 0.5114, f1 0.5114	weighted_f1:0.3853
dev	acc: 0.4662	macro: p 0.2622, r 0.1872, f1: 0.1527	micro: p 0.4662, r 0.4662, f1 0.4662	weighted_f1:0.3325
test	acc: 0.5211	macro: p 0.2685, r 0.1893, f1: 0.1653	micro: p 0.5211, r 0.5211, f1 0.5211	weighted_f1:0.3966
New best model!
global_step: 8081, epoch: 3, loss: 1.487727
global_step: 8082, epoch: 3, loss: 1.496857
global_step: 8083, epoch: 3, loss: 1.538729
global_step: 8084, epoch: 3, loss: 1.518995
global_step: 8085, epoch: 3, loss: 1.559814
global_step: 8086, epoch: 3, loss: 1.357438
global_step: 8087, epoch: 3, loss: 1.470582
global_step: 8088, epoch: 3, loss: 1.513676
global_step: 8089, epoch: 3, loss: 1.461615
global_step: 8090, epoch: 3, loss: 1.491441
global_step: 8091, epoch: 3, loss: 1.440408
global_step: 8092, epoch: 3, loss: 1.508790
global_step: 8093, epoch: 3, loss: 1.445577
global_step: 8094, epoch: 3, loss: 1.447558
global_step: 8095, epoch: 3, loss: 1.407961
global_step: 8096, epoch: 3, loss: 1.423589
global_step: 8097, epoch: 3, loss: 1.470788
global_step: 8098, epoch: 3, loss: 1.523390
global_step: 8099, epoch: 3, loss: 1.454787
global_step: 8100, epoch: 3, loss: 1.481730
global_step: 8101, epoch: 3, loss: 1.530549
global_step: 8102, epoch: 3, loss: 1.435666
global_step: 8103, epoch: 3, loss: 1.390584
global_step: 8104, epoch: 3, loss: 1.486910
global_step: 8105, epoch: 3, loss: 1.473311
global_step: 8106, epoch: 3, loss: 1.412855
global_step: 8107, epoch: 3, loss: 1.541379
global_step: 8108, epoch: 3, loss: 1.463738
global_step: 8109, epoch: 3, loss: 1.464149
global_step: 8110, epoch: 3, loss: 1.417394
global_step: 8111, epoch: 3, loss: 1.459177
global_step: 8112, epoch: 3, loss: 1.406972
global_step: 8113, epoch: 3, loss: 1.453749
global_step: 8114, epoch: 3, loss: 1.367036
global_step: 8115, epoch: 3, loss: 1.484218
global_step: 8116, epoch: 3, loss: 1.373046
global_step: 8117, epoch: 3, loss: 1.400493
global_step: 8118, epoch: 3, loss: 1.513196
global_step: 8119, epoch: 3, loss: 1.443662
global_step: 8120, epoch: 3, loss: 1.222054
epoch: 3
train	acc: 0.5409	macro: p 0.2902, r 0.2175, f1: 0.2008	micro: p 0.5409, r 0.5409, f1 0.5409	weighted_f1:0.4392
dev	acc: 0.4815	macro: p 0.1958, r 0.2132, f1: 0.1835	micro: p 0.4815, r 0.4815, f1 0.4815	weighted_f1:0.3700
test	acc: 0.5487	macro: p 0.2878, r 0.2247, f1: 0.2054	micro: p 0.5487, r 0.5487, f1 0.5487	weighted_f1:0.4443
New best model!
global_step: 8121, epoch: 4, loss: 1.415772
global_step: 8122, epoch: 4, loss: 1.524496
global_step: 8123, epoch: 4, loss: 1.568577
global_step: 8124, epoch: 4, loss: 1.459474
global_step: 8125, epoch: 4, loss: 1.359504
global_step: 8126, epoch: 4, loss: 1.394459
global_step: 8127, epoch: 4, loss: 1.437749
global_step: 8128, epoch: 4, loss: 1.354700
global_step: 8129, epoch: 4, loss: 1.393056
global_step: 8130, epoch: 4, loss: 1.480294
global_step: 8131, epoch: 4, loss: 1.417553
global_step: 8132, epoch: 4, loss: 1.422796
global_step: 8133, epoch: 4, loss: 1.378336
global_step: 8134, epoch: 4, loss: 1.408511
global_step: 8135, epoch: 4, loss: 1.461019
global_step: 8136, epoch: 4, loss: 1.424536
global_step: 8137, epoch: 4, loss: 1.422834
global_step: 8138, epoch: 4, loss: 1.415421
global_step: 8139, epoch: 4, loss: 1.452361
global_step: 8140, epoch: 4, loss: 1.341710
global_step: 8141, epoch: 4, loss: 1.392027
global_step: 8142, epoch: 4, loss: 1.442509
global_step: 8143, epoch: 4, loss: 1.443656
global_step: 8144, epoch: 4, loss: 1.380734
global_step: 8145, epoch: 4, loss: 1.409885
global_step: 8146, epoch: 4, loss: 1.321899
global_step: 8147, epoch: 4, loss: 1.439327
global_step: 8148, epoch: 4, loss: 1.447203
global_step: 8149, epoch: 4, loss: 1.457506
global_step: 8150, epoch: 4, loss: 1.417224
global_step: 8151, epoch: 4, loss: 1.365886
global_step: 8152, epoch: 4, loss: 1.376597
global_step: 8153, epoch: 4, loss: 1.486965
global_step: 8154, epoch: 4, loss: 1.508680
global_step: 8155, epoch: 4, loss: 1.416333
global_step: 8156, epoch: 4, loss: 1.399308
global_step: 8157, epoch: 4, loss: 1.380322
global_step: 8158, epoch: 4, loss: 1.443632
global_step: 8159, epoch: 4, loss: 1.346582
global_step: 8160, epoch: 4, loss: 0.886181
epoch: 4
train	acc: 0.5536	macro: p 0.3086, r 0.2318, f1: 0.2157	micro: p 0.5536, r 0.5536, f1 0.5536	weighted_f1:0.4600
dev	acc: 0.4905	macro: p 0.2482, r 0.2255, f1: 0.1925	micro: p 0.4905, r 0.4905, f1 0.4905	weighted_f1:0.3852
test	acc: 0.5552	macro: p 0.2859, r 0.2344, f1: 0.2134	micro: p 0.5552, r 0.5552, f1 0.5552	weighted_f1:0.4579
New best model!
global_step: 8161, epoch: 5, loss: 1.445252
global_step: 8162, epoch: 5, loss: 1.386717
global_step: 8163, epoch: 5, loss: 1.383500
global_step: 8164, epoch: 5, loss: 1.461184
global_step: 8165, epoch: 5, loss: 1.345674
global_step: 8166, epoch: 5, loss: 1.407025
global_step: 8167, epoch: 5, loss: 1.400240
global_step: 8168, epoch: 5, loss: 1.351533
global_step: 8169, epoch: 5, loss: 1.386689
global_step: 8170, epoch: 5, loss: 1.316148
global_step: 8171, epoch: 5, loss: 1.317320
global_step: 8172, epoch: 5, loss: 1.414250
global_step: 8173, epoch: 5, loss: 1.623880
global_step: 8174, epoch: 5, loss: 1.411360
global_step: 8175, epoch: 5, loss: 1.494570
global_step: 8176, epoch: 5, loss: 1.394653
global_step: 8177, epoch: 5, loss: 1.463240
global_step: 8178, epoch: 5, loss: 1.502700
global_step: 8179, epoch: 5, loss: 1.330196
global_step: 8180, epoch: 5, loss: 1.450255
global_step: 8181, epoch: 5, loss: 1.404337
global_step: 8182, epoch: 5, loss: 1.378950
global_step: 8183, epoch: 5, loss: 1.442538
global_step: 8184, epoch: 5, loss: 1.386101
global_step: 8185, epoch: 5, loss: 1.412418
global_step: 8186, epoch: 5, loss: 1.395307
global_step: 8187, epoch: 5, loss: 1.382704
global_step: 8188, epoch: 5, loss: 1.289230
global_step: 8189, epoch: 5, loss: 1.385404
global_step: 8190, epoch: 5, loss: 1.439985
global_step: 8191, epoch: 5, loss: 1.425271
global_step: 8192, epoch: 5, loss: 1.376236
global_step: 8193, epoch: 5, loss: 1.394232
global_step: 8194, epoch: 5, loss: 1.394337
global_step: 8195, epoch: 5, loss: 1.337873
global_step: 8196, epoch: 5, loss: 1.311365
global_step: 8197, epoch: 5, loss: 1.307136
global_step: 8198, epoch: 5, loss: 1.395862
global_step: 8199, epoch: 5, loss: 1.388425
global_step: 8200, epoch: 5, loss: 0.918300
epoch: 5
train	acc: 0.5621	macro: p 0.2859, r 0.2466, f1: 0.2380	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.4807
dev	acc: 0.5068	macro: p 0.2619, r 0.2425, f1: 0.2187	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.4134
test	acc: 0.5621	macro: p 0.2688, r 0.2469, f1: 0.2339	micro: p 0.5621, r 0.5621, f1 0.5621	weighted_f1:0.4792
New best model!
global_step: 8201, epoch: 6, loss: 1.375182
global_step: 8202, epoch: 6, loss: 1.442012
global_step: 8203, epoch: 6, loss: 1.391885
global_step: 8204, epoch: 6, loss: 1.438703
global_step: 8205, epoch: 6, loss: 1.333852
global_step: 8206, epoch: 6, loss: 1.324862
global_step: 8207, epoch: 6, loss: 1.470749
global_step: 8208, epoch: 6, loss: 1.412624
global_step: 8209, epoch: 6, loss: 1.421883
global_step: 8210, epoch: 6, loss: 1.506113
global_step: 8211, epoch: 6, loss: 1.411902
global_step: 8212, epoch: 6, loss: 1.397524
global_step: 8213, epoch: 6, loss: 1.390238
global_step: 8214, epoch: 6, loss: 1.354454
global_step: 8215, epoch: 6, loss: 1.449660
global_step: 8216, epoch: 6, loss: 1.351446
global_step: 8217, epoch: 6, loss: 1.370735
global_step: 8218, epoch: 6, loss: 1.423701
global_step: 8219, epoch: 6, loss: 1.226673
global_step: 8220, epoch: 6, loss: 1.394987
global_step: 8221, epoch: 6, loss: 1.278963
global_step: 8222, epoch: 6, loss: 1.314987
global_step: 8223, epoch: 6, loss: 1.416242
global_step: 8224, epoch: 6, loss: 1.375854
global_step: 8225, epoch: 6, loss: 1.278812
global_step: 8226, epoch: 6, loss: 1.263238
global_step: 8227, epoch: 6, loss: 1.350243
global_step: 8228, epoch: 6, loss: 1.343512
global_step: 8229, epoch: 6, loss: 1.341503
global_step: 8230, epoch: 6, loss: 1.384503
global_step: 8231, epoch: 6, loss: 1.339889
global_step: 8232, epoch: 6, loss: 1.422119
global_step: 8233, epoch: 6, loss: 1.365073
global_step: 8234, epoch: 6, loss: 1.417255
global_step: 8235, epoch: 6, loss: 1.384819
global_step: 8236, epoch: 6, loss: 1.288279
global_step: 8237, epoch: 6, loss: 1.450700
global_step: 8238, epoch: 6, loss: 1.388727
global_step: 8239, epoch: 6, loss: 1.331510
global_step: 8240, epoch: 6, loss: 1.227447
epoch: 6
train	acc: 0.5723	macro: p 0.2968, r 0.2599, f1: 0.2559	micro: p 0.5723, r 0.5723, f1 0.5723	weighted_f1:0.4980
dev	acc: 0.5149	macro: p 0.2652, r 0.2513, f1: 0.2312	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4276
test	acc: 0.5640	macro: p 0.2681, r 0.2513, f1: 0.2418	micro: p 0.5640, r 0.5640, f1 0.5640	weighted_f1:0.4873
New best model!
global_step: 8241, epoch: 7, loss: 1.445834
global_step: 8242, epoch: 7, loss: 1.430442
global_step: 8243, epoch: 7, loss: 1.339451
global_step: 8244, epoch: 7, loss: 1.393815
global_step: 8245, epoch: 7, loss: 1.317485
global_step: 8246, epoch: 7, loss: 1.365669
global_step: 8247, epoch: 7, loss: 1.411982
global_step: 8248, epoch: 7, loss: 1.302566
global_step: 8249, epoch: 7, loss: 1.305602
global_step: 8250, epoch: 7, loss: 1.337715
global_step: 8251, epoch: 7, loss: 1.370554
global_step: 8252, epoch: 7, loss: 1.424030
global_step: 8253, epoch: 7, loss: 1.396282
global_step: 8254, epoch: 7, loss: 1.377832
global_step: 8255, epoch: 7, loss: 1.328034
global_step: 8256, epoch: 7, loss: 1.360061
global_step: 8257, epoch: 7, loss: 1.292230
global_step: 8258, epoch: 7, loss: 1.277331
global_step: 8259, epoch: 7, loss: 1.361288
global_step: 8260, epoch: 7, loss: 1.313198
global_step: 8261, epoch: 7, loss: 1.407145
global_step: 8262, epoch: 7, loss: 1.441291
global_step: 8263, epoch: 7, loss: 1.370582
global_step: 8264, epoch: 7, loss: 1.441960
global_step: 8265, epoch: 7, loss: 1.307452
global_step: 8266, epoch: 7, loss: 1.388625
global_step: 8267, epoch: 7, loss: 1.482152
global_step: 8268, epoch: 7, loss: 1.464885
global_step: 8269, epoch: 7, loss: 1.363850
global_step: 8270, epoch: 7, loss: 1.309295
global_step: 8271, epoch: 7, loss: 1.230001
global_step: 8272, epoch: 7, loss: 1.280308
global_step: 8273, epoch: 7, loss: 1.290452
global_step: 8274, epoch: 7, loss: 1.508672
global_step: 8275, epoch: 7, loss: 1.409765
global_step: 8276, epoch: 7, loss: 1.289070
global_step: 8277, epoch: 7, loss: 1.392339
global_step: 8278, epoch: 7, loss: 1.400577
global_step: 8279, epoch: 7, loss: 1.308180
global_step: 8280, epoch: 7, loss: 1.338086
epoch: 7
train	acc: 0.5790	macro: p 0.2873, r 0.2760, f1: 0.2715	micro: p 0.5790, r 0.5790, f1 0.5790	weighted_f1:0.5136
dev	acc: 0.5113	macro: p 0.2422, r 0.2537, f1: 0.2328	micro: p 0.5113, r 0.5113, f1 0.5113	weighted_f1:0.4299
test	acc: 0.5670	macro: p 0.2626, r 0.2641, f1: 0.2535	micro: p 0.5670, r 0.5670, f1 0.5670	weighted_f1:0.4987
New best model!
global_step: 8281, epoch: 8, loss: 1.442405
global_step: 8282, epoch: 8, loss: 1.410685
global_step: 8283, epoch: 8, loss: 1.264472
global_step: 8284, epoch: 8, loss: 1.276340
global_step: 8285, epoch: 8, loss: 1.319807
global_step: 8286, epoch: 8, loss: 1.251267
global_step: 8287, epoch: 8, loss: 1.343177
global_step: 8288, epoch: 8, loss: 1.378078
global_step: 8289, epoch: 8, loss: 1.339739
global_step: 8290, epoch: 8, loss: 1.265922
global_step: 8291, epoch: 8, loss: 1.386743
global_step: 8292, epoch: 8, loss: 1.447054
global_step: 8293, epoch: 8, loss: 1.281174
global_step: 8294, epoch: 8, loss: 1.297179
global_step: 8295, epoch: 8, loss: 1.380487
global_step: 8296, epoch: 8, loss: 1.314423
global_step: 8297, epoch: 8, loss: 1.481576
global_step: 8298, epoch: 8, loss: 1.347808
global_step: 8299, epoch: 8, loss: 1.351958
global_step: 8300, epoch: 8, loss: 1.284637
global_step: 8301, epoch: 8, loss: 1.351409
global_step: 8302, epoch: 8, loss: 1.358334
global_step: 8303, epoch: 8, loss: 1.325094
global_step: 8304, epoch: 8, loss: 1.301417
global_step: 8305, epoch: 8, loss: 1.283114
global_step: 8306, epoch: 8, loss: 1.403195
global_step: 8307, epoch: 8, loss: 1.422136
global_step: 8308, epoch: 8, loss: 1.383606
global_step: 8309, epoch: 8, loss: 1.454036
global_step: 8310, epoch: 8, loss: 1.368085
global_step: 8311, epoch: 8, loss: 1.370191
global_step: 8312, epoch: 8, loss: 1.380695
global_step: 8313, epoch: 8, loss: 1.434327
global_step: 8314, epoch: 8, loss: 1.382366
global_step: 8315, epoch: 8, loss: 1.350246
global_step: 8316, epoch: 8, loss: 1.346725
global_step: 8317, epoch: 8, loss: 1.393656
global_step: 8318, epoch: 8, loss: 1.247723
global_step: 8319, epoch: 8, loss: 1.275608
global_step: 8320, epoch: 8, loss: 1.686553
epoch: 8
train	acc: 0.5833	macro: p 0.3026, r 0.2751, f1: 0.2725	micro: p 0.5833, r 0.5833, f1 0.5833	weighted_f1:0.5151
dev	acc: 0.5149	macro: p 0.2506, r 0.2545, f1: 0.2328	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4304
test	acc: 0.5693	macro: p 0.2686, r 0.2611, f1: 0.2506	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.4967
New best model!
global_step: 8321, epoch: 9, loss: 1.394514
global_step: 8322, epoch: 9, loss: 1.339430
global_step: 8323, epoch: 9, loss: 1.331161
global_step: 8324, epoch: 9, loss: 1.285869
global_step: 8325, epoch: 9, loss: 1.347495
global_step: 8326, epoch: 9, loss: 1.295334
global_step: 8327, epoch: 9, loss: 1.346930
global_step: 8328, epoch: 9, loss: 1.360086
global_step: 8329, epoch: 9, loss: 1.321645
global_step: 8330, epoch: 9, loss: 1.303732
global_step: 8331, epoch: 9, loss: 1.342786
global_step: 8332, epoch: 9, loss: 1.357074
global_step: 8333, epoch: 9, loss: 1.312685
global_step: 8334, epoch: 9, loss: 1.343335
global_step: 8335, epoch: 9, loss: 1.445025
global_step: 8336, epoch: 9, loss: 1.486638
global_step: 8337, epoch: 9, loss: 1.389897
global_step: 8338, epoch: 9, loss: 1.451987
global_step: 8339, epoch: 9, loss: 1.297763
global_step: 8340, epoch: 9, loss: 1.245293
global_step: 8341, epoch: 9, loss: 1.274081
global_step: 8342, epoch: 9, loss: 1.339465
global_step: 8343, epoch: 9, loss: 1.312927
global_step: 8344, epoch: 9, loss: 1.232471
global_step: 8345, epoch: 9, loss: 1.277185
global_step: 8346, epoch: 9, loss: 1.365955
global_step: 8347, epoch: 9, loss: 1.307757
global_step: 8348, epoch: 9, loss: 1.334767
global_step: 8349, epoch: 9, loss: 1.256350
global_step: 8350, epoch: 9, loss: 1.281376
global_step: 8351, epoch: 9, loss: 1.294546
global_step: 8352, epoch: 9, loss: 1.379899
global_step: 8353, epoch: 9, loss: 1.319456
global_step: 8354, epoch: 9, loss: 1.410030
global_step: 8355, epoch: 9, loss: 1.346946
global_step: 8356, epoch: 9, loss: 1.295256
global_step: 8357, epoch: 9, loss: 1.382772
global_step: 8358, epoch: 9, loss: 1.307049
global_step: 8359, epoch: 9, loss: 1.320807
global_step: 8360, epoch: 9, loss: 1.176009
epoch: 9
train	acc: 0.5887	macro: p 0.3094, r 0.2839, f1: 0.2814	micro: p 0.5887, r 0.5887, f1 0.5887	weighted_f1:0.5242
dev	acc: 0.5239	macro: p 0.2699, r 0.2655, f1: 0.2473	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4452
test	acc: 0.5716	macro: p 0.2763, r 0.2677, f1: 0.2585	micro: p 0.5716, r 0.5716, f1 0.5716	weighted_f1:0.5041
New best model!
global_step: 8361, epoch: 10, loss: 1.270405
global_step: 8362, epoch: 10, loss: 1.311490
global_step: 8363, epoch: 10, loss: 1.352857
global_step: 8364, epoch: 10, loss: 1.455881
global_step: 8365, epoch: 10, loss: 1.233793
global_step: 8366, epoch: 10, loss: 1.238800
global_step: 8367, epoch: 10, loss: 1.316573
global_step: 8368, epoch: 10, loss: 1.348580
global_step: 8369, epoch: 10, loss: 1.381812
global_step: 8370, epoch: 10, loss: 1.251136
global_step: 8371, epoch: 10, loss: 1.384150
global_step: 8372, epoch: 10, loss: 1.271823
global_step: 8373, epoch: 10, loss: 1.363153
global_step: 8374, epoch: 10, loss: 1.342782
global_step: 8375, epoch: 10, loss: 1.298366
global_step: 8376, epoch: 10, loss: 1.378466
global_step: 8377, epoch: 10, loss: 1.388581
global_step: 8378, epoch: 10, loss: 1.412439
global_step: 8379, epoch: 10, loss: 1.370115
global_step: 8380, epoch: 10, loss: 1.300624
global_step: 8381, epoch: 10, loss: 1.318351
global_step: 8382, epoch: 10, loss: 1.249540
global_step: 8383, epoch: 10, loss: 1.364780
global_step: 8384, epoch: 10, loss: 1.341962
global_step: 8385, epoch: 10, loss: 1.310747
global_step: 8386, epoch: 10, loss: 1.290490
global_step: 8387, epoch: 10, loss: 1.268303
global_step: 8388, epoch: 10, loss: 1.322060
global_step: 8389, epoch: 10, loss: 1.336192
global_step: 8390, epoch: 10, loss: 1.400844
global_step: 8391, epoch: 10, loss: 1.365092
global_step: 8392, epoch: 10, loss: 1.227566
global_step: 8393, epoch: 10, loss: 1.240642
global_step: 8394, epoch: 10, loss: 1.377205
global_step: 8395, epoch: 10, loss: 1.302052
global_step: 8396, epoch: 10, loss: 1.372316
global_step: 8397, epoch: 10, loss: 1.291076
global_step: 8398, epoch: 10, loss: 1.395184
global_step: 8399, epoch: 10, loss: 1.396297
global_step: 8400, epoch: 10, loss: 1.265895
epoch: 10
train	acc: 0.5917	macro: p 0.3102, r 0.2876, f1: 0.2861	micro: p 0.5917, r 0.5917, f1 0.5917	weighted_f1:0.5280
dev	acc: 0.5203	macro: p 0.2583, r 0.2597, f1: 0.2419	micro: p 0.5203, r 0.5203, f1 0.5203	weighted_f1:0.4398
test	acc: 0.5759	macro: p 0.2787, r 0.2709, f1: 0.2634	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5086
global_step: 8401, epoch: 11, loss: 1.372981
global_step: 8402, epoch: 11, loss: 1.371419
global_step: 8403, epoch: 11, loss: 1.301782
global_step: 8404, epoch: 11, loss: 1.375207
global_step: 8405, epoch: 11, loss: 1.248425
global_step: 8406, epoch: 11, loss: 1.403525
global_step: 8407, epoch: 11, loss: 1.385179
global_step: 8408, epoch: 11, loss: 1.348494
global_step: 8409, epoch: 11, loss: 1.277393
global_step: 8410, epoch: 11, loss: 1.343206
global_step: 8411, epoch: 11, loss: 1.264882
global_step: 8412, epoch: 11, loss: 1.329517
global_step: 8413, epoch: 11, loss: 1.292515
global_step: 8414, epoch: 11, loss: 1.317341
global_step: 8415, epoch: 11, loss: 1.363472
global_step: 8416, epoch: 11, loss: 1.316447
global_step: 8417, epoch: 11, loss: 1.292753
global_step: 8418, epoch: 11, loss: 1.299018
global_step: 8419, epoch: 11, loss: 1.258473
global_step: 8420, epoch: 11, loss: 1.254934
global_step: 8421, epoch: 11, loss: 1.383270
global_step: 8422, epoch: 11, loss: 1.235458
global_step: 8423, epoch: 11, loss: 1.364217
global_step: 8424, epoch: 11, loss: 1.301950
global_step: 8425, epoch: 11, loss: 1.335541
global_step: 8426, epoch: 11, loss: 1.306843
global_step: 8427, epoch: 11, loss: 1.314628
global_step: 8428, epoch: 11, loss: 1.287996
global_step: 8429, epoch: 11, loss: 1.335106
global_step: 8430, epoch: 11, loss: 1.261284
global_step: 8431, epoch: 11, loss: 1.378471
global_step: 8432, epoch: 11, loss: 1.312122
global_step: 8433, epoch: 11, loss: 1.392947
global_step: 8434, epoch: 11, loss: 1.172925
global_step: 8435, epoch: 11, loss: 1.313999
global_step: 8436, epoch: 11, loss: 1.252344
global_step: 8437, epoch: 11, loss: 1.405790
global_step: 8438, epoch: 11, loss: 1.331965
global_step: 8439, epoch: 11, loss: 1.209530
global_step: 8440, epoch: 11, loss: 1.330228
epoch: 11
train	acc: 0.5924	macro: p 0.3095, r 0.2911, f1: 0.2892	micro: p 0.5924, r 0.5924, f1 0.5924	weighted_f1:0.5306
dev	acc: 0.5248	macro: p 0.2658, r 0.2669, f1: 0.2512	micro: p 0.5248, r 0.5248, f1 0.5248	weighted_f1:0.4493
test	acc: 0.5743	macro: p 0.2766, r 0.2717, f1: 0.2645	micro: p 0.5743, r 0.5743, f1 0.5743	weighted_f1:0.5096
New best model!
global_step: 8441, epoch: 12, loss: 1.280969
global_step: 8442, epoch: 12, loss: 1.275231
global_step: 8443, epoch: 12, loss: 1.306317
global_step: 8444, epoch: 12, loss: 1.382607
global_step: 8445, epoch: 12, loss: 1.453997
global_step: 8446, epoch: 12, loss: 1.256899
global_step: 8447, epoch: 12, loss: 1.164960
global_step: 8448, epoch: 12, loss: 1.314726
global_step: 8449, epoch: 12, loss: 1.383132
global_step: 8450, epoch: 12, loss: 1.492030
global_step: 8451, epoch: 12, loss: 1.239816
global_step: 8452, epoch: 12, loss: 1.176051
global_step: 8453, epoch: 12, loss: 1.320265
global_step: 8454, epoch: 12, loss: 1.211660
global_step: 8455, epoch: 12, loss: 1.239301
global_step: 8456, epoch: 12, loss: 1.263612
global_step: 8457, epoch: 12, loss: 1.319033
global_step: 8458, epoch: 12, loss: 1.304457
global_step: 8459, epoch: 12, loss: 1.405993
global_step: 8460, epoch: 12, loss: 1.294184
global_step: 8461, epoch: 12, loss: 1.312602
global_step: 8462, epoch: 12, loss: 1.473107
global_step: 8463, epoch: 12, loss: 1.242241
global_step: 8464, epoch: 12, loss: 1.292461
global_step: 8465, epoch: 12, loss: 1.298245
global_step: 8466, epoch: 12, loss: 1.267389
global_step: 8467, epoch: 12, loss: 1.256245
global_step: 8468, epoch: 12, loss: 1.234416
global_step: 8469, epoch: 12, loss: 1.301292
global_step: 8470, epoch: 12, loss: 1.375628
global_step: 8471, epoch: 12, loss: 1.268052
global_step: 8472, epoch: 12, loss: 1.306191
global_step: 8473, epoch: 12, loss: 1.243079
global_step: 8474, epoch: 12, loss: 1.289323
global_step: 8475, epoch: 12, loss: 1.263252
global_step: 8476, epoch: 12, loss: 1.260520
global_step: 8477, epoch: 12, loss: 1.359033
global_step: 8478, epoch: 12, loss: 1.328498
global_step: 8479, epoch: 12, loss: 1.311872
global_step: 8480, epoch: 12, loss: 1.184368
epoch: 12
train	acc: 0.5954	macro: p 0.3111, r 0.2927, f1: 0.2905	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5328
dev	acc: 0.5239	macro: p 0.2594, r 0.2665, f1: 0.2472	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4453
test	acc: 0.5747	macro: p 0.2744, r 0.2731, f1: 0.2630	micro: p 0.5747, r 0.5747, f1 0.5747	weighted_f1:0.5079
global_step: 8481, epoch: 13, loss: 1.311379
global_step: 8482, epoch: 13, loss: 1.239794
global_step: 8483, epoch: 13, loss: 1.241732
global_step: 8484, epoch: 13, loss: 1.417151
global_step: 8485, epoch: 13, loss: 1.343036
global_step: 8486, epoch: 13, loss: 1.376999
global_step: 8487, epoch: 13, loss: 1.138103
global_step: 8488, epoch: 13, loss: 1.169228
global_step: 8489, epoch: 13, loss: 1.301192
global_step: 8490, epoch: 13, loss: 1.273743
global_step: 8491, epoch: 13, loss: 1.216477
global_step: 8492, epoch: 13, loss: 1.274621
global_step: 8493, epoch: 13, loss: 1.266230
global_step: 8494, epoch: 13, loss: 1.208808
global_step: 8495, epoch: 13, loss: 1.291472
global_step: 8496, epoch: 13, loss: 1.262278
global_step: 8497, epoch: 13, loss: 1.316579
global_step: 8498, epoch: 13, loss: 1.224699
global_step: 8499, epoch: 13, loss: 1.290009
global_step: 8500, epoch: 13, loss: 1.345174
global_step: 8501, epoch: 13, loss: 1.226816
global_step: 8502, epoch: 13, loss: 1.274659
global_step: 8503, epoch: 13, loss: 1.299023
global_step: 8504, epoch: 13, loss: 1.311580
global_step: 8505, epoch: 13, loss: 1.326585
global_step: 8506, epoch: 13, loss: 1.432068
global_step: 8507, epoch: 13, loss: 1.279065
global_step: 8508, epoch: 13, loss: 1.399052
global_step: 8509, epoch: 13, loss: 1.382557
global_step: 8510, epoch: 13, loss: 1.255255
global_step: 8511, epoch: 13, loss: 1.293981
global_step: 8512, epoch: 13, loss: 1.316381
global_step: 8513, epoch: 13, loss: 1.393975
global_step: 8514, epoch: 13, loss: 1.279342
global_step: 8515, epoch: 13, loss: 1.317924
global_step: 8516, epoch: 13, loss: 1.276059
global_step: 8517, epoch: 13, loss: 1.415061
global_step: 8518, epoch: 13, loss: 1.360181
global_step: 8519, epoch: 13, loss: 1.194701
global_step: 8520, epoch: 13, loss: 2.447682
epoch: 13
train	acc: 0.5970	macro: p 0.4566, r 0.2968, f1: 0.2956	micro: p 0.5970, r 0.5970, f1 0.5970	weighted_f1:0.5368
dev	acc: 0.5284	macro: p 0.4104, r 0.2719, f1: 0.2548	micro: p 0.5284, r 0.5284, f1 0.5284	weighted_f1:0.4531
test	acc: 0.5759	macro: p 0.2783, r 0.2751, f1: 0.2660	micro: p 0.5759, r 0.5759, f1 0.5759	weighted_f1:0.5112
New best model!
global_step: 8521, epoch: 14, loss: 1.239175
global_step: 8522, epoch: 14, loss: 1.368097
global_step: 8523, epoch: 14, loss: 1.292152
global_step: 8524, epoch: 14, loss: 1.240728
global_step: 8525, epoch: 14, loss: 1.296302
global_step: 8526, epoch: 14, loss: 1.256348
global_step: 8527, epoch: 14, loss: 1.247379
global_step: 8528, epoch: 14, loss: 1.301234
global_step: 8529, epoch: 14, loss: 1.255428
global_step: 8530, epoch: 14, loss: 1.372921
global_step: 8531, epoch: 14, loss: 1.333187
global_step: 8532, epoch: 14, loss: 1.256398
global_step: 8533, epoch: 14, loss: 1.371627
global_step: 8534, epoch: 14, loss: 1.287994
global_step: 8535, epoch: 14, loss: 1.324653
global_step: 8536, epoch: 14, loss: 1.330485
global_step: 8537, epoch: 14, loss: 1.242239
global_step: 8538, epoch: 14, loss: 1.273627
global_step: 8539, epoch: 14, loss: 1.251254
global_step: 8540, epoch: 14, loss: 1.279600
global_step: 8541, epoch: 14, loss: 1.212318
global_step: 8542, epoch: 14, loss: 1.227608
global_step: 8543, epoch: 14, loss: 1.272844
global_step: 8544, epoch: 14, loss: 1.239197
global_step: 8545, epoch: 14, loss: 1.266835
global_step: 8546, epoch: 14, loss: 1.260442
global_step: 8547, epoch: 14, loss: 1.240027
global_step: 8548, epoch: 14, loss: 1.198349
global_step: 8549, epoch: 14, loss: 1.422141
global_step: 8550, epoch: 14, loss: 1.238842
global_step: 8551, epoch: 14, loss: 1.202906
global_step: 8552, epoch: 14, loss: 1.354824
global_step: 8553, epoch: 14, loss: 1.278179
global_step: 8554, epoch: 14, loss: 1.251565
global_step: 8555, epoch: 14, loss: 1.336608
global_step: 8556, epoch: 14, loss: 1.403637
global_step: 8557, epoch: 14, loss: 1.369346
global_step: 8558, epoch: 14, loss: 1.331826
global_step: 8559, epoch: 14, loss: 1.275992
global_step: 8560, epoch: 14, loss: 2.571820
epoch: 14
train	acc: 0.5950	macro: p 0.4196, r 0.3016, f1: 0.2991	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5382
dev	acc: 0.5302	macro: p 0.4041, r 0.2764, f1: 0.2615	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4597
test	acc: 0.5755	macro: p 0.4151, r 0.2815, f1: 0.2732	micro: p 0.5755, r 0.5755, f1 0.5755	weighted_f1:0.5160
New best model!
global_step: 8561, epoch: 15, loss: 1.274102
global_step: 8562, epoch: 15, loss: 1.169190
global_step: 8563, epoch: 15, loss: 1.271819
global_step: 8564, epoch: 15, loss: 1.225902
global_step: 8565, epoch: 15, loss: 1.243239
global_step: 8566, epoch: 15, loss: 1.386494
global_step: 8567, epoch: 15, loss: 1.262484
global_step: 8568, epoch: 15, loss: 1.268818
global_step: 8569, epoch: 15, loss: 1.278988
global_step: 8570, epoch: 15, loss: 1.381879
global_step: 8571, epoch: 15, loss: 1.330420
global_step: 8572, epoch: 15, loss: 1.342467
global_step: 8573, epoch: 15, loss: 1.221256
global_step: 8574, epoch: 15, loss: 1.191111
global_step: 8575, epoch: 15, loss: 1.324651
global_step: 8576, epoch: 15, loss: 1.332412
global_step: 8577, epoch: 15, loss: 1.257447
global_step: 8578, epoch: 15, loss: 1.283445
global_step: 8579, epoch: 15, loss: 1.356140
global_step: 8580, epoch: 15, loss: 1.260276
global_step: 8581, epoch: 15, loss: 1.312346
global_step: 8582, epoch: 15, loss: 1.251513
global_step: 8583, epoch: 15, loss: 1.177166
global_step: 8584, epoch: 15, loss: 1.285611
global_step: 8585, epoch: 15, loss: 1.259907
global_step: 8586, epoch: 15, loss: 1.163204
global_step: 8587, epoch: 15, loss: 1.402172
global_step: 8588, epoch: 15, loss: 1.337617
global_step: 8589, epoch: 15, loss: 1.341110
global_step: 8590, epoch: 15, loss: 1.246337
global_step: 8591, epoch: 15, loss: 1.251032
global_step: 8592, epoch: 15, loss: 1.380892
global_step: 8593, epoch: 15, loss: 1.273723
global_step: 8594, epoch: 15, loss: 1.222216
global_step: 8595, epoch: 15, loss: 1.227240
global_step: 8596, epoch: 15, loss: 1.263896
global_step: 8597, epoch: 15, loss: 1.340368
global_step: 8598, epoch: 15, loss: 1.245155
global_step: 8599, epoch: 15, loss: 1.263797
global_step: 8600, epoch: 15, loss: 0.418518
epoch: 15
train	acc: 0.5990	macro: p 0.4622, r 0.2952, f1: 0.2947	micro: p 0.5990, r 0.5990, f1 0.5990	weighted_f1:0.5366
dev	acc: 0.5311	macro: p 0.4122, r 0.2733, f1: 0.2544	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4527
test	acc: 0.5782	macro: p 0.2812, r 0.2745, f1: 0.2651	micro: p 0.5782, r 0.5782, f1 0.5782	weighted_f1:0.5106
global_step: 8601, epoch: 16, loss: 1.185583
global_step: 8602, epoch: 16, loss: 1.241882
global_step: 8603, epoch: 16, loss: 1.331066
global_step: 8604, epoch: 16, loss: 1.233511
global_step: 8605, epoch: 16, loss: 1.354424
global_step: 8606, epoch: 16, loss: 1.269168
global_step: 8607, epoch: 16, loss: 1.278105
global_step: 8608, epoch: 16, loss: 1.357977
global_step: 8609, epoch: 16, loss: 1.163548
global_step: 8610, epoch: 16, loss: 1.229513
global_step: 8611, epoch: 16, loss: 1.334007
global_step: 8612, epoch: 16, loss: 1.230293
global_step: 8613, epoch: 16, loss: 1.271461
global_step: 8614, epoch: 16, loss: 1.214871
global_step: 8615, epoch: 16, loss: 1.353298
global_step: 8616, epoch: 16, loss: 1.134730
global_step: 8617, epoch: 16, loss: 1.362511
global_step: 8618, epoch: 16, loss: 1.217560
global_step: 8619, epoch: 16, loss: 1.322648
global_step: 8620, epoch: 16, loss: 1.342343
global_step: 8621, epoch: 16, loss: 1.255115
global_step: 8622, epoch: 16, loss: 1.260283
global_step: 8623, epoch: 16, loss: 1.298553
global_step: 8624, epoch: 16, loss: 1.264884
global_step: 8625, epoch: 16, loss: 1.241701
global_step: 8626, epoch: 16, loss: 1.243933
global_step: 8627, epoch: 16, loss: 1.234875
global_step: 8628, epoch: 16, loss: 1.374956
global_step: 8629, epoch: 16, loss: 1.269971
global_step: 8630, epoch: 16, loss: 1.195828
global_step: 8631, epoch: 16, loss: 1.251998
global_step: 8632, epoch: 16, loss: 1.280380
global_step: 8633, epoch: 16, loss: 1.233547
global_step: 8634, epoch: 16, loss: 1.303148
global_step: 8635, epoch: 16, loss: 1.180623
global_step: 8636, epoch: 16, loss: 1.261859
global_step: 8637, epoch: 16, loss: 1.340566
global_step: 8638, epoch: 16, loss: 1.296743
global_step: 8639, epoch: 16, loss: 1.306691
global_step: 8640, epoch: 16, loss: 1.599791
epoch: 16
train	acc: 0.5995	macro: p 0.4354, r 0.3045, f1: 0.3026	micro: p 0.5995, r 0.5995, f1 0.5995	weighted_f1:0.5423
dev	acc: 0.5338	macro: p 0.4110, r 0.2787, f1: 0.2637	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4625
test	acc: 0.5770	macro: p 0.4167, r 0.2817, f1: 0.2731	micro: p 0.5770, r 0.5770, f1 0.5770	weighted_f1:0.5166
New best model!
global_step: 8641, epoch: 17, loss: 1.262054
global_step: 8642, epoch: 17, loss: 1.188788
global_step: 8643, epoch: 17, loss: 1.235525
global_step: 8644, epoch: 17, loss: 1.297669
global_step: 8645, epoch: 17, loss: 1.254380
global_step: 8646, epoch: 17, loss: 1.252464
global_step: 8647, epoch: 17, loss: 1.257056
global_step: 8648, epoch: 17, loss: 1.199863
global_step: 8649, epoch: 17, loss: 1.309864
global_step: 8650, epoch: 17, loss: 1.361888
global_step: 8651, epoch: 17, loss: 1.390371
global_step: 8652, epoch: 17, loss: 1.340591
global_step: 8653, epoch: 17, loss: 1.259086
global_step: 8654, epoch: 17, loss: 1.201553
global_step: 8655, epoch: 17, loss: 1.258540
global_step: 8656, epoch: 17, loss: 1.205224
global_step: 8657, epoch: 17, loss: 1.234164
global_step: 8658, epoch: 17, loss: 1.151192
global_step: 8659, epoch: 17, loss: 1.291836
global_step: 8660, epoch: 17, loss: 1.174744
global_step: 8661, epoch: 17, loss: 1.274721
global_step: 8662, epoch: 17, loss: 1.180176
global_step: 8663, epoch: 17, loss: 1.187482
global_step: 8664, epoch: 17, loss: 1.437181
global_step: 8665, epoch: 17, loss: 1.274192
global_step: 8666, epoch: 17, loss: 1.382875
global_step: 8667, epoch: 17, loss: 1.257347
global_step: 8668, epoch: 17, loss: 1.344838
global_step: 8669, epoch: 17, loss: 1.298849
global_step: 8670, epoch: 17, loss: 1.382209
global_step: 8671, epoch: 17, loss: 1.261733
global_step: 8672, epoch: 17, loss: 1.294232
global_step: 8673, epoch: 17, loss: 1.215437
global_step: 8674, epoch: 17, loss: 1.225883
global_step: 8675, epoch: 17, loss: 1.216744
global_step: 8676, epoch: 17, loss: 1.264241
global_step: 8677, epoch: 17, loss: 1.196828
global_step: 8678, epoch: 17, loss: 1.224265
global_step: 8679, epoch: 17, loss: 1.389877
global_step: 8680, epoch: 17, loss: 2.417532
epoch: 17
train	acc: 0.6064	macro: p 0.4369, r 0.3099, f1: 0.3136	micro: p 0.6064, r 0.6064, f1 0.6064	weighted_f1:0.5505
dev	acc: 0.5401	macro: p 0.4199, r 0.2847, f1: 0.2706	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4684
test	acc: 0.5778	macro: p 0.3900, r 0.2804, f1: 0.2737	micro: p 0.5778, r 0.5778, f1 0.5778	weighted_f1:0.5168
New best model!
global_step: 8681, epoch: 18, loss: 1.251541
global_step: 8682, epoch: 18, loss: 1.278106
global_step: 8683, epoch: 18, loss: 1.255160
global_step: 8684, epoch: 18, loss: 1.121708
global_step: 8685, epoch: 18, loss: 1.187806
global_step: 8686, epoch: 18, loss: 1.167197
global_step: 8687, epoch: 18, loss: 1.274354
global_step: 8688, epoch: 18, loss: 1.241049
global_step: 8689, epoch: 18, loss: 1.320216
global_step: 8690, epoch: 18, loss: 1.338959
global_step: 8691, epoch: 18, loss: 1.142040
global_step: 8692, epoch: 18, loss: 1.291878
global_step: 8693, epoch: 18, loss: 1.280897
global_step: 8694, epoch: 18, loss: 1.216684
global_step: 8695, epoch: 18, loss: 1.227165
global_step: 8696, epoch: 18, loss: 1.350639
global_step: 8697, epoch: 18, loss: 1.270464
global_step: 8698, epoch: 18, loss: 1.260068
global_step: 8699, epoch: 18, loss: 1.263598
global_step: 8700, epoch: 18, loss: 1.273309
global_step: 8701, epoch: 18, loss: 1.248601
global_step: 8702, epoch: 18, loss: 1.226128
global_step: 8703, epoch: 18, loss: 1.237090
global_step: 8704, epoch: 18, loss: 1.359874
global_step: 8705, epoch: 18, loss: 1.326653
global_step: 8706, epoch: 18, loss: 1.109955
global_step: 8707, epoch: 18, loss: 1.199468
global_step: 8708, epoch: 18, loss: 1.280333
global_step: 8709, epoch: 18, loss: 1.232216
global_step: 8710, epoch: 18, loss: 1.200609
global_step: 8711, epoch: 18, loss: 1.332606
global_step: 8712, epoch: 18, loss: 1.328456
global_step: 8713, epoch: 18, loss: 1.211441
global_step: 8714, epoch: 18, loss: 1.281239
global_step: 8715, epoch: 18, loss: 1.310070
global_step: 8716, epoch: 18, loss: 1.216100
global_step: 8717, epoch: 18, loss: 1.285710
global_step: 8718, epoch: 18, loss: 1.362437
global_step: 8719, epoch: 18, loss: 1.267853
global_step: 8720, epoch: 18, loss: 1.079175
epoch: 18
train	acc: 0.6078	macro: p 0.4300, r 0.3121, f1: 0.3167	micro: p 0.6078, r 0.6078, f1 0.6078	weighted_f1:0.5529
dev	acc: 0.5401	macro: p 0.3637, r 0.2847, f1: 0.2712	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4695
test	acc: 0.5805	macro: p 0.3818, r 0.2834, f1: 0.2781	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5207
New best model!
global_step: 8721, epoch: 19, loss: 1.285931
global_step: 8722, epoch: 19, loss: 1.289864
global_step: 8723, epoch: 19, loss: 1.250528
global_step: 8724, epoch: 19, loss: 1.240469
global_step: 8725, epoch: 19, loss: 1.228029
global_step: 8726, epoch: 19, loss: 1.156530
global_step: 8727, epoch: 19, loss: 1.302271
global_step: 8728, epoch: 19, loss: 1.142627
global_step: 8729, epoch: 19, loss: 1.195288
global_step: 8730, epoch: 19, loss: 1.248271
global_step: 8731, epoch: 19, loss: 1.298571
global_step: 8732, epoch: 19, loss: 1.264149
global_step: 8733, epoch: 19, loss: 1.209596
global_step: 8734, epoch: 19, loss: 1.191250
global_step: 8735, epoch: 19, loss: 1.246191
global_step: 8736, epoch: 19, loss: 1.320366
global_step: 8737, epoch: 19, loss: 1.169289
global_step: 8738, epoch: 19, loss: 1.256125
global_step: 8739, epoch: 19, loss: 1.239381
global_step: 8740, epoch: 19, loss: 1.329139
global_step: 8741, epoch: 19, loss: 1.297007
global_step: 8742, epoch: 19, loss: 1.251917
global_step: 8743, epoch: 19, loss: 1.258904
global_step: 8744, epoch: 19, loss: 1.272694
global_step: 8745, epoch: 19, loss: 1.264665
global_step: 8746, epoch: 19, loss: 1.214596
global_step: 8747, epoch: 19, loss: 1.230331
global_step: 8748, epoch: 19, loss: 1.243295
global_step: 8749, epoch: 19, loss: 1.231386
global_step: 8750, epoch: 19, loss: 1.455937
global_step: 8751, epoch: 19, loss: 1.199198
global_step: 8752, epoch: 19, loss: 1.152084
global_step: 8753, epoch: 19, loss: 1.320449
global_step: 8754, epoch: 19, loss: 1.242287
global_step: 8755, epoch: 19, loss: 1.157421
global_step: 8756, epoch: 19, loss: 1.306898
global_step: 8757, epoch: 19, loss: 1.284254
global_step: 8758, epoch: 19, loss: 1.237857
global_step: 8759, epoch: 19, loss: 1.151063
global_step: 8760, epoch: 19, loss: 1.032760
epoch: 19
train	acc: 0.6090	macro: p 0.4291, r 0.3155, f1: 0.3197	micro: p 0.6090, r 0.6090, f1 0.6090	weighted_f1:0.5554
dev	acc: 0.5365	macro: p 0.3781, r 0.2825, f1: 0.2687	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4664
test	acc: 0.5801	macro: p 0.3714, r 0.2849, f1: 0.2795	micro: p 0.5801, r 0.5801, f1 0.5801	weighted_f1:0.5214
global_step: 8761, epoch: 20, loss: 1.162091
global_step: 8762, epoch: 20, loss: 1.226515
global_step: 8763, epoch: 20, loss: 1.311353
global_step: 8764, epoch: 20, loss: 1.289516
global_step: 8765, epoch: 20, loss: 1.225399
global_step: 8766, epoch: 20, loss: 1.162108
global_step: 8767, epoch: 20, loss: 1.203482
global_step: 8768, epoch: 20, loss: 1.160908
global_step: 8769, epoch: 20, loss: 1.306836
global_step: 8770, epoch: 20, loss: 1.192267
global_step: 8771, epoch: 20, loss: 1.263103
global_step: 8772, epoch: 20, loss: 1.261697
global_step: 8773, epoch: 20, loss: 1.184357
global_step: 8774, epoch: 20, loss: 1.187572
global_step: 8775, epoch: 20, loss: 1.215164
global_step: 8776, epoch: 20, loss: 1.209639
global_step: 8777, epoch: 20, loss: 1.182499
global_step: 8778, epoch: 20, loss: 1.215066
global_step: 8779, epoch: 20, loss: 1.238564
global_step: 8780, epoch: 20, loss: 1.182958
global_step: 8781, epoch: 20, loss: 1.247278
global_step: 8782, epoch: 20, loss: 1.220208
global_step: 8783, epoch: 20, loss: 1.252408
global_step: 8784, epoch: 20, loss: 1.140696
global_step: 8785, epoch: 20, loss: 1.282493
global_step: 8786, epoch: 20, loss: 1.283870
global_step: 8787, epoch: 20, loss: 1.293662
global_step: 8788, epoch: 20, loss: 1.167539
global_step: 8789, epoch: 20, loss: 1.159014
global_step: 8790, epoch: 20, loss: 1.228280
global_step: 8791, epoch: 20, loss: 1.339748
global_step: 8792, epoch: 20, loss: 1.355892
global_step: 8793, epoch: 20, loss: 1.254416
global_step: 8794, epoch: 20, loss: 1.358139
global_step: 8795, epoch: 20, loss: 1.294358
global_step: 8796, epoch: 20, loss: 1.195041
global_step: 8797, epoch: 20, loss: 1.356460
global_step: 8798, epoch: 20, loss: 1.303037
global_step: 8799, epoch: 20, loss: 1.197947
global_step: 8800, epoch: 20, loss: 0.581236
epoch: 20
train	acc: 0.6122	macro: p 0.4332, r 0.3173, f1: 0.3239	micro: p 0.6122, r 0.6122, f1 0.6122	weighted_f1:0.5586
dev	acc: 0.5419	macro: p 0.3659, r 0.2866, f1: 0.2716	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4701
test	acc: 0.5820	macro: p 0.3793, r 0.2866, f1: 0.2811	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5221
New best model!
global_step: 8801, epoch: 21, loss: 1.155746
global_step: 8802, epoch: 21, loss: 1.175646
global_step: 8803, epoch: 21, loss: 1.230308
global_step: 8804, epoch: 21, loss: 1.249640
global_step: 8805, epoch: 21, loss: 1.243662
global_step: 8806, epoch: 21, loss: 1.144189
global_step: 8807, epoch: 21, loss: 1.199657
global_step: 8808, epoch: 21, loss: 1.261457
global_step: 8809, epoch: 21, loss: 1.231608
global_step: 8810, epoch: 21, loss: 1.292947
global_step: 8811, epoch: 21, loss: 1.218375
global_step: 8812, epoch: 21, loss: 1.359427
global_step: 8813, epoch: 21, loss: 1.218047
global_step: 8814, epoch: 21, loss: 1.240796
global_step: 8815, epoch: 21, loss: 1.376710
global_step: 8816, epoch: 21, loss: 1.184341
global_step: 8817, epoch: 21, loss: 1.188621
global_step: 8818, epoch: 21, loss: 1.113271
global_step: 8819, epoch: 21, loss: 1.311474
global_step: 8820, epoch: 21, loss: 1.255634
global_step: 8821, epoch: 21, loss: 1.129683
global_step: 8822, epoch: 21, loss: 1.164599
global_step: 8823, epoch: 21, loss: 1.159483
global_step: 8824, epoch: 21, loss: 1.339947
global_step: 8825, epoch: 21, loss: 1.205105
global_step: 8826, epoch: 21, loss: 1.220399
global_step: 8827, epoch: 21, loss: 1.179586
global_step: 8828, epoch: 21, loss: 1.223241
global_step: 8829, epoch: 21, loss: 1.203931
global_step: 8830, epoch: 21, loss: 1.187752
global_step: 8831, epoch: 21, loss: 1.177117
global_step: 8832, epoch: 21, loss: 1.196211
global_step: 8833, epoch: 21, loss: 1.256158
global_step: 8834, epoch: 21, loss: 1.243057
global_step: 8835, epoch: 21, loss: 1.261896
global_step: 8836, epoch: 21, loss: 1.204843
global_step: 8837, epoch: 21, loss: 1.128061
global_step: 8838, epoch: 21, loss: 1.280153
global_step: 8839, epoch: 21, loss: 1.307455
global_step: 8840, epoch: 21, loss: 1.157994
epoch: 21
train	acc: 0.6133	macro: p 0.4399, r 0.3167, f1: 0.3240	micro: p 0.6133, r 0.6133, f1 0.6133	weighted_f1:0.5590
dev	acc: 0.5401	macro: p 0.3648, r 0.2839, f1: 0.2674	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4664
test	acc: 0.5835	macro: p 0.3799, r 0.2866, f1: 0.2795	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5215
global_step: 8841, epoch: 22, loss: 1.090103
global_step: 8842, epoch: 22, loss: 1.244453
global_step: 8843, epoch: 22, loss: 1.150228
global_step: 8844, epoch: 22, loss: 1.206570
global_step: 8845, epoch: 22, loss: 1.211116
global_step: 8846, epoch: 22, loss: 1.206777
global_step: 8847, epoch: 22, loss: 1.211521
global_step: 8848, epoch: 22, loss: 1.112257
global_step: 8849, epoch: 22, loss: 1.254389
global_step: 8850, epoch: 22, loss: 1.204172
global_step: 8851, epoch: 22, loss: 1.177478
global_step: 8852, epoch: 22, loss: 1.310397
global_step: 8853, epoch: 22, loss: 1.151052
global_step: 8854, epoch: 22, loss: 1.247123
global_step: 8855, epoch: 22, loss: 1.148465
global_step: 8856, epoch: 22, loss: 1.290415
global_step: 8857, epoch: 22, loss: 1.275319
global_step: 8858, epoch: 22, loss: 1.195855
global_step: 8859, epoch: 22, loss: 1.283937
global_step: 8860, epoch: 22, loss: 1.280906
global_step: 8861, epoch: 22, loss: 1.142149
global_step: 8862, epoch: 22, loss: 1.371068
global_step: 8863, epoch: 22, loss: 1.182979
global_step: 8864, epoch: 22, loss: 1.333375
global_step: 8865, epoch: 22, loss: 1.114511
global_step: 8866, epoch: 22, loss: 1.265411
global_step: 8867, epoch: 22, loss: 1.257221
global_step: 8868, epoch: 22, loss: 1.250772
global_step: 8869, epoch: 22, loss: 1.241607
global_step: 8870, epoch: 22, loss: 1.287632
global_step: 8871, epoch: 22, loss: 1.230030
global_step: 8872, epoch: 22, loss: 1.140243
global_step: 8873, epoch: 22, loss: 1.267667
global_step: 8874, epoch: 22, loss: 1.186724
global_step: 8875, epoch: 22, loss: 1.091498
global_step: 8876, epoch: 22, loss: 1.138176
global_step: 8877, epoch: 22, loss: 1.148990
global_step: 8878, epoch: 22, loss: 1.264880
global_step: 8879, epoch: 22, loss: 1.245903
global_step: 8880, epoch: 22, loss: 0.578929
epoch: 22
train	acc: 0.6161	macro: p 0.4395, r 0.3218, f1: 0.3280	micro: p 0.6161, r 0.6161, f1 0.6161	weighted_f1:0.5630
dev	acc: 0.5419	macro: p 0.3634, r 0.2868, f1: 0.2742	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4727
test	acc: 0.5820	macro: p 0.3700, r 0.2857, f1: 0.2818	micro: p 0.5820, r 0.5820, f1 0.5820	weighted_f1:0.5234
New best model!
global_step: 8881, epoch: 23, loss: 1.209076
global_step: 8882, epoch: 23, loss: 1.197096
global_step: 8883, epoch: 23, loss: 1.154875
global_step: 8884, epoch: 23, loss: 1.181332
global_step: 8885, epoch: 23, loss: 1.218500
global_step: 8886, epoch: 23, loss: 1.281535
global_step: 8887, epoch: 23, loss: 1.245474
global_step: 8888, epoch: 23, loss: 1.236517
global_step: 8889, epoch: 23, loss: 1.299379
global_step: 8890, epoch: 23, loss: 1.173026
global_step: 8891, epoch: 23, loss: 1.113114
global_step: 8892, epoch: 23, loss: 1.172851
global_step: 8893, epoch: 23, loss: 1.281672
global_step: 8894, epoch: 23, loss: 1.211144
global_step: 8895, epoch: 23, loss: 1.164947
global_step: 8896, epoch: 23, loss: 1.133169
global_step: 8897, epoch: 23, loss: 1.265969
global_step: 8898, epoch: 23, loss: 1.123842
global_step: 8899, epoch: 23, loss: 1.267252
global_step: 8900, epoch: 23, loss: 1.307670
global_step: 8901, epoch: 23, loss: 1.243595
global_step: 8902, epoch: 23, loss: 1.219990
global_step: 8903, epoch: 23, loss: 1.231008
global_step: 8904, epoch: 23, loss: 1.205064
global_step: 8905, epoch: 23, loss: 1.278036
global_step: 8906, epoch: 23, loss: 1.225516
global_step: 8907, epoch: 23, loss: 1.164192
global_step: 8908, epoch: 23, loss: 1.253532
global_step: 8909, epoch: 23, loss: 1.188630
global_step: 8910, epoch: 23, loss: 1.188809
global_step: 8911, epoch: 23, loss: 1.134744
global_step: 8912, epoch: 23, loss: 1.325729
global_step: 8913, epoch: 23, loss: 1.224731
global_step: 8914, epoch: 23, loss: 1.280734
global_step: 8915, epoch: 23, loss: 1.196205
global_step: 8916, epoch: 23, loss: 1.211487
global_step: 8917, epoch: 23, loss: 1.181133
global_step: 8918, epoch: 23, loss: 1.204040
global_step: 8919, epoch: 23, loss: 1.228273
global_step: 8920, epoch: 23, loss: 1.789347
epoch: 23
train	acc: 0.6249	macro: p 0.4246, r 0.3356, f1: 0.3433	micro: p 0.6249, r 0.6249, f1 0.6249	weighted_f1:0.5768
dev	acc: 0.5482	macro: p 0.3757, r 0.2967, f1: 0.2832	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4812
test	acc: 0.5870	macro: p 0.3742, r 0.2969, f1: 0.2946	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5334
New best model!
global_step: 8921, epoch: 24, loss: 1.258780
global_step: 8922, epoch: 24, loss: 1.184343
global_step: 8923, epoch: 24, loss: 1.223333
global_step: 8924, epoch: 24, loss: 1.071700
global_step: 8925, epoch: 24, loss: 1.224803
global_step: 8926, epoch: 24, loss: 1.191085
global_step: 8927, epoch: 24, loss: 1.220667
global_step: 8928, epoch: 24, loss: 1.228297
global_step: 8929, epoch: 24, loss: 1.155241
global_step: 8930, epoch: 24, loss: 1.113059
global_step: 8931, epoch: 24, loss: 1.278409
global_step: 8932, epoch: 24, loss: 1.254203
global_step: 8933, epoch: 24, loss: 1.270614
global_step: 8934, epoch: 24, loss: 1.280145
global_step: 8935, epoch: 24, loss: 1.245042
global_step: 8936, epoch: 24, loss: 1.158163
global_step: 8937, epoch: 24, loss: 1.186330
global_step: 8938, epoch: 24, loss: 1.117275
global_step: 8939, epoch: 24, loss: 1.329304
global_step: 8940, epoch: 24, loss: 1.186593
global_step: 8941, epoch: 24, loss: 1.226799
global_step: 8942, epoch: 24, loss: 1.268952
global_step: 8943, epoch: 24, loss: 1.134502
global_step: 8944, epoch: 24, loss: 1.119923
global_step: 8945, epoch: 24, loss: 1.229318
global_step: 8946, epoch: 24, loss: 1.142179
global_step: 8947, epoch: 24, loss: 1.143187
global_step: 8948, epoch: 24, loss: 1.177989
global_step: 8949, epoch: 24, loss: 1.166142
global_step: 8950, epoch: 24, loss: 1.174754
global_step: 8951, epoch: 24, loss: 1.306770
global_step: 8952, epoch: 24, loss: 1.184634
global_step: 8953, epoch: 24, loss: 1.342796
global_step: 8954, epoch: 24, loss: 1.136157
global_step: 8955, epoch: 24, loss: 1.112238
global_step: 8956, epoch: 24, loss: 1.165555
global_step: 8957, epoch: 24, loss: 1.273935
global_step: 8958, epoch: 24, loss: 1.300640
global_step: 8959, epoch: 24, loss: 1.189923
global_step: 8960, epoch: 24, loss: 1.844983
epoch: 24
train	acc: 0.6198	macro: p 0.4327, r 0.3299, f1: 0.3380	micro: p 0.6198, r 0.6198, f1 0.6198	weighted_f1:0.5703
dev	acc: 0.5437	macro: p 0.3508, r 0.2892, f1: 0.2806	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4787
test	acc: 0.5897	macro: p 0.3781, r 0.2948, f1: 0.2962	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5359
global_step: 8961, epoch: 25, loss: 1.139579
global_step: 8962, epoch: 25, loss: 1.101379
global_step: 8963, epoch: 25, loss: 1.166525
global_step: 8964, epoch: 25, loss: 1.255031
global_step: 8965, epoch: 25, loss: 1.336648
global_step: 8966, epoch: 25, loss: 1.168763
global_step: 8967, epoch: 25, loss: 1.160569
global_step: 8968, epoch: 25, loss: 1.149934
global_step: 8969, epoch: 25, loss: 1.079888
global_step: 8970, epoch: 25, loss: 1.109249
global_step: 8971, epoch: 25, loss: 1.121674
global_step: 8972, epoch: 25, loss: 1.242209
global_step: 8973, epoch: 25, loss: 1.175915
global_step: 8974, epoch: 25, loss: 1.211562
global_step: 8975, epoch: 25, loss: 1.161082
global_step: 8976, epoch: 25, loss: 1.140240
global_step: 8977, epoch: 25, loss: 1.219594
global_step: 8978, epoch: 25, loss: 1.167944
global_step: 8979, epoch: 25, loss: 1.279066
global_step: 8980, epoch: 25, loss: 1.300134
global_step: 8981, epoch: 25, loss: 1.243501
global_step: 8982, epoch: 25, loss: 1.256688
global_step: 8983, epoch: 25, loss: 1.194324
global_step: 8984, epoch: 25, loss: 1.123199
global_step: 8985, epoch: 25, loss: 1.170318
global_step: 8986, epoch: 25, loss: 1.250448
global_step: 8987, epoch: 25, loss: 1.252268
global_step: 8988, epoch: 25, loss: 1.197609
global_step: 8989, epoch: 25, loss: 1.176870
global_step: 8990, epoch: 25, loss: 1.315181
global_step: 8991, epoch: 25, loss: 1.100543
global_step: 8992, epoch: 25, loss: 1.265894
global_step: 8993, epoch: 25, loss: 1.192863
global_step: 8994, epoch: 25, loss: 1.232942
global_step: 8995, epoch: 25, loss: 1.046414
global_step: 8996, epoch: 25, loss: 1.288523
global_step: 8997, epoch: 25, loss: 1.204601
global_step: 8998, epoch: 25, loss: 1.193250
global_step: 8999, epoch: 25, loss: 1.240516
global_step: 9000, epoch: 25, loss: 1.570235
epoch: 25
train	acc: 0.6281	macro: p 0.4257, r 0.3422, f1: 0.3484	micro: p 0.6281, r 0.6281, f1 0.6281	weighted_f1:0.5819
dev	acc: 0.5464	macro: p 0.3443, r 0.2954, f1: 0.2868	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4847
test	acc: 0.5885	macro: p 0.3803, r 0.2991, f1: 0.2988	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5377
New best model!
global_step: 9001, epoch: 26, loss: 1.206161
global_step: 9002, epoch: 26, loss: 1.103010
global_step: 9003, epoch: 26, loss: 1.213085
global_step: 9004, epoch: 26, loss: 1.211602
global_step: 9005, epoch: 26, loss: 1.168586
global_step: 9006, epoch: 26, loss: 1.157746
global_step: 9007, epoch: 26, loss: 1.184620
global_step: 9008, epoch: 26, loss: 1.186549
global_step: 9009, epoch: 26, loss: 1.246587
global_step: 9010, epoch: 26, loss: 1.238693
global_step: 9011, epoch: 26, loss: 1.090094
global_step: 9012, epoch: 26, loss: 1.143661
global_step: 9013, epoch: 26, loss: 1.162072
global_step: 9014, epoch: 26, loss: 1.168843
global_step: 9015, epoch: 26, loss: 1.247378
global_step: 9016, epoch: 26, loss: 1.127537
global_step: 9017, epoch: 26, loss: 1.230784
global_step: 9018, epoch: 26, loss: 1.126686
global_step: 9019, epoch: 26, loss: 1.291960
global_step: 9020, epoch: 26, loss: 1.158783
global_step: 9021, epoch: 26, loss: 1.118209
global_step: 9022, epoch: 26, loss: 1.175253
global_step: 9023, epoch: 26, loss: 1.195205
global_step: 9024, epoch: 26, loss: 1.229544
global_step: 9025, epoch: 26, loss: 1.237481
global_step: 9026, epoch: 26, loss: 1.227263
global_step: 9027, epoch: 26, loss: 1.150253
global_step: 9028, epoch: 26, loss: 1.214971
global_step: 9029, epoch: 26, loss: 1.120141
global_step: 9030, epoch: 26, loss: 1.202388
global_step: 9031, epoch: 26, loss: 1.208757
global_step: 9032, epoch: 26, loss: 1.112713
global_step: 9033, epoch: 26, loss: 1.263404
global_step: 9034, epoch: 26, loss: 1.241829
global_step: 9035, epoch: 26, loss: 1.112048
global_step: 9036, epoch: 26, loss: 1.228566
global_step: 9037, epoch: 26, loss: 1.145372
global_step: 9038, epoch: 26, loss: 1.231886
global_step: 9039, epoch: 26, loss: 1.246845
global_step: 9040, epoch: 26, loss: 1.393127
epoch: 26
train	acc: 0.6310	macro: p 0.4207, r 0.3482, f1: 0.3549	micro: p 0.6310, r 0.6310, f1 0.6310	weighted_f1:0.5869
dev	acc: 0.5464	macro: p 0.3489, r 0.2964, f1: 0.2888	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4863
test	acc: 0.5885	macro: p 0.3667, r 0.3039, f1: 0.3048	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5411
New best model!
global_step: 9041, epoch: 27, loss: 1.158658
global_step: 9042, epoch: 27, loss: 1.116827
global_step: 9043, epoch: 27, loss: 1.200660
global_step: 9044, epoch: 27, loss: 1.266794
global_step: 9045, epoch: 27, loss: 1.252160
global_step: 9046, epoch: 27, loss: 1.165295
global_step: 9047, epoch: 27, loss: 1.178332
global_step: 9048, epoch: 27, loss: 1.146758
global_step: 9049, epoch: 27, loss: 1.235901
global_step: 9050, epoch: 27, loss: 1.103688
global_step: 9051, epoch: 27, loss: 1.247476
global_step: 9052, epoch: 27, loss: 1.222985
global_step: 9053, epoch: 27, loss: 1.109291
global_step: 9054, epoch: 27, loss: 1.171194
global_step: 9055, epoch: 27, loss: 1.318697
global_step: 9056, epoch: 27, loss: 1.192512
global_step: 9057, epoch: 27, loss: 1.189919
global_step: 9058, epoch: 27, loss: 1.069854
global_step: 9059, epoch: 27, loss: 1.251548
global_step: 9060, epoch: 27, loss: 1.105834
global_step: 9061, epoch: 27, loss: 1.211893
global_step: 9062, epoch: 27, loss: 1.125162
global_step: 9063, epoch: 27, loss: 1.195439
global_step: 9064, epoch: 27, loss: 1.151164
global_step: 9065, epoch: 27, loss: 1.165903
global_step: 9066, epoch: 27, loss: 1.135296
global_step: 9067, epoch: 27, loss: 1.250470
global_step: 9068, epoch: 27, loss: 1.226311
global_step: 9069, epoch: 27, loss: 1.218728
global_step: 9070, epoch: 27, loss: 1.177788
global_step: 9071, epoch: 27, loss: 1.323586
global_step: 9072, epoch: 27, loss: 1.149431
global_step: 9073, epoch: 27, loss: 1.171809
global_step: 9074, epoch: 27, loss: 1.093914
global_step: 9075, epoch: 27, loss: 1.130912
global_step: 9076, epoch: 27, loss: 1.104027
global_step: 9077, epoch: 27, loss: 1.166672
global_step: 9078, epoch: 27, loss: 1.186897
global_step: 9079, epoch: 27, loss: 1.173989
global_step: 9080, epoch: 27, loss: 1.419136
epoch: 27
train	acc: 0.6295	macro: p 0.4264, r 0.3427, f1: 0.3514	micro: p 0.6295, r 0.6295, f1 0.6295	weighted_f1:0.5830
dev	acc: 0.5464	macro: p 0.3512, r 0.2951, f1: 0.2883	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4849
test	acc: 0.5885	macro: p 0.3768, r 0.2984, f1: 0.2999	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5372
global_step: 9081, epoch: 28, loss: 1.269429
global_step: 9082, epoch: 28, loss: 1.221632
global_step: 9083, epoch: 28, loss: 1.112303
global_step: 9084, epoch: 28, loss: 1.156316
global_step: 9085, epoch: 28, loss: 1.186612
global_step: 9086, epoch: 28, loss: 1.198676
global_step: 9087, epoch: 28, loss: 1.170743
global_step: 9088, epoch: 28, loss: 1.220381
global_step: 9089, epoch: 28, loss: 1.179256
global_step: 9090, epoch: 28, loss: 1.174711
global_step: 9091, epoch: 28, loss: 1.162057
global_step: 9092, epoch: 28, loss: 1.240553
global_step: 9093, epoch: 28, loss: 1.255931
global_step: 9094, epoch: 28, loss: 1.179436
global_step: 9095, epoch: 28, loss: 1.177261
global_step: 9096, epoch: 28, loss: 1.149872
global_step: 9097, epoch: 28, loss: 1.100649
global_step: 9098, epoch: 28, loss: 1.224066
global_step: 9099, epoch: 28, loss: 1.180552
global_step: 9100, epoch: 28, loss: 1.209348
global_step: 9101, epoch: 28, loss: 1.107282
global_step: 9102, epoch: 28, loss: 1.116706
global_step: 9103, epoch: 28, loss: 1.266671
global_step: 9104, epoch: 28, loss: 1.177786
global_step: 9105, epoch: 28, loss: 1.094468
global_step: 9106, epoch: 28, loss: 1.175254
global_step: 9107, epoch: 28, loss: 1.281098
global_step: 9108, epoch: 28, loss: 1.130641
global_step: 9109, epoch: 28, loss: 1.065609
global_step: 9110, epoch: 28, loss: 1.191665
global_step: 9111, epoch: 28, loss: 1.175859
global_step: 9112, epoch: 28, loss: 1.181030
global_step: 9113, epoch: 28, loss: 1.162086
global_step: 9114, epoch: 28, loss: 1.076269
global_step: 9115, epoch: 28, loss: 1.215873
global_step: 9116, epoch: 28, loss: 1.156291
global_step: 9117, epoch: 28, loss: 1.214871
global_step: 9118, epoch: 28, loss: 1.184714
global_step: 9119, epoch: 28, loss: 1.114648
global_step: 9120, epoch: 28, loss: 0.756928
epoch: 28
train	acc: 0.6358	macro: p 0.4272, r 0.3493, f1: 0.3585	micro: p 0.6358, r 0.6358, f1 0.6358	weighted_f1:0.5906
dev	acc: 0.5500	macro: p 0.3554, r 0.3001, f1: 0.2922	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4892
test	acc: 0.5900	macro: p 0.3670, r 0.3017, f1: 0.3028	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5400
New best model!
global_step: 9121, epoch: 29, loss: 1.076029
global_step: 9122, epoch: 29, loss: 1.220152
global_step: 9123, epoch: 29, loss: 1.119383
global_step: 9124, epoch: 29, loss: 1.186803
global_step: 9125, epoch: 29, loss: 1.279640
global_step: 9126, epoch: 29, loss: 1.123611
global_step: 9127, epoch: 29, loss: 1.068934
global_step: 9128, epoch: 29, loss: 1.116885
global_step: 9129, epoch: 29, loss: 1.282255
global_step: 9130, epoch: 29, loss: 1.273213
global_step: 9131, epoch: 29, loss: 1.245329
global_step: 9132, epoch: 29, loss: 1.084685
global_step: 9133, epoch: 29, loss: 1.181773
global_step: 9134, epoch: 29, loss: 1.205193
global_step: 9135, epoch: 29, loss: 1.216248
global_step: 9136, epoch: 29, loss: 1.286633
global_step: 9137, epoch: 29, loss: 1.126715
global_step: 9138, epoch: 29, loss: 1.219498
global_step: 9139, epoch: 29, loss: 1.156167
global_step: 9140, epoch: 29, loss: 1.168845
global_step: 9141, epoch: 29, loss: 1.184396
global_step: 9142, epoch: 29, loss: 1.142016
global_step: 9143, epoch: 29, loss: 1.120943
global_step: 9144, epoch: 29, loss: 1.088326
global_step: 9145, epoch: 29, loss: 1.052839
global_step: 9146, epoch: 29, loss: 1.154908
global_step: 9147, epoch: 29, loss: 1.211542
global_step: 9148, epoch: 29, loss: 1.211025
global_step: 9149, epoch: 29, loss: 1.127152
global_step: 9150, epoch: 29, loss: 1.102260
global_step: 9151, epoch: 29, loss: 1.070038
global_step: 9152, epoch: 29, loss: 1.181027
global_step: 9153, epoch: 29, loss: 1.185237
global_step: 9154, epoch: 29, loss: 1.179458
global_step: 9155, epoch: 29, loss: 1.085518
global_step: 9156, epoch: 29, loss: 1.202697
global_step: 9157, epoch: 29, loss: 1.098346
global_step: 9158, epoch: 29, loss: 1.144381
global_step: 9159, epoch: 29, loss: 1.219621
global_step: 9160, epoch: 29, loss: 1.095523
epoch: 29
train	acc: 0.6402	macro: p 0.4274, r 0.3558, f1: 0.3623	micro: p 0.6402, r 0.6402, f1 0.6402	weighted_f1:0.5955
dev	acc: 0.5473	macro: p 0.3559, r 0.2986, f1: 0.2886	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4858
test	acc: 0.5877	macro: p 0.3667, r 0.3020, f1: 0.3004	micro: p 0.5877, r 0.5877, f1 0.5877	weighted_f1:0.5380
global_step: 9161, epoch: 30, loss: 1.156868
global_step: 9162, epoch: 30, loss: 1.112433
global_step: 9163, epoch: 30, loss: 1.155569
global_step: 9164, epoch: 30, loss: 1.078777
global_step: 9165, epoch: 30, loss: 1.088030
global_step: 9166, epoch: 30, loss: 1.128901
global_step: 9167, epoch: 30, loss: 1.124349
global_step: 9168, epoch: 30, loss: 1.216689
global_step: 9169, epoch: 30, loss: 1.162742
global_step: 9170, epoch: 30, loss: 1.275665
global_step: 9171, epoch: 30, loss: 1.227903
global_step: 9172, epoch: 30, loss: 0.978985
global_step: 9173, epoch: 30, loss: 1.157124
global_step: 9174, epoch: 30, loss: 1.202442
global_step: 9175, epoch: 30, loss: 1.166515
global_step: 9176, epoch: 30, loss: 1.168763
global_step: 9177, epoch: 30, loss: 1.123469
global_step: 9178, epoch: 30, loss: 1.169284
global_step: 9179, epoch: 30, loss: 1.180511
global_step: 9180, epoch: 30, loss: 1.207432
global_step: 9181, epoch: 30, loss: 1.180922
global_step: 9182, epoch: 30, loss: 1.215340
global_step: 9183, epoch: 30, loss: 1.091961
global_step: 9184, epoch: 30, loss: 1.241266
global_step: 9185, epoch: 30, loss: 1.042511
global_step: 9186, epoch: 30, loss: 1.228431
global_step: 9187, epoch: 30, loss: 1.152633
global_step: 9188, epoch: 30, loss: 1.140541
global_step: 9189, epoch: 30, loss: 1.121931
global_step: 9190, epoch: 30, loss: 1.162015
global_step: 9191, epoch: 30, loss: 1.104024
global_step: 9192, epoch: 30, loss: 1.262168
global_step: 9193, epoch: 30, loss: 1.127649
global_step: 9194, epoch: 30, loss: 1.149529
global_step: 9195, epoch: 30, loss: 1.054994
global_step: 9196, epoch: 30, loss: 1.259499
global_step: 9197, epoch: 30, loss: 1.164562
global_step: 9198, epoch: 30, loss: 1.188871
global_step: 9199, epoch: 30, loss: 1.236650
global_step: 9200, epoch: 30, loss: 0.765172
epoch: 30
train	acc: 0.6425	macro: p 0.4341, r 0.3556, f1: 0.3647	micro: p 0.6425, r 0.6425, f1 0.6425	weighted_f1:0.5979
dev	acc: 0.5482	macro: p 0.3565, r 0.2994, f1: 0.2898	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4864
test	acc: 0.5912	macro: p 0.3697, r 0.3042, f1: 0.3043	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5413
global_step: 9201, epoch: 31, loss: 1.117016
global_step: 9202, epoch: 31, loss: 1.128797
global_step: 9203, epoch: 31, loss: 1.198400
global_step: 9204, epoch: 31, loss: 1.100929
global_step: 9205, epoch: 31, loss: 1.188150
global_step: 9206, epoch: 31, loss: 1.196528
global_step: 9207, epoch: 31, loss: 1.079646
global_step: 9208, epoch: 31, loss: 1.179150
global_step: 9209, epoch: 31, loss: 1.085786
global_step: 9210, epoch: 31, loss: 1.124828
global_step: 9211, epoch: 31, loss: 1.124189
global_step: 9212, epoch: 31, loss: 1.181261
global_step: 9213, epoch: 31, loss: 1.147763
global_step: 9214, epoch: 31, loss: 1.342753
global_step: 9215, epoch: 31, loss: 1.122934
global_step: 9216, epoch: 31, loss: 1.107786
global_step: 9217, epoch: 31, loss: 1.189323
global_step: 9218, epoch: 31, loss: 1.243305
global_step: 9219, epoch: 31, loss: 1.152972
global_step: 9220, epoch: 31, loss: 1.172324
global_step: 9221, epoch: 31, loss: 1.183961
global_step: 9222, epoch: 31, loss: 1.108429
global_step: 9223, epoch: 31, loss: 1.127463
global_step: 9224, epoch: 31, loss: 1.169433
global_step: 9225, epoch: 31, loss: 1.126605
global_step: 9226, epoch: 31, loss: 1.067938
global_step: 9227, epoch: 31, loss: 1.141691
global_step: 9228, epoch: 31, loss: 1.123042
global_step: 9229, epoch: 31, loss: 1.326862
global_step: 9230, epoch: 31, loss: 1.154635
global_step: 9231, epoch: 31, loss: 1.135912
global_step: 9232, epoch: 31, loss: 1.212759
global_step: 9233, epoch: 31, loss: 1.074964
global_step: 9234, epoch: 31, loss: 1.172331
global_step: 9235, epoch: 31, loss: 1.148428
global_step: 9236, epoch: 31, loss: 1.101824
global_step: 9237, epoch: 31, loss: 1.153965
global_step: 9238, epoch: 31, loss: 1.120184
global_step: 9239, epoch: 31, loss: 1.096232
global_step: 9240, epoch: 31, loss: 0.723690
epoch: 31
train	acc: 0.6385	macro: p 0.4442, r 0.3466, f1: 0.3585	micro: p 0.6385, r 0.6385, f1 0.6385	weighted_f1:0.5905
dev	acc: 0.5509	macro: p 0.3603, r 0.2967, f1: 0.2874	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4849
test	acc: 0.5900	macro: p 0.3765, r 0.2966, f1: 0.2970	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5347
global_step: 9241, epoch: 32, loss: 1.055537
global_step: 9242, epoch: 32, loss: 1.186371
global_step: 9243, epoch: 32, loss: 1.064558
global_step: 9244, epoch: 32, loss: 1.169592
global_step: 9245, epoch: 32, loss: 1.078794
global_step: 9246, epoch: 32, loss: 1.160452
global_step: 9247, epoch: 32, loss: 1.110481
global_step: 9248, epoch: 32, loss: 1.121429
global_step: 9249, epoch: 32, loss: 1.096807
global_step: 9250, epoch: 32, loss: 1.097406
global_step: 9251, epoch: 32, loss: 1.143585
global_step: 9252, epoch: 32, loss: 1.218470
global_step: 9253, epoch: 32, loss: 1.107754
global_step: 9254, epoch: 32, loss: 1.059693
global_step: 9255, epoch: 32, loss: 1.096585
global_step: 9256, epoch: 32, loss: 1.205188
global_step: 9257, epoch: 32, loss: 1.173417
global_step: 9258, epoch: 32, loss: 1.173936
global_step: 9259, epoch: 32, loss: 1.211656
global_step: 9260, epoch: 32, loss: 1.121946
global_step: 9261, epoch: 32, loss: 1.151008
global_step: 9262, epoch: 32, loss: 1.122718
global_step: 9263, epoch: 32, loss: 1.172217
global_step: 9264, epoch: 32, loss: 1.227766
global_step: 9265, epoch: 32, loss: 1.124995
global_step: 9266, epoch: 32, loss: 1.175939
global_step: 9267, epoch: 32, loss: 1.153618
global_step: 9268, epoch: 32, loss: 1.153379
global_step: 9269, epoch: 32, loss: 1.225979
global_step: 9270, epoch: 32, loss: 1.195595
global_step: 9271, epoch: 32, loss: 1.123832
global_step: 9272, epoch: 32, loss: 1.181564
global_step: 9273, epoch: 32, loss: 1.163639
global_step: 9274, epoch: 32, loss: 1.074545
global_step: 9275, epoch: 32, loss: 1.122185
global_step: 9276, epoch: 32, loss: 1.114349
global_step: 9277, epoch: 32, loss: 1.025624
global_step: 9278, epoch: 32, loss: 1.134017
global_step: 9279, epoch: 32, loss: 1.107039
global_step: 9280, epoch: 32, loss: 1.710645
epoch: 32
train	acc: 0.6432	macro: p 0.4410, r 0.3538, f1: 0.3642	micro: p 0.6432, r 0.6432, f1 0.6432	weighted_f1:0.5971
dev	acc: 0.5518	macro: p 0.3680, r 0.3004, f1: 0.2932	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4899
test	acc: 0.5904	macro: p 0.3721, r 0.2984, f1: 0.2988	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5371
New best model!
global_step: 9281, epoch: 33, loss: 1.077160
global_step: 9282, epoch: 33, loss: 1.147004
global_step: 9283, epoch: 33, loss: 1.019154
global_step: 9284, epoch: 33, loss: 1.136243
global_step: 9285, epoch: 33, loss: 1.145415
global_step: 9286, epoch: 33, loss: 1.087392
global_step: 9287, epoch: 33, loss: 1.163969
global_step: 9288, epoch: 33, loss: 1.138033
global_step: 9289, epoch: 33, loss: 1.090939
global_step: 9290, epoch: 33, loss: 1.101672
global_step: 9291, epoch: 33, loss: 1.086217
global_step: 9292, epoch: 33, loss: 1.169142
global_step: 9293, epoch: 33, loss: 1.123842
global_step: 9294, epoch: 33, loss: 1.205353
global_step: 9295, epoch: 33, loss: 1.054109
global_step: 9296, epoch: 33, loss: 1.140010
global_step: 9297, epoch: 33, loss: 1.027026
global_step: 9298, epoch: 33, loss: 1.127266
global_step: 9299, epoch: 33, loss: 1.111434
global_step: 9300, epoch: 33, loss: 1.032809
global_step: 9301, epoch: 33, loss: 1.219938
global_step: 9302, epoch: 33, loss: 1.314288
global_step: 9303, epoch: 33, loss: 1.186439
global_step: 9304, epoch: 33, loss: 1.107827
global_step: 9305, epoch: 33, loss: 1.131777
global_step: 9306, epoch: 33, loss: 1.249108
global_step: 9307, epoch: 33, loss: 1.094081
global_step: 9308, epoch: 33, loss: 1.169942
global_step: 9309, epoch: 33, loss: 1.198897
global_step: 9310, epoch: 33, loss: 1.142673
global_step: 9311, epoch: 33, loss: 1.037033
global_step: 9312, epoch: 33, loss: 1.149499
global_step: 9313, epoch: 33, loss: 1.039578
global_step: 9314, epoch: 33, loss: 1.133234
global_step: 9315, epoch: 33, loss: 1.173752
global_step: 9316, epoch: 33, loss: 1.070355
global_step: 9317, epoch: 33, loss: 1.183777
global_step: 9318, epoch: 33, loss: 1.198074
global_step: 9319, epoch: 33, loss: 1.211798
global_step: 9320, epoch: 33, loss: 2.056784
epoch: 33
train	acc: 0.6603	macro: p 0.4356, r 0.3830, f1: 0.3903	micro: p 0.6603, r 0.6603, f1 0.6603	weighted_f1:0.6220
dev	acc: 0.5528	macro: p 0.3532, r 0.3084, f1: 0.3024	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4986
test	acc: 0.5870	macro: p 0.3563, r 0.3073, f1: 0.3075	micro: p 0.5870, r 0.5870, f1 0.5870	weighted_f1:0.5425
New best model!
global_step: 9321, epoch: 34, loss: 1.139653
global_step: 9322, epoch: 34, loss: 1.235347
global_step: 9323, epoch: 34, loss: 1.071557
global_step: 9324, epoch: 34, loss: 1.047171
global_step: 9325, epoch: 34, loss: 1.253572
global_step: 9326, epoch: 34, loss: 1.176605
global_step: 9327, epoch: 34, loss: 1.074141
global_step: 9328, epoch: 34, loss: 1.026328
global_step: 9329, epoch: 34, loss: 1.074270
global_step: 9330, epoch: 34, loss: 1.154750
global_step: 9331, epoch: 34, loss: 1.123608
global_step: 9332, epoch: 34, loss: 1.172684
global_step: 9333, epoch: 34, loss: 1.238448
global_step: 9334, epoch: 34, loss: 1.032220
global_step: 9335, epoch: 34, loss: 1.044933
global_step: 9336, epoch: 34, loss: 1.050895
global_step: 9337, epoch: 34, loss: 1.248647
global_step: 9338, epoch: 34, loss: 1.174066
global_step: 9339, epoch: 34, loss: 1.215687
global_step: 9340, epoch: 34, loss: 1.091685
global_step: 9341, epoch: 34, loss: 1.069539
global_step: 9342, epoch: 34, loss: 1.090055
global_step: 9343, epoch: 34, loss: 1.092841
global_step: 9344, epoch: 34, loss: 1.095716
global_step: 9345, epoch: 34, loss: 1.095328
global_step: 9346, epoch: 34, loss: 1.136545
global_step: 9347, epoch: 34, loss: 1.085624
global_step: 9348, epoch: 34, loss: 1.182885
global_step: 9349, epoch: 34, loss: 1.014930
global_step: 9350, epoch: 34, loss: 1.088967
global_step: 9351, epoch: 34, loss: 1.213720
global_step: 9352, epoch: 34, loss: 1.126701
global_step: 9353, epoch: 34, loss: 1.041505
global_step: 9354, epoch: 34, loss: 1.115450
global_step: 9355, epoch: 34, loss: 1.160638
global_step: 9356, epoch: 34, loss: 1.110585
global_step: 9357, epoch: 34, loss: 1.210073
global_step: 9358, epoch: 34, loss: 1.066284
global_step: 9359, epoch: 34, loss: 1.121058
global_step: 9360, epoch: 34, loss: 1.252129
epoch: 34
train	acc: 0.6571	macro: p 0.4396, r 0.3749, f1: 0.3849	micro: p 0.6571, r 0.6571, f1 0.6571	weighted_f1:0.6162
dev	acc: 0.5555	macro: p 0.3653, r 0.3093, f1: 0.3002	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4963
test	acc: 0.5920	macro: p 0.3650, r 0.3095, f1: 0.3090	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5440
global_step: 9361, epoch: 35, loss: 1.222781
global_step: 9362, epoch: 35, loss: 1.074233
global_step: 9363, epoch: 35, loss: 1.077238
global_step: 9364, epoch: 35, loss: 1.156914
global_step: 9365, epoch: 35, loss: 1.250236
global_step: 9366, epoch: 35, loss: 1.076430
global_step: 9367, epoch: 35, loss: 1.079304
global_step: 9368, epoch: 35, loss: 1.201036
global_step: 9369, epoch: 35, loss: 1.042713
global_step: 9370, epoch: 35, loss: 1.180694
global_step: 9371, epoch: 35, loss: 1.006935
global_step: 9372, epoch: 35, loss: 1.108728
global_step: 9373, epoch: 35, loss: 1.163500
global_step: 9374, epoch: 35, loss: 1.244353
global_step: 9375, epoch: 35, loss: 1.149111
global_step: 9376, epoch: 35, loss: 1.195495
global_step: 9377, epoch: 35, loss: 1.053692
global_step: 9378, epoch: 35, loss: 1.129029
global_step: 9379, epoch: 35, loss: 1.155071
global_step: 9380, epoch: 35, loss: 1.130835
global_step: 9381, epoch: 35, loss: 1.194880
global_step: 9382, epoch: 35, loss: 1.184899
global_step: 9383, epoch: 35, loss: 1.154448
global_step: 9384, epoch: 35, loss: 1.123554
global_step: 9385, epoch: 35, loss: 1.016187
global_step: 9386, epoch: 35, loss: 1.036334
global_step: 9387, epoch: 35, loss: 1.065313
global_step: 9388, epoch: 35, loss: 1.056182
global_step: 9389, epoch: 35, loss: 1.046752
global_step: 9390, epoch: 35, loss: 1.155806
global_step: 9391, epoch: 35, loss: 1.002013
global_step: 9392, epoch: 35, loss: 1.269032
global_step: 9393, epoch: 35, loss: 1.095574
global_step: 9394, epoch: 35, loss: 1.107833
global_step: 9395, epoch: 35, loss: 0.961885
global_step: 9396, epoch: 35, loss: 1.141859
global_step: 9397, epoch: 35, loss: 1.109646
global_step: 9398, epoch: 35, loss: 1.163193
global_step: 9399, epoch: 35, loss: 1.184345
global_step: 9400, epoch: 35, loss: 0.782248
epoch: 35
train	acc: 0.6518	macro: p 0.4452, r 0.3639, f1: 0.3757	micro: p 0.6518, r 0.6518, f1 0.6518	weighted_f1:0.6078
dev	acc: 0.5537	macro: p 0.3720, r 0.3016, f1: 0.2955	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4924
test	acc: 0.5966	macro: p 0.3828, r 0.3065, f1: 0.3097	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5458
global_step: 9401, epoch: 36, loss: 1.101428
global_step: 9402, epoch: 36, loss: 1.066306
global_step: 9403, epoch: 36, loss: 1.090839
global_step: 9404, epoch: 36, loss: 1.201542
global_step: 9405, epoch: 36, loss: 1.058598
global_step: 9406, epoch: 36, loss: 1.138237
global_step: 9407, epoch: 36, loss: 1.175675
global_step: 9408, epoch: 36, loss: 1.136753
global_step: 9409, epoch: 36, loss: 1.160120
global_step: 9410, epoch: 36, loss: 1.149835
global_step: 9411, epoch: 36, loss: 1.124113
global_step: 9412, epoch: 36, loss: 1.066559
global_step: 9413, epoch: 36, loss: 1.088750
global_step: 9414, epoch: 36, loss: 1.125335
global_step: 9415, epoch: 36, loss: 1.120822
global_step: 9416, epoch: 36, loss: 1.147580
global_step: 9417, epoch: 36, loss: 1.228812
global_step: 9418, epoch: 36, loss: 1.074998
global_step: 9419, epoch: 36, loss: 1.145130
global_step: 9420, epoch: 36, loss: 1.053502
global_step: 9421, epoch: 36, loss: 1.138921
global_step: 9422, epoch: 36, loss: 1.130115
global_step: 9423, epoch: 36, loss: 1.054793
global_step: 9424, epoch: 36, loss: 1.088091
global_step: 9425, epoch: 36, loss: 1.173385
global_step: 9426, epoch: 36, loss: 1.133482
global_step: 9427, epoch: 36, loss: 1.044699
global_step: 9428, epoch: 36, loss: 1.113205
global_step: 9429, epoch: 36, loss: 1.003393
global_step: 9430, epoch: 36, loss: 1.072475
global_step: 9431, epoch: 36, loss: 1.098901
global_step: 9432, epoch: 36, loss: 1.023676
global_step: 9433, epoch: 36, loss: 1.100314
global_step: 9434, epoch: 36, loss: 1.016050
global_step: 9435, epoch: 36, loss: 1.134416
global_step: 9436, epoch: 36, loss: 1.231803
global_step: 9437, epoch: 36, loss: 1.094909
global_step: 9438, epoch: 36, loss: 1.067832
global_step: 9439, epoch: 36, loss: 1.121936
global_step: 9440, epoch: 36, loss: 0.589193
epoch: 36
train	acc: 0.6515	macro: p 0.4521, r 0.3610, f1: 0.3738	micro: p 0.6515, r 0.6515, f1 0.6515	weighted_f1:0.6061
dev	acc: 0.5437	macro: p 0.3500, r 0.2913, f1: 0.2787	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4764
test	acc: 0.5935	macro: p 0.3778, r 0.3020, f1: 0.3024	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5395
global_step: 9441, epoch: 37, loss: 1.079517
global_step: 9442, epoch: 37, loss: 1.006600
global_step: 9443, epoch: 37, loss: 1.168150
global_step: 9444, epoch: 37, loss: 1.122433
global_step: 9445, epoch: 37, loss: 1.117272
global_step: 9446, epoch: 37, loss: 1.137261
global_step: 9447, epoch: 37, loss: 1.037717
global_step: 9448, epoch: 37, loss: 1.061406
global_step: 9449, epoch: 37, loss: 1.234201
global_step: 9450, epoch: 37, loss: 1.082124
global_step: 9451, epoch: 37, loss: 1.017270
global_step: 9452, epoch: 37, loss: 1.055708
global_step: 9453, epoch: 37, loss: 1.101473
global_step: 9454, epoch: 37, loss: 1.147630
global_step: 9455, epoch: 37, loss: 1.051217
global_step: 9456, epoch: 37, loss: 1.050592
global_step: 9457, epoch: 37, loss: 1.087110
global_step: 9458, epoch: 37, loss: 1.087503
global_step: 9459, epoch: 37, loss: 1.214382
global_step: 9460, epoch: 37, loss: 1.142128
global_step: 9461, epoch: 37, loss: 1.090407
global_step: 9462, epoch: 37, loss: 1.158112
global_step: 9463, epoch: 37, loss: 1.198608
global_step: 9464, epoch: 37, loss: 1.040941
global_step: 9465, epoch: 37, loss: 1.133538
global_step: 9466, epoch: 37, loss: 1.147476
global_step: 9467, epoch: 37, loss: 1.093053
global_step: 9468, epoch: 37, loss: 0.998789
global_step: 9469, epoch: 37, loss: 1.089152
global_step: 9470, epoch: 37, loss: 1.080111
global_step: 9471, epoch: 37, loss: 1.133315
global_step: 9472, epoch: 37, loss: 1.040369
global_step: 9473, epoch: 37, loss: 1.125389
global_step: 9474, epoch: 37, loss: 1.073437
global_step: 9475, epoch: 37, loss: 1.300933
global_step: 9476, epoch: 37, loss: 1.086408
global_step: 9477, epoch: 37, loss: 1.266119
global_step: 9478, epoch: 37, loss: 1.058145
global_step: 9479, epoch: 37, loss: 1.067039
global_step: 9480, epoch: 37, loss: 0.701905
epoch: 37
train	acc: 0.6670	macro: p 0.4477, r 0.3860, f1: 0.3956	micro: p 0.6670, r 0.6670, f1 0.6670	weighted_f1:0.6270
dev	acc: 0.5546	macro: p 0.3577, r 0.3073, f1: 0.3015	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4976
test	acc: 0.5946	macro: p 0.3651, r 0.3114, f1: 0.3120	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5471
global_step: 9481, epoch: 38, loss: 0.970398
global_step: 9482, epoch: 38, loss: 1.146333
global_step: 9483, epoch: 38, loss: 1.074444
global_step: 9484, epoch: 38, loss: 1.137684
global_step: 9485, epoch: 38, loss: 1.164507
global_step: 9486, epoch: 38, loss: 1.016079
global_step: 9487, epoch: 38, loss: 1.128967
global_step: 9488, epoch: 38, loss: 1.125749
global_step: 9489, epoch: 38, loss: 1.093437
global_step: 9490, epoch: 38, loss: 1.011166
global_step: 9491, epoch: 38, loss: 1.153926
global_step: 9492, epoch: 38, loss: 1.102237
global_step: 9493, epoch: 38, loss: 1.238189
global_step: 9494, epoch: 38, loss: 1.122972
global_step: 9495, epoch: 38, loss: 1.054564
global_step: 9496, epoch: 38, loss: 1.140560
global_step: 9497, epoch: 38, loss: 1.075036
global_step: 9498, epoch: 38, loss: 0.930593
global_step: 9499, epoch: 38, loss: 1.090194
global_step: 9500, epoch: 38, loss: 1.032405
global_step: 9501, epoch: 38, loss: 1.113827
global_step: 9502, epoch: 38, loss: 1.018930
global_step: 9503, epoch: 38, loss: 1.046041
global_step: 9504, epoch: 38, loss: 1.191560
global_step: 9505, epoch: 38, loss: 1.041326
global_step: 9506, epoch: 38, loss: 1.132315
global_step: 9507, epoch: 38, loss: 1.210791
global_step: 9508, epoch: 38, loss: 1.118669
global_step: 9509, epoch: 38, loss: 1.220684
global_step: 9510, epoch: 38, loss: 1.057620
global_step: 9511, epoch: 38, loss: 1.142308
global_step: 9512, epoch: 38, loss: 1.136092
global_step: 9513, epoch: 38, loss: 0.976003
global_step: 9514, epoch: 38, loss: 1.022601
global_step: 9515, epoch: 38, loss: 1.194640
global_step: 9516, epoch: 38, loss: 1.081804
global_step: 9517, epoch: 38, loss: 1.066903
global_step: 9518, epoch: 38, loss: 1.088155
global_step: 9519, epoch: 38, loss: 1.005443
global_step: 9520, epoch: 38, loss: 1.028995
epoch: 38
train	acc: 0.6667	macro: p 0.4520, r 0.3854, f1: 0.3935	micro: p 0.6667, r 0.6667, f1 0.6667	weighted_f1:0.6266
dev	acc: 0.5555	macro: p 0.3655, r 0.3071, f1: 0.3031	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4993
test	acc: 0.5927	macro: p 0.3652, r 0.3072, f1: 0.3089	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5454
New best model!
global_step: 9521, epoch: 39, loss: 1.081326
global_step: 9522, epoch: 39, loss: 1.075983
global_step: 9523, epoch: 39, loss: 1.083957
global_step: 9524, epoch: 39, loss: 1.033969
global_step: 9525, epoch: 39, loss: 1.094878
global_step: 9526, epoch: 39, loss: 1.070687
global_step: 9527, epoch: 39, loss: 1.108123
global_step: 9528, epoch: 39, loss: 1.169443
global_step: 9529, epoch: 39, loss: 1.166614
global_step: 9530, epoch: 39, loss: 0.991811
global_step: 9531, epoch: 39, loss: 1.137525
global_step: 9532, epoch: 39, loss: 1.018111
global_step: 9533, epoch: 39, loss: 1.146761
global_step: 9534, epoch: 39, loss: 1.059790
global_step: 9535, epoch: 39, loss: 1.052260
global_step: 9536, epoch: 39, loss: 1.087872
global_step: 9537, epoch: 39, loss: 1.036554
global_step: 9538, epoch: 39, loss: 1.027296
global_step: 9539, epoch: 39, loss: 1.089993
global_step: 9540, epoch: 39, loss: 0.951430
global_step: 9541, epoch: 39, loss: 1.117077
global_step: 9542, epoch: 39, loss: 1.102344
global_step: 9543, epoch: 39, loss: 1.069953
global_step: 9544, epoch: 39, loss: 1.066573
global_step: 9545, epoch: 39, loss: 1.067224
global_step: 9546, epoch: 39, loss: 1.155566
global_step: 9547, epoch: 39, loss: 1.149590
global_step: 9548, epoch: 39, loss: 1.080971
global_step: 9549, epoch: 39, loss: 1.043283
global_step: 9550, epoch: 39, loss: 1.144195
global_step: 9551, epoch: 39, loss: 1.076650
global_step: 9552, epoch: 39, loss: 1.022923
global_step: 9553, epoch: 39, loss: 1.087937
global_step: 9554, epoch: 39, loss: 1.226036
global_step: 9555, epoch: 39, loss: 1.160954
global_step: 9556, epoch: 39, loss: 1.046861
global_step: 9557, epoch: 39, loss: 1.044011
global_step: 9558, epoch: 39, loss: 1.136633
global_step: 9559, epoch: 39, loss: 1.120370
global_step: 9560, epoch: 39, loss: 0.656734
epoch: 39
train	acc: 0.6648	macro: p 0.4584, r 0.3773, f1: 0.3894	micro: p 0.6648, r 0.6648, f1 0.6648	weighted_f1:0.6227
dev	acc: 0.5491	macro: p 0.3553, r 0.2994, f1: 0.2878	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4855
test	acc: 0.5954	macro: p 0.3737, r 0.3079, f1: 0.3069	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5432
global_step: 9561, epoch: 40, loss: 1.098724
global_step: 9562, epoch: 40, loss: 1.034652
global_step: 9563, epoch: 40, loss: 1.067207
global_step: 9564, epoch: 40, loss: 1.112010
global_step: 9565, epoch: 40, loss: 1.079554
global_step: 9566, epoch: 40, loss: 1.074208
global_step: 9567, epoch: 40, loss: 1.062041
global_step: 9568, epoch: 40, loss: 1.034599
global_step: 9569, epoch: 40, loss: 1.004337
global_step: 9570, epoch: 40, loss: 1.064771
global_step: 9571, epoch: 40, loss: 1.033774
global_step: 9572, epoch: 40, loss: 1.166529
global_step: 9573, epoch: 40, loss: 1.121294
global_step: 9574, epoch: 40, loss: 0.979695
global_step: 9575, epoch: 40, loss: 1.124156
global_step: 9576, epoch: 40, loss: 1.019477
global_step: 9577, epoch: 40, loss: 1.067511
global_step: 9578, epoch: 40, loss: 1.107194
global_step: 9579, epoch: 40, loss: 1.184640
global_step: 9580, epoch: 40, loss: 1.170015
global_step: 9581, epoch: 40, loss: 1.100233
global_step: 9582, epoch: 40, loss: 1.101516
global_step: 9583, epoch: 40, loss: 1.103183
global_step: 9584, epoch: 40, loss: 1.018474
global_step: 9585, epoch: 40, loss: 1.089350
global_step: 9586, epoch: 40, loss: 1.073809
global_step: 9587, epoch: 40, loss: 1.241215
global_step: 9588, epoch: 40, loss: 1.053692
global_step: 9589, epoch: 40, loss: 1.138763
global_step: 9590, epoch: 40, loss: 1.124470
global_step: 9591, epoch: 40, loss: 1.078528
global_step: 9592, epoch: 40, loss: 1.192689
global_step: 9593, epoch: 40, loss: 1.084759
global_step: 9594, epoch: 40, loss: 0.955751
global_step: 9595, epoch: 40, loss: 1.026469
global_step: 9596, epoch: 40, loss: 1.065798
global_step: 9597, epoch: 40, loss: 1.067903
global_step: 9598, epoch: 40, loss: 1.030675
global_step: 9599, epoch: 40, loss: 1.005371
global_step: 9600, epoch: 40, loss: 0.846716
epoch: 40
train	acc: 0.6690	macro: p 0.4596, r 0.3834, f1: 0.3967	micro: p 0.6690, r 0.6690, f1 0.6690	weighted_f1:0.6276
dev	acc: 0.5518	macro: p 0.3600, r 0.3023, f1: 0.2959	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4917
test	acc: 0.5966	macro: p 0.3732, r 0.3080, f1: 0.3115	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5466
global_step: 9601, epoch: 41, loss: 1.136406
global_step: 9602, epoch: 41, loss: 1.025683
global_step: 9603, epoch: 41, loss: 1.079173
global_step: 9604, epoch: 41, loss: 1.119238
global_step: 9605, epoch: 41, loss: 1.085801
global_step: 9606, epoch: 41, loss: 1.142634
global_step: 9607, epoch: 41, loss: 0.993947
global_step: 9608, epoch: 41, loss: 1.108798
global_step: 9609, epoch: 41, loss: 1.008320
global_step: 9610, epoch: 41, loss: 1.123467
global_step: 9611, epoch: 41, loss: 1.140447
global_step: 9612, epoch: 41, loss: 1.002151
global_step: 9613, epoch: 41, loss: 1.021795
global_step: 9614, epoch: 41, loss: 1.109859
global_step: 9615, epoch: 41, loss: 1.104288
global_step: 9616, epoch: 41, loss: 1.015288
global_step: 9617, epoch: 41, loss: 0.949572
global_step: 9618, epoch: 41, loss: 1.058458
global_step: 9619, epoch: 41, loss: 1.129533
global_step: 9620, epoch: 41, loss: 1.145173
global_step: 9621, epoch: 41, loss: 1.003460
global_step: 9622, epoch: 41, loss: 1.113752
global_step: 9623, epoch: 41, loss: 0.997060
global_step: 9624, epoch: 41, loss: 1.161462
global_step: 9625, epoch: 41, loss: 1.109640
global_step: 9626, epoch: 41, loss: 0.916242
global_step: 9627, epoch: 41, loss: 1.102733
global_step: 9628, epoch: 41, loss: 1.123604
global_step: 9629, epoch: 41, loss: 0.990766
global_step: 9630, epoch: 41, loss: 0.990504
global_step: 9631, epoch: 41, loss: 1.143185
global_step: 9632, epoch: 41, loss: 1.040922
global_step: 9633, epoch: 41, loss: 0.996913
global_step: 9634, epoch: 41, loss: 1.076324
global_step: 9635, epoch: 41, loss: 1.011600
global_step: 9636, epoch: 41, loss: 1.108484
global_step: 9637, epoch: 41, loss: 1.151816
global_step: 9638, epoch: 41, loss: 1.054771
global_step: 9639, epoch: 41, loss: 1.101380
global_step: 9640, epoch: 41, loss: 1.203126
epoch: 41
train	acc: 0.6885	macro: p 0.4625, r 0.4129, f1: 0.4214	micro: p 0.6885, r 0.6885, f1 0.6885	weighted_f1:0.6530
dev	acc: 0.5509	macro: p 0.3488, r 0.3081, f1: 0.3030	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4975
test	acc: 0.5950	macro: p 0.3657, r 0.3158, f1: 0.3167	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5509
global_step: 9641, epoch: 42, loss: 1.031635
global_step: 9642, epoch: 42, loss: 1.010368
global_step: 9643, epoch: 42, loss: 1.095159
global_step: 9644, epoch: 42, loss: 1.053018
global_step: 9645, epoch: 42, loss: 1.016305
global_step: 9646, epoch: 42, loss: 1.111667
global_step: 9647, epoch: 42, loss: 1.170100
global_step: 9648, epoch: 42, loss: 1.123306
global_step: 9649, epoch: 42, loss: 1.077771
global_step: 9650, epoch: 42, loss: 1.115570
global_step: 9651, epoch: 42, loss: 1.079869
global_step: 9652, epoch: 42, loss: 0.952255
global_step: 9653, epoch: 42, loss: 1.063631
global_step: 9654, epoch: 42, loss: 1.028673
global_step: 9655, epoch: 42, loss: 1.134262
global_step: 9656, epoch: 42, loss: 1.068758
global_step: 9657, epoch: 42, loss: 1.038731
global_step: 9658, epoch: 42, loss: 1.083781
global_step: 9659, epoch: 42, loss: 1.065985
global_step: 9660, epoch: 42, loss: 1.020965
global_step: 9661, epoch: 42, loss: 1.113729
global_step: 9662, epoch: 42, loss: 1.045410
global_step: 9663, epoch: 42, loss: 1.196993
global_step: 9664, epoch: 42, loss: 1.099951
global_step: 9665, epoch: 42, loss: 1.095498
global_step: 9666, epoch: 42, loss: 1.008753
global_step: 9667, epoch: 42, loss: 0.965562
global_step: 9668, epoch: 42, loss: 1.053305
global_step: 9669, epoch: 42, loss: 1.078117
global_step: 9670, epoch: 42, loss: 1.085297
global_step: 9671, epoch: 42, loss: 1.125505
global_step: 9672, epoch: 42, loss: 1.113716
global_step: 9673, epoch: 42, loss: 1.013826
global_step: 9674, epoch: 42, loss: 0.949553
global_step: 9675, epoch: 42, loss: 0.952722
global_step: 9676, epoch: 42, loss: 1.112637
global_step: 9677, epoch: 42, loss: 0.977491
global_step: 9678, epoch: 42, loss: 1.044478
global_step: 9679, epoch: 42, loss: 1.093854
global_step: 9680, epoch: 42, loss: 0.533570
epoch: 42
train	acc: 0.6738	macro: p 0.4680, r 0.3860, f1: 0.3986	micro: p 0.6738, r 0.6738, f1 0.6738	weighted_f1:0.6324
dev	acc: 0.5464	macro: p 0.3516, r 0.2987, f1: 0.2869	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4828
test	acc: 0.5969	macro: p 0.3726, r 0.3090, f1: 0.3078	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5443
global_step: 9681, epoch: 43, loss: 1.071476
global_step: 9682, epoch: 43, loss: 1.083520
global_step: 9683, epoch: 43, loss: 1.072153
global_step: 9684, epoch: 43, loss: 1.142895
global_step: 9685, epoch: 43, loss: 0.923866
global_step: 9686, epoch: 43, loss: 1.018987
global_step: 9687, epoch: 43, loss: 1.145802
global_step: 9688, epoch: 43, loss: 1.093423
global_step: 9689, epoch: 43, loss: 0.981295
global_step: 9690, epoch: 43, loss: 1.046895
global_step: 9691, epoch: 43, loss: 0.996162
global_step: 9692, epoch: 43, loss: 1.049022
global_step: 9693, epoch: 43, loss: 1.104124
global_step: 9694, epoch: 43, loss: 1.059589
global_step: 9695, epoch: 43, loss: 1.034430
global_step: 9696, epoch: 43, loss: 1.050933
global_step: 9697, epoch: 43, loss: 0.956297
global_step: 9698, epoch: 43, loss: 1.071374
global_step: 9699, epoch: 43, loss: 0.972741
global_step: 9700, epoch: 43, loss: 1.123405
global_step: 9701, epoch: 43, loss: 1.103835
global_step: 9702, epoch: 43, loss: 1.085292
global_step: 9703, epoch: 43, loss: 1.102645
global_step: 9704, epoch: 43, loss: 1.110653
global_step: 9705, epoch: 43, loss: 0.936272
global_step: 9706, epoch: 43, loss: 0.973891
global_step: 9707, epoch: 43, loss: 1.028167
global_step: 9708, epoch: 43, loss: 1.130563
global_step: 9709, epoch: 43, loss: 0.952525
global_step: 9710, epoch: 43, loss: 1.088397
global_step: 9711, epoch: 43, loss: 0.968243
global_step: 9712, epoch: 43, loss: 1.134753
global_step: 9713, epoch: 43, loss: 1.143838
global_step: 9714, epoch: 43, loss: 1.079761
global_step: 9715, epoch: 43, loss: 1.087211
global_step: 9716, epoch: 43, loss: 1.089326
global_step: 9717, epoch: 43, loss: 1.052016
global_step: 9718, epoch: 43, loss: 1.064941
global_step: 9719, epoch: 43, loss: 1.141474
global_step: 9720, epoch: 43, loss: 0.979897
epoch: 43
train	acc: 0.6895	macro: p 0.4671, r 0.4097, f1: 0.4205	micro: p 0.6895, r 0.6895, f1 0.6895	weighted_f1:0.6526
dev	acc: 0.5555	macro: p 0.3575, r 0.3098, f1: 0.3043	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4998
test	acc: 0.5946	macro: p 0.3655, r 0.3107, f1: 0.3132	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5479
New best model!
global_step: 9721, epoch: 44, loss: 1.011570
global_step: 9722, epoch: 44, loss: 1.049617
global_step: 9723, epoch: 44, loss: 1.025466
global_step: 9724, epoch: 44, loss: 0.955078
global_step: 9725, epoch: 44, loss: 1.084899
global_step: 9726, epoch: 44, loss: 1.044861
global_step: 9727, epoch: 44, loss: 0.985740
global_step: 9728, epoch: 44, loss: 1.084852
global_step: 9729, epoch: 44, loss: 0.925653
global_step: 9730, epoch: 44, loss: 1.082199
global_step: 9731, epoch: 44, loss: 1.146685
global_step: 9732, epoch: 44, loss: 0.908422
global_step: 9733, epoch: 44, loss: 0.992416
global_step: 9734, epoch: 44, loss: 1.024692
global_step: 9735, epoch: 44, loss: 0.935125
global_step: 9736, epoch: 44, loss: 1.072865
global_step: 9737, epoch: 44, loss: 0.938822
global_step: 9738, epoch: 44, loss: 1.075934
global_step: 9739, epoch: 44, loss: 1.168752
global_step: 9740, epoch: 44, loss: 1.060704
global_step: 9741, epoch: 44, loss: 1.017451
global_step: 9742, epoch: 44, loss: 1.024515
global_step: 9743, epoch: 44, loss: 0.911303
global_step: 9744, epoch: 44, loss: 0.985016
global_step: 9745, epoch: 44, loss: 1.031203
global_step: 9746, epoch: 44, loss: 1.083598
global_step: 9747, epoch: 44, loss: 1.058856
global_step: 9748, epoch: 44, loss: 1.020032
global_step: 9749, epoch: 44, loss: 1.221576
global_step: 9750, epoch: 44, loss: 1.145945
global_step: 9751, epoch: 44, loss: 1.011208
global_step: 9752, epoch: 44, loss: 1.004542
global_step: 9753, epoch: 44, loss: 1.073230
global_step: 9754, epoch: 44, loss: 1.089923
global_step: 9755, epoch: 44, loss: 1.026911
global_step: 9756, epoch: 44, loss: 0.942622
global_step: 9757, epoch: 44, loss: 1.067908
global_step: 9758, epoch: 44, loss: 1.246148
global_step: 9759, epoch: 44, loss: 1.093945
global_step: 9760, epoch: 44, loss: 1.214944
epoch: 44
train	acc: 0.6957	macro: p 0.4753, r 0.4157, f1: 0.4262	micro: p 0.6957, r 0.6957, f1 0.6957	weighted_f1:0.6593
dev	acc: 0.5455	macro: p 0.3444, r 0.3024, f1: 0.2934	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4886
test	acc: 0.5950	macro: p 0.3701, r 0.3136, f1: 0.3143	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5483
global_step: 9761, epoch: 45, loss: 1.101268
global_step: 9762, epoch: 45, loss: 0.997683
global_step: 9763, epoch: 45, loss: 1.099503
global_step: 9764, epoch: 45, loss: 0.955209
global_step: 9765, epoch: 45, loss: 1.017139
global_step: 9766, epoch: 45, loss: 1.065282
global_step: 9767, epoch: 45, loss: 1.269533
global_step: 9768, epoch: 45, loss: 1.021947
global_step: 9769, epoch: 45, loss: 0.975730
global_step: 9770, epoch: 45, loss: 0.977011
global_step: 9771, epoch: 45, loss: 1.055679
global_step: 9772, epoch: 45, loss: 1.036824
global_step: 9773, epoch: 45, loss: 1.062776
global_step: 9774, epoch: 45, loss: 0.975154
global_step: 9775, epoch: 45, loss: 1.079404
global_step: 9776, epoch: 45, loss: 1.044793
global_step: 9777, epoch: 45, loss: 1.015146
global_step: 9778, epoch: 45, loss: 0.993212
global_step: 9779, epoch: 45, loss: 0.979632
global_step: 9780, epoch: 45, loss: 1.023844
global_step: 9781, epoch: 45, loss: 0.925559
global_step: 9782, epoch: 45, loss: 0.921062
global_step: 9783, epoch: 45, loss: 1.022099
global_step: 9784, epoch: 45, loss: 1.066126
global_step: 9785, epoch: 45, loss: 1.002984
global_step: 9786, epoch: 45, loss: 1.129216
global_step: 9787, epoch: 45, loss: 1.125144
global_step: 9788, epoch: 45, loss: 1.117031
global_step: 9789, epoch: 45, loss: 1.070214
global_step: 9790, epoch: 45, loss: 1.038546
global_step: 9791, epoch: 45, loss: 1.038898
global_step: 9792, epoch: 45, loss: 1.039019
global_step: 9793, epoch: 45, loss: 1.017093
global_step: 9794, epoch: 45, loss: 0.989043
global_step: 9795, epoch: 45, loss: 1.078047
global_step: 9796, epoch: 45, loss: 1.002440
global_step: 9797, epoch: 45, loss: 0.967348
global_step: 9798, epoch: 45, loss: 0.977204
global_step: 9799, epoch: 45, loss: 0.927939
global_step: 9800, epoch: 45, loss: 1.900173
epoch: 45
train	acc: 0.6996	macro: p 0.4768, r 0.4198, f1: 0.4294	micro: p 0.6996, r 0.6996, f1 0.6996	weighted_f1:0.6633
dev	acc: 0.5446	macro: p 0.3433, r 0.3016, f1: 0.2931	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4882
test	acc: 0.5958	macro: p 0.3697, r 0.3143, f1: 0.3153	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5496
global_step: 9801, epoch: 46, loss: 1.033039
global_step: 9802, epoch: 46, loss: 1.007628
global_step: 9803, epoch: 46, loss: 1.035648
global_step: 9804, epoch: 46, loss: 1.002651
global_step: 9805, epoch: 46, loss: 0.941345
global_step: 9806, epoch: 46, loss: 1.051329
global_step: 9807, epoch: 46, loss: 0.961799
global_step: 9808, epoch: 46, loss: 0.949577
global_step: 9809, epoch: 46, loss: 1.033829
global_step: 9810, epoch: 46, loss: 1.036774
global_step: 9811, epoch: 46, loss: 0.988623
global_step: 9812, epoch: 46, loss: 0.951832
global_step: 9813, epoch: 46, loss: 0.985627
global_step: 9814, epoch: 46, loss: 1.053766
global_step: 9815, epoch: 46, loss: 1.049849
global_step: 9816, epoch: 46, loss: 1.071747
global_step: 9817, epoch: 46, loss: 1.048725
global_step: 9818, epoch: 46, loss: 1.115485
global_step: 9819, epoch: 46, loss: 1.077663
global_step: 9820, epoch: 46, loss: 0.993867
global_step: 9821, epoch: 46, loss: 1.002401
global_step: 9822, epoch: 46, loss: 1.037806
global_step: 9823, epoch: 46, loss: 1.166115
global_step: 9824, epoch: 46, loss: 0.985256
global_step: 9825, epoch: 46, loss: 1.045957
global_step: 9826, epoch: 46, loss: 0.943771
global_step: 9827, epoch: 46, loss: 0.959540
global_step: 9828, epoch: 46, loss: 1.011954
global_step: 9829, epoch: 46, loss: 1.016189
global_step: 9830, epoch: 46, loss: 1.082599
global_step: 9831, epoch: 46, loss: 0.951732
global_step: 9832, epoch: 46, loss: 1.008963
global_step: 9833, epoch: 46, loss: 1.115715
global_step: 9834, epoch: 46, loss: 0.975918
global_step: 9835, epoch: 46, loss: 1.030392
global_step: 9836, epoch: 46, loss: 1.024204
global_step: 9837, epoch: 46, loss: 1.015324
global_step: 9838, epoch: 46, loss: 0.960347
global_step: 9839, epoch: 46, loss: 0.987594
global_step: 9840, epoch: 46, loss: 1.332415
epoch: 46
train	acc: 0.7073	macro: p 0.4811, r 0.4350, f1: 0.4448	micro: p 0.7073, r 0.7073, f1 0.7073	weighted_f1:0.6748
dev	acc: 0.5555	macro: p 0.3495, r 0.3122, f1: 0.3085	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5035
test	acc: 0.5966	macro: p 0.3598, r 0.3154, f1: 0.3181	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5527
New best model!
global_step: 9841, epoch: 47, loss: 1.131337
global_step: 9842, epoch: 47, loss: 1.029175
global_step: 9843, epoch: 47, loss: 1.042811
global_step: 9844, epoch: 47, loss: 1.054468
global_step: 9845, epoch: 47, loss: 1.004428
global_step: 9846, epoch: 47, loss: 0.958066
global_step: 9847, epoch: 47, loss: 1.007486
global_step: 9848, epoch: 47, loss: 0.963289
global_step: 9849, epoch: 47, loss: 0.935448
global_step: 9850, epoch: 47, loss: 1.016969
global_step: 9851, epoch: 47, loss: 0.996756
global_step: 9852, epoch: 47, loss: 1.014857
global_step: 9853, epoch: 47, loss: 1.027858
global_step: 9854, epoch: 47, loss: 1.090316
global_step: 9855, epoch: 47, loss: 1.010653
global_step: 9856, epoch: 47, loss: 1.052660
global_step: 9857, epoch: 47, loss: 1.088946
global_step: 9858, epoch: 47, loss: 1.044847
global_step: 9859, epoch: 47, loss: 1.101715
global_step: 9860, epoch: 47, loss: 1.041746
global_step: 9861, epoch: 47, loss: 1.001387
global_step: 9862, epoch: 47, loss: 0.896058
global_step: 9863, epoch: 47, loss: 0.952927
global_step: 9864, epoch: 47, loss: 0.929181
global_step: 9865, epoch: 47, loss: 1.063277
global_step: 9866, epoch: 47, loss: 0.956482
global_step: 9867, epoch: 47, loss: 1.018211
global_step: 9868, epoch: 47, loss: 0.977411
global_step: 9869, epoch: 47, loss: 1.008502
global_step: 9870, epoch: 47, loss: 1.167445
global_step: 9871, epoch: 47, loss: 0.955136
global_step: 9872, epoch: 47, loss: 1.029292
global_step: 9873, epoch: 47, loss: 1.038901
global_step: 9874, epoch: 47, loss: 1.075887
global_step: 9875, epoch: 47, loss: 0.929401
global_step: 9876, epoch: 47, loss: 1.057677
global_step: 9877, epoch: 47, loss: 1.001366
global_step: 9878, epoch: 47, loss: 1.007563
global_step: 9879, epoch: 47, loss: 1.010744
global_step: 9880, epoch: 47, loss: 0.963504
epoch: 47
train	acc: 0.7098	macro: p 0.4870, r 0.4309, f1: 0.4403	micro: p 0.7098, r 0.7098, f1 0.7098	weighted_f1:0.6736
dev	acc: 0.5500	macro: p 0.3475, r 0.3054, f1: 0.2968	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4926
test	acc: 0.5981	macro: p 0.3686, r 0.3171, f1: 0.3171	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5511
global_step: 9881, epoch: 48, loss: 1.001983
global_step: 9882, epoch: 48, loss: 1.011934
global_step: 9883, epoch: 48, loss: 1.133320
global_step: 9884, epoch: 48, loss: 1.016967
global_step: 9885, epoch: 48, loss: 0.950731
global_step: 9886, epoch: 48, loss: 1.014418
global_step: 9887, epoch: 48, loss: 0.962221
global_step: 9888, epoch: 48, loss: 0.985680
global_step: 9889, epoch: 48, loss: 1.017477
global_step: 9890, epoch: 48, loss: 1.060899
global_step: 9891, epoch: 48, loss: 0.986252
global_step: 9892, epoch: 48, loss: 0.990544
global_step: 9893, epoch: 48, loss: 1.093992
global_step: 9894, epoch: 48, loss: 1.011749
global_step: 9895, epoch: 48, loss: 1.052374
global_step: 9896, epoch: 48, loss: 1.132641
global_step: 9897, epoch: 48, loss: 1.085393
global_step: 9898, epoch: 48, loss: 0.968455
global_step: 9899, epoch: 48, loss: 0.924016
global_step: 9900, epoch: 48, loss: 1.038692
global_step: 9901, epoch: 48, loss: 1.005140
global_step: 9902, epoch: 48, loss: 1.016085
global_step: 9903, epoch: 48, loss: 0.948426
global_step: 9904, epoch: 48, loss: 1.044595
global_step: 9905, epoch: 48, loss: 0.957377
global_step: 9906, epoch: 48, loss: 0.899414
global_step: 9907, epoch: 48, loss: 1.040568
global_step: 9908, epoch: 48, loss: 1.124888
global_step: 9909, epoch: 48, loss: 0.981672
global_step: 9910, epoch: 48, loss: 1.039304
global_step: 9911, epoch: 48, loss: 1.001210
global_step: 9912, epoch: 48, loss: 0.949497
global_step: 9913, epoch: 48, loss: 1.048427
global_step: 9914, epoch: 48, loss: 0.899993
global_step: 9915, epoch: 48, loss: 0.996785
global_step: 9916, epoch: 48, loss: 0.954175
global_step: 9917, epoch: 48, loss: 1.094131
global_step: 9918, epoch: 48, loss: 1.014999
global_step: 9919, epoch: 48, loss: 0.936529
global_step: 9920, epoch: 48, loss: 0.975005
epoch: 48
train	acc: 0.7029	macro: p 0.4880, r 0.4186, f1: 0.4302	micro: p 0.7029, r 0.7029, f1 0.7029	weighted_f1:0.6646
dev	acc: 0.5528	macro: p 0.3527, r 0.3045, f1: 0.2966	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4926
test	acc: 0.5981	macro: p 0.3720, r 0.3111, f1: 0.3135	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5491
global_step: 9921, epoch: 49, loss: 1.039409
global_step: 9922, epoch: 49, loss: 0.946925
global_step: 9923, epoch: 49, loss: 1.022915
global_step: 9924, epoch: 49, loss: 0.906619
global_step: 9925, epoch: 49, loss: 1.002087
global_step: 9926, epoch: 49, loss: 0.917692
global_step: 9927, epoch: 49, loss: 1.029142
global_step: 9928, epoch: 49, loss: 0.992306
global_step: 9929, epoch: 49, loss: 0.957059
global_step: 9930, epoch: 49, loss: 1.092134
global_step: 9931, epoch: 49, loss: 1.015625
global_step: 9932, epoch: 49, loss: 1.062912
global_step: 9933, epoch: 49, loss: 1.048559
global_step: 9934, epoch: 49, loss: 0.932355
global_step: 9935, epoch: 49, loss: 1.015188
global_step: 9936, epoch: 49, loss: 1.068747
global_step: 9937, epoch: 49, loss: 0.975100
global_step: 9938, epoch: 49, loss: 1.042266
global_step: 9939, epoch: 49, loss: 1.108006
global_step: 9940, epoch: 49, loss: 1.030166
global_step: 9941, epoch: 49, loss: 0.965631
global_step: 9942, epoch: 49, loss: 0.960408
global_step: 9943, epoch: 49, loss: 0.955094
global_step: 9944, epoch: 49, loss: 1.031616
global_step: 9945, epoch: 49, loss: 1.033714
global_step: 9946, epoch: 49, loss: 0.956805
global_step: 9947, epoch: 49, loss: 0.956340
global_step: 9948, epoch: 49, loss: 1.039236
global_step: 9949, epoch: 49, loss: 0.990487
global_step: 9950, epoch: 49, loss: 0.937595
global_step: 9951, epoch: 49, loss: 0.926900
global_step: 9952, epoch: 49, loss: 0.986838
global_step: 9953, epoch: 49, loss: 1.008447
global_step: 9954, epoch: 49, loss: 1.083785
global_step: 9955, epoch: 49, loss: 0.987965
global_step: 9956, epoch: 49, loss: 0.948013
global_step: 9957, epoch: 49, loss: 1.099107
global_step: 9958, epoch: 49, loss: 1.010139
global_step: 9959, epoch: 49, loss: 1.115778
global_step: 9960, epoch: 49, loss: 1.263074
epoch: 49
train	acc: 0.7348	macro: p 0.4910, r 0.4745, f1: 0.4776	micro: p 0.7348, r 0.7348, f1 0.7348	weighted_f1:0.7076
dev	acc: 0.5482	macro: p 0.3432, r 0.3123, f1: 0.3055	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4996
test	acc: 0.5897	macro: p 0.3489, r 0.3215, f1: 0.3213	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5513
global_step: 9961, epoch: 50, loss: 0.984563
global_step: 9962, epoch: 50, loss: 0.902173
global_step: 9963, epoch: 50, loss: 1.015089
global_step: 9964, epoch: 50, loss: 0.965326
global_step: 9965, epoch: 50, loss: 0.902923
global_step: 9966, epoch: 50, loss: 0.980771
global_step: 9967, epoch: 50, loss: 0.951683
global_step: 9968, epoch: 50, loss: 0.988735
global_step: 9969, epoch: 50, loss: 0.949552
global_step: 9970, epoch: 50, loss: 1.009533
global_step: 9971, epoch: 50, loss: 0.992579
global_step: 9972, epoch: 50, loss: 1.069590
global_step: 9973, epoch: 50, loss: 0.985058
global_step: 9974, epoch: 50, loss: 0.954832
global_step: 9975, epoch: 50, loss: 0.999718
global_step: 9976, epoch: 50, loss: 1.008400
global_step: 9977, epoch: 50, loss: 0.971415
global_step: 9978, epoch: 50, loss: 0.967858
global_step: 9979, epoch: 50, loss: 1.157561
global_step: 9980, epoch: 50, loss: 0.901710
global_step: 9981, epoch: 50, loss: 0.866677
global_step: 9982, epoch: 50, loss: 1.085150
global_step: 9983, epoch: 50, loss: 0.976373
global_step: 9984, epoch: 50, loss: 1.034560
global_step: 9985, epoch: 50, loss: 0.924770
global_step: 9986, epoch: 50, loss: 1.115221
global_step: 9987, epoch: 50, loss: 0.883153
global_step: 9988, epoch: 50, loss: 1.071168
global_step: 9989, epoch: 50, loss: 0.992739
global_step: 9990, epoch: 50, loss: 0.979897
global_step: 9991, epoch: 50, loss: 1.008027
global_step: 9992, epoch: 50, loss: 1.014663
global_step: 9993, epoch: 50, loss: 0.948875
global_step: 9994, epoch: 50, loss: 1.033715
global_step: 9995, epoch: 50, loss: 1.071712
global_step: 9996, epoch: 50, loss: 1.064560
global_step: 9997, epoch: 50, loss: 0.984666
global_step: 9998, epoch: 50, loss: 0.900119
global_step: 9999, epoch: 50, loss: 1.107659
global_step: 10000, epoch: 50, loss: 1.313218
epoch: 50
train	acc: 0.7263	macro: p 0.4941, r 0.4561, f1: 0.4659	micro: p 0.7263, r 0.7263, f1 0.7263	weighted_f1:0.6955
dev	acc: 0.5455	macro: p 0.3393, r 0.3040, f1: 0.2976	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4920
test	acc: 0.5962	macro: p 0.3562, r 0.3168, f1: 0.3181	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5515
global_step: 10001, epoch: 51, loss: 1.044839
global_step: 10002, epoch: 51, loss: 0.885268
global_step: 10003, epoch: 51, loss: 0.948321
global_step: 10004, epoch: 51, loss: 0.923258
global_step: 10005, epoch: 51, loss: 1.090385
global_step: 10006, epoch: 51, loss: 0.929563
global_step: 10007, epoch: 51, loss: 1.054916
global_step: 10008, epoch: 51, loss: 0.988329
global_step: 10009, epoch: 51, loss: 1.058309
global_step: 10010, epoch: 51, loss: 1.111424
global_step: 10011, epoch: 51, loss: 0.886367
global_step: 10012, epoch: 51, loss: 1.003188
global_step: 10013, epoch: 51, loss: 0.968512
global_step: 10014, epoch: 51, loss: 0.988447
global_step: 10015, epoch: 51, loss: 0.987362
global_step: 10016, epoch: 51, loss: 1.039324
global_step: 10017, epoch: 51, loss: 0.953745
global_step: 10018, epoch: 51, loss: 1.001177
global_step: 10019, epoch: 51, loss: 0.878914
global_step: 10020, epoch: 51, loss: 0.965082
global_step: 10021, epoch: 51, loss: 1.047927
global_step: 10022, epoch: 51, loss: 1.156713
global_step: 10023, epoch: 51, loss: 1.068562
global_step: 10024, epoch: 51, loss: 0.997107
global_step: 10025, epoch: 51, loss: 0.977745
global_step: 10026, epoch: 51, loss: 0.963152
global_step: 10027, epoch: 51, loss: 0.927179
global_step: 10028, epoch: 51, loss: 0.886158
global_step: 10029, epoch: 51, loss: 1.096882
global_step: 10030, epoch: 51, loss: 0.926381
global_step: 10031, epoch: 51, loss: 0.996046
global_step: 10032, epoch: 51, loss: 0.933250
global_step: 10033, epoch: 51, loss: 0.891752
global_step: 10034, epoch: 51, loss: 0.874503
global_step: 10035, epoch: 51, loss: 0.967083
global_step: 10036, epoch: 51, loss: 0.881010
global_step: 10037, epoch: 51, loss: 0.994401
global_step: 10038, epoch: 51, loss: 1.087099
global_step: 10039, epoch: 51, loss: 1.014308
global_step: 10040, epoch: 51, loss: 0.661165
epoch: 51
train	acc: 0.7254	macro: p 0.4961, r 0.4531, f1: 0.4609	micro: p 0.7254, r 0.7254, f1 0.7254	weighted_f1:0.6932
dev	acc: 0.5482	macro: p 0.3459, r 0.3083, f1: 0.3028	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4962
test	acc: 0.5954	macro: p 0.3635, r 0.3165, f1: 0.3177	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5516
global_step: 10041, epoch: 52, loss: 1.029331
global_step: 10042, epoch: 52, loss: 1.016282
global_step: 10043, epoch: 52, loss: 0.918996
global_step: 10044, epoch: 52, loss: 1.062472
global_step: 10045, epoch: 52, loss: 0.955799
global_step: 10046, epoch: 52, loss: 0.949154
global_step: 10047, epoch: 52, loss: 1.054990
global_step: 10048, epoch: 52, loss: 0.932755
global_step: 10049, epoch: 52, loss: 1.001594
global_step: 10050, epoch: 52, loss: 1.079788
global_step: 10051, epoch: 52, loss: 0.979227
global_step: 10052, epoch: 52, loss: 0.955396
global_step: 10053, epoch: 52, loss: 1.027552
global_step: 10054, epoch: 52, loss: 1.008011
global_step: 10055, epoch: 52, loss: 1.094739
global_step: 10056, epoch: 52, loss: 0.946619
global_step: 10057, epoch: 52, loss: 0.962989
global_step: 10058, epoch: 52, loss: 0.918422
global_step: 10059, epoch: 52, loss: 1.006693
global_step: 10060, epoch: 52, loss: 0.890027
global_step: 10061, epoch: 52, loss: 0.981057
global_step: 10062, epoch: 52, loss: 0.909188
global_step: 10063, epoch: 52, loss: 0.945927
global_step: 10064, epoch: 52, loss: 1.053322
global_step: 10065, epoch: 52, loss: 0.996845
global_step: 10066, epoch: 52, loss: 1.123987
global_step: 10067, epoch: 52, loss: 0.897352
global_step: 10068, epoch: 52, loss: 0.933944
global_step: 10069, epoch: 52, loss: 1.063574
global_step: 10070, epoch: 52, loss: 0.952831
global_step: 10071, epoch: 52, loss: 0.872190
global_step: 10072, epoch: 52, loss: 0.998138
global_step: 10073, epoch: 52, loss: 0.975786
global_step: 10074, epoch: 52, loss: 1.008238
global_step: 10075, epoch: 52, loss: 0.908227
global_step: 10076, epoch: 52, loss: 0.968174
global_step: 10077, epoch: 52, loss: 0.976069
global_step: 10078, epoch: 52, loss: 0.960508
global_step: 10079, epoch: 52, loss: 0.896247
global_step: 10080, epoch: 52, loss: 0.930961
epoch: 52
train	acc: 0.7283	macro: p 0.4999, r 0.4537, f1: 0.4615	micro: p 0.7283, r 0.7283, f1 0.7283	weighted_f1:0.6950
dev	acc: 0.5509	macro: p 0.3470, r 0.3087, f1: 0.3030	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4980
test	acc: 0.5973	macro: p 0.3650, r 0.3177, f1: 0.3189	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5528
global_step: 10081, epoch: 53, loss: 0.985802
global_step: 10082, epoch: 53, loss: 0.957724
global_step: 10083, epoch: 53, loss: 0.936095
global_step: 10084, epoch: 53, loss: 0.992307
global_step: 10085, epoch: 53, loss: 0.962027
global_step: 10086, epoch: 53, loss: 0.895872
global_step: 10087, epoch: 53, loss: 0.919843
global_step: 10088, epoch: 53, loss: 0.973637
global_step: 10089, epoch: 53, loss: 1.036190
global_step: 10090, epoch: 53, loss: 0.971565
global_step: 10091, epoch: 53, loss: 1.025526
global_step: 10092, epoch: 53, loss: 0.950835
global_step: 10093, epoch: 53, loss: 1.086239
global_step: 10094, epoch: 53, loss: 1.004703
global_step: 10095, epoch: 53, loss: 0.928168
global_step: 10096, epoch: 53, loss: 1.055775
global_step: 10097, epoch: 53, loss: 0.933766
global_step: 10098, epoch: 53, loss: 0.896296
global_step: 10099, epoch: 53, loss: 1.019236
global_step: 10100, epoch: 53, loss: 0.989581
global_step: 10101, epoch: 53, loss: 0.968671
global_step: 10102, epoch: 53, loss: 0.949499
global_step: 10103, epoch: 53, loss: 0.955204
global_step: 10104, epoch: 53, loss: 0.902595
global_step: 10105, epoch: 53, loss: 1.001896
global_step: 10106, epoch: 53, loss: 1.032290
global_step: 10107, epoch: 53, loss: 0.919743
global_step: 10108, epoch: 53, loss: 0.932502
global_step: 10109, epoch: 53, loss: 1.016719
global_step: 10110, epoch: 53, loss: 0.948304
global_step: 10111, epoch: 53, loss: 0.934756
global_step: 10112, epoch: 53, loss: 1.080915
global_step: 10113, epoch: 53, loss: 0.934187
global_step: 10114, epoch: 53, loss: 0.940487
global_step: 10115, epoch: 53, loss: 0.997576
global_step: 10116, epoch: 53, loss: 0.882360
global_step: 10117, epoch: 53, loss: 0.923841
global_step: 10118, epoch: 53, loss: 1.085953
global_step: 10119, epoch: 53, loss: 1.050203
global_step: 10120, epoch: 53, loss: 1.787815
epoch: 53
train	acc: 0.7445	macro: p 0.5069, r 0.4772, f1: 0.4810	micro: p 0.7445, r 0.7445, f1 0.7445	weighted_f1:0.7141
dev	acc: 0.5473	macro: p 0.3422, r 0.3098, f1: 0.3023	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4963
test	acc: 0.5931	macro: p 0.3573, r 0.3219, f1: 0.3191	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5508
global_step: 10121, epoch: 54, loss: 1.034798
global_step: 10122, epoch: 54, loss: 0.973397
global_step: 10123, epoch: 54, loss: 1.020559
global_step: 10124, epoch: 54, loss: 0.857033
global_step: 10125, epoch: 54, loss: 0.936591
global_step: 10126, epoch: 54, loss: 1.019419
global_step: 10127, epoch: 54, loss: 0.897166
global_step: 10128, epoch: 54, loss: 0.879534
global_step: 10129, epoch: 54, loss: 1.014204
global_step: 10130, epoch: 54, loss: 0.947271
global_step: 10131, epoch: 54, loss: 0.956878
global_step: 10132, epoch: 54, loss: 0.896789
global_step: 10133, epoch: 54, loss: 0.892880
global_step: 10134, epoch: 54, loss: 0.920619
global_step: 10135, epoch: 54, loss: 1.001216
global_step: 10136, epoch: 54, loss: 0.981053
global_step: 10137, epoch: 54, loss: 0.931292
global_step: 10138, epoch: 54, loss: 0.964989
global_step: 10139, epoch: 54, loss: 0.900069
global_step: 10140, epoch: 54, loss: 0.974377
global_step: 10141, epoch: 54, loss: 0.991300
global_step: 10142, epoch: 54, loss: 0.898905
global_step: 10143, epoch: 54, loss: 1.084795
global_step: 10144, epoch: 54, loss: 0.974145
global_step: 10145, epoch: 54, loss: 0.992472
global_step: 10146, epoch: 54, loss: 1.008586
global_step: 10147, epoch: 54, loss: 0.988388
global_step: 10148, epoch: 54, loss: 0.965294
global_step: 10149, epoch: 54, loss: 0.929505
global_step: 10150, epoch: 54, loss: 0.991986
global_step: 10151, epoch: 54, loss: 0.968897
global_step: 10152, epoch: 54, loss: 1.067481
global_step: 10153, epoch: 54, loss: 0.902925
global_step: 10154, epoch: 54, loss: 0.942133
global_step: 10155, epoch: 54, loss: 0.870999
global_step: 10156, epoch: 54, loss: 0.989267
global_step: 10157, epoch: 54, loss: 0.968767
global_step: 10158, epoch: 54, loss: 0.915430
global_step: 10159, epoch: 54, loss: 0.847843
global_step: 10160, epoch: 54, loss: 1.101126
epoch: 54
train	acc: 0.7432	macro: p 0.5094, r 0.4738, f1: 0.4786	micro: p 0.7432, r 0.7432, f1 0.7432	weighted_f1:0.7126
dev	acc: 0.5482	macro: p 0.3474, r 0.3100, f1: 0.3041	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4976
test	acc: 0.5931	macro: p 0.3620, r 0.3201, f1: 0.3192	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5512
global_step: 10161, epoch: 55, loss: 0.947534
global_step: 10162, epoch: 55, loss: 0.956373
global_step: 10163, epoch: 55, loss: 0.867708
global_step: 10164, epoch: 55, loss: 0.849796
global_step: 10165, epoch: 55, loss: 0.885119
global_step: 10166, epoch: 55, loss: 1.121593
global_step: 10167, epoch: 55, loss: 0.766576
global_step: 10168, epoch: 55, loss: 1.006652
global_step: 10169, epoch: 55, loss: 0.883815
global_step: 10170, epoch: 55, loss: 0.935852
global_step: 10171, epoch: 55, loss: 0.971532
global_step: 10172, epoch: 55, loss: 0.980592
global_step: 10173, epoch: 55, loss: 0.967168
global_step: 10174, epoch: 55, loss: 0.957798
global_step: 10175, epoch: 55, loss: 0.934099
global_step: 10176, epoch: 55, loss: 1.036157
global_step: 10177, epoch: 55, loss: 0.887075
global_step: 10178, epoch: 55, loss: 0.979907
global_step: 10179, epoch: 55, loss: 0.953772
global_step: 10180, epoch: 55, loss: 0.958414
global_step: 10181, epoch: 55, loss: 1.007006
global_step: 10182, epoch: 55, loss: 0.962121
global_step: 10183, epoch: 55, loss: 0.946126
global_step: 10184, epoch: 55, loss: 0.980963
global_step: 10185, epoch: 55, loss: 0.945251
global_step: 10186, epoch: 55, loss: 0.947587
global_step: 10187, epoch: 55, loss: 0.950459
global_step: 10188, epoch: 55, loss: 0.935179
global_step: 10189, epoch: 55, loss: 0.870057
global_step: 10190, epoch: 55, loss: 0.904029
global_step: 10191, epoch: 55, loss: 0.947129
global_step: 10192, epoch: 55, loss: 0.938768
global_step: 10193, epoch: 55, loss: 0.941437
global_step: 10194, epoch: 55, loss: 0.887851
global_step: 10195, epoch: 55, loss: 0.962846
global_step: 10196, epoch: 55, loss: 1.063923
global_step: 10197, epoch: 55, loss: 0.990680
global_step: 10198, epoch: 55, loss: 0.955905
global_step: 10199, epoch: 55, loss: 1.009696
global_step: 10200, epoch: 55, loss: 1.593895
epoch: 55
train	acc: 0.7443	macro: p 0.5094, r 0.4757, f1: 0.4826	micro: p 0.7443, r 0.7443, f1 0.7443	weighted_f1:0.7139
dev	acc: 0.5546	macro: p 0.3550, r 0.3144, f1: 0.3105	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5041
test	acc: 0.5962	macro: p 0.3574, r 0.3184, f1: 0.3194	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5524
New best model!
global_step: 10201, epoch: 56, loss: 0.871457
global_step: 10202, epoch: 56, loss: 0.810567
global_step: 10203, epoch: 56, loss: 1.019180
global_step: 10204, epoch: 56, loss: 0.978876
global_step: 10205, epoch: 56, loss: 0.861049
global_step: 10206, epoch: 56, loss: 0.975249
global_step: 10207, epoch: 56, loss: 0.894080
global_step: 10208, epoch: 56, loss: 1.012473
global_step: 10209, epoch: 56, loss: 1.023769
global_step: 10210, epoch: 56, loss: 0.937220
global_step: 10211, epoch: 56, loss: 1.055820
global_step: 10212, epoch: 56, loss: 0.983144
global_step: 10213, epoch: 56, loss: 0.925183
global_step: 10214, epoch: 56, loss: 1.002252
global_step: 10215, epoch: 56, loss: 1.002768
global_step: 10216, epoch: 56, loss: 1.085909
global_step: 10217, epoch: 56, loss: 0.951919
global_step: 10218, epoch: 56, loss: 1.002991
global_step: 10219, epoch: 56, loss: 1.055516
global_step: 10220, epoch: 56, loss: 0.945474
global_step: 10221, epoch: 56, loss: 0.872372
global_step: 10222, epoch: 56, loss: 0.926792
global_step: 10223, epoch: 56, loss: 0.989416
global_step: 10224, epoch: 56, loss: 0.904271
global_step: 10225, epoch: 56, loss: 0.912214
global_step: 10226, epoch: 56, loss: 0.979051
global_step: 10227, epoch: 56, loss: 1.006170
global_step: 10228, epoch: 56, loss: 1.027482
global_step: 10229, epoch: 56, loss: 0.828534
global_step: 10230, epoch: 56, loss: 0.966266
global_step: 10231, epoch: 56, loss: 1.010248
global_step: 10232, epoch: 56, loss: 0.925275
global_step: 10233, epoch: 56, loss: 0.963540
global_step: 10234, epoch: 56, loss: 0.824759
global_step: 10235, epoch: 56, loss: 0.897839
global_step: 10236, epoch: 56, loss: 0.864793
global_step: 10237, epoch: 56, loss: 1.021124
global_step: 10238, epoch: 56, loss: 1.007161
global_step: 10239, epoch: 56, loss: 0.996664
global_step: 10240, epoch: 56, loss: 0.790179
epoch: 56
train	acc: 0.7373	macro: p 0.5146, r 0.4598, f1: 0.4696	micro: p 0.7373, r 0.7373, f1 0.7373	weighted_f1:0.7037
dev	acc: 0.5482	macro: p 0.3485, r 0.3047, f1: 0.2968	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4919
test	acc: 0.5962	macro: p 0.3645, r 0.3144, f1: 0.3156	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5495
global_step: 10241, epoch: 57, loss: 0.981112
global_step: 10242, epoch: 57, loss: 0.979967
global_step: 10243, epoch: 57, loss: 0.985499
global_step: 10244, epoch: 57, loss: 0.944129
global_step: 10245, epoch: 57, loss: 0.981257
global_step: 10246, epoch: 57, loss: 0.931452
global_step: 10247, epoch: 57, loss: 0.837118
global_step: 10248, epoch: 57, loss: 1.038809
global_step: 10249, epoch: 57, loss: 0.896129
global_step: 10250, epoch: 57, loss: 1.080240
global_step: 10251, epoch: 57, loss: 0.946234
global_step: 10252, epoch: 57, loss: 0.968928
global_step: 10253, epoch: 57, loss: 0.923825
global_step: 10254, epoch: 57, loss: 0.874270
global_step: 10255, epoch: 57, loss: 0.837173
global_step: 10256, epoch: 57, loss: 0.966722
global_step: 10257, epoch: 57, loss: 0.964589
global_step: 10258, epoch: 57, loss: 1.018270
global_step: 10259, epoch: 57, loss: 0.967439
global_step: 10260, epoch: 57, loss: 0.860092
global_step: 10261, epoch: 57, loss: 0.864776
global_step: 10262, epoch: 57, loss: 0.944658
global_step: 10263, epoch: 57, loss: 0.964705
global_step: 10264, epoch: 57, loss: 0.892145
global_step: 10265, epoch: 57, loss: 0.928200
global_step: 10266, epoch: 57, loss: 0.939195
global_step: 10267, epoch: 57, loss: 0.961651
global_step: 10268, epoch: 57, loss: 1.045986
global_step: 10269, epoch: 57, loss: 0.901596
global_step: 10270, epoch: 57, loss: 1.001082
global_step: 10271, epoch: 57, loss: 1.004920
global_step: 10272, epoch: 57, loss: 0.957895
global_step: 10273, epoch: 57, loss: 0.984853
global_step: 10274, epoch: 57, loss: 0.914907
global_step: 10275, epoch: 57, loss: 0.921830
global_step: 10276, epoch: 57, loss: 0.854547
global_step: 10277, epoch: 57, loss: 0.947305
global_step: 10278, epoch: 57, loss: 0.901739
global_step: 10279, epoch: 57, loss: 0.990850
global_step: 10280, epoch: 57, loss: 0.753273
epoch: 57
train	acc: 0.7539	macro: p 0.5177, r 0.4877, f1: 0.4944	micro: p 0.7539, r 0.7539, f1 0.7539	weighted_f1:0.7249
dev	acc: 0.5546	macro: p 0.3555, r 0.3148, f1: 0.3122	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5048
test	acc: 0.5950	macro: p 0.3538, r 0.3171, f1: 0.3187	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5518
New best model!
global_step: 10281, epoch: 58, loss: 0.893183
global_step: 10282, epoch: 58, loss: 0.933077
global_step: 10283, epoch: 58, loss: 0.953810
global_step: 10284, epoch: 58, loss: 0.923131
global_step: 10285, epoch: 58, loss: 0.935521
global_step: 10286, epoch: 58, loss: 0.979976
global_step: 10287, epoch: 58, loss: 0.943931
global_step: 10288, epoch: 58, loss: 0.834576
global_step: 10289, epoch: 58, loss: 0.994742
global_step: 10290, epoch: 58, loss: 0.876935
global_step: 10291, epoch: 58, loss: 1.028548
global_step: 10292, epoch: 58, loss: 0.930529
global_step: 10293, epoch: 58, loss: 0.915596
global_step: 10294, epoch: 58, loss: 0.951034
global_step: 10295, epoch: 58, loss: 0.941496
global_step: 10296, epoch: 58, loss: 0.995199
global_step: 10297, epoch: 58, loss: 0.852794
global_step: 10298, epoch: 58, loss: 0.861759
global_step: 10299, epoch: 58, loss: 0.877206
global_step: 10300, epoch: 58, loss: 0.869628
global_step: 10301, epoch: 58, loss: 0.906086
global_step: 10302, epoch: 58, loss: 0.880239
global_step: 10303, epoch: 58, loss: 0.979565
global_step: 10304, epoch: 58, loss: 0.979900
global_step: 10305, epoch: 58, loss: 0.894437
global_step: 10306, epoch: 58, loss: 0.901796
global_step: 10307, epoch: 58, loss: 0.938188
global_step: 10308, epoch: 58, loss: 0.889837
global_step: 10309, epoch: 58, loss: 0.893409
global_step: 10310, epoch: 58, loss: 0.856743
global_step: 10311, epoch: 58, loss: 1.060531
global_step: 10312, epoch: 58, loss: 0.916716
global_step: 10313, epoch: 58, loss: 0.959632
global_step: 10314, epoch: 58, loss: 0.990616
global_step: 10315, epoch: 58, loss: 0.946253
global_step: 10316, epoch: 58, loss: 0.920870
global_step: 10317, epoch: 58, loss: 0.939739
global_step: 10318, epoch: 58, loss: 0.958837
global_step: 10319, epoch: 58, loss: 0.997218
global_step: 10320, epoch: 58, loss: 1.294865
epoch: 58
train	acc: 0.7549	macro: p 0.5229, r 0.4857, f1: 0.4920	micro: p 0.7549, r 0.7549, f1 0.7549	weighted_f1:0.7237
dev	acc: 0.5518	macro: p 0.3510, r 0.3099, f1: 0.3049	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4984
test	acc: 0.5958	macro: p 0.3589, r 0.3189, f1: 0.3191	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5511
global_step: 10321, epoch: 59, loss: 1.003867
global_step: 10322, epoch: 59, loss: 0.911452
global_step: 10323, epoch: 59, loss: 1.053633
global_step: 10324, epoch: 59, loss: 0.927174
global_step: 10325, epoch: 59, loss: 0.973608
global_step: 10326, epoch: 59, loss: 0.950467
global_step: 10327, epoch: 59, loss: 0.898325
global_step: 10328, epoch: 59, loss: 0.960441
global_step: 10329, epoch: 59, loss: 0.909205
global_step: 10330, epoch: 59, loss: 0.945730
global_step: 10331, epoch: 59, loss: 0.937148
global_step: 10332, epoch: 59, loss: 0.848047
global_step: 10333, epoch: 59, loss: 0.877646
global_step: 10334, epoch: 59, loss: 0.988602
global_step: 10335, epoch: 59, loss: 0.811256
global_step: 10336, epoch: 59, loss: 0.947734
global_step: 10337, epoch: 59, loss: 0.862379
global_step: 10338, epoch: 59, loss: 0.915514
global_step: 10339, epoch: 59, loss: 0.862505
global_step: 10340, epoch: 59, loss: 0.942259
global_step: 10341, epoch: 59, loss: 0.837364
global_step: 10342, epoch: 59, loss: 0.897467
global_step: 10343, epoch: 59, loss: 0.961982
global_step: 10344, epoch: 59, loss: 0.948331
global_step: 10345, epoch: 59, loss: 0.927389
global_step: 10346, epoch: 59, loss: 0.967944
global_step: 10347, epoch: 59, loss: 0.940080
global_step: 10348, epoch: 59, loss: 0.932979
global_step: 10349, epoch: 59, loss: 0.861973
global_step: 10350, epoch: 59, loss: 0.854394
global_step: 10351, epoch: 59, loss: 0.812142
global_step: 10352, epoch: 59, loss: 0.919078
global_step: 10353, epoch: 59, loss: 0.873130
global_step: 10354, epoch: 59, loss: 0.931883
global_step: 10355, epoch: 59, loss: 0.894579
global_step: 10356, epoch: 59, loss: 0.892435
global_step: 10357, epoch: 59, loss: 0.933916
global_step: 10358, epoch: 59, loss: 0.925995
global_step: 10359, epoch: 59, loss: 0.894605
global_step: 10360, epoch: 59, loss: 1.047077
epoch: 59
train	acc: 0.7553	macro: p 0.5239, r 0.4847, f1: 0.4932	micro: p 0.7553, r 0.7553, f1 0.7553	weighted_f1:0.7254
dev	acc: 0.5509	macro: p 0.3514, r 0.3091, f1: 0.3028	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4975
test	acc: 0.5966	macro: p 0.3608, r 0.3148, f1: 0.3163	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5507
global_step: 10361, epoch: 60, loss: 0.856944
global_step: 10362, epoch: 60, loss: 0.932216
global_step: 10363, epoch: 60, loss: 0.930520
global_step: 10364, epoch: 60, loss: 0.967502
global_step: 10365, epoch: 60, loss: 0.941026
global_step: 10366, epoch: 60, loss: 0.861292
global_step: 10367, epoch: 60, loss: 0.835493
global_step: 10368, epoch: 60, loss: 0.924784
global_step: 10369, epoch: 60, loss: 0.978444
global_step: 10370, epoch: 60, loss: 0.934674
global_step: 10371, epoch: 60, loss: 0.886897
global_step: 10372, epoch: 60, loss: 0.852490
global_step: 10373, epoch: 60, loss: 0.850921
global_step: 10374, epoch: 60, loss: 0.878062
global_step: 10375, epoch: 60, loss: 0.840920
global_step: 10376, epoch: 60, loss: 0.926470
global_step: 10377, epoch: 60, loss: 0.969594
global_step: 10378, epoch: 60, loss: 0.948416
global_step: 10379, epoch: 60, loss: 0.873682
global_step: 10380, epoch: 60, loss: 0.890262
global_step: 10381, epoch: 60, loss: 0.945678
global_step: 10382, epoch: 60, loss: 0.917763
global_step: 10383, epoch: 60, loss: 0.956142
global_step: 10384, epoch: 60, loss: 0.834127
global_step: 10385, epoch: 60, loss: 0.932655
global_step: 10386, epoch: 60, loss: 1.009859
global_step: 10387, epoch: 60, loss: 0.934406
global_step: 10388, epoch: 60, loss: 0.929764
global_step: 10389, epoch: 60, loss: 0.807128
global_step: 10390, epoch: 60, loss: 0.943426
global_step: 10391, epoch: 60, loss: 0.936435
global_step: 10392, epoch: 60, loss: 0.951875
global_step: 10393, epoch: 60, loss: 0.954564
global_step: 10394, epoch: 60, loss: 0.893161
global_step: 10395, epoch: 60, loss: 0.943161
global_step: 10396, epoch: 60, loss: 0.941514
global_step: 10397, epoch: 60, loss: 0.841034
global_step: 10398, epoch: 60, loss: 0.965988
global_step: 10399, epoch: 60, loss: 0.960104
global_step: 10400, epoch: 60, loss: 1.159237
epoch: 60
train	acc: 0.7543	macro: p 0.5278, r 0.4800, f1: 0.4908	micro: p 0.7543, r 0.7543, f1 0.7543	weighted_f1:0.7229
dev	acc: 0.5482	macro: p 0.3458, r 0.3050, f1: 0.2974	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4918
test	acc: 0.5992	macro: p 0.3669, r 0.3167, f1: 0.3181	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5515
global_step: 10401, epoch: 61, loss: 0.884836
global_step: 10402, epoch: 61, loss: 0.876089
global_step: 10403, epoch: 61, loss: 0.845245
global_step: 10404, epoch: 61, loss: 0.805258
global_step: 10405, epoch: 61, loss: 0.873373
global_step: 10406, epoch: 61, loss: 0.846838
global_step: 10407, epoch: 61, loss: 0.856702
global_step: 10408, epoch: 61, loss: 0.895016
global_step: 10409, epoch: 61, loss: 0.937938
global_step: 10410, epoch: 61, loss: 0.929566
global_step: 10411, epoch: 61, loss: 0.969541
global_step: 10412, epoch: 61, loss: 0.978558
global_step: 10413, epoch: 61, loss: 0.931116
global_step: 10414, epoch: 61, loss: 0.796883
global_step: 10415, epoch: 61, loss: 0.920444
global_step: 10416, epoch: 61, loss: 0.865801
global_step: 10417, epoch: 61, loss: 0.968600
global_step: 10418, epoch: 61, loss: 0.942375
global_step: 10419, epoch: 61, loss: 0.869234
global_step: 10420, epoch: 61, loss: 0.855867
global_step: 10421, epoch: 61, loss: 0.918592
global_step: 10422, epoch: 61, loss: 0.927885
global_step: 10423, epoch: 61, loss: 0.956843
global_step: 10424, epoch: 61, loss: 0.919060
global_step: 10425, epoch: 61, loss: 0.890919
global_step: 10426, epoch: 61, loss: 0.852562
global_step: 10427, epoch: 61, loss: 0.954523
global_step: 10428, epoch: 61, loss: 1.020178
global_step: 10429, epoch: 61, loss: 0.853304
global_step: 10430, epoch: 61, loss: 0.747044
global_step: 10431, epoch: 61, loss: 0.904067
global_step: 10432, epoch: 61, loss: 0.823497
global_step: 10433, epoch: 61, loss: 1.007032
global_step: 10434, epoch: 61, loss: 0.861656
global_step: 10435, epoch: 61, loss: 0.861747
global_step: 10436, epoch: 61, loss: 0.944874
global_step: 10437, epoch: 61, loss: 0.940902
global_step: 10438, epoch: 61, loss: 0.963626
global_step: 10439, epoch: 61, loss: 1.009969
global_step: 10440, epoch: 61, loss: 0.743639
epoch: 61
train	acc: 0.7726	macro: p 0.5273, r 0.5115, f1: 0.5138	micro: p 0.7726, r 0.7726, f1 0.7726	weighted_f1:0.7455
dev	acc: 0.5482	macro: p 0.3473, r 0.3108, f1: 0.3060	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.5001
test	acc: 0.5966	macro: p 0.3562, r 0.3236, f1: 0.3224	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5545
global_step: 10441, epoch: 62, loss: 0.840695
global_step: 10442, epoch: 62, loss: 0.948072
global_step: 10443, epoch: 62, loss: 0.931340
global_step: 10444, epoch: 62, loss: 0.882200
global_step: 10445, epoch: 62, loss: 0.912512
global_step: 10446, epoch: 62, loss: 0.867262
global_step: 10447, epoch: 62, loss: 0.927027
global_step: 10448, epoch: 62, loss: 0.885820
global_step: 10449, epoch: 62, loss: 0.860924
global_step: 10450, epoch: 62, loss: 0.908217
global_step: 10451, epoch: 62, loss: 0.934936
global_step: 10452, epoch: 62, loss: 0.834969
global_step: 10453, epoch: 62, loss: 0.966141
global_step: 10454, epoch: 62, loss: 0.903701
global_step: 10455, epoch: 62, loss: 0.870290
global_step: 10456, epoch: 62, loss: 0.987909
global_step: 10457, epoch: 62, loss: 0.771463
global_step: 10458, epoch: 62, loss: 0.895822
global_step: 10459, epoch: 62, loss: 0.817810
global_step: 10460, epoch: 62, loss: 0.889735
global_step: 10461, epoch: 62, loss: 0.946462
global_step: 10462, epoch: 62, loss: 0.891146
global_step: 10463, epoch: 62, loss: 0.983470
global_step: 10464, epoch: 62, loss: 0.819812
global_step: 10465, epoch: 62, loss: 0.876995
global_step: 10466, epoch: 62, loss: 0.875362
global_step: 10467, epoch: 62, loss: 0.965279
global_step: 10468, epoch: 62, loss: 0.974038
global_step: 10469, epoch: 62, loss: 0.885340
global_step: 10470, epoch: 62, loss: 0.856481
global_step: 10471, epoch: 62, loss: 0.742248
global_step: 10472, epoch: 62, loss: 1.013328
global_step: 10473, epoch: 62, loss: 0.905751
global_step: 10474, epoch: 62, loss: 0.952079
global_step: 10475, epoch: 62, loss: 0.899082
global_step: 10476, epoch: 62, loss: 0.936745
global_step: 10477, epoch: 62, loss: 0.867264
global_step: 10478, epoch: 62, loss: 0.792531
global_step: 10479, epoch: 62, loss: 0.937244
global_step: 10480, epoch: 62, loss: 1.610851
epoch: 62
train	acc: 0.7767	macro: p 0.5270, r 0.5194, f1: 0.5204	micro: p 0.7767, r 0.7767, f1 0.7767	weighted_f1:0.7508
dev	acc: 0.5509	macro: p 0.3488, r 0.3149, f1: 0.3130	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5045
test	acc: 0.5969	macro: p 0.3549, r 0.3207, f1: 0.3238	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5558
global_step: 10481, epoch: 63, loss: 0.881575
global_step: 10482, epoch: 63, loss: 0.932038
global_step: 10483, epoch: 63, loss: 0.879551
global_step: 10484, epoch: 63, loss: 0.807153
global_step: 10485, epoch: 63, loss: 0.972813
global_step: 10486, epoch: 63, loss: 0.910536
global_step: 10487, epoch: 63, loss: 1.016525
global_step: 10488, epoch: 63, loss: 0.877040
global_step: 10489, epoch: 63, loss: 0.762127
global_step: 10490, epoch: 63, loss: 0.910098
global_step: 10491, epoch: 63, loss: 0.999879
global_step: 10492, epoch: 63, loss: 0.902109
global_step: 10493, epoch: 63, loss: 0.939979
global_step: 10494, epoch: 63, loss: 0.835040
global_step: 10495, epoch: 63, loss: 0.849189
global_step: 10496, epoch: 63, loss: 0.812263
global_step: 10497, epoch: 63, loss: 0.981453
global_step: 10498, epoch: 63, loss: 0.805918
global_step: 10499, epoch: 63, loss: 0.887690
global_step: 10500, epoch: 63, loss: 0.785786
global_step: 10501, epoch: 63, loss: 0.889588
global_step: 10502, epoch: 63, loss: 0.781998
global_step: 10503, epoch: 63, loss: 0.861783
global_step: 10504, epoch: 63, loss: 0.966770
global_step: 10505, epoch: 63, loss: 0.906268
global_step: 10506, epoch: 63, loss: 0.800954
global_step: 10507, epoch: 63, loss: 0.820974
global_step: 10508, epoch: 63, loss: 0.932103
global_step: 10509, epoch: 63, loss: 0.891325
global_step: 10510, epoch: 63, loss: 0.860942
global_step: 10511, epoch: 63, loss: 0.913213
global_step: 10512, epoch: 63, loss: 0.871649
global_step: 10513, epoch: 63, loss: 0.976607
global_step: 10514, epoch: 63, loss: 0.929481
global_step: 10515, epoch: 63, loss: 0.870974
global_step: 10516, epoch: 63, loss: 0.803342
global_step: 10517, epoch: 63, loss: 0.932517
global_step: 10518, epoch: 63, loss: 0.861464
global_step: 10519, epoch: 63, loss: 0.964450
global_step: 10520, epoch: 63, loss: 1.090991
epoch: 63
train	acc: 0.7740	macro: p 0.5335, r 0.5086, f1: 0.5131	micro: p 0.7740, r 0.7740, f1 0.7740	weighted_f1:0.7455
dev	acc: 0.5455	macro: p 0.3434, r 0.3058, f1: 0.2988	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4931
test	acc: 0.5954	macro: p 0.3597, r 0.3188, f1: 0.3184	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5510
global_step: 10521, epoch: 64, loss: 0.833116
global_step: 10522, epoch: 64, loss: 0.935123
global_step: 10523, epoch: 64, loss: 0.830013
global_step: 10524, epoch: 64, loss: 0.874633
global_step: 10525, epoch: 64, loss: 0.841169
global_step: 10526, epoch: 64, loss: 0.985112
global_step: 10527, epoch: 64, loss: 0.781096
global_step: 10528, epoch: 64, loss: 0.840318
global_step: 10529, epoch: 64, loss: 0.896507
global_step: 10530, epoch: 64, loss: 0.950544
global_step: 10531, epoch: 64, loss: 0.838188
global_step: 10532, epoch: 64, loss: 0.908349
global_step: 10533, epoch: 64, loss: 0.889677
global_step: 10534, epoch: 64, loss: 0.927867
global_step: 10535, epoch: 64, loss: 0.740058
global_step: 10536, epoch: 64, loss: 1.010678
global_step: 10537, epoch: 64, loss: 0.861063
global_step: 10538, epoch: 64, loss: 0.810580
global_step: 10539, epoch: 64, loss: 0.905998
global_step: 10540, epoch: 64, loss: 0.761755
global_step: 10541, epoch: 64, loss: 0.883551
global_step: 10542, epoch: 64, loss: 0.844872
global_step: 10543, epoch: 64, loss: 0.827340
global_step: 10544, epoch: 64, loss: 0.861650
global_step: 10545, epoch: 64, loss: 0.903069
global_step: 10546, epoch: 64, loss: 0.812707
global_step: 10547, epoch: 64, loss: 0.903524
global_step: 10548, epoch: 64, loss: 0.993703
global_step: 10549, epoch: 64, loss: 0.779599
global_step: 10550, epoch: 64, loss: 0.892436
global_step: 10551, epoch: 64, loss: 0.946753
global_step: 10552, epoch: 64, loss: 0.926273
global_step: 10553, epoch: 64, loss: 0.786640
global_step: 10554, epoch: 64, loss: 0.765259
global_step: 10555, epoch: 64, loss: 0.865384
global_step: 10556, epoch: 64, loss: 0.905970
global_step: 10557, epoch: 64, loss: 0.973409
global_step: 10558, epoch: 64, loss: 0.962007
global_step: 10559, epoch: 64, loss: 0.943424
global_step: 10560, epoch: 64, loss: 1.691946
epoch: 64
train	acc: 0.7869	macro: p 0.6815, r 0.5295, f1: 0.5299	micro: p 0.7869, r 0.7869, f1 0.7869	weighted_f1:0.7610
dev	acc: 0.5555	macro: p 0.3560, r 0.3195, f1: 0.3163	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5092
test	acc: 0.5954	macro: p 0.3608, r 0.3237, f1: 0.3243	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5557
New best model!
global_step: 10561, epoch: 65, loss: 0.835070
global_step: 10562, epoch: 65, loss: 0.828224
global_step: 10563, epoch: 65, loss: 0.824949
global_step: 10564, epoch: 65, loss: 0.890446
global_step: 10565, epoch: 65, loss: 0.732480
global_step: 10566, epoch: 65, loss: 0.783758
global_step: 10567, epoch: 65, loss: 0.856035
global_step: 10568, epoch: 65, loss: 0.836203
global_step: 10569, epoch: 65, loss: 0.877448
global_step: 10570, epoch: 65, loss: 0.898667
global_step: 10571, epoch: 65, loss: 0.831175
global_step: 10572, epoch: 65, loss: 0.941513
global_step: 10573, epoch: 65, loss: 0.912122
global_step: 10574, epoch: 65, loss: 0.976665
global_step: 10575, epoch: 65, loss: 0.866912
global_step: 10576, epoch: 65, loss: 0.875876
global_step: 10577, epoch: 65, loss: 0.918434
global_step: 10578, epoch: 65, loss: 0.867397
global_step: 10579, epoch: 65, loss: 0.866637
global_step: 10580, epoch: 65, loss: 0.907096
global_step: 10581, epoch: 65, loss: 0.873762
global_step: 10582, epoch: 65, loss: 0.816826
global_step: 10583, epoch: 65, loss: 0.900285
global_step: 10584, epoch: 65, loss: 0.964010
global_step: 10585, epoch: 65, loss: 0.919885
global_step: 10586, epoch: 65, loss: 0.803749
global_step: 10587, epoch: 65, loss: 0.856638
global_step: 10588, epoch: 65, loss: 0.888364
global_step: 10589, epoch: 65, loss: 0.829620
global_step: 10590, epoch: 65, loss: 0.879200
global_step: 10591, epoch: 65, loss: 0.925562
global_step: 10592, epoch: 65, loss: 0.972343
global_step: 10593, epoch: 65, loss: 0.910711
global_step: 10594, epoch: 65, loss: 0.841447
global_step: 10595, epoch: 65, loss: 0.868314
global_step: 10596, epoch: 65, loss: 0.890523
global_step: 10597, epoch: 65, loss: 0.939698
global_step: 10598, epoch: 65, loss: 0.852918
global_step: 10599, epoch: 65, loss: 0.895569
global_step: 10600, epoch: 65, loss: 0.197281
epoch: 65
train	acc: 0.7712	macro: p 0.6847, r 0.5005, f1: 0.5108	micro: p 0.7712, r 0.7712, f1 0.7712	weighted_f1:0.7412
dev	acc: 0.5473	macro: p 0.3495, r 0.3047, f1: 0.3001	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4933
test	acc: 0.6011	macro: p 0.3668, r 0.3158, f1: 0.3185	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5532
global_step: 10601, epoch: 66, loss: 0.921888
global_step: 10602, epoch: 66, loss: 0.893313
global_step: 10603, epoch: 66, loss: 0.838365
global_step: 10604, epoch: 66, loss: 0.826343
global_step: 10605, epoch: 66, loss: 0.876583
global_step: 10606, epoch: 66, loss: 0.851858
global_step: 10607, epoch: 66, loss: 0.867673
global_step: 10608, epoch: 66, loss: 0.786525
global_step: 10609, epoch: 66, loss: 0.892216
global_step: 10610, epoch: 66, loss: 0.899701
global_step: 10611, epoch: 66, loss: 0.830272
global_step: 10612, epoch: 66, loss: 0.888858
global_step: 10613, epoch: 66, loss: 0.833841
global_step: 10614, epoch: 66, loss: 0.741500
global_step: 10615, epoch: 66, loss: 0.817053
global_step: 10616, epoch: 66, loss: 0.896389
global_step: 10617, epoch: 66, loss: 0.806560
global_step: 10618, epoch: 66, loss: 1.015923
global_step: 10619, epoch: 66, loss: 0.861960
global_step: 10620, epoch: 66, loss: 0.881576
global_step: 10621, epoch: 66, loss: 0.927459
global_step: 10622, epoch: 66, loss: 0.800814
global_step: 10623, epoch: 66, loss: 1.016593
global_step: 10624, epoch: 66, loss: 0.883264
global_step: 10625, epoch: 66, loss: 0.940790
global_step: 10626, epoch: 66, loss: 0.786645
global_step: 10627, epoch: 66, loss: 0.920928
global_step: 10628, epoch: 66, loss: 0.720051
global_step: 10629, epoch: 66, loss: 0.874278
global_step: 10630, epoch: 66, loss: 0.778506
global_step: 10631, epoch: 66, loss: 0.955508
global_step: 10632, epoch: 66, loss: 0.891585
global_step: 10633, epoch: 66, loss: 0.778344
global_step: 10634, epoch: 66, loss: 0.932924
global_step: 10635, epoch: 66, loss: 0.994640
global_step: 10636, epoch: 66, loss: 0.964263
global_step: 10637, epoch: 66, loss: 0.873824
global_step: 10638, epoch: 66, loss: 0.761063
global_step: 10639, epoch: 66, loss: 0.956599
global_step: 10640, epoch: 66, loss: 0.422508
epoch: 66
train	acc: 0.7871	macro: p 0.6857, r 0.5249, f1: 0.5268	micro: p 0.7871, r 0.7871, f1 0.7871	weighted_f1:0.7596
dev	acc: 0.5500	macro: p 0.3504, r 0.3111, f1: 0.3078	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5014
test	acc: 0.5977	macro: p 0.3629, r 0.3204, f1: 0.3221	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5551
global_step: 10641, epoch: 67, loss: 0.813384
global_step: 10642, epoch: 67, loss: 0.821547
global_step: 10643, epoch: 67, loss: 0.936887
global_step: 10644, epoch: 67, loss: 0.874581
global_step: 10645, epoch: 67, loss: 0.828960
global_step: 10646, epoch: 67, loss: 0.881174
global_step: 10647, epoch: 67, loss: 0.764195
global_step: 10648, epoch: 67, loss: 0.776797
global_step: 10649, epoch: 67, loss: 0.882744
global_step: 10650, epoch: 67, loss: 0.891953
global_step: 10651, epoch: 67, loss: 0.821149
global_step: 10652, epoch: 67, loss: 0.806952
global_step: 10653, epoch: 67, loss: 0.817546
global_step: 10654, epoch: 67, loss: 0.801685
global_step: 10655, epoch: 67, loss: 0.838484
global_step: 10656, epoch: 67, loss: 0.829632
global_step: 10657, epoch: 67, loss: 0.903837
global_step: 10658, epoch: 67, loss: 0.915243
global_step: 10659, epoch: 67, loss: 0.779344
global_step: 10660, epoch: 67, loss: 0.791691
global_step: 10661, epoch: 67, loss: 0.867949
global_step: 10662, epoch: 67, loss: 0.828364
global_step: 10663, epoch: 67, loss: 0.847775
global_step: 10664, epoch: 67, loss: 0.830978
global_step: 10665, epoch: 67, loss: 0.839342
global_step: 10666, epoch: 67, loss: 0.911547
global_step: 10667, epoch: 67, loss: 1.039709
global_step: 10668, epoch: 67, loss: 0.884388
global_step: 10669, epoch: 67, loss: 0.877375
global_step: 10670, epoch: 67, loss: 0.850135
global_step: 10671, epoch: 67, loss: 0.958168
global_step: 10672, epoch: 67, loss: 0.921379
global_step: 10673, epoch: 67, loss: 0.787555
global_step: 10674, epoch: 67, loss: 0.918443
global_step: 10675, epoch: 67, loss: 0.881519
global_step: 10676, epoch: 67, loss: 0.816442
global_step: 10677, epoch: 67, loss: 0.912874
global_step: 10678, epoch: 67, loss: 0.844214
global_step: 10679, epoch: 67, loss: 0.799514
global_step: 10680, epoch: 67, loss: 2.004845
epoch: 67
train	acc: 0.8061	macro: p 0.8268, r 0.5595, f1: 0.5518	micro: p 0.8061, r 0.8061, f1 0.8061	weighted_f1:0.7823
dev	acc: 0.5446	macro: p 0.3302, r 0.3138, f1: 0.3072	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.5002
test	acc: 0.5916	macro: p 0.3491, r 0.3311, f1: 0.3290	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5555
global_step: 10681, epoch: 68, loss: 0.840180
global_step: 10682, epoch: 68, loss: 0.843527
global_step: 10683, epoch: 68, loss: 0.779161
global_step: 10684, epoch: 68, loss: 0.743606
global_step: 10685, epoch: 68, loss: 0.899215
global_step: 10686, epoch: 68, loss: 0.951050
global_step: 10687, epoch: 68, loss: 0.943176
global_step: 10688, epoch: 68, loss: 0.761980
global_step: 10689, epoch: 68, loss: 0.841806
global_step: 10690, epoch: 68, loss: 0.828790
global_step: 10691, epoch: 68, loss: 0.777833
global_step: 10692, epoch: 68, loss: 0.870182
global_step: 10693, epoch: 68, loss: 0.945597
global_step: 10694, epoch: 68, loss: 0.826561
global_step: 10695, epoch: 68, loss: 0.830824
global_step: 10696, epoch: 68, loss: 0.768958
global_step: 10697, epoch: 68, loss: 0.820947
global_step: 10698, epoch: 68, loss: 0.822038
global_step: 10699, epoch: 68, loss: 0.879861
global_step: 10700, epoch: 68, loss: 0.874573
global_step: 10701, epoch: 68, loss: 0.849803
global_step: 10702, epoch: 68, loss: 0.821958
global_step: 10703, epoch: 68, loss: 0.844916
global_step: 10704, epoch: 68, loss: 0.742322
global_step: 10705, epoch: 68, loss: 0.954586
global_step: 10706, epoch: 68, loss: 0.880806
global_step: 10707, epoch: 68, loss: 0.929393
global_step: 10708, epoch: 68, loss: 0.822076
global_step: 10709, epoch: 68, loss: 0.898404
global_step: 10710, epoch: 68, loss: 1.001417
global_step: 10711, epoch: 68, loss: 0.811345
global_step: 10712, epoch: 68, loss: 0.946349
global_step: 10713, epoch: 68, loss: 0.844954
global_step: 10714, epoch: 68, loss: 0.967014
global_step: 10715, epoch: 68, loss: 0.824247
global_step: 10716, epoch: 68, loss: 0.805662
global_step: 10717, epoch: 68, loss: 0.804382
global_step: 10718, epoch: 68, loss: 0.959406
global_step: 10719, epoch: 68, loss: 0.811242
global_step: 10720, epoch: 68, loss: 1.226053
epoch: 68
train	acc: 0.8007	macro: p 0.8299, r 0.5494, f1: 0.5493	micro: p 0.8007, r 0.8007, f1 0.8007	weighted_f1:0.7763
dev	acc: 0.5546	macro: p 0.3444, r 0.3174, f1: 0.3144	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.5085
test	acc: 0.5966	macro: p 0.3506, r 0.3223, f1: 0.3247	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5555
global_step: 10721, epoch: 69, loss: 0.880919
global_step: 10722, epoch: 69, loss: 0.881937
global_step: 10723, epoch: 69, loss: 0.765110
global_step: 10724, epoch: 69, loss: 0.802766
global_step: 10725, epoch: 69, loss: 0.829156
global_step: 10726, epoch: 69, loss: 0.857086
global_step: 10727, epoch: 69, loss: 0.789416
global_step: 10728, epoch: 69, loss: 0.854123
global_step: 10729, epoch: 69, loss: 0.876135
global_step: 10730, epoch: 69, loss: 0.737220
global_step: 10731, epoch: 69, loss: 0.907262
global_step: 10732, epoch: 69, loss: 0.855669
global_step: 10733, epoch: 69, loss: 0.776962
global_step: 10734, epoch: 69, loss: 0.758753
global_step: 10735, epoch: 69, loss: 0.840574
global_step: 10736, epoch: 69, loss: 0.886495
global_step: 10737, epoch: 69, loss: 0.898425
global_step: 10738, epoch: 69, loss: 0.835101
global_step: 10739, epoch: 69, loss: 0.853890
global_step: 10740, epoch: 69, loss: 0.958028
global_step: 10741, epoch: 69, loss: 0.917094
global_step: 10742, epoch: 69, loss: 0.892766
global_step: 10743, epoch: 69, loss: 0.795189
global_step: 10744, epoch: 69, loss: 0.948013
global_step: 10745, epoch: 69, loss: 0.810772
global_step: 10746, epoch: 69, loss: 0.805564
global_step: 10747, epoch: 69, loss: 0.823658
global_step: 10748, epoch: 69, loss: 0.764742
global_step: 10749, epoch: 69, loss: 0.838819
global_step: 10750, epoch: 69, loss: 0.842578
global_step: 10751, epoch: 69, loss: 0.899789
global_step: 10752, epoch: 69, loss: 0.773833
global_step: 10753, epoch: 69, loss: 0.882693
global_step: 10754, epoch: 69, loss: 0.766641
global_step: 10755, epoch: 69, loss: 0.811410
global_step: 10756, epoch: 69, loss: 0.834142
global_step: 10757, epoch: 69, loss: 0.828534
global_step: 10758, epoch: 69, loss: 0.844597
global_step: 10759, epoch: 69, loss: 0.832207
global_step: 10760, epoch: 69, loss: 0.973419
epoch: 69
train	acc: 0.7975	macro: p 0.6934, r 0.5381, f1: 0.5422	micro: p 0.7975, r 0.7975, f1 0.7975	weighted_f1:0.7710
dev	acc: 0.5555	macro: p 0.3499, r 0.3144, f1: 0.3104	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5054
test	acc: 0.6000	macro: p 0.3613, r 0.3202, f1: 0.3222	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5553
global_step: 10761, epoch: 70, loss: 0.742461
global_step: 10762, epoch: 70, loss: 0.846262
global_step: 10763, epoch: 70, loss: 0.767443
global_step: 10764, epoch: 70, loss: 0.755241
global_step: 10765, epoch: 70, loss: 0.750969
global_step: 10766, epoch: 70, loss: 0.852865
global_step: 10767, epoch: 70, loss: 0.796107
global_step: 10768, epoch: 70, loss: 0.838770
global_step: 10769, epoch: 70, loss: 0.816793
global_step: 10770, epoch: 70, loss: 0.909843
global_step: 10771, epoch: 70, loss: 0.796102
global_step: 10772, epoch: 70, loss: 0.794120
global_step: 10773, epoch: 70, loss: 0.791558
global_step: 10774, epoch: 70, loss: 0.964997
global_step: 10775, epoch: 70, loss: 0.800256
global_step: 10776, epoch: 70, loss: 0.830992
global_step: 10777, epoch: 70, loss: 0.779176
global_step: 10778, epoch: 70, loss: 0.858524
global_step: 10779, epoch: 70, loss: 0.846920
global_step: 10780, epoch: 70, loss: 0.800907
global_step: 10781, epoch: 70, loss: 0.780541
global_step: 10782, epoch: 70, loss: 0.763173
global_step: 10783, epoch: 70, loss: 0.909228
global_step: 10784, epoch: 70, loss: 0.925202
global_step: 10785, epoch: 70, loss: 0.832561
global_step: 10786, epoch: 70, loss: 0.800637
global_step: 10787, epoch: 70, loss: 0.824102
global_step: 10788, epoch: 70, loss: 0.833672
global_step: 10789, epoch: 70, loss: 0.887772
global_step: 10790, epoch: 70, loss: 0.776589
global_step: 10791, epoch: 70, loss: 0.972929
global_step: 10792, epoch: 70, loss: 0.871645
global_step: 10793, epoch: 70, loss: 0.883918
global_step: 10794, epoch: 70, loss: 0.805995
global_step: 10795, epoch: 70, loss: 0.815755
global_step: 10796, epoch: 70, loss: 0.812781
global_step: 10797, epoch: 70, loss: 0.783198
global_step: 10798, epoch: 70, loss: 0.937256
global_step: 10799, epoch: 70, loss: 0.811237
global_step: 10800, epoch: 70, loss: 0.324452
epoch: 70
train	acc: 0.8095	macro: p 0.8409, r 0.5567, f1: 0.5559	micro: p 0.8095, r 0.8095, f1 0.8095	weighted_f1:0.7846
dev	acc: 0.5518	macro: p 0.3503, r 0.3155, f1: 0.3112	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5049
test	acc: 0.5935	macro: p 0.3505, r 0.3235, f1: 0.3236	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5542
global_step: 10801, epoch: 71, loss: 0.833221
global_step: 10802, epoch: 71, loss: 0.794791
global_step: 10803, epoch: 71, loss: 0.710611
global_step: 10804, epoch: 71, loss: 0.819881
global_step: 10805, epoch: 71, loss: 0.869949
global_step: 10806, epoch: 71, loss: 0.860472
global_step: 10807, epoch: 71, loss: 0.830006
global_step: 10808, epoch: 71, loss: 0.766603
global_step: 10809, epoch: 71, loss: 0.898746
global_step: 10810, epoch: 71, loss: 0.786282
global_step: 10811, epoch: 71, loss: 0.869532
global_step: 10812, epoch: 71, loss: 0.766396
global_step: 10813, epoch: 71, loss: 0.866335
global_step: 10814, epoch: 71, loss: 0.868903
global_step: 10815, epoch: 71, loss: 0.873334
global_step: 10816, epoch: 71, loss: 0.847278
global_step: 10817, epoch: 71, loss: 0.781869
global_step: 10818, epoch: 71, loss: 0.802428
global_step: 10819, epoch: 71, loss: 0.867141
global_step: 10820, epoch: 71, loss: 0.850157
global_step: 10821, epoch: 71, loss: 0.902420
global_step: 10822, epoch: 71, loss: 0.841138
global_step: 10823, epoch: 71, loss: 0.897422
global_step: 10824, epoch: 71, loss: 0.792446
global_step: 10825, epoch: 71, loss: 0.811788
global_step: 10826, epoch: 71, loss: 0.901058
global_step: 10827, epoch: 71, loss: 0.825129
global_step: 10828, epoch: 71, loss: 0.931350
global_step: 10829, epoch: 71, loss: 0.819247
global_step: 10830, epoch: 71, loss: 0.806828
global_step: 10831, epoch: 71, loss: 0.825268
global_step: 10832, epoch: 71, loss: 0.725793
global_step: 10833, epoch: 71, loss: 0.811239
global_step: 10834, epoch: 71, loss: 0.817875
global_step: 10835, epoch: 71, loss: 0.786830
global_step: 10836, epoch: 71, loss: 0.811949
global_step: 10837, epoch: 71, loss: 0.796162
global_step: 10838, epoch: 71, loss: 0.795344
global_step: 10839, epoch: 71, loss: 0.883828
global_step: 10840, epoch: 71, loss: 0.646009
epoch: 71
train	acc: 0.8075	macro: p 0.8425, r 0.5525, f1: 0.5556	micro: p 0.8075, r 0.8075, f1 0.8075	weighted_f1:0.7821
dev	acc: 0.5528	macro: p 0.3510, r 0.3141, f1: 0.3090	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.5031
test	acc: 0.5985	macro: p 0.3612, r 0.3226, f1: 0.3238	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5553
global_step: 10841, epoch: 72, loss: 0.771028
global_step: 10842, epoch: 72, loss: 0.766448
global_step: 10843, epoch: 72, loss: 0.775194
global_step: 10844, epoch: 72, loss: 0.862132
global_step: 10845, epoch: 72, loss: 0.829717
global_step: 10846, epoch: 72, loss: 0.785353
global_step: 10847, epoch: 72, loss: 0.834413
global_step: 10848, epoch: 72, loss: 0.832633
global_step: 10849, epoch: 72, loss: 0.705908
global_step: 10850, epoch: 72, loss: 0.726026
global_step: 10851, epoch: 72, loss: 0.884379
global_step: 10852, epoch: 72, loss: 0.906770
global_step: 10853, epoch: 72, loss: 0.913025
global_step: 10854, epoch: 72, loss: 0.810735
global_step: 10855, epoch: 72, loss: 0.732919
global_step: 10856, epoch: 72, loss: 0.819329
global_step: 10857, epoch: 72, loss: 0.788453
global_step: 10858, epoch: 72, loss: 0.881429
global_step: 10859, epoch: 72, loss: 0.754779
global_step: 10860, epoch: 72, loss: 0.864553
global_step: 10861, epoch: 72, loss: 0.727079
global_step: 10862, epoch: 72, loss: 0.796619
global_step: 10863, epoch: 72, loss: 0.791322
global_step: 10864, epoch: 72, loss: 0.859467
global_step: 10865, epoch: 72, loss: 0.786142
global_step: 10866, epoch: 72, loss: 0.913384
global_step: 10867, epoch: 72, loss: 0.769888
global_step: 10868, epoch: 72, loss: 0.814503
global_step: 10869, epoch: 72, loss: 0.861000
global_step: 10870, epoch: 72, loss: 0.808762
global_step: 10871, epoch: 72, loss: 0.773324
global_step: 10872, epoch: 72, loss: 0.849933
global_step: 10873, epoch: 72, loss: 0.908859
global_step: 10874, epoch: 72, loss: 0.834628
global_step: 10875, epoch: 72, loss: 0.785280
global_step: 10876, epoch: 72, loss: 0.802576
global_step: 10877, epoch: 72, loss: 0.815728
global_step: 10878, epoch: 72, loss: 0.781384
global_step: 10879, epoch: 72, loss: 0.816919
global_step: 10880, epoch: 72, loss: 0.631516
epoch: 72
train	acc: 0.8024	macro: p 0.8434, r 0.5443, f1: 0.5502	micro: p 0.8024, r 0.8024, f1 0.8024	weighted_f1:0.7764
dev	acc: 0.5555	macro: p 0.3574, r 0.3137, f1: 0.3107	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5045
test	acc: 0.5950	macro: p 0.3567, r 0.3140, f1: 0.3174	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5502
global_step: 10881, epoch: 73, loss: 0.800842
global_step: 10882, epoch: 73, loss: 0.835031
global_step: 10883, epoch: 73, loss: 0.794494
global_step: 10884, epoch: 73, loss: 0.787030
global_step: 10885, epoch: 73, loss: 0.813005
global_step: 10886, epoch: 73, loss: 0.736739
global_step: 10887, epoch: 73, loss: 0.786715
global_step: 10888, epoch: 73, loss: 0.877090
global_step: 10889, epoch: 73, loss: 0.902400
global_step: 10890, epoch: 73, loss: 0.766504
global_step: 10891, epoch: 73, loss: 0.773063
global_step: 10892, epoch: 73, loss: 0.875133
global_step: 10893, epoch: 73, loss: 0.800450
global_step: 10894, epoch: 73, loss: 0.826653
global_step: 10895, epoch: 73, loss: 0.700689
global_step: 10896, epoch: 73, loss: 0.849373
global_step: 10897, epoch: 73, loss: 0.878061
global_step: 10898, epoch: 73, loss: 0.933715
global_step: 10899, epoch: 73, loss: 0.839321
global_step: 10900, epoch: 73, loss: 0.863176
global_step: 10901, epoch: 73, loss: 0.681135
global_step: 10902, epoch: 73, loss: 0.801314
global_step: 10903, epoch: 73, loss: 0.818192
global_step: 10904, epoch: 73, loss: 0.802824
global_step: 10905, epoch: 73, loss: 0.921130
global_step: 10906, epoch: 73, loss: 0.817111
global_step: 10907, epoch: 73, loss: 0.794316
global_step: 10908, epoch: 73, loss: 0.833116
global_step: 10909, epoch: 73, loss: 0.782336
global_step: 10910, epoch: 73, loss: 0.823010
global_step: 10911, epoch: 73, loss: 0.737125
global_step: 10912, epoch: 73, loss: 0.805912
global_step: 10913, epoch: 73, loss: 0.825822
global_step: 10914, epoch: 73, loss: 0.790878
global_step: 10915, epoch: 73, loss: 0.786588
global_step: 10916, epoch: 73, loss: 0.840460
global_step: 10917, epoch: 73, loss: 0.816270
global_step: 10918, epoch: 73, loss: 0.764935
global_step: 10919, epoch: 73, loss: 0.842784
global_step: 10920, epoch: 73, loss: 0.674815
epoch: 73
train	acc: 0.8158	macro: p 0.8486, r 0.5634, f1: 0.5661	micro: p 0.8158, r 0.8158, f1 0.8158	weighted_f1:0.7910
dev	acc: 0.5482	macro: p 0.3415, r 0.3093, f1: 0.3040	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4985
test	acc: 0.5985	macro: p 0.3607, r 0.3228, f1: 0.3245	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5555
global_step: 10921, epoch: 74, loss: 0.798531
global_step: 10922, epoch: 74, loss: 0.840310
global_step: 10923, epoch: 74, loss: 0.839186
global_step: 10924, epoch: 74, loss: 0.835620
global_step: 10925, epoch: 74, loss: 0.782248
global_step: 10926, epoch: 74, loss: 0.800456
global_step: 10927, epoch: 74, loss: 0.760467
global_step: 10928, epoch: 74, loss: 0.764628
global_step: 10929, epoch: 74, loss: 0.843935
global_step: 10930, epoch: 74, loss: 0.904876
global_step: 10931, epoch: 74, loss: 0.772278
global_step: 10932, epoch: 74, loss: 0.739316
global_step: 10933, epoch: 74, loss: 0.823318
global_step: 10934, epoch: 74, loss: 0.834430
global_step: 10935, epoch: 74, loss: 0.792789
global_step: 10936, epoch: 74, loss: 0.819797
global_step: 10937, epoch: 74, loss: 0.788151
global_step: 10938, epoch: 74, loss: 0.805982
global_step: 10939, epoch: 74, loss: 0.749972
global_step: 10940, epoch: 74, loss: 0.746659
global_step: 10941, epoch: 74, loss: 0.660958
global_step: 10942, epoch: 74, loss: 0.846809
global_step: 10943, epoch: 74, loss: 0.796338
global_step: 10944, epoch: 74, loss: 0.779795
global_step: 10945, epoch: 74, loss: 0.778312
global_step: 10946, epoch: 74, loss: 0.856535
global_step: 10947, epoch: 74, loss: 0.796750
global_step: 10948, epoch: 74, loss: 0.776737
global_step: 10949, epoch: 74, loss: 0.832120
global_step: 10950, epoch: 74, loss: 0.917123
global_step: 10951, epoch: 74, loss: 0.843321
global_step: 10952, epoch: 74, loss: 0.852156
global_step: 10953, epoch: 74, loss: 0.796049
global_step: 10954, epoch: 74, loss: 0.800009
global_step: 10955, epoch: 74, loss: 0.788927
global_step: 10956, epoch: 74, loss: 0.790702
global_step: 10957, epoch: 74, loss: 0.927933
global_step: 10958, epoch: 74, loss: 0.768797
global_step: 10959, epoch: 74, loss: 0.800117
global_step: 10960, epoch: 74, loss: 0.453085
epoch: 74
train	acc: 0.8163	macro: p 0.8505, r 0.5622, f1: 0.5649	micro: p 0.8163, r 0.8163, f1 0.8163	weighted_f1:0.7914
dev	acc: 0.5518	macro: p 0.3492, r 0.3118, f1: 0.3071	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.5023
test	acc: 0.5985	macro: p 0.3636, r 0.3203, f1: 0.3232	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5558
global_step: 10961, epoch: 75, loss: 0.645276
global_step: 10962, epoch: 75, loss: 0.765697
global_step: 10963, epoch: 75, loss: 0.746982
global_step: 10964, epoch: 75, loss: 0.777334
global_step: 10965, epoch: 75, loss: 0.684328
global_step: 10966, epoch: 75, loss: 0.740977
global_step: 10967, epoch: 75, loss: 0.880761
global_step: 10968, epoch: 75, loss: 0.669016
global_step: 10969, epoch: 75, loss: 0.912114
global_step: 10970, epoch: 75, loss: 0.766999
global_step: 10971, epoch: 75, loss: 0.869766
global_step: 10972, epoch: 75, loss: 0.802936
global_step: 10973, epoch: 75, loss: 0.858809
global_step: 10974, epoch: 75, loss: 0.789494
global_step: 10975, epoch: 75, loss: 0.793490
global_step: 10976, epoch: 75, loss: 0.761189
global_step: 10977, epoch: 75, loss: 0.827415
global_step: 10978, epoch: 75, loss: 0.783398
global_step: 10979, epoch: 75, loss: 0.800570
global_step: 10980, epoch: 75, loss: 0.757337
global_step: 10981, epoch: 75, loss: 0.782820
global_step: 10982, epoch: 75, loss: 0.819357
global_step: 10983, epoch: 75, loss: 0.884872
global_step: 10984, epoch: 75, loss: 0.833166
global_step: 10985, epoch: 75, loss: 0.879938
global_step: 10986, epoch: 75, loss: 0.712334
global_step: 10987, epoch: 75, loss: 0.915990
global_step: 10988, epoch: 75, loss: 0.747297
global_step: 10989, epoch: 75, loss: 0.871927
global_step: 10990, epoch: 75, loss: 0.806972
global_step: 10991, epoch: 75, loss: 0.881520
global_step: 10992, epoch: 75, loss: 0.822125
global_step: 10993, epoch: 75, loss: 0.785338
global_step: 10994, epoch: 75, loss: 0.729513
global_step: 10995, epoch: 75, loss: 0.724980
global_step: 10996, epoch: 75, loss: 0.816220
global_step: 10997, epoch: 75, loss: 0.732363
global_step: 10998, epoch: 75, loss: 0.923108
global_step: 10999, epoch: 75, loss: 0.769350
global_step: 11000, epoch: 75, loss: 0.962743
epoch: 75
train	acc: 0.8260	macro: p 0.8510, r 0.5797, f1: 0.5766	micro: p 0.8260, r 0.8260, f1 0.8260	weighted_f1:0.8028
dev	acc: 0.5446	macro: p 0.3372, r 0.3108, f1: 0.3027	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4978
test	acc: 0.5927	macro: p 0.3551, r 0.3287, f1: 0.3263	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5549
global_step: 11001, epoch: 76, loss: 0.800829
global_step: 11002, epoch: 76, loss: 0.663228
global_step: 11003, epoch: 76, loss: 0.888191
global_step: 11004, epoch: 76, loss: 0.633653
global_step: 11005, epoch: 76, loss: 0.808201
global_step: 11006, epoch: 76, loss: 0.768800
global_step: 11007, epoch: 76, loss: 0.805816
global_step: 11008, epoch: 76, loss: 0.791460
global_step: 11009, epoch: 76, loss: 0.786898
global_step: 11010, epoch: 76, loss: 0.826035
global_step: 11011, epoch: 76, loss: 0.748724
global_step: 11012, epoch: 76, loss: 0.837604
global_step: 11013, epoch: 76, loss: 0.832088
global_step: 11014, epoch: 76, loss: 0.824046
global_step: 11015, epoch: 76, loss: 0.749499
global_step: 11016, epoch: 76, loss: 0.808574
global_step: 11017, epoch: 76, loss: 0.766329
global_step: 11018, epoch: 76, loss: 0.802607
global_step: 11019, epoch: 76, loss: 0.757634
global_step: 11020, epoch: 76, loss: 0.793601
global_step: 11021, epoch: 76, loss: 0.765537
global_step: 11022, epoch: 76, loss: 0.746056
global_step: 11023, epoch: 76, loss: 0.881450
global_step: 11024, epoch: 76, loss: 0.777250
global_step: 11025, epoch: 76, loss: 0.832982
global_step: 11026, epoch: 76, loss: 0.787080
global_step: 11027, epoch: 76, loss: 0.770051
global_step: 11028, epoch: 76, loss: 0.820223
global_step: 11029, epoch: 76, loss: 0.813379
global_step: 11030, epoch: 76, loss: 0.832312
global_step: 11031, epoch: 76, loss: 0.782668
global_step: 11032, epoch: 76, loss: 0.770196
global_step: 11033, epoch: 76, loss: 0.789431
global_step: 11034, epoch: 76, loss: 0.814906
global_step: 11035, epoch: 76, loss: 0.750980
global_step: 11036, epoch: 76, loss: 0.936564
global_step: 11037, epoch: 76, loss: 0.825465
global_step: 11038, epoch: 76, loss: 0.812209
global_step: 11039, epoch: 76, loss: 0.857913
global_step: 11040, epoch: 76, loss: 0.925143
epoch: 76
train	acc: 0.8292	macro: p 0.8558, r 0.5814, f1: 0.5800	micro: p 0.8292, r 0.8292, f1 0.8292	weighted_f1:0.8057
dev	acc: 0.5455	macro: p 0.3413, r 0.3078, f1: 0.3036	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4988
test	acc: 0.5981	macro: p 0.3595, r 0.3243, f1: 0.3267	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5582
global_step: 11041, epoch: 77, loss: 0.736994
global_step: 11042, epoch: 77, loss: 0.843966
global_step: 11043, epoch: 77, loss: 0.744773
global_step: 11044, epoch: 77, loss: 0.737228
global_step: 11045, epoch: 77, loss: 0.854881
global_step: 11046, epoch: 77, loss: 0.726403
global_step: 11047, epoch: 77, loss: 0.759532
global_step: 11048, epoch: 77, loss: 0.792202
global_step: 11049, epoch: 77, loss: 0.800041
global_step: 11050, epoch: 77, loss: 0.840816
global_step: 11051, epoch: 77, loss: 0.765152
global_step: 11052, epoch: 77, loss: 0.795855
global_step: 11053, epoch: 77, loss: 0.764117
global_step: 11054, epoch: 77, loss: 0.678750
global_step: 11055, epoch: 77, loss: 0.756262
global_step: 11056, epoch: 77, loss: 0.741799
global_step: 11057, epoch: 77, loss: 0.724883
global_step: 11058, epoch: 77, loss: 0.862795
global_step: 11059, epoch: 77, loss: 0.814320
global_step: 11060, epoch: 77, loss: 0.778376
global_step: 11061, epoch: 77, loss: 0.717275
global_step: 11062, epoch: 77, loss: 0.705407
global_step: 11063, epoch: 77, loss: 0.726143
global_step: 11064, epoch: 77, loss: 0.796939
global_step: 11065, epoch: 77, loss: 0.827534
global_step: 11066, epoch: 77, loss: 0.721653
global_step: 11067, epoch: 77, loss: 0.827365
global_step: 11068, epoch: 77, loss: 0.830983
global_step: 11069, epoch: 77, loss: 0.753275
global_step: 11070, epoch: 77, loss: 0.800330
global_step: 11071, epoch: 77, loss: 0.801133
global_step: 11072, epoch: 77, loss: 0.723182
global_step: 11073, epoch: 77, loss: 0.815725
global_step: 11074, epoch: 77, loss: 0.895459
global_step: 11075, epoch: 77, loss: 0.741841
global_step: 11076, epoch: 77, loss: 0.779623
global_step: 11077, epoch: 77, loss: 0.765396
global_step: 11078, epoch: 77, loss: 0.837621
global_step: 11079, epoch: 77, loss: 0.779331
global_step: 11080, epoch: 77, loss: 1.233849
epoch: 77
train	acc: 0.8267	macro: p 0.8588, r 0.5789, f1: 0.5850	micro: p 0.8267, r 0.8267, f1 0.8267	weighted_f1:0.8032
dev	acc: 0.5482	macro: p 0.3439, r 0.3069, f1: 0.3030	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4970
test	acc: 0.6004	macro: p 0.3630, r 0.3215, f1: 0.3252	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5567
global_step: 11081, epoch: 78, loss: 0.728817
global_step: 11082, epoch: 78, loss: 0.851690
global_step: 11083, epoch: 78, loss: 0.731907
global_step: 11084, epoch: 78, loss: 0.665118
global_step: 11085, epoch: 78, loss: 0.759804
global_step: 11086, epoch: 78, loss: 0.737084
global_step: 11087, epoch: 78, loss: 0.805599
global_step: 11088, epoch: 78, loss: 0.761058
global_step: 11089, epoch: 78, loss: 0.850517
global_step: 11090, epoch: 78, loss: 0.840047
global_step: 11091, epoch: 78, loss: 0.764358
global_step: 11092, epoch: 78, loss: 0.785533
global_step: 11093, epoch: 78, loss: 0.836703
global_step: 11094, epoch: 78, loss: 0.820499
global_step: 11095, epoch: 78, loss: 0.848324
global_step: 11096, epoch: 78, loss: 0.729478
global_step: 11097, epoch: 78, loss: 0.740486
global_step: 11098, epoch: 78, loss: 0.775599
global_step: 11099, epoch: 78, loss: 0.765193
global_step: 11100, epoch: 78, loss: 0.763321
global_step: 11101, epoch: 78, loss: 0.809265
global_step: 11102, epoch: 78, loss: 0.686926
global_step: 11103, epoch: 78, loss: 0.907417
global_step: 11104, epoch: 78, loss: 0.763019
global_step: 11105, epoch: 78, loss: 0.801125
global_step: 11106, epoch: 78, loss: 0.767803
global_step: 11107, epoch: 78, loss: 0.769719
global_step: 11108, epoch: 78, loss: 0.750163
global_step: 11109, epoch: 78, loss: 0.735635
global_step: 11110, epoch: 78, loss: 0.765208
global_step: 11111, epoch: 78, loss: 0.729131
global_step: 11112, epoch: 78, loss: 0.797220
global_step: 11113, epoch: 78, loss: 0.755445
global_step: 11114, epoch: 78, loss: 0.768027
global_step: 11115, epoch: 78, loss: 0.803329
global_step: 11116, epoch: 78, loss: 0.803898
global_step: 11117, epoch: 78, loss: 0.694249
global_step: 11118, epoch: 78, loss: 0.757115
global_step: 11119, epoch: 78, loss: 0.812192
global_step: 11120, epoch: 78, loss: 1.435786
epoch: 78
train	acc: 0.8390	macro: p 0.8587, r 0.5975, f1: 0.5970	micro: p 0.8390, r 0.8390, f1 0.8390	weighted_f1:0.8167
dev	acc: 0.5455	macro: p 0.3371, r 0.3112, f1: 0.3051	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4990
test	acc: 0.5966	macro: p 0.3578, r 0.3312, f1: 0.3303	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5583
global_step: 11121, epoch: 79, loss: 0.731421
global_step: 11122, epoch: 79, loss: 0.718840
global_step: 11123, epoch: 79, loss: 0.741449
global_step: 11124, epoch: 79, loss: 0.751615
global_step: 11125, epoch: 79, loss: 0.668454
global_step: 11126, epoch: 79, loss: 0.884464
global_step: 11127, epoch: 79, loss: 0.682263
global_step: 11128, epoch: 79, loss: 0.781544
global_step: 11129, epoch: 79, loss: 0.827324
global_step: 11130, epoch: 79, loss: 0.776260
global_step: 11131, epoch: 79, loss: 0.839401
global_step: 11132, epoch: 79, loss: 0.748194
global_step: 11133, epoch: 79, loss: 0.835097
global_step: 11134, epoch: 79, loss: 0.795168
global_step: 11135, epoch: 79, loss: 0.745383
global_step: 11136, epoch: 79, loss: 0.809373
global_step: 11137, epoch: 79, loss: 0.760294
global_step: 11138, epoch: 79, loss: 0.856941
global_step: 11139, epoch: 79, loss: 0.734820
global_step: 11140, epoch: 79, loss: 0.766734
global_step: 11141, epoch: 79, loss: 0.818683
global_step: 11142, epoch: 79, loss: 0.740200
global_step: 11143, epoch: 79, loss: 0.834017
global_step: 11144, epoch: 79, loss: 0.839101
global_step: 11145, epoch: 79, loss: 0.819711
global_step: 11146, epoch: 79, loss: 0.805451
global_step: 11147, epoch: 79, loss: 0.699244
global_step: 11148, epoch: 79, loss: 0.661656
global_step: 11149, epoch: 79, loss: 0.670589
global_step: 11150, epoch: 79, loss: 0.757020
global_step: 11151, epoch: 79, loss: 0.787693
global_step: 11152, epoch: 79, loss: 0.667015
global_step: 11153, epoch: 79, loss: 0.706581
global_step: 11154, epoch: 79, loss: 0.742507
global_step: 11155, epoch: 79, loss: 0.735729
global_step: 11156, epoch: 79, loss: 0.718334
global_step: 11157, epoch: 79, loss: 0.727078
global_step: 11158, epoch: 79, loss: 0.816114
global_step: 11159, epoch: 79, loss: 0.812628
global_step: 11160, epoch: 79, loss: 0.754449
epoch: 79
train	acc: 0.8361	macro: p 0.8606, r 0.5906, f1: 0.5915	micro: p 0.8361, r 0.8361, f1 0.8361	weighted_f1:0.8136
dev	acc: 0.5437	macro: p 0.3396, r 0.3104, f1: 0.3023	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4975
test	acc: 0.5981	macro: p 0.3647, r 0.3282, f1: 0.3285	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5590
global_step: 11161, epoch: 80, loss: 0.778018
global_step: 11162, epoch: 80, loss: 0.765437
global_step: 11163, epoch: 80, loss: 0.912982
global_step: 11164, epoch: 80, loss: 0.709180
global_step: 11165, epoch: 80, loss: 0.764328
global_step: 11166, epoch: 80, loss: 0.742924
global_step: 11167, epoch: 80, loss: 0.871688
global_step: 11168, epoch: 80, loss: 0.686303
global_step: 11169, epoch: 80, loss: 0.721281
global_step: 11170, epoch: 80, loss: 0.697327
global_step: 11171, epoch: 80, loss: 0.778811
global_step: 11172, epoch: 80, loss: 0.713593
global_step: 11173, epoch: 80, loss: 0.764235
global_step: 11174, epoch: 80, loss: 0.764835
global_step: 11175, epoch: 80, loss: 0.743768
global_step: 11176, epoch: 80, loss: 0.739484
global_step: 11177, epoch: 80, loss: 0.808084
global_step: 11178, epoch: 80, loss: 0.755301
global_step: 11179, epoch: 80, loss: 0.737137
global_step: 11180, epoch: 80, loss: 0.732518
global_step: 11181, epoch: 80, loss: 0.703090
global_step: 11182, epoch: 80, loss: 0.842126
global_step: 11183, epoch: 80, loss: 0.680222
global_step: 11184, epoch: 80, loss: 0.782191
global_step: 11185, epoch: 80, loss: 0.715441
global_step: 11186, epoch: 80, loss: 0.700318
global_step: 11187, epoch: 80, loss: 0.804954
global_step: 11188, epoch: 80, loss: 0.809806
global_step: 11189, epoch: 80, loss: 0.762413
global_step: 11190, epoch: 80, loss: 0.759423
global_step: 11191, epoch: 80, loss: 0.758939
global_step: 11192, epoch: 80, loss: 0.785604
global_step: 11193, epoch: 80, loss: 0.672589
global_step: 11194, epoch: 80, loss: 0.780610
global_step: 11195, epoch: 80, loss: 0.798230
global_step: 11196, epoch: 80, loss: 0.710998
global_step: 11197, epoch: 80, loss: 0.767332
global_step: 11198, epoch: 80, loss: 0.710917
global_step: 11199, epoch: 80, loss: 0.773620
global_step: 11200, epoch: 80, loss: 0.319260
epoch: 80
train	acc: 0.8374	macro: p 0.8628, r 0.5916, f1: 0.5933	micro: p 0.8374, r 0.8374, f1 0.8374	weighted_f1:0.8140
dev	acc: 0.5446	macro: p 0.3343, r 0.3081, f1: 0.3017	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4956
test	acc: 0.5981	macro: p 0.3599, r 0.3254, f1: 0.3256	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5563
global_step: 11201, epoch: 81, loss: 0.769309
global_step: 11202, epoch: 81, loss: 0.721226
global_step: 11203, epoch: 81, loss: 0.880649
global_step: 11204, epoch: 81, loss: 0.753581
global_step: 11205, epoch: 81, loss: 0.829499
global_step: 11206, epoch: 81, loss: 0.815965
global_step: 11207, epoch: 81, loss: 0.806959
global_step: 11208, epoch: 81, loss: 0.724095
global_step: 11209, epoch: 81, loss: 0.673292
global_step: 11210, epoch: 81, loss: 0.725973
global_step: 11211, epoch: 81, loss: 0.732747
global_step: 11212, epoch: 81, loss: 0.817026
global_step: 11213, epoch: 81, loss: 0.860836
global_step: 11214, epoch: 81, loss: 0.819133
global_step: 11215, epoch: 81, loss: 0.678410
global_step: 11216, epoch: 81, loss: 0.719828
global_step: 11217, epoch: 81, loss: 0.726126
global_step: 11218, epoch: 81, loss: 0.685942
global_step: 11219, epoch: 81, loss: 0.763626
global_step: 11220, epoch: 81, loss: 0.568775
global_step: 11221, epoch: 81, loss: 0.747408
global_step: 11222, epoch: 81, loss: 0.730281
global_step: 11223, epoch: 81, loss: 0.774593
global_step: 11224, epoch: 81, loss: 0.663024
global_step: 11225, epoch: 81, loss: 0.806838
global_step: 11226, epoch: 81, loss: 0.627717
global_step: 11227, epoch: 81, loss: 0.760761
global_step: 11228, epoch: 81, loss: 0.679521
global_step: 11229, epoch: 81, loss: 0.771276
global_step: 11230, epoch: 81, loss: 0.778962
global_step: 11231, epoch: 81, loss: 0.740289
global_step: 11232, epoch: 81, loss: 0.739924
global_step: 11233, epoch: 81, loss: 0.713880
global_step: 11234, epoch: 81, loss: 0.762449
global_step: 11235, epoch: 81, loss: 0.743858
global_step: 11236, epoch: 81, loss: 0.764108
global_step: 11237, epoch: 81, loss: 0.753568
global_step: 11238, epoch: 81, loss: 0.736056
global_step: 11239, epoch: 81, loss: 0.846829
global_step: 11240, epoch: 81, loss: 0.366581
epoch: 81
train	acc: 0.8432	macro: p 0.8626, r 0.6061, f1: 0.6072	micro: p 0.8432, r 0.8432, f1 0.8432	weighted_f1:0.8222
dev	acc: 0.5446	macro: p 0.3408, r 0.3116, f1: 0.3056	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4995
test	acc: 0.5962	macro: p 0.3562, r 0.3285, f1: 0.3285	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5586
global_step: 11241, epoch: 82, loss: 0.753653
global_step: 11242, epoch: 82, loss: 0.700185
global_step: 11243, epoch: 82, loss: 0.751486
global_step: 11244, epoch: 82, loss: 0.756235
global_step: 11245, epoch: 82, loss: 0.721384
global_step: 11246, epoch: 82, loss: 0.763360
global_step: 11247, epoch: 82, loss: 0.667797
global_step: 11248, epoch: 82, loss: 0.758706
global_step: 11249, epoch: 82, loss: 0.745449
global_step: 11250, epoch: 82, loss: 0.693807
global_step: 11251, epoch: 82, loss: 0.781266
global_step: 11252, epoch: 82, loss: 0.711241
global_step: 11253, epoch: 82, loss: 0.731413
global_step: 11254, epoch: 82, loss: 0.673951
global_step: 11255, epoch: 82, loss: 0.647213
global_step: 11256, epoch: 82, loss: 0.646320
global_step: 11257, epoch: 82, loss: 0.719404
global_step: 11258, epoch: 82, loss: 0.740704
global_step: 11259, epoch: 82, loss: 0.652245
global_step: 11260, epoch: 82, loss: 0.646065
global_step: 11261, epoch: 82, loss: 0.734595
global_step: 11262, epoch: 82, loss: 0.786132
global_step: 11263, epoch: 82, loss: 0.694942
global_step: 11264, epoch: 82, loss: 0.630557
global_step: 11265, epoch: 82, loss: 0.790835
global_step: 11266, epoch: 82, loss: 0.748753
global_step: 11267, epoch: 82, loss: 0.780170
global_step: 11268, epoch: 82, loss: 0.795008
global_step: 11269, epoch: 82, loss: 0.818875
global_step: 11270, epoch: 82, loss: 0.793049
global_step: 11271, epoch: 82, loss: 0.675596
global_step: 11272, epoch: 82, loss: 0.784428
global_step: 11273, epoch: 82, loss: 0.760819
global_step: 11274, epoch: 82, loss: 0.761057
global_step: 11275, epoch: 82, loss: 0.798533
global_step: 11276, epoch: 82, loss: 0.741147
global_step: 11277, epoch: 82, loss: 0.736992
global_step: 11278, epoch: 82, loss: 0.805989
global_step: 11279, epoch: 82, loss: 0.808946
global_step: 11280, epoch: 82, loss: 2.321520
epoch: 82
train	acc: 0.8525	macro: p 0.8692, r 0.6282, f1: 0.6368	micro: p 0.8525, r 0.8525, f1 0.8525	weighted_f1:0.8341
dev	acc: 0.5446	macro: p 0.3310, r 0.3089, f1: 0.3048	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4993
test	acc: 0.5969	macro: p 0.3588, r 0.3285, f1: 0.3328	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5600
global_step: 11281, epoch: 83, loss: 0.746096
global_step: 11282, epoch: 83, loss: 0.761458
global_step: 11283, epoch: 83, loss: 0.706541
global_step: 11284, epoch: 83, loss: 0.667147
global_step: 11285, epoch: 83, loss: 0.726831
global_step: 11286, epoch: 83, loss: 0.698122
global_step: 11287, epoch: 83, loss: 0.755461
global_step: 11288, epoch: 83, loss: 0.689210
global_step: 11289, epoch: 83, loss: 0.670150
global_step: 11290, epoch: 83, loss: 0.762276
global_step: 11291, epoch: 83, loss: 0.835886
global_step: 11292, epoch: 83, loss: 0.643774
global_step: 11293, epoch: 83, loss: 0.775373
global_step: 11294, epoch: 83, loss: 0.785617
global_step: 11295, epoch: 83, loss: 0.700346
global_step: 11296, epoch: 83, loss: 0.745669
global_step: 11297, epoch: 83, loss: 0.647488
global_step: 11298, epoch: 83, loss: 0.768474
global_step: 11299, epoch: 83, loss: 0.662893
global_step: 11300, epoch: 83, loss: 0.753402
global_step: 11301, epoch: 83, loss: 0.682028
global_step: 11302, epoch: 83, loss: 0.677564
global_step: 11303, epoch: 83, loss: 0.722792
global_step: 11304, epoch: 83, loss: 0.820344
global_step: 11305, epoch: 83, loss: 0.721129
global_step: 11306, epoch: 83, loss: 0.686189
global_step: 11307, epoch: 83, loss: 0.768574
global_step: 11308, epoch: 83, loss: 0.726282
global_step: 11309, epoch: 83, loss: 0.733431
global_step: 11310, epoch: 83, loss: 0.778620
global_step: 11311, epoch: 83, loss: 0.673064
global_step: 11312, epoch: 83, loss: 0.714555
global_step: 11313, epoch: 83, loss: 0.867041
global_step: 11314, epoch: 83, loss: 0.763841
global_step: 11315, epoch: 83, loss: 0.742173
global_step: 11316, epoch: 83, loss: 0.736764
global_step: 11317, epoch: 83, loss: 0.749711
global_step: 11318, epoch: 83, loss: 0.789635
global_step: 11319, epoch: 83, loss: 0.675287
global_step: 11320, epoch: 83, loss: 0.616269
epoch: 83
train	acc: 0.8466	macro: p 0.8716, r 0.6118, f1: 0.6232	micro: p 0.8466, r 0.8466, f1 0.8466	weighted_f1:0.8260
dev	acc: 0.5473	macro: p 0.3314, r 0.3085, f1: 0.2997	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4964
test	acc: 0.5981	macro: p 0.3605, r 0.3229, f1: 0.3208	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5534
global_step: 11321, epoch: 84, loss: 0.792538
global_step: 11322, epoch: 84, loss: 0.798043
global_step: 11323, epoch: 84, loss: 0.750195
global_step: 11324, epoch: 84, loss: 0.726788
global_step: 11325, epoch: 84, loss: 0.693264
global_step: 11326, epoch: 84, loss: 0.856578
global_step: 11327, epoch: 84, loss: 0.669461
global_step: 11328, epoch: 84, loss: 0.755943
global_step: 11329, epoch: 84, loss: 0.736139
global_step: 11330, epoch: 84, loss: 0.674179
global_step: 11331, epoch: 84, loss: 0.747280
global_step: 11332, epoch: 84, loss: 0.760158
global_step: 11333, epoch: 84, loss: 0.807573
global_step: 11334, epoch: 84, loss: 0.747303
global_step: 11335, epoch: 84, loss: 0.763786
global_step: 11336, epoch: 84, loss: 0.632494
global_step: 11337, epoch: 84, loss: 0.755187
global_step: 11338, epoch: 84, loss: 0.650492
global_step: 11339, epoch: 84, loss: 0.707836
global_step: 11340, epoch: 84, loss: 0.738183
global_step: 11341, epoch: 84, loss: 0.697029
global_step: 11342, epoch: 84, loss: 0.794419
global_step: 11343, epoch: 84, loss: 0.830770
global_step: 11344, epoch: 84, loss: 0.673390
global_step: 11345, epoch: 84, loss: 0.619648
global_step: 11346, epoch: 84, loss: 0.700863
global_step: 11347, epoch: 84, loss: 0.678421
global_step: 11348, epoch: 84, loss: 0.725184
global_step: 11349, epoch: 84, loss: 0.698669
global_step: 11350, epoch: 84, loss: 0.737426
global_step: 11351, epoch: 84, loss: 0.800821
global_step: 11352, epoch: 84, loss: 0.758078
global_step: 11353, epoch: 84, loss: 0.711027
global_step: 11354, epoch: 84, loss: 0.630044
global_step: 11355, epoch: 84, loss: 0.755714
global_step: 11356, epoch: 84, loss: 0.763155
global_step: 11357, epoch: 84, loss: 0.698088
global_step: 11358, epoch: 84, loss: 0.751961
global_step: 11359, epoch: 84, loss: 0.886269
global_step: 11360, epoch: 84, loss: 0.174780
epoch: 84
train	acc: 0.8533	macro: p 0.8727, r 0.6231, f1: 0.6306	micro: p 0.8533, r 0.8533, f1 0.8533	weighted_f1:0.8337
dev	acc: 0.5446	macro: p 0.3374, r 0.3091, f1: 0.3044	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4983
test	acc: 0.5992	macro: p 0.3637, r 0.3274, f1: 0.3308	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5598
global_step: 11361, epoch: 85, loss: 0.704295
global_step: 11362, epoch: 85, loss: 0.758894
global_step: 11363, epoch: 85, loss: 0.662309
global_step: 11364, epoch: 85, loss: 0.728275
global_step: 11365, epoch: 85, loss: 0.705103
global_step: 11366, epoch: 85, loss: 0.768509
global_step: 11367, epoch: 85, loss: 0.669003
global_step: 11368, epoch: 85, loss: 0.767528
global_step: 11369, epoch: 85, loss: 0.684938
global_step: 11370, epoch: 85, loss: 0.775702
global_step: 11371, epoch: 85, loss: 0.706573
global_step: 11372, epoch: 85, loss: 0.705169
global_step: 11373, epoch: 85, loss: 0.715816
global_step: 11374, epoch: 85, loss: 0.801647
global_step: 11375, epoch: 85, loss: 0.667140
global_step: 11376, epoch: 85, loss: 0.654002
global_step: 11377, epoch: 85, loss: 0.705321
global_step: 11378, epoch: 85, loss: 0.724995
global_step: 11379, epoch: 85, loss: 0.730855
global_step: 11380, epoch: 85, loss: 0.697550
global_step: 11381, epoch: 85, loss: 0.723026
global_step: 11382, epoch: 85, loss: 0.677009
global_step: 11383, epoch: 85, loss: 0.846946
global_step: 11384, epoch: 85, loss: 0.781845
global_step: 11385, epoch: 85, loss: 0.760202
global_step: 11386, epoch: 85, loss: 0.709166
global_step: 11387, epoch: 85, loss: 0.735753
global_step: 11388, epoch: 85, loss: 0.676436
global_step: 11389, epoch: 85, loss: 0.770165
global_step: 11390, epoch: 85, loss: 0.733671
global_step: 11391, epoch: 85, loss: 0.768790
global_step: 11392, epoch: 85, loss: 0.663116
global_step: 11393, epoch: 85, loss: 0.710101
global_step: 11394, epoch: 85, loss: 0.755710
global_step: 11395, epoch: 85, loss: 0.738909
global_step: 11396, epoch: 85, loss: 0.798465
global_step: 11397, epoch: 85, loss: 0.722334
global_step: 11398, epoch: 85, loss: 0.695840
global_step: 11399, epoch: 85, loss: 0.724689
global_step: 11400, epoch: 85, loss: 0.894292
epoch: 85
train	acc: 0.8615	macro: p 0.8753, r 0.6509, f1: 0.6649	micro: p 0.8615, r 0.8615, f1 0.8615	weighted_f1:0.8455
dev	acc: 0.5446	macro: p 0.3295, r 0.3106, f1: 0.3054	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4999
test	acc: 0.5962	macro: p 0.3546, r 0.3298, f1: 0.3318	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5599
global_step: 11401, epoch: 86, loss: 0.806008
global_step: 11402, epoch: 86, loss: 0.667794
global_step: 11403, epoch: 86, loss: 0.649272
global_step: 11404, epoch: 86, loss: 0.680346
global_step: 11405, epoch: 86, loss: 0.687430
global_step: 11406, epoch: 86, loss: 0.735407
global_step: 11407, epoch: 86, loss: 0.720160
global_step: 11408, epoch: 86, loss: 0.747640
global_step: 11409, epoch: 86, loss: 0.793501
global_step: 11410, epoch: 86, loss: 0.692091
global_step: 11411, epoch: 86, loss: 0.842281
global_step: 11412, epoch: 86, loss: 0.720627
global_step: 11413, epoch: 86, loss: 0.621982
global_step: 11414, epoch: 86, loss: 0.729489
global_step: 11415, epoch: 86, loss: 0.783532
global_step: 11416, epoch: 86, loss: 0.732678
global_step: 11417, epoch: 86, loss: 0.742235
global_step: 11418, epoch: 86, loss: 0.656188
global_step: 11419, epoch: 86, loss: 0.871725
global_step: 11420, epoch: 86, loss: 0.664979
global_step: 11421, epoch: 86, loss: 0.754515
global_step: 11422, epoch: 86, loss: 0.769581
global_step: 11423, epoch: 86, loss: 0.652829
global_step: 11424, epoch: 86, loss: 0.799799
global_step: 11425, epoch: 86, loss: 0.821376
global_step: 11426, epoch: 86, loss: 0.773454
global_step: 11427, epoch: 86, loss: 0.726983
global_step: 11428, epoch: 86, loss: 0.726440
global_step: 11429, epoch: 86, loss: 0.669823
global_step: 11430, epoch: 86, loss: 0.780210
global_step: 11431, epoch: 86, loss: 0.656207
global_step: 11432, epoch: 86, loss: 0.636623
global_step: 11433, epoch: 86, loss: 0.795226
global_step: 11434, epoch: 86, loss: 0.624212
global_step: 11435, epoch: 86, loss: 0.573253
global_step: 11436, epoch: 86, loss: 0.654704
global_step: 11437, epoch: 86, loss: 0.783451
global_step: 11438, epoch: 86, loss: 0.703369
global_step: 11439, epoch: 86, loss: 0.674328
global_step: 11440, epoch: 86, loss: 0.754251
epoch: 86
train	acc: 0.8572	macro: p 0.8695, r 0.6364, f1: 0.6538	micro: p 0.8572, r 0.8572, f1 0.8572	weighted_f1:0.8398
dev	acc: 0.5401	macro: p 0.3328, r 0.3023, f1: 0.2962	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4908
test	acc: 0.5958	macro: p 0.5012, r 0.3244, f1: 0.3280	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5550
global_step: 11441, epoch: 87, loss: 0.665176
global_step: 11442, epoch: 87, loss: 0.754486
global_step: 11443, epoch: 87, loss: 0.600976
global_step: 11444, epoch: 87, loss: 0.902215
global_step: 11445, epoch: 87, loss: 0.676177
global_step: 11446, epoch: 87, loss: 0.657553
global_step: 11447, epoch: 87, loss: 0.796608
global_step: 11448, epoch: 87, loss: 0.599766
global_step: 11449, epoch: 87, loss: 0.631496
global_step: 11450, epoch: 87, loss: 0.693427
global_step: 11451, epoch: 87, loss: 0.781119
global_step: 11452, epoch: 87, loss: 0.706714
global_step: 11453, epoch: 87, loss: 0.703389
global_step: 11454, epoch: 87, loss: 0.758516
global_step: 11455, epoch: 87, loss: 0.707204
global_step: 11456, epoch: 87, loss: 0.671037
global_step: 11457, epoch: 87, loss: 0.676623
global_step: 11458, epoch: 87, loss: 0.654408
global_step: 11459, epoch: 87, loss: 0.691048
global_step: 11460, epoch: 87, loss: 0.712577
global_step: 11461, epoch: 87, loss: 0.633862
global_step: 11462, epoch: 87, loss: 0.730611
global_step: 11463, epoch: 87, loss: 0.725160
global_step: 11464, epoch: 87, loss: 0.667983
global_step: 11465, epoch: 87, loss: 0.724862
global_step: 11466, epoch: 87, loss: 0.744538
global_step: 11467, epoch: 87, loss: 0.677533
global_step: 11468, epoch: 87, loss: 0.749796
global_step: 11469, epoch: 87, loss: 0.631556
global_step: 11470, epoch: 87, loss: 0.694711
global_step: 11471, epoch: 87, loss: 0.810669
global_step: 11472, epoch: 87, loss: 0.729637
global_step: 11473, epoch: 87, loss: 0.717014
global_step: 11474, epoch: 87, loss: 0.676628
global_step: 11475, epoch: 87, loss: 0.731065
global_step: 11476, epoch: 87, loss: 0.754691
global_step: 11477, epoch: 87, loss: 0.729140
global_step: 11478, epoch: 87, loss: 0.652278
global_step: 11479, epoch: 87, loss: 0.786205
global_step: 11480, epoch: 87, loss: 0.314424
epoch: 87
train	acc: 0.8543	macro: p 0.8774, r 0.6263, f1: 0.6395	micro: p 0.8543, r 0.8543, f1 0.8543	weighted_f1:0.8351
dev	acc: 0.5473	macro: p 0.3321, r 0.3057, f1: 0.3023	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4971
test	acc: 0.5954	macro: p 0.3569, r 0.3165, f1: 0.3206	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5517
global_step: 11481, epoch: 88, loss: 0.624518
global_step: 11482, epoch: 88, loss: 0.624764
global_step: 11483, epoch: 88, loss: 0.696535
global_step: 11484, epoch: 88, loss: 0.725088
global_step: 11485, epoch: 88, loss: 0.718765
global_step: 11486, epoch: 88, loss: 0.714972
global_step: 11487, epoch: 88, loss: 0.655554
global_step: 11488, epoch: 88, loss: 0.658416
global_step: 11489, epoch: 88, loss: 0.605965
global_step: 11490, epoch: 88, loss: 0.719250
global_step: 11491, epoch: 88, loss: 0.688963
global_step: 11492, epoch: 88, loss: 0.671496
global_step: 11493, epoch: 88, loss: 0.786758
global_step: 11494, epoch: 88, loss: 0.622748
global_step: 11495, epoch: 88, loss: 0.700313
global_step: 11496, epoch: 88, loss: 0.748306
global_step: 11497, epoch: 88, loss: 0.664845
global_step: 11498, epoch: 88, loss: 0.615508
global_step: 11499, epoch: 88, loss: 0.720151
global_step: 11500, epoch: 88, loss: 0.715002
global_step: 11501, epoch: 88, loss: 0.699056
global_step: 11502, epoch: 88, loss: 0.698450
global_step: 11503, epoch: 88, loss: 0.762722
global_step: 11504, epoch: 88, loss: 0.726615
global_step: 11505, epoch: 88, loss: 0.723104
global_step: 11506, epoch: 88, loss: 0.659858
global_step: 11507, epoch: 88, loss: 0.679104
global_step: 11508, epoch: 88, loss: 0.758838
global_step: 11509, epoch: 88, loss: 0.730506
global_step: 11510, epoch: 88, loss: 0.807127
global_step: 11511, epoch: 88, loss: 0.736413
global_step: 11512, epoch: 88, loss: 0.681782
global_step: 11513, epoch: 88, loss: 0.626087
global_step: 11514, epoch: 88, loss: 0.799923
global_step: 11515, epoch: 88, loss: 0.669977
global_step: 11516, epoch: 88, loss: 0.753848
global_step: 11517, epoch: 88, loss: 0.731985
global_step: 11518, epoch: 88, loss: 0.701540
global_step: 11519, epoch: 88, loss: 0.722950
global_step: 11520, epoch: 88, loss: 0.398501
epoch: 88
train	acc: 0.8605	macro: p 0.8737, r 0.6393, f1: 0.6562	micro: p 0.8605, r 0.8605, f1 0.8605	weighted_f1:0.8433
dev	acc: 0.5446	macro: p 0.3400, r 0.3060, f1: 0.3019	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4965
test	acc: 0.5969	macro: p 0.3593, r 0.3223, f1: 0.3257	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5566
global_step: 11521, epoch: 89, loss: 0.597975
global_step: 11522, epoch: 89, loss: 0.618894
global_step: 11523, epoch: 89, loss: 0.733381
global_step: 11524, epoch: 89, loss: 0.760941
global_step: 11525, epoch: 89, loss: 0.690928
global_step: 11526, epoch: 89, loss: 0.642496
global_step: 11527, epoch: 89, loss: 0.661637
global_step: 11528, epoch: 89, loss: 0.608319
global_step: 11529, epoch: 89, loss: 0.571488
global_step: 11530, epoch: 89, loss: 0.687086
global_step: 11531, epoch: 89, loss: 0.686135
global_step: 11532, epoch: 89, loss: 0.748575
global_step: 11533, epoch: 89, loss: 0.688135
global_step: 11534, epoch: 89, loss: 0.629957
global_step: 11535, epoch: 89, loss: 0.655023
global_step: 11536, epoch: 89, loss: 0.748239
global_step: 11537, epoch: 89, loss: 0.653425
global_step: 11538, epoch: 89, loss: 0.736326
global_step: 11539, epoch: 89, loss: 0.676787
global_step: 11540, epoch: 89, loss: 0.745737
global_step: 11541, epoch: 89, loss: 0.675848
global_step: 11542, epoch: 89, loss: 0.666063
global_step: 11543, epoch: 89, loss: 0.705321
global_step: 11544, epoch: 89, loss: 0.653533
global_step: 11545, epoch: 89, loss: 0.802307
global_step: 11546, epoch: 89, loss: 0.614395
global_step: 11547, epoch: 89, loss: 0.715558
global_step: 11548, epoch: 89, loss: 0.650346
global_step: 11549, epoch: 89, loss: 0.767872
global_step: 11550, epoch: 89, loss: 0.670541
global_step: 11551, epoch: 89, loss: 0.694231
global_step: 11552, epoch: 89, loss: 0.655012
global_step: 11553, epoch: 89, loss: 0.827556
global_step: 11554, epoch: 89, loss: 0.627752
global_step: 11555, epoch: 89, loss: 0.654845
global_step: 11556, epoch: 89, loss: 0.752648
global_step: 11557, epoch: 89, loss: 0.660180
global_step: 11558, epoch: 89, loss: 0.697311
global_step: 11559, epoch: 89, loss: 0.688957
global_step: 11560, epoch: 89, loss: 0.485234
epoch: 89
train	acc: 0.8722	macro: p 0.8705, r 0.6668, f1: 0.6844	micro: p 0.8722, r 0.8722, f1 0.8722	weighted_f1:0.8577
dev	acc: 0.5383	macro: p 0.3276, r 0.3060, f1: 0.2989	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4940
test	acc: 0.5946	macro: p 0.5006, r 0.3349, f1: 0.3370	micro: p 0.5946, r 0.5946, f1 0.5946	weighted_f1:0.5612
global_step: 11561, epoch: 90, loss: 0.682706
global_step: 11562, epoch: 90, loss: 0.708908
global_step: 11563, epoch: 90, loss: 0.547194
global_step: 11564, epoch: 90, loss: 0.743788
global_step: 11565, epoch: 90, loss: 0.653995
global_step: 11566, epoch: 90, loss: 0.636236
global_step: 11567, epoch: 90, loss: 0.676044
global_step: 11568, epoch: 90, loss: 0.705370
global_step: 11569, epoch: 90, loss: 0.586625
global_step: 11570, epoch: 90, loss: 0.657464
global_step: 11571, epoch: 90, loss: 0.597849
global_step: 11572, epoch: 90, loss: 0.756107
global_step: 11573, epoch: 90, loss: 0.759164
global_step: 11574, epoch: 90, loss: 0.688393
global_step: 11575, epoch: 90, loss: 0.706951
global_step: 11576, epoch: 90, loss: 0.673796
global_step: 11577, epoch: 90, loss: 0.774504
global_step: 11578, epoch: 90, loss: 0.726416
global_step: 11579, epoch: 90, loss: 0.659458
global_step: 11580, epoch: 90, loss: 0.653649
global_step: 11581, epoch: 90, loss: 0.660543
global_step: 11582, epoch: 90, loss: 0.807459
global_step: 11583, epoch: 90, loss: 0.712187
global_step: 11584, epoch: 90, loss: 0.748700
global_step: 11585, epoch: 90, loss: 0.668112
global_step: 11586, epoch: 90, loss: 0.677428
global_step: 11587, epoch: 90, loss: 0.695538
global_step: 11588, epoch: 90, loss: 0.697757
global_step: 11589, epoch: 90, loss: 0.603144
global_step: 11590, epoch: 90, loss: 0.712566
global_step: 11591, epoch: 90, loss: 0.691513
global_step: 11592, epoch: 90, loss: 0.685231
global_step: 11593, epoch: 90, loss: 0.771725
global_step: 11594, epoch: 90, loss: 0.681789
global_step: 11595, epoch: 90, loss: 0.809673
global_step: 11596, epoch: 90, loss: 0.653920
global_step: 11597, epoch: 90, loss: 0.609236
global_step: 11598, epoch: 90, loss: 0.699561
global_step: 11599, epoch: 90, loss: 0.640498
global_step: 11600, epoch: 90, loss: 0.388251
epoch: 90
train	acc: 0.8643	macro: p 0.8841, r 0.6489, f1: 0.6680	micro: p 0.8643, r 0.8643, f1 0.8643	weighted_f1:0.8474
dev	acc: 0.5446	macro: p 0.3325, r 0.3057, f1: 0.3007	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4950
test	acc: 0.5958	macro: p 0.3584, r 0.3187, f1: 0.3215	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5519
global_step: 11601, epoch: 91, loss: 0.663899
global_step: 11602, epoch: 91, loss: 0.694027
global_step: 11603, epoch: 91, loss: 0.644092
global_step: 11604, epoch: 91, loss: 0.696426
global_step: 11605, epoch: 91, loss: 0.672985
global_step: 11606, epoch: 91, loss: 0.749862
global_step: 11607, epoch: 91, loss: 0.617298
global_step: 11608, epoch: 91, loss: 0.688218
global_step: 11609, epoch: 91, loss: 0.645498
global_step: 11610, epoch: 91, loss: 0.699525
global_step: 11611, epoch: 91, loss: 0.669030
global_step: 11612, epoch: 91, loss: 0.664015
global_step: 11613, epoch: 91, loss: 0.664248
global_step: 11614, epoch: 91, loss: 0.663257
global_step: 11615, epoch: 91, loss: 0.719130
global_step: 11616, epoch: 91, loss: 0.619763
global_step: 11617, epoch: 91, loss: 0.696157
global_step: 11618, epoch: 91, loss: 0.645699
global_step: 11619, epoch: 91, loss: 0.652164
global_step: 11620, epoch: 91, loss: 0.554899
global_step: 11621, epoch: 91, loss: 0.700767
global_step: 11622, epoch: 91, loss: 0.732684
global_step: 11623, epoch: 91, loss: 0.623401
global_step: 11624, epoch: 91, loss: 0.682437
global_step: 11625, epoch: 91, loss: 0.726088
global_step: 11626, epoch: 91, loss: 0.664205
global_step: 11627, epoch: 91, loss: 0.730194
global_step: 11628, epoch: 91, loss: 0.739650
global_step: 11629, epoch: 91, loss: 0.808271
global_step: 11630, epoch: 91, loss: 0.765732
global_step: 11631, epoch: 91, loss: 0.698850
global_step: 11632, epoch: 91, loss: 0.716453
global_step: 11633, epoch: 91, loss: 0.619811
global_step: 11634, epoch: 91, loss: 0.742535
global_step: 11635, epoch: 91, loss: 0.607077
global_step: 11636, epoch: 91, loss: 0.659400
global_step: 11637, epoch: 91, loss: 0.639800
global_step: 11638, epoch: 91, loss: 0.591868
global_step: 11639, epoch: 91, loss: 0.663652
global_step: 11640, epoch: 91, loss: 0.820352
epoch: 91
train	acc: 0.8747	macro: p 0.8802, r 0.6736, f1: 0.6933	micro: p 0.8747, r 0.8747, f1 0.8747	weighted_f1:0.8607
dev	acc: 0.5419	macro: p 0.3294, r 0.3080, f1: 0.2995	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4961
test	acc: 0.5943	macro: p 0.5050, r 0.3335, f1: 0.3365	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5593
global_step: 11641, epoch: 92, loss: 0.625952
global_step: 11642, epoch: 92, loss: 0.754398
global_step: 11643, epoch: 92, loss: 0.635688
global_step: 11644, epoch: 92, loss: 0.774276
global_step: 11645, epoch: 92, loss: 0.590663
global_step: 11646, epoch: 92, loss: 0.678575
global_step: 11647, epoch: 92, loss: 0.786874
global_step: 11648, epoch: 92, loss: 0.709195
global_step: 11649, epoch: 92, loss: 0.685428
global_step: 11650, epoch: 92, loss: 0.647504
global_step: 11651, epoch: 92, loss: 0.669338
global_step: 11652, epoch: 92, loss: 0.757042
global_step: 11653, epoch: 92, loss: 0.675799
global_step: 11654, epoch: 92, loss: 0.671400
global_step: 11655, epoch: 92, loss: 0.625821
global_step: 11656, epoch: 92, loss: 0.616615
global_step: 11657, epoch: 92, loss: 0.693694
global_step: 11658, epoch: 92, loss: 0.679364
global_step: 11659, epoch: 92, loss: 0.634332
global_step: 11660, epoch: 92, loss: 0.693158
global_step: 11661, epoch: 92, loss: 0.720860
global_step: 11662, epoch: 92, loss: 0.634826
global_step: 11663, epoch: 92, loss: 0.659237
global_step: 11664, epoch: 92, loss: 0.733312
global_step: 11665, epoch: 92, loss: 0.689785
global_step: 11666, epoch: 92, loss: 0.722170
global_step: 11667, epoch: 92, loss: 0.620081
global_step: 11668, epoch: 92, loss: 0.805669
global_step: 11669, epoch: 92, loss: 0.649060
global_step: 11670, epoch: 92, loss: 0.654128
global_step: 11671, epoch: 92, loss: 0.674235
global_step: 11672, epoch: 92, loss: 0.636910
global_step: 11673, epoch: 92, loss: 0.802221
global_step: 11674, epoch: 92, loss: 0.603041
global_step: 11675, epoch: 92, loss: 0.646287
global_step: 11676, epoch: 92, loss: 0.645032
global_step: 11677, epoch: 92, loss: 0.622505
global_step: 11678, epoch: 92, loss: 0.694728
global_step: 11679, epoch: 92, loss: 0.602912
global_step: 11680, epoch: 92, loss: 0.136346
epoch: 92
train	acc: 0.8744	macro: p 0.8818, r 0.6700, f1: 0.6909	micro: p 0.8744, r 0.8744, f1 0.8744	weighted_f1:0.8600
dev	acc: 0.5410	macro: p 0.3303, r 0.3070, f1: 0.2995	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4947
test	acc: 0.5962	macro: p 0.5108, r 0.3309, f1: 0.3356	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5595
global_step: 11681, epoch: 93, loss: 0.670054
global_step: 11682, epoch: 93, loss: 0.618702
global_step: 11683, epoch: 93, loss: 0.740756
global_step: 11684, epoch: 93, loss: 0.734486
global_step: 11685, epoch: 93, loss: 0.682057
global_step: 11686, epoch: 93, loss: 0.771724
global_step: 11687, epoch: 93, loss: 0.798022
global_step: 11688, epoch: 93, loss: 0.692577
global_step: 11689, epoch: 93, loss: 0.731460
global_step: 11690, epoch: 93, loss: 0.688519
global_step: 11691, epoch: 93, loss: 0.609037
global_step: 11692, epoch: 93, loss: 0.628514
global_step: 11693, epoch: 93, loss: 0.648264
global_step: 11694, epoch: 93, loss: 0.676849
global_step: 11695, epoch: 93, loss: 0.675897
global_step: 11696, epoch: 93, loss: 0.653400
global_step: 11697, epoch: 93, loss: 0.603811
global_step: 11698, epoch: 93, loss: 0.718924
global_step: 11699, epoch: 93, loss: 0.621544
global_step: 11700, epoch: 93, loss: 0.757509
global_step: 11701, epoch: 93, loss: 0.760603
global_step: 11702, epoch: 93, loss: 0.590541
global_step: 11703, epoch: 93, loss: 0.684984
global_step: 11704, epoch: 93, loss: 0.657064
global_step: 11705, epoch: 93, loss: 0.688714
global_step: 11706, epoch: 93, loss: 0.671700
global_step: 11707, epoch: 93, loss: 0.765811
global_step: 11708, epoch: 93, loss: 0.616686
global_step: 11709, epoch: 93, loss: 0.653634
global_step: 11710, epoch: 93, loss: 0.591668
global_step: 11711, epoch: 93, loss: 0.694426
global_step: 11712, epoch: 93, loss: 0.713970
global_step: 11713, epoch: 93, loss: 0.698373
global_step: 11714, epoch: 93, loss: 0.727715
global_step: 11715, epoch: 93, loss: 0.661146
global_step: 11716, epoch: 93, loss: 0.641970
global_step: 11717, epoch: 93, loss: 0.744442
global_step: 11718, epoch: 93, loss: 0.645257
global_step: 11719, epoch: 93, loss: 0.660619
global_step: 11720, epoch: 93, loss: 0.531256
epoch: 93
train	acc: 0.8708	macro: p 0.8801, r 0.6601, f1: 0.6840	micro: p 0.8708, r 0.8708, f1 0.8708	weighted_f1:0.8552
dev	acc: 0.5428	macro: p 0.3444, r 0.3028, f1: 0.2989	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4920
test	acc: 0.5950	macro: p 0.5058, r 0.3191, f1: 0.3242	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5518
global_step: 11721, epoch: 94, loss: 0.773764
global_step: 11722, epoch: 94, loss: 0.651028
global_step: 11723, epoch: 94, loss: 0.724212
global_step: 11724, epoch: 94, loss: 0.555722
global_step: 11725, epoch: 94, loss: 0.666845
global_step: 11726, epoch: 94, loss: 0.747556
global_step: 11727, epoch: 94, loss: 0.709133
global_step: 11728, epoch: 94, loss: 0.652466
global_step: 11729, epoch: 94, loss: 0.623666
global_step: 11730, epoch: 94, loss: 0.632997
global_step: 11731, epoch: 94, loss: 0.535388
global_step: 11732, epoch: 94, loss: 0.644782
global_step: 11733, epoch: 94, loss: 0.699636
global_step: 11734, epoch: 94, loss: 0.604658
global_step: 11735, epoch: 94, loss: 0.711586
global_step: 11736, epoch: 94, loss: 0.581935
global_step: 11737, epoch: 94, loss: 0.674408
global_step: 11738, epoch: 94, loss: 0.638726
global_step: 11739, epoch: 94, loss: 0.655536
global_step: 11740, epoch: 94, loss: 0.688472
global_step: 11741, epoch: 94, loss: 0.794973
global_step: 11742, epoch: 94, loss: 0.612820
global_step: 11743, epoch: 94, loss: 0.747930
global_step: 11744, epoch: 94, loss: 0.604942
global_step: 11745, epoch: 94, loss: 0.660048
global_step: 11746, epoch: 94, loss: 0.683267
global_step: 11747, epoch: 94, loss: 0.503568
global_step: 11748, epoch: 94, loss: 0.773850
global_step: 11749, epoch: 94, loss: 0.710697
global_step: 11750, epoch: 94, loss: 0.603501
global_step: 11751, epoch: 94, loss: 0.820445
global_step: 11752, epoch: 94, loss: 0.567661
global_step: 11753, epoch: 94, loss: 0.651896
global_step: 11754, epoch: 94, loss: 0.614848
global_step: 11755, epoch: 94, loss: 0.617256
global_step: 11756, epoch: 94, loss: 0.682752
global_step: 11757, epoch: 94, loss: 0.639883
global_step: 11758, epoch: 94, loss: 0.701370
global_step: 11759, epoch: 94, loss: 0.656657
global_step: 11760, epoch: 94, loss: 0.635026
epoch: 94
train	acc: 0.8789	macro: p 0.8830, r 0.6803, f1: 0.7048	micro: p 0.8789, r 0.8789, f1 0.8789	weighted_f1:0.8652
dev	acc: 0.5401	macro: p 0.3312, r 0.3036, f1: 0.2982	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4921
test	acc: 0.5935	macro: p 0.5002, r 0.3235, f1: 0.3273	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5531
global_step: 11761, epoch: 95, loss: 0.673206
global_step: 11762, epoch: 95, loss: 0.574670
global_step: 11763, epoch: 95, loss: 0.659552
global_step: 11764, epoch: 95, loss: 0.691227
global_step: 11765, epoch: 95, loss: 0.659975
global_step: 11766, epoch: 95, loss: 0.603472
global_step: 11767, epoch: 95, loss: 0.636271
global_step: 11768, epoch: 95, loss: 0.651726
global_step: 11769, epoch: 95, loss: 0.647171
global_step: 11770, epoch: 95, loss: 0.708284
global_step: 11771, epoch: 95, loss: 0.659524
global_step: 11772, epoch: 95, loss: 0.554768
global_step: 11773, epoch: 95, loss: 0.653806
global_step: 11774, epoch: 95, loss: 0.688075
global_step: 11775, epoch: 95, loss: 0.581182
global_step: 11776, epoch: 95, loss: 0.628836
global_step: 11777, epoch: 95, loss: 0.681236
global_step: 11778, epoch: 95, loss: 0.541197
global_step: 11779, epoch: 95, loss: 0.554250
global_step: 11780, epoch: 95, loss: 0.623366
global_step: 11781, epoch: 95, loss: 0.666755
global_step: 11782, epoch: 95, loss: 0.570786
global_step: 11783, epoch: 95, loss: 0.609784
global_step: 11784, epoch: 95, loss: 0.636226
global_step: 11785, epoch: 95, loss: 0.643057
global_step: 11786, epoch: 95, loss: 0.664031
global_step: 11787, epoch: 95, loss: 0.656589
global_step: 11788, epoch: 95, loss: 0.705517
global_step: 11789, epoch: 95, loss: 0.688821
global_step: 11790, epoch: 95, loss: 0.675218
global_step: 11791, epoch: 95, loss: 0.676525
global_step: 11792, epoch: 95, loss: 0.715616
global_step: 11793, epoch: 95, loss: 0.617654
global_step: 11794, epoch: 95, loss: 0.658371
global_step: 11795, epoch: 95, loss: 0.561072
global_step: 11796, epoch: 95, loss: 0.788337
global_step: 11797, epoch: 95, loss: 0.631202
global_step: 11798, epoch: 95, loss: 0.575670
global_step: 11799, epoch: 95, loss: 0.618438
global_step: 11800, epoch: 95, loss: 0.239206
epoch: 95
train	acc: 0.8794	macro: p 0.8846, r 0.6786, f1: 0.7033	micro: p 0.8794, r 0.8794, f1 0.8794	weighted_f1:0.8655
dev	acc: 0.5401	macro: p 0.3262, r 0.3024, f1: 0.2969	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4910
test	acc: 0.5935	macro: p 0.5020, r 0.3216, f1: 0.3251	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5518
global_step: 11801, epoch: 96, loss: 0.577116
global_step: 11802, epoch: 96, loss: 0.571669
global_step: 11803, epoch: 96, loss: 0.682144
global_step: 11804, epoch: 96, loss: 0.590441
global_step: 11805, epoch: 96, loss: 0.643775
global_step: 11806, epoch: 96, loss: 0.715297
global_step: 11807, epoch: 96, loss: 0.608567
global_step: 11808, epoch: 96, loss: 0.521667
global_step: 11809, epoch: 96, loss: 0.609607
global_step: 11810, epoch: 96, loss: 0.673450
global_step: 11811, epoch: 96, loss: 0.705467
global_step: 11812, epoch: 96, loss: 0.735878
global_step: 11813, epoch: 96, loss: 0.692242
global_step: 11814, epoch: 96, loss: 0.707802
global_step: 11815, epoch: 96, loss: 0.607620
global_step: 11816, epoch: 96, loss: 0.713850
global_step: 11817, epoch: 96, loss: 0.646098
global_step: 11818, epoch: 96, loss: 0.574969
global_step: 11819, epoch: 96, loss: 0.648465
global_step: 11820, epoch: 96, loss: 0.631931
global_step: 11821, epoch: 96, loss: 0.616513
global_step: 11822, epoch: 96, loss: 0.561568
global_step: 11823, epoch: 96, loss: 0.561525
global_step: 11824, epoch: 96, loss: 0.674946
global_step: 11825, epoch: 96, loss: 0.587593
global_step: 11826, epoch: 96, loss: 0.657741
global_step: 11827, epoch: 96, loss: 0.702972
global_step: 11828, epoch: 96, loss: 0.611812
global_step: 11829, epoch: 96, loss: 0.687198
global_step: 11830, epoch: 96, loss: 0.620472
global_step: 11831, epoch: 96, loss: 0.558535
global_step: 11832, epoch: 96, loss: 0.651429
global_step: 11833, epoch: 96, loss: 0.677136
global_step: 11834, epoch: 96, loss: 0.726688
global_step: 11835, epoch: 96, loss: 0.737471
global_step: 11836, epoch: 96, loss: 0.654149
global_step: 11837, epoch: 96, loss: 0.752561
global_step: 11838, epoch: 96, loss: 0.650246
global_step: 11839, epoch: 96, loss: 0.657892
global_step: 11840, epoch: 96, loss: 0.230864
epoch: 96
train	acc: 0.8825	macro: p 0.8883, r 0.6905, f1: 0.7182	micro: p 0.8825, r 0.8825, f1 0.8825	weighted_f1:0.8704
dev	acc: 0.5428	macro: p 0.3331, r 0.3062, f1: 0.3022	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4953
test	acc: 0.5916	macro: p 0.4954, r 0.3215, f1: 0.3262	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5519
global_step: 11841, epoch: 97, loss: 0.705123
global_step: 11842, epoch: 97, loss: 0.565524
global_step: 11843, epoch: 97, loss: 0.589076
global_step: 11844, epoch: 97, loss: 0.603818
global_step: 11845, epoch: 97, loss: 0.601718
global_step: 11846, epoch: 97, loss: 0.706315
global_step: 11847, epoch: 97, loss: 0.617574
global_step: 11848, epoch: 97, loss: 0.730339
global_step: 11849, epoch: 97, loss: 0.665913
global_step: 11850, epoch: 97, loss: 0.541786
global_step: 11851, epoch: 97, loss: 0.619018
global_step: 11852, epoch: 97, loss: 0.707278
global_step: 11853, epoch: 97, loss: 0.638473
global_step: 11854, epoch: 97, loss: 0.696265
global_step: 11855, epoch: 97, loss: 0.556743
global_step: 11856, epoch: 97, loss: 0.717529
global_step: 11857, epoch: 97, loss: 0.664920
global_step: 11858, epoch: 97, loss: 0.605188
global_step: 11859, epoch: 97, loss: 0.646181
global_step: 11860, epoch: 97, loss: 0.606884
global_step: 11861, epoch: 97, loss: 0.574923
global_step: 11862, epoch: 97, loss: 0.690178
global_step: 11863, epoch: 97, loss: 0.595931
global_step: 11864, epoch: 97, loss: 0.687778
global_step: 11865, epoch: 97, loss: 0.705200
global_step: 11866, epoch: 97, loss: 0.724301
global_step: 11867, epoch: 97, loss: 0.654114
global_step: 11868, epoch: 97, loss: 0.574097
global_step: 11869, epoch: 97, loss: 0.571562
global_step: 11870, epoch: 97, loss: 0.694962
global_step: 11871, epoch: 97, loss: 0.678896
global_step: 11872, epoch: 97, loss: 0.579722
global_step: 11873, epoch: 97, loss: 0.586032
global_step: 11874, epoch: 97, loss: 0.714000
global_step: 11875, epoch: 97, loss: 0.716383
global_step: 11876, epoch: 97, loss: 0.659998
global_step: 11877, epoch: 97, loss: 0.699744
global_step: 11878, epoch: 97, loss: 0.663530
global_step: 11879, epoch: 97, loss: 0.634863
global_step: 11880, epoch: 97, loss: 0.914941
epoch: 97
train	acc: 0.8883	macro: p 0.8937, r 0.7037, f1: 0.7312	micro: p 0.8883, r 0.8883, f1 0.8883	weighted_f1:0.8776
dev	acc: 0.5392	macro: p 0.4027, r 0.3131, f1: 0.3103	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4987
test	acc: 0.5927	macro: p 0.5039, r 0.3318, f1: 0.3363	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5593
global_step: 11881, epoch: 98, loss: 0.673395
global_step: 11882, epoch: 98, loss: 0.632405
global_step: 11883, epoch: 98, loss: 0.502476
global_step: 11884, epoch: 98, loss: 0.564096
global_step: 11885, epoch: 98, loss: 0.590780
global_step: 11886, epoch: 98, loss: 0.646053
global_step: 11887, epoch: 98, loss: 0.672495
global_step: 11888, epoch: 98, loss: 0.558418
global_step: 11889, epoch: 98, loss: 0.596259
global_step: 11890, epoch: 98, loss: 0.624742
global_step: 11891, epoch: 98, loss: 0.628332
global_step: 11892, epoch: 98, loss: 0.633579
global_step: 11893, epoch: 98, loss: 0.634535
global_step: 11894, epoch: 98, loss: 0.612958
global_step: 11895, epoch: 98, loss: 0.549921
global_step: 11896, epoch: 98, loss: 0.533057
global_step: 11897, epoch: 98, loss: 0.689323
global_step: 11898, epoch: 98, loss: 0.597713
global_step: 11899, epoch: 98, loss: 0.648499
global_step: 11900, epoch: 98, loss: 0.673296
global_step: 11901, epoch: 98, loss: 0.583371
global_step: 11902, epoch: 98, loss: 0.648509
global_step: 11903, epoch: 98, loss: 0.692714
global_step: 11904, epoch: 98, loss: 0.647758
global_step: 11905, epoch: 98, loss: 0.601323
global_step: 11906, epoch: 98, loss: 0.596219
global_step: 11907, epoch: 98, loss: 0.732537
global_step: 11908, epoch: 98, loss: 0.630767
global_step: 11909, epoch: 98, loss: 0.628487
global_step: 11910, epoch: 98, loss: 0.627147
global_step: 11911, epoch: 98, loss: 0.744890
global_step: 11912, epoch: 98, loss: 0.601808
global_step: 11913, epoch: 98, loss: 0.661578
global_step: 11914, epoch: 98, loss: 0.677613
global_step: 11915, epoch: 98, loss: 0.628060
global_step: 11916, epoch: 98, loss: 0.656383
global_step: 11917, epoch: 98, loss: 0.619772
global_step: 11918, epoch: 98, loss: 0.660632
global_step: 11919, epoch: 98, loss: 0.648105
global_step: 11920, epoch: 98, loss: 0.691670
epoch: 98
train	acc: 0.8917	macro: p 0.8980, r 0.7133, f1: 0.7395	micro: p 0.8917, r 0.8917, f1 0.8917	weighted_f1:0.8811
dev	acc: 0.5338	macro: p 0.3879, r 0.3040, f1: 0.3021	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4893
test	acc: 0.5908	macro: p 0.4911, r 0.3278, f1: 0.3318	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5554
global_step: 11921, epoch: 99, loss: 0.698086
global_step: 11922, epoch: 99, loss: 0.633784
global_step: 11923, epoch: 99, loss: 0.631396
global_step: 11924, epoch: 99, loss: 0.593350
global_step: 11925, epoch: 99, loss: 0.710624
global_step: 11926, epoch: 99, loss: 0.597080
global_step: 11927, epoch: 99, loss: 0.626142
global_step: 11928, epoch: 99, loss: 0.589060
global_step: 11929, epoch: 99, loss: 0.671332
global_step: 11930, epoch: 99, loss: 0.651134
global_step: 11931, epoch: 99, loss: 0.644488
global_step: 11932, epoch: 99, loss: 0.701737
global_step: 11933, epoch: 99, loss: 0.552167
global_step: 11934, epoch: 99, loss: 0.561578
global_step: 11935, epoch: 99, loss: 0.649521
global_step: 11936, epoch: 99, loss: 0.616579
global_step: 11937, epoch: 99, loss: 0.623999
global_step: 11938, epoch: 99, loss: 0.555708
global_step: 11939, epoch: 99, loss: 0.566052
global_step: 11940, epoch: 99, loss: 0.536676
global_step: 11941, epoch: 99, loss: 0.691238
global_step: 11942, epoch: 99, loss: 0.606172
global_step: 11943, epoch: 99, loss: 0.675976
global_step: 11944, epoch: 99, loss: 0.626411
global_step: 11945, epoch: 99, loss: 0.699998
global_step: 11946, epoch: 99, loss: 0.644284
global_step: 11947, epoch: 99, loss: 0.644963
global_step: 11948, epoch: 99, loss: 0.605305
global_step: 11949, epoch: 99, loss: 0.605199
global_step: 11950, epoch: 99, loss: 0.496123
global_step: 11951, epoch: 99, loss: 0.687086
global_step: 11952, epoch: 99, loss: 0.562697
global_step: 11953, epoch: 99, loss: 0.703611
global_step: 11954, epoch: 99, loss: 0.533075
global_step: 11955, epoch: 99, loss: 0.598807
global_step: 11956, epoch: 99, loss: 0.633484
global_step: 11957, epoch: 99, loss: 0.676382
global_step: 11958, epoch: 99, loss: 0.718903
global_step: 11959, epoch: 99, loss: 0.621174
global_step: 11960, epoch: 99, loss: 0.635247
epoch: 99
train	acc: 0.8888	macro: p 0.8936, r 0.7056, f1: 0.7354	micro: p 0.8888, r 0.8888, f1 0.8888	weighted_f1:0.8778
dev	acc: 0.5392	macro: p 0.3944, r 0.3053, f1: 0.3034	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4920
test	acc: 0.5935	macro: p 0.4959, r 0.3226, f1: 0.3270	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5530
global_step: 11961, epoch: 100, loss: 0.632682
global_step: 11962, epoch: 100, loss: 0.638090
global_step: 11963, epoch: 100, loss: 0.586069
global_step: 11964, epoch: 100, loss: 0.568680
global_step: 11965, epoch: 100, loss: 0.566908
global_step: 11966, epoch: 100, loss: 0.625793
global_step: 11967, epoch: 100, loss: 0.546824
global_step: 11968, epoch: 100, loss: 0.633843
global_step: 11969, epoch: 100, loss: 0.706353
global_step: 11970, epoch: 100, loss: 0.709990
global_step: 11971, epoch: 100, loss: 0.632531
global_step: 11972, epoch: 100, loss: 0.550616
global_step: 11973, epoch: 100, loss: 0.716836
global_step: 11974, epoch: 100, loss: 0.586458
global_step: 11975, epoch: 100, loss: 0.627977
global_step: 11976, epoch: 100, loss: 0.535863
global_step: 11977, epoch: 100, loss: 0.634626
global_step: 11978, epoch: 100, loss: 0.594349
global_step: 11979, epoch: 100, loss: 0.573338
global_step: 11980, epoch: 100, loss: 0.625952
global_step: 11981, epoch: 100, loss: 0.597753
global_step: 11982, epoch: 100, loss: 0.578676
global_step: 11983, epoch: 100, loss: 0.696041
global_step: 11984, epoch: 100, loss: 0.724533
global_step: 11985, epoch: 100, loss: 0.663646
global_step: 11986, epoch: 100, loss: 0.626036
global_step: 11987, epoch: 100, loss: 0.630507
global_step: 11988, epoch: 100, loss: 0.593212
global_step: 11989, epoch: 100, loss: 0.568390
global_step: 11990, epoch: 100, loss: 0.626005
global_step: 11991, epoch: 100, loss: 0.605015
global_step: 11992, epoch: 100, loss: 0.626719
global_step: 11993, epoch: 100, loss: 0.625747
global_step: 11994, epoch: 100, loss: 0.679995
global_step: 11995, epoch: 100, loss: 0.589380
global_step: 11996, epoch: 100, loss: 0.659921
global_step: 11997, epoch: 100, loss: 0.682657
global_step: 11998, epoch: 100, loss: 0.624308
global_step: 11999, epoch: 100, loss: 0.628105
global_step: 12000, epoch: 100, loss: 1.130718
epoch: 100
train	acc: 0.8941	macro: p 0.8945, r 0.7184, f1: 0.7419	micro: p 0.8941, r 0.8941, f1 0.8941	weighted_f1:0.8839
dev	acc: 0.5374	macro: p 0.3937, r 0.3116, f1: 0.3111	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4987
test	acc: 0.5881	macro: p 0.4842, r 0.3290, f1: 0.3322	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5564
BEST MODEL epoch: 64
train	acc: 0.7869 macro_p: 0.6815 macro_r: 0.5295 macro_f1: 0.5299 micro_p: 0.7869 micro_r: 0.7869 micro_f1: 0.7869 weighted_f1: 0.7610
dev	acc: 0.5555 macro_p: 0.3560 macro_r: 0.3195 macro_f1: 0.3163 micro_p: 0.5555 micro_r: 0.5555 micro_f1: 0.5555 weighted_f1: 0.5092
test	acc: 0.5954 macro_p: 0.3608 macro_r: 0.3237 macro_f1: 0.3243 micro_p: 0.5954 micro_r: 0.5954 micro_f1: 0.5954 weighted_f1: 0.5557
==========ROUND 4==========
global_step: 12001, epoch: 1, loss: 1.887855
global_step: 12002, epoch: 1, loss: 1.901174
global_step: 12003, epoch: 1, loss: 1.859878
global_step: 12004, epoch: 1, loss: 1.815027
global_step: 12005, epoch: 1, loss: 1.802042
global_step: 12006, epoch: 1, loss: 1.827910
global_step: 12007, epoch: 1, loss: 1.780854
global_step: 12008, epoch: 1, loss: 1.782332
global_step: 12009, epoch: 1, loss: 1.726051
global_step: 12010, epoch: 1, loss: 1.761863
global_step: 12011, epoch: 1, loss: 1.709126
global_step: 12012, epoch: 1, loss: 1.752063
global_step: 12013, epoch: 1, loss: 1.659621
global_step: 12014, epoch: 1, loss: 1.680508
global_step: 12015, epoch: 1, loss: 1.667753
global_step: 12016, epoch: 1, loss: 1.644394
global_step: 12017, epoch: 1, loss: 1.771147
global_step: 12018, epoch: 1, loss: 1.629709
global_step: 12019, epoch: 1, loss: 1.630461
global_step: 12020, epoch: 1, loss: 1.611417
global_step: 12021, epoch: 1, loss: 1.563107
global_step: 12022, epoch: 1, loss: 1.618176
global_step: 12023, epoch: 1, loss: 1.596749
global_step: 12024, epoch: 1, loss: 1.561514
global_step: 12025, epoch: 1, loss: 1.718873
global_step: 12026, epoch: 1, loss: 1.714223
global_step: 12027, epoch: 1, loss: 1.579198
global_step: 12028, epoch: 1, loss: 1.585879
global_step: 12029, epoch: 1, loss: 1.590278
global_step: 12030, epoch: 1, loss: 1.641364
global_step: 12031, epoch: 1, loss: 1.579189
global_step: 12032, epoch: 1, loss: 1.594140
global_step: 12033, epoch: 1, loss: 1.591520
global_step: 12034, epoch: 1, loss: 1.581264
global_step: 12035, epoch: 1, loss: 1.565953
global_step: 12036, epoch: 1, loss: 1.581585
global_step: 12037, epoch: 1, loss: 1.581751
global_step: 12038, epoch: 1, loss: 1.640117
global_step: 12039, epoch: 1, loss: 1.550512
global_step: 12040, epoch: 1, loss: 1.273750
epoch: 1
train	acc: 0.4935	macro: p 0.1346, r 0.1643, f1: 0.1287	micro: p 0.4935, r 0.4935, f1 0.4935	weighted_f1:0.3535
dev	acc: 0.4482	macro: p 0.1197, r 0.1682, f1: 0.1245	micro: p 0.4482, r 0.4482, f1 0.4482	weighted_f1:0.3003
test	acc: 0.5073	macro: p 0.1384, r 0.1714, f1: 0.1378	micro: p 0.5073, r 0.5073, f1 0.5073	weighted_f1:0.3689
New best model!
global_step: 12041, epoch: 2, loss: 1.486696
global_step: 12042, epoch: 2, loss: 1.473023
global_step: 12043, epoch: 2, loss: 1.457382
global_step: 12044, epoch: 2, loss: 1.544384
global_step: 12045, epoch: 2, loss: 1.517226
global_step: 12046, epoch: 2, loss: 1.471433
global_step: 12047, epoch: 2, loss: 1.538657
global_step: 12048, epoch: 2, loss: 1.523807
global_step: 12049, epoch: 2, loss: 1.559820
global_step: 12050, epoch: 2, loss: 1.543576
global_step: 12051, epoch: 2, loss: 1.612725
global_step: 12052, epoch: 2, loss: 1.623281
global_step: 12053, epoch: 2, loss: 1.529011
global_step: 12054, epoch: 2, loss: 1.674214
global_step: 12055, epoch: 2, loss: 1.595037
global_step: 12056, epoch: 2, loss: 1.475108
global_step: 12057, epoch: 2, loss: 1.536654
global_step: 12058, epoch: 2, loss: 1.482587
global_step: 12059, epoch: 2, loss: 1.510984
global_step: 12060, epoch: 2, loss: 1.478374
global_step: 12061, epoch: 2, loss: 1.536909
global_step: 12062, epoch: 2, loss: 1.484885
global_step: 12063, epoch: 2, loss: 1.548249
global_step: 12064, epoch: 2, loss: 1.479907
global_step: 12065, epoch: 2, loss: 1.518623
global_step: 12066, epoch: 2, loss: 1.480546
global_step: 12067, epoch: 2, loss: 1.484842
global_step: 12068, epoch: 2, loss: 1.507437
global_step: 12069, epoch: 2, loss: 1.493142
global_step: 12070, epoch: 2, loss: 1.524599
global_step: 12071, epoch: 2, loss: 1.483024
global_step: 12072, epoch: 2, loss: 1.470964
global_step: 12073, epoch: 2, loss: 1.461837
global_step: 12074, epoch: 2, loss: 1.408529
global_step: 12075, epoch: 2, loss: 1.498371
global_step: 12076, epoch: 2, loss: 1.444362
global_step: 12077, epoch: 2, loss: 1.508470
global_step: 12078, epoch: 2, loss: 1.384874
global_step: 12079, epoch: 2, loss: 1.358063
global_step: 12080, epoch: 2, loss: 1.187570
epoch: 2
train	acc: 0.5178	macro: p 0.2353, r 0.1874, f1: 0.1546	micro: p 0.5178, r 0.5178, f1 0.5178	weighted_f1:0.3923
dev	acc: 0.4635	macro: p 0.2096, r 0.1862, f1: 0.1412	micro: p 0.4635, r 0.4635, f1 0.4635	weighted_f1:0.3256
test	acc: 0.5211	macro: p 0.2354, r 0.1868, f1: 0.1510	micro: p 0.5211, r 0.5211, f1 0.5211	weighted_f1:0.3920
New best model!
global_step: 12081, epoch: 3, loss: 1.455776
global_step: 12082, epoch: 3, loss: 1.419314
global_step: 12083, epoch: 3, loss: 1.484074
global_step: 12084, epoch: 3, loss: 1.426826
global_step: 12085, epoch: 3, loss: 1.417152
global_step: 12086, epoch: 3, loss: 1.463893
global_step: 12087, epoch: 3, loss: 1.463943
global_step: 12088, epoch: 3, loss: 1.376394
global_step: 12089, epoch: 3, loss: 1.483512
global_step: 12090, epoch: 3, loss: 1.504900
global_step: 12091, epoch: 3, loss: 1.464978
global_step: 12092, epoch: 3, loss: 1.538704
global_step: 12093, epoch: 3, loss: 1.430249
global_step: 12094, epoch: 3, loss: 1.426603
global_step: 12095, epoch: 3, loss: 1.438343
global_step: 12096, epoch: 3, loss: 1.487180
global_step: 12097, epoch: 3, loss: 1.426293
global_step: 12098, epoch: 3, loss: 1.341768
global_step: 12099, epoch: 3, loss: 1.457625
global_step: 12100, epoch: 3, loss: 1.481475
global_step: 12101, epoch: 3, loss: 1.509713
global_step: 12102, epoch: 3, loss: 1.389502
global_step: 12103, epoch: 3, loss: 1.415499
global_step: 12104, epoch: 3, loss: 1.563383
global_step: 12105, epoch: 3, loss: 1.464174
global_step: 12106, epoch: 3, loss: 1.304899
global_step: 12107, epoch: 3, loss: 1.356296
global_step: 12108, epoch: 3, loss: 1.447991
global_step: 12109, epoch: 3, loss: 1.367545
global_step: 12110, epoch: 3, loss: 1.472716
global_step: 12111, epoch: 3, loss: 1.458086
global_step: 12112, epoch: 3, loss: 1.547233
global_step: 12113, epoch: 3, loss: 1.395025
global_step: 12114, epoch: 3, loss: 1.344828
global_step: 12115, epoch: 3, loss: 1.455784
global_step: 12116, epoch: 3, loss: 1.457743
global_step: 12117, epoch: 3, loss: 1.449033
global_step: 12118, epoch: 3, loss: 1.460817
global_step: 12119, epoch: 3, loss: 1.456689
global_step: 12120, epoch: 3, loss: 0.705001
epoch: 3
train	acc: 0.5464	macro: p 0.2380, r 0.2184, f1: 0.1934	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4398
dev	acc: 0.4959	macro: p 0.2340, r 0.2233, f1: 0.1873	micro: p 0.4959, r 0.4959, f1 0.4959	weighted_f1:0.3812
test	acc: 0.5521	macro: p 0.2355, r 0.2247, f1: 0.1982	micro: p 0.5521, r 0.5521, f1 0.5521	weighted_f1:0.4430
New best model!
global_step: 12121, epoch: 4, loss: 1.412975
global_step: 12122, epoch: 4, loss: 1.442205
global_step: 12123, epoch: 4, loss: 1.353415
global_step: 12124, epoch: 4, loss: 1.356269
global_step: 12125, epoch: 4, loss: 1.394837
global_step: 12126, epoch: 4, loss: 1.404098
global_step: 12127, epoch: 4, loss: 1.505714
global_step: 12128, epoch: 4, loss: 1.478636
global_step: 12129, epoch: 4, loss: 1.438752
global_step: 12130, epoch: 4, loss: 1.309294
global_step: 12131, epoch: 4, loss: 1.373067
global_step: 12132, epoch: 4, loss: 1.481375
global_step: 12133, epoch: 4, loss: 1.442393
global_step: 12134, epoch: 4, loss: 1.405251
global_step: 12135, epoch: 4, loss: 1.470746
global_step: 12136, epoch: 4, loss: 1.479720
global_step: 12137, epoch: 4, loss: 1.327179
global_step: 12138, epoch: 4, loss: 1.381289
global_step: 12139, epoch: 4, loss: 1.458107
global_step: 12140, epoch: 4, loss: 1.455198
global_step: 12141, epoch: 4, loss: 1.376396
global_step: 12142, epoch: 4, loss: 1.400896
global_step: 12143, epoch: 4, loss: 1.421056
global_step: 12144, epoch: 4, loss: 1.440878
global_step: 12145, epoch: 4, loss: 1.435031
global_step: 12146, epoch: 4, loss: 1.437482
global_step: 12147, epoch: 4, loss: 1.439481
global_step: 12148, epoch: 4, loss: 1.418093
global_step: 12149, epoch: 4, loss: 1.429535
global_step: 12150, epoch: 4, loss: 1.484072
global_step: 12151, epoch: 4, loss: 1.400709
global_step: 12152, epoch: 4, loss: 1.331798
global_step: 12153, epoch: 4, loss: 1.407988
global_step: 12154, epoch: 4, loss: 1.350947
global_step: 12155, epoch: 4, loss: 1.281824
global_step: 12156, epoch: 4, loss: 1.400440
global_step: 12157, epoch: 4, loss: 1.429885
global_step: 12158, epoch: 4, loss: 1.459766
global_step: 12159, epoch: 4, loss: 1.328750
global_step: 12160, epoch: 4, loss: 1.528107
epoch: 4
train	acc: 0.5524	macro: p 0.3447, r 0.2280, f1: 0.2037	micro: p 0.5524, r 0.5524, f1 0.5524	weighted_f1:0.4529
dev	acc: 0.5068	macro: p 0.2233, r 0.2373, f1: 0.2014	micro: p 0.5068, r 0.5068, f1 0.5068	weighted_f1:0.3981
test	acc: 0.5586	macro: p 0.3636, r 0.2359, f1: 0.2082	micro: p 0.5586, r 0.5586, f1 0.5586	weighted_f1:0.4561
New best model!
global_step: 12161, epoch: 5, loss: 1.309102
global_step: 12162, epoch: 5, loss: 1.380670
global_step: 12163, epoch: 5, loss: 1.364467
global_step: 12164, epoch: 5, loss: 1.454165
global_step: 12165, epoch: 5, loss: 1.488512
global_step: 12166, epoch: 5, loss: 1.372876
global_step: 12167, epoch: 5, loss: 1.476812
global_step: 12168, epoch: 5, loss: 1.279339
global_step: 12169, epoch: 5, loss: 1.457039
global_step: 12170, epoch: 5, loss: 1.348558
global_step: 12171, epoch: 5, loss: 1.402109
global_step: 12172, epoch: 5, loss: 1.494324
global_step: 12173, epoch: 5, loss: 1.411271
global_step: 12174, epoch: 5, loss: 1.281296
global_step: 12175, epoch: 5, loss: 1.404820
global_step: 12176, epoch: 5, loss: 1.304992
global_step: 12177, epoch: 5, loss: 1.420444
global_step: 12178, epoch: 5, loss: 1.432513
global_step: 12179, epoch: 5, loss: 1.474653
global_step: 12180, epoch: 5, loss: 1.421698
global_step: 12181, epoch: 5, loss: 1.344063
global_step: 12182, epoch: 5, loss: 1.353462
global_step: 12183, epoch: 5, loss: 1.374431
global_step: 12184, epoch: 5, loss: 1.263551
global_step: 12185, epoch: 5, loss: 1.455887
global_step: 12186, epoch: 5, loss: 1.398770
global_step: 12187, epoch: 5, loss: 1.280710
global_step: 12188, epoch: 5, loss: 1.344418
global_step: 12189, epoch: 5, loss: 1.345500
global_step: 12190, epoch: 5, loss: 1.447886
global_step: 12191, epoch: 5, loss: 1.406311
global_step: 12192, epoch: 5, loss: 1.363074
global_step: 12193, epoch: 5, loss: 1.439149
global_step: 12194, epoch: 5, loss: 1.393594
global_step: 12195, epoch: 5, loss: 1.470794
global_step: 12196, epoch: 5, loss: 1.416375
global_step: 12197, epoch: 5, loss: 1.418203
global_step: 12198, epoch: 5, loss: 1.390844
global_step: 12199, epoch: 5, loss: 1.426634
global_step: 12200, epoch: 5, loss: 1.193650
epoch: 5
train	acc: 0.5606	macro: p 0.2838, r 0.2433, f1: 0.2197	micro: p 0.5606, r 0.5606, f1 0.5606	weighted_f1:0.4715
dev	acc: 0.5140	macro: p 0.1981, r 0.2511, f1: 0.2131	micro: p 0.5140, r 0.5140, f1 0.5140	weighted_f1:0.4123
test	acc: 0.5655	macro: p 0.2756, r 0.2540, f1: 0.2261	micro: p 0.5655, r 0.5655, f1 0.5655	weighted_f1:0.4745
New best model!
global_step: 12201, epoch: 6, loss: 1.447336
global_step: 12202, epoch: 6, loss: 1.361758
global_step: 12203, epoch: 6, loss: 1.363820
global_step: 12204, epoch: 6, loss: 1.342307
global_step: 12205, epoch: 6, loss: 1.399894
global_step: 12206, epoch: 6, loss: 1.406404
global_step: 12207, epoch: 6, loss: 1.366822
global_step: 12208, epoch: 6, loss: 1.411414
global_step: 12209, epoch: 6, loss: 1.395746
global_step: 12210, epoch: 6, loss: 1.296951
global_step: 12211, epoch: 6, loss: 1.370790
global_step: 12212, epoch: 6, loss: 1.452881
global_step: 12213, epoch: 6, loss: 1.490628
global_step: 12214, epoch: 6, loss: 1.376861
global_step: 12215, epoch: 6, loss: 1.393380
global_step: 12216, epoch: 6, loss: 1.365322
global_step: 12217, epoch: 6, loss: 1.339226
global_step: 12218, epoch: 6, loss: 1.352369
global_step: 12219, epoch: 6, loss: 1.402028
global_step: 12220, epoch: 6, loss: 1.368048
global_step: 12221, epoch: 6, loss: 1.331650
global_step: 12222, epoch: 6, loss: 1.326800
global_step: 12223, epoch: 6, loss: 1.345455
global_step: 12224, epoch: 6, loss: 1.415554
global_step: 12225, epoch: 6, loss: 1.401471
global_step: 12226, epoch: 6, loss: 1.279881
global_step: 12227, epoch: 6, loss: 1.339941
global_step: 12228, epoch: 6, loss: 1.377954
global_step: 12229, epoch: 6, loss: 1.356751
global_step: 12230, epoch: 6, loss: 1.427678
global_step: 12231, epoch: 6, loss: 1.257931
global_step: 12232, epoch: 6, loss: 1.312273
global_step: 12233, epoch: 6, loss: 1.391808
global_step: 12234, epoch: 6, loss: 1.338704
global_step: 12235, epoch: 6, loss: 1.322043
global_step: 12236, epoch: 6, loss: 1.355218
global_step: 12237, epoch: 6, loss: 1.392004
global_step: 12238, epoch: 6, loss: 1.389973
global_step: 12239, epoch: 6, loss: 1.361574
global_step: 12240, epoch: 6, loss: 1.318761
epoch: 6
train	acc: 0.5657	macro: p 0.3067, r 0.2476, f1: 0.2289	micro: p 0.5657, r 0.5657, f1 0.5657	weighted_f1:0.4796
dev	acc: 0.5149	macro: p 0.2481, r 0.2511, f1: 0.2119	micro: p 0.5149, r 0.5149, f1 0.5149	weighted_f1:0.4121
test	acc: 0.5678	macro: p 0.2997, r 0.2546, f1: 0.2326	micro: p 0.5678, r 0.5678, f1 0.5678	weighted_f1:0.4822
global_step: 12241, epoch: 7, loss: 1.315978
global_step: 12242, epoch: 7, loss: 1.303529
global_step: 12243, epoch: 7, loss: 1.339683
global_step: 12244, epoch: 7, loss: 1.451944
global_step: 12245, epoch: 7, loss: 1.347368
global_step: 12246, epoch: 7, loss: 1.425852
global_step: 12247, epoch: 7, loss: 1.354760
global_step: 12248, epoch: 7, loss: 1.200787
global_step: 12249, epoch: 7, loss: 1.477426
global_step: 12250, epoch: 7, loss: 1.283909
global_step: 12251, epoch: 7, loss: 1.400187
global_step: 12252, epoch: 7, loss: 1.277226
global_step: 12253, epoch: 7, loss: 1.420197
global_step: 12254, epoch: 7, loss: 1.305574
global_step: 12255, epoch: 7, loss: 1.413381
global_step: 12256, epoch: 7, loss: 1.451293
global_step: 12257, epoch: 7, loss: 1.475610
global_step: 12258, epoch: 7, loss: 1.436783
global_step: 12259, epoch: 7, loss: 1.387135
global_step: 12260, epoch: 7, loss: 1.341453
global_step: 12261, epoch: 7, loss: 1.305191
global_step: 12262, epoch: 7, loss: 1.431510
global_step: 12263, epoch: 7, loss: 1.330209
global_step: 12264, epoch: 7, loss: 1.333633
global_step: 12265, epoch: 7, loss: 1.381905
global_step: 12266, epoch: 7, loss: 1.388675
global_step: 12267, epoch: 7, loss: 1.446074
global_step: 12268, epoch: 7, loss: 1.392194
global_step: 12269, epoch: 7, loss: 1.404710
global_step: 12270, epoch: 7, loss: 1.401711
global_step: 12271, epoch: 7, loss: 1.235435
global_step: 12272, epoch: 7, loss: 1.262500
global_step: 12273, epoch: 7, loss: 1.295452
global_step: 12274, epoch: 7, loss: 1.290223
global_step: 12275, epoch: 7, loss: 1.315543
global_step: 12276, epoch: 7, loss: 1.403287
global_step: 12277, epoch: 7, loss: 1.367581
global_step: 12278, epoch: 7, loss: 1.374737
global_step: 12279, epoch: 7, loss: 1.297569
global_step: 12280, epoch: 7, loss: 1.452476
epoch: 7
train	acc: 0.5726	macro: p 0.4468, r 0.2575, f1: 0.2480	micro: p 0.5726, r 0.5726, f1 0.5726	weighted_f1:0.4946
dev	acc: 0.5221	macro: p 0.2850, r 0.2593, f1: 0.2341	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4324
test	acc: 0.5713	macro: p 0.2822, r 0.2589, f1: 0.2434	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.4917
New best model!
global_step: 12281, epoch: 8, loss: 1.422224
global_step: 12282, epoch: 8, loss: 1.335573
global_step: 12283, epoch: 8, loss: 1.300937
global_step: 12284, epoch: 8, loss: 1.338034
global_step: 12285, epoch: 8, loss: 1.428065
global_step: 12286, epoch: 8, loss: 1.361473
global_step: 12287, epoch: 8, loss: 1.291351
global_step: 12288, epoch: 8, loss: 1.533851
global_step: 12289, epoch: 8, loss: 1.386360
global_step: 12290, epoch: 8, loss: 1.506050
global_step: 12291, epoch: 8, loss: 1.296389
global_step: 12292, epoch: 8, loss: 1.362629
global_step: 12293, epoch: 8, loss: 1.382976
global_step: 12294, epoch: 8, loss: 1.251929
global_step: 12295, epoch: 8, loss: 1.351309
global_step: 12296, epoch: 8, loss: 1.360586
global_step: 12297, epoch: 8, loss: 1.287356
global_step: 12298, epoch: 8, loss: 1.280637
global_step: 12299, epoch: 8, loss: 1.236222
global_step: 12300, epoch: 8, loss: 1.349679
global_step: 12301, epoch: 8, loss: 1.279219
global_step: 12302, epoch: 8, loss: 1.389877
global_step: 12303, epoch: 8, loss: 1.290418
global_step: 12304, epoch: 8, loss: 1.268142
global_step: 12305, epoch: 8, loss: 1.370452
global_step: 12306, epoch: 8, loss: 1.305571
global_step: 12307, epoch: 8, loss: 1.386826
global_step: 12308, epoch: 8, loss: 1.375119
global_step: 12309, epoch: 8, loss: 1.312394
global_step: 12310, epoch: 8, loss: 1.257298
global_step: 12311, epoch: 8, loss: 1.357813
global_step: 12312, epoch: 8, loss: 1.368295
global_step: 12313, epoch: 8, loss: 1.292327
global_step: 12314, epoch: 8, loss: 1.348496
global_step: 12315, epoch: 8, loss: 1.400444
global_step: 12316, epoch: 8, loss: 1.387790
global_step: 12317, epoch: 8, loss: 1.428160
global_step: 12318, epoch: 8, loss: 1.393229
global_step: 12319, epoch: 8, loss: 1.340188
global_step: 12320, epoch: 8, loss: 1.614939
epoch: 8
train	acc: 0.5787	macro: p 0.4522, r 0.2665, f1: 0.2590	micro: p 0.5787, r 0.5787, f1 0.5787	weighted_f1:0.5054
dev	acc: 0.5266	macro: p 0.2828, r 0.2644, f1: 0.2400	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4395
test	acc: 0.5728	macro: p 0.2858, r 0.2618, f1: 0.2469	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.4954
New best model!
global_step: 12321, epoch: 9, loss: 1.241793
global_step: 12322, epoch: 9, loss: 1.181957
global_step: 12323, epoch: 9, loss: 1.395579
global_step: 12324, epoch: 9, loss: 1.327821
global_step: 12325, epoch: 9, loss: 1.464313
global_step: 12326, epoch: 9, loss: 1.369437
global_step: 12327, epoch: 9, loss: 1.290519
global_step: 12328, epoch: 9, loss: 1.271473
global_step: 12329, epoch: 9, loss: 1.323480
global_step: 12330, epoch: 9, loss: 1.397412
global_step: 12331, epoch: 9, loss: 1.196290
global_step: 12332, epoch: 9, loss: 1.207575
global_step: 12333, epoch: 9, loss: 1.378067
global_step: 12334, epoch: 9, loss: 1.266911
global_step: 12335, epoch: 9, loss: 1.328823
global_step: 12336, epoch: 9, loss: 1.319068
global_step: 12337, epoch: 9, loss: 1.380756
global_step: 12338, epoch: 9, loss: 1.339347
global_step: 12339, epoch: 9, loss: 1.343496
global_step: 12340, epoch: 9, loss: 1.307859
global_step: 12341, epoch: 9, loss: 1.450784
global_step: 12342, epoch: 9, loss: 1.312303
global_step: 12343, epoch: 9, loss: 1.328340
global_step: 12344, epoch: 9, loss: 1.325825
global_step: 12345, epoch: 9, loss: 1.356377
global_step: 12346, epoch: 9, loss: 1.238147
global_step: 12347, epoch: 9, loss: 1.425363
global_step: 12348, epoch: 9, loss: 1.329203
global_step: 12349, epoch: 9, loss: 1.425756
global_step: 12350, epoch: 9, loss: 1.278139
global_step: 12351, epoch: 9, loss: 1.432949
global_step: 12352, epoch: 9, loss: 1.294896
global_step: 12353, epoch: 9, loss: 1.396932
global_step: 12354, epoch: 9, loss: 1.302594
global_step: 12355, epoch: 9, loss: 1.317092
global_step: 12356, epoch: 9, loss: 1.423584
global_step: 12357, epoch: 9, loss: 1.464481
global_step: 12358, epoch: 9, loss: 1.386581
global_step: 12359, epoch: 9, loss: 1.315665
global_step: 12360, epoch: 9, loss: 0.994672
epoch: 9
train	acc: 0.5827	macro: p 0.4526, r 0.2713, f1: 0.2672	micro: p 0.5827, r 0.5827, f1 0.5827	weighted_f1:0.5119
dev	acc: 0.5275	macro: p 0.2798, r 0.2645, f1: 0.2455	micro: p 0.5275, r 0.5275, f1 0.5275	weighted_f1:0.4444
test	acc: 0.5751	macro: p 0.2862, r 0.2643, f1: 0.2530	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.5004
New best model!
global_step: 12361, epoch: 10, loss: 1.336489
global_step: 12362, epoch: 10, loss: 1.276928
global_step: 12363, epoch: 10, loss: 1.333927
global_step: 12364, epoch: 10, loss: 1.295006
global_step: 12365, epoch: 10, loss: 1.278908
global_step: 12366, epoch: 10, loss: 1.340405
global_step: 12367, epoch: 10, loss: 1.352333
global_step: 12368, epoch: 10, loss: 1.292821
global_step: 12369, epoch: 10, loss: 1.353259
global_step: 12370, epoch: 10, loss: 1.318813
global_step: 12371, epoch: 10, loss: 1.326494
global_step: 12372, epoch: 10, loss: 1.229480
global_step: 12373, epoch: 10, loss: 1.316102
global_step: 12374, epoch: 10, loss: 1.328170
global_step: 12375, epoch: 10, loss: 1.289827
global_step: 12376, epoch: 10, loss: 1.359770
global_step: 12377, epoch: 10, loss: 1.265017
global_step: 12378, epoch: 10, loss: 1.269163
global_step: 12379, epoch: 10, loss: 1.276718
global_step: 12380, epoch: 10, loss: 1.274676
global_step: 12381, epoch: 10, loss: 1.347113
global_step: 12382, epoch: 10, loss: 1.388112
global_step: 12383, epoch: 10, loss: 1.322584
global_step: 12384, epoch: 10, loss: 1.295118
global_step: 12385, epoch: 10, loss: 1.453473
global_step: 12386, epoch: 10, loss: 1.333807
global_step: 12387, epoch: 10, loss: 1.323847
global_step: 12388, epoch: 10, loss: 1.346400
global_step: 12389, epoch: 10, loss: 1.352883
global_step: 12390, epoch: 10, loss: 1.460713
global_step: 12391, epoch: 10, loss: 1.408350
global_step: 12392, epoch: 10, loss: 1.266429
global_step: 12393, epoch: 10, loss: 1.279085
global_step: 12394, epoch: 10, loss: 1.306346
global_step: 12395, epoch: 10, loss: 1.308537
global_step: 12396, epoch: 10, loss: 1.321526
global_step: 12397, epoch: 10, loss: 1.336009
global_step: 12398, epoch: 10, loss: 1.260640
global_step: 12399, epoch: 10, loss: 1.360885
global_step: 12400, epoch: 10, loss: 1.615697
epoch: 10
train	acc: 0.5858	macro: p 0.4517, r 0.2780, f1: 0.2754	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5189
dev	acc: 0.5302	macro: p 0.2787, r 0.2682, f1: 0.2523	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4515
test	acc: 0.5797	macro: p 0.2884, r 0.2704, f1: 0.2612	micro: p 0.5797, r 0.5797, f1 0.5797	weighted_f1:0.5088
New best model!
global_step: 12401, epoch: 11, loss: 1.378402
global_step: 12402, epoch: 11, loss: 1.249568
global_step: 12403, epoch: 11, loss: 1.354990
global_step: 12404, epoch: 11, loss: 1.182897
global_step: 12405, epoch: 11, loss: 1.378121
global_step: 12406, epoch: 11, loss: 1.283939
global_step: 12407, epoch: 11, loss: 1.297999
global_step: 12408, epoch: 11, loss: 1.302343
global_step: 12409, epoch: 11, loss: 1.263016
global_step: 12410, epoch: 11, loss: 1.452909
global_step: 12411, epoch: 11, loss: 1.308175
global_step: 12412, epoch: 11, loss: 1.226521
global_step: 12413, epoch: 11, loss: 1.340022
global_step: 12414, epoch: 11, loss: 1.326448
global_step: 12415, epoch: 11, loss: 1.304033
global_step: 12416, epoch: 11, loss: 1.290369
global_step: 12417, epoch: 11, loss: 1.332143
global_step: 12418, epoch: 11, loss: 1.308813
global_step: 12419, epoch: 11, loss: 1.326169
global_step: 12420, epoch: 11, loss: 1.310326
global_step: 12421, epoch: 11, loss: 1.338418
global_step: 12422, epoch: 11, loss: 1.280876
global_step: 12423, epoch: 11, loss: 1.397198
global_step: 12424, epoch: 11, loss: 1.339919
global_step: 12425, epoch: 11, loss: 1.299468
global_step: 12426, epoch: 11, loss: 1.369388
global_step: 12427, epoch: 11, loss: 1.435654
global_step: 12428, epoch: 11, loss: 1.302855
global_step: 12429, epoch: 11, loss: 1.246444
global_step: 12430, epoch: 11, loss: 1.246258
global_step: 12431, epoch: 11, loss: 1.232710
global_step: 12432, epoch: 11, loss: 1.234124
global_step: 12433, epoch: 11, loss: 1.289101
global_step: 12434, epoch: 11, loss: 1.220403
global_step: 12435, epoch: 11, loss: 1.338156
global_step: 12436, epoch: 11, loss: 1.227825
global_step: 12437, epoch: 11, loss: 1.444693
global_step: 12438, epoch: 11, loss: 1.389511
global_step: 12439, epoch: 11, loss: 1.432065
global_step: 12440, epoch: 11, loss: 1.938827
epoch: 11
train	acc: 0.5864	macro: p 0.4592, r 0.2794, f1: 0.2770	micro: p 0.5864, r 0.5864, f1 0.5864	weighted_f1:0.5201
dev	acc: 0.5302	macro: p 0.2831, r 0.2684, f1: 0.2508	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4502
test	acc: 0.5808	macro: p 0.2953, r 0.2714, f1: 0.2625	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5106
global_step: 12441, epoch: 12, loss: 1.337621
global_step: 12442, epoch: 12, loss: 1.265232
global_step: 12443, epoch: 12, loss: 1.309961
global_step: 12444, epoch: 12, loss: 1.340822
global_step: 12445, epoch: 12, loss: 1.228300
global_step: 12446, epoch: 12, loss: 1.294233
global_step: 12447, epoch: 12, loss: 1.381150
global_step: 12448, epoch: 12, loss: 1.294640
global_step: 12449, epoch: 12, loss: 1.242377
global_step: 12450, epoch: 12, loss: 1.464373
global_step: 12451, epoch: 12, loss: 1.346703
global_step: 12452, epoch: 12, loss: 1.236698
global_step: 12453, epoch: 12, loss: 1.285498
global_step: 12454, epoch: 12, loss: 1.302498
global_step: 12455, epoch: 12, loss: 1.222587
global_step: 12456, epoch: 12, loss: 1.380276
global_step: 12457, epoch: 12, loss: 1.396400
global_step: 12458, epoch: 12, loss: 1.292291
global_step: 12459, epoch: 12, loss: 1.211941
global_step: 12460, epoch: 12, loss: 1.252214
global_step: 12461, epoch: 12, loss: 1.240037
global_step: 12462, epoch: 12, loss: 1.324453
global_step: 12463, epoch: 12, loss: 1.311935
global_step: 12464, epoch: 12, loss: 1.449972
global_step: 12465, epoch: 12, loss: 1.233373
global_step: 12466, epoch: 12, loss: 1.416651
global_step: 12467, epoch: 12, loss: 1.325084
global_step: 12468, epoch: 12, loss: 1.245656
global_step: 12469, epoch: 12, loss: 1.357717
global_step: 12470, epoch: 12, loss: 1.334144
global_step: 12471, epoch: 12, loss: 1.354160
global_step: 12472, epoch: 12, loss: 1.293998
global_step: 12473, epoch: 12, loss: 1.267408
global_step: 12474, epoch: 12, loss: 1.260859
global_step: 12475, epoch: 12, loss: 1.249006
global_step: 12476, epoch: 12, loss: 1.293066
global_step: 12477, epoch: 12, loss: 1.257456
global_step: 12478, epoch: 12, loss: 1.164736
global_step: 12479, epoch: 12, loss: 1.267407
global_step: 12480, epoch: 12, loss: 2.156125
epoch: 12
train	acc: 0.5882	macro: p 0.4617, r 0.2785, f1: 0.2749	micro: p 0.5882, r 0.5882, f1 0.5882	weighted_f1:0.5197
dev	acc: 0.5293	macro: p 0.2841, r 0.2667, f1: 0.2450	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4449
test	acc: 0.5766	macro: p 0.2873, r 0.2673, f1: 0.2546	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5028
global_step: 12481, epoch: 13, loss: 1.250721
global_step: 12482, epoch: 13, loss: 1.292610
global_step: 12483, epoch: 13, loss: 1.242775
global_step: 12484, epoch: 13, loss: 1.308541
global_step: 12485, epoch: 13, loss: 1.303131
global_step: 12486, epoch: 13, loss: 1.224133
global_step: 12487, epoch: 13, loss: 1.314696
global_step: 12488, epoch: 13, loss: 1.332263
global_step: 12489, epoch: 13, loss: 1.221957
global_step: 12490, epoch: 13, loss: 1.231166
global_step: 12491, epoch: 13, loss: 1.347932
global_step: 12492, epoch: 13, loss: 1.241337
global_step: 12493, epoch: 13, loss: 1.220437
global_step: 12494, epoch: 13, loss: 1.301924
global_step: 12495, epoch: 13, loss: 1.292714
global_step: 12496, epoch: 13, loss: 1.418997
global_step: 12497, epoch: 13, loss: 1.192216
global_step: 12498, epoch: 13, loss: 1.164965
global_step: 12499, epoch: 13, loss: 1.249668
global_step: 12500, epoch: 13, loss: 1.277267
global_step: 12501, epoch: 13, loss: 1.199019
global_step: 12502, epoch: 13, loss: 1.317925
global_step: 12503, epoch: 13, loss: 1.287800
global_step: 12504, epoch: 13, loss: 1.344153
global_step: 12505, epoch: 13, loss: 1.339199
global_step: 12506, epoch: 13, loss: 1.307046
global_step: 12507, epoch: 13, loss: 1.264954
global_step: 12508, epoch: 13, loss: 1.268855
global_step: 12509, epoch: 13, loss: 1.266029
global_step: 12510, epoch: 13, loss: 1.322009
global_step: 12511, epoch: 13, loss: 1.393674
global_step: 12512, epoch: 13, loss: 1.248930
global_step: 12513, epoch: 13, loss: 1.297208
global_step: 12514, epoch: 13, loss: 1.352836
global_step: 12515, epoch: 13, loss: 1.310900
global_step: 12516, epoch: 13, loss: 1.342060
global_step: 12517, epoch: 13, loss: 1.324851
global_step: 12518, epoch: 13, loss: 1.350816
global_step: 12519, epoch: 13, loss: 1.310518
global_step: 12520, epoch: 13, loss: 1.310962
epoch: 13
train	acc: 0.5920	macro: p 0.4288, r 0.2895, f1: 0.2873	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5298
dev	acc: 0.5356	macro: p 0.2798, r 0.2769, f1: 0.2592	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4586
test	acc: 0.5808	macro: p 0.4241, r 0.2776, f1: 0.2673	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5136
New best model!
global_step: 12521, epoch: 14, loss: 1.258750
global_step: 12522, epoch: 14, loss: 1.205610
global_step: 12523, epoch: 14, loss: 1.309806
global_step: 12524, epoch: 14, loss: 1.298513
global_step: 12525, epoch: 14, loss: 1.301528
global_step: 12526, epoch: 14, loss: 1.201839
global_step: 12527, epoch: 14, loss: 1.252107
global_step: 12528, epoch: 14, loss: 1.322875
global_step: 12529, epoch: 14, loss: 1.311714
global_step: 12530, epoch: 14, loss: 1.226824
global_step: 12531, epoch: 14, loss: 1.325106
global_step: 12532, epoch: 14, loss: 1.228071
global_step: 12533, epoch: 14, loss: 1.286109
global_step: 12534, epoch: 14, loss: 1.404642
global_step: 12535, epoch: 14, loss: 1.278662
global_step: 12536, epoch: 14, loss: 1.301649
global_step: 12537, epoch: 14, loss: 1.358128
global_step: 12538, epoch: 14, loss: 1.273018
global_step: 12539, epoch: 14, loss: 1.160864
global_step: 12540, epoch: 14, loss: 1.211424
global_step: 12541, epoch: 14, loss: 1.299910
global_step: 12542, epoch: 14, loss: 1.336208
global_step: 12543, epoch: 14, loss: 1.172035
global_step: 12544, epoch: 14, loss: 1.373276
global_step: 12545, epoch: 14, loss: 1.256368
global_step: 12546, epoch: 14, loss: 1.289815
global_step: 12547, epoch: 14, loss: 1.343444
global_step: 12548, epoch: 14, loss: 1.276303
global_step: 12549, epoch: 14, loss: 1.272852
global_step: 12550, epoch: 14, loss: 1.336877
global_step: 12551, epoch: 14, loss: 1.234455
global_step: 12552, epoch: 14, loss: 1.266360
global_step: 12553, epoch: 14, loss: 1.312896
global_step: 12554, epoch: 14, loss: 1.268866
global_step: 12555, epoch: 14, loss: 1.424946
global_step: 12556, epoch: 14, loss: 1.309361
global_step: 12557, epoch: 14, loss: 1.314399
global_step: 12558, epoch: 14, loss: 1.361984
global_step: 12559, epoch: 14, loss: 1.320699
global_step: 12560, epoch: 14, loss: 0.735164
epoch: 14
train	acc: 0.5950	macro: p 0.4354, r 0.2946, f1: 0.2941	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5345
dev	acc: 0.5329	macro: p 0.2716, r 0.2723, f1: 0.2590	micro: p 0.5329, r 0.5329, f1 0.5329	weighted_f1:0.4584
test	acc: 0.5889	macro: p 0.4355, r 0.2852, f1: 0.2809	micro: p 0.5889, r 0.5889, f1 0.5889	weighted_f1:0.5260
global_step: 12561, epoch: 15, loss: 1.337187
global_step: 12562, epoch: 15, loss: 1.347932
global_step: 12563, epoch: 15, loss: 1.311349
global_step: 12564, epoch: 15, loss: 1.250376
global_step: 12565, epoch: 15, loss: 1.276808
global_step: 12566, epoch: 15, loss: 1.228843
global_step: 12567, epoch: 15, loss: 1.227667
global_step: 12568, epoch: 15, loss: 1.203044
global_step: 12569, epoch: 15, loss: 1.399099
global_step: 12570, epoch: 15, loss: 1.309013
global_step: 12571, epoch: 15, loss: 1.300250
global_step: 12572, epoch: 15, loss: 1.160131
global_step: 12573, epoch: 15, loss: 1.256349
global_step: 12574, epoch: 15, loss: 1.279513
global_step: 12575, epoch: 15, loss: 1.390004
global_step: 12576, epoch: 15, loss: 1.279406
global_step: 12577, epoch: 15, loss: 1.243154
global_step: 12578, epoch: 15, loss: 1.210282
global_step: 12579, epoch: 15, loss: 1.255560
global_step: 12580, epoch: 15, loss: 1.285803
global_step: 12581, epoch: 15, loss: 1.352275
global_step: 12582, epoch: 15, loss: 1.327989
global_step: 12583, epoch: 15, loss: 1.248768
global_step: 12584, epoch: 15, loss: 1.239620
global_step: 12585, epoch: 15, loss: 1.277367
global_step: 12586, epoch: 15, loss: 1.220860
global_step: 12587, epoch: 15, loss: 1.283043
global_step: 12588, epoch: 15, loss: 1.274948
global_step: 12589, epoch: 15, loss: 1.284626
global_step: 12590, epoch: 15, loss: 1.346261
global_step: 12591, epoch: 15, loss: 1.303249
global_step: 12592, epoch: 15, loss: 1.203113
global_step: 12593, epoch: 15, loss: 1.297821
global_step: 12594, epoch: 15, loss: 1.337565
global_step: 12595, epoch: 15, loss: 1.338440
global_step: 12596, epoch: 15, loss: 1.288092
global_step: 12597, epoch: 15, loss: 1.203446
global_step: 12598, epoch: 15, loss: 1.308586
global_step: 12599, epoch: 15, loss: 1.311888
global_step: 12600, epoch: 15, loss: 1.153820
epoch: 15
train	acc: 0.5930	macro: p 0.4382, r 0.2837, f1: 0.2820	micro: p 0.5930, r 0.5930, f1 0.5930	weighted_f1:0.5260
dev	acc: 0.5302	macro: p 0.2844, r 0.2674, f1: 0.2438	micro: p 0.5302, r 0.5302, f1 0.5302	weighted_f1:0.4442
test	acc: 0.5805	macro: p 0.4365, r 0.2722, f1: 0.2614	micro: p 0.5805, r 0.5805, f1 0.5805	weighted_f1:0.5083
global_step: 12601, epoch: 16, loss: 1.252025
global_step: 12602, epoch: 16, loss: 1.302496
global_step: 12603, epoch: 16, loss: 1.219758
global_step: 12604, epoch: 16, loss: 1.182820
global_step: 12605, epoch: 16, loss: 1.248281
global_step: 12606, epoch: 16, loss: 1.307603
global_step: 12607, epoch: 16, loss: 1.255496
global_step: 12608, epoch: 16, loss: 1.270755
global_step: 12609, epoch: 16, loss: 1.304705
global_step: 12610, epoch: 16, loss: 1.323459
global_step: 12611, epoch: 16, loss: 1.266508
global_step: 12612, epoch: 16, loss: 1.299983
global_step: 12613, epoch: 16, loss: 1.233632
global_step: 12614, epoch: 16, loss: 1.278361
global_step: 12615, epoch: 16, loss: 1.209482
global_step: 12616, epoch: 16, loss: 1.315263
global_step: 12617, epoch: 16, loss: 1.372048
global_step: 12618, epoch: 16, loss: 1.291732
global_step: 12619, epoch: 16, loss: 1.222550
global_step: 12620, epoch: 16, loss: 1.117590
global_step: 12621, epoch: 16, loss: 1.263391
global_step: 12622, epoch: 16, loss: 1.340598
global_step: 12623, epoch: 16, loss: 1.195309
global_step: 12624, epoch: 16, loss: 1.203827
global_step: 12625, epoch: 16, loss: 1.228217
global_step: 12626, epoch: 16, loss: 1.249684
global_step: 12627, epoch: 16, loss: 1.254933
global_step: 12628, epoch: 16, loss: 1.282088
global_step: 12629, epoch: 16, loss: 1.219534
global_step: 12630, epoch: 16, loss: 1.267514
global_step: 12631, epoch: 16, loss: 1.290696
global_step: 12632, epoch: 16, loss: 1.165375
global_step: 12633, epoch: 16, loss: 1.181646
global_step: 12634, epoch: 16, loss: 1.246865
global_step: 12635, epoch: 16, loss: 1.260128
global_step: 12636, epoch: 16, loss: 1.288359
global_step: 12637, epoch: 16, loss: 1.362369
global_step: 12638, epoch: 16, loss: 1.300747
global_step: 12639, epoch: 16, loss: 1.368943
global_step: 12640, epoch: 16, loss: 0.935161
epoch: 16
train	acc: 0.5974	macro: p 0.4223, r 0.2921, f1: 0.2933	micro: p 0.5974, r 0.5974, f1 0.5974	weighted_f1:0.5346
dev	acc: 0.5419	macro: p 0.4334, r 0.2813, f1: 0.2662	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4650
test	acc: 0.5858	macro: p 0.4373, r 0.2804, f1: 0.2729	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5180
New best model!
global_step: 12641, epoch: 17, loss: 1.244621
global_step: 12642, epoch: 17, loss: 1.282428
global_step: 12643, epoch: 17, loss: 1.269102
global_step: 12644, epoch: 17, loss: 1.209552
global_step: 12645, epoch: 17, loss: 1.336773
global_step: 12646, epoch: 17, loss: 1.242874
global_step: 12647, epoch: 17, loss: 1.204162
global_step: 12648, epoch: 17, loss: 1.380792
global_step: 12649, epoch: 17, loss: 1.332375
global_step: 12650, epoch: 17, loss: 1.271595
global_step: 12651, epoch: 17, loss: 1.205884
global_step: 12652, epoch: 17, loss: 1.390890
global_step: 12653, epoch: 17, loss: 1.310251
global_step: 12654, epoch: 17, loss: 1.327802
global_step: 12655, epoch: 17, loss: 1.221367
global_step: 12656, epoch: 17, loss: 1.283707
global_step: 12657, epoch: 17, loss: 1.345494
global_step: 12658, epoch: 17, loss: 1.295593
global_step: 12659, epoch: 17, loss: 1.226746
global_step: 12660, epoch: 17, loss: 1.218209
global_step: 12661, epoch: 17, loss: 1.263392
global_step: 12662, epoch: 17, loss: 1.220123
global_step: 12663, epoch: 17, loss: 1.315607
global_step: 12664, epoch: 17, loss: 1.175722
global_step: 12665, epoch: 17, loss: 1.294226
global_step: 12666, epoch: 17, loss: 1.330752
global_step: 12667, epoch: 17, loss: 1.237575
global_step: 12668, epoch: 17, loss: 1.206189
global_step: 12669, epoch: 17, loss: 1.347164
global_step: 12670, epoch: 17, loss: 1.321485
global_step: 12671, epoch: 17, loss: 1.230891
global_step: 12672, epoch: 17, loss: 1.209394
global_step: 12673, epoch: 17, loss: 1.172875
global_step: 12674, epoch: 17, loss: 1.193729
global_step: 12675, epoch: 17, loss: 1.158926
global_step: 12676, epoch: 17, loss: 1.193409
global_step: 12677, epoch: 17, loss: 1.255842
global_step: 12678, epoch: 17, loss: 1.323941
global_step: 12679, epoch: 17, loss: 1.240310
global_step: 12680, epoch: 17, loss: 1.819000
epoch: 17
train	acc: 0.6008	macro: p 0.4201, r 0.3012, f1: 0.3051	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5425
dev	acc: 0.5338	macro: p 0.4212, r 0.2739, f1: 0.2637	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4618
test	acc: 0.5897	macro: p 0.4231, r 0.2864, f1: 0.2858	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5288
global_step: 12681, epoch: 18, loss: 1.219744
global_step: 12682, epoch: 18, loss: 1.322741
global_step: 12683, epoch: 18, loss: 1.155123
global_step: 12684, epoch: 18, loss: 1.312610
global_step: 12685, epoch: 18, loss: 1.098925
global_step: 12686, epoch: 18, loss: 1.251660
global_step: 12687, epoch: 18, loss: 1.358020
global_step: 12688, epoch: 18, loss: 1.186747
global_step: 12689, epoch: 18, loss: 1.190244
global_step: 12690, epoch: 18, loss: 1.245092
global_step: 12691, epoch: 18, loss: 1.236400
global_step: 12692, epoch: 18, loss: 1.205778
global_step: 12693, epoch: 18, loss: 1.224077
global_step: 12694, epoch: 18, loss: 1.220936
global_step: 12695, epoch: 18, loss: 1.239250
global_step: 12696, epoch: 18, loss: 1.272514
global_step: 12697, epoch: 18, loss: 1.223816
global_step: 12698, epoch: 18, loss: 1.236998
global_step: 12699, epoch: 18, loss: 1.211025
global_step: 12700, epoch: 18, loss: 1.234508
global_step: 12701, epoch: 18, loss: 1.326376
global_step: 12702, epoch: 18, loss: 1.252656
global_step: 12703, epoch: 18, loss: 1.271718
global_step: 12704, epoch: 18, loss: 1.239053
global_step: 12705, epoch: 18, loss: 1.241837
global_step: 12706, epoch: 18, loss: 1.266147
global_step: 12707, epoch: 18, loss: 1.279005
global_step: 12708, epoch: 18, loss: 1.168429
global_step: 12709, epoch: 18, loss: 1.256412
global_step: 12710, epoch: 18, loss: 1.323921
global_step: 12711, epoch: 18, loss: 1.334371
global_step: 12712, epoch: 18, loss: 1.386004
global_step: 12713, epoch: 18, loss: 1.248691
global_step: 12714, epoch: 18, loss: 1.240310
global_step: 12715, epoch: 18, loss: 1.268362
global_step: 12716, epoch: 18, loss: 1.203250
global_step: 12717, epoch: 18, loss: 1.264143
global_step: 12718, epoch: 18, loss: 1.301161
global_step: 12719, epoch: 18, loss: 1.383239
global_step: 12720, epoch: 18, loss: 0.703594
epoch: 18
train	acc: 0.6024	macro: p 0.4188, r 0.2995, f1: 0.3039	micro: p 0.6024, r 0.6024, f1 0.6024	weighted_f1:0.5427
dev	acc: 0.5446	macro: p 0.4302, r 0.2843, f1: 0.2729	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4714
test	acc: 0.5881	macro: p 0.4170, r 0.2846, f1: 0.2798	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5232
New best model!
global_step: 12721, epoch: 19, loss: 1.266361
global_step: 12722, epoch: 19, loss: 1.344977
global_step: 12723, epoch: 19, loss: 1.116230
global_step: 12724, epoch: 19, loss: 1.296384
global_step: 12725, epoch: 19, loss: 1.234150
global_step: 12726, epoch: 19, loss: 1.255043
global_step: 12727, epoch: 19, loss: 1.319987
global_step: 12728, epoch: 19, loss: 1.283926
global_step: 12729, epoch: 19, loss: 1.188171
global_step: 12730, epoch: 19, loss: 1.137781
global_step: 12731, epoch: 19, loss: 1.310086
global_step: 12732, epoch: 19, loss: 1.263560
global_step: 12733, epoch: 19, loss: 1.235458
global_step: 12734, epoch: 19, loss: 1.220262
global_step: 12735, epoch: 19, loss: 1.201952
global_step: 12736, epoch: 19, loss: 1.189362
global_step: 12737, epoch: 19, loss: 1.148360
global_step: 12738, epoch: 19, loss: 1.290857
global_step: 12739, epoch: 19, loss: 1.189168
global_step: 12740, epoch: 19, loss: 1.293571
global_step: 12741, epoch: 19, loss: 1.191014
global_step: 12742, epoch: 19, loss: 1.342310
global_step: 12743, epoch: 19, loss: 1.180404
global_step: 12744, epoch: 19, loss: 1.269152
global_step: 12745, epoch: 19, loss: 1.241339
global_step: 12746, epoch: 19, loss: 1.395664
global_step: 12747, epoch: 19, loss: 1.238760
global_step: 12748, epoch: 19, loss: 1.328933
global_step: 12749, epoch: 19, loss: 1.110989
global_step: 12750, epoch: 19, loss: 1.253107
global_step: 12751, epoch: 19, loss: 1.248423
global_step: 12752, epoch: 19, loss: 1.179890
global_step: 12753, epoch: 19, loss: 1.264304
global_step: 12754, epoch: 19, loss: 1.327607
global_step: 12755, epoch: 19, loss: 1.177053
global_step: 12756, epoch: 19, loss: 1.201521
global_step: 12757, epoch: 19, loss: 1.233883
global_step: 12758, epoch: 19, loss: 1.321888
global_step: 12759, epoch: 19, loss: 1.220781
global_step: 12760, epoch: 19, loss: 1.281762
epoch: 19
train	acc: 0.6076	macro: p 0.4182, r 0.3102, f1: 0.3175	micro: p 0.6076, r 0.6076, f1 0.6076	weighted_f1:0.5528
dev	acc: 0.5455	macro: p 0.3983, r 0.2868, f1: 0.2767	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4750
test	acc: 0.5908	macro: p 0.3936, r 0.2913, f1: 0.2896	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5308
New best model!
global_step: 12761, epoch: 20, loss: 1.329884
global_step: 12762, epoch: 20, loss: 1.238941
global_step: 12763, epoch: 20, loss: 1.222054
global_step: 12764, epoch: 20, loss: 1.188014
global_step: 12765, epoch: 20, loss: 1.342765
global_step: 12766, epoch: 20, loss: 1.158319
global_step: 12767, epoch: 20, loss: 1.304497
global_step: 12768, epoch: 20, loss: 1.232316
global_step: 12769, epoch: 20, loss: 1.140189
global_step: 12770, epoch: 20, loss: 1.255701
global_step: 12771, epoch: 20, loss: 1.278922
global_step: 12772, epoch: 20, loss: 1.175710
global_step: 12773, epoch: 20, loss: 1.147491
global_step: 12774, epoch: 20, loss: 1.166258
global_step: 12775, epoch: 20, loss: 1.315708
global_step: 12776, epoch: 20, loss: 1.243720
global_step: 12777, epoch: 20, loss: 1.272207
global_step: 12778, epoch: 20, loss: 1.268175
global_step: 12779, epoch: 20, loss: 1.199700
global_step: 12780, epoch: 20, loss: 1.205287
global_step: 12781, epoch: 20, loss: 1.245240
global_step: 12782, epoch: 20, loss: 1.233163
global_step: 12783, epoch: 20, loss: 1.200138
global_step: 12784, epoch: 20, loss: 1.217031
global_step: 12785, epoch: 20, loss: 1.190896
global_step: 12786, epoch: 20, loss: 1.270491
global_step: 12787, epoch: 20, loss: 1.270171
global_step: 12788, epoch: 20, loss: 1.299026
global_step: 12789, epoch: 20, loss: 1.274202
global_step: 12790, epoch: 20, loss: 1.222351
global_step: 12791, epoch: 20, loss: 1.153357
global_step: 12792, epoch: 20, loss: 1.200513
global_step: 12793, epoch: 20, loss: 1.203326
global_step: 12794, epoch: 20, loss: 1.192157
global_step: 12795, epoch: 20, loss: 1.171795
global_step: 12796, epoch: 20, loss: 1.326797
global_step: 12797, epoch: 20, loss: 1.271328
global_step: 12798, epoch: 20, loss: 1.222407
global_step: 12799, epoch: 20, loss: 1.258420
global_step: 12800, epoch: 20, loss: 1.878848
epoch: 20
train	acc: 0.6128	macro: p 0.4282, r 0.3188, f1: 0.3277	micro: p 0.6128, r 0.6128, f1 0.6128	weighted_f1:0.5612
dev	acc: 0.5410	macro: p 0.3522, r 0.2844, f1: 0.2736	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4727
test	acc: 0.5950	macro: p 0.3964, r 0.2961, f1: 0.2964	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5378
global_step: 12801, epoch: 21, loss: 1.132149
global_step: 12802, epoch: 21, loss: 1.236349
global_step: 12803, epoch: 21, loss: 1.218175
global_step: 12804, epoch: 21, loss: 1.241368
global_step: 12805, epoch: 21, loss: 1.262946
global_step: 12806, epoch: 21, loss: 1.267281
global_step: 12807, epoch: 21, loss: 1.160483
global_step: 12808, epoch: 21, loss: 1.325399
global_step: 12809, epoch: 21, loss: 1.138193
global_step: 12810, epoch: 21, loss: 1.197464
global_step: 12811, epoch: 21, loss: 1.225698
global_step: 12812, epoch: 21, loss: 1.217814
global_step: 12813, epoch: 21, loss: 1.211254
global_step: 12814, epoch: 21, loss: 1.279936
global_step: 12815, epoch: 21, loss: 1.168607
global_step: 12816, epoch: 21, loss: 1.195544
global_step: 12817, epoch: 21, loss: 1.283031
global_step: 12818, epoch: 21, loss: 1.207301
global_step: 12819, epoch: 21, loss: 1.264501
global_step: 12820, epoch: 21, loss: 1.278422
global_step: 12821, epoch: 21, loss: 1.146705
global_step: 12822, epoch: 21, loss: 1.318888
global_step: 12823, epoch: 21, loss: 1.201261
global_step: 12824, epoch: 21, loss: 1.216976
global_step: 12825, epoch: 21, loss: 1.194849
global_step: 12826, epoch: 21, loss: 1.266530
global_step: 12827, epoch: 21, loss: 1.293333
global_step: 12828, epoch: 21, loss: 1.268044
global_step: 12829, epoch: 21, loss: 1.157573
global_step: 12830, epoch: 21, loss: 1.280777
global_step: 12831, epoch: 21, loss: 1.194487
global_step: 12832, epoch: 21, loss: 1.232150
global_step: 12833, epoch: 21, loss: 1.184287
global_step: 12834, epoch: 21, loss: 1.231124
global_step: 12835, epoch: 21, loss: 1.258116
global_step: 12836, epoch: 21, loss: 1.287073
global_step: 12837, epoch: 21, loss: 1.279326
global_step: 12838, epoch: 21, loss: 1.281200
global_step: 12839, epoch: 21, loss: 1.235064
global_step: 12840, epoch: 21, loss: 1.205389
epoch: 21
train	acc: 0.6144	macro: p 0.4295, r 0.3193, f1: 0.3281	micro: p 0.6144, r 0.6144, f1 0.6144	weighted_f1:0.5621
dev	acc: 0.5446	macro: p 0.3781, r 0.2851, f1: 0.2747	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4742
test	acc: 0.5969	macro: p 0.3982, r 0.2976, f1: 0.2979	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5391
global_step: 12841, epoch: 22, loss: 1.077375
global_step: 12842, epoch: 22, loss: 1.210675
global_step: 12843, epoch: 22, loss: 1.189452
global_step: 12844, epoch: 22, loss: 1.180686
global_step: 12845, epoch: 22, loss: 1.252088
global_step: 12846, epoch: 22, loss: 1.160197
global_step: 12847, epoch: 22, loss: 1.157278
global_step: 12848, epoch: 22, loss: 1.147516
global_step: 12849, epoch: 22, loss: 1.101640
global_step: 12850, epoch: 22, loss: 1.292859
global_step: 12851, epoch: 22, loss: 1.316304
global_step: 12852, epoch: 22, loss: 1.237145
global_step: 12853, epoch: 22, loss: 1.243567
global_step: 12854, epoch: 22, loss: 1.198202
global_step: 12855, epoch: 22, loss: 1.232287
global_step: 12856, epoch: 22, loss: 1.336999
global_step: 12857, epoch: 22, loss: 1.250570
global_step: 12858, epoch: 22, loss: 1.236109
global_step: 12859, epoch: 22, loss: 1.368047
global_step: 12860, epoch: 22, loss: 1.186160
global_step: 12861, epoch: 22, loss: 1.179012
global_step: 12862, epoch: 22, loss: 1.250266
global_step: 12863, epoch: 22, loss: 1.173301
global_step: 12864, epoch: 22, loss: 1.193882
global_step: 12865, epoch: 22, loss: 1.179252
global_step: 12866, epoch: 22, loss: 1.235363
global_step: 12867, epoch: 22, loss: 1.265536
global_step: 12868, epoch: 22, loss: 1.243942
global_step: 12869, epoch: 22, loss: 1.178747
global_step: 12870, epoch: 22, loss: 1.253819
global_step: 12871, epoch: 22, loss: 1.224996
global_step: 12872, epoch: 22, loss: 1.227708
global_step: 12873, epoch: 22, loss: 1.350723
global_step: 12874, epoch: 22, loss: 1.284639
global_step: 12875, epoch: 22, loss: 1.179199
global_step: 12876, epoch: 22, loss: 1.152683
global_step: 12877, epoch: 22, loss: 1.163283
global_step: 12878, epoch: 22, loss: 1.163882
global_step: 12879, epoch: 22, loss: 1.247226
global_step: 12880, epoch: 22, loss: 1.215573
epoch: 22
train	acc: 0.6152	macro: p 0.4315, r 0.3187, f1: 0.3284	micro: p 0.6152, r 0.6152, f1 0.6152	weighted_f1:0.5622
dev	acc: 0.5455	macro: p 0.3661, r 0.2866, f1: 0.2755	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4745
test	acc: 0.5950	macro: p 0.3960, r 0.2958, f1: 0.2945	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5355
global_step: 12881, epoch: 23, loss: 1.153693
global_step: 12882, epoch: 23, loss: 1.257526
global_step: 12883, epoch: 23, loss: 1.204480
global_step: 12884, epoch: 23, loss: 1.213528
global_step: 12885, epoch: 23, loss: 1.128855
global_step: 12886, epoch: 23, loss: 1.201762
global_step: 12887, epoch: 23, loss: 1.292134
global_step: 12888, epoch: 23, loss: 1.281217
global_step: 12889, epoch: 23, loss: 1.274004
global_step: 12890, epoch: 23, loss: 1.163245
global_step: 12891, epoch: 23, loss: 1.241204
global_step: 12892, epoch: 23, loss: 1.058388
global_step: 12893, epoch: 23, loss: 1.209684
global_step: 12894, epoch: 23, loss: 1.184156
global_step: 12895, epoch: 23, loss: 1.340761
global_step: 12896, epoch: 23, loss: 1.161799
global_step: 12897, epoch: 23, loss: 1.236512
global_step: 12898, epoch: 23, loss: 1.200661
global_step: 12899, epoch: 23, loss: 1.419884
global_step: 12900, epoch: 23, loss: 1.252340
global_step: 12901, epoch: 23, loss: 1.277924
global_step: 12902, epoch: 23, loss: 1.261536
global_step: 12903, epoch: 23, loss: 1.199584
global_step: 12904, epoch: 23, loss: 1.181369
global_step: 12905, epoch: 23, loss: 1.193336
global_step: 12906, epoch: 23, loss: 1.269711
global_step: 12907, epoch: 23, loss: 1.193311
global_step: 12908, epoch: 23, loss: 1.195381
global_step: 12909, epoch: 23, loss: 1.146649
global_step: 12910, epoch: 23, loss: 1.170459
global_step: 12911, epoch: 23, loss: 1.307352
global_step: 12912, epoch: 23, loss: 1.260856
global_step: 12913, epoch: 23, loss: 1.127292
global_step: 12914, epoch: 23, loss: 1.152215
global_step: 12915, epoch: 23, loss: 1.228030
global_step: 12916, epoch: 23, loss: 1.158216
global_step: 12917, epoch: 23, loss: 1.187162
global_step: 12918, epoch: 23, loss: 1.217746
global_step: 12919, epoch: 23, loss: 1.207202
global_step: 12920, epoch: 23, loss: 1.508722
epoch: 23
train	acc: 0.6156	macro: p 0.4326, r 0.3171, f1: 0.3254	micro: p 0.6156, r 0.6156, f1 0.6156	weighted_f1:0.5614
dev	acc: 0.5464	macro: p 0.3705, r 0.2879, f1: 0.2757	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4751
test	acc: 0.5931	macro: p 0.3910, r 0.2927, f1: 0.2902	micro: p 0.5931, r 0.5931, f1 0.5931	weighted_f1:0.5322
New best model!
global_step: 12921, epoch: 24, loss: 1.227854
global_step: 12922, epoch: 24, loss: 1.250393
global_step: 12923, epoch: 24, loss: 1.207121
global_step: 12924, epoch: 24, loss: 1.256713
global_step: 12925, epoch: 24, loss: 1.158210
global_step: 12926, epoch: 24, loss: 1.311348
global_step: 12927, epoch: 24, loss: 1.264069
global_step: 12928, epoch: 24, loss: 1.166588
global_step: 12929, epoch: 24, loss: 1.215490
global_step: 12930, epoch: 24, loss: 1.195152
global_step: 12931, epoch: 24, loss: 1.233325
global_step: 12932, epoch: 24, loss: 1.195778
global_step: 12933, epoch: 24, loss: 1.157909
global_step: 12934, epoch: 24, loss: 1.209255
global_step: 12935, epoch: 24, loss: 1.212516
global_step: 12936, epoch: 24, loss: 1.256655
global_step: 12937, epoch: 24, loss: 1.149207
global_step: 12938, epoch: 24, loss: 1.228483
global_step: 12939, epoch: 24, loss: 1.220842
global_step: 12940, epoch: 24, loss: 1.071297
global_step: 12941, epoch: 24, loss: 1.179458
global_step: 12942, epoch: 24, loss: 1.301764
global_step: 12943, epoch: 24, loss: 1.111732
global_step: 12944, epoch: 24, loss: 1.288525
global_step: 12945, epoch: 24, loss: 1.164971
global_step: 12946, epoch: 24, loss: 1.162894
global_step: 12947, epoch: 24, loss: 1.172593
global_step: 12948, epoch: 24, loss: 1.231572
global_step: 12949, epoch: 24, loss: 1.167685
global_step: 12950, epoch: 24, loss: 1.221138
global_step: 12951, epoch: 24, loss: 1.205205
global_step: 12952, epoch: 24, loss: 1.160028
global_step: 12953, epoch: 24, loss: 1.282964
global_step: 12954, epoch: 24, loss: 1.191935
global_step: 12955, epoch: 24, loss: 1.267450
global_step: 12956, epoch: 24, loss: 1.280063
global_step: 12957, epoch: 24, loss: 1.201835
global_step: 12958, epoch: 24, loss: 1.243888
global_step: 12959, epoch: 24, loss: 1.230655
global_step: 12960, epoch: 24, loss: 1.297767
epoch: 24
train	acc: 0.6196	macro: p 0.4328, r 0.3237, f1: 0.3339	micro: p 0.6196, r 0.6196, f1 0.6196	weighted_f1:0.5676
dev	acc: 0.5482	macro: p 0.3643, r 0.2891, f1: 0.2793	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4784
test	acc: 0.5954	macro: p 0.3832, r 0.2972, f1: 0.2976	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5378
New best model!
global_step: 12961, epoch: 25, loss: 1.158530
global_step: 12962, epoch: 25, loss: 1.218449
global_step: 12963, epoch: 25, loss: 1.124934
global_step: 12964, epoch: 25, loss: 1.169503
global_step: 12965, epoch: 25, loss: 1.095082
global_step: 12966, epoch: 25, loss: 1.200984
global_step: 12967, epoch: 25, loss: 1.204496
global_step: 12968, epoch: 25, loss: 1.166966
global_step: 12969, epoch: 25, loss: 1.277486
global_step: 12970, epoch: 25, loss: 1.231749
global_step: 12971, epoch: 25, loss: 1.244411
global_step: 12972, epoch: 25, loss: 1.200478
global_step: 12973, epoch: 25, loss: 1.345592
global_step: 12974, epoch: 25, loss: 1.090368
global_step: 12975, epoch: 25, loss: 1.170640
global_step: 12976, epoch: 25, loss: 1.247691
global_step: 12977, epoch: 25, loss: 1.166883
global_step: 12978, epoch: 25, loss: 1.153958
global_step: 12979, epoch: 25, loss: 1.156514
global_step: 12980, epoch: 25, loss: 1.316736
global_step: 12981, epoch: 25, loss: 1.219978
global_step: 12982, epoch: 25, loss: 1.170047
global_step: 12983, epoch: 25, loss: 1.297765
global_step: 12984, epoch: 25, loss: 1.325600
global_step: 12985, epoch: 25, loss: 1.202933
global_step: 12986, epoch: 25, loss: 1.171932
global_step: 12987, epoch: 25, loss: 1.202257
global_step: 12988, epoch: 25, loss: 1.128493
global_step: 12989, epoch: 25, loss: 1.192523
global_step: 12990, epoch: 25, loss: 1.241731
global_step: 12991, epoch: 25, loss: 1.187577
global_step: 12992, epoch: 25, loss: 1.180300
global_step: 12993, epoch: 25, loss: 1.242948
global_step: 12994, epoch: 25, loss: 1.218385
global_step: 12995, epoch: 25, loss: 1.136797
global_step: 12996, epoch: 25, loss: 1.190768
global_step: 12997, epoch: 25, loss: 1.278930
global_step: 12998, epoch: 25, loss: 1.095436
global_step: 12999, epoch: 25, loss: 1.079228
global_step: 13000, epoch: 25, loss: 1.717559
epoch: 25
train	acc: 0.6244	macro: p 0.4324, r 0.3333, f1: 0.3429	micro: p 0.6244, r 0.6244, f1 0.6244	weighted_f1:0.5755
dev	acc: 0.5437	macro: p 0.3452, r 0.2879, f1: 0.2797	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4785
test	acc: 0.5973	macro: p 0.3880, r 0.3015, f1: 0.3040	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5436
New best model!
global_step: 13001, epoch: 26, loss: 1.180419
global_step: 13002, epoch: 26, loss: 1.160248
global_step: 13003, epoch: 26, loss: 1.155550
global_step: 13004, epoch: 26, loss: 1.039213
global_step: 13005, epoch: 26, loss: 1.171015
global_step: 13006, epoch: 26, loss: 1.190896
global_step: 13007, epoch: 26, loss: 1.158590
global_step: 13008, epoch: 26, loss: 1.336289
global_step: 13009, epoch: 26, loss: 1.173517
global_step: 13010, epoch: 26, loss: 1.247580
global_step: 13011, epoch: 26, loss: 1.080457
global_step: 13012, epoch: 26, loss: 1.275286
global_step: 13013, epoch: 26, loss: 1.237238
global_step: 13014, epoch: 26, loss: 1.186237
global_step: 13015, epoch: 26, loss: 1.295698
global_step: 13016, epoch: 26, loss: 1.246414
global_step: 13017, epoch: 26, loss: 1.142646
global_step: 13018, epoch: 26, loss: 1.180432
global_step: 13019, epoch: 26, loss: 1.228904
global_step: 13020, epoch: 26, loss: 1.182343
global_step: 13021, epoch: 26, loss: 1.212796
global_step: 13022, epoch: 26, loss: 1.172377
global_step: 13023, epoch: 26, loss: 1.225478
global_step: 13024, epoch: 26, loss: 1.223371
global_step: 13025, epoch: 26, loss: 1.206674
global_step: 13026, epoch: 26, loss: 1.279040
global_step: 13027, epoch: 26, loss: 1.275767
global_step: 13028, epoch: 26, loss: 1.132688
global_step: 13029, epoch: 26, loss: 1.135328
global_step: 13030, epoch: 26, loss: 1.157036
global_step: 13031, epoch: 26, loss: 1.226227
global_step: 13032, epoch: 26, loss: 1.093683
global_step: 13033, epoch: 26, loss: 1.148890
global_step: 13034, epoch: 26, loss: 1.347930
global_step: 13035, epoch: 26, loss: 1.100893
global_step: 13036, epoch: 26, loss: 1.128421
global_step: 13037, epoch: 26, loss: 1.155224
global_step: 13038, epoch: 26, loss: 1.097331
global_step: 13039, epoch: 26, loss: 1.141939
global_step: 13040, epoch: 26, loss: 0.985165
epoch: 26
train	acc: 0.6282	macro: p 0.4408, r 0.3371, f1: 0.3473	micro: p 0.6282, r 0.6282, f1 0.6282	weighted_f1:0.5792
dev	acc: 0.5455	macro: p 0.3569, r 0.2889, f1: 0.2804	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4787
test	acc: 0.5966	macro: p 0.3804, r 0.3015, f1: 0.3027	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5417
New best model!
global_step: 13041, epoch: 27, loss: 1.265964
global_step: 13042, epoch: 27, loss: 1.154701
global_step: 13043, epoch: 27, loss: 1.193831
global_step: 13044, epoch: 27, loss: 1.176121
global_step: 13045, epoch: 27, loss: 1.130663
global_step: 13046, epoch: 27, loss: 1.092167
global_step: 13047, epoch: 27, loss: 1.191694
global_step: 13048, epoch: 27, loss: 1.178813
global_step: 13049, epoch: 27, loss: 0.978177
global_step: 13050, epoch: 27, loss: 1.097324
global_step: 13051, epoch: 27, loss: 1.201287
global_step: 13052, epoch: 27, loss: 1.265332
global_step: 13053, epoch: 27, loss: 1.182270
global_step: 13054, epoch: 27, loss: 1.199324
global_step: 13055, epoch: 27, loss: 1.176096
global_step: 13056, epoch: 27, loss: 1.192210
global_step: 13057, epoch: 27, loss: 1.130780
global_step: 13058, epoch: 27, loss: 1.113388
global_step: 13059, epoch: 27, loss: 1.119518
global_step: 13060, epoch: 27, loss: 1.203114
global_step: 13061, epoch: 27, loss: 1.135277
global_step: 13062, epoch: 27, loss: 1.227311
global_step: 13063, epoch: 27, loss: 1.116589
global_step: 13064, epoch: 27, loss: 1.193713
global_step: 13065, epoch: 27, loss: 1.175060
global_step: 13066, epoch: 27, loss: 1.234808
global_step: 13067, epoch: 27, loss: 1.237979
global_step: 13068, epoch: 27, loss: 1.216066
global_step: 13069, epoch: 27, loss: 1.135016
global_step: 13070, epoch: 27, loss: 1.257344
global_step: 13071, epoch: 27, loss: 1.124599
global_step: 13072, epoch: 27, loss: 1.235790
global_step: 13073, epoch: 27, loss: 1.235980
global_step: 13074, epoch: 27, loss: 1.165957
global_step: 13075, epoch: 27, loss: 1.141754
global_step: 13076, epoch: 27, loss: 1.336097
global_step: 13077, epoch: 27, loss: 1.250758
global_step: 13078, epoch: 27, loss: 1.270450
global_step: 13079, epoch: 27, loss: 1.183493
global_step: 13080, epoch: 27, loss: 0.555516
epoch: 27
train	acc: 0.6322	macro: p 0.4354, r 0.3433, f1: 0.3547	micro: p 0.6322, r 0.6322, f1 0.6322	weighted_f1:0.5856
dev	acc: 0.5464	macro: p 0.3417, r 0.2927, f1: 0.2822	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4811
test	acc: 0.5977	macro: p 0.3838, r 0.3050, f1: 0.3055	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5438
New best model!
global_step: 13081, epoch: 28, loss: 1.262163
global_step: 13082, epoch: 28, loss: 1.173770
global_step: 13083, epoch: 28, loss: 1.200461
global_step: 13084, epoch: 28, loss: 1.149474
global_step: 13085, epoch: 28, loss: 1.291434
global_step: 13086, epoch: 28, loss: 1.137858
global_step: 13087, epoch: 28, loss: 1.228464
global_step: 13088, epoch: 28, loss: 1.199377
global_step: 13089, epoch: 28, loss: 1.186394
global_step: 13090, epoch: 28, loss: 1.219294
global_step: 13091, epoch: 28, loss: 1.218875
global_step: 13092, epoch: 28, loss: 1.230896
global_step: 13093, epoch: 28, loss: 1.080320
global_step: 13094, epoch: 28, loss: 1.184006
global_step: 13095, epoch: 28, loss: 1.150659
global_step: 13096, epoch: 28, loss: 1.190884
global_step: 13097, epoch: 28, loss: 1.111842
global_step: 13098, epoch: 28, loss: 1.150128
global_step: 13099, epoch: 28, loss: 1.137310
global_step: 13100, epoch: 28, loss: 1.251991
global_step: 13101, epoch: 28, loss: 1.168873
global_step: 13102, epoch: 28, loss: 1.129217
global_step: 13103, epoch: 28, loss: 1.142723
global_step: 13104, epoch: 28, loss: 1.258289
global_step: 13105, epoch: 28, loss: 1.070489
global_step: 13106, epoch: 28, loss: 1.147083
global_step: 13107, epoch: 28, loss: 1.116011
global_step: 13108, epoch: 28, loss: 1.213231
global_step: 13109, epoch: 28, loss: 1.144691
global_step: 13110, epoch: 28, loss: 1.164982
global_step: 13111, epoch: 28, loss: 1.227367
global_step: 13112, epoch: 28, loss: 1.125144
global_step: 13113, epoch: 28, loss: 1.185031
global_step: 13114, epoch: 28, loss: 1.085817
global_step: 13115, epoch: 28, loss: 1.126218
global_step: 13116, epoch: 28, loss: 1.193411
global_step: 13117, epoch: 28, loss: 1.209782
global_step: 13118, epoch: 28, loss: 1.171097
global_step: 13119, epoch: 28, loss: 1.170083
global_step: 13120, epoch: 28, loss: 1.313891
epoch: 28
train	acc: 0.6305	macro: p 0.4394, r 0.3386, f1: 0.3507	micro: p 0.6305, r 0.6305, f1 0.6305	weighted_f1:0.5818
dev	acc: 0.5455	macro: p 0.3476, r 0.2881, f1: 0.2798	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4787
test	acc: 0.6000	macro: p 0.3848, r 0.3037, f1: 0.3066	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5454
global_step: 13121, epoch: 29, loss: 1.041114
global_step: 13122, epoch: 29, loss: 1.234738
global_step: 13123, epoch: 29, loss: 1.176352
global_step: 13124, epoch: 29, loss: 1.070774
global_step: 13125, epoch: 29, loss: 1.173816
global_step: 13126, epoch: 29, loss: 1.031678
global_step: 13127, epoch: 29, loss: 1.236832
global_step: 13128, epoch: 29, loss: 1.171235
global_step: 13129, epoch: 29, loss: 1.282347
global_step: 13130, epoch: 29, loss: 1.118014
global_step: 13131, epoch: 29, loss: 1.135310
global_step: 13132, epoch: 29, loss: 1.153738
global_step: 13133, epoch: 29, loss: 1.194476
global_step: 13134, epoch: 29, loss: 1.113427
global_step: 13135, epoch: 29, loss: 1.218930
global_step: 13136, epoch: 29, loss: 1.209152
global_step: 13137, epoch: 29, loss: 1.139056
global_step: 13138, epoch: 29, loss: 1.149185
global_step: 13139, epoch: 29, loss: 1.209704
global_step: 13140, epoch: 29, loss: 1.002553
global_step: 13141, epoch: 29, loss: 1.217530
global_step: 13142, epoch: 29, loss: 1.192587
global_step: 13143, epoch: 29, loss: 1.296812
global_step: 13144, epoch: 29, loss: 1.195502
global_step: 13145, epoch: 29, loss: 1.158851
global_step: 13146, epoch: 29, loss: 1.179198
global_step: 13147, epoch: 29, loss: 1.131482
global_step: 13148, epoch: 29, loss: 1.199624
global_step: 13149, epoch: 29, loss: 1.143807
global_step: 13150, epoch: 29, loss: 1.185620
global_step: 13151, epoch: 29, loss: 1.189125
global_step: 13152, epoch: 29, loss: 1.337497
global_step: 13153, epoch: 29, loss: 1.082943
global_step: 13154, epoch: 29, loss: 1.062276
global_step: 13155, epoch: 29, loss: 1.191479
global_step: 13156, epoch: 29, loss: 1.205817
global_step: 13157, epoch: 29, loss: 1.068502
global_step: 13158, epoch: 29, loss: 1.226160
global_step: 13159, epoch: 29, loss: 1.083659
global_step: 13160, epoch: 29, loss: 1.626806
epoch: 29
train	acc: 0.6348	macro: p 0.4350, r 0.3480, f1: 0.3600	micro: p 0.6348, r 0.6348, f1 0.6348	weighted_f1:0.5899
dev	acc: 0.5428	macro: p 0.3371, r 0.2894, f1: 0.2825	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4806
test	acc: 0.6019	macro: p 0.3856, r 0.3092, f1: 0.3137	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5512
global_step: 13161, epoch: 30, loss: 1.170082
global_step: 13162, epoch: 30, loss: 1.128526
global_step: 13163, epoch: 30, loss: 1.185089
global_step: 13164, epoch: 30, loss: 1.332095
global_step: 13165, epoch: 30, loss: 1.169834
global_step: 13166, epoch: 30, loss: 1.266939
global_step: 13167, epoch: 30, loss: 1.185954
global_step: 13168, epoch: 30, loss: 1.032647
global_step: 13169, epoch: 30, loss: 1.191692
global_step: 13170, epoch: 30, loss: 1.174212
global_step: 13171, epoch: 30, loss: 1.237365
global_step: 13172, epoch: 30, loss: 1.229234
global_step: 13173, epoch: 30, loss: 1.167696
global_step: 13174, epoch: 30, loss: 0.955584
global_step: 13175, epoch: 30, loss: 1.126412
global_step: 13176, epoch: 30, loss: 1.085332
global_step: 13177, epoch: 30, loss: 1.278283
global_step: 13178, epoch: 30, loss: 1.393604
global_step: 13179, epoch: 30, loss: 1.137743
global_step: 13180, epoch: 30, loss: 1.280766
global_step: 13181, epoch: 30, loss: 1.170861
global_step: 13182, epoch: 30, loss: 1.085233
global_step: 13183, epoch: 30, loss: 1.126006
global_step: 13184, epoch: 30, loss: 1.154227
global_step: 13185, epoch: 30, loss: 1.069423
global_step: 13186, epoch: 30, loss: 1.201570
global_step: 13187, epoch: 30, loss: 1.114122
global_step: 13188, epoch: 30, loss: 1.173357
global_step: 13189, epoch: 30, loss: 1.165812
global_step: 13190, epoch: 30, loss: 1.080914
global_step: 13191, epoch: 30, loss: 1.076812
global_step: 13192, epoch: 30, loss: 1.113006
global_step: 13193, epoch: 30, loss: 1.114921
global_step: 13194, epoch: 30, loss: 1.250347
global_step: 13195, epoch: 30, loss: 1.378648
global_step: 13196, epoch: 30, loss: 1.163300
global_step: 13197, epoch: 30, loss: 1.106624
global_step: 13198, epoch: 30, loss: 1.105342
global_step: 13199, epoch: 30, loss: 1.099811
global_step: 13200, epoch: 30, loss: 1.345501
epoch: 30
train	acc: 0.6348	macro: p 0.4320, r 0.3494, f1: 0.3623	micro: p 0.6348, r 0.6348, f1 0.6348	weighted_f1:0.5908
dev	acc: 0.5482	macro: p 0.3389, r 0.2939, f1: 0.2885	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4869
test	acc: 0.6042	macro: p 0.3921, r 0.3119, f1: 0.3181	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5542
New best model!
global_step: 13201, epoch: 31, loss: 1.150943
global_step: 13202, epoch: 31, loss: 1.081599
global_step: 13203, epoch: 31, loss: 1.179689
global_step: 13204, epoch: 31, loss: 1.135240
global_step: 13205, epoch: 31, loss: 1.141053
global_step: 13206, epoch: 31, loss: 1.087357
global_step: 13207, epoch: 31, loss: 1.287992
global_step: 13208, epoch: 31, loss: 1.175738
global_step: 13209, epoch: 31, loss: 1.132804
global_step: 13210, epoch: 31, loss: 1.255692
global_step: 13211, epoch: 31, loss: 1.136947
global_step: 13212, epoch: 31, loss: 1.124709
global_step: 13213, epoch: 31, loss: 1.105662
global_step: 13214, epoch: 31, loss: 1.071108
global_step: 13215, epoch: 31, loss: 1.152446
global_step: 13216, epoch: 31, loss: 1.176720
global_step: 13217, epoch: 31, loss: 1.155783
global_step: 13218, epoch: 31, loss: 1.133586
global_step: 13219, epoch: 31, loss: 1.121857
global_step: 13220, epoch: 31, loss: 1.259806
global_step: 13221, epoch: 31, loss: 1.206190
global_step: 13222, epoch: 31, loss: 0.994333
global_step: 13223, epoch: 31, loss: 1.199266
global_step: 13224, epoch: 31, loss: 1.210368
global_step: 13225, epoch: 31, loss: 1.073382
global_step: 13226, epoch: 31, loss: 1.096274
global_step: 13227, epoch: 31, loss: 1.289863
global_step: 13228, epoch: 31, loss: 1.179632
global_step: 13229, epoch: 31, loss: 1.121820
global_step: 13230, epoch: 31, loss: 1.141770
global_step: 13231, epoch: 31, loss: 1.088964
global_step: 13232, epoch: 31, loss: 1.163162
global_step: 13233, epoch: 31, loss: 1.089486
global_step: 13234, epoch: 31, loss: 1.292871
global_step: 13235, epoch: 31, loss: 1.153096
global_step: 13236, epoch: 31, loss: 1.168723
global_step: 13237, epoch: 31, loss: 1.243373
global_step: 13238, epoch: 31, loss: 1.109921
global_step: 13239, epoch: 31, loss: 1.286955
global_step: 13240, epoch: 31, loss: 1.370048
epoch: 31
train	acc: 0.6440	macro: p 0.4383, r 0.3580, f1: 0.3694	micro: p 0.6440, r 0.6440, f1 0.6440	weighted_f1:0.6007
dev	acc: 0.5446	macro: p 0.3367, r 0.2928, f1: 0.2828	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4816
test	acc: 0.6008	macro: p 0.3802, r 0.3098, f1: 0.3111	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5495
global_step: 13241, epoch: 32, loss: 1.050009
global_step: 13242, epoch: 32, loss: 1.040900
global_step: 13243, epoch: 32, loss: 1.056432
global_step: 13244, epoch: 32, loss: 1.176609
global_step: 13245, epoch: 32, loss: 1.216238
global_step: 13246, epoch: 32, loss: 1.141789
global_step: 13247, epoch: 32, loss: 1.188794
global_step: 13248, epoch: 32, loss: 1.169355
global_step: 13249, epoch: 32, loss: 1.087893
global_step: 13250, epoch: 32, loss: 1.063730
global_step: 13251, epoch: 32, loss: 1.185206
global_step: 13252, epoch: 32, loss: 1.159653
global_step: 13253, epoch: 32, loss: 1.106180
global_step: 13254, epoch: 32, loss: 1.036050
global_step: 13255, epoch: 32, loss: 1.092672
global_step: 13256, epoch: 32, loss: 1.184202
global_step: 13257, epoch: 32, loss: 1.233236
global_step: 13258, epoch: 32, loss: 1.129084
global_step: 13259, epoch: 32, loss: 1.196647
global_step: 13260, epoch: 32, loss: 1.108542
global_step: 13261, epoch: 32, loss: 1.107115
global_step: 13262, epoch: 32, loss: 1.206771
global_step: 13263, epoch: 32, loss: 1.153791
global_step: 13264, epoch: 32, loss: 1.176337
global_step: 13265, epoch: 32, loss: 1.075228
global_step: 13266, epoch: 32, loss: 1.130244
global_step: 13267, epoch: 32, loss: 1.217800
global_step: 13268, epoch: 32, loss: 1.197522
global_step: 13269, epoch: 32, loss: 1.147366
global_step: 13270, epoch: 32, loss: 1.160224
global_step: 13271, epoch: 32, loss: 1.191501
global_step: 13272, epoch: 32, loss: 1.219880
global_step: 13273, epoch: 32, loss: 1.153874
global_step: 13274, epoch: 32, loss: 1.186833
global_step: 13275, epoch: 32, loss: 1.292201
global_step: 13276, epoch: 32, loss: 1.172419
global_step: 13277, epoch: 32, loss: 1.181582
global_step: 13278, epoch: 32, loss: 1.214296
global_step: 13279, epoch: 32, loss: 1.113929
global_step: 13280, epoch: 32, loss: 1.719854
epoch: 32
train	acc: 0.6406	macro: p 0.4423, r 0.3499, f1: 0.3632	micro: p 0.6406, r 0.6406, f1 0.6406	weighted_f1:0.5952
dev	acc: 0.5473	macro: p 0.3438, r 0.2925, f1: 0.2801	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4802
test	acc: 0.6011	macro: p 0.3871, r 0.3070, f1: 0.3086	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5476
global_step: 13281, epoch: 33, loss: 1.119178
global_step: 13282, epoch: 33, loss: 1.239855
global_step: 13283, epoch: 33, loss: 1.150818
global_step: 13284, epoch: 33, loss: 1.105537
global_step: 13285, epoch: 33, loss: 1.170780
global_step: 13286, epoch: 33, loss: 1.107764
global_step: 13287, epoch: 33, loss: 1.133668
global_step: 13288, epoch: 33, loss: 1.182272
global_step: 13289, epoch: 33, loss: 1.238046
global_step: 13290, epoch: 33, loss: 1.097311
global_step: 13291, epoch: 33, loss: 1.146873
global_step: 13292, epoch: 33, loss: 1.213651
global_step: 13293, epoch: 33, loss: 1.168165
global_step: 13294, epoch: 33, loss: 1.127743
global_step: 13295, epoch: 33, loss: 1.169040
global_step: 13296, epoch: 33, loss: 1.192829
global_step: 13297, epoch: 33, loss: 1.097093
global_step: 13298, epoch: 33, loss: 1.165471
global_step: 13299, epoch: 33, loss: 1.221779
global_step: 13300, epoch: 33, loss: 1.077585
global_step: 13301, epoch: 33, loss: 1.140584
global_step: 13302, epoch: 33, loss: 1.055998
global_step: 13303, epoch: 33, loss: 1.088426
global_step: 13304, epoch: 33, loss: 1.119051
global_step: 13305, epoch: 33, loss: 1.103457
global_step: 13306, epoch: 33, loss: 0.988252
global_step: 13307, epoch: 33, loss: 1.062443
global_step: 13308, epoch: 33, loss: 1.120856
global_step: 13309, epoch: 33, loss: 1.133572
global_step: 13310, epoch: 33, loss: 0.983103
global_step: 13311, epoch: 33, loss: 1.238774
global_step: 13312, epoch: 33, loss: 1.081412
global_step: 13313, epoch: 33, loss: 1.160919
global_step: 13314, epoch: 33, loss: 1.171732
global_step: 13315, epoch: 33, loss: 1.147663
global_step: 13316, epoch: 33, loss: 1.164801
global_step: 13317, epoch: 33, loss: 1.132407
global_step: 13318, epoch: 33, loss: 1.191482
global_step: 13319, epoch: 33, loss: 1.124534
global_step: 13320, epoch: 33, loss: 1.265952
epoch: 33
train	acc: 0.6422	macro: p 0.4465, r 0.3517, f1: 0.3655	micro: p 0.6422, r 0.6422, f1 0.6422	weighted_f1:0.5964
dev	acc: 0.5491	macro: p 0.3456, r 0.2936, f1: 0.2831	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4825
test	acc: 0.6000	macro: p 0.3842, r 0.3049, f1: 0.3066	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5454
global_step: 13321, epoch: 34, loss: 1.154305
global_step: 13322, epoch: 34, loss: 1.211873
global_step: 13323, epoch: 34, loss: 1.140960
global_step: 13324, epoch: 34, loss: 1.133528
global_step: 13325, epoch: 34, loss: 1.121041
global_step: 13326, epoch: 34, loss: 1.123466
global_step: 13327, epoch: 34, loss: 1.154839
global_step: 13328, epoch: 34, loss: 1.137766
global_step: 13329, epoch: 34, loss: 1.116516
global_step: 13330, epoch: 34, loss: 1.087375
global_step: 13331, epoch: 34, loss: 1.094906
global_step: 13332, epoch: 34, loss: 1.138898
global_step: 13333, epoch: 34, loss: 1.104133
global_step: 13334, epoch: 34, loss: 1.178418
global_step: 13335, epoch: 34, loss: 1.220034
global_step: 13336, epoch: 34, loss: 1.134791
global_step: 13337, epoch: 34, loss: 1.078804
global_step: 13338, epoch: 34, loss: 1.057588
global_step: 13339, epoch: 34, loss: 1.104132
global_step: 13340, epoch: 34, loss: 1.134128
global_step: 13341, epoch: 34, loss: 1.148974
global_step: 13342, epoch: 34, loss: 1.119948
global_step: 13343, epoch: 34, loss: 1.202915
global_step: 13344, epoch: 34, loss: 1.078861
global_step: 13345, epoch: 34, loss: 1.033047
global_step: 13346, epoch: 34, loss: 1.145779
global_step: 13347, epoch: 34, loss: 1.091494
global_step: 13348, epoch: 34, loss: 1.191199
global_step: 13349, epoch: 34, loss: 1.230874
global_step: 13350, epoch: 34, loss: 1.110306
global_step: 13351, epoch: 34, loss: 1.180298
global_step: 13352, epoch: 34, loss: 1.186693
global_step: 13353, epoch: 34, loss: 1.178344
global_step: 13354, epoch: 34, loss: 1.126981
global_step: 13355, epoch: 34, loss: 1.051433
global_step: 13356, epoch: 34, loss: 1.127648
global_step: 13357, epoch: 34, loss: 1.086654
global_step: 13358, epoch: 34, loss: 1.086882
global_step: 13359, epoch: 34, loss: 1.183658
global_step: 13360, epoch: 34, loss: 0.384715
epoch: 34
train	acc: 0.6412	macro: p 0.4469, r 0.3482, f1: 0.3619	micro: p 0.6412, r 0.6412, f1 0.6412	weighted_f1:0.5938
dev	acc: 0.5555	macro: p 0.3566, r 0.2993, f1: 0.2877	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4869
test	acc: 0.5973	macro: p 0.3846, r 0.3020, f1: 0.3017	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5399
global_step: 13361, epoch: 35, loss: 1.068287
global_step: 13362, epoch: 35, loss: 1.157005
global_step: 13363, epoch: 35, loss: 1.122763
global_step: 13364, epoch: 35, loss: 1.156809
global_step: 13365, epoch: 35, loss: 1.073694
global_step: 13366, epoch: 35, loss: 1.097314
global_step: 13367, epoch: 35, loss: 1.158456
global_step: 13368, epoch: 35, loss: 1.194611
global_step: 13369, epoch: 35, loss: 1.129348
global_step: 13370, epoch: 35, loss: 1.206369
global_step: 13371, epoch: 35, loss: 1.245489
global_step: 13372, epoch: 35, loss: 1.253715
global_step: 13373, epoch: 35, loss: 1.104459
global_step: 13374, epoch: 35, loss: 1.255953
global_step: 13375, epoch: 35, loss: 1.094211
global_step: 13376, epoch: 35, loss: 1.089494
global_step: 13377, epoch: 35, loss: 1.031466
global_step: 13378, epoch: 35, loss: 1.062920
global_step: 13379, epoch: 35, loss: 1.146772
global_step: 13380, epoch: 35, loss: 1.051577
global_step: 13381, epoch: 35, loss: 1.084958
global_step: 13382, epoch: 35, loss: 1.093665
global_step: 13383, epoch: 35, loss: 1.138348
global_step: 13384, epoch: 35, loss: 1.117877
global_step: 13385, epoch: 35, loss: 1.079449
global_step: 13386, epoch: 35, loss: 1.155398
global_step: 13387, epoch: 35, loss: 1.195492
global_step: 13388, epoch: 35, loss: 1.174569
global_step: 13389, epoch: 35, loss: 1.145142
global_step: 13390, epoch: 35, loss: 1.107035
global_step: 13391, epoch: 35, loss: 1.250002
global_step: 13392, epoch: 35, loss: 1.050862
global_step: 13393, epoch: 35, loss: 1.056271
global_step: 13394, epoch: 35, loss: 1.060674
global_step: 13395, epoch: 35, loss: 1.110075
global_step: 13396, epoch: 35, loss: 1.174539
global_step: 13397, epoch: 35, loss: 1.177910
global_step: 13398, epoch: 35, loss: 1.045027
global_step: 13399, epoch: 35, loss: 0.985647
global_step: 13400, epoch: 35, loss: 1.770367
epoch: 35
train	acc: 0.6569	macro: p 0.4401, r 0.3765, f1: 0.3852	micro: p 0.6569, r 0.6569, f1 0.6569	weighted_f1:0.6160
dev	acc: 0.5491	macro: p 0.3395, r 0.3037, f1: 0.2934	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4896
test	acc: 0.5989	macro: p 0.3722, r 0.3135, f1: 0.3121	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5491
New best model!
global_step: 13401, epoch: 36, loss: 1.068417
global_step: 13402, epoch: 36, loss: 1.126663
global_step: 13403, epoch: 36, loss: 1.197271
global_step: 13404, epoch: 36, loss: 1.050740
global_step: 13405, epoch: 36, loss: 1.168565
global_step: 13406, epoch: 36, loss: 1.150050
global_step: 13407, epoch: 36, loss: 1.072291
global_step: 13408, epoch: 36, loss: 1.028406
global_step: 13409, epoch: 36, loss: 1.124533
global_step: 13410, epoch: 36, loss: 1.167272
global_step: 13411, epoch: 36, loss: 1.117665
global_step: 13412, epoch: 36, loss: 1.096287
global_step: 13413, epoch: 36, loss: 1.031862
global_step: 13414, epoch: 36, loss: 1.133795
global_step: 13415, epoch: 36, loss: 1.080005
global_step: 13416, epoch: 36, loss: 1.075243
global_step: 13417, epoch: 36, loss: 1.013919
global_step: 13418, epoch: 36, loss: 1.099644
global_step: 13419, epoch: 36, loss: 1.120819
global_step: 13420, epoch: 36, loss: 1.203173
global_step: 13421, epoch: 36, loss: 1.213241
global_step: 13422, epoch: 36, loss: 1.108287
global_step: 13423, epoch: 36, loss: 1.026618
global_step: 13424, epoch: 36, loss: 1.098969
global_step: 13425, epoch: 36, loss: 1.110936
global_step: 13426, epoch: 36, loss: 1.126856
global_step: 13427, epoch: 36, loss: 1.100914
global_step: 13428, epoch: 36, loss: 1.056234
global_step: 13429, epoch: 36, loss: 1.181873
global_step: 13430, epoch: 36, loss: 1.129177
global_step: 13431, epoch: 36, loss: 1.142578
global_step: 13432, epoch: 36, loss: 1.168138
global_step: 13433, epoch: 36, loss: 0.995957
global_step: 13434, epoch: 36, loss: 1.111481
global_step: 13435, epoch: 36, loss: 1.202324
global_step: 13436, epoch: 36, loss: 1.112720
global_step: 13437, epoch: 36, loss: 1.200834
global_step: 13438, epoch: 36, loss: 1.042599
global_step: 13439, epoch: 36, loss: 1.040268
global_step: 13440, epoch: 36, loss: 1.444593
epoch: 36
train	acc: 0.6603	macro: p 0.4473, r 0.3810, f1: 0.3933	micro: p 0.6603, r 0.6603, f1 0.6603	weighted_f1:0.6224
dev	acc: 0.5500	macro: p 0.3393, r 0.3000, f1: 0.2944	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4925
test	acc: 0.6054	macro: p 0.3815, r 0.3176, f1: 0.3221	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5586
New best model!
global_step: 13441, epoch: 37, loss: 1.096368
global_step: 13442, epoch: 37, loss: 1.077288
global_step: 13443, epoch: 37, loss: 1.038133
global_step: 13444, epoch: 37, loss: 1.266036
global_step: 13445, epoch: 37, loss: 1.137389
global_step: 13446, epoch: 37, loss: 1.176926
global_step: 13447, epoch: 37, loss: 1.115387
global_step: 13448, epoch: 37, loss: 1.009658
global_step: 13449, epoch: 37, loss: 1.100274
global_step: 13450, epoch: 37, loss: 1.156009
global_step: 13451, epoch: 37, loss: 0.973400
global_step: 13452, epoch: 37, loss: 1.047560
global_step: 13453, epoch: 37, loss: 1.160332
global_step: 13454, epoch: 37, loss: 1.173460
global_step: 13455, epoch: 37, loss: 1.058887
global_step: 13456, epoch: 37, loss: 0.951607
global_step: 13457, epoch: 37, loss: 1.171551
global_step: 13458, epoch: 37, loss: 1.161311
global_step: 13459, epoch: 37, loss: 1.026565
global_step: 13460, epoch: 37, loss: 1.168016
global_step: 13461, epoch: 37, loss: 1.014489
global_step: 13462, epoch: 37, loss: 1.160892
global_step: 13463, epoch: 37, loss: 1.072436
global_step: 13464, epoch: 37, loss: 1.079077
global_step: 13465, epoch: 37, loss: 0.998988
global_step: 13466, epoch: 37, loss: 1.024499
global_step: 13467, epoch: 37, loss: 1.094653
global_step: 13468, epoch: 37, loss: 1.077340
global_step: 13469, epoch: 37, loss: 1.217491
global_step: 13470, epoch: 37, loss: 1.111336
global_step: 13471, epoch: 37, loss: 1.226333
global_step: 13472, epoch: 37, loss: 1.119415
global_step: 13473, epoch: 37, loss: 1.088703
global_step: 13474, epoch: 37, loss: 1.107856
global_step: 13475, epoch: 37, loss: 1.201977
global_step: 13476, epoch: 37, loss: 1.152003
global_step: 13477, epoch: 37, loss: 1.033504
global_step: 13478, epoch: 37, loss: 1.186114
global_step: 13479, epoch: 37, loss: 1.074235
global_step: 13480, epoch: 37, loss: 0.622721
epoch: 37
train	acc: 0.6570	macro: p 0.4541, r 0.3681, f1: 0.3809	micro: p 0.6570, r 0.6570, f1 0.6570	weighted_f1:0.6131
dev	acc: 0.5546	macro: p 0.3448, r 0.3013, f1: 0.2921	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4910
test	acc: 0.6004	macro: p 0.3808, r 0.3080, f1: 0.3094	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5476
global_step: 13481, epoch: 38, loss: 1.075077
global_step: 13482, epoch: 38, loss: 1.152614
global_step: 13483, epoch: 38, loss: 1.142331
global_step: 13484, epoch: 38, loss: 1.086153
global_step: 13485, epoch: 38, loss: 0.959513
global_step: 13486, epoch: 38, loss: 1.133002
global_step: 13487, epoch: 38, loss: 1.086158
global_step: 13488, epoch: 38, loss: 1.101864
global_step: 13489, epoch: 38, loss: 1.049642
global_step: 13490, epoch: 38, loss: 1.058004
global_step: 13491, epoch: 38, loss: 1.195038
global_step: 13492, epoch: 38, loss: 1.111029
global_step: 13493, epoch: 38, loss: 1.116791
global_step: 13494, epoch: 38, loss: 1.035576
global_step: 13495, epoch: 38, loss: 1.097232
global_step: 13496, epoch: 38, loss: 1.169464
global_step: 13497, epoch: 38, loss: 1.092036
global_step: 13498, epoch: 38, loss: 1.144505
global_step: 13499, epoch: 38, loss: 1.121904
global_step: 13500, epoch: 38, loss: 1.050822
global_step: 13501, epoch: 38, loss: 1.103608
global_step: 13502, epoch: 38, loss: 0.987121
global_step: 13503, epoch: 38, loss: 1.183016
global_step: 13504, epoch: 38, loss: 1.185456
global_step: 13505, epoch: 38, loss: 1.086086
global_step: 13506, epoch: 38, loss: 1.046386
global_step: 13507, epoch: 38, loss: 1.010930
global_step: 13508, epoch: 38, loss: 1.146187
global_step: 13509, epoch: 38, loss: 1.160679
global_step: 13510, epoch: 38, loss: 1.161515
global_step: 13511, epoch: 38, loss: 1.059247
global_step: 13512, epoch: 38, loss: 0.972742
global_step: 13513, epoch: 38, loss: 1.122761
global_step: 13514, epoch: 38, loss: 1.093347
global_step: 13515, epoch: 38, loss: 1.121431
global_step: 13516, epoch: 38, loss: 1.058112
global_step: 13517, epoch: 38, loss: 1.114784
global_step: 13518, epoch: 38, loss: 1.091277
global_step: 13519, epoch: 38, loss: 1.131461
global_step: 13520, epoch: 38, loss: 0.601745
epoch: 38
train	acc: 0.6581	macro: p 0.4539, r 0.3698, f1: 0.3836	micro: p 0.6581, r 0.6581, f1 0.6581	weighted_f1:0.6150
dev	acc: 0.5564	macro: p 0.3489, r 0.3040, f1: 0.2911	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4899
test	acc: 0.5996	macro: p 0.3793, r 0.3080, f1: 0.3074	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5454
global_step: 13521, epoch: 39, loss: 1.046879
global_step: 13522, epoch: 39, loss: 1.019467
global_step: 13523, epoch: 39, loss: 1.030532
global_step: 13524, epoch: 39, loss: 1.077411
global_step: 13525, epoch: 39, loss: 1.088278
global_step: 13526, epoch: 39, loss: 1.108835
global_step: 13527, epoch: 39, loss: 1.001082
global_step: 13528, epoch: 39, loss: 1.115845
global_step: 13529, epoch: 39, loss: 0.983325
global_step: 13530, epoch: 39, loss: 1.165986
global_step: 13531, epoch: 39, loss: 1.109221
global_step: 13532, epoch: 39, loss: 0.972977
global_step: 13533, epoch: 39, loss: 1.110035
global_step: 13534, epoch: 39, loss: 0.940251
global_step: 13535, epoch: 39, loss: 1.122913
global_step: 13536, epoch: 39, loss: 1.065815
global_step: 13537, epoch: 39, loss: 1.157684
global_step: 13538, epoch: 39, loss: 1.019404
global_step: 13539, epoch: 39, loss: 1.068389
global_step: 13540, epoch: 39, loss: 1.051332
global_step: 13541, epoch: 39, loss: 1.171302
global_step: 13542, epoch: 39, loss: 1.214824
global_step: 13543, epoch: 39, loss: 1.165003
global_step: 13544, epoch: 39, loss: 1.048530
global_step: 13545, epoch: 39, loss: 1.223590
global_step: 13546, epoch: 39, loss: 1.071939
global_step: 13547, epoch: 39, loss: 1.031579
global_step: 13548, epoch: 39, loss: 1.195691
global_step: 13549, epoch: 39, loss: 1.135422
global_step: 13550, epoch: 39, loss: 1.149660
global_step: 13551, epoch: 39, loss: 1.019724
global_step: 13552, epoch: 39, loss: 1.172771
global_step: 13553, epoch: 39, loss: 1.106308
global_step: 13554, epoch: 39, loss: 1.021775
global_step: 13555, epoch: 39, loss: 1.094389
global_step: 13556, epoch: 39, loss: 1.125224
global_step: 13557, epoch: 39, loss: 1.150802
global_step: 13558, epoch: 39, loss: 1.133497
global_step: 13559, epoch: 39, loss: 1.117903
global_step: 13560, epoch: 39, loss: 2.607935
epoch: 39
train	acc: 0.6716	macro: p 0.4539, r 0.3909, f1: 0.4048	micro: p 0.6716, r 0.6716, f1 0.6716	weighted_f1:0.6343
dev	acc: 0.5591	macro: p 0.3487, r 0.3083, f1: 0.3003	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.5001
test	acc: 0.6027	macro: p 0.3732, r 0.3179, f1: 0.3204	micro: p 0.6027, r 0.6027, f1 0.6027	weighted_f1:0.5552
New best model!
global_step: 13561, epoch: 40, loss: 1.103032
global_step: 13562, epoch: 40, loss: 1.156584
global_step: 13563, epoch: 40, loss: 1.207874
global_step: 13564, epoch: 40, loss: 1.157865
global_step: 13565, epoch: 40, loss: 1.094104
global_step: 13566, epoch: 40, loss: 1.081114
global_step: 13567, epoch: 40, loss: 1.093254
global_step: 13568, epoch: 40, loss: 0.956852
global_step: 13569, epoch: 40, loss: 1.011120
global_step: 13570, epoch: 40, loss: 0.941881
global_step: 13571, epoch: 40, loss: 1.174819
global_step: 13572, epoch: 40, loss: 1.093136
global_step: 13573, epoch: 40, loss: 1.069447
global_step: 13574, epoch: 40, loss: 1.136657
global_step: 13575, epoch: 40, loss: 1.035290
global_step: 13576, epoch: 40, loss: 1.078007
global_step: 13577, epoch: 40, loss: 1.126018
global_step: 13578, epoch: 40, loss: 1.177335
global_step: 13579, epoch: 40, loss: 1.077911
global_step: 13580, epoch: 40, loss: 1.342892
global_step: 13581, epoch: 40, loss: 1.013107
global_step: 13582, epoch: 40, loss: 1.031003
global_step: 13583, epoch: 40, loss: 0.964755
global_step: 13584, epoch: 40, loss: 1.085182
global_step: 13585, epoch: 40, loss: 1.055881
global_step: 13586, epoch: 40, loss: 1.117680
global_step: 13587, epoch: 40, loss: 1.190544
global_step: 13588, epoch: 40, loss: 1.061103
global_step: 13589, epoch: 40, loss: 1.036514
global_step: 13590, epoch: 40, loss: 1.026906
global_step: 13591, epoch: 40, loss: 1.123383
global_step: 13592, epoch: 40, loss: 0.957234
global_step: 13593, epoch: 40, loss: 0.981414
global_step: 13594, epoch: 40, loss: 1.107464
global_step: 13595, epoch: 40, loss: 1.214353
global_step: 13596, epoch: 40, loss: 1.025548
global_step: 13597, epoch: 40, loss: 1.048407
global_step: 13598, epoch: 40, loss: 1.132017
global_step: 13599, epoch: 40, loss: 1.113211
global_step: 13600, epoch: 40, loss: 1.008214
epoch: 40
train	acc: 0.6709	macro: p 0.4561, r 0.3912, f1: 0.4052	micro: p 0.6709, r 0.6709, f1 0.6709	weighted_f1:0.6332
dev	acc: 0.5573	macro: p 0.3455, r 0.3067, f1: 0.3019	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.5000
test	acc: 0.6046	macro: p 0.3822, r 0.3182, f1: 0.3237	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5577
global_step: 13601, epoch: 41, loss: 1.153949
global_step: 13602, epoch: 41, loss: 1.060840
global_step: 13603, epoch: 41, loss: 1.067095
global_step: 13604, epoch: 41, loss: 1.172216
global_step: 13605, epoch: 41, loss: 0.988979
global_step: 13606, epoch: 41, loss: 1.026381
global_step: 13607, epoch: 41, loss: 1.168237
global_step: 13608, epoch: 41, loss: 0.986800
global_step: 13609, epoch: 41, loss: 1.172342
global_step: 13610, epoch: 41, loss: 1.062176
global_step: 13611, epoch: 41, loss: 1.030322
global_step: 13612, epoch: 41, loss: 1.159646
global_step: 13613, epoch: 41, loss: 1.107485
global_step: 13614, epoch: 41, loss: 1.122499
global_step: 13615, epoch: 41, loss: 1.102617
global_step: 13616, epoch: 41, loss: 1.004547
global_step: 13617, epoch: 41, loss: 1.058480
global_step: 13618, epoch: 41, loss: 1.088592
global_step: 13619, epoch: 41, loss: 1.145085
global_step: 13620, epoch: 41, loss: 0.935436
global_step: 13621, epoch: 41, loss: 1.093553
global_step: 13622, epoch: 41, loss: 1.005230
global_step: 13623, epoch: 41, loss: 1.130491
global_step: 13624, epoch: 41, loss: 1.152960
global_step: 13625, epoch: 41, loss: 1.137391
global_step: 13626, epoch: 41, loss: 0.999423
global_step: 13627, epoch: 41, loss: 1.180493
global_step: 13628, epoch: 41, loss: 1.099618
global_step: 13629, epoch: 41, loss: 1.015840
global_step: 13630, epoch: 41, loss: 1.107977
global_step: 13631, epoch: 41, loss: 1.072549
global_step: 13632, epoch: 41, loss: 1.046944
global_step: 13633, epoch: 41, loss: 1.008958
global_step: 13634, epoch: 41, loss: 1.105146
global_step: 13635, epoch: 41, loss: 1.209686
global_step: 13636, epoch: 41, loss: 0.996958
global_step: 13637, epoch: 41, loss: 1.084300
global_step: 13638, epoch: 41, loss: 1.129562
global_step: 13639, epoch: 41, loss: 1.009114
global_step: 13640, epoch: 41, loss: 0.665181
epoch: 41
train	acc: 0.6655	macro: p 0.4609, r 0.3815, f1: 0.3958	micro: p 0.6655, r 0.6655, f1 0.6655	weighted_f1:0.6255
dev	acc: 0.5546	macro: p 0.3520, r 0.3013, f1: 0.2968	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4950
test	acc: 0.6061	macro: p 0.3925, r 0.3170, f1: 0.3238	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5583
global_step: 13641, epoch: 42, loss: 1.100500
global_step: 13642, epoch: 42, loss: 1.181967
global_step: 13643, epoch: 42, loss: 1.050083
global_step: 13644, epoch: 42, loss: 1.094087
global_step: 13645, epoch: 42, loss: 1.096287
global_step: 13646, epoch: 42, loss: 1.079661
global_step: 13647, epoch: 42, loss: 1.041342
global_step: 13648, epoch: 42, loss: 1.039144
global_step: 13649, epoch: 42, loss: 1.001950
global_step: 13650, epoch: 42, loss: 1.113840
global_step: 13651, epoch: 42, loss: 1.071359
global_step: 13652, epoch: 42, loss: 1.095387
global_step: 13653, epoch: 42, loss: 1.040755
global_step: 13654, epoch: 42, loss: 1.016945
global_step: 13655, epoch: 42, loss: 0.996423
global_step: 13656, epoch: 42, loss: 1.028105
global_step: 13657, epoch: 42, loss: 0.983014
global_step: 13658, epoch: 42, loss: 1.090457
global_step: 13659, epoch: 42, loss: 1.068754
global_step: 13660, epoch: 42, loss: 1.052887
global_step: 13661, epoch: 42, loss: 1.044960
global_step: 13662, epoch: 42, loss: 1.143114
global_step: 13663, epoch: 42, loss: 1.090136
global_step: 13664, epoch: 42, loss: 1.037247
global_step: 13665, epoch: 42, loss: 1.078595
global_step: 13666, epoch: 42, loss: 1.074435
global_step: 13667, epoch: 42, loss: 1.043314
global_step: 13668, epoch: 42, loss: 1.179688
global_step: 13669, epoch: 42, loss: 1.103768
global_step: 13670, epoch: 42, loss: 1.001698
global_step: 13671, epoch: 42, loss: 1.065227
global_step: 13672, epoch: 42, loss: 1.129047
global_step: 13673, epoch: 42, loss: 1.179594
global_step: 13674, epoch: 42, loss: 0.996476
global_step: 13675, epoch: 42, loss: 0.924612
global_step: 13676, epoch: 42, loss: 0.992646
global_step: 13677, epoch: 42, loss: 1.101177
global_step: 13678, epoch: 42, loss: 1.171399
global_step: 13679, epoch: 42, loss: 1.099957
global_step: 13680, epoch: 42, loss: 0.988014
epoch: 42
train	acc: 0.6750	macro: p 0.4659, r 0.3918, f1: 0.4047	micro: p 0.6750, r 0.6750, f1 0.6750	weighted_f1:0.6354
dev	acc: 0.5509	macro: p 0.3404, r 0.3010, f1: 0.2958	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4928
test	acc: 0.6077	macro: p 0.3904, r 0.3203, f1: 0.3256	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5603
global_step: 13681, epoch: 43, loss: 1.030749
global_step: 13682, epoch: 43, loss: 0.998328
global_step: 13683, epoch: 43, loss: 1.205822
global_step: 13684, epoch: 43, loss: 1.084835
global_step: 13685, epoch: 43, loss: 1.135186
global_step: 13686, epoch: 43, loss: 1.024863
global_step: 13687, epoch: 43, loss: 0.972286
global_step: 13688, epoch: 43, loss: 1.084052
global_step: 13689, epoch: 43, loss: 0.999346
global_step: 13690, epoch: 43, loss: 1.040648
global_step: 13691, epoch: 43, loss: 1.061196
global_step: 13692, epoch: 43, loss: 1.051595
global_step: 13693, epoch: 43, loss: 1.148673
global_step: 13694, epoch: 43, loss: 1.134273
global_step: 13695, epoch: 43, loss: 1.117018
global_step: 13696, epoch: 43, loss: 1.118389
global_step: 13697, epoch: 43, loss: 1.044078
global_step: 13698, epoch: 43, loss: 1.018606
global_step: 13699, epoch: 43, loss: 0.975558
global_step: 13700, epoch: 43, loss: 1.123447
global_step: 13701, epoch: 43, loss: 1.086275
global_step: 13702, epoch: 43, loss: 0.965621
global_step: 13703, epoch: 43, loss: 1.141613
global_step: 13704, epoch: 43, loss: 1.029852
global_step: 13705, epoch: 43, loss: 1.054397
global_step: 13706, epoch: 43, loss: 1.159134
global_step: 13707, epoch: 43, loss: 1.015716
global_step: 13708, epoch: 43, loss: 1.157888
global_step: 13709, epoch: 43, loss: 1.000557
global_step: 13710, epoch: 43, loss: 1.029003
global_step: 13711, epoch: 43, loss: 1.026742
global_step: 13712, epoch: 43, loss: 1.069350
global_step: 13713, epoch: 43, loss: 0.912011
global_step: 13714, epoch: 43, loss: 1.066766
global_step: 13715, epoch: 43, loss: 1.115165
global_step: 13716, epoch: 43, loss: 1.047363
global_step: 13717, epoch: 43, loss: 1.077151
global_step: 13718, epoch: 43, loss: 1.152049
global_step: 13719, epoch: 43, loss: 1.140044
global_step: 13720, epoch: 43, loss: 0.781637
epoch: 43
train	acc: 0.6854	macro: p 0.4679, r 0.4086, f1: 0.4212	micro: p 0.6854, r 0.6854, f1 0.6854	weighted_f1:0.6505
dev	acc: 0.5537	macro: p 0.3426, r 0.3089, f1: 0.3052	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.5013
test	acc: 0.6015	macro: p 0.3715, r 0.3175, f1: 0.3223	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5566
New best model!
global_step: 13721, epoch: 44, loss: 1.025403
global_step: 13722, epoch: 44, loss: 1.113027
global_step: 13723, epoch: 44, loss: 1.136605
global_step: 13724, epoch: 44, loss: 1.064140
global_step: 13725, epoch: 44, loss: 1.042903
global_step: 13726, epoch: 44, loss: 1.102910
global_step: 13727, epoch: 44, loss: 1.131603
global_step: 13728, epoch: 44, loss: 1.000130
global_step: 13729, epoch: 44, loss: 1.051774
global_step: 13730, epoch: 44, loss: 1.135069
global_step: 13731, epoch: 44, loss: 0.994243
global_step: 13732, epoch: 44, loss: 1.017504
global_step: 13733, epoch: 44, loss: 1.153499
global_step: 13734, epoch: 44, loss: 1.040791
global_step: 13735, epoch: 44, loss: 1.119308
global_step: 13736, epoch: 44, loss: 0.938107
global_step: 13737, epoch: 44, loss: 1.086985
global_step: 13738, epoch: 44, loss: 0.994196
global_step: 13739, epoch: 44, loss: 0.991735
global_step: 13740, epoch: 44, loss: 0.955426
global_step: 13741, epoch: 44, loss: 1.118920
global_step: 13742, epoch: 44, loss: 1.059852
global_step: 13743, epoch: 44, loss: 1.012482
global_step: 13744, epoch: 44, loss: 1.008676
global_step: 13745, epoch: 44, loss: 1.054085
global_step: 13746, epoch: 44, loss: 1.099375
global_step: 13747, epoch: 44, loss: 1.097423
global_step: 13748, epoch: 44, loss: 1.001297
global_step: 13749, epoch: 44, loss: 1.029676
global_step: 13750, epoch: 44, loss: 1.109025
global_step: 13751, epoch: 44, loss: 1.067352
global_step: 13752, epoch: 44, loss: 1.055735
global_step: 13753, epoch: 44, loss: 1.035536
global_step: 13754, epoch: 44, loss: 1.183148
global_step: 13755, epoch: 44, loss: 1.076345
global_step: 13756, epoch: 44, loss: 1.033589
global_step: 13757, epoch: 44, loss: 1.119901
global_step: 13758, epoch: 44, loss: 0.937449
global_step: 13759, epoch: 44, loss: 0.995218
global_step: 13760, epoch: 44, loss: 0.663808
epoch: 44
train	acc: 0.6798	macro: p 0.4735, r 0.3943, f1: 0.4082	micro: p 0.6798, r 0.6798, f1 0.6798	weighted_f1:0.6404
dev	acc: 0.5509	macro: p 0.3412, r 0.3005, f1: 0.2929	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4908
test	acc: 0.6054	macro: p 0.3856, r 0.3164, f1: 0.3203	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5564
global_step: 13761, epoch: 45, loss: 1.051470
global_step: 13762, epoch: 45, loss: 1.055151
global_step: 13763, epoch: 45, loss: 1.046447
global_step: 13764, epoch: 45, loss: 1.043551
global_step: 13765, epoch: 45, loss: 1.006525
global_step: 13766, epoch: 45, loss: 1.006331
global_step: 13767, epoch: 45, loss: 1.061888
global_step: 13768, epoch: 45, loss: 1.019881
global_step: 13769, epoch: 45, loss: 1.074425
global_step: 13770, epoch: 45, loss: 0.977559
global_step: 13771, epoch: 45, loss: 1.163394
global_step: 13772, epoch: 45, loss: 1.025529
global_step: 13773, epoch: 45, loss: 1.031801
global_step: 13774, epoch: 45, loss: 0.958723
global_step: 13775, epoch: 45, loss: 1.108752
global_step: 13776, epoch: 45, loss: 1.052429
global_step: 13777, epoch: 45, loss: 1.037058
global_step: 13778, epoch: 45, loss: 1.109252
global_step: 13779, epoch: 45, loss: 0.973069
global_step: 13780, epoch: 45, loss: 1.082952
global_step: 13781, epoch: 45, loss: 1.033469
global_step: 13782, epoch: 45, loss: 0.867757
global_step: 13783, epoch: 45, loss: 1.145392
global_step: 13784, epoch: 45, loss: 1.097952
global_step: 13785, epoch: 45, loss: 1.053485
global_step: 13786, epoch: 45, loss: 0.950573
global_step: 13787, epoch: 45, loss: 1.021085
global_step: 13788, epoch: 45, loss: 1.066239
global_step: 13789, epoch: 45, loss: 0.983254
global_step: 13790, epoch: 45, loss: 1.093063
global_step: 13791, epoch: 45, loss: 1.016391
global_step: 13792, epoch: 45, loss: 1.024277
global_step: 13793, epoch: 45, loss: 1.040936
global_step: 13794, epoch: 45, loss: 1.077628
global_step: 13795, epoch: 45, loss: 1.039387
global_step: 13796, epoch: 45, loss: 1.072231
global_step: 13797, epoch: 45, loss: 1.110689
global_step: 13798, epoch: 45, loss: 1.003542
global_step: 13799, epoch: 45, loss: 1.056980
global_step: 13800, epoch: 45, loss: 1.235549
epoch: 45
train	acc: 0.6974	macro: p 0.4754, r 0.4204, f1: 0.4328	micro: p 0.6974, r 0.6974, f1 0.6974	weighted_f1:0.6635
dev	acc: 0.5509	macro: p 0.3383, r 0.3078, f1: 0.3021	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4982
test	acc: 0.6038	macro: p 0.3673, r 0.3214, f1: 0.3251	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5595
global_step: 13801, epoch: 46, loss: 1.039056
global_step: 13802, epoch: 46, loss: 0.911733
global_step: 13803, epoch: 46, loss: 1.031608
global_step: 13804, epoch: 46, loss: 1.002483
global_step: 13805, epoch: 46, loss: 0.956700
global_step: 13806, epoch: 46, loss: 1.033935
global_step: 13807, epoch: 46, loss: 0.952772
global_step: 13808, epoch: 46, loss: 0.961158
global_step: 13809, epoch: 46, loss: 1.037963
global_step: 13810, epoch: 46, loss: 1.057468
global_step: 13811, epoch: 46, loss: 1.048988
global_step: 13812, epoch: 46, loss: 1.074414
global_step: 13813, epoch: 46, loss: 1.015031
global_step: 13814, epoch: 46, loss: 1.021042
global_step: 13815, epoch: 46, loss: 1.012151
global_step: 13816, epoch: 46, loss: 1.050250
global_step: 13817, epoch: 46, loss: 1.055271
global_step: 13818, epoch: 46, loss: 1.129672
global_step: 13819, epoch: 46, loss: 1.121763
global_step: 13820, epoch: 46, loss: 1.095184
global_step: 13821, epoch: 46, loss: 1.021419
global_step: 13822, epoch: 46, loss: 1.103777
global_step: 13823, epoch: 46, loss: 1.029534
global_step: 13824, epoch: 46, loss: 1.036267
global_step: 13825, epoch: 46, loss: 1.121008
global_step: 13826, epoch: 46, loss: 1.054010
global_step: 13827, epoch: 46, loss: 1.022085
global_step: 13828, epoch: 46, loss: 1.130146
global_step: 13829, epoch: 46, loss: 1.110601
global_step: 13830, epoch: 46, loss: 0.922797
global_step: 13831, epoch: 46, loss: 1.026850
global_step: 13832, epoch: 46, loss: 1.037981
global_step: 13833, epoch: 46, loss: 1.146523
global_step: 13834, epoch: 46, loss: 1.018693
global_step: 13835, epoch: 46, loss: 0.960123
global_step: 13836, epoch: 46, loss: 1.040489
global_step: 13837, epoch: 46, loss: 1.041275
global_step: 13838, epoch: 46, loss: 1.112760
global_step: 13839, epoch: 46, loss: 1.037984
global_step: 13840, epoch: 46, loss: 0.740478
epoch: 46
train	acc: 0.6924	macro: p 0.4766, r 0.4147, f1: 0.4309	micro: p 0.6924, r 0.6924, f1 0.6924	weighted_f1:0.6573
dev	acc: 0.5518	macro: p 0.3386, r 0.3036, f1: 0.3004	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4968
test	acc: 0.6065	macro: p 0.3675, r 0.3203, f1: 0.3257	micro: p 0.6065, r 0.6065, f1 0.6065	weighted_f1:0.5604
global_step: 13841, epoch: 47, loss: 1.065709
global_step: 13842, epoch: 47, loss: 1.075381
global_step: 13843, epoch: 47, loss: 0.927046
global_step: 13844, epoch: 47, loss: 0.999736
global_step: 13845, epoch: 47, loss: 1.086729
global_step: 13846, epoch: 47, loss: 1.115746
global_step: 13847, epoch: 47, loss: 1.003938
global_step: 13848, epoch: 47, loss: 1.159925
global_step: 13849, epoch: 47, loss: 1.066261
global_step: 13850, epoch: 47, loss: 1.023376
global_step: 13851, epoch: 47, loss: 0.963310
global_step: 13852, epoch: 47, loss: 1.139476
global_step: 13853, epoch: 47, loss: 1.051995
global_step: 13854, epoch: 47, loss: 1.066482
global_step: 13855, epoch: 47, loss: 1.018727
global_step: 13856, epoch: 47, loss: 1.004237
global_step: 13857, epoch: 47, loss: 0.915950
global_step: 13858, epoch: 47, loss: 1.044096
global_step: 13859, epoch: 47, loss: 0.986278
global_step: 13860, epoch: 47, loss: 1.067796
global_step: 13861, epoch: 47, loss: 1.027316
global_step: 13862, epoch: 47, loss: 1.088769
global_step: 13863, epoch: 47, loss: 1.055444
global_step: 13864, epoch: 47, loss: 1.040063
global_step: 13865, epoch: 47, loss: 1.038647
global_step: 13866, epoch: 47, loss: 1.103800
global_step: 13867, epoch: 47, loss: 1.070774
global_step: 13868, epoch: 47, loss: 0.980041
global_step: 13869, epoch: 47, loss: 1.170771
global_step: 13870, epoch: 47, loss: 0.965588
global_step: 13871, epoch: 47, loss: 0.943574
global_step: 13872, epoch: 47, loss: 0.991309
global_step: 13873, epoch: 47, loss: 0.983865
global_step: 13874, epoch: 47, loss: 1.100993
global_step: 13875, epoch: 47, loss: 1.026645
global_step: 13876, epoch: 47, loss: 1.088602
global_step: 13877, epoch: 47, loss: 0.984755
global_step: 13878, epoch: 47, loss: 0.983850
global_step: 13879, epoch: 47, loss: 0.960980
global_step: 13880, epoch: 47, loss: 1.644719
epoch: 47
train	acc: 0.6973	macro: p 0.4832, r 0.4203, f1: 0.4334	micro: p 0.6973, r 0.6973, f1 0.6973	weighted_f1:0.6627
dev	acc: 0.5482	macro: p 0.3358, r 0.3040, f1: 0.2997	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4950
test	acc: 0.6050	macro: p 0.3766, r 0.3215, f1: 0.3267	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5602
global_step: 13881, epoch: 48, loss: 1.090384
global_step: 13882, epoch: 48, loss: 1.031708
global_step: 13883, epoch: 48, loss: 0.992526
global_step: 13884, epoch: 48, loss: 0.993289
global_step: 13885, epoch: 48, loss: 0.985123
global_step: 13886, epoch: 48, loss: 1.074039
global_step: 13887, epoch: 48, loss: 0.978359
global_step: 13888, epoch: 48, loss: 0.943583
global_step: 13889, epoch: 48, loss: 0.984685
global_step: 13890, epoch: 48, loss: 1.016330
global_step: 13891, epoch: 48, loss: 0.990650
global_step: 13892, epoch: 48, loss: 0.981249
global_step: 13893, epoch: 48, loss: 1.045376
global_step: 13894, epoch: 48, loss: 1.063517
global_step: 13895, epoch: 48, loss: 0.974835
global_step: 13896, epoch: 48, loss: 1.033901
global_step: 13897, epoch: 48, loss: 1.037779
global_step: 13898, epoch: 48, loss: 1.051165
global_step: 13899, epoch: 48, loss: 1.019117
global_step: 13900, epoch: 48, loss: 0.966567
global_step: 13901, epoch: 48, loss: 1.055388
global_step: 13902, epoch: 48, loss: 1.050515
global_step: 13903, epoch: 48, loss: 1.065655
global_step: 13904, epoch: 48, loss: 1.001134
global_step: 13905, epoch: 48, loss: 1.013428
global_step: 13906, epoch: 48, loss: 1.092276
global_step: 13907, epoch: 48, loss: 1.118863
global_step: 13908, epoch: 48, loss: 0.988242
global_step: 13909, epoch: 48, loss: 1.037139
global_step: 13910, epoch: 48, loss: 1.068977
global_step: 13911, epoch: 48, loss: 1.011384
global_step: 13912, epoch: 48, loss: 0.992042
global_step: 13913, epoch: 48, loss: 0.984053
global_step: 13914, epoch: 48, loss: 1.136658
global_step: 13915, epoch: 48, loss: 0.997157
global_step: 13916, epoch: 48, loss: 0.994137
global_step: 13917, epoch: 48, loss: 1.033342
global_step: 13918, epoch: 48, loss: 0.965666
global_step: 13919, epoch: 48, loss: 1.060680
global_step: 13920, epoch: 48, loss: 1.175605
epoch: 48
train	acc: 0.7001	macro: p 0.4820, r 0.4201, f1: 0.4352	micro: p 0.7001, r 0.7001, f1 0.7001	weighted_f1:0.6651
dev	acc: 0.5555	macro: p 0.3448, r 0.3064, f1: 0.2982	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4967
test	acc: 0.6034	macro: p 0.3704, r 0.3182, f1: 0.3209	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5557
global_step: 13921, epoch: 49, loss: 1.009265
global_step: 13922, epoch: 49, loss: 1.128678
global_step: 13923, epoch: 49, loss: 1.059858
global_step: 13924, epoch: 49, loss: 1.035868
global_step: 13925, epoch: 49, loss: 1.031682
global_step: 13926, epoch: 49, loss: 1.096239
global_step: 13927, epoch: 49, loss: 1.028062
global_step: 13928, epoch: 49, loss: 1.000471
global_step: 13929, epoch: 49, loss: 1.000235
global_step: 13930, epoch: 49, loss: 1.020378
global_step: 13931, epoch: 49, loss: 1.028310
global_step: 13932, epoch: 49, loss: 1.068876
global_step: 13933, epoch: 49, loss: 1.030547
global_step: 13934, epoch: 49, loss: 0.983235
global_step: 13935, epoch: 49, loss: 1.007656
global_step: 13936, epoch: 49, loss: 0.999985
global_step: 13937, epoch: 49, loss: 1.004480
global_step: 13938, epoch: 49, loss: 1.045224
global_step: 13939, epoch: 49, loss: 0.981381
global_step: 13940, epoch: 49, loss: 1.004349
global_step: 13941, epoch: 49, loss: 1.007521
global_step: 13942, epoch: 49, loss: 1.107568
global_step: 13943, epoch: 49, loss: 1.030239
global_step: 13944, epoch: 49, loss: 0.921793
global_step: 13945, epoch: 49, loss: 1.014386
global_step: 13946, epoch: 49, loss: 1.016684
global_step: 13947, epoch: 49, loss: 0.987316
global_step: 13948, epoch: 49, loss: 0.973274
global_step: 13949, epoch: 49, loss: 1.102566
global_step: 13950, epoch: 49, loss: 0.999677
global_step: 13951, epoch: 49, loss: 1.068265
global_step: 13952, epoch: 49, loss: 0.954980
global_step: 13953, epoch: 49, loss: 0.989747
global_step: 13954, epoch: 49, loss: 0.819881
global_step: 13955, epoch: 49, loss: 0.991339
global_step: 13956, epoch: 49, loss: 1.113633
global_step: 13957, epoch: 49, loss: 1.009080
global_step: 13958, epoch: 49, loss: 1.056216
global_step: 13959, epoch: 49, loss: 0.970964
global_step: 13960, epoch: 49, loss: 0.798231
epoch: 49
train	acc: 0.7116	macro: p 0.4865, r 0.4347, f1: 0.4465	micro: p 0.7116, r 0.7116, f1 0.7116	weighted_f1:0.6783
dev	acc: 0.5528	macro: p 0.3433, r 0.3093, f1: 0.3021	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4988
test	acc: 0.6057	macro: p 0.3775, r 0.3233, f1: 0.3266	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5604
global_step: 13961, epoch: 50, loss: 1.001962
global_step: 13962, epoch: 50, loss: 0.974639
global_step: 13963, epoch: 50, loss: 1.007123
global_step: 13964, epoch: 50, loss: 0.922667
global_step: 13965, epoch: 50, loss: 0.956041
global_step: 13966, epoch: 50, loss: 0.979828
global_step: 13967, epoch: 50, loss: 1.016417
global_step: 13968, epoch: 50, loss: 0.914157
global_step: 13969, epoch: 50, loss: 1.064318
global_step: 13970, epoch: 50, loss: 0.965254
global_step: 13971, epoch: 50, loss: 1.014345
global_step: 13972, epoch: 50, loss: 0.925672
global_step: 13973, epoch: 50, loss: 0.936434
global_step: 13974, epoch: 50, loss: 1.148920
global_step: 13975, epoch: 50, loss: 1.022874
global_step: 13976, epoch: 50, loss: 0.914715
global_step: 13977, epoch: 50, loss: 1.041017
global_step: 13978, epoch: 50, loss: 0.895564
global_step: 13979, epoch: 50, loss: 0.967920
global_step: 13980, epoch: 50, loss: 1.008258
global_step: 13981, epoch: 50, loss: 1.065841
global_step: 13982, epoch: 50, loss: 1.008916
global_step: 13983, epoch: 50, loss: 0.991674
global_step: 13984, epoch: 50, loss: 1.071932
global_step: 13985, epoch: 50, loss: 1.160306
global_step: 13986, epoch: 50, loss: 0.975454
global_step: 13987, epoch: 50, loss: 1.084047
global_step: 13988, epoch: 50, loss: 0.993689
global_step: 13989, epoch: 50, loss: 0.976059
global_step: 13990, epoch: 50, loss: 1.007903
global_step: 13991, epoch: 50, loss: 0.960737
global_step: 13992, epoch: 50, loss: 1.030655
global_step: 13993, epoch: 50, loss: 0.903222
global_step: 13994, epoch: 50, loss: 1.085707
global_step: 13995, epoch: 50, loss: 1.092599
global_step: 13996, epoch: 50, loss: 1.198747
global_step: 13997, epoch: 50, loss: 0.992226
global_step: 13998, epoch: 50, loss: 1.089545
global_step: 13999, epoch: 50, loss: 0.991171
global_step: 14000, epoch: 50, loss: 2.573756
epoch: 50
train	acc: 0.7189	macro: p 0.4931, r 0.4447, f1: 0.4566	micro: p 0.7189, r 0.7189, f1 0.7189	weighted_f1:0.6873
dev	acc: 0.5482	macro: p 0.3336, r 0.3051, f1: 0.2997	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4956
test	acc: 0.6054	macro: p 0.3716, r 0.3233, f1: 0.3281	micro: p 0.6054, r 0.6054, f1 0.6054	weighted_f1:0.5619
global_step: 14001, epoch: 51, loss: 0.926397
global_step: 14002, epoch: 51, loss: 0.971145
global_step: 14003, epoch: 51, loss: 1.075777
global_step: 14004, epoch: 51, loss: 1.033712
global_step: 14005, epoch: 51, loss: 0.990179
global_step: 14006, epoch: 51, loss: 1.071644
global_step: 14007, epoch: 51, loss: 0.942988
global_step: 14008, epoch: 51, loss: 0.937675
global_step: 14009, epoch: 51, loss: 1.023799
global_step: 14010, epoch: 51, loss: 0.969179
global_step: 14011, epoch: 51, loss: 0.934920
global_step: 14012, epoch: 51, loss: 0.908775
global_step: 14013, epoch: 51, loss: 0.905035
global_step: 14014, epoch: 51, loss: 0.949748
global_step: 14015, epoch: 51, loss: 0.929380
global_step: 14016, epoch: 51, loss: 0.941414
global_step: 14017, epoch: 51, loss: 1.005933
global_step: 14018, epoch: 51, loss: 0.992586
global_step: 14019, epoch: 51, loss: 1.125834
global_step: 14020, epoch: 51, loss: 1.053601
global_step: 14021, epoch: 51, loss: 1.041501
global_step: 14022, epoch: 51, loss: 0.901051
global_step: 14023, epoch: 51, loss: 0.849536
global_step: 14024, epoch: 51, loss: 1.025213
global_step: 14025, epoch: 51, loss: 1.080471
global_step: 14026, epoch: 51, loss: 1.068226
global_step: 14027, epoch: 51, loss: 0.992988
global_step: 14028, epoch: 51, loss: 1.004751
global_step: 14029, epoch: 51, loss: 1.002036
global_step: 14030, epoch: 51, loss: 1.019381
global_step: 14031, epoch: 51, loss: 1.027541
global_step: 14032, epoch: 51, loss: 0.953276
global_step: 14033, epoch: 51, loss: 1.011302
global_step: 14034, epoch: 51, loss: 1.046234
global_step: 14035, epoch: 51, loss: 1.081440
global_step: 14036, epoch: 51, loss: 1.077396
global_step: 14037, epoch: 51, loss: 1.006161
global_step: 14038, epoch: 51, loss: 0.966745
global_step: 14039, epoch: 51, loss: 1.039535
global_step: 14040, epoch: 51, loss: 1.013050
epoch: 51
train	acc: 0.7184	macro: p 0.4977, r 0.4406, f1: 0.4532	micro: p 0.7184, r 0.7184, f1 0.7184	weighted_f1:0.6842
dev	acc: 0.5464	macro: p 0.3283, r 0.3027, f1: 0.2941	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4899
test	acc: 0.6046	macro: p 0.3734, r 0.3207, f1: 0.3224	micro: p 0.6046, r 0.6046, f1 0.6046	weighted_f1:0.5574
global_step: 14041, epoch: 52, loss: 1.015174
global_step: 14042, epoch: 52, loss: 1.001706
global_step: 14043, epoch: 52, loss: 1.062084
global_step: 14044, epoch: 52, loss: 0.899822
global_step: 14045, epoch: 52, loss: 0.929585
global_step: 14046, epoch: 52, loss: 1.115952
global_step: 14047, epoch: 52, loss: 0.989116
global_step: 14048, epoch: 52, loss: 0.950644
global_step: 14049, epoch: 52, loss: 0.969480
global_step: 14050, epoch: 52, loss: 0.960915
global_step: 14051, epoch: 52, loss: 0.971337
global_step: 14052, epoch: 52, loss: 1.069860
global_step: 14053, epoch: 52, loss: 0.900944
global_step: 14054, epoch: 52, loss: 1.020561
global_step: 14055, epoch: 52, loss: 1.093948
global_step: 14056, epoch: 52, loss: 0.877090
global_step: 14057, epoch: 52, loss: 1.034192
global_step: 14058, epoch: 52, loss: 1.039416
global_step: 14059, epoch: 52, loss: 1.058413
global_step: 14060, epoch: 52, loss: 1.040540
global_step: 14061, epoch: 52, loss: 0.987046
global_step: 14062, epoch: 52, loss: 0.932957
global_step: 14063, epoch: 52, loss: 1.023508
global_step: 14064, epoch: 52, loss: 1.030028
global_step: 14065, epoch: 52, loss: 0.821546
global_step: 14066, epoch: 52, loss: 1.038483
global_step: 14067, epoch: 52, loss: 0.943294
global_step: 14068, epoch: 52, loss: 0.975972
global_step: 14069, epoch: 52, loss: 0.819188
global_step: 14070, epoch: 52, loss: 0.886150
global_step: 14071, epoch: 52, loss: 1.044872
global_step: 14072, epoch: 52, loss: 1.024975
global_step: 14073, epoch: 52, loss: 1.007843
global_step: 14074, epoch: 52, loss: 0.898217
global_step: 14075, epoch: 52, loss: 0.997231
global_step: 14076, epoch: 52, loss: 1.037910
global_step: 14077, epoch: 52, loss: 0.878589
global_step: 14078, epoch: 52, loss: 1.101159
global_step: 14079, epoch: 52, loss: 1.189263
global_step: 14080, epoch: 52, loss: 0.867147
epoch: 52
train	acc: 0.7140	macro: p 0.4938, r 0.4363, f1: 0.4524	micro: p 0.7140, r 0.7140, f1 0.7140	weighted_f1:0.6806
dev	acc: 0.5509	macro: p 0.3399, r 0.3028, f1: 0.2974	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4938
test	acc: 0.6057	macro: p 0.3724, r 0.3212, f1: 0.3259	micro: p 0.6057, r 0.6057, f1 0.6057	weighted_f1:0.5590
global_step: 14081, epoch: 53, loss: 0.998520
global_step: 14082, epoch: 53, loss: 0.962989
global_step: 14083, epoch: 53, loss: 1.039887
global_step: 14084, epoch: 53, loss: 0.991178
global_step: 14085, epoch: 53, loss: 1.024591
global_step: 14086, epoch: 53, loss: 0.949362
global_step: 14087, epoch: 53, loss: 0.925297
global_step: 14088, epoch: 53, loss: 0.956007
global_step: 14089, epoch: 53, loss: 0.843462
global_step: 14090, epoch: 53, loss: 1.054500
global_step: 14091, epoch: 53, loss: 0.935821
global_step: 14092, epoch: 53, loss: 1.010419
global_step: 14093, epoch: 53, loss: 1.000226
global_step: 14094, epoch: 53, loss: 0.993495
global_step: 14095, epoch: 53, loss: 0.956253
global_step: 14096, epoch: 53, loss: 0.848187
global_step: 14097, epoch: 53, loss: 0.975687
global_step: 14098, epoch: 53, loss: 1.060334
global_step: 14099, epoch: 53, loss: 0.924632
global_step: 14100, epoch: 53, loss: 1.014174
global_step: 14101, epoch: 53, loss: 0.828429
global_step: 14102, epoch: 53, loss: 0.879636
global_step: 14103, epoch: 53, loss: 1.003980
global_step: 14104, epoch: 53, loss: 1.050580
global_step: 14105, epoch: 53, loss: 1.028616
global_step: 14106, epoch: 53, loss: 0.913648
global_step: 14107, epoch: 53, loss: 1.054969
global_step: 14108, epoch: 53, loss: 1.107247
global_step: 14109, epoch: 53, loss: 0.929508
global_step: 14110, epoch: 53, loss: 1.056242
global_step: 14111, epoch: 53, loss: 1.024565
global_step: 14112, epoch: 53, loss: 1.027024
global_step: 14113, epoch: 53, loss: 0.995448
global_step: 14114, epoch: 53, loss: 1.014905
global_step: 14115, epoch: 53, loss: 0.959817
global_step: 14116, epoch: 53, loss: 0.925796
global_step: 14117, epoch: 53, loss: 1.006876
global_step: 14118, epoch: 53, loss: 1.018409
global_step: 14119, epoch: 53, loss: 0.989617
global_step: 14120, epoch: 53, loss: 0.603375
epoch: 53
train	acc: 0.7205	macro: p 0.4987, r 0.4413, f1: 0.4550	micro: p 0.7205, r 0.7205, f1 0.7205	weighted_f1:0.6863
dev	acc: 0.5428	macro: p 0.3272, r 0.2985, f1: 0.2896	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4853
test	acc: 0.6023	macro: p 0.3735, r 0.3171, f1: 0.3190	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5531
global_step: 14121, epoch: 54, loss: 0.990846
global_step: 14122, epoch: 54, loss: 0.983050
global_step: 14123, epoch: 54, loss: 1.097825
global_step: 14124, epoch: 54, loss: 0.991084
global_step: 14125, epoch: 54, loss: 0.911310
global_step: 14126, epoch: 54, loss: 1.016373
global_step: 14127, epoch: 54, loss: 0.833922
global_step: 14128, epoch: 54, loss: 0.849966
global_step: 14129, epoch: 54, loss: 0.935581
global_step: 14130, epoch: 54, loss: 0.881759
global_step: 14131, epoch: 54, loss: 1.031480
global_step: 14132, epoch: 54, loss: 0.949614
global_step: 14133, epoch: 54, loss: 1.018753
global_step: 14134, epoch: 54, loss: 0.872699
global_step: 14135, epoch: 54, loss: 1.022527
global_step: 14136, epoch: 54, loss: 0.967043
global_step: 14137, epoch: 54, loss: 1.002606
global_step: 14138, epoch: 54, loss: 0.951115
global_step: 14139, epoch: 54, loss: 0.907799
global_step: 14140, epoch: 54, loss: 0.969359
global_step: 14141, epoch: 54, loss: 1.034281
global_step: 14142, epoch: 54, loss: 1.086185
global_step: 14143, epoch: 54, loss: 1.105223
global_step: 14144, epoch: 54, loss: 0.958915
global_step: 14145, epoch: 54, loss: 1.014524
global_step: 14146, epoch: 54, loss: 0.973559
global_step: 14147, epoch: 54, loss: 1.001090
global_step: 14148, epoch: 54, loss: 0.888549
global_step: 14149, epoch: 54, loss: 0.975649
global_step: 14150, epoch: 54, loss: 0.869232
global_step: 14151, epoch: 54, loss: 0.962664
global_step: 14152, epoch: 54, loss: 0.998157
global_step: 14153, epoch: 54, loss: 0.931705
global_step: 14154, epoch: 54, loss: 1.003995
global_step: 14155, epoch: 54, loss: 1.039594
global_step: 14156, epoch: 54, loss: 0.934498
global_step: 14157, epoch: 54, loss: 1.042001
global_step: 14158, epoch: 54, loss: 0.929389
global_step: 14159, epoch: 54, loss: 1.119513
global_step: 14160, epoch: 54, loss: 1.056884
epoch: 54
train	acc: 0.7407	macro: p 0.5084, r 0.4693, f1: 0.4785	micro: p 0.7407, r 0.7407, f1 0.7407	weighted_f1:0.7104
dev	acc: 0.5455	macro: p 0.3278, r 0.3043, f1: 0.2968	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4931
test	acc: 0.6023	macro: p 0.3714, r 0.3236, f1: 0.3260	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5588
global_step: 14161, epoch: 55, loss: 1.053420
global_step: 14162, epoch: 55, loss: 0.896282
global_step: 14163, epoch: 55, loss: 0.923747
global_step: 14164, epoch: 55, loss: 0.957421
global_step: 14165, epoch: 55, loss: 0.855292
global_step: 14166, epoch: 55, loss: 0.968903
global_step: 14167, epoch: 55, loss: 0.939504
global_step: 14168, epoch: 55, loss: 0.850359
global_step: 14169, epoch: 55, loss: 1.011519
global_step: 14170, epoch: 55, loss: 0.936968
global_step: 14171, epoch: 55, loss: 0.963894
global_step: 14172, epoch: 55, loss: 0.870443
global_step: 14173, epoch: 55, loss: 1.008262
global_step: 14174, epoch: 55, loss: 0.905519
global_step: 14175, epoch: 55, loss: 1.033159
global_step: 14176, epoch: 55, loss: 1.012174
global_step: 14177, epoch: 55, loss: 1.038733
global_step: 14178, epoch: 55, loss: 0.907935
global_step: 14179, epoch: 55, loss: 0.967031
global_step: 14180, epoch: 55, loss: 1.028478
global_step: 14181, epoch: 55, loss: 0.951813
global_step: 14182, epoch: 55, loss: 1.053985
global_step: 14183, epoch: 55, loss: 0.952818
global_step: 14184, epoch: 55, loss: 0.943680
global_step: 14185, epoch: 55, loss: 0.923153
global_step: 14186, epoch: 55, loss: 1.109375
global_step: 14187, epoch: 55, loss: 0.942486
global_step: 14188, epoch: 55, loss: 0.953458
global_step: 14189, epoch: 55, loss: 0.955099
global_step: 14190, epoch: 55, loss: 0.976525
global_step: 14191, epoch: 55, loss: 1.014476
global_step: 14192, epoch: 55, loss: 0.972173
global_step: 14193, epoch: 55, loss: 0.992245
global_step: 14194, epoch: 55, loss: 0.972367
global_step: 14195, epoch: 55, loss: 0.952925
global_step: 14196, epoch: 55, loss: 0.959877
global_step: 14197, epoch: 55, loss: 0.990857
global_step: 14198, epoch: 55, loss: 1.026415
global_step: 14199, epoch: 55, loss: 0.928780
global_step: 14200, epoch: 55, loss: 1.011746
epoch: 55
train	acc: 0.7437	macro: p 0.5072, r 0.4762, f1: 0.4831	micro: p 0.7437, r 0.7437, f1 0.7437	weighted_f1:0.7158
dev	acc: 0.5428	macro: p 0.3261, r 0.3051, f1: 0.2988	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4938
test	acc: 0.5989	macro: p 0.3627, r 0.3225, f1: 0.3251	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5578
global_step: 14201, epoch: 56, loss: 0.903188
global_step: 14202, epoch: 56, loss: 1.020250
global_step: 14203, epoch: 56, loss: 0.890617
global_step: 14204, epoch: 56, loss: 1.081001
global_step: 14205, epoch: 56, loss: 0.889240
global_step: 14206, epoch: 56, loss: 0.979168
global_step: 14207, epoch: 56, loss: 0.945284
global_step: 14208, epoch: 56, loss: 1.055691
global_step: 14209, epoch: 56, loss: 0.897529
global_step: 14210, epoch: 56, loss: 0.910848
global_step: 14211, epoch: 56, loss: 0.906726
global_step: 14212, epoch: 56, loss: 0.903717
global_step: 14213, epoch: 56, loss: 0.994029
global_step: 14214, epoch: 56, loss: 0.956202
global_step: 14215, epoch: 56, loss: 0.898314
global_step: 14216, epoch: 56, loss: 0.988398
global_step: 14217, epoch: 56, loss: 0.916755
global_step: 14218, epoch: 56, loss: 1.007202
global_step: 14219, epoch: 56, loss: 0.932543
global_step: 14220, epoch: 56, loss: 1.006352
global_step: 14221, epoch: 56, loss: 1.041503
global_step: 14222, epoch: 56, loss: 0.935037
global_step: 14223, epoch: 56, loss: 0.878794
global_step: 14224, epoch: 56, loss: 0.953610
global_step: 14225, epoch: 56, loss: 0.956876
global_step: 14226, epoch: 56, loss: 0.945332
global_step: 14227, epoch: 56, loss: 0.970217
global_step: 14228, epoch: 56, loss: 0.918617
global_step: 14229, epoch: 56, loss: 1.034086
global_step: 14230, epoch: 56, loss: 0.944230
global_step: 14231, epoch: 56, loss: 0.957975
global_step: 14232, epoch: 56, loss: 0.895732
global_step: 14233, epoch: 56, loss: 0.944028
global_step: 14234, epoch: 56, loss: 1.064536
global_step: 14235, epoch: 56, loss: 1.080598
global_step: 14236, epoch: 56, loss: 0.913059
global_step: 14237, epoch: 56, loss: 0.863377
global_step: 14238, epoch: 56, loss: 1.004854
global_step: 14239, epoch: 56, loss: 1.013138
global_step: 14240, epoch: 56, loss: 1.027084
epoch: 56
train	acc: 0.7342	macro: p 0.5096, r 0.4625, f1: 0.4764	micro: p 0.7342, r 0.7342, f1 0.7342	weighted_f1:0.7037
dev	acc: 0.5500	macro: p 0.3305, r 0.3048, f1: 0.3000	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4956
test	acc: 0.6061	macro: p 0.3733, r 0.3216, f1: 0.3268	micro: p 0.6061, r 0.6061, f1 0.6061	weighted_f1:0.5602
global_step: 14241, epoch: 57, loss: 0.852546
global_step: 14242, epoch: 57, loss: 0.861367
global_step: 14243, epoch: 57, loss: 0.958957
global_step: 14244, epoch: 57, loss: 0.944230
global_step: 14245, epoch: 57, loss: 1.048518
global_step: 14246, epoch: 57, loss: 0.994598
global_step: 14247, epoch: 57, loss: 0.855153
global_step: 14248, epoch: 57, loss: 0.875597
global_step: 14249, epoch: 57, loss: 1.018081
global_step: 14250, epoch: 57, loss: 0.906167
global_step: 14251, epoch: 57, loss: 1.059450
global_step: 14252, epoch: 57, loss: 0.971198
global_step: 14253, epoch: 57, loss: 0.968535
global_step: 14254, epoch: 57, loss: 0.923000
global_step: 14255, epoch: 57, loss: 0.947135
global_step: 14256, epoch: 57, loss: 0.970518
global_step: 14257, epoch: 57, loss: 0.887236
global_step: 14258, epoch: 57, loss: 0.990790
global_step: 14259, epoch: 57, loss: 1.027268
global_step: 14260, epoch: 57, loss: 0.979027
global_step: 14261, epoch: 57, loss: 0.933340
global_step: 14262, epoch: 57, loss: 0.886468
global_step: 14263, epoch: 57, loss: 0.995336
global_step: 14264, epoch: 57, loss: 0.955274
global_step: 14265, epoch: 57, loss: 1.003616
global_step: 14266, epoch: 57, loss: 0.928746
global_step: 14267, epoch: 57, loss: 0.915220
global_step: 14268, epoch: 57, loss: 0.944509
global_step: 14269, epoch: 57, loss: 0.966351
global_step: 14270, epoch: 57, loss: 0.927198
global_step: 14271, epoch: 57, loss: 0.870376
global_step: 14272, epoch: 57, loss: 1.015013
global_step: 14273, epoch: 57, loss: 1.062630
global_step: 14274, epoch: 57, loss: 0.917091
global_step: 14275, epoch: 57, loss: 0.998777
global_step: 14276, epoch: 57, loss: 0.836455
global_step: 14277, epoch: 57, loss: 0.834389
global_step: 14278, epoch: 57, loss: 0.912114
global_step: 14279, epoch: 57, loss: 0.953506
global_step: 14280, epoch: 57, loss: 0.266353
epoch: 57
train	acc: 0.7308	macro: p 0.5159, r 0.4517, f1: 0.4675	micro: p 0.7308, r 0.7308, f1 0.7308	weighted_f1:0.6971
dev	acc: 0.5464	macro: p 0.3330, r 0.2987, f1: 0.2904	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4862
test	acc: 0.6015	macro: p 0.3758, r 0.3154, f1: 0.3184	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5523
global_step: 14281, epoch: 58, loss: 0.914453
global_step: 14282, epoch: 58, loss: 0.979990
global_step: 14283, epoch: 58, loss: 1.002330
global_step: 14284, epoch: 58, loss: 0.850735
global_step: 14285, epoch: 58, loss: 0.840152
global_step: 14286, epoch: 58, loss: 0.925329
global_step: 14287, epoch: 58, loss: 0.935318
global_step: 14288, epoch: 58, loss: 0.881007
global_step: 14289, epoch: 58, loss: 0.953923
global_step: 14290, epoch: 58, loss: 0.850908
global_step: 14291, epoch: 58, loss: 0.915902
global_step: 14292, epoch: 58, loss: 0.935647
global_step: 14293, epoch: 58, loss: 1.103475
global_step: 14294, epoch: 58, loss: 0.875369
global_step: 14295, epoch: 58, loss: 0.912681
global_step: 14296, epoch: 58, loss: 1.039382
global_step: 14297, epoch: 58, loss: 0.987717
global_step: 14298, epoch: 58, loss: 0.867055
global_step: 14299, epoch: 58, loss: 0.888070
global_step: 14300, epoch: 58, loss: 1.006976
global_step: 14301, epoch: 58, loss: 0.975939
global_step: 14302, epoch: 58, loss: 0.971837
global_step: 14303, epoch: 58, loss: 0.979470
global_step: 14304, epoch: 58, loss: 1.010127
global_step: 14305, epoch: 58, loss: 0.961376
global_step: 14306, epoch: 58, loss: 0.891338
global_step: 14307, epoch: 58, loss: 0.879906
global_step: 14308, epoch: 58, loss: 0.892091
global_step: 14309, epoch: 58, loss: 0.942731
global_step: 14310, epoch: 58, loss: 1.048099
global_step: 14311, epoch: 58, loss: 0.960501
global_step: 14312, epoch: 58, loss: 0.857397
global_step: 14313, epoch: 58, loss: 0.916044
global_step: 14314, epoch: 58, loss: 1.011685
global_step: 14315, epoch: 58, loss: 0.887401
global_step: 14316, epoch: 58, loss: 0.930634
global_step: 14317, epoch: 58, loss: 1.073138
global_step: 14318, epoch: 58, loss: 0.943520
global_step: 14319, epoch: 58, loss: 0.997834
global_step: 14320, epoch: 58, loss: 2.066857
epoch: 58
train	acc: 0.7587	macro: p 0.5182, r 0.4950, f1: 0.5018	micro: p 0.7587, r 0.7587, f1 0.7587	weighted_f1:0.7314
dev	acc: 0.5401	macro: p 0.3160, r 0.3011, f1: 0.2945	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4892
test	acc: 0.6023	macro: p 0.3593, r 0.3257, f1: 0.3295	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5611
global_step: 14321, epoch: 59, loss: 1.008358
global_step: 14322, epoch: 59, loss: 0.943141
global_step: 14323, epoch: 59, loss: 0.989770
global_step: 14324, epoch: 59, loss: 0.878063
global_step: 14325, epoch: 59, loss: 0.931660
global_step: 14326, epoch: 59, loss: 0.967693
global_step: 14327, epoch: 59, loss: 0.883031
global_step: 14328, epoch: 59, loss: 0.896268
global_step: 14329, epoch: 59, loss: 0.905900
global_step: 14330, epoch: 59, loss: 0.938361
global_step: 14331, epoch: 59, loss: 0.968128
global_step: 14332, epoch: 59, loss: 0.949695
global_step: 14333, epoch: 59, loss: 0.911577
global_step: 14334, epoch: 59, loss: 0.912207
global_step: 14335, epoch: 59, loss: 0.926031
global_step: 14336, epoch: 59, loss: 0.934649
global_step: 14337, epoch: 59, loss: 0.885927
global_step: 14338, epoch: 59, loss: 0.845030
global_step: 14339, epoch: 59, loss: 0.961862
global_step: 14340, epoch: 59, loss: 1.042529
global_step: 14341, epoch: 59, loss: 0.898380
global_step: 14342, epoch: 59, loss: 0.874874
global_step: 14343, epoch: 59, loss: 1.042036
global_step: 14344, epoch: 59, loss: 0.930838
global_step: 14345, epoch: 59, loss: 0.889783
global_step: 14346, epoch: 59, loss: 0.967455
global_step: 14347, epoch: 59, loss: 0.915886
global_step: 14348, epoch: 59, loss: 0.931779
global_step: 14349, epoch: 59, loss: 0.969767
global_step: 14350, epoch: 59, loss: 0.968766
global_step: 14351, epoch: 59, loss: 0.959363
global_step: 14352, epoch: 59, loss: 0.953479
global_step: 14353, epoch: 59, loss: 0.865462
global_step: 14354, epoch: 59, loss: 1.029991
global_step: 14355, epoch: 59, loss: 0.925955
global_step: 14356, epoch: 59, loss: 0.821984
global_step: 14357, epoch: 59, loss: 0.906774
global_step: 14358, epoch: 59, loss: 0.935479
global_step: 14359, epoch: 59, loss: 0.973176
global_step: 14360, epoch: 59, loss: 1.076575
epoch: 59
train	acc: 0.7532	macro: p 0.5244, r 0.4829, f1: 0.4933	micro: p 0.7532, r 0.7532, f1 0.7532	weighted_f1:0.7232
dev	acc: 0.5464	macro: p 0.3226, r 0.3036, f1: 0.2958	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4915
test	acc: 0.6042	macro: p 0.3708, r 0.3228, f1: 0.3251	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5588
global_step: 14361, epoch: 60, loss: 0.857257
global_step: 14362, epoch: 60, loss: 0.878800
global_step: 14363, epoch: 60, loss: 0.957551
global_step: 14364, epoch: 60, loss: 0.860549
global_step: 14365, epoch: 60, loss: 0.889496
global_step: 14366, epoch: 60, loss: 0.937177
global_step: 14367, epoch: 60, loss: 0.979238
global_step: 14368, epoch: 60, loss: 0.864691
global_step: 14369, epoch: 60, loss: 0.942046
global_step: 14370, epoch: 60, loss: 0.931672
global_step: 14371, epoch: 60, loss: 0.975364
global_step: 14372, epoch: 60, loss: 0.904901
global_step: 14373, epoch: 60, loss: 0.963203
global_step: 14374, epoch: 60, loss: 1.030475
global_step: 14375, epoch: 60, loss: 0.919493
global_step: 14376, epoch: 60, loss: 0.952674
global_step: 14377, epoch: 60, loss: 0.856111
global_step: 14378, epoch: 60, loss: 0.970963
global_step: 14379, epoch: 60, loss: 0.998791
global_step: 14380, epoch: 60, loss: 0.886073
global_step: 14381, epoch: 60, loss: 0.884397
global_step: 14382, epoch: 60, loss: 0.932927
global_step: 14383, epoch: 60, loss: 0.925652
global_step: 14384, epoch: 60, loss: 0.944141
global_step: 14385, epoch: 60, loss: 0.945629
global_step: 14386, epoch: 60, loss: 0.873986
global_step: 14387, epoch: 60, loss: 1.003108
global_step: 14388, epoch: 60, loss: 0.931034
global_step: 14389, epoch: 60, loss: 0.967431
global_step: 14390, epoch: 60, loss: 0.868949
global_step: 14391, epoch: 60, loss: 0.869052
global_step: 14392, epoch: 60, loss: 0.873106
global_step: 14393, epoch: 60, loss: 0.861889
global_step: 14394, epoch: 60, loss: 0.976698
global_step: 14395, epoch: 60, loss: 0.981217
global_step: 14396, epoch: 60, loss: 0.917750
global_step: 14397, epoch: 60, loss: 1.022973
global_step: 14398, epoch: 60, loss: 0.924423
global_step: 14399, epoch: 60, loss: 0.978698
global_step: 14400, epoch: 60, loss: 1.239420
epoch: 60
train	acc: 0.7556	macro: p 0.5219, r 0.4923, f1: 0.4987	micro: p 0.7556, r 0.7556, f1 0.7556	weighted_f1:0.7290
dev	acc: 0.5446	macro: p 0.3256, r 0.3048, f1: 0.3014	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4955
test	acc: 0.6008	macro: p 0.3618, r 0.3231, f1: 0.3277	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5602
global_step: 14401, epoch: 61, loss: 0.883698
global_step: 14402, epoch: 61, loss: 0.934077
global_step: 14403, epoch: 61, loss: 0.955858
global_step: 14404, epoch: 61, loss: 0.830297
global_step: 14405, epoch: 61, loss: 0.948993
global_step: 14406, epoch: 61, loss: 0.936644
global_step: 14407, epoch: 61, loss: 0.920782
global_step: 14408, epoch: 61, loss: 0.821414
global_step: 14409, epoch: 61, loss: 0.970385
global_step: 14410, epoch: 61, loss: 0.907061
global_step: 14411, epoch: 61, loss: 0.930472
global_step: 14412, epoch: 61, loss: 0.858760
global_step: 14413, epoch: 61, loss: 0.908557
global_step: 14414, epoch: 61, loss: 0.846228
global_step: 14415, epoch: 61, loss: 0.892646
global_step: 14416, epoch: 61, loss: 0.831116
global_step: 14417, epoch: 61, loss: 0.877969
global_step: 14418, epoch: 61, loss: 0.937476
global_step: 14419, epoch: 61, loss: 1.012900
global_step: 14420, epoch: 61, loss: 0.999124
global_step: 14421, epoch: 61, loss: 0.918534
global_step: 14422, epoch: 61, loss: 1.058498
global_step: 14423, epoch: 61, loss: 0.907227
global_step: 14424, epoch: 61, loss: 0.847149
global_step: 14425, epoch: 61, loss: 0.964465
global_step: 14426, epoch: 61, loss: 0.918700
global_step: 14427, epoch: 61, loss: 0.904580
global_step: 14428, epoch: 61, loss: 0.876573
global_step: 14429, epoch: 61, loss: 0.984235
global_step: 14430, epoch: 61, loss: 0.927092
global_step: 14431, epoch: 61, loss: 0.897688
global_step: 14432, epoch: 61, loss: 1.001514
global_step: 14433, epoch: 61, loss: 0.913750
global_step: 14434, epoch: 61, loss: 0.909865
global_step: 14435, epoch: 61, loss: 0.931093
global_step: 14436, epoch: 61, loss: 0.934569
global_step: 14437, epoch: 61, loss: 1.041241
global_step: 14438, epoch: 61, loss: 0.925140
global_step: 14439, epoch: 61, loss: 0.928520
global_step: 14440, epoch: 61, loss: 0.723454
epoch: 61
train	acc: 0.7639	macro: p 0.5273, r 0.4974, f1: 0.5058	micro: p 0.7639, r 0.7639, f1 0.7639	weighted_f1:0.7360
dev	acc: 0.5392	macro: p 0.3183, r 0.2994, f1: 0.2926	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4874
test	acc: 0.6077	macro: p 0.3710, r 0.3286, f1: 0.3329	micro: p 0.6077, r 0.6077, f1 0.6077	weighted_f1:0.5652
global_step: 14441, epoch: 62, loss: 0.905656
global_step: 14442, epoch: 62, loss: 0.782751
global_step: 14443, epoch: 62, loss: 0.784235
global_step: 14444, epoch: 62, loss: 0.892364
global_step: 14445, epoch: 62, loss: 0.975320
global_step: 14446, epoch: 62, loss: 0.958134
global_step: 14447, epoch: 62, loss: 0.860704
global_step: 14448, epoch: 62, loss: 0.916274
global_step: 14449, epoch: 62, loss: 0.789398
global_step: 14450, epoch: 62, loss: 1.033505
global_step: 14451, epoch: 62, loss: 0.937040
global_step: 14452, epoch: 62, loss: 0.885592
global_step: 14453, epoch: 62, loss: 0.935631
global_step: 14454, epoch: 62, loss: 0.987128
global_step: 14455, epoch: 62, loss: 0.908113
global_step: 14456, epoch: 62, loss: 0.870558
global_step: 14457, epoch: 62, loss: 0.900222
global_step: 14458, epoch: 62, loss: 1.021064
global_step: 14459, epoch: 62, loss: 0.949146
global_step: 14460, epoch: 62, loss: 0.981295
global_step: 14461, epoch: 62, loss: 0.891276
global_step: 14462, epoch: 62, loss: 0.975615
global_step: 14463, epoch: 62, loss: 0.829363
global_step: 14464, epoch: 62, loss: 0.904168
global_step: 14465, epoch: 62, loss: 0.917741
global_step: 14466, epoch: 62, loss: 0.899384
global_step: 14467, epoch: 62, loss: 0.897489
global_step: 14468, epoch: 62, loss: 0.925717
global_step: 14469, epoch: 62, loss: 0.913499
global_step: 14470, epoch: 62, loss: 0.902515
global_step: 14471, epoch: 62, loss: 0.922296
global_step: 14472, epoch: 62, loss: 0.873198
global_step: 14473, epoch: 62, loss: 0.954788
global_step: 14474, epoch: 62, loss: 0.901791
global_step: 14475, epoch: 62, loss: 0.851950
global_step: 14476, epoch: 62, loss: 0.916974
global_step: 14477, epoch: 62, loss: 0.967521
global_step: 14478, epoch: 62, loss: 0.932974
global_step: 14479, epoch: 62, loss: 0.950974
global_step: 14480, epoch: 62, loss: 0.420956
epoch: 62
train	acc: 0.7743	macro: p 0.6704, r 0.5163, f1: 0.5209	micro: p 0.7743, r 0.7743, f1 0.7743	weighted_f1:0.7479
dev	acc: 0.5428	macro: p 0.3150, r 0.3027, f1: 0.2956	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4905
test	acc: 0.5985	macro: p 0.3486, r 0.3230, f1: 0.3248	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5571
global_step: 14481, epoch: 63, loss: 0.910100
global_step: 14482, epoch: 63, loss: 0.866571
global_step: 14483, epoch: 63, loss: 0.917698
global_step: 14484, epoch: 63, loss: 0.814303
global_step: 14485, epoch: 63, loss: 0.943076
global_step: 14486, epoch: 63, loss: 0.999930
global_step: 14487, epoch: 63, loss: 0.949398
global_step: 14488, epoch: 63, loss: 0.788369
global_step: 14489, epoch: 63, loss: 0.941195
global_step: 14490, epoch: 63, loss: 0.885347
global_step: 14491, epoch: 63, loss: 0.942340
global_step: 14492, epoch: 63, loss: 0.918152
global_step: 14493, epoch: 63, loss: 0.852701
global_step: 14494, epoch: 63, loss: 0.896484
global_step: 14495, epoch: 63, loss: 0.891844
global_step: 14496, epoch: 63, loss: 0.919091
global_step: 14497, epoch: 63, loss: 0.894869
global_step: 14498, epoch: 63, loss: 0.981408
global_step: 14499, epoch: 63, loss: 0.963054
global_step: 14500, epoch: 63, loss: 0.860018
global_step: 14501, epoch: 63, loss: 0.923343
global_step: 14502, epoch: 63, loss: 0.910435
global_step: 14503, epoch: 63, loss: 0.937633
global_step: 14504, epoch: 63, loss: 0.892805
global_step: 14505, epoch: 63, loss: 0.839488
global_step: 14506, epoch: 63, loss: 0.850183
global_step: 14507, epoch: 63, loss: 0.932149
global_step: 14508, epoch: 63, loss: 0.844808
global_step: 14509, epoch: 63, loss: 0.879568
global_step: 14510, epoch: 63, loss: 0.882330
global_step: 14511, epoch: 63, loss: 0.901646
global_step: 14512, epoch: 63, loss: 0.901287
global_step: 14513, epoch: 63, loss: 0.879429
global_step: 14514, epoch: 63, loss: 0.955815
global_step: 14515, epoch: 63, loss: 0.917150
global_step: 14516, epoch: 63, loss: 0.968942
global_step: 14517, epoch: 63, loss: 0.871430
global_step: 14518, epoch: 63, loss: 0.925018
global_step: 14519, epoch: 63, loss: 0.809428
global_step: 14520, epoch: 63, loss: 1.402398
epoch: 63
train	acc: 0.7747	macro: p 0.6774, r 0.5097, f1: 0.5166	micro: p 0.7747, r 0.7747, f1 0.7747	weighted_f1:0.7473
dev	acc: 0.5365	macro: p 0.3161, r 0.2985, f1: 0.2906	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4851
test	acc: 0.5985	macro: p 0.3631, r 0.3224, f1: 0.3236	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5556
global_step: 14521, epoch: 64, loss: 0.928052
global_step: 14522, epoch: 64, loss: 0.927088
global_step: 14523, epoch: 64, loss: 0.859860
global_step: 14524, epoch: 64, loss: 0.858567
global_step: 14525, epoch: 64, loss: 0.940923
global_step: 14526, epoch: 64, loss: 0.941574
global_step: 14527, epoch: 64, loss: 0.777898
global_step: 14528, epoch: 64, loss: 0.823258
global_step: 14529, epoch: 64, loss: 0.924087
global_step: 14530, epoch: 64, loss: 0.933977
global_step: 14531, epoch: 64, loss: 0.897781
global_step: 14532, epoch: 64, loss: 0.883992
global_step: 14533, epoch: 64, loss: 1.005798
global_step: 14534, epoch: 64, loss: 0.814008
global_step: 14535, epoch: 64, loss: 0.819260
global_step: 14536, epoch: 64, loss: 0.954660
global_step: 14537, epoch: 64, loss: 0.834488
global_step: 14538, epoch: 64, loss: 0.928520
global_step: 14539, epoch: 64, loss: 0.975016
global_step: 14540, epoch: 64, loss: 0.838683
global_step: 14541, epoch: 64, loss: 0.823327
global_step: 14542, epoch: 64, loss: 0.889978
global_step: 14543, epoch: 64, loss: 0.914436
global_step: 14544, epoch: 64, loss: 1.009261
global_step: 14545, epoch: 64, loss: 0.801771
global_step: 14546, epoch: 64, loss: 0.962088
global_step: 14547, epoch: 64, loss: 0.905616
global_step: 14548, epoch: 64, loss: 0.938420
global_step: 14549, epoch: 64, loss: 0.850373
global_step: 14550, epoch: 64, loss: 0.800927
global_step: 14551, epoch: 64, loss: 0.946167
global_step: 14552, epoch: 64, loss: 0.980375
global_step: 14553, epoch: 64, loss: 0.930561
global_step: 14554, epoch: 64, loss: 0.774574
global_step: 14555, epoch: 64, loss: 0.829889
global_step: 14556, epoch: 64, loss: 0.873047
global_step: 14557, epoch: 64, loss: 0.937000
global_step: 14558, epoch: 64, loss: 0.949544
global_step: 14559, epoch: 64, loss: 0.974153
global_step: 14560, epoch: 64, loss: 0.470964
epoch: 64
train	acc: 0.7647	macro: p 0.6784, r 0.4965, f1: 0.5091	micro: p 0.7647, r 0.7647, f1 0.7647	weighted_f1:0.7360
dev	acc: 0.5401	macro: p 0.3232, r 0.2960, f1: 0.2871	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4824
test	acc: 0.6031	macro: p 0.3715, r 0.3197, f1: 0.3219	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5552
global_step: 14561, epoch: 65, loss: 0.901542
global_step: 14562, epoch: 65, loss: 0.944874
global_step: 14563, epoch: 65, loss: 0.879899
global_step: 14564, epoch: 65, loss: 0.824777
global_step: 14565, epoch: 65, loss: 0.927940
global_step: 14566, epoch: 65, loss: 0.853016
global_step: 14567, epoch: 65, loss: 0.790035
global_step: 14568, epoch: 65, loss: 0.875742
global_step: 14569, epoch: 65, loss: 0.973529
global_step: 14570, epoch: 65, loss: 0.837319
global_step: 14571, epoch: 65, loss: 0.909945
global_step: 14572, epoch: 65, loss: 0.904356
global_step: 14573, epoch: 65, loss: 0.918628
global_step: 14574, epoch: 65, loss: 0.893701
global_step: 14575, epoch: 65, loss: 0.739792
global_step: 14576, epoch: 65, loss: 0.911803
global_step: 14577, epoch: 65, loss: 0.921802
global_step: 14578, epoch: 65, loss: 0.958969
global_step: 14579, epoch: 65, loss: 0.841331
global_step: 14580, epoch: 65, loss: 0.772403
global_step: 14581, epoch: 65, loss: 0.786093
global_step: 14582, epoch: 65, loss: 0.855137
global_step: 14583, epoch: 65, loss: 0.761954
global_step: 14584, epoch: 65, loss: 1.035716
global_step: 14585, epoch: 65, loss: 0.894001
global_step: 14586, epoch: 65, loss: 1.011687
global_step: 14587, epoch: 65, loss: 0.855702
global_step: 14588, epoch: 65, loss: 0.835238
global_step: 14589, epoch: 65, loss: 0.821363
global_step: 14590, epoch: 65, loss: 0.807418
global_step: 14591, epoch: 65, loss: 0.861661
global_step: 14592, epoch: 65, loss: 0.884920
global_step: 14593, epoch: 65, loss: 0.867122
global_step: 14594, epoch: 65, loss: 0.865845
global_step: 14595, epoch: 65, loss: 0.924677
global_step: 14596, epoch: 65, loss: 0.888172
global_step: 14597, epoch: 65, loss: 0.912763
global_step: 14598, epoch: 65, loss: 0.815256
global_step: 14599, epoch: 65, loss: 0.866485
global_step: 14600, epoch: 65, loss: 0.787943
epoch: 65
train	acc: 0.7692	macro: p 0.6821, r 0.5010, f1: 0.5141	micro: p 0.7692, r 0.7692, f1 0.7692	weighted_f1:0.7402
dev	acc: 0.5428	macro: p 0.3230, r 0.2986, f1: 0.2913	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4853
test	acc: 0.6038	macro: p 0.3647, r 0.3181, f1: 0.3206	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5547
global_step: 14601, epoch: 66, loss: 0.965364
global_step: 14602, epoch: 66, loss: 0.872221
global_step: 14603, epoch: 66, loss: 0.980121
global_step: 14604, epoch: 66, loss: 0.917711
global_step: 14605, epoch: 66, loss: 0.825719
global_step: 14606, epoch: 66, loss: 0.954686
global_step: 14607, epoch: 66, loss: 1.012926
global_step: 14608, epoch: 66, loss: 0.894964
global_step: 14609, epoch: 66, loss: 0.853568
global_step: 14610, epoch: 66, loss: 0.870210
global_step: 14611, epoch: 66, loss: 0.875151
global_step: 14612, epoch: 66, loss: 0.796430
global_step: 14613, epoch: 66, loss: 0.897749
global_step: 14614, epoch: 66, loss: 0.876239
global_step: 14615, epoch: 66, loss: 0.844349
global_step: 14616, epoch: 66, loss: 0.894997
global_step: 14617, epoch: 66, loss: 0.906253
global_step: 14618, epoch: 66, loss: 0.868383
global_step: 14619, epoch: 66, loss: 0.934622
global_step: 14620, epoch: 66, loss: 0.939140
global_step: 14621, epoch: 66, loss: 0.842088
global_step: 14622, epoch: 66, loss: 0.840588
global_step: 14623, epoch: 66, loss: 0.866229
global_step: 14624, epoch: 66, loss: 0.840025
global_step: 14625, epoch: 66, loss: 0.847737
global_step: 14626, epoch: 66, loss: 0.835737
global_step: 14627, epoch: 66, loss: 0.886933
global_step: 14628, epoch: 66, loss: 0.831176
global_step: 14629, epoch: 66, loss: 0.828339
global_step: 14630, epoch: 66, loss: 0.884560
global_step: 14631, epoch: 66, loss: 0.793759
global_step: 14632, epoch: 66, loss: 0.880260
global_step: 14633, epoch: 66, loss: 0.945606
global_step: 14634, epoch: 66, loss: 0.923184
global_step: 14635, epoch: 66, loss: 0.801779
global_step: 14636, epoch: 66, loss: 1.005838
global_step: 14637, epoch: 66, loss: 0.914273
global_step: 14638, epoch: 66, loss: 0.827060
global_step: 14639, epoch: 66, loss: 0.852065
global_step: 14640, epoch: 66, loss: 1.397866
epoch: 66
train	acc: 0.7855	macro: p 0.6824, r 0.5263, f1: 0.5312	micro: p 0.7855, r 0.7855, f1 0.7855	weighted_f1:0.7592
dev	acc: 0.5464	macro: p 0.3238, r 0.3061, f1: 0.2977	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4933
test	acc: 0.6004	macro: p 0.3573, r 0.3226, f1: 0.3240	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5566
global_step: 14641, epoch: 67, loss: 0.829585
global_step: 14642, epoch: 67, loss: 0.804125
global_step: 14643, epoch: 67, loss: 0.849482
global_step: 14644, epoch: 67, loss: 0.816312
global_step: 14645, epoch: 67, loss: 0.882382
global_step: 14646, epoch: 67, loss: 0.912036
global_step: 14647, epoch: 67, loss: 1.001299
global_step: 14648, epoch: 67, loss: 0.720367
global_step: 14649, epoch: 67, loss: 0.924399
global_step: 14650, epoch: 67, loss: 0.829483
global_step: 14651, epoch: 67, loss: 0.832345
global_step: 14652, epoch: 67, loss: 0.883857
global_step: 14653, epoch: 67, loss: 0.869589
global_step: 14654, epoch: 67, loss: 0.902032
global_step: 14655, epoch: 67, loss: 0.840214
global_step: 14656, epoch: 67, loss: 0.814453
global_step: 14657, epoch: 67, loss: 0.882291
global_step: 14658, epoch: 67, loss: 0.914906
global_step: 14659, epoch: 67, loss: 0.842491
global_step: 14660, epoch: 67, loss: 0.807555
global_step: 14661, epoch: 67, loss: 0.791313
global_step: 14662, epoch: 67, loss: 0.910063
global_step: 14663, epoch: 67, loss: 0.908833
global_step: 14664, epoch: 67, loss: 0.807002
global_step: 14665, epoch: 67, loss: 0.777227
global_step: 14666, epoch: 67, loss: 0.723417
global_step: 14667, epoch: 67, loss: 0.873568
global_step: 14668, epoch: 67, loss: 0.773172
global_step: 14669, epoch: 67, loss: 0.907471
global_step: 14670, epoch: 67, loss: 0.908008
global_step: 14671, epoch: 67, loss: 0.854134
global_step: 14672, epoch: 67, loss: 1.022214
global_step: 14673, epoch: 67, loss: 0.907599
global_step: 14674, epoch: 67, loss: 0.862097
global_step: 14675, epoch: 67, loss: 0.900425
global_step: 14676, epoch: 67, loss: 0.975086
global_step: 14677, epoch: 67, loss: 0.855486
global_step: 14678, epoch: 67, loss: 0.890704
global_step: 14679, epoch: 67, loss: 0.860593
global_step: 14680, epoch: 67, loss: 0.785821
epoch: 67
train	acc: 0.7848	macro: p 0.6863, r 0.5211, f1: 0.5271	micro: p 0.7848, r 0.7848, f1 0.7848	weighted_f1:0.7576
dev	acc: 0.5401	macro: p 0.3262, r 0.3048, f1: 0.2931	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4870
test	acc: 0.5977	macro: p 0.3671, r 0.3218, f1: 0.3211	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5529
global_step: 14681, epoch: 68, loss: 0.856806
global_step: 14682, epoch: 68, loss: 0.952293
global_step: 14683, epoch: 68, loss: 0.821271
global_step: 14684, epoch: 68, loss: 0.921709
global_step: 14685, epoch: 68, loss: 0.841114
global_step: 14686, epoch: 68, loss: 0.796332
global_step: 14687, epoch: 68, loss: 0.828040
global_step: 14688, epoch: 68, loss: 0.872330
global_step: 14689, epoch: 68, loss: 0.790181
global_step: 14690, epoch: 68, loss: 0.993458
global_step: 14691, epoch: 68, loss: 0.954099
global_step: 14692, epoch: 68, loss: 0.843533
global_step: 14693, epoch: 68, loss: 0.917055
global_step: 14694, epoch: 68, loss: 0.776859
global_step: 14695, epoch: 68, loss: 0.846162
global_step: 14696, epoch: 68, loss: 0.850680
global_step: 14697, epoch: 68, loss: 0.854706
global_step: 14698, epoch: 68, loss: 0.774322
global_step: 14699, epoch: 68, loss: 0.855437
global_step: 14700, epoch: 68, loss: 0.928190
global_step: 14701, epoch: 68, loss: 0.876511
global_step: 14702, epoch: 68, loss: 0.944122
global_step: 14703, epoch: 68, loss: 0.996186
global_step: 14704, epoch: 68, loss: 0.931126
global_step: 14705, epoch: 68, loss: 0.774892
global_step: 14706, epoch: 68, loss: 0.825235
global_step: 14707, epoch: 68, loss: 0.897043
global_step: 14708, epoch: 68, loss: 0.762286
global_step: 14709, epoch: 68, loss: 0.765160
global_step: 14710, epoch: 68, loss: 0.917260
global_step: 14711, epoch: 68, loss: 0.843837
global_step: 14712, epoch: 68, loss: 0.906938
global_step: 14713, epoch: 68, loss: 0.964018
global_step: 14714, epoch: 68, loss: 0.836555
global_step: 14715, epoch: 68, loss: 0.881693
global_step: 14716, epoch: 68, loss: 0.721304
global_step: 14717, epoch: 68, loss: 0.856950
global_step: 14718, epoch: 68, loss: 0.873092
global_step: 14719, epoch: 68, loss: 0.836716
global_step: 14720, epoch: 68, loss: 0.665528
epoch: 68
train	acc: 0.7979	macro: p 0.6923, r 0.5410, f1: 0.5419	micro: p 0.7979, r 0.7979, f1 0.7979	weighted_f1:0.7724
dev	acc: 0.5428	macro: p 0.3212, r 0.3084, f1: 0.3003	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4948
test	acc: 0.5958	macro: p 0.3525, r 0.3233, f1: 0.3231	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5552
global_step: 14721, epoch: 69, loss: 0.914347
global_step: 14722, epoch: 69, loss: 0.878389
global_step: 14723, epoch: 69, loss: 0.901856
global_step: 14724, epoch: 69, loss: 0.900877
global_step: 14725, epoch: 69, loss: 0.846277
global_step: 14726, epoch: 69, loss: 0.952653
global_step: 14727, epoch: 69, loss: 0.804941
global_step: 14728, epoch: 69, loss: 0.809141
global_step: 14729, epoch: 69, loss: 0.874298
global_step: 14730, epoch: 69, loss: 0.872701
global_step: 14731, epoch: 69, loss: 0.816054
global_step: 14732, epoch: 69, loss: 0.860198
global_step: 14733, epoch: 69, loss: 0.748878
global_step: 14734, epoch: 69, loss: 0.927443
global_step: 14735, epoch: 69, loss: 0.850399
global_step: 14736, epoch: 69, loss: 0.822033
global_step: 14737, epoch: 69, loss: 0.808326
global_step: 14738, epoch: 69, loss: 0.954118
global_step: 14739, epoch: 69, loss: 0.849882
global_step: 14740, epoch: 69, loss: 0.865253
global_step: 14741, epoch: 69, loss: 0.894526
global_step: 14742, epoch: 69, loss: 0.939210
global_step: 14743, epoch: 69, loss: 0.806842
global_step: 14744, epoch: 69, loss: 0.861216
global_step: 14745, epoch: 69, loss: 0.782141
global_step: 14746, epoch: 69, loss: 0.767696
global_step: 14747, epoch: 69, loss: 0.863488
global_step: 14748, epoch: 69, loss: 0.736506
global_step: 14749, epoch: 69, loss: 0.772771
global_step: 14750, epoch: 69, loss: 0.838838
global_step: 14751, epoch: 69, loss: 0.965705
global_step: 14752, epoch: 69, loss: 0.924697
global_step: 14753, epoch: 69, loss: 0.830121
global_step: 14754, epoch: 69, loss: 0.787388
global_step: 14755, epoch: 69, loss: 0.807842
global_step: 14756, epoch: 69, loss: 0.830911
global_step: 14757, epoch: 69, loss: 0.872229
global_step: 14758, epoch: 69, loss: 0.876951
global_step: 14759, epoch: 69, loss: 0.928240
global_step: 14760, epoch: 69, loss: 0.725286
epoch: 69
train	acc: 0.8055	macro: p 0.6928, r 0.5542, f1: 0.5517	micro: p 0.8055, r 0.8055, f1 0.8055	weighted_f1:0.7814
dev	acc: 0.5437	macro: p 0.3199, r 0.3080, f1: 0.3011	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4960
test	acc: 0.5935	macro: p 0.3482, r 0.3230, f1: 0.3247	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5555
global_step: 14761, epoch: 70, loss: 0.860936
global_step: 14762, epoch: 70, loss: 0.836064
global_step: 14763, epoch: 70, loss: 0.791989
global_step: 14764, epoch: 70, loss: 0.976330
global_step: 14765, epoch: 70, loss: 0.830887
global_step: 14766, epoch: 70, loss: 0.832791
global_step: 14767, epoch: 70, loss: 0.861809
global_step: 14768, epoch: 70, loss: 0.789732
global_step: 14769, epoch: 70, loss: 0.805356
global_step: 14770, epoch: 70, loss: 0.880270
global_step: 14771, epoch: 70, loss: 0.781426
global_step: 14772, epoch: 70, loss: 0.834641
global_step: 14773, epoch: 70, loss: 0.906183
global_step: 14774, epoch: 70, loss: 0.809102
global_step: 14775, epoch: 70, loss: 0.751464
global_step: 14776, epoch: 70, loss: 0.918874
global_step: 14777, epoch: 70, loss: 0.839907
global_step: 14778, epoch: 70, loss: 0.857792
global_step: 14779, epoch: 70, loss: 0.837918
global_step: 14780, epoch: 70, loss: 0.986368
global_step: 14781, epoch: 70, loss: 0.774857
global_step: 14782, epoch: 70, loss: 0.832455
global_step: 14783, epoch: 70, loss: 0.789653
global_step: 14784, epoch: 70, loss: 0.841620
global_step: 14785, epoch: 70, loss: 0.786225
global_step: 14786, epoch: 70, loss: 0.861251
global_step: 14787, epoch: 70, loss: 0.811934
global_step: 14788, epoch: 70, loss: 0.811823
global_step: 14789, epoch: 70, loss: 0.819545
global_step: 14790, epoch: 70, loss: 0.857315
global_step: 14791, epoch: 70, loss: 0.957473
global_step: 14792, epoch: 70, loss: 0.780127
global_step: 14793, epoch: 70, loss: 0.846627
global_step: 14794, epoch: 70, loss: 0.839878
global_step: 14795, epoch: 70, loss: 0.818021
global_step: 14796, epoch: 70, loss: 1.014526
global_step: 14797, epoch: 70, loss: 0.817547
global_step: 14798, epoch: 70, loss: 0.794612
global_step: 14799, epoch: 70, loss: 0.929521
global_step: 14800, epoch: 70, loss: 0.347788
epoch: 70
train	acc: 0.7945	macro: p 0.6974, r 0.5332, f1: 0.5408	micro: p 0.7945, r 0.7945, f1 0.7945	weighted_f1:0.7674
dev	acc: 0.5482	macro: p 0.3329, r 0.3048, f1: 0.2994	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4936
test	acc: 0.6008	macro: p 0.3622, r 0.3187, f1: 0.3207	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5543
global_step: 14801, epoch: 71, loss: 0.915903
global_step: 14802, epoch: 71, loss: 0.772887
global_step: 14803, epoch: 71, loss: 0.960420
global_step: 14804, epoch: 71, loss: 0.695276
global_step: 14805, epoch: 71, loss: 0.728849
global_step: 14806, epoch: 71, loss: 0.871498
global_step: 14807, epoch: 71, loss: 0.884663
global_step: 14808, epoch: 71, loss: 0.860500
global_step: 14809, epoch: 71, loss: 0.757332
global_step: 14810, epoch: 71, loss: 0.757222
global_step: 14811, epoch: 71, loss: 0.790223
global_step: 14812, epoch: 71, loss: 0.870334
global_step: 14813, epoch: 71, loss: 0.882183
global_step: 14814, epoch: 71, loss: 0.884225
global_step: 14815, epoch: 71, loss: 0.842192
global_step: 14816, epoch: 71, loss: 0.805354
global_step: 14817, epoch: 71, loss: 0.692276
global_step: 14818, epoch: 71, loss: 0.914663
global_step: 14819, epoch: 71, loss: 0.779548
global_step: 14820, epoch: 71, loss: 0.882514
global_step: 14821, epoch: 71, loss: 0.871062
global_step: 14822, epoch: 71, loss: 0.916685
global_step: 14823, epoch: 71, loss: 0.770455
global_step: 14824, epoch: 71, loss: 0.888870
global_step: 14825, epoch: 71, loss: 0.930712
global_step: 14826, epoch: 71, loss: 0.941848
global_step: 14827, epoch: 71, loss: 0.782173
global_step: 14828, epoch: 71, loss: 0.771550
global_step: 14829, epoch: 71, loss: 0.702478
global_step: 14830, epoch: 71, loss: 0.770871
global_step: 14831, epoch: 71, loss: 0.850152
global_step: 14832, epoch: 71, loss: 0.991048
global_step: 14833, epoch: 71, loss: 0.823727
global_step: 14834, epoch: 71, loss: 0.815355
global_step: 14835, epoch: 71, loss: 0.889406
global_step: 14836, epoch: 71, loss: 0.904750
global_step: 14837, epoch: 71, loss: 0.907370
global_step: 14838, epoch: 71, loss: 0.855637
global_step: 14839, epoch: 71, loss: 0.755011
global_step: 14840, epoch: 71, loss: 0.693759
epoch: 71
train	acc: 0.8044	macro: p 0.7013, r 0.5440, f1: 0.5473	micro: p 0.8044, r 0.8044, f1 0.8044	weighted_f1:0.7779
dev	acc: 0.5428	macro: p 0.3253, r 0.3039, f1: 0.2960	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4906
test	acc: 0.5977	macro: p 0.3615, r 0.3200, f1: 0.3205	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5536
global_step: 14841, epoch: 72, loss: 0.826991
global_step: 14842, epoch: 72, loss: 0.896391
global_step: 14843, epoch: 72, loss: 0.802992
global_step: 14844, epoch: 72, loss: 0.857375
global_step: 14845, epoch: 72, loss: 0.711327
global_step: 14846, epoch: 72, loss: 0.838309
global_step: 14847, epoch: 72, loss: 0.940410
global_step: 14848, epoch: 72, loss: 0.763121
global_step: 14849, epoch: 72, loss: 0.840079
global_step: 14850, epoch: 72, loss: 0.746420
global_step: 14851, epoch: 72, loss: 0.883013
global_step: 14852, epoch: 72, loss: 0.823287
global_step: 14853, epoch: 72, loss: 0.805491
global_step: 14854, epoch: 72, loss: 0.815316
global_step: 14855, epoch: 72, loss: 0.783035
global_step: 14856, epoch: 72, loss: 0.843176
global_step: 14857, epoch: 72, loss: 0.871329
global_step: 14858, epoch: 72, loss: 0.781790
global_step: 14859, epoch: 72, loss: 0.790453
global_step: 14860, epoch: 72, loss: 0.848839
global_step: 14861, epoch: 72, loss: 0.882605
global_step: 14862, epoch: 72, loss: 0.820868
global_step: 14863, epoch: 72, loss: 0.880040
global_step: 14864, epoch: 72, loss: 0.758595
global_step: 14865, epoch: 72, loss: 0.913599
global_step: 14866, epoch: 72, loss: 0.695399
global_step: 14867, epoch: 72, loss: 0.818510
global_step: 14868, epoch: 72, loss: 0.780374
global_step: 14869, epoch: 72, loss: 0.886440
global_step: 14870, epoch: 72, loss: 0.757611
global_step: 14871, epoch: 72, loss: 0.783573
global_step: 14872, epoch: 72, loss: 0.768924
global_step: 14873, epoch: 72, loss: 0.835755
global_step: 14874, epoch: 72, loss: 0.915386
global_step: 14875, epoch: 72, loss: 0.944241
global_step: 14876, epoch: 72, loss: 0.833305
global_step: 14877, epoch: 72, loss: 0.820922
global_step: 14878, epoch: 72, loss: 0.867475
global_step: 14879, epoch: 72, loss: 0.885172
global_step: 14880, epoch: 72, loss: 1.050369
epoch: 72
train	acc: 0.8128	macro: p 0.6958, r 0.5630, f1: 0.5591	micro: p 0.8128, r 0.8128, f1 0.8128	weighted_f1:0.7886
dev	acc: 0.5419	macro: p 0.3202, r 0.3069, f1: 0.2971	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4920
test	acc: 0.5958	macro: p 0.3497, r 0.3252, f1: 0.3248	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5560
global_step: 14881, epoch: 73, loss: 0.855620
global_step: 14882, epoch: 73, loss: 0.812031
global_step: 14883, epoch: 73, loss: 0.769739
global_step: 14884, epoch: 73, loss: 0.712133
global_step: 14885, epoch: 73, loss: 0.872075
global_step: 14886, epoch: 73, loss: 0.686615
global_step: 14887, epoch: 73, loss: 0.850859
global_step: 14888, epoch: 73, loss: 0.763062
global_step: 14889, epoch: 73, loss: 0.790599
global_step: 14890, epoch: 73, loss: 0.883301
global_step: 14891, epoch: 73, loss: 0.814871
global_step: 14892, epoch: 73, loss: 0.930309
global_step: 14893, epoch: 73, loss: 0.776358
global_step: 14894, epoch: 73, loss: 0.832743
global_step: 14895, epoch: 73, loss: 0.818036
global_step: 14896, epoch: 73, loss: 0.809867
global_step: 14897, epoch: 73, loss: 0.817564
global_step: 14898, epoch: 73, loss: 0.810687
global_step: 14899, epoch: 73, loss: 0.838637
global_step: 14900, epoch: 73, loss: 0.810220
global_step: 14901, epoch: 73, loss: 0.829357
global_step: 14902, epoch: 73, loss: 0.789715
global_step: 14903, epoch: 73, loss: 0.826972
global_step: 14904, epoch: 73, loss: 0.788355
global_step: 14905, epoch: 73, loss: 0.706808
global_step: 14906, epoch: 73, loss: 0.674157
global_step: 14907, epoch: 73, loss: 0.927157
global_step: 14908, epoch: 73, loss: 0.824742
global_step: 14909, epoch: 73, loss: 0.709151
global_step: 14910, epoch: 73, loss: 0.897635
global_step: 14911, epoch: 73, loss: 0.825675
global_step: 14912, epoch: 73, loss: 0.788157
global_step: 14913, epoch: 73, loss: 0.907660
global_step: 14914, epoch: 73, loss: 0.887364
global_step: 14915, epoch: 73, loss: 0.820154
global_step: 14916, epoch: 73, loss: 0.775355
global_step: 14917, epoch: 73, loss: 0.779914
global_step: 14918, epoch: 73, loss: 0.912192
global_step: 14919, epoch: 73, loss: 0.940856
global_step: 14920, epoch: 73, loss: 0.786103
epoch: 73
train	acc: 0.8155	macro: p 0.7050, r 0.5654, f1: 0.5627	micro: p 0.8155, r 0.8155, f1 0.8155	weighted_f1:0.7918
dev	acc: 0.5455	macro: p 0.3249, r 0.3089, f1: 0.3037	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4974
test	acc: 0.5927	macro: p 0.3490, r 0.3206, f1: 0.3225	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5537
global_step: 14921, epoch: 74, loss: 0.885323
global_step: 14922, epoch: 74, loss: 0.814097
global_step: 14923, epoch: 74, loss: 0.854629
global_step: 14924, epoch: 74, loss: 0.819670
global_step: 14925, epoch: 74, loss: 0.773239
global_step: 14926, epoch: 74, loss: 0.836361
global_step: 14927, epoch: 74, loss: 0.816154
global_step: 14928, epoch: 74, loss: 0.845970
global_step: 14929, epoch: 74, loss: 0.857931
global_step: 14930, epoch: 74, loss: 0.864823
global_step: 14931, epoch: 74, loss: 0.850516
global_step: 14932, epoch: 74, loss: 0.775235
global_step: 14933, epoch: 74, loss: 0.755987
global_step: 14934, epoch: 74, loss: 0.789020
global_step: 14935, epoch: 74, loss: 0.677998
global_step: 14936, epoch: 74, loss: 0.781577
global_step: 14937, epoch: 74, loss: 0.790621
global_step: 14938, epoch: 74, loss: 0.786937
global_step: 14939, epoch: 74, loss: 0.846431
global_step: 14940, epoch: 74, loss: 0.881286
global_step: 14941, epoch: 74, loss: 0.811576
global_step: 14942, epoch: 74, loss: 0.762735
global_step: 14943, epoch: 74, loss: 0.828387
global_step: 14944, epoch: 74, loss: 0.839795
global_step: 14945, epoch: 74, loss: 0.761343
global_step: 14946, epoch: 74, loss: 0.797539
global_step: 14947, epoch: 74, loss: 0.901102
global_step: 14948, epoch: 74, loss: 0.851720
global_step: 14949, epoch: 74, loss: 0.862731
global_step: 14950, epoch: 74, loss: 0.835566
global_step: 14951, epoch: 74, loss: 0.801607
global_step: 14952, epoch: 74, loss: 0.687418
global_step: 14953, epoch: 74, loss: 0.801914
global_step: 14954, epoch: 74, loss: 0.905290
global_step: 14955, epoch: 74, loss: 0.795439
global_step: 14956, epoch: 74, loss: 0.879119
global_step: 14957, epoch: 74, loss: 0.821085
global_step: 14958, epoch: 74, loss: 0.831819
global_step: 14959, epoch: 74, loss: 0.822556
global_step: 14960, epoch: 74, loss: 0.702929
epoch: 74
train	acc: 0.8136	macro: p 0.8479, r 0.5598, f1: 0.5621	micro: p 0.8136, r 0.8136, f1 0.8136	weighted_f1:0.7887
dev	acc: 0.5419	macro: p 0.3210, r 0.3004, f1: 0.2935	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4888
test	acc: 0.5989	macro: p 0.3563, r 0.3195, f1: 0.3212	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5543
global_step: 14961, epoch: 75, loss: 0.696414
global_step: 14962, epoch: 75, loss: 0.982562
global_step: 14963, epoch: 75, loss: 0.785899
global_step: 14964, epoch: 75, loss: 0.845402
global_step: 14965, epoch: 75, loss: 0.854427
global_step: 14966, epoch: 75, loss: 0.836814
global_step: 14967, epoch: 75, loss: 0.784319
global_step: 14968, epoch: 75, loss: 0.866104
global_step: 14969, epoch: 75, loss: 0.893029
global_step: 14970, epoch: 75, loss: 0.697878
global_step: 14971, epoch: 75, loss: 0.784215
global_step: 14972, epoch: 75, loss: 0.806504
global_step: 14973, epoch: 75, loss: 0.868138
global_step: 14974, epoch: 75, loss: 0.710649
global_step: 14975, epoch: 75, loss: 0.836637
global_step: 14976, epoch: 75, loss: 0.722189
global_step: 14977, epoch: 75, loss: 0.729848
global_step: 14978, epoch: 75, loss: 0.856177
global_step: 14979, epoch: 75, loss: 0.889077
global_step: 14980, epoch: 75, loss: 0.807618
global_step: 14981, epoch: 75, loss: 0.773632
global_step: 14982, epoch: 75, loss: 0.667454
global_step: 14983, epoch: 75, loss: 0.775440
global_step: 14984, epoch: 75, loss: 0.697350
global_step: 14985, epoch: 75, loss: 0.805417
global_step: 14986, epoch: 75, loss: 0.847431
global_step: 14987, epoch: 75, loss: 0.823906
global_step: 14988, epoch: 75, loss: 0.895224
global_step: 14989, epoch: 75, loss: 0.852119
global_step: 14990, epoch: 75, loss: 0.772720
global_step: 14991, epoch: 75, loss: 0.816648
global_step: 14992, epoch: 75, loss: 0.851957
global_step: 14993, epoch: 75, loss: 0.684925
global_step: 14994, epoch: 75, loss: 0.786056
global_step: 14995, epoch: 75, loss: 0.826260
global_step: 14996, epoch: 75, loss: 0.750343
global_step: 14997, epoch: 75, loss: 0.917967
global_step: 14998, epoch: 75, loss: 0.846695
global_step: 14999, epoch: 75, loss: 0.870048
global_step: 15000, epoch: 75, loss: 0.608192
epoch: 75
train	acc: 0.8187	macro: p 0.8532, r 0.5663, f1: 0.5680	micro: p 0.8187, r 0.8187, f1 0.8187	weighted_f1:0.7948
dev	acc: 0.5437	macro: p 0.3248, r 0.3038, f1: 0.2980	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4931
test	acc: 0.5950	macro: p 0.3589, r 0.3188, f1: 0.3220	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5537
global_step: 15001, epoch: 76, loss: 0.942695
global_step: 15002, epoch: 76, loss: 0.717628
global_step: 15003, epoch: 76, loss: 0.784763
global_step: 15004, epoch: 76, loss: 0.747731
global_step: 15005, epoch: 76, loss: 0.808471
global_step: 15006, epoch: 76, loss: 0.767836
global_step: 15007, epoch: 76, loss: 0.803073
global_step: 15008, epoch: 76, loss: 0.817895
global_step: 15009, epoch: 76, loss: 0.735899
global_step: 15010, epoch: 76, loss: 0.836133
global_step: 15011, epoch: 76, loss: 0.731120
global_step: 15012, epoch: 76, loss: 0.755911
global_step: 15013, epoch: 76, loss: 0.818188
global_step: 15014, epoch: 76, loss: 0.718964
global_step: 15015, epoch: 76, loss: 0.807348
global_step: 15016, epoch: 76, loss: 0.753022
global_step: 15017, epoch: 76, loss: 0.717598
global_step: 15018, epoch: 76, loss: 0.811010
global_step: 15019, epoch: 76, loss: 0.832432
global_step: 15020, epoch: 76, loss: 0.806277
global_step: 15021, epoch: 76, loss: 0.809733
global_step: 15022, epoch: 76, loss: 0.792042
global_step: 15023, epoch: 76, loss: 0.749189
global_step: 15024, epoch: 76, loss: 0.787977
global_step: 15025, epoch: 76, loss: 0.894957
global_step: 15026, epoch: 76, loss: 0.771768
global_step: 15027, epoch: 76, loss: 0.849727
global_step: 15028, epoch: 76, loss: 0.734631
global_step: 15029, epoch: 76, loss: 0.801655
global_step: 15030, epoch: 76, loss: 0.794930
global_step: 15031, epoch: 76, loss: 0.719784
global_step: 15032, epoch: 76, loss: 0.707127
global_step: 15033, epoch: 76, loss: 0.773027
global_step: 15034, epoch: 76, loss: 0.803623
global_step: 15035, epoch: 76, loss: 0.835273
global_step: 15036, epoch: 76, loss: 0.794661
global_step: 15037, epoch: 76, loss: 0.843043
global_step: 15038, epoch: 76, loss: 0.797599
global_step: 15039, epoch: 76, loss: 0.812808
global_step: 15040, epoch: 76, loss: 0.532931
epoch: 76
train	acc: 0.8216	macro: p 0.8546, r 0.5718, f1: 0.5702	micro: p 0.8216, r 0.8216, f1 0.8216	weighted_f1:0.7986
dev	acc: 0.5464	macro: p 0.3292, r 0.3071, f1: 0.3026	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4969
test	acc: 0.5927	macro: p 0.3575, r 0.3177, f1: 0.3207	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5524
global_step: 15041, epoch: 77, loss: 0.789703
global_step: 15042, epoch: 77, loss: 0.686236
global_step: 15043, epoch: 77, loss: 0.791348
global_step: 15044, epoch: 77, loss: 0.790037
global_step: 15045, epoch: 77, loss: 0.727814
global_step: 15046, epoch: 77, loss: 0.865953
global_step: 15047, epoch: 77, loss: 0.921311
global_step: 15048, epoch: 77, loss: 0.701793
global_step: 15049, epoch: 77, loss: 0.792692
global_step: 15050, epoch: 77, loss: 0.782074
global_step: 15051, epoch: 77, loss: 0.801457
global_step: 15052, epoch: 77, loss: 0.871909
global_step: 15053, epoch: 77, loss: 0.711894
global_step: 15054, epoch: 77, loss: 0.706621
global_step: 15055, epoch: 77, loss: 0.866131
global_step: 15056, epoch: 77, loss: 0.838989
global_step: 15057, epoch: 77, loss: 0.851037
global_step: 15058, epoch: 77, loss: 0.814336
global_step: 15059, epoch: 77, loss: 0.850463
global_step: 15060, epoch: 77, loss: 0.763531
global_step: 15061, epoch: 77, loss: 0.761042
global_step: 15062, epoch: 77, loss: 0.914165
global_step: 15063, epoch: 77, loss: 0.797572
global_step: 15064, epoch: 77, loss: 0.742562
global_step: 15065, epoch: 77, loss: 0.731554
global_step: 15066, epoch: 77, loss: 0.770450
global_step: 15067, epoch: 77, loss: 0.779602
global_step: 15068, epoch: 77, loss: 0.723760
global_step: 15069, epoch: 77, loss: 0.784436
global_step: 15070, epoch: 77, loss: 0.808712
global_step: 15071, epoch: 77, loss: 0.667993
global_step: 15072, epoch: 77, loss: 0.752016
global_step: 15073, epoch: 77, loss: 0.815370
global_step: 15074, epoch: 77, loss: 0.887534
global_step: 15075, epoch: 77, loss: 0.743623
global_step: 15076, epoch: 77, loss: 0.864129
global_step: 15077, epoch: 77, loss: 0.716696
global_step: 15078, epoch: 77, loss: 0.799815
global_step: 15079, epoch: 77, loss: 0.733142
global_step: 15080, epoch: 77, loss: 0.470633
epoch: 77
train	acc: 0.8174	macro: p 0.8568, r 0.5608, f1: 0.5656	micro: p 0.8174, r 0.8174, f1 0.8174	weighted_f1:0.7922
dev	acc: 0.5455	macro: p 0.3301, r 0.3044, f1: 0.2974	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4926
test	acc: 0.6015	macro: p 0.3727, r 0.3198, f1: 0.3231	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5565
global_step: 15081, epoch: 78, loss: 0.690284
global_step: 15082, epoch: 78, loss: 0.843619
global_step: 15083, epoch: 78, loss: 0.812083
global_step: 15084, epoch: 78, loss: 0.756688
global_step: 15085, epoch: 78, loss: 0.686348
global_step: 15086, epoch: 78, loss: 0.667081
global_step: 15087, epoch: 78, loss: 0.788349
global_step: 15088, epoch: 78, loss: 0.734322
global_step: 15089, epoch: 78, loss: 0.740752
global_step: 15090, epoch: 78, loss: 0.771913
global_step: 15091, epoch: 78, loss: 0.713998
global_step: 15092, epoch: 78, loss: 0.866938
global_step: 15093, epoch: 78, loss: 0.844898
global_step: 15094, epoch: 78, loss: 0.783466
global_step: 15095, epoch: 78, loss: 0.782630
global_step: 15096, epoch: 78, loss: 0.846126
global_step: 15097, epoch: 78, loss: 0.757267
global_step: 15098, epoch: 78, loss: 0.822715
global_step: 15099, epoch: 78, loss: 0.766473
global_step: 15100, epoch: 78, loss: 0.815474
global_step: 15101, epoch: 78, loss: 0.682892
global_step: 15102, epoch: 78, loss: 0.787727
global_step: 15103, epoch: 78, loss: 0.757043
global_step: 15104, epoch: 78, loss: 0.812394
global_step: 15105, epoch: 78, loss: 0.811009
global_step: 15106, epoch: 78, loss: 0.812708
global_step: 15107, epoch: 78, loss: 0.765640
global_step: 15108, epoch: 78, loss: 0.890739
global_step: 15109, epoch: 78, loss: 0.790524
global_step: 15110, epoch: 78, loss: 0.796168
global_step: 15111, epoch: 78, loss: 0.720574
global_step: 15112, epoch: 78, loss: 0.743995
global_step: 15113, epoch: 78, loss: 0.888568
global_step: 15114, epoch: 78, loss: 0.887352
global_step: 15115, epoch: 78, loss: 0.799603
global_step: 15116, epoch: 78, loss: 0.806139
global_step: 15117, epoch: 78, loss: 0.860143
global_step: 15118, epoch: 78, loss: 0.862867
global_step: 15119, epoch: 78, loss: 0.684097
global_step: 15120, epoch: 78, loss: 0.328309
epoch: 78
train	acc: 0.8240	macro: p 0.8604, r 0.5720, f1: 0.5777	micro: p 0.8240, r 0.8240, f1 0.8240	weighted_f1:0.7995
dev	acc: 0.5464	macro: p 0.3275, r 0.3048, f1: 0.2973	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4922
test	acc: 0.5977	macro: p 0.3583, r 0.3178, f1: 0.3179	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5522
global_step: 15121, epoch: 79, loss: 0.603279
global_step: 15122, epoch: 79, loss: 0.820533
global_step: 15123, epoch: 79, loss: 0.730602
global_step: 15124, epoch: 79, loss: 0.751480
global_step: 15125, epoch: 79, loss: 0.761796
global_step: 15126, epoch: 79, loss: 0.790573
global_step: 15127, epoch: 79, loss: 0.763745
global_step: 15128, epoch: 79, loss: 0.871790
global_step: 15129, epoch: 79, loss: 0.767063
global_step: 15130, epoch: 79, loss: 0.743672
global_step: 15131, epoch: 79, loss: 0.816916
global_step: 15132, epoch: 79, loss: 0.724396
global_step: 15133, epoch: 79, loss: 0.750100
global_step: 15134, epoch: 79, loss: 0.725368
global_step: 15135, epoch: 79, loss: 0.717800
global_step: 15136, epoch: 79, loss: 0.727012
global_step: 15137, epoch: 79, loss: 0.735514
global_step: 15138, epoch: 79, loss: 0.736875
global_step: 15139, epoch: 79, loss: 0.752522
global_step: 15140, epoch: 79, loss: 0.768406
global_step: 15141, epoch: 79, loss: 0.830198
global_step: 15142, epoch: 79, loss: 0.861878
global_step: 15143, epoch: 79, loss: 0.930882
global_step: 15144, epoch: 79, loss: 0.767580
global_step: 15145, epoch: 79, loss: 0.753505
global_step: 15146, epoch: 79, loss: 0.858711
global_step: 15147, epoch: 79, loss: 0.830107
global_step: 15148, epoch: 79, loss: 0.784261
global_step: 15149, epoch: 79, loss: 0.734870
global_step: 15150, epoch: 79, loss: 0.674520
global_step: 15151, epoch: 79, loss: 0.884750
global_step: 15152, epoch: 79, loss: 0.793576
global_step: 15153, epoch: 79, loss: 0.762379
global_step: 15154, epoch: 79, loss: 0.802932
global_step: 15155, epoch: 79, loss: 0.839077
global_step: 15156, epoch: 79, loss: 0.842869
global_step: 15157, epoch: 79, loss: 0.854703
global_step: 15158, epoch: 79, loss: 0.799554
global_step: 15159, epoch: 79, loss: 0.834482
global_step: 15160, epoch: 79, loss: 0.185519
epoch: 79
train	acc: 0.8345	macro: p 0.8596, r 0.5875, f1: 0.5855	micro: p 0.8345, r 0.8345, f1 0.8345	weighted_f1:0.8108
dev	acc: 0.5446	macro: p 0.3223, r 0.3060, f1: 0.2968	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4916
test	acc: 0.5908	macro: p 0.3447, r 0.3177, f1: 0.3167	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5485
global_step: 15161, epoch: 80, loss: 0.677470
global_step: 15162, epoch: 80, loss: 0.672178
global_step: 15163, epoch: 80, loss: 0.643076
global_step: 15164, epoch: 80, loss: 0.767645
global_step: 15165, epoch: 80, loss: 0.768854
global_step: 15166, epoch: 80, loss: 0.734299
global_step: 15167, epoch: 80, loss: 0.793355
global_step: 15168, epoch: 80, loss: 0.784988
global_step: 15169, epoch: 80, loss: 0.820854
global_step: 15170, epoch: 80, loss: 0.815028
global_step: 15171, epoch: 80, loss: 0.755077
global_step: 15172, epoch: 80, loss: 0.684178
global_step: 15173, epoch: 80, loss: 0.780306
global_step: 15174, epoch: 80, loss: 0.748004
global_step: 15175, epoch: 80, loss: 0.768365
global_step: 15176, epoch: 80, loss: 0.929289
global_step: 15177, epoch: 80, loss: 0.796512
global_step: 15178, epoch: 80, loss: 0.815626
global_step: 15179, epoch: 80, loss: 0.839808
global_step: 15180, epoch: 80, loss: 0.771948
global_step: 15181, epoch: 80, loss: 0.745015
global_step: 15182, epoch: 80, loss: 0.786015
global_step: 15183, epoch: 80, loss: 0.646138
global_step: 15184, epoch: 80, loss: 0.828748
global_step: 15185, epoch: 80, loss: 0.746030
global_step: 15186, epoch: 80, loss: 0.792576
global_step: 15187, epoch: 80, loss: 0.846529
global_step: 15188, epoch: 80, loss: 0.728341
global_step: 15189, epoch: 80, loss: 0.769270
global_step: 15190, epoch: 80, loss: 0.795524
global_step: 15191, epoch: 80, loss: 0.763008
global_step: 15192, epoch: 80, loss: 0.866479
global_step: 15193, epoch: 80, loss: 0.902658
global_step: 15194, epoch: 80, loss: 0.751998
global_step: 15195, epoch: 80, loss: 0.716453
global_step: 15196, epoch: 80, loss: 0.820549
global_step: 15197, epoch: 80, loss: 0.685377
global_step: 15198, epoch: 80, loss: 0.794427
global_step: 15199, epoch: 80, loss: 0.763728
global_step: 15200, epoch: 80, loss: 0.160425
epoch: 80
train	acc: 0.8315	macro: p 0.8641, r 0.5824, f1: 0.5829	micro: p 0.8315, r 0.8315, f1 0.8315	weighted_f1:0.8082
dev	acc: 0.5446	macro: p 0.3285, r 0.3057, f1: 0.2999	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4945
test	acc: 0.5939	macro: p 0.3601, r 0.3195, f1: 0.3216	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5527
global_step: 15201, epoch: 81, loss: 0.752077
global_step: 15202, epoch: 81, loss: 0.837880
global_step: 15203, epoch: 81, loss: 0.748606
global_step: 15204, epoch: 81, loss: 0.732910
global_step: 15205, epoch: 81, loss: 0.822426
global_step: 15206, epoch: 81, loss: 0.723665
global_step: 15207, epoch: 81, loss: 0.704991
global_step: 15208, epoch: 81, loss: 0.806681
global_step: 15209, epoch: 81, loss: 0.837365
global_step: 15210, epoch: 81, loss: 0.695673
global_step: 15211, epoch: 81, loss: 0.781498
global_step: 15212, epoch: 81, loss: 0.857649
global_step: 15213, epoch: 81, loss: 0.750790
global_step: 15214, epoch: 81, loss: 0.888761
global_step: 15215, epoch: 81, loss: 0.782117
global_step: 15216, epoch: 81, loss: 0.728384
global_step: 15217, epoch: 81, loss: 0.767760
global_step: 15218, epoch: 81, loss: 0.769547
global_step: 15219, epoch: 81, loss: 0.846549
global_step: 15220, epoch: 81, loss: 0.622525
global_step: 15221, epoch: 81, loss: 0.663989
global_step: 15222, epoch: 81, loss: 0.748281
global_step: 15223, epoch: 81, loss: 0.838628
global_step: 15224, epoch: 81, loss: 0.831415
global_step: 15225, epoch: 81, loss: 0.762887
global_step: 15226, epoch: 81, loss: 0.743137
global_step: 15227, epoch: 81, loss: 0.762893
global_step: 15228, epoch: 81, loss: 0.859253
global_step: 15229, epoch: 81, loss: 0.807448
global_step: 15230, epoch: 81, loss: 0.837868
global_step: 15231, epoch: 81, loss: 0.713032
global_step: 15232, epoch: 81, loss: 0.714367
global_step: 15233, epoch: 81, loss: 0.687862
global_step: 15234, epoch: 81, loss: 0.713032
global_step: 15235, epoch: 81, loss: 0.795170
global_step: 15236, epoch: 81, loss: 0.811170
global_step: 15237, epoch: 81, loss: 0.742145
global_step: 15238, epoch: 81, loss: 0.710449
global_step: 15239, epoch: 81, loss: 0.689867
global_step: 15240, epoch: 81, loss: 0.497446
epoch: 81
train	acc: 0.8302	macro: p 0.8642, r 0.5805, f1: 0.5851	micro: p 0.8302, r 0.8302, f1 0.8302	weighted_f1:0.8063
dev	acc: 0.5374	macro: p 0.3222, r 0.2970, f1: 0.2866	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4809
test	acc: 0.5958	macro: p 0.3600, r 0.3148, f1: 0.3160	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5489
global_step: 15241, epoch: 82, loss: 0.777291
global_step: 15242, epoch: 82, loss: 0.841841
global_step: 15243, epoch: 82, loss: 0.762361
global_step: 15244, epoch: 82, loss: 0.730170
global_step: 15245, epoch: 82, loss: 0.754312
global_step: 15246, epoch: 82, loss: 0.747113
global_step: 15247, epoch: 82, loss: 0.821004
global_step: 15248, epoch: 82, loss: 0.732684
global_step: 15249, epoch: 82, loss: 0.742627
global_step: 15250, epoch: 82, loss: 0.754984
global_step: 15251, epoch: 82, loss: 0.759518
global_step: 15252, epoch: 82, loss: 0.814456
global_step: 15253, epoch: 82, loss: 0.773339
global_step: 15254, epoch: 82, loss: 0.736730
global_step: 15255, epoch: 82, loss: 0.665640
global_step: 15256, epoch: 82, loss: 0.734109
global_step: 15257, epoch: 82, loss: 0.769559
global_step: 15258, epoch: 82, loss: 0.749193
global_step: 15259, epoch: 82, loss: 0.852666
global_step: 15260, epoch: 82, loss: 0.691917
global_step: 15261, epoch: 82, loss: 0.754782
global_step: 15262, epoch: 82, loss: 0.660169
global_step: 15263, epoch: 82, loss: 0.659858
global_step: 15264, epoch: 82, loss: 0.734655
global_step: 15265, epoch: 82, loss: 0.776984
global_step: 15266, epoch: 82, loss: 0.768012
global_step: 15267, epoch: 82, loss: 0.743159
global_step: 15268, epoch: 82, loss: 0.764104
global_step: 15269, epoch: 82, loss: 0.797770
global_step: 15270, epoch: 82, loss: 0.763042
global_step: 15271, epoch: 82, loss: 0.679888
global_step: 15272, epoch: 82, loss: 0.752053
global_step: 15273, epoch: 82, loss: 0.768842
global_step: 15274, epoch: 82, loss: 0.770131
global_step: 15275, epoch: 82, loss: 0.764849
global_step: 15276, epoch: 82, loss: 0.873480
global_step: 15277, epoch: 82, loss: 0.756255
global_step: 15278, epoch: 82, loss: 0.718281
global_step: 15279, epoch: 82, loss: 0.850590
global_step: 15280, epoch: 82, loss: 0.846153
epoch: 82
train	acc: 0.8382	macro: p 0.8651, r 0.5987, f1: 0.6041	micro: p 0.8382, r 0.8382, f1 0.8382	weighted_f1:0.8170
dev	acc: 0.5374	macro: p 0.3287, r 0.3033, f1: 0.2937	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4881
test	acc: 0.5935	macro: p 0.3534, r 0.3227, f1: 0.3213	micro: p 0.5935, r 0.5935, f1 0.5935	weighted_f1:0.5529
global_step: 15281, epoch: 83, loss: 0.689918
global_step: 15282, epoch: 83, loss: 0.691266
global_step: 15283, epoch: 83, loss: 0.732188
global_step: 15284, epoch: 83, loss: 0.719195
global_step: 15285, epoch: 83, loss: 0.710054
global_step: 15286, epoch: 83, loss: 0.823600
global_step: 15287, epoch: 83, loss: 0.701714
global_step: 15288, epoch: 83, loss: 0.708308
global_step: 15289, epoch: 83, loss: 0.704498
global_step: 15290, epoch: 83, loss: 0.685241
global_step: 15291, epoch: 83, loss: 0.757021
global_step: 15292, epoch: 83, loss: 0.751738
global_step: 15293, epoch: 83, loss: 0.781315
global_step: 15294, epoch: 83, loss: 0.760304
global_step: 15295, epoch: 83, loss: 0.767112
global_step: 15296, epoch: 83, loss: 0.695697
global_step: 15297, epoch: 83, loss: 0.726539
global_step: 15298, epoch: 83, loss: 0.750589
global_step: 15299, epoch: 83, loss: 0.830454
global_step: 15300, epoch: 83, loss: 0.766098
global_step: 15301, epoch: 83, loss: 0.681315
global_step: 15302, epoch: 83, loss: 0.868917
global_step: 15303, epoch: 83, loss: 0.761094
global_step: 15304, epoch: 83, loss: 0.821459
global_step: 15305, epoch: 83, loss: 0.675021
global_step: 15306, epoch: 83, loss: 0.847000
global_step: 15307, epoch: 83, loss: 0.820204
global_step: 15308, epoch: 83, loss: 0.791290
global_step: 15309, epoch: 83, loss: 0.734013
global_step: 15310, epoch: 83, loss: 0.770674
global_step: 15311, epoch: 83, loss: 0.802217
global_step: 15312, epoch: 83, loss: 0.698365
global_step: 15313, epoch: 83, loss: 0.871101
global_step: 15314, epoch: 83, loss: 0.731844
global_step: 15315, epoch: 83, loss: 0.704178
global_step: 15316, epoch: 83, loss: 0.813766
global_step: 15317, epoch: 83, loss: 0.738329
global_step: 15318, epoch: 83, loss: 0.725559
global_step: 15319, epoch: 83, loss: 0.718491
global_step: 15320, epoch: 83, loss: 0.839072
epoch: 83
train	acc: 0.8486	macro: p 0.8709, r 0.6151, f1: 0.6210	micro: p 0.8486, r 0.8486, f1 0.8486	weighted_f1:0.8283
dev	acc: 0.5419	macro: p 0.3205, r 0.3039, f1: 0.2965	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4909
test	acc: 0.5927	macro: p 0.3451, r 0.3225, f1: 0.3219	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5528
global_step: 15321, epoch: 84, loss: 0.825315
global_step: 15322, epoch: 84, loss: 0.735718
global_step: 15323, epoch: 84, loss: 0.654276
global_step: 15324, epoch: 84, loss: 0.702927
global_step: 15325, epoch: 84, loss: 0.645871
global_step: 15326, epoch: 84, loss: 0.754128
global_step: 15327, epoch: 84, loss: 0.714657
global_step: 15328, epoch: 84, loss: 0.705025
global_step: 15329, epoch: 84, loss: 0.664412
global_step: 15330, epoch: 84, loss: 0.726384
global_step: 15331, epoch: 84, loss: 0.707145
global_step: 15332, epoch: 84, loss: 0.708852
global_step: 15333, epoch: 84, loss: 0.781746
global_step: 15334, epoch: 84, loss: 0.756028
global_step: 15335, epoch: 84, loss: 0.807535
global_step: 15336, epoch: 84, loss: 0.751147
global_step: 15337, epoch: 84, loss: 0.671941
global_step: 15338, epoch: 84, loss: 0.662649
global_step: 15339, epoch: 84, loss: 0.813143
global_step: 15340, epoch: 84, loss: 0.709022
global_step: 15341, epoch: 84, loss: 0.873300
global_step: 15342, epoch: 84, loss: 0.735904
global_step: 15343, epoch: 84, loss: 0.670092
global_step: 15344, epoch: 84, loss: 0.761811
global_step: 15345, epoch: 84, loss: 0.839693
global_step: 15346, epoch: 84, loss: 0.748371
global_step: 15347, epoch: 84, loss: 0.766264
global_step: 15348, epoch: 84, loss: 0.649830
global_step: 15349, epoch: 84, loss: 0.690148
global_step: 15350, epoch: 84, loss: 0.835325
global_step: 15351, epoch: 84, loss: 0.741967
global_step: 15352, epoch: 84, loss: 0.768761
global_step: 15353, epoch: 84, loss: 0.784813
global_step: 15354, epoch: 84, loss: 0.720365
global_step: 15355, epoch: 84, loss: 0.776322
global_step: 15356, epoch: 84, loss: 0.774646
global_step: 15357, epoch: 84, loss: 0.719280
global_step: 15358, epoch: 84, loss: 0.725270
global_step: 15359, epoch: 84, loss: 0.735474
global_step: 15360, epoch: 84, loss: 1.473780
epoch: 84
train	acc: 0.8490	macro: p 0.8736, r 0.6097, f1: 0.6152	micro: p 0.8490, r 0.8490, f1 0.8490	weighted_f1:0.8276
dev	acc: 0.5401	macro: p 0.3231, r 0.3028, f1: 0.2934	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4871
test	acc: 0.5950	macro: p 0.3561, r 0.3219, f1: 0.3204	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5524
global_step: 15361, epoch: 85, loss: 0.743843
global_step: 15362, epoch: 85, loss: 0.773559
global_step: 15363, epoch: 85, loss: 0.730732
global_step: 15364, epoch: 85, loss: 0.761237
global_step: 15365, epoch: 85, loss: 0.730497
global_step: 15366, epoch: 85, loss: 0.711278
global_step: 15367, epoch: 85, loss: 0.889365
global_step: 15368, epoch: 85, loss: 0.608483
global_step: 15369, epoch: 85, loss: 0.700579
global_step: 15370, epoch: 85, loss: 0.773043
global_step: 15371, epoch: 85, loss: 0.653319
global_step: 15372, epoch: 85, loss: 0.655093
global_step: 15373, epoch: 85, loss: 0.679986
global_step: 15374, epoch: 85, loss: 0.700456
global_step: 15375, epoch: 85, loss: 0.775776
global_step: 15376, epoch: 85, loss: 0.842713
global_step: 15377, epoch: 85, loss: 0.779295
global_step: 15378, epoch: 85, loss: 0.701196
global_step: 15379, epoch: 85, loss: 0.648862
global_step: 15380, epoch: 85, loss: 0.712925
global_step: 15381, epoch: 85, loss: 0.708555
global_step: 15382, epoch: 85, loss: 0.801239
global_step: 15383, epoch: 85, loss: 0.739057
global_step: 15384, epoch: 85, loss: 0.778859
global_step: 15385, epoch: 85, loss: 0.646567
global_step: 15386, epoch: 85, loss: 0.714032
global_step: 15387, epoch: 85, loss: 0.697964
global_step: 15388, epoch: 85, loss: 0.756353
global_step: 15389, epoch: 85, loss: 0.689071
global_step: 15390, epoch: 85, loss: 0.704658
global_step: 15391, epoch: 85, loss: 0.804077
global_step: 15392, epoch: 85, loss: 0.674761
global_step: 15393, epoch: 85, loss: 0.717269
global_step: 15394, epoch: 85, loss: 0.676683
global_step: 15395, epoch: 85, loss: 0.737652
global_step: 15396, epoch: 85, loss: 0.786036
global_step: 15397, epoch: 85, loss: 0.777651
global_step: 15398, epoch: 85, loss: 0.811946
global_step: 15399, epoch: 85, loss: 0.704252
global_step: 15400, epoch: 85, loss: 0.897725
epoch: 85
train	acc: 0.8534	macro: p 0.8729, r 0.6263, f1: 0.6347	micro: p 0.8534, r 0.8534, f1 0.8534	weighted_f1:0.8344
dev	acc: 0.5338	macro: p 0.3120, r 0.2993, f1: 0.2906	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4843
test	acc: 0.5920	macro: p 0.3479, r 0.3229, f1: 0.3238	micro: p 0.5920, r 0.5920, f1 0.5920	weighted_f1:0.5541
global_step: 15401, epoch: 86, loss: 0.724970
global_step: 15402, epoch: 86, loss: 0.756362
global_step: 15403, epoch: 86, loss: 0.626065
global_step: 15404, epoch: 86, loss: 0.715226
global_step: 15405, epoch: 86, loss: 0.823519
global_step: 15406, epoch: 86, loss: 0.762073
global_step: 15407, epoch: 86, loss: 0.679336
global_step: 15408, epoch: 86, loss: 0.739365
global_step: 15409, epoch: 86, loss: 0.677560
global_step: 15410, epoch: 86, loss: 0.713577
global_step: 15411, epoch: 86, loss: 0.738434
global_step: 15412, epoch: 86, loss: 0.806157
global_step: 15413, epoch: 86, loss: 0.709310
global_step: 15414, epoch: 86, loss: 0.630206
global_step: 15415, epoch: 86, loss: 0.752794
global_step: 15416, epoch: 86, loss: 0.685845
global_step: 15417, epoch: 86, loss: 0.745716
global_step: 15418, epoch: 86, loss: 0.750046
global_step: 15419, epoch: 86, loss: 0.860990
global_step: 15420, epoch: 86, loss: 0.728230
global_step: 15421, epoch: 86, loss: 0.742857
global_step: 15422, epoch: 86, loss: 0.739499
global_step: 15423, epoch: 86, loss: 0.625519
global_step: 15424, epoch: 86, loss: 0.827461
global_step: 15425, epoch: 86, loss: 0.725328
global_step: 15426, epoch: 86, loss: 0.678865
global_step: 15427, epoch: 86, loss: 0.752346
global_step: 15428, epoch: 86, loss: 0.739379
global_step: 15429, epoch: 86, loss: 0.729300
global_step: 15430, epoch: 86, loss: 0.722002
global_step: 15431, epoch: 86, loss: 0.719918
global_step: 15432, epoch: 86, loss: 0.729711
global_step: 15433, epoch: 86, loss: 0.597789
global_step: 15434, epoch: 86, loss: 0.700629
global_step: 15435, epoch: 86, loss: 0.699636
global_step: 15436, epoch: 86, loss: 0.747345
global_step: 15437, epoch: 86, loss: 0.824671
global_step: 15438, epoch: 86, loss: 0.693563
global_step: 15439, epoch: 86, loss: 0.749319
global_step: 15440, epoch: 86, loss: 0.376023
epoch: 86
train	acc: 0.8488	macro: p 0.8766, r 0.6112, f1: 0.6214	micro: p 0.8488, r 0.8488, f1 0.8488	weighted_f1:0.8281
dev	acc: 0.5401	macro: p 0.3226, r 0.3003, f1: 0.2934	micro: p 0.5401, r 0.5401, f1 0.5401	weighted_f1:0.4879
test	acc: 0.5977	macro: p 0.3592, r 0.3208, f1: 0.3219	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5548
global_step: 15441, epoch: 87, loss: 0.634231
global_step: 15442, epoch: 87, loss: 0.675322
global_step: 15443, epoch: 87, loss: 0.784501
global_step: 15444, epoch: 87, loss: 0.762819
global_step: 15445, epoch: 87, loss: 0.660617
global_step: 15446, epoch: 87, loss: 0.659719
global_step: 15447, epoch: 87, loss: 0.737085
global_step: 15448, epoch: 87, loss: 0.693823
global_step: 15449, epoch: 87, loss: 0.661865
global_step: 15450, epoch: 87, loss: 0.693298
global_step: 15451, epoch: 87, loss: 0.675481
global_step: 15452, epoch: 87, loss: 0.703819
global_step: 15453, epoch: 87, loss: 0.721439
global_step: 15454, epoch: 87, loss: 0.746051
global_step: 15455, epoch: 87, loss: 0.744349
global_step: 15456, epoch: 87, loss: 0.686898
global_step: 15457, epoch: 87, loss: 0.646116
global_step: 15458, epoch: 87, loss: 0.755162
global_step: 15459, epoch: 87, loss: 0.767364
global_step: 15460, epoch: 87, loss: 0.767526
global_step: 15461, epoch: 87, loss: 0.697892
global_step: 15462, epoch: 87, loss: 0.679490
global_step: 15463, epoch: 87, loss: 0.691451
global_step: 15464, epoch: 87, loss: 0.738702
global_step: 15465, epoch: 87, loss: 0.713823
global_step: 15466, epoch: 87, loss: 0.701354
global_step: 15467, epoch: 87, loss: 0.767248
global_step: 15468, epoch: 87, loss: 0.681620
global_step: 15469, epoch: 87, loss: 0.779300
global_step: 15470, epoch: 87, loss: 0.699062
global_step: 15471, epoch: 87, loss: 0.784959
global_step: 15472, epoch: 87, loss: 0.588802
global_step: 15473, epoch: 87, loss: 0.806306
global_step: 15474, epoch: 87, loss: 0.727746
global_step: 15475, epoch: 87, loss: 0.703790
global_step: 15476, epoch: 87, loss: 0.710407
global_step: 15477, epoch: 87, loss: 0.639835
global_step: 15478, epoch: 87, loss: 0.717062
global_step: 15479, epoch: 87, loss: 0.694940
global_step: 15480, epoch: 87, loss: 0.660411
epoch: 87
train	acc: 0.8458	macro: p 0.8791, r 0.6077, f1: 0.6214	micro: p 0.8458, r 0.8458, f1 0.8458	weighted_f1:0.8250
dev	acc: 0.5437	macro: p 0.3392, r 0.3005, f1: 0.2966	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4893
test	acc: 0.6011	macro: p 0.3601, r 0.3159, f1: 0.3184	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5538
global_step: 15481, epoch: 88, loss: 0.829276
global_step: 15482, epoch: 88, loss: 0.644645
global_step: 15483, epoch: 88, loss: 0.680996
global_step: 15484, epoch: 88, loss: 0.738976
global_step: 15485, epoch: 88, loss: 0.603182
global_step: 15486, epoch: 88, loss: 0.740851
global_step: 15487, epoch: 88, loss: 0.841134
global_step: 15488, epoch: 88, loss: 0.718636
global_step: 15489, epoch: 88, loss: 0.651069
global_step: 15490, epoch: 88, loss: 0.659617
global_step: 15491, epoch: 88, loss: 0.736969
global_step: 15492, epoch: 88, loss: 0.699660
global_step: 15493, epoch: 88, loss: 0.738608
global_step: 15494, epoch: 88, loss: 0.670372
global_step: 15495, epoch: 88, loss: 0.763182
global_step: 15496, epoch: 88, loss: 0.746900
global_step: 15497, epoch: 88, loss: 0.633692
global_step: 15498, epoch: 88, loss: 0.735533
global_step: 15499, epoch: 88, loss: 0.756984
global_step: 15500, epoch: 88, loss: 0.657285
global_step: 15501, epoch: 88, loss: 0.658074
global_step: 15502, epoch: 88, loss: 0.716381
global_step: 15503, epoch: 88, loss: 0.600315
global_step: 15504, epoch: 88, loss: 0.749706
global_step: 15505, epoch: 88, loss: 0.781512
global_step: 15506, epoch: 88, loss: 0.724587
global_step: 15507, epoch: 88, loss: 0.713685
global_step: 15508, epoch: 88, loss: 0.617350
global_step: 15509, epoch: 88, loss: 0.746545
global_step: 15510, epoch: 88, loss: 0.683453
global_step: 15511, epoch: 88, loss: 0.679794
global_step: 15512, epoch: 88, loss: 0.646248
global_step: 15513, epoch: 88, loss: 0.621187
global_step: 15514, epoch: 88, loss: 0.652333
global_step: 15515, epoch: 88, loss: 0.680726
global_step: 15516, epoch: 88, loss: 0.678582
global_step: 15517, epoch: 88, loss: 0.686009
global_step: 15518, epoch: 88, loss: 0.735399
global_step: 15519, epoch: 88, loss: 0.708677
global_step: 15520, epoch: 88, loss: 1.195842
epoch: 88
train	acc: 0.8575	macro: p 0.8792, r 0.6321, f1: 0.6435	micro: p 0.8575, r 0.8575, f1 0.8575	weighted_f1:0.8389
dev	acc: 0.5410	macro: p 0.3198, r 0.3022, f1: 0.2968	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4902
test	acc: 0.5973	macro: p 0.3491, r 0.3220, f1: 0.3248	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5567
global_step: 15521, epoch: 89, loss: 0.765651
global_step: 15522, epoch: 89, loss: 0.725306
global_step: 15523, epoch: 89, loss: 0.677992
global_step: 15524, epoch: 89, loss: 0.717976
global_step: 15525, epoch: 89, loss: 0.660231
global_step: 15526, epoch: 89, loss: 0.652188
global_step: 15527, epoch: 89, loss: 0.731688
global_step: 15528, epoch: 89, loss: 0.647249
global_step: 15529, epoch: 89, loss: 0.786669
global_step: 15530, epoch: 89, loss: 0.542236
global_step: 15531, epoch: 89, loss: 0.732062
global_step: 15532, epoch: 89, loss: 0.689806
global_step: 15533, epoch: 89, loss: 0.696286
global_step: 15534, epoch: 89, loss: 0.642960
global_step: 15535, epoch: 89, loss: 0.879122
global_step: 15536, epoch: 89, loss: 0.718394
global_step: 15537, epoch: 89, loss: 0.731805
global_step: 15538, epoch: 89, loss: 0.684725
global_step: 15539, epoch: 89, loss: 0.677060
global_step: 15540, epoch: 89, loss: 0.561994
global_step: 15541, epoch: 89, loss: 0.771467
global_step: 15542, epoch: 89, loss: 0.723177
global_step: 15543, epoch: 89, loss: 0.845315
global_step: 15544, epoch: 89, loss: 0.692257
global_step: 15545, epoch: 89, loss: 0.677408
global_step: 15546, epoch: 89, loss: 0.629588
global_step: 15547, epoch: 89, loss: 0.696130
global_step: 15548, epoch: 89, loss: 0.778267
global_step: 15549, epoch: 89, loss: 0.665751
global_step: 15550, epoch: 89, loss: 0.692327
global_step: 15551, epoch: 89, loss: 0.690743
global_step: 15552, epoch: 89, loss: 0.698333
global_step: 15553, epoch: 89, loss: 0.730931
global_step: 15554, epoch: 89, loss: 0.703443
global_step: 15555, epoch: 89, loss: 0.754328
global_step: 15556, epoch: 89, loss: 0.669966
global_step: 15557, epoch: 89, loss: 0.833462
global_step: 15558, epoch: 89, loss: 0.667500
global_step: 15559, epoch: 89, loss: 0.662877
global_step: 15560, epoch: 89, loss: 0.590610
epoch: 89
train	acc: 0.8610	macro: p 0.8844, r 0.6394, f1: 0.6576	micro: p 0.8610, r 0.8610, f1 0.8610	weighted_f1:0.8434
dev	acc: 0.5410	macro: p 0.3224, r 0.3021, f1: 0.2947	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4886
test	acc: 0.5943	macro: p 0.3516, r 0.3208, f1: 0.3215	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5525
global_step: 15561, epoch: 90, loss: 0.641803
global_step: 15562, epoch: 90, loss: 0.658455
global_step: 15563, epoch: 90, loss: 0.680432
global_step: 15564, epoch: 90, loss: 0.677057
global_step: 15565, epoch: 90, loss: 0.806858
global_step: 15566, epoch: 90, loss: 0.683602
global_step: 15567, epoch: 90, loss: 0.686458
global_step: 15568, epoch: 90, loss: 0.600581
global_step: 15569, epoch: 90, loss: 0.649874
global_step: 15570, epoch: 90, loss: 0.621602
global_step: 15571, epoch: 90, loss: 0.695293
global_step: 15572, epoch: 90, loss: 0.690706
global_step: 15573, epoch: 90, loss: 0.763251
global_step: 15574, epoch: 90, loss: 0.749755
global_step: 15575, epoch: 90, loss: 0.634859
global_step: 15576, epoch: 90, loss: 0.767833
global_step: 15577, epoch: 90, loss: 0.812277
global_step: 15578, epoch: 90, loss: 0.700354
global_step: 15579, epoch: 90, loss: 0.775990
global_step: 15580, epoch: 90, loss: 0.618298
global_step: 15581, epoch: 90, loss: 0.794054
global_step: 15582, epoch: 90, loss: 0.725553
global_step: 15583, epoch: 90, loss: 0.681532
global_step: 15584, epoch: 90, loss: 0.761412
global_step: 15585, epoch: 90, loss: 0.675193
global_step: 15586, epoch: 90, loss: 0.648493
global_step: 15587, epoch: 90, loss: 0.687125
global_step: 15588, epoch: 90, loss: 0.642077
global_step: 15589, epoch: 90, loss: 0.662660
global_step: 15590, epoch: 90, loss: 0.854793
global_step: 15591, epoch: 90, loss: 0.677654
global_step: 15592, epoch: 90, loss: 0.783728
global_step: 15593, epoch: 90, loss: 0.650628
global_step: 15594, epoch: 90, loss: 0.602080
global_step: 15595, epoch: 90, loss: 0.705611
global_step: 15596, epoch: 90, loss: 0.721338
global_step: 15597, epoch: 90, loss: 0.741143
global_step: 15598, epoch: 90, loss: 0.685451
global_step: 15599, epoch: 90, loss: 0.668608
global_step: 15600, epoch: 90, loss: 0.570846
epoch: 90
train	acc: 0.8635	macro: p 0.8831, r 0.6430, f1: 0.6554	micro: p 0.8635, r 0.8635, f1 0.8635	weighted_f1:0.8455
dev	acc: 0.5392	macro: p 0.3173, r 0.3003, f1: 0.2941	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4877
test	acc: 0.5989	macro: p 0.3540, r 0.3236, f1: 0.3272	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5577
global_step: 15601, epoch: 91, loss: 0.774579
global_step: 15602, epoch: 91, loss: 0.769496
global_step: 15603, epoch: 91, loss: 0.688565
global_step: 15604, epoch: 91, loss: 0.657702
global_step: 15605, epoch: 91, loss: 0.609474
global_step: 15606, epoch: 91, loss: 0.716986
global_step: 15607, epoch: 91, loss: 0.636177
global_step: 15608, epoch: 91, loss: 0.678837
global_step: 15609, epoch: 91, loss: 0.718588
global_step: 15610, epoch: 91, loss: 0.600611
global_step: 15611, epoch: 91, loss: 0.735603
global_step: 15612, epoch: 91, loss: 0.705829
global_step: 15613, epoch: 91, loss: 0.693544
global_step: 15614, epoch: 91, loss: 0.730583
global_step: 15615, epoch: 91, loss: 0.702620
global_step: 15616, epoch: 91, loss: 0.606730
global_step: 15617, epoch: 91, loss: 0.609963
global_step: 15618, epoch: 91, loss: 0.643006
global_step: 15619, epoch: 91, loss: 0.826041
global_step: 15620, epoch: 91, loss: 0.820249
global_step: 15621, epoch: 91, loss: 0.634280
global_step: 15622, epoch: 91, loss: 0.788489
global_step: 15623, epoch: 91, loss: 0.629864
global_step: 15624, epoch: 91, loss: 0.663256
global_step: 15625, epoch: 91, loss: 0.686305
global_step: 15626, epoch: 91, loss: 0.716967
global_step: 15627, epoch: 91, loss: 0.750094
global_step: 15628, epoch: 91, loss: 0.792508
global_step: 15629, epoch: 91, loss: 0.733492
global_step: 15630, epoch: 91, loss: 0.780811
global_step: 15631, epoch: 91, loss: 0.719100
global_step: 15632, epoch: 91, loss: 0.660009
global_step: 15633, epoch: 91, loss: 0.636881
global_step: 15634, epoch: 91, loss: 0.668535
global_step: 15635, epoch: 91, loss: 0.642438
global_step: 15636, epoch: 91, loss: 0.764871
global_step: 15637, epoch: 91, loss: 0.682033
global_step: 15638, epoch: 91, loss: 0.708685
global_step: 15639, epoch: 91, loss: 0.685950
global_step: 15640, epoch: 91, loss: 0.660195
epoch: 91
train	acc: 0.8643	macro: p 0.8841, r 0.6447, f1: 0.6592	micro: p 0.8643, r 0.8643, f1 0.8643	weighted_f1:0.8468
dev	acc: 0.5464	macro: p 0.3290, r 0.3088, f1: 0.3017	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4962
test	acc: 0.5904	macro: p 0.3437, r 0.3204, f1: 0.3206	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5514
global_step: 15641, epoch: 92, loss: 0.717758
global_step: 15642, epoch: 92, loss: 0.652611
global_step: 15643, epoch: 92, loss: 0.697222
global_step: 15644, epoch: 92, loss: 0.666512
global_step: 15645, epoch: 92, loss: 0.595805
global_step: 15646, epoch: 92, loss: 0.640865
global_step: 15647, epoch: 92, loss: 0.758649
global_step: 15648, epoch: 92, loss: 0.754256
global_step: 15649, epoch: 92, loss: 0.581570
global_step: 15650, epoch: 92, loss: 0.716829
global_step: 15651, epoch: 92, loss: 0.692501
global_step: 15652, epoch: 92, loss: 0.730421
global_step: 15653, epoch: 92, loss: 0.758121
global_step: 15654, epoch: 92, loss: 0.621521
global_step: 15655, epoch: 92, loss: 0.579562
global_step: 15656, epoch: 92, loss: 0.802189
global_step: 15657, epoch: 92, loss: 0.767530
global_step: 15658, epoch: 92, loss: 0.650004
global_step: 15659, epoch: 92, loss: 0.722005
global_step: 15660, epoch: 92, loss: 0.723872
global_step: 15661, epoch: 92, loss: 0.710576
global_step: 15662, epoch: 92, loss: 0.775369
global_step: 15663, epoch: 92, loss: 0.734332
global_step: 15664, epoch: 92, loss: 0.561090
global_step: 15665, epoch: 92, loss: 0.647672
global_step: 15666, epoch: 92, loss: 0.720289
global_step: 15667, epoch: 92, loss: 0.665949
global_step: 15668, epoch: 92, loss: 0.588633
global_step: 15669, epoch: 92, loss: 0.673280
global_step: 15670, epoch: 92, loss: 0.651334
global_step: 15671, epoch: 92, loss: 0.650989
global_step: 15672, epoch: 92, loss: 0.658536
global_step: 15673, epoch: 92, loss: 0.726826
global_step: 15674, epoch: 92, loss: 0.641150
global_step: 15675, epoch: 92, loss: 0.762155
global_step: 15676, epoch: 92, loss: 0.730394
global_step: 15677, epoch: 92, loss: 0.683530
global_step: 15678, epoch: 92, loss: 0.687525
global_step: 15679, epoch: 92, loss: 0.782730
global_step: 15680, epoch: 92, loss: 0.548290
epoch: 92
train	acc: 0.8657	macro: p 0.8838, r 0.6468, f1: 0.6617	micro: p 0.8657, r 0.8657, f1 0.8657	weighted_f1:0.8483
dev	acc: 0.5392	macro: p 0.3202, r 0.3014, f1: 0.2926	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4863
test	acc: 0.5897	macro: p 0.3430, r 0.3188, f1: 0.3167	micro: p 0.5897, r 0.5897, f1 0.5897	weighted_f1:0.5478
global_step: 15681, epoch: 93, loss: 0.636176
global_step: 15682, epoch: 93, loss: 0.735483
global_step: 15683, epoch: 93, loss: 0.704215
global_step: 15684, epoch: 93, loss: 0.728099
global_step: 15685, epoch: 93, loss: 0.733354
global_step: 15686, epoch: 93, loss: 0.611797
global_step: 15687, epoch: 93, loss: 0.720899
global_step: 15688, epoch: 93, loss: 0.687370
global_step: 15689, epoch: 93, loss: 0.601477
global_step: 15690, epoch: 93, loss: 0.654127
global_step: 15691, epoch: 93, loss: 0.694408
global_step: 15692, epoch: 93, loss: 0.562353
global_step: 15693, epoch: 93, loss: 0.606039
global_step: 15694, epoch: 93, loss: 0.566809
global_step: 15695, epoch: 93, loss: 0.689386
global_step: 15696, epoch: 93, loss: 0.789070
global_step: 15697, epoch: 93, loss: 0.662563
global_step: 15698, epoch: 93, loss: 0.631803
global_step: 15699, epoch: 93, loss: 0.698381
global_step: 15700, epoch: 93, loss: 0.620920
global_step: 15701, epoch: 93, loss: 0.641362
global_step: 15702, epoch: 93, loss: 0.638238
global_step: 15703, epoch: 93, loss: 0.614785
global_step: 15704, epoch: 93, loss: 0.635095
global_step: 15705, epoch: 93, loss: 0.648558
global_step: 15706, epoch: 93, loss: 0.802392
global_step: 15707, epoch: 93, loss: 0.606901
global_step: 15708, epoch: 93, loss: 0.812521
global_step: 15709, epoch: 93, loss: 0.662689
global_step: 15710, epoch: 93, loss: 0.652128
global_step: 15711, epoch: 93, loss: 0.691537
global_step: 15712, epoch: 93, loss: 0.709097
global_step: 15713, epoch: 93, loss: 0.673207
global_step: 15714, epoch: 93, loss: 0.841879
global_step: 15715, epoch: 93, loss: 0.612584
global_step: 15716, epoch: 93, loss: 0.717465
global_step: 15717, epoch: 93, loss: 0.796504
global_step: 15718, epoch: 93, loss: 0.784807
global_step: 15719, epoch: 93, loss: 0.650634
global_step: 15720, epoch: 93, loss: 0.776619
epoch: 93
train	acc: 0.8745	macro: p 0.8910, r 0.6686, f1: 0.6908	micro: p 0.8745, r 0.8745, f1 0.8745	weighted_f1:0.8598
dev	acc: 0.5347	macro: p 0.3128, r 0.2980, f1: 0.2922	micro: p 0.5347, r 0.5347, f1 0.5347	weighted_f1:0.4850
test	acc: 0.5916	macro: p 0.3422, r 0.3212, f1: 0.3225	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5528
global_step: 15721, epoch: 94, loss: 0.678456
global_step: 15722, epoch: 94, loss: 0.663563
global_step: 15723, epoch: 94, loss: 0.675207
global_step: 15724, epoch: 94, loss: 0.694610
global_step: 15725, epoch: 94, loss: 0.722011
global_step: 15726, epoch: 94, loss: 0.636688
global_step: 15727, epoch: 94, loss: 0.652089
global_step: 15728, epoch: 94, loss: 0.616439
global_step: 15729, epoch: 94, loss: 0.777680
global_step: 15730, epoch: 94, loss: 0.675692
global_step: 15731, epoch: 94, loss: 0.666871
global_step: 15732, epoch: 94, loss: 0.656005
global_step: 15733, epoch: 94, loss: 0.664751
global_step: 15734, epoch: 94, loss: 0.709360
global_step: 15735, epoch: 94, loss: 0.680726
global_step: 15736, epoch: 94, loss: 0.688221
global_step: 15737, epoch: 94, loss: 0.643739
global_step: 15738, epoch: 94, loss: 0.730748
global_step: 15739, epoch: 94, loss: 0.559306
global_step: 15740, epoch: 94, loss: 0.659611
global_step: 15741, epoch: 94, loss: 0.653663
global_step: 15742, epoch: 94, loss: 0.691570
global_step: 15743, epoch: 94, loss: 0.721476
global_step: 15744, epoch: 94, loss: 0.727744
global_step: 15745, epoch: 94, loss: 0.720348
global_step: 15746, epoch: 94, loss: 0.774620
global_step: 15747, epoch: 94, loss: 0.716148
global_step: 15748, epoch: 94, loss: 0.669164
global_step: 15749, epoch: 94, loss: 0.602949
global_step: 15750, epoch: 94, loss: 0.632646
global_step: 15751, epoch: 94, loss: 0.597774
global_step: 15752, epoch: 94, loss: 0.669655
global_step: 15753, epoch: 94, loss: 0.690928
global_step: 15754, epoch: 94, loss: 0.645950
global_step: 15755, epoch: 94, loss: 0.691831
global_step: 15756, epoch: 94, loss: 0.674703
global_step: 15757, epoch: 94, loss: 0.667749
global_step: 15758, epoch: 94, loss: 0.582313
global_step: 15759, epoch: 94, loss: 0.703866
global_step: 15760, epoch: 94, loss: 0.202661
epoch: 94
train	acc: 0.8670	macro: p 0.8898, r 0.6472, f1: 0.6661	micro: p 0.8670, r 0.8670, f1 0.8670	weighted_f1:0.8497
dev	acc: 0.5410	macro: p 0.3287, r 0.3020, f1: 0.2960	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4883
test	acc: 0.5950	macro: p 0.3523, r 0.3170, f1: 0.3178	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5509
global_step: 15761, epoch: 95, loss: 0.731513
global_step: 15762, epoch: 95, loss: 0.734634
global_step: 15763, epoch: 95, loss: 0.691203
global_step: 15764, epoch: 95, loss: 0.724048
global_step: 15765, epoch: 95, loss: 0.604304
global_step: 15766, epoch: 95, loss: 0.669333
global_step: 15767, epoch: 95, loss: 0.653888
global_step: 15768, epoch: 95, loss: 0.742645
global_step: 15769, epoch: 95, loss: 0.713544
global_step: 15770, epoch: 95, loss: 0.727359
global_step: 15771, epoch: 95, loss: 0.612802
global_step: 15772, epoch: 95, loss: 0.600285
global_step: 15773, epoch: 95, loss: 0.772378
global_step: 15774, epoch: 95, loss: 0.647720
global_step: 15775, epoch: 95, loss: 0.584409
global_step: 15776, epoch: 95, loss: 0.612981
global_step: 15777, epoch: 95, loss: 0.658740
global_step: 15778, epoch: 95, loss: 0.668479
global_step: 15779, epoch: 95, loss: 0.766660
global_step: 15780, epoch: 95, loss: 0.682842
global_step: 15781, epoch: 95, loss: 0.741697
global_step: 15782, epoch: 95, loss: 0.749017
global_step: 15783, epoch: 95, loss: 0.725784
global_step: 15784, epoch: 95, loss: 0.693990
global_step: 15785, epoch: 95, loss: 0.606246
global_step: 15786, epoch: 95, loss: 0.609801
global_step: 15787, epoch: 95, loss: 0.647303
global_step: 15788, epoch: 95, loss: 0.695501
global_step: 15789, epoch: 95, loss: 0.591710
global_step: 15790, epoch: 95, loss: 0.698142
global_step: 15791, epoch: 95, loss: 0.680877
global_step: 15792, epoch: 95, loss: 0.779842
global_step: 15793, epoch: 95, loss: 0.613349
global_step: 15794, epoch: 95, loss: 0.666433
global_step: 15795, epoch: 95, loss: 0.696377
global_step: 15796, epoch: 95, loss: 0.575145
global_step: 15797, epoch: 95, loss: 0.641936
global_step: 15798, epoch: 95, loss: 0.585733
global_step: 15799, epoch: 95, loss: 0.752018
global_step: 15800, epoch: 95, loss: 0.290392
epoch: 95
train	acc: 0.8670	macro: p 0.8933, r 0.6497, f1: 0.6734	micro: p 0.8670, r 0.8670, f1 0.8670	weighted_f1:0.8503
dev	acc: 0.5392	macro: p 0.3229, r 0.2989, f1: 0.2907	micro: p 0.5392, r 0.5392, f1 0.5392	weighted_f1:0.4845
test	acc: 0.5954	macro: p 0.3550, r 0.3147, f1: 0.3159	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5494
global_step: 15801, epoch: 96, loss: 0.704109
global_step: 15802, epoch: 96, loss: 0.693105
global_step: 15803, epoch: 96, loss: 0.562757
global_step: 15804, epoch: 96, loss: 0.647784
global_step: 15805, epoch: 96, loss: 0.759884
global_step: 15806, epoch: 96, loss: 0.673622
global_step: 15807, epoch: 96, loss: 0.602565
global_step: 15808, epoch: 96, loss: 0.603418
global_step: 15809, epoch: 96, loss: 0.664504
global_step: 15810, epoch: 96, loss: 0.609062
global_step: 15811, epoch: 96, loss: 0.685717
global_step: 15812, epoch: 96, loss: 0.700587
global_step: 15813, epoch: 96, loss: 0.612963
global_step: 15814, epoch: 96, loss: 0.676547
global_step: 15815, epoch: 96, loss: 0.595607
global_step: 15816, epoch: 96, loss: 0.596201
global_step: 15817, epoch: 96, loss: 0.564530
global_step: 15818, epoch: 96, loss: 0.704527
global_step: 15819, epoch: 96, loss: 0.729844
global_step: 15820, epoch: 96, loss: 0.663942
global_step: 15821, epoch: 96, loss: 0.714641
global_step: 15822, epoch: 96, loss: 0.543906
global_step: 15823, epoch: 96, loss: 0.748577
global_step: 15824, epoch: 96, loss: 0.706279
global_step: 15825, epoch: 96, loss: 0.610106
global_step: 15826, epoch: 96, loss: 0.662330
global_step: 15827, epoch: 96, loss: 0.664256
global_step: 15828, epoch: 96, loss: 0.671548
global_step: 15829, epoch: 96, loss: 0.670707
global_step: 15830, epoch: 96, loss: 0.684944
global_step: 15831, epoch: 96, loss: 0.644948
global_step: 15832, epoch: 96, loss: 0.677161
global_step: 15833, epoch: 96, loss: 0.641294
global_step: 15834, epoch: 96, loss: 0.649858
global_step: 15835, epoch: 96, loss: 0.700585
global_step: 15836, epoch: 96, loss: 0.706550
global_step: 15837, epoch: 96, loss: 0.603037
global_step: 15838, epoch: 96, loss: 0.601666
global_step: 15839, epoch: 96, loss: 0.700655
global_step: 15840, epoch: 96, loss: 0.620307
epoch: 96
train	acc: 0.8744	macro: p 0.8943, r 0.6649, f1: 0.6864	micro: p 0.8744, r 0.8744, f1 0.8744	weighted_f1:0.8595
dev	acc: 0.5374	macro: p 0.3223, r 0.3022, f1: 0.2944	micro: p 0.5374, r 0.5374, f1 0.5374	weighted_f1:0.4888
test	acc: 0.5927	macro: p 0.3544, r 0.3199, f1: 0.3205	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5529
global_step: 15841, epoch: 97, loss: 0.575580
global_step: 15842, epoch: 97, loss: 0.607295
global_step: 15843, epoch: 97, loss: 0.677010
global_step: 15844, epoch: 97, loss: 0.564676
global_step: 15845, epoch: 97, loss: 0.618488
global_step: 15846, epoch: 97, loss: 0.766666
global_step: 15847, epoch: 97, loss: 0.650017
global_step: 15848, epoch: 97, loss: 0.688899
global_step: 15849, epoch: 97, loss: 0.629059
global_step: 15850, epoch: 97, loss: 0.561234
global_step: 15851, epoch: 97, loss: 0.654625
global_step: 15852, epoch: 97, loss: 0.634113
global_step: 15853, epoch: 97, loss: 0.647144
global_step: 15854, epoch: 97, loss: 0.661049
global_step: 15855, epoch: 97, loss: 0.646618
global_step: 15856, epoch: 97, loss: 0.700198
global_step: 15857, epoch: 97, loss: 0.597711
global_step: 15858, epoch: 97, loss: 0.700780
global_step: 15859, epoch: 97, loss: 0.673018
global_step: 15860, epoch: 97, loss: 0.614603
global_step: 15861, epoch: 97, loss: 0.727770
global_step: 15862, epoch: 97, loss: 0.689815
global_step: 15863, epoch: 97, loss: 0.710578
global_step: 15864, epoch: 97, loss: 0.566601
global_step: 15865, epoch: 97, loss: 0.662284
global_step: 15866, epoch: 97, loss: 0.680006
global_step: 15867, epoch: 97, loss: 0.693933
global_step: 15868, epoch: 97, loss: 0.578844
global_step: 15869, epoch: 97, loss: 0.753381
global_step: 15870, epoch: 97, loss: 0.655904
global_step: 15871, epoch: 97, loss: 0.549972
global_step: 15872, epoch: 97, loss: 0.638035
global_step: 15873, epoch: 97, loss: 0.620781
global_step: 15874, epoch: 97, loss: 0.620627
global_step: 15875, epoch: 97, loss: 0.684391
global_step: 15876, epoch: 97, loss: 0.681492
global_step: 15877, epoch: 97, loss: 0.739689
global_step: 15878, epoch: 97, loss: 0.591763
global_step: 15879, epoch: 97, loss: 0.690437
global_step: 15880, epoch: 97, loss: 0.657694
epoch: 97
train	acc: 0.8803	macro: p 0.8966, r 0.6763, f1: 0.6989	micro: p 0.8803, r 0.8803, f1 0.8803	weighted_f1:0.8658
dev	acc: 0.5356	macro: p 0.3182, r 0.2993, f1: 0.2922	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4852
test	acc: 0.5900	macro: p 0.3410, r 0.3168, f1: 0.3166	micro: p 0.5900, r 0.5900, f1 0.5900	weighted_f1:0.5488
global_step: 15881, epoch: 98, loss: 0.615242
global_step: 15882, epoch: 98, loss: 0.544239
global_step: 15883, epoch: 98, loss: 0.731062
global_step: 15884, epoch: 98, loss: 0.700587
global_step: 15885, epoch: 98, loss: 0.633000
global_step: 15886, epoch: 98, loss: 0.718522
global_step: 15887, epoch: 98, loss: 0.634860
global_step: 15888, epoch: 98, loss: 0.567189
global_step: 15889, epoch: 98, loss: 0.604952
global_step: 15890, epoch: 98, loss: 0.620515
global_step: 15891, epoch: 98, loss: 0.601726
global_step: 15892, epoch: 98, loss: 0.652694
global_step: 15893, epoch: 98, loss: 0.593105
global_step: 15894, epoch: 98, loss: 0.655337
global_step: 15895, epoch: 98, loss: 0.685304
global_step: 15896, epoch: 98, loss: 0.620717
global_step: 15897, epoch: 98, loss: 0.641458
global_step: 15898, epoch: 98, loss: 0.715178
global_step: 15899, epoch: 98, loss: 0.671803
global_step: 15900, epoch: 98, loss: 0.616243
global_step: 15901, epoch: 98, loss: 0.692577
global_step: 15902, epoch: 98, loss: 0.663333
global_step: 15903, epoch: 98, loss: 0.576367
global_step: 15904, epoch: 98, loss: 0.620172
global_step: 15905, epoch: 98, loss: 0.672059
global_step: 15906, epoch: 98, loss: 0.636034
global_step: 15907, epoch: 98, loss: 0.643891
global_step: 15908, epoch: 98, loss: 0.589130
global_step: 15909, epoch: 98, loss: 0.651605
global_step: 15910, epoch: 98, loss: 0.704072
global_step: 15911, epoch: 98, loss: 0.623386
global_step: 15912, epoch: 98, loss: 0.627893
global_step: 15913, epoch: 98, loss: 0.704170
global_step: 15914, epoch: 98, loss: 0.690158
global_step: 15915, epoch: 98, loss: 0.659659
global_step: 15916, epoch: 98, loss: 0.651084
global_step: 15917, epoch: 98, loss: 0.648696
global_step: 15918, epoch: 98, loss: 0.748729
global_step: 15919, epoch: 98, loss: 0.552976
global_step: 15920, epoch: 98, loss: 0.338108
epoch: 98
train	acc: 0.8769	macro: p 0.8971, r 0.6719, f1: 0.6982	micro: p 0.8769, r 0.8769, f1 0.8769	weighted_f1:0.8623
dev	acc: 0.5365	macro: p 0.3212, r 0.2969, f1: 0.2890	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4824
test	acc: 0.5943	macro: p 0.3468, r 0.3148, f1: 0.3141	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5479
global_step: 15921, epoch: 99, loss: 0.592596
global_step: 15922, epoch: 99, loss: 0.658890
global_step: 15923, epoch: 99, loss: 0.593267
global_step: 15924, epoch: 99, loss: 0.654067
global_step: 15925, epoch: 99, loss: 0.638163
global_step: 15926, epoch: 99, loss: 0.587136
global_step: 15927, epoch: 99, loss: 0.716555
global_step: 15928, epoch: 99, loss: 0.728226
global_step: 15929, epoch: 99, loss: 0.629243
global_step: 15930, epoch: 99, loss: 0.617629
global_step: 15931, epoch: 99, loss: 0.649775
global_step: 15932, epoch: 99, loss: 0.503259
global_step: 15933, epoch: 99, loss: 0.713041
global_step: 15934, epoch: 99, loss: 0.619389
global_step: 15935, epoch: 99, loss: 0.532526
global_step: 15936, epoch: 99, loss: 0.682217
global_step: 15937, epoch: 99, loss: 0.538391
global_step: 15938, epoch: 99, loss: 0.581875
global_step: 15939, epoch: 99, loss: 0.708839
global_step: 15940, epoch: 99, loss: 0.696158
global_step: 15941, epoch: 99, loss: 0.611189
global_step: 15942, epoch: 99, loss: 0.637583
global_step: 15943, epoch: 99, loss: 0.723849
global_step: 15944, epoch: 99, loss: 0.709108
global_step: 15945, epoch: 99, loss: 0.665361
global_step: 15946, epoch: 99, loss: 0.678514
global_step: 15947, epoch: 99, loss: 0.723854
global_step: 15948, epoch: 99, loss: 0.596472
global_step: 15949, epoch: 99, loss: 0.627723
global_step: 15950, epoch: 99, loss: 0.590565
global_step: 15951, epoch: 99, loss: 0.671592
global_step: 15952, epoch: 99, loss: 0.650213
global_step: 15953, epoch: 99, loss: 0.671064
global_step: 15954, epoch: 99, loss: 0.657008
global_step: 15955, epoch: 99, loss: 0.594804
global_step: 15956, epoch: 99, loss: 0.642586
global_step: 15957, epoch: 99, loss: 0.619790
global_step: 15958, epoch: 99, loss: 0.598377
global_step: 15959, epoch: 99, loss: 0.696043
global_step: 15960, epoch: 99, loss: 0.575060
epoch: 99
train	acc: 0.8782	macro: p 0.8942, r 0.6703, f1: 0.6942	micro: p 0.8782, r 0.8782, f1 0.8782	weighted_f1:0.8634
dev	acc: 0.5383	macro: p 0.3298, r 0.2994, f1: 0.2940	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4868
test	acc: 0.5985	macro: p 0.3617, r 0.3193, f1: 0.3216	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5546
global_step: 15961, epoch: 100, loss: 0.623092
global_step: 15962, epoch: 100, loss: 0.549287
global_step: 15963, epoch: 100, loss: 0.592555
global_step: 15964, epoch: 100, loss: 0.641209
global_step: 15965, epoch: 100, loss: 0.722735
global_step: 15966, epoch: 100, loss: 0.594289
global_step: 15967, epoch: 100, loss: 0.591707
global_step: 15968, epoch: 100, loss: 0.652489
global_step: 15969, epoch: 100, loss: 0.618417
global_step: 15970, epoch: 100, loss: 0.626611
global_step: 15971, epoch: 100, loss: 0.623693
global_step: 15972, epoch: 100, loss: 0.628317
global_step: 15973, epoch: 100, loss: 0.591439
global_step: 15974, epoch: 100, loss: 0.648120
global_step: 15975, epoch: 100, loss: 0.678402
global_step: 15976, epoch: 100, loss: 0.681943
global_step: 15977, epoch: 100, loss: 0.630866
global_step: 15978, epoch: 100, loss: 0.622059
global_step: 15979, epoch: 100, loss: 0.661391
global_step: 15980, epoch: 100, loss: 0.624183
global_step: 15981, epoch: 100, loss: 0.589164
global_step: 15982, epoch: 100, loss: 0.654776
global_step: 15983, epoch: 100, loss: 0.662441
global_step: 15984, epoch: 100, loss: 0.720870
global_step: 15985, epoch: 100, loss: 0.638434
global_step: 15986, epoch: 100, loss: 0.556354
global_step: 15987, epoch: 100, loss: 0.621878
global_step: 15988, epoch: 100, loss: 0.722743
global_step: 15989, epoch: 100, loss: 0.775524
global_step: 15990, epoch: 100, loss: 0.675245
global_step: 15991, epoch: 100, loss: 0.606440
global_step: 15992, epoch: 100, loss: 0.611358
global_step: 15993, epoch: 100, loss: 0.632574
global_step: 15994, epoch: 100, loss: 0.662653
global_step: 15995, epoch: 100, loss: 0.698696
global_step: 15996, epoch: 100, loss: 0.593927
global_step: 15997, epoch: 100, loss: 0.629044
global_step: 15998, epoch: 100, loss: 0.493576
global_step: 15999, epoch: 100, loss: 0.622158
global_step: 16000, epoch: 100, loss: 0.494531
epoch: 100
train	acc: 0.8839	macro: p 0.8977, r 0.6877, f1: 0.7109	micro: p 0.8839, r 0.8839, f1 0.8839	weighted_f1:0.8706
dev	acc: 0.5365	macro: p 0.3132, r 0.3006, f1: 0.2941	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4873
test	acc: 0.5908	macro: p 0.3407, r 0.3195, f1: 0.3197	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5508
BEST MODEL epoch: 43
train	acc: 0.6854 macro_p: 0.4679 macro_r: 0.4086 macro_f1: 0.4212 micro_p: 0.6854 micro_r: 0.6854 micro_f1: 0.6854 weighted_f1: 0.6505
dev	acc: 0.5537 macro_p: 0.3426 macro_r: 0.3089 macro_f1: 0.3052 micro_p: 0.5537 micro_r: 0.5537 micro_f1: 0.5537 weighted_f1: 0.5013
test	acc: 0.6015 macro_p: 0.3715 macro_r: 0.3175 macro_f1: 0.3223 micro_p: 0.6015 micro_r: 0.6015 micro_f1: 0.6015 weighted_f1: 0.5566
==========ROUND 5==========
global_step: 16001, epoch: 1, loss: 1.897864
global_step: 16002, epoch: 1, loss: 1.873420
global_step: 16003, epoch: 1, loss: 1.816208
global_step: 16004, epoch: 1, loss: 1.833509
global_step: 16005, epoch: 1, loss: 1.764176
global_step: 16006, epoch: 1, loss: 1.736895
global_step: 16007, epoch: 1, loss: 1.744532
global_step: 16008, epoch: 1, loss: 1.684171
global_step: 16009, epoch: 1, loss: 1.757965
global_step: 16010, epoch: 1, loss: 1.758696
global_step: 16011, epoch: 1, loss: 1.690793
global_step: 16012, epoch: 1, loss: 1.734580
global_step: 16013, epoch: 1, loss: 1.699578
global_step: 16014, epoch: 1, loss: 1.705876
global_step: 16015, epoch: 1, loss: 1.651942
global_step: 16016, epoch: 1, loss: 1.660034
global_step: 16017, epoch: 1, loss: 1.618841
global_step: 16018, epoch: 1, loss: 1.611489
global_step: 16019, epoch: 1, loss: 1.597573
global_step: 16020, epoch: 1, loss: 1.618328
global_step: 16021, epoch: 1, loss: 1.611388
global_step: 16022, epoch: 1, loss: 1.608742
global_step: 16023, epoch: 1, loss: 1.517672
global_step: 16024, epoch: 1, loss: 1.478115
global_step: 16025, epoch: 1, loss: 1.564421
global_step: 16026, epoch: 1, loss: 1.551360
global_step: 16027, epoch: 1, loss: 1.581297
global_step: 16028, epoch: 1, loss: 1.505764
global_step: 16029, epoch: 1, loss: 1.624468
global_step: 16030, epoch: 1, loss: 1.579884
global_step: 16031, epoch: 1, loss: 1.598241
global_step: 16032, epoch: 1, loss: 1.507987
global_step: 16033, epoch: 1, loss: 1.541854
global_step: 16034, epoch: 1, loss: 1.586901
global_step: 16035, epoch: 1, loss: 1.513345
global_step: 16036, epoch: 1, loss: 1.602865
global_step: 16037, epoch: 1, loss: 1.534985
global_step: 16038, epoch: 1, loss: 1.530001
global_step: 16039, epoch: 1, loss: 1.510276
global_step: 16040, epoch: 1, loss: 1.405300
epoch: 1
train	acc: 0.4956	macro: p 0.2334, r 0.1668, f1: 0.1337	micro: p 0.4956, r 0.4956, f1 0.4956	weighted_f1:0.3582
dev	acc: 0.4500	macro: p 0.3996, r 0.1704, f1: 0.1304	micro: p 0.4500, r 0.4500, f1 0.4500	weighted_f1:0.3064
test	acc: 0.5092	macro: p 0.2469, r 0.1751, f1: 0.1463	micro: p 0.5092, r 0.5092, f1 0.5092	weighted_f1:0.3753
New best model!
global_step: 16041, epoch: 2, loss: 1.467242
global_step: 16042, epoch: 2, loss: 1.491649
global_step: 16043, epoch: 2, loss: 1.491192
global_step: 16044, epoch: 2, loss: 1.527782
global_step: 16045, epoch: 2, loss: 1.429786
global_step: 16046, epoch: 2, loss: 1.446541
global_step: 16047, epoch: 2, loss: 1.526482
global_step: 16048, epoch: 2, loss: 1.503333
global_step: 16049, epoch: 2, loss: 1.569664
global_step: 16050, epoch: 2, loss: 1.430416
global_step: 16051, epoch: 2, loss: 1.481347
global_step: 16052, epoch: 2, loss: 1.425355
global_step: 16053, epoch: 2, loss: 1.492677
global_step: 16054, epoch: 2, loss: 1.493647
global_step: 16055, epoch: 2, loss: 1.453230
global_step: 16056, epoch: 2, loss: 1.473966
global_step: 16057, epoch: 2, loss: 1.463825
global_step: 16058, epoch: 2, loss: 1.506696
global_step: 16059, epoch: 2, loss: 1.437649
global_step: 16060, epoch: 2, loss: 1.527302
global_step: 16061, epoch: 2, loss: 1.518098
global_step: 16062, epoch: 2, loss: 1.448877
global_step: 16063, epoch: 2, loss: 1.554164
global_step: 16064, epoch: 2, loss: 1.505101
global_step: 16065, epoch: 2, loss: 1.489077
global_step: 16066, epoch: 2, loss: 1.505421
global_step: 16067, epoch: 2, loss: 1.491838
global_step: 16068, epoch: 2, loss: 1.421668
global_step: 16069, epoch: 2, loss: 1.424176
global_step: 16070, epoch: 2, loss: 1.428455
global_step: 16071, epoch: 2, loss: 1.474688
global_step: 16072, epoch: 2, loss: 1.507354
global_step: 16073, epoch: 2, loss: 1.422594
global_step: 16074, epoch: 2, loss: 1.461838
global_step: 16075, epoch: 2, loss: 1.446518
global_step: 16076, epoch: 2, loss: 1.426937
global_step: 16077, epoch: 2, loss: 1.482725
global_step: 16078, epoch: 2, loss: 1.538922
global_step: 16079, epoch: 2, loss: 1.417944
global_step: 16080, epoch: 2, loss: 1.344303
epoch: 2
train	acc: 0.5403	macro: p 0.2334, r 0.2121, f1: 0.1844	micro: p 0.5403, r 0.5403, f1 0.5403	weighted_f1:0.4303
dev	acc: 0.4842	macro: p 0.2380, r 0.2120, f1: 0.1742	micro: p 0.4842, r 0.4842, f1 0.4842	weighted_f1:0.3659
test	acc: 0.5437	macro: p 0.2278, r 0.2157, f1: 0.1865	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4320
New best model!
global_step: 16081, epoch: 3, loss: 1.452965
global_step: 16082, epoch: 3, loss: 1.521752
global_step: 16083, epoch: 3, loss: 1.426378
global_step: 16084, epoch: 3, loss: 1.449936
global_step: 16085, epoch: 3, loss: 1.360236
global_step: 16086, epoch: 3, loss: 1.424956
global_step: 16087, epoch: 3, loss: 1.423052
global_step: 16088, epoch: 3, loss: 1.450579
global_step: 16089, epoch: 3, loss: 1.464995
global_step: 16090, epoch: 3, loss: 1.462914
global_step: 16091, epoch: 3, loss: 1.389879
global_step: 16092, epoch: 3, loss: 1.427456
global_step: 16093, epoch: 3, loss: 1.431251
global_step: 16094, epoch: 3, loss: 1.335784
global_step: 16095, epoch: 3, loss: 1.449381
global_step: 16096, epoch: 3, loss: 1.461494
global_step: 16097, epoch: 3, loss: 1.369958
global_step: 16098, epoch: 3, loss: 1.413343
global_step: 16099, epoch: 3, loss: 1.422234
global_step: 16100, epoch: 3, loss: 1.541873
global_step: 16101, epoch: 3, loss: 1.465478
global_step: 16102, epoch: 3, loss: 1.464454
global_step: 16103, epoch: 3, loss: 1.435714
global_step: 16104, epoch: 3, loss: 1.260417
global_step: 16105, epoch: 3, loss: 1.414605
global_step: 16106, epoch: 3, loss: 1.466999
global_step: 16107, epoch: 3, loss: 1.511901
global_step: 16108, epoch: 3, loss: 1.315961
global_step: 16109, epoch: 3, loss: 1.479521
global_step: 16110, epoch: 3, loss: 1.539851
global_step: 16111, epoch: 3, loss: 1.403343
global_step: 16112, epoch: 3, loss: 1.421654
global_step: 16113, epoch: 3, loss: 1.347749
global_step: 16114, epoch: 3, loss: 1.436579
global_step: 16115, epoch: 3, loss: 1.348958
global_step: 16116, epoch: 3, loss: 1.513352
global_step: 16117, epoch: 3, loss: 1.378035
global_step: 16118, epoch: 3, loss: 1.406514
global_step: 16119, epoch: 3, loss: 1.473668
global_step: 16120, epoch: 3, loss: 1.527137
epoch: 3
train	acc: 0.5495	macro: p 0.3633, r 0.2241, f1: 0.1967	micro: p 0.5495, r 0.5495, f1 0.5495	weighted_f1:0.4473
dev	acc: 0.5032	macro: p 0.2302, r 0.2326, f1: 0.1926	micro: p 0.5032, r 0.5032, f1 0.5032	weighted_f1:0.3904
test	acc: 0.5533	macro: p 0.2148, r 0.2302, f1: 0.1989	micro: p 0.5533, r 0.5533, f1 0.5533	weighted_f1:0.4489
New best model!
global_step: 16121, epoch: 4, loss: 1.383573
global_step: 16122, epoch: 4, loss: 1.424445
global_step: 16123, epoch: 4, loss: 1.426423
global_step: 16124, epoch: 4, loss: 1.540216
global_step: 16125, epoch: 4, loss: 1.447223
global_step: 16126, epoch: 4, loss: 1.341566
global_step: 16127, epoch: 4, loss: 1.475147
global_step: 16128, epoch: 4, loss: 1.386782
global_step: 16129, epoch: 4, loss: 1.510683
global_step: 16130, epoch: 4, loss: 1.379590
global_step: 16131, epoch: 4, loss: 1.405133
global_step: 16132, epoch: 4, loss: 1.355105
global_step: 16133, epoch: 4, loss: 1.414668
global_step: 16134, epoch: 4, loss: 1.359740
global_step: 16135, epoch: 4, loss: 1.378041
global_step: 16136, epoch: 4, loss: 1.398342
global_step: 16137, epoch: 4, loss: 1.470530
global_step: 16138, epoch: 4, loss: 1.431563
global_step: 16139, epoch: 4, loss: 1.365325
global_step: 16140, epoch: 4, loss: 1.419080
global_step: 16141, epoch: 4, loss: 1.385008
global_step: 16142, epoch: 4, loss: 1.317880
global_step: 16143, epoch: 4, loss: 1.408645
global_step: 16144, epoch: 4, loss: 1.374845
global_step: 16145, epoch: 4, loss: 1.355323
global_step: 16146, epoch: 4, loss: 1.444124
global_step: 16147, epoch: 4, loss: 1.444714
global_step: 16148, epoch: 4, loss: 1.401826
global_step: 16149, epoch: 4, loss: 1.329000
global_step: 16150, epoch: 4, loss: 1.314865
global_step: 16151, epoch: 4, loss: 1.375301
global_step: 16152, epoch: 4, loss: 1.422607
global_step: 16153, epoch: 4, loss: 1.398565
global_step: 16154, epoch: 4, loss: 1.407430
global_step: 16155, epoch: 4, loss: 1.327375
global_step: 16156, epoch: 4, loss: 1.402398
global_step: 16157, epoch: 4, loss: 1.335787
global_step: 16158, epoch: 4, loss: 1.468903
global_step: 16159, epoch: 4, loss: 1.353428
global_step: 16160, epoch: 4, loss: 1.590192
epoch: 4
train	acc: 0.5595	macro: p 0.3008, r 0.2389, f1: 0.2197	micro: p 0.5595, r 0.5595, f1 0.5595	weighted_f1:0.4698
dev	acc: 0.5104	macro: p 0.2835, r 0.2426, f1: 0.2040	micro: p 0.5104, r 0.5104, f1 0.5104	weighted_f1:0.4040
test	acc: 0.5567	macro: p 0.2731, r 0.2374, f1: 0.2113	micro: p 0.5567, r 0.5567, f1 0.5567	weighted_f1:0.4635
New best model!
global_step: 16161, epoch: 5, loss: 1.461868
global_step: 16162, epoch: 5, loss: 1.388063
global_step: 16163, epoch: 5, loss: 1.404716
global_step: 16164, epoch: 5, loss: 1.366419
global_step: 16165, epoch: 5, loss: 1.445340
global_step: 16166, epoch: 5, loss: 1.384640
global_step: 16167, epoch: 5, loss: 1.377600
global_step: 16168, epoch: 5, loss: 1.277259
global_step: 16169, epoch: 5, loss: 1.373060
global_step: 16170, epoch: 5, loss: 1.483706
global_step: 16171, epoch: 5, loss: 1.379790
global_step: 16172, epoch: 5, loss: 1.356784
global_step: 16173, epoch: 5, loss: 1.471121
global_step: 16174, epoch: 5, loss: 1.286720
global_step: 16175, epoch: 5, loss: 1.355061
global_step: 16176, epoch: 5, loss: 1.485657
global_step: 16177, epoch: 5, loss: 1.360491
global_step: 16178, epoch: 5, loss: 1.306186
global_step: 16179, epoch: 5, loss: 1.417244
global_step: 16180, epoch: 5, loss: 1.514908
global_step: 16181, epoch: 5, loss: 1.326535
global_step: 16182, epoch: 5, loss: 1.418338
global_step: 16183, epoch: 5, loss: 1.320795
global_step: 16184, epoch: 5, loss: 1.457393
global_step: 16185, epoch: 5, loss: 1.435790
global_step: 16186, epoch: 5, loss: 1.362425
global_step: 16187, epoch: 5, loss: 1.385370
global_step: 16188, epoch: 5, loss: 1.362136
global_step: 16189, epoch: 5, loss: 1.346809
global_step: 16190, epoch: 5, loss: 1.354164
global_step: 16191, epoch: 5, loss: 1.373250
global_step: 16192, epoch: 5, loss: 1.314338
global_step: 16193, epoch: 5, loss: 1.455934
global_step: 16194, epoch: 5, loss: 1.416145
global_step: 16195, epoch: 5, loss: 1.358615
global_step: 16196, epoch: 5, loss: 1.478317
global_step: 16197, epoch: 5, loss: 1.389882
global_step: 16198, epoch: 5, loss: 1.362639
global_step: 16199, epoch: 5, loss: 1.355199
global_step: 16200, epoch: 5, loss: 1.479675
epoch: 5
train	acc: 0.5632	macro: p 0.3126, r 0.2434, f1: 0.2272	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.4760
dev	acc: 0.5122	macro: p 0.2848, r 0.2440, f1: 0.2089	micro: p 0.5122, r 0.5122, f1 0.5122	weighted_f1:0.4088
test	acc: 0.5590	macro: p 0.2800, r 0.2398, f1: 0.2160	micro: p 0.5590, r 0.5590, f1 0.5590	weighted_f1:0.4681
New best model!
global_step: 16201, epoch: 6, loss: 1.222039
global_step: 16202, epoch: 6, loss: 1.318594
global_step: 16203, epoch: 6, loss: 1.280260
global_step: 16204, epoch: 6, loss: 1.410352
global_step: 16205, epoch: 6, loss: 1.503786
global_step: 16206, epoch: 6, loss: 1.409343
global_step: 16207, epoch: 6, loss: 1.411325
global_step: 16208, epoch: 6, loss: 1.358513
global_step: 16209, epoch: 6, loss: 1.347010
global_step: 16210, epoch: 6, loss: 1.437809
global_step: 16211, epoch: 6, loss: 1.465068
global_step: 16212, epoch: 6, loss: 1.357120
global_step: 16213, epoch: 6, loss: 1.239673
global_step: 16214, epoch: 6, loss: 1.496094
global_step: 16215, epoch: 6, loss: 1.291659
global_step: 16216, epoch: 6, loss: 1.426207
global_step: 16217, epoch: 6, loss: 1.359635
global_step: 16218, epoch: 6, loss: 1.318686
global_step: 16219, epoch: 6, loss: 1.390206
global_step: 16220, epoch: 6, loss: 1.436067
global_step: 16221, epoch: 6, loss: 1.399761
global_step: 16222, epoch: 6, loss: 1.303069
global_step: 16223, epoch: 6, loss: 1.388977
global_step: 16224, epoch: 6, loss: 1.381073
global_step: 16225, epoch: 6, loss: 1.481689
global_step: 16226, epoch: 6, loss: 1.384828
global_step: 16227, epoch: 6, loss: 1.327307
global_step: 16228, epoch: 6, loss: 1.391042
global_step: 16229, epoch: 6, loss: 1.384446
global_step: 16230, epoch: 6, loss: 1.456096
global_step: 16231, epoch: 6, loss: 1.429045
global_step: 16232, epoch: 6, loss: 1.317752
global_step: 16233, epoch: 6, loss: 1.465142
global_step: 16234, epoch: 6, loss: 1.332077
global_step: 16235, epoch: 6, loss: 1.338031
global_step: 16236, epoch: 6, loss: 1.296578
global_step: 16237, epoch: 6, loss: 1.356573
global_step: 16238, epoch: 6, loss: 1.328171
global_step: 16239, epoch: 6, loss: 1.291047
global_step: 16240, epoch: 6, loss: 1.782506
epoch: 6
train	acc: 0.5693	macro: p 0.3085, r 0.2514, f1: 0.2370	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.4865
dev	acc: 0.5212	macro: p 0.2937, r 0.2539, f1: 0.2229	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4239
test	acc: 0.5632	macro: p 0.2802, r 0.2464, f1: 0.2244	micro: p 0.5632, r 0.5632, f1 0.5632	weighted_f1:0.4767
New best model!
global_step: 16241, epoch: 7, loss: 1.332592
global_step: 16242, epoch: 7, loss: 1.320273
global_step: 16243, epoch: 7, loss: 1.323620
global_step: 16244, epoch: 7, loss: 1.349721
global_step: 16245, epoch: 7, loss: 1.367722
global_step: 16246, epoch: 7, loss: 1.398566
global_step: 16247, epoch: 7, loss: 1.224890
global_step: 16248, epoch: 7, loss: 1.363441
global_step: 16249, epoch: 7, loss: 1.390990
global_step: 16250, epoch: 7, loss: 1.345355
global_step: 16251, epoch: 7, loss: 1.302289
global_step: 16252, epoch: 7, loss: 1.212169
global_step: 16253, epoch: 7, loss: 1.489486
global_step: 16254, epoch: 7, loss: 1.340295
global_step: 16255, epoch: 7, loss: 1.468574
global_step: 16256, epoch: 7, loss: 1.443362
global_step: 16257, epoch: 7, loss: 1.322987
global_step: 16258, epoch: 7, loss: 1.391880
global_step: 16259, epoch: 7, loss: 1.364511
global_step: 16260, epoch: 7, loss: 1.362058
global_step: 16261, epoch: 7, loss: 1.340503
global_step: 16262, epoch: 7, loss: 1.366534
global_step: 16263, epoch: 7, loss: 1.226749
global_step: 16264, epoch: 7, loss: 1.430406
global_step: 16265, epoch: 7, loss: 1.465415
global_step: 16266, epoch: 7, loss: 1.331219
global_step: 16267, epoch: 7, loss: 1.384769
global_step: 16268, epoch: 7, loss: 1.339087
global_step: 16269, epoch: 7, loss: 1.349525
global_step: 16270, epoch: 7, loss: 1.346328
global_step: 16271, epoch: 7, loss: 1.315476
global_step: 16272, epoch: 7, loss: 1.436499
global_step: 16273, epoch: 7, loss: 1.370062
global_step: 16274, epoch: 7, loss: 1.285207
global_step: 16275, epoch: 7, loss: 1.333220
global_step: 16276, epoch: 7, loss: 1.304933
global_step: 16277, epoch: 7, loss: 1.401556
global_step: 16278, epoch: 7, loss: 1.413107
global_step: 16279, epoch: 7, loss: 1.441350
global_step: 16280, epoch: 7, loss: 1.591388
epoch: 7
train	acc: 0.5707	macro: p 0.3100, r 0.2526, f1: 0.2392	micro: p 0.5707, r 0.5707, f1 0.5707	weighted_f1:0.4883
dev	acc: 0.5221	macro: p 0.2933, r 0.2550, f1: 0.2256	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4261
test	acc: 0.5644	macro: p 0.2821, r 0.2477, f1: 0.2271	micro: p 0.5644, r 0.5644, f1 0.5644	weighted_f1:0.4787
New best model!
global_step: 16281, epoch: 8, loss: 1.407904
global_step: 16282, epoch: 8, loss: 1.392620
global_step: 16283, epoch: 8, loss: 1.371009
global_step: 16284, epoch: 8, loss: 1.351443
global_step: 16285, epoch: 8, loss: 1.260319
global_step: 16286, epoch: 8, loss: 1.376087
global_step: 16287, epoch: 8, loss: 1.366940
global_step: 16288, epoch: 8, loss: 1.418265
global_step: 16289, epoch: 8, loss: 1.400277
global_step: 16290, epoch: 8, loss: 1.322312
global_step: 16291, epoch: 8, loss: 1.384808
global_step: 16292, epoch: 8, loss: 1.357153
global_step: 16293, epoch: 8, loss: 1.361705
global_step: 16294, epoch: 8, loss: 1.372431
global_step: 16295, epoch: 8, loss: 1.362038
global_step: 16296, epoch: 8, loss: 1.355901
global_step: 16297, epoch: 8, loss: 1.323154
global_step: 16298, epoch: 8, loss: 1.332193
global_step: 16299, epoch: 8, loss: 1.313461
global_step: 16300, epoch: 8, loss: 1.306504
global_step: 16301, epoch: 8, loss: 1.363060
global_step: 16302, epoch: 8, loss: 1.346168
global_step: 16303, epoch: 8, loss: 1.429194
global_step: 16304, epoch: 8, loss: 1.268976
global_step: 16305, epoch: 8, loss: 1.448647
global_step: 16306, epoch: 8, loss: 1.212335
global_step: 16307, epoch: 8, loss: 1.454808
global_step: 16308, epoch: 8, loss: 1.418150
global_step: 16309, epoch: 8, loss: 1.366587
global_step: 16310, epoch: 8, loss: 1.289981
global_step: 16311, epoch: 8, loss: 1.368904
global_step: 16312, epoch: 8, loss: 1.307149
global_step: 16313, epoch: 8, loss: 1.352472
global_step: 16314, epoch: 8, loss: 1.296907
global_step: 16315, epoch: 8, loss: 1.467937
global_step: 16316, epoch: 8, loss: 1.224610
global_step: 16317, epoch: 8, loss: 1.202410
global_step: 16318, epoch: 8, loss: 1.404363
global_step: 16319, epoch: 8, loss: 1.327186
global_step: 16320, epoch: 8, loss: 1.914010
epoch: 8
train	acc: 0.5779	macro: p 0.3100, r 0.2652, f1: 0.2583	micro: p 0.5779, r 0.5779, f1 0.5779	weighted_f1:0.5044
dev	acc: 0.5293	macro: p 0.2982, r 0.2631, f1: 0.2446	micro: p 0.5293, r 0.5293, f1 0.5293	weighted_f1:0.4450
test	acc: 0.5713	macro: p 0.2910, r 0.2566, f1: 0.2455	micro: p 0.5713, r 0.5713, f1 0.5713	weighted_f1:0.4959
New best model!
global_step: 16321, epoch: 9, loss: 1.343588
global_step: 16322, epoch: 9, loss: 1.304898
global_step: 16323, epoch: 9, loss: 1.438386
global_step: 16324, epoch: 9, loss: 1.324996
global_step: 16325, epoch: 9, loss: 1.315945
global_step: 16326, epoch: 9, loss: 1.420104
global_step: 16327, epoch: 9, loss: 1.442660
global_step: 16328, epoch: 9, loss: 1.311426
global_step: 16329, epoch: 9, loss: 1.248391
global_step: 16330, epoch: 9, loss: 1.276674
global_step: 16331, epoch: 9, loss: 1.305844
global_step: 16332, epoch: 9, loss: 1.355468
global_step: 16333, epoch: 9, loss: 1.293577
global_step: 16334, epoch: 9, loss: 1.313833
global_step: 16335, epoch: 9, loss: 1.381116
global_step: 16336, epoch: 9, loss: 1.416099
global_step: 16337, epoch: 9, loss: 1.387844
global_step: 16338, epoch: 9, loss: 1.258787
global_step: 16339, epoch: 9, loss: 1.229509
global_step: 16340, epoch: 9, loss: 1.217117
global_step: 16341, epoch: 9, loss: 1.356410
global_step: 16342, epoch: 9, loss: 1.251037
global_step: 16343, epoch: 9, loss: 1.390365
global_step: 16344, epoch: 9, loss: 1.273880
global_step: 16345, epoch: 9, loss: 1.416719
global_step: 16346, epoch: 9, loss: 1.395334
global_step: 16347, epoch: 9, loss: 1.333989
global_step: 16348, epoch: 9, loss: 1.298103
global_step: 16349, epoch: 9, loss: 1.273377
global_step: 16350, epoch: 9, loss: 1.489556
global_step: 16351, epoch: 9, loss: 1.362720
global_step: 16352, epoch: 9, loss: 1.356557
global_step: 16353, epoch: 9, loss: 1.368685
global_step: 16354, epoch: 9, loss: 1.367944
global_step: 16355, epoch: 9, loss: 1.218653
global_step: 16356, epoch: 9, loss: 1.446147
global_step: 16357, epoch: 9, loss: 1.357839
global_step: 16358, epoch: 9, loss: 1.326741
global_step: 16359, epoch: 9, loss: 1.359779
global_step: 16360, epoch: 9, loss: 1.162035
epoch: 9
train	acc: 0.5789	macro: p 0.3181, r 0.2653, f1: 0.2569	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5044
dev	acc: 0.5239	macro: p 0.2823, r 0.2606, f1: 0.2334	micro: p 0.5239, r 0.5239, f1 0.5239	weighted_f1:0.4339
test	acc: 0.5693	macro: p 0.2881, r 0.2569, f1: 0.2399	micro: p 0.5693, r 0.5693, f1 0.5693	weighted_f1:0.4899
global_step: 16361, epoch: 10, loss: 1.359433
global_step: 16362, epoch: 10, loss: 1.230284
global_step: 16363, epoch: 10, loss: 1.434440
global_step: 16364, epoch: 10, loss: 1.267169
global_step: 16365, epoch: 10, loss: 1.416545
global_step: 16366, epoch: 10, loss: 1.322794
global_step: 16367, epoch: 10, loss: 1.308383
global_step: 16368, epoch: 10, loss: 1.318140
global_step: 16369, epoch: 10, loss: 1.263747
global_step: 16370, epoch: 10, loss: 1.403402
global_step: 16371, epoch: 10, loss: 1.353170
global_step: 16372, epoch: 10, loss: 1.293810
global_step: 16373, epoch: 10, loss: 1.345675
global_step: 16374, epoch: 10, loss: 1.349923
global_step: 16375, epoch: 10, loss: 1.272515
global_step: 16376, epoch: 10, loss: 1.268615
global_step: 16377, epoch: 10, loss: 1.209568
global_step: 16378, epoch: 10, loss: 1.267054
global_step: 16379, epoch: 10, loss: 1.311897
global_step: 16380, epoch: 10, loss: 1.319974
global_step: 16381, epoch: 10, loss: 1.329164
global_step: 16382, epoch: 10, loss: 1.286097
global_step: 16383, epoch: 10, loss: 1.378142
global_step: 16384, epoch: 10, loss: 1.415174
global_step: 16385, epoch: 10, loss: 1.390488
global_step: 16386, epoch: 10, loss: 1.400922
global_step: 16387, epoch: 10, loss: 1.288487
global_step: 16388, epoch: 10, loss: 1.300481
global_step: 16389, epoch: 10, loss: 1.379663
global_step: 16390, epoch: 10, loss: 1.423857
global_step: 16391, epoch: 10, loss: 1.355669
global_step: 16392, epoch: 10, loss: 1.344323
global_step: 16393, epoch: 10, loss: 1.271364
global_step: 16394, epoch: 10, loss: 1.350550
global_step: 16395, epoch: 10, loss: 1.491348
global_step: 16396, epoch: 10, loss: 1.394167
global_step: 16397, epoch: 10, loss: 1.206693
global_step: 16398, epoch: 10, loss: 1.273299
global_step: 16399, epoch: 10, loss: 1.291950
global_step: 16400, epoch: 10, loss: 0.729932
epoch: 10
train	acc: 0.5715	macro: p 0.3247, r 0.2550, f1: 0.2364	micro: p 0.5715, r 0.5715, f1 0.5715	weighted_f1:0.4880
dev	acc: 0.5212	macro: p 0.3222, r 0.2576, f1: 0.2193	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4205
test	acc: 0.5690	macro: p 0.3065, r 0.2574, f1: 0.2319	micro: p 0.5690, r 0.5690, f1 0.5690	weighted_f1:0.4818
global_step: 16401, epoch: 11, loss: 1.384639
global_step: 16402, epoch: 11, loss: 1.187666
global_step: 16403, epoch: 11, loss: 1.331374
global_step: 16404, epoch: 11, loss: 1.299447
global_step: 16405, epoch: 11, loss: 1.426842
global_step: 16406, epoch: 11, loss: 1.262777
global_step: 16407, epoch: 11, loss: 1.303462
global_step: 16408, epoch: 11, loss: 1.190289
global_step: 16409, epoch: 11, loss: 1.397211
global_step: 16410, epoch: 11, loss: 1.317690
global_step: 16411, epoch: 11, loss: 1.356802
global_step: 16412, epoch: 11, loss: 1.464433
global_step: 16413, epoch: 11, loss: 1.371289
global_step: 16414, epoch: 11, loss: 1.287752
global_step: 16415, epoch: 11, loss: 1.422297
global_step: 16416, epoch: 11, loss: 1.351696
global_step: 16417, epoch: 11, loss: 1.196652
global_step: 16418, epoch: 11, loss: 1.315377
global_step: 16419, epoch: 11, loss: 1.387196
global_step: 16420, epoch: 11, loss: 1.200209
global_step: 16421, epoch: 11, loss: 1.288544
global_step: 16422, epoch: 11, loss: 1.353435
global_step: 16423, epoch: 11, loss: 1.420504
global_step: 16424, epoch: 11, loss: 1.311200
global_step: 16425, epoch: 11, loss: 1.400102
global_step: 16426, epoch: 11, loss: 1.246806
global_step: 16427, epoch: 11, loss: 1.295354
global_step: 16428, epoch: 11, loss: 1.304200
global_step: 16429, epoch: 11, loss: 1.339006
global_step: 16430, epoch: 11, loss: 1.326777
global_step: 16431, epoch: 11, loss: 1.190389
global_step: 16432, epoch: 11, loss: 1.303250
global_step: 16433, epoch: 11, loss: 1.296175
global_step: 16434, epoch: 11, loss: 1.280050
global_step: 16435, epoch: 11, loss: 1.341456
global_step: 16436, epoch: 11, loss: 1.229252
global_step: 16437, epoch: 11, loss: 1.240932
global_step: 16438, epoch: 11, loss: 1.400840
global_step: 16439, epoch: 11, loss: 1.243987
global_step: 16440, epoch: 11, loss: 0.935362
epoch: 11
train	acc: 0.5792	macro: p 0.3109, r 0.2652, f1: 0.2531	micro: p 0.5792, r 0.5792, f1 0.5792	weighted_f1:0.5022
dev	acc: 0.5221	macro: p 0.2640, r 0.2593, f1: 0.2265	micro: p 0.5221, r 0.5221, f1 0.5221	weighted_f1:0.4274
test	acc: 0.5686	macro: p 0.2691, r 0.2582, f1: 0.2359	micro: p 0.5686, r 0.5686, f1 0.5686	weighted_f1:0.4850
global_step: 16441, epoch: 12, loss: 1.320196
global_step: 16442, epoch: 12, loss: 1.432732
global_step: 16443, epoch: 12, loss: 1.371952
global_step: 16444, epoch: 12, loss: 1.214465
global_step: 16445, epoch: 12, loss: 1.338116
global_step: 16446, epoch: 12, loss: 1.343760
global_step: 16447, epoch: 12, loss: 1.353295
global_step: 16448, epoch: 12, loss: 1.235555
global_step: 16449, epoch: 12, loss: 1.297000
global_step: 16450, epoch: 12, loss: 1.335716
global_step: 16451, epoch: 12, loss: 1.272783
global_step: 16452, epoch: 12, loss: 1.321329
global_step: 16453, epoch: 12, loss: 1.355510
global_step: 16454, epoch: 12, loss: 1.252922
global_step: 16455, epoch: 12, loss: 1.307478
global_step: 16456, epoch: 12, loss: 1.286900
global_step: 16457, epoch: 12, loss: 1.336278
global_step: 16458, epoch: 12, loss: 1.299613
global_step: 16459, epoch: 12, loss: 1.294488
global_step: 16460, epoch: 12, loss: 1.277865
global_step: 16461, epoch: 12, loss: 1.340243
global_step: 16462, epoch: 12, loss: 1.323353
global_step: 16463, epoch: 12, loss: 1.320478
global_step: 16464, epoch: 12, loss: 1.194836
global_step: 16465, epoch: 12, loss: 1.404095
global_step: 16466, epoch: 12, loss: 1.235698
global_step: 16467, epoch: 12, loss: 1.267695
global_step: 16468, epoch: 12, loss: 1.231032
global_step: 16469, epoch: 12, loss: 1.331918
global_step: 16470, epoch: 12, loss: 1.236654
global_step: 16471, epoch: 12, loss: 1.234552
global_step: 16472, epoch: 12, loss: 1.454823
global_step: 16473, epoch: 12, loss: 1.275893
global_step: 16474, epoch: 12, loss: 1.267859
global_step: 16475, epoch: 12, loss: 1.416725
global_step: 16476, epoch: 12, loss: 1.297518
global_step: 16477, epoch: 12, loss: 1.287750
global_step: 16478, epoch: 12, loss: 1.400541
global_step: 16479, epoch: 12, loss: 1.335447
global_step: 16480, epoch: 12, loss: 1.342752
epoch: 12
train	acc: 0.5815	macro: p 0.3129, r 0.2676, f1: 0.2582	micro: p 0.5815, r 0.5815, f1 0.5815	weighted_f1:0.5065
dev	acc: 0.5212	macro: p 0.2645, r 0.2581, f1: 0.2266	micro: p 0.5212, r 0.5212, f1 0.5212	weighted_f1:0.4275
test	acc: 0.5736	macro: p 0.2897, r 0.2625, f1: 0.2448	micro: p 0.5736, r 0.5736, f1 0.5736	weighted_f1:0.4936
global_step: 16481, epoch: 13, loss: 1.302942
global_step: 16482, epoch: 13, loss: 1.300645
global_step: 16483, epoch: 13, loss: 1.304675
global_step: 16484, epoch: 13, loss: 1.358809
global_step: 16485, epoch: 13, loss: 1.260450
global_step: 16486, epoch: 13, loss: 1.381667
global_step: 16487, epoch: 13, loss: 1.233411
global_step: 16488, epoch: 13, loss: 1.352660
global_step: 16489, epoch: 13, loss: 1.301205
global_step: 16490, epoch: 13, loss: 1.211801
global_step: 16491, epoch: 13, loss: 1.308361
global_step: 16492, epoch: 13, loss: 1.254994
global_step: 16493, epoch: 13, loss: 1.297257
global_step: 16494, epoch: 13, loss: 1.301070
global_step: 16495, epoch: 13, loss: 1.230763
global_step: 16496, epoch: 13, loss: 1.330455
global_step: 16497, epoch: 13, loss: 1.316480
global_step: 16498, epoch: 13, loss: 1.233829
global_step: 16499, epoch: 13, loss: 1.282128
global_step: 16500, epoch: 13, loss: 1.286191
global_step: 16501, epoch: 13, loss: 1.385483
global_step: 16502, epoch: 13, loss: 1.307834
global_step: 16503, epoch: 13, loss: 1.160120
global_step: 16504, epoch: 13, loss: 1.340434
global_step: 16505, epoch: 13, loss: 1.413701
global_step: 16506, epoch: 13, loss: 1.231637
global_step: 16507, epoch: 13, loss: 1.318708
global_step: 16508, epoch: 13, loss: 1.412441
global_step: 16509, epoch: 13, loss: 1.278205
global_step: 16510, epoch: 13, loss: 1.416708
global_step: 16511, epoch: 13, loss: 1.243002
global_step: 16512, epoch: 13, loss: 1.397140
global_step: 16513, epoch: 13, loss: 1.299880
global_step: 16514, epoch: 13, loss: 1.371740
global_step: 16515, epoch: 13, loss: 1.239387
global_step: 16516, epoch: 13, loss: 1.303378
global_step: 16517, epoch: 13, loss: 1.184777
global_step: 16518, epoch: 13, loss: 1.300242
global_step: 16519, epoch: 13, loss: 1.313661
global_step: 16520, epoch: 13, loss: 1.058742
epoch: 13
train	acc: 0.5806	macro: p 0.3210, r 0.2661, f1: 0.2556	micro: p 0.5806, r 0.5806, f1 0.5806	weighted_f1:0.5044
dev	acc: 0.5230	macro: p 0.2787, r 0.2597, f1: 0.2273	micro: p 0.5230, r 0.5230, f1 0.5230	weighted_f1:0.4285
test	acc: 0.5728	macro: p 0.2896, r 0.2617, f1: 0.2423	micro: p 0.5728, r 0.5728, f1 0.5728	weighted_f1:0.4914
global_step: 16521, epoch: 14, loss: 1.252134
global_step: 16522, epoch: 14, loss: 1.327850
global_step: 16523, epoch: 14, loss: 1.379625
global_step: 16524, epoch: 14, loss: 1.218885
global_step: 16525, epoch: 14, loss: 1.275727
global_step: 16526, epoch: 14, loss: 1.255078
global_step: 16527, epoch: 14, loss: 1.328740
global_step: 16528, epoch: 14, loss: 1.269473
global_step: 16529, epoch: 14, loss: 1.413730
global_step: 16530, epoch: 14, loss: 1.199362
global_step: 16531, epoch: 14, loss: 1.285069
global_step: 16532, epoch: 14, loss: 1.367597
global_step: 16533, epoch: 14, loss: 1.207452
global_step: 16534, epoch: 14, loss: 1.286168
global_step: 16535, epoch: 14, loss: 1.269004
global_step: 16536, epoch: 14, loss: 1.234674
global_step: 16537, epoch: 14, loss: 1.270635
global_step: 16538, epoch: 14, loss: 1.323338
global_step: 16539, epoch: 14, loss: 1.273539
global_step: 16540, epoch: 14, loss: 1.323110
global_step: 16541, epoch: 14, loss: 1.419617
global_step: 16542, epoch: 14, loss: 1.296504
global_step: 16543, epoch: 14, loss: 1.344684
global_step: 16544, epoch: 14, loss: 1.220530
global_step: 16545, epoch: 14, loss: 1.323767
global_step: 16546, epoch: 14, loss: 1.290021
global_step: 16547, epoch: 14, loss: 1.284436
global_step: 16548, epoch: 14, loss: 1.307489
global_step: 16549, epoch: 14, loss: 1.406140
global_step: 16550, epoch: 14, loss: 1.318054
global_step: 16551, epoch: 14, loss: 1.196373
global_step: 16552, epoch: 14, loss: 1.339871
global_step: 16553, epoch: 14, loss: 1.226693
global_step: 16554, epoch: 14, loss: 1.282348
global_step: 16555, epoch: 14, loss: 1.239272
global_step: 16556, epoch: 14, loss: 1.255727
global_step: 16557, epoch: 14, loss: 1.283477
global_step: 16558, epoch: 14, loss: 1.206636
global_step: 16559, epoch: 14, loss: 1.238761
global_step: 16560, epoch: 14, loss: 0.859166
epoch: 14
train	acc: 0.5885	macro: p 0.3179, r 0.2765, f1: 0.2708	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5173
dev	acc: 0.5257	macro: p 0.2649, r 0.2631, f1: 0.2370	micro: p 0.5257, r 0.5257, f1 0.5257	weighted_f1:0.4377
test	acc: 0.5766	macro: p 0.2885, r 0.2671, f1: 0.2534	micro: p 0.5766, r 0.5766, f1 0.5766	weighted_f1:0.5010
global_step: 16561, epoch: 15, loss: 1.289213
global_step: 16562, epoch: 15, loss: 1.320970
global_step: 16563, epoch: 15, loss: 1.400310
global_step: 16564, epoch: 15, loss: 1.426776
global_step: 16565, epoch: 15, loss: 1.238497
global_step: 16566, epoch: 15, loss: 1.264366
global_step: 16567, epoch: 15, loss: 1.343771
global_step: 16568, epoch: 15, loss: 1.246619
global_step: 16569, epoch: 15, loss: 1.286603
global_step: 16570, epoch: 15, loss: 1.377077
global_step: 16571, epoch: 15, loss: 1.200116
global_step: 16572, epoch: 15, loss: 1.282014
global_step: 16573, epoch: 15, loss: 1.252503
global_step: 16574, epoch: 15, loss: 1.235011
global_step: 16575, epoch: 15, loss: 1.184865
global_step: 16576, epoch: 15, loss: 1.296174
global_step: 16577, epoch: 15, loss: 1.224075
global_step: 16578, epoch: 15, loss: 1.253667
global_step: 16579, epoch: 15, loss: 1.222444
global_step: 16580, epoch: 15, loss: 1.313839
global_step: 16581, epoch: 15, loss: 1.246197
global_step: 16582, epoch: 15, loss: 1.282659
global_step: 16583, epoch: 15, loss: 1.327886
global_step: 16584, epoch: 15, loss: 1.418131
global_step: 16585, epoch: 15, loss: 1.295091
global_step: 16586, epoch: 15, loss: 1.159144
global_step: 16587, epoch: 15, loss: 1.251265
global_step: 16588, epoch: 15, loss: 1.240919
global_step: 16589, epoch: 15, loss: 1.256345
global_step: 16590, epoch: 15, loss: 1.306285
global_step: 16591, epoch: 15, loss: 1.255690
global_step: 16592, epoch: 15, loss: 1.198488
global_step: 16593, epoch: 15, loss: 1.356569
global_step: 16594, epoch: 15, loss: 1.311883
global_step: 16595, epoch: 15, loss: 1.216557
global_step: 16596, epoch: 15, loss: 1.361750
global_step: 16597, epoch: 15, loss: 1.281544
global_step: 16598, epoch: 15, loss: 1.272105
global_step: 16599, epoch: 15, loss: 1.225538
global_step: 16600, epoch: 15, loss: 1.282877
epoch: 15
train	acc: 0.5847	macro: p 0.3239, r 0.2717, f1: 0.2623	micro: p 0.5847, r 0.5847, f1 0.5847	weighted_f1:0.5107
dev	acc: 0.5266	macro: p 0.2702, r 0.2642, f1: 0.2308	micro: p 0.5266, r 0.5266, f1 0.5266	weighted_f1:0.4325
test	acc: 0.5751	macro: p 0.2891, r 0.2659, f1: 0.2466	micro: p 0.5751, r 0.5751, f1 0.5751	weighted_f1:0.4953
global_step: 16601, epoch: 16, loss: 1.310801
global_step: 16602, epoch: 16, loss: 1.309924
global_step: 16603, epoch: 16, loss: 1.204084
global_step: 16604, epoch: 16, loss: 1.248530
global_step: 16605, epoch: 16, loss: 1.315818
global_step: 16606, epoch: 16, loss: 1.212952
global_step: 16607, epoch: 16, loss: 1.189016
global_step: 16608, epoch: 16, loss: 1.259157
global_step: 16609, epoch: 16, loss: 1.314286
global_step: 16610, epoch: 16, loss: 1.258872
global_step: 16611, epoch: 16, loss: 1.195084
global_step: 16612, epoch: 16, loss: 1.255472
global_step: 16613, epoch: 16, loss: 1.367205
global_step: 16614, epoch: 16, loss: 1.246641
global_step: 16615, epoch: 16, loss: 1.256445
global_step: 16616, epoch: 16, loss: 1.230668
global_step: 16617, epoch: 16, loss: 1.342172
global_step: 16618, epoch: 16, loss: 1.331586
global_step: 16619, epoch: 16, loss: 1.338076
global_step: 16620, epoch: 16, loss: 1.272433
global_step: 16621, epoch: 16, loss: 1.288478
global_step: 16622, epoch: 16, loss: 1.304878
global_step: 16623, epoch: 16, loss: 1.278383
global_step: 16624, epoch: 16, loss: 1.185561
global_step: 16625, epoch: 16, loss: 1.251347
global_step: 16626, epoch: 16, loss: 1.290966
global_step: 16627, epoch: 16, loss: 1.293229
global_step: 16628, epoch: 16, loss: 1.264820
global_step: 16629, epoch: 16, loss: 1.258339
global_step: 16630, epoch: 16, loss: 1.244115
global_step: 16631, epoch: 16, loss: 1.195966
global_step: 16632, epoch: 16, loss: 1.191352
global_step: 16633, epoch: 16, loss: 1.314945
global_step: 16634, epoch: 16, loss: 1.252108
global_step: 16635, epoch: 16, loss: 1.121499
global_step: 16636, epoch: 16, loss: 1.352070
global_step: 16637, epoch: 16, loss: 1.317455
global_step: 16638, epoch: 16, loss: 1.289973
global_step: 16639, epoch: 16, loss: 1.332888
global_step: 16640, epoch: 16, loss: 0.968477
epoch: 16
train	acc: 0.5904	macro: p 0.3257, r 0.2788, f1: 0.2728	micro: p 0.5904, r 0.5904, f1 0.5904	weighted_f1:0.5197
dev	acc: 0.5311	macro: p 0.2731, r 0.2691, f1: 0.2403	micro: p 0.5311, r 0.5311, f1 0.5311	weighted_f1:0.4418
test	acc: 0.5789	macro: p 0.2915, r 0.2702, f1: 0.2546	micro: p 0.5789, r 0.5789, f1 0.5789	weighted_f1:0.5029
global_step: 16641, epoch: 17, loss: 1.435346
global_step: 16642, epoch: 17, loss: 1.264385
global_step: 16643, epoch: 17, loss: 1.358621
global_step: 16644, epoch: 17, loss: 1.238316
global_step: 16645, epoch: 17, loss: 1.308885
global_step: 16646, epoch: 17, loss: 1.234141
global_step: 16647, epoch: 17, loss: 1.160786
global_step: 16648, epoch: 17, loss: 1.253867
global_step: 16649, epoch: 17, loss: 1.315891
global_step: 16650, epoch: 17, loss: 1.250028
global_step: 16651, epoch: 17, loss: 1.177295
global_step: 16652, epoch: 17, loss: 1.106844
global_step: 16653, epoch: 17, loss: 1.216199
global_step: 16654, epoch: 17, loss: 1.290819
global_step: 16655, epoch: 17, loss: 1.282134
global_step: 16656, epoch: 17, loss: 1.384304
global_step: 16657, epoch: 17, loss: 1.202146
global_step: 16658, epoch: 17, loss: 1.312697
global_step: 16659, epoch: 17, loss: 1.284827
global_step: 16660, epoch: 17, loss: 1.274253
global_step: 16661, epoch: 17, loss: 1.197127
global_step: 16662, epoch: 17, loss: 1.163552
global_step: 16663, epoch: 17, loss: 1.208332
global_step: 16664, epoch: 17, loss: 1.300453
global_step: 16665, epoch: 17, loss: 1.349676
global_step: 16666, epoch: 17, loss: 1.323549
global_step: 16667, epoch: 17, loss: 1.181132
global_step: 16668, epoch: 17, loss: 1.334270
global_step: 16669, epoch: 17, loss: 1.215123
global_step: 16670, epoch: 17, loss: 1.235795
global_step: 16671, epoch: 17, loss: 1.275632
global_step: 16672, epoch: 17, loss: 1.210483
global_step: 16673, epoch: 17, loss: 1.313501
global_step: 16674, epoch: 17, loss: 1.216928
global_step: 16675, epoch: 17, loss: 1.279915
global_step: 16676, epoch: 17, loss: 1.223610
global_step: 16677, epoch: 17, loss: 1.239318
global_step: 16678, epoch: 17, loss: 1.235115
global_step: 16679, epoch: 17, loss: 1.351621
global_step: 16680, epoch: 17, loss: 0.952304
epoch: 17
train	acc: 0.5982	macro: p 0.3257, r 0.2916, f1: 0.2905	micro: p 0.5982, r 0.5982, f1 0.5982	weighted_f1:0.5340
dev	acc: 0.5365	macro: p 0.2793, r 0.2754, f1: 0.2599	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4605
test	acc: 0.5862	macro: p 0.4405, r 0.2791, f1: 0.2737	micro: p 0.5862, r 0.5862, f1 0.5862	weighted_f1:0.5199
New best model!
global_step: 16681, epoch: 18, loss: 1.205925
global_step: 16682, epoch: 18, loss: 1.217266
global_step: 16683, epoch: 18, loss: 1.171851
global_step: 16684, epoch: 18, loss: 1.118588
global_step: 16685, epoch: 18, loss: 1.162741
global_step: 16686, epoch: 18, loss: 1.368513
global_step: 16687, epoch: 18, loss: 1.314889
global_step: 16688, epoch: 18, loss: 1.202892
global_step: 16689, epoch: 18, loss: 1.263293
global_step: 16690, epoch: 18, loss: 1.252582
global_step: 16691, epoch: 18, loss: 1.366413
global_step: 16692, epoch: 18, loss: 1.369013
global_step: 16693, epoch: 18, loss: 1.288163
global_step: 16694, epoch: 18, loss: 1.266161
global_step: 16695, epoch: 18, loss: 1.236966
global_step: 16696, epoch: 18, loss: 1.358605
global_step: 16697, epoch: 18, loss: 1.166141
global_step: 16698, epoch: 18, loss: 1.255389
global_step: 16699, epoch: 18, loss: 1.281485
global_step: 16700, epoch: 18, loss: 1.262782
global_step: 16701, epoch: 18, loss: 1.271457
global_step: 16702, epoch: 18, loss: 1.366234
global_step: 16703, epoch: 18, loss: 1.230695
global_step: 16704, epoch: 18, loss: 1.201345
global_step: 16705, epoch: 18, loss: 1.326700
global_step: 16706, epoch: 18, loss: 1.231704
global_step: 16707, epoch: 18, loss: 1.247160
global_step: 16708, epoch: 18, loss: 1.264697
global_step: 16709, epoch: 18, loss: 1.310899
global_step: 16710, epoch: 18, loss: 1.258539
global_step: 16711, epoch: 18, loss: 1.103691
global_step: 16712, epoch: 18, loss: 1.228269
global_step: 16713, epoch: 18, loss: 1.164360
global_step: 16714, epoch: 18, loss: 1.329265
global_step: 16715, epoch: 18, loss: 1.302863
global_step: 16716, epoch: 18, loss: 1.300703
global_step: 16717, epoch: 18, loss: 1.186757
global_step: 16718, epoch: 18, loss: 1.181163
global_step: 16719, epoch: 18, loss: 1.300225
global_step: 16720, epoch: 18, loss: 0.621553
epoch: 18
train	acc: 0.5943	macro: p 0.4750, r 0.2833, f1: 0.2794	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5254
dev	acc: 0.5356	macro: p 0.2856, r 0.2737, f1: 0.2483	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4496
test	acc: 0.5828	macro: p 0.4417, r 0.2750, f1: 0.2618	micro: p 0.5828, r 0.5828, f1 0.5828	weighted_f1:0.5089
global_step: 16721, epoch: 19, loss: 1.283413
global_step: 16722, epoch: 19, loss: 1.269079
global_step: 16723, epoch: 19, loss: 1.360141
global_step: 16724, epoch: 19, loss: 1.279530
global_step: 16725, epoch: 19, loss: 1.179516
global_step: 16726, epoch: 19, loss: 1.334182
global_step: 16727, epoch: 19, loss: 1.167148
global_step: 16728, epoch: 19, loss: 1.100122
global_step: 16729, epoch: 19, loss: 1.291305
global_step: 16730, epoch: 19, loss: 1.200375
global_step: 16731, epoch: 19, loss: 1.254901
global_step: 16732, epoch: 19, loss: 1.303727
global_step: 16733, epoch: 19, loss: 1.274613
global_step: 16734, epoch: 19, loss: 1.274393
global_step: 16735, epoch: 19, loss: 1.194393
global_step: 16736, epoch: 19, loss: 1.210259
global_step: 16737, epoch: 19, loss: 1.214270
global_step: 16738, epoch: 19, loss: 1.212255
global_step: 16739, epoch: 19, loss: 1.224529
global_step: 16740, epoch: 19, loss: 1.317111
global_step: 16741, epoch: 19, loss: 1.143784
global_step: 16742, epoch: 19, loss: 1.225785
global_step: 16743, epoch: 19, loss: 1.227254
global_step: 16744, epoch: 19, loss: 1.318096
global_step: 16745, epoch: 19, loss: 1.171075
global_step: 16746, epoch: 19, loss: 1.211393
global_step: 16747, epoch: 19, loss: 1.152331
global_step: 16748, epoch: 19, loss: 1.201515
global_step: 16749, epoch: 19, loss: 1.311991
global_step: 16750, epoch: 19, loss: 1.229514
global_step: 16751, epoch: 19, loss: 1.324924
global_step: 16752, epoch: 19, loss: 1.248201
global_step: 16753, epoch: 19, loss: 1.290748
global_step: 16754, epoch: 19, loss: 1.284012
global_step: 16755, epoch: 19, loss: 1.261832
global_step: 16756, epoch: 19, loss: 1.180585
global_step: 16757, epoch: 19, loss: 1.316153
global_step: 16758, epoch: 19, loss: 1.326437
global_step: 16759, epoch: 19, loss: 1.150343
global_step: 16760, epoch: 19, loss: 1.568724
epoch: 19
train	acc: 0.6031	macro: p 0.4681, r 0.2978, f1: 0.2965	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5400
dev	acc: 0.5383	macro: p 0.4098, r 0.2780, f1: 0.2531	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4551
test	acc: 0.5831	macro: p 0.4311, r 0.2801, f1: 0.2684	micro: p 0.5831, r 0.5831, f1 0.5831	weighted_f1:0.5142
global_step: 16761, epoch: 20, loss: 1.276198
global_step: 16762, epoch: 20, loss: 1.196007
global_step: 16763, epoch: 20, loss: 1.278974
global_step: 16764, epoch: 20, loss: 1.140208
global_step: 16765, epoch: 20, loss: 1.171900
global_step: 16766, epoch: 20, loss: 1.291859
global_step: 16767, epoch: 20, loss: 1.343359
global_step: 16768, epoch: 20, loss: 1.220167
global_step: 16769, epoch: 20, loss: 1.220661
global_step: 16770, epoch: 20, loss: 1.173426
global_step: 16771, epoch: 20, loss: 1.263513
global_step: 16772, epoch: 20, loss: 1.344794
global_step: 16773, epoch: 20, loss: 1.180562
global_step: 16774, epoch: 20, loss: 1.257907
global_step: 16775, epoch: 20, loss: 1.154157
global_step: 16776, epoch: 20, loss: 1.327227
global_step: 16777, epoch: 20, loss: 1.129780
global_step: 16778, epoch: 20, loss: 1.154282
global_step: 16779, epoch: 20, loss: 1.295085
global_step: 16780, epoch: 20, loss: 1.277856
global_step: 16781, epoch: 20, loss: 1.241270
global_step: 16782, epoch: 20, loss: 1.263661
global_step: 16783, epoch: 20, loss: 1.246878
global_step: 16784, epoch: 20, loss: 1.250160
global_step: 16785, epoch: 20, loss: 1.243394
global_step: 16786, epoch: 20, loss: 1.281593
global_step: 16787, epoch: 20, loss: 1.262462
global_step: 16788, epoch: 20, loss: 1.137311
global_step: 16789, epoch: 20, loss: 1.203412
global_step: 16790, epoch: 20, loss: 1.138369
global_step: 16791, epoch: 20, loss: 1.251562
global_step: 16792, epoch: 20, loss: 1.226864
global_step: 16793, epoch: 20, loss: 1.165322
global_step: 16794, epoch: 20, loss: 1.163784
global_step: 16795, epoch: 20, loss: 1.245246
global_step: 16796, epoch: 20, loss: 1.251959
global_step: 16797, epoch: 20, loss: 1.283653
global_step: 16798, epoch: 20, loss: 1.274267
global_step: 16799, epoch: 20, loss: 1.367964
global_step: 16800, epoch: 20, loss: 1.739219
epoch: 20
train	acc: 0.6074	macro: p 0.4382, r 0.3035, f1: 0.3063	micro: p 0.6074, r 0.6074, f1 0.6074	weighted_f1:0.5472
dev	acc: 0.5419	macro: p 0.4162, r 0.2824, f1: 0.2648	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4654
test	acc: 0.5851	macro: p 0.4039, r 0.2817, f1: 0.2735	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5183
New best model!
global_step: 16801, epoch: 21, loss: 1.173273
global_step: 16802, epoch: 21, loss: 1.299043
global_step: 16803, epoch: 21, loss: 1.310932
global_step: 16804, epoch: 21, loss: 1.229062
global_step: 16805, epoch: 21, loss: 1.292770
global_step: 16806, epoch: 21, loss: 1.276333
global_step: 16807, epoch: 21, loss: 1.226735
global_step: 16808, epoch: 21, loss: 1.132532
global_step: 16809, epoch: 21, loss: 1.283651
global_step: 16810, epoch: 21, loss: 1.212094
global_step: 16811, epoch: 21, loss: 1.216178
global_step: 16812, epoch: 21, loss: 1.419862
global_step: 16813, epoch: 21, loss: 1.219485
global_step: 16814, epoch: 21, loss: 1.210863
global_step: 16815, epoch: 21, loss: 1.107396
global_step: 16816, epoch: 21, loss: 1.239637
global_step: 16817, epoch: 21, loss: 1.122092
global_step: 16818, epoch: 21, loss: 1.266141
global_step: 16819, epoch: 21, loss: 1.281795
global_step: 16820, epoch: 21, loss: 1.192281
global_step: 16821, epoch: 21, loss: 1.232355
global_step: 16822, epoch: 21, loss: 1.197761
global_step: 16823, epoch: 21, loss: 1.204159
global_step: 16824, epoch: 21, loss: 1.296119
global_step: 16825, epoch: 21, loss: 1.151891
global_step: 16826, epoch: 21, loss: 1.279526
global_step: 16827, epoch: 21, loss: 1.330128
global_step: 16828, epoch: 21, loss: 1.259859
global_step: 16829, epoch: 21, loss: 1.211328
global_step: 16830, epoch: 21, loss: 1.296245
global_step: 16831, epoch: 21, loss: 1.175858
global_step: 16832, epoch: 21, loss: 1.133586
global_step: 16833, epoch: 21, loss: 1.141887
global_step: 16834, epoch: 21, loss: 1.306702
global_step: 16835, epoch: 21, loss: 1.126324
global_step: 16836, epoch: 21, loss: 1.279417
global_step: 16837, epoch: 21, loss: 1.134011
global_step: 16838, epoch: 21, loss: 1.102548
global_step: 16839, epoch: 21, loss: 1.230841
global_step: 16840, epoch: 21, loss: 1.046762
epoch: 21
train	acc: 0.5951	macro: p 0.4541, r 0.2850, f1: 0.2813	micro: p 0.5951, r 0.5951, f1 0.5951	weighted_f1:0.5264
dev	acc: 0.5338	macro: p 0.4190, r 0.2737, f1: 0.2439	micro: p 0.5338, r 0.5338, f1 0.5338	weighted_f1:0.4453
test	acc: 0.5808	macro: p 0.4349, r 0.2737, f1: 0.2567	micro: p 0.5808, r 0.5808, f1 0.5808	weighted_f1:0.5038
global_step: 16841, epoch: 22, loss: 1.116231
global_step: 16842, epoch: 22, loss: 1.300420
global_step: 16843, epoch: 22, loss: 1.251955
global_step: 16844, epoch: 22, loss: 1.285276
global_step: 16845, epoch: 22, loss: 1.189832
global_step: 16846, epoch: 22, loss: 1.257160
global_step: 16847, epoch: 22, loss: 1.243346
global_step: 16848, epoch: 22, loss: 1.119091
global_step: 16849, epoch: 22, loss: 1.183381
global_step: 16850, epoch: 22, loss: 1.242720
global_step: 16851, epoch: 22, loss: 1.166225
global_step: 16852, epoch: 22, loss: 1.288882
global_step: 16853, epoch: 22, loss: 1.295362
global_step: 16854, epoch: 22, loss: 1.297249
global_step: 16855, epoch: 22, loss: 1.143301
global_step: 16856, epoch: 22, loss: 1.208946
global_step: 16857, epoch: 22, loss: 1.198715
global_step: 16858, epoch: 22, loss: 1.194386
global_step: 16859, epoch: 22, loss: 1.253580
global_step: 16860, epoch: 22, loss: 1.346308
global_step: 16861, epoch: 22, loss: 1.228553
global_step: 16862, epoch: 22, loss: 1.218330
global_step: 16863, epoch: 22, loss: 1.119210
global_step: 16864, epoch: 22, loss: 1.252167
global_step: 16865, epoch: 22, loss: 1.178996
global_step: 16866, epoch: 22, loss: 1.174055
global_step: 16867, epoch: 22, loss: 1.076324
global_step: 16868, epoch: 22, loss: 1.273566
global_step: 16869, epoch: 22, loss: 1.238272
global_step: 16870, epoch: 22, loss: 1.177702
global_step: 16871, epoch: 22, loss: 1.269724
global_step: 16872, epoch: 22, loss: 1.130952
global_step: 16873, epoch: 22, loss: 1.284344
global_step: 16874, epoch: 22, loss: 1.160430
global_step: 16875, epoch: 22, loss: 1.306658
global_step: 16876, epoch: 22, loss: 1.206900
global_step: 16877, epoch: 22, loss: 1.252318
global_step: 16878, epoch: 22, loss: 1.168663
global_step: 16879, epoch: 22, loss: 1.230096
global_step: 16880, epoch: 22, loss: 1.288545
epoch: 22
train	acc: 0.6050	macro: p 0.4548, r 0.2981, f1: 0.2993	micro: p 0.6050, r 0.6050, f1 0.6050	weighted_f1:0.5415
dev	acc: 0.5410	macro: p 0.3933, r 0.2823, f1: 0.2590	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4595
test	acc: 0.5835	macro: p 0.4070, r 0.2790, f1: 0.2653	micro: p 0.5835, r 0.5835, f1 0.5835	weighted_f1:0.5107
global_step: 16881, epoch: 23, loss: 1.163187
global_step: 16882, epoch: 23, loss: 1.150467
global_step: 16883, epoch: 23, loss: 1.230374
global_step: 16884, epoch: 23, loss: 1.167580
global_step: 16885, epoch: 23, loss: 1.238811
global_step: 16886, epoch: 23, loss: 1.227991
global_step: 16887, epoch: 23, loss: 1.177823
global_step: 16888, epoch: 23, loss: 1.239686
global_step: 16889, epoch: 23, loss: 1.139587
global_step: 16890, epoch: 23, loss: 1.190387
global_step: 16891, epoch: 23, loss: 1.284513
global_step: 16892, epoch: 23, loss: 1.183579
global_step: 16893, epoch: 23, loss: 1.165872
global_step: 16894, epoch: 23, loss: 1.226400
global_step: 16895, epoch: 23, loss: 1.190443
global_step: 16896, epoch: 23, loss: 1.235489
global_step: 16897, epoch: 23, loss: 1.290707
global_step: 16898, epoch: 23, loss: 1.097145
global_step: 16899, epoch: 23, loss: 1.234986
global_step: 16900, epoch: 23, loss: 1.188423
global_step: 16901, epoch: 23, loss: 1.182683
global_step: 16902, epoch: 23, loss: 1.285363
global_step: 16903, epoch: 23, loss: 1.221281
global_step: 16904, epoch: 23, loss: 1.164981
global_step: 16905, epoch: 23, loss: 1.088284
global_step: 16906, epoch: 23, loss: 1.176193
global_step: 16907, epoch: 23, loss: 1.265369
global_step: 16908, epoch: 23, loss: 1.211164
global_step: 16909, epoch: 23, loss: 1.133223
global_step: 16910, epoch: 23, loss: 1.166485
global_step: 16911, epoch: 23, loss: 1.151893
global_step: 16912, epoch: 23, loss: 1.284217
global_step: 16913, epoch: 23, loss: 1.204056
global_step: 16914, epoch: 23, loss: 1.091790
global_step: 16915, epoch: 23, loss: 1.290544
global_step: 16916, epoch: 23, loss: 1.264206
global_step: 16917, epoch: 23, loss: 1.237343
global_step: 16918, epoch: 23, loss: 1.368116
global_step: 16919, epoch: 23, loss: 1.326349
global_step: 16920, epoch: 23, loss: 1.594222
epoch: 23
train	acc: 0.6162	macro: p 0.4342, r 0.3154, f1: 0.3164	micro: p 0.6162, r 0.6162, f1 0.6162	weighted_f1:0.5585
dev	acc: 0.5437	macro: p 0.3742, r 0.2876, f1: 0.2646	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4656
test	acc: 0.5858	macro: p 0.3755, r 0.2889, f1: 0.2756	micro: p 0.5858, r 0.5858, f1 0.5858	weighted_f1:0.5192
New best model!
global_step: 16921, epoch: 24, loss: 1.125742
global_step: 16922, epoch: 24, loss: 1.182824
global_step: 16923, epoch: 24, loss: 1.123683
global_step: 16924, epoch: 24, loss: 1.166872
global_step: 16925, epoch: 24, loss: 1.261097
global_step: 16926, epoch: 24, loss: 1.200275
global_step: 16927, epoch: 24, loss: 1.249609
global_step: 16928, epoch: 24, loss: 1.390283
global_step: 16929, epoch: 24, loss: 1.203771
global_step: 16930, epoch: 24, loss: 1.263609
global_step: 16931, epoch: 24, loss: 1.282442
global_step: 16932, epoch: 24, loss: 1.177340
global_step: 16933, epoch: 24, loss: 1.312608
global_step: 16934, epoch: 24, loss: 1.219712
global_step: 16935, epoch: 24, loss: 1.244267
global_step: 16936, epoch: 24, loss: 1.137865
global_step: 16937, epoch: 24, loss: 1.178045
global_step: 16938, epoch: 24, loss: 1.230444
global_step: 16939, epoch: 24, loss: 1.165552
global_step: 16940, epoch: 24, loss: 1.200271
global_step: 16941, epoch: 24, loss: 1.183205
global_step: 16942, epoch: 24, loss: 1.195265
global_step: 16943, epoch: 24, loss: 1.232996
global_step: 16944, epoch: 24, loss: 1.103201
global_step: 16945, epoch: 24, loss: 1.153463
global_step: 16946, epoch: 24, loss: 1.242073
global_step: 16947, epoch: 24, loss: 1.206890
global_step: 16948, epoch: 24, loss: 1.158217
global_step: 16949, epoch: 24, loss: 1.265542
global_step: 16950, epoch: 24, loss: 1.314583
global_step: 16951, epoch: 24, loss: 1.259365
global_step: 16952, epoch: 24, loss: 1.185667
global_step: 16953, epoch: 24, loss: 1.182846
global_step: 16954, epoch: 24, loss: 1.259682
global_step: 16955, epoch: 24, loss: 1.145563
global_step: 16956, epoch: 24, loss: 1.289028
global_step: 16957, epoch: 24, loss: 1.205430
global_step: 16958, epoch: 24, loss: 1.096621
global_step: 16959, epoch: 24, loss: 1.070099
global_step: 16960, epoch: 24, loss: 1.904497
epoch: 24
train	acc: 0.6205	macro: p 0.4431, r 0.3209, f1: 0.3274	micro: p 0.6205, r 0.6205, f1 0.6205	weighted_f1:0.5655
dev	acc: 0.5473	macro: p 0.3896, r 0.2899, f1: 0.2747	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4750
test	acc: 0.5908	macro: p 0.3808, r 0.2914, f1: 0.2873	micro: p 0.5908, r 0.5908, f1 0.5908	weighted_f1:0.5295
New best model!
global_step: 16961, epoch: 25, loss: 1.172966
global_step: 16962, epoch: 25, loss: 1.229910
global_step: 16963, epoch: 25, loss: 1.220496
global_step: 16964, epoch: 25, loss: 1.171753
global_step: 16965, epoch: 25, loss: 1.137617
global_step: 16966, epoch: 25, loss: 1.183404
global_step: 16967, epoch: 25, loss: 1.180000
global_step: 16968, epoch: 25, loss: 1.127930
global_step: 16969, epoch: 25, loss: 1.168085
global_step: 16970, epoch: 25, loss: 1.168253
global_step: 16971, epoch: 25, loss: 1.205414
global_step: 16972, epoch: 25, loss: 1.142045
global_step: 16973, epoch: 25, loss: 1.229640
global_step: 16974, epoch: 25, loss: 1.173259
global_step: 16975, epoch: 25, loss: 1.239537
global_step: 16976, epoch: 25, loss: 1.154376
global_step: 16977, epoch: 25, loss: 1.171506
global_step: 16978, epoch: 25, loss: 1.215153
global_step: 16979, epoch: 25, loss: 1.225894
global_step: 16980, epoch: 25, loss: 1.119469
global_step: 16981, epoch: 25, loss: 1.179025
global_step: 16982, epoch: 25, loss: 1.212786
global_step: 16983, epoch: 25, loss: 1.231447
global_step: 16984, epoch: 25, loss: 1.168972
global_step: 16985, epoch: 25, loss: 1.221435
global_step: 16986, epoch: 25, loss: 1.143544
global_step: 16987, epoch: 25, loss: 1.152054
global_step: 16988, epoch: 25, loss: 1.177275
global_step: 16989, epoch: 25, loss: 1.126350
global_step: 16990, epoch: 25, loss: 1.267991
global_step: 16991, epoch: 25, loss: 1.171243
global_step: 16992, epoch: 25, loss: 1.215396
global_step: 16993, epoch: 25, loss: 1.287798
global_step: 16994, epoch: 25, loss: 1.226095
global_step: 16995, epoch: 25, loss: 1.170700
global_step: 16996, epoch: 25, loss: 1.188173
global_step: 16997, epoch: 25, loss: 1.209857
global_step: 16998, epoch: 25, loss: 1.213748
global_step: 16999, epoch: 25, loss: 1.250664
global_step: 17000, epoch: 25, loss: 1.207898
epoch: 25
train	acc: 0.6225	macro: p 0.4330, r 0.3263, f1: 0.3278	micro: p 0.6225, r 0.6225, f1 0.6225	weighted_f1:0.5677
dev	acc: 0.5410	macro: p 0.3496, r 0.2851, f1: 0.2617	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4626
test	acc: 0.5851	macro: p 0.3631, r 0.2909, f1: 0.2805	micro: p 0.5851, r 0.5851, f1 0.5851	weighted_f1:0.5227
global_step: 17001, epoch: 26, loss: 1.168026
global_step: 17002, epoch: 26, loss: 1.135535
global_step: 17003, epoch: 26, loss: 1.271788
global_step: 17004, epoch: 26, loss: 1.153015
global_step: 17005, epoch: 26, loss: 1.319209
global_step: 17006, epoch: 26, loss: 1.213886
global_step: 17007, epoch: 26, loss: 1.174106
global_step: 17008, epoch: 26, loss: 1.168000
global_step: 17009, epoch: 26, loss: 1.117497
global_step: 17010, epoch: 26, loss: 1.240604
global_step: 17011, epoch: 26, loss: 1.241864
global_step: 17012, epoch: 26, loss: 1.160949
global_step: 17013, epoch: 26, loss: 1.108998
global_step: 17014, epoch: 26, loss: 1.225670
global_step: 17015, epoch: 26, loss: 1.144786
global_step: 17016, epoch: 26, loss: 1.162208
global_step: 17017, epoch: 26, loss: 1.173431
global_step: 17018, epoch: 26, loss: 1.033461
global_step: 17019, epoch: 26, loss: 1.221044
global_step: 17020, epoch: 26, loss: 1.191898
global_step: 17021, epoch: 26, loss: 1.090567
global_step: 17022, epoch: 26, loss: 1.270482
global_step: 17023, epoch: 26, loss: 1.231663
global_step: 17024, epoch: 26, loss: 1.191480
global_step: 17025, epoch: 26, loss: 1.142811
global_step: 17026, epoch: 26, loss: 1.283369
global_step: 17027, epoch: 26, loss: 1.172953
global_step: 17028, epoch: 26, loss: 1.305045
global_step: 17029, epoch: 26, loss: 1.248124
global_step: 17030, epoch: 26, loss: 1.270452
global_step: 17031, epoch: 26, loss: 1.156188
global_step: 17032, epoch: 26, loss: 1.153045
global_step: 17033, epoch: 26, loss: 1.213581
global_step: 17034, epoch: 26, loss: 1.158842
global_step: 17035, epoch: 26, loss: 1.071325
global_step: 17036, epoch: 26, loss: 1.134428
global_step: 17037, epoch: 26, loss: 1.156019
global_step: 17038, epoch: 26, loss: 1.265877
global_step: 17039, epoch: 26, loss: 1.175995
global_step: 17040, epoch: 26, loss: 1.152767
epoch: 26
train	acc: 0.6222	macro: p 0.4430, r 0.3216, f1: 0.3274	micro: p 0.6222, r 0.6222, f1 0.6222	weighted_f1:0.5666
dev	acc: 0.5482	macro: p 0.3724, r 0.2910, f1: 0.2695	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4706
test	acc: 0.5885	macro: p 0.3768, r 0.2900, f1: 0.2808	micro: p 0.5885, r 0.5885, f1 0.5885	weighted_f1:0.5232
global_step: 17041, epoch: 27, loss: 1.211431
global_step: 17042, epoch: 27, loss: 1.195616
global_step: 17043, epoch: 27, loss: 1.193861
global_step: 17044, epoch: 27, loss: 1.151371
global_step: 17045, epoch: 27, loss: 1.118078
global_step: 17046, epoch: 27, loss: 1.079111
global_step: 17047, epoch: 27, loss: 1.181464
global_step: 17048, epoch: 27, loss: 1.248054
global_step: 17049, epoch: 27, loss: 1.189119
global_step: 17050, epoch: 27, loss: 1.217891
global_step: 17051, epoch: 27, loss: 1.151098
global_step: 17052, epoch: 27, loss: 1.155547
global_step: 17053, epoch: 27, loss: 1.166851
global_step: 17054, epoch: 27, loss: 1.218670
global_step: 17055, epoch: 27, loss: 1.096094
global_step: 17056, epoch: 27, loss: 1.183141
global_step: 17057, epoch: 27, loss: 1.189912
global_step: 17058, epoch: 27, loss: 1.132978
global_step: 17059, epoch: 27, loss: 1.166194
global_step: 17060, epoch: 27, loss: 1.160979
global_step: 17061, epoch: 27, loss: 1.218000
global_step: 17062, epoch: 27, loss: 1.170379
global_step: 17063, epoch: 27, loss: 1.187926
global_step: 17064, epoch: 27, loss: 1.068740
global_step: 17065, epoch: 27, loss: 1.139901
global_step: 17066, epoch: 27, loss: 1.182092
global_step: 17067, epoch: 27, loss: 1.354158
global_step: 17068, epoch: 27, loss: 1.140314
global_step: 17069, epoch: 27, loss: 1.162524
global_step: 17070, epoch: 27, loss: 1.250597
global_step: 17071, epoch: 27, loss: 1.212205
global_step: 17072, epoch: 27, loss: 1.215754
global_step: 17073, epoch: 27, loss: 1.273669
global_step: 17074, epoch: 27, loss: 1.259873
global_step: 17075, epoch: 27, loss: 1.146266
global_step: 17076, epoch: 27, loss: 1.156531
global_step: 17077, epoch: 27, loss: 1.195088
global_step: 17078, epoch: 27, loss: 1.163719
global_step: 17079, epoch: 27, loss: 1.056846
global_step: 17080, epoch: 27, loss: 0.422545
epoch: 27
train	acc: 0.6251	macro: p 0.4482, r 0.3241, f1: 0.3301	micro: p 0.6251, r 0.6251, f1 0.6251	weighted_f1:0.5691
dev	acc: 0.5455	macro: p 0.3854, r 0.2887, f1: 0.2692	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4688
test	acc: 0.5881	macro: p 0.3759, r 0.2897, f1: 0.2818	micro: p 0.5881, r 0.5881, f1 0.5881	weighted_f1:0.5237
global_step: 17081, epoch: 28, loss: 1.075394
global_step: 17082, epoch: 28, loss: 1.195839
global_step: 17083, epoch: 28, loss: 0.965723
global_step: 17084, epoch: 28, loss: 1.153798
global_step: 17085, epoch: 28, loss: 1.138625
global_step: 17086, epoch: 28, loss: 1.157425
global_step: 17087, epoch: 28, loss: 1.148276
global_step: 17088, epoch: 28, loss: 1.232583
global_step: 17089, epoch: 28, loss: 1.138022
global_step: 17090, epoch: 28, loss: 1.233227
global_step: 17091, epoch: 28, loss: 1.282319
global_step: 17092, epoch: 28, loss: 1.062378
global_step: 17093, epoch: 28, loss: 1.328833
global_step: 17094, epoch: 28, loss: 1.169746
global_step: 17095, epoch: 28, loss: 1.279225
global_step: 17096, epoch: 28, loss: 1.279341
global_step: 17097, epoch: 28, loss: 1.163365
global_step: 17098, epoch: 28, loss: 1.206869
global_step: 17099, epoch: 28, loss: 1.085097
global_step: 17100, epoch: 28, loss: 1.190144
global_step: 17101, epoch: 28, loss: 1.229843
global_step: 17102, epoch: 28, loss: 1.207463
global_step: 17103, epoch: 28, loss: 1.041283
global_step: 17104, epoch: 28, loss: 1.117306
global_step: 17105, epoch: 28, loss: 1.132945
global_step: 17106, epoch: 28, loss: 1.069590
global_step: 17107, epoch: 28, loss: 1.253189
global_step: 17108, epoch: 28, loss: 1.090017
global_step: 17109, epoch: 28, loss: 1.168880
global_step: 17110, epoch: 28, loss: 1.196931
global_step: 17111, epoch: 28, loss: 1.134928
global_step: 17112, epoch: 28, loss: 1.108076
global_step: 17113, epoch: 28, loss: 1.082244
global_step: 17114, epoch: 28, loss: 1.109266
global_step: 17115, epoch: 28, loss: 1.273272
global_step: 17116, epoch: 28, loss: 1.230251
global_step: 17117, epoch: 28, loss: 1.127341
global_step: 17118, epoch: 28, loss: 1.252117
global_step: 17119, epoch: 28, loss: 1.208592
global_step: 17120, epoch: 28, loss: 0.922736
epoch: 28
train	acc: 0.6290	macro: p 0.4426, r 0.3296, f1: 0.3385	micro: p 0.6290, r 0.6290, f1 0.6290	weighted_f1:0.5759
dev	acc: 0.5464	macro: p 0.3677, r 0.2889, f1: 0.2723	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4731
test	acc: 0.5916	macro: p 0.3889, r 0.2924, f1: 0.2890	micro: p 0.5916, r 0.5916, f1 0.5916	weighted_f1:0.5303
global_step: 17121, epoch: 29, loss: 1.154725
global_step: 17122, epoch: 29, loss: 1.093802
global_step: 17123, epoch: 29, loss: 1.244402
global_step: 17124, epoch: 29, loss: 1.096101
global_step: 17125, epoch: 29, loss: 1.247243
global_step: 17126, epoch: 29, loss: 1.241461
global_step: 17127, epoch: 29, loss: 1.081056
global_step: 17128, epoch: 29, loss: 1.129969
global_step: 17129, epoch: 29, loss: 1.083539
global_step: 17130, epoch: 29, loss: 1.038062
global_step: 17131, epoch: 29, loss: 1.195479
global_step: 17132, epoch: 29, loss: 1.148532
global_step: 17133, epoch: 29, loss: 1.232948
global_step: 17134, epoch: 29, loss: 1.189848
global_step: 17135, epoch: 29, loss: 1.181426
global_step: 17136, epoch: 29, loss: 1.278622
global_step: 17137, epoch: 29, loss: 1.278155
global_step: 17138, epoch: 29, loss: 1.128500
global_step: 17139, epoch: 29, loss: 1.121911
global_step: 17140, epoch: 29, loss: 1.148886
global_step: 17141, epoch: 29, loss: 1.220629
global_step: 17142, epoch: 29, loss: 1.170539
global_step: 17143, epoch: 29, loss: 1.298221
global_step: 17144, epoch: 29, loss: 1.200414
global_step: 17145, epoch: 29, loss: 1.099832
global_step: 17146, epoch: 29, loss: 1.076828
global_step: 17147, epoch: 29, loss: 1.226857
global_step: 17148, epoch: 29, loss: 1.080040
global_step: 17149, epoch: 29, loss: 1.125741
global_step: 17150, epoch: 29, loss: 1.174766
global_step: 17151, epoch: 29, loss: 1.076548
global_step: 17152, epoch: 29, loss: 1.039651
global_step: 17153, epoch: 29, loss: 1.168689
global_step: 17154, epoch: 29, loss: 1.264457
global_step: 17155, epoch: 29, loss: 1.163245
global_step: 17156, epoch: 29, loss: 1.118040
global_step: 17157, epoch: 29, loss: 1.353580
global_step: 17158, epoch: 29, loss: 1.073338
global_step: 17159, epoch: 29, loss: 1.085595
global_step: 17160, epoch: 29, loss: 0.821085
epoch: 29
train	acc: 0.6343	macro: p 0.4465, r 0.3362, f1: 0.3451	micro: p 0.6343, r 0.6343, f1 0.6343	weighted_f1:0.5823
dev	acc: 0.5446	macro: p 0.3710, r 0.2882, f1: 0.2732	micro: p 0.5446, r 0.5446, f1 0.5446	weighted_f1:0.4728
test	acc: 0.5912	macro: p 0.3768, r 0.2931, f1: 0.2883	micro: p 0.5912, r 0.5912, f1 0.5912	weighted_f1:0.5301
global_step: 17161, epoch: 30, loss: 1.079628
global_step: 17162, epoch: 30, loss: 1.152329
global_step: 17163, epoch: 30, loss: 1.081131
global_step: 17164, epoch: 30, loss: 1.171269
global_step: 17165, epoch: 30, loss: 1.160402
global_step: 17166, epoch: 30, loss: 1.122471
global_step: 17167, epoch: 30, loss: 1.055656
global_step: 17168, epoch: 30, loss: 1.174236
global_step: 17169, epoch: 30, loss: 1.121133
global_step: 17170, epoch: 30, loss: 1.092257
global_step: 17171, epoch: 30, loss: 1.152432
global_step: 17172, epoch: 30, loss: 1.163519
global_step: 17173, epoch: 30, loss: 1.096222
global_step: 17174, epoch: 30, loss: 1.225160
global_step: 17175, epoch: 30, loss: 1.126743
global_step: 17176, epoch: 30, loss: 1.266606
global_step: 17177, epoch: 30, loss: 1.064258
global_step: 17178, epoch: 30, loss: 1.255578
global_step: 17179, epoch: 30, loss: 1.150974
global_step: 17180, epoch: 30, loss: 1.219240
global_step: 17181, epoch: 30, loss: 1.085957
global_step: 17182, epoch: 30, loss: 1.166758
global_step: 17183, epoch: 30, loss: 1.119694
global_step: 17184, epoch: 30, loss: 1.201181
global_step: 17185, epoch: 30, loss: 1.234188
global_step: 17186, epoch: 30, loss: 1.269749
global_step: 17187, epoch: 30, loss: 1.145249
global_step: 17188, epoch: 30, loss: 1.215497
global_step: 17189, epoch: 30, loss: 1.234963
global_step: 17190, epoch: 30, loss: 1.096693
global_step: 17191, epoch: 30, loss: 1.105312
global_step: 17192, epoch: 30, loss: 1.131790
global_step: 17193, epoch: 30, loss: 1.063783
global_step: 17194, epoch: 30, loss: 1.229757
global_step: 17195, epoch: 30, loss: 1.197217
global_step: 17196, epoch: 30, loss: 1.136454
global_step: 17197, epoch: 30, loss: 1.106472
global_step: 17198, epoch: 30, loss: 1.312458
global_step: 17199, epoch: 30, loss: 1.068288
global_step: 17200, epoch: 30, loss: 0.802505
epoch: 30
train	acc: 0.6378	macro: p 0.4471, r 0.3422, f1: 0.3514	micro: p 0.6378, r 0.6378, f1 0.6378	weighted_f1:0.5879
dev	acc: 0.5537	macro: p 0.3620, r 0.2988, f1: 0.2913	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4902
test	acc: 0.5939	macro: p 0.3864, r 0.2964, f1: 0.2959	micro: p 0.5939, r 0.5939, f1 0.5939	weighted_f1:0.5369
New best model!
global_step: 17201, epoch: 31, loss: 1.042058
global_step: 17202, epoch: 31, loss: 1.107173
global_step: 17203, epoch: 31, loss: 1.181718
global_step: 17204, epoch: 31, loss: 1.339870
global_step: 17205, epoch: 31, loss: 1.171283
global_step: 17206, epoch: 31, loss: 1.247075
global_step: 17207, epoch: 31, loss: 1.282276
global_step: 17208, epoch: 31, loss: 1.245874
global_step: 17209, epoch: 31, loss: 1.102104
global_step: 17210, epoch: 31, loss: 1.130878
global_step: 17211, epoch: 31, loss: 1.220463
global_step: 17212, epoch: 31, loss: 1.195946
global_step: 17213, epoch: 31, loss: 1.104226
global_step: 17214, epoch: 31, loss: 1.174164
global_step: 17215, epoch: 31, loss: 1.120274
global_step: 17216, epoch: 31, loss: 1.136833
global_step: 17217, epoch: 31, loss: 1.126646
global_step: 17218, epoch: 31, loss: 1.139817
global_step: 17219, epoch: 31, loss: 1.112539
global_step: 17220, epoch: 31, loss: 1.034317
global_step: 17221, epoch: 31, loss: 1.125198
global_step: 17222, epoch: 31, loss: 1.121065
global_step: 17223, epoch: 31, loss: 1.120545
global_step: 17224, epoch: 31, loss: 1.149563
global_step: 17225, epoch: 31, loss: 1.035996
global_step: 17226, epoch: 31, loss: 1.131924
global_step: 17227, epoch: 31, loss: 1.017648
global_step: 17228, epoch: 31, loss: 1.084442
global_step: 17229, epoch: 31, loss: 1.031213
global_step: 17230, epoch: 31, loss: 1.151098
global_step: 17231, epoch: 31, loss: 1.106041
global_step: 17232, epoch: 31, loss: 1.170340
global_step: 17233, epoch: 31, loss: 1.139288
global_step: 17234, epoch: 31, loss: 1.176295
global_step: 17235, epoch: 31, loss: 1.102262
global_step: 17236, epoch: 31, loss: 1.069235
global_step: 17237, epoch: 31, loss: 1.089341
global_step: 17238, epoch: 31, loss: 1.087126
global_step: 17239, epoch: 31, loss: 1.189726
global_step: 17240, epoch: 31, loss: 0.541619
epoch: 31
train	acc: 0.6420	macro: p 0.4502, r 0.3466, f1: 0.3574	micro: p 0.6420, r 0.6420, f1 0.6420	weighted_f1:0.5924
dev	acc: 0.5473	macro: p 0.3474, r 0.2922, f1: 0.2803	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.4790
test	acc: 0.5943	macro: p 0.3777, r 0.2993, f1: 0.2983	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5367
global_step: 17241, epoch: 32, loss: 1.077142
global_step: 17242, epoch: 32, loss: 1.178380
global_step: 17243, epoch: 32, loss: 1.218609
global_step: 17244, epoch: 32, loss: 1.089990
global_step: 17245, epoch: 32, loss: 1.172437
global_step: 17246, epoch: 32, loss: 1.072744
global_step: 17247, epoch: 32, loss: 1.121071
global_step: 17248, epoch: 32, loss: 1.049091
global_step: 17249, epoch: 32, loss: 1.161006
global_step: 17250, epoch: 32, loss: 1.071936
global_step: 17251, epoch: 32, loss: 1.151979
global_step: 17252, epoch: 32, loss: 1.074197
global_step: 17253, epoch: 32, loss: 1.160799
global_step: 17254, epoch: 32, loss: 1.247576
global_step: 17255, epoch: 32, loss: 1.102188
global_step: 17256, epoch: 32, loss: 1.142138
global_step: 17257, epoch: 32, loss: 1.289646
global_step: 17258, epoch: 32, loss: 1.150473
global_step: 17259, epoch: 32, loss: 1.162651
global_step: 17260, epoch: 32, loss: 1.049522
global_step: 17261, epoch: 32, loss: 1.109220
global_step: 17262, epoch: 32, loss: 1.015992
global_step: 17263, epoch: 32, loss: 1.088351
global_step: 17264, epoch: 32, loss: 1.166817
global_step: 17265, epoch: 32, loss: 1.131867
global_step: 17266, epoch: 32, loss: 1.156962
global_step: 17267, epoch: 32, loss: 1.046344
global_step: 17268, epoch: 32, loss: 1.221691
global_step: 17269, epoch: 32, loss: 1.068216
global_step: 17270, epoch: 32, loss: 1.155214
global_step: 17271, epoch: 32, loss: 1.110345
global_step: 17272, epoch: 32, loss: 1.135178
global_step: 17273, epoch: 32, loss: 1.110548
global_step: 17274, epoch: 32, loss: 1.116805
global_step: 17275, epoch: 32, loss: 1.088292
global_step: 17276, epoch: 32, loss: 1.104356
global_step: 17277, epoch: 32, loss: 1.161682
global_step: 17278, epoch: 32, loss: 1.155337
global_step: 17279, epoch: 32, loss: 1.090314
global_step: 17280, epoch: 32, loss: 1.339258
epoch: 32
train	acc: 0.6467	macro: p 0.4518, r 0.3538, f1: 0.3638	micro: p 0.6467, r 0.6467, f1 0.6467	weighted_f1:0.5995
dev	acc: 0.5500	macro: p 0.3471, r 0.2965, f1: 0.2841	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4844
test	acc: 0.5950	macro: p 0.3700, r 0.3008, f1: 0.2987	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5393
global_step: 17281, epoch: 33, loss: 1.106491
global_step: 17282, epoch: 33, loss: 1.047458
global_step: 17283, epoch: 33, loss: 1.181764
global_step: 17284, epoch: 33, loss: 1.111037
global_step: 17285, epoch: 33, loss: 1.175448
global_step: 17286, epoch: 33, loss: 1.102017
global_step: 17287, epoch: 33, loss: 1.220472
global_step: 17288, epoch: 33, loss: 1.096593
global_step: 17289, epoch: 33, loss: 1.038585
global_step: 17290, epoch: 33, loss: 1.023656
global_step: 17291, epoch: 33, loss: 1.239477
global_step: 17292, epoch: 33, loss: 1.107941
global_step: 17293, epoch: 33, loss: 1.230103
global_step: 17294, epoch: 33, loss: 1.049528
global_step: 17295, epoch: 33, loss: 1.121928
global_step: 17296, epoch: 33, loss: 1.093649
global_step: 17297, epoch: 33, loss: 1.169215
global_step: 17298, epoch: 33, loss: 1.132344
global_step: 17299, epoch: 33, loss: 1.080017
global_step: 17300, epoch: 33, loss: 1.097231
global_step: 17301, epoch: 33, loss: 1.158140
global_step: 17302, epoch: 33, loss: 1.027401
global_step: 17303, epoch: 33, loss: 1.121662
global_step: 17304, epoch: 33, loss: 1.033507
global_step: 17305, epoch: 33, loss: 1.128252
global_step: 17306, epoch: 33, loss: 1.324196
global_step: 17307, epoch: 33, loss: 1.147950
global_step: 17308, epoch: 33, loss: 1.064905
global_step: 17309, epoch: 33, loss: 1.181519
global_step: 17310, epoch: 33, loss: 1.035455
global_step: 17311, epoch: 33, loss: 1.179927
global_step: 17312, epoch: 33, loss: 1.124332
global_step: 17313, epoch: 33, loss: 1.109039
global_step: 17314, epoch: 33, loss: 1.172976
global_step: 17315, epoch: 33, loss: 1.135857
global_step: 17316, epoch: 33, loss: 1.211455
global_step: 17317, epoch: 33, loss: 1.131493
global_step: 17318, epoch: 33, loss: 1.092463
global_step: 17319, epoch: 33, loss: 1.211750
global_step: 17320, epoch: 33, loss: 1.179941
epoch: 33
train	acc: 0.6490	macro: p 0.4557, r 0.3549, f1: 0.3666	micro: p 0.6490, r 0.6490, f1 0.6490	weighted_f1:0.6014
dev	acc: 0.5500	macro: p 0.3464, r 0.2944, f1: 0.2844	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4843
test	acc: 0.5958	macro: p 0.3767, r 0.3002, f1: 0.3013	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5406
global_step: 17321, epoch: 34, loss: 1.153906
global_step: 17322, epoch: 34, loss: 1.171662
global_step: 17323, epoch: 34, loss: 1.118861
global_step: 17324, epoch: 34, loss: 1.116124
global_step: 17325, epoch: 34, loss: 1.145154
global_step: 17326, epoch: 34, loss: 1.095573
global_step: 17327, epoch: 34, loss: 1.009531
global_step: 17328, epoch: 34, loss: 1.133759
global_step: 17329, epoch: 34, loss: 1.172039
global_step: 17330, epoch: 34, loss: 1.137837
global_step: 17331, epoch: 34, loss: 1.153748
global_step: 17332, epoch: 34, loss: 1.023928
global_step: 17333, epoch: 34, loss: 1.179914
global_step: 17334, epoch: 34, loss: 1.065947
global_step: 17335, epoch: 34, loss: 1.118628
global_step: 17336, epoch: 34, loss: 1.121351
global_step: 17337, epoch: 34, loss: 1.109068
global_step: 17338, epoch: 34, loss: 1.055527
global_step: 17339, epoch: 34, loss: 1.057249
global_step: 17340, epoch: 34, loss: 1.229934
global_step: 17341, epoch: 34, loss: 1.103683
global_step: 17342, epoch: 34, loss: 1.111707
global_step: 17343, epoch: 34, loss: 1.092141
global_step: 17344, epoch: 34, loss: 1.161693
global_step: 17345, epoch: 34, loss: 1.146020
global_step: 17346, epoch: 34, loss: 1.174532
global_step: 17347, epoch: 34, loss: 1.124081
global_step: 17348, epoch: 34, loss: 1.152386
global_step: 17349, epoch: 34, loss: 1.071130
global_step: 17350, epoch: 34, loss: 1.117101
global_step: 17351, epoch: 34, loss: 1.100256
global_step: 17352, epoch: 34, loss: 1.069067
global_step: 17353, epoch: 34, loss: 1.002384
global_step: 17354, epoch: 34, loss: 1.128302
global_step: 17355, epoch: 34, loss: 1.114773
global_step: 17356, epoch: 34, loss: 1.116117
global_step: 17357, epoch: 34, loss: 1.210461
global_step: 17358, epoch: 34, loss: 1.122435
global_step: 17359, epoch: 34, loss: 1.208042
global_step: 17360, epoch: 34, loss: 1.165940
epoch: 34
train	acc: 0.6525	macro: p 0.4532, r 0.3595, f1: 0.3710	micro: p 0.6525, r 0.6525, f1 0.6525	weighted_f1:0.6056
dev	acc: 0.5518	macro: p 0.3443, r 0.2978, f1: 0.2839	micro: p 0.5518, r 0.5518, f1 0.5518	weighted_f1:0.4840
test	acc: 0.5969	macro: p 0.3777, r 0.3043, f1: 0.3025	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5411
global_step: 17361, epoch: 35, loss: 1.183089
global_step: 17362, epoch: 35, loss: 1.027621
global_step: 17363, epoch: 35, loss: 1.071727
global_step: 17364, epoch: 35, loss: 1.081499
global_step: 17365, epoch: 35, loss: 1.058818
global_step: 17366, epoch: 35, loss: 1.132215
global_step: 17367, epoch: 35, loss: 1.205697
global_step: 17368, epoch: 35, loss: 1.085097
global_step: 17369, epoch: 35, loss: 1.151441
global_step: 17370, epoch: 35, loss: 1.039499
global_step: 17371, epoch: 35, loss: 1.138905
global_step: 17372, epoch: 35, loss: 1.141916
global_step: 17373, epoch: 35, loss: 1.142283
global_step: 17374, epoch: 35, loss: 1.176924
global_step: 17375, epoch: 35, loss: 1.134893
global_step: 17376, epoch: 35, loss: 1.245022
global_step: 17377, epoch: 35, loss: 1.122221
global_step: 17378, epoch: 35, loss: 1.052342
global_step: 17379, epoch: 35, loss: 1.089953
global_step: 17380, epoch: 35, loss: 1.060298
global_step: 17381, epoch: 35, loss: 1.114923
global_step: 17382, epoch: 35, loss: 1.083513
global_step: 17383, epoch: 35, loss: 1.132233
global_step: 17384, epoch: 35, loss: 1.110483
global_step: 17385, epoch: 35, loss: 1.070385
global_step: 17386, epoch: 35, loss: 0.994645
global_step: 17387, epoch: 35, loss: 1.199508
global_step: 17388, epoch: 35, loss: 1.067733
global_step: 17389, epoch: 35, loss: 1.093900
global_step: 17390, epoch: 35, loss: 1.057067
global_step: 17391, epoch: 35, loss: 1.215016
global_step: 17392, epoch: 35, loss: 1.109390
global_step: 17393, epoch: 35, loss: 1.107684
global_step: 17394, epoch: 35, loss: 1.063181
global_step: 17395, epoch: 35, loss: 1.161535
global_step: 17396, epoch: 35, loss: 1.136058
global_step: 17397, epoch: 35, loss: 1.140522
global_step: 17398, epoch: 35, loss: 1.090365
global_step: 17399, epoch: 35, loss: 0.965930
global_step: 17400, epoch: 35, loss: 1.435950
epoch: 35
train	acc: 0.6556	macro: p 0.4587, r 0.3627, f1: 0.3735	micro: p 0.6556, r 0.6556, f1 0.6556	weighted_f1:0.6087
dev	acc: 0.5537	macro: p 0.3484, r 0.3003, f1: 0.2856	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4856
test	acc: 0.5954	macro: p 0.3722, r 0.3025, f1: 0.2988	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5380
global_step: 17401, epoch: 36, loss: 1.151677
global_step: 17402, epoch: 36, loss: 1.146359
global_step: 17403, epoch: 36, loss: 1.155576
global_step: 17404, epoch: 36, loss: 1.131414
global_step: 17405, epoch: 36, loss: 1.069645
global_step: 17406, epoch: 36, loss: 1.225859
global_step: 17407, epoch: 36, loss: 1.007413
global_step: 17408, epoch: 36, loss: 1.059367
global_step: 17409, epoch: 36, loss: 1.179477
global_step: 17410, epoch: 36, loss: 1.078179
global_step: 17411, epoch: 36, loss: 1.131179
global_step: 17412, epoch: 36, loss: 1.168583
global_step: 17413, epoch: 36, loss: 1.049032
global_step: 17414, epoch: 36, loss: 1.163684
global_step: 17415, epoch: 36, loss: 1.075690
global_step: 17416, epoch: 36, loss: 1.018625
global_step: 17417, epoch: 36, loss: 1.124990
global_step: 17418, epoch: 36, loss: 1.071355
global_step: 17419, epoch: 36, loss: 0.977578
global_step: 17420, epoch: 36, loss: 0.971090
global_step: 17421, epoch: 36, loss: 1.150993
global_step: 17422, epoch: 36, loss: 1.102878
global_step: 17423, epoch: 36, loss: 1.053247
global_step: 17424, epoch: 36, loss: 1.076402
global_step: 17425, epoch: 36, loss: 1.091605
global_step: 17426, epoch: 36, loss: 1.118582
global_step: 17427, epoch: 36, loss: 1.149716
global_step: 17428, epoch: 36, loss: 1.230331
global_step: 17429, epoch: 36, loss: 1.072876
global_step: 17430, epoch: 36, loss: 1.030082
global_step: 17431, epoch: 36, loss: 1.076628
global_step: 17432, epoch: 36, loss: 1.083282
global_step: 17433, epoch: 36, loss: 1.052594
global_step: 17434, epoch: 36, loss: 1.024102
global_step: 17435, epoch: 36, loss: 1.100895
global_step: 17436, epoch: 36, loss: 1.114258
global_step: 17437, epoch: 36, loss: 1.105548
global_step: 17438, epoch: 36, loss: 1.183081
global_step: 17439, epoch: 36, loss: 1.073427
global_step: 17440, epoch: 36, loss: 0.904913
epoch: 36
train	acc: 0.6588	macro: p 0.4623, r 0.3672, f1: 0.3772	micro: p 0.6588, r 0.6588, f1 0.6588	weighted_f1:0.6118
dev	acc: 0.5500	macro: p 0.3471, r 0.2970, f1: 0.2834	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4826
test	acc: 0.5954	macro: p 0.3784, r 0.3031, f1: 0.3010	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5391
global_step: 17441, epoch: 37, loss: 1.057995
global_step: 17442, epoch: 37, loss: 1.072238
global_step: 17443, epoch: 37, loss: 1.112302
global_step: 17444, epoch: 37, loss: 1.050518
global_step: 17445, epoch: 37, loss: 1.138561
global_step: 17446, epoch: 37, loss: 1.111991
global_step: 17447, epoch: 37, loss: 1.000789
global_step: 17448, epoch: 37, loss: 1.075333
global_step: 17449, epoch: 37, loss: 1.011523
global_step: 17450, epoch: 37, loss: 1.162038
global_step: 17451, epoch: 37, loss: 1.116904
global_step: 17452, epoch: 37, loss: 1.035851
global_step: 17453, epoch: 37, loss: 1.167993
global_step: 17454, epoch: 37, loss: 1.125714
global_step: 17455, epoch: 37, loss: 1.039590
global_step: 17456, epoch: 37, loss: 1.070752
global_step: 17457, epoch: 37, loss: 1.099741
global_step: 17458, epoch: 37, loss: 1.157549
global_step: 17459, epoch: 37, loss: 1.016444
global_step: 17460, epoch: 37, loss: 1.046585
global_step: 17461, epoch: 37, loss: 1.125732
global_step: 17462, epoch: 37, loss: 1.149773
global_step: 17463, epoch: 37, loss: 1.164913
global_step: 17464, epoch: 37, loss: 0.961869
global_step: 17465, epoch: 37, loss: 0.950401
global_step: 17466, epoch: 37, loss: 1.116817
global_step: 17467, epoch: 37, loss: 1.123505
global_step: 17468, epoch: 37, loss: 1.185675
global_step: 17469, epoch: 37, loss: 1.136087
global_step: 17470, epoch: 37, loss: 0.999801
global_step: 17471, epoch: 37, loss: 1.156619
global_step: 17472, epoch: 37, loss: 1.102387
global_step: 17473, epoch: 37, loss: 1.133298
global_step: 17474, epoch: 37, loss: 1.151517
global_step: 17475, epoch: 37, loss: 1.171959
global_step: 17476, epoch: 37, loss: 1.058836
global_step: 17477, epoch: 37, loss: 1.132055
global_step: 17478, epoch: 37, loss: 1.145087
global_step: 17479, epoch: 37, loss: 1.078880
global_step: 17480, epoch: 37, loss: 0.469289
epoch: 37
train	acc: 0.6619	macro: p 0.4593, r 0.3703, f1: 0.3810	micro: p 0.6619, r 0.6619, f1 0.6619	weighted_f1:0.6164
dev	acc: 0.5528	macro: p 0.3460, r 0.2995, f1: 0.2867	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4866
test	acc: 0.5985	macro: p 0.3747, r 0.3059, f1: 0.3049	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5435
global_step: 17481, epoch: 38, loss: 1.003053
global_step: 17482, epoch: 38, loss: 0.965270
global_step: 17483, epoch: 38, loss: 1.060644
global_step: 17484, epoch: 38, loss: 1.031342
global_step: 17485, epoch: 38, loss: 1.037884
global_step: 17486, epoch: 38, loss: 1.065544
global_step: 17487, epoch: 38, loss: 1.124822
global_step: 17488, epoch: 38, loss: 0.956102
global_step: 17489, epoch: 38, loss: 1.045312
global_step: 17490, epoch: 38, loss: 1.217195
global_step: 17491, epoch: 38, loss: 0.982355
global_step: 17492, epoch: 38, loss: 1.075938
global_step: 17493, epoch: 38, loss: 1.036753
global_step: 17494, epoch: 38, loss: 1.113050
global_step: 17495, epoch: 38, loss: 1.212124
global_step: 17496, epoch: 38, loss: 1.066580
global_step: 17497, epoch: 38, loss: 1.065736
global_step: 17498, epoch: 38, loss: 1.088112
global_step: 17499, epoch: 38, loss: 1.049089
global_step: 17500, epoch: 38, loss: 1.075096
global_step: 17501, epoch: 38, loss: 1.042089
global_step: 17502, epoch: 38, loss: 0.988072
global_step: 17503, epoch: 38, loss: 1.194253
global_step: 17504, epoch: 38, loss: 1.148173
global_step: 17505, epoch: 38, loss: 1.061501
global_step: 17506, epoch: 38, loss: 1.071733
global_step: 17507, epoch: 38, loss: 1.135233
global_step: 17508, epoch: 38, loss: 1.038235
global_step: 17509, epoch: 38, loss: 1.116811
global_step: 17510, epoch: 38, loss: 1.163634
global_step: 17511, epoch: 38, loss: 1.012025
global_step: 17512, epoch: 38, loss: 1.180865
global_step: 17513, epoch: 38, loss: 1.081850
global_step: 17514, epoch: 38, loss: 1.199297
global_step: 17515, epoch: 38, loss: 1.228487
global_step: 17516, epoch: 38, loss: 1.139877
global_step: 17517, epoch: 38, loss: 1.067435
global_step: 17518, epoch: 38, loss: 1.203410
global_step: 17519, epoch: 38, loss: 1.193060
global_step: 17520, epoch: 38, loss: 2.352710
epoch: 38
train	acc: 0.6769	macro: p 0.4599, r 0.3916, f1: 0.4003	micro: p 0.6769, r 0.6769, f1 0.6769	weighted_f1:0.6355
dev	acc: 0.5582	macro: p 0.3404, r 0.3089, f1: 0.2958	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4965
test	acc: 0.5992	macro: p 0.3763, r 0.3145, f1: 0.3143	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5499
New best model!
global_step: 17521, epoch: 39, loss: 1.034289
global_step: 17522, epoch: 39, loss: 1.101563
global_step: 17523, epoch: 39, loss: 1.220343
global_step: 17524, epoch: 39, loss: 1.022164
global_step: 17525, epoch: 39, loss: 1.125374
global_step: 17526, epoch: 39, loss: 1.005716
global_step: 17527, epoch: 39, loss: 1.074718
global_step: 17528, epoch: 39, loss: 1.038067
global_step: 17529, epoch: 39, loss: 1.105931
global_step: 17530, epoch: 39, loss: 1.029330
global_step: 17531, epoch: 39, loss: 0.998147
global_step: 17532, epoch: 39, loss: 1.068137
global_step: 17533, epoch: 39, loss: 1.054890
global_step: 17534, epoch: 39, loss: 1.083334
global_step: 17535, epoch: 39, loss: 1.090661
global_step: 17536, epoch: 39, loss: 1.055511
global_step: 17537, epoch: 39, loss: 1.197088
global_step: 17538, epoch: 39, loss: 1.054643
global_step: 17539, epoch: 39, loss: 1.073797
global_step: 17540, epoch: 39, loss: 1.083294
global_step: 17541, epoch: 39, loss: 1.071987
global_step: 17542, epoch: 39, loss: 1.071158
global_step: 17543, epoch: 39, loss: 1.068439
global_step: 17544, epoch: 39, loss: 1.018706
global_step: 17545, epoch: 39, loss: 1.211092
global_step: 17546, epoch: 39, loss: 1.085448
global_step: 17547, epoch: 39, loss: 1.026340
global_step: 17548, epoch: 39, loss: 1.165902
global_step: 17549, epoch: 39, loss: 1.028313
global_step: 17550, epoch: 39, loss: 1.043178
global_step: 17551, epoch: 39, loss: 1.089768
global_step: 17552, epoch: 39, loss: 1.073727
global_step: 17553, epoch: 39, loss: 1.209605
global_step: 17554, epoch: 39, loss: 1.072109
global_step: 17555, epoch: 39, loss: 1.114334
global_step: 17556, epoch: 39, loss: 1.069113
global_step: 17557, epoch: 39, loss: 1.051280
global_step: 17558, epoch: 39, loss: 1.037538
global_step: 17559, epoch: 39, loss: 1.185456
global_step: 17560, epoch: 39, loss: 1.120872
epoch: 39
train	acc: 0.6714	macro: p 0.4647, r 0.3797, f1: 0.3901	micro: p 0.6714, r 0.6714, f1 0.6714	weighted_f1:0.6277
dev	acc: 0.5509	macro: p 0.3366, r 0.2996, f1: 0.2814	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4826
test	acc: 0.5958	macro: p 0.3732, r 0.3054, f1: 0.3020	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5406
global_step: 17561, epoch: 40, loss: 1.001279
global_step: 17562, epoch: 40, loss: 1.080439
global_step: 17563, epoch: 40, loss: 1.133611
global_step: 17564, epoch: 40, loss: 0.999542
global_step: 17565, epoch: 40, loss: 0.979060
global_step: 17566, epoch: 40, loss: 1.127600
global_step: 17567, epoch: 40, loss: 1.152103
global_step: 17568, epoch: 40, loss: 1.068554
global_step: 17569, epoch: 40, loss: 1.142533
global_step: 17570, epoch: 40, loss: 1.091833
global_step: 17571, epoch: 40, loss: 1.116285
global_step: 17572, epoch: 40, loss: 1.040680
global_step: 17573, epoch: 40, loss: 1.041352
global_step: 17574, epoch: 40, loss: 1.101195
global_step: 17575, epoch: 40, loss: 1.180630
global_step: 17576, epoch: 40, loss: 1.049432
global_step: 17577, epoch: 40, loss: 1.090525
global_step: 17578, epoch: 40, loss: 1.008370
global_step: 17579, epoch: 40, loss: 1.102685
global_step: 17580, epoch: 40, loss: 1.042543
global_step: 17581, epoch: 40, loss: 1.173042
global_step: 17582, epoch: 40, loss: 0.999233
global_step: 17583, epoch: 40, loss: 1.045256
global_step: 17584, epoch: 40, loss: 1.021933
global_step: 17585, epoch: 40, loss: 1.022933
global_step: 17586, epoch: 40, loss: 1.067309
global_step: 17587, epoch: 40, loss: 1.074142
global_step: 17588, epoch: 40, loss: 1.103882
global_step: 17589, epoch: 40, loss: 1.217967
global_step: 17590, epoch: 40, loss: 1.007018
global_step: 17591, epoch: 40, loss: 1.050606
global_step: 17592, epoch: 40, loss: 1.114607
global_step: 17593, epoch: 40, loss: 0.999396
global_step: 17594, epoch: 40, loss: 1.003492
global_step: 17595, epoch: 40, loss: 1.091757
global_step: 17596, epoch: 40, loss: 1.076659
global_step: 17597, epoch: 40, loss: 0.969526
global_step: 17598, epoch: 40, loss: 1.050997
global_step: 17599, epoch: 40, loss: 1.035687
global_step: 17600, epoch: 40, loss: 1.077841
epoch: 40
train	acc: 0.6782	macro: p 0.4671, r 0.3898, f1: 0.3978	micro: p 0.6782, r 0.6782, f1 0.6782	weighted_f1:0.6354
dev	acc: 0.5582	macro: p 0.3450, r 0.3063, f1: 0.2942	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4953
test	acc: 0.6000	macro: p 0.3737, r 0.3112, f1: 0.3091	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5481
global_step: 17601, epoch: 41, loss: 1.064269
global_step: 17602, epoch: 41, loss: 1.139399
global_step: 17603, epoch: 41, loss: 1.117357
global_step: 17604, epoch: 41, loss: 1.000828
global_step: 17605, epoch: 41, loss: 1.011787
global_step: 17606, epoch: 41, loss: 1.054119
global_step: 17607, epoch: 41, loss: 0.963571
global_step: 17608, epoch: 41, loss: 1.054119
global_step: 17609, epoch: 41, loss: 1.157537
global_step: 17610, epoch: 41, loss: 1.017144
global_step: 17611, epoch: 41, loss: 1.103843
global_step: 17612, epoch: 41, loss: 0.995875
global_step: 17613, epoch: 41, loss: 1.124714
global_step: 17614, epoch: 41, loss: 1.086912
global_step: 17615, epoch: 41, loss: 1.088873
global_step: 17616, epoch: 41, loss: 1.088987
global_step: 17617, epoch: 41, loss: 1.210325
global_step: 17618, epoch: 41, loss: 1.089159
global_step: 17619, epoch: 41, loss: 1.076986
global_step: 17620, epoch: 41, loss: 1.034777
global_step: 17621, epoch: 41, loss: 1.040171
global_step: 17622, epoch: 41, loss: 1.147021
global_step: 17623, epoch: 41, loss: 1.214368
global_step: 17624, epoch: 41, loss: 1.200010
global_step: 17625, epoch: 41, loss: 1.123768
global_step: 17626, epoch: 41, loss: 1.048688
global_step: 17627, epoch: 41, loss: 0.956299
global_step: 17628, epoch: 41, loss: 1.052707
global_step: 17629, epoch: 41, loss: 1.131577
global_step: 17630, epoch: 41, loss: 1.008273
global_step: 17631, epoch: 41, loss: 0.963418
global_step: 17632, epoch: 41, loss: 1.064916
global_step: 17633, epoch: 41, loss: 1.043337
global_step: 17634, epoch: 41, loss: 1.027762
global_step: 17635, epoch: 41, loss: 0.991935
global_step: 17636, epoch: 41, loss: 1.078285
global_step: 17637, epoch: 41, loss: 0.998505
global_step: 17638, epoch: 41, loss: 1.026631
global_step: 17639, epoch: 41, loss: 1.001088
global_step: 17640, epoch: 41, loss: 1.499371
epoch: 41
train	acc: 0.6722	macro: p 0.4751, r 0.3795, f1: 0.3908	micro: p 0.6722, r 0.6722, f1 0.6722	weighted_f1:0.6273
dev	acc: 0.5573	macro: p 0.3511, r 0.3039, f1: 0.2908	micro: p 0.5573, r 0.5573, f1 0.5573	weighted_f1:0.4912
test	acc: 0.5981	macro: p 0.3790, r 0.3056, f1: 0.3042	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5427
global_step: 17641, epoch: 42, loss: 1.128309
global_step: 17642, epoch: 42, loss: 1.127594
global_step: 17643, epoch: 42, loss: 1.020620
global_step: 17644, epoch: 42, loss: 0.965551
global_step: 17645, epoch: 42, loss: 0.975255
global_step: 17646, epoch: 42, loss: 1.057286
global_step: 17647, epoch: 42, loss: 1.085672
global_step: 17648, epoch: 42, loss: 0.987590
global_step: 17649, epoch: 42, loss: 1.095277
global_step: 17650, epoch: 42, loss: 1.044762
global_step: 17651, epoch: 42, loss: 1.157641
global_step: 17652, epoch: 42, loss: 1.079705
global_step: 17653, epoch: 42, loss: 0.987812
global_step: 17654, epoch: 42, loss: 1.025546
global_step: 17655, epoch: 42, loss: 1.215851
global_step: 17656, epoch: 42, loss: 1.075039
global_step: 17657, epoch: 42, loss: 1.056192
global_step: 17658, epoch: 42, loss: 1.007871
global_step: 17659, epoch: 42, loss: 1.040027
global_step: 17660, epoch: 42, loss: 1.046715
global_step: 17661, epoch: 42, loss: 0.900178
global_step: 17662, epoch: 42, loss: 1.209088
global_step: 17663, epoch: 42, loss: 1.084620
global_step: 17664, epoch: 42, loss: 1.023650
global_step: 17665, epoch: 42, loss: 1.021086
global_step: 17666, epoch: 42, loss: 1.117662
global_step: 17667, epoch: 42, loss: 0.983448
global_step: 17668, epoch: 42, loss: 1.107522
global_step: 17669, epoch: 42, loss: 0.990676
global_step: 17670, epoch: 42, loss: 1.096255
global_step: 17671, epoch: 42, loss: 1.014342
global_step: 17672, epoch: 42, loss: 1.096734
global_step: 17673, epoch: 42, loss: 1.127025
global_step: 17674, epoch: 42, loss: 1.164537
global_step: 17675, epoch: 42, loss: 0.962985
global_step: 17676, epoch: 42, loss: 1.006958
global_step: 17677, epoch: 42, loss: 0.948262
global_step: 17678, epoch: 42, loss: 1.023873
global_step: 17679, epoch: 42, loss: 1.094670
global_step: 17680, epoch: 42, loss: 1.362967
epoch: 42
train	acc: 0.6726	macro: p 0.4675, r 0.3804, f1: 0.3932	micro: p 0.6726, r 0.6726, f1 0.6726	weighted_f1:0.6288
dev	acc: 0.5591	macro: p 0.3493, r 0.3058, f1: 0.2939	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.4946
test	acc: 0.6000	macro: p 0.3812, r 0.3074, f1: 0.3095	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5464
global_step: 17681, epoch: 43, loss: 1.097958
global_step: 17682, epoch: 43, loss: 0.954856
global_step: 17683, epoch: 43, loss: 1.096535
global_step: 17684, epoch: 43, loss: 1.068076
global_step: 17685, epoch: 43, loss: 1.119682
global_step: 17686, epoch: 43, loss: 0.985327
global_step: 17687, epoch: 43, loss: 1.017427
global_step: 17688, epoch: 43, loss: 1.145598
global_step: 17689, epoch: 43, loss: 1.117054
global_step: 17690, epoch: 43, loss: 1.017420
global_step: 17691, epoch: 43, loss: 0.971339
global_step: 17692, epoch: 43, loss: 1.105859
global_step: 17693, epoch: 43, loss: 1.109348
global_step: 17694, epoch: 43, loss: 1.027694
global_step: 17695, epoch: 43, loss: 1.164388
global_step: 17696, epoch: 43, loss: 1.148918
global_step: 17697, epoch: 43, loss: 1.187480
global_step: 17698, epoch: 43, loss: 1.163303
global_step: 17699, epoch: 43, loss: 1.002967
global_step: 17700, epoch: 43, loss: 1.023928
global_step: 17701, epoch: 43, loss: 0.959653
global_step: 17702, epoch: 43, loss: 0.983258
global_step: 17703, epoch: 43, loss: 1.159152
global_step: 17704, epoch: 43, loss: 1.006216
global_step: 17705, epoch: 43, loss: 1.139381
global_step: 17706, epoch: 43, loss: 1.049256
global_step: 17707, epoch: 43, loss: 1.020444
global_step: 17708, epoch: 43, loss: 0.947758
global_step: 17709, epoch: 43, loss: 1.020564
global_step: 17710, epoch: 43, loss: 1.016004
global_step: 17711, epoch: 43, loss: 0.948883
global_step: 17712, epoch: 43, loss: 0.981169
global_step: 17713, epoch: 43, loss: 1.039522
global_step: 17714, epoch: 43, loss: 1.044949
global_step: 17715, epoch: 43, loss: 1.016683
global_step: 17716, epoch: 43, loss: 0.990555
global_step: 17717, epoch: 43, loss: 1.048256
global_step: 17718, epoch: 43, loss: 1.013701
global_step: 17719, epoch: 43, loss: 1.096031
global_step: 17720, epoch: 43, loss: 0.299039
epoch: 43
train	acc: 0.6713	macro: p 0.4787, r 0.3759, f1: 0.3887	micro: p 0.6713, r 0.6713, f1 0.6713	weighted_f1:0.6253
dev	acc: 0.5509	macro: p 0.3450, r 0.2974, f1: 0.2826	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.4825
test	acc: 0.5969	macro: p 0.3827, r 0.3017, f1: 0.2999	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5388
global_step: 17721, epoch: 44, loss: 1.017425
global_step: 17722, epoch: 44, loss: 0.979752
global_step: 17723, epoch: 44, loss: 1.023848
global_step: 17724, epoch: 44, loss: 1.036372
global_step: 17725, epoch: 44, loss: 1.022331
global_step: 17726, epoch: 44, loss: 1.007878
global_step: 17727, epoch: 44, loss: 1.045175
global_step: 17728, epoch: 44, loss: 0.954684
global_step: 17729, epoch: 44, loss: 1.030335
global_step: 17730, epoch: 44, loss: 1.164261
global_step: 17731, epoch: 44, loss: 0.947128
global_step: 17732, epoch: 44, loss: 0.967638
global_step: 17733, epoch: 44, loss: 1.018810
global_step: 17734, epoch: 44, loss: 1.038253
global_step: 17735, epoch: 44, loss: 1.110168
global_step: 17736, epoch: 44, loss: 1.107835
global_step: 17737, epoch: 44, loss: 1.081559
global_step: 17738, epoch: 44, loss: 0.946896
global_step: 17739, epoch: 44, loss: 1.106960
global_step: 17740, epoch: 44, loss: 0.977194
global_step: 17741, epoch: 44, loss: 1.050170
global_step: 17742, epoch: 44, loss: 1.103639
global_step: 17743, epoch: 44, loss: 1.030569
global_step: 17744, epoch: 44, loss: 1.086091
global_step: 17745, epoch: 44, loss: 1.039983
global_step: 17746, epoch: 44, loss: 1.120922
global_step: 17747, epoch: 44, loss: 1.098124
global_step: 17748, epoch: 44, loss: 1.080362
global_step: 17749, epoch: 44, loss: 1.025274
global_step: 17750, epoch: 44, loss: 1.107283
global_step: 17751, epoch: 44, loss: 1.064186
global_step: 17752, epoch: 44, loss: 1.038048
global_step: 17753, epoch: 44, loss: 1.017699
global_step: 17754, epoch: 44, loss: 0.994235
global_step: 17755, epoch: 44, loss: 0.997984
global_step: 17756, epoch: 44, loss: 1.015883
global_step: 17757, epoch: 44, loss: 1.037605
global_step: 17758, epoch: 44, loss: 1.069061
global_step: 17759, epoch: 44, loss: 0.957010
global_step: 17760, epoch: 44, loss: 0.387612
epoch: 44
train	acc: 0.6868	macro: p 0.4781, r 0.3966, f1: 0.4073	micro: p 0.6868, r 0.6868, f1 0.6868	weighted_f1:0.6441
dev	acc: 0.5555	macro: p 0.3442, r 0.3030, f1: 0.2912	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4912
test	acc: 0.5981	macro: p 0.3772, r 0.3073, f1: 0.3077	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5449
global_step: 17761, epoch: 45, loss: 0.962094
global_step: 17762, epoch: 45, loss: 1.011569
global_step: 17763, epoch: 45, loss: 1.101106
global_step: 17764, epoch: 45, loss: 1.088731
global_step: 17765, epoch: 45, loss: 1.055355
global_step: 17766, epoch: 45, loss: 1.024907
global_step: 17767, epoch: 45, loss: 0.997861
global_step: 17768, epoch: 45, loss: 0.992698
global_step: 17769, epoch: 45, loss: 0.958658
global_step: 17770, epoch: 45, loss: 0.972298
global_step: 17771, epoch: 45, loss: 0.993564
global_step: 17772, epoch: 45, loss: 1.008915
global_step: 17773, epoch: 45, loss: 1.130752
global_step: 17774, epoch: 45, loss: 1.004003
global_step: 17775, epoch: 45, loss: 1.070661
global_step: 17776, epoch: 45, loss: 1.128304
global_step: 17777, epoch: 45, loss: 0.988653
global_step: 17778, epoch: 45, loss: 1.001637
global_step: 17779, epoch: 45, loss: 1.042217
global_step: 17780, epoch: 45, loss: 1.069847
global_step: 17781, epoch: 45, loss: 1.068256
global_step: 17782, epoch: 45, loss: 1.025149
global_step: 17783, epoch: 45, loss: 1.089504
global_step: 17784, epoch: 45, loss: 1.042516
global_step: 17785, epoch: 45, loss: 1.087781
global_step: 17786, epoch: 45, loss: 1.140965
global_step: 17787, epoch: 45, loss: 0.920605
global_step: 17788, epoch: 45, loss: 1.059992
global_step: 17789, epoch: 45, loss: 1.123010
global_step: 17790, epoch: 45, loss: 1.021302
global_step: 17791, epoch: 45, loss: 1.146634
global_step: 17792, epoch: 45, loss: 0.983937
global_step: 17793, epoch: 45, loss: 1.016722
global_step: 17794, epoch: 45, loss: 1.098047
global_step: 17795, epoch: 45, loss: 1.014656
global_step: 17796, epoch: 45, loss: 0.988339
global_step: 17797, epoch: 45, loss: 0.987278
global_step: 17798, epoch: 45, loss: 0.920393
global_step: 17799, epoch: 45, loss: 0.999367
global_step: 17800, epoch: 45, loss: 0.815585
epoch: 45
train	acc: 0.6924	macro: p 0.4752, r 0.4093, f1: 0.4172	micro: p 0.6924, r 0.6924, f1 0.6924	weighted_f1:0.6524
dev	acc: 0.5627	macro: p 0.3499, r 0.3130, f1: 0.3050	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5045
test	acc: 0.6034	macro: p 0.3790, r 0.3178, f1: 0.3212	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5562
New best model!
global_step: 17801, epoch: 46, loss: 1.037765
global_step: 17802, epoch: 46, loss: 1.020400
global_step: 17803, epoch: 46, loss: 1.024285
global_step: 17804, epoch: 46, loss: 1.004871
global_step: 17805, epoch: 46, loss: 1.022750
global_step: 17806, epoch: 46, loss: 1.002812
global_step: 17807, epoch: 46, loss: 1.011264
global_step: 17808, epoch: 46, loss: 0.968213
global_step: 17809, epoch: 46, loss: 1.061850
global_step: 17810, epoch: 46, loss: 1.004651
global_step: 17811, epoch: 46, loss: 1.002679
global_step: 17812, epoch: 46, loss: 1.036479
global_step: 17813, epoch: 46, loss: 0.959679
global_step: 17814, epoch: 46, loss: 1.034822
global_step: 17815, epoch: 46, loss: 0.942824
global_step: 17816, epoch: 46, loss: 1.028340
global_step: 17817, epoch: 46, loss: 0.957984
global_step: 17818, epoch: 46, loss: 0.985957
global_step: 17819, epoch: 46, loss: 0.962515
global_step: 17820, epoch: 46, loss: 0.992137
global_step: 17821, epoch: 46, loss: 1.073688
global_step: 17822, epoch: 46, loss: 1.061598
global_step: 17823, epoch: 46, loss: 1.090104
global_step: 17824, epoch: 46, loss: 1.044677
global_step: 17825, epoch: 46, loss: 1.052042
global_step: 17826, epoch: 46, loss: 1.114659
global_step: 17827, epoch: 46, loss: 0.917985
global_step: 17828, epoch: 46, loss: 1.041163
global_step: 17829, epoch: 46, loss: 1.098206
global_step: 17830, epoch: 46, loss: 1.043763
global_step: 17831, epoch: 46, loss: 1.150353
global_step: 17832, epoch: 46, loss: 1.108987
global_step: 17833, epoch: 46, loss: 1.057003
global_step: 17834, epoch: 46, loss: 0.971512
global_step: 17835, epoch: 46, loss: 1.072880
global_step: 17836, epoch: 46, loss: 1.047920
global_step: 17837, epoch: 46, loss: 1.050029
global_step: 17838, epoch: 46, loss: 1.062765
global_step: 17839, epoch: 46, loss: 1.022123
global_step: 17840, epoch: 46, loss: 1.574546
epoch: 46
train	acc: 0.6989	macro: p 0.4819, r 0.4130, f1: 0.4234	micro: p 0.6989, r 0.6989, f1 0.6989	weighted_f1:0.6592
dev	acc: 0.5564	macro: p 0.3439, r 0.3047, f1: 0.2940	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4942
test	acc: 0.5973	macro: p 0.3704, r 0.3098, f1: 0.3105	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5466
global_step: 17841, epoch: 47, loss: 0.838154
global_step: 17842, epoch: 47, loss: 1.016435
global_step: 17843, epoch: 47, loss: 1.129762
global_step: 17844, epoch: 47, loss: 1.085437
global_step: 17845, epoch: 47, loss: 1.012199
global_step: 17846, epoch: 47, loss: 0.909299
global_step: 17847, epoch: 47, loss: 0.960478
global_step: 17848, epoch: 47, loss: 1.015171
global_step: 17849, epoch: 47, loss: 1.022933
global_step: 17850, epoch: 47, loss: 1.103894
global_step: 17851, epoch: 47, loss: 1.002954
global_step: 17852, epoch: 47, loss: 0.964249
global_step: 17853, epoch: 47, loss: 0.988620
global_step: 17854, epoch: 47, loss: 0.927750
global_step: 17855, epoch: 47, loss: 1.085194
global_step: 17856, epoch: 47, loss: 1.015006
global_step: 17857, epoch: 47, loss: 0.924093
global_step: 17858, epoch: 47, loss: 1.083867
global_step: 17859, epoch: 47, loss: 0.968715
global_step: 17860, epoch: 47, loss: 0.990130
global_step: 17861, epoch: 47, loss: 1.027929
global_step: 17862, epoch: 47, loss: 1.091795
global_step: 17863, epoch: 47, loss: 1.039305
global_step: 17864, epoch: 47, loss: 1.028393
global_step: 17865, epoch: 47, loss: 1.038923
global_step: 17866, epoch: 47, loss: 0.904151
global_step: 17867, epoch: 47, loss: 1.142957
global_step: 17868, epoch: 47, loss: 0.941271
global_step: 17869, epoch: 47, loss: 1.064737
global_step: 17870, epoch: 47, loss: 1.021988
global_step: 17871, epoch: 47, loss: 0.867134
global_step: 17872, epoch: 47, loss: 1.034781
global_step: 17873, epoch: 47, loss: 0.975673
global_step: 17874, epoch: 47, loss: 0.957780
global_step: 17875, epoch: 47, loss: 0.933953
global_step: 17876, epoch: 47, loss: 0.995365
global_step: 17877, epoch: 47, loss: 1.030195
global_step: 17878, epoch: 47, loss: 1.056472
global_step: 17879, epoch: 47, loss: 0.956088
global_step: 17880, epoch: 47, loss: 0.460378
epoch: 47
train	acc: 0.6935	macro: p 0.4870, r 0.4039, f1: 0.4151	micro: p 0.6935, r 0.6935, f1 0.6935	weighted_f1:0.6515
dev	acc: 0.5600	macro: p 0.3509, r 0.3073, f1: 0.3001	micro: p 0.5600, r 0.5600, f1 0.5600	weighted_f1:0.4993
test	acc: 0.6042	macro: p 0.3806, r 0.3116, f1: 0.3145	micro: p 0.6042, r 0.6042, f1 0.6042	weighted_f1:0.5524
global_step: 17881, epoch: 48, loss: 0.939266
global_step: 17882, epoch: 48, loss: 1.002834
global_step: 17883, epoch: 48, loss: 1.072129
global_step: 17884, epoch: 48, loss: 1.052973
global_step: 17885, epoch: 48, loss: 0.961408
global_step: 17886, epoch: 48, loss: 0.953987
global_step: 17887, epoch: 48, loss: 0.955454
global_step: 17888, epoch: 48, loss: 1.025159
global_step: 17889, epoch: 48, loss: 1.027349
global_step: 17890, epoch: 48, loss: 0.987866
global_step: 17891, epoch: 48, loss: 1.094356
global_step: 17892, epoch: 48, loss: 0.953220
global_step: 17893, epoch: 48, loss: 1.035167
global_step: 17894, epoch: 48, loss: 0.974720
global_step: 17895, epoch: 48, loss: 0.975543
global_step: 17896, epoch: 48, loss: 1.043581
global_step: 17897, epoch: 48, loss: 1.052394
global_step: 17898, epoch: 48, loss: 1.017118
global_step: 17899, epoch: 48, loss: 0.976080
global_step: 17900, epoch: 48, loss: 1.086329
global_step: 17901, epoch: 48, loss: 1.010630
global_step: 17902, epoch: 48, loss: 1.026145
global_step: 17903, epoch: 48, loss: 0.947224
global_step: 17904, epoch: 48, loss: 0.983779
global_step: 17905, epoch: 48, loss: 0.866194
global_step: 17906, epoch: 48, loss: 1.078191
global_step: 17907, epoch: 48, loss: 1.013068
global_step: 17908, epoch: 48, loss: 1.010967
global_step: 17909, epoch: 48, loss: 1.009704
global_step: 17910, epoch: 48, loss: 1.041637
global_step: 17911, epoch: 48, loss: 1.035430
global_step: 17912, epoch: 48, loss: 1.099718
global_step: 17913, epoch: 48, loss: 0.947355
global_step: 17914, epoch: 48, loss: 0.952756
global_step: 17915, epoch: 48, loss: 1.006953
global_step: 17916, epoch: 48, loss: 1.049392
global_step: 17917, epoch: 48, loss: 1.063722
global_step: 17918, epoch: 48, loss: 0.983274
global_step: 17919, epoch: 48, loss: 1.025584
global_step: 17920, epoch: 48, loss: 0.749057
epoch: 48
train	acc: 0.7065	macro: p 0.4854, r 0.4197, f1: 0.4300	micro: p 0.7065, r 0.7065, f1 0.7065	weighted_f1:0.6675
dev	acc: 0.5564	macro: p 0.3427, r 0.3063, f1: 0.2938	micro: p 0.5564, r 0.5564, f1 0.5564	weighted_f1:0.4941
test	acc: 0.5969	macro: p 0.3698, r 0.3101, f1: 0.3096	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5457
global_step: 17921, epoch: 49, loss: 0.978739
global_step: 17922, epoch: 49, loss: 1.071002
global_step: 17923, epoch: 49, loss: 1.038468
global_step: 17924, epoch: 49, loss: 0.942544
global_step: 17925, epoch: 49, loss: 1.027749
global_step: 17926, epoch: 49, loss: 0.960055
global_step: 17927, epoch: 49, loss: 0.979101
global_step: 17928, epoch: 49, loss: 0.931482
global_step: 17929, epoch: 49, loss: 1.018246
global_step: 17930, epoch: 49, loss: 0.922139
global_step: 17931, epoch: 49, loss: 1.078771
global_step: 17932, epoch: 49, loss: 1.043604
global_step: 17933, epoch: 49, loss: 0.997860
global_step: 17934, epoch: 49, loss: 1.056319
global_step: 17935, epoch: 49, loss: 0.958915
global_step: 17936, epoch: 49, loss: 0.951660
global_step: 17937, epoch: 49, loss: 0.830032
global_step: 17938, epoch: 49, loss: 1.028183
global_step: 17939, epoch: 49, loss: 1.149029
global_step: 17940, epoch: 49, loss: 1.085640
global_step: 17941, epoch: 49, loss: 0.928064
global_step: 17942, epoch: 49, loss: 1.038095
global_step: 17943, epoch: 49, loss: 1.033453
global_step: 17944, epoch: 49, loss: 1.042361
global_step: 17945, epoch: 49, loss: 0.985009
global_step: 17946, epoch: 49, loss: 1.061847
global_step: 17947, epoch: 49, loss: 0.881995
global_step: 17948, epoch: 49, loss: 0.967704
global_step: 17949, epoch: 49, loss: 1.011088
global_step: 17950, epoch: 49, loss: 1.011175
global_step: 17951, epoch: 49, loss: 0.989027
global_step: 17952, epoch: 49, loss: 0.982635
global_step: 17953, epoch: 49, loss: 1.082511
global_step: 17954, epoch: 49, loss: 1.032380
global_step: 17955, epoch: 49, loss: 0.966176
global_step: 17956, epoch: 49, loss: 0.971190
global_step: 17957, epoch: 49, loss: 1.087392
global_step: 17958, epoch: 49, loss: 1.074931
global_step: 17959, epoch: 49, loss: 0.988788
global_step: 17960, epoch: 49, loss: 0.350079
epoch: 49
train	acc: 0.7094	macro: p 0.4892, r 0.4245, f1: 0.4340	micro: p 0.7094, r 0.7094, f1 0.7094	weighted_f1:0.6700
dev	acc: 0.5627	macro: p 0.3428, r 0.3126, f1: 0.3031	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5025
test	acc: 0.5992	macro: p 0.3724, r 0.3129, f1: 0.3146	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5493
global_step: 17961, epoch: 50, loss: 1.065939
global_step: 17962, epoch: 50, loss: 1.041442
global_step: 17963, epoch: 50, loss: 0.995372
global_step: 17964, epoch: 50, loss: 0.952074
global_step: 17965, epoch: 50, loss: 0.980945
global_step: 17966, epoch: 50, loss: 0.977942
global_step: 17967, epoch: 50, loss: 0.961756
global_step: 17968, epoch: 50, loss: 1.025347
global_step: 17969, epoch: 50, loss: 0.921249
global_step: 17970, epoch: 50, loss: 1.005913
global_step: 17971, epoch: 50, loss: 1.040384
global_step: 17972, epoch: 50, loss: 1.041230
global_step: 17973, epoch: 50, loss: 0.934384
global_step: 17974, epoch: 50, loss: 1.055869
global_step: 17975, epoch: 50, loss: 0.895578
global_step: 17976, epoch: 50, loss: 0.996889
global_step: 17977, epoch: 50, loss: 1.053197
global_step: 17978, epoch: 50, loss: 1.007357
global_step: 17979, epoch: 50, loss: 0.908609
global_step: 17980, epoch: 50, loss: 1.016624
global_step: 17981, epoch: 50, loss: 0.947498
global_step: 17982, epoch: 50, loss: 0.971197
global_step: 17983, epoch: 50, loss: 1.008629
global_step: 17984, epoch: 50, loss: 0.989932
global_step: 17985, epoch: 50, loss: 0.983733
global_step: 17986, epoch: 50, loss: 0.976461
global_step: 17987, epoch: 50, loss: 1.018111
global_step: 17988, epoch: 50, loss: 0.985134
global_step: 17989, epoch: 50, loss: 1.028663
global_step: 17990, epoch: 50, loss: 1.013425
global_step: 17991, epoch: 50, loss: 0.887335
global_step: 17992, epoch: 50, loss: 0.983963
global_step: 17993, epoch: 50, loss: 0.866274
global_step: 17994, epoch: 50, loss: 1.058677
global_step: 17995, epoch: 50, loss: 0.949570
global_step: 17996, epoch: 50, loss: 1.040712
global_step: 17997, epoch: 50, loss: 0.966666
global_step: 17998, epoch: 50, loss: 1.012553
global_step: 17999, epoch: 50, loss: 1.060726
global_step: 18000, epoch: 50, loss: 2.083547
epoch: 50
train	acc: 0.7283	macro: p 0.4951, r 0.4532, f1: 0.4601	micro: p 0.7283, r 0.7283, f1 0.7283	weighted_f1:0.6956
dev	acc: 0.5546	macro: p 0.3479, r 0.3135, f1: 0.3018	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4991
test	acc: 0.5958	macro: p 0.3557, r 0.3185, f1: 0.3167	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5511
global_step: 18001, epoch: 51, loss: 0.993543
global_step: 18002, epoch: 51, loss: 0.975786
global_step: 18003, epoch: 51, loss: 1.029068
global_step: 18004, epoch: 51, loss: 1.045361
global_step: 18005, epoch: 51, loss: 0.965512
global_step: 18006, epoch: 51, loss: 0.897416
global_step: 18007, epoch: 51, loss: 1.067906
global_step: 18008, epoch: 51, loss: 0.976518
global_step: 18009, epoch: 51, loss: 0.913247
global_step: 18010, epoch: 51, loss: 0.951453
global_step: 18011, epoch: 51, loss: 1.073167
global_step: 18012, epoch: 51, loss: 1.150421
global_step: 18013, epoch: 51, loss: 1.000753
global_step: 18014, epoch: 51, loss: 0.991527
global_step: 18015, epoch: 51, loss: 0.956769
global_step: 18016, epoch: 51, loss: 0.888454
global_step: 18017, epoch: 51, loss: 0.993056
global_step: 18018, epoch: 51, loss: 0.920474
global_step: 18019, epoch: 51, loss: 1.028040
global_step: 18020, epoch: 51, loss: 1.007027
global_step: 18021, epoch: 51, loss: 0.903387
global_step: 18022, epoch: 51, loss: 0.880446
global_step: 18023, epoch: 51, loss: 0.922382
global_step: 18024, epoch: 51, loss: 0.981962
global_step: 18025, epoch: 51, loss: 1.052320
global_step: 18026, epoch: 51, loss: 0.986505
global_step: 18027, epoch: 51, loss: 0.933642
global_step: 18028, epoch: 51, loss: 1.015403
global_step: 18029, epoch: 51, loss: 0.910498
global_step: 18030, epoch: 51, loss: 0.937925
global_step: 18031, epoch: 51, loss: 0.969010
global_step: 18032, epoch: 51, loss: 1.124322
global_step: 18033, epoch: 51, loss: 1.017412
global_step: 18034, epoch: 51, loss: 0.953609
global_step: 18035, epoch: 51, loss: 1.036023
global_step: 18036, epoch: 51, loss: 1.029672
global_step: 18037, epoch: 51, loss: 0.926382
global_step: 18038, epoch: 51, loss: 1.058679
global_step: 18039, epoch: 51, loss: 1.085082
global_step: 18040, epoch: 51, loss: 1.629985
epoch: 51
train	acc: 0.7243	macro: p 0.4971, r 0.4439, f1: 0.4530	micro: p 0.7243, r 0.7243, f1 0.7243	weighted_f1:0.6895
dev	acc: 0.5546	macro: p 0.3326, r 0.3069, f1: 0.2948	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4951
test	acc: 0.5954	macro: p 0.3631, r 0.3128, f1: 0.3144	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5486
global_step: 18041, epoch: 52, loss: 0.963542
global_step: 18042, epoch: 52, loss: 0.928077
global_step: 18043, epoch: 52, loss: 1.027856
global_step: 18044, epoch: 52, loss: 0.949282
global_step: 18045, epoch: 52, loss: 0.933438
global_step: 18046, epoch: 52, loss: 0.978938
global_step: 18047, epoch: 52, loss: 0.962332
global_step: 18048, epoch: 52, loss: 0.961098
global_step: 18049, epoch: 52, loss: 0.989058
global_step: 18050, epoch: 52, loss: 0.985991
global_step: 18051, epoch: 52, loss: 1.036236
global_step: 18052, epoch: 52, loss: 0.913977
global_step: 18053, epoch: 52, loss: 0.918905
global_step: 18054, epoch: 52, loss: 1.020502
global_step: 18055, epoch: 52, loss: 0.940300
global_step: 18056, epoch: 52, loss: 0.977289
global_step: 18057, epoch: 52, loss: 1.094849
global_step: 18058, epoch: 52, loss: 0.952413
global_step: 18059, epoch: 52, loss: 0.974082
global_step: 18060, epoch: 52, loss: 0.930931
global_step: 18061, epoch: 52, loss: 0.917013
global_step: 18062, epoch: 52, loss: 0.984062
global_step: 18063, epoch: 52, loss: 0.862205
global_step: 18064, epoch: 52, loss: 0.909792
global_step: 18065, epoch: 52, loss: 1.120463
global_step: 18066, epoch: 52, loss: 0.966507
global_step: 18067, epoch: 52, loss: 1.040483
global_step: 18068, epoch: 52, loss: 0.964758
global_step: 18069, epoch: 52, loss: 1.046599
global_step: 18070, epoch: 52, loss: 0.906657
global_step: 18071, epoch: 52, loss: 0.971367
global_step: 18072, epoch: 52, loss: 0.970656
global_step: 18073, epoch: 52, loss: 0.941819
global_step: 18074, epoch: 52, loss: 0.936392
global_step: 18075, epoch: 52, loss: 1.043491
global_step: 18076, epoch: 52, loss: 1.004644
global_step: 18077, epoch: 52, loss: 1.070016
global_step: 18078, epoch: 52, loss: 0.959348
global_step: 18079, epoch: 52, loss: 0.949536
global_step: 18080, epoch: 52, loss: 1.742474
epoch: 52
train	acc: 0.7356	macro: p 0.5032, r 0.4641, f1: 0.4677	micro: p 0.7356, r 0.7356, f1 0.7356	weighted_f1:0.7047
dev	acc: 0.5609	macro: p 0.3445, r 0.3181, f1: 0.3097	micro: p 0.5609, r 0.5609, f1 0.5609	weighted_f1:0.5081
test	acc: 0.6000	macro: p 0.3616, r 0.3229, f1: 0.3238	micro: p 0.6000, r 0.6000, f1 0.6000	weighted_f1:0.5585
New best model!
global_step: 18081, epoch: 53, loss: 0.936662
global_step: 18082, epoch: 53, loss: 1.003359
global_step: 18083, epoch: 53, loss: 0.927483
global_step: 18084, epoch: 53, loss: 0.951402
global_step: 18085, epoch: 53, loss: 0.962905
global_step: 18086, epoch: 53, loss: 0.978736
global_step: 18087, epoch: 53, loss: 0.955176
global_step: 18088, epoch: 53, loss: 0.950525
global_step: 18089, epoch: 53, loss: 0.990540
global_step: 18090, epoch: 53, loss: 1.012906
global_step: 18091, epoch: 53, loss: 1.017222
global_step: 18092, epoch: 53, loss: 0.896555
global_step: 18093, epoch: 53, loss: 0.975604
global_step: 18094, epoch: 53, loss: 0.818550
global_step: 18095, epoch: 53, loss: 0.980644
global_step: 18096, epoch: 53, loss: 0.943098
global_step: 18097, epoch: 53, loss: 0.973444
global_step: 18098, epoch: 53, loss: 0.969288
global_step: 18099, epoch: 53, loss: 1.025841
global_step: 18100, epoch: 53, loss: 0.978594
global_step: 18101, epoch: 53, loss: 1.017664
global_step: 18102, epoch: 53, loss: 0.957767
global_step: 18103, epoch: 53, loss: 1.102661
global_step: 18104, epoch: 53, loss: 0.909232
global_step: 18105, epoch: 53, loss: 0.928304
global_step: 18106, epoch: 53, loss: 1.035516
global_step: 18107, epoch: 53, loss: 0.969441
global_step: 18108, epoch: 53, loss: 0.888131
global_step: 18109, epoch: 53, loss: 0.926690
global_step: 18110, epoch: 53, loss: 0.972733
global_step: 18111, epoch: 53, loss: 0.974295
global_step: 18112, epoch: 53, loss: 1.025708
global_step: 18113, epoch: 53, loss: 1.088342
global_step: 18114, epoch: 53, loss: 1.013431
global_step: 18115, epoch: 53, loss: 0.879212
global_step: 18116, epoch: 53, loss: 0.916825
global_step: 18117, epoch: 53, loss: 1.014184
global_step: 18118, epoch: 53, loss: 0.942655
global_step: 18119, epoch: 53, loss: 0.933603
global_step: 18120, epoch: 53, loss: 0.441216
epoch: 53
train	acc: 0.7110	macro: p 0.5003, r 0.4227, f1: 0.4363	micro: p 0.7110, r 0.7110, f1 0.7110	weighted_f1:0.6714
dev	acc: 0.5582	macro: p 0.3453, r 0.3049, f1: 0.2977	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.4967
test	acc: 0.5996	macro: p 0.3788, r 0.3078, f1: 0.3115	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5475
global_step: 18121, epoch: 54, loss: 0.992224
global_step: 18122, epoch: 54, loss: 0.952155
global_step: 18123, epoch: 54, loss: 0.932178
global_step: 18124, epoch: 54, loss: 0.932636
global_step: 18125, epoch: 54, loss: 0.846953
global_step: 18126, epoch: 54, loss: 1.012319
global_step: 18127, epoch: 54, loss: 1.032936
global_step: 18128, epoch: 54, loss: 0.923846
global_step: 18129, epoch: 54, loss: 0.975493
global_step: 18130, epoch: 54, loss: 0.952268
global_step: 18131, epoch: 54, loss: 1.034348
global_step: 18132, epoch: 54, loss: 0.918350
global_step: 18133, epoch: 54, loss: 0.961854
global_step: 18134, epoch: 54, loss: 1.020048
global_step: 18135, epoch: 54, loss: 0.844933
global_step: 18136, epoch: 54, loss: 0.931763
global_step: 18137, epoch: 54, loss: 0.906397
global_step: 18138, epoch: 54, loss: 0.968049
global_step: 18139, epoch: 54, loss: 0.812200
global_step: 18140, epoch: 54, loss: 1.031072
global_step: 18141, epoch: 54, loss: 1.109035
global_step: 18142, epoch: 54, loss: 1.009112
global_step: 18143, epoch: 54, loss: 0.969992
global_step: 18144, epoch: 54, loss: 0.989365
global_step: 18145, epoch: 54, loss: 0.974888
global_step: 18146, epoch: 54, loss: 1.090818
global_step: 18147, epoch: 54, loss: 1.007246
global_step: 18148, epoch: 54, loss: 0.996614
global_step: 18149, epoch: 54, loss: 0.903604
global_step: 18150, epoch: 54, loss: 0.904559
global_step: 18151, epoch: 54, loss: 1.041119
global_step: 18152, epoch: 54, loss: 0.923441
global_step: 18153, epoch: 54, loss: 1.021632
global_step: 18154, epoch: 54, loss: 0.892117
global_step: 18155, epoch: 54, loss: 0.917981
global_step: 18156, epoch: 54, loss: 0.962505
global_step: 18157, epoch: 54, loss: 1.009500
global_step: 18158, epoch: 54, loss: 0.988152
global_step: 18159, epoch: 54, loss: 0.901917
global_step: 18160, epoch: 54, loss: 1.034653
epoch: 54
train	acc: 0.7388	macro: p 0.5072, r 0.4642, f1: 0.4733	micro: p 0.7388, r 0.7388, f1 0.7388	weighted_f1:0.7075
dev	acc: 0.5627	macro: p 0.3475, r 0.3168, f1: 0.3099	micro: p 0.5627, r 0.5627, f1 0.5627	weighted_f1:0.5084
test	acc: 0.5992	macro: p 0.3596, r 0.3184, f1: 0.3209	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5551
New best model!
global_step: 18161, epoch: 55, loss: 0.978799
global_step: 18162, epoch: 55, loss: 1.036651
global_step: 18163, epoch: 55, loss: 0.944302
global_step: 18164, epoch: 55, loss: 1.035388
global_step: 18165, epoch: 55, loss: 0.900792
global_step: 18166, epoch: 55, loss: 0.897001
global_step: 18167, epoch: 55, loss: 1.072260
global_step: 18168, epoch: 55, loss: 0.810541
global_step: 18169, epoch: 55, loss: 1.021785
global_step: 18170, epoch: 55, loss: 0.924446
global_step: 18171, epoch: 55, loss: 1.014059
global_step: 18172, epoch: 55, loss: 0.867589
global_step: 18173, epoch: 55, loss: 0.926646
global_step: 18174, epoch: 55, loss: 0.970932
global_step: 18175, epoch: 55, loss: 0.913787
global_step: 18176, epoch: 55, loss: 0.955445
global_step: 18177, epoch: 55, loss: 1.001994
global_step: 18178, epoch: 55, loss: 0.965117
global_step: 18179, epoch: 55, loss: 0.880509
global_step: 18180, epoch: 55, loss: 0.928659
global_step: 18181, epoch: 55, loss: 0.824864
global_step: 18182, epoch: 55, loss: 0.936631
global_step: 18183, epoch: 55, loss: 1.045376
global_step: 18184, epoch: 55, loss: 0.902468
global_step: 18185, epoch: 55, loss: 0.936599
global_step: 18186, epoch: 55, loss: 0.935973
global_step: 18187, epoch: 55, loss: 0.904147
global_step: 18188, epoch: 55, loss: 0.992859
global_step: 18189, epoch: 55, loss: 0.921592
global_step: 18190, epoch: 55, loss: 0.877779
global_step: 18191, epoch: 55, loss: 0.919793
global_step: 18192, epoch: 55, loss: 1.033974
global_step: 18193, epoch: 55, loss: 1.007707
global_step: 18194, epoch: 55, loss: 1.005231
global_step: 18195, epoch: 55, loss: 0.933026
global_step: 18196, epoch: 55, loss: 0.953103
global_step: 18197, epoch: 55, loss: 0.906163
global_step: 18198, epoch: 55, loss: 0.968975
global_step: 18199, epoch: 55, loss: 0.939262
global_step: 18200, epoch: 55, loss: 1.266826
epoch: 55
train	acc: 0.7420	macro: p 0.5081, r 0.4668, f1: 0.4759	micro: p 0.7420, r 0.7420, f1 0.7420	weighted_f1:0.7103
dev	acc: 0.5528	macro: p 0.3321, r 0.3074, f1: 0.2968	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4953
test	acc: 0.5966	macro: p 0.3568, r 0.3152, f1: 0.3160	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5508
global_step: 18201, epoch: 56, loss: 0.881209
global_step: 18202, epoch: 56, loss: 1.017149
global_step: 18203, epoch: 56, loss: 0.978497
global_step: 18204, epoch: 56, loss: 0.893572
global_step: 18205, epoch: 56, loss: 1.036109
global_step: 18206, epoch: 56, loss: 0.918400
global_step: 18207, epoch: 56, loss: 0.870647
global_step: 18208, epoch: 56, loss: 0.978397
global_step: 18209, epoch: 56, loss: 0.913160
global_step: 18210, epoch: 56, loss: 0.922327
global_step: 18211, epoch: 56, loss: 0.906938
global_step: 18212, epoch: 56, loss: 0.904204
global_step: 18213, epoch: 56, loss: 0.992048
global_step: 18214, epoch: 56, loss: 0.930851
global_step: 18215, epoch: 56, loss: 0.889761
global_step: 18216, epoch: 56, loss: 1.034548
global_step: 18217, epoch: 56, loss: 0.842990
global_step: 18218, epoch: 56, loss: 1.003095
global_step: 18219, epoch: 56, loss: 0.827278
global_step: 18220, epoch: 56, loss: 0.910315
global_step: 18221, epoch: 56, loss: 0.865303
global_step: 18222, epoch: 56, loss: 1.010108
global_step: 18223, epoch: 56, loss: 0.850831
global_step: 18224, epoch: 56, loss: 0.950427
global_step: 18225, epoch: 56, loss: 0.981124
global_step: 18226, epoch: 56, loss: 0.973405
global_step: 18227, epoch: 56, loss: 0.819692
global_step: 18228, epoch: 56, loss: 1.072951
global_step: 18229, epoch: 56, loss: 1.047779
global_step: 18230, epoch: 56, loss: 0.957397
global_step: 18231, epoch: 56, loss: 0.945551
global_step: 18232, epoch: 56, loss: 0.938718
global_step: 18233, epoch: 56, loss: 0.937970
global_step: 18234, epoch: 56, loss: 0.847984
global_step: 18235, epoch: 56, loss: 0.973300
global_step: 18236, epoch: 56, loss: 0.936212
global_step: 18237, epoch: 56, loss: 0.902991
global_step: 18238, epoch: 56, loss: 1.017763
global_step: 18239, epoch: 56, loss: 0.967759
global_step: 18240, epoch: 56, loss: 0.533846
epoch: 56
train	acc: 0.7476	macro: p 0.5131, r 0.4741, f1: 0.4822	micro: p 0.7476, r 0.7476, f1 0.7476	weighted_f1:0.7155
dev	acc: 0.5528	macro: p 0.3249, r 0.3099, f1: 0.2977	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4957
test	acc: 0.5977	macro: p 0.3558, r 0.3173, f1: 0.3174	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5511
global_step: 18241, epoch: 57, loss: 0.924173
global_step: 18242, epoch: 57, loss: 0.943614
global_step: 18243, epoch: 57, loss: 0.903471
global_step: 18244, epoch: 57, loss: 0.862574
global_step: 18245, epoch: 57, loss: 1.002454
global_step: 18246, epoch: 57, loss: 0.949105
global_step: 18247, epoch: 57, loss: 0.887045
global_step: 18248, epoch: 57, loss: 0.961521
global_step: 18249, epoch: 57, loss: 0.913989
global_step: 18250, epoch: 57, loss: 0.820604
global_step: 18251, epoch: 57, loss: 0.923943
global_step: 18252, epoch: 57, loss: 1.010695
global_step: 18253, epoch: 57, loss: 0.953736
global_step: 18254, epoch: 57, loss: 1.023657
global_step: 18255, epoch: 57, loss: 0.954319
global_step: 18256, epoch: 57, loss: 1.015984
global_step: 18257, epoch: 57, loss: 0.988531
global_step: 18258, epoch: 57, loss: 1.122786
global_step: 18259, epoch: 57, loss: 0.931219
global_step: 18260, epoch: 57, loss: 0.815182
global_step: 18261, epoch: 57, loss: 0.923400
global_step: 18262, epoch: 57, loss: 0.819607
global_step: 18263, epoch: 57, loss: 0.992563
global_step: 18264, epoch: 57, loss: 0.827803
global_step: 18265, epoch: 57, loss: 0.882297
global_step: 18266, epoch: 57, loss: 0.916785
global_step: 18267, epoch: 57, loss: 0.980310
global_step: 18268, epoch: 57, loss: 0.968640
global_step: 18269, epoch: 57, loss: 0.893476
global_step: 18270, epoch: 57, loss: 0.837753
global_step: 18271, epoch: 57, loss: 0.895942
global_step: 18272, epoch: 57, loss: 0.865483
global_step: 18273, epoch: 57, loss: 0.950851
global_step: 18274, epoch: 57, loss: 0.826766
global_step: 18275, epoch: 57, loss: 0.929984
global_step: 18276, epoch: 57, loss: 1.044099
global_step: 18277, epoch: 57, loss: 0.978222
global_step: 18278, epoch: 57, loss: 0.841919
global_step: 18279, epoch: 57, loss: 0.963146
global_step: 18280, epoch: 57, loss: 1.797210
epoch: 57
train	acc: 0.7533	macro: p 0.6604, r 0.4780, f1: 0.4852	micro: p 0.7533, r 0.7533, f1 0.7533	weighted_f1:0.7214
dev	acc: 0.5555	macro: p 0.3325, r 0.3121, f1: 0.2999	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4987
test	acc: 0.6004	macro: p 0.3638, r 0.3202, f1: 0.3199	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5542
global_step: 18281, epoch: 58, loss: 0.998979
global_step: 18282, epoch: 58, loss: 0.888643
global_step: 18283, epoch: 58, loss: 0.951362
global_step: 18284, epoch: 58, loss: 0.939966
global_step: 18285, epoch: 58, loss: 0.886019
global_step: 18286, epoch: 58, loss: 0.818750
global_step: 18287, epoch: 58, loss: 1.018527
global_step: 18288, epoch: 58, loss: 1.053708
global_step: 18289, epoch: 58, loss: 0.996487
global_step: 18290, epoch: 58, loss: 0.883972
global_step: 18291, epoch: 58, loss: 0.873480
global_step: 18292, epoch: 58, loss: 0.981609
global_step: 18293, epoch: 58, loss: 0.905964
global_step: 18294, epoch: 58, loss: 0.972559
global_step: 18295, epoch: 58, loss: 0.984901
global_step: 18296, epoch: 58, loss: 0.890884
global_step: 18297, epoch: 58, loss: 0.981862
global_step: 18298, epoch: 58, loss: 0.919310
global_step: 18299, epoch: 58, loss: 1.004074
global_step: 18300, epoch: 58, loss: 0.920820
global_step: 18301, epoch: 58, loss: 0.995176
global_step: 18302, epoch: 58, loss: 0.934361
global_step: 18303, epoch: 58, loss: 0.910363
global_step: 18304, epoch: 58, loss: 0.876781
global_step: 18305, epoch: 58, loss: 0.945925
global_step: 18306, epoch: 58, loss: 0.903549
global_step: 18307, epoch: 58, loss: 0.911753
global_step: 18308, epoch: 58, loss: 0.920040
global_step: 18309, epoch: 58, loss: 0.859442
global_step: 18310, epoch: 58, loss: 0.965038
global_step: 18311, epoch: 58, loss: 0.921270
global_step: 18312, epoch: 58, loss: 0.936898
global_step: 18313, epoch: 58, loss: 0.969508
global_step: 18314, epoch: 58, loss: 0.992565
global_step: 18315, epoch: 58, loss: 0.772623
global_step: 18316, epoch: 58, loss: 0.984282
global_step: 18317, epoch: 58, loss: 0.942876
global_step: 18318, epoch: 58, loss: 0.947067
global_step: 18319, epoch: 58, loss: 0.910365
global_step: 18320, epoch: 58, loss: 0.968978
epoch: 58
train	acc: 0.7544	macro: p 0.6635, r 0.4767, f1: 0.4828	micro: p 0.7544, r 0.7544, f1 0.7544	weighted_f1:0.7211
dev	acc: 0.5546	macro: p 0.3302, r 0.3110, f1: 0.2995	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4979
test	acc: 0.5973	macro: p 0.3603, r 0.3179, f1: 0.3177	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5515
global_step: 18321, epoch: 59, loss: 0.941112
global_step: 18322, epoch: 59, loss: 0.879389
global_step: 18323, epoch: 59, loss: 0.861832
global_step: 18324, epoch: 59, loss: 0.923062
global_step: 18325, epoch: 59, loss: 0.889929
global_step: 18326, epoch: 59, loss: 1.016900
global_step: 18327, epoch: 59, loss: 0.974820
global_step: 18328, epoch: 59, loss: 0.840975
global_step: 18329, epoch: 59, loss: 0.925309
global_step: 18330, epoch: 59, loss: 0.883616
global_step: 18331, epoch: 59, loss: 0.937743
global_step: 18332, epoch: 59, loss: 0.906332
global_step: 18333, epoch: 59, loss: 0.965948
global_step: 18334, epoch: 59, loss: 0.910382
global_step: 18335, epoch: 59, loss: 0.862633
global_step: 18336, epoch: 59, loss: 0.905669
global_step: 18337, epoch: 59, loss: 0.955659
global_step: 18338, epoch: 59, loss: 0.991733
global_step: 18339, epoch: 59, loss: 0.911374
global_step: 18340, epoch: 59, loss: 0.849134
global_step: 18341, epoch: 59, loss: 0.960561
global_step: 18342, epoch: 59, loss: 0.851852
global_step: 18343, epoch: 59, loss: 0.914585
global_step: 18344, epoch: 59, loss: 0.827483
global_step: 18345, epoch: 59, loss: 0.915245
global_step: 18346, epoch: 59, loss: 1.046298
global_step: 18347, epoch: 59, loss: 0.944551
global_step: 18348, epoch: 59, loss: 0.944674
global_step: 18349, epoch: 59, loss: 0.891087
global_step: 18350, epoch: 59, loss: 1.003519
global_step: 18351, epoch: 59, loss: 0.914393
global_step: 18352, epoch: 59, loss: 0.827583
global_step: 18353, epoch: 59, loss: 0.954318
global_step: 18354, epoch: 59, loss: 0.931282
global_step: 18355, epoch: 59, loss: 0.830348
global_step: 18356, epoch: 59, loss: 0.867710
global_step: 18357, epoch: 59, loss: 0.912968
global_step: 18358, epoch: 59, loss: 0.845850
global_step: 18359, epoch: 59, loss: 0.925855
global_step: 18360, epoch: 59, loss: 1.306787
epoch: 59
train	acc: 0.7557	macro: p 0.6659, r 0.4820, f1: 0.4910	micro: p 0.7557, r 0.7557, f1 0.7557	weighted_f1:0.7237
dev	acc: 0.5582	macro: p 0.3376, r 0.3121, f1: 0.3023	micro: p 0.5582, r 0.5582, f1 0.5582	weighted_f1:0.5005
test	acc: 0.5989	macro: p 0.3564, r 0.3166, f1: 0.3170	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5515
global_step: 18361, epoch: 60, loss: 0.918913
global_step: 18362, epoch: 60, loss: 0.916966
global_step: 18363, epoch: 60, loss: 0.832365
global_step: 18364, epoch: 60, loss: 0.927031
global_step: 18365, epoch: 60, loss: 0.944138
global_step: 18366, epoch: 60, loss: 0.910559
global_step: 18367, epoch: 60, loss: 0.945106
global_step: 18368, epoch: 60, loss: 0.912231
global_step: 18369, epoch: 60, loss: 0.883735
global_step: 18370, epoch: 60, loss: 0.897171
global_step: 18371, epoch: 60, loss: 0.925662
global_step: 18372, epoch: 60, loss: 0.798222
global_step: 18373, epoch: 60, loss: 0.899766
global_step: 18374, epoch: 60, loss: 0.998594
global_step: 18375, epoch: 60, loss: 0.948713
global_step: 18376, epoch: 60, loss: 0.830063
global_step: 18377, epoch: 60, loss: 0.933092
global_step: 18378, epoch: 60, loss: 0.894963
global_step: 18379, epoch: 60, loss: 0.843101
global_step: 18380, epoch: 60, loss: 0.963014
global_step: 18381, epoch: 60, loss: 0.864864
global_step: 18382, epoch: 60, loss: 0.926997
global_step: 18383, epoch: 60, loss: 0.963370
global_step: 18384, epoch: 60, loss: 0.866685
global_step: 18385, epoch: 60, loss: 0.994802
global_step: 18386, epoch: 60, loss: 0.849738
global_step: 18387, epoch: 60, loss: 0.964265
global_step: 18388, epoch: 60, loss: 0.915696
global_step: 18389, epoch: 60, loss: 1.052543
global_step: 18390, epoch: 60, loss: 0.907038
global_step: 18391, epoch: 60, loss: 0.828640
global_step: 18392, epoch: 60, loss: 0.902561
global_step: 18393, epoch: 60, loss: 0.958794
global_step: 18394, epoch: 60, loss: 1.037271
global_step: 18395, epoch: 60, loss: 0.877093
global_step: 18396, epoch: 60, loss: 0.929103
global_step: 18397, epoch: 60, loss: 1.011946
global_step: 18398, epoch: 60, loss: 0.894506
global_step: 18399, epoch: 60, loss: 0.871730
global_step: 18400, epoch: 60, loss: 0.995253
epoch: 60
train	acc: 0.7412	macro: p 0.5260, r 0.4598, f1: 0.4735	micro: p 0.7412, r 0.7412, f1 0.7412	weighted_f1:0.7065
dev	acc: 0.5591	macro: p 0.3445, r 0.3076, f1: 0.3009	micro: p 0.5591, r 0.5591, f1 0.5591	weighted_f1:0.4993
test	acc: 0.6015	macro: p 0.3758, r 0.3115, f1: 0.3172	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5515
global_step: 18401, epoch: 61, loss: 0.902989
global_step: 18402, epoch: 61, loss: 0.851164
global_step: 18403, epoch: 61, loss: 0.877212
global_step: 18404, epoch: 61, loss: 0.844580
global_step: 18405, epoch: 61, loss: 0.906401
global_step: 18406, epoch: 61, loss: 0.926941
global_step: 18407, epoch: 61, loss: 1.003576
global_step: 18408, epoch: 61, loss: 0.894112
global_step: 18409, epoch: 61, loss: 0.893792
global_step: 18410, epoch: 61, loss: 1.049871
global_step: 18411, epoch: 61, loss: 0.864642
global_step: 18412, epoch: 61, loss: 0.890212
global_step: 18413, epoch: 61, loss: 0.910268
global_step: 18414, epoch: 61, loss: 0.948838
global_step: 18415, epoch: 61, loss: 0.868348
global_step: 18416, epoch: 61, loss: 0.927314
global_step: 18417, epoch: 61, loss: 0.883750
global_step: 18418, epoch: 61, loss: 0.845683
global_step: 18419, epoch: 61, loss: 0.907202
global_step: 18420, epoch: 61, loss: 0.932893
global_step: 18421, epoch: 61, loss: 0.813930
global_step: 18422, epoch: 61, loss: 0.829293
global_step: 18423, epoch: 61, loss: 0.938538
global_step: 18424, epoch: 61, loss: 1.034696
global_step: 18425, epoch: 61, loss: 0.936363
global_step: 18426, epoch: 61, loss: 0.966938
global_step: 18427, epoch: 61, loss: 0.927830
global_step: 18428, epoch: 61, loss: 0.851178
global_step: 18429, epoch: 61, loss: 0.788621
global_step: 18430, epoch: 61, loss: 0.897955
global_step: 18431, epoch: 61, loss: 0.846638
global_step: 18432, epoch: 61, loss: 0.923979
global_step: 18433, epoch: 61, loss: 0.838592
global_step: 18434, epoch: 61, loss: 0.959837
global_step: 18435, epoch: 61, loss: 0.927587
global_step: 18436, epoch: 61, loss: 0.889013
global_step: 18437, epoch: 61, loss: 0.846041
global_step: 18438, epoch: 61, loss: 0.947947
global_step: 18439, epoch: 61, loss: 0.951765
global_step: 18440, epoch: 61, loss: 0.932653
epoch: 61
train	acc: 0.7553	macro: p 0.6722, r 0.4783, f1: 0.4898	micro: p 0.7553, r 0.7553, f1 0.7553	weighted_f1:0.7228
dev	acc: 0.5546	macro: p 0.3386, r 0.3064, f1: 0.2981	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4963
test	acc: 0.6004	macro: p 0.3647, r 0.3135, f1: 0.3164	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5514
global_step: 18441, epoch: 62, loss: 0.898373
global_step: 18442, epoch: 62, loss: 0.889551
global_step: 18443, epoch: 62, loss: 0.915951
global_step: 18444, epoch: 62, loss: 0.979252
global_step: 18445, epoch: 62, loss: 0.864022
global_step: 18446, epoch: 62, loss: 0.848780
global_step: 18447, epoch: 62, loss: 0.901011
global_step: 18448, epoch: 62, loss: 0.959026
global_step: 18449, epoch: 62, loss: 0.906698
global_step: 18450, epoch: 62, loss: 0.993474
global_step: 18451, epoch: 62, loss: 0.836611
global_step: 18452, epoch: 62, loss: 1.036886
global_step: 18453, epoch: 62, loss: 0.881831
global_step: 18454, epoch: 62, loss: 0.919578
global_step: 18455, epoch: 62, loss: 0.866253
global_step: 18456, epoch: 62, loss: 0.865258
global_step: 18457, epoch: 62, loss: 0.925056
global_step: 18458, epoch: 62, loss: 0.965761
global_step: 18459, epoch: 62, loss: 0.838620
global_step: 18460, epoch: 62, loss: 0.980124
global_step: 18461, epoch: 62, loss: 0.794122
global_step: 18462, epoch: 62, loss: 0.774485
global_step: 18463, epoch: 62, loss: 0.961823
global_step: 18464, epoch: 62, loss: 0.897407
global_step: 18465, epoch: 62, loss: 0.836879
global_step: 18466, epoch: 62, loss: 0.944491
global_step: 18467, epoch: 62, loss: 0.970975
global_step: 18468, epoch: 62, loss: 0.876815
global_step: 18469, epoch: 62, loss: 0.909812
global_step: 18470, epoch: 62, loss: 0.936633
global_step: 18471, epoch: 62, loss: 0.869996
global_step: 18472, epoch: 62, loss: 0.838231
global_step: 18473, epoch: 62, loss: 0.856289
global_step: 18474, epoch: 62, loss: 0.922392
global_step: 18475, epoch: 62, loss: 0.905875
global_step: 18476, epoch: 62, loss: 1.027289
global_step: 18477, epoch: 62, loss: 0.838604
global_step: 18478, epoch: 62, loss: 0.826504
global_step: 18479, epoch: 62, loss: 0.922050
global_step: 18480, epoch: 62, loss: 0.894954
epoch: 62
train	acc: 0.7549	macro: p 0.6737, r 0.4760, f1: 0.4837	micro: p 0.7549, r 0.7549, f1 0.7549	weighted_f1:0.7208
dev	acc: 0.5546	macro: p 0.3397, r 0.3068, f1: 0.2980	micro: p 0.5546, r 0.5546, f1 0.5546	weighted_f1:0.4962
test	acc: 0.6034	macro: p 0.3721, r 0.3168, f1: 0.3187	micro: p 0.6034, r 0.6034, f1 0.6034	weighted_f1:0.5551
global_step: 18481, epoch: 63, loss: 0.890862
global_step: 18482, epoch: 63, loss: 0.891080
global_step: 18483, epoch: 63, loss: 0.800880
global_step: 18484, epoch: 63, loss: 0.975180
global_step: 18485, epoch: 63, loss: 0.868314
global_step: 18486, epoch: 63, loss: 0.866213
global_step: 18487, epoch: 63, loss: 0.835716
global_step: 18488, epoch: 63, loss: 0.892679
global_step: 18489, epoch: 63, loss: 0.827091
global_step: 18490, epoch: 63, loss: 0.796802
global_step: 18491, epoch: 63, loss: 0.797344
global_step: 18492, epoch: 63, loss: 0.891167
global_step: 18493, epoch: 63, loss: 0.941428
global_step: 18494, epoch: 63, loss: 0.847055
global_step: 18495, epoch: 63, loss: 0.820778
global_step: 18496, epoch: 63, loss: 0.846287
global_step: 18497, epoch: 63, loss: 0.870197
global_step: 18498, epoch: 63, loss: 0.895298
global_step: 18499, epoch: 63, loss: 0.890016
global_step: 18500, epoch: 63, loss: 0.946775
global_step: 18501, epoch: 63, loss: 0.897145
global_step: 18502, epoch: 63, loss: 0.921809
global_step: 18503, epoch: 63, loss: 0.966653
global_step: 18504, epoch: 63, loss: 0.855984
global_step: 18505, epoch: 63, loss: 0.917358
global_step: 18506, epoch: 63, loss: 1.014571
global_step: 18507, epoch: 63, loss: 0.937615
global_step: 18508, epoch: 63, loss: 0.876608
global_step: 18509, epoch: 63, loss: 0.908677
global_step: 18510, epoch: 63, loss: 0.813971
global_step: 18511, epoch: 63, loss: 0.847070
global_step: 18512, epoch: 63, loss: 1.038514
global_step: 18513, epoch: 63, loss: 0.892553
global_step: 18514, epoch: 63, loss: 0.962176
global_step: 18515, epoch: 63, loss: 0.839509
global_step: 18516, epoch: 63, loss: 1.068157
global_step: 18517, epoch: 63, loss: 0.942666
global_step: 18518, epoch: 63, loss: 0.874685
global_step: 18519, epoch: 63, loss: 0.862726
global_step: 18520, epoch: 63, loss: 0.609088
epoch: 63
train	acc: 0.7496	macro: p 0.5333, r 0.4677, f1: 0.4831	micro: p 0.7496, r 0.7496, f1 0.7496	weighted_f1:0.7156
dev	acc: 0.5528	macro: p 0.3277, r 0.3002, f1: 0.2906	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4896
test	acc: 0.5989	macro: p 0.3679, r 0.3066, f1: 0.3084	micro: p 0.5989, r 0.5989, f1 0.5989	weighted_f1:0.5447
global_step: 18521, epoch: 64, loss: 0.834734
global_step: 18522, epoch: 64, loss: 0.811510
global_step: 18523, epoch: 64, loss: 0.769659
global_step: 18524, epoch: 64, loss: 0.955285
global_step: 18525, epoch: 64, loss: 0.861110
global_step: 18526, epoch: 64, loss: 0.847413
global_step: 18527, epoch: 64, loss: 0.985926
global_step: 18528, epoch: 64, loss: 0.851641
global_step: 18529, epoch: 64, loss: 0.880169
global_step: 18530, epoch: 64, loss: 0.824734
global_step: 18531, epoch: 64, loss: 0.935504
global_step: 18532, epoch: 64, loss: 0.836640
global_step: 18533, epoch: 64, loss: 1.039189
global_step: 18534, epoch: 64, loss: 0.828240
global_step: 18535, epoch: 64, loss: 0.867792
global_step: 18536, epoch: 64, loss: 0.870355
global_step: 18537, epoch: 64, loss: 0.888792
global_step: 18538, epoch: 64, loss: 0.862431
global_step: 18539, epoch: 64, loss: 0.854606
global_step: 18540, epoch: 64, loss: 0.893560
global_step: 18541, epoch: 64, loss: 0.972159
global_step: 18542, epoch: 64, loss: 0.877446
global_step: 18543, epoch: 64, loss: 0.883521
global_step: 18544, epoch: 64, loss: 0.878083
global_step: 18545, epoch: 64, loss: 0.928201
global_step: 18546, epoch: 64, loss: 0.996853
global_step: 18547, epoch: 64, loss: 0.761595
global_step: 18548, epoch: 64, loss: 0.871387
global_step: 18549, epoch: 64, loss: 0.774097
global_step: 18550, epoch: 64, loss: 0.823265
global_step: 18551, epoch: 64, loss: 0.892088
global_step: 18552, epoch: 64, loss: 0.899275
global_step: 18553, epoch: 64, loss: 0.746317
global_step: 18554, epoch: 64, loss: 0.891221
global_step: 18555, epoch: 64, loss: 0.888693
global_step: 18556, epoch: 64, loss: 0.893335
global_step: 18557, epoch: 64, loss: 0.949646
global_step: 18558, epoch: 64, loss: 0.892952
global_step: 18559, epoch: 64, loss: 0.976943
global_step: 18560, epoch: 64, loss: 0.353976
epoch: 64
train	acc: 0.7659	macro: p 0.8246, r 0.4896, f1: 0.5006	micro: p 0.7659, r 0.7659, f1 0.7659	weighted_f1:0.7339
dev	acc: 0.5500	macro: p 0.3383, r 0.3032, f1: 0.2916	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4897
test	acc: 0.5996	macro: p 0.3640, r 0.3125, f1: 0.3121	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5489
global_step: 18561, epoch: 65, loss: 0.878796
global_step: 18562, epoch: 65, loss: 0.783242
global_step: 18563, epoch: 65, loss: 0.885706
global_step: 18564, epoch: 65, loss: 0.928093
global_step: 18565, epoch: 65, loss: 0.937693
global_step: 18566, epoch: 65, loss: 0.913806
global_step: 18567, epoch: 65, loss: 0.900284
global_step: 18568, epoch: 65, loss: 0.943324
global_step: 18569, epoch: 65, loss: 0.846627
global_step: 18570, epoch: 65, loss: 0.874122
global_step: 18571, epoch: 65, loss: 0.970527
global_step: 18572, epoch: 65, loss: 0.884369
global_step: 18573, epoch: 65, loss: 0.965815
global_step: 18574, epoch: 65, loss: 0.886047
global_step: 18575, epoch: 65, loss: 0.780024
global_step: 18576, epoch: 65, loss: 0.893529
global_step: 18577, epoch: 65, loss: 0.928331
global_step: 18578, epoch: 65, loss: 0.816245
global_step: 18579, epoch: 65, loss: 0.835551
global_step: 18580, epoch: 65, loss: 0.856359
global_step: 18581, epoch: 65, loss: 0.849362
global_step: 18582, epoch: 65, loss: 0.864638
global_step: 18583, epoch: 65, loss: 0.844251
global_step: 18584, epoch: 65, loss: 0.870019
global_step: 18585, epoch: 65, loss: 0.826503
global_step: 18586, epoch: 65, loss: 0.839715
global_step: 18587, epoch: 65, loss: 0.933253
global_step: 18588, epoch: 65, loss: 0.863628
global_step: 18589, epoch: 65, loss: 0.908083
global_step: 18590, epoch: 65, loss: 0.867119
global_step: 18591, epoch: 65, loss: 0.839661
global_step: 18592, epoch: 65, loss: 0.907991
global_step: 18593, epoch: 65, loss: 0.806051
global_step: 18594, epoch: 65, loss: 0.819195
global_step: 18595, epoch: 65, loss: 0.875700
global_step: 18596, epoch: 65, loss: 0.937247
global_step: 18597, epoch: 65, loss: 0.937695
global_step: 18598, epoch: 65, loss: 0.910870
global_step: 18599, epoch: 65, loss: 0.821163
global_step: 18600, epoch: 65, loss: 1.326137
epoch: 65
train	acc: 0.7643	macro: p 0.8246, r 0.4868, f1: 0.4980	micro: p 0.7643, r 0.7643, f1 0.7643	weighted_f1:0.7311
dev	acc: 0.5555	macro: p 0.3383, r 0.3064, f1: 0.2971	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4955
test	acc: 0.6019	macro: p 0.3723, r 0.3150, f1: 0.3165	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5519
global_step: 18601, epoch: 66, loss: 0.907769
global_step: 18602, epoch: 66, loss: 0.840742
global_step: 18603, epoch: 66, loss: 0.813986
global_step: 18604, epoch: 66, loss: 0.854729
global_step: 18605, epoch: 66, loss: 0.955795
global_step: 18606, epoch: 66, loss: 0.873800
global_step: 18607, epoch: 66, loss: 0.923813
global_step: 18608, epoch: 66, loss: 0.866925
global_step: 18609, epoch: 66, loss: 0.891997
global_step: 18610, epoch: 66, loss: 0.820858
global_step: 18611, epoch: 66, loss: 0.834295
global_step: 18612, epoch: 66, loss: 0.863054
global_step: 18613, epoch: 66, loss: 0.718754
global_step: 18614, epoch: 66, loss: 0.892929
global_step: 18615, epoch: 66, loss: 0.928672
global_step: 18616, epoch: 66, loss: 0.794076
global_step: 18617, epoch: 66, loss: 0.885937
global_step: 18618, epoch: 66, loss: 0.958316
global_step: 18619, epoch: 66, loss: 0.916150
global_step: 18620, epoch: 66, loss: 0.709514
global_step: 18621, epoch: 66, loss: 0.803874
global_step: 18622, epoch: 66, loss: 0.850477
global_step: 18623, epoch: 66, loss: 0.838697
global_step: 18624, epoch: 66, loss: 0.885157
global_step: 18625, epoch: 66, loss: 0.911393
global_step: 18626, epoch: 66, loss: 0.850285
global_step: 18627, epoch: 66, loss: 0.855443
global_step: 18628, epoch: 66, loss: 0.787354
global_step: 18629, epoch: 66, loss: 0.758517
global_step: 18630, epoch: 66, loss: 0.871094
global_step: 18631, epoch: 66, loss: 0.869108
global_step: 18632, epoch: 66, loss: 0.991092
global_step: 18633, epoch: 66, loss: 0.993272
global_step: 18634, epoch: 66, loss: 0.880266
global_step: 18635, epoch: 66, loss: 0.861208
global_step: 18636, epoch: 66, loss: 0.856116
global_step: 18637, epoch: 66, loss: 0.918313
global_step: 18638, epoch: 66, loss: 0.873033
global_step: 18639, epoch: 66, loss: 0.880326
global_step: 18640, epoch: 66, loss: 0.114844
epoch: 66
train	acc: 0.7773	macro: p 0.8272, r 0.5081, f1: 0.5180	micro: p 0.7773, r 0.7773, f1 0.7773	weighted_f1:0.7481
dev	acc: 0.5537	macro: p 0.3354, r 0.3067, f1: 0.2979	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4962
test	acc: 0.6015	macro: p 0.3678, r 0.3175, f1: 0.3211	micro: p 0.6015, r 0.6015, f1 0.6015	weighted_f1:0.5555
global_step: 18641, epoch: 67, loss: 0.881466
global_step: 18642, epoch: 67, loss: 0.854689
global_step: 18643, epoch: 67, loss: 0.806844
global_step: 18644, epoch: 67, loss: 0.877026
global_step: 18645, epoch: 67, loss: 0.881603
global_step: 18646, epoch: 67, loss: 0.788175
global_step: 18647, epoch: 67, loss: 0.767907
global_step: 18648, epoch: 67, loss: 0.796210
global_step: 18649, epoch: 67, loss: 0.826636
global_step: 18650, epoch: 67, loss: 0.940390
global_step: 18651, epoch: 67, loss: 0.824318
global_step: 18652, epoch: 67, loss: 0.915235
global_step: 18653, epoch: 67, loss: 0.863674
global_step: 18654, epoch: 67, loss: 0.848485
global_step: 18655, epoch: 67, loss: 0.900824
global_step: 18656, epoch: 67, loss: 0.858564
global_step: 18657, epoch: 67, loss: 0.864838
global_step: 18658, epoch: 67, loss: 0.847905
global_step: 18659, epoch: 67, loss: 0.837281
global_step: 18660, epoch: 67, loss: 0.952813
global_step: 18661, epoch: 67, loss: 0.948777
global_step: 18662, epoch: 67, loss: 0.885433
global_step: 18663, epoch: 67, loss: 0.896030
global_step: 18664, epoch: 67, loss: 0.750888
global_step: 18665, epoch: 67, loss: 1.013937
global_step: 18666, epoch: 67, loss: 0.850688
global_step: 18667, epoch: 67, loss: 0.865711
global_step: 18668, epoch: 67, loss: 0.905775
global_step: 18669, epoch: 67, loss: 0.772616
global_step: 18670, epoch: 67, loss: 0.890007
global_step: 18671, epoch: 67, loss: 0.838607
global_step: 18672, epoch: 67, loss: 0.797619
global_step: 18673, epoch: 67, loss: 0.919367
global_step: 18674, epoch: 67, loss: 0.843761
global_step: 18675, epoch: 67, loss: 0.857649
global_step: 18676, epoch: 67, loss: 0.897090
global_step: 18677, epoch: 67, loss: 0.964085
global_step: 18678, epoch: 67, loss: 0.915276
global_step: 18679, epoch: 67, loss: 0.823852
global_step: 18680, epoch: 67, loss: 0.331723
epoch: 67
train	acc: 0.7872	macro: p 0.8315, r 0.5203, f1: 0.5285	micro: p 0.7872, r 0.7872, f1 0.7872	weighted_f1:0.7589
dev	acc: 0.5482	macro: p 0.3244, r 0.3065, f1: 0.2953	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4925
test	acc: 0.5962	macro: p 0.3641, r 0.3151, f1: 0.3159	micro: p 0.5962, r 0.5962, f1 0.5962	weighted_f1:0.5496
global_step: 18681, epoch: 68, loss: 0.864784
global_step: 18682, epoch: 68, loss: 0.848615
global_step: 18683, epoch: 68, loss: 0.742434
global_step: 18684, epoch: 68, loss: 0.892718
global_step: 18685, epoch: 68, loss: 0.759251
global_step: 18686, epoch: 68, loss: 0.935167
global_step: 18687, epoch: 68, loss: 0.840232
global_step: 18688, epoch: 68, loss: 0.798033
global_step: 18689, epoch: 68, loss: 0.879063
global_step: 18690, epoch: 68, loss: 0.856897
global_step: 18691, epoch: 68, loss: 0.837586
global_step: 18692, epoch: 68, loss: 0.937331
global_step: 18693, epoch: 68, loss: 0.796600
global_step: 18694, epoch: 68, loss: 0.817552
global_step: 18695, epoch: 68, loss: 0.763989
global_step: 18696, epoch: 68, loss: 0.848135
global_step: 18697, epoch: 68, loss: 0.685260
global_step: 18698, epoch: 68, loss: 0.956160
global_step: 18699, epoch: 68, loss: 0.880119
global_step: 18700, epoch: 68, loss: 0.833176
global_step: 18701, epoch: 68, loss: 0.817611
global_step: 18702, epoch: 68, loss: 0.955837
global_step: 18703, epoch: 68, loss: 0.935794
global_step: 18704, epoch: 68, loss: 0.821498
global_step: 18705, epoch: 68, loss: 0.823602
global_step: 18706, epoch: 68, loss: 0.722716
global_step: 18707, epoch: 68, loss: 0.889135
global_step: 18708, epoch: 68, loss: 0.776713
global_step: 18709, epoch: 68, loss: 0.920033
global_step: 18710, epoch: 68, loss: 0.911336
global_step: 18711, epoch: 68, loss: 0.923859
global_step: 18712, epoch: 68, loss: 0.977450
global_step: 18713, epoch: 68, loss: 0.785495
global_step: 18714, epoch: 68, loss: 0.829985
global_step: 18715, epoch: 68, loss: 0.817105
global_step: 18716, epoch: 68, loss: 0.877806
global_step: 18717, epoch: 68, loss: 0.852514
global_step: 18718, epoch: 68, loss: 0.865502
global_step: 18719, epoch: 68, loss: 0.856238
global_step: 18720, epoch: 68, loss: 1.524982
epoch: 68
train	acc: 0.7823	macro: p 0.8353, r 0.5144, f1: 0.5261	micro: p 0.7823, r 0.7823, f1 0.7823	weighted_f1:0.7537
dev	acc: 0.5528	macro: p 0.3384, r 0.3048, f1: 0.2976	micro: p 0.5528, r 0.5528, f1 0.5528	weighted_f1:0.4958
test	acc: 0.6019	macro: p 0.3676, r 0.3153, f1: 0.3189	micro: p 0.6019, r 0.6019, f1 0.6019	weighted_f1:0.5545
global_step: 18721, epoch: 69, loss: 0.787224
global_step: 18722, epoch: 69, loss: 0.870689
global_step: 18723, epoch: 69, loss: 0.885168
global_step: 18724, epoch: 69, loss: 0.884316
global_step: 18725, epoch: 69, loss: 0.824462
global_step: 18726, epoch: 69, loss: 0.821573
global_step: 18727, epoch: 69, loss: 0.800561
global_step: 18728, epoch: 69, loss: 0.930551
global_step: 18729, epoch: 69, loss: 0.820147
global_step: 18730, epoch: 69, loss: 0.935331
global_step: 18731, epoch: 69, loss: 0.916105
global_step: 18732, epoch: 69, loss: 0.827052
global_step: 18733, epoch: 69, loss: 0.757303
global_step: 18734, epoch: 69, loss: 0.865619
global_step: 18735, epoch: 69, loss: 0.816669
global_step: 18736, epoch: 69, loss: 0.867451
global_step: 18737, epoch: 69, loss: 0.803534
global_step: 18738, epoch: 69, loss: 0.809238
global_step: 18739, epoch: 69, loss: 0.824671
global_step: 18740, epoch: 69, loss: 0.835344
global_step: 18741, epoch: 69, loss: 0.775226
global_step: 18742, epoch: 69, loss: 0.859689
global_step: 18743, epoch: 69, loss: 0.858787
global_step: 18744, epoch: 69, loss: 0.829498
global_step: 18745, epoch: 69, loss: 0.758680
global_step: 18746, epoch: 69, loss: 0.848910
global_step: 18747, epoch: 69, loss: 0.860837
global_step: 18748, epoch: 69, loss: 0.790608
global_step: 18749, epoch: 69, loss: 0.717426
global_step: 18750, epoch: 69, loss: 0.787104
global_step: 18751, epoch: 69, loss: 0.874303
global_step: 18752, epoch: 69, loss: 0.913396
global_step: 18753, epoch: 69, loss: 0.841905
global_step: 18754, epoch: 69, loss: 0.840286
global_step: 18755, epoch: 69, loss: 0.874849
global_step: 18756, epoch: 69, loss: 0.959085
global_step: 18757, epoch: 69, loss: 0.863096
global_step: 18758, epoch: 69, loss: 0.760892
global_step: 18759, epoch: 69, loss: 0.806956
global_step: 18760, epoch: 69, loss: 0.665345
epoch: 69
train	acc: 0.7737	macro: p 0.8377, r 0.4989, f1: 0.5152	micro: p 0.7737, r 0.7737, f1 0.7737	weighted_f1:0.7426
dev	acc: 0.5482	macro: p 0.3362, r 0.2979, f1: 0.2862	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4848
test	acc: 0.6011	macro: p 0.3703, r 0.3094, f1: 0.3101	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5477
global_step: 18761, epoch: 70, loss: 0.917409
global_step: 18762, epoch: 70, loss: 0.783806
global_step: 18763, epoch: 70, loss: 0.760755
global_step: 18764, epoch: 70, loss: 0.872549
global_step: 18765, epoch: 70, loss: 0.738686
global_step: 18766, epoch: 70, loss: 0.781254
global_step: 18767, epoch: 70, loss: 0.789362
global_step: 18768, epoch: 70, loss: 0.906676
global_step: 18769, epoch: 70, loss: 0.807784
global_step: 18770, epoch: 70, loss: 0.823523
global_step: 18771, epoch: 70, loss: 0.877207
global_step: 18772, epoch: 70, loss: 0.749182
global_step: 18773, epoch: 70, loss: 0.879866
global_step: 18774, epoch: 70, loss: 0.753725
global_step: 18775, epoch: 70, loss: 0.870003
global_step: 18776, epoch: 70, loss: 0.809534
global_step: 18777, epoch: 70, loss: 0.778103
global_step: 18778, epoch: 70, loss: 0.763038
global_step: 18779, epoch: 70, loss: 0.920236
global_step: 18780, epoch: 70, loss: 0.885816
global_step: 18781, epoch: 70, loss: 0.919499
global_step: 18782, epoch: 70, loss: 0.831438
global_step: 18783, epoch: 70, loss: 0.777862
global_step: 18784, epoch: 70, loss: 0.772490
global_step: 18785, epoch: 70, loss: 0.794956
global_step: 18786, epoch: 70, loss: 0.794008
global_step: 18787, epoch: 70, loss: 0.802967
global_step: 18788, epoch: 70, loss: 0.797523
global_step: 18789, epoch: 70, loss: 0.809602
global_step: 18790, epoch: 70, loss: 0.848306
global_step: 18791, epoch: 70, loss: 0.866646
global_step: 18792, epoch: 70, loss: 0.787034
global_step: 18793, epoch: 70, loss: 0.851915
global_step: 18794, epoch: 70, loss: 0.783999
global_step: 18795, epoch: 70, loss: 0.933436
global_step: 18796, epoch: 70, loss: 0.850241
global_step: 18797, epoch: 70, loss: 0.836652
global_step: 18798, epoch: 70, loss: 0.884465
global_step: 18799, epoch: 70, loss: 0.816281
global_step: 18800, epoch: 70, loss: 0.713010
epoch: 70
train	acc: 0.7870	macro: p 0.8367, r 0.5244, f1: 0.5381	micro: p 0.7870, r 0.7870, f1 0.7870	weighted_f1:0.7600
dev	acc: 0.5555	macro: p 0.3324, r 0.3065, f1: 0.3001	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.4985
test	acc: 0.6038	macro: p 0.3673, r 0.3165, f1: 0.3215	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5562
global_step: 18801, epoch: 71, loss: 0.784204
global_step: 18802, epoch: 71, loss: 0.760895
global_step: 18803, epoch: 71, loss: 0.851695
global_step: 18804, epoch: 71, loss: 0.832929
global_step: 18805, epoch: 71, loss: 0.754879
global_step: 18806, epoch: 71, loss: 0.790593
global_step: 18807, epoch: 71, loss: 0.838467
global_step: 18808, epoch: 71, loss: 0.793010
global_step: 18809, epoch: 71, loss: 0.879493
global_step: 18810, epoch: 71, loss: 0.769931
global_step: 18811, epoch: 71, loss: 0.850844
global_step: 18812, epoch: 71, loss: 0.781254
global_step: 18813, epoch: 71, loss: 0.938648
global_step: 18814, epoch: 71, loss: 0.935324
global_step: 18815, epoch: 71, loss: 0.786510
global_step: 18816, epoch: 71, loss: 0.856062
global_step: 18817, epoch: 71, loss: 0.797506
global_step: 18818, epoch: 71, loss: 0.841368
global_step: 18819, epoch: 71, loss: 0.777854
global_step: 18820, epoch: 71, loss: 0.827292
global_step: 18821, epoch: 71, loss: 0.835660
global_step: 18822, epoch: 71, loss: 0.887885
global_step: 18823, epoch: 71, loss: 0.747740
global_step: 18824, epoch: 71, loss: 0.933143
global_step: 18825, epoch: 71, loss: 0.927474
global_step: 18826, epoch: 71, loss: 0.860340
global_step: 18827, epoch: 71, loss: 0.755342
global_step: 18828, epoch: 71, loss: 0.828647
global_step: 18829, epoch: 71, loss: 0.821865
global_step: 18830, epoch: 71, loss: 0.866685
global_step: 18831, epoch: 71, loss: 0.684155
global_step: 18832, epoch: 71, loss: 0.846200
global_step: 18833, epoch: 71, loss: 0.770116
global_step: 18834, epoch: 71, loss: 0.923336
global_step: 18835, epoch: 71, loss: 0.794512
global_step: 18836, epoch: 71, loss: 0.854344
global_step: 18837, epoch: 71, loss: 0.738471
global_step: 18838, epoch: 71, loss: 0.876685
global_step: 18839, epoch: 71, loss: 0.872374
global_step: 18840, epoch: 71, loss: 0.331791
epoch: 71
train	acc: 0.7924	macro: p 0.8420, r 0.5272, f1: 0.5405	micro: p 0.7924, r 0.7924, f1 0.7924	weighted_f1:0.7644
dev	acc: 0.5537	macro: p 0.3319, r 0.3066, f1: 0.2965	micro: p 0.5537, r 0.5537, f1 0.5537	weighted_f1:0.4945
test	acc: 0.6008	macro: p 0.3691, r 0.3146, f1: 0.3146	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5497
global_step: 18841, epoch: 72, loss: 0.806085
global_step: 18842, epoch: 72, loss: 0.906270
global_step: 18843, epoch: 72, loss: 0.755124
global_step: 18844, epoch: 72, loss: 0.960574
global_step: 18845, epoch: 72, loss: 0.731397
global_step: 18846, epoch: 72, loss: 0.918754
global_step: 18847, epoch: 72, loss: 0.837252
global_step: 18848, epoch: 72, loss: 0.860606
global_step: 18849, epoch: 72, loss: 0.855288
global_step: 18850, epoch: 72, loss: 0.743583
global_step: 18851, epoch: 72, loss: 0.833493
global_step: 18852, epoch: 72, loss: 0.820619
global_step: 18853, epoch: 72, loss: 0.740793
global_step: 18854, epoch: 72, loss: 0.892245
global_step: 18855, epoch: 72, loss: 0.844654
global_step: 18856, epoch: 72, loss: 0.756032
global_step: 18857, epoch: 72, loss: 0.677201
global_step: 18858, epoch: 72, loss: 0.810734
global_step: 18859, epoch: 72, loss: 0.799195
global_step: 18860, epoch: 72, loss: 0.826853
global_step: 18861, epoch: 72, loss: 0.887382
global_step: 18862, epoch: 72, loss: 0.816473
global_step: 18863, epoch: 72, loss: 0.908249
global_step: 18864, epoch: 72, loss: 0.905005
global_step: 18865, epoch: 72, loss: 0.811508
global_step: 18866, epoch: 72, loss: 0.763405
global_step: 18867, epoch: 72, loss: 0.805682
global_step: 18868, epoch: 72, loss: 0.882997
global_step: 18869, epoch: 72, loss: 0.834163
global_step: 18870, epoch: 72, loss: 0.752665
global_step: 18871, epoch: 72, loss: 0.740857
global_step: 18872, epoch: 72, loss: 0.788790
global_step: 18873, epoch: 72, loss: 0.706304
global_step: 18874, epoch: 72, loss: 0.806468
global_step: 18875, epoch: 72, loss: 0.796132
global_step: 18876, epoch: 72, loss: 0.708020
global_step: 18877, epoch: 72, loss: 0.835390
global_step: 18878, epoch: 72, loss: 0.780237
global_step: 18879, epoch: 72, loss: 0.893762
global_step: 18880, epoch: 72, loss: 0.843758
epoch: 72
train	acc: 0.8084	macro: p 0.8426, r 0.5555, f1: 0.5637	micro: p 0.8084, r 0.8084, f1 0.8084	weighted_f1:0.7841
dev	acc: 0.5555	macro: p 0.3415, r 0.3130, f1: 0.3087	micro: p 0.5555, r 0.5555, f1 0.5555	weighted_f1:0.5041
test	acc: 0.6031	macro: p 0.3663, r 0.3235, f1: 0.3276	micro: p 0.6031, r 0.6031, f1 0.6031	weighted_f1:0.5596
global_step: 18881, epoch: 73, loss: 0.799439
global_step: 18882, epoch: 73, loss: 0.859179
global_step: 18883, epoch: 73, loss: 0.797322
global_step: 18884, epoch: 73, loss: 0.820171
global_step: 18885, epoch: 73, loss: 0.829323
global_step: 18886, epoch: 73, loss: 0.725268
global_step: 18887, epoch: 73, loss: 0.784420
global_step: 18888, epoch: 73, loss: 0.892263
global_step: 18889, epoch: 73, loss: 0.810694
global_step: 18890, epoch: 73, loss: 0.748546
global_step: 18891, epoch: 73, loss: 0.909524
global_step: 18892, epoch: 73, loss: 0.867962
global_step: 18893, epoch: 73, loss: 0.796854
global_step: 18894, epoch: 73, loss: 0.787198
global_step: 18895, epoch: 73, loss: 0.867055
global_step: 18896, epoch: 73, loss: 0.890093
global_step: 18897, epoch: 73, loss: 0.745828
global_step: 18898, epoch: 73, loss: 0.863434
global_step: 18899, epoch: 73, loss: 0.925583
global_step: 18900, epoch: 73, loss: 0.808277
global_step: 18901, epoch: 73, loss: 0.790086
global_step: 18902, epoch: 73, loss: 0.706279
global_step: 18903, epoch: 73, loss: 0.799958
global_step: 18904, epoch: 73, loss: 0.783404
global_step: 18905, epoch: 73, loss: 0.795751
global_step: 18906, epoch: 73, loss: 0.809103
global_step: 18907, epoch: 73, loss: 0.735666
global_step: 18908, epoch: 73, loss: 0.855179
global_step: 18909, epoch: 73, loss: 0.880543
global_step: 18910, epoch: 73, loss: 0.751751
global_step: 18911, epoch: 73, loss: 0.819134
global_step: 18912, epoch: 73, loss: 0.828658
global_step: 18913, epoch: 73, loss: 0.728443
global_step: 18914, epoch: 73, loss: 0.771048
global_step: 18915, epoch: 73, loss: 0.856296
global_step: 18916, epoch: 73, loss: 0.759026
global_step: 18917, epoch: 73, loss: 0.751643
global_step: 18918, epoch: 73, loss: 0.802953
global_step: 18919, epoch: 73, loss: 0.880943
global_step: 18920, epoch: 73, loss: 0.975519
epoch: 73
train	acc: 0.8214	macro: p 0.8455, r 0.5750, f1: 0.5760	micro: p 0.8214, r 0.8214, f1 0.8214	weighted_f1:0.7982
dev	acc: 0.5473	macro: p 0.3316, r 0.3142, f1: 0.3078	micro: p 0.5473, r 0.5473, f1 0.5473	weighted_f1:0.5002
test	acc: 0.5981	macro: p 0.3539, r 0.3240, f1: 0.3243	micro: p 0.5981, r 0.5981, f1 0.5981	weighted_f1:0.5569
global_step: 18921, epoch: 74, loss: 0.901408
global_step: 18922, epoch: 74, loss: 0.846646
global_step: 18923, epoch: 74, loss: 0.721772
global_step: 18924, epoch: 74, loss: 0.835475
global_step: 18925, epoch: 74, loss: 0.836840
global_step: 18926, epoch: 74, loss: 0.891116
global_step: 18927, epoch: 74, loss: 0.849344
global_step: 18928, epoch: 74, loss: 0.816940
global_step: 18929, epoch: 74, loss: 0.850724
global_step: 18930, epoch: 74, loss: 0.846643
global_step: 18931, epoch: 74, loss: 0.814790
global_step: 18932, epoch: 74, loss: 0.751379
global_step: 18933, epoch: 74, loss: 0.708138
global_step: 18934, epoch: 74, loss: 0.786033
global_step: 18935, epoch: 74, loss: 0.766916
global_step: 18936, epoch: 74, loss: 0.750839
global_step: 18937, epoch: 74, loss: 0.784885
global_step: 18938, epoch: 74, loss: 0.869468
global_step: 18939, epoch: 74, loss: 0.909011
global_step: 18940, epoch: 74, loss: 0.923267
global_step: 18941, epoch: 74, loss: 0.749599
global_step: 18942, epoch: 74, loss: 0.784911
global_step: 18943, epoch: 74, loss: 0.801745
global_step: 18944, epoch: 74, loss: 0.844485
global_step: 18945, epoch: 74, loss: 0.759165
global_step: 18946, epoch: 74, loss: 0.799387
global_step: 18947, epoch: 74, loss: 0.788393
global_step: 18948, epoch: 74, loss: 0.854937
global_step: 18949, epoch: 74, loss: 0.850437
global_step: 18950, epoch: 74, loss: 0.750955
global_step: 18951, epoch: 74, loss: 0.730996
global_step: 18952, epoch: 74, loss: 0.847812
global_step: 18953, epoch: 74, loss: 0.790644
global_step: 18954, epoch: 74, loss: 0.749817
global_step: 18955, epoch: 74, loss: 0.661500
global_step: 18956, epoch: 74, loss: 0.789071
global_step: 18957, epoch: 74, loss: 0.709656
global_step: 18958, epoch: 74, loss: 0.682421
global_step: 18959, epoch: 74, loss: 0.894236
global_step: 18960, epoch: 74, loss: 1.002042
epoch: 74
train	acc: 0.8109	macro: p 0.8492, r 0.5560, f1: 0.5702	micro: p 0.8109, r 0.8109, f1 0.8109	weighted_f1:0.7863
dev	acc: 0.5455	macro: p 0.3234, r 0.3032, f1: 0.2943	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4905
test	acc: 0.5996	macro: p 0.3662, r 0.3179, f1: 0.3184	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5525
global_step: 18961, epoch: 75, loss: 0.853683
global_step: 18962, epoch: 75, loss: 0.803376
global_step: 18963, epoch: 75, loss: 0.744447
global_step: 18964, epoch: 75, loss: 0.824028
global_step: 18965, epoch: 75, loss: 0.809832
global_step: 18966, epoch: 75, loss: 0.784249
global_step: 18967, epoch: 75, loss: 0.720276
global_step: 18968, epoch: 75, loss: 0.797099
global_step: 18969, epoch: 75, loss: 0.761078
global_step: 18970, epoch: 75, loss: 0.751996
global_step: 18971, epoch: 75, loss: 0.854666
global_step: 18972, epoch: 75, loss: 0.763163
global_step: 18973, epoch: 75, loss: 0.751029
global_step: 18974, epoch: 75, loss: 0.738398
global_step: 18975, epoch: 75, loss: 0.746568
global_step: 18976, epoch: 75, loss: 0.729638
global_step: 18977, epoch: 75, loss: 0.773671
global_step: 18978, epoch: 75, loss: 0.807139
global_step: 18979, epoch: 75, loss: 0.754297
global_step: 18980, epoch: 75, loss: 0.839955
global_step: 18981, epoch: 75, loss: 0.830747
global_step: 18982, epoch: 75, loss: 0.781400
global_step: 18983, epoch: 75, loss: 0.665905
global_step: 18984, epoch: 75, loss: 0.868637
global_step: 18985, epoch: 75, loss: 0.852356
global_step: 18986, epoch: 75, loss: 0.815695
global_step: 18987, epoch: 75, loss: 0.872884
global_step: 18988, epoch: 75, loss: 0.810680
global_step: 18989, epoch: 75, loss: 0.872926
global_step: 18990, epoch: 75, loss: 0.849011
global_step: 18991, epoch: 75, loss: 0.818646
global_step: 18992, epoch: 75, loss: 0.729567
global_step: 18993, epoch: 75, loss: 0.730541
global_step: 18994, epoch: 75, loss: 0.791459
global_step: 18995, epoch: 75, loss: 0.810819
global_step: 18996, epoch: 75, loss: 0.793430
global_step: 18997, epoch: 75, loss: 0.889177
global_step: 18998, epoch: 75, loss: 0.706950
global_step: 18999, epoch: 75, loss: 0.792606
global_step: 19000, epoch: 75, loss: 0.925398
epoch: 75
train	acc: 0.8177	macro: p 0.8523, r 0.5666, f1: 0.5794	micro: p 0.8177, r 0.8177, f1 0.8177	weighted_f1:0.7933
dev	acc: 0.5482	macro: p 0.3370, r 0.3088, f1: 0.3002	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4947
test	acc: 0.5950	macro: p 0.3546, r 0.3156, f1: 0.3127	micro: p 0.5950, r 0.5950, f1 0.5950	weighted_f1:0.5470
global_step: 19001, epoch: 76, loss: 0.798434
global_step: 19002, epoch: 76, loss: 0.728840
global_step: 19003, epoch: 76, loss: 0.806934
global_step: 19004, epoch: 76, loss: 0.769779
global_step: 19005, epoch: 76, loss: 0.803972
global_step: 19006, epoch: 76, loss: 0.883374
global_step: 19007, epoch: 76, loss: 0.858076
global_step: 19008, epoch: 76, loss: 0.734507
global_step: 19009, epoch: 76, loss: 0.786133
global_step: 19010, epoch: 76, loss: 0.729246
global_step: 19011, epoch: 76, loss: 0.652395
global_step: 19012, epoch: 76, loss: 0.831076
global_step: 19013, epoch: 76, loss: 0.739184
global_step: 19014, epoch: 76, loss: 0.694798
global_step: 19015, epoch: 76, loss: 0.845147
global_step: 19016, epoch: 76, loss: 0.826010
global_step: 19017, epoch: 76, loss: 0.848562
global_step: 19018, epoch: 76, loss: 0.761379
global_step: 19019, epoch: 76, loss: 0.750631
global_step: 19020, epoch: 76, loss: 0.805357
global_step: 19021, epoch: 76, loss: 0.921074
global_step: 19022, epoch: 76, loss: 0.819065
global_step: 19023, epoch: 76, loss: 0.804728
global_step: 19024, epoch: 76, loss: 0.798226
global_step: 19025, epoch: 76, loss: 0.700622
global_step: 19026, epoch: 76, loss: 0.809397
global_step: 19027, epoch: 76, loss: 0.852015
global_step: 19028, epoch: 76, loss: 0.786991
global_step: 19029, epoch: 76, loss: 0.709532
global_step: 19030, epoch: 76, loss: 0.743938
global_step: 19031, epoch: 76, loss: 0.726727
global_step: 19032, epoch: 76, loss: 0.815383
global_step: 19033, epoch: 76, loss: 0.730016
global_step: 19034, epoch: 76, loss: 0.800506
global_step: 19035, epoch: 76, loss: 0.840004
global_step: 19036, epoch: 76, loss: 0.777212
global_step: 19037, epoch: 76, loss: 0.875398
global_step: 19038, epoch: 76, loss: 0.707961
global_step: 19039, epoch: 76, loss: 0.810613
global_step: 19040, epoch: 76, loss: 1.120240
epoch: 76
train	acc: 0.8309	macro: p 0.8542, r 0.5908, f1: 0.6003	micro: p 0.8309, r 0.8309, f1 0.8309	weighted_f1:0.8093
dev	acc: 0.5509	macro: p 0.3316, r 0.3183, f1: 0.3096	micro: p 0.5509, r 0.5509, f1 0.5509	weighted_f1:0.5024
test	acc: 0.5973	macro: p 0.3529, r 0.3227, f1: 0.3207	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5544
global_step: 19041, epoch: 77, loss: 0.668136
global_step: 19042, epoch: 77, loss: 0.778586
global_step: 19043, epoch: 77, loss: 0.853064
global_step: 19044, epoch: 77, loss: 0.803992
global_step: 19045, epoch: 77, loss: 0.815636
global_step: 19046, epoch: 77, loss: 0.777644
global_step: 19047, epoch: 77, loss: 0.812738
global_step: 19048, epoch: 77, loss: 0.733580
global_step: 19049, epoch: 77, loss: 0.815489
global_step: 19050, epoch: 77, loss: 0.846901
global_step: 19051, epoch: 77, loss: 0.717792
global_step: 19052, epoch: 77, loss: 0.694547
global_step: 19053, epoch: 77, loss: 0.839422
global_step: 19054, epoch: 77, loss: 0.770484
global_step: 19055, epoch: 77, loss: 0.824304
global_step: 19056, epoch: 77, loss: 0.772441
global_step: 19057, epoch: 77, loss: 0.902675
global_step: 19058, epoch: 77, loss: 0.759019
global_step: 19059, epoch: 77, loss: 0.895520
global_step: 19060, epoch: 77, loss: 0.776573
global_step: 19061, epoch: 77, loss: 0.777851
global_step: 19062, epoch: 77, loss: 0.658363
global_step: 19063, epoch: 77, loss: 0.705061
global_step: 19064, epoch: 77, loss: 0.724642
global_step: 19065, epoch: 77, loss: 0.680572
global_step: 19066, epoch: 77, loss: 0.817275
global_step: 19067, epoch: 77, loss: 0.795878
global_step: 19068, epoch: 77, loss: 0.850577
global_step: 19069, epoch: 77, loss: 0.771117
global_step: 19070, epoch: 77, loss: 0.776643
global_step: 19071, epoch: 77, loss: 0.777240
global_step: 19072, epoch: 77, loss: 0.870466
global_step: 19073, epoch: 77, loss: 0.887500
global_step: 19074, epoch: 77, loss: 0.784944
global_step: 19075, epoch: 77, loss: 0.788856
global_step: 19076, epoch: 77, loss: 0.759219
global_step: 19077, epoch: 77, loss: 0.922723
global_step: 19078, epoch: 77, loss: 0.740654
global_step: 19079, epoch: 77, loss: 0.718095
global_step: 19080, epoch: 77, loss: 0.434912
epoch: 77
train	acc: 0.8215	macro: p 0.8566, r 0.5741, f1: 0.5891	micro: p 0.8215, r 0.8215, f1 0.8215	weighted_f1:0.7989
dev	acc: 0.5500	macro: p 0.3297, r 0.3070, f1: 0.3008	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.4980
test	acc: 0.5985	macro: p 0.3598, r 0.3175, f1: 0.3186	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5536
global_step: 19081, epoch: 78, loss: 0.752979
global_step: 19082, epoch: 78, loss: 0.821501
global_step: 19083, epoch: 78, loss: 0.812170
global_step: 19084, epoch: 78, loss: 0.651437
global_step: 19085, epoch: 78, loss: 0.834506
global_step: 19086, epoch: 78, loss: 0.717696
global_step: 19087, epoch: 78, loss: 0.831923
global_step: 19088, epoch: 78, loss: 0.712152
global_step: 19089, epoch: 78, loss: 0.863742
global_step: 19090, epoch: 78, loss: 0.708315
global_step: 19091, epoch: 78, loss: 0.723609
global_step: 19092, epoch: 78, loss: 0.724997
global_step: 19093, epoch: 78, loss: 0.735452
global_step: 19094, epoch: 78, loss: 0.772476
global_step: 19095, epoch: 78, loss: 0.867542
global_step: 19096, epoch: 78, loss: 0.873425
global_step: 19097, epoch: 78, loss: 0.763956
global_step: 19098, epoch: 78, loss: 0.772426
global_step: 19099, epoch: 78, loss: 0.830649
global_step: 19100, epoch: 78, loss: 0.755839
global_step: 19101, epoch: 78, loss: 0.835092
global_step: 19102, epoch: 78, loss: 0.762591
global_step: 19103, epoch: 78, loss: 0.798177
global_step: 19104, epoch: 78, loss: 0.703504
global_step: 19105, epoch: 78, loss: 0.815423
global_step: 19106, epoch: 78, loss: 0.782745
global_step: 19107, epoch: 78, loss: 0.836106
global_step: 19108, epoch: 78, loss: 0.768475
global_step: 19109, epoch: 78, loss: 0.760390
global_step: 19110, epoch: 78, loss: 0.737342
global_step: 19111, epoch: 78, loss: 0.731238
global_step: 19112, epoch: 78, loss: 0.863820
global_step: 19113, epoch: 78, loss: 0.729126
global_step: 19114, epoch: 78, loss: 0.745012
global_step: 19115, epoch: 78, loss: 0.820368
global_step: 19116, epoch: 78, loss: 0.787719
global_step: 19117, epoch: 78, loss: 0.835372
global_step: 19118, epoch: 78, loss: 0.844794
global_step: 19119, epoch: 78, loss: 0.686097
global_step: 19120, epoch: 78, loss: 1.013546
epoch: 78
train	acc: 0.8386	macro: p 0.8551, r 0.6073, f1: 0.6167	micro: p 0.8386, r 0.8386, f1 0.8386	weighted_f1:0.8190
dev	acc: 0.5410	macro: p 0.3229, r 0.3086, f1: 0.3028	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4941
test	acc: 0.5996	macro: p 0.3535, r 0.3270, f1: 0.3284	micro: p 0.5996, r 0.5996, f1 0.5996	weighted_f1:0.5597
global_step: 19121, epoch: 79, loss: 0.745087
global_step: 19122, epoch: 79, loss: 0.758562
global_step: 19123, epoch: 79, loss: 0.715096
global_step: 19124, epoch: 79, loss: 0.811716
global_step: 19125, epoch: 79, loss: 0.753285
global_step: 19126, epoch: 79, loss: 0.728010
global_step: 19127, epoch: 79, loss: 0.783422
global_step: 19128, epoch: 79, loss: 0.737759
global_step: 19129, epoch: 79, loss: 0.762798
global_step: 19130, epoch: 79, loss: 0.770300
global_step: 19131, epoch: 79, loss: 0.774158
global_step: 19132, epoch: 79, loss: 0.844458
global_step: 19133, epoch: 79, loss: 0.748845
global_step: 19134, epoch: 79, loss: 0.789538
global_step: 19135, epoch: 79, loss: 0.734163
global_step: 19136, epoch: 79, loss: 0.692108
global_step: 19137, epoch: 79, loss: 0.701662
global_step: 19138, epoch: 79, loss: 0.744306
global_step: 19139, epoch: 79, loss: 0.822399
global_step: 19140, epoch: 79, loss: 0.818009
global_step: 19141, epoch: 79, loss: 0.764453
global_step: 19142, epoch: 79, loss: 0.906330
global_step: 19143, epoch: 79, loss: 0.572495
global_step: 19144, epoch: 79, loss: 0.837844
global_step: 19145, epoch: 79, loss: 0.774301
global_step: 19146, epoch: 79, loss: 0.575662
global_step: 19147, epoch: 79, loss: 0.766657
global_step: 19148, epoch: 79, loss: 0.795677
global_step: 19149, epoch: 79, loss: 0.773809
global_step: 19150, epoch: 79, loss: 0.715986
global_step: 19151, epoch: 79, loss: 0.670333
global_step: 19152, epoch: 79, loss: 0.819177
global_step: 19153, epoch: 79, loss: 0.788742
global_step: 19154, epoch: 79, loss: 0.800166
global_step: 19155, epoch: 79, loss: 0.847819
global_step: 19156, epoch: 79, loss: 0.755699
global_step: 19157, epoch: 79, loss: 0.785671
global_step: 19158, epoch: 79, loss: 0.745030
global_step: 19159, epoch: 79, loss: 0.783088
global_step: 19160, epoch: 79, loss: 0.712814
epoch: 79
train	acc: 0.8359	macro: p 0.8578, r 0.6009, f1: 0.6116	micro: p 0.8359, r 0.8359, f1 0.8359	weighted_f1:0.8159
dev	acc: 0.5500	macro: p 0.3324, r 0.3128, f1: 0.3090	micro: p 0.5500, r 0.5500, f1 0.5500	weighted_f1:0.5027
test	acc: 0.5992	macro: p 0.3609, r 0.3232, f1: 0.3262	micro: p 0.5992, r 0.5992, f1 0.5992	weighted_f1:0.5582
global_step: 19161, epoch: 80, loss: 0.725483
global_step: 19162, epoch: 80, loss: 0.829796
global_step: 19163, epoch: 80, loss: 0.686800
global_step: 19164, epoch: 80, loss: 0.794099
global_step: 19165, epoch: 80, loss: 0.754396
global_step: 19166, epoch: 80, loss: 0.813059
global_step: 19167, epoch: 80, loss: 0.779577
global_step: 19168, epoch: 80, loss: 0.825964
global_step: 19169, epoch: 80, loss: 0.766766
global_step: 19170, epoch: 80, loss: 0.734794
global_step: 19171, epoch: 80, loss: 0.702100
global_step: 19172, epoch: 80, loss: 0.717728
global_step: 19173, epoch: 80, loss: 0.808198
global_step: 19174, epoch: 80, loss: 0.764821
global_step: 19175, epoch: 80, loss: 0.811053
global_step: 19176, epoch: 80, loss: 0.739168
global_step: 19177, epoch: 80, loss: 0.849643
global_step: 19178, epoch: 80, loss: 0.616485
global_step: 19179, epoch: 80, loss: 0.725398
global_step: 19180, epoch: 80, loss: 0.762021
global_step: 19181, epoch: 80, loss: 0.772334
global_step: 19182, epoch: 80, loss: 0.772205
global_step: 19183, epoch: 80, loss: 0.846071
global_step: 19184, epoch: 80, loss: 0.735257
global_step: 19185, epoch: 80, loss: 0.769666
global_step: 19186, epoch: 80, loss: 0.815299
global_step: 19187, epoch: 80, loss: 0.735116
global_step: 19188, epoch: 80, loss: 0.728141
global_step: 19189, epoch: 80, loss: 0.743570
global_step: 19190, epoch: 80, loss: 0.774565
global_step: 19191, epoch: 80, loss: 0.764947
global_step: 19192, epoch: 80, loss: 0.731625
global_step: 19193, epoch: 80, loss: 0.749778
global_step: 19194, epoch: 80, loss: 0.797879
global_step: 19195, epoch: 80, loss: 0.770317
global_step: 19196, epoch: 80, loss: 0.731740
global_step: 19197, epoch: 80, loss: 0.741879
global_step: 19198, epoch: 80, loss: 0.761919
global_step: 19199, epoch: 80, loss: 0.743391
global_step: 19200, epoch: 80, loss: 1.003555
epoch: 80
train	acc: 0.8417	macro: p 0.8634, r 0.6122, f1: 0.6285	micro: p 0.8417, r 0.8417, f1 0.8417	weighted_f1:0.8232
dev	acc: 0.5410	macro: p 0.3237, r 0.3060, f1: 0.2983	micro: p 0.5410, r 0.5410, f1 0.5410	weighted_f1:0.4918
test	acc: 0.5958	macro: p 0.3574, r 0.3184, f1: 0.3202	micro: p 0.5958, r 0.5958, f1 0.5958	weighted_f1:0.5528
global_step: 19201, epoch: 81, loss: 0.738832
global_step: 19202, epoch: 81, loss: 0.789406
global_step: 19203, epoch: 81, loss: 0.727268
global_step: 19204, epoch: 81, loss: 0.676643
global_step: 19205, epoch: 81, loss: 0.774743
global_step: 19206, epoch: 81, loss: 0.796332
global_step: 19207, epoch: 81, loss: 0.704756
global_step: 19208, epoch: 81, loss: 0.751333
global_step: 19209, epoch: 81, loss: 0.721966
global_step: 19210, epoch: 81, loss: 0.724351
global_step: 19211, epoch: 81, loss: 0.804946
global_step: 19212, epoch: 81, loss: 0.790480
global_step: 19213, epoch: 81, loss: 0.695024
global_step: 19214, epoch: 81, loss: 0.730101
global_step: 19215, epoch: 81, loss: 0.759839
global_step: 19216, epoch: 81, loss: 0.798087
global_step: 19217, epoch: 81, loss: 0.778012
global_step: 19218, epoch: 81, loss: 0.773345
global_step: 19219, epoch: 81, loss: 0.832804
global_step: 19220, epoch: 81, loss: 0.682330
global_step: 19221, epoch: 81, loss: 0.924084
global_step: 19222, epoch: 81, loss: 0.741774
global_step: 19223, epoch: 81, loss: 0.742830
global_step: 19224, epoch: 81, loss: 0.762453
global_step: 19225, epoch: 81, loss: 0.786332
global_step: 19226, epoch: 81, loss: 0.821950
global_step: 19227, epoch: 81, loss: 0.716839
global_step: 19228, epoch: 81, loss: 0.706306
global_step: 19229, epoch: 81, loss: 0.699971
global_step: 19230, epoch: 81, loss: 0.808406
global_step: 19231, epoch: 81, loss: 0.782590
global_step: 19232, epoch: 81, loss: 0.774746
global_step: 19233, epoch: 81, loss: 0.716661
global_step: 19234, epoch: 81, loss: 0.696862
global_step: 19235, epoch: 81, loss: 0.728460
global_step: 19236, epoch: 81, loss: 0.770229
global_step: 19237, epoch: 81, loss: 0.737111
global_step: 19238, epoch: 81, loss: 0.717574
global_step: 19239, epoch: 81, loss: 0.630042
global_step: 19240, epoch: 81, loss: 0.893998
epoch: 81
train	acc: 0.8401	macro: p 0.8620, r 0.6034, f1: 0.6186	micro: p 0.8401, r 0.8401, f1 0.8401	weighted_f1:0.8197
dev	acc: 0.5419	macro: p 0.3204, r 0.3041, f1: 0.2954	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4900
test	acc: 0.5977	macro: p 0.3599, r 0.3188, f1: 0.3188	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5525
global_step: 19241, epoch: 82, loss: 0.739551
global_step: 19242, epoch: 82, loss: 0.750025
global_step: 19243, epoch: 82, loss: 0.776911
global_step: 19244, epoch: 82, loss: 0.796814
global_step: 19245, epoch: 82, loss: 0.689317
global_step: 19246, epoch: 82, loss: 0.692509
global_step: 19247, epoch: 82, loss: 0.730570
global_step: 19248, epoch: 82, loss: 0.780473
global_step: 19249, epoch: 82, loss: 0.761379
global_step: 19250, epoch: 82, loss: 0.793357
global_step: 19251, epoch: 82, loss: 0.708173
global_step: 19252, epoch: 82, loss: 0.801462
global_step: 19253, epoch: 82, loss: 0.773050
global_step: 19254, epoch: 82, loss: 0.792924
global_step: 19255, epoch: 82, loss: 0.626703
global_step: 19256, epoch: 82, loss: 0.861030
global_step: 19257, epoch: 82, loss: 0.686763
global_step: 19258, epoch: 82, loss: 0.830569
global_step: 19259, epoch: 82, loss: 0.692565
global_step: 19260, epoch: 82, loss: 0.726060
global_step: 19261, epoch: 82, loss: 0.679132
global_step: 19262, epoch: 82, loss: 0.746647
global_step: 19263, epoch: 82, loss: 0.772457
global_step: 19264, epoch: 82, loss: 0.729716
global_step: 19265, epoch: 82, loss: 0.794908
global_step: 19266, epoch: 82, loss: 0.750821
global_step: 19267, epoch: 82, loss: 0.693822
global_step: 19268, epoch: 82, loss: 0.724315
global_step: 19269, epoch: 82, loss: 0.792100
global_step: 19270, epoch: 82, loss: 0.727891
global_step: 19271, epoch: 82, loss: 0.700204
global_step: 19272, epoch: 82, loss: 0.768185
global_step: 19273, epoch: 82, loss: 0.865964
global_step: 19274, epoch: 82, loss: 0.733341
global_step: 19275, epoch: 82, loss: 0.769359
global_step: 19276, epoch: 82, loss: 0.706573
global_step: 19277, epoch: 82, loss: 0.688213
global_step: 19278, epoch: 82, loss: 0.702067
global_step: 19279, epoch: 82, loss: 0.792066
global_step: 19280, epoch: 82, loss: 0.559933
epoch: 82
train	acc: 0.8487	macro: p 0.8666, r 0.6238, f1: 0.6381	micro: p 0.8487, r 0.8487, f1 0.8487	weighted_f1:0.8306
dev	acc: 0.5464	macro: p 0.3285, r 0.3120, f1: 0.3067	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4991
test	acc: 0.5973	macro: p 0.3567, r 0.3251, f1: 0.3279	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5574
global_step: 19281, epoch: 83, loss: 0.663258
global_step: 19282, epoch: 83, loss: 0.707160
global_step: 19283, epoch: 83, loss: 0.805804
global_step: 19284, epoch: 83, loss: 0.779487
global_step: 19285, epoch: 83, loss: 0.738245
global_step: 19286, epoch: 83, loss: 0.739307
global_step: 19287, epoch: 83, loss: 0.821035
global_step: 19288, epoch: 83, loss: 0.720971
global_step: 19289, epoch: 83, loss: 0.725891
global_step: 19290, epoch: 83, loss: 0.714062
global_step: 19291, epoch: 83, loss: 0.689057
global_step: 19292, epoch: 83, loss: 0.681817
global_step: 19293, epoch: 83, loss: 0.741211
global_step: 19294, epoch: 83, loss: 0.757993
global_step: 19295, epoch: 83, loss: 0.677721
global_step: 19296, epoch: 83, loss: 0.773256
global_step: 19297, epoch: 83, loss: 0.695272
global_step: 19298, epoch: 83, loss: 0.732450
global_step: 19299, epoch: 83, loss: 0.796846
global_step: 19300, epoch: 83, loss: 0.796099
global_step: 19301, epoch: 83, loss: 0.784951
global_step: 19302, epoch: 83, loss: 0.675907
global_step: 19303, epoch: 83, loss: 0.777398
global_step: 19304, epoch: 83, loss: 0.695814
global_step: 19305, epoch: 83, loss: 0.717335
global_step: 19306, epoch: 83, loss: 0.822844
global_step: 19307, epoch: 83, loss: 0.786066
global_step: 19308, epoch: 83, loss: 0.701180
global_step: 19309, epoch: 83, loss: 0.705784
global_step: 19310, epoch: 83, loss: 0.732322
global_step: 19311, epoch: 83, loss: 0.695254
global_step: 19312, epoch: 83, loss: 0.652567
global_step: 19313, epoch: 83, loss: 0.807698
global_step: 19314, epoch: 83, loss: 0.756444
global_step: 19315, epoch: 83, loss: 0.741824
global_step: 19316, epoch: 83, loss: 0.749418
global_step: 19317, epoch: 83, loss: 0.770291
global_step: 19318, epoch: 83, loss: 0.632441
global_step: 19319, epoch: 83, loss: 0.757722
global_step: 19320, epoch: 83, loss: 0.697756
epoch: 83
train	acc: 0.8351	macro: p 0.8695, r 0.6039, f1: 0.6297	micro: p 0.8351, r 0.8351, f1 0.8351	weighted_f1:0.8158
dev	acc: 0.5491	macro: p 0.3291, r 0.3066, f1: 0.3016	micro: p 0.5491, r 0.5491, f1 0.5491	weighted_f1:0.4962
test	acc: 0.6038	macro: p 0.3649, r 0.3169, f1: 0.3210	micro: p 0.6038, r 0.6038, f1 0.6038	weighted_f1:0.5554
global_step: 19321, epoch: 84, loss: 0.905647
global_step: 19322, epoch: 84, loss: 0.545250
global_step: 19323, epoch: 84, loss: 0.740652
global_step: 19324, epoch: 84, loss: 0.653677
global_step: 19325, epoch: 84, loss: 0.730930
global_step: 19326, epoch: 84, loss: 0.623414
global_step: 19327, epoch: 84, loss: 0.772208
global_step: 19328, epoch: 84, loss: 0.760588
global_step: 19329, epoch: 84, loss: 0.746961
global_step: 19330, epoch: 84, loss: 0.719940
global_step: 19331, epoch: 84, loss: 0.651411
global_step: 19332, epoch: 84, loss: 0.727412
global_step: 19333, epoch: 84, loss: 0.735245
global_step: 19334, epoch: 84, loss: 0.740032
global_step: 19335, epoch: 84, loss: 0.731410
global_step: 19336, epoch: 84, loss: 0.721245
global_step: 19337, epoch: 84, loss: 0.702350
global_step: 19338, epoch: 84, loss: 0.804317
global_step: 19339, epoch: 84, loss: 0.789490
global_step: 19340, epoch: 84, loss: 0.813449
global_step: 19341, epoch: 84, loss: 0.700141
global_step: 19342, epoch: 84, loss: 0.700835
global_step: 19343, epoch: 84, loss: 0.726541
global_step: 19344, epoch: 84, loss: 0.741183
global_step: 19345, epoch: 84, loss: 0.705282
global_step: 19346, epoch: 84, loss: 0.738541
global_step: 19347, epoch: 84, loss: 0.713884
global_step: 19348, epoch: 84, loss: 0.758298
global_step: 19349, epoch: 84, loss: 0.758533
global_step: 19350, epoch: 84, loss: 0.824274
global_step: 19351, epoch: 84, loss: 0.741401
global_step: 19352, epoch: 84, loss: 0.777047
global_step: 19353, epoch: 84, loss: 0.687189
global_step: 19354, epoch: 84, loss: 0.791480
global_step: 19355, epoch: 84, loss: 0.656996
global_step: 19356, epoch: 84, loss: 0.767066
global_step: 19357, epoch: 84, loss: 0.785244
global_step: 19358, epoch: 84, loss: 0.704374
global_step: 19359, epoch: 84, loss: 0.678842
global_step: 19360, epoch: 84, loss: 1.303315
epoch: 84
train	acc: 0.8505	macro: p 0.8695, r 0.6333, f1: 0.6553	micro: p 0.8505, r 0.8505, f1 0.8505	weighted_f1:0.8342
dev	acc: 0.5437	macro: p 0.3218, r 0.3058, f1: 0.2982	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4923
test	acc: 0.5954	macro: p 0.3502, r 0.3167, f1: 0.3167	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5501
global_step: 19361, epoch: 85, loss: 0.665671
global_step: 19362, epoch: 85, loss: 0.714516
global_step: 19363, epoch: 85, loss: 0.698275
global_step: 19364, epoch: 85, loss: 0.686289
global_step: 19365, epoch: 85, loss: 0.740139
global_step: 19366, epoch: 85, loss: 0.650728
global_step: 19367, epoch: 85, loss: 0.704543
global_step: 19368, epoch: 85, loss: 0.678523
global_step: 19369, epoch: 85, loss: 0.685092
global_step: 19370, epoch: 85, loss: 0.775292
global_step: 19371, epoch: 85, loss: 0.738305
global_step: 19372, epoch: 85, loss: 0.712500
global_step: 19373, epoch: 85, loss: 0.751318
global_step: 19374, epoch: 85, loss: 0.764035
global_step: 19375, epoch: 85, loss: 0.634155
global_step: 19376, epoch: 85, loss: 0.691702
global_step: 19377, epoch: 85, loss: 0.675798
global_step: 19378, epoch: 85, loss: 0.735720
global_step: 19379, epoch: 85, loss: 0.764574
global_step: 19380, epoch: 85, loss: 0.726100
global_step: 19381, epoch: 85, loss: 0.671556
global_step: 19382, epoch: 85, loss: 0.697011
global_step: 19383, epoch: 85, loss: 0.722420
global_step: 19384, epoch: 85, loss: 0.688506
global_step: 19385, epoch: 85, loss: 0.764604
global_step: 19386, epoch: 85, loss: 0.655834
global_step: 19387, epoch: 85, loss: 0.888744
global_step: 19388, epoch: 85, loss: 0.604321
global_step: 19389, epoch: 85, loss: 0.619595
global_step: 19390, epoch: 85, loss: 0.763759
global_step: 19391, epoch: 85, loss: 0.670678
global_step: 19392, epoch: 85, loss: 0.756503
global_step: 19393, epoch: 85, loss: 0.716201
global_step: 19394, epoch: 85, loss: 0.687320
global_step: 19395, epoch: 85, loss: 0.741011
global_step: 19396, epoch: 85, loss: 0.795455
global_step: 19397, epoch: 85, loss: 0.798965
global_step: 19398, epoch: 85, loss: 0.694117
global_step: 19399, epoch: 85, loss: 0.701082
global_step: 19400, epoch: 85, loss: 1.326022
epoch: 85
train	acc: 0.8613	macro: p 0.8720, r 0.6560, f1: 0.6769	micro: p 0.8613, r 0.8613, f1 0.8613	weighted_f1:0.8473
dev	acc: 0.5365	macro: p 0.3210, r 0.3078, f1: 0.3021	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4929
test	acc: 0.5966	macro: p 0.3566, r 0.3270, f1: 0.3302	micro: p 0.5966, r 0.5966, f1 0.5966	weighted_f1:0.5596
global_step: 19401, epoch: 86, loss: 0.741199
global_step: 19402, epoch: 86, loss: 0.737021
global_step: 19403, epoch: 86, loss: 0.758112
global_step: 19404, epoch: 86, loss: 0.713207
global_step: 19405, epoch: 86, loss: 0.765849
global_step: 19406, epoch: 86, loss: 0.756612
global_step: 19407, epoch: 86, loss: 0.711662
global_step: 19408, epoch: 86, loss: 0.771302
global_step: 19409, epoch: 86, loss: 0.715992
global_step: 19410, epoch: 86, loss: 0.713672
global_step: 19411, epoch: 86, loss: 0.667852
global_step: 19412, epoch: 86, loss: 0.769272
global_step: 19413, epoch: 86, loss: 0.615784
global_step: 19414, epoch: 86, loss: 0.766099
global_step: 19415, epoch: 86, loss: 0.606338
global_step: 19416, epoch: 86, loss: 0.652270
global_step: 19417, epoch: 86, loss: 0.829504
global_step: 19418, epoch: 86, loss: 0.747853
global_step: 19419, epoch: 86, loss: 0.768115
global_step: 19420, epoch: 86, loss: 0.702022
global_step: 19421, epoch: 86, loss: 0.710722
global_step: 19422, epoch: 86, loss: 0.709429
global_step: 19423, epoch: 86, loss: 0.614529
global_step: 19424, epoch: 86, loss: 0.647818
global_step: 19425, epoch: 86, loss: 0.768643
global_step: 19426, epoch: 86, loss: 0.732068
global_step: 19427, epoch: 86, loss: 0.756842
global_step: 19428, epoch: 86, loss: 0.882363
global_step: 19429, epoch: 86, loss: 0.743282
global_step: 19430, epoch: 86, loss: 0.654136
global_step: 19431, epoch: 86, loss: 0.643636
global_step: 19432, epoch: 86, loss: 0.708144
global_step: 19433, epoch: 86, loss: 0.742016
global_step: 19434, epoch: 86, loss: 0.661604
global_step: 19435, epoch: 86, loss: 0.641541
global_step: 19436, epoch: 86, loss: 0.781468
global_step: 19437, epoch: 86, loss: 0.654992
global_step: 19438, epoch: 86, loss: 0.696074
global_step: 19439, epoch: 86, loss: 0.646512
global_step: 19440, epoch: 86, loss: 0.632156
epoch: 86
train	acc: 0.8565	macro: p 0.8754, r 0.6447, f1: 0.6684	micro: p 0.8565, r 0.8565, f1 0.8565	weighted_f1:0.8410
dev	acc: 0.5365	macro: p 0.3134, r 0.3006, f1: 0.2926	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4858
test	acc: 0.5985	macro: p 0.3601, r 0.3208, f1: 0.3222	micro: p 0.5985, r 0.5985, f1 0.5985	weighted_f1:0.5546
global_step: 19441, epoch: 87, loss: 0.638180
global_step: 19442, epoch: 87, loss: 0.635155
global_step: 19443, epoch: 87, loss: 0.729926
global_step: 19444, epoch: 87, loss: 0.650087
global_step: 19445, epoch: 87, loss: 0.729290
global_step: 19446, epoch: 87, loss: 0.784039
global_step: 19447, epoch: 87, loss: 0.726022
global_step: 19448, epoch: 87, loss: 0.667486
global_step: 19449, epoch: 87, loss: 0.752325
global_step: 19450, epoch: 87, loss: 0.763510
global_step: 19451, epoch: 87, loss: 0.757437
global_step: 19452, epoch: 87, loss: 0.676423
global_step: 19453, epoch: 87, loss: 0.726847
global_step: 19454, epoch: 87, loss: 0.691286
global_step: 19455, epoch: 87, loss: 0.684678
global_step: 19456, epoch: 87, loss: 0.757146
global_step: 19457, epoch: 87, loss: 0.633970
global_step: 19458, epoch: 87, loss: 0.643653
global_step: 19459, epoch: 87, loss: 0.751115
global_step: 19460, epoch: 87, loss: 0.708435
global_step: 19461, epoch: 87, loss: 0.708478
global_step: 19462, epoch: 87, loss: 0.772898
global_step: 19463, epoch: 87, loss: 0.705005
global_step: 19464, epoch: 87, loss: 0.761064
global_step: 19465, epoch: 87, loss: 0.676462
global_step: 19466, epoch: 87, loss: 0.633707
global_step: 19467, epoch: 87, loss: 0.609607
global_step: 19468, epoch: 87, loss: 0.661971
global_step: 19469, epoch: 87, loss: 0.697654
global_step: 19470, epoch: 87, loss: 0.635324
global_step: 19471, epoch: 87, loss: 0.688105
global_step: 19472, epoch: 87, loss: 0.758834
global_step: 19473, epoch: 87, loss: 0.719436
global_step: 19474, epoch: 87, loss: 0.762681
global_step: 19475, epoch: 87, loss: 0.672422
global_step: 19476, epoch: 87, loss: 0.670504
global_step: 19477, epoch: 87, loss: 0.728450
global_step: 19478, epoch: 87, loss: 0.722012
global_step: 19479, epoch: 87, loss: 0.736421
global_step: 19480, epoch: 87, loss: 0.567736
epoch: 87
train	acc: 0.8567	macro: p 0.8763, r 0.6468, f1: 0.6745	micro: p 0.8567, r 0.8567, f1 0.8567	weighted_f1:0.8418
dev	acc: 0.5464	macro: p 0.3289, r 0.3070, f1: 0.3016	micro: p 0.5464, r 0.5464, f1 0.5464	weighted_f1:0.4959
test	acc: 0.6023	macro: p 0.3660, r 0.3213, f1: 0.3239	micro: p 0.6023, r 0.6023, f1 0.6023	weighted_f1:0.5575
global_step: 19481, epoch: 88, loss: 0.576773
global_step: 19482, epoch: 88, loss: 0.709071
global_step: 19483, epoch: 88, loss: 0.644271
global_step: 19484, epoch: 88, loss: 0.790588
global_step: 19485, epoch: 88, loss: 0.652544
global_step: 19486, epoch: 88, loss: 0.819516
global_step: 19487, epoch: 88, loss: 0.626525
global_step: 19488, epoch: 88, loss: 0.693583
global_step: 19489, epoch: 88, loss: 0.729114
global_step: 19490, epoch: 88, loss: 0.747211
global_step: 19491, epoch: 88, loss: 0.744580
global_step: 19492, epoch: 88, loss: 0.671786
global_step: 19493, epoch: 88, loss: 0.770626
global_step: 19494, epoch: 88, loss: 0.780390
global_step: 19495, epoch: 88, loss: 0.679162
global_step: 19496, epoch: 88, loss: 0.515830
global_step: 19497, epoch: 88, loss: 0.737439
global_step: 19498, epoch: 88, loss: 0.693214
global_step: 19499, epoch: 88, loss: 0.648937
global_step: 19500, epoch: 88, loss: 0.746358
global_step: 19501, epoch: 88, loss: 0.773330
global_step: 19502, epoch: 88, loss: 0.641479
global_step: 19503, epoch: 88, loss: 0.699212
global_step: 19504, epoch: 88, loss: 0.670759
global_step: 19505, epoch: 88, loss: 0.732458
global_step: 19506, epoch: 88, loss: 0.709989
global_step: 19507, epoch: 88, loss: 0.574145
global_step: 19508, epoch: 88, loss: 0.684546
global_step: 19509, epoch: 88, loss: 0.859174
global_step: 19510, epoch: 88, loss: 0.629639
global_step: 19511, epoch: 88, loss: 0.700439
global_step: 19512, epoch: 88, loss: 0.767564
global_step: 19513, epoch: 88, loss: 0.809492
global_step: 19514, epoch: 88, loss: 0.680968
global_step: 19515, epoch: 88, loss: 0.762920
global_step: 19516, epoch: 88, loss: 0.693890
global_step: 19517, epoch: 88, loss: 0.666854
global_step: 19518, epoch: 88, loss: 0.805729
global_step: 19519, epoch: 88, loss: 0.705914
global_step: 19520, epoch: 88, loss: 0.455059
epoch: 88
train	acc: 0.8620	macro: p 0.8745, r 0.6584, f1: 0.6817	micro: p 0.8620, r 0.8620, f1 0.8620	weighted_f1:0.8481
dev	acc: 0.5419	macro: p 0.3224, r 0.3074, f1: 0.3014	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4942
test	acc: 0.6008	macro: p 0.3630, r 0.3270, f1: 0.3307	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5607
global_step: 19521, epoch: 89, loss: 0.628429
global_step: 19522, epoch: 89, loss: 0.603150
global_step: 19523, epoch: 89, loss: 0.681750
global_step: 19524, epoch: 89, loss: 0.794479
global_step: 19525, epoch: 89, loss: 0.588732
global_step: 19526, epoch: 89, loss: 0.721852
global_step: 19527, epoch: 89, loss: 0.760040
global_step: 19528, epoch: 89, loss: 0.660123
global_step: 19529, epoch: 89, loss: 0.693605
global_step: 19530, epoch: 89, loss: 0.684957
global_step: 19531, epoch: 89, loss: 0.654605
global_step: 19532, epoch: 89, loss: 0.672575
global_step: 19533, epoch: 89, loss: 0.649819
global_step: 19534, epoch: 89, loss: 0.691711
global_step: 19535, epoch: 89, loss: 0.735510
global_step: 19536, epoch: 89, loss: 0.712478
global_step: 19537, epoch: 89, loss: 0.818065
global_step: 19538, epoch: 89, loss: 0.692430
global_step: 19539, epoch: 89, loss: 0.645836
global_step: 19540, epoch: 89, loss: 0.723891
global_step: 19541, epoch: 89, loss: 0.745712
global_step: 19542, epoch: 89, loss: 0.681691
global_step: 19543, epoch: 89, loss: 0.727970
global_step: 19544, epoch: 89, loss: 0.818048
global_step: 19545, epoch: 89, loss: 0.777301
global_step: 19546, epoch: 89, loss: 0.715709
global_step: 19547, epoch: 89, loss: 0.649571
global_step: 19548, epoch: 89, loss: 0.736034
global_step: 19549, epoch: 89, loss: 0.751463
global_step: 19550, epoch: 89, loss: 0.818019
global_step: 19551, epoch: 89, loss: 0.698553
global_step: 19552, epoch: 89, loss: 0.687410
global_step: 19553, epoch: 89, loss: 0.737024
global_step: 19554, epoch: 89, loss: 0.740459
global_step: 19555, epoch: 89, loss: 0.693971
global_step: 19556, epoch: 89, loss: 0.790017
global_step: 19557, epoch: 89, loss: 0.593597
global_step: 19558, epoch: 89, loss: 0.580195
global_step: 19559, epoch: 89, loss: 0.756507
global_step: 19560, epoch: 89, loss: 0.285378
epoch: 89
train	acc: 0.8658	macro: p 0.8788, r 0.6626, f1: 0.6864	micro: p 0.8658, r 0.8658, f1 0.8658	weighted_f1:0.8519
dev	acc: 0.5383	macro: p 0.3254, r 0.3091, f1: 0.3009	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4925
test	acc: 0.5923	macro: p 0.3518, r 0.3196, f1: 0.3181	micro: p 0.5923, r 0.5923, f1 0.5923	weighted_f1:0.5514
global_step: 19561, epoch: 90, loss: 0.710676
global_step: 19562, epoch: 90, loss: 0.774710
global_step: 19563, epoch: 90, loss: 0.620987
global_step: 19564, epoch: 90, loss: 0.632404
global_step: 19565, epoch: 90, loss: 0.707577
global_step: 19566, epoch: 90, loss: 0.696688
global_step: 19567, epoch: 90, loss: 0.687795
global_step: 19568, epoch: 90, loss: 0.646428
global_step: 19569, epoch: 90, loss: 0.733463
global_step: 19570, epoch: 90, loss: 0.644631
global_step: 19571, epoch: 90, loss: 0.647206
global_step: 19572, epoch: 90, loss: 0.658187
global_step: 19573, epoch: 90, loss: 0.675071
global_step: 19574, epoch: 90, loss: 0.648769
global_step: 19575, epoch: 90, loss: 0.716480
global_step: 19576, epoch: 90, loss: 0.729365
global_step: 19577, epoch: 90, loss: 0.726544
global_step: 19578, epoch: 90, loss: 0.628908
global_step: 19579, epoch: 90, loss: 0.691782
global_step: 19580, epoch: 90, loss: 0.668283
global_step: 19581, epoch: 90, loss: 0.681810
global_step: 19582, epoch: 90, loss: 0.650537
global_step: 19583, epoch: 90, loss: 0.645644run.py:91: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  nn.utils.clip_grad_norm(parameters, max_norm=params["NORM_LIMIT"])
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
/users5/yjtian/anaconda3/envs/py36th1.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)

global_step: 19584, epoch: 90, loss: 0.748787
global_step: 19585, epoch: 90, loss: 0.704624
global_step: 19586, epoch: 90, loss: 0.738879
global_step: 19587, epoch: 90, loss: 0.606364
global_step: 19588, epoch: 90, loss: 0.715668
global_step: 19589, epoch: 90, loss: 0.641573
global_step: 19590, epoch: 90, loss: 0.700321
global_step: 19591, epoch: 90, loss: 0.657481
global_step: 19592, epoch: 90, loss: 0.711245
global_step: 19593, epoch: 90, loss: 0.686772
global_step: 19594, epoch: 90, loss: 0.638323
global_step: 19595, epoch: 90, loss: 0.805791
global_step: 19596, epoch: 90, loss: 0.703248
global_step: 19597, epoch: 90, loss: 0.782265
global_step: 19598, epoch: 90, loss: 0.663245
global_step: 19599, epoch: 90, loss: 0.724805
global_step: 19600, epoch: 90, loss: 0.273498
epoch: 90
train	acc: 0.8642	macro: p 0.8807, r 0.6645, f1: 0.6934	micro: p 0.8642, r 0.8642, f1 0.8642	weighted_f1:0.8504
dev	acc: 0.5482	macro: p 0.3310, r 0.3095, f1: 0.3031	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4972
test	acc: 0.5977	macro: p 0.3543, r 0.3175, f1: 0.3167	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5514
global_step: 19601, epoch: 91, loss: 0.583977
global_step: 19602, epoch: 91, loss: 0.650480
global_step: 19603, epoch: 91, loss: 0.621580
global_step: 19604, epoch: 91, loss: 0.547726
global_step: 19605, epoch: 91, loss: 0.643721
global_step: 19606, epoch: 91, loss: 0.707150
global_step: 19607, epoch: 91, loss: 0.626113
global_step: 19608, epoch: 91, loss: 0.614939
global_step: 19609, epoch: 91, loss: 0.621686
global_step: 19610, epoch: 91, loss: 0.692526
global_step: 19611, epoch: 91, loss: 0.628146
global_step: 19612, epoch: 91, loss: 0.695201
global_step: 19613, epoch: 91, loss: 0.609198
global_step: 19614, epoch: 91, loss: 0.728689
global_step: 19615, epoch: 91, loss: 0.633366
global_step: 19616, epoch: 91, loss: 0.713768
global_step: 19617, epoch: 91, loss: 0.750881
global_step: 19618, epoch: 91, loss: 0.712834
global_step: 19619, epoch: 91, loss: 0.695019
global_step: 19620, epoch: 91, loss: 0.714638
global_step: 19621, epoch: 91, loss: 0.625719
global_step: 19622, epoch: 91, loss: 0.660277
global_step: 19623, epoch: 91, loss: 0.655976
global_step: 19624, epoch: 91, loss: 0.669177
global_step: 19625, epoch: 91, loss: 0.768933
global_step: 19626, epoch: 91, loss: 0.723573
global_step: 19627, epoch: 91, loss: 0.709673
global_step: 19628, epoch: 91, loss: 0.747521
global_step: 19629, epoch: 91, loss: 0.643794
global_step: 19630, epoch: 91, loss: 0.688512
global_step: 19631, epoch: 91, loss: 0.742732
global_step: 19632, epoch: 91, loss: 0.692752
global_step: 19633, epoch: 91, loss: 0.817700
global_step: 19634, epoch: 91, loss: 0.735749
global_step: 19635, epoch: 91, loss: 0.680805
global_step: 19636, epoch: 91, loss: 0.675667
global_step: 19637, epoch: 91, loss: 0.595545
global_step: 19638, epoch: 91, loss: 0.781504
global_step: 19639, epoch: 91, loss: 0.749649
global_step: 19640, epoch: 91, loss: 0.253024
epoch: 91
train	acc: 0.8705	macro: p 0.8864, r 0.6821, f1: 0.7140	micro: p 0.8705, r 0.8705, f1 0.8705	weighted_f1:0.8588
dev	acc: 0.5455	macro: p 0.3244, r 0.3055, f1: 0.3003	micro: p 0.5455, r 0.5455, f1 0.5455	weighted_f1:0.4951
test	acc: 0.6011	macro: p 0.3617, r 0.3204, f1: 0.3247	micro: p 0.6011, r 0.6011, f1 0.6011	weighted_f1:0.5568
global_step: 19641, epoch: 92, loss: 0.569271
global_step: 19642, epoch: 92, loss: 0.723230
global_step: 19643, epoch: 92, loss: 0.640043
global_step: 19644, epoch: 92, loss: 0.742251
global_step: 19645, epoch: 92, loss: 0.654080
global_step: 19646, epoch: 92, loss: 0.680694
global_step: 19647, epoch: 92, loss: 0.756219
global_step: 19648, epoch: 92, loss: 0.688110
global_step: 19649, epoch: 92, loss: 0.658918
global_step: 19650, epoch: 92, loss: 0.692123
global_step: 19651, epoch: 92, loss: 0.702408
global_step: 19652, epoch: 92, loss: 0.680582
global_step: 19653, epoch: 92, loss: 0.769826
global_step: 19654, epoch: 92, loss: 0.755954
global_step: 19655, epoch: 92, loss: 0.735483
global_step: 19656, epoch: 92, loss: 0.713588
global_step: 19657, epoch: 92, loss: 0.572459
global_step: 19658, epoch: 92, loss: 0.614365
global_step: 19659, epoch: 92, loss: 0.699076
global_step: 19660, epoch: 92, loss: 0.707673
global_step: 19661, epoch: 92, loss: 0.680483
global_step: 19662, epoch: 92, loss: 0.720497
global_step: 19663, epoch: 92, loss: 0.734584
global_step: 19664, epoch: 92, loss: 0.637445
global_step: 19665, epoch: 92, loss: 0.682184
global_step: 19666, epoch: 92, loss: 0.590398
global_step: 19667, epoch: 92, loss: 0.635952
global_step: 19668, epoch: 92, loss: 0.598042
global_step: 19669, epoch: 92, loss: 0.688457
global_step: 19670, epoch: 92, loss: 0.692814
global_step: 19671, epoch: 92, loss: 0.694026
global_step: 19672, epoch: 92, loss: 0.718327
global_step: 19673, epoch: 92, loss: 0.639675
global_step: 19674, epoch: 92, loss: 0.631640
global_step: 19675, epoch: 92, loss: 0.698840
global_step: 19676, epoch: 92, loss: 0.661144
global_step: 19677, epoch: 92, loss: 0.578063
global_step: 19678, epoch: 92, loss: 0.681611
global_step: 19679, epoch: 92, loss: 0.778071
global_step: 19680, epoch: 92, loss: 0.294274
epoch: 92
train	acc: 0.8667	macro: p 0.8892, r 0.6685, f1: 0.7066	micro: p 0.8667, r 0.8667, f1 0.8667	weighted_f1:0.8537
dev	acc: 0.5482	macro: p 0.3285, r 0.3059, f1: 0.2975	micro: p 0.5482, r 0.5482, f1 0.5482	weighted_f1:0.4934
test	acc: 0.6004	macro: p 0.3625, r 0.3172, f1: 0.3175	micro: p 0.6004, r 0.6004, f1 0.6004	weighted_f1:0.5519
global_step: 19681, epoch: 93, loss: 0.642016
global_step: 19682, epoch: 93, loss: 0.640521
global_step: 19683, epoch: 93, loss: 0.594948
global_step: 19684, epoch: 93, loss: 0.674811
global_step: 19685, epoch: 93, loss: 0.681866
global_step: 19686, epoch: 93, loss: 0.616014
global_step: 19687, epoch: 93, loss: 0.584652
global_step: 19688, epoch: 93, loss: 0.650308
global_step: 19689, epoch: 93, loss: 0.634910
global_step: 19690, epoch: 93, loss: 0.661374
global_step: 19691, epoch: 93, loss: 0.644114
global_step: 19692, epoch: 93, loss: 0.705118
global_step: 19693, epoch: 93, loss: 0.695288
global_step: 19694, epoch: 93, loss: 0.700102
global_step: 19695, epoch: 93, loss: 0.617985
global_step: 19696, epoch: 93, loss: 0.602043
global_step: 19697, epoch: 93, loss: 0.714615
global_step: 19698, epoch: 93, loss: 0.646834
global_step: 19699, epoch: 93, loss: 0.795626
global_step: 19700, epoch: 93, loss: 0.716253
global_step: 19701, epoch: 93, loss: 0.660472
global_step: 19702, epoch: 93, loss: 0.694314
global_step: 19703, epoch: 93, loss: 0.692941
global_step: 19704, epoch: 93, loss: 0.675262
global_step: 19705, epoch: 93, loss: 0.635949
global_step: 19706, epoch: 93, loss: 0.752438
global_step: 19707, epoch: 93, loss: 0.720672
global_step: 19708, epoch: 93, loss: 0.655694
global_step: 19709, epoch: 93, loss: 0.601327
global_step: 19710, epoch: 93, loss: 0.686559
global_step: 19711, epoch: 93, loss: 0.629909
global_step: 19712, epoch: 93, loss: 0.720740
global_step: 19713, epoch: 93, loss: 0.703921
global_step: 19714, epoch: 93, loss: 0.733564
global_step: 19715, epoch: 93, loss: 0.665907
global_step: 19716, epoch: 93, loss: 0.615928
global_step: 19717, epoch: 93, loss: 0.651197
global_step: 19718, epoch: 93, loss: 0.677688
global_step: 19719, epoch: 93, loss: 0.731124
global_step: 19720, epoch: 93, loss: 0.407842
epoch: 93
train	acc: 0.8756	macro: p 0.8916, r 0.6950, f1: 0.7328	micro: p 0.8756, r 0.8756, f1 0.8756	weighted_f1:0.8655
dev	acc: 0.5365	macro: p 0.3201, r 0.3030, f1: 0.2946	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4871
test	acc: 0.5969	macro: p 0.3663, r 0.3192, f1: 0.3215	micro: p 0.5969, r 0.5969, f1 0.5969	weighted_f1:0.5528
global_step: 19721, epoch: 94, loss: 0.555941
global_step: 19722, epoch: 94, loss: 0.650848
global_step: 19723, epoch: 94, loss: 0.729610
global_step: 19724, epoch: 94, loss: 0.721274
global_step: 19725, epoch: 94, loss: 0.620707
global_step: 19726, epoch: 94, loss: 0.711021
global_step: 19727, epoch: 94, loss: 0.651782
global_step: 19728, epoch: 94, loss: 0.647590
global_step: 19729, epoch: 94, loss: 0.606912
global_step: 19730, epoch: 94, loss: 0.662675
global_step: 19731, epoch: 94, loss: 0.628149
global_step: 19732, epoch: 94, loss: 0.613572
global_step: 19733, epoch: 94, loss: 0.687963
global_step: 19734, epoch: 94, loss: 0.636004
global_step: 19735, epoch: 94, loss: 0.597700
global_step: 19736, epoch: 94, loss: 0.696849
global_step: 19737, epoch: 94, loss: 0.608625
global_step: 19738, epoch: 94, loss: 0.586375
global_step: 19739, epoch: 94, loss: 0.652333
global_step: 19740, epoch: 94, loss: 0.686067
global_step: 19741, epoch: 94, loss: 0.723828
global_step: 19742, epoch: 94, loss: 0.775656
global_step: 19743, epoch: 94, loss: 0.651111
global_step: 19744, epoch: 94, loss: 0.699250
global_step: 19745, epoch: 94, loss: 0.665338
global_step: 19746, epoch: 94, loss: 0.702896
global_step: 19747, epoch: 94, loss: 0.635950
global_step: 19748, epoch: 94, loss: 0.622753
global_step: 19749, epoch: 94, loss: 0.599318
global_step: 19750, epoch: 94, loss: 0.675394
global_step: 19751, epoch: 94, loss: 0.760335
global_step: 19752, epoch: 94, loss: 0.639764
global_step: 19753, epoch: 94, loss: 0.687599
global_step: 19754, epoch: 94, loss: 0.699877
global_step: 19755, epoch: 94, loss: 0.653734
global_step: 19756, epoch: 94, loss: 0.704466
global_step: 19757, epoch: 94, loss: 0.620299
global_step: 19758, epoch: 94, loss: 0.694428
global_step: 19759, epoch: 94, loss: 0.709410
global_step: 19760, epoch: 94, loss: 0.870395
epoch: 94
train	acc: 0.8778	macro: p 0.8878, r 0.6881, f1: 0.7132	micro: p 0.8778, r 0.8778, f1 0.8778	weighted_f1:0.8661
dev	acc: 0.5356	macro: p 0.3222, r 0.3073, f1: 0.3037	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4934
test	acc: 0.5943	macro: p 0.3489, r 0.3243, f1: 0.3265	micro: p 0.5943, r 0.5943, f1 0.5943	weighted_f1:0.5577
global_step: 19761, epoch: 95, loss: 0.741918
global_step: 19762, epoch: 95, loss: 0.630660
global_step: 19763, epoch: 95, loss: 0.603822
global_step: 19764, epoch: 95, loss: 0.732570
global_step: 19765, epoch: 95, loss: 0.537780
global_step: 19766, epoch: 95, loss: 0.614128
global_step: 19767, epoch: 95, loss: 0.582513
global_step: 19768, epoch: 95, loss: 0.573263
global_step: 19769, epoch: 95, loss: 0.693238
global_step: 19770, epoch: 95, loss: 0.648335
global_step: 19771, epoch: 95, loss: 0.643596
global_step: 19772, epoch: 95, loss: 0.650331
global_step: 19773, epoch: 95, loss: 0.609858
global_step: 19774, epoch: 95, loss: 0.689895
global_step: 19775, epoch: 95, loss: 0.599013
global_step: 19776, epoch: 95, loss: 0.630868
global_step: 19777, epoch: 95, loss: 0.715930
global_step: 19778, epoch: 95, loss: 0.703646
global_step: 19779, epoch: 95, loss: 0.620551
global_step: 19780, epoch: 95, loss: 0.696324
global_step: 19781, epoch: 95, loss: 0.710802
global_step: 19782, epoch: 95, loss: 0.615979
global_step: 19783, epoch: 95, loss: 0.701395
global_step: 19784, epoch: 95, loss: 0.681149
global_step: 19785, epoch: 95, loss: 0.716326
global_step: 19786, epoch: 95, loss: 0.697157
global_step: 19787, epoch: 95, loss: 0.701826
global_step: 19788, epoch: 95, loss: 0.636346
global_step: 19789, epoch: 95, loss: 0.707732
global_step: 19790, epoch: 95, loss: 0.634383
global_step: 19791, epoch: 95, loss: 0.607991
global_step: 19792, epoch: 95, loss: 0.619293
global_step: 19793, epoch: 95, loss: 0.600420
global_step: 19794, epoch: 95, loss: 0.656828
global_step: 19795, epoch: 95, loss: 0.696405
global_step: 19796, epoch: 95, loss: 0.614406
global_step: 19797, epoch: 95, loss: 0.733875
global_step: 19798, epoch: 95, loss: 0.588036
global_step: 19799, epoch: 95, loss: 0.706713
global_step: 19800, epoch: 95, loss: 0.380718
epoch: 95
train	acc: 0.8761	macro: p 0.8971, r 0.6919, f1: 0.7305	micro: p 0.8761, r 0.8761, f1 0.8761	weighted_f1:0.8650
dev	acc: 0.5437	macro: p 0.3259, r 0.3015, f1: 0.2955	micro: p 0.5437, r 0.5437, f1 0.5437	weighted_f1:0.4906
test	acc: 0.6008	macro: p 0.3618, r 0.3165, f1: 0.3201	micro: p 0.6008, r 0.6008, f1 0.6008	weighted_f1:0.5537
global_step: 19801, epoch: 96, loss: 0.688416
global_step: 19802, epoch: 96, loss: 0.645032
global_step: 19803, epoch: 96, loss: 0.640761
global_step: 19804, epoch: 96, loss: 0.662615
global_step: 19805, epoch: 96, loss: 0.594040
global_step: 19806, epoch: 96, loss: 0.667859
global_step: 19807, epoch: 96, loss: 0.611782
global_step: 19808, epoch: 96, loss: 0.642733
global_step: 19809, epoch: 96, loss: 0.622354
global_step: 19810, epoch: 96, loss: 0.636826
global_step: 19811, epoch: 96, loss: 0.669726
global_step: 19812, epoch: 96, loss: 0.594690
global_step: 19813, epoch: 96, loss: 0.559908
global_step: 19814, epoch: 96, loss: 0.752114
global_step: 19815, epoch: 96, loss: 0.559895
global_step: 19816, epoch: 96, loss: 0.598220
global_step: 19817, epoch: 96, loss: 0.570175
global_step: 19818, epoch: 96, loss: 0.632177
global_step: 19819, epoch: 96, loss: 0.620065
global_step: 19820, epoch: 96, loss: 0.501817
global_step: 19821, epoch: 96, loss: 0.606765
global_step: 19822, epoch: 96, loss: 0.575579
global_step: 19823, epoch: 96, loss: 0.596073
global_step: 19824, epoch: 96, loss: 0.607860
global_step: 19825, epoch: 96, loss: 0.559163
global_step: 19826, epoch: 96, loss: 0.675939
global_step: 19827, epoch: 96, loss: 0.584831
global_step: 19828, epoch: 96, loss: 0.655053
global_step: 19829, epoch: 96, loss: 0.563663
global_step: 19830, epoch: 96, loss: 0.694626
global_step: 19831, epoch: 96, loss: 0.744578
global_step: 19832, epoch: 96, loss: 0.679922
global_step: 19833, epoch: 96, loss: 0.686190
global_step: 19834, epoch: 96, loss: 0.653227
global_step: 19835, epoch: 96, loss: 0.674796
global_step: 19836, epoch: 96, loss: 0.692811
global_step: 19837, epoch: 96, loss: 0.670899
global_step: 19838, epoch: 96, loss: 0.708812
global_step: 19839, epoch: 96, loss: 0.682858
global_step: 19840, epoch: 96, loss: 0.722132
epoch: 96
train	acc: 0.8838	macro: p 0.8995, r 0.7165, f1: 0.7565	micro: p 0.8838, r 0.8838, f1 0.8838	weighted_f1:0.8752
dev	acc: 0.5428	macro: p 0.3322, r 0.3089, f1: 0.3014	micro: p 0.5428, r 0.5428, f1 0.5428	weighted_f1:0.4939
test	acc: 0.5977	macro: p 0.3601, r 0.3182, f1: 0.3178	micro: p 0.5977, r 0.5977, f1 0.5977	weighted_f1:0.5517
global_step: 19841, epoch: 97, loss: 0.693922
global_step: 19842, epoch: 97, loss: 0.596385
global_step: 19843, epoch: 97, loss: 0.676214
global_step: 19844, epoch: 97, loss: 0.592443
global_step: 19845, epoch: 97, loss: 0.671066
global_step: 19846, epoch: 97, loss: 0.557123
global_step: 19847, epoch: 97, loss: 0.629255
global_step: 19848, epoch: 97, loss: 0.555395
global_step: 19849, epoch: 97, loss: 0.632708
global_step: 19850, epoch: 97, loss: 0.591031
global_step: 19851, epoch: 97, loss: 0.533274
global_step: 19852, epoch: 97, loss: 0.611207
global_step: 19853, epoch: 97, loss: 0.539435
global_step: 19854, epoch: 97, loss: 0.699740
global_step: 19855, epoch: 97, loss: 0.683890
global_step: 19856, epoch: 97, loss: 0.648280
global_step: 19857, epoch: 97, loss: 0.675920
global_step: 19858, epoch: 97, loss: 0.698456
global_step: 19859, epoch: 97, loss: 0.567919
global_step: 19860, epoch: 97, loss: 0.651664
global_step: 19861, epoch: 97, loss: 0.645663
global_step: 19862, epoch: 97, loss: 0.559786
global_step: 19863, epoch: 97, loss: 0.522781
global_step: 19864, epoch: 97, loss: 0.590120
global_step: 19865, epoch: 97, loss: 0.615451
global_step: 19866, epoch: 97, loss: 0.669826
global_step: 19867, epoch: 97, loss: 0.634453
global_step: 19868, epoch: 97, loss: 0.549042
global_step: 19869, epoch: 97, loss: 0.673307
global_step: 19870, epoch: 97, loss: 0.639170
global_step: 19871, epoch: 97, loss: 0.643801
global_step: 19872, epoch: 97, loss: 0.725056
global_step: 19873, epoch: 97, loss: 0.661766
global_step: 19874, epoch: 97, loss: 0.716601
global_step: 19875, epoch: 97, loss: 0.683116
global_step: 19876, epoch: 97, loss: 0.678089
global_step: 19877, epoch: 97, loss: 0.623296
global_step: 19878, epoch: 97, loss: 0.625923
global_step: 19879, epoch: 97, loss: 0.679963
global_step: 19880, epoch: 97, loss: 0.576902
epoch: 97
train	acc: 0.8860	macro: p 0.9021, r 0.7214, f1: 0.7616	micro: p 0.8860, r 0.8860, f1 0.8860	weighted_f1:0.8776
dev	acc: 0.5419	macro: p 0.3295, r 0.3061, f1: 0.3010	micro: p 0.5419, r 0.5419, f1 0.5419	weighted_f1:0.4938
test	acc: 0.5973	macro: p 0.3578, r 0.3171, f1: 0.3185	micro: p 0.5973, r 0.5973, f1 0.5973	weighted_f1:0.5523
global_step: 19881, epoch: 98, loss: 0.595463
global_step: 19882, epoch: 98, loss: 0.635703
global_step: 19883, epoch: 98, loss: 0.617001
global_step: 19884, epoch: 98, loss: 0.668393
global_step: 19885, epoch: 98, loss: 0.613826
global_step: 19886, epoch: 98, loss: 0.650920
global_step: 19887, epoch: 98, loss: 0.595767
global_step: 19888, epoch: 98, loss: 0.647816
global_step: 19889, epoch: 98, loss: 0.617338
global_step: 19890, epoch: 98, loss: 0.629224
global_step: 19891, epoch: 98, loss: 0.551123
global_step: 19892, epoch: 98, loss: 0.632444
global_step: 19893, epoch: 98, loss: 0.614705
global_step: 19894, epoch: 98, loss: 0.682159
global_step: 19895, epoch: 98, loss: 0.652989
global_step: 19896, epoch: 98, loss: 0.568176
global_step: 19897, epoch: 98, loss: 0.561304
global_step: 19898, epoch: 98, loss: 0.666517
global_step: 19899, epoch: 98, loss: 0.637299
global_step: 19900, epoch: 98, loss: 0.681539
global_step: 19901, epoch: 98, loss: 0.678699
global_step: 19902, epoch: 98, loss: 0.682811
global_step: 19903, epoch: 98, loss: 0.638824
global_step: 19904, epoch: 98, loss: 0.640847
global_step: 19905, epoch: 98, loss: 0.646621
global_step: 19906, epoch: 98, loss: 0.631581
global_step: 19907, epoch: 98, loss: 0.609221
global_step: 19908, epoch: 98, loss: 0.665716
global_step: 19909, epoch: 98, loss: 0.567070
global_step: 19910, epoch: 98, loss: 0.567029
global_step: 19911, epoch: 98, loss: 0.722180
global_step: 19912, epoch: 98, loss: 0.612552
global_step: 19913, epoch: 98, loss: 0.664081
global_step: 19914, epoch: 98, loss: 0.629458
global_step: 19915, epoch: 98, loss: 0.767763
global_step: 19916, epoch: 98, loss: 0.613453
global_step: 19917, epoch: 98, loss: 0.591790
global_step: 19918, epoch: 98, loss: 0.701254
global_step: 19919, epoch: 98, loss: 0.677530
global_step: 19920, epoch: 98, loss: 1.260139
epoch: 98
train	acc: 0.8929	macro: p 0.8999, r 0.7365, f1: 0.7700	micro: p 0.8929, r 0.8929, f1 0.8929	weighted_f1:0.8855
dev	acc: 0.5356	macro: p 0.3204, r 0.3083, f1: 0.3042	micro: p 0.5356, r 0.5356, f1 0.5356	weighted_f1:0.4937
test	acc: 0.5927	macro: p 0.3491, r 0.3244, f1: 0.3271	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5560
global_step: 19921, epoch: 99, loss: 0.587522
global_step: 19922, epoch: 99, loss: 0.614701
global_step: 19923, epoch: 99, loss: 0.585505
global_step: 19924, epoch: 99, loss: 0.595670
global_step: 19925, epoch: 99, loss: 0.626128
global_step: 19926, epoch: 99, loss: 0.598628
global_step: 19927, epoch: 99, loss: 0.609816
global_step: 19928, epoch: 99, loss: 0.617653
global_step: 19929, epoch: 99, loss: 0.724090
global_step: 19930, epoch: 99, loss: 0.581410
global_step: 19931, epoch: 99, loss: 0.530326
global_step: 19932, epoch: 99, loss: 0.610408
global_step: 19933, epoch: 99, loss: 0.705076
global_step: 19934, epoch: 99, loss: 0.645451
global_step: 19935, epoch: 99, loss: 0.680716
global_step: 19936, epoch: 99, loss: 0.674865
global_step: 19937, epoch: 99, loss: 0.723082
global_step: 19938, epoch: 99, loss: 0.569342
global_step: 19939, epoch: 99, loss: 0.638471
global_step: 19940, epoch: 99, loss: 0.685043
global_step: 19941, epoch: 99, loss: 0.632484
global_step: 19942, epoch: 99, loss: 0.609266
global_step: 19943, epoch: 99, loss: 0.655145
global_step: 19944, epoch: 99, loss: 0.731600
global_step: 19945, epoch: 99, loss: 0.592268
global_step: 19946, epoch: 99, loss: 0.636004
global_step: 19947, epoch: 99, loss: 0.635747
global_step: 19948, epoch: 99, loss: 0.767945
global_step: 19949, epoch: 99, loss: 0.625298
global_step: 19950, epoch: 99, loss: 0.540512
global_step: 19951, epoch: 99, loss: 0.714689
global_step: 19952, epoch: 99, loss: 0.518757
global_step: 19953, epoch: 99, loss: 0.653154
global_step: 19954, epoch: 99, loss: 0.664240
global_step: 19955, epoch: 99, loss: 0.614666
global_step: 19956, epoch: 99, loss: 0.660879
global_step: 19957, epoch: 99, loss: 0.711831
global_step: 19958, epoch: 99, loss: 0.554261
global_step: 19959, epoch: 99, loss: 0.530465
global_step: 19960, epoch: 99, loss: 0.511935
epoch: 99
train	acc: 0.8916	macro: p 0.9058, r 0.7380, f1: 0.7797	micro: p 0.8916, r 0.8916, f1 0.8916	weighted_f1:0.8847
dev	acc: 0.5383	macro: p 0.3217, r 0.3031, f1: 0.2985	micro: p 0.5383, r 0.5383, f1 0.5383	weighted_f1:0.4908
test	acc: 0.5927	macro: p 0.3465, r 0.3140, f1: 0.3154	micro: p 0.5927, r 0.5927, f1 0.5927	weighted_f1:0.5486
global_step: 19961, epoch: 100, loss: 0.534720
global_step: 19962, epoch: 100, loss: 0.655183
global_step: 19963, epoch: 100, loss: 0.560144
global_step: 19964, epoch: 100, loss: 0.613834
global_step: 19965, epoch: 100, loss: 0.610436
global_step: 19966, epoch: 100, loss: 0.644271
global_step: 19967, epoch: 100, loss: 0.537902
global_step: 19968, epoch: 100, loss: 0.661652
global_step: 19969, epoch: 100, loss: 0.650124
global_step: 19970, epoch: 100, loss: 0.598866
global_step: 19971, epoch: 100, loss: 0.739948
global_step: 19972, epoch: 100, loss: 0.580698
global_step: 19973, epoch: 100, loss: 0.696320
global_step: 19974, epoch: 100, loss: 0.656387
global_step: 19975, epoch: 100, loss: 0.614145
global_step: 19976, epoch: 100, loss: 0.564797
global_step: 19977, epoch: 100, loss: 0.646208
global_step: 19978, epoch: 100, loss: 0.669992
global_step: 19979, epoch: 100, loss: 0.708489
global_step: 19980, epoch: 100, loss: 0.709470
global_step: 19981, epoch: 100, loss: 0.589820
global_step: 19982, epoch: 100, loss: 0.666448
global_step: 19983, epoch: 100, loss: 0.537470
global_step: 19984, epoch: 100, loss: 0.610184
global_step: 19985, epoch: 100, loss: 0.587691
global_step: 19986, epoch: 100, loss: 0.562811
global_step: 19987, epoch: 100, loss: 0.635219
global_step: 19988, epoch: 100, loss: 0.620250
global_step: 19989, epoch: 100, loss: 0.670355
global_step: 19990, epoch: 100, loss: 0.640822
global_step: 19991, epoch: 100, loss: 0.600378
global_step: 19992, epoch: 100, loss: 0.556138
global_step: 19993, epoch: 100, loss: 0.653376
global_step: 19994, epoch: 100, loss: 0.705666
global_step: 19995, epoch: 100, loss: 0.589866
global_step: 19996, epoch: 100, loss: 0.655631
global_step: 19997, epoch: 100, loss: 0.604210
global_step: 19998, epoch: 100, loss: 0.648983
global_step: 19999, epoch: 100, loss: 0.721624
global_step: 20000, epoch: 100, loss: 0.726354
epoch: 100
train	acc: 0.8953	macro: p 0.9028, r 0.7421, f1: 0.7759	micro: p 0.8953, r 0.8953, f1 0.8953	weighted_f1:0.8875
dev	acc: 0.5365	macro: p 0.3217, r 0.3045, f1: 0.2987	micro: p 0.5365, r 0.5365, f1 0.5365	weighted_f1:0.4900
test	acc: 0.5954	macro: p 0.3500, r 0.3186, f1: 0.3197	micro: p 0.5954, r 0.5954, f1 0.5954	weighted_f1:0.5523
BEST MODEL epoch: 54
train	acc: 0.7388 macro_p: 0.5072 macro_r: 0.4642 macro_f1: 0.4733 micro_p: 0.7388 micro_r: 0.7388 micro_f1: 0.7388 weighted_f1: 0.7075
dev	acc: 0.5627 macro_p: 0.3475 macro_r: 0.3168 macro_f1: 0.3099 micro_p: 0.5627 micro_r: 0.5627 micro_f1: 0.5627 weighted_f1: 0.5084
test	acc: 0.5992 macro_p: 0.3596 macro_r: 0.3184 macro_f1: 0.3209 micro_p: 0.5992 micro_r: 0.5992 micro_f1: 0.5992 weighted_f1: 0.5551
====================TRAINING FINISHED====================
best epoch: [44, 62, 64, 43, 54], avg test weighted f1: 0.556088
